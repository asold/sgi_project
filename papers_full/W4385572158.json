{
  "title": "Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction",
  "url": "https://openalex.org/W4385572158",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2127268750",
      "name": "Ashish Sharma",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2112208620",
      "name": "Kevin Rushton",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": null,
      "name": "Inna Lin",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2062479001",
      "name": "David Wadden",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A5035889285",
      "name": "Khendra Lucas",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2664001902",
      "name": "Adam Miner",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2130436610",
      "name": "Theresa Nguyen",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2227326281",
      "name": "Tim Althoff",
      "affiliations": [
        "Stanford University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4220763927",
    "https://openalex.org/W3034496424",
    "https://openalex.org/W3033757400",
    "https://openalex.org/W3034319502",
    "https://openalex.org/W3106912061",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W3034595127",
    "https://openalex.org/W4308827648",
    "https://openalex.org/W3205149574",
    "https://openalex.org/W2934582891",
    "https://openalex.org/W2613485171",
    "https://openalex.org/W4400139037",
    "https://openalex.org/W2911378332",
    "https://openalex.org/W1560729591",
    "https://openalex.org/W4285158689",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4385572715",
    "https://openalex.org/W2167299310",
    "https://openalex.org/W2963303106",
    "https://openalex.org/W3104982372",
    "https://openalex.org/W4224326626",
    "https://openalex.org/W4287854610",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W3197754201",
    "https://openalex.org/W2988937804",
    "https://openalex.org/W4317757464",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4385574293",
    "https://openalex.org/W2063051517",
    "https://openalex.org/W4206657241",
    "https://openalex.org/W3026768119",
    "https://openalex.org/W2965016654",
    "https://openalex.org/W3026338371",
    "https://openalex.org/W2136511536",
    "https://openalex.org/W1585767463",
    "https://openalex.org/W3154272574",
    "https://openalex.org/W4288262459",
    "https://openalex.org/W4385572965",
    "https://openalex.org/W2069858173",
    "https://openalex.org/W2964134121",
    "https://openalex.org/W2964262738",
    "https://openalex.org/W4385573223",
    "https://openalex.org/W2980364910",
    "https://openalex.org/W2048587526",
    "https://openalex.org/W2080095540",
    "https://openalex.org/W2951098724",
    "https://openalex.org/W4308900200",
    "https://openalex.org/W3207821200",
    "https://openalex.org/W2412278397",
    "https://openalex.org/W2734466076",
    "https://openalex.org/W3099215402",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2046115172",
    "https://openalex.org/W3176855473",
    "https://openalex.org/W3182275036",
    "https://openalex.org/W4226353085",
    "https://openalex.org/W2795743556",
    "https://openalex.org/W2983921939"
  ],
  "abstract": "Ashish Sharma, Kevin Rushton, Inna Lin, David Wadden, Khendra Lucas, Adam Miner, Theresa Nguyen, Tim Althoff. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
  "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 9977–10000\nJuly 9-14, 2023 ©2023 Association for Computational Linguistics\nCognitive Reframing of Negative Thoughts through\nHuman-Language Model Interaction\nAshish Sharma♠ Kevin Rushton♢ Inna Wanyin Lin♠ David Wadden♣\nKhendra G. Lucas♢ Adam S. Miner♥♡ Theresa Nguyen♢ Tim Althoff♠\n♠Paul G. Allen School of Computer Science & Engineering, University of Washington\n♢Mental Health America ♣Allen Institute for Artificial Intelligence\n♥Department of Psychiatry and Behavioral Sciences, Stanford University\n♡Center for Biomedical Informatics Research, Stanford University\n{ashshar,althoff}@cs.washington.edu\nAbstract\nA proven therapeutic technique to overcome\nnegative thoughts is to replace them with a\nmore hopeful “reframed thought.” Although\ntherapy can help people practice and learn\nthis Cognitive Reframing of Negative Thoughts,\nclinician shortages and mental health stigma\ncommonly limit people’s access to therapy. In\nthis paper, we conduct a human-centered study\nof how language models may assist people in\nreframing negative thoughts. Based on psychol-\nogy literature, we define a framework of seven\nlinguistic attributes that can be used to reframe\na thought. We develop automated metrics to\nmeasure these attributes and validate them with\nexpert judgements from mental health practi-\ntioners. We collect a dataset of 600 situations,\nthoughts and reframes from practitioners and\nuse it to train a retrieval-enhanced in-context\nlearning model that effectively generates re-\nframed thoughts and controls their linguistic\nattributes. To investigate what constitutes a\n“high-quality” reframe, we conduct an IRB-\napproved randomized field study on a large\nmental health website with over 2,000 partici-\npants. Amongst other findings, we show that\npeople prefer highly empathic or specific re-\nframes, as opposed to reframes that are overly\npositive. Our findings provide key implications\nfor the use of LMs to assist people in overcom-\ning negative thoughts.\n1 Introduction\nNegative thoughts are a natural part of human cog-\nnition. However, for people experiencing men-\ntal health challenges, such thoughts are often\nentrenched, automatic and emotionally trigger-\ning, making it difficult to overcome them in-the-\nmoment (Beck, 1976). An evidence-based, well-\nestablished therapeutic intervention to overcome\nnegative thoughts is Cognitive Reframing, in which\na negative thought is replaced with a more hope-\nful “reframed thought,” which offers an alternative\nperspective on one’s situation (Beck, 1976). For\nexample, imagine a person with a situation “ I’m\nsubmitting a research paper to ACL 2023 ” has a\nthought “This paper is going to get rejected .” A\npossible way to reframe this thought is to say “This\npaper has some chance of getting accepted due to\nits novel methodology and potential impact.”\nPsychotherapy research suggests that for a re-\nframed thought to be effective, it must be (a) relat-\nable to the individual, (b) helpful in overcoming the\nnegative thought and (c) memorable to be acces-\nsible the next time a similar thought arises (Beck,\n1976; Burns, 1980). However, understanding what\ncharacterizes a relatable, helpful and memorable\nreframe is challenging and unknown. Professional\ntherapists can support people in coming up with\nsuch highly effective reframed thoughts. However,\nbarriers like clinician shortages, lack of insurance\ncoverage and stigma commonly limit access to ther-\napists (Olfson, 2016; Sickel et al., 2014). NLP-\nbased methods that assist individuals in reframing\nnegative thoughts, in-the-moment, may provide\nscaffolding that is easier to engage with and that\ncould be made widely accessible.\nPrior NLP research has developed methods for\na range of text reframing tasks like sentiment and\nempathy rewriting (Reif et al., 2022; Sharma et al.,\n2021) and more recently, positive reframing (Ziems\net al., 2022). However, little is known about how to\ndevelop cognitive reframing methods that automat-\nically generate relatable, helpful and memorable\nreframed thoughts.\nIn this paper, we conduct a study of how lan-\nguage models can be used to reframe negative\nthoughts (Figure 1). We study ways in which a\nnegative thought can be reframed, how LMs can be\nutilized to perform this reframing and what types\nof reframes are preferred by people who experience\nnegative thoughts.\nFirst, in collaboration with clinical psycholo-\n9977\nMore Actionable\nSituation\nI submitted a research paper and \nit got rejected\nThought\nIʼll never succeed as a researcher\n“It is normal to feel \ndisappointed when a paper \ngets rejected. I can use this \nexperience to learn and \ngrow”\nReframe\nActionability\nPositivity\nAddressing Thinking Trap (e.g., Fortune Telling)\nSpecificity\nRationality Empathy\nReadability\nLinguistic Attributes of Reframed Thoughts\n“It is normal to feel disappointed \nwhen a paper gets rejected. I can \ntake the feedback I received and use \nit to improve my paper”\n“It is normal to feel disappointed \nwhen a paper gets rejected”\n(a)Reframing Negative Thoughts (b) Controlling Reframing Attributes (c) Randomized Field Study Evaluation\nLess Actionable\nACL\nFigure 1: (a) We consider the task of reframing negative thoughts with different, more hopeful thoughts using\nLMs; (b) Different perspectives on a situation may result in different reframes. Here, we propose a framework of\nseven reframing attributes (see gray box). Given a reframed thought, we control each attribute (e.g., actionability)\nto generate reframes that score higher or lower on that attribute (e.g., more or less actionable ); (c) We deploy\nthis model on Mental Health America, a large U.S. national mental health website (bit.ly/changing-thoughts) and\nconduct a randomized field study with 2,067 participants. We suggest LM-generated reframes to MHA visitors and\nassess which reframing attributes are desirable and what constitutes a relatable, helpful and memorable reframe.\ngists and mental health professionals, we develop\na new conceptual framework for characterizing the\nways in which a thought might be reframed. We\nsynthesize the most prominent cognitive reframing\nprocesses used in therapy and define seven linguis-\ntic attributes of reframed thoughts: whether the\nreframe addresses “thinking traps” (faulty or dis-\ntorted patterns of thinking), whether it is rational,\npositive, empathic, actionable, specific and read-\nable. Building on prior research, we develop auto-\nmated metrics to measure these attributes and es-\ntablish construct validity by correlating them with\njudgements from mental health practitioners.\nNext, to develop models for the cognitive re-\nframing task, we collect and share1 a dataset from\nmental health practitioners and clinical psychology\ngraduate students. The dataset includes 600 situa-\ntions and thoughts with expert-suggested reframes\nas well as annotations of the proposed reframing at-\ntributes. Using this dataset, we develop a retrieval-\nenhanced in-context learning method (Brown et al.,\n2020) to generate reframed thoughts and to control\ntheir linguistic attributes. We show that this method\nachieves the highest overlap with expert-suggested\nreframes and the highest relatability and helpful-\nness ratings based on evaluation from mental health\n1Our code and datasets are available at\ngithub.com/behavioral-data/Cognitive-Reframing.\nexperts, when compared to popular NLP baselines.\nWe investigate which reframing attributes are\ndesirable and what constitutes a relatable, helpful\nand memorable reframe. In collaboration (and co-\nauthorship) with mental health experts, and after\nappropriate ethical review, we deploy a month-long\nrandomized field study on Mental Health America\n(MHA; a popular website that shares mental health\nresources and tools online), with 2,067 participants\nwith informed consent. We ask MHA visitors to\ndescribe situations and negative thoughts they are\nexperiencing and then suggest LM-generated re-\nframed thoughts with varying linguistic attributes.\nWe find that highly specific and highly empathic\nreframing is the most preferred and highly specific\nand actionable reframing is considered the most\nhelpful and memorable. However, we find that re-\nframes that are highly positive are less preferred.\nThese findings provide key implications for cogni-\ntive reframing of negative thoughts and for the use\nof Human-LM interaction in this process.\n2 Problem Definition and Goals\nWe work on the task ofCognitive Reframing. Given\na situation Si and a negative thought Ti, the task\nis to generate a reframed thought Ri.\nPsychotherapy literature (Beck, 1976) highlights\nthree desirable outcomes for a successful reframe:\n9978\n(a) the reframed thought must be relatable to the\nindividual, (b) it must help them overcome the neg-\native thought and (c) it must be memorable the next\ntime a similar negative thinking pattern emerges.\nHere, we aim to understand what constitutes\nsuccessful reframing and how language models\ncan assist people in this process. Towards this\ngoal, we characterize the linguistic attributes of re-\nframed thoughts (§3), collect a dataset of situations,\nthoughts and reframes (§4), develop methods to\ngenerate reframes and to measure and control their\nattributes (§5; §6) and investigate which linguistic\nattributes are related to the reframing outcomes of\nrelatability, helpfulness and memorability (§7).\n3 Framework of Linguistic Attributes of\nReframed Thoughts\nWe draw from clinical therapy practices and collab-\norate with mental health experts (some of whom are\nco-authors) to develop a framework of linguistic\nattributes of reframed thoughts. We illustrate these\nattributes with the following example for all re-\nframes below – Situation: “I submitted a research\npaper and it got rejected ;” Thought: “ I’ll never\nsucceed as a researcher.”\nAddressing Thinking Traps. Negative thinking\noften falls into common patterns, called “thinking\ntraps.” Also called cognitive distortions, these in-\nclude exaggerated and biased patterns of thinking\nwhich cause individuals to perceive reality inac-\ncurately (Beck, 1976; Ding et al., 2022). Com-\nmon thinking traps include: assuming what others\nthink (“Mind reading”), thinking in extremes (“All-\nor-nothing thinking”), focusing on the worst-case\nscenario (“Catastrophizing”), trying to predict the\nfuture (“Fortune telling”), etc. See Appendix D for\nthe full list.\nA reframe may or may not directly address one\nor more of the thought’s thinking traps. A reframe\nlike “I don’t know what the future will bring ” di-\nrectly addresses the thinking trap “Fortune telling,”\nwhereas a reframe like “I will surely become a suc-\ncessful researcher” does not address this thinking\ntrap but rather continues to express it.\nRationality. Another strategy to reframe a thought\nis to reflect on evidence for and against it and rea-\nson about what these evidence imply (Beck, 1976).\nFor example, the rejection of the paper is evidence\nof having the thought “ I’ll never succeed as a\nresearcher.” However, the evidence against this\nthought could be that acceptance or rejection of one\npaper does not make someone a failure, which may\nlead to a reframe “Just getting one paper rejected\ndoesn’t define my failure.” A rational reframe is\nguided by such strong evidence whereas an irra-\ntional reframe is based on unrealistic assumptions.\nPositivity. A reframe of a negative thought tries to\nemphasize the positive perspectives of the situation\nbut different reframes may have different levels of\npositivity. An overly positive reframe like “ I’m\ngoing to win best paper awards for every paper\nfrom now on” exaggerates the positive perspectives,\nwhich is likely to set the person up for disappoint-\nment rather than success (Dember and Penwell,\n1980). On the other hand, a balanced response like\n“I may or may not succeed, but I’ll keep trying” con-\nsiders both positive and negative perspectives of\nthe situation.\nEmpathy. It can be helpful to acknowledge the\nfeelings caused by negative thoughts (Allen and\nLeary, 2010; Elliott et al., 2011). A reframe may\nexpress empathy or self-compassion by validating\nhow one is feeling. E.g., “ It is okay to feel disap-\npointed when a paper gets rejected.”\nActionability. To encourage pleasant emotions,\none commonly used therapeutic approach is Behav-\nioral Activation (Dimidjian et al., 2011; Burkhardt\net al., 2021). This involves engaging in behaviors\nor actions that may help in overcoming negative\nthoughts. A reframe may suggest specific actions\n(e.g., “I can take the feedback I received and use\nit to improve my paper”), may not suggest specific\nactions but be actionable (e.g., “I can use this expe-\nrience to learn and grow”) or may not be actionable\nat all (e.g., “I may or may not become a successful\nresearcher”).\nSpecificity. A reframe may specifically address\nthe situation and the thought (e.g., “ One paper\nrejection doesn’t define my failure as a researcher”)\nor may be generic enough to be applicable to a wide\nrange of negative situations and thoughts (e.g., “I’m\ngoing to succeed”). While a specific reframe may\nbe more helpful in-the-moment, a generic reframe\ncould be effective for recurring thoughts, which\nare frequently a result of the “core” beliefs that a\nperson holds (Beck, 2005; David et al., 2009).\nReadability. The linguistic reasoning capabilities\nof individuals may be different (e.g., across age\ngroups or education levels) (Kaplan et al., 1995).\nAccordingly, a reframe may either be simple or\ncomplex to read (e.g., “I’ll do well in the future” vs.\n9979\n“I’m resolute in my ambition to succeed”).\n4 Data Collection\nTo facilitate computational methods for cogni-\ntive reframing, we collect a dataset of reframed\nthoughts, annotated with their linguistic attributes.\n4.1 Curated Situations & Negative Thoughts\nWe start by curating data sources for situations and\nnegative thoughts.\nThought Records Dataset (Burger et al., 2021).\nThis dataset contains hypothetical and real-world\nsituations, thoughts and emotional processes re-\nported by crowdworkers on Amazon Mechanical\nTurk. We manually curate 180 pairs of diverse\nsituations with negative thoughts from this dataset.\nMental Health America (MHA). Situations and\nthoughts from crowdworkers may not reflect the\nbroad range of mental health challenges that people\nface in real-life. To incorporate more real-world\nsituations and thoughts, we ran a survey on the\nMHA website (screening.mhanational.org). MHA\nvisitors (who typically use the website for screen-\ning of mental illnesses) were asked to describe any\nnegative thoughts and the associated situations they\nwere struggling with. We manually curate 120 pairs\nof self-reported situations and thoughts to ensure\nbroad coverage of relevant topics based on high\ndiversity and manual filtering.\n4.2 Annotation Task and Procedure\nReframing negative thoughts is a cognitively dif-\nficult process that requires practice and training,\nmaking crowdwork data collection approaches\nchallenging. To ensure high-quality reframes and\nannotations, we recruit 15 current mental health\npractitioners and clinical psychology graduate stu-\ndents with significant practical experience in cog-\nnitive reframing.2 For each (situation, thought)\npair in our data source (§4.1), we ask them to\n(1) write two different reframed thoughts, (2) an-\nnotate the thinking traps addressed by each re-\nframed thought and (3) compare the two reframes\nand choose the one that is more rational, more\npositive, more actionable, more empathic, more\nspecific and more readable. In total, we col-\nlect 600 reframed thoughts with annotations on\ntheir linguistic attributes. We share this dataset\n2For recruitment, we advertised our study through univer-\nsity mailing lists and newsletter of a mental health organiza-\ntion. Recruited experts were paid @ 37.5 USD / hr.\npublicly at github.com/behavioral-data/Cognitive-\nReframing.\n4.3 Ethics and Safety\nOur data collection and randomized field study (§7)\nwere designed and conducted after review of poten-\ntial benefits and risks to participants in consultation\nand collaboration with mental health experts. Both\nstudies were approved by the University of Wash-\nington’s Institutional Review Board and informed\nparticipants about study purpose, risks and data col-\nlection. All participants were 18 or older, provided\ninformed consent and were given access to a crisis\nhotline. We do not assess any clinical outcomes.\nSee §10 for an extended discussion of ethical and\nsafety considerations.\n5 Method\nWe design automated metrics for measuring linguis-\ntic attributes (§5.1), develop methods to generate\nreframed thoughts (§5.2) and to control their at-\ntributes (§5.3).\n5.1 Measuring Reframing Attributes\nAddressing Thinking Traps. Given a situation Si,\na negative thought Ti and a reframed thought Ri,\nour goal is to identify the set of thinking traps ad-\ndressed by the reframed thought. We approach this\nas a multi-label classification task, and fine-tune\na GPT-3 model3 on the expert-annotated thinking\ntrap labels collected in §4.2.\nRationality. Rationality is the quality of being\nguided by reasons (Damielson et al., 2004). Here,\nwe operationalize rationality of a reframed thought\nRi as its reasoning strength and ask the following\ntwo questions: (1) What might be the reasoning\nbehind Ri?; (2) Are the reasons sound? To un-\nderstand the reasoning behind Ri, we develop an\nabductive explanation based method (Peirce, 1974;\nBhagavatula et al., 2020; Jung et al., 2022). For a\ngiven (Si, Ti), we use a language model to generate\n(a) the most plausible explanations that support Ri\nand (b) the most plausible explanations thatrefute it.\nMoreover, to check if the explanations are sound,\nwe recursively generate explanations behind the\nexplanations to test their reasoning strength (Ap-\npendix E). Let sup(⋅) be a generator function that\ngenerates explanation supporting a reframe and let\n3We use text-davinci-003 as our GPT-3 model for all\nexperiments in this paper.\n9980\nref(⋅) be a generator function that generates ex-\nplanation refuting a reframe. Then, we recursively\ndefine reasoning strength RS(Si, Ti, Ri) as\n(P(Ri =sound∣Si, Ti)×Er∼sup(⋅) [RS (Si, Ti, r)])\n−(P(Ri =flawed∣Si, Ti)× Er∼ref(⋅) [RS (Si, Ti, r)])\nTo design the explanation generator functions,\nsup(⋅)and ref(⋅), we leverage in-context learning\n(Brown et al., 2020). In collaboration with mental\nhealth experts, we design 10 demonstration exam-\nples of situations, thoughts and reframed thoughts\nwith explanations that support (“ This reframed\nthought is sound because... ”) and refute (“ This\nreframed thought is flawed because... ”) a partic-\nular reframe. We use these examples to prompt\nGPT-3. Moreover, to estimate the probabilities\nP(Ri = sound) and P(Ri = flawed), we use\nthe token probability of generating “ sound” and\n“flawed” respectively, givenSi, Ti, Ri and the text\n“This reframed thought is” as input to GPT-3.4\nPositivity. To measure the positivity of the gener-\nated reframed thought, we use a RoBERTa-based\nsentiment classifier fine-tuned on the TweetEval\nbenchmark (Barbieri et al., 2020).\nEmpathy. To measure empathy, we build upon the\nempathy classification model presented in Sharma\net al. (2020b). This RoBERTa-based model lever-\nages a theoretically-grounded framework of em-\npathy consisting of three empathy communication\nmechanisms (emotional reactions, interpretations\nand explorations) and predicts empathy levels in\nmental health conversations on a scale from 0 to\n6. Here, we further fine-tune this model on the\ndomain of reframed thoughts through a manually\nlabeled dataset of 300 reframed thoughts with em-\npathy labels (labeled by one author with expertise\nin empathy in mental health context).\nActionability. To measure actionability, we hy-\npothesize that an actionable reframe is one that\neither (1) suggests a concrete actionor (2) does not\nsuggest a concrete action but is easy to act upon.\nWe cast action concreteness as a binary\nclassification task: given reframe Ri, predict\ncontains_action(Ri) ∈ {0, 1}. We make few-\nshot predictions by prompting GPT-3 with 10 exam-\nples of reframed thoughts paired with actionability\nratings from §4.2 (details in Appendix A.1).\nTo determine the ease with which Ri can be\nacted upon, we examine the next set of actions\n4We experimented with different alternatives for “sound”\nand “flawed” and observed similar results.\nentailed by Ri. Our hypothesis is that a diverse\nnext action set may indicate ambiguity which\nmight be less actionable, whereas a coherent next\naction set may indicate clarity which might be\nmore actionable. Here, we instruct GPT-3 to\ngenerate k = 5 next action candidates given a\nreframed thought (instruction prompting; zero-\nshot). We compute the next action coherence —\ndenoted next_action_coherence(Ri) — by em-\nbedding each of the k action candidates using\nRoBERTa (Liu et al., 2019) and computing the\naverage pairwise cosine similarity. Higher simi-\nlarity indicates greater coherence among the pos-\nsible next actions. Our overall actionability mea-\nsurement is defined as contains_action(Ri) +\nnext_action_coherence(Ri).\nSpecificity. Following prior work (Xu et al., 2018;\nSharma et al., 2021), we measure specificity us-\ning sentence embedding similarity between the re-\nframed thought Ri and the concatenation of the\nsituation Si and the thought Ti (using RoBERTa\nembeddings (Liu et al., 2019)).\nReadability. We employ the commonly used\nColeman-Liau Index (CLI) metric (Coleman and\nLiau, 1975) which assesses readability based on\nthe character and word structure within a sen-\ntence. The Coleman-Liau Index is calculated as\n0.0588L −0.296S −15.8, where L: average num-\nber of letters per 100 words; S is the average num-\nber of sentences per 100 words.\n5.2 Reframe Generation\nIn-context learning methods can learn to generalize\nNLP tasks from a handful of examples ( few-shot\nlearning) or from hand-written instructions alone\n(instruction prompting) (Brown et al., 2020). How-\never, through a qualitative analysis of 100 manually\nwritten situations and thoughts, we found that a\nsimple in-context learning method with a fixed set\nof examples often failed to appropriately reframe\nsituations and thoughts for which no relevant in-\ncontext examples were provided (e.g., someone\nwith anxiety having “racing thoughts”).\nTo appropriately reframe thoughts related to a\nrange of situations and thoughts, we develop a\nretrieval-based in-context learning method (Liu\net al., 2022b). For each situation Si and nega-\ntive thought Ti, we retrieve k-similar examples\nfrom our dataset (§4). We first encode situations\nand thoughts using RoBERTa embeddings. Then,\nwe retrieve k examples, {(s1, t1), ...,(sk, tk)},\n9981\nAttribute Pearson Correlation\nAddressing Thinking Traps 0.680***\nRationality 0.448**\nPositivity 0.550***\nEmpathy 0.575***\nActionability 0.647***\nSpecificity 0.427**\nReadability 0.331*\nTable 1: Correlation of our proposed attribute measures\nby with human judgments from mental health experts.\n*:p <0.05; **:p <0.001; ***:p <10−5.\nfrom our dataset based on the top- k values of\ncosine_sim(concat(s, t), concat(Si, Ti)). We\nchoose k =5 (Appendix A.3).\n5.3 Controlling Linguistic Attributes of\nGenerated Reframes\nWhile our proposed method allows us to generate a\nsingle reframe, it does not directly give us control\nover its linguistic attributes beyond mimicking the\nretrieved examples (§3). Here, we intend to vary\nthe linguistic attributes of the reframes.\nA reframed thought may or may not address a\nthinking trap in the original thought Ti. Here, we\ngenerate two reframes Ri\n(tt,Y) and Ri\n(tt,N), one\nthat addresses the thinking traps in Ti and another\nthat does not address it.5 We extract two separate\nsets of in-context examples from our dataset – those\nthat address at least one thinking trap and those that\ndo not (as collected in §4). We use those examples\nto prompt GPT-3 to generate Ri\n(tt,Y) and Ri\n(tt,N).\nMoreover, a reframed thought may have high\nor low rationality, positivity, empathy, actionabil-\nity, specificity and readability values. For these\nsix attributes, given a reframe Ri and a linguistic\nattribute a, we generate two additional reframes\nRi\n(a,H) and Ri\n(a,L), one that scores higher on at-\ntribute a and another that scores lower on it (e.g.,\nhigher or lower actionability). To accomplish this,\nrecall that each (situation, thought) pair from §4.2\nis annotated with two reframes and that the re-\nframes are compared along each linguistic attribute.\nFor a human-annotated instance j, let Rj\n∗(a,H) and\nRj\n∗(a,L) be the reframes judged to be high and low\non attribute a, respectively. To generate Ri\n(a,H)\nfrom Ri, we prompt GPT-3 with in-context ex-\namples {Rj\n∗(a,L) → Rj\n∗(a,H)}k\nj=1, using k = 5.\n5If a thought exhibits multiple thinking traps, we check if\nthe reframe addresses at least one of them.\nModel Automatic Human\nBLEU R-1 R-L BScore Rel. Help.\nRetrieval Only 21.6 18.8 14.2 86.7 2.58 3.14\nPos. Reframing 24.4 23.6 17.6 87.6 2.67 2.40\nDialoGPT 22.5 17.4 13.5 86.3 2.49 3.21\nT5 24.9 23.4 17.8 87.2 2.51 3.30\nGPT-3 Only 25.0 23.9 18.0 88.3 2.97 3.98\nOur Model 27.8 26.0 19.9 88.6 3.10 4.11\nTable 2: Automatic and Human Evaluation Results. R-1:\nROUGE-1; R-L: ROUGE-L; BScore: BertScore; Rel.:\nRelatability; Help.: Helpfulness.\nSimilarly, to generate Ri\n(a,L) from Ri, we prompt\nGPT-3 with examples {Rj\n∗(a,H) → Rj\n∗(a,L)}k\nj=1.\n6 Experiments and Results\nWe assess the construct validity of proposed linguis-\ntic attributes (§6.1) and evaluate the performance\nof the reframe generation model (§6.2).\n6.1 Construct Validity of Linguistic Attributes\nWe validate our proposed linguistic attribute mea-\nsures by correlating them with the human judg-\nments of mental health experts, as obtained in\n§4.2. We find a strong Pearson correlation for\naddressing thinking traps (0.680***) and action-\nability (0.647***), a moderate correlation for ra-\ntionality (0.448**), positivity (0.550***), empathy\n(0.575***) and specificity (0.427**), and a weak\ncorrelation for readability (0.331*) (Table 1).6\n6.2 Reframe Generation Performance\nWe use both automatic and human evaluation to\nassess the performance of our proposed reframe\ngeneration model as developed in §5.2.\nExperimental Setup. We use top-p sampling with\np =0.6 for text generation (Holtzman et al., 2020).\nWe split the 600 expert-annotated examples (§4)\ninto train and test using a 70:30 split.\nBaselines. (1) Retrieval Only – For a test input, we\nretrieve the training set example with the highest\ncosine similarity based on RoBERTa embeddings;\n(2) Positive Reframing – We reuse the BART-based\npositive reframing model from Ziems et al. (2022);\n(3) DialoGPT – GPT-2 adapted to dialogue (Zhang\net al., 2020); (4) T5 – Text-to-text transfer LM (Raf-\nfel et al., 2020);7 (5) GPT-3 Only – We randomly\n6*:p <0.05;**:p <0.001;***:p <10−5\n7Training DialoGPT and T5 on 600 samples only may\nbe challenging. Here, we use an overgeneration strategy –\n9982\n(a) (b) (c) (d) (e) (f) (g)\nFigure 2: Which linguistic attributes of reframed thoughts do people prefer? For a given situation and thought\nfrom MHA visitors, we show them multiple LM-generated reframes with variance across a randomly selected\nattribute (e.g., low, medium and high actionability). We find that highly empathic and highly specific reframings are\nmore preferred. On the other hand, reframes with high positivity are less preferred. N: No; Y: Yes; L: Low; M:\nMedium; H: High. Error bars in any figure represent 95% bootstrapped confidence intervals.\nretrieve 5 examples from our training set and use\nthem to prompt GPT-3.\nAutomatic Evaluation. We examine the se-\nmantic similarity between the model outputs\nand the ground truth reframings in the above-\ncreated test split. We use BLEU (Papineni et al.,\n2002), ROUGE-1, ROUGE-L (Lin, 2004) and the\nBERTScore (Zhang et al., 2019b) metrics. We\nfind that our proposed model has an 11.2% higher\nBLEU score and 9.7% higher ROUGE scores than\nthe next best-performing baselines – GPT-3 Only\nand Positive Reframing (Table 2).\nHuman Evaluation. We assess the two key refram-\ning outcome metrics of relatability (how relatable\nwould a reframed thought be) and helpfulness (how\nhelpful would a reframed thought be in overcom-\ning negative thoughts). We recruit three mental\nhealth practitioners. We ask them to rate the mod-\nels’ outputs on test set examples based on their\nreliability and helpfulness on a 1 to 5 scale. We\nfind that our proposed model achieves the highest\nrelatability and helpfulness ratings (Table 2). Sur-\nprisingly, the Positive Reframing method showed\nthe least helpfulness and low relatability, indicat-\ning that just reframing negative thoughts based on\npositivity may not be highly relatable and helpful.\n7 Randomized Field Study on a Large\nMental Health Platform\nNext, we deploy our model on a large mental health\nplatform (§7.1) and study what types of reframes\ndo people prefer (§7.2) and what characterizes re-\nlatable, helpful and memorable reframes (§7.3).\nStarting from our collected data samples, we utilize the pattern\nreplication capabilities of GPT-3 to generate 10,000 more\nexamples, similar to Liu et al. (2022a).\n7.1 Model Deployment\nWe try to understand how our proposed cognitive\nreframing model may assist people who experience\nnegative thoughts. After careful assessment of ethi-\ncal and safety considerations, active collaboration\nwith mental health experts and clinical psychol-\nogists (some of whom are co-authors) and IRB\napproval, we deploy our model on Mental Health\nAmerica (MHA), a large mental health website\nthat provides mental health resources and tools to\nmillions of users (bit.ly/changing-thoughts). We\nconduct a month-long randomized field study with\n2,067 MHA visitors as participants. After choosing\nto use our model and after consenting to partici-\npate, MHA visitors described their situation and\nthe thoughts they were struggling with. Next, they\nwere shown multiple model-generated reframed\nthoughts in random order, asked to select the re-\nframed thought they find most relatable, helpful\nand memorable and finally evaluate the selected\nreframed thought based on relatability, helpfulness\nand memorability (See Appendix F).\n7.2 What types of reframed thoughts do\npeople prefer?\nTo understand which reframing attributes people\nprefer, we suggest multiple LM-generated reframes\nwhich vary across our attribute values. Given a\nsituation and thought, we start by generating one\nreframed thought using our model. Next, we ran-\ndomly select an attribute (e.g., actionability) and\nvary the first reframe based on it (e.g., to gener-\nate two additional reframes with higher or lower\nactionability) using our proposed controllable text\ngeneration method (§5.3). Figure 2 reveals key\ndifferences between the linguistic attributes of re-\nframes that people select and prefer:\n9983\n** *\n**\n**\n*\n*(a)\n(c)\n(b)\nFigure 3: Which linguistic attributes are associated with desired cognitive reframing outcomes? For a given\nsituation and thought, we show one LM-generated reframe to MHA participants and ask them to rate it on relatability,\nhelpfulness and memorability on a 1 to 5 scale. For each linguistic attribute, we compare the first (Q1) and the\nfourth quartile (Q4). We find that (a) reframes that have higher rationality are more relatable; (b) reframes that\naddress thinking traps, have higher actionability or higher specificity are more helpful; (c) reframes that have higher\nactionability or higher specificity are more memorable. *:p <0.05;**:p <0.01.\n(1) Highly empathic and specific reframings are\npreferred more. We find that highly empathic\nreframes are preferred 55.7% more frequently than\nreframes with lower empathy (39.7% vs. 25.5%;\np <10−5); highly specific reframes are preferred\n43.1% more frequently than reframes with lower\nspecificity (39.2% vs. 27.4%; p < 10−5). Prior\nwork has shown the importance of empathy and\nless “templated” responses in mental health support\nconversations (Sharma et al., 2020b; Althoff et al.,\n2016). Here, we show that empathy and specificity\nof LM-generated reframes may support people in\nreframing negative thoughts.\n(2) Overly positive reframes are preferred less.\nOn the other hand, reframes with high positivity\nare preferred 22.7% less frequently than reframes\nwith lower positivity (29.6% vs. 38.3%; p <10−5).\nThis may be because adopting an overly positive re-\nframed thought may be challenging for individuals\nwho are already experiencing emotionally trigger-\ning negative thoughts (Dember and Penwell, 1980).\nParticipants also prefer medium-readability re-\nframes over very simple or very complex reframes,\nperhaps because their language is balanced for a\nwider audience.\n7.3 How do the linguistic attributes of\nreframed thoughts relate to the desired\noutcomes of cognitive reframing?\nWe assess what characterizes a reframe that is re-\nlatable, helpful and memorable. We show a single\nmodel-generated reframe to the participants and\nask them to rate it on a 5-point Likert scale (Likert,\n1932) with regards to the three outcome measures\n(1: Strongly Disagree; 5: Strongly Agree). We\ndo not provide participants in this experiment with\na choice of multiple reframes to avoid any selec-\ntion effects (§7.2). Figure 3 offers key insights on\nwhich attributes of reframed thoughts are related to\ndifferent desired outcomes:\n(1) Reframes that are more rational are more\nrelatable. We find that reframes that have higher\n9984\nrationality are 10.8% more relatable than lower\nrationality reframes (3.91 vs. 3.53; p < 0.05).\nThis may be because higher rationality reframes,\nby definition, are more likely to be based on reasons\nand are less likely to make unrealistic assumptions,\nmaking them easier to relate to.\n(2) Reframes that address thinking traps and\nare more actionable and specific are more help-\nful. Reframes that address thinking traps are 6.3%\nmore helpful than reframes that do not address\nthem (3.39 vs. 3.19; p < 0.01). Such reframes\nspecifically challenge the cognitive biases in think-\ning patterns (e.g., “Fortune Telling”; Appendix D),\nwhich has shown to be more effective in dealing\nwith negative thoughts in psychotherapy research\n(Beck, 1976; Burns, 1980). Moreover, we find that\nreframes with higher actionability are 6.6% more\nhelpful than lower actionability reframes (3.41 vs.\n3.20; p < 0.05) and reframes with higher speci-\nficity are 9.6% more helpful than lower specificity\nreframes (3.42 vs. 3.12; p <0.01).\n(3) Reframes that are more actionable and more\nspecific are more memorable. We find that re-\nframes with higher actionability are 7.9% more\nmemorable than lower actionability reframes (3.67\nvs. 3.40; p <0.01) and reframes with higher speci-\nficity are 6.3% more memorable than lower speci-\nficity reframes (3.70 vs. 3.48; p <0.05).\n8 Related Work\nSeveral Human-LM interaction tools for mental\nhealth assist support providers, e.g., clinicians\n(Tanana et al., 2019; Shen et al., 2020) or peers\n(Sharma et al., 2023). Our work provides insights\non how Human-LM interaction may directly sup-\nport people struggling with mental health chal-\nlenges through cognitive reframing. Computational\nwork on cognitive reframing has relied on small-\nscale crowdsourcing studies (Smith et al., 2021;\nMorris et al., 2015). Our work develops scalable\nmethods for cognitive reframing and conducts a\nrandomized field study on a large mental health\nplatform. Prior text reframing research has de-\nveloped methods for related tasks including style,\nsentiment, politeness and empathy transfer (Reif\net al., 2022; Madaan et al., 2020; Sharma et al.,\n2021) as well as positive reframing (Ziems et al.,\n2022). Our work develops text-reframing meth-\nods for cognitive reframing and demonstrates that\nlinguistic attributes of addressing thinking traps,\nrationality, actionability, specificity and readability\nare critical to high-quality reframes. More broadly,\nour work relates to the growing body of research\nin NLP for mental health and psychological well-\nbeing (Althoff et al., 2016; Sharma and De Choud-\nhury, 2018; Gaur et al., 2019; Lee et al., 2019;\nMiner et al., 2019; Pendse et al., 2019; Pérez-Rosas\net al., 2019; Pruksachatkun et al., 2019; Yang et al.,\n2019; Zhang et al., 2019a; Jaidka et al., 2020; Saha\nand Sharma, 2020; Sharma et al., 2020a,b; Wadden\net al., 2021; Welch et al., 2020; Zhang and Danescu-\nNiculescu-Mizil, 2020; Lahnala et al., 2021; Lin\net al., 2022; Naseem et al., 2022; Pérez-Rosas et al.,\n2022; Shah et al., 2022; Shen et al., 2022; Stewart\net al., 2023).\n9 Conclusion\nIn this paper, we conducted a study of how Human-\nLanguage Model Interaction may support humans\nin the cognitive reframing of negative thoughts. We\ndefine a framework of seven linguistic attributes\nof cognitive reframing, develop automatic metrics\nto measure these attributes and validate their mea-\nsurements with mental health experts. We collect\nand share a dataset of 600 situations, thoughts and\nreframes from mental health experts and use it\nto train a retrieval-enhanced in-context learning\nmodel based on GPT-3. We deploy this model on\nthe Mental Health America website and conduct a\nrandomized field study with 2,067 participants. We\nfind that people struggling with negative thoughts\nprefer reframes that are highly empathic or specific,\nbut do not prefer reframes that are highly positive.\n10 Ethics Statement\nIntervention in high-risk settings such as mental\nhealth necessitates ethical considerations related\nto safety, privacy and bias. There is a possibil-\nity that, in attempting to assist, AI may have the\nopposite effect on people struggling with mental\nhealth challenges. Here, in active collaboration and\nconsultation with mental health professionals and\nclinical psychologists, we took several measures to\nminimize these risks.\nIRB Approval. We obtained approval from\nthe University of Washington’s Institutional Re-\nview Board for both our data collection (IRB ID\nSTUDY00015882) as well as the randomized field\nstudy (IRB ID STUDY00016783). Our organi-\nzation requires all research personnel who con-\nduct human subjects research to complete human\nsubjects protection training using the online CITI\n9985\ncourse. The graduate students conducting these\nstudies were certified by our IRB.\nInformed Consent from Participants. We ob-\ntained informed consent from all participants in our\nrandomized field study (Appendix H). All partici-\npants were 18 years of age and older. Participants\nwere informed that they will be interacting with\nan AI-based model that automatically generates re-\nframed thoughts and is not monitored by a human.\nAlso, they were informed about the possibility that\nsome of the generated content may be upsetting or\ndisturbing.\nCrisis Resources. We made it very explicit that the\nmodel should not be used as a “cry for help” outlet\nand should not be used in cases of suicidal ideation\nand self-harm. Also, we provided two crisis re-\nsources – Crisis Text Line (crisistextline.org) and\n988 Suicide and Crisis Lifeline (988lifeline.org) –\nto our participants at the start of the study.\nSafety Measures. To minimize harmful LM-\ngenerated reframings, we filtered out any response\nthat contained suicidal ideation or self-harm-related\nwords or phrases. For this, we created a list of\n50 regular expressions (e.g., to identify phrases\nlike “feeling suicidal”, “wish to die ”, “harm my-\nself ”) using suicidal risk assessment lexicons such\nas Gaur et al. (2019). An LM-generated response\nthat matched any of the regular expressions was\nfiltered out and not shown to the participants. Also,\nparticipants were given an option to flag inappro-\npriate reframing suggestions through a “Flag inap-\npropriate” button (Appendix C).\nPrivacy. We did not collect any privately identifi-\nable information in our randomized field study and\nremoved any user identifiers before conducting our\ndata analysis. All research data was stored within\na separate secure computing environment and only\ntrained research personnel were provided access to\ndata. The situations and thoughts collected in §4.1\nwent through an anonymization process, where we\nmanually removed any user identifiers and replaced\nany specific identifiable information including loca-\ntions, names, etc. with their more general version,\nfollowing Matthews et al. (2017).\n11 Limitations\nWe conducted our randomized field study on a sin-\ngle platform (Mental Health America) and in a\nsingle language (English). However, MHA is a par-\nticularly popular source for mental health resources\nwith over ten million yearly visitors.\nIn addition, we note that a range of socio-cultural\nfactors might influence how negative thoughts\nshould be reframed and how LMs assisting this pro-\ncess should be developed. Conducting studies on\nspecific communities, including underrepresented\ncommunities and minorities, was beyond the scope\nof this research. Ensuring equitable access of these\ntools and adapting them to various socio-cultural\ncontexts requires further investigation.\nNot all cognitive reframing implementations\nelicit situations, but we believed it was essential\nfor making the reframe personally relatable. In the\nfuture, when an individual uses the system for mul-\ntiple situations and thoughts, it would be interesting\nto study how their context can be learned more ef-\nfectively over time. Due to privacy concerns, we\npresently do not gather information to link multiple\nsessions. However, with appropriate ethical con-\nsiderations and user consent, this approach may be\nbeneficial.\nOur focus in this paper was primarily on creat-\ning an intervention that is effective in-the-moment.\nThis was motivated by recent clinical psychology\nresearch that suggests that such single-session, in-\nthe-moment interventions can lead to significant\npositive long-term mental health outcomes (Schlei-\nder et al., 2022). To integrate a partial longer-term\nperspective, we assessed the memorability of a\nreframe, which may be essential for future util-\nity. Nevertheless, evaluating long-term outcomes\nis critical and forms an important future research\ndirection. Finally, we emphasize that our study\ndoes not investigate short-term or long-term clini-\ncal outcomes.\nAcknowledgements\nWe are grateful to the mental health practitioners\nand clinical psychology graduate students for data\nannotation, as well as the MHA visitors for partici-\npating in our field study. We thank the anonymous\nreviewers and the UW Behavioral Data Science\nGroup members for their suggestions and feedback.\nWe also thank Justin Evans for their assistance in\nmodel deployment, Xiang Lorraine Li for their\ninput on data collection and Sebastin Santy for\ntheir input on the tool interface. T.A., A.S. and\nI.W.L. were supported in part by NSF grant IIS-\n1901386, NSF CAREER IIS-2142794, NSF grant\nCNS-2025022, NIH grant R01MH125179, Bill &\nMelinda Gates Foundation (INV-004841), the Of-\n9986\nfice of Naval Research (#N00014-21-1-2154), a\nMicrosoft AI for Accessibility grant, and a Garvey\nInstitute Innovation grant.\nReferences\nAshley Batts Allen and Mark R Leary. 2010. Self-\ncompassion, stress, and coping. Social and personal-\nity psychology compass.\nTim Althoff, Kevin Clark, and Jure Leskovec. 2016.\nLarge-scale analysis of counseling conversations: An\napplication of natural language processing to mental\nhealth. Transactions of the Association for Computa-\ntional Linguistics.\nFrancesco Barbieri, Jose Camacho-Collados, Luis Es-\npinosa Anke, and Leonardo Neves. 2020. TweetEval:\nUnified benchmark and comparative evaluation for\ntweet classification. In EMNLP Findings.\nAaron T Beck. 1976. Cognitive therapy and the emo-\ntional disorders. International Universities Press.\nJudith S Beck. 2005. Cognitive therapy for challenging\nproblems: What to do when the basics don’t work .\nGuilford Press.\nChandra Bhagavatula, Ronan Le Bras, Chaitanya\nMalaviya, Keisuke Sakaguchi, Ari Holtzman, Han-\nnah Rashkin, Doug Downey, Wen-tau Yih, and Yejin\nChoi. 2020. Abductive commonsense reasoning. In\nICLR.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. NeurIPS.\nFranziska Burger, Mark A Neerincx, and Willem-Paul\nBrinkman. 2021. Natural language processing for\ncognitive therapy: Extracting schemas from thought\nrecords. PloS one.\nHannah A Burkhardt, George S Alexopoulos, Michael D\nPullmann, Thomas D Hull, Patricia A Areán, and\nTrevor Cohen. 2021. Behavioral activation and de-\npression symptomatology: longitudinal assessment\nof linguistic indicators in text-based therapy sessions.\nJMIR.\nDavid D Burns. 1980. Feeling good: Thenew mood\ntherapy. New York.\nMeri Coleman and Ta Lin Liau. 1975. A computer\nreadability formula designed for machine scoring.\nJournal of Applied Psychology.\nPeter Damielson, Robert Audi, Cristina Bicchieri, et al.\n2004. The Oxford handbook of rationality. Oxford\nUniversity Press, USA.\nDaniel David, Steven Jay Lynn, and Albert Ellis. 2009.\nRational and irrational beliefs: Research, theory, and\nclinical practice. Oxford University Press.\nWilliam N Dember and Larry Penwell. 1980. Happi-\nness, depression, and the pollyanna principle. Bul-\nletin of the Psychonomic Society.\nSona Dimidjian, Manuel Barrera Jr, Christopher Martell,\nRicardo F Muñoz, and Peter M Lewinsohn. 2011.\nThe origins and current status of behavioral activation\ntreatments for depression. Annual review of clinical\npsychology.\nXiruo Ding, Kevin Lybarger, Justin Tauscher, and\nTrevor Cohen. 2022. Improving classification of\ninfrequent cognitive distortions: Domain-specific\nmodel vs. data augmentation. In Proceedings of\nthe 2022 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies: Student Research\nWorkshop.\nRobert Elliott, Arthur C Bohart, Jeanne C Watson, and\nLeslie S Greenberg. 2011. Empathy. Psychotherapy.\nManas Gaur, Amanuel Alambo, Joy Prakash Sain, Ugur\nKursuncu, Krishnaprasad Thirunarayan, Ramakanth\nKavuluru, Amit Sheth, Randy Welton, and Jyotish-\nman Pathak. 2019. Knowledge-aware assessment\nof severity of suicide risk for early intervention. In\nWWW.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and\nYejin Choi. 2020. The curious case of neural text\ndegeneration. In ICLR.\nKokil Jaidka, Niyati Chhaya, Saran Mumick, Matthew\nKillingsworth, Alon Halevy, and Lyle Ungar. 2020.\nBeyond positive emotion: Deconstructing happy mo-\nments based on writing prompts. In ICWSM.\nJaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brah-\nman, Chandra Bhagavatula, Ronan Le Bras, and\nYejin Choi. 2022. Maieutic prompting: Logically\nconsistent reasoning with recursive explanations. In\nEMNLP.\nCarole A Kaplan, Anne E Thompson, and Sheila M Sear-\nson. 1995. Cognitive behaviour therapy in children\nand adolescents. Archives of disease in childhood.\nAllison Lahnala, Yuntian Zhao, Charles Welch,\nJonathan K Kummerfeld, Lawrence C An, Kenneth\nResnicow, Rada Mihalcea, and Verónica Pérez-Rosas.\n2021. Exploring self-identified counseling expertise\nin online support forums. In ACL-IJCNLP Findings.\nFei-Tzin Lee, Derrick Hull, Jacob Levine, Bonnie Ray,\nand Kathleen McKeown. 2019. Identifying therapist\nconversational actions across diverse psychotherapeu-\ntic approaches. In Proceedings of the Sixth Workshop\non Computational Linguistics and Clinical Psychol-\nogy.\nRensis Likert. 1932. A technique for the measurement\nof attitudes. Archives of psychology.\n9987\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text summarization\nbranches out.\nInna Lin, Lucille Njoo, Anjalie Field, Ashish Sharma,\nKatharina Reinecke, Tim Althoff, and Yulia Tsvetkov.\n2022. Gendered mental health stigma in masked\nlanguage models. In EMNLP.\nAlisa Liu, Swabha Swayamdipta, Noah A Smith, and\nYejin Choi. 2022a. Wanli: Worker and ai collabora-\ntion for natural language inference dataset creation.\narXiv preprint arXiv:2201.05955.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, William B\nDolan, Lawrence Carin, and Weizhu Chen. 2022b.\nWhat makes good in-context examples for gpt-3? In\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extraction\nand Integration for Deep Learning Architectures.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nAman Madaan, Amrith Setlur, Tanmay Parekh, Barn-\nabás Poczós, Graham Neubig, Yiming Yang, Ruslan\nSalakhutdinov, Alan W Black, and Shrimai Prabhu-\nmoye. 2020. Politeness transfer: A tag and generate\napproach. In ACL.\nTara Matthews, Kathleen O’Leary, Anna Turner, Manya\nSleeper, Jill Palzkill Woelfer, Martin Shelton, Cori\nManthorne, Elizabeth F Churchill, and Sunny Con-\nsolvo. 2017. Stories from survivors: Privacy & se-\ncurity practices when coping with intimate partner\nabuse. In CHI.\nAdam S Miner, Nigam Shah, Kim D Bullock, Bruce A\nArnow, Jeremy Bailenson, and Jeff Hancock. 2019.\nKey considerations for incorporating conversational\nai in psychotherapy. Frontiers in psychiatry.\nRobert R Morris, Stephen M Schueller, and Rosalind W\nPicard. 2015. Efficacy of a web-based, crowdsourced\npeer-to-peer cognitive reappraisal platform for de-\npression: randomized controlled trial. JMIR.\nUsman Naseem, Adam G Dunn, Jinman Kim, and Mat-\nloob Khushi. 2022. Early identification of depression\nseverity levels on reddit using ordinal classification.\nIn WWW.\nMark Olfson. 2016. Building the mental health work-\nforce capacity needed to treat adults with serious\nmental illnesses. Health Affairs.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In ACL.\nCharles Sanders Peirce. 1974. Collected papers of\ncharles sanders peirce. Harvard University Press.\nSachin R Pendse, Kate Niederhoffer, and Amit Sharma.\n2019. Cross-cultural differences in the use of online\nmental health support forums. CSCW.\nVerónica Pérez-Rosas, Kenneth Resnicow, Rada Mihal-\ncea, et al. 2022. Pair: Prompt-aware margin ranking\nfor counselor reflection scoring in motivational inter-\nviewing. In EMNLP.\nVerónica Pérez-Rosas, Xinyi Wu, Kenneth Resnicow,\nand Rada Mihalcea. 2019. What makes a good coun-\nselor? learning to distinguish between high-quality\nand low-quality counseling conversations. In ACL.\nYada Pruksachatkun, Sachin R Pendse, and Amit\nSharma. 2019. Moments of change: Analyzing peer-\nbased cognitive support in online mental health fo-\nrums. In CHI.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, Peter J Liu, et al. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. JMLR.\nEmily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen,\nChris Callison-Burch, and Jason Wei. 2022. A recipe\nfor arbitrary text style transfer with large language\nmodels. In ACL.\nKoustuv Saha and Amit Sharma. 2020. Causal factors\nof effective psychosocial outcomes in online mental\nhealth communities. In ICWSM.\nJessica L Schleider, Michael C Mullarkey, Kathryn R\nFox, Mallory L Dobias, Akash Shroff, Erica A Hart,\nand Chantelle A Roulston. 2022. A randomized\ntrial of online single-session interventions for ado-\nlescent depression during covid-19. Nature Human\nBehaviour.\nRaj Sanjay Shah, Faye Holt, Shirley Anugrah Hayati,\nAastha Agarwal, Yi-Chia Wang, Robert E Kraut, and\nDiyi Yang. 2022. Modeling motivational interview-\ning strategies on an online peer-to-peer counseling\nplatform. CSCW.\nAshish Sharma, Monojit Choudhury, Tim Althoff, and\nAmit Sharma. 2020a. Engagement patterns of peer-\nto-peer interactions on mental health platforms. In\nICWSM.\nAshish Sharma, Inna W Lin, Adam S Miner, David C\nAtkins, and Tim Althoff. 2021. Towards facilitating\nempathic conversations in online mental health sup-\nport: A reinforcement learning approach. In WWW.\nAshish Sharma, Inna W. Lin, Adam S. Miner, David C.\nAtkins, and Tim Althoff. 2023. Human–AI collabo-\nration enables more empathic conversations in text-\nbased peer-to-peer mental health support. Nature\nMachine Intelligence.\nAshish Sharma, Adam S Miner, David C Atkins, and\nTim Althoff. 2020b. A computational approach to un-\nderstanding empathy expressed in text-based mental\nhealth support. In EMNLP.\n9988\nEva Sharma and Munmun De Choudhury. 2018. Men-\ntal health support and its relationship to linguistic\naccommodation in online communities. In CHI.\nSiqi Shen, Verónica Pérez-Rosas, Charles Welch, Sou-\njanya Poria, and Rada Mihalcea. 2022. Knowledge\nenhanced reflection generation for counseling dia-\nlogues. In ACL.\nSiqi Shen, Charles Welch, Rada Mihalcea, and Verónica\nPérez-Rosas. 2020. Counseling-style reflection gen-\neration using generative pretrained transformers with\naugmented context. In SIGDIAL.\nAmy E Sickel, Jason D Seacat, and Nina A Nabors.\n2014. Mental health stigma update: A review of\nconsequences. Advances in Mental Health.\nC Estelle Smith, William Lane, Hannah Miller Hillberg,\nDaniel Kluver, Loren Terveen, and Svetlana Yarosh.\n2021. Effective strategies for crowd-powered cog-\nnitive reappraisal systems: A field deployment of\nthe flip* doubt web application for mental health.\nCSCW.\nIan Stewart, Charles Welch, Lawrence An, Kenneth\nResnicow, James Pennebaker, and Rada Mihalcea.\n2023. Expressive interviewing agents to support\nhealth-related behavior change: A study of covid-\n19 behaviors. JMIR formative research.\nMichael J Tanana, Christina S Soma, Vivek Srikumar,\nDavid C Atkins, and Zac E Imel. 2019. Development\nand evaluation of clientbot: Patient-like conversa-\ntional agent to train basic counseling skills. JMIR.\nDavid Wadden, Tal August, Qisheng Li, and Tim Al-\nthoff. 2021. The effect of moderation on online men-\ntal health conversations. In ICWSM.\nCharles Welch, Allison Lahnala, Verónica Pérez-Rosas,\nSiqi Shen, Sarah Seraj, Larry An, Kenneth Resni-\ncow, James Pennebaker, and Rada Mihalcea. 2020.\nExpressive interviewing: A conversational system\nfor coping with covid-19. In Proceedings of the 1st\nWorkshop on NLP for COVID-19 (Part 2) at EMNLP\n2020.\nXinnuo Xu, Ondˇrej Dušek, Ioannis Konstas, and Ver-\nena Rieser. 2018. Better conversations by modeling,\nfiltering, and optimizing for coherence and diversity.\nIn ACL.\nDiyi Yang, Zheng Yao, Joseph Seering, and Robert\nKraut. 2019. The channel matters: Self-disclosure,\nreciprocity and social support in online cancer sup-\nport groups. In CHI.\nJustine Zhang and Cristian Danescu-Niculescu-Mizil.\n2020. Balancing objectives in counseling conversa-\ntions: Advancing forwards or looking backwards. In\nACL.\nJustine Zhang, Robert Filbin, Christine Morrison, Ja-\nclyn Weiser, and Cristian Danescu-Niculescu-Mizil.\n2019a. Finding your voice: The linguistic develop-\nment of mental health counselors. In ACL.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Wein-\nberger, and Yoav Artzi. 2019b. Bertscore: Eval-\nuating text generation with bert. arXiv preprint\narXiv:1904.09675.\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,\nChris Brockett, Xiang Gao, Jianfeng Gao, Jingjing\nLiu, and Bill Dolan. 2020. Dialogpt: Large-scale\ngenerative pre-training for conversational response\ngeneration. In ACL, system demonstration.\nCaleb Ziems, Minzhi Li, Anthony Zhang, and Diyi\nYang. 2022. Inducing positive perspectives with text\nreframing. In ACL.\n9989\nA Method\nA.1 Linguistic Attributes of Reframed\nThoughts\nWe provide additional detail on the approaches de-\nscribed in §5.1.\nActionability. As described in §5.1, we measure\nactionability using: contains_action(Ri), and\nnext_action_coherence(Ri).\nFor contains_action(Ri), our few-shot in-\ncontext learning approach proceeds as follows. Us-\ning the reframed thoughts that were annotated as\nhigh or low actionable in our collected data (§4.2),\nwe manually create 10 demonstration examples.\nIf a reframed thought contains an action, we ask\nGPT-3 to extract the action from it. Otherwise,\nwe ask it to generate the text “ No Action”. Ap-\npendix A.2 shows examples. We then use these\n10 demonstrations as in-context examples, fol-\nlowed by the reframe Ri which we aim to clas-\nsify. If GPT-3 predicts an action for Ri, we assign\ncontains_action(Ri) =1; else we assign 0.\nFor next_action_coherence(Ri), we instruct\nGPT-3 to generate k = 5 possible next actions\ngiven a reframed thought. Given (Si, Ti, Ri), let\nAi = ai1, ai2, ..., aik be the generated set of next\nactions. Let emb(⋅) denote RoBERTa embeddings.\nThen, we define next_action_coherence(Ri) as\nthe average cosine similarity between emb(ai) and\nemb(aj) for all ai, aj ∈Ai.\nA.2 Action Generation Prompt\nWe use the following prompt template for extract-\ning actions through GPT-3:\nStatement: “My bank card could be\nin many different places and I want to\ncheck them first before making any con-\nclusions”\nProposed Action: “Check bank card.”\nStatement: “I cancelled that trip because\nI had to. It hurts to have done so but it\nwas the right thing”\nProposed Action: None\nAlso, we use the following instruction prompt\nfor generating the next set of actions through GPT-\n3: “ Suggest 5 actions that the person could take\nbased on the following statement:”\nA.3 Hyperparameter Choices for our\nProposed Retrieval-Enhanced In-Context\nLearning Method\nFor the number of examples to retrieve, we experi-\nmented with k =1, 5, 10 and 20 and found k =5\nto generate the most effective reframed thoughts,\nbased on a qualitative assessment of 100 manually\nwritten situations and thoughts.\nB Reproducibility\nCodes and datasets created in the paper can\nbe found at https://github.com/behavioral-\ndata/Cognitive-Reframing under an academic,\nattribution-only license. The use of existing\nartifacts was consistent with their intended\nuse. For GPT-3 based models, we will use\nthe OpenAI library. For other deep learning\nmodels, we train and them on two NVIDIA Titan\nRTX GPUs. We use the evaluate python library\n(pypi.org/project/evaluate) for measuring BLEU\nand ROUGE scores and scipy for statistical tests.\nC Flagged Reframes\nThere were 32 reframing suggestions out of 5,760\nwhich were flagged (0.56%). 19 of them were\ngeneric (59%). 5 of them made incorrect assump-\ntions about the person’s situation (16%). And 8\nof them may not have been relatable to the person\n(25%). Importantly, we did not find any flagged\nreframes that were harmful or unsafe, which is crit-\nical in these scenarios. In future, exploring ways to\ncreate more personalized reframes could help avoid\ngeneric, assumptive or less relatable reframes.\n9990\nD List of Thinking Traps\nThinking Traps Description Example\nAll-or-Nothing Thinking Thinking in extremes. If it isn’t perfect, I failed. There’s no such\nthing as “good enough”.\nOvergeneralizing Jumping to conclusions based on one experi-\nence.\nThey didn’t text me back. Nobody ever texts\nme back.\nLabeling Defining a person based on one action or char-\nacteristic.\nI said something embarrassing. I’m such a\nloser.\nFortune Telling\nTrying to predict the future. Focusing on\none possibility and ignoring\nother, more likely outcomes.\nI’m late for the meeting. I’ll make a fool of\nmyself.\nMind Reading Assuming you know what someone else is\nthinking.\nShe didn’t say hello. She must be mad at me.\nEmotional Reasoning Treating your feelings like facts. I woke up feeling anxious. I just know some-\nthing bad is going to happen today.\nShould Statements Setting unrealistic expectations for yourself. I shouldn’t need to ask for help. I should be\nindependent.\nPersonalizing Taking things personally or making them about\nyou.\nHe’s quiet today. I wonder what I did wrong.\nDisqualifying the Positive When something good happens, you ignore it\nor think it doesn’t count. I only won because I got lucky.\nCatastrophizing Focusing on the worst-case scenario. My boss asked if I had a few minutes to talk.\nI’m going to get fired!\nComparing and Despairing Comparing your worst to someone else’s best.My niece’s birthday party had twice the\namount of people\nBlaming Giving away your own power to other people.It’s not my fault I yelled. You made me angry!\nNegative Feeling or EmotionGetting “stuck” on a distressing thought, emo-\ntion, or belief.\nI am feeling lonely.\n9991\nE Example Illustrating Our Rationality\nMeasurement\nFigure 4: To measure reasoning strength, we generate\ntwo explanations for each reframe – one for why it might\nbe sound; another for why it may be flawed. To check\nif the explanations themselves are well-reasoned, we\nrecursively generate explanations for the explanations.\nHere, we choose a recursive tree depth of 3. Also, at\nevery step, we generate three explanations in favour of\na reframe and three explanations against it.\nSo f ar , no r ejections, which means I might get t he \njob. Good news on t he wa y?\nThr ee da ys ha v e passed since m y job int er view and I \ndidn’ t r eceiv e an y updat es. I didn’ t get t he job.\n... not hearing back fr om an \nemplo y er aft er an int er view \ndoes not mean y ou will get \nt he job\n... t he person has not \nr eceiv ed an y news, which \nmight mean t he y ar e still in \nconsideration f or t he job.\nThe r esponse is , because... flaw ed sound , because...\nSITUA TION\nRESPONSE\nEXPL ANA TION\n...usually if a compan y is \nint er est ed, t he y w ould’ v e \ngiv en some f eedback b y no w . \nThe possibility of t he person \ngetting t he job is lo w .\n.......\nEXPL ANA TION\n9992\nF Randomized Field-Study Interface\n(a) Thought(b) Situation(c) Cognitive Distortions(d) Reframed Thoughts\nFigure 5: Illustration of the interface used for our ran-\ndomized field-study: ( a) Participant starts by writing\nthe negative thought they are struggling with in the mo-\nment; (b) We ask the participant to describe a recent\nsituation that may have led to their thought; (c) An AI\nmodel identifies possible cognitive distortion(s) in the\nthought. Participant selects the cognitive distortions that\nthey most relate to; (d) An AI model generates and sug-\ngests three different reframed thoughts that may help\novercome negative thinking and the associated cognitive\ndistortion. Participant selects the reframe they find the\nmost relatable, helpful and memorable. Some of the\ninstructions provided to the participants, including in-\nformed consent and evaluation, have been omitted from\nthis illustration for brevity.\n9993\nG Data Collection Instructions\nFigure 6: Instructions shown during data collection with\nmental health experts. Continued on the next page (1/3).\nCognitive\nRestructuring\nStudy Goals\nThe goal of this study is to collect a dataset for cognitive restructuring.\nDe\u0000nitions\nSituation Anything that happens to the person or the circumstance\nthat the person \u0000nds themselves in (e.g., \"My boss walked\npast me the hallway without saying hello\")\nThought What goes through the person's mind in the situation\n(e.g., \"Why are they angry with me?\").\nThinking\nTraps\nThinking traps, also called cognitive distortions, are\nexaggerated, biased, and irrational thoughts which\ncause individuals to perceive reality inaccurately.\nThinking\nTrap\nCategories\nCategories of thinking traps include assuming what\nothers think (“Mind Reading”), thinking in extremes (“All-\nor-nothing thinking”), focusing on the worst-case\nscenario (“Catastrophizing”), focusing only on the bad\n(“Disqualifying the positive”), etc.\nExample Thinking Trap\nSituation: My boss walked past me the hallway without saying hello\nThought: Why are they angry with me?\nThinking Trap: Mind Reading\n9994\nFigure 7: Instructions shown during data collection with mental health experts. Continued on the next page (2/3).\nThought\nResponse\nA thought response is self-talk (conversation with\noneself) that tries to challenge the thinking trap in the\noriginal thought\nCognitive\nRestructuring\nCognitive Restructuring is a process that helps people\nnotice thinking traps in their thoughts and respond\nrationally to them.\nStudy Steps\nIn this study, you will perform 20 cognitive restructuring tasks. In each task, you\nwill be shown a situation and a thought. You will be asked to identify thinking traps\nin the thought and write and rate thought responses.\nNote: The use of \"Both are similar\" option (wherever applicable) is discouraged.\nUse it only when the two responses are truly identical and there is nothing to\ndistinguish the two.\nHere, I'm reading my boss's mind and assuming that they are upset with\nme. I can't \u0000gure this out unless I ask them.\nExample Thought Responses\nSituation: My boss walked past me the hallway without saying hello.\nThought: Why are they angry with me?\nResponse 1: I have no way of \u0000guring out what they might be thinking.\nMaybe they had a lot on her mind\nResponse 2: They are the most wonderful person I know. They must not have\nnoticed me.\nResponse 3: They might be mad at me, but atleast they didn't say anything.\n9995\nFigure 8: Instructions shown during data collection with mental health experts (3/3).\nContent Warning\nThis study contains situations and thoughts including but not limited to self-harm\nand suicidal ideation, which may be disturbing. If you have any questions or\nconcerns, please send us an email. Should you have a strong negative reaction to\nsome of the content, you can reach a crisis counselor at crisis text line or by\ntexting HOME to 741741.\nIf you have questions about your rights as a research participant, or wish to obtain\ninformation, ask questions or discuss any concerns about this study with someone\nother than the researcher(s), please contact the Human Subjects Division at xxx.\n9996\nH Consent Form Used in the Randomized\nField Study on MHA\nFigure 9: Consent form shown to the MHA visitors.\nContinued on the next page (1/2).\nTerms of Use\nThis tool uses arti\u0000cial intelligence to generate reframed thoughts and is\npart of a research study.\nPurpose: The purpose of the study is to understand how digital tools can\nhelp people recognize thinking traps and practice reframing negative\nthoughts.\nProcedure: You will be asked to describe a thought and a situation you\nare struggling with. You will then identify potential \"thinking traps\" (or\ncognitive distortions) in the thought and reframe it in a way that is more\npositive, realistic, or helpful. Finally, you will be asked to take an optional\ndemographic survey, which can be skipped as preferred. The tool is\nexpected to take ~5 minutes to complete.\nBene\u0000ts: By using this tool, you may learn about thinking traps. You will\npractice identifying them and reframing negative thoughts and situations.\nHowever, there is no guarantee that the tool will help you reframe your\nthoughts.\nData Collection and Sharing: We will not ask you for your name or any\nidenti\u0000able personal information. Usage data will be made unidenti\u0000able\nto the best of our extent, will be analyzed to improve the tool, and may be\nshared and used for future research.\nRisks: Talking about situations and thoughts you are struggling with may\nbe disturbing to you and may bring up negative emotional reactions. In\naddition, the tool uses arti\u0000cial intelligence to generate reframed\nthoughts. Appropriate steps have been taken to avoid harmful reframes,\nbut there is a possibility that the generated content might be upsetting to\nyou. Also, the optional demographic survey asks for information that may\nbe sensitive and could make you feel uncomfortable (e.g., \"What are the\nmain things contributing to your mental health problems right now?\"). This\n9997\nFigure 10: Consent form shown to the MHA visitors (2/2).\ntool is not being actively monitored by a human and should not be used\nas a \"cry for help\" outlet. Should you have a strong negative reaction to\nsome of the content, you can text MHA to 741741 or call or text 988.\nParticipation: Participation in this study is completely voluntary. You will\nnot receive any payment for participation. You can refuse participation or\nstop participating at any time without penalty or loss of bene\u0000ts to which\nyou are otherwise entitled.\nContact Us: If you have questions or concerns about this research, or if\nyou think you have been harmed from being in the study, please email us\nat XXX. If you have questions about your rights as a research participant,\nyou can call Human Subjects Division at XXX.\nBy ticking this box, you are agreeing to use this tool. You are also\ncon\u0000rming that you are at least 18 years old. Be sure that questions\nabout the tool have been answered and that you understand what you\nare being asked to do. You may contact us if you think of a question\nlater. You are free to stop using the tool at any time. To save a copy of\nthis consent form, you can use this link.\n Previous Next\n9998\nACL 2023 Responsible NLP Checklist\nA For every submission:\n□\u0013 A1. Did you describe the limitations of your work?\nSection 11\n□\u0013 A2. Did you discuss any potential risks of your work?\nSection 10\n□\u0013 A3. Do the abstract and introduction summarize the paper’s main claims?\nSection 1\n□\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB □\u0013 Did you use or create scientiﬁc artifacts?\nSection 4; Section 5\n□\u0013 B1. Did you cite the creators of artifacts you used?\nSection 4; Section 5\n□\u0013 B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nAppendix B\n□\u0013 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciﬁed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nAppendix B\n□\u0013 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiﬁes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nSection 10\n□\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nSection 11\n□\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiﬁcant, while on small test sets they may not be.\nSection 4; Section 6\nC □\u0013 Did you run computational experiments?\nSection 6; Section 7\n□\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nAppendix B\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n9999\n□\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nSection 5; Section 6; Appendix A.3\n□\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSection 6; Section 7\n□\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nAppendix B\nD □\u0013 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nSection 4; Section 7\n□\u0013 D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nAppendix D; Appendix E; Appendix F\n□\u0013 D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants’ demographic\n(e.g., country of residence)?\nSection 4; Section 7\n□\u0013 D3. Did you discuss whether and how consent was obtained from people whose data you’re\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nSection 4.3; Section 10\n□\u0013 D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nSection 4.3; Section 10\n□\u0013 D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nSection 4\n10000",
  "topic": "Cognitive reframing",
  "concepts": [
    {
      "name": "Cognitive reframing",
      "score": 0.8991274833679199
    },
    {
      "name": "Cognitive science",
      "score": 0.49344363808631897
    },
    {
      "name": "Cognition",
      "score": 0.47449564933776855
    },
    {
      "name": "Psychology",
      "score": 0.39797109365463257
    },
    {
      "name": "Linguistics",
      "score": 0.35174107551574707
    },
    {
      "name": "Computer science",
      "score": 0.33289599418640137
    },
    {
      "name": "Epistemology",
      "score": 0.3268068730831146
    },
    {
      "name": "Philosophy",
      "score": 0.2640628516674042
    },
    {
      "name": "Social psychology",
      "score": 0.17150941491127014
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ]
}