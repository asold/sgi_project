{
  "title": "Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation of Power Transformers",
  "url": "https://openalex.org/W3091784365",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A1999641301",
      "name": "Sherif S. M. Ghoneim",
      "affiliations": [
        "Taif University",
        "Suez University"
      ]
    },
    {
      "id": "https://openalex.org/A2231331346",
      "name": "Ibrahim B.M. Taha",
      "affiliations": [
        "Tanta University",
        "Taif University"
      ]
    },
    {
      "id": "https://openalex.org/A1999641301",
      "name": "Sherif S. M. Ghoneim",
      "affiliations": [
        "Taif University",
        "Suez University"
      ]
    },
    {
      "id": "https://openalex.org/A2231331346",
      "name": "Ibrahim B.M. Taha",
      "affiliations": [
        "Tanta University",
        "Taif University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2031757379",
    "https://openalex.org/W2771918728",
    "https://openalex.org/W3045707326",
    "https://openalex.org/W6766576792",
    "https://openalex.org/W2084575229",
    "https://openalex.org/W2803229189",
    "https://openalex.org/W2753676244",
    "https://openalex.org/W1988097236",
    "https://openalex.org/W2863257163",
    "https://openalex.org/W2577627646",
    "https://openalex.org/W2344696956",
    "https://openalex.org/W2968688692",
    "https://openalex.org/W2746633539",
    "https://openalex.org/W2913950581",
    "https://openalex.org/W2767672119",
    "https://openalex.org/W2960947282",
    "https://openalex.org/W2945639261",
    "https://openalex.org/W2766313919",
    "https://openalex.org/W3016244550",
    "https://openalex.org/W2474047844",
    "https://openalex.org/W2475596014",
    "https://openalex.org/W2792128614",
    "https://openalex.org/W2918218571",
    "https://openalex.org/W2892442579",
    "https://openalex.org/W2787337767",
    "https://openalex.org/W1988400047",
    "https://openalex.org/W2738112252",
    "https://openalex.org/W2767762497",
    "https://openalex.org/W2051542965",
    "https://openalex.org/W1984636526",
    "https://openalex.org/W2140417752",
    "https://openalex.org/W2602377377",
    "https://openalex.org/W2960944079",
    "https://openalex.org/W2127234432",
    "https://openalex.org/W2131987814",
    "https://openalex.org/W3103707007",
    "https://openalex.org/W2967663220",
    "https://openalex.org/W3028288947"
  ],
  "abstract": "Power transformer health index (PTHI) computation is performed based on the results of different tests, such as dissolved gas analysis (DGA), oil quality (OQ) evaluation, and depolarization factor (DP) testing. In this study, PTHI computation is performed using 631 dataset samples from Malaysia and 730 samples from the Gulf Region. A new model is proposed to predict the PTHI state by adopting intelligent classification methods (e.g., decision tree, support vector machine, k-nearest neighbor, and ensemble methods). The model is built via two-stage data processing. The first stage separates the test results into three modules that represent DGA, OQ, and DP factor codes. In the second stage, the output of the three modules is processed to predict the PTHI state. The four classification methods are applied to the proposed model, and the prediction accuracy of the PTHI state is determined. Results indicate that the proposed model has superior classification accuracy for each AI method compared with recent work. Furthermore, feature reductions are applied to minimize the testing time, effort, and costs. The reduced-feature models reveal the effectiveness of the adopted feature reduction technique. A slight difference in accuracy is observed between the full- and reduced-feature scenarios. Thus, the reduced-feature scenario is considered to decrease the effort and time of the computation process and the experimental cost. The proposed model is validated against uncertain noise in features of up to &#x00B1;20%.",
  "full_text": "IEEE POWER & ENERGY SOCIETY SECTION\nReceived September 23, 2020, accepted September 30, 2020, date of publication October 5, 2020, date of current version October 14, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.3028689\nComparative Study of Full and Reduced Feature\nScenarios for Health Index Computation of\nPower Transformers\nSHERIF S. M. GHONEIM\n1,2, (Senior Member, IEEE), AND IBRAHIM B. M. TAHA\n1,3\n1Department of Electrical Engineering, College of Engineering, Taif University, Taif 21944, Saudi Arabia\n2Faculty of Technology and Education, Suez University, Suez 43527, Egypt\n3Electrical Power and Machines Department, Faculty of Engineering, Tanta University, Tanta 31521, Egypt\nCorresponding author: Ibrahim B. M. Taha (i.taha@tu.edu.sa)\nThis work was support by Taif University Researchers Support Project Number (TURSP-2020/34).\nABSTRACT Power transformer health index (PTHI) computation is performed based on the results of\ndifferent tests, such as dissolved gas analysis (DGA), oil quality (OQ) evaluation, and depolarization\nfactor (DP) testing. In this study, PTHI computation is performed using 631 dataset samples from Malaysia\nand 730 samples from the Gulf Region. A new model is proposed to predict the PTHI state by adopting\nintelligent classiﬁcation methods (e.g., decision tree, support vector machine, k-nearest neighbor, and\nensemble methods). The model is built via two-stage data processing. The ﬁrst stage separates the test results\ninto three modules that represent DGA, OQ, and DP factor codes. In the second stage, the output of the three\nmodules is processed to predict the PTHI state. The four classiﬁcation methods are applied to the proposed\nmodel, and the prediction accuracy of the PTHI state is determined. Results indicate that the proposed model\nhas superior classiﬁcation accuracy for each AI method compared with recent work. Furthermore, feature\nreductions are applied to minimize the testing time, effort, and costs. The reduced-feature models reveal\nthe effectiveness of the adopted feature reduction technique. A slight difference in accuracy is observed\nbetween the full- and reduced-feature scenarios. Thus, the reduced-feature scenario is considered to decrease\nthe effort and time of the computation process and the experimental cost. The proposed model is validated\nagainst uncertain noise in features of up to ±20%.\nINDEX TERMS Power transformer health index, transformer tests, intelligent classiﬁcation methods.\nI. INTRODUCTION\nThe transformer is the most expensive equipment in the\nelectric power system. Monitoring the status of the insula-\ntion system in a power transformer is vital. Deterioration of\nthe transformer insulating oil due to electrical and thermal\nstresses can lead to undesired transformer outage in elec-\ntric power networks. Therefore, the continuous evaluation\nof the power transformer state has elicited much attention.\nThe condition of a transformer can be evaluated using a\nhealth index [1]. Establishing the power transformer health\nindex (PTHI) is a challenge. It involves the fusion of present\ndata from several sensors and equally important histori-\ncal data. PTHI is a practical method that uses transformer\ntest results to indicate the state of a power transformer.\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Arpan Kumar Pradhan\n.\nCommon transformer tests include dissolved gas analy-\nsis (DGA), insulating oil quality (OQ) evaluation, and furan\nanalysis (FA) [1]–[3].\nArtiﬁcial intelligence (AI) methods have been used to\nconstruct a prediction model to identify PTHI directly from\ntest results. A neuro-fuzzy (NF) network was constructed\nin [3], [4] to determine PTHI on the basis of the results\nof DGA, OQ, and FA. The results indicated that 62% of\nthe 73 tested transformers had the same assessment results\nregardless of the type of data used. In [4], an artiﬁcial neural\nnetwork (ANN) and adaptive NF inference system were used\nto construct a model for identifying PTHI. Technical and eco-\nnomical parameters were utilized as inputs to the constructed\nmodel. The technical parameters were DGA, OQ, and FA.\nThe economical parameters included transformer aging vari-\nables and cost functions. A fuzzy logic (FL) system was\nutilized in [2], [5]–[7]. In [2], the effect of interfacial tension\n181326 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nand oil color was ignored, and the accuracy of the proposed\nFL model was not reported. In [5], an elaborate approach was\nused to construct separate FL systems for identifying indi-\nvidual transformer states. Then, a ﬁnal FL system was built\nto compute PTHI on the basis of the results of the primary\nFL systems (thermal, electrical, mechanical, and dielectric\nintegrity conditions). In [6], a Cauchy membership function\nfor fuss grade division and a fuzzy evidence fusion method\nwere used to develop a PTHI prediction model. The model\nconsiders the bushing state and the state of other accessories.\nIn [7], PTHI was estimated using the FL approach based on a\ndistribution area of 69 KV or less. An analysis was conducted\nusing the results of oil tests, such as water content, breakdown\nvoltage, dissipation factor, furan, H 2, CH4, C2H2, C2H6, and\nC2H4. The ANN approach was applied to predict the PTHI\nstate in [8]–[10]. In [8], an ANN was proposed for PTHI pre-\ndiction by using a feature-based exhaustive method to elim-\ninate the least signiﬁcant tests. The constructed model was\nbased on DGA, OQ, and FA. In [9], integrated transformer\nsubsystems (insulation system, bushing, tap changer, core,\nand windings) were considered to evaluate PTHI. An intel-\nligent multiple regression ANN model was constructed to\nbuild a quantitative PTHI. The model was applied on the basis\nof 345 transformer datasets with high-performance PTHI\nstate prediction. In [10], an ANN model was built based on\nDGA, OQ, and FA factors to predict the PTHI state. The\nmodel exhibited an accuracy of 95% when it used the subset\nof input features, but its accuracy was 89% when it was tested\nwith datasets of other utility networks.\nA support vector machine (SVM) model was built in [11]\nto predict PTHI. The model was tested with 14 oil test results,\nwhich were used to build the model on the basis of 724 test\nsamples with high detection accuracy. In [12], the level of\nfuran content in transformer oil was determined through the\nmeasurement of oil test factors, such as breakdown voltage,\nwater content, and dissolved gas. A prediction model was\nbuilt using the k-nearest neighbor (KNN) method with 90%\ndetection accuracy. A wavelet model was developed in [13]\non the basis of 19 oil test results to predict the PTHI state.\nThe main objective of this work was to present a new method\nof assessing transformer conditions by adding a PTHI table\nthat improves conventional approaches. The model was used\nto predict the PTHI state in 345 transformers, and it exhibited\ngood detection performance.\nA Bayesian information fusion approach was proposed\nin [14] to predict the PTHI state on the basis of data collected\nfrom transformer measurements, maintenance, and failure\nstatistics. In [15], a decision-making model was built in\nconsideration of reliability and economy to identify the best\nmaintenance strategy for oil-ﬁlled transformers as a basis of\nPTHI prediction. Particle swarm optimization was used to\nconstruct the decision-making model on the basis of DGA,\noil test, electrical test, reliability, and economic operation.\nIn [16], a Markov model (MM) was utilized to determine\nthe PTHI of 373 transformers. Dissolved gas, OQ, and furan\ncompounds were used as model inputs. The MM model was\nbuilt based on a probability decision process, and it was used\nfor PTHI prediction. Meanwhile, a cluster-merging model\nwas presented in [17] to predict the PTHI state. However, only\nDGA was considered in this work; all other tests for identify-\ning the PTHI state were ignored. The method’s accuracy was\ninvestigated by using one case only, which was not enough\nto verify the model’s prediction capability. The proposed\nmodel in [18] was used to estimate the linear relation between\nPTHI and transformer tests. The researchers concluded that\nDGA, FA, and breakdown voltage test are sufﬁcient and can\nprovide an acceptable indication of PTHI compared with\nother techniques that involve many tests. However, the model\nwas applied in 90 transformers only, which may not be\nenough to provide useful insights into the accuracy of the\nmethod. In [19], a feature reduction model was developed\nbased on different reduced-feature approaches. The results\nshowed that water content, breakdown voltage, furan, and\nacidity are the most important features in predicting the\nPTHI state.\nThe drawbacks of these previous studies are as follows.\nFirst, most of them predicted the PTHI state by using a one-\nstage process, which decreases the overall prediction accu-\nracy. Second, they did not investigate the effect of uncertainty\noriginating from various parameters, such as sampling tem-\nperature, sampling position, loading history, and maintenance\nhistory of the test transformer.\nThe current study presents a PTHI framework for trans-\nformers that is based on extensive research on ageing markers\nin transformers and how to classify them effectively for asset\nmanagement. The framework is fed with training data and\nassesses classiﬁcation accuracy by using a test dataset.\nVOLUME 8, 2020 181327\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nIn addition, a new AI-based model for PTHI prediction was\ndeveloped. The proposed model consists of two-stage data\nprocessing. The ﬁrst stage uses four modules to process each\ntype of test result, including DGA, OQ, and DP, and produces\nintermediate code factors. The codes are used as inputs to\nthe second-stage module (module 4), which identiﬁes the\nﬁnal PTHI state. All modules in the proposed model use\nAI classiﬁcation methods, such as decision tree (DT), SVM,\nKNN, and ensemble method (EN). A total of 631 and 730 test\ndataset samples were collected from the test and maintenance\nlaboratories of two electricity companies in two countries\nto evaluate the accuracy of the proposed models and alter-\nnative AI-optimized methods. The datasets were utilized for\ntraining and testing purposes. The results on PTHI prediction\naccuracy indicated that the proposed model and the four\nclassiﬁcation methods exhibited high prediction accuracy for\nPTHI states. The EN method demonstrated an advantage over\nthe other AI methods. A feature reduction approach was used\nto reduce testing time, effort, and costs. The results of the\nfeature reduction showed high PTHI detection performance.\nThe uncertainty study revealed the robustness of the pro-\nposed method in predicting the PTHI state, and PTHI predic-\ntion accuracy exhibited only a slight change. The maximum\nchange in PTHI accuracy was 2.8% and 5.3% for the KNN\nmethod at ±15% and ±20% uncertainty noise compared\nwith that without uncertainty under full- and reduced-feature\nscenarios, respectively.\nII. POWER TRANSFORMER HEALTH INDEX\nThe determination of PTHI was performed based on the\nanalysis in [1], [20], [21]. PTHI can be estimated as follows.\nA. DISSOLVED GAS ANALYSIS\nThe computation of the DGA factor (DGAF) was performed\nbased on the following dissolved gases decomposed in trans-\nformer insulating oil: H 2, CH4, C2H6, C2H4, C2H2, CO, and\nCO2. DGAF can be determined as\nDGAF =\n∑7\ni=1\nSi ×Wi\nWi\n, (1)\nwhere Wi and Si refer to the weight and score of test parameter\ni, respectively, as shown in Table 12 in the appendix [20].\nThe transformer condition based on DGAF is represented\nby a range from ‘‘A’’ to ‘‘E’’ For instance, when DGAF is\nless than 1.2, the transformer condition is good and referred\nto as code ‘‘A’’ The transformer condition is considered poor\nwhen DGAF is greater than 3.0, which corresponds to code\n‘‘E’’ The codes from ‘‘A’’ to ‘‘E’’ are deﬁned in Table 13 in\nthe appendix [20].\nB. OIL QUALITY\nThe second important factor that inﬂuences PTHI is the\noil quality factor (OQF), which depends on the dielectric\nstrength, humidity, color, interfacial tension, acid amount of\nthe insulating oil, and insulation dissipation factor (DF). The\ncondition of the transformer can be monitored and evaluated\nby measuring the insulation DF [20]. Insulation DF indicates\nthe state of the insulation integrity of the winding and identi-\nﬁes the DF of the overall insulation, including the winding\nand bushing. The DF test is a routine test that measures\nthe insulation capacitance and power factor of transformer\ninsulation under 10 kV with 50 or 60 Hz [22]. Table 16 in\nthe appendix (as in [20]) illustrates a ranking method of the\ntransformer insulation DF. The score (S i) and weight factors\n(Wi) of test parameter i in different transformer operating\nvoltage ratings are listed in detail in Table 14 in the appendix,\nas in [20]. OQF can be calculated as follows:\nOQF =\n∑6\ni=1\nSi×Wi\nWi\n(2)\nThe transformer condition is identiﬁed based on OQF by\nusing a code from ‘‘A’’ to ‘‘E’’ similar to DGAF.\nC. DEPOLARIZATION FACTOR\nThe degree of depolarization (DP) of the paper insulation\ncan be measured via the furfural content in the insulating\noil [23]. The furan test is recommended and should be per-\nformed periodically when the rate of change in CO and CO 2\nconcentration increases or when the transformer age exceeds\n25 years [22]. DP is an important factor to compute PTHI.\nHowever, when the oil has been replaced, the degradation of\nthe cellulose paper cannot be identiﬁed based on the furan\ncontent. In this case, the age of the transformer can be used\nas a factor for health index computation [20], [23]. The range\nof furan content and the transformer age can be utilized to\ncompute the DP factor (DPF) in accordance with Table 15 in\nthe appendix, as in [20].\nTable 1 shows the scoring system of the main represen-\ntative factors for investigating the transformer health index\nfactor (HIF). The HIF score varies from 4 to 0, which corre-\nspond to transformer criteria codes ‘‘A’’ to ‘‘E’’ respectively.\nOn the basis of representative factors, the total PTHI can be\ncomputed as\nPTHI =\n∑4\ni=1 Ki ×HIFi\n∑4\ni=1 4Ki\n, (3)\nwhere Ki is the weight factor for each transformer condition\ncriterion [1], [20]. Ki is identiﬁed in accordance with the\nimportance of the test (DGA, OQ, and DP) in evaluating the\nPTHI state. The weighting factor of DGAF is 10 because\nits effect on evaluating the PTHI state is higher than that of\nOQF (8) and DPF (6). DGAF is the main factor that indicates\nfaulty (poor) and non-faulty (good and fair) states. Utility\nengineers use the values of DGA features as indicators for\nfaulty and non-faulty states of power transformers.\nTable 2 deﬁnes three PTHI states and their correspond-\ning threshold limits [24]. The ‘‘good’’ state represents the\ncase where the PTHI value is greater than or equal to 85,\nand the ‘‘fair’’ state represents the case where PTHI ranges\nfrom 85 to 50. The threshold limits for the ‘‘poor’’ state are\nobtained when PTHI is lower than 50. The required actions\ncorresponding to each sate are deﬁned in Table 2 [24].\n181328 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nTABLE 1. Health index scoring [20].\nTABLE 2. Threshold limit of transformer health state [24].\nFIGURE 1. Strategy of the classification methodology.\nIII. METHODOLOGY AND SCENARIOS\nA. FULL-FEATURE SCENARIO\nPTHI is computed using AI classiﬁcation methods (DT,\nSVM, KNN, and EN). Figure 1 presents the procedure used\nto compute the PTHI state in the proposed model depending\non the full features of the three test results (DGA, OQ, and\nDP tests). The dataset containing test results collected from\na chemical company in Malaysia and an electric company in\nthe Gulf Region is divided into two subsets. The ﬁrst subset\nis used for training, and the second one is used for testing.\nTo calculate the target output for each feature vector of the\ntraining and testing datasets, PTHI is computed using Eq. (3)\nand mapped to the corresponding transformer health state in\naccordance with Table 2. Then, the selected AI classiﬁca-\ntion method is applied. Finally, the PTHI state is predicted\nand reported against the selected AI classiﬁcation method.\nFigure 2 shows the procedure of the proposed model.\nIn the full-feature scenario, the PTHI state is predicted\nin two stages, as illustrated in Figure 2. In the ﬁrst stage,\nthe 14 input parameters are divided into three groups cor-\nresponding to the three factors: DGAF, OQF, and DP. Each\ngroup and its corresponding factor are used for training an\nFIGURE 2. Proposed model scenari.\nindividual module. The ﬁrst group consists of seven input\nparameters (H 2, CH 4, C 2H6, C 2H4, C 2H2, CO, and CO 2)\nthat are fed into the ﬁrst classiﬁcation module with the cor-\nresponding calculated DGAF. The second group consists of\nsix inputs parameters (moisture, breakdown voltage, color,\nacidity, IF, and DF) that are supplied to the second clas-\nsiﬁcation module with the corresponding calculated OQF.\nThe furan concentration is applied to the third classiﬁcation\nmodule with the corresponding calculated DPF. The selected\nclassiﬁcation method is used to train the three classiﬁcation\nmodules individually. In the second stage, a fourth module is\ntrained with a feature vector composed of DGAF, OQF, and\nDPF as the input and the PTHI state obtained from Table 2 as\nthe output. After completing the training process, the testing\ndataset is used to measure the accuracy of the developed\nclassiﬁcation methods.\nB. REDUCED-FEATURE SCENARIO\nFeature selection (FS) is a process of considering relevant fea-\ntures and discarding irrelevant features that do not inﬂuence\nthe output of a problem with minimum performance degra-\ndation. Given that PTHI evaluation considers all features,\nit requires considerable time for experiments, intensive labor,\nand high costs. FS is divided into three categories, namely, ﬁl-\nters, wrappers, and embedded methods. In this work, the min-\nimum redundancy maximum relevance (MRMR) approaches\ncategorized as ﬁlter methods were used to determine the\nimportance features. The feature importance scores were esti-\nmated using MRMR, as performed in [25]–[27].\nMRMR ranks the importance features of the classiﬁcation\nproblem. The main objective of MRMR is to minimize the\nredundancy of a feature set and maximize the relevance of a\nfeature set to classiﬁcation output c by using mutual informa-\ntion I, as follows [18], [19]:\nAs = 1\n|S|\n∑\nxϵS I (x,c), (4)\nBs = 1\n|S|2\n∑\nx,zϵS I (x,z), (5)\nVOLUME 8, 2020 181329\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nThe algorithms of the four modules are introduced as\nfollows:\nModule 1 Algorithm\n1. Insert the DGA features to the classiﬁcation method\n(H2, CH4, C2H6, C2H4, C2H2, CO, and CO 2).\n2. Calculate DGAF by using Eq. (1) on the basis of the\nDGA feature scores and weights in Table 12.\n3. Evaluate the DGAF code according to Table 13.\n4. Insert the DGA features (for the training dataset) as\nthe input and the corresponding DGAF code as the\noutput to each AI classiﬁcation method for the training\nprocess to build classiﬁcation module 1.\n5. Use the constructed classiﬁcation module 1 to predict\nthe DGAF code of the testing dataset samples.\nModule 2 Algorithm\n1. Insert the OQ features to the classiﬁcation method\n(BVD, IF , acidity, moisture, color, and DF).\n2. Calculate OQF by using Eq. (2) on the basis of the OQ\nfeature scores and weights in Table 12.\n3. Evaluate the OQF code according to Table 14.\n4. Insert the OQ features (for the training dataset) as the\ninput and the corresponding OQF code as the output to\neach AI classiﬁcation method for the training process\nto build classiﬁcation module 2.\n5. Use the constructed classiﬁcation module 2 to predict\nthe OQF code of the testing dataset samples.\nModule 3 Algorithm\n1. Insert the furan feature to the classiﬁcation method.\n2. Evaluate the DPF code according to Table 15.\n3. Insert the furan features (for the training dataset) as the\ninput and the corresponding DPF code as the output to\neach AI classiﬁcation method for the training process\nto build classiﬁcation module 3.\n4. Use the constructed classiﬁcation module 3 to predict\nthe DPF code of the testing dataset samples.\nModule 4 Algorithm\n1. Insert the DGAF , OQF , and DPF codes.\n2. Evaluate the PTHI state according to Tables 1 and 2.\n3. Insert the three output codes of Modules 1, 2, and 3 (for\nthe training dataset) as the input and the correspond-\ning PTHI code as the output to each AI classiﬁcation\nmethod for the training process to build classiﬁcation\nmodule 4.\n4. Use the constructed classiﬁcation module 4 to predict\nthe PTHI state of the testing dataset samples.\nwhere S is the optimal set of features that maximize rele-\nvance As and minimize redundancy Bs, |S|is the number of\nfeatures in S, x and z are two features that belong to set S,\nc denotes the output classes, and I is the mutual information\nthat can be expressed as follows [18], [20]:\nI =\n∑\nbϵB\n∑\naϵA p(a,b) ×log p(a,b)\np(a) ×p(b), (6)\nwhere A and B are two sets; a and b are features in subsets A\nand B, respectively; p(a, b) is the probability of a and b; and\np(a) and p(b) are the probability of a and b, respectively.\nCalculating an optimal set S requires considering all 2 w\ncombinations, where w is the entire feature site. The mutual\ninformation quotient (MIQ) is used to facilitate the estimation\nof MRMR, as follows:\nMIQx =Ax\nBx\n, (7)\nwhere Ax and Bx are the relevance and redundancy of a fea-\nture, respectively, and they can be evaluated as follows:\nAx =I(x,c), (8)\nBx = 1\n|S|\n∑\nzϵS I (x,z) (9)\nIV. RESULTS AND DISCUSSIONS\nA. FULL-FEATURE RESULTS\nEach of the four selected classiﬁcation methods (DT,\nSVM, KNN, and EN) was implemented using 2019b MAT-\nLAB/software. The methods were optimized and imple-\nmented in accordance with the MATLAB classiﬁcation\nlearner application toolbox. A brief description of the\nfour intelligent classiﬁcation methods is presented in the\nappendix.\nThe cross-fold validation approach with ﬁve folds was\nused to train the four AI-optimized classiﬁcation methods.\nThe training and testing processes were carried out on the\n1,361 dataset samples. The dataset samples were collected\nfrom two countries. The ﬁrst set (631 samples) was collected\nfrom the transmission regions of Malaysia Electricity Com-\npany. The dataset includes samples of power transformers\nof 220 kV at the transmission stage. The second set (730 sam-\nples) was collected from the Gulf Region’s medium-voltage\nregion (66 kV). Each set was divided randomly into 65%\nand 35% training and testing data samples, respectively. The\ntraining samples (885) of the two sets were collected for\ntraining, and the testing samples (476) of the two sets were\ncollected for testing. Table 3 shows the distribution of the\nsamples.\nThe accuracy of each AI classiﬁcation method for training,\ntesting, and overall stages was calculated as:\n%Accuracy =Nc\nNt ×100, (10)\nwhere Nc is the number of correctly predicted state samples\nfrom each AI-optimized classiﬁcation method. The correctly\npredicted state sample was identiﬁed by comparing the result\nof the AI classiﬁcation method with the result of the PTHI\nof Eq. (3) for each sample. Nt is the total number of state\nsamples.\nThe classiﬁcation learner toolbox application in MATLAB\n2019b was used to build the four classiﬁcation methods\n181330 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nTABLE 3. Data distribution of the samples used in training and testing\nstages.\nTABLE 4. Main optimization parameters of training DT, SVM, KNN, and EN\nmethods.\n(DT, SVM, KNN, and EN). For example, the DT method\ntypes (ﬁne tree, medium tree, and coarse tree) were used,\nand the issue was determining which one develops the best\npredictor. Hence, the hyperparameter optimization in the\nclassiﬁcation learner toolbox was used to select the suitable\nclassiﬁcation method and the corresponding parameters of\nthe two suggested scenarios.\nThe minimum estimated error was determined as follows:\nminimum error =min(1 −Nci\nNt ), (11)\nwhere Nci is the number of correctly predicted states of\nclassiﬁcation type i.\nAI classiﬁcation algorithms (DT, SVM, KNN, and EN)\nrequire an optimization technique to determine the best opti-\nmization parameters for each AI classiﬁcation method. The\noptimal parameters of DT methods are the maximum number\nof splits and split criterion, and that of SVM are multi-\nclass method, box constraint level, kernel function used, and\nstandardized data. Several optimization approaches, such as\nBayesian optimization (BO), grid search, and random search,\nare frequently used with classiﬁcation methods. The BO\napproach is effective for optimization problems and can be\nused for most machine learning techniques for hyperparam-\neter optimization [28]. BO iteratively explores the hyper-\nparameter space, where a probabilistic model of estimation\nis built based on prior calculation. Then, the probabilis-\ntic model is utilized to evaluate the optimal parameters by\nusing the probability values of its position and selecting\nthe parameters related to the highest probability [29]. The\ndetailed model of BO used for estimating the optimal hyper-\nparameters of machine learning techniques was introduced\nin [29], [30].\nThe training process was conducted through the following\nsteps. First, the main optimization parameters were selected\nbefore the training process of each classiﬁcation method\n(DT, SVM, KNN, and EN). Second, the optimization training\nprocess was carried out for each classiﬁcation method. Third,\nan optimized model was generated for each classiﬁcation\nmethod. Lastly, Steps 2 and 3 were repeated for each module\nof the proposed model shown in Figure 2. The main optimiza-\ntion parameters of training DT, SVM, KNN, and EN methods\nare presented in Table 4.\nTABLE 5. Classification method optimization and range parameters for\nthe full-feature scenario.\nThe DT, SVM, KNN, and EN methods were optimized for\nthe four modules of the full-feature approach on the basis of\nthe 885-sample training dataset. The optimal parameters of\nthe four classiﬁcation methods for the four modules with the\nfull-feature scenario are given as in Table 5.\nFigure 3 shows the minimum errors during the optimiza-\ntion process of the training stage for DT, SVM, KNN, and\nEN method corresponding to the four modules introduced\nin Figure 2 in the full-feature scenario. SVM had a mini-\nmum error for module 1, EN had a minimum error for mod-\nule 2, and the four methods had an equal minimum error for\nmodules 3 and 4.\nVOLUME 8, 2020 181331\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nFIGURE 3. Comparisons of the minimum errors of DT, SVM, KNN, and EN methods for different modules of the two-stage model classificatio.\nFIGURE 4. Confusion matrix for the training process of the SVM method.\nFigure 4 presents the confusion matrix for the training\nprocess of SVM with the full-feature scenario. The state\nclasses of ‘‘good,’’ ‘‘fair,’’ and ‘‘poor’’ are denoted by 1, 2,\nand 3, respectively. The results showed that the classiﬁcation\nprocess for the ‘‘good’’ state had the highest classiﬁcation\naccuracy (653/662 =98.6%), whereas the ‘‘poor’’ state had\nthe lowest classiﬁcation accuracy (8/19 =42.1%). The over-\nall accuracy of predicting the PTHI state was (851/885 =\n96.2%).\nFigure 5 illustrates the overall accuracy for training\nand testing stages in the full-feature scenario. The overall\naccuracy of predicting the PTHI states for DT, SVM, KNN,\nand EN methods corresponding to the training and testing\nprocess was (95.3%, 96.2%, 95.4%, and 96%) and (93.9%,\n95.2%, 95.2%, and 95.6%), respectively. These results indi-\ncate good prediction accuracy during the training and testing\nstages.\nTable 6 presents the number of total samples correctly\npredicted by each of the four methods against each PTHI\nstate. The detection accuracy of SVM and EN was better\nthan that of the other methods for the ‘‘good’’ state. KNN\nhad the highest accuracy for the ‘‘fair’’ state, and SVM\nmethod had the highest accuracy for the ‘‘poor’’ state. The EN\nmethod achieved superior classiﬁcation accuracy (95.9%) in\nthe full-feature scenario.\nB. REDUCED-FEATURE RESULTS\nThis section introduces the procedure of evaluating the rank\nof important redundancy features for DGAF and OQF by\nusing the MRMR approach presented in Section III (B). The\nsufﬁcient features for each factor were determined using the\n181332 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nFIGURE 5. Training and testing accuracy of the four methods for the\nfull-feature scenario.\nTABLE 6. Overall accuracy of the classification methods for the\nfull-feature model.\nprincipal component analysis (PCA) facility in the MATLAB\nclassiﬁcation learner toolbox after the training process. The\nsufﬁcient features for each factor were those that had a\nvariance greater than 95%. The training process was carried\nout with PCA for DGAF and OQF. The minimum feature\nfor DGAF was only one feature with explained variance\nratios in the order of 98.9%, 1%, and other features <0.1%.\nMeanwhile, the number of features required for OQF was\nat least three, with explained variance ratios in the order\nof 72.4%, 15.7%, 9.3%, 2.5%, 0.2%, and 0%. The importance\nfeatures for DGAF and OQF were selected based on the\nhighest feature scores obtained from the MRMR method. The\nimportance feature scores of DGAF and OQF are presented\nin Figures (6) and (7), respectively. The results showed that\nCO2, C2H2, C2H6, and C2H4 (Figure 6) were the most impor-\ntant factors of DGAF, whereas color, BDV , IF, and moisture\n(Figure 7) were the most important features of OQF. The\ntraining process was repeated with the selected features for\nDGAF and OQF. Although the variance of DGAF was only\none (CO 2), it was not enough to represent DGAF because\nCO2 and CO illustrate the insulation paper state, and the other\nfeatures illustrate the faulty state of transformer oil. Hence,\none of them was selected with CO 2 as an input of module\n1 to predict the DGAF state.\nAfter selecting the required features for each module (mod-\nules 1 and 2), the same procedure for the full-feature scenario\nwas carried out for the reduced-feature scenario. Different\nfeatures were selected for DGAF and OQF and applied to\nFIGURE 6. Feature importance of DGAF.\nFIGURE 7. Feature importance scores of OQF.\nmodules 1 and 2, respectively, whereas furan was inserted\ninto module 3. The output codes of modules 1, 2, and 3 were\napplied to module 4 to obtain the ﬁnal PTHI state. The\nobtained model for each case was used at the testing stage to\npredict the PTHI by using the testing data samples. Different\nnumbers of features were considered for DGAF and OQF.\nThe overall accuracy in each case is reported in Table 7.\nIn Table 7, the numbers 7, 5, 3, and 4 denote CO 2, C 2H2,\nC2H6, and C 2H4 on the DGAF column, respectively, and the\nnumbers 12, 8, 9, and 11 denote color, BDV , IF, and moisture\non the OQF column, respectively. The highlighted case has\nthe best prediction accuracy of 93.5%, 94.3%, 94.9, and\n95.8% for DT, SVM, KNN, and EN methods, respectively.\nThe selected features for DGAF that satisfy the minimum\nrequirements of PCA and achieve the highest prediction accu-\nracy for the PTHI state were CO 2, C 2H2, C 2H2, and C 2H4;\nthe corresponding features for OQF were color, BDV , IF, and\nmoisture.\nFigure 8 shows the confusion matrix for the training\nprocess of the EN method in the reduced-feature scenario.\nThe classiﬁcation process for the ‘‘good’’ state had the\nhighest classiﬁcation accuracy (655/662 =98.9%), whereas\nthe ‘‘poor’’ state had the lowest classiﬁcation accuracy\nVOLUME 8, 2020 181333\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nTABLE 7. Accuracy of the classification methods for the selected features\nof DGAF and OQF.\nFIGURE 8. Confusion matrix for the training process of the EN method.\nFIGURE 9. Training and testing accuracy of the four methods for the\nreduced-feature scenario.\n(10/19 =52.6%). The overall accuracy of detecting the PTHI\nstate was (846/885 =95.6%).\nFigure 9 presents the overall accuracy for training and\ntesting stages in the reduced-feature scenario. The overall\naccuracy of predicting the PTHI states for DT, SVM, KNN,\nand EN methods during the training and testing processes was\n(94.1%, 95%, 94.4% and 95.6%) and (92.4%, 92.9%, 96%\nand 96.2%), respectively. The results reveal a good prediction\naccuracy during the training and testing stages, especially\nwith the EN method.\nTable 8 presents the correct number of samples for the clas-\nsiﬁcation methods in comparison with each PTHI state. The\nresults indicated that the detection accuracy of the EN method\nwas better than that of the other methods for the ‘‘good’’\nand ‘‘fair’’ states. KNN exhibited the highest accuracy for\nthe ‘‘poor’’ state. The EN method achieved the highest clas-\nsiﬁcation accuracy (95.8%) in the reduced-feature scenario.\nOnly a slight difference in accuracy was observed between the\nTABLE 8. Overall accuracy of the classification methods for the\nreduced-feature model.\nTABLE 9. Comparison of full-feature and reduced-feature scenarios.\nfull- and reduced-feature scenarios. Thus, the reduced-feature\nscenario was considered to decrease the effort and time of the\ncomputation process and the experimental cost.\nC. COMPARISON OF FULL AND REDUCED FEATURES\nComparisons of the full- and reduced-feature scenarios were\nimplemented to investigate the difference in their predic-\ntion accuracy. All features were used for training and test-\ning the full-feature scenario, but only nine features (CO 2,\nC2H2, C 2H6, C 2H4, color, BDV , IF, moisture, and furan)\nwere adopted for the reduced-feature scenario. Applying the\nreduced features resulted in a short training time (for training\nmodules 1 and 2), less time and effort for measuring the\nfeatures in the laboratory, and fewer oil samples required for\nmeasuring the features.\nTable 9 presents a detailed comparison of the full- and\nreduced-feature scenarios for ‘‘good,’’ ‘‘fair,’’ ‘‘poor,’’ and\noverall PTHI states. The prediction accuracies of each\nmethod in the two scenarios showed good agreement. The\nprediction accuracy of ‘‘good,’’ ‘‘fair,’’ ‘‘poor,’’ and overall\nPTHI states for the EN method was (98.6%, 91%, 61.8%,\n95.9%) and (98.7%, 91%, 55.9%, 95.8%) for the full- and\nreduced-feature scenarios, respectively. The results show a\nslight difference between the full- and reduced-feature sce-\nnarios, especially when the EN method was involved.\nFigure 10 presents a comparison boxplot of the classiﬁ-\ncation methods (DT, SVM, KNN, and EN) for the full- and\nreduced-feature scenarios. It presents the minimum, max-\nimum, and standard deviation of each method in the two\nscenarios. A slight difference in the maximum and mean\nvalues was observed between the two scenarios for the four\nclassiﬁcation methods, especially the EN method. The KNN\nand EN methods had small differences in their minimum\nvalues under the full- and reduced-feature scenarios, whereas\nDT and SVM showed a large difference. The EN method is\nthus the preferred method for the reduced-feature scenario; it\nrequires only nine features, and its accuracy is close to that of\nthe full-feature accuracy.\n181334 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nFIGURE 10. Accuracy of the full- and reduced-feature scenarios with\ndifferent states and overall PTHI states.\nTABLE 10. Comparison of the proposed methods and the methods in [24]\nby using two dataset samples.\nD. PROPOSED MODEL VALIDATION\n1) PROPOSED MODEL AGAINST THE RESULTS IN [24]\nThe effectiveness of the proposed model was checked by\nusing two approaches. The ﬁrst one involved comparisons\nwith the results published in [24], which used dataset samples\nof System 2 (Gulf Region). The second approach was an\nuncertainty check.\nTable 10 presents the comparison between the results\nobtained by the proposed methods and those presented in [24]\nfor the full- and reduced-feature scenarios. The results in [24]\nare based on the Gulf Region dataset and on the methods\nNN, MLR, J48, and RF (the nine methods in [24] exhibited\nhigh accuracy). The proposed methods demonstrated higher\naccuracy compared with the methods presented in [24] for\nthe full-feature (∗) scenario and acceptable accuracy for the\nreduced-feature (∗∗) scenario. For the full-feature scenario,\nthe highest accuracy achieved by the proposed model was\n96.7% for the KNN classiﬁcation method, whereas the high-\nest accuracy achieved by the method in [24] was 96.6 % for\nRF classiﬁcation. In the reduced-feature scenario, the results\nof the proposed methods were better than those in [24],\nexcept for the RF method that has 96.6%. The best among\nthe proposed methods (the EN method) achieved 95.6%.\n2) PROPOSED MODEL AGAINST UNCERTAINTY\nThe process of preparing the datasets of the power trans-\nformers was carried out ofﬂine in three main steps. The ﬁrst\nstep was extracting samples from the power transformers.\nThe second step was extracting the gases from the transformer\noil, and the third step was predicting the PTHI state. The oil\nsamples were extracted using special syringes. The extracted\nsamples were stored and transferred to laboratories. Many\nfactors, such as storage time and temperature, affect gas con-\ncentration. The extraction process of gases is often conducted\nusing several techniques. Air bubble is the most critical fac-\ntor that affects gas concentrations [31]. Air bubbles reduce\ndissolved gases because of the diffusion of gases into the air\nbubbles, thus leaving the oil [32]. Hence, uncertainty during\nmeasurements affects PTHI state prediction. The uncertainty\nduring measurements must therefore be considered by the\nAI classiﬁcation techniques used for PTHI state prediction.\nAn uncertainty level of ±14% is caused by the sample’s\nstorage and temperature effects, and an uncertainty level of\nup to ±5% is caused by measurement accuracy [33]. In this\nwork, an uncertainty level of up to ±20% was considered.\nAn uncertainty evaluation was carried out by applying\npercentage noise on the input data. Percentage noise can be\ncalculated as follows [21]:\nNl ={100 −m +(2m ×RL )/100, (12)\nwhere Nl is the noise vector, l represents the number of\napplied samples in the uncertainty evaluation (476 testing\nsamples), m is the required noise percentage level (5%, 10%,\n15%, or 20%), and RL is a random vector with a length\nof 14 and varies from 0 to 1.\nNoise vector Nl is a vector that has numbers varying from\n0.95 to 1.05, 0.9 to 1.1, 0.85 to 1.15, or 0.8 to 1.2 when\nm has values of 5%, 10%, 15%, or 20%, respectively. The\noriginal input feature vector and Nl were produced element by\nelement to obtain new data (data with uncertain noise). These\nnew data were inserted into the proposed model by using dif-\nferent AI classiﬁcation methods for full- and reduced-feature\nscenarios. The test dataset was used to measure the per-\nformance of the four AI methods during the uncertainty\nevaluation.\nTable 11 presents the results of full- and reduced-feature\nscenarios against uncertainty data (476 testing dataset sam-\nples) for the four AI classiﬁcation methods. Tables 6 and\n10 show the results of the four AI methods with the testing\ndata for the full- and reduced-feature scenarios, respectively.\nThe four AI methods exhibited good depredation perfor-\nmance against uncertainty, and the EN method showed the\nbest performance in the full-feature scenario. Its accuracy\ndecreased from 95.6% to 95.2%, 95.2%, 93.7%, and 94.5%\nwith uncertainty noise of ±5%, ±10%, ±15%, and ±20%,\nrespectively. The maximum percentage error was obtained\nwith the KNN method ([95.2−92.4]/95.2 ×100=2.8%) at\n15% uncertainty noise.\nFurthermore, the four AI classiﬁcation methods exhibited\ngood performance against uncertainty in the reduced-feature\nscenario. The EN method had the best performance. Its\naccuracy decreased from 96.2% to 94.1%, 93.5%, 92.9%,\nand 92.0% with uncertainty noise of ±5%, ±10%, ±15%,\nand ±20%, respectively. The maximum percentage error was\nobtained with the KNN method ([96.2−91/96.2 ∗100]=5.4 %)\nVOLUME 8, 2020 181335\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nTABLE 11. Accuracy of the full- and reduced-feature scenarios against\nuncertainty data.\nFIGURE 11. Accuracy of the full- and reduced-feature scenarios with\nuncertainty noise in the four AI methods.\nat ±20% uncertainty noise. The performance of the four AI\nclassiﬁcation methods conﬁrmed that the uncertainty noise\neffect was limited in the proposed scenarios.\nFigure 11 presents the change in the accuracy of the four\nAI classiﬁcation methods against uncertainty noise of 0%\nto ±20% under the two scenarios. The degradation in the\naccuracy of the four methods was limited in the two sce-\nnarios against an uncertainty level of up to ±20%. EN had\nthe best performance against uncertainty in the full- and\nreduced-feature scenarios.\nV. CONCLUSION\nIn this work, full- and reduced-feature scenarios were pro-\nposed to predict the PTHI state by using four intelligent clas-\nsiﬁcation methods. The full-feature scenario included four\nclassiﬁcation modules for predicting the PTHI state. The four\nproposed AI classiﬁcation methods were DT, SVM, KNN,\nand EN. The overall prediction accuracy in the full-feature\nscenario was 94.8%, 95.3%, 95.8%, and 95.9% for DT, SVM,\nKNN, and EN, respectively. These results indicate that the\nrecommended method for PTHI state prediction is the EN\nmethod for the full-feature scenario. Furthermore, the results\nof the proposed model are superior to those presented in [24].\nThe MRMR feature reduction method was also used to reduce\nthe input features of the full-feature scenario from 7 to\n4 and from 6 to 4 for DGAF and OQF, respectively. CO 2,\nC2H2, C2H6, C2H4, color, BDV , IF, moisture, and furan were\nthe ﬁnal selected features for the reduced-feature scenario.\nFIGURE 12. Decision tree construction.\nA slight difference in accuracy was observed between the full-\nand reduced-feature scenarios. The highest overall accuracy\nin the full- and reduced-feature scenarios was 95.9% and\n95.8%, respectively; these values were obtained with the EN\nmethod. Thus, using the reduced-feature scenario is more\nreasonable than using the full-feature scenario. An uncer-\ntainty approach was applied to investigate the robustness of\nthe proposed model. The results indicated that the maximum\nerrors of classiﬁcation accuracy were 2.8% at ±15% uncer-\ntainty noise and 5.4% at ±20% uncertainty noise for the\nfull- and reduced-feature scenarios, respectively; these values\nwere obtained with the KNN classiﬁcation method.\nAPPENDIX A\nDECISION TREE (DT)\nThe DT method is a classiﬁcation approach. The ﬁrst step\nof the decision tree is the root node [34]. In this step, data\nare classiﬁed into different branches of the tree to obtain the\nspeciﬁed classes. The second step of the decision tree is to\nidentify the class condition, and the classiﬁcation forms a\nsub-tree. The same sorting process is repeated until all data\nin a branch are of the same type.\nFigure 12 shows the construction of a decision tree that\nconsists of the root node. Two or more paths branch from the\nroot node to represent an outcome of the test on the training\ndataset. These paths end with an internal node, which denotes\na test on an attribute. At the end, the leaf node holds a numeric\nprediction that considers numeric class. The DT method has\ndifferent types, such as ﬁne, medium, and coarse.\nAPPENDIX B\nENSEMBLE METHOD (EN)\nThis classiﬁer method is used to reduce variance in prediction\nmodels. The EN method has different types, such as bag,\nAdaBoost, RUS boost, logit boost, and gentle boost. The\nmost important EN method is the bag trees method. It accom-\nplishes the task by extracting new generation datasets using\ncombinations with repetitions from the original dataset for\ntraining [35], [36]. It ﬁts the base classiﬁers of the random\ngeneration subsets from the original dataset. Hence, it aggre-\ngates the individual predictions of these subsets to develop\nthe ﬁnal decision. This type of classiﬁcation is based on a\ntree structure consisting of a master node called the ‘‘root’’\nand a group of internal and ﬁnal nodes called ‘‘terminals.’’\nThe models generated by this classiﬁcation are characterized\n181336 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nFIGURE 13. Separation between two classes by SVM.\nby high accuracy and speed in model construction. It can\nalso be applied to multiclass data and can be interpreted and\nunderstood by decision tree analysis. The proposed model\nwas validated against uncertainty noise of up to ±20%.\nAPPENDIX C\nSUPPORT VECTOR MACHINE (SVM)\nSVM is one of the most common machine learning methods,\nand it is used as a classiﬁer for data analysis [37], [38].\nSVM ﬁnds the optimal separating hyperplane to maximize\nthe margin between data samples, as indicated in Figure 13.\nThe ﬁlled circles denote the support vectors, and the unﬁlled\ncircles refer to the training data.\nSVM regression evaluates a function on the basis of input\nand output data, as follows [38]:\nf (x)=w.x +b =\n∑m\nk=1 wk .xk +b =0, (A1)\nwhere w refers to the weight factor and b is the bias term.\nThey are used to identify the location of the hyperplane that\nsatisﬁes certain constraints, as follows [38]:\n\n\n\nyk (w.xk +b)≥1,k =1,2,......, m\nmin(1\n2 ∥w∥2)\n(A2)\nTherefore, SVM depends on the features of each collected\nsample. SVM constructs a hyperplane to segregate the sam-\nples of different classes. The hyperplane is built according\nto the training datasets, and it is used as a classiﬁer for a\nnew sample to obtain the actual class of each tested sample.\nA popular function used to identify the hyperplane is the\nkernel function. The kernel function has different types, such\nas Gaussian, linear, quadratic, and cubic [39].\nAPPENDIX D\nK-NEAREST NEIGHBOR (KNN) CLASSIFIER\nKNN is a machine learning classiﬁcation method. KNN\nstores all available data on certain states and classiﬁes the new\nsample on the basis of a similarity measure by measuring the\nFIGURE 14. Influence of a neighbo’s number on the classification [40].\nTABLE 12. Scoring and weight factors for gas levels [ppm].\nTABLE 13. Transformer rating based on DGAF.\ndistance functions. KNN operation theory determines the dis-\ntances between a query and all samples of the datasets. Then,\nby selecting the speciﬁed number of samples (k) close to the\nquery, KNN votes on the most frequent label or averages the\nlabels. Figure 14 shows the operation of KNN.\nSeveral classes can be represented by different shapes,\nsuch as squares and triangles. A test sample is expressed\nusing a star to identify the class that it belongs to (class 1\n[square] or class 2 [triangle]). The label of k determines the\nclass. For example, k =3 expresses class 1 because only two\nsquares and only one triangle exist. By contrast, k =5 refers\nto class 2 because the number of samples is ﬁve, which\nconsists of three triangles and two squares [40]. The different\nmetric distance methods used for KN are Euclidean, city\nblock, Chebyshev, Minkowski (cubic), Mahalanobis, cosine,\nSpearman correlation, Hamming, and Jaccard.\nVOLUME 8, 2020 181337\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\nTABLE 14. Grading method for oil quality test parameters.\nTABLE 15. Furan test rating code or age rating when testing is not\navailable.\nTABLE 16. Rating code of the maximum insulation dissipation factor.\nACKNOWLEDGMENT\nThe authors would like to acknowledge the ﬁnancial sup-\nport received from Taif University Researchers Supporting\nProject Number (TURSP-2020/34), Taif University, Taif,\nSaudi Arabia. The authors thank Prof. Ayman Al-Hag and\nProf. Norazhar Abu Bakar for their valuable discussion in this\nwork and for helping us to obtain the datasets.\nREFERENCES\n[1] A. Jahromi, R. Piercy, S. Cress, J. Service, and W. Fan, ‘‘An approach\nto power transformer asset management using health index,’’ IEEE Elect.\nInsul. Mag., vol. 25, no. 2, pp. 20–34, Mar. 2009.\n[2] C. Ranga, A. K. Chandel, and R. Chandel, ‘‘Condition assessment of power\ntransformers based on multi-attributes using fuzzy logic,’’ IET Sci., Meas.\nTechnol., vol. 11, no. 8, pp. 983–990, Nov. 2017.\n[3] E. Kadim, N. Azis, J. Jasni, S. Ahmad, and M. Talib, ‘‘Transformers health\nindex assessment based on neural-fuzzy network,’’ Energies, vol. 11, no. 4,\np. 710, Mar. 2018.\n[4] H. Zeinoddini-Meymand and B. Vahidi, ‘‘Health index calculation for\npower transformers using technical and economical Parameters,’’ IET Sci.,\nMeas. Technol., vol. 10, no. 7, pp. 823–830, 2016.\n[5] A. Chantola, M. Sharma, and A. Saini, ‘‘Integrated fuzzy logic approach\nfor calculation of health index of power transformer,’’ in Proc. 2nd Int.\nConf. Inventive Commun. Comput. Technol. (ICICCT), Coimbatore, India,\nApr. 2018, pp. 1045–1050.\n[6] F. Tian, Z. Jing, H. Zhao, E. Zhang, and J. Liu, ‘‘A synthetic condition\nassessment model for power transformers using the fuzzy evidence fusion\nmethod,’’Energies, vol. 12, no. 5, p. 857, 2019.\n[7] A. E. B. Abu-Elanien, M. M. A. Salama, and M. Ibrahim, ‘‘Calculation\nof a health index for oil-immersed transformers rated under 69 kV using\nfuzzy logic,’’ IEEE Trans. Power Del., vol. 27, no. 4, pp. 2029–2036,\nOct. 2012.\n[8] A. Y . Alqudsi and A. H. ElHag, ‘‘A cost effective artiﬁcial intelli-\ngence based transformer insulation health index,’’ in Proc. 3rd Int. Conf.\nCondition Assessment Techn. Electr. Syst. (CATCON), Rupnagar, India,\nNov. 2017, pp. 108–111.\n[9] M. Islam, G. Lee, S. N. Hettiwatte, and K. Williams, ‘‘Calculating a\nhealth index for power transformers using a subsystem-based GRNN\napproach,’’ IEEE Trans. Power Del., vol. 33, no. 4, pp. 1903–1912,\nAug. 2018.\n[10] A. Alqudsi and A. El-Hag, ‘‘Assessing the power transformer insulation\nhealth condition using a feature-reduced predictor mode,’’ IEEE Trans.\nDielectr. Electr. Insul., vol. 25, no. 3, pp. 853–862, Jun. 2018.\n[11] K. Ibrahim, R. M. Sharkawy, H. K. Temraz, and M. M. A. Salama,\n‘‘Selection criteria for oil transformer measurements to calculate the health\nindex,’’IEEE Trans. Dielectr. Electr. Insul., vol. 23, no. 6, pp. 3397–3404,\nDec. 2016.\n[12] K. B. Shaban, A. H. El-Hag, and K. Benhmed, ‘‘Prediction of transformer\nfuran levels,’’ IEEE Trans. Power Del., vol. 31, no. 4, pp. 1778–1779,\nAug. 2016.\n[13] R. M. A. Velasquez and J. V . M. Lara, ‘‘Health index for trans-\nformer condition assessment,’’ IEEE Latin Amer. Trans., vol. 16, no. 12,\npp. 2843–2849, Dec. 2018.\n[14] S. Li, H. Ma, T. Saha, and G. Wu, ‘‘Bayesian information fusion for\nprobabilistic health index of power transformer,’’ IET Gener., Transmiss.\nDistrib., vol. 12, no. 2, pp. 279–287, Jan. 2018.\n[15] M. Dong, H. Zheng, Y . Zhang, K. Shi, S. Yao, X. Kou, G. Ding, and\nL. Guo, ‘‘A novel maintenance decision making model of power transform-\ners based on reliability and economy assessment,’’ IEEE Access, vol. 7,\npp. 28778–28790, 2019.\n[16] M. Yahaya, N. Azis, M. Z. A. A. Kadir, J. Jasni, M. H. Hairi, and\nM. A. Talib, ‘‘Estimation of transformers health index based on the Markov\nchain,’’Energies, vol. 10, no. 11, p. 1824, 2017.\n[17] B. Qi, P. Zhang, Z. Rong, J. Wang, C. Li, and J. Chen, ‘‘Rapid transformer\nhealth state recognition through canopy cluster-merging of dissolved gas\ndata in high-dimensional space,’’ IEEE Access, vol. 7, pp. 94520–94532,\n2019.\n[18] A. E. B. Abu-Elanien and M. M. A. Salama, ‘‘Evaluation of transformer\nhealth condition using reduced number of tests,’’ Electr. Eng., vol. 101,\nno. 2, pp. 357–368, Jun. 2019.\n[19] K. Benhmed, A. Mooman, A. Younes, K. Shaban, and A. El-Hag, ‘‘Feature\nselection for effective health index diagnoses of power transformers,’’\nIEEE Trans. Power Del., vol. 33, no. 6, pp. 3223–3226, Dec. 2018.\n[20] A. Naderian, S. Cress, R. Piercy, F. Wang, and J. Service, ‘‘An approach\nto determine the health index of power transformers,’’ in Proc. Conf.\nRec. IEEE Int. Symp. Electr. Insul., Vancouver, BC, Canada, Jun. 2008,\npp. 192–196.\n[21] A. Azmi, J. Jasni, N. Azis, and M. Z. A. A. Kadir, ‘‘Evolution of trans-\nformer health index in the form of mathematical equation,’’ Renew. Sustain.\nEnergy Rev., vol. 76, pp. 687–700, Sep. 2017.\n[22] M. Wang, A. J. Vandermaar, and K. D. Srivastava, ‘‘Review of condition\nassessment of power transformers in service,’’ IEEE Elect. Insul. Mag.,\nvol. 18, no. 6, pp. 12–25, Nov. 2002.\n[23] B. Gorgan, P. V . Notingher, L. V . Badicu, and G. Tanasescu, ‘‘Calculation\nof power transformers health indexes,’’ Ann. Univ. Craiova, Electr. Eng.\nSer., no. 34, pp. 13–18, 2010.\n[24] A. Alqudsi and A. El-Hag, ‘‘Application of machine learning in trans-\nformer health index prediction,’’ Energies, vol. 12, no. 14, p. 2694, 2019.\n[25] C. Ding and H. Peng, ‘‘Minimum redundancy feature selection from\nmicroarray gene expression data,’’ J. Bioinf. Comput. Biol., vol. 3, no. 2,\npp. 185–205, Apr. 2005.\n[26] G. A. Darbellay and I. Vajda, ‘‘Estimation of the information by an adaptive\npartitioning of the observation space,’’ IEEE Trans. Inf. Theory, vol. 45,\nno. 4, pp. 1315–1321, May 1999.\n181338 VOLUME 8, 2020\nS. S. M. Ghoneim, I. B. M. Taha: Comparative Study of Full and Reduced Feature Scenarios for Health Index Computation\n[27] S. Ramírez-Gallego, I. Lastra, D. Martínez-Rego, V . Bolón-Canedo,\nJ. M. Benítez, F. Herrera, and A. Alonso-Betanzos, ‘‘Fast-mRMR: Fast\nminimum redundancy maximum relevance algorithm for high-dimensional\nbig data,’’ Int. J. Intell. Syst., vol. 32, no. 2, pp. 134–152, Feb. 2017.\n[28] S. Putatunda and K. Rama, ‘‘A modiﬁed Bayesian optimization based\nhyper-parameter tuning approach for extreme gradient boosting,’’ in Proc.\n15th Int. Conf. Inf. Process. (ICINPRO), Dec. 2019, pp. 1–6.\n[29] W. William, B. Burank, and P. Efstratios, ‘‘Hyperparameter optimization\nof machine learning models through parametric programming,’’ Comput.\nChem. Eng., vol. 139, pp. 1–12, Apr. 2020.\n[30] J. Wu, X.-Y . Chen, H. Zhang, L.-D. Xiong, H. Lei, and S.-H. Deng,\n‘‘Hyperparameter optimization for machine learning models based on\nBayesian optimization,’’ J. Electron. Sci. Technol., vol. 17, pp. 26–40,\nMar. 2019.\n[31] A. Hoballah, D.-E.-A. Mansour, and I. B. M. Taha, ‘‘Hybrid grey wolf\noptimizer for transformer fault diagnosis using dissolved gases considering\nuncertainty in measurements,’’ IEEE Access, vol. 8, pp. 139176–139187,\n2020.\n[32] S. M. Korobeynikov, A. V . Ridel, A. Y . Korobenkova, and D. V . Vagin,\n‘‘Dissolution of bubbles with diagnostic gases in insulating liquids,’’ in\nProc. IEEE 19th Int. Conf. Dielectr. Liquids (ICDL), Manchester, U.K.,\nJun. 2017, pp. 1–4.\n[33] S. Tenbohlen, J. Aragon-Patil, M. Fischer, M. Schäfer, Z. D. Wang, and\nI. H. Atanasova, ‘‘Investigation on sampling, measurement and interpreta-\ntion of gas-in-oil analysis for power transformers,’’ in Proc. CIGRE, 2008,\npp. D1–D204.\n[34] D.-Y . Yeh, C.-H. Cheng, and S.-C. Hsiao, ‘‘Classiﬁcation knowledge\ndiscovery in mold tooling test using decision tree algorithm,’’ J. Intell.\nManuf., vol. 22, no. 4, pp. 585–595, Aug. 2011.\n[35] T. Muhlbacher, L. Linhardt, T. Moller, and H. Piringer, ‘‘TreePOD:\nSensitivity-aware selection of Pareto-optimal decision trees,’’ IEEE Trans.\nVis. Comput. Graphics, vol. 24, no. 1, pp. 174–183, Jan. 2018.\n[36] P. K. Mishra, A. Yadav, and M. Pazoki, ‘‘A novel fault classiﬁcation scheme\nfor series capacitor compensated transmission line based on bagged tree\nensemble classiﬁer,’’ IEEE Access, vol. 6, pp. 27373–27382, 2018.\n[37] K. Bacha, S. Souahlia, and M. Gossa, ‘‘Power transformer fault diagnosis\nbased on dissolved gas analysis by support vector machine,’’ Electr. Power\nSyst. Res., vol. 83, no. 1, pp. 73–79, Feb. 2012.\n[38] A. D. Ashkezari, H. Ma, T. K. Saha, and C. Ekanayake, ‘‘Application\nof fuzzy support vector machine for determining the health index of the\ninsulation system of in-service power transformers,’’ IEEE Trans. Dielectr.\nElectr. Insul., vol. 20, no. 3, pp. 965–973, Jun. 2013.\n[39] Hyperparameter Optimization in Classiﬁcation Learner App.\n[Online]. Available: https://ch.mathworks.com/help/stats/hyperparameter-\noptimization-in-classiﬁcation-learner-app.html\n[40] Y . Benmahamed, Y . Kemari, M. Teguar, and A. Boubakeur, ‘‘Diagnosis of\npower transformer oil using KNN and Naïve Bayes classiﬁers,’’ in Proc.\nIEEE 2nd Int. Conf. Dielectr. (ICD), Jul. 2018, pp. 1–4.\nSHERIF S. M. GHONEIM (Senior Member,\nIEEE) received the B.Sc. and M.Sc. degrees from\nthe Faculty of Engineering at Shoubra, Zagazig\nUniversity, Egypt, in 1994 and 2000, respectively,\nand the Ph.D. degree in electrical power and\nmachines from the Faculty of Engineering, Cairo\nUniversity, in 2008. Since 1996, he has been teach-\ning at the Faculty of Industrial Education, Suez\nCanal University, Egypt. From the end of 2005 to\nthe end of 2007, he was a Guest Researcher with\nthe Institute of Energy Transport and Storage (ETS), University of Duisburg–\nEssen, Germany. He joined Taif University as an Associate Professor with\nthe Electrical Engineering Department, Faculty of Engineering. His research\ninterests include grounding systems, dissolved gas analysis, breakdown in\nSF6 gas, and AI technique applications.\nIBRAHIM B. M. TAHAreceived the B.Sc. degree\nfrom the Faculty of Engineering, Tanta University,\nEgypt, in 1995, the M.Sc. degree from the Fac-\nulty of Engineering, Mansoura University, Egypt,\nin 1999, and the Ph.D. degree in electrical power\nand machines from the Faculty of Engineering,\nTanta University, in 2007. Since 1996, he has been\nteaching at the Faculty of Engineering, Tanta Uni-\nversity. He joined Taif University as an Associate\nProfessor with the Electrical Engineering Depart-\nment, Faculty of Engineering. His research interests include steady state and\ntransient stability of HVDC systems, FACTS, multilevel inverters, dissolved\ngas analysis, and AI technique applications.\nVOLUME 8, 2020 181339",
  "topic": "Computation",
  "concepts": [
    {
      "name": "Computation",
      "score": 0.7174731492996216
    },
    {
      "name": "Computer science",
      "score": 0.6349455118179321
    },
    {
      "name": "Data mining",
      "score": 0.5267894864082336
    },
    {
      "name": "Transformer",
      "score": 0.5030099749565125
    },
    {
      "name": "Feature (linguistics)",
      "score": 0.4951407015323639
    },
    {
      "name": "Decision tree",
      "score": 0.4814419150352478
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4627091884613037
    },
    {
      "name": "Random forest",
      "score": 0.43609851598739624
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3941066861152649
    },
    {
      "name": "Algorithm",
      "score": 0.23973029851913452
    },
    {
      "name": "Engineering",
      "score": 0.16366174817085266
    },
    {
      "name": "Linguistics",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130009713",
      "name": "Suez University",
      "country": "EG"
    },
    {
      "id": "https://openalex.org/I179331831",
      "name": "Taif University",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I21376657",
      "name": "Tanta University",
      "country": "EG"
    }
  ]
}