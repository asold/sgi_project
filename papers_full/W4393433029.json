{
    "title": "Species-aware DNA language models capture regulatory elements and their evolution",
    "url": "https://openalex.org/W4393433029",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A3162374597",
            "name": "Alexander Karollus",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3033514342",
            "name": "Johannes Hingerl",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2990471267",
            "name": "Dennis Gankin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3112323933",
            "name": "Martin Grosshauser",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4318284026",
            "name": "Kristian Klemon",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1907835997",
            "name": "Julien Gagneur",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2259938310",
        "https://openalex.org/W2750304043",
        "https://openalex.org/W1996816368",
        "https://openalex.org/W4206641739",
        "https://openalex.org/W3159728495",
        "https://openalex.org/W4378976294",
        "https://openalex.org/W4367173711",
        "https://openalex.org/W2167406239",
        "https://openalex.org/W2054624670",
        "https://openalex.org/W1993351732",
        "https://openalex.org/W1987414043",
        "https://openalex.org/W2167300924",
        "https://openalex.org/W3127238141",
        "https://openalex.org/W4380488316",
        "https://openalex.org/W2153452535",
        "https://openalex.org/W4292767338",
        "https://openalex.org/W2067644347",
        "https://openalex.org/W2601509136",
        "https://openalex.org/W2013449615",
        "https://openalex.org/W2105796031",
        "https://openalex.org/W2162600254",
        "https://openalex.org/W2162165765",
        "https://openalex.org/W2005244073",
        "https://openalex.org/W2138572581",
        "https://openalex.org/W2761430568",
        "https://openalex.org/W3105484006",
        "https://openalex.org/W2085567058",
        "https://openalex.org/W4213140257",
        "https://openalex.org/W2997580108",
        "https://openalex.org/W3139265997",
        "https://openalex.org/W2104262114",
        "https://openalex.org/W2007232912",
        "https://openalex.org/W2794189415",
        "https://openalex.org/W2087058596",
        "https://openalex.org/W2093094564",
        "https://openalex.org/W2907899595",
        "https://openalex.org/W2145191876",
        "https://openalex.org/W2773564951",
        "https://openalex.org/W3135803532",
        "https://openalex.org/W2096286842",
        "https://openalex.org/W2151233592",
        "https://openalex.org/W2180876606",
        "https://openalex.org/W2038661569",
        "https://openalex.org/W2015635728",
        "https://openalex.org/W2041103217",
        "https://openalex.org/W2040370607",
        "https://openalex.org/W2610908544",
        "https://openalex.org/W2046754106",
        "https://openalex.org/W2274600402",
        "https://openalex.org/W3108101741",
        "https://openalex.org/W2140090852",
        "https://openalex.org/W1984948517",
        "https://openalex.org/W1971933513",
        "https://openalex.org/W2101762601",
        "https://openalex.org/W2892403696",
        "https://openalex.org/W3215110686",
        "https://openalex.org/W4200135473",
        "https://openalex.org/W2142678478",
        "https://openalex.org/W4387966979",
        "https://openalex.org/W4207025036"
    ],
    "abstract": "Abstract Background The rise of large-scale multi-species genome sequencing projects promises to shed new light on how genomes encode gene regulatory instructions. To this end, new algorithms are needed that can leverage conservation to capture regulatory elements while accounting for their evolution. Results Here, we introduce species-aware DNA language models, which we trained on more than 800 species spanning over 500 million years of evolution. Investigating their ability to predict masked nucleotides from context, we show that DNA language models distinguish transcription factor and RNA-binding protein motifs from background non-coding sequence. Owing to their flexibility, DNA language models capture conserved regulatory elements over much further evolutionary distances than sequence alignment would allow. Remarkably, DNA language models reconstruct motif instances bound in vivo better than unbound ones and account for the evolution of motif sequences and their positional constraints, showing that these models capture functional high-order sequence and evolutionary context. We further show that species-aware training yields improved sequence representations for endogenous and MPRA-based gene expression prediction, as well as motif discovery. Conclusions Collectively, these results demonstrate that species-aware DNA language models are a powerful, flexible, and scalable tool to integrate information from large compendia of highly diverged genomes.",
    "full_text": "Species‑aware DNA language models \ncapture regulatory elements and their evolution\nAlexander Karollus1,2†  , Johannes Hingerl1†, Dennis Gankin1†, Martin Grosshauser1, Kristian Klemon1 and \nJulien Gagneur1,2,3,4,5* \nIntroduction\nA typical eukaryotic genome contains large regions of non-coding DNA. These are not \ntranslated into proteins but contain regulatory elements which control gene expression \nin response to environmental cues. Finding these regulatory elements and elucidating \nhow their combinations and arrangements determine gene expression is a major goal of \ngenomics research and is of great utility for synthetic biology and personalized medicine.\nIn the last decade, significant progress has been made towards understanding the reg -\nulation of model species, particularly humans and mice, by leveraging the work of large \nAbstract \nBackground: The rise of large-scale multi-species genome sequencing projects prom-\nises to shed new light on how genomes encode gene regulatory instructions. To this \nend, new algorithms are needed that can leverage conservation to capture regulatory \nelements while accounting for their evolution.\nResults: Here, we introduce species-aware DNA language models, which we trained \non more than 800 species spanning over 500 million years of evolution. Investigating \ntheir ability to predict masked nucleotides from context, we show that DNA language \nmodels distinguish transcription factor and RNA-binding protein motifs from back-\nground non-coding sequence. Owing to their flexibility, DNA language models \ncapture conserved regulatory elements over much further evolutionary distances \nthan sequence alignment would allow. Remarkably, DNA language models reconstruct \nmotif instances bound in vivo better than unbound ones and account for the evolu-\ntion of motif sequences and their positional constraints, showing that these models \ncapture functional high-order sequence and evolutionary context. We further show \nthat species-aware training yields improved sequence representations for endogenous \nand MPRA-based gene expression prediction, as well as motif discovery.\nConclusions: Collectively, these results demonstrate that species-aware DNA lan-\nguage models are a powerful, flexible, and scalable tool to integrate information \nfrom large compendia of highly diverged genomes.\nOpen Access\n© The Author(s) 2024. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate-\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://\ncreativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdo-\nmain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nRESEARCH\nKarollus et al. Genome Biology           (2024) 25:83  \nhttps://doi.org/10.1186/s13059‑024‑03221‑x\nGenome Biology\n†Alexander Karollus, Johannes \nHingerl, and Dennis Gankin \ncontributed equally to this work.\n*Correspondence:   \ngagneur@in.tum.de\n1 School of Computation, \nInformation and Technology, \nTechnical University of Munich, \nGarching, Germany\n2 Munich Center for Machine \nLearning, Munich, Germany\n3 Institute of Human Genetics, \nSchool of Medicine and Health, \nTechnical University of Munich, \nMunich, Germany\n4 Computational Health Center, \nHelmholtz Center Munich, \nNeuherberg, Germany\n5 Munich Data Science Institute, \nTechnical University of Munich, \nGarching, Germany\nPage 2 of 21Karollus et al. Genome Biology           (2024) 25:83 \nconsortia such as ENCODE [1] or FANTOM5 [2]. These groups have invested consider -\nable resources to compile massive compendia of experiments which probe many steps of \ntranscription control at high resolution and depth.\nNonetheless, estimates indicate that there are millions of eukaryotic species [3]. Many \nof these have agricultural, medical, or biotechnological relevance and even those lack -\ning direct economic importance may still hold key insights about regulatory evolution. \nAccordingly, it would certainly be valuable if existing approaches were extended beyond \nmodel organisms. Nevertheless, generating an ENCODE for every species is not feasible \nat the current level of technology. What is more in reach, however, is to sequence the \ngenomes of all species—and this is increasingly being done [4–8].\nAs the genomes of all organisms are evolutionarily related, it is possible to study reg -\nulatory elements through sequence comparison, without requiring additional experi -\nmental annotations [9]. Specifically, we expect that regulatory sequences and functional \narrangements thereof are selected and thus generally more conserved than expected for \nneutral mutations [10]. The main method to determine whether particular nucleotides \nare conserved makes use of sequence alignment. Unfortunately, alignment is difficult \nfor non-coding sequences, presumably because regulatory sequences evolve faster than \ncoding sequences and because of a certain tolerance to the exact order, orientation, and \nspacing of regulatory elements in regulatory sequences [11, 12]. Thus, while alignments \nwill certainly remain valuable, their ability to integrate information across large compen-\ndia of highly diverged species is limited.\nInferring regulatory elements from genomic sequences only, without requiring further \ngene expression-related experimental data, i.e., labels, is reminiscent of a typical chal -\nlenge in another domain, natural language processing, where vast quantities of mostly \nunlabelled text are available. There, masked language modeling, a type of self-supervised \nrepresentation learning, presents another way to generate insights from unlabelled data \n[13]. To train masked language models (LMs), parts of an input sequence are hidden \n(masked), and the model is tasked to reconstruct them. To do so, LMs learn an internal \nnumerical representation of words and their context, capturing the syntax and semantics \nof natural language. In turn, these representations can be used as features for efficiently \ntraining supervised models for many downstream tasks. This approach has alleviated \nthe scarcity of labeled data in many natural language processing predictive tasks such as \ntranslation or question answering.\nIn genomics, previous work has adopted masked language modeling as a method to \nbuild sequence representations for DNA [14], although initially this was focused on sin -\ngle species. Only recently, multi-species datasets have been used to train large genomic \nlanguage models [15–17]. These models foremost serve as a basis to build predictors \nof molecular phenotypes. In principle, LMs should benefit from multi-species train -\ning through the ability to leverage evolution. While first results in this direction have \nbeen very encouraging [16], a recent analysis found that a model trained only on human \nsequences achieves better predictions for fruit fly enhancers compared to a multispecies \nmodel that includes the fruit fly genome [17]—an observation which is difficult to rec -\noncile with the 700 million years of divergence between these species [18]. Performance \non downstream tasks after fine-tuning, i.e., using the pre-trained model as initialization \nto then train the full model in a supervised fashion, is an indirect measure of the features \nPage 3 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \nlearned by multispecies pretraining since the exact features needed to succeed at the \ngiven tasks are unknown, potentially learned during fine tuning and not investigated in \nthese works.\nDue to their focus on downstream tasks, previous works considered the actual task \nthe language model is trained to perform—reconstructing masked nucleotides—as a \nmeans to an end and do not study it. The sole exception to this trend is a recent contri -\nbution [19], which showed that poorly reconstructed nucleotides were enriched for vari-\nants with low frequency in the Arabidopsis thaliana population—although the strongest \nvariants driving this signal appear to be coding rather than regulatory. Moreover, while \ntheir model was trained on eight genomes, all evaluations were done on the Arabidopsis \nthaliana genome only, which the model was also trained on. Thus, while the authors \nsuggest that the prediction of their language model can be considered a generalized con-\nservation score, it is unclear whether their language model leverages between-species, \nrather than within-species, conservation of regulatory rules, and, more importantly, if \ntheir model accounts for changes in the code between species.\nIn this study, we aim to address these limitations by training masked LMs on a large \nnumber of highly evolutionarily diverged eukaryotes. Compared to previous approaches, \nwe provide species information to our models to avoid the model having to infer the spe-\ncies context to account for the evolution of the regulatory code. We focus on non-coding \nregions and explicitly evaluate whether the models have learned meaningful species-\nspecific and shared regulatory features during training across evolution and can transfer \nthem to unseen species. Finally, we evaluate whether sequence representations provided \nby the models are predictive of important molecular phenotypes, such as RNA half-life \nor gene expression, and encode biologically meaningful motifs.\nResults\nUsing language models as an alignment‑free method to capture the conservation \nand evolution of regulatory elements\nSequence alignment is a well-known and highly effective method to study the evolu -\ntion of biological sequences. It can be used to detect homologies, find conserved subse -\nquences, and pinpoint sequence motifs. We first assessed whether sequence alignments \ncould be a viable starting point to capture conserved regulatory sequence elements in \n3′ regions across large evolutionary distances. To this end, we aligned annotated 3′ \nuntranslated regions (UTRs) and, as control, coding sequences of Saccharomyces cer -\nevisiae to the genomes of a variety of fungal species (Fig.  1A). Coding sequences could \nbe successfully aligned even between highly diverged species. In contrast, the ability to \nalign 3′ regions almost completely disappears beyond the Saccharomyces genus.\nNevertheless, many regulatory sequence elements of 3′ UTRs are conserved far \nbeyond the genus boundary. The 3′ region of the cytochrome B assembly factor CBP3 \nillustrates this. Experiments have shown that the RNA-binding protein Puf3 binds 3′ \nUTR of this gene in S. cerevisiae and the far diverged (about 500 Mya [20]) Neurospora \ncrassa [21]. Moreover, we found that the Puf3 consensus binding motif can be found \n3′ to the stop of the CBP3 homolog in almost all yeasts. However, we observed that \nthe motif appears to be highly mobile, complicating alignment (Fig.  1B). This example \nPage 4 of 21Karollus et al. Genome Biology           (2024) 25:83 \nillustrates the need and potential for alignment-free approaches to leverage conservation \nacross large evolutionary distances.\nIn principle, masked language modeling should be able to leverage evolutionary infor -\nmation without requiring alignment because their representation of sequence is more \nflexible and expressive, alleviating the rigid order constraint that sequence alignments \nsubsume. Specifically, we expect that nucleotides with regulatory function should be \nmore conserved, within and particularly across species, and therefore easier to recon -\nstruct when masked than remaining background non-coding sequences.\nPrior to applications of masked language models in genomics, methods addressed the \nissue of lack of alignments of non-coding sequences. Generally, these methods either \nmake use of motif representations learned from experimental data in model organisms \nto investigate genomes of other species [22, 23] or are based on k-mer enrichments \n[24–28]. The language modeling approach is similar to the latter, as learning to predict \nmasked nucleotides from context requires capturing subtle patterns of co-occurrence. \nHowever, in contrast to these approaches, language models implicitly model such pat -\nterns using flexible, nonlinear functions which enables them to learn informative \nFig. 1 Masked language modeling can serve as an alternative for alignments, which struggle to capture \nthe conservation of regulatory elements over large evolutionary distances. A BLAST hits of S. cerevisiae CDS \nand 3′ UTRs in other fungal species. B Regions 3′ to the stop codon of CBP3 orthologues in different fungal \nspecies. Instances of Puf3-like motifs (TGTA*ATA) are indicated in red, and a star indicates experimental \nevidence of Puf3 binding. It appears that Puf3 binding is conserved whereas the location of the motif is not. \nC Masked language models are neural networks trained to reconstruct masked nucleotides from context. \nWe illustrate this with the example of a Puf3 motif (TGT AAA TA), where the second to last T has been hidden. \nSince this motif is highly conserved, the model may learn that, given this context, a T is most likely. For each \nmasked nucleotide, the model returns a probability distribution over the letters A, C, G, and T. We can extract \nsequence representations from the model by pooling the hidden representations of the last four layers of \nthe model. The architecture of the LM corresponds to DNABERT [14], with the modification that we make the \nmodel species-aware, by providing a token denoting the species where the sequence is originally from. D \nWe train language models on hundreds of highly diverged fungi. In each genome, we locate the annotated \ncoding sequences and we extract the non-coding sequences immediately before the start codon (5′ region) \nand immediately after the stop codon (3′ region). We train separate models for each region. Each model is \ntrained on more than 10 million sequences\nPage 5 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \nrepresentations of their input. Moreover, the attention mechanism guides the model \ntowards the parts of the input relevant for a particular prediction. This, in theory, allows \ncapturing high-order dependencies between nucleotides or motifs without requiring a \ntabulation of all possible dependencies or explicit assumptions regarding their shape and \nnature.\nTo explicitly test this, we trained masked LMs (Fig.  1C) on non-coding regions adja -\ncent to genes extracted from a vast multispecies dataset, comprising 806 fungal species \nseparated by more than 500 million of years of evolution. We trained distinct models \nfor the 1000 nucleotides 5′ of the start codon (5′ region) and the 300 nucleotides 3′ of \nthe stop codon (3′ region) of all annotated coding sequences (Fig.  1D). The 5′ region \ntypically contains the 5′ UTR and the promoter of the gene [29]. The 3′ region typically \ncontains the 3′ UTR [30]. Hence, we expect these regions to be enriched for non-coding \nsequences and to capture both transcriptional regulatory elements as well as post-tran -\nscriptional regulatory elements involved in mRNA stability and translation. Importantly, \nno annotation of UTR, promoters, nor transcription start site or polyA site was provided \nto the model. Models were trained with (species LM) and without species tokens in the \ninput (agnostic LM). However, we provided no information about the phylogeny of the \nspecies, nor did we indicate to the models which sequences flank orthologous genes. The \nmodels were trained on all extracted sequences jointly. We focused on fungi, since many \nfungal genomes are available, they evolve quickly and their transcriptional control gener-\nally makes less use of extreme long-range interactions which are difficult to model with \ncurrent approaches. We held out the entire Saccharomyces genus to test the generaliza -\ntion performance of our model in the well-studied species Saccharomyces cerevisiae.\nLanguage models reconstruct known binding motifs in an unseen species\nBinding motifs, which represent the sequence specificities of DNA and RNA-binding \nproteins (RBP), are considered to be the “atomic units of gene expression” [31]. Accord -\ningly, to verify that LMs can capture aspects of the regulatory code in an alignment-free \nmanner, we first needed to verify that they capture important known motifs.\nTo test this, we analyzed to what extent our 3′ and 5′ LMs could reconstruct nucle -\notides in the held-out species S. cerevisiae. We compared the reconstruction obtained \nby our LMs with a number of baselines, including approaches based on k-mer frequen -\ncies and alignment of species beyond the genus. We also computed the reconstruc -\ntion achieved by aligning S. cerevisiae with other Saccharomyces species, which can be \nregarded as an estimate of the upper range of achievable reconstruction.\nWe found that all approaches—except the alignment of close species—perform simi -\nlarly when we compute the reconstruction accuracy over all nucleotides (Fig.  2A and \nAdditional file  1: Fig S1). This changes drastically when considering the reconstruction \nof known motifs. Instances matching the Puf3 consensus motif, for example, are recon -\nstructed almost as well by the species-aware 3′ model as they are by the alignment of \nclose species (Fig.  2A), strongly outperforming the alignment with far species and other \nbaselines. We observe similar results for other RBP motifs, as well as the consensus \nmotifs of a number of transcription factors (TF) in the 5′ region (Additional file  1: Fig \nS1). Remarkably, by applying Modisco clustering [32] on all nucleotides weighted by \ntheir information content as computed by our LMs, we were able to recover some of \nPage 6 of 21Karollus et al. Genome Biology           (2024) 25:83 \nthese motifs de novo (Fig. 2B, Additional file 1: Fig S2). This approach seems to recover a \nsimilar number of known motifs as STREME [33], a dedicated motif-finding tool (Addi -\ntional file 1: Motif Discovery), although developing a general-purpose motif-finder based \non the LM was out of the scope of this paper.\nFor many motifs we tested, the species-aware language models reconstructed slightly \nbetter than their already strong agnostic counterparts. In sum, our analysis clearly \ndemonstrates that language models trained on a large compendium of highly diverged \ngenomes are (1) able to learn conserved regulatory elements and (2) able to transfer this \nknowledge to unseen species.\nContext‑sensitive reconstruction of motifs is predictive of in vivo binding\nIt has been shown for many genomes that only a fraction of the instances of a particu -\nlar motif is functional, i.e., binds the respective protein in vivo [35–37]. This is because, \nFig. 2 Language models reconstruct likely regulatory sequences in a held-out species and recover known \nbinding motifs. A Reconstruction accuracy for nucleotides within instances of RNA-binding protein \nconsensus motifs and across all nucleotides in S. cerevisiae 3′ UTR sequences (those longer than 300 bp \nhave been truncated). We compare the agnostic and species 3′ LM to a variety of baselines. The dashed \nline represents the accuracy achieved by the intra-genus alignment. Star indicates that the species LM \nsignificantly (P < 0.05, binomial test) outperforms the best baseline. For Puf3 and Whi3, Modisco clustering \non the species LM reconstructions recovers the motif (depicted above the respective plots). B A sample \nof known transcription factor motifs recovered by applying Modisco clustering to the 5′ species LM \nreconstructions, (manually) matched to the respective high-confidence PWM from the YeTFaSCo [34] \ndatabase\nPage 7 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \namong other reasons, binding also depends on the context of the motif. Therefore, we \nnext sought to evaluate whether our models can recognize these relationships.\nAn important piece of context for many motifs is their position with respect to certain \ngenomic landmarks. One example of this is that RBP motifs can only be functional if \nthey are located in a transcribed region. Another example is that in yeast TF binding \nsites tend to be located relatively close to the transcription start site (TSS) [38]. As a first \ntest of whether our LMs are capable of locating these genomic landmarks—despite their \nlocation not having been indicated during training—we computed the actual and pre -\ndicted nucleotide biases as a function of the distance to the TSS (imputed using CAGE \ndata [39]) and the distance to the end of the 3′ UTR [30]. In both cases, we observed that \nthe LMs track local changes in nucleotide biases (Fig. 3A, Additional file 1: Fig S3).\nTo explicitly test whether the 3′ LM locates and accounts for genomic landmarks when \nreconstructing motifs, we compared the reconstruction of instances of the Puf3 consen -\nsus motif located within annotated 3′ UTR regions to those that are located beyond the \n3′ UTR yet still within 300 bp of the stop codon. We find that motif instances within the \nannotated 3′ UTR are reconstructed significantly better (Fig.  3B–C), consistent with the \nfunction of RBPs. In contrast, the phastCons [40] score, an alignment-based measure of \nconservation, appeared to be a poor predictor of whether a Puf3 site is within a 3′ UTR \nor not. We repeated this analysis for the other 3′ UTR motifs, finding similar results \n(Additional file 1: Fig S4A, B). For a TF, we expected this relationship to be reversed, and \nindeed the E-box motif was reconstructed better when found outside of 3′ UTR regions \n(Additional file 1: Fig S4C).\nHaving shown that the models did not simply learn a mere lexicon of over-represented \nmotifs, but instead seemed to account for the context in which motif instances occur, we \nnext asked whether the reconstruction fidelity could predict whether a motif is bound \nin vivo. To this end, we compared the reconstruction of Puf3 motif instances located in \n3′ of genes that have been experimentally verified to bind Puf3p [41] to those without \nverified binding. Strikingly, we found that the reconstruction fidelity serves as a predic -\ntor of whether a gene containing a Puf3 consensus motif is bound by Puf3p—despite our \nmodels never having been exposed to binding data (Additional file 1: Fig S5).\nWe repeated a similar analysis for Tbf1 (Fig.  3D) and a variety of other transcription \nfactors (Additional file  1: Fig S6, S7). Specifically, we evaluated the reconstruction of \nthe consensus binding motifs of these TFs as a function of their distance to the closest \nupstream TSS. We observed that reconstruction improved when the motifs were located \nat a biologically plausible distance [38] from the TSS. Moreover, the reconstruction fidel-\nity is highly predictive of in vivo binding to motif instances as measured by Chip-Exo \n[42], outperforming the phastCons score and, in some cases, expert-curated PWMs con-\nstructed using binding data (Fig. 3E, Additional file 1: Fig S6, S7) [34].\nDistinct motifs have been established to exhibit associations with specific groups \nof co-regulated genes. An example in S. cerevisiae is the Rap1 motif, which is found \nprimarily in the promoters of ribosomal protein genes [43, 44]. Accordingly, we find \nthat instances of the Rap1 consensus motifs tend to be better reconstructed if they are \nfound within 1 kb 5′  of a ribosomal protein gene (Additional file  1: Fig S8A). In other \nwords, the reconstruction of the Rap1 motif serves as an indirect predictor of whether \na gene belongs to the ribosomal protein module. We performed a similar analysis for \nPage 8 of 21Karollus et al. Genome Biology           (2024) 25:83 \nthe RRPE motif, which is primarily found near genes involved in ribosome biogenesis, \nand obtained similar results (Additional file 1 : Fig S8B).\nOverall, this analysis demonstrates that LMs do not just learn a lexicon of conserved \nmotifs, but additionally pick up on correlations between the motifs and their context \nFig. 3 Reconstruction of motifs depends on the context and predicts whether a motif instance will be \nbound in vivo. A Actual and predicted (by the 5′ species LM) nucleotide biases as a function of the distance \nto the TSS (imputed using CAGE data). The model keeps track of local variations in nucleotide biases. B \nReconstruction fidelity (log-likelihood of the individual observed nucleotides, averaged per motif instance, \naccording to the 3′ species LM) of instances of the Puf3 motif (TGT AAA TA), as a function of the distance to \nthe end of the annotated 3′ UTR. The predictions of the model for masked nucleotides are indicated for \ntwo instances of the motif (blue circles). Reconstruction fidelity is notably degraded beyond the 3′ UTR \nend (P = 2.2 ×  10−15, Mann–Whitney U). C ROC curve evaluating to what extent the reconstruction fidelity \nof our 3′ LMs, as well as the phastCons conservation score, can serve as a predictor of whether a Puf3 motif \ninstance is within or beyond the 3′ UTR boundary. The LMs greatly outperform the conservation score. \nD Reconstruction fidelity (log-likelihood of the observed nucleotides according to the 5′ species LM) of \ninstances of the Tbf1 consensus motif (ARC CCT A), as a function of the distance to the closest 3′ TSS (imputed \nusing CAGE data). Blue indicates that the motif instance was bound in vivo according to Chip-exo data. Motif \ninstances that are around − 100 to − 250 nt to the TSS are better reconstructed than those further away or \nin the 5′ UTR (P = 1.2 ×  10−11, Mann–Whitney U). E ROC curve evaluating to what extent the reconstruction \nfidelity of our 5′ LMs, as well as the phastCons conservation score and an expert-curated PWM, can serve as a \npredictor of whether a Tbf1 motif instance is bound in vivo. The LMs again greatly outperform the alternative \nmethods\nPage 9 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \nwhich are predictive of whether motif instances are bound in  vivo. Notably, this is \nachieved purely from genomic sequences without requiring any additional experi -\nmental data during training. This suggests that the attention mechanism provides an \neffective way to integrate motif interactions, although determining which exact inter -\nactions are learned is difficult to disentangle. Finally, the ability to outperform the \nphastCons conservation score shows the advantages of an alignment-free approach.\nLanguage models account for changes in the regulatory code between species\nOur previous analyses have focused on the held-out species S. cerevisiae. However, one \nof the main use cases we envision for genomic LMs is to serve as a method to explore \nunderstudied species. We thus analyzed how the LMs perform when evaluated across \nfungal species.\nIn Fig.  1B, we showed that the Puf3 motif, but not its location, is conserved in the 3′ \nregions of CBP3 homologs. We applied our 3′ model to these sequences and found that, \nin most species, the Puf3 motif tends to be well reconstructed compared to the back -\nground (Fig. 4A). We next applied Modisco clustering to the predictions of the model on \nthe 3′ regions of all CBP3 homologs in our dataset. We recovered the Puf3 motif, as well \nas two versions of the Puf4 motif (Additional file  1: Fig S9A) [45]. This indicates that our \nmethod allows motif discovery not just across genes in one organism, but also for indi -\nvidual genes across organisms.\nOver evolutionary timescales, certain motifs may either change drastically or fully \ndisappear, particularly if the binding protein evolves or is lost. As an example, we con -\nsidered Rap1p, a conserved protein known to control telomere length [46]. However, as \nnoted previously, Rap1p additionally acts as a regulator of ribosomal protein expression \nin certain parts of the yeast lineage, a change that is associated with the acquisition of \na transactivation domain by Rap1p [44]. To determine whether our models can reflect \nsuch changes, we analyzed the reconstruction of the S. cerevisiae Rap1 motif in 60 fun -\ngal species. Specifically, we computed for each species the difference in reconstruction \nof instances of the consensus motif and instances that correspond to shuffled versions \nthereof. This procedure controls for GC content and general differences in reconstruc -\ntion fidelity between species. We found that in species close to S. cerevisiae, the motif \ninstances are reconstructed significantly better than the shuffled instances (Fig.  4B). By \ncontrast, in species where we cannot find a significant BLAST match to S. cerevisiae \nRap1p we observed no such enrichment. An example of this is Y. lipolytica, a species \nknown to not have a Rap1p homolog [47]. We performed a similar analysis for two other \nmotifs, finding consistent results (Additional file 1: Fig S9B–C).\nIn addition to motif evolution, the proper context of motifs can change as well. A \nfamous example is the positional constraint of the TATA box. In most eukaryotes includ-\ning the Schizosaccharomyces yeasts, the TATA box is preferentially located about 30 bp \n5′ from the TSS [29]. Budding yeasts, however, use a scanning mechanism to initiate \ntranscription and therefore the position of the TATA box in these species is more flex -\nible, but usually located between 50 and 120 bp 5′ from the TSS [29]. To verify whether \nour model correctly recapitulates these constraints, we located all instances of TAT AWA \nWR in the respective species. We then assessed how well the model reconstructs these \nnucleotides as a function of the distance to the closest upstream TSS [39]. We found \nPage 10 of 21Karollus et al. Genome Biology           (2024) 25:83 \nthat in S. pombe, reconstruction fidelity of the TATA box notably peaks around 30 bp \n5′ to the TSS, whereas instances located further or beyond the TSS are generally recon -\nstructed poorly (Fig.  4C). In S. cerevisiae, on the other hand, TATA boxes were gener -\nally well reconstructed (likely also reflecting the AT-bias of the budding yeasts), but we \nobserved a peak in the region 120 to 50 bp 5′ of the TSS. Thus, the model applies spe -\ncific constraints when reconstructing motifs in a way that reflects the evolution of the \ninitiation code.\nOne feature of the species LM is that it learns a representation for each species in the \ntraining dataset. To explore what information is contained in this representation, we first \nperformed PCA analysis on the species representations of the 5′ species LM. We found \nFig. 4 LMs can trace the movement and disappearance of motifs across species and they account for the \nevolution of the transcription initiation mechanism. A We applied the 3′ species LM to the 3′ region of CBP3 \nhomologs in a number of fungal species (compare Fig. 1A). Darker color indicates that the model assigns \na higher probability to the correct nucleotide at that position. In most species, the Puf3 motif instance \n(delineated with black bars) is notably reconstructed better than the remaining nucleotides. Star indicates \nthat this difference in reconstruction is significant (P < 0.05, Mann–Whitney U). Species with gray background \nwere held out during LM training. B We computed the reconstruction fidelity (log-likelihood) achieved by \nthe species 5′ LM for the S. cerevisiae consensus Rap1 motif (CAY CCR TACAY) instances and for instances \nmatching shuffled versions of this motif in 60 fungal species. The difference in reconstruction between the \ntrue and shuffled motif instances, expressed as  log2 fold change, is plotted against the −  log10 P-value of this \ndifference, computed using a Mann–Whitney U test. We observe that in species that have no BLAST match \nto S. cerevisiae Rap1p, the reconstruction fidelity of the S. cerevisiae Rap1 motif is generally not much better \nthan that of shuffled versions thereof, indicating that the model correctly accounts for species context when \nreconstructing motifs. C Reconstruction fidelity (log-likelihood of the observed nucleotides according to \nthe 5′ Species LM) of instances of the TATA-box (TAT AWA WR), as a function of the distance to the closest 3′ \nTSS (imputed using CAGE data). Positive values indicate that the TATA-box instance is located in the 5′ UTR. \nWe observe that in S. pombe, the TATA-box is best reconstructed when located ca. − 30 bp to the TSS. In S. \ncerevisiae, which uses a scanning mechanism to initiate transcription and therefore allows more flexible \npositioning of the TATA, the model reconstructs TATA well overall, but somewhat better when located 50 to \n120 bp 5′ from the TSS\nPage 11 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \nthat the first principal component, which explains about 10% of variance, is highly cor -\nrelated with GC content of the respective species (r =  − 0.86, Additional file 1: Fig S10). \nNext, we found that species of the same taxonomic class tend to be closer together than \nthose of different classes (Additional file 1: Fig S11, S12). This suggests that the represen-\ntations encode features that at least partially correspond to the fungal taxonomy.\nNext, we investigated whether changes in motif preferences are also captured by the \nspecies representation. To this end, we considered the previously characterized differ -\nential preferences of TF motifs in nucleosome-depleted regions between S. cerevisiae \nand C. albicans [48, 49]. Specifically, S. cerevisiae nucleosome depletion was associated \nwith the Reb1 motif, whereas in C. albicans it was associated with the k-mer aCAC  GAC \nc (“Tsankov” motif here and elsewhere)—which to our knowledge is not known to have \nany role in S. cerevisiae. We compared how the reconstruction accuracy achieved by \nthe 5′ species LM for these motifs is affected by swapping the species token. We find \nthat with our S. cerevisiae proxy token (K. africana), the species LM reconstructed Reb1 \ninstances better, both in S. cerevisiae and C. albicans 5′ regions (Additional file  1: Fig \nS13). Conversely, with the C. albicans token, the C. albicans-specific Tsankov motif is \nreconstructed better in both species.\nIn conclusion, we find considerable evidence that LMs can account for changes in the \nregulatory code and learn meaningful motif-context relationships in a species-specific \nmanner.\nSpecies‑aware language model representations encode biologically meaningful features \nand are directly predictive of many molecular phenotypes\nWhile our previous analyses demonstrated that the reconstructions of any LM are \nalready very informative and could potentially be used to explore regulation in under -\nstudied species, we can also extract the learned sequence representations and leverage \nthem to predict gene-expression-related traits in a supervised fashion. We note that this \nmakes most sense for tasks that are data-constrained, such as gene-level measures of \nexpression or half-life where there can only be as many data points as there are unique \ngenes/transcripts. Accordingly, to test the predictive power of the representations them-\nselves, we selected several gene-level omics assays, including RNA half-life measure -\nments in S. cerevisiae and S. pombe, RNA-seq-based gene expression in S. cerevisiae and \nmicroarray measures of condition-specific gene expression for a number of yeast species \n[50–54]. We additionally included three reporter assays testing 3′ sequences [55, 56] and \npromoter sequences in isolation [57].\nWe then used our masked language models to generate sequence representations for \nthe different sequences assayed in the respective experiments (Methods). We trained \nlinear models in cross-validation using LM representations as input for different tasks. \nWe used linear models specifically to ensure that the predictive power derives mostly \nfrom the LM and not from a fine-tuning procedure or a heavily engineered nonlinear \nfitting with many tunable hyperparameters. As a baseline for what can be achieved using \n“naive” sequence representations, we also trained linear models on k-mer counts. Fur -\nthermore, if available, we compared against state of the art.\nWe found that LM sequence representations outperform simple sequence representa -\ntions based on k-mer counts across all tasks, a finding consistent with previous work \nPage 12 of 21Karollus et al. Genome Biology           (2024) 25:83 \n[16]. Remarkably, the species LM performed best on all tasks (Fig.  5A, Additional file  1: \nTable S1). On a task where most of the signal comes from the coding sequence, it per -\nformed on par (better, but not significantly) with expert hand-crafted features (Cheng \net al. [50]) to predict mRNA half-life. Furthermore, simple ridge regressions trained on \nspecies-aware representations significantly outperformed hyperparameter-optimized \ndeep neural networks (Zrimec et al. [53]) on gene expression prediction from non-cod -\ning sequence. This clearly shows that species LMs learn sequence representations rich in \ninformation without requiring labeled data.\nOne of the datasets we considered, the Shalem et  al. 3′ MPRA [55], used a tiled \nmutagenesis design to measure the effect of individual subsequences of native 3′ \nsequences on expression. Here, the species LM performs extremely well, outperform -\ning the agnostic model by 20 percentage points of explained variation (Fig.  5B, C). The \nresults of this controlled experiment demonstrate that supervised models trained on \nspecies-LM sequence representations can capture causal determinants of expression \nfound in 3′ UTR sequences.\nWhile LM representations prove advantageous on species included in the dataset (S. \npombe), we emphasize that they generalize to unseen species (S. cerevisiae). To ensure \nthat LM performance is independent of dataset composition, and to ascertain that \nFig. 5 Sequence representations of the species LM outperform other methods on a variety of downstream \ntasks. A Performance (R2) of linear models trained on embeddings from language models compared to \nstate-of-the-art models and k-mer count regressions, where the best k from {3, 4, 5} is shown. Star indicates \nthat the Species LM significantly (P < 0.05) outperforms the second best. B Effect of mutation of 3′ sequences \non expression. Observed  log2 fold changes, as measured in Shalem et al. [55] are well predicted by the \nspecies LM representation. C Observed and predicted effects of mutation on expression as a function of \ndistance to the stop codon for the YDR131C 3′ sequence. D Motifs recovered through in-silico mutagenesis \nfollowed by Modisco clustering on our linear model for the S. cerevisiae half-life task. Motifs with a negative \neffect on half-life are depicted upside down. We recover (2 of 4) motifs found by Cheng et al. [50]: the Puf3 \nmotif and the Whi3 motif. Additionally, we find two motifs not found by this previous analysis, the Puf4 motif \nand the efficiency element, both of which have known effects on RNA stability\nPage 13 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \ntraining on more species is beneficial, we repeated these analyses using different models \npre-trained on different sets of species. We found that for all tasks, training on more \nspecies in a species-aware fashion led to better predictions (Additional file 1: Table S2).\nHowever, in genomics, models are often used not primarily for prediction but rather \nas a method to discover motifs or mechanisms in large datasets. To verify that super -\nvised learning models trained on LM sequence representations are suitable for motif \ndiscovery, we applied a standard model interpretation workflow (in-silico mutagenesis, \nfollowed by Modisco clustering, Methods) to the S. cerevisiae mRNA half-life data. In \nthis way, we recovered two out of the four motifs originally found by Cheng et al. [50]: \nthe Puf3 and the Whi3 motif—both of which our model correctly predicts as being \ndestabilizing (Fig.  5D). We additionally found one more destabilizing element, namely \nthe Puf4 motif [58] and one stabilizing element, the efficiency motif, which was shown to \nhave large positive effects on expression in the Shalem mutagenesis reporter assay [55]—\nwhere we also recovered this motif using the same technique. In sum, applying stand -\nard interpretation techniques with minimal manual tuning to our embedding-based \napproach yielded biologically meaningful sequence features.\nDiscussion\nIn this study, we trained language models on the genomes of hundreds of fungal species, \nspanning more than 500 million years of evolution. We specifically directed our atten -\ntion to non-coding regions, examining the  ability of the models to acquire meaningful \nspecies-specific and shared regulatory attributes when trained on the genomes of many \nspecies. To our knowledge, we are the first to show that LMs are able to transfer these \nattributes to unseen species.\nThrough analysis of the masked nucleotide reconstructions provided by the models, \nwe have demonstrated that they not only can preferentially reconstruct motifs, but they \ndo so in a way that is sensitive to context. As a result, the reconstruction fidelity can \nserve as a predictor of whether a particular instance of a consensus motif will be bound \nin vivo. This suggests that these models could be used to discover candidate high-affinity \nregulatory elements in species where no binding data is available.\nWe have further illustrated that the models better reconstruct RBP binding sites if they \nare located within annotated 3′ UTRs and exhibit improved reconstruction of TATA-\nbox instances if they are placed at a distance to the TSS that is appropriate for the given \nspecies. This is remarkable, as we indicated neither the TSS site nor the polyadenyla -\ntion site during training. This suggests that the models can infer the location of these \ngenomic landmarks. Consequently, LMs may prove useful for accurate genome annota -\ntion of understudied species.\nAltogether, these analyses further indicate that the reconstruction of masked nucle -\notides, rather than just a means to an end, can be very informative by itself. We have \nfocused on verifying that the models capture known features of the regulatory code, but \nsimilar techniques could potentially reveal novel associations between regulatory ele -\nments and their context.\nAdditionally, we have shown that providing species information to DNA LMs greatly \nimproves their internal numerical representations of regulatory sequences. Strik -\ningly, these representations, when used as input for simple linear models, achieve \nPage 14 of 21Karollus et al. Genome Biology           (2024) 25:83 \nstate-of-the-art predictive accuracy on a wide variety of tasks such as prediction of RNA \nabundance, condition-specific RNA expression, or mRNA half-life. We note that this \napproach requires neither retraining the whole model nor engineering a complex non -\nlinear downstream predictor. Despite its simplicity, we show that this procedure never -\ntheless recovers biologically meaningful motifs. Thus, LMs do not only learn predictive \nsequence representations but can also serve as a tool for biological discovery. As spe -\ncies awareness provides significant improvements at practically no cost (one additional \ntoken), we think that integrating a species representation will be useful for almost all \nDNA LMs. Perhaps, a similar strategy could be used to make the model aware of gene \nfamilies or functions, by providing a token that indicates orthologues or contains some \nother representation of the gene. This could help the model to learn conserved gene-\nspecific or pathway-specific motifs. However, requiring a gene token would hinder \napplications on synthetic assays, reporter genes, or genes with few homologs (e.g., many \nlncRNAs in humans).\nThis notwithstanding, the language modeling approach does have two important \ndrawbacks. Firstly, it is computationally costly, particularly for longer sequence contexts. \nWe initially experimented with state space models [59, 60], which scaled better to longer \nsequences. However, we ultimately adopted the standard DNABERT transformer archi -\ntecture for simplicity, as our main goal was to explore the suitability of language models \nfor multi-species modeling rather than a comprehensive evaluation of model architec -\ntures. Scaling language models to mammals with long-range regulatory interactions \nwhile maintaining single nucleotide resolution will require architectural improvements \n[61].\nWhile we showed that LMs generalize across highly diverged species, our analysis \nfocused on a single kingdom. Therfore, it falls short of demonstrating that training on \nthe entire eukaryotic tree of life—from protists to blue whales—could further improve \nlanguage models. It is conceivable that at a certain point regulatory mechanisms diverge \nso fundamentally that proper generalization is no longer possible. Additionally, massive \ndifferences in genome size may require careful dataset curation. On the other hand, we \ndid not evaluate whether LMs would benefit from large collections of very similar spe -\ncies, such as the recently released 233 primate genomes [6]. Lastly, we also must note \nthat most existing genome collections do not represent a random sample of the true \nphylogeny but tend to oversample species with medical or biotechnological relevance \nwhile undersampling non-western species and those that are hard to isolate [62]. Sys -\ntematically studying how dataset composition influences what the model learns and how \nwell it performs in different target species is an important avenue for future work.\nMaterials and methods\nGenome data\nWe obtained 1,500 fungal genomes, comprising 806 different species, from the Ensembl \nfungi 53 database [63]. For each annotated protein-coding gene in each genome, \nwe extracted 300 base pairs 3′ to the stop codon of genes and 1,000 bases 5′ to the \nstart codon. While the actual transcribed 3′ untranslated regions (3′ UTR) vary in \nlength, we expect that in most cases 300  bp will be sufficient to include the entire 3′ \nUTR [30]. Equally, in most species, 1 kb should be sufficient to cover the 5′ UTR and \nPage 15 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \npromoter—and scaling beyond this length becomes computationally infeasible for the \nmodeling approach taken here. Overall our train set included in the order of 13 million \nsequences, meaning that the 3′ models are trained on 3.9 billion nucleotides, whereas \nthe 5′ models were trained on 13 billion nucleotides.\nAs a test set, we used the widely studied species Saccharomyces cerevisiae. To prevent \ndata leakage from closely related species, the train set excludes the entire Saccharomyces \ngenus.\nSequence alignment\nSequence alignment of annotated Saccharomyces cerevisiae CDS and 3′ UTR sequences \nwas performed using discontiguous megablast, which was specifically designed for \ncross-species alignment, version 2.13 with default parameters [64]. Sequence alignment \nfor S. cerevisiae proteins was performed using tBlastn, with default parameters.\nMasked language modeling\nWe performed masked language modeling on the fungi 3′ and 5′ regions. Specifically, \nwe randomly masked nucleotides in each sequence and trained DNABERT models [14] \nto reconstruct these from context, so as to minimize cross-entropy.\nFor DNABERT, nucleotides were tokenized into overlapping six-mers before being \npassed to the model. In this context, we mask spans of overlapping 6-mers so that 80% of \nthe nucleotides selected for masking were masked, 10% percent were randomly mutated, \nand the remaining 10% were left unchanged. This choice of masking strategy is based \non the empirical investigations performed in the original BERT paper for natural lan -\nguage [13]. The model consists of 12 transformer encoder blocks and has around 90 M \nparameters. We employed Flash-attention [65] as a fast exact attention implementation. \nModels were trained for 200,000 steps using a batch size of 2048 using the Adam opti -\nmizer [66]. The learning rate was warmed up to  4x10-4 during the first 10,000 steps and \nthen linearly decayed to 0 until training terminates. We increased the masking ratio after \n100,000 steps from 15 to 20%. Note that these hyperparameters are the same as those \nused in the DNABERT paper.\nTo make the model species aware, the species label corresponding to each region was \nprovided as an additional input token and prepended to the sequence. At the beginning \nof training the species token embedding was randomly initialized and learned during \ntraining. For purposes of comparison, we also trained a species-agnostic version of the \nmodel, which does not receive the species label.\nAs the test species was held out from the training set, the species LM could not be \nprovided with the matching species token. To allow it to predict anyway, we provided \nthe model with a proxy species token of a closely related species. For the 3′ species LM, \nwe used C. glabrata, for the 5′ species LM we used K. africana for all analyses. An expla-\nnation of why these proxies were selected and a detailed investigation of the impact of \nthe choice of proxy can be found in Supplementary Material—Species Token Choice.\nWe trained ablations of the 3′ models where we varied the dataset composition. The \nsubstantial computational cost of training the model prevented us from exploring more \n5′ models.\nPage 16 of 21Karollus et al. Genome Biology           (2024) 25:83 \nNucleotide reconstruction\nWe computed reconstruction predictions for each position in the 3′ and 5′ sequences of \nthe test species S. cerevisiae using the respective species and agnostic LMs. For this, we \nmasked each nucleotide individually by masking the span of six overlapping 6-mers that \ncontains this nucleotide. We then averaged the prediction for this nucleotide over the \noverlapping 6-mers, to obtain one probability distribution per position.\nTo fit the k-mer-models, we tabulated the frequencies of nucleotides conditional on \nthe identity of the (k-1)/2 flanking nucleotides, where k is an odd number in {7,…,13} \nacross our training dataset. To reconstruct masked nucleotides, we extracted the (k-1)/2 \nflanking nucleotides on either side of this masked position and then calculated the prob-\nability of each nucleotide accordingly.\nTo reconstruct using alignment, we first downloaded the seven yeast alignment [40] \nand found the aligned position in the other species for each position in S. cerevisiae. We \nthen computed the frequency over the nucleotides in the aligned positions to obtain a \ndistribution. For the far-alignment we used the species N. castellii and L. kluyveri. For \nthe intra-genus alignment, we used the Saccharomyces species.\nTo evaluate reconstruction for a particular motif, we used regex search to find posi -\ntions in the 3′ or 5′ sequences matching the motif consensus. We allowed overlapping \nmatches. When 5′ sequences overlap (which can occur, as they are 1  kb long), we do \nnot double count matches, but instead keep only the match in the sequence where it is \nlocated closest to the upstream gene.\nMany consensus motifs we used in our analyses have degenerate positions. When we \ncomputed metrics such as reconstruction accuracy or log-likelihood on these motifs, \nwe only take into account the non-degenerate positions, as otherwise the metrics are \ninflated.\nFor all analyses where we use reconstruction fidelity to predict some kind of out -\ncome, including whether the motif is in the 3′ UTR, whether it is bound and whether \nit is reconstructed better than a shuffled version, we always use the reconstruction log-\nlikelihood (this is the log-likelihood of each nucleotide, averaged over nucleotides in the \nmotif) as the metric. This is mainly because accuracy, while easier to interpret, is also \nmore likely to produce ties.\n3′ UTR and TSS annotations\nWe extracted 3′ UTR annotations for S. cerevisiae from Cheng et al. [50], who derived \nthem from Pelechano et al. [30], and matched them to the 3′ sequences. Note that these \nannotations were only available for 4,388 genes.\nTo get TSS annotations, we gathered the consensus CAGE clusters for S. cerevisiae in \nYPD from YeastTSS [39]. We matched the locations of these consensus TSS sites with \nthe 5′ sequences. We then matched motif instances to their closest 3′ TSS (or to the \nclosest 5′ TSS site, if there was no 3′ TSS site between the motif and the start codon of \nthe gene).\nBinding data\nTo test whether the reconstruction fidelity is predictive of Puf3 binding, we collected all \ninstances of the Puf3 consensus motifs 3′ (i.e., within 300 bp 3′ of the stop codon) of S. \nPage 17 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \ncerevisiae genes. We considered as a positive set all instances of the Puf3 motif in genes \nwith experimental evidence of Puf3p binding their 3′ UTR [41]. We resorted to this as \nthe data does not indicate the exact binding site, just that the 3′ UTR was bound. The \nnegative set comprised the remaining instances. We then computed the reconstruction \nlog-likelihood for all motifs of interest. PhastCons conservation scores [40] for S. cerevi -\nsiae were downloaded from UCSC and extracted for regions of interest.\nFor transcription factors, we matched instances of the consensus motif with Chip-exo \npeaks [42]. Specifically, the data indicates the center of Chip-exo peaks. We extend this \nby 10 bp to either side and consider that an instance of the motif was bound if it over -\nlapped the extended peak.\nDownstream tasks\nTo evaluate the predictiveness of LM sequence representations, we considered the fol -\nlowing tasks. Sun et  al. [51] measured half-life for 4,388 S. cerevisiae mRNAs using \nnonperturbing metabolic RNA labeling. Cheng et al. [50] used this data to build a quan -\ntitative model to predict mRNA half-life from sequence, using handcrafted features from \nthe coding sequence, 5′ and 3′ UTR—which to our knowledge is the state-of-the-art \nmodel of mRNA stability in yeast. Eser et al. [52] measured mRNA half-life in S. pombe. \nIn the Shalem et al. [55] MPRA, the expression of a fixed reporter gene was measured \nwhen combined with different 3′ sequences. These include genomic 3′ sequences as well \nas mutated versions of these sequences where mutations were performed in such a way \nas to tile the sequence. Zrimec et al. [53] aggregated over 20,000 RNA-Seq experiments \nand built a convolutional neural network to predict the variation in mRNA abundance \nbetween genes from sequence. To our knowledge, this represents the state-of-the-art \nmodel for predicting endogenous gene expression in S. cerevisiae. Zrimec et al. also con -\nsider two additional tasks to evaluate the generalization of their model, which we adopt. \nFirstly, Keren et al. [57] measured, using a fluorescence reporter assay, the expression of \na fixed reporter gene when combined with different endogenous S. cerevisiae promoter \nsequences. Yamanishi et al. [56] also used a fluorescence reporter assay to measure the \nimpact of different S. cerevisiae terminator sequences. Finally, to have data from non-\nmodel species, we obtain microarray data measuring condition-specific gene expression \nin different stages of growth for a number of yeast species [54].\nGenerating sequence representations and downstream predictions using linear models\nTo generate LM sequence representations, we pass each sequence to the language mod -\nels and extract the sequence representation of the last 4 layers for all tokens, which are \nthen mean pooled to obtain a single embedding per sequence as in Devlin et al. [13] As \nour models expect fixed length sequences, we truncated longer input sequences. We did \nthis in the following way: for the 3′ sequences, we truncate from the end, and for the 5′ \nsequences, we truncate from the start. If sequences were shorter than the input, for the \n3′ model, we feed them as is. For the 5′ model, we pad them from the left using a fixed \nsequence. We do this because the 5′ model expects the 1000th sequence position to be \nimmediately 5′ of the start codon.\nFor predicting half-life, we provided 5′  UTR and coding sequence (CDS) fea -\ntures, as described in Cheng et  al. [50] for S. cerevisiae and Eser et  al. [52] for S. \nPage 18 of 21Karollus et al. Genome Biology           (2024) 25:83 \npombe, in addition to our (or competing methods’) sequence representations of the \n3′ sequence to a ridge regression with the regularization parameter set by nested \ncross-validation. We performed 10-fold cross-validation to estimate generalization \nperformance.\nWe proceeded similarly for predicting reporter expression in the experiment of \nShalem et al. [55] but did not include any features besides the 3′  sequence represen -\ntation. However, as the reporter contains many almost-duplicate sequences that rep -\nresent mutations of the same endogenous sequence, we performed grouped 10-fold \ncross-validation, where the groups consisted of said endogenous sequences. This \nprevented trivial overfitting.\nZrimec et al. [53] trained different convolutional neural networks using different \nparts of the regulatory sequence as input. To mimic this, we trained separate lin -\near models for 3′  and 5′ as well as the combination thereof to predict gene expres -\nsion. Here, we do not perform cross-validation but use the same train test split as in \nZrimec et al. To predict expression driven by terminator and promoter sequences, \nZrimec et al. do not train new models but instead directly apply their convolutional \nneural network trained on endogenous gene expression. To be comparable, we \nequally transfer linear model weights to these tasks.\nFor the microarray, we embed 3′  and 5′ sequences for each species and train sep -\narate ridge regressions for each species and condition combination. We again use \n10-fold cross-validation to evaluate performance.\nTo assess statistical significance, we computed the residuals and for each task \nperformed a paired Wilcoxon test to determine if the residuals of the species LM \nwere significantly smaller than those of the next best-performing method. The only \nexception to this is the Zrimec et al. endogenous gene expression task. Here, we only \nhad access to the aggregate performance measures (R 2) of their models. Thus, we \nused bootstrapping to compute 95% confidence intervals for the performance of the \nSpecies LM and determined its performance to be significantly better than Zrimec \net al. if the confidence interval did not overlap their result.\nModisco clustering\nFor de novo motif discovery based on reconstruction probability only, we normal -\nized the reconstruction probability p  at each position: pnormalized = p ·log(p/pmean ) . \nWe then passed this to tfmodisco-lite (https:// github. com/ jmsch rei/ tfmod isco- lite) \nto obtain motifs.\nTo perform motif discovery on downstream tasks, we calculated embeddings and \npredictions for all possible single nucleotide polymorphisms of the original input \nsequences (in silico mutagenesis). Since ridge models were trained using cross-val -\nidation, we always selected the model which had the non-mutagenized sequence in \nits test fold to predict mutation effects for this sequence. Having collected all vari -\nant effects, we removed their mean at each position (to also associate an attribution \nscore to the reference nucleotide) and passed this to Modisco.\nFor every Modisco analysis, we set the sliding window size to 8, the flank size to 3, \nthe target seqlet FDR to 0.05, and the number of Leiden runs to 3.\nPage 19 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \nSTREME\nTo discover motifs in S. cerevisiae 3′ and 5′ regions with STREME, we used the \nwebinterface: https:// meme- suite. org/ meme/ tools/ streme. For 5′ regions, we used \ndefault parameters. For the 3′ regions, as here we mostly expect stranded RBP motifs, \nwe used the RNA mode which uses only one strand. Moreover, we set the minimum \nwidth to five nucleotides, to allow STREME to discover motifs such as Whi3.\nSupplementary Information\nThe online version contains supplementary material available at https:// doi. org/ 10. 1186/ s13059- 024- 03221-x.\nAdditional file 1. PDF containing supplementary figures and analyses cited in the main text.\nAdditional file 2. List of the specific datasets analyzed.\nAdditional file 3. Peer review history.\nAcknowledgements\nWe thank all the scientists who isolated, sequenced, and assembled the genome data which builds the basis for our \nresearch. Figure 1D was created with BioRe nder. com.\nReview history\nThe review history is available as Additional file 3.\nPeer review information\nTim Sands was the primary editor of this article and managed its editorial process and peer review in collaboration with \nthe rest of the editorial team.\nAuthors’ contributions\nJG and AK conceived the study. JG supervised the research. JH designed and trained the models used in the study. AK \nand JH designed the evaluations and analyzed the data. DG, MG, and KK explored prototype versions of the model and \nevaluations. AK, JH, and JG wrote the manuscript. All authors read and approved the final manuscript.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL. This study was funded by the German Bundesministerium \nfür Bildung und Forschung (BMBF) through the Model Exchange for Regulatory Genomics project MERGE (031L0174A \nto JG). The funders had no role in the study design, data collection, analysis, decision to publish, or preparation of the \nmanuscript.\nAvailability of data and materials\nThe code is available on https:// github. com/ gagne urlab/ Speci esLM   [67] under a MIT license.\nAll supporting data is available on Zenodo: https:// doi. org/ 10. 5281/ zenodo. 82471 34   [68].\nThe species and agnostic LMs are available on figshare: https:// doi. org/ 10. 6084/ m9. figsh are. 23732 655   [69].\nThe models are additionally available on Huggingface: https:// huggi ngface. co/ gagne urlab/ Speci esLM   [70].\nA list of all datasets analyzed in the study can be found in Additional file 2.\nDeclarations\nEthics approval and consent to participate\nNot applicable.\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare that they have no competing interests.\nReceived: 14 August 2023   Accepted: 20 March 2024\nReferences\n 1. Dunham I, Kundaje A, Aldred SF, Collins PJ, Davis CA, Doyle F, et al. An integrated encyclopedia of DNA elements in \nthe human genome. Nature. 2012;489:57–74.\n 2. Noguchi S, Arakawa T, Fukuda S, Furuno M, Hasegawa A, Hori F, et al. FANTOM5 CAGE profiles of human and mouse \nsamples. Sci Data. 2017;4:170112.\nPage 20 of 21Karollus et al. Genome Biology           (2024) 25:83 \n 3. Mora C, Tittensor DP , Adl S, Simpson AGB, Worm B. How many species are there on Earth and in the ocean? PLOS Biol. \n2011;9:e1001127.\n 4. Blaxter M, Archibald JM, Childers AK, Coddington JA, Crandall KA, Di Palma F, et al. Why sequence all eukaryotes? Proc \nNatl Acad Sci. 2022;119:e2115636118.\n 5. Rhie A, McCarthy SA, Fedrigo O, Damas J, Formenti G, Koren S, et al. Towards complete and error-free genome assem-\nblies of all vertebrate species. Nature. 2021;592:737–46.\n 6. Kuderna LFK, Gao H, Janiak MC, Kuhlwilm M, Orkin JD, Bataillon T, et al. A global catalog of whole-genome diversity from \n233 primate species. Science. 2023;380:906–13.\n 7. Osmanski AB, Paulat NS, Korstian J, Grimshaw JR, Halsey M, Sullivan KAM, et al. Insights into mammalian TE diversity \nthrough the curation of 248 genome assemblies. Science. 2023;380:eabn1430.\n 8. Zhang G, Li C, Li Q, Li B, Larkin DM, Lee C, et al. Comparative genomics reveals insights into avian genome evolution and \nadaptation. Science. 2014;346:1311–20.\n 9. Kellis M, Patterson N, Endrizzi M, Birren B, Lander ES. Sequencing and comparison of yeast species to identify genes and \nregulatory elements. Nature. 2003;423:241–54.\n 10. Kimura M. Evolutionary rate at the molecular level. Nature. 1968;217:624–6.\n 11. Weirauch MT, Hughes TR. Conserved expression without conserved regulatory sequence: the more things change, the \nmore they stay the same. Trends Genet. 2010;26:66–74.\n 12. Hare EE, Peterson BK, Iyer VN, Meier R, Eisen MB. Sepsid even-skipped enhancers are functionally conserved in Dros-\nophila despite lack of sequence conservation. PLOS Genet. 2008;4:e1000106.\n 13. Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language understand-\ning. arXiv; 2019. Available from: http:// arxiv. org/ abs/ 1810. 04805. Cited 2023 Jan 18.\n 14. Ji Y, Zhou Z, Liu H, Davuluri RV. DNABERT: pre-trained bidirectional encoder representations from transformers model for \nDNA-language in genome. Bioinformatics. 2021;37:2112–20.\n 15. Zhou Z, Ji Y, Li W, Dutta P , Davuluri R, Liu H. DNABERT-2: efficient foundation model and benchmark for multi-species \ngenome. arXiv; 2023. Available from: http:// arxiv. org/ abs/ 2306. 15006. Cited 2023 Jul 22.\n 16. Dalla-Torre H, Gonzalez L, Revilla JM, Carranza NL, Grzywaczewski AH, Oteri F, et al. The nucleotide transformer: building \nand evaluating robust foundation models for human genomics. bioRxiv; 2023. p. 2023.01.11.523679. Available from: \nhttps:// www. biorx iv. org/ conte nt/ 10. 1101/ 2023. 01. 11. 52367 9v1. Cited 2023 Jan 19.\n 17. Fishman V, Kuratov Y, Petrov M, Shmelev A, Shepelin D, Chekanov N, et al. GENA-LM: a family of open-source founda-\ntional models for long DNA sequences. bioRxiv; 2023. p. 2023.06.12.544594. Available from: https:// www. biorx iv. org/ \nconte nt/ 10. 1101/ 2023. 06. 12. 54459 4v1. Cited 2023 Jul 22.\n 18. Hedges SB, Dudley J, Kumar S. TimeTree: a public knowledge-base of divergence times among organisms. Bioinformat-\nics. 2006;22:2971–2.\n 19. Benegas G, Batra SS, Song YS. DNA language models are powerful zero-shot predictors of genome-wide variant effects. \nbioRxiv; 2023. p. 2022.08.22.504706. Available from: https:// www. biorx iv. org/ conte nt/ 10. 1101/ 2022. 08. 22. 50470 6v2. \nCited 2023 Jul 22.\n 20. Prieto M, Wedin M. Dating the diversification of the major lineages of Ascomycota (Fungi). PLoS One. 2013;8:e65576.\n 21. Wilinski D, Buter N, Klocko AD, Lapointe CP , Selker EU, Gasch AP , et al. Recurrent rewiring and emergence of RNA regula-\ntory networks. Proc Natl Acad Sci. 2017;114:E2816–25.\n 22. Tanay A. Extensive low-affinity transcriptional interactions in the yeast genome. Genome Res. 2006;16:962–72.\n 23. Ward LD, Bussemaker HJ. Predicting functional transcription factor binding through alignment-free and affinity-based \nanalysis of orthologous promoter sequences. Bioinformatics. 2008;24:i165–71.\n 24. Wolfertstetter F, Frech K, Herrmann G, Werner T. Identification of functional elements in unaligned nucleic acid \nsequences by a novel tuple search algorithm. Bioinformatics. 1996;12:71–80.\n 25. Elemento O, Tavazoie S. Fast and systematic genome-wide discovery of conserved regulatory elements using a non-\nalignment based approach. Genome Biol. 2005;6:R18.\n 26. Bussemaker HJ, Li H, Siggia ED. Building a dictionary for genomes: identification of presumptive regulatory sites by \nstatistical analysis. Proc Natl Acad Sci. 2000;97:10096–100.\n 27. Gordân R, Narlikar L, Hartemink AJ. Finding regulatory DNA motifs using alignment-free evolutionary conservation \ninformation. Nucleic Acids Res. 2010;38:e90.\n 28. Zielezinski A, Vinga S, Almeida J, Karlowski WM. Alignment-free sequence comparison: benefits, applications, and tools. \nGenome Biol. 2017;18:186.\n 29. Lu Z, Lin Z. The origin and evolution of a distinct mechanism of transcription initiation in yeasts. Genome Res. \n2021;31:51-63.\n 30. Pelechano V, Wei W, Steinmetz LM. Extensive transcriptional heterogeneity revealed by isoform profiling. Nature. \n2013;497:127–31.\n 31. Sahu B, Hartonen T, Pihlajamaa P , Wei B, Dave K, Zhu F, et al. Sequence determinants of human gene regulatory ele-\nments. Nat Genet. 2022;54:283–94.\n 32. Shrikumar A, Tian K, Avsec Ž, Shcherbina A, Banerjee A, Sharmin M, et al. Technical note on Transcription Factor Motif \nDiscovery from Importance Scores (TF-MoDISco) version 0.5.6.5. arXiv; 2020. Available from: http:// arxiv. org/ abs/ 1811. \n00416. Cited 2022 Sep 25.\n 33. Bailey TL. STREME: accurate and versatile sequence motif discovery. Bioinformatics. 2021;37:2834–40.\n 34. de Boer CG, Hughes TR. YeTFaSCo: a database of evaluated yeast transcription factor sequence specificities. Nucleic \nAcids Res. 2012;40:D169–79.\n 35. Yang A, Zhu Z, Kapranov P , McKeon F, Church GM, Gingeras TR, et al. Relationships between p63 binding, DNA \nsequence, transcription activity, and biological function in human cells. Mol Cell. 2006;24:593–602.\n 36. Rossi MJ, Lai WKM, Pugh BF. Genome-wide determinants of sequence-specific DNA binding of general regulatory fac-\ntors. Genome Res. 2018;28:497–508.\n 37. Gordân R, Shen N, Dror I, Zhou T, Horton J, Rohs R, et al. Genomic regions flanking E-box binding sites influence DNA \nbinding specificity of bHLH transcription factors through DNA shape. Cell Rep. 2013;3:1093–104.\nPage 21 of 21\nKarollus et al. Genome Biology           (2024) 25:83 \n \n 38. Erb I, van Nimwegen E. Transcription factor binding site positioning in yeast: proximal promoter motifs characterize \nTATA-less promoters. PLoS ONE. 2011;6:e24279.\n 39. McMillan J, Lu Z, Rodriguez JS, Ahn T-H, Lin Z. YeasTSS: an integrative web database of yeast transcription start sites. \nDatabase. 2019;2019:baz048.\n 40. Siepel A, Bejerano G, Pedersen JS, Hinrichs AS, Hou M, Rosenbloom K, et al. Evolutionarily conserved elements in verte-\nbrate, insect, worm, and yeast genomes. Genome Res. 2005;15:1034–50.\n 41. Lapointe CP , Stefely JA, Jochem A, Hutchins PD, Wilson GM, Kwiecien NW, et al. Multi-omics reveal specific targets of the \nRNA-binding protein Puf3p and its orchestration of mitochondrial biogenesis. Cell Syst. 2018;6:125–135.e6.\n 42. Rossi MJ, Kuntala PK, Lai WKM, Yamada N, Badjatia N, Mittal C, et al. A high-resolution protein architecture of the budding \nyeast genome. Nature. 2021;592:309–14.\n 43. Lieb JD, Liu X, Botstein D, Brown PO. Promoter-specific binding of Rap1 revealed by genome-wide maps of protein–\nDNA association. Nat Genet. 2001;28:327–34.\n 44. Tanay A, Regev A, Shamir R. Conservation and evolvability in regulatory networks: the evolution of ribosomal regulation \nin yeast. Proc Natl Acad Sci. 2005;102:7203–8.\n 45. Hogan GJ, Brown PO, Herschlag D. Evolutionary conservation and diversification of Puf RNA binding proteins and their \nmRNA targets. PLOS Biol. 2015;13:e1002307.\n 46. Li B, Oestreich S, de Lange T. Identification of human Rap1: implications for telomere evolution. Cell. 2000;101:471–83.\n 47. Kramara J, Willcox S, Gunisova S, Kinsky S, Nosek J, Griffith JD, et al. Tay1 protein, a novel telomere binding factor from \nYarrowia lipolytica*. J Biol Chem. 2010;285:38078–92.\n 48. Tsankov AM, Thompson DA, Socha A, Regev A, Rando OJ. The role of nucleosome positioning in the evolution of gene \nregulation. PLOS Biol. 2010;8:e1000414.\n 49. Tsankov A, Yanagisawa Y, Rhind N, Regev A, Rando OJ. Evolutionary divergence of intrinsic and trans-regulated nucleo-\nsome positioning sequences reveals plastic rules for chromatin organization. Genome Res. 2011;21:1851–62.\n 50. Cheng J, Maier KC, Avsec Ž, Rus P , Gagneur J. Cis-regulatory elements explain most of the mRNA stability variation across \ngenes in yeast. RNA. 2017;23:1648–59.\n 51. Sun M, Schwalb B, Pirkl N, Maier KC, Schenk A, Failmezger H, et al. Global analysis of eukaryotic mRNA degradation \nreveals Xrn1-dependent buffering of transcript levels. Mol Cell. 2013;52:52–62.\n 52. Eser P , Wachutka L, Maier KC, Demel C, Boroni M, Iyer S, et al. Determinants of RNA metabolism in the Schizosaccharo-\nmyces pombe genome. Mol Syst Biol. 2016;12:857.\n 53. Zrimec J, Börlin CS, Buric F, Muhammad AS, Chen R, Siewers V, et al. Deep learning suggests that gene expression is \nencoded in all parts of a co-evolving interacting gene regulatory structure. Nat Commun. 2020;11:6141.\n 54. Thompson DA, Roy S, Chan M, Styczynsky MP , Pfiffner J, French C, et al. Evolutionary principles of modular gene regula-\ntion in yeasts. Tautz D, editor. Elife. 2013;2:e00603.\n 55. Shalem O, Sharon E, Lubliner S, Regev I, Lotan-Pompan M, Yakhini Z, et al. Systematic dissection of the sequence deter-\nminants of gene 3’ end mediated expression control. PLOS Genet. 2015;11:e1005147.\n 56. Yamanishi M, Ito Y, Kintaka R, Imamura C, Katahira S, Ikeuchi A, et al. A genome-wide activity assessment of terminator \nregions in Saccharomyces cerevisiae provides a “terminatome” toolbox. ACS Synth Biol. 2013;2:337–47.\n 57. Keren L, Zackay O, Lotan-Pompan M, Barenholz U, Dekel E, Sasson V, et al. Promoters maintain their relative activity levels \nunder different growth conditions. Mol Syst Biol. 2013;9:701.\n 58. Fischer AD, Olivas WM. Multiple Puf proteins regulate the stability of ribosome biogenesis transcripts. RNA Biol. \n2018;15:1228–43.\n 59. Gu A, Johnson I, Goel K, Saab K, Dao T, Rudra A, et al. Combining recurrent, convolutional, and continuous-time models \nwith linear state-space layers. arXiv; 2021. Available from: http:// arxiv. org/ abs/ 2110. 13985. Cited 2023 Jan 18.\n 60. Gupta A, Gu A, Berant J. Diagonal state spaces are as effective as structured state spaces. arXiv; 2022. Available from: \nhttp:// arxiv. org/ abs/ 2203. 14343. Cited 2023 Jan 18.\n 61. Nguyen E, Poli M, Faizi M, Thomas A, Birch-Sykes C, Wornow M, et al. HyenaDNA: long-range genomic sequence mod-\neling at single nucleotide resolution. arXiv; 2023. Available from: http:// arxiv. org/ abs/ 2306. 15794. Cited 2023 Jul 22.\n 62. Marks RA, Hotaling S, Frandsen PB, VanBuren R. Representation and participation across 20 years of plant genome \nsequencing. Nat Plants. 2021;7:1571–8.\n 63. Cunningham F, Allen JE, Allen J, Alvarez-Jarreta J, Amode MR, Armean IM, et al. Ensembl 2022. Nucleic Acids Res. \n2022;50:D988–95.\n 64. Camacho C, Coulouris G, Avagyan V, Ma N, Papadopoulos J, Bealer K, et al. BLAST+: architecture and applications. BMC \nBioinformatics. 2009;10:421.\n 65. Dao T, Fu DY, Ermon S, Rudra A, Ré C. FlashAttention: fast and memory-efficient exact attention with IO-awareness. arXiv; \n2022. Available from: http:// arxiv. org/ abs/ 2205. 14135. Cited 2023 Jul 22.\n 66. Kingma DP , Ba J. Adam: a method for stochastic optimization. arXiv; 2017. Available from: http:// arxiv. org/ abs/ 1412. 6980. \nCited 2023 Jul 22.\n 67. Karollus A, Hingerl J, Gankin D, Grosshauser M, Klemon K, Gagneur J. gagneurlab/SpeciesLM. 2023. Available from: \nhttps:// github. com/ gagne urlab/ Speci esLM.\n 68. Karollus A, Hingerl J, Gankin D, Gagneur J. Supporting data for species-aware DNA language models. Zenodo; 2023. \nAvailable from: https:// zenodo. org/ recor ds/ 82471 34. Cited 2024 Mar 11.\n 69. Karollus A, Hingerl J, Gagneur J. Species and agnostic LM. figshare; 2023. Available from: https:// figsh are. com/ artic les/ \ncode/ Speci es_ and_ Agnos tic_ LM/ 23732 655/1. Cited 2024 Mar 11.\n 70. Karollus A, Hingerl J, Gagneur J. gagneurlab/SpeciesLM hugging face. Available from: https:// huggi ngface. co/ gagne \nurlab/ Speci esLM. Cited 2024 Mar 11.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
}