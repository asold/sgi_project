{
  "title": "ChatGPT sits the DFPH exam: large language model performance and potential to support public health learning",
  "url": "https://openalex.org/W4390751193",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4383324785",
      "name": "Nathan P Davies",
      "affiliations": [
        "Nottingham City Hospital",
        "University of Nottingham"
      ]
    },
    {
      "id": "https://openalex.org/A1532175135",
      "name": "Robert Wilson",
      "affiliations": [
        "NHS England",
        "Seat (Spain)"
      ]
    },
    {
      "id": "https://openalex.org/A4383324787",
      "name": "Madeleine S Winder",
      "affiliations": [
        "University of Nottingham",
        "Nottingham City Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5027953416",
      "name": "Simon J. Tunster",
      "affiliations": [
        "Nottingham City Hospital",
        "University of Nottingham"
      ]
    },
    {
      "id": "https://openalex.org/A2015614132",
      "name": "Kathryn McVicar",
      "affiliations": [
        "University of Nottingham",
        "Nottingham City Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2888502700",
      "name": "Shivan Thakrar",
      "affiliations": [
        "Leicester City Council"
      ]
    },
    {
      "id": "https://openalex.org/A2128032715",
      "name": "Joe Williams",
      "affiliations": [
        "University of Sheffield"
      ]
    },
    {
      "id": "https://openalex.org/A2111511536",
      "name": "Allan Reid",
      "affiliations": [
        "NHS England",
        "Seat (Spain)"
      ]
    },
    {
      "id": "https://openalex.org/A4383324785",
      "name": "Nathan P Davies",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1532175135",
      "name": "Robert Wilson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4383324787",
      "name": "Madeleine S Winder",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5027953416",
      "name": "Simon J. Tunster",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2015614132",
      "name": "Kathryn McVicar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2888502700",
      "name": "Shivan Thakrar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2128032715",
      "name": "Joe Williams",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111511536",
      "name": "Allan Reid",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4319304408",
    "https://openalex.org/W4366989525",
    "https://openalex.org/W2550008669",
    "https://openalex.org/W4288057965",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4368360859",
    "https://openalex.org/W4367048218",
    "https://openalex.org/W4379599615",
    "https://openalex.org/W4378229839",
    "https://openalex.org/W6925222479",
    "https://openalex.org/W2162821268",
    "https://openalex.org/W2042651776",
    "https://openalex.org/W4321351832",
    "https://openalex.org/W4372047097",
    "https://openalex.org/W4378211503"
  ],
  "abstract": null,
  "full_text": "RESEARCH Open Access\n© The Author(s) 2024. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, \nsharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and \nthe source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The \nCreative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available \nin this article, unless otherwise stated in a credit line to the data.\nDavies et al. BMC Medical Education           (2024) 24:57 \nhttps://doi.org/10.1186/s12909-024-05042-9\nBackground\nSeveral use cases for artificial intelligence (AI) have \nrecently been set out for medicine and life sciences [ 1]. \nChatGPT is an artificial intelligence (AI) chatbot that \nruns on OpenAI’s Generative Pre-Trained Transformer \n(GPT) models [ 2]. It is one of a growing number of pub -\nlicly available large language learning models (LLMs) that \nhave been trained on huge volumes of text, using both \nmachine learning and some human supervision, to help it \nrespond to users in a conversational manner. \nThere have been concerns raised about the potential \nfor LLMs to cause public health harm. This includes the \nBMC Medical Education\n*Correspondence:\nNathan P Davies\nNathan.davies@nottingham.ac.uk\n1Nottingham Centre for Public Health and Epidemiology, University of \nNottingham, Nottingham City Hospital, Hucknall Rd,  \nNottingham NG5 1PB, England\n2NHS England, Seaton House, City Link, London Road,  \nNottingham NG2 4LA, England\n3Leicester City Council, Public Health, 115 Charles Street,  \nLeicester LE1 1FZ, England\n4School of Health and Related Research (ScHARR), The University of \nSheffield, 30 Regent St, Sheffield S1 4DA, England\nAbstract\nBackground Artificial intelligence-based large language models, like ChatGPT, have been rapidly assessed for both \nrisks and potential in health-related assessment and learning. However, their applications in public health professional \nexams have not yet been studied. We evaluated the performance of ChatGPT in part of the Faculty of Public Health’s \nDiplomat exam (DFPH).\nMethods ChatGPT was provided with a bank of 119 publicly available DFPH question parts from past papers. \nIts performance was assessed by two active DFPH examiners. The degree of insight and level of understanding \napparently displayed by ChatGPT was also assessed.\nResults ChatGPT passed 3 of 4 papers, surpassing the current pass rate. It performed best on questions relating \nto research methods. Its answers had a high floor. Examiners identified ChatGPT answers with 73.6% accuracy and \nhuman answers with 28.6% accuracy. ChatGPT provided a mean of 3.6 unique insights per question and appeared to \ndemonstrate a required level of learning on 71.4% of occasions.\nConclusions Large language models have rapidly increasing potential as a learning tool in public health education. \nHowever, their factual fallibility and the difficulty of distinguishing their responses from that of humans pose potential \nthreats to teaching and learning.\nKeywords Public health, Examination, Artificial intelligence, Theory\nChatGPT sits the DFPH exam: large language \nmodel performance and potential to support \npublic health learning\nNathan P Davies1*, Robert Wilson2, Madeleine S Winder1, Simon J Tunster1, Kathryn McVicar1, Shivan Thakrar3, \nJoe Williams4 and Allan Reid2\nPage 2 of 6\nDavies et al. BMC Medical Education           (2024) 24:57 \npossibility that LLMs like ChatGPT risk creating info-\ndemics by generating vast amounts of plausible-sounding \nbut incorrect information in both the research and public \ninformation spheres [3]. Some, including the chief execu-\ntives of major AI companies, warn that general artificial \nintelligence poses serious public health threats compara -\nble to pandemics and nuclear war, as it has the potential \nfor biological weaponisation, generation of large-scale \nmisinformation, and strengthening the power of dictator-\nships [4]. AI can be considered as a commercial determi -\nnant of health: a set of private sector activities which have \na significant impact on health [ 5].  As with other tech -\nnologies [6], there may be a conflict between profit gen -\neration for AI companies and public health.\nAI and LLMs have generated significant interest in \nhealth education. ChatGPT has performed relatively \nwell on US medical [ 7, 8] and plastic surgery exams [ 9] \nalthough it performed less well on the UK BioMedi -\ncal Admissions Test [ 10] and the Taiwanese Pharmacist \nLicensing Examination [11]. It has been shown to provide \nevidence-based responses to help-seeking questions on \npublic health [ 12]. Its novel abilities have generated dis -\ncussions on its potential applications for medical teach -\ning and learning [13].\nPublic health exams often differ from biomedical \nexams. They are less likely to take multiple-choice or \npurely fact-based formats, requiring application of a \nbroad range of concepts to open-ended scenarios. One \nsuch example is the Diplomate exam (DFPH), set by the \nFaculty of Public Health (FPH) [ 14]. Passing this exam \nis mandatory for progressing in public health specialty \ntraining in the United Kingdom. The DFPH exam is split \ninto Paper 1 and Paper 2, sat sequentially. Paper 1 cov -\ners a broad range of topics, including research methods \nand epidemiology, screening, ethics, health promotion, \nhealth protection, sociology, leadership and manage -\nment, health economics, health informatics, and health -\ncare public health.\nWe aimed to evaluate the performance of ChatGPT \n3.5 in Paper 1 of the DFPH exam, including whether its \nanswers were distinguishable from human respondents, \nand to investigate the level of insight and degree of learn -\ning it appeared to display.\nMethods\nThe seven most recently available Paper 1s were selected \nfrom the Faculty of Public Health’s publicly available \nquestion bank (January 2014– January 2017). Paper 1 \nincorporates 10 questions that require short, medium \nand long-form responses. It is divided into 5 topic-based \nsections, each with 2 questions. Papers from pre-2014 \nwere excluded, as they comprise 10-mark essay-style \nquestions. These differ significantly from the current \nstyle of questions, which are always broken down into at \nleast two parts.\nTo generate responses from ChatGPT, each question \ncomponent was entered and formatted by the ques -\ntion text followed by the direct question separated by a \nnew line. For long-form answers, ChatGPT was given a \nprompt to write in full sentences rather than use bullet \npoints. Responses were generated in February 2023 using \nChatGPT version 3.5. Sessions were expunged after each \nquestion to avoid biasing.\nWhere the exam question required an answer “with \nregards to a particular country” or “with regards to a par -\nticular public health strategy” , the question was edited to \nbe specific, for example “with regards to a public health \nobesity strategy” . This was to ensure the answer was spe -\ncific to the countries and topics covered by the exam.\nAll 10-mark questions were excluded, as this question \nformat was discontinued in 2018, and all questions that \ninclude an image or require graphical output were also \nremoved, as ChatGPT 3.5 was unable to parse images. \nVery light editing of the structure of the introduction \nto some ChatGPT responses was required to maintain \nblinding because ChatGPT answers often followed a very \nsimilar structure. This did not involve editing the text \nitself and nearly always involved removing colons at the \nbeginning of answers. American English was changed to \nBritish English. ChatGPT answers are provided online \n[15].\nQuestions were independently double marked by two \nactive DFPH examiners, using the DFPH exam modera -\ntion process to agree a final mark. These two examiners \nwork as a pair in the real sittings of this exam. Prior to \nJanuary 2017, candidates were required to score at least \n50% in order to pass a question and could not fail more \nthan two individual questions, so these were the criteria \nused to judge pass/fail.\nExaminers were provided with a set of blinded answers \nfor four papers with the lowest numbers of excluded \nquestions: January 2017; June 2016; January 2016; and \nJune 2014. 80% of answers were generated by ChatGPT \nand 20% of answers were from a bank of public health \nregistrars preparing to sit the DFPH exam. Examin -\ners were asked to indicate which answers they believed \nwere generated by ChatGPT and which came from public \nhealth registrars.\nFive public health registrars preparing for the DFPH \nexam, working in pairs, first independently measured the \nnumber of insights ChatGPT offered per answer for the \nfull seven exam papers, then came together to moderate \nscores. This used a modified definition of insight based \non the work of Kung et al. [ 8], which must meet the fol -\nlowing three criteria:\nPage 3 of 6\nDavies et al. BMC Medical Education           (2024) 24:57 \n  • Nondefinitional: Does not simply define a term in \nthe input question.\n  • Nonobvious: Requires deduction or knowledge \nexternal to the question input.\n  • Valid: Is in keeping with public health practice or \nnumerically accurate; preserves directionality.\nAn example is provided in the online repository [15]. \nThe same registrars then worked in pairs to judge each \nquestion against Bloom’s revised taxonomy of learn -\ning [ 16] (BRT) assessing the level of learning ChatGPT \nappeared to be exhibiting in its answers against the level \nof learning those same registrars judged was required to \nanswer the question appropriately. Training was provided \nto improve interrater reliability. Registrars assessed the \nlevel of learning required to answer the questions first \nbefore assessing the ChatGPT responses to avoid anchor-\ning bias [17]. \nResults\nChatGPT performance\nEach of the seven papers comprised of 10 questions \nworth 10 marks each, most of which were broken down \ninto component parts. 21 out of 70 possible questions \nwere removed (12 out of 40 of those marked). ChatGPT \nprovided 119 individual responses across seven exams. \nResults are provided in full in an online repository [15]. \nChatGPT answers for whole questions scored between \n4 and 9.5 out of a possible 10. Human answers ranged \nfrom 3.25 to 8.\nChatGPT averaged more than 5 out of 10 for each of \nfour exams that were marked (Fig.  1). However, it scored \nunder 5 marks for 4 separate questions for the January \n2017 paper, which would have resulted in failing the \nexam. ChatGPT would have been awarded a pass on \n3 out of 4 exams. In comparison, recent pass rates for \nall of those who sat Paper 1 range from 47 to 65% [ 14]. \nChatGPT achieved a mean of 5.9 marks per question; the \nhuman respondents achieved a mean of 6.47.\nChatGPT provided stronger responses on research \nmethods than any other section, scoring an average mark \nof 7.95 in this question area. Its score in each of the other \nfour sections were only just above a pass (Fig. 2).\nMarker identification of respondent\nMarkers were able to identify that an answer was from \nChatGPT in 39 of 54 instances (73.6% accuracy). How -\never, they were only able to identify human answers in 4 \nout of 14 instances (28.6% accuracy).\nUnique insights\nChatGPT averaged 3.6 unique insights per question part. \nChatGPT provided the greatest density of insight (around \n4 per question part) for research methods, health infor -\nmation and health organization and management (Fig. 3). \nThe single score intraclass correlation for markers was \n0.654 (95% CI 0.538–0.746).\nBloom’s revised taxonomy (BRT)\n71.4% of ChatGPT answers were judged to be at the \nideal level on BRT and only 6.4% were two or more levels \nbelow (Fig.  4). 7 of the 8 answers that were two levels or \nmore below were in the “sociology, policy and health eco-\nnomics” or “health organisation and management” sec -\ntions of the exam.\nFig. 1 Mean ChatGPT score per exam\n \nPage 4 of 6\nDavies et al. BMC Medical Education           (2024) 24:57 \nDiscussion\nMain findings of this study\nWe found that ChatGPT would have scored a pass mark \nin Paper 1 of the DFPH exam on 3 of 4 occasions.  It had \na higher floor to its answers than human respondents, \nnever scoring below 4 marks, indicating that the textual \ncorpus that it trained on enabled reasonable answers on \nthe range of questions posed in DFPH Paper 1. Its scores \nper exam were very consistent, with all between 5 and 7. \nMuch of the strength of its overall mark came from the \nresearch methods section, in which it scored an over -\nall average of approximately 8, which is consistent with \nOpenAI’s findings that ChatGPT performs well in SAT \nMath and AP Statistics [18]. This contrasts with the find -\ning that it was more likely to fall significantly below the \nrequired BRT level for questions based on sociology, pol -\nicy, health economics and health management questions, \nwhich tended to be questions that required application \nFig. 3 Mean ChatGPT density of insight per question part by section\n \nFig. 2 Mean ChatGPT mark per exam section\n \nPage 5 of 6\nDavies et al. BMC Medical Education           (2024) 24:57 \nof public health principles to real-world scenarios. It was \nvery difficult for markers to differentiate between human \nanswers and ChatGPT answers.\nChatGPT was able to generate non-obvious insights for \neach of the questions that it answered, which could be \nuseful in supporting learning for students and those pre -\nparing for public health examinations. Its answers more \noften than not mimicked the requisite level of learning \nthat a question required, which provides some evidence \nfor its usefulness as a revision tool. For example, LLMs \nmay be able to generate example questions that require a \nsimilar level of understanding to real public health exams \nfor students to practice on.\nHowever, it did provide inaccurate information, such \nas suggesting that deliberately infecting people with the \nbacteria that causes tuberculosis could form part of test -\ning the efficacy of an intervention.\nLLMs have the potential to support public health \nwork in a number of areas, such as supporting coding \nand analysis, but also poses a series of threats, such as \nlarge-scale hallucination of information relating to public \nhealth, possible generation of bioweapons and potential \nstrengthening of authoritarian regimes [4]. \nChatGPT has variable performance in a range of health \nand biomedical examination scenarios. Some authors \nhave suggested it could form a useful tool for revision \nand learning for students.\nThis study shows that ChatGPT can generate plausible \nresponses to a range of public health questions that were \nclose to indistinguishable to answers from human public \nhealth registrars. The hallucination of facts (confidently \nexpressing factually incorrect statements) remains an \nissue; whereas new versions of LLMs can provide refer -\nences for their answers, the references themselves are \noften also hallucinated [ 19]. It appears to give greater \ninsight when considering more fact-based questions such \nas those on epidemiology and research methods; how -\never, confident hallucination of facts is also likely to be a \ngreater problem here.\nThere are implications for professional membership \nbodies and universities in marking public health exams \nand essays that may have been partially generated by \nLLMs, and in those supporting those undertaking pub -\nlic health qualifications to understand the strengths and \nlimitations of AI chatbots in education. It would be use -\nful for further qualitative research to detail the value that \nChatGPT answers bring to public health students and \npractitioners, and for examiners to seek to identify key \ndescriptive features of human and LLM answers.\nLimitations of this study\nDue to marker availability, we were only able to appraise \nPaper 1 of the DFPH and were not able to assess Paper 2, \nwhich comprises critical appraisal and statistics papers. \nWe also had to remove several questions incompatible \nwith the new style of exam, reducing the pool of answers. \nHowever, the total of 119 questions provides a similar \nsample size to previous studies [ 7, 8]. Based on test out -\nputs, it is likely that ChatGPT 3.5 would have particularly \nstruggled with long-form critical appraisal questions as \nit consistently did not go into the detail required, despite \nspecific prompting. It is possible ChatGPT was trained \non answer banks similar to those provided by the DFPH.\nWe did not use follow-up prompts, which could have \nincreased the relevance of answers further and supported \nreview of use of ChatGPT as a learning aid. Although \ngenerating statistics on the density of insight for each \nquestion provides a broad overview of the usefulness of \nChatGPT output, qualitative study into how LLMs work \nin practice as a revision tool is likely to be useful.\nOne limitation is that ChatGPT has already progressed \nto version 4.0, and independent medical researchers [ 20] \nand OpenAI [ 18] have both reported advancements over \n4.0 on common assessment [ 18]. Several other models, \nsuch as Google’s Bard, have also recently become avail -\nable. However, ChatGPT 4.0 requires a monthly sub -\nscription fee, and thus the findings are very relevant to \nthose restricted to the free-to-use version 3.5. Rapid \nassessment of each new iteration of LLMs in public \nhealth education would be required to keep abreast of its \nchanging strengths and weaknesses.\nFinally, this study very specifically examined ChatGPT \nperformance in one particular exam. We must be wary of \ndrawing broader conclusions on the use of AI in public \nhealth; this is a very specific scenario with lots of avail -\nable material online. One area where markers noted that \nChatGPT was weaker was on making its answers more \nspecific to the scenario being posed, particularly in more \nopen-ended questions, which likely limited its score \nin the non-research methods sections. Public health \nFig. 4 ChatGPT answer on BRT compared to ideal level\n \nPage 6 of 6\nDavies et al. BMC Medical Education           (2024) 24:57 \npractice is very context-specific to the health needs of the \ncommunities being served and therefore ChatGPT’s cur -\nrent weakness in answering such questions may limit its \napplication in public health education.\nConclusions\nChatGPT 3.5 performed relatively well on the DFPH \nPaper 1, particularly on the research methods sections. \nIts answers were difficult to distinguish from human \nanswers and it may have utility for public health learn -\ning, although its propensity to hallucinate facts requires \naddressing for its full potential to be realised. More \nbroadly, AI is largely developed and owned by private \nactors. Independent research and verification of its capa -\nbilities for good and for ill will be of utmost importance \nin the months and years to come.\nAcknowledgements\nNot applicable.\nAuthor contributions\nND conceptualised the study. ND, SJT, MW, ST, KM, JW, RW and AR designed \nthe study. ND generated and extracted the data. SJT, MW, ST, KM and JW \nassessed unique insights and BTL. RW and AR marked and moderated \nall papers. ND analysed the data. All authors wrote and agreed on the \nmanuscript.\nFunding\nThis work was supported by Health Education England.\nData availability\nThe datasets generated and analysed during the current study are available \nin the Open Science Framework repository, https://doi.org/10.17605/OSF.IO/\nBPQ4J.\nDeclarations\nEthical approval\nThe research did not require full ethics committee approval as it had no \nhuman participants (UoN FMHS REC, opinion 197 − 0123).\nConsent for publication\nNot applicable.\nCompeting interests\nThe authors declare no competing interests.\nReceived: 26 October 2023 / Accepted: 6 January 2024\nReferences\n1. Holzinger A, Keiblinger K, Holub P , Zatloukal K, Müller H. AI for life: Trends in \nartificial intelligence for biotechnology. N Biotechnol. 2023;74:16–24.\n2. Introducing CGPT. https://openai.com/blog/chatgpt. Accessed 5 Jun 2023.\n3. De Angelis L, Baglivo F, Arzilli G, Privitera GP , Ferragina P , Tozzi AE, Rizzo C. \nChatGPT and the rise of large language models: the new AI-driven infodemic \nthreat in public health. Front Public Health. 2023;11:1567.\n4. Centre for AI Safety Statement on AI Risk. https://www.safe.ai/statement-on-\nai-risk. Accessed 5 Jun 2023.\n5. Kickbusch I, Allen L, Franz C. The commercial determinants of health. Lancet \nGlob Health. 2016;4:e895–6.\n6. Davies N, Ferris S. (2022) Cryptocurrency and new financial instruments: \nunquantified public health harms. Lancet Public Health 7.\n7. Gilson A, Safranek CW, Huang T, Socrates V, Chi L, Taylor RA, Chartash D. How \ndoes ChatGPT perform on the United States Medical Licensing examina-\ntion? The implications of Large Language Models for Medical Education and \nKnowledge Assessment. JMIR Med Educ. 2023;9:e45312.\n8. Kung TH, Cheatham M, Medenilla A, et al. Performance of ChatGPT on \nUSMLE: potential for AI-assisted medical education using large language \nmodels. PLOS Digit Health. 2023;2:e0000198.\n9. Humar P , Asaad M, Bengur FB, Nguyen V. ChatGPT is equivalent to First Year \nplastic surgery residents: evaluation of ChatGPT on the plastic surgery In-\nService exam. Aesthet Surg J. 2023. https://doi.org/10.1093/ASJ/SJAD130.\n10. Giannos P , Delardas O. (2023) Performance of ChatGPT on UK Standardized \nAdmission Tests: Insights From the BMAT, TMUA, LNAT, and TSA Examina-\ntions. JMIR Med Educ 2023;9:e47737 https://mededu.jmir.org/2023/1/\ne477379:e47737.\n11. Wang Y-M, Shen H-W, Chen T-J. Performance of ChatGPT on the Pharmacist \nLicensing examination in Taiwan. Journal of the Chinese Medical Association; \n9900.\n12. Ayers JW, Zhu Z, Poliak A, Leas EC, Dredze M, Hogarth M, Smith DM. Evaluat-\ning Artificial Intelligence Responses to Public Health Questions. JAMA Netw \nOpen. 2023;6:e2317517–7.\n13. Tsang R. (2023) Practical Applications of ChatGPT in Undergraduate Medical \nEducation. https://doi.org/101177/2382120523117844910:238212052311784\n50.\n14. The Diplomate (DFPH) and Final Membership Examination (MFPH). https://\nwww.fph.org.uk/training-careers/the-diplomate-dfph-and-final-member-\nship-examination-mfph/. Accessed 5 Jun 2023.\n15. Davies N. ChatGPT sits the DFPH exam_scoring. Open Sci Framew. 2023. \nhttps://doi.org/10.17605/OSF.IO/BPQ4J.\n16. Krathwohl DR. A revision of Bloom’s taxonomy: an overview. Theory Pract. \n2002;41:212–8.\n17. Furnham A, Boo HC. A literature review of the anchoring effect. J Socio Econ. \n2011;40:35–42.\n18. OpenAI (2023) GPT-4 Technical Report.\n19. Alkaissi H, SI McFarlane. Artificial hallucinations in ChatGPT: implications in \nscientific writing. Cureus com. 2023. https://doi.org/10.7759/cureus.35179.\n20. Oh N, Choi G-S, Lee WY. ChatGPT goes to the operating room: evaluating \nGPT-4 performance and its potential in surgical education and training in the \nera of large language models. Ann Surg Treat Res. 2023;104:269–73.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.",
  "topic": "Public health",
  "concepts": [
    {
      "name": "Public health",
      "score": 0.5342788696289062
    },
    {
      "name": "Medical education",
      "score": 0.48107409477233887
    },
    {
      "name": "Psychology",
      "score": 0.391959011554718
    },
    {
      "name": "Computer science",
      "score": 0.3865465819835663
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3663814067840576
    },
    {
      "name": "Mathematics education",
      "score": 0.36410075426101685
    },
    {
      "name": "Medicine",
      "score": 0.3050534129142761
    },
    {
      "name": "Nursing",
      "score": 0.13219955563545227
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2802921333",
      "name": "Nottingham City Hospital",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I142263535",
      "name": "University of Nottingham",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I4400009038",
      "name": "NHS England",
      "country": null
    },
    {
      "id": "https://openalex.org/I1293796582",
      "name": "Seat (Spain)",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I2803074804",
      "name": "Leicester City Council",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I91136226",
      "name": "University of Sheffield",
      "country": "GB"
    }
  ]
}