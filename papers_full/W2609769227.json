{
  "title": "The Right to Remember: Implementing a Rudimentary Emotive-Effect Layer for Frustration on AI Agent Gameplay Strategy",
  "url": "https://openalex.org/W2609769227",
  "year": 2017,
  "authors": [
    {
      "id": "https://openalex.org/A5050902320",
      "name": "James Stallwood",
      "affiliations": [
        "University of Southampton",
        "University of Winchester"
      ]
    },
    {
      "id": "https://openalex.org/A5004726814",
      "name": "Ashok Ranchhod",
      "affiliations": [
        "University of Southampton",
        "University of Winchester"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2119368976",
    "https://openalex.org/W2048407516",
    "https://openalex.org/W2476009077",
    "https://openalex.org/W1970114962",
    "https://openalex.org/W2004987601",
    "https://openalex.org/W2007098914",
    "https://openalex.org/W2076453264",
    "https://openalex.org/W1995270501",
    "https://openalex.org/W2576172705",
    "https://openalex.org/W2068063061",
    "https://openalex.org/W7008130063",
    "https://openalex.org/W1985542898",
    "https://openalex.org/W2131963071",
    "https://openalex.org/W2151723656",
    "https://openalex.org/W2084397606",
    "https://openalex.org/W2040878866",
    "https://openalex.org/W2105931454",
    "https://openalex.org/W2169828024",
    "https://openalex.org/W2007350029",
    "https://openalex.org/W2002976116",
    "https://openalex.org/W1999294210"
  ],
  "abstract": "AI (Artificial Intelligence) is often looked at as a logical way to develop a game agent that methodically looks at options and delivers rational or irrational solutions. This paper is based on developing an AI agent that plays a game with a similar emotive content like a human. The purpose of the study was to see if the incorporation of this emotive content would influence the outcomes within the game Love Letter. In order to do this an AI agent with an emotive layer was developed to play the game over a million times. A lower win/loss ratio demonstrates that, to some extent, this methodology was vindicated and a 100 per cent win for the AI agent did not happen. Machine learning techniques were modelled purposely so as to match extreme models of behavioural change. The results demonstrated a win/loss ratio of 0.67 for the AI agent and, in many ways, reflected the frustration that a normal player would exhibit during game play. As was hypothesised, the final agent investment value was, on average, lower after match play than its initial value.",
  "full_text": null,
  "topic": "Emotive",
  "concepts": [
    {
      "name": "Emotive",
      "score": 0.9669691324234009
    },
    {
      "name": "Irrational number",
      "score": 0.8040450811386108
    },
    {
      "name": "Value (mathematics)",
      "score": 0.5322548747062683
    },
    {
      "name": "Psychology",
      "score": 0.44407549500465393
    },
    {
      "name": "Computer science",
      "score": 0.4234212636947632
    },
    {
      "name": "Order (exchange)",
      "score": 0.4128963053226471
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3926790952682495
    },
    {
      "name": "Cognitive psychology",
      "score": 0.35680946707725525
    },
    {
      "name": "Social psychology",
      "score": 0.3541930913925171
    },
    {
      "name": "Mathematics",
      "score": 0.17272084951400757
    },
    {
      "name": "Economics",
      "score": 0.1618497669696808
    },
    {
      "name": "Epistemology",
      "score": 0.13562056422233582
    },
    {
      "name": "Machine learning",
      "score": 0.12049075961112976
    },
    {
      "name": "Philosophy",
      "score": 0.09209173917770386
    },
    {
      "name": "Finance",
      "score": 0.0
    },
    {
      "name": "Geometry",
      "score": 0.0
    }
  ]
}