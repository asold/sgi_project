{
  "title": "Tied-mixture language modeling in continuous space",
  "url": "https://openalex.org/W2102062345",
  "year": 2009,
  "authors": [
    {
      "id": "https://openalex.org/A116639046",
      "name": "Ruhi Sarikaya",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096610695",
      "name": "Mohamed Afify",
      "affiliations": [
        "New Cairo Academy"
      ]
    },
    {
      "id": "https://openalex.org/A2019566994",
      "name": "Brian Kingsbury",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2147152072",
    "https://openalex.org/W2098287788",
    "https://openalex.org/W2158025800",
    "https://openalex.org/W2125610823",
    "https://openalex.org/W1900367739",
    "https://openalex.org/W2165271495",
    "https://openalex.org/W1989705153",
    "https://openalex.org/W2158195707",
    "https://openalex.org/W2086699924",
    "https://openalex.org/W115706727",
    "https://openalex.org/W2146871184",
    "https://openalex.org/W2105638720",
    "https://openalex.org/W2150907703",
    "https://openalex.org/W2161188302",
    "https://openalex.org/W4285719527",
    "https://openalex.org/W2998704965",
    "https://openalex.org/W2010797893"
  ],
  "abstract": "This paper presents a new perspective to the language modeling problem by moving the word representations and modeling into the continuous space. In a previous work we introduced Gaussian-Mixture Language Model (GMLM) and presented some initial experiments. Here, we propose Tied-Mixture Language Model (TMLM), which does not have the model parameter estimation problems that GMLM has. TMLM provides a great deal of parameter tying across words, hence achieves robust parameter estimation. As such, TMLM can estimate the probability of any word that has as few as two occurrences in the training data. The speech recognition experiments with the TMLM show improvement over the word trigram model.",
  "full_text": null,
  "topic": "Trigram",
  "concepts": [
    {
      "name": "Trigram",
      "score": 0.8359067440032959
    },
    {
      "name": "Language model",
      "score": 0.8121755123138428
    },
    {
      "name": "Computer science",
      "score": 0.7808321118354797
    },
    {
      "name": "Word (group theory)",
      "score": 0.6802358627319336
    },
    {
      "name": "Artificial intelligence",
      "score": 0.576066255569458
    },
    {
      "name": "Mixture model",
      "score": 0.5434106588363647
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.5361841320991516
    },
    {
      "name": "Estimation theory",
      "score": 0.5299443006515503
    },
    {
      "name": "Space (punctuation)",
      "score": 0.5232892632484436
    },
    {
      "name": "Parameter space",
      "score": 0.5105305910110474
    },
    {
      "name": "Speech recognition",
      "score": 0.4681784212589264
    },
    {
      "name": "Gaussian",
      "score": 0.45991837978363037
    },
    {
      "name": "Tying",
      "score": 0.4388469457626343
    },
    {
      "name": "Natural language processing",
      "score": 0.3942592740058899
    },
    {
      "name": "Algorithm",
      "score": 0.31701895594596863
    },
    {
      "name": "Mathematics",
      "score": 0.1529567837715149
    },
    {
      "name": "Statistics",
      "score": 0.08585137128829956
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": []
}