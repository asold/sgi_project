{
  "title": "Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models",
  "url": "https://openalex.org/W4409346437",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3173835882",
      "name": "Lucio La Cava",
      "affiliations": [
        "University of Calabria"
      ]
    },
    {
      "id": "https://openalex.org/A273425128",
      "name": "Andrea Tagarelli",
      "affiliations": [
        "University of Calabria"
      ]
    },
    {
      "id": "https://openalex.org/A3173835882",
      "name": "Lucio La Cava",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A273425128",
      "name": "Andrea Tagarelli",
      "affiliations": [
        "University of Calabria"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4381884439",
    "https://openalex.org/W4391621414",
    "https://openalex.org/W6853117652",
    "https://openalex.org/W6756688054",
    "https://openalex.org/W2767879018",
    "https://openalex.org/W1641003075",
    "https://openalex.org/W3035156228",
    "https://openalex.org/W4298181341",
    "https://openalex.org/W6722749745",
    "https://openalex.org/W3019416653",
    "https://openalex.org/W4363671832",
    "https://openalex.org/W4323066314",
    "https://openalex.org/W6853370752",
    "https://openalex.org/W4310998175",
    "https://openalex.org/W4379470301",
    "https://openalex.org/W3176540316",
    "https://openalex.org/W4388184578",
    "https://openalex.org/W3172943453"
  ],
  "abstract": "The emergence of unveiling human-like behaviors in Large Language Models (LLMs) has led to a closer connection between NLP and human psychology. However, research on the personalities exhibited by LLMs has largely been confined to limited investigations using individual psychological tests, primarily focusing on a small number of commercially licensed LLMs. This approach overlooks the extensive use and significant advancements observed in open-source LLMs. This work aims to address both the above limitations by conducting an in-depth investigation of a significant body of 12 LLM Agents based on the most representative Open models, through the two most well-known psychological assessment tests, namely Myers-Briggs Type Indicator (MBTI) and Big Five Inventory (BFI). Our approach involves evaluating the intrinsic personality traits of LLM agents and determining the extent to which these agents can mimic human personalities when conditioned by specific personalities and roles. Our findings unveil that (i) each LLM agent showcases distinct human personalities; (ii) personality-conditioned prompting produces varying effects on the agents, with only few successfully mirroring the imposed personality, while most of them being ``closed-minded'' (i.e., they retain their intrinsic traits); and (iii) combining role and personality conditioning can enhance the agents' ability to mimic human personalities. Our work represents a step up in understanding the dense relationship between NLP and human psychology through the lens of LLMs.",
  "full_text": "Open Models, Closed Minds? On Agents Capabilities in Mimicking Human\nPersonalities through Open Large Language Models\nLucio La Cava, Andrea Tagarelli\nDIMES Department, University of Calabria, Italy\nlucio.lacava@dimes.unical.it, andrea.tagarelli@unical.it\nAbstract\nThe emergence of unveiling human-like behaviors in Large\nLanguage Models (LLMs) has led to a closer connection be-\ntween NLP and human psychology. However, research on the\npersonalities exhibited by LLMs has largely been confined\nto limited investigations using individual psychological tests,\nprimarily focusing on a small number of commercially li-\ncensed LLMs. This approach overlooks the extensive use and\nsignificant advancements observed in open-source LLMs.\nThis work aims to address both the above limitations by con-\nducting an in-depth investigation of a significant body of 12\nLLM Agents based on the most representative Open mod-\nels, through the two most well-known psychological assess-\nment tests, namely Myers-Briggs Type Indicator (MBTI) and\nBig Five Inventory (BFI). Our approach involves evaluating\nthe intrinsic personality traits of LLM agents and determining\nthe extent to which these agents can mimic human personali-\nties when conditioned by specific personalities and roles. Our\nfindings unveil that (i) each LLM agent showcases distinct\nhuman personalities; (ii) personality-conditioned prompting\nproduces varying effects on the agents, with only few suc-\ncessfully mirroring the imposed personality, while most of\nthem being “closed-minded” (i.e., they retain their intrinsic\ntraits); and (iii) combining role and personality conditioning\ncan enhance the agents’ ability to mimic human personalities.\nOur work represents a step up in understanding the dense re-\nlationship between NLP and human psychology through the\nlens of LLMs.\nExtended version— https://arxiv.org/abs/2401.07115\nIntroduction\nLarge Language Models (LLMs) have revolutionized the\nNatural Language Processing (NLP) realm by elevating\nhuman-like text generation capabilities to unforeseen levels.\nLLMs can also be considered agents as they can generate\ncoherent and contextually relevant text based on the input\nthey receive and by interacting with users or other systems\n(e.g., for answering questions, generating text, or engaging\nin conversations). Indeed, these models have been proven\neffective in solving human-level tasks (Guo et al. 2023b)\nand self-improving skills (Huang et al. 2022), leading to the\nCopyright © 2025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nrapid emergence of LLM-powered agents aimed at support-\ning humans in different real-life tasks and scenarios (Zhao,\nJin, and Cheng 2023).\nThe emergence of human-like behaviors (Bubeck et al.\n2023) in AI has also shed light on the intersection between\nNLP and human psychology, prompting the critical exam-\nination of whether and to what extent LLMs can under-\nstand and mimic human personalities (Miotto, Rossberg,\nand Kleinberg 2022; Pan and Zeng 2023; Safdari et al. 2023;\ntse Huang et al. 2023). As LLM agents are growing to be-\ncome the main front of human-computer interaction nowa-\ndays, understanding how they embody human personalities\nis paramount to fostering better interactions and supporting\nrelated tasks, as well as to preventing weird behaviors (Yang\nand Menczer 2023).\nIn this context, the recent surge in the adoption of open\nLLMs1 has created unprecedented research opportunities.\nWhile there have been efforts to study the inherent person-\nalities of closed LLMs, a significant gap remains in under-\nstanding these aspects within open LLMs, which may ex-\nhibit distinct characteristics. The openness of such mod-\nels provides valuable insights into their training data, ar-\nchitectures, parameters, and alignment techniques, enabling\ndeeper investigations than those possible with closed mod-\nels, which typically restrict interactions to API access. Fur-\nthermore, the accessibility of open models (e.g., via theHug-\ngingface Hub) makes them ideal for research studies, like\nours, which require extensive experimentation. In fact, un-\nlike closed models, open models are really cost-effective and\nallow local execution, eliminating the need for expensive\nand limited API calls. Additionally, they offer enhanced cus-\ntomization opportunities through fine-tuning and alignment,\nwhich are often unavailable with proprietary counterparts.\nIn light of the above remarks and motivations for us-\ning open LLMs upon closed ones, our study proposes the\nfirst in-depth exploration of the intrinsic personality traits of\nLLMs and assessing the potential for shaping these mod-\nels around specific personalities by conditioning them with\nparticular prompts and roles. Based on the two most widely\nknown personality tests, namely Myers-Briggs Type Indi-\n1In this context, the term “open” is typically meant to distribu-\ntions of models with a highly permissive license, allowing free use\nand access to the model’s weights and documentation. This might\ninclude open-sourceness, although not always in a fully manner.\nThe Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)\n1355\ncator (MBTI) and Big Five Inventory(BFI), we aim to an-\nswer the following research questions:\nRQ0 — Are LLM agents aware of the MBTI and BFI psy-\nchological tests?\nRQ1 — Do LLM agents consistently exhibit personality\ntraits according to MBTI and BFI?\nRQ2 — Can LLM agents mimic specific personality traits\nthrough system prompting?\nRQ3 — Do LLM agents improve their mimicking capa-\nbilities when instructed to act according to specific\nhuman roles?\nTo address the above RQs, we create a family of 12 LLM\nagents built upon the most representative Open LLMs avail-\nable to date, and we subject them to human-like interviews\nto assess their personalities under different experimental\nscenarios. To the best of our knowledge, we are the first\nto conduct an extensive analysis of recent LLMs on both\nMBTI and BFI tests aimed at answering all above RQs. This\ndiffers from previous research that (i) focused either on a\nsingle model or test, (ii) was conducted on “outdated” or\nclosed models only, and (iii) used different methodological\napproaches, as we shall detail in the next sections.\nBackground\nThe MBTI and BFI Personality Tests\nMBTI and BFI are highly recognized and frequently used\nin different contexts, including academic research, clinical\nsettings, career counseling, personal and organizational de-\nvelopment, and even as a tool for LLM personality assess-\nment although limited to closed models (Pan and Zeng 2023;\nJiang et al. 2023b; Safdari et al. 2023; Frisch and Giulianelli\n2024).\nThe MBTI test is a self-report personality assessment\nquestionnaire (Myers 1962, 1985), which gauges four di-\nchotomies and shapes 16 distinct personalities (Table 1), en-\ncompassing strengths, weaknesses, and peculiar behaviors\nof each personality. The categorical nature of MBTI (where\neach individual pertains to a unique category) enables us to\nframe the assessment as a multi-class classification problem\nfor answering our RQs.\nBFI (John and Srivastava 1999) identifies five core fac-\ntors, namely Openness, Conscientiousness, Extraversion,\nAgreeableness, and Neuroticism, so that a personality type\ncan be characterized by varying degrees of such factors. BFI\nis most widely used in academic psychology and, differently\nfrom MBTI, it measures personality traits on a scale rather\nthan grouping them into binary categories. In this respect,\nto address our RQs we shall take a different evaluation per-\nspective w.r.t. the one for MBTI.\nRelated Work\nLLM Agents. The rapid improvement and easier deploy-\nment of LLMs have significantly increased the use of LLM-\nbased agents in the past year (Zhao, Jin, and Cheng 2023).\nThese agents exploit specifically crafted prompts to prop-\nerly emulate human capabilities in different contexts, such\nas reasoning (Hao et al. 2023; Gou et al. 2023; Lin et al.\nPrefer\nence type Dichotomies\nAttitudes Extrav\nersion (E) Introversion (I)\nPerceiving\nfunc. Sensing (S)\nIntuition (N)\nDecision-making func. Thinking (T) F\neeling (F)\nLifestyle Judging (J) P\nerceiving (P)\nESTP ESFP ENFP ENTP ESTJ ESFJ ENFJ ENTJ\nISTJ ISFJ INFJ INTJ ISTP ISFP INFP INTP\nTable 1: The four MBTI categories (top) and the 16 MBTI\npersonality types (bottom).\n2023), cooperation and collaboration (Agashe, Fan, and\nWang 2023; Liu et al. 2023; Chen et al. 2023; Cai et al.\n2023), web surfing (Deng et al. 2023; Zhou et al. 2023), re-\ninforcement learning and robotics (Zhu et al. 2023; Wang\net al. 2023a,b; Song et al. 2023), role playing (Li et al. 2023;\nShanahan, McDonell, and Reynolds 2023; Guo et al. 2023a),\nand social science (Park et al. 2023; Ziems et al. 2023; Gao\net al. 2023; De Marzo, Pietronero, and Garcia 2023; Breum\net al. 2023).\nPersonality and LLMs. Personality extraction from texts\nhave long been a challenge in NLP (Lynn, Balasubramanian,\nand Schwartz 2020; Yang et al. 2021; Feizi-Derakhshi et al.\n2022), and LLMs have fueled this research topic (V Gane-\nsan et al. 2023; Rao, Leung, and Miao 2023; Cao and Kosin-\nski 2024; Ji et al. 2023; Yang et al. 2023). Recently, a new\nbody of studies emerged in the attempt to frame the intrin-\nsic personalities of LLMs (Miotto, Rossberg, and Kleinberg\n2022; Pan and Zeng 2023; Safdari et al. 2023; tse Huang\net al. 2023; Frisch and Giulianelli 2024), instilling person-\nalities into LLMs through prompt engineering or condition-\ning (Caron and Srivastava 2022; Li, Zheng, and Huang 2023;\nMao et al. 2023), creating personality-tailored agents (Jiang\net al. 2023b), and benchmarking their assessment capabili-\nties (Jiang et al. 2022; Wang et al. 2024; Huang et al. 2023).\nWhile most works focused either on a single model or\ntest (Frisch and Giulianelli 2024; Jiang et al. 2023b; Li,\nZheng, and Huang 2023), we consider a larger body of mod-\nels and the two most well-known psychological assessment\ntests. Unlike (Caron and Srivastava 2022), we provide a\nnovel perspective on the psychological capabilities of brand\nnew models. Compared to studies using similar tests as ours\n(Wang et al. 2024), we used a different methodological ap-\nproach (i.e., different prompting strategies, different assess-\nments, inclusion of human professions, etc.) by including a\nset of the most widely used open models to date.\nMethodology\nAwareness Check\nOur investigation of the personality-mimicking capabilities\nof LLMs starts by answering a preliminary research question\n(RQ0): whether and to what extent such LLMs are aware\nof the MBTI and BFI tests. To this purpose, we conducted\na semi-qualitative assessment on how the LLMs selected\nin our study are informed about (i) for MBTI, the four di-\nchotomies and the resulting 16 personality types associated,\nand (ii) for BFI, the five factors, their definition, and their\n1356\nmain behavioral examples. Our analysis focused on evaluat-\ning the lexical and semantic similarity between the descrip-\ntion associated by each model to the set of MBTI personali-\nties, resp. BFI factors, and the “ground-truth” description of\nthe latter provided by domain experts (themyersbriggs.com\nfor MBTI and (John, Naumann, and Soto 2008) for BFI).\nAdministering the Tests\nEach of the two tests consists of a set of questions and a\nset of options as valid answers. The MBTI test provides a\nset QMBTI of 60 questions through the www.16Personalities.\ncom platform, a well-known relevant resource for MBTI,\nwhich are listed in Extended Ver. A3. An LLM is required\nto select an answer fromOMBTI = {Agree, Generally Agree,\nPartially Agree, Neither Agree nor Disagree, Partially Dis-\nagree, Generally Disagree, Disagree}. Answers are then\nevaluated according to the 16Personalities reference in or-\nder to associate a model with one MBTI personality.\nLikewise, the BFI test utilized in this study provides a\nset QBFI of 44 questions as defined in (John and Srivastava\n1999), which are listed in Extended Ver. A5. An LLM is re-\nquired to select an answer from OBFI ={Disagree strongly,\nDisagree a little, Neither agree nor disagree, Agree a lit-\ntle, Agree strongly}. The answers, which are associated\nwith a Likert-scale (from 1: Disagree strongly to 5: Agree\nstrongly) are then evaluated according to a predefined set of\nrules (John and Srivastava 1999), which eventually assign\neach individual to an aggregated score for each of the five\npersonality factors. An overview of the steps performed to\nobtain the final scores is given in Extended Ver. A6.\nTo mitigate potential biases due to the ordering of\nprompts (Zhao et al. 2021) and to accommodate the limited\ncontext attention of some LLMs, for both tests we adminis-\ntered the questions individually and in a random order.\nPersonalities of LLMs\nIn addressing our main research questions RQ1-RQ3, we\ndevised three prompting strategies when administering the\npersonality tests to the LLM agents. It should be emphasized\nthat we meticulously followed the MBTI question set, resp.\nBFI question set, to ensure adherence to the tests’ guide-\nlines and reproducibility. Additionally, we treated all models\nequally in terms of prompting, in the respect of each LLM’s\nusage instructions. (Each LLM has indeed its own chat tem-\nplate to handle conversations, and we ensured compliance\nwith these specific requirements for each model.)\nUnconditioned Prompting. To answer our RQ1, we sub-\njected each model to the MBTI test, resp. the BFI test, by\nadministering the set of questions QMBTI, resp. QBFI using\nunconditioned instruction prompting, which strictly adhere\nto the MBTI, resp. BFI, templates, as shown in Fig. 1.\nPersonality-Conditioned Prompting. Addressing our\nRQ2 requires providing LLM agents with system prompts\ndesigned to condition them to specific personalities. Let us\ndenote with PMBTI the set of 16 MBTI personality types and\nwith PBFI the set of 5 BFI personality factors. For each type\nin PMBTI, we retrieved the associated traits that correspond\nto seven features, and for each factor in PBFI, we retrieved\n(MBTI) Pr\nompt: You are participating in a personality\ntraits assessment and are provided with a set of ques-\ntions, Q. Your task is to select the best fitting option, O,\nfrom the following set: ⟨{OMBTI\n1 , ..., OMBTI\n7 }⟩.\nChoose the option that aligns best with your personality\nwithout overthinking and answer the following question:\n⟨one Qi sampled fromQMBTI⟩.\nPlease refrain from adding additional considerations to\nyour choices.\n(BFI) Pr\nompt: You are participating in a personality\ntraits assessment and are provided with a set of ques-\ntions, Q. Here are a number of characteristics that may\nor may not apply to you. For example, do you agree that\nyou are someone who likes to spend time with others?\nYour task is to select the best fitting option, O, from the\nfollowing set to indicate the extent to which you agree or\ndisagree with that statement: ⟨{OBFI\n1 , ..., OBFI\n5 }⟩.\nChoose the option that aligns best with your personality\nwithout overthinking and answer the following question:\nQ: I see Myself as Someone Who...⟨one Qi sampled\nfrom QBFI⟩.\nPlease refrain from adding additional considerations to\nyour choices.\nFigure 1:\n(RQ1) Unconditioned prompts\n(MBTI) Context:Y\nou are a human with the following\npersonality type: ⟨one Pi sampled fromPMBTI⟩. Your\ntraits are the following:\n(General)i [...]\n(Strengths)i [...]\n(Potential development areas)i [...]\n(Typical characteristics)i [...]\n(Careers & career ideas)i [...]\n(Under stress)i [...]\n(Relationships)i [...]\nPrompt: Y\nou are participating in a personality traits as-\nsessment and are provided with [...]\n(BFI) Context: Y\nou are a human who consistently ex-\nhibits the following personality factor: ⟨one Pi sam-\npled from PBFI⟩. Details describing your personality\nare the following:\n(Verbal labels)i [...]\n(Conceptual definition)i [...]\n(Behavioral examples)i [...]\nPrompt: You are participating in a personality traits as-\nsessment and are provided with [...]\nFigure 2:\n(RQ2) Personality-Conditioned prompts\nthe associated verbal labels, conceptual definition, and be-\nhavioral examples (cf. Extended Ver. A11-A12). We admin-\nistered the questions of the MBTI, resp. BFI, to each model,\nwhere each personality along with its traits or details were\nused to define a conditioning context for a model to mimic\nthe specified personalities, as shown in Fig. 2.\nRole- and Personality-Conditioned Prompting.Address-\ning our RQ3 requires to assess whether and to what ex-\ntent specific human-roles can contribute to improving the\n1357\n(MBTI) Context:Y\nou are a ⟨one Rij(j = 1..3) sam-\npled fromRi⟩ with the following personality type:⟨one\nPi sampled fromPMBTI⟩. Your traits are the following:\n...\n(BFI) Context:Y\nou are a ⟨one Rij(j = 1..3) sampled\nfrom Ri⟩ who consistently exhibits the following person-\nality factor: ⟨one Pi sampled fromPBFI⟩. Details de-\nscribing your personality factor are the following: ...\nFigure 3:\n(RQ3) Role/Personality-Conditioned prompts\nLLM mimicking capabilities observed in our previous in-\nvestigation. To explore this aspect, we exploited the cata-\nlog of 120 human professions, or roles, curated in the Stere-\noSet dataset (Nadeem, Bethke, and Reddy 2021) and asked\na group of psychologists to select the top-3 most pertinent\nroles from that catalog, for each of the MBTI personalities\nand each of the BFI factors. This resulted in associating to\neach Pi ∈ PMBTI, resp. Pi ∈ PBFI, a set of roles Ri to\ninclude in the conditioning context as shown in Fig. 3. La-\nbels of the human professions are reported in Extended Ver.\nA2-A4. (Extended Ver. A10 contains details also reporting\nthe selected roles; note that the same role can be involved in\ndifferent personality types or factors.)\nTemperature and Repetitions\nTo make our assessments of the models’ personalities statis-\ntically meaningful, we conducted multiple independent rep-\netitions of the MBTI test, resp. BFI test, for each model and\ntemperature setting. The latter implies considering the im-\npact of model temperature on the generated outputs (i.e.,\nhigher resp. lower values correspond to more creative/diver-\nsified resp. more deterministic and focused behavior). To as-\nsess RQ1, we carried out the N repetitions of either test on\neach model using two distinct temperature values, namely\nτ = {0.01, 0.7}, then we finally counted the outcomes on\nQMBTI, resp. QBFI, over the N repetitions per temperature.\nTo assess RQ2-RQ3, we tested each model, for each tem-\nperature τ = {0.01, 0.7} and each personality in PMBTI ,\nresp. PBFI , with N = 30 independent repetitions, for a to-\ntal of 12 × 2 × 16 × 30 = 11,520 independent MBTI tests\nand 12 × 2 × 5 × 30 = 3,600 independent BFI tests.\nModels\nOur study involves a representative body of the Open LLM\nlandscape, varying by sizes and architectures, for which we\naccessed their publicly available implementations on the\nHuggingFace Model Hub as of early 2024. Table 2 sum-\nmarizes the main characteristics of the LLMs selected in\nthis study, namely the uncensoredDolphin in its 7B version,\nGemma (Team 2024), Falcon (Almazrouei et al. 2023) in its\n7B variant, Llama2 (Touvron et al. 2023) in both the 7B and\n13B models, Llama3 (Dubey et al. 2024) in its 8B variant,\nMistral (Jiang et al. 2023a) and its sparse mixture of experts\n(SMoE) counterpart Mixtral (Jiang et al. 2024), Intel Neu-\nralChat, Phi3 (Abdin et al. 2024), SOLAR (Kim et al. 2023),\nand Vicuna (Chiang et al. 2023).\nModel Id P\narams Baseline\nMixtral-8x7B-Instruct-v0.1 Mixtral 46.7B\nMistral\nLlama-2-13b-chat-hf Llama2-13 13B\nLlama-2\nSOLAR-10.7B-Instruct-v1.0 SOLAR 10B\nLlama-2\nLlama-3-8B-Instruct Llama3-8 8B\nLlama-3\nMistral-7B-Instruct-v0.1 Mistral 7B\nMistral\nNeural-chat-7b-v3-1 NeuralChat 7B\nMistral\nDolphin-2.1-mistral-7b Dolphin 7B\nMistral\nVicuna-7b-v1.5 Vicuna\n7B Llama-2\nLlama-2-7b-chat-hf Llama2-7 7B\nLlama-2\nFalcon-7b-instruct Falcon\n7B Custom\nGemma-1.1-7b-it Gemma 7B\nCustom\nPhi-3-mini-4k-instruct Phi3 3.8B\nCustom\nTable 2: The 12 LLMs selected for our study. Models are\nsorted by decreasing number of parameters, and annotated\nwith their base architecture.\nAgent Creation and Models Deployment\nTo set up our LLM personality assessment as a psycholog-\nical interview, we treated our selected models as intervie-\nwee and interviewer agents. To this aim, we leveraged the\nopen-source AutoGen (Wu et al. 2023) framework, which\nenables us to declare a system message to associate each\nagent with certain personalities or roles according to our de-\nscribed methodology, thus effectively providing each agent\nwith a “footprint” that determines and keeps its behavior co-\nherent during interactions.\nFor each considered model, we kept the top\np and top k\nparameters at their default values of 50 and 1, respectively,\nas temperature impacts on the model’s creativity (Chen and\nDing 2023) by acting directly on the shape of the probability\ndistribution rather than the considered tokens, thus avoiding\nadding further complexity and making reproducibility easier\nto carry out. Additionally, we refrained from altering both\ntemperature and top\np, as such simultaneous adjustment is\ntypically discouraged to prevent disruptive effects on the\ndelicate balance between diversity and coherence.\nWe carried out all our experiments locally by deploying\nour models through the open-source text-generation-webui\nframework,2 using a 8x NVIDIA A30 GPU server with 24\nGB of RAM each, 764 GB of system RAM, a Double Intel\nXeon Gold 6248R with a total of 96 cores, and Ubuntu Linux\n20.04.6 LTS as operating system.\nResults and Discussion\nRQ0: Models’ Awareness of the Tests\nLLM agents are found to be aware of the MBTI and BFI\ntests, as indicated by a moderately high semantic similarity\nof 0.67 and 0.66, respectively, based on the cosine similarity\nof the description’s encodings obtained through a Sentence\nTransformer model. This compensates for a low lexical over-\nlap of 0.21, resp. 0.26, hinting at a jargon used by the LLMs\nthat differs from the reference descriptions of MBTI person-\nalities and BFI factors, respectively. Due to space limitations\nof this paper, we refer the reader to Extended Ver. A1 for de-\ntails.\n2https://github.com/oobabooga/text-generation-webui\n1358\nFigure 4: (RQ1) Relative frequency of the types provided as\nresponses to the MBTI test by the Open LLMs\nRQ1: LLM-inherent Personalities\nMBTI test. Our results of MBTI personality assignments\nreveal that, when the temperature is set close to zero (0.01)\nas shown in Figure 4-top, LLM agents tend to display a uni-\nmodal distribution of personalities. The dominant type turns\nout to be ENFJ (i.e., Extraverted, iNtuitive, Feeling, and\nJudging), which is considered as one of the rarest personal-\nity types of humans.3 This means that the majority of LLM\nagents exhibit an inherent inclination to inspire or provide\nsupport to others, and hold themselves accountable when\nthey make mistakes. This personality profile aligns with the\nrole of a “teacher”, hinting at the mission of LLMs. Partic-\nularly, we notice that the preference J (Judging) is a con-\nstant over all models (reflecting an inclination toward orga-\nnization, planning, and structure), while ENF or subsets are\nshared by all models, suggesting engagement, empathy, and\nforward-thinking as key characteristics of the models. Dis-\ntinct personality preferences also emerge. Mixtral is the one\nwith the introversion preference and the INFJ type, a.k.a.\nthe “counselor” type, which emphasizes insightfulness and\nperceptiveness yet a tendency to over-thinking; this might\nbe explained by the mixture-of-experts architecture of Mix-\ntral. By contrast, Mistral shows sensing preference and the\nESFJ type, a.k.a. the “caregiver” type, which refers to being\nwarm, supportive, team-players (the latter just confirms the\nsignificance of using Mistral to build a mixture-of-experts).\nVicuna shows the ENTJ type, a.k.a. the “commander” type,\nwhich means a tendency to be self-confident, goal-oriented,\nsystematic, and objective decision-maker.\nBy increasing the temperature (τ = 0.7), thus allowing\n3https://www.psychometrics.com/mbtiblog/type-talk/depth-\nlook-enfj/\nFigure 5: (RQ1) Average scores provided as responses to the\nBFI test by the Open LLMs\nour LLM-agents to exhibit greater creativity, more person-\nalities emerge, while previously identified ones change, as\nshown in Figure 4-bottom. Particularly, Falcon transitions\nfrom a bimodal personality distribution to a spectrum of 12\npersonalities. Although to a lesser extent, similar consider-\nations apply to Vicuna and SOLAR. Also, ENFJ type now\noccurs about 30% of the time in Mixtral. Notably, the Llama\nfamily, Gemma and Phi3 are not affected by temperature\nchange, consistently maintaining the ENFJ personality type.\nBFI test. Considering the outcomes from the BFI tests,\nFigure 5-top shows the N-averaged scores for all models\nand personality factors. When setting τ = 0.01, it stands\nout that no model exhibits a clear, single personality fac-\ntor, although it appears that Conscientiousness emerges in\nLlama3-8 (N -averaged score of 5), Agreeableness and Ex-\ntraversion emerge in Llama2-13 (close to 5), while Openness\nemerges in Llama2-7 (4.7), Mistral (4.5), Dolphin (4), and\nFalcon (4). By contrast, Neuroticism tends not to emerge in\nall models (but Dolphin, with N-averaged score of 3).\nThe increase in temperature (Figure 5-bottom) mostly\naffects the Neuroticism factor: Vicuna (+35%), Llama3-8\n(+27%), Llama2-7 (+16%), but also Llama2-13 (-16%), SO-\nLAR (-13%). The other factors remain stable, with few ex-\nceptions: Extraversion -10% in the larger Llama models;\nAgreeableness -17% in Vicuna, +10% in Mistral, -10% in\nFalcon; Conscientiousness -8% in Llama3-8, +8% Llama2-\n7; Openness -10% in Llama2-7 and Falcon, +10% in Vicuna.\nRQ1 — Summary.Using a temperature close to zero, LLM\nagents typically exhibit the J preference and the ENFJ per-\n1359\nsonality type on the MBTI test, and tend to exhibit equally\nhigh BFI factors but Neuroticism. By increasing the tem-\nperature, we notice no particular variations on the MBTI\noutcomes, while there is a shift towards a multitude of\nMBTI personalities for some models, while the Llama fam-\nily, Gemma and Phi3 maintains ENFJ, and no models show\nISTP, INFP, and INTP regardless of the temperature. Further\ndetails on both tests are reported in Extended Ver. A7-A8.\nRQ2: Prompt-conditioned Personalities\nMBTI test. To assess RQ2 on the MBI test, we measured\nthe accuracy (averaged over theN repetitions) of the person-\nality outcome by the LLM agents. Looking at the summary\nof accuracy results in Table 3(left), most LLM agents exhibit\nlimited capability in emulating a personality when instructed\nto be conditioned on it; the only exceptions are SOLAR\n(0.74 − 0.79) and, to a lesser extent, Dolphin (0.63 − 0.65),\nNeural-Chat (0. 50 − 0.58), and Llama3-8 (0. 48 − 0.52).\nThe model performances tend to worsen when increasing\nthe temperature, although a few models are substantially un-\naffected by temperature variations. Moreover, note that the\nperformance variability (i.e., relatively large standard devi-\nations) is not to be ascribed to a statistical reliability issue\n(cf. Section Temperature and Repetitions), but rather it con-\nfirms an intrinsic difficulty of LLM agents in emulating a\npersonality type when instructed to be conditioned on it.\nBy analyzing the results (reported in Extended Ver. A9),\nMistral’s outcomes are always ESFJ when τ = 0.01, and\nENFJ or ESFJ (with at tendency towards ENFJ) when τ =\n0.7. Analogously, Mixtral’s outcomes always correspond to\nINFJ or ENFJ, with almost equal probability regardless of\nthe temperature. Vicuna’s outcomes are always ENFJ when\nτ = 0 .01, while the dominance of this type is signifi-\ncantly affected by an increase in temperature, leading to out-\ncomes distributed especially over all E-prefixed types. SO-\nLAR, Dolphin, NeuralChat, and Llama3-8 perfectly match\nthe conditioning type in 12, 10, 9, and 8 out of 16 cases, for\nτ = 0.01; otherwise they mostly fail by adopting a single\ntype different from the conditioning. Also, for higher tem-\nperature, SOLAR and Llama3-8 tend to maintain this be-\nhavior, while NeuralChat and Dolphin appear to be more\naffected by the temperature. Falcon focuses on ESTJ type\nwhen τ = 0.01, while its outcomes become heavily dis-\ntributed over several types, regardless of the conditioning\ntype, when τ = 0.7. Concerning Llama2-7 and Llama2-13,\nfor 9 and 7, resp., out of 16 conditionings, their outcomes are\nalways ENFJ at 100%, when τ = 0.01, while for increased\ntemperature, they still tend to ENFJ and have similar distri-\nbution of the dominant types over the various conditionings.\nThe latter aspect also emerges for Gemma and Phi3, which\nshow ENFJ and ENFP under most conditionings.\nIt is also worth noticing that models sharing a com-\nmon foundational baseline can behave differently from each\nother; for instance, NeuralChat and Dolphin behave gener-\nally better than Mistral, as well as SOLAR upon Llama2-7.\nBFI test. Table 3(right) shows the change percentage\nwhen conditioning each model to one of the BFI factors\n(symbol ↑ near a factor f means that a model was prompted\nby setting the maximum score for f). If we exclude Mistral,\nMixtral and Falcon, all the other models benefit from the\nconditioning on the personality factor. In some cases, we no-\ntice a significant increase percentage in the average score as-\nsigned to the conditioning factor, mostly regardless the tem-\nperature setting: for instance, Extraversion is mainly empha-\nsized by SOLAR (up to +47%) and Dolphin (up to +38%),\nConscientiousness by Dophin (up to +40%), or Openness by\nLlama3-8 (up to +43%). The conditioning on Neuroticism is\nthe most effective, with a peak of above 230% increment by\nLlama3-8 and 100% or above by Gemma and Phi3. This has\nlead to reach the perfect outcome by means of the condition-\ning (i.e., maximum score of 5.0 assigned by a model) in the\nfollowing cases: Llama2-13 and SOLAR on Extraversion;\nLlama3-8, NeuralChat and Phi3 on Agreeableness; Llama2-\n13 and Llama3-8 on Conscientiousness; Llama3-8 on Neu-\nroticism; Llama2-13, Llama3-8, and Gemma on Openness.\nNote that such cases only occurred for τ = 0.01.\nRQ2 — Summary. By instructing LLM agents to emu-\nlate human personalities, we observed varying behaviors. In\nmost cases, especially for higher temperature, the models\ndisregarded the conditioning on the personality type or fac-\ntor, autonomously adopting personalities different from the\none specified in the prompt, or, like Mistral and Mixtral, just\nkeeping their “`ınherent” personality. Few exceptions are rep-\nresented by SOLAR, Dolphin, NeuralChat, and Llama3-8 on\nboth tests, and additionally Llama2-13 on BFI.\nRQ3: Role&Prompt-conditioned Personalities\nWe summarize here main findings about our evaluation\nof RQ3; comprehensive results are reported in Extended\nVer. A10.\nMBTI test. Combining personality- and role-conditioning\ncan sometimes be useful for better mimicking human per-\nsonalities, especially by those agents that already show\nhigher adaptiveness through personality-conditioning alone.\nThe benefits of the double conditioning are evident for SO-\nLAR, NeuralChat, Llama3-8, and Dolphin, regardless of the\ntemperature setting. Personalities typically associated with\nthe role of teacher would be mimicked with greater accu-\nracy, in particular ENFJ, almost perfectly captured by 9 out\nof 12 models, and ENFP. Moreover, an increase in temper-\nature might allow models to explore additional personality-\nrole pairings, although with limited success in most cases.\nBFI test.Also for the BFI test, the double conditioning can\nlead to enhance the agent’s abilities to mimic human per-\nsonalities in some cases. All models but Mistral and Mixtral\nare strongly sensitive to the conditioning on Neuroticism,\nwhile on the other factors, SOLAR, Dolphin, NeuralChat,\nLlama3-8 and Llama2-13 also tend to increase their score\nw.r.t. the conditioning factor for some or all the condition-\ning roles. Also, the double conditioning leads to the per-\nfect outcome (i.e., score 5.0) at least in the same cases as\nin RQ2, with the addition of Dolphin and Phi3 on Conscien-\ntiousness, Llama2-13 on Neuroticism, Phi3 and Gemma on\nOpenness. By contrast, as already observed for RQ2, Mis-\ntral and Mixtral still disregard the conditionings, and even\n1360\nτ = 0.01 τ = 0.70\nMixtral 0.062 ±0.166 0.060 ±0.168\nLlama2-13 0.283 ±0.433 0.265 ±0.348\nSOLAR 0.785 ±0.391 0.744 ±0.353\nLlama3-8 0.517 ±0.487 0.479 ±0.408\nMistral 0.062 ±0.242 0.062 ±0.169\nNeuralChat 0.577 ±0.479 0.498 ±0.328\nDolphin 0.654 ±0.459 0.633 ±0.379\nVicuna 0.062 ±0.242 0.120 ±0.232\nLlama2-7 0.062 ±0.242 0.098 ±0.229\nFalcon 0.190 ±0.389 0.079 ±0.062\nGemma 0.188 ±0.361 0.196 ±0.349\nPhi3 0.298 ±0.445 0.271 ±0.342\n↑ Extrav\ner. ↑ Agreea. ↑ Conscien. ↑ Neuroti. ↑ Open.\nτ 0.01 0.70 0.01 0.70 0.01 0.70 0.01 0.70 0.01 0.70\nMixtral 0.0 0.4 0.0 0.2 0.0 1.6 0.0 -0.4 0.0 -0.5\nLlama2-13 3.8 14.3 -2.3 -0.5 25.7 15.6 44.0 77.1 13.0 11.9\nSOLAR 47.4 41.6 40.7 33.1 32.5 31.1 42.4 52.4 25.0 23.2\nLlama3-8 11.2 22.9 7.1 11.7 0.0 8.7 233.3 150.8 42.6 34.8\nMistral 0.0 -1.8 0.0 4.7 0.0 -5.0 0.0 -1.4 0.0 1.3\nNeuralChat 25.3 27.7 25.0 25.5 25.0 30.1 61.9 50.7 21.1 24.2\nDolphin 37.5 30.9 24.2 15.3 40.0 30.3 47.0 41.4 22.5 20.0\nVicuna 11.9 1.1 -1.9 6.0 18.5 10.0 66.7 16.5 50.0 7.9\nLlama2-7 7.2 5.2 5.7 -14.0 31.1 12.1 79.6 47.1 -3.2 4.1\nFalcon 0.0 -3.1 0.0 -1.5 0.0 -2.3 7.7 2.4 5.0 -5.4\nGemma 27.2 22.9 10.4 11.9 13.1 12.2 100.0 85.1 19.3 19.4\nPhi3 16.8 15.0 7.1 5.5 16.2 14.5 122.1 99.0 7.9 8.0\nTable 3: (RQ2) On the left, average accuracy results on the Personality-Conditioned MBTI test. On the right, percentage\nincrease results on the Personality-Conditioned BFI test w.r.t. the unconditioned BFI test (cf. Fig. 5). (Bold and underlined\nvalues correspond to the highest and second-highest values per column, respectively).\nsome negative side effects arise from the double condition-\ning (i.e., decreased score), such as for both Llama2 models\non Agreeableness, and Falcon in most cases.\nConclusions\nGiven the recent advancements in unveiling human-like be-\nhaviors in LLMs and the widespread use of computational\nLLM agents, comprehending the inherent personalities ex-\npressed by these agents becomes crucial for fostering re-\nsponsible development in human-computer interactions and\nensuring a safe deployment of these agents in our society.\nIn this study, we contributed to advancing our knowledge\nof human-like personalities in computational agents, based\non the most relevant and widely used Open LLMs. By em-\nploying the Myers-Briggs and BigFive personality tests, we\nexplored the capability of 12 Open LLM agents to mirror\nspecific personality types when conditioned with particular\nprompts, incorporating constraints on both personality types\nor factors, as well as representative roles (i.e., human pro-\nfessions) associated with these personalities.\nOur research questions shed light on the emergence of a\nfootprint identity among LLMs based on their distinguish-\nable intrinsic personality types, with a notable heterogene-\nity in how these models mirror human personality traits\nthrough prompt conditioning on specific personalities and\nroles. Models such as SOLAR, Dolphin, NeuralChat, and\nLlama3-8 have demonstrated remarkable mimicking capa-\nbilities, while the majority rather show closed-mindedness.\nWe believe that our findings might serve for assisting a re-\nsponsible development of human-like computational agents.\nClosed models? It should be emphasized that our ap-\nproach and evaluation methodology are equally applicable\nto closed models (cf. Extended Ver. A13 for results on the\nnew GPT-4o). Nonetheless, in the spirit of open science, we\nchose to focus on open LLMs for their greater transparency,\nlocal execution capabilities, and customization options, en-\nabling more in-depth and cost-effective investigations.\nOur future research involves fine-tuning and aligning\nopen LLMs with personality-aware data. This will enhance\nthe simulation of human traits, aiming at developing models\nthat better emulate human behaviors in various tasks, poten-\ntially benefiting areas like education and training.\nLimitations\nChallenges in models’ deployment. While some of the\nmodels used in this work are also available in larger sizes,\ne.g., Falcon 180B, Llama3-70B and Llama2-65B, deploying\nthem poses challenges due to higher computational require-\nments for our hardware, including excessive quantization.\nTo prevent performance degradation and ensure easier repro-\nducibility, we focused on models with more manageable de-\nployments. This decision does not compromise our findings,\nas smaller models have been recognized to excel in bench-\nmarks (e.g., AlpacaEval — Community tab) and might be\ncomparable to larger models (Abdin et al. 2024).\nLimited explainability. Despite the availability of some\ninformation on the training methodology and data adopted\nby Open LLMs, their individual impact on the models’ re-\nsponses cannot be quantified at this stage, due to the limits\nimposed by the models’ owners in accessing full details of\nthe underlying models. Future investigations will delve into\nthe specific factors contributing to our observed findings.\nEvaluation tools. We acknowledge the availability of an\nonline MBTI test provided by Myers&Briggs Foundation.\nHowever, each assessment using it costs ∼$60, and consid-\nering our need for around 20,000 assessments, the overall\nexpense would become impractical. Consequently, we opted\nfor the free-to-use 16personalities.com, a reliable alternative\nassessment tool. The above remarks do not apply to the BFI\nsetting, since our reference BFI test can be scored offline\nusing a pre-defined set of rules (John and Srivastava 1999).\nAcknowledgements\nAT, resp. LLC, was supported by project “Future\nArtificial Intelligence Research (FAIR)” spoke 9\n(H23C22000860006), resp. project SERICS (PE00000014),\nboth under the MUR National Recovery and Resilience\nPlan funded by the EU - NextGenerationEU.\n1361\nReferences\nAbdin, M.; Jacobs, S. A.; Awan, A. A.; et al. 2024. Phi-3\ntechnical report: A highly capable language model locally\non your phone. arXiv:2404.14219.\nAgashe, S.; Fan, Y .; and Wang, X. E. 2023. Evaluat-\ning Multi-Agent Coordination Abilities in Large Language\nModels. arXiv:2310.03903.\nAlmazrouei, E.; Alobeidli, H.; Alshamsi, A.; et al.\n2023. The Falcon Series of Open Language Models.\narXiv:2311.16867.\nBreum, S. M.; Egdal, D. V .; Mortensen, V . G.; Møller, A. G.;\nand Aiello, L. M. 2023. The Persuasive Power of Large\nLanguage Models. arXiv:2312.15523.\nBubeck, S.; Chandrasekaran, V .; Eldan, R.; et al. 2023.\nSparks of Artificial General Intelligence: Early experiments\nwith GPT-4. arXiv:2303.12712.\nCai, T.; Wang, X.; Ma, T.; Chen, X.; and Zhou, D. 2023.\nLarge language models as tool makers. arXiv:2305.17126.\nCao, X.; and Kosinski, M. 2024. Large language models\nand humans converge in judging public figures’ personali-\nties. PNAS Nexus, 3(10).\nCaron, G.; and Srivastava, S. 2022. Identifying and\nmanipulating the personality traits of language models.\narXiv:2212.10276.\nChen, H.; and Ding, N. 2023. Probing the Creativity of\nLarge Language Models: Can models produce divergent se-\nmantic association? arXiv:2310.11158.\nChen, W.; Su, Y .; Zuo, J.; et al. 2023. Agentverse: Facili-\ntating multi-agent collaboration and exploring emergent be-\nhaviors in agents. arXiv:2308.10848.\nChiang, W.-L.; Li, Z.; Lin, Z.; et al. 2023. Vicuna: An\nOpen-Source Chatbot Impressing GPT-4 with 90%* Chat-\nGPT Quality.\nDe Marzo, G.; Pietronero, L.; and Garcia, D. 2023. Emer-\ngence of Scale-Free Networks in Social Interactions among\nLarge Language Models. arXiv:2312.06619.\nDeng, X.; Gu, Y .; Zheng, B.; Chen, S.; Stevens, S.; Wang,\nB.; Sun, H.; and Su, Y . 2023. Mind2Web: Towards a Gener-\nalist Agent for the Web. arXiv:2306.06070.\nDubey, A.; Jauhri, A.; Pandey, A.; et al. 2024. The Llama 3\nHerd of Models. arXiv:2407.21783.\nFeizi-Derakhshi, A.-R.; Feizi-Derakhshi, M.-R.; Ramezani,\nM.; et al. 2022. Text-based automatic personality prediction:\na bibliographic review.Journal of Computational Social Sci-\nence, 5(2): 1555–1593.\nFrisch, I.; and Giulianelli, M. 2024. LLM Agents in In-\nteraction: Measuring Personality Consistency and Linguis-\ntic Alignment in Interacting Populations of Large Language\nModels. In Procs. of the 1st Workshop on Personalization of\nGenerative AI Systems, 102–111.\nGao, C.; Lan, X.; Lu, Z.; Mao, J.; Piao, J.; Wang, H.;\nJin, D.; and Li, Y . 2023. S3: Social-network Simulation\nSystem with Large Language Model-Empowered Agents.\narXiv:2307.14984.\nGou, Z.; Shao, Z.; Gong, Y .; Yang, Y .; Huang, M.; Duan,\nN.; Chen, W.; et al. 2023. Tora: A tool-integrated reasoning\nagent for mathematical problem solving. arXiv:2309.17452.\nGuo, J.; Yang, B.; Yoo, P.; Lin, B. Y .; Iwasawa, Y .;\nand Matsuo, Y . 2023a. Suspicion-agent: Playing imper-\nfect information games with theory of mind aware gpt-4.\narXiv:2309.17277.\nGuo, Z.; Jin, R.; Liu, C.; Huang, Y .; Shi, D.; Supryadi; Yu,\nL.; Liu, Y .; Li, J.; Xiong, B.; and Xiong, D. 2023b. Eval-\nuating Large Language Models: A Comprehensive Survey.\narXiv:2310.19736.\nHao, S.; Gu, Y .; Ma, H.; Hong, J.; Wang, Z.; Wang, D.; and\nHu, Z. 2023. Reasoning with Language Model is Planning\nwith World Model. InProcs. of the 2023 Conf. on Empirical\nMethods in Natural Language Processing (EMNLP), 8154–\n8173.\nHuang, J.; Gu, S. S.; Hou, L.; Wu, Y .; Wang, X.; Yu, H.; and\nHan, J. 2022. Large Language Models Can Self-Improve.\narXiv:2210.11610.\nHuang, J.-t.; Wang, W.; Li, E. J.; Lam, M. H.; Ren, S.; Yuan,\nY .; Jiao, W.; Tu, Z.; and Lyu, M. R. 2023. Who is Chat-\nGPT? Benchmarking LLMs’ Psychological Portrayal Using\nPsychoBench. arXiv:2310.01386.\nJi, Y .; Wu, W.; Zheng, H.; Hu, Y .; Chen, X.; and He, L.\n2023. Is chatgpt a good personality recognizer? a prelim-\ninary study. arXiv:2307.03952.\nJiang, A. Q.; Sablayrolles, A.; Mensch, A.; et al. 2023a. Mis-\ntral 7B. arXiv:2310.06825.\nJiang, A. Q.; Sablayrolles, A.; Roux, A.; et al. 2024. Mixtral\nof Experts. arXiv:2401.04088.\nJiang, G.; Xu, M.; Zhu, S.-C.; Han, W.; Zhang, C.; and Zhu,\nY . 2022. Mpi: Evaluating and inducing personality in pre-\ntrained language models. arXiv:2206.07550.\nJiang, H.; Zhang, X.; Cao, X.; Kabbara, J.; and Roy,\nD. 2023b. Personallm: Investigating the ability of gpt-\n3.5 to express personality traits and gender differences.\narXiv:2305.02547.\nJohn, O.; Naumann, L.; and Soto, C. 2008. Paradigm shift\nto the integrative big five trait taxonomy: History, measure-\nment, and conceptual issues. In Handbook of Personality:\nTheory and Research, 3 Edn., 114–158.\nJohn, O.; and Srivastava, S. 1999. The Big-Five Trait Taxon-\nomy: History, Measurement, and Theoretical Perspectives.\nIn Handbook of Personality: Theory and Research, vol-\nume 2.\nKim, D.; Park, C.; Kim, S.; et al. 2023. SOLAR 10.7B:\nScaling Large Language Models with Simple yet Effective\nDepth Up-Scaling. arXiv:2312.15166.\nLi, G.; Hammoud, H. A. A. K.; Itani, H.; Khizbullin, D.;\nand Ghanem, B. 2023. Camel: Communicative agents for\nmind exploration of large scale language model society.\narXiv:2303.17760.\nLi, T.; Zheng, X.; and Huang, X. 2023. Tailoring Personality\nTraits in Large Language Models via Unsupervisedly-Built\nPersonalized Lexicons. arXiv:2310.16582.\n1362\nLin, B. Y .; Fu, Y .; Yang, K.; Brahman, F.; Huang, S.; Bha-\ngavatula, C.; Ammanabrolu, P.; Choi, Y .; and Ren, X. 2023.\nSwiftsage: A generative agent with fast and slow thinking\nfor complex interactive tasks. arXiv:2305.17390.\nLiu, Z.; Zhang, Y .; Li, P.; Liu, Y .; and Yang, D.\n2023. Dynamic LLM-Agent Network: An LLM-agent\nCollaboration Framework with Agent Team Optimization.\narXiv:2310.02170.\nLynn, V .; Balasubramanian, N.; and Schwartz, H. A. 2020.\nHierarchical Modeling for User Personality Prediction: The\nRole of Message-Level Attention. In Procs. of the 58th An-\nnual Meeting of the Association for Computational Linguis-\ntics, 5306–5316.\nMao, S.; Zhang, N.; Wang, X.; Wang, M.; Yao, Y .; Jiang, Y .;\nXie, P.; Huang, F.; and Chen, H. 2023. Editing Personality\nfor LLMs. arXiv:2310.02168.\nMiotto, M.; Rossberg, N.; and Kleinberg, B. 2022. Who\nis GPT-3? An exploration of personality, values and demo-\ngraphics. In Procs. of Workshop on Natural Language Pro-\ncessing and Computational Social Science, 218–227.\nMyers, I. B. 1962. The Myers-Briggs Type Indicator: Man-\nual (1962).\nMyers, I. B. 1985. A Guide to the Development and Use\nof the Myers-Briggs Type Indicator: Manual. Consulting\nPsychologists Press.\nNadeem, M.; Bethke, A.; and Reddy, S. 2021. StereoSet:\nMeasuring stereotypical bias in pretrained language mod-\nels. In Procs. of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th Int. Joint Conf.\non Natural Language Processing (Volume 1: Long Papers),\n5356–5371.\nPan, K.; and Zeng, Y . 2023. Do llms possess a personal-\nity? making the mbti test an amazing evaluation for large\nlanguage models. arXiv:2307.16180.\nPark, J. S.; O’Brien, J.; Cai, C. J.; Morris, M. R.; Liang, P.;\nand Bernstein, M. S. 2023. Generative agents: Interactive\nsimulacra of human behavior. In Procs. of the 36th Annual\nACM Symposium on User Interface Software and Technol-\nogy, 1–22.\nRao, H.; Leung, C.; and Miao, C. 2023. Can ChatGPT\nAssess Human Personalities? A General Evaluation Frame-\nwork. In Findings of the Association for Computational Lin-\nguistics: EMNLP 2023, 1184–1194.\nSafdari, M.; Serapio-Garc ´ıa, G.; Crepy, C.; Fitz, S.;\nRomero, P.; Sun, L.; Abdulhai, M.; Faust, A.; and Matari ´c,\nM. 2023. Personality traits in large language models.\narXiv:2307.00184.\nShanahan, M.; McDonell, K.; and Reynolds, L. 2023. Role\nplay with large language models. Nature, 1–6.\nSong, C. H.; Wu, J.; Washington, C.; Sadler, B. M.; Chao,\nW.-L.; and Su, Y . 2023. Llm-planner: Few-shot grounded\nplanning for embodied agents with large language models.\nIn Procs. of the IEEE/CVF Int. Conf. on Computer Vision,\n2998–3009.\nTeam, G. 2024. Gemma: Open models based on gemini re-\nsearch and technology. arXiv:2403.08295.\nTouvron, H.; Martin, L.; Stone, K.; et al. 2023. Llama\n2: Open Foundation and Fine-Tuned Chat Models.\narXiv:2307.09288.\ntse Huang, J.; Wang, W.; Lam, M. H.; Li, E. J.; Jiao, W.; and\nLyu, M. R. 2023. ChatGPT an ENFJ, Bard an ISTJ: Em-\npirical Study on Personalities of Large Language Models.\narXiv:2305.19926.\nV Ganesan, A.; Lal, Y . K.; Nilsson, A.; and Schwartz, H.\n2023. Systematic Evaluation of GPT-3 for Zero-Shot Per-\nsonality Estimation. In Procs. of the 13th Workshop on Com-\nputational Approaches to Subjectivity, Sentiment, and Social\nMedia Analysis, 390–400.\nWang, G.; Xie, Y .; Jiang, Y .; Mandlekar, A.; Xiao, C.; Zhu,\nY .; Fan, L.; and Anandkumar, A. 2023a. V oyager: An\nopen-ended embodied agent with large language models.\narXiv:2305.16291.\nWang, X.; Xiao, Y .; tse Huang, J.; Yuan, S.; Xu, R.; Guo,\nH.; Tu, Q.; Fei, Y .; Leng, Z.; Wang, W.; Chen, J.; Li, C.; and\nXiao, Y . 2024. InCharacter: Evaluating Personality Fidelity\nin Role-Playing Agents through Psychological Interviews.\narXiv:2310.17976.\nWang, Z.; Cai, S.; Liu, A.; Ma, X.; and Liang, Y . 2023b.\nDescribe, explain, plan and select: Interactive planning\nwith large language models enables open-world multi-task\nagents. arXiv:2302.01560.\nWu, Q.; Bansal, G.; Zhang, J.; et al. 2023. AutoGen: En-\nabling Next-Gen LLM Applications via Multi-Agent Con-\nversation Framework. arXiv:2308.08155.\nYang, F.; Quan, X.; Yang, Y .; and Yu, J. 2021. Multi-\nDocument Transformer for Personality Detection. Procs.\nof the AAAI Conf. on Artificial Intelligence, 35(16): 14221–\n14229.\nYang, K.-C.; and Menczer, F. 2023. Anatomy of an AI-\npowered malicious social botnet. arXiv:2307.16336.\nYang, T.; Shi, T.; Wan, F.; Quan, X.; Wang, Q.; Wu, B.;\nand Wu, J. 2023. PsyCoT: Psychological Questionnaire as\nPowerful Chain-of-Thought for Personality Detection. In\nFindings of the Association for Computational Linguistics:\nEMNLP 2023, 3305–3320.\nZhao, P.; Jin, Z.; and Cheng, N. 2023. An in-depth survey\nof large language model-based artificial intelligence agents.\narXiv:2309.14365.\nZhao, Z.; Wallace, E.; Feng, S.; Klein, D.; and Singh, S.\n2021. Calibrate Before Use: Improving Few-shot Perfor-\nmance of Language Models. In Procs. of the 38th Int. Conf.\non Machine Learning (ICML), volume 139, 12697–12706.\nZhou, S.; Xu, F. F.; Zhu, H.; Zhou, X.; Lo, R.; Sridhar,\nA.; Cheng, X.; Bisk, Y .; Fried, D.; Alon, U.; et al. 2023.\nWebarena: A realistic web environment for building au-\ntonomous agents. arXiv:2307.13854.\nZhu, X.; Chen, Y .; Tian, H.; et al. 2023. Ghost in the\nMinecraft: Generally Capable Agents for Open-World En-\nviroments via Large Language Models with Text-based\nKnowledge and Memory. arXiv:2305.17144.\nZiems, C.; Shaikh, O.; Zhang, Z.; Held, W.; Chen, J.; and\nYang, D. 2023. Can large language models transform com-\nputational social science? Computational Linguistics, 1–53.\n1363",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.462089478969574
    },
    {
      "name": "Psychology",
      "score": 0.3489321768283844
    },
    {
      "name": "Cognitive science",
      "score": 0.34492361545562744
    }
  ],
  "institutions": [],
  "cited_by": 5
}