{
  "title": "Integrating prior knowledge to build transformer models",
  "url": "https://openalex.org/W4390499460",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1975278566",
      "name": "Pei Jiang",
      "affiliations": [
        "Tokyo Medical and Dental University"
      ]
    },
    {
      "id": "https://openalex.org/A2100290451",
      "name": "Takashi Obi",
      "affiliations": [
        "Tokyo Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2486785783",
      "name": "Yoshikazu Nakajima",
      "affiliations": [
        "Tokyo Medical and Dental University"
      ]
    },
    {
      "id": "https://openalex.org/A1975278566",
      "name": "Pei Jiang",
      "affiliations": [
        "Tokyo Medical and Dental University"
      ]
    },
    {
      "id": "https://openalex.org/A2100290451",
      "name": "Takashi Obi",
      "affiliations": [
        "Tokyo Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2486785783",
      "name": "Yoshikazu Nakajima",
      "affiliations": [
        "Tokyo Medical and Dental University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4311373233",
    "https://openalex.org/W4221125739",
    "https://openalex.org/W4293767307",
    "https://openalex.org/W4296580115",
    "https://openalex.org/W3204603732",
    "https://openalex.org/W3169129566",
    "https://openalex.org/W3186643354",
    "https://openalex.org/W3087845270",
    "https://openalex.org/W3118799843",
    "https://openalex.org/W3157349954",
    "https://openalex.org/W3164570135",
    "https://openalex.org/W3094589761",
    "https://openalex.org/W3161331151",
    "https://openalex.org/W4223519356",
    "https://openalex.org/W3167899070",
    "https://openalex.org/W3184842396",
    "https://openalex.org/W3200581805",
    "https://openalex.org/W2892741787",
    "https://openalex.org/W2991414967",
    "https://openalex.org/W2616247523",
    "https://openalex.org/W2282821441",
    "https://openalex.org/W3107568551",
    "https://openalex.org/W3198148990",
    "https://openalex.org/W3173631909",
    "https://openalex.org/W4283077289",
    "https://openalex.org/W3209846823",
    "https://openalex.org/W3164508800",
    "https://openalex.org/W3184255274",
    "https://openalex.org/W3207066068",
    "https://openalex.org/W3175110185",
    "https://openalex.org/W4318028366",
    "https://openalex.org/W4221081531",
    "https://openalex.org/W6600445788",
    "https://openalex.org/W3124211791",
    "https://openalex.org/W4296343374",
    "https://openalex.org/W2104148727",
    "https://openalex.org/W3034368386",
    "https://openalex.org/W2962936809",
    "https://openalex.org/W2953796333",
    "https://openalex.org/W4206706211",
    "https://openalex.org/W6607687417",
    "https://openalex.org/W4313229413",
    "https://openalex.org/W6944027168",
    "https://openalex.org/W3138154797",
    "https://openalex.org/W3102564565"
  ],
  "abstract": "Abstract The big Artificial General Intelligence models inspire hot topics currently. The black box problems of Artificial Intelligence (AI) models still exist and need to be solved urgently, especially in the medical area. Therefore, transparent and reliable AI models with small data are also urgently necessary. To build a trustable AI model with small data, we proposed a prior knowledge-integrated transformer model. We first acquired prior knowledge using Shapley Additive exPlanations from various pre-trained machine learning models. Then, we used the prior knowledge to construct the transformer models and compared our proposed models with the Feature Tokenization Transformer model and other classification models. We tested our proposed model on three open datasets and one non-open public dataset in Japan to confirm the feasibility of our proposed methodology. Our results certified that knowledge-integrated transformer models perform better (1%) than general transformer models. Meanwhile, our proposed methodology identified that the self-attention of factors in our proposed transformer models is nearly the same, which needs to be explored in future work. Moreover, our research inspires future endeavors in exploring transparent small AI models.",
  "full_text": "Vol.:(0123456789)1 3\nInt. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \nhttps://doi.org/10.1007/s41870-023-01635-7\nORIGINAL RESEARCH\nIntegrating prior knowledge to¬†build transformer models\nPei¬†Jiang1 ¬†¬∑ Takashi¬†Obi2 ¬†¬∑ Yoshikazu¬†Nakajima1¬†\nReceived: 17 May 2023 / Accepted: 14 November 2023 / Published online: 2 January 2024 \n¬© The Author(s) 2024\nAbstract The big Artificial General Intelligence mod-\nels inspire hot topics currently. The black box problems of \nArtificial Intelligence (AI) models still exist and need to be \nsolved urgently, especially in the medical area. Therefore, \ntransparent and reliable AI models with small data are also \nurgently necessary. To build a trustable AI model with small \ndata, we proposed a prior knowledge-integrated transformer \nmodel. We first acquired prior knowledge using Shapley \nAdditive exPlanations from various pre-trained machine \nlearning models. Then, we used the prior knowledge to \nconstruct the transformer models and compared our pro-\nposed models with the Feature Tokenization Transformer \nmodel and other classification models. We tested our pro-\nposed model on three open datasets and one non-open public \ndataset in Japan to confirm the feasibility of our proposed \nmethodology. Our results certified that knowledge-integrated \ntransformer models perform better (1%) than general trans-\nformer models. Meanwhile, our proposed methodology \nidentified that the self-attention of factors in our proposed \ntransformer models is nearly the same, which needs to be \nexplored in future work. Moreover, our research inspires \nfuture endeavors in exploring transparent small AI models.\nKeywords AI¬†¬∑ Knowledge¬†¬∑ SHAP¬†¬∑ Transformer¬†¬∑ \nReliable AI\n1 Introduction\nArtificial Intelligence (AI) technology has been used in vari-\nous fields in our current society [1‚Äì5]. AI technology makes \nan innovative society possible and changes our lifestyles. \nFor example, automatic car driving [6 ‚Äì9], face recognition \nsystems [10‚Äì13], and computer aid detection in the medical \narea [14‚Äì17]. However, AI models are generally based on \nlarge data and huge parameters, called big AI models, espe-\ncially in the computer version (diffusion model [18]) and the \nfield of natural language processing. The robust Large Lan-\nguage Model (LLM): Generative Pre-trained Transformer \n(GPT) models [19] make our daily work more convenient \nand will even¬†change our work life in the future. The GPT \nmodels have been used in various fields [20]. The trans-\nfer-based various models [20‚Äì 27] indicate the possibility \nof Artificial General Intelligence (AGI) models. However, \neven with current AI technology, a prominent data-based AI \nmodel is impossible in some research fields. For example, \nin the medical area and biomedical, big data are not always \navailable other than big AI models. Researcher Andrew \nWu states the importance of ‚Äúbig AI in small data‚Äù [28] \nand¬†also certificated the necessity of efficient AI models for \nsmall datasets. Moreover, a few million parameters in big AI \nmodels also cost colossal energy. Research about the energy \nsaved by small AI models is urgently necessary. Therefore, \nwe proposed to build AI models based on prior knowledge.\nBesides the big AI models and huge parameter prob-\nlems, some other limitations still exist in AI research. The \nblack box problem is one of the most pressing issues in AI \nstudies [29‚Äì 33]. The black box problems lower the reli-\nability of AI models. Meanwhile, current AI models are \nstatistical-analysis-based models, not logic-theory-based \nmodels. This keeps the uncertainty of current AI models, \n * Takashi Obi \n obi.t.aa@m.titech.ac.jp\n1 Institute of¬†Biomaterials and¬†Bioengineering, Tokyo Medical \nand¬†Dental University, Kanda-Surugadai, Tokyo, Japan\n2 Institute of¬†Innovative Research, Tokyo Institute \nof¬†Technology, R2-60, Nagatsutachou 4259, Midori Ward, \nYokohama, Kanagawa, Japan\n1280 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\neven though the big AI models are efficient. Therefore, \nunderstanding the AI models becomes necessary.\nTo clarify the AI models, Explainable AI (XAI) [34‚Äì38] \nhas become one highlight topic in the AI research field. \nCurrently, two kinds of XAI models exist: intrinsic (rule-\nbased) and¬†post hoc models [39]. The intrinsic models \nexplain models by restricting the rules of machine learning \nmodels, e.g., linear regression, logistic analysis, and Grad-\nCAM [40]. In contrast, post hoc models interpret models \nafter training, such as Local interpretable model-agnos -\ntic explanations (LIME) [ 41, 42] and Shapley Additive \nexPlanations (SHAP) [43]. The SHAP method is the most \nrobust agent explanation model currently. SHAP method \nhas been used in many fields [44‚Äì 53] and was certificated \nrobust [54‚Äì 56]. The SHAP methods allow us to interpret \nthe black box models and know the local and global rea-\nsons for one prediction or classification. There are also \ntwo kinds of SHAP methods: model agnostic (Kernel \nSHAP) and model specific (Tree SHAP, deep SHAP) [ 43, \n57]. The model-specific SHAP methods are designed to \nexplain the specific models to decrease the calculation or \nloss of the complex models. They can only be used for a \nparticular situation. In contrast, the kernel SHAP can be \nused for any model type. However, the SHAP method is \na causal-inference-based methodology. The logic among \nAI models still needs to be clarified. The SHAP meth-\nodology just increased the transparency of AI models in \nsome aspects. Research on AI reliability and transparency \nis still urgently necessary. Are there also ways to explain \nAI models by instructing the rules of models? This still \nneeds to be explored.\nEven though the SHAP method explained AI models in \nsome aspects, it already supplied some knowledge about \nAI models to us humans. Research by Feifei Li [58] certi-\nfies that human interaction will improve the performance \nof AI models, while the latest GPT4 models [19] also \ncertify the necessary human insertion in large AI models. \nThese situations show that human-knowledge-integrated \nAI models are one available research direction in AI stud -\nies. Currently, reinforcement models [59] give rewards in \ndecision-making while knowledge distillation [60] models \nfilter the knowledge (weights in layers) in AI models. Is \nthere another efficient way to use knowledge in AI models? \nCan we make human knowledge-integrated AI models pos-\nsible? Furthermore, how can we integrate knowledge into \nAI models efficiently? Our research makes one significant \nstep to answering these questions. In this study, we proposed \nknowledge-integrated AI transformer models to improve the \ntrust and efficiency of AI models. The main contribution of \nour study was summarized as follows:\n‚Ä¢ Prior knowledge-integrated transformer AI models were \nproposed in our study.\n‚Ä¢ Our proposed methodology paves the way to improve \nthe transparency and reliability of AI models.\n‚Ä¢ Our study is one significant technical try for research-\ning small and trustable AI models.\n‚Ä¢ Our proposed methodology certified the possibility of \nbuilding knowledge-integrated neural network models.\n‚Ä¢ Our research helps us understand the logic of attention \nmodels.\nThe rest of this paper is organized as follows. We make \na small literature review in Sect.¬† 2. Our proposed meth-\nodology is introduced in Sect.¬† 3. Section¬† 4 describes the \nused datasets. We show the detailed results of our study \nin Sect.¬†5. Then, we discuss our effects in Sect.¬† 6. Finally, \nwe made one conclusion and discussed our future research \ndirection in Sect.¬† 7.\n2  Literature review\n2.1  Literature about¬†prior knowledge\nSome studies focused on building logic-based, trustable, \nexplainable AI models [61‚Äì64]. Besides XAI to explore and \nexplain the AI models to improve the reliability of AI mod-\nels, some other studies try to build trustable AI models. Philip \nSlingerland et¬†al. proposed adapting proposed trustable AI mod-\nels to space mission autonomy [65], while Robin Cohen, Etc. \n[66] Sketched ways in which trust modeling may be leveraged \ntowards trustable AI. Based on our current knowledge, few stud-\nies propose building knowledge-integrated AI models as to how \nto build trustable AI models. Meanwhile, some researchers state \nthat AI models with human inserting can perform better [58].\nYann LeCun [67] proposed a word model that states \nwe can build models like human learning progress. Our \nhumans use our knowledge to make decisions and solve \nproblems. Can the AI model also integrate knowledge to \nbuild more reliable models? Especially, do the AI mod-\nels combine human knowledge to optimize themselves? \nIntegrating knowledge to build AI models becomes one \nnew research topic. However, there are few researchers \nfocused on building knowledge-integrated AI models. \nMeanwhile, what is human knowledge, and how can¬† \nhuman knowledge¬†be integrated into AI models? There \nis no standardization currently. Therefore, we proposed \nusing prior knowledge to build models. However, what \ncan be treated as prior knowledge? While some studies use \nthe pre-trained models as prior knowledge, we proposed \nusing the XAI results to build models, especially building \nAI models based on small datasets, when most research \nfocused on big data-based big AI models [19].\n1281Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\n2.2  Literature about¬†transformer models\nAt present, the transformer models [68, 69], which are the base \nmodel of generative AI models, become one highlight topic \nin AI. The attention model [70] is the primary structure of the \ntransformer model. Using attention, we can check the connec-\ntions among factors, like the research using attention to predict \nthe connection among language tokens [23]. Even though the \nattention of the transformer model is also based on the Neural \nNetwork (NN) models, the attention models can help us under-\nstand the AI models in some aspects. The attention models in the \nLLM model can show the relationship among tokens. Especially \nafter the attention model was used in the computer vision field, \nthe vision transformer models can explain the images to let us \nknow which areas are important [71]. Therefore, we also inte-\ngrated prior knowledge to build transformer models for tabular \ndata and compared our results with another tabular data trans-\nformer model: the Feature Tokenization Transformer (FTT) [72] \nmodel. Using self-attention models, we aim to clarify the rela-\ntionship among the input features. Therefore, we can understand \nthe AI models in some aspects.\n3  Methodology\nIn this study, we proposed one knowledge-integrated self-\nattention transformer model. Unlike the attention mecha-\nnism using various methods to adjust the NN model weights, \nwe proposed using ensemble SHAP values as knowledge \nto build transformer models. We first proposed ensemble \nSHAP value calculation methods to acquire more reliable \nknowledge. Then, we used the prior knowledge as the input \nof self-attention transformer models. The whole methodol-\nogy structure is shown in Fig.¬†1.\nCurrently, the SHAP methodology is one of the most \nrobust XAI methods and can be used to explain various \nmodels. Research also certificated the efficiency and robust-\nness of SHAP methods [ 52, 54‚Äì56]. Because the SHAP \nvalue was calculated based on the casual inference theory, \nthe SHAP value will be changed in different models. To \nbalance the effect caused by various models, we proposed \nan ensemble SHAP value, which will consider all models‚Äô \naccuracy and kernel SHAP values. Therefore, we use the \nensemble SHAP values as knowledge to build our models, \nnot the hybrid SHAP value. The details are introduced in the \nfollowing subsection.\n3.1  Ensemble XAI to¬†acquire knowledge\nSHAP predicts an instance x by computing each feature‚Äôs val-\nue‚Äôs contribution to the prediction of one model. The SHAP \nexplanation method computes Shapley‚Äôs values from coali-\ntional game theory. The feature values x  of a data instance \nact as players in a coalition. Shapley values tell us how to \ndistribute the prediction among the features fairly. SHAP \nby appropriate the original model function to new function \nf(x)= gÔøΩzÔøΩÔøΩ = /u1D7190 + ‚àëM\ni=1 /u1D719izÔøΩ\ni . Where zÔøΩ ‚àà{ 0, 1}M  , M is \nthe number of simplified input features, and /u1D719i ‚àà ‚Ñù , which is \ntreated as local factor importance. The z/uni2032.var represents the dataset \nof x , and M has the same feature space. In kernel SHAP, the \ng/parenleft.s1z/uni2032.var/parenright.s1 is linear model. The explanation of x is\nwhere the fx (zÔøΩ) is the function when the z/uni2032.var\ni is 1, while the \nfx (zÔøΩ‚ßµi) is the original function when the z/uni2032.var\ni is zero. The ker-\nnel of /u1D70Bx is /u1D70Bx(ZÔøΩ)= (M ‚àí1)\n‚éõ\n‚éú\n‚éú‚éù\nM\nÔøΩZÔøΩÔøΩ\n‚éû\n‚éü\n‚éü‚é†\nÔøΩZÔøΩÔøΩ(M ‚àíÔøΩZÔøΩÔøΩ)\n where the /uni007C.varz/uni2032.var/uni007C.var is the \nnumber of nonzero entries in z/uni2032.var and z/uni2032.var‚äÜ x represents all z/uni2032.var \nvectors where the nonzero entries are a subset of the entries \nin x.\nIn kernel SHAP /u1D7190 = f(hx (0)) is set as 0, and the loss func-\ntion of kernel SHAP becomes\nKernel SHAP estimated the contribution of instance x by \nappropriate the x using a linear model and treating the weight \nof linear models as the local factor contribution /u1D719i . Although \nthe kernel SHAP can help us understand the factor contribu-\ntion in each model, the value of the factor ranking in each \nmodel is different. Because the kernel SHAP is based on the \n(1)ùúôi(f, x ) =\n/uni2211.s1\nzÔøΩ‚äÜx ÔøΩ\nùúãx (zÔøΩ)/bracketleft.s1fx (zÔøΩ)‚àí fx (zÔøΩ ‚ßµ i)/bracketright.s1\n(2)L\n/parenleft.s2\n/uni0302.s1f,g,/u1D70Bx\n/parenright.s2\n=\n/uni2211.s1\nzÔøΩ‚ààZ\n/bracketleft.s2\n/uni0302.s1f/parenleft.s1hx\n/parenleft.s1zÔøΩ/parenright.s1/parenright.s1‚àí g/parenleft.s1zÔøΩ/parenright.s1/bracketright.s22\n/u1D70Bx\n/parenleft.s1zÔøΩ/parenright.s1\nFig. 1  The proposed methodology flowchart\n1282 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\nappropriate calculation theory, the kernel SHAP values of \ndifferent methods will differ [73]. When the SHAP method \napproximates a linear model, it just uses the predicted output \nof one model, which will affect the predicted outcome by \nhow good the prediction model is. Meanwhile, because the \nmodel-agnostic explanation method only approximates the \npredicted outputs of models, the kernel SHAP values for all \nmodels have the same metric when we analyze one dataset. \nTherefore, our proposed ensemble SHAP method is avail-\nable. Moreover, the goodness of one model also should be \nconsidered when calculating the factor‚Äôs importance. There-\nfore, we also used the precision of the models to adjust the \nranking of the factors. If one model has higher accuracy, it \nwill be more critical in ensemble SHAP value calculation. \nThe calculation is shown as Algorithm¬†1, Where the Acc j is \nthe accuracy of one classification or regression model, The \nN is the number of analytical approaches for one dataset, \nand the Ij is the factor of importance ranking in one analysis. \nTherefore, the single kernel SHAP value cannot stand the \nfundamental rank of factor importance. We proposed using \nensemble SHAP values, shown in Algorithm¬†1. Even though \nwe used local ensemble SHAP as input to build our proposed \nself-attention transformer model, we also checked the global \nensemble SHAP value to confirm that our proposed ensem-\nble SHAP method is efficient in our used datasets, which can \nbe calculated as follows:\nAlthough our previous study already certificated the effi -\nciency of the ensemble SHAP methods [73].\nAlgorithm¬†1  Knowledge acquisition\ni=0, j=0,N is all the number of analysis\nmodels,\nfor N analysis models, select N-1 analysis\nmodel do\nfor j< = N ‚àí 1:do\nWj = exp(Accj)‚àëN‚àí1\ni=1 exp(Accj) where Accj is the\naccuracy of jth analysis in the N-1m odels\nfor i< = M : do\nœÜj = ‚àëM\ni=1 œÜij\nend for\nœÜj = Wj ‚àóœÜj\n(# Forg lobalf actori mportance Ij = Wj ‚àóIj)\nœÜ+= œÜj\n(# Forg lobalf actori mportance I+=I j)\nend for\nœÜ = œÜ\nN\n(# Forg lobalf actori mportance I = I\nN )\nend for\nFinal global factor importance is I\n(3)I=\nN ‚àí1ÔøΩ\nj=1\nW jIj =\nN ‚àí1ÔøΩ\nj=1\nexp(Accj)\n‚àëN ‚àí1\nj=1 exp(Accj)\nMÔøΩ\ni=1\n/u1D719i\n3.2  Prior knowledge to¬†build transformer model\nOur proposed whole methodology flow is shown in Fig.¬† 1. \nWe treated the proposed ensemble SHAP values as prior \nknowledge. Firstly, nine general and robust machine learn-\ning classification models: logistic analysis, Navie Bayside \nclassification, quantitative discriminate analysis,k-nearest \nneighbors classification, AdaBoost, general Decision Tree, \nrandom forest classification, XGBoost, and Multi-Layer Per-\nception classification, were used to make a classification in \nthree classification-task datasets. Then, for one non-open \ndataset, the kernel SHAP was used to explain each classifica-\ntion model and got the contribution (local SHAP value) of \nfactors for each model, while the importance ranking of fac-\ntors was also reviewed. After we got the kernel SHAP value \nof factors, we used our proposed ensemble methodology to \ncalculate the importance of the factors. Finally, we used the \nensemble SHAP value as prior knowledge to build the self-\nattention transformer models. We compared our proposed \nknowledge-integrated self-attention transformer model with \nthe FTT and other machine learning or NN models. Moreo-\nver, we also checked the self-attention of each transformer \nblock in the FTT model and our proposed model. To confirm \nthe efficiency of our models, we also tested various layers of \nself-attention transformer models in this study: 2 layers, 4 \nlayers, 8 layers, and 12 layers. Reviewing the self-attention \nof each layer, we can understand the difference between the \nFTT model and our proposed model. Moreover, attention to \ntransformer models also can help us understand the running \nrules of AI models. After checking the difference among \nvarious layer-deep transformer models, we also compared \nthe average self-attention of our proposed transformer mod-\nels with FTT models (Fig.¬† 7) and the general coefficient \namong input factors (Fig.¬†8). The apparent difference is also \nshown in the results section and discussed.\n4  Data source\nTo testify to the efficiency of our proposed models, three \nopen data sets and one non-open data set were used to test \nour proposed methodology. The three open data sets are for \nTable 1  Used datasets in this analysis\nDatasets introduction\nType Tasks Samples Pre-train Test\nPIDD Open Classify 768 614 614 & 154\nDiabetes Open Classify 1000 800 800 & 200\nHeart dis-\nease\nOpen Classify 898 718 718 & 180\nMHLW Non-open Classify 12,736 2548 10,188 & \n2548\n1283Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\nclassification among the used open data sets. Pima Indians \nDiabetes Database (PIDD) [74], Mendeley open diabetes \ndata set [75], and the heart disease dataset [76]. All open \ndatasets can be downloaded from the Internet. The PIDD \nis a small diabetes dataset containing 768 diabetes samples \nand eight factors of diabetes: pregnancies, glucose, blood \npressure, skin thickness, insulin, BMI, diabetes pre-degree \nfunction, and age. Similarly, the US open diabetes dataset \ncontains 11 risk factors for diabetes. BMI, HbA1c, age, etc., \nwhile the heart disease data sets have 17 factors. Moreover, \nThe proposed method was also used to analyze the Minis-\ntry of Healthcare, Labor, and Welfare (MHLW) [77] cen-\nsus data. The MHLW dataset is non-objective-oriented; we \nused the newest MHLW (2018) data and deleted the null \nvalue samples. Finally, after pre-processing the datasets, \n12,736 balanced samples were used to test our proposed \nmethodology.\nIn our proposed methodology, samples of the datasets \nare divided into two parts: one part of the data was used \nto acquire prior knowledge, and the other part was used \nto train our proposed methodology. As¬†shown in Table¬† 1, \nfor treating SHAP values as input models, we used 80 per -\ncentage data to obtain ensemble SHAP values and treated \nthe ensemble SHAP values as a new input to self-attention \ntransformer models and compared their performance with \nFTT and other machine learning models [logistic, K-nearest \nneighbors, decision tree, Multi-Layer Perception (MLP), \nAdaBoost, Naive Bayes classification, Quantum Discrimi-\nnate Analysis (QDA) and XGBoost]. We used kernel SHAP \nto explain various classification models separately, and the \nfactors‚Äô importance ranking to each model was reviewed. \nThen, we used the proposed ensemble SHAP value to build \nself-attention transformer models. Finally, we checked the \nperformance of our proposed models. Details of the results \nare shown in the Results section.\n5  Results\nIn this study, we proposed using ensemble SHAP value as \nknowledge to build self-attention transformer models. Then, \nwe checked our proposed transformer models‚Äô performance \nand self-attention. We also compared the self-attention of \nour proposed models with FTT models and the general fac-\ntor coefficients to confirm the efficiency of our proposed \ntransformer models. All the results are shown as follows.\n5.1  Model performance comparison of¬†proposed \ntransformer models\nTo confirm the efficiency of the proposed ensemble SHAP \nmethod, the final global factor importance (global ensemble \nSHAP value) is shown in Fig.¬†2. The ensemble global SHAP \nvalue can show the factor difference more clearly, which \nfits our general human common sense better. After we used \nthe ensemble SHAP results as prior knowledge and used \nthe knowledge to build self-attention transformer models, \nwe compared our proposed models with FTT models and \nother classification models. The results (model accuracy: \nAcc) are shown in Table¬†2. In the MHLW dataset, our pro-\nposed models do not have the same level of performance as \nother classification methods. Because we only used 20% of \nthe data to acquire knowledge. Then, we used the knowl-\nedge to build transformer models and acquired nearly the \nsame level of performance (bold results in Table¬†2 ) as FTT \nTable 2  Model performance \ncomparison of classification \nmodels for the classification \ntask datasets in our study\nThe bold results show the better performance of our proposed model than the FTT model\nMethods PIDD (%) Diabetes (%) Heart disease (%) MHLW (%)\nLogistic 77.92 94.00 75.38 60.36\nK-nearest neighbors 72.73 92.00 64.58 51.53\nDecision tree 67.53 97.00 65.37 55.38\nRandom forest 83.12 98.50 73.64 59.38\nMLP 65.58 96.50 75.56 56.20\nAdaBoost 79.22 98.50 75.63 61.22\nNaive Bayes 77.27 90.50 70.19 58.36\nQDA 74.03 93.50 70.44 58.36\nXGBoost 75.32 98.50 76.02 58.59\nFTT 64.65 89.75 49.85 50.87\nProposed 65.30 89.75 50.94 48.94\n1284 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\nFig. 2  Ensemble SHAP factor importance for four datasets\n1285Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\nmodels. However, our proposed prior knowledge-integrated \ntransformer model performs better (bold results in Table¬† 2) \nthan FTT models in the PIDD and heart disease datasets. \nEspecially for the heart disease dataset, we used 20% of the \ndata to acquire knowledge and build knowledge-integrated \nself-attention transformer models. Moreover, the attention \nof our proposed self-attention transformer models became \nmore stable than general FTT models, as¬†shown in the fol-\nlowing subsection.\n5.2  The self‚Äëattention comparison of¬†transformer \nmodels\nTo understand the theory of the transformer models, we also \nchecked the self-attention of each transformer block. We \ncompared the FTT models and our proposed self-attention \ntransformer models. The details are shown in Figs.¬† 3, 4, 5 \nand 6.\nWhen we check the self-attention among various trans-\nformer models, the attention in each transformer block \nchanges randomly in FTT models. However, in our pro-\nposed self-attention transformer models, the attention of \neach transformer block becomes stable in all four datasets. \nTo avoid possible randomness, we tested our proposed \nself-attention transformer models in 2 self-attention layers, \n4 self-attention layers, 8 self-attention layers, and 12 self-\nattention layers transformer models. The results are shown \nin Figs.¬† 3, 4, 5 and 6 . The self-attention of our proposed \nknowledge-integrated transformer model becomes more sta-\nble than general FTT models, especially in the lower self-\nattention layer transformer models. In the 2 self-attention \nlayer transformer models, the attention is the same. In the \n4 self-attention layer and 8 self-attention layer transformer \nmodels, the attention is also nearly identical. Moreover, \nwhen we compare the self-attention of our proposed trans-\nformer model with the coefficients among features, we can \nFig. 3  The self-attention of proposed transformer models with gen-\neral FTT models (Diabetes dataset) a self-attention in each layer for \n2 layers of FTT models; b self-attention in each layer for 2 layers of \nproposed models; c self-attention in each layer for 4 layers of FTT \nmodels; d self-attention in each layer for 4 layers of proposed models; \ne self-attention in each layer for 8 layers of FTT models; f self-atten-\ntion in each layer for 8 layers of proposed models; g self-attention in \neach layer for 12 layers of FTT models; h self-attention in each layer \nfor 12 layers of proposed models\n1286 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\nfind that the factors‚Äô self-attention (Fig.¬† 7) of our proposed \ntransformer models becomes similar to the factor coeffi-\ncients in general machine learning models (Fig.¬† 8). In con-\ntrast, FTT models‚Äô self-attention seems distributed randomly \nand has lower similarity with the factor coefficients (Fig.¬†8). \nWhen we use our proposed prior knowledge as input, the \ncoefficients among factors seem to become similar (color in \nFig.¬†8 becomes similar in each datasets)\n6  Discussion\nIn this study, we used the proposed ensemble SHAP value \nas knowledge to build self-attention transformer models \nbased on knowledge. The performance of our prior knowl-\nedge-integrated models has better performance than the \nnon-knowledge-integrated FTT models. The better perfor -\nmance of our proposed models ensured that our proposed \nknowledge-integrated transformer model is an available \nresearch idea. Moreover, when we treated the ensemble \nSHAP value as knowledge and inserted the knowledge into \ntransformer models, the self-attention of our knowledge-\nintegrated transformer models became more stable than the \ngeneral FTT model in all four tested datasets. Stable self-\nattention of each layer verified that the knowledge inserted \nin the transformer models influenced the transformer mod-\nels. Meanwhile, stable self-attention of transformer mod -\nels inspires us that we can interpret the AI models directly, \nrather than using agented methods [41‚Äì43] to explain the AI \nmodels. Moreover, our study certificated that knowledge-\nintegrated AI methodology is achievable. Our results con-\nfirmed that a small AI model with knowledge is feasible \nfor future research. Like the study of Feifei Li [58], our \nresearch also certifies that inserting knowledge in the AI \nmodel can help us improve the performance of traditional \nartificial intelligence methods. Moreover, our results inspire \nus to believe that a small AI model based on a small dataset \n[28] is possible.\nWhile the reinforcement model rewards statement func-\ntion and knowledge distillation filers the weights of NN \nFig. 4  The cooperation of proposed initial weight setting and general \ninitial weight setting (PIDD dataset) a self-attention in each layer for \n2 layers of FTT models; b self-attention in each layer for 2 layers of \nproposed models; c self-attention in each layer for 4 layers of FTT \nmodels; d self-attention in each layer for 4 layers of proposed models; \ne self-attention in each layer for 8 layers of FTT models; f self-atten-\ntion in each layer for 8 layers of proposed models; g self-attention in \neach layer for 12 layers of FTT models; h self-attention in each layer \nfor 12 layers of proposed models\n1287Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\nmodels, our proposed model used prior knowledge as the \ninput of the transformer model, which can be transformed \ninto other datasets and widely used in natural language \nprocessing, computer vision, and voice analysis areas. Our \nresults also certified that our proposed model is available in \nclassification models. Moreover, our study found that the \nattention of the transformer model becomes stable, which \ninspires us that we can probably understand the logic of NN \nmodels and make deep learning AI models transparent and \nreliable in the future.\nOur proposed knowledge-integrated AI models used less \ndata and performance than general AI models. Moreover, \nour results confirmed that our proposal is efficient. Our \nstudy certified that knowledge-integrated small AI models \nare available and efficient. Meanwhile, the attention results \nof our proposed transformer models show that the knowl-\nedge-integrated transformer models differ from the general \ntransformer model. The self-attention of our proposed mod-\nels becomes stable in each layer, unlike general transformer \nmodels (Figs.¬†3, 4, 5, 6). These inspire us that there must be \nlogic and undefined rules in NN models. We can explore the \nreal neural connection of NN in future studies and make AI \nmodels more transparent and reliable.\nCertainly, there are also some limitations in our study. \nThe prior knowledge used is different from the natural \nhuman experience. We will find quantified human knowl-\nedge to test our model in future work. However, our pro-\nposed methodology is one significant try for building a \ntrustworthy small AI model, which will inspire more stud-\nies about reliable AI. Meanwhile, our study also confirmed \nthat the small AI model with a small data set is feasible. At \nthe same time, nearly all research efforts have focused on \nthe large AI model, which is difficult in some research areas \nand wastes energy.\nFig. 5  The cooperation of proposed initial weight setting and general \ninitial weight setting (Heart diseases) a self-attention in each layer for \n2 layers of FTT models; b self-attention in each layer for 2 layers of \nproposed models; c self-attention in each layer for 4 layers of FTT \nmodels; d self-attention in each layer for 4 layers of proposed models; \ne self-attention in each layer for 8 layers of FTT models; f self-atten-\ntion in each layer for 8 layers of proposed models; g self-attention in \neach layer for 12 layers of FTT models; h self-attention in each layer \nfor 12 layers of proposed models\n1288 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\n7  Conclusion\nIn this study, we creatively designed knowledge-integrated \nAI models using prior knowledge to build transformer mod-\nels. Our results confirmed the feasibility of our proposed \nmethodology. Meanwhile, our research has certified that the \nresearch about trustable and logic-based AI models based on \nsmall data is feasible in the future. Indeed, there are some \nlimitations to our study. More future work on trustable AI is \nstill needed. However, our research inspires future studies \nabout theory-based, trustable AI models in small-data-based. \nIt paves the way for explaining and understanding the logic \nand theory of black-box AI models.\n8  Future scope\nOur future work will still explore the possibility of building \ntransparent and reliable AI models, hoping to clarify the \nlogic among NN models. Meanwhile, we will also consider \nusing our proposed model in an actual life screen, especially \nin the medical and healthcare fields, which generally need \nmore data to build big AI models.\nFig. 6  The cooperation of proposed initial weight setting and general \ninitial weight setting (MHLW dataset) a self-attention in each layer \nfor 2 layers of FTT models; b self-attention in each layer for 2 layers \nof proposed models; c self-attention in each layer for 4 layers of FTT \nmodels; d self-attention in each layer for 4 layers of proposed models; \ne self-attention in each layer for 8 layers of FTT models; f self-atten-\ntion in each layer for 8 layers of proposed models; g self-attention in \neach layer for 12 layers of FTT models; h self-attention in each layer \nfor 12 layers of proposed models\n1289Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\nFig. 7  The average of self-\nattention comparison among \nFTT models and proposed \nmodels (8 layers) a average \nself-attention of FTT models \n(US Diabetes); b average self-\nattention of proposed models \n(US Diabetes); c self-attention \nof FTT models (PIDD); d self-\nattention of proposed models \n(PIDD); e self-attention of FTT \nmodels (Heart disease); f self-\nattention of proposed models \n(Heart disease); g self-attention \nof FTT models (MHLW); h \nself-attention of proposed mod-\nels (MHLW)\n\n1290 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\nFunding The authors declare that no funds and grants were received \nduring the preparation of this manuscript. However, we thank the \nMinistry of Healthcare, Labor, and Welfare of Japan for supplying the \nanonymous data for our study.\nData Availability The non-open dataset in this study needs usage \napproval from the Ministry of Healthcare, Labor, and Welfare of Japan.\nCode availability Not applicable.\nDeclarations \nConflict of interest The authors have no relevant financial or non-\nfinancial interests to disclose.\nEthical approval The ethics of the Ministry of Healthcare, Labor, \nand Welfare of Japan approved this study for using anonymous data.\nOpen Access This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as long \nFig. 8  The coefficients of prior knowledge integrated input a the factor coefficients of the US Diabetes dataset; b the factor coefficients of the \nPIDD dataset; c the factor coefficients of the Heart disease dataset; d the factor coefficients of the MHLW dataset\n1291Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292 \n1 3\nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article‚Äôs Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article‚Äôs Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Said Y, Alanazi A (2023) Ai-based solar energy forecasting for \nsmart grid integration. Neural Comput Appl 35:8625‚Äì8635\n 2. Chang V, Bailey J, Xu QA, Sun Z (2023) Pima Indians diabetes \nmellitus classification based on machine learning (ml) algorithms. \nNeural Comput Appl 35:16157‚Äì16173\n 3. Sreekala K, Rajkumar N, Sugumar R, Sagar K, Shobarani R, \nKrishnamoorthy KP, Saini A, Palivela H, Yeshitla A (2022) Skin \ndiseases classification using hybrid ai based localization approach. \nComput Intell Neurosci 2022:7. https:// doi. org/ 10. 1155/ 2022/ \n61384 90\n 4. Wang C (2022) Ai-based heterogenous large-scale english transla-\ntion strategy. Mob Inf Syst 2022:8344814\n 5. Du Y, Xu D (2022) Analysis of graphic design based on ai interac-\ntion technology. J Environ Public Health. 2022. https:// doi. org/ 10. \n1155/ 2022/ 84935 28\n 6. Alam A, Praveen S (2021) A review of automatic driving system \nby recognizing road signs using digital image processing. J Inform \nElectr Electron Eng (JIEEE) 2(2):1‚Äì9\n 7. Ma W, Zhao S, Xu S, Guo K, Qin K (2021) In: International \nconference on smart transportation and city engineering vol \n12050. SPIE, pp 591‚Äì598\n 8. Yang M (2022) Research on vehicle automatic driving target \nperception technology based on improved msrpn algorithm. J \nComput Cogn Eng 1(3):147‚Äì151\n 9. Du Y, Zhi Jy (2022) Impacts of attention level on manual take-\nover performance in automatic driving on high-speed railways. \nInt J Hum Comput Interact 1‚Äì10\n 10. Meng Q, Zhao S, Huang Z, Zhou F (2021) Magface: a universal \nrepresentation for face recognition and quality assessment. In: \nProceedings of the IEEE/CVF conference on computer vision \nand pattern recognition, pp 14225‚Äì14234\n 11. Aggarwal D, Zhou J, Jain AK (2021) Fedface: Collaborative \nlearning of face recognition model. In: 2021 IEEE international \njoint conference on biometrics (IJCB). IEEE, pp 1‚Äì8\n 12. Du H, Shi H, Zeng D, Zhang XP, Mei T (2022) The elements of \nend-to-end deep face recognition: a survey of recent advances. \nACM Comput Surv (CSUR) 54(10s):1‚Äì42\n 13. Zeng J, Qiu X, Shi S (2021) Image processing effects on the deep \nface recognition system. Math Biosci Eng 18(2):1187‚Äì1200\n 14. Tian S, Wang M, Yuan F, Dai N, Sun Y, Xie W, Qin J (2021) \nEfficient computer-aided design of dental inlay restoration: \na deep adversarial framework. IEEE Trans Med Imaging \n40(9):2415‚Äì2427\n 15. Oza P, Sharma P, Patel S (2021) In: Proceedings of second \ninternational conference on computing, communications, and \ncyber-security. Springer, pp 377‚Äì392\n 16. Nazir A, Azhar A, Nazir U, Liu YF, Qureshi WS, Chen JE, \nAlanazi E (2021) The rise of 3d printing entangled with smart \ncomputer aided design during COVID-19 era. J Manuf Syst \n60:774‚Äì786\n 17. Cohen MW, Gilo O, David L (2022) A computer aided medical \nclassification system of COVID-19 ct lung scans using convolu-\ntion neural networks. Comput Aided Des Appl 522‚Äì533\n 18. Croitoru FA, Hondru V, Ionescu RT, Shah M (2022) Diffusion \nmodels in vision: a survey. arXiv: 2209. 04747\n 19. Openai. https:// openai. com/ resea rch/ gpt-4. Accessed 01 May \n2023\n 20. Bajaj D, Goel A, Gupta S, Batra H (2022) Muce: a multilin-\ngual use case model extractor using gpt-3. Int J Inf Technol \n14(3):1543‚Äì1554\n 21. Mulla N, Gharpure P (2023) Leveraging well-formedness and \ncognitive level classifiers for automatic question generation on \njava technical passages using t5 transformer. Int J Inf Technol \n15:1961‚Äì1973\n 22. Dowlagar S, Mamidi R (2021) Cmsaone@ dravidian-codemix-\nfire2020: A meta embedding and transformer model for code-\nmixed sentiment analysis on social media text. arXiv: 2101. 09004\n 23. Soni J, Mathur K (2022) Sentiment analysis based on aspect and \ncontext fusion using attention encoder with lstm. Int J Inf Technol \n14(7):3611‚Äì3618\n 24. Sheik R, Parida SS, Nirmala SJ (2023) A hybrid model utiliz-\ning transfer learning for legal citation linking. Int J Inf Technol \n15:2783‚Äì2792\n 25. Priya CSR (2023) Sentiment analysis from unstructured hotel \nreviews data in social network using deep learning techniques. \nInt J Inf Technol 15:3563‚Äì3574\n 26. George L, Sumathy P (2023) An integrated clustering and \nbert framework for improved topic modeling. Int J Inf Technol \n15:2178‚Äì2195\n 27. Sengupta S, Mayya V, Kamath SS (2022) Detection of bradycar-\ndia from electrocardiogram signals using feature extraction and \nsnapshot ensembling. Int J Inf Technol 14(6):3235‚Äì3244\n 28. Strickland E (2022) Andrew ng, ai minimalist: the machine-learn-\ning pioneer says small is the new big. IEEE Spectr 59(4):22‚Äì50\n 29. Wei CY, Luo H (2021) Non-stationary reinforcement learning \nwithout prior knowledge: An optimal black-box approach. In: \nConference on learning theory. PMLR, pp 4300‚Äì4354\n 30. Li Y, Shen W, Zhang Y, Chen H, Jiang M, Liu J, Jiang J, Gao \nW, Wu Z, Yang et¬†al (2021) Openbox: a generalized black-box \noptimization service. In: Proceedings of the 27th ACMSIGKDD \nconference on knowledge discovery & data mining, pp 3209‚Äì3219\n 31. Wadden JJ (2022) Defining the undefinable: the black box problem \nin healthcare artificial intelligence. J Med Ethics 48(10):764‚Äì768\n 32. Bodria F, Giannotti F, Guidotti R, Naretto F, Pedreschi D, Rinziv-\nillo S (2021) Benchmarking and survey of explanation methods \nfor black box models. arXiv: 2102. 13076\n 33. Dur√°n JM, Jongsma KR (2021) Who is afraid of black box algo-\nrithms? on the epistemological and ethical basis of trust in medi-\ncal ai. J Med Ethics 47(5):329‚Äì335\n 34. Knapiƒç S, Malhi A, Saluja R, Fr√§mling K (2021) Explainable \nartificial intelligence for human decision support system in the \nmedical domain. Mach Learn Knowl Extr 3(3):740‚Äì770\n 35. Sokolovsky A, Arnaboldi L, Bacardit J, Gross T (2021) Explain-\nable machine learning-driven strategy for automated trading pat-\ntern extraction. arXiv: 2103. 12419\n 36. Covert I, Lundberg SM, Lee SI (2021) Explaining by removing: \na unified framework for model explanation. J Mach Learn Res \n22:209‚Äì211\n 37. Lundberg SM, Nair B, Vavilala MS, Horibe M, Eisses MJ, Adams \nT, Liston DE, Low DKW, Newman SF, Kim J, Lee SI (2018) \nExplainable machine-learning predictions for the prevention of \nhypoxaemia during surgery. Nat Biomed Eng 2(10):749‚Äì760. \nhttps:// doi. org/ 10. 1038/ s41551- 018- 0304-0\n1292 Int. j. inf. tecnol. (March 2024) 16(3):1279‚Äì1292\n1 3\n 38. Chen H, Lundberg S, Lee SI (2021) Explaining Models by Propa-\ngating Shapley Values of Local Components. Stud Comput Intell \n914:261‚Äì270. https:// doi. org/ 10. 1007/ 978-3- 030- 53352-6_ 24\n 39. Molnar C (2022) Interpretable machine learning, 2nd edn. (add). \nhttps:// chris tophm. github. io/ inter preta ble- ml- book\n 40. Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh D, Batra \nD (2020) Grad-CAM: visual explanations from deep networks \nvia gradient-based localization. Int J Comput Vis 128(2), 336‚Äì\n359. https:// doi. org/ 10. 1007/ s11263- 019- 01228-7. arXiv: 1610. \n02391\n 41. Zhao X, Huang W, Huang X, Robu V, Flynn D (2021) In: Uncer-\ntainty in artificial intelligence. PMLR, pp. 887‚Äì896\n 42. Ribeiro MT, Singh S, Guestrin C (2016) In: Proceedings of the \nACM SIGKDD international conference on knowledge discovery \nand data mining, vol 13‚Äì17-August-2016. Association for Com-\nputing Machinery, pp. 1135‚Äì1144. https:// doi. org/ 10. 1145/ 29396 \n72. 29397 78\n 43. Meng Y, Yang N, Qian Z, Zhang G (2021) What makes an online \nreview more helpful: an interpretation framework using xgboost \nand shap values. J Theor Appl Electron Commer Res 16(3):466‚Äì\n490. https:// doi. org/ 10. 3390/ jtaer 16030 029\n 44. Feng DC, Wang WJ, Mangalathu S, Taciroglu E (2021) Inter -\npretable xgboost-shap machine-learning model for shear strength \nprediction of squat rc walls. J Struct Eng 147(11):04021173\n 45. Wen X, Xie Y, Wu L, Jiang L (2021) Quantifying and comparing \nthe effects of key risk factors on various types of roadway segment \ncrashes with lightgbm and shap. Accid Anal Prev 159:106261\n 46. Li Z (2022) Extracting spatial effects from machine learning \nmodel using local interpretation method: an example of shap and \nxgboost. Comput Environ Urban Syst 96:101845\n 47. Chelgani SC, Nasiri H, Alidokht M (2021) Interpretable modeling \nof metallurgical responses for an industrial coal column flotation \ncircuit by xgboost and shap‚Äîa ‚Äúconscious-lab‚Äô‚Äô development. Int \nJ Min Sci Technol 31(6):1135‚Äì1144\n 48. Yang C, Chen M, Yuan Q (2021) The application of xgboost and \nshap to examining the factors in freight truck-related crashes: an \nexploratory analysis. Accid Anal Prev 158:106153\n 49. Jabeur SB, Mefteh-Wali S, Viviani JL (2021) Forecasting gold \nprice with the xgboost algorithm and shap interaction values. Ann \nOper Res 1‚Äì21\n 50. Wang D, Thun√©ll S, Lindberg U, Jiang L, Trygg J, Tysklind M \n(2022) Towards better process management in wastewater treat-\nment plants: process analytics based on shap values for tree-based \nmachine learning methods. J Environ Manag 301:113941\n 51. Van den Broeck G, Lykov A, Schleich M, Suciu D (2022) On the \ntractability of shap explanations. J Artif Intell Res 74:851‚Äì886\n 52. Jiang P, Suzuki H, Obi T (2023) Interpretable machine learning \nanalysis to identify risk factors for diabetes using the anonymous \nliving census data of japan. Health Technol 13:1‚Äì13\n 53. Alwadi M, Chetty G, Yamin M (2023) A framework for vehicle \nquality evaluation based on interpretable machine learning. Int J \nInf Technol 15(1):129‚Äì136\n 54. Mitrentsis G, Lens H (2022) An interpretable probabilistic model \nfor short-term solar power forecasting using natural gradient \nboosting. Appl Energy 309:118473\n 55. Zhao W, Joshi T, Nair VN, Sudjianto A (2020) Shap values for \nexplaining cnn-based text classification models. arXiv: 2008.  \n11825\n 56. Wang J, Wiens J, Lundberg S (2021) In: International conference \non artificial intelligence and statistics. PMLR, pp 721‚Äì729\n 57. Lundberg SM, Lee SI (2017) A unified approach to interpreting \nmodel predictions. Adv Neural Inf Process Syst 30:4768‚Äì4777\n 58. Krishna R, Lee D, Fei-Fei L, Bernstein MS (2022) Socially situ-\nated artificial intelligence enables learning from human interac-\ntion. Proc Natl Acad Sci 119(39):e2115730119\n 59. Lee D, Seo H, Jung MW (2012) Neural basis of reinforcement \nlearning and decision making. Ann Rev Neurosci 35:287‚Äì308\n 60. Gou J, Yu B, Maybank SJ, Tao D (2021) Knowledge distillation: \na survey. Int J Comput Vis 129:1789‚Äì1819\n 61. Ignatiev A, Narodytska N, Marques-Silva J (2019) On validat-\ning, repairing and refining heuristic ml explanations. arXiv: 1907. \n02509\n 62. Tao G, Ma S, Liu Y, Zhang X (2018) Attacks meet interpretability: \nattribute-steered detection of adversarial samples. Adv Neural Inf \nProcess Syst 31:7728‚Äì7739\n 63. Shih A, Choi A, Darwiche A (2018) A symbolic approach to \nexplaining Bayesian network classifiers. arXiv: 1805. 03364\n 64. Narodytska N, Shrotri A, Meel KS, Ignatiev A, Marques-Silva J \n(2019) In: Theory and applications of satisfiability testing-SAT \n2019: 22nd international conference, SAT 2019, Lisbon, Portugal, \nJuly 9‚Äì12, 2019, Proceedings 22. Springer, pp 267‚Äì278\n 65. Slingerland P, Perry L, Kaufman J, Bycroft B, Linstead E, Man-\ndrake L, Doran G, Goel A, Feather MS, Fesq L et¬†al (2022) In: \n2022 IEEE aerospace conference (AERO). IEEE, pp 1‚Äì20\n 66. Cohen R, Schaekermann M, Liu S, Cormier M (2019) Trusted AI \nand the contribution of trust modeling in multiagent systems. In: \nProceedings of the 18th international conference on autonomous \nagents and multiagent systems. pp 1644‚Äì1648\n 67. A path towards autonomous machine intelligence version 0.9.2, \n2022-06-27. https:// openr  eview. net/ pdf? id= BZ5a1r- kVsf. \nAccessed 24 Oct 2023\n 68. Khan S, Naseer M, Hayat M, Zamir SW, Khan FS, Shah M (2021) \nTransformers in vision: a survey. ACM Comput Surv (CSUR) \n54:1‚Äì41\n 69. Lin T, Wang Y, Liu X, Qiu X (2021) A survey of transformers. \narXiv: 2106. 04554\n 70. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez \nAN, Kaiser ≈Å, Polosukhin I (2017) Attention is all you need. Adv \nNeural Inf Process Syst 30\n 71. Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, \nUnterthiner T, Dehghani M, Minderer M, Heigold G, Gelly S et¬†al \n(2020) An image is worth 16 x 16 words: transformers for image \nrecognition at scale. arXiv: 2010. 11929\n 72. Sun L, Zhao G, Zheng Y, Wu Z (2022) Spectral-spatial feature \ntokenization transformer for hyperspectral image classification. \nIEEE Trans Geosci Remote Sens 60:1‚Äì14\n 73. Jiang P, Suzuki H, Obi T (2023) Xai-based cross-ensemble fea-\nture ranking methodology for machine learning models. Int J Inf \nTechnol 15(4):1759‚Äì1768\n 74. kaggle. Pima Indians diabetes database (2006). https:// www. kag-\ngle. com/ datas ets/ uciml/ pima- india ns- diabe tes- datab ase. Accessed \n15 May 2023\n 75. Rashid A (2020) Diabetes dataset. https:// doi. org/ 10. 17632/ wj9rw \nkp9c2.1. Accessed 15 May 2023\n 76. C.¬†for Disease¬†Control, Prevention. Personal key indicators of \nheart disease (2020). https:// www. kaggle. com/ datas ets/ kamil pyt-\nlak/ perso nal- key- indic ators- of- heart- disea se\n 77. L. Ministry of Health, W. of Japan (2023). https:// www. mhlw. go. \njp/ engli sh/ index. html. Accessed 15 May 2023",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8366121649742126
    },
    {
      "name": "Transformer",
      "score": 0.7494369149208069
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5644499659538269
    },
    {
      "name": "Machine learning",
      "score": 0.5073239207267761
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I125602781",
      "name": "Tokyo Medical and Dental University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I114531698",
      "name": "Tokyo Institute of Technology",
      "country": "JP"
    }
  ]
}