{
    "title": "WaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization",
    "url": "https://openalex.org/W4403334501",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A5006171300",
            "name": "Liwenhan Xie",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong",
                "Harvard University Press",
                "University of California, San Diego",
                "University of Minnesota"
            ]
        },
        {
            "id": "https://openalex.org/A5085140104",
            "name": "Chengbo Zheng",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong",
                "Harvard University Press",
                "University of California, San Diego",
                "University of Minnesota"
            ]
        },
        {
            "id": "https://openalex.org/A5016819583",
            "name": "Haijun Xia",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong",
                "Harvard University Press",
                "University of California, San Diego",
                "University of Minnesota"
            ]
        },
        {
            "id": "https://openalex.org/A5091466289",
            "name": "Huamin Qu",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong",
                "Harvard University Press",
                "University of California, San Diego",
                "University of Minnesota"
            ]
        },
        {
            "id": "https://openalex.org/A5082790087",
            "name": "Zhutian Chen",
            "affiliations": [
                "Hong Kong University of Science and Technology",
                "University of Hong Kong",
                "Harvard University Press",
                "Twin Cities Orthopedics",
                "University of California, San Diego",
                "University of Minnesota"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4385714563",
        "https://openalex.org/W2973366514",
        "https://openalex.org/W4232488826",
        "https://openalex.org/W4401043091",
        "https://openalex.org/W4366547526",
        "https://openalex.org/W4389520463",
        "https://openalex.org/W4225012671",
        "https://openalex.org/W2010645028",
        "https://openalex.org/W4385565383",
        "https://openalex.org/W2946535156",
        "https://openalex.org/W4318621382",
        "https://openalex.org/W4388447970",
        "https://openalex.org/W4291138228",
        "https://openalex.org/W4396832182",
        "https://openalex.org/W4396832076",
        "https://openalex.org/W4396833112",
        "https://openalex.org/W2157289187",
        "https://openalex.org/W4393161130",
        "https://openalex.org/W4396833079",
        "https://openalex.org/W4388145405",
        "https://openalex.org/W4385682544",
        "https://openalex.org/W2064766209",
        "https://openalex.org/W2593083061",
        "https://openalex.org/W2157922094",
        "https://openalex.org/W4381546658",
        "https://openalex.org/W4365601419",
        "https://openalex.org/W4399492331",
        "https://openalex.org/W4389524334",
        "https://openalex.org/W4282813546",
        "https://openalex.org/W4396828482",
        "https://openalex.org/W4366587430",
        "https://openalex.org/W4383816897",
        "https://openalex.org/W2114877339",
        "https://openalex.org/W4394745423",
        "https://openalex.org/W3134547365",
        "https://openalex.org/W2753739212",
        "https://openalex.org/W6907684267",
        "https://openalex.org/W3159054342",
        "https://openalex.org/W4360614990",
        "https://openalex.org/W3198767185",
        "https://openalex.org/W3205259242",
        "https://openalex.org/W3203841973",
        "https://openalex.org/W4388447964",
        "https://openalex.org/W4396832739",
        "https://openalex.org/W4377371585",
        "https://openalex.org/W4396832139",
        "https://openalex.org/W4392026410",
        "https://openalex.org/W4396832280",
        "https://openalex.org/W4224991060",
        "https://openalex.org/W2796111556",
        "https://openalex.org/W4399486930",
        "https://openalex.org/W3203321135",
        "https://openalex.org/W4396817330",
        "https://openalex.org/W4380714529",
        "https://openalex.org/W4385945128",
        "https://openalex.org/W4210312918",
        "https://openalex.org/W4210294742",
        "https://openalex.org/W4385565416",
        "https://openalex.org/W4225004658",
        "https://openalex.org/W4389610651",
        "https://openalex.org/W4226451059",
        "https://openalex.org/W4402401986"
    ],
    "abstract": "Large language models (LLMs) support data analysis through conversational\\nuser interfaces, as exemplified in OpenAI's ChatGPT (formally known as Advanced\\nData Analysis or Code Interpreter). Essentially, LLMs produce code for\\naccomplishing diverse analysis tasks. However, presenting raw code can obscure\\nthe logic and hinder user verification. To empower users with enhanced\\ncomprehension and augmented control over analysis conducted by LLMs, we propose\\na novel approach to transform LLM-generated code into an interactive visual\\nrepresentation. In the approach, users are provided with a clear, step-by-step\\nvisualization of the LLM-generated code in real time, allowing them to\\nunderstand, verify, and modify individual data operations in the analysis. Our\\ndesign decisions are informed by a formative study (N=8) probing into user\\npractice and challenges. We further developed a prototype named WaitGPT and\\nconducted a user study (N=12) to evaluate its usability and effectiveness. The\\nfindings from the user study reveal that WaitGPT facilitates monitoring and\\nsteering of data analysis performed by LLMs, enabling participants to enhance\\nerror detection and increase their overall confidence in the results.\\n",
    "full_text": "WaitGPT: Monitoring and Steering Conversational LLM Agent in\nData Analysis with On-the-Fly Code Visualization\nLiwenhan Xie∗\nliwenhan.xie@connect.ust.hk\nHong Kong University of Science and\nTechnology\nHong Kong SAR, China\nChengbo Zheng\ncb.zheng@connect.ust.hk\nHong Kong University of Science and\nTechnology\nHong Kong SAR, China\nHaijun Xia\nhaijunxia@ucsd.edu\nUniversity of California San Diego\nLa Jolla, CA, USA\nHuamin Qu\nhuamin@ust.hk\nHong Kong University of Science and\nTechnology\nHong Kong SAR, China\nChen Zhu-Tian\nztchen@umn.edu\nUniversity of Minnesota\nMinneapolis, MN, USA\nFigure 1: Monitoring and steering LLM-powered data analysis tools with WaitGPT: Beyond viewing the raw code, users can\ninspect data operations with a transformable representation generated on the fly and participate in data analysis proactively.\nABSTRACT\nLarge language models (LLMs) support data analysis through con-\nversational user interfaces, as exemplified in OpenAI’s ChatGPT\n(formally known as Advanced Data Analysis or Code Interpreter).\nEssentially, LLMs produce code for accomplishing diverse analysis\ntasks. However, presenting raw code can obscure the logic and\nhinder user verification. To empower users with enhanced compre-\nhension and augmented control over analysis conducted by LLMs,\nwe propose a novel approach to transform LLM-generated code into\nan interactive visual representation. In the approach, users are pro-\nvided with a clear, step-by-step visualization of the LLM-generated\ncode in real time, allowing them to understand, verify, and modify\nindividual data operations in the analysis. Our design decisions are\ninformed by a formative study (N=8) probing into user practice\n∗This study was partially conducted during an academic visit to Harvard University.\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA\n© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nThis is the author’s version of the work. It is posted here for your personal use. Not\nfor redistribution. The definitive Version of Record was published in The 37th Annual\nACM Symposium on User Interface Software and Technology (UIST ’24), October 13–16,\n2024, Pittsburgh, PA, USA , https://doi.org/10.1145/3654777.3676374.\nand challenges. We further developed a prototype named WaitGPT\nand conducted a user study (N=12) to evaluate its usability and\neffectiveness. The findings from the user study reveal that WaitGPT\nfacilitates monitoring and steering of data analysis performed by\nLLMs, enabling participants to enhance error detection and increase\ntheir overall confidence in the results.\nCCS CONCEPTS\n• Human-centered computing →Natural language interfaces;\nGraphical user interfaces ; Information visualization .\nKEYWORDS\nConversational Data Analysis, LLM Agent, Human-AI Interaction,\nGenerative AI, Code Verification, Visual Programming\nACM Reference Format:\nLiwenhan Xie, Chengbo Zheng, Haijun Xia, Huamin Qu, and Chen Zhu-\nTian. 2024. WaitGPT: Monitoring and Steering Conversational LLM Agent in\nData Analysis with On-the-Fly Code Visualization. InThe 37th Annual ACM\nSymposium on User Interface Software and Technology (UIST ’24), October\n13–16, 2024, Pittsburgh, PA, USA. ACM, New York, NY, USA, 14 pages. https:\n//doi.org/10.1145/3654777.3676374\narXiv:2408.01703v1  [cs.HC]  3 Aug 2024\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\n1 INTRODUCTION\nLarge language models (LLMs) have significantly lowered the entry\npoint for data analysis, empowering users without strong program-\nming skills to engage in sophisticated analytical tasks [ 8, 12, 23].\nInstead of writing scripts or using complex software, people can\ndirectly talk to conversational LLM agents. Examples of emerg-\ning LLM-powered data analysis services or tools include ChatGPT\nPlus [47], Gemini Advanced [17], and CodeActAgent [65]. Gener-\nally, these tools follow a planning framework, where the LLM agent\nproposes a plan to divide the task, then generates code to process\ndata and continues the process based on the execution result.\nDespite their potential, real-world deployment of LLM-powered\ndata analysis tools has exposed reliability concerns, including hal-\nlucinations [6, 33], subtle bugs [ 69, 73], and mismatch between\nLLM’s understanding of the tasks and under-articulated user in-\ntents [32, 64]. Such shortcomings necessitate human oversight to\nverify and correct the data analysis process [ 9, 19, 46]. Current\ntools often present raw data analysis code, shifting the user’s focus\nto low-level details instead of the high-level data analysis process.\nAccording to our interview with ChatGPT users, individuals, espe-\ncially those with limited coding skills, struggle to comprehensively\nreview the code produced by LLMs, thereby risking undetected\nerrors and potentially incorrect results. Moreover, rectifying code\nthrough conversation can turn into a cumbersome exchange, adding\nto the inefficiency and frustration.\nOur goal is to make the data analysis process conducted by LLMs\neasier to understand and navigate for users, in line with current\nresearch on designing UIs featuring generative AIs (e.g., [52, 57]).\nSpecifically, we aim to support real-time monitoring and proactive\nintervention (steering) at any point. Compared with existing ap-\nproaches targeting a traditional data analysis pipeline (e.g., [31, 55]),\nthis scenario features conversational interaction and on-demand\ngeneration of unfamiliar code to the users, where the code streams\nin. Informed by a formative study involving 8 users experienced in\nLLM-powered data analysis, we propose a workflow that identifies\ndata operations within the generated code and maps them to visual,\ninteractive primitives on the fly (Figure.1). These primitives collec-\ntively offer an overview of the data analysis process, and surface the\ndetails of each data operation and their internal runtime states in an\nintuitive, syntax-independent format. Furthermore, users can refine\neach operation by interacting directly with these primitives without\nregenerating the entire analysis code. Through this approach, we\naugment traditional conversational user interfaces (CUIs) with in-\nteractive visualization, transforming users from passive recipients\nof information into active participants in the data analysis task.\nWe have designed and implemented WaitGPT, a prototype sys-\ntem that converts the data analysis code generated by an LLM\ninto a visual diagram that consists of nodes representing key data\noperations, composing an overview step by step. This diagram\nprogressively evolves along with the code generation process. Fur-\nthermore, WaitGPT executes the underlying code line by line and\nupdates the visual diagram to reflect the code’s intermediate state\nduring runtime. Users can interact with these nodes to modify or\nadjust the operations, thereby refining the data analysis process.\nExecution results are maintained and preserved within a sandbox\nenvironment, enabling the system to resume or rerun the analysis\ncode after modifications, without the need to regenerate the entire\ncode. A user study with 12 participants reported an enhanced ex-\nperience, noting the ease of spotting errors, increased agency, and\nheightened confidence in the results produced by the LLM.\nIn summary, our contributions are three-fold.\n•A formative study (N=8) that summarizes practices, challenges,\nand expectations in conducting data analysis with LLM agents\nbased on conversation.\n•A novel design that facilitates monitoring and steering LLM-\ngenerated data analysis script featuring interactive visualizations.\nWe implement a prototype system named WaitGPT and evaluate\nits usability (N=12).\n•Discussions and implications on user interface design of LLM\nagents for data analysis tasks.\n2 BACKGROUND & RELATED WORK\nHere, we review NLI-based data analysis tools, visualization tech-\nniques for data processing scripts, and user interface design for\nhuman-LLM interactions, which are closely related to our study.\n2.1 Demystifying NLI-based Data Analysis\nNLI-based data analysis tools interpret users’ instructions in nat-\nural language and automatically perform analytic tasks. Existing\ntools often assemble atomic data operations based on a clear cate-\ngorization of analytical tasks [53, 75]. To support more flexible user\ntasks, there has been surging interest in applying LLMs to trans-\nlate NL-based user intents into data-related operations or directly\nsynthesize visualization programs (e.g., [34, 35, 60]).\nHowever, it remains unrealistic to expect completely correct out-\nputs for reasons like language ambiguity and algorithmic or model\naccuracy [14, 15, 44]. This issue becomes more pronounced when\nintegrating LLMs into data analysis tools, given their black-box\nnature. This characteristic calls for rigorous inspection and verifica-\ntion strategies, as highlighted in prior research [9, 18, 49]. Example\nerrors include wrong column selection, data mapping, data trans-\nformation, etc. In response to the challenge, XNLI [14] provides a\nstandalone interface that shows one user query to the key aspects\nin a finite set of the traditional NLI pipeline, i.e., attributes, tasks,\nand visual encodings. With LLMs, Huang et al. [25] converted the\ndata transformation program into a flowchart using intermediate\ntables as nodes. Under a spreadsheet-based interface, Liu et al. [33]\nproposed grounded abstraction matching (GAM) that explains LLM-\ngenerated code to end users in natural language. ColDeco [ 15]\nfurther augments GAM with two complementary views of inter-\nmediate results, highlighting how the operation changes the result.\nOur work applies to analytic tasks that are more open-ended and\nconcern complex data operations, which is under-examined [23].\nMost relevant to our interest in a conversational interface, Gu et al.\n[19] added a side panel that profiles intermediate data to facilitate\nretrospective examination of the synthesized code. Kazemitabaar\net al. [28] proposed to afford editable assumptions, execution plans,\nand code in LLM response for close verification and steering. We\ncomplemented their design by proposing a transformable represen-\ntation of the code, aiming to lower the abstraction level of the code\nand enhance user engagement during the interaction.\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\n2.2 Sense-making of Data Processing Code\nSimplifying data processing code can support learning [31], collabo-\nrative work [50], and quality control [56, 72]. To give a comprehen-\nsive view, prior research has condensed the operations into descrip-\ntive narratives [14, 33] or schematic diagrams [25, 51]. In addition,\nmany works focused on visualizing interim results through anima-\ntion (e.g., [21, 29, 50]) or a timeline representation (e.g., [2, 36, 45]).\nFor instance, Datamation [50] visually maps and links each step of\nthe data process to the underlying dataset, providing more context\nfor the audience. Smallset Timeline [36] intelligently selects sam-\nples affected by the operation and encodes the changes on a table\nalong the timeline.\nTo enhance understanding of atomic data operations, many\nworks investigated step-wise examination of the underlying data.\nThis can be achieved by revealing the connections and discrep-\nancies between the input and output states. Pandas Tutor [ 31]\nhighlights selected rows and links their new position with arrows.\nSOMNUS [72] presents 23 static glyphs for data transformation\noperations in table, column, and row granularity, respectively. To\nbridge the mental map between data transform specifications and\nresults, some works allow interactive inspection [27, 55, 56]. For\ninstance, Unravel [ 55] automatically transforms individual data\noperations into summary boxes with key parameters and the table\nsize, which serves as an intermediate layer for users to modify and\naccess runtime execution results.\nWaitGPT addresses a new problem: sense-making of data pro-\ncessing code produced by an LLM agent. Compared to previous\napproaches that deal with complete and static scripts, the code is\ngenerated in a streaming manner, which may present challenges for\nusers in terms of following the LLM’s response during the genera-\ntion process. In addition, some tools (e.g., [55, 63]) require coding\nproficiency while some have a rigid functionality (e.g., [ 14, 72]).\nHowever, in our scenario, end-users, including data analysts, laypeo-\nple, etc., talk to an LLM agent for various data analysis tasks. We\nprioritize intuitive visualization designs for immediate understand-\ning and rapid verification, keeping users engaged and undistracted\nduring the active code generation phase. General code debugging,\nhowever, is beyond our scope.\n2.3 Advancing UIs for Human-LLM Interaction\nAmidst the wave of LLMs, the HCI community has been advancing\nuser interface design to enhance control over LLMs, moving beyond\na standard chatbot framework or basic API invocations.\nSimilar to our motivation to facilitate easier comprehension and\nverification of the generated content, some works seek to bridge\nthe gulf of envisioning in human-LLM interactions [ 57, 59]. For\nexample, Graphlogue [26] converts linear text into a diagram that\nencodes logical structure on the fly to assist information-seeking\ntasks. Zhu-Tian et al. [ 76] foreshadows LLM-generated code in-\ncrementally and instantly during prompt crafting. Sensecape [58]\nempowers users with a multilevel abstraction of existing conver-\nsation and supports information foraging and sense-making. We\nattend to an emerging scenario of conversational data analysis with\nLLMs, where we present novel features like on-the-fly visualization\nas code streams in, code scrolly-telling, and snippet navigation.\nAnother stream of research explores novel interaction designs\nwith LLMs that surpass the conventional single-text prompt, where\nmore dynamic and progressive workflows and interaction modali-\nties are promoted. For instance, Wu et al. [68] introduced the con-\ncept of AI Chains, where users specify how the output of one step\nbecomes the input for the next, resulting in cumulative gains per\nstep. Many works targeted specific application domains, including\nwriting [10], graphics design [37], programming [1], etc. Relevant to\nour interest in granular control of LLM-generated code, Low-code\nLLM [4] allows users to edit the tentative workflow synthesized by\na planning LLM, thereby providing control over the generated code.\nDynaVis [61] leverages LLM to synthesize UI widgets to edit data\nvisualizations dynamically. Bearing a similar idea, our work sup-\nports user interactions with the intermediate visualization to drill\ndown or refine the code in place for more intuitive and granular\ncontrol with LLMs.\n3 FORMATIVE STUDY\nWe conducted a formative study (N=8) to better understand the\nglitches in LLM-powered data analysis tools and inform the design\nconsiderations for contextualized support.\n3.1 Setup\nRecruitment & Screening. We posted recruitment advertisements\non social media and university forums. Candidate participants were\nrequired to complete a questionnaire about their demographic in-\nformation and relevant experience. We selected volunteers who\nare more experienced with data analysis and familiar with LLM-\npowered data analysis tools.\nProtocol. The study consisted of a contextual inquiry (20∼40 min)\nand a structured interview (15 min). First, we asked participants\nto show their interaction history with LLM agents in data analysis\ntasks. If their original dataset is available, they will also walk the\nmoderator through the data analysis procedure while thinking\naloud. For five participants with the original dataset at hand, we\nasked them to replicate one analysis session directly while thinking\naloud. The interview ended with a list of questions regarding the\noverall experience. Each participant is compensated with $12/hour.\nParticipants. We recruited 8 participants in total (P1–P8), with\n3 females and 5 males, aged from 20 to 30. Specifically, there are\n6 postgraduate students, 1 undergraduate student (P3), and 1 data\njournalist (P4). All are familiar with the data analysis mode (for-\nmally named as “Advanced Data Analysis” or “Code Interpreter”)\nembedded in OpenAI’s ChatGPT [47] and had at least 5 sessions.\nAnalysis. All interviews were video-recorded and transcribed\ninto text. Following thematic analysis [3], the first author applied\ninductive and deductive approaches and derived initial categorized\ncodes and themes. The first three authors reviewed transcripts and\nimportant screenshots based on weekly meetings to agree on the\nfinal themes after iterations.\n3.2 Findings\nHere, we summarize the key findings from the interview study.\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\nTable 1: Common issues in the code generated by OpenAI’s\nChatGPT for data analysis tasks.\nIssue Type Detailed Behaviors of an LLM Agent\nIncomplete workflow Misses some important steps, e.g., not excluding\nempty value when computing means.\nNon-existing symbols Invoke a function, configure a parameter, or use\na variable that is not defined.\nData transform failure Fails to handle edge data value, e.g., accessing an\nattribute that does not exist in all data items.\nWrong columns Selects the wrong column(s).\nUnreasonable values Sets parameter to an inappropriate value, e.g., us-\ning an overly high threshold for outliers.\n3.2.1 Why do people turn to LLM-powered tools for data analysis?\nParticipants recognized the versatility of conversational LLM agents\nfor data analysis as a significant advantage. They have utilized it\nfor a diversity of data-intensive tasks, including exploratory data\nanalysis (4/8), data wrangling (4/8), confirmatory data analysis (2/8),\ndata profiling (2/8), and data retrieval (1/8). In addition, participants\nappreciated its flexibility in open-ended data analysis. “Compared\nwith software with rigid functionalities, I enjoy the freedom here [in\nChatGPT]. I can ask for an explanation based on the result, request\nrecommendations for the next step, or insert irrelevant questions. ”\n(P6) Another strength of an LLM-powered data analysis tool is its\nlow-code or no-code environment, where end users only need to\ndescribe the tasks and obtain a well-organized response in the form\nof code or report. For instance, P4, who works in investigative\ndata journalism [54] and regularly cleans and organizes datasets\nfrom various sources, stated “Having code generated from scratch\nsaves days of my work ”. This feature was particularly valued by\nparticipants who were not proficient in coding (2/8). “I no longer\nneed to care about detailed operations and learn the APIs. ” (P2)\n3.2.2 How do people work with LLM-powered tools in data analy-\nsis? We categorize participants’ workflows into three phases: code\ngeneration, post-verification, and iterative refinement.\nBy default, ChatGPT collapses the code and communicates the\nprogress in percentage only. Correspondingly, participants (7/8)\nhardly toggled the code panel during the generation phase but\ndistracted themselves by turning to personal matters or engaging\nin related side tasks like reviewing previous conversations.\nUpon completion of the code generation, every participant con-\nsistently reviewed the textual response and, if available, the visual-\nizations to grasp the analysis’s implications. Verifying the code’s\nreliability was a common concern, with most (6/8) participants\ninspecting the generated script, especially when the data insights\nwere important. They would look into the entire data processing\npipeline and specific parameters of individual operands. P4 some-\ntimes posed a validation question to verify the code’s correctness,\nsuch as requesting the mean value to see if it aligned with his prior\nknowledge. When the generated code was inconsistent with ex-\npectations, participants (6/8) attempted to recalibrate the agent’s\ndirection through refined prompts. P2 mentioned a special strat-\negy: “I try really hard to decompose the task into actionable items\nso that it won’t be too challenging for ChatGPT. ” Notably, some par-\nticipants (3/8) regenerated the response instead of starting a new\nconversation. “I am afraid to break the analysis flow with additional\nrequirements on a small step. ” (P3) For open-ended tasks, after ob-\ntaining initial results, participants may further drill down through\nconversation (3/8) or turn to a local coding environment (2/8), de-\npending on the trade-off between coding and prompting. “With the\ncode, I can easily reuse it on a (computational) notebook. ” (P1)\n3.2.3 What hinders human-LLM collaboration in data analysis tasks?\nThree themes emerge regarding glitches for users to participate in\ndata analysis assisted by LLM agents actively.\n⋄Disrupted workflow negatively impacts user engagement. As\ncode generation and execution are sometimes long-winded, it in-\nterrupts the analysis flow. Most participants (7/8) would shift focus\nduring the process instead of monitoring the generated code closely,\nfor code is not as intuitive or accessible as natural language. “I feel\nexhausted when reading the code, so I’d rather leave it alone. ” (P1)\nWithout timely intervention, tiny errors in the code may propagate\nand invalidate the analysis result, precipitating a need to revisit\nand revise the work. This leads to heightened frustration and a con-\nsiderable waste of time, as finishing one exploratory data analysis\ntask generally takes half to three minutes. To avoid such prolonged\ndialogue exchanges, P3 explicitly requested the agent to ask for\npermission before generating and executing, explaining that “(In\nthis way,) I can at least take control over the direction ”. (P5)\n⋄Verifying raw code is mentally demanding. While LLMs may\nprovide clear annotations to explain each step, many participants\n(7/8) still found verifying the generated code challenging.\nOn the one hand, reviewing the code snippet is inherently la-\nborious and counter-intuitive, particularly when deciphering code\nfrom an external source, which can be mentally taxing. After all,\nLLMs may not follow the coding styles the participants are com-\nfortable with. “It [LLM] sometimes uses much-advanced syntax, so I\nask it to write code like a freshman. ” (P5) Besides, LLMs may employ\nunfamiliar packages. “I don’t even know what the function parameter\nis about, let alone correct it. ” (P3)\nOn the other hand, LLMs may introduce various unexpected\nerrors in the code that require careful inspection, as evidenced in\nthe literature [9, 14, 18]. Table1 lists example issues. P6 noted LLM\nhallucinations: “At first look, the logic was awfully smooth, yet the\nparameter was a synthesized constant. It’s very tricky (to identify the\nissue).” Some participants (3/8) were concerned about the finding’s\nreliability but frustrated with limited approaches. “ I am not sure\nif the conclusion is correct. I have a tight time budget, so I check the\nmajor steps and cross my fingers for no other issues. ” (P8)\n⋄Iterations can be extensively back-and-forth. To fix identified\nissues, users need to formulate instructions regarding what is wrong\nand how to correct the errors and then wait for another generation-\nexecution-report cycle. Unfortunately, this process can become\ntime-consuming due to its trial-and-error nature and requires sub-\nstantial effort to communicate the nuances of the desired analysis\neffectively. Therefore, many participants (6/8) were reluctant to\nembrace the conversational workflow fully. For minor issues like\nrefining operational details, some participants (5/8) preferred to\ncopy-paste the code to a local environment and make adaptations.\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\n“It is more convenient to reuse the code than telling ChatGPT specif-\nically what to do. ” (P7) For major changes like adding a new pro-\ncessing step, they were more willing to communicate with the LLM\nagent since writing code becomes tedious. Still, after several trials,\nthey would turn to the local environment when losing patience.\n3.3 Design Considerations\nInformed by the formative study, we draw the following design\nconsiderations (DC) to guide our conception of an alternative in-\nteraction design for LLM-powered data analysis tools. Our design\ngoal is to support monitoring and steering LLM-synthesized\ndata analysis with interactive visual scaffolding .\nDC1. Abstract code stream into key data operations for a\nfocused verification. In the context of LLM-based data analysis,\na primary challenge emerges due to the often extensive and com-\nplex nature of the generated code. However, users usually prefer\nunderstanding the analysis process itself over the complex details\nof the code. Echoing a previous study [19], participants expressed\nthe need to access data operations, determinant parameters, and\ntheir outcomes. To address this challenge, we propose to simplify\nthe information to digest for verifying the data analysis proce-\ndure conducted by LLMs. By extracting the layered information\nconcerning individual data operations from the code, such as the\nparametric specifications and execution results, we aim to refocus\nusers’ attention on the analysis process itself, sparing them from\nthe overwhelming task of understanding the raw code.\nDC2. Scaffold data operations and execution results through\nstraightforward visualization generated on the fly. Despite\nthe abstraction, users, particularly those with limited program-\nming expertise, may still find it challenging to interpret the raw,\nsyntax-heavy output produced by LLMs. Drawing inspiration from\nprevious works in code visualization [42, 62], we adopt visual repre-\nsentations that abstract away from specific code syntax to facilitate\nquick comprehension of the data analysis process. Thus, the visual\nrepresentation should also expose this information, including the\ndata state before and after each operation. Moreover, this process\nshould be executed on the fly along the code generation process,\nensuring a seamless experience for the user aligning to their sense-\nmaking process. It is also critical to establish a connection between\nthe code and its visual representation. This will allow users to see\nthe direct impact of their instructions on the data and to navigate\nthe analysis workflow more effectively.\nDC3. Support interrogation to the LLM and iterative code\ngeneration in the visualization. An outstanding issue of LLM-\npowered data analysis in a conversational interface is the tedious-\nness of articulating refinement intents and uncertainties in LLMs’\nfollow-up responses. To overcome this, the visual representations\nshould simplify articulating these intents by providing mechanisms\nto modify the data analysis process at a granular level. Users should\nbe able to interact with individual steps (data operations) of the\ngenerated analysis, allowing them to make precise adjustments\nwithout the need to rewrite large portions of code or restart the\nconversation. This granular control empowers users to fine-tune\nthe analysis, accurately reflects their intentions, and streamlines\nthe iterative refinement process.\nFigure 2: We propose a workflow that identifies data oper-\nations within the generated code and maps them to visual,\ninteractive primitives on the fly. These primitives collectively\noffer an overview of the data analysis process.\nDC4. Embed visualization seamlessly into the conversa-\ntional user interface (CUI). As conversational data analysis nor-\nmally takes place in a CUI [9, 19], we tailor the design to common\ndesign patterns of web CUIs in a non-intrusive manner. For instance,\nthe visualization should be stably revealed during the progressive\ngeneration, following the same vertical order as the code. It should\noffer a lightweight complementary view of the code section in the\nLLM’s response (see Figure.2) and afford a level of visual guidance\nfor the code dependency between conversational threads.\n4 WAITGPT: USAGE SCENARIO\nInformed by the formative study and design considerations, we\npropose dynamically visualizing the code generation process to\nhelp users steer a conversational LLM agent during the data analysis\nprocess. This is achieved through a workflow that identifies data\noperations within the generated code and maps them to visual\nprimitives on the fly (see Figure. 2). These visual primitives not\nonly illustrate the static aspects of data operations but also display\nthe runtime states of the underlying data (i.e., tables) both before\nand after these operations. Moreover, they provide users with rich\ninteraction possibilities, allowing them to refine the data operations\nwithout regenerating the code entirely.\nWe instantiate this idea with a prototype system, WaitGPT,\nwhich enables users to proactively guide the data analysis process\nwith an LLM agent, making interventions akin to saying, “Wait,\nGPT, there is something wrong... ” This section walks through Wait-\nGPT using a hypothetical use case, demonstrating its capacity to\ntransform the user’s interaction with LLMs in data analysis tasks.\nUsage Scenario. Zoey, a college lecturer, would like to review\nher students’ performance across assignments to inform future\nteaching strategies. She opened WaitGPT, an LLM-powered conver-\nsational tool for data analysis that she was familiar with.\nWaitGPT’s interface resembles a chat box, allowing users to up-\nload spreadsheets and inquire about the data in natural language\n(Figure.3). Upon uploading two spreadsheets — one detailing stu-\ndent profiles and the other their individual assignment scores —\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\nFigure 3: A screenshot of the WaitGPT user interface. (A) An enlarged view of the flow diagram representing the code. (B) An\nillustration of the “table glyphs” that flow along the edge showing table dependency and changes during code generation. (C)\nInspecting intermediate data by toggling the interactive table panel. (D) Interrogating LLM based on an operation.\nZoey asks WaitGPT to compare the performance of students with\ndifferent backgrounds. In response, WaitGPT outlines a plan to meet\nher requirements, then crafts a code snippet to conduct analysis.\nAn external executor executes this code snippet to yield results.\nUnlike similar tools, WaitGPT visualizes the data analysis process\ninstead of just presenting raw code and textual execution results\n(Figure.3 A). It dynamically extracts data operations and presents\nthem as nodes within a diagram illustrating the data flow. For in-\nstance, a “join” operation node would display as “merge”. And the\nnode shows the tables being joined, the type of join (e.g., left join,\ncross join, etc.), and the indexing column used for the join. These\nblocks are linked based on dependencies and posited from left to\nright to reflect the procedural order. Notably, WaitGPT breaks down\nthe analysis script into executable blocks that are executed imme-\ndiately instead of executing until the entire code snippet is ready.\nThis allows for a progressive understanding and debugging process,\nenabling users to see the effects of each operation in real time. The\ntool also visualizes the runtime state of data tables (e.g., the number\nof data entries/columns, selected columns) as part of the diagram.\nSpecifically, the runtime state of each table is visualized as glyphs,\nwhich move along the linked edges between operation objects.\nThrough the visual representation, Zoey quickly spots a flaw in\nthe diagram—the row number reduces (Figure. 3 B). Rather than\nrequiring rewriting the original query and regenerating the entire\ndata analysis code, WaitGPT enables users to refine specific opera-\ntions directly within the visualizations. Users can directly update its\nparameters, inquire about details, and indicate refinement intents\nthrough natural language. Thus, Zoey adjusts the join parameters\nto student IDs, and then clicks on the re-run button to execute\nthe updated code. While the analysis goes on, Zoey inspects the\ntable. She requests the LLM to clean the data. The diagram updates,\nreflecting the corrected scores after the agent integrates a data vali-\ndation operation. Now Zoey is ready to analyze the reliable data,\nher teaching plans are secure on a foundation of accuracy.\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\n5 WAITGPT: SYSTEM DESIGN\nThe design of WaitGPT consists of three major components: ab-\nstracting the code to data operation chains, visualizing these chains,\nand providing interactions to steer the analysis process.\n5.1 Abstracting Code to Operation Chains\nBased on the interview, we identified three types of information\nindispensable for code comprehension: table variables, data op-\nerations, and execution results. In addition, different data opera-\ntions encapsulate dedicated semantics and independent parameters.\nTherefore, we opt to abstract a data analysis process into a graph\nstructure, chaining its nodes with an input-output relationship as\nfollows (DC1). The input of each data operation is table(s), whereas\nthe output can be the updated table, new table(s), other derived\nvalues/visualizations, or none.\n∗Table node : A table node corresponds to a variable for an un-\nderlying table in the code, such as a dataframe in the Pandas\npackage. It can be either loaded from a data file or dynamically\ngenerated during code execution as an interim variable.\n∗Operation node : An operation node ties to an atomic data opera-\ntion. It surfaces the detailed parameters of an operation object,\ne.g.,, Select, Filter, and Sort.\n∗Result node : A result node is associated with an execution result,\nsuch as printed values or data visualization.\nAdditionally, the relationship between these nodes can be one\nof the following:\n∗Input: From table node(s) to an operation node. It means the data\noperation is based on the input table(s).\n∗Assignment: From an operation node to a new table node. It\nmeans a new table-typed variable is yielded from the operation.\n∗Result generation : From an operation node to a result node. It\nmeans the operation outputs some visible results.\n∗Operation chain : From an operation node to an operation node.\nIt means a table undergoes the two operations sequentially.\nExtracting the Nodes through Static Analysis. To extract these\nnodes and relationships, we perform static analysis on the ab-\nstract syntax tree (AST) of the generated code, where we apply\nheuristics informed by patterns of data analysis scripts and func-\ntional interface design of relevant packages. WaitGPT currently can\nparse atomic operations including Load Data, Inspect, Select,\nFilter, Sort, Transform, Group, Aggregate, Merge, Add\nColumn, and Visualize, based on the Pandas, Matplotlib, and\nSeaborn packages, which are the default choices of ChatGPT and\nwidely adopted [6]. For instance,merge_df = df[[\"attr_1\", \"attr_2\n\"]].sort() will be converted into two operation objects: Select\nand Sort. To bind the table targets to the operations, we maintain\na global variable of existing table variables. This is because a table\nvariable can only be created by being loaded from external sources\n(files, database, etc.) or generated as the output of prior operations.\n5.2 Visualizing Data Operation Chains\nOur goal is to transform the LLM-generated code into easily in-\nterpretable visualizations, facilitating user inspection of the data\nanalysis process (DC2). To this end, we have developed a suite of\nvisual primitives, which present the details of each operation and\ntheir internal runtime states. These primitives are chained together,\ncollectively offering an overview of the data analysis process.\nVisual primitives for the static code. We utilize a diagram to rep-\nresent the graph-based data processing procedure for individual\ncode snippets. The table node, operation node, and result node are\nvisualized as blocks, color-encoded in yellow, pink, and white. A\nnode-style visualization is chosen for its familiarity to general users\n(DC2) and flexibility in displaying layered information, expanding\nwith the code stream, and implying the operation order ( DC4).\nAs LLMs sometimes synthesize long variable names for clarifica-\ntion, we considered a rectangular block beneficial for encapsulating\nthis information. For simplicity, a table node only shows the cor-\nresponding variable name, and a result node shows a thumbnail.\nFor an operation node, we use a bold font style to prioritize the\ncommunication of its type (e.g., filter, group, etc.). And we visually\ndifferentiate its parameters’ names and values through typography.\nAn operation chain spans from top to bottom, following its pro-\ncedure. For a table node, there can be multiple associated operation\nchains. These chains are aligned from left to right with respect to\nthe execution order. A code snippet depends on preexisting code\nas the runtime environment is shared throughout a conversation.\nTherefore, a table node may trace back to previous snippets. To\nreflect such a relationship, a copy is made in such a situation, which\nis linked to its previous occurrence with a cross-conversation curve.\nVisual primitives for the runtime states. The diagram is further\nenriched by visual glyphs that encode the runtime status of table\nvariables. A table glyph takes a common visual representation for\ntables—a 2D matrix. The number of matrix columns is the same\nas the column number of the table. The number of matrix rows\nper column is proportional to the number of table rows to roughly\nindicate changes in data size and scale to different data sizes. To ac-\ncess precise information about the runtime states, one may interact\nwith the associated operation node for details. Through chained\noperations, the size of a table can be updated.\n5.3 Steering the Data Analysis of LLMs\nThe diagram goes beyond merely a visual representation of the\ndata analysis process. It also acts as an interactive scaffold for users\nto steer data analysis code generated by LLMs, enabling real-time\ninspection, retrospective examination, and granular refinement\n(DC3). This section introduces interactions supported in WaitGPT.\n5.3.1 Real-Time Inspection on the underlying code.During code\ngeneration, only the diagram is shown to reduce the cognitive load\nof end users. However, they may still toggle on the code panel and\njuxtapose the diagram side-by-side. When a data operation is being\nactivated, i.e., the external executor has just run the code, it will\nbe added to the diagram, potentially introducing a new table node\nor a result node. Meanwhile, relevant table glyphs also appear and\ngradually flow from the previous node to the current node. Figure.4\nshowcases an example of the dynamic process.\n5.3.2 Retrospective Investigation on the analysis process.After the\ncode and diagram are completely generated, users may perform a\nretrospective examination to verify the procedure and investigate\npotential issues. To evaluate the analysis flow, users may replay\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\nFigure 4: An illustration of how the diagram grows with\nanimated table glyphs during the code generation process.\nthe animation showing diagram expansion or utilize scrolly-telling,\nwhere they can take control over the animation progress using\nscroll-based interactions ( DC4). If the code panel is toggled on,\nthe corresponding line(s) of code will be highlighted for activated\nnodes upon re-play or the user’s mouse hover events (see Figure.5\nA). This feature bridges the visual representation and the textual\ncode, visual navigation and troubleshooting. Essentially, nodes in\na diagram are visually displayed in the simplest way to support\nfast comprehension. To access details about the underlying data\ntables in the runtime context, users may click on a node of interest\nand review an additional panel (see Figure.5 B). The thumbnail of a\nvisualization result node is expandable (see Figure.5 E).\n5.3.3 Granular Refinement. The diagram offers new interaction\nmodes for granular refinement through direct manipulation and\ncontextual interrogation. Instead of regenerating the entire analysis,\nwhich may involve multiple code snippets, users can steer the data\nanalysis at a finer granularity within the visualization (DC3). Users\nmay directly manipulate the operation objects based on their visual\nrepresentation and update the underlying code (see Figure.5 D). The\nfields of parameters in operation nodes are editable input forms,\nallowing fine-grain updates.\nSimilar to the concept of interrogative debugging [ 30], users\ncan select specific operation nodes within the diagram and then\nrequest explanations or suggest revisions to the LLM by focusing\non a particular node, which offers a targeted context for verification\nand refinement (Figure.5 C). This provides an alternative mode to\nthe common practice of selecting code or table cells and posting\nqueries to LLMs [43]. Inspired by the regeneration practice of par-\nticipants in the formative study, the query is independent of the\nmain conversation and, thus, will not affect the memory of LLM\nagents. The LLM’s suggestion of code update will directly apply to\nthe code panel, and the previous version will be commented out for\ncomparison. When satisfied with the refinement, users can re-run\nthe code snippet to attain updated analysis from LLM agents based\non the new execution results.\nFigure 5: The visualization offers multiple interactions for\ninspecting and refining the underlying data analysis. Users\ncan: (A) toggle a table node to view the underlying data; (B)\nhover over a node to highlight its corresponding code; (C)\nmodify a data operation using natural language; (D) directly\nmanipulate the parameters of a node; and (E) view the result-\ning visualizations from the analysis.\n6 IMPLEMENTATION\nWaitGPT is a web-based app implemented in the React [40] frame-\nwork based on TypeScript. We apply the Monaco Editor [ 41] to\ndisplay the code with standard syntax highlighting. We adopt the\nOpenAI’s API, with the gpt-4-0125-preview model. To manage\nuser-uploaded files, parse LLM-synthesized code into an abstract\nsyntax tree, and obtain its execution result, we also host a back-end\nserver implemented in Python with Flask [48]. The LLM prompts\napplied in WaitGPT generally follow the guidance of OpenAI with\nlittle engineering effort. Our implementation integrates three key\nmechanisms as follows.\nSession Management. In addition to the conversation history for\neach session, WaitGPT maintains other contexts to support dia-\ngram generation on the fly and granular refinement. The associated\ncontexts include a sandbox environment for file storage and code\nexecution, a global record of table variables, and specifications of\nthe diagram for each data analysis code snippet. In addition to the\nparsed parameters, the runtime status of target tables, and render-\ning configurations, the specification of a data operation node in a\ndiagram also records conversation logs with the LLMs based on the\ncode to support iterative refinement.\nWhen a user sends a query, the LLM will respond with textual\ncontents or a function call to the pre-declared Python executable.\nFor code-based response, WaitGPT first decides whether it is about\ndata analysis and then activates the automatic parser. The runtime\ncontext for each code snippet is cloned from the main process and\ncached for potential rework, thus enabling flexible user interrup-\ntions and refinement at any point. We enhance user navigation by\nprompting LLM to summarize the main task and build a minimap\nfor existing data analysis snippets.\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\nSandbox Execution. Before running the code in a sandbox envi-\nronment, WaitGPT refactors the method chain into separate stan-\ndalone statements. Therefore, based on the identified targets (i.e., ta-\nble variables) of data operations, the static parser inserts printing\nstatements based on templates to retrieve the intermediate status\nof the table, including the number of rows, the number of columns,\nand column names. The table status is then bonded to the corre-\nsponding data operation object. As a note, we opt to insert code\nto the LLM-generated script in a post hoc manner to reduce de-\npendency on specific versions. An alternative approach is to inject\nlogging facilities into the standard libraries [50, 55].\nRendering. The rendering of the flow diagram comprises two\nsteps. Once the static analyzer extracts new data operation objects,\nthey will be added to the diagram using a graph layout algorithm\nand maintain inactivated status. When the runtime information is\nbound to the operation object, its animated effect is pushed to a\nqueue to play sequentially, where the corresponding node will be\nactivated and the table glyph will flow from the prior node to the\ncurrent node.\n7 USER EVALUATION\nWe evaluate WaitGPT through an in-lab user study with 12 partici-\npants of various backgrounds and data analysis expertise. Specifi-\ncally, we are interested in the following research questions.\n•How effectively does WaitGPT facilitate intermediate verification\nduring the generation process of LLM agents?\n•How effectively does WaitGPT support retrospective verification\nafter data analysis tasks are completed?\n•To what extent does WaitGPT support the granular refinement\nof generated code snippets?\n•How do users perceive the usefulness of WaitGPT in their daily\ndata analysis tasks?\n7.1 Participants\nWe recruited 12 participants (10 males, 2 females; ages 23—30, M =\n26.33, SD = 2.15) through social media and word-of-mouth. They\nwere postgraduate students with diverse backgrounds in databases,\nmachine learning, visual analytics, industrial engineering, compu-\ntational sociology, and HCI. According to their self-rating based on\na 5-point Likert scale (1: lowest extent, 5: greatest extent), partici-\npants were generally adept at data analysis (M = 3.67, SD = 1.37)\nand familiar with the Pandas syntax used in WaitGPT (M = 3.5, SD\n= 1.38). They were experienced with LLM-powered chatbots (M =\n3.75, SD = 1.06). Specifically, 5/12 participants leveraged ChatGPT\nto analyze more than 20 datasets, whereas 4/12 analyzed less than\n5 datasets on ChatGPT.\n7.2 Protocol\nTasks. There are three tasks in total. Task A is based on the Em-\nployee dataset1 with six analysis tasks (A1–A6). Task B is based on\nthe Flight dataset2 with four tasks (B1–B4). For Tasks A & B, the\nparticipants are required to address individual questions by interact-\ning with LLMs and decide if the LLM-generated code is error-free.\n1https://www.kaggle.com/datasets/soorajgupta7/corporate-compensation-insights\n2https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction\nTo cover representative cases, we included both confirmation and\nexploratory tasks on two tabular datasets and replicated 4 known er-\nrors made by LLMs [19]. In addition, we prepared dedicated prompts\nfor the participants to ensure that the first LLM-generated content\nwas identical in each task. These prompts are grounded in the AR-\nCADE [74] and Text2Analysis [ 23] datasets. Each data analysis\ntask is independent of the other, including common data insight\ntypes [13], e.g., rank, distribution, outlier, etc. Task C is based on the\nsynthesized dataset used in the usage scenario (see Sec.4), where\nparticipants were asked to explore the dataset freely. We also offer\na list of self-curated queries for their reference.\nBaseline and Apparatus. We removed the extended view of the\ndiagram as the baseline system, namely Baseline. Baseline retains es-\nsential functionalities of ChatGPT that the participants are familiar\nwith. The code snippet offers by-line textual comments explaining\neach step for user verification and has standard syntax highlighting\nfor Python. Meanwhile, Baseline shares the same visual appearance\nas WaitGPT. This ensures that any differences in user interaction\ncan be attributed to the diagram’s presence or absence rather than\nother factors like aesthetics or layout. Participants joined the study\nin person and finished their tasks on standardized desktop devices\nto eliminate hardware variability as a confounding factor.\nProcedure. We opted for a counterbalanced within-subjects de-\nsign to compare WaitGPT and Baseline. There are two groups (I,\nII) that participants were randomly assigned to. In Group I, partici-\npants finish A1-3 & B1-2 in Baseline, and A4-6 & B3-4 in WaitGPT.\nConversely, in Group II, participants finish A1-3 & B1-2 in WaitGPT,\nand A4-6 & B3-4 in Baseline. This approach allowed each partici-\npant to experience both conditions while performing a balanced\nset of tasks across the two systems.\nThe user study begins with a presentation of the visualization\nand interaction design, where participants can ask for details (5\nmin). Then, the participant should work on Task A1-6 (15-30 min),\nTask B1-4 (10-20 min), and Task C (5-15 min) sequentially. The study\nends with a semi-structured interview (10-15 min) and a question-\nnaire (5 min). A facilitator conducted one-on-one sessions with\neach participant, closely observing and taking notes of participant\nbehaviors. The post-study interview was audio-recorded for later\nanalysis. Participants were compensated with $12 per hour.\n7.3 Measures\nWe adopted the NASA-TLX [22] questionnaire to measure the per-\nceived cognitive load in steering LLM-synthesized data analysis.\nWe developed a questionnaire based on a 7-point Likert scale to\nevaluate the usefulness of WaitGPT. For each pre-recorded query,\nthe facilitator records (1) the time cost that the participant discerns\nissues in the result since response generation, (2) the time cost that\nthe participant makes a judgment on the correctness, (3) whether\nthe data has been examined, and (4) whether the code panel is\nexpanded when viewing diagrams only.\n7.4 Results\nTo compare Baseline and WaitGPT, we analyze task correctness\nfor Task A & B and the subjective ratings of the participants. We\nfurther report insights from the interview,\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\nTable 2: The success rate (%) and average duration (seconds) in WaitGPT and Baseline for Task A & Task B (N=6/condition). The\nfailure column describes the mistake made by LLMs in the task. #Line: No. lines in the code snippet; #Char: No. characters. #Df:\nNo. table nodes in the data operation chains, #Op: No. operation nodes, #Res: No. result nodes. “(Value)”: standard deviance.\nTask Failure #Line #Char #Df #Op #Res Success (%) Average Duration (s)\nWaitGPT Baseline WaitGPT Baseline\nA1 Sort on string 14 474 2 5 0 83 (0.41) 33 (0.52) 65.83 (45.32) 136.67 (88.69)\nA2 Miss a group condition 5 233 2 3 0 50 (0.55) 50 (0.55) 88.33 (40.21) 102.50 (68.68)\nA3 NA 47 1,836 5 10 1 100 (0.00) 100 (0.00) 154.00 (103.00) 151.67 (143.69)\nA4 Miss a filter condition 10 509 3 4 0 67 (0.52) 83 (0.41) 86.67 (18.62) 92.50 (34.31)\nA5 Miss dropping duplicates 24 780 1 5 1 50 (0.06) 50 (0.55) 92.50 (58.37) 87.50 (27.34)\nA6 NA 21 817 1 3 1 100 (0.10) 100 (0.00) 144.17 (69.02) 95.83 (22.45)\nB1 NA 29 1,167 4 7 1 100 (0.00) 83 (0.41) 141.67 (49.97) 160.00 (82.16)\nB2 Miss dropping duplicates 25 1,287 5 6 1 67 (0.52) 50 (0.55) 242.50 (167.74) 221.67 (159.80)\nB3 NA 25 1,262 4 6 1 100 (0.00) 100 (0.00) 185.00 (113.31) 176.67 (64.94)\nB4 Wrong aggregation logic 10 654 4 6 0 83 (0.41) 83 (0.41) 212.50 (145.87) 138.50 (40.71)\n7.4.1 Task Correctness. Table 2 lists detailed configurations and\nparticipant performance in Task A1-6 and B1-4. In general, the\nsuccess rates in the WaitGPT condition are no less than the Baseline\ncondition, except for A4. A4 asked for 10 employees with the highest\nsalary currently, whereas LLM did not filter out those on leave.\nMany participants did not notice this problem in the response. As\nfor the duration, the two conditions had similar time costs (≤10s)\nfor Task A3-5 and B3. And WaitGPT took less time in Task A1-2\nand Task B. However, multiple factors are attributed to the total\nduration, as seen in the relatively large standard deviation values.\nFor instance, we did not consider expertise in data analysis when\nassigning participants to different groups. When the participant\nchose to inspect the code after viewing the diagram, there was an\nadditional time cost to browse the code.\n7.4.2 Subjective Ratings. As the questionnaires are based on an\nordinal Likert scale and the sample size is relatively small, we\nperformed the Wilcoxon signed-rank test to compare the subjective\nratings between Baseline and WaitGPT.\n⋄On the cognitive load. In the NASA-TLX questionnaire, Wait-\nGPT demonstrates lower cognitive demand to the participants. Ac-\ncording to the statistical tests, there are highly significant differ-\nences (p<.001) in the mental and physical demand, performance,\nand affective states between the two conditions. The difference in\nthe effort to accomplish self-performance level (p=.010) and the\ntemporal demand (p=.050) is also significant.\n⋄On the usefulness. Figure.6 compares the distribution of the\nuser ratings on Baseline and WaitGPT based on our self-developed\nquestionnaire. For each question, WaitGPT attains a higher median\nrating than Baseline at a confidence level of 99.5%, demonstrating\nits usefulness in demystifying the analysis (Q1-3), verifying or\ncorrecting the code (Q4-5), and engaging end-users (Q6). Notably,\nwhile participants varied in task performance, 10/12 people reported\nincreased confidence in the correctness of the analysis result (Q1).\nBesides, based on a 7-point Likert scale (1: strongly disagree, 7:\nstrongly agree), the participants considered it easy to comprehend\nthe visualization design (Med=6.5, M=6.65, SD=.87) and interact\nwith the diagram (Med=6.0, M=6.33, SD=.65).\n7.4.3 General impressions. The participants were generally pos-\nitive about WaitGPT and affirmed its support in monitoring and\nsteering LLM-generated analysis.\n⋄Difference in the UX between conditions. Despite in-line ex-\nplanations and meaningful variable names in the LLM-generated\ncode, the participants found it mentally taxing to follow the source\ncode and unguided in verification. The reasons include memory\ndemand for excessively long content (8/12), limited runtime con-\ntexts (3/12), and unfamiliar coding styles (2/12). In comparison,\nparticipants (12/12) resonated with the ease of understanding and\nverifying the code in WaitGPT with a higher level abstraction. The\ndiagram “strips off unimportant details ” (P5) and offers an overview\nof the code. “It [the diagram] has a clean structure and can serve as\na navigation for the code. ” (P11) This also kept participants engaged\nduring the code generation. “I felt stressed viewing the code stream,\nbut it’s a pleasure to watch the diagram grow. ” (P4) The benefits of\na visual summary were more apparent when the underlying code\nwas long, as the diagram fit in the screen without the need to scroll\nvertically or horizontally (3/12). Lastly, many participants (8/12)\nwere positive about the node-based interaction instead of sending\na new chat. “There’s a chance that a new chat introduces new errors,\nso I prefer to change the code directly. ” (P9)\n⋄Perceived usefulness of the visualization. The current visual\ndesign was well-received by the participants (12/12). We catego-\nrize the perceived usefulness of the extended visualization and\nassociated interactions into three dimensions.\nFirst, the diagram offers an abstract layer to focus on high-level\nlogic and task decomposition. As observed by P12, “ GPT outputs\npretty code with mostly correct functional calls. This makes me lose\ncaution for logical errors. ” P3 claimed that the visualization facil-\nitated LLM alignment—“I have a rough idea of how to process the\ndata, and the diagram makes it easy to compare with my mind map. ”\nSecond, the visualization surfaces information at different layers,\nincluding the detailed parameters for data operations, profiles of\nthe data table, and navigation back to the source code. For instance,\nthe high accuracy rate for Task A1 was due to the convenience\nof inspecting data tables. “It’s great to access the table right away.\nIt’s [the diagram] like an information hub. ” (P10) P3 appreciated\nthe typography applied in the operation nodes, as “it separates the\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\nSt r on g l y Di s a g r e e\nDi s a g r e e\nS ome wha t Di s a g r e e\nN e i t her Di s a g r e e or a g r e e\nAg r e e\nS ome wha t a g r e e\nSt r on g l y Ag r e e\nQ1: C onfi d e nce in corr e c t ne s s\nQ2: L e arn ho w s y s t e m w or k s\nQ3: F ac ili t a t e co d e und e r s t anding\nQ4: F ac ili t a t e co d e v e r i fi ca t i on\nQ5: E a s y t o corr e c t mi s t ak e s\nQ6: En j o y me n t\nB a s e l i ne W ai t GP T\n0% 2 5% 50% 7 5% 100%\n1\n1\n2\n3\n4\n3\n4\n1\n1\n2\n3\n4\n3\n3\n1\n2\n3\n3\n2\n5\n5\n4\n2\n4\n2\n1\n2\n1\n1 1\n1\n4\n1\n2\n5\n5\n8\n9\n7\n4\n5\n6\n2\n3\n1\n1\n6\n0% 2 5% 50% 7 5% 100%\nFigure 6: User ratings on the baseline (code-only interface) and WaitGPT.\nvariable names, operations, parameter names, and parameters ”. P7\nnoted that the table glyphs suggested the semantics of unfamiliar\nfunctions through the input-output trace.\nThird, the node-based interactions offer a granular approach to\ninterrogating or modifying the code. “ I prefer talking to nodes in\nthe diagram because the context is preserved, so I don’t need to type\nmuch. It’s nice to have something to point to make things clearer. ” (P9)\nSome participants (2/11) felt more comfortable manipulating the\nnodes than overwriting the code. “ Here [in the diagram], I don’t\nneed to care much about syntax but doing minimum updates. ” (P5) In\naddition, the context of a node-based interaction is constrained to\nthe corresponding code section parallel to the entire conversation.\n“I am happy to maintain a clean conversation thread. ” (P11)\n7.4.4 Glitches in using WaitGPT.Despite the benefits mentioned,\nusers encountered several glitches while using the prototype.\n⋄Diverse needs for level of details. Participants had divergent\nperspectives on the current design of WaitGPT. For instance, P10\nexpressed the hope of showing relevant annotations directly on\nthe operation nodes. For the table glyphs, a few participants (2/12)\ncompetent in data analysis criticized them as trivial. “ I’d prefer\na small annotation showing the table dimensions. ” (P9) However,\nsome participants (3/12) embraced the design and commented that\nits animation double encoded the program procedure, in addition\nto the implicit node layout from left to right—“When the code has\ncomplex dependencies, I can follow the operations step by step with the\ntable glyphs. ” (P2) To accommodate diverse needs, a customizable\ninterface is anticipated for flexible user configuration.\n⋄Concerns in the reliability & expressiveness. Participants with\na computer science background (8/12) were generally interested\nin how the code was transformed into the diagram and expressed\nconcerns about algorithmic failures (1/12) or potential information\nloss (2/12). Like what P12 asked: “ What if it [LLM] made errors\nin parameters not presented in the diagram? ” P6 recalled that he\nsometimes copied his code and prompted LLMs to use customized\nlambda functions for data transformation. However, in the current\nimplementation, WaitGPT will only tag this as a “lambda function”\nwithout presenting more details due to the limit of current heuris-\ntics. As there are limited datasets on LLM-synthesized data analysis\ncode at the moment, it remains challenging to systematically eval-\nuate the coverage of our heuristics. To mitigate these concerns,\nfuture improvements may incorporate automatic verification of the\nparsing results and generative AI to surpass expressiveness limits.\n7.4.5 Opportunities for Applications. The participants shared sev-\neral creative ideas for extending WaitGPT. P8 wanted to transfer the\nunderlying concept into a visualization authoring context, where\nthe encoding specifications are procedural and atomized—“After an-\nalyzing the data, I need to present it with high-quality visualizations,\nbut tools like ChatGPT often fail my expectations. ” P7 saw the value\nof a diagram in communication, especially to an audience with\nlimited technical backgrounds. He said: “I can use the scroll-telling\nin my presentation to explain how the data has been transformed. ”\nP3 envisioned a visual programming paradigm in which the basic\nbuilding blocks can be self-composed or reused to communicate\nintention in addition to textual prompts to LLMs.\n8 DISCUSSION\nIn this section, we synthesize the implications and potential avenues\nfor future research and reflect on the limitations.\n8.1 Design Implications\nMonitoring LLM agent through “visible hands”. Despite recent\nprogress, known issues like hallucinations in LLM agents warrant\nexternal steering. In WaitGPT, we abstract the LLM’s generated\ncontent into high-level operations rather than raw text outputs,\nwhich align more closely with human cognitive processes. Our ap-\nproach also enriches the design space of AI resilient interfaces [20].\nThrough static analysis, WaitGPT translates synthesized programs\ninto abstracted operations. These abstracted operations are brought\nto life through dynamic visual representations, making it possi-\nble for end-users to monitor the actions of LLM agents, similar\nto watching “visible hands” in real-time. Future design may con-\nsider a similar mechanism of semantically rich representation and\nincremental update [76] in communicating agent actions.\nScrollytelling for LLM-generated content. WaitGPT incorporates\na basic form of scrollytelling, guiding users through the code by\nhighlighting the corresponding diagrams as they scroll through the\ngenerated content. By combining the flow diagram with a scroll-\ntriggered revealing mechanism, this technique aligns naturally with\nthe generating process of LLM-produced content, fostering a deeper\nengagement and understanding of the content. Looking ahead, we\nadvocate developing automated streaming methods to create scrol-\nlytelling narratives for presenting LLM-generated content. This\ncomplements the animation in the steaming generation phase, al-\nlowing users to control their understanding speed rather than pas-\nsively following a predefined playing timeline.\nAddressing context composition in different task granularity. One\ninteresting property of LLMs is that they can provide reasonably\nhigh-quality responses to a wide variety of user tasks [57]. Echoing\nour formative study, users may request background information or\nincorporate more contexts when analyzing data. They may start\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\na sub-thread to test their assumptions [ 18]. The highly diverse\nand evolving nature of user tasks in LLM-powered data analysis\nnecessitates the development of adaptive user interfaces. A more\nchallenging direction is to generate visual representations for mis-\ncellaneous contexts in unpredictable LLM responses.\n8.2 Future Works\nDemocratizing data consumption with verifiable generative AI.\nWith nowadays generative AI, individuals without a programming\nbackground may easily create data visualizations for analysis or\ncommunication. However, such democratization comes with chal-\nlenges, particularly in ensuring the accuracy and reliability of AI-\ngenerated content. There’s a pressing need to navigate users to the\npotential inaccuracies and biases inherent in AI outputs [7, 28, 77].\nWe believe that the key to fully leveraging AI’s capabilities in data\nconsumption hinges on creating user interfaces that align with the\nexpertise levels of the intended users. In addition, different data\ntasks raise different requirements warranting tailored supports,\nsuch as an emphasis on the authorial intent matching of encoding\nschemes in expressive visualization design (e.g., [61, 70]).\nIntroducing a “stop” mechanism in human-LLM agent interaction.\nWhile WaitGPT is based on a chatbot-like interface, such an inter-\naction paradigm can apply to a standalone AI assistant integrated\ninto data analysis software or notebook platforms [38]. Essentially,\nduring the ongoing conversation with LLM agents, users may be\noverwhelmed by the token-based output and fail to prevent propa-\ngating errors in time. WaitGPT integrates proactive strategies to\nidentify and rectify potential failures in AI-generated content. Sim-\nilarly, future works may further enrich the design space of visual\nrepresentations of LLM outputs [4, 20] for instant understanding\nand explore a low-cost approach to facilitate steering content gen-\neration based on intermediate outputs.\nExploiting interaction modalities in conversational data interface.\nFirst, beyond textual prompts with simple selections of data slices\nin ChatGPT, future systems may incorporate other input types like\ndirect manipulation [37], demonstration [24], and reference [71].\nSecond, to navigate users in nuanced decisions with drill-down\nexplorations [18, 19], it is promising to provide explanations on\ndemand [39], or establish a tighter connection between code, data,\ntextual analysis, and generated visualizations [5, 66]. Last, enabling\nusers to directly reuse the generated code or interact with the result-\ning visualizations for further exploration [16, 67] could augment\nthe flexibility of conversational data analysis tools.\n8.3 Limitation\nThreats to validity. The sample size in our formative and evalua-\ntion studies is relatively small and thus may not be representative\nof the broader population of data analysts and LLM users. In the\nevaluation study, both conditions were equipped with standard\nsyntax highlight for Python language. However, without a careful\nvisual design for key operations in the Baseline, participants may\nfavor more on WaitGPT with its simplified information. Besides,\nparticipants were prompted to view the transformable representa-\ntion of the data analysis script, which may not reflect their natural\ninteraction patterns. The reported usability rating may also be sub-\nject to response bias [11] and participants’ familiarity with the tasks.\nFuture works may investigate how and how often users leverage\nthis augmented view in their natural working space without explicit\nprompts to capture its real-world utility.\nScalability issues. In the framework, translating code into a flow\ndiagram requires static analysis, which is dependent on the syntax.\nWaitGPT is currently tailored to Python language and libraries\nlike Pandas and Matplotlib for tubular data. A potential solution\nto improve generalizability is to redesign LLM prompts to allow\na mixed output stream of code and underlying operation objects,\ne.g., [28, 58]. However, the code stream visualization may not work\nfor SQL-like languages with a reversed execution order compared\nto the procedure declaration. Second, the flow diagram assumes a\nlinear structure in the code, targeting fluent interfaces [55]. Future\nworks can incorporate control flows like loops and visual primitives\nfor other data types. Last, the current glyph design may not scale\nto tables with over 20 columns. To address this, unused columns\ncan be aggregated, or important ones can be hidden.\n9 CONCLUSION\nIn this paper, we introduced WaitGPT, a novel interface design\nthat transforms LLM-generated code into an accessible, interactive\nrepresentation to address the reliability issues and user challenges\nin LLM-powered data analysis tools. Drawing from an interview\nstudy with general users (N=8) of ChatGPT, we gained insights into\ngeneral perspectives on these nascent tools and glitches in disrup-\ntive workflow, code verification, and labor-intensive iterations. By\ntranslating stream-based code into a growing visualization of the\nkey data operations and affording granular interactions, WaitGPT\nempowers users to monitor and steer data analysis performed by\nLLM agents. A user study (N=12) covering basic data analysis tasks\ndemonstrated that WaitGPT could enhance error detection rate and\nimprove overall confidence in the results.\nOur work contributes to the field of human-AI collaboration in\ndata analysis by demonstrating the effectiveness of transformable\ncode representations in facilitating user understanding and engage-\nment. As LLM applications in data analysis become more prevalent,\nprioritizing user experience and trust through accessible, interac-\ntive interfaces will be crucial in harnessing the potential of these\npowerful tools while ensuring their reliability and usability. We\nurge more exploration of novel human-LLM interaction paradigms\nand intuitive visual representation design for LLM responses.\nACKNOWLEDGMENTS\nThis research is supported by RGC GRF grant 16210321. The first\nauthor thanks Prof. Hanspeter Pfister for hosting the visit to the\nHarvard Visual Computing Group. We also thank the anonymous\nreviewers for their constructive feedback, the participants in the\nformative and user studies, and Zhan Wang, Leixian Shen, Xiaofu\nJin, Shuchang Xu, Dr. Yanna Lin, Dr. Qingyu Guo, and Dr. Yun\nWang for their valuable input.\nWaitGPT: Monitoring and Steering Conversational LLM Agent in Data Analysis with On-the-Fly Code Visualization UIST ’24, Oct 13–16, 2024, Pittsburgh, PA\nREFERENCES\n[1] Tyler Angert, Miroslav Suzara, Jenny Han, Christopher Pondoc, and Hariharan\nSubramonyam. 2023. Spellburst: A node-based interface for exploratory cre-\native coding with natural language prompts. In Proceedings of the Symposium on\nUser Interface Software and Technology (UIST) . ACM, New York, NY, Article 100,\n22 pages. https://doi.org/10.1145/3586183.3606719\n[2] Christian Bors, Theresia Gschwandtner, and Silvia Miksch. 2019. Capturing and\nvisualizing provenance from data wrangling. IEEE Comput. Graph. Appl. 39, 6\n(2019), 61–75. https://doi.org/10.1109/MCG.2019.2941856\n[3] Virginia Braun and Victoria Clarke. 2012. Thematic analysis. In APA handbook of\nresearch methods in psychology, Vol. 2. Research designs: Quantitative, qualitative,\nneuropsychological, and biological . APA, Washington D.C. https://doi.org/10.\n1037/13620-004\n[4] Yuzhe Cai, Shaoguang Mao, Wenshan Wu, Zehua Wang, Yaobo Liang, Tao Ge,\nChenfei Wu, You Wang, Ting Song, Yan Xia, Nan Duan, and Furu Wei. 2024.\nLow-code LLM: Graphical user interface over large language models. In Pro-\nceedings of the 2024 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies (Volume 3: System\nDemonstrations). 12–25. https://aclanthology.org/2024.naacl-demo.2\n[5] Yining Cao, Jane L. E, Chen Zhu-Tian, and Haijun Xia. 2023. DataParticles:\nBlock-based and language-oriented authoring of animated unit visualizations. In\nProceedings of the ACM Conference on Human Factors in Computing Systems (CHI) .\nACM, New York, NY, Article 808, 15 pages. https://doi.org/10.1145/3544548.\n3581472\n[6] Nan Chen, Yuge Zhang, Jiahang Xu, Kan Ren, and Yuqing Yang. 2024. VisE-\nval: A benchmark for data visualization in the era of large language models.\narXiv:2407.00981\n[7] Yida Chen, Aoyu Wu, Catherine Yeh Trevor DePodesta, Kenneth Li,\nNicholas Castillo Marin, Oam Patel, Jan Riecke, Shivam Raval, Olivia Seow,\nMartin Wattenberg, and Fernanda Viégas. 2024. Designing a dashboard for\ntransparency and control of conversational AI. arXiv:2406.07882\n[8] Liying Cheng, Xingxuan Li, and Lidong Bing. 2023. Is GPT-4 a good data analyst?.\nIn Findings of the Association for Computational Linguistics: EMNLP . ACL, 9496–\n9514. https://doi.org/10.18653/v1/2023.findings-emnlp.637\n[9] Bhavya Chopra, Ananya Singha, Anna Fariha, Sumit Gulwani, Chris Parnin,\nAshish Tiwari, and Austin Z Henley. 2023. Conversational challenges\nin AI-powered data science: Obstacles, needs, and design opportunities.\narXiv:2310.16164\n[10] John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan\nAdar, and Minsuk Chang. 2022. TaleBrush: Sketching stories with generative\npretrained language models. In Proceedings of the ACM Conference on Human\nFactors in Computing Systems (CHI) . ACM, New York, NY, Article 209, 19 pages.\nhttps://doi.org/10.1145/3491102.3501819\n[11] Nicola Dell, Vidya Vaidyanathan, Indrani Medhi, Edward Cutrell, and William\nThies. 2012. “Yours is better!” Participant response bias in HCI. In Proceedings\nof the sigchi conference on human factors in computing systems . ACM, New York,\nNY, 1321–1330. https://doi.org/10.1145/2207676.2208589\n[12] Victor Dibia. 2023. LIDA: A tool for automatic generation of grammar-agnostic\nvisualizations and infographics using large language models. InProceedings of the\nAnnual Meeting of the Association for Computational Linguistics (Volume 3: System\nDemonstrations). ACL, Toronto, Canada, 113–126. https://doi.org/10.18653/v1/\n2023.acl-demo.11\n[13] Rui Ding, Shi Han, Yong Xu, Haidong Zhang, and Dongmei Zhang. 2019. Quick-\nInsights: Quick and automatic discovery of insights from multi-dimensional data.\nIn Proceedings of the International Conference on Management of Data (SIGMOD) .\nACM, New York, NY, 317–332. https://doi.org/10.1145/3299869.3314037\n[14] Yingchaojie Feng, Xingbo Wang, Bo Pan, Kam Kwai Wong, Yi Ren, Shi Liu,\nZihan Yan, Yuxin Ma, Huamin Qu, and Wei Chen. 2024. XNLI: Explaining and\ndiagnosing NLI-based visual data analysis. IEEE Trans. Vis. Comput. Graph. 30, 7\n(2024), 3813–3827. https://doi.org/10.1109/TVCG.2023.3240003\n[15] Kasra Ferdowsi, Jack Williams, Ian Drosos, Andrew D Gordon, Carina Negreanu,\nNadia Polikarpova, Advait Sarkar, and Benjamin Zorn. 2023. ColDeco: An end\nuser spreadsheet inspection tool for AI-generated code. InProceedings of the IEEE\nSymposium on Visual Languages and Human-Centric Computing (VL/HCC) . IEEE,\nPiscataway, NJ, 82–91. https://doi.org/10.1109/VL-HCC57772.2023.00017\n[16] Kiran Gadhave, Zach Cutler, and Alexander Lex. 2022. Reusing interactive\nanalysis workflows. Comput. Graphics Forum 41, 3 (2022), 133–144. https:\n//doi.org/10.1111/cgf.14528\n[17] Google. 2024. Gemini Advanced: Release updates . Google. Retrieved June 1, 2024\nfrom https://gemini.google.com/updates 2024.05.21: updates on data analysis\nfeatures.\n[18] Ken Gu, Madeleine Grunde-McLaughlin, Andrew M. McNutt, Jeffrey Heer, and\nTim Althoff. 2024. How do data analysts respond to AI assistance? A wizard-of-oz\nstudy. In Proceedings of the ACM Conference on Human Factors in Computing\nSystems (CHI). ACM, New York, NY, Article 1015, 22 pages. https://doi.org/10.\n1145/3613904.3641891\n[19] Ken Gu, Ruoxi Shang, Tim Althoff, Chenglong Wang, and Steven M Drucker. 2024.\nHow do analysts understand and verify AI-assisted data analyses?. InProceedings\nof the ACM Conference on Human Factors in Computing Systems (CHI) . ACM, New\nYork, NY, Article 748, 22 pages. https://doi.org/10.1145/3613904.3642497\n[20] Ziwei Gu, Ian Arawjo, Kenneth Li, Jonathan K Kummerfeld, and Elena L\nGlassman. 2024. An AI-resilient text rendering technique for reading and\nskimming documents. In Proceedings of the ACM Conference on Human Fac-\ntors in Computing Systems (CHI) . ACM, New York, NY, Article 898, 22 pages.\nhttps://doi.org/10.1145/3613904.3642699\n[21] Yi Guo, Nan Cao, Xiaoyu Qi, Haoyang Li, Danqing Shi, Jing Zhang, Qing Chen,\nand Daniel Weiskopf. 2023. Urania: Visualizing data analysis pipelines for natural\nlanguage-based data exploration. arXiv:2306.07760\n[22] Sandra G Hart and Lowell E Staveland. 1988. Development of NASA-TLX (Task\nLoad Index): Results of empirical and theoretical research. InAdvances in psychol-\nogy. Vol. 52. Elsevier, 139–183. https://doi.org/10.1016/S0166-4115(08)62386-9\n[23] Xinyi He, Mengyu Zhou, Xinrun Xu, Xiaojun Ma, Rui Ding, Lun Du, Yan Gao, Ran\nJia, Xu Chen, Shi Han, Zejian Yuan, and Dongmei Zhang. 2024. Text2Analysis: A\nbenchmark of table question answering with advanced data analysis and unclear\nqueries. Proceedings of the Annual AAAI Conference on Artificial Intelligence\n(AAAI) 38, 16 (2024), 18206–18215. https://doi.org/10.1609/aaai.v38i16.29779\n[24] Yanwei Huang, Yurun Yang, Xinhuan Shu, Ran Chen, Di Weng, and Yingcai Wu.\n2024. Table Illustrator: Puzzle-based interactive authoring of plain tables. In\nProceedings of the ACM Conference on Human Factors in Computing Systems (CHI) .\nACM, New York, NY, Article 186, 18 pages. https://doi.org/10.1145/3613904.\n3642415\n[25] Yanwei Huang, Yunfan Zhou, Ran Chen, Changhao Pan, Xinhuan Shu, Di Weng,\nand Yingcai Wu. 2023. Interactive table synthesis with natural language. IEEE\nTrans. Vis. Comput. Graph. (2023). https://doi.org/10.1109/TVCG.2023.3329120\nEarly Access.\n[26] Peiling Jiang, Jude Rayan, Steven P Dow, and Haijun Xia. 2023. Graphologue:\nExploring large language model responses with interactive diagrams. In Proceed-\nings of the Symposium on User Interface Software and Technology (UIST) . ACM,\nNew York, NY, Article 3, 20 pages. https://doi.org/10.1145/3586183.3606737\n[27] Sean Kandel, Andreas Paepcke, Joseph Hellerstein, and Jeffrey Heer. 2011. Wran-\ngler: Interactive visual specification of data transformation scripts. InProceedings\nof the ACM Conference on Human Factors in Computing Systems (CHI) . ACM, New\nYork, NY, 3363–3372. https://doi.org/10.1145/1978942.1979444\n[28] Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman, Austin Henley,\nCarina Negreanu, and Advait Sarkar. 2024. Improving steering and verification in\nAI-assisted data analysis with interactive task decomposition. arXiv:2407.02651\n[29] Meraj Khan, Larry Xu, Arnab Nandi, and Joseph M Hellerstein. 2017. Data\ntweening: Incremental visualization of data transforms. Proceedings of the VLDB\nEndowment 10, 6 (2017), 661–672. https://doi.org/10.14778/3055330.3055333\n[30] Amy J Ko and Brad A Myers. 2004. Designing the Whyline: A debugging inter-\nface for asking questions about program behavior. In Proceedings of the ACM\nConference on Human Factors in Computing Systems (CHI) . ACM, New York, NY,\n151–158. https://doi.org/10.1145/985692.985712\n[31] Sam Lau, Sean Kross, Eugene Wu, and Philip J Guo. 2023. Teaching data science\nby visualizing data table transformations: Pandas Tutor for Python, Tidy Data\nTutor for R, and SQL Tutor. In Proceedings of the International Workshop on Data\nSystems Education: Bridging Education Practice with Education Research . ACM,\nNew York, NY, 50–55. https://doi.org/10.1145/3596673.3596972\n[32] Boyan Li, Yuyu Luo, Chengliang Chai, Guoliang Li, and Nan Tang. 2024. The\ndawn of natural language to SQL: Are we fully ready? arXiv:2406.01265\n[33] Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Ben Zorn, Jack Williams,\nNeil Toronto, and Andy Gordon. 2023. “What it wants me to say”: Bridging\nthe abstraction gap between end-user programmers and code-generating large\nlanguage models. In Proceedings of the ACM Conference on Human Factors in\nComputing Systems (CHI) . ACM, New York, NY, 31 pages. https://doi.org/10.\n1145/3544548.3580817\n[34] Shusen Liu, Haichao Miao, Zhimin Li, Matthew Olson, Valerio Pascucci, and\nPeer-Timo Bremer. 2024. AVA: Towards autonomous visualization agents through\nvisual perception-driven decision-making. Comput. Graphics Forum 43, 3, Article\ne15093 (2024), 12 pages. https://doi.org/10.1111/cgf.15093\n[35] Shang-Ching Liu, ShengKun Wang, Tsungyao Chang, Wenqi Lin, Chung-Wei\nHsiung, Yi-Chen Hsieh, Yu-Ping Cheng, Sian-Hong Luo, and Jianwei Zhang. 2023.\nJarviX: A LLM no code platform for tabular data analysis and optimization. In\nProceedings of the Conference on Empirical Methods in Natural Language Processing:\nIndustry Track . ACL, 622–630. https://doi.org/10.18653/v1/2023.emnlp-industry.\n59\n[36] Lydia R Lucchesi, Petra M Kuhnert, Jenny L Davis, and Lexing Xie. 2022. Smallset\nTimelines: A visual representation of data preprocessing decisions. InProceedings\nof the ACM Conference on Fairness, Accountability, and Transparency (FAccT) .\nACM, New York, NY, 1136–1153. https://doi.org/10.1145/3531146.3533175\n[37] Damien Masson, Sylvain Malacria, Géry Casiez, and Daniel Vogel. 2024. Direct-\nGPT: A direct manipulation interface to interact with large language models. In\nProceedings of the ACM Conference on Human Factors in Computing Systems (CHI) .\nACM, New York, NY, Article 975, 16 pages. https://doi.org/10.1145/3613904.\n3642462\nUIST ’24, Oct 13–16, 2024, Pittsburgh, PA L. Xie, C. Zheng, H. Xia, H. Qu, and C. Zhu-Tian\n[38] Andrew M Mcnutt, Chenglong Wang, Robert A Deline, and Steven M. Drucker.\n2023. On the design of AI-powered code assistants for notebooks. In Proceedings\nof the ACM Conference on Human Factors in Computing Systems (CHI) . ACM, New\nYork, NY, Article 434, 16 pages. https://doi.org/10.1145/3544548.3580940\n[39] Sahar Mehrpour and Thomas D. Latoza. 2023. A survey of tool support for\nworking with design decisions in code. Comput. Surveys 56, 2, Article 37 (2023),\n37 pages. https://doi.org/10.1145/3607868\n[40] Meta Open Source. 2024. React. https://react.dev/\n[41] Microsoft. 2024. Monaco Editor . https://microsoft.github.io/monaco-editor/\n[42] Brad A Myers. 1990. Taxonomies of visual programming and program vi-\nsualization. Journal of Visual Languages & Computing 1, 1 (1990), 97–123.\nhttps://doi.org/10.1016/S1045-926X(05)80036-9\n[43] Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu, and Brad\nMyers. 2024. Using an LLM to help with code understanding. In Proceedings of\nthe ACM International Conference on Software Engineering (ICSE) . IEEE, Article\n97, 13 pages. https://doi.org/10.1145/3597503.3639187\n[44] Arpit Narechania, Adam Fourney, Bongshin Lee, and Gonzalo Ramos. 2021. DIY:\nAssessing the correctness of natural language to SQL systems. In Proceedings of\nthe International Conference on Intelligent User Interfaces (IUI) . ACM, New York,\nNY, 597–607. https://doi.org/10.1145/3397481.3450667\n[45] Christina Niederer, Holger Stitz, Reem Hourieh, Florian Grassinger, Wolfgang\nAigner, and Marc Streit. 2017. TACO: Visualizing changes in tables over time.\nIEEE Trans. Vis. Comput. Graph. 24, 1 (2017), 677–686. https://doi.org/10.1109/\nTVCG.2017.2745298\n[46] Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, and\nArmando Solar-Lezama. 2024. Is self-repair a silver bullet for code generation?.\nIn Proceedings of the International Conference on Learning Representations (ICLR) .\n49 pages. arXiv:2306.09896 Poster.\n[47] OpenAI. 2024. Data analysis with ChatGPT . OpenAI. Retrieved June 1, 2024\nfrom https://help.openai.com/en/articles/8437071-data-analysis-with-chatgpt\n[48] Pallets. 2024. Flask. https://flask.palletsprojects.com/en/3.0.x/\n[49] Luca Podo, Muhammad Ishmal, and Marco Angelini. 2024. Toward a structured\ntheoretical framework for the evaluation of generative AI-based visualizations.\nIn Proceedings of the EuroVis Workshop on Visual Analytics (EuroVA) . The Euro-\ngraphics Association, 6 pages. https://doi.org/10.2312/eurova.20241118\n[50] Xiaoying Pu, Sean Kross, Jake M. Hofman, and Daniel G. Goldstein. 2021. Data-\nmations: Animated explanations of data analysis pipelines. In Proceedings of the\nACM Conference on Human Factors in Computing Systems (CHI) . ACM, New York,\nNY, Article 467, 14 pages. https://doi.org/10.1145/3411764.3445063\n[51] Dhivyabharathi Ramasamy, Cristina Sarasua, Alberto Bacchelli, and Abraham\nBernstein. 2023. Visualising data science workflows to support third-party note-\nbook comprehension: An empirical study. Empirical Software Engineering 28, 3\n(2023), 58. https://doi.org/10.1007/s10664-023-10289-9\n[52] Hua Shen, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan Krishna,\nYachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei, et al . 2024.\nTowards bidirectional human-AI alignment: A systematic review for clarifications,\nframework, and future directions. arXiv:2406.09264\n[53] Leixian Shen, Enya Shen, Yuyu Luo, Xiaocong Yang, Xuming Hu, Xiongshuai\nZhang, Zhiwei Tai, and Jianmin Wang. 2022. Towards natural language interfaces\nfor data visualization: A survey. IEEE Trans. Vis. Comput. Graph. 29, 6 (2022),\n3121–3144. https://doi.org/10.1109/TVCG.2022.3148007\n[54] Dilruba Showkat and Eric P. S. Baumer. 2021. Where do stories come from?\nExamining the exploration process in investigative data journalism. Proc. ACM\nHum.-Comput. Interact. 5, CSCW2, Article 390 (2021), 31 pages. https://doi.org/\n10.1145/3479534\n[55] Nischal Shrestha, Titus Barik, and Chris Parnin. 2021. Unravel: A fluent code\nexplorer for data wrangling. In Proceedings of the Symposium on User Interface\nSoftware and Technology (UIST) . ACM, New York, NY, 198–207. https://doi.org/\n10.1145/3472749.3474744\n[56] Nischal Shrestha, Bhavya Chopra, Austin Z Henley, and Chris Parnin. 2023.\nDetangler: Helping data scientists explore, understand, and debug data wrangling\npipelines. In Proceedings of the IEEE Symposium on Visual Languages and Human-\nCentric Computing (VL/HCC) . IEEE, Piscataway, NJ, 189–198. https://doi.org/10.\n1109/VL-HCC57772.2023.00031\n[57] Hariharan Subramonyam, Roy Pea, Christopher Lawrence Pondoc, Maneesh\nAgrawala, and Colleen Seifert. 2024. Bridging the gulf of envisioning: Cognitive\ndesign challenges in LLM interfaces. In Proceedings of the ACM Conference on\nHuman Factors in Computing Systems (CHI) . ACM, New York, NY, Article 1039,\n19 pages. https://doi.org/10.1145/3613904.3642754\n[58] Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023. Sensecape: En-\nabling multilevel exploration and sensemaking with large language models. In\nProceedings of the Symposium on User Interface Software and Technology (UIST) .\nACM, New York, NY, Article 1, 18 pages. https://doi.org/10.1145/3586183.3606756\n[59] Lev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait\nSarkar, Abigail Sellen, and Sean Rintel. 2024. The metacognitive demands and\nopportunities of generative AI. In Proceedings of the ACM Conference on Human\nFactors in Computing Systems (CHI) . ACM, New York, NY, Article 680, 24 pages.\nhttps://doi.org/10.1145/3613904.3642902\n[60] Yuan Tian, Weiwei Cui, Dazhen Deng, Xinjing Yi, Yurun Yang, Haidong Zhang,\nand Yingcai Wu. 2024. ChartGPT: Leveraging LLMs to generate charts from\nabstract natural language. IEEE Trans. Vis. Comput. Graph. (2024). https://doi.\norg/10.1109/TVCG.2024.3368621 Early Access.\n[61] Priyan Vaithilingam, Elena L. Glassman, Jeevana Priya Inala, and Chenglong\nWang. 2024. DynaVis: Dynamically synthesized UI widgets for visualization\nediting. In Proceedings of the ACM Conference on Human Factors in Computing\nSystems (CHI) . ACM, New York, NY, Article 985, 17 pages. https://doi.org/10.\n1145/3613904.3642639\n[62] Bret Victor. 2011. Up and down the ladder of abstraction: A systematic approach to\ninteractive visualization . Retrieved April 1, 2024 from http://worrydream.com/\nLadderOfAbstraction/\n[63] April Yi Wang, Will Epperson, Robert A DeLine, and Steven M. Drucker. 2022.\nDiff in the loop: Supporting data comparison in exploratory data analysis. In\nProceedings of the ACM Conference on Human Factors in Computing Systems\n(CHI). ACM, New York, NY, Article 97, 10 pages. https://doi.org/10.1145/3491102.\n3502123\n[64] April Y Wang, Ryan Mitts, Philip J Guo, and Parmit K Chilana. 2018. Mismatch of\nexpectations: How modern learning resources fail conversational programmers.\nIn Proceedings of the ACM Conference on Human Factors in Computing Systems\n(CHI). ACM, New York, NY, Article 511, 13 pages. https://doi.org/10.1145/3173574.\n3174085\n[65] Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, and\nHeng Ji. 2024. Executable code actions elicit better LLM agents. In Proceedings\nof the International Conference on Machine Learning (ICML) . Article PMLR 235,\n13 pages. arXiv:2402.01030\n[66] Yun Wang, Leixian Shen, Zhengxin You, Xinhuan Shu, Bongshin Lee, John Thomp-\nson, Haidong Zhang, and Dongmei Zhang. 2024. WonderFlow: Narration-centric\ndesign of animated data videos. IEEE Trans. Vis. Comput. Graph. (2024), 17 pages.\nhttps://doi.org/10.1109/TVCG.2024.3411575 Early Access.\n[67] Luoxuan Weng, Xingbo Wang, Junyu Lu, Yingchaojie Feng, Yihan Liu, and Wei\nChen. 2024. InsightLens: Discovering and exploring insights from conversational\ncontexts in large-language-model-powered data analysis. arXiv:2404.01644\n[68] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Transparent\nand controllable human-AI interaction by chaining large language model prompts.\nIn Proceedings of the ACM Conference on Human Factors in Computing Systems\n(CHI). ACM, New York, NY, Article 385, 22 pages. https://doi.org/10.1145/3491102.\n3517582\n[69] Yang Wu, Yao Wan, Hongyu Zhang, Yulei Sui, Wucai Wei, Wei Zhao, Guandong\nXu, and Hai Jin. 2024. Automated data visualization from natural language\nvia large language models: An exploratory study. Proceedings of the ACM on\nManagement of Data 2, 3, Article 115 (2024), 28 pages. https://doi.org/10.1145/\n3654992\n[70] Liwenhan Xie, Xinhuan Shu, Jeon Cheol Su, Yun Wang, Siming Chen, and Huamin\nQu. 2024. Creating emordle: Animating word cloud for emotion expression. IEEE\nTrans. Vis. Comput. Graph. 30, 8 (2024), 5198–5211. https://doi.org/10.1109/TVCG.\n2023.3286392\n[71] Liwenhan Xie, Zhaoyu Zhou, Kerun Yu, Yun Wang, Huamin Qu, and Siming\nChen. 2023. Wakey-Wakey: Animate text by mimicking characters in a GIF. In\nProceedings of the Symposium on User Interface Software and Technology (UIST) .\nACM, New York, NY, Article 98, 14 pages. https://doi.org/10.1145/3586183.\n3606813\n[72] Kai Xiong, Siwei Fu, Guoming Ding, Zhongsu Luo, Rong Yu, Wei Chen, Hujun\nBao, and Yingcai Wu. 2022. Visualizing the scripts of data wrangling with\nSOMNUS. IEEE Trans. Vis. Comput. Graph. 29, 6 (2022), 2950–2964. https:\n//doi.org/10.1109/TVCG.2022.3144975\n[73] Chenyang Yang, Shurui Zhou, Jin LC Guo, and Christian Kästner. 2021. Subtle\nbugs everywhere: Generating documentation for data wrangling code. InProceed-\nings of the IEEE/ACM International Conference on Automated Software Engineering\n(ASE). IEEE, Piscataway, NJ, 304–316. https://doi.org/10.1109/ASE51524.2021.\n9678520\n[74] Pengcheng Yin, Wen-Ding Li, Kefan Xiao, Abhishek Rao, Yeming Wen, Kensen Shi,\nJoshua Howland, Paige Bailey, Michele Catasta, Henryk Michalewski, Oleksandr\nPolozov, and Charles Sutton. 2023. Natural language to code generation in\ninteractive data science notebooks. In Proceedings of the Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1: Long Papers) . ACL, Toronto,\nCanada, 126–173. https://doi.org/10.18653/v1/2023.acl-long.9\n[75] Chen Zhu-Tian and Haijun Xia. 2022. CrossData: Leveraging text-data connec-\ntions for authoring data documents. In Proceedings of the ACM Conference on\nHuman Factors in Computing Systems (CHI) . ACM, New York, NY, Article 95,\n15 pages. https://doi.org/10.1145/3491102.3517485\n[76] Chen Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, and Elena Glassman. 2024. Sketch\nthen generate: Providing incremental user feedback and guiding LLM code gen-\neration through language-oriented code sketches. arXiv:2405.03998\n[77] Chen Zhu-Tian, Chenyang Zhang, Qianwen Wang, Jakob Troidl, Simon Warchol,\nJohanna Beyer, Nils Gehlenborg, and Hanspeter Pfister. 2024. Beyond generating\ncode: Evaluating GPT on a data visualization course. arXiv:2306.02914"
}