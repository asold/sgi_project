{
  "title": "Evaluating large language models: a systematic review of efficiency, applications, and future directions",
  "url": "https://openalex.org/W4410795016",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A4323007956",
      "name": "Yasmeen Saleh",
      "affiliations": [
        "University of Sharjah"
      ]
    },
    {
      "id": "https://openalex.org/A2308950541",
      "name": "Manar Abu Talib",
      "affiliations": [
        "University of Sharjah"
      ]
    },
    {
      "id": "https://openalex.org/A851660079",
      "name": "Qassim Nasir",
      "affiliations": [
        "University of Sharjah"
      ]
    },
    {
      "id": "https://openalex.org/A4220256270",
      "name": "Fatima Dakalbab",
      "affiliations": [
        "University of Sharjah"
      ]
    },
    {
      "id": "https://openalex.org/A4323007956",
      "name": "Yasmeen Saleh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2308950541",
      "name": "Manar Abu Talib",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A851660079",
      "name": "Qassim Nasir",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4220256270",
      "name": "Fatima Dakalbab",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4324316215",
    "https://openalex.org/W4367185264",
    "https://openalex.org/W6850227699",
    "https://openalex.org/W4362601804",
    "https://openalex.org/W6849584742",
    "https://openalex.org/W4388277090",
    "https://openalex.org/W4385346108",
    "https://openalex.org/W4378966181",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4362582720",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W4323848232",
    "https://openalex.org/W4385297391",
    "https://openalex.org/W4384200891",
    "https://openalex.org/W4362472309",
    "https://openalex.org/W4382246105",
    "https://openalex.org/W4381572755",
    "https://openalex.org/W4385190659",
    "https://openalex.org/W6852280460",
    "https://openalex.org/W4392388527",
    "https://openalex.org/W4406754779",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W4360980513",
    "https://openalex.org/W4385287322",
    "https://openalex.org/W4383058631",
    "https://openalex.org/W3154459044",
    "https://openalex.org/W3215445770",
    "https://openalex.org/W3085802396",
    "https://openalex.org/W4388049829"
  ],
  "abstract": "Large language models, the innovative breakthrough taking the world by storm, have been applied in several fields, such as medicine, education, finance, and law. Moreover, large language models can integrate into those fields through their abilities in natural language processing, text generation, question answering, and several other use cases that benefit human interactions and decision-making. Furthermore, it is imperative to acknowledge the differences involved with large language models beyond their applications by considering aspects such as their types, setups, parameters, and performance. This could help us understand how each large language model could be utilized to its fullest extent for maximum benefit. In this systematic literature review, we explore each of these aspects in depth. Finally, we conclude with insights and future directions for advancing the efficiency and applicability of large language models.",
  "full_text": "Frontiers in Computer Science 01 frontiersin.org\nEvaluating large language \nmodels: a systematic review of \nefficiency, applications, and \nfuture directions\nYasmeen Saleh 1, Manar Abu Talib 1*, Qassim Nasir 2 and \nFatima Dakalbab 1\n1 Department of Computer Science, College of Computing and Informatics, University of Sharjah, \nSharjah, United Arab Emirates, 2 Department of Computer Engineering, College of Computing and \nInformatics, University of Sharjah, Sharjah, United Arab Emirates\nLarge language models, the innovative breakthrough taking the world by storm, \nhave been applied in several fields, such as medicine, education, finance, and law. \nMoreover, large language models can integrate into those fields through their \nabilities in natural language processing, text generation, question answering, and \nseveral other use cases that benefit human interactions and decision-making. \nFurthermore, it is imperative to acknowledge the differences involved with large \nlanguage models beyond their applications by considering aspects such as their \ntypes, setups, parameters, and performance. This could help us understand how \neach large language model could be utilized to its fullest extent for maximum \nbenefit. In this systematic literature review, we explore each of these aspects in \ndepth. Finally, we conclude with insights and future directions for advancing the \nefficiency and applicability of large language models.\nKEYWORDS\nlarge language models, LLMS, efficiency, performance, application\n1 Introduction\nIn today’s world, human interaction with artificial intelligence has significantly risen \nthanks to the recent advancements in large language models and natural language processing. \nThe field of large language models, while still an emerging subfield of artificial intelligence, is \na vast field with varying types and specifications of each large language model and the \nlimitations and accuracies of each. To discover this vast field more, we must develop a basic \nunderstanding of large language models, their history, applications, and challenges. \nFurthermore, efficiency in large language models involves several aspects, including hardware \nand software requirements, sourcing, training, and output accuracy. Understanding and \noptimizing the efficiencies of these models is imperative, given the increasing reliance on such \ntechnology in various applications. To the best of our knowledge, there are very few Systematic \nLiterature Reviews (SLR) on the efficiencies of large language models, which has motivated \nthis work. Therefore, this systematic literature review aims to provide a comprehensive \noverview of the state-of-the-art research on the efficiencies of large language models.\nFirstly, language models possess the skill of assigning probabilities to sequences of tokens \nby analyzing statistical patterns in the distribution of a sequence of tokens within data. Modern \nlanguage models include multiple neural network layers representing tokens within a \nmultidimensional feature space. Unlike early n-gram models that only learned transition \nprobabilities between one-word sequences and the following, neural language models could \nutilize pre-trained representation of words, called embedding ( Bender et  al., 2021 ; \nOPEN ACCESS\nEDITED BY\nBarkaoui Kamel,  \nConservatoire National des Arts et Métiers \n(CNAM), France\nREVIEWED BY\nAdamantios Koumpis,  \nUniversity Hospital of Cologne, Germany\nSabina Rossi,  \nCa’ Foscari University of Venice, Italy\nXiaoding Wang,  \nFujian Normal University, China\n*CORRESPONDENCE\nManar Abu Talib  \n mtalib@sharjah.ac.ae\nRECEIVED 06 November 2024\nACCEPTED 13 May 2025\nPUBLISHED 27 May 2025\nCITATION\nSaleh Y, Abu Talib M, Nasir Q and \nDakalbab F (2025) Evaluating large language \nmodels: a systematic review of efficiency, \napplications, and future directions.\nFront. Comput. Sci. 7:1523699.\ndoi: 10.3389/fcomp.2025.1523699\nCOPYRIGHT\n© 2025 Saleh, Abu Talib, Nasir and Dakalbab. \nThis is an open-access article distributed \nunder the terms of the Creative Commons \nAttribution License (CC BY). The use, \ndistribution or reproduction in other forums is \npermitted, provided the original author(s) and \nthe copyright owner(s) are credited and that \nthe original publication in this journal is cited, \nin accordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.\nTYPE Systematic Review\nPUBLISHED 27 May 2025\nDOI 10.3389/fcomp.2025.1523699\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 02 frontiersin.org\nTrott et  al., 2023 ). Since language models cannot store or recall \ninformation, having a memory component, such as vector stores, is \nimperative. Vector stores help search and store embedded data. When \ndata retrieval is required from the vector store, invoked by a user query, \nthe documents could be passed to the large language models (LLMs) \nthrough multiple methods. One of the most used methods is called the \nstuff method. This method is most efficient when passing similar \ndocuments in a single prompt, whereas other methods can be used in \nprocessing documents that cannot be  passed in a single prompt \n(Topsakal and Akinci, 2023). Sophisticated neural language models \nwith billions of parameters and several deep learning techniques are \nwhat modern LLMs are.\nMoreover, it is no wonder that with such powerful internal \nworkflow complexity and ease of user access and querying, LLMs will \nbe able to solve a wide range of tasks with complexities while being \nuser-friendly. This sparked the widespread usage and integration of \nLLMs across various areas and into multiple fields, such as medicine, \neducation, finance, and law. LLMs are essential in disease prediction, \ndiagnosis, and assessment of therapeutic targets in medicine. These \ninclude providing treatment guidelines for cancer patients based on \ntheir magnetic resonance imaging radionics and predicting aging-\nrelated diseases (Singhal et al., 2023 ; Cascella et al., 2023 ; Jo et al., \n2023). ChatGPT, an LLM, was used to write preauthorization requests \nfor dental insurance companies. Tailored and fine-tuned applications \nbased on LLMs can enhance dental telemedicine services when \ncombined with dental health care personnel ( Huang et  al., 2023; \nEggmann et al., 2023). In education, ChatGPT was used to evaluate \nstudent-generated answers in a learning environment and help \nstudents generate answers to their questions (Porsdam Mann et al., \n2023; Meyer et al., 2023; Kasneci et al., 2023; Milano et al., 2023; Lund \net  al., 2023 ). Financial applications include fraud detection, \nalgorithmic trading, and risk assessment (Fan, 2024). In legal settings, \nLLMs support document analysis, contract review, and automated \nlegal reasoning (Siino et al., 2025). In addition to their established uses \nin medicine, education, finance, and law, LLMs are being explored in \nemerging fields such as blockchain. Recent research has highlighted \nthe use of LLMs to automate smart contract verification and improve \nsecurity in decentralized systems ( Ressi et al., 2024 ). AI-enhanced \nblockchain technology provides new prospects for boosting trust and \naccuracy in contract execution, which is still an area for future research.\nUnfortunately, despite their various applications, there are still many \nchallenges relating to performance, ethics, and many more. On the \nethical front, concerns grow regarding bias and integrity, as these \nmodels, developed on extensive data collections, may unknowingly \nperpetuate and reinforce existing biases present in the training data. This \nraises questions about the accuracy and fairness of the outputs generated \nby these models, especially in sensitive applications such as hiring \nprocesses or automated decision-making (Head et  al., 2023 ). The \nextensive knowledge these models acquire while training raises serious \nprivacy problems, raising the possibility of inadvertently disclosing \nsensitive information and necessitating the implementation of strong \nprivacy protections. Furthermore, the necessity of developing ethical \nstandards to stop malicious use is emphasized by the possibility of \nmanipulating and abusing massive language models to produce false \ninformation or participate in disinformation campaigns (Wu et al., 2023).\nBeyond ethical concerns, LLMs encounter other challenges. The \ncomputational resources required for training and fine-tuning are \nextensive, limiting access to these technologies for smaller organizations \nand researchers with constrained computing capabilities. The \ndependency on training data introduces challenges related to the \ndiversity and quality of the data, potentially leading to difficulties in \nunderstanding specific contexts or generating appropriate responses for \nunderrepresented topics. Adapting these models to domain-specific \ncontexts requires careful consideration, as fine-tuning for specialized \ntasks may be resource-intensive and may only sometimes yield optimal \nresults (Deng et  al., 2023). The delicate balance between human-\nmachine collaboration presents a challenge, as it is crucial to ensure that \nthese models augment human capabilities without replacing critical \ndecision-making processes (Bender et al., 2021; Trott et al., 2023).\nContinuous learning and updating pose challenges as well. LLMs \nneed frequent updates to stay relevant and accurate, necessitating a \nrobust infrastructure for managing model evolution and ensuring \nseamless integration with emerging information sources. These \nchallenges underscore the importance of a collaborative effort \ninvolving researchers, policymakers, and industry stakeholders to \nestablish ethical guidelines, develop governance mechanisms, and \nfoster responsible use of LLMs. As these models play a transformative \nrole in diverse domains, addressing these challenges is imperative for \nensuring ethical and effective social integration (Trott et al., 2023).\nWith this systematic literature review, we look forward to providing \na comprehensive analysis and comparison of the efficiencies of different \nLLMs. We  will contribute to presenting such a comparison by \npresenting the information we collected on the hardware and software \nrequirements, sourcing, training, and output accuracy associated with \nthese models. This represents a critical step in understanding the \nmultifaceted dimensions of LLM efficiencies, enabling researchers, \npractitioners, and policymakers to make informed decisions about \ntheir utilization and development. By shedding light on the current \nstate of knowledge in this domain, we aim to facilitate the development \nof accurate and optimal solutions in the era of LLMs.\nThe remainder of this paper is divided into six sections: Section 2 \nprovides information on related work. Section 3 describes the \nmethodology. Section 4 lists the results and discussions. Section 5 \naddresses the limitations of this review—finally, Section 6 concludes \nand suggests suggestions for future work.\n2 Related work\nDuring our research, we found a total of 7 survey papers that are \nrelated to our topic. These papers have been published in the last \n5 years, and most of the documents tackled the advantages, \ndisadvantages, and ethical and legal issues associated with LLMs. \nDespite our paper discussing similar points, we have mainly focused \non the efficiency aspect of LLMs, unlike the other papers. Furthermore, \nwe  developed a deeper understanding of LLMs, their efficiencies, \napplication, and overall benefits to compare our work with others. All \nthe papers mentioned below discuss LLMs.\nFloridi (2023), Mökander et al. (2023), and Teubner et al. (2023) \ndiscuss topics of ethical and legal matters regarding LLMs. To \nbe specific, Floridi (2023) talks about intelligence regarding LLMs. The \nauthor provides information regarding LLMs’ possible implications \nand ethical, legal, and human costs. Floridi compares the spiritual, \nanimal, and AI agents and how we interact with them (Floridi, 2023). \nSecondly, Mökander et al. (2023) delved deeper into implications and \ndiscussed auditing, its importance, methods, and limitations. As the \nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 03 frontiersin.org\nauthor explained, auditing is the governing process used to recognize \nand alleviate issues with AI (artificial intelligence) technologies. \nAuditing LLMs can be done through a three-layered approach, which \nincludes (governance, model, and application) ( Mökander et  al., \n2023). Thirdly, Teubner et al. (2023) discussed the expectations and \nfuture involved with LLMs and their implications. Teubner defends \nLLMs by pointing out that acknowledging their power instead of \nbanning them is a more reasonable action toward LLMs’ growth. \nHe also discusses their effectiveness, legality, and threats, clarifying \nmisconceptions and supporting integrating and adopting LLMs into \nsociety (Teubner et al., 2023). Fourthly, PLMs (pre-trained language \nmodels) and NLP (natural language processing), two fields relating to \nLLMs, were explored by Min et  al. (2023) . The survey provides \nbackground information on PLMs and categorizes the utilization of \nPLMs for NLPs into three paradigms: pre-train then fine-tune, \nprompt-based learning, and NLP as text generation, each discussed in \ndepth (Min et al., 2023). Next, Liu et al. (2023) discuss prompting and \nprovide in-depth background information. The author also explains \nmore complex ideas, such as multi-prompt learning methods and \nprompt engineering, and provides information on the topic’s \napplications and challenges (Liu et al., 2023). Furthermore, Kamnis \n(2023) explores GPTs (generative pre-trained transformers) through \nsurface engineering. However, the author’s main idea is custom data \nindexing, which enables entities to organize and store data using AI \ntools for efficient data retrieval. The author compares GPT-4 and a \nfine-tuned data-indexed GPT-3 model, evaluating them on their \nquery-answering performances (Kamnis, 2023). Finally, Qureshi et al. \n(2023) investigate LLMs’ , specifically ChatGPT’s, ability to integrate \ninto SRs (systematic reviews). The author tests ChatGPT’s utility and \napplicability by quizzing it on language interpretation tasks related to \nsystematic reviews. Although ChatGPT faced some challenges, it \ncould still form responses according to what was requested (Qureshi \net al., 2023). Floridi (2023) and Teubner et al. (2023) all discuss similar \ntopics of ethical and legal matters regarding LLMs. However, they \nseem to lack information on the efficiencies of LLMs. Except for \nFloridi (2023), the other two papers, Mökander et  al. (2023) and \nTeubner et al. (2023), did not include comparisons between LLMs. \nSimilarly, Qureshi et al. (2023) do not conduct comparisons, but they \ntest and discuss topics related to ChatGPT. On the contrary, Kamnis \n(2023) compares, but the topic is too specific.\nIn our work, we  will conduct a systematic literature review \ncomparing different LLMs focusing on efficiency. Table 1 shows the \ncontributions of each paper. We have added a column describing the \ndifference between our contribution and the others’ .\n3 Methodology\nIn this critical review, we  used the framework proposed by \nKitchenham and Charters methodology to implement our review. \nTABLE 1 Summary of related work.\nRef. Year Contributions Difference\nFloridi (2023) 2023 Talks about different LLMs, their pros and cons, and their ethical and \nlegal issues.\nProvides no information on the requirements \nor efficiency of the large language models.\nMökander et al. (2023) 2023 This paper analyses and evaluates LLMs from technical, ethical, and legal \nperspectives. It talks about the opportunities and risks of LLMs, \nhighlights the properties that undermine the feasibility and effectiveness \nof existing AI auditing procedures, and derives and defends seven claims \nabout how LLM auditing procedures should be designed and how to \nstructure such procedures.\nIt does not compare large language models or \ncover the main idea, efficiency.\nTeubner et al. (2023) 2023 This paper discusses the emergence of ChatGPT and LLMs in general \nand their limits, threats, and legality.\nIt does not directly compare the efficiencies of \ndifferent large language models and mainly \ndiscusses ChatGPT.\nMin et al. (2023) 2023 This paper surveys the three trending paradigms that use pre-trained \nlanguage models for natural language processing. The paper describes \neach of them in-depth, summarizes prior works whose applications have \nshown promise, and discusses limitations.\nIt compares large language models from a \nnatural language processing perspective, but \nnot generally.\nLiu et al. (2023) 2023 This paper summarizes and analyses several paradigms in developing \nstatistical natural language processing techniques. It also highlights the \ncommonalities and differences between the four paradigms of natural \nlanguage processing.\nCompares large language models from a \nprompting parameters perspective.\nKamnis (2023) 2023 This paper demonstrates that a fine-tuned data-indexed GPT model can \nsignificantly improve query response performance compared to state-of-\nthe-art GPT-4. This model can provide more accurate, coherent, and \nrelevant responses, which have important implications for developing \nand applying natural language processing models in surface engineering \ndomains by utilizing domain adaptation and data indexing techniques.\nFocuses on large language models, specifically \nGPT, for surface engineering.\nQureshi et al. (2023) 2023 This paper discusses the capability of ChatGPT and other LLMs and \ntheir limitations or reliability in being integrated into systematic reviews.\nIt only tests ChatGPT and does not test or \ncompare it with other models.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 04 frontiersin.org\nFIGURE 1\nThe stages of conducting a systematic literature review.\nFIGURE 2\nApplied research methodology.\nThis approach comprises planning, conducting, and reporting \nphases, each comprising various stages. During the planning phase, \na review protocol was formulated, encompassing six stages: \narticulating research questions, devising the search strategy, \ndelineating study selection procedures, specifying quality \nassessment rules, outlining the data extraction strategy, and \ncombining the extracted data. Figure  1  illustrates the six \nstages mentioned.\nFigure  1 illustrates our journey from identifying research \nquestions to synthesizing extracted data. The stages involve identifying \nsearch terms, searching, initial results, filtering, acquiring the final \npapers, applying data extraction strategies, finalizing the extraction, \nand finally synthesizing the extracted data.\nFigure  2, shown above, illustrates the process we  followed in \nhelping us narrow down our research papers. It first starts with \nidentifying our research questions and search terms. Secondly, we apply \nan initial search and filtration process. Lastly, we finalize the extraction \nand double-check if the research technique requires to be repeated.\n3.1 Research questions\nThe formulation of research questions was as follows:\n • RQ1: What is the large language model’s application and use \ncase deployed?\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 05 frontiersin.org\nThis question aims to understand the diverse range of applications \nwhere large language models are utilized, shedding light on the \npractical contexts in which they are deployed.\n • RQ2: Which specific type of large language model is employed? \nIs the considered model open source?\nThis question seeks to identify the specific models used in \ndifferent studies and assess whether they are open-source or \nproprietary, which can affect replicability and accessibility.\n • RQ3: What prerequisites and resource demands are utilized in \ndeploying a large language model? Which hardware specifications \nwere used in the experiment? What were the model parameters \nemployed in the experiment?\nThe sub-questions delve into the hardware and computational \nrequirements and the model parameters, providing \ninsights into the resource demands of deploying large \nlanguage models.\n • RQ4: What are the methodologies for assessing the performance \nmetrics of the large language model deployed?\nThis question aims to understand the evaluation methods and \nmetrics employed to assess the performance of large language \nmodels in various applications, offering insights into their \neffectiveness and limitations.\n3.2 Search strategy\nMoving on to the subsequent stage, we  provide the search \nstrategy, aligning it with the initial stage to retrieve pertinent \narticles. Identifying search terms and the leading publishers used, \nessential for precision in the search, was also addressed.\n3.2.1 Key search terms\nTable 2, shown below, presents the key search terms used in the \nsearch process. These search expressions were identified based on \nthree criteria: Firstly, the research questions were the main driver to \nguide the determination of the search phrases. Secondly, Boolean \noperators such as ANDs and ORs were utilized to aid in filtering the \nsearch results. Thirdly, new search terms were discovered by exploring \nrelevant resources.\n3.2.2 Publishers\n 1. ACM Digital Library\n 2. Springer\n 3. IEEE Explore\n 4. Elsevier Science Direct\n 5. Google Scholar\n3.3 Study selection\nStage three focused on selection criteria and establishing inclusion \nand exclusion rules, as shown in Table 3.\n3.4 Quality assessment rules (QARs)\nIn stage 4, we evaluate the collected research articles based on the \nfollowing QAR set. The QAR utilized in this research are listed below:\nQAR 1: Is the application and use case of the deployed large \nlanguage models stated?\nQAR 2: Are the types of large language models used identified \nand explained?\nQAR 3: Are the requirements for deploying the large language \nmodel detailed?\nQAR 4: Is there a comparison between the efficiency of different \nlarge language models?\nQAR 5: Is the evaluation of the significant language model/s \nwell performed?\nQAR 6: Is the method used for evaluating the large language \nmodel clear and accurate?\nQAR 7: Are the performance metrics of large language models \nclearly defined and used?\nQAR 8: Is the large language model’s experimental setup stated \nand clear?\nQAR 9: Are the large language models’ parameters described \nclearly and concisely?\nQAR 10: Does this study provide enough information and \nevidence to be considered as related to our work?\nEach QAR score is allocated based on the following scale. ‘Not \nanswered’ is assigned a score of 0, ‘below average’ is valued at 0.25, \n‘average’ is given a score of 0.5, ‘above average’ is designated 0.75, and \n‘fully answered’ is assigned a score of 1. Each study’s overall QAR score \nwas determined on a scale of 1 to 10. Studies that had a score of less than \nfour were disqualified from further synthesis in accordance with our \nreview process. The assessment adhered to a uniform and repeatable \nmethodology that was established during the systematic review’s \npreparation phase, even though the authoring team handled the scoring. \nThis strategy aligns with Kitchenham and Charters’ suggestions, which \nhighlight protocol-driven quality evaluation as a means of minimizing \nbias and improving transparency in software engineering reviews.\n3.5 Data extraction strategy\nWe created a sheet for articles that we found and collected. The \nsheet includes information regarding the large language model, paper \nnumber, paper URL, paper title, author/s, publisher, publisher source, \npublication type, year of publication, paper description, RQ1(field), \nRQ2(LLM type, source), RQ3(software requirements, hardware \nrequirements, model parameters), and RQ4(performance metrics). It’s \nimperative to note that not all research papers can answer the \nresearch questions.\n3.6 Synthesis of extracted data\nAs emphasized by Kitchenham and Charters, the review protocol \nholds significant importance in any SLR. Consequently, the authors \nhave held regular meetings to mitigate researcher bias and uphold the \nquality of the review protocol. Due to the nature of our findings, our \nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 06 frontiersin.org\nFIGURE 3\nFrequency histogram of the 4 LLM categories.\ndata synthesis technique is qualitative because our RQs do not involve \nnumbers or calculations. In the results and discussions section below, \nwe will organize the data in diagrams to the best of our ability.\n4 Results and discussions\nThis section will discuss the answers to the RQs and their \nsubsections, enabling us to conclude our results for this SLR.\n4.1 RQ1: LLM application and use cases\nIn this research question, we aim to understand what field or area \nthe large language model utilized. Since each paper discussed a \ndifferent topic in different fields, we created categories to help organize \nthe collected research papers. After studying the papers carefully, \nwe found that most papers covered four fields: data generation (image, \ntext, code, etc.), prompting, modification or control of data (editing, \ndeletion, retrieval, etc.), and prediction. We then illustrated the result \nof this categorization in Figure 3.\nWhile prompt engineering and data generation may overlap in \npractice, they are fundamentally independent categories. Designing \nand organizing input prompts to elicit particular actions or enhance \nthe quality of model output is the primary purpose of prompt \nengineering. This covers prompt adjustments, prompt templates, and \nzero−/few-shot instances. Data generation, on the other hand, deals \nwith the output process itself, when new artifacts like text passages, \ncode snippets, or summaries are generated from the LLM. Studies \nwere categorized according to their main goal as stated in each paper: \ntasks that focused on generating outputs were labeled as data \ngeneration, whereas operations that focused on modifying inputs were \ncategorized as prompt engineering. Research papers on LLMs in data \ngeneration and prompting appeared most frequently. The references \nfor the documents in each category are listed in Table 4. Out of 27 \npapers, 13 were related to data generation, nine were prompting-\nrelated, four were related to the modification or control of data, and \none was associated with data prediction.\n4.2 RQ2: LLM type and access\nIn this research question, we plan to investigate the type of large \nlanguage model used in the research paper. We also explore whether \nthe LLM is open source or closed source. Figure 4 displays the LLM \ntype along with the frequency; Figure 5 shows whether the LLM \ntype is open or closed source, while Table 5 provides a combination \nof references for papers involved with each LLM type and source.\nFrom the results in Figure 4 above, we infer that GPT-3 was the \nmost utilized LLM in the research papers studied, with a frequency of \n10, meaning it has been used or mentioned by 10 papers. Next comes \nCodex, with a frequency of 8, making it the second most used or \nmentioned LLM amongst the papers investigated. Lambda, GPT-3.5, \nand GPT-2 are all tied with a frequency of 3. Papers (Deng et al., 2023; \nTABLE 2 Display of key search terms.\nLLM keywords Operator Performance \nkeywords\n“Large language model” OR “LLM” \nOR “Efficient language models” OR \n“Prompt-based language models” \nOR “Generative pre-trained \ntransformer “OR “ChatGPT” OR \n“GPT-3” OR “GPT-4” OR “google \nBARD” OR “LLaMA ”\nAND\n“Efficiency” OR \n“Optimization” OR \n“Contextual prompts \nefficiency” OR \n“Prompt optimization \ntransformer models. ”\nTABLE 3 Exclusion and inclusion criteria.\nInclusion rules Exclusion rules\n • Trusted source.\n • Published in the last 5 years.\n • Direct mention of large \nlanguage models.\n • Weak or unknown source.\n • Archive (unpublished).\n • Papers that talk about using large language \nmodels, too, specifically.\n • Papers that do not mention large \nlanguage models.\n • Papers less than four on the QAR total score.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 07 frontiersin.org\nSarsa et al., 2022; Hämäläinen et al., 2023; Ross et al., 2023; Badini \net al., 2023; Mahuli et al., 2023; Macneil et al., 2022; Xu et al., 2022; \nStrobelt et  al., 2023; Wang et  al., 2023; Chang, 2023; Zamfirescu-\nPereira et al., 2023; Wu et al., 2022; Pan and Ke, 2023; Scells et al., \n2023) were papers that either decided to deploy their models or have \nused models that no other paper used, making the LLM, when \nrepresented in a table or illustrated, have a frequency of 1.\nFigure 5 answers the question of whether the LLM is open source \nor closed source. The results display the percentage of papers that \nutilized open-source LLMs contrasted with those that accessed closed-\nsource LLMs instead. With 59% against 41%, we conclude that most \npapers used open-source LLMs. This means that out of the 34 LLMs \nstudied carefully in each paper, 20 LLMs were open source, while 14 \nwere closed source. Despite the fact that a number of articles stated \nthe utilization of open-source models, certain fine-tuning techniques \nwere frequently overlooked out or only briefly mentioned. Therefore, \nit is still difficult to replicate the experimental conditions outlined in \nthose studies. This draws attention to a more general problem in the \nliterature and emphasizes the importance of identifying methods for \nsupporting reproducibility in future research.\nTable 5 combines the two previous figures, Figure 4 and 5, and \ndetails which papers utilized what specific LLM and whether it was \nopen source.\n4.3 RQ3: Setup approach and LLM \nparameters\nThrough this research question, we seek to provide information \non the hardware setup utilized for operating the LLM as well as the \nLLM’s parameters. For this question, we considered the variety of \nLLMs deployed by each research paper and the different resources \nused by various researchers. Therefore, we will organize the hardware \ninformation we collected into smaller components. The results are \nreflected in Table 6.\nTable 6 provides information on the specific hardware components \nmentioned in the research papers. Although the hardware configurations \nutilized in the examined research are shown, many of the articles did not \nprovide full system specifications. A variety of configurations are \nobserved among the remaining studies, ranging from high-end \nmulti-GPU systems to more affordable single-GPU or CPU-only setups. \nThis diversity reflects the varying resource capacities of researchers and \nuse cases, and it underscores the need for more consistent reporting in \nfuture studies to support improved documentation and analysis of \nmodel performance. The most powerful setup among the reviewed \npapers was reported by the researchers in (Xu et al., 2022). The rest have \nmixed to lower-end setups, yet they could still deploy powerful LLMs \ndespite that. Most papers still need to provide information regarding the \nhardware setup.\nTABLE 4 Paper reference numbers in each RQ1 category.\nReference RQ1 Category\nDeng et al. (2023); Sarsa et al. (2022); Hämäläinen \net al. (2023); Ross et al. (2023); Badini et al. (2023); \nMahuli et al. (2023); Macneil et al. (2022); Xu et al. \n(2022); Jain et al. (2022); Vaithilingam et al. (2022); Di \nFede et al. (2022); King (2023); Kang et al. (2023)\nGeneration of Data\nStrobelt et al. (2023); Wang et al. (2023); Chang \n(2023); Zamfirescu-Pereira et al. (2023); Wu et al. \n(2022); Jiang et al. (2022); Reynolds and McDonell \n(2021); Singh et al. (2023); Beurer-Kellner et al. (2023)\nPrompting Related\nPan and Ke (2023); Scells et al. (2023); Fan et al. \n(2023); Urban et al. (2023)\nModification or Control \nof Data\nKim et al. (2021) Prediction of Data\nFIGURE 4\nFrequency histogram of the LLM types.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 08 frontiersin.org\nTABLE 5 LLM type for each paper.\nLLM Frequency\nReference Number Large Language \nModel\nFrequency Open-\nSource?\nSarsa et al. (2022); Hämäläinen et al. (2023); Macneil et al. (2022); Chang (2023); Jain et al. \n(2022); Di Fede et al. (2022); Reynolds and McDonell (2021); Singh et al. (2023); Beurer-\nKellner et al. (2023); Urban et al. (2023)\nGPT-3 10 No\nDeng et al. (2023); Sarsa et al. (2022); Ross et al. (2023); Xu et al. (2022); Vaithilingam et al. \n(2022); Kang et al. (2023); Singh et al. (2023); Fan et al. (2023)\nCodex 8 Ye s\nWu et al. (2022); Pan and Ke (2023); King (2023) LaMDA 3 Ye s\nBadini et al. (2023); Mahuli et al. (2023); Zamfirescu-Pereira et al. (2023) GPT-3.5 3 No\nXu et al. (2022); Beurer-Kellner et al. (2023); Kim et al. (2021) GPT-2 3 Ye s\nXu et al. (2022); Beurer-Kellner et al. (2023) GPT-J 2 Ye s\nStrobelt et al. (2023) T0 1 Ye s\nWang et al. (2023) PaLM 1 No\nPan and Ke (2023) Stytr2 1 Ye s\nScells et al. (2023) PubMed-BERT, BERT, \nDistilBERT\n1 Ye s\nXu et al. (2022) GPT-Neo, GPT-NeoX, \nCodeParrot\n1 Ye s\nFor the section about LLM parameter sizes, a figure was generated \nto show the scale of the models described in the examined research, \nfrom largest to smallest. The findings are shown in Figure 6. CuBERT \nhas the fewest parameters (about 345 million), while PaLM has the \nlargest, with 540 billion parameters.\nA comprehensive evaluation of deployment feasibility cannot \nbe  obtained from parameter count independently; however, it \ndoes give a broad idea of model complexity and possible resource \nrequirements. Due to a lack of consistency in the studied literature, \nimportant factors, including energy usage during training and \ninference, as well as the economic cost per inference step, were \nexcluded from our study. In order to provide more comprehensive \nand useful assessments of model efficiency, this limitation \nhighlights the significance of including energy and cost-related \nindicators in further studies.\n4.4 RQ4: Performance metrics and \nevaluation\nWith this research question, we  aim to identify the metrics \nused to evaluate the performance of different LLMs. It is \nimportant to note that the metrics vary from one LLM to \nanother because of the use case or application of the LLM. For \nexample, PaLM ( Wang et  al., 2023 ) was evaluated on grammar \ncorrectness because the paper is prompting-related. In contrast, \nCodex ( Deng et al., 2023 ) was considered regarding the number \nof detected bugs because the paper is related to code \ngeneration purpose.\nTo provide a more structured overview, performance metrics \nwere grouped into six categories: Translation Evaluation Metrics, \nCode Analysis Metrics, NLP Output Quality Metrics, User \nInteraction and Feedback Metrics, Model Evaluation Benchmarks, \nand Domain-Specific Evaluation Metrics. This restructuring \naddresses differences in evaluation criteria across domains and \nensures a more balanced representation, especially for fields like \nhealthcare and education. While code-related metrics remain \nprominent due to the number of studies in programming contexts, \ndomain-specific metrics have been explicitly highlighted to \nmitigate cross-domain bias and promote greater clarity. Table 7 \npresents the reorganized metric categories along with \nrepresentative evaluation aspects.\nFIGURE 5\nOpen source LLM frequency.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 09 frontiersin.org\nTable 8 reveals the categorization result, presenting each paper \nwith its language model and the information it provided regarding \nthe metrics and category. The table concludes that most papers \nbelong to the “Code Analysis Metrics” category, to be specific, 11 \npapers evaluated their LLMs on program analysis metrics and \nnatural language processing (NLP) metrics. Next were specific \nmodel evaluation metrics, user interaction and feedback metrics, \nand translation evaluation metrics, with 7, 4, and 1 research papers \nrelated to each category in that order.\n5 Challenges and recommendations\nOver a broad spectrum of applications, LLM has shown \nconsiderable promise. Nonetheless, there are several major challenges \nto overcome, especially in developing fields like smart contract \nvalidation, Internet of Things (IoT) integration, and privacy-preserving \nimplementations. To guarantee the safe, open, and responsible \napplication of LLMs in high-stakes situations, these challenges require \nfurther consideration.\nTABLE 6 The hardware components of each setup.\nRef LLM CPU RAM GPUs Notes\nFan et al. (2023) Codex Intel Xeon E5-\n2660\n64GB 1 x NVIDIA Titan V Single GPU, likely development/testing \nsetup\nBeurer-Kellner et al. \n(2023)\nGPT-3, GPT-2, GPT-J Not available Not available 1 x NVIDIA A100 \n(40GB/80GB)\nSingle A100 GPU, likely inference/smaller \nmodels\nDeng et al. (2023) Codex High-end \nworkstation\n256GB 4 x NVIDIA RTX A6000 Powerful multi-GPU setup\nPan and Ke (2023) Stytr2 Not available Not available 2 x NVIDIA Tesla P100 + 2 x \nNVIDIA RTX 3090\nMixed older/newer GPUs, research-specific \nsetup\nScells et al. (2023) PubMed-BERT, BERT, \nDistilBERT\nNot available Not available Not available No hardware information\nXu et al. (2022) Codex, GPT-2, GPT-J, \nGPT-Neo, GPT-NeoX, \nCodeParrot\nNot available Not available 8 x NVIDIA RTX 8000 Most powerful setup, likely large/complex \nmodels/training\nKim et al. (2021) GPT-2 Not available Not available 4 x NVIDIA Tesla V100 Multi-GPU setup with older GPUs, \nresearch/development\nKang et al. (2023) Codex Intel Core i7-7700 32GB Not available Low-end setup, likely small models/testing\nFIGURE 6\nFrequency histogram of the LLMs’ parameters.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 10 frontiersin.org\nTABLE 7 Categories of performance metrics and their aspects.\nCategory Aspect\nTranslation Evaluation Metrics  • BLEU (Bilingual Evaluation Understudy): Measures the quality of machine-generated translations by comparing them to reference \ntranslations.\nCode Analysis Metrics Program Analysis Metrics:\n • LOC (Lines of Code): Measures the number of lines of code in a program.\n • Number of model queries, Number of Decoder calls, Billable tokens: Metrics related to the usage and efficiency of language models in \ncode-related tasks.\n • Statistical analyses, Frechet Distance, precision, recall, topic similarities and differences, answer consistency, game frequencies: Metrics \nfor evaluating code generation models’ statistical properties and performance.\n • Number of detected bugs, Code coverage, Number of covered APIs, Number of unique, valid programs generated, Execution time: \nMetrics related to the quality, coverage, and efficiency of generated code.\nNLP Output Quality Metrics  • Grammar Correctness, UI Relevance, Question Coverage, BLEU, CIDEr, ROUGE-L, METEOR.\n • Exact Matches, Contains GT, Sub-String of GT, Micro-F1: Metrics related to the quality and relevance of natural language outputs, \nespecially in conversational contexts.\nUser Interaction and Feedback \nMetrics\n • Success rate (SR), goal conditions recall (GCR), Executability (Exec): Metrics measuring the success and effectiveness of user interactions \nwith language models.\n • Quantitative and qualitative participant feedback, Surveys: Metrics involving user feedback, satisfaction, and perception.\n • Number of errors encountered during task completion, Number of retries required to complete a task, Time taken to complete a task, \nPerceived ease of use, and usefulness of the tool: Metrics assessing the user experience, efficiency, and usability of language models.\nModel Evaluation Benchmarks  • GLUE (General Language Understanding Evaluation Benchmark): Evaluates a model’s performance on various NLP tasks.\n • CRIT (Critical Reading Inquisitive Template): Evaluates models based on critical reading comprehension.\n • Perplexity: Measures how well a language model predicts the next token in a sequence of code or text.\n • Recall, precision, f-measure: Standard metrics for evaluating the performance of models in information retrieval or classification tasks.\nDomain-Specific Evaluation \nMetrics\n • Using ROBINS-I tool and Risk of Bias analysis, Data extraction from a randomized controlled trial: Metrics related to evaluating research \nstudies and experiments.\n • Likert Scale: Measures attitudes or opinions using a scale of responses.\nThe use of LLMs to support smart contract verification is an \nemerging area of interest. Although LLMs can assist in developing, \nsummarizing, or analyzing smart contracts, their integration within \nblockchain systems presents unique difficulties. Smart contracts demand \nprecise and verifiable logic, where even minor errors can lead to \nsignificant financial consequences. The limited interpretability of \nLLM-generated outputs further complicates efforts to trace and validate \ncontract code, particularly in security-critical scenarios. Significant \nprivacy and security issues also arise from the integration of LLMs into \nedge computing and industrial IoT environments. One study, Wang et al. \n(2022) emphasizes the importance of secure data aggregation techniques \nin blockchain-enabled IoT systems to protect user privacy. Another work, \nWang et al. (2022) highlights the complexity of developing hierarchical \ntrust evaluation models in 5G-enabled intelligent transportation systems, \nespecially when incorporating AI-driven components like LLMs. \nAdditionally, hierarchical federated learning has demonstrated the \npotential to enhance both privacy and anomaly detection in industrial \nsettings (Wang et al., 2023). Collectively, these studies underscore the \nurgency of adapting LLM deployments to privacy-aware architectures, \nparticularly when dealing with real-time, sensitive, or decentralized data.\nFuture LLM applications in smart contracts should include formal \nverification tools that confirm logic soundness and identify potential \nvulnerabilities in order to address these problems. To reduce data \nexposure during model training and inference, techniques like \ndifferential privacy and federated learning should be  further \ninvestigated in privacy-sensitive domains like the IoT and \ntransportation. Furthermore, policy and regulatory frameworks need \nto change to take into account the increasing role that LLMs play in \noperational, financial, and legal decision-making. Lastly, to improve \nreproducibility and ease cross-domain benchmarking, researchers are \nencouraged to accept stronger reporting standards, especially with \nregard to fine-tuning methods, evaluation processes, and deployment.\n6 Conclusion and future work\nIn our systematic literature review, we researched a comparison \nbetween large language models, with our focus on their efficiency. \nWe reviewed 27 research papers published between 2019 and 2023. \nWe  also crafted four research questions that we  believed would \nbe relevant in helping with our comparison. RQ1 covered the field \nthe LLM was used in, RQ2 covered the type of LLM as well as \nwhether it is open source or not, RQ3 covered hardware requirements \nas well as the LLMs’ parameters, and finally, RQ4 covered the metrics \nused for the evaluation of the LLM. We collected research papers and \nevaluated them based on the above research questions.\nOur findings revealed that most studies leveraged LLMs for data \ngeneration tasks, followed by prompting-related applications. GPT-3 \nwas the most widely used model, appearing in 10 studies, followed \nby Codex. A majority of studies utilized open-source LLMs, while \nothers employed proprietary models. Our analysis of hardware \nsetups highlighted a lack of detailed reporting on computational \nresources, though one study utilized an 8 x NVIDIA RTX 8000 GPU \nsetup for high-performance LLM deployment. Regarding evaluation, \nwe observed a strong emphasis on code analysis metrics, followed \nby model-specific evaluations and user interaction feedback.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 11 frontiersin.org\nFuture studies should investigate more detailed efficiency \nindicators, including delay inference, energy usage, and model \nresilience, alongside computing cost and accuracy. Comparative \nstudies in fields such as law, finance, and scientific research could \nprovide further insights into the specialized performance of LLMs. \nAddressing biases, data privacy challenges, and adversarial robustness \nwill require more systematic evaluations. Additionally, advancements \nin model optimization techniques, such as pruning, quantization, and \nefficient fine-tuning, can help mitigate the computational burden of \nlarge-scale deployment. Beyond efficiency, future research should \nemphasize interpretability and usability, as these factors are crucial for \nreal-world adoption. Transparency in decision-making, bias \nreduction, and explainability in high-risk applications, particularly in \nhealthcare and finance, remain critical research areas. Exploring LLM \napplications in novel domains, such as blockchain-based smart \ncontract verification, could further reveal insights into their \nadaptability and security implications. By addressing these research \ngaps, the continued evolution of LLMs can be  guided toward \nmaximizing efficiency while mitigating potential risks associated with \nwidespread deployment.\nTABLE 8 LLM performance metrics.\nRef Model Metrics Category\nReynolds and McDonell (2021) GPT-3 BLEU (French-to-English translations) Translation Evaluation Metrics\nFan et al. (2023) Codex Manual analysis, codex-e, TBar, and Recorder Code Analysis Metrics\nBeurer-Kellner et al. (2023) GPT-3, GPT-2, GPT-J LOC, Number of model queries, Number of Decoder calls, Billable \ntokens\nCode Analysis Metrics\nSarsa et al. (2022) GPT-3, Codex Programmatic analysis Code Analysis Metrics\nHämäläinen et al. (2023) GPT-3 Statistical analyses, Frechet Distance, precision, recall, topic \nsimilarities and differences, answer consistency, game frequencies\nCode Analysis Metrics\nDeng et al. (2023) Codex Number of detected bugs, Code coverage, Number of covered APIs, \nNumber of unique, valid programs generated, Execution time\nCode Analysis Metrics\nWang et al. (2023) PaLM Grammar Correctness, UI Relevance, Question Coverage, BLEU, \nCIDEr, ROUGE-L, and METEOR, Exact Matches, Contains GT, \nSub-String of GT, Micro-F1\nCode Analysis Metrics\nScells et al. (2023) PubMed-BERT, BERT, \nDistilBERT\nRecall, precision, f-measure Code Analysis Metrics\nZamfirescu-Pereira et al. (2023) GPT-3.5 Number of errors encountered during task completion, Number of \nretries required to complete a task, Time taken to complete a task, \nPerceived ease of use, and usefulness of the tool\nUser Interaction and Feedback Metrics\nBadini et al. (2023) GPT-3.5 Resolution of specific 3D printing issues considering filament \nmaterial and other conditions\nCode Analysis Metrics\nWu et al. (2022) LaMDA Likert Scale, Interaction mechanisms and behaviors, Consecutive \nrun, Edited, Curated, Created, Undone\nUser Interaction and Feedback Metrics\nXu et al. (2022) Codex, GPT-2, GPT-J, \nGPT-Neo, GPT-NeoX, \nCodeParrot\nPerplexity, Code completion accuracy, Human evaluation Code Analysis Metrics\nSingh et al. (2023) Codex Success rate (SR), goal conditions recall (GCR), Executability (Exec) User Interaction and Feedback Metrics\nRoss et al. (2023) Codex Quantitative and qualitative feedback from 42 participants, Surveys \n(pre-study, pre-task, post-task)\nUser Interaction and Feedback Metrics\nMahuli et al. (2023) GPT-3.5 Using the ROBINS-I tool and Risk of Bias analysis, Data extraction \nfrom a randomized controlled trial\nUser Interaction and Feedback Metrics\nStrobelt et al. (2023) T0 GLUE (General Language Understanding Evaluation Benchmark) Specific Model Evaluation Metrics\nChang (2023) GPT-3 CRIT (Critical Reading Inquisitive Template) Specific Model Evaluation Metrics\nMacneil et al. (2022) GPT-3 Tracing the execution of code, Fixing bugs, Explaining how they \nwere fixed, Generating analogies, Listing relevant programming \nconcepts, Predicting the console output\nSpecific Model Evaluation Metrics\nKing (2023) LaMDA Analysis of the accuracy of scientific references generated by \nGoogle’s Bard chatbot\nSpecific Model Evaluation Metrics\nUrban et al. (2023) GPT-3 The accuracy of natural language prompts and structured prompts Specific Model Evaluation Metrics\nKim et al. (2021) GPT-2 Evaluation of next token prediction for leaf tokens Specific Model Evaluation Metrics\nKang et al. (2023) Codex “-acc@n, ” precision, wef, wef@n Specific Model Evaluation Metrics\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 12 frontiersin.org\nData availability statement\nThe original contributions presented in the study are included in \nthe article/supplementary material, further inquiries can be directed \nto the corresponding author.\nAuthor contributions\nYS: Data curation, Formal analysis, Methodology, Resources, \nVisualization, Writing – original draft. MA: Data curation, Funding \nacquisition, Project administration, Resources, Software, Supervision, \nWriting – review & editing. QN: Conceptualization, Formal analysis, \nInvestigation, Project administration, Resources, Supervision, \nWriting – review & editing. FD: Conceptualization, Data curation, \nFormal analysis, Investigation, Resources, Visualization, Writing – \noriginal draft, Writing – review & editing.\nFunding\nThe author(s) declare that no financial support was received for \nthe research and/or publication of this article.\nAcknowledgments\nWe like to convey our sincere appreciation to the General \nCivil Aviation Authority (GCAA) of the UAE for founding \nthe Aerospace Centre of Excellence and executing this \nresearch study. We  express our gratitude to our supervisors \nand colleagues from the OpenUAE Research and \nDevelopment Group at the University of Sharjah for their \ninvaluable insights and knowledge that significantly contributed \nto the research.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe construed as a potential conflict of interest.\nGenerative AI statement\nThe author(s) declare that no Gen AI was used in the creation of \nthis manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the \nauthors and do not necessarily represent those of their affiliated \norganizations, or those of the publisher, the editors and the \nreviewers. Any product that may be evaluated in this article, or \nclaim that may be made by its manufacturer, is not guaranteed or \nendorsed by the publisher.\nReferences\nBadini, S., Regondi, S., Frontoni, E., and Pugliese, R. (2023). Assessing the capabilities \nof ChatGPT to improve additive manufacturing troubleshooting. Adv. Indust. Eng. \nPolymer Res. 6, 278–287. doi: 10.1016/j.aiepr.2023.03.003\nBender, E. M., Gebru, T., McMillan-Major, A., and Shmitchell, S., (2021). “On the \ndangers of stochastic parrots: can language models be  too big?, ” in FAccT 2021  - \nProceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. \npp. 610–623.\nBeurer-Kellner, L., Fischer, M., and Vechev, M. (2023). Prompting is programming: a \nquery language for large language models. Proc. ACM Program. Lang. 7, 1946–1969. doi: \n10.1145/3591300\nCascella, M., Montomoli, J., Bellini, V ., and Bignami, E. (2023). Evaluating the \nfeasibility of ChatGPT in healthcare: an analysis of multiple clinical and research \nscenarios. J. Med. Syst. 47, 1–5. doi: 10.1007/S10916-023-01925-4/TABLES/2\nChang, E. Y ., (2023). “Prompting large language models with the Socratic method, ” In \n2023 IEEE 13th Annual Computing and Communication Workshop and Conference, \nCCWC 2023, Institute of Electrical and Electronics Engineers Inc., pp. 351–360.\nDeng, Y ., Xia, C. S., Peng, H., Y ang, C., and Zhang, L., (2023). “Large language models \nare zero-shot Fuzzers: fuzzing deep-learning libraries via large language models, ” ISSTA \n2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software \nTesting and Analysis. pp. 423–435.\nDi Fede, G., Rocchesso, D., Dow, S. P ., and Andolina, S., (2022). “The idea machine: \nLLM-based expansion, rewriting, combination, and suggestion of ideas, ” in ACM \nInternational Conference Proceeding Series. pp. 623–627.\nEggmann, F ., Weiger, R., Zitzmann, N. U., and Blatz, M. B. (2023). Implications of \nlarge language models such as ChatGPT for dental medicine. J. Esthet. Restor. Dent. 35, \n1098–1102. doi: 10.1111/jerd.13046\nFan, M., (2024). “LLMs in banking: applications, challenges, and approaches, ” in \nProceedings of the International Conference on Digital Economy, Blockchain and Artificial \nIntelligence, in DEBAI ‘24. New Y ork, NY , USA: Association for Computing Machinery. \npp. 314–321.\nFan, Z., Gao, X., Mirchev, M., Roychoudhury, A., and Tan, S. H., (2023). “ Automated \nrepair of programs from large language models, ” Institute of Electrical and Electronics \nEngineers (IEEE). pp. 1469–1481.\nFloridi, L. (2023). AI as agency without intelligence: on ChatGPT, large language \nmodels, and other generative models. Philos. Technol.  36, 1–7. doi: \n10.1007/S13347-023-00621-Y/FIGURES/3\nHämäläinen, P ., Tavast, M., and Kunnari, A., (2023). “Evaluating large language \nmodels in generating synthetic HCI research data: a case study, ” in Conference on Human \nFactors in Computing Systems - Proceedings.\nHead, C. B., Jasper, P ., McConnachie, M., Raftree, L., and Higdon, G. (2023). Large \nlanguage model applications for evaluation: opportunities and ethical implications. N. \nDir. Eval. 2023, 33–46. doi: 10.1002/EV .20556\nHuang, H., Zheng, O., Wang, D., Yin, J., Wang, Z., Ding, S., et al. (2023). ChatGPT for \nshaping the future of dentistry: the potential of multi-modal large language model. Int. \nJ. Oral Sci. 15, 29–13. doi: 10.1038/s41368-023-00239-y\nJain, N., Vaidyanath, S., Iyer, A., Natarajan, N., Parthasarathy, S., Rajamani, S., et al. \n(2022). “Jigsaw: large language models meet program synthesis, ” in Proceedings  - \nInternational Conference on Software Engineering, IEEE Computer Society. pp. 1219–1231.\nJiang, E., Olson, K., Toh, E., Molina, A., Donsbach, A., Terry, M., et al. (2022). \n“PromptMaker: prompt-based prototyping with large language models, ” in Conference on \nHuman Factors in Computing Systems - Proceedings. Association for Computing Machinery.\nJo, E., Epstein, D. A., Jung, H., and Kim, Y . H., (2023). “Understanding the benefits \nand challenges of deploying conversational AI leveraging large language models for \npublic health intervention, ” Conference on Human Factors in Computing Systems  - \nProceedings. p. 16.\nKamnis, S. (2023). Generative pre-trained transformers (GPT) for surface engineering. \nSurf. Coat. Technol. 466:129680. doi: 10.1016/j.surfcoat.2023.129680\nKang, S., Y oon, J., and Y oo, S., (2023). “Large language models are few-shot testers: \nexploring LLM-based general bug reproduction, ” in Proceedings  - International \nConference on Software Engineering. pp. 2312–2323.\nKasneci, E., Sessler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F ., et al. \n(2023). ChatGPT for good? On opportunities and challenges of large language models \nfor education. Learn. Individ. Differ. 103:102274. doi: 10.1016/j.lindif.2023.102274\nKim, S., Zhao, J., Tian, Y ., and Chandra, S., (2021). “Code prediction by feeding trees \nto transformers, ” Proceedings  - International Conference on Software Engineering , \npp. 150–162.\nSaleh et al. 10.3389/fcomp.2025.1523699\nFrontiers in Computer Science 13 frontiersin.org\nKing, M. R. (2023). Can Bard, Google’s experimental Chatbot based on the \nLaMDA large language model, help to analyze the gender and racial diversity of \nauthors in your cited scientific references? Cell. Mol. Bioeng.  16, 175–179. doi: \n10.1007/s12195-023-00761-3\nLiu, P ., Yuan, W ., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. (2023). Pre-train, \nprompt, and predict: a systematic survey of prompting methods in natural language \nprocessing. ACM Comput. Surv. 55, 1–35. doi: 10.1145/3560815\nLund, B. D., Wang, T., Mannuru, N. R., Nie, B., Shimray, S., and Wang, Z. (2023). \nChatGPT and a new academic reality: artificial intelligence-written research papers and \nthe ethics of the large language models in scholarly publishing. J. Assoc. Inf. Sci. Technol. \n74, 570–581. doi: 10.1002/ASI.24750\nMacneil, S., Tran, A., Mogil, D., Bernstein, S., Ross, E., and Huang, Z., (2022). \n“Generating diverse code explanations using the GPT-3 large language model, ” in \nProceedings of the 2022 ACM Conference on International Computing Education \nResearch - Volume 2. p. 3.\nMahuli, S. A., Rai, A., Mahuli, A. V ., and Kumar, A. (2023). Application ChatGPT in \nconducting systematic reviews and meta-analyses. Br. Dent. J.  235, 90–92. doi: \n10.1038/s41415-023-6132-y\nMeyer, J. G., Urbanowicz, R. J., Martin, P . C. N., O’Connor, K., Li, R., Peng, P . C., et al. \n(2023). ChatGPT and large language models in academia: opportunities and challenges. \nBioData Mining 16, 20–11. doi: 10.1186/s13040-023-00339-9\nMilano, S., McGrane, J. A., and Leonelli, S. (2023). Large language models challenge \nthe future of higher education. Nat. Mach. Intellig.  5, 333–334. doi: \n10.1038/s42256-023-00644-2\nMin, B., Ross, H., Sulem, E., Veyseh, A. P . B., Nguyen, T. H., Sainz, O., et al. (2023). \nRecent advances in natural language processing via large pre-trained language models: \na survey. ACM Comput. Surv. 56, 1–40. doi: 10.1145/3605943\nMökander, J., and Schuett, J., · Hannah, R. Kirk, and Floridi, Luciano, “ Auditing large \nlanguage models: a three-layered approach, ” AI Ethics vol. 1, pp. 1–31, (2023). doi: \n10.1007/S43681-023-00289-2\nPan, B., and Ke, Y . K., (2023). “Efficient artistic image style transfer with large language \nmodel (LLM): a new perspective, ” in Proceedings of the 8th International Conference on \nCommunication and Electronics systems, ICCES 2023 , Institute of Electrical and \nElectronics Engineers Inc. pp. 1729–1732.\nPorsdam Mann, S., Earp, B. D., Møller, N., Vynn, S., and Savulescu, J. (2023). \nAUTOGEN: a personalized large language model for academic enhancement—ethics \nand proof of principle. Am. J. Bioeth.  23, 28–41. doi: 10.1080/15265161.2023.  \n2233356\nQureshi, R., Shaughnessy, D., Gill, K. A. R., Robinson, K. A., Li, T., and Agai, E. (2023). \nAre ChatGPT and large language models ‘the answer’ to bringing us closer to systematic \nreview automation? Syst. Rev. 12, 1–4. doi: 10.1186/S13643-023-02243-Z/PEER-REVIEW\nRessi, D., Romanello, R., Piazza, C., and Rossi, S. (2024). AI-enhanced blockchain \ntechnology: a review of advancements and opportunities. J. Netw. Comput. Appl.  \n225:103858. doi: 10.1016/j.jnca.2024.103858\nReynolds, L., and McDonell, K., (2021). “Prompt programming for large language \nmodels: beyond the few-shot paradigm, ” in Conference on Human Factors in Computing \nSystems - Proceedings. Association for Computing Machinery.\nRoss, S. I., Martinez, F ., Houde, S., Muller, M., and Weisz, J. D., (2023). “The \nProgrammer’s assistant: conversational interaction with a large language model for \nsoftware development, ” in International Conference on Intelligent User Interfaces, \nProceedings IUI, Association for Computing Machinery. pp. 491–514.\nSarsa, S., Denny, P ., Hellas, A., and Leinonen, J., (2022). “ Automatic generation of \nprogramming exercises and code explanations using large language models, ” in ICER \n2022 - Proceedings of the 2022 ACM Conference on International Computing Education \nResearch. Association for Computing Machinery, Inc. pp. 27–43.\nScells, H., Schlatt, F ., and Potthast, M., (2023). “Smooth operators for effective \nsystematic review queries, ” in SIGIR 2023 - Proceedings of the 46th International ACM \nSIGIR Conference on Research and Development in Information Retrieval, Association \nfor Computing Machinery, Inc pp. 580–590.\nSiino, M., Falco, M., Croce, D., and Rosso, P . (2025). Exploring LLMs applications in \nlaw: a literature review on current legal NLP approaches. IEEE Access 13, 18253–18276. \ndoi: 10.1109/ACCESS.2025.3533217\nSingh, I., Blukis, V ., Mousavian, A., Goyal, A., Xu, D., Tremblay, J., et al . (2023). \n“ProgPrompt: generating situated robot task plans using large language models, ” in \nProceedings - IEEE International Conference on Robotics and Automation, Institute of \nElectrical and Electronics Engineers Inc. pp. 11523–11530.\nSinghal, K., Azizi, S., Tu, T., Mahdavi, S. S., Wei, J., Chung, H. W ., et al. (2023). Large \nlanguage models encode clinical knowledge. Nature 620, 172–180. doi: \n10.1038/s41586-023-06291-2\nStrobelt, H., Webson, A., Sanh, V ., Hoover, B., Beyer, J., Pfister, H., et al. (2023). \nInteractive and visual prompt engineering for ad-hoc task adaptation with large language \nmodels. IEEE Trans. Vis. Comput. Graph. 29, 1146–1156. doi: 10.1109/TVCG.2022.3209479\nTeubner, T., Flath, C. M., Weinhardt, C., van der Aalst, W ., and Hinz, O. (2023). \nWelcome to the era of ChatGPT et al.: the prospects of large language models. Bus. Inf. \nSyst. Eng. 65, 95–101. doi: 10.1007/s12599-023-00795-x\nTopsakal, O., and Akinci, T. C. (2023). Creating large language model applications \nutilizing LangChain: a primer on developing LLM apps fast. Int. Conf. Appl. Eng. Nat. \nSci. 1, 1050–1056. doi: 10.59287/icaens.1127\nTrott, S., Jones, C., Chang, T., Michaelov, J., and Bergen, B. (2023). Do large language \nmodels know what humans know? Cogn. Sci. 47:13309. doi: 10.1111/COGS.13309\nUrban, M., Nguyen, D. D., and Binnig, C., (2023). “OmniscientDB: a large language model-\naugmented DBMS that knows what other DBMSs do not know, ” Proceedings of the 6th \nInternational Workshop on Exploiting Artificial Intelligence Techniques for Data Management, \naiDM 2023 - in conjunction with the 2023 ACM SIGMOD/PODS Conference.\nVaithilingam, P ., Zhang, T., and Glassman, E. L., (2022). “Expectation vs. experience: \nevaluating the usability of code generation tools powered by large language models, ” in \nConference on Human Factors in Computing Systems  - Proceedings.  Association for \nComputing Machinery.\nWang, X., Garg, S., Lin, H., Hu, J., Kaddoum, G., Jalil Piran, M., et al. (2022). Toward \naccurate anomaly detection in industrial internet of things using hierarchical federated \nlearning. IEEE Internet Things J. 9, 7110–7119. doi: 10.1109/JIOT.2021.3074382\nWang, X., Garg, S., Lin, H., Kaddoum, G., Hu, J., and Hassan, M. M. (2023). \nHeterogeneous Blockchain and AI-driven hierarchical trust evaluation for 5G-enabled \nintelligent transportation systems. IEEE Trans. Intell. Transp. Syst.  24, 1–10. doi: \n10.1109/TITS.2021.3129417\nWang, X., Garg, S., Lin, H., Kaddoum, G., Hu, J., and Hossain, M. S. (2022). A secure \ndata aggregation strategy in edge computing and Blockchain-empowered internet of \nthings. IEEE Internet Things J. 9, 14237–14246. doi: 10.1109/JIOT.2020.3023588\nWang, B., Li, G., and Li, Y ., (2023). “Enabling conversational interaction with Mobile \nUI using large language models, ” in Conference on Human Factors in Computing \nSystems - Proceedings. Association for Computing Machinery.\nWu, X., Duan, R., and Ni, J. (2023). Unveiling security, privacy, and ethical concerns \nof ChatGPT. J. Inform. Intellig. 2, 102–115. doi: 10.1016/J.JIIXD.2023.10.007\nWu, T., Terry, M., and Cai, C. J., (2022). “ AI chains: transparent and controllable \nhuman-AI interaction by chaining large language model prompts, ” in Conference on \nHuman Factors in Computing Systems  - Proceedings . Association for Computing \nMachinery.\nXu, F . F ., Alon, U., Neubig, G., and Hellendoorn, V . J., (2022). “ A systematic evaluation of \nlarge language models of code, ” in Association for Computing Machinery (ACM). pp. 1–10.\nZamfirescu-Pereira, J. D., Wong, R. Y ., Hartmann, B., and Y ang, Q., (2023). “Why \nJohnny Can’t prompt: how non-AI experts try (and fail) to design LLM prompts, ” in \nConference on Human Factors in Computing Systems  - Proceedings.  Association for \nComputing Machinery.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5163415670394897
    }
  ]
}