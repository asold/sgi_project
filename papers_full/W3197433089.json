{
  "title": "Transformers in the loop: Polarity in neural models of language",
  "url": "https://openalex.org/W3197433089",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A137883719",
      "name": "Lisa Bylinina",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105630735",
      "name": "Alexey Tikhonov",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2998696444",
    "https://openalex.org/W3168987555",
    "https://openalex.org/W2143693877",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W3013286647",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W2068905204",
    "https://openalex.org/W3103536442",
    "https://openalex.org/W2954194820",
    "https://openalex.org/W2946794439",
    "https://openalex.org/W3129158874",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3175508917",
    "https://openalex.org/W3034510440",
    "https://openalex.org/W3185327153",
    "https://openalex.org/W2898556170",
    "https://openalex.org/W4288631803",
    "https://openalex.org/W3004346089",
    "https://openalex.org/W3097977265",
    "https://openalex.org/W2971044268",
    "https://openalex.org/W2126678393",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W2910243263",
    "https://openalex.org/W4285719527",
    "https://openalex.org/W2962961857",
    "https://openalex.org/W4287632625",
    "https://openalex.org/W4287118015",
    "https://openalex.org/W2888922637",
    "https://openalex.org/W2044424967",
    "https://openalex.org/W2921890305",
    "https://openalex.org/W1522920269",
    "https://openalex.org/W3035172163",
    "https://openalex.org/W3176245452",
    "https://openalex.org/W2864832950",
    "https://openalex.org/W4287124808",
    "https://openalex.org/W2964117978",
    "https://openalex.org/W3119854206",
    "https://openalex.org/W2108299914",
    "https://openalex.org/W3154603286",
    "https://openalex.org/W2802158617"
  ],
  "abstract": "Representation of linguistic phenomena in computational language models is typically assessed against the predictions of existing linguistic theories of these phenomena. Using the notion of polarity as a case study, we show that this is not always the most adequate set-up. We probe polarity via so-called ‘negative polarity items’ (in particular, English ‘any’) in two pre-trained Transformer-based models (BERT and GPT-2). We show that – at least for polarity – metrics derived from language models are more consistent with data from psycholinguistic experiments than linguistic theory predictions. Establishing this allows us to more adequately evaluate the performance of language models and also to use language models to discover new insights into natural language grammar beyond existing linguistic theories. This work contributes to establishing closer ties between psycholinguistic experiments and experiments with language models.",
  "full_text": "Transformers in the loop:\nPolarity in neural models of language\nLisa Bylinina∗\nBookarang, Amsterdam\nbylinina@gmail.com\nAlexey Tikhonov∗\nYandex Technologies GmbH, Berlin\naltsoph@gmail.com\nAbstract\nRepresentation of linguistic phenomena in com-\nputational language models is typically as-\nsessed against the predictions of existing lin-\nguistic theories of these phenomena. Using the\nnotion of polarity as a case study, we show that\nthis is not always the most adequate set-up. We\nprobe polarity via so-called ‘negative polarity\nitems’ (in particular, English any) in two pre-\ntrained Transformer-based models (BERT and\nGPT-2). We show that – at least for polarity –\nmetrics derived from language models are more\nconsistent with data from psycholinguistic ex-\nperiments than linguistic theory predictions.\nEstablishing this allows us to more adequately\nevaluate the performance of language models\nand also to use language models to discover\nnew insights into natural language grammar\nbeyond existing linguistic theories. This work\ncontributes to establishing closer ties between\npsycholinguistic experiments and experiments\nwith language models.\n1 Introduction\nRecent Transformer-based language representation\nmodels (LRMs) – such as BERT and GPT-2 (De-\nvlin et al., 2019; Radford et al., 2019) – show im-\npressive results on practical text analysis tasks. But\ndo these models have access to complex linguistic\nnotions? The results in this domain are less clear –\nas well as ways to best approach this question.\nInstead of asking whether LRMs encode frag-\nments of current linguistic theory, we will directly\ncompare metrics derived from LRMs to correspond-\ning human judgments obtained in psycholinguistic\nexperiments. The motivation for this is twofold.\nFirst, linguistic theories can be inaccurate – so,\nevaluating a model with respect to predictions of\nsuch theories is not informative about the model\nperformance. Second, robust abstract theoretical\nnotions rarely correspond to robust judgments in\n∗Equal contribution. Accepted to ACL main conference.\nhumans, and ‘theoretical’ and ‘perceived’ versions\nof the same phenomenon can be significantly dif-\nferent (for instance, see Geurts 2003 on inference\njudgments; discussed in Section 2). If this is some-\nthing that LRMs inherit through training on human-\nproduced texts, this makes LRMs an attractive pos-\nsible component in an experimental pipeline, serv-\ning as a source of empirical predictions about hu-\nman linguistic behaviour (Baroni, 2021; Linzen\nand Baroni, 2021).\nAs a case study, we focus on polarity: a com-\nplex property of sentences at the intersection of\ngrammar and semantics. We tackle polarity via\nthe distribution of items that are sensitive to it –\nnamely, so-called negative polarity items (NPIs)\nlike English any. As a basic illustration of NPI\nsensitivity to polarity, consider a pair of sentences\nin (1) (* = ungrammaticality):\n(1) a. Mary didn’t buy any books.\nb. *Mary bought any books.\n(1-a) is a negative sentence (has negative polarity),\nand any is grammatical in it. (1-b) is an affirma-\ntive sentence (has positive polarity) and any in this\nsentence is grammatically degraded compared to\n(1-a). Apart from this paradigmatic contrast, as we\ndiscuss below, polarity contrasts are expressed in a\nvariety of ways and are tied to semantics.\nAs a proxy for a grammaticality measure, we\nwill use the probability of any in the masked to-\nken position (in BERT) (following Goldberg 2019;\nWarstadt et al. 2019 a.o.) and perplexity increase\nwhen adding any to a sentence (in GPT-2). The\ndifferences in the metrics for the two different mod-\nels stem from the differences in their architecture\nand training objectives. For all experiments, we\nuse non-fine-tuned pre-trained LRMs. For this, we\nintroduce our ANY dataset, which combines natural\nand synthetic data.\nWe findhigh levels of alignment between results\nof psycholinguistic experiments on monotonicity\nand NPIs, on the one hand – and our LRM-derived\nresults, on the other hand. Furthermore, show how\nLRMs can be used to make new predictions about\nNPIs in contexts with different numerals and con-\nfirm these predictions in a psycholinguistic experi-\nment.\nThis case study contributes to the complement\nof the ‘interpretability of neural LRMs’ research\nagenda: we can ask not only what linguistic tasks\ntell us about LRMs, but also what these models can\nhelp us find out about natural language (see Baroni\n2021; Linzen and Baroni 2021 for a discussion\nalong these lines).\nThe paper is structured as follows. First, in sec-\ntion 2, we set up the context for our study: we\ndescribe the background in theoretical and experi-\nmental linguistics in the domains relevant for our\ndiscussion. Section 3 discusses previous work on\nNPIs and polarity in computational linguistics. Sec-\ntion 4 contains the description of our experimen-\ntal method. First, we introduce our ANY dataset;\nthen, we describe the tests and metrics we use with\nBERT and with GPT-2 given our dataset. Section\n5 discusses our results. In section 6, we go be-\nyond state-of-the-art knowledge in experimental\nsemantics and pragmatics and study the effect of\nthe numeral on NPI acceptability – first, we do a\nBERT study and then confirm the results on hu-\nman participants. Section 7 concludes: we propose\ndirections for future work aligning experimental\nstudies of language in humans and LRMs.\n2 Background\nNPIs are expressions with limited linguistic distri-\nbution. While their use is grammatical in some\nsentences, in other sentences their use results in\nungrammaticality. The distribution of NPIs like\nany is governed by the notion of polarity that is\nmuch more intricate than the simple presence or\nabsence of sentential negation, as in (1).\nFor instance, in examples (2)-(3), (2) are ‘neg-\native enough’ to allow for (=‘license’) any, while\n(3) are not – even though none of these sentences\ncontain overt sentential negation.\n(2) a. None of the boxes contain anything.\nb. Nobody talked to anybody.\nc. At most five students did anything.\nd. Few people had any thoughts\n(3) a. *Some of the boxes contain anything.\nb. *Somebody talked to anybody.\nc. *At least 5 students did anything.\nd. *Many people had any thoughts\nThe notion of polarity at play here relates to a se-\nmantic notion of monotonicity.1\nThe notion of monotonicity builds on logical en-\ntailment. Monotonicity of a linguistic environment\ndefines its entailment patterns. In (4), the domain\nin square brackets is upward-entailing (UE), or\nupward-monotone, – as evidenced by the valid in-\nference from sets (textbooks) to supersets (books):\nsentence (4-b) entails sentence (4-a).\n(4) a. Some boxes [ contain books ] ↑\nb. Some boxes [ contain textbooks ] ↑\nIn contrast, (5) shows adownward-entailing (DE),\nor downward-monotone, environment, which sup-\nports inferences from sets (books) to subsets (text-\nbooks): (5-a) entails (5-b).\n(5) a. No boxes [ contain books ] ↓\nb. No boxes [ contain textbooks ] ↓\nNot all environments are either UE or DE – some\nare non-monotone, that is, supporting neither of\nthe inferences:\n(6) a. Exactly 5 boxes [ contain books ] −\nb. Exactly 5 boxes [ contain textbooks ]−\nExpressions responsible for monotonicity of a lin-\nguistic context are a heterogeneous class that in-\ncludes sentential operators such as negation and\nconditional if; quantifiers (some, no, few, at most\nfive etc.); quantificational adverbs (rarely, always\netc.) and more.\nMonotonicity is a highly abstract logical prop-\nerty interfacing with general reasoning. At the\nsame time, it is deeply embedded into natural lan-\nguage grammar and it is relevant for understanding\nof inner workings of different linguistic expres-\nsions, such as NPIs.\nAs shown by examples (1)-(3), DE contexts give\nrise to negative polarity, as seen from NPI accept-\nability; UE contexts are positive. There is conflict-\ning evidence concerning non-monotone contexts\n(Crniˇc, 2014; Alexandropoulou et al., 2020).\nThe connection between monotonicity and NPI\nlicensing is undeniable also beyond examples (1)-\n(3) (see Fauconnier 1975; Ladusaw 1979 and much\n1This is a simplification. This is true of so-called ‘weak\nNPIs’ – a subclass of NPIs to which any belongs. We will\nkeep referring to them simply as NPIs since we are only dis-\ncussing weak ones. There are also other factors in weak NPI\ndistribution apart from monotonicity (see Giannakidou 1998;\nBarker 2018). Still, we focus on monotonicity as a crucial\nfactor in NPI acceptability, following evidence discussed in\nthe rest of the section.\nLogical monotonicity Subjective monotonicity\nNEG >> AFF; AT MOST > AT LEAST NEG > AT MOST ; NO > FEW\nNO >> SOME ; AT MOST > BETWEEN / EXACTLY NEG > FEW ; NO > FEWER\nFEW > MANY ; FEW > BETWEEN / EXACTLY NEG > FEWER ; FEWER > AT MOST\nFEWER > MORE ; FEWER > BETWEEN / EXACTLY NO > AT MOST ; EXACTLY > BETWEEN\nTable 1: Graded monotonicity: summary of psycholinguistic experimental results (Geurts, 2003; Sanford et al.,\n2007; Chemla et al., 2011; McNabb et al., 2016; Deni ´c et al., 2020). The order in pairs represents that the first\nelement is judged as a better NPI licenser than the second one or that it better supports DE inferences (or both).\nThat is, ‘NEG >> AFF’ reads as ‘Sentences with sentential negation show much higher level of NPI acceptability\nor support DE inferences more than simple affirmative sentences.’. The ‘Logical monotonicity’ side of the table\ngroups together all relations expected under the logical view of monotonicity; ‘Subjective monotonicity’ contains\nadditional asymmetries found experimentally that do not follow from the simple logical view.\nsubsequent literature). Experimental evidence\nshows a bi-directional connection between infer-\nence judgments in a context and NPI acceptability\nin that context. Chemla et al. (2011) found that the\ninferences a person considers valid in a given lin-\nguistic context predict how acceptable they would\nfind an NPI in that same context. Conversely, Deni´c\net al. (2020) show that inferential judgments are\nmodified by the presence of an NPI. So, the two\nphenomena show clear mutual influence.\nImportantly, both monotonicity and NPI accept-\nability in humans is not an all-or-nothing matter.\nAcceptance of logically valid inferences and re-\njection of invalid ones varies to some extent from\nperson to person – and from context to context\n(Geurts, 2003; Sanford et al., 2007; Chemla et al.,\n2011; McNabb et al., 2016; Deni´c et al., 2020).\nChemla et al. (2011) report that logically DE\nsentences with no are perceived as DE by human\nparticipants only 72% of the time. At most – also\nlogically a DE environment – is only recognized as\nsuch 56% of the time. Moreover, less than and at\nmost – truth-conditionally equivalent environments\n– differ in DE inference endorsement by 11%. The\nbest predictor of NPI acceptability by humans was\nfound to be not the logical entailment pattern but\nthe subjective, or perceived, one (Chemla et al.,\n2011; Deni´c et al., 2020).\nThere is no single overarching psycholinguistic\nstudy testing the whole landscape of contexts. Com-\nbined knowledge from an array of studies (Geurts,\n2003; Sanford et al., 2007; Chemla et al., 2011;\nMcNabb et al., 2016; Deni´c et al., 2020) produces\nthe picture summarized in Table 1.\n3 Previous work\nNPIs have been a topic of an investigation in the\ncontext of LRMs, both as a subset of a more general\ntest dataset (Marvin and Linzen, 2018; Hu et al.,\n2020), and as the main object of study (Jumelet\nand Hupkes, 2018; Warstadt et al., 2019; Jumelet\net al., 2021; Weber et al., 2021). Here we focus\non (Warstadt et al., 2019) as a representative case,\nas it shares with other previous studies its general\nset-up: assessment of LRMs against predictions of\nlinguistic theory.\nWarstadt et al. (2019) focus on NPIs in BERT.\nUsing a variety of testing techniques, both zero-\nshot and with fine-tuning, they conclude that\nBERT’s ability to recognize NPI licensing envi-\nronments and, therefore, to tell licit uses of NPIs\nfrom illicit ones varies a lot depending on the type\nof context, scope configuration and the type of ex-\nperimental setting.\nThis might lead one to conclude that BERT’s\nability to recognize polarity of a sentence is not\nso great across the board. Indeed, reports from\nother tasks that involve polarity and/or monotonic-\nity seem to support this. In particular, natural\nlanguage inference has been reported to be hard\nfor LRMs (Yanaka et al., 2019a,b; Talmor et al.,\n2020; Geiger et al., 2020). Remarkably, Geiger\net al. (2020) report that fine-tuning BERT on the\nSNLI dataset and then evaluating it on DE sen-\ntences (their NMoNLI dataset) results in 2.2% ac-\ncuracy – that is, the model practically ignores the\nmonotonicity profile of the sentence. But is alleged\npoor polarity detection to blame here?\nImportantly for our study, Warstadt et al. (2019)\njudge BERT’s recognition of NPI acceptability\nagainst logical monotonicity rather than subjective\nmonotonicity as uncovered by psycholinguistic ex-\nperiments. So, we believe that these results deserve\na second look.\nOne of the measuring techniques in Warstadt\net al. (2019) is very close to one of the two tech-\nniques we will adopt in this paper. It is a version of\nCloze Test adapted for MLM, where probabilities\nof candidates for the masked position are compared.\nWe discuss the set-up in section 4.\nFinally, the idea of targeted LRM evaluations\nmodeled after psycholinguistic experiments is be-\ning used in an increasing number of recent studies,\nalbeit mainly in the domains of syntax and lexical\nsemantics (Gulordava et al., 2018; Linzen et al.,\n2016; Marvin and Linzen, 2018; Wilcox et al.,\n2018; Chowdhury and Zamparelli, 2018; Futrell\net al., 2019; Nair et al., 2020; Abdou et al., 2020;\nEttinger, 2020).\nWe move on to describing our dataset, procedure\nand results.\n4 Method\nWe perform two types of tests using the dataset that\nwe produce for this purpose. One experiment is\ndone with BERT, the other one with GPT-2. Both\nexperiments are performed in a zero-shot setting –\nusing the pre-trained models without fine-tuning.\nThe goal of these experiments is to test the contrasts\nbetween types of sentences described in Table 1.\nWe will do this by comparing the relevant pairs of\ncontexts along LRM-derived metrics that are meant\nto capture grammaticality / acceptability.\nFirst, we describe the dataset; then we explain\nthe experiment procedure for BERT and GPT-2;\nfinally, we report and discuss the results.\n4.1 The ANY dataset2\nOur dataset consists of two parts: one with natural\nand one with synthetic data.\n4.1.1 Natural data\nWe scraped the Gutenberg Project and a subset of\nEnglish Wikipedia to obtain the list of sentences\nthat contain any. Next, using a combination of\nheuristics3, we filtered the result with regular ex-\npressions to produce two sets of sentences (the\nsecond set underwent additional manual filtering):\n• 3844 sentences with sentential negation and a\nplural object with any to the right to the verb;\n• 330 sentences with nobody / no one as subject\nand a plural object with any to the right.\n2The data are available at https://github.com/\naltsoph/Transformers-in-the-loop\n3The script that can be used to reproduce the filtering\nprocedure is available in the project repository, see fn. 2.\nThe first set was modified to substitute the negated\nverb by its non-negated version, so we contrast\n3844 sentences with negation and 3844 affirmative\nones (NEG vs. AFF). In the second dataset, we\nsubstituted nobody for somebody and no one for\nsomeone, to check the SOME vs. NO contrast.\n4.1.2 Synthetic data\nWe used the following procedure. First, we auto-\nmatically identified the set of verbs and nouns to\nbuild our items from. To do so, we started with\nbert-base-uncased4 vocabulary. Taking its\nnon-subword lexical tokens is an easy way to get\na list of simple and common words. We ran this\nlist through a SpaCy POS tagger5. Further, we lem-\nmatized the result using pattern6 and dropped\nduplicates. Then, we filtered out modal verbs, sin-\ngularia tantum nouns and some visible lemmatiza-\ntion mistakes. Finally, we filtered out non-transitive\nverbs to give the dataset a bit of a higher baseline\nof grammaticality.7\nWe kept top 100 nouns and top 100 verbs from\nthe resulting lists – these are the lexical entries we\nwill deal with. Then, we generated sentences with\nthese words, using the following pattern:\nA(n) nounx verb.PST.SG a(n) nouny8\nFor this, we iterate over the 100 nouns in the subject\nand the object positions (excluding cases where the\nsame noun appears in both positions) and over the\n100 verbs. The procedure gave us 990k sentences\nlike these:\n(7) a. A girl crossed a road.\nb. A community hosted a game.\nc. A record put an air.\nSome are more natural, make more sense and ad-\nhere to the verb’s selectional restrictions better than\nthe others. To control for this, we ran the sentences\nthrough GPT-29 and assigned perplexity to all can-\ndidates. Then we took the bottom 20k of the sen-\ntences (≈ the most ‘natural’ ones) as the core of\nour synthetic dataset.\n4https://huggingface.co/\nbert-base-uncased\n5https://github.com/explosion/\nspacy-models\n6https://pypi.org/project/Pattern/\n7Our procedure was equivalent to that in github.com/\nMirith/Verb-categorizer\n8We use the singular indefinite object for this part of the\nprocedure to avoid idiomatic verb phrases (change hands, join\nforces) at the top of the list.\n9https://huggingface.co/gpt2\nWe tried to approximate the ‘naturalness’ of ex-\namples by a combination of measures. We rely\non insights from different models (GPT-2, BERT,\ncorpus-based statistical insights into verb transitiv-\nity) on different stages of the dataset creation. Still,\nsome sentences sound intuitively ‘weird’. We do\nnot see this as a problem though – we will not rely\ndirectly on the naturalness of individual examples,\nrather we will measure the effect of the NPI across\nthe dataset (as is common practice when working\nwith synthetic data – see, for example, Geiger et al.\n2020, 2021). The amount of the examples will\nallow us to generalize across varying parts of the\nsentences to make sure that the results can be at-\ntributed to the parts we are interested in: items\nresponsible for the polarity of the sentence. The\nquantity of test items is crucial for reproducing psy-\ncholinguistic experiments on LRMs – while in the\nformer one sentence gives rise to a number of ob-\nservations when different human participants make\na judgment, in the latter one test sentence gives one\nobservation only.\nWith this in mind, we use the 20k sentences\nproduced by the previous steps to build the parts\nof our synthetic dataset. Each of the sentences\nhas a pluralized (not singular anymore!) object in\ncombination with any: any roads. The subject\ntype varies in different datasets comprising our\nsynthetic data. Here is what we end up with:\n• 12 datasets 20k sentences each:\nAFF (8-a); NEG (8-b); SOME (8-c); NO;\nMANY ; FEW ; MORE THAN 5; FEWER THAN\n5; AT LEAST 5; AT MOST 5; EXACTLY 5;\nBETWEEN 5 AND 10;\n• 2 datasets 8230 sentences each:\nSOMEBODY / SOMEONE / SOMETHING (8-d);\nNOBODY / NO ONE / NOTHING (replacing the\nwhole subject, duplicates deleted)\n(8) a. A girl crossed any roads.\nb. A girl didn’t cross any roads.\nc. Some girls crossed any roads.\nd. Somebody crossed any roads.\nOverall, sentences in all parts of our dataset vary\nin the type of context it instantiates (simple affir-\nmative, negation, different quantifiers) – but all\nsentences contain any in the object position in com-\nbination with a plural noun.\nThe next two subsections explain the metrics de-\nrived from the two model we study, stemming from\nthe differences in their architecture and training\nobjectives.\n4.2 BERT: Cloze Test\nThe Cloze Test on BERT is very similar to that\ndescribed in (Warstadt et al., 2019). In each of\nthe sentences in the dataset, we mask any and ask\nBERT for predictions for the masked position:\n[CLS] Few girls crossed [MASK] roads . [SEP]\nWe extract the probability that BERT assigns to\nany in the masked position, as well as the rank of\nany in BERT vocabulary sorted by the probability\nin the masked position.\nFurther, we compare these values between con-\nditions (= different types of contexts). The compar-\nison between a pair of conditions will be expressed\nas the percentage of sentences in our dataset where\nany got a higher probability in the first condition\ncompared to the probability of any in the corre-\nsponding sentence in the second condition. The\nsame for the rank of any instead of probability. For\nexample, ⟨AFF: NEG ⟩ : 0.12% reads as: in 0.12%\nof the dataset, any got a higher probability (or a\nhigher rank) in an affirmative sentence compared\nto the corresponding sentence with negation. In-\ntuitively: that most of the time, a sentence with\nnegation makes a better environment for any than\nthe minimally different affirmative sentence.\n4.3 GPT-2: Perplexity difference\nIn this test, for each sentence in the dataset, we\ncalculate perplexity of this sentence(9-a) according\nto the GPT-2 model – and perplexity of that same\nsentence with any deleted (9-b):\n(9) a. Few girls crossed any roads.\nb. Few girls crossed roads.\nWe take the difference between these perplexity\nvalues normalized by the number of tokens as our\nmeasure of how much the presence of any affects\nthe ‘naturalness’ of each particular sentence.\nAs before, we compare these values for differ-\nent conditions. For example, ⟨AFF: NEG ⟩ : 0.25%\nreads as: in 0.25% of sentences, the presence of\nany leads to a smaller increase in perplexity for the\naffirmative sentence, compared to the analogous\nnegative sentence. That is, most of the time the\npresence of any worsens affirmative sentences a lot,\nwhile the corresponding negative one – less so.\nThis is the closest possible LM analogue of the\nacceptability judgment experiments like (Alexan-\n(a) BERT-prob comparison across conditions\n (b) GPT-PPL-diff comparison across conditions\nFigure 1: LRM experiment results\ndropoulou et al., 2020), which measure the differ-\nences between acceptability scores with and with-\nout any for different types of contexts.\n5 Results of model evaluation\nWe will discuss results from BERT and GPT-2 to-\ngether, because they mostly agree.\nOne general result that allows us to limit our at-\ntention to one of the two BERT metrics is that\nBERT rank and BERT probability produce the\nsame order on all condition pairs of interest ex-\ncept for one (⟨AT MOST , AT LEAST ⟩) and we will\nonly discuss BERT probabilities in this section.\nThe 20k synthetic data results are summarized\nin Fig. 1. The conditions in the 20k results are\nsorted for readability. 8k synthetic data results:\n⟨NO-, SOME -⟩: 99.76% (BERT-prob); 99.56%\n(GPT-PPL-diff).\nIn short, all predictions based on psycholin-\nguistic evidence discussed in section 2 (Table 1)\nare confirmed by our LRM data.\nAs a sanity check, we compare these results with\nthe results of the same procedure on our natural\ndataset, and they are very similar: ⟨NEG , AFF⟩:\n97.21% (BERT-prob), 97.17% (GPT-PPL-diff);\n⟨NO-, SOME -⟩: 98.29% (BERT-prob), 96.98%\n(GPT-PPL-diff).\nThe take home message from these results is that\nLRMs can tell between negative and positive\npolarity, as well as between different types of\ncontexts by their monotonicity, as measured by\nNPI acceptability. Moreover, what is encoded is\na subjective version of the relevant property, sim-\nilar to what is reflected in graded non-categorical\njudgments seen in psycholinguistic experiments.\nEstablishing this, first of all, helps us make more\nsense of the metrics derived from such models and\nhelps draw a more accurate line between noise\nand meaningful output. Second, it encourages a\ncloser tie between experiments with humans and\nwith LRMs: LRMs encode a snapshot of numerous\nsubjective linguistic intuitions, and maybe we can\nuse LRMs to get indirect access to speakers’ shared\nintuitions as a source of new theoretically relevant\nlinguistic generalisations. The next section is a\npilot attempt in this direction. We establish a new\ngeneralization looking at LRM data – and then\nconfirm it in a psycholinguistic experiment.\n6 Next step: Cardinality dependency\nFor the conditions which involve numerals we left\none parameter unexplored so far, namely, the nu-\nmeral itself. In this section, we look at the depen-\ndency between NPI acceptability and the numeral.\nThere is no experimental data on this. Theoret-\nical literature tentatively suggests that the higher\nthe numeral, the less acceptable an NPI in its scope\n(Crniˇc, 2014):\n(10) Exactly two of the boxes contain anything\n(11) ??Exactly 98 of the boxes contain anything\nHowever, the judgments are subtle and theoretical\ndiscussion still waits for an empirical basis. Let us\nlook at our conditions with numerals (apart from\nBETWEEN – we set it aside as too complicated). For\neach of the conditions, we keep everything constant\napart from the numeral and check the effect the\nnumeral has on NPI acceptability.\n6.1 As seen in LRMs\nWe looked at numerals with these numeric values:\n[2−20, 30, 40, 50, 60, 70, 80, 90]. As before, we\nmade pair-wise comparisons between sentences in\nour synthetic dataset that differ only in the numeral\nit contains. The measures are the same as before.\nBoth models show an upward trend: the higher\nthe numeral, the worse the context becomes forany.\nThis tendency is shown on Fig. 2.\nThe lines show comparison between sentence\npairs in which the second one has a numeral higher\nthan the one in the first sentence by n, where n is\nplotted on thex axis (so, 10 on the x axis comprises\nall pairs that differ by 10 – ⟨2, 12⟩,⟨3, 13⟩...). On y,\nwe show the percentage of pairs in which the first\nsentence showed higher probability of any than the\nsecond one.\nFigure 2: The effect of numeral on any.\nThe effect of the numeral on the NPI acceptabil-\nity can be sometimes quite strong: to the point\nof flipping the ‘better NPI licenser’ relation in a\npair of contexts. For example, this is the case for\nAT LEAST and MORE THAN in BERT. They have\nthe same logical monotonicity profile (both UE).\nHowever, we can find a pair of numerals such that\nflipping them orders the resulting contexts differ-\nently:\nAT LEAST 2 > MORE THAN 70: 94%\nMORE THAN 2 > AT LEAST 70: 68%\nLet us check the effect of numeral on humans, as\nwell as a licensing flip due to the numeral.\n6.2 In humans\nFor the ease of comparison between our LRM ex-\nperiment data in the previous section and the ex-\nperiment on human participants, we formulate the\nlatter as a forced-choice task.\nThe participants saw pairs of sentences and were\ninstructed to pick the one that is more grammatical.\nThe study has a 2x2 design with these factors:\n• NUMERAL : five vs. seventy\n• QUANTIFIER : at least vs. more than\nThis gives six forced-choice test conditions:\nat least five vs. at least seventy\nat least five vs. more than five\nat least five vs. more than seventy\nat least seventy vs. more than five\nat least seventy vs. more than seventy\nmore than five vs. more than seventy\nThese prefixes were used to generate pairs of sen-\ntences using patterns from the 20k synthetic dataset.\nWe randomly selected 50 out of the 20k patterns,\nwhich results in 2500 pattern pairs. With 6 test\nconditions, this amounts to 15k unique test items.\nWe used Toloka to recruit self-reported native\nspeakers of English for this experiment. 10 They\nwere allowed to complete the full task after they\npassed a test with 10 control items with 7 or more\ncorrectly identified grammatical sentences.\nIn the main part of the task, each participant saw\n38 pairs of sentences: 22 were filler/control items\nand 16 test items. All participants saw the same\nfiller/control items (random order), test items were\ntaken from the pool of 15k test items in random\norder and evaluated with no overlap.\nIn total, 968 participants were recruited. We\nfiltered out the data from those who gave wrong\nanswers to more than 30% of the filter/control items\nin the main part of the task. We were left with 656\nparticipants (= 10496 test items; more than a 2/3\nof our pool of test items). Fig. 3 shows the results\nof the experiment. We used the binomial test to\nanalyze the data. The boxes in the plot show the\n95% confidence interval.\nResult #1: The effect of the numeral is confirmed\nboth within and across the two types of contexts\n(lines 1, 6, 9 and 10 in Fig. 3). Result #2: AT\nLEAST and MORE THAN are not ordered with re-\nspect to each other (lines 7 and 8). It is possible\nto find a particular numeral where the difference\nreaches significance (line 2), but overall there is\nno clear order. Result #3: Our data do not show a\nstatistically significant flip between contexts with\ndifferent numeral values. Even though one side of\nthe flip is there (line 3), the flip of this pair did not\nreach significance (line 5).\n10https://toloka.ai/ready-to-go/\nFigure 3: Human judgments of any-acceptability\nConclusion: The results are generally in line with\nthe trend observed in section 6: the higher the nu-\nmeral, the worse the context gets for an NPI. This\nis the first experimental confirmation of this effect,\nto the best of our knowledge. It is noteworthy that\nwe first found it via LRM – and then confirmed it\nwith human participants.\nA more specific result of this effect – what we\ncall a ‘flip’ – is seen in our data as a tendency, but\nthe effect did not reach significance. It could be an\nLRM artifact – or the lack of it could be an artifact\nof our experiment. A different choice of numerals\nor a higher number of participants could sharpen\nthese results. We leave this for future work.\n7 Discussion and outlook\nOur experiments provide solid support for an ap-\nproach under which LRM performance is com-\npared directly to psycholinguistic data rather than\nto predictions of a linguistic theory. This opens\nup prospects for research that will result in a more\nempirically grounded picture of where the limits of\nLRM abilities lie.\nOur results tell us something new about LRMs\nbut also suggest that LRMs can be included in the\nexperimental loop of theoretical semantics along-\nside with traditional experiments. To pilot this idea,\nwe conducted an experiment on the effect of the\nnumeral on NPI acceptability. We confirmed our\nLRM findings in a parallel psycholinguistic study.\nIn this paper, we only explore the connection\nbetween behavioral experiments and LRM-derived\nmetrics. What about online measures in psycholin-\nguistic studies? Can we find a usable analogue to,\nfor example, eye-tracking or reaction times in self-\npaced reading studies – that is, studies that tell us\nwhich parts of input are important in processing?\nOne obvious LRM-based candidate is attention.\nWe took a preliminary look at BERT attention\ndistribution in sentences with any in an attempt to\nidentify the attention head that contributes most to\nmonotonicity-via-NPIs (see V oita et al. 2019 for\na discussion of attention head specialization). To\nfactor out linear position, we focused on the natural\npart of our dataset. We took the sentences that con-\ntained both a quantifier with a clear monotonicity\nprofile (somebody, nobody, someone etc.) and any;\ncalculated attention from any to the quantifier for\nevery layer and every attention head and averaged\nit across sentences. Then we sorted the results and\nwent through the top of the resulting list.\nWe found that the attention head (6,2) of\nbert-base-uncased model – 6th layer, at-\ntention head 2 – seems to specialize in precisely\nwhat we are looking for. Saliency maps below\nshow that in a variety of contexts beyond the\nones we checked for the purposes of this paper,\nmonotonicity-affecting items are highlighted – but-\ntressing the hypothesis that monotonicity is impor-\ntant for NPI licensing ( without, do-support in a\nquestion, if, lexical negation):\n[CLS] it felt odd without any wards on it . [SEP]\n[CLS] do you have any brothers or sisters ? [SEP]\n[CLS] if there ’ d been any babies present , he ’\nd have been un ##sto ##ppa ##ble . [SEP]\n[CLS] we are unable to identify any others who knew\nof the scheme at the time it was being considered .\n[SEP]\nAdditionally, this attention head reflects the role of\nthe numeral in NPI licensing that we established\nin section 6: in all contexts with numerals that\nwe looked at, a lot of attention goes from any to\nboth the quantifier (say, exactly) and the numeral\nthat comes with it. Moreover, the higher the nu-\nmeral, the more attention goes to it, compared to\nthe amount of attention that goes to the quantifier:\n[CLS] exactly two games told any stories . [SEP]\n[CLS] exactly ninety games told any stories . [SEP]\nMore work is needed to verify and interpret these\npatterns systematically and compare them to other\nattribution measures and to online metrics in psy-\ncholinguistic studies.\nAcknowledgements\nWe thank the anonymous ARR reviewers; the audi-\nence and organizers of the CNRS Seminar on the\nInteractions between Formal and Computational\nLinguistics; Toloka team for the help with the hu-\nman assessment study. We also thank Alexandre\nCremers, Ekaterina Garmash, Borislav Kozlovskii,\nRick Nouwen, and Denis Paperno for the discus-\nsions of our ideas and earlier versions of the paper.\nReferences\nMostafa Abdou, Vinit Ravishankar, Maria Barrett,\nYonatan Belinkov, Desmond Elliott, and Anders Sø-\ngaard. 2020. The sensitivity of language models\nand humans to Winograd schema perturbations. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 7590–\n7604.\nStavroula Alexandropoulou, Lisa Bylinina, and Rick\nNouwen. 2020. Is there ‘any’ licensing in non-DE\ncontexts? An experimental study. In Proceedings of\nSinn und Bedeutung, volume 24, pages 35–47.\nChris Barker. 2018. Negative polarity as scope marking.\nLinguistics and philosophy, 41(5):483–510.\nMarco Baroni. 2021. On the proper role of\nlinguistically-oriented deep net analysis in linguistic\ntheorizing. arXiv preprint arXiv:2106.08694.\nEmmanuel Chemla, Vincent Homer, and Daniel Roth-\nschild. 2011. Modularity and intuitions in formal\nsemantics: The case of polarity items. Linguistics\nand Philosophy, 34(6):537–570.\nShammur Absar Chowdhury and Roberto Zamparelli.\n2018. RNN simulations of grammaticality judgments\non long-distance dependencies. In Proceedings of\nthe 27th international conference on computational\nlinguistics, pages 133–144.\nLuka Crniˇc. 2014. Non-monotonicity in NPI licensing.\nNatural Language Semantics, 22(2):169–217.\nMilica Deni´c, Vincent Homer, Daniel Rothschild, and\nEmmanuel Chemla. 2020. The influence of polarity\nitems on inferential judgments. Submitted.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL-HLT.\nAllyson Ettinger. 2020. What BERT is not: Lessons\nfrom a new suite of psycholinguistic diagnostics for\nlanguage models. volume 8, pages 34–48. MIT\nPress.\nGilles Fauconnier. 1975. Polarity and the scale princi-\nple. In Proceedings of Chicago Linguistc Society 11,\npages 188–99.\nRichard Futrell, Ethan Wilcox, Takashi Morita, Peng\nQian, Miguel Ballesteros, and Roger Levy. 2019.\nNeural language models as psycholinguistic subjects:\nRepresentations of syntactic state. In Proceedings of\nthe 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 32–42.\nAtticus Geiger, Hanson Lu, Thomas Icard, and Christo-\npher Potts. 2021. Causal abstractions of neural net-\nworks. arXiv preprint arXiv:2106.02997.\nAtticus Geiger, Kyle Richardson, and Christopher Potts.\n2020. Neural natural language inference models par-\ntially embed theories of lexical entailment and nega-\ntion. In Proceedings of the Third BlackboxNLP Work-\nshop on Analyzing and Interpreting Neural Networks\nfor NLP, pages 163–173.\nBart Geurts. 2003. Reasoning with quantifiers. Cogni-\ntion, 86(3):223–251.\nAnastasia Giannakidou. 1998. Polarity sensitivity as\n(non) veridical dependency, volume 23. John Ben-\njamins Publishing.\nYoav Goldberg. 2019. Assessing BERT’s syntactic abil-\nities. arXiv preprint arXiv:1901.05287.\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nTal Linzen, and Marco Baroni. 2018. Colorless green\nrecurrent networks dream hierarchically. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1\n(Long Papers), pages 1195–1205.\nJennifer Hu, Jon Gauthier, Peng Qian, Ethan Wilcox,\nand Roger Levy. 2020. A systematic assessment\nof syntactic generalization in neural language mod-\nels. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n1725–1744.\nJaap Jumelet, Milica Denic, Jakub Szymanik, Dieuwke\nHupkes, and Shane Steinert-Threlkeld. 2021. Lan-\nguage models use monotonicity to assess NPI licens-\ning. CoRR, abs/2105.13818.\nJaap Jumelet and Dieuwke Hupkes. 2018. Do lan-\nguage models understand anything? on the ability\nof lstms to understand negative polarity items. In\nBlackboxNLP@ EMNLP.\nWilliam A Ladusaw. 1979. Polarity sensitivity as in-\nherent scope relations . Ph.D. thesis, Austin, TX:\nUniversity of Texas at Austin.\nTal Linzen and Marco Baroni. 2021. Syntactic structure\nfrom deep learning. Annual Review of Linguistics,\n7:195–212.\nTal Linzen, Emmanuel Dupoux, and Yoav Goldberg.\n2016. Assessing the ability of LSTMs to learn syntax-\nsensitive dependencies. In Transactions of the As-\nsociation for Computational Linguistics, volume 4,\npages 521–535. MIT Press.\nRebecca Marvin and Tal Linzen. 2018. Targeted syn-\ntactic evaluation of language models. In Proceedings\nof the 2018 Conference on Empirical Methods in\nNatural Language Processing, pages 1192–1202.\nYaron McNabb, Stavroula Alexandropoulou, Do-\nminique Blok, Sofia Bimpikou, and Rick Nouwen.\n2016. The likelihood of upper-bound construals\namong numeral modifiers. In Proceedings of Sinn\nund Bedeutung, volume 20, pages 497–514.\nSathvik Nair, Mahesh Srinivasan, and Stephan Mey-\nlan. 2020. Contextualized word embeddings encode\naspects of human-like word sense knowledge. In Pro-\nceedings of the Workshop on the Cognitive Aspects\nof the Lexicon, pages 129–141.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nAnthony J Sanford, Eugene J Dawydiak, and Linda M\nMoxey. 2007. A unified account of quantifer per-\nspective effects in discourse. Discourse Processes,\n44(1):1–32.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. oLMpics-on what language\nmodel pre-training captures. In Transactions of the\nAssociation for Computational Linguistics, volume 8,\npages 743–758. MIT Press.\nElena V oita, David Talbot, Fedor Moiseev, Rico Sen-\nnrich, and Ivan Titov. 2019. Analyzing multi-head\nself-attention: Specialized heads do the heavy lift-\ning, the rest can be pruned. In Proceedings of the\n57th Annual Meeting of the Association for Computa-\ntional Linguistics, pages 5797–5808, Florence, Italy.\nAssociation for Computational Linguistics.\nAlex Warstadt, Yu Cao, Ioana Grosu, Wei Peng, Ha-\ngen Blix, Yining Nie, Anna Alsop, Shikha Bordia,\nHaokun Liu, Alicia Parrish, et al. 2019. Investigating\nbert’s knowledge of language: Five analysis methods\nwith npis. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n2877–2887.\nLucas Weber, Jaap Jumelet, Elia Bruni, and Dieuwke\nHupkes. 2021. Language modelling as a multi-task\nproblem. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Compu-\ntational Linguistics: Main Volume, pages 2049–2060,\nOnline. Association for Computational Linguistics.\nEthan Wilcox, Roger Levy, Takashi Morita, and Richard\nFutrell. 2018. What do RNN language models learn\nabout filler-gap dependencies? In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP , pages\n211–221.\nHitomi Yanaka, Koji Mineshima, Daisuke Bekki, Ken-\ntaro Inui, Satoshi Sekine, Lasha Abzianidze, and\nJohan Bos. 2019a. Can neural networks understand\nmonotonicity reasoning? In Proceedings of the 2019\nACL Workshop BlackboxNLP: Analyzing and Inter-\npreting Neural Networks for NLP, pages 31–40.\nHitomi Yanaka, Koji Mineshima, Daisuke Bekki, Ken-\ntaro Inui, Satoshi Sekine, Lasha Abzianidze, and\nJohan Bos. 2019b. HELP: A dataset for identify-\ning shortcomings of neural models in monotonic-\nity reasoning. In Proceedings of the Eighth Joint\nConference on Lexical and Computational Semantics\n(*SEM 2019), pages 250–255.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7194846868515015
    },
    {
      "name": "Polarity (international relations)",
      "score": 0.6598794460296631
    },
    {
      "name": "Natural language processing",
      "score": 0.6166366934776306
    },
    {
      "name": "Transformer",
      "score": 0.6026634573936462
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5571587681770325
    },
    {
      "name": "Language model",
      "score": 0.5477858781814575
    },
    {
      "name": "Natural language",
      "score": 0.5244048833847046
    },
    {
      "name": "Grammar",
      "score": 0.46887969970703125
    },
    {
      "name": "Representation (politics)",
      "score": 0.44477391242980957
    },
    {
      "name": "Computational linguistics",
      "score": 0.43185630440711975
    },
    {
      "name": "Linguistics",
      "score": 0.39584052562713623
    },
    {
      "name": "Engineering",
      "score": 0.10904717445373535
    },
    {
      "name": "Chemistry",
      "score": 0.08843213319778442
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Cell",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I55106644",
      "name": "Amsterdam University of Applied Sciences",
      "country": "NL"
    },
    {
      "id": "https://openalex.org/I58957048",
      "name": "Yandex (Russia)",
      "country": "RU"
    }
  ],
  "cited_by": 3
}