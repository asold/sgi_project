{
  "title": "Evaluating Large Language Models for Drafting Emergency Department Discharge Summaries",
  "url": "https://openalex.org/W4393942046",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2995843509",
      "name": "Christopher Y. K. Williams",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2786617309",
      "name": "Jaskaran Bains",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2109605985",
      "name": "Tianyu Tang",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2114913489",
      "name": "Kishan Patel",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2945272814",
      "name": "Alexa N. Lucas",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2671097329",
      "name": "Fiona Chen",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A4316189112",
      "name": "Brenda Y. Miao",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A284454978",
      "name": "Atul J. Butte",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2696559489",
      "name": "Aaron E. Kornblith",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2995843509",
      "name": "Christopher Y. K. Williams",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2786617309",
      "name": "Jaskaran Bains",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2109605985",
      "name": "Tianyu Tang",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2114913489",
      "name": "Kishan Patel",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2945272814",
      "name": "Alexa N. Lucas",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A2671097329",
      "name": "Fiona Chen",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A4316189112",
      "name": "Brenda Y. Miao",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A284454978",
      "name": "Atul J. Butte",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2696559489",
      "name": "Aaron E. Kornblith",
      "affiliations": [
        null,
        "University of California, San Francisco"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2467236557",
    "https://openalex.org/W4281989098",
    "https://openalex.org/W2984982467",
    "https://openalex.org/W2890157215",
    "https://openalex.org/W2515682654",
    "https://openalex.org/W3005890082",
    "https://openalex.org/W4387393114",
    "https://openalex.org/W3023680935",
    "https://openalex.org/W3127725882",
    "https://openalex.org/W2132643104",
    "https://openalex.org/W2751958615",
    "https://openalex.org/W2770750122",
    "https://openalex.org/W1514648103",
    "https://openalex.org/W4389178822",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W4386272371",
    "https://openalex.org/W4391995913",
    "https://openalex.org/W4383223222",
    "https://openalex.org/W4385794417",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4389046946",
    "https://openalex.org/W2139056371",
    "https://openalex.org/W4392800721",
    "https://openalex.org/W4389917881"
  ],
  "abstract": "Abstract Importance Large language models (LLMs) possess a range of capabilities which may be applied to the clinical domain, including text summarization. As ambient artificial intelligence scribes and other LLM-based tools begin to be deployed within healthcare settings, rigorous evaluations of the accuracy of these technologies are urgently needed. Objective To investigate the performance of GPT-4 and GPT-3.5-turbo in generating Emergency Department (ED) discharge summaries and evaluate the prevalence and type of errors across each section of the discharge summary. Design Cross-sectional study. Setting University of California, San Francisco ED. Participants We identified all adult ED visits from 2012 to 2023 with an ED clinician note. We randomly selected a sample of 100 ED visits for GPT-summarization. Exposure We investigate the potential of two state-of-the-art LLMs, GPT-4 and GPT-3.5-turbo, to summarize the full ED clinician note into a discharge summary. Main Outcomes and Measures GPT-3.5-turbo and GPT-4-generated discharge summaries were evaluated by two independent Emergency Medicine physician reviewers across three evaluation criteria: 1) Inaccuracy of GPT-summarized information; 2) Hallucination of information; 3) Omission of relevant clinical information. On identifying each error, reviewers were additionally asked to provide a brief explanation for their reasoning, which was manually classified into subgroups of errors. Results From 202,059 eligible ED visits, we randomly sampled 100 for GPT-generated summarization and then expert-driven evaluation. In total, 33% of summaries generated by GPT-4 and 10% of those generated by GPT-3.5-turbo were entirely error-free across all evaluated domains. Summaries generated by GPT-4 were mostly accurate, with inaccuracies found in only 10% of cases, however, 42% of the summaries exhibited hallucinations and 47% omitted clinically relevant information. Inaccuracies and hallucinations were most commonly found in the Plan sections of GPT-generated summaries, while clinical omissions were concentrated in text describing patients’ Physical Examination findings or History of Presenting Complaint. Conclusions and Relevance In this cross-sectional study of 100 ED encounters, we found that LLMs could generate accurate discharge summaries, but were liable to hallucination and omission of clinically relevant information. A comprehensive understanding of the location and type of errors found in GPT-generated clinical text is important to facilitate clinician review of such content and prevent patient harm.",
  "full_text": " 1 \n 2 \n 3 \n 4 \n 5 \nEvaluating Large Language Models for Drafting 6 \nEmergency Department Discharge Summaries 7 \n 8 \nChristopher Y.K. Williams1*, Jaskaran Bains2, Tianyu Tang2, Kishan Patel2, Alexa N. Lucas2, 9 \nFiona Chen2, Brenda Y. Miao1, Atul J. Butte1, Aaron E. Kornblith1,2 10 \n 11 \n 12 \n 13 \n 14 \n1Bakar Computational Health Sciences Institute; University of California, San Francisco 15 \n2Department of Emergency Medicine; University of California, San Francisco 16 \n 17 \n 18 \n 19 \n 20 \n*Corresponding author: 21 \nDr Christopher Y.K. Williams 22 \nPostdoctoral Scholar; Bakar Computational Health Sciences Institute, UCSF 23 \ncykw2@doctors.org.uk   24 \n 25 \n 26 \n 27 \n 28 \nWord count: 2951 words  29 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract 30 \nImportance: Large language models (LLMs) possess a range of capabilities which may be 31 \napplied to the clinical domain, including text summarization. As ambient artificial intelligence 32 \nscribes and other LLM-based tools begin to be deployed within healthcare settings, rigorous 33 \nevaluations of the accuracy of these technologies are urgently needed. 34 \nObjective: To investigate the performance of GPT-4 and GPT-3.5-turbo in generating 35 \nEmergency Department (ED) discharge summaries and evaluate the prevalence and type of 36 \nerrors across each section of the discharge summary. 37 \nDesign: Cross-sectional study. 38 \nSetting: University of California, San Francisco ED. 39 \nParticipants: We identified all adult ED visits from 2012 to 2023 with an ED clinician note. We 40 \nrandomly selected a sample of 100 ED visits for GPT-summarization.  41 \nExposure: We investigate the potential of two state-of-the-art LLMs, GPT-4 and GPT-3.5-turbo, 42 \nto summarize the full ED clinician note into a discharge summary. 43 \nMain Outcomes and Measures: GPT-3.5-turbo and GPT-4-generated discharge summaries 44 \nwere evaluated by two independent Emergency Medicine physician reviewers across three 45 \nevaluation criteria: 1) Inaccuracy of GPT-summarized information; 2) Hallucination of 46 \ninformation; 3) Omission of relevant clinical information. On identifying each error, reviewers 47 \nwere additionally asked to provide a brief explanation for their reasoning, which was manually 48 \nclassified into subgroups of errors. 49 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nResults: From 202,059 eligible ED visits, we randomly sampled 100 for GPT-generated 50 \nsummarization and then expert-driven evaluation. In total, 33% of summaries generated by GPT-51 \n4 and 10% of those generated by GPT-3.5-turbo were entirely error-free across all evaluated 52 \ndomains. Summaries generated by GPT-4 were mostly accurate, with inaccuracies found in only 53 \n10% of cases, however, 42% of the summaries exhibited hallucinations and 47% omitted 54 \nclinically relevant information. Inaccuracies and hallucinations were most commonly found in 55 \nthe Plan sections of GPT-generated summaries, while clinical omissions were concentrated in 56 \ntext describing patients’ Physical Examination findings or History of Presenting Complaint. 57 \nConclusions and Relevance: In this cross-sectional study of 100 ED encounters, we found that 58 \nLLMs could generate accurate discharge summaries, but were liable to hallucination and 59 \nomission of clinically relevant information. A comprehensive understanding of the location and 60 \ntype of errors found in GPT-generated clinical text is important to facilitate clinician review of 61 \nsuch content and prevent patient harm.  62 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nIntroduction 63 \nClinical documentation is an essential part of high-quality patient care. 1,2 However, in recent 64 \nyears there has been an increase in the complexity of clinical documentation as a result of the 65 \ntransition from paper-based to electronic health records (EHRs). 3 This has had downstream 66 \neffects on the amount of time physicians spend on the EHR, with recent studies suggesting that 67 \nevery hour of direct clinical time spent with patients is associated with 2 extra hours of EHR 68 \ndocumentation.4,5 This concerning increase in EHR burden is a significant contributing factor to 69 \nthe rising prevalence of physician burnout, which may lead to a reduction in the overall quality 70 \nof patient care.6–9 71 \n 72 \nA foundational element of clinical documentation is the patient discharge or encounter summary, 73 \ncreated following both Emergency Department (ED) visits and inpatient hospital admissions. 74 \nDischarge summaries serve as a critical method of patient information transfer and provide 75 \ninstructions for the ongoing management of patients’ illness.10–12 However, the process of 76 \nwriting discharge summaries is time-consuming and, consequently, these summaries are often 77 \nnot completed in a timely manner or finished at all.12,13 This is problematic given that the 78 \ntimeliness and availability of discharge summaries is associated with patients’ readmission rates, 79 \nwith the absence of a discharge summary associated with a 79% increased rate of 7-day 80 \nreadmission and 37% increased rate of readmission within 28 days.13 The AHRQ identifies the 81 \nlack of adequate post-discharge summarization and communication as primary reasons for ED 82 \ndischarge failures.14 83 \n 84 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nThe recent introduction of large language models (LLMs) such as ChatGPT has led to renewed 85 \nfocus on the use of natural language processing (NLP) to improve both quality and efficiency in 86 \nhealthcare.15 LLMs possess a range of capabilities which may be applied to the clinical domain, 87 \none of which is text summarization. Previous reports have evaluated the potential use of LLMs in 88 \nsummarizing scientific literature, radiology reports, patient problem lists and doctor-patient 89 \nconversations, with varying success.16,17 However, there has been limited research on the ability 90 \nof LLMs to summarize information from a patient’s hospital encounter into a discharge 91 \nsummary.18 As ambient AI scribes and other LLM-based tools begin to be deployed within 92 \nhealthcare settings,19 rigorous evaluations of the accuracy of these technologies are urgently 93 \nneeded. 94 \n 95 \nIn this study, we investigate the performance of two state-of-the-art LLMs, GPT-4 and GPT-3.5-96 \nturbo, in generating ED discharge summaries and evaluate the prevalence and type of errors 97 \nacross each section of the discharge summary.  98 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nMethods 99 \nThe UCSF Information Commons contains deidentif ied structured clinical data as well as 100 \ndeidentified clinical text notes, with externally certified deidentification as previously 101 \ndescribed.20 The UCSF Institutional Review Board determined that this use of deidentified data 102 \nwithin the UCSF Information Commons is not human participants research and, therefore, was 103 \nexempt from further approval and informed consent. This study was completed according to a 104 \nprospectively developed protocol (Supplementary File 1). 105 \n 106 \nWe identified all adult patients discharged from the University of California, San Francisco 107 \n(UCSF) ED from 2012 to 2023 with an ED clinician note present within Information Commons 108 \n(Figure 1). If more than one Emergency Medicine (EM) clinician note was available for a 109 \nparticular ED visit, the earliest note was selected as subsequent notes were often attending 110 \nattestation notes. In the case of multiple notes with the same chart time, the longest note (by 111 \ncharacter count) was selected. Clinical notes were minimally preprocessed – only line breaks and 112 \nextra spaces were removed. Software packages incorporating a series of regular expressions were 113 \ncreated and used to examine the structure of notes, confirming the presence/absence of the 114 \nfollowing note headers: ‘Chief Complaint’ (274,983/278,629 notes); ‘Review of Systems’ 115 \n(263,219/278,629 notes); ‘Physical Exam’ (276,834/278,629 notes); ‘ED Course’ 116 \n(245,900/278,629 notes); and ‘Initial Assessment’ (139,838/278,629 notes). Notes which did not 117 \ncontain appropriate history, physical examination and assessment/plan sections were excluded. 118 \nEach note was tokenized using the OpenAI Tiktoken tokenizer.21 Notes containing ≥3500 tokens 119 \nwere excluded to allow sufficient tokens for the GPT-3.5-turbo API response to be completed 120 \nwithin the model’s 4096 token context window, which was the shortest context window of the 121 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nmodels used. Patients who were admitted to hospital from the ED were identified from the 122 \nstructured electronic health record and excluded so that only patients discharged from the ED 123 \nwere included in our cohort. 124 \n 125 \nNext, we randomly selected two n = 100 samples to be used as the development and test sets. All 126 \nprompt engineering and resident annotator training was conducted on the development  set, while 127 \nevaluation was conducted on the held-out test set. Using the secure, HIPAA-compliant, UCSF 128 \nVersa Application Programming Interface (API) on Microsoft Azure, we prompted both GPT-129 \n3.5-turbo (model = ‘gpt-3.5-turbo-0613’, role = ‘user’, temperature = 0; all other settings at 130 \ndefault values) and GPT-4 (model = ‘gpt-4-0613’, role = ‘user’, temperature = 0; all other 131 \nsettings at default values) to summarize the full ED clinician note into a discharge summary. The 132 \nfollowing prompt was used, followed by the corresponding note for each patient, denoted by 133 \ntriple quotation marks: “You are an Emergency Department physician. Below is the History and 134 \nPhysical Examination note for a patient presenting to the Emergency Department who was 135 \nsubsequently discharged. Write a discharge summary for the patient based on this note. Do not 136 \ninclude any additional information not present in the note. \\n\\n \"\"\" Note text \"\"\" ” 137 \n 138 \nThe GPT-3.5-turbo and GPT-4 generated discharge summaries were evaluated by two 139 \nindependent EM resident reviewers (from AL, FC, KB, KP, TT) in accordance with the protocol. 140 \nInitial rates of inte r-reviewer agreement were over 90% (Table S1). Disagreements were 141 \nresolved by consensus and, if required, by an attending EM physician reviewer (AK). We 142 \nselected three evaluation criteria for review: 1) Inaccuracy of GPT-summarized information; 2) 143 \nHallucination of information; 3) Omission of relevant clinical information. An inaccuracy refers 144 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nto information that is not factual and/or is contradicted by the original ED clinician note. 145 \nHallucination refers to the fabrication of information in the discharge summary that is not present 146 \nin the original ED clinician note. Omissions refer to information from the ED clinician note that 147 \nthe reviewer deemed relevant for inclusion in the discharge summary but was not included.  The 148 \nfollowing aspects of a patient’s ED visit were evaluated for the presence of inaccuracies, 149 \nhallucinations, and omissions: Presenting complaint; History of presenting complaint; Past 150 \nmedical history; Allergies/contraindications; Review of systems; Positive examination findings; 151 \nLaboratory test results; Radiological investigations; Plan; Other notable events during ED stay (if 152 \nany). On identifying each error, reviewers were additionally asked to provide a brief explanation 153 \nfor their reasoning, which was subsequently manually classified into subgroups of errors within 154 \neach of the above three evaluation criteria. 155 \n 156 \nStatistical analysis 157 \nFor both the GPT-3.5-turbo and GPT-4 discharge summaries, counts of each error (Inaccuracy, 158 \nHallucination or Omission) across each section (Presenting complaint; History of presenting 159 \ncomplaint; Past medical history; Allergies/contraindications; Review of systems; Positive 160 \nexamination findings; Laboratory test results; Radiological investigations; Plan; Other notable 161 \nevents during ED stay [if any]) relating to the ED visit were collated and reported in a 162 \ndescriptive analysis. The median word count with interquartile range (IQR) for the original EM 163 \nclinician notes, alongside both the GPT-4-generated and GPT-3.5-turbo generated summaries 164 \nwas calculated. To evaluate discharge summary readability, the average Flesch-Kincaid Reading 165 \nEase Score (FRES) and Flesch Kincaid Grade Level (FKGL) was calculated for each GPT 166 \nmodel. Median word counts and FRES/FKGL values were compared using the Mann-Whitney U 167 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \ntest against the null hypothesis that there is no significant difference between GPT-4-generated 168 \nand GPT-3.5-turbo-generated discharge summaries. Categorical variables were compared using 169 \nthe Chi-squared test. P < 0.05 was significant. Analyses were performed in Python and R.  170 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nResults 171 \nFrom 202,059 eligible ED visits with an EM clinician note, we randomly sampled 100 for GPT-172 \ngenerated summarization and then expert-driven evaluation (Figure 1; Table 1). The average 173 \nlength of the original EM clinician notes summarized by the GPT models was 802.5 words (IQR 174 \n643.5-1053.25) (Figure S1). GPT-4-generated discharge summaries (median word count = 235 175 \nwords, IQR 205-264) were shorter than those generated by GPT-3.5-turbo (median word count = 176 \n369.5 words, IQR 307.75-445) (Figure S2; Mann-Whitney U, p < 0.001). The average Flesch-177 \nKincaid Grade Level for GPT-4-generated summaries was lower (FKGL = 10.0, IQR 9.5-11.1) 178 \nthan for GPT-3.5-turbo-generated summaries (FKGL = 10.7, IQR 9.7-11.7) (Mann-Whitney U, p 179 \n= 0.02), indicating greater readability of GPT-4-generated discharge summaries. This was also 180 \nreflected in the Flesch Reading Ease Scores, with GPT-4 summaries (FRES = 48.6, IQR 41.0-181 \n52.0) having a higher score on average than GPT-3.5-turbo summaries (FRES = 46.7, IQR 39.7-182 \n49.5), though this did not meet statistical significance (Mann-Whitney U, p = 0.10). 183 \n 184 \nOverall, GPT-4-generated discharge summaries contained fewer errors than GPT-3.5-turbo-185 \ngenerated summaries across all three domains (Figure 2). In total, 33% of summaries generated 186 \nby GPT-4 and 10% of those generated by GPT-3.5-turbo were entirely error-free across all 187 \nevaluated domains. Summaries generated by GPT-4 were mostly accurate, with inaccuracies 188 \nfound in only 10% of cases. However, 42% of the summaries exhibited hallucinations and 47% 189 \nomitted clinically relevant information. This compares to 36% of GPT-3.5-turbo summaries 190 \ncontaining an inaccuracy, with 64% and 50% of the predecessor model’s summaries containing 191 \nhallucinations and clinical omissions, respectively. Initial inte r-reviewer agreement rates were 192 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n95.8%, 93.6% and 91.9% for inaccuracy, hallucination and omission errors, respectively, prior to 193 \nconsensus agreement (Table S1). 194 \n 195 \nError rate by domain and discharge summary section is shown in Figure 3. The few inaccuracy 196 \nerrors identified in GPT-4-generated discharge summaries predominantly occurred in the Plan 197 \nsection of the summary (n = 4). When comparing GPT-3.5-turbo and GPT-4 models, there was a 198 \nnotable improvement in the accuracy of reporting patients’ Past Medical History, in which 10% 199 \nof GPT-3.5-turbo summaries contained an error compared to only 1% of GPT-4 summaries. 200 \nMost hallucination errors, across both GPT-3.5-turbo and GPT-4 models, occurred in either the 201 \nPlan or Other sections of the summary, with GPT-4 recording 36% fewer hallucinations in these 202 \nsections than GPT-3.5-turbo. Omissions were most frequently present in the Physical 203 \nExamination section for both GPT-4 (20%) and GPT-3.5-turbo (18%) summaries, followed by 204 \nthe History of Presenting Complaint  section (10% of GPT-4 summaries vs 17% of GPT-3.5-205 \nturbo summaries).  206 \n 207 \nFinally, we manually categorized free-text reviewer comments detailing the subtype of each 208 \nerror (Table 2 & Figure S3). Among the GPT-4 summaries, inaccuracy errors included 209 \ninaccurate follow-up details (e.g., reviewer comment: “[the original note states that the] patient 210 \nhad follow-up with GI for colonoscopy.. already scheduled [whereas the GPT summary states 211 \nthe patient was advised to obtain this]”), inaccurately reporting the interim plan as the follow up 212 \nplan (e.g., reviewer comment: “the final plan is listed [by GPT-4] as ‘follow-up labs/psych 213 \nrecommendations’, but this was the sign-out plan – the final plan was actually: ‘safe for 214 \ndischarge’”) and inaccurate reporting of physical examination findings (e.g., reviewer comment: 215 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n“[the GPT summary] states HINTS exam was positive, but is in fact negative” ). The most 216 \ncommonly identified hallucination error subtype was hallucination of information in the note that 217 \nhad been redacted during the de-identification process (n = 15; e.g., reviewer comment: 218 \n“redacted portion [of original note] filled in [in GPT summary] as ‘headache’”). The next most 219 \ncommon hallucinations related to patients’ follow up, with GPT-4 either providing details of 220 \noutpatient specialty follow-up that had not been arranged (n = 11; e.g., reviewer comment: “[the 221 \nGPT summary] hallucinated follow-up with Rheumatology and Neurology, though [there is] no 222 \nmention of this in [the original] note” ), hallucinating ED return precautions (n = 7), and 223 \nhallucinating follow-up instructions (n = 3; e.g., reviewer comment: “no instructions to continue 224 \ncurrent meds or avoid morphine were provided in the original note” ). Meanwhile, examples of 225 \nthe most common omission errors include GPT-4 omitting certain positive physical examination 226 \nfindings (n = 13; e.g., “[GPT summary] omitted left sided laceration”  or “[GPT summary] 227 \nomitted murmur”),  imaging results (n = 8), details of patients’ management in ED (n = 7; mostly 228 \nrelating to specialty consults that had taken place) and symptom(s) reported (n = 7; e.g “[GPT 229 \nsummary] does not mention Tylenol overdose concern” ). The manually categorized reviewer 230 \ncomments for the GPT-3.5-turbo-generated summaries are shown in Supplementary File 2 231 \n(Table S2 & Figure S4).  232 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nDiscussion 233 \nIn this cross-sectional study of 100 ED encounters, we found that LLMs could generate accurate 234 \ndischarge summaries, but were liable to hallucination and omission of clinically relevant 235 \ninformation. Overall, GPT-4-generated summaries contained fewer errors than GPT-3.5-turbo 236 \nsummaries across all three domains, with 10%, 42% and 47% of summaries containing 237 \ninaccuracies, hallucinations and omissions, respectively. GPT-4-generated summaries were also 238 \nshorter and more readable than those generated by GPT-3.5-turbo, with an average Flesch-239 \nKincaid Grade Level of 10.  240 \n 241 \nThe improved performance of GPT-4 compared to GPT-3.5-turbo aligns with prior literature 242 \nwhich has shown superior GPT-4 performance across both medical and non-medical tasks. 22–24 243 \nMoreover, the fact that GPT-4 summaries contained a lower number of omissions than GPT-3.5-244 \nturbo, whilst summarizing the same information in fewer words, suggests increased summary 245 \nconcision that may be welcomed by primary care physicians and others on the receiving end of 246 \nthe transition of care.25 247 \n 248 \nAlthough only 33% of summaries generated by GPT-4 were entirely error-free across all 249 \ndomains, a more detailed review of the subtypes of error demonstrated that a majority of 250 \nhallucinations either related to information redacted in the original note as part of our 251 \ninstitution’s de-identification process or resulted from GPT-4 hallucinating follow-up 252 \ninstructions and/or return precautions. In the latter instance, such follow-up instructions were 253 \noften appropriate for the patient’s care (as if they were derived from a standard set of precautions 254 \nassociated with the patient’s final diagnosis), but because they had not been explicitly mentioned 255 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nin the original EM provider’s note, they were classified as hallucinations in accordance with our 256 \npre-specified protocol. After excluding these specific  types of errors post-hoc, the proportion of 257 \nGPT-4 generated summaries considered error-free across all domains increased by 14%, 258 \nreaching 47% error-free across the three domains. 259 \n 260 \nMeanwhile, there were notable differences in initial inter-reviewer agreement between error type 261 \nprior to consensus agreement, with 91.9% agreement on the presence of clinical omissions 262 \ncompared to 95.8% and 93.6% agreement for inaccuracies and hallucinations, respectively. This 263 \nreflects the subjective nature of classifying clinical omissions, where the inclusion of different 264 \nclinical details may depend on the preference of the discharging clinician.  It is possible that, 265 \nwith either dedicated prompt engineering or the addition of few-shot examples during future 266 \nprompting, clinician-specific preferences of what information ought to be included in each 267 \ndischarge summary may be incorporated to address this. 268 \n 269 \nThere is a paucity of existing literature examining the performance of LLMs when generating 270 \ndischarge summaries, either in the Emergency Department or inpatient hospital setting. This is 271 \nconcerning given reports of the recent deployment of ambient artificial intelligence (AI) scribes 272 \nat a large healthcare organisation. 19 In that study, 35 example patient transcripts and encounter 273 \nsummaries generated by the AI scribe were rated using a modified version of the Physician 274 \nDocumentation Quality Instrument, with an average score of 48/50 achieved. 19,26 However, a 275 \nquantitative analysis of the number and type of errors present was not reported. Meanwhile, a 276 \nseparate study of neurology inpatient encounters showed that Bidirectional Encoder 277 \nRepresentations from Transformers (BERT) and Bidirectional and Auto-Regressive 278 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nTransformers (BART) models could be used to generate summaries which met the standard of 279 \ncare in 62% of cases, but acknowledged that future work should count the number and type of 280 \nhallucinations in automated summaries.18  281 \n 282 \n Since clinicians will ultimately be responsible for auditing and modifying clinical 283 \ndocumentation produced by LLMs, gaining a thorough understanding of potential error sources 284 \nin this documentation is critically important. Without a thorough understanding of where errors 285 \nmay occur, there's a risk that errors made by LLMs could be overlooked, potentially harming 286 \npatient care. 27 Additionally, the increased workload on clinicians to meticulously audit the 287 \ndischarge summary could lead to worsening burnout, potentially negating the benefits of using 288 \nthis technology. Our findings suggest that the location of errors within a GPT-generated 289 \ndischarge summary may vary based on the type of error: inaccuracies and hallucinations are most 290 \ncommonly found within the Plan sections of GPT-generated discharge summaries, while the 291 \nPhysical Examination and History of Presenting Complaint  sections should be checked closely 292 \nfor clinical omissions. Future studies should evaluate the application of LLMs themselves to 293 \nidentify instances of inaccuracy, hallucination and clinical omission errors within LLM-294 \ngenerated clinical documents when compared to the original source documents, allowing 295 \nclinicians to audit and amend areas that are subject to discordance.  296 \n 297 \nThis study has several limitations. First, in this study only the initial EM clinician note was 298 \nsummarized. While this note typically contains the patient’s clinical history, physical 299 \nexamination findings, results of investigations performed and overall plan, other pertinent 300 \ninformation that is found in notes from other providers, such as physical or occupational 301 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \ntherapist recommendations and specialty consult advice, may not have been included in the 302 \ndischarge summary. Future work should evaluate the performance of LLMs in the more complex 303 \ntask of multi-document summarization before deployment to EDs can be considered. Second, 304 \ndue to the time and labor-intensive process of manual expert review, we included 100 randomly 305 \nselected ED encounters in our sample, which may limit generalizability across different types of 306 \npatient demographics and presenting symptoms. Notably, our randomly selected sample 307 \npredominantly consisted of White, Asian or Black/African American patients, with limited 308 \nrepresentation of other minority groups. As LLM performance continues to be evaluated across 309 \ndifferent medical tasks, racial and gender bias assessments of these tools must be performed 310 \nprior to their integration into clinical care. 28 Third, GPT model performance may improve with 311 \nfurther iterations of prompt engineering and/or in-context learning. For instance, in comparing 312 \nGPT-3.5-turbo to GPT-4, there was an enhancement in summarization capabilities across all 313 \ndomains evaluated, including over ED discharge summary length. Fourth, we did not directly 314 \ncompare the GPT-generated discharge summaries with the actual clinician-generated discharge 315 \nsummaries for these encounters. It is possible that important information might have been 316 \nmissing, or inaccurately reported, in the clinician-generated discharge summaries as well. 317 \n 318 \nConclusion 319 \nIn this cross-sectional study of 100 ED encounters, we found that LLMs could generate accurate 320 \ndischarge summaries, but were liable to hallucination and omission of clinically relevant 321 \ninformation. Our results suggest that the location of errors within a GPT-generated discharge 322 \nsummary may vary based on the type of error. A comprehensive understanding of where errors 323 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nare most likely to occur in GPT-generated clinical text is critically important to facilitate 324 \nclinician review and revision of such content and prevent patient harm.  325 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nTables 326 \n 327 \nVariable Category Number of patients, n \nSex \nMale 44 \nFemale 56 \nRace/ethnicity \nWhite 39 \nAsian 20 \nBlack or African American 18 \nLatinx 11 \nOther 4 \nNative Hawaiian or Other \nPacific Islander \n3 \nSouthwest Asian and North \nAfrican \n3 \nUnknown/Declined 2 \nAge, median (IQR) 48.1 years (37.4 – 67.9) \nESI Acuity Level \nUrgent 54 \nLess Urgent 27 \nEmergent 16 \nNon-Urgent 2 \nUnspecified 1 \nDischarge disposition \nHome or Self Care 95 \nSkilled Nursing Facility 2 \nOther 3 \nTable 1.  Patient demographics in n = 100 sample of Emergency Department encounters 328 \nrandomly selected for GPT-3.5-turbo and GPT-4 discharge summary generation. ED = 329 \nEmergency department; ESI = Emergency Severity Index; IQR = interquartile range. 330 \n  331 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nError Type \n \nError category Example reviewer comment* Count \nInaccuracy \nInaccurate follow-up details \n“[The original note states that the] \npatient had follow-up with GI for \ncolonoscopy and EGD and hematology \nfollow-up [was] already scheduled \n[whereas the GPT summary states the \npatient was advised to obtain this]” \n3 \nInaccurate examination findings \n“[The GPT summary] states HINTS \nexam was positive, but is in fact \nnegative” \n2 \nInaccurately reported the interim \nplan as the follow-up plan \n“The final plan is listed as ‘follow-up \nlabs/psych recommendations’, but this \nwas the sign-out plan – the final plan was \nactually: ‘safe for discharge’”) \n2 \nInaccurately reported patient’s \nmanagement in ED \n“Written for but did not get \nacetaminophen in ED” 1 \nInaccurately reported imaging as \nnormal \n“CT pelvis was not negative” 1 \nInaccurate social history reported \n“States patient is a former smoker, when \nin fact patient is a former drinker and \nnever smoked” \n1 \nHallucination \nHallucinated redacted \ninformation \n“Redacted portion [of original note] \nfilled in [in GPT summary] as \n‘headache’” \n15 \nHallucinated outpatient follow-up \ndetails \n“[The GPT summary] hallucinated \nfollow-up with Rheumatology and \nNeurology, though [there is] no mention \nof this in [the original] note” \n11 \nHallucinated ED return \nprecautions \n“No return precautions mentioned in \nnon-redacted portion of [original] note” 7 \nHallucinated medication plan \n“[GPT summary] hallucinated plan of \ncontinuing medications as prescribed - \nthere was no reference to this in original \nnote” \n3 \nHallucinated primary care \nphysician follow-up details \n“[GPT summary] hallucinated PCP \nfollow-up” 3 \nHallucinated follow-up \ninstructions \n“No specific return precautions (fever, \nchest pain, SOB) provided in [original] \nnote; no instructions to continue current \nmeds or avoid morphine were provided \nin the original note” \n3 \nHallucinated patient’s \nmanagement in ED \n“Patient did not receive Nitro spray in \nED” 3 \nHallucinated cause of symptoms \n \n“Under diagnosis, [GPT summary] states \nheadache is due to post-surgical changes, \nwhich was not documented in the initial \nnote” \n1 \nHallucinated patient’s diagnosis “No mention of what final diagnosis was \non original note, yet GPT wrote ‘likely 1 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \ndue to cyst or surgery’” \nHallucinated symptoms “[GPT summary] hallucinated patient as \nhaving carotid tenderness” 1 \nClinical \nOmission \nOmission of positive physical \nexamination findings \n“Omitted left sided laceration”; “Did not \nmention contracture”; “Omitted bilateral \nconjunctival injection”; “Omitted \nmurmur”; “Omitted patient’s \nsomnolence and gait stability” \n13 \nOmission of imaging performed \n“Omitted chest x-ray”; “Omitted MRI \nresults”; “Omission of all radiology \nresults” \n8 \nOmission of symptom reported \n“Does not mention Tylenol overdose \nconcern”; “No mention of watery \ndiarrhea”; “Omitted that bleeding was \nseen by ED nurse and pressure dressing \nwas applied” \n7 \nOmission of details of patient’s \nmanagement in ED \n“Omitted orthopedics consult”; “Omitted \ngynecology consult”; “Omitted \nreassessment and repeat check of \nambulatory saturation”  \n7 \nOmission of pertinent negative \nphysical examination findings \n“Omitted patient was afebrile”; “Should \ninclude that patient had a benign GU \nexam”; “Should have included benign \nabdominal exam” \n5 \nOmission of details of patient’s \nmedication history \n“Omitted that she was on antibiotics”; \n“Omitted estrogen use” 4 \nOmission of details of patient’s \nPast Medical History \n“Omitted history of known pulmonary \nembolus”; “Did not mention clarification \non baseline bradycardia (this is \nsignificant abnormality that provider \ncontacted PMD to clarify)”; “Omitted \nkey medical history including patient \nwas unable to walk secondary to \ndizziness” \n4 \nOmission of details of patient’s \nallergies \n“No mention of allergies” 2 \nOmission of details of patient’s \nPast Surgical History \n“Omitted cholecystectomy surgery”; \n“Omits history of PEG” 2 \nOmission of ECG performed \n“Omission of any mention of an \nelectrocardiogram for patient’s \ntachycardia” \n1 \nOmission of laboratory tests \nperformed \n“Omitted mention of stool studies \ncollected” 1 \nOmission of symptom time \ncourse \n“Omitted timeline of symptoms – \nimprovement, but woke her up second \nnight in a row” \n1 \nOmission of symptom character \n“Does not mention that the reason the \npatient’s chest pain is different now is \nthat it is now constant” \n1 \nOmission of suspicious injury “Omission of suspicious injury report” 1 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nreport \nOmission of pertinent normal \nlaboratory test results \n“Omitted negative troponins” 1 \nOmission of follow-up \ninformation \n“Discussion of possible bowel regiment \nnot included” 1 \nOmission that patient declined \nphysical examination \n“Refusal of rectal exam” 1 \nOmission of diagnosis \n“Did not include the presumptive \ndiagnosis selection (menstrual cramps) \namongst the various differential \ndiagnosis entities” \n1 \nOmission of code stroke \nactivation \n“Omits activation of code stroke” 1 \nOmission of bedside imaging \ndone \n“Omits bedside ultrasound (but mentions \nx-ray”) 1 \nOmission of urinalysis results “Omitted positive urine drug screen for \ncocaine (not extremely relevant)” 1 \nTable 2. Manual categorization of expert reviewer comments providing further details for each 332 \nerror subtype among GPT-4-generated discharge summaries compared to the ground-truth, 333 \noriginal Emergency Medicine provider note. *Comments reported with minor modifications to 334 \nsyntax for improved readability.  335 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nFigures 336 \nFigure 1. A) Flowchart of included Emergency Department (ED) visits. B) Study workflow.  337 \n 338 \nFigure 2. Proportion of discharge summaries with 1 or more error identified by clinical 339 \nreviewers in each of the three domains evaluated: 1) Inaccuracy, 2) Hallucination and 3) Clinical 340 \nOmission. 341 \n 342 \nFigure 3. Breakdown of errors for each domain (Accuracy, Hallucination and Clinical Omission) 343 \nby section of discharge summary. PC = Presenting Complaint; HPC = History of Presenting 344 \nComplaint; PMH = Past Medical History; ROS = Review of Systems; PE = Physical 345 \nExamination.  346 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nSupplementary Figures and Tables 347 \nFigure S1. Histogram of original Emergency Medicine provider note length among the n = 100 348 \nsample of Emergency Department encounters randomly selected for GPT-3.5-turbo and GPT-4 349 \nsummarization. 350 \n 351 \nFigure S2. Histogram of word counts of a) GPT-3.5-turbo and b) GPT-4 generated discharge 352 \nsummaries. 353 \n 354 \nFigure S3. Manual categorization of reviewer comments providing further details for each error 355 \nsubtype [a) Inaccuracy, b) Hallucination, and c) Clinical omission] among GPT-4-generated 356 \ndischarge summaries compared to the ground-truth, original Emergency Medicine provider note. 357 \n 358 \nFigure S4. Manual categorization of reviewer comments providing further details for each error 359 \nsubtype [a) Inaccuracy, b) Hallucination, and c) Clinical omission] among GPT-3.5-turbo-360 \ngenerated discharge summaries compared to the ground-truth, original Emergency Medicine 361 \nprovider note. 362 \n 363 \n 364 \nTable S1. Initial inter-reviewer agreement rates by error type, prior to consensus agreement. 365 \n 366 \nTable S2. Manual categorization of expert reviewer comments providing further details for each 367 \nerror subtype among GPT-3.5-turbo-generated discharge summaries compared to the ground-368 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \ntruth, original Emergency Medicine provider note. *Comments reported with minor 369 \nmodifications to syntax for improved readability. 370 \n  371 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nReferences 372 \n1. Ngo E, Patel N, Chandrasekaran K, Tajik AJ, Paterick TE. The Importance of the Medical 373 \nRecord: A Critical Professional Responsibility. J Med Pract Manag MPM. 2016;31(5):305-374 \n308. 375 \n2. Ebbers T, Kool RB, Smeele LE, et al. The Impact of Structured and Standardized 376 \nDocumentation on Documentation Quality; a Multicenter, Retrospective Study. J Med Syst. 377 \n2022;46(7):46. doi:10.1007/s10916-022-01837-9 378 \n3. Gesner E, Gazarian P, Dykes P. The Burden and Burnout in Documenting Patient Care: An 379 \nIntegrative Literature Review. Stud Health Technol Inform. 2019;264:1194-1198. 380 \ndoi:10.3233/SHTI190415 381 \n4. Mishra P, Kiang JC, Grant RW. Association of Medical Scribes in Primary Care With 382 \nPhysician Workflow and Patient Experience. JAMA Intern Med. 2018;178(11):1467-1472. 383 \ndoi:10.1001/jamainternmed.2018.3956 384 \n5. Sinsky C, Colligan L, Li L, et al. Allocation of Physician Time in Ambulatory Practice: A 385 \nTime and Motion Study in 4 Specialties. Ann Intern Med. 2016;165(11):753-760. 386 \ndoi:10.7326/M16-0961 387 \n6. Adler-Milstein J, Zhao W, Willard-Grace R, Knox M, Grumbach K. Electronic health records 388 \nand burnout: Time spent on the electronic health record after hours and message volume 389 \nassociated with exhaustion but not with cynicism among primary care clinicians. J Am Med 390 \nInform Assoc. 2020;27(4):531-538. doi:10.1093/jamia/ocz220 391 \n7. Ortega MV, Hidrue MK, Lehrhoff SR, et al. Patterns in Physician Burnout in a Stable-Linked 392 \nCohort. JAMA Netw Open. 2023;6(10):e2336745. doi:10.1001/jamanetworkopen.2023.36745 393 \n8. Tajirian T, Stergiopoulos V, Strudwick G, et al. The Influence of Electronic Health Record 394 \nUse on Physician Burnout: Cross-Sectional Survey. J Med Internet Res. 2020;22(7):e19274. 395 \ndoi:10.2196/19274 396 \n9. Peccoralo LA, Kaplan CA, Pietrzak RH, Charney DS, Ripp JA. The impact of time spent on 397 \nthe electronic health record after work and of clerical work on burnout among clinical faculty. 398 \nJ Am Med Inform Assoc. 2021;28(5):938-947. doi:10.1093/jamia/ocaa349 399 \n10. Taylor DM, Cameron PA. Discharge instructions for emergency department patients: 400 \nwhat should we provide? Emerg Med J. 2000;17(2):86-90. doi:10.1136/emj.17.2.86 401 \n11. Sorita A, Robelia PM, Kattel SB, et al. The Ideal Hospital Discharge Summary: A Survey 402 \nof U.S. Physicians. J Patient Saf. 2021;17(7):e637-e644. 403 \ndoi:10.1097/PTS.0000000000000421 404 \n12. Robelia PM, Kashiwagi DT, Jenkins SM, Newman JS, Sorita A. Information Transfer 405 \nand the Hospital Discharge Summary: National Primary Care Provider Perspectives of 406 \nChallenges and Opportunities. J Am Board Fam Med JABFM. 2017;30(6):758-765. 407 \ndoi:10.3122/jabfm.2017.06.170194 408 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n13. Li JYZ, Yong TY, Hakendorf P, Ben-Tovim D, Thompson CH. Timeliness in discharge 409 \nsummary dissemination is associated with patients’ clinical outcomes. J Eval Clin Pract. 410 \n2013;19(1):76-79. doi:10.1111/j.1365-2753.2011.01772.x 411 \n14. Improving the Emergency Department Discharge Process: Environmental Scan Report. 412 \n15. Wachter RM, Brynjolfsson E. Will Generative Artificial Intelligence Deliver on Its 413 \nPromise in Health Care? JAMA. 2024;331(1):65-69. doi:10.1001/jama.2023.25054 414 \n16. Tang L, Sun Z, Idnay B, et al. Evaluating large language models on medical evidence 415 \nsummarization. Npj Digit Med. 2023;6(1):1-8. doi:10.1038/s41746-023-00896-7 416 \n17. Van Veen D, Van Uden C, Blankemeier L, et al. Adapted large language models can 417 \noutperform medical experts in clinical text summarization. Nat Med. Published online 418 \nFebruary 27, 2024:1-9. doi:10.1038/s41591-024-02855-5 419 \n18. Hartman VC, Bapat SS, Weiner MG, Navi BB, Sholle ET, Campion TR. A method to 420 \nautomate the discharge summary hospital course for neurology patients. J Am Med Inform 421 \nAssoc JAMIA. 2023;30(12):1995-2003. doi:10.1093/jamia/ocad177 422 \n19. Tierney AA, Gayre G, Hoberman B, et al. Ambient Artificial Intelligence Scribes to 423 \nAlleviate the Burden of Clinical Documentation. Catal Non-Issue Content. 424 \n2024;5(1):CAT.23.0404. doi:10.1056/CAT.23.0404 425 \n20. Radhakrishnan L, Schenk G, Muenzen K, et al. A certified de-identification system for 426 \nall clinical text documents for information extraction at scale. JAMIA Open. 427 \n2023;6(3):ooad045. doi:10.1093/jamiaopen/ooad045 428 \n21. openai/tiktoken. Published online March 23, 2024. Accessed March 23, 2024. 429 \nhttps://github.com/openai/tiktoken 430 \n22. Williams CYK, Zack T, Miao BY, Sushil M, Wang M, Butte AJ. Assessing clinical 431 \nacuity in the Emergency Department using the GPT-3.5 Artificial Intelligence Model. 432 \nPublished online August 13, 2023:2023.08.09.23293795. doi:10.1101/2023.08.09.23293795 433 \n23. OpenAI. GPT-4 Technical Report. Published online March 27, 2023. 434 \ndoi:10.48550/arXiv.2303.08774 435 \n24. Fink MA, Bischoff A, Fink CA, et al. Potential of ChatGPT and GPT-4 for Data Mining 436 \nof Free-Text CT Reports on Lung Cancer. Radiology. 2023;308(3):e231362. 437 \ndoi:10.1148/radiol.231362 438 \n25. Chatterton B, Chen J, Schwarz EB, Karlin J. Primary Care Physicians’ Perspectives on 439 \nHigh-Quality Discharge Summaries. J Gen Intern Med. Published online November 27, 2023. 440 \ndoi:10.1007/s11606-023-08541-5 441 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n26. Stetson PD, Bakken S, Wrenn JO, Siegler EL. Assessing Electronic Note Quality Using 442 \nthe Physician Documentation Quality Instrument (PDQI-9). Appl Clin Inform. 2012;3(2):164-443 \n174. doi:10.4338/ACI-2011-11-RA-0070 444 \n27. Adler-Milstein J, Redelmeier DA, Wachter RM. The Limits of Clinician Vigilance as an 445 \nAI Safety Bulwark. JAMA. Published online March 14, 2024. doi:10.1001/jama.2024.3620 446 \n28. Zack T, Lehman E, Suzgun M, et al. Assessing the potential of GPT-4 to perpetuate 447 \nracial and gender biases in health care: a model evaluation study. Lancet Digit Health. 448 \n2024;6(1):e12-e22. doi:10.1016/S2589-7500(23)00225-X 449 \n  450 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nConflicts of Interest 451 \nAEK is a co-founder and consultant to CaptureDx. AJB is a co-founder and consultant to 452 \nPersonalis and NuMedii; consultant to Mango Tree Corporation, and in the recent past, Samsung, 453 \n10x Genomics, Helix, Pathway Genomics, and Verinata (Illumina); has served on paid advisory 454 \npanels or boards for Geisinger Health, Regenstrief Institute, Gerson Lehman Group, 455 \nAlphaSights, Covance, Novartis, Genentech, and Merck, and Roche; is a shareholder in 456 \nPersonalis and NuMedii; is a minor shareholder in Apple, Meta (Facebook), Alphabet (Google), 457 \nMicrosoft, Amazon, Snap, 10x Genomics, Illumina, Regeneron, Sanofi, Pfizer, Royalty Pharma, 458 \nModerna, Sutro, Doximity, BioNtech, Invitae, Pacific Biosciences, Editas Medicine, Nuna 459 \nHealth, Assay Depot, and Vet24seven, and several other non-health related companies and 460 \nmutual funds; and has received honoraria and travel reimbursement for invited talks from 461 \nJohnson and Johnson, Roche, Genentech, Pfizer, Merck, Lilly, Takeda, Varian, Mars, Siemens, 462 \nOptum, Abbott, Celgene, AstraZeneca, AbbVie, Westat, and many academic institutions, 463 \nmedical or disease specific foundations and associations, and health systems. AJB receives 464 \nroyalty payments through Stanford University, for several patents and other disclosures licensed 465 \nto NuMedii and Personalis. AJB’s research has been funded by NIH, Peraton (as the prime on an 466 \nNIH contract), Genentech, Johnson and Johnson, FDA, Robert Wood Johnson Foundation, Leon 467 \nLowenstein Foundation, Intervalien Foundation, Priscilla Chan and Mark Zuckerberg, the 468 \nBarbara and Gerson Bakar Foundation, and in the recent past, the March of Dimes, Juvenile 469 \nDiabetes Research Foundation, California Governor’s Office of Planning and Research, 470 \nCalifornia Institute for Regenerative Medicine, L’Oreal, and Progenity. None of these entities 471 \nhad any bearing on the design of this study or the writing of the manuscript.  472 \n 473 \nNo other authors have conflicts of interest to disclose. 474 \n 475 \nAcknowledgements 476 \nDr Aaron E. Kornblith is supported by Eunice Kennedy Shriver National Institute of Child 477 \nHealth and Human Development of the National Institutes of Health under award number 478 \nK23HD110716. 479 \n 480 \nThe authors acknowledge the use of the UCSF Information Commons computational research 481 \nplatform, developed and supported by UCSF Bakar Computational Health Sciences Institute. 482 \nThe authors also thank the UCSF AI Tiger Team, Academic Research Services, Research 483 \nInformation Technology, and the Chancellor’s Task Force for Generative AI for their software 484 \ndevelopment, analytical and technical support related to the use of Versa API gateway (the 485 \nUCSF secure implementation of large language models and generative AI via API gateway), 486 \nVersa chat (the chat user interface), and related data asset and services. 487 \n 488 \nDr Christopher Y.K. Williams had full access to all the data in the study and takes responsibility 489 \nfor the integrity of the data and the accuracy of the data analysis. 490 \n 491 \nCode availability 492 \nThe code accompanying this manuscript is available at https://github.com/cykwilliams/GPT-4-493 \nEmergency-Department-Discharge-Summary/  494 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \nFigures \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 1. A) Flowchart of included Emergency Department (ED) visits. B) Study workﬂow. \n \n \n278,629 adult ED visits with \nEmergency Medicine provider note \nExclude ED visits with notes that lack history, examina8on \nand assessment/plan sec8ons (n = 7937) \n202,059 eligible ED visits \nExclude ED visits with notes ³3500 tokens in length (n = \n5929) \nExclude ED visits where pa8ent was admiEed to hospital (n \n= 62,704) \nn = 100 sample randomly selected \nfor GPT model evaluaPon \nA \nB \nClinician review of each sec0on (from Presen0ng Complaint, History \nof Presen0ng Complaint, Past Medical History, Allergies, Review of \nSystems, Physical Examina0on ﬁndings, Labs, Imaging, Plan, Other)  \nof the GPT-generated discharge summary to iden0fy errors across \nthree domains (Inaccuracy, Hallucina0on, Clinical omission) \nDe-iden'ﬁed Emergency \nMedicine clerking notes \nassociated with 100 ED visits \nGPT-3.5-turbo & GPT-4 \nsummariza'on of ED note into \ndischarge summary \n“You are an Emergency Department physician. Below is the \nHistory and Physical Examination note for a patient \npresenting to the Emergency Department who was \nsubsequently discharged. Write a discharge summary for the \npatient based on this note. Do not include  any additional \ninformation not present in the note.” \nReview domains: \n- Inaccuracy \n- Hallucina6on \n- Clinical omission \n \nEvalua'on \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n \nFigure 2. Proportion of discharge summaries with 1 or more error identified by clinical \nreviewers in each of the three domains evaluated: 1) Inaccuracy, 2) Hallucination and 3) Clinical \nOmission. \n  \n0\n20\n40\n60\nGPT-3.5-turbo GPT-4\nProportion of cases (%)\nDomain\nAccuracy\nHa llucination\nClin ical Omission\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFigure 3. Breakdown of errors for each domain (Accuracy, Hallucination and Clinical Omission) \nby section of discharge summary. PC = Presenting Complaint; HPC = History of Presenting \nComplaint; PMH = Past Medical History; ROS = Review of Systems; PE = Physical \nExamination. \nClin ical Omission\nHa llucination\nAccuracy\nPC HP C PMH Allergies RO S PE Labs Imaging Plan Other\n0\n10\n20\n30\n0\n10\n20\n30\n0\n10\n20\n30\nClin ical Omission\nHa llucination\nAccuracy\nPC HP C PMH Allergies RO S PE Labs Imaging Plan Other\n0\n10\n20\n30\n0\n10\n20\n30\n0\n10\n20\n30 Count\nGPT-3.5-turbo \n GPT-4 \n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted April 4, 2024. ; https://doi.org/10.1101/2024.04.03.24305088doi: medRxiv preprint ",
  "topic": "Emergency department",
  "concepts": [
    {
      "name": "Emergency department",
      "score": 0.6548313498497009
    },
    {
      "name": "Computer science",
      "score": 0.4167672097682953
    },
    {
      "name": "Programming language",
      "score": 0.36879146099090576
    },
    {
      "name": "Medicine",
      "score": 0.13307708501815796
    },
    {
      "name": "Nursing",
      "score": 0.04994380474090576
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I180670191",
      "name": "University of California, San Francisco",
      "country": "US"
    }
  ]
}