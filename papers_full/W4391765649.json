{
    "title": "Domain-specific language models pre-trained on construction management systems corpora",
    "url": "https://openalex.org/W4391765649",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2997553950",
            "name": "Yunshun Zhong",
            "affiliations": [
                "University of Toronto"
            ]
        },
        {
            "id": "https://openalex.org/A4224348115",
            "name": "Sebastian D. Goodfellow",
            "affiliations": [
                "University of Toronto"
            ]
        },
        {
            "id": "https://openalex.org/A2997553950",
            "name": "Yunshun Zhong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4224348115",
            "name": "Sebastian D. Goodfellow",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4200248815",
        "https://openalex.org/W4290991313",
        "https://openalex.org/W3010212250",
        "https://openalex.org/W4309772935",
        "https://openalex.org/W4313420701",
        "https://openalex.org/W3180168080",
        "https://openalex.org/W4283219089",
        "https://openalex.org/W1918694413",
        "https://openalex.org/W3031264305",
        "https://openalex.org/W4205158424",
        "https://openalex.org/W3199748762",
        "https://openalex.org/W3149443267",
        "https://openalex.org/W3198659451",
        "https://openalex.org/W2395579298",
        "https://openalex.org/W4285791949",
        "https://openalex.org/W4387430635",
        "https://openalex.org/W2096772585",
        "https://openalex.org/W2347658236",
        "https://openalex.org/W3120530803",
        "https://openalex.org/W6739496531",
        "https://openalex.org/W3175917553",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W6779277177",
        "https://openalex.org/W6682691769",
        "https://openalex.org/W4239025696",
        "https://openalex.org/W6691431627",
        "https://openalex.org/W2777670633",
        "https://openalex.org/W2043182541",
        "https://openalex.org/W6749969641",
        "https://openalex.org/W6740213971",
        "https://openalex.org/W2905068499",
        "https://openalex.org/W6676145601",
        "https://openalex.org/W6687483927",
        "https://openalex.org/W2625066715",
        "https://openalex.org/W2930957955",
        "https://openalex.org/W4234552385",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2781626870",
        "https://openalex.org/W2792932412",
        "https://openalex.org/W4225156065",
        "https://openalex.org/W4294170691",
        "https://openalex.org/W2525778437",
        "https://openalex.org/W2949847915",
        "https://openalex.org/W4225823287",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4386044393",
        "https://openalex.org/W2730123083",
        "https://openalex.org/W2797575854"
    ],
    "abstract": "The rising demand for automated methods in the Construction Management Systems (CMS) sector highlights opportunities for the Transformer architecture, which enables pre-training Deep Learning models on large, unlabeled datasets for Natural Language Processing (NLP) tasks, outperforming traditional Recurrent Neural Network models. However, their potential in the CMS domain remains underexplored. Therefore, this research produced the first CMS domain corpora from academic papers and introduced an end-to-end pipeline for pre-training and fine-tuning domain-specific Pre-trained Language Models. Four corpora were constructed and transfer learning was employed to pre-train BERT and RoBERTa using the corpora. The best-performing models were then fine-tuned and outperformed models pre-trained on general corpora. In two key NLP tasks, text classification using an infrastructure condition prediction dataset and named entity recognition using an automatic construction control dataset, domain-specific pre-training improved F1 scores by 5.9% and 8.5%, respectively. These promising results demonstrate extended applicability beyond CMS to the Architecture, Engineering, and Construction sectors.",
    "full_text": null
}