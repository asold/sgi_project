{
  "title": "Automated MRI protocoling in neuroradiology in the era of large language models",
  "url": "https://openalex.org/W4412188017",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Reiner, Lara Noelle",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Chelbi, Moudather",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Fetscher, Leonard",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Stöckel, Juliane C.",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Csapó-Schmidt, Christoph",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Guseynova, Shakhnaz",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Al Mohamad, Fares",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Bressem, Keno Kyrill",
      "affiliations": [
        "Klinikum rechts der Isar",
        "Deutsches Herzzentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A3173075704",
      "name": "Nawabi Jawed",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Siebert, Eberhard",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Wattjes, Mike P.",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": "https://openalex.org/A3180906099",
      "name": "Scheel, Michael",
      "affiliations": [
        "Charité - Universitätsmedizin Berlin"
      ]
    },
    {
      "id": null,
      "name": "Meddeb, Aymen",
      "affiliations": [
        "Centre Hospitalier Universitaire de Reims",
        "Berlin Institute of Health at Charité - Universitätsmedizin Berlin",
        "Hôpital Maison Blanche",
        "Charité - Universitätsmedizin Berlin",
        "Université de Reims Champagne-Ardenne"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2422148244",
    "https://openalex.org/W3217105868",
    "https://openalex.org/W2251460154",
    "https://openalex.org/W2795630411",
    "https://openalex.org/W3122882518",
    "https://openalex.org/W3015264156",
    "https://openalex.org/W3171068822",
    "https://openalex.org/W3179033263",
    "https://openalex.org/W2766934786",
    "https://openalex.org/W4409286800",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4395052272",
    "https://openalex.org/W4401248212",
    "https://openalex.org/W4362608470",
    "https://openalex.org/W4405498977",
    "https://openalex.org/W4380422747",
    "https://openalex.org/W4392597393",
    "https://openalex.org/W4398218462",
    "https://openalex.org/W4397003633",
    "https://openalex.org/W4395050972",
    "https://openalex.org/W4392544551",
    "https://openalex.org/W4402853403",
    "https://openalex.org/W4293697180",
    "https://openalex.org/W4406149441",
    "https://openalex.org/W4406542750",
    "https://openalex.org/W4394780593",
    "https://openalex.org/W4399774223",
    "https://openalex.org/W4387472906",
    "https://openalex.org/W2997405307",
    "https://openalex.org/W4394948082",
    "https://openalex.org/W4406724553"
  ],
  "abstract": "Abstract Purpose This study investigates the automation of MRI protocoling, a routine task in radiology, using large language models (LLMs), comparing an open-source (LLama 3.1 405B) and a proprietary model (GPT-4o) with and without retrieval-augmented generation (RAG), a method for incorporating domain-specific knowledge. Material and Methods This retrospective study included MRI studies conducted between January and December 2023, along with institution-specific protocol assignment guidelines. Clinical questions were extracted, and a neuroradiologist established the gold standard protocol. LLMs were tasked with assigning MRI protocols and contrast medium administration with and without RAG. The results were compared to protocols selected by four radiologists. Token-based symmetric accuracy, the Wilcoxon signed-rank test, and the McNemar test were used for evaluation. Results Data from 100 neuroradiology reports (mean age = 54.2 years ± 18.41, women 50%) were included. RAG integration significantly improved accuracy in sequence and contrast media prediction for LLama 3.1 (Sequences: 38% vs. 70%, P &lt; .001, Contrast Media: 77% vs. 94%, P &lt; .001), and GPT-4o (Sequences: 43% vs. 81%, P &lt; .001, Contrast Media: 79% vs. 92%, P = .006). GPT-4o outperformed LLama 3.1 in MRI sequence prediction (81% vs. 70%, P &lt; .001), with comparable accuracies to the radiologists (81% ± 0.21, P = .43). Both models equaled radiologists in predicting contrast media administration (LLama 3.1 RAG: 94% vs. 91% ± 0.2, P = .37, GPT-4o RAG: 92% vs. 91% ± 0.24, P = .48). Conclusion Large language models show great potential as decision-support tools for MRI protocoling, with performance similar to radiologists. RAG enhances the ability of LLMs to provide accurate, institution-specific protocol recommendations.",
  "full_text": "Vol:.(1234567890)\nLa radiologia medica (2025) 130:1472–1482\nhttps://doi.org/10.1007/s11547-025-02040-9\nMAGNETIC RESONANCE IMAGING\nAutomated MRI protocoling in neuroradiology in the era of large \nlanguage models\nLara Noelle Reiner1  · Moudather Chelbi1 · Leonard Fetscher1 · Juliane C. Stöckel1 · Christoph Csapó‑Schmidt1 · \nShakhnaz Guseynova1 · Fares Al Mohamad1 · Keno Kyrill Bressem4,5 · Jawed Nawabi1 · Eberhard Siebert1 · \nMike P . Wattjes1 · Michael Scheel1 · Aymen Meddeb1,2,3\nReceived: 12 November 2024 / Accepted: 9 June 2025 / Published online: 11 July 2025 \n© The Author(s) 2025\nAbstract\nPurpose This study investigates the automation of MRI protocoling, a routine task in radiology, using large language mod-\nels (LLMs), comparing an open-source (LLama 3.1 405B) and a proprietary model (GPT-4o) with and without retrieval-\naugmented generation (RAG), a method for incorporating domain-specific knowledge.\nMaterial and Methods This retrospective study included MRI studies conducted between January and December 2023, along \nwith institution-specific protocol assignment guidelines. Clinical questions were extracted, and a neuroradiologist established \nthe gold standard protocol. LLMs were tasked with assigning MRI protocols and contrast medium administration with and \nwithout RAG. The results were compared to protocols selected by four radiologists. Token-based symmetric accuracy, the \nWilcoxon signed-rank test, and the McNemar test were used for evaluation.\nResults Data from 100 neuroradiology reports (mean age = 54.2 years ± 18.41, women 50%) were included. RAG integration \nsignificantly improved accuracy in sequence and contrast media prediction for LLama 3.1 (Sequences: 38% vs. 70%, P < .001, \nContrast Media: 77% vs. 94%, P < .001), and GPT-4o (Sequences: 43% vs. 81%, P < .001, Contrast Media: 79% vs. 92%, \nP = .006). GPT-4o outperformed LLama 3.1 in MRI sequence prediction (81% vs. 70%, P < .001), with comparable accura-\ncies to the radiologists (81% ± 0.21, P = .43). Both models equaled radiologists in predicting contrast media administration \n(LLama 3.1 RAG: 94% vs. 91% ± 0.2, P = .37, GPT-4o RAG: 92% vs. 91% ± 0.24, P = .48).\nConclusion Large language models show great potential as decision-support tools for MRI protocoling, with performance \nsimilar to radiologists. RAG enhances the ability of LLMs to provide accurate, institution-specific protocol recommendations.\nKeywords Artificial intelligence · Automation · Decision-support systems · Clinical · Large language models · Magnetic \nresonance imaging · Natural language processing · Neuroradiology\nAbbreviations\nAI  Artificial intelligence\nGT  Ground Truth\nLLM  Large language model\nRAG   Retrieval-augmented generation\nIntroduction\nMRI acquisition protocol assignment is a critical step in \nthe radiology workflow, ensuring adequate imaging for \npatient care. However, this process is time-consuming, \naccounting for approximately 6.2% of a radiologist’s work \nshift [1]. Each institution customizes its protocols based on \nfactors such as the availability of MRI machines, exami-\nnation time constraints, and the specific needs of other \n * Lara Noelle Reiner \n lara.reiner@charite.de\n1 Department of Neuroradiology, Charité—\nUniversitätsmedizin Berlin, Augustenburger Platz 1, \n13353 Berlin, Germany\n2 Department of Neuroradiology, Hôpital Maison-Blanche, \nCHU Reims, Université Reims-Champagne-Ardenne, Reims, \nFrance\n3 Berlin Institute of Health at Charité—Universitätsmedizin \nBerlin, Charitéplatz 1, 10117 Berlin, Germany\n4 Department of Radiology, Technical University Munich, \nKlinikum Rechts Der Isar, Ismaninger Str. 22, 81675 Munich, \nGermany\n5 Department or Radiology and Nuclear Medicine, Technical \nUniversity Munich, German Heart Center Munich, \nLazarethstr. 36, 80636 Munich, Germany\n1473La radiologia medica (2025) 130:1472–1482 \nclinical departments, such as radiotherapy or surgery. This \nlack of standardization poses challenges, particularly for \nless experienced physicians [ 2]. Manual protocol selection \nis not only time-consuming but also prone to errors, with \nhigher error rates observed among trainees [3 ]. Moreover, \nthe continuous influx of new MRI orders disrupts radiolo-\ngists' workflow, diverting their attention away from critical \nimage interpretation tasks. To address these challenges, \nseveral studies have explored the automation of protocol \nassignment using artificial intelligence (AI), specifically \nmachine learning techniques [4 –10].\nThe introduction of transformer-based large language \nmodels (LLMs) represents a major advancement in auto-\nmated language processing [11], with their application \nrapidly expanding within the medical field [12]. In radiol-\nogy, LLMs have been particularly explored for summa -\nrizing and simplifying reports, extracting structured data \nfor research purposes and clinical quality assessment [13, \n14], and for translating reports to enhance cross-linguistic \npatient care [15]. LLM-based predictions of certain radiol-\nogy protocol categories have been investigated, but studies \nhave largely excluded specific MRI protocols and their \nvaried sequences [16].\nDue to their autoregressive nature, LLMs are prone \nto generating responses that sound convincing but \nare inaccurate, a phenomenon termed hallucination. \nThis is particularly problematic in the healthcare sec-\ntor, where hallucination can negatively affect patient \nhealth. Retrieval-augmented generation (RAG) is a novel \napproach that helps mitigate this issue, by providing the \nLLMs with additional context. Specifically, an external \ndatabase, composed of custom text data, is queried, and \nthe most relevant information for the task is retrieved—\nsimilarly to a search engine—and passed to the model, \nallowing the generation of context-specific responses [17 ]. \nThis technique is particularly suitable for medical tasks \nwhere the required information is not necessarily available \nin the models initial training data, and where diagnostic \nand treatment guidelines are continuously evolving. New \ninsights can be easily added to the database and does not \nrequire a retraining of the model, contrary to machine \nlearning models.\nThe use of RAG in medicine has been investigated in \nstudies spanning from answering disease-specific ques-\ntions to recalling guideline information and providing \nguideline-specific recommendations, with promising \nresults [18– 22].\nThis study aims to evaluate the performance of LLMs \nin assigning MRI protocols based on patients’ clinical \nquestions in neuroradiology. It compares the accuracy \nof responses between an open-source and a proprietary \nmodel and examines whether incorporating RAG improves \naccuracy within the same model.\nMaterial and methods\nPopulation\nFor this retrospective study, MRI examination reports \nwere obtained from the Department of Neuroradiology at \na university hospital. The study was approved by the ethics \ncommittee of the university (No. EA4/062/20). The need \nfor informed consent was waived due to the retrospec-\ntive nature of the research. From a total of 13,960 reports \nfrom examinations conducted in 2023, a random sample \nof 128 reports was drawn using the Radiology Informa -\ntion System (RIS) with a fixed random state of 42. This \nrandomized selection minimized selection bias caused by \nclustering based on disease patterns or the ordering physi-\ncian in consecutive MRI orders. Selected reports included \nexaminations performed between January 3, 2023, and \nDecember 20, 2023. All reports pertained to neuroradio-\nlogical patients who underwent uninterrupted MRI exami-\nnations of the brain or spine, serving as the inclusion cri-\nteria for this study. Exclusion criteria and corresponding \nnumbers are detailed in Fig.  1. MRI examinations were \nconducted with 12 different MRI devices: four with 1.5 T \nMAGNETOM Aera and eight with 3 T MAGNETOM \nSkyra (Siemens, Munich, Germany). The administered \ncontrast media were Gadovist® (Bayer, Leverkusen, Ger -\nmany) or Dotarem® (Guerbet, Villepinte, France). Data \ncollection adhered to the ethical standards of the Decla-\nration of Helsinki, following strict clinical research data \nFig. 1  Report Selection Process. A fully conducted MRI examina-\ntion with a neuroradiological question served as inclusion criteria \nfor this study. Exclusion criteria included early examination termina-\ntion, the use of specific study protocols or requirement of one specific \nsequence, and patients under the age of 17, as all neuroradiological \nexaminations for this age group follow pediatric MRI protocols\n1474 La radiologia medica (2025) 130:1472–1482\nprotection guidelines. Patient data were anonymized to \nensure privacy and confidentiality, following strict clini-\ncal research data protection guidelines, and no identifiable \npatient information was shared with the AI system.\nData extraction\nThe RIS dataset was provided as a.csv file containing \npatients’ demographic data, MRI device names and the \ncorresponding report. Key information, including symp-\ntoms, indication, clinical question, and imaging procedure, \nwas extracted from the report using regular expression-\nbased text extraction. The device column was renamed to \nindicate magnetic field strength due to differences between \n1.5 T and 3 T protocols. Data extraction was performed in \nPython (Vers.: 3.12.3, [23]) using the NumPy and Pandas \npackage (Versions: 1.26.4 and 1.5.3, respectively).\nThe current protocol guidelines used by the Department \nof Neuroradiology were provided in a portable document \nformat (PDF) file. To facilitate their use in the RAG sys-\ntem, manual basic formatting adjustments were applied to \nthe document, which contains 63 different MRI protocols.\nEstablishment of ground truth\nTo establish the ground truth, a neuroradiologist with \n13 years of experience (J.S.) reviewed all clinical questions \nand selected the appropriate MRI protocol for each patient \nbased on protocol guidelines.\nFor the comparison of models and radiologists, two \nboard-certified general radiologists with seven years of \nexperience (S.G., J.N.) and two first-year radiology residents \n(F.A., L.F.) completed the same task. The study design is \noutlined in Fig. 2.\nModels\nWe used OpenAI’s GPT-4o (Version gpt-4o-2024–08-06) \nas a proprietary model and Meta’s LLaMA 3.1 405B as an \nopen-source model, both based on the GPT architecture. \nGPT-4o, OpenAI’s latest model, released on May 13, 2024, \nsupports up to 128,000 tokens in context, with an estimated \nparameter size of around 1.8 trillion [24]. Meta’s LLaMA \n3.1 405B, released on July 23, 2024, also supports 128,000 \ntokens and has 405 billion parameters, making it the largest \nopen-source model available at the time [25].\nFig. 2  Study Design. The clinical question and MRI device data \nwere extracted from MRI reports and provided to an experienced neu-\nroradiologist (J.S., 13 years of experience) for manual protocol selec-\ntion to establish the ground truth. This information was also used as \ninput for the four tested pipelines. Additionally, four radiologists with \nvarying experience levels performed manual protocol selection for \ncomparison. Statistical analysis was conducted to compare the proto-\ncol selections of the large language model and the radiologists against \nthe ground truth\n1475La radiologia medica (2025) 130:1472–1482 \nA single embedding model, OpenAI's \"text-embedding-\nada-002\" [24], was used for both RAG pipelines to ensure \nconsistent retrieval results. LLaMa 3.1 405B was run in a \nnon-quantized format on Replicate [26], which provides the \nnecessary computational resources for large open-source \nmodels.\nRAG‑system\nThis study distinguishes between two workflows: the non-\nRAG scenario and the RAG scenario. Both start with the \npatient's clinical question and aim to predict optimal MRI \nsequences while also determining the need for contrast \nmedium.\nTo set up the RAG-System, the guidelines were first seg-\nmented into paragraphs using the recursive character text \nsplitter function by LangChain, with a maximum chunk \nsize of 400 characters and zero overlap, ensuring the sepa-\nration of the individual MRI protocols. The embedding \nmodel converted each paragraph into a continuous, high-\ndimensional vector representation and stored them in a vec-\ntor database, thereby capturing semantic relationships and \nsimilarities of the text data. The patients’ clinical questions \nwere used to query the data in the vector store. Based on \nsimilarity search, the four most relevant MRI protocols were \nretrieved and subsequently incorporated into the prompt. \nThe constructed setup is depicted in Fig. 3.\nIn the RAG scenario, the model selects the appropriate \nprotocol from the top four retrieved options and outputs \nthe MRI sequences exactly as listed in the protocol. In the \nnon-RAG scenario where no protocols are specified, the \nmodel chooses the MRI sequences from a list that includes \nall sequences mentioned across protocols, ensuring that the \nnames remain consistent despite non-standardized MRI \nsequence naming.\nTo evaluate the model's grasp of medical terminology \nand reasoning, it was also instructed to explain \nabbreviations in the clinical question, identify any \nFig. 3  Combination of Large Language Model and Retrieval-\nAugmented Generation. In the non-retrieval-augmented genera-\ntion (RAG) approach, the clinical question is embedded directly in \nthe prompt, enabling the large language model to predict contrast \nmedium administration and suitable MRI sequences based on our \ninstitution’s standard sequences. RAG extends this process by using \nthe clinical question to query the vector store, which is constructed \nfrom segmented protocols based on our institution-specific guide-\nlines. Through similarity search, the four most relevant protocols are \nretrieved and incorporated into the prompt\n1476 La radiologia medica (2025) 130:1472–1482\nexplicitly mentioned diagnoses, and suggest the three \nmost likely differential diagnoses for the patient.\nThe prompt was presented to all four models in Ger -\nman, with the temperature parameter set to 0.1 to ensure \nlow variability and high reproducibility. Model access \nand RAG implementation were handled via an application \nprogramming interface (API) in Python (Version: 3.12.3, \n[23]) using Replicate (Version: 0.32.1), OpenAI (Version: \n1.37.1) and LangChain packages (Versions: Community: \n0.2.9, Text Splitters: 0.2.2, OpenAI: 0.1.17).\nThe source code for the methods used in this study is \npublicly accessible on GitHub [27].\nStatistical analysis\nThe accuracy of MRI sequence predictions was evaluated \nusing symmetric token-based accuracy. Both the ground \ntruth (GT) sequences and the model’s predictions are \nsplit into individual tokens, each representing one MRI \nsequence (e.g., Axial T1). The metric conducts a bidirec-\ntional comparison between the ground truth and the pre-\ndiction, treating all MRI sequences equally while disre-\ngarding their order. With this approach, both missing and \nsuperfluous MRI sequences negatively affect accuracy.\nBootstrapping, as a statistical resampling method, was \nemployed to estimate the 95% confidence interval for the \naccuracy measurements. This method repeatedly samples \nwith replacement from the original output data to approx-\nimate the metric’s distribution, allowing accurate con-\nfidence interval estimation without excessive, resource-\nconsuming output generation. To assess the agreement \namong raters, while accounting for the possibility of cor -\nrect predictions due to random guessing, Cohen’s kappa \nwas calculated for the radiologists’ protocol selection.\nFor statistical comparison of the LLM outputs and \nradiologists’ protocol selection, the Wilcoxon signed-\nrank test was used for MRI sequences, and McNemar \ntest was employed for contrast medium administration, \nwith P < 0.05 considered indicative for statistical signifi-\ncance. The mean accuracy and standard deviation were \ncalculated for the radiologists’ results to enable a singular \ncomparison.\nDocument retrieval from the vector store, triggered by \nthe query, is considered successful if the target proto-\ncol appears among the top four retrieved protocols, with \nerrors assessed manually.\nStatistical analysis was performed in Python (Version: \n3.12.3, [23]) using the additional packages: Scikit-learn, \nStatsmodels, and SciPy (Versions: 1.5.1, 0.14.3, and \n1.14.0, respectively).\nResults\nStudy population\nAfter exclusion, 100 reports remained for analysis. The data-\nset characteristics, including demographic information and \nthe most commonly selected protocols for the patients in the \nGT, are summarized in Table 1.\nLLM predictions with and without RAG \nThe accuracies for predicting MRI sequences without RAG \nwere 38% (95% CI: 0.35–0.41) for LLaMA 3.1 405B and \n43% (95% CI: 0.4–0.45) for GPT-4o. For contrast medium \nprediction, LLaMa 3.1 405B achieved an accuracy of 77% \n(95% CI: 0.69–0.85), while GPT-4o achieved 79% (95% CI: \n0.71–0.87). When incorporating RAG, LLaMa 3.1 405B \nreached an accuracy of 70% (95% CI: 0.65–0.76) for MRI \nsequence prediction and 94% (95% CI: 0.89–0.98) for con-\ntrast medium prediction. GPT-4o with RAG achieved an \naccuracy of 81% (95% CI: 0.75–0.86) for MRI sequence pre-\ndiction and 92% (95% CI: 0.86–0.97) for contrast medium \nprediction.\nThe implementation of RAG resulted in significantly \nhigher accuracies for sequence prediction and contrast \nmedium administration in both models (Sequence Predic-\ntion: GPT-4o 43%, GPT-4o with RAG 81%, P  < 0.001; \nLLaMA 3.1 38%, LLaMA 3.1 with RAG 70%, P  < 0.001, \nContrast Medium Prediction: GPT-4o 79%, GPT-4o with \nRAG 92%, P  = 0.006, LLaMA 3.1 77%, LLaMA 3.1 with \nRAG 94%, P  < 0.001). Comparing both models, GPT-4o \nyielded significantly higher accuracies in predicting MRI \nsequences (GPT-4o with RAG 81%, LLaMA 3.1 with RAG \n70%, P < 0.001). Conversely, in predicting the administra-\ntion of contrast medium, LLaMA 3.1 showed a marginally \nTable 1   Dataset Characteristics\nSD: Standard Deviation, TIA: Transient Ischemic Attack\nOverall\nAge(Mean Age + SD) 54.2 + 18.41\nWomen (in %) 50\nBrain protocols 98\nSpine protocols 2\nMost common protocols\nTumor-metastases 19\nTumor-Follow-Up 11\nTumor-Early -MRI 9\nInflammation-standard 9\nVascular-infraction/TIA 6\nOthers 46\n1477La radiologia medica (2025) 130:1472–1482 \nsuperior accuracy, but without reaching statistical signifi-\ncance (GPT-4o with RAG 92%, LLaMA 3.1 with RAG 94%, \nP = 0.48).\nProtocol prediction, meaning both predictions for MRI \nsequences and contrast medium administration, of employed \nLLMs and tasked radiologists, in comparison to ground \ntruth, is illustrated in Fig. 4.\nTable 2 presents translated output examples from both \nmodels with RAG, alongside the corresponding GT, for four \nrandomly selected clinical questions.\nProtocol selection of radiologists\nIn protocol selection, Radiology Resident 2 achieved an \naccuracy of 82% (95% CI: 0.76–0.88, κ = 0.67) for MRI \nsequences and 91% (95% CI: 0.85–0.96, κ = 0.78) for \ncontrast medium selection. Radiology Resident 1 achieved \nan accuracy of 81% (95% CI: 0.75–0.86, κ = 0.59) for \nMRI sequences and 91% (95% CI: 0.86–0.96, κ = 0.78) \nfor contrast medium. Radiologist 2 selected protocols \nwith an accuracy of 83% (95% CI: 0.78–0.88, κ = 0.61) for \nMRI sequences and 88% (95% CI: 0.82–0.94, κ = 0.72) for \ncontrast medium. Radiologist 1 had an accuracy of 79% (95% \nCI: 0.74–0.85, κ = 0.56) for MRI sequences and 93% (95% \nCI: 0.88–0.97, κ = 0.83) for contrast medium administration. \nThe calculated mean accuracy for all four radiologists was \n81% ± 0.21 for MRI sequences and 91% ± 0.24 for contrast \nmedium administration.\nWhen comparing these results to GPT-4o with RAG, no \nsignificant differences were found in either task (Sequences: \nRadiologists 81%, GPT-4o with RAG 81%, P  = 0.89; Con-\ntrast Medium: Radiologists 91%, GPT-4o with RAG 92%, \nP = 0.48). Similarly, radiologists and LLaMA 3.1 had no \nsignificant difference in contrast medium prediction (Radi-\nologists 91%, LLaMA 3.1 94%, P  = 0.48). However, radi-\nologists achieved significantly higher accuracy in sequence \nprediction (Radiologists 81%, LLaMA 3.1 70%, P < 0.001).\nRAG‑system\nThe RAG system correctly retrieved protocols for 81 out of \n100 clinical questions using GPT-4o and 78 using LLaMA \n3.1. Most retrieval errors were due to the selection of overly \nspecific protocols. In these cases, vague clinical questions \nrequired general protocols capable of addressing multiple \ndifferential diagnoses, but the system retrieved disease-\nspecific protocols focused on a single symptom or condition. \nErrors involving confusion between protocols within the \nsame category (e.g., tumor follow-up vs. recurrence) were \nclassified as ‘incorrect protocol within the correct subgroup’. \nAdditional errors included misinterpretation of medical \nterminology, confusion between brain and spine protocols, \nFig. 4  Accuracies of Protocol Prediction. Error bars indicate the respective 95% confidence interval (CI). LLM = Large Language Model\n1478 La radiologia medica (2025) 130:1472–1482\nTable 2  Output Examples of Large Language Models and Gold Standard\nRed Incorrect; Green Correct\nTo ensure transparency, we present examples of generated responses to four clinical questions from both large language models, translated into \nEnglish. For sequence and contrast medium selection, the Gold Standard answer is provided for comparison. Color coding indicates output accu-\nracy—green for alignment and red for misalignment with the Gold Standard. RAG = Retrieval-Augmented Generation\n1479La radiologia medica (2025) 130:1472–1482 \nand retrieval driven by prior diagnoses rather than the \npatient’s current symptoms. A detailed breakdown of error \ntypes is provided in Table 3.\nDiscussion\nThe automation of radiology protocol assignment holds sig-\nnificant potential to reduce the daily workload of radiolo-\ngists while maintaining safety and high quality care. In this \nstudy, we evaluated the capabilities of retrieval-augmented \nopen-source and proprietary LLMs to predict MRI protocol \nassignments in neuroradiological practice.\nThe use of RAG led to a significant increase in sequence \nprediction accuracy for LLaMa 3.1 405B from 38 to 70% \n(P < 0.001) and for GPT-4o from 43 to 81% (P < 0.001), \nachieving at least a 1.8-fold improvement compared to per-\nformance without RAG. OpenAI’s GPT-4o demonstrated \nsignificantly superior accuracy compared to the open-source \nmodel for MRI sequence prediction (P  < 0.001) achieving \nlevels comparable to those of radiologists (P = 0.89).\nSeveral studies have explored automating MRI protocol \nselection using machine learning [ 4–9]. Research incorpo -\nrating protocols across all body regions or focusing solely \non musculoskeletal imaging achieved similar accuracies \n(83–87%) using convolutional neural networks or support \nvector machines [4 –7]. In neuroradiology, Brown et al. \nidentified gradient boosting machines as the most effective \nmodel with 95% accuracy, while Chillakuru et al. employed \nnatural language processing (fastText, XGBoost), achieving \n83% accuracy for spine and 85% for brain MRI. However, \ntask complexity varies significantly across studies. While we \nincorporated the full neuroradiological set of 63 protocols, \nothers included solely two to nine protocols, which does not \nreflect the complexity in clinical routine [4, 8]. Importantly, \nour approach preserved the original clinical question format \nencountered by radiologists, leveraging the free-text pro-\ncessing capabilities of LLMs. In contrast, previous studies \nrequired preprocessing to accommodate free-text input with \nmachine learning models. However, free-text input of clini-\ncal indication is crucial, since protocol selection cannot rely \nsolely on admitting diagnoses or extracted features, as they \nlack sufficient clinical detail [28]. Despite these complexi-\nties, GPT-4o's sequence selection accuracy, when combined \nwith RAG, reached 81%, which is comparable to the results \nof Chillakuru et al. While their errors tended to select overly \ngeneral protocols, our model’s errors were primarily due to \noverly specific choices. The key limitation across all of these \nstudies is the challenge machine learning models face in gen-\neralizing due to non-standardized MRI sequence nomencla-\nture and institution-specific protocols. Frequent equipment \nupdates and evolving protocol guidelines further necessitate \nperiodic model retraining—a process that requires expert \ninput, time, and training-associated costs, making it difficult \nfor these models to adapt seamlessly to new information.\nGertz et al. investigated GPT-4’s ability to predict the \nappropriate imaging modality based on clinical questions, \nachieving an overall accuracy of 84% in identifying imaging \nmodality (X-ray, scintigraphy, CT, MRI), anatomical \nregion, and contrast phase [16 ]. However, their model did \nnot address specific MRI protocols or sequences in detail. \nOur study advances this work by automating MRI protocol \nassignment across a wide range of institution-specific \nprotocols, achieving high accuracy in retrieving detailed \nprotocol information.\nKim et al. investigated the automation of MRI protocol \nassignment in neuroradiology using LLMs alone. In a study \ndesign similar to ours, both open-source and proprietary \nLLMs were tasked with assigning MRI protocols, with and \nwithout access to external medical knowledge. However, \ninstead of using RAG, their study employed in-context \nlearning by supplying institutional MRI protocols and cor -\nresponding explanations directly within the prompt. Overall, \nOpenAI’s o3-mini achieved the highest performance, fol-\nlowed by GPT-4o and the open-access models DeepSeek-R1 \nand Qwen-2.5-72B. In line with our findings, incorporating \nexternal knowledge enhanced the accuracy of all evaluated \nmodels. In-context learning emerges as an alternative to \nRAG, as the context windows of LLMs continue to expand \n[10]. However, this approach substantially increases the \ntoken count, resulting in longer inference times, higher \ncomputational costs and energy consumption. Moreover, \nRAG offers greater transparency by enabling objective \ntraceability of the source documents used in generating the \nLLM’s response. This helps mitigate the commonly cited \n'black box' limitation of LLMs [29]. Given the importance \nof time-efficiency and source traceability in clinical settings, \nTable 3  Error-Evaluation of Document Retrieval\nOverly specific protocols = vague clinical question requires a general \nprotocol for broad differential diagnoses, disease-specific protocols \nare chosen instead; Incorrect protocol in the correct subgroup = con-\nfusion between protocols within the same category (e.g., tumor fol-\nlow-up vs. recurrence); Misunderstanding of medical terms = misin-\nterpretation of medical language; Incorrect body region = brain and \nspine protocols mistakenly interchanged; Protocol retrieval based on \npre-diagnosis = focus on past diagnosis rather than current symptoms; \nRAG = Retrieval-Augmented Generation\nType of error in document retrieval LLaMA 3.1 \n405B with \nRAG \nGPT-4o \nwith \nRAG \nOverly specific protocols 10 8\nIncorrect protocol in the correct subgroup 5 4\nMisunderstanding of medical terms 4 4\nIncorrect body region 2 2\nProtocol retrieval based on pre-diagnosis 1 1\n1480 La radiologia medica (2025) 130:1472–1482\nRAG-based approaches demonstrate greater practical appli-\ncability in healthcare than LLMs alone.\nRAG, as an innovative approach, is rapidly advancing in \nthe medical field [29], demonstrating high accuracy in vari-\nous tasks, such as disease-specific treatment recommenda-\ntions [18, 21], guideline-based clinical decision support [19, \n20], and radiology-specific queries [22]. For instance, Ferber \net al. demonstrated RAG’s effectiveness in oncology treat-\nment decision-making, observing an accuracy increase from \n57 to 84% when implemented with GPT-4. This underscores \nRAG’s potential for significantly enhancing LLM-powered \ndecision-support systems in complex clinical settings. \nSimultaneously, RAG remains an active area of research, \nwith ongoing advances in architectures aimed at improv -\ning retrieval accuracy and overall model performance. \nAgentic RAG introduces multi-step, iterative use of LLMs \nto enhance planning, reflection, and reasoning [30 ], while \nhybrid search improves retrieval by combining semantic and \nkeyword-based search [31]. Both developments hold particu-\nlar promise for optimizing RAG applications in healthcare.\nUnlike prior studies comparing open-source and propri-\netary models, LLaMa 3.1 405B, the open-source model used \nin this study, performed significantly worse on the main task \n[32, 33]. Previous research has often confined LLMs to mul-\ntiple-choice questions within structured frameworks, while \nour study used a more open-ended approach, increasing \nthe complexity of the decision-making process. This sug-\ngests that as task complexity increases, the performance gap \nbetween open-source and proprietary models may widen. \nHowever, proprietary models cannot be deployed locally, \nwhich presents a notable limitation: data privacy challenges \nrestrict their clinical applicability, as patient data requires \nthorough de-identification—a complex process—prior to \nuse [33]. Encouragingly, advancements in data privacy or \nimprovements of open-source LLMs may soon address these \nlimitations.\nData privacy is not the only challenge that must be \naddressed for the clinical application of LLM-based tools. \nHallucination remains a significant concern [29], although \nstrategies such as RAG have been shown to mitigate this \nissue and demonstrably reduce its occurrence. Prediction \nerrors in protocol assignment can result in critical findings \nbeing missed during MRI examinations, potentially necessi-\ntating patient recall—an outcome that is both time-consum-\ning, and in the worst case, detrimental to patient health [34]. \nConsequently, AI-based tools used in clinical settings are \nclassified as medical devices and are subject to strict regula-\ntory oversight. A fully autonomous system for radiologists’ \ndecision-making in protocol selection is, therefore, currently \nunattainable. However, a further refined LLM- and RAG-\npowered tool, operating under continued human supervi-\nsion—similar to the proposed integration of the NLP model \n[8]—could offer meaningful support for radiologists.\nOur study has its limitations. First, the retrieval of rel-\nevant documents did not consistently function as intended, \nwhich in some cases prevented the LLM from selecting the \ncorrect protocol. During the study, we addressed this issue \nthrough prompt engineering and by increasing the number of \nretrieved documents, which led to substantial improvements. \nHowever, further optimization is necessary to fully lever -\nage the potential of LLMs—for example, by implementing \nadvanced RAG architectures or enhancing retrieval through \nimproved search techniques such as hybrid search, rather \nthan relying solely on semantic search [30, 31]. Second, \nprotocol selection varies, as radiologists may use different \nbut valid approaches to achieve the same diagnostic goals. \nFor example, a radiologist might choose Protocol 1 and add \nsequences from Protocol 2, an option not allowed in our \nstudy, but could be overcome by instructing the LLM to \nsuggest multiple protocols. Third, the models lacked time \nstamps, and clinical questions sometimes mentioned symp-\ntom onset without specific intervals, complicating decisions \nfor time-sensitive protocols, such as stroke protocols in acute \nor subacute phases. Future studies should integrate tempo-\nral data. Fourth, our results are based on the model’s per -\nformance in protocol assignment in German language, and \ntherefore may not be directly applicable in other languages. \nHowever, previous studies have shown that LLMs achieve \ncomparable task performance in English and German [35]. \nLastly, the small sample size may limit the generalizability \nof our findings.\nConclusion\nMRI protocol assignment is a routine yet time-consuming \nand error-prone task in radiology, highlighting the clinical \nneed for automation. We demonstrated that automated MRI \nprotocoling, using a pipeline that integrates a large language \nmodel with retrieval-augmented generation, achieves high \naccuracy in predicting institution-specific protocols. This \napproach represents a novel solution for automated protocol \nassignment, distinct from previous studies with strong poten-\ntial for long-term, cross-institutional implementation. Given \nthe rapid advancements in computer science and artificial \nintelligence, future research should focus on adapting the \nmodel to emerging technologies, particularly by optimizing \nthe retrieval process. Additionally, investigating the model’s \ntransferability to other imaging modalities and anatomical \nregions would be of significant clinical value.\nAcknowledgements A.M. is a fellow of the BIH Charité Digital Clini-\ncian Scientist Program funded by the Charité—Universitätsmedizin \nBerlin and the Berlin Institute of Health at Charité (BIH), and has \nreceived a research grant from the „Institut d'Intelligence Artificielle \nen Santé“ (IIAS), University of Reims Champagne-Ardenne.\n1481La radiologia medica (2025) 130:1472–1482 \nAuthor contribution L.R. and A.M. designed the study, J.S., L.F., S.G., \nF.A. and J.N. rated the protocols. L.R. conducted the statistical analysis \nand prepared the figures. L.R. and A.M. drafted the manuscript. All \nauthors reviewed the manuscript and approved the final version.\nFunding Open Access funding enabled and organized by Projekt \nDEAL. The authors have not disclosed any funding.\nData availability The source code for the methodology used in this \nstudy is available on GitHub (https:// github. com/ laran oelle reiner/  \nLLM_ RAG_ Neuro radio logy). The research data are not publicly avail-\nable. However, inquiries regarding the analyzed data can be directed to \nthe corresponding author.\nDeclarations \nConflict of interest The authors declare no conflict of interests.\nEthical approval The study was conducted in accordance with the lat-\nest version of the Declaration of Helsinki. The study was approved by \nthe ethics committee of the university (No. EA4/062/20). The need \nfor informed consent was waived due to the retrospective nature of \nthe research.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Schemmel A et al (2016) Radiology workflow disruptors: a \ndetailed analysis. J Am Coll Radiol 13(10):1210–1214. https://  \ndoi. org/ 10. 1016/j. jacr. 2016. 04. 009\n 2. Bjaalie JG et al (2021) Magnetic resonance imaging sequence \nidentification using a metadata learning approach. Metadata Learn \nApproach Front Neuroinform. https:// doi. org/ 10. 3389/ fninf. 2021. \n622951\n 3. Ginat DT, Uppuluri P, Christoforidis G, Katzman G, Lee SK \n(2016) Identification of neuroradiology MRI protocol errors \nvia a quality-driven categorization approach. J Am Coll Radiol \n13(5):545–548. https:// doi. org/ 10. 1016/j. jacr. 2015. 08. 027\n 4. Lee YH (2018) Efficiency improvement in a busy radiology \npractice: determination of musculoskeletal magnetic resonance \nimaging protocol using deep-learning convolutional neural net-\nworks. J Digit Imaging 31(5):604–610. https:// doi. org/ 10. 1007/ \ns10278- 018- 0066-y\n 5. López-Úbeda P, Díaz-Galiano MC, Martín-Noguerol T, Luna A, \nUreña-López LA, Martín-Valdivia MT (2021) Automatic medical \nprotocol classification using machine learning approaches. Com-\nput Methods Programs Biomed. https:// doi. org/ 10. 1016/j. cmpb. \n2021. 105939\n 6. Kalra A, Chakraborty A, Fine B, Reicher J (2020) Machine \nlearning for automation of radiology protocols for quality and \nefficiency improvement. J Am Coll Radiol 17(9):1149–1158. \nhttps:// doi. org/ 10. 1016/j. jacr. 2020. 03. 012\n 7. Nencka AS, Sherafati M, Goebel T, Tolat P, Koch KM, (2021) \n“Deep-learning based Tools for Automated Protocol Definition \nof Advanced Diagnostic Imaging Exams,” [Online]. Available: \nhttp:// arxiv. org/ abs/ 2106. 08963\n 8. Chillakuru YR et al (2021) Development and web deployment of \nan automated neuroradiology MRI protocoling tool with natural \nlanguage processing. BMC Med Inform Decis Mak 21:25. https:// \ndoi. org/ 10. 1186/ s12911- 021- 01574-y\n 9. Brown AD, Marotta TR (2018) Using machine learning for \nsequence-level automated MRI protocol selection in neuroradi-\nology. J Am Med Inform Assoc 25(5):568–571. https:// doi. org/  \n10. 1093/ jamia/ ocx125\n 10. Kim SH et al (2025) “Evaluating Large Language Model-Gen-\nerated Brain MRI Protocols: Performance of GPT4o, o3-mini, \nDeepSeek-R1 and Qwen2.5–72B,” https:// doi. org/ 10. 1101/ 2025. \n04. 08. 25325 433\n 11. Vaswani A et al. (2017) “Attention is All you Need,” Neural Infor-\nmation Processing Systems, https:// doi. org/ 10. 48550/ arXiv. 1706. \n03762\n 12. Meng X et al (2024) The application of large language models in \nmedicine: A scoping review. iscience 27:109713. https:// doi. org/ \n10. 1016/J. ISCI. 2024. 109713\n 13. Meddeb A et al (2024) Evaluating local open-source large lan-\nguage models for data extraction from unstructured reports on \nmechanical thrombectomy in patients with ischemic stroke. J \nNeurointerv Surg. https:// doi. org/ 10. 1136/ JNIS- 2024- 022078\n 14. Elkassem AA, Smith AD (2023) Potential use cases for ChatGPT \nin radiology reporting. AJR Am J Roentgenol 221(3):373–376. \nhttps:// doi. org/ 10. 2214/ AJR. 23. 29198\n 15. Meddeb A et al (2024) Large language model ability to translate \nCT and MRI free-text radiology reports into multiple languages. \nRadiology 313(3):e241736. https:// doi. org/ 10. 1148/ RADIOL. \n241736\n 16. Gertz RJ et al (2023) GPT-4 for automated determination of radio-\nlogic study and protocol based on radiology request forms: A \nfeasibility study. Radiology 307:25. https:// doi. org/ 10. 1148/ radiol. \n230877\n 17. Miao J, Thongprayoon C, Suppadungsuk S, Garcia Valencia \nOA, Cheungpasitporn W (2024) Integrating retrieval-augmented \ngeneration with large language models in nephrology: advancing \npractical applications. Medicina 60(3):445\n 18. Zhou Q et al (2024) GastroBot: a Chinese gastrointestinal disease \nchatbot based on the retrieval-augmented generation. Front Med \n(Lausanne). https:// doi. org/ 10. 3389/ fmed. 2024. 13925 55\n 19. Ferber D et al (2024) GPT-4 for Information Retrieval and Com-\nparison of Medical Oncology Guidelines. NEJM AI. https:// doi.  \norg/ 10. 1056/ AICS2 300235\n 20. Kresevic S, Giuffrè M, Ajcevic M, Accardo A, Crocè LS, Shung \nDL (2024) Optimization of hepatological clinical guidelines \ninterpretation by large language models: a retrieval augmented \ngeneration-based framework. NPJ Digit Med 7:25. https:// doi. org/ \n10. 1038/ s41746- 024- 01091-y\n 21. Ge J et al (2024) Development of a liver disease-specific large \nlanguage model chat interface using retrieval-augmented genera-\ntion. Hepatology 25:26. https:// doi. org/ 10. 1097/ HEP. 00000 00000 \n000834\n 22. S. T. Arasteh et al. (2024) “RadioRAG: Factual large language \nmodels for enhanced diagnostics in radiology using dynamic \nretrieval augmented generation,” Accessed: Oct. 28, 2024. \n[Online]. https:// doi. org/ 10. 48550/ arXiv. 2407. 15621\n 23. Python, “Python, https:// www. python. org/”.\n 24. OpenAI, “GTP-4o, GPT-3.5, OpenAI Embeddings, https:// platf  \norm. openai. com/ docs/ models.”\n1482 La radiologia medica (2025) 130:1472–1482\n 25. Meta, “Llama 3.1 405B, https:// www. llama. com/ llama- downl \noads/”.\n 26. Replicate, “Replicate, https:// repli cate. com/ terms”.\n 27. GitHub, “GitHub, https:// github. com/ laran oelle reiner/ LLM_ \nRAG_ Neuro radio logy”.\n 28. Denck J, Haas O, Guehring J, Maier A, Rothgang E (2022) \nAutomated protocoling for MRI exams—challenges and solu-\ntions. J Digit Imaging 35(5):1293–1302. https:// doi. org/ 10. 1007/ \ns10278- 022- 00610-1\n 29. Yang R et al (2025) Retrieval-augmented generation for generative \nartificial intelligence in health care. npj Health Systems 2:1–5\n 30. Singh A, Ehtesham A, Kumar S, Khoei TT (2025) “Agentic \nretrieval-augmented generation: a survey on agentic RAG,” 2025, \nAccessed: May 21, [Online], https:// doi. org/ 10. 48550/ arXiv. 2501. \n09136\n 31. “Blended RAG (2025) Improving RAG (Retriever-Augmented \nGeneration) Accuracy with Semantic Search and Hybrid Query-\nBased Retrievers”, Accessed: May 21, [Online], https:// doi. org/ \n10. 48550/ arXiv. 2404. 07220\n 32. Longwell JB et al (2024) Performance of large language mod-\nels on medical oncology examination questions key points + \nsupplemental content. JAMA Netw Open 7(6):2417641. https://  \ndoi. org/ 10. 1001/ jaman etwor kopen. 2024. 17641\n 33. Mukherjee P, Hou B, Lanfredi RB, Summers RM (2023) Feasibil-\nity of using the privacy-preserving large language model vicuna \nfor labeling radiology reports. Radiology. https:// doi. org/ 10. 1148/ \nradiol. 231147\n 34. Liles AL, Francis IR, Kalia V, Kim J, Davenport MS (2020) Com-\nmon causes of outpatient CT and MRI callback examinations: \nopportunities for improvement. Am J Roentgenol 214(3):487–492. \nhttps:// doi. org/ 10. 2214/ AJR. 19. 21839\n 35. Z. Li et al. (2025) “Language Ranker: A metric for quantifying \nLLM performance across high and low-resource languages,” \nAccessed: May 21, [Online], https:// doi. org/ 10. 48550/ arXiv. 2404. \n11553\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Neuroradiology",
  "concepts": [
    {
      "name": "Neuroradiology",
      "score": 0.7566772699356079
    },
    {
      "name": "Medicine",
      "score": 0.6946905255317688
    },
    {
      "name": "McNemar's test",
      "score": 0.637704610824585
    },
    {
      "name": "Contrast (vision)",
      "score": 0.610069215297699
    },
    {
      "name": "Wilcoxon signed-rank test",
      "score": 0.5786765217781067
    },
    {
      "name": "Protocol (science)",
      "score": 0.5699239373207092
    },
    {
      "name": "Magnetic resonance imaging",
      "score": 0.4146701395511627
    },
    {
      "name": "Radiology",
      "score": 0.3738057315349579
    },
    {
      "name": "Nuclear medicine",
      "score": 0.32674750685691833
    },
    {
      "name": "Computer science",
      "score": 0.21623161435127258
    },
    {
      "name": "Internal medicine",
      "score": 0.20528548955917358
    },
    {
      "name": "Artificial intelligence",
      "score": 0.18466410040855408
    },
    {
      "name": "Mann–Whitney U test",
      "score": 0.1642880141735077
    },
    {
      "name": "Pathology",
      "score": 0.15960904955863953
    },
    {
      "name": "Statistics",
      "score": 0.10085263848304749
    },
    {
      "name": "Mathematics",
      "score": 0.09691980481147766
    },
    {
      "name": "Neurology",
      "score": 0.09180891513824463
    },
    {
      "name": "Alternative medicine",
      "score": 0.0
    },
    {
      "name": "Psychiatry",
      "score": 0.0
    }
  ]
}