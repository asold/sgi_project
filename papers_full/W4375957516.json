{
  "title": "Augmenting Passage Representations with Query Generation for Enhanced Cross-Lingual Dense Retrieval",
  "url": "https://openalex.org/W4375957516",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5012958162",
      "name": "Shengyao Zhuang",
      "affiliations": [
        "The University of Queensland"
      ]
    },
    {
      "id": "https://openalex.org/A5077262995",
      "name": "Linjun Shou",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5076031002",
      "name": "Guido Zuccon",
      "affiliations": [
        "The University of Queensland"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6832427677",
    "https://openalex.org/W3185042171",
    "https://openalex.org/W4284680461",
    "https://openalex.org/W3171975879",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2963096510",
    "https://openalex.org/W3039695075",
    "https://openalex.org/W6601899773",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W6600291067",
    "https://openalex.org/W4225338712",
    "https://openalex.org/W4225727172",
    "https://openalex.org/W3184918446",
    "https://openalex.org/W3045958725",
    "https://openalex.org/W3156836409",
    "https://openalex.org/W4226112939",
    "https://openalex.org/W3168875417",
    "https://openalex.org/W4385573019",
    "https://openalex.org/W6607599472",
    "https://openalex.org/W3206455169",
    "https://openalex.org/W4284699573",
    "https://openalex.org/W4287887143",
    "https://openalex.org/W4200635123",
    "https://openalex.org/W3175980629",
    "https://openalex.org/W4309698332",
    "https://openalex.org/W4224983763",
    "https://openalex.org/W3210968241",
    "https://openalex.org/W3155895380",
    "https://openalex.org/W4284704885",
    "https://openalex.org/W4225319197",
    "https://openalex.org/W2069065514",
    "https://openalex.org/W3212422886",
    "https://openalex.org/W3197464301"
  ],
  "abstract": "Effective cross-lingual dense retrieval methods that rely on multilingual\\npre-trained language models (PLMs) need to be trained to encompass both the\\nrelevance matching task and the cross-language alignment task. However,\\ncross-lingual data for training is often scarcely available. In this paper,\\nrather than using more cross-lingual data for training, we propose to use\\ncross-lingual query generation to augment passage representations with queries\\nin languages other than the original passage language. These augmented\\nrepresentations are used at inference time so that the representation can\\nencode more information across the different target languages. Training of a\\ncross-lingual query generator does not require additional training data to that\\nused for the dense retriever. The query generator training is also effective\\nbecause the pre-training task for the generator (T5 text-to-text training) is\\nvery similar to the fine-tuning task (generation of a query). The use of the\\ngenerator does not increase query latency at inference and can be combined with\\nany cross-lingual dense retrieval method. Results from experiments on a\\nbenchmark cross-lingual information retrieval dataset show that our approach\\ncan improve the effectiveness of existing cross-lingual dense retrieval\\nmethods. Implementation of our methods, along with all generated query files\\nare made publicly available at https://github.com/ielab/xQG4xDR.\\n",
  "full_text": "Augmenting Passage Representations with Query Generation\nfor Enhanced Cross-Lingual Dense Retrieval\nShengyao Zhuang\nThe University of Queensland\nBrisbane, QLD, Australia\ns.zhuang@uq.edu.au\nLinjun Shou\nMicrosoft STCA\nBeijing, China\nlisho@microsoft.com\nGuido Zuccon\nThe University of Queensland\nBrisbane, QLD, Australia\ng.zuccon@uq.edu.au\nABSTRACT\nEffective cross-lingual dense retrieval methods that rely on multi-\nlingual pre-trained language models (PLMs) need to be trained\nto encompass both the relevance matching task and the cross-\nlanguage alignment task. However, cross-lingual data for training\nis often scarcely available. In this paper, rather than using more\ncross-lingual data for training, we propose to use cross-lingual\nquery generation to augment passage representations with qu-\neries in languages other than the original passage language. These\naugmented representations are used at inference time so that the\nrepresentation can encode more information across the different\ntarget languages. Training of a cross-lingual query generator does\nnot require additional training data to that used for the dense re-\ntriever. The query generator training is also effective because the\npre-training task for the generator (T5 text-to-text training) is very\nsimilar to the fine-tuning task (generation of a query). The use of\nthe generator does not increase query latency at inference and can\nbe combined with any cross-lingual dense retrieval method. Results\nfrom experiments on a benchmark cross-lingual information re-\ntrieval dataset show that our approach can improve the effectiveness\nof existing cross-lingual dense retrieval methods. Implementation of\nour methods, along with all generated query files are made publicly\navailable at https://github.com/ielab/xQG4xDR.\nCCS CONCEPTS\nâ€¢ Information systems â†’Query representation ; Language\nmodels.\nKEYWORDS\nCross-lingual query generation; Cross-lingual retrieval; Dense re-\ntriever\nACM Reference Format:\nShengyao Zhuang, Linjun Shou, and Guido Zuccon. 2023. Augmenting\nPassage Representations with Query Generation for Enhanced Cross-Lingual\nDense Retrieval. InProceedings of the 46th International ACM SIGIR Conference\non Research and Development in Information Retrieval (SIGIR â€™23), July\n23â€“27, 2023, Taipei, Taiwan. ACM, New York, NY, USA, 6 pages. https:\n//doi.org/10.1145/3539618.3591952\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\nÂ© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9408-6/23/07. . . $15.00\nhttps://doi.org/10.1145/3539618.3591952\n1 INTRODUCTION\nPre-trained language model-based (PLM) dense retrievers (DRs)\nhave achieved remarkable success in the task of English-only passage\nretrieval [12â€“14, 20, 21, 26, 28, 29, 40, 43, 44]. These models use a\ndual-encoder architecture that encodes both queries and passages\nwith a PLM encoder into dense embeddings. They then perform\napproximate nearest neighbor (ANN) searching in the embedding\nspace. Compared to traditional bag-of-words approaches, DRs benefit\nfrom semantic soft matching, which helps overcome the problem\nof word mismatch in passage retrieval [33, 45].\nTo leverage the semantic modelling power of DRs, recent research\nhas extended English-only DRs to support cross-lingual settings [1,\n2, 19, 22, 27, 31], i.e, where queries and passages are in different\nlanguages. This is achieved using multi-lingual PLMs, such as mul-\ntilingual BERT [ 6], in place of the English-only PLMs. This ap-\nproach is particularly important in this setting where traditional\nbag-of-words methods are ineffective due to the limited number\nof matching terms across languages. In contrast, cross-lingual DRs\n(xDRs) are able to encode queries and passages in different languages\ninto a shared embedding space, enabling efficient ANN search\nacross languages. However, such multi-lingual PLM-based xDRs\nusually are less effective on the cross-lingual passage retrieval task\nthan DRs in the English-only setting [1]. The hypothesis to explain\nthis result is that, in the English-only setting, a DR only needs to\nlearn relevance matching between queries and passages. In contrast,\na xDR not only needs to learn the relevance matching task, but\nalso needs to learn how to align the embeddings of texts with\nsimilar semantic meaning but in different language [24, 41]. It is\nthis language gap that makes cross lingual retrieval a relatively\nharder task for xDRs.\nBased on this hypothesis, this paper proposes the use of cross-\nlingual query generation (xQG) to bridge the language gap for xDRs.\nOur approach is illustrated in Figure 1. Specifically, we fine-tune a\nmultilingual T5 (mT5) model using language-specific prompts to\ngenerate several queries per passage for each target language. In\nthe indexing phase, we use a given xDR model to encode passages\nand their associated generated queries in different languages into\nembeddings. Finally, we augment the original passage embeddings\nwith the embeddings of the generated queries before adding them\nto the ANN index. By doing so, we move the passage embeddings\nto a space that is closer to the target user query language. Our\napproach does not add extra query latency and can be applied to\nany existing xDRs.\n2 RELATED WORKS\nCross-lingual dense retrievers.The development of cross-lingual\npre-trained language models has significantly contributed to the\narXiv:2305.03950v1  [cs.IR]  6 May 2023\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Shengyao Zhuang, Linjun Shou, and Guido Zuccon\nFigure 1: Augmenting passage representations with cross-lingual generated query embeddings. The query examples shown in this figure were\ngenerated using our trained xQG model. For each query, we report the corresponding translation obtained using Googleâ€™s translation service.\nprogress of cross-lingual dense retrieval (xDR) [4, 5, 8, 39]. Notable\nexamples of recent xDR methods include CORA [2], which employs\na generator to facilitate retrieval training data mining, Sentri [31],\nwhich proposes a single encoder and self-training, and DR.DECR [19],\nwhich utilizes parallel queries and sentences for cross-lingual knowl-\nedge distillation. Among these, our work is most closely related\nto QuiCK [27], which also utilizes a cross-lingual query generator\nfor xDR. However, unlike QuiCK, which uses the xQG as a teacher\nmodel in knowledge distillation for xDR in the training phase, our\nmethod directly augments passage embeddings with xQG queries\nwithout any xDR training involved.\nQuery generation for information retrieval.Query generation\nis a well-established technique that has been widely used to improve\nretrieval performance in various retrieval models [11, 25]. In addition,\nit has been shown to be effective for domain adaptation in dense\npassage retrieval tasks [ 23, 32, 34], as well as for enhancing the\neffectiveness of other PLM-based rankers [37, 48]. In our approach,\nwe also rely on a query generation model to generate high-quality\nqueries for downstream passage embedding augmentation tasks.\nAugmenting embeddings for dense retrievers.Our method\nrelies on effectively augmenting representations encoded by DR\nencoders â€“ a direction recently explored also by other works. For\ninstance, Li et al. [16, 17] use the top retrieved passages as pseudo-\nrelevant feedback to augment query embeddings using the Rocchio\naggregation function. Similarly, Zhuang et al. [47] extend this idea\nby using embeddings of clicked passages to augment query em-\nbeddings. Other PRF methods have also been extensively researched\nto enhance both English-only dense retrieval [ 18, 35, 36, 42, 46]\nand cross-lingual dense retrieval [3]. On the other hand, the HyDE\nmethod uses large pre-trained language models to generate hypo-\nthetical passages for a given query and directly uses the embedding\nof the hypothetical passage to perform the search [ 9]. While all\nthese works focus on augmenting query embeddings for DRs at\nquery time, our work focuses on augmenting passage embeddings\nat indexing time , thereby avoiding the extra overhead in terms of\nquery latency.\n3 METHOD\nOur approach consists of two components: (1) a cross-lingual query\ngeneration model that, for each passage, generates high-quality\nqueries in different languages, and (2) an embedding aggregation\nfunction that augments the original passage embedding with the\nembeddings of the generated queries.\nTo obtain a xQG model, we fine-tune a mT5 model with labeled\nrelevant (ğ‘ğ‘¡ , ğ‘)pairs, where ğ‘¡ is the target query language. We use\na seq2seq objective akin to docTquery-T5â€™s objective [25]; in our\ncase the input is the passage text with language-specific prompts:\nprompt (ğ‘¡, ğ‘)= Generate a [ğ‘¡]question for this passage: [ğ‘], (1)\nwhere [ğ‘¡]and [ğ‘]are prompt placeholders for the target language\nand passage text, respectively. Once we have trained a xQG model,\nwe can generate a set of queries for each target language and\npassage by replacing the placeholders accordingly:\nğ‘„ğ‘ =\nÃ˜\nğ‘¡âˆˆğ‘‡\nğ‘„ğ‘¡\nğ‘ ; ğ‘„ğ‘¡\nğ‘ = xQG (prompt (ğ‘¡, ğ‘))Ã— ğ‘›, (2)\nwhere ğ‘‡ is the target language set and ğ‘„ğ‘ is the set of all generated\nqueries for passage ğ‘ which includes ğ‘› generated queries for each\ntarget language. In our experiments, we use a top- ğ‘˜ sampling\nscheme [7] to generate queries, and set ğ‘˜ = 10. We find that these\nsimple language-specific prompts can effectively lead the T5 model\nto generate the desired output in that language.\nFor the embedding aggregation function, we use a Rocchio-\nlike aggregation function that is similar to previous works that\naggregated dense representations [16, 47]. We use this aggregation\nfunction to obtain the embeddings of all passages in the corpus:\nğ‘’ğ‘šğ‘(ğ‘, ğ‘„ğ‘, ğœƒ, ğ›¼)= (1 âˆ’ğ›¼)Â·ğœƒ (ğ‘)+ğ›¼\nâˆ‘ï¸\n^ğ‘ğ‘¡ âˆˆğ‘„ğ‘\nğœƒ (^ğ‘ğ‘¡ ), (3)\nwhere ^ğ‘ğ‘¡ is a generated query for target language ğ‘¡, ğœƒ is the xDR\nencoder model and ğœƒ (.)is the text embedding given by the xDR\nencoder. The hyper-parameter ğ›¼ is the augmentation ratio, ğ›¼ âˆˆ\n[0, 1]. This ratio is used to control the weights assigned to the\noriginal passage embedding and the generated query embeddings.\n4 EXPERIMENTAL SETTINGS\nWe design our experiments to answer the research questions:\nRQ1: How does the number of generated queries affect xDR ef-\nfectiveness?\nRQ2: How does the augmentation ratio ğ›¼ impact xDR effective-\nness?\nRQ3: How do the queries generated for each language impact xDR\neffectiveness?\nDatasets and Evaluation.We train and evaluate our approach on\nXOR-TyDi [1], a cross-lingual open retrieval question answering\nbenchmark dataset. The dataset contains approximately 15k an-\nnotated relevant passage-query pairs in the training set and 2k\npassage-answer pairs in the dev set. Queries in both the train and\ndev sets are in seven typologically diverse languages (Ar, Bn, Fi, Ja,\nKo, Ru, and Te), while passages are in English. There are about 18M\npassages in the corpus. We use the training set to train both the\nAugmenting Passage Representations with Query Generation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\nTable 1: xDR models trained with different backbone PLMs. Zero-shot means trained with only the English subset of the NQ training data\n(thus, zero-shot for the cross-lingual task). Statistical differences against the base model (without xQG) are labelled with â˜… (ğ‘ < 0.05).\n(a) R@2kt\nModel Ar Bn Fi Ja Ko Ru Te Average\nXLM-R 28.5 26.3 29.3 22.4 34.0 17.3 34.9 27.5\nXLM-R + xQG 30.1 29.6 31.2 23.7 36.1 19.4 38.2 29.8â˜…\nmBERT 41.1 49.0 52.2 37.3â˜… 48.1 33.3 47.9 44.1\nmBERT + xQG 42.4 54.9 â˜… 54.1 33.6 52.3â˜… 33.8 52.5 â˜… 46.2â˜…\nmBERT (zero-shot) 32.6 25.0 38.2 29.5 38.9 27.0 39.9 33.0\nmBERT (zero-shot) + XQG 33.9 28.9 â˜… 43.0â˜… 32.8â˜… 41.4 29.5 42.0 36.0â˜…\n(b) R@5kt\nModel Ar Bn Fi Ja Ko Ru Te Average\nXLM-R 38.5 33.6 37.9 32.8 42.8 28.3 47.5 37.3\nXLM-R + xQG 38.8 41.1 â˜… 39.8 32.8 43.2 30.8 49.6 39.4â˜…\nmBERT 49.2 57.6 58.6 42.7 57.5 41.4 55.9 51.8\nmBERT + xQG 51.5 60.9 â˜… 58.3 43.6 58.6 41.4 60.1 â˜… 53.5â˜…\nmBERT (zero-shot) 38.5 36.5 47.5 38.2 48.1 35.0 48.7 41.8\nmBERT (zero-shot) + xQG 43.7â˜… 40.8â˜… 50.0â˜… 40.2 49.8 39.7 â˜… 51.7 45.1â˜…\nxQG model and the xDRs. We evaluate the effectiveness of our ap-\nproach and baselines using recall at ğ‘š kilo-tokens (R@ğ‘škt), which\nis the datasetâ€™s official evaluation metric. This metric computes\nthe fraction of queries for which the minimal answer is contained\nin the top ğ‘š tokens of the retrieved passages. We consider ğ‘š =\n2ğ‘˜, 5ğ‘˜ (R@2kt and R@5kt), as per common practice for this dataset.\nStatistical significant differences are reported with respect to a\ntwo-tailed t-test with Bonferroni correction.\nBaselines. Following common practice on XOR-TyDi [ 1], we\nadapt DPR [14] to the cross-lingual setting by initializing it with\ndifferent multilingual pre-trained language models (PLMs). Specifi-\ncally, in our experiments we use the multilingual variants of BERT [6]\n(mBERT) and XLM-RoBERTa [ 5] (XLM-R) for this purpose. In\naddition to the standard supervised baselines, we also explore how\nour xQG embedding augmentation approach can improve a zero-\nshot xDR model, where the xDR is initialized with mBERT but it\nis trained with English only passage-query pairs and is directly\napplied to the XOR-TyDi cross-lingual retrieval task.\nImplementation details.We initialize our xQG model with the\nmultilingual T5-base checkpoint provided by Google1 and available\nin the Huggingface library [38]. We fine-tune this checkpoint with\nthe passage-query pairs in the XOR-TyDi training set. We train\nthe xQG model for 1600 steps using a batch size of 128 and a\nlearning rate of 1e-4. After training, we generate 5 queries per\npassage for each target language, resulting in about 7 * 5 * 18M\n= 630M generated queries in total. We use four A100 GPUs to\ngenerate all queries; this process took about 70 hours to complete.\nWe release our generated queries on the Huggingface hub 2 to\nallow the community to reuse this resource [30]. For training the\nxDRs, we use the Tevatron dense retriever training toolkit [ 10],\nwhich uses with BM25 hard negative passages. We train the xDRs\nwith a batch size of 128, initializing them with mBERT base 3 or\nXLM-R base4 checkpoints and training them on the XOR-TyDi\ntraining set for 40 epochs. For each training sample, we set the\nnumber of hard negative passages in the contrastive loss to 7 and\napplied in-batch negatives training. We use a learning rate of 1e-5\n1https://huggingface.co/google/mt5-base\n2https://huggingface.co/datasets/ielab/xor-tydi-xqg-augmented\n3https://huggingface.co/bert-base-multilingual-cased\n4https://huggingface.co/xlm-roberta-base\nFigure 2: Impact of the amount of generated queries for target\nlanguage. Scores are averaged across all languages. Statistical\nsignificant improvements over no augmentation (number of qu-\neries ğ‘› = 0) are labelled with stars ( ğ‘ < 0.05).\nfor mBERT-based xDRs and of 2e-5 for XLM-R-based xDRs. For\nthe zero-shot xDR, we use the same training configurations as for\nthe mBERT-based xDR trained on XOR-TyDi but using the Natural\nQuestions (NQ) training data [ 15] which contains English-only\nquery-passage training samples.\n5 RESULTS\n5.1 Main results\nTable 1 presents the effectiveness of xDR models initialized with\nthe XLM-R and mBERT backbone PLMs and trained on the XOR-\nTyDi dataset. Zero-shot denotes the models trained only on the\nEnglish subset of the NQ dataset. In these experiments, we use all\nthe queries generated by our xQG and set the augmentation ratio\nto ğ›¼ = 0.01 for augmenting the passage embeddings of the xDRs.\nFor the R@2kt metric, the xDR initialized with mBERT out-\nperforms the xDR initialized with XLM-R, achieving an average\nR@2kt score of 44.1, while XLM-R achieves an average score of 27.5.\nOur xQG passage embedding augmentation approach improves\nthe XLM-R xDR, achieving an average score of 29.8, which is a\nstatistically significant improvement compared to its baseline effect-\niveness (ğ‘ < 0.05). Similarly, mBERTâ€™s effectiveness improves with\nxQG, achieving an average score of 46.2, which is also a statistically\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Shengyao Zhuang, Linjun Shou, and Guido Zuccon\nFigure 3: Impact of the augmentation ratio ğ›¼. Scores are averaged\nacross all languages. Statistical significant improvements over no\naugmentation (ğ›¼ = 0) are labelled with stars ( ğ‘ < 0.05).\nsignificant improvement compared to its corresponding baseline\n(ğ‘ < 0.05). The zero-shot mBERT model achieves an average R@2kt\nof 33.0; this also improves when combined with xQG, achieving an\naverage score of 36.0. This improvement is statistically significant\n(ğ‘ < 0.05). Similar trends are found for R@5kt. Overall, we find\nthat our xQG can significantly improve all investigated xDR models.\nIn terms of per language effectiveness, xQG improves almost all\nmodels across all languages with the exceptions of mBERTâ€™s R@2kt\nfor Japanese (Ja) and mBERTâ€™s R@5kt for Finnish (Fi).\nIn summary, mBERT performs better than XLM-R for both R@2kt\nand R@5kt. The use of xQG embedding augmentation statistically\nsignificantly improves the effectiveness of both backbones.\n5.2 RQ1: Impact of number of generated\nqueries\nFigure 2 reports the impact of using different amounts of generated\nqueries to augment passage embeddings when using mBERT xDR.\nThe results suggest that using more generated queries is beneficial\nfor both R@2tk and R@5tk. The improvements become statistically\nsignificant when 4 or more generated queries are used for each\ntarget language. While the curves do not plateau, indicating that\nusing even more generated queries could further improve the effect-\niveness, our experiments were limited to up to 5 generated queries\nper target language due to computational constraints.\n5.3 RQ2: Impact of augmentation ratio\nWe report the impact of the augmentation ratio ğ›¼ on the effective-\nness of xDR in Figure 3. Higher values ofğ›¼ correspond to assigning\nmore weight to the generated query embeddings during embedding\naggregation, and ğ›¼ = 0 corresponds to no augmentation. As shown\nin the figure, even a small value of ğ›¼ (0.01) leads to a significant\nimprovement in both R@2kt and R@5kt. The best effectiveness is\nachieved when ğ›¼ = 0.02. However, using higher values ofğ›¼ does\nnot result in further improvements â€“ rather, it can even hurt the\neffectiveness when ğ›¼ > 0.05. Based on these results, we conclude\nthat the augmentation ratio in our embedding aggregation function\nhas a significant impact on the effectiveness of xDR, and using a\nsmall value of ğ›¼ can be beneficial for improving effectiveness.\nFigure 4: R@2kt for target languages (rows) augmented by source\ngenerated queries (columns). We plot ğ›¼ from 0 to 0.1 with step size\nof 0.01 (x axis). Statistically significant better results with respect to\nno augmentation ( ğ›¼ = 0) are labelled with stars ( ğ‘ < 0.05).\n5.4 RQ3: Impact of each languages\nIn the previous experiments we used all the queries generated for a\npassage to augment the original passage embedding, irrespective of\nlanguage of the generated query. Next, we investigate the impact on\neffectiveness of using generated queries from each of the languages\nseparately. We analyze this in Figure 4, where we plot R@2kt for\neach target language (rows) against different values of ğ›¼ (x-axis).\nThe plots in the diagonal show that xDR effectiveness improves\nwhen passage embeddings are augmented with generated queries\nfor the same language. Notably, we observe that the best value ofğ›¼\nvaries across different languages, and the improvements in effective-\nness are not always statistically significant. We also observe that, for\nsome languages, queries generated for other languages can improve\nthe effectiveness of target queries in a different language. For\ninstance, using queries generated for Japanese (Ja) can improve the\neffectiveness of target queries in Korean (ko), while using Russian\n(Ru) generated queries can help target queries in Telugu (Te). These\nresults suggest that the embeddings of the queries generated for\nany single language potentially can also provide useful information\nfor target queries in other languages.\n6 CONCLUSION AND FUTURE WORK\nIn this paper we propose a passage embedding augmentation ap-\nproach to enhance the effectiveness of cross-lingual DRs. Our\nmethod can be applied to any cross-lingual DR and it requires\nno further DR training nor changes to the retrieval pipeline. We\nempirically showed the method is effective for the cross-lingual DPR\nmethod across different backbones. However, a limitation of our\nempirical investigation is that we did not evaluate the method across\nother dense retriever architectures. We leave the extension of this\nAugmenting Passage Representations with Query Generation SIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan\ninvestigation to future work. We also note that our approach relies\non a xQG model that can generate high quality queries. However,\na recent work has shown that T5-based query generation is prone\nto hallucination and that along with highly effective queries, the\ngenerator also produces poor queries that negatively impact re-\ntrieval effectiveness [ 11]. They then propose the use of a cross-\nencoder ranker to filter out some ineffective generated queries; this\npractice can further improve effectiveness. We leave the adaptation\nof this approach in our xQG setting to future work.\nREFERENCES\n[1] Akari Asai, Jungo Kasai, Jonathan H. Clark, Kenton Lee, Eunsol Choi, and\nHannaneh Hajishirzi. 2021. XOR QA: Cross-lingual Open-Retrieval Question\nAnswering. In NAACL-HLT.\n[2] Akari Asai, Xinyan Yu, Jungo Kasai, and Hanna Hajishirzi. 2021. One question\nanswering model for many languages with cross-lingual dense passage retrieval.\nAdvances in Neural Information Processing Systems 34 (2021), 7547â€“7560.\n[3] Ramraj Chandradevan, Eugene Yang, Mahsa Yarmohammadi, and Eugene\nAgichtein. 2022. Learning to Enrich Query Representation with Pseudo-Relevance\nFeedback for Cross-lingual Retrieval. InProceedings of the 45th International ACM\nSIGIR Conference on Research and Development in Information Retrieval . 1790â€“\n1795.\n[4] Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang,\nXia Song, Xian-Ling Mao, He-Yan Huang, and Ming Zhou. 2021. InfoXLM:\nAn Information-Theoretic Framework for Cross-Lingual Language Model Pre-\nTraining. In Proceedings of the 2021 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies .\n3576â€“3588.\n[5] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary,\nGuillaume Wenzek, Francisco GuzmÃ¡n, Ã‰douard Grave, Myle Ott, Luke\nZettlemoyer, and Veselin Stoyanov. 2020. Unsupervised Cross-lingual\nRepresentation Learning at Scale. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics . 8440â€“8451.\n[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding.\nIn Proceedings of the 2019 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies, NAACL-\nHLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short\nPapers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association\nfor Computational Linguistics, 4171â€“4186. https://doi.org/10.18653/v1/n19-1423\n[7] Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hierarchical Neural Story\nGeneration. In Proceedings of the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) . 889â€“898.\n[8] Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang.\n2022. Language-agnostic BERT Sentence Embedding. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers). 878â€“891.\n[9] Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2022. Precise Zero-Shot\nDense Retrieval without Relevance Labels.arXiv preprint arXiv:2212.10496 (2022).\n[10] Luyu Gao, Xueguang Ma, Jimmy J. Lin, and Jamie Callan. 2022. Tevatron: An\nEfficient and Flexible Toolkit for Dense Retrieval. ArXiv abs/2203.05765 (2022).\n[11] Mitko Gospodinov, Sean MacAvaney, and Craig Macdonald. 2023. Doc2Query:\nWhen Less is More. arXiv preprint arXiv:2301.03266 (2023).\n[12] Sebastian HofstÃ¤tter, Sophia Althammer, Michael SchrÃ¶der, Mete Sertkan, and\nAllan Hanbury. 2020. Improving efficient neural ranking models with cross-\narchitecture knowledge distillation. arXiv preprint arXiv:2010.02666 (2020).\n[13] Sebastian HofstÃ¤tter, Sheng-Chieh Lin, Jheng-Hong Yang, Jimmy Lin, and Allan\nHanbury. 2021. Efficiently teaching an effective dense retriever with balanced\ntopic aware sampling. In Proceedings of the 44th International ACM SIGIR\nConference on Research and Development in Information Retrieval . 113â€“122.\n[14] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey\nEdunov, Danqi Chen, and Wen-tau Yih. 2020. Dense Passage Retrieval for Open-\nDomain Question Answering. In Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) . Association for Computational\nLinguistics, Online, 6769â€“6781. https://doi.org/10.18653/v1/2020.emnlp-main.550\n[15] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur\nParikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob\nDevlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew\nDai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural Questions: a\nBenchmark for Question Answering Research. Transactions of the Association of\nComputational Linguistics (2019).\n[16] Hang Li, Ahmed Mourad, Shengyao Zhuang, Bevan Koopman, and Guido Zuccon.\n2023. Pseudo relevance feedback with deep language models and dense retrievers:\nSuccesses and pitfalls. ACM Transactions on Information Systems (2023).\n[17] Hang Li, Shengyao Zhuang, Xueguang Ma, Jimmy Lin, and Guido Zuccon. 2023.\nPseudo-Relevance Feedback with Dense Retrievers in Pyserini. In Proceedings of\nthe 26th Australasian Document Computing Symposium (ADCS â€™22) .\n[18] Hang Li, Shengyao Zhuang, Ahmed Mourad, Xueguang Ma, Jimmy Lin, and\nGuido Zuccon. 2022. Improving query representations for dense retrieval with\npseudo relevance feedback: A reproducibility study. In Advances in Information\nRetrieval: 44th European Conference on IR Research, ECIR 2022, Stavanger, Norway,\nApril 10â€“14, 2022, Proceedings, Part I . Springer, 599â€“612.\n[19] Yulong Li, Martin Franz, Md Arafat Sultan, Bhavani Iyer, Young-Suk Lee, and\nAvirup Sil. 2022. Learning Cross-Lingual IR from an English Retriever. In\nProceedings of the 2022 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies . 4428â€“4436.\n[20] Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. 2020. Distilling dense\nrepresentations for ranking using tightly-coupled teachers. arXiv preprint\narXiv:2010.11386 (2020).\n[21] Sheng-Chieh Lin, Jheng-Hong Yang, and Jimmy Lin. 2021. In-batch negatives\nfor knowledge distillation with tightly-coupled teachers for dense retrieval. In\nProceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-\n2021). 163â€“173.\n[22] Shayne Longpre, Yi Lu, and Joachim Daiber. 2021. MKQA: A linguistically diverse\nbenchmark for multilingual open domain question answering. Transactions of\nthe Association for Computational Linguistics 9 (2021), 1389â€“1406.\n[23] Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zero-shot\nNeural Passage Retrieval via Domain-targeted Synthetic Question Generation.\nIn Proceedings of the 16th Conference of the European Chapter of the Association\nfor Computational Linguistics: Main Volume . 1075â€“1088.\n[24] Suraj Nair, Eugene Yang, Dawn Lawrie, Kevin Duh, Paul McNamee, Kenton\nMurray, James Mayfield, and Douglas W Oard. 2022. Transfer learning approaches\nfor building cross-language dense retrieval models. In Advances in Information\nRetrieval: 44th European Conference on IR Research, ECIR 2022, Stavanger, Norway,\nApril 10â€“14, 2022, Proceedings, Part I . Springer, 382â€“396.\n[25] Rodrigo Nogueira and Jimmy Lin. 2019. From doc2query to docTTTTTquery.\n[26] Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao,\nDaxiang Dong, Hua Wu, and Haifeng Wang. 2021. RocketQA: An optimized\ntraining approach to dense passage retrieval for open-domain question answering.\nIn Proceedings of the 2021 Conference of the North American Chapter of the\nAssociation for Computational Linguistics: Human Language Technologies . 5835â€“\n5847.\n[27] Houxing Ren, Linjun Shou, Ning Wu, Ming Gong, and Daxin Jiang. 2022.\nEmpowering Dual-Encoder with Query Generator for Cross-Lingual Dense Re-\ntrieval. In Proceedings of the 2022 Conference on Empirical Methods in Natural\nLanguage Processing . 3107â€“3121.\n[28] Ruiyang Ren, Shangwen Lv, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao\nShe, Hua Wu, Haifeng Wang, and Ji-Rong Wen. 2021. PAIR: Leveraging Passage-\nCentric Similarity Relation for Improving Dense Passage Retrieval. In Findings of\nthe Association for Computational Linguistics: ACL-IJCNLP 2021 . 2173â€“2183.\n[29] Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu,\nHaifeng Wang, and Ji-Rong Wen. 2021. RocketQAv2: A Joint Training Method\nfor Dense Passage Retrieval and Passage Re-ranking. In Proceedings of the 2021\nConference on Empirical Methods in Natural Language Processing . 2825â€“2835.\n[30] Harrisen Scells, Shengyao Zhuang, and Guido Zuccon. 2022. Reduce, Reuse,\nRecycle: Green Information Retrieval Research. In Proceedings of the 45th\nInternational ACM SIGIR Conference on Research and Development in Information\nRetrieval. 2825â€“2837.\n[31] Nikita Sorokin, Dmitry Abulkhanov, Irina Piontkovskaya, and Valentin Malykh.\n2022. Ask me anything in your native language. In Proceedings of the 2022\nConference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies . 395â€“406.\n[32] Nandan Thakur, Nils Reimers, Andreas RÃ¼cklÃ©, Abhishek Srivastava, and Iryna\nGurevych. 2021. BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of\nInformation Retrieval Models. In Thirty-fifth Conference on Neural Information\nProcessing Systems Datasets and Benchmarks Track (Round 2) . https://openreview.\nnet/forum?id=wCu6T5xFjeJ\n[33] Nicola Tonellotto. 2022. Lecture Notes on Neural Information Retrieval. arXiv\npreprint arXiv:2207.13443 (2022).\n[34] Kexin Wang, Nandan Thakur, Nils Reimers, and Iryna Gurevych. 2022. GPL:\nGenerative Pseudo Labeling for Unsupervised Domain Adaptation of Dense\nRetrieval. In Proceedings of the 2022 Conference of the North American Chapter\nof the Association for Computational Linguistics: Human Language Technologies .\n2345â€“2360.\n[35] Xiao Wang, Craig Macdonald, Nicola Tonellotto, and Iadh Ounis. 2021. Pseudo-\nrelevance feedback for multiple representation dense retrieval. In Proceedings of\nthe 2021 ACM SIGIR International Conference on Theory of Information Retrieval .\n297â€“306.\n[36] Xiao Wang, Craig Macdonald, Nicola Tonellotto, and Iadh Ounis. 2023. ColBERT-\nPRF: Semantic pseudo-relevance feedback for dense passage and document re-\ntrieval. ACM Transactions on the Web 17, 1 (2023), 1â€“39.\nSIGIR â€™23, July 23â€“27, 2023, Taipei, Taiwan Shengyao Zhuang, Linjun Shou, and Guido Zuccon\n[37] Yujing Wang, Yingyan Hou, Haonan Wang, Ziming Miao, Shibin Wu, Qi Chen,\nYuqing Xia, Chengmin Chi, Guoshuai Zhao, Zheng Liu, et al. [n.d.]. A Neural\nCorpus Indexer for Document Retrieval. In Advances in Neural Information\nProcessing Systems .\n[38] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,\nAnthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz, Joe\nDavison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu,\nCanwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,\nand Alexander M. Rush. 2020. Transformers: State-of-the-Art Natural Language\nProcessing. In Proceedings of the 2020 Conference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations . Association for Computational\nLinguistics, 38â€“45.\n[39] Ning Wu, Yaobo Liang, Houxing Ren, Linjun Shou, Nan Duan, Ming Gong,\nand Daxin Jiang. 2022. Unsupervised context aware sentence representation\npretraining for multi-lingual dense retrieval. arXiv preprint arXiv:2206.03281\n(2022).\n[40] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett,\nJunaid Ahmed, and Arnold Overwijk. 2020. Approximate Nearest Neighbor\nNegative Contrastive Learning for Dense Text Retrieval. In International\nConference on Learning Representations .\n[41] Eugene Yang, Suraj Nair, Ramraj Chandradevan, Rebecca Iglesias-Flores, and\nDouglas W Oard. 2022. C3: Continued pretraining with contrastive weak\nsupervision for cross language ad-hoc retrieval. In Proceedings of the 45th\nInternational ACM SIGIR Conference on Research and Development in Information\nRetrieval. 2507â€“2512.\n[42] HongChien Yu, Chenyan Xiong, and Jamie Callan. 2021. Improving Query Repre-\nsentations for Dense Retrieval with Pseudo Relevance Feedback. InProceedings of\nthe 30th ACM International Conference on Information & Knowledge Management .\n3592â€“3596.\n[43] Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo, Min Zhang, and Shaoping\nMa. 2021. Optimizing Dense Retrieval Model Training with Hard Negatives.\nProceedings of the 44th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval (2021).\n[44] Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Min Zhang, and Shaoping Ma. 2020.\nRepBERT: Contextualized text embeddings for first-stage retrieval.arXiv preprint\narXiv:2006.15498 (2020).\n[45] Wayne Xin Zhao, Jing Liu, Ruiyang Ren, and Ji-Rong Wen. 2022. Dense\ntext retrieval based on pretrained language models: A survey. arXiv preprint\narXiv:2211.14876 (2022).\n[46] Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng. 2022.\nLoL: A Comparative Regularization Loss over Query Reformulation Losses for\nPseudo-Relevance Feedback. In Proceedings of the 45th International ACM SIGIR\nConference on Research and Development in Information Retrieval . 825â€“836.\n[47] Shengyao Zhuang, Hang Li, and Guido Zuccon. 2022. Implicit feedback for\ndense passage retrieval: A counterfactual approach. In Proceedings of the 45th\nInternational ACM SIGIR Conference on Research and Development in Information\nRetrieval. 18â€“28.\n[48] Shengyao Zhuang, Houxing Ren, Linjun Shou, Jian Pei, Ming Gong, Guido\nZuccon, and Daxin Jiang. 2022. Bridging the gap between indexing and re-\ntrieval for differentiable search index with query generation. arXiv preprint\narXiv:2206.10128 (2022).",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8903197050094604
    },
    {
      "name": "Query expansion",
      "score": 0.6525878310203552
    },
    {
      "name": "Task (project management)",
      "score": 0.5635493993759155
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5316916704177856
    },
    {
      "name": "Generator (circuit theory)",
      "score": 0.5286819338798523
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.5197253227233887
    },
    {
      "name": "Natural language processing",
      "score": 0.5069973468780518
    },
    {
      "name": "Inference",
      "score": 0.4952150881290436
    },
    {
      "name": "Query language",
      "score": 0.4861278533935547
    },
    {
      "name": "Relevance (law)",
      "score": 0.480885773897171
    },
    {
      "name": "Information retrieval",
      "score": 0.46590882539749146
    },
    {
      "name": "Query by Example",
      "score": 0.4219655990600586
    },
    {
      "name": "ENCODE",
      "score": 0.4120282530784607
    },
    {
      "name": "Web search query",
      "score": 0.3410670757293701
    },
    {
      "name": "Search engine",
      "score": 0.1958675980567932
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I165143802",
      "name": "The University of Queensland",
      "country": "AU"
    }
  ],
  "cited_by": 6
}