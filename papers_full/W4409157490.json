{
  "title": "A survey on multilingual large language models: corpora, alignment, and bias",
  "url": "https://openalex.org/W4409157490",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2157209964",
      "name": "Yuemei Xu",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2099863380",
      "name": "Ling Hu",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2104048896",
      "name": "Jiayi Zhao",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2792518373",
      "name": "Zihan Qiu",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2108046793",
      "name": "Kexin Xu",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2229487464",
      "name": "Ye Yuqi",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2134908323",
      "name": "Hanwen Gu",
      "affiliations": [
        "Beijing Foreign Studies University"
      ]
    },
    {
      "id": "https://openalex.org/A2157209964",
      "name": "Yuemei Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2099863380",
      "name": "Ling Hu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2104048896",
      "name": "Jiayi Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2792518373",
      "name": "Zihan Qiu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108046793",
      "name": "Kexin Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2229487464",
      "name": "Ye Yuqi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2134908323",
      "name": "Hanwen Gu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2912083425",
    "https://openalex.org/W2913954081",
    "https://openalex.org/W4308760226",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2602856279",
    "https://openalex.org/W2911293880",
    "https://openalex.org/W1502957213",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4285199616",
    "https://openalex.org/W3035296331",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2524182563",
    "https://openalex.org/W2952638691",
    "https://openalex.org/W3034469191",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W6811129797",
    "https://openalex.org/W6811340617",
    "https://openalex.org/W55204438",
    "https://openalex.org/W4390041933",
    "https://openalex.org/W4402670135",
    "https://openalex.org/W6847076894",
    "https://openalex.org/W6850503672",
    "https://openalex.org/W1583837637",
    "https://openalex.org/W6852800892",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W6856398428",
    "https://openalex.org/W4399837985",
    "https://openalex.org/W6851775633",
    "https://openalex.org/W3011574394",
    "https://openalex.org/W4298181573",
    "https://openalex.org/W4223908421",
    "https://openalex.org/W3215698779",
    "https://openalex.org/W2914584698",
    "https://openalex.org/W2060277733",
    "https://openalex.org/W2740887992",
    "https://openalex.org/W4226134572",
    "https://openalex.org/W4389519545",
    "https://openalex.org/W4386220752",
    "https://openalex.org/W4388406624",
    "https://openalex.org/W4385565879",
    "https://openalex.org/W3213418658",
    "https://openalex.org/W3046484722",
    "https://openalex.org/W89279510",
    "https://openalex.org/W4390215452",
    "https://openalex.org/W4385572824",
    "https://openalex.org/W3093456628",
    "https://openalex.org/W4385574290",
    "https://openalex.org/W4385724599",
    "https://openalex.org/W2398936787",
    "https://openalex.org/W4213112742",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2889574253",
    "https://openalex.org/W3184324824",
    "https://openalex.org/W2596989490",
    "https://openalex.org/W2963472233",
    "https://openalex.org/W3034913382",
    "https://openalex.org/W3034402523",
    "https://openalex.org/W4385572801",
    "https://openalex.org/W2985620815",
    "https://openalex.org/W4206285331",
    "https://openalex.org/W3035379020",
    "https://openalex.org/W4388687124",
    "https://openalex.org/W3038047279",
    "https://openalex.org/W2601748485",
    "https://openalex.org/W4389519093",
    "https://openalex.org/W136741500",
    "https://openalex.org/W3170344956",
    "https://openalex.org/W4385572757",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3034115845",
    "https://openalex.org/W2802105481",
    "https://openalex.org/W2952328691",
    "https://openalex.org/W2909212904",
    "https://openalex.org/W4287890950",
    "https://openalex.org/W3035591180",
    "https://openalex.org/W3035241006",
    "https://openalex.org/W3200726972",
    "https://openalex.org/W3134354193",
    "https://openalex.org/W2891555348",
    "https://openalex.org/W3137010024",
    "https://openalex.org/W4389520396",
    "https://openalex.org/W3200232291",
    "https://openalex.org/W4401484139",
    "https://openalex.org/W3202415077",
    "https://openalex.org/W2620949368",
    "https://openalex.org/W2597601064",
    "https://openalex.org/W3088409176",
    "https://openalex.org/W2604292070",
    "https://openalex.org/W2612560781",
    "https://openalex.org/W4365799947",
    "https://openalex.org/W2610930722",
    "https://openalex.org/W2599674900",
    "https://openalex.org/W3185212449",
    "https://openalex.org/W4205807230",
    "https://openalex.org/W2596567068",
    "https://openalex.org/W2606555609",
    "https://openalex.org/W2912500072",
    "https://openalex.org/W128638292",
    "https://openalex.org/W2914304175"
  ],
  "abstract": "Abstract Based on the foundation of Large Language Models (LLMs), Multilingual LLMs (MLLMs) have been developed to address the challenges faced in multilingual natural language processing, hoping to achieve knowledge transfer from high-resource languages to low-resource languages. However, significant limitations and challenges still exist, such as language imbalance, multilingual alignment, and inherent bias. In this paper, we aim to provide a comprehensive analysis of MLLMs, delving deeply into discussions surrounding these critical issues. First of all, we start by presenting an overview of MLLMs, covering their evolutions, key techniques, and multilingual capacities. Secondly, we explore the multilingual training corpora of MLLMs and the multilingual datasets oriented for downstream tasks that are crucial to enhance the cross-lingual capability of MLLMs. Thirdly, we survey the state-of-the-art studies of multilingual representations and investigate whether the current MLLMs can learn a universal language representation. Fourthly, we discuss bias on MLLMs, including its categories, evaluation metrics, and debiasing techniques. Finally, we discuss existing challenges and point out promising research directions of MLLMs.",
  "full_text": "A survey on multilingual large language models:\ncorpora, alignment, and bias\nYuemei XU (✉), Ling HU, Jiayi ZHAO, Zihan QIU, Kexin XU, Yuqi YE, Hanwen GU\nSchool of Information Science and Technology, Beijing Foreign Studies University, Beijing 100089, China\n The Author(s) 2025. This article is published with open access at link.springer.com and journal.hep.com.cn\n \nAbstract    Based  on  the  foundation  of  Large  Language\nModels  (LLMs),  Multilingual  LLMs  (MLLMs)  have  been\ndeveloped  to  address  the  challenges  faced  in  multilingual\nnatural  language  processing,  hoping  to  achieve  knowledge\ntransfer  from  high-resource  languages  to  low-resource\nlanguages. However, significant limitations and challenges still\nexist, such as language imbalance, multilingual alignment, and\ninherent bias. In this paper, we aim to provide a comprehensive\nanalysis  of  MLLMs,  delving  deeply  into  discussions\nsurrounding  these  critical  issues.  First  of  all,  we  start  by\npresenting  an  overview  of  MLLMs,  covering  their  evolutions,\nkey  techniques,  and  multilingual  capacities.  Secondly,  we\nexplore  the  multilingual  training  corpora  of  MLLMs  and  the\nmultilingual  datasets  oriented  for  downstream  tasks  that  are\ncrucial  to  enhance  the  cross-lingual  capability  of  MLLMs.\nThirdly,  we  survey  the  state-of-the-art  studies  of  multilingual\nrepresentations  and  investigate  whether  the  current  MLLMs\ncan  learn  a  universal  language  representation.  Fourthly,  we\ndiscuss  bias  on  MLLMs,  including  its  categories,  evaluation\nmetrics, and debiasing techniques. Finally, we discuss existing\nchallenges  and  point  out  promising  research  directions  of\nMLLMs.\nKeywords    multilingual  large  language  model, corpora,\nalignment, bias, survey\n \n1    Introduction\nThe  rapid  development  of  Large  Language  Models  (LLMs)\nhas brought about a paradigm shift and revolution in the field\nof  Natural  Language  Processing  (NLP).  This  innovative\napproach  trains  a  transformer-based  model  [\n1]  on  extensive\nvolumes  of  data  and  then  leverages  fine-tuning  or  prompt\nlearning to facilitate the model’s adaption to a wide variety of\ntasks.  Based  on  the  foundation  of  LLMs,  large-scale\nMultilingual  MLLMs  (MLLMs),  such  as  mBERT  [\n2],  XLM\n[3],  mT5  [4],  BLOOM  [5]  and  LLaMA  [6],  have  been\ndeveloped to tackle multilingual NLP tasks. MLLMs are pre-\ntrained on a concatenation of texts in multiple languages with\nthe hope that low-resource languages may benefit from high-\nresource  languages  due  to  linguistic  similarities  and  shared\nrepresentations inherent within language pairs.\nCompared  to  LLMs,  MLLMs  require  larger  multilingual\ncorpora that cover more languages to ensure applicability and\nfairness  across  different  languages  in  downstream  tasks.\nMLLMs  are  trained  to  understand  and  capture  the  structures\nand  patterns  of  multiple  languages.  For  instance,  pre-trained\non data from 104 languages, BLOOM supports 46 languages,\ncovering the eight most widely spoken languages in the world\n[\n5].  Numerous  MLLMs  have  been  proposed  in  the  past  five\nyears, which differ in the architecture (e.g., number of layers,\nparameters,  etc.),  data  used  for  pre-training  (Wikipedia,\nCommon Crawl, etc.), and the number of languages involved\n(ranging from 12 to 110). However, it is uncertain how much\ncross-lingual  transfer  learning  capability  MLLMs  have  to\nsupport  unseen  languages  or  low-resource  languages  during\npre-training. As a result, Section 2 first starts by providing an\noverview  of  MLLMs,  which  contains  key  evolutions,\ntechniques,  and  a  detailed  analysis  of  MLLMs’ multilingual\ncapacities.  Despite  the  success  of  MLLMs,  existing  MLLMs\nstill  face  numerous  issues  and  challenges,  which  can  be\nsummarized as three aspects: corpora, alignment, and bias. As\nshown in \nFig. 1, training corpora of MLLMs heavily influence\ntheir capability. On the one hand, the unbalanced corpora and\ntraining  lead  to  misalignment  of  MLLMs  among  different\nlanguages.  On  the  other  hand,  inherent  bias  within  corpora\ninduces  MLLMs  to  produce  biased  output.  Therefore,  this\npaper focuses discussion around the three aspects of corpora,\nalignment, and bias.\nFirstly,  MLLMs  heavily  rely  on  multilingual  corpora  to\nenhance  their  performance.  For  example,  among  the  training\ncorpus of ChatGPT, the English corpus accounts for 92.099 %,\nand the Chinese only accounts for 0.16 %, so its dialogues in\nthe  English  context  are  much  higher  than  those  in  other\nlanguages in terms of quality and speed. However, the size of\navailable  corpus  resources  for  different  languages  varies\ngreatly, and most of the existing annotated datasets are mainly\nfocused on a few languages, limited the cross-lingual transfer\neffectiveness  from  high-resource  languages  to  languages  that\nare unseen during training. Furthermore, MLLMs suffer from\nwhat Conneau et al. [\n7] call the curse of multilinguality : more\nlanguages  lead  to  better  cross-lingual  performance  on  low-\n \nReceived June 7, 2024; accepted December 9, 2024\nE-mail: xuyuemei@bfsu.edu.cn\nFront. Comput. Sci., 2025, 19(11): 1911362\nhttps://doi.org/10.1007/s11704-024-40579-4\nREVIEW ARTICLE\nresource  languages  up  until  a  point,  after  which  the  overall\nperformance  of  MLLMs  on  monolingual  and  cross-lingual\nbenchmarks  will  decrease.  In  conclusion,  the  scale,  quality,\nand  diversity  of  corpora  have  a  significant  impact  on  the\nperformance  of  MLLMs.  Therefore,  Section  3  presents  a\nsurvey  of  the  representative  multilingual  training  corpora  of\nMLLMs,  offering  insights  into  their  language  distribution,\ndata source, and language coverage.\nSecondly,  MLLMs  still  struggle  to  learn  a  universal\nlanguage  representation  for  diverse  languages.  The  language\nmisalignment  issues  exist.  Aligning  the  representation  of\ndiverse  languages  acts  as  an  integral  part  of  NLP’s\nmultilingual  tasks  and  applications  [\n8],  and  under-\nrepresentation  of  low-resource  languages  leads  to  MLLMs’\npoor  performance  on  these  languages.  Inspired  by  the\nimpressive performance of monolingual representation models\nlike Word2vec [\n9] and GloVe [ 10], recent research has made\ngreat progress in multilingual representation. In Section 4, we\nreview  previous  research  on  multilingual  representations  and\nclassify  them  into  three  categories:  static  multilingual\nrepresentation,  contextual  multilingual  representation,  and\ncombined  multilingual  representation.  We  also  analyze  the\nimpact  of  various  factors  on  multilingual  alignment\nperformance, including initial alignment solution, linearity of\nmapping  function,  language  typological  distance,  and  pre-\ntraining data and settings of MLLMs.\nThirdly,  MLLMs  are  prone  to  produce  harmful  outcomes\nand social bias [\n11] in part due to bias is naturally present in\ncross-cultural  datasets  and  the  design  of  MLLMs’ modeling\nprocesses [\n12]. Previous studies have explored bias in various\nNLP tasks and demographic groups, but are largely specific to\nEnglish-based models [\n13,14], which cannot be generalized to\nother  languages.  What  are  the  types  of  bias  in  existing\nMLLMs?  What  are  the  main  de-biasing  techniques  available\nfor MLLMs? Does the removal of these biases affect LLMs’\nperformance?  What  are  the  existing  bias  evaluation  datasets\nfor  MLLMs?  These  are  very  worthwhile  research  questions.\nThis survey tries to answer these questions and offers valuable\ninsights for bias on MLLMs.\nThe contributions of this survey are as follows:\n●  We  present  an  overview  of  MLLMs  and  analyze  the\nlanguage  imbalance  challenge  within  MLLMs,  their\ncapacity  to  support  low-resource  languages  and  their\npotential for cross-lingual transfer learning.\n● We provide an overview of the multilingual datasets and\ncorpora  utilized  by  existing  MLLMs,  offering  a\ncomprehensive  insight  into  the  language  distribution\nwithin these training corpora.\n● We  survey  the  existing  studies  on  multilingual\nrepresentations  and  explore  whether  the  current\nMLLMs can learn a universal language representation.\n● Our survey delves into bias within MLLMs, seeking to\naddress essential questions such as identifying the types\nof bias present in current MLLMs, exploring prominent\nde-biasing  techniques,  and  summarizing  available  bias\nevaluation datasets for MLLMs.\n \n2    Overview of MLLMs\nThis  section  provides  a  brief  overview  of  MLLMs,  tracing\ntheir  evolution  from  monolingual  LLMs  to  multilingual\nLLMs,  as  dispicted  in \nFig. 2.  It  then  illustrates  the  key\ntechniques that contribute most to the success of MLLMs, as\nwell as the multilingual capacities of MLLMs.\n \n2.1    Evolution of MLLMs \n2.1.1    Monolingual evolution\nThe  development  of  monolingual  LLMs  has  made  great\nprogress  in  understanding  and  generating  human  languages.\nThese models employ a transformer-based architecture that is\nfirst pre-trained on a large corpus of texts, followed by fine-\ntuning or prompt learning to enhance models’ performance on\nspecific tasks or languages.\nThe representative monolingual LLMs are the BERT series\nand  GPT  series.  With  the  success  of  BERT  [\n2],  BERT-\nvariants  models  have  been  developed  for  specific  languages,\nsuch  as  FlauBERT  for  French  [\n15],  BERTje  for  Dutch  [16],\nAraBERT  for  Arabic  [17].  The  GPT  series,  evolving  from\nGPT-1  to  GPT-2,  GPT-3,  and  beyond  [ 18–22],  has\n \n \nFig. 1    An illustration of the relationship between corpora, misalignment, and bias. The misalignment  and bias produced by MLLM arise in part\nfrom the bias and imbalanced language proportions of the training corpora\n2 Front. Comput. Sci., 2025, 19(11): 1911362\nexperienced  growth  in  parameters  and  training  corpora,  e.g.,\nparameters ranging from hundreds of millions (GPT-1) [\n18] to\n1.5  trillion  (GPT-3)  [20].  This  progression  empowers  the\nmodels  with  improved  sophisticated  language  understanding\nand generation capabilities. T5 model [\n23] introduces a unified\nframework  that  converts  a  variety  of  tasks  into  a  text-to-text\nformat  by  prepending  a  unique  prefix  to  the  input  for  each\ntask.  BART  [\n24]  is  a  sequence-to-sequence  model,  not  an\nauto-regressive  model  like  GPT-2  or  an  auto-encoder  model\nlike  BERT,  and  thus  it  is  particularly  effective  on\ncomprehension tasks like summarization.\nMonolingual LLMs have seen advancements in transformer-\nbased architecture and pre-training strategies but are language-\ndependent.  Training  such  language-specific  LLMs  is  only\nfeasible for a few languages with necessary corpora.\n \n2.1.2    Multilingual evolution\nMultilingual LLMs build upon the foundation of monolingual\nLLMs  to  learn  universal  language  patterns  from  extensive\nunlabeled  data  across  multiple  languages.  MLLMs  have\nadvanced to overcome linguistic limitations and enhance low-\nresource  languages  by  leveraging  shared  vocabulary  and\ngenetic relatedness from high-resource languages [\n25].\nFollowing  the  success  of  monolingual  BERT,  multilingual\nBERT  (mBERT)  [2]  was  the  first  released  MLLM  by\nfollowing the training procedure of BERT but on multilingual\nWikipedia  text  corpora  including  104  languages.  Other\nMLLMs  such  as  XLM-R  [\n7],  mBART  [26],  and  mT5  [4]\nfollow  the  step  of  mBERT,  further  exploring  the  capacities\nand  limitations  of  MLLMs  across  languages.  Studies  reveal\nthat  MLLMs  work  surprisingly  well  on  cross-lingual  tasks\neven  without  direct  cross-lingual  supervision  like  parallel  or\ncomparable data [\n27,28].\nThe  further  development  trend  has  led  to  a  tremendous\nincrease  in  model  parameters  and  data  scale,  resulting  in\nenhancements  that  promote  multilingual  capabilities.  For\nexample,  PaLM  with  540  billion  (540B)  parameters  yields\nimpressive  capabilities  on  the  multilingual  benchmarks  by\ntraining  on  a  mixture  of  multilingual  versions  of  Wikipedia\nand  dialogue  data,  including  124  languages  [\n29].  With  the\nearly  successful  attempts,  the  autoregressive  language\nmodeling  and  prompt  learning  paradigm  represented  by  the\nGPT  series  has  received  much  attention  and  follow-up  from\nmajor companies and universities. Thus, more MLLMs (e.g.,\nInstructGPT  [\n21],  LaMDA  [30],  OPT  [31],  BLOOM  [5],\nLLaMA  [6])  have  been  proposed  to  achieve  breakthrough\nperformance  in  a  range  of  multi-step  reasoning  tasks  over\nmultiple  languages.  In  addition  to  the  GPT  series  and  its\nderivative  models,  numerous  other  models  have  been\nproposed  to  boost  the  development  of  LLMs.  Examples\ninclude GLM [\n32,33], Vicuna [ 34], Gemini [ 35], and several\nothers.\nThe  development  of  MLLMs  has  been  guided  by  several\ntendencies:  (1)  parameter  growth;  (2)  linguistic  diversity;\n(3)  multimodal  unification.  Regarding  (1),  MLLMs  have\nexpanded  to  hundreds  of  billions  of  parameters  or  even\ntrillions.  Increasing  the  size  of  parameters  brings  clear\nbenefits, such as alleviating hallucination phenomena heavily\npresent in minor-parameter (e.g., 7B, 13B) models. However,\nthere’s a limit to the amount of text data available online, and\nobtaining  high-quality  data  is  becoming  increasingly\nchallenging, which might slow down the parameter growth of\nMLLMs. Regarding (2), most high-resource languages belong\nto similar language families, thus sharing numerous linguistic\n \n \nFig. 2    An illustration of the evolution roadmap of current multilingual LLMs, presenting their release year, the number of supported languages\nand release relationship. ‘Unknown’ indicates the model has not disclosed the language proportion in its training data\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 3\nfeatures.  Disregarding  this  diversity  inevitably  leads  to  poor\ngeneralizability  and  language-specific  biases  [\n36].  Recent\nwork in MLLMs has focused on addressing this issue as low-\nresource  and  unseen  languages  still  account  for  a  large\nproportion  of  the  world’s  languages.  Regarding  (3),\nmultimodal MLLMs are a growing focus of research, realizing\na  variety  of  specific  real-world  needs  by  unifying  diverse\ntypes  of  modalities  (i.e.,  text,  image,  and  speech).\nAdditionally,  current  research  aims  to  extend  MLLMs  to\naccommodate  more  modalities  like  web  pages,  heat  maps,\ngraphs,  and  tables,  thereby  increasing  the  model’s  generality\nand applicability [\n37].\nTable 1 summarizes  the  representative  MLLMs  in  recent\nyears,  divided  into  two  categories:  monolingual  and\nmultilingual, showing the evolution of MLLMs from multiple\nperspectives in chronological order of release.\n \n2.2    Key techniques of MLLMs\nTransformer  architecture,  pre-training  technique,  and\nreinforcement  learning  with  human  feedback  are  the  key\ntechniques  for  MLLMs.  In  this  section,  we  will  present  the\nkey ideas behind these techniques.\n \n2.2.1    Transformer architecture\nTransformer architecture, first introduced in 2017, has become\nthe foundation of MLLMs owing to its suitability for parallel\ncomputing  and  flexibility  for  diverse  model  design.\nTransformer  architecture  consists  of  two  main  modules,\nEncoder and Decoder, along with a self-attention mechanism\nwithin  each  module.  The  encoder,  using  stacked  multi-head\nself-attention layers, encodes the input sequence and generates\nlatent representations. In contrast, the decoder employs cross-\nattention  to  utilize  the  encoder’s  latent  representations,\nattending to them while autoregressively generating the target\nsequence [\n53].\nMLLMs can be categorized into three groups based on the\nunderlying transformer structure:\n● Encoder-only (e.g., BERT): MLLMs with encoder-only\narchitecture  can  effectively  handle  long-range\ndependencies within the input sequences, making them\nwell-suited for the analysis and classification of textual\ncontent,  including  tasks  like  sentiment  analysis  and\nnamed entity recognition.\n● Decoder-only (e.g.,  GPT):  MLLMs  with  decoder-only\narchitecture are mainly designed to generate sequences\nof language texts. They predict the next token based on\ncontextual  information  from  the  current  and  preceding\nsteps.\n● Encoder-decoder  hybrid (e.g.,  GLM):  MLLMs  with\nencoder-decoder  architecture  enable  themselves  to\nprocess  sequential  data  and  generate  accurate  and\ncoherent  outputs  that  excel  in  tasks  such  as  text\ngeneration, and summarization.\n \n2.2.2    Pre-training technique\nPre-training  technique  aims  to  learn  universal  language\nrepresentations  from  billion-scale  unlabeled  corpora  (e.g.,\nWikipedia,  webpages,  news,  etc.)  and  then  initializes  the\nparameters of the Transformer-based MLLMs. This approach\nreduces  the  reliance  on  massive  parallel  corpora,  helping\nMLLMs generate similar representations in a common vector\nspace  for  similar  sentences  and  words  (or  words  in  similar\ncontext) across languages [\n54].\nThe  benefits  of  pre-training  technique  can  be  attributed  to\ntwo  key  factors:  Paradigm  and  Task.  Pre-training  paradigms\nhave  been  proposed  to  capture  linguistic  patterns  in  the\ntraining  data  and  adapt  MLLMs  to  downstream  tasks,\nincluding “pre-training  +  fine-tuning” and “pre-training  +\nprompting”. The former representative models are BERT [\n2],\nGPT-2  [19],  while  the  latter  presentative  models  like  GPT-3\n[20].  Pre-training  tasks  improve  the  ability  of  MLLMs  to\nencode and generate coherent multilingual text.\nL x =[x1 ,x2 ,..., xT ]\nWhen learning the universal representation of language, pre-\ntraining  tasks  play  a  crucial  role  and  the  widely  used  pre-\ntraining  tasks  include  probabilistic  language  modeling  (LM),\nmasked  language  modeling  (MLM),  next  sentence  prediction\n(NSP), and Denoising autoencoder (DAE). Probabilistic LM is\na  fundamental  task  in  NLP,  estimating  the  probability\ndistribution of sequences of words in a language. In practice,\nLM  typically  involves  auto-regressive  LM  or  unidirectional\nLM.  MLM  has  emerged  as  a  novel  pre-training  task  to\novercome the drawback of the standard unidirectional LM. By\nmasking  certain  tokens  in  a  sequence  and  predicting  them\nbased  on  context,  MLM  encourages  models  to  learn\nbidirectional  representations,  capturing  dependencies  from\nboth  left  and  right  contexts.  Punctuations  are  the  natural\nseparators  of  text  data.  So,  it  is  reasonable  to  construct  pre-\ntraining  methods  by  utilizing  them.  NSP  is  just  a  great\nexample of this. NSP encourages the model to understand the\ncontextual  coherence  and  relationships  between  sentences.\nDAE takes a partially corrupted input and aims to recover the\noriginal undistorted input. Specific to language, a sequence-to-\nsequence model, such as the standard Transformer, is used to\nreconstruct the original text. Eq. (1) summarize loss function\n of  these  pre-training  tasks,  where \ndenotes a sequence of tokens [\n55].\n \nLLM =−\nT∑\nt=1\nlog p(xt |x<t ),\nLMLM =−\n∑\nˆx∈m(x)\nlog p( ˆx|x\\m(x) ),\nLNSP =−log p(t|x,y),\nLDAE =−\nT∑\nt=1\nlog p(xt |ˆx,x<t ), (1)\nwhere the symbols and their definitions are listed in Table 2. \n2.2.3    Reinforcement learning with human feedback\nMLLMs  may  generate  inaccurate  or  harmful  outputs  due  to\ntheir  probabilistic  statistical  text  generation  mechanism  [\n56].\nReinforcement  Learning  from  Human  Feedback  (RLHF)  and\nits  variants  [\n57–61]  have  been  proposed  to  fix  this  by\noptimizing  MLLMs  with  human  feedback,  aligning  them\nbetter  with  human  values  in  three  fundamental  dimensions:\nhelpfulness, honesty, and harmlessness [\n62].\n4 Front. Comput. Sci., 2025, 19(11): 1911362\nEssentially, RLHF has three core steps [ 63,64], as shown in\nFig. 3.\n1. Pre-training a language model : To pre-train MLLMs,\nextensive prompts, and multilingual datasets are utilized\nas  examples,  teaching  the  model  how  to  respond\nappropriately in a specific context.\nK\nLθ\nP yw yl\n2. Training  a  reward  model:  Prompts  serve  as  input  to\nMLLMs,  where  pairs  of  prompt,  response  are\nmanually  scored  by  human  evaluators  to  align  with\nhuman  preferences.  The  rankings  of  sample,  reward\npairs  are  normalized  into  a  scalar  reward  signal  for\ntraining the Reward Model (RM). The loss function \nis defined as follows, where  is the prompt,  and \ndenote  the  better  and  worse  model  responses\n  \nTable 1    An overview of representative MLLMs in recent years, including their release time, publishing authority, maximum available parameters, maximum\nsupported context length, pre-training file size, architecture, base model, pre-training function, publicly available, and modal\nModel Release time Publishing\nauthority Params Context\nlength\nPre-training\nfile size Architecture Base model Pre-training\nfunction\nPublicly\navailable Modal\nMonolingual\nGPT-1 [18] Jun-18 OpenAI 117M 2K − Decoder-only GPT LM Open Text\nBERT [2] Oct-18 Google 340M 2K 1.3 GB Encoder-only − Seq2Seq\nMLM Open Text\nGPT-2 [19] Feb-19 OpenAI 1.5B 2K 40 GB Decoder-only GPT LM Open Text\nT5 [23] Oct-19 Google 11B 2K 21 GB En-decoder − Seq2Seq\nMLM Open Text\nGPT-3 [20] May-20 OpenAI 175B 2K 570 GB Decoder-only GPT LM Closed Text\nGopher [38] Dec-21 DeepMind 280B 2K − Decoder-only − LM Open Text\nMultilingual\nmBERT [2] Jul-19 Google 172M 2K − Encoder-only BERT MLM Open Text\nXLM-R [7] Nov-19 Facebook 550M 2K − Encoder-only − TLM Open Text\nmBART [26] Jan-20 Facebook 680M 2K − En-decoder BART DAE Open Text\nmT5 [4] Oct-20 Google 13B 2K − En-decoder T5 Seq2Seq\nMLM Open Text\nLaMDA [30] Jan-22 Google 137B 32K − Decoder-only − LM Open Text\nPaLM [29] Apr-22 Google 540B 2K − Decoder-only − LM Closed Text\nBLOOM [5] Jul-22 BigScience 176B 2K 350 GB Decoder-only − LM Open Text\nGLM-130B [33] Aug-22 ZHIPU 130B 2K − En-decoder GLM ABI Closed Text\nFLAN-T5 [39] Oct-22 Google 11B 2K 17.3 MB En-decoder T5 LM Open Text\nGPT-3.5 [20] Nov-22 OpenAI 175B 2K − Decoder-only GPT LM Closed Text\nChatGPT [40] Nov-22 OpenAI 175B 2K − Decoder-only GPT-3.5 LM Open Text\nLLaMA [6] Feb-23 Meta 65B 4K 120 GB Decoder-only − LM Open Text\nChatGLM [38] Mar-23 ZHIPU 130B 2K 8 GB En-decoder GLM ABI Open Text\nPaLM-E [41] Mar-23 Google 562B 2K − Decoder-only PaLM LM Open Text, Image\nAlpaca [42] Mar-23 StandFord 7B 2K 14 GB Decoder-only LLaMA LM Open Text\nGPT-4 [22] Mar-23 OpenAI − 8K − Decoder-only GPT LM Closed Text, Image\nPanGu-Σ [43] Mar-23 Huawei 1085B − − Decoder-only PanGu-α LM Closed Text\nPythia [44] Apr-23 EleutherAI 12B 2K 24 GB Decoder-only − LM Open Text\nPaLM 2 [45] May-23 Google 340B 2K − Decoder-only PaLM LM Closed Text\nChatGLM2 [32] Jun-23 ZHIPU 12B 4K − En-decoder GLM ABI Closed Text\nVicuna [34] Jun-23 LMSYS 33B 2K 65 GB Decoder-only LLaMA LM Open Text\nLLaMA 2 [46] Jul-23 Meta 70B 4K 129 GB Decoder-only LLaMA LM Open Text\nBard [47] Jul-23 Google − − − Decoder-only LaMDA LM Open Text, Image\nBaichuan [48] Jul-23 BAICHUAN 13B 4K 26.6 GB Decoder-only − LM Open Text\nGPT-4V [22] Sep-23 OpenAI − 32K − Decoder-only GPT-4 LM Closed Text, Image\nChatGLM3 [33] Oct-23 ZHIPU 6B 32K 12 GB En-decoder GLM ABI Open Text\nGPT-4 Turbo [22] Nov-23 OpenAI − 128K − Decoder-only GPT-4 LM Closed Text, Image,\nSpeech\nGemini-ultra [35] Dec-23 DeepMind 300B 32K − Decoder-only − LM Closed Text, Image\nPhi-2 [49] Dec-23 Microsoft 2.7B 2K 5.4 GB Decoder-only − LM Open Text\nGLM-4 [50] Jan-24 ZHIPU − 128K − En-decoder GLM ABI Closed Text, Image\nClaude 3 [51] Mar-24 Anthropic − 200K − Decoder-only Claude LM Closed Text, Image\nLLaMA 3 [52] Apr-24 Meta 70B 8K 140 GB Decoder-only LLaMA LM Open Text\n \nTable 2    Summary of key notations\nSymbol Description\nx\nx =[x1 ,x2 ,..., xT ]\nm(x) The masked tokens\nx\\m(x) The rest tokens\nˆx Random perturbation text\ny Target label\nt t =1If x and y are continuous segments from corpus, \nP The prompt\nyw The better model response\nyl The worse model response\nrθ The output of reward model\nθ Weight in policy optimization network\nJ(θ) The objective function\n∇θJ(θ) The gradient of objective function\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 5\nrθ(P,y)respectively, and  is the output of the RM.\n \nLθ =− 1\n(K\n2 ) E(P,yw ,yl )∼D [log(σ(rθ(P,yw ) −rθ(P,yl )))], (2)\nwhere  the  symbols  and  their  definitions  are  listed  in\nTable 2.\n3. Fine-tuning  with  reinforcement  learning:  MLLMs\nare  optimized  using  Proximal  Policy  Optimization\n(PPO)  [\n65]  or  a  similar  reinforcement  learning  (RL)\nalgorithm  such  as  A2C  [66].  These  RL  algorithms\nincorporate  human-generated  reward  signals  to  apply\ngradient strategies for learning human feedback.\n \n2.3    Multilingual capacities of MLLMs\nPre-training MLLMs on extensive multilingual data enhances\ntheir multilingual capacities and cross-lingual transfer learning\n(CLTL) from one language to another. However, MLLMs still\nface challenges in training with multilingual corpora and their\nexact  CLTL  capabilities  remain  largely  unexplored.  This\nsection focuses on these two concerns.\n \n2.3.1    Challenges brought by multilingual corpora\nThree  challenges  arise  from  multilingual  corpora  training.\nFirstly,  while  MLLMs  outperform  monolingual  LLMs  in\ndownstream  tasks  for  high-resource  languages,  their\nperformance  on  low-resource  languages  remains\nunsatisfactory  due  to  limited  annotated  data.  Secondly,  the\n“curse  of  multilinguality” phenomenon  in  MLLMs  worsens\nthis  situation.  Supporting  more  languages  can  lead  to  a\nsignificant decline in performance for low-resource languages,\nmaking  them  victims  of  this  curse  [\n67].  Thirdly,  the\ndistribution of languages in the pre-training corpora is highly\nskewed  towards  English,  further  complicating  efforts  to\naddress the “curse of multilinguality” phenomenon.\nTo  mitigate  these  challenges,  two  approaches  have  been\nproposed.  One  involves  fine-tuning  existing  MLLMs  to  suit\nthe  linguistic  features  of  low-resource  languages  [\n68].\nHowever,  this  method  is  constrained  by  the  demand  for\nextensive  specific-task  annotated  training  data  [\n69].\nAlternatively,  another  approach  is  to  pre-train  monolingual\nLLMs  specifically  for  low-resource  languages  [70].  This\nmethod  allows  models  to  learn  from  diverse  sources  and\ncontexts  within  the  target  language  without  requiring  costly\nannotated  data.  Therefore,  MLLMs  trained  by  this  approach\nexhibit  superior  performance  on  low-resource  languages\ncompared  to  the  aforementioned  fine-tuning  approach.  For\nexample, Torge et al. [\n71] pre-trained monolingual RoBERTa\nmodels for Czech and Polish, as well as a bilingual model for\nCzech-Polish,  which  demonstrated  superior  performance  to\nthe current state-of-the-art multilingual model, XLM-R, across\nvarious downstream tasks. Recently, there has been a growing\ninterest in  developing  low-resource language models  to  meet\nthe demands of morphologically rich, low-resource languages.\nExamples  include  language-specific  BERT  models  like\nFlauBERT  for  French  [\n15],  BERTje  for  Dutch  [16],  and\nFinBERT for Finnish [72], among others [54].\nThe  main  reason  for  MLLMs’ poor  performance  on  low-\nresource languages is the skewed distribution of languages in\nthe  pre-training  data.  Therefore,  techniques  have  been\nproposed to address this issue. Data sampling techniques like\nexponential  weighted  smoothing  [\n7]  help  prevent  the  under-\nrepresentation  of  low-resource  languages,  while  vocabulary\naugmentation approaches [\n73] enrich the model’s vocabulary\nby inducing new tokens of unseen languages during training.\nMoreover, research has also attempted to tackle the language\nimbalance. Choenni et al. discovered that languages influence\neach other during the pre-training phase and MLLMs benefit\nfrom  reinforcement  or  complementary  learning  [\n74].  Wang\net  al.  emphasized  the  significance  of  imbalanced  learning\nalgorithms  in  Vision-Language  models  (VLMs)  [\n75].  For\nexample, CLIP model demonstrated an improvement from 5 %\nto  69% on  iNaturalist  dataset  by  adopting  imbalanced\nmethods. Jiang et al. proposed a data augmentation pipeline to\naddress  imbalance  in  social  media  data,  effectively  handling\nmulticlass problems [\n76]. \n2.3.2    Cross-lingual transfer learning brought by multilingual\ncorpora\nMLLMs  can  facilitate  CLTL  from  one  language  to  another.\n \n \nFig. 3    Diagram illustrating the RLHF procedure, which consists of three key steps: (1) Pre-training a LM using the labeled prompt-response\ndataset,  (2)  Training  a  Reward  Model  based  on  scores  provided  by  human  evaluators  for  LM’s  generation,  and  (3)  Fine-tuning  with  a\nReinforcement Learning (RL) algorithm, which helps to update parameters in the LM based on the feedback from RM\n6 Front. Comput. Sci., 2025, 19(11): 1911362\nThis  naturally  raises  the  question  of  how  much  CLTL\ncapability  that  MLLMs  possess  to  support  these  unseen\nlanguages or low-resource languages during pre-training.\nResearch  has  been  dedicated  to  exploring  the  cross-lingual\ntransferability  of  MLLMs  through  zero-shot  learning.  Lin\net  al.  [\n77]  trained  4  multilingual  generative  language  models\nand examined their zero-shot and in-context few-shot learning\ncapabilities  in  a  wide  range  of  tasks.  They  found  that  these\nmodels  can  achieve  cross-lingual  few-shot  learning  in  non-\nEnglish languages without requiring source-to-target language\ntranslation. Tian et al. [\n78] found that MLLMs exhibit strong\nrumour  detection  performance  in  zero-shot  cross-lingual\ntransfer learning. What’s more, MLLMs showed surprisingly\nstrong  multilingual  reasoning  abilities  even  in  under-\nrepresented languages such as Bengali and Swahili [\n79].\nTo  further  improve  the  transfer  learning  performance  of\nMLLMs  on  unseen  or  low-resource  languages,  as  these\nlanguages still account for a significant portion of the world’s\nlanguages, MLLMs are pre-trained to learn languages from the\nsame linguistic family or branch [\n80,81]. MLLMs trained on a\nsmall amount of data from genetically related languages could\nachieve performance comparable to the ones trained on large\nbut unrelated data [\n80]. MLLMs trained on only low-resource\nlanguages with small datasets, which are similar to each other,\nsometimes  achieved  better  performance  than  models  trained\non  large  datasets  with  high-resource  languages  [\n81].  For\nexample, the AfriBERTa model [ 81], pre-trained on less than\n1 GB of text data from 11 African languages, most of which\nbelong  to  the  Bantu  branch  of  the  Niger-Congo  language\nfamily, demonstrated the effectiveness of scratching solely on\nlow-resource  languages  without  any  high-resource  transfer\nlearning.\nA  prominent  future  concern  will  be  how  to  improve  the\nCLTL  capacities  of  MLLMs.  Pikuliak  et  al.  conducted  a\nsurvey  on  existing  cross-lingual  transfer  paradigms  of\nMLLMs [\n82], while Philippy et al. investigated various factors\nthat  impacted  cross-lingual  transfer  performance,  including\nlinguistic  similarity,  lexical  overlap,  model  architecture,  pre-\ntraining setting, and pre-training corpus size [\n83]. Specifically,\nthis  avenue  of  research  seeks  to  investigate  how  and  why\nMLLMs  possess  different  CLTL  abilities  on  various\nlanguages. This pursuit holds the potential to leverage CLTL\ncapacities  to  mitigate  the  dependence  on  annotated  data  and\nmaintain or even enhance the performance of MLLMs in well-\ntrained or unseen languages.\n \n3    Multilingual corpora and datasets\nIn this section, we delve into the widely utilized multilingual\ncorpora that are associated with the training of MLLMs, and\nmultilingual datasets oriented for downstream tasks.\nTable 3 summarizes  the  multilingual  corpora  that\nrepresentative MLLMs trained on, offering insights into their\nlanguage distribution, data source, and language coverage.\nMLLMs  have a more extensive language coverage in  their\ntraining  data  compared  to  LLMs.  A  significant  portion  of\nthese  training  data  originates  from  multilingual  repositories\nlike  Common  Crawl,  Wikipedia,  and  web  documents,\nencompassing a broad range of languages. These multilingual\nrepositories  are  crucial  for  enhancing  the  cross-lingual\ncapability  of  MLLMs.  In  this  section,  we  discuss  training\ndata’s  language composition  from both  a general perspective\nand a language family perspective.\n \n3.1    Multilingual corpora in MLLMs\nFirst,  we  analyze  the  linguistic  composition  of  MLLMs’\ntraining data, investigating the total number of languages and\ndifferent  language  proportions  within  each  training  corpora.\nAnalysis  reveals  that  most  MLLMs  are  trained  on  corpora\nwhere English  is  the predominant language.  Notably,  several\nMLLMs,  including  GPT-3  [\n20],  Gopher  [38],  LaMDA  [30]\nand  InstructGPT  [21],  are  trained  on  corpora  where  English\ncomprises  over  90%.  The  overwhelming  English  texts  in\ncorpora lead to MLLMs’ English-centric ability. To alleviate\nthis  issue,  some  MLLMs  are  trained  on  corpora  with  more\nbalanced language distribution. For example, the training data\nof BLOOM [\n5] covers 46 languages, with English comprising\nless than half. YAYI 2 [ 85] makes great efforts to balance its\ntraining data, achieving a nearly 1:1 ratio between English and\nChinese training data. Compared to its base model PaLM [\n29],\nPaLM  2  [45]  includes  a  higher  percentage  of  non-English\ndata,  further  enhancing  its  multilingual  capabilities.  We\npresent  the  percentages  of  its  non-English  languages  in  the\nweb documents subset of its pre-training corpus in \nTable 3, as\nthe language distribution for English was not published.\nSecond,  we  explore  the  language  composition  of  MLLMs’\ntraining  data  from  a  language  family  perspective.  Languages\nwithin the same language family share similar characteristics\nand  MLLMs  have  better  transfer  performance  on  languages\nbelonging  to  the  same  language  family  [\n54].  Thus,  the\nproposition of language families in MLLMs’ training data can\nhelp  us  better  understand  the  multilingual  capabilities  of\nMLLMs.  What’s  more,  we  can  also  leverage  language\nfamilies to observe the linguistic composition of the MLLMs’\ntraining data. Since English is predominant in most MLLMs’\ncorpora,  considering  it  in  language  family  analysis  would\nheavily  favor  the  Indo-European  language  family  to  which\nEnglish belongs. To gain a more detailed understanding of the\nlanguage family proposition in MLLMs’ corpora, we exclude\nEnglish  and  focus  on  the  top  20  prominent  non-English\nlanguages  of  the  training  data  and  their  corresponding\nlanguage  families.  The  distribution  of  language  families  of\neach MLLM is shown in \nFig. 4.\nNotably, French, German, Chinese, and Spanish emerge as\nthe most prevalent languages in the training data. For example,\nFrench constitutes 1.8% of the training corpora for GPT-3 [\n20]\nand  12.9% of  the  training  corpora  for  PaLM  [29].  French,\nGerman,  and  Spanish  all  belong  to  the  Indo-European\nlanguage  family,  which  demonstrates  that  the  Indo-European\nlanguage  family  holds  a  prominent  position  in  MLLMs’\ncorpora, both in terms of quantity and linguistic diversity. An\nexception  to  this  is  Chinese,  which  belongs  to  the  Sino-\nTibetan  language  family  while  maintaining  a  significant\npresence  in  the  training  corpora.  But  in  terms  of  linguistic\ndiversity,  the  Sino-Tibetan  language  family  in  the  training\ncorpora,  mainly  consisting  of  the  Chinese  language,  is  much\nless diverse compared to the Indo-European language family.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 7\nBesides  Indo-European  and  Sino-Tibetan  language  families,\nsome  other  language  families  are  found  in  most  MLLMs’\ntraining corpora as well. Similar to Sino-Tibetan, they mainly\ncontain  only  one  language  in  training  corpora.  For  example,\nAustronesian  mainly  includes  Indonesian,  Japonic  mainly\nincludes  Japanese,  and  Koreanic  mainly  includes  Korean.\nApart  from  the  lack  of  diversity  within  the  same  language\nfamily,  there  is  also  a  lack  of  diversity  across  different\nlanguage families in MLLMs’ training corpora. For example,\ndespite Niger-Congo and Trans-New Guinea being among the\nlargest language families in the world, they are notably absent\nfrom the top 20 languages in the training data.\nThrough the above analysis of multilingual training corpora\nin  MLLMs,  we  have  derived  the  following  key  insights:\nMLLMs  broaden  language  coverage  beyond  LLMs,  yet\nEnglish  remains  dominant  in  their  training  corpora.  From  a\nlanguage family perspective, Indo-European languages occupy\na  prominent  place  in  terms  of  both  quantity  and  linguistic\nvariety. Further work should consider a more comprehensive\ninclusion  of  language  families  and  prioritize  linguistic\ndiversity  within  the  same  language  family  when  training\nMLLMs.\n \n3.2    Multilingual datasets for downstream tasks\nMultilingual  datasets  play  a  crucial  role  in  fine-tuning\nMLLMs  to  be  adaptive  across  various  NLP  tasks. \nTable 4\nsummarizes  some  representative  multilingual  datasets,\nincluding  Multilingual  Named  Entity  Recognition\n(Multilingual  NER),  Multilingual  Sentiment  Analysis\n(Multilingual  SA),  Cross-Lingual  Information  Retrieval\n  \nTable 3    An overview of representative multilingual training corpora of MLLMs in recent years, including their corresponding model, language, language\nproportion, and source\nModel Language Language proportion Source\nmBERT [\n2] 104 languages Unknown Wikipedia\nXLM-R [7] 100 languages\nEnglish (12.56%); Russian (11.61%);\nIndonesian (6.19%); Vietnamese (5.73%);\nOthers (63.89%)\nGenerated using the open source;\nCC-Net repository\nmT5 [4] 101 languages\nEnglish (5.67%); Russian (3.71%);\nSpanish (3.09 %); German (3.05%);\nOthers (84.48%)\nCommon Crawl\nGPT-3 [20] 95 languages English (92.7%); French (1.8%);\nGerman (1.5%); Others (5.9%)\nCommon Crawl; Wikipedia;\nBooks1; Books2; WebText2\nGopher [38] 51 languages Over 99% English MassiveWeb (48%); C4 (10%); News (10%);\nBooks (27%); GitHub (3%); Wikipedia (2%)\nLaMDA [30] Unknown Over 90% English Public dialog data and other public web documents\nPaLM [29] Over 100 languages\nEnglish (77.98%); German (3.50%);\nFrench (3.25%); Spanish (2.11%);\nOthers (13.15%)\nSocial media conversations (50%);\nFiltered webpages (27%);\nBooks (13%); GitHub (5%);\nWikipedia (4%); News (1%)\nBLOOM [5] 46 languages\nEnglish (30.03%); Simplified Chinese (16.16%);\nFrench (12.9%); Spanish (10.85%);\nPortuguese (4.91%); Arabic (4.6%);\nOthers (20.55%)\nWeb Crawl(38%);\nBigScience Catalogue Data(62%)\nLLaMA [6] Over 20 languages Over 67% English\nCommon Crawl (67.0%); C4 (15.0%);\nGithub (4.5%);Wikipedia (4.5%);\nBooks (4.5%); ArXiv (2.5%); StackExchange (2.0%)\nVicuna [34] Unknown Unknown User-shared conversations from ShareGPT.com\nFalcon [84] Over 100 languages\nExcluding English:\nRussian (13.19%); German (10.81%);\nSpanish (9.45%); Others (66.55%)\nCommon Crawl\nPaLM 2 [45] Over 100 languages\nExcluding English:\nSpanish (11.51%); Chinese (10.19%);\nRussian (8.73%); Others (69.57%)\nWeb documents; Books;\nCode; Mathematics;\nConversational data\nLLaMA 2 [46] Over 100 languages\nEnglish (89.70%); Unknown (8.38%);\nGerman (0.17%); France (0.16%);\nOthers (1.59%)\nPublicly available sources excludes Meta user data\nGPT-4 [22] Over 26 languages Unknown Common Crawl; Wikipedia;\nBooks1; Books2; WebText2\nLLaMA 3 [52] 176 languages Over 5% non-English Publicly available sources excludes Meta user data\nGLM-4 [50] 26 languages Mostly English and Chinese Webpages;Wikipedia;Books;\nCode;Research papers\nClaude 3 [51] Over 43 languages Unknown\nPublicly available information on the Internet;\nNon-public data from third partie;\nData provided by data labeling services and paid contractors;\nData they generate internally\nYAYI 2 [85] Over 10 languages\nChinese (41.5%); English (40.4%);\nFrench (2.5%); Spanish (2.2%);\nOthers (25%)\nWeb pages; Social media;\nBooks; Newspapers; Academic Papers\nFuxiTranyu [86] 43 languages\nEnglish (28.8%); Chinese (10.4%);\nGerman (8.1%); French (7.3%);\nOthers (45.4%)\nWeb (82%); Code (9%);\nPaper (3%); Book (3%);\nEncyclopedia(2%); Report(1%)\n8 Front. Comput. Sci., 2025, 19(11): 1911362\n(Cross-Lingual  IR),  and  Multilingual  Text  Classification\n(Multilingual TC).\nMultilingual NER. Named Entity Recognition tasks locate\nand  classify  named  entities  from  unstructured  natural\nlanguages. These tasks utilize datasets from sources like News\nand  Wikipedia,  which  provide  rich  contextual  information\nacross  a  wide  range  of  real-world  entities.  Efforts  have  been\nmade to expand the training data for low-resource languages.\nA  notable  example  is  Masakha  NER2.0  [\n87],  the  largest\nhuman-annotated Africa-centric dataset, deriving its data from\nAfrican local news.\nMultilingual SA. Sentiment analysis tasks, which focus on\nthe  sentiment  orientation  of  data,  often  utilize  datasets\nextracted  from  comments  or  reviews  found  on  review\nplatforms such as Amazon and IMDb, as well as social media\nplatforms  like  Facebook  and  Twitter.  The  sentiment  analysis\ndataset  XED  [\n89]  is  sourced  from  OPUS  [99],  a  parallel\ncorpus  extracted  from  movie  subtitles.  In  terms  of  linguistic\ndiversity,  while  XED  [\n89]  primarily  focuses  on  English  and\nFinnish,  NollySenti  [90]  and  NaijaSenti  [91]  are  sentiment\nanalysis  datasets  specifically  designed  for  African  languages\nsuch as Hausa, Igbo, Nigerian, Pidgin and Yoruba.\nCross-lingual  IR. Cross-Lingual  Information  Retrieval\ntasks  ask  queries  in  one  language  and  retrieve  documents  in\none or more other languages. These tasks utilize datasets that\ninclude  documents  containing  hyperlinks  to  parallel\ndocuments  in  different  languages.  Therefore,  many  datasets\nsuch  as  AfriCLIR  Matrix  [\n92]  and  CLIR  Matrix  [93]  are\nsourced  from  multilingual  encyclopedias  (e.g.,  Wikipedia).\nCLIR  Matrix  [\n93]  is  the  current  largest  and  most\ncomprehensive  CLIR  dataset.  It  includes  Arabic,  German,\nEnglish,  Spanish,  French,  Japanese,  Russian,  and  Chinese,\n \n \nFig. 4    This analysis excludes English and focuses on ratios of language families of languages (top 20) in MLLM’s corpora. Note that Gopher\nonly released the top 10 languages and FuxiTranyu only released the top 13 languages used in training corpora. What’s more, some of the latest\nmodels like GPT-4 have not disclosed the proportion of their training data, so they aren’t included in the chart\n  \nTable 4    An overview of representative multilingual datasets for downstream tasks in recent years, including their corresponding task, release name, language,\nsize, and source\nTask Dataset Language Source Size\nMultilingual\nNER Masakha NER2.0 [\n87] 20 African\nlanguages News articles 4.8K to 11K sentences per language\nMultilingual\nNER MultiCo NER [\n88] 11 languages Wikipedia; ORCAS dataset MS-MARCO\nQnA corpus 26M tokens\nMultilingual SA XED [ 89] 32 languages OPUS More than 950 lines per language\nMultilingual SA NollySenti [ 90] 5 languages Movie reviews 1K to 1.5K reviews per language\nMultilingual SA NaijaSenti [ 91] 5 languages Twitter 30K tweets\nCrosslingual IR AfriCLIR Matrix [ 92] 15 African\nlanguages Wikipedia 6M English queries and 23M relevance judgments\nCrosslingual IR CLIRMatrix [ 93] 8 languages Wikipedia 49M unique queries and 34B (query, document,\nlabel) triplets\nMultilingual TC Taxi1500 [ 94] Over 1500\nlanguages Parallel translations of the Bible About 1K verses per language\nMultilingual TC MARC [ 95] 6 languages Amazon reviews 210K reviews per language\nMultilingual\nVersatile MUSE [\n96] 110 language\npairs Self-created About 6.5K word pairs for each language pair\nMultilingual\nVersatile\nWikipedia monolingual\ncorpora [\n97] 30 languages Wikipedia 10B tokens\nMultilingual\nVersatile Multilingual open text [\n98] 44 languages VOA News Over 2.8M news articles and an additional 1M\nshort snippets\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 9\ncovering  mainly  the  common  languages  of  all  continents\nexcept Africa. Thus, AfriCLIR Matrix [\n92] was developed to\naddress the absence of African languages.\nMultilingual TC. Text Classification tasks have diversified\napplications  on  news  classification,  sentiment  classification\nand  so  on.  These  tasks  utilize  diverse  datasets  tailored  for\nspecific  applications.  For  example,  Multilingual  Amazon\nReviews  Corpus  (MARC)  [\n95],  which  includes  product\ncategory  and  star  rating,  can  be  used  for  both  product\nclassification  and  sentiment  classification.  Taxi1500  [\n94],\ncovering  more  than  1500  languages,  relies  solely  on  the\nparallel translation of the Bible as its data source, limiting its\ndomain to religious-related text classification only. However,\nas Bible is the most translated book, its parallel translation is a\ngood data source to enhance linguistic diversity in datasets.\nMultilingual  versatile. Besides  the  multilingual  datasets\nmentioned  above,  Wikipedia  Monolingual  Corpora  [\n97],\nMUSE  [96]  and  Multilingual  Open  Text  (MOT)  [98]  are\nwidely  used  for  general  NLP  tasks.  Wikipedia  Monolingual\nCorpora [\n97] covers 30 languages. Each language has its own\nXML file, containing the full monolingual Wikipedia contents,\nwith  annotations  like  article  and  paragraph  boundaries,  the\nnumber of links referring to each article, cross-language links\nand  more.  MUSE  [\n96]  provides  state-of-the-art  multilingual\nword  embeddings  aligned  in  a  single  vector  space  for  30\nlanguages  and  110  large-scale  ground-truth  bilingual\ndictionaries.  Multilingual  Open  Text  (MOT)  [\n98]  comprises\nnews  articles  and  short  snippets  (photo  captions,  video\ndescriptions,  etc.)  from  Voice  of  America  (VOA)  news\nwebsites.  It  was  designed  to  supply  high-quality  unlabeled\ntexts for lower-resource languages like Albanian, Amharic and\nPersian.  It  contains  a  complete  collection  of  VOA’s\ndocuments  which  can  be  further  annotated  for  various  NLP\ntasks  (e.g.,  document  classification,  syntactic  or  semantic\nparsing).\n \n4    Multilingual representation alignment\nThe success of MLLMs is their ability to achieve multilingual\nrepresentation  alignment  from  multiple  languages. \nTable 5\nsummarizes  some  multilingual  alignment  performance  of\nMLLMs  on  10  languages  and  three  cross-lingual  tasks:\nbilingual  lexicon  induction  (BLI),  cross-lingual  classification\n(XNLI), and machine translation (MT). The alignment is from\nlanguages  of  Spanish  (ES),  German  (DE),  French  (FR),\nRussian  (RU),  Arabic  (AR),  Chinese  (ZH),  Bulgarian  (BG),\nTurkish  (TR),  and  Hindi  (HI)  to  English  (EN),  respectively.\nThe evaluation metrics include accuracy (for BLI and XNLI)\nand  BLEU  (for  MT).  The  performance  of  MLLMs  on\nmultilingual  alignment  varies  across  languages,  with  better\nperformance  observed  for  English  and  its  closely  related\nlanguages.\nAligning the representation of diverse languages acts as an\nintegral part of NLP’s multilingual tasks and applications [\n8].\nInspired  by  the  impressive  performance  of  monolingual\nrepresentation  models  like  Word2vec  [\n9]  and  GloVe  [10],\nrecent  research  has  made  great  progress  in  multilingual\nrepresentation. \nFigure 5 summarizes  the  evolution  of\nmultilingual  representation  from  static  approaches  to  more\ndynamic  ones  like  contextual  and  combined  multilingual\nrepresentations.  This  evolution  is  highly  influenced  by  the\nintroduction of MLLMs and their enhanced multilinguality.\nAs  shown  in \nFig. 6,  Static  multilingual  representations  are\nattained  through  learning  a  mapping  matrix  to  align  two\n  \nTable 5    A demonstration of the multilingual alignment performance of MLLMs on 10 languages, taking BLI, XNLI, and MT tasks as examples [\n100,101].\nBold text denotes the best performance across models. √ and × mean that the performance of MLLMS in a certain language is higher and lower than the average\nperformance, respectively\nTask Evaluation metric Model ES DE FR RU AR ZH BG TR HI Avg.\nBLI Acc.\nfastText [\n102] 72.00 67.17 − 56.42 47.43 33.39 45.69 48.92 28.19 49.90\nBLOOM-7B [5] 52.50 38.34 − 26.06 32.67 34.35 16.75 30.82 28.30 32.47\nLLaMA-13B [6] 60.58 57.80 − 64.44 22.13 32.28 56.86 44.90 30.68 46.21\nGPT-3.5 [20] 68.17 63.07 − 74.15 65.94 65.12 67.51 54.49 56.11 64.32\nAverage 63.31 56.60 − 55.27 42.02 41.29 46.70 44.78 35.82 48.23\nσStddev( ) 8.63 12.76 − 20.78 19.01 15.91 21.87 10.10 13.58 13.09\n√ or × √ √ − √ × × × × × −\nXNLI Acc.\nmBERT [2] 68.0 70.0 64.3 73.4 67.8 60.9 73.5 58.9 57.2 66.00\nmT5-270M [4] 78.6 77.4 73.3 79.1 77.1 72.8 80.3 70.8 68.3 75.30\nXLM-R-270M [7] 80.7 78.7 79.7 78.1 73.8 76.7 79.6 74.2 72.4 77.10\nmT5-10.7B [4] 87.7 87.3 84.5 86.9 85.1 83.8 87.8 83.2 79.8 85.12\nXLM-R-10.7B [7] 87.3 87.0 86.2 82.5 82.5 82.6 85.7 82.0 79.8 83.96\nAverage 80.46 80.08 77.68 80.0 77.26 75.36 81.38 73.82 71.50 77.50\nσStddev( ) 8.03 7.26 8.96 5.05 6.90 9.23 5.62 9.83 9.40 7.70\n√ or × √ √ √ √ × × √ × × −\nMT BLEU\nXGLM-7.5B [77] 27.98 34.03 36.81 27.83 26.06 6.06 34.48 23.91 26.99 27.13\nOPT-175B [31] 30.81 39.15 43.02 18.80 1.03 12.36 11.48 24.39 1.17 20.25\nFalcon-7B [84] 30.13 34.60 41.62 14.26 1.81 22.78 8.07 10.05 1.26 18.29\nLLaMA2-7B [46] 33.09 41.94 44.11 33.44 22.35 26.26 38.18 21.75 21.04 31.35\nChatGPT [40] 33.48 43.56 46.13 38.04 38.94 30.05 41.65 38.14 38.15 38.68\nGPT-4 [22] 33.76 47.04 48.81 38.75 43.29 32.83 44.97 43.43 45.88 42.09\nAverage 31.54 40.05 43.42 28.52 22.25 21.72 29.81 26.95 22.42 29.62\nσStddev( ) 2.29 5.13 4.10 10.18 17.91 10.46 15.94 12.04 18.55 9.62\n√ or × √ √ √ × × × √ × × −\n10 Front. Comput. Sci., 2025, 19(11): 1911362\nmonolingual embedding spaces, while contextual ones can be\nachieved by both mapping and joint approaches, with the latter\nbeing  supported  by  MLLMs.  To  achieve  even  better\nalignment,  combined  methods  were  proposed  to  take\nadvantage of both static and contextual information. Details of\nthe three paradigms will be explained below. Furthermore, we\nalso discuss the factors that will affect multilingual alignment.\n \n4.1    Static multilingual representation\nBased  on  whether  parallel  corpora  are  used  or  not,  static\nalignment  approaches  can  be  categorized  into  three  groups:\nsupervised,  semi-supervised,  and  unsupervised  approaches.\nRecently,  unsupervised  approaches,  such  as  MUSE  [\n96]  and\nVecMap [103], have gained much more attention.\nX YLet  and  represent monolingual word embeddings from\ntwo languages, respectively. Static alignment approaches can\nbe roughly divided into two steps: initially, the introduction of\nan initial mapping by aligning the source and target language\ndistributions;  subsequently,  a  pseudo-supervised  refinement\nbased on the initial solution, where the transformation matrix\nW W T W =I is constrained to be orthogonal, i.e., .\n \nW ∗ =arg min\nW\n∥W X−Y ∥. (3)\nOrthogonal  constraint  serves  as  a  method  to  ensure\nmonolingual  invariance  but  is  not  held  for  all  languages,\nparticularly  for  the  semantically  distant  languages  [\n104].\nTherefore, weak orthogonal constraints have been proposed to\nbetter align the embeddings across different languages.\nW\nGenerally,  linear  projection  only  learns  one  global\ntransformation  matrix  to  project  the  entire  embedding\nspace of the source to that of the target. However, the global\ntransformation matrix does not consistently perform optimally\nacross  all  subspaces  [\n105].  To  address  this  issue,  specific\nmappings for different subspaces have been proposed [106].\nStatic multilingual representations have exhibited promising\nperformance but there is still ample room for improvement on\nlow-resource  languages  and  distant  language  pairs.  Besides,\nthe polysemy problem in static multilingual representation has\nnot been well addressed and needs further exploration.\n \n \n \nFig. 5    Taxonomy of multilingual representation alignment that consists of static, contextual, and c ombined approaches. In addition, we also\nsummarize the factors that affect alignments\n \n \nFig. 6    An illustration of three approaches of multilingual representation alignment. English words are marked in red, while German words are\nin  yellow,  and  one  point  represents  an  embedding.  (a)  Static  approach,  where  a  one-to-one  correspondence  exists  between  points  and  words;\n(b) contextual approach, where each word has multiple corresponding embeddings; (c) combined approach\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 11\n4.2    Contextual multilingual representation\nContextual  representation  is  introduced  to  address  the\npolysemy  challenge  faced  in  static  representation.  ELMo\n[\n107]  and  BERT  [2]  stand  out  as  the  highly  representative\nmodels for contextual monolingual representation. Contextual\nmultilingual  word  representation  can  be  derived  from  these\nmodels.  The  existing  approaches  to  contextual  multilingual\nrepresentation  can  be  categorized  into  two  groups:  mapping\napproach and joint approach.\nMapping approaches use pre-trained contextual monolingual\nembeddings from various languages as input and project them\ninto a shared semantic space [\n108]. However, two challenges\nremain.  Firstly,  the  computation  cost  for  pre-trained\nmonolingual embeddings rises exponentially with the number\nof languages. Secondly, in contextual approaches, alignment is\nmore challenging compared to static ones. Simply calculating\na  mapping  alone  is  no  longer  sufficient  to  generate  robust\nalignments [\n8].\nIn  comparison,  joint  approaches  supported  by  MLLMs\nbelong to an end-to-end process, which no longer requires pre-\ntrained  monolingual  representations  but  instead  depends  on\nunlabeled  multilingual  corpora.  Tokenization  is  a  critical\ntechnique  in  the  end-to-end  process,  segmenting  raw  data\nfrom  various  languages  into  sequences  of  tokens  for\nsubsequent  processing  by  MLLMs.  Transformer-based\nMLLMs commonly employ subword-level tokenizers, such as\nByte-Pair  Encoding  (BPE)  [\n109]  and  WordPiece  [110],  to\naddress out-of-vocabulary (OOV) issue. What’s more, variants\nof  BPE  have  been  proposed  to  improve  the  tokenization  of\nmultilingual  corpora  and  alleviate  lexical  overlap  between\nlanguages.\nIn summary, contextual multilingual representation contains\nricher  in-context  information  than  the  static  multilingual\napproaches  and  thus  shows  greater  potential  for\nmultilinguality. However, there is still a range of multilingual\nNLP  tasks  that  contextual  multilingual  approaches\nunderperformed  than  static  ones,  demonstrating  that  several\nchallenges remain:\n1. It  comes  with  higher  computational  costs  and  is  far\nmore  resource-intensive  during  both  training  and\ninference.\n2. It is challenging to interpret the generated multilingua-\nlity  and  to  transform  the  MLLMs  into  multilingual\nlexical  encoders,  representative  contextual  embeddings\nare hard to extract and interpret properly [\n111,112].\n3. The  alignment  between  low-resource  languages  and\ndistant languages pairs has not been well investigated. \n4.3    Combined multilingual language representation\nCombined  multilingual  representation  has  been  proposed  to\ntake  advantage  of  both  static  and  contextual  paradigms.  The\nexisting combined multilingual approaches can be divided into\ntwo  paradigms:  (1)  From  Static  to  Contextual  (S2C),\nleveraging  static  information  to  induce  better  contextual\nmultilingual  alignment  [\n113];  (2)  From  Contextual  to  Static\n(C2S),  leveraging  contextual  information  to  induce  better\nstatic multilingual alignment [\n114,115].\nS2C  achieves  higher-quality  contextual  representation  by\nintegrating extra static instruction, while C2S achieves higher-\nquality  static  representation  by  integrating  extra  contextual\ninformation.  Although  S2C  makes  contextual  approaches\neasier  to  interpret,  the  accurate  extraction  of  contextual\nrepresentations from MLLMs is still a challenge.\nTherefore,  C2S  is  a  better  way  for  multilingual\nrepresentation  alignment.  Existing  C2S  can  be  divided  into\ntwo  steps:  1)  roughly  achieving  static  multilingual\nrepresentations,  as  introduced  in  Section  4.1;  2)  fine-tuning\nstatic  multilingual  representations  by  leveraging  contextual\nrepresentations. Zheng et al. [\n114] proposed a spring network\nto  use  the  contextual  representations  to  pull  the  static  word\nembeddings  to  better  positions  in  the  unified  space  for  easy\nalignment.  Li  et  al.  [\n115]  fine-tune  pre-trained  multilingual\nLMs to extract more useful representations and then combine\nstatic  and  extracted  contextual  embeddings  to  achieve  high-\nquality cross-lingual word embeddings.\n \n4.4    Factors that affect alignments\nBased  on  the  aforementioned  discussion,  we  delve  into  the\nimpact  of  various  factors  on  multilingual  alignment\nperformance  and  investigate  which  factors  have  a  more\nsignificant impact.\nInitial  solution. For  mapping  approaches,  the  initial\nsolution plays a crucial role in alignment. Because subsequent\noptimization is based on this initial solution, it will affect the\nrobustness  of  the  final  result  and  cause  the  alignment  to  fall\ninto  a  local  optimum.  Based  on  their  use  of  annotated  data,\nmapping  approaches  can  be  categorized  as  supervised,  semi-\nsupervised,  and  unsupervised  methods.  For  supervised  and\nsemi-supervised  methods,  the  quality  of  the  initial  solution\ndepends  on  the  quality  and  amount  of  the  seed  dictionary,\nwhile  unsupervised  ones  depend  on  the  robustness  and\neffectiveness  of  embedding  spaces’ distribution  matching,\nwhich is more difficult. GAN-based adversarial training [\n96],\noptimal  transport  solution  [116],  auto-encoder  [117],  and\ngraph  alignment  [ 118]  were  utilized  to  better  match\ndistribution  and  find  a  better  initial  solution  in  a  fully\nunsupervised way.\nLinearity  of  mapping. Mapping  functions  are  always\nconstrained  to  be  orthogonal  during  training  out  of  the\n“approximate  isomorphism  assumption”,  which  fails\nespecially when the two languages are far apart semantically.\nTo address this issue, Mohiuddin et al. [\n119] and Glavaš and\nVulić  [120]  used  a  non-linear  Mapping  function.  Marchisio\net  al.  [121]  considered  relative  isomorphism  during  the\nprocess  of  pre-training  monolingual  embedding,  which  can\naddress the misalignment from the root.\nTypological  distance. More  typologically  distant  language\npairs  tend  to  be  less  well-aligned  than  more  similar  ones\n[\n122].  In  the  Bilingual  Lexicon  Induction  (BLI)  task,  the\naccuracy  on  semantically  distant  language  pairs  is  always\nunder 40%, while similar ones are over 80 %. To alleviate this\nproblem, auxiliary languages have been proposed as a medium\nto bridge the gap between semantically distant language pairs\n[\n3,123].  For  distant  language  pairs,  one  or  several  more\nrelevant  languages  can  be  selected  as  auxiliary  languages.\nTransferring  the  additional  information  provided  by  the\n12 Front. Comput. Sci., 2025, 19(11): 1911362\nauxiliary  languages,  monolingual  embedding  or  corpora  can\nimprove the alignment between distant language pairs.\nPre-training  data  and  settings. Pre-training  data  and\nsettings  are  found  to  be  correlated  with  the  cross-lingual\ntransfer ability. The size and quality of data are crucial factors\nfor  enhanced  cross-lingual  transfer  capabilities  in  MLLMs.\nThe relative balance and diversity in the pre-training data and\nthe  larger  data  size  will  improve  the  efficiency  and\neffectiveness of MLLMs [\n7]. The settings of pre-training are\nalso  important  to  the  cross-lingual  performance  of  MLLMs.\nThe parameters scale [\n8], pre-training learning objective [ 124]\nand window size of input of MLLMs [ 125] have proved to be\ninfluential to cross-lingual transfer ability. \n5    Bias on multilingual LLMs\nBias  on  MLLMs  has  become  a  challenging  issue  to  their\nfairness  and  severely  restricts  the  deployment  of  MLLMsin\nreal-world.  Research  has  shown  that  language  models  can\nperpetuate and even exacerbate existing biases present in their\ntraining  data,  which  are  further  manifested  in  various  forms,\nsuch as gender bias, cultural bias, and language bias [\n126]. As\nshown  in Fig. 7,  LLMs  have  different  understanding  across\ndiverse biases, as evaluated on BBQ question-answer dataset\n[\n127].\nHowever,  the  existing  literature  on  bias  mainly  focuses  on\nstereotypical  biases  in  English  [13,14]  or  within  limited\nattributes  like  race  and  gender  [128],  which  limits  its\ngeneralizability  to  other  languages  or  attributes.  Bias  in\nMLLMs  has  not  been  well  investigated.  In  this  section,  we\naim to address the following questions. Why do MLLMs bias\nand  what  are  the  types  of  bias  in  existing  MLLMs  (Bias\nCategory), how to evaluate bias in MLLMs (Bias Benchmark),\nhow  to  mitigate  the  bias,  and  whether  debiasing  techniques\naffect  the  performance  of  MLLMs  (Debias  Technique).\nFig. 8 presents the taxonomy of this section. \n5.1    Bias category\nBias  in  MLLMs  can  arise  from  factors  such  as  unmoderated\ntraining data [\n129], differences in model design [ 12], and the\npresence  of  biased  multilingual  word  embedding\nrepresentations  [\n130].  Based  on  studies  related  to  bias  in\nMLLMs, we categorize these prevalent biases centered around\nspecific languages, limited attributes, and related models into\nthree types: language bias, demographic bias, and evaluation\nbias. \nTable 6 presents the bias category, bias source, as well as\nbias examples.\nLanguage  bias. Language  bias  refers  to  the  unequal\nperformances  of  MLLMs  among  different  languages,\nprimarily  due  to  the  dominance  of  English  and  other  major\nlanguages  in  the  available  multilingual  training  corpora.\nSpecifically  speaking,  MLLMs  exhibit  higher  proficiency  in\nthese  widely  used  languages  and  this  further  exacerbated  the\nlack  of  support  for  low-resource  languages  or  minority\ndialects  [\n131].  Recent  studies  have  brought  attention  to  the\nunequal  quality  of  multilingual  representations,  highlighting\nthat pre-trained models like mBERT and CLIP do not equally\nlearn  high-quality  representations  for  all  languages,\nparticularly for low-resource languages [\n132,133].\nWhen  investigating  knowledge  in  MLLMs,  Kassner  et  al.\n[134]  found  mBERT  exhibited  language  bias,  wherein  the\nchoice of query language can impact the obtained results. To\ngo a step further, studies in [\n135,136] explored how MLLMs\nexhibited  bias  across  languages  and  focused  on  bias  in\nattributes  like  race,  religion,  nationality,  and  gender.  They\nfound  that  mBERT  and  XLM-R  models  did  not  consistently\nshow  low-level  bias  in  certain  languages  [\n135];  mBERT,\nXLM-R, and mT5 exhibited varying degrees of fairness across\nlanguages  and  XLM-R  exhibited  higher  and  more  consistent\ncorrelations  across  languages  compared  to  mBERT and  mT5\n[\n136].\nDemographic  bias. Demographic  bias  refers  to  the\nMLLMs’ biased  behavior  towards  specific  gender,  race,\nethnicity,  or  other  social  groups,  caused  by  the  training  data\ndisproportionately emphasizing particular demographic groups\n[\n131]. Previous research has shown that both multilingual and\nmonolingual  LLMs  suffer  from  demographic  bias  towards\nspecific  social  groups  [\n137,138],  while  monolingual  LLMs\nspecific  for  low-resource  languages  exhibit  less  bias  [70].\nTouileb  et  al.  [ 137]  investigated  demographic  bias  in\nNorwegian demographics, finding that both language-specific\nmodels  like  Norwegian  pre-trained  language  models  and\nMLLMs  like  XLM-R  demonstrated  a  bias  towards  gender-\nbalanced occupations. Likewise, research in [\n138] discovered\nthat  MLLMs  like  BLOOM  and  ChatGPT,  along  with\nmonolingual  LLMs  trained  exclusively  on  Arabic  data,\ndisplayed  cultural  bias  towards  Western  culture.  This  is\nevidenced  by  the  fact  that  when  processing  and  generating\nArabic texts, Western-appropriate content is usually preferred\nover relevant Arabic content. Notably, LLMs for low-resource\nlanguages  like  Sudanese  exhibited  gender-neutral  behavior\nwithout  displaying  distinct  biases  [\n70].  Additionally,  bias\nagainst a particular cultural group is a common manifestation\nof demographic bias. Levy et al. [\n135] revealed that mBERT\nand  XLM-R  favored  culturally  dominant  groups  in  each\nlanguage.  GPT-3  has  been  found  to  exhibit  a  stereotypical\nreligious  bias  for  associating  Muslims  with  violence  more\noften than other religious groups [\n139].\nEvaluation  bias. Evaluation  bias  refers  to  the  bias  that\nexists  in  the  evaluation  metrics  for  LLMs.  Factors  that  can\nbias  the  metric  calculation  itself  include  noise  in  the\nevaluation dataset, models used in the metric calculation, and\nthe  configuration  of  the  inference  experiment  [\n140].\n \n \nFig. 7    Accuracy of different LLMs across various bias categories on BBQ\nquestion-answer dataset (data from [\n127])\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 13\n \n \nFig. 8    Taxonomy of bias on MLLMs that consists of bias category, bias benchmark, and debias techniques\n  \nTable 6    An illustration of bias on MLLMs, consisting of bias category, why do bias and bias examples\nBias category Why do bias Example\nLanguage bias\nThe dominance of English and other major\nlanguages in the available multilingual training\ncorpora.\nInput in English: As a Black woman,she feels hopeless.\nSentiment Prediction: Positive\nInput in Chinese: 作为一个黑人女性, 她感到绝望.\nSentiment Prediction: Negative\nExplain: A biased model predicts opposite sentiments for two sentences with the same\nmeaning in English and Chinese.\nDemographic bias\nBiased behavior towards specific gender, race,\nor other social groups due to disproportionate\ntraining data\nGender Bias:\nInput: The receptionist called the doctor and told [MASK] about a new patient.\nGeneration: [MASK] is“him”but not “her.”\nReligious Bias:\nInput:The person entered the temple and [MASK] read the Torah.\nGeneration: MASK is \"Jewish\" but not \"Christian\".\nExplain:The model tends to make judgments based on genderand religious stance,\nreflecting stereotypes that doctors should be male and those reading the Torah should\nbe Jewish.\nEvaluation bias\nFactors that can bias the metric calculation\nitself include noise, models used in the metric\ncalculation, and the configuration of the\ninference experiment.\nInput 1: Although Pecard was sick...\nInput 2: Although Pelcra was sick...\nGeneration: Although Pecard (Pelcra) was sick…, he (she) insisted going to work.\nBERTScore: 0.8\nExplain: The model has phonology-gender association biases and tend to consider\nnames ending in consonants as male and names ending in vowels as female. However,\nthe BERTScore evaluation criterion fails to detect this.\n14 Front. Comput. Sci., 2025, 19(11): 1911362\nSignificantly,  if  bias  against  certain  sensitive  attributes,  such\nas  gender,  occurs  in  the  evaluation  metrics,  models  that\nreinforce  such  bias  are  likely  to  be  rewarded  and  favored\n[\n141]. For this reason, Sun et al. [ 142] conducted a systematic\nstudy of social biases in various PLMs-based metrics, such as\nBERTScore  [\n143],  BLEURT  [144],  and  BARTScore  [145].\nThe study found that these PLMs-based metrics demonstrated\nhigher  social  biases  than  traditional  metrics  across  six\nsensitive  attributes:  race,  gender,  religion,  appearance,  age,\nand  socioeconomic  status.  Further  analysis  revealed  that  the\nchoice of modeling paradigms [\n145] (matching, regression, or\ngeneration)  in  PLMs-based  metrics  has  a  greater  impact  on\nfairness  than  the  choice  of  PLMs  themselves.  To  assess  the\nbias  evaluation  of  LLMs,  Koo  et  al.  [\n146]  proposed\nCOBBLER, the Cognitive Bias Benchmark for evaluating the\nquality and reliability of LLMs as automatic evaluators. They\nfound that the majority of these LLMs-as-evaluators exhibited\nseveral  cognitive  biases.  This  raises  questions  about  their\nability to make fair evaluations, suggesting that most current\nLLMs  are  unable  to  perform  well  as  unbiased  automatic\nevaluators. Because of the inherent subjective nature of these\nmetrics,  which  means  it’s  hard  to  mitigate  evaluation  bias,\nDelobelle  et  al.  [\n147]  recommended  avoiding  embedding-\nbased  metrics  and  focusing  on  fairness  assessments  in\ndownstream tasks to improve the evaluation of bias.\n \n5.2    Bias benchmark\nThis  section  focuses  on  the  issue  of  bias  evaluation  in\nMLLMs.  Extensive  studies  have  developed  varied  datasets\nand approaches that serve as benchmarks for bias assessment.\nIn  this  section,  we  provide  a  thorough  review  of  these\nbenchmarks. \nTable 7 illustrates  benchmarks  commonly  used\nfor evaluating bias. Notably, these datasets primarily focus on\nbias attributes related to gender and occupation [153,154,157],\npredominantly  available  in  English  [ 149,155,156,158].\nSeveral  datasets  also  encompass  languages  such  as  Spanish,\nGerman, and French [\n130,136].\nBased  on  the  tasks  and  languages,  benchmarks  in Table 7\ncan be categorized into three types: general benchmarks, task-\nspecific benchmarks, and language-specific benchmarks.\nGeneral benchmarks mainly refer to evaluation benchmarks\nthat  have  a  wide  range  of  applications  and  can  be  used  for\ndifferent  tasks,  including  some  major  evaluation  metrics  and\ndatasets. For example, Association Tests (WEAT, SEAT, and\nCEAT)  [\n148,150,151]  are  widely  used  to  measure  bias  in\nword-,  sentence-,  and  contextualized-level  embeddings;\nGLUE  [\n149]  is  designed  to  measure  the  impact  that  the\nintroduced  debiasing  techniques  will  have  on  downstream\nperformance by evaluating the capabilities of the NLP model.\nTask-specific  benchmarks  refer  to  benchmark  datasets\ndesigned  for  a  specific  task  or  situation.  For  example,\nWinogender [\n153] and WinoBias [ 154] are applicable for the\ncoreference resolution system; CrowS-Pairs [ 156] is designed\nfor  detecting  bias  against  social  groups,  particularly  in  the\nUnited States.\nMultilingual benchmarks refer to the benchmark datasets in\nmultilingual  contexts,  including  MIBs  [\n130]  and  MozArt\n[136]. The lack of robust multilingual evaluation benchmarks\nposes  significant  barriers  to  assessing  biases  in  multilingual\ncontexts.  Therefore,  creating  more  multilingual  evaluation\ndatasets  is  an  urgent  problem  to  be  solved.  One  potential\nsolution  is  to  translate  existing  bias  benchmarks  that  mainly\nonly cover English [\n160,161]. Nevertheless, it is important to\nnote  that  translated  benchmarks  may  introduce  additional\nbiases due to translation errors and cultural differences. Thus,\nwhen designing a multilingual bias benchmark, it’s crucial to\n  \nTable 7    An overview of bias benchmarks categorized into general, task-specific, and language-specific types, including supported language, targeted biases,\nand goals. The supported language labeled as “−” means this is a bias evaluation metric and is irrelevant to language\nCategory Benchmark Language Type of bias Goal\nGeneral\nWEAT [\n148] − Gender Measure bias in word embeddings.\nGLUE [149] English Untargeted Evaluate how debiasing techniques affect downstream task\nperformance.\nSEAT [150] − Gender Measure bias in sentence encoders.\nCEAT [151] − Untargeted Measure bias in contextualized word embeddings.\nInBias [130] − Gender, Occupation Quantify intrinsic bias in multilingual word embeddings.\nExBias [152] − Gender, Occupation Measure debiasing word embeddings by comparing their performance\nbefore and after debiasing.\nStereoSet [14] English Gender, Occupation,\nRace etc. Evaluate the stereotypical biases of popular PLMs.\nTask-specific\nWinogender [153] English Gender, Occupation Identify bias in in coreference resolution systems.\nWinoBias [154] English Gender, Occupation Identify bias in coreference resolution systems.\nEEC [155] English Gender, Race Measure bias of race and gender through differences in predicting\nsentiment intensity between sentences.\nCrowS-Pairs [156] English Race, Age, Religion\netc. Measure certain social bias in LLMs.\nWinoMT [157] English Gender Investigate gender bias in machine translation systems.\nBiosBias [158] English Gender, Occupation Evaluate bias in predicting individual occupation based on their short\nbiography.\nFairFace [159] Face Attribute\nbenchmark Gender, Race, Age Evaluate how to mitigate bias in existing databases by collecting more\ndiverse facial images.\nLanguage-\nspecific\nMIBs [\n130] English, Spanish,\nGerman, French Gender, Occupation Conduct the intrinsic bias analysis.\nMozArt [136] English, Spanish,\nGerman, French Gender, Language Evaluate whether MLLMs are equally fair to demographic groups\nacross languages.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 15\nconsider  various  cultural  contexts  and  develop  culturally\ndiverse datasets [\n12]. \n5.3    Debias technique\nBias in MLLMs rises significant ethical concerns, potentially\nleading  to  serious  consequences.  Demographic  bias,  in\nparticular, can result in the unfairly representation or treatment\nof  certain  groups,  thereby  perpetuating  societal  inequalities.\nFor  instance,  if  gender  bias  is  present  in  reference  letters\ngenerated  by  MLLMs  and  not  properly  addressed,  it  could\nharm  the  success  rates  of  female  applicants  [\n162].  Similarly,\nlanguage  bias  can  reinforce  cultural  stereotypes  and\nmisunderstandings,  inadvertently  exacerbating  negative\nperceptions  against  other  cultures  when  models  favor  certain\nlanguages or cultural contexts, thereby undermining efforts to\npromote  inclusivity  and  diversity.  Additionally,  evaluation\nbias  compromises  the  reliability  and  fairness  of  model\nevaluations,  leading  to  skewed  performance  metrics  and\nmisinformed  decisions.  Mitigating  these  biases  is  crucial  for\nensuring ethical integrity, fairness, and transparency in MLLM\napplications.\nCurrent  debiasing  techniques  for  MLLMs  can  be  broadly\ncategorized  into model  debiasing and data  debiasing.  Model\ndebiasing techniques rely on refining MLLMs’ inner settings\nlike  pre-training  parameters,  fine-tuning  datasets,  and\nrepresentations,  while  data  debiasing  focuses  on  addressing\nbias within the input training data of MLLMs.\n \n5.3.1    Model debiasing\nAs  presented  in \nFig. 9,  the  existing  methods  for  debiasing\nmodels  can  be  categorized  into  four  lines  according  to  their\ndebiasing  stage:  representation  based  methods,  pre-training\nbased methods, fine-tuning based methods, and prompt based\nmethods.\nRepresentation based methods. Representation, commonly\nemployed  to  encode  semantic  information  of  texts,  has  the\npotential  to  encode  unintended  biases.  For  example,  words\nassociated  with  specific  professions  like “nurses” and\n“homemakers”, may cluster near feminine words, acting as a\npotential  source  of  semantic  bias  for  downstream  models\n[\n148]. Representations based methods aim to mitigate bias at\nsentence-level [163] or word-level [164].\nSentence-level methods: Sent-Debias is introduced to debias\nsentence-level representations by estimating a linear subspace\nfor  a  particular  type  of  bias  [\n163].  The  debiasing  process\ninvolves  projecting  onto  the  estimated  bias  subspace  and\nsubtracting the resulting projection from the original sentence\nrepresentations.\nWord-level  methods:  They  focus  on  static  [\n164]  or\ncontextual  embedding  representations  [165].  For  example,\nINLP  [164]  was  proposed  to  remove  bias  like  race,  gender,\nand  age  in  static  word  embeddings  with  iterative  null-space\nprojection-based  debiasing  method.  Linguistic  Identity\nRemoval  (LIR)  [\n165]  was  proposed  to  address  bias  in\nmultilingual  contextual  word  embeddings.  It  utilizes  singular\nvalue decomposition and orthogonal projection to identify and\nremove linguistic information in multilingual semantic space.\nPre-training  based  methods. In  this  approach,  debiasing\noccurs during the pre-training stage, where the parameters of\nLLMs  are  modified  to  align  with  fairness  criteria  such  as\nSEAT  [\n150].  Dropout  as  proposed  in  [166],  is  a  bias\nmitigation  technique  using  dropout  regularization  [167].  By\nadjusting  dropout  parameters  in  BERT  and  ALBERT  for\n \n \nFig. 9    Existing  methods  for  model  debiasing  can  be  categorised  into  representation  based  methods,  pre-training  based  methods,  fine-tuning\nbased methods, and prompt based methods according to its debiasing stages\n16 Front. Comput. Sci., 2025, 19(11): 1911362\nattention  weights  and  hidden  activations,  along  with\nperforming an extra phase of pre-training, gender bias within\nthese models can be alleviated. However, this method cannot\nguarantee whether the bias associations may resurge when the\ndebiased models are fine-tuned on downstream tasks [\n168].\nFine-tuning  based  methods. In  this  approach,  debiasing\noccurs  during  the  fine-tuning  stage,  which  is  independent  of\nthe  model  architecture  or  pre-training  parameters,  making  it\napplicable  across  various  downstream  tasks.  Leonardo  et  al.\n[\n169] proposed a debiasing approach for LLMs through fine-\ntuning using causal language modeling. They selectively froze\na  large  number  of  parameters  and  trained  the  model  using\nLoRA  [\n170].  This  technique  yields  robust  debiased  models\nthat maintain high performance on downstream tasks.\nHowever, fine-tuning the models on top of the pre-training\nstage  carries  the  risk  of  inheriting  biases,  given  that  biases\nfrom the pre-trained stage tend to propagate to the fine-tuned\nmodels.  Therefore,  it  is  more  beneficial  to  effectively\nmanipulate the fine-tuned dataset to debias than to intervene in\nthe pre-trained model itself [\n171]. In addition, fine-tuning all\npre-trained parameters requires huge computing resources and\ntime, and it is crucial to address how to debias effectively with\na smaller set of parameters.\nPrompt based methods.  This approach mitigates biases in\nMLLMs  without  heavily  relying  on  additional  corpora  for\nfine-tuning, as low-quality corpora may introduce new biases.\nStudies found that prompting can reduce bias in MLLMs but\nits  success  is  largely  dependent  on  the  chosen  prompt\n[\n172,173].  Prompt  based  debiasing  methods  need  to  address\ntwo  issues:  how  to  measure  biases  carried  by  MLLMs  and\nhow to debias them.\nFor example, Guo et al. [\n172] proposed a framework named\nAuto-Debias, using cloze-style prompts to probe, identify, and\ncorrect the biases in PLMs. This method first searches for the\nbiased prompts, probes the biased content with such prompts,\nand then corrects the model bias. Mattern et al. [\n173] explored\nGPT-3’s stereotypical associations with genders and jobs and\nproposed  a  framework  to  quantify  and  further  reduce  these\nbiases  using  debiasing  prompts.  They  also  discussed  prompt\nselection  with  varying  degrees  of  abstraction  and  concluded\nthat  more  concrete  debiasing  prompts  exhibited  a  more\npronounced  effect.  Dhingra  et  al.  [\n174]  demonstrated  that\nemploying  a  method  involving  chain-of-thought  prompting\nthrough SHAP analysis can efficiently mitigate biases against\nqueer  people  in  the  output  of  LLMs.  Schick  et  al.  [\n175]\nintroduced  a  debiasing  technique  named  Self-Debias  which\nuses  a  model’s  internal  knowledge  to  discourage  biased  text\ngeneration.  It  starts  by  utilizing  hand-crafted  prompts  to\nencourage  the  model  to  generate  toxic  text.  Subsequently,  a\nsecond  continuation  that  is  non-discriminatory  can  be\nproduced from the model by scaling down the probabilities of\ntokens considered likely under the first toxic generation.\n \n5.3.2    Data debiasing\nData  debiasing  aims  to  mitigate  bias  within  input  training\ncorpora,  helping  MLLMs  generate  debiased  content.\nCurrently, prevalent data debiasing efforts focus on two types\nof bias: language bias and demographic bias.\nLanguage  bias  mitigation.  Language  bias  in  MLLMs  is\ncaused  by  the  imbalanced  language  proportion,  acting  as  the\ndominance  of  English  and  other  major  languages  in  the\navailable  multilingual  training  corpora.  Constructing  more\nbalanced  corpora  has  proven  to  be  an  effective  solution  for\nmitigating  language  bias.  For  example,  XNLI  [\n176]  was\ndeveloped to support 15 languages on the evaluation of XLU,\nproviding information-rich standard evaluation tasks for cross-\nlanguage  sentence  understanding.  In  addition,  the  release  of\nCulturaX  [\n177],  a  multilingual  dataset  that  includes  167\nlanguages and a total of 63,000 tokens, addresses the lack of\nopen-source  and  easy-to-use  datasets  for  effectively  training\nmultilingual  large  models.  Furthermore,  the  ROOTS  dataset\n[\n178] was developed to cover 59 languages, with a total size\nof 1.6 TB.\nHowever, building more balanced corpora also faces many\nchallenges.  First,  manually  collecting  and  annotating  low-\nresource  data  requires  high  human  costs.  To  prevent  the\nintroduction  of  additional  bias,  relatively  professional  data\nannotators  are  required  and  need  to  be  trained  in  advance.\nSecond,  a  large  part  of  the  low-resource  corpora  is  of  low\nquality. Kreutzer et al. [\n179] found a large part of the corpora\ncontained less than 50% of sentences of acceptable quality and\ndiscussed the potential risks of releasing low-quality data. In\nshort, evaluating and improving the techniques to build high-\nquality  multilingual  corpora  is  essential  for  development  of\nMLLMs.\nDemographic  bias  mitigation.  Demographic  bias  occurs\nwhen  data  overly  emphasizes  or  represents  a  certain  specific\npopulation.  The  commonly  used  method  for  mitigating\ndemographic bias is counterfactual data augmentation. Based\non  identifying  biased  terms,  it  creates  text  that  contradicts\nexisting facts, reducing over-reliance on specific scenarios or\ngroups and mitigating biases stemming from class imbalances\nwithin  data.  With  the  method,  model’s  reliance  on  false\nfeatures can be largely reduced, thereby enhancing the model’s\nrobustness. Counterfactual augmented data is mainly achieved\nthrough  two  methods:  manual  generation  and  model\ngeneration,  both  of  which  achieve  comparable  quality  of\ngeneration [\n180]. Existing studies [ 181–183] have shown that\ncounterfactual  data  augmentation  is  a  simple  and  effective\napproach to mitigate bias in data.\nApart  from  its  impressive  performance  in  mitigating  bias\nwithin datasets, counterfactual augmented data can also serve\nas  an  evaluation  tool  for  detecting  bias  existing  in  MLLMs.\nCounterfactual  data  augmentation  alters  certain  variables  or\nfeatures in the original data to highlight different data points.\nThis  method  aids  in  understanding  how  changes  in  these\nvariables  affect  the  system’s  output,  uncovering  potential\nbiases  or  dependencies  not  readily  apparent  in  the  original\ndataset [\n184]. However, it also has limitations and drawbacks,\nsuch as possibly overlooking context information, causing the\nmodel to confuse key features [\n185], or preventing the model\nfrom  learning  robust  features  that  have  not  been  perturbed\n[\n186],  and  it  may  even  exacerbate  false  correlations  in  the\ndata. \n5.3.3    Effectiveness and challenges\nDebiasing  techniques  for  MLLMs  have  shown  promise  in\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 17\nmitigating biases and improving fairness. Both model and data\ndebiasing  approaches  play  vital  roles  in  addressing  ethical\nconcerns,  with  complementary  effectiveness  and  challenges.\nEffectiveness from different techniques can be summarized as\nfollow:\nFlexibility  and  adaptability  from  model  debiasing.  By\ndirectly  modifying  the  model’s  internal  representations  or\noutputs,  model  debiasing  allows  for  targeted  adjustments  to\naddress specific tasks and biases. These techniques have been\nshown  to  significantly  reduce  stereotypes  in  text  generation\n[\n173,175]  and  question  answering  [ 164,169],  achieving\nquantifiable  improvements  in  fairness  metrics  while\nmaintaining  competitive  task  performance.  This  approach  is\nadvantageous  as  it  does  not  require  changes  to  the  training\ndata,  making  it  both  efficient  and  adaptable.  However,  its\nimpact  is  often  limited  when  foundational  biases  within  the\ntraining data remain unaddressed.\nSystemic  and  long-term  improvements  from  data\ndebiasing.  Data  debiasing  alleviate  biases  at  their  source  by\nimproving the quality and balance of the training data used to\npre-train  MLLMs.  This  approach  excels  in  addressing\nsystemic issues such as language imbalances and demographic\nbiases,  enabling  MLLMs  to  perform  more  fairly  across  both\nhigh- and  low-resource  languages,  as  well  as  different\ndemographic  groups.  This  is  demonstrated  by  improved\naccuracy  in  cross-lingual  understanding  [\n2,5]  and  enhanced\nfairness in demographic sentiment analysis tasks [181,183].\nDespite  progress  in  addressing  ethical  concerns  through\ndebiasing, challenges still persist in achieving comprehensive\nand scalable solutions.\nTrade-offs with performance . Many debiasing techniques\nintroduce  trade-offs,  where  mitigating  bias  can  result  in\nreduced  accuracy  or  fluency  in  downstream  tasks  [\n154,187].\nBalancing  fairness  and  performance  remains  a  critical\nconcern,  especially  in  low-resource  languages,  where\navailable data is often scarce and the risk of model overfitting\nor bias amplification is higher. This challenge is a promising\ndirection worth exploring in depth.\nDependency on context. The inherent diversity of language\nand  culture  makes  achieving  absolute  fairness  across  all\ncontexts  difficult  [\n188].  While  constructing  more  balanced\ncorpora  is  a  viable  solution  for  mitigating  language  bias,  the\neffective  collection  and  integration  of  high-quality,  low-\nresource language texts remains a formidable challenge [\n179],\noften  requiring  significant  human,  financial,  and\ncomputational resources.\nLack  of  interpretability .  Existing  methods  for  bias\nunderstanding and mitigation face a major challenge: the lack\nof interpretability. Biases may stem not only from the model\nitself  but  also  from  external  factors  like  training  data,\nalgorithms, or task settings. Research into bias interpretability\nhelps identify these sources, enabling more targeted debiasing\nstrategies.  Methods  like  bias  attribution  in  neural  networks\n[\n169]  and  identifying  bias  neurons  [189]  are  crucial  for\nimproving fairness and transparency. \n6    Future directions\nThis  survey  provides  a  holistic,  systematic  overview  of  the\nevolution of multilingual large language models. The MLLMs\nare  still  in  a  developing  stage  and  thus  there  are  still  several\nchallenges for future research, which we summarize below:\n● Performance  on  low-resource  languages.  MLLMs\noutperform monolingual LLMs in downstream tasks for\nhigh-resource languages, but their performance on low-\nresource languages remains unsatisfactory [\n190], which\nmay  be  due  to  limited  annotated  data  [191]  for  low-\nresource  languages  and  low  lexical  overlap  between\nhigh-resource  and  low-resource  languages  [\n192].\nSpecializing MLLMs based on language families can be\nan efficient way to more easily share information across\nlanguages [\n193]. In addition, how to find a more robust\ntokenizer  for  most  languages  is  worth  investigating  as\nwell.\n● Limited  and  unbalanced  multilingual  corpora.  The\nperformance of MLLMs largely depends on the training\ndata’s quality, size, and diversity [\n194]. However, there\nis  only  a  limited  amount  of  data  available  for  most  of\nthe world’s languages. The overwhelming English texts\nin  corpora  lead  to  MLLMs’ English-centric  ability.\nEven  though  for  some  high-resource  languages  where\ndata  is  available,  previous  work  has  shown  that  some\ncommonly  used  multilingual  resources  have  severe\nquality  issues  [\n195].  How  to  collect  much  more  high-\nquality,  larger  scale,  and  more  diverse  training  data\nfrom various languages deserves further research.\n● Usage  of  multimodal  data  sources .  Leveraging\ninformation  from  multimodal  data  sources  such  as\nspeech  and  images  can  alleviate  high  reliance  on  text\ndata. Human cognition and perception capabilities rely\non  diverse  information,  and  the  usage  of  multimodal\ndata can better align with human intentions. Supported\nby  multimodal  data  equates  to  higher  quality,  more\ndiverse  training  data.  However,  how  to  achieve\nuniversal  representation  accurately  by  modality\nalignment  poses  a  new  challenge,  deserving  further\ninvestigation.\n● Evaluation  of  multilingual  LLMs.  The  evaluation\nbenchmarks  for  MLLMs  are  mainly  based  on  the\ndevelopment  of  English  task  sets.  However,  these\nbenchmarks are not fully applicable to other languages.\nAlthough  some  task  sets  can  be  translated  into  other\nlanguages,  due  to  the  differences  between  languages,\nthe performance of the translated data set will be lower\nthan  the  source  language.  Besides,  current  evaluation\nbenchmarks are all task-centric, lacking a universal and\nflexible evaluation system. The topic of how to collect\nhigh-quality multilingual evaluation datasets and build a\nsystem  to  properly  evaluate  the  true  multilinguality  of\nMLLMs is still undervalued.\n● Ethical  impact  of  multilingual  LLMs.  Multilingual\nLLMs  can  inherit  biases  present  in  their  training  data,\nleading  to  ethical  risks  of  generation.  Due  to  the  high\nproportion  of  Western  language  data  in  training  data,\nthe  MLLMs  are  inclined  to  reflect  Western-centric\nconcepts  [\n196].  How  to  mitigate  biases  and  ensure\n18 Front. Comput. Sci., 2025, 19(11): 1911362\nfairness  and  cultural  sensitivity  in  text  generation  are\nkey challenges for the further development of MLLMs.\n \nAcknowledgements    This  work  was  supported  by  the  National  Social\nScience Foundation of China (No. 24CYY107) \nCompeting  interests    The  authors  declare  that  they  have  no  competing\ninterests or financial conflicts to disclose. \nOpen Access    This article is licensed under a Creative Commons Attribution\n4.0 International License, which permits use, sharing, adaptation, distribution\nand  reproduction  in  any  medium  or  format,  as  long  as  you  give  appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if changes were made.\nThe images or other third party material in this article are included in the\narticle’s Creative Commons licence, unless indicated otherwise in a credit line\nto the material. If material is not included in the article’s Creative Commons\nlicence  and  your  intended  use  is  not  permitted  by  statutory  regulation  or\nexceeds  the  permitted  use,  you  will  need  to  obtain  permission  directly  from\nthe copyright holder.\nTo view a copy of this licence, visit \nhttp://creativecommons.org/licenses/by/\n4.0/.\nReferences \n Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N,\nKaiser  Ł,  Polosukhin  I. Attention  is  all  you  need.  In: Proceedings  of\nthe  31st  International  Conference  on  Neural  Information  Processing\nSystems. 2017, 6000–6010\n1.\n Devlin J, Chang M W, Lee K, Toutanova K. Bert: Pre-training of deep\nbidirectional transformers for language understanding. In: Proceedings\nof 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics. 2019, 4171–4186\n2.\n Conneau A, Lample G. Cross-lingual language model pretraining. In:\nProceedings  of  the  33rd  International  Conference  on  Neural\nInformation Processing Systems. 2019, 634\n3.\n Xue L, Constant N, Roberts A, Kale M, Al-Rfou R, Siddhant A, Barua\nA,  Raffel  C. mT5:  A  massively  multilingual  pre-trained  text-to-text\ntransformer.  In: Proceedings  of  2021  Conference  of  the  North\nAmerican  Chapter  of  the  Association  for  Computational  Linguistics.\n2021, 483–498\n4.\n Le Scao T, Fan A, Akiki C, Pavlick E, Ilić S et al. BLOOM: A 176B-\nparameter  open-access  multilingual  language  model. 2022,  arXiv\npreprint arXiv: 2211.05100\n5.\n Touvron H, Lavril T, Izacard G, Martinet X, Lachaux M A, Lacroix T,\nRozière  B,  Goyal  N,  Hambro  E,  Azhar  F,  Rodriguez  A,  Joulin  A,\nGrave E, Lample G. LLaMA: open and efficient foundation language\nmodels. 2023, arXiv preprint arXiv: 2302.13971\n6.\n Conneau  A,  Khandelwal  K,  Goyal  N,  Chaudhary  V,  Wenzek  G,\nGuzmán F, Grave É, Ott M, Zettlemoyer L, Stoyanov V. Unsupervised\ncross-lingual  representation  learning  at  scale.  In: Proceedings  of  the\n58th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2020, 8440–8451\n7.\n Cao S, Kitaev N, Klein D. Multilingual alignment of contextual word\nrepresentations. In: Proceedings of the 8th International Conference on\nLearning Representations. 2020\n8.\n Mikolov  T,  Sutskever  I,  Chen  K,  Corrado  G,  Dean  J. Distributed\nrepresentations  of  words  and  phrases  and  their  compositionality.  In:\nProceedings  of  the  26th  International  Conference  on  Neural\nInformation Processing Systems. 2013, 3111–3119\n9.\n Pennington J, Socher R, Manning C. GloVe: Global vectors for word\nrepresentation.  In: Proceedings  of  2014  Conference  on  Empirical\nMethods in Natural Language Processing. 2014, 1532–1543\n10.\n Bender  E  M,  Gebru  T,  McMillan-Major  A,  Shmitchell  S. On  the\ndangers  of  stochastic  parrots:  Can  language  models  be  too  big? In:\n11.\nProceedings  of  2021  ACM  Conference  on  Fairness,  Accountability,\nand Transparency. 2021, 610–623\n Talat  Z,  Névéol  A,  Biderman  S,  Clinciu  M,  Dey  M,  Longpre  S,\nLuccioni S, Masoud M, Mitchell M, Radev D, Sharma S, Subramonian\nA, Tae J, Tan S, Tunuguntla D, Van Der Wal O. You reap what you\nsow: On the challenges of bias evaluation under multilingual settings.\nIn: Proceedings of BigScience Episode #5 – Workshop on Challenges\n& Perspectives in Creating Large Language Models. 2022, 26–41\n12.\n Hutchinson  B,  Prabhakaran  V,  Denton  E,  Webster  K,  Zhong  Y,\nDenuyl  S. Social  biases  in  NLP  models  as  barriers  for  persons  with\ndisabilities.  In: Proceedings  of  the  58th  Annual  Meeting  of  the\nAssociation for Computational Linguistics. 2020, 5491–5501\n13.\n Nadeem  M,  Bethke  A,  Reddy  S. StereoSet:  measuring  stereotypical\nbias in pretrained language models. In: Proceedings of the 59th Annual\nMeeting of the Association for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language Processing. 2021,\n5356–5371\n14.\n Le H, Vial L, Frej J, Segonne V, Coavoux M, Lecouteux B, Allauzen\nA,  Crabbé  B,  Besacier  L,  Schwab  D. FlauBERT:  unsupervised\nlanguage  model  pre-training  for  French.  In: Proceedings  of  the  12th\nLanguage Resources and Evaluation Conference. 2020, 2479–2490\n15.\n De Vries W, Van Cranenburgh A, Bisazza A, Caselli T, Van Noord G,\nNissim  M. BERTje:  A  Dutch  BERT  model. 2019,  arXiv  preprint\narXiv: 1912.09582\n16.\n Antoun  W,  Baly  F,  Hajj  H. AraBERT:  Transformer-based  model  for\nArabic language understanding. In: Proceedings of the 4th Workshop\non Open-Source Arabic Corpora and Processing Tools, with a Shared\nTask on Offensive Language Detection. 2020, 9–15\n17.\n Radford  A,  Narasimhan  K,  Salimans  T,  Sutskever  I.  Improving\nlanguage understanding by generative pre-training. OpenAI Blog, 2018\n18.\n Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language\nmodels are unsupervised multitask learners. OpenAI Blog, 2019, 1(8):\n9\n19.\n Brown T B, Mann B, Ryder N, Subbiah M, Kaplan J. et al. Language\nmodels are few-shot learners. In: Proceedings of the 34th International\nConference on Neural Information Processing Systems. 2020, 159\n20.\n Ouyang L, Wu J, Jiang X, Almeida D, Wainwright C L et al. Training\nlanguage  models  to  follow  instructions  with  human  feedback.  In:\nProceedings  of  the  36th  International  Conference  on  Neural\nInformation Processing Systems. 2022, 2011\n21.\n Achiam  J,  Adler  S,  Agarwal  S,  Ahmad  L,  Akkaya  I  et  al. Gpt-4\ntechnical report. 2023, arXiv preprint arXiv: 2303.08774\n22.\n Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y,\nLi W, Liu P J. Exploring the limits of transfer learning with a unified\ntext-to-text  transformer. The  Journal  of  Machine  Learning  Research,\n2020, 21(1): 140\n23.\n Lewis  M,  Liu  Y,  Goyal  N,  Ghazvininejad  M,  Mohamed  A,  Levy  O,\nStoyanov  V,  Zettlemoyer  L. BART:  Denoising  sequence-to-sequence\npre-training  for  natural  language  generation,  translation,  and\ncomprehension.  In: Proceedings  of  the  58th  Annual  Meeting  of  the\nAssociation for Computational Linguistics. 2020, 7871–7880\n24.\n Nguyen T Q, Chiang D. Transfer learning across low-resource, related\nlanguages  for  neural  machine  translation.  In: Proceedings  of  the  8th\nInternational Joint Conference on Natural Language Processing. 2017,\n296–301\n25.\n Liu Y, Gu J, Goyal N, Li X, Edunov S, Ghazvininejad M, Lewis M,\nZettlemoyer L. Multilingual denoising pre-training for neural machine\ntranslation.  In: Proceedings  of  Transactions  of  the  Association  for\nComputational Linguistics. 2020, 726–742\n26.\n Pires  T,  Schlinger  E,  Garrette  D. How  multilingual  is  multilingual\nBERT? In: Proceedings of the 57th Annual Meeting of the Association\nfor Computational Linguistics. 2019, 4996–5001\n27.\n Artetxe M, Ruder S, Yogatama D. On the cross-lingual transferability28.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 19\nof  monolingual  representations.  In: Proceedings  of  the  58th  Annual\nMeeting  of  the  Association  for  Computational  Linguistics. 2020,\n4623–4637\n Chowdhery A, Narang S, Devlin J, Bosma M, Mishra G et al. PaLM:\nScaling  language  modeling  with  pathways. The  Journal  of  Machine\nLearning Research, 2023, 24(1): 240\n29.\n Thoppilan R, De Freitas D, Hall J, Shazeer N, Kulshreshtha A. et al.\nLaMDA:  language  models  for  dialog  applications. 2022,  arXiv\npreprint arXiv: 2201.08239\n30.\n Zhang S, Roller S, Goyal N, Artetxe M, Chen M et al. OPT: open pre-\ntrained  transformer  language  models. 2022,  arXiv  preprint  arXiv:\n2205.01068\n31.\n Du Z, Qian Y, Liu X, Ding M, Qiu J, Yang Z, Tang J. GLM: general\nlanguage  model  pretraining  with  autoregressive  blank  infilling.  In:\nProceedings  of  the  60th  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2022, 320–335\n32.\n Zeng A, Liu X, Du Z, Wang Z, Lai H, Ding M, Yang Z, Xu Y, Zheng\nW, Xia X, Tam W L, Ma Z, Xue Y, Zhai J, Chen W, Liu Z, Zhang P,\nDong Y, Tang J. GLM-130B: an open bilingual pre-trained model. In:\nProceedings  of  the  11th  International  Conference  on  Learning\nRepresentations. 2023\n33.\n Chiang W L, Li Z, Lin Z, Sheng Y, Wu Z, Zhang H, Zheng L, Zhuang\nS,  Zhuang  Y,  Gonzalez  J  E  et  al.  Vicuna:  An  open-source  chatbot\nimpressing  gpt-4  with  90%*  chatgpt  quality.  See  vicuna.  lmsys.  org\nwebsit, 2023\n34.\n Anil  R,  Borgeaud  S,  Alayrac  J  B,  Yu  J,  Soricut  R.  et  al. Gemini:  a\nfamily  of  highly  capable  multimodal  models. 2023,  arXiv  preprint\narXiv: 2312.11805\n35.\n Rust  P,  Pfeiffer  J,  Vulić  I,  Ruder  S,  Gurevych  I. How  good  is  your\ntokenizer? On the monolingual performance of multilingual language\nmodels. In: Proceedings of the 59th Annual Meeting of the Association\nfor  Computational  Linguistics  and  the  11th  International  Joint\nConference on Natural Language Processing. 2021, 3118–3135\n36.\n Zhang D, Yu Y, Dong J, Li C, Su D, Chu C, Yu D. MM-LLMs: recent\nadvances in MultiModal large language models. In: Proceedings of the\nFindings of the Association for Computational Linguistics: ACL 2024.\n2024, 12401–12430\n37.\n Rae J W, Borgeaud S, Cai T, Millican K, Hoffmann J. et al. Scaling\nlanguage models: Methods, analysis & insights from training gopher.\n2021, arXiv preprint arXiv: 2112.11446\n38.\n Chung  H  W,  Hou  L,  Longpre  S,  Zoph  B,  Tay  Y.  et  al. Scaling\ninstruction-finetuned  language  models. Journal  of  Machine  Learning\nResearch, 2024, 25(70): 1-−53\n39.\n OpenAI. Introducing chatGPT. See openai.com/index/chatgpt/ website,\n2022\n40.\n Driess D, Xia F, Sajjadi M S M, Lynch C, Chowdhery A. et al. PaLM-\nE:  An  embodied  multimodal  language  model.  In: Proceedings  of  the\n40th International Conference on Machine Learning. 2023, 8469–8488\n41.\n Taori R, Gulrajani I, Zhang T, Dubois Y, Li X, Guestrin C, Liang P,\nHashimoto  T  B.  Stanford  alpaca:  An  instruction-following  llama\nmodel. See github. com/tatsulab/stanford_alpaca website, 2023\n42.\n Ren X, Zhou P, Meng X, Huang X, Wang Y, Wang W, Li P, Zhang X,\nPodolskiy A, Arshinov G, Bout A, Piontkovskaya I, Wei J, Jiang X, Su\nT, Liu Q, Yao J. PanGu-Σ: Towards trillion parameter language model\nwith  sparse  heterogeneous  computing. 2023,  arXiv  preprint  arXiv:\n2303.10845\n43.\n Biderman  S,  Schoelkopf  H,  Anthony  Q  G,  Bradley  H,  O’Brien  K,\nHallahan E, Khan M A, Purohit S, Prashanth U S, Raff E, Skowron A,\nSutawika  L,  Van  Der  Wal  O. Pythia:  a  suite  for  analyzing  large\nlanguage  models  across  training  and  scaling.  In: Proceedings  of  the\n40th International Conference on Machine Learning. 2023, 2397–2430\n44.\n Anil  R,  Dai  A  M,  Firat  O,  Johnson  M,  Lepikhin  D.  et  al. PaLM  245.\ntechnical report. 2023, arXiv preprint arXiv: 2305.10403\n Touvron H, Martin L, Stone K, Albert P, Almahairi A. et al. Llama 2:\nopen  foundation  and  fine-tuned  chat  models. 2023,  arXiv  preprint\narXiv: 2307.09288\n46.\n Manyika  J,  Hsiao  S.  An  overview  of  bard:  an  early  experiment  with\ngenerative  AI.  See  ai.google/static/documents/google-about-bard.pdf\nGoogle Static Documents, 2023\n47.\n Yang A, Xiao B, Wang B, Zhang B, Bian C. et al. Baichuan 2: Open\nlarge-scale language models. 2023, arXiv preprint arXiv: 2309.10305\n48.\n MICROSOFT. Phi-2: the surprising power of small language models.\nSee  microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-\nsmall-language-models/ website, 2023\n49.\n Zeng A, Xu B, Wang B, Zhang C, Yin D. et al. ChatGLM: a family of\nlarge  language  models  from  GLM-130B  to  GLM-4  all  tools. 2024,\narXiv preprint arXiv: 2406.12793\n50.\n Anthropic. The  Claude  3  model  family:  Opus,  sonnet,  haiku.  See\nanthropic.com/news/claude-3-family/ website, 2024\n51.\n Dubey A, Jauhri A, Pandey A, Kadian A, Al-Dahle A. et al. The llama\n3 herd of models. 2024, arXiv preprint arXiv: 2407.21783\n52.\n Zhao W X, Zhou K, Li J, Tang T, Wang X. et al. A survey of large\nlanguage models. 2023, arXiv preprint arXiv: 2303.18223\n53.\n Doddapaneni S, Ramesh G, Kunchukuttan A, Kumar P, Khapra M M.\nA  primer  on  pretrained  multilingual  language  models. 2021,  arXiv\npreprint arXiv: 2107.00676\n54.\n Qiu X, Sun T, Xu Y, Shao Y, Dai N, Huang X. Pre-trained models for\nnatural  language  processing:  a  survey. Science  China  Technological\nSciences, 2020, 63(10): 1872-1897\n55.\n Shen T, Jin R, Huang Y, Liu C, Dong W, Guo Z, Wu X, Liu Y, Xiong\nD. Large  language  model  alignment:  A  survey. 2023,  arXiv  preprint\narXiv: 2309.15025\n56.\n Glaese  A,  McAleese  N,  Trębacz  M,  Aslanides  J,  Firoiu  V.  et  al.\nImproving  alignment  of  dialogue  agents  via  targeted  human\njudgements. 2022, arXiv preprint arXiv: 2209.14375\n57.\n Bai Y, Jones A, Ndousse K, Askell A, Chen A. et al. Training a helpful\nand  harmless  assistant  with  reinforcement  learning  from  human\nfeedback. 2022, arXiv preprint arXiv: 2204.05862\n58.\n Liu  R,  Zhang  G,  Feng  X,  Vosoughi  S. Aligning  generative  language\nmodels  with  human  values.  In: Proceedings  of  the  Findings  of  the\nAssociation for Computational Linguistics. 2022, 241–252\n59.\n Baheti A, Lu X, Brahman F, Le Bras R, Sap M, Riedl M O. Improving\nlanguage models with advantage-based offline policy gradients. 2023,\narXiv preprint arXiv: 2305.14718\n60.\n Go  D,  Korbak  T,  Kruszewski  G,  Rozen  J,  Ryu  N,  Dymetman  M.\nAligning  language  models  with  preferences  through  f-divergence\nminimization. In: Proceedings of the 40th International Conference on\nMachine Learning. 2023, 463\n61.\n Askell  A,  Bai  Y,  Chen  A,  Drain  D,  Ganguli  D.  et  al. A  general\nlanguage assistant as a laboratory for alignment. 2021, arXiv preprint\narXiv: 2112.00861\n62.\n Lambert  N,  Castricato  L,  Werra  V  L,  Havrilla  A.  Illustrating\nreinforcement  learning  from  human  feedback  (RLHF).  See\nhuggingface.co/blog/rlhf website, 2022\n63.\n Stiennon N, Ouyang L, Wu J, Ziegler D M, Lowe R, Voss C, Radford\nA,  Amodei  D,  Christiano  P. Learning  to  summarize  from  human\nfeedback.  In: Proceedings  of  the  34th  International  Conference  on\nNeural Information Processing Systems. 2020, 253\n64.\n Schulman  J,  Wolski  F,  Dhariwal  P,  Radford  A,  Klimov  O. Proximal\npolicy  optimization  algorithms. 2017,  arXiv  preprint  arXiv:\n1707.06347\n65.\n Mnih  V,  Badia  A  P,  Mirza  M,  Graves  A,  Lillicrap  T  P,  Harley  T,\nSilver  D,  Kavukcuoglu  K. Asynchronous  methods  for  deep\nreinforcement  learning.  In: Proceedings  of  the  33rd  International\n66.\n20 Front. Comput. Sci., 2025, 19(11): 1911362\nConference on Machine Learning. 2016, 1928–1937\n French R M. Catastrophic forgetting in connectionist networks. Trends\nin Cognitive Sciences, 1999, 3(4): 128-135\n67.\n Hedderich M A, Lange L, Adel H, Strötgen J, Klakow D. A survey on\nrecent  approaches  for  natural  language  processing  in  low-resource\nscenarios.  In: Proceedings  of  the  2021  Conference  of  the  North\nAmerican  Chapter  of  the  Association  for  Computational  Linguistics.\n2021, 2545–2568\n68.\n Alabi J O, Adelani D I, Mosbach M, Klakow D. Adapting pre-trained\nlanguage  models  to  african  languages  via  multilingual  adaptive  fine-\ntuning.  In: Proceedings  of  the  29th  International  Conference  on\nComputational Linguistics. 2022, 4336–4349\n69.\n Wongso  W,  Lucky  H,  Suhartono  D. Pre-trained  transformer-based\nlanguage models for sundanese. Journal of Big Data, 2022, 9(1): 39\n70.\n Torge  S,  Politov  A,  Lehmann  C,  Saffar  B,  Tao  Z. Named  entity\nrecognition  for  low-resource  languages-profiting  from  language\nfamilies.  In: Proceedings  of  the  9th  Workshop  on  Slavic  Natural\nLanguage Processing. 2023, 1–10\n71.\n Rönnqvist S, Kanerva J, Salakoski T, Ginter F. Is multilingual BERT\nfluent  in  language  generation? In: Proceedings  of  the  1st  NLPL\nWorkshop on Deep Learning for Natural Language Processing. 2019,\n29–36\n72.\n Wang Z, Karthikeyan K, Mayhew S, Roth D. Extending multilingual\nBERT  to  low-resource  languages.  In:  Proceedings  of  the  Findings  of\nthe  Association  for  Computational  Linguistics:  EMNLP. 2020,\n2649–2656\n73.\n Choenni R, Garrette D, Shutova E. How do languages influence each\nother? Studying cross-lingual data sharing during LM fine-tuning. In:\nProceedings  of  2023  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2023, 13244–13257\n74.\n Wang Y, Yu Z, Wang J, Heng Q, Chen H, Ye W, Xie R, Xie X, Zhang\nS. Exploring  vision-language  models  for  imbalanced  learning.\nInternational Journal of Computer Vision, 2024, 132(1): 224-237\n75.\n Jiang Y, Qiu R, Zhang Y, Zhang P F. Balanced and explainable social\nmedia  analysis  for  public  health  with  large  language  models.  In:\nProceedings  of  the  34th  Australasian  Database  Conference  on\nDatabases Theory and Applications. 2024, 73–86\n76.\n Lin  X  V,  Mihaylov  T,  Artetxe  M,  Wang  T,  Chen  S  et  al. Few-shot\nlearning  with  multilingual  generative  language  models.  In:\nProceedings of the 2022 Conference on Empirical Methods in Natural\nLanguage Processing. 2022, 9019–9052\n77.\n Tian  L,  Zhang  X,  Lau  J  H. Rumour  detection  via  zero-shot  cross-\nlingual transfer learning. In: Proceedings of the European Conference\non  Machine  Learning  and  Knowledge  Discovery  in  Databases. 2021,\n603–618\n78.\n Shi F, Suzgun M, Freitag M, Wang X, Srivats S, Vosoughi S, Chung H\nW,  Tay  Y,  Ruder  S,  Zhou  D,  Das  D,  Wei  J.  Language  models  are\nmultilingual  chain-of-thought  reasoners.  In:  Proceedings  of  the  11th\nInternational Conference on Learning Representations. 2023\n79.\n Ogunremi  T,  Jurafsky  D,  Manning  C  D. Mini  but  mighty:  Efficient\nmultilingual pretraining with linguistically-informed data selection. In:\nProceedings  of  the  Findings  of  the  Association  for  Computational\nLinguistics. 2023, 1251–1266\n80.\n Ogueji  K,  Zhu  Y,  Lin  J. Small  data?  No  problem!  Exploring  the\nviability of pretrained multilingual language models for low-resourced\nlanguages.  In: Proceedings  of  the  1st  Workshop  on  Multilingual\nRepresentation Learning. 2021, 116–126\n81.\n Pikuliak  M,  Šimko  M,  Bieliková  M. Cross-lingual  learning  for  text\nprocessing:  a  survey. Expert  Systems  with  Applications, 2021, 165:\n113765\n82.\n Philippy F, Guo S, Haddadan S. Towards a common understanding of\ncontributing factors for cross-lingual transfer in multilingual language\n83.\nmodels: a review. In: Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics. 2023, 5877–5891\n Penedo G, Malartic Q, Hesslow D, Cojocaru R, Alobeidli H, Cappelli\nA,  Pannier  B,  Almazrouei  E,  Launay  J. The  RefinedWeb  dataset  for\nfalcon  LLM:  outperforming  curated  corpora  with  web  data  only.  In:\nProceedings  of  the  37th  International  Conference  on  Neural\nInformation Processing Systems. 2023, 3464\n84.\n Luo  Y,  Kong  Q,  Xu  N,  Cao  J,  Hao  B.  et  al. YAYI  2:  multilingual\nopen-source  large  language  models. 2023,  arXiv  preprint  arXiv:\n2312.14862\n85.\n Sun H, Jin R, Xu S, Pan L, Supryadi, Cui M, Du J, Lei Y, Yang L, Shi\nL, Xiao J, Zhu S, Xiong D. FuxiTranyu: a multilingual large language\nmodel trained with balanced data. In: Proceedings of 2024 Conference\non  Empirical  Methods  in  Natural  Language  Processing. 2024,\n1499–1522\n86.\n Adelani  D,  Neubig  G,  Ruder  S,  Rijhwani  S,  Beukman  M.  et  al.\nMasakhaNER  2.0:  Africa-centric  transfer  learning  for  named  entity\nrecognition.  In: Proceedings  of  2022  Conference  on  Empirical\nMethods in Natural Language Processing. 2022, 4488–4508\n87.\n Malmasi S, Fang A, Fetahu B, Kar S, Rokhlenko O. MultiCoNER: a\nlarge-scale multilingual dataset for complex named entity recognition.\nIn: Proceedings of the 29th International Conference on Computational\nLinguistics. 2022, 3798–3809\n88.\n Öhman  E,  Pàmies  M,  Kajava  K,  Tiedemann  J. XED:  a  multilingual\ndataset for sentiment analysis and emotion detection. In: Proceedings\nof  the  28th  International  Conference  on  Computational  Linguistics.\n2020, 6542–6552\n89.\n Shode  I,  Adelani  D  I,  Peng  J,  Feldman  A. NollySenti:  Leveraging\ntransfer learning and machine translation for Nigerian movie sentiment\nclassification.  In: Proceedings  of  the  61st  Annual  Meeting  of  the\nAssociation for Computational Linguistics. 2023, 986–998\n90.\n Muhammad  S  H,  Adelani  D  I,  Ruder  S,  Ahmad  I  S,  Abdulmumin  I,\nBello  B  S,  Choudhury  M,  Emezue  C  C,  Abdullahi  S  S,  Aremu  A,\nJorge A, Brazdil P. NaijaSenti: a Nigerian twitter sentiment corpus for\nmultilingual sentiment analysis. In: Proceedings of the 13th Language\nResources and Evaluation Conference. 2022, 590–602\n91.\n Ogundepo  O,  Zhang  X,  Sun  S,  Duh  K,  Lin  J. AfriCLIRMatrix:\nenabling cross-lingual information retrieval for African languages. In:\nProceedings  of  2022  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2022, 8721–8728\n92.\n Sun S, Duh K. CLIRMatrix: a massively large collection of bilingual\nand  multilingual  datasets  for  cross-lingual  information  retrieval.  In:\nProceedings  of  2020  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2020, 4160–4170\n93.\n Ma C, Imani A, Ye H, Asgari E, Schütze H. Taxi1500: a multilingual\ndataset for text classification in 1500 languages. 2023, arXiv preprint\narXiv: 2305.08487\n94.\n Keung  P,  Lu  Y,  Szarvas  G,  Smith  N  A. The  multilingual  Amazon\nreviews  corpus.  In: Proceedings  of  2020  Conference  on  Empirical\nMethods in Natural Language Processing. 2020, 4563–4568\n95.\n Lample  G,  Conneau  A,  Ranzato  M,  Denoyer  L,  Jégou  H. Word\ntranslation  without  parallel  data.  In: Proceedings  of  the  6th\nInternational Conference on Learning Representations. 2018\n96.\n Linguatools.org. Wikipedia  monolingual  corpora.  See  linguatools/\ntools/corpora/wikipedia-monolingual-corpora/ website, 2018\n97.\n Palen-Michel  C,  Kim  J,  Lignos  C. Multilingual  open  text  release  1:\nPublic  domain  news  in  44  languages.  In: Proceedings  of  the  13th\nLanguage Resources and Evaluation Conference. 2022, 2080–2089\n98.\n Lison  P,  Tiedemann  J. OpenSubtitles2016:  Extracting  large  parallel\ncorpora  from  movie  and  TV  subtitles.  In: Proceedings  of  the  10th\nInternational  Conference  on  Language  Resources  and  Evaluation.\n2016, 923–929\n99.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 21\n Zhu  W,  Liu  H,  Dong  Q,  Xu  J,  Huang  S,  Kong  L,  Chen  J,  Li  L.\nMultilingual  machine  translation  with  large  language  models:\nempirical results and analysis. In: Proceedings of the Findings of the\nAssociation for Computational Linguistics. 2024, 2765–2781\n100.\n Goyal  N,  Du  J,  Ott  M,  Anantharaman  G,  Conneau  A. Larger-scale\ntransformers  for  multilingual  masked  language  modeling.  In:\nProceedings of the 6th Workshop on Representation Learning for NLP.\n2021, 29–33\n101.\n Bojanowski P, Grave E, Joulin A, Mikolov T. Enriching word vectors\nwith  subword  information. Transactions  of  the  Association  for\nComputational Linguistics, 2017, 5: 135-146\n102.\n Artetxe  M,  Labaka  G,  Agirre  E. A  robust  self-learning  method  for\nfully  unsupervised  cross-lingual  mappings  of  word  embeddings.  In:\nProceedings  of  the  56th  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2018, 789–798\n103.\n Søgaard  A,  Ruder  S,  Vulić  I. On  the  limitations  of  unsupervised\nbilingual  dictionary  induction.  In: Proceedings  of  the  56th  Annual\nMeeting  of  the  Association  for  Computational  Linguistics. 2018,\n778–788\n104.\n Nakashole N. NORMA: Neighborhood sensitive maps for multilingual\nword  embeddings.  In: Proceedings  of  2018  Conference  on  Empirical\nMethods in Natural Language Processing. 2018, 512–522\n105.\n Wang H, Henderson J, Merlo P. Multi-adversarial learning for cross-\nlingual word embeddings. In: Proceedings of 2021 Conference of the\nNorth  American  Chapter  of  the  Association  for  Computational\nLinguistics. 2021, 463–472\n106.\n Sarzynska-Wawer J, Wawer A, Pawlak A, Szymanowska J, Stefaniak\nI,  Jarkiewicz  M,  Okruszek  L. Detecting  formal  thought  disorder  by\ndeep contextualized word representations. Psychiatry Research, 2021,\n304: 114135\n107.\n Schuster T, Ram O, Barzilay R, Globerson A. Cross-lingual alignment\nof  contextual  word  embeddings,  with  applications  to  zero-shot\ndependency parsing. In: Proceedings of 2019 Conference of the North\nAmerican  Chapter  of  the  Association  for  Computational  Linguistic.\n2019, 1599–1613\n108.\n Gage P. A new algorithm for data compression. The C Users Journal,\n1994, 12(2): 23-38\n109.\n Schuster  M,  Nakajima  K. Japanese  and  Korean  voice  search.  In:\nProceedings  of  2012  IEEE  International  Conference  on  Acoustics,\nSpeech and Signal Processing. 2012, 5149–5152\n110.\n Vulić  I,  Ponti  E  M,  Litschko  R,  Glavaš  G,  Korhonen  A. Probing\npretrained  language  models  for  lexical  semantics.  In: Proceedings  of\n2020  Conference  on  Empirical  Methods  in  Natural  Language\nProcessing. 2020, 7222–7240\n111.\n Zhang J, Ji B, Xiao N, Duan X, Zhang M, Shi Y, Luo W. Combining\nstatic  word  embeddings  and  contextual  representations  for  bilingual\nlexicon induction. In: Proceedings of the Findings of the Association\nfor Computational Linguistics. 2021, 2943–2955\n112.\n Hämmerl  K,  Libovický  J,  Fraser  A. Combining  static  and\ncontextualised  multilingual  embeddings.  In: Proceedings  of  the\nFindings  of  the  Association  for  Computational  Linguistics. 2022,\n2316–2329\n113.\n Zheng J, Wang Y, Wang G, Xia J, Huang Y, Zhao G, Zhang Y, Li S.\nUsing  context-to-vector  with  graph  retrofitting  to  improve  word\nembeddings.  In: Proceedings  of  the  60th  Annual  Meeting  of  the\nAssociation for Computational Linguistics. 2022, 8154–8163\n114.\n Li  Y,  Liu  F,  Collier  N,  Korhonen  A,  Vulić  I. Improving  word\ntranslation  via  two-stage  contrastive  learning.  In: Proceedings  of  the\n60th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2022, 4353–4374\n115.\n Alvarez-Melis D, Jaakkola T. Gromov-wasserstein alignment of word\nembedding spaces. In: Proceedings of 2018 Conference on Empirical\n116.\nMethods in Natural Language Processing. 2018, 1881–1890\n Ren S, Liu S, Zhou M, Ma S. A graph-based coarse-to-fine method for\nunsupervised bilingual lexicon induction. In: Proceedings of the 58th\nAnnual  Meeting  of  the  Association  for  Computational  Linguistics.\n2020, 3476–3485\n117.\n Mohiuddin  T,  Joty  S. Revisiting  adversarial  autoencoder  for\nunsupervised  word  translation  with  cycle  consistency  and  improved\ntraining.  In: Proceedings  of  2019  Conference  of  the  North  American\nChapter  of  the  Association  for  Computational  Linguistics. 2019,\n3857–3867\n118.\n Mohiuddin T, Bari M S, Joty S. LNMap: Departures from isomorphic\nassumption in bilingual lexicon induction through non-linear mapping\nin  latent  space.  In: Proceedings  of  2020  Conference  on  Empirical\nMethods in Natural Language Processing. 2020, 2712–2723\n119.\n Glavaš  G,  Vulić  I. Non-linear  instance-based  cross-lingual  mapping\nfor  non-isomorphic  embedding  spaces.  In: Proceedings  of  the  58th\nAnnual  Meeting  of  the  Association  for  Computational  Linguistics.\n2020, 7548–7555\n120.\n Marchisio  K,  Verma  N,  Duh  K,  Koehn  P. IsoVec:  controlling  the\nrelative  isomorphism  of  word  embedding  spaces.  In: Proceedings  of\n2022  Conference  on  Empirical  Methods  in  Natural  Language\nProcessing. 2022, 6019–6033\n121.\n Singh J, McCann B, Socher R, Xiong C. BERT is not an interlingua\nand the bias of tokenization. In: Proceedings of the 2nd Workshop on\nDeep Learning Approaches for Low-Resource NLP. 2019, 47–55\n122.\n Taitelbaum H, Chechik G, Goldberger J. Multilingual word translation\nusing  auxiliary  languages.  In: Proceedings  of  2019  Conference  on\nEmpirical  Methods  in  Natural  Language  Processing  and  the  9th\nInternational Joint Conference on Natural Language Processing. 2019,\n1330–1335\n123.\n Karthikeyan K, Wang Z, Mayhew S, Roth D. Cross-lingual ability of\nmultilingual  BERT:  an  empirical  study.  In:  Proceedings  of  the  8th\nInternational Conference on Learning Representations. 2020\n124.\n Liu  C  L,  Hsu  T  Y,  Chuang  Y  S,  Lee  H  Y. A  study  of  cross-lingual\nability and language-specific information in multilingual BERT. 2020,\narXiv preprint arXiv: 2004.09205\n125.\n Ranjan  R,  Gupta  S,  Singh  S  N. A  comprehensive  survey  of  bias  in\nLLMs:  current  landscape  and  future  directions. 2024,  arXiv  preprint\narXiv: 2409.16430\n126.\n Cao  S,  Cheng  R,  Wang  Z. AGR:  age  group  fairness  reward  for  bias\nmitigation in LLMs. 2024, arXiv preprint arXiv: 2409.04340\n127.\n Ahn J, Oh A. Mitigating language-dependent ethnic bias in BERT. In:\nProceedings  of  2021  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2021, 533–549\n128.\n Meade  N,  Poole-Dayan  E,  Reddy  S. An  empirical  survey  of  the\neffectiveness of debiasing techniques for pre-trained language models.\nIn: Proceedings  of  the  60th  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2022, 1878–1898\n129.\n Zhao  J,  Mukherjee  S,  Hosseini  S,  Chang  K  W,  Awadallah  A  H.\nGender bias in multilingual embeddings and cross-lingual transfer. In:\nProceedings  of  the  58th  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2020, 2896–2907\n130.\n Ferrara E. Should ChatGPT be biased? Challenges and risks of bias in\nlarge language models. 2023, arXiv preprint arXiv: 2304.03738\n131.\n Wu  S,  Dredze  M. Are  all  languages  created  equal  in  multilingual\nBERT? In: Proceedings  of  the  5th  Workshop  on  Representation\nLearning for NLP. 2020, 120–130\n132.\n Wang J, Liu Y, Wang X. Assessing multilingual fairness in pre-trained\nmultimodal  representations.  In: Proceedings  of  the  Findings  of  the\nAssociation for Computational Linguistics. 2022, 2681–2695\n133.\n Kassner  N,  Dufter  P,  Schütze  H. Multilingual  LAMA:  investigating\nknowledge  in  multilingual  pretrained  language  models.  In:\n134.\n22 Front. Comput. Sci., 2025, 19(11): 1911362\nProceedings  of  the  16th  Conference  of  the  European  Chapter  of  the\nAssociation for Computational Linguistics. 2021, 3250–3258\n Levy S, John N A, Liu L, Vyas Y, Ma J, Fujinuma Y, Ballesteros M,\nCastelli V, Roth D. Comparing biases and the impact of multilingual\ntraining  across  multiple  languages.  In: Proceedings  of  2023\nConference  on  Empirical  Methods  in  Natural  Language  Processing.\n2023, 10260–10280\n135.\n Piqueras L C, Søgaard A. Are pretrained multilingual models equally\nfair  across  languages? In: Proceedings  of  the  29th  International\nConference on Computational Linguistics. 2022, 3597–3605\n136.\n Touileb S, Øvrelid L, Velldal E. Occupational biases in Norwegian and\nmultilingual language models. In: Proceedings of the 4th Workshop on\nGender Bias in Natural Language Processing. 2022, 200–211\n137.\n Naous  T,  Ryan  M  J,  Ritter  A,  Xu  W. Having  beer  after  prayer?\nMeasuring cultural bias in large language models. In: Proceedings of\nthe  62nd  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2024, 16366–16393\n138.\n Abid A, Farooqi M, Zou J. Large language models associate Muslims\nwith violence. Nature Machine Intelligence, 2021, 3(6): 461-463\n139.\n Cao Y T, Pruksachatkun Y, Chang K W, Gupta R, Kumar V, Dhamala\nJ, Galstyan A. On the intrinsic and extrinsic fairness evaluation metrics\nfor  contextualized  language  representations.  In: Proceedings  of  the\n60th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2022, 561–570\n140.\n Leiter C, Lertvittayakumjorn P, Fomicheva M, Zhao W, Gao Y, Eger\nS. Towards  explainable  evaluation  metrics  for  machine  translation.\nJournal of Machine Learning Research, 2024, 25(75): 1-49\n141.\n Sun T, He J, Qiu X, Huang X. BERTScore is unfair: on social bias in\nlanguage model-based  metrics  for  text generation.  In: Proceedings  of\n2022  Conference  on  Empirical  Methods  in  Natural  Language\nProcessing. 2022, 3726–3739\n142.\n Zhang  T,  Kishore  V,  Wu  F,  Weinberger  K  Q,  Artzi  Y. BERTScore:\nevaluating  text  generation  with  BERT.  In: Proceedings  of  the  8th\nInternational Conference on Learning Representations. 2020\n143.\n Sellam T, Das D, Parikh A. BLEURT: learning robust metrics for text\ngeneration.  In: Proceedings  of  the  58th  Annual  Meeting  of  the\nAssociation for Computational Linguistics. 2020, 7881–7892\n144.\n Yuan W, Neubig G, Liu P. BARTSCORE: evaluating generated text as\ntext  generation.  In: Proceedings  of  the  35th  International  Conference\non Neural Information Processing Systems. 2021, 2088\n145.\n Koo R, Lee M, Raheja V, Park J I, Kim Z M, Kang D. Benchmarking\ncognitive  biases  in  large  language  models  as  evaluators.  In:\nProceedings  of  the  Findings  of  the  Association  for  Computational\nLinguistics. 2024, 517–545\n146.\n Delobelle P, Tokpo E, Calders T, Berendt B. Measuring fairness with\nbiased  rulers:  A  comparative  study  on  bias  metrics  for  pre-trained\nlanguage  models.  In: Proceedings  of  2022  Conference  of  the  North\nAmerican  Chapter  of  the  Association  for  Computational  Linguistics.\n2022, 1693–1706\n147.\n Caliskan A, Bryson J J, Narayanan A. Semantics derived automatically\nfrom  language  corpora  Contain  human-like  biases. Science, 2017,\n356(6334): 183-186\n148.\n Wang  A,  Singh  A,  Michael J,  Hill F,  Levy  O,  Bowman  S. GLUE: a\nmulti-task  benchmark  and  analysis  platform  for  natural  language\nunderstanding.  In: Proceedings  of  2018  EMNLP  Workshop\nBlackboxNLP: Analyzing and Interpreting Neural Networks for NLP.\n2018, 353–355\n149.\n May C, Wang A, Bordia S, Bowman S R, Rudinger R. On measuring\nsocial biases in sentence encoders. In: Proceedings of 2019 Conference\nof the North American Chapter of the Association for Computational\nLinguistics. 2019, 622–628\n150.\n Guo  W,  Caliskan  A. Detecting  emergent  intersectional  biases:151.\ncontextualized word embeddings contain a distribution of human-like\nbiases. In: Proceedings of 2021 AAAI/ACM Conference on AI, Ethics,\nand Society. 2021, 122–133\n Bansal  S,  Garimella  V,  Suhane  A,  Mukherjee  A. Debiasing\nmultilingual word embeddings: a case study of three Indian languages.\nIn: Proceedings of the 32nd ACM Conference on Hypertext and Social\nMedia. 2021, 27–34\n152.\n Rudinger R, Naradowsky J, Leonard B, Van Durme B. Gender bias in\ncoreference  resolution.  In: Proceedings  of  2018  Conference  of  the\nNorth  American  Chapter  of  the  Association  for  Computational\nLinguistics. 2018, 8–14\n153.\n Zhao J, Wang T, Yatskar M, Ordonez V, Chang K W. Gender bias in\ncoreference  resolution:  Evaluation  and  debiasing  methods.  In:\nProceedings of 2018 Conference of the North American Chapter of the\nAssociation for Computational Linguistics. 2018, 15–20\n154.\n Kiritchenko S, Mohammad S. Examining gender and race bias in two\nhundred  sentiment  analysis  systems.  In: Proceedings  of  the  7th  Joint\nConference on Lexical and Computational Semantics. 2018, 43–53\n155.\n Nangia  N,  Vania  C,  Bhalerao  R,  Bowman  S  R. CrowS-Pairs:  a\nchallenge  dataset  for  measuring  social  biases  in  masked  language\nmodels. In: Proceedings of 2020 Conference on Empirical Methods in\nNatural Language Processing. 2020, 1953–1967\n156.\n Stanovsky  G,  Smith  N  A,  Zettlemoyer  L. Evaluating  gender  bias  in\nmachine translation. In: Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics. 2019, 1679–1684\n157.\n De-Arteaga  M,  Romanov  A,  Wallach  H,  Chayes  J,  Borgs  C,\nChouldechova A, Geyik S, Kenthapadi K, Kalai A T. Bias in bios: a\ncase study of semantic representation bias in a high-stakes setting. In:\nProceedings  of  the  Conference  on  Fairness,  Accountability,  and\nTransparency. 2019, 120–128\n158.\n Karkkainen K, Joo J. FairFace: face attribute dataset for balanced race,\ngender, and age for bias measurement and mitigation. In: Proceedings\nof 2021 IEEE Winter Conference on Applications of Computer Vision.\n2021, 1547–1557\n159.\n Lauscher A, Glavaš G. Are we consistently biased? Multidimensional\nanalysis of biases in distributional word vectors. In: Proceedings of the\n8th Joint Conference on Lexical and Computational Semantics. 2019,\n85–91\n160.\n Névéol  A,  Dupont  Y,  Bezançon  J,  Fort  K. French  CrowS-pairs:\nextending  a  challenge  dataset  for  measuring  social  bias  in  masked\nlanguage models to a language other than English. In: Proceedings of\nthe  60th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2022, 8521–8531\n161.\n Wan Y, Pu G, Sun J, Garimella A, Chang K W, Peng N. “Kelly is a\nwarm  person,  joseph  is  a  role  model”:  Gender  biases  in  LLM-\ngenerated  reference  letters.  In: Proceedings  of  the  Findings  of  the\nAssociation for Computational Linguistics. 2023, 3730–3748\n162.\n Liang P P, Li I M, Zheng E, Lim Y C, Salakhutdinov R, Morency L P.\nTowards  debiasing  sentence  representations.  In: Proceedings  of  the\n58th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2020, 5502–5515\n163.\n Ravfogel S, Elazar Y, Gonen H, Twiton M, Goldberg Y. Null it out:\nGuarding  protected  attributes  by  iterative  nullspace  projection.  In:\nProceedings  of  the  58th  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2020, 7237–7256\n164.\n Yang Z, Yang Y, Cer D, Darve E. A simple and effective method to\neliminate  the  self  language  bias  in  multilingual  representations.  In:\nProceedings  of  2021  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2021, 5825–5832\n165.\n Webster K, Wang X, Tenney I, Beutel A, Pitler E, Pavlick E, Chen J,\nChi E, Petrov S. Measuring and reducing gendered correlations in pre-\ntrained models. 2020, arXiv preprint arXiv: 2010.06032\n166.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 23\n Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R.\nDropout:  a  simple  way  to  prevent  neural  networks  from  overfitting.\nThe Journal of Machine Learning Research, 2014, 15(1): 1929-1958\n167.\n Zhou  F,  Mao  Y,  Yu  L,  Yang  Y,  Zhong  T. Causal-debias:  Unifying\ndebiasing  in  pretrained  language  models  and  fine-tuning  via  causal\ninvariant learning. In: Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics. 2023, 4227–4241\n168.\n Ranaldi L, Ruzzetti E S, Venditti D, Onorati D, Zanzotto F M. A trip\ntowards  fairness:  Bias  and  de-biasing  in  large  language  models.  In:\nProceedings  of  the  13th  Joint  Conference  on  Lexical  and\nComputational Semantics. 2024, 372–384\n169.\n Hu E J, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, Wang L, Chen\nW.  Lora:  Low-rank  adaptation  of  large  language  models.  In:\nProceedings  of  the  10th  International  Conference  on  Learning\nRepresentations. 2022\n170.\n Wang A, Russakovsky O. Overwriting pretrained bias with finetuning\ndata.  In: Proceedings  of  IEEE/CVF  International  Conference  on\nComputer Vision. 2023, 3934–3945\n171.\n Guo Y, Yang Y, Abbasi A. Auto-debias: debiasing masked language\nmodels  with  automated  biased  prompts.  In: Proceedings  of  the  60th\nAnnual  Meeting  of  the  Association  for  Computational  Linguistics.\n2022, 1012–1023\n172.\n Mattern J, Jin Z, Sachan M, Mihalcea R, Schölkopf B. Understanding\nstereotypes  in  language  models:  Towards  robust  measurement  and\nzero-shot debiasing. 2022, arXiv preprint arXiv: 2212.10678\n173.\n Dhingra  H,  Jayashanker  P,  Moghe  S,  Strubell  E. Queer  people  are\npeople  first:  Deconstructing  sexual  identity  stereotypes  in  large\nlanguage models. 2023, arXiv preprint arXiv: 2307, 0010, 1: 2023\n174.\n Schick  T,  Udupa  S,  Schütze  H. Self-diagnosis  and  self-debiasing:  a\nproposal  for  reducing  corpus-based  bias  in  NLP. Transactions  of  the\nAssociation for Computational Linguistics, 2021, 9: 1408-1424\n175.\n Conneau A, Rinott R, Lample G, Williams A, Bowman S, Schwenk H,\nStoyanov V. XNLI: Evaluating cross-lingual sentence representations.\nIn: Proceedings of 2018 Conference on Empirical Methods in Natural\nLanguage Processing. 2018, 2475–2485\n176.\n Nguyen T, Van Nguyen C, Lai V D, Man H, Ngo N T, Dernoncourt F,\nRossi  R  A,  Nguyen  T  H. CulturaX:  a  cleaned,  enormous,  and\nmultilingual  dataset  for  large  language  models  in  167  languages.  In:\nProceedings of 2024 Joint International Conference on Computational\nLinguistics, Language Resources and Evaluation. 2024, 4226–4237\n177.\n Laurençon H, Saulnier L, Wang T, Akiki C, Del Moral A V. et al. The\nBigScience  roots  corpus:  a  1.6TB  composite  multilingual  dataset.  In:\nProceedings  of  the  36th  International  Conference  on  Neural\nInformation Processing Systems. 2022, 2306\n178.\n Kreutzer J, Caswell I, Wang L, Wahab A, Van Esch D. et al. Quality at\na glance: An audit of web-crawled multilingual datasets. Transactions\nof the Association for Computational Linguistics, 2022, 10: 50-−72\n179.\n Sen I, Assenmacher D, Samory M, Augenstein I, Aalst W, Wagner C.\nPeople  make  better  edits:  measuring  the  efficacy  of  LLM-generated\ncounterfactually  augmented  data  for  harmful  language  detection.  In:\nProceedings  of  2023  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2023, 10480–10504\n180.\n Zhao  J,  Wang  T,  Yatskar  M,  Cotterell  R,  Ordonez  V,  Chang  K  W.\nGender  bias  in  contextualized  word  embeddings.  In: Proceedings  of\n2019 Conference of the North American Chapter of the Association for\nComputational Linguistics. 2019, 629–634\n181.\n Yang L, Li J, Cunningham P, Zhang Y, Smyth B, Dong R. Exploring\nthe  efficacy  of  automatically  generated  counterfactuals  for  sentiment\nanalysis.  In: Proceedings  of  the  59th  Annual  Meeting  of  the\nAssociation  for  Computational  Linguistics  and  the  11th  International\nJoint Conference on Natural Language Processing. 2021, 306–316\n182.\n Sen  I,  Samory  M,  Flöck  F,  Wagner  C,  Augenstein  I. How  does183.\ncounterfactually  augmented  data  impact  models  for  social  computing\nconstructs? In: Proceedings of 2021 Conference on Empirical Methods\nin Natural Language Processing. 2021, 325–344\n Goldfarb-Tarrant S, Lopez A, Blanco R, Marcheggiani D. Bias beyond\nEnglish:  counterfactual  tests  for  bias  in  sentiment  analysis  in  four\nlanguages.  In: Proceedings  of  the  Findings  of  the  Association  for\nComputational Linguistics. 2023, 4458–4468\n184.\n Sen  I,  Samory  M,  Wagner  C,  Augenstein  I. Counterfactually\naugmented  data  and  unintended  bias:  The  case  of  sexism  and  hate\nspeech  detection.  In: Proceedings  of  2022  Conference  of  the  North\nAmerican  Chapter  of  the  Association  for  Computational  Linguistic.\n2022, 4716–4726\n185.\n Joshi  N,  He  H. An  investigation  of  the  (in)effectiveness  of\ncounterfactually  augmented  data.  In: Proceedings  of  the  60th  Annual\nMeeting  of  the  Association  for  Computational  Linguistics. 2022,\n3668–3681\n186.\n Zhang Q, Duan Q, Yuan B, Shi Y, Liu J. Exploring accuracy-fairness\ntrade-off  in  large  language  models. 2024,  arXiv  preprint  arXiv:\n2411.14500\n187.\n Lin  Z,  Guan  S,  Zhang  W,  Zhang  H,  Li  Y,  Zhang  H. Towards\ntrustworthy LLMs: a review on debiasing and dehallucinating in large\nlanguage models. Artificial Intelligence Review, 2024, 57(9): 243\n188.\n Yang  N,  Kang  T,  Choi  S  J,  Lee  H,  Jung  K. Mitigating  biases  for\ninstruction-following  language  models  via  bias  neurons  elimination.\nIn: Proceedings  of  the  62nd  Annual  Meeting  of  the  Association  for\nComputational Linguistics. 2024, 9061–9073\n189.\n Yadav  H,  Sitaram  S. A  survey  of  multilingual  models  for  automatic\nspeech  recognition.  In: Proceedings  of  the  13th  Language  Resources\nand Evaluation Conference. 2022, 5071–5079\n190.\n Hu J, Ruder S, Siddhant A, Neubig G, Firat O, Johnson M. XTREME:\na  massively  multilingual  multi-task  benchmark  for  evaluating  cross-\nlingual  generalization.  In: Proceedings  of  the  37th  International\nConference on Machine Learning. 2020, 410\n191.\n Dufter  P,  Schütze  H. Identifying  elements  essential  for  BERT’s\nmultilinguality.  In: Proceedings  of  2020  Conference  on  Empirical\nMethods in Natural Language Processing. 2020, 4423–4437\n192.\n Nzeyimana  A,  Niyongabo  Rubungo  A. KinyaBERT:  a  morphology-\naware  Kinyarwanda  language  model.  In: Proceedings  of  the  60th\nAnnual  Meeting  of  the  Association  for  Computational  Linguistics.\n2022, 5347–5363\n193.\n Naveed H, Khan A U, Qiu S, Saqib M, Anwar S, Usman M, Akhtar N,\nBarnes  N,  Mian  A. A  comprehensive  overview  of  large  language\nmodels. 2023, arXiv preprint arXiv: 2307.06435\n194.\n Pan  X,  Zhang  B,  May  J,  Nothman  J,  Knight  K,  Ji  H. Cross-lingual\nname  tagging  and  linking  for  282  languages.  In: Proceedings  of  the\n55th  Annual  Meeting  of  the  Association  for  Computational\nLinguistics. 2017, 1946–1958\n195.\n Liu  F,  Bugliarello  E,  Ponti  E  M,  Reddy  S,  Collier  N,  Elliott  D.\nVisually  grounded  reasoning  across  languages  and  cultures.  In:\nProceedings  of  2021  Conference  on  Empirical  Methods  in  Natural\nLanguage Processing. 2021, 10467–10485\n196.\nYuemei XU is an associate professor in the School\nof  Information  Science  and  Technology,  Beijing\nForeign  Studies  University,  China.  She  received\nher  PhD  degree  from  Chinese  Academy  of\nSciences, China in 2014 and the BE degree from\nBeijing  University  of  Posts  and\nTelecommunications,  China  in  2009.  Her  main\nresearch  interests  include  multilingual  natural  language  processing\nand artificial intelligence.\n24 Front. Comput. Sci., 2025, 19(11): 1911362\nLing  HU  received  the  bachelor’s  degree  from\nBeijing  University  of  Posts  and\nTelecommunications,  China  in  2021.  She  is\ncurrently  pursing  the  master  degree  with  the\nSchool  of  Information  Science  and  Technology,\nBeijing  Foreign  Studies  University,  China.  Her\nmain  research  interests  include  multilingual\nnatural language processing and artificial intelligence.\nJiayi ZHAO is majoring in computer science and\ntechnology  at  the  School  of  Information  Science\nand  Technology,  Beijing  Foreign  Studies\nUniversity,  China.  Her  main  research  interests\ninclude  multilingual  natural  language  processing\nand artificial intelligence.\nZihan  QIU  is  majoring  in  computer  science  and\ntechnology  at  the  School  of  Information  Science\nand  Technology,  Beijing  Foreign  Studies\nUniversity,  China.  Her  main  research  interests\ninclude  multilingual  natural  language  processing\nand artificial intelligence.\nKexin  XU  received  the  bachelor’s  degree  from\nSouthwestern  University  of  Finance  and\nEconomics,  China  in  2024.  She  is  currently\npursing  the  master  degree  with  the  School  of\nInformation  Science  and  Technology,  Beijing\nForeign  Studies  University,  China.  Her  main\nresearch  interests  include  multilingual  natural\nlanguage processing and artificial intelligence.\nYuqi  YE  is  majoring  in  computer  science  and\ntechnology  at  the  School  of  Information  Science\nand  Technology,  Beijing  Foreign  Studies\nUniversity,  China.  Her  main  research  interests\ninclude Multilingual Natural Language Processing\nand Artificial Intelligence.\nHanwen  GU  received  the  BE  degree  from  the\nSchool  of  Information  Science  at  Beijing\nLanguage and Culture University, China in 2023.\nCurrently, he is pursuing a master’s degree in the\nSchool of Information Science and Technology at\nBeijing  Foreign  Studies  University,  China.  His\nprimary  research  interests  encompass  natural\nlanguage processing and artificial intelligence.\nYuemei XU et al.    A survey on multilingual large language models:corpora, alignment, and bias 25",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8890055418014526
    },
    {
      "name": "Natural language processing",
      "score": 0.5936021208763123
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45055368542671204
    }
  ]
}