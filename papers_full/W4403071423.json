{
  "title": "Phoenixes at LLMs4OL 2024 Tasks A, B, and C: Retrieval Augmented Generation for Ontology Learning",
  "url": "https://openalex.org/W4403071423",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3096919681",
      "name": "Mahsa Sanaei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2184124168",
      "name": "Fatemeh Azizi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2889026094",
      "name": "Hamed Babaei Giglou",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4388144297",
    "https://openalex.org/W4392903638",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W4403071417"
  ],
  "abstract": "Large language models (LLMs) showed great capabilities in ontology learning (OL) where they automatically extract knowledge from text. In this paper, we proposed a Retrieval Augmented Generation (RAG) formulation for three different tasks of ontology learning defined in the LLMs4OL Challenge at ISWC 2024. For task A - term typing - we considered terms as a query and encoded the query through the Query Encoder model for searching through knowledge base embedding of types embeddings obtained through Context Encoder. Next, using Zero-Shot Prompt template we asked LLM to determine what types are appropriate for a given term within the term typing task. Similarly, for Task B, we calculated the similarity matrix using an encoder-based transformer model, and by applying the similarity threshold we considered only similar pairs to query LLM to identify whatever pairs have the \"is-a\" relation between a given type and in a case of having the relationships which one is \"parent\" and which one is \"child\". In final, for Task C -- non-taxonomic relationship extraction -- we combined both approaches for Task A and B, where first using Task B formulation, child-parents are identified then using Task A, we assigned them an appropriate relationship. For the LLMs4OL challenge, we experimented with the proposed framework over 5 subtasks of Task A, all subtasks of Task B, and one subtask of Task C using Mistral-7B LLM.",
  "full_text": null,
  "topic": "Ontology",
  "concepts": [
    {
      "name": "Ontology",
      "score": 0.698403000831604
    },
    {
      "name": "Information retrieval",
      "score": 0.6144018769264221
    },
    {
      "name": "Computer science",
      "score": 0.5843886137008667
    },
    {
      "name": "World Wide Web",
      "score": 0.34577202796936035
    },
    {
      "name": "Philosophy",
      "score": 0.045827269554138184
    },
    {
      "name": "Epistemology",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 4
}