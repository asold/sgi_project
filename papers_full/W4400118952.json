{
  "title": "When large language models meet personalization: perspectives of challenges and opportunities",
  "url": "https://openalex.org/W4400118952",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5100394926",
      "name": "Jing Chen",
      "affiliations": [
        "Hong Kong University of Science and Technology",
        "University of Hong Kong"
      ]
    },
    {
      "id": "https://openalex.org/A5100570551",
      "name": "Zheng Liu",
      "affiliations": [
        "Beijing Academy of Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A5101492309",
      "name": "Xu Huang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5111018264",
      "name": "Chenwang Wu",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5100393403",
      "name": "Qi Liu",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5020691963",
      "name": "Gangwei Jiang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5111131626",
      "name": "Yuanhao Pu",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5035063837",
      "name": "Yuxuan Lei",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5100365902",
      "name": "Xiaolong Chen",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5034212740",
      "name": "Xingmei Wang",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5100603979",
      "name": "Kai Zheng",
      "affiliations": [
        "University of Electronic Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5085254654",
      "name": "Defu Lian",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5048237545",
      "name": "Enhong Chen",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4385571689",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4402671806",
    "https://openalex.org/W4401834466",
    "https://openalex.org/W4400606525",
    "https://openalex.org/W4394994587",
    "https://openalex.org/W2155106456",
    "https://openalex.org/W2124187902",
    "https://openalex.org/W2054141820",
    "https://openalex.org/W2117311203",
    "https://openalex.org/W1530276735",
    "https://openalex.org/W2135790056",
    "https://openalex.org/W2509893387",
    "https://openalex.org/W2947936100",
    "https://openalex.org/W2157881433",
    "https://openalex.org/W2723293840",
    "https://openalex.org/W2962745591",
    "https://openalex.org/W2945827670",
    "https://openalex.org/W2963367478",
    "https://openalex.org/W2984100107",
    "https://openalex.org/W2988746856",
    "https://openalex.org/W2964112275",
    "https://openalex.org/W3014901735",
    "https://openalex.org/W179875071",
    "https://openalex.org/W4391215636",
    "https://openalex.org/W6810081322",
    "https://openalex.org/W4385574005",
    "https://openalex.org/W6600511658",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W6602430550",
    "https://openalex.org/W2898076813",
    "https://openalex.org/W2963869731",
    "https://openalex.org/W2798385737",
    "https://openalex.org/W2772021946",
    "https://openalex.org/W2047729491",
    "https://openalex.org/W2912664727",
    "https://openalex.org/W2982019227",
    "https://openalex.org/W2792839191",
    "https://openalex.org/W2913560138",
    "https://openalex.org/W2945623882",
    "https://openalex.org/W2949687195",
    "https://openalex.org/W2951050019",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W3135357496",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W6600741150",
    "https://openalex.org/W3100283070",
    "https://openalex.org/W3146844750",
    "https://openalex.org/W3176793246",
    "https://openalex.org/W4401754921",
    "https://openalex.org/W3099206682",
    "https://openalex.org/W3095839900",
    "https://openalex.org/W3117339789",
    "https://openalex.org/W3201503287",
    "https://openalex.org/W3130909864",
    "https://openalex.org/W4221021831",
    "https://openalex.org/W4385572441",
    "https://openalex.org/W3175225269",
    "https://openalex.org/W4225716497",
    "https://openalex.org/W3175081470",
    "https://openalex.org/W3173436410",
    "https://openalex.org/W3176762756",
    "https://openalex.org/W6600238479",
    "https://openalex.org/W4402670285",
    "https://openalex.org/W3207166518",
    "https://openalex.org/W4403220611",
    "https://openalex.org/W4392367398",
    "https://openalex.org/W4403582587",
    "https://openalex.org/W4285305471",
    "https://openalex.org/W1493526108",
    "https://openalex.org/W2605246672",
    "https://openalex.org/W2725606191",
    "https://openalex.org/W4223982309",
    "https://openalex.org/W2474765392",
    "https://openalex.org/W2742272831",
    "https://openalex.org/W2950416834",
    "https://openalex.org/W2950421571",
    "https://openalex.org/W2970793364",
    "https://openalex.org/W3035725536",
    "https://openalex.org/W2897125675",
    "https://openalex.org/W2903803738",
    "https://openalex.org/W3175529606",
    "https://openalex.org/W3189967866",
    "https://openalex.org/W3155368131",
    "https://openalex.org/W4284882462",
    "https://openalex.org/W4385573063",
    "https://openalex.org/W3170841641",
    "https://openalex.org/W3172750682",
    "https://openalex.org/W4221159558",
    "https://openalex.org/W4385567868",
    "https://openalex.org/W6849763556",
    "https://openalex.org/W6600283593",
    "https://openalex.org/W4290944002",
    "https://openalex.org/W4367047145",
    "https://openalex.org/W4384648324",
    "https://openalex.org/W4378465281",
    "https://openalex.org/W4386728933",
    "https://openalex.org/W6601574642",
    "https://openalex.org/W6600459194",
    "https://openalex.org/W6600120041",
    "https://openalex.org/W6600538214",
    "https://openalex.org/W2897405591",
    "https://openalex.org/W2903340942",
    "https://openalex.org/W4385574286",
    "https://openalex.org/W2798435682",
    "https://openalex.org/W1997136459",
    "https://openalex.org/W2159094788",
    "https://openalex.org/W2089566520",
    "https://openalex.org/W3196695903",
    "https://openalex.org/W6600577311",
    "https://openalex.org/W6753134527",
    "https://openalex.org/W4224311926",
    "https://openalex.org/W2739992143",
    "https://openalex.org/W2740167620",
    "https://openalex.org/W3094497946",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W3175536494",
    "https://openalex.org/W4372338207",
    "https://openalex.org/W2971196067",
    "https://openalex.org/W4377715604",
    "https://openalex.org/W4313484857",
    "https://openalex.org/W3046111474",
    "https://openalex.org/W4389524090",
    "https://openalex.org/W4401864369",
    "https://openalex.org/W6604662147",
    "https://openalex.org/W4385569968",
    "https://openalex.org/W3212213895",
    "https://openalex.org/W6761372199",
    "https://openalex.org/W6600062020",
    "https://openalex.org/W4368755500",
    "https://openalex.org/W6600001191",
    "https://openalex.org/W4392846385",
    "https://openalex.org/W6600103761",
    "https://openalex.org/W6675775337",
    "https://openalex.org/W4385571886",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W4385571445",
    "https://openalex.org/W4296591867",
    "https://openalex.org/W6633340474",
    "https://openalex.org/W6600194071",
    "https://openalex.org/W3034552531",
    "https://openalex.org/W3117684406",
    "https://openalex.org/W3197870239",
    "https://openalex.org/W4224227049",
    "https://openalex.org/W4290874950",
    "https://openalex.org/W3081190557",
    "https://openalex.org/W3034483718",
    "https://openalex.org/W2954698196",
    "https://openalex.org/W3172054950",
    "https://openalex.org/W3174341621",
    "https://openalex.org/W3041360407",
    "https://openalex.org/W3190884738",
    "https://openalex.org/W3208642157",
    "https://openalex.org/W4224320476",
    "https://openalex.org/W4402769683",
    "https://openalex.org/W6601342325",
    "https://openalex.org/W4400413686",
    "https://openalex.org/W6602279052",
    "https://openalex.org/W2963963856",
    "https://openalex.org/W1518951372",
    "https://openalex.org/W2963124051",
    "https://openalex.org/W2265289447",
    "https://openalex.org/W2766397879",
    "https://openalex.org/W2400801499",
    "https://openalex.org/W2399456070",
    "https://openalex.org/W4299796682",
    "https://openalex.org/W2964101860",
    "https://openalex.org/W2429300145",
    "https://openalex.org/W2963797754",
    "https://openalex.org/W2988937804",
    "https://openalex.org/W2997662139",
    "https://openalex.org/W3038439974",
    "https://openalex.org/W3152509363",
    "https://openalex.org/W6600474606",
    "https://openalex.org/W4283324387",
    "https://openalex.org/W6702248584",
    "https://openalex.org/W6600210674",
    "https://openalex.org/W4389524458",
    "https://openalex.org/W6600696048",
    "https://openalex.org/W4385570088",
    "https://openalex.org/W4385567201",
    "https://openalex.org/W4385572830",
    "https://openalex.org/W6604738668",
    "https://openalex.org/W6600504320",
    "https://openalex.org/W6601899773",
    "https://openalex.org/W6600274115",
    "https://openalex.org/W6601076540",
    "https://openalex.org/W4388626886",
    "https://openalex.org/W4312933868",
    "https://openalex.org/W6609127548",
    "https://openalex.org/W6743090812",
    "https://openalex.org/W2971169337",
    "https://openalex.org/W2001528886",
    "https://openalex.org/W4226192380",
    "https://openalex.org/W4385572809",
    "https://openalex.org/W1977664850",
    "https://openalex.org/W2066158919",
    "https://openalex.org/W2953171463",
    "https://openalex.org/W3166731436",
    "https://openalex.org/W4290875552",
    "https://openalex.org/W3209034179",
    "https://openalex.org/W3168282198",
    "https://openalex.org/W4280644551",
    "https://openalex.org/W4290943347",
    "https://openalex.org/W2928773704",
    "https://openalex.org/W6600960895",
    "https://openalex.org/W6600254619",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W6790220310",
    "https://openalex.org/W2509019445",
    "https://openalex.org/W3098605233",
    "https://openalex.org/W6600339457",
    "https://openalex.org/W4375949262",
    "https://openalex.org/W3112689365",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W3098087397",
    "https://openalex.org/W3104506006",
    "https://openalex.org/W3099865390",
    "https://openalex.org/W3098923689",
    "https://openalex.org/W3155001903",
    "https://openalex.org/W3100790518",
    "https://openalex.org/W3105157853",
    "https://openalex.org/W3097982973",
    "https://openalex.org/W3100278010",
    "https://openalex.org/W3106439716",
    "https://openalex.org/W3101366597"
  ],
  "abstract": "Abstract The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users’ requests can be proactively explored, and users’ required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user’s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools’ outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.",
  "full_text": "Published online: 28 June 2024\nWorld Wide Web (2024) 27:42\nhttps://doi.org/10.1007/s11280-024-01276-1\nWhen large language models meet personalization:\nperspectives of challenges and opportunities\nJin Chen 1 · Zheng Liu 2 · Xu Huang 3 · Chenwang Wu 3 · Qi Liu 3 · Gangwei Jiang 3 ·\nYuanhao Pu 3 · Yuxuan Lei 3 · Xiaolong Chen 3 · Xingmei Wang 3 · Kai Zheng 4 ·\nDefu Lian 3 · Enhong Chen 3\nReceived: 22 November 2023 / Revised: 15 March 2024 / Accepted: 14 May 2024 /\n© The Author(s) 2024\nAbstract\nThe advent of large language models marks a revolutionary breakthrough in artiﬁcial intelli-\ngence. With the unprecedented scale of training and model parameters, the capability of large\nlanguage models has been dramatically improved, leading to human-like performances in\nunderstanding, language synthesizing, common-sense reasoning, etc. Such a major leap for-\nward in general AI capacity will fundamentally change the pattern of how personalization is\nconducted. For one thing, it will reform the way of interaction between humans and personal-\nization systems. Instead of being a passive medium of information ﬁltering, like conventional\nrecommender systems and search engines, large language models present the foundation for\nactive user engagement. On top of such a new foundation, users’ requests can be proactively\nexplored, and users’ required information can be delivered in a natural, interactable, and\nexplainable way. For another thing, it will also considerably expand the scope of personal-\nization, making it grow from the sole function of collecting personalized information to the\ncompound function of providing personalized services. By leveraging large language models\nas a general-purpose interface, the personalization systems may compile user’s requests into\nplans, calls the functions of external tools (e.g., search engines, calculators, service APIs,\netc.) to execute the plans, and integrate the tools’ outputs to complete the end-to-end person-\nalization tasks. Today, large language models are still being rapidly developed, whereas the\napplication in personalization is largely unexplored. Therefore, we consider it to be right the\ntime to review the challenges in personalization and the opportunities to address them with\nlarge language models. In particular, we dedicate this perspective paper to the discussion\nof the following aspects: the development and challenges for the existing personalization\nsystem, the newly emerged capabilities of large language models, and the potential ways of\nmaking use of large language models for personalization.\nKeywords Large language models · Personalization systems · Recommender systems ·\nTool-learning · AIGC\nJin Chen and Zheng Liu contributed equally to this work.\nExtended author information available on the last page of the article\n123\nWorld Wide Web (2024) 27:42\n1 Introduction\nThe emergence of large language models [ 1], which have demonstrated remarkable progress\nin understanding human expression, is profoundly impacting the AI community. These mod-\nels, equipped with vast amounts of data and large-scale neural networks, exhibit impressive\ncapabilities in comprehending human language and generating text that closely resembles\nour own. Among these abilities are reasoning [ 2], few-shot learning [ 3], and the incorporation\nof extensive world knowledge within pre-trained models [ 1]. This marks a signiﬁcant break-\nthrough in the ﬁeld of artiﬁcial intelligence, leading to a revolution in our interactions with\nmachines. Consequently, large language models have become indispensable across various\napplications, ranging from natural language processing and machine translation to creative\ncontent generation and chatbot development. The introduction of ChatGPT, in particular,\nhas gained signiﬁcant attention from the human community, prompting reﬂections on the\ntransformative power of large language models and their potential to push the boundaries of\nwhat artiﬁcial intelligence (AI) can achieve. This disruptive technology holds the promise\nof transforming how we interact with and leverage AI in countless domains, opening up\nnew possibilities and opportunities for innovation. As these language models continue to\nadvance and evolve, they are likely to shape the future of artiﬁcial intelligence, empower-\ning us to explore uncharted territories and unlock even greater potential in human-machine\ncollaboration.\nPersonalization, the art of tailoring experiences to individual preferences, stands as an\nessential and dynamic connection that bridges the gap between humans and machines. In\ntoday’s technologically driven world, personalization plays a pivotal role in enhancing user\ninteractions and engagements with a diverse array of digital platforms and services. By\nadapting to individual preferences, personalization systems empower machines to cater to\neach user’s unique needs, leading to more efﬁcient and enjoyable interactions. Moreover,\npersonalization goes beyond mere content recommendations; it encompasses various facets of\nuser experiences, encompassing user interfaces, communication styles, and more. As artiﬁcial\nintelligence continues to advance, personalization becomes increasingly sophisticated in\nhandling large volumes of interactions and diverse user intents. This calls for the development\nof more advanced techniques to tackle complex scenarios and provide even more enjoyable\nand satisfying experiences. The pursuit of improved personalization is driven by the desire\nto better understand users and cater to their ever-evolving needs. As technology evolves,\npersonalization systems will likely continue to evolve, ultimately creating a future where\nhuman-machine interactions are seamlessly integrated into every aspect of our lives, offering\npersonalized and tailored experiences that enrich daily routines.\nLarge language models, with their deep and broad capabilities, have the potential to revo-\nlutionize personalization systems, transforming the way humans interact and expanding the\nscope of personalization. The interaction between humans and machines can no longer be\nsimply classiﬁed as active and passive, just like traditional search engines and recommenda-\ntion systems. However, these large language models go beyond simple information ﬁltering\nand they offer a diverse array of additional functionalities. Speciﬁcally, user intent will be\nactively and comprehensively explored, allowing for more direct and seamless communica-\ntion between users and systems through natural language. Unlike traditional technologies that\nrely on abstract and less interpretable ID-based information representation, large language\nmodels enable a more profound understanding of users’ accurate demands and interests. This\ndeeper comprehension paves the way for higher-quality personalized services, meeting users’\nneeds and preferences in a more reﬁned and effective manner. Moreover, the integration of\n123\n42 Page 2 of 45\nWorld Wide Web (2024) 27:42\nvarious tools is greatly enhanced by the capabilities of large language models, signiﬁcantly\nbroadening the possibilities and scenarios for personalized systems. By transforming user\nrequirements into plans, including understanding, generating, and executing them, users can\naccess a diverse range of information and services. Importantly, users remain unaware of\nthe intricate and complex transformations happening behind the scenes, as they experience\na seamless end-to-end model. The potential of large language models in personal is largely\nunexplored.\nThis paper addresses the challenges in personalization and explores the potential solu-\ntions using large language models. In the existing related work, LaMP [ 4] introduces a novel\nbenchmark for training and evaluating language models in producing personalized outputs for\ninformation retrieval systems. On the other hand, other related surveys [ 5–7] focus mainly on\ntraditional personalization techniques, such as recommender systems. From the perspective\nof learning mechanisms, LLM4Rec [ 5] delves into both Discriminative LLM for Recom-\nmendation and Generative LLM for Recommendation. Regarding the adaptation of LLM\nfor recommender systems in terms of ‘Where’ and ‘How’, Li et al [ 6] concentrate on the\noverall pipeline in industrial recommender phases. Fan et al [ 7], on the other hand, con-\nduct a review with a focus on pre-training, ﬁne-tuning, and prompting approaches. While\nthese works discuss pre-trained language models like Bert for ease of analysis, they dedicate\nlimited attention to the emergent capabilities of large language models. This paper aims to\nﬁll this gap by examining the unique and powerful abilities of large language models in\npersonalization, and further expand the scope of personalization with tools.\nThe remaining of this survey is organized as follows: we review the personalization and\nlarge language models in Section 2 to overview the development and challenges. Then we\ncarefully discuss the potential actors of large language models for personalization from\nSection 3, following the simple utilization of emergent capabilities and the complex integra-\ntion with other tools. We also discuss the potential challenges when large language models\nare adapted for personalization. The whole architecture of this paper is shown in Figure 1.\nFigure 1 Overview of this paper\n123\nPage 3 of 45 42\nWorld Wide Web (2024) 27:42\n2 Backgroundoverview\n2.1 Personalization techniques\nPersonalization, a nuanced art that tailors experience to the unique preferences and needs of\nindividual users, has become a cornerstone of modern artiﬁcial intelligence. In this section,\nwe explore the captivating world of personalized techniques and their profound impact on\nuser interactions with AI systems. We will delve into two key aspects of personalization:\nrecommender systems and personalized assistance. These techniques not only enhance user\nsatisfaction but also exemplify the evolution of AI, where machines seamlessly integrate\nwith our lives, understanding us on a profound level. By tailoring recommendations, provid-\ning customized assistance, and delivering personalized search results, AI systems have the\npotential to create a truly immersive and individualized user experience.\n2.1.1 Recommender systems\nRecommender systems play a pivotal role in personalization, revolutionizing the way users\ndiscover and engage with content. These systems aim to predict and suggest items of interest\nto individual users, such as movies, products, or articles, based on their historical interactions\nand preferences.\nRegarding the development of recommender systems, they have evolved signiﬁcantly\nover the years, with collaborative ﬁltering [ 8, 9] being one of the earliest and most inﬂuential\napproaches. Collaborative ﬁltering relies on user-item interaction data to identify patterns and\nmake recommendations based on users with similar preferences. Traditional solutions, such as\nmatrix factorization [ 10] and user/item-based approaches [ 11], extract potentially interesting\nitems based on the idea that users who have shown similar preferences in the past are likely to\nhave similar preferences in the future. While effective, collaborative ﬁltering has limitations,\nsuch as the \"cold start\" problem for new users and items. To address these limitations, content-\nbased ﬁltering [ 12] emerged, which considers the content of items to make recommendations.\nIt leverages the features and attributes of items to ﬁnd similarities and make personalized\nsuggestions. These features can be grouped into user-side information, such as user proﬁles,\nitem-side information [ 13, 14], such as item brands and item categories, and interaction-\nbased information [ 15], such as reviews and comments. However, content-based ﬁltering\nmay struggle to capture complex user preferences and discover diverse recommendations\nrestricted by the limited feature representations.\nIn recent years, deep learning has gained signiﬁcant attention in the ﬁeld of recommender\nsystems due to its ability to model complex patterns and interactions in user-item data [ 16].\nDeep learning-based methods have shown promising results in capturing sequential, tem-\nporal, and contextual information, as well as extracting meaningful representations from\nlarge-scale data. With the introduction of deep networks, high-order interactions between\nfeatures of users and items are well captured to extract user interest. Deep learning-based\nmethods offer approaches to capture high-order interactions by employing techniques like\nattention mechanisms [ 17, 18] and graph-based networks [ 19] to mine complex relationships\nbetween user and item. These methods have been shown to enhance recommendation per-\nformance by considering higher-order dependencies and inter-item relationships. Another\narea of deep learning-based recommender systems is sequential recommenders, speciﬁcally\ndesigned to handle sequential user-item interactions, such as user behavior sequences over\ntime. Self-Attentions [ 20] and Gated Recurrent Units (GRUs) [ 21] are popular choices for\n123\n42 Page 4 of 45\nWorld Wide Web (2024) 27:42\nmodeling sequential data in recommender systems. These models excel in capturing temporal\ndependencies and context, making them well-suited for tasks like next-item recommendation\nand session-based recommendation. Sequential-based models can take into account the order\nin which items are interacted with and learn patterns of user behavior that evolve. Further-\nmore, the rise of language models like BERT has further advanced recommender systems\nby enabling a better understanding of both natural language features and user sequential\nbehaviors [22]. These language models can capture deep semantic representations and world\nknowledge, enriching the recommendation process and facilitating more personalized and\ncontext-aware recommendations. Overall, the application of deep learning techniques in\nrecommender systems has opened new avenues for research and innovation, promising to\nrevolutionize the ﬁeld of personalized recommendations and enhance user experiences.\n2.1.2 Personalized assistance\nPersonalization Assistance refers to the use of artiﬁcial intelligence and machine learning\ntechniques to tailor and customize experiences, products, or content based on individual\npreferences, behavior, and characteristics of users [ 23]. By analyzing individual prefer-\nences, behaviors, and characteristics, it creates a personalized ecosystem that enhances user\nengagement and satisfaction. In contrast to traditional recommender systems, which rely on\npredicting user interests passively, personalized assistance takes a more proactive approach.\nIt ventures into the realm of predicting users’ next intentions or actions by utilizing con-\ntextual information, such as historical instructions and speech signals. This deeper level of\nunderstanding enables the system to cater to users’ needs in a more anticipatory and intuitive\nmanner. At the core of this capability lies the incorporation of cutting-edge technologies like\nnatural language processing (NLP) and computer vision. These advanced tools empower\nthe system to recognize and interpret user intentions, whether conveyed through spoken or\nwritten language, or even visual cues. Moreover, the potential of personalized assistance\nextends beyond static recommendations to dynamic and context-aware interactions. As the\nsystem becomes more and more familiar with a user’s preferences and patterns, it adapts\nand reﬁnes its recommendations in real-time, keeping pace with the ever-changing needs and\npreferences of the user.\nConversational Recommender Systems [ 24, 25] mark a remarkable stride forward in the\nrealm of personalized assistance. By engaging users in interactive conversations, these sys-\ntems delve deeper into their preferences and ﬁne-tune their recommendations accordingly.\nLeveraging the power of natural language understanding, these conversational recommenders\nadeptly interpret user queries and responses, culminating in a seamless and engaging\nuser experience. Notable instances of personalized assistance products, such as Siri 1 and\nMicrosoft Cortana 2, have already proven their effectiveness on mobile devices. Addition-\nally, the integration of large language models like ChatGPT further elevates the capabilities\nof conversational recommenders, promising even more enhanced user experiences. As this\ntechnology continues to progress, we can anticipate its growing signiﬁcance across diverse\nindustries, including healthcare, education, ﬁnance, etc. While the growth of conversational\nrecommenders and personalized assistance promises immense beneﬁts, it is imperative to\ndevelop these products responsibly. Upholding user privacy and ensuring transparent data\nhandling practices are essential to maintain user trust and safeguard sensitive information.\n1 https://www.apple.com/siri/\n2 https://www.microsoft.com/en-us/cortana\n123\nPage 5 of 45 42\nWorld Wide Web (2024) 27:42\n2.2 Large language models\nLanguage models perform the probabilistic modeling for the generation of natural lan-\nguage [26, 27], i.e., presented with one speciﬁc context, the language models make predictions\nfor the words which are to be generated for the future steps. Nowadays, language models are\nmostly built upon deep neural networks, where two features need to be emphasized. First of\nall, the majority of language models are based on transformers or their close variations [ 28,\n29]. Such types of neural networks are proﬁcient at modeling context dependency within\nnatural languages and exhibit superior and consistently improved performances when being\nscaled up. Secondly, the language models are pre-trained at scale with a massive amount of\nunlabeled corpus [ 3, 30–32]. The pre-trained models are further ﬁne-tuned with task-oriented\ndata to adapt to different downstream applications.\nThere has been tremendous progress in language models in recent years, where the emer-\ngence of large language models, represented by GPT-3 [ 3], marks an important milestone\nfor the entire AI community. The large language models (LLMs), as the name suggests, are\nmassively scaled-up derivatives of conventional language models. Particularly, the backbone\nnetworks and the training data have been largely magniﬁed. For one thing, although there are\nno speciﬁc criteria for the minimum number, a typical LLM usually consists of no less than\nseveral billion and up to trillions of model parameters, which are orders larger than before [ 33].\nFor another thing, the pre-training is conducted based on much more unsupervised corpora,\nwith hundreds of billions or trillions of tokens carefully ﬁltered from sources like Common\nCrawl, GitHub, Wikipedia, Books, ArXiv, etc [ 1]. The impact of scaling is illustrated by the\nscaling laws [ 34, 35], which numerically uncover the power-law relationship between model\nsize, data volume, training scale and the growth of the model’s performance.\nThe scaling up of network and training data lead to the leap-forward of large language\nmodels’ capability. They not only become more proﬁcient at conventional skills, like under-\nstanding people’s intent and synthesising human-like languages, but also process capabilities\nwhich are rarely exhibited by those smaller models. Such a phenomenon is referred as the\nemergent abilities of LLMs, where three representatives capabilities are frequently discussed.\nOne is the in-context learning capability [ 3], where LLMs may quickly learn from the few-\nshot examples provided in the prompt. Another one is the instruct following capability [ 36,\n37]. After ﬁne-tuned with diversiﬁed tasks in the form of instruction tuning, the LLMs are\nmade proﬁcient to follow the human’s instructions. Thus, they may handle different tasks\npresented in an ad-hoc manner. Last but not least, LLMs are found to be able to conduct\nstep-by-step reasoning [ 38, 39]. With certain types of prompting strategies, like Chain-of-\nThought (CoT), LLMs may iteratively approach the ﬁnal answer of some complex tasks, like\nmathematical word problems, by breaking down the tasks into sub-problems and ﬁguring\nout the plausible intermediate answers for each of the sub-problems.\nThanks to the superior capabilities of understanding, reasoning, and generating, large\nlanguage models, especially the chat models produced by instruction tuning, are presented\nas foundamental building blocks for many personalization services. One direct scenario is\nthe conversational search and recommendation [ 40]. Once built upon large language models,\nthe search and recommendation systems will be able to engage with users via interactions,\npresent outputs in a verbalized and explainable way, receive feedback from the user and make\nadjustments on top of the feedback, etc. The above changes will bring about a paradigm\nshift for personalization services, from passively making search and recommendation, to\nproactively ﬁguring out user’s need and seeking for user’s preferred items. In broader scopes,\nthe LLMs may go beyond simply making personalized search and recommendation, but play\nas personalized assistants to help users with their task completions. The LLMs may take\n123\n42 Page 6 of 45\nWorld Wide Web (2024) 27:42\nnotes of users’ important information within their memory, make personalized plans based\non memorized information when new demands are raised, and execute plans by leveraging\ntools like search engines and recommendation systems.\nYet, we have to confront the reality that applying LLMs for personalization is not a trivial\nproblem. To name a quite few of the open challenges. Firstly, personalization calls for the\nunderstanding of user preference, which is more domain-speciﬁc knowledge rather than the\ncommon-sense knowledge learned by LLMs. The effective and efﬁcient adaptation of LLMs\nfor personalized services remains to be resolved. Besides, the LLMs could memorize user’s\nconﬁdential information while providing personalized services. Thus, it raises concerns for\nprivacy protection. The LLMs are learned from Internet data; due to the exposure bias, it is\nalmost inevitable to make unfair predictions for minorities. To address the above challenges,\nbenchmarks and evaluation datasets are needed by the research communities. However, such\nresources are far from complete at present. To fully support personalization with LLMs,\nmethodological and experimental frameworks need to be systematically established for all\nthese perspectives.\n3 LLMsforpersonalization\nIn the following sections, we delve into the potential of large language models for personal-\nization, examining their evolution from simple use cases, like utilizing word knowledge as\nfeatures, to more intricate integration with other tool modules to act as agents. Speciﬁcally,\nwe focus on the progression of emergent capabilities, starting from basic world knowledge\nand understanding user intent, and advancing to high-level reasoning abilities. We explore\nhow large language models can contribute to constructing a knowledge base that enriches\ncommon-sense knowledge about various items. Additionally, we discuss how the understand-\ning capability of large language models can empower content interpreters and explainers for\nin-depth analysis of interactions. Furthermore, we observe attempts to leverage the reasoning\nability of large language models for system reasoners to provide recommendation results.\nThese increasingly sophisticated capabilities enable complex utilization of large language\nmodels with other tool modules, enabling them to better comprehend user intentions and\nfulﬁll user instructions. Consequently, we also explore the integration of large language\nmodels with other tools for personalization, including tool learning, conversational agents\nand personalized content creators. The overview of this chapter is depicted in Figure 2.O u r\ncomprehensive survey aims to provide a deeper understanding of the current landscape, shed-\nding light on the opportunities and challenges associated with incorporating large language\nmodels into personalization.\nFigure 2 The overview of LLM for personalization\n123\nPage 7 of 45 42\nWorld Wide Web (2024) 27:42\n4 LLMsasknowledgebase\nThe knowledge base provides rich information with semantics, attracting increasing attention\nfor the usage of the knowledge base in the recommender systems. Particularly, the knowl-\nedge graphs, where nodes represent entities and edges represent relations in the heterogeneous\ninformation graph, are the common format of knowledge bases and are introduced as side\ninformation to enhance the performance of recommenders. Knowledge graphs help under-\nstand the mutual relations between users and items and also provide better explainability\nfor recommenders. Existing methods that incorporate knowledge graphs in recommender\nsystems can be classiﬁed into three main groups: embedding-based methods, path-based\nmethods and uniﬁed methods. Embedding-based methods, such as CKE [ 14] and DKN [ 41],\nKSR [ 42], SHINE [ 43], utilize semantic representations of users and items. These meth-\nods aim to capture the underlying semantic relationships between entities in the knowledge\ngraph, which can improve the quality of recommendations. Path-based approaches, such as\nHete-MF [ 44], SemRec [ 45], RuleRec [ 46], EIUM [ 47], exploit the semantic connectivity\ninformation present in the knowledge graph to regularize the user and item representations.\nThese methods consider the paths between users and items in the graph and leverage them\nto incorporate interpretability into the recommendation process. Uniﬁed methods, such as\nRippleNet [ 48], KGCN [ 49], KGA T [50], AKUPM [ 51], IntentGC [ 52] reﬁne the represen-\ntations of entities in the knowledge graph by leveraging embedding propagation techniques.\nThese methods propagate the embeddings of entities through the graph structure, allowing\ninformation to ﬂow across connected entities and reﬁning the representations accordingly.\nHowever, the knowledge graphs adopted in recommender systems are limited and with\nlow usability. Reviewing the various knowledge graph datasets for recommender systems,\ncovering the domains of movies, books, news, products, etc., these datasets are still signif-\nicantly sparse compared to the vast amount of human knowledge, particularly the lack of\nfacts, due to the expensive supervision to construct the knowledge graph. Building a com-\nprehensive and accurate knowledge graph would be a complex and resource-intensive task,\nwhich would include data collection, integration, and cleaning to assure data quality and\nconsistency. Limited by the expensive cost of labelling the knowledge graphs, there would\nusually exist missing entities or relations. The user preferences for these entities or paths\nmay be ignored, and the recommendation performance suffers.\nThe ability of Large Language Models to retrieve factual knowledge as explicit knowl-\nedge bases [ 53–56, 56–61] has been stirred discussed, which presents an opportunity to\nconstruct more comprehensive knowledge graphs within recommender systems. Tracing\nback to the work [ 53], large language models have shown their impressive power in storing\nfactual information, such as entities and common sense, and then commonsense knowledge\ncan be reliably transferred to downtown tasks. Existing methods in knowledge graphs fall\nshort of handling incomplete KGs [62] and constructing KGs with text corpus [63]a n d\nmany researchers attempt to leverage the power of LLM to solve the two tasks, i.e., the\nknowledge completion [ 64] and knowledge construction [ 65]. For knowledge graph com-\npletion, which refers to the task of missing facts in the given knowledge graph, recent efforts\nhave been made to encode text or generate facts for knowledge graphs. MTL-KGC [ 66]\nencoders the text sequences to predict the possibility of the tuples. MEMKGC [ 67]p r e d i c t s\nthe masked entities of the triple. StAR [ 68] utilizes Siamese textual encoders to separately\nencode the entities. GenKGC [ 69] uses the decoder-only language models to directly generate\nthe tail entity. TagReal [ 70] generates high-quality prompts from the external text corpora.\nAutoKG [ 63] directly adopts the LLMs, such as ChatGPT and GPT-4, and designs tailored\n123\n42 Page 8 of 45\nWorld Wide Web (2024) 27:42\nprompts to predict the tail entity. As for the another important task, i.e., knowledge graph\nconstruction, which refers to creating a structured representation of knowledge, LLMs can be\napplied in the process of constructing knowledge graphs, including entity discovery [ 71, 72],\ncoreference resolution [ 73, 74] and relation extraction [ 75, 76]. LLMs can also achieve the\nend-to-end construction [ 57, 65, 70, 77, 78] to directly build KGs from raw text. LLMs enable\nthe knowledge distillation to construct knowledge graphs. symbolic-kg [ 79] distills common-\nsense facts from GPT3 and then ﬁnetunes the small student model to generate knowledge\ngraphs. These models have demonstrated the capacity to store large volumes of knowledge,\nproviding a viable option for improving the scope and depth of knowledge graphs. Further-\nmore, these advancements have prompted research into the direct transfer of stored knowledge\nfrom LLMs to knowledge graphs, eliminating the need for human supervision. This inter-\nesting research throws light on the possibilities of automating knowledge graph completion\nutilizing cutting-edge big language models.\nBy leveraging the capabilities of LLMs, recommender systems would beneﬁt from a more\nextensive and up-to-date knowledge base. Firstly, missing faculty information can be com-\npleted to construct more extensive knowledge graphs and thus the relations between entities\ncan be extracted for better recommenders. Secondly, in contrast to the preceding exclusively\nin-domain data, the large language model itself contains plenty of cross-domain information\nthat can help achieve cross-domain recommendations, such as recommending appropriate\nmovies based on the user’s favourite music songs. To sum up, the stored knowledge can\nbe utilized to enhance recommendation accuracy, relevance, and personalization, ultimately\nimproving the overall performance of recommender systems. Existing work [ 80] prompts\nlarge language models to generate factual knowledge about movies to enhance the perfor-\nmance of CTR prediction models. To better utilize the factual knowledge, a Knowledge\nAdaptation module is adopted for better contextual information extraction. LLMRec [ 81]\nadopts LLM-based graph augmentation strategies to enrich the information of items and fur-\nther designs denoise methods to ensure the augmentation. LLM-KRec [ 82] adopts the large\nlanguage models to determine complementary relationships in each entity pair and construct\na complementary knowledge graph, which enhances the industrial recommenders. The exist-\ning work leveraging the capabilities of knowledge base in personalization is summerized in\nTable 1.\nIt is worth noting that the phantom problem of large language models can be a challenge\nwhen applied to recommendation tasks. The inherent nature of large language models can\nintroduce ambiguity or inaccurate provenance [ 83]. This issue can emerge as the introduction\nof extraneous information or even noise into the recommendation process. The large language\nmodels may generate responses that, while syntactically correct, lack informative context or\nrelevance. According to the KoLA [ 84], a benchmark for evaluating word knowledge of\nLLMs, even the top-ranked GPT4 just achieves 0.012 in Precision and 0.013 in Recall on the\ntask Named Entity Recognition , which falls far short of the performance (0.712 in Precision\nand 0.706 in Recall) of the task-speciﬁc models PL-Marker [ 85]. Such a ﬁnding suggests\nthat common sense is still far from being sufﬁciently captured by LLM.\n5 LLMsascontentinterpreter\nContent-based recommenders provide an effective solution for mitigating the sparse feed-\nback issue in recommender systems. By leveraging the attributes and characteristics of items,\nthese systems achieve a more profound understanding of their properties, facilitating accurate\n123\nPage 9 of 45 42\nWorld Wide Web (2024) 27:42\nTable 1 LLMs as knowledge base\nApproach Knowledge Task LLM backbone Datasets\nKAR [ 80] Factual knowledge CTR prediction & Rerank gpt-3.5-turbo Ml-1M, Amazon Book\nLLMRec [ 81] User-item interactions, side information TopK Recommendation gpt-3.5-turbo ML, Netﬂix\nKRec [ 82] Complementary relationship CTR Prediction ChatGPT 3.5, ChatGLM 2 Alipay Data\n123\n42 Page 10 of 45\nWorld Wide Web (2024) 27:42\nmatching with user preferences. However, the content features used in content-based recom-\nmendation may also exhibit sparsity. Relying solely on the recommended supervision signal,\nsuch as clicking and browsing, might not fully exploit the potential beneﬁts of these features.\nTo overcome this challenge, language models emerge as powerful fundamental algorithms\nthat act as content interpreters in processing textual features. Their utilization enhances the\neffectiveness of recommender systems by effectively understanding and interpreting textual\ncontent, leading to improved recommendations.\n5.1 Conventional content interpreter\nConventional content interpreter includes statistical model, neural networks, and advanced\nNLP networks, as summarized in Figure 3. These approaches primarily focus on transforming\ncontent information, such as textual data, into feature embeddings to facilitate the recom-\nmendation process.\nStatistical models like TF-IDF, Minimum Description Length (MDL) [ 86], and bag-of-\nwords have been traditionally used to encode textual data such as news articles and documents\ninto continuous value vectors. However, with the advancement of deep learning techniques,\nresearchers have explored various neural network architectures to learn more expressive con-\ntent representations. Instead of relying solely on statistical embeddings, some approaches\ninitialize the vectors with bag-of-words representations and then employ autoencoder-based\nmodels to learn more powerful representations. For example, CDL [ 16] combines the latent\nvectors obtained from autoencoders with the original ID embeddings to enhance content rep-\nresentations. CRAE [ 87] introduces a collaborative recurrent autoencoder that captures the\nword order in texts, enabling the modeling of content sequences in collaborative ﬁltering sce-\nnarios. Dong et al. [ 88] propose a stacked denoising autoencoder that reconstructs item/user\nratings and textual information simultaneously, allowing for the joint modeling of collabo-\nrative and textual knowledge. CV AE [ 89] introduces a collaborative variational autoencoder\nthat learns probabilistic textual features. While autoencoders are effective in learning low-\ndimensional representations from text data, they may struggle to capture semantic information\neffectively [90]. In some cases, approaches like doc2vec [ 91] are used to construct content\nembeddings [ 92, 93] and learn hidden representations. Okura et al. [ 94] evaluate differ-\nent network architectures, including word-models and GRU networks, for representing user\nstates.\nFigure 3 The development of content interpreter in recommendation\n123\nPage 11 of 45 42\nWorld Wide Web (2024) 27:42\nFollowing the advancements in neural natural language processing (NLP) models, more\nsophisticated architectures such as Convolutional Neural Networks (CNNs), Recurrent\nNeural Networks (RNNs), and Neural Attention models have been employed as content\ninterpreters to extract contextual information and capture user preferences. These models\ntake sentence inputs, such as news titles, reviews, or comments, and transform them into\nword embedding matrices using random initialization or word2vec embeddings [ 95]. V ar-\nious architectures, including CNNs, attention networks, and hybrid models, are utilized to\nlearn representations of sentences. For example, NPA [ 96] and LSTUR [ 97] incorporate\nattention mechanisms to determine the importance of words after CNN layers. NRMS [ 98]\nand CPRS [ 99] utilize multi-head self-attention networks to learn word representations.\nThese models are effective in capturing long-context dependencies and understanding the\nsemantic information in the text. In addition to text modeling, language models are also\nused as content interpreters to capture user interests based on their historical interactions.\nFor instance, WE3CN [ 100] employs a 3D CNN to extract temporal features from the his-\ntorical data. DKN [ 41] utilizes an attention mechanism to aggregate historical information\nrelated to candidate items. DAN [ 101] proposes an attention-based LSTM to capture richer\nhidden sequence features. These models leverage different neural architectures to enhance\nthe representation of text in the context of recommendation systems. It is worth noting that\nthese models still have limitations in terms of depth and the ability to effectively generalize\nsemantic information.\n5.2 Language model based content interpreter\nIn recent years, there has been a growing interest in incorporating more powerful pre-trained\nlanguage models, such as BERT and GPT, into recommendation systems. These language\nmodels have shown exceptional performance in various natural language processing tasks and\nhave sparked researchers’ inspiration to leverage them for capturing deep semantic represen-\ntations and incorporating world knowledge in recommendation systems. However, applying\npre-trained language models to recommendation tasks presents two main challenges. Firstly,\nthere is a misalignment of goals between general-purpose language models and the spe-\nciﬁc objectives of recommendation systems. To address this, researchers have proposed\napproaches that ﬁne-tune the pre-trained models or design task-speciﬁc pre-training tasks to\nadapt them to recommendation tasks. For example, U-BERT [ 102] employs BERT as a con-\ntent interpreter and introduces masked opinion token prediction and opinion rating prediction\nas pre-training tasks to better align BERT with recommendation objectives. Similarly, other\nworks [ 103–107] have utilized pre-trained BERT to initialize the news encoder for news\nrecommendation, enhancing the representation of textual features. The pre-trained model,\nERNIE, is also utilized to enhance the representation ability of queries and documents [ 108,\n109]. The second challenge is reducing the online inference latency caused by pre-trained\nlanguage models, which can be computationally expensive. Researchers have explored tech-\nniques such as knowledge distillation and model optimization to obtain lightweight and\nefﬁcient models suitable for online services. For instance, CTR-BERT [ 110] employs knowl-\nedge distillation to obtain a cache-friendly model for click-through rate prediction, addressing\nthe latency issue.\nMoreover, pre-trained language models have been applied beyond mainstream recommen-\ndation tasks. They have been integrated into various recommendation scenarios, including\ntag recommendation [ 111], tweet representations [ 112], and code example recommenda-\ntion [ 113], to enhance the representation of textual features in those speciﬁc domains.\n123\n42 Page 12 of 45\nWorld Wide Web (2024) 27:42\nAdditionally, some recent works [ 114–117] have explored using only textual features as\ninputs to recommendation models, leveraging pre-trained language models to alleviate cold-\nstart problems and enable cross-domain recommendations. This paradigm offers advantages\nin alleviating cold-start problems and facilitating cross-domain recommendations based on\nthe universality of natural language. ZESREC [ 114] uses BERT to obtain universal continuous\nrepresentations of item descriptions for zero-shot recommendation. Unisrec [ 115] focuses on\ncross-domain sequential recommendation and employs a lightweight MoE-enhanced module\nto incorporate the ﬁxed BERT representation into the recommendation task. VQ-Rec [ 116]\nfurther aligns the textual embeddings produced by pre-trained language models to the rec-\nommendation task with the help of vector quantization. Fu et al. [ 118] explore layerwise\nadaptor tuning to achieve parameter-efﬁcient transferable recommendations.\nWhile the pre-trained language models empower the text understanding with the beneﬁt\nof capturing world knowledge ﬁrst, the development of pre-trained large language models\nprovides great emergency ability in the ﬁelds of reasoning and generalization, as shown\nin Table 2. TALLRe [ 119] explores the ability of large language models for the sequential\nrecommendation. They observe that original language models perform poorly in zero-shot\nand few-shot scenarios, while recommendation-speciﬁc instruction-tuned language models\ndemonstrate superior performance in few-shot learning and cross-domain generalization. Li\net al. [ 123] adopt the large language models as context encoders and attempt to examine\nthe upper limits of the large language models. Similarly, Kang et al. [ 120] propose a sim-\nilar instruction tuning method for rating prediction recommendation tasks based on the T5\nbackbone. They ﬁnd that the tuned language models, which leverage data efﬁciency, outper-\nform traditional recommenders. PALR [ 121] further enhances the construction pipeline of\nrecommendation-speciﬁc instruction tuning, which ﬁrst employs large language models to\ngenerate reasoning as additional features based on the user’s behavior history. Next, a small\nset of candidates is retrieved using any existing model based on the user proﬁle. Finally,\nto adapt general-purpose language models to the recommendation task, they convert the\ngenerated reasoning features, user interaction history, and retrieved candidates into natural\nlanguage instruction data and ﬁne-tune a language model. Existing instruction tuning meth-\nods of language models for recommendation scenarios typically focus on a single type of\nrecommendation task, limiting the full utilization of language models’ strong generalization\nability. InstructRec [ 122] addresses this limitation by formulating recommendation as an\ninstruction-following procedure. They design various instruction templates to accommodate\ndifferent recommendation tasks and employ GPT-3.5 to generate high-quality instruction\ndata based on the historical data of users and templates. The language models ﬁne-tuned\nwith this instruction data can effectively handle a wide range of recommendation tasks and\ncater to diverse information requirements from different users.\n6 LLMsasexplainer\nIn addition to valuing the suggestions made by a recommendation model, users are also\ninterested in the comprehensible justiﬁcations for these recommendations [ 124, 125]. This is\ncrucial as most recommender systems are black boxes whose inner workings are inscrutable\nto human understanding [ 126], diminishing user trust. Taking drug recommendations, for\ninstance, it is unacceptable to recommend drugs with good curative effects simply but fail to\ngive reasons why they are effective. To this end, explainable recommendations aim to couple\nhigh-quality suggestions with accessible explanations. This not only helps to improve the\n123\nPage 13 of 45 42\nWorld Wide Web (2024) 27:42\nTable 2 LLMs for content interpreter\nApproach Task LLM backbone Tuning strategy Datasets\nTALLRe [119] Sequential recommendation LLaMA-7B Instruct tuning & Fine tuning MovieLens100k, BookCrossing\nLLMs-Rec [ 120] Rating prediction Flan-T5-Base, Flan-T5-XXL Fine tuning MovieLens-1M, Amazon book\nPALR [121] Item recommendation LLaMa-7B Instruction tuning MovieLens-1M, Amazon beauty\nInstructRec [ 122] Sequential recommendation\npersonalized search\nFlan-T5-XL Instruction tuning Amazon-Games, CDs\n123\n42 Page 14 of 45\nWorld Wide Web (2024) 27:42\nmodel’s transparency, persuasiveness, and reliability, but also facilitates the identiﬁcation\nand rectiﬁcation of potential errors through insightful explanations. These beneﬁts have been\nextensively documented in recent work [ 38, 127–129]. For instance, [ 128] conducted a\nstudy that involved addressing 40 difﬁcult tasks and evaluating the impact of explanations\non zero-shot and few-shot scenarios. Their ﬁndings demonstrated that explanations have a\npositive effect on model performance by establishing a connection between examples and\ninterpretation.\nTraditional approaches mainly focus on template-based explanations, which can be\nbroadly categorized into item-based, user-based, and attribute-based explanations [ 130].\nItem-based explainable methods relate recommendations to familiar items [ 131], explaining\nthat the recommended item bears similarity to others the user prefers , which are prevalent\non platforms like Amazon [ 132] and Netﬂix [ 133]. However, due to its collaboration, it may\nunderperform in personalized recommendations requiring diversity and can struggle to iden-\ntify relevant items among industrial settings with vast items efﬁciently. In contrast, user-based\nexplanations [ 134] leverage social relationships to make recommendations by explaining\nthat users with similar interests also favor the recommended item . The user’s social property\nmakes these explanations more persuasive, encouraging users to try the recommendations.\nHowever, the variance in user preferences may render this approach less impactful in gauging\nactual preference. Lastly, attribute-based explanations focus on highlighting the attributes of\nrecommended items that users might ﬁnd appealing, essentially conveying \" these features\nmight interest you \". This method demands customization according to each user’s interests,\nyielding higher accuracy and satisfaction. Thus, they are at the forefront of research [ 124,\n135–138].\nObviously, such explanations typically employ pre-deﬁned and formulaic formats, such\nas explanations based on similar items or friends. Although capable of conveying essential\ninformation, such inﬂexible formats may diminish the user experience and satisfaction by\nlacking adaptability and personalization [ 124]. For this reason, natural language generation\napproaches have received increasing attention. Early work [ 139–141] mainly relied on recur-\nrent neural networks (e.g., LSTM [ 142], GRU [143]). Limited by the model’s expressiveness,\nthey often suffer from the issue of insufﬁcient diversity. With the excellent performance of\nTransformer-based models in various natural language tasks, some work attempts to integrate\nTransformer-based models into explainable recommendations. Li et al. [ 144] use the posi-\ntion vectors corresponding to the user (item) IDs to predict interpreted tokens. Subsequent\nwork [ 145] has shown that the generated explanation cannot justify the user’s preference\nby synthesizing irrelevant descriptions. Therefore, Ni et al. [ 146] used such information as\nguided input to BERT to obtain a controllable justiﬁcation. Considering that such auxiliary\ninformation is not always available in real-world scenarios, ExBERT [ 145] only requires his-\ntorical explanations written by users, and utilizes a multi-head self-attention based encoder to\ncapture the relevance between these explanations and user-item pairs. Recently, MMCT [ 147],\nEG4Rec [ 148], and KAER [ 149] have further carried out ﬁner-grained modeling of infor-\nmation such as visual images, time series, and emotional tendencies to obtain high-quality\ninterpretations. An early attempt, LLM4Vis [ 150], has been paid to the explainable visu-\nalization recommendation through ChatGPT. RecExplainer [ 151] proposes three alignment\nstrategies for interpretability.\nDue to the limited expressive power of traditional language models, natural language\ngeneration methods are prone to long-range dependence problems [ 145], that is, the input of\nlong texts will appear to generate explanations that lack diversity and coherence in content. In\naddition, these explanation methods are tightly coupled with speciﬁc recommendation mod-\nels (e.g., NETE [ 141]), or directly design a new recommendation model (e.g., NRT [ 139],\n123\nPage 15 of 45 42\nWorld Wide Web (2024) 27:42\nPETER [ 144]), and they are often powerless when faced with existing advanced recom-\nmendation models, which limits their generalizability. This is also a ﬂaw in template-based\nmethods. Notably, in industrial settings, recommendation algorithms frequently involve not\njust a single model but a cascade or integration of multiple models, and these elaborate\ncombinations further exacerbate the difﬁculty of deciphering recommendations.\nThanks to LLMs’ remarkable generative ability in language tasks, they are ideal for tack-\nling the aforementioned challenges [ 152]. Firstly, with the leverage of extensive training\ndata, LLMs adeptly harness human language, encompassing context, metaphors, and com-\nplex syntax. This equips them to craft customized explanations that are precise, natural,\nand adaptable to various user preferences [ 141, 144, 153], mitigating the limitations of con-\nventional, formulaic explanations. Secondly, the unique in-context learning capabilities of\nLLMs, such as zero-shot prompting, few-shot prompting, and chain-of-thought prompting,\nenable them to garner real-time user feedback during interactions, furnish recommendation\noutcomes, and their corresponding interpretations, fostering bidirectional human-machine\nalignment. Recent study [ 154] has demonstrated the potential of LLMs in elucidating the\nintricacies of complex models, as evidenced by GPT-4 autonomously interpreting the func-\ntion of GPT-2’s each neuron by inputting appropriate prompts and the corresponding neuron\nactivation. This showcases an innovative approach to interpreting deep learning-based rec-\nommendation models. It’s critical to highlight that this interpretation technique is agnostic to\nthe model’s architecture, distinguishing it from traditional interpretations that are bound to\nspeciﬁc algorithms. Thus, recommendation interpretations founded on LLMs pave the way\nfor a versatile and scalable interpretational framework with broader applicability.\nAlthough LLMs have inherently signiﬁcant advantages in recommendation explanations,\nit is imperative to recognize potential issues. Firstly, akin to recommendation models, LLMs\nare essentially black boxes that are difﬁcult for humans to understand. We cannot identify\nwhat concepts they give explanations based on [ 155]. Also, the explanation given may be\ninsincere; that is, the explanations are inconsistent with their recommended behaviors. Some\nrecent developments [ 38, 156] involve utilizing chains of thought to prompt reasoning for\nimproved interpretability; however, the opacity of the reasoning process of each step remains\na concern, and [ 157] has questioned the possible unfaithful explanations of chain-of-thought\nprompting. Secondly, the extensive data utilized by LLMs may encompass human biases and\nerroneous content [158]. Consequently, even if the explanation aligns with the model’s recom-\nmendation behavior, both the explanation and recommendation could be ﬂawed. Monitoring\nand calibrating these models to ensure fairness and accuracy in explainable recommendations\nis essential. Lastly, generative models exhibit varying levels of proﬁciency across different\ntasks, leading to inconsistencies in performance. Identical semantic cues could yield dis-\nparate recommendation explanations. This inconsistency has been substantiated by recent\nstudies [ 159, 160] focusing on the LLMs’ robustness. Addressing these issues calls for\nexploring techniques to mitigate or even circumvent low-reliability explanatory behavior,\nand investigating how LLMs can be trained to consistently generate reliable recommenda-\ntion explanations, especially under adversarial conditions, is a worthwhile avenue for further\nresearch.\n7 LLMsascommonsystemreasoner\nWith the development of large language models, there is an observation that LLMs exhibit\nreasoning abilities [ 2, 161] when they are sufﬁciently large, which is fundamental for human\n123\n42 Page 16 of 45\nWorld Wide Web (2024) 27:42\nintelligence for decision-making and problem-solving. By providing the models with the\n‘chain of thoughts’ [ 38], such as prompting with ’let us think about it step by step’ ,t h e\nlarge language models exhibit emergent abilities for reasoning and can arrive at conclusions\nor judgments according to the evidence or logics. Accordingly, for recommender systems,\nlarge language models are capable of reasoning to help user interest mining, thus improving\nperformance.\n7.1 Making direct recommendations\nIn-context learning [ 167–173] is one of the emergent abilities of LLMs that differentiate\nLLMs from previous pre-trained language models, where, given a natural language instruction\nand task demonstrations, LLMs would generate the output by completing the word sequence\nwithout training or tuning [ 3]. As for in-context learning, the prompt follows by the task\ninstruction and/or the several input-output pairs to demonstrate the task and a test input is\nadded to require the LLM to make predictions. The input-output pair is called a shot.T h i s\nemergent ability enables prediction on new cases without tuning unlike previous machine\nlearning.\nIn the realm of recommender systems, numerous studies have explored the performance\nof zero-shot/few-shot learning using large language models, covering the common recom-\nmendation tasks such as rating prediction, and ranking prediction. These studies evaluate the\nability of language models to provide recommendations without explicit tuning, as summa-\nrized in Table 3, where all methods adopt in-context learning for direct recommenders. The\ngeneral process can be attached in Figure 4. Accordingly, we have the following ﬁndings:\n The aforementioned studies primarily focused on evaluating zero-shot/few-shot recom-\nmenders using open-domain datasets, predominantly in domains such as movies and\nbooks. Large language models are trained on extensive open-domain datasets, enabling\nthem to possess a signiﬁcant amount of common-sense knowledge, including informa-\ntion about well-known movies. However, when it comes to private domain data, such as\ne-commerce products or speciﬁc locations, the ability of zero-shot recommenders lacks\nof validation, which is expected to be challenging.\n Current testing methods necessitate the integration of additional modules to validate\nthe performance of zero-shot recommenders for speciﬁc tasks. In particular, for ranking\ntasks that involve providing a list of items in order of preference, a candidate generation\nmodule is employed to narrow down the pool of items [ 164]a n d[ 165]. Generative-based\nmodels like gpt-3.5-turbo generate results in a generative manner rather than relying on\nrecall from existing memories, thus requiring additional modules to implement ID-based\nitem recommendations.\n From the perspective of recommendation performance, zero-shot recommenders exhibit\nsome capabilities and few-shot learners perform better. However, there still exists a\nsubstantial gap when compared to traditional recommendation models, particularly ﬁne-\ntuned large language models designed speciﬁcally for recommenders, such as P5 [ 174]\nand M6-Rec [175]. This highlights that large language models do not possess a signiﬁcant\nadvantage in personalized modeling.\nAnother important emergent ability is the ‘step by step’ reasoning, where LLMs can\nsolve complex tasks by utilizing prompts including previous intermediate reasoning steps,\ncalled the ‘chain of thoughts’ strategy [ 38]. Wang and Lim [ 164] design a three-step prompt,\nnamely NIR, to capture user preferences, extract the most representative movies and rerank\n123\nPage 17 of 45 42\nWorld Wide Web (2024) 27:42\nTable 3 Zero/Few-shot learners of LLMs for RS\nApproach LLM backbone Task Metric Datasets ICL COT\n[162] gpt-3.5-turbo Rating prediction\nsequential recom-\nmendation direct\nrecommendation\nexplanation gen-\neration review\nsummarization\nRMSE,MAE\nHR,NDCG\nHR,NDCG\nBLUE4,ROUGE,Human\nEval\nBLUE4,ROUGE,Human\nEval\nAmazon beauty ✓\n[163] Text-davinci-002\ntext-davinci-003\ngpt-3.5-turbo\nPoint-wise pair-\nwise list-wise\nNDCG,MRR MovieLens-1M\nAmazon-Book\nAmazon-Music\nMIND-small\n✓\n[120] Flan-U-PALM\ngpt-3.5-turbo text-\ndavinci-003\nRating prediction\nranking prediction\nRMSE,MAE\nROC-AUC\nMovieLens-1M\nAmazon-Books\n✓\n[164] Text-davinci-003 Reranking NDCG,HR MovieLens 100K ✓✓\n[165] gpt-3.5-turbo Reranking NDCG MovieLens-1M\nAmazon-Games\n✓\n[166] gpt-3.5-turbo Reranking Precision MIND ✓\n123\n42 Page 18 of 45\nWorld Wide Web (2024) 27:42\nFigure 4 An example of zero/few-shot learning for direct recommenders\nthe items after item ﬁltering. Such a multi-step reasoning strategy signiﬁcantly improves\nrecommendation performance.\n7.2 Reasoning for automated selection\nAutomated Machine Learning (AutoML) is widely applied in recommender systems to elimi-\nnate the costly manual setup with trials and errors. The search space in recommender systems\ncan be categorized in (1) Embedding size (2) Feature (3) Feature interaction (4) Model archi-\ntecture. Embedding size search, such as [ 176–179] seeks for appropriate embedding size\nfor each feature to avoid resources overconsumption. Searching for features consisting of\nraw feature search [ 180, 181] and synthetic feature search [ 182, 183], which selects a subset\nfrom the set of original or cross features to maintain informative features to reduce both\ncomputation and space cost. Feature interaction search, such as [ 184–188], automatically\nﬁlters out feature interactions that are not helpful. Model architecture search, like [ 189–192],\nexpands the search space to the integral architectures. The search strategy shifts from the\ndiscrete reinforcement learning process, which iteratively samples architectures for training\nand is time-consuming, into the differentiable searching, which adaptively selects architec-\ntures within one-shot learning to circumvent the computational burden, for more efﬁcient\nconvergence. The evaluation for each sampled architecture then acts as the signal to adjust\nthe selections. That is, there is a decision maker who memorizes the prior results of previous\narchitecture choices and analyzes the prior results to give the next recommended choice.\nThe emergent LLMs have excellent memorization and reasoning capabilities that would\nwork for automated learning. Several works have attempted to validate the potential of auto-\nmated machine learning with LLMs. Preliminarily, GPT-NAS [ 193] takes advantage of the\ngenerative capability of LLMs. The architecture of networks is formulated into sequential\ncharacters, and thus the generation of network architectures can be easily achieved through\nthe generative pre-training models. NAS-Bench-101 [ 194] is utilized for pre-training and the\nstate-of-the-art results are used for ﬁne-tuning. The generative pre-training models produce\nreasonable architectures, which would reduce the search space for later genetic algorithms\nfor searching optimal architectures. The relatively advanced reasoning ability is further eval-\nuated in GENIUS [ 195], where GPT-4 is employed as a black-box agent to generate potential\nbetter-performing architectures according to previous trials including tried architectures with\ntheir evaluation performance. According to the results, GPT-4 can generate good architecture\nnetworks, showing the potential for more complicated tasks. Yet it is too difﬁcult for LLMs\nto directly make decisions on challenging technical problems only by prompting. To balance\n123\nPage 19 of 45 42\nWorld Wide Web (2024) 27:42\nefﬁciency and interpretability, one approach is to integrate the LLMs into certain search\nstrategies, where the genetic algorithm guides the search process and LLMs generate the\ncandidate crossovers. LLMatic [ 196] and EvoPrompting [ 197] use code-LLMs as mutation\nand crossover operators for a genetic NAS algorithm. During the evolution process, each\ngeneration has a certain probability of deciding whether to perform crossover or mutation\nto produce new offspring. Crossover and mutation are generated by prompting LLMs. Such\na solution integrates LLM into the genetic search algorithm, which would achieve better\nperformances than direct reasoning over the whole space.\nThe research mentioned above brings valuable insights into the ﬁeld of automated learn-\ning in recommender systems. However, several challenges need to be addressed. Firstly, the\nsearch space in recommender systems is considerably more complex, encompassing diverse\ntypes of search space and facing signiﬁcant volume issues. This complexity poses a chal-\nlenge in effectively exploring and optimizing the search space. Secondly, compared to the\ncommon architecture search in other domains, recommender systems lack a strong founda-\ntion of knowledge regarding the informative components within the search space, especially\nthe effective high-order feature interactions. Unlike well-established network structures in\nother areas, recommender systems operate in various domains and scenarios, resulting in\ndiverse and domain-speciﬁc components. Addressing these challenges and advancing the\nunderstanding of the search space and informative components in recommender systems\nwill pave the way for signiﬁcant improvements in automated learning approaches.\n8 LLMsasconversationalagent\nConversational recommender system (CRS) is a specialized type of recommendation tool\nthat aims to uncover users’ interests and preferences through dialogue, enabling personal-\nized recommendations and real-time adjustment of recommendation strategies based on user\nfeedback. Compared to traditional recommender systems, conversational recommender sys-\ntems have the advantage of real-time understanding of user intents and the ability to adapt\nrecommendations based on user feedback. Typically, a conversational recommender system\nconsists of two main components: a dialogue module and a recommendation module.\nIn this section, we will primarily focus on discussing the dialogue module, which plays a\ncrucial role in facilitating effective user-system interactions and understanding user prefer-\nences (Figure 5).\nIn a conversational recommender system, the dialogue module typically takes the form of\na dialogue system. Dialogue systems can generally be classiﬁed into two main categories:\nchit-chat and task-oriented. The former focuses on open-domain question answering, and two\nmajor methods are commonly employed: generative and retrieval-based methods. Generative\nmethods [ 198–200] utilize a sequence-to-sequence model structure to generate responses,\nwhile retrieval-based methods [ 201–203] transform the task of generating responses into a\nretrieval problem by searching for the most relevant response in a response database based on\nthe dialogue context. In conversational recommender systems, task-oriented dialogue systems\nare more often required, as they are speciﬁcally designed to assist users in accomplishing\nspeciﬁc tasks. For task-oriented dialogue systems, a common approach [ 24, 204] is to treat the\nresponse generation as a pipeline and handle it separately using four components: dialogue\nunderstanding [ 205, 206], dialogue state tracking [ 207–209], dialogue policy learning [ 24,\n210], and natural language generation [ 211, 212]. Another approach is to employ an end-to-\nend method [ 213–215], training an encoder-decoder model to handle all the processing steps\n123\n42 Page 20 of 45\nWorld Wide Web (2024) 27:42\nFigure 5 Important approaches in conversational agent\ncollectively. The ﬁrst approach suffers from scalability issues and lacks synergy between the\ncomponents, while the second approach requires a substantial amount of supervised data for\ntraining.\nBased on the classiﬁcation of dialogue systems, common approaches in conversational\nrecommender systems can also be divided into two categories: attribute-based QA (question-\nanswering) and generative methods. The attribute-based QA approach [ 24, 216–218] utilizes\na pipeline method within the dialogue system. In each dialogue turn, the system needs to\ndecide whether to ask the user a question or provide a recommendation. The decision-making\nprocess, particularly regarding which attribute to ask about, is typically handled by a policy\nnetwork. On the other hand, generative methods do not explicitly model the decision-making\nprocess. Instead, they often employ an end-to-end training approach, where a sequence-\nto-sequence model generates output directly from a shared vocabulary of words and items.\nWhether the generated output is chit-chat, a question, or a recommendation is implicitly deter-\nmined during the generation process. Compared to attribute-based QA methods, generative\nmethods [ 219–222] appear to be simpler and more scalable. However, they require a large\namount of supervised training data. With the advancement of pre-trained language models\n(PLMs) in the ﬁeld of natural language processing, particularly models like BERT [ 223]a n d\nGPT [ 224], the capabilities of pre-trained models in language understanding and generation\nhave become increasingly powerful. Researchers have found that ﬁne-tuning pre-trained mod-\nels with a small amount of supervised data can yield impressive results on speciﬁc tasks. This\ndiscovery has led to the application of PLMs in generative conversational recommender sys-\ntems. For example, DialoGPT [ 215] achieved promising dialogue intelligence by ﬁne-tuning\nGPT-2 on dialogue data collected from platforms like Reddit. Subsequently, BARCOR [ 220],\nRecInDial [ 222], and UniCRS [ 221] utilized DialoGPT for constructing conversational rec-\nommender systems, with variations in their action decision strategies. While PLMs reduce\nthe dependency of generative dialogue models on extensive data, the ﬁne-tuning process still\nincurs signiﬁcant computational time and requires the collection of high-quality domain-\nspeciﬁc training data due to the large parameter space.\nWith the increase in model parameters and training data, the intelligence and knowledge\ncapacity of models continues to improve. OpenAI has been expanding the model parameters\nand training data while employing techniques such as RLHF (Reinforcement Learning from\n123\nPage 21 of 45 42\nWorld Wide Web (2024) 27:42\nHuman Feedback) and Instruction Tuning to further ﬁne-tune GPT-3 [ 3]. This has led to\nthe emergent abilities of models like InstructGPT [ 37] and subsequent models like Chat-\nGPT, which exhibit incredible intelligence and have opened the doors to new intelligent\ndialogue systems based on large language models (LLMs). Furthermore, Google’s BARD\nand META ’s LLaMA [32] are also large language dialogue models that have been proposed\nand demonstrated remarkable performance in conversational abilities. The Vicuna model,\nfor instance, utilizes dialogue corpora shared by users in using ChatGPT to ﬁne-tune the\nopen-source LLaMA model, with the team claiming it can achieve over 90% of ChatGPT’s\ncapability. This series of successive LLM introductions has brought new insights to conversa-\ntional recommender systems. Due to the utilization of extensive open-domain corpora during\nthe training of LLM, it possesses inherent conversational recommendation capabilities and\ncan provide reasonable recommendations in open domains such as movies, music, news, and\ngames.\nHowever, there are still signiﬁcant challenges in building an enterprise-level CRS. The\nﬁrst challenge is the lack of awareness of large models about private domain data. It is well\nknown that most of the training data for LLMs, such as GPT-3, comes from publicly available\nsources on the internet. As a result, these models may lack visibility into the data that resides\nwithin information platforms, making their modeling and understanding capabilities of such\ndata relatively poor. To address this challenge, there are currently two approaches being\nexplored: ﬁne-tuning [ 215] and tool learning [ 225, 226]. Fine-tuning involves tuning LLM\nusing private domain-speciﬁc dialogue data. There are two major concerns in the approach.\nFirst, massive high-quality domain-speciﬁc dialogue data is required to tune the extremely\nlarge model. However, in most recommendation scenarios, data primarily consists of explicit\nor implicit user-item interactions, which may lack conversational context. Therefore, gener-\nating high-quality dialogue data from interaction data is a key concern in the approach. In\nRecLLM [ 226]a n di E v a L M[ 227], researchers have proposed using LLMs to construct a\nuser simulator for generating conversational data. Besides, the ﬁne-tuning technique plays\na crucial role in determining the ultimate quality of LLMs. A well-designed and effective\nﬁne-tuning strategy can lead to signiﬁcant improvements in the model’s performance and\ncapabilities, such as instruction tuning and RLHF proposed in InstructGPT [ 3]. Tool learning\nis another approach to address this challenge, and its main idea is to treat traditional recom-\nmendation models as tools to be utilized, such as Matrix Factorization (MF) and DeepFM.\nFor a more detailed explanation of tool learning, please refer to Section 9. Since recommenda-\ntion models are domain-speciﬁc, LLM can leverage these models to obtain recommendation\nresults and recommend them to the users in the response. In this approach, there are two\nmain technical points: the construction of the tool model and the engineering of prompts to\nguide the LLM in the proper utilization of the tool. First of all, conventional recommenda-\ntion models generally use id or categorical features as input, while users always give their\nrequirements or preferences in natural language in conversations. Therefore, unstructured text\nfeatures should be taken into consideration in tool construction. In Chat-Rec [ 225], a conven-\ntional recommendation model and a text embedding-based model(text-embedding-ada-002)\nare used as tools. RecLLM [ 226] adapted a language model enhanced dual-encoder model\nand several text retrieval methods as the recommendation engine. On the other hand, despite\nthe strong intelligence and reasoning capabilities of LLMs, effectively harnessing these abili-\nties requires well-crafted prompts for guidance. For instance, the Chain of Thought proposed\nby Jason [ 38] could trigger LLM to reason and engage in step-by-step thinking, which\n123\n42 Page 22 of 45\nWorld Wide Web (2024) 27:42\nbeneﬁts the tool-using capability. Subsequent studies like ToT [ 228], Plan-and-Solve [ 229]\nand ReAct [ 230] have proposed more advanced techniques for prompt design to assist in\nguiding LLM to engage in deeper thinking and tool planning.\nThe second challenge lies in the issue of memory and comprehension in long conversa-\ntions. Due to the input constraints of LLMs, models like ChatGPT can support a maximum of\n4096 tokens in a single call, including both input and output. In multi-turn dialogue scenar-\nios, longer dialogue contexts often meet the risk of exceeding this token limit. The simplest\napproach to tackle this challenge is to trim the dialogue by discarding earlier turns. How-\never, in conversational recommender systems, users may express a signiﬁcant amount of\npersonal information and interests in the early stages of the conversation. The omission of\nsuch information directly impacts the accuracy of recommendations. To address this issue,\nseveral relevant works have proposed solutions. MemPrompt [ 231] enhances the prompt by\nincorporating a memory module, enabling GPT-3 to possess stronger long-dialogue memory\ncapability. Similarly, RecLLM [226] leverages LLM to extract user proﬁles and store them as\nfactual statements in user memory. When processing user queries, relevant facts are retrieved\nbased on text similarity.\n9 Tool-learninganditsapplicationsinrecommendation\n9.1 LLM-based tool learning\nTool learning is an emerging research ﬁeld that aims to enhance task-solving capabilities by\ncombining specialized tools with foundational models, which has been understood by [ 232]\nas two perspectives:\n1. Tool-augmented learning treats specialized tools as assistants in order for improving\nthe quality and accuracy of tasks, or Tool for AI ;\n2. Tool-oriented learning focuses more on training models to effectively use tools, con-\ntrolling and optimizing tool-applying processes, or AI for Tool .\nTool learning has found applications in various ﬁelds, and this section primarily focuses\non tool learning paradigms based on large language models (LLMs). While recent works\noften involve a combination of these two perspectives, we do not speciﬁcally categorize each\nwork into one type. LLMs, such as GPT, are well-suited for tool learning applications [ 233].\nWith their powerful natural language processing capabilities, LLMs can break down complex\ntasks into smaller sub-tasks and convert them into executable instructions. Specialized tools\nallow LLMs to access knowledge that is beyond their own understanding. By integrating\nspecialized tools, LLMs can better understand and then address complex problems, offering\nmore accurate and efﬁcient solutions for personalized systems.\nLLMs are commonly applied as controllers to select and manage various existing AI\nmodels to solve complex tasks, which rely on user input and language interfaces on making\nsummarizations. They act as the central component, responsible for comprehending prob-\nlem statements and making decisions regarding which actions to execute. Additionally, they\naggregate the outcomes based on the results of the executed actions. In that case, Hug-\ngingGPT [ 243] leverages existing models from the Hugging Face community 3 to assist in\n3 https://huggingface.co\n123\nPage 23 of 45 42\nWorld Wide Web (2024) 27:42\ntask-solving. Visual ChatGPT [ 244] combines visual foundation models like BLIP [ 247],\nStable Diffusion [ 248], etc. with LangChain 4 to handle complex visual tasks, while the fol-\nlowing TaskMatrix.AI [ 245] maintains a uniﬁed API Platform extending the capabilities\nof Visual ChatGPT, extends the capabilities of Visual ChatGPT by maintaining a uniﬁed\nAPI Platform, enabling input from multiple modalities and generating more complex task\nsolutions. On the contrary, Auto-GPT 5 operates as an agent that autonomously understands\nspeciﬁc targets through natural language and performs all processes in an automated loop,\nwithout requiring mandatory human input.\nWebGPT [ 239] introduces a text-based Web browsing interactive environment, where\nLLMs learn to emulate the complete process of human interaction with a Web browser\nusing behavior cloning and rejection sampling techniques. In ReAct [ 230], by leveraging\nan intuitive prompt, LLMs learn to generate both reasoning paths and task-speciﬁc actions\nalternately when solving a speciﬁc task. The execution of speciﬁc actions is delegated to\ncorresponding tools, and external feedback obtained from these tools is utilized to validate and\nguide the reasoning process further. The motivation behind Toolformer [ 246] aligns closely\nwith ReAct; however, it goes a step further by combining diverse tools within a single model.\nThis integration provides the model with ﬂexible decision-making abilities and improved\ngeneralization capabilities, achieved through a simple yet effective self-supervised method.\nIn contrast to prior works, LA TM [ 249] takes a novel approach by empowering LLMs to\ndirectly generate tools. It achieves a division of labor within the task-solving process by\nemploying LLMs at different scales: the tool maker, tool user, and dispatcher. LA TM is\nentirely composed of LLMs, enabling the self-generation and self-utilization of tools.\n9.2 Applications in personalization scenarios\nRecently, LLMs have demonstrated impressive abilities in leveraging internal world knowl-\nedge and common sense reasoning to accurately understand user intent from dialogues.\nMoreover, LLMs can communicate with users ﬂuently in natural language, offering a seam-\nless and delightful user experience. These advantages make LLMs an appealing choice as\nrecommendation agents to enhance the personalized experience.\nHowever, despite the impressive memory capacity of LLMs, they face challenges in mem-\norizing speciﬁc knowledge in private and specialized domains without sufﬁcient training. For\ninstance, storing the item corpus and all user proﬁles in a recommender system can be chal-\nlenging for LLMs. This limitation can result in LLMs generating inaccurate or incorrect\nresponses and makes it difﬁcult to control their behavior within a speciﬁc domain. Further-\nmore, LLMs face the challenge of the temporal generalization problem as external knowledge\ncontinues to evolve and change over time. To address these issues, various tools can be uti-\nlized to augment LLMs and enhance their effectiveness as recommendation agents. Table 4\nshows examples of related tools.\nSearch engine Search engines are widely employed to provide external knowledge to\nLLMs, reducing LLMs’ memory burden and alleviating the occurrence of hallucinations in\nLLMs’ responses. BlenderBot 3 [ 250] uses speciﬁc datasets to ﬁne-tune a series of modules,\nenabling LLMs to learn to invoke the search engine at the appropriate time and extract useful\nknowledge from the retrieval results. LaMDA [ 238] learns to use a toolset that includes an IR\n4 https://docs.langchain.com\n5 https://github.com/Signiﬁcant-Gravitas/Auto-GPT\n123\n42 Page 24 of 45\nWorld Wide Web (2024) 27:42\nTable 4 LLM-based tool learning approaches\nApproach Tool usage LLM backbone Task\nRe3 [ 234] LLM gpt3-instruct-175B gpt3-instruct-\n13B\nLong stories generation\nPEER [ 235] LLM LM-Adapted T5 Editions, citations, quotes\nMETALM [236] Pretrained encoders with diverse\nmodalities\nTransformer (pretrained from\nscratch)\nlanguage-only tasks vision-\nlanguage tasks\nAtlas [ 237] Dense retriever T5 Knowledge-intensive language\ntasks massively-multitask language\nunderstanding question answering\nfact checking\nLaMDA [238] Retriever translator calculator Decoder-only transformer Dialog\nWebGPT [239] Web browser gpt-3 Question answering\nMind’s Eye [240] Physics engine text-to-code LM gpt-3 PaLM Reasoning\nPAL [241] Python interpreter CODEX(code-davinci-002) Mathematical symbolic algorithmic\nreasoning\nSayCan [ 242] Robots PaLM Real-world robotic tasks\nHuggingGPT [ 243] AI models in hugging face commu-\nnity\ngpt-3.5-turbo text-davinci-003 gpt-\n4\nImage classiﬁcation image caption-\ning object detection etc.\nAuto-GPT Web browser gpt-3.5-turbo text-davinci-003 gpt-\n4\nUser-speciﬁed tasks\nVisual ChatGPT [ 244]\nTaskmatrix.AI [245]\nVisual foundation models cus-\ntomized models with uniﬁed API\nform\ntext-davinci-003 Visual customized tasks\nReAct [ 230] Wikipedia API PaLM-540B Question answering face veriﬁ-\ncaiton\nToolformer [246] Calculator Q&A system search\nengine translation system calendar\nGPT-J Downstream tasks\n123\nPage 25 of 45 42\nWorld Wide Web (2024) 27:42\nsystem, a translator, and a calculator through ﬁne-tuning to generate more factual responses.\nRETA-LLM [251] is a toolkit for retrieval-augmented LLMs. It disentangles IR systems and\nLLMs entirely, facilitating the development of in-domain LLM-based systems.Thoppilan et\nal. [ 238] shows a case of applying LaMDA to content recommendation. Preconditioned on\na few role-speciﬁc dialogues, LaMDA can play the role of a music recommendation agent.\nRecommendation engine Some works have attempted to alleviate the memory burden\nof LLMs by equipping them with a recommendation engine as a tool, enabling LLMs to\noffer recommendations grounded on the item corpus. The recommendation engine in Chat-\nREC [ 225] is further divided into two stages: retrieve and reranking, which aligns with\ntypical recommendation system strategies. In the retrieval stage, LLMs utilize traditional\nrecommendation systems as tools to retrieve 20 items from the item corpus as a candidate\nitem set. Subsequently, LLMs employ themselves as tools to rerank the candidate item set.\nLLMs’ commonsense reasoning ability, coupled with the internal world knowledge within\nthem, allow them to provide explanations for the sorting results. The recommendation engine\ntool used in RecLLM [ 226] is highly similar to it in Chat-REC, and it is also divided into\nretrieval and reranking stages. RecLLM provides several practical solutions for large-scale\nretrievals, such as Generalized Dual Encoder Model and Concept Based Search, and so on.\nDatabase Databases are also utilized as tools to supplement additional information for\nLLMs. In order to better cope with the cold-start problem for new items and alleviate the\ntemporal generalization problem of LLMs, a vector database is utilized to provide information\nfor new items that the LLMs are unaware of in Chat-REC [ 225]. When encountering new\nitems, LLMs can utilize this database to access information about them based on the similarity\nbetween the user’s request embedding and item embeddings in the database. User proﬁles\ncan also help LLMs better understand the user’s intent. RecLLM [ 226]e m p l o y sau s e r\nproﬁle module as a tool to deposit meaningful and enduring facts about users exposed during\nhistorical conversations in user memory and retrieve a single fact related to the current\ndialogue when necessary.\nAlthough some works have applied the concept of tool learning to personalization sys-\ntems, there are still interesting and promising research topics that deserve exploration. 1)\nFine-tuning models for better tool use. In-context learning has shown promise in teach-\ning LLMs how to effectively use tools with a small number of demonstrations, as shown\nin Chat-REC and RecLLM. However, LLMs often struggled to learn strategies for handling\ncomplex contexts with limited demonstrations. Fine-tuning is a viable option for improving\ntool use, but it requires sufﬁcient training data and effective techniques. RecLLM further\nﬁne-tunes some modules of it using synthetic data generated by a user simulator through\nRLHF [ 37] technique. Investigating methods to obtain sufﬁcient training data and develop-\ning tailored ﬁne-tuning techniques for recommendation systems is a worthwhile research\ndirection. 2) Developing a more powerful recommendation engine. Traditional recom-\nmendation systems often rely on collaborative ﬁltering signals and item-to-item transition\nrelationships for recommendations. However, with the use of LLMs as the foundation mod-\nels, user preferences can be reﬂected through natural language and even images. Therefore,\ndeveloping a recommendation engine that supports multimodal data is a crucial research\ndirection. Additionally, the recommendation engine should also be capable of adjusting the\ncandidate set based on user preferences or feedback (such as querying movies of a speciﬁc\ngenre or disliking an item in the recommendation set). 3) Building more tools. To provide\nLLMs with more authentic and personalized information, the development of additional tools\nis crucial. For example, APIs for querying knowledge graphs [ 252] or accessing users’ social\n123\n42 Page 26 of 45\nWorld Wide Web (2024) 27:42\nrelationships can enhance the knowledge available to LLMs, enabling more accurate and\ntailored recommendations.\n10 LLMsaspersonalizedcontentcreator\nTraditional recommender systems focus on suggesting existing items based on user prefer-\nences and historical data, where displayed content is already generated for retrieval. However,\nwith the advancements in techniques and platforms for content creators, personalized content\ncreator has attracted more and more attention, where more appealing content is customized\ngenerated to match the user’s interests and preferences, especially in the realm of online adver-\ntising [253]. The common contents contain the visual and semantic contents [ 254–256], such\nas title, abstract, description, copywritings, ad banners, thumbnail, and videos. One more\nwidely discussed topic is text ad generation, where the ad title and ad description are gen-\nerated with personalized information. Earlier works adopt the pre-deﬁned templates [ 254,\n257, 258] to reduce the extensive human effort, which, however, often fail to fully meet\nthe user’s interests and preferences. More recent data-driven methods have emerged, which\nincorporate user feedback as rewards in the reinforcement learning framework to guide the\ngeneration process [ 259–262]. Furthermore, the incorporation of pre-trained language mod-\nels has played a signiﬁcant role in improving the generation process for multiple content\nitems [ 263–266]. This integration helps reﬁne the content generation models and improve\ntheir ability to meet user preferences effectively.\nAs recommender systems and large language models continue to evolve, a promising tech-\nnique that would bring new opportunities is the integration of AI Generated Content (AIGC).\nAIGC [ 267] involves the creation of digital content, such as images, music and natural lan-\nguage through AI models, with the aim of making the content creation process more efﬁcient\nand accessible. Earlier efforts in this ﬁeld focused on deep-learning-based generative mod-\nels, including Generative Adversarial Networks (GANs) [ 268], V ariational AutoEncoders\n(V AEs) [269], Normalizing Flows [ 270], and diffusion-based models [ 271] for high-quality\nimage generation. As the generative model evolves, it eventually emerges as the transformer\narchitecture [28], acting as the foundational blocks for BERT [ 29]a n dG P T[ 224]i nt h eﬁ e l d\nof NLP , and for Vision Transformer (ViT) [ 272]a n dS w i nT r a n s f o r m e r[273]i nt h eﬁ e l d\nof CV . Moreover, the scope of generation tasks expanded from uni-modal to multi-modal\ntasks, including the representative model CLIP [ 274], which can be used as image encoders\nwith multi-modal prompting for generation. The multi-modal generation has become an\nessential aspect of AIGC, which learns the multimodal connection and interaction, typically\nincluding vision language generation [ 274], text audio generation [ 275], text graph gen-\neration [ 276], text Code Generation [ 277]. With the emergence of large language models,\nnowadays AIGC is achieved by extracting the human intention from instructions and generat-\ning the content according to its knowledge and intention. Representative products, including\nChatGPT [ 278], DALL-E-2 [ 279], Codex [ 280] and Midjourney [ 281], have attaining sig-\nniﬁcant attention from society. With the growth of data and model size, the model can learn\nmore comprehensive information and thus leading to more realistic and high-quality content\ncreators.\nRecall to the personalized content creator, the large language models would bring oppor-\ntunities from the following points (Figure 6). Large language models would further extend\n123\nPage 27 of 45 42\nWorld Wide Web (2024) 27:42\nFigure 6 Advantages of content creator with LLMs\nthe capabilities of the pre-trained model, allowing for better reasoning of user personalized\nintent and interest. Previous methods [ 264, 265] depending on tailored pre-training models\nmay be enhanced to better improve the reasoning abilities and few-shot prompting. Sec-\nondly, Reinforcement Learning from Human Feedback (RLHF) strategy can be applied to\nﬁne-tune models to better capture the user intent information, similar to existing RL-based\nframework [ 260] for text ad generation. Last but not least, the powerful generative abilities\nof large language models empower realistic creation thanks to the availability of sufﬁcient\ncross-modal knowledge bases. The work [ 282] more speciﬁcally proposes a recommendation\nparadigm based on ChatGPT, where the generation process receives feedback and multiple\nrounds of conversions to better capture the user explicit preferences. Compared to previous\ntraining paradigms, more explicit expressions of user interest can be understood by the large\nlanguage models and converted into corresponding instructions to guide the generation of\ncontent, signiﬁcantly alleviating the problem of extremely sparse feedback. The integration\nof AIGC (Artiﬁcial Intelligence and Generative Content) with recommender systems offers\nvaluable opportunities in various business scenarios. In E-commerce, large language models\ncan power chatbots for personalized product recommendations and create captivating con-\ntent to attract users. In Customer Service, AIGC enables automated responses, FAQs, and\npersonalized assistance, improving support efﬁciency and customer satisfaction. Overall,\nintegrating AIGC with recommender systems enhances user experiences and drives business\ngrowth.\nHowever, there are two major security and privacy risks for personalized content cre-\nators. One of the concerns is the reliability of models like ChatGPT in terms of factuality, as\nindicated in the work [ 283]. While these models generate content that appears reasonable,\nthere is a risk of distributing misleading or inaccurate information, which can weaken the\ntruthfulness of internet content. This concern becomes particularly crucial in personalized\nrecommendations, where the model may inadvertently promote misleading information tai-\nlored to the user’s interests. The second concern revolves around data privacy, encompassing\nboth user proﬁles and long-term human interaction histories. In the case of large language\nmodels, these interaction histories are collected or shared, potentially leading to the large\n123\n42 Page 28 of 45\nWorld Wide Web (2024) 27:42\nmodels memorizing sensitive user data. Previous work [ 284] has demonstrated that large lan-\nguage models, especially GPT-2 [ 285], memorize and leak individual training examples. This\nemphasizes the need for strict user approval and careful handling of annotator data to miti-\ngate privacy risks. It is crucial to develop new techniques that prioritize privacy preservation\nduring the training process.\n11 Openchallenges\n11.1 Deployment difficulties\n11.1.1 Industrial challenges\nPersonalization services, particularly with recommender systems, are complex industrial\nproducts that face numerous challenges when implemented in real-world scenarios. We will\nnow summarize the key challenges as follows:\nScaling computational resources Existing large language models, such as BERT and\nGPT, demand signiﬁcant computational power for training and inference. This includes\nhigh memory usage and time consumption. Fine-tuning these models to align them with\npersonalization systems, which has shown promising results for improved personalization\nperformance, can be computationally intensive. Several efﬁcient ﬁnetuning strategies, e.g.,\noption tuning in M6-Rec [ 175], Lora [ 286], QLora [ 287], have been developed to address\nthis issue and pave the way for more efﬁcient tuning.\nSigniﬁcant response time Achieving efﬁcient response times is crucial for online serv-\ning and greatly impacts the personalized user experience. Response time includes both the\ninference phase of large language models and the concurrent user requests in large num-\nbers. The introduction of large language models can result in considerable inference time,\nposing a challenge for real-world deployment. One approach is to pre-compute the embed-\ndings of intermediate outputs from language models, storing and indexing them in a vector\ndatabase, particularly for methods that utilize large language models as textual encoders.\nOther approaches, such as distillation and quantization, aim to strike a balance between\nperformance and latency.\n11.1.2 Laborious data collection\nLarge language models are widely known to leverage extensive amounts of open-domain\nknowledge during their training and ﬁne-tuning processes. These knowledge sources include\nwell-known references such as Wikipedia, books, and various websites [ 3]. Similarly, when\napplied in recommender systems, these models often rely on representative open-domain\ndatasets such as MovieLens and Amazon Books. While this type of open-domain knowledge\ncontains a wealth of common-sense information, personalized tasks require access to more\ndomain-speciﬁc data that is not easily shareable. Additionally, the nature of user feedback\nin personalized tasks can be complex and sparse, often accompanied by noisy feedback.\nCollecting and ﬁltering this data, in contrast to acquiring common-sense knowledge, presents\nchallenges. It incurs higher labour costs and introduces additional training redundancy due\nto the need for extensive data processing and ﬁltering. Furthermore, designing appropriate\nprompts to instruct or ﬁne-tune large language models is crucial for aligning them with the\ndistribution of in-domain inputs in personalization tasks. By carefully tailoring the prompts,\n123\nPage 29 of 45 42\nWorld Wide Web (2024) 27:42\nresearchers and practitioners can guide the model to produce outputs that better cater to\npersonalized applications, thereby maximizing performance and effectiveness.\n11.2 Capacities of LLMs\n11.2.1 Long text modeling\nLarge language models have a limitation on the maximum number of input tokens they can\nhandle, typically constrained by the context window size, e.g., 4096 for ChatGPT. This poses\nchallenges when dealing with long user behavior sequences, which are common in mod-\nern recommender systems. Careful design is necessary to generate effective and appropriate\nprompt inputs within this limited length. In the case of conversations with multiple rounds,\naccumulating several rounds of dialogue can easily exceed the token limit of models. The\ncurrent approach in handling long conversations is to truncate the history, keeping only the\nmost recent tokens. However, this truncation discards valuable historical information, poten-\ntially harming the performance of models. To address these challenges, several techniques\ncan be employed. One approach is to prioritize and select the most relevant parts of the user\nbehavior sequence or conversation history to include in the prompt. This selection can be\nbased on various criteria such as recency, importance, or relevance to the task at hand. Another\ntechnique involves summarizing or compressing the lengthy input while preserving essen-\ntial information. This can be achieved through techniques like extractive summarization or\nrepresenting the long sequence in a condensed form. Moreover, architectural modiﬁcations,\nsuch as hierarchical or memory-augmented models, can be explored to better handle long\nsequences by incorporating mechanisms to store and retrieve relevant information efﬁciently.\nIn addition, collaborative modeling of long text data and recommendation tasks is an\nemerging and pressing challenge. In conventional personalization systems, item ID infor-\nmation along with other categorical information is commonly used for modeling feature\ninteractions and user preferences. With the rise of large language models, there would be a\ngrowing trend toward leveraging textual information more extensively. Textual data provides\nunique insights about items or users, making it valuable for modeling purposes. From the\nperspective of modeling, dealing with long text data requires more attention and complexity\ncompared to categorical data, not to mention the need to match the modeling of user interests.\nFrom the perspective of implementation, reforming the entire pipeline becomes necessary\nto accommodate the requirements of efﬁcient latency. There lie the technical challenges of\nincorporating long text data into recommendation models and serving them in real time.\n11.2.2 Interpretability and explainability\nWhile large language models provide good reasoning capabilities, they are notorious for the\nnature of the ’black box’, which is highly complex and non-linear in their enormous size and\nlayered architecture, making it challenging to comprehend the internal workings and under-\nstand the generation process of recommendations. Without a deep understanding of how the\nmodel operates, it becomes challenging to detect and address biases or ensure fair and ethical\nrecommendations. Once transparency about the internal mechanisms is lacking, users strug-\ngle to trust and accept the decisions made by the system. Users often desire understandable\nexplanations for recommended choices. Addressing the challenge of model interpretability\nand explainability requires research involving natural language processing, explainable AI,\nhuman-computer interaction, and recommendation systems. The development of techniques\n123\n42 Page 30 of 45\nWorld Wide Web (2024) 27:42\nthat unveil the inner workings of language models, facilitate the generation of meaningful\nand accurate interpretations, and enable robust evaluation methods is the main focus. By pro-\nviding transparent and interpretable recommendations, users can establish trust, understand\nthe reasoning behind the recommendations, and make informed decisions.\n11.3 Evaluation\n11.3.1 Tools and metrics\nConventional personalization systems typically rely on task-speciﬁc metrics such as ranking-\noriented metrics, NDCG, AUC, and Recall to evaluate model performance. However, with\nthe integration of large language models into recommender systems, the evaluation tools\nand metrics undergo signiﬁcant changes. Traditional metrics may not sufﬁciently capture\nthe performance of recommender systems powered by large language models, which intro-\nduce novel capabilities and generate recommendations in a different manner and require the\ndevelopment of new evaluation tools.\nOne crucial aspect of evaluation is considering user preferences in large language model-\npowered systems, which requires a user-centric approach. Metrics such as user satisfaction,\nengagement, and overall experience become essential considerations. For example, Liu’s\nwork [162] proposes a crowdsourcing task to assess the quality of generated explanations and\nreview summaries, providing a way to evaluate the effectiveness of the generated content.\nAdditionally, user satisfaction surveys and feedback questionnaires can serve as valuable\noptions.\nAnother perspective to consider is the health of the system, which involves evaluating\nnovelty and assessing factors like diversity, novelty, serendipity, and user retention rates.\nThese metrics help evaluate the freshness of recommendations and the long-term effects of\nlarge language models. Furthermore, it is crucial to assess the interpretability and fairness of\nrecommendations. The interpretability assessment focuses on measuring the clarity, under-\nstandability, and transparency of recommendations. Simultaneously, the fairness evaluation\naims to address potential biases in personalized results. By prioritizing fairness, we strive to\ncreate personalized experiences that are equitable and inclusive for all users. Both of these\nevaluations are essential to enhance the overall user experience and build conﬁdence in the\npersonalized recommendations delivered by the system.\n11.3.2 Trade-off between helpfulness, honesty, harmlessness\nWhen large language models are employed for personalization, some of their disadvantages\nwould be magniﬁed. Striving for a more honest and harmless system may come at the expense\nof system performance.\nFirst of all, the accuracy and factuality of the system must be ensured. Although large\nlanguage models can generate seemingly reasonable content, there is a risk of disseminating\nmisleading or inaccurate information. This becomes even more critical when incorporating\nuser feedback, as the model may mimic user behaviors in an attempt to appear honest.\nHowever, this imitation can result in biased guidance for users, offering no real beneﬁts.\nSecondly, in terms of harmlessness, concerns regarding privacy, discrimination, and ethics\narise. While large language models have the potential to provide highly personalized recom-\nmendations by leveraging user data, privacy, and data security become paramount. Unlike\nopen-domain datasets, the privacy of individual data used for training should be rigorously\n123\nPage 31 of 45 42\nWorld Wide Web (2024) 27:42\nprotected, with strict user permissions for sharing their personal information. For discrim-\nination, large language models may inevitably reﬂect biases inherent in the training data,\nleading to discriminatory recommendations. Considering the biased user and item distribu-\ntion, which is much more signiﬁcant in recommender systems with the long-tail effect, where\nbiased user and item distribution can lead to decisions that favor majority choices, resulting\nin discrimination against certain users. The ﬁnal concern revolves around ethical consid-\nerations. Harmful messages, if clicked by users unconsciously, can guide large language\nmodels toward generating similar harmful content. However, when assisting in personalized\ndecision-making, it is essential for large language models to have the capability to minimize\nexposure to harmful messages and guide users in a responsible manner. Approaches like\nconstructing a Constitutional AI [ 288], where critiques, revisions, and supervised Learning\nare adopted for better training models, may offer valuable insights.\nBy addressing these concerns, safeguarding privacy, mitigating discrimination, and adher-\ning to ethical guidelines, recommender systems can leverage the power of large language\nmodels while ensuring user trust, fairness, and responsible recommendations.\n12 Conclusion\nIn conclusion, the emergence of large language models represents a signiﬁcant breakthrough\nin the ﬁeld of artiﬁcial intelligence. Their enhanced abilities in understanding, language anal-\nysis, and common-sense reasoning have opened up new possibilities for personalization. In\nthis paper, we provide several perspectives on when large language models adapt to per-\nsonalization systems. We have observed a progression from utilizing low-level capabilities\nof large language models to enhance performance, to leveraging their potential in complex\ninteractions with external tools for end-to-end tasks. This evolution promises to revolutionize\nthe way personalized services are delivered. We also acknowledge the open challenges that\ncome with the integration of large language models into personalization systems.\nAuthor Contributions Jin Chen organized the main writing and wrote the main manuscript text. Zheng Liu\norganized the entire structure of the manuscript and wrote the introduction of large language models. Xu\nHuang wrote the Section 8: LLMs as Conversational Agent. Chenwang Wu wrote the Section 6: LLMs as\nExplainer. Qi Liu and Gangwei Jiang wrote the Section 5: LLMs as Content Interpreter. Y uanhao Pu, Y uxuan\nLei and Xiaolong Chen wrote Section 9: Tool-Learning and its Applications in Recommendation. Xingmei\nWang wrote the Section 7.2 Reasoning for Automated Selection. Kai zheng, Defu Lian, and Enhong Chen\nrevised the article over and over again. All authors reviewed the manuscript.\nFunding Open access funding provided by Hong Kong University of Science and Technology. This work was\nsupported by the National Natural Science Foundation of China (NSFC) No. 62022077.\nData Availability No datasets were generated or analysed during the current study.\nDeclarations\nCompeting of interest The authors declare no competing interests.\nEthical Approval This research does not involve human participants or pose potential harm to individuals.\nAs such, formal ethical approval was not required. However, we would like to emphasize our commitment to\nethical research practices and conﬁrm that the study adheres to the ethical guidelines and principles set forth\nin ACM Code of Ethics.\n123\n42 Page 32 of 45\nWorld Wide Web (2024) 27:42\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence,\nand indicate if changes were made. The images or other third party material in this article are included in the\narticle’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is\nnot included in the article’s Creative Commons licence and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.\nTo view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .\nReferences\n1. Zhao, W.X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y ., Min, Y ., Zhang, B., Zhang, J., Dong, Z., et al.:\nA survey of large language models. arXiv:2303.18223 (2023)\n2. Huang, J., Chang, K.C.-C.: Towards reasoning in large language models: a survey. arXiv:2212.10403\n(2022)\n3. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P ., Neelakantan, A., Shyam, P .,\nSastry, G., Askell, A., et al.: Language models are few-shot learners. Adv. Neural. Inf. Process. Syst. 33,\n1877–1901 (2020)\n4. Salemi, A., Mysore, S., Bendersky, M., Zamani, H.: Lamp: When large language models meet person-\nalization. arXiv:2304.11406 (2023)\n5. Wu, L., Zheng, Z., Qiu, Z., Wang, H., Gu, H., Shen, T., Qin, C., Zhu, C., Zhu, H., Liu, Q., et al.: A survey\non large language models for recommendation. arXiv:2305.19860 (2023)\n6. Lin, J., Dai, X., Xi, Y ., Liu, W., Chen, B., Li, X., Zhu, C., Guo, H., Y u, Y ., Tang, R., et al.: How can\nrecommender systems beneﬁt from large language models: a survey. arXiv:2306.05817 (2023)\n7. Fan, W., Zhao, Z., Li, J., Liu, Y ., Mei, X., Wang, Y ., Tang, J., Li, Q.: Recommender systems in the era\nof large language models (llms). arXiv:2307.02046 (2023)\n8. Resnick, P ., Iacovou, N., Suchak, M., Bergstrom, P ., Riedl, J.: Grouplens: an open architecture for\ncollaborative ﬁltering of netnews. In: Proceedings of the 1994 ACM Conference on Computer Supported\nCooperative Work, pp. 175–186 (1994)\n9. Pan, R., Zhou, Y ., Cao, B., Liu, N.N., Lukose, R., Scholz, M., Yang, Q.: One-class collaborative ﬁltering.\nIn: 2008 Eighth IEEE International Conference on Data Mining, pp. 502–511 (2008). IEEE\n10. Koren, Y ., Bell, R., V olinsky, C.: Matrix factorization techniques for recommender systems. Computer\n42(8), 30–37 (2009)\n11. Wang, J., De Vries, A.P ., Reinders, M.J.: Unifying user-based and item-based collaborative ﬁltering\napproaches by similarity fusion. In: Proceedings of the 29th Annual International ACM SIGIR Confer-\nence on Research and Development in Information Retrieval, pp. 501–508 (2006)\n12. Pazzani, M.J., Billsus, D.: Content-based recommendation systems. In: The adaptive Web: Methods and\nStrategies of Web Personalization, pp. 325–341. Springer (2007)\n13. Wang, C., Blei, D.M.: Collaborative topic modeling for recommending scientiﬁc articles. In: Proceedings\nof the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.\n448–456 (2011)\n14. Zhang, F., Y uan, N.J., Lian, D., Xie, X., Ma, W.-Y .: Collaborative knowledge base embedding for recom-\nmender systems. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, pp. 353–362 (2016)\n15. Liu, H., Wu, F., Wang, W., Wang, X., Jiao, P ., Wu, C., Xie, X.: Nrpa: neural recommendation with\npersonalized attention. In: Proceedings of the 42nd International ACM SIGIR Conference on Research\nand Development in Information Retrieval, pp. 1233–1236 (2019)\n16. Wang, H., Wang, N., Yeung, D.-Y .: Collaborative deep learning for recommender systems. In: Proceed-\nings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\npp. 1235–1244 (2015)\n17. Zhou, G., Zhu, X., Song, C., Fan, Y ., Zhu, H., Ma, X., Yan, Y ., Jin, J., Li, H., Gai, K.: Deep interest\nnetwork for click-through rate prediction. In: Proceedings of the 24th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, pp. 1059–1068 (2018)\n18. Zhou, G., Mou, N., Fan, Y ., Pi, Q., Bian, W., Zhou, C., Zhu, X., Gai, K.: Deep interest evolution network\nfor click-through rate prediction. In: Proceedings of the AAAI Conference on Artiﬁcial Intelligence,\nvol. 33, pp. 5941–5948 (2019)\n123\nPage 33 of 45 42\nWorld Wide Web (2024) 27:42\n19. Wang, X., He, X., Wang, M., Feng, F., Chua, T.-S.: Neural graph collaborative ﬁltering. In: Proceedings of\nthe 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval,\npp. 165–174 (2019)\n20. Kang, W.-C., McAuley, J.: Self-attentive sequential recommendation. In: 2018 IEEE International Con-\nference on Data Mining (ICDM), pp. 197–206 (2018). IEEE\n21. Hidasi, B., Karatzoglou, A., Baltrunas, L., Tikk, D.: Session-based recommendations with recurrent\nneural networks. arXiv:1511.06939 (2015)\n22. Sun, F., Liu, J., Wu, J., Pei, C., Lin, X., Ou, W., Jiang, P .: Bert4rec: Sequential recommendation with\nbidirectional encoder representations from transformer. In: Proceedings of the 28th ACM International\nConference on Information and Knowledge Management, pp. 1441–1450 (2019)\n23. Paschou, M., Sakkopoulos, E.: Personalized assistant apps in healthcare: a systematic review. In: 2019\n10th International Conference on Information, Intelligence, Systems and Applications (IISA), pp. 1–8\n(2019). IEEE\n24. Sun, Y ., Zhang, Y .: Conversational recommender system. In: The 41st International Acm Sigir Confer-\nence on Research & Development in Information Retrieval, pp. 235–244 (2018)\n25. Jannach, D., Manzoor, A., Cai, W., Chen, L.: A survey on conversational recommender systems. ACM\nComputing Surveys (CSUR) 54(5), 1–36 (2021)\n26. Bengio, Y ., Ducharme, R., Vincent, P .: A neural probabilistic language model. Adv. Neural. Inf. Process.\nSyst. 13 (2000)\n27. Mikolov, T., Karaﬁát, M., Burget, L., Cernock` y, J., Khudanpur, S.: Recurrent neural network based\nlanguage model. In: Interspeech, vol. 2, pp. 1045–1048 (2010). Makuhari\n28. V aswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I.:\nAttention is all you need. Adv. Neural. Inf. Process. Syst. 30 (2017)\n29. Kenton, J.D.M.-W.C., Toutanova, L.K.: Bert: Pre-training of deep bidirectional transformers for language\nunderstanding. In: Proceedings of NAACL-HLT, pp. 4171–4186 (2019)\n30. Shanahan, M.: Talking about large language models. Commun. ACM 67(2), 68–79 (2024)\n31. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P ., Chung, H.W.,\nSutton, C., Gehrmann, S., et al.: Palm: scaling language modeling with pathways. J. Mach. Learn. Res.\n24(240), 1–113 (2023)\n32. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N.,\nHambro, E., Azhar, F., et al.: Llama: open and efﬁcient foundation language models. arXiv:2302.13971\n(2023)\n33. Le Scao, T., Wang, T., Hesslow, D., Bekman, S., Bari, M.S., Biderman, S., Elsahar, H., Muennighoff,\nN., Phang, J., Press, O., et al.: What language model to train if you have one million gpu hours?. In:\nFindings of the Association for Computational Linguistics: EMNLP 2022, pp. 765–782 (2022)\n34. Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child, R., Gray, S., Radford, A., Wu,\nJ., Amodei, D.: Scaling laws for neural language models. arXiv:2001.08361 (2020)\n35. Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D.d.L.,\nHendricks, L.A., Welbl, J., Clark, A., et al.: Training compute-optimal large language models.\narXiv:2203.15556 (2022)\n36. Sanh, V ., Webson, A., Raffel, C., Bach, S., Sutawika, L., Alyafeai, Z., Chafﬁn, A., Stiegler, A., Raja,\nA., Dey, M., et al.: Multitask prompted training enables zero-shot task generalization. In: International\nConference on Learning Representations (2021)\n37. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P ., Zhang, C., Agarwal, S., Slama,\nK., Ray, A., et al.: Training language models to follow instructions with human feedback. Adv. Neural.\nInf. Process. Syst. 35, 27730–27744 (2022)\n38. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., Zhou, D.: Chain of thought prompting\nelicits reasoning in large language models. arXiv:2201.11903 (2022)\n39. Fu, Y ., Peng, H., Khot, T.: How does gpt obtain its ability? tracing emergent abilities of language models\nto their sources. Yao Fu’s Notion (2022)\n40. Zhang, Y ., Chen, X., Ai, Q., Yang, L., Croft, W.B.: Towards conversational search and recommendation:\nsystem ask, user respond. In: Proceedings of the 27th ACM International Conference on Information\nand Knowledge Management, pp. 177–186 (2018)\n41. Wang, H., Zhang, F., Xie, X., Guo, M.: Dkn: deep knowledge-aware network for news recommendation.\nIn: Proceedings of the 2018 World Wide Web Conference, pp. 1835–1844 (2018)\n42. Huang, J., Zhao, W.X., Dou, H., Wen, J.-R., Chang, E.Y .: Improving sequential recommendation with\nknowledge-enhanced memory networks. In: The 41st international ACM SIGIR Conference on Research\n& Development in Information Retrieval, pp. 505–514 (2018)\n123\n42 Page 34 of 45\nWorld Wide Web (2024) 27:42\n43. Wang, H., Zhang, F., Hou, M., Xie, X., Guo, M., Liu, Q.: Shine: signed heterogeneous information\nnetwork embedding for sentiment link prediction. In: Proceedings of the Eleventh ACM International\nConference on Web Search and Data Mining, pp. 592–600 (2018)\n44. Y u, X., Ren, X., Gu, Q., Sun, Y ., Han, J.: Collaborative ﬁltering with entity similarity regularization in\nheterogeneous information networks. IJCAI HINA 27 (2013)\n45. Shi, C., Zhang, Z., Luo, P ., Y u, P .S., Y ue, Y ., Wu, B.: Semantic path based personalized recommendation\non weighted heterogeneous information networks. In: Proceedings of the 24th ACM International on\nConference on Information and Knowledge Management, pp. 453–462 (2015)\n46. Ma, W., Zhang, M., Cao, Y ., Jin, W., Wang, C., Liu, Y ., Ma, S., Ren, X.: Jointly learning explainable\nrules for recommendation with knowledge graph. In: The World Wide Web Conference, pp. 1210–1221\n(2019)\n47. Huang, X., Fang, Q., Qian, S., Sang, J., Li, Y ., Xu, C.: Explainable interaction-driven user modeling\nover knowledge graph for sequential recommendation. In: Proceedings of the 27th ACM International\nConference on Multimedia, pp. 548–556 (2019)\n48. Wang, H., Zhang, F., Wang, J., Zhao, M., Li, W., Xie, X., Guo, M.: Ripplenet: propagating user preferences\non the knowledge graph for recommender systems. In: Proceedings of the 27th ACM International\nConference on Information and Knowledge Management, pp. 417–426 (2018)\n49. Wang, H., Zhao, M., Xie, X., Li, W., Guo, M.: Knowledge graph convolutional networks for recommender\nsystems. In: The World Wide Web Conference, pp. 3307–3313 (2019)\n50. Wang, X., He, X., Cao, Y ., Liu, M., Chua, T.-S.: Kgat: knowledge graph attention network for recommen-\ndation. In: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery\n& Data Mining, pp. 950–958 (2019)\n51. Tang, X., Wang, T., Yang, H., Song, H.: Akupm: attention-enhanced knowledge-aware user preference\nmodel for recommendation. In: Proceedings of the 25th ACM SIGKDD International Conference on\nKnowledge Discovery & Data Mining, pp. 1891–1899 (2019)\n52. Zhao, J., Zhou, Z., Guan, Z., Zhao, W., Ning, W., Qiu, G., He, X.: Intentgc: a scalable graph convolution\nframework fusing heterogeneous information for recommendation. In: Proceedings of the 25th ACM\nSIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2347–2357 (2019)\n53. Petroni, F., Rocktäschel, T., Lewis, P ., Bakhtin, A., Wu, Y ., Miller, A.H., Riedel, S.: Language models\nas knowledge bases?. arXiv:1909.01066 (2019)\n54. Roberts, A., Raffel, C., Shazeer, N.: How much knowledge can you pack into the parameters of a language\nmodel?. arXiv:2002.08910 (2020)\n55. Petroni, F., Lewis, P ., Piktus, A., Rocktäschel, T., Wu, Y ., Miller, A.H., Riedel, S.: How context affects\nlanguage models’ factual predictions. In: Automated Knowledge Base Construction\n56. Jiang, Z., Xu, F.F., Araki, J., Neubig, G.: How can we know what language models know? Trans. Assoc.\nComput. Linguist 8, 423–438 (2020)\n57. Wang, C., Liu, X., Song, D.: Language models are open knowledge graphs. arXiv:2010.11967 (2020)\n58. Poerner, N., Waltinger, U., Schütze, H.: E-bert: efﬁcient-yet-effective entity embeddings for bert. In:\nFindings of the Association for Computational Linguistics: EMNLP 2020, pp. 803–818 (2020)\n59. Heinzerling, B., Inui, K.: Language models as knowledge bases: On entity representations, storage\ncapacity, and paraphrased queries. In: Proceedings of the 16th Conference of the European Chapter of\nthe Association for Computational Linguistics: Main V olume, pp. 1772–1791 (2021)\n60. Wang, C., Liu, P ., Zhang, Y .: Can generative pre-trained language models serve as knowledge bases\nfor closed-book qa?. In: Proceedings of the 59th Annual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Conference on Natural Language Processing (vol. 1: long\npapers), pp. 3241–3251 (2021)\n61. Guu, K., Lee, K., Tung, Z., Pasupat, P ., Chang, M.: Retrieval augmented language model pre-training.\nIn: International Conference on Machine Learning, pp. 3929–3938 (2020). PMLR\n62. Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., Yakhnenko, O.: Translating embeddings for\nmodeling multi-relational data. Adv. Neural. Inf. Process. Syst. 26 (2013)\n63. Zhu, Y ., Wang, X., Chen, J., Qiao, S., Ou, Y ., Yao, Y ., Deng, S., Chen, H., Zhang, N.: Llms for knowledge\ngraph construction and reasoning: recent capabilities and future opportunities. arXiv:2305.13168 (2023)\n64. Zhang, Z., Liu, X., Zhang, Y ., Su, Q., Sun, X., He, B.: Pretrain-kge: learning knowledge representation\nfrom pretrained language models. In: Findings of the Association for Computational Linguistics: EMNLP\n2020, pp. 259–266 (2020)\n65. Kumar, A., Pandey, A., Gadia, R., Mishra, M.: Building knowledge graph using pre-trained language\nmodel for learning entity-aware relationships. In: 2020 IEEE International Conference on Computing,\nPower and Communication Technologies (GUCON), pp. 310–315 (2020). IEEE\n123\nPage 35 of 45 42\nWorld Wide Web (2024) 27:42\n66. Kim, B., Hong, T., Ko, Y ., Seo, J.: Multi-task learning for knowledge graph completion with pre-trained\nlanguage models. In: Proceedings of the 28th International Conference on Computational Linguistics,\npp. 1737–1743 (2020)\n67. Choi, B., Jang, D., Ko, Y .: Mem-kgc: masked entity model for knowledge graph completion with pre-\ntrained language model. IEEE Access 9, 132025–132032 (2021)\n68. Wang, B., Shen, T., Long, G., Zhou, T., Wang, Y ., Chang, Y .: Structure-augmented text representation\nlearning for efﬁcient knowledge graph completion. In: Proceedings of the Web Conference 2021, pp.\n1737–1748 (2021)\n69. Xie, X., Zhang, N., Li, Z., Deng, S., Chen, H., Xiong, F., Chen, M., Chen, H.: From discrimination to\ngeneration: knowledge graph completion with generative transformer. In: Companion Proceedings of\nthe Web Conference 2022, pp. 162–165 (2022)\n70. Jiang, P ., Agarwal, S., Jin, B., Wang, X., Sun, J., Han, J.: Text-augmented open knowledge graph\ncompletion via pre-trained language models. arXiv:2305.15597 (2023)\n71. Yan, H., Gui, T., Dai, J., Guo, Q., Zhang, Z., Qiu, X.: A uniﬁed generative framework for various ner\nsubtasks. In: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural Language Processing (vol. 1: long papers), pp.\n5808–5822 (2021)\n72. Li, B., Yin, W., Chen, M.: Ultra-ﬁne entity typing with indirect supervision from natural language\ninference. Trans. Assoc. Comput. Linguist. 10, 607–622 (2022)\n73. Kirstain, Y ., Ram, O., Levy, O.: Coreference resolution without span representations. In: Proceedings\nof the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\nJoint Conference on Natural Language Processing (vol. 2: short papers), pp. 14–19 (2021)\n74. Cattan, A., Eirew, A., Stanovsky, G., Joshi, M., Dagan, I.: Cross-document coreference resolution over\npredicted mentions. In: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,\npp. 5100–5107 (2021)\n75. Lyu, S., Chen, H.: Relation classiﬁcation with entity type restriction. In: Findings of the Association for\nComputational Linguistics: ACL-IJCNLP 2021, pp. 390–395 (2021)\n76. Wang, H., Focke, C., Sylvester, R., Mishra, N., Wang, W.: Fine-tune bert for docred with two-step\nprocess. arXiv:1909.11898 (2019)\n77. Han, J., Collier, N., Buntine, W., Shareghi, E.: Pive: prompting with iterative veriﬁcation improving\ngraph-based generative capability of llms. arXiv:2305.12392 (2023)\n78. Trajanoska, M., Stojanov, R., Trajanov, D.: Enhancing knowledge graph construction using large lan-\nguage models. arXiv:2305.04676 (2023)\n79. West, P ., Bhagavatula, C., Hessel, J., Hwang, J., Jiang, L., Le Bras, R., Lu, X., Welleck, S., Choi, Y .: Sym-\nbolic knowledge distillation: from general language models to commonsense models. In: Proceedings of\nthe 2022 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, pp. 4602–4625 (2022)\n80. Xi, Y ., Liu, W., Lin, J., Zhu, J., Chen, B., Tang, R., Zhang, W., Zhang, R., Y u, Y .: Towards open-world\nrecommendation with knowledge augmentation from large language models. arXiv:2306.10933 (2023)\n81. Wei, W., Ren, X., Tang, J., Wang, Q., Su, L., Cheng, S., Wang, J., Yin, D., Huang, C.: Llmrec: large\nlanguage models with graph augmentation for recommendation. In: Proceedings of the 17th ACM\nInternational Conference on Web Search and Data Mining, pp. 806–815 (2024)\n82. Zhao, Q., Qian, H., Liu, Z., Zhang, G.-D., Gu, L.: Breaking the barrier: utilizing large language models for\nindustrial recommendation systems through an inferential knowledge graph. arXiv:2402.13750 (2024)\n83. Razniewski, S., Yates, A., Kassner, N., Weikum, G.: Language models as or for knowledge bases.\narXiv:2110.04888 (2021)\n84. Y u, J., Wang, X., Tu, S., Cao, S., Zhang-Li, D., Lv, X., Peng, H., Yao, Z., Zhang, X., Li, H., et al.: Kola:\nCarefully benchmarking world knowledge of large language models. arXiv:2306.09296 (2023)\n85. Ye, D., Lin, Y ., Li, P ., Sun, M.: Packed levitated marker for entity and relation extraction. In: Proceedings\nof the 60th Annual Meeting of the Association for Computational Linguistics (vol. 1: long papers), pp.\n4904–4917 (2022)\n86. Lang, K.: Newsweeder: Learning to ﬁlter netnews. In: Machine Learning Proceedings 1995, pp. 331–339.\nElsevier (1995)\n87. Wang, H., Shi, X., Yeung, D.-Y .: Collaborative recurrent autoencoder: recommend while learning to ﬁll\nin the blanks. Adv. Neural. Inf. Process. Syst. 29 (2016)\n88. Dong, X., Y u, L., Wu, Z., Sun, Y ., Y uan, L., Zhang, F.: A hybrid collaborative ﬁltering model with deep\nstructure for recommender systems. In: Proceedings of the AAAI Conference on Artiﬁcial Intelligence,\nvol. 31 (2017)\n123\n42 Page 36 of 45\nWorld Wide Web (2024) 27:42\n89. Li, X., She, J.: Collaborative variational autoencoder for recommender systems. In: Proceedings of the\n23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 305–314\n(2017)\n90. Wu, C., Wu, F., Huang, Y ., Xie, X.: Personalized news recommendation: methods and challenges. ACM\nTrans. Inf. Syst. 41(1), 24–12450 (2023)\n91. Le, Q.V ., Mikolov, T.: Distributed representations of sentences and documents. In: ICML. JMLR Work-\nshop and Conference Proceedings, vol. 32, pp. 1188–1196. JMLR.org (2014)\n92. Song, Y ., Elkahky, A.M., He, X.: Multi-rate deep learning for temporal recommendation. In: SIGIR, pp.\n909–912. ACM (2016)\n93. Kumar, V ., Khattar, D., Gupta, S., Gupta, M., V arma, V .: Deep neural architecture for news recommen-\ndation. In: CLEF (Working Notes). CEUR Workshop Proceedings, vol. 1866. CEUR-WS.org (2017)\n94. Okura, S., Tagami, Y ., Ono, S., Tajima, A.: Embedding-based news recommendation for millions of\nusers. In: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery\nand Data Mining, pp. 1933–1942 (2017)\n95. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Efﬁcient estimation of word representations in vector\nspace. In: ICLR (Workshop Poster) (2013)\n96. Wu, C., Wu, F., An, M., Huang, J., Huang, Y ., Xie, X.: NPA: neural news recommendation with person-\nalized attention. In: KDD, pp. 2576–2584. ACM (2019)\n97. An, M., Wu, F., Wu, C., Zhang, K., Liu, Z., Xie, X.: Neural news recommendation with long- and\nshort-term user representations. In: ACL (1), pp. 336–345. Association for Computational Linguistics\n(2019)\n98. Wu, C., Wu, F., Ge, S., Qi, T., Huang, Y ., Xie, X.: Neural news recommendation with multi-head self-\nattention. In: EMNLP/IJCNLP (1), pp. 6388–6393. Association for Computational Linguistics (2019)\n99. Wu, C., Wu, F., Qi, T., Huang, Y .: User modeling with click preference and reading satisfaction for news\nrecommendation. In: IJCAI, pp. 3023–3029. ijcai.org (2020)\n100. Khattar, D., Kumar, V ., V arma, V ., Gupta, M.: Weave&rec: a word embedding based 3-d convolutional\nnetwork for news recommendation. In: CIKM, pp. 1855–1858. ACM (2018)\n101. Zhu, Q., Zhou, X., Song, Z., Tan, J., Guo, L.: DAN: deep attention neural network for news recommen-\ndation. In: AAAI, pp. 5973–5980. rAAAI Press (2019)\n102. Qiu, Z., Wu, X., Gao, J., Fan, W.: U-bert: Pre-training user representations for improved recommendation.\nIn: Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 35, pp. 4320–4327 (2021)\n103. Zhang, Q., Li, J., Jia, Q., Wang, C., Zhu, J., Wang, Z., He, X.: Unbert: user-news matching bert for news\nrecommendation. In: IJCAI, pp. 3356–3362 (2021)\n104. Wu, C., Wu, F., Qi, T., Huang, Y .: Empowering news recommendation with pre-trained language models.\nIn: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval, pp. 1652–1656 (2021)\n105. Liu, Q., Zhu, J., Dai, Q., Wu, X.: Boosting deep ctr prediction with a plug-and-play pre-trainer for news\nrecommendation. In: Proceedings of the 29th International Conference on Computational Linguistics,\npp. 2823–2833 (2022)\n106. Wu, C., Wu, F., Qi, T., Zhang, C., Huang, Y ., Xu, T.: Mm-rec: visiolinguistic model empowered mul-\ntimodal news recommendation. In: Proceedings of the 45th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, pp. 2560–2564 (2022)\n107. Y u, Y ., Wu, F., Wu, C., Yi, J., Liu, Q.: Tiny-newsrec: effective and efﬁcient plm-based news recommen-\ndation. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,\npp. 5478–5489 (2022)\n108. Zou, L., Zhang, S., Cai, H., Ma, D., Cheng, S., Wang, S., Shi, D., Cheng, Z., Yin, D.: Pre-trained\nlanguage model based ranking in baidu search. In: Proceedings of the 27th ACM SIGKDD Conference\non Knowledge Discovery & Data Mining, pp. 4014–4022 (2021)\n109. Liu, Y ., Lu, W., Cheng, S., Shi, D., Wang, S., Cheng, Z., Yin, D.: Pre-trained language model for web-\nscale retrieval in baidu search. In: Proceedings of the 27th ACM SIGKDD Conference on Knowledge\nDiscovery & Data Mining, pp. 3365–3375 (2021)\n110. Muhamed, A., Keivanloo, I., Perera, S., Mracek, J., Xu, Y ., Cui, Q., Rajagopalan, S., Zeng, B., Chilimbi,\nT.: Ctr-bert: cost-effective knowledge distillation for billion-parameter teacher models. In: NeurIPS\nEfﬁcient Natural Language and Speech Processing Workshop (2021)\n111. He, J., Xu, B., Yang, Z., Han, D., Yang, C., Lo, D.: Ptm4tag: sharpening tag recommendation of stack\noverﬂow posts with pre-trained models. In: Proceedings of the 30th IEEE/ACM International Conference\non Program Comprehension, pp. 1–11 (2022)\n112. Zhang, X., Malkov, Y ., Florez, O., Park, S., McWilliams, B., Han, J., El-Kishky, A.: Twhin-bert: a\nsocially-enriched pre-trained language model for multilingual tweet representations. arXiv:2209.07562\n(2022)\n123\nPage 37 of 45 42\nWorld Wide Web (2024) 27:42\n113. Rahmani, S., Naghshzan, A., Guerrouj, L.: Improving code example recommendations on informal\ndocumentation using bert and query-aware lsh: a comparative study. arXiv:2305.03017 (2023)\n114. Ding, H., Ma, Y ., Deoras, A., Wang, Y ., Wang, H.: Zero-shot recommender systems. arXiv:2105.08318\n(2021)\n115. Hou, Y ., Mu, S., Zhao, W.X., Li, Y ., Ding, B., Wen, J.-R.: Towards universal sequence representation\nlearning for recommender systems. In: Proceedings of the 28th ACM SIGKDD Conference on Knowl-\nedge Discovery and Data Mining, pp. 585–593 (2022)\n116. Hou, Y ., He, Z., McAuley, J., Zhao, W.X.: Learning vector-quantized item representation for transferable\nsequential recommenders. In: Proceedings of the ACM Web Conference 2023, pp. 1162–1171 (2023)\n117. Y uan, Z., Y uan, F., Song, Y ., Li, Y ., Fu, J., Yang, F., Pan, Y ., Ni, Y .: Where to go next for recommender\nsystems? id-vs. modality-based recommender models revisited. arXiv:2303.13835 (2023)\n118. Fu, J., Y uan, F., Song, Y ., Y uan, Z., Cheng, M., Cheng, S., Zhang, J., Wang, J., Pan, Y .: Exploring\nadapter-based transfer learning for recommender systems: empirical studies and practical insights.\narXiv:2305.15036 (2023)\n119. Bao, K., Zhang, J., Zhang, Y ., Wang, W., Feng, F., He, X.: Tallrec: an effective and efﬁcient tuning\nframework to align large language model with recommendation. arXiv:2305.00447 (2023)\n120. Kang, W.-C., Ni, J., Mehta, N., Sathiamoorthy, M., Hong, L., Chi, E., Cheng, D.Z.: Do llms understand\nuser preferences?. evaluating llms on user rating prediction. arXiv:2305.06474 (2023)\n121. Chen, Z.: Palr: Personalization aware llms for recommendation. arXiv:2305.07622 (2023)\n122. Zhang, J., Xie, R., Hou, Y ., Zhao, W.X., Lin, L., Wen, J.-R.: Recommendation as instruction following:\na large language model empowered recommendation approach. arXiv:2305.07001 (2023)\n123. Li, R., Deng, W., Cheng, Y ., Y uan, Z., Zhang, J., Y uan, F.: Exploring the upper limits of text-based\ncollaborative ﬁltering using large language models: discoveries and insights. arXiv:2305.11700 (2023)\n124. Wang, X., Chen, Y ., Yang, J., Wu, L., Wu, Z., Xie, X.: A reinforcement learning framework for explainable\nrecommendation. In: 2018 IEEE International Conference on Data Mining (ICDM), pp. 587–596 (2018).\nIEEE\n125. Gao, J., Wang, X., Wang, Y ., Xie, X.: Explainable recommendation through attentive multi-view learning.\nIn: Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 33, pp. 3622–3629 (2019)\n126. Lee, S., Wang, X., Han, S., Yi, X., Xie, X., Cha, M.: Self-explaining deep models with logic rule\nreasoning. Adv. Neural. Inf. Process. Syst. (2022)\n127. Nye, M., Andreassen, A.J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz,\nA., Bosma, M., Luan, D., et al.: Show your work: scratchpads for intermediate computation with language\nmodels. arXiv:2112.00114 (2021)\n128. Lampinen, A.K., Dasgupta, I., Chan, S.C., Matthewson, K., Tessler, M.H., Creswell, A., McClelland,\nJ.L., Wang, J.X., Hill, F.: Can language models learn from explanations in context?. arXiv:2204.02329\n(2022)\n129. Zelikman, E., Wu, Y ., Mu, J., Goodman, N.: Star: bootstrapping reasoning with reasoning. Adv. Neural.\nInf. Process. Syst. 35, 15476–15488 (2022)\n130. Zhang, Y ., Chen, X., et al.: Explainable recommendation: a survey and new perspectives. Found. Trends®\nin Inf. Retr. 14(1), 1–101 (2020)\n131. Schafer, J.B., Konstan, J., Riedl, J.: Recommender systems in e-commerce. In: Proceedings of the 1st\nACM Conference on Electronic Commerce, pp. 158–166 (1999)\n132. Linden, G., Smith, B., Y ork, J.: Amazon. com recommendations: item-to-item collaborative ﬁltering.\nIEEE Internet Comput. 7(1), 76–80 (2003)\n133. Gomez-Uribe, C.A., Hunt, N.: The netﬂix recommender system: algorithms, business value, and inno-\nvation. ACM Trans. Manage. Inf. Syst. (TMIS) 6(4), 1–19 (2015)\n134. Sinha, R., Swearingen, K.: The role of transparency in recommender systems. In: CHI’02 Extended\nAbstracts on Human Factors in Computing Systems, pp. 830–831 (2002)\n135. Xian, Y ., Zhao, T., Li, J., Chan, J., Kan, A., Ma, J., Dong, X.L., Faloutsos, C., Karypis, G., Muthukrishnan,\nS., et al.: Ex3: explainable attribute-aware item-set recommendations. In: Proceedings of the 15th ACM\nConference on Recommender Systems, pp. 484–494 (2021)\n136. Wang, X., Li, Q., Y u, D., Xu, G.: Reinforced path reasoning for counterfactual explainable recommen-\ndation. arXiv:2207.06674 (2022)\n137. V erma, S., Beniwal, A., Sadagopan, N., Seshadri, A.: Recxplainer: post-hoc attribute-based explanations\nfor recommender systems. arXiv:2211.14935 (2022)\n138. Zhang, W., Yan, J., Wang, Z., Wang, J.: Neuro-symbolic interpretable collaborative ﬁltering for attribute-\nbased recommendation. In: Proceedings of the ACM Web Conference 2022, pp. 3229–3238 (2022)\n139. Li, P ., Wang, Z., Ren, Z., Bing, L., Lam, W.: Neural rating regression with abstractive tips generation for\nrecommendation. In: Proceedings of the 40th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval, pp. 345–354 (2017)\n123\n42 Page 38 of 45\nWorld Wide Web (2024) 27:42\n140. Dong, L., Huang, S., Wei, F., Lapata, M., Zhou, M., Xu, K.: Learning to generate product reviews\nfrom attributes. In: Proceedings of the 15th Conference of the European Chapter of the Association for\nComputational Linguistics: volume 1, long papers, pp. 623–632 (2017)\n141. Li, L., Zhang, Y ., Chen, L.: Generate neural template explanations for recommendation. In: Proceedings\nof the 29th ACM International Conference on Information & Knowledge Management, pp. 755–764\n(2020)\n142. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8), 1735–1780 (1997)\n143. Cho, K., V an Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y .: Learn-\ning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv:1406.1078\n(2014)\n144. Li, L., Zhang, Y ., Chen, L.: Personalized transformer for explainable recommendation. In: Proceedings\nof the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\nJoint Conference on Natural Language Processing (vol. 1: Long papers) (2021)\n145. Zhan, H., Li, L., Li, S., Liu, W., Gupta, M., Kot, A.C.: Towards explainable recommendation via bert-\nguided explanation generator. In: ICASSP 2023-2023 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP), pp. 1–5 (2023). IEEE\n146. Ni, J., Li, J., McAuley, J.: Justifying recommendations using distantly-labeled reviews and ﬁne-grained\naspects. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp.\n188–197 (2019)\n147. Liu, Z., Ma, Y ., Schubert, M., Ouyang, Y ., Rong, W., Xiong, Z.: Multimodal contrastive transformer for\nexplainable recommendation. IEEE Transactions on Computational Social Systems (2023)\n148. Qu, Y ., Nobuhara, H.: Explanation generated for sequential recommendation based on transformer\nmodel. In: 2022 Joint 12th International Conference on Soft Computing and Intelligent Systems and\n23rd International Symposium on Advanced Intelligent Systems (SCIS&ISIS), pp. 1–6 (2022). IEEE\n149. Bai, P ., Xia, Y ., Xia, Y .: Fusing knowledge and aspect sentiment for explainable recommendation. IEEE\nAccess 8, 137150–137160 (2020)\n150. Wang, L., Zhang, S., Wang, Y ., Lim, E.-P ., Wang, Y .: Llm4vis: explainable visualization recommendation\nusing chatgpt. arXiv:2310.07652 (2023)\n151. Lei, Y ., Lian, J., Yao, J., Huang, X., Lian, D., Xie, X.: Recexplainer: aligning large language models for\nrecommendation model interpretability. arXiv:2311.10947 (2023)\n152. Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., Arx, S., Bernstein, M.S., Bohg, J.,\nBosselut, A., Brunskill, E., et al.: On the opportunities and risks of foundation models. arXiv:2108.07258\n(2021)\n153. Li, L., Zhang, Y ., Chen, L.: Personalized prompt learning for explainable recommendation. ACM Trans.\nInf. Syst. 41(4), 1–26 (2023)\n154. Bills, S., Cammarata, N., Mossing, D., Tillman, H., Gao, L., Goh, G., Sutskever, I., Leike, J., Wu, J.,\nSaunders, W.: Language models can explain neurons in language models (2023)\n155. Wu, Z., Geiger, A., Potts, C., Goodman, N.D.: Interpretability at scale: identifying causal mechanisms\nin alpaca. arXiv:2305.08809 (2023)\n156. Li, Y ., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., Chen, W.: Making large language models better\nreasoners with step-aware veriﬁer (2023)\n157. Turpin, M., Michael, J., Perez, E., Bowman, S.R.: Language models don’t always say what they think:\nunfaithful explanations in chain-of-thought prompting. arXiv:2305.04388 (2023)\n158. Li, S., Liu, H., Dong, T., Zhao, B.Z.H., Xue, M., Zhu, H., Lu, J.: Hidden backdoors in human-centric\nlanguage models. In: Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communi-\ncations Security, pp. 3123–3140 (2021)\n159. Wang, J., Hu, X., Hou, W., Chen, H., Zheng, R., Wang, Y ., Yang, L., Huang, H., Ye, W., Geng, X., et al.: On\nthe robustness of chatgpt: an adversarial and out-of-distribution perspective. arXiv:2302.12095 (2023)\n160. Han, R., Peng, T., Yang, C., Wang, B., Liu, L., Wan, X.: Is information extraction solved by chatgpt? an\nanalysis of performance, evaluation criteria, robustness and errors. arXiv:2305.14450 (2023)\n161. Wei, J., Tay, Y ., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Y ogatama, D., Bosma, M., Zhou,\nD., Metzler, D., et al.: Emergent abilities of large language models. arXiv:2206.07682 (2022)\n162. Liu, J., Liu, C., Lv, R., Zhou, K., Zhang, Y .: Is chatgpt a good recommender? a preliminary study.\narXiv:2304.10149 (2023)\n163. Dai, S., Shao, N., Zhao, H., Y u, W., Si, Z., Xu, C., Sun, Z., Zhang, X., Xu, J.: Uncovering chatgpt’s\ncapabilities in recommender systems. arXiv:2305.02182 (2023)\n164. Wang, L., Lim, E.-P .: Zero-shot next-item recommendation using large pretrained language models.\narXiv:2304.03153 (2023)\n123\nPage 39 of 45 42\nWorld Wide Web (2024) 27:42\n165. Hou, Y ., Zhang, J., Lin, Z., Lu, H., Xie, R., McAuley, J., Zhao, W.X.: Large language models are zero-shot\nrankers for recommender systems. arXiv:2305.08845 (2023)\n166. Li, X., Zhang, Y ., Malthouse, E.C.: A preliminary study of chatgpt on news recommendation: personal-\nization, provider fairness, fake news. arXiv:2306.10702 (2023)\n167. Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., Sun, X., Xu, J., Sui, Z.: A survey for in-context\nlearning. arXiv:2301.00234 (2022)\n168. Dai, D., Sun, Y ., Dong, L., Hao, Y ., Sui, Z., Wei, F.: Why can gpt learn in-context? language models\nsecretly perform gradient descent as meta optimizers. arXiv:2212.10559 (2022)\n169. Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., Zettlemoyer, L.: Rethinking the\nrole of demonstrations: What makes in-context learning work?. arXiv:2202.12837 (2022)\n170. Levy, I., Bogin, B., Berant, J.: Diverse demonstrations improve in-context compositional generalization.\narXiv:2212.06800 (2022)\n171. Xie, S.M., Raghunathan, A., Liang, P ., Ma, T.: An explanation of in-context learning as implicit bayesian\ninference. In: International Conference on Learning Representations\n172. Olsson, C., Elhage, N., Nanda, N., Joseph, N., DasSarma, N., Henighan, T., Mann, B., Askell, A., Bai,\nY ., Chen, A., et al.: In-context learning and induction heads. arXiv:2209.11895 (2022)\n173. Akyürek, E., Schuurmans, D., Andreas, J., Ma, T., Zhou, D.: What learning algorithm is in-context\nlearning? investigations with linear models. arXiv:2211.15661 (2022)\n174. Geng, S., Liu, S., Fu, Z., Ge, Y ., Zhang, Y .: Recommendation as language processing (rlp): a uniﬁed\npretrain, personalized prompt & predict paradigm (p5). In: Proceedings of the 16th ACM Conference\non Recommender Systems, pp. 299–315 (2022)\n175. Cui, Z., Ma, J., Zhou, C., Zhou, J., Yang, H.: M6-rec: generative pretrained language models are open-\nended recommender systems. arXiv:2205.08084 (2022)\n176. Liu, S., Gao, C., Chen, Y ., Jin, D., Li, Y .: Learnable embedding sizes for recommender systems.\narXiv:2101.07577 (2021)\n177. Liu, H., Zhao, X., Wang, C., Liu, X., Tang, J.: Automated embedding size search in deep recommender\nsystems. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Develop-\nment in Information Retrieval, pp. 2307–2316 (2020)\n178. Deng, W., Pan, J., Zhou, T., Kong, D., Flores, A., Lin, G.: Deeplight: deep lightweight feature interactions\nfor accelerating ctr predictions in ad serving. In: Proceedings of the 14th ACM International Conference\non Web Search and Data Mining, pp. 922–930 (2021)\n179. Ginart, A.A., Naumov, M., Mudigere, D., Yang, J., Zou, J.: Mixed dimension embeddings with appli-\ncation to memory-efﬁcient recommendation systems. In: 2021 IEEE International Symposium on\nInformation Theory (ISIT), pp. 2786–2791 (2021). IEEE\n180. Wang, Y ., Zhao, X., Xu, T., Wu, X.: Autoﬁeld: automating feature selection in deep recommender\nsystems. In: Proceedings of the ACM Web Conference 2022, pp. 1977–1986 (2022)\n181. Lin, W., Zhao, X., Wang, Y ., Xu, T., Wu, X.: Adafs: adaptive feature selection in deep recommender\nsystem. In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data\nMining, pp. 3309–3317 (2022)\n182. Tsang, M., Cheng, D., Liu, H., Feng, X., Zhou, E., Liu, Y .: Feature interaction interpretability: a case\nfor explaining ad-recommendation systems via neural interaction detection. arXiv:2006.10966 (2020)\n183. Y uanfei, L., Mengshuo, W., Hao, Z., Quanming, Y ., WeiWei, T., Y uqiang, C., Qiang, Y ., Wenyuan,\nD.: Autocross: automatic feature crossing for tabular data in real-world applications. arXiv:1904.12857\n(2019)\n184. Liu, B., Zhu, C., Li, G., Zhang, W., Lai, J., Tang, R., He, X., Li, Z., Y u, Y .: Autoﬁs: automatic feature\ninteraction selection in factorization models for click-through rate prediction. In: Proceedings of the\n26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2636–\n2645 (2020)\n185. Liu, B., Xue, N., Guo, H., Tang, R., Zafeiriou, S., He, X., Li, Z.: Autogroup: automatic feature grouping\nfor modelling explicit high-order feature interactions in ctr prediction. In: Proceedings of the 43rd\nInternational ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 199–\n208 (2020)\n186. Chen, Y ., Ren, P ., Wang, Y ., Rijke, M.: Bayesian personalized feature interaction selection for factor-\nization machines. In: Proceedings of the 42nd International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval, pp. 665–674 (2019)\n187. Xie, Y ., Wang, Z., Li, Y ., Ding, B., Gürel, N.M., Zhang, C., Huang, M., Lin, W., Zhou, J.: Fives: feature\ninteraction via edge search for large-scale tabular data. In: Proceedings of the 27th ACM SIGKDD\nConference on Knowledge Discovery & Data Mining, pp. 3795–3805 (2021)\n188. Su, Y ., Zhang, R., Erfani, S., Xu, Z.: Detecting beneﬁcial feature interactions for recommender systems.\nIn: Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 35, pp. 4357–4365 (2021)\n123\n42 Page 40 of 45\nWorld Wide Web (2024) 27:42\n189. Song, Q., Cheng, D., Zhou, H., Yang, J., Tian, Y ., Hu, X.: Towards automated neural interaction discovery\nfor click-through rate prediction. In: Proceedings of the 26th ACM SIGKDD International Conference\non Knowledge Discovery & Data Mining, pp. 945–955 (2020)\n190. Zhao, P ., Xiao, K., Zhang, Y ., Bian, K., Yan, W.: Ameir: automatic behavior modeling, interaction\nexploration and mlp investigation in the recommender system. In: IJCAI, pp. 2104–2110 (2021)\n191. Wei, Z., Wang, X., Zhu, W.: Autoias: automatic integrated architecture searcher for click-trough rate\nprediction. In: Proceedings of the 30th ACM International Conference on Information & Knowledge\nManagement, pp. 2101–2110 (2021)\n192. Cheng, M., Liu, Z., Liu, Q., Ge, S., Chen, E.: Towards automatic discovering of deep hybrid network\narchitecture for sequential recommendation. In: Proceedings of the ACM Web Conference 2022, pp.\n1923–1932 (2022)\n193. Y u, C., Liu, X., Tang, C., Feng, W., Lv, J.: Gpt-nas: Neural architecture search with the generative\npre-trained model. arXiv:2305.05351 (2023)\n194. Ying, C., Klein, A., Christiansen, E., Real, E., Murphy, K., Hutter, F.: Nas-bench-101: Towards repro-\nducible neural architecture search. In: International Conference on Machine Learning, pp. 7105–7114\n(2019). PMLR\n195. Zheng, M., Su, X., Y ou, S., Wang, F., Qian, C., Xu, C., Albanie, S.: Can gpt-4 perform neural architecture\nsearch? arXiv:2304.10970 (2023)\n196. Nasir, M.U., Earle, S., Togelius, J., James, S., Cleghorn, C.: Llmatic: Neural architecture search via large\nlanguage models and quality-diversity optimization. arXiv:2306.01102 (2023)\n197. Chen, A., Dohan, D.M., So, D.R.: Evoprompting: language models for code-level neural architecture\nsearch. arXiv:2302.14838 (2023)\n198. Shang, L., Lu, Z., Li, H.: Neural responding machine for short-text conversation. arXiv:1503.02364\n(2015)\n199. Vinyals, O., Le, Q.: A neural conversational model. arXiv:1506.05869 (2015)\n200. Sordoni, A., Galley, M., Auli, M., Brockett, C., Ji, Y ., Mitchell, M., Nie, J.-Y ., Gao, J., Dolan, B.: A\nneural network approach to context-sensitive generation of conversational responses. arXiv:1506.06714\n(2015)\n201. Wu, W., Yan, R.: Deep chit-chat: deep learning for chatbots. In: Proceedings of the 42nd international\nACM SIGIR Conference on Research and Development in Information Retrieval, pp. 1413–1414 (2019)\n202. Qiu, X., Huang, X.: Convolutional neural tensor network architecture for community-based question\nanswering. In: Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence (2015)\n203. Wan, S., Lan, Y ., Guo, J., Xu, J., Pang, L., Cheng, X.: A deep architecture for semantic matching\nwith multiple positional sentence representations. In: Proceedings of the AAAI Conference on Artiﬁcial\nIntelligence, vol. 30 (2016)\n204. Greco, C., Suglia, A., Basile, P ., Semeraro, G.: Converse-et-impera: exploiting deep learning and hier-\narchical reinforcement learning for conversational recommender systems. In: AI* IA 2017 Advances in\nArtiﬁcial Intelligence: XVIth International Conference of the Italian Association for Artiﬁcial Intelli-\ngence, Bari, Italy, November 14-17, 2017, Proceedings 16, pp. 372–386 (2017). Springer\n205. Yao, K., Zweig, G., Hwang, M.-Y ., Shi, Y ., Y u, D.: Recurrent neural networks for language understanding.\nIn: Interspeech, pp. 2524–2528 (2013)\n206. Mesnil, G., He, X., Deng, L., Bengio, Y .: Investigation of recurrent-neural-network architectures and\nlearning methods for spoken language understanding. In: Interspeech, pp. 3771–3775 (2013)\n207. Goddeau, D., Meng, H., Polifroni, J., Seneff, S., Busayapongchai, S.: A form-based dialogue manager for\nspoken language applications. In: Proceeding of Fourth International Conference on Spoken Language\nProcessing. ICSLP’96, vol. 2, pp. 701–704 (1996). IEEE\n208. Henderson, M., Thomson, B., Y oung, S.: Deep neural network approach for the dialog state tracking\nchallenge. In: Proceedings of the SIGDIAL 2013 Conference, pp. 467–471 (2013)\n209. Mrkši´ c, N., Séaghdha, D.O., Wen, T.-H., Thomson, B., Y oung, S.: Neural belief tracker: data-driven\ndialogue state tracking. arXiv:1606.03777 (2016)\n210. Cuayáhuitl, H., Keizer, S., Lemon, O.: Strategic dialogue management via deep reinforcement learning.\narXiv:1511.08099 (2015)\n211. Zhou, H., Huang, M., Zhu, X.: Context-aware natural language generation for spoken dialogue systems.\nIn: Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics:\nTechnical Papers, pp. 2032–2041 (2016)\n212. Dušek, O., Jurˇ cíˇcek, F.: Sequence-to-sequence generation for spoken dialogue via deep syntax trees and\nstrings. arXiv:1606.05491 (2016)\n213. Wen, T.-H., V andyke, D., Mrksic, N., Gasic, M., Rojas-Barahona, L.M., Su, P .-H., Ultes, S., Y oung, S.:\nA network-based end-to-end trainable task-oriented dialogue system. arXiv:1604.04562 (2016)\n123\nPage 41 of 45 42\nWorld Wide Web (2024) 27:42\n214. Bordes, A., Boureau, Y .-L., Weston, J.: Learning end-to-end goal-oriented dialog. arXiv:1605.07683\n(2016)\n215. Zhang, Y ., Sun, S., Galley, M., Chen, Y .-C., Brockett, C., Gao, X., Gao, J., Liu, J., Dolan, B.: Dialogpt:\nlarge-scale generative pre-training for conversational response generation. arXiv:1911.00536 (2019)\n216. Lei, W., He, X., Miao, Y ., Wu, Q., Hong, R., Kan, M.-Y ., Chua, T.-S.: Estimation-action-reﬂection:\ntowards deep interaction between conversational and recommender systems. In: Proceedings of the 13th\nInternational Conference on Web Search and Data Mining, pp. 304–312 (2020)\n217. Lei, W., Zhang, G., He, X., Miao, Y ., Wang, X., Chen, L., Chua, T.-S.: Interactive path reasoning on\ngraph for conversational recommendation. In: Proceedings of the 26th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, pp. 2073–2083 (2020)\n218. Deng, Y ., Li, Y ., Sun, F., Ding, B., Lam, W.: Uniﬁed conversational recommendation policy learning via\ngraph-based reinforcement learning. In: Proceedings of the 44th International ACM SIGIR Conference\non Research and Development in Information Retrieval, pp. 1431–1441 (2021)\n219. Li, R., Ebrahimi Kahou, S., Schulz, H., Michalski, V ., Charlin, L., Pal, C.: Towards deep conversational\nrecommendations. Adv. Neural. Inf. Process. Syst. 31 (2018)\n220. Wang, T.-C., Su, S.-Y ., Chen, Y .-N.: Barcor: Towards a uniﬁed framework for conversational recom-\nmendation systems. arXiv:2203.14257 (2022)\n221. Wang, X., Zhou, K., Wen, J.-R., Zhao, W.X.: Towards uniﬁed conversational recommender systems\nvia knowledge-enhanced prompt learning. In: Proceedings of the 28th ACM SIGKDD Conference on\nKnowledge Discovery and Data Mining, pp. 1929–1937 (2022)\n222. Wang, L., Hu, H., Sha, L., Xu, C., Jiang, D., Wong, K.-F.: Recindial: a uniﬁed framework for conversa-\ntional recommendation with pretrained language models. In: Proceedings of the 2nd Conference of the\nAsia-Paciﬁc Chapter of the Association for Computational Linguistics and the 12th International Joint\nConference on Natural Language Processing, pp. 489–500 (2022)\n223. Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: Bert: pre-training of deep bidirectional transformers\nfor language understanding. arXiv:1810.04805 (2018)\n224. Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et al.: Improving language understanding by\ngenerative pre-training (2018)\n225. Gao, Y ., Sheng, T., Xiang, Y ., Xiong, Y ., Wang, H., Zhang, J.: Chat-rec: towards interactive and explain-\nable llms-augmented recommender system. arXiv:2303.14524 (2023)\n226. Friedman, L., Ahuja, S., Allen, D., Tan, T., Sidahmed, H., Long, C., Xie, J., Schubiner, G., Patel, A., Lara,\nH., et al.: Leveraging large language models in conversational recommender systems. arXiv:2305.07961\n(2023)\n227. Wang, X., Tang, X., Zhao, W.X., Wang, J., Wen, J.-R.: Rethinking the evaluation for conversational\nrecommendation in the era of large language models. arXiv:2305.13112 (2023)\n228. Yao, S., Y u, D., Zhao, J., Shafran, I., Grifﬁths, T.L., Cao, Y ., Narasimhan, K.: Tree of thoughts: deliberate\nproblem solving with large language models. arXiv:2305.10601 (2023)\n229. Wang, L., Xu, W., Lan, Y ., Hu, Z., Lan, Y ., Lee, R.K.-W., Lim, E.-P .: Plan-and-solve prompting: improv-\ning zero-shot chain-of-thought reasoning by large language models. arXiv:2305.04091 (2023)\n230. Yao, S., Zhao, J., Y u, D., Du, N., Shafran, I., Narasimhan, K., Cao, Y .: React: synergizing reasoning and\nacting in language models. arXiv:2210.03629 (2022)\n231. Madaan, A., Tandon, N., Clark, P ., Yang, Y .: Memory-assisted prompt editing to improve gpt-3 after\ndeployment. arXiv:2201.06009 (2022)\n232. Qin, Y ., Hu, S., Lin, Y ., Chen, W., Ding, N., Cui, G., Zeng, Z., Huang, Y ., Xiao, C., Han, C., et al.: Tool\nlearning with foundation models. arXiv:2304.08354 (2023)\n233. Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozière, B., Schick, T.,\nDwivedi-Y u, J., Celikyilmaz, A., et al.: Augmented language models: a survey. arXiv:2302.07842 (2023)\n234. Yang, K., Peng, N., Tian, Y ., Klein, D.: Re3: Generating longer stories with recursive reprompting and\nrevision. arXiv:2210.06774 (2022)\n235. Schick, T., Dwivedi-Y u, J., Jiang, Z., Petroni, F., Lewis, P ., Izacard, G., Y ou, Q., Nalmpantis, C., Grave,\nE., Riedel, S.: Peer: a collaborative language model. arXiv:2208.11663 (2022)\n236. Hao, Y ., Song, H., Dong, L., Huang, S., Chi, Z., Wang, W., Ma, S., Wei, F.: Language models are\ngeneral-purpose interfaces. arXiv:2206.06336 (2022)\n237. Izacard, G., Lewis, P ., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Y u, J., Joulin, A., Riedel,\nS., Grave, E.: Few-shot learning with retrieval augmented language models. arXiv:2208.03299 (2022)\n238. Thoppilan, R., De Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng, H.-T., Jin, A., Bos, T.,\nBaker, L., Du, Y ., et al.: Lamda: language models for dialog applications. arXiv:2201.08239 (2022)\n239. Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V ., Saunders,\nW., et al.: Webgpt: browser-assisted question-answering with human feedback. arXiv:2112.09332 (2021)\n123\n42 Page 42 of 45\nWorld Wide Web (2024) 27:42\n240. Liu, R., Wei, J., Gu, S.S., Wu, T.-Y ., V osoughi, S., Cui, C., Zhou, D., Dai, A.M.: Mind’s eye: grounded\nlanguage model reasoning through simulation. arXiv:2210.05359 (2022)\n241. Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P ., Yang, Y ., Callan, J., Neubig, G.: Pal: Program-aided\nlanguage models. arXiv:2211.10435 (2022)\n242. Ahn, M., Brohan, A., Brown, N., Chebotar, Y ., Cortes, O., David, B., Finn, C., Fu, C., Gopalakrishnan, K.,\nHausman, K., et al.: Do as i can, not as i say: grounding language in robotic affordances. arXiv:2204.01691\n(2022)\n243. Shen, Y ., Song, K., Tan, X., Li, D., Lu, W., Zhuang, Y .: Hugginggpt: solving ai tasks with chatgpt and\nits friends in huggingface. arXiv:2303.17580 (2023)\n244. Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., Duan, N.: Visual chatgpt: talking, drawing and editing with\nvisual foundation models. arXiv:2303.04671 (2023)\n245. Liang, Y ., Wu, C., Song, T., Wu, W., Xia, Y ., Liu, Y ., Ou, Y ., Lu, S., Ji, L., Mao, S., et al.: Taskmatrix.\nai: completing tasks by connecting foundation models with millions of apis. arXiv:2303.16434 (2023)\n246. Schick, T., Dwivedi-Y u, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., Scialom,\nT.: Toolformer: language models can teach themselves to use tools. arXiv:2302.04761 (2023)\n247. Li, J., Li, D., Xiong, C., Hoi, S.: Blip: Bootstrapping language-image pre-training for uniﬁed vision-\nlanguage understanding and generation. In: International Conference on Machine Learning, pp. 12888–\n12900 (2022). PMLR\n248. Rombach, R., Blattmann, A., Lorenz, D., Esser, P ., Ommer, B.: High-resolution image synthesis with\nlatent diffusion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\nRecognition, pp. 10684–10695 (2022)\n249. Cai, T., Wang, X., Ma, T., Chen, X., Zhou, D.: Large language models as tool makers. arXiv:2305.17126\n(2023)\n250. Shuster, K., Xu, J., Komeili, M., Ju, D., Smith, E.M., Roller, S., Ung, M., Chen, M., Arora, K., Lane,\nJ., et al.: Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage.\narXiv:2208.03188 (2022)\n251. Liu, J., Jin, J., Wang, Z., Cheng, J., Dou, Z., Wen, J.-R.: Reta-llm: a retrieval-augmented large language\nmodel toolkit. arXiv:2306.05212 (2023)\n252. Pan, S., Luo, L., Wang, Y ., Chen, C., Wang, J., Wu, X.: Unifying large language models and knowledge\ngraphs: a roadmap. arXiv:2306.08302 (2023)\n253. V empati, S., Malayil, K.T., Sruthi, V ., Sandeep, R.: Enabling hyper-personalisation: automated ad creative\ngeneration and ranking for fashion e-commerce. In: Fashion Recommender Systems, pp. 25–48 (2020).\nSpringer\n254. Thomaidou, S., Lourentzou, I., Katsivelis-Perakis, P ., V azirgiannis, M.: Automated snippet generation\nfor online advertising. In: Proceedings of the 22nd ACM International Conference on Information &\nKnowledge Management, pp. 1841–1844 (2013)\n255. Zhang, X., Zou, Y ., Zhang, H., Zhou, J., Diao, S., Chen, J., Ding, Z., He, Z., He, X., Xiao, Y ., et al.:\nAutomatic product copywriting for e-commerce. In: Proceedings of the AAAI Conference on Artiﬁcial\nIntelligence, vol. 36, pp. 12423–12431 (2022)\n256. Lei, Z., Zhang, C., Xu, X., Wu, W., Niu, Z.-Y ., Wu, H., Wang, H., Yang, Y ., Li, S.: Plato-ad: a uniﬁed\nadvertisement text generation framework with multi-task prompt learning. In: Proceedings of the 2022\nConference on Empirical Methods in Natural Language Processing: Industry Track, pp. 512–520 (2022)\n257. Bartz, K., Barr, C., Aijaz, A.: Natural language generation for sponsored-search advertisements. In:\nProceedings of the 9th ACM Conference on Electronic Commerce, pp. 1–9 (2008)\n258. Fujita, A., Ikushima, K., Sato, S., Kamite, R., Ishiyama, K., Tamachi, O.: Automatic generation of listing\nads by reusing promotional texts. In: Proceedings of the 12th International Conference on Electronic\nCommerce: Roadmap for the Future of Electronic Business, pp. 179–188 (2010)\n259. Hughes, J.W., Chang, K.-h., Zhang, R.: Generating better search engine text advertisements with deep\nreinforcement learning. In: Proceedings of the 25th ACM SIGKDD International Conference on Knowl-\nedge Discovery & Data Mining, pp. 2269–2277 (2019)\n260. Wang, X., Gu, X., Cao, J., Zhao, Z., Yan, Y ., Middha, B., Xie, X.: Reinforcing pretrained models for\ngenerating attractive text advertisements. In: Proceedings of the 27th ACM SIGKDD Conference on\nKnowledge Discovery & Data Mining, pp. 3697–3707 (2021)\n261. Chen, C., Wang, X., Yi, X., Wu, F., Xie, X., Yan, R.: Personalized chit-chat generation for recommenda-\ntion using external chat corpora. In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, pp. 2721–2731 (2022)\n262. Zhang, C., Zhou, J., Zang, X., Xu, Q., Yin, L., He, X., Liu, L., Xiong, H., Dou, D.: Chase: commonsense-\nenriched advertising on search engine with explicit knowledge. In: Proceedings of the 30th ACM\nInternational Conference on Information & Knowledge Management, pp. 4352–4361 (2021)\n123\nPage 43 of 45 42\nWorld Wide Web (2024) 27:42\n263. Kanungo, Y .S., Negi, S., Rajan, A.: Ad headline generation using self-critical masked language model. In:\nProceedings of the 2021 Conference of the North American Chapter of the Association for Computational\nLinguistics: Human Language Technologies: Industry Papers, pp. 263–271 (2021)\n264. Wei, P ., Yang, X., Liu, S., Wang, L., Zheng, B.: Creater: ctr-driven advertising text generation with\ncontrolled pre-training and contrastive ﬁne-tuning. arXiv:2205.08943 (2022)\n265. Kanungo, Y .S., Das, G., Negi, S.: Cobart: controlled, optimized, bidirectional and auto-regressive trans-\nformer for ad headline generation. In: Proceedings of the 28th ACM SIGKDD Conference on Knowledge\nDiscovery and Data Mining, pp. 3127–3136 (2022)\n266. Chen, Q., Lin, J., Zhang, Y ., Yang, H., Zhou, J., Tang, J.: Towards knowledge-based personalized\nproduct description generation in e-commerce. In: Proceedings of the 25th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining, pp. 3040–3050 (2019)\n267. Cao, Y ., Li, S., Liu, Y ., Yan, Z., Dai, Y ., Y u, P .S., Sun, L.: A comprehensive survey of ai-generated\ncontent (aigc): a history of generative ai from gan to chatgpt. arXiv:2303.04226 (2023)\n268. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio,\nY .: Generative adversarial nets. Adv. Neural. Inf. Process. Syst. 27 (2014)\n269. Kingma, D.P ., Welling, M.: Auto-encoding variational bayes. arXiv:1312.6114 (2013)\n270. Dinh, L., Krueger, D., Bengio, Y .: Nice: non-linear independent components estimation. arXiv:1410.8516\n(2014)\n271. Ho, J., Jain, A., Abbeel, P .: Denoising diffusion probabilistic models. Adv. Neural. Inf. Process. Syst.\n33, 6840–6851 (2020)\n272. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M.,\nMinderer, M., Heigold, G., Gelly, S., et al.: An image is worth 16x16 words: transformers for image\nrecognition at scale. In: International Conference on Learning Representations\n273. Liu, Z., Lin, Y ., Cao, Y ., Hu, H., Wei, Y ., Zhang, Z., Lin, S., Guo, B.: Swin transformer: hierarchical\nvision transformer using shifted windows. In: Proceedings of the IEEE/CVF International Conference\non Computer Vision, pp. 10012–10022 (2021)\n274. Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P .,\nClark, J., et al.: Learning transferable visual models from natural language supervision. In: International\nConference on Machine Learning, pp. 8748–8763 (2021). PMLR\n275. Chen, M., Tan, X., Li, B., Liu, Y ., Qin, T., Liu, T.-Y ., et al.: Adaspeech: adaptive text to speech for custom\nvoice. In: International Conference on Learning Representations\n276. Li, X., Taheri, A., Tu, L., Gimpel, K.: Commonsense knowledge base completion. In: Proceedings of\nthe 54th Annual Meeting of the Association for Computational Linguistics (vol. 1: long papers), pp.\n1445–1455 (2016)\n277. Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.:\nCodebert: a pre-trained model for programming and natural languages. In: Findings of the Association\nfor Computational Linguistics: EMNLP 2020, pp. 1536–1547 (2020)\n278. OpenAI: ChatGPT: A Large-Scale Generative Model for Conversation. OpenAI Blog (2020)\n279. Ramesh, A., Pavlov, M., Goh, G., Gray, S., V oss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot\ntext-to-image generation. In: International Conference on Machine Learning, pp. 8821–8831 (2021).\nPMLR\n280. Chen, M., Tworek, J., Jun, H., Y uan, Q., Pinto, H.P .d.O., Kaplan, J., Edwards, H., Burda, Y ., Joseph, N.,\nBrockman, G., et al.: Evaluating large language models trained on code. arXiv:2107.03374 (2021)\n281. Midjourney: Midjourney. Retrieved from. https://midjourney.com (2022)\n282. Wang, W., Lin, X., Feng, F., He, X., Chua, T.-S.: Generative recommendation: towards next-generation\nrecommender paradigm. arXiv:2304.03516 (2023)\n283. Borji, A.: A categorical archive of chatgpt failures. arXiv:2302.03494 (2023)\n284. Carlini, N., Tramer, F., Wallace, E., et al.: Extracting training data from large language models. (2021)\n285. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Language models are unsu-\npervised multitask learners\n286. Hu, E.J., Wallis, P ., Allen-Zhu, Z., Li, Y ., Wang, S., Wang, L., Chen, W., et al.: Lora: low-rank adaptation\nof large language models. In: International Conference on Learning Representations (2021)\n287. Dettmers, T., Pagnoni, A., Holtzman, A., Zettlemoyer, L.: Qlora: Efﬁcient ﬁnetuning of quantized llms.\narXiv:2305.14314 (2023)\n288. Bai, Y ., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini,\nA., McKinnon, C., et al.: Constitutional ai: Harmlessness from ai feedback. arXiv:2212.08073 (2022)\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and\ninstitutional afﬁliations.\n123\n42 Page 44 of 45\nWorld Wide Web (2024) 27:42\nAuthorsandAﬃliations\nJin Chen 1 · Zheng Liu 2 · Xu Huang 3 · Chenwang Wu 3 · Qi Liu 3 · Gangwei Jiang 3 ·\nYuanhao Pu 3 · Yuxuan Lei 3 · Xiaolong Chen 3 · Xingmei Wang 3 · Kai Zheng 4 ·\nDefu Lian 3 · Enhong Chen 3\nB Jin Chen\njinchen@ust.hk\nZheng Liu\nzhengliu1026@gmail.com\nXu Huang\nxuhuangcs@mail.ustc.edu.cn\nChenwang Wu\nwcw1996@mail.ustc.edu.cn\nQi Liu\nqiliu67@mail.ustc.edu.cn\nGangwei Jiang\ngwjiang@mail.ustc.edu.cn\nY uanhao Pu\npuyuanhao@mail.ustc.edu.cn\nY uxuan Lei\nlyx180812@mail.ustc.edu.cn\nXiaolong Chen\nchenxiaolong@mail.ustc.edu.cn\nXingmei Wang\nxingmeiwang@mail.ustc.edu.cn\nKai Zheng\nzhengkai@uestc.edu.cn\nDefu Lian\nliandefu@ustc.edu.cn\nEnhong Chen\ncheneh@ustc.edu.cn\n1 Hong Kong University of Science and Technology, Hong Kong, China\n2 Beijing Academy of Artiﬁcial Intelligence, Beijing, China\n3 University of Science and Technology of China, Hefei, China\n4 University of Electronic Science and Technology of China, Chengdu, China\n123\nPage 45 of 45 42",
  "topic": "Personalization",
  "concepts": [
    {
      "name": "Personalization",
      "score": 0.9338502287864685
    },
    {
      "name": "Computer science",
      "score": 0.8682138919830322
    },
    {
      "name": "Function (biology)",
      "score": 0.6088907122612
    },
    {
      "name": "Scope (computer science)",
      "score": 0.6072620153427124
    },
    {
      "name": "Language model",
      "score": 0.5524003505706787
    },
    {
      "name": "Service (business)",
      "score": 0.4861621558666229
    },
    {
      "name": "User modeling",
      "score": 0.4705807566642761
    },
    {
      "name": "Natural language understanding",
      "score": 0.4642791152000427
    },
    {
      "name": "World Wide Web",
      "score": 0.4395636320114136
    },
    {
      "name": "User interface",
      "score": 0.42912915349006653
    },
    {
      "name": "Natural language",
      "score": 0.41515955328941345
    },
    {
      "name": "Human–computer interaction",
      "score": 0.4033201336860657
    },
    {
      "name": "Data science",
      "score": 0.32611024379730225
    },
    {
      "name": "Artificial intelligence",
      "score": 0.29596543312072754
    },
    {
      "name": "Programming language",
      "score": 0.08814188838005066
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Evolutionary biology",
      "score": 0.0
    },
    {
      "name": "Economy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I200769079",
      "name": "Hong Kong University of Science and Technology",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I889458895",
      "name": "University of Hong Kong",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I4210100255",
      "name": "Beijing Academy of Artificial Intelligence",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I150229711",
      "name": "University of Electronic Science and Technology of China",
      "country": "CN"
    }
  ]
}