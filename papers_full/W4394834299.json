{
    "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
    "url": "https://openalex.org/W4394834299",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4293806800",
            "name": "Lars‐Peter Meyer",
            "affiliations": [
                "Leipzig University",
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2157435787",
            "name": "Claus Stadler",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft",
                "Leipzig University"
            ]
        },
        {
            "id": "https://openalex.org/A2135410773",
            "name": "Johannes Frey",
            "affiliations": [
                "Leipzig University",
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2400098720",
            "name": "Norman Radtke",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A1905742916",
            "name": "Kurt Junghanns",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2532382930",
            "name": "Roy Meissner",
            "affiliations": [
                "Leipzig University"
            ]
        },
        {
            "id": "https://openalex.org/A4307832254",
            "name": "Gordian Dziwis",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2229642114",
            "name": "Kirill Bulert",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2023244512",
            "name": "Michael Martin",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A4293806800",
            "name": "Lars‐Peter Meyer",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft",
                "Leipzig University of Applied Sciences",
                "Leipzig University"
            ]
        },
        {
            "id": "https://openalex.org/A2157435787",
            "name": "Claus Stadler",
            "affiliations": [
                "Leipzig University",
                "Leipzig University of Applied Sciences",
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2135410773",
            "name": "Johannes Frey",
            "affiliations": [
                "Leipzig University",
                "Leipzig University of Applied Sciences",
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2400098720",
            "name": "Norman Radtke",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A1905742916",
            "name": "Kurt Junghanns",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2532382930",
            "name": "Roy Meissner",
            "affiliations": [
                "Leipzig University",
                "Leipzig University of Applied Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A4307832254",
            "name": "Gordian Dziwis",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2229642114",
            "name": "Kirill Bulert",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        },
        {
            "id": "https://openalex.org/A2023244512",
            "name": "Michael Martin",
            "affiliations": [
                "Institut für Angewandte Trainingswissenschaft"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4361194022",
        "https://openalex.org/W4311430511",
        "https://openalex.org/W4327486086",
        "https://openalex.org/W4320854854"
    ],
    "abstract": "Zusammenfassung Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs. Zusammenfassung. Wissensgraphen (englisch Knowledge Graphs , KGs), bieten uns eine strukturierte, flexible, transparente, systemübergreifende und kollaborative Möglichkeit, unser Wissen und unsere Daten über verschiedene Bereiche der Gesellschaft und der industriellen sowie wissenschaftlichen Disziplinen hinweg zu organisieren. KGs übertreffen jede andere Form der Repräsentation in Bezug auf die Effektivität. Die Entwicklung von Wissensgraphen (englisch Knowledge Graph Engineering , KGE) erfordert jedoch fundierte Erfahrungen mit Graphstrukturen, Webtechnologien, bestehenden Modellen und Vokabularen, Regelwerken, Logik sowie Best Practices. Es erfordert auch einen erheblichen Arbeitsaufwand. In Anbetracht der Fortschritte bei großen Sprachmodellen (englisch Large Language Modells , LLMs) und ihren Schnittstellen und Anwendungen in den letzten Jahren haben wir umfassende Experimente mit ChatGPT durchgeführt, um sein Potenzial zur Unterstützung von KGE zu untersuchen. In diesem Artikel stellen wir eine Auswahl dieser Experimente und ihre Ergebnisse vor, um zu zeigen, wie ChatGPT uns bei der Entwicklung und Verwaltung von KGs unterstützen kann.",
    "full_text": "LLM-assisted Knowledge Graph\nEngineering: Experiments with ChatGPT\nLars-Peter Meyer1,2,3(B) , Claus Stadler1,2,3 , Johannes Frey1,2,3 ,\nNorman Radtke1,2 , Kurt Junghanns1,2 , Roy Meissner2,3 ,\nGordian Dziwis1 , Kirill Bulert1,2 and Michael Martin1,2\n1 Institut f¨ur Angewandte Informatik (InfAI) e. V., Leipzig, Germany\n{lpmeyer,stadler,radtke,junghanns,dziwis,bulert,martin}@infai.org;\nfrey@informatik.uni-leipzig.de\nhttps://www.infai.org,\n2 AKSW research group, Leipzig, Germany\nroy.meissner@uni-leipzig.de\nhttps://aksw.org,\n3 Erziehungswiss. Fakult¨at, Allgemeine P¨adagogik, Universit¨at Leipzig, Leipzig,\nGermany\nhttps://www.uni-leipzig.de\nAbstract. Knowledge Graphs (KG) provide us with a structured, ﬂex-\nible, transparent, cross-system, and collaborative way of organizing our\nknowledge and data across various domains in society and industrial as\nwell as scientiﬁc disciplines. KGs surpass any other form of representa-\ntion in terms of eﬀectiveness. However, Knowledge Graph Engineering\n(KGE) requires in-depth experiences of graph structures, web technolo-\ngies, existing models and vocabularies, rule sets, logic, as well as best\npractices. It also demands a signiﬁcant amount of work.\nConsidering the advancements in large language models (LLMs) and\ntheir interfaces and applications in recent years, we have conducted com-\nprehensive experiments with ChatGPT to explore its potential in sup-\nporting KGE. In this paper, we present a selection of these experiments\nand their results to demonstrate how ChatGPT can assist us in the devel-\nopment and management of KGs.\nZusammenfassung. Wissensgraphen (englisch Knowledge Graphs ,\nKGs), bieten uns eine strukturierte, ﬂexible, transparente, sys-\ntem¨ubergreifende und kollaborative M¨ oglichkeit, unser Wissen und\nunsere Daten ¨uber verschiedene Bereiche der Gesellschaft und der indus-\ntriellen sowie wissenschaftlichen Disziplinen hinweg zu organisieren. KGs\n¨ubertreﬀen jede andere Form der Repr¨asentation in Bezug auf die Eﬀek-\ntivit¨at. Die Entwicklung von Wissensgraphen (englischKnowledge Graph\nEngineering, KGE) erfordert jedoch fundierte Erfahrungen mit Graph-\nstrukturen, Webtechnologien, bestehenden Modellen und Vokabularen,\nRegelwerken, Logik sowie Best Practices. Es erfordert auch einen erhe-\nblichen Arbeitsaufwand.\nc⃝ Der/die Autor(en) 2024\nC. Zinke-Wehlmann und J. Friedrich (Hrsg.), First Working Conference on Artiﬁcial\nIntelligence Development for a Resilient and Sustainable Tomorrow, AIDRST 2023,\nInformatik aktuell, S. 103–115, https://doi.org/10.1007/978-3-658-43705-3_8\n104 L. P. Meyer et al.\nIn Anbetracht der Fortschritte bei groen Sprachmodellen (englisch\nLarge Language Modells , LLMs) und ihren Schnittstellen und Anwen-\ndungen in den letzten Jahren haben wir umfassende Experimente mit\nChatGPT durchgef¨uhrt, um sein Potenzial zur Unterst¨utzung von KGE\nzu untersuchen. In diesem Artikel stellen wir eine Auswahl dieser Exper-\nimente und ihre Ergebnisse vor, um zu zeigen, wie ChatGPT uns bei der\nEntwicklung und Verwaltung von KGs unterst¨utzen kann.\nKey words: ChatGPT\n· knowledge graph engineering · RDF · large\nlanguage model use cases · AI application\n1 Introduction\nIn the last years, Artiﬁcial Intelligence (AI) has shown great promise in improv-\ning or revolutionizing various ﬁelds of research and practice, including knowl-\nedge engineering. The recent big leap in AI-based assistant chatbots, like Chat-\nGPT (Generative Pre-trained Transformer) model, has created new opportu-\nnities to automate knowledge engineering tasks and reduce the workload on\nhuman experts. With the growing volume of information in diﬀerent ﬁelds, the\nneed for scalable and eﬃcient methods to manage and extract knowledge from\ndata that also adapt to new sources is critical. Despite the advances in research\nw.r.t. (semi)automation, knowledge engineering tasks still rely vastly on human\nexperts. On one hand, this process can be time-consuming, resource-intensive,\nand susceptible to errors. On the other hand, the reliance on human expertise in\nknowledge engineering exposes it to workforce shortages (as knowledge engineers\nare scarce and the demand is growing) and the risk of expertise loss. These fac-\ntors can impact the resilience and sustainability of systems and operations that\nrely on knowledge engineering. AI-based assistant bot approaches, such as Chat-\nGPT, could bridge this gap by providing a uniﬁed tool for tasks in knowledge\nengineering, to reduce the workload of knowledge engineers themselves, but also\nmake knowledge engineering more accessible to a broader audience. ChatGPT,\nin particular, has shown promise in generating responses in a variety of syntac-\ntical representations (including code and markup languages) to user queries or\ntask descriptions written in natural language.\nIn this paper, we discuss and investigate the potential of ChatGPT to sup-\nport or automate various knowledge engineering tasks (e.g. ontology generation,\nSPARQL query generation). We will explore the beneﬁts, pitfalls and challenges\nof using it and identify potential avenues for future research.\n2 Related Work\nChatGPT, a Large Language Model (LLM) published by OpenAI 1, raised the\ninterest in the broad ﬁeld of Machine Learning (ML)2 and especially LLMs [4]o n\n1 https://openai.com/blog/chatgpt\n2 https://aiindex.stanford.edu/wp-content/uploads/2023/04/HAI AI-Index-\nReport 2023.pdf\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 105\na broad scale. While there are current discussions and analysis on the capabilities\nof LLMs like ChatGPT in general (e.g. [1]), there is little in the area of knowledge\ngraph engineering. Ekaputra et al. [3] gives a general overview of current research\non the combination of the broad ﬁeld of ML and semantic web.\nSearching Google Scholar and Semantic Scholar with “knowledge graph\nChatGPT”, “ontology ChatGPT” and “rdf ChatGPT” in the beginning of April\n2023 results in only two relevant papers. The ﬁrst one, [7], reviews the diﬀerences\nbetween conversational AI models, prominent ChatGPT, and state-of-the-art\nquestion-answering systems for knowledge graphs. In their survey and experi-\nments, they detect capabilities of their used frameworks but highlight ChatG-\nPTs explainability and robustness. The second one, [ 6], discusses the usage of\nChatGPT for database management tasks when tabular schema is expressed in\na natural language. They conclude among others that ChatGPT is able to assist\nin complex semantic integration and table joins to simplify database manage-\nment and enhance productivity. The applied approaches and results of these\ntwo papers indicate that the idea of using LLMs like ChatGPT in the ﬁeld of\nKG engineering is encouraging and that the LLMs might assist KG engineers in\ntheir workﬂows. Still, the research on the usage of LLMs for knowledge graph\nengineers is scarce and seems to be a new research area.\nThere exist some non- and semi-scientiﬁc resources which render the topic\nfrom a practical and experience perspective. We want to highlight here a helpful\nblog post by Kurt Cagle [ 2] on ChatGPT for “knowledge graph workers” and\na blog post by Konrad Kalici´nski [5] on knowledgegraph generation in Neo4J\nassisted by ChatGPT.\n3 LLM-Assisted Knowledge Graph Engineering –\nPotential Application Areas\nIn discussion rounds with knowledge graph engineering experts we identiﬁed the\nfollowing preliminary list of potential use cases in the domain of knowledge graph\nengineering applicable to LLMs assistance:\n– Assistance in knowledge graph usage:\n Generate SPARQL queries from natural language questions (related\nexperiment in Sect. 4.1 and 4.3)\n Exploration and summarization of existing knowledge graphs (related\nexperiment in Sect. 4.5)\n Conversion of competency questions to SPARQL queries\n Code generation or conﬁguration of tool(chain)s for data pipelines\n– Assistance in knowledge graph construction\n Populating knowledge graphs (related experiment in Sect. 4.4) and vice\nversa\n Creation or enrichment of knowledge graph schemas / ontologies\n Get hints for problematic graph design by analysing ChatGPT usages\nproblems with a knowledge graph\n106 L. P. Meyer et al.\n Semantic search for concepts or properties deﬁned in other already exist-\ning knowledge graphs\n Creation and adjustment of knowledge graphs based on competency ques-\ntions\nGiven the limited space of this paper, we evaluate a subset of the application\nareas with experiments in the following section.\n4 Experiments\nTo evaluate the capabilities of LLMs at the example of ChatGPT for assist-\ning with knowledge graph engineering, we present several experiments and\ntheir results. Further details about them is given in the Supplemental Online\nResources. Most experiments were conducted with ChatGPT with the LLM\nGPT-3.5-turbo\n3 (named ChatGPT-3 from here on), some additionally with\nChatGPT with the LLM GPT-44 (named ChatGPT-4 from here on).\n4.1 SPARQL Query Generation for a Custom Small Knowledge\nGraph\nFor a ﬁrst evaluation, we designed a small knowledge graph as shown in Listing\n1. Speciﬁcally, we wanted to know whether (1) GPT can explain connections\nbetween indirectly related entities, (2) create SPARQL queries over the given\nmodel and (3) reconstruct the model if all properties and classes were relabelled.\nWe issued the following prompt, which includes the knowledge graph from\nListing 1, on ChatGPT-3 and ChatGPT-4:\n3 https://platform.openai.com/docs/models/gpt-3-5\n4 https://platform.openai.com/docs/models/gpt-4\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 107\nPrompt 1: Given the RDF/Turtle model below, are there any connections\nbetween US and UK? <rdf-model>\nIn the knowledge graph of Listing 1, there is a connection between the two coun-\ntries via the two people living in these, which got a job in diﬀerent departments of\nthe same company. While ChatGPT-3 fails to identify this relation, ChatGPT-4\nsuccessfully identiﬁes it in all cases.\nWe further asked both ChatGPT models with prompt 2 and received ﬁve\nSPARQL queries each, which we analysed for their syntactic correctness, plau-\nsible query structure, and result quality. The results for prompt 2 are listed in\nTab. 1 and show that both models produce syntactically correct queries, which\nin most cases are plausible and produce corrects results in 3/5 (ChatGPT3) and\n2/5 (ChatGPT4) cases.\nPrompt 2: Given the RDF/Turtle model below, create a SPARQL query\nthat lists for every person the country, company and department and role.\nPlease adhere strictly to the given model. <rdf-model>\nTable 1. Findings in generated SPARQL queries for prompt 2\nChatGPT-3 ChatGPT-4\nsyntactically correct 5/5 5/5\nplausible query structure 4/5 3/5\nproducing correct result 3/5 2/5\nusing only deﬁned classes and properties 3/5 4/5\ncorrect usage of classes and properties 5/5 5/5\ncorrect preﬁx for the graph 5/5 4/5\nIn essence, AI-based query generation is possible and it can produce valid queries.\nHowever, the process needs result validation in two dimensions: 1) validating\nthe query itself by matching to static information, like available classes and\nproperties in the graph, as well as 2) validating the executed query results to\nlet ChatGPT generate new queries in case of empty result sets in order to ﬁnd\nworking queries in a try & error approach.\nAs a last prompt on the knowledge graph from Listing 1, we created a derived\nRDF graph by relabelling all classes and properties with sequentially numbered\nIRIs in the example namespace, likeeg:prop1 and eg:class2. Given the relabelled\nmodel, we tasked ChatGPT:\n108 L. P. Meyer et al.\nPrompt 3: Given the RDF/Turtle model below, please replace all prop-\nerties and classes with the most likely standard ones. <rdf-model>\nWith ChatGPT-3 only 2/5 iterations succeeded in carrying out all substitu-\ntions. In those succeeding cases, the quality was still not as expected because of\nlimited ontology reuse: Only IRIs in the example namespace were introduced,\nrather than reusing thefoaf, vcard,a n dorg vocabularies. Yet, the ad-hoc proper-\nties and classes were reasonably named, such aseg:ﬁrstName, eg:countryName or\neg:departmentName. In contrast, ChatGPT-4 delivered better results: All classes\nand properties were substituted with those from standard vocabularies—foaf,\nvcard, and org were correctly identiﬁed. For some iterations, ChatGPT-4 used\nthe schema.org vocabulary instead of the org vocabulary as an alternative app-\nroach.\n4.2 Token Counts for Knowledge Graphs Schemas\nAfter the results with the small custom knowledge graph we wanted to check\nthe size of some well known knowledge graphs with respect to LLMs.\nThe LLMs behind ChatGPT can handle at the moment only 4096 tokens\n(GPT-3.5\n3) or 8192 respective 32,768 tokens for GPT-44.\nTable 2. Token counts for selected knowledge graphs and serialisations\nGraph Serialisation Type Token Count\nMondial Oracle DB schema SQL schema 2,608 token\nMondial RDF schema turtle 5,339 token\nMondial RDF schema functional syntax 9,696 token\nMondial RDF schema manchester syntax 11,336 token\nMondial RDF schema xml/rdf 17,179 token\nMondial RDF schema json-ld 47,229 token\nWine Ontology turtle 13,591 token\nWine Ontology xml/rdf 24,217 token\nPizza Ontology turtle 5.431 token\nPizza Ontology xml/rdf 35,331 token\nDBpedia RDF schema turtle 471,251 token\nDBpedia RDF schema xml/rdf 2,338,484 token\nWe counted tokens for various public knowledge graphs in diﬀerent serializa-\ntion formats with the library tiktoken5 as recommended for ChatGPT. Tab. 2\n5 https://github.com/openai/tiktoken\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 109\nlists the token counts for a couple of combinations ordered by token count. More\ndata and information is available in the Supplemental Online Resources. The\nturtle serialization seem to result in minimal token count, but is still bigger than\nthe similar SQL schema added for comparison. All knowledge graphs exceed the\ntoken limit for GPT-3.5 and 3 of 4 knowledge graphs listed here exceed the limit\nfor GPT-4.\n4.3 SPARQL Query Generation for the Mondial Knowledge Graph\nIn addition to the experiments with the small custom knowledge graph (see\nSect. 4.1) we tested ChatGPT with the bigger mondial knowledge graph\n6 which\nis published since decades with the latest “main revision” 2015.\nWe asked ChatGPT to generate a SPARQL query for a natural language\nquestion from a sparql university lecture 7. We used the following prompt ﬁve\ntimes with ChatGPT-3 and ChatGPT-4 each:\nPrompt 4: Please create a sparql query based on the mondial knowledge\ngraph for the following question: which river has the most riparian states?\nThe results are documented in the Supplemental Online Resources together with\ndetailed comments on the given queries. Tab.3 gives some statistics. In summary,\nall SPARQL queries given by ChatGPT were syntactically correct, but none of\nthem worked when executed. Actually all queries had at least one error prevent-\ning the correct execution like referencing a wrong namespace, wrong usage of\nproperties or referencing undeﬁned classes.\nTable 3. Findings in generated sparql queries for prompt 4.\nChatGPT-3 ChatGPT-4\nsyntactically correct 5/5 5/5\nplausible query structure 2/5 4/5\nproducing correct result 0/5 0/5\nusing only deﬁned classes and properties 1/5 3/5\ncorrect usage of classes and properties 0/5 3/5\ncorrect preﬁx for mondial graph 0/5 1/5\n6 https://www.dbis.informatik.uni-goettingen.de/Mondial\n7 https://www.dbis.informatik.uni-goettingen.de/Teaching/SWPr-SS20/swpr-1.pdf\n110 L. P. Meyer et al.\n4.4 Knowledge Extraction from Fact Sheets\nAs an experiment to evaluate knowledge extraction capabilities, we used PDF\nfact sheets of 3D printer speciﬁcations from diﬀerent additive manufacturing\n(AM) vendor websites. The goal is to build a KG about existing 3D printers\nand their type as well as capabilities. We fed plaintext excerpts (extracted via\npdfplumber) from these PDFs into ChatGPT-3 and prompted it to:\nPrompt 5: Convert the following $$vendor$$ 3d printer speciﬁcation into\na JSON LD formatted Knowledge Graph. The node for this KG should be\nPrinter as a main node, Type of 3d printer such as FDM, SLA, and SLS,\nManufacturer, Material, Applications, and Technique.\nSince the fact sheets are usually formatted using a table scheme, the nature of\nthese plain texts is that mostly the printer entity is mentioned in the beginning\nof the text which then is further characterized in a key-value style. As a result,\nthe text typically does not use full sentences and contains only one entity that\nis described in detail, but several dependant entities (like printing materials).\nHowever, the format of the key-value pairs can be noisy. Key names can be\nseparated with colons, new line feeds, or in contrast multiple key-value pairs can\nbe in the same line, which could impose a challenge. Nevertheless, ChatGPT\nwas able to identify the key-value pairs of the evaluation document in a reliably\nway. Unfortunately, it delivered out of 5 test runs for this document 4 partial\nand 1 complete JSON document. In spite of that, we summarize ﬁrst insights\ngained from a knowledge engineering perspective (but for the sake of brevity, we\nrefer to the output documents in the experiment supplements)\n– The JSON-LD output format prioritizes usage of schema.org vocabulary in\nthe 5 evaluation runs. This works good for well-known entities and properties\n(e.g. Organization @type for the manufacturer, or thename property), how-\never, for the AM-speciﬁc feature key names or terms likeprinter ChatGPT-\n3 invents reasonable but non-existent property names (in the schema.org\nnamespace) instead of accurately creating a new namespace or using a dedi-\ncated AM ontology for that purpose.\n– Requesting turtle as output format instead, leads to diﬀerent results. E.g.\nthe property namespace preﬁx is based on the printer ID and therefore printer\ndescriptions are not interoperable and can not be queried in uniﬁed way in a\njoint KG.\n– Successfully splitting x, y and z values of the maximum print dimension\n(instead of extracting all dimensions into one string literal) works in 3 runs.\nAlthough ChatGPT-3 accurately appends the unit of measurement to all x,\ny, z values (which is only mentioned after the z value in the input) in those\ncases, this is a modelling ﬂaw, as querying the KG will be more complex. In\none run it addressed this issue by separating units into a separate unit code\nﬁeld.\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 111\n– A similar eﬀect was observed when it comes to modelling the dependent\nentities. E.g., in 4 runs, the manufacturer was modelled correctly as a separate\ntyped entity, in 1 as string literal instead.\nAs a general conclusion of the experiment, ChatGPT-3 has overall solid skills to\nextract the key value pairs from the sheets, but the correct modelling or represen-\ntation in terms of a KG signiﬁcantly varies from run to run. Subsequently, none\nof the generated JSON documents contained suﬃcient information on their own,\nbut only a subset that was modelled accurately. A question for future research is\nwhether cherrypicking of individual JSON elements from outputs of several runs\nand combining them into one ﬁnal document or iteratively reﬁning the output\nby giving ChatGPT generic modelling feedback (like use an ontology, or separate\nunit information, etc.) can be automated in a good and scalable way.\n4.5 Knowledge Graph Exploration\nExperts in the ﬁeld of knowledge graphs are familiar with concepts from RDF\nSchema (RDFS) (domain/range, subPropertyOf, subClassOf) and Web Ontol-\nogy Language (OWL) (ObjectProperty, DatatypeProperty, FunctionalProperty,\n...). Often, each of these experts has their preferred tools and methods for gaining\nan overview of an ontology they are not yet familiar with. We asked ChatGPT-3\ntwo diﬀerent questions requesting the mermaid\n8 visualization of the most impor-\ntant concepts and their connections:\nPrompt 6: Can you create me a visualization showing the most important\nclasses and concepts and how they are linked for dbpedia ontology, serialized\nfor mermaid?\nPrompt 7: Can you create me a visualization of the most common con-\ncepts of the DBpedia ontology and their connections focusing on domain\nand range deﬁned in properties.\nWe expected a graph with at least eight nodes and their corresponding edges.\nThe identiﬁers for the nodes and edges are expected to follow the Turtle or\nSPARQL prefix:concept notation. If the ﬁrst question did not achieve the\ngoal, we asked additional questions or demands to ChatGPT-3. The results are\npresented in Tab.4 and we evaluated the displayed graphs based on the following\ncriteria:\n8 “ ...a J a v a S c r i p t - b a s e d d i a g r a m m i n g a n d c h a r t i n g t oo l ...”https://mermaid.js.\norg/.\n112 L. P. Meyer et al.\nTable 4. Diagram content overview.\nPrompt 6 Prompt 7\nMermaid Type graph graph ∗\nLabels of Nodes preﬁx and concept preﬁx and concept ∗∗\nLabels of Edges preﬁx and concept preﬁx and concept ∗∗\nNumber of Nodes (total/existing/dbo) 10/10/8 13/12/12\nNumber of Edges (total/unique) 12/2 17/17\n∗ One more prompt was needed to serialize a graph\n∗∗ One more prompt was needed to add preﬁxed labels\nPrompt 6 led to an answer with a hierarchical graph representation of the\nimportant classes deﬁned in the DBpedia ontology. The diagram already met\nour requirements regarding the minimum number and labelling after the ﬁrst\nanswer and can be seen in the Supplemental Online Resources.\nThe class hierarchy was represented by the rdfs:subPropertyOf relation,\nand the nodes were labelled in preﬁx notation, as were the edges. By arranging\nit as a tree using the subClassOf-pattern, only two diﬀerent properties were used\nfor the relations (edges). The root node was of type owl:Thing other nodes are\nconnected as (sub)classes from the DBpedia ontology. These were: Place, Organi-\nzation, Event, Work, Species, and Person. The class Work had one more subClas-\nsOf relation to the class MusicalWork. The class Person had the most complex\nrepresentation, with two more subClassOf relations leading tofoaf:Person and\nfoaf:Agent, the latter of which is a subclass of the root node (owl:Thing).\nIn the second prompt (Prompt7 ChatGPT-3 referred to a graphic ﬁle within\nthe answer text that no longer existed. Upon further inquiry, a mermaid diagram\nwas generated. It was of type “Graph” and contained thirteen common concepts\nand seventeen edges, which were all unique. The labels of both, nodes and edges\ncontain no preﬁxes, but were addable with further inquiry. Only the generated\nconcept dbo:Occupation is non-existent. All remaining nodes and edges comply\nwith the rules of the ontology, even if the concepts used are derived through fur-\nther subclass relationships. The resulting diagram is shown in the Supplemental\nOnline Resources.\nWhile prompt 6 leads to a result that can be more comprehensively achieved\nwith conventional tools for visualizing RDF, the result from prompt7 provides an\noverview of concepts (classes) and properties that can be used to relate instances\nof these classes to each other.\n5 Conclusion and Future Work\nFrom the perspective of a knowledge graph engineer, ChatGPT has demon-\nstrated impressive capabilities. It successfully generated knowledge graphs from\nsemi-structured textual data, translated natural language questions into syn-\ntactically correct and well-structured SPARQL queries for the given knowl-\nedge graphs, and even generated overview diagrams for large knowledge graph\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 113\nschemas, as outlined in Sect.4. An detailed analysis revealed that the generated\nresults contain mistakes, of which some are subtle. For some use cases, this might\nbe harmless and can be tackled with additional validation steps in general, like\nwith the metrics we used for SPARQL queries. In general, our conclusion is, that\none needs to keep in mind ChatGPT’s tendency tohallucinate\n9, especially when\napplied to the ﬁeld of knowledge graph engineering where many engineers are\nused to mathematical precision and logic.\nThe closed-source nature of ChatGPT challenges scientiﬁc research on it in\ntwo ways: 1. Detailed capability ratings of closed-source probabilistic models\nrequire much eﬀort 2. Result reproducibility is bound to service availability and\nresults might be irreproducible at a later date (due to service changes)\nThus, open training corpora and LLMS are mandatory for proper scientiﬁc\nresearch.\nIn the future, metrics are to be found to rate generated ChatGPT answers\nautomatically, like we broached with SPARQL queries. This again enables to\nextend the number of test cases for a speciﬁc experiment and to generate pro-\nfound statistical results. Another research focus should be given to methods that\nlet the LLM access a broader/necessary context to increase the chance for correct\nanswers.\nAcknowledgements This work was partially supported by grants from the German\nFederal Ministry for Economic Aﬀairs and Climate Action (BMWK) to the CoyPu\nproject (01MK21007A) and KISS project (01MK22001A) as well as from the Ger-\nman Federal Ministry of Education and Research (BMBF) to the project StahlDigital\n(13XP5116B) and project KupferDigital (13XP5119F).\nSupplemental Online Resources\nDetails on the experiments described can be found at the following github repo:\nhttps://github.com/AKSW/AI-Tomorrow-2023-KG-ChatGPT-Experiments\nReferences\n1. Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., ...\n& Zhang, Y. (Mar 2023). Sparks of artiﬁcial general intelligence: Early experiments\nwith gpt-4. https://doi.org/10.48550/ARXIV.2303.12712.\n2. Cagle, K. (Mar 2023). Nine chatgpt tricks for knowledge graph workers.\nhttps://www.thecaglereport.com/2023/03/16/nine-chatgpt-tricks-for-knowledge-\ngraph-workers/, Accessed: 14. Apr. 2023.\n3. Ekaputra, F. J., Llugiqi, M., Sabou, M., Ekelhart, A., Paulheim, H., Breit, A., ... &\nAuer, S. (Mar 2023). Describing and organizing semantic web and machine learning\nsystems in the swemls-kg. https://doi.org/10.48550/ARXIV.2303.15113.\n4. Haque, M. U., Dharmadasa, I., Sworna, Z. T., Rajapakse, R. N., & Ahmad, H. (Dec\n2022). “i think this is the most disruptive technology”: Exploring sentiments of\nchatgpt early adopters using twitter data. https://doi.org/10.48550/ARXIV.2212.\n05856.\n9 Generation of content without any foundation\n114 L. P. Meyer et al.\n5. Kalici´nski, K. (Jan 2023). Create neo4j database model with chatgpt.\nhttps://neo4j.com/developer-blog/create-neo4j-database-model-with-chatgpt/,\nAccessed: 14. Apr. 2023.\n6. Lin, W., Babyn, P., yan, Y., & Zhang, W. (Mar 2023). Context-based ontology mod-\nelling for database: Enabling chatgpt for semantic database management. https://\ndoi.org/10.48550/ARXIV.2303.07351.\n7. Omar, R., Mangukiya, O., Kalnis, P., Mansour, & E. (Feb 2023). Chatgpt versus tra-\nditional question answering for knowledge graphs: Current status and future direc-\ntions towards knowledge graph chatbots. https://doi.org/10.48550/ARXIV.2302.\n06466.\nLLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT 115\nOpen Access Dieses Kapitel wird unter der Creative Commons Namensnen-\nnung 4.0 International Lizenz ( http://creativecommons.org/licenses/by/4.0/deed.\nde)v e r ¨oﬀentlicht, welche die Nutzung, Vervielf¨ altigung, Bearbeitung, Verbreitung\nund Wiedergabe in jeglichem Medium und Format erlaubt, sofern Sie den/die\nurspr¨unglichen Autor(en) und die Quelle ordnungsgem¨ aßnennen, einen Link zur\nCreative Commons Lizenz beif¨ ugen und angeben, ob ¨Anderungen vorgenommen\nwurden.\nDie in diesem Kapitel enthaltenen Bilder und sonstiges Drittmaterial unterliegen\nebenfalls der genannten Creative Commons Lizenz, sofern sich aus der Abbildungsle-\ngende nichts anderes ergibt. Sofern das betreﬀende Material nicht unter der genannten\nCreative Commons Lizenz steht und die betreﬀende Handlung nicht nach gesetzlichen\nVorschriften erlaubt ist, ist f¨ur die oben aufgef¨uhrten Weiterverwendungen des Mate-\nrials die Einwilligung des jeweiligen Rechteinhabers einzuholen."
}