{
  "title": "Precise individual muscle segmentation in whole thigh CT scans for sarcopenia assessment using U-net transformer",
  "url": "https://openalex.org/W4391657487",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5082649982",
      "name": "Hyeon Su Kim",
      "affiliations": [
        "Inha University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5101876083",
      "name": "Hyunbin Kim",
      "affiliations": [
        "Inha University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5102615156",
      "name": "Shinjune Kim",
      "affiliations": [
        "Inha University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5043883809",
      "name": "Yonghan Cha",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5043818973",
      "name": "Jung-Taek Kim",
      "affiliations": [
        "Ajou University"
      ]
    },
    {
      "id": "https://openalex.org/A5100372671",
      "name": "Jin Woo Kim",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5013538373",
      "name": "Yong‐Chan Ha",
      "affiliations": [
        "Bumin Hospital Group"
      ]
    },
    {
      "id": "https://openalex.org/A5087702584",
      "name": "Jun‐Il Yoo",
      "affiliations": [
        "Inha University Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3015936016",
    "https://openalex.org/W2897513125",
    "https://openalex.org/W3005437800",
    "https://openalex.org/W2138699295",
    "https://openalex.org/W4221033187",
    "https://openalex.org/W2910295065",
    "https://openalex.org/W2945329470",
    "https://openalex.org/W2992300992",
    "https://openalex.org/W1993947467",
    "https://openalex.org/W3160082876",
    "https://openalex.org/W3119668554",
    "https://openalex.org/W3137561054",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W4206693420",
    "https://openalex.org/W3038091703",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W2898146684",
    "https://openalex.org/W2158818043",
    "https://openalex.org/W3112139896",
    "https://openalex.org/W2972629588"
  ],
  "abstract": null,
  "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports\nPrecise individual muscle \nsegmentation in whole thigh CT \nscans for sarcopenia assessment \nusing U‑net transformer\nHyeon Su Kim 1*, Hyunbin Kim 1, Shinjune Kim 1, Yonghan Cha 2, Jung‑Taek Kim 3, \nJin‑Woo Kim 4, Yong‑Chan Ha 5 & Jun‑Il Yoo 6*\nThe study aims to develop a deep learning based automatic segmentation approach using the \nUNETR(U‑net Transformer) architecture to quantify the volume of individual thigh muscles(27 muscles \nin 5 groups) for Sarcopenia assessment. By automating the segmentation process, this approach \nimproves the efficiency and accuracy of muscle volume calculation, facilitating a comprehensive \nunderstanding of muscle composition and its relationship to Sarcopenia. The study utilized a dataset \nof 72 whole thigh CT scans from hip fracture patients, annotated by two radiologists. The UNETR \nmodel was trained to perform precise voxel‑level segmentation and various metrics such as dice score, \naverage symmetric surface distance, volume correlation, relative absolute volume difference and \nHausdorff distance were employed to evaluate the model’s performance. Additionally, the correlation \nbetween Sarcopenia and individual thigh muscle volumes was examined. The proposed model \ndemonstrated superior segmentation performance compared to the baseline model, achieving higher \ndice scores (DC = 0.84) and lower average symmetric surface distances (ASSD = 1.4191 ± 0.91). The \nvolume correlation between Sarcopenia and individual thigh muscles in the male group. Furthermore, \nthe correlation analysis of grouped thigh muscles also showed negative associations with Sarcopenia \nin the male participants. This thesis presents a deep learning based automatic segmentation approach \nfor quantifying individual thigh muscle volume in sarcopenia assessment. The results highlights the \nassociations between Sarcopenia and specific individual muscles as well as grouped thigh muscle \nregions, particularly in males. The proposed method improves the efficiency and accuracy of muscle \nvolume calculation, contributing to a comprehensive evaluation of Sarcopenia. This research enhances \nour understanding of muscle composition and performance, providing valuable insights for effective \ninterventions in Sarcopenia management.\nKeywords Sarcopenia, Computed tomographic, Thigh, Muscles, Hip fracture\nSarcopenia, a condition characterized by age-related loss of muscle mass, strength and function, has garnered \nsignificant attention in recent years. As research progresses, there has been a shift in the consensus and focus \nfrom solely considering total muscle volume to exploring muscle quality and performance  factors1. Understand-\ning the intricate relationship between muscle composition, function and overall health has become crucial in \ndeveloping effective interventions for individuals at risk of or affected by  sarcopenia2.\nThe diagnostic consensus of Sarcopenia has been revised in recent years to improve accuracy and standardi-\nzation. In 2019, known as EWGSOP2 and AWGS2019, introduced diagnostic criteria that consider multiple \n parameters3,4. These criteria include calf circumference, grip strength, SARC_f questionnaire and assessments \nof limb muscle mass using techniques such as Dual-energy X-ray absorptiometry (DXA) and Bioelectrical \nOPEN\n1Department of Biomedical Research Institute, Inha University Hospital, Incheon, South Korea. 2Department \nof Orthopaedic Surgery, Daejeon Eulji Medical Center, Daejeon, South Korea. 3Department of Orthopedic \nSurgery, Ajou University School of Medicine, Suwon, South Korea. 4Department of Orthopaedic Surgery, Nowon \nEulji Medical Center, Seoul, South Korea. 5Department of Orthopaedic Surgery, Seoul Bumin Hospital, Seoul, \nSouth Korea. 6Department of Orthopedic Surgery, School of Medicine, Inha University Hospital, Incheon, South \nKorea. *email: lemonjames96@gmail.com; furim@hanmail.net\n2\nVol:.(1234567890)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nImpedance Analysis (BIA). These updated guidelines reflect a more comprehensive approach to Sarcopenia \ndiagnosis, incorporating not only muscle mass but also functional measures and patient-reported performance \noutcomes.\nNumerous studies have investigated the use of cross-sectional area measurements as a proxy for muscle assess-\nment. For instance, the study by Miller et al. revealed that hip joint fracture caused the asymmetry of muscle \ncross-sectional area and intermuscular adipose tissue in CT  scan5. In the paper, thigh muscle cross-sectional \narea (CSA) was less on the side of the fracture by 9.2  cm2 (95% CI 5.9, 12.4  cm2), whereas the CSA of IMAT was \ngreater by 2.8  cm2 (95% CI 1.9, 3.8   cm2) on the fractured side. Another study by Jung et al. showed significant \nreduction in muscle mass in the hip flexor (iliopsoas and rectus femoris) were observed on postoperative CT \nscans. These findings imply targeted exercise for the hip flexor may be beneficial in rehabilitation of hip  fractures6. \nFurthermore, the study by Byun et al. indicated measuring psoas cross-sectional area (PCA) has potential as a \ndiagnostic tool for  sarcopenia7. Notably, the study found the lowest quintile of PCA was significantly associated \nwith mortality in females, with hazard ratio of 1.76 (95% CI 1.05–2.70, p = 0.017).\nBy quantifying the muscle area in a single plane, these works aimed to assess muscle size and identify individ-\nuals at risk of Sarcopenia. However, this approach has limitations. Sole reliance on cross-sectional area overlooks \nthe complexity of individual muscle groups and fails to capture important aspects such as muscle composition, \ndistribution, and overall  performance8. Moreover, factors such as participant positioning, limb orientation and \nthe choice of imaging plane can influence the accuracy and comparability of cross-sectional area measurements.\nAcquiring the volume of each individual muscle by calculating the annotated segmentation mask is achiev-\nable. However, manual segmentation on CT scans is a time-intensive, laborious, and costly task that requires \nsignificant effort and expertise. The process often exhibits high variation due to the difficulty of differentiating \ntissue characteristics. CT scans primarily provides excellent visualization of bony structures and dense tissues, \nbut it has limitations in differentiating soft tissues such as muscles. Muscles have similar radiodensity, making \nit challenge to distinguish individual muscles based on CT scans. Nevertheless, achieving precise voxel-level \nsegmentation is essential for accurately quantifying each individual muscle’s volume and gaining comprehensive \ninsights into muscle  performance9.\nTo address these challenges, we propose a deep learning-based automatic individual muscle segmentation \napproach by using UNETR model. This approach leverages the power of deep learning algorithms to learn \nintricate muscle features and perform precise segmentation at the voxel level. By automating the segmentation \nprocess, our proposed method enables efficient and accurate calculation of each individual muscle’s volume.\nThe objective of our study is to automate segmentation, quantify the volume of individual thigh muscles and \nexamine how each individual thigh muscle contributes to performance and impacts to Sarcopenia. This approach \nholds great promise for advancing sarcopenia assessment, providing a more comprehensive understanding of \nmuscle quality and performance in individuals affected by this condition.\nMethods\nStudy design\nIn this study, we trained an AI model that segments individual muscles from whole thigh level CT scan and cal-\nculates each individual muscle volume for Sarcopenia evaluation. The study utilized a dataset of 72 (train: 60 and \nvalidation: 12) whole thigh CT scans obtained from 72 hip fracture patients at Gyeongsang National University \nHospital. The dataset was annotated by two radiologists, providing ground truth for training and validation of \nthe AI model. The study adhered to the principles of the Declaration of Helsinki and was approved by the IRB \nat Gyeongsang National University Hospital. All research procedures were carried out with strict adherence to \nethical standards, including protection of participants’ privacy, confidentiality, and rights.\nIn this study, we employ a semantic segmentation model to calculate muscle volume, as discussed in the “Deep \nlearning method of automatic muscle segmentation” section. This model operates by classifying each pixel in an \nimage into distinct categories. In the context of muscle segmentation in CT scans, this means identifying and \ncategorizing each pixel as part of a particular muscle or as background. Capturing intricate details and variations \nin the images is vital because muscles have complex structures and can vary significantly between individuals. \nAccurate segmentation requires the model to recognize these subtle differences, ensuring precise analysis and \nassessment of sarcopenia.\nFor the segmentation task, we utilized the state-of-the-art deep learning model, UNETR, designed for precise \nvoxel level segmentation and sequential information. This architecture provided the foundation for our AI model \nto achieve high-quality segmentation results.\nThe model’s performance was evaluated using various metrics, including dice score (DC), average symmetric \nsurface distance (ASSD), relate absolute volume difference (RAVD), volume correlation (VC) and hausdorff  \ndistance (HD)10,11. To validate the robustness of the trained AI model, the predicted individual muscle segments \nwere compared with manual segmentations performed by two radiologists. The study design encompassed \nrigorous statistical analyses to evaluate the performance of the trained AI model and assess its clinical utility in \nSarcopenia assessment.\nCT scans acquisition\nThe study comprised 72 CT scans with annotation from a cohort of 98 participants who had been diagnosed with \nhip fractures. The mean age of the participants was 77.3  ± 9.73 (standard deviation) years. The CT scans were \nperformed in supine position (Head-First Supine and Feat-First Supine), covering the entire thigh region from \nhip to knee joint which we call the whole thigh level CT scans. The participants were recruited from Gyeongsang \nNational University Hospital between December 2016 and June 2022.\n3\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nAs demonstrated in Fig.  1, the inclusion criteria consisted of age over 50 years, stable medical conditions, \nand no contraindications to CT scanning. To ensure the reliability and accuracy of the muscle segmentation \nfor Sarcopenia assessment, certain exclusion criteria including lower limb amputation, femur shaft fracture, \nsubtrochanteric fracture, muscle or bone deformities and substantial metal artifacts on imaging were applied.\nAs lower limb amputations cases could introduce significant anatomical variations that would affect accurate \nmuscle segmentation. Participants with shaft fractures were excluded due to the potential muscle distortion \ncaused by the angulation of the two parts of the broken femur observed on CT scans was excluded to mini-\nmize confounding factors introduced by the fractured femur. Participants with muscle or bone deformities and \nsubstantial metal artifacts on imaging were also excluded, as these factors could interfere with the quality and \nreliability of subsequent muscle segmentation on CT scans.\nBy implementing these criteria, we aimed to create a homogeneous study population and minimize poten -\ntial confounding factors that could affect the analysis of muscle segmentation for Sarcopenia assessment in hip \nfracture patients.\nCT examinations and ground truth labeling\nIn this study, we classified 30 classes including iliac, femur and background within 5 major thigh muscle groups \non hip to knee joint CT scans (whole thigh). The 5 major thigh muscle groups comprised Anterior, Medial and \nPosterior thigh muscles, Gluteal region muscle and else.\nThe classification of 5 muscles in the Anterior thigh included Sartorius, Rectus femoris and Vastus muscles \n(lateralis, intermedius and medialis). In the medial thigh, we categorized the 5 muscles as Adductor (magnus, bre-\nvis and longus), gracilis and pectineus. The Posterior thigh muscles were classified as Semitendinosus, Semimem-\nbranosus and Biceps femoris. In the Gluteal region, the 8 muscles were categorized as Gluteus (maximus, medius \nFigure 1.  Dataflow. The data flow of the study. In 478 hip fracture patients CT datasets from GNUH between \nDecember 2016 and June 2022, the inclusion criteria consisted of age over 50, stable medical condition and \nno contraindications to CT scanning. Exclusion criteria encompassed such ad missing hip to knee joint cuts, \nvariations in scanning protocols, lower limb amputations, femur shaft fractures, subtrochanteric fractures, \nmuscle or bone deformities, substantial metal artifacts on imaging and other image processing factors that could \naffect data quality. Out of 478 participants, the final dataset of 98 participants was deemed suitable for the study’s \nobjectives.\n4\nVol:.(1234567890)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nand minimus), Fascia latae, Piriformis, Obturator (internus and externus) and Quadratus femoris. Additionally, \nthe Iliacus, Iliopsoas, Psoas, Abdominal oblique, Rectus abdominis, Multifidus, Femur bone, Iilac bone and \nbackground on image were classified separately. The example of ground truth image has been displayed in Fig. 2.\nThe manual annotation process was performed by two experienced radiologists who utilized 3D Slicer and \nMonai label as annotation tool. 3D slicer, a DICOM viewer program, provides annotation tools such as brush, \neraser, and growth from seeds. The growth from seeds method enables the indication of tissue regions based on \nbrushed area in three dimensions and this functionality was developed by 3D slicer. On the other hand, Monai \nlabel was employed as server client application, facilitating an efficient annotation workflow by managing the \nsegmentation list and data organization in a regulated manner.\nPre‑processing\nIn the pre-processing phase, several heuristic methods were applied to enhance the deep learning performance \nin vision tasks. Initially, the intensity range of the CT scan images was scaled from − 57 to 164 to improve \nthe distinction of individual muscle tissues within the CT  scans12,13. Following this, contrast adjustment was \nperformed using a gamma value of 2, to further enhance the visibility of muscle tissues. The resulting image \ndisplayed in Fig. 3 with enhanced contrast was then cropped to only foreground region. The pixel dimensions of \nthe input image and annotation mask were rescaled with scaling factors of (1.5, 1.5, 2.0) using bilinear interpola-\ntion for input image and nearest interpolation for annotation mask. Additionally, each image was cropped into \nfour images with a shape of (96, 96, 96) which will be converted into non-overlapping patches of (16, 16, 16) to \nfacilitate the subsequent segmentation  process14,15. By cropping and rescaling the images, we ensured that the \nmodel concentrated on the most relevant areas, thereby reducing the computational burden and enhancing the \noverall efficiency of the segmentation process.\nDeep learning method of automatic muscle segmentation\nOur study is centered around the task of semantic segmentation which is a crucial task in the field of computer \nvision, particularly in medical imaging. It serves to delineate and classify different regions of interest within an \nFigure 2.  Ground truth image (3D).\nFigure 3.  Pre-processing procedure. Presents image pre-processing result.\n5\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\n image16. In the context of muscle segmentation, semantic segmentation involves assigning each voxel in the \nimage to a specific class, such as muscle tissue, bone tissue and background. The main challenge in semantic \nsegmentation is the accurate capture of the intricate details and variations in the images, including different \npatients’ size, position and tissue textures, while also dealing with noise and other imaging artifacts. Due to the \nambiguity of each individual muscle tissue in CT scans, our study requires precise voxel-level  segmentation9. For \nthe automatic segmentation process, we adopted the architecture of the UNETR model demonstrated in Fig. 4 14.\nThe UNETR model leverages the power of transformers, which have shown exceptional performance in \ntimeseries domain including Natural Language Process (NLP). The task of 3D medical image segmentation is \nre-envisioned as a sequence and the UNETR model employs a transformer as the encoder to learn sequence \nrepresentations of the input volume, effectively capturing global multi-scale information. The encoder follows \na U-shaped design, reminiscent of the original U-net architecture, which is known for its success in biomedical \nimage segmentation. The transformer encoder is directly connected to a decoder via skip connections at dif-\nferent resolutions, allowing for the computation of the final semantic segmentation output. This design enables \nthe model to capture both high-level contextual information and low-level spatial details, making it particularly \neffective for the individual thigh muscle segmentation.\nTraining of automatic muscle segmentation model\nThe training procedure was conducted on a DGX A100 workstation provided by NVIDIA, equipped with Nvidia \nA100 GPU and running on the Ubuntu 20.04 operating system. The deep learning based segmentation model \nutilized Pytorch and Monai frameworks for its implementation. During the model training, the dice coefficient \nwas employed as the loss function, which is a common choice for semantic segmentation  tasks17. The hyper \nparameters of AdamW optimizer were configured with a learning rate of 8e − 5, weight decay of 1e − 5, batch size \nof 2 and 5000 epochs. The configuration was determined through a grid search approach, where various values \nwere explored within a learning rate range of 1e − 3 to 1e − 5. The decision of hyperparameters was determined \nthrough heuristic techniques, due to their demonstrated capability to achieve the best performance in current \ndatasets for the muscle segmentation model.\nIntraclass correlation coefficient (ICC)\nTo assess the consistency of the predicted results in medical images, we computed the Intraclass Correlation \nCoefficient (ICC) value between the manual segmentation masks annotated by two researchers and the predicted \nmasks generated by our proposal model using whole thigh CT scans. The ICC is a statistical measure used to \nratings performed on the same subjects or objects. The ICC value based on 95% confident interval, it is generally \nFigure 4.  UNETR architecture. Presents overview of the UNETR architecture. This model utilizes the \ntransformer to extract sequence representations from multiple layers and these represents are merged with the \ndecoder through skip connections. The output sizes shown in the figure correspond to a patch dimension of \nN = 16 and an embedding size of C = 768.\n6\nVol:.(1234567890)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\naccepted that the values below 0.5 indicate poor, between 0.5 and 0.75 indicate moderate, 0.75 and 0.9 indicate \ngood and greater than 0.90 are excellent  reliability18.\nBy calculating the ICC value, we aimed to determine the level of agreement between the manual annotations \nand the predictions, thereby assessing the consistency and reliability of the model’s performance.\nEvaluation metrics\nIn evaluating the performance of our model, we employed several metrics to assess its accuracy, including (1) \nDice score (DC), (2) Average symmetric surface distance (ASSD), (3) Volume correlation (VC), (4) Relative \nabsolute volume difference (RAVD) and (5) Hausdorff distance (HD)10,11.\nThe (1) Dice score (DC) measures the overlap between the model’s segmentation results and the ground truth, \nproviding a clear indication of the model’s accuracy in segmenting muscles. The (2) Average Symmetric Surface \nDistance (ASSD) calculates the mean distance between the contours of the predicted and actual segmentations, \nshowcasing the model’s ability to precisely outline muscle shapes. (3) Volume Correlation (VC) evaluates the \ncorrelation between the segmented and actual muscle volumes, demonstrating the model’s accuracy in vol-\nume estimation. The (4) Relative Absolute Volume Difference (RAVD) sheds light on the volume discrepancies \nbetween the model’s segmentation and the ground truth, acting as a gauge of the model’s consistency in volume \nrepresentation. The (5) Hausdorff Distance (HD) measures the greatest distance between the surfaces of the \npredicted and actual segmentations, ensuring the accuracy of the segmentation right up to its furthest points, \nthus emphasizing the model’s capability in accurately defining muscle boundaries.\nEach metrics has own advantages and limitations, allowing us to comprehensively evaluate performance of \nthe models in various aspects.\nThe (1) Dice score, also known as F1 score, quantifies the overlap between the predicted segmentation and \nthe ground truth. It is calculated as twice the intersection of the predicted and ground truth regions divided by \nthe sum of their individual volumes.\nThe Dice score metric captures both true positive and false positive predictions and is widely utilized due \nto interpretability. However, Dice score can be sensitive to imbalanced classes, penalizing false negatives more \nheavily.\nThe (2) Average symmetric surface distance measures the average distance between the predicted surface and \nthe ground truth surface that it provides insight into localization accuracy.\nHowever, the ASSD does not consider volumetric differences and is influenced by outliers.\n(3) Volume correlation quantifies the correlation between predicted and ground truth volumes, indicating \noverall size agreement.\nThe Volume correlation is calculated by using Pearson’s correlation and it’s only calculated with the volume \nof predicted and ground truth, thus, it tends to ignore the spatial correspondence and may not capture localized \nerrors.\nThe (4) Relative absolute volume difference measures the percentage of difference between predicted and \nground truth volumes, indicating volume estimation accuracy.\nBut it also does not capture spatial correspondence.\nThe (5) Hausdorff Distance measures the maximum distance between predicted and ground truth surfaces, \nindicating worst-case localization error, so it’s sensitive to outliers, influenced by noise and does not consider \nvolumetric.\nDice Score= 2TP\n2TP + 2FP + FN\nASSD = 1\nN\nn∑\ni=1\n(|di− di′|)\ndi = Distance from each surface point on the predicted\nsurface to the nearest point on the ground truth\ndi′= Distance from each surface point on the ground truth\nsurface to the nearest point on the predicted surface\nVolume Correlation =\n(\ncov(gp, gt)\n)\n√\nVar (V P ) × var\n(\nVg t\n)\nRAVD = VP − Vgt\nVgt\n× 100\nHD = max(h(P, G), h(G, P))\n7\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nEthical standards\nThe study adhered to the principles of the Declaration of Helsinki and was approved by the IRB at Gyeongsang \nNational University Hospital. (IRB No. GNUH 2022-01-032-008). All research procedures were carried out with \nstrict adherence to ethical standards, including protection of participants’ privacy, confidentiality, and rights.\nResult\nPrediction performance\nThe prediction performance of our model was evaluated using various metrics through a cross validation method \ndue to limited number of datasets available (60 training samples and 12 validation samples). The evaluation \nresult of the model performance shown in the Fig.  5, among these metrics, the highest average Dice score of \neach individual thigh muscle class prediction of our model was 0.84 which is 0.1 higher than baseline(3D U-net, \n0.69) model for the validation datasets. The Dice score provides a measure of the overlap between the predicted \nand ground truth. Our model achieved a substantial Dice score, indicating a high level of agreement between \nthe predicted muscle segmentations and the ground truth annotations.\nThe average ASSD (Average Symmetric Surface Distance) of individual thigh muscle classes was 1.4191 ± 0.91 \nwhich is 6.9863 less than baseline (3D U-net, 8.4054 ± 13.36) model for the validation datasets. The Average \nsymmetric surface distance provides insight into localization accuracy between the predicted and ground truth.\nOur proposal model achieved an average volume correlation of 0.968 for each individual muscle class in the \nvalidation datasets, indicating a high level of accuracy in estimating the volume of each muscle. The Volume \ncorrelation metric measures the correlation between the ground truth segmentation mask’s volume and the \npredicted segmentation mask’s volume. The Volume correlation metric has limitations in capturing local voxel \naccuracy, as it primarily focuses on the correlation of overall volumes. However, when considering the perspec-\ntive of each individual muscle volume, the high Volume correlation result demonstrates the robust performance \nof our model in accurately estimating the volumes of individual muscles. This outcome highlights the model’s \nability to provide reliable and precise muscle volume assessments.\nUpon analyzing the result image in Fig. 6, it was observed that the baseline model, lacking sequence informa-\ntion, tended to predict the area of femur area to iliac region. In contrast, our proposal model exhibited accurate \npredictions in this region. Considering this observation and the difference in Dice scores, our findings suggest \nthat our proposal model outperforms the baseline model in reducing false negative and false positives in local \nsegmentation voxels.\nIn our hip fracture cohort, we investigated 69 participants and assessed their Skeletal Muscle Index (SMI). \nThe diagnosis of Sarcopenia was made based on the consensus standards, with a cutoff value of 5.4 for females \nand 7 for males, as defined by the Asian Working Group for Sarcopenia (AWSG2019)4. Out of total participants, \nFigure 5.  Model performance evaluation. Comparison between proposal model UNETR and baseline model \nU-net. The table displays average evaluation result of metrics DC (Dice Score), ASSD (Average Symmetric \nSurface Distance), HD (Hausdorff Distance), RAVD (Relative Absolute Volume Difference) and VC (Volume \nCorrelation) on datasets. This indicates our proposal model UNETR shows higher dice score including other \nmetrics. Notably, the RAVD result suggests that quantifying each individual muscle by using proposal model’s \nautomatic segmentation method is a robust approach.\n8\nVol:.(1234567890)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\n41 patients were diagnosed with Sarcopenia (20 females and 21 males), while 28 participants were classified as \nnon-Sarcopenia (23 females and 5 males).\nTo examine the relationship between Sarcopenia and individual thigh muscle volumes, we calculated the \nvolume of each individual muscle for all participants and adjusted the volume using the SMI calculation formula \n( mm 3\nheight2 ) from our automatic segmentation model. We then compared the correlation between Sarcopenia and \neach individual thigh muscles.\nThe result, as depicted in Fig.  7, revealed that in the female group, there were no significant correlations \nobserved between Sarcopenia and the volume of individual thigh muscles. However, in the male group, several \nmuscles showed significant negative correlation with Sarcopenia. These included the sartorius (r = − 0.73), vastus \n(lateralis r = − 0.76, intermedius r = − 0.78 and medialis r = − 0.74), adductor (longus r = -0.77, brevis r = − 0.82 \nand magnus r = − 0.8), gluteus maximus (r = − 0.78), obturator externus (r = − 0.83), semitendinosus (r  = − 0.7), \nsemimembranosus (r = − 0.75) and biceps femoris (r = − 0.72).\nFurthermore, we investigated the correlation between Sarcopenia and grouped thigh muscles, as illustrated \nin Fig. 8. In the male group, significant negative correlations were observed between Sarcopenia and the anterior \nthigh muscle group (r = − 0.77), medial thigh muscle group (r = − 0.81), gluteal region muscle group (r = − 0.75) \nand posterior thigh muscle group (r = − 0.77).\nConclusions\nDiscussion\nAs the consensus and research on Sarcopenia shift focus from total muscle volume to muscle performance, our \nstudy presents a novel approach to calculating individual muscle volume in the thigh using CT scans. We utilized \na deep learning-based segmentation method, which significantly reduced the manual segmentation time of 30 \nclasses on whole thigh CT scan by a factor of almost 900. The average processing time for automatic segmenta-\ntion per scan was less than 20 s, demonstrating the efficiency of our method and its potential for scaling up to \nlarge datasets. The findings presented in the “Result” section suggest that there are notable associations between \nSarcopenia and specific individual muscles as well as grouped thigh muscle regions, particularly in the male \nparticipants. These results contribute to our understanding of the relationship between Sarcopenia and thigh \nmuscle composition, highlighting the importance of assessing muscle volume in Sarcopenia evaluation.\nLimitation\nOur current study, while promising, does present several limitations. The first limitation is inadequate implants \nand fractures of femur shaft and subtrochanteric. These specific conditions, which are frequently encountered \nin real-world scenarios, may have influenced the accuracy and applicability of our result. The complexity and \nvariability introduced by these conditions could potentially affect the model’s performance. As a future direction, \nwe plan to enrich our training dataset with a diverse range of cases, including those with implants and other \nFigure 6.  Prediction example image of baseline and proposal model. Example images of segmentation result.\n9\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nartifacts. This approach will not only enhance the robustness of our model but also extend its applicability to a \nbroader range of real-world scenarios.\nThe second limitation of our current study is related to label noise. The presence of label noise and diversity \nin our dataset could potentially lead to less precise segmentation results. This noise is primarily due to time-\nintensive and laborious manual segmentation process. Furthermore, the diversity in CT scans is attributed to \nthe challenge of distinguishing individual muscle tissues concretely in CT scans. To address this issue, our future \nwork will focus on minimizing the label noise and diversity in our dataset. We intend to employ unsupervised \nFigure 7.  Heatmap between Sarcopenia and individual thigh muscles. Presents a heatmap illustrating the \nrelationship between Sarcopenia and individual thigh muscles grouped by gender. Panel (A) represents the \nfemale group, while panel (B) represents the male group. In the male group, several muscles showed significant \nnegative correlation with Sarcopenia. The sartorius (r = − 0.73), vastus (lateralis r = − 0.76, intermedius r = − 0.78 \nand medialis r = − 0.74), adductor (longus r = − 0.77, brevis r = − 0.82 and magnus r = − 0.8), gluteus maximus \n(r = − 0.78), obturator externus (r = − 0.83), semitendinosus (r = − 0.7), semimembranosus (r = − 0.75) and biceps \nfemoris (r = − 0.72) displayed significant correlations.\nFigure 8.  Heatmap between Sarcopenia and thigh muscle groups. Presents a heatmap illustrating the \nrelationship between Sarcopenia and grouped thigh muscles grouped by gender. Panel (A) represents the \nfemale group, while panel (B) represents the male group. In the male group, significant negative correlations \nwere observed between Sarcopenia and the anterior thigh muscle group (r = − 0.77), medial thigh muscle group \n(r = − 0.81), gluteal region muscle group (r = − 0.75) and posterior thigh muscle group (r = − 0.77).\n10\nVol:.(1234567890)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nlearning methos to detect and rectify inconsistencies in the labels. Through the refinement of our dataset, we aim \nto enhance the accuracy of our segmentation results and improve the overall efficacy of our model.\nConclusions\nOur study offers a reliable and effective option for segmenting hip to thigh CT scans, enhancing the speed and \nconsistency of calculating the volume of individual thigh muscles. This approach not only streamlines the process \nbut also increases the accuracy of the measurements, making it a valuable tool for researchers and clinicians alike.\nFurthermore, we propose the use of individual muscle volume as a quantitative assessment for Sarcopenia \nevaluation. This approach aligns with the current shift in focus towards muscle performance in Sarcopenia \nresearch and has the potential to provide more nuanced and accurate assessments of this condition.\nData availability\nThe data used in this study were collected at Gyeongsang National University Hospital, and inquiries about the \ndata should be directed to the author J.I.Y .\nReceived: 19 July 2023; Accepted: 4 February 2024\nReferences\n 1. Santilli, V ., Bernetti, A., Mangone, M. & Paoloni, M. Clinical definition of sarcopenia. Clin. Cases Miner. Bone Metab Off. J. Ital. \nSoc. Osteoporos. Miner. Metab. Skelet. Dis. 11, 177–180 (2014).\n 2. Arnold, W . D. & Padilla Colón, C. J. Maintaining muscle function across the lifespan: The state of science. Am. J. Phys. Med. Rehabil. \n99, 1171–1176 (2020).\n 3. Cruz-Jentoft, A. J. et al. Sarcopenia: Revised European consensus on definition and diagnosis. Age Ageing 48, 16–31 (2019).\n 4. Chen, L.-K. et al. Asian working group for sarcopenia: 2019 consensus update on sarcopenia diagnosis and treatment. J. Am. Med. \nDir. Assoc. 21, 300-307.e2 (2020).\n 5. Miller, R. R. et al. Asymmetry in CT scan measures of thigh muscle 2 months after hip fracture: The Baltimore hip studies. J. \nGerontol. A. Biol. Sci. Med. Sci. 70, 753–756 (2015).\n 6. Jung, S. Y ., Kim, H. J. & Oh, K. T. Comparative analysis of preoperative and postoperative muscle mass around hip joint by com-\nputed tomography in patients with hip fracture. Hip Pelvis 34, 10–17 (2022).\n 7. Byun, S.-E., Kim, S., Kim, K.-H. & Ha, Y .-C. Psoas cross-sectional area as a predictor of mortality and a diagnostic tool for sarco-\npenia in hip fracture patients. J. Bone Miner. Metab. 37, 871–879 (2019).\n 8. Honkanen, T. et al. Cross-sectional area of the paraspinal muscles and its association with muscle strength among fighter pilots: \nA 5-year follow-up. BMC Musculoskelet. Disord. 20, 170 (2019).\n 9. Hiasa, Y . et al. Automated muscle segmentation from clinical CT using Bayesian U-Net for personalized musculoskeletal modeling. \nhttps:// doi. org/ 10. 48550/ arXiv. 1907. 08915 (2019).\n 10. Zou, K. H. et al. Statistical validation of image segmentation quality based on a spatial overlap index. Acad. Radiol.  11, 178–189 \n(2004).\n 11. Nai, Y .-H. et al. Comparison of metrics for the evaluation of medical segmentations using prostate MRI dataset. Comput. Biol. \nMed. 134, 104497 (2021).\n 12. Masoudi, S. et al. Quick guide on radiology image pre-processing for deep learning applications in prostate cancer research. J. \nMed. Imaging 8, 010901 (2021).\n 13. Engelke, K., Museyko, O., Wang, L. & Laredo, J.-D. Quantitative analysis of skeletal muscle by computed tomography imaging—\nState of the art. J. Orthop. Transl. 15, 91–103 (2018).\n 14. Hatamizadeh, A. et al. UNETR: Transformers for 3D medical image segmentation. https:// doi. org/ 10. 48550/ arXiv. 2103. 10504 \n(2021).\n 15. Dosovitskiy, A. et al. An image is worth 16 × 16 words: Transformers for image recognition at scale. https:// doi. org/ 10. 48550/ arXiv. \n2010. 11929 (2021).\n 16. Wang, R. et al. Medical image segmentation using deep learning: A survey. IET Image Process. 16, 1243–1267 (2022).\n 17. Jadon, S. A survey of loss functions for semantic segmentation. in 2020 IEEE Conference on Computational Intelligence in Bioin-\nformatics and Computational Biology (CIBCB) 1–7 (2020). https:// doi. org/ 10. 1109/ CIBCB 48159. 2020. 92776 38.\n 18. Koo, T. K. & Li, M. Y . A guideline of selecting and reporting intraclass correlation coefficients for reliability research. J. Chiropr. \nMed. 15, 155–163 (2016).\nAcknowledgements\nThis work was supported by the National Research Foundation of Korea (NRF) Grant funded by the Korea \nGovernment (MSIT) (No. 2022R1C1C1004134).\nAuthor contributions\nH.S.K. and J.I.Y . conceived the study and designed the experiments. H.B.K., S.J.K., Y .H.C., J.T.K., J.W .K, and \nY .C.H. collected and analyzed the data. H.S.K. and J.I.Y . wrote the manuscript with comments from all authors. \nAll authors have read and approved the final version of the manuscript. All individuals included in this study \nhave given their informed consent for the publication of the results.\nCompeting interests \nThe authors declare no competing interests.\nAdditional information\nCorrespondence and requests for materials should be addressed to H.S.K. or J.-I.Y .\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\n11\nVol.:(0123456789)Scientific Reports |         (2024) 14:3301  | https://doi.org/10.1038/s41598-024-53707-8\nwww.nature.com/scientificreports/\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2024",
  "topic": "Sarcopenia",
  "concepts": [
    {
      "name": "Sarcopenia",
      "score": 0.946871280670166
    },
    {
      "name": "Segmentation",
      "score": 0.7134279012680054
    },
    {
      "name": "Thigh",
      "score": 0.6961038112640381
    },
    {
      "name": "Medicine",
      "score": 0.46127936244010925
    },
    {
      "name": "Computer science",
      "score": 0.40726619958877563
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2850117087364197
    },
    {
      "name": "Anatomy",
      "score": 0.24466705322265625
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210153373",
      "name": "Inha University Hospital",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I57664883",
      "name": "Ajou University",
      "country": "KR"
    },
    {
      "id": "https://openalex.org/I4210156402",
      "name": "Bumin Hospital Group",
      "country": "KR"
    }
  ]
}