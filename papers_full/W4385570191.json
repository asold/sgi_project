{
    "title": "AD-KD: Attribution-Driven Knowledge Distillation for Language Model Compression",
    "url": "https://openalex.org/W4385570191",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2225941986",
            "name": "Siyue Wu",
            "affiliations": [
                "Sun Yat-sen University"
            ]
        },
        {
            "id": "https://openalex.org/A2149851839",
            "name": "Hongzhan Chen",
            "affiliations": [
                "Sun Yat-sen University"
            ]
        },
        {
            "id": "https://openalex.org/A2099425862",
            "name": "Xiaojun Quan",
            "affiliations": [
                "Sun Yat-sen University"
            ]
        },
        {
            "id": "https://openalex.org/A2127284166",
            "name": "Qifan Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2036086788",
            "name": "Rui Wang",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3174544005",
        "https://openalex.org/W2977944219",
        "https://openalex.org/W4287869422",
        "https://openalex.org/W2998991762",
        "https://openalex.org/W2978017171",
        "https://openalex.org/W3153147196",
        "https://openalex.org/W4287907717",
        "https://openalex.org/W2934842096",
        "https://openalex.org/W3101066076",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W2943552823",
        "https://openalex.org/W3176614973",
        "https://openalex.org/W1787224781",
        "https://openalex.org/W4285199320",
        "https://openalex.org/W2970454332",
        "https://openalex.org/W3106325613",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W4303447594",
        "https://openalex.org/W3138154797",
        "https://openalex.org/W2594633041",
        "https://openalex.org/W3104033643",
        "https://openalex.org/W131533222",
        "https://openalex.org/W3105966348",
        "https://openalex.org/W2978670439",
        "https://openalex.org/W4298061300",
        "https://openalex.org/W1821462560",
        "https://openalex.org/W3034682120",
        "https://openalex.org/W2605409611",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W2944854690",
        "https://openalex.org/W2804897457",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W4292418834",
        "https://openalex.org/W2971296520",
        "https://openalex.org/W2970726176",
        "https://openalex.org/W2923014074",
        "https://openalex.org/W2964159778",
        "https://openalex.org/W3199246732",
        "https://openalex.org/W4285269381",
        "https://openalex.org/W2963846996",
        "https://openalex.org/W3092292656",
        "https://openalex.org/W3008374555",
        "https://openalex.org/W3101155149",
        "https://openalex.org/W2975429091",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W3034457371",
        "https://openalex.org/W2963748441",
        "https://openalex.org/W4288347855",
        "https://openalex.org/W1849277567"
    ],
    "abstract": "Knowledge distillation has attracted a great deal of interest recently to compress large language models. However, existing knowledge distillation methods suffer from two limitations. First, the student model simply imitates the teacher‚Äôs behavior while ignoring the reasoning behind it. Second, these methods usually focus on the transfer of sophisticated model-specific knowledge but overlook data-specific knowledge. In this paper, we present a novel attribution-driven knowledge distillation approach, which explores the token-level rationale behind the teacher model based on Integrated Gradients (IG) and transfers attribution knowledge to the student model. To enhance the knowledge transfer of model reasoning and generalization, we further explore multi-view attribution distillation on all potential decisions of the teacher. Comprehensive experiments are conducted with BERT on the GLUE benchmark. The experimental results demonstrate the superior performance of our approach to several state-of-the-art methods.",
    "full_text": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 8449‚Äì8465\nJuly 9-14, 2023 ¬©2023 Association for Computational Linguistics\nAD-KD: Attribution-Driven Knowledge Distillation for\nLanguage Model Compression\nSiyue Wu1, Hongzhan Chen1, Xiaojun Quan1‚àó, Qifan Wang2 and Rui Wang3\n1School of Computer Science and Engineering, Sun Yat-sen University, China\n2Meta AI\n3Vipshop (China) Co., Ltd., China\n1 {wusy39, chenhzh59}@mail2.sysu.edu.cn, quanxj3@mail.sysu.edu.cn\n2wqfcr@fb.com\n3mars198356@hotmail.com\nAbstract\nKnowledge distillation has attracted a great\ndeal of interest recently to compress pre-trained\nlanguage models. However, existing knowl-\nedge distillation methods suffer from two lim-\nitations. First, the student model simply imi-\ntates the teacher‚Äôs behavior while ignoring the\nunderlying reasoning. Second, these methods\nusually focus on the transfer of sophisticated\nmodel-specific knowledge but overlook data-\nspecific knowledge. In this paper, we present\na novel attribution-driven knowledge distilla-\ntion approach, which explores the token-level\nrationale behind the teacher model based on\nIntegrated Gradients (IG) and transfers attri-\nbution knowledge to the student model. To\nenhance the knowledge transfer of model rea-\nsoning and generalization, we further explore\nmulti-view attribution distillation on all poten-\ntial decisions of the teacher. Comprehensive\nexperiments are conducted with BERT on the\nGLUE benchmark. The experimental results\ndemonstrate the superior performance of our\napproach to several state-of-the-art methods.\n1 Introduction\nTransformer-based pre-trained language models\n(PLMs), such as BERT (Devlin et al., 2019)\nand RoBERTa (Liu et al., 2019), have aroused\nwidespread interest among Natural Language Pro-\ncessing (NLP) researchers in recent years. These\nlanguage models are first pre-trained on large-scale\nunlabeled corpora to learn the general representa-\ntion of language, and then fine-tuned on specific\ndownstream tasks to effectively transfer the gen-\neral knowledge to target domains. This pre-training\nand fine-tuning paradigm leads to state-of-the-art\nperformances in various NLP tasks such as nat-\nural language understanding. However, with the\nrapid growth of the model scale, the deployment of\nlarge-scale PLMs becomes challenging, especially\nin low-resource scenarios. To this end, a variety\n‚àóCorresponding author.\nInput Layer Output Layer\nIntermediate Layer\nEntailment\nResponse-based\nKnowledge\nFeature-based\nKnowledge\nRelation-based\nKnowledge\nAttribution-based\nKnowledge\nAttribution Score\n0.0 0.40.2\n‚ùì\nQuestion:\nWhat land was ceded to\nSpain ?\nüìú\nSentence:\nIt ceded French Louisiana\nwest of the Mississippi\nRiver ( including New\nOrleans ) to its ally Spain ,\nin compensation for\nSpain ' s loss to Britain of\nFlorida ‚Ä¶\n}\nfeatures from other data\nFigure 1: An example from the QNLI dataset (Rajpurkar\net al., 2016) to illustrate different knowledge distillation\ntechniques including the proposed attribution-driven\nmethod. Darker colors mean larger attribution scores.\nof model compression techniques have been devel-\noped. Among them, knowledge distillation (KD)\n(Hinton et al., 2015) is a newly emerging technol-\nogy that aims to obtain a small student model by\ndistilling knowledge from a large teacher model\nand achieve comparable performance.\nExisting knowledge distillation methods can be\ndivided into three categories, namely response-\nbased, feature-based, and relation-based (Gou et al.,\n2021). While response-based methods (Turc et al.,\n2019) directly distill the final output, e.g. prob-\nability distribution, from the top of the teacher,\nfeature-based (Sun et al., 2019) and relation-based\nmethods (Liu et al., 2022) try to align the features\nfrom intermediate layers of teacher and student\nmodels and minimize the difference. To transfer\ncomprehensive knowledge from the teacher, a com-\nmon practice is to combine response-based meth-\nods with the other two (Park et al., 2021). How-\never, due to the capacity gap between the teacher\nand the student, feature-based and relation-based\nmethods may not necessarily bring improvement\nto response-based methods (Liang et al., 2022).\nTo sum up, existing knowledge distillation meth-\nods have two limitations. First, they mainly focus\non understanding what the teacher‚Äôs behavior is,\ninstead of why the teacher behaves like this, hinder-\n8449\ning the reasoning and generalization ability of the\nstudent model. Second, they pay more attention to\ndistilling sophisticated model-specific knowledge\nfrom intermediate layers but neglect data-specific\nknowledge, which may contain valuable rationale\ninformation to understand how the teacher model\narrives at a prediction.\nTo address the above limitations, in this pa-\nper we propose a novel Attribution-Driven Knowl-\nedge Distillation (AD-KD) approach that transfers\nattribution-based knowledge from the teacher to the\nstudent. As shown in Figure 1, the attribution infor-\nmation reflects the importance of different tokens\ntowards the prediction, which contains reasoning\nknowledge of the model and can be complementary\nto the soft-label knowledge. By transferring such\nattribution knowledge, the student is allowed to\nlearn the token-level rationale behind the teacher‚Äôs\nbehavior and thus generalizes better. Specifically,\nwe utilize Integrated Gradients (IG) (Sundararajan\net al., 2017), a well-established gradient-based at-\ntribution method, to calculate the importance score\nof each input token. To reduce the influence of\ntrivial dimensions in the teacher‚Äôs input embed-\ndings, we further adopt the top-K strategy to filter\nout dimensions with low attribution scores. The\nremaining attribution scores are aggregated and\nnormalized to denote the importance of individual\ntokens. Moreover, we extract the attribution knowl-\nedge for all possible predictions rather than just the\nprediction with the highest probability. By trans-\nferring the multi-view attribution knowledge, the\nstudent learns a more comprehensive understand-\ning of the teacher‚Äôs soft-label distribution.\nExtensive experiments are conducted with BERT\n(Devlin et al., 2019) on the GLUE benchmark\n(Wang et al., 2018). The experimental results\ndemonstrate the effectiveness and superiority of\nour approach over several state-of-the-art baselines.\nFurthermore, we show that attribution knowledge\nfrom different layers contains different information,\nwhile the input layer contains the most prominent\nattribution knowledge for distillation. To summa-\nrize, the main contributions are threefold. First,\nwe propose a novel attribution-driven knowledge\ndistillation framework for language model com-\npression that effectively transfers attribution knowl-\nedge from the teacher to the student. Second, we\nextract multi-view attribution knowledge based on\nmodel predictions to learn comprehensive reason-\ning knowledge. Third, we systematically validate\nAD-KD on the GLUE benchmark and show its su-\nperior performance over state-of-the-art baselines.\n2 Related Work\n2.1 Knowledge Distillation\nKnowledge distillation methods can be divided into\nthree categories, namely response-based, feature-\nbased and relation-based KD (Gou et al., 2021).\nResponse-based KD was first proposed by Hinton\net al. (2015), where the final output is adopted to\ntransfer the label knowledge. Sanh et al. (2019) and\nTurc et al. (2019) applied this idea to BERT and\nyielded smaller models with minor performance\ndrops. Recently, feature-based and relation-based\ndistillation methods have drawn a lot of attention,\nwhich transfer knowledge contained in the inter-\nmediate layers to the student. For feature-based\nmethods, Sun et al. (2019) first regarded the hidden\nrepresentations of the [CLS] token as hints to ex-\ntract sentence-level features from the teacher. Jiao\net al. (2020) and Sun et al. (2020b) further matched\nthe hidden representations of all tokens between\nteacher and student models. Sun et al. (2020a)\nproposed contrastive distillation on intermediate\nrepresentations. As for relation-based methods,\nPark et al. (2021) proposed CKD which adopts\npair-wise distance and triple-wise angle to model\nthe sophisticated relations among token representa-\ntions from both horizontal and vertical directions.\nBased on CKD, Liu et al. (2022) further extracted\nstructural relations from multi-granularity repre-\nsentations and distilled this kind of well-organized\nmulti-granularity structural knowledge hierarchi-\ncally across layers. Wang et al. (2020, 2021) gen-\neralized the conventional query-key attention to\nquery-query attention, key-key attention, and value-\nvalue attention. Different from these methods, we\ninvestigate knowledge distillation from the attribu-\ntion perspective, which reveals the teacher‚Äôs rea-\nsoning behavior and can be used to transfer com-\nprehensive data-specific knowledge. More details\nabout the differences between existing methods and\nours are discussed in Appendix B.\n2.2 Attribution\nAttribution analysis (Baehrens et al., 2010; An-\ncona et al., 2018) aims at assigning importance\nscores to intermediate or input features of a net-\nwork. Occlusion-based methods (Zeiler and Fer-\ngus, 2014) compute the importance score of each\nfeature by erasing that feature and measuring the\n8450\ndifference between new output and the original\noutput. However, occlusion-based methods need\nto forward pass the model once for each feature,\nleading to low computational efficiency. To ad-\ndress this issue, gradient-based methods (Li et al.,\n2016; Ding et al., 2019; Brunner et al., 2020;\nSundararajan et al., 2017) exploit the gradient in-\nformation of features to approximate occlusion-\nbased methods, which only require a single for-\nward process. Similarly, propagation-based meth-\nods (Bach et al., 2015; Shrikumar et al., 2017) mod-\nify the back-propagation rules to redistribute the\nmodel output among the target features along the\nback-propagation path. Perturbation-based meth-\nods (Guan et al., 2019; Schulz et al., 2020; De Cao\net al., 2020) add noise to features to examine their\nimportance for model predictions. Attribution has\nbeen adopted in model compression techniques\nsuch as pruning (Michel et al., 2019) and adaptive\ninference (Modarressi et al., 2022) but has not been\nexplored in knowledge distillation. In this work,\nwe take the initiative to investigate the effect of\nattribution in knowledge distillation.\n3 Methodology\n3.1 Preliminary\nIntegrated Gradients (Sundararajan et al., 2017)\nis a theoretically tenable method to attribute the\nprediction of a deep network to its input or in-\ntermediate features. Formally, given a feature\nx = [x1,x2,...,x n] ‚ààRn with a baseline feature\nx‚Ä≤ = [x‚Ä≤\n1,x‚Ä≤\n2,...,x ‚Ä≤\nn] ‚ààRn, and the model func-\ntion F(.), IG leverages integral to represent the\ndifference between F(x) and F(x‚Ä≤) by selecting a\nstraight line path from x‚Ä≤to x as the integral path:\nF(x) ‚àíF(x‚Ä≤) =\nn‚àë\ni=1\nIGi(F,x) =\nn‚àë\ni=1\n[(xi ‚àíx‚Ä≤\ni) √ó\n‚à´1\nŒ±=0\n‚àÇF(x‚Ä≤+ Œ±√ó(x‚àíx‚Ä≤))\n‚àÇxi\ndŒ±].\n(1)\nIn practice, continual integral can be approximated\nby discrete summation:\nIGapprox\ni (F,x) =\n(xi ‚àíx‚Ä≤\ni) √ó\nm‚àë\nk=1\n‚àÇF(x‚Ä≤+ k\nm √ó(x‚àíx‚Ä≤))\n‚àÇxi\n√ó 1\nm, (2)\nwhere mis the number of summation steps (a big-\nger musually results in better approximation). In-\ntuitively, the magnitude of integrated gradient in-\ndicates its importance while its sign illustrates the\npositive or negative effect on the target output.\nIn this paper, we focus on Transformer-based\narchitecture and attribute the model prediction to\ninput features. With slight abuse of notation, we\ndenote the input sequence as x = [x1,x2,...,x n],\nwhere nis the sequence length and each xi repre-\nsents a token. Transformer first converts the token\nsequence to d-dimensional embedding sequence\nE = [e1,e2,..., en] ‚ààRn√ód through the embed-\nding layer. And then the contextualized representa-\ntions H = Transformer(E) ‚ààRn√ód are obtained\nafter several layers of Transformer blocks. Finally,\na task-specific head is applied on H to get the final\noutput P = [P1,P2,...,P C] ‚ààRC, which is typ-\nically a probability distribution. Denote the map-\nping function E ‚ÜíPc as Fc(.), where crepresents\nthe label of interest. In this case, our attribution\nmap is computed on each individual dimension of\neach input embedding, which is denoted as eij:\nIGapprox\nij (Fc,E) =\n(eij ‚àíe‚Ä≤\nij) √ó\nm‚àë\nk=1\n‚àÇFc(E‚Ä≤+ k\nm √ó(E ‚àíE‚Ä≤))\n‚àÇeij\n√ó 1\nm. (3)\nIn the implementation, we stackn[PAD]token em-\nbeddings as baseline features E‚Ä≤since they usually\nhave no influence on the model prediction.\n3.2 AD-KD\nIn this section, we elaborate on our proposed\nAttribution-Driven Knowledge Distillation (AD-\nKD), including attribution maps and attribution\ndistillation. The overall framework of AD-KD is\nillustrated in Figure 2.\n3.2.1 Attribution Maps\nThe attribution scores of a language model re-\nflect the importance of different tokens towards the\nprediction, which contains valuable data-specific\nreasoning knowledge. The scores are computed\namong different tokens at different dimensions of\na given model, using IG defined in Section 3.1. In\nthis work, we do not take the sign into consider-\nation, since the scores at different dimensions of\nthe same token embedding would cannibalize each\nother when combining them into a token-level at-\ntribution score. This observation is consistent with\nthe findings in (Atanasova et al., 2020).\nWhen calculating the attribution scores, we ob-\nserved that there exist certain dimensions whose\nattribution scores remain relatively low across dif-\nferent tokens. The attribution scores from these di-\nmensions minimize the difference between impor-\ntant and unimportant tokens, which can be regarded\n8451\nTransformer \nBlockN√ó\nAttribution Maps\nEntailment\nInput: What land was ceded to Spain ? ‚Ä¶\nTeacher\nClassifier\nEmbedding Layer\nEntailment Not entailment\nAttribution\nSort&  Drop\nL2  norm\nNot entailment\nEntailment Not entailment\nStudent\nClassifier\nEmbedding Layer\nTransformer \nBlock √óM\nEntailment\nEntailment Not entailment\nL2  norm\nAttribution Maps\nNot entailment\nAttribution\nAttribution Distillation Loss\nKL-divergence Loss Cross-entropy Loss\nground-truth label\nFigure 2: Overview of our AD-KD framework. The example in Figure 1 is taken as the input. AD-KD first extracts\nthe attribution maps from the teacher model and then transfers the attribution-based knowledge to the student.\nas noises. For better illustration, Figure 3 shows\nan example of sentence ‚Äúseem weird and distanced‚Äù\nwhose annotation is negative sentiment. It is clear\nthat ‚Äúweird‚Äù and ‚Äúdistance‚Äù are the keywords that\ncontribute most to the prediction, whereas a pro-\nportion of dimensions of them present low attri-\nbution scores. To alleviate the influence of noisy\ndimensions in the input embeddings, we simply\nchoose the top-K dimensions with high attribution\nscores and filter out dimensions with low attribu-\ntion scores. Formally, the attribution score of token\nxi with respect to the label cin the teacher model\ncan be calculated as:\nat,c\ni = ‚à•TopK(IGapprox\ni (Ft,c,Et))‚à•2, (4)\nwhere the superscript tdenotes the teacher model.\nTherefore, the attribution map of the teacher con-\nsists of a sequence of attribution scores:\nat,c = [at,c\n1 ,at,c\n2 ,...,a t,c\nn ]. (5)\nFor the student, the extraction of attribution map\nis similar except that we consider all dimensions\nfor two reasons. First, it reduces the difficulty of\ntraining. Second, the student is allowed to learn\nfrom the noiseless attribution map of the teacher.\nas,c\ni = ‚à•IGapprox\ni (Fs,c,Es)‚à•2,\nas,c = [as,c\n1 ,as,c\n2 ,...,a s,c\nn ]. (6)\nConsidering that the teacher can make multiple\ndecisions, each of which is associated with a prob-\nability, we further propose to extract multi-view\nattribution knowledge. Specifically, we extract the\nattribution maps for all possible predictions of the\nmodel rather than a single prediction, e.g., the pre-\ndiction with the maximum probability or the pre-\ndiction corresponding to the ground-truth label. By\ntransferring the multi-view attribution knowledge,\nthe student can capture a more comprehensive un-\nderstanding of the teacher‚Äôs soft-label distribution.\nThe multi-view attribution maps are defined as:\nAt =‚à•C\nc=1 at,c, As =‚à•C\nc=1 as,c, (7)\nwhere ‚à•is the concatenation operation.\n3.2.2 Attribution Distillation\nGiven the multi-view attribution maps, a straight-\nforward strategy to transfer the knowledge is to\ndirectly minimize the difference between the two\nsets of maps in teacher and student models, with\ndistance metrics like L2 distance (MSE):\n‚à•At ‚àíAs‚à•2. (8)\nHowever, one obvious shortcoming with this ap-\nproach is that there may exist a magnitude gap\nbetween the attribution scores in teacher and stu-\ndent models at the early phase of distillation, since\nthe teacher is already well-trained while the stu-\ndent has little attribution knowledge. Under this\ncircumstance, the student is likely to fall into a local\noptimum. To enable smooth knowledge distillation,\nwe normalize the attribution maps before minimiz-\ning the difference. Concretely, we first transform\nthe single-view attribution maps into unit vectors:\nÀúat,c = at,c\n‚à•at,c‚à•2\n, Àúas,c = as,c\n‚à•as,c‚à•2\n. (9)\n8452\n0 250 500 750\nEmbedding Dimension\n(a) seem\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06Absolute Attribution Score\n0 250 500 750\nEmbedding Dimension\n(b) weird\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06Absolute Attribution Score\n0 250 500 750\nEmbedding Dimension\n(c) and\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06Absolute Attribution Score\n0 250 500 750\nEmbedding Dimension\n(d) distance\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06Absolute Attribution Score\n0 250 500 750\nEmbedding Dimension\n(e) ##d\n0.00\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06Absolute Attribution Score\nFigure 3: An example from the SST-2 dataset (Socher et al., 2013). Given the sentence ‚Äúseem weird and distanced‚Äù\nand its sentiment label negative, the distributions of absolute attribution scores among different tokens and dimen-\nsions are shown in subfigures (a)-(e). The model is a well-trained BERTbase (teacher) and the IG steps mis set to 1.\nThen we reformulate the normalized multi-view\nattribution maps in Eq. (7) as:\nÀúAt =‚à•C\nc=1 Àúat,c, ÀúAs =‚à•C\nc=1 Àúas,c. (10)\nThe normalized attribution maps only preserve the\ninformation of relative importance among tokens\nregardless of their absolute importance, which we\nbelieve is the crucial knowledge to transfer. Finally,\nwe define the attribution distillation loss as:\nLattr = ‚à•ÀúAt ‚àíÀúAs‚à•2. (11)\n3.2.3 Overall Objective\nWe combine the original cross-entropy loss be-\ntween the output of the student and the ground-\ntruth label, the response-based loss (on the logits)\n(Hinton et al., 2015), and the proposed attribution-\ndriven distillation loss to train the student model.\nThe overall objective is defined as:\nL= (1‚àíŒ±)Lce + Œ±Llogit + Œ≤Lattr, (12)\nwhere Lce = ‚àílogœÉ(zs)[y] is the cross-entropy loss\nand Llogit=KL(œÉ(zt\nœÑ )‚à•œÉ(zs\nœÑ )) is the loss on the out-\nput logits. And, Œ±and Œ≤are two hyperparameters,\nœÉ is the softmax function, y is the ground-truth\nlabel, œÑ is the temperature, and zt and zs are the\noutput logits of the teacher and student models,\nrespectively. KL(¬∑) denotes the KL-divergence.\n4 Experimental Settings\n4.1 Datasets\nWe evaluate our method on eight tasks of the GLUE\nbenchmark (Wang et al., 2018), including CoLA\n(Warstadt et al., 2019), MNLI (Williams et al.,\n2018), SST-2 (Socher et al., 2013), QNLI (Ra-\njpurkar et al., 2016), MRPC (Dolan and Brockett,\n2005), QQP (Chen et al., 2018), RTE (Bentivogli\net al., 2009) and STS-B (Cer et al., 2017). The de-\ntails of these datasets are introduced in Appendix\nA.1. For evaluation metrics, we follow previous\nworks (Park et al., 2021; Liu et al., 2022) and report\naccuracy on MNLI, SST-2, QNLI, QQP and RTE,\nF1 score on MRPC, Matthews correlation coeffi-\ncient on CoLA, and Spearman‚Äôs rank correlation\ncoefficient on STS-B.\n4.2 Baseline Methods\nWe compare AD-KD with response-based KD\nmethods and several state-of-the-art feature-based\nand relation-based KD methods. Response-based\nbaselines include Vanilla KD (Hinton et al., 2015)\nand PD (Turc et al., 2019). Feature-based and\nrelation-based baselines include PKD (Sun et al.,\n2019) which distills the hidden representations,\nTinyBERT (Jiao et al., 2020) which distills the self-\nattention matrices, and CKD (Park et al., 2021)\nand MGSKD (Liu et al., 2022) which distill the\nrelation between hidden representations. For a fair\ncomparison, MiniLM (Wang et al., 2020, 2021)\nand MobileBERT (Sun et al., 2020b) are not pre-\nsented due to their two-stage distillation settings\nwhich involve both task-agnostic and task-specific\ndistillation. Our AD-KD focuses on task-specific\ndistillation and does not augment the training sets.\nMoreover, MGSKD (Liu et al., 2022) only reports\nresults on a 4-layer BERT student model which is\ndifferent from other baselines. To ensure a fair com-\nparison, we re-implemented MGSKD using their\nreleased code to obtain a 6-layer student model.\nThe original MGSKD approach also relies on span-\nlevel information that is extracted from external\nknowledge sources, which is not publicly avail-\nable nor included in other baselines. Therefore,\nwe did not use this external knowledge in our re-\nimplementation of MGSKD.\n4.3 Implementation Details\nOur code is implemented in Pytorch with the Trans-\nformers package (Wolf et al., 2020). We fine-\n8453\nModel #ParamsCoLA\n(Mcc)\nMNLI-(m/mm)\n(Acc)\nSST-2\n(Acc)\nQNLI\n(Acc)\nMRPC\n(F1)\nQQP\n(Acc)\nRTE\n(Acc)\nSTS-B\n(Spear) Avg\nDev\nBERTbase(Teacher) 110M 60.3 84.9/84.8 93.7 91.7 91.4 91.5 69.7 89.4 84.1\nBERT6 (Student) 66M 51.2 81.7/82.6 91.0 89.3 89.2 90.4 66.1 88.3 80.9\nVanilla KD (Hinton et al., 2015)66M 53.6 82.7/83.1 91.1 90.1 89.4 90.5 66.8 88.7 81.6\nPD (Turc et al., 2019) 66M - 82.5/83.4 91.1 89.4 89.4 90.7 66.7 - -\nPKD (Sun et al., 2019) 66M 45.5 81.3/- 91.3 88.4 85.7 88.4 66.5 86.2 79.2\nTinyBERT (Jiao et al., 2020)66M 53.8 83.1/83.4 92.3 89.9 88.8 90.5 66.9 88.3 81.7\nCKD (Park et al., 2021) 66M 55.1 83.6/ 84.1 93.0 90.5 89.6 91.2 67.3 89.0 82.4\nMGSKD (Liu et al., 2022) 66M 49.1 83.3/83.9 91.7 90.3 89.8 91.2 67.9 88.5 81.5\nAD-KD 66M 58.3 83.4/84.2 91.9 91.2 91.2 91.2 70.9 89.2 83.4\nTest\nBERTbase(Teacher) 110M 51.5 84.5/84.1 94.1 90.9 87.7 89.2 67.5 85.5 81.4\nBERT6 (Student) 66M 41.7 81.9/81.0 91.3 88.9 85.2 88.0 64.0 82.4 77.9\nVanilla KD (Hinton et al., 2015)66M 42.3 82.7/81.8 92.0 89.3 86.3 88.2 65.0 82.7 78.6\nPD (Turc et al., 2019) 66M - 82.8/82.2 91.8 88.9 86.8 88.9 65.3 - -\nPKD (Sun et al., 2019) 66M 43.5 81.5/81.0 92.0 89.0 85.0 88.9 65.5 81.6 78.4\nMGSKD (Liu et al., 2022) 66M 42.8 83.4/82.8 92.1 89.5 87.0 89.1 63.7 82.2 78.7\nAD-KD 66M 47.0 83.1/82.6 91.8 90.0 87.1 88.9 65.8 83.4 79.6\nTable 1: Overall results on the GLUE benchmark. The results of baselines except vanilla KD and MGSKD are\nimported from Park et al. (2021). Results of development sets are averaged over 3 runs and we submit the model\nwith the highest score to the official GLUE server to obtain the results of test sets. Average score is computed\nexcluding the MNLI-mm accuracy. The best results of the student models are shown in bold and the second best\nresults are shown with underline. Results are statistically significant with p-value <0.005.\ntune BERTbase as the teacher model, and utilize\na smaller BERT released by Turc et al. (2019) with\n6 Transformer layers, 768 hidden neurons and 12\nattention heads to instantiate the student model\nfollowing Park et al. (2021). We search for the\noptimal learning rate in {2e-5, 3e-5, 4e-5, 5e-5},\nŒ± in {0.8, 0.9, 1.0} and temperature œÑ in {1, 2,\n3, 4}. For the hyperparameter Œ≤, we tune within\n{1, 10, 50, 100}. For the IG steps mdescribed in\nSection 3.1, we adopt m= 1 in the main results\ndue to the huge computational overhead. Part of\nresults with m varying from 1 to 8 are reported\nin Section 5.4. K is empirically searched within\n{384, 512, 640, 700, 734, 768}. Results with dif-\nferent values of Kare also reported. The detailed\nhyperparameter settings and training cost are pro-\nvided in Appendix A.2. Our code is available at\nhttps://github.com/brucewsy/AD-KD.\n5 Results and Analysis\n5.1 Main Results\nThe main results are presented in Table 1. It can be\nseen that AD-KD outperforms all baselines on most\nof the datasets. Specifically, AD-KD yields an av-\nerage improvement of 1.0 and 1.9 points over CKD\nand MGSKD respectively on development sets,\nand another average improvement of 0.9 points\nover MGSKD on test sets. Note that other feature-\nbased and relation-based KD methods even under-\nperform vanilla KD, indicating the difficulty of\naligning the teacher and the student at intermediate\nlayers. In contrast, AD-KD distills the attribution\nknowledge from a global perspective which is more\ndata-specific and shows significant improvement\nover vanilla KD. We provide two cases in Appendix\nC.3 to intuitively demonstrate the strength of AD-\nKD. We also observe that AD-KD does not show\na satisfying performance on SST-2. We believe\nthe reason is that the sentences in SST-2 are much\nshorter than those in other datasets, and in this case,\nthe student is likely to already capture the attribu-\ntion knowledge implicitly from the soft-labels of\nthe teacher (Zhang et al., 2022).\n5.2 Ablation Study\nImpact of Loss Terms To analyze the impact of\ndifferent loss terms, we conduct ablation experi-\nments on three variants of AD-KD: (1) AD-KD\nwithout attribution distillation (i.e., vanilla KD),\n(2) AD-KD without the original cross-entropy loss,\nand (3) AD-KD without logit distillation. As re-\nported in Table 2, again we observe an obvious\nperformance drop after removing the attribution\ndistillation. We also note that removing either the\nconventional cross-entropy loss or logit distillation\nloss causes noticeable performance degradation,\nsuggesting both of them contribute to the improve-\n8454\nMethod CoLA\n(Mcc)\nMNLI-(m/mm)\n(Acc)\nSST-2\n(Acc)\nQNLI\n(Acc)\nMRPC\n(F1)\nQQP\n(Acc)\nRTE\n(Acc)\nSTS-B\n(Spear)\nAD-KD 58.3 83.4/84.2 91.9 91.2 91.2 91.2 70.9 89.2\nw/oLattr 53.6 82.7/83.1 91.2 90.2 89.2 90.5 67.5 88.9\nw/oLce 57.8 83.6/84.1 91.3 90.8 90.8 91.2 69.3 88.9\nw/oLlogit 53.9 81.9/82.8 91.1 90.5 89.9 90.9 68.6 88.8\nTable 2: Ablation study of different loss terms. The results are based on GLUE development sets.\nMNLI-m MNLI-mm\n82.0\n82.5\n83.0\n83.5\n84.0\n84.5\n85.0Accuracy (%)\n83.4\n84.2\n82.8\n83.8\n83.2\n83.7\n82.9\n83.8\n82.7\n83.1\nMulti\nSingle (contradiction)\nSingle (entailment)\nSingle (neutral)\nVanilla KD\nFigure 4: Ablation study of multi-view attribution on\nthe MNLI development set.\nment of AD-KD. Nevertheless, our attribution dis-\ntillation contributes most to the performance of\nAD-KD, showing that data-specific reasoning in-\nformation is crucial in knowledge distillation.\nMulti-view Attribution In AD-KD, the student\nlearns the attribution knowledge from a variety of\npossible outputs to get a better understanding of the\nteacher. Here we study how the number of attribu-\ntion views affects the final results. Experiments are\nconducted on MNLI which is a multi-classification\ntask including three labels: entailment, contradic-\ntion, and neutral. We make a comparison between\nmulti-view attribution and single-view attribution\nw.r.t. each candidate label respectively. The results\nare shown in Figure 4, from which we note that\neach of the single-view attributions plays a posi-\ntive role and is superior to vanilla KD. Moreover,\ncombining all attribution views yields further per-\nformance improvement, demonstrating that multi-\nview attribution is more preferable for distillation.\nStudent Model Size To investigate whether AD-\nKD can boost the performance across different\nsizes of student, we further compare AD-KD with\nvanilla KD on MRPC and QNLI under various\nstudent scales provided by Turc et al. (2019). As\nobserved in Figure 5, AD-KD consistently outper-\nforms vanilla KD, which validates the effectiveness\nand stability of our approach.\n5.3 Impact of Top- K\nRecall that in order to eliminate the interference\nof noisy dimension, AD-KD adopts the top-K ap-\n4/256\n4/512\n4/768\n6/256\n6/512\n6/768\n8/256\n8/512\n8/768\n12/256\n12/512\nDepth/Width\n86\n87\n88\n89\n90\n91\n92F1 Score (%)\nMRPC\nAD-KD\nVanilla KD\n4/256\n4/512\n4/768\n6/256\n6/512\n6/768\n8/256\n8/512\n8/768\n12/256\n12/512\nDepth/Width\n86\n88\n90Accuracy (%)\nQNLI\nAD-KD\nVanilla KD\nFigure 5: Results of AD-KD and vanilla KD on MRPC\nand QNLI development sets at different student scales.\nproach on the input embeddings of the teacher to\nfilter out the dimensions with relatively low attri-\nbution scores. In this section, we conduct in-depth\nanalysis on the impact of K. We conduct exper-\niments on STS-B and QNLI, and plot the results\nwith different values of K in Figure 6. As illus-\ntrated in the figure, the performance on the small\ndataset STS-B (7k) first improves as K increases\nand then slightly degrades after K exceeds 600.\nHowever, the performance on the larger dataset\nQNLI (108k) improves almost monotonically with\nthe increasing of K. We conjecture that choosing\na suitable K is beneficial on small datasets since\nthere are probably more noisy dimensions in the in-\nput embeddings of the teacher, while preserving all\ndimensions may be preferable on larger datasets.\n5.4 Impact of IG Steps\nIn our experiments, the IG steps mare set to 1 by\ndefault when extracting the attribution maps. In\nthis section, we provide more results with different\nvalues of min Figure 7 to understand its impact\non distillation. We observe that as m increases,\n8455\n0 100 200 300 400 500 600 700 800\nK\n90.6\n90.8\n91.0\n91.2\n91.4Accuracy (%)\nQNLI\n89.0\n89.1\n89.2\n89.3\nSpearman (%)\nSTS-B\nFigure 6: Results on STS-B and QNLI development sets\nas the number (K) of retained dimensions changes.\n1 2 3 4 5 6 7 8\nm\n90.50\n90.75\n91.00\n91.25\n91.50\n91.75\n92.00Accuracy (%)\nQNLI\n90.5\n91.0\n91.5\n92.0\n92.5\nF1 Score (%)\nMRPC\nFigure 7: Results on MRPC and QNLI development\nsets as the number (m) of IG steps changes.\nthe performance of AD-KD fluctuates in a certain\nrange. Although it is possible to find a point that\nsurpasses our default setting and even the teacher,\nidentifying the optimal value of mfor each task is\ncostly since a large mcauses huge computational\noverhead. In contrast, m=1 achieves better trade-\noff between performance and computational cost.\nAttribution LayerMRPC\n(F1)\nQNLI\n(Acc)\ninput 91.2 91.2\nfirst 90.5 90.9\npenultimate 90.4 90.9\nuniform 90.6 91.1\ninput & uniform 90.1 90.6\nTable 3: Results of different attribution layers on MRPC\nand QNLI development sets.\n5.5 Attribution Distillation Layer\nApart from the attribution knowledge of input layer,\nthe attribution knowledge of intermediate layers\ncan also be transferred during distillation. To con-\nfirm the motivation that the former is better than\nthe latter, we conduct experiments on MRPC and\nQNLI with different attribution layers. Specifically,\nwe choose the first layer and the penultimate layer\nfor comparison. Besides, we also try a uniform\nstrategy which is widely adopted as the mapping\nfunction between the teacher and the student layers\n(Jiao et al., 2020; Park et al., 2021; Liu et al., 2022).\nFrom the results shown in Table 3, we see that\nuniform mapping strategy performs best among\n0.0 0.2 0.4 0.6 0.8 1.0\n90.4\n90.6\n90.8\n91.0\n91.2\n91.4Accuracy (%)\nQNLI\n1 10 30 50 100 150 200\n90.6\n90.8\n91.0\n91.2\n91.4Accuracy (%)\nQNLI\n90.0\n90.5\n91.0\n91.5\nF1 Score (%)\nMRPC\n90.50\n90.75\n91.00\n91.25\n91.50\nF1 Score (%)\nMRPC\nFigure 8: Results on MRPC and QNLI development\nsets as Œ±and Œ≤changes.\nintermediate layer methods. However, neither of\nthese intermediate layers outperforms input layer,\nindicating that the attribution knowledge of inter-\nmediate layers is more model-specific and difficult\nto transfer. In addition, distilling the knowledge\njointly from the input and the intermediate layers\ndoes not improve the performance.\n5.6 Impact of Œ±and Œ≤\nFor the training objective of AD-KD, we introduce\nŒ±and Œ≤to balance the original cross-entropy loss,\nlogit distillation loss, and attribution distillation\nloss. To investigate their impact on model perfor-\nmance, we show the results of different values of\nŒ±and Œ≤ on MRPC and QNLI in Figure 8, where\nwe fix one while altering the other. We observe a\nunified trend across different tasks that when Œ±is\nsmall, the student does not perform well due to the\nlack of response-based knowledge of the teacher,\nand when Œ±is around 0.9, the student performs best.\nTherefore, we select Œ±close to 1. We also observe\nfrom the figure that asŒ≤increases, the performance\nfirst keeps improving and reaches the peak, then it\nstarts to decline. Unlike Œ±, however, the optimal\nvalue of Œ≤ varies with different tasks, indicating\nthat Œ≤is more sensitive to the task compared to Œ±.\nMore discussion of Œ≤are given in Appendix C.2.\n6 Conclusion\nIn this paper, we propose AD-KD, a novel knowl-\nedge distillation framework for language model\ncompression. Unlike other distillation methods,\nAD-KD investigates the model knowledge from\nthe perspective of input attribution, which is vital\nyet easy to transfer between the teacher and the\n8456\nstudent. Moreover, top- K method is adopted to\nobtain noiseless attribution maps among input to-\nkens, and multi-view attribution is conducted for\na more comprehensive distillation. To our knowl-\nedge, this is the first work that incorporates attri-\nbution into knowledge distillation. Extensive ex-\nperiments including ablation studies are carried\nout to show the effectiveness of AD-KD and its\ncomponents. With the recent emergence of large\nlanguage models (LLMs), gradient-based attribu-\ntion methods are infeasible due to the unavailable\nparameters. However, the idea of AD-KD can still\nbe potentially extended to these black-box models\nby using occlusion-based attribution or using chain-\nof-thoughts (Wei et al., 2022) as the rationale for\ndistillation. We will leave it to future work.\nAcknowledgements\nThis work was supported by the National Natu-\nral Science Foundation of China (No. 62176270),\nthe Guangdong Basic and Applied Basic Research\nFoundation (No. 2023A1515012832), and the Pro-\ngram for Guangdong Introducing Innovative and\nEntrepreneurial Teams (No. 2017ZT07X355).\nLimitations\nThis work introduces the general idea of incorpo-\nrating attribution into knowledge distillation, and\nthere are three potential limitations. First, although\nAD-KD chooses Integrated Gradients for attribu-\ntion, there are actually other attribution methods\n(Janizek et al., 2021; Sikdar et al., 2021) which can\nalso be fitted in our framework. The question of\nwhether these methods perform better than Inte-\ngrated Gradients when combined with knowledge\ndistillation is still unclear. Second, we conduct ex-\nperiments on BERT of different scales and have not\nyet validated the effectiveness of AD-KD on other\nmodel structures. Third, while we only perform\ntask-specific knowledge distillation in our exper-\niments, applying AD-KD to task-agnostic knowl-\nedge distillation is also worth investigating.\nEthics Statement\nOur work will not cause ethical issues and the\ndatasets used in this paper are publicly available.\nReferences\nMarco Ancona, Enea Ceolini, Cengiz √ñztireli, and\nMarkus Gross. 2018. Towards better understand-\ning of gradient-based attribution methods for deep\nneural networks. In 6th International Conference\non Learning Representations, ICLR 2018, Vancou-\nver, BC, Canada, April 30-May 3, 2018, Conference\nTrack Proceedings. OpenReview. net.\nPepa Atanasova, Jakob Grue Simonsen, Christina Li-\noma, and Isabelle Augenstein. 2020. A diagnostic\nstudy of explainability techniques for text classifi-\ncation. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 3256‚Äì3274, Online. Association for\nComputational Linguistics.\nSebastian Bach, Alexander Binder, Gr√©goire Montavon,\nFrederick Klauschen, Klaus-Robert M√ºller, and Wo-\njciech Samek. 2015. On pixel-wise explanations\nfor non-linear classifier decisions by layer-wise rele-\nvance propagation. PloS one, 10(7):e0130140.\nDavid Baehrens, Timon Schroeter, Stefan Harmeling,\nMotoaki Kawanabe, Katja Hansen, and Klaus-Robert\nM√ºller. 2010. How to explain individual classifica-\ntion decisions. The Journal of Machine Learning\nResearch, 11:1803‚Äì1831.\nJasmijn Bastings and Katja Filippova. 2020. The ele-\nphant in the interpretability room: Why use attention\nas explanation when we have saliency methods? In\nProceedings of the Third BlackboxNLP Workshop\non Analyzing and Interpreting Neural Networks for\nNLP, pages 149‚Äì155, Online. Association for Com-\nputational Linguistics.\nLuisa Bentivogli, Peter Clark, Ido Dagan, and Danilo\nGiampiccolo. 2009. The fifth pascal recognizing\ntextual entailment challenge. In TAC.\nGino Brunner, Yang Liu, Damian Pascual, Oliver\nRichter, Massimiliano Ciaramita, and Roger Watten-\nhofer. 2020. On identifiability in transformers. In 8th\nInternational Conference on Learning Representa-\ntions (ICLR 2020)(virtual). International Conference\non Learning Representations.\nDaniel Cer, Mona Diab, Eneko Agirre, I√±igo Lopez-\nGazpio, and Lucia Specia. 2017. SemEval-2017\ntask 1: Semantic textual similarity multilingual and\ncrosslingual focused evaluation. In Proceedings\nof the 11th International Workshop on Semantic\nEvaluation (SemEval-2017), pages 1‚Äì14, Vancouver,\nCanada. Association for Computational Linguistics.\nZihan Chen, Hongbo Zhang, Xiaoji Zhang, and Leqi\nZhao. 2018. Quora question pairs. URL https://www.\nkaggle. com/c/quora-question-pairs.\nNicola De Cao, Michael Sejr Schlichtkrull, Wilker Aziz,\nand Ivan Titov. 2020. How do decisions emerge\nacross layers in neural models? interpretation with\ndifferentiable masking. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 3243‚Äì3255, On-\nline. Association for Computational Linguistics.\n8457\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171‚Äì4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nShuoyang Ding, Hainan Xu, and Philipp Koehn. 2019.\nSaliency-driven word alignment interpretation for\nneural machine translation. In Proceedings of the\nFourth Conference on Machine Translation (Volume\n1: Research Papers), pages 1‚Äì12, Florence, Italy.\nAssociation for Computational Linguistics.\nWilliam B. Dolan and Chris Brockett. 2005. Automati-\ncally constructing a corpus of sentential paraphrases.\nIn Proceedings of the Third International Workshop\non Paraphrasing (IWP2005).\nJianping Gou, Baosheng Yu, Stephen J Maybank, and\nDacheng Tao. 2021. Knowledge distillation: A\nsurvey. International Journal of Computer Vision,\n129(6):1789‚Äì1819.\nChaoyu Guan, Xiting Wang, Quanshi Zhang, Runjin\nChen, Di He, and Xing Xie. 2019. Towards a deep\nand unified understanding of deep neural models in\nnlp. In International Conference on Machine Learn-\ning, pages 2454‚Äì2463. PMLR.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.\nDistilling the knowledge in a neural network. arXiv\npreprint arXiv:1503.02531.\nSarthak Jain and Byron C. Wallace. 2019. Attention is\nnot Explanation. In Proceedings of the 2019 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 3543‚Äì3556, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nJoseph D Janizek, Pascal Sturmfels, and Su-In Lee.\n2021. Explaining explanations: Axiomatic feature\ninteractions for deep networks. Journal of Machine\nLearning Research, 22:1‚Äì54.\nXiaoqi Jiao, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao\nChen, Linlin Li, Fang Wang, and Qun Liu. 2020.\nTinyBERT: Distilling BERT for natural language un-\nderstanding. In Findings of the Association for Com-\nputational Linguistics: EMNLP 2020, pages 4163‚Äì\n4174, Online. Association for Computational Lin-\nguistics.\nDaniel Khashabi, Snigdha Chaturvedi, Michael Roth,\nShyam Upadhyay, and Dan Roth. 2018. Looking\nbeyond the surface: A challenge set for reading com-\nprehension over multiple sentences. In Proceedings\nof the 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long Pa-\npers), pages 252‚Äì262, New Orleans, Louisiana. As-\nsociation for Computational Linguistics.\nJiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky.\n2016. Visualizing and understanding neural models\nin NLP. In Proceedings of the 2016 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 681‚Äì691, San Diego, California.\nAssociation for Computational Linguistics.\nChen Liang, Simiao Zuo, Qingru Zhang, Pengcheng He,\nWeizhu Chen, and Tuo Zhao. 2022. Less is more:\nTask-aware layer-wise distillation for language model\ncompression. arXiv preprint arXiv:2210.01351.\nChang Liu, Chongyang Tao, Jiazhan Feng, and Dongyan\nZhao. 2022. Multi-granularity structural knowledge\ndistillation for language model compression. In Pro-\nceedings of the 60th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 1001‚Äì1011, Dublin, Ireland. Associa-\ntion for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nPaul Michel, Omer Levy, and Graham Neubig. 2019.\nAre sixteen heads really better than one? In Proceed-\nings of the 33rd International Conference on Neu-\nral Information Processing Systems, pages 14037‚Äì\n14047.\nAli Modarressi, Hosein Mohebbi, and Moham-\nmad Taher Pilehvar. 2022. AdapLeR: Speeding up\ninference by adaptive length reduction. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 1‚Äì15, Dublin, Ireland. Association for\nComputational Linguistics.\nGeondo Park, Gyeongman Kim, and Eunho Yang. 2021.\nDistilling linguistic context for language model com-\npression. In Proceedings of the 2021 Conference on\nEmpirical Methods in Natural Language Processing,\npages 364‚Äì378, Online and Punta Cana, Dominican\nRepublic. Association for Computational Linguistics.\nDamian Pascual, Gino Brunner, and Roger Wattenhofer.\n2021. Telling BERT‚Äôs full story: from local attention\nto global aggregation. In Proceedings of the 16th\nConference of the European Chapter of the Associ-\nation for Computational Linguistics: Main Volume,\npages 105‚Äì124, Online. Association for Computa-\ntional Linguistics.\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing, pages 2383‚Äì2392, Austin,\nTexas. Association for Computational Linguistics.\n8458\nVictor Sanh, Lysandre Debut, Julien Chaumond, and\nThomas Wolf. 2019. Distilbert, a distilled version\nof bert: smaller, faster, cheaper and lighter. arXiv\npreprint arXiv:1910.01108.\nKarl Schulz, Leon Sixt, Federico Tombari, and Tim\nLandgraf. 2020. Restricting the flow: Informa-\ntion bottlenecks for attribution. arXiv preprint\narXiv:2001.00396.\nAvanti Shrikumar, Peyton Greenside, and Anshul Kun-\ndaje. 2017. Learning important features through\npropagating activation differences. In International\nConference on Machine Learning, pages 3145‚Äì3153.\nPMLR.\nSandipan Sikdar, Parantapa Bhattacharya, and Kieran\nHeese. 2021. Integrated directional gradients: Fea-\nture interaction attribution for neural NLP models. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing (Volume 1: Long Papers), pages 865‚Äì878,\nOnline. Association for Computational Linguistics.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Proceedings of the 2013 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1631‚Äì1642, Seattle, Washington, USA. Association\nfor Computational Linguistics.\nSiqi Sun, Yu Cheng, Zhe Gan, and Jingjing Liu. 2019.\nPatient knowledge distillation for BERT model com-\npression. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n4323‚Äì4332, Hong Kong, China. Association for Com-\nputational Linguistics.\nSiqi Sun, Zhe Gan, Yuwei Fang, Yu Cheng, Shuohang\nWang, and Jingjing Liu. 2020a. Contrastive distil-\nlation on intermediate representations for language\nmodel compression. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 498‚Äì508, Online. Asso-\nciation for Computational Linguistics.\nZhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu,\nYiming Yang, and Denny Zhou. 2020b. Mobile-\nBERT: a compact task-agnostic BERT for resource-\nlimited devices. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 2158‚Äì2170, Online. Association for\nComputational Linguistics.\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\nAxiomatic attribution for deep networks. In Inter-\nnational Conference on Machine Learning, pages\n3319‚Äì3328. PMLR.\nIulia Turc, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. 2019. Well-read students learn better:\nOn the importance of pre-training compact models.\narXiv preprint arXiv:1908.08962.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia, Aman-\npreet Singh, Julian Michael, Felix Hill, Omer Levy,\nand Samuel R Bowman. 2019. Superglue: a stickier\nbenchmark for general-purpose language understand-\ning systems. In Proceedings of the 33rd International\nConference on Neural Information Processing Sys-\ntems, pages 3266‚Äì3280.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel Bowman. 2018. GLUE:\nA multi-task benchmark and analysis platform for nat-\nural language understanding. In Proceedings of the\n2018 EMNLP Workshop BlackboxNLP: Analyzing\nand Interpreting Neural Networks for NLP, pages\n353‚Äì355, Brussels, Belgium. Association for Com-\nputational Linguistics.\nWenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong,\nand Furu Wei. 2021. MiniLMv2: Multi-head self-\nattention relation distillation for compressing pre-\ntrained transformers. In Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021,\npages 2140‚Äì2151, Online. Association for Computa-\ntional Linguistics.\nWenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan\nYang, and Ming Zhou. 2020. Minilm: Deep self-\nattention distillation for task-agnostic compression\nof pre-trained transformers. Advances in Neural In-\nformation Processing Systems, 33:5776‚Äì5788.\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2019. Neural network acceptability judgments.\nTransactions of the Association for Computational\nLinguistics, 7:625‚Äì641.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. arXiv preprint arXiv:2201.11903.\nSarah Wiegreffe and Yuval Pinter. 2019. Attention is not\nnot explanation. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 11‚Äì20, Hong Kong, China. Association for\nComputational Linguistics.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112‚Äì1122, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\n8459\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38‚Äì45, Online. Association\nfor Computational Linguistics.\nSong Xu, Haoran Li, Peng Yuan, Youzheng Wu, Xi-\naodong He, and Bowen Zhou. 2020. Self-attention\nguided copy mechanism for abstractive summariza-\ntion. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n1355‚Äì1362, Online. Association for Computational\nLinguistics.\nMatthew D Zeiler and Rob Fergus. 2014. Visualizing\nand understanding convolutional networks. In 13th\nEuropean Conference on Computer Vision, ECCV\n2014, pages 818‚Äì833. Springer Verlag.\nQuanshi Zhang, Xu Cheng, Yilan Chen, and Zhefan\nRao. 2022. Quantifying the knowledge in a dnn\nto explain knowledge distillation for classification.\nIEEE Transactions on Pattern Analysis & Machine\nIntelligence, (01):1‚Äì17.\n8460\nA Experimental Details\nA.1 Details of Datasets\nWe evaluate AD-KD on eight tasks of GLUE\nbenchmark (Wang et al., 2018). Specifically, there\nare two single-sentence tasks: CoLA (Warstadt\net al., 2019) which aims to predict if the given sen-\ntence is grammatically correct, and SST-2 (Socher\net al., 2013) which aims to predict the sentiment of\nthe given sentence; two paraphrase tasks: MRPC\n(Dolan and Brockett, 2005) which aims to predict\nif two given sentences are semantically equivalent,\nand QQP (Chen et al., 2018) which is similar to\nMRPC; three inference tasks which aim to pre-\ndict if the premise entails the hypothesis: MNLI\n(Williams et al., 2018), QNLI (Rajpurkar et al.,\n2016), and RTE (Bentivogli et al., 2009); and one\nsimilarity task: STS-B (Cer et al., 2017) which\naims to predict a continual score measuring the se-\nmantic similarity between a pair of sentences. The\nstatistics of these datasets are shown in Table 4.\nTask #Train #Dev #Test #Label\nSingle-Sentence Classification\nCoLA 8.5k 1k 1k 2\nSST-2 67k 872 1.8k 2\nPairwise Text Classification\nMNLI 393k 20k 20k 3\nQNLI 108k 5.7k 5.7k 2\nMRPC 3.7k 408 1.7k 2\nQQP 364k 40k 391k 2\nRTE 2.5k 276 3k 2\nText Similarity\nSTS-B 7k 1.5k 1.4k 1\nTable 4: Statistics of the GLUE datasets.\nA.2 Hyperparameter Settings\nWe run all experiments on GeForce RTX 2080 Ti\nGPUs. Table 5 presents the hyperparameter set-\ntings and training costs of AD-KD on GLUE tasks.\nGenerally, AD-KD runs 1.2 to 3 times slower com-\npared to vanilla KD on different tasks, due to the\nextra back-propagation. However, all students ob-\ntained by different distillation methods have the\nsame inference speed.\nB More Discussion\nIn this section, we discuss the difference between\ndistilling the attribution maps and distilling the at-\ntention matrices. In a sense, attention matrices are\nsimilar to attribution maps since they both reflect\nthe contribution that each input token makes on a\nHyperparameterCoLA MNLI SST-2 QNLI MRPC QQP RTE STS-BLearning Rate4e-5 4e-5 5e-5 4e-5 3e-5 4e-5 2e-5 5e-5Total Batch Size32 64 32 32 16 32 16 16Max Seq. Length128 128 128 128 128 128 128 128Œ± 0.9 0.8 0.8 0.9 0.9 1.0 0.9 0.8Œ≤ 1 10 1 100 10 50 10 1œÑ 1 3 2 3 4 4 2 3K 768 768 768 768 768 734 700 640m 1 1 1 1 1 1 1 1# GPU 1 4 1 1 1 1 1 1Training Time30min 12hr 2.5hr 3hr 20min 16hr 12min 20min\nTable 5: Hyperparameter settings and training cost.\nmodel prediction to some extent (Bastings and Fil-\nippova, 2020; Xu et al., 2020). However, there are\nseveral drawbacks when it comes to distillation. On\none hand, attention correlates well with attribution\nlocally in specific layers and heads but not glob-\nally, indicating that attention maps are inadequate\nto draw conclusions that refer to the input of the\nmodel (Pascual et al., 2021). In other words, atten-\ntion matrices are more like model-specific knowl-\nedge that are probably challenging for the student\nto learn due to the layer mapping issue, especially\nwhen the student has much fewer parameters than\nthe teacher. On the other hand, some works point\nout that by adversarial training, alternative atten-\ntion weights can be found whereas the prediction\nremains almost the same (Jain and Wallace, 2019;\nWiegreffe and Pinter, 2019). Therefore, an opti-\nmal student unnecessarily shares similar attention\nmatrices with its teacher. Our proposed AD-KD\nadopts a more reliable gradient-based method to\nobtain the attribution maps, which is shown better\nthan attention matrices employed by baselines.\nC More Experimental Results\nC.1 Results on MultiRC\nConsidering that the text in GLUE is relatively\nshort (with Max_Seq_Length set to 128), We\nconduct additional experiments on SuperGLUE\n(Wang et al., 2019) for more comprehensive evalu-\nation. We select a challenging QA task, MultiRC\n(Khashabi et al., 2018), with much longer text (with\nMax_Seq_Length set to 512) which requires more\nattribution knowledge. As shown in Table 6, AD-\nKD improves 0.97% over vanilla KD and 0.38%\nover MGSKD. Moreover, the performance of AD-\nKD is on par with the teacher.\nModel #Params Acc\nBERTbase(Teacher) 110M 68.53\nVanilla KD 66M 67.70\nMGSKD 66M 68.29\nAD-KD 66M 68.67\nTable 6: Results on MultiRC development set.\n8461\n1 5 10 30 50 100\n(a) MRPC\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0MSE of attribution maps\n1e 3\ntrain\ndev\n1 10 50 100 150 200\n(b) QNLI\n1.0\n1.2\n1.4\n1.6\n1.8\n2.0\n2.2\n2.4MSE of attribution maps\n1e 3\ntrain\ndev\nFigure 9: Comparison of the attribution gap between teacher and student on training set and development set.\nC.2 Overfitting Study\nIn this section, we investigate whether the overfit-\nting problem would happen in attribution distilla-\ntion. Using Eq. (11), we calculate the attribution\ngap between the teacher and the student models on\nthe training and development sets of MRPC and\nQNLI respectively, and show the results in Fig-\nure 9. By altering Œ≤, the tendency of attribution\ngap on development sets is consistent with the one\non training sets, which indicates that the attribution\nknowledge learned from training data can be well\ngeneralized to unseen data. Therefore, overfitting\ntends not to happen in attribution distillation.\nC.3 Case Study\nIn this section, we provide two examples to\nshow how AD-KD facilitates the imitation of the\nteacher‚Äôs reasoning and outperforms vanilla KD.\nAs shown in Figure 10, vanilla KD makes mistakes\nby ignoring keyword Louisiana or emphasizing an\nirrelevant word billion. In contrast, the attribution\nmaps of AD-KD are more consistent with the ones\nin the teacher. AD-KD learns what to and not to\nfocus on and thus predicts the label correctly.\n8462\nTeacher\nQuestion:\nSentence: \nPrediction: Not entailment\nVanilla KD\nQuestion:\nSentence: \nPrediction: Entailment\nAD-KD\nQuestion:\nSentence: \nPrediction: Not entailment\nTeacher\nQuestion:\nSentence: \nPrediction: Entailment\nVanilla KD\nQuestion:\nSentence: \nPrediction: Not entailment\nAD-KD\nQuestion:\nSentence: \nPrediction: Entailment\nCase #1\nCase #2\nFigure 10: Two illustrative examples of attribution maps and predictions by teacher, vanilla KD and AD-KD from\nthe QNLI development set, where darker colors mean larger attribution scores. In case #1, AD-KD learns which\ntokens to focus on (Louisiana), while in case #2, AD-KD learns which tokens not to focus on (billion).\n8463\nACL 2023 Responsible NLP Checklist\nA For every submission:\n‚ñ°\u0013 A1. Did you describe the limitations of your work?\nSection Limitations\n‚ñ°\u0013 A2. Did you discuss any potential risks of your work?\nSection Ethics Statement\n‚ñ°\u0013 A3. Do the abstract and introduction summarize the paper‚Äôs main claims?\nSection Abstract and Section 1\n‚ñ°\u0017 A4. Have you used AI writing assistants when working on this paper?\nLeft blank.\nB ‚ñ°\u0013 Did you use or create scientiÔ¨Åc artifacts?\nSection 4\n‚ñ°\u0013 B1. Did you cite the creators of artifacts you used?\nSection 4.1 and Section 4.3\n‚ñ° B2. Did you discuss the license or terms for use and / or distribution of any artifacts?\nNot applicable. Left blank.\n‚ñ°\u0017 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided\nthat it was speciÔ¨Åed? For the artifacts you create, do you specify intended use and whether that is\ncompatible with the original access conditions (in particular, derivatives of data accessed for research\npurposes should not be used outside of research contexts)?\nThe datasets we use are consistent with those used in previous works.\n‚ñ° B4. Did you discuss the steps taken to check whether the data that was collected / used contains any\ninformation that names or uniquely identiÔ¨Åes individual people or offensive content, and the steps\ntaken to protect / anonymize it?\nNot applicable. Left blank.\n‚ñ°\u0013 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and\nlinguistic phenomena, demographic groups represented, etc.?\nSection 4.1\n‚ñ°\u0013 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits,\netc. for the data that you used / created? Even for commonly-used benchmark datasets, include the\nnumber of examples in train / validation / test splits, as these provide necessary context for a reader\nto understand experimental results. For example, small differences in accuracy on large test sets may\nbe signiÔ¨Åcant, while on small test sets they may not be.\nAppendix A.1\nC ‚ñ°\u0013 Did you run computational experiments?\nSection 5\n‚ñ°\u0013 C1. Did you report the number of parameters in the models used, the total computational budget\n(e.g., GPU hours), and computing infrastructure used?\nAppendix A.2\nThe Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing\nassistance.\n8464\n‚ñ°\u0013 C2. Did you discuss the experimental setup, including hyperparameter search and best-found\nhyperparameter values?\nSection 4.3 and Appendix A.2\n‚ñ°\u0013 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary\nstatistics from sets of experiments), and is it transparent whether you are reporting the max, mean,\netc. or just a single run?\nSection 5.1\n‚ñ°\u0013 C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did\nyou report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE,\netc.)?\nSection 4.3\nD ‚ñ°\u0017 Did you use human annotators (e.g., crowdworkers) or research with human participants?\nLeft blank.\n‚ñ° D1. Did you report the full text of instructions given to participants, including e.g., screenshots,\ndisclaimers of any risks to participants or annotators, etc.?\nNo response.\n‚ñ° D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students)\nand paid participants, and discuss if such payment is adequate given the participants‚Äô demographic\n(e.g., country of residence)?\nNo response.\n‚ñ° D3. Did you discuss whether and how consent was obtained from people whose data you‚Äôre\nusing/curating? For example, if you collected data via crowdsourcing, did your instructions to\ncrowdworkers explain how the data would be used?\nNo response.\n‚ñ° D4. Was the data collection protocol approved (or determined exempt) by an ethics review board?\nNo response.\n‚ñ° D5. Did you report the basic demographic and geographic characteristics of the annotator population\nthat is the source of the data?\nNo response.\n8465"
}