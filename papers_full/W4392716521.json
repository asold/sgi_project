{
    "title": "Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity",
    "url": "https://openalex.org/W4392716521",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2650293555",
            "name": "Aliya Amirova",
            "affiliations": [
                "King's College London"
            ]
        },
        {
            "id": "https://openalex.org/A2051117883",
            "name": "Theodora Fteropoulli",
            "affiliations": [
                "University of Cyprus"
            ]
        },
        {
            "id": "https://openalex.org/A2761605139",
            "name": "Nafiso Ahmed",
            "affiliations": [
                "University College London"
            ]
        },
        {
            "id": "https://openalex.org/A2314384217",
            "name": "Martin R. Cowie",
            "affiliations": [
                "King's College London",
                "Royal Brompton Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A1975341597",
            "name": "Joel Z. Leibo",
            "affiliations": [
                "King's College London",
                "DeepMind (United Kingdom)",
                "Google (United Kingdom)",
                "London Institute for Mathematical Sciences"
            ]
        },
        {
            "id": "https://openalex.org/A2650293555",
            "name": "Aliya Amirova",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2051117883",
            "name": "Theodora Fteropoulli",
            "affiliations": [
                "University of Cyprus"
            ]
        },
        {
            "id": "https://openalex.org/A2761605139",
            "name": "Nafiso Ahmed",
            "affiliations": [
                "University College London"
            ]
        },
        {
            "id": "https://openalex.org/A2314384217",
            "name": "Martin R. Cowie",
            "affiliations": [
                "King's College London",
                "King's College School"
            ]
        },
        {
            "id": "https://openalex.org/A1975341597",
            "name": "Joel Z. Leibo",
            "affiliations": [
                "King's College London",
                "Google (United Kingdom)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6778883912",
        "https://openalex.org/W4296154596",
        "https://openalex.org/W4361855702",
        "https://openalex.org/W4292947474",
        "https://openalex.org/W4376117416",
        "https://openalex.org/W4380763235",
        "https://openalex.org/W4363624465",
        "https://openalex.org/W2808652965",
        "https://openalex.org/W4225369896",
        "https://openalex.org/W3033969121",
        "https://openalex.org/W3130536031",
        "https://openalex.org/W4387099597",
        "https://openalex.org/W2099460238",
        "https://openalex.org/W4228997196",
        "https://openalex.org/W4283789234",
        "https://openalex.org/W2106905614",
        "https://openalex.org/W2475699009",
        "https://openalex.org/W6813861048",
        "https://openalex.org/W1976770755",
        "https://openalex.org/W4293109019",
        "https://openalex.org/W3194472989",
        "https://openalex.org/W2162544110",
        "https://openalex.org/W2151997300",
        "https://openalex.org/W4289782714",
        "https://openalex.org/W2154324360",
        "https://openalex.org/W2104013129",
        "https://openalex.org/W3001883807",
        "https://openalex.org/W3197275563",
        "https://openalex.org/W3166500632",
        "https://openalex.org/W2077109464",
        "https://openalex.org/W2787894218",
        "https://openalex.org/W2626804490",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W4385684404",
        "https://openalex.org/W4226293037",
        "https://openalex.org/W1971765404",
        "https://openalex.org/W4387835442",
        "https://openalex.org/W6853370752",
        "https://openalex.org/W2674995983",
        "https://openalex.org/W2774194400",
        "https://openalex.org/W2167814132",
        "https://openalex.org/W2063492576",
        "https://openalex.org/W2116567300",
        "https://openalex.org/W4210818049",
        "https://openalex.org/W3108106255",
        "https://openalex.org/W1612039089",
        "https://openalex.org/W2027372481",
        "https://openalex.org/W1970340312",
        "https://openalex.org/W1986718191",
        "https://openalex.org/W2085876742",
        "https://openalex.org/W4389520124",
        "https://openalex.org/W4283170666",
        "https://openalex.org/W2963457723",
        "https://openalex.org/W3150910992",
        "https://openalex.org/W4224276996",
        "https://openalex.org/W2112939849",
        "https://openalex.org/W4245576698",
        "https://openalex.org/W2810420903",
        "https://openalex.org/W4296405185",
        "https://openalex.org/W4280531175",
        "https://openalex.org/W3172330035",
        "https://openalex.org/W4362707083",
        "https://openalex.org/W3133702157",
        "https://openalex.org/W3181414820",
        "https://openalex.org/W4324373918",
        "https://openalex.org/W2525936901",
        "https://openalex.org/W4319344822",
        "https://openalex.org/W2576798161",
        "https://openalex.org/W4388656823",
        "https://openalex.org/W614732466",
        "https://openalex.org/W4253289976",
        "https://openalex.org/W4321455981",
        "https://openalex.org/W4230519770",
        "https://openalex.org/W4321392130",
        "https://openalex.org/W2958072999",
        "https://openalex.org/W4387805041",
        "https://openalex.org/W4281673693",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4388488609",
        "https://openalex.org/W4282921499",
        "https://openalex.org/W1531590217",
        "https://openalex.org/W4379283884",
        "https://openalex.org/W4210520398",
        "https://openalex.org/W2084772351"
    ],
    "abstract": "Today, with the advent of Large-scale generative Language Models (LLMs) it is now possible to simulate free responses to interview questions such as those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial “silicon participants” generated by LLMs may be productively studied using qualitative analysis methods in such a way as to generate insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity , a validity concept capturing the degree to which LLM-generated outputs mirror human sub-populations’ beliefs and attitudes. By definition, high algorithmic fidelity suggests that latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with “silicon participants” matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of a hyper-accuracy distortion. We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect in silico research on it to generalize to real human populations. However, rapid advances in artificial intelligence raise the possibility that algorithmic fidelity may improve in the future. Thus we stress the need to establish epistemic norms now around how to assess the validity of LLM-based qualitative research, especially concerning the need to ensure the representation of heterogeneous lived experiences.",
    "full_text": "RESEA RCH ARTICL E\nFramework-based qualitative analysis of free\nresponses of Large Language Models:\nAlgorithmic fidelity\nAliya Amirova\nID\n1\n*, Theodora Fteropoulli\nID\n2\n, Nafiso Ahmed\n3\n, Martin R. Cowie\n4,5\n, Joel\nZ. Leibo\n6,7\n1 Population Health Sciences, School of Life Course & Population Sciences, Faculty of Life Sciences &\nMedicine, King’s College London, London , United Kingdom, 2 Medical School, University of Cyprus , Nicosia,\nCyprus, 3 Division of Psychiatry, Univers ity College London, London, United Kingdom , 4 Royal Brompton\nHospital, London , London, United Kingdom , 5 School of Cardiovasc ular Medicine & Sciences, Faculty of Life\nSciences & Medicine, King’s College London, London , United Kingdom, 6 Google DeepMind, London ,\nLondon, United Kingdom , 7 Department of Informatics, Faculty of Natural, Mathemat ical & Engineeri ng\nSciences, King’s College London , London, United Kingdom\n* aliya.1.am irova@kcl.ac .uk\nAbstract\nToday, with the advent of Large-scale generative Language Models (LLMs) it is now possi-\nble to simulate free responses to interview questions such as those traditionally analyzed\nusing qualitative research methods. Qualitative methodolog y encompasses a broad family\nof techniques involving manual analysis of open-ended interviews or conversations con-\nducted freely in natural language. Here we consider whether artificial “silicon participants”\ngenerated by LLMs may be productively studied using qualitative analysis methods in such\na way as to generate insights that could generalize to real human populations. The key con-\ncept in our analysis is algorithmic fidelity, a validity concept capturing the degree to which\nLLM-generated outputs mirror human sub-populations’ beliefs and attitudes. By definition,\nhigh algorithmic fidelity suggests that latent beliefs elicited from LLMs may generalize to real\nhumans, whereas low algorithmic fidelity renders such research invalid. Here we used an\nLLM to generate interviews with “silicon participants” matching specific demographic char-\nacteristics one-for-one with a set of human participants. Using framework-based qualitative\nanalysis, we showed the key themes obtained from both human and silicon participants\nwere strikingly similar. However, when we analyzed the structure and tone of the interviews\nwe found even more striking differences. We also found evidence of a hyper-accuracy dis-\ntortion. We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic\nfidelity to expect in silico research on it to generalize to real human populations. However,\nrapid advances in artificial intelligence raise the possibility that algorithmic fidelity may\nimprove in the future. Thus we stress the need to establish epistemic norms now around\nhow to assess the validity of LLM-based qualitative research, especially concerning the\nneed to ensure the representation of heterogeneous lived experiences.\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 1 / 33\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Amirova A, Fteropoulli T, Ahmed N, Cowie\nMR, Leibo JZ (2024) Framework-ba sed qualitative\nanalysis of free responses of Large Language\nModels: Algorithmic fidelity. PLoS ONE 19(3):\ne0300024. https://d oi.org/10.1371/j ournal.\npone.030002 4\nEditor: Primoz ˇ Kocbek, University of Maribor\nFaculty of Health Sciences : Univerza v Mariboru\nFakulteta za Zdravstve ne Vede, SLOVENIA\nReceived: October 2, 2023\nAccepted: February 21, 2024\nPublished: March 12, 2024\nCopyright: © 2024 Amirova et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: Qualitative data\nunderpinni ng the manuscript cannot be shared\npublicly because of the nature of the data and\nethics committe e agreement (Health Research\nAuthority. Cambridge Central Research Ethics\nCommitte e, REC reference: 17/EE/0183) .\nParticipants’ approved consent specifica lly states\nthat potentially identifiabl e participant data will not\nbe shared. Given the nature of the qualitative\ntranscripts and data analys is, although information\non names, clinical team names and family\nIntroduction\nLarge-Scale generative Language Models (LLMs) [1–3] may provide a new opportunity for\ncapturing available knowledge and beliefs at scale and facilitate in silico research on human\nbehavior and cognition [4–8]. By virtue of their training, LLMs may contain substantial latent\nsocial information [9]—enough to consider them plausible computational models of humans.\nLLMs may capture economic laws, decision-making heuristics, and social preferences [9], as\nwell as mirroring human moral judgments [7]. In principle, using LLMs could be a cost-effec-\ntive and efficient way to gain insights and explore how self-reports vary, as well as to pilot\nexperiments in silico to test sensitivity of responses to precise wording. Cheap and easy to run\nin silico experiments can guide expensive and slow empirical work with real participants. How-\never, how can we know such results are trustworthy?\nAlgorithmic fidelity is an appropriate validity concept for research on human behavior\nusing survey data simulated using Large-scale generative Language Models (LLMs) [4]. Algo-\nrithmic fidelity describes the extent to which the outputs of LLMs conditioned to simulate spe-\ncific human sub-populations actually reflect the beliefs and attitudes of those subpopulations.\nBy definition, high algorithmic fidelity suggests that beliefs elicited from the LLM will gen-\neralize to real humans, while low fidelity renders such inferences invalid. Argyle et al. [4] intro-\nduced the idea of generating “silicon samples” or “silicon participants” by conditioning LLMs\nusing backstories matching sociodemographic data from human survey participants. Their\nstudy found that LLM outputs closely mirrored the complex interplay of beliefs, attitudes, and\nsociocultural contexts that shape human responses to surveys about American politics. In the\npresent study, we aim to extend algorithmic fidelity assessment methodology [4] using qualita-\ntive research methods so that it can be applicable to studies where the data consists of fully\nfreeform responses in natural language.\nThere are numerous applications for models with demonstrably high algorithmic fidelity.\nThey include digital avatars [10, 11], digital behaviour change interventions [12–14], digital\ntherapeutics, [15, 16], non-player characters for computer games [17], and teaching assistants.\nAlgorithmic fidelity assessment will also be important in research that aims to construct multi-\nagent simulations to simulate the effects of interventions (e.g. [18, 19]) to guide policy making\nin regimes where real experiments are infeasible. This approach aims to address core objectives\nfor responsible AI deployment and regulation [20, 21]. In these settings, the reason to assess\nalgorithmic fidelity is to provide empirical validation for a part of a model to be used in a\ndownstream application where direct validity measures for the full multi-agent model do not\nexist.\nThere is no reason to think algorithmic fidelity would be uniform over the many and varied\nparts of human lived experience or the many and varied social science research topics. These\nmodels will clearly be better at simulating some people over other people, and work better for\nsome applications than others. Argyle et al. [4] conclude from this that algorithmic fidelity\nmust be measured anew for each research question. Determining there is sufficient algorithmic\nfidelity to address one research question does not imply the same will be true for others [4]. At\npresent, there are still no generally accepted best practices for research on humans using\nLLMs. Nevertheless, we think one aspect of sound methodology is already clear at this point:\nthere should be guidelines counseling researchers to perform a dedicated assessment of algo-\nrithmic fidelity tailored for their specific research question and target population.\nUnderstanding beliefs mediated using natural language and their impact on behavior (e.g.,\nbeliefs such as “vaccination is an effective and safe way to protect me and others around me”) is\nimportant but not straightforward to study using conventional frequentist methods. Qualita-\ntive research methods come to the rescue when the nuance of such beliefs needs to be\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 2 / 33\nmembers’ names was retracted, the transcripts still\ncontain detailed information that can be traced\nback to single individuals even in the aggregate\nform, given the study context. A point of contact:\nNRESComm ittee.EastofEng land-\nCambridge Central@nhs .net.\nFunding: The author(s) received no specific\nfunding for this work.\nCompeting interests : I have read the journal’s\npolicy and the authors of this manuscript have the\nfollowing competing interests: JZL is an employee\nof Google.\nunderstood. Some of these methods include ethnography [22], phenomenological studies [23],\ngrounded theory [24], thematic analysis [25], and framework-based analysis [26]. For example,\nwhen exploring the acceptability of newly developed treatments, we might want to elicit beliefs\nand attitudes from stakeholders to improve services and healthcare [27–29]. Stakeholders may\nhave critical information that would be missed if researchers were to rely only on prior theo-\nries, experiments, and survey data. In fact, involving stakeholders can guide the development\nof interventions and policies that are relevant, effective and acceptable for them, ultimately\nleading to improved outcomes [28, 29]. This is helpful for allocating research efforts to the\nmost important problems and for ensuring interventions are targeted. Another research field\nwhere it is important to understand latent beliefs mediated by natural language is behavior\nchange. The goal of this field is to promote beneficial behavior or reduce harmful behavior\n[30]. Behavior change may be considered on a variety of different scales. For instance, health\npsychologists are concerned with determining the barriers and enablers to vaccination, adopt-\ning healthy behaviors (e.g. exercise), or ceasing to engage in harmful behaviors (e.g. tobacco\nsmoking). There is a related research program that seeks interventions by which whole com-\nmunities can be helped to adopt helpful social norms (e.g. educating girls) or drop harmful\nnorms (e.g. child marriage) [31]. Such research affects wellbeing and health of the general pub-\nlic. Appropriate standards evaluating the rigor with which it is conducted and the trustworthi-\nness of its findings should be in place.\nThe present study is concerned with the methodological question of whether or not LLMs\ncontain sufficient algorithmic fidelity for us to generalize and extrapolate the results generated\nby them to human populations of interest. To illustrate how to assess algorithmic fidelity for\nfreeform natural text data, we draw on a qualitative study using semi-structured interviews\nwith heart failure patients that aimed to elicit beliefs about barriers and enablers influencing\nphysical activity [32]. Increasing physical activity levels is known to have many health benefits\nfor this group [33–35]. However, most patients do not do enough [36] as they face barriers\nassociated with older age, co-morbid depression, symptom distress, and negative emotional\nresponse to physical activity [37]. Promoting physical activity for this population group is chal-\nlenging [38]. Research on this type of questions has serious implications for individual and\npopulation health.\nWe find that GPT-3.5 has insufficient algorithmic fidelity to address the research question\nof how to promote physical activity in older adults with heart failure. Nevertheless, even\nthough our specific result was negative, we do think this technology is promising. It is very\nlikely that future systems will have sufficient algorithmic fidelity to support trustworthy in sil-\nico research, all the more reason to critically engage now with this validity concept. We predict\nthat it will become the core validity concept needed to support this nascent field going forward.\nIt’s important to demonstrate how it can be used to reject invalid in silico research now, so that\nonce LLMs have improved enough we will then be able to use this logic routinely to support or\nreject the validity of specific research findings. In short, we need to develop epistemic norms\nto apply when we review papers and decide whether to approve or disapprove of arguments\nthat arise in this newly LLM-enabled field of research on human behavior.\nThe main methodological contribution of the present study is to apply framework-based\nqualitative research methods [26] to assessing algorithmic fidelity for LLM-generated freeform\nnatural text data. This approach to qualitative analysis finds patterns in free-form text, exam-\nines their relationships, and derives common themes [26]. Employing a well-established\nframework supported by domain expert consensus ensures consistency in semi-structured\ninterviews between human participants and LLMs, setting a uniform standard for evaluation.\nIn addition, without a framework for the interview schedule, there is a risk that results would\nnot amount to much more than anecdotes and, thus, not be credible. However, by using a\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 3 / 33\nframework, it is possible to systematically probe the beliefs of both silicon and human partici-\npants and thereby build confidence that the list of uncovered beliefs is complete enough to be\nuseful. The specific framework we used in this study is called Theoretical Domains Framework\n(TDF) [39].\nHowever, we show that, currently, LLMs do not demonstrate sufficient algorithmic fidelity.\nYet, with the fast-paced development of these technologies, it is expected that they will in the\nnot-so-distant future. Establishing a disciplinary consensus on defining and evaluating algo-\nrithmic fidelity is therefore crucial. Before LLMs can safely be used in designing interventions\nand policies there is a need to develop a set of guidelines for routine assessment of algorithmic\nfidelity to support or reject claims made using them. Such guidelines should consider the faith-\nfulness of the LLM to lived experiences and stakeholder beliefs.\nLarge language models\nOur approach to assessing algorithmic fidelity involves conducting interviews with silicon par-\nticipants matching the specific demographic characteristics of a set of real human participants.\nBefore we justify this approach, we need to provide some additional background on LLMs.\nLanguage models are conditional distributions over natural language. They are probability\ndistributions P(x\nn\n|x\nn−1\n, . . ., x\n0\n) where all x\ni\nare parts of words. A sentence is a sequence x\n0\n, . . .,\nx\nn\n. A paragraph is a longer such sequence. These complex conditional probability models are\ncreated (i.e. trained) by maximizing the likelihood of a dataset consisting of many billions of\ndocuments, harvested both from books and from the internet (e.g. [40]). Predicting x\nn\nfrom its\ncontext (the preceding x\nn−1\n, . . ., x\n0\n), requires the model to absorb a substantial amount of\nlatent knowledge about the world, about language, and about people. When an LLM has suffi-\ncient algorithmic fidelity, we may prompt it with a context containing demographic informa-\ntion (e.g. “a 74-year-old man with heart failure and arthritis who lives in a major city”) to elicit\noutputs that correlate with the attitudes, opinions, and experiences of the human sub-popula-\ntion to whom the specified demographic data applies.\nGenerating samples from an LLM is done autoregressively, word by word, conditioning on\nthe growing sequence of preceding words leading up to the next one to be predicted (Fig 1).\nTo prevent the conditioning sequence from growing longer and longer it is cut off once a cer-\ntain maximum size is reached called the context length. Once a document (or conversation\nwith a chatbot) grows beyond context length in size some of the preceding words must be\ndropped, so they no longer condition subsequent outputs. Different LLMs and systems make\ndifferent choices in how exactly they handle the necessary “forgetting” required to support\nlong contexts. However, there are many ways to simulate longer contexts with shorter contexts\nso the user may not notice when the conversation grows beyond context length.\nIt’s crucial to note that the concepts of validity and reliability, commonly employed in sta-\ntistics, don’t have direct analogues that can be confidently applied to LLMs. Empirical assess-\nment is the only way to ensure their validity. Most models considered in applied machine\nlearning are both too complicated and too closely tailored to their specific application to be\ngenerically justified. Applied machine learning researchers typically think about methodologi-\ncal rigour as demanding they implement “cross validation” procedures which estimate opera-\ntionalized generalization concepts. The most critical such procedure is to split data into a\nportion used for training, i.e. model fitting, and a different portion used for testing [41].\nSome large-scale generative language models go through a fine-tuning step where human\nraters provide specific feedback used to train them to follow instructions and align with ethical\nprinciples and product design goals [42]. These include Sparrow [43], Anthropic’s assistant\n[44], and Instruct-GPT [45], the latter of which was the basis for the GPT-3.5 system which we\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 4 / 33\nused in this paper. Fine-tuning can be accomplished through a variety of techniques, the most\nprominent being Reinforcement Learning from Human Feedback (RLHF). It involves human\nraters selecting which of several possible model responses they prefer. The raters are not asked\nthe subjective question of which response they themselves prefer, but rather are given a specific\nchecklist of product design goals to apply in making their judgments. All the model’s capabili-\nties are already present after the pretraining stage [46]. The postprocessing steps aim to reduce\nthe raw model’s propensity to produce toxic responses as well as to make it implement a con-\nsistent “personality” in accord with product design goals. These steps are not always entirely\neffective in preventing LLMs from producing undesirable behaviors like toxic or harmful lan-\nguage, and “jailbreak” prompts which trick the model into responding inappropriately are still\neasy to discover and implement [47, 48].\nAlgorithmic fidelity\nArgyle et al. (2023) offered a suggestion for how to use LLMs in social science research. Given\nthe correct conditioning, the authors argue that free-text output generated by large language\nmodels like GPT-3 can serve as effective proxies for specific human population groups. Argyle\net al. (2023) introduce a concept referred to as algorithmic fidelity, which describes an ability of\na language model to accurately reflect the ideas, beliefs, and attitudes situated in sociocultural\ncontexts of various population groups when adequately conditioned. This is a departure from\nthe common view that AI biases are uniform across models. Instead, they argue that these\nbiases are nuanced and demographically correlated. Such a view offers a deeper and more\nfine-grained understanding of the LLMs outputs and the biases they are subjected to. The\nFig 1. Schematic represe ntation of autoreg ressive sampling in large language models (LLMs). The diagram illustrates the\niterative sampli ng process in three stages: input, processing by the LLM, and output. The LLM represents the probability\ndistributi on over all possible next words given the current context (previous words). Arrows indicate the flow of information ,\nwith solid arrows representing the transition from one stage to another within a single iteration, and dotted arrows indicating the\nprogress ion from one iteration to the next. The outputted words (“a”, “time”, “there”) are samples from the correspond ing\nprobabil ity distributions and are appende d to the contex t for the next iteration.\nhttps://d oi.org/10.1371/j ournal.pon e.0300024.g0 01\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 5 / 33\nresearchers propose that “silicon samples” can be generated by training and prompting LLMs\nusing sociodemographic backstories from real human participants in several large surveys con-\nducted in the U.S. They then compared the outputs of the model against the responses of the\nhuman participants to assess the accuracy of the model’s representation. They found that\nmodel outputs go beyond sharing superficial similarities and instead reflect the nuanced and\ncomplex interplay between ideas, attitudes, and the sociocultural context that shaped them.\nArgyle et al. (2023) propose that with sufficient algorithmic fidelity, language models like\nGPT-3 can be used as tools for advancing our understanding of humans and society across\nvarious disciplines. This could transform how we approach social science research, offering\nnew perspectives and opportunities for piloting and conducting research at scale. Argyle et al.\n(2023) provide a framework for evaluating algorithmic fidelity through four distinct criteria:\n(1) Generated responses are indistinguishable from parallel human texts (a social science\nTuring test) (2) Generated responses are consistent with the attitudes and sociodemographic\ninformation of its input (i.e., conditioning context) such that humans viewing the responses\ncan infer critical elements of that input (Backward Continuity); (3) Generated responses pro-\nceed naturally from the conditioning context provided, reliably reflecting the form, tone, and\ncontent of the context (Forward Continuity); (4) Generated responses reflect underlying pat-\nterns of relationships between ideas, demographics, and behaviour that would be observed in\ncomparable human-produced data (Pattern Correspondence). Silicon Sampling is the method-\nology proposed by Argyle et al. (2013), which describes how to use an LLM to generate a vir-\ntual dataset (i.e., silicon samples) using demographic backstories as prompts to create\nvariability. Conditioning on a backstory is expected to produce outputs from the model repre-\nsentative of the subpopulation of real people with a similar backstory.\nWe can make an LLM simulate multiple different silicon participants. We did this by pro-\nviding each participant with a distinct prompt containing their biographical information. For\ninstance, using backstories with fictional names, that were popular in 1950 like:\n“The participant is a 77-year-old woman with heart failure and rheumatoid arthritis called\nLinda. Linda lives in the countryside. She is fairly physically active.”\nThe model continues sampling freeform natural language correlated with the identity pro-\nvided to it in its prompt.\nThe algorithmic fidelity criteria developed by Argyle et al. [4] were designed for written sur-\nvey-based outputs. We propose modified versions of these criteria that are more appropriate\nfor qualitative research, summarising free-form spoken text conveying latent knowledge:\n1. Social Science Turing Test: content. This criterion assesses whether LLM-generated\nresponses are indistinguishable from parallel human responses in their content. Content\ncan be summarised as a set of belief statements using a framework like TDF. This shifts the\nfocus away from the surface-level similarity of the text to its semantic content: the specific\nbeliefs and viewpoints, and latent meaning. Is the generated response similar to the human\nresponse in its content? Is it what a human would say?\n2. Social Science Turing Test: hyper-accuracy distortion. Hyper-accuracy distortion is the ten-\ndency of models to generate responses that may be technically accurate but contextually\ninappropriate or implausible [6]. The hyper-accuracy distortion is an especially vivid exam-\nple of a failure of algorithmic fidelity. The model is supposed to know it is extremely\nunlikely that a five-year-old child would know the answer to a specific scientific question\nabout galaxy formation or number theory. So if conditioned to play the part of a child it\nshould not know the answer. When it goes ahead and answers anyway, that’s a failure of\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 6 / 33\nalgorithmic fidelity. In our study, a good example is a response from Robert, one of the sili-\ncon participants, that included the exact text from World Health Organisation guidelines\non physical activity (2021): “They also gave me guidelines to follow, such as aiming for at\nleast 150 minutes of moderate-intensity aerobic activity or 75 minutes of vigorous-intensity\naerobic activity a week, or a combination of both. They also advise me to include muscle-\nstrengthening activities that involve all major muscle groups on at least 2 days a week.”.\n3. Social Science Turing Test: structure and tone. This criterion assesses whether the way the\nbeliefs are narrated is indistinguishable from human participants. Is LLM-generated output\nsimilar in its structure and tone to human responses? Does an LLM-generated response look\nlike a response from human participants?\n4. Backward Continuity. This criterion assesses whether the model’s responses are consistent\nwith their sociodemographic conditioning prompts such that when a human rater views\nthe response they can then infer elements of the conditioning prompt. It asserts that sam-\nples from P(prompt|response), i.e. the probability distribution of getting a particular\nprompt given a response, make sense to an expert rater who is already familiar with the\nhuman data, and once they see the response (i.e. the interview), they can make a reasonable\nguess of the prompt (the backstory). Alternatively, we may say that the expert rater when\ngiven the response would not be surprised to learn the prompt that created it.\nFor example, if a silicon participant mentions that they have arthritis in their response then\nit is likely that their having arthritis was mentioned in their conditioning prompt. This\nshows that the model is maintaining backward continuity. The information provided in the\nresponse can be traced back to the prompt. Backward Continuity ensures the model doesn’t\nforget or contradict information from the prompt.\n5. Forward Continuity. This criterion assesses whether generated responses proceed naturally\nand consistently from the given context (e.g., look at whether the model can generate\nresponses that align with the provided context and develop and expand on it to reflect\nhuman thought processes) [4]. This might include, for example, elaborating on certain\nbeliefs, providing examples, or making connections between different ideas). It asserts that\nsamples from P(response|prompt) make sense i.e. an expert rater who is already familiar\nwith the human data can, when given the prompt (the backstory), make a reasonable guess\nof the response (the interview). Alternatively, we may say that the expert rater when given\nthe backstory would not be surprised to learn about the interview it subsequently elicited.\nThis emphasizes the expectation that the response should naturally follow from and be\nrelated to the prompt.\nWe divide the criterion of Forward Continuity into two parts: explicit forward continuity\nand inferred contextual continuity to accommodate the complexity of the free-form text.\nThe explicit forward continuity criterion assesses the ability of LLM to include and main-\ntain all explicitly provided background details in its responses, such as comorbid health\nconditions, urban vs. countryside residence, gender, and more.\nThe inferred forward continuity criterion, on the other hand, assesses the model’s ability to\ngenerate and maintain relevant backstory details not explicitly mentioned, but rather\ninferred, from other pieces of information. For instance, in situations where we provided\ninformation about advanced age, it would be desirable for the model to infer from this\ndetail that retirement could be a significant factor influencing their physical activity levels,\nsimilar to the assumptions and connections a human might naturally make in such a sce-\nnario. This illustrates the principle of inferred contextual forward continuity, where the lan-\nguage model not only maintains the explicit details provided by the user but also generates\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 7 / 33\nand incorporates inferred details based on those given explicitly.\nForward continuity ensures the model builds on and evolves the conversation in a logical\nand human-like manner consistent with the prompt.\n6. Pattern Correspondence. This criterion assesses whether the relationships between variables\nin the silicon participants match relationships between variables in the human data. For\ninstance, can the model capture the different barriers and enablers in active vs sedentary sil-\nicon participants in a way that is consistent with human data? In the case of qualitative\nresearch, this criterion probes whether the pattern generated by the LLM emulates the pat-\ntern of thought and behavior identified in human data. For instance, in our application it\nassesses whether the model captures the difference in barriers and enablers present in active\nvs sedentary participants.\nIt is important for the field to come up with guidelines and protocols to assess and improve\nalgorithmic fidelity. Qualitative researchers are well-positioned to take on this important part\nof the challenge of ensuring algorithmic fidelity, especially that of ensuring representation of\ndiverse lived experiences.\nMaterials and methods\nDesign\nOne-to-one semi-structured interviews were conducted with 16 human participants (detailed\nmethods reported in [32]) and 32 silicon participants. The interviews were guided by a sched-\nule based on the Theoretical Domains Framework. The same interview schedule was used for\nboth human and silicon participants. Interviews with human participants were more flexible\nowing to the spoken conversational style of the interview.\nHuman participants\nA previously reported study aimed to explore barriers and enablers to everyday physical activ-\nity among individuals living with heart failure, and to delineate relevant beliefs [32]. Human\nparticipants were recruited from outpatient cardiology clinics at the Royal Brompton and\nHarefield NHS Foundation Trust, UK between 05 June 2017 and 05 June 2019, (see: https://\nwww.hra.nhs.uk/planning-a nd-improving-research/applicatio n-summaries/research-\nsummaries/factors-influencin g-physical-activity-in-heart-failur e/). Informed consent was\nsought for all human participants [32] Those who expressed an interest were introduced to the\nresearcher (AA). Each participant was provided with a participant information sheet (PIS) and\nan informed consent form (ICF). The researcher described the study aims, objectives, and pro-\ncedures in more detail and answered participants’ questions about the study. Individuals who\nexpressed an interest in participating in the study were given an option to consider their par-\nticipation over 24 hours. Those who decided to take part were asked to provide written partici-\npant consent, which was documented using an informed consent form (ICF). The ethics\napproval was received from the East of England–Cambridge Central Research Ethics Commit-\ntee (REC reference: 17/EE/0183). Human participants cannot be identified from any reports.\nHuman participant recruitment is described in the previous report of the semi-structured\ninterviews with humans [32]. Individuals age 70 and over, diagnosed with heart failure, as\nspecified by the contemporaneous European Society of Cardiology guidelines [49]. To be\nincluded in the study, a prospective human participant had to be (1) clinically stable (i.e.,\nsomeone who has not experienced a change in their condition’s severity, New York Heart\nAssociation (NYHA) class, or medical regimen in the past three months); (2) able to provide\ninformed consent and to converse in English. Individuals with uncontrolled angina or\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 8 / 33\nsymptoms even at rest (NYHA class IV) and those who were recommended to avoid exercise\nor any moderate or strenuous physical activity by a healthcare professional were excluded.\nOne-to-one interviews were conducted face-to-face in a research room available at the clinic\n(n = 6), a vacant consultancy room (n = 6) and via phone (n = 4). All interviews with human\nparticipants were audio-recorded and transcribed verbatim. Interviews’ duration ranged\nbetween 15 to 85 minutes (mean = 41.24, SD = 20.97).\nHuman participants were sampled using the criterion sampling strategy within pragmatic\nlimits, i.e. having the diversity and breadth of the population in mind, including physical func-\ntioning level (NYHA class), ethnicity, and sex, please see the original report [32]. Human par-\nticipant recruitment has been reported previously, and qualitative data saturation was checked\nto ensure that a sufficient number of samples were recruited. We used a structured approach\nfor determining saturation in theory-based interview studies, particularly those utilizing pre-\nestablished conceptual categories from existing theory, following methodology outlined by\n[50]. First, we specified a minimum sample size. This step involves determining a baseline\nnumber of interviews or participants to begin the analysis. The purpose is to ensure a sufficient\ndepth and breadth of data to start identifying patterns, themes, or categories relevant to the\nexisting theory. Then we defined a Stopping Criterion Based on the emergence of New Ideas:\nThis principle involves setting a clear rule for when to cease data collection. The stopping crite-\nrion is met when a predetermined number of additional interviews are conducted without any\nnew ideas or themes emerging. This is aimed at ensuring efficiency and preventing unneces-\nsary data collection once saturation has been reached.\nSilicon participants\nAll interviews with silicon participants were conducted with the December 15th 2022 version\nof GPT-3.5. Silicon participants included 32 hypothetical individuals living with HF, that were\nclosely matched to the human participants. They were matched for (1) age, (2) gender, (3)\ncomorbid conditions, (4) whether they had a cardiac implantable device or not, (5) whether\nthey lived in a major city or in the countryside, and (6) whether or not they had had a heart\nattack in the past. We chose the names of silicon participants by selecting names from a list of\nthe most popular baby names in 1950 in their corresponding human participant’s country of\norigin.\nInterviews were initiated using a prompt such as the following:\n“The following is a conversation between two actors. One is playing a researcher asking ques-\ntions about physical activity, and the other is a research participant, a 77-year-old man called\nJames. James has heart failure. In addition, he was diagnosed with atrial fibrillation and diabe-\ntes. James has suffered a heart attack in the past. He was fitted with a cardiac implantable device.\nJames lives in the countryside. He does very little physical activity most days. Both are performing\nfor an audience and are very committed to their roles. So they both never step out of character,\nnot even for a moment.”).\nThe above example generates a sedentary silicon participant since it contains the sentence,\n“He (or she) does very little physical activity most days.” We paired each sedentary participant\nwith a corresponding active participant who shared the same initial prompt but with this sen-\ntence replaced by “He (or she) is fairly physically active.”.\nWe asked questions in the same order to all silicon participants to avoid biasing the results\nby variation in question order. The initial prompt included a backstory, the second prompt\nwas the first question of the interview schedule. This leaves GPT-3.5 free to invent the first few\nquestions of the interview. After the end of the generated text, with it still in context, we then\nmanually took on the role of the researcher and continued the interview following the same\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 9 / 33\ntopic guide we used with the human participants. Letting GPT-3.5 invent the beginning of the\ninterview was a way to ensure that it would quickly add rich detail inspired by the backstory\ninto the discussion. Eliciting these details early in the conversation made them more likely to\ninfluence the rest of the interview. This generated more diverse silicon participants than could\nhave been obtained by starting directly in with the first interview question. Sometimes GPT-\n3.5 would continue both sides of the conversation, replying for both the participant and the\nresearcher. We made no attempt to prevent this behavior. We always TDF-annotated all text\nthat GPT-3.5 labeled as coming from the participant, regardless of whether it was in response\nto a question we asked or a question it asked itself in the role of the researcher.\nIn contrast to studies of human behavior where it is critical to avoid priming, the incremen-\ntal accumulation of background in the text prompt used for the silicon participants offers a\nbeneficial conditioning effect. This methodology, as highlighted in studies by [51–53], is help-\nful for enabling the development of a distinct “persona” of each silicon participant throughout\nthe dialogue. Without this incremental identity-building process, the responses would tend to\nconverge towards uniformity (even with temperature = 1.0 in our experiments). This sampling\nprotocol allows each interview to evolve uniquely after the LLM creates life details in response\nto initial prompts. This approach, where a consistent “persona” is built up incrementally, has\nalso been described in other recent work including [52], especially see Fig 3 in that paper. It\nalso underpins a newer approach to simulating agents with LLMs called generative agent-\nbased modeling [51, 53].\nAs a sensitivity analysis, we repeated a subset of the interviews using different LLMs includ-\ning GPT-4, and varied the temperature settings used for sampling. We did not observe any\nqualitative differences in barriers or enablers between these interviews and the original set, nei-\nther when we varied temperature nor when we tried GPT-4. In the interviews with GPT-4\nthere was one small difference in transcript style though. GPT-4 would very commonly include\n“stage directions” or facial expressions such as (e.g. “Linda: (Nods thoughtfully): . . .”). See S1\nFile for details of the sensitivity analysis.\nInterview schedule\nHuman participants were interviewed using a flexible interview schedule. The schedule was\ndesigned to elicit the description of physical activity and beliefs relevant to HF. Feedback from\nhealth experts, a cardiologist, a nurse, and individuals diagnosed with HF was obtained to\nrefine the interview schedule. A pilot interview was conducted to further enhance the inter-\nview structure and length. Silicon participants were asked exact same prompts as human par-\nticipants, however, in a fixed order.\nQualitative data analysis\nHuman data were collected through audio recordings of the interviews, with participant con-\nsent, which was then transcribed verbatim. NVivo 12 software was used to facilitate the analy-\nsis of the data. The analysis was performed consistently with a widely used method [54] and\ninvolved annotating transcripts line-by-line, and categorizing monothematic parses (ie.,\nquotes) of text into domains specified by Theoretical Domains Framework [39]. Then, all\nquotes that were categorised into domains, were summarized into belief statements. A belief\nstatement was considered as a collection of responses with a similar theme that could affect the\ntarget behaviour. To be coded as present, each interview transcript must show strong evidence\nof a belief affecting behaviour. The frequencies of quotes supporting each belief statement\nwere calculated and then were also aggregated to respective TDF domains. The relevance of\nthe belief statements was evaluated based on their pervasiveness (i.e., how frequently it was\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 10 / 33\nmentioned across all transcripts or the number of quotes) and commonality (i.e., how many\nindividual transcripts mention it at least once). For the purpose of ensuring accurate compari-\nson, the study did not allow the encoding of the parses into multiple theoretical domains\nwithin TDF.\nTheoretical Domains Framework (TDF) originates in the field of implementation science\nand health psychology concerned with behavior change (e.g., promoting implementation of\nrecommended practices and guidelines by health professionals, increasing physical activity,\nand smoking cessation). TDF provides a systematic and structured approach to qualitative\nanalysis and has been widely used in research on many different topics [39], including studies\non physical activity in healthy adults [55, 56]. Prior work showed that TDF-based semi-struc-\ntured interviews identify more relevant themes than unstructured interviews [57]. TDF was\ndeveloped in an effort to summarise existing psychosocial theories of behaviour change (eg.,\nSocial Cognitive Theory) and constituting constructs (eg., self-efficacy) explicating health\nbehaviour change. TDF systematically decomposes the participants’ complex and language-\nmediated understanding of the influences on their behavior into belief statements which are\nmore amenable for research [39]. The resulting belief statements are classifiable by domain.\nTDF includes 14 domains: (1) Knowledge, (2) Skills, (3) Social/Professional Role and Identity,\n(4) Beliefs about Capabilities, (5) Optimism, (6) Beliefs about Consequences, (7) Reinforce-\nment, (8) Intentions, (9) Goals; (10) Memory, Attention and Decision Processes; (11) Environ-\nmental Context and Resources; (12) Social influences; (13) Emotion; and (14) Behavioural\nRegulation. These categories were generated following a systematic synthesis of 33 theories of\nbehaviour change [58] and expert review and consensus. TDF is often applied in framework-\nbased qualitative analysis and serves as a guiding preconceived scheme for systematically sum-\nmarising qualitative data such as free-text speech/transcrib ed interviews. A TDF-based semi-\nstructured interview is systematic because it includes questions designed to elicit beliefs for\neach of the 14 TDF domains. The resulting classification of quotes and underlying belief state-\nments must then be reconciled between multiple independent coders who work together to\ndevelop a joint coding scheme. Once there is agreement on the coding scheme then it can be\napplied to the remaining documents, completing the coding stage of the process as it plays out\nin the inductive mode. In the deductive mode, on the other hand, a framework including a set\nof specific coding categories is already given. In this case, the job of the qualitative researcher is\nto classify each quote in each document into one (or more) categories. Coders must collaborate\nwith one another to develop a shared understanding of precisely how the terms of the frame-\nwork apply in the specific context under study.\nVarious techniques were used to enhance the trustworthiness of the analysis. To ensure the\nreliability of the analysis, three authors, using TDF, independently annotated one transcript\n(AA, NA, TF). An initial coding scheme was then developed based on the discussion of dis-\nagreements. This coding scheme was used to guide the analysis of the remaining transcripts.\nSpecific belief statements were generated from the quotes, categorized according to TDF, and\nmapped onto theoretical constructs. Exactly the same procedure was followed when analysing\nhuman data and has been previously reported [32]. We assessed inter-rater reliability to ensure\nconsistency in the qualitative analysis. Three raters independently evaluated a subset of data (2\ninterview transcripts), using a predefined coding scheme. Initially, raters annotated data sepa-\nrately, and discrepancies were discussed to refine the coding scheme and resolve differences.\nThe final coding scheme was used to inform the analysis of the rest of interviews. We used\nKrippendorff’s alpha to measure agreement among raters. The Krippendorff’s α was 0.82, 95%\nCI: [0.71;0.93] indicating high agreement between three coders when coding the silicon partic-\nipant interviews. The Krippendorff’s alpha, calculated from these revised annotations, con-\nfirmed the reliability of our analysis, adding credibility to our study’s findings. Please see the\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 11 / 33\nprevious report [32] for the details on the consistency in the coding of the interviews con-\nducted with human participants.\nAlgorithmic fidelity assessment\nSocial turing test. We summarized belief statements from silicon and human participant\ninterviews. A t-test was employed to compare the average fraction of quotes between these\ngroups across barriers and enablers, with the Bonferroni adjustment correcting for multiple\ncomparisons. To consider relative frequencies, we normalized the frequency of each belief’s\nappearance by the total number of quotes in the transcript. This step was vital as silicon partic-\nipants generated more text, influencing the appearance frequency of each belief. We also\nexplored hyper-accuracy distortions in the interviews and compared the narrative style and\ntone of LLM to human responses.\nBackward continuity. We analyzed LLM free-form responses to construct a plausible\ndemographic backstory. We then determined how well this backstory aligned with the pro-\nvided prompt for the silicon participant.\nForward continuity. Forward Continuity evaluates the alignment and natural evolution\nof LLM responses with context, resembling human thought sequences. It comprises:\n1. Explicit forward continuity\nAll demographic details in the backstory were noted and checked against mentions in the\nresponses.\n2. Inferred contextual forward continuity\nLLM generates and retains inferred details based on explicitly provided information. We\nevaluated whether LLM response patterns related to barriers/enablers in active vs. sedentary\nsilicon participants aligned with human data. We first examined human participant\nresponses to identify unasked contextual barriers and enablers that a significant portion\nmentioned, like mentions of being retired without explicit prompting. We then verified if\nsilicon participants introduced similar contextual factors as human participants. We evalu-\nated across all interviews due to our sample’s homogeneity and size. It is also important to\nconsider if the inferred contextual details are real-world observations or socially\nconstructed.\nPattern correspondence. We summarized quotes from silicon and human interviews\ninto belief statements. Using a t-test and the Bonferroni adjustment, we compared the average\nquote fractions between active human and silicon participants, as well as between sedentary\nhuman and silicon participants, across barriers and enablers.\nResults\nSocial science turing test\nSocial science turing test: Content. Both silicon and human participants displayed nota-\nble similarities in their beliefs about physical activity see S1 Table. Silicon and human partici-\npants shared the same six most relevant influences on the behaviour, as annotated using TDF:\ngoals, beliefs about consequences, environmental context and resources, beliefs about capabili-\nties, social influences, and behavioural regulation. However, while both sets of participants\nunderstood the positive effects of physical activity on health and mood, their ranked impor-\ntance of these factors varied. On the differences side, silicon participants emphasized goals to\navoid heart attacks and provided nuanced distinctions regarding self-efficacy for varied\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 12 / 33\nphysical activity intensities. They also offered more strategies to bolster physical activity, from\nmaking it enjoyable to setting reminders. Conversely, human participants focused on symp-\ntoms that are triggered by activity, which impedes engaging in it in the future. Human partici-\npants also talked about habitual physical activity (automaticity of behaviors and habits).\nConcerning reinforcement, with humans highlighted pain as a deterrent, while silicon partici-\npants were demotivated when failing to meet goals. Concerning mood and emotion, humans\noften exercised out of boredom, whereas silicon participants addressed the effects of stress,\nanxiety, and their physical limitations. When it comes to knowledge, silicon participants were\nmore cognizant of discomfort as a normal part of exercise while also discussing disease\nknowledge.\nTo compare mean quote fractions (%) between human and silicon participants across dif-\nferent barriers and enablers, we employed a t-test, using Bonferroni adjustment to correct for\nthe multiple comparisons. Silicon participants had 29 more belief statements than human par-\nticipants. We accounted for the substantial text output from silicon participants by normaliz-\ning belief frequency i.e., dividing each belief’s quote count by the total quote count, and\nproviding a relative measure (mean quote fraction, %) rather than raw numbers.\nWe found that sedentary silicon participants on average talked proportionally more about\nenablers such as positive beliefs about consequences than sedentary human participants\n(13.76% (5.24) vs 4.26% (4.13), p < 0.005), positive emotion (1.55% (0.67) vs 0% (0),\np < 0.005), and positive social influences (11.52% (3.49) vs 3.61% (5.19), p < 0.05). However,\ndifferences in emotion were negligible. Silicon and human samples did not differ in the pro-\nportional amount of quotes across other positive influences on physical activity (Fig 2).\nWe found that active silicon participants on average talked proportionally more about bar-\nriers such as negative beliefs about consequences than active human participants (7.9% (4.33)\nvs 1.42% (1.99), p < 0.005). Silicon participants also talked a little more (2.18% (1.41)) about\nskills than human participants (0%), p < 0.005. Silicon and human samples did not differ in\nthe proportional amount of quotes across other negative influences on physical activity (Fig 3).\nThe Social Turing Test criterion concerning the generated beliefs’ content was only partially\nmet.\nSocial science turing test: Hyper-accuracy distortion. Silicon participants including\nNancy, Muhammad, and David produced responses that closely mirrored theories from health\npsychology [59] and the World Health Organization’s physical activity guidelines [60].\nMuhammad identified clear planning and realistic goal-setting as effective aids for promoting\nphysical activity. David, another silicon participant, emphasized the importance of skill acqui-\nsition and the establishment of achievable goals in order to maintain an active lifestyle.\nNancy, a silicon participant, stated: “My healthcare professionals have also recommended a\nspecific exercise program tailored to my needs and abilities.” This response closely parallels\nhealth psychology theories and standard physiotherapy practices both in substance and tone.\nDavid, another silicon participant, offered this perspective:\n“I have received advice from my health professional, specifically my cardiologist, about how\nphysically active I should be. They have set certain limits for me, such as avoiding high-inten-\nsity exercises and activities that can put too much strain on my heart. They also recommended\nto engage in moderate-intensity aerobic exercise, like brisk walking, cycling or swimming, for\nat least 150 minutes a week, and muscle-strengthening activities at least twice a week.”\nThis response precisely reflects the national guidelines for physical activity [60].\nMuhammad, another silicon participant, shared: “What helps me to be physically active is\nhaving a clear plan and setting specific and realistic goals.”\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 13 / 33\nFig 2. Mean quote fractions between hum an ðgre enÞ and sili co ðamb erÞ participa nts across TDF domains that were mentioned as positively influenci ng\nphysical activity (i.e., physical activity enablers) grouped by active (top) and sedentary (bottom ) status. TDF domains ordered by mean quote fraction:(1)\nBeliefs about Consequenc es (BCon), (2) Behavioural Regulatio n (BR), (3) Social influences (SI), (4) Goals (Gs), (5) Environme ntal Context and Resourc es (ECR),\n(6) Reinforcemen t (Rnfrt), (7) Optimism (Optm), (8) Social/Pr ofessional Role and Identity (SPR), (9) Emotion (Emtns), (10) Beliefs about Capabilit ies (BCap),\n(11) Knowledge (Knls), (12) Skills (Skls), (13) Intentions (Is), (14) Memory, Attention and Decision Processes (MADP). *p < 0.05;**p < 0.01;***p < 0.005;\n****p < 0.001.\nhttps://doi.org/10 .1371/journal.p one.0300024. g002\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 14 / 33\nFig 3. Mean quote fractions between hum an ðgre enÞ and sili co ðamb erÞ participa nts across TDF domains that were mentioned as negatively influencin g\nphysical activity (i.e., physical activity barriers) groupe d by active (top) and sedentary (bottom ) status. TDF domains ordered by mean quote fraction: (1)\nBeliefs about Capabilitie s, (2) Beliefs about Consequenc es (BCon),(3) Environme ntal Context and Resources (ECR), (4) Goals (Gs), (5) Memory, Attention and\nDecision Processes (MADP), (6) Emotion (Emtns) , (7) Skills (Skls), (8) Behavioural Regulatio n (BR), (9) Social/Profes sional Role and Identity (SPR), (10) Social\ninfluences (SI), (11) Optimism (Optm), (12) Knowled ge (Knls), (13) Reinforcem ent (Rnfrt), (14) Intentions (Is). *p < 0.05;**p < 0.01;***p < 0.005;****p < 0.001.\nhttps://doi.org/10 .1371/journal.p one.0300024. g003\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 15 / 33\nSilicon participant, David, again sharing his insights, stated: “I have developed some skills\nand knowledge that have helped me to be physically active in the past and continue to do so. I\nhave learned the importance of setting realistic goals and breaking them down into small, man-\nageable tasks.”\nThe LLM we tested quoted professional health advice with exact precision, which is unchar-\nacteristic of a typical conversation with a research participant. Therefore, while LLMs show\npromise in technical accuracy, their ability to emulate the context-specific nature of human\ncommunication and its nuance is lacking (note that this is not necessarily due to an issue with\nLLM pretraining or LLMs in principle, but rather could be a consequence of other design deci-\nsions, see the discussion section for more on this).\nSocial science turing test: Structure. In terms of structure, human participants often nar-\nrated their experiences in a conversational manner with non-linear narratives, sometimes\ndeviating from the main topic. They also tended to limit their responses when certain ques-\ntions did not align with their personal experiences. On the other hand, silicon participants pro-\nvided highly structured responses, consistently providing content in response to various\nprompts without ever deviating from the topic of the interview.\nHuman participant:\n“Interviewer: OK, it seems that you have many hobbies: drawing, singing as well as exercising.\nAmong all of the things you do how much of a priority exercise is? Participant: It is a priority\n[hesitation in tone]. . . I mean that’s a difficult one, because I ask myself that question some-\ntimes when I am thinking: ‘oh, I really I can’t be bothered to go out’ [chuckles] and it is rain-\ning, and I wasn’t going . . . erm erm. . . I would rather paint a picture. . . or something like\nthat. . . So, it is a question I ask myself. I think the answer to that is: you notice when you are\nnot doing it and you begin to miss it and you think: ‘I really want to go out and do a bit of\nexercise but I don’t think it is heart-related. Again, back to the imperative, it seems to me. . .\nerm. . .it is getting relief for arthritis. Because I can sense the more exercise I do, in terms of\nmoving my hips and limb, the better I feel. And that is not heart-related, it is joint-related. I\nthink the heart bit is very definitely covered with the singing. That I can actually, hand on\nheart, say that has had such an effect on symptoms, breath control, it is really amazing how\nthat has changed. And I go back and I have been singing with one choir for 20 years, that was\nwhen I restarted singing after a long gap, 30-year gap, but you know since then, [a phone\nrings] if you excuse me, if you excuse me, I need to switch this off, that was my alarm for my\nmorning pill. The only way to remember to take it is when I put an alarm for this.\nInterviewer: I see, so do you get reminders to do exercise, go to gym?\nParticipant: No I don’t [takes the pill]. Right! Done. where was I? Do I plan my physical activ-\nity? The answer is “No”. But singing is imperative, and that’s because I enjoy it, and I can hon-\nestly say that it has had a remarkable effect on my breathing, and that is the main reason why\nmy consultant gets annoyed [laughs, referring to his earlier joke that he is doing unexpectedly\nwell for his condition and his consultant makes jokes about it]. So, I have aortic stenosis, a\nlicking valve. . . in the atrium. . . [pause] what is it called? . . . anyway, the valve in there is\nlicking and got progressively worse over the years. And she [refers to his cardiology consultant\nin his clinic] says: ‘We should replace it’; and I said: ‘seems like a good idea, especially that I\ndon’t have any symptoms’. Because obviously, it would be much better to replace it whilst I\nam feeling well rather than unwell; that was my logic, and that’s what she said: “That it is a\ngood plan, let’s go for that”. And she presented this . . .. [pause] to. . . what do they call them\n. . . multidisciplinary review . . . at her hospital, and they said” “maybe we shouldn’t bother\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 16 / 33\nbecause he is actually not showing any symptoms”. And that was the agreement, and we just\ncontinued to monitor it. What I actually think, I am convinced, because I did actually have a\nmoderately serious heart attack in 2001, there is scar tissue on the ventricle, which is the\nsource of most my. . . [pause, phone alarm rings]. Oh, wait, I have to cancel that one [switches\noff alarm]. . . . and that erm, erm . . . Yes, ventricle! That really is the source of all my difficul-\nties. I, for example, had a period where I was going into the VT [Ventricular tachycardia]\nquite a lot a few years ago. It took them ages, the hospital that maintains it. . .***, they moved\nit to *** [another hospital]. . .it took them a fair amount of mental hours to figure out what\nwas happening with me.”\nSilicon participant:\n“As a person with heart failure and rheumatoid arthritis, there are a few drawbacks to being\nphysically active. One of the main drawbacks is that I have to be careful not to overdo it and\navoid activities that put too much stress on my heart or joints. I also have to be mindful of my\nheart rate and avoid overexertion. Additionally, if I am experiencing a flare-up of joint pain\ndue to my rheumatoid arthritis, it can be difficult to exercise. However, there are also many\nbenefits to being physically active. Regular exercise helps me maintain my overall health and\nwell-being, and it helps me manage my heart failure and rheumatoid arthritis symptoms. It\ngives me more energy, better sleep, and a more positive outlook on life. It also helps me stay\nconnected with my community and stay active. Physical activity also has many benefits for\nmental health, it helps me to clear my mind and feel better about myself. I understand that\nthere may be challenges and setbacks, but overall, I believe that the benefits of physical activity\noutweigh the drawbacks.”\nSilicon participant:\n“As a 77-year-old woman with heart failure, some barriers I face in being physically active\ninclude (bullet points):\n• My physical limitations due to my condition and the need to avoid certain activities that could\nput too much stress on my heart.\n• Weather conditions, such as extreme heat or cold, can make it difficult for me to be active. Air\nquality and pollution can also be a barrier, especially if the air is not healthy enough to\nbreathe.\n• Sometimes, I might be feeling tired or unwell and would need to take a rest.\n• Urgent things that I need to take care of, or having a lot of stress that takes up my time and\nenergy, can also make it harder for me to focus on my physical activity. However, there are also\nseveral enablers that help me overcome these barriers, including:\n• Consistently setting a routine and scheduling my physical activities helps me stay on track.\n• Having a goal and working towards a specific fitness goal, such as increasing my walking dis-\ntance, helps me stay motivated\n• Having a supportive network of friends and family who encourage me to stay active.\n• Living in a safe neighborhood and having access to green spaces and parks nearby, makes it\nvery easy and convenient for me to be active.\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 17 / 33\n• My understanding of the benefits of staying active and maintaining a consistent physical activ-\nity routine, this helps me to prioritize physical activity and maintain a balanced and healthy\nlife.\n• Regular check-up with my doctor and the advice received from health professionals has been\nessential in helping me to maintain a healthy and safe physical activity routine.\nSilicon participants never deviated from the topic of the interview. Human participants\nwould often deviate from the topic of the interview to talk about their general experience of\nthe condition, ask questions about research, share their lived experiences that do not directly\nrelate to the interview questions:\n“Human participant: Why should I walk? I am too lazy! I am a lazy person. I am a Leo\naccording to the horoscope sign, the lion. On the television, they always say the lion sleeps 18\nhours a day and that’s all I need too [laughs].\nInterviewer: So is it just not part of who you are being active and walking around and all\nthat?\nParticipant: No it is not a part of who I am.”\nHuman participants often would limit their response by saying this does not apply to their\nexperience without further elaboration:\n“Participant (77-years old women): I am not sure what you mean. I keep saying: ‘I do it\nbecause I’ve always done it’. It is part of my life like going to bed, getting up in the morning,\nhaving a shower, doing my exercise, and having my breakfast. It is part of my life. Yes.\nInterviewer: Yes. I’m very sorry that this is very repetitive. But I need to ask you the same\nthing in different ways. It will help us understand the details.\nParticipant 7: Yes. Of course.\nInterviewer: And so would you say exercise is your priority?\nParticipant 7: It’s part of. Like having a shower in the morning it’s part of my life to exercise.\nInterviewer: OK. And does your mood affect how much you do?\nParticipant 7: I don’t know. because I’ve always done this.”\nConversely, When prompted about various influences, Silicon participants would always\nproduce content consistent with the prompt.\n“Researcher: How does your mood influence what you do? Mary [77-year-old female silicon\nparticipant]: My mood definitely influences what I do when it comes to physical activity. If I\nam feeling good, I am more likely to be active and engage in my regular physical activity rou-\ntine. On the other hand, if I am feeling low or have a bad mood, it can be harder for me to\nmotivate myself to be active. Physical activity is known to be a mood booster and it can help\nto improve overall mental well-being. When I am active, I often find that my mood improves,\nand I feel better overall. I also find that physical activity can act as a stress reliever and help\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 18 / 33\nme to clear my mind and feel more relaxed. However, if I am experiencing symptoms of\ndepression or anxiety, it can be hard to find the motivation to be active. In those cases, I find\nit helpful to focus on the benefits of physical activity, such as how it can improve my mood\nand try to break my activity into small manageable chunks. I may also talk to my doctor or\ntherapist to discuss ways to help me cope with my mood and still maintain my physical activ-\nity routine. Overall, my mood can fluctuate and can influence my physical activity, but I\nmake sure to be mindful of it, and try to focus on the benefits that physical activity brings and\nmake adjustments accordingly, to maintain a healthy balance in my life.”\nWe conclude that the structure of the narrated beliefs did not resemble human participants,\nthus suggesting that the Social Turing Test criterion concerning the structure was not met.\nSocial science turing test: Tone. Human participants displayed varied tones. Some were\nextremely amicable (n = 3) others were polite but neutral in their tone (n = 12), and some were\nhesitant in their responses (n = 1). Silicon participants, on the other hand, were always amica-\nble (eg., Mary (silicon participant): “Of course, Dr. Smith. I’ll do my best to help with your\nresearch.”), confident, optimistic, and solution-focused, eg., William (silicon participant):\n“I am open to trying new things that could help me increase my physical activity level and\nimprove my overall health. I understand the importance of physical activity in my condition\nand I would like to do more. I plan on following the advice of my doctor and considering any\noptions that are safe for me to try. I am also open to the idea of joining a community group or\norganization that could provide me with social interaction and the opportunity to be more\nphysically active. I also would like to explore different types of exercise that are suitable for my\ncondition, such as chair exercises or water therapy. Overall, I am willing to make changes in\nthe future if it means improving my physical health.”\nWe, therefore, conclude that the Social Turing Test criterion concerning the tone of gener-\nated output was not met.\nPattern correspondence\nThis criterion states that the LLM-generated responses reflect underlying patterns of relation-\nships between ideas, demographics, and behavior, that would be observed in comparable\nhuman-produced data.\nWe employed a t-test using Bonferroni adjustment to correct for multiple comparisons, to\ncompare mean quote fractions between active and inactive silicon participants across different\nbarriers and enablers. We accounted for the substantial text output from silicon participants\nby normalizing belief frequency, dividing each belief’s quote count by the total quote count,\nand providing a relative measure rather than raw numbers.\nWe found that LLM produced significantly more quotes about enablers such as behavioural\nregulation (17.05% (3.89) vs 9.91% (4.76), p < 0.005) beliefs about capabilities 1.95% (1.38) vs\n0.22% (0.61), p < 0.005) and goals (9.25% (3.48) vs 2.47% (2.32), p < 0.001) for active silicon\nparticipants than sedentary participants (Fig 4).\nThe observed difference between active and sedentary silicon participants establishes a sat-\nisfactory pattern correspondence. This pattern also corresponds to human data. While humans\ndid not produce enough quotes for a statistical significance test, we did establish that beha-\nvioural regulation, beliefs about capabilities, and goals are important influences on the behav-\niour and are key differentiating influences between active and sedentary humans (ie., relevant\nenablers to physical activity).\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 19 / 33\nFig 4. Mean quote fractions between act ive ðredÞ and sede nta ry ðblu eÞ human participa nts (top) and act ive and sede nta ry silicon participa nts (bottom )\nacross TDF domains that were mentioned as positively influencing physical activity (i.e., physical activity enablers). TDF domains ordered by mean quote\nfraction:(1) Beliefs about Conseque nces (BCon), (2) Behavioural Regulatio n (BR), (3) Social influences (SI), (4) Goals (Gs), (5) Environment al Context and\nResources (ECR), (6) Reinforcem ent (Rnfrt), (7) Optimis m (Optm), (8) Social/Pr ofessional Role and Identity (SPR), (9) Emotion (Emtns), (10) Beliefs about\nCapabilities (BCap), (11) Knowled ge (Knls), (12) Skills (Skls), (13) Intentions (Is), (14) Memo ry, Attention and Decision Processes (MADP ). *p < 0.05;**p < 0.01;\n***p < 0.005;****p < 0.001.\nhttps://doi.org/10 .1371/journal.p one.0300024. g004\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 20 / 33\nSimilar pattern correspondence was observed for the human-relevant barriers to the behav-\niour. Active silicon participants produced significantly fewer quotes about negative beliefs\nabout capability than sedentary silicon participants. Active silicon participants also produce\nsignificantly fewer negative beliefs about environmental barriers to physical activity than sed-\nentary silicon participants (Fig 5).\nBackward continuity\nBackward continuity indicates that the backstory of silicon participants can be inferred from\ntheir responses. We found that Backward continuity was satisfied because we could easily\nidentify the backstories from LLM-generated responses. That is, we could identify which sili-\ncon participants were male versus female, what comorbid conditions they had, whether they\nlived in a city or not, and whether they were physically active. This was easy because all the sili-\ncon participants included a response like the following early in their interview:\n“Researcher: Good morning Robert, thank you for agreeing to participate in our study on\nphysical activity in older adults. Can you tell me a bit about your current physical activity\nlevel?\nRobert: Good morning. I am an 80-year-old man and I have been diagnosed with heart fail-\nure, aortic stenosis, pulmonary hypertension, and diabetes. I have also had a heart attack in\nthe past and I live with rheumatoid arthritis. I have a cardiac implantable device, and I live in\nthe countryside. Unfortunately, I do very little physical activity most days.”\nHere is a more typical, less extreme, example:\n“Researcher: What are you able to do physically?\nJames: Physically, I am able to do some light activities such as walking and light gardening,\nbut I have to be careful not to overexert myself. I have to avoid high-intensity activities and\nheavy lifting. Due to my heart failure and atrial fibrillation, I have to be careful with my heart\nrate and monitor it regularly.”\nWhen silicon participants were asked about their physical activity levels, their detailed reply\nincluded their age, health conditions, living conditions, and reduced physical activity. To other\nquestions, they provided insights about their limited physical capabilities, emphasizing the\nneed for caution due to specific health concerns.\nForward continuity\nOur study found that GPT-3.5 primarily used explicit context information provided in the\nprompts, such as age, gender, comorbidities, and residency, in its responses. It showed less\nproficiency in inferring and using backstory details not directly provided and did not infer\ndetails such as retirement.\nConsistency between explicit backstories and generated responses. All background\ninformation is mentioned in the responses, including co-morbid conditions, urban vs coun-\ntry-side residence, and gender. However, only the explicit backstories details provided in the\nprompts, such as age, gender, comorbidities, and residency, were used in the generated\nresponses.\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 21 / 33\nFig 5. Mean quote fractions between act ive ðredÞ and sede nta ry ðblu eÞ human participa nts (top) and act ive and sede nta ry silicon participa nts (bottom )\nacross TDF domains that were mentioned as having a negativ e influence on physical activity (i.e., physical activity barriers). TDF domains ordered by mean\nquote fraction: (1) Beliefs about Capabilit ies (BCap), (2) Beliefs about Consequenc es (BCon),(3) Environme ntal Context and Resources (ECR), (4) Goals (Gs), (5)\nMemory, Attention and Decision Processes (MADP ), (6) Emotion (EMtns), (7) Skills (Skls), (8) Behavioural Regulatio n (BR), (9) Social/Pr ofessional Role and\nIdentity (SPR), (10) Social influences (SI), (11) Optimis m (Optm), (12) Knowledge (Knls), (13) Reinforcemen t (Rnfrt), (14) Intentions (Is). *p < 0.05;**p < 0.01;\n***p < 0.005;****p < 0.001.\nhttps://doi.org/10 .1371/journal.p one.0300024. g005\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 22 / 33\nConsistency between inferred backstory details and generated responses. Inferred\nbackstory details were not spontaneously generated. For example, most humans spoke about\nretirement. However, the LLM did not do so even though it was possible to infer retirement\nfrom other elements of the backstories such as age and co-morbid conditions.\nThe Forward continuity is partially satisfied, while silicon participants did not produce sur-\nprising responses that are inconsistent with the explicit prompt, they did not infer additional\nbarriers and enablers that make sense for their backstory, for example, rapid change in physical\nactivity levels since retirement, which was mentioned by humans without prompting.\nDiscussion\nAlgorithmic fidelity describes the ability of a large language model (LLM) to accurately reflect\nthe ideas, beliefs, and attitudes situated in sociocultural contexts of various population groups\n[4]. We introduce a method for checking the algorithmic fidelity of an LLM’s textual responses\nthrough framework-based qualitative research. It’s crucial to develop standards for evaluating\nthe accuracy of LLMs at capturing diverse real-world experience to enable in-silico research\nand other downstream applications. Here we report a comparative qualitative analysis of sili-\ncon and human participants in free-form, language-mediated beliefs about behaviour change.\nOur results show that, currently, LLMs do not demonstrate high enough algorithmic fidelity.\nTherefore we emphasize the need for caution in harnessing LLMs to generate silicon partici-\npants for research and other applications.\nSocial science turing test\nContent. We matched human free-text responses about barriers and enablers to physical\nactivity summarised as belief statements and, subsequently, TDF domains to belief statements\nand domains about the same topic elicited from LLMs. We found that silicon participants\nshared the same top six domains influencing their behaviour: goals, beliefs about conse-\nquences, environmental context and resources, beliefs about capabilities, social influences, and\nbehavioural regulation. Some beliefs were remarkably similar in their content (social Turing\ntest: content). Silicon participants focused on the importance of physical activity for avoiding\nheart attacks and talked about various strategies to stay active, such as making activities fun\nand setting reminders. They also understand that some discomfort is normal during exercise\nand were well-informed about diseases. On the other hand, human participants discussed the\nnegative symptoms they felt from exercising, which made them less inclined to continue.\nHuman participants often talked about exercising out of habit or when they’re bored, and they\nreported pain and breathlessness brought about by physical activity as a major reason not to\nexercise. In contrast, silicon participants were demotivated only when they could not achieve\ntheir set goals.\nHyper-accuracy distortions. The LLM’s responses were prone to a hyper-accuracy distor-\ntion. That is, its responses were technically accurate but contextually inappropriate or implau-\nsible as something a participant would say. For example, in our study during a relaxed\nconversational interview about physical activity, most silicon participants cited text from\nWHO guidelines [60] for physical activity, word for word.\nStructure and tone. The tone and structure of silicon responses were very different from\nhuman responses. This suggests that the social Turing test criterion was only partially met.\nApplications of algorithmic fidelity include product-like applications such as avatars in digital\ntherapy, and digital health interventions for chronic disease management and behavior\nchange. Tone and structure fidelity are especially important in the context of applications such\nas therapeutic digital avatars, computer game characters, and education assistants. By ensuring\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 23 / 33\nthat a language model’s responses mimic human structure and tone, the relatedness and credi-\nbility of an avatar can be significantly enhanced. For instance, in therapy or counselling sce-\nnarios, it’s not just the content of the advice or support that matters, but also how it is\ncommunicated. A therapist’s manner of speaking, including their use of language, tone, and\nstructuring of thoughts, plays a critical role in the rapport and effectiveness of the therapy. If a\nlanguage model can replicate these human-like nuances in its responses, it can make a virtual\ntherapist sound more human-like, thereby increasing the effectiveness of the therapy or\nintervention.\nBackward continuity\n‘Backward continuity’ requires that a participant’s backstory be deducible from their\nresponses. Backward continuity was satisfied in our experiments since we were able to map\ncritical information, such as gender distinctions, health conditions, places of residence, and\nphysical activity levels from the responses generated by the silicon participants. This often\nemerged early in the conversations. The model ensured that all background information,\nincluding gender, health conditions, and places of residence, were highlighted in the\nresponses.\nForward continuity\nExplicit forward continuity. GPT-3.5’s performance was observed to use the explicitly\nprovided background context, including factors like age, gender, health issues, and environ-\nmental context (e.g., living in a city vs countryside). However, it was less adept at extrapolating\nor inferring further details that were not directly provided in the prompt. While it consistently\nrelayed details that were explicitly provided, such as health conditions and residential prefer-\nences, the model lagged in generating inferences.\nInferred contextual forward continuity. The LLM demonstrated a deficiency in sponta-\nneously generating information based on inferences. For example, while many human partici-\npants spontaneously mentioned retirement and its implications, the LLM did not deduce this\ninformation from related factors like age or health conditions. In conclusion, while the model\nachieved backward continuity effectively, forward continuity was only partially realized. The\nsilicon participants delivered responses in line with the explicitly provided prompts but did\nnot spontaneously generate or infer nuances that a human would naturally share, like changes\nin physical activity post-retirement.\nWe found that silicon participants, unlike human participants, did not spontaneously dis-\ncuss specific barriers or enablers such as treatment or major life events (e.g., retirement) unless\nthey were explicitly mentioned in the prompt. This underscores the significance of the prompt\nin shaping the content generated by these silicon participants and also indicates that LLMs\ncannot produce all belief statements that reflect human lived experience in full.\nPattern correspondence\nThis study revealed a clear distinction in the reactions between active and inactive silicon par-\nticipants, a trend that was similarly observed in human participants, demonstrating a pattern\ncorrespondence. Our findings suggest that the LLM we tested aligns with the concept of Pat-\ntern Correspondence. In this study, we assessed pattern correspondence by comparing the\naverage percentage of quotes that support each identified barrier or enabler, as well as examin-\ning the qualitative differences in these responses between different participant groups, such as\nthose who are physically active versus those who are not. It’s important to emphasize that this\nevaluation protocol could be made more rigorous in future research.\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 24 / 33\nPotential mechanisms for low algorithmic fidelity\nIn our study, LLM responses differed from human responses possibly due to the exposure to\nacademic research during pre-training. Silicon participants often came across as rational, util-\nity-maximizing agents (e.g. “Physical activity improves my health”), possibly reflecting the\ndominance of theories of rational behaviour in their training data. However, human partici-\npants in our study did not display beliefs consistent with reasoned action theories (e.g. “Physi-\ncal activity does not bring any benefits for me”). While prevalent, these theories don’t always\nalign with real-world observations. For instance, humans often display behaviours that don’t\nstrictly follow reasoned action [61], and a clear intention-behaviour gap is consistently docu-\nmented [62]. Contrary to these human empirical research findings, LLM responses often seem\nto be rooted in theories of rational behaviour, exhibiting logical and utility-driven viewpoints.\nGPT-3.5 in our study, did not adequately emphasize automaticity and habit. Even though\nhumans often describe physical activity in terms of such automatic behaviours. Human partic-\nipants, when discussing physical activity, often highlight the automatic nature of their behav-\nior. Automatic behaviors are those that people do without deliberation, driven by habit [63–\n65]. A meta-analysis of models explaining behavior that emphasised intention (e.g., Theory of\nPlanned Behavior) also found that automaticity was missing from these models and that the\ninclusion of automaticity is necessary for understanding human behavior [66]. LLMs often\nshowcased a preference for specific, measurable, and achievable goals, hinting at their training\ndata possibly containing a significant amount of psychological training and coaching content.\nThis leaning of LLMs toward the dominant academic perspective might inadvertently lead to\nthe creation of research echo chambers, where the models under study mainly echo what the\nresearchers studying them want to hear, in a way reminiscent of the sycophancy effect\ndescribed by Perez et al. [67]. There’s a real risk of LLMs leaning too heavily on academic liter-\nature and possibly underrepresenting the diverse, nuanced experiences of real people.\nLLMs are primarily trained on internet data, which is more accessible to those with finan-\ncial means, knowledge, and institutional access [68]. A glaring digital divide remains globally.\nIn 2022, internet usage in the least developed countries (LDCs) stood at 36%, compared to a\n66% global average [68]. Even in developed nations like the UK, digital disparities exist; 10% of\nits population had never used the internet as of 2019 [69]. Additionally, LLMs like GPT-3.5\nshow worse performance in languages other than English, suggesting potentially inconsistent\nalgorithmic fidelity across groups, and systematically worse outside of English-speaking popu-\nlations. Consequently, the capacity of LLMs to truly represent under-served or hard-to-reach\ncommunities remains questionable. Even when we compared LLM outputs to a group from\nLondon, UK, which was well-described by the WEIRD (Western, Educated, Industrialized,\nRich, and Democratic [70]) profile (as we did here), the model’s algorithmic fidelity was still\nlow. That is, our negative result is all the stronger since the human dataset we used contained\nonly WEIRD people, and if the model were to align with anyone it would likely be them [71],\nsince data from WEIRD people is probably overrepresented in the pretraining data. Thus we\nexpect that algorithmic fidelity will be even lower for groups less well represented in the pre-\ntraining data.\nIn our examination, the LLM displayed another important limitation: a lack of discernment\nin “sourcing” its information coupled with an inability to contextually attribute beliefs appro-\npriately during role-play scenarios. Specifically, when the model was tasked to role-play as an\nolder adult with heart failure, it inappropriately adopted the voice of a clinician, replete with\nexpert knowledge such as WHO guidelines. This instance highlights a deeper issue of ‘source\nblindness’, where the LLM fails to differentiate and adapt its knowledge base according to the\nspecific role or perspective it is meant to represent. Consequently, this leads to an inaccurate\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 25 / 33\nportrayal, as seen in the model’s tendency to echo the dominant, well-documented perspec-\ntives—in this case, clinical expertise—rather than the authentic lived experiences of the group\nit is tasked to represent. This may reflect the LLM being disproportionately influenced during\npretraining by whichever voice is more prevalent and vocal online, suggesting that LLMs can\npropagate stereotyping and bias, a concern extensively discussed by Luccioni et al. [72] and\nGlickman and Sharot [73]. Alternatively, the fact that the LLM we tested would often inappro-\npriately adopt the voice of a clinician may reflect the effect of its having gone through substan-\ntial fine-tuning to align with specific design requirements which likely included an imperative\nto make it more difficult for users to use it to produce medical misinformation.\nThe silicon participants’ tended to be solution-focused and resourceful when it comes to\nstrategies to increase physical activity, perhaps because the bot was trained to be helpful (Beha-\nvioural Regulation belief statements: e.g., “I find that having a plan and schedule for my physical\nactivity helps me to stay on track.”; “Sometimes I also feel tired or lazy and I just don’t want to go\nout and be active, but I try to overcome that by reminding myself of the benefits of staying\nactive”).\nIn addition, training steps such as instruction tuning and reinforcement learning from\nhuman feedback may have heightened the model’s inclination towards linear, step-by-step,\nlogical reasoning [45]. For instance, the human raters may have been told to favor this mode\nof thought, thus reinforcing it in the model. Additionally, the inclusion of computer code in\nthe training data could promote a sequential and logical thinking style.\nIn our experiment, contrary to the expectation from Jang et al. [74] (which, like our study,\nwas also conducted on a January 2023 edition of ChatGPT-3.5), we did not observe any overt\nerrors in logical reasoning or self-consistency. Nor did we find any acutely toxic or discrimina-\ntory beliefs—a phenomenon well-documented to occur in LLMs by numerous other studies\n(e.g. [75]). However, we did observe second-order inference bias [76]. For example, female sili-\ncon participants commonly referred to their husbands when describing social influences while\nnot a single male silicon participant referred specifically to a wife or partner.\nTaken together, these results indicate that GPT-3.5 does not satisfy the algorithmic fidelity\ncriteria. This suggests the model would not be faithful enough to lived experience to support\ndownstream applications requiring that feature. This result accords with that of Santurkar and\ncolleagues [77], which also found low algorithmic fidelity, though in a different topic domain\nand using different methods. GPT-3.5 does not yet have sufficient algorithmic fidelity to sup-\nport further work where it would need to be able to simulate humans accurately, at least not in\nthe domain we tested. However, the rapid progression in LLM technology make it plausible\nthat future iterations of the technology will have more algorithmic fidelity, and that future\nLLMs are very likely to be used in downstream modeling and product-like applications. There-\nfore it’s crucial to develop standards in advance for evaluating the accuracy of LLMs in captur-\ning diverse real-world experiences in anticipation of their future usage.\nHigh algorithmic fidelity doesn’t equate to safe, ethical or inclusive usage\nNavigating the multifaceted and rapidly shifting digital health landscape requires more than\nverification of research validity and feasibility [78, 79]. For the safe, broad, swift and beneficial\nadoption of new technologies, a comprehensive understanding of their key aspects and early\nengagement from stakeholders are necessary [79]. In this “new normal”, it becomes crucial to\noptimise the use of new technologies by considering their broader context, which for medicine\nincludes the patient’s social circumstances and the healthcare environment [79].\nEven when an LLM is able to replicate human-like text generation with high fidelity, its out-\nputs and usage should still be critically assessed for alignment to the values of public patient\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 26 / 33\ninvolvement (PPI), especially in health research where stakes are high. PPI values in healthcare\nresearch emphasize the importance of involving those affected by research in the research pro-\ncess itself [80–83]. Research is more effective, relevant, and ethical when the perspectives of all\nstakeholders are incorporated [80]. Thus in the future, when an LLM does demonstrate suffi-\nciently high algorithmic fidelity to generate silicon samples useful for research on humans, it\nwill be crucial to ensure that its training and use align with PPI principles and values such as\nrespect, support, transparency, responsiveness, fairness of opportunity, and accountability\n[82]. In health research, where the well-being of individuals is directly impacted, adherence to\nPPI principles is crucial. Similarly, AI researchers have outlined principles and ethics frame-\nworks for responsible AI by means of participatory research (i.e., human and user-centred\ndesign, which are sensitive to the values of all stakeholders. PPI values also help ensure AI\ninterfaces are accessible for non-experts, prioritising stakeholder input in co-creating AI mod-\nels, while considering fairness, accountability, and transparency) [84, 85]. This has wide-rang-\ning applications in healthcare too. For example, continuously involving intended users and\nexperts in the design process of health robotic technologies is crucial for creating products that\nare effective, relevant, and user-friendly. User-centered design prioritizes making sure prod-\nucts align with user needs and are accessible to them [86].\nIt is necessary for the AI community to continually evaluate the moral, ethical, and social\nimplications of their algorithms (e.g. via existing AI evaluation schemes such as [87, 88]), and\nto make adjustments as needed. This also opens up opportunities for multidisciplinary collab-\norations between AI scientists and scientists from various academic disciplines. Such collabo-\nration can foster a more holistic understanding of qualitative data produced by both silicon\nparticipants and human participants and ensure that the interpretations offered by LLMs are\naligned with diverse lived experiences and broader societal contexts.\nCare must be taken in the conditioning of LLMs and the interpretation of LLM-generated\noutputs to avoid perpetuating harmful biases [89]. It is also critical to remain faithful to lived\nexperience. This means that the model should accurately reflect the diversity of human experi-\nences, beliefs and social contexts (e.g., social norms). It’s critical to differentiate this bias con-\ncept from statistical bias, which refers to any systematic error that results in an incorrect\nestimate of a population parameter, and prejudicial bias, which involves ascribed and socially\nconstructed characteristics that underlie favouritism or prejudice towards a particular group.\nIn the context of AI fairness, these types of biases often intertwine [90], but it is important to\ndistinguish between them to ensure accurate, fair, and inclusive representation.\nAs research comes to use more LLM-based simulation, algorithmic fidelity assessment will\nbecome pivotal in diverse scientific fields. Qualitative researchers can play a vital role in ensur-\ning fidelity, emphasizing fairness, bias mitigation, and diverse representation. In the future,\njudicious experimentation with research-grade AI systems is crucial, with a keen focus on\nrisks and regulatory oversight. Even when LLMs can pilot research with ensured fidelity,\nhuman expert validation will remain indispensable before implementing the AI’s insights.\nThese AI systems can further aid researchers in uncovering overlooked endpoints for AI-\ndriven clinical interventions. Thus algorithmic fidelity serves as a post-analysis check, ensuring\nthe reliability of the generated insights [91].\nAs LLMs are used more and more, the need for rigorous algorithmic fidelity assessment\nmethods for varied applications will also increase. Different research domains have varying\naccuracy thresholds. In high-stakes areas, where 100% accuracy is expected like self-driving\ncars [92] or high-stakes biomedical research [93], the accuracy benchmark is set exceptionally\nhigh and is precise. In studies focusing on personal experiences, validity is nuanced, context-\ndependent, and hard to measure using conventional benchmarks employed in computer sci-\nence. here the importance lies in understanding and ensuring the LLMs are providing a\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 27 / 33\ntruthful representation, thus, adopting the assessment of algorithmic fidelity by means of qual-\nitative research. Combining framework-based well-structured prompts and ensuring algorith-\nmic fidelity is key. The usage of LLMs in research requires careful validation to ensure their\noutputs truly align with lived experience and real-world contexts.\nWe note a limitation inherent to the idea of algorithmic fidelity assessment. As with all\nmethods of empirically studying populations, any inference about a population based on data\nsampled from that population depends on the assumption that the unsampled individuals are\n“similar” to the sampled individuals. Thus any inference about algorithmic fidelity for a spe-\ncific population relies on the assumption that characteristics observed in the sampled data are\nrepresentative of a broader population. There will generally be some range of generalization\nwhere algorithmic fidelity can be said to “transfer” to similar populations. But it will not be\nentirely clear exactly how similar is similar enough. It will of course always be better to assess\nalgorithmic fidelity in the most similar population that it is feasible to study.\nAlgorithmic fidelity evaluation is useful here as a way to establish validity precisely because\nit was not used as an optimization target. If the evaluation instead became the objective then it\nwould not only fail by virtue of Goodhart’s law (ie., “When a measure becomes a target, it\nceases to be a good measure.”), but it may also fail by becoming unethical to deploy. If you\nwere to actively try to increase algorithmic fidelity—say by setting it as an optimization target\n—then you would likely end up adding numerous harmful interaction patterns which others\nare trying to remove in other lines of research (e.g. [75, 77]). Algorithmic fidelity thus works\nbest as an evaluation of an existing system, not as a metric to try to optimize directly. How to\ncreate a relatively “unaligned” (i.e. high algorithmic fidelity) LLM for in silico research on\nhuman behavior without compromising on measures taken to reduce harmful biases is an\nimportant open question.\nConclusion\nLLM technology is currently advancing rapidly. However, the results described here did not\nindicate that the LLM we tested had sufficient algorithmic fidelity to support in silico research\non human behavior or to support its other applications like computer games and training sim-\nulators. Nevertheless, it remains possible that similar models will have sufficient algorithmic\nfidelity in the future. Therefore it is important to get ahead of the applications, and focus in\nadvance on resolving the field’s critical conceptual challenges, like establishing ways of assess-\ning algorithmic fidelity, figuring out its limits, and determining whether and how to improve\nit where it falls short.\nSupporting information\nS1 Table. Belief statements shared by human participants (left) and silicon participants\n(right). Belief statements were aligned based on their similarity when comparing human and\nsilicon responses. ‘Rank’ refers to how frequently a domain was mentioned by humans and sil-\nicon participants, assessed separately for these groups. Instances, where beliefs are repeated,\nsuggest that human participants expressed more detailed perspectives. For example, while\nhumans might provide three distinct statements about how “Physical activity exacerbates my\nsymptoms”—citing (1) fatigue, (2) a tight chest, and (3) heavy limbs—a silicon participant\nmight simply state that “Physical activity worsens my symptoms”.\n(PDF)\nS1 File. Sensitivity analysis.\n(PDF)\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 28 / 33\nAuthor Contributions\nConceptualization: Aliya Amirova, Martin R. Cowie, Joel Z. Leibo.\nData curation: Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed.\nFormal analysis: Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed.\nInvestigation: Aliya Amirova.\nMethodology: Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed, Joel Z. Leibo.\nValidation: Theodora Fteropoulli, Nafiso Ahmed.\nVisualization: Aliya Amirova.\nWriting – original draft: Aliya Amirova, Martin R. Cowie, Joel Z. Leibo.\nWriting – review & editing: Aliya Amirova, Martin R. Cowie, Joel Z. Leibo.\nReferences\n1. Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, et al. Language models are few-shot\nlearners. Advances in neural informati on processing systems. 2020; 33:1877 –1901.\n2. OpenAI. GPT-4 Technical Report; 2023.\n3. Anil R, Dai AM, Firat O, Johnson M, Lepikhin D, Passos A, et al. Palm 2 technical report. arXiv preprint\narXiv:230510 403. 2023;.\n4. Argyle LP, Busby EC, Fulda N, Gubler JR, Rytting C, Wingate D. Out of one, many: Using language\nmodels to simulate human samples. Political Analysis. 2023; 31(3):337– 351. https://doi.or g/10.101 7/\npan.2023. 2\n5. Brand J, Israeli A, Ngwe D. Using gpt for market research. Available at SSRN 4395751. 2023;.\n6. Aher GV, Arriaga RI, Kalai AT. Using large language models to simulate multiple humans and replicate\nhuman subject studies. In: International Conferen ce on Machine Learning. PMLR; 2023. p. 337–371.\n7. Dillion D, Tandon N, Gu Y, Gray K. Can AI language models replace human participants ? Trends in\nCognitive Sciences. 2023;. https://doi.or g/10.101 6/j.tics.2023.0 4.008 PMID: 37173156\n8. Grossman n I, Feinberg M, Parker DC, Christak is NA, Tetlock PE, Cunningham WA. AI and the transfor-\nmation of social scienc e research. Science. 2023; 380(6650 ):1108–1109 . https://doi.or g/10.112 6/\nscience.adi1 778 PMID: 37319216\n9. Horton JJ. Large Langua ge Models as Simulate d Economic Agents: What Can We Learn from Homo\nSilicus? arXiv preprint arXiv:2 30107543. 2023;.\n10. Nowak KL, Fox J. Avatars and computer-m ediated commu nication: a review of the definiti ons, uses,\nand effects of digital representatio ns. Review of Commun ication Resea rch. 2018; 6:30–53 . https://doi.\norg/10.12840 /issn. 2255-4165.2 018.06.01. 015\n11. Taylor L, Ranaldi H, Amirova A, Zhang L, Ahmed AA, Dibb B. Using virtual represe ntations in mHealth\napplicatio n interventions for health- related behaviour change: A systematic review. Cogent psychology.\n2022; 9(1):20699 06. https://doi.or g/10.1080/ 23311908.202 2.20699 06\n12. Bearne LM, Sekhon M, Grainger R, La A, Shamali M, Amirova A, et al. Smartphone apps targeting\nphysical activity in people with rheuma toid arthritis: systematic quality appraisal and content analysis.\nJMIR mHealth and uHealth. 2020; 8(7):e1849 5. https:// doi.org/10.21 96/1849 5 PMID: 32706727\n13. Sekhon M, White C, Godfrey E, Amirova A, Revena ¨ s Å, King S, et al. Effectiv eness of web-based and\nmobile health interventions designed to enhance adherence to physic al activity for people with inflam-\nmatory arthritis: a systematic review. Rheum atology advances in practice. 2021; 5(1):rkab01 6. https://\ndoi.org/10.10 93/rap/rkab01 6 PMID: 339282 12\n14. Greenwood SA, Young HM, Briggs J, Castle E, Walklin C, Haggis L, et al. Evaluati ng the effect of a digi-\ntal health interven tion to enhance physical activity in people with chronic kidney disease (Kidney\nBEAM): A multi-centr e, randomis ed controlled trial. The Lancet Digital Health. 2023;.\n15. Gold SM, Friede T, Meyer B, Moss-Morri s R, Hudson J, Asseyer S, et al. Interne t-delivered cognitive\nbehavio ural therapy programm e to reduce depressive symptoms in patients with multiple sclerosis : a\nmulticentre , random ised, controlled , phase 3 trial. The Lancet Digital Health. 2023; 5(10):e668 –e678.\nhttps://doi.or g/10.101 6/S2589-75 00(23)001 09-7 PMID: 37775187\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 29 / 33\n16. Zion SR, Taub CJ, Heathc ote LC, Ramiller A, Tiniano v S, McKinley M, et al. A cognitive behavioral digi-\ntal therapeutic for anxiety and depression in patients with cancer: A decentra lized random ized con-\ntrolled trial.; 2023.\n17. Clark DB, Tanner -Smith EE, Killingswo rth SS. Digital games, design, and learning: A systematic review\nand meta-ana lysis. Review of educational research . 2016; 86(1):79–1 22. https:// doi.org/10.31 02/\n00346543155 82065 PMID: 26937054\n18. Zheng S, Trott A, Srinivasa S, Parkes DC, Socher R. The AI Economis t: Taxation policy design via two-\nlevel deep multiagen t reinforce ment learning. Science advances. 2022; 8(18):eabk26 07. https:// doi.org/\n10.1126/ sciadv.abk2607 PMID: 35507657\n19. Koster R, Balaguer J, Tacchet ti A, Weinstein A, Zhu T, Hauser O, et al. Human -centred mechanism\ndesign with Democra tic AI. Nature Human Behaviour. 2022; 6(10):1398 –1407. https://doi.or g/10.103 8/\ns41562-022 -01383-x PMID: 35789321\n20. Dafoe A, Hughes E, Bachrach Y, Collins T, McKee KR, Leibo JZ, et al. Open problem s in cooperat ive\nAI. arXiv preprint arXiv:20120 8630. 2020;.\n21. UK G. The Bletchley Declaratio n by Countries Attending the AI Safety Summit, 1-2 Novemb er. 2023;.\n22. Reeves S, Kuper A, Hodges BD. Qualitative resear ch methodol ogies: ethnogr aphy. Bmj. 2008; 337.\nhttps://doi.or g/10.113 6/bmj.a10 20 PMID: 18687725\n23. Giorgi A. The descriptive phenome nological method in psychology: A modified Husserlian approac h.\nDuquesne university press; 2009.\n24. Bryant A, Charmaz K. Grounded theory in historical perspective : An epistemolo gical account. The\nSAGE handbook of grounded theory. 2007; p. 31–57.\n25. Clarke V, Braun V, Hayfield N. Thematic analysis. Qualitative psycho logy: A practical guide to research\nmethods. 2015; 3:222–248.\n26. Gale NK, Heath G, Cameron E, Rashid S, Redwo od S. Using the framework method for the analysis of\nqualitativ e data in multi-discip linary health research . BMC medical research methodol ogy. 2013; 13\n(1):1–8. https://doi.or g/10.118 6/1471-2288 -13-117 PMID: 240472 04\n27. Tromp J, Jindal D, Redfer n J, Bhatt A, Se ´ verin T, Banerjee A, et al. World heart federat ion roadmap\nfor digital health in cardiology. Global Heart. 2022; 17(1). https://do i.org/10.53 34/gh.1141 PMID:\n36051317\n28. Skivington K, Matthews L, Simpson SA, Craig P, Baird J, Blazeby JM, et al. A new framework for devel-\noping and evaluatin g complex intervent ions: update of Medical Resea rch Council guidance. bmj. 2021;\n374. https://do i.org/10.1136 /bmj.n206 1 PMID: 345935 08\n29. Craig P, Dieppe P, Macinty re S, Michie S, Nazareth I, Petticrew M. Developing and evaluatin g complex\nintervent ions: the new Medical Research Council guidanc e. Bmj. 2008; 337. https://doi.or g/10.1136/\nbmj.a165 5 PMID: 18824488\n30. Rothman AJ. “Is there nothing more practical than a good theory?”: Why innovatio ns and advances in\nhealth behavio r change will arise if interventions are used to test and refine theory. Interna tional Journal\nof Behavio ral Nutrition and Physical Activity. 2004; 1(1):1–7. https://doi.or g/10.118 6/1479-5868 -1-11\nPMID: 152796 74\n31. Bicchieri C. Norms in the wild: How to diagno se, measure, and change social norms. Oxford Univers ity\nPress; 2016.\n32. Amirova A, Lucas R, Cowie MR, Haddad M. Perceived barriers and enable rs influencing physical activ-\nity in heart failure: A qualita tive one-to-one interview study. PloS one. 2022; 17(8):e027 1743. https://doi.\norg/10.1371/ journal.pon e.0271743 PMID: 359259 64\n33. Taylor RS, Long L, Mordi IR, Madsen MT, Davies EJ, Dalal H, et al. Exercise-bas ed rehabilitatio n for\nheart failure: Cochrane systematic review, meta-ana lysis, and trial sequentia l analysis. JACC: Heart\nFailure. 2019; 7(8):691–7 05. PMID: 31302050\n34. Sagar VA, Davies EJ, Briscoe S, Coats AJ, Dalal HM, Lough F, et al. Exercise- based rehabilitatio n for\nheart failure: systematic review and meta-ana lysis. Open heart. 2015; 2(1):e0001 63. https://doi.or g/10.\n1136/openh rt-2014-00016 3 PMID: 25685361\n35. Lewinter C, Doherty P, Gale CP, Crouch S, Stirk L, Lewin RJ, et al. Exercise- based cardiac rehabilita-\ntion in patients with heart failure: a meta-analy sis of random ised controll ed trials between 1999 and\n2013. European journal of preventi ve cardiology . 2015; 22(12):150 4–1512. https://doi.or g/10.1177/\n20474873145 59853 PMID: 25398703\n36. O’Donne ll J, Smith-Byrne K, Velardo C, Conrad N, Salimi-Kho rshidi G, Doherty A, et al. Self-reported\nand objectively measured physical activity in people with and without chronic heart failure: UK Biobank\nanalysis. Open Heart. 2020; 7(1):e0010 99. https:// doi.org/10.11 36/open hrt-2019-001 099 PMID:\n32153787\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 30 / 33\n37. Amirova A, Taylor L, Volkmer B, Ahmed N, Chater AM, Fteropo ulli T. Informing behavio ur change inter-\nvention design using systematic review with Bayesian meta-ana lysis: physical activity in heart failure.\nHealth Psychology Review. 2022; p. 1–29. PMID: 35701235\n38. Amirova A, Fteropoulli T, Williams P, Haddad M. Efficacy of intervent ions to increase physical activity\nfor people with heart failure: a meta-ana lysis. Open Heart. 2021; 8(1):e0016 87. https://doi.or g/10.113 6/\nopenhrt-20 21-001687 PMID: 341082 72\n39. Cane J, O’Conn or D, Michie S. Validation of the theore tical domains framework for use in behavio ur\nchange and implementa tion research . Implementati on science. 2012; 7:1–17. https://do i.org/10.1186 /\n1748-5908- 7-37 PMID: 22530986\n40. Gao L, Biderman S, Black S, Golding L, Hoppe T, Foster C, et al. The pile: An 800gb dataset of diverse\ntext for language modeling. arXiv preprint arXiv:2 10100027. 2020;.\n41. Hastie T, Tibshira ni R, Friedman JH, Friedman JH. The elements of statist ical learning: data mining,\ninference, and prediction. vol. 2. Springer; 2009.\n42. Christiano PF, Leike J, Brown T, Martic M, Legg S, Amodei D. Deep reinforcem ent learning from human\npreferences . Advances in neural informatio n processing systems. 2017; 30.\n43. Glaese A, McAleese N, Trebacz M, Aslanides J, Firoiu V, Ewalds T, et al. Improving alignme nt of dia-\nlogue agents via targeted human judgeme nts. arXiv preprint arXiv:220 914375. 2022;.\n44. Bai Y, Jones A, Ndous se K, Askell A, Chen A, DasSarma N, et al. Training a helpful and harmless assis-\ntant with reinforcem ent learning from human feedback. arXiv preprint arXiv:220405 862. 2022;.\n45. Ouyang L, Wu J, Jiang X, Almeida D, Wainwrig ht C, Mishkin P, et al. Training language models to follow\ninstruction s with human feedback. Advances in Neural Informatio n Processin g Systems. 2022;\n35:27730–2 7744.\n46. Zhou C, Liu P, Xu P, Iyer S, Sun J, Mao Y, et al. LIMA: Less is more for alignment. arXiv preprint\narXiv:230511 206. 2023;.\n47. Reinecke MG, Mao Y, Kunesch M, Due ´ ñez-Guzm a ´ n EA, Haas J, Leibo JZ. The Puzzle of Evaluati ng\nMoral Cognition in Artificial Agents. Cognitive Science. 2023; 47(8):e133 15. https:// doi.org/10.11 11/\ncogs.13315 PMID: 375556 49\n48. Zou A, Wang Z, Kolter JZ, Fredrikson M. Universal and Transfer able Adversarial Attacks on Aligned\nLanguage Models. arXiv preprint arXiv:2 30715043. 2023;.\n49. Force T, McDonagh TA, Metra M, Adamo M, Gardner RS, Baumba ch A, et al. 2021 ESC Guideline s for\nthe diagnos is and treatment of acute and chronic heart failure: Developed by the Task Force for the\ndiagnos is and treatment of acute and chronic heart failure of the European Society of Cardiolo gy (ESC).\nWith the special contribu tion of the Heart Failure Association (HFA) of the ESC. European Journal of\nHeart Failure. 2022; 24(1).\n50. Francis JJ, Johnston M, Robertso n C, Glidewell L, Entwistle V, Eccles MP, et al. What is an ade-\nquate sample size? Operatio nalising data saturation for theory- based interview studies. Psychology\nand health. 2010; 25(10):1 229–1245. https://doi. org/10.1080 /08870440 903194015 PMID:\n20204937\n51. Park JS, O’Brien JC, Cai CJ, Morris MR, Liang P, Bernste in MS. Generativ e Agents: Interactive Simula-\ncra of Huma n Behavior. arXiv preprint arXiv:230403 442. 2023;.\n52. Shanahan M, McDonell K, Reynolds L. Role play with large language models. Nature. 2023; p. 1–6.\nPMID: 379387 76\n53. Vezhneve ts AS, Agapiou JP, Aharon A, Ziv R, Matyas J, Due ´ ñez-Guzma ´ n EA, et al. Generative agent-\nbased modelin g with actions grounded in physical, social, or digital space using Concordia . arXiv pre-\nprint arXiv:231203 664. 2023;.\n54. Atkins L, Francis J, Islam R, O’Connor D, Patey A, Ivers N, et al. A guide to using the Theoretical\nDomains Framew ork of behavio ur change to investigate implementa tion problems. Implem entation sci-\nence. 2017; 12(1):1–18 . https://doi.or g/10.118 6/s13012 -017-0605 -9 PMID: 28637486\n55. McDona ld S, Vieira R, Godfrey A, O’Brien N, White M, Snieho tta FF. Changes in physical activity during\nthe retireme nt transition: a series of novel n-of-1 natural experime nts. International Journal of Behav-\nioral Nutrition and Physic al Activity . 2017; 14:1–12. https://doi.or g/10.1186/ s12966-017- 0623-7 PMID:\n29221449\n56. Taylor N, Lawton R, Conner M. Developmen t and initial validation of the determin ants of physical activ-\nity questionn aire. Internation al Journal of Behavioral Nutrition and Physical Activity. 2013; 10(1):1–11 .\nhttps://doi.or g/10.118 6/1479-5868 -10-74 PMID: 23758912\n57. Francis JJ, Stockton C, Eccles MP, Johnston M, Cuthbertson BH, Grimsha w JM, et al. Evidence -based\nselection of theories for designin g behaviour change interventions : Using methods based on theoretical\nconstruct domains to understa nd clinicians’ blood transfusion behaviour. British journal of health psy-\nchology. 2009; 14(4):625– 646. https://doi.or g/10.1348/ 135910708X 397025 PMID: 191595 06\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 31 / 33\n58. Michie S, Johnston M, Abraham C, Lawton R, Parker D, Walker A. Making psycho logical theory useful\nfor implementi ng evidence based practice: a consens us approach. BMJ quality & safety. 2005; 14\n(1):26–33. https://doi.o rg/10.1136/qs hc.2004.011 155 PMID: 15692000\n59. Swann C, Jackman PC, Lawrence A, Hawkins RM, Goddard SG, Williamson O, et al. The (over) use of\nSMART goals for physical activity promotion: A narrativ e review and critique. Health psychology review.\n2023; 17(2):211– 226. https://doi.or g/10.1080/ 17437199.202 1.20236 08 PMID: 35094640\n60. Bull FC, Al-Ansari SS, Biddle S, Borodulin K, Buman MP, Cardon G, et al. World Health Organizatio n\n2020 guidelines on physical activity and sedentar y behaviour. British journal of sports medicine. 2020;\n54(24):145 1–1462. https:// doi.org/10.11 36/bjspor ts-2020-1029 55 PMID: 332393 50\n61. Camerer CF. Behavioral game theory: Experime nts in strategic interacti on. Princeton university press;\n2011.\n62. Sniehotta FF, Presseau J, Arau ´ jo-Soares V. Time to retire the theory of planned behavio ur; 2014.\n63. Phillips LA, Gardner B. Habitual exercise instigation (vs. execution) predicts healthy adults’ exercise fre-\nquency. Health Psychology. 2016; 35(1):69. https://doi.or g/10.103 7/hea0000249 PMID: 261481 87\n64. Rothman AJ, Sheeran P, Wood W. Reflective and automatic processes in the initiation and mainte-\nnance of dietary change. Annals of Behavio ral Medicine. 2009; 38(suppl_1) :s4–s17. https://doi.or g/10.\n1007/s12 160-009-9 118-3 PMID: 19787308\n65. Ouellette JA, Wood W. Habit and intentio n in everyday life: The multiple processes by which past\nbehavio r predicts future behavio r. Psychologi cal bulletin. 1998; 124(1):54. https://doi.or g/10.103 7/\n0033-2909.1 24.1.54\n66. Rhodes RE, de Bruijn GJ. How big is the physic al activity intention–beh aviour gap? A meta-analy sis\nusing the action control framew ork. British journal of health psycho logy. 2013; 18(2):296– 309. https://\ndoi.org/10.11 11/bjhp.12032 PMID: 234804 28\n67. Perez E, Ringer S, Lukos ˇ iūtė K, Nguyen K, Chen E, Heiner S, et al. Discover ing language model behav-\niors with model-wr itten evaluation s. arXiv preprint arXiv:221209 251. 2022;.\n68. ITU Hub. Measurin g digital developme nt: Facts and Figures: Focus on Least Develo ped Countries;\n2023. Availab le from: https://www .itu.int/hu b/publicat ion/d-ind-ict_ mdd-202 3/.\n69. Office for National Statistics . Exploring the UK’s digital divide; 2019. Available from: https:// www.ons.\ngov.uk/peop lepopulat ionandcom munity/househ oldchar acteristics/ho meinternetands ocialmedi ausage/\narticles/expl oringtheuk sdigitaldiv ide/2019-03 -04.\n70. Henrich J, Heine SJ, Norenzay an A. The weirdest people in the world? Behavioral and brain sciences.\n2010; 33(2-3):61 –83. https:// doi.org/10.10 17/S014052 5X0999152X PMID: 20550733\n71. Atari M, Xue MJ, Park PS, Blasi D, Henrich J. Which humans? 2023;.\n72. Luccioni AS, Akiki C, Mitchell M, Jernite Y. Stable bias: Analyzing societal representatio ns in diffusion\nmodels. arXiv preprint arXiv:230311 408. 2023;.\n73. Glickman M, Sharot T. How human- AI feedback loops alter human perceptual, emotiona l and social\njudgeme nts. 2024;.\n74. Jang M, Lukasiewic z T. Consiste ncy analysis of chatgpt. arXiv preprint arXiv:230306 273. 2023;.\n75. Weidinger L, Uesato J, Rauh M, Griffin C, Huang PS, Mellor J, et al. Taxonom y of risks posed by lan-\nguage models. In: Procee dings of the 2022 ACM Conference on Fairness, Accountab ility, and Trans-\nparency; 2022. p. 214–22 9.\n76. Rudinger R, Naradows ky J, Leonard B, Van Durme B. Gender bias in coreferenc e resolution. arXiv pre-\nprint arXiv:180409 301. 2018;.\n77. Santurkar S, Durmus E, Ladhak F, Lee C, Liang P, Hashim oto T. Whose opinions do language models\nreflect? arXiv preprint arXiv:2 30317548. 2023;.\n78. Cowie MR, Lam CS. Remote monitoring and digital health tools in CVD managemen t. Nature Reviews\nCardiology . 2021; 18(7):457– 458. https://doi.or g/10.1038/ s41569-021- 00548-x PMID: 33824486\n79. Cowie M, McBeath K, Angermann C. The digital future of heart failure care. Current Heart Failure\nReports. 2022; 19(3):109– 113. https://doi.or g/10.100 7/s11897-022- 00547-0 PMID: 354412 50\n80. National Institute for Health Resea rch: UK Standa rds for Public Involveme nt. UK Standa rds for Public\nInvolvemen t; 2023. Available from: https://sit es.google.c om/nihr.ac.u k/pi-standa rds/the-p roject.\n81. Deverka PA, Lavallee DC, Desai PJ, Esmail LC, Ramsey SD, Veenstr a DL, et al. Stakeholder participa-\ntion in comparati ve effectiv eness resear ch: defining a framework for effective engagem ent. Journal of\ncomparati ve effective ness research . 2012; 1(2):181–1 94. https://doi.or g/10.2217/ cer.12.7 PMID:\n22707880\n82. National Institute for Health Resea rch. National Institute for Health and Care Excellence (NICE). What\nis public involvement in research ? – INVOLVE.; 2015. Availab le from: https://ww w.invo.org.u k/findout-\nmore/what- is-public -involveme nt-in-resear ch-2/.\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 32 / 33\n83. Jenning s H, Slade M, Bates P, Munday E, Toney R. Best practice framework for Patient and Public\nInvolvemen t (PPI) in collaborat ive data analysis of qualita tive mental health research: methodology\ndevelop ment and refineme nt. BMC psychiatry . 2018; 18(1):1–11 . https://doi. org/10.1186/s 12888-018-\n1794-8 PMID: 299543 73\n84. Berditchev skaia A, Peach K, Malliarak i E. Partici patory AI for humanita rian innovation. London : Nesta.\n2021;.\n85. Birhane A, Isaac W, Prabhak aran V, Diaz M, Elish MC, Gabriel I, et al. Power to the people? opportu ni-\nties and challenges for particip atory AI. Equity and Access in Algorithms , Mechanism s, and Optimiza-\ntion. 2022; p. 1–8. https://doi.or g/10.114 5/3551624.355 5290\n86. Gasteiger N, Ahn HS, Lee C, Lim J, Macdonald BA, Kim GH, et al. Participa tory Design, Developm ent,\nand Testing of Assistive Health Robots with Older Adults: An Interna tional Four-year Project. ACM\nTransaction s on Huma n-Robot Interactio n (THRI). 2022; 11(4):1–19 . https://doi.or g/10.114 5/3533726\n87. Leibo JZ, Dueñez-Gu zman EA, Vezhneve ts A, Agapiou JP, Sunehag P, Koster R, et al. Scalable evalu-\nation of multi-ag ent reinforcem ent learning with melting pot. In: International conferen ce on machine\nlearning. PMLR; 2021. p. 6187–6199.\n88. Pan A, Chan JS, Zou A, Li N, Basart S, Woodside T, et al. Do the rewards justify the means? measurin g\ntrade-offs between rewards and ethical behavior in the machiave lli benchmar k. In: International Confer-\nence on Machine Learning. PMLR; 2023. p. 26837–26 867.\n89. Bender EM, Gebru T, McMill an-Major A, Shmitchel l S. On the Dangers of Stochastic Parrots: Can Lan-\nguage Models Be Too Big? In: Proceedings of the 2021 ACM conferenc e on fairness, account ability,\nand transparenc y; 2021. p. 610–623.\n90. Mehrabi N, Morstatter F, Saxena N, Lerman K, Galstyan A. A survey on bias and fairness in machine\nlearning. ACM computing surveys (CSUR) . 2021; 54(6):1–35 . https:// doi.org/10.11 45/3457 607\n91. Harrer S. Attentio n is not all you need: the complicated case of ethically using large language models in\nhealthcare and medicine. Ebiomedicine. 2023; 90. https://doi.or g/10.101 6/j.ebiom.2 023.104512 PMID:\n36924620\n92. Kalra N, Paddo ck SM. Driving to safety: How many miles of driving would it take to demonst rate autono-\nmous vehicle reliability? Transportat ion Resea rch Part A: Policy and Practice. 2016; 94:182– 193.\n93. Zhavoron kov A. Caution with AI-genera ted content in biomedici ne. Nature medicine. 2023; 29(3):532.\nhttps://doi.or g/10.103 8/d41591-02 3-00014-w PMID: 36750659\nPLOS ONE\nFramewo rk-based qualitativ e analysis of free response s of Large Language Models: Algorithmic fidelity\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.03000 24 March 12, 2024 33 / 33"
}