{
  "title": "Compiling Language Models from a Linguistically Motivated Unification Grammar",
  "url": "https://openalex.org/W2949918103",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4297710021",
      "name": "Rayner, Manny",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Hockey, Beth Ann",
      "affiliations": []
    },
    {
      "id": null,
      "name": "James, Frankie",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Bratt, Elizabeth O.",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3173455974",
      "name": "Goldwater, Sharon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4323217889",
      "name": "Gawron, Mark",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1972573551",
    "https://openalex.org/W2444378235",
    "https://openalex.org/W2011623898",
    "https://openalex.org/W1577541558"
  ],
  "abstract": "Systems now exist which are able to compile unification grammars into language models that can be included in a speech recognizer, but it is so far unclear whether non-trivial linguistically principled grammars can be used for this purpose. We describe a series of experiments which investigate the question empirically, by incrementally constructing a grammar and discovering what problems emerge when successively larger versions are compiled into finite state graph representations and used as language models for a medium-vocabulary recognition task.",
  "full_text": "arXiv:cs/0006021v1  [cs.CL]  9 Jun 2000\nCompiling Language Models from a Linguistically Motivated\nUniﬁcation Grammar\nManny Rayner 1, Beth Ann Hockey 1, Frankie James 1\nElizabeth Owen Bratt 2, Sharon Goldwater 2 and Jean Mark Gawron 2\n(1) Research Institute for Advanced Computer Science\nMail Stop 19-39, NASA Ames Research Center, Moﬀett Field, CA 940 35-1000\n(2) SRI International, 333 Ravenswood Ave, Menlo Park, CA 94025\nAbstract\nSystems now exist which are able to compile\nuniﬁcation grammars into language models that\ncan be included in a speech recognizer, but it\nis so far unclear whether non-trivial linguisti-\ncally principled grammars can be used for this\npurpose. We describe a series of experiments\nwhich investigate the question empirically, by\nincrementally constructing a grammar and dis-\ncovering what problems emerge when succes-\nsively larger versions are compiled into ﬁnite\nstate graph representations and used as lan-\nguage models for a medium-vocabulary recog-\nnition task.\n1 Introduction\nConstruction of speech recognizers for medium-\nvocabulary dialogue tasks has now become an\nimportant practical problem. The central task\nis usually building a suitable language model,\nand a number of standard methodologies have\nbecome established. Broadly speaking, these\nfall into two main classes. One approach is\nto obtain or create a domain corpus, and from\nit induce a statistical language model, usually\nsome kind of N-gram grammar; the alternative\nis to manually design a grammar which speciﬁes\nthe utterances the recognizer will accept. There\nare many theoretical reasons to prefer the ﬁrst\ncourse if it is feasible, but in practice there is of-\nten no choice. Unless a substantial domain cor-\npus is available, the only method that stands a\nchance of working is hand-construction of an ex-\nplicit grammar based on the grammar-writer’s\nintuitions.\nIf the application is simple enough, experi-\nence shows that good grammars of this kind\ncan be constructed quickly and eﬃciently using\ncommercially available products like ViaVoice\nSDK or the Nuance Toolkit (Nuance 1999).\nSystems of this kind typically allow speciﬁca-\ntion of some restricted subset of the class of\ncontext-free grammars, together with annota-\ntions that permit the grammar-writer to asso-\nciate semantic values with lexical entries and\nrules. This kind of framework is fully adequate\nfor small grammars. As the grammars increase\nin size, however, the limited expressive power\nof context-free language notation becomes in-\ncreasingly burdensome. The grammar tends to\nbecome large and unwieldy, with many rules\nappearing in multiple versions that constantly\nneed to be kept in step with each other. It\nrepresents a large development cost, is hard to\nmaintain, and does not usually port well to new\napplications.\nIt is tempting to consider the option of mov-\ning towards a more expressive grammar formal-\nism, like uniﬁcation grammar, writing the orig-\ninal grammar in uniﬁcation grammar form and\ncompiling it down to the context-free notation\nrequired by the underlying toolkit. At least\none such system (Gemini; (Moore et al 1997))\nhas been implemented and used to build suc-\ncessful and non-trivial applications, most no-\ntably CommandTalk (Stent et al 1999). Gem-\nini accepts a slightly constrained version of the\nuniﬁcation grammar formalism originally used\nin the Core Language Engine (Alshawi 1992),\nand compiles it into context-free grammars in\nthe GSL formalism supported by the Nuance\nToolkit. The Nuance Toolkit compiles GSL\ngrammars into sets of probabilistic ﬁnite state\ngraphs (PFSGs), which form the ﬁnal language\nmodel.\nThe relative success of the Gemini system\nsuggests a new question. Uniﬁcation grammars\nhave been used many times to build substantial\ngeneral grammars for English and other natu-\nral languages, but the language model oriented\ngrammars so far developed for Gemini (includ-\ning the one for CommandTalk) have all been\ndomain-speciﬁc. One naturally wonders how\nfeasible it is to take yet another step in the di-\nrection of increased generality; roughly, what\nwe want to do is start with a completely gen-\neral, linguistically motivated grammar, combine\nit with a domain-speciﬁc lexicon, and compile\nthe result down to a domain-speciﬁc context-\nfree grammar that can be used as a language\nmodel. If this programme can be realized, it is\neasy to believe that the result would be an ex-\ntremely useful methodology for rapid construc-\ntion of language models. It is important to note\nthat there are no obvious theoretical obstacles\nin our way. The claim that English is context-\nfree has been respectable since at least the early\n80s (Pullum and Gazdar 1982) 1, and the idea\nof using uniﬁcation grammar as a compact way\nof representing an underlying context-free lan-\nguage is one of the main motivations for GPSG\n(Gazdar et al1985) and other formalisms based\non it. The real question is whether the goal is\npractically achievable, given the resource limi-\ntations of current technology.\nIn this paper, we describe work aimed at the\ntarget outlined above, in which we used the\nGemini system (described in more detail in Sec-\ntion 2) to attempt to compile a variety of lin-\nguistically principled uniﬁcation grammars into\nlanguage models. Our ﬁrst experiments (Sec-\ntion 3) were performed on a large pre-existing\nuniﬁcation grammar. These were unsuccessful,\nfor reasons that were not entirely obvious; in\norder to investigate the problem more system-\natically, we then conducted a second series of\nexperiments (Section 4), in which we incremen-\ntally built up a smaller grammar. By monitor-\ning the behavior of the compilation process and\nthe resulting language model as the grammar’s\ncoverage was expanded, we were able to iden-\ntify the point at which serious problems began\nto emerge (Section 5). In the ﬁnal section, we\nsummarize and suggest further directions.\n1We are aware that this claim is most probably not\ntrue for natural languages in general (Bresnan et al\n1987), but further discussion of this point is beyond the\nscope of the paper.\n2 The Gemini Language Model\nCompiler\nTo make the paper more self-contained, this sec-\ntion provides some background on the method\nused by Gemini to compile uniﬁcation gram-\nmars into CFGs, and then into language mod-\nels. The basic idea is the obvious one: enu-\nmerate all possible instantiations of the features\nin the grammar rules and lexicon entries, and\nthus transform each rule and entry in the orig-\ninal uniﬁcation grammar into a set of rules in\nthe derived CFG. For this to be possible, the\nrelevant features must be constrained so that\nthey can only take values in a ﬁnite predeﬁned\nrange. The ﬁnite range restriction is inconve-\nnient for features used to build semantic repre-\nsentations, and the formalism consequently dis-\ntinguishes syntactic and semantic features; se-\nmantic features are discarded at the start of the\ncompilation process.\nA naive implementation of the basic method\nwould be impractical for any but the small-\nest and simplest grammars, and considerable\ningenuity has been expended on various opti-\nmizations. Most importantly, categories are ex-\npanded in a demand-driven fashion, with infor-\nmation being percolated both bottom-up (from\nthe lexicon) and top-down (from the grammar’s\nstart symbol). This is done in such a way\nthat potentially valid combinations of feature\ninstantiations in rules are successively ﬁltered\nout if they are not licensed by the top-down\nand bottom-up constraints. Ranges of feature\nvalues are also kept together when possible, so\nthat sets of context-free rules produced by the\nnaive algorithm may in these cases be merged\ninto single rules.\nBy exploiting the structure of the gram-\nmar and lexicon, the demand-driven expansion\nmethod can often eﬀect substantial reductions\nin the size of the derived CFG. (For the type\nof grammar we consider in this paper, the re-\nduction is typically by a factor of over 10 20.\nThe downside is that even an apparently small\nchange in the syntactic features associated with\na rule may have a large eﬀect on the size of\nthe CFG, if it opens up or blocks an impor-\ntant percolation path. Adding or deleting lexi-\ncon entries can also have a signiﬁcant eﬀect on\nthe size of the CFG, especially when there are\nonly a small number of entries in a given gram-\nmatical category; as usual, entries of this type\nbehave from a software engineering standpoint\nlike grammar rules.\nThe language model compiler also performs\na number of other non-trivial transformations.\nThe most important of these is related to the\nfact that Nuance GSL grammars are not al-\nlowed to contain left-recursive rules, and left-\nrecursive uniﬁcation-grammar rules must con-\nsequently be converted into a non-left-recursive\nform. Rules of this type do not however occur\nin the grammars described below, and we conse-\nquently omit further description of the method.\n3 Initial Experiments\nOur initial experiments were performed on a\nrecent uniﬁcation grammar in the ATIS (Air\nTravel Information System) domain, developed\nas a linguistically principled grammar with a\ndomain-speciﬁc lexicon. This grammar was\ncreated for an experiment comparing cover-\nage and recognition performance of a hand-\nwritten grammar with that of automatically de-\nrived recognition language models, as increas-\ning amounts of data from the ATIS corpus\nwere made available for each method. Exam-\nples of sentences covered by this grammar are\n“yes”, “on friday”, “i want to ﬂy from boston\nto denver on united airlines on friday septem-\nber twenty third”, “is the cheapest one way\nfare from boston to denver a morning ﬂight”,\nand “what ﬂight leaves earliest from boston to\nsan francisco with the longest layover in den-\nver”. Problems obtaining a working recognition\ngrammar from the uniﬁcation grammar ended\nour original experiment prematurely, and led\nus to investigate the factors responsible for the\npoor recognition performance.\nWe explored several likely causes of recogni-\ntion trouble: number of rules, number of vocab-\nulary items, size of node array, perplexity, and\ncomplexity of the grammar, measured by aver-\nage and highest number of transitions per graph\nin the PFSG form of the grammar.\nWe were able to immediately rule out sim-\nple size metrics as the cause of Nuance’s diﬃ-\nculties with recognition. Our smallest air travel\ngrammar had 141 Gemini rules and 1043 words,\nproducing a Nuance grammar with 368 rules.\nThis compares to the CommandTalk grammar,\nwhich had 1231 Gemini rules and 1771 words,\nproducing a Nuance grammar with 4096 rules.\nTo determine whether the number of the\nwords in the grammar or the structure of\nthe phrases was responsible for the recognition\nproblems, we created extreme cases of a Word+\ngrammar (i.e. a grammar that constrains the\ninput to be any sequence of the words in the\nvocabulary) and a one-word-per-category gram-\nmar. We found that both of these variants\nof our grammar produced reasonable recogni-\ntion, though the Word+ grammar was very in-\naccurate. However, a three-words-per-category\ngrammar could not produce successful speech\nrecognition.\nMany feature speciﬁcations can make a gram-\nmar more accurate, but will also result in a\nlarger recognition grammar due to multiplica-\ntion of feature values to derive the categories\nof the context-free grammar. We experimented\nwith various techniques of selecting features to\nbe retained in the recognition grammar. As de-\nscribed in the previous section, Gemini’s default\nmethod is to select only syntactic features and\nnot consider semantic features in the recogni-\ntion grammar. We experimented with selecting\na subset of syntactic features to apply and with\napplying only semantic sortal features, and no\nsyntactic features. None of these grammars pro-\nduced successful speech recognition.\nFrom these experiments, we were unable to\nisolate any simple set of factors to explain which\ngrammars would be problematic for speech\nrecognition. However, the numbers of transi-\ntions per graph in a PFSG did seem suggestive\nof a factor. The ATIS grammar had a high of\n1184 transitions per graph, while the semantic\ngrammar of CommandTalk had a high of 428\ntransitions per graph, and produced very rea-\nsonable speech recognition.\nStill, at the end of these attempts, it became\nclear that we did not yet know the precise char-\nacteristic that makes a linguistically motivated\ngrammar intractable for speech recognition, nor\nthe best way to retain the advantages of the\nhand-written grammar approach while provid-\ning reasonable speech recognition.\n4 Incremental Grammar\nDevelopment\nIn our second series of experiments, we in-\ncrementally developed a new grammar from\nscratch. The new grammar is basically a scaled-\ndown and adapted version of the Core Lan-\nguage Engine grammar for English (Pulman\n1992; Rayner 1993); concrete development work\nand testing were organized around a speech in-\nterface to a set of functionalities oﬀered by a\nsimple simulation of the Space Shuttle (Rayner,\nHockey and James 2000). Rules and lexical\nentries were added in small groups, typically\n2–3 rules or 5–10 lexical entries in one incre-\nment. After each round of expansion, we tested\nto make sure that the grammar could still be\ncompiled into a usable recognizer, and at sev-\neral points this suggested changes in our im-\nplementation strategy. The rest of this section\ndescribes the new grammar in more detail.\n4.1 Overview of Rules\nThe current versions of the grammar and lexi-\ncon contain 58 rules and 301 uninﬂected entries\nrespectively. They cover the following phenom-\nena:\n1. Top-level utterances: declarative clauses,\nWH-questions, Y-N questions, imperatives,\nelliptical NPs and PPs, interjections.\n2. WH-movement of NPs and PPs.\n3. The following verb types: intransi-\ntive, simple transitive, PP complement,\nmodal/auxiliary, -ing VP complement, par-\nticle+NP complement, sentential comple-\nment, embedded question complement.\n4. PPs: simple PP, PP with postposition\n(“ago”), PP modiﬁcation of VP and NP.\n5. Relative clauses with both relative NP pro-\nnoun (“the temperature that I measured”)\nand relative PP (“the deck where I am”).\n6. Numeric determiners, time expressions,\nand postmodiﬁcation of NP by numeric ex-\npressions.\n7. Constituent conjunction of NPs and\nclauses.\nThe following example sentences illustrate\ncurrent coverage: “yes”, “how about scenario\nthree?”, “what is the temperature?”, “mea-\nsure the pressure at ﬂight deck”, “go to the\ncrew hatch and close it”, “what were temper-\nature and pressure at ﬁfteen oh ﬁve?”, “is the\ntemperature going up?”, “do the ﬁxed sensors\nsay that the pressure is decreasing?”, “ﬁnd out\nwhen the pressure reached ﬁfteen p s i”, “what\nis the pressure that you measured?”, “what is\nthe temperature where you are?”, “can you ﬁnd\nout when the ﬁxed sensors say the temperature\nat ﬂight deck reached thirty degrees celsius?”.\n4.2 Unusual Features of the Grammar\nMost of the grammar, as already stated, is\nclosely based on the Core Language Engine\ngrammar. We brieﬂy summarize the main di-\nvergences between the two grammars.\n4.2.1 Inversion\nThe new grammar uses a novel treatment of\ninversion, which is partly designed to simplify\nthe process of compiling a feature grammar into\ncontext-free form. The CLE grammar’s treat-\nment of inversion uses a movement account, in\nwhich the fronted verb is moved to its notional\nplace in the VP through a feature. So, for\nexample, the sentence “is pressure low?” will\nin the original CLE grammar have the phrase-\nstructure\n“[[is]V [pressure]NP [[]V [low]ADJ ]V P]S”\nin which the head of the VP is a V gap coin-\ndexed with the fronted main verb “is”.\nOur new grammar, in contrast, handles in-\nversion without movement, by making the com-\nbination of inverted verb and subject into a\nVBAR constituent. A binary feature invsubj\npicks out these VBARs, and there is a question-\nformation rule of the form\nS → VP:[invsubj=y]\nContinuing the example, the new gram-\nmar assigns this sentence the simpler phrase-\nstructure\n“[[[is]V [pressure]NP ]V BAR [[low]ADJ ]V P]S”\n4.2.2 Sortal Constraints\nSortal constraints are coded into most grammar\nrules as syntactic features in a straight-forward\nmanner, so they are available to the compilation\nprocess which constructs the context-free gram-\nmar, and ultimately the language model. The\ncurrent lexicon allows 11 possible sortal values\nfor nouns, and 5 for PPs.\nWe have taken the rather non-standard step\nof organizing the rules for PP modiﬁcation so\nthat a VP or NP cannot be modiﬁed by two\nPPs of the same sortal type. The principal mo-\ntivation is to tighten the language model with\nregard to prepositions, which tend to be pho-\nnetically reduced and often hard to distinguish\nfrom other function words. For example, with-\nout this extra constraint we discovered that an\nutterance like\nmeasure temperature at ﬂight deck\nand lower deck\nwould frequently be misrecognized as\nmeasure temperature at ﬂight deck in\nlower deck\n5 Experiments with Incremental\nGrammars\nOur intention when developing the new gram-\nmar was to ﬁnd out just when problems began\nto emerge with respect to compilation of lan-\nguage models. Our initial hypothesis was that\nthese would probably become serious if the rules\nfor clausal structure were reasonably elaborate;\nwe expected that the large number of possible\nways of combining modal and auxiliary verbs,\nquestion formation, movement, and sentential\ncomplements would rapidly combine to produce\nan intractably loose language model. Interest-\ningly, this did not prove to be the case. In-\nstead, the rules which appear to be the primary\ncause of diﬃculties are those relating to relative\nclauses. We describe the main results in Sec-\ntion 5.1; quantitative results on recognizer per-\nformance are presented together in Section 5.2.\n5.1 Main Findings\nWe discovered that addition of the single rule\nwhich allowed relative clause modiﬁcation of an\nNP had a drastic eﬀect on recognizer perfor-\nmance. The most obvious symptoms were that\nrecognition became much slower and the size of\nthe recognition process much larger, sometimes\ncausing it to exceed resource bounds. The false\nreject rate (the proportion of utterances which\nfell below the recognizer’s minimum conﬁdence\ntheshold) also increased substantially, though\nwe were surprised to discover no signiﬁcant in-\ncrease in the word error rate for sentences which\ndid produce a recognition result. To investi-\ngate the cause of these eﬀects, we examined the\nresults of performing compilation to GSL and\nPFSG level. The compilation processes are such\nthat symbols retain mnemonic names, so that it\nis relatively easy to ﬁnd GSL rules and graphs\nused to recognize phrases of speciﬁed grammat-\nical categories.\nAt the GSL level, addition of the relative\nclause rule to the original uniﬁcation grammar\nonly increased the number of derived Nuance\nrules by about 15%, from 4317 to 4959. The av-\nerage size of the rules however increased much\nmore2. It is easiest to measure size at the level of\nPFSGs, by counting nodes and transitions; we\nfound that the total size of all the graphs had in-\ncreased from 48836 nodes and 57195 transitions\nto 113166 nodes and 140640 transitions, rather\nmore than doubling. The increase was not dis-\ntributed evenly between graphs. We extracted\nﬁgures for only the graphs relating to speciﬁc\ngrammatical categories; this showed that the\nnumber of graphs for NPs had increased from\n94 to 258, and moreover that the average size\nof each NP graph had increased from 21 nodes\nand 25.5 transitions to 127 nodes and 165 transi-\ntions, a more than sixfold increase. The graphs\nfor clause (S) phrases had only increased in\nnumber from 53 to 68. They had however also\ngreatly increased in average size, from 171 nodes\nand 212 transitions to 445 nodes and 572 tran-\nsitions, or slightly less than a threefold increase.\nSince NP and S are by far the most important\ncategories in the grammar, it is not strange that\nthese large changes make a great diﬀerence to\nthe quality of the language model, and indi-\nrectly to that of speech recognition.\nComparing the original uniﬁcation grammar\nand the compiled GSL version, we were able to\nmake a precise diagnosis. The problem with the\nrelative clause rules are that they unify feature\nvalues in the critical S and NP subgrammars;\nthis means that each constrains the other, lead-\ning to the large observed increase in the size\nand complexity of the derived Nuance grammar.\nSpeciﬁcally, agreement information and sortal\ncategory are shared between the two daugh-\nter NPs in the relative clause modiﬁcation rule,\nwhich is schematically as follows:\n2GSL rules are written in an notation which allows\ndisjunction and Kleene star.\nNP:[agr=A, sort=S] →\nNP:[agr=A, sort=S]\nREL:[agr=A, sort=S]\nThese feature settings are needed in order to get\nthe right alternation in pairs like\nthe robot that *measure/measures the\ntemperature [agr]\nthe *deck/temperature that you mea-\nsured [sort]\nWe tested our hypothesis by commenting out\nthe agr and sort features in the above rule.\nThis completely solves the main problem of ex-\nplosion in the size of the PFSG representation;\nthe new version is only very slightly larger than\nthe one with no relative clause rule (50647 nodes\nand 59322 transitions against 48836 nodes and\n57195 transitions). Most importantly, there is\nno great increase in the number or average size\nof the NP and S graphs. NP graphs increase in\nnumber from 94 to 130, and stay constant in av-\nerage size; S graphs increase in number from 53\nto 64, and actually decrease in average size to\n135 nodes and 167 transitions. Tests on speech\ndata show that recognition quality is nearly the\nsame as for the version of the recognizer which\ndoes not cover relative clauses. Although speed\nis still signiﬁcantly degraded, the process size\nhas been reduced suﬃciently that the problems\nwith resource bounds disappear.\nIt would be reasonable to expect that remov-\ning the explosion in the PFSG representation\nwould result in an underconstrained language\nmodel for the relative clause part of the gram-\nmar, causing degraded performance on utter-\nances containing a relative clause. Interestingly,\nthis does not appear to happen, though recog-\nnition speed under the new grammar is signif-\nicantly worse for these utterances compared to\nutterances with no relative clause.\n5.2 Recognition Results\nThis section summarizes our empirical recog-\nnition results. With the help of the Nuance\nToolkit batchrec tool, we evaluated three ver-\nsions of the recognizer, which diﬀered only with\nrespect to the language model. no\nrels used\nthe version of the language model derived from a\ngrammar with the relative clause rule removed;\nrels is the version derived from the full gram-\nmar; and unlinked is the compromise version,\nwhich keeps the relative clause rule but removes\nthe critical features. We constructed a corpus\nof 41 utterances, of mean length 12.1 words.\nThe utterances were chosen so that the ﬁrst 31\nwere within the coverage of all three versions\nof the grammar; the last 10 contained relative\nclauses, and were within the coverage of rels\nand unlinked but not of no\nrels. Each utter-\nance was recorded by eight diﬀerent subjects,\nnone of whom had participated in development\nof the grammar or recognizers. Tests were run\non a dual-processor SUN Ultra60 with 1.5 GB\nof RAM.\nThe recognizer was set to reject utterances if\ntheir associated conﬁdence measure fell under\nthe default threshold. Figures 1 and 2 sum-\nmarize the results for the ﬁrst 31 utterances\n(no relative clauses) and the last 10 utterances\n(relative clauses) respectively. Under ‘xRT’,\nwe give mean recognition speed (averaged over\nsubjects) expressed as a multiple of real time;\n‘FRej’ gives the false reject rate, the mean per-\ncentage of utterances which were rejected due to\nlow conﬁdence measures; ‘Mem’ gives the mean\npercentage of utterances which failed due to the\nrecognition process exceeding memory resource\nbounds; and ‘WER’ gives the mean word er-\nror rate on the sentences that were neither re-\njected nor failed due to resource bound prob-\nlems. Since the distribution was highly skewed,\nall means were calculated over the six subjects\nremaining after exclusion of the extreme high\nand low values.\nLooking ﬁrst at Figure 1, we see that rels is\nclearly inferior to no\nrels on the subset of the\ncorpus which is within the coverage of both ver-\nsions: nearly twice as many utterances are re-\njected due to low conﬁdence values or resource\nproblems, and recognition speed is about ﬁve\ntimes slower. unlinked is in contrast not sig-\nniﬁcantly worse than no\nrels in terms of recog-\nnition performance, though it is still two and a\nhalf times slower.\nFigure 2 compares rels and unlinked on the\nutterances containing a relative clause. It seems\nreasonable to say that recognition performance\nis comparable for the two versions: rels has\nlower word error rate, but also rejects more\nutterances. Recognition speed is marginally\nGrammar xRT FRej Mem WER\nno rels 1.04 9.0% – 6.0%\nrels 4.76 16.1% 1.1% 5.7%\nunlinked 2.60 9.6% – 6.5%\nFigure 1: Evaluation results for 31 utterances\nnot containing relative clauses, averaged across\n8 subjects excluding extreme values.\nGrammar xRT FRej Mem WER\nrels 4.60 26.7% 1.6% 3.5%\nunlinked 5.29 20.0% – 5.4%\nFigure 2: Evaluation results for 10 utterances\ncontaining relative clauses, averaged across 8\nsubjects excluding extreme values.\nlower for unlinked, though it is not clear to us\nwhether the diﬀerence is signiﬁcant given the\nhigh variability of the data.\n6 Conclusions and Further\nDirections\nWe found the results presented above surpris-\ning and interesting. When we began our pro-\ngramme of attempting to compile increasingly\nlarger linguistically based uniﬁcation grammars\ninto language models, we had expected to see a\nsteady combinatorial increase, which we guessed\nwould be most obviously related to complex\nclause structure. This did not turn out to be the\ncase. Instead, the serious problems we encoun-\ntered were caused by a small number of crit-\nical rules, of which the one for relative clause\nmodiﬁcation was by the far the worst. It was\nnot immediately obvious how to deal with the\nproblem, but a careful analysis revealed a rea-\nsonable compromise solution, whose only draw-\nback was a signiﬁcant but undisastrous degra-\ndation in recognition speed.\nIt seems optimistic to hope that the rela-\ntive clause problem is the end of the story; the\nobvious way to investigate is by continuing to\nexpand the grammar in the same incremental\nfashion, and ﬁnd out what happens next. We\nintend to do this over the next few months, and\nexpect in due course to be able to present fur-\nther results.\n7 Acknowledgements\nThe research described in Section 3 was sup-\nported by the Defense Advanced Research\nProjects Agency under Contract N66001–94–C–\n6046 with the Naval Command, Control, and\nOcean Surveillance Center. The majority of\nthe research reported was performed at RIACS\nunder NASA Cooperative Agreement Number\nNCC 2-1006.\nReferences\nH. Alshawi. 1992. The Core Language Engine.\nCambridge, Massachusetts: The MIT Press.\nJ. Bresnan, R.M. Kaplan, S. Peters and A. Za-\nenen. Cross-Serial Dependencies in Dutch.\n1987. In W. J. Savitch et al (eds.), The For-\nmal Complexity of Natural Language, Reidel,\nDordrecht, pages 286–319.\nG. Gazdar, E. Klein, G. Pullum and I. Sag.\n1985. Generalized Phrase Structure Gram-\nmar Basil Blackwell.\nR. Moore, J. Dowding, H. Bratt, J.M.\nGawron, Y. Gorfu, and A. Cheyer. 1997.\nCommandTalk: A Spoken-Language Inter-\nface for Battleﬁeld Simulations. Proceed-\nings of the Fifth Conference on Applied\nNatural Language Processing , pages 1–7,\nWashington, DC. Available online from\nhttp://www.ai.sri.com/natural-language\n/projects/arpa-sls/commandtalk.html.\nNuance Communications. 1999. Nuance Speech\nRecognition System Developer’s Manual, Ver-\nsion 6.2\nG. Pullum and G. Gazdar. 1982. Natural Lan-\nguages and Context-Free Languages. Lin-\nguistics and Philosophy, 4, pages 471–504.\nS.G. Pulman. 1992. Uniﬁcation-Based Syntac-\ntic Analysis. In (Alshawi 1992)\nM. Rayner. 1993. English Linguistic Coverage.\nIn M.S. Agn¨ as et al. 1993. Spoken Language\nTranslator: First Year Report. SRI Techni-\ncal Report CRC-043. Available online from\nhttp://www.sri.com.\nM. Rayner, B.A. Hockey and F. James. 2000.\nTurning Speech into Scripts. To appear in\nProceedings of the 2000 AAAI Spring Sym-\nposium on Natural Language Dialogues with\nPractical Robotic Devices\nA. Stent, J. Dowding, J.M. Gawron, E.O.\nBratt, and R. Moore. 1999. The Com-\nmandTalk Spoken Dialogue System. Pro-\nceedings of the 37th Annual Meeting of the\nACL, pages 183–190. Available online from\nhttp://www.ai.sri.com/natural-language\n/projects/arpa-sls/commandtalk.html.",
  "topic": "Unification",
  "concepts": [
    {
      "name": "Unification",
      "score": 0.8637401461601257
    },
    {
      "name": "Computer science",
      "score": 0.8033968210220337
    },
    {
      "name": "Natural language processing",
      "score": 0.6816748380661011
    },
    {
      "name": "Grammar",
      "score": 0.6602119207382202
    },
    {
      "name": "Rule-based machine translation",
      "score": 0.617954671382904
    },
    {
      "name": "Vocabulary",
      "score": 0.5837916135787964
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5696237683296204
    },
    {
      "name": "Compiler",
      "score": 0.5210639834403992
    },
    {
      "name": "Task (project management)",
      "score": 0.49361932277679443
    },
    {
      "name": "Graph",
      "score": 0.47259339690208435
    },
    {
      "name": "Language model",
      "score": 0.45262476801872253
    },
    {
      "name": "Finite state",
      "score": 0.42254674434661865
    },
    {
      "name": "Programming language",
      "score": 0.38956379890441895
    },
    {
      "name": "Linguistics",
      "score": 0.36378639936447144
    },
    {
      "name": "Theoretical computer science",
      "score": 0.1878262460231781
    },
    {
      "name": "Machine learning",
      "score": 0.05977407097816467
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Markov chain",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 10
}