{
  "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
  "url": "https://openalex.org/W4389523710",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A1905034734",
      "name": "Zhen Wan",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A1980519239",
      "name": "Fei Cheng",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A3001786042",
      "name": "Zhuoyuan Mao",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2127015929",
      "name": "Qianying Liu",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2150677482",
      "name": "Haiyue Song",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2107548077",
      "name": "Jiwei Li",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A112209514",
      "name": "Sadao Kurohashi",
      "affiliations": [
        "Kyoto University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4281252097",
    "https://openalex.org/W1840435438",
    "https://openalex.org/W3164972323",
    "https://openalex.org/W2964022985",
    "https://openalex.org/W2126539437",
    "https://openalex.org/W3192478068",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3092542022",
    "https://openalex.org/W4385567149",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4281488715",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W3156470785",
    "https://openalex.org/W4307205413",
    "https://openalex.org/W3093833448",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3167136668",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W2963777632",
    "https://openalex.org/W4226135474",
    "https://openalex.org/W2181042685",
    "https://openalex.org/W3156636935",
    "https://openalex.org/W4225591000",
    "https://openalex.org/W2759211898",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W2963718112",
    "https://openalex.org/W4309201735",
    "https://openalex.org/W4221160826",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4285233740",
    "https://openalex.org/W2963341956"
  ],
  "abstract": "In spite of the potential for ground-breaking achievements offered by large language models (LLMs) (e.g., GPT-3) via in-context learning (ICL), they still lag significantly behind fully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE). This is due to the two major shortcomings of ICL for RE: (1) low relevance regarding entity and relation in existing sentence-level demonstration retrieval approaches for ICL; and (2) the lack of explaining input-label mappings of demonstrations leading to poor ICL effectiveness. In this paper, we propose GPT-RE to successfully address the aforementioned issues by (1) incorporating task-aware representations in demonstration retrieval; and (2) enriching the demonstrations with gold label-induced reasoning logic. We evaluate GPT-RE on four widely-used RE datasets, and observe that GPT-RE achieves improvements over not only existing GPT-3 baselines, but also fully-supervised baselines as in Figure 1. Specifically, GPT-RE achieves SOTA performances on the Semeval and SciERC datasets, and competitive performances on the TACRED and ACE05 datasets. Additionally, a critical issue of LLMs revealed by previous work, the strong inclination to wrongly classify NULL examples into other pre-defined labels, is substantially alleviated by our method. We show an empirical analysis.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3534‚Äì3547\nDecember 6-10, 2023 ¬©2023 Association for Computational Linguistics\nGPT-RE: In-context Learning for Relation Extraction\nusing Large Language Models\nZhen Wan 1 Fei Cheng 1 Zhuoyuan Mao 1\nQianying Liu1 Haiyue Song1 Jiwei Li2 Sadao Kurohashi1\n1 Kyoto University, Japan\n2 Zhejiang University, China\n{zhenwan, zhuoyuanmao, ying, song}@nlp.ist.i.kyoto-u.ac.jp\n{feicheng, kuro}@i.kyoto-u.ac.jp\n{jiwei_li}@zju.edu.cn\nAbstract\nIn spite of the potential for ground-breaking\nachievements offered by large language models\n(LLMs) (e.g., GPT-3) via in-context learning\n(ICL), they still lag significantly behind fully-\nsupervised baselines (e.g., fine-tuned BERT)\nin relation extraction (RE). This is due to the\ntwo major shortcomings of ICL for RE: (1) low\nrelevance regarding entity and relation in exist-\ning sentence-level demonstration retrieval ap-\nproaches for ICL; and (2) the lack of explaining\ninput-label mappings of demonstrations lead-\ning to poor ICL effectiveness.\nIn this paper, we propose GPT-RE to success-\nfully address the aforementioned issues by\n(1) incorporating task-aware representations\nin demonstration retrieval; and (2) enriching\nthe demonstrations with gold label-induced rea-\nsoning logic. We evaluate GPT-RE on four\nwidely-used RE datasets and observe that GPT-\nRE achieves improvements over not only exist-\ning GPT-3 baselines, but also fully-supervised\nbaselines as in Figure 1. Specifically, GPT-RE\nachieves SOTA performances on the Semeval\nand SciERC datasets, and competitive perfor-\nmances on the TACRED and ACE05 datasets.\nAdditionally, a critical issue of LLMs revealed\nby previous work, the strong inclination to\nwrongly classify NULL examples into other pre-\ndefined labels, is substantially alleviated by our\nmethod. We show an empirical analysis.1\n1 Introduction\nThe emergence of large language models (LLMs)\nsuch as GPT-3 (Brown et al., 2020; Thoppilan et al.,\n2022; Chowdhery et al., 2022; Rae et al., 2021;\nHoffmann et al., 2022) represents a significant ad-\nvancement in natural language processing (NLP).\nInstead of following a pretraining-and-finetuning\npipeline (Devlin et al., 2019; Beltagy et al., 2019;\nRaffel et al., 2019; Lan et al., 2019; Zhuang et al.,\n2021), which finetunes a pre-trained model on\n1Codes will be released after the anonymous period.\n70.04\n79.94\n91.989.9Semeval\n32.4933.45\n72.1469.72TACRED\nFine-tuning Baseline (PURE)GPT-RandomGPT-Sent GPT-RE (ours)\nFigure 1: Micro F1 performances on two RE datasets.\nPrevious GPT baselines (GPT-Random: randomly se-\nlected demonstrations and GPT-Sent: sentence-level\ndemonstration retrieval) largely underperform fine-\ntuning baseline PURE while our GPT-RE substantially\noutperforms all baselines.\na task-specific dataset in a fully-supervised man-\nner, LLMs employ a new paradigm known as in-\ncontext learning (ICL) (Brown et al., 2020; Min\net al., 2022a) which formulates an NLP task under\nthe paradigm of language generation and makes\npredictions by learning from a few demonstra-\ntions. Under the framework of ICL, LLMs achieve\nremarkable performance rivaling previous fully-\nsupervised methods even with only a limited num-\nber of demonstrations provided in various tasks\nsuch as solving math problems, commonsense rea-\nsoning, text classification, fact retrieval, natural\nlanguage inference, and semantic parsing (Brown\net al., 2020; Min et al., 2022b; Zhao et al., 2021;\nLiu et al., 2022b; Shin et al., 2021).\nDespite the overall promising performance of\nLLMs, the utilization of ICL for relation extraction\n(RE) is still suboptimal. RE is the central task for\nknowledge retrieval requiring a deep understanding\nof natural language, which seeks to identify a pre-\ndefined relation between a specific entity pair men-\ntioned in the input sentence or NULL if no relation\nis found. Given a test input, ICL for RE prompts\nthe input of LLMs with the task instruction, a few\ndemonstrations retrieved from the training data,\n3534\nMicrosoft is a technology company located in the U.S., founded in 1975 by Bill Gatesand Paul AllenRE TrainingData\nMicrosoft is a famouscomputer technologycompany in the U.S. whose history started in 1975\nRetrievalTestInput\nFew-shot DemonstrationsRelation Triplet: (Microsoft, Bill Gates, founded by)\nRelation Triplet: (Microsoft, the U.S., located in)\nFigure 2: Retrieval without considering the task-aware\ntriplet results in noisy demonstrations.\nand the test input itself. Then LLMs generate the\ncorresponding relation. Recent research (Guti√©r-\nrez et al., 2022) has sought to apply GPT-3 ICL to\nbiomedical RE, but the results are relatively nega-\ntive and suggest that GPT-3 ICL still significantly\nunderperforms fine-tuned models.\nThe reasons that cause the pitfall of GPT-3 ICL\nin RE are two folds: (1) The low relevance re-\ngarding entity and relation in the retrieved demon-\nstrations for ICL. Demonstrations are selected ran-\ndomly or via k-nearest neighbor ( kNN) search\nbased on sentence embedding (Liu et al., 2022b;\nGuti√©rrez et al., 2022). Regrettably, kNN-retrieval\nbased on sentence embedding is more concerned\nwith the relevance of the overall sentence seman-\ntics and not as much with the specific entities and\nrelations it contains, which leads to low-quality\ndemonstrations. As shown in Figure 2, the test in-\nput retrieves a semantically similar sentence but is\nnot desired in terms of entities and relations.\n(2) The lack of explaining input-label mappings\nin demonstrations leads to poor ICL effectiveness:\nA vanilla form of ICL lists all demonstrations as\ninput-label pairs without any explanations. This\nmay mislead LLMs to learn shallow clues from\nsurface words, while a relation can be presented\nin diverse forms due to language complexity. Es-\npecially when ICL has a maximal input length,\noptimizing the learning efficiency of each single\ndemonstration becomes extremely important.\nTo this end, we propose GPT-RE for the RE\ntask. GPT-RE employs two strategies to resolve\nthe issues above: (1) task-aware retrieval and (2)\ngold label-induced reasoning. For (1) task-aware\nretrieval, its core is to use representations that de-\nliberately encode and emphasize entity and relation\ninformation rather than sentence embedding for\nkNN search. We achieve this by two different re-\ntrieval approaches: (a) entity-prompted sentence\nembedding; (b) fine-tuned relation representation,\nwhich naturally places emphasis on entities and\nNULLCEIAPPNULLCEIAPP\nTrue\nPredicted\nBERT Fine-tuning\nNULLCEIAPP\n1.00.80.60.40.20.0NULLCEIAPP\nTrue\nPredicted\nGPT-3 In-context Learning\nFigure 3: Confusion matrix on Semeval dataset with\nthree selected relation labels. The NULL examples are\noverpredicted to other relations by GPT-3. CE: Cause-\nEffect, IA: Instrument-Agency, PP: Product-Producer.\nrelations. Both methods contain more RE-specific\ninformation than sentence semantics, thus effec-\ntively addressing the problem of low relevance.\nFor (2) gold label-induced reasoning, we pro-\npose to inject the reasoning logic into the demon-\nstration to provide more evidence to align an in-\nput and the label, a strategy akin to the Chain-of-\nThought (CoT) research (Wei et al., 2022; Wang\net al., 2022b; Kojima et al., 2022). But different\nfrom previous work, we allow LLMs to elicit the\nreasoning process to explain not only why a given\nsentence should be classified under a particular la-\nbel but also why a NULL example should not be\nassigned to any of the pre-defined categories. This\nprocess significantly improves the ability of LLMs\nto align the relations with diverse expression forms.\nRecent work reveals another crucial problem\nnamed ‚Äúoverpredicting‚Äù as shown in Figure 3: we\nobserve that LLMs have the strong inclination to\nwrongly classify NULL examples into other pre-\ndefined labels . A similar phenomenon has also\nbeen observed in other tasks such as NER (Guti√©r-\nrez et al., 2022; Blevins et al., 2022). In this paper,\nwe show that this issue can be alleviated if the rep-\nresentations for retrieval can be supervised with the\nwhole set of NULL in the training data.\nWe evaluate our proposed method on three popu-\nlar general domain RE datasets: Semeval 2010 task\n8, TACRED and ACE05, and one scientific domain\ndataset SciERC. We observe that GPT-RE achieves\nimprovements over not only existing GPT-3 base-\nlines, but also fully-supervised baselines. Specifi-\ncally, GPT-RE achieves SOTA performances on the\nSemeval and SciERC datasets, and competitive per-\nformances on the TACRED and ACE05 datasets.\n3535\n‚Ñé[\"#$]‚äï‚Ñé[&$']\nContext: My 8 year-olddaughtercame up withan extremely goodidea.Relation: ?\nTraining Set\nTokens: [ùê∂ùêøùëÜ]My 8 year-oldùëÇùêµùêΩdaughter[/ùëÇùêµùêΩ]came up withan extremely good [ùëÜùëàùêµ]idea[/ùëÜùëàùêµ].Reconstructed context: The relation between ‚Äúidea‚Äù and ‚Äúdaughter‚Äù in the context:My 8 year-olddaughtercame up with an extremely good idea.\nSimCSE Fine-tuned RE Model‚Ñé()*+)*,)\nContext: ideasfor continuous development also emerged from the students' collaborative efforts.Relation: PRODUCT AND PRODUCER\nI will predict the relation between two entities given the context.The pre-defined relations areCAUSE AND EFFECT,COMPONENT AND WHOLE, ‚Ä¶I will output NULLif the relation does not belong to them.\nTask Description\nICL Demonstrations (ùíå-shot)\nContext: My 8 year-olddaughtercame up withan extremely goodidea.Given the context, the relation between ideaand daughterisTest Input\nTest OutputPRODUCT AND PRODUCER\nGold Label-induced Reasoning (Sec. 2.5)\nContext: ideasfor continuous development also emerged from the students' collaborative efforts.Given the context, the relation between ideasand studentsis PRODUCT AND PRODUCER.Reason: The phrase \"collaborative efforts\" suggests that students are working together to create something;The word ‚Äúemerged‚Äù ‚Ä¶\nTask-aware Demonstration Retreval (Sec. 2.4) Prompt Construction (Sec. 2.3)\nTest Input\nùëòNN Retrieval\nRetrieved Demonstrations\nFigure 4: An illustration of GPT-RE. Given a test input, we first leverage two different task-aware retrieval methods\nto search for highly relevant demonstrations from the training set, and then incorporate the gold label-induced\nreasoning for each demonstration. Above contents will then be included in the prompt construction to make the\nprediction.\n2 Methodology: GPT-RE\n2.1 Task Definition\nLet C denote the input context and esub ‚àà C,\neobj ‚ààC denote the pair of subject and object entity.\nGiven a set of pre-defined relation classes R, rela-\ntion extraction aims to predict the relation y ‚ààR\nbetween the pair of entities ( esub, eobj) within the\ncontext C, or if there is no pre-defined relation be-\ntween them, predict y = NULL .\n2.2 Overview\nWe will first introduce the prompt construction\nto formalize RE as a language generation task\nin Sec. 2.3. Then to improve the ICL frame-\nwork for RE, we will introduce two modules: (1)\ntask-aware demonstration retrieval to select higher-\nquality demonstrations (Sec. 2.4); (2) gold label-\ninduced reasoning to enrich each demonstration\nwith explanations (Sec. 2.5). In Figure 4, we show\nthe concrete workflow of processing a test input.\n2.3 Prompt Construction\nWe construct a prompt for each given test example,\nwhich is fed to the GPT-3 model. Each prompt\nconsists of the following components:\nInstructions I We provide a succinct overview\nof the RE task description and the set of pre-defined\nclasses R. The model is explicitly asked to out-\nput the relation, which belongs to the pre-defined\nclasses. Otherwise, the model will output NULL .\nICL Demonstrations D We first leverage a task-\naware retriever to acquire a k-shot demonstration\nset, then enrich each demonstration (xi, yi) with\nthe gold label-induced reasoning ri to build a new\nset of (xi, yi, ri) as D.\nTest Input xtest Similar to the demonstrations,\nwe offer the test input xtest, and GPT-3 is expected\nto generate the corresponding relation ytest.\nIn summary, GPT-RE can be formulated as:\np (ytest ‚ààR ‚à™{NULL }|I, D, xtest) (1)\n2.4 Task-aware Demonstration Retrieval\nSince ICL demonstrations closer to the test sample\nin the embedding space result in more consistent\nand robust performance (Liu et al., 2022b). Re-\ncent work (Guti√©rrez et al., 2022; Liu et al., 2022b)\nemploys the kNN to retrieve the most similar ex-\namples in the training set as the few-shot demon-\nstrations for each test input. As kNN relies on the\nchoice of the embedding space to encode both test\ninput and examples in the training set, they propose\nto obtain sentence embedding using pre-trained\nlanguage models, or other improved sentence em-\nbedding.\nHowever, using sentence embedding for kNN\nretrieval has a severe drawback: relation extrac-\ntion focuses on pair-wise entities, which diverge\nfrom the semantic meaning of the entire sentence,\nleading to an ambiguous retrieval using sentence\nembedding. In this study, we propose two novel\n3536\nmethods to provide more robust representations for\nbetter retrieval quality: (1) a naive entity-prompted\nsentence embedding in Sec. 2.4.1; (2) an advanced\nfine-tuned relation representation in Sec. 2.4.2.\n2.4.1 Entity-Prompted Sentence Embedding\nGiven the discrepancy between sentence embed-\nding and relation extraction, the original context is\ninsufficient for demonstration retrieval. Consider-\ning the importance of entity information in RE, we\npropose reconstructing the context by incorporat-\ning entity pair information. For example, given the\ncontext ‚ÄúHe has a sister Lisa,‚Äù the reconstructed\ncontext with the entity prompted will be ‚ÄúThe re-\nlation between ‚ÄòHe‚Äô and ‚ÄòLisa‚Äô in the context: He\nhas a sister Lisa.‚Äù This approach preserves both\nthe semantic meaning of the sentence and the en-\ntity pair-centered information during retrieval. In\nthe paper, we employ the latest robust model Sim-\nCSE (Gao et al., 2021) for computing sentence\nembedding-based similarity.\n2.4.2 Fine-tuned Relation Representation\nCompared to prompt entity information into con-\ntext sentences, a more straightforward solution is to\nextract the relation representation from a fine-tuned\nRE model for retrieving demonstrations.\nCurrent BERT-based fine-tuning methods for\nRE (Baldini Soares et al., 2019; Zhong and Chen,\n2021; Wan et al., 2022) attempts to capture both\nthe context information and the entity information\nby adding extra marker tokens to highlight the sub-\nject and object entities and their types. Specifically,\ngiven an example: ‚Äú He has a sister Lisa.‚Äù, the in-\nput tokens are ‚Äú[CLS] [SUB_PER] He [/SUB_PER]\nhas a sister [OBJ_PER] Lisa [/OBJ_PER] . [SEP] ‚Äù\nwhere ‚ÄúPER ‚Äù is the entity type if provided. De-\nnote the n-th hidden representation of the BERT\nencoder as hn. Assuming i and j are the indices\nof two beginning entity markers [SUB_PER] and\n[OBJ_PER] , we define the relation representation as\nRel = hi ‚äïhj where ‚äïstands for concatenation\nof representations in the first dimension. Subse-\nquently, this representation is fed into a feedfor-\nward network for predicting the relation probability\np(y ‚ààR ‚à™{NULL }| Rel).\nThe entity markers have explicitly encoded sub-\nject and object entities and the relation represen-\ntation Rel is naturally enriched with the entity in-\nformation. We believe this approach can poten-\ntially compensate for the limitations of GPT-3 in\nRE. While GPT-3 ICL has a constraint of limited\nContext: ideasfor continuous development also emerged from the students' collaborative efforts.Given the context, the relation between ideasand studentsis PRODUCT AND PRODUCER.\nICL Demostration\nWhat are the clues that lead to the relation between ‚Äúideas‚Äù and ‚Äústudents‚Äù to be PRODUCT AND PRODUCER in the sentence ‚Äúideasfor continuous development also emerged from the students' collaborative efforts.‚Äù?\nQuery\nIt is because: The phrase \"collaborative efforts\" suggests that students are working together to create or produce something; The use of the word \"emerged\" implies that the ideas are a result or product of the students' efforts. Therefore, the relation between students and ideas is PRODUCT AND PRODUCER.\nReason\nFigure 5: An illustration of adding reasoning.\nDataset # Relation # Train # Dev # Test (# Subset) NULL (%)Semeval 9 6,507 1,493 2,717 (2,717) 17.40%TACRED 41 68,124 22,631 15,509 (1,600) 79.40%SciERC 7 16,872 2,033 4,088 (4,088) 90.16%ACE05 6 121,368 27,597 24,420 (2,442) 95.60%\nTable 1: Statistics of datasets.\ndemonstrations, the fine-tuning process is unbun-\ndled and can be done on the whole train data. It\nhas two subsequent merits. First, the relation repre-\nsentations are directly fine-tuned to fit the RE task,\nwhich could significantly boost the overall retrieval\nquality. Second, the overpredicting NULL issue\nwill be substantially alleviated because the similar\nNULL demonstrated can be accurately recognized\nby the fine-tuned model.\n2.5 Gold Label-induced Reasoning\nRecent CoT work has reported significant progress\nin the commonsense and numerical reasoning tasks\nby automatically eliciting the reasoning steps for\nsolving a question. While in the RE task, two\nentities can possibly hold multiple relations, e.g.,\n‚ÄúJoe Biden‚Äù can be either the president of or lives\nin ‚ÄúU.S.‚Äù. The reasoning generation could be out\nof focus if it lacks interaction with the gold label.\nIn this section, we propose to let GPT-3 induce\nthe reasoning logic for each demonstration by the\ncorresponding gold relation label. As shown in\nFigure 5, given a selected demonstration, we first\ngenerate a query prompt ‚ÄúWhat are the clues that\nlead to the relation between [entity1] and [entity2]\nto be [relation] in the sentence [context]?‚Äù based\non the demonstration and subsequently ask GPT-3\nto generate clues ‚ÄúIt is because: ...‚Äù on the labeled\nrelation between the pair of entities in the context.\nFinally, we augment the demonstration by incorpo-\nrating the generated clues induced by GPT-3.\n3537\nMethods Retriever Semeval TACRED SciERC ACE05\nGPT-3 Baselines (Bestk-shot)\nGPT-Random - 70.04 (30) 32.49 (15) 17.92 (25) 9.04 (25)\nGPT-Sent SimCSE 79.94 (30) 33.45 (15) 20.96 (25) 6.31 (25)\nOurs (Bestk-shot)\nGPT-RE_SimCSE SimCSE 81.02 (30) 37.44 (15) 26.46 (25) 8.67 (25)\nGPT-RE_SimCSE* SimCSE 77.49 (15) 31.58 (10) - -\n+ Reasoning SimCSE 79.88 (15) 33.18 (10) - -\nGPT-RE_FT PURE 91.90 (25) 72.14 (15) 69.00 (30) 68.73 (25)\nGPT-RE_FT* PURE 91.11 (15) 70.38 (10) - -\n+ Reasoning PURE 91.82 (15) 70.97 (10) - -\nFine-tuned RE Baselines\nCohen et al. (2020) 91.90 - - -\nWang et al. (2022a) - ‚ô£76.80 - -\nPURE (Zhong and Chen, 2021) 89.90 69.72 68.45 70.09\nTable 2: Main Results on four RE datasets. All results are given by Micro-F1. * denotes the same k-shot for the\ncomparison with + Reasoning. Due to the costly GPT-3 expense, we conducted Reasoning experiments on the two\nrelatively smaller datasets Semeval and TACRED.‚ô£denotes that this performance is not comparable as it evaluates\non the entire test set. The underline denotes the results outperforming the fine-tuning baseline PURE.\n3 Experiment Setup\n3.1 Datasets\nWe evaluate on three popular general domain RE\ndatasets and one scientific domain dataset. Due\nto the cost of running the model in the API with\nGPT-3, in our main results, we sample a subset\n(See Appendix C) from the original test set for\ntwo datasets: ACE05 and TACRED as shown in\nTable 1.\nSemeval 2010 task 8 Hendrickx et al. (2010) fo-\ncuses on semantic relations between pairs of nomi-\nnals collected from general domain resources.\nTACRED Zhang et al. (2017) is a large-scale\nrelation extraction dataset with 106,264 examples\nbuilt over newswire and web text.\nSciERC Luan et al. (2018) collects AI paper\nabstracts and annotated relations, especially for\nscientific knowledge graph construction.\nACE05 contains the entity, relation, and event\nannotations collected from domains including\nnewswire, broadcast, discussion forums, etc.\n3.2 Baseline Methods\nGPT-3 baselines For GPT-3 baselines and our\nmethods, we select ‚Äú text-davinci-003‚Äù with\nmaximal 4,097 input tokens and use the identical\nprompt construction (Sec. 2.3) via OpenAI API.\nWe implement two categories of GPT-3 baselines:\n(1) GPT-Random Instead of randomly selecting\nfew-shot demonstrations from the training data for\neach test input, we add extra constraints to make the\nlabel distribution of selected demonstrations more\nuniform. Our preliminary experiments suggest that\nthis is a stronger baseline than the vanilla random.\n(2) GPT-Sent Previous work attempts various sen-\ntence embedding in retrieval. In this work, our im-\nplementation adopted SimCSE (Gao et al., 2021),\nwhich has been demonstrated to be the state-of-the-\nart method for sentence similarity tasks.\nFine-tuned RE Models In our experiment, we\nchoose PURE (Zhong and Chen, 2021), an en-\ntity marker-based fine-tuned model mentioned in\nSec. 2.4.2 to obtain the representations for retrieval.\nMeanwhile, PURE performs as a directly compara-\nble baseline. We also compare with corresponding\nSOTA fine-tuned baselines on Semeval Cohen et al.\n(2020) (reformulate RE as the question answering\ntask) and TACRED Wang et al. (2022a) (extra pre-\ntraining to capture RE structure) datasets.\nAll implementation details are in Appendix A.\n3538\n(a) The comparison on retrieval modules\n(b) Reasoning with fewer demonstrations.\nFigure 6: Ablation study on the retrieval and reason-\ning components on Semeval. We sampled a subset\nfrom the test data with 300 examples. We show the ‚Äòw/o\nreasoning‚Äô results with k = 30for comparison.\n4 Experimental Results\n4.1 Main Results\nWe compare our main experiment results with pre-\nvious methods in Table 2. GPT-RE_SimCSE de-\nnotes our entity-prompted sentence embedding for\nretrieval and GPT-RE_FT denotes our fine-tuned\nrelation representation for retrieval. From the table,\nwe can observe that: (1) bothGPT-RE_SimCSE and\nGPT-RE_FT outperform the retrieval-based GPT-\nSent, indicating that it is necessary to inject the task-\nspecific information into sentence embedding for\nselecting proper demonstrations; (2) GPT-RE_FT\nsucceeds to outperform the fine-tuning baseline\nPURE on three datasets by +2.00, +2.42, +0.55\nMicro-F1. It suggests that GPT-3 has the poten-\ntial to beat fine-tuning when the retriever has prior\ntask knowledge. GPT-RE_FT eventually achieves\nSOTA results on Semeval and SciERC. (3) reason-\ning module improves GPT-RE_SimCSE by around\n2% Micro-F1, indicating that gold label-induced\nreasoning successfully enriches the knowledge\nFigure 7: Low-resource Scenario on Semeval . We\nlimit the percentage of training data for both fine-tuning\nand retrieval in GPT-RE.\nof demonstrations. Meanwhile, the high-quality\ndemonstrations obtained by GPT-RE_FT offset the\neffort of enriching reasoning into demonstrations,\nwhich shows relatively trivial improvements. Since\nreasoning aims at enriching demonstrations, this\nfeature potentially works better with fewer demon-\nstrations, as shown in Section 4.3.\n4.2 Ablation Study on Task-aware Retrieval\nWe first implement the ablation experiments of the\nretrieval component with the setting of increasing\nk-shot demonstrations (Figure 6a). We find that:\n(1) compared to GPT-Random, all the retrieval-\nbased models have higher F1 scores and large gra-\ndients of the performance curves. It means that\nGPT-3 can learn from high-quality demonstrations\nmore effectively; (2) after adding entity informa-\ntion to the SimCSE retrieval, GPT-RE_SimCSE\nachieves better performance throughout allK shots,\nindicating that task-aware sentence embedding can\ncapture the feature of RE and provide more proper\ndemonstrations; (3) finally, the fine-tuned relation\nrepresentation retriever GPT-RE_FT significantly\noutperforms all retrieval-based methods and beats\nthe fine-tuning baseline when k >15. Note that\neven with k = 5demonstrations, GPT-RE_FT still\nworks better than GPT-RE_SimCSE with k = 30\n(80.30 ‚àí ‚Üí83.43(+3.13)), which indicates that the\nquality of demonstrations shows much more impor-\ntant than the number of demonstrations.\n4.3 Ablation Study on Reasoning Enhancing\nWe then check the influence of our proposed\nreasoning-enhanced demonstration, as shown in\nFigure 6b. Due to the limited amount of input to-\nkens of GPT-3, we have to set the k ‚â§15 for the\n3539\n(a) General domain with 17.4% NULL examples\n (b) Scientific domain with 90.16% NULL examples\nFigure 8: Analysis on the effects of NULL examples. w/o NULL refers to the classification setting that NULL\nexamples are excluded from the train and test data. w/ NULL refers to the original extraction setting. We use the full\ntest set for the evaluation.\ntokens of reasoning, leading to a trade-off between\nadding reasoning and adding more demonstrations.\nFrom the result, we find that: (1) with reasoning-\nenhanced demonstrations, GPT-3 always achieves\nbetter scores across all the k-shot settings of both\nGPT-RE_SimCSE and GPT-RE_FT, indicating that\nthe reasoning induced from ground truth relation\nlabels can effectively unlock the reasoning ability\nof GPT-3 and improve the ICL with a deeper under-\nstanding of demonstrations. Specifically, for GPT-\nRE_FT, the performance improvement becomes\nless significant when more demonstrations are pro-\nvided, which is feasible as with more high-quality\ndemonstrations available, GPT-3 can already learn\nthe internal reasoning behind each demonstration;\n(2) since the reasoning enhancement works better\nwith fewer demonstrations, we expect this method\ncan be an effective solution to low-shot relation\nextraction (Han et al., 2018; Geng et al., 2020; Liu\net al., 2022a), which aims at recognizing novel re-\nlations with very few or no examples, and we leave\nthis for future work.\n4.4 Low-resource Scenario\nWe conduct the experiment for observing the low-\nresource performance in the general domain Se-\nmeval task. As shown in Figure 7, we observe\nthat: (1) all the GPT-3 based results work bet-\nter than fine-tuning in when the training examples\nare less than # 650 (10%). It indicates that in the\ngeneral domain RE, GPT-3 benefits from its abun-\ndant prior knowledge to understand the relations;\n(2) GPT-RE_SimCSE starts to show a substantial\ndifference to GPT-Sent after the training size sur-\npasses 30%. We believe fewer training candidates\ncould limit the effects of retrieval; (3) GPT-RE_FT\nachieves an upper bound performance in all set-\ntings, even when the fine-tuned model shows poor\nperformance with hundreds of training data (from\n#100 to #400). This emphasizes the impressive\neffectiveness of fine-tuned relation representations\nfor capturing higher-quality demonstrations. The\nobservation in the low-resource setting is very dif-\nferent from Guti√©rrez et al. (2022). We assume\nthe difference could be caused by the domain and\nNULL proportion of the task.\n5 Analysis\n5.1 The Issue of ‚ÄúOverpredicting‚Äù\nTo analyze the influence of NULL class, we com-\npare the effectiveness of each method for allevi-\nating this issue on two datasets: general domain\nSemeval with 17.4% NULL examples and scientific\ndomain SciERC with 90.16% NULL examples. As\nshown in Figure 8, (1) by comparing the perfor-\nmance on Semeval and SciERC, a larger percentage\nof NULL examples results in more significant per-\nformance drop showing the negative influence of\noverpredicting NULL examples; (2) by comparing\nw/o NULL and w/ NULL , our GPT-RE_FT shows\nthe most robustness to the influence of NULL ex-\namples, indicating that the RE fine-tuned represen-\ntations in retrieval can release the overpredicting\nissue of GPT-3 by providing higher-quality demon-\nstrations; (3) however, even with task-aware repre-\nsentations, all GPT-3 methods still underperform\nthe fine-tuning baseline on NULL examples, this is\ndue to the confusing definition of NULL , in many\ncases, there is a certain relation between entities\nin the context, but out of the distribution of pre-\n3540\nContext: among the contents of the vesselwere a set of carpenter 's tools, several large storage jars , ceramic utensils , rope ‚Ä¶‚Ä¶Given the context, the relation between tools and vesselis CONTENT AND CONTAINER.\nGPT-Sent Demonstration\nContext: to preserve its catchof fish, each boat loads between 2000 and 3000 kilos of ice before it goes out to sea .Given the context, the relation between catchand fishis [NULL]\nTest Input\nContext: local fisherman heated some of their catchcooked over coals in a scuttle.Given the context, the relation between catchand scuttle is CONTENT AND CONTAINER.\nGPT-RE_SimCSE Demonstration\nContext: septembernormally marks the arrival of the earliest runof fishinto lake tributaries , and peak runs occur in october.Given the context, the relation between runand fishis NULL.\nGPT-RE_FT Demonstration\nRetrievalGPT-SentGPT-RE_SimCSEGPT-RE_FTGPT-3 OutputCONTENT AND CONTAINERPRODUCT AND PRODUCERNULL\nFigure 9: A case study of demonstration quality on\nSemeval. [NULL ] is the gold label here.\ndefined classes. In these cases, GPT-3 tends to\noverpredict as the relation information may be cov-\nered in its prior knowledge. We think this ability\nof GPT-3 can be useful in more open fields, such\nas open RE (Banko and Etzioni, 2008) which has\nno pre-defined relation classes.\n5.2 Case Study of Demonstration Quality\nWe select one typical test example to better illus-\ntrate the amendment of our task-aware demonstra-\ntion retrieval. As shown in Figure 9, given the\nNULL Example, we show the most similar demon-\nstration in retrieval based on three methods. The\nGPT-Sent retrieved demonstration focuses on the\nsemantic meaning of ‚ÄúCONTENT AND CON-\nTAINER‚Äù which is shared in the test context, but\nnot revealed in the target entity pair. This mismatch\nconfirms the problem of lacking entity information\nin retrieval. Instead, GPT-RE_SimCSE retrieves a\nmuch more relevant demonstration that shows the\nsame semantic relation between ‚Äúcatch‚Äù and ‚Äúfish‚Äù\nbut still faces a minor mismatch as the gold label\nis between ‚Äúcatch‚Äù and ‚Äúscuttle.‚Äù Finally, GPT-\nRE_FT demonstration shares a similar structure\nwith the test input regarding the pair of entities,\nwhich is the key clue for predicting the relation\nbetween entities. This result shows a level-by-\nlevel enhancement with more entity information\nprovided in retrieval. We also show some other\ncase examples in Appendix B.\n6 Related Work\nIn-context Learning Recent work shows that\nICL of GPT-3 (Brown et al., 2020) can perform\nnumerous tasks when provided a few examples in a\nnatural language prompt. Existing work focuses on\nvarious aspects to effectively utilize the advantages\nof GPT-3, from prompt design (Perez et al., 2021)\nfor proper input to coherence calibration (Malkin\net al., 2022) for tackling the diverse generated out-\nput. Another research path locates in the demon-\nstration part, including ordered prompts (Lu et al.,\n2022) and retrieval-based demonstrations (Rubin\net al., 2022; Liu et al., 2022b; Shin et al., 2021).\nTo the best of our knowledge, there is no pre-\nvious work exploring the potential of GPT-3 on\ngeneral domain RE tasks. A recent work attempts\nto leverage GPT-3 in biomedical information ex-\ntraction (NER and RE), and reveals issues of ICL\nthat may be detrimental to IE tasks in general. Our\nwork succeeds in overcoming these issues to some\nextent and confirms the potential of GPT-3 in both\ngeneral and the scientific domain RE.\nRetrieval-based Demonstrations Several stud-\nies have demonstrated that dynamically selecting\nfew-shot demonstrations for each test example, in-\nstead of utilizing a fixed set, leads to significant\nimprovement in GPT-3 ICL (Liu et al., 2022b;\nShin et al., 2021; Rubin et al., 2022). They also\nshow that nearest neighbor in-context examples\nyield much better results than the farthest ones.\nThis leads to the significance of better retrieval\nmodules for demonstrations. Existing attempts rely\non sentence embedding in retrieval, including the\nsentence encoders of PLMs such as BERT (De-\nvlin et al., 2019), RoBERTa (Zhuang et al., 2021)\nKATE (Liu et al., 2022b) , SimCSE (Gao et al.,\n2021), Sentence-BERT (Reimers and Gurevych,\n2019; Wolf et al., 2020). Unlike these sentence\nembeddings, we propose to fine-tune PLMs on our\ntarget RE tasks to produce more task-specific and\nrobust representations for retrieval.\n7 Conclusions\nThis work explores the potential of GPT-3 ICL\non RE for bridging the performance gap to the\nfine-tuning baselines via two strategies: (1) task-\naware demonstration retrieval emphasizes entity\nand relation information for improving the accu-\nracy of searching demonstrations; (2) gold label-\ninduced reasoning enriches the reasoning evidence\n3541\nof each demonstration. To the best of our knowl-\nedge, GPT-RE is the first GPT-3 ICL research that\nsignificantly outperforms the fine-tuning baseline\non three datasets and achieves SOTA on Semeval\nand SciERC. We implement detailed studies to ex-\nplore how GPT-3 overcomes the difficulties such\nas NULL example influence.\nLimitations\nDespite the overall positive results, GPT-RE still\nfaces two shortcomings: (1) the issue of overpre-\ndicting has been significantly alleviated but not\ncompletely solved, and the NULL recall still lags\nbehind full-supervised baselines, especially on the\ndatasets containing a large proportion of NULL ex-\namples such as ACE05 (‚Äú95.60%‚Äù); (2) Though\nthe task-aware retriever optimizes the representa-\ntions of PLMs such as SimCSE and BERT, it is\nwidely considered that LLMs can generate more ro-\nbust representations than small PLMs. Future work\ncan replace representations generated by smaller\nPLMs with GPT-3 itself. However, due to the ac-\ncess limitation to the representations of GPT-3, we\ncan nearly confirm this proposal up to now.\nReferences\nLivio Baldini Soares, Nicholas FitzGerald, Jeffrey Ling,\nand Tom Kwiatkowski. 2019. Matching the blanks:\nDistributional similarity for relation learning. In Pro-\nceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 2895‚Äì\n2905, Florence, Italy. Association for Computational\nLinguistics.\nMichele Banko and Oren Etzioni. 2008. The tradeoffs\nbetween open and traditional relation extraction. In\nProceedings of ACL-08: HLT, pages 28‚Äì36, Colum-\nbus, Ohio. Association for Computational Linguis-\ntics.\nIz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB-\nERT: A pretrained language model for scientific text.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 3615‚Äì\n3620, Hong Kong, China. Association for Computa-\ntional Linguistics.\nTerra Blevins, Hila Gonen, and Luke Zettlemoyer. 2022.\nPrompting language models for linguistic structure.\nCoRR, abs/2211.07830.\nSamuel R. Bowman, Gabor Angeli, Christopher Potts,\nand Christopher D. Manning. 2015. A large anno-\ntated corpus for learning natural language inference.\nIn Proceedings of the 2015 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n632‚Äì642, Lisbon, Portugal. Association for Compu-\ntational Linguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems,\nvolume 33, pages 1877‚Äì1901. Curran Associates,\nInc.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways. CoRR, abs/2204.02311.\nAmir D. N. Cohen, Shachar Rosenman, and Yoav Gold-\nberg. 2020. Relation extraction as two-way span-\nprediction. CoRR, abs/2010.04829.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171‚Äì4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nTianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\nSimCSE: Simple contrastive learning of sentence em-\nbeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 6894‚Äì6910, Online and Punta Cana, Do-\nminican Republic. Association for Computational\nLinguistics.\n3542\nXiaoqing Geng, Xiwen Chen, Kenny Q. Zhu, Libin\nShen, and Yinggong Zhao. 2020. MICK: A meta-\nlearning framework for few-shot relation classifica-\ntion with small training data. In CIKM ‚Äô20: The\n29th ACM International Conference on Information\nand Knowledge Management, Virtual Event, Ireland,\nOctober 19-23, 2020, pages 415‚Äì424. ACM.\nBernal Jim√©nez Guti√©rrez, Nikolas McNeal, Clay Wash-\nington, You Chen, Lang Li, Huan Sun, and Yu Su.\n2022. Thinking about GPT-3 in-context learning for\nbiomedical ie? think again. CoRR, abs/2203.08410.\nXu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao,\nZhiyuan Liu, and Maosong Sun. 2018. FewRel: A\nlarge-scale supervised few-shot relation classification\ndataset with state-of-the-art evaluation. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 4803‚Äì4809,\nBrussels, Belgium. Association for Computational\nLinguistics.\nIris Hendrickx, Su Nam Kim, Zornitsa Kozareva,\nPreslav Nakov, Diarmuid √ì S√©aghdha, Sebastian\nPad√≥, Marco Pennacchiotti, Lorenza Romano, and\nStan Szpakowicz. 2010. SemEval-2010 task 8: Multi-\nway classification of semantic relations between pairs\nof nominals. In Proceedings of the 5th International\nWorkshop on Semantic Evaluation, pages 33‚Äì38, Up-\npsala, Sweden. Association for Computational Lin-\nguistics.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,\nElena Buchatskaya, Trevor Cai, Eliza Rutherford,\nDiego de Las Casas, Lisa Anne Hendricks, Johannes\nWelbl, Aidan Clark, Tom Hennigan, Eric Noland,\nKatie Millican, George van den Driessche, Bogdan\nDamoc, Aurelia Guy, Simon Osindero, Karen Si-\nmonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,\nand Laurent Sifre. 2022. Training compute-optimal\nlarge language models.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large\nlanguage models are zero-shot reasoners. CoRR,\nabs/2205.11916.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2019. Albert: A lite bert for self-supervised learning\nof language representations.\nFangchao Liu, Hongyu Lin, Xianpei Han, Boxi Cao, and\nLe Sun. 2022a. Pre-training to match for unified low-\nshot relation extraction. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 5785‚Äì\n5795, Dublin, Ireland. Association for Computational\nLinguistics.\nJiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,\nLawrence Carin, and Weizhu Chen. 2022b. What\nmakes good in-context examples for GPT-3? In\nProceedings of Deep Learning Inside Out (DeeLIO\n2022): The 3rd Workshop on Knowledge Extrac-\ntion and Integration for Deep Learning Architectures,\npages 100‚Äì114, Dublin, Ireland and Online. Associa-\ntion for Computational Linguistics.\nYao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,\nand Pontus Stenetorp. 2022. Fantastically ordered\nprompts and where to find them: Overcoming few-\nshot prompt order sensitivity. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n8086‚Äì8098, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nYi Luan, Luheng He, Mari Ostendorf, and Hannaneh\nHajishirzi. 2018. Multi-task identification of entities,\nrelations, and coreference for scientific knowledge\ngraph construction. In Proceedings of the 2018 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3219‚Äì3232, Brussels, Belgium.\nAssociation for Computational Linguistics.\nNikolay Malkin, Zhen Wang, and Nebojsa Jojic. 2022.\nCoherence boosting: When your pretrained language\nmodel is not paying enough attention. InProceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 8214‚Äì8236, Dublin, Ireland. Association for\nComputational Linguistics.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022a. Rethinking the role of demonstrations:\nWhat makes in-context learning work?\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022b. Rethinking the role of demonstra-\ntions: What makes in-context learning work? CoRR,\nabs/2202.12837.\nEthan Perez, Douwe Kiela, and Kyunghyun Cho. 2021.\nTrue few-shot learning with language models. In Ad-\nvances in Neural Information Processing Systems 34:\nAnnual Conference on Neural Information Process-\ning Systems 2021, NeurIPS 2021, December 6-14,\n2021, virtual, pages 11054‚Äì11070.\nJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, Eliza Rutherford, Tom Hennigan, Ja-\ncob Menick, Albin Cassirer, Richard Powell, George\nvan den Driessche, Lisa Anne Hendricks, Mari-\nbeth Rauh, Po-Sen Huang, Amelia Glaese, Jo-\nhannes Welbl, Sumanth Dathathri, Saffron Huang,\nJonathan Uesato, John Mellor, Irina Higgins, Anto-\nnia Creswell, Nat McAleese, Amy Wu, Erich Elsen,\nSiddhant Jayakumar, Elena Buchatskaya, David Bud-\nden, Esme Sutherland, Karen Simonyan, Michela Pa-\nganini, Laurent Sifre, Lena Martens, Xiang Lorraine\nLi, Adhiguna Kuncoro, Aida Nematzadeh, Elena\nGribovskaya, Domenic Donato, Angeliki Lazaridou,\nArthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-\npoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-\ntiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,\nDaniel Toyama, Cyprien de Masson d‚ÄôAutume, Yujia\n3543\nLi, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,\nAidan Clark, Diego de Las Casas, Aurelia Guy,\nChris Jones, James Bradbury, Matthew Johnson,\nBlake Hechtman, Laura Weidinger, Iason Gabriel,\nWilliam Isaac, Ed Lockhart, Simon Osindero, Laura\nRimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub,\nJeff Stanway, Lorrayne Bennett, Demis Hassabis, Ko-\nray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling\nlanguage models: Methods, analysis &amp; insights\nfrom training gopher.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3982‚Äì3992, Hong Kong, China. Association for Com-\nputational Linguistics.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\n2022. Learning to retrieve prompts for in-context\nlearning. In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 2655‚Äì2671, Seattle, United States.\nAssociation for Computational Linguistics.\nRichard Shin, Christopher Lin, Sam Thomson, Charles\nChen, Subhro Roy, Emmanouil Antonios Platanios,\nAdam Pauls, Dan Klein, Jason Eisner, and Benjamin\nVan Durme. 2021. Constrained language models\nyield few-shot semantic parsers. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natu-\nral Language Processing, pages 7699‚Äì7715, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall,\nNoam Shazeer, Apoorv Kulshreshtha, Heng-Tze\nCheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,\nYaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,\nAmin Ghafouri, Marcelo Menegali, Yanping Huang,\nMaxim Krikun, Dmitry Lepikhin, James Qin, Dehao\nChen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,\nMaarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-\nChing Chang, Igor Krivokon, Will Rusch, Marc\nPickett, Pranesh Srinivasan, Laichee Man, Kathleen\nMeier-Hellstern, Meredith Ringel Morris, Tulsee\nDoshi, Renelito Delos Santos, Toju Duke, Johnny So-\nraker, Ben Zevenbergen, Vinodkumar Prabhakaran,\nMark Diaz, Ben Hutchinson, Kristen Olson, Ale-\njandra Molina, Erin Hoffman-John, Josh Lee, Lora\nAroyo, Ravi Rajakumar, Alena Butryna, Matthew\nLamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-\nhen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-\nArcas, Claire Cui, Marian Croak, Ed Chi, and Quoc\nLe. 2022. Lamda: Language models for dialog appli-\ncations.\nZhen Wan, Qianying Liu, Zhuoyuan Mao, Fei Cheng,\nSadao Kurohashi, and Jiwei Li. 2022. Rescue im-\nplicit and long-tail cases: Nearest neighbor relation\nextraction. CoRR, abs/2210.11800.\nChenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong,\nJie Tang, and Dawn Song. 2022a. DeepStruct: Pre-\ntraining of language models for structure prediction.\nIn Findings of the Association for Computational Lin-\nguistics: ACL 2022, pages 803‚Äì823, Dublin, Ireland.\nAssociation for Computational Linguistics.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V .\nLe, Ed H. Chi, and Denny Zhou. 2022b. Self-\nconsistency improves chain of thought reasoning in\nlanguage models. CoRR, abs/2203.11171.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. CoRR, abs/2201.11903.\nAdina Williams, Nikita Nangia, and Samuel Bowman.\n2018. A broad-coverage challenge corpus for sen-\ntence understanding through inference. In Proceed-\nings of the 2018 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume\n1 (Long Papers), pages 1112‚Äì1122, New Orleans,\nLouisiana. Association for Computational Linguis-\ntics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38‚Äì45, Online. Association\nfor Computational Linguistics.\nYuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli,\nand Christopher D. Manning. 2017. Position-aware\nattention and supervised data improve slot filling.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n35‚Äì45, Copenhagen, Denmark. Association for Com-\nputational Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate before use: Improv-\ning few-shot performance of language models. In\nProceedings of the 38th International Conference on\nMachine Learning, ICML 2021, 18-24 July 2021, Vir-\ntual Event, volume 139 of Proceedings of Machine\nLearning Research, pages 12697‚Äì12706. PMLR.\nZexuan Zhong and Danqi Chen. 2021. A frustratingly\neasy approach for entity and relation extraction. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies,\n3544\npages 50‚Äì61, Online. Association for Computational\nLinguistics.\nLiu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun. 2021. A\nrobustly optimized BERT pre-training approach with\npost-training. In Proceedings of the 20th Chinese\nNational Conference on Computational Linguistics,\npages 1218‚Äì1227, Huhhot, China. Chinese Informa-\ntion Processing Society of China.\n3545\nHyperparameter In Experiment\nEngine text-davinci-003\nTemperature 0.0\nMax_tokens 256\nTop_p 1\nFrequency_penalty 0.0\nPresence_penalty 0.0\nBest_of 1\nLogprob 1\nTable 3: GPT-3 Hyperparamters.\nDataset Lower bound Upper bound\nSemeval 5 30\nTACRED 5 15\nSciERC 5 30\nACE05 5 25\nTable 4: Search range for each dataset.\nA Hyperparameters\nA.1 GPT-3 Hyperparameters\nWe use the GPT-3 API during the experiments and\nset the hyperparameters as in Table 3. Since the\n‚ÄúTemperature‚Äù is set to be 0.0, denoting the stable\noutput of GPT-3, we report the result of the single\nrun for all experiments. Due to the input length lim-\nitation of GPT-3 and the various average lengths of\ncontexts from each dataset, we set different search\nranges for the number of demonstrations of each\ndataset as shown in Table 4.\nA.2 Fine-tuning Baseline PURE\nWe follow their single-sentence setup to keep con-\nsistency among datasets as Semeval and TACRED\nare both sentence-level RE datasets. For the PLMs,\nwe also follow PURE by using scibert-scivocab-\nuncased (Beltagy et al., 2019) as the base en-\ncoder for SciERC and bert-base-uncased (Devlin\net al., 2019) for the remaining three general domain\ndatasets. We follow hyperparameters in their paper.\nWe used 2 NVIDIA RTX3090 for training.\nA.3 Sentence Embedding Methods\nGuti√©rrez et al. (2022) uses the [CLS] of RoBERTa-\nlarge as the representation in retrieval, Liu et al.\n(2022b) fine-tunes RoBERTa-large on two natural\nlanguage inference (NLI) datasets: SNLI (Bow-\nman et al., 2015) and MultiNLI (Williams et al.,\n2018) to enhance the quality of sentence embed-\nding. For the sentence embedding method Sim-\nCSE in our experiment, we utilize the version:\nsup-simcse-bert-base-uncased.\nContext: this paper describes a setof principlesdesigned to help archives position themselves to address the management ......Given the context, the relation between principlesand setis MEMBER AND COLLECTION.\nGPT-Sent Demonstration\nContext: basic diagrams also work well on the computerscreenif they are carefully designed to match the grid of pixels on the screen. Given the context, the relation between screenand computer is[COMPONENT AND WHOLE]\nTest Input\nContext: thescreen works using ink, just like books and newspapers , but displays the ink particles electronically .Given the context, the relation betweenink and screenis COMPONENT AND WHOLE.\nGPT-RE_SimCSE Demonstration\nContext: the computer mousehas been the input device of choice for a long time now in the computer world .Given the context, the relation between mouse and computeris COMPONENT AND WHOLE.\nGPT-RE_FT Demonstration\nRetrievalGPT-SentGPT-RE_SimCSEGPT-RE_FTGPT-3 OutputMEMBER AND COLLECTIONCOMPONENT AND WHOLECOMPONENT AND WHOLE\n(a) [COMPONENT AND WHOLE] denotes the gold label\nContext: a woman diagnosed with breast cancer today joins a huge sisterhoodof cancer survivorsready to help her along the way ‚Ä¶‚Ä¶Given the context, the relation between survivorsand sisterhoodis MEMBER AND COLLECTION.\nGPT-Sent Demonstration\nContext: the wheelchair foundation donated wheelchairsto peoplewith physical problems in hundred countries .Given the context, the relation between wheelchairsand peopleis [ENTITY AND DESTINATION].\nTest Input\nContext: the victim of last night 's car accident donated his organsto several patientswho have been waiting for donated organs .Given the context, the relation between organsand patientsis ENTITY AND DESTINATION.\nGPT-RE_SimCSE Demonstration\nContext: operation homefrontand partners delivered toysto military children.Given the context, the relation between toysand childrenis ENTITY AND DESTINATION.\nGPT-RE_FT Demonstration\nRetrievalGPT-SentGPT-RE_SimCSEGPT-RE_FTGPT-3 OutputMEMBER AND COLLECTIONENTITY AND DESTINATIONENTITY AND DESTINATION\n(b) [ENTITY AND DESTINATION] denotes the gold label.\nFigure 10: More casees.\n3546\nLabel # Num\nPHYS 28\nGEN-AFF 12\nPER-SOC 11\nGEN-AFF 33\nPART-WHOLE 13\nART 19\nNULL 2329\nTable 5: ACE05\nB Case Study\nTo verify the effectiveness of our task-aware\ndemonstration retrieval, we provide more cases.\nFor Figure 10a, GPT-Sent retrieves a demonstra-\ntion that shares the same semantic meaning of ‚Äúde-\nsign‚Äù with the test input. However, the entity pair\nis irrelevant to the concept ‚Äúdesign‚Äù resulting in a\nnoisy demonstration. Instead, GPT-RE_SimCSE\nretrieves a more relative demonstration with closer\npair of entities sharing the same relation label. Fur-\nthermore, GPT-RE_FT retrieves the demonstration\ncontaining both the closing entity pair and the same\nlinguistic structure between entities. This case em-\nphasizes level-by-level improvement using our pro-\nposed methods. Figure 10b shows a similar phe-\nnomenon.\nC Subset\nThe number of sampled examples is not only re-\nlated to the size of the training data itself. A more\nimportant factor is the proportion of NULL . We\nhave to maintain the original label distribution in\ndatasets with a high proportion of NULL . Thus, the\nrule to sample the subset is to keep the proportion\nof each relation label consistent with the original\ntest set. Table 5 6 are label distributions of two\nsubsets.\nGPT-RE_FT on TACRED surpasses the super-\nvised baseline in the current subset. As we show\nabove, some labels in TACRED are indeed not well\npresented (only 1 example), since TACRED dataset\ncontains some long-tail labels. We decided to add\nadditional results of GPT-RE_FT by enlarging our\nsampled set to # 3200 (2 times the current version),\nand the performance of GPT-RE_FT (k = 15) is\n73.16 while the performance of PURE is 70.48.\nLabel # Num\nPer:title 40\nPER:city_of_death 1\nOrg:shareholders 2\nPer:origin 12\nOrg:top_members/employees 36\nOrg:city_of_headquarters 11\nPer:religion 4\nPer:city_of_birth 1\nPer:employee_of 27\nPer:data_of_death 3\nPer:other_family 5\nOrg:website 6\nPer:cause_of_death 3\nOrg:subsidiaries 4\nOrg:stateorprovince_of_headquarters 5\nPer:countries_of_residence 10\nPer:siblings 5\nPer:stateorprovinces_of_residence 11\nOrg:alternate_names 27\nPer:spouse 4\nPer:parents 7\nOrg:country_of_headquarters 9\nPer:age 21\nPer:date_of_birth 1\nPer:country_of_death 1\nPer:schools_attended 4\nOrg:member_of 3\nPer:children 5\nOrg:parents 7\nPer:cities_of_residence 24\nPer:stateorprovince_of_brith 1\nPer:charges 12\nOrg:founded 2\nOrg:country_founded_by 5\nPer:stateorprovince_of_death 1\nOrg:members 4\nPer:country_of_birth 1\nPer:alternate_names 1\nOrg:number_of_employees/members 1\nOrg:dissolved 1\nOrg:political/religious_affiliation 1\nNULL 1271\nTable 6: TACRED\n3547",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7916654348373413
    },
    {
      "name": "Context (archaeology)",
      "score": 0.6920957565307617
    },
    {
      "name": "Relevance (law)",
      "score": 0.6427850723266602
    },
    {
      "name": "Relation (database)",
      "score": 0.6413166522979736
    },
    {
      "name": "Sentence",
      "score": 0.6319328546524048
    },
    {
      "name": "Task (project management)",
      "score": 0.6268228888511658
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5920867323875427
    },
    {
      "name": "Relationship extraction",
      "score": 0.5698956251144409
    },
    {
      "name": "Natural language processing",
      "score": 0.5305255651473999
    },
    {
      "name": "SemEval",
      "score": 0.49431824684143066
    },
    {
      "name": "Machine learning",
      "score": 0.44998571276664734
    },
    {
      "name": "Language model",
      "score": 0.4115147590637207
    },
    {
      "name": "Data mining",
      "score": 0.2248104214668274
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I22299242",
      "name": "Kyoto University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I76130692",
      "name": "Zhejiang University",
      "country": "CN"
    }
  ],
  "cited_by": 110
}