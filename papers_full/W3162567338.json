{
  "title": "Investigating Math Word Problems using Pretrained Multilingual Language Models",
  "url": "https://openalex.org/W3162567338",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4221545357",
      "name": "Tan, Minghuan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1947704774",
      "name": "Wang Lei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2348649521",
      "name": "Jiang, Lingxiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107264555",
      "name": "Jiang Jing",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2251349042",
    "https://openalex.org/W2963545046",
    "https://openalex.org/W2786059879",
    "https://openalex.org/W2061466269",
    "https://openalex.org/W3034835156",
    "https://openalex.org/W2561975193",
    "https://openalex.org/W2951939640",
    "https://openalex.org/W2251935656",
    "https://openalex.org/W2970854433",
    "https://openalex.org/W2105717194",
    "https://openalex.org/W2250769864",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W2964165364",
    "https://openalex.org/W3035497479",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2962800603",
    "https://openalex.org/W1505640990",
    "https://openalex.org/W2073036035",
    "https://openalex.org/W2475046758",
    "https://openalex.org/W1655078475",
    "https://openalex.org/W1539746312",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2963510263",
    "https://openalex.org/W3102315106",
    "https://openalex.org/W2513499049",
    "https://openalex.org/W2252202991",
    "https://openalex.org/W2971291256",
    "https://openalex.org/W2757276219",
    "https://openalex.org/W2891555348",
    "https://openalex.org/W2964710271"
  ],
  "abstract": "In this paper, we revisit math word problems~(MWPs) from the cross-lingual and multilingual perspective. We construct our MWP solvers over pretrained multilingual language models using sequence-to-sequence model with copy mechanism. We compare how the MWP solvers perform in cross-lingual and multilingual scenarios. To facilitate the comparison of cross-lingual performance, we first adapt the large-scale English dataset MathQA as a counterpart of the Chinese dataset Math23K. Then we extend several English datasets to bilingual datasets through machine translation plus human annotation. Our experiments show that the MWP solvers may not be transferred to a different language even if the target expressions have the same operator set and constants. But for both cross-lingual and multilingual cases, it can be better generalized if problem types exist on both source language and target language.",
  "full_text": "Investigating Math Word Problems using Pretrained Multilingual\nLanguage Models\nMinghuan Tan and Lei Wang and Lingxiao Jiang and Jing Jiang\nSchool of Computing and Information Systems\nSingapore Management University\n{mhtan.2017,lei.wang.2019}@phdcs.smu.edu.sg,{lxjiang,jingjiang}@smu.edu.sg\nAbstract\nIn this paper, we revisit math word prob-\nlems (MWPs) from the cross-lingual and\nmultilingual perspective. We construct our\nMWP solvers over pretrained multilingual lan-\nguage models using the sequence-to-sequence\nmodel with copy mechanism. We com-\npare how the MWP solvers perform in cross-\nlingual and multilingual scenarios. To facil-\nitate the comparison of cross-lingual perfor-\nmance, we ﬁrst adapt the large-scale English\ndataset MathQA as a counterpart of the Chi-\nnese dataset Math23K. Then we extend several\nEnglish datasets to bilingual datasets through\nmachine translation plus human annotation.\nOur experiments show that the MWP solvers\nmay not be transferred to a different language\neven if the target expressions share the same\nnumerical constants and operator set. How-\never, it can be better generalized if problem\ntypes exist on both source language and target\nlanguage.\n1 Introduction\nHow to use machine learning and NLP techniques\nto solve Math Word Problems (MWPs) has at-\ntracted much attention in recent years (Hosseini\net al., 2014; Kushman et al., 2014; Roy et al., 2015;\nLing et al., 2017; Wang et al., 2017a, 2018; Amini\net al., 2019). Given a math problem expressed in\nhuman language, a MWP solver typically ﬁrst con-\nverts the input sequence of words to an expression\ntree consisting of math operators and numerical\nvalues, and then invokes an executor (such as the\neval function in Python) to execute the expression\ntree to obtain the ﬁnal numerical answer. Figure 1\nshows an example math word problem, the correct\nexpression tree, and the ﬁnal answer.\nDespite the relatively simple syntax of these\nexpression trees, building MWP solvers is not a\ntrivial task, and researchers have proposed vari-\nous methods to tackle the different challenges of\nthis problem such as statistical methods (Kushman\nProblem: A chef needs to cook 9 potatoes. He has \nalready cooked 7. If each potato takes 3 minutes to \ncook,  how long will it take him to cook the rest?\nMult\nSub 3\n9 7\nExpression: (9 - 7) * 3\nExpression Tree: \nAnswer: 6\nFigure 1: Example of an MWP and its expression tree.\net al., 2014; Roy et al., 2015), parsing-based meth-\nods (Shi et al., 2015) and generation-based meth-\nods (Wang et al., 2018; Xie and Sun, 2019). How-\never, an aspect that has been largely overlooked is\ncross-lingual and multilingual MWP solving, i.e.,\nwhether a MWP solver trained on one human lan-\nguage can still work on another human language,\nor whether a MWP solver trained on multiple hu-\nman languages together is more effective than a\nsolver trained on only one language. We believe\nthis is an interesting aspect to study for the fol-\nlowing reasons. First, in cognitive science, people\nhave long studied the relationship between humans’\nnumerical processing abilities and language abili-\nties, and found that on the one hand, the two are\nlargely independent (Xu and Spelke, 2000), but on\nthe other hand, “acquiring and mastering symbolic\nrepresentations of exact quantities critically de-\npends on language and instruction\" (Van Rinsveld\net al., 2015). It is therefore also intriguing to study\nwhether machines separately acquire arithmetic\nand language abilities. Second, with pre-trained\nlarge-scale multilingual language models such as\nmBERT (Devlin et al., 2019) and XLM-R (Con-\nneau et al., 2020), which presumably project differ-\nent human languages into a common embedding\nspace, we have seen some success in cross-lingual\nNLP tasks such as XNLI (Conneau et al., 2018) and\narXiv:2105.08928v3  [cs.CL]  13 Nov 2022\nMLQA (Lewis et al., 2020) in both zero-shot and\nfew-shot settings (Wu and Dredze, 2019; Conneau\net al., 2020). It is therefore reasonable to expect\nthat for MWP solving, there is the possibility of\ntransferring machine’s capability of MWP solving\nfrom one language to another by leveraging these\npre-trained multilingual language models.\nIn this paper, we conduct an empirical study to\nunderstand to what extent MWP solvers can work\nin cross-lingual and multilingual settings. Specif-\nically, we ask the following questions: (1) Cross-\nlingual setting: Given a model trained with mono-\nlingual dataset, can the model solve MWPs over\nanother language? (2) Multilingual setting: Can\ncombining datasets of different languages further\nboost the performance for each language? (3) Can\nwe identify some critical factors that may affect the\nresults in (1) and (2)?\nIn order to empirically answer the questions\nabove, we need multilingual MWP datasets, which\nare limited currently. We ﬁrst use large scale\ndatasets like Math23K (Wang et al., 2017b) and\nMathQA (Amini et al., 2019) as monolingual\nMWPs resource and further adapt MathQA to have\nthe same operator set and expression style with\nMath23K. To better evaluate the models with paral-\nlel corpus, we extend some existing MWP datasets\nby translating them from English into Chinese. We\nthen conduct three sets of experiments on the con-\nstructed datasets. We ﬁnd that: (1) a cross-lingual\nMWP solver ﬁnetuned on one language cannot\nwork on a second language, even if they are sharing\nthe same decoding vocabulary, (2) a multilingual\nMWP solver may not boost performance for all the\ntraining languages but can improve those problems\nof similar types if one training language is close\nto the evaluation language, (3) combining (1) (2),\nwe think for multilingual MWP solvers, despite\nlanguage similarity, the performance relies heavily\non domain similarity (problem types).\nOur work makes the following contributions: (1)\nTo the best of our knowledge, we are the ﬁrst to\nstudy cross-lingual and multilingual MWP solv-\ning, and we empirically demonstrate that cross-\nlingual MWP solving is still difﬁcult, but multi-\nlingual MWP solving is to some extent effective.\n(2) We discover that multilingual MWP solving is\nmostly effective for questions with similar prob-\nlem types. (3) Our constructed datasets can help\nother researchers to further study cross-lingual and\nmultilingual MWP solving.\n2 Related work\nSolving Math Word Problems (MWPs) has been\nattracting researchers since the emergence of arti-\nﬁcial intelligence. STUDENT(Bobrow, 1964) is a\nrule-based math word problem solver which con-\ntains a pipeline that consists of heuristics for pattern\ntransformation. Many researchers start with the\nfundamental problem types like addition and sub-\ntraction (Hosseini et al., 2014) or those that have\nonly one single operator (Roy et al., 2015). Roy and\nRoth (2015) look at problems that require multi-\nsteps using two or more operators. The question\ntypes of MWPs are also expanding. Rather than\nfocusing on problems that need only one variable,\nKushman et al. (2014) propose a dataset ALG514\nwhich includes problems with a system of equa-\ntions. With the development of deep learning,\nthere has been a demand for large-scale datasets\nwith more variations. Dolphin18K (Huang et al.,\n2016) is a large-scale dataset that is more than 9\ntimes of the size of previous ones, and contains\nmany more problem types. Math23K (Wang et al.,\n2017a) contains math word problems for elemen-\ntary school students in Chinese language and is\ncrawled from multiple online education websites.\nMathQA (Amini et al., 2019) is a new large-scale,\ndiverse dataset of 37k multiple-choice math word\nproblems in English and each problem is annotated\nwith an executable formula using a new operation-\nbased representation language. HMWP (Qin et al.,\n2020) contains three types of MWPs: arithmetic\nword problems, equations set problems, and non-\nlinear equation problems.\nVarious approaches have been proposed to solve\nMWPs. Template-based approaches (Kushman\net al., 2014; Zhou et al., 2015; Upadhyay et al.,\n2016; Huang et al., 2017) are widely adopted as\nnumbers appeared in the expressions are usually\nsparse in the representation space and the expres-\nsions may fall into the same category. More re-\ncently, the community is also paying more atten-\ntion to train a math solver by ﬁne-tuning pretrained\nlanguage models. For example, EPT (Kim et al.,\n2020) adopts ALBERT (Lan et al., 2020) as the\nencoder for its sequence-to-sequence module.\nThe monolingual performance gains achieved re-\ncently have not been evaluated from cross-lingual\nand cross-domain perspectives. Therefore, we de-\ncide to revisit MWPs using current SOTA pre-\ntrained multilingual language models to construct\na competitive math solver and conduct experiments\nover various bilingual evaluations.\n3 Preliminaries\n3.1 The MWP Solver Task\nWe ﬁrst formally deﬁne the task of building MWP\nsolvers. Given a math word problem with nwords\nW = (w1,w2,...,w n), and k numerical values\nN = (n0,n1,...,n k), the model needs to gener-\nate a ﬂattened tree representation using operators\nfrom permitted operator set Oand numerical val-\nues from constants Cand N. The generated tree\nshould be able to be evaluated via some compiler\nand executor to return a numerical value.\n3.2 Solution Framework\nA MWP solver needs to generate executable code\nfor a target programming language to be evaluated\nby an executor compiled for the programming lan-\nguage.\nOur MWP solver is built upon a sequence-to-\nsequence model with copy mechanism (Gu et al.,\n2016). Speciﬁcally, we use a pretrained multilin-\ngual model as the encoder to get contextualized\nrepresentations of math word problems. Due to the\nword piece tokenizer, the encoded context is not\nwell-aligned to original input words. We choose to\nmap these word pieces back to input words through\nmean pooling. Then we pass the mean pooled word\nrepresentations to a bidirectional LSTM. Finally,\nwe use a LSTM decoder with copy mechanism,\nwhich takes in the last decoded word vector and in-\ntermediate reading states, to predict the next token\none by one. When the decoding ﬁnishes, we are\nexpecting to get a linear tree representation. We\nattach the full model details in Section A.\nGiven the decoded tree representation, we ﬁrst\nconvert the generated linear tree representation into\na piece of python expression with basic operators\n(+,-,*,/,**), then use the built-in function eval in\nPython to execute the generated code.\n3.3 Existing Datasets\nWe use two large-scale datasets for this cross-\nlingual research. One is Math23K (Wang et al.,\n2017a) in Chinese and the other is MathQA (Amini\net al., 2019) in English. Although the two datasets\nare similar in size and question types, there are still\ndifferences in terms with permitted operators and\nannotations.\nDataset Problem Types Size\nAddSub (Hosseini et al., 2014) Add 395\nSub\nSingleOp (Roy et al., 2015) Add 562\nSub\nMult\nDiv\nMultiArith (Roy and Roth, 2015) (Add, Sub) 600\n(Sub, Add)\n(Add, Mult)\n(Add, Div)\n(Sub, Mult)\n(Sub, Div)\nTable 1: Datasets which are focusing on speciﬁc prob-\nlem types.\nMath23K The dataset Math23K (Wang et al.,\n2017a) contains math word problems for elemen-\ntary school students in Chinese (zh) and is crawled\nfrom multiple online education websites. The\ndataset focuses on arithmetic problems with a\nsingle-variable and contains 23,161 problems la-\nbeled with structured equations and answers.\nMathQA The dataset is a new large-scale, di-\nverse dataset of 37k multiple-choice math word\nproblems in English (en). Each question is an-\nnotated with an executable formula using a new\noperation-based representation language (Amini\net al., 2019). It covers multiple math domain cate-\ngories. To make MathQA a comparable counterpart\nwith Math23K, we choose to ﬁlter those solvable\nproblems with shared permitted operators from\nMathQA to create an adapted MathQA dataset.\nOther datasets focusing on speciﬁc problem\ntypes These datasets are smaller in size but more\nfocused on speciﬁc problem types. We follow the\ndataset naming conventions from MAWPS (Koncel-\nKedziorski et al., 2016).\nSpeciﬁcally, AddSub (Hosseini et al., 2014) cov-\ners arithmetic word problems on addition and sub-\ntraction for third, fourth, and ﬁfth graders. Its prob-\nlem types include combinations of additions, sub-\ntractions, one unknown equation, and U.S. money\nword problems. SingleOp (Roy et al., 2015) is a\ndataset with elementary math word problems of\nsingle operation. MultiArith (Roy and Roth, 2015)\nincludes problems with multiple steps which we\nlisted all the seven types in Table 1. These datasets\nare all in English (en). We will illustrate how we\nextend them into bilingual datasets in Section 4.2.\n4 Cross-lingual and Multilingual MWP\nSolvers\nIn this work, as we are focusing on the cross-lingual\nand multilingual properties of MWPs, we need to\ntrain separate MWP solvers using different datasets.\nOur cross-lingual MWP solver will be trained us-\ning one language but evaluated using another. Our\nmultilingual MWP solver can be trained on all\nlanguages available and evaluated separately. To\nsufﬁce these goals, it would be better if the prob-\nlems in different languages have comparable prop-\nerties. Since we are using pretrained multilingual\nlanguage models as the sequence embedder of the\nencoder, all the languages can be projected into\na shared representation. However, the candidate\ndatasets also need to share a common operator set\nand numerical constants to make the decoding pro-\ncess consistent. But some of the categories from\nMathQA do not exist on Math23K or one of the\noperators is not in our permitted set. Therefore, we\nneed to adapt MathQA as a counterpart of Math23K\nsharing the same decoding vocabulary, including\noperators and constants.\n4.1 Adaptation of MathQA\nWe adapt MathQA by doing the following:\n1) We notice that the annotated formulas in\nMathQA are function calls of predeﬁned func-\ntions which can be converted into a tree using an\nabstract syntax tree (AST) parser.\n2) To be consistent with Math23K, which cov-\ners only basic arithmetic operators like addi-\ntion (Add), subtraction (Sub), division (Div),\nmultiplication (Mult) and exponentiation (Pow),\nwe keep only functions in MathQA that can\nbe expressed in such operators. For example,\nvolume_sphere(r) from MathQA equalizes to\n4\n3 πr3 and is adapted using the method shown\nin Figure 2. Formulas containing operators not\nused in Math23K, like sine and permutation, are\nnot considered in this work. A full list of adapted\noperators can be found in Table 6 of Appendix A.\n3) Upon constructing the trees using permitted op-\nerators, we evaluate each sample to verify its cor-\nrectness against its ground-truth answer. Those\ncases that fail to get the correct answer are not\nconsidered in this work.\nAfter the adaptation, we get the adapted MathQA\ndataset of solvable problems with comparable sizes\nand question types to Math23K. For Math23K, we\nfurther sample a development set of size 1000 from\ndivide\nvolume_sphere\nsubtract\nadd\nvolume_sphere\nconst_2\n4 0.5\n4\nDiv\nMult\nSub\nAdd\n2\n4 0.5\nPow Mult\n3 Div const_pi\n4 3\nMult\n4\nPow Mult\n3 Div const_pi\n4 3\nAST parsing\nAdaptation\n MathQA: divide(subtract(volume_sphere(add(4, \n0.5)), volume_sphere(4)), const_2)\n Tree: (Div (Sub (Mult (Pow (Add 4 0.5) 3) (Mult \n(Div 4 3) const_pi)) (Mult (Pow 4 3) (Mult (Div 4 3) \nconst_pi))) 2)\nFigure 2: Adaptation of MathQA to Math23K. The part\nhighlighted with dashed lines shows the adaptation of\nthe function volume_sphere.\nMath23K MathQA\nw/o Pow w/ Pow w/o Pow w/ Pow\nTrain 21,107 21,161 15,302 16,645\nDev 995 1,000 2,263 2,479\nTest 999 1,000 1,532 1,653\nTable 2: Statistics of different splits for Math23K and\nthe adapted MathQA.\nits training set. Considering the operator Pow has\nonly several training and evaluating instances on\nMath23K, we separate them with others to make a\nfairer adaptation of MathQA to Math23K. We show\nthe statistics of both Math23K and the adapted\nMathQA in Table 2. In this work, all the exper-\niments will be conducted on the dataset marked\nwith w/o Pow.\n4.2 Zero-shot Cross-lingual Evaluation\nDatasets\nTo test cross-lingual transferability of MWP\nsolvers, we make use of problem-type-speciﬁc\ndatasets discussed in Section 3.3 as evaluation\nDataset AddSub SingleOp MultiArith\nProblem Types addition, subtraction single operation multi-step\nEn Keith has 20 books . Ja-\nson has 21 books . How\nmany books do they have\ntogether ?\nLisa ﬂew 256 miles at 32\nmiles per hour. How long\ndid Lisa ﬂy?\nA chef needs to cook 9 potatoes. He has\nalready cooked 7. If each potato takes\n3 minutes to cook, how long will it take\nhim to cook the rest?\nZh 基思有20本书。杰森\n有21本书。他们总共有\n多少本书？\n丽莎以每小时32英里的\n速度飞行了256英里。\n丽莎飞了多长时间？\n厨师需要煮9个土豆。他已经煮\n了7个了。如果每个土豆煮3分钟，\n剩下的他要煮多久？\nSize 395 562 600\nTable 3: Examples from each dataset used for zero-shot cross-lingual evaluation.\ndatasets, including AddSub (Hosseini et al., 2014),\nSingleOp (Roy et al., 2015) and MultiArith (Roy\nand Roth, 2015). To extend these datasets for cross-\nlingual evaluation, we use online machine transla-\ntion APIs to translate them into Chinese and further\nmanually reﬁne the translations to be more native.\nFor each dataset, we list an example in Table 3, in\nboth English (En) and Chinese (Zh).\n5 Template-based Contrastive Training\nMath word problems can be categorized by ex-\npression templates if we replace numerical values\nof expressions with a special token. Such tem-\nplates have been adopted for supervision in other\nmath solver approaches like (Wang et al., 2018) and\n(Xie and Sun, 2019). Different from these meth-\nods, we don’t use templates directly for supervision\nbut make an assumption that problems sharing the\nsame template are closer with each other from the\npoint view of arithmetics, regardless of the surface\nforms of languages and descriptions.\nTo make use of this assumption, we introduce\ninter-language template-based contrastive training\ninto our training process. Speciﬁcally, we ﬁrst\ngroup math word problems based on their tem-\nplates. During training, we pair each problem with\na random sample from a different language sharing\nthe same template.\nAs the representation learned by the encoder\nin Section A is M, we use its maxpooling with\nnormalization as the latent representation for each\nproblem and its positive sample, denoted as z and\nz+ respectively. Then, we conduct a batch-level\ncontrastive training similar to SimCLR (Chen et al.,\n2020) and use the NT-Xent loss (the normalized\ntemperature-scaled cross entropy loss) as the fol-\nlowing:\nL= −log exp(⟨z,z+⟩/τ)\nexp(⟨z,z+⟩/τ⟩+ ∑N−1\nj=1 exp(⟨z,z−\nj ⟩/τ)\n,\n(1)\nwhere ⟨·,·⟩is the inner product of the two vectors\nand the batch size is N.\nIt’s worth noting that the distribution of tem-\nplates is highly skewed. In our experiments, we\nfurther consider two settings: (1) CL, contrastive\nlearning, when a problem doesn’t have a candidate\nwith the same template from another language, it\ncontrasts with itself. (2) CL + TC , contrastive\nlearning with template constraint, we only use\nthose problems which have at least one sample\nfrom another language.\nOur contrastive learning approach differs with\nthat of Li et al. (2022) in the following ways: (1)\nour method is focusing on cross-lingual setting that\neach pair of examples come from different lan-\nguages, (2) we use batch-level contrastive training\nin consist with SimCLR.\nThere are also other works making use of latent\nrepresentations of math word problems to enhance\ngeneralization ability of math solvers. For example,\nLiang and Zhang (2021) designed a teacher mod-\nule to make the latent vector to match the correct\nsolution rather than its variations.\n6 Experiments\n6.1 Experiment Setup\nEvaluation metrics: The model is expected to\nbe a math problem solver, so the generated expres-\nsions should be executable by a speciﬁc compiler\nand executor. During evaluation, each problem is\ncounted as solved if the absolute error rate for the\nexecuted value and the target value is lower than\na predeﬁned threshold. In our experiments, we\nchoose 1e−4 as the threshold. The ﬁnal evaluation\nModel\nTest Zero-shot\nMath23K MathQA AddSub SingleOp MultiArith\nzh en zh en zh en zh en\nmBERT-zh 76.5 3.3 30.9 10.4 66.0 32.7 51.2 15.7\nmBERT-en 0.5 77.9 2.8 6.1 5.0 10.5 5.0 3.2\nXLM-R-xl 75.5 79.0 39.0 21.3 67.4 40.4 44.7 18.3\nmBERT-xl 76.3 79.0 35.2 24.1 69.8 41.6 45.0 16.0\nTable 4: Comparisons of different cross-lingual models over Test set and zero-shot datasets.\nmetric is the accuracy of solved problem against\nall the problems.\nMethods to be compared: We empirically com-\npare the following cross-lingual: (1) mBERT-zh\nis using original multilingual BERT (Devlin et al.,\n2019) but trained over Math23K only; (2)mBERT-\nen is using original multilingual BERT (Devlin\net al., 2019) but trained over the adapted MathQA\nonly, and multilingual methods: (1) mBERT-xlis\nusing original multilingual BERT (Devlin et al.,\n2019) but trained by mixing Math23K and the\nadapted MathQA; (2) XLM-R-xl is using XLM-\nR (Conneau et al., 2020) but trained by mixing\nMath23K and the adapted MathQA.\nOther experiment settings: We choose to use\nmulti-lingual BERT (mBERT) (Devlin et al., 2019)\nfor cross-lingual training. We train our models\nusing one Nvidia 2080ti and a batch size of 160.\nThe learning rate is set to 3e−5 with a scheduler\nsupporting polynomial decay. The training lasts for\nat most 150 epochs and will stop after 30 epochs if\nno improvement is observed.1\n6.2 Results\nWe list experiment results of all the methods in\nTable 4.\nCross-lingual MWP Solver The ﬁrst research\nquestion we want to answer is to what extent\na MWP solver trained on one language can\nwork on another language, with the help of pre-\ntrained multilingual language models. Table 4\nshows that the MWP solvers trained using either\nMath23K ( mBERT-zh) or MathQA (mBERT-en)\nhave achieved impressive performance when tested\nin the same language. However, the performance\nover a different language drops drastically and is\n1https://github.com/VisualJoyce/\nAnDuShu\nalmost negligible. In a word, the MWP solver is\nalmost non-transferable when it is trained on one\nlanguage but evaluated over a second with the same\noperator set.\nMultilingual MWP Solver The second research\nquestion we want to answer is whether training a\nMWP solver on multiple languages helps improve\nits effectiveness compared with training on a single\nlanguage. We can see that mixing two languages to\ntrain can give us a more language-agnostic model\nas the performance on Test split of both languages\nare competitive with monolingual cases. What’s\nmore, on the newly extended bilingual datasets,\nthere are consistent improvements for most of the\ndatasets, especially for the English language.\nConsidering the difﬁculty of problems, these\nbilingual evaluation datasets are closer to\nMath23K (primary school) than to MathQA (GRE\nor GMAT). Adding that mBERT-zh is also doing\nbetter than mBERT-en on English language, we\nsuspect domain similarity is more important than\nlanguage for MWP solvers.\nTemplate-based Contrastive Training The last\nsection of Table 5 shows how contrastive learning\naffects performance. Firstly, adding contrastive\nlearning can further boost performance on the test\nset of both languages. There’s a signiﬁcant in-\ncrease (3 points) for Math23K. However, in zero-\nshot evaluation settings, performance over English\ndrops consistently. We suspect this might be caused\nby the diversity of templates on MathQA is much\nlarger than that of Math23K.\nTherefore, we further conduct a template-\nconstrained experiment that ensures each template\ncan be found on both languages. Due to the number\nof training cases are reduced, performance of the\ntest sets also drop by a large margin. However, En-\nglish problems over zero-shot setting beneﬁt most\nfrom this experiment, which further veriﬁes that\nModel\nTest Zero-shot\nMath23K MathQA AddSub SingleOp MultiArith\nzh en zh en zh en zh en\nmBERT-xl 76.3 79.0 35.2 24.1 69.8 41.6 45.0 16.0\nmBERT-xl + CL 79.4 79.4 39.5 19.2 62.6 29.9 46.2 10.8\nmBERT-xl + CL + TC 72.4 49.5 44.8 19.2 67.4 44.5 45.5 17.3\nTable 5: Performance of template-based contrastive training models over Test set and zero-shot datasets.\nmath word problems depend closely on the prob-\nlem types of the training set.\n7 Conclusion\nIn this paper, we revisit the math word problems\nusing a generation-based method constructed over\npretrained multilingual models. To assist analy-\nsis of cross-lingual properties of math solvers, we\nadopt two large-scale monolingual datasets and\nfurther adapts MathQA into the same annotation\nframework with Math23K. We also reuse earlier\nsmaller datasets and upgrade them into bilingual\ndatasets by machine translation and manual check-\ning. Our experiments show that the MWP solvers\nmay not be transferred to a different language even\nif the target expressions have the same operator\nset and constants. But for both cross-lingual and\nmultilingual cases, it can be better generalized if\nproblem types exist on both source language and\ntarget language. Problems considered to be easy by\nhumans may still be hard for a math solver trained\nover the same language but from a different domain.\nThis tells us that for math word problem solvers,\nit might be beneﬁcial to consider balancing differ-\nent question types and permitted operators during\ntraining.\nReferences\nAida Amini, Saadia Gabriel, Shanchuan Lin, Rik\nKoncel-Kedziorski, Yejin Choi, and Hannaneh Ha-\njishirzi. 2019. MathQA: Towards interpretable\nmath word problem solving with operation-based\nformalisms. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 2357–2367, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nDaniel G. Bobrow. 1964. Natural language input for a\ncomputer problem solving system. Technical report,\nUSA.\nTing Chen, Simon Kornblith, Mohammad Norouzi,\nand Geoffrey Hinton. 2020. A simple framework\nfor contrastive learning of visual representations. In\nProceedings of the 37th International Conference\non Machine Learning , volume 119 of Proceedings\nof Machine Learning Research , pages 1597–1607.\nPMLR.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nAlexis Conneau, Ruty Rinott, Guillaume Lample, Ad-\nina Williams, Samuel Bowman, Holger Schwenk,\nand Veselin Stoyanov. 2018. XNLI: Evaluating\ncross-lingual sentence representations. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 2475–2485,\nBrussels, Belgium. Association for Computational\nLinguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nJiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K.\nLi. 2016. Incorporating copying mechanism in\nsequence-to-sequence learning. In Proceedings of\nthe 54th Annual Meeting of the Association for Com-\nputational Linguistics (Volume 1: Long Papers) ,\npages 1631–1640, Berlin, Germany. Association for\nComputational Linguistics.\nMohammad Javad Hosseini, Hannaneh Hajishirzi,\nOren Etzioni, and Nate Kushman. 2014. Learning\nto solve arithmetic word problems with verb catego-\nrization. In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 523–533, Doha, Qatar. Association\nfor Computational Linguistics.\nDanqing Huang, Shuming Shi, Chin-Yew Lin, and Jian\nYin. 2017. Learning ﬁne-grained expressions to\nsolve math word problems. In Proceedings of the\n2017 Conference on Empirical Methods in Natural\nLanguage Processing, pages 805–814, Copenhagen,\nDenmark. Association for Computational Linguis-\ntics.\nDanqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin,\nand Wei-Ying Ma. 2016. How well do comput-\ners solve math word problems? large-scale dataset\nconstruction and evaluation. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n887–896, Berlin, Germany. Association for Compu-\ntational Linguistics.\nBugeun Kim, Kyung Seo Ki, Donggeon Lee, and Gah-\ngene Gweon. 2020. Point to the Expression: Solv-\ning Algebraic Word Problems using the Expression-\nPointer Transformer Model. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 3768–3779,\nOnline. Association for Computational Linguistics.\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini,\nNate Kushman, and Hannaneh Hajishirzi. 2016.\nMAWPS: A math word problem repository. In Pro-\nceedings of the 2016 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n1152–1157, San Diego, California. Association for\nComputational Linguistics.\nNate Kushman, Yoav Artzi, Luke Zettlemoyer, and\nRegina Barzilay. 2014. Learning to automatically\nsolve algebra word problems. In Proceedings of\nthe 52nd Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 271–281, Baltimore, Maryland. Association\nfor Computational Linguistics.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. ALBERT: A lite BERT for self-supervised\nlearning of language representations. In Interna-\ntional Conference on Learning Representations.\nPatrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian\nRiedel, and Holger Schwenk. 2020. MLQA: Evalu-\nating cross-lingual extractive question answering. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 7315–\n7330, Online. Association for Computational Lin-\nguistics.\nZhongli Li, Wenxuan Zhang, Chao Yan, Qingyu Zhou,\nChao Li, Hongzhi Liu, and Yunbo Cao. 2022. Seek-\ning patterns, not just memorizing procedures: Con-\ntrastive learning for solving math word problems. In\nFindings of the Association for Computational Lin-\nguistics: ACL 2022 , pages 2486–2496, Dublin, Ire-\nland. Association for Computational Linguistics.\nZhenwen Liang and Xiangliang Zhang. 2021. Solving\nmath word problems with teacher supervision. In\nIJCAI, pages 3522–3528.\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-\nsom. 2017. Program induction by rationale genera-\ntion: Learning to solve and explain algebraic word\nproblems. In Proceedings of the 55th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 158–167, Vancou-\nver, Canada. Association for Computational Linguis-\ntics.\nJinghui Qin, Lihui Lin, Xiaodan Liang, Rumin Zhang,\nand Liang Lin. 2020. Semantically-aligned univer-\nsal tree-structured solver for math word problems.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 3780–3789, Online. Association for Computa-\ntional Linguistics.\nSubhro Roy and Dan Roth. 2015. Solving general arith-\nmetic word problems. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1743–1752, Lisbon, Portu-\ngal. Association for Computational Linguistics.\nSubhro Roy, Tim Vieira, and Dan Roth. 2015. Reason-\ning about quantities in natural language. Transac-\ntions of the Association for Computational Linguis-\ntics, 3:1–13.\nShuming Shi, Yuehui Wang, Chin-Yew Lin, Xiaojiang\nLiu, and Yong Rui. 2015. Automatically solving\nnumber word problems by semantic parsing and rea-\nsoning. In Proceedings of the 2015 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1132–1142, Lisbon, Portugal. Association for\nComputational Linguistics.\nShyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang,\nand Wen-tau Yih. 2016. Learning from explicit and\nimplicit supervision jointly for algebra word prob-\nlems. In Proceedings of the 2016 Conference on\nEmpirical Methods in Natural Language Processing,\npages 297–306, Austin, Texas. Association for Com-\nputational Linguistics.\nAmandine Van Rinsveld, Martin Brunner, Karin Lan-\nderl, Christine Schiltz, and Sonja Ugen. 2015. The\nrelation between language and arithmetic in bilin-\nguals: insights from different stages of language ac-\nquisition. Frontiers in psychology, 6:265.\nLei Wang, Yan Wang, Deng Cai, Dongxiang Zhang,\nand Xiaojiang Liu. 2018. Translating a math word\nproblem to a expression tree. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 1064–1069, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nMingxuan Wang, Zhengdong Lu, Jie Zhou, and Qun\nLiu. 2017a. Deep neural machine translation with\nlinear associative unit. In Proceedings of the 55th\nAnnual Meeting of the Association for Computa-\ntional Linguistics (Volume 1: Long Papers) , pages\n136–145, Vancouver, Canada. Association for Com-\nputational Linguistics.\nYan Wang, Xiaojiang Liu, and Shuming Shi. 2017b.\nDeep neural solver for math word problems. In Pro-\nceedings of the 2017 Conference on Empirical Meth-\nods in Natural Language Processing , pages 845–\n854.\nShijie Wu and Mark Dredze. 2019. Beto, bentz, be-\ncas: The surprising cross-lingual effectiveness of\nBERT. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n833–844, Hong Kong, China. Association for Com-\nputational Linguistics.\nZhipeng Xie and Shichao Sun. 2019. A goal-driven\ntree-structured neural model for math word prob-\nlems. In Proceedings of the Twenty-Eighth In-\nternational Joint Conference on Artiﬁcial Intelli-\ngence, IJCAI-19 , pages 5299–5305. International\nJoint Conferences on Artiﬁcial Intelligence Organi-\nzation.\nFei Xu and Elizabeth S Spelke. 2000. Large number\ndiscrimination in 6-month-old infants. Cognition,\n74(1):B1–B11.\nLipu Zhou, Shuaixiang Dai, and Liwei Chen. 2015.\nLearn to solve algebra word problems using\nquadratic programming. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 817–822, Lisbon, Portugal.\nAssociation for Computational Linguistics.\nA Method\nIn this section, we construct a generation-based\nMWP solver using a sequence-to-sequence model\nwith copy mechanism. Our whole model can be vi-\nsualized in modules through Figure 3. The detailed\nillustration for each module is given as following:\nEncoder Our encoder is built upon a pretrained\nmultilingual transformer, either BERT or XLM-\nR. Suppose our input word wi is tokenized into\nword pieces (xi1,xi2,... ) and let hij ∈Rdh de-\nnotes the hidden vector produced by the pretrained\nmodel representing xij. We use average pooling\nto get the representation for the word wi, denoted\nas hi. Then we feed this contextualized represen-\ntation of the math word problem into a two-layer\nbidirectional LSTM. The output of this biLSTM is\nthe encoder hidden states for decoding, denoted as\nM = (m0,m1,..., mn).\nDecoder We use a LSTM cell as the decoding\ncell to predict the next token. For each decoding\nstep t, the cell will accept the embedding for pre-\nvious word as input and output a decoder state\nst ∈Rds. Most of the numerical values in MWPs\ndo not exist in the target vocabulary. Therefore, we\nneed copy mechanism (Gu et al., 2016) to facilitate\ngeneration of numerical values during decoding.\nThe copy scores are calculated as follows,\nut\ni = σ(m⊺\ni Wc)st (2)\nwhere Wc ∈Rdh×ds. However, the embedding\nof a copied token will be identical to an out-of-\nvocabulary token. To better capture the information\nfrom last decoding step, we use the copy score\nto further derive a state of selecting from source\ntokens, which is called Selective Read.\nqt = softmax(ut) (3)\nbt =\n∑\ni\nqt\ni mi (4)\nWe use a bilinear attention to attentively read\ninformation from M, getting the context vector ct,\nwhich is called Attentive Read.\nvt\ni = σ(m⊺\ni Wast + b) (5)\ndt = softmax(vt) (6)\nct =\n∑\ni\ndt\nimi (7)\nwhere Wa ∈Rdh×ds.\nFrom the problem deﬁnition, the target vocabu-\nlary is V= O∪C . The generation score for the\nnext token is given by:\npt = W⊺\ndst + b (8)\nwhere Wd ∈Rds×|V|.\nThe state updating process for the decoding cell\ntakes in a fused information of last word embed-\nding et ∈Rde, selective read state bt and attentive\nread state ct.\nst+1 = f(Ws[et,bt,ct],st) (9)\nwhere Ws ∈Rds×(de+dh+dh).\n[SEP][CLS] Lisa\nBERT\nh3,0 h3,1 hSEPhCLS h1,0\n256 ##0\n2560\n...\nLisa\nflew\nflew\nmiles\nmiles\nh2,0 h4,0\n  \n@start@\n(\n(\nMult\nMult\n2560\n... @oov@\nSelective Read\nAttentive Read\n...\nM\nts\ntb \ntc\nte\nt+1 s\ntq\ntp\nFigure 3: Sequence-to-sequence model with copy mechanism.\nAdapted Operators Filtered Operators\nadd,subtract,multiply,\nrectangle_area,divide,\nspeed,power,negate,inverse,\nsquare_area,sqrt,\nsquare_edge_by_area,\ncube_edge_by_volume,\nvolume_cube,surface_cube,\nsquare_perimeter,\nrectangle_perimeter,\nstream_speed,triangle_area,\ntriangle_perimeter,surface_sphere,\nvolume_sphere,rhombus_area,\nquadrilateral_area,volume_cylinder,\ncircle_area,volume_cone,circumface,\ndiagonal,volume_rectangular_prism,\noriginal_price_before_loss,\noriginal_price_before_gain,\np_after_gain,\nsquare_edge_by_perimeter,negate_prob\nfloor,choose,min,tangent,sine,\nreminder,lcm,factorial,gcd,max,\npermutation,\ntriangle_area_three_edges,\nsurface_cylinder,rhombus_perimeter,\nsurface_rectangular_prism,\nspeed_in_still_water,log\nTable 6: Operators that are adapted in MathQA.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8008079528808594
    },
    {
      "name": "Machine translation",
      "score": 0.6684578657150269
    },
    {
      "name": "Word (group theory)",
      "score": 0.6549910306930542
    },
    {
      "name": "Natural language processing",
      "score": 0.6489022970199585
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5939768552780151
    },
    {
      "name": "Annotation",
      "score": 0.5807424187660217
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.5705002546310425
    },
    {
      "name": "Sequence (biology)",
      "score": 0.5365901589393616
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.5241898894309998
    },
    {
      "name": "Construct (python library)",
      "score": 0.5063496828079224
    },
    {
      "name": "Translation (biology)",
      "score": 0.49791693687438965
    },
    {
      "name": "Operator (biology)",
      "score": 0.47085708379745483
    },
    {
      "name": "Scheme (mathematics)",
      "score": 0.4702284038066864
    },
    {
      "name": "Language model",
      "score": 0.45574119687080383
    },
    {
      "name": "Linguistics",
      "score": 0.1939285397529602
    },
    {
      "name": "Mathematics",
      "score": 0.15142416954040527
    },
    {
      "name": "Programming language",
      "score": 0.11980047821998596
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Repressor",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Messenger RNA",
      "score": 0.0
    },
    {
      "name": "Transcription factor",
      "score": 0.0
    }
  ]
}