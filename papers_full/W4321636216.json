{
  "title": "Predicting Generalized Anxiety Disorder From Impromptu Speech Transcripts Using Context-Aware Transformer-Based Neural Networks: Model Evaluation Study",
  "url": "https://openalex.org/W4321636216",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5067115403",
      "name": "Bazen Gashaw Teferra",
      "affiliations": [
        "University of Toronto"
      ]
    },
    {
      "id": "https://openalex.org/A5090184149",
      "name": "Jonathan Rose",
      "affiliations": [
        "Centre for Addiction and Mental Health",
        "University of Toronto"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2067001184",
    "https://openalex.org/W2050378943",
    "https://openalex.org/W2104126098",
    "https://openalex.org/W2100772444",
    "https://openalex.org/W122399454",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W3121900947",
    "https://openalex.org/W2163670407",
    "https://openalex.org/W1979232396",
    "https://openalex.org/W2793244201",
    "https://openalex.org/W4223942700",
    "https://openalex.org/W2941393987",
    "https://openalex.org/W2911546748",
    "https://openalex.org/W4281381605",
    "https://openalex.org/W4307764818",
    "https://openalex.org/W2296681920",
    "https://openalex.org/W3121601851",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2779206865",
    "https://openalex.org/W2043705607",
    "https://openalex.org/W2144961120",
    "https://openalex.org/W2041325469",
    "https://openalex.org/W2037064842",
    "https://openalex.org/W2077880694",
    "https://openalex.org/W3049188596",
    "https://openalex.org/W3195898203",
    "https://openalex.org/W2002993000",
    "https://openalex.org/W2021030166",
    "https://openalex.org/W1579838312",
    "https://openalex.org/W4285718091",
    "https://openalex.org/W2618561563",
    "https://openalex.org/W2615649472"
  ],
  "abstract": "Background The ability to automatically detect anxiety disorders from speech could be useful as a screening tool for an anxiety disorder. Prior studies have shown that individual words in textual transcripts of speech have an association with anxiety severity. Transformer-based neural networks are models that have been recently shown to have powerful predictive capabilities based on the context of more than one input word. Transformers detect linguistic patterns and can be separately trained to make specific predictions based on these patterns. Objective This study aimed to determine whether a transformer-based language model can be used to screen for generalized anxiety disorder from impromptu speech transcripts. Methods A total of 2000 participants provided an impromptu speech sample in response to a modified version of the Trier Social Stress Test (TSST). They also completed the Generalized Anxiety Disorder 7-item (GAD-7) scale. A transformer-based neural network model (pretrained on large textual corpora) was fine-tuned on the speech transcripts and the GAD-7 to predict whether a participant was above or below a screening threshold of the GAD-7. We reported the area under the receiver operating characteristic curve (AUROC) on the test data and compared the results with a baseline logistic regression model using the Linguistic Inquiry and Word Count (LIWC) features as input. Using the integrated gradient method to determine specific words that strongly affect the predictions, we inferred specific linguistic patterns that influence the predictions. Results The baseline LIWC-based logistic regression model had an AUROC value of 0.58. The fine-tuned transformer model achieved an AUROC value of 0.64. Specific words that were often implicated in the predictions were also dependent on the context. For example, the first-person singular pronoun “I” influenced toward an anxious prediction 88% of the time and a nonanxious prediction 12% of the time, depending on the context. Silent pauses in speech, also often implicated in predictions, influenced toward an anxious prediction 20% of the time and a nonanxious prediction 80% of the time. Conclusions There is evidence that a transformer-based neural network model has increased predictive power compared with the single word–based LIWC model. We also showed that the use of specific words in a specific context—a linguistic pattern—is part of the reason for the better prediction. This suggests that such transformer-based models could play a useful role in anxiety screening systems.",
  "full_text": "Original Paper\nPredicting Generalized Anxiety Disorder From Impromptu Speech\nTranscripts Using Context-Aware Transformer-Based Neural\nNetworks: Model Evaluation Study\nBazen Gashaw Teferra1, PhD; Jonathan Rose1,2, PhD\n1The Edward S Rogers Sr Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada\n2The Centre for Addiction and Mental Health, Toronto, ON, Canada\nCorresponding Author:\nBazen Gashaw Teferra, PhD\nThe Edward S Rogers Sr Department of Electrical and Computer Engineering\nUniversity of Toronto\n10 King’s College Road\nToronto, ON, M5S3G4\nCanada\nPhone: 1 4169786992\nEmail: bazen.teferra@mail.utoronto.ca\nAbstract\nBackground: The ability to automatically detect anxiety disorders from speech could be useful as a screening tool for an anxiety\ndisorder. Prior studies have shown that individual words in textual transcripts of speech have an association with anxiety severity.\nTransformer-based neural networks are models that have been recently shown to have powerful predictive capabilities based on\nthe context of more than one input word. Transformers detect linguistic patterns and can be separately trained to make specific\npredictions based on these patterns.\nObjective: This study aimed to determine whether a transformer-based language model can be used to screen for generalized\nanxiety disorder from impromptu speech transcripts.\nMethods: A total of 2000 participants provided an impromptu speech sample in response to a modified version of the Trier\nSocial Stress Test (TSST). They also completed the Generalized Anxiety Disorder 7-item (GAD-7) scale. A transformer-based\nneural network model (pretrained on large textual corpora) was fine-tuned on the speech transcripts and the GAD-7 to predict\nwhether a participant was above or below a screening threshold of the GAD-7. We reported the area under the receiver operating\ncharacteristic curve (AUROC) on the test data and compared the results with a baseline logistic regression model using the\nLinguistic Inquiry and Word Count (LIWC) features as input. Using the integrated gradient method to determine specific words\nthat strongly affect the predictions, we inferred specific linguistic patterns that influence the predictions.\nResults: The baseline LIWC-based logistic regression model had an AUROC value of 0.58. The fine-tuned transformer model\nachieved an AUROC value of 0.64. Specific words that were often implicated in the predictions were also dependent on the\ncontext. For example, the first-person singular pronoun “I” influenced toward an anxious prediction 88% of the time and a\nnonanxious prediction 12% of the time, depending on the context. Silent pauses in speech, also often implicated in predictions,\ninfluenced toward an anxious prediction 20% of the time and a nonanxious prediction 80% of the time.\nConclusions: There is evidence that a transformer-based neural network model has increased predictive power compared with\nthe single word–based LIWC model. We also showed that the use of specific words in a specific context—a linguistic pattern—is\npart of the reason for the better prediction. This suggests that such transformer-based models could play a useful role in anxiety\nscreening systems.\n(JMIR Ment Health 2023;10:e44325) doi: 10.2196/44325\nKEYWORDS\nmental health; generalized anxiety disorder; impromptu speech; linguistic features; anxiety prediction; neural networks; natural\nlanguage processing; transformer models; mobile phone\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 1https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nIntroduction\nBackground\nThe screening, diagnosis, and tracking of mental health disorders\nrequire frequent interactions with psychiatrists or psychologists.\nHowever, the high cost [1] and low availability of mental health\nprofessionals make frequent interactions difficult [2]. This\nshortage could be addressed, in part, if there is an ability to\nassess a mental health disorder automatically through a passive\nand frequent collection of patient data. One possible way to do\nsuch monitoring may be through speech, as the presence of a\nmental health disorder has been shown to be associated with\nchanges in human speech [3,4].\nIn this study, we focused on anxiety disorders, specifically on\ngeneralized anxiety disorder (GAD) [5]. Anxiety disorders are\ncharacterized by an excessive and uncontrollable fear of what\nis to come and are among the most common mental health\nissues, with an incidence of approximately 10% in the Canadian\npopulation [6]. It may be possible to reach a much greater\nproportion of the population using methods that automate some\naspects of the measurement and diagnosis of anxiety disorders,\nsuch as the detection of anxiety from speech.\nThe current gold standard diagnosis for GAD requires multiple\nsessions with a mental health professional where the professional\ncompares the different symptoms exhibited by the patient with\nthe Diagnostic and Statistical Manual of Mental Disorders, Fifth\nEdition diagnostic criteria for GAD [7]. One place to look for\nsymptoms is in the linguistic patterns used by the patient as the\nchoice of words by anxious individuals tends to be different\nfrom that of nonanxious individuals [4]. The goal of this study\nwas to determine the accuracy of a method for the automatic\ndetection of anxiety from the transcript of impromptu speech.\nWe were motivated to pursue this goal, in part, because it should\nbe possible to frequently collect speech-to-text (STT) transcripts\nusing smartphones or other wearable devices and, therefore, to\nenable a system for monitoring symptoms during or after\ntreatment.\nIn recent years, transformer-based [8-12] neural network models\n[13] have been shown to have a strong capability to predict from\nlanguage, including tasks such as next-word prediction, machine\ntranslation, and sequence classification. In this study, we\nleveraged this capability to predict whether a participant is above\nor below the screening threshold for GAD.\nThis paper is organized as follows: the Prior Work subsection\nsummarizes related work in anxiety prediction from language\nand provides a brief overview of transformer language models.\nThe Methods section describes the speech sample collection\nmethods and the construction, training, and evaluation of the\nprediction model. The Results section presents the prediction\nmodel’s performance, whereas the Discussion section discusses\nspecific patterns that were influential in the prediction.\nPrior Work\nPrevious Work on the Automatic Prediction of Anxiety\nFrom Speech\nSeveral prior studies have explored the automatic prediction of\nanxiety from speech. These studies have used both the acoustic\nproperties as well as the linguistic features of speech and have\nshown some ability to detect anxiety. Most prior studies have\nfocused on the acoustic structure of speech, that is, the nature\nof the audio signal itself. Comparatively less work has been\ndone on the linguistic aspects of speech, the focus of this paper,\nwhich we describe in the subsequent paragraphs.\nDi Matteo et al [14] explored the relationship between passively\ncollected audio data and anxiety and depression. A total of 84\nparticipants installed an Android app on their smartphone for\n2 weeks. During this period, the app passively collected\nintermittent samples of audio data from the participants’\nsmartphones. The audio was then converted to text, and the\nLinguistic Inquiry and Word Count (LIWC) [15] was used to\nclassify the words into 67 different categories. The correlation\nbetween the LIWC scores and self-report measures was\ncalculated for social anxiety disorder (SAD), GAD, depression,\nand functional impairment. A significant correlation was\nobserved between words related to the perceptual process (“See”\nin the LIWC) and SAD (r=0.31; P=.003). In addition, words\nrelated to reward were significantly correlated with GAD\n(r=−0.29; P=.007).\nAnderson et al [16] recruited 42 participants diagnosed with\nSAD and 27 healthy controls to explore the differences in the\nwords used between these 2 groups using the LIWC features.\nAn anxiety-stimulating task was performed in which the\nparticipants were asked to write about an autobiographical and\nsocially painful memory, which required them to recall a social\nhumiliation, embarrassment, or shame. The word count in each\nof the LIWC categories was generated, including first-person\nsingular pronouns, anxiety-related words, and fear-related words.\nThe patients with SAD used more first-person singular pronouns\n(I, me, and mine), anxiety-related words, sensory or perceptual\nwords, and words denoting physical touch but made fewer\nreferences to other people than the healthy controls.\nHofmann et al [17] examined the association between linguistic\nfeatures and SAD. They recruited 24 participants diagnosed\nwith SAD and 21 healthy controls. The participants were asked\nto provide a speech on any topic of their choice for a total of 4\nminutes in front of an experimenter while being video recorded.\nTo induce stress and anxiety in the participants, they were told\nthat a panel of judges would rate their speech after it was\nrecorded on the basis of poise, social confidence, and general\npresentation skills. The speech was transcribed, and LIWC was\nused to extract the count of the words in the following\ncategories: first-person pronouns, negative emotion words, and\npositive emotion words. The results showed that the patients\nwith SAD used more positive emotion words than the healthy\ncontrols. The authors did not observe any significant difference\nfor the other explored LIWC categories.\nSonnenschein et al [18] explored the transcripts from passively\nrecorded therapy sessions of 85 patients. These patients were\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 2https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\ncategorized into 3 groups: those diagnosed with anxiety but not\ndepression, those diagnosed with depression but not anxiety,\nand those diagnosed with both anxiety and depression. From\nthe transcripts, the LIWC score was generated in 4 categories:\nfirst-person singular, sad, anxiety, and filler. The group with\ndepression but not anxiety showed a higher use of sad words\nthan the group with anxiety but not depression. The group with\nanxiety but not depression showed a higher use of\nanxiety-related words than the group with depression but not\nanxiety. The both anxious and depressed group also showed a\nhigher use of “sad” words than the group with anxiety but not\ndepression. None of the other LIWC categories explored showed\na significant difference.\nRook et al [19] attempted to predict GAD from linguistic\npatterns because they believed that the worrying behavior in\nGAD comes from the verbal linguistic process. A total of 142\nundergraduate participants (n=56, 39.4% men and n=86, 60.6%\nwomen) were recruited for their study and were asked to recall\nand write about an anxious experience during their university\nlife. The Generalized Anxiety Disorder 7-item (GAD-7) scale\nscore and behavioral inhibition/behavioral approach system\n(BIS/BAS) scale score were used as the label for each of the\nparticipants. The LIWC features [15] were extracted from the\ntexts written by the participants. Another set of features was\nalso used by combining the LIWC features with the BIS/BAS\nscores. Several machine learning models were explored,\nincluding support vector machine (SVM) with linear kernel,\nlogistic regression, naive Bayes, and random forest. Their results\nshowed that all models built using the LIWC features performed\nsignificantly better than a random model (average\nprecision~0.61; average recall~0.6) and achieved a higher\nperformance (except for the SVM model) when the LIWC\nfeatures were used together with the BIS/BAS scores as input\nfeatures (average precision~0.65; average recall~0.64).\nGruda and Hasan [20] explored the prediction of anxiety from\nmicroblogs such as tweets using machine learning approaches.\nThe authors started by labeling 600 tweets on a 4-point anxiety\nlevel using the short version of the traditional full-scale\nState-Trait Anxiety Inventory [21]. Then, a machine learning\nmodel was trained using features extracted from the textual\ncontent. The features used include a semantic embedding vector,\nwhich is the mean of multiple word vectors that map words to\na vector. They also used the count of specific words and emojis\nas another type of features. They achieved an R2 of 0.49 between\nthe human label and the predicted label after training a Bayesian\nridge regression [22] model. The authors then compared their\nmodel with a model that classifies a tweet as anxious or not\nbased on the presence of anxiety-type words and negative\nemotion–type words, which was acquired using the LIWC\nlibrary. The method that used the LIWC features to classify\nbetween anxious and nonanxious tweets achieved an R2 of 0.21,\nindicating the importance of the meaning of words represented\nby word vectors.\nA precursor study to this work [23] identified both acoustic\nfeatures and linguistic features using LIWC that significantly\ncorrelated with the GAD-7. Using these features, in another\nstudy [24], a logistic regression model was trained to predict\nwhether a participant was above or below the screening\nthreshold for GAD based on the GAD-7. Using both the acoustic\nand linguistic features, we achieved a mean area under the\nreceiver operating characteristic curve (AUROC) of 0.59.\nNote that this previous study [24] and the other prior work,\ndescribed in the previous paragraphs, explored the count of\nsingle words (using the LIWC) to find an association with\nanxiety or to predict anxiety. However, there are some studies\nthat found specific word categories to be associated with anxiety,\nwhereas others found no such association. For example, the\nstudies by both Di Matteo et al [14] and Anderson et al [16]\nfound that the word categories for “perceptual process” were\nassociated with anxiety, whereas no other prior studies did so.\nSimilarly, the first-person singular pronoun category was\nassociated with anxiety only in the studies by Anderson et al\n[16] and Teferra et al [23] and nowhere else. These\ninconsistencies may be explained if the context for the specific\nwords is taken into account—or, in other words, if the evaluation\nmodel is context aware. In this study, we hypothesized that there\nis a greater predictive power in examining the larger context of\nmultiple words than in examining single words using LIWC.\nThe former can be done using recent advances in natural\nlanguage processing (NLP) [8], which has new powerful\nmethods of converting language into numerical quantities that\nrepresent meaning and learning features that are patterns of\nthose meanings.\nFurthermore, note that the largest sample size among the\npreviously explored studies (excluding our own [23,24]) was\n142. This limits the potential for generalizability to a larger\npopulation. In this study, we used a much larger data set based\non speech samples from a total of 2000 people.\nTransformers and NLP\nOver the last 5 years, substantial advances have been made in\nthe field of NLP [25]. A key advance was the invention of\nlimited-size word vectors or embeddings, through which it has\nbeen shown that a small-sized (from 50 to 300) vector of real\nnumbers was capable of representing the meaning of individual\nwords or parts of words [26-28]. Note that sometimes, words\nare divided into subparts and then converted into tokens, which\ncan represent either a full or a partial word. These word or token\nvectors make it possible to determine whether 2 words have\nsimilar meaning through a numerical comparison, as well as\nother encapsulations of meaning through calculation. This\ninvention also permitted the use of neural networks to process\nlanguage in a far more effective way and has led to major\nadvances in the subfields of speech recognition, natural language\nunderstanding, question answering, and language generation\n[26,29].\nAnother important step that has dramatically improved the state\nof the art in these fields is the advent of the transformer-based\nneural network models [8,10-12,30]. These so-called large\nlanguage models are trained using massive corpora of text, often\nobtained from the internet. More specifically, the “learning” (in\nthe machine learning sense [31]) is done by either predicting\nthe next word in sequence or predicting intentionally missing\nwords. The architecture of a transformer-style neural network\nhas 2 important properties. First, it “transforms” a sequence of\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 3https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nwords or parts of words, represented as vectors, into another\nsequence of vectors. The output vectors account for additional\nmeaning inferred from the full sequence of words and thus create\na sequence of so-called contextual embeddings that better\nencapsulate the meaning of the full input sequence. Second, it\nmakes use of an important neural network mechanism known\nas “attention” [8,32]. In this, a part of the network learns several\ndifferent ways in which parts of a sentence or paragraph are\nrelated to other parts of the sentence. For example, a certain\nword or meaning may typically be connected with specific other\nwords in a sentence. A transformer learns many such\nrelationships, which makes it capable of classifying the broader\nmeaning of a sentence or paragraph. It is this capability that we\nleverage in this study to look for patterns of language that\nindicate the presence of anxiety.\nThere now exist many such large language models that have\nalready been fully “pretrained” on massive corpora of text\ngathered from a number of sources on the internet and elsewhere\n[10,12,30]. A common use case in the field of deep learning\nand NLP is to take such pretrained models and “fine-tune” them\nfor a specific prediction task that takes language as input. To\n“fine-tune” a model means to train it on a (typically much\nsmaller) data set to learn the task at hand. The task described\nin the subsequent section is the classification of participants\ninto anxious or nonanxious categories.\nMethods\nData Collection\nRecruitment and Demographics\nWe note that this study used the same participants and data as\n2 earlier studies [23,24]. This study performed a novel analysis\nof these data using a transformer-based neural network.\nThe participants were recruited using Prolific [33], a web-based\nhuman participant recruitment platform. The inclusion criteria\nwere an age range of 18 to 65 years; fluency in English; English\nas a first language; and the completion of at least 10 previous\nstudies on Prolific, with 95% of these previous Prolific tasks\ncompleted satisfactorily (as labeled by the study author). The\ndata set was also balanced for sex (n=1000, 50% female and\nn=1000, 50% male).\nThe participants who completed the study were paid £2\n(approximately CAD $3.41 and US $2.74) for approximately\n15 minutes of work. They completed the entire study remotely\nusing their PCs.\nEthics Approval\nThis study was approved by the University of Toronto Research\nEthics Board (protocol #37584).\nStudy Procedure\nThe participants were recruited for a 10- to 15-minute task\nimplemented through a custom website. An earlier study that\ndetermined the correlates of anxiety [23] described the data\ncollection procedure in detail. The parts of the data collection\nprocedure that are relevant for the purpose of this study are\npresented in the following paragraphs.\nOn the Prolific platform, the participants who met the inclusion\ncriteria were presented with the opportunity to participate in\nthis study. Those who wished to participate clicked on the study\nlink, which brought them to a consent form that described the\nprocedure and goals of the study and provided information on\ndata privacy. If a participant granted consent, a hyperlink\nbrought them to an external web application that implemented\nthe tasks described subsequently.\nThe participants were asked to fill out the standard GAD-7\nquestionnaire [34], which is described in more detail in the\nAnxiety Measures section. Then, they were asked to perform a\nspeech task, which was both audio and video recorded using\ntheir computer’s microphone and camera. The speech task\nfollowed a modified version of the widely used Trier Social\nStress Test (TSST) [35], which aims to evoke a moderate\namount of stress from each participant. Prior studies [36,37]\nhave shown a higher activation in participants with relatively\nhigher anxiety after they experienced moderate stress induced\nby the TSST.\nIn the modified version of the TSST, the participants were told\nto imagine that they were a job applicant invited for an interview\nwith a hiring manager. They were told to imagine that it was a\njob that they really wanted—their so-called dream job. They\nwere given a few minutes to prepare—to choose their dream\njob—and to think about how they would convince an interviewer\nthat they were the right person for that position. The participants\nwere also told that the recorded video would be viewed by\nresearchers studying their behavior and language. The\nparticipants were then asked to speak for 5 minutes, making the\ncase for themselves to be hired for that dream job.\nNote that, in the original TSST [35], participants would normally\ndeliver their speech in front of a live panel of judges. If a\nparticipant finished their delivery in <5 minutes, the judges in\nthe original TSST design would encourage the participant to\nkeep speaking for the full 5 minutes. For example, in the original\nTSST, to encourage the participants, they were asked the\nfollowing question: “What are your personal strengths?” In the\nmodified TSST, we implemented a similar method to encourage\nthe participants to speak for the full 5 minutes: when our system\ndetects silence (defined as the absence of speech for >6 seconds),\nit will display several different prompts inviting the participants\nto keep speaking on different topics relating to the task. Finally,\nnote that the modified TSST only included the first task of the\noriginal TSST, not the second task, which involves the\nperformance of mental arithmetic.\nAnxiety Measures\nOur goal was to predict, based on the transcript of the language\nspoken, whether a participant was above or below the screening\nthreshold for GAD based on the GAD-7 scale. The GAD-7 [34]\nscale is a 7-item questionnaire that asks participants how often\nthey were bothered by anxiety-related problems during the\nprevious 2 weeks. Although the 2-week period suggests that\nthe GAD-7 measures a temporary condition, a GAD diagnosis\nrequires a 6-month duration of symptoms [7,38]. However, the\nGAD-7 has been validated as a diagnostic tool for GAD using\na value of 10 as the cutoff threshold, with a sensitivity of 89%\nand a specificity of 82% [34]. Thus, we chose to use the GAD-7\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 4https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nthreshold of 10 to obtain a binary label of GAD as our indicator\nof anxiety.\nEach of the 7 questions on the GAD-7 has 4 options for the\nparticipant to select from, indicating how often they have been\n“bothered” by the 7 problems listed. These options and their\nnumerical ratings are 0=not at all, 1=several days, 2=more than\nhalf the days, and 3=nearly every day. The final GAD-7 score\nis a summation of the values for all the questions, giving a\nseverity measure for GAD in the range from 0 (no anxiety\nsymptoms) to 21 (severe anxiety symptoms).\nConstruction and Evaluation of the Baseline\nClassification Model\nIn this section, the inputs, structure, and evaluation of a baseline\nmodel are described. The inputs to this model were the linguistic\nfeatures acquired using LIWC [15]. LIWC is based on the count\nof words from a given transcript that fall into different preset\ncategories. An example category is “negemo,” which comprises\nwords (such as hurt, ugly, and nasty) that are associated with\nnegative emotion. The full set of categories in LIWC can be\nfound in the study by Pennebaker et al [15].\nThe transcript was generated from the speech samples using\nAmazon Web Services STT system (Amazon.com, Inc)\n[39]—the transcription accuracy on a written text had an average\nword error rate (WER) of 7% (SD 4.6%). In our earlier study\n[23], we identified LIWC features that had a significant (P<.05)\ncorrelation with the GAD-7. These features are listed in Table\n1. These were the features that were used as the input to the\nbaseline prediction model.\nA logistic regression model was trained to make predictions\nbetween the anxious and nonanxious classes. The construction\nand evaluation steps were as follows. First, the input features\nwere normalized so that each feature would have a mean of 0\nand an SD of 1. Next, the data were undersampled to equalize\nrepresentation from both the anxious and nonanxious classes.\nThis avoids the problem of class imbalance, which, if it occurs,\ncauses low predictive accuracy for the minority class (which is\nthe anxious class in our case). To undersample the data, samples\nwere randomly selected and removed from the majority class\nuntil the majority class had an equal number of samples as the\nminority class.\nThe model construction and training steps used 3 data sets: a\ntraining data set (80% of the entire subsampled data), which\nwas used to train the model; a validation data set (20% of the\ntraining data), which was used to select the best hyperparameters\nduring training; and a test data set (20% of the entire subsampled\ndata that were not included in the training data set), which was\nused to evaluate the performance of the trained model using the\nAUROC metric. This methodology—the careful separation of\nthe training and validation data from the test data—is standard\nin the machine learning community [31].\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 5https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nTable 1. Correlation of significant Linguistic Inquiry and Word Count features with the Generalized Anxiety Disorder 7-item scale.\nP valuerFeature\n<.0010.13AllPunc\n<.001−0.12Word Count\n<.0010.12Period\n<.0010.10Assent\n<.0010.10Negemo\n<.001−0.09Relativ\n<.001−0.08Motion\n<.0010.08Swear\n<.0010.08Anger\n.003−0.07Focusfuture\n.004−0.07Adverb\n.004−0.07Time\n.005−0.07Function\n.0060.07Negate\n.007−0.06Prep\n.007−0.06WPSa\n.0080.06Anx\n.010.06Hear\n.010.06Death\n.01−0.06Ipron\n.01−0.06See\n.020.06Affect\n.020.05I\n.020.05Family\n.030.05Sad\n.030.05Ppron\n.04−0.05Space\n.04−0.05Article\n.040.05Leisure\n.0470.05Friend\naWPS: words per sentence.\nConstruction and Evaluation of the Transformer-Based\nModel\nThe advent and remarkable success of transformer-based neural\nnetworks for NLP is discussed in the Prior Work section. A\nproperty that distinguishes different transformer models is the\nnumber of textual words or tokens that will fit into the contextual\nwindow that the model can consider at one time, which itself\nis limited by the computational burden of the key method of\nattention [8]. These windows range in size from 512 tokens [10]\nto 4096 tokens [30].\nThe modified TSST that provided the input to our model\nrequired the participants to speak for 5 minutes, which produced\ntranscripts ranging in size from 15 to 1190 (mean 707, SD 183)\ntokens. Therefore, our model required a transformer model that\ncan process sequences of this length. We selected the\ntransformer model known as Longformer (obtained from the\nHuggingFace model hub [40]) because it has a contextual\nwindow of size 4096 tokens (recall that tokens are either words\nor parts of a word).\nWe fine-tuned a pretrained version of Longformer (as described\nin the Prior Work section) to create a classifier for the anxiety\nclassification task. This process took a pretrained model and\nattached it to an untrained (and much smaller) neural network\ncalled a “classification head.” The pretrained model together\nwith the sequence classification head was then fine-tuned on\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 6https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nthe specific task of predicting whether a participant is above or\nbelow the screening threshold for GAD based on the GAD-7\nscale.\nThe input data set was processed in a similar way to how the\nbaseline model was processed. Beginning with the set of\ntranscripts from all the participants, the data were first\nundersampled to equalize the representation from both the\nanxious and nonanxious classes. The model fine-tuning step\nalso used 3 data sets: a training data set (80% of the full data);\na validation data set (20% of the training data); and a test data\nset (20% of the full data set), which was used to evaluate the\nperformance of the trained model using the AUROC metric.\nThe overall structure of both the baseline logistic regression\nmodel and the fine-tuned transformer-based model is shown in\nFigure 1.\nFigure 1. Overall structure of the baseline classification model and fine-tuned transformer-based model. LIWC: Linguistic Inquiry and Word Count.\nTransformer Model Interpretation\nDeep neural networks [13], including the transformer network\nused in this study, do not lend themselves to an easy explanation\nof which features or factors are important for any specific\nprediction. This contrasts with the logistic regression model\n(the baseline) in which the weights on each feature are\ninformative. This study endeavored to provide some\ninterpretation of the results of the transformer model,\nparticularly, to provide insights into which words or group of\nwords were the most influential in the model’s prediction of\nanxious and nonanxious classes when given a specific transcript.\nTo achieve this model interpretation, we used a method known\nas integrated gradient (IG) [41]. IG computes a score for every\ninput (word or token) to the model. The score is a function of\nthe rate of change of the prediction with respect to that specific\ninput. When the score of specific input is higher and positive,\nit is an indication that the input had more influence toward\nproducing a positive classification (which is the anxious class\nin our case). Similarly, a high negative score indicates a strong\ninfluence toward the negative, nonanxious case. This score is\nreferred to as the attribution score of the input token. We used\na library called Transformer Interpret [42] to compute the\nattribution score for each word in a given transcript.\nUsing the attribution score, we can report specific words or\ntokens that are influential in the prediction of both anxious and\nnonanxious cases. From there, we explored the specific context\nof those words to look for patterns of language that were\ninfluential. The description in the following paragraphs provides\nthe specific method for selecting words and identifying patterns.\nFirst, the attribution score of each word or token in all the\ntranscripts from all the participants was computed. In the plot\nof the distribution of the number of words with each score, the\nknee of the distribution appeared around a threshold attribution\nscore of 0.05, which provided a tractable number of words to\nexplore. The tokens with scores above the threshold of 0.05 are\npresented in the Results section. A summary of the steps we\ntook to get the list of words is shown in Figure 2.\nTo determine whether there were patterns in the context\nsurrounding the high-attribution words, we manually reviewed\nthe surrounding context of each high-attribution word. The\npatterns we observed from these contexts, together with the\nspecific direction of the prediction (anxious or nonanxious), are\npresented in the Results section.\nFigure 2. Steps to obtain the list of tokens with a high attribution score and high count at influencing the prediction toward both anxious and nonanxious.\nIG: integrated gradient.\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 7https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nResults\nRecruitment and Data Inclusion\nA total of 4542 participants accepted the offer from the Prolific\nrecruitment platform to participate in this study. Of them, 2212\nparticipants finished the study, giving a recruitment yield of\n48.7%. Of the 2212 participants who completed the study, 2000\nprovided acceptable submissions (and thus received payment),\ngiving a submission-to-approval yield of 90.4%. To be clear,\nthe recruitment continued until 2000 acceptable submissions\nwere received. The reasons for which submissions were deemed\nunacceptable include the following: a missing video, missing\nor grossly imperfect audio, and failure to complete the task. The\nrecruitment period lasted from November 23, 2020, to May 28,\n2021. We note that the recruitment was conducted during the\nCOVID-19 pandemic.\nData Overview\nOf the 2000 participants, 620 (31%) were above the GAD-7\nscreening threshold of 10 and 1380 (69%) were below the\nscreening threshold of 10. Henceforth, the participants with a\nGAD-7 score ≥10 are referred to as the anxious group, and those\nwith a GAD-7 score <10 are referred to as the nonanxious group.\nAs described in the Methods section, to have an equal\nrepresentation of the anxious and nonanxious classes, the\nnonanxious group was undersampled, resulting in the inclusion\nof a total of 1240 participants (620 anxious and 620 nonanxious)\nin our analysis.\nClassification Model Performance\nThis section presents the AUROC of the 2 binary classification\nmodels that classify anxious and nonanxious groups. The first\nmodel is the logistic regression model that uses the LIWC\nfeatures as input, which is the baseline model described earlier.\nThe LIWC features used were the ones shown to be significantly\ncorrelated with the GAD-7 in our earlier study [23], as listed in\nTable 1. Note that we also explored other machine learning\nmodels such as SVM, decision tree, random forest, multilayer\nperceptron, but these did not perform better than the baseline\nlogistic regression model. The second model is the fine-tuned\ntransformer-based model. The AUROC curve value for the\nlogistic regression model that uses the LIWC features as input\nwas 0.58 and for the transformer-based model was 0.64. Figures\n3 and 4 present the receiver operating characteristics curves.\nFigure 3. Area under the receiver operating characteristic curve (AUROC) of the baseline logistic regression model.\nFigure 4. Area under the receiver operating characteristic curve (AUROC) of the fine-tuned transformer-based model.\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 8https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nModel Interpretation: Tokens Used to Predict Both\nAnxious and Nonanxious\nIn the Transformer Model Interpretation section, we described\nthe IG method that was used to determine an attribution score\nfor each word in a transcript. That score gives an indication of\nhow strongly the word is implicated in the prediction toward\nanxious (if positive) or nonanxious (if negative). Table 2\npresents the number of times (across all transcripts) that a\nspecific token (listed in the first column) had a high attribution\nscore (absolute value >0.05, as described earlier) based on the\nIG method. The tokens presented in Table 2 were selected\nbecause they had a high count in having both high positive and\nhigh negative attribution scores, that is, at predicting both\nanxious and nonanxious. Note that tokens could be words, parts\nof a word, or characters (eg, the STT system we used generates\na “.” to indicate silent pauses in speech).\nTable 3 presents the patterns we observed with examples taken\nfrom the actual transcripts of the recruited participants where\nthe same token influenced the prediction toward anxious in\nsome cases and toward nonanxious in other cases. The first\ncolumn lists these tokens, indicates the direction (anxious or\nnonanxious) in which they influenced the prediction, and\ndescribes the pattern of the context that we inferred was relevant\nusing the qualitative analysis described in the Methods section.\nThe second column provides a specific example of that pattern,\ntaken from the transcripts, and the third column provides the\nnumber of occurrences of that pattern across all the transcripts.\nTable 2. Tokens with high attribution scores and high counts of prediction influence.\nTimes influencing toward nonanxious, n (%)Times influencing toward anxious, n (%)Token\n427 (12.35)3032 (87.65)I (n=3459)\n11,557 (79.76)2933 (20.24)[Silent pause]a (n=14,490)\n1395 (40.62)2039 (59.38)[Filled pause]b (n=3434)\n682 (42.76)913 (57.24)And (n=1595)\na[Silent pause]: a silent pause in speech, as determined by the speech-to-text software.\nb[Filled pause]: a pause consisting of filler words such as “um,” “mm,” “uh,” “hmm,” or “mhm.”\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 9https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nTable 3. Cases in which the tokens in influenced the prediction of both anxious and nonanxious.\nOccurrences across\nall transcripts, n\nExample of patternToken, prediction class, and definition of pattern\nI\nAnxious\n476I have um I worked very well“I” followed by a filled pausea\n1567I get on well with various different groups“I” is the first word in a sentence but in the middle of\nthe transcript\n208I [Silent pause]Starting a sentence and pausing after just saying “I”\n1515I am able to relate“I” used together with am or have\nNonanxious\n47I was able to remember all their names“I” used in a sentence to reference others\n171<speech starts> I think I would be perfect for this job“I” is the very first word in the transcript\n77I am imaginative“I” used to describe a positive thing about oneself\n[Silent pause]b\nAnxious\n1740[Silent pause] um mm [Silent pause][Silent pause] used before or after a [Filled pause]\n2057my [Silent pause]Starting a sentence and pausing within a short period\nNonanxious\n11,557bring a specific [Silent pause] area of expertise of functionalityPauses during speech that are not accompanied by a\n[Filled pause] and produce a correct sentence\n[Filled pause]a\nAnxious\n1577[Silent pause] um mm [Silent pause][Filled pause] used together with a [Silent pause]\n23<speech starts> hello um I just like to[Filled pause] used in the beginning of a speech\nNonanxious\n480many years playing music at parties um starting at the age ofFilled pause used in the middle of a sentence without\na silent pause\nAnd\nAnxious\n519really think about it in detail andFinishing a sentence with “and”\n187was tasked in doing that and and I did that successfully and thatUsing “and” more than once in a sentence\n282and [Silent pause] sometimes things areStarting a sentence and pausing after just saying “and”\nNonanxious\n572eight people for twelve years and after that I managed an addi-\ntional\n“and” used grammatically correctly in a sentence\na[Filled pause]: a pause consisting of filler words such as “um,” “mm,” “uh,” “hmm,” or “mhm.”\nb[Silent pause]: a silent pause in speech, as determined by the speech-to-text software.\nDiscussion\nThe goal of this study was to determine how well a\ntransformer-based neural network model can predict GAD and\ncompare it to the performance of an LIWC-based logistic\nregression predictor. In this section, we discuss the implications\nof the findings presented in the Results section, as well as the\nlimitations of the study.\nPrincipal Findings\nRecruitment and Data Overview\nResults presented in the Data Overview section indicates that\na substantially larger number of participants screened positive\nfor GAD compared with the prevalence rate of 10% in the\ngeneral population [6]. This suggests that participants recruited\nfrom Prolific are more likely to experience anxiety, which is\nconsistent with previous research using participants from Prolific\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 10https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\n[23,43,44]. Another possible reason for a higher number of\nanxious participants is the recruitment period (November 23,\n2020, to May 28, 2021), which coincided with the COVID-19\npandemic. More demographic information can be found in our\nearlier published papers [23,24].\nClassification Model Performance\nThe logistic regression model with LIWC features is the baseline\npoint of comparison. This model performed better than the\nrandom model (as it has an AUROC of >0.5). This indicates\nthat the count and type of words used by individuals do provide\nsome insights into their anxiety, which is in line with prior work\n[14,16-19] that explored the association between LIWC features\nand anxiety.\nThe performance of the fine-tuned transformer model was larger\nthan the baseline model by 10%—suggesting that it is context\naware. We believe that a model that considers context can\nachieve higher predictive performance. This suggests that\ntransformer models, which search for multiword contexts to\nfind patterns, can extract more information for prediction than\nsingle word–based models. The results presented in Tables 2\nand 3 allow us to understand, in more detail, what the fine-tuned\ntransformer model based its predictions on, as discussed in the\nsubsequent section.\nFurthermore, we note that it is possible to increase the\nprobability of correct prediction by incorporating acoustic\nfeatures in the prediction of the transformer-based model as\nwell as by using multiple measurements if the circumstances\nof the measurement system permit it. This would be the case if\nthis kind of a model is applied to passively collected speech,\nand we could sample the speech and measure it over time. In\nthat case, one could survey the multiple measurements and\nselect the majority result (anxious or nonanxious) that has been\npredicted as the true result. This approach works under the\nassumption that each measurement from a different speech\nsample is independent and will work less well as a function of\nindependence. We have discussed this approach in more detail\nin our earlier paper [24].\nModel Interpretation\nIn this section, we discuss our attempt to provide an\ninterpretation of the results from the transformer model. Table\n2 shows the tokens with a high attribution score, as defined\nearlier, and a high count at influencing the prediction toward\nanxious and nonanxious. The first entries in Table 3 describe\nthe effects of the singular pronoun “I.” Depending on the\ncontext, the use of the word “I” influences either toward an\nanxious prediction or toward a nonanxious prediction. By\ncontrast, previous studies have shown an increased use of “I”\nto be associated only toward the direction of anxiety [16]. A\npossible reason why “I” is associated with anxiety is because\nindividuals with anxiety will try to divert their attention from\nanxiety-inducing events by focusing on themselves. This might\nresult in the frequent use of “I” in their speech.\nHowever, this study shows how the context around the word\n“I” matters—although its presence influenced the prediction\ntoward anxiety for the majority of the cases (88%), it also\ninfluenced the prediction toward nonanxious in 12% of the\ncases. A pattern around “I” that influenced the prediction toward\nnonanxious is when it was used to reference others (eg, “I was\nable to remember all their names”). This is opposite to the case\nwhere anxious individuals tend to focus on themselves and\nhence a possible reason as to why focusing on others would\ninfluence the prediction toward nonanxious. Another pattern of\n“I” that influenced the prediction toward nonanxious is when\nit was one of the very first words at the beginning of speech (ie,\nat the very beginning). This may be because confident people\nmight start their speech by introducing themselves or placing\nthe focus on themselves before proceeding with whatever the\nsubject matter of their speech is. Similarly, relating to\nconfidence, there is a pattern where “I” was used to say\nsomething positive about oneself, which influenced the\nprediction toward nonanxious. These cases suggest that\nconfidence is related to the state of being nonanxious.\nSilent pauses ([Silent pause] in Tables 2 and 3) mainly\ninfluenced the prediction toward nonanxious, for 80% of the\ncases. This is in line with prior work [45], which indicated that\nanxiety is associated with a reduction in the number of silent\npauses during speech. The authors suggested that pausing during\nspeech represents a cognitive activity that is observed more in\nnonanxious individuals than in anxious individuals.\nHowever, there were also times when a silent pause influenced\nthe prediction toward anxiety. The difference was the context:\nwhen a silent pause was used together with a filled pause and\npausing after saying a single word. These cases hint toward\ndifficulty in producing complete sentences and instead using\nfiller words in the middle of their speech or inability to finish\na sentence. This might be because of a higher level of anxiety.\nThe other 2 types of tokens presented in Table 2 ([Filled Pauses]\nand “and”) had a high count in influencing the prediction toward\nboth anxious and nonanxious. We believe that they have a high\ncount because they are commonly used tokens in STT\ntranscripts. A pattern that stood out around both ([Filled Pauses]\nand “and”) types of tokens is the use of grammatically correct\nlanguage, which was exhibited more by the participants without\nanxiety. Prior work [46] suggests that anxiety causes disfluencies\nin speech, which, therefore, could be a possible explanation for\nthe use of grammatically incorrect language by the participants\nwith anxiety. Our results suggest that the model is picking up\non this grammatical incorrectness.\nLimitations\nOne limitation of this study is the accuracy of the STT\ntranscription. In this study, we used Amazon’s STT program\n[39], which had good transcription accuracy, with an average\nWER of 7% (SD 4.6%). The fact that the WER is not 0 means\nthat we obtain the wrong transcription for some words, and our\nmodel might make a wrong prediction based on these words.\nHowever, we speculate that because the STT software is\nimproving each year, the WER would become closer and closer\nto 0, so the prediction of a model based on these transcripts\nwould also improve.\nAnother limitation of this study is the use of a modified version\nof the TSST. In the original TSST, participants are asked to\ndescribe why they should be hired for their dream job in front\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 11https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nof a live panel of judges. However, in our study, we asked the\nrecruited participants to describe why they should be hired for\ntheir dream job in front of a camera at their own location. This\nis a limitation in achieving the full replication of the TSST as\na stress induction task. Nonetheless, we had an internal check\nwhere we asked them how anxious they felt before and after\nthe TSST task (more information can be found in our earlier\npublished study [23]), and we observed, on average, a 25%\nincrease in the participants’ level of anxiety.\nAnother limitation is the use of self-report measures to assess\nGAD. Self-report measures are subjective opinions that\nindividuals have about themselves and may not completely\ncapture clinical symptoms. Ideally, we would want the gold\nstandard label for determining whether a participant has GAD.\nThis is acquired through a one-on-one session between a patient\nand clinician where the clinician analyzes the patient’s behavior\nto identify possible symptoms of GAD according to the\nDiagnostic and Statistical Manual of Mental Disorders, Fifth\nEdition [7], but this is clearly much more expensive to acquire.\nAnother limitation is the subjective or qualitative nature of\npattern detection, which is presented in Table 3 and forms the\nbasis of the insights in the Discussion section. As described in\nthe Methods section, the transcripts were analyzed manually,\nand instances that we believed exhibited similar patterns across\nmultiple contexts were selected. These were our subjective\nopinions of what constituted a similar pattern; therefore, other\nresearchers might be able to find other patterns that we might\nhave overlooked. In future studies, we aim to release our\ntranscripts for other researchers to go through as we did and see\nwhether any other interesting patterns could be detected.\nConclusions\nIn this paper, we have presented the results of a large-sample\nstudy that aimed to predict whether participants who provided\nspeech samples fell below or above the screening threshold for\nGAD based on the GAD-7 scale. More specifically, we\ninvestigated the importance of multiword context when\npredicting the presence or absence of anxiety. Although prior\nstudies have shown that the choice of individual words is a good\npredictor of mental health disorders, we have shown that the\nchoice of words together with the context is an even better\npredictor. Furthermore, transformer-based neural network\nmodels can be leveraged to find such linguistic patterns that\nhelp identify whether a certain word, given the context, would\npredict anxiety. There is a type of transformer-based model\nrecently published in the literature [47], which is a model\npretrained on a mental health corpus (focusing on depression\nand suicidality). Therefore, we recommend that future studies\nexplore the linguistic patterns of speech identified using\ntransformer models and apply them to the screening of different\ntypes of mental health disorders.\nAcknowledgments\nThis research was funded by a University of Toronto XSeed grant, Natural Sciences and Engineering Research Council of Canada\nDiscovery Grant (RGPIN-2019-04395), and Social Sciences and Humanities Research Council Partnership Engage Grant\n(892-2019-0011).\nThe authors are grateful to Professor Ludovic Rheault, Professor Sophie Borwein, and Dr Danielle D DeSouza for their energy,\nassistance with the launch of this project and data collection, and advice.\nConflicts of Interest\nNone declared.\nReferences\n1. Koerner N, Dugas MJ, Savard P, Gaudet A, Turcotte J, Marchand A. The economic burden of anxiety disorders in Canada.\nCanadian Psychology / Psychologie canadienne 2004 Aug;45(3):191-201. [doi: 10.1037/h0088236]\n2. Roberge P, Fournier L, Duhoux A, Nguyen CT, Smolders M. Mental health service use and treatment adequacy for anxiety\ndisorders in Canada. Soc Psychiatry Psychiatr Epidemiol 2011 Apr;46(4):321-330. [doi: 10.1007/s00127-010-0186-2]\n[Medline: 20217041]\n3. Thompson AR. Pharmacological agents with effects on voice. Am J Otolaryngol 1995;16(1):12-18. [doi:\n10.1016/0196-0709(95)90003-9] [Medline: 7717466]\n4. Pennebaker JW, Mehl MR, Niederhoffer KG. Psychological aspects of natural language. use: our words, our selves. Annu\nRev Psychol 2003;54:547-577. [doi: 10.1146/annurev.psych.54.101601.145041] [Medline: 12185209]\n5. Hidalgo RB, Sheehan DV. Generalized anxiety disorder. Handb Clin Neurol 2012;106:343-362. [doi:\n10.1016/B978-0-444-52002-9.00019-X] [Medline: 22608630]\n6. Mental Health - Anxiety Disorders. Government of Canada. URL: https://www.canada.ca/en/health-canada/services/\nhealthy-living/your-health/diseases/mental-health-anxiety-disorders.html [accessed 2022-01-24]\n7. Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition. Washington, D.C., United States: American Psychiatric\nAssociation; 2013.\n8. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A, et al. Attention is all you need. arXiv 2017 [FREE Full\ntext]\n9. Wolf T, Debut L, Sanh V, Chaumond J, Delangue C, Moi A, et al. Transformers: state-of-the-art natural language processing.\nIn: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations.\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 12https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\n2020 Presented at: 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations; Nov\n8-12, 2020; Online. [doi: 10.18653/v1/2020.emnlp-demos.6]\n10. Devlin J, Chang M, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding.\narXiv 2019 [FREE Full text]\n11. Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language models are unsupervised multitask learners. GitHub.\nURL: https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/\nlanguage-models.pdf [accessed 2022-11-15]\n12. Floridi L, Chiriatti M. GPT-3: its nature, scope, limits, and consequences. Minds Mach 2020 Nov 01;30(4):681-694. [doi:\n10.1007/s11023-020-09548-1]\n13. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015 May 28;521(7553):436-444. [doi: 10.1038/nature14539]\n[Medline: 26017442]\n14. Di Matteo D, Wang W, Fotinos K, Lokuge S, Yu J, Sternat T, et al. Smartphone-detected ambient speech and self-reported\nmeasures of anxiety and depression: exploratory observational study. JMIR Form Res 2021 Jan 29;5(1):e22723 [FREE\nFull text] [doi: 10.2196/22723] [Medline: 33512325]\n15. Pennebaker J, Boyd R, Jordan K, Blackburn K. The development and psychometric properties of LIWC2015. The University\nof Texas at Austin. URL: https://repositories.lib.utexas.edu/bitstream/handle/2152/31333/LIWC2015_LanguageManual.\npdf [accessed 2022-01-24]\n16. Anderson B, Goldin PR, Kurita K, Gross JJ. Self-representation in social anxiety disorder: linguistic analysis of\nautobiographical narratives. Behav Res Ther 2008 Oct;46(10):1119-1125 [FREE Full text] [doi: 10.1016/j.brat.2008.07.001]\n[Medline: 18722589]\n17. Hofmann SG, Moore PM, Gutner C, Weeks JW. Linguistic correlates of social anxiety disorder. Cogn Emot\n2012;26(4):720-726 [FREE Full text] [doi: 10.1080/02699931.2011.602048] [Medline: 21851248]\n18. Sonnenschein AR, Hofmann SG, Ziegelmayer T, Lutz W. Linguistic analysis of patients with mood and anxiety disorders\nduring cognitive behavioral therapy. Cogn Behav Ther 2018 Jul;47(4):315-327. [doi: 10.1080/16506073.2017.1419505]\n[Medline: 29345528]\n19. Rook L, Mazza MC, Lefter I, Brazier F. Toward linguistic recognition of generalized anxiety disorder. Front Digit Health\n2022;4:779039 [FREE Full text] [doi: 10.3389/fdgth.2022.779039] [Medline: 35493530]\n20. Gruda D, Hasan S. Feeling anxious? Perceiving anxiety in tweets using machine learning. Comput Human Behav 2019\nSep;98:245-255. [doi: 10.1016/j.chb.2019.04.020]\n21. Skapinakis P. Spielberger state-trait anxiety inventory. In: Encyclopedia of Quality of Life and Well-Being Research.\nDordrecht: Springer; 2014.\n22. MacKay DJ. Bayesian interpolation. Neural Computation 1992 May;4(3):415-447. [doi: 10.1162/neco.1992.4.3.415]\n23. Teferra BG, Borwein S, DeSouza DD, Simpson W, Rheault L, Rose J. Acoustic and linguistic features of impromptu speech\nand their association with anxiety: validation study. JMIR Ment Health 2022 Jul 08;9(7):e36828 [FREE Full text] [doi:\n10.2196/36828] [Medline: 35802401]\n24. Teferra BG, Borwein S, DeSouza DD, Rose J. Screening for generalized anxiety disorder from acoustic and linguistic\nfeatures of impromptu speech: prediction model evaluation study. JMIR Form Res 2022 Oct 28;6(10):e39998 [FREE Full\ntext] [doi: 10.2196/39998] [Medline: 36306165]\n25. Jurafsky D, Martin J. Speech and Language Processing An Introduction to Natural Language Processing, Computational\nLinguistics, and Speech Recognition. Hoboken, New Jersey, U.S: Pearson Prentice Hall; 2008.\n26. Bengio S, Heigold G. Word embeddings for speech recognition. Proc Interspeech 2014 2014:1053-1057. [doi:\n10.21437/interspeech.2014-273]\n27. Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. arXiv 2013 [FREE\nFull text] [doi: 10.3126/jiee.v3i1.34327]\n28. Pennington J, Socher R, Manning C. GloVe: global vectors for word representation. In: Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Processing (EMNLP). 2014 Presented at: 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP); Oct, 2014; Doha, Qatar. [doi: 10.3115/v1/d14-1162]\n29. Li Y, Yang T. Word embedding for understanding natural language: a survey. In: Guide to Big Data Applications. Cham:\nSpringer; 2018.\n30. Beltagy I, Peters M, Cohan A. Longformer: the long-document transformer. arXiv 2020 [FREE Full text]\n31. Mitchell T. Machine Learning. New York: McGraw-Hill; 2017.\n32. Kim Y, Denton C, Hoang L, Rush A. Structured attention networks. arXiv 2017 [FREE Full text]\n33. Palan S, Schitter C. Prolific.ac—A subject pool for online experiments. J Behavioral Experimental Finance 2018\nMar;17:22-27. [doi: 10.1016/j.jbef.2017.12.004]\n34. Spitzer RL, Kroenke K, Williams JB, Löwe B. A brief measure for assessing generalized anxiety disorder: the GAD-7.\nArch Intern Med 2006 May 22;166(10):1092-1097. [doi: 10.1001/archinte.166.10.1092] [Medline: 16717171]\n35. Kirschbaum C, Pirke KM, Hellhammer DH. The 'Trier Social Stress Test'--a tool for investigating psychobiological stress\nresponses in a laboratory setting. Neuropsychobiology 1993;28(1-2):76-81. [doi: 10.1159/000119004] [Medline: 8255414]\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 13https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\n36. Gerra G, Zaimovic A, Zambelli U, Timpano M, Reali N, Bernasconi S, et al. Neuroendocrine responses to psychological\nstress in adolescents with anxiety disorder. Neuropsychobiology 2000;42(2):82-92. [doi: 10.1159/000026677] [Medline:\n10940763]\n37. Jezova D, Makatsori A, Duncko R, Moncek F, Jakubek M. High trait anxiety in healthy subjects is associated with low\nneuroendocrine activity during psychosocial stress. Prog Neuropsychopharmacol Biol Psychiatry 2004 Dec;28(8):1331-1336.\n[doi: 10.1016/j.pnpbp.2004.08.005] [Medline: 15588760]\n38. Endler NS, Kocovski NL. State and trait anxiety revisited. J Anxiety Disord 2001;15(3):231-245. [doi:\n10.1016/s0887-6185(01)00060-3] [Medline: 11442141]\n39. Hashemipour S, Ali M. Amazon web services (AWS) – an overview of the on-demand cloud computing platform. In:\nEmerging Technologies in Computing. Cham: Springer International Publishing; 2020.\n40. Beltagy I, Peters M, Cohan A. Longformer. Hugging Face. URL: https://huggingface.co/docs/transformers/v4.20.1/en/\nmodel_doc/longformer#longformer [accessed 2022-11-15]\n41. Sundararajan M, Taly A, Yan Q. Axiomatic attribution for deep networks. arXiv 2017 [FREE Full text]\n42. Pierse C. Transformers interpret. GitHub. URL: https://github.com/cdpierse/transformers-interpret [accessed 2022-11-15]\n43. Di Matteo D, Fotinos K, Lokuge S, Yu J, Sternat T, Katzman MA, et al. The relationship between smartphone-recorded\nenvironmental audio and symptomatology of anxiety and depression: exploratory study. JMIR Form Res 2020 Aug\n13;4(8):e18751 [FREE Full text] [doi: 10.2196/18751] [Medline: 32788153]\n44. Di Matteo D, Fotinos K, Lokuge S, Mason G, Sternat T, Katzman MA, et al. Automated screening for social anxiety,\ngeneralized anxiety, and depression from objective smartphone-collected data: cross-sectional study. J Med Internet Res\n2021 Aug 13;23(8):e28918 [FREE Full text] [doi: 10.2196/28918] [Medline: 34397386]\n45. Siegman AW. The meaning of silent pauses in the initial interview. J Nerv Ment Dis 1978 Sep;166(9):642-654. [doi:\n10.1097/00005053-197809000-00004] [Medline: 690624]\n46. Mahl GF. Disturbances and silences in the patient's speech in psychotherapy. J Abnorm Psychol 1956 Jul;53(1):1-15. [doi:\n10.1037/h0047552] [Medline: 13345560]\n47. Ji S, Zhang T, Ansari L, Fu J, Tiwari P, Cambria E. MentalBERT: publicly available pretrained language models for mental\nhealthcare. ArXiv 2021:10 [FREE Full text]\nAbbreviations\nAUROC: area under the receiver operating characteristic curve\nBIS/BAS: behavioral inhibition/behavioral approach system\nGAD: generalized anxiety disorder\nGAD-7: Generalized Anxiety Disorder 7-item\nIG: integrated gradient\nLIWC: Linguistic Inquiry and Word Count\nNLP: natural language processing\nSAD: social anxiety disorder\nSTT: speech-to-text\nSVM: support vector machine\nTSST: Trier Social Stress Test\nWER: word error rate\nEdited by J Torous; submitted 15.11.22; peer-reviewed by K Gupta, Z Yang, T Zhang; comments to author 19.12.22; revised version\nreceived 21.02.23; accepted 23.02.23; published 28.03.23\nPlease cite as:\nTeferra BG, Rose J\nPredicting Generalized Anxiety Disorder From Impromptu Speech Transcripts Using Context-Aware Transformer-Based Neural\nNetworks: Model Evaluation Study\nJMIR Ment Health 2023;10:e44325\nURL: https://mental.jmir.org/2023/1/e44325\ndoi: 10.2196/44325\nPMID: 36976636\n©Bazen Gashaw Teferra, Jonathan Rose. Originally published in JMIR Mental Health (https://mental.jmir.org), 28.03.2023. This\nis an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 14https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX\nprovided the original work, first published in JMIR Mental Health, is properly cited. The complete bibliographic information, a\nlink to the original publication on https://mental.jmir.org/, as well as this copyright and license information must be included.\nJMIR Ment Health 2023 | vol. 10 | e44325 | p. 15https://mental.jmir.org/2023/1/e44325\n(page number not for citation purposes)\nTeferra & RoseJMIR MENTAL HEALTH\nXSL•FO\nRenderX",
  "topic": "Impromptu",
  "concepts": [
    {
      "name": "Impromptu",
      "score": 0.6668087244033813
    },
    {
      "name": "Psychology",
      "score": 0.574425995349884
    },
    {
      "name": "Anxiety",
      "score": 0.5736536979675293
    },
    {
      "name": "Logistic regression",
      "score": 0.5339929461479187
    },
    {
      "name": "Receiver operating characteristic",
      "score": 0.48140788078308105
    },
    {
      "name": "Artificial intelligence",
      "score": 0.449789822101593
    },
    {
      "name": "Transformer",
      "score": 0.4480477273464203
    },
    {
      "name": "Artificial neural network",
      "score": 0.41392451524734497
    },
    {
      "name": "Computer science",
      "score": 0.41140735149383545
    },
    {
      "name": "Natural language processing",
      "score": 0.3685029149055481
    },
    {
      "name": "Cognitive psychology",
      "score": 0.3541446626186371
    },
    {
      "name": "Machine learning",
      "score": 0.32464906573295593
    },
    {
      "name": "Psychiatry",
      "score": 0.09026941657066345
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}