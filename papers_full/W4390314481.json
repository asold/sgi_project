{
  "title": "Radiological Differential Diagnoses Based on Cardiovascular and Thoracic Imaging Patterns: Perspectives of Four Large Language Models",
  "url": "https://openalex.org/W4390314481",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2411372681",
      "name": "Pradosh Kumar Sarangi",
      "affiliations": [
        "All India Institute of Medical Sciences, Deoghar"
      ]
    },
    {
      "id": "https://openalex.org/A1880441755",
      "name": "Aparna Irodi",
      "affiliations": [
        "Christian Medical College & Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3096356599",
      "name": "Swaha Panda",
      "affiliations": [
        "All India Institute of Medical Sciences, Deoghar"
      ]
    },
    {
      "id": "https://openalex.org/A2781048075",
      "name": "Debasish Swapnesh Kumar Nayak",
      "affiliations": [
        "Siksha O Anusandhan University"
      ]
    },
    {
      "id": "https://openalex.org/A2556512418",
      "name": "Himel Mondal",
      "affiliations": [
        "All India Institute of Medical Sciences, Deoghar"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4281640569",
    "https://openalex.org/W4323652488",
    "https://openalex.org/W4366989525",
    "https://openalex.org/W4386033569",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4381480701",
    "https://openalex.org/W4376640725",
    "https://openalex.org/W4379136378",
    "https://openalex.org/W4383186888",
    "https://openalex.org/W4362608470",
    "https://openalex.org/W4385330587",
    "https://openalex.org/W4380995257",
    "https://openalex.org/W4382774929",
    "https://openalex.org/W4378229839",
    "https://openalex.org/W1522819505"
  ],
  "abstract": "Abstract Background Differential diagnosis in radiology is a critical aspect of clinical decision-making. Radiologists in the early stages may find difficulties in listing the differential diagnosis from image patterns. In this context, the emergence of large language models (LLMs) has introduced new opportunities as these models have the capacity to access and contextualize extensive information from text-based input. Objective The objective of this study was to explore the utility of four LLMs—ChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity—in providing most important differential diagnoses of cardiovascular and thoracic imaging patterns. Methods We selected 15 unique cardiovascular (n = 5) and thoracic (n = 10) imaging patterns. We asked each model to generate top 5 most important differential diagnoses for every pattern. Concurrently, a panel of two cardiothoracic radiologists independently identified top 5 differentials for each case and came to consensus when discrepancies occurred. We checked the concordance and acceptance of LLM-generated differentials with the consensus differential diagnosis. Categorical variables were compared by binomial, chi-squared, or Fisher's exact test. Results A total of 15 cases with five differentials generated a total of 75 items to analyze. The highest level of concordance was observed for diagnoses provided by Perplexity (66.67%), followed by ChatGPT (65.33%) and Bing (62.67%). The lowest score was for Bard with 45.33% of concordance with expert consensus. The acceptance rate was highest for Perplexity (90.67%), followed by Bing (89.33%) and ChatGPT (85.33%). The lowest acceptance rate was for Bard (69.33%). Conclusion Four LLMs—ChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity—generated differential diagnoses had high level of acceptance but relatively lower concordance. There were significant differences in acceptance and concordance among the LLMs. Hence, it is important to carefully select the suitable model for usage in patient care or in medical education.",
  "full_text": "Radiological Differential Diagnoses Based on\nCardiovascular and Thoracic Imaging Patterns:\nPerspectives of Four Large Language Models\nPradosh Kumar Sarangi1 Aparna Irodi2 Swaha Panda3 Debasish Swapnesh Kumar Nayak4\nHimel Mondal5\n1 Department of Radiodiagnosis, All India Institute of Medical\nSciences, Deoghar, Jharkhand, India\n2 Department of Radiodiagnosis, Christian Medical College and\nHospital, Vellore, Tamil Nadu, India\n3 Department of Otorhinolaryngology and Head and Neck Surgery, All\nIndia Institute of Medical Sciences, Deoghar, Jharkhand, India\n4 Department of Computer Science and Engineering, Siksha ‘O’\nAnusandhan (Deemed to be) University, Bhubaneswar, Odisha, India\n5 Department of Physiology, All India Institute of Medical Sciences,\nDeoghar, Jharkhand, India\nIndian J Radiol Imaging 2024;34:269– 275.\nAddress for correspondence Himel Mondal, MBBS, MD, Department\nof Physiology, All India Institute of Medical Sciences, Deoghar,\nJharkhand 814152, India (e-mail: himelmkcg@gmail.com).\nKeywords\n► artificial intelligence\n► cardiothoracic\n► ChatGPT\n► Google Bard\n► Microsoft Bing\n► perplexity\n► differential diagnosis\n► radiologists\nAbstract Background Differential diagnosis in radiology is a critical aspect of clinical decision-\nmaking. Radiologists in the early stages mayﬁnd difﬁculties in listing the differential\ndiagnosis from image patterns. In this context, the emergence of large language\nmodels (LLMs) has introduced new opportunities as these models have the capacity to\naccess and contextualize extensive information from text-based input.\nObjective The objective of this study was to explore the utility of four LLMs —\nChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity— in providing most important\ndifferential diagnoses of cardiovascular and thoracic imaging patterns.\nMethods We selected 15 unique cardiovascular (n ¼5) and thoracic (n ¼10) imaging\npatterns. We asked each model to generate top 5 most important differential\ndiagnoses for every pattern. Concurrently, a panel of two cardiothoracic radiologists\nindependently identiﬁed top 5 differentials for each case and came to consensus when\ndiscrepancies occurred. We checked the concordance and acceptance of LLM-generat-\ned differentials with the consensus differential diagnosis. Categorical variables were\ncompared by binomial, chi-squared, or Fisher’se x a c tt e s t .\nResults At o t a lo f1 5c a s e sw i t hﬁve differentials generated a total of 75 items to\nanalyze. The highest level of concordance was observed for diagnoses provided by\nPerplexity (66.67%), followed by ChatGP T (65.33%) and Bing (62.67%). The lowest\nscore was for Bard with 45.33% of concordance with expert consensus. The acceptance\nrate was highest for Perplexity (90.67%), followed by Bing (89.33%) and ChatGPT\n(85.33%). The lowest acceptance rate was for Bard (69.33%).\narticle published online\nDecember 28, 2023\nDOI https://doi.org/\n10.1055/s-0043-1777289.\nISSN 0971-3026.\n© 2023. Indian Radiological Association. All rights reserved.\nThis is an open access article published by Thieme under the terms of the\nCreative Commons Attribution-NonDeri vative-NonCommercial-License,\npermitting copying and reproduction so long as the original work is given\nappropriate credit. Contents may not be used for commercial purposes, or\nadapted, remixed, transformed or built upon. (https://creativecommons.org/\nlicenses/by-nc-nd/4.0/)\nThieme Medical and Scientiﬁc Publishers Pvt. Ltd., A-12, 2nd Floor,\nSector 2, Noida-201301 UP, India\nTHIEME\nOriginal Article 269\nArticle published online: 2023-12-28\nIntroduction\nIdentifying imaging patterns from different radiological mo-\ndalities and linking them to speciﬁc pathologies while taking\ninto account clinical contexts and probabilities is a crucial\naspect of radiological diagnosis for which radiologists have to\npossess a vast amount of knowledge. Radiologists in the early\nstages of their training often rely on seeking guidance from\nseniors and delving into relevant literature to validate or\nexpand their list of potential diagnoses, which can be a\ntime-consuming and resource-intensive endeavor.\n1 However,\nthe emergence of artiﬁcial intelligence (AI) and large language\nmodels (LLMs) has introduced new opportunities in this\nregard as these models have the capacity to access and\ncontextualize extensive information present in their text-\nbased training data.\n2 The deep learning (DL) models serve as\nthe foundation for the design of various LLMs. DL models use\nartiﬁcial neural networks yet operate on the same principles as\nthe human brain. The foundation of any accessible LLM is\ncomprised of these pretrained DL models.\n3\nCardiovascular and thoracic diseases present diverse and\ncomplex imaging patterns, often necessitating careful inter-\npretation. The advent of LLMs like Open AI’s ChatGPT, Google\nBard (Experiment), Microsoft Bing (creative), and Perplexity AI\nintroduces an intriguing prospect.4 These models, trained on\nextensive medical literature and data, possess the ability to\ncomprehend complex diagnostic contexts that offer unique\ninsights that can potentially assist in providing differential\ndiagnoses from text-based description of imaging pattern.\n5\nChatGPT has been explored for an adjunct for radiologic\ndecision-making and it was found to be feasible to use it for\nimproving clinical workﬂow.\n6 In addition, ChatGPT per-\nformed well in radiology board-style examination without\nimages. Hence, it has the capability to comprehend textual\ndescription of radiological question.\n7 However, in another\nstudy, it was reported that ChatGPT3.5 performed below the\naverage student in written tasks.8 Kottlors et al used the\nlatest version of the paid model ChatGPT4. They found that\nChatGPT4 provides 68.8% concordant and 93.8% acceptable\ndifferential diagnosis in radiology.9 ChatGPT4 is a premium\nversion of Open AI’s chatbot. Users from developing coun-\ntries may not have access to this version. Free chatbots like\nGoogle Bard (Experiment), Microsoft Bing (creative), and\nPerplexity are available for users.\nThe role of freely available chatbots in the domain of\nradiology in providing relevant differential diagnoses from\ntext-based descriptions of image patterns remains unex-\nplored. Hence, this study aimed to bridge this gap by investi-\ngating the potential of four important and widely used free\nLLMs to provide relevant differential diagnosis from imaging\npattern (cardiovascular and thoracic imaging). By comparing\ntheir generated differential diagnoses against expert consen-\nsus, the utility of LLMs in augmenting traditional diagnostic\napproaches is explored.\nMethods\nStudy Design\nThis research employed a cross-sectional observational\nstudy design to explore the application of LLMs in suggesting\nmost relevant differential diagnoses for cardiovascular and\nthoracic imaging patterns.\nImaging Pattern\nWe curated a dataset of 15 cardiovascular and thoracic\nimaging patterns sourced from a textbook (Chapman &\nNakielny’s Aids to Radiological Differential Diagnosis) and\nan online platform https://radiopaedia.org.\n9 The imaging\npatterns are shown in►Table 1.\nLLMs\nWe observed that various LLMs have been developed in\nrecent years. According to the literature, there will more\nthan 36 LLMs in the market by 2023.4 There are two different\nkinds of accessible LLMs: one is open source and available to\nall users for free and the other is subscription-based and\nrequires a fee to use the advanced features. Based on their\npopularity, architecture, usefulness, and services to medical\nscience, we chose four open source LLMs for this study. We\nused Open AI’s ChatGPT3.5 (https://chat.openai.com) free\nresearch version, Google Bard (https://bard.google.com) Ex-\nperiment, Microsoft Bing (https://www.bing.com/) Chat\n(Creative) based on GPT4, and Perplexity AI (https://www.\nperplexity.ai). Henceforth in this manuscript, we will refer to\nthese as ChatGPT, Bard, Bing, and Perplexity. A summary of\nthe four LLMs used in this study is shown in\n►Table 2.\nModel-Generated Differential Diagnoses\nFor each of the 15 imaging patterns, ChatGPT, Bard, Bing, and\nPerplexity were asked to generate top 5 most important\ndifferential diagnoses. These model-generated diagnoses\nwere stored for further analysis. A brief of the study proce-\ndure is shown in\n►Fig. 1.\nExpert Consensus\nAn expert panel comprising two experienced radiologists\nspecialized in cardiothoracic imaging independently\nConclusion Four LLMs— ChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity—\ngenerated differential diagnoses had high level of acceptance but relatively lower\nconcordance. There were signi ﬁcant differences in acceptance and concordance\namong the LLMs. Hence, it is important to carefully select the suitable model for\nusage in patient care or in medical education.\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al.270\n\nidentiﬁed the topﬁve most important differential diagnoses\nfor each imaging pattern leveraging their clinical expertise,\ndomain knowledge, and book references. Then a consensus\nwas reached to generate aﬁnal list ofﬁve most important\ndifferential diagnoses for each imaging pattern.\nConcordance and Acceptance Evaluation\nTo assess the performance of the LLMs, we evaluated two key\nmetrics— concordance and acceptance. Concordance was the\noverlap between the differential diagnoses suggested by the\nLLMs and those determined by the expert consensus panel (i.e.,\nmatching differentials). Acceptance was determined by the\nproportion of model-generated diagnoses that were deemed\nacceptable alternatives by the experts including concordance.\nExperts had the liberty to utilize reference sources they\nconsidered suitable to validate their judgments, when needed,\nsuch as textbooks, publications, or online platforms.\nStatistical Analysis\nThe results were presented in number and percentages.\nCategorical variables were compared statistically by the\nTable 1 Cardiothoracic imaging pattern used in the study\nThorax Unilateral hyperlucent hemithorax on chest radiograph\nNonresolving or recurrent lung consolidation\nReticular pattern with honeycombing in the lungs\nMosaic attenuation pattern in high-resolution computed tomography (HRCT) of the thorax\nPulmonary nodules with cavitation\nR i bl e s i o nw i t ha na d j a c e n ts o f t - t i s s u em a s s\nDiffuse ground-glass nodules on HRCT of the thorax\nPediatric mediastinal masses\nMediastinal mass containing fat\nCystic lung disease\nCardiac Late gadolinium enhancement on cardiac magnetic resonance imaging (MRI)\nPulmonary arterial enlargement\nCardiac calciﬁcation\nSeptal bounce sign on cardiac MRI\nLeft ventricular hypertrophy\nTable 2 Language models used in this study and their architectures\nLLM Developer Launch date Transformer/neural network architectures\nBard Google AI March 21, 2023 PaLM\nBing Microsoft February 2023 GPT 4\nChatGPT3.5 OpenAI November 30, 2022 GPT 3.5\nPerplexity Perplexity AI August 2022 GPT 3.5\nAbbreviations: AI, artiﬁcial intelligence; GPT, generative pretrained transformer; LLM, large language models; PaLM, pathways language model.\nFig. 1 Brief study procedure.\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al. 271\n\nchi-squared test or Fisher’s exact test where frequency was\nless than 5. The statistically signiﬁcant difference between\nyes and no categories was tested by binomial test where\nsigniﬁcance indicates that the occurrence was not by chance.\nWe used Microsoft Excel 2010 for data storage and GraphPad\nPrism 9.5.0 (GraphPad Software, United States) for inferen-\ntial statistics. A p value of less than 0.05 was considered\nstatistically signiﬁcant.\nEthical Considerations\nThe study did not use any identiﬁable patient data. The data\ngenerated by LLMs were also not presented in this study.\nHence, according to the ethical guidelines, this study does not\nrequire institutional ethics committee clearance.\nResults\nA total of 15 cases withﬁve differentials generated a total of\n75 items to analyze. The highest level of concordance was\nobserved for diagnoses provided by Perplexity (66.67%),\nfollowed by ChatGPT (65.33%) and Bing (62.67%). The lowest\nscore was for Bard with 45.33% of concordance with expert\nconsensus. The acceptance rate was highest for Perplexity\n(90.67%), followed by Bing (89.33%) and ChatGPT (85.33%).\nThe lowest acceptance rate was for Bard (69.33%;\n►Fig. 2).\nHowever, the acceptance and concordance percentages were\nnot signiﬁcantly different from each other (p ¼0.93).\nDomain-wise score of four LLMs are shown in\n►Table 3.\nChatGPT in cardiac, Bing in thorax, and Perplexity in thorax\nshowed signiﬁcance in concordance. However, all LLMs\nshowed signiﬁcantly higher acceptance. There was no sta-\ntistically signiﬁcant difference in the performance of LLMs in\nproviding differential diagnosis in cardiac and thoracic cases.\nThe concordance among the four LLMs were signiﬁcantly\ndifferent (chi-squared test, p ¼0.002) and the scores are\nshown in\n►Fig. 3. The acceptance also differed (chi-squared;\np ¼0.03) in the four LLMs as shown in►Fig. 4.\nDiscussion\nIn terms of concordance with expert consensus, Perplexity\nemerged as the top performer, with a little lower perfor-\nmance by ChatGPT and Bing (all had>60% concordance). This\nsuggests that the algorithm and training data used by the\nLLMs to generate diagnoses align closely with what experts\nwould determine. These concordance rates are similar to the\nconcordance rate of ChatGPT4 (69%) as reported by Kottlors\net al.\n9 Bard, with the lowest concordance rate, likely employs\nan algorithm or training data that substantially diverge from\nexpert consensus, leading to a lower level of agreement.\nExamining the acceptance rates of the generated diagno-\nses, Perplexity once again came out on top with the highest\nacceptance rate and ChatGPT and Bing also had an accep-\ntance rate greater than 85%. This suggests that the diagnoses\ngenerated by these three were more likely to be accepted by\nthe evaluators. The acceptance rate was slightly lower than\nFig. 2 Percentage of concordance and acceptance of diagnoses. LLM,\nlarge language model.\nTable 3 Domain wise concordance and acceptance of diagnoses provided by four large language models\nLLM Category Concordance p-Value (binomial) Acceptance p-Value (binomial)\nYes No Yes No\nn (%) n (%)\nChatGPT Thorax ( n ¼50) 29 (58) 21 (42) 0.26 41 (82) 9 (18) <0.0001\na\nCardiac (n ¼25) 20 (80) 5 (20) 0.004 a 23 (92) 2 (8) <0.0001a\np (chi-squared) 0.07 – 0.32 –\nBard Thorax ( n ¼50) 23 (46) 27 (54) 0.67 34 (68) 16 (32) 0.02 a\nCardiac (n ¼25) 11 (44) 14 (56) 0.69 19 (76) 6 (24) 0.009 a\np (chi-squared) 0.87 – 0.47 –\nBing Thorax ( n ¼50) 32 (64) 18 (36) 0.06 a 45 (90) 5 (10) <0.0001a\nCardiac (n ¼25) 15 (60) 10 (40) 0.33 22 (88) 3 (12) 0.0002 a\np (chi-squared) 0.74 – 0.79 –\nPerplexity Thorax ( n ¼50) 33 (66) 17 (34) 0.03 a 47 (94) 3 (6) <0.0001a\nCardiac (n ¼25) 17 (68) 8 (32) 0.08 21 (84) 4 (16) 0.009 a\np (chi-squared) 0.86 – 0.16 –\naStatistically signiﬁcant p-Value of binomial test.\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al.272\n\nthat of ChatGPT4 (94%) as reported by Kottlors et al.9 Bard,\nwith the lowest acceptance rate (69.33%), likely generated\ndiagnoses that were less frequently deemed acceptable. This\ncould be due to variation and limitations in algorithm or\ntraining data, resulting in diagnoses that were different\nacross different LLMs. However, exploring the underlying\ncause was beyond the scope of this study.\nIn the context of concordance, only cardiac domain for\nChatGPT, thorax domain for Bing, and thorax domain for\nPerplexity showed signiﬁcance. However, in other instances,\nthe score was not signiﬁcantly different, which indicates that\nresponses of the models are not necessarily generating\ndifferential diagnosis like human experts. However, all\nLLMs demonstrated signiﬁcance in acceptance across the\ndomains. This implies that regardless of the speciﬁc medical\ndomain (cardiac or thorax), all of these language models\nproduced diagnoses or assessments that were considered\nacceptable by evaluators or domain experts. This uniform\nsigniﬁcance in acceptance underscores the overall compe-\ntence of these LLMs in generating diagnoses that are deemed\nsuitable or credible in both the cardiac and thorax domains.\nWhen we compared the overall score of concordance and\nacceptance, there was signiﬁcant difference in concordance\nand acceptance rates among LLMs. The signiﬁcant differ-\nences in acceptance rates and concordance levels among the\nfour LLMs were likely the result of a combination of factors,\nincluding algorithm design, training data, model complexity,\ndomain-speciﬁc knowledge, potential bias, postprocessing\nmethods, and variability in evaluator perspectives. However,\nas a radiologist, for clinical purposes, a careful consideration\nof concordance and acceptance may be the priority for\nselecting the LLMs in generating the most signiﬁcant differ-\nential diagnoses within the realm of cardiovascular and\nthoracic imaging patterns, and potentially other subspecial-\nties in radiology. Concordance and acceptance are two\nimportant metrics to assess the performance of LLMs. A\nhigher level of concordance indicates a closer alignment\nwith expert consensus. Therefore, an LLM with higher con-\ncordance and acceptance is preferred.\nWhile LLMs have been explored in various domains of\nmedical decision-making,\n10–13 our study is an addition to the\nknowledge of AI in radiology, especially for the cardiothorac-\nic imaging pattern. This study may be beneﬁcial for radiol-\nogists in training who aim to strike a balance between\nclinical efﬁciency and ongoing knowledge acquisition. More-\nover, the study holds the potential to guide the development\nof LLM-based decision support systems tailored for cardio-\nvascular and thoracic imaging interpretation. Such systems\ncould empower health care professionals to make more\ninformed decisions, improving patient outcomes and con-\ntributing to the ongoing evolution of personalized medicine.\nIn addition, this study holds importance in teaching radiolo-\ngy and facilitating self-directed learning for students in the\nmedical ﬁeld.\n14 They can utilize this information to make\njudicious decisions about which LLMs to integrate into\neducational resources, ensuring that students have access\nto materials with the highest concordance rates and accep-\ntance levels.\nHowever, in some instances, the LLMs may fail to provide\na credible answer. For an example,\n►Fig. 5shows the answer\nby ChatGPT3.5 to the question–“ Think you are a radiologist.\nPlease provide me with the topﬁve differential diagnoses of\ndiffuse ground-glass nodules on HRCT thorax.” The answer\nneither had concordance nor acceptance. Hence, users\nshould be careful while using LLMs for patient care and\nalways remember the limitation of AI.\nNovelty and Limitation\nTo the best of our knowledge, this is the initial study\nevaluating the capabilities of four LLMs in generating appro-\npriate lists of potential diagnoses based on textual descrip-\ntions of image patterns in cardiothoracic radiology. It is\nimportant to note that the results presented in this report\nare preliminary, and there is a need for more comprehensive\nresearch using a structured methodology. Nevertheless, it is\nessential to emphasize that the LLMs used in this initial\nanalysis were not speciﬁcally designed and trained for the\npurpose of generating differential diagnoses from text-based\ndescriptions of image patterns in radiology.\nThere are some limitations of the study. Only two radiol-\nogists made the list of differential diagnoses and four LLMs\nwere tested. Furthermore, the study’s ﬁndings may not fully\nFig. 3 Concordance scores of four large language models (LLMs) in\noverall cases (15 imaging patterns and 75 differential diagnoses).\nFig. 4 Acceptance scores of four large language models (LLMs) in\noverall cases (15 imaging patterns and 75 differential diagnoses).\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al. 273\n\ngeneralize to real-world medical settings, where clinical\njudgment, patient history, and physical examinations play\npivotal roles in diagnosis. In addition, LLMs are continuously\nevolving technologically.15 Hence, the result at this point of\ntime may vary in the near future. Therefore, the results\nshould be interpreted with caution, recognizing the limita-\ntions. In addition, we only used textual input to get response\nfrom the LLMs and did not feed any image. However, our\nstudy functions as a demonstration of the capability of LLMs\nto produce pertinent differential diagnoses tailored to dis-\ntinct imaging patterns. Consequently, it underscores their\npotential in offering support for diagnostic decision-making.\nConclusion\nThis study sheds light on the varying performance of LLMs in\npredicting medical differential diagnoses from cardiothorac-\nic imaging patterns. There was acceptance of differential\ndiagnoses generated by LLMs, but their concordance with\nexpert radiologists was low. Signiﬁcant differences were also\nobserved in acceptance rates and concordance levels among\nthe LLMs. Hence, it is important to carefully select the\nsuitable model for usage in patient care or in medical\neducation. The four different LLMs tested here currently\nhold great potential in providing relevant differential diag-\nnoses from text-based descriptions of image patterns in\ncardiothoracic radiology.\nFunding\nNone.\nConﬂict of Interest\nNone declared.\nAcknowledgments\nThe corresponding author would like to thank Sarika\nMondal and Ahana Aarshi for their sacriﬁce of family\ntime during data analysis, interpretation, visualization,\npreparation, and handling of the manuscript on journal\nmanagement system.\nReferences\n1 Hussain S, Mubeen I, Ullah N, et al. Modern diagnostic imaging\ntechnique applications and risk factors in the medicalﬁeld: a\nreview. BioMed Res Int 2022;2022:5164970\n2 Alberts IL, Mercolli L, Pyka T, et al. Large language models (LLM)\nand ChatGPT: what will the impact on nuclear medicine be? Eur J\nNucl Med Mol Imaging 2023;50(06):1549–1552\nFig. 5 An example answer by ChatGPT-3.5 where the differential diagnoses were neither concordant nor acceptable.\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al.274\n\n3 De Angelis L, Baglivo F, Arzilli G, et al. ChatGPT and the rise of large\nlanguage models: the new AI-driven infodemic threat in public\nhealth. Front Public Health 2023;11:1166120\n4 Kumari A, Kumari A, Singh A, et al. Large language models in\nhematology case solving: a comparative study of ChatGPT-3.5,\nGoogle Bard, and Microsoft Bing. Cureus 2023;15(08):e43861\n5 Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF,\nTing DSW. Large language models in medicine. Nat Med 2023;29\n(08):1930–1940\n6 Rao A, Kim J, Kamineni M, Pang M, Lie W, Dreyer KJ, Succi MD.\nEvaluating GPT as an adjunct for radiologic decision making: GPT-\n4 versus GPT-3.5 in a breast imaging pilot. J Am Coll Radiol 2023;\n20(10):990–997\n7 Bhayana R, Krishna S, Bleakney RR. Performance of ChatGPT on a\nradiology board-style examination: insights into current\nstrengths and limitations. Radiology 2023;307(05):e230582\n8 Currie G, Singh C, Nelson T, Nabasenja C, Al-Hayek Y, Spuur K.\nChatGPT in medical imaging higher education. Radiography\n2023;29(04):792–799\n9 Kottlors J, Bratke G, Rauen P, et al. Feasibility of differential\ndiagnosis based on imaging patterns using a large language\nmodel. Radiology 2023;308(01):e231167\n10 Davies SG. Chapman & Nakielny’s Aids to Radiological Differential\nDiagnosis. 6th ed. Edinburg: Elsevier Saunders; 2014\n11 Elkassem AA, Smith AD. Potential use cases for ChatGPT in\nradiology reporting. AJR Am J Roentgenol 2023;221(03):373–376\n12 Schukow C, Smith SC, Landgrebe E, et al. Application of ChatGPT in\nroutine diagnostic pathology: promises, pitfalls, and potential\nfuture directions. Adv Anat Pathol 2023 (e-pub ahead of print).\nDoi: 10.1097/PAP.0000000000000406\n13 Liu J, Wang C, Liu S. Utility of ChatGPT in clinical practice. J Med\nInternet Res 2023;25:e48568\n14 Mondal H, Mondal S, Podder I. Using ChatGPT for writing articles\nfor patients’education for dermatological diseases: a pilot study.\nIndian Dermatol Online J 2023;14(04):482–486\n15 Tsang R. Practical applications of ChatGPT in undergraduate\nmedical education. J Med Educ Curric Dev 2023;10:238212\n05231178449\nIndian Journal of Radiology and Imaging Vol. 34 No. 2/2024 © 2023. Indian Radiological Association. All rights reserved.\nChatbots in Radiological Differential Diagnosis Sarangi et al. 275\n",
  "topic": "Concordance",
  "concepts": [
    {
      "name": "Concordance",
      "score": 0.7788519263267517
    },
    {
      "name": "Perplexity",
      "score": 0.7671463489532471
    },
    {
      "name": "Medical diagnosis",
      "score": 0.7524258494377136
    },
    {
      "name": "Differential diagnosis",
      "score": 0.639051079750061
    },
    {
      "name": "Medicine",
      "score": 0.6047609448432922
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5872139930725098
    },
    {
      "name": "Radiology",
      "score": 0.45933687686920166
    },
    {
      "name": "Pathology",
      "score": 0.22436046600341797
    },
    {
      "name": "Language model",
      "score": 0.20966953039169312
    },
    {
      "name": "Internal medicine",
      "score": 0.16688916087150574
    },
    {
      "name": "Computer science",
      "score": 0.1608026921749115
    },
    {
      "name": "Natural language processing",
      "score": 0.1364276111125946
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4396570500",
      "name": "All India Institute of Medical Sciences, Deoghar",
      "country": null
    },
    {
      "id": "https://openalex.org/I172917736",
      "name": "Christian Medical College, Vellore",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I193073490",
      "name": "Siksha O Anusandhan University",
      "country": "IN"
    }
  ]
}