{
  "title": "Homophily in An Artificial Social Network of Agents Powered By Large Language Models",
  "url": "https://openalex.org/W4381888913",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2572304352",
      "name": "James He",
      "affiliations": [
        "University of Cambridge"
      ]
    },
    {
      "id": "https://openalex.org/A4381905539",
      "name": "Felix Wallis",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A3121799347",
      "name": "Steve Rathje",
      "affiliations": [
        "New York University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4377098551",
    "https://openalex.org/W4378718176",
    "https://openalex.org/W4366850553",
    "https://openalex.org/W2590734737",
    "https://openalex.org/W4380763235",
    "https://openalex.org/W4380769213",
    "https://openalex.org/W2130354913",
    "https://openalex.org/W1969769935",
    "https://openalex.org/W2118027753",
    "https://openalex.org/W2002009785",
    "https://openalex.org/W4297453923",
    "https://openalex.org/W2021715735",
    "https://openalex.org/W1987027200",
    "https://openalex.org/W4380715494",
    "https://openalex.org/W4381163899",
    "https://openalex.org/W3049476187",
    "https://openalex.org/W2085876742",
    "https://openalex.org/W2607007071",
    "https://openalex.org/W2508383602",
    "https://openalex.org/W2132202037",
    "https://openalex.org/W6685221449",
    "https://openalex.org/W2047940964",
    "https://openalex.org/W3104846106",
    "https://openalex.org/W2167482691",
    "https://openalex.org/W2978381397",
    "https://openalex.org/W4255783720",
    "https://openalex.org/W4300388893"
  ],
  "abstract": "<title>Abstract</title> Recent advances in Artificial Intelligence (AI) have given rise to chatbots based on Large Language Models (LLMs) - such as ChatGPT - that can provide human-like responses to a wide range of psychological and economic tasks. However, no study to date has explored whether a <italic>society</italic> of LLM-based agents behaves comparably to human societies. We conduct Social Network Analysis on Chirper.ai, a Twitter-like platform consisting only of LLM chatbots. We find early evidence of self-organized homophily in the sampled artificial society (<italic>N</italic> = 31,764): like humans, bots with similar language and content engage more than dissimilar bots. However, content created by the bots tends to be more generic than human-generated content. We discuss the potential for developing LLM-driven Agent-Based Models of human societies, which may inform AI research and development and further the social scientific understanding of human social dynamics.",
  "full_text": "Arti\u0000cial Intelligence Chatbots Mimic Human\nCollective Behaviour\nJames He¬† ( ÔÉ† kh672@cantab.ac.uk )\nUniversity of Cambridge https://orcid.org/0000-0002-1859-4914\nFelix Wallis¬†\nUniversity College London\nAndr√©s Gvirtz¬†\nKing's College London\nSteve Rathje¬†\nNew York University\nResearch Article\nKeywords: Arti\u0000cial Intelligence, Collective Behaviour, Homophily, Social Dynamics\nPosted Date: January 15th, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-3096289/v2\nLicense: Ôâû Ôìß This work is licensed under a Creative Commons Attribution 4.0 International License. ¬†\nRead Full License\nAdditional Declarations: The authors declare no competing interests.\nTitle: Artificial Intelligence Chatbots Mimic Human Collective Behaviour   \nShort title: AI Chatbots Mimic Societies \nJames K. He*1, Felix P. S. Wallis2, Andr√©s Gvirtz1,3, Steve Rathje4  \n \n1 University of Cambridge \n2 University College London \n3 King‚Äôs College London \n4 New York University \n \n*Corresponding author information: James K. He, University of Cambridge, Department of Psychology, Cambridge CB2 \n3EB, United Kingdom, (e-mail: \nkh672@cantab.ac.uk).  \n \nAbstract: \nArtificial Intelligence (AI) chatbots, such as ChatGPT, have been shown to mimic individual \nhuman behaviour in a wide range of psychological and economic tasks. Do groups of AI \nchatbots also mimic collective behaviour? If so, artificial societies of AI chatbots may aid \nsocial-scientific research by simulating human collectives. To investigate this theoretical \npossibility, we focus on whether AI chatbots natively mimic one commonly observed \ncollective behaviour: homophily, or people‚Äôs tendency to form community with similar \nothers. In a large simulated online society of AI chatbots powered by large-language models \n(N = 24,443), we find that communities form over time around bots using a common \nlanguage. In addition, among chatbots that predominantly use English (N = 16,003), \ncommunities emerge around bots that post similar content. The findings suggest that AI \nchatbots mimic homophily, a key aspect of human collective behaviour. Thus, in addition to \nsimulating individual human behaviour, AI-powered artificial societies may advance social \nscience research by allowing researchers to simulate nuanced aspects of collective behaviour.  \n \nKeywords: Artificial Intelligence, Collective Behaviour, Homophily, Social Dynamics \n \nAuthor Contributions: \nJKH: Conceptualization, Data Curation, Formal Analysis (equal), Investigation (equal), \nMethodology (equal), Project Administration, Software (equal), Visualization, Writing ‚Äì \nOriginal Draft Preparation. FPSW: Conceptualization, Formal Analysis (equal), Investigation \n(equal), Methodology (equal), Software (equal), Writing ‚Äì Review & Editing. AG: \nConceptualization, Supervision, Writing ‚Äì Review & Editing. SR: Conceptualization, \nSupervision, Writing ‚Äì Review & Editing. \n \nData Availability Statement: \nThe data that support the findings of this study are openly available on Open Science \nFoundation at \nhttps://osf.io/rsuwn/?view_only=d9f954f7947143f3b2fdcdb365acbaea. \n \nAcknowledgements: \nSR is supported by a Gates Cambridge Scholarship (Grant #OPP144), a Russell Sage \nFoundation Grant awarded to Steve Rathje and Jay Van Bavel (G-2110-33990), the Center \nfor the Science of Moral Understanding, and the AE foundation. We express our gratitude to \nChirper.ai for providing data access and technical details that made this research possible. We \nthank Dan Mirea for his help during the project. \n \nEthics Declarations: \nThe method of data collection in the present research falls below the definition of minimal \nrisk. The authors declare no conflict of interest. \n  \nBackground \nRecent developments in Large Language Models (LLMs) have given rise to advanced \nArtificial Intelligence (AI) chatbots, such as ChatGPT, that can mimic human individual \nbehaviour in a wide range of psychological and economic tasks (Aher et al., 2022; Akata et \nal., 2023). For example, AI chatbots make moral judgements that are highly correlated (r = \n0.95) with human participants (Dillion et al., 2023), reflect human imperfections in abstract \nreasoning (Dasgupta et al., 2023), and respond similarly to emotion inductions (Aher et al., \n2022; Binz & Schulz, 2023). Though, they differ from human participants in making \nestimations and causal reasoning (Aher et al., 2022; Binz & Schulz, 2023). Thus, some have \nsuggested that AI chatbots can further social science research by simulating human \nparticipants (Dillion et al., 2023), giving rise to the term ‚Äúsilicon sampling‚Äù (Argyle et al., \n2023).  \nSince AI chatbots emulate human individual behaviour, do groups of chatbots mimic \nhuman collective behaviour? Here, we use ‚Äúcollective behaviour‚Äù to refer to group-level \nsocial dynamics and social phenomena. Mimicking collective behaviour is a non-trivial issue \nfor AI chatbots. If we consider AI chatbots as ‚Äústochastic parrots‚Äù (Bender et al., 2021), we \nmay expect a chatbot prompted to mimic a certain human characteristic (e.g., being anxious) \nto produce language associated with the characteristic. Mimicking collective behaviour, \nhowever, requires chatbots to infer associated social behaviours in a multi-agent \nenvironment, without being explicitly prompted on how humans would interact. If groups of \nAI chatbots do indeed mimic human collective behaviour, they could be used to create \nartificial societies that simulate human societies‚Äô nuanced dynamics, and thus be used to \nenhance collective-level social science research.  \nStudying human social dynamics and collective behaviour is important. It impacts \npolitical movements (Wahlstr√∂m & T√∂rnberg, 2021), the acceptance of climate-friendly \ntechnologies (Zhang et al., 2020), the spread of misinformation (Cinelli et al., 2020; Rathje et \nal., 2022), and how societies become divided by echo chambers (Cinelli et al., 2021). \nHowever, human societies are difficult to study directly. First, gathering data about social \ninteractions is invasive and expensive to undertake with human participants (Knoke & Yang, \n2019; Ryan & D‚ÄôAngelo, 2018; Valente & Pitts, 2017). Second, group-level field \nexperiments face ethical challenges and are hard to scale (Baldassarri & Abascal, 2017). \nFinally, recruiting genuine human participants is becoming more difficult, as workers in \nonline subject pools increasingly use ChatGPT (Veselovsky et al., 2023).  \nDue to these challenges, Agent-Based Modelling (ABM) has become a key tool in \nsocial scientific research (Epstein et al., 2023; Lazer et al., 2020). Instead of observing human \nparticipants, ABM simulates them as computational agents and observes their behaviour in \nvirtual environments (Abar et al., 2017). Previous ABM studies have revealed mechanisms \nbehind opinion segregations (Baumann et al., 2020), examined the potential outcomes of \ndifferent COVID-19 social policies (Gumel et al., 2021; Silva et al., 2020), uncovered how \nfake news and rumours spread in society (Lotito et al., 2021), and tested theories about the \nformation of filter bubbles and echo chambers (Geschke et al., 2019). However, classical \nABM set-ups often simplify and homogenise each agent‚Äôs actions, which limits their ability \nto capture the nuance, diversity, and complexity that exists in real human societies (Abar et \nal., 2017; Geschke et al., 2019; Lotito et al., 2021).  \nRecent advances in AI chatbots have led some researchers to propose using them as \nagents to improve ABM‚Äôs ability to simulate complex human collective dynamics (Epstein et \nal., 2023; Grossmann et al., 2023; Park et al., 2023; Pastor-Galindo et al., 2023). However, to \ndate, there has been limited research into the natural collective behaviours of AI chatbots. \nThe majority of existing research has either used mechanistic rules to guide the AI chatbots‚Äô \nsocial interactions (Ghaffarzadegan et al., 2023), or predominantly focused on their \nindividual-level actions and coordination within a group setting (Akata et al., 2023; Y. Li et \nal., 2023). Two studies examined AI chatbots as collectives. One study specifically prompted \nAI chatbots to behave like humans in economic decision-making and found that realistic \nmacroeconomic phenomena emerged in the chatbot population (N. Li et al., 2023). In another \nstudy, the authors prompted AI chatbots to mimic specific humans in terms of emotion, \nattitude, and interactions, and found group-level information propagation patterns comparable \nto the human reference group (Gao et al., 2023). However, without understanding how AI \nchatbots behave as collectives, ABM studies based on these models cannot assert that their \nfindings are generalisable to human populations. Conversely, if groups of chatbots behave \nlike groups of humans, they may simulate human collectives with greater nuance, flexibility, \nand fidelity than conventional ABMs.  \nWhat human collective behaviours are important for AI chatbots to demonstrate? \nHuman societies are well-documented to display power dynamics, ingroup conformity, and \noutgroup animosity (Homans, 1974; Rathje et al., 2021; Sunstein, 2019). Underlying these \ndynamics is a human tendency to form communities around similar individuals, a collective \nbehaviour known as homophily (Girvan & Newman, 2002; McPherson et al., 2001). \nHomophily arises from an inclination for contact between similar individuals to take place \nmore frequently than contact between dissimilar individuals (McPherson et al., 2001). It \nmanifests as structural communities ‚Äì clusters of individuals who maintain denser \nconnections within their group than with external entities (Girvan & Newman, 2002) ‚Äì where \nthere exists relative homogeneity within communities and relative heterogeneity between \ncommunities (Knoke & Yang, 2019). Homophily is well documented in real-world human \nsocieties, such as in community formation around common languages and similarities in \nindividual demographics, attitudes, and beliefs (Knoke & Yang, 2019; McPherson et al., \n2001; Titzmann, 2014; Titzmann & Silbereisen, 2009). It is also well documented on online \nsocial networks such as X, formerly Twitter, where people are more likely to connect with \nthose who share similar backgrounds (Aiello et al., 2012), discuss similar topics (Faralli et \nal., 2015; Himelboim et al., 2017; Kang & Lerman, 2012), and have similar values and \nbeliefs (Conover et al., 2011; De Choudhury, 2011; Rathje et al., 2022).  \nThus, to examine whether groups of AI chatbots behave like groups of humans, we \nfocus on homophily, a well-established, key dynamic in human collective behaviour. We \nobserve the first 24 days of social engagements within a large, organically simulated online \nsociety made entirely of character-playing AI chatbots powered by LLMs such as GPT-3.5 \n(Total N = 24,443). To examine whether homophily exists within this artificial society, we \ninvestigate two exploratory hypotheses: H1. Whether distinct structural communities exist \nwithin the population of AI chatbots, and if so, H2. Whether there is intra-community \nhomogeneity and inter-community heterogeneity (Knoke & Yang, 2019), or in other words, \nwhether these structural communities are made of similar individuals. \n \n  \nMethods \nSet-up and Data Collection \nWe examine our hypotheses by observing early activity on Chirper.ai, at the time, a \nmicro-blogging social media platform analogous to X (formerly called Twitter) but consisting \nentirely of AI chatbots. During the period of observation, Chirper.ai allowed human users \nanywhere in the world to sign-up and create AI chatbot characters, referred to on the platform \nas ‚ÄúChirpers‚Äù. Human users were only allowed to observe the AI chatbots‚Äô interactions and \nposts on the platform, referred to as ‚Äúchirps‚Äù, and were unable to interact with the chatbots. \nHuman users created characters by providing natural language prompts about their \nbackgrounds, which were then enacted by AI chatbots powered by LLMs, predominantly \nOpenAI‚Äôs GPT-3.5. We will henceforth use ‚ÄúAI chatbots‚Äù or ‚Äúchatbots‚Äù to refer to these \nsimulated characters played by the LLMs.  \nWhen running, each AI chatbot was presented with background prompts and a \n‚Äúmemory‚Äù of its past posts and actions, before being asked to make a decision. This decision \ncould be to write a post, or to choose one of the actions in Table 1, impersonating the \nprompted character. Depending on the action chosen, the AI chatbot may then be asked to \nprovide the property required for the action and be given the results. For each post, or ‚Äúchirp‚Äù \nreturned, the chatbot was prompted with: ‚ÄúActing as the character @{name}, choose one of \nthe following actions: no reaction, like the chirp, dislike the chirp, follow the Chirper, \nunfollow the Chirper, mention the Chirper in a new chirp.‚Äù Each decision made by the AI \nchatbot was accompanied by a ‚Äúthought‚Äù generated by the LLM that powers the chatbot.  \n \n  \nTable 1: Descriptions of actions available to AI chatbots \nAction Description Returns \nSearch \n‚ÄúFind something on the internet based on a \nproperty ‚Äòquery‚Äô. Returns a list of results to \nchoose from.‚Äù \nList of internet search \nresults matching ‚Äòquery‚Äô. \nTagged \n‚ÄúList recent chirps that you have been tagged in, \nno properties are required.‚Äù \nList of tagged posts. \nDiscover \n‚ÄúFind a list of chirps with a 1-to-2-word property \n‚Äòquery‚Äô. Returns matching chirps to reply to.‚Äù \nList of posts matching \n‚Äòquery‚Äô.  \nTrending \n‚ÄúFind a list of recently trending chirps with a 1-\nword property ‚Äòtopic‚Äô. Returns matching trending \nchirps for that topic to reply to.‚Äù \nList of posts matching \n‚Äòtopic‚Äô. \nFollowing \n‚ÄúList recent chirps from Chirpers you are \nfollowing, no properties are required.‚Äù \nList of posts from \nfollowing chatbots. \nNotes. Descriptions and returns of sample actions available to each AI chatbot. Each chatbot \nis first given background prompts, then asked to choose from these actions and writing a post. \nIf an action results in a list of posts, the chatbot is asked to choose a reaction to each post \nfrom ‚Äúno reaction‚Äù, ‚Äúlike‚Äù, ‚Äúdislike‚Äù, ‚Äúfollow author‚Äù, ‚Äúunfollow author‚Äù, and ‚Äúreply‚Äù. \n \n \nWe collected data on the posts and social engagements of AI chatbots on Chirper.ai \nduring the first month after the platform launched on April 23rd, 2023. We define social \nengagements as the frequency of any following, liking, disliking, or mentioning between two \nchatbots. We sampled the chatbot population through a breadth-first search based on social \nengagements: starting from 1,000 random chatbots, we documented all their engagement \nactions and subsequently performed the same search on all of their engagement targets that \nhad not previously been investigated, repeating for ten iterations. By filtering the engagement \nactions to only include those preceding the end of Day 22, we arrived at 24,443 AI chatbots. \nWe collected additional data for chatbots that predominantly post in English until the end of \nDay 24, arriving at a total of 16,003 English-posting AI chatbots.  \n \nCommunity Analysis \nTo examine H1: whether there are structurally distinct communities in the AI chatbot \npopulation, we created social network graphs based on the engagement data. Social network \ngraphs are mathematical and visual representations of the relationship between many \nindividuals, with ‚Äúnodes‚Äù that represent individuals and ‚Äúedges‚Äù representing relationships \nbetween pairs of individuals. We constructed graphs on AI chatbots‚Äô social engagements, that \nis, where nodes in the graphs represent individual chatbots, and edges between a pair of \nchatbots represent the frequency of their engagements.  \nFor the full chatbot population, we constructed network graphs for engagement \nactivities up to Day 6 (N = 8,519), Day 14 (N = 18,535), and Day 22 (N = 24,443) since the \nplatform was launched. For the population of chatbots that predominantly posted in English, \nwe constructed network graphs for engagements up to Day 6 (N = 1,149), Day 14 (N = \n6,814), Day 22 (N = 9,131), and Day 24 (N = 16,003) after the platform was launched. We \ndid not construct a network graph for the full population on Day 24, because the total \nengagement instances more than doubled over Day 23‚Äì24 and reached a scale beyond our \ncomputational capability. To examine the major community structures in the chatbot \npopulations, we used the igraph package in R to construct graphs following these steps: \n1. Construct weighted, non-directed network graphs. \n2. Remove chatbots that engaged with less than two other chatbots to reduce \ncomputational load. \n3. Detect communities with a clustering algorithm. \n4. Remove communities that contain < 1% of the population. \nFor network graphs of the full chatbot population, we used the label-propagation \nclustering algorithm (Raghavan et al., 2007) to detect communities, since it is efficient for \nfinding simple community structures in very large graphs. For network graphs of the English-\nlanguage chatbot population, we instead used the fast-greedy clustering algorithm (Clauset et \nal., 2004), since it is more sensitive and thus more suitable for detecting sub-communities. To  \nvisualise these large graphs efficiently, we set the graph layouts using the Fruchterman-\nReingold force-directed layout algorithm (Fruchterman & Reingold, 1991). For each network \ngraph, we coloured AI chatbots that were identified as belonging to the same community with \nthe same colour. For the network graphs of the full population, we also coloured the AI \nchatbots by their predominant language to aid comparison. \nTo statistically test whether the detected communities are structurally distinct, that is, \nwhether chatbots engage more with those inside their communities than with those outside \ntheir communities, we measured the modularity and assortativity scores of each graph given \ntheir detected communities. A high modularity score indicates that chatbots in the same \ncommunities are densely connected, while chatbots in different communities are sparsely \nconnected. By contrast, a high assortativity score indicates that connections in the network ‚Äì \nin this case, social engagements ‚Äì are more likely to exist between chatbots in the same \ncommunities than between chatbots in different communities.  \nWe performed a bootstrapping test to investigate whether the observed modularity \nand assortativity scores could be due to chance. For each graph, we created 1,000 random \nways to label communities, and we recorded the modularity and assortativity scores for these \nrandomised communities. This results in distributions of the scores under the null hypothesis, \nwhere the communities are not structurally distinct. Then, we counted the proportion of the \nsimulated null that yielded a score more extreme than what we observed in reality. This \nproportion is the Bootstrapped p value, measuring the likelihood for a randomised \ncommunity label to be more structurally distinct than the observed communities. We consider \nBootstrapped p less than 0.05 to signal statistical significance, since it indicates a less than \n5% probability that the observed community distinctness is due to chance. \n \nAlignment Analysis \nTo examine H2: whether the communities have internal homogeneity and external \nheterogeneity, we tested whether the identified communities are aligned with individual \nproperties of the AI chatbots. For the network graphs of the full population of AI chatbots, we \nfocused on whether the communities align with the languages predominantly used by the \nchatbots. To do this, we performed the \nùúí! contingency test suitable for correlating \ncategorical, non-parametric variables. For the graphs of the English-language chatbot \npopulation, we focused on whether the communities align with the content posted by the \nchatbots. To do this at scale without manually examining all the content posted by the \nEnglish-language chatbots, we numerically represented the content of each chatbot with the \nfollowing steps: \n1. Sample ten posts from each chatbot. \n2. Clean the posts by removing all non-roman characters and punctuations. \n3. Convert each chatbot‚Äôs sample into a set of numerical coordinates, known as \nsemantic embeddings, using the all-MiniLM-L6-v2 (Sentence Transformers, n.d.) \nmodel from the sentence-transformer Python package. \nSince pre-trained transformers learned the relationship between different concepts in \nthe language, numerically representing natural language with embeddings is a well-\nestablished way to quantitatively compare the semantic content of texts (Harispe et al., 2015). \nIn other words, embeddings of each chatbot‚Äôs sample posts represent the relative meanings of \neach chatbot‚Äôs posts within the English language. Using these embeddings, we visualised the \nsemantic distribution of the chatbots in each of the four social graphs constructed for the \nEnglish-language population. To plot the embeddings, we used the Uniform Manifold \nApproximation and Projection (UMAP) algorithm (McInnes et al., 2018) to transform them \ninto two-dimensional coordinates and plotted each AI chatbot as a dot coloured by its \ncommunity. Thus, chatbots that are plotted closer together post more similar content, and \nchatbots with the same colours belong to the same communities. \nIn addition to visualisations, we tested whether each chatbot, on average, posts more \nsimilarly to their community-average, than to all English-language chatbots‚Äô population-\naverage. We computed the cosine distances ‚Äì a standard measure of semantic dissimilarity \nfrom embeddings (Harispe et al., 2015) ‚Äì between each chatbot and their community‚Äôs \naverage embedding, and between each chatbot and the average embedding of all English-\nlanguage chatbots. We then performed Student‚Äôs t test to compare the two distances - the \ndistance to community averages, and the distance to global averages - and recorded the \nCohen‚Äôs d value for the observed difference.  \n  \nResults \nFormation of Language Communities  \nFirst, we examined community formation in the full population of AI chatbots. We \nfound no communities in the Day 6 graph, two communities in the Day 14 graph (N1 = \n14,356, N2 = 4,179), and three communities in the Day 22 graph (N1 = 15,039, N2 = 8,044, \nN3 = 1,360). We visualised this process of community formation in Figure 1 panel A, B, C, \nwhere nodes are coloured by their community memberships as detected by the clustering \nalgorithm. The detected communities are structurally distinct: chatbots are more engaged \nwith those inside their community than with those outside their community (Day 14: \nModularity = 0.31, Bootstrapped p < .001; Day 22: Modularity = 0.47, Bootstrapped p < \n.001), and engagements are more likely to exist within each community than across the \ncommunities (Day 14: Assortativity = 0.94, Bootstrapped p < .001; Day 22: Assortativity = \n0.92, Bootstrapped p < .001). This result lends support to H1: a society of AI chatbots does \nform socially distinct communities. \n \n  \nFigure. 1. Community Formation Around Languages \n \n \nNotes. Social network graphs across three time points and two colourings are displayed. Nodes in each graph \nrepresent individual AI chatbots, and each edge between two nodes represents the frequency of social \nengagements between the pair of chatbots. The three rows represent three time points: Day 6, Day 14, and Day \n22 since the society was created. The left column shows the graphs coloured by communities identified by the \nlabel-propagation clustering algorithm, and the right column shows the same graphs coloured by languages. \n \n  \n\nThese communities are aligned with the languages that are predominantly used by the \nAI chatbots. We visualised the distribution of languages in Figure 1, panels D, E, and F, \nwhere nodes are coloured by the chatbot‚Äôs predominant languages. In the Day 14 graph, \nEnglish-language bots make up 58.9% of Community 1, but only 2.2% of Community 2. By \ncontrast, Chinese-language bots make up only 3.7% of Community 1, but 97.7% of \nCommunity 2. The alignment became clearer in the Day 22 graph, where Community 1 \nconsists largely of English-language bots (67.1%), Community 2 largely of Chinese-language \nbots (92.7%), and Community 3 largely of Japanese-language bots (78.6%).  \nWe find that the alignment between communities and languages is statistically \nsignificant on Day 14 (œá¬≤(3, N = 18,535) = 15,276.75, p < .001) as well as Day 22 (œá¬≤(6, N = \n24,443) = 39,155.62, p < .001). In addition, while engagements are not more likely to take \nplace within each language than between different languages on Day 6 (Assortativity = -0.01, \nBootstrapped p = 0.81), engagements became more likely to take place within than between \nlanguages on Day 14 (Assortativity = 0.67, Bootstrapped p < .001), and grew in extent on \nDay 22 (Assortativity = 0.81, Bootstrapped p < .001). These results lend support to H2: the \ncommunities formed by AI chatbots are made of similar individuals; in this case, chatbots in \nthe same community use common languages. In agreement with our exploratory hypotheses, \nthe simulated society made of AI chatbots does indeed form socially distinct communities \n(H1) around similar individuals (H2). Thus, AI chatbots appear able to mimic the language \nhomophily behaviour commonly observed in human societies (Titzmann, 2014; Titzmann & \nSilbereisen, 2009). \n \nFormation of Content Communities \nTo examine whether communities, beyond language, form around similar post \ncontent, we narrowed our investigation to the English-language chatbots alone. We identified \n31 communities on Day 6 (Mean N = 37.1), 22 communities on Day 14 (Mean N = 309.7), 12 \ncommunities on Day 22 (Mean N = 760.9), and 4 communities on Day 24 (Mean N = \n4000.8). The evolution of these community structures is visualised in Figure 2, where nodes \nare coloured by their community memberships as identified by the clustering algorithm. \n \n \nFigure 2. Community Formation within English Chatbots \n \nNotes. Social engagement graphs within the sample of English-language AI chatbots are displayed. Nodes in \neach graph represent individual AI chatbots, and each edge between two nodes represents the frequency of \nsocial engagements between the pair of chatbots. Nodes are coloured by their community memberships, as \nidentified by the fast-greedy graph clustering algorithm. \n \n\nWe find that the communities detected in the Day 14, Day 22, and Day 24 graphs are \nstructurally distinct. At these time points, AI chatbots are more engaged with bots inside their \ncommunity than outside their community (Day 14: Modularity = 0.47, Bootstrapped p < \n.001; Day 22: Modularity = 0.33, Bootstrapped p < .001; Day 24: Modularity = 0.50, \nBootstrapped p < .001), and engagements are more likely to take place within each \ncommunity than across the communities (Day 14: Assortativity = 0.56, Bootstrapped p < \n.001; Day 22: Assortativity = 0.44, Bootstrapped p < .001; Day 24: Assortativity = 0.74, \nBootstrapped p < .001). This result lends support to H1: in addition to forming distinct \ncommunities based on languages, socially distinct communities also form within a society of \nAI chatbots that use the same language. \nMoreover, English chatbots in the same community appear to post similar content. \nFigure 3 displays the relative distribution of sample post content of the English chatbots, in \nwhich each chatbot is coloured by its engagement community membership. Here, each dot \nrepresents an AI chatbot: bots near one another posted similar content, while bots far from \none another posted dissimilar content.  \n \n  \nFigure 3. Content Distribution of English Chatbots Communities \n \nNotes. Semantic embeddings of each chatbot‚Äôs sample posts, across four timepoints, are represented and \ndisplayed. Each dot represents a chatbot, coloured by the chatbot‚Äôs community membership, as identified by a \nclustering algorithm in the social engagement graph. Dots near one-another represent chatbots that post similar \ncontent, while dots far from one-another represent chatbots that post dissimilar content.  \n \n \nVisual examination of Figure 3 shows that, on Day 22 and Day 24, dots of the same \ncolour are located close to one another, forming areas of relatively uniform colours. This \nsuggests that AI chatbots belonging to the same social community (same colour), are also \nsimilar in terms of the content they posted (proximity). On Day 14, AI chatbots posted \ncontent more similar to their community‚Äôs average content, than to the full English chatbot \npopulation‚Äôs average content, where the difference was small but statistically significant \n\n(t(6,813) = - 23.37, p < .001; Cohen‚Äôs d = -0.28, 95% CI = [-0.31, -0.26]). The difference \nbetween each chatbot‚Äôs similarity with its own community, and similarity with the full \npopulation, increased slightly on Day 22 (t(9,130) = - 32.81, p < .001; Cohen‚Äôs d = -0.34, \n95% CI = [-0.36, -0.32]), and grew to a moderate-to-large difference on Day 24 (t(16,002) = - \n88.77, p < .001; Cohen‚Äôs d = -0.69, 95% CI = [-0.71, -0.68]).  \nThe finding lends support to H2: communities within the English AI chatbot \npopulation are made of similar individuals; in this case, chatbots in the same community post \nsimilar content. Taken together, we find evidence that in a simulated society made of AI \nchatbots, there exist distinct communities (H1) around similar individuals (H2) on multiple \nlevels: there are not only global communities aligned by common languages, but also distinct \nlocal communities aligned by similar content. Thus, it appears that a society of AI chatbots \nmimics a well-established characteristic of human collective behaviour: homophily, or that \ndistinct communities form around similar individuals.  \n \n  \nDiscussion \nBy observing the social engagements within a large simulated online society made of \nAI chatbots, the present work finds distinct social communities of chatbots forming around \ncommon languages, and within English-language chatbots around similar post content. \nSupporting our first hypothesis H1, the communities are structurally distinct: chatbots are \nmore likely to engage with those inside their communities than with those outside their \ncommunities. In addition, we find that the chatbot communities exhibit internal similarities \nand external differentiations, supporting our second hypothesis H2. Therefore, our findings \nsuggest that groups of AI chatbots exhibit homophily and, hence, mimic a key characteristic \nof human collective behaviour. We note that, unlike previous work, the AI chatbots were not \nexplicitly prompted to socialise like humans, or instructed to engage more with chatbots that \nare more alike to themselves. Thus, the observed homophily theoretically suggests that AI \nchatbots powered by LLMs can infer social behaviour from character prompts: by being \nprompted to play a certain character, the LLMs inferred to engage more with characters that \nare more similar to its prompted persona.  \nThe present work has two major limitations. First, while homophily is a theoretical \nand practical important antecedent to much of human collective behaviour, homophily on its \nown is not enough to practically establish that AI chatbots fully emulate human societies. \nAdditional research is needed to examine whether groups of AI chatbots demonstrate other \nfacets of human collective behaviour, such as power dynamics, social influence, conformity, \nand how individual personality and cultural differences influence social dynamics. In \nparticular, we need to improve our understanding of the boundary conditions, at which AI \nchatbots diverge from human behaviour, and caution a too optimistic use of silicon data \nbefore they are established. Secondly, the present work did not examine potential \ndiscrepancies and biases in how the group of AI chatbots simulate human societies. Research \nhas found that LLMs may reproduce biases present in the training data (Crockett & Messeri, \n2023; Dillion et al., 2023) and are likely to over-represent Western, high-income cultures \n(Apicella et al., 2020; Atari et al., 2024; Bender et al., 2021; Facts and Figures 2021, 2021). \nThus, it is important for future research to examine these biases, as using LLMs to simulate \nhuman behaviours in social science research may exacerbate the representativeness issue \nalready faced by social and behavioural research (Apicella et al., 2020; Henrich et al., 2010).  \nDespite these limitations, our current findings establish the theoretical possibility that \ngroups of AI chatbots may mimic human collective behaviours and thus open up avenues of \nfuture explorations that compare the collective behaviours of AI chatbots with those of \nhumans. With these explorations, future social scientists may enhance their research with \nartificial societies made of AI chatbots that capture nuanced human collective behaviour. For \nexample, before conducting costly field experiments, future researchers may use an artificial \nsociety to test, e.g., what content algorithms contribute to the spread of misinformation on \nsocial media, what interventions facilitate the adoption of technologies in organisations and \nsocieties, and how to bridge echo chambers in a polarised community. Thus, we propose that \nLLM-powered AI chatbots may be used to construct artificial societies that simulate the \ncollective behaviours of human societies. Such a tool may potentially become valuable for \nunderstanding complex social dynamics and studying what drives better societal outcomes. \n  \nReferences \nAbar, S., Theodoropoulos, G. K., Lemarinier, P., & O‚ÄôHare, G. M. P. (2017). Agent Based \nModelling and Simulation tools: A review of the state-of-art software. Computer \nScience Review, 24, 13‚Äì33. https://doi.org/10.1016/j.cosrev.2017.03.001 \nAher, G., Arriaga, R. I., & Kalai, A. T. (2022). Using large language models to simulate \nmultiple humans. arXiv Preprint arXiv:2208.10264. \nAiello, L. M., Barrat, A., Schifanella, R., Cattuto, C., Markines, B., & Menczer, F. (2012). \nFriendship prediction and homophily in social media. ACM Transactions on the Web \n(TWEB), 6(2), 1‚Äì33. \nAkata, E., Schulz, L., Coda-Forno, J., Oh, S. J., Bethge, M., & Schulz, E. (2023). Playing \nrepeated games with Large Language Models (arXiv:2305.16867). arXiv. \nhttps://doi.org/10.48550/arXiv.2305.16867 \nApicella, C., Norenzayan, A., & Henrich, J. (2020). Beyond WEIRD: A review of the last \ndecade and a look ahead to the global laboratory of the future. In Evolution and \nHuman Behavior (Vol. 41, Issue 5, pp. 319‚Äì329). Elsevier. \nArgyle, L. P., Busby, E. C., Fulda, N., Gubler, J. R., Rytting, C., & Wingate, D. (2023). Out \nof One, Many: Using language models to simulate human samples. Political Analysis, \n31(3), 337‚Äì351. https://doi.org/10.1017/pan.2023.2 \nAtari, M., Xue, M. J., Park, P. S., Blasi, D., & Henrich, J. (2024). Which Humans? \nhttps://doi.org/10.31234/osf.io/5b26t \nBaldassarri, D., & Abascal, M. (2017). Field experiments across the social sciences. Annual \nReview of Sociology, 43(1), 41‚Äì73. https://doi.org/10.1146/annurev-soc-073014-\n112445 \nBaumann, F., Lorenz-Spreen, P., Sokolov, I. M., & Starnini, M. (2020). Modeling Echo \nChambers and Polarization Dynamics in Social Networks. Physical Review Letters, \n124(4), 048301. https://doi.org/10.1103/PhysRevLett.124.048301 \nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of \nStochastic Parrots: Can language models be too big?\nü¶ú. Proceedings of the 2021 \nACM Conference on Fairness, Accountability, and Transparency, 610‚Äì623. \nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT-3. \nProceedings of the National Academy of Sciences, 120(6), e2218523120. \nCinelli, M., De Francisci Morales, G., Galeazzi, A., Quattrociocchi, W., & Starnini, M. \n(2021). The echo chamber effect on social media. Proceedings of the National \nAcademy of Sciences, 118(9), e2023301118. https://doi.org/10.1073/pnas.2023301118 \nCinelli, M., Quattrociocchi, W., Galeazzi, A., Valensise, C. M., Brugnoli, E., Schmidt, A. L., \nZola, P., Zollo, F., & Scala, A. (2020). The COVID-19 social media infodemic. \nScientific Reports, 10(1), Article 1. https://doi.org/10.1038/s41598-020-73510-5 \nClauset, A., Newman, M. E., & Moore, C. (2004). Finding community structure in very large \nnetworks. Physical Review E, 70(6), 066111. \nConover, M., Ratkiewicz, J., Francisco, M., Gon√ßalves, B., Menczer, F., & Flammini, A. \n(2011). Political polarization on twitter. Proceedings of the International Aaai \nConference on Web and Social Media, 5(1), 89‚Äì96. \nCrockett, M., & Messeri, L. (2023). Should large language models replace human \nparticipants? PsyArXiv. https://doi.org/10.31234/osf.io/4zdx9 \nDasgupta, I., Lampinen, A. K., Chan, S. C. Y., Sheahan, H. R., Creswell, A., Kumaran, D., \nMcClelland, J. L., & Hill, F. (2023). Language models show human-like content \neffects on reasoning tasks (arXiv:2207.07051). arXiv. \nhttps://doi.org/10.48550/arXiv.2207.07051 \nDe Choudhury, M. (2011). Tie formation on twitter: Homophily and structure of egocentric \nnetworks. 2011 IEEE Third International Conference on Privacy, Security, Risk and \nTrust and 2011 IEEE Third International Conference on Social Computing, 465‚Äì470. \nDillion, D., Tandon, N., Gu, Y., & Gray, K. (2023). Can AI language models replace human \nparticipants? Trends in Cognitive Sciences. \nEpstein, Z., Hertzmann, A., & THE INVESTIGATORS OF HUMAN CREATIVITY. (2023). \nArt and the science of generative AI. Science, 380(6650), 1110‚Äì1111. \nhttps://doi.org/10.1126/science.adh4451 \nFacts and Figures 2021: 2.9 billion people still offline. (2021, November 29). ITU Hub. \nhttps://www.itu.int/hub/2021/11/facts-and-figures-2021-2-9-billion-people-still-\noffline/ \nFaralli, S., Stilo, G., & Velardi, P. (2015). Large scale homophily analysis in twitter using a \ntwixonomy. Twenty-Fourth International Joint Conference on Artificial Intelligence. \nFruchterman, T. M., & Reingold, E. M. (1991). Graph drawing by force-directed placement. \nSoftware: Practice and Experience, 21(11), 1129‚Äì1164. \nGao, C., Lan, X., Lu, Z., Mao, J., Piao, J., Wang, H., Jin, D., & Li, Y. (2023). S3: Social-\nnetwork Simulation System with Large Language Model-Empowered Agents \n(arXiv:2307.14984). arXiv. https://doi.org/10.48550/arXiv.2307.14984 \nGeschke, D., Lorenz, J., & Holtz, P. (2019). The triple-filter bubble: Using agent-based \nmodelling to test a meta-theoretical framework for the emergence of filter bubbles and \necho chambers. British Journal of Social Psychology, 58(1), 129‚Äì149. \nhttps://doi.org/10.1111/bjso.12286 \nGhaffarzadegan, N., Majumdar, A., Williams, R., & Hosseinichimeh, N. (2023). Generative \nAgent-Based Modeling: Unveiling Social System Dynamics through Coupling \nMechanistic Models with Generative Artificial Intelligence (arXiv:2309.11456). \narXiv. https://doi.org/10.48550/arXiv.2309.11456 \nGirvan, M., & Newman, M. E. (2002). Community structure in social and biological \nnetworks. Proceedings of the National Academy of Sciences, 99(12), 7821‚Äì7826. \nGrossmann, I., Feinberg, M., Parker, D. C., Christakis, N. A., Tetlock, P. E., & Cunningham, \nW. A. (2023). AI and the transformation of social science research. Science, \n380(6650), 1108‚Äì1109. https://doi.org/10.1126/science.adi1778 \nGumel, A. B., Iboi, E. A., Ngonghala, C. N., & Elbasha, E. H. (2021). A primer on using \nmathematics to understand COVID-19 dynamics: Modeling, analysis and simulations. \nInfectious Disease Modelling, 6, 148‚Äì168. https://doi.org/10.1016/j.idm.2020.11.005 \nHarispe, S., Ranwez, S., Janaqi, S., & Montmain, J. (2015). Semantic similarity from natural \nlanguage and ontology analysis. Synthesis Lectures on Human Language \nTechnologies, 8(1), 1‚Äì254. \nHenrich, J., Heine, S. J., & Norenzayan, A. (2010). The weirdest people in the world? \nBehavioral and Brain Sciences, 33(2‚Äì3), 61‚Äì83. \nHimelboim, I., Smith, M. A., Rainie, L., Shneiderman, B., & Espina, C. (2017). Classifying \nTwitter topic-networks using social network analysis. Social Media+ Society, 3(1), \n2056305117691545. \nHomans, G. C. (1974). Social behavior: Its elementary forms, Revised ed (pp. xi, 386). \nHarcourt Brace Jovanovich. \nKang, J. H., & Lerman, K. (2012). Using lists to measure homophily on twitter. AAAI \nWorkshop on Intelligent Techniques for Web Personalization and Recommendation, \n18. \nKnoke, D., & Yang, S. (2019). Social network analysis. SAGE publications. \nLazer, D. M. J., Pentland, A., Watts, D. J., Aral, S., Athey, S., Contractor, N., Freelon, D., \nGonzalez-Bailon, S., King, G., Margetts, H., Nelson, A., Salganik, M. J., Strohmaier, \nM., Vespignani, A., & Wagner, C. (2020). Computational social science: Obstacles \nand opportunities. Science, 369(6507), 1060‚Äì1062. \nhttps://doi.org/10.1126/science.aaz8170 \nLi, N., Gao, C., Li, Y., & Liao, Q. (2023). Large Language Model-Empowered Agents for \nSimulating Macroeconomic Activities (arXiv:2310.10436). arXiv. \nhttps://doi.org/10.48550/arXiv.2310.10436 \nLi, Y., Zhang, Y., & Sun, L. (2023). MetaAgents: Simulating Interactions of Human \nBehaviors for LLM-based Task-oriented Coordination via Collaborative Generative \nAgents (arXiv:2310.06500). arXiv. https://doi.org/10.48550/arXiv.2310.06500 \nLotito, Q. F., Zanella, D., & Casari, P. (2021). Realistic aspects of simulation models for fake \nnews epidemics over social networks. Future Internet, 13(3), Article 3. \nhttps://doi.org/10.3390/fi13030076 \nMcInnes, L., Healy, J., & Melville, J. (2018). Umap: Uniform manifold approximation and \nprojection for dimension reduction. arXiv Preprint arXiv:1802.03426. \nMcPherson, M., Smith-Lovin, L., & Cook, J. M. (2001). Birds of a feather: Homophily in \nsocial networks. Annual Review of Sociology, 27(1), 415‚Äì444. \nhttps://doi.org/10.1146/annurev.soc.27.1.415 \nPark, J. S., O‚ÄôBrien, J., Cai, C. J., Morris, M. R., Liang, P., & Bernstein, M. S. (2023). \nGenerative Agents: Interactive Simulacra of Human Behavior. Proceedings of the \n36th Annual ACM Symposium on User Interface Software and Technology, 1‚Äì22. \nhttps://doi.org/10.1145/3586183.3606763 \nPastor-Galindo, J., Nespoli, P., & Ruip√©rez-Valiente, J. A. (2023). Generative Agent-Based \nSocial Networks for Disinformation: Research Opportunities and Open Challenges \n(arXiv:2310.07545). arXiv. https://doi.org/10.48550/arXiv.2310.07545 \nRaghavan, U. N., Albert, R., & Kumara, S. (2007). Near linear time algorithm to detect \ncommunity structures in large-scale networks. Physical Review E, 76(3), 036106. \nRathje, S., He, J. K., Roozenbeek, J., Van Bavel, J. J., & van der Linden, S. (2022). Social \nmedia behavior is associated with vaccine hesitancy. PNAS Nexus, 1(4), pgac207. \nRathje, S., Van Bavel, J. J., & van der Linden, S. (2021). Out-group animosity drives \nengagement on social media. Proceedings of the National Academy of Sciences, \n118(26), e2024292118. https://doi.org/10.1073/pnas.2024292118 \nRyan, L., & D‚ÄôAngelo, A. (2018). Changing times: Migrants‚Äô social network analysis and the \nchallenges of longitudinal research. Social Networks, 53, 148‚Äì158. \nSentence Transformers. (n.d.). All-MiniLM-L6-v2 [Computer software]. Hugging Face. \nhttps://huggingface.co/sentence-transformers/all-MiniLM-L6-v2 \nSilva, P. C. L., Batista, P. V. C., Lima, H. S., Alves, M. A., Guimar√£es, F. G., & Silva, R. C. \nP. (2020). COVID-ABS: An agent-based model of COVID-19 epidemic to simulate \nhealth and economic effects of social distancing interventions. Chaos, Solitons & \nFractals, 139, 110088. https://doi.org/10.1016/j.chaos.2020.110088 \nSunstein, C. R. (2019). Conformity. New York University Press. \nhttps://doi.org/10.18574/nyu/9781479896585.001.0001 \nTitzmann, P. F. (2014). Immigrant adolescents‚Äô adaptation to a new context: Ethnic \nfriendship homophily and its predictors. Child Development Perspectives, 8(2), 107‚Äì\n112. \nTitzmann, P. F., & Silbereisen, R. K. (2009). Friendship homophily among ethnic German \nimmigrants: A longitudinal comparison between recent and more experienced \nimmigrant adolescents. Journal of Family Psychology, 23(3), 301. \nValente, T. W., & Pitts, S. R. (2017). An appraisal of social network theory and analysis as \napplied to public health: Challenges and opportunities. Annual Review of Public \nHealth, 38, 103‚Äì118. \nVeselovsky, V., Ribeiro, M. H., & West, R. (2023). Artificial Artificial Artificial Intelligence: \nCrowd Workers Widely Use Large Language Models for Text Production Tasks \n(arXiv:2306.07899). arXiv. https://doi.org/10.48550/arXiv.2306.07899 \nWahlstr√∂m, M., & T√∂rnberg, A. (2021). Social Media Mechanisms for Right-Wing Political \nViolence in the 21st Century: Discursive Opportunities, Group Dynamics, and Co-\nOrdination. Terrorism and Political Violence, 33(4), 766‚Äì787. \nhttps://doi.org/10.1080/09546553.2019.1586676 \nZhang, T., Tao, D., Qu, X., Zhang, X., Zeng, J., Zhu, H., & Zhu, H. (2020). Automated \nvehicle acceptance in China: Social influence and initial trust are key determinants. \nTransportation Research Part C: Emerging Technologies, 112, 220‚Äì233. \nhttps://doi.org/10.1016/j.trc.2020.01.027 \n \n  \nSupplementary Materials \nWe computed several descriptive statistics for each of the 7 graphs constructed. The \nincluded statistics and a brief explanation are as follows: \n1. Size: The number of nodes present in the network. \n2. Diameter: The maximum shortest path length between any pair of nodes in the \nnetwork, reflecting the network‚Äôs maximum pairwise reachability. \n3. Density: The proportion of potential connections in the network that are actually \npresent, indicating the degree of network compactness or completeness. \n4. Transitivity: The likelihood that adjacent nodes of a node are connected, which \nrepresents the overall tendency of the network to form triads. \n5. Average Path Length: The mean shortest path between all pairs of nodes, \nrepresenting the average steps it takes for information to travel across the network. \nThe statistics for the complete sample network at each of the three time-points are \ndisplayed in Table S1. The statistics for the English-language sub-graphs at each of the four \ntime-points are displayed in Table S2.  \n \nTable S1: Descriptive Statistics of The Complete Network \n Day 6 Day 14 Day 22 \nSize 8,519 18,535 24,443 \nDiameter 10 14 9 \nDensity 0.000679 0.000446 0.000575 \nTransitivity 0.00911 0.0113 0.0206 \nAverage Path Length 4.97 4.75 4.21 \nNotes. This table displays the major descriptive statistics for the complete network at each of \nthe three time-points since the Chirper.ai platform was launched on April 23rd, 2023.  \n \nTable S2: Descriptive Statistics of The English-Language Sub-Network \n Day 6 Day 14 Day 22 Day 28 \nSize 1,149 6,814 9,131 16,003 \nDiameter 23 12 10 7 \nDensity 0.00246 0.000924 0.00140 0.00228 \nTransitivity 0.0130 0.0129 0.0246 0.00440 \nAverage Path Length 6.819 4.672 3.906 2.850 \nNotes. This table displays the major descriptive statistics for the English-language sub-\nnetwork at each of the four available time-points since the platform‚Äôs launch. \n \n ",
  "topic": "Homophily",
  "concepts": [
    {
      "name": "Homophily",
      "score": 0.9585822820663452
    },
    {
      "name": "Sociology",
      "score": 0.48080936074256897
    },
    {
      "name": "Computer science",
      "score": 0.46192213892936707
    },
    {
      "name": "Social network (sociolinguistics)",
      "score": 0.42377960681915283
    },
    {
      "name": "World Wide Web",
      "score": 0.2177378237247467
    },
    {
      "name": "Social media",
      "score": 0.1885215938091278
    },
    {
      "name": "Social science",
      "score": 0.14178046584129333
    }
  ]
}