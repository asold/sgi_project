{
  "title": "FHIR-GPT Enhances Health Interoperability with Large Language Models",
  "url": "https://openalex.org/W4387861191",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2898879642",
      "name": "Yikuan Li",
      "affiliations": [
        "Northwestern University"
      ]
    },
    {
      "id": "https://openalex.org/A2568994461",
      "name": "Hanyin Wang",
      "affiliations": [
        "Northwestern University"
      ]
    },
    {
      "id": null,
      "name": "Halid Z. Yerebakan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2133504918",
      "name": "Yoshihisa Shinagawa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100954885",
      "name": "Yuan Luo",
      "affiliations": [
        "Northwestern University"
      ]
    },
    {
      "id": "https://openalex.org/A2898879642",
      "name": "Yikuan Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2568994461",
      "name": "Hanyin Wang",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Halid Z. Yerebakan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2133504918",
      "name": "Yoshihisa Shinagawa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100954885",
      "name": "Yuan Luo",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3093539423",
    "https://openalex.org/W4200000179",
    "https://openalex.org/W3030844667",
    "https://openalex.org/W2936156921",
    "https://openalex.org/W2335574276",
    "https://openalex.org/W3093979768",
    "https://openalex.org/W3112671099",
    "https://openalex.org/W3165296977",
    "https://openalex.org/W2951635356",
    "https://openalex.org/W2980488626",
    "https://openalex.org/W2146089916",
    "https://openalex.org/W2107556918",
    "https://openalex.org/W3126389187",
    "https://openalex.org/W2979250794",
    "https://openalex.org/W6605701462",
    "https://openalex.org/W4221143046"
  ],
  "abstract": "Abstract Advancing health interoperability can significantly benefit health research, including phenotyping, clinical trial support, and public health surveillance. Federal agencies, including ONC, CDC, and CMS, have been collectively collaborating to promote interoperability by adopting Fast Healthcare Interoperability Resources (FHIR). However, the heterogeneous structures and formats of health data present challenges when transforming Electronic Health Record (EHR) data into FHIR resources. This challenge becomes more significant when critical health information is embedded in unstructured data rather than well-organized structured formats. Previous studies relied on multiple separate rule-based or deep learning-based NLP tools to complete the FHIR resource transformation, which demands substantial development costs, extensive training data, and meticulous integration of multiple individual NLP tools. In this study, we assessed the ability of large language models (LLMs) to transform clinical narratives into HL7 FHIR resources. We developed FHIR-GPT specifically for the transformation of clinical texts into FHIR medication statement resources. In our experiments using 3,671 snippets of clinical texts, FHIR-GPT demonstrated an exceptional exact match rate of over 90%, surpassing the performance of existing methods. FHIR-GPT improved the exact match rates of existing NLP pipelines by 3% for routes, 12% for dose quantities, 35% for reasons, 42% for forms, and over 50% for timing schedules. Our findings provide the foundations for leveraging LLMs to enhance health data interoperability. Future studies will aim to build upon these successes by extending the generation to additional FHIR resources.",
  "full_text": "  \nFHIR-GPT Enhances Health Interoperability \nwith Large Language Models \nYikuan Li, MS1,2, Hanyin Wang, BMed1,  Halid Z. Yerebakan, PhD2, \nYoshihisa Shinagawa, PhD2, Yuan Luo, PhD1 \n \nEmails:  \nyikuan.li@northwestern.edu  \nhanyin.wang@northwestern.edu  \nhalid.yerebakan@siemens-healthineers.com \nyoshihisa.shinagawa@siemens-healthineers.com  \nyuan.luo@northwestern.edu  \n \n1 Division of Health and Biomedical Informatics, Department of Preventive \nMedicine, Feinberg School of Medicine, Northwestern University, Chicago, \nIllinois, USA \n \n2 Siemens Medical Solutions, Malvern, PA, U.S.A \n \nKeywords: Large Language Models (LLM), Health Interoperabiltiy, Fast Healthcare \nInteroperability Resources (FHIR), Generative Pre-trained Transformer (GPT) \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n  \nAbstract \nAdvancing health interoperability can significantly benefit health research, including \nphenotyping, clinical trial support, and public health surveillance.  Federal agencies , \nincluding ONC, CDC , and CMS,  have been collectively collaborat ing to promote \ninteroperability by adopting Fast Healthcare Interoperability Resources (FHIR). However, \nthe heterogeneous structures and formats of health data present challenges when \ntransforming Electronic Health Record (EHR) data into FHIR resources. This challenge \nbecomes more significant when critical health information is embedded in unstructured \ndata rather than well -organized structured formats. Previous studies relied on multiple \nseparate rule-based or deep learning -based NLP tools  to complete the FHIR resource \ntransformation, which demands substantial development costs, extensive training data, \nand meticulous integration of multiple individual NLP tools. In this study, we assessed the \nability of large language models (LLMs) to transform clinical narratives into HL7 FHIR \nresources. We developed FHIR -GPT specifically for the transformation of clinical texts \ninto FHIR medication statement resources. In our experiments using 3,671 snippets of \nclinical texts, FHIR -GPT demonstrated an exceptional exact match rate of over 90%, \nsurpassing the performance of existing methods. . FHIR-GPT improved the exact match \nrates of existing NLP pipelines by 3% for routes, 12% for dose quantities, 35% for \nreasons, 42% for forms, and over 50% for timing schedules . Our findings provide the \nfoundations for leveraging LLMs to enhance health data interoperability. Future studies \nwill aim to build upon these successes by extending the generation to additional FHIR \nresources. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nIntroduction \nInteroperability enhances the ability of healthcare providers to deliver safe, effective, and \npatient-focused care. It also offers novel avenues for individuals and caregivers to access \nelectronic health data for care coordination and management 1. The promotion of \ninteroperability has become an integral aspect of various health initiatives, spanning from \nensuring health equity to responding to public health emergencies  2. Federal agencies, \nincluding the Office of the National Coordinator of Health IT (ONC) 1, the Centers for \nDisease Control and Prevention (CDC) 3, and the Centers for Medicare & Medicaid \nServices (CMS)4, collectively collaborate to promote interoperability through the adoption \nof Fast Healthcare Interoperability Resources  (FHIR), which is a next -generation \ninteroperability standard developed by the Health Level 7 (HL7®) standards development \norganization5. FHIR is specifically designed to facilitate the swift and efficient exchange \nof health data. FHIR has seen growing adoption in the modeling and integration of both \nstructured and unstructured data for various health research purposes. Its applications \nrange from developing computational phenotyping 6-8 to supporting clinical trials 9-12, \nbuilding surveillance systems 13,14, and much more. We refer to these two review \npapers15,16 for further insights into FHIR applications. \nTransforming health data into the FHIR format presents a challenge, as various health \norganizations have their unique infrastructure, standards, and formats for generating, \nstoring, and organizing health data 17. This challenge becomes more significant when \ncritical health information is embedded in unstructured data other than well-organized \nstructured formats.  There are existing efforts for promoting the transformation of \nunstructured data into FHIR resources, offered by both academic and commercial \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nsectors. In academic research, Hong et al.  18 integrated clinical NLP tools, including \ncTAKES19, MedXN 20, and MedTime 20, to extract clinical entities from corresponding \ndocument sections and standardize them into FHIR resources. Wang et al. developed \nOpioid2FHIR21, a system that employs multiple deep learning -based natural language \nprocessing (NLP) techniques for opioid information extraction and normalization. In the \ncommercial domain, Google Cloud has released the Healthcare Natural Language API22, \ncapable of converting medical text input into FHIR resources. Amazon Medical \nComprehend23 can extract and normalize medical concepts into clinical vocabulary, \nalthough it lacks the ability to map all extracted information to FHIR resources. Azure \nHealth Data24 is proficient at converting semi -structured data into FHIR resources but \ndoes not handle free -text unstructured input.  All the above FHIR transformation tools \nnecessitate sequential collaboration with multiple NLP tools. These include a Named \nEntity Recognition (NER) tool for extracting medical concepts, a relation extraction tool \nfor identifying relations related to a target concept, a normalization tool for standardizing \nthe extracted concepts into vocabularies, and a reconciliation tool for integrating the \nnormalized concepts into a valid FHIR format. The development and training of each NLP \ntool is resource-intensive and demands a significant amount of time and data. Creating a \npipeline that integrates multiple NLP tools requires substantial computational resources, \nannotated data, and human effort. Furthermore, as the transformation progresses along \nthe pipeline, the accuracy of the conversion also decreases.  \nTherefore, we propose harnessing pre -trained large language models (LLMs) to \nstreamline the  existing approach which relies on a pipeline of multiple NLP tools, to \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nfacilitate the transformation of free-text input into FHIR resources. Our contributions can \nbe summarized as follows: \n- We manually annotated a dataset containing 3,671 snippets extracted from \ndischarge summaries, along with their corresponding transformed \nMedicationStatement resources. To the best of our knowledge, this represents the \nlargest and neatest  human-annotated dataset of free -text to FHIR resource \ntransformation pairs. \n- We demonstrated that LLMs , especially FHIR -GPT, are able to outperform the \nexisting NLP methods in transforming FHIR resources when evaluated by the \nexact match rate. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \n \nFigure 1. a . A snippet of the discharge summary will be used to generate the FHIR \nresource. b. The i2b2 expert annotates word spans related to medications in the \ndischarge summary. c. An example of the transformed FHIR MedicationStatement \nresource based on our annotations. The same color shading from panel b is used. These \nresults represent the ground truth  transformation. d. An example of the prompt used to \ninstruct large language models in generating FHIR resources. e. The workflow details \nhow we annotate the dataset and compare the performance of Large Language Models \nand existing NLP pipelines in transforming free -text inputs into associated FHIR \nresources. \nDischarge Summary:\nDischarge Medications:\n…\n[7. senna 8.6 mg Tablet Sig: \nOne (1) Tablet PO BID P.R.N \nConstipation]\n…\nPatient was discharged to \nlong-term care facility.\na.   Discharge Summary\nMedication senna\nReason Constipation\nRoute PO\nTiming BID \nDose One (1)\nForm Tablet\nStrength 8.6 mg\nasNeeded P.R.N\nb.   Entity Annotations c.   FHIR MedicationStatement\n{'resourceType': 'MedicationStatement',\n 'id': '100035T133',\n 'subject': {'reference': 'hadm_id100035'},\n 'medication': {'reference': {'reference': '#med100035T133'}},\n 'reason': [\n     {'concept': {'text': 'Constipation’,\n 'coding': [{'system': 'http://snomed.info/sct’,\n 'code': '14760008’,\n 'display': 'Constipation'}]}}],\n 'dosage': [\n     {'route': {'text': 'PO’, \n                   'coding': [{'system': 'http://snomed.info/sct’, \n                   'code': '26643006’, \n                   'display': 'Oral route'}]},\n      'timing': {'repeat': {'frequency': 2, 'period': 1.0, 'periodUnit': 'd'},\n                     'code': {'coding': [{'system': 'http://terminology.hl7.org/’, \n                                'code': 'BID’,\n           'display': 'BID'}]}},\n      'asNeeded': True,\n      'doseAndRate': [{'doseQuantity': {'value': 1.0}}]}],\n 'contained': [\n     {'resourceType': 'Medication',\n      'id': 'med100035T133',\n      'code': {'coding’: [\n {'system': 'National Drug Code’, \n 'code': '00904516561’, \n 'display': 'sennosides, USP 8.6 MG Oral Tablet’},\n {'system': 'RxNorm’, \n 'code': '312935’, \n 'display': 'sennosides, USP 8.6 MG Oral Tablet'}], \n                   'text': 'senna 8.6 mg Tablet'},\n      'doseForm': {'text': 'Tablet’, \n 'coding': [{'system': 'http://snomed.info/sct’, \n 'code': '385055001’, \n 'display': 'Tablet'}]},\n      'ingredient': [{'item': {'concept': {'text': 'senna'}}, \n 'strengthQuantity’: \n       {'value': 8.6, 'unit': 'milligram’, \n        'system': 'http://unitsofmeasure.org’, \n        'code': 'mg'}}]}]}\n[INSTRUCTIONS]\nYou are a helpful assistant that can help with medication data extraction. \nUser will paste a short narrative that describes the administration of a drug.\nPlease extract the drug route (How drug should enter body), e.g. PO, IV.\n< Collapsed for more instructions >\n[TEMPLATE]\n{\"text\": \"<string>\", // the originial text mention of drug route\n \"coding\": [ //optional, but MUST lookup from the table below\n    {\"system\": \"http://snomed.info/sct\",\n      \"code\": \"<code>\", # SNOMED code\n      \"display\": \"<display>\" # the display of the code}]}\n[EXAMPLES]\nFor example, the narrative \n\"Oxycodone-Acetaminophen 5-325 mg Tablet \nSig: 1-2 Tablets PO\\nQ4-6H (every 4 to 6 hours) as needed“\nYou should return a json format:\n {'text': 'PO', 'coding': [{'system': 'http://snomed.info/sct', 'code’: \n'26643006','display': 'Oral route'}]}\n< Collapsed for 4 more examples >\n[TERMINOLOGIES]\nCode Display\n6064005 Topical route\n10547007 Otic route\n<Collapsed for 143 more SNOMED CT Codes>\nd.   Prompts for LLMs\ne.   Workflow\nFree-text input\nPrompts\nEntity Annotations\nNLP2FHIR\nGoogle HNL API\nExisting NLP Pipelines\nOpenAI GPT-4\nLLaMa-2-70B\nFalcon-180B\nLarge Language Models\nExisting i2b2 Annotation \nFHIR Resources\nOur Annotation\nTransformationInput\nGenerationInput\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nResults \nThe annotation results are presented in Table 1. In summary, we annotated a total of \n3,671 pairs of free -text to FHIR MedicationStatement resources transformations. The \nfree-text input was derived from discharge summaries for 280 admissions. The character \nlengths of the input data exhibit an average of  approximately 66 characters, with a \nrelatively high standard deviation of 65. The annotated resources encompass 625 distinct \nmedications in 26 different forms and are associated with 354 different reasons, as well \nas 16 administration routes. These elements display varying levels of availability, ranging \nfrom approximately 30% for reasons to 65% for timing schedules. SNOMED CT is the \nmost commonly used terminology system, which was applied to medication, form, route, \nand reason, while HL7’s own code set was used for timing schedules. The annotated \nresources in the .JSON structure ha ve an average number of objects of 58.2 (standard \ndeviation = 16.2) and an average depth of 6.7 (standard deviation = 0.5).  \n \nThe transformation results are presented in Table 2. In summary, transformation with \nGPT-4, namely FHIR-GPT,  achieved an exceptional exact match rate of over 0.90 for all \nelements, outperforming both baseline models and all other LLMs. Specifically, when \ncompared to existing NLP pipelines, FHIR-GPT improved the exact match rate by 3% for \nroutes, 12% for dose quantities, 35% for reasons, 42% for forms, and over 50% for timing \nschedules. Among all LLMs, we observed a trend of increasing accuracy as the \nparameter size increased. GPT-4, with approximately 1.7 trillion parameters, surpassed \nthe 180 billion parameter Falcon models and further improved upon the 70 billion \nparameter Llama-2 models. Within all elements, the most challenging ones for LLMs and \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nexisting methods are timing schedules and reasons. Timing schedules, consisting of 10 \nobjects, require calculations and inferences (e.g., inferring the duration based on \nfrequency and distribution), while reasons involve relationship extraction and handlin g \ncardinality, as a medication can be taken for more than one reason. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nTable 1. Descriptions,  examples, and statistics of human annotation for the FHIR medicationstatement resource. \nMedication \nStatement \nElements \nType Card. Example Description CodeSystem N (%) N, \nUniq. \nEntries  \nN,  \nUniq. \nCodes \nidentifier String 1..1 100035T133 External identifier MIMIC+i2b2 3671 (100%) 3,671 3,671 \nsubject Codeable\nReference \n1..1 {'reference': 'hadm_id164366'} Who is/was taking the \nmedication \nMIMIC 3671 (100%) 280 280 \nmedication \n \n1..1 \n \nWhat medication   \n   \n \nmedication-\nCode \nCodeable\nConcept \n0..1 {'coding':  \n[{'system': 'NDC', 'code': '51079088120', \n'display': 'clonazepam 0.5 MG Oral Tablet'}, \n{'system': 'RxNORM', 'code': '197527'','display': \n'Clonazepam 500 microgram oral tablet'}, \n{'system': 'SNOMED', 'code': '322897008', \n'display': 'Clonazepam 500 microgram oral \ntablet'}], \n'text': 'clonazepam 0.5 mg Tablet'} \nCodes that identify this \nmedication \nNDC / RxNorm /  \nSNOMED CT \nMedication \n3671 (100%) 1762 NDC: \n625, \n \nRxNorm: \n520, \n \nSNOMED\n: 210  \ndoseForm Codeable\nConcept \n0..1 {'text': 'Tablet','coding': [{'system': 'SNOMED', \n'code': '385055001','display': 'Tablet'}]} \npowder | tablets | \ncapsule + \nSNOMED CT \nDose Form \n1478 (40.3%) 176 26 \n \ningredient. \nStrength \nQuantity 0..1 {'value': 0.5, 'unit': 'milligram', \n'system': 'http://unitsofmeasure.org', \n'code': 'mg'} \nQuantity of ingredient \npresents \nunitsofmeasure. \norg \n2383 (64.9%) 188 16 \nreason Codeable\nConcept \n0..* [{'concept': {'text': 'headache', \n'coding': [{'system': 'SNOMED', 'code': \n'25064002','display': 'Headache'}]}}] \nReason for why the \nmedication is \nbeing/was taken \nSNOMED CT \nFinding \n1106 (30.1%) 619 354 \ndosage \n \n0..* \n  \n \n   \n \nasNeeded Boolean 0..1 True Take \"as needed\"  3671 (100%) 2 \n \n \nroute Codeable\nConcept \n \n{'text': 'PO', 'coding': [{'system': 'SNOMED', \n'code': '26643006', 'display': 'Oral route'}]} \nHow medication enters \nthe body \nSNOMED CT \nRoute of Admin. \n2011 (54.8%) 64 15 \n \ntiming. \nrepeat \nElement 0..1 {'frequency': 1, 'period': 4.0, 'periodMax': 6.0, \n'periodUnit': 'h', 'duration': 3.0, 'durationUnit':'d'} \nTiming schedule hl7.org/fhir/ 2393 (65.2%) 177 6 \n \ntiming. \ncode \nCodeable\nConcept \n0..1 {'coding': [{'system': 'HL7','code': 'Q4H', \n'display': 'Q4H'}]}} \nCode for timing \nschedule, e.g. 'BID' \nhl7.org/fhir/ 2287 (62.3%) 17 17 \n \ndose- \nRange \nQuantity 0..1 {\"doseQuantity\": {\"value\": 5.0, \"unit\": \"ML\"}}  \nAmount or range of \nmedication per dose \n 1378 (37.5%) 53 \n \n \ndose- \nQuantity \nRange 0..1 {\"doseRange\": { \n\"low\": { \"value\": 1.0},\"high\": { \"value\": 3.0}}} \n 11 (0.30%) 7 \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nTable 2. Comparison of LLMs and existing NLP pipelines for transforming free-\ntext input into FHIR MedicationStatement resources. Performance is evaluated \nusing the exact match rate, which requires that the resources generated by the models \nprecisely match human annotations in all aspects, including structure, codes, and \ncardinality. Due to version and implementation differences, the existing NLP pipelines \ncannot generate all the elements included in our annotations. The best-performing \nmodel for each element is indicated in bold, while the second-place model is underlined. \nElements of \nmedicationstatement Large Language Models Existing NLP \nPipelines \n \nGPT-432 Falcon-\n180B33 \nLlama-2-\n70B34 NLP2FHIR18 \nGoogle \nHealthcare \nNL API22 \n \nmedication     \n \n  medicationCode 0.968 0.899 0.859 0.862 0.963 \n \ndoseForm 0.976 0.890 0.633 0.556 - \n \ningredient.Strength 0.980 0.921 0.792 - - \n \nreason 0.902 0.593 0.169 0.645 - \n \ndosage           \n \n \nroute 0.902 0.457 0.516 - 0.871 \n \n \ntiming.repeat 0.947 0.268 0.221 0.403 - \n \n \ntiming.code 0.952 0.818 0.600 0.424 - \n \n  doseQuantity/Range 0.973 0.864 0.823 0.724 0.854 \n \n \nMethods \nIn this section, we delve into the technical details employed in data annotation, LLMs \nusage, and the evaluation process. For an illustrative visual representation of the \nworkflow, please refer to Figure 1. \nData Annotation \nThe HAPI FHIR public test server 25 hosts millions of examples of converted FHIR \nresources. However, we are unable to retrieve their source data before the conversion . \nTo the best of our knowledge, there is no largely publicly available dataset in the FHIR \nstandard that has been generated from the clinical notes. Therefore, we have decided to \nannotate a dataset that contains both free -text input and structured output i n FHIR \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nresources. The latter will serve as the ground truth against which we can evaluate the \nperformance of our LLMs in FHIR transformation. \nWe manually annotated the medication -related clinical narratives to adhere to the \nMedicationStatement resource as per FHIR v6.0.0: R6 implementation guide26. According \nto the official FHIR definition, a MedicationStatement indicates that a patient may \ncurrently be taking a medication, has taken it in the past, or will take it in the future. This \ntransformation holds particular significance because many medication -related details, \nsuch as the reasons for administration and d osage instructions, often remain absent in \nstructured data. Clinical notes within the Electronic Health Record (EHR) system \nfrequently represent the sole available source for retrieval and c onversion into a \nstandardized format. Clinical notes within the EHR system might be the sole source \navailable for the retrieval and transformation of this information into a standardized format. \nThe MedicationStatement encompasses various contents of medic ation, including \ndosage, schedule, reason, form, route, strength, and more. For detailed examples of the \nelements in the MedicationStatement resource, please refer to Table 1.  \nThe clinical text input is obtained from the discharge summaries in the MIMIC-III dataset27. \nThe 2018 n2c2 medication extraction challenge28, essentially a named entity recognition \ntask, provided mentions of medications and the word spans of the medications' \nassociated entities (including drug routes, frequencies, durations, adverse effects, forms, \nstrengths, dosages, and reasons) within the d ischarge summaries in the MIMIC -III \ndataset. All entities were manually annotated by clinical experts. We extracted text \nsnippets, each containing mentions of one medication and all its associated entities, from \nthe discharge summaries. We also included some buffer words  from the original \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \ndischarges summaries before and after the extracted word spans  to ensure that these \nsnippets are complete sentences. These extracted snippets, each related to a specific \nmedication, serve as input for both annotations and transformations. \nThe human annotation for transformation to the FHIR standard consists of three key \nsteps. The first step involved identifying the elements associated with each medication, \nand this task was effectively addressed by re -using expert annotations from the n2c2  \ndataset, which accurately pinpointed the word spans of each element. The second step \nrequired standardizing the elements from free -text into clinical terminology coding \nsystems. The elements were linked to different coding systems, and we have provided a \ndetailed description of which code systems were used in Table 1. Notably, the medication \nname was encoded in three distinct coding systems. Initially, the medication name was \nmapped to the patient's prescription table in MIMIC-III, where NDC codes were provided. \nInput data, for which the medication name couldn't be mapped to the patient's prescription \ntable, were excluded from the dataset. Subsequently, NDC codes were mapped to \nRxNorm codes and SNOMED CT Medication Codes using the APIs provided by the \nRxNav toolkit29. For all other elements, such as reasons, routes, and forms, the SNOMED \nCT coding system was primarily used, unless HL7.org provided its own code set. The \ntransformation of these codes relied primarily on manual lookup. We looked up the display \nnames, codes, and other SNOMED CT terminology details  form the SNOMED CT \nBrowser, International Edition 30. . The third step involved assembling the identifiers, \ncodes, texts, extensions, and structures into a complete MedicationStatement resource. \nThroughout the study, we utilized the .json structure format. The converted FHIR \nmedication statements undergo validation by the official FHIR validator 31 to ensure \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \ncompliance with FHIR standards, including structure, datatypes, cardinalities code sets, \ndisplay names, etc. \nThe annotation tasks were conducted by Y. Li, and  H.W., who worked collectively to  \nresolve ambiguities or uncertainties. We will make the annotated dataset available to the \npublic for authorized use upon paper acceptance. \nLarge Language Models \nThe LLMs we experimented with include OpenAI GPT -432, Llama-2-70B33, and Falcon-\n180B34. We accessed the GPT -4 APIs through the Azure OpenAI service, as \nrecommended by the responsible use guideline of MIMIC data. The specific model we \nused is gpt-4-32k in its 2023 -05-15 version. To enhance efficiency, we made multiple \nasynchronous API calls. For Llama -2-70B and Falcon -180B, we deployed them on our \nHIPAA-compliant firewalled local servers with multiple GPU backends. GPTQ 35 was used \nto accelerate the inference time for Llama-2-70B and Falcon-180B. \nWe required these Language Models (LLMs) to transform the free -text entries into \nMedicationStatements conforming to the FHIR standard, employing the few-shot prompt \nsettings. Each clinical snippet was individually input into the LLMs to generate the \nMedicationStatement resource. We used five separate prompts to instruct the LLM to \ntransform the free -text input into the elements of a MedicationStatement resource, \nincluding medication details (such as drug name, strength, and form), route, timing, \ndosage, and reason, respectively. All few -shot prompts adhered to  a template with the \nfollowing order: task instructions, expected output FHIR templates in .JSON format, 4 -5 \nexamples of transformations, a comprehensive list of codes from which the model could \nmake selections, and the input text to be transformed. As  there was no fine -tuning or \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \ndomain-specific adaptation in our experiments, we initially had the LLM generate the \nFHIR format for a small subset of the dataset (N=~100). Then, we manually reviewed the \ndiscrepancies between the LLM -generated FHIR output and our human annotations. \nCommon mistakes were identified and used to refine the prompts. There were slight \ndifferences in the prompts for each LLM, as different LLMs may be sensitive to different \nprompts. It's important to note that we did not have access to comprehensive lists of NDC, \nRxNorm, and SNOMED Medication codes for all medication names, as well as SNOMED \nFinding codes for reasons. We did not instruct the LLMs to look up the SNOMED codes \nfor the 'medication' and 'reason' elements, as the complete list of SNOMED CT \nMedication and Finding codes, numbering in the thousands or more, exceeds the token \nlimits of LLMs. Instead, our instructions were for them to identify the contexts mentioned \nin the input text and convert them into the appropriate JSON format. For instance, the \nexpected output is {\"reason\": [{\"concept\": {\"text\": \"Headach\"}}]}  rather than the more \ndetailed {\"reason\":[{'concept': {'text': 'headache', 'coding': [{'system': 'SNOMED', 'code': \n'25064002','display': 'Headache'}]}}]}.. For other code sets, such as SNOMED CT Form \ncodes, numbering in the hundreds, we allowed LLMs to directly code them. Please see \nthe appendix for prompts. \nEvaluation \nWe compared the transformed resources with the outputs from two existing approaches: \nNLP2FHIR 18 and Google Healthcare Natural Language (NL) API 22. The transformation \nresults from both approaches lacked some elements covered by our human annotation \nand LLMs generation. NLP2FHIR was built based on a previous version of the FHIR \nimplement guide, and the Google Healthcare NL API primarily standardized concepts to \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \nUMLS CUIs, rather than SNOMED CT codes, which are used in our annotations and \nLLMs' transformations . We made adaptations and conversion to ensure a fair \ncomparison. We deployed the NLP2FHIR pipeline on our HIPAA -compliant firewalled \nlocal servers. We accessed the Google Healthcare NL API through the Google Cloud \nHealthcare API, which is also compliant with HIPAA regulations. \nWhen evaluating the FHIR resources generated by the LLMs, our initial step was to verify \nthat the output was in valid JSON format. Once the JSON format check was successfully \npassed, our primary criterion for evaluation was the exact match rate. This crite rion \nrequired that the resources generated by the LLMs exactly matched the human \nannotations in all aspects, including structures, codes, and cardinality. Unlike previous \nstudies that reported word scan F1, precision, and recall scores, which considered th e \ntransformation as a NER (Named Entity Recognition) task, we did not use these metrics. \nThis decision was made because those metrics may overlook the essential aspects of \ninferring and standardizing the content based on contexts. Exact identification of the word \nspan does not guarantee the correct corresponding codes can be identified and that the \naccurate FHIR schema can be derived.  \nConclusion \nIn this study, we provided the foundations of leveraging LLMs to enhance health data \ninteroperability by transforming free -text input into the FHIR resources. The FHIR-GPT \nmodel is not only training-free but also improves transformation accuracy. Future studies \nwill aim to build upon these successes by extending the generation to additional FHIR \nresources and comparing the performance of more LLM models.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \n \n \n1. Office of the National Coordinator for Health Information Technology (ONC). Interoperability. Accessed \nOct 31, 2023, https://www.healthit.gov/topic/interoperability \n2. Office of the National Coordinator for Health Information Technology. United States Core Data for \nInteroperability (USCDI). 2023; \n3. Centers for Disease Control and Prevention. Advancing Interoperability for Public Health. Accessed Oct 31, \n2023. https://www.cdc.gov/surveillance/policy-standards/interoperability.html \n4. CMS Health Informatics and Interoperability Group (HIIG). Federal Interoperability. Accessed Oct 31, 2023. \nhttps://www.cms.gov/priorities/key-initiatives/burden-reduction/interoperability/federal-interoperability \n5. HL7.org. FHIR Overview. Accessed Oct 31, 2023. https://hl7.org/fhir/overview.html \n6. Bauer DC, Metke ‐Jimenez A, Maurer ‐Stroh S, et al. Interoperable medical data: the missing link for \nunderstanding COVID‐19. Transboundary and emerging diseases. 2021;68(4):1753-1760.  \n7. Brandt PS, Pacheco JA, Rasmussen LV. Development of a repository of computable phenotype definitions \nusing the clinical quality language. JAMIA open. 2021;4(4):ooab094.  \n8. Zong N, Sharma DK, Yu Y, et al. Developing a FHIR -based framework for phenome wide association \nstudies: a case study with a pan-cancer cohort. AMIA Summits on Translational Science Proceedings. 2020;2020:750.  \n9. Metke-Jimenez A, Hansen D. FHIRCap: Transforming REDCap forms into FHIR resources. AMIA Summits \non Translational Science Proceedings. 2019;2019:54.  \n10. Pfiffner PB, Pinyol I, Natter MD, Mandl KD. C3 -PRO: connecting ResearchKit to the health system using \ni2b2 and FHIR. PLoS One. 2016;11(3):e0152722.  \n11. Reinecke I, Gulden C, Kümmel M, Nassirian A, Blasini R, Sedlmayr M. Design for a modular clinical trial \nrecruitment support system based on FHIR and OMOP. Digital Personalized Health and Medicine . IOS Press; \n2020:158-162. \n12. Zong N, Stone DJ, Sharma DK, et al. Modeling cancer clinical trials using HL7 FHIR to support downstream \napplications: A case study with colorectal cancer data. International journal of medical informatics. 2021;145:104308.  \n13. Lee H-A, Kung H -H, Lee Y -J, et al. Global infectious disease surveillance and case tracking system for \nCOVID-19: development study. JMIR Medical Informatics. 2020;8(12):e20567.  \n14. Wang X, Lehmann H, Botsis T. Can FHIR support standardization in post-market safety surveillance? Public \nHealth and Informatics. IOS Press; 2021:33-37. \n15. Ayaz M, Pasha MF, Alzahrani MY, Budiarto R, Stiawan D. The Fast Health Interoperability Resources \n(FHIR) standard: systematic literature review of implementations, applications, challenges and opportunities. JMIR \nmedical informatics. 2021;9(7):e21929.  \n16. Vorisek CN, Lehne M, Klopfenstein SAI, et al. Fast healthcare interoperability resources (FHIR) for \ninteroperability in health research: systematic review. JMIR medical informatics. 2022;10(7):e35724.  \n17. Dash S, Shakyawar SK, Sharma M, Kaushik S. Big data in healthcare: management, analysis and future \nprospects. Journal of big data. 2019;6(1):1-25.  \n18. Hong N, Wen A, Shen F, et al. Developing a scalable FHIR -based clinical data normalization pipeline for \nstandardizing and integrating unstructured and structured electronic health record data. JAMIA open. 2019;2(4):570-\n579.  \n19. Savova GK, Masanz JJ, Ogren PV, et al. Mayo clinical Text Analysis and Knowledge Extraction System \n(cTAKES): architecture, component evaluation and applications. Journal of the American Medical Informatics \nAssociation. 2010;17(5):507-513.  \n20. Sohn S, Clark C, Halgrim SR, Murphy SP, Chute CG, Liu H. MedXN: an open source medication extraction \nand normalization tool for clinical text. Journal of the American Medical Informatics Association . 2014;21(5):858-\n865.  \n21. Wang J, Mathews WC, Pham HA, Xu H, Zhang Y. Opioid2FHIR: A system for extracting FHIR-compatible \nopioid prescriptions from clinical text. IEEE; 2020:1748-1751. \n22. Google Cloud. Use the Healthcare Natural Language API. Accessed Oct 31, 2023. \nhttps://cloud.google.com/healthcare-api/docs/how-tos/nlp \n23. Bhatia P, Celikkaya B, Khalilia M, Senthivel S. Comprehend medical: a named entity recognition and \nrelationship extraction web service. IEEE; 2019:1844-1851. \n24. Microsoft Azure. Azure Health Data Services. Accessed Oct 31, 2023. https://azure.microsoft.com/en-\nus/products/health-data-services \n25. HL7.org. HAPI FHIR. Accessed Oct 31, 2023. https://hapi.fhir.org/ \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint \n  \n26. HL7.org. Resource MedicationStatement - Content. Accessed Oct 31, 2023. \nhttps://build.fhir.org/medicationstatement.html \n27. Johnson AE, Pollard TJ, Shen L, et al. MIMIC-III, a freely accessible critical care database. Scientific data. \n2016;3(1):1-9.  \n28. Henry S, Buchan K, Filannino M, Stubbs A, Uzuner O. 2018 n2c2 shared task on adverse drug events and \nmedication extraction in electronic health records. Journal of the American Medical Informatics Association . \n2020;27(1):3-12.  \n29. Zeng K, Bodenreider O, Kilbourne J, Nelson SJ. RxNav: a web service for standard drug information. \nAmerican Medical Informatics Association; 2006:1156. \n30. SNOMED International. SNOMED International SNOMED CT Browser. Accessed Oct 31, 2023. \nhttps://browser.ihtsdotools.org/ \n31. HL7.org. Validate Resources. Accessed Oct 31, 2023. https://validator.fhir.org/ \n32. OpenAI R. GPT-4 technical report. arXiv. 2023:2303.08774.  \n33. Touvron H, Martin L, Stone K, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint \narXiv:230709288. 2023; \n34. Penedo G, Malartic Q, Hesslow D, et al. The RefinedWeb dataset for Falcon LLM: outperforming curated \ncorpora with web data, and web data only. arXiv preprint arXiv:230601116. 2023; \n35. Frantar E, Ashkboos S, Hoefler T, Alistarh D. Gptq: Accurate post-training quantization for generative pre-\ntrained transformers. arXiv preprint arXiv:221017323. 2022; \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted November 28, 2023. ; https://doi.org/10.1101/2023.10.17.23297028doi: medRxiv preprint ",
  "topic": "Interoperability",
  "concepts": [
    {
      "name": "Interoperability",
      "score": 0.9007009267807007
    },
    {
      "name": "Computer science",
      "score": 0.6950015425682068
    },
    {
      "name": "Health care",
      "score": 0.483352392911911
    },
    {
      "name": "Semantic interoperability",
      "score": 0.44853243231773376
    },
    {
      "name": "Resource (disambiguation)",
      "score": 0.4357782006263733
    },
    {
      "name": "Data science",
      "score": 0.4207220673561096
    },
    {
      "name": "Knowledge management",
      "score": 0.3852393627166748
    },
    {
      "name": "World Wide Web",
      "score": 0.34529173374176025
    },
    {
      "name": "Political science",
      "score": 0.08504506945610046
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Computer network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I111979921",
      "name": "Northwestern University",
      "country": "US"
    }
  ]
}