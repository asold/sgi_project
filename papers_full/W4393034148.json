{
  "title": "Exploring the Potential of Large Language Models in Personalized Diabetes Treatment Strategies",
  "url": "https://openalex.org/W4393034148",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1985984607",
      "name": "Hao Yang",
      "affiliations": [
        "Sichuan University",
        "West China Hospital of Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A2108981464",
      "name": "Jiaxi Li",
      "affiliations": [
        "Maternal and Child Health Hospital of Sichuan Province"
      ]
    },
    {
      "id": "https://openalex.org/A2555062769",
      "name": "Siru Liu",
      "affiliations": [
        "Vanderbilt University Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2125685373",
      "name": "Jialin Liu",
      "affiliations": [
        "West China Hospital of Sichuan University",
        "Sichuan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3019636814",
    "https://openalex.org/W2995999703",
    "https://openalex.org/W2950048237",
    "https://openalex.org/W4366769280",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W6776935626",
    "https://openalex.org/W4368340908",
    "https://openalex.org/W4380995257"
  ],
  "abstract": "Abstract Object: This study aims to explore the application of a fine-tuned model-based outpatient treatment support system for the treatment of patients with diabetes and evaluate its effectiveness and potential value. Methods: The ChatGLM model was selected as the subject of investigation and trained using the P-tuning and LoRA fine-tuning methods. Subsequently, the fine-tuned model was successfully integrated into the Hospital Information System (HIS). The system generates personalized treatment recommendations, laboratory test suggestions, and medication prompts based on patients' basic information, chief complaints, medical history, and diagnosis data. Results: Experimental testing revealed that the fine-tuned ChatGLM model is capable of generating accurate treatment recommendations based on patient information, while providing appropriate laboratory test suggestions and medication prompts. However, for patients with complex medical records, the model's outputs may carry certain risks and cannot fully substitute outpatient physicians' clinical judgment and decision-making abilities. The model's input data is confined to electronic health record (EHR), limiting the ability to comprehensively reconstruct the patient's treatment process and occasionally leading to misjudgments of the patient's treatment goals. Conclusion: This study demonstrates the potential of the fine-tuned ChatGLM model in assisting the treatment of patients with diabetes, providing reference recommendations to healthcare professionals to enhance work efficiency and quality. However, further improvements and optimizations are still required, particularly regarding medication therapy and the model's adaptability.",
  "full_text": "Page 1/19\nExploring the Potential of Large Language Models in\nPersonalized Diabetes Treatment Strategies\nHao Yang \nWest China Hospital of Sichuan University\njiaxi li \nJinniu Maternity and Child Health Hospital of Chengdu\nsiru liu \nVanderbilt University Medical Center\nJialin Liu  \n \nWest China Hospital of Sichuan University\nArticle\nKeywords: ChatGLM, Arti\u0000cial intelligence, Large language models, Diabetes, EHR\nPosted Date: March 21st, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-3995740/v1\nLicense:     This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nPage 2/19\nAbstract\nObject: This study aims to explore the application of a \u0000ne-tuned model-based outpatient treatment\nsupport system for the treatment of patients with diabetes and evaluate its effectiveness and potential\nvalue.\nMethods: The ChatGLM model was selected as the subject of investigation and trained using the P-\ntuning and LoRA \u0000ne-tuning methods. Subsequently, the \u0000ne-tuned model was successfully integrated\ninto the Hospital Information System (HIS). The system generates personalized treatment\nrecommendations, laboratory test suggestions, and medication prompts based on patients' basic\ninformation, chief complaints, medical history, and diagnosis data.\nResults: Experimental testing revealed that the \u0000ne-tuned ChatGLM model is capable of generating\naccurate treatment recommendations based on patient information, while providing appropriate\nlaboratory test suggestions and medication prompts. However, for patients with complex medical records,\nthe model's outputs may carry certain risks and cannot fully substitute outpatient physicians' clinical\njudgment and decision-making abilities. The model's input data is con\u0000ned to electronic health record\n(EHR), limiting the ability to comprehensively reconstruct the patient's treatment process and occasionally\nleading to misjudgments of the patient's treatment goals.\nConclusion: This study demonstrates the potential of the \u0000ne-tuned ChatGLM model in assisting the\ntreatment of patients with diabetes, providing reference recommendations to healthcare professionals to\nenhance work e\u0000ciency and quality. However, further improvements and optimizations are still required,\nparticularly regarding medication therapy and the model's adaptability.\nIntroduction\nDiabetes is a chronic metabolic disorder characterized by elevated blood glucose levels, which over time\ncan cause serious damage to the heart, blood vessels, eyes, kidneys and nervous system. The most\ncommon type is type 2 diabetes, which accounts for about 90–95% of diabetes cases [1] and affects\nmainly adults. According to the World Health Organization, approximately 422 million people worldwide\nhave diabetes, the majority in low- and middle-income countries, and 1.5 million people die each year as a\ndirect result of diabetes [2]. The incidence and prevalence of diabetes have been steadily increasing over\nthe last few decades [1]. As diabetes patients require long-term medication to control blood glucose levels\nand prevent complications [3], they can face several challenges during the treatment process, such as\nmedication selection, dosage adjustment and management of adverse effects. Failure to address these\nissues in a timely manner can compromise the e\u0000cacy of medication and even pose a threat to patients'\nlives [4]. Therefore, people with diabetes need timely medication advice, health education and nutrition\nsupport to help them use their medicines correctly, safely and effectively, thereby improving adherence\nand quality of life. To better serve patients and increase the e\u0000ciency of healthcare professionals, we aim\nto optimize the management of diabetes patients through the application of arti\u0000cial intelligence.\nPage 3/19\nWith the signi\u0000cant success of ChatGPT in tasks related to understanding and generating human-like\nresponses [5], large language models (LLMs) have attracted considerable attention. They have shown\nstrong performance in various natural language processing (NLP) tasks and the ability to generalize to\nunfamiliar tasks, demonstrating their potential as a uni\u0000ed solution for natural language understanding,\ntext generation and dialogue. Although ChatGPT has shown promising results in medical document\nsummarization and decision support [7, 8], as well as in passing the United States Medical Licensing\nExamination (USMLE) Step 1 and 2 [6], the exploration of these broad-domain LLMs in the medical \u0000eld\nis still relatively limited [9]. Currently, there is a lack of speci\u0000cally trained LLMs in the \u0000eld of healthcare.\nTo address this gap, we plan to \u0000ne-tune a large language model using de-identi\u0000ed data from diabetes\npatients, with the aim of exploring its application in diabetes management. In addition, harnessing the\npotential of large language models will open up new opportunities for medical research and practice, and\ndrive advances and innovation in healthcare technology.\nMethods\nThis study will utilize the Big Data Integration Platform of West China Hospital as the primary source of\ndata collection [10]. Our research protocol has been approved by the Ethics Committee of West China\nHospital, Sichuan University, in accordance with the requirements of informed consent (Approval No.\n2024 − 126), exempting us from the need for informed consent. All methods have been conducted in\naccordance with relevant guidelines and regulations, including encryption and de-identi\u0000cation of patient\ndata during data processing. Furthermore, the study involves only large language model training and\ntesting, with no clinical trials conducted. We will collect EHR data from patients diagnosed with diabetes\nwho visited the outpatient department from January 2022 to February 2022. The collected data will\ninclude information such as the patient's department of visit, age, gender, chief complaint, present illness\nhistory, and diagnosis, which will serve as input for the model. In addition, we will obtain data on patients'\noutpatient medications, laboratory tests, examinations, and physician opinions, which will be used as\nmodel outputs. Patient data with missing chief complaints and present illness history will be excluded to\nensure data quality and usability. Furthermore, we will collect an additional set of data from 300 patients\n(visiting in March 2022) as a test set to evaluate the performance of the optimized model. Figure 1\nillustrates the data collection process. The research is limited to retrospective data analysis and has\nreceived approval from the ethics committee (2024 − 126).\nData Pre-processing\nPrior to model training, we pre-process the collected data. This includes data cleaning, standardization\nand anonymization. Data cleaning involves the removal of missing values, outliers and duplicates.\nStandardization ensures that different data elements have a consistent format and unit, which facilitates\nthe input and output processing of the model. To protect patient privacy, we will anonymize the personal\nidentity information of patients. For example, we will use anonymization techniques to replace or remove\nnames and identi\u0000cation numbers.\nPage 4/19\nModel selection\nChatGLM is an LLM developed by Tsinghua University and Zhipu.AI [11]. ChatGLM-6B is an open-source\ndialogue language model based on the General Language Model (GLM) architecture, speci\u0000cally\ndesigned for question answering in both Chinese and English. It consists of 6 billion parameters [11]. The\nopen-source nature of the model is an important consideration when choosing a model. With the\nimplementation of model quantization techniques, it can be deployed locally on consumer-grade graphics\ncards. The experimental environment for this study utilized a single GPU, speci\u0000cally an RTX 3090 with\n24GB of memory, and a CPU with 16 vCPUs (Intel(R) Xeon(R) Platinum 8350C CPU @ 2.60GHz). These\nhardware components were used to facilitate the training and inference processes of the ChatGLM-6B\nmodel.\nFine-tune\nWe will use ChatGLM as the base model and \u0000ne-tune it for speci\u0000c tasks in the \u0000eld of diabetes\nmanagement. For the \u0000ne-tuning process, we will employ commonly used techniques for LLMs, namely\nP-tuning [12] and LoRA [13]. These methods have been proven effective in adapting pre-trained language\nmodels to domain-speci\u0000c tasks and improving their performance [14].\nP-tuning: P-tuning is a method that automatically constructs templates for language models to perform\ndownstream tasks [12]. It uses [unused]* tokens as continuous prompts and optimizes them with labelled\ndata. It can achieve comparable or better performance than \u0000ne-tuning with much fewer trainable\nparameters. P-tuning v2 is an improved version of P-tuning that applies continuous prompts to each layer\nof the pre-trained model and adapts it to natural language understanding tasks [15]. In this study, we\nused p-tuning v2 as the technical implementation of \u0000ne-tuning (Fig. 2).\nLoRA\nLora (low-rank adaptation) is a low-rank adaptation technique that allows for a signi\u0000cant reduction in\nthe number of trainable parameters in downstream tasks while keeping the weights of the pre-trained\nmodel unchanged [13]. This method is similar to matrix factorization, where a trainable low-rank\ndecomposition matrix is injected into each layer of the Transformer structure. By employing a fully\nconnected layer, the dimensionality of the trainable layers is reduced from 'd' to 'r', and then mapped back\nto the original dimension 'd' through another fully connected layer, where 'r' represents the rank of the\nmatrix, and 'r < < d'. As a result, the computational complexity of matrix operations is reduced from 'd×d'\nto 'd×r + r×d', leading to a signi\u0000cant decrease in the number of parameters. In Lora, both parameters A\nand B are initialized using random Gaussian initialization (Fig. 3).\nModel metrics\nBLEU: BLEU (Bilingual Evaluation Understudy) measures the effectiveness of a model by computing the\nn-gram matching between the machine-generated content and the reference standard text [16].\nPage 5/19\nIn the BLEU, the BP (Brevity Penalty) is a penalty factor that addresses the issue of shorter machine-\ngenerated content compared to the reference text. The weights, wn, represent the importance assigned to\neach n-gram matching score. Pn refers to the precision of the n-gram matching.\nROUGE: ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is an evaluation metric that compares\nthe system-generated content with manually generated reference texts. It measures the overlap between\nthe two by counting the number of shared basic units, such as n-grams, word sequences, and word pairs,\nto assess the effectiveness of a model [17]. In the context of Chinese NLP tasks, ROUGE Chinese is\nemployed for algorithm optimization. It involves transforming Chinese summaries into numeric IDs and\nthen utilizing dynamic programming to calculate the counts of matching units, such as the longest\ncommon subsequence and N-grams. This approach allows for the computation of ROUGE-N and ROUGE-\nL metrics.\nIn the Roug-N, S represents the set of generated content, gramn represents the n-gram, Count_match\n(gramn) indicates the number of n-grams shared between the reference and generated content, and Count\n(gramn) represents the total number of n-grams in the reference. ROUGE-N is used to measure the overlap\nat the n-gram level between the automatically generated text and the reference text. It is a commonly\nused evaluation metric.\nIn the Rouge-L, LCS(X, Y) is the length of the longest common subsequence between X and Y. m and n are\nlengths of the reference summary and the automatic summary, typically measured in the number of\nwords. Rlcs and Plcs denote recall and precision, respectively. Finally, Flcs corresponds to what we refer to\nas Rouge-L. In this formula, β  is set to a large value, so Rouge-L primarily considers Rlcs.\nPhysician assessment of recommendations\nAfter the \u0000ne-tuning process, we will evaluate the model using the reserved dataset of 300 patients. The\nevaluation will assess the accuracy and consistency of the model in terms of diabetes treatment\nBLEU=BP×exp(∑N\nn=1wnlogPn)\nRouge−N= ∑S∈ReferenceSummaries∑gramn∈SCountmatch(gramn)\n∑S∈ReferenceSummaries∑gramn∈SCount(gramn)\nRlcs= LCS(X,Y)\nm\nPlcs= LCS(X,Y)\nn\nRouge−L=Flcs = (1+β2)RlcsPlcs\nRlcs +β2Plcs\nPage 6/19\nrecommendations. We will compare the model-generated outputs and seek evaluations from three\nendocrinologists based on the following three categories: useful, useless, and harmful.\nUseful: This category refers to cases where the model provides correct treatment recommendations that\nare helpful in clinical practice [18].\nUseless: This category pertains to instances where the content generated by the model lacks logical\ncoherence or speci\u0000c guiding signi\u0000cance in certain tasks [19].\nHarmful: This category addresses potential negative impacts and risks that the model might introduce in\nits application [20]. For example, it may include erroneous medication or treatment suggestions.\nModel integrated\nThe \u0000ne-tuned model will be integrated into the EHR system (Fig. 4) to facilitate the management of\ndiabetes patients by clinical physicians. This integration will enable the provision of personalized\ntreatment recommendations for diabetes patients. By integrating the model with the EHR, physicians will\nhave easy access to the system's output, enhancing their ability to make informed decisions and develop\ntailored management plans for patients with diabetes.\nEthics\nThroughout the research and model development process, we will strictly adhere to ethical standards and\nprivacy principles. Patient data will be de-identi\u0000ed to protect their privacy. We will ensure secure storage\nand transmission of the data and will only use it for model training and evaluation when necessary. In\naddition, this study has been approved by the Ethics Committee of West China Hospital, Sichuan\nUniversity (2021 − 1450).\nResults\nThe LoRA and P-Tuning training resulted in a training loss curve for both \u0000ne-tuning methods (Fig. 5). The\nresults show that the LoRA can converge faster and achieve better \u0000ne-tuning results than P-Tuning.\nThese results indicate that the LoRA \u0000ne-tuning method achieves signi\u0000cant improvements in the task of\ndiabetes management, enhancing model performance and adaptability. It provides clinicians with more\naccurate and personalized guidance and recommendations.\nThe results shown in Table 1, the comparison between the \u0000ne-tuned models and the original model in\nterms of BLEU and Rouge on the test set are as follows. The model after LoRA tuning shows a signi\u0000cant\nimprovement over the original model (p < 0.05). The model after P-Tuning shows a signi\u0000cant\nimprovement in the BLEU score compared to the original model (p < 0.05), while there is no improvement\nin the Rouge score (p > 0.05).\nPage 7/19\nTable 1\nPerformanceanalysis ofbased onBLEU andRouge scores(mean:std)For the samequestion, theoriginalmodel, themodel after P-tuning and theLoRA showthe followingspeci\u0000cperformances:\nPage 8/19\nExample\nInput:\n##Department: Endocrinology and Metabolism Medical Unit\n##Gender: Male\n##Age: 68 years old\n##Diagnosis: Type 2 diabetes; hyperlipidemia\n##Chief complaint: Diabetes follow-up visit\n##Medical history: Diabetes for 2 more years\nReal clinical data\nOutput:\n##Laboratory tests\nBiochemistry 2: Liver and kidney glucose and fat-a, glycated hemoglobin (HbA1c)\n##Medication:\nGanjing insulin injection (3ml:300 units/pre-\u0000lled) 11 U once a day, OuTangning (5mg×7 tablets) 5 mgonce a day, Atorvastatin calcium tablets (10mg×28 tablets) 10 mg once every night.\nOrigin ChatGLM\nOutput:\nA patient with diabetes who comes for a follow-up visit needs to undergo a detailed medical historyand physical examination in order to better understand the patient’s condition and develop atreatment plan. According to your description, the patient has type 2 diabetes and hyperlipidemia.Diabetes is a chronic disease that requires long-term management and treatment. Hyperlipidemia is acommon metabolic disorder that can affect the patient’s cardiovascular health and increase the riskof cardiovascular disease.\nDuring the follow-up visit, the patient needs to monitor blood glucose levels and adjust themaccording to the control of blood glucose levels, diet, exercise, etc. In addition, the patient also needsto undergo regular blood lipid level checks and develop corresponding treatment plans based on theresults of the checks.\nFor diabetes, common treatment options include oral medications, insulin injections, blood glucosemonitoring, and dietary control. During the treatment process, patients need to actively cooperate withdoctors, adhere to dietary and exercise control, and have regular follow-up visits to maintain stableand healthy blood glucose levels.\nP-tuning ChatGLM\nPage 9/19\nExample\nOutput:\nAccording to the patient’s diagnosis, he needs to be treated for both type 2 diabetes andhyperlipidemia. Here are some treatment recommendations:\n1. Drug treatment: The patient needs to continue drug treatment, including oral medications andinsulin. Depending on the patient’s blood glucose and blood lipid levels, the doctor may adjust thedrug dosage or switch to another medication.\n2.Dietary control: The patient needs to control his diet, avoid high-sugar and high-fat foods, andincrease his exercise. It is recommended that patients eat high-\u0000ber, low-fat, and low-sugar foodssuch as vegetables, fruits, whole grains, legumes, lean meats, \u0000sh, etc.\n3. Lifestyle adjustments: The patient needs to quit smoking, limit alcohol consumption, controlweight, maintain regular exercise and sleep patterns.\n4. Regular follow-up visits: The patient needs to have regular follow-up visits to monitor blood glucoseand blood lipid levels and adjust drug dosage or lifestyle in a timely manner.\nWeight control: The patient needs to control his weight and avoid obesity to reduce the risk ofhyperlipidemia.\nLoRA ChatGLM\nOutput:\n##Laboratory tests\nGlycosylated hemoglobin (HbA1c)\nBiochemistry 1: Liver and kidney lipase-a, Fasting insulin, 2-hour postprandial insulin, Fasting plasmaglucose, 2-hour postprandial C-peptide, 2-hour postprandial plasma glucose\n##Medication:\nGan Jing insulin injection (3ml:300 units/pre-\u0000lled) 11 U once a day, OuTangning (5mg×7 tablets) 5mg once a day\n## Physician's recommendation:\nRegular follow-up is recommended.\nRecommended evaluation\nTable 2 shows the results of three endocrinologists' evaluation of the 300 treatment recommendations\ngenerated by ChatGLM. The results show that more than 50% of the recommendations are clinically\nrelevant to diabetes management, while more than 30% are of limited help to physicians. In addition,\nabout 10% of the recommendations carried potential risks, such as incorrect treatment recommendations\nor overtreatment. There was no signi\u0000cant difference in the results of the three physician ratings (p > \n0.05).\nPage 10/19\nTable 2\nPhysician assessment of recommendations\nDoctor ϑ useful Κ useless Λ harmful P\n#1 187(62.33%) 91(30.33%) 22(7.33%) 0.26\n#2 172(57.33%) 95(31.67%) 33(11.00%)\n#3 167(55.67%) 108(36%) 25(8.33%)\nIntegration with existing EHR\nIn order to seamlessly integrate ChatGLM into existing clinical work\u0000ows and EHR systems, we\nconducted internal testing by integrating ChatGLM into the hospital's EHR system within an internal test\nenvironment. In this internal test environment, when a physician completes the patient's basic\ninformation, chief complaints, history of present illness and diagnosis, the system automatically collects\nthe information and uses a \u0000ne-tuned GLM to generate appropriate treatment recommendations.\nPhysicians can refer to these treatment recommendations and use them as a reference when issuing\nmedical orders and treatment suggestions to patients (Fig. 6). It is important to note that these treatment\nrecommendations serve as a reference for physicians and do not replace their decision-making process.\nPhysicians are still required to make a comprehensive assessment based on the speci\u0000c circumstances\nof each patient and to make \u0000nal decisions based on their clinical experience and expertise.\nDiscussion\nChatGLM, developed by Tsinghua University and Zhipu.AI, is an open-source LLM for natural language\nunderstanding and generation. It is a general pre-training framework that can be effectively\nparameterized for different tasks. In our study, we used the ChatGLM model and trained it on data from\ndiabetic patients.\nIn terms of \u0000ne-tuning, traditional \u0000ne-tuning algorithms typically require manual selection of parameters\nto be \u0000ne-tuned, which requires domain knowledge and expertise. In addition, LLM typically have a large\nnumber of parameters, which is an important consideration for GPU computing power and training\ndataset requirements. Even if only a small fraction of the parameters are frozen, forward and backward\npropagation computations are still required, and these computations scale linearly with the number of\nmodel parameters. As a result, large-scale models require relatively large GPU computing power and\ntraining data sets. To address these issues, our research has used the P-tuning and LoRA methods for\n\u0000ne-tuning training.\nP-tuning is a prompt-based \u0000ne-tuning method that guides the model to produce more accurate outputs\nby inserting speci\u0000c markers in the input. Compared to traditional \u0000ne-tuning methods, P-tuning makes\nbetter use of the knowledge of the pre-trained model and achieves better results on small datasets [21].\nMoreover, P-tuning allows control over the style and content of the generated text by adjusting the prompt\n[22].\nPage 11/19\nLoRA is a parameter-based \u0000ne-tuning method that improves performance by \u0000ne-tuning the parameters\nof the model [23]. Compared to traditional \u0000ne-tuning methods, LoRA makes better use of the knowledge\nof the pre-trained model and provides better interpretability [24]. In addition, LoRA can further improve the\ne\u0000ciency of a model by reducing the number of parameters through low-rank decomposition [25]. It is\nimportant to note that low-rank decomposition may introduce some loss of information as it\napproximates the original model parameters [13]. Therefore, when applying LoRA or other parameter\nreduction techniques, it is essential to strike a balance between model e\u0000ciency and performance to\nensure adequate information retention and model effectiveness [26].\nAfter repeated debugging and testing of the model, we have found that for a subset of patients with\ncomplex medical records, the model output can be potentially harmful and fail to assist healthcare\nprofessionals in their treatment. This situation can occur for the following reasons: 1) Data imbalance or\nsample bias: The model may have been trained on an over-representation of certain types of patient\nrecords, leading to an inadequate understanding of other types of patients. This bias can lead to\ninaccurate or harmful treatment recommendations for certain patients. 2) Unknown or rare scenarios: If\nthe model encounters unfamiliar or infrequent situations during training, it may struggle to make accurate\npredictions or appropriate recommendations. Complex patient records often contain such unknown\nscenarios, rendering the model's output ineffective. 3) Limitations of the model: The model may have\ninherent design or training limitations that prevent it from adequately accounting for factors speci\u0000c to\ncomplex medical records. As a result, the model's outputs may lack accuracy or reliability in these cases.\n4) The size of the training data has a direct impact on the performance of large models. Therefore, it is\ncrucial for us to explore methods to increase the scale of our dataset. [27] (supplementary material).\nIt is important to understand that while LLMs often perform well in many scenarios, they may have\nlimitations when dealing with complex medical records. Therefore, model outputs should not be the sole\nbasis for decision making. Healthcare professionals should rely on their expertise and clinical judgement,\nand integrate model outputs with comprehensive assessments to make informed decisions [27].\nThis research also has some limitations. Firstly, this work is at an early stage and contains some errors,\nmaking it unsuitable for any commercial or clinical use. The aforementioned experimental environment is\nlimited to the experimental testing phase. Secondly, ChatGLM-6B is a GLM with only 6 billion parameters,\nwhich is signi\u0000cantly smaller than larger models such as ChatGPT and GPT-4, which have hundreds of\nbillions of parameters. However, due to its smaller size, it does not require powerful computing resources\nand can be deployed on an intranet at a lower cost. Thirdly, the training data for this study comes from a\nsingle medical institution and is relatively small in volume. The results of the study require further\nvalidation. In future research, we will consider using larger models and incorporating more training data\nto improve the robustness of the results.\nConclusion\nPage 12/19\nWhile ChatGLM has shown promise in assisting with the treatment of diabetic patients, thorough\nvalidation, scrutiny and regulatory measures must be undertaken to ensure safety and e\u0000cacy before the\nmodel can be applied in clinical practice or commercial settings. Future research directions include\ndeveloping more universally applicable medical assistance models, incorporating Reinforcement\nLearning from Human Feedback (RLHF) techniques for model \u0000ne-tuning, and ensuring the model's\napplicability in different hospitals and real-world scenarios.\nDeclarations\nAvailability of data and materials\nConsidering data security, the data will not be publicly available on the website for now. However, the data\nand code used in this study are available from the corresponding author upon reasonable request.\nEthics approval and consent to participate.\nThe data used in this study were sourced from the West China Hospital. This is a retrospective study, and\nall data were encrypted and desensitized, without involving any patient privacy-sensitive information or\nclinical interventions. The data extraction and study methods were approved by the Ethics Committee of\nWest China Hospital, Sichuan University, with an informed consent exemption statement (2024-126).\nReferences\n1. Artasensi A, Pedretti A, Vistoli G, Fumagalli L. Type 2 Diabetes Mellitus: A Review of Multi-Target\nDrugs. Molecules. 2020 Apr 23;25(8):1987. doi: 10.3390/molecules25081987. PMID: 32340373;\nPMCID: PMC7221535..\n2. WHO|Diabetes Programme. WHO. [(accessed on 27 January 2019)];2019 Available online:\nhttps://www.who.int/diabetes/en/.\n3. Landgraf R, Aberle J, Birkenfeld AL, Gallwitz B, Kellerer M, Klein H, Müller-Wieland D, Nauck MA,\nReuter HM, Siegel E. Therapy of Type 2 Diabetes. Exp Clin Endocrinol Diabetes. 2019 Dec;127(S\n01):S73-S92. doi: 10.1055/a-1018-9106. Epub 2019 Dec 20. PMID: 31860927.\n4. Eghbali-Zarch M, Tavakkoli-Moghaddam R, Esfahanian F, Azaron A, Sepehri MM. A Markov decision\nprocess for modeling adverse drug reactions in medication treatment of type 2 diabetes. Proc Inst\nMech Eng H. 2019 Aug;233(8):793-811. doi: 10.1177/0954411919853394. Epub 2019 Jun 10. PMID:\n31177917.\n5. Eloundou T, Manning S, Mishkin P, et al. Gpts are gpts: An early look at the labor market impact\npotential of large language models[J]. arXiv preprint arXiv:2303.10130, 2023.\n\u0000. Nori H, King N, McKinney S M, et al. Capabilities of gpt-4 on medical challenge problems[J]. arXiv\npreprint arXiv:2303.13375, 2023.\nPage 13/19\n7. Liu Z, Yu X, Zhang L, et al. Deid-gpt: Zero-shot medical text de-identi\u0000cation by gpt-4[J]. arXiv preprint\narXiv:2303.11032, 2023.\n\u0000. Liu S, Wright AP, Patterson BL, et al. Using AI-generated suggestions from ChatGPT to optimize\nclinical decision support. J Am Med Inform Assoc. 2023 Apr 22:ocad072. doi:\n10.1093/jamia/ocad072.\n9. Gilson A, Safranek CW, Huang T, et al. How Does ChatGPT Perform on the United States Medical\nLicensing Examination? The Implications of Large Language Models for Medical Education and\nKnowledge Assessment. JMIR Med Educ. 2023 Feb 8;9:e45312. doi: 10.2196/45312.\n10. Wang M, Li S, Zheng T, et al. Big data health care platform with multisource heterogeneous data\nintegration and massive high-dimensional data governance for large hospitals: Design, development,\nand application[J]. JMIR Medical Informatics, 2022, 10(4): e36481.\n11. Du Z, Qian Y, Liu X, et al. GLM: General language model pretraining with autoregressive blank\nin\u0000lling[C]//Proceedings of the 60th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers). 2022: 320-335.\n12. Liu X, Ji K, Fu Y, et al. P-tuning v2: Prompt tuning can be comparable to \u0000ne-tuning universally across\nscales and tasks[J]. arXiv preprint arXiv:2110.07602, 2021.\n13. Hu E J, Shen Y, Wallis P, et al. Lora: Low-rank adaptation of large language models[J]. arXiv preprint\narXiv:2106.09685, 2021.\n14. Lukichev D, Kryanina D, Bystrova A, et al. Parameter-E\u0000cient Tuning of Transformer Models for\nAnglicism Detection and Substitution in Russian[C]//Proceedings of the International Conference\n“Dialogue. 2023, 2023.\n15. Liu X, Ji K, Fu Y, et al. P-tuning v2: Prompt tuning can be comparable to \u0000ne-tuning universally across\nscales and tasks[J]. arXiv preprint arXiv:2110.07602, 2021.\n1\u0000. Papineni K, Roukos S, Ward T, et al. Bleu: a method for automatic evaluation of machine\ntranslation[C]//Proceedings of the 40th annual meeting of the Association for Computational\nLinguistics. 2002: 311-318.\n17. Lin C Y. Rouge: A package for automatic evaluation of summaries[C]//Text summarization branches\nout. 2004: 74-81.\n1\u0000. Eggmann F, Weiger R, Zitzmann N U, et al. Implications of large language models such as ChatGPT\nfor dental medicine[J]. Journal of Esthetic and Restorative Dentistry, 2023.\n19. Kang D, Li X, Stoica I, et al. Exploiting programmatic behavior of llms: Dual-use through standard\nsecurity attacks[J]. arXiv preprint arXiv:2302.05733, 2023.\n20. Dash D, Thapa R, Banda J M, et al. Evaluation of GPT-3.5 and GPT-4 for supporting real-world\ninformation needs in healthcare delivery[J]. arXiv preprint arXiv:2304.13714, 2023.\n21. Liu X, Zheng Y, Du Z, et al. GPT understands, too[J]. arXiv preprint arXiv:2103.10385, 2021.\n22. Dong Z, Wei P, Lin L. Dreamartist: Towards controllable one-shot text-to-image generation via\ncontrastive prompt-tuning[J]. arXiv preprint arXiv:2211.11337, 2022.\nPage 14/19\n23. Hu Z, Lan Y, Wang L, et al. LLM-Adapters: An Adapter Family for Parameter-E\u0000cient Fine-Tuning of\nLarge Language Models[J]. arXiv preprint arXiv:2304.01933, 2023.\n24. Chavan A, Liu Z, Gupta D, et al. One-for-All: Generalized LoRA for Parameter-E\u0000cient Fine-tuning[J].\narXiv preprint arXiv:2306.07967, 2023.\n25. Fried D, Polajnar T, Clark S. Low-rank tensors for verbs in compositional distributional\nsemantics[C]//Proceedings of the 53rd Annual Meeting of the Association for Computational\nLinguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2:\nShort Papers). 2015: 731-736.\n2\u0000. Wang G, Cao Q, Yang J, et al. Task-oriented Memory-e\u0000cient Pruning-Adapter[J]. arXiv preprint\narXiv:2303.14704, 2023.\n27. Antaki F, Touma S, Milad D, et al. Evaluating the performance of chatgpt in ophthalmology: An\nanalysis of its successes and shortcomings[J]. Ophthalmology Science, 2023: 100324.\n2\u0000. Liu J, Wang C, Liu S. Utility of ChatGPT in Clinical Practice. J Med Internet Res 2023;25:e48568.doi:\n10.2196/48568\nFigures\nPage 15/19\nFigure 1\nSee image above for \u0000gure legend\nPage 16/19\nFigure 2\nSee image above for \u0000gure legend\nPage 17/19\nFigure 3\nSee image above for \u0000gure legend\nPage 18/19\nFigure 4\nChatGLM \u0000ne-tuning based treatment aid model for diabetes\nFigure 5\nTraining Loss for LoRA and P-Tuning\nPage 19/19\nFigure 6\nIntegration with existing EMR\nSupplementary Files\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nsupplementarymaterial.docx",
  "topic": "Diabetes mellitus",
  "concepts": [
    {
      "name": "Diabetes mellitus",
      "score": 0.5559228658676147
    },
    {
      "name": "Diabetes treatment",
      "score": 0.47547927498817444
    },
    {
      "name": "Computer science",
      "score": 0.45804187655448914
    },
    {
      "name": "Language model",
      "score": 0.4358944892883301
    },
    {
      "name": "Personalized medicine",
      "score": 0.4170008897781372
    },
    {
      "name": "Medicine",
      "score": 0.3315877616405487
    },
    {
      "name": "Computational biology",
      "score": 0.32923102378845215
    },
    {
      "name": "Data science",
      "score": 0.32082733511924744
    },
    {
      "name": "Type 2 diabetes",
      "score": 0.3122932016849518
    },
    {
      "name": "Bioinformatics",
      "score": 0.258419930934906
    },
    {
      "name": "Natural language processing",
      "score": 0.2356148660182953
    },
    {
      "name": "Biology",
      "score": 0.1768760085105896
    },
    {
      "name": "Endocrinology",
      "score": 0.08827120065689087
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210124723",
      "name": "Maternal and Child Health Hospital of Sichuan Province",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I24185976",
      "name": "Sichuan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210089761",
      "name": "West China Hospital of Sichuan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I901861585",
      "name": "Vanderbilt University Medical Center",
      "country": "US"
    }
  ],
  "cited_by": 2
}