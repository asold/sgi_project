{
  "title": "Hybrid Emoji-Based Masked Language Models for Zero-Shot Abusive Language Detection",
  "url": "https://openalex.org/W3094474409",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5015073608",
      "name": "Michele Corazza",
      "affiliations": [
        "University of Bologna"
      ]
    },
    {
      "id": "https://openalex.org/A5026350868",
      "name": "Stefano Menini",
      "affiliations": [
        "Fondazione Bruno Kessler"
      ]
    },
    {
      "id": "https://openalex.org/A5049137879",
      "name": "Elena Cabrio",
      "affiliations": [
        "Centre National de la Recherche Scientifique",
        "Institut national de recherche en sciences et technologies du numérique"
      ]
    },
    {
      "id": "https://openalex.org/A5067301751",
      "name": "Sara Tonelli",
      "affiliations": [
        "Fondazione Bruno Kessler"
      ]
    },
    {
      "id": "https://openalex.org/A5016281730",
      "name": "Serena Villata",
      "affiliations": [
        "Centre National de la Recherche Scientifique",
        "Institut national de recherche en sciences et technologies du numérique"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2270070752",
    "https://openalex.org/W2340954483",
    "https://openalex.org/W2887782043",
    "https://openalex.org/W3013027210",
    "https://openalex.org/W2806872289",
    "https://openalex.org/W2914730082",
    "https://openalex.org/W2740168486",
    "https://openalex.org/W2888854441",
    "https://openalex.org/W2908323419",
    "https://openalex.org/W2953692061",
    "https://openalex.org/W2962977603",
    "https://openalex.org/W3115903740",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2963481894",
    "https://openalex.org/W2962797668",
    "https://openalex.org/W2949089361",
    "https://openalex.org/W2952629768",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2518630504",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2946681640",
    "https://openalex.org/W4248491679",
    "https://openalex.org/W2119769989",
    "https://openalex.org/W3023443524",
    "https://openalex.org/W2595715041",
    "https://openalex.org/W2785615365",
    "https://openalex.org/W2954226438",
    "https://openalex.org/W2998764526",
    "https://openalex.org/W2124807415",
    "https://openalex.org/W2941596569",
    "https://openalex.org/W2251855545",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2971150411",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W2540646130",
    "https://openalex.org/W4387687025",
    "https://openalex.org/W3011385529",
    "https://openalex.org/W3115174251",
    "https://openalex.org/W2963341956"
  ],
  "abstract": "Recent studies have demonstrated the effectiveness of cross-lingual language model pre-training on different NLP tasks, such as natural language inference and machine translation. In our work, we test this approach on social media data, which are particularly challenging to process within this framework, since the limited length of the textual messages and the irregularity of the language make it harder to learn meaningful encodings. More specifically, we propose a hybrid emoji-based Masked Language Model (MLM) to leverage the common information conveyed by emojis across different languages and improve the learned cross-lingual representation of short text messages, with the goal to perform zero- shot abusive language detection. We compare the results obtained with the original MLM to the ones obtained by our method, showing improved performance on German, Italian and Spanish.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 943–949\nNovember 16 - 20, 2020.c⃝2020 Association for Computational Linguistics\n943\nHybrid Emoji-Based Masked Language Models\nfor Zero-Shot Abusive Language Detection\nMichele Corazza†, Stefano Menini‡,\nElena Cabrio§, Sara Tonelli‡, Serena Villata§\n†University of Bologna, Italy\n‡Fondazione Bruno Kessler, Trento, Italy\n§Universit´e Cˆote d’Azur, CNRS, Inria, I3S, France\nmichele.corazza2@unibo.it\n{menini,satonelli}@fbk.eu\n{elena.cabrio,serena.villata}@univ-cotedazur.fr\nAbstract\nRecent studies have demonstrated the effec-\ntiveness of cross-lingual language model pre-\ntraining on different NLP tasks, such as nat-\nural language inference and machine trans-\nlation. In our work, we test this approach\non social media data, which are particularly\nchallenging to process within this framework,\nsince the limited length of the textual messages\nand the irregularity of the language make it\nharder to learn meaningful encodings. More\nspeciﬁcally, we propose a hybrid emoji-based\nMasked Language Model (MLM) to leverage\nthe common information conveyed by emo-\njis across different languages and improve the\nlearned cross-lingual representation of short\ntext messages, with the goal to perform zero-\nshot abusive language detection. We compare\nthe results obtained with the original MLM to\nthe ones obtained by our method, showing im-\nproved performance on German, Italian and\nSpanish.\n1 Introduction\nThe extensive use of large-scale self-supervised pre-\ntraining has greatly contributed to recent progress\nin many Natural Language Processing (NLP)\ntasks (Devlin et al., 2019; Liu et al., 2019; Con-\nneau and Lample, 2019). In this context, masked\nlanguage modelling objectives represent one of the\nmain novelties of these approaches, where some\ntokens of an input sequence are randomly masked,\nand the objective is to predict these masked posi-\ntions taking the corrupted sequence as input. Still,\nlittle attention has been devoted to the adaptation\nof these techniques to tasks dealing with social\nmedia data, probably because they are character-\nized by a very domain-speciﬁc language, with\nhigh variability and instability. Nevertheless, all\nthese challenges make social media data an inter-\nesting testbed for novel deep-learning architectures,\naround the research question: how could the mask-\ning mechanism be adapted to target social media\nlanguage?\nIn this paper, we address the above issue by\nadapting a novel architecture for cross-lingual mod-\nels called XLM (Conneau and Lample, 2019) to\nzero-shot abusive language detection, a task that\nhas gained increasing importance given the recent\nsurge in abusive online behavior and the need to\ndevelop reliable and efﬁcient methods to detect it.\nIn particular, we evaluate two methods to pre-train\nbilingual language models, one similar to the origi-\nnal XLM masked model, and the other based on a\nnovel hybrid emoji-based masked model. We then\nevaluate them on zero-shot abusive language detec-\ntion for Italian, German and Spanish, showing that,\nalthough our results are below the state-of-the-art\nin a monolingual setting, the proposed solutions to\nadapt XLM to social media data are beneﬁcial and\ncan be effectively extended to other languages.\nIn the following, Section 2 discusses the related\nwork. Section 3 describes our approach to train\ncross-lingual models for social media data classiﬁ-\ncation, while Section 4 presents the experimental\nsetup. Section 5 reports on the evaluation results,\nwhile Section 6 summarizes our ﬁndings.\n2 Related work\nThe focus of this paper is the abusive language de-\ntection task, which has been widely explored in the\nlast years thanks to numerous datasets, approaches\nand shared tasks (Waseem et al., 2017; Fiˇser et al.,\n2018; Carmona et al., 2018; Wiegand et al., 2018;\nBosco et al., 2018; Zampieri et al., 2019b; Roberts\net al., 2019) covering different languages. An in-\ncreasing number of approaches has been proposed\nto detect this kind of messages (for a survey on\nthe task, see (Schmidt and Wiegand, 2017) and\n(Fortuna and Nunes, 2018)).\n944\nAbusive language detection is usually framed\nas a supervised learning problem, built using a\ncombination of manually crafted features such\nas n-grams (Wulczyn et al., 2017), syntactic fea-\ntures (Nobata et al., 2016), and linguistic fea-\ntures (Yin et al., 2009), to more recent neural net-\nworks (Park and Fung, 2017; Zhang and Tepper,\n2018; Agrawal and Awekar, 2018; Corazza et al.,\n2018). (Lee et al., 2018) address a comparative\nstudy of various learning models on the Hate and\nAbusive Speech on Twitter dataset (Founta et al.,\n2018), while (Zampieri et al., 2019a) build the Of-\nfensive Language Identiﬁcation Dataset and ex-\nperiment with SVMs, BiLSTM and CNN both on\nthe binary abusive language classiﬁcation and on a\nmore ﬁne-grained categorization. Our work deals\nwith the same task, addressed from a cross-lingual\nperspective.\nIn recent years, some proposals have been\nmade to tackle abusive language detection in a\ncross-lingual framework (Sohn and Lee, 2019; Pa-\nmungkas and Patti, 2019; Casula et al., 2020), with\nsome attempts at zero-shot learning (Stappen et al.,\n2020). Most systems, however, rely on pretrained\nmodels and do not investigate the potential of in-\ndomain data for pretraining. Additionally, as re-\ngards masked language models, we are not aware\nof any work in the literature modifying masking\nmechanisms for this task.\n3 Cross-Lingual Language Models\n3.1 MLM and HE-MLM training objectives\nOur basic architecture relies on the XLM approach\ndescribed in (Conneau and Lample, 2019), specif-\nically developed to learn joint multilingual repre-\nsentations enabling knowledge transfer across lan-\nguages. In particular, we borrow from XLM the\nmethod developed for unsupervised machine trans-\nlation, that relies on the Masked Language Model\n(MLM) objective (Devlin et al., 2019) applied to\nmultiple monolingual datasets as pretraining. We\nchoose to adopt the unsupervised approach because\nthe alternative (i.e., the supervised one based on\nthe Translation Language Modeling) would need\nto be trained on parallel data, which are not avail-\nable at scale for social media. As in XLM, we use\nByte Pair Encoding (BPE) (Sennrich et al., 2016)\nto learn a shared vocabulary of common subwords\nbetween the languages. This technique has proven\nbeneﬁcial to the alignment of embeddings from\ndifferent languages, when used on languages that\nshare some common traits, such as alphabet and\ndigits.\nFollowing the original approach to MLM, 15%\nof the tokens in a sentence get selected, which get\nmasked 80% of the times, replaced by a random\ntoken in 10% of the cases and kept unchanged 10%\nof the times. In order to reduce the impact of rel-\natively frequent words on the model, tokens are\nsampled according to a multinomial distribution\nthat is proportional to the square root of their in-\nverted frequency. While the original XLM operates\non streams of text, split by sentence separators, we\nsplit the stream of tweets, so that each example\ncontains only one tweet.\nSince using a standard pre-trained language\nmodel to classify irregular data obtained from so-\ncial networks would prove very challenging, we try\nto adapt our cross-lingual model to social media\ndata as much as possible. Speciﬁcally, we rely on\ntwo main intuitions: emojis are linked to emotion\nexpressions, correlated in turn with various forms\nof online harassment (Arslan et al., 2019). Besides,\nemojis could be seen as common traits that are\npresent in tweets across different languages, main-\ntaining a similar meaning at least when comparing\nIndo-European languages (Lu et al., 2016). If we\nconsider the data used in this paper, we can ﬁnd\na good coverage of emojis, with 16.82% of the\ntweets containing at least one emoji for English,\n16.15% for German, 7.68% for Italian, and 18.39%\nfor Spanish. Furthermore, in these datasets the\nmost frequent emojis are shared among all the four\nlanguages, with ‘red heart’, ‘face with tears of joy’,\n‘thinking face’ and ‘smiling face with heart-eyes’\namong the top ten emojis in each dataset. We there-\nfore compare a standard masked language model\nwith one that targets emoji prediction instead of the\ncloze task (Taylor, 1953). However, since emojis\nare not always present in each tweet, we adopt a hy-\nbrid approach: when emojis are not present, the pre-\nviously described MLM objective is trained. When\nemojis are found, we select them as candidates to\nbe masked 80% of the time, replaced by a random\ntoken 10% of the time or kept unchanged 10% of\nthe time as in MLM. With this technique, which we\ncall Hybrid Emoji-based Masked Language Model\n(HE-MLM) we can use all the available data, while\nalso leveraging the common information conveyed\nby emojis.\nWe test also a variant of MLM and HE-MLM,\nin which we put special tokens “ <emoji>” and\n945\n“</emoji>” around all emojis in the dataset, given\nthat we are effectively performing two different\ntasks with the same model. This approach allows\nthe model to distinguish between normal words and\nemojis in the text while training masked language\nmodels.\n3.2 Fine-tuning for abusive language\ndetection\nIn order to assess how invariant our tweet embed-\ndings are with respect to the language provided as\ninput to the encoder, we create a zero-shot frame-\nwork, where the system is only trained on English\ntweets and is evaluated on multiple languages. In\nparticular, we ﬁrst load the pretrained transformer\nand attach to it a single feed-forward layer on top of\nthe encoder with a single, sigmoid activated output\nneuron. The entire model is then ﬁne-tuned on the\nEnglish hate speech detection dataset using a bi-\nnary cross-entropy loss function. The system uses\nearly stopping with the minimum F1 score between\nthe two classes as a stopping criterion, relying on\na balanced dataset that contains all languages as\nvalidation set. Finally, the performance is evalu-\nated on the German, Italian and Spanish test sets to\nassess how our classiﬁer performs on the different\nlanguages using the bilingual models.\n4 Experimental setting\n4.1 Datasets\nSince we run our classiﬁcation in a zero-shot sce-\nnario, we use English data for training, and tweets\nin German, Italian and Spanish for validation and\ntest. The datasets we used and the related number\nof tweets are reported in Table 1. To guarantee a\ncomparable setting for our experiments, we care-\nfully investigated data samples and the annotation\nschemes adopted for the different languages, con-\ncluding that the tweet content as well as the bi-\nnary annotation tagsets (hate-speech/offensive and\nother) of the datasets are similar enough to use\nthem in the same classiﬁcation framework. Also\nthe class distribution is similar, with the abusive\nclass covering around 30% of the tweets in each\ndataset.\nTo pre-train our cross-lingual language models\nwith in-domain data, we gather 5 million tweets\nfor each of the targeted languages (i.e., English,\nGerman, Italian and Spanish). Such tweets have\nbeen collected in different time periods spanning\nfrom March to August 2019 through the Twitter\nENGLISH (Waseem and Hovy, 2016)\nTrain Validation Test\n9,534 –\nGERMAN (Wiegand et al., 2018)\nTrain Validation Test\n– 1,002 (+ 1,002 EN) 3,532\nITALIAN (Bosco et al., 2018)\nTrain Validation Test\n– 600 (+ 600 EN) 1,000\nSPANISH (Basile et al., 2019)\nTrain Validation Test\n– 500 (+ 500 EN) 1,600\nTable 1: Number of tweets used for ﬁne-tuning (En-\nglish), validation and testing (German, Italian, Span-\nish). For each classiﬁcation language, the validation set\ncomprises the same amount of language-speciﬁc and\nEnglish tweets.\nStreaming API using the stopwords of the target\nlanguage as ﬁlter to query the API, as in (Schefﬂer,\n2014).\n4.2 Data splitting\nConcerning the dataset splits into training and test\ninstances, for the English dataset - since no stan-\ndardized split is provided - we randomly selected\n60% of the dataset for training, 20% for valida-\ntion and 20% for testing. For the German and\nItalian datasets, we use the training and test split\nprovided by the Germeval and Evalita task organis-\ners, respectively. In both cases, we use 20% of the\ntraining set as validation set. Whenever we split\nthe datasets, we use the train test split function\nfrom scikit-learn (Pedregosa et al., 2011), using 42\nas a seed value. Finally, for Spanish, we use the\ndevelopment, test and training set provided by the\nHatEval task organisers.\nFor each combination of languages tested in\nour experiments (i.e., English-German, English-\nItalian and English-Spanish), the validation test is\nobtained by keeping the language-speciﬁc valida-\ntion set as is and undersampling the English one to\nthe same size, so that each language has the same\nweight during the early stopping phase.\nBefore classiﬁcation, the text is ﬁrst lowercased,\nall accents are removed, then it is tokenized with\n(Koehn et al., 2007)’s system. Finally, Byte Pair\nEncoding is applied to all datasets by using the\n946\npre-trained model MLM MLM with<emoji> HE–MLM HE–MLM with<emoji>\nLang. Category P R F1 P R F1 P R F1 P R F1 P R F1\nEN\nNon-hate speech0.682 0.993 0.809 0.700 0.736 0.688 0.698 0.387 0.465 0.690 0.830 0.738 0.685 0.907 0.773\nHate speech 0.423 0.013 0.023 0.340 0.293 0.257 0.320 0.625 0.412 0.304 0.185 0.175 0.248 0.099 0.101\nmacro avg 0.553 0.503 0.417 0.520 0.515 0.473 0.509 0.506 0.439 0.497 0.507 0.456 0.466 0.503 0.437\nDE\nNon-hate speech0.660 0.998 0.795 0.626 0.371 0.359 0.477 0.114 0.141 0.575 0.319 0.283 0.656 0.821 0.667\nHate speech 0.142 0.002 0.005 0.294 0.637 0.379 0.342 0.890 0.487 0.286 0.676 0.375 0.112 0.180 0.109\nmacro avg 0.401 0.500 0.400 0.460 0.504 0.369 0.409 0.502 0.314 0.430 0.497 0.329 0.384 0.500 0.388\nTable 2: Average performance (10 runs) on English and German, comparing the En-De model from (Conneau\nand Lample, 2019) pre-trained on Wikipedia, our MLM re-trained on English and German tweets, and our Hybrid\nEmoji-based MLM (HE–MLM). MLM and HE–MLM are evaluated with and without the use of<emoji> tokens.\nMLM MLM with<emoji> HE–MLM HE–MLM with<emoji>\nLang. Category P R F1 P R F1 P R F1 P R F1\nEN\nNon-hate speech 0.473 0.181 0.220 0.699 0.712 0.610 0.449 0.317 0.321 0.616 0.732 0.635\nHate speech 0.326 0.837 0.458 0.113 0.293 0.162 0.273 0.689 0.374 0.170 0.270 0.179\nmacro avg 0.400 0.509 0.339 0.406 0.503 0.386 0.361 0.503 0.347 0.393 0.501 0.407\nIT\nNon-hate speech 0.688 0.718 0.679 0.680 0.891 0.765 0.698 0.740 0.713 0.664 0.446 0.452\nHate speech 0.352 0.301 0.262 0.221 0.122 0.137 0.381 0.326 0.326 0.296 0.587 0.349\nmacro avg 0.520 0.510 0.470 0.451 0.507 0.451 0.539 0.533 0.519 0.480 0.517 0.401\nTable 3: Average performance (10 runs) on English and Italian after re-training the Masked Language Model\n(MLM) on tweets and using Hybrid Emoji-based MLM (HE–MLM).\nfastBPE implementation1. We evaluate the classi-\nﬁer performance over a maximum of 100 training\nepochs, and use an early stopping mechanism with\na patience of 5. The selected model is then used to\nevaluate performance on the test set.\n4.3 Pretraining methods\nSince we want to assess the impact of emojis on\nthe pretraining results, we train four different con-\nﬁgurations:\n•Using the base MLM training objective;\n•Using the base MLM training objective and\n<emoji> tokens;\n•Using the HE-MLM training objective;\n•Using the HE-MLM training objective and\n<emoji> tokens.\nFor each conﬁguration, we pretrain two models in\norder to reduce the impact of random initialization\non the ﬁnal results and we ﬁne-tune each model 10\ntimes (20 total). The ﬁnal results are obtained by\naveraging the results of these 20 runs.\n5 Evaluation\nWe report the experiment results for each language\nin Tables 2, 3, 4. For all languages, training is\nperformed using only English data.\n1https://github.com/glample/fastBPE\nResults for German (Table 2) show that using\nin-domain unlabeled data from Twitter instead of\npre-trained models yields an improvement in per-\nformance on English, while on German the model\nis not able to outperform the pre-trained model. In\nthis case, however, the pretrained model is only\nlearning the non-hate class, while the other three\nmodels all achieve non zero recall on both classes.\nBeside the baseline, the HE–MLM model with\n<emoji> is the best performing one on the Ger-\nman data, while on English the best performance\nis achieved by using the vanilla MLM model.\nWe evaluate MLM and HE–MLM also for zero-\nshot Italian hate speech classiﬁcation, comparing\nthe conﬁgurations with and without <emoji> to-\nkens like in the previous experiments (Table 3). For\nEnglish, the best performing model is HE–MLM\nwith emoji tokens, while on Italian the HE–MLM\nmodel with no tokens is better in terms of macro\naveraged F1. When comparing conﬁgurations, we\nobserve that the MLM model with emoji tokens has\nbetter F1 score than the MLM one in the non hate\nspeech class, while the MLM model has improved\nperformance on the hate class. This results in the\nMLM model having better macro average F1 for\nItalian, while the MLM model with emoji tokens\nshows higher average F1 on English. When consid-\nering the hybrid emoji-based models, HE–MLM\nachieves a higher F1 for the hate speech class in\nEnglish and for the non hate class in Italian. This\nresults in the HE–MLM model having a higher\n947\nMLM MLM with<emoji> HE–MLM HE–MLM with<emoji>\nLang. Category P R F1 P R F1 P R F1 P R F1\nEN\nNon-hate speech 0.667 0.927 0.762 0.692 0.847 0.706 0.752 0.308 0.305 0.699 0.722 0.676\nHate speech 0.072 0.072 0.048 0.118 0.146 0.090 0.316 0.698 0.370 0.296 0.307 0.234\nmacro avg 0.369 0.499 0.405 0.405 0.497 0.398 0.534 0.503 0.337 0.498 0.515 0.455\nES\nNon-hate speech 0.599 0.760 0.655 0.577 0.679 0.599 0.598 0.725 0.648 0.595 0.740 0.643\nHate speech 0.365 0.267 0.275 0.407 0.307 0.298 0.438 0.303 0.332 0.451 0.275 0.280\nmacro avg 0.482 0.513 0.465 0.492 0.493 0.449 0.518 0.514 0.490 0.523 0.507 0.461\nTable 4: Average performance (10 runs) on English and Spanish after re-training the Masked Language Model\n(MLM) on tweets and using Hybrid Emoji-based MLM (HE–MLM).\nmacro averaged F1 in the Italian language, while\nthe HE–MLM model with emoji tokens is better on\nEnglish.\nAs a ﬁnal test, we evaluate the performance of\nthe model trained on English and Spanish (Table\n4). Our English–Spanish models show a similar be-\nhaviour to the one observed for the English–Italian\npair. In terms of macro averages, the HE–MLM\nmodel with emoji tokens has a higher average F1\nfor English, while the HE–MLM model has higher\nmacro F1 for Spanish.\nOn all the runs, the classiﬁer achieves a lower\nperformance on German than on the other two lan-\nguages, while the results on Italian and Spanish are\ncomparable. This conﬁrms the ﬁndings in (Corazza\net al., 2020) suggesting that, even when using the\nsame classiﬁcation framework, experimental set-\nting and amount of training data, offensive speech\ndetection on German achieves lower performance\nthan on other languages. This may have two possi-\nble reasons: on the one hand, German may have in-\nherent characteristics that make it more challenging\nto classify for abusive language detection, for exam-\nple the presence of compound words makes hashtag\nsplitting more error-prone. On the other hand, the\nGermeval dataset was built by sampling data from\nspeciﬁc users and avoiding keyword-based queries,\nso to obtain the highest possible variability in the\noffensive language. This led to the creation of a\nvery challenging dataset, where lexical overlap be-\ntween training and test data is limited and where\nhate speech is not associated with speciﬁc topics or\nkeywords, as suggested in (Wiegand et al., 2019).\n6 Conclusions\nIn this paper, we present a novel zero-shot frame-\nwork for multilingual abusive language detection.\nWe compare two cross-lingual language models,\ni.e., standard MLM and a hybrid version of MLM\nbased on emojis (HE–MLM), highlighting that the\nlatter shows some advantages over the MLM model\nwhen used on social media data: ﬁrst of all, when\nusing emojis, the pre-training step is aimed at pre-\ndicting tokens that are inherently more relevant for\nthe ﬁnal abusive language detection task whenever\npossible, as opposed to random tokens. Secondly,\nemojis convey similar meaning in the languages\nthat we consider, serving as a common trait be-\ntween languages during pre-training. We also use\n<emoji> tokens around emojis to help the system\ndiscriminate between the two training objectives\nwhen using HE–MLM.\nThe proposed methods represent a novel contri-\nbution with respect to social media data processing\nand abusive language detection. Our aim is not\nto create a system comparable with monolingual\nstate-of-the-art solutions, but to investigate the pos-\nsibility to use an unsupervised approach for zero-\nshot cross lingual abusive language detection. As\na ﬁrst step in this direction, we focused on four\nEuropean languages, for which similar data were\navailable. The only existing work dealing with\nzero-shot abusive language detection, presented in\n(Stappen et al., 2020), only focuses on a language\npair and, while obtaining promising results, relies\non the English and Spanish corpora annotated for\nHatEval 2019 following the same guidelines and\nfocusing on hate against immigrants and women.\nOur approach aims to be more robust, comparing\ndatasets annotated for different shared tasks which\nmay adopt slightly different guidelines.\nIn the near future, we plan to further extend the\nsocial media-speciﬁc datasets we are collecting\nto pre-train HE-MLM, since 5 million tweets we\nused for each language correspond to a small-sized\ncorpus compared to standard pre-trained language\nmodels. Then, to investigate whether our results\ncan be generalised also when dealing with typologi-\ncally different languages, we will test our approach\non additional abusive language datasets covering\nother languages (Ousidhoum et al., 2019; Zampieri\net al., 2020).\n948\nReferences\nSweta Agrawal and Amit Awekar. 2018. Deep learn-\ning for detecting cyberbullying across multiple so-\ncial media platforms. In ECIR, pages 141–153.\nPinar Arslan, Michele Corazza, Elena Cabrio, and Ser-\nena Villata. 2019. Overwhelmed by Negative Emo-\ntions? Maybe You Are Being Cyber-bullied! In\nProceedings of the 34th ACM/SIGAPP Symposium\nOn Applied Computing (SAC), Limassol, Cyprus.\nValerio Basile, Cristina Bosco, Elisabetta Fersini,\nDebora Nozza, Viviana Patti, Francisco Manuel\nRangel Pardo, Paolo Rosso, and Manuela San-\nguinetti. 2019. SemEval-2019 task 5: Multilin-\ngual detection of hate speech against immigrants and\nwomen in twitter. In Proceedings of the 13th Inter-\nnational Workshop on Semantic Evaluation , pages\n54–63, Minneapolis, Minnesota, USA. Association\nfor Computational Linguistics.\nCristina Bosco, Felice Dell’Orletta, Fabio Poletto,\nManuela Sanguinetti, and Maurizio Tesconi. 2018.\nOverview of the EV ALITA 2018 hate speech detec-\ntion task. In Proceedings of EVALITA 2018.\nMiguel ´Angel ´Alvarez Carmona, Estefan ´ıa Guzm´an-\nFalc´on, Manuel Montes-y-G ´omez, Hugo Jair Es-\ncalante, Luis Villase ˜nor Pineda, Ver ´onica Reyes-\nMeza, and Antonio Rico Sulayes. 2018. Overview\nof MEX-A3T at IberEval 2018: Authorship and Ag-\ngressiveness Analysis in Mexican Spanish Tweets.\nIn Proceedings of IberEval 2018, pages 74–96.\nCamilla Casula, Alessio Palmero Aprosio, Stefano\nMenini, and Sara Tonelli. 2020. FBK-DH at\nSemEval-2020 Task 12: Using Multi-channel BERT\nfor Multilingual Offensive Language Detection. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation (SemEval-2020) . Association\nfor Computational Linguistics.\nAlexis Conneau and Guillaume Lample. 2019. Cross-\nlingual language model pretraining. In Advances\nin Neural Information Processing Systems 32: An-\nnual Conference on Neural Information Processing\nSystems 2019, NeurIPS 2019, 8-14 December 2019,\nVancouver, BC, Canada, pages 7057–7067.\nMichele Corazza, Stefano Menini, Pinar Arslan,\nRachele Sprugnoli, Elena Cabrio, Sara Tonelli, and\nSerena Villata. 2018. Comparing different super-\nvised approaches to hate speech detection. In Pro-\nceedings of the Sixth Evaluation Campaign of Natu-\nral Language Processing and Speech Tools for Ital-\nian. Final Workshop (EVALITA 2018) co-located\nwith the Fifth Italian Conference on Computational\nLinguistics (CLiC-it 2018), Turin, Italy.\nMichele Corazza, Stefano Menini, Elena Cabrio, Sara\nTonelli, and Serena Villata. 2020. A multilin-\ngual evaluation for online hate speech detection.\nACM Transactions on Internet Technology (TOIT) ,\n20(2):1–22.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nDarja Fiˇser, Ruihong Huang, Vinodkumar Prabhakaran,\nRob V oigt, Zeerak Waseem, and Jacqueline Werni-\nmont, editors. 2018. Proceedings of the 2nd Work-\nshop on Abusive Language Online (ALW2) . Associ-\nation for Computational Linguistics, Brussels, Bel-\ngium.\nPaula Fortuna and S´ergio Nunes. 2018. A survey on au-\ntomatic detection of hate speech in text. ACM Com-\nput. Surv., 51(4):85:1–85:30.\nAntigoni-Maria Founta, Constantinos Djouvas, De-\nspoina Chatzakou, Ilias Leontiadis, Jeremy Black-\nburn, Gianluca Stringhini, Athena Vakali, Michael\nSirivianos, and Nicolas Kourtellis. 2018. Large\nscale crowdsourcing and characterization of twitter\nabusive behavior. In ICWSM, pages 491–500.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris\nCallison-Burch, Marcello Federico, Nicola Bertoldi,\nBrooke Cowan, Wade Shen, Christine Moran,\nRichard Zens, et al. 2007. Moses: Open source\ntoolkit for statistical machine translation. In ACL:\ndemo and poster, pages 177–180.\nYounghun Lee, Seunghyun Yoon, and Kyomin Jung.\n2018. Comparative studies of detecting abusive lan-\nguage on twitter. CoRR, abs/1808.10245.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. CoRR, abs/1907.11692.\nXuan Lu, Wei Ai, Xuanzhe Liu, Qian Li, Ning Wang,\nGang Huang, and Qiaozhu Mei. 2016. Learning\nfrom the ubiquitous language: An empirical analy-\nsis of emoji usage of smartphone users. InUbiComp,\npages 770–780, New York, NY , USA. ACM.\nChikashi Nobata, Joel R. Tetreault, Achint Thomas,\nYashar Mehdad, and Yi Chang. 2016. Abusive lan-\nguage detection in online user content. In WWW,\npages 145–153.\nNedjma Ousidhoum, Zizheng Lin, Hongming Zhang,\nYangqiu Song, and Dit-Yan Yeung. 2019. Multi-\nlingual and multi-aspect hate speech analysis. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 4667–\n4676, Hong Kong, China. Association for Computa-\ntional Linguistics.\n949\nEndang Wahyu Pamungkas and Viviana Patti. 2019.\nCross-domain and cross-lingual abusive language\ndetection: A hybrid approach with deep learning\nand a multilingual lexicon. In Proceedings of the\n57th Conference of the Association for Computa-\ntional Linguistics, ACL 2019, Florence, Italy, July\n28 - August 2, 2019, Volume 2: Student Research\nWorkshop, pages 363–370. Association for Compu-\ntational Linguistics.\nJi Ho Park and Pascale Fung. 2017. One-step and two-\nstep classiﬁcation for abusive language detection on\ntwitter. In Workshop on Abusive Language Online ,\npages 41–45.\nF. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel,\nB. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,\nR. Weiss, V . Dubourg, J. Vanderplas, A. Passos,\nD. Cournapeau, M. Brucher, M. Perrot, and E. Duch-\nesnay. 2011. Scikit-learn: Machine learning in\nPython. Journal of Machine Learning Research ,\n12:2825–2830.\nSarah T. Roberts, Joel Tetreault, Vinodkumar Prab-\nhakaran, and Zeerak Waseem, editors. 2019. Pro-\nceedings of the Third Workshop on Abusive Lan-\nguage Online . Association for Computational Lin-\nguistics, Florence, Italy.\nTatjana Schefﬂer. 2014. A german twitter snapshot. In\nProceedings of Language Resources and Evaluation\nConference (LREC).\nAnna Schmidt and Michael Wiegand. 2017. A survey\non hate speech detection using natural language pro-\ncessing. In Proceedings of the Fifth International\nWorkshop on Natural Language Processing for So-\ncial Media , pages 1–10, Valencia, Spain. Associa-\ntion for Computational Linguistics.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In ACL, Berlin, Germany.\nHajung Sohn and Hyunju Lee. 2019. MC-\nBERT4HATE: hate speech detection using multi-\nchannel BERT for different languages and transla-\ntions. In 2019 International Conference on Data\nMining Workshops, ICDM Workshops 2019, Beijing,\nChina, November 8-11, 2019, pages 551–559. IEEE.\nLukas Stappen, Fabian Brunn, and Bj ¨orn W. Schuller.\n2020. Cross-lingual zero- and few-shot hate speech\ndetection utilising frozen transformer language mod-\nels and AXEL. CoRR, abs/2004.13850.\nWilson L. Taylor. 1953. Cloze Procedure: A New\nTool for Measuring Readability. Journalism Bul-\nletin, 30(4):415–433.\nZeerak Waseem, Wendy Hui Kyong Chung, Dirk Hovy,\nand Joel Tetreault, editors. 2017. Proceedings of\nthe First Workshop on Abusive Language Online. As-\nsociation for Computational Linguistics, Vancouver,\nBC, Canada.\nZeerak Waseem and Dirk Hovy. 2016. Hateful sym-\nbols or hateful people? predictive features for hate\nspeech detection on twitter. In SRW@HLT-NAACL.\nMichael Wiegand, Josef Ruppenhofer, and Thomas\nKleinbauer. 2019. Detection of Abusive Language:\nthe Problem of Biased Datasets. In Proceedings of\nthe 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long\nand Short Papers) , pages 602–608, Minneapolis,\nMinnesota. Association for Computational Linguis-\ntics.\nMichael Wiegand, Melanie Siegel, and Josef Ruppen-\nhofer. 2018. Overview of the germeval 2018 shared\ntask on the identiﬁcation of offensive language. In\nGermEval 2018.\nEllery Wulczyn, Nithum Thain, and Lucas Dixon. 2017.\nEx machina: Personal attacks seen at scale. In Pro-\nceedings of WWW Conference, pages 1391–1399.\nDawei Yin, Zhenzhen Xue, Liangjie Hong, Brian D.\nDavison, April Kontostathis, and Lynne Edwards.\n2009. Detection of harassment on web 2.0. In Pro-\nceedings of the Content Analysis in the Web , pages\n1–7.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019a. Predicting the type and target of offensive\nposts in social media. In Proceedings of NAACL-\nHLT.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019b. Semeval-2019 task 6: Identifying and cate-\ngorizing offensive language in social media (offense-\nval). In Proceedings of the 13th International Work-\nshop on Semantic Evaluation, pages 75–86.\nMarcos Zampieri, Preslav Nakov, Sara Rosenthal, Pepa\nAtanasova, Georgi Karadzhov, Hamdy Mubarak,\nLeon Derczynski, Zeses Pitenis, and C ¸ a˘grı C ¸¨oltekin.\n2020. SemEval-2020 Task 12: Multilingual Offen-\nsive Language Identiﬁcation in Social Media (Offen-\nsEval 2020). In Proceedings of SemEval.\nRobinson D. Zhang, Z. and J. Tepper. 2018. Detect-\ning hate speech on twitter using a convolution-gru\nbased deep neural network. In ESWC, pages 745–\n760. Springer Verlag.",
  "topic": "Emoji",
  "concepts": [
    {
      "name": "Emoji",
      "score": 0.9117962121963501
    },
    {
      "name": "Computer science",
      "score": 0.8285152912139893
    },
    {
      "name": "Natural language processing",
      "score": 0.6892616748809814
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6604897975921631
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6027578115463257
    },
    {
      "name": "Inference",
      "score": 0.5312618613243103
    },
    {
      "name": "Language model",
      "score": 0.5054516792297363
    },
    {
      "name": "German",
      "score": 0.4722553789615631
    },
    {
      "name": "Machine translation",
      "score": 0.45979970693588257
    },
    {
      "name": "Natural language",
      "score": 0.4490358829498291
    },
    {
      "name": "Social media",
      "score": 0.3155025839805603
    },
    {
      "name": "Linguistics",
      "score": 0.18736228346824646
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I9360294",
      "name": "University of Bologna",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I2277624104",
      "name": "Fondazione Bruno Kessler",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I1294671590",
      "name": "Centre National de la Recherche Scientifique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I1326498283",
      "name": "Institut national de recherche en sciences et technologies du numérique",
      "country": "FR"
    }
  ],
  "cited_by": 15
}