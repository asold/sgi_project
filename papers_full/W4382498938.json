{
  "title": "Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models",
  "url": "https://openalex.org/W4382498938",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4366793198",
      "name": "Paula Maddigan",
      "affiliations": [
        "Massey University"
      ]
    },
    {
      "id": "https://openalex.org/A2060503807",
      "name": "Teo Susnjak",
      "affiliations": [
        "Massey University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3081277912",
    "https://openalex.org/W6800878516",
    "https://openalex.org/W4302275696",
    "https://openalex.org/W3213578841",
    "https://openalex.org/W4290874921",
    "https://openalex.org/W3177093812",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W6793933049",
    "https://openalex.org/W3174906424",
    "https://openalex.org/W4281763536",
    "https://openalex.org/W3012830400",
    "https://openalex.org/W4248741877",
    "https://openalex.org/W2274505579",
    "https://openalex.org/W2534380090",
    "https://openalex.org/W6749216537",
    "https://openalex.org/W2965346190",
    "https://openalex.org/W2143017621",
    "https://openalex.org/W2123442489",
    "https://openalex.org/W3172214016",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6811245451",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3198767185",
    "https://openalex.org/W4226277810"
  ],
  "abstract": "The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with prior studies.",
  "full_text": "Received 5 April 2023, accepted 3 May 2023, date of publication 8 May 2023, date of current version 12 May 2023.\nDigital Object Identifier 10.1 109/ACCESS.2023.3274199\nChat2VIS: Generating Data Visualizations via\nNatural Language Using ChatGPT, Codex and\nGPT-3 Large Language Models\nPAULA MADDIGAN\n AND TEO SUSNJAK\nSchool of Mathematical and Computational Sciences, Massey University, Auckland 0632, New Zealand\nCorresponding author: Teo Susnjak (t.susnjak@massey.ac.nz)\nABSTRACT The field of data visualisation has long aimed to devise solutions for generating visualisations\ndirectly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards\nthe development of such techniques. However, the implementation of workable NLIs has always been\nchallenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and\npoorly written user queries which pose problems for existing language models in discerning user intent.\nInstead of pursuing the usual path of developing new iterations of language models, this study uniquely\nproposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and\nGPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper\npresents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates\nhow, with effective prompt engineering, the complex problem of language understanding can be solved more\nefficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS\nshows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations\nfrom natural language queries, even when queries are highly misspecified and underspecified. This solution\nalso presents a significant reduction in costs for the development of NLI systems, while attaining greater\nvisualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar\nrules and tailored models. This study also presents how LLM prompts can be constructed in a way that\npreserves data security and privacy while being generalisable to different datasets. This work compares the\nperformance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with\nprior studies.\nINDEX TERMS ChatGPT, codex, end-to-end visualisations from natural language, GPT-3, large language\nmodels, natural language interfaces, text-to-visualisation.\nI. INTRODUCTION\nThe ability to generate visualisations based on natural lan-\nguage (NL) text has long been a desirable goal in the field of\ndata visualisation. Research into Natural Language Interfaces\n(NLIs) for visualisation has emerged as the primary field that\nhas recently spearheaded the advancements in this area [1],\n[2]. These interfaces allow users to generate visualisations\nin response to NL queries or prompts that are free from\nprogramming and technical constructs, thus providing a\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Walter Didimo\n.\nflexible and intuitive way to interact with data. The ultimate\naim is to devise systems enabling users to express queries like\n‘‘Show me the sales trend?’’ which are correctly understood\nand depicted by automatically discerning the correct chart\ntype.\nThe data visualisation paradigm can be difficult to learn\nfor users [3] who must translate their analysis intentions\ninto tool-specific operations which may take the form of\npoint-and-click applications or code in various programming\nlanguages. Therefore, NLIs can improve the usability of\nvisualisation tools [4] by making them more convenient and\nnovice-friendly as well as effective, and ultimately, inclusive\nVOLUME 11, 2023\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.\nFor more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\n45181\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nfor a broader range of users. As such, approaches like NLIs\nhave the potential to make data and insights more accessible\nto a wider audience and lower the barrier [3] by allowing users\nto express their queries and analysis intentions in a form that\nis most natural to them.\nThe process of translating NL inputs into visualisations\n(NL2VIS) involves several non-trivial tasks. Generally, the\ninput query is first parsed and modelled, then the required\ndata attributes are identified, and the low-level analytic tasks\nexpressed within the query are discerned. These low-level\ntasks, such as filtering, correlation, and trend analysis, must\nthen be translated into code to be executed. Finally, the input\nquery is analysed and matched with the most appropriate\nvisualisation, and then code is invoked to render the data.\nEach component in the pipeline is error-prone.\nThe implementation of NL2VIS is a particularly challeng-\ning task due to the inherent characteristics of NL, such as\nambiguity and the underspecification of requirements in the\nprompts, as well as unavoidable typographical errors. These\ncharacteristics of NL make it difficult to accurately interpret\nthe user’s intent and generate appropriate visualisations with\nthe existing technologies and approaches [5]. Despite these\nchallenges, the popularity of NLIs for data visualisation has\ncontinued to grow, being driven by the demand for data\nanalytics and the increasing need for flexible and intuitive\nways of interacting with data.\nThe performance of NLIs for visualisations is largely\ndependent on Natural Language Processing (NLP) models [6]\nand their robustness in understanding NL. A recent com-\nprehensive survey [6] of the use of NLIs for visualisations\nnoted that while most existing approaches utilise hand-crafted\ngrammar rules that require proficiency with typical NLP\ntoolkits, more complex large language models (LLMs) like\nGPT-3 which are capable of achieving human-level perfor-\nmance on specific tasks [7] have not yet been implemented\nor explored for visualisation generation directly from NL.\nLLMs have revolutionised the field of NL understanding and\ngeneration. These models are based on the transformer archi-\ntecture [8] which has demonstrated remarkable successes in\ntasks such as sentiment analysis, question-answering, and\nlanguage generation owing both to the effectiveness of the\narchitecture, and also due to them being trained on vast\namounts of data. The data used to train these models typically\ncomes from the internet and can include websites, books,\nand code repositories. As a result of being trained on such a\nlarge amount of data, LLMs have developed a comprehensive\nunderstanding of the structure and meaning of language,\nallowing them to perform tasks in a highly sophisticated\nmanner, but also important to this study, the ability to generate\ncode in response to NL requests. For these reasons, LLMs\noffer the potential to accurately understand free-form NL\ninput and the capability to convert it into functional code that\ngenerates suitable visualisations which correctly pair with the\nunderlying data types.\nContribution: This study is the first of its kind to propose\nan end-to-end NL2VIS solution which converts free-form\nconversational language into visualisations via LLMs. The\npresent work leverages the most recent advances in LLM\ntechnologies and AI in general, specifically investigating\nChatGPT and GPT-3, which are considered state-of-the-\nart [7]. The advantage of using pre-trained LLMs for this task\nis that they offer not only accuracy gains in robustly under-\nstanding user requests, even when malformed, but they also\nresult in accelerated development turnarounds and a signifi-\ncant decrease in costs. Despite the capabilities of these mod-\nels to display human-like performance on specific tasks, the\nintegration of LLMs with NLIs for visualisation has not been\nexplored in published literature. Therefore, this study seeks\nto examine the capability and comparative performances\nof two types of GPT-3 models and ChatGPT for NL2VIS\ntasks that also include the automatic selection of chart types,\nthrough numerous experiments and examples. The experi-\nments demonstrate the potential of the LLMs to enhance\nthe performance of NL2VIS in terms of accuracy, efficiency,\nand cost reduction, thus potentially minimising the need to\ndevise new language models for this problem going forward.\nThis work also demonstrates how LLMs can be used in a\nmanner that is data-privacy preserving and security-aware,\nmaking the approach generalisable to all types of datasets,\nirrespective of confidentiality concerns. In the process, this\nstudy shows how prompts for LLMs can be engineered to\nelicit desired outputs. Furthermore, the system developed\nhere has also been made publicly available through an online\napplication for testing and experimentation, with the ability\nfor users to upload their datasets and generate visualisations. 1\nII. RELATED WORK\nIn recent years, the idea of using NL as a way to create\nvisualisations has gained significant attention within the field\nof data visualisation [4], [9]. The use of NLIs has also\ngrown in popularity in commercial software as a means\nof improving the usability of visualisation systems. Vari-\nous tools, such as IBM Watson Analytics, Microsoft Power\nBI, Tableau, ThoughtSpot, and Google Spreadsheet, have to\nvarying degrees implemented NLIs that allow users to gener-\nate visualisations in response to NL queries or prompts [1],\n[3], [4], [10], [11] indicating the level of demand for this\ninnovation. These are early commercial iterations of this tech-\nnology as these systems typically constrain NL interactions\nto data queries and standard chart types, and do not support\nmore complex or open-ended visualisation tasks [3].\nNL modelling techniques, which underpin NL2VIS, can\nbroadly be categorised into traditional symbolic-based NLP\napproaches which rely on explicit rules and representation\nof the language structure and the emerging neural machine\ntranslation methods which rely on language models devel-\noped typically through deep learning [10]. Fig. 1 depicts the\n1Chat2VIS is currently hosted on Streamlit Cloud and can be accessed via\nhttps://chat2vis.streamlit.app/\n45182 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 1. Timeline depicting the recent evolution of NL2VIS systems and\nthe proposed Chat2VIS system.\nrecent evolution of NL2VIS systems in published literature, 2\nand their trend towards more sophisticated machine learning\napproaches, where the authors in this study posit that the\nlogical trajectory is pointing in the direction of using the most\nadvanced AI systems like LLMs for language understanding\nand code generation.\nA. SYMBOLIC NLP APPROACHES\nSymbolic approaches to NLP can involve heuristic, rule-\nbased and probabilistic grammar-based approaches for\nparsing and understanding NL. Heuristic algorithms use\npre-defined rules or heuristics to find approximate solu-\ntions for complex problems like NL and tend to be less\naccurate than other methods [13]. Meanwhile, rule-based\napproaches rely on predefined rules created by experts for\nunderstanding NL. They are more accurate and reliable but,\nalso less flexible in handling complex queries [9]. Probabilis-\ntic grammar-based approaches use formal grammar rules and\nprobability distributions over the possible parses of a given\ninput. These approaches are considered more accurate as well\nas flexible than the previous approaches but require more\ncomputational resources. Each of these approaches presents\ncomplexities and can be time-consuming and challenging to\nresolve especially for developers without prior experience\n[1].\nThe majority of the earlier systems have been developed\nusing these approaches [11], including Articulate [14], Data-\nTone [15], Eviza [16], and Deep-Eye [17], with each using\ndistinct methodologies for mapping NL queries to visuali-\nsations. Certain systems also allow for user interaction to\nmanage ambiguities. Meanwhile, recent state-of-the-art stud-\nies like NL4DV [1] and FlowSense [18] using symbolic\nNLP approaches have relied on semantic parsers such as\nNLTK [19], NER, and Stanford CoreNLP [20], to auto-\nmatically add layers of valuable semantic information, such\nas parts-of-speech (PoS) tagging and named entity recogni-\ntion to the NL input which improves accuracy. NL4DV [1],\n2YoloPandas [12] , a Python module leveraging LLMs to execute com-\nmands with natural language that also includes visualisations was released\nas this manuscript was being prepared for publication.\nan open-source Python toolkit, accepts NL queries for a given\ndataset and outputs a JSON object with keys for dataset\nattributes, analytical tasks, and Vega-Lite visualisation speci-\nfications. This framework enables those who lack NLP exper-\ntise to harness NL2VIS concepts by creating NLIs or render-\ning the output in their own systems.\nB. DEEP-LEARNING MODEL APPROACHES\nA more promising route has been highlighted by recent\nadvancements in NL2VIS systems which have shifted the\nfocus towards neural end-to-end models that leverage deep\nlearning. These approaches combine the processes of lan-\nguage understanding, reasoning and chart generation in a\nsingle system and are closer to the proposed system in\nthis study. These approaches aim to achieve greater robust-\nness, flexibility and adaptability compared to traditional\nmethods [9].\nOne notable system developed along these lines is ADVI-\nSor [21]. ADVISor comprises multiple customised deep\nlearning modules for determining the necessary visualisa-\ntion data and appropriate attributes, as well as the filter and\naggregation operations. These models are underpinned by the\nlarge language transformer-based BERT [22] model which\nperforms the vectorisation of user input and the data attribute\nnames for subsequent steps. Meanwhile, the chart type is\nchosen based on a predefined rule map.\nncNet [4] is a novel approach which also uses\ntransformer-based models and visualisation-aware optimi-\nsations. ncNet is a machine learning model that is trained\nusing the nvBench [23] dataset, which maps natural language\nqueries to visualisations. The system accepts the NL query\nand an optional chart template as an additional input to\nconstrain the possible visualisations being outputted. The\napproach has been evaluated through a quantitative evaluation\nas well as a user study, and has shown promising accuracy\nin the nvBench benchmark. Recently, this system has been\nextended to include speech-to-visualisation capabilities [11].\nMeanwhile, a system called RGVisNet [5] was developed\nthat decouples the NL2VIS process into two subtasks which\nconsist of a hybrid retrieval and a generation framework. The\nfirst part of the system retrieves the most relevant visualisa-\ntion query from a large-scale visualisation codebase which\nserves as a candidate prototype that is refined in the next step\nby a GNN-based deep-learning model.\nSummary of Literature and Research Aims: The trends\nin NL2VIS research highlight that the focus is moving\ntowards using transformer-based deep learning models and\nend-to-end solutions, and away from the complex task\nof engineering symbolic-based language models. Recent\nadvancements, such as the use of pre-trained language models\nlike BERT and domain-specific models like ncNet, have\nshown promising results in various benchmarks. However,\nthere is a gap in the literature exploring the recent state-\nof-the-art pre-trained LLMs which are significantly larger\nand more sophisticated. This work aims to address this gap\nVOLUME 11, 2023 45183\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 2. The Chat2VIS architecture for converting free-form query text into visualisations using the large language models GPT-3, Codex, and ChatGPT.\nand examines the potential to simplify the NL2VIS pipeline,\nwhile making it more robust for free-form NL and complex\nvisualisation tasks. Additionally, while advanced systems\nlike ADVISor [21] and ncNet [4] rely on various explicit\nmechanisms for determining which types of visualisations\nare to be rendered, the proposed system addresses this gap\nby investigating the ability to delegate the chart selection\ndecision-making to the AI component.\nC. RESEARCH QUESTIONS\nIn light of the existing literature, this study poses the follow-\ning research questions:\n• (RQ1) Do current LLMs support accurate end-to-end\ngeneration of visualisations from NL?\n• (RQ2) How can LLMs be effectively leveraged to elicit\nthe generation of correct and appropriately rendered\ncharts?\n• (RQ3) Which LLMs tend to perform more robustly to\nNL prompts? How do they perform against other state-\nof-the-art approaches?\n• (RQ4) What are the limitations of using LLMs for\nNL2VIS as well as the future research directions?\nIII. METHODOLOGY\nThis study explored the ability of three OpenAI LLMs\nto generate Python scripts for visualising data based on\nNL queries without explicit direction as to which types of\ngraphs to generate. The models chosen for this investigation\ninclude the most advanced model family, Davinci, specif-\nically the GPT-3 model ‘‘text-davinci-003’’ and the Codex\nmodel ‘‘code-davinci-002’’, as well as the most recent addi-\ntion, ChatGPT.3\nThe Davinci model family consists of billions of param-\neters,4 and is widely considered to be the most capable of\nall available models in its ability to follow instructions. This\nmodel family is based on GPT-3, with the Codex model\nreceiving additional training data from a massive quantity\nof GitHub repository code. This makes the Codex model\nparticularly well-suited for translating NL into code, being\nproficient in over a dozen programming languages, with\nPython being the target language in this study.\nFig. 2 depicts the overview of the developed Chat2VIS\nsystem. A user enters a NL query via a Streamlit NLI app\nwhich is an open-source Python framework for web-based\ndashboards. The query is combined with a prompt script\nwhich engineers a suitable prompt for a selected dataset. The\nprompt is forwarded to selected LLMs, which return a Python\nscript that is subsequently rendered within the Streamlit NLI.\nA. NATURAL LANGUAGE INTERFACE\nThe interface for the Chat2VIS software artefact used in this\nstudy is depicted in Fig. 3. The interface enables users to\nselect a dataset and enter free-form text describing their data\nvisualisation intent. The side toolbar provides the function-\nality to import additional CSV files and SQLite databases,\nwith options to choose the desired LLMs to render the\n3OpenAI documentation refers to ‘‘text-davinci-003’’, ‘‘code-\ndavinci-002’’ and ChatGPT models as belonging to the GPT-3.5 series\nhttps://platform.openai.com/docs/model-index-for-researchers During the\nfinal preparation of the manuscript, GPT-4 has been released.\n4The reported number of parameters is 175B.\n45184 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nvisualisations. An OpenAI Access Key is required to access\nthe models and must be entered prior to querying. An input\nbox is provided for entering the NL free-format text. Visuali-\nsations are presented for each selected model, with the actual\ndataset also shown to the users.\nB. PROMPT ENGINEERING\nThe most effective method for obtaining the desired output\nfrom the LLM is to use the ‘‘show-and-tell’’ technique 5\nby supplying within the prompt an example together with\ninstructions. The proposed system generates an LLM prompt\nconsisting of two parts: (1) a Description Prompt built from\na Python docstring and declared using triple double quotes\n‘‘\"’’ at the beginning and the end of the definition, (2) a Code\nPrompt comprising of Python code statements that provides\nguidance and a starting point for the script.\nThe structure of the prompt is presented in Fig. 4 and is\ndescribed by way of an example dataset, using the prod-\nucts table from the nvBench database 6 department_store,\npre-loaded into dataframe df_products. For context, the\nexample dataset lists the prices for a selection of clothing\nproducts such as coloured jeans and tops, together with hard-\nware products like monitors and keyboards. There are four\ncolumns, product_id, product_type_code, product_name and\nproduct_price which have data types int64, object, object and\nfloat64 respectively.\nThe Description Prompt and the Code Prompt shown in\nFig. 4 are depicted in components in order to aid their expla-\nnation. The bolded type highlights substitution values which\nare variable and dependent on the chosen dataset and are thus\nspecific to this illustration. These provide an overview of the\nDataFrame (a tabular data object) to the LLM, listing column\nnames, their data types and categorical values, which assists\nthe LLM in understanding the context, while maintaining data\nprivacy by withholding the actual raw values from being sent\nto the LLMs. Each component of the proposed prompt is\ndescribed as follows:\n1) The Description Prompt is initiated with a Python doc-\nstring Fig. 4(a)\n2) In Fig. 4(b) the LLM is explicitly informed to use a\nDataFrame with the name df which enables a reference\nto be made to this DataFrame by a specific name,\nthereby avoiding any confusion that might arise if the\nLLM were to assign a different name to the DataFrame.\nEven though it was opted to utilise a pre-loaded CSV\nfile, there may be instances when the LLM (typically\nChatGPT) includes code for loading the file. By antic-\nipating the file name as data_file.csv, one can easily\nidentify and eliminate this code if required before exe-\ncution.\n3) The Description Prompt in Fig. 4(c) consists of one\nentry for each column indicating its data type. If a\n5https://beta.openai.com/docs/guides/completion/prompt-design\n6https://github.com/TsinghuaDatabaseGroup/nvBench/blob/main/\nnvBench_VegaLite/VIS_6.html\nTABLE 1. API parameters.\ncolumn with an object data type has less than 20 distinct\nvalues, it is deemed as a categorical type, and its values\nare enumerated in the prompt. This listing could aid the\nLLM in identifying keywords for certain requests, for\ninstance, prompts relating to keyboards or black jeans\nin this example.\n4) In Fig. 4(d) the LLM is asked to decide on appropriate\nnaming for the x and y axes, and the plot title. In some\ncases, when working with grouped data, particularly\nbox plots, the LLMs add a plot super-title unnecessar-\nily. To address this, it is recommended to remove it by\nusing positive instructions and explicitly setting it to\nempty.\n5) To encourage correct syntax, the Python version is\nincluded as shown in Fig. 4(e).\n6) The Description Prompt concludes with an instruction\nto create a plotting script with the supplied user query\nin Fig. 4(f).\n7) For this demonstration, the submitted NL query from\nnvBench is: What is the highest price of product,\ngrouped by product type? Show a bar chart, and display\nby the names in desc.\n8) The Python docstring in Fig. 4(g) closes off the\nDescription Prompt\n9) The Code Prompt begins with import statements for the\nrequired Python packages that is deemed helpful for the\nLLMs to use in Fig. 4(h).\n10) To foster uniformity in the plot layout, the prompt asks\nfor a single subplot with a fixed figure size in Fig. 4(i)\nin an attempt to render equivalently sized plots on the\ninterface.\n11) By assigning a copy of the named DataFrame in\nFig. 4(j) to the variable df in the Code Prompt, con-\nsistency is ensured within the script and enables the\noriginal DataFrame to be retained for further querying.\nOnce formulated, the two prompt elements are amalga-\nmated, with the resulting string submitted to the LLMs via the\ntext completion endpoint API with settings shown in Table. 1.\nUnspecified parameters remain at their default values.\nWith many variations to Python scripting, the model tempera-\nture is set to 0 to help ensure the LLM is less creative and more\nconsistent in its code generation. To encourage the model to\navoid any unnecessarily long script responses, a token limit of\n500 is enforced for responses. The authors believe this limit\nis sufficient for generating a Python script within the context\nof this study. A stopping point is specified to avoid returning\nmultiple script examples and code alternatives.\nVOLUME 11, 2023 45185\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 3. The Streamlit Chat2VIS Natural Language Interface enabling dataset visualisations from free-form text queries.\nC. SCRIPT REFINEMENT AND RENDERING\nOn the return of the script from the API for each model,\nthe Code Prompt is inserted at the start and the Python code\nmay be edited to eliminate unnecessary instructions. It is\nrendered on the interface for each LLM. To further enhance\nthe visualisations, users can refine their NL query, including\nrequesting alternative chart types, plot colours, labels etc.\nD. Chat2VIS EVALUATION\nThe capabilities of the proposed Chat2VIS system to render\nvisualisations based on NL input via LLMs, and their unique\ndecision-making skills in autonomously selecting appropriate\ncharting elements are demonstrated over six case studies\ncovering five datasets. Four of these case studies are repro-\nduced from examples in existing literature, comparing the\nresulting visualisations here with those from prior studies\nusing nvBench SQLite databases 7 and the NL4DV Python\npackage.8 One case study is taken from NL4DV [1], one\nfrom ADVISor [21] in which the authors also use NL4DV\nin their evaluation, and the final two using databases from\nnvBench [23].\nIn the remaining two case studies, this study tests the\ncapabilities of the LLMs and the prompt scripts to handle\n7https://sites.google.com/view/nvbench\n8https://nl4dv.github.io/nl4dv/documentation.html\nmisspecification in the form of typographical errors as well\nas acute underspecification, where the ability of the LLMs\nto exhibit reasoning and assumptions in the context of the\npriming text is explored.\nThe results are inspected and evaluated visually for cor-\nrectness and suitability. All case study examples are also\nreproducible from the online web app. The non-deterministic\nnature of the LLMs does occasionally lead to variability in\nplot generation even when an identical prompt is resubmitted.\nIV. RESULTS\nA. CASE STUDY 1: DEPARTMENT STORE DATASET\nThe first example is based on the products table illustrated\nabove in the description of the prompt engineering which\noriginated from the nvBench department_store database. The\ntest query is as follows: ‘‘What is the highest price of product,\ngrouped by product type? Show a bar chart, and display by\nthe names in desc. ’’. The query is categorised by nvBench as\nan easy visualisation for NLI systems. Fig. 5 shows results\ngenerated by Chat2VIS alongside the correct nvBench visu-\nalisation. GPT-3 and Codex produce identical results, with\nChatGPT rotating labels for ease of reading and arguably pro-\nviding a slightly more comprehensive title. All three LLMs\nprovide more informative x and y axis labelling and titles than\nthe ground truth example from nvBench.\n45186 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 4. Description and Code Prompts built from combining the\nfree-form text query with the selected dataset to be submitted to the\nLLMs.\nB. CASE STUDY 2: COLLEGES DATASET\nThis dataset holds information on students and staff at U.S.\npublic and private colleges. The colleges dataset9 was used\n9https://github.com/nl4dv/nl4dv/blob/master/examples/assets/data/\ncolleges.csv\nby [1] to demonstrate the Vega-Lite editor for rendering\nqueries visualised by NL4DV . The output from their toolset\nrendered via Streamlit is compared with Chat2VIS results.\nThe broadness of the submitted query used in their study\n‘‘Show debt and earnings for Public and Private colleges. ’’\nallows flexibility for different interpretations of the request.\nThe figure (Fig. 6) demonstrates that GPT-3 generated a\nscatter plot, similar to that produced by NL4DV , to represent\nthe relationship between median debt and median earnings\nfor all colleges by type. Codex interpreted the query by cre-\nating a bar chart to show the mean value of debt and earnings\nfor each college type. ChatGPT focused on the distributions\nof debt and earnings by creating a box-and-whisker plot for\npublic and private colleges. The models were able to differen-\ntiate between public and private colleges using the ‘‘Control’’\ncolumn, which was not easily recognisable as a college type.\nHowever, by providing categorical values in the prompt, the\nmodels were able to accurately categorise the data based on\nthe ‘‘public/private’’ indicator in the column. In addition, the\nmodels were required to perform further reasoning in order to\narrive at the decision to extract data from the ‘‘Median Debt’’\nand ‘‘Median Earnings’’ columns, having only been queried\nto show debt and earnings, thus illustrating the capability of\nAI inference potentials.\nC. CASE STUDY 3: ENERGY PRODUCTION DATASET\nThe next set of visualisations is depicted on the Energy\nProduction Dataset described in the ADVISor study and com-\npared to those of both ADVISor and NL4DV outputs. The\ndataset details coal, oil, gas, and nuclear energy production\nin megawatt-hours per person per year from 2000 to 2011 for\nan unspecified country, including population statistics.\nHere, the test query used is from the ADVISor study,\n‘‘What is the trend of oil production since 2004?’’. The results\nfrom Chat2VIS are shown in Fig. 7 together with the output\nfrom NL4DV rendered via Streamlit. The results can be\ncompared with the ADVISor plot presented in their study.\nAll three LLMs select a line plot as the most suitable style\nof plot for this query, with GPT-3 and ChatGPT correctly\nshowing data from 2004 onward. Codex, however, neglects\nto incorporate this detail into its code generation and has\ndepicted data from 2000 onwards. NL4DV has produced an\nincorrect visualisation due to its semantic parsing limitations\nwhich lacks flexibility, as mentioned in [21]. The ADVISor\nplot also selected the correct chart type, but like Codex,\nit was unable to filter the data to include 2004 onwards.\nIt did, however, highlight the data points from 2004 onwards\ndrawing attention to the oil trend and the selected data range.\nD. CASE STUDY 4: CUSTOMERS AND PRODUCTS\nCONTACTS DATASET\nThe following example provides a demonstration of a\nmore complex NL2VIS task from the products table in\nVOLUME 11, 2023 45187\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 5. Case Study 1: Chat2VIS results compared with nvBench using the department store dataset with query‘‘What is the highest price of product,\ngrouped by product type? Show a bar chart, and display by the names in desc. ’’\nFIGURE 6. Case Study 2: Chat2VIS results compared with NL4DV using the Colleges Dataset with query‘‘Show debt and earnings for Public and Private\ncolleges. ’’\nthe customers_and_products_contacts database,10 which the\nnvBench example benchmark classifies as Extra Hard. The\n10https://github.com/TsinghuaDatabaseGroup/nvBench/blob/main/\nnvBench_VegaLite/VIS_299.html\nquery is ‘‘Show the number of products with price higher than\n1000 or lower than 500 for each product name in a bar chart,\nand could you rank y-axis in descending order?’’.\nFig. 8 shows all three models generate similar visuali-\nsations to the ground truth example specified in nvBench.\n45188 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 7. Case Study 3: Chat2VIS results compared with NL4DV using the Energy Production Dataset with query‘‘What is the trend of oil production\nsince 2004?’’\nFIGURE 8. Case Study 4: Chat2VIS results compared with nvBench using the Customers and Products Contacts Dataset with query‘‘Show the number\nof products with price higher than 1000 or lower than 500 for each product name in a bar chart, and could you rank y-axis in descending order?’’\nChatGPT provides a slightly more informative title, convey-\ning that products with a price higher than 1000 are ‘‘expen-\nsive’’ and those lower than 500 are ‘‘cheap’’. Despite Sony\nand & jcrew products swapped in comparison to nvBench,\nboth have a value of 3 and are plotted accurately. The visuali-\nsation from Codex, while correct, is sub-optimal, requiring\nsome further improvement in its coding structure to elim-\ninate the multiple bar plotting. All three plots show more\nVOLUME 11, 2023 45189\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 9. Case Study 5: Chat2VIS plots depicting the output from the misspelt prompt‘‘draw the numbr of movie by gener’’.\ninformative axis labels than their nvBench counterpart. The\nexample demonstrates the high capability levels of Chat2VIS\nto handle challenging NL queries.\nE. CASE STUDY 5: MISSPECIFIED PROMPTS\nThe following example illustrates the robustness of Chat2VIS\nto input errors that take the form of typographical mistakes.\nThe movies 11 dataset is used here and contains information\non movies released between 1996 and 2010, including details\nsuch as financials, ratings, and classifications. The ideal\nquery in this example is ‘‘Plot the number of movies by genre’’\nhowever, the system is prompted with ‘‘draw the numbr of\nmovie by gener’’.\nThe results are shown in Fig.9. The correct results across\nall three LLMs highlight the ability of the LLMs to inter-\npret language even in the presence of multiple typographical\nerrors and misspecification, thus emphasising their robust-\nness. However, from the point of view of clarity of insights,\nthe figure generated by ChatGPT is superior to those of the\nother models since it has decided to render the results as a\nrank-ordered bar graph in a descending order, while GPT-3\nand Codex presented movies alphabetically.\n11https://github.com/nl4dv/nl4dv/blob/master/examples/assets/data/\nmovies-w-year.csv\nF. CASE STUDY 6: UNDERSPECIFIED AND AMBIGUOUS\nPROMPTS\nThe movies dataset is again used in this example in order\nto demonstrate the inference capabilities of the LLMs\ntogether with the underlying priming prompts developed for\nChat2VIS, to creatively make decisions based on extremely\nunderspecified or ambiguous queries.\nThe test query used here is: ‘‘tomatoes’’, which has an\nassociation with an existing column in the dataset called\nRotten Tomatoes Rating. Fig. 10 demonstrates the results.\nRemarkably, the figures demonstrate that each LLM was able\nto make inferences and produce a figure that connected the\nresults with the Rotten Tomatoes Rating despite a lack of\ndirection.\nGPT-3 plots the rating against the IMDb Rating column.\nIt is uncertain whether this column is selected due to it being\na rating column or simply because it is the next column in\nthe dataset. Codex plots the rating for every title, producing\nan aesthetically unusable visualisation due to overcrowding,\nwhile ChatGPT produces a meaningful distribution plot of the\nratings.\nV. DISCUSSION\nThe experimental results from the six case studies in this work\nconfirm that LLMs can effectively support the end-to-end\n45190 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nFIGURE 10. Case Study 6: Chat2VIS plots depicting the output from the underspecified and ambiguous prompt‘‘tomatoes’’.\ngeneration of visualisations from NL when supported by\nwell-engineered prompts, and are therefore, an ideal solu-\ntion for the NL2VIS problem (RQ1). The proposed method\nexhibits a number of advantages over existing NL2VIS sys-\ntems which rely on developing tailored symbolic NLP and\ndeep learning approaches for the NL semantic analysis com-\nponent. The primary one is efficiency since LLMs provide\nan end-to-end solution from language understanding to code\ngeneration. This results in reduced development expenses, but\nalso, in higher accuracies. As such, LLMs offer a pre-trained\nand simplified solution to the most difficult problem of\nunderstanding NL, while also providing advanced capabili-\nties for automated chart selection as well as the encapsula-\ntion of the code generation. The abilities of current LLMs\nraise questions about the necessity to continue to further\nexplore symbolic NLP approaches for providing solutions\nto NL2VIS as a whole. Meanwhile, the proposed method\ndemonstrated superior performances over existing methods,\nwhile showing robustness to misspecified and highly under-\nspecified NL queries. Since the accuracy of LLMs will only\ncontinue to improve with time, they therefore represent the\nmost viable solution for developing NL2VIS systems going\nforward.\nTo leverage this technology (RQ2), this study demon-\nstrated the importance of prompt engineering in providing\nthe LLMs with clear and concise NL requests. The study\ndemonstrated how effective prompts can be engineered using\nDescription and Code Prompt definitions that inform LLMs\non the underlying data attributes as well as a coding guide.\nThe results confirm that LLMs can be effectively primed with\nthe proposed prompts, and it is the prompt engineering that\nhelps elicit the correct chart selection and the appropriately\nrendered charts when accompanying the NL requests. The\ndemonstration of the autonomous selection of correct plotting\ntypes by LLMs goes beyond the capabilities of prior studies.\nIn terms of performance (RQ3), the preliminary results\nindicate that the capability between ChatGPT, GPT-3 and\nCodex LLMs tend not to show large deviations. Arguably,\nsome enhanced performance was exhibited by ChatGPT. The\nlargely comparable performances can likely be attributable to\nthe fact that the three LLMs were trained on similar datasets.\nWhile the results demonstrate the potential of LLMs for\nNL2VIS, there are still some challenges to this technology\n(RQ4), mostly minor, and centering around aesthetic features\nof graphs and variations in visualisation results. These chal-\nlenges are addressed individually below.\nVOLUME 11, 2023 45191\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nA. REMAINING CHALLENGES\nWhile the proposed framework has performed impressively\nwell and provided a viable solution to the problem of con-\nverting free-form NL directly into visualisation, some minor\nchallenges still remain.\n1) SETTING THE PLOT BACKGROUND COLOUR\nProviding instruction within the engineered prompt to con-\nsistently and successfully generate code to change the back-\nground colour of a plot proved unsuccessful. With multiple\nfactors at play, ranging from the type of plot generated and\nthe Python container it is rendered within, through to software\ntheme settings, no consistent approach was unearthed.\n2) DISPLAY OF PLOT GRID LINES\nThe incorporation of grid lines into a plot can enhance its\naesthetics and aid in its interpretation. However, generating\nprecise code for the successful rendering of grid lines is often\ndetermined by the choice of plot type. As this is not spec-\nified within the engineered prompt, it is difficult to inform\nthe LLM of the correct methods and function parameters to\nrender the grid lines successfully. With thorough experimen-\ntation, the LLMs produced varying levels of success when\nthe request for horizontal grid lines was included in the engi-\nneered prompt. Therefore, it is more favourable to request the\nadjustment of styling elements such as grid lines during the\nrefinement of the NL query, and will be most successful when\nperformed in conjunction with explicitly stating the type of\nplot to be rendered.\n3) SPECIFYING COLOURING OF PLOT LINES AND ELEMENTS\nAnalogously to the problems encountered with rendering\ngrid lines, specifying refinements to other plotting elements\nsuch as line colour proved challenging within the engineered\nprompt. With the dependence of some function and parameter\nvalues on plot type selection, LLMs on occasion attempted\nto invoke unsuitable functions or assign values to unknown\nparameters while endeavouring to style plot elements as\nrequested. As with grid line refinement, styling of plot lines\nwill be most successful when combined with plot type and\nincluded as an extension to the user query.\n4) VARIABILITY IN PLOT GENERATION\nIdentical prompts to the same language model can result in\nsignificant variability in the type of plot generated and its\nfeatures. This can make it difficult to consistently gener-\nate the desired visualisations. With their non-deterministic\nnature, especially of ChatGPT, is not possible to address\nthis adequately at this stage since parameters that regulate\nthe stochastic processes in its reasoning are not yet publicly\navailable.\n5) REFINING THE PROMPT FOR BEST RESULTS\nThe generic and verbose nature of the engineered prompt\ncaters to all three LLM models, but experimentation has\nshown that the ideal prompt for each model can be varied\nslightly to achieve the best results. Once a specific LLM\nis selected, the prompt may be optimised and refined for\ngenerating the best visualisations.\nStudy Limitations and Future Work: The current study\nincluded a limited number of case studies consisting of a\nselection of NL queries and example visualisations. Ideally,\na comprehensive evaluation of a system like Chat2VIS would\ninclude end-users and a qualitative assessment of the system’s\nusefulness based on their feedback. While the evaluation of\nNLIs in data visualisation is a complex task in the context\nof end-user experience, it is the intention of the authors to\nexpand this study and conduct this type of evaluation in the\nsubsequent work.\nFuture work will explore the incorporation of the nvBench\nbenchmark dataset into the refinement of the Chat2VIS capa-\nbilities and make use of the dataset for a more comprehensive\nquantitative analysis of its capabilities across a wider set\nof queries, thus enabling a more robust comparison against\nresults from prior studies. Additionally, a valuable future\nresearch direction is the study of the effects of perturbations in\nthe LLM prompts for this domain, quantifying the sensitivity\nin the changes of the quality of the outputs. Comparing the\ncapabilities of a wider range of LLMs, including YoloPandas,\nto solve the NL2VIS problem is also a worthwhile undertak-\ning; however, methods and benchmark datasets that support\nthe automation of comparisons need to be further developed\nin this area in order to facilitate progress.\nVI. CONCLUSION\nThe ability to generate visualisations based on natural lan-\nguage has been a long-standing goal in the field of data visu-\nalisation. The development of Natural Language Interfaces\nhas paved the way for advancements in this area making data\nvisualisation more accessible to a broader range of users by\nallowing them to express their queries and analysis intentions\nin natural language. However, the process of accurately and\nreliably translating natural language inputs into visualisations\n(NL2VIS) has been a challenging problem to solve due to the\ndifficulty in understanding natural language.\nThis study proposed a novel end-to-end solution for con-\nverting free-form natural language into visualisations using\nstate-of-the-art Large Language Models (LLMs). This study\nexplored ChatGPT and its predecessors like GPT-3 and\nCodex for their ability to solve the task of understand-\ning the queries and both auto-generating code while using\ntheir internal inference abilities for selecting the appropriate\nvisualisation types. The proposed system, Chat2VIS, has\ndemonstrated that the use of pre-trained LLMs together\nwith well-engineered prompts, provides an efficient, reli-\nable and accurate solution for the problem of NL2VIS.\nChart-type selection is automatic, and the LLMs are able\nto understand vague user queries as well as those that are\nmalformed. Moreover, the approach is also data-privacy pre-\nserving and security-aware, making it generalisable to all\ntypes of datasets.\n45192 VOLUME 11, 2023\nP. Maddigan, T. Susnjak: Chat2VIS: Generating Data Visualizations via Natural Language\nThe present study highlights the viability of LLMs to\nfurther the capabilities of existing NLIs for visualisation,\nproviding a simpler pathway towards robust solutions which\ndo not involve the task of defining grammars and customised\ndomain-specific language models for language understand-\ning. The results of this study provide valuable insights for\nresearchers and practitioners in the field of data visualisation\nand NLIs, and offer simpler and more accurate solutions for\nmaking data and insights more accessible to a wider audience.\nREFERENCES\n[1] A. Narechania, A. Srinivasan, and J. Stasko, ‘‘NL4DV: A toolkit for gen-\nerating analytic specifications for data visualization from natural language\nqueries,’’IEEE Trans. Vis. Comput. Graphics, vol. 27, no. 2, pp. 369–379,\nFeb. 2021.\n[2] L. Shen, E. Shen, Y . Luo, X. Yang, X. Hu, X. Zhang, Z. Tai, and J. Wang,\n‘‘Towards natural language interfaces for data visualization: A survey,’’\n2021, arXiv:2109.03506.\n[3] Y . Wang, Z. Hou, L. Shen, T. Wu, J. Wang, H. Huang, H. Zhang,\nand D. Zhang, ‘‘Towards natural language-based visualization author-\ning,’’ IEEE Trans. Vis. Comput. Graphics, vol. 29, no. 1, pp. 1222–1232,\nJan. 2022.\n[4] Y . Luo, N. Tang, G. Li, J. Tang, C. Chai, and X. Qin, ‘‘Natural language\nto visualization by neural machine translation,’’ IEEE Trans. Vis. Comput.\nGraphics, vol. 28, no. 1, pp. 217–226, Jan. 2022.\n[5] Y . Song, X. Zhao, R. C.-W. Wong, and D. Jiang, ‘‘RGVisNet: A hybrid\nretrieval-generation neural framework towards automatic data visualiza-\ntion generation,’’ in Proc. 28th ACM SIGKDD Conf. Knowl. Discovery\nData Mining, Aug. 2022, pp. 1646–1655.\n[6] Q. Wang, Z. Chen, Y . Wang, and H. Qu, ‘‘A survey on ML4VIS: Applying\nmachine learning advances to data visualization,’’ IEEE Trans. Vis. Com-\nput. Graphics, vol. 28, no. 12, pp. 5134–5153, Dec. 2022.\n[7] T. B. Brown et al., ‘‘Language models are few-shot learners,’’ 2020,\narXiv:2005.14165.\n[8] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, ‘‘Attention is all you need,’’ in Proc. Adv.\nNeural Inf. Process. Syst., 2017, pp. 6000–6010.\n[9] H. V oigt, M. Meuschke, K. Lawonn, and S. Zarrieß, ‘‘Challenges in\ndesigning natural language interfaces for complex visual models,’’ in Proc.\n1st Workshop Bridging Hum.–Comput. Interact. Natural Lang. Process.,\n2021, pp. 66–73.\n[10] Y . Luo, N. Tang, G. Li, C. Chai, W. Li, and X. Qin, ‘‘Synthesizing\nnatural language to visualization (NL2VIS) benchmarks from NL2SQL\nbenchmarks,’’ in Proc. Int. Conf. Manage. Data, China, Jun. 2021,\npp. 1235–1247.\n[11] J. Tang, Y . Luo, M. Ouzzani, G. Li, and H. Chen, ‘‘Sevi: Speech-to-\nvisualization through neural machine translation,’’ in Proc. Int. Conf.\nManage. Data, Jun. 2022, pp. 2353–2356.\n[12] YoloPandas Developers. (2023). YoloPandas. Python Package Index\n(PyPI). [Online]. Available: https://pypi.org/project/yolopandas/\n[13] G. Liu, X. Li, J. Wang, M. Sun, and P. Li, ‘‘Extracting knowledge from\nweb text with Monte Carlo tree search,’’ in Proc. Web Conf., Apr. 2020,\npp. 2585–2591.\n[14] Y . Sun, J. Leigh, A. Johnson, and S. Lee, ‘‘Articulate: A semi-automated\nmodel for translating natural language queries into meaningful visualiza-\ntions,’’ in Proc. 10th Int. Symp. Smart Graph. Smart Graph., Banff, AB,\nCanada: Springer, Jun. 2010, pp. 184–195.\n[15] T. Gao, M. Dontcheva, E. Adar, Z. Liu, and K. G. Karahalios, ‘‘DataTone:\nManaging ambiguity in natural language interfaces for data visualization,’’\nin Proc. 28th Annu. ACM Symp. User Interface Softw. Technol., Nov. 2015,\npp. 489–500.\n[16] V . Setlur, S. E. Battersby, M. Tory, R. Gossweiler, and A. X. Chang,\n‘‘Eviza: A natural language interface for visual analysis,’’ in Proc. 29th\nAnnu. Symp. User Interface Softw. Technol., Oct. 2016, pp. 365–377.\n[17] X. Qin, Y . Luo, N. Tang, and G. Li, ‘‘DeepEye: Visualizing your data by\nkeyword search,’’ in Proc. EDBT, 2018, pp. 441–444.\n[18] B. Yu and C. T. Silva, ‘‘FlowSense: A natural language interface for visual\ndata exploration within a dataflow system,’’ IEEE Trans. Vis. Comput.\nGraphics, vol. 26, no. 1, pp. 1–11, Jan. 2020.\n[19] E. Loper and S. Bird, ‘‘NLTK: The natural language toolkit,’’ 2002,\narXiv:cs/0205028.\n[20] C. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. Bethard, and\nD. McClosky, ‘‘The Stanford CoreNLP natural language processing\ntoolkit,’’ in Proc. 52nd Annu. Meeting Assoc. Comput. Linguistics, Syst.\nDemonstrations, 2014, pp. 55–60.\n[21] C. Liu, Y . Han, R. Jiang, and X. Yuan, ‘‘ADVISor: Automatic visualization\nanswer for natural-language question on tabular data,’’ in Proc. IEEE 14th\nPacific Vis. Symp. (PacificVis), Apr. 2021, pp. 11–20.\n[22] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training\nof deep bidirectional transformers for language understanding,’’ in Proc.\nConf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Tech-\nnol., vol. 1, 2018, pp. 4171–4186.\n[23] Y . Luo, J. Tang, and G. Li, ‘‘NvBench: A large-scale synthesized\ndataset for cross-domain natural language to visualization task,’’ 2021,\narXiv:2112.12926.\nPAULA MADDIGAN received the B.Sc. degree\n(Hons.) in statistics and operations research from\nthe Victoria University of Wellington Te Herenga\nWaka, New Zealand, and the Master of Analyt-\nics degree in business from Massey University,\nAuckland, New Zealand, in 2022. She is currently\npursuing the Ph.D. degree in computer science.\nShe has extensive industry experience as a Soft-\nware Engineer and more recently held Research\nAssistant positions within the university.\nTEO SUSNJAKreceived the Ph.D. degree in com-\nputer science with a focus on machine learning.\nHe is currently the Subject Lead of Data Science\nand the Coordinator for the Master of Analyt-\nics degree with Massey University. He has broad\nindustry experience, as a Machine Learning Ana-\nlyst, and he continues to apply his expertise to solv-\ning real-world problems using machine learning\napproaches.\nVOLUME 11, 2023 45193",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8793339729309082
    },
    {
      "name": "Natural language",
      "score": 0.6984109878540039
    },
    {
      "name": "Natural language generation",
      "score": 0.5776796340942383
    },
    {
      "name": "Rendering (computer graphics)",
      "score": 0.5630525350570679
    },
    {
      "name": "Visualization",
      "score": 0.5621689558029175
    },
    {
      "name": "Ambiguity",
      "score": 0.5372493267059326
    },
    {
      "name": "Natural language programming",
      "score": 0.5336803793907166
    },
    {
      "name": "Natural language user interface",
      "score": 0.49349772930145264
    },
    {
      "name": "Inference",
      "score": 0.4513040781021118
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4280550181865692
    },
    {
      "name": "Natural language processing",
      "score": 0.42791467905044556
    },
    {
      "name": "Programming language",
      "score": 0.3877466917037964
    },
    {
      "name": "Human–computer interaction",
      "score": 0.35109269618988037
    },
    {
      "name": "Universal Networking Language",
      "score": 0.33567360043525696
    },
    {
      "name": "Comprehension approach",
      "score": 0.13398540019989014
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I51158804",
      "name": "Massey University",
      "country": "NZ"
    }
  ]
}