{
    "title": "Unsupervised learning of dependency structure for language modeling",
    "url": "https://openalex.org/W2136515308",
    "year": 2003,
    "authors": [
        {
            "id": "https://openalex.org/A2104437897",
            "name": "Jian-Feng Gao",
            "affiliations": [
                "Microsoft Research Asia (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2166808512",
            "name": "Hisami Suzuki",
            "affiliations": [
                "Microsoft (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2104437897",
            "name": "Jian-Feng Gao",
            "affiliations": [
                "Microsoft Research Asia (China)"
            ]
        },
        {
            "id": "https://openalex.org/A2166808512",
            "name": "Hisami Suzuki",
            "affiliations": [
                "Microsoft (United States)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W6601443004",
        "https://openalex.org/W2125838338",
        "https://openalex.org/W4300925921",
        "https://openalex.org/W2155693943",
        "https://openalex.org/W2096466920",
        "https://openalex.org/W1974967573",
        "https://openalex.org/W4253573210",
        "https://openalex.org/W1607229519",
        "https://openalex.org/W2123893795",
        "https://openalex.org/W1989705153",
        "https://openalex.org/W2153208746",
        "https://openalex.org/W2134237567",
        "https://openalex.org/W1590952807",
        "https://openalex.org/W2110882317",
        "https://openalex.org/W2005614013",
        "https://openalex.org/W4255764218"
    ],
    "abstract": "This paper presents a dependency language model (DLM) that captures linguistic constraints via a dependency structure, i.e., a set of probabilistic dependencies that express the relations between headwords of each phrase in a sentence by an acyclic, planar, undirected graph. Our contributions are three-fold. First, we incorporate the dependency structure into an n-gram language model to capture long distance word dependency. Second, we present an unsupervised learning method that discovers the dependency structure of a sentence using a bootstrapping procedure. Finally, we evaluate the proposed models on a realistic application (Japanese Kana-Kanji conversion). Experiments show that the best DLM achieves an 11.3% error rate reduction over the word trigram model.",
    "full_text": null
}