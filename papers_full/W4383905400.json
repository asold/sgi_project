{
  "title": "Large Language Models, scientific knowledge and factuality: A systematic analysis in antibiotic discovery",
  "url": "https://openalex.org/W4383905400",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2163320418",
      "name": "Magdalena Wysocka",
      "affiliations": [
        "Cancer Research UK Manchester Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2677071765",
      "name": "Oskar Wysocki",
      "affiliations": [
        "Idiap Research Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2963540676",
      "name": "Maxime Delmas",
      "affiliations": [
        "Idiap Research Institute"
      ]
    },
    {
      "id": "https://openalex.org/A260319362",
      "name": "Vincent Mutel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2172270055",
      "name": "André Freitas",
      "affiliations": [
        "Idiap Research Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2944095447",
    "https://openalex.org/W3007309629",
    "https://openalex.org/W6600050674",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4283170666",
    "https://openalex.org/W2550285568",
    "https://openalex.org/W6601700763",
    "https://openalex.org/W4307092072",
    "https://openalex.org/W4210757531",
    "https://openalex.org/W6794634756",
    "https://openalex.org/W7073704029",
    "https://openalex.org/W2273267066",
    "https://openalex.org/W2789816271",
    "https://openalex.org/W3135543423",
    "https://openalex.org/W3024693033",
    "https://openalex.org/W4297253404",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W3037013468",
    "https://openalex.org/W4287799740",
    "https://openalex.org/W4288116810",
    "https://openalex.org/W4221142828",
    "https://openalex.org/W4288016823",
    "https://openalex.org/W4287278250",
    "https://openalex.org/W3096331697",
    "https://openalex.org/W3152497014",
    "https://openalex.org/W2611972942",
    "https://openalex.org/W4306808680",
    "https://openalex.org/W4321366933",
    "https://openalex.org/W4361251463",
    "https://openalex.org/W2996219887",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3199709353",
    "https://openalex.org/W3166699508",
    "https://openalex.org/W4386576819",
    "https://openalex.org/W4318239126",
    "https://openalex.org/W4360891289",
    "https://openalex.org/W3040709534",
    "https://openalex.org/W4312062661",
    "https://openalex.org/W3118781290",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W3206959854",
    "https://openalex.org/W4226153908",
    "https://openalex.org/W3157831393",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2635787197",
    "https://openalex.org/W4296783454",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W4205450747",
    "https://openalex.org/W4385571479",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "Abstract Background Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially drive a new era in biomedical research, reducing the barriers for accessing existing medical evidence. This work examines the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery as an exemplar motivational scenario. The context of biomedical discovery from natural products entails understanding the relational evidence between an organism (e.g. a Fungi such as Albifimbria verrucaria), an associated chemical (Verrucarin A) and its associated antibiotic properties (present antibiotic activity). Results This work provides a systematic assessment on the ability of LLMs to encode and express these relations, verifying for fluency, prompt-alignment, semantic coherence, factual knowledge and specificity of generated responses. The systematic analysis is applied to nine state-of-the-art models, from models specialised on biomedical scientific corpora to general models such as ChatGPT and GPT-4 in two prompting-based tasks: chemical compound definition generation and chemical compound-fungus relation determination. Results show that while recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted. The best performing GPT-4 produced a factual definition for 70% of chemical compounds and 43.6% factual relations to fungi, whereas the best open source model BioGPT-large 30% of the compounds and 30% of the relations for the best-performing prompt. Conclusions The results show that while LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale-up in size and level of human feedback.",
  "full_text": "Large Language Models, scienti\u0000c knowledge and\nfactuality: A systematic analysis in antibiotic\ndiscovery\nMagdalena Wysocka  (  magdalena.wysocka@manchester.ac.uk )\ndigital Experimental Cancer Medicine Team, Cancer Biomarker Centre, CRUK Manchester Institute\nOskar Wysocki \nIdiap Research Institute\nMaxime Delmas \nIdiap Research Institute\nVincent Mutel \nIn\u0000amalps SA\nAndre Freitas \nIdiap Research Institute\nResearch Article\nKeywords: Large Language Models, GPT-4, ChatGPT, antibiotic discovery\nPosted Date: July 11th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3117447/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nWysocka et al.\nRESEARCH\nLarge Language Models, scientiﬁc knowledge and\nfactuality: A systematic analysis in antibiotic\ndiscovery\nMagdalena Wysocka 1,2* , Oskar Wysocki 1,3, Maxime Delmas 3, Vincent Mutel 4 and Andr´ e Freitas1,2,3\n*Correspondence: mag-\ndalena.wysocka@manchester.ac.uk\n1digital Experimental Cancer\nMedicine Team, Cancer Biomarker\nCentre, CRUK Manchester\nInstitute, University of\nManchester, Oxford Rd, M13 9 PL\nManchester, UK\nFull list of author information is\navailable at the end of the article\nAbstract\nBackground Inferring over and extracting information from Large Language\nModels (LLMs) trained on a large corpus of scientiﬁc literature ca n potentially\ndrive a new era in biomedical research, reducing the barriers for accessing existing\nmedical evidence. This work examines the potential of LLMs for d ialoguing with\nbiomedical background knowledge, using the context of antibiotic d iscovery as an\nexemplar motivational scenario. The context of biomedical discove ry from natural\nproducts entails understanding the relational evidence bet ween an organism (e.g.\na Fungi such as Albiﬁmbria verrucaria ), an associated chemical (Verrucarin A)\nand its associated antibiotic properties (present antibiotic activity).\nResults This work provides a systematic assessment on the ability of LLMs to\nencode and express these relations, verifying for ﬂuency, pr ompt-alignment,\nsemantic coherence, factual knowledge and speciﬁcity of genera ted responses.\nThe systematic analysis is applied to nine state-of-the-art models, from models\nspecialised on biomedical scientiﬁc corpora to general models such as ChatGPT\nand GPT-4 in two prompting-based tasks: chemical compound deﬁni tion\ngeneration and chemical compound-fungus relation determination. Results show\nthat while recent models have improved in ﬂuency, factual acc uracy is still low\nand models are biased towards over-represented entities. Th e ability of LLMs to\nserve as biomedical knowledge bases is questioned, and the need for additional\nsystematic evaluation frameworks is highlighted. The best per forming GPT-4\nproduced a factual deﬁnition for 70% of chemical compounds and 43.6% fa ctual\nrelations to fungi, whereas the best open source model BioGPT-lar ge 30% of the\ncompounds and 30% of the relations for the best-performing prompt.\nConclusions The results show that while LLMs are currently not ﬁt for purpose\nto be used as biomedical factual knowledge bases, there is a prom ising emerging\nproperty in the direction of factuality as the models become domai n specialised,\nscale-up in size and level of human feedback.\nKeywords: Large Language Models; GPT-4; ChatGPT; antibiotic discovery\nBackground\nRecently, artiﬁcial intelligence (AI) algorithms have signiﬁcantly facilitated the ac-\nceleration of antibiotic discovery through high-throughput drug scre ening, with a\nparticular emphasis on the identiﬁcation of novel antibiotic compounds [1]. Deep\nlearning (DL) methods have proven eﬀective in isolating small mole cule antibiotics\nexhibiting potent activity against a diverse array of bacterial pathogen s [2]. This\nadvancement in machine learning (ML) for drug discovery has been bols tered by the\nwidespread accessibility of datasets emerging from empirical analyse s. Notably, the\nWysocka et al. Page 2 of 22\ndiscovery of novel compounds primarily relies on protein structur e prediction and\nmodeling of antibiotic targets. Moreover, since the knowledge relat ed to antibiotic\ndiscovery is communicated as text in the scientiﬁc literature, p atents and clinical\ntrials, this creates an opportunity for Large Language Models (LLMs), especial ly\nGenerative Pre-trained Transformers (GPTs), to serve as proxy for background sci-\nentiﬁc knowledge, reducing the barriers for integrating and mappin g the landscape\nof available evidence. Eliciting information from LLMs trained on large cor pora of\nscientiﬁc, biomedical literature could potentially support the ant ibiotic discovery\nprocess.\nLarge Language Models have evolved in the past two years signiﬁcantly inﬂu encing\nnatural language processing (NLP) with a variable level of adoption in diﬀe rent\nspeciﬁc domains [3, 4]. GPT-1 (Generative Pre-trained Transformer) [5], the ﬁrst\nLLM trained using self-supervised pre-training, predicts the ne xt word in a sequence\ngiven the previous words, performing this task unidirectionally fr om left to right.\nThis enables GPT-1 to learn the dependency relations between word s and generate\nrelevant and contextual content. GPT-2 [5] was trained with a larger arch itecture\non a larger and more diverse corpus than GPT-1, with 1.5 billion parameters , thus\ndemonstrating better generalisation properties.\nGPT-3 [6] with 175 billion parameters represents a phase transition in the evo-\nlutionary arch of language models, where the in-context learning proper ties was\nnoticeably present. Subsequently, InstructGPT [7] extended t his foundation, using\nreinforcement learning from human feedback (RLHF) as a training strate gy, lever-\naging on the ability of the pre-training model to re-align at instructi on/intensional\nlevel. ChatGPT [8] follows the same architectural principles of Ins tructGPT, using\nGPT-3.5 (both larger corpora, and human-feedback prompting datasets). De spite\nhaving signiﬁcantly less domain-speciﬁc biomedical text, it can st ill deliver the abil-\nity to encode and articulate more specialised discourse, for example , achieving a\nscore equivalent to a third-year medical student [9].\nDespite their comprehensive linguistic interpretation propert ies, LLMs have in-\nherent operational properties, most notably hallucinations [10, 11], i.e. d ivergence\nfrom factual knowledge and spurious inference, despite its ﬂuency and syntactic cor-\nrectness [12, 13]. The recently released GPT-4 is not free from this l imitation [14].\nHallucinations tend to surface prominently in domain-speciﬁc discou rse, including\nthe sciences. This elicits the need to establish the ability of t hese models to encode\nand preserve factual knowledge as well as establishing methodologies f or the critical\nevaluation of its representation properties [15, 16, 17].\nIn this work we systematically assess the biological relational knowled ge encoded\non state-of-the-art LLMs, namely: GPT-2, GPT-3, GPT-neo, Bloom, BioGPT,\nBioGPT-Large, Galactica, ChatGPT and GPT-4. We focus on systematically de -\ntermining the ability of LLMs to capture fundamental entities (fungi , chemicals and\nantibiotic properties), their relations and supporting facts, whic h are fundamental\nfor delivering inference in the context of downstream biomedical i nference (Fig. 1).\nFor instance, we aim to answer the question on whether LLMs can faithfull y capture\nbiological domain-speciﬁc factual knowledge such as:\n• “Aspergillus fumigatus produces festuclavine”\n• “Cycloclavine is biosynthesised by Aspergillus japonicus”\nWysocka et al. Page 3 of 22\n• “Enfumafungin demonstrates antibiotic activity against several bacter ial, yeast\nand fungal species”\n• “Enfumafungin and ergokonin A are isolated from Hormonema and Tri cho-\nderma species and demonstrate antibiotic activity against several bacter ial,\nyeast and fungal species”\nThis overarching question is translated into the following speci ﬁc research ques-\ntions (RQs):\n1 Do large language models encode biomedical domain knowledge at entity le vel\n(e.g. fungi, chemical, antibiotic properties) and at a relational level ?\n2 Are there signiﬁcant diﬀerences between diﬀerent models in th eir ability of\nencoding domain knowledge?\n3 Which model performs better in faithfully encoding biological re lations?\n4 How do we evaluate the limitations of LLMs in factual knowledge extraction ?\nThis work targets the following contributions:\n• We propose a framework for the systematic evaluation of the ability of LLMs\nto encode domain speciﬁc factual knowledge (target entities and relat ions).\n• We provide a qualitative evaluation and comparison of the state-of-the-ar t\nLLMs in the context of biomedical inference and factual knowledge extrac tion.\n• We provide an argument and extensive evidence for the need for evaluat ion\nframeworks to determine the limits of LLMs and for the eﬃcient assessm ent\nof generated text.\nThis study is organized as follows: ﬁrst, we deﬁne our contribution and link it with\nthe existing frameworks and other investigations within the biomedi cal domain. In\nthe Results section we apply our new proposed framework to nine LLMs and e val-\nuate them for ten chemical compounds with a detailed description of th e generated\nresponses. Then, we discuss our ﬁndings in the broader context of rep orted LLMs’\nlimitations. We conclude the paper with a summary of the contribution s and with\nfuture perspectives on the role of LLMs in biomedical inference. In t he Metohds sec-\ntion, we present a new framework for the qualitative evaluation of the bi omedical\nknowledge embedded in LLMs, followed by a detailed description of th e methods\nand a review of related work in the ﬁeld of LLMs and their knowledge repre senta-\ntion properties. The workﬂow of the analysis is depicted in Fig. 2, and t he proposed\nevaluation framework in Fig. 3.\nResults\nChemical compound deﬁnition generation\nThis task assesses the ability of the LLM to generate a factual deﬁnition of a chem-\nical compound. For instance with the Prompt = ‘entity is’ with the en tity ‘Atro-\nmentin’, a correct answer could have the form ‘Atromentin is a natur al product...’.\nWe investigated ten examples of chemical compounds (ﬁve with and ﬁve w ithout\nantibiotic activity) for the qualitative evaluation according to the pr eviously de-\nscribed criteria (see Methods, Additional ﬁle 1: Table S1). As prompt s, we provided\nsingle entities or entities with the more speciﬁc context (Additi onal ﬁle 2: Table\nS2). The results are summarized in Table 1. Examples of generated answer s with\nthe qualitative evaluation are presented in Additional ﬁle 3: Table S3. Note , for\nChatGPT and GPT-4 we did not limit the number of tokens and evaluated th e\ncomplete output. In total, we manually evaluated 350 outputs in this task.\nWysocka et al. Page 4 of 22\nGPT-2 and GPT-neo: no semantic coherence, no factuality. GPT-2 failed\nto generate any semantically coherent text that is related to the enti ty and to the\ntarget domain (biomedicine in general). After adding ‘is’ to the prompt s, the model\ngenerates ﬂuent text only for 2/10 compounds, but with no semantic cohere nce.\nAdding context leads to even more ﬂuent outputs but still loses seman tic coherence\nand there is no prompt-alignment. For 7/10 compounds very ﬂuent text is ge nerated\nthat is unrelated to either the associated fungus or the antibiotic act ivity of the\ncompound.\nGPT-neo, similarly to GPT-2, failed to generate any text or any ﬂuent te xt. After\nadding ‘is’ - the model generates (for 8/10) syntactically correct texts unrelated to\nthe given name, resembling to an n-gram scientiﬁc fragment unrelated to the men-\ntion. After adding context, the model asserts two compounds (Fumitr emorgin C,\nConidiogenone) as being produced by fungi ( Fusarium sphaerospermum, Penicil-\nlium notatum , respectively), however under incorrect associations. The mod el failed\nto generate factual knowledge.\nGPT-3: Semantically coherent answers less sensitive to prompt desi gn.\n3/10 factual answers. Hallucinates fungi names from compounds. GPT-3\ngenerated semantically coherent text regardless of the prompt design f or all chemical\ncompounds, both with and without context (see example of Atromentin in Addi-\ntional ﬁle 3: Table S3). It generated a similar number of factual answers re gardless\nof the context (30% vs 35%). Interestingly, adding context to the prompt did not\nincrease speciﬁcity ( ‘Ergosterol is ... a sterol found in the cell membranes of fungi.\nIt is a major component of the fungal cell membrane, and is similar to cholesterol\nin animals. It is an important precursor for the synthesis of ot her compounds, such\nas ergocalciferol’ vs ‘Ergosterol is a compound ... found in the cell membranes of\nfungi. It is a sterol, a type of lipid molecule, and is the main stero l in the fungal cell\nmembrane. It is similar to cholesterol, which is found in animal cell m embranes’).\nFor 2/10 chemicals (Ergosterol and Alternariol) GPT-3 generated factual and sp e-\nciﬁc answers regardless of the prompt and context. GTP-3 generated inc orrect fungi\nnames (in 39.3% of incorrect answers) that consists of the compound name in t he\nprompt, e.g. Myriocin - Streptomyces myriocin, Chloromonicilin - Streptomyces\nchloromyceticus (Additional ﬁle 4: Table S4).\nBloom: no factual knowledge, low semantic coherence: biased to-\nwards treatments, repeats the same associated terms or statements.\nFor prompts without context, Bloom fails to generate a syntactically cor rect\noutput. It does not generate any text (for example, ‘Conidiogenone ’ ), gen-\nerates the chemical compound entity as a code within a link (for examp le,\n‘org.apache.thrift.TBase(”org.apache.thrift.TBase”, ”ﬂavasperone”,’) or generates\ntext with only special characters (for example, ‘ErgosterolˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸ˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸\nˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸ˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸ˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸ˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸ˆE¨ a´ oˆEß ˆA ˚ a˜ nˆAˆ aC ¸\nˆE¨ a´ oˆEß ˆA ˚ a˜ n’). The model tends to repeat the same words or phrases for a given\nentity (for example, ‘Fumitremorgin C is a potent inhibitor of the enzyme, which is\nresponsible for the synthesis of the enzyme, and is therefore a potent inhibitor of the\nsynthesis of the enzyme.’ ). In addition, the model generates names that does not\nexist in the literature (for example, ‘Atromentin is a natural product derived from\nthe fruit of the plant Atrium tridentatum.’). When adding the context to the\nWysocka et al. Page 5 of 22\nprompts, Bloom is biased towards considering the compounds as a treatm ent for a\nvariety of diseases. It generates ﬂuent but no semantically coherent text, unrelated\nor not speciﬁc to the compound. Frequently the answer contains repeat ed state-\nments and facts, e.g. ‘Fumitremorgin C is a substance that is used in the treatment\nof cancer. It is a natural product that is used in the treatment of cancer. It is a nat-\nural product that is’ - despite its factuality, it corresponds to low prompt-alignment\nand speciﬁcity.\nBioGPT: low speciﬁcity, adding context leads to even lower speciﬁ city,\nleading to the answer being true for any compound. BioGPT generates\nﬂuent and syntactically correct text tends to correspond to a more gen eral dis-\ncourse type (when contrasted to scientiﬁc discourse). For prompts ‘{entity}’ and\n‘{entity} is’, only one compound (Ergosterol) has factual answers. For instance,\nthe generated text states that one compound is an antibiotic, but the res t of the\nsentence is not related to the compound, or the model confuses DNA poly merase al-\npha/beta/gamma (Additional ﬁle 3: Table S3 for Aphidicolin). When more contex t\nis provided (prompt with ‘is a compound’), BioGPT generates a factual text with\nlow speciﬁcity for 4/10 compounds. It provides a non-speciﬁc, unive rsal deﬁnition\nof a compound, which is referred to regardless of the compound name (Addi tional\nﬁle 3: Table S3, example: ‘Fumitremorgin C is a compound with a unique structure\nand a unique mode of action.’ - the same is for Verrucarin A). After adding the\ncontext ‘is a substance’, BioGPT recognises that 5 /10 compounds were pr oduced\nby fungus, but all incorrect.\nBioGPT-large: Semantically very coherent. 3/10 factual answers. Hal-\nlucinations under high quality, scientiﬁc text are diﬃcult to spot .\nBioGPT-large generated semantically coherent outputs for 80% of the prompt s\nwithout and 100% prompts with the context. However, the answers were fac tual\nonly for 30% and 35% for prompts without and with context, respectively. De spite\nsome of them were not speciﬁc, BioGPT-large generated answers better ﬁ tting to a\nscientiﬁc discourse level, compared to the previous models (see Myriocin in Addi-\ntional ﬁle 4: Table S4). Similarly to GPT-3, for 28% of answers with no factual ity,\nBioGPT-large assigned a wrong producer to the compound, e.g. ’Chloromonilicin\nis a new antibiotic produced by a strain of Streptomyces. It is active against Gram-\npositive bacteria and fungi.’ (true answer: is produced by Monilinia fructicola ). This\nis of particular concern, as the generated text imitates correct deﬁni tions very well,\ndisguising the lack of factual knowledge. Such hallucination is very d iﬃcult to spot\nand a vigilant expert check is required.\nGalactica: poor semantic coherence, improves after adding context to\nthe prompt, answers resembles as corpora fragments. 1/10 factual an-\nswers. Galactica only for 2/10 compound names can generate text that is related to\nthe target entity and that is aligned to the domain, but in both cases lacks factual-\nity. For one case, the model assigned that the compound was produced by a fungus\nbut misnamed it (‘Aphidicolin is a polyketide antibiotic produced by the fungus\nAspergillus nidulans . It is a potent inhibitor of DNA polymerase alpha.’). Adding\nthe context ‘What is the compound entity?’ improves the output. Th e text is more\nmeaningful and ﬂuent, and is domain-aligned. However, it still lacks fac tual knowl-\nedge with one exception for Myriocin, which is recognized as an antibiot ic. The\nWysocka et al. Page 6 of 22\ngenerated text resembles the fragment from a title of a speciﬁc scie ntiﬁc paper than\na general description (‘Myriocin, a new antifungal antibiotic. I. Tax onomy, fermen-\ntation, isolation, physico-chemical properties and biological activity. ’). Moreover,\nthe model recognises that Fumitremorgin C is a mycotoxin but again mis named the\nfungus name ( ‘Fusarium verticillioides’, instead of ‘Aspergillus fumigatus’).\nChatGPT: Fluent, prompt-alignment and semantically coherent de-\nscriptions. Hallucinations are diﬃcult to spot. 6/10 factual answers. Chat-\nGPT generated ﬂuent and semantically coherent text for all prompts. For prompts\nwith no context, the statements were longer and divided into paragraph s (mostly\nthree; note, that a limit was not set on the length of generated answer for C hatGPT).\nThe generated text was coherent regardless of the designed prompts (en tity or en-\ntity is), and 6/10 outputs were factual. The other four generated the wrong fungus\nname or the wrong chemical formula in the answer. Interestingly, the answers often\nclosely resembled Wikipedia-style descriptions (7/10 compounds - W ikipedia, 2/10\n- Wikidata). For prompts with the context, the answers were shorter an d mostly\nconsisted of one paragraph. For prompts {entity is a compound } the text contained\na chemical formula and a description of the chemical structure. Howe ver, in 60% of\nthese prompts the chemical formula was incorrect (see Aphidicolin i n Additional ﬁle\n3: Table S3). The answers that were factual had low speciﬁcity, and could satisfy the\ndeﬁnition of many other chemical compounds. For prompts {entity is a substance },\nthe answer provides additional biological context and informs about the bi ological\nactivity of the compound or what it is used against. 70% of these answers contai ned\nfactual knowledge. Comparing to BioGPT-large, ChatGPT produces even more ﬂu-\nent, prompt-alignment and semantically coherent answers. Due to sem antic ﬂuency,\nevaluation of the factual knowledge is very challenging, and requires bot h the expert\nknowledge and time-consuming fact veriﬁcation. In other words, gener ated answers\ncan be easily regarded as true and factual for a non-expert, creating a real risk of\nderiving false facts from the model.\nGPT-4: Top of the list and epistemically-aware (admits to lack of knowl-\nedge). 14/20 factual answers. For prompts without context, the model gave 70%\n(14/20) of the answers that were speciﬁc and with factuality. In two prompt s (out\nof 20), the characterisation of a given chemical compound was non-factual due t o\nthe incorrect name of the fungus that may produce the chemical. Impor tantly, the\nmodel did not guess the deﬁnition if it did not recognize the name. For t wo chem-\nical compounds, the model generated a request for more context or refer red to\nthe knowledge cutoﬀ date of 2021-09. After adding context, GPT-4 generated te xt\nabout the one chemical, but is factual for one out of two prompts. In the case of the\nsecond compound, the model still referred to the knowledge cutoﬀ d ate of 2021-09.\nIn general, adding context did not improve neither the factuality nor speciﬁcity\nmetrics, which was still at 70%. The quoted names of the fungus that prod uces\nthe chemical were incorrect. In general, the model generated ﬂuent , semantically\ncoherent, highly speciﬁc text (see Fumitremorgin C in Additional ﬁl e 3: Table S3).\nWe observed less hallucinations compared to ChatGPT.\nChemical-fungus relation determination via entity generation\nThe aim of the task was to check whether the model generates a factual re lation\nbetween the chemical compound and the fungus, which is producer of t he given\nWysocka et al. Page 7 of 22\nTable 1 Performance in the chemical compound deﬁnition generation task . Evaluation according\nto the framework (see Fig. 3). 0 means correct in 0/20 prompts; 1 means co rrect in 20/20\nprompts.\nTask Compound deﬁnition generation\n(prompts P1-P3)\nCompound deﬁnition generation + context\n(prompts P4-P7)\nModel\nSTEP 1\nFluency,\nPrompt-alignment,\nSemantic coherence\nSTEP 2\nFactuality\nSTEP 3\nSpeciﬁcity\nSTEP 1\nFluency,\nPrompt-alignment,\nSemantic coherence\nSTEP 2\nFactuality\nSTEP 3\nSpeciﬁcity\nGPT-2 0.1 0 0 0.45 0 0\nGPT-3 1 0.3 0.3 1 0.35 0.35\nGPT-neo 0.4 0 0 0.55 0 0\nBloom 0.2 0 0 0.3 0 0\nBioGPT 0.7 0.05 0 0.95 0.35 0.1\nBioGPT-large 0.8 0.3 0.25 1 0.35 0.3\nGalactica 0.2 0 0 0.45 0.05 0\nChatGPT 1 0.6 0.6 1 0.55 0.5\nGPT-4 1 0.7 0.7 1 0.7 0.7\ncompound. We investigated ten compounds (ﬁve with and ﬁve without anti biotic\nactivity), the same as in chemical compound deﬁnition generation task. W e followed\nthe proposed evaluation framework (Fig. 3): ﬁrst investigated the ﬂuenc y, prompt-\nalignment and semantic coherence of the generated output, then the rel ation with\ngenerated fungus name and the factuality and speciﬁcity of the whole gene rated\ntext. As prompts, we provided simple clausal fragments (e.g. ‘ {entity} is isolated\nfrom’) or with an additional noun (e.g. ‘ {entity} is produced by fungus’) as preﬁx\n(see Additional ﬁle 2: Table S2). All models, except for Galactica, were e valuated via\nthe 11 prompts designs. We report aggregated results for all 110 prompts (Tabl e 2)\nand an optimal prompt with the best performance (Table 3). The optimal prom pt\nconﬁguration varies across models. In total we manually evaluated 1110 outputs in\nthis task.\nTable 2 Performance in the chemical-fungus relation determination vi a entity generation task.\nEvaluation according to the framework (see Fig. 3). 10 chemicals, 11 promp ts (P8-P18), 110\noutputs per model in total, % relates to 110 outputs. For Galactica one pr ompt (P19), 10 outputs.\nModel Fungus name\n(%)\nFactual chemical-fungus relation\n(%)\nFactual chemical-fungus relation\nand factual whole description\n(%)\nGPT-2 0 (0) 0 (0) 0 (0)\nGPT-3 56 (51.0) 26 (23.6) 15 (13.6)\nGPT-neo 28 (25.5) 4 (3.6) 2 (1.8)\nBloom 12 (11.0) 3 (2.7) 2 (1.8)\nBioGPT 57 (51.8) 15 (13.6) 10 (9.1)\nBioGPT-large 74 (67.3) 44 (40.0) 18 (16.4)\nGalactica 8 (80.0) 6 (60.0) -\nChatGPT 101 (91.8) 49 (44.5) 35 (31.8)\nGPT-4 77 (70.0) 56 (50.9) 48 (43.6)\nGTP-2, GPT-neo and Bloom fail to establish chemical-fungus relation.\nThe GPT-2 model did not generate any answer containing the name of a poten -\ntial fungus from which a given chemical compound can be isolated, regardle ss of\nthe designed prompt. In addition, the model hallucinated new bacter ia names (e.g.\nStreptococcus aureus). The GPT-neo model generated only 3.6% (4/110) of correct\nchemical compound-fungus relations. One correct answer each for Ergoste rol, Al-\nternariol, Atromentin and Flavasperone for three diﬀerent prompts. The optimal\nprompt produced ﬁve chemical-fungus names relations, where only tw o relations\nwere correct. Out of four correct chemical compound-fungus relations, only two\nhad factual knowledge for the entire generated text (1.8% (2/110)).\nWysocka et al. Page 8 of 22\nTable 3 Performance in the chemical-fungus relation determination vi a entity generation task for\noptimal prompts. For each model an optimal prompt was selected. Ten outp uts per model.\nEvaluation according to the framework (see Fig. 3). {entity} - a chemical compound.\nModel Optimal Prompt Fungus\nname\nFactual\nchemical-fungus\nrelation\nFactual\nchemical-fungus\nrelation and\nfactual whole\ndescription\nGPT-3 {entity} is produced by the fungus ... 8 5 4\nGPT-neo {entity} is produced by the fungus ... 5 2 0\nBloom {entity} is produced by the fungus ... 7 2 1\nBioGPT {entity} is produced by fungi, such as ... 10 3 1\n{entity} is isolated from fungi, such as ... 10 3 2\nBioGPT-large {entity} is produced by the fungus ... 10 6 2\n{entity} is isolated from the fungus ... 10 6 3\nChatGPT {entity} originally isolated from ... 10 6 1\nGPT-4\n{entity} is isolated from the fungus ... 7 6 4\n{entity} is isolated from fungi ... 9 6 5\n{entity} is isolated from fungi, such as ... 9 6 5\nThe Bloom model generated only 2.7% (3/110) of factual chemical compound-\nfungus relations. In general, only 11% (12/110) of answers contained a fungus name\n(both factual and no factual relations). The model generated answers wit h the name\nof the fungus only for the two prompts, that hint towards fungus context : ‘entity is\nproduced by the fungus’ and ‘entity is isolated from the fungus’. Con sidering the\noptimal prompt, Bloom produced seven fungi, two of them were in fact ual relation\nwith the chemical. Out of three factual chemical compound-fungus rel ations, only\ntwo had factual knowledge for the entire generated text (1.8% (2/110)).\nGPT-3 produces at least one factual relation for 6/10 compounds. GPT-\n3 generated 51% (56/110) answers containing a fungus name, where 23.6% (26/110)\nwere factual compound-fungus relations, but only in 13.6% (15/110) the whole rel a-\ntion description was factual. The optimal prompt resulted in ﬁve factu al relations,\neach containing individual fungus, of which only four answers were fact ual for whole\ndescription. The model produced a factual relation for at least one prom pt for 6/10\ntested compounds. Alternariol turned out to be a chemical with the mos t factual\nrelations (8 out of 10 tested prompts), which aligns with the results f rom ﬁrst task\nfor GPT-3 (Additional ﬁle 5: Table S5).\nBioGPT biased towards Aspergillus, limited proportion of factual re-\nlations. BioGPT generated factual relations with fungi names for only 13.6%\n(15/110) of the cases, of which only ten answers had factual knowledge. Only th ree\ncompounds were factually associated with the corresponding fungus fr om which\nthey were isolated (Alternariol - six answers with factual relation, At romentin - one\nanswer with factual relation, Ergosterol - six answers with factual re lation). Out of\n62 generated answers that contained a fungus, 45 were Aspergillus, of which only\n11 answers were factual. The two optimal prompts for this model were at 30% of\nthe factual chemical compound-fungus relations.\nBioGPT-large: at least one factual chemical-fungus relation for 9/10\ncompounds. BioGPT-large generated 40.0% (44/110) of the factual chemical\ncompound-fungus relations, of which less than half (18/44) were factual. The model\ngenerated at least one factual answer for 9 out of 10 tested compounds. This im plies\nthat it is possible to achieve 90% of factual relations if picking the righ t prompt for\neach chemical, showing the dependency on prompt optimisation. The m odel gave\nthe most factual answers for Ergosterol (8 out of 10 tested prompts). If an opt imal\nWysocka et al. Page 9 of 22\nprompt is considered, BioGPT-large obtained 60% factual relations. The lac k of\nfactual knowledge resulted mainly from the incorrect name of the inhi bitor of a\ngiven compound. Contrary to previous models, we observed that BioGPT- large did\nnot generate additional context, when unclear (e.g. the names of the disc overers or\nthe year of discovery of the compound if not known) reducing the over all number\nof hallucinations.\nGalactica biased towards a large genus Aspergillus and poor perfor-\nmance. Galactica generated factual chemical-fungi relations for 6 out of 10 com-\npounds. However, for four prompts we naively accepted a genus name Aspergillus\nas the factual answer, despite not being a speciﬁc name (Additional ﬁle 6: Table\nS6). Only for Fumitremorgin C the answer contained the species name: Aspergillus\nfumigatus. Aspergillus is at the same time the most frequently generated fungus (7\ntimes). For Aphidicolin and Myriocin the model generated no answer. The gener-\nated answers consisted only of the name of the fungus, so no factual knowl edge in\nthe entire generated text was assessed.\nChatGPT: coherent answers, regardless the prompt. ChatGPT generated\n44.5% (49/110) factual chemical compound-fungus relations. The model provide d\nall 11 fungal-name responses for eight compounds. The exception was one prom pt\nfor Conidiogenone and seven prompts for Ergosterol. The rest of the answers given\nfor Ergosterol (4) were 100% factual with fungus relation. For three compounds\nall answers were factual (100% for Fumitremorgin C, Alternariol, Verrucar in A\n(Additional ﬁle 7: Table S7)) and for four compounds all prompts led to incorr ect\nrelations. The model produced very coherent answers regardless of t he prompt, but\nonly 31.8% (35/110) of them had a factuality for the whole generated description.\nThe lack of factual knowledge was mainly due to the incorrect statement of the\nyear of discovery/isolation of a given compound, the name of the discovere r or the\nclass of the compound. The optimal prompt turned out to be ‘entity origin ally\nisolated from’, with 6/10 factual relations, of which the answer for only one r elation\nhad a factuality of whole answer. Almost 70% of the generated descriptions\ncontained hallucinations.\nGPT-4 gives either the factual chemical-fungus relations or no answer\nat all. GPT-4 generated 50.9% (56/110) factual chemical compound-fungi relations.\nThe model produced very coherent answers regardless of the prompt d esign. For four\ncompounds, all answers were factual (11/11, 100% for Fumitremorgin C, Alternariol ,\nVerrucarin A, Myriocin). The model for all prompts for Ergosterol did n ot generate\nany relations with the fungus. The model factually recognized the comp ound by\nciting its characteristics, but without giving the names of the fun gi that produce\nergosterol. In most cases, the model creates a new ﬁrst sentence wit hout completing\nthe sentence from the prompt. Rarely in the ﬁrst sentence is the n ame of the fungus\nthat produces the chemical compound. In the case of 13.6% (15/110) responses,\nthe model asked for more context and/or indicated that the question is in complete.\nFor 4.5% (5/110) prompts the model referred to the knowledge cutoﬀ date of 2021-\n09, thus not providing an answer. Three prompts were optimal with 6/10 fact ual\nrelations. Out of 56 factual chemical-fungi relations, the model generat ed 48 answers\nthat had factual knowledge for the entire generated text (43.6%, 48/110). The\nhallucination (lack of factual knowledge) was observed for 56% of outputs, mai nly\nWysocka et al. Page 10 of 22\nas an incorrect statement of the year of discovery/isolation of a given compou nd or\nthe incorrect citation of the name of the synonym of the fungus.\nCorrectly generated relations are homogeneous and prevalent\nConsidering the models with outputs that contain the fungus name, in majority\nthey recognize one speciﬁc factual relation chemical-fungus, although t he chemical\ncan be produced by several fungi. For instance, in all factually generat ed rela-\ntions for Fumitremorgin C the fungus was Aspergillus fumigatus or Aspergillus (33\nout of 33 correct fungi name, from 52 generated fungi in total). Other chemic als:\nAphidicolin → Cephalosporium aphidicola (17/17 out of 33), Verrucarin A → My-\nrothecium verrucaria or Myrothecium (22/22 out of 55), (+)-Chloromonilicin →\nMonilinia fructicola or Monilinia (8/8 out of 38), Alternariol → Alternaria alter-\nnata or Alternaria fungus (38/44 out of 48), Flavasperone → Aspergillus (13/17 out\nof 33), Atromentin → Aspergillus (11/11 out ouf 39), Myriocin → Isaria sinclarii\n(14/18 out of 42). The least recognised chemical Conidiogenone was associated wit h\nPenicillium 3 out of 4 correct outputs (out of 42 outputs with fungi assoc iations).\nFactually generated relations for Ergosterol are with two fungi: Aspergillus (11/22)\nand Ganoderma lucidum (7/22). Interestingly, Aspergillus is output by BioGPT\nand Ganoderma lucidum by BioGPT-Large. Although trained on the same corpus,\nwe hypothesise that the higher number of parameters in BioGPT-Large (347M v s\n1.5B) led to a more speciﬁc relation.\nDiscussion\nLLMs’ biases towards compounds and fungi\nBias towards Aspergillus - the most cited fungus in PubMed.\nWe observe that the models are biased towards certain compounds. For in stance,\nBioGPT generates the fungus Aspergillus as the answer in most of the prompts\n(79%, 45/57), which is rarely correct (only 11 times; 19%) (Additional ﬁle 6: Tabl e\nS6). We accredit this bias to the imbalance in the training corpus, as t he Aspergillus\nis a ubiquitous fungus in home and hospital environments. The genus Aspergillus,\nconsists of a few hundred opportunistic species found in various cli matic conditions,\nof which in humans, A. fumigatus is the most common and life-threatening airborne\npathogen, which is particularly important among immunocompromised host s [18].\nThe PubMed search outputs almost 60k references related to Aspergillus. The most\ncited compound from our analysis Ergosterol outputs 6000, second Aphidicolin\n2500. Thus, we argue Aspergillus is over-represented in the training corpus and\noccurs as a statistically most probable fungus to be related to chemic als.\nRare chemical compound confused with an overrepresented biological\nprocess.\nAnother example, Conidiogenone was consistently not recognised by the best models\n(GPT-4, ChatGPT, BioGPT-large, Galactica). We argue that the models conf use\nConidiogenone with conidiogenesis or conidiation. Conidiogenesis is a widespread\nmorphogenetic process that ﬁlamentous fungi undertake for dispersion . Conidiation\nis also important for pathogenicity of phytopathogens. Understanding the c ellular\nmechanism of conidiation is a highly relevant research topic, thus it has been exten-\nsively studied. Conidiogenone is associated with nine results in a PubMed search,\nWysocka et al. Page 11 of 22\nconidiogenesis with 346 and conidiation with 6047. The strongest and widespread\nstimulus for conidiation among ﬁlamentous fungi is the exposure of hyphae to the\nair. Often the generated texts focused on this aspect of the process , suggesting that\nthe model encoded the signal for the representation of the process i nstead of the\nchemical compound.\nOutput not focused on fungi despite the prompt context.\nIn the case of Ergosterol, which is a compound widely known for its signi ﬁcance in\nthe scientiﬁc community, the LLM speciﬁcally trained for the bio-dom ain (BioGPT-\nLarge) outperforms the rest. It generated seven factual Ergosterol-fungu s relations\nfrom 11 prompts (Additional ﬁle 8: Table S8). For the other models, the re lation to\nfungus was either minimally addressed or not considered at all, particu larly for the\nmodels that have generally demonstrated superior eﬃcacy (i.e., GPT -4 with 0/11\nand ChatGPT with 4/11 factual responses). We observe that GPT-4 and ChatGP T\nfocus on Ergosterol’s biosynthesis in fungi and relevance as an antifungal target,\nrather than on the producing fungi, despite the prompt that explici tly deﬁnes such\ncontext. Importantly, these two models do not generate text as a conti nuation of\nthe prompt, but they generate new paragraphs.\nLimited ability of LLMs as Knowledge Bases\nIn our study, we provide evidence of the limitations in the determ ination of factual\nknowledge from LLMs in the text generation tasks. Best models were able to provide\nonly 6/10 of the factual description of chemical entities, and only 5/10 of the f actual\ndescription of fungus-chemical relations. Despite small sample siz e in our evaluation,\nit clearly shows that the performance is below the threshold allowe d for a systematic\nand reliable application.\nHigh dependency and variability due to prompt design choices\nA desirable property of a LLM is to a consistent answer regardless of the p rompts\ndesign. For instance, the prompt ‘ {entity} is produced by fungi, such as’ should be\nequivalent to ‘{entity} is isolated from fungi, such as’ because it refers to the same\nbiological relation. However, we observe a variation in the output as the ev idence of\nsensitivity for prompt design. Similarly to Masked Language Models [19], in order\nto fully exploit GPTs capabilities, prompt engineering is requir ed. In our study, we\nobserve that providing context in the prompt improves the perform ance. Of note,\nChatGPT and GPT-4 are the least sensitive and produce new paragraphs in stead\nof ﬁnishing the prompt.\nBest overall performance was on large corpora, large parameters and most extensive\nhuman feedback alignment\nGPT-4 outperforms ChatGPT (as well the rest tested models) in ter ms of factu-\nality of the answer. It scores 70% (7/10) and 43.6% (48/110) for chemical entity\nrecognition and chemical-fungi relation recognition, respectively. I n general, the fac-\ntual knowledge of the entire generated text was higher (still signiﬁc antly higher in\nGPT-4), but the output did not contain the relation that we asked for, so t hey were\nconsidered not speciﬁc. The hallucinations in GPT-4 is the lowest (54.4%). Im-\nportantly, GPT-4 produced only names of fungi which actually produce chemical\ncompounds.\nWysocka et al. Page 12 of 22\nLimitations\nWe recognise the following limitations of our study. First, LLMs are eval uated on\na speciﬁc biological dataset related to chemical compounds, fungi and anti biotic\nactivity. The models can perform diﬀerently for other biological relat ion. The sample\nsize of 10 compounds is relatively small and increasing the size would l ead to more\nrepresentative results. However, due to a signiﬁcant eﬀort, incl uding domain experts,\nrequired to evaluate generated texts, we argue that our ﬁndings highligh t current\nlimitations and challenges regarding LLM’s applications in the biomedical domain.\nAlthough we evaluated 19 prompt designs, the prompt engineering could be im-\nproved with e.g. a systematic search or optimal prompt algorithms. No ﬁne -tuning,\nnor few-shot learning was performed. Evaluated LLM’s are of-the-shelf m odels.\nMoreover, this analysis concentrated on comparing and contrasting the b ehaviour\nof diﬀerent models with regard to their factuality for a focused task within a scien-\ntiﬁc domain of discourse. Models have a diverse set of corpora, number of parameters\nand design intent, and it was not the intent of this study equalise and c ontrol for\nthese settings. Instead, this analysis aimed to sample a highly dive rse set of models,\nin order to elicit, which of these features are relevant for factual, k nowledge-based\ninference within LLMs.\nA total of > 150 000 fungi species have been described in the literature [20]. The\nnaming of fungal species is subject to change over time [20, 21], and moreov er, the\nnumber of fungal names continue to increase over time. Despite the i mprovements\nin information sharing, the changing fungal nomenclature rules [22, 23] and pr ovid-\ning a tool for name standardisation, the existing literature still con tains plenty of\nsynonyms, isonyms, homonyms, orthographic variants and misused names th at are\nnot in accordance with the standard nomenclature system [24]. In addition , some\ntaxon names in the databases may be variants, synonyms or invalidly publi shed\nnames for various reasons. This may lead to inaccurate search results and renders\nthe assessment of factual knowledge in generated relations challenging even for the\ndomain expert.\nConclusion\nIn this work, we investigate the potential of LLMs to encode domain speci ﬁc factual\nknowledge. We propose an evaluation framework, which examines ﬂuency, prompt-\nalignment, semantic coherence, factuality and speciﬁcity of the gene rated text. We\napply the framework to nine of-the-shelf models in two tasks: chem ical compound\ndeﬁnition generation and chemical-fungus relation determination via e ntity gener-\nation. Although we observe a substantial improvement in the ﬂuency and semantic\ncoherence of generated text in larger and more extensively aligned mode ls, the fac-\ntually of the biological deﬁnitions and relations is still low. The mode ls are biased\ntowards most prevalent and over-represented entities. The abili ty of oﬀ-the-shelf\nLLMs to be used as knowledge bases is limited in their current state. The best\nperforming model, GPT-4, in some cases prevents hallucinations by an epistemic\nawareness mechanism (admitting lack of knowledge). We highlight the need for\nother evaluation frameworks in order to determine limits of LLMs with re spect to\nfactual knowledge, their sensitivity to the prompt design and biase s towards cer-\ntain entities. The best performing GPT-4 recognized 70% chemical com pounds and\nWysocka et al. Page 13 of 22\nproduced less than half factual and speciﬁc relations to fungi, compare d to the best\nopen source model BioGPT-large: 30% compounds and 30% relations for the best\nprompt.\nFuture work. As a follow-up of this study, we will continue evaluating LLMs in\nthe context of biomedical inference, including very recent mode ls such as Llama [25].\nWe plan to extent our proposed framework addressing the need for eﬃcie nt qualita-\ntive and quantitative evaluation of responses generated by LLMs. Such fram eworks\nshould go beyond the well-known benchmarks and be applicable in any sp eciﬁc\nbiomedical applications, such as the one exempliﬁed in this study (c hemical-fungus\nrelation). The promising future direction is to use prompts contain ing biomedi-\ncal texts as contexts (abstract or full texts) combined with few-shot learning or\nin-context learning, as well as the integration with robust, high-recal l retrieval aug-\nmentation mechanisms.\nMethods\nIn this section we describe the workﬂow of our analysis (depicted in Fig. 2), which\nconsists of the following steps:\n• extraction and curation of a dataset with biological relations\n• deﬁnition of text generation tasks for LLMs\n• selection of the target LLMs to be included in the evaluation\n• development of an evaluation framework for the eﬃcient qualitative analys is\nof generated output, including prompt deﬁnition, prompt engineerin g and\nevaluation metrics\nThe above steps allowed us to provide the ﬁrst comparative analysis of LLMs in\nthe context of tasks related to fungi and antibiotics and is transportable to other\nbiological and biomedical relations.\nMotivational scenario\nAntimicrobial resistance in clinically relevant bacteria compromis es the eﬀective-\nness of existing antibiotics and call for the discovery of new antibiot ic substances.\nAntibiotic development is a slow, costly and failure-prone process that can take\nover a decade and costs can reach the scale of hundreds of millions of dollar s [26].\nIn a study of nearly 186,000 clinical trials spanning over 21,000 compounds, th e\nprobability of success of new drugs treating infectious diseases was f ound to be\n25.2% [27]. However since 2017, only eight new antibiotics have been approved , in-\ncluding one for the treatment of multidrug-resistant tuberculosis (2017-2021) [28].\nFurthermore, antibiotics in clinical trials are generally analogues of ex isting drugs\nfor which antimicrobial resistance mechanisms have already emerged [ 29], further\nhighlighting the need for new approaches to antibiotic discovery.\nSome organisms, such as fungi or bacteria, naturally produce a variety of se c-\nondary metabolites (also called natural products) associated with many biologi-\ncal activities. Penicillin, a beta-lactam antibiotic, is a historic al example of fungal\nmetabolites with therapeutic properties. In order to eﬀectively exploit the pool of\npotential sources of antibiotics, avoiding dead ends and rediscovery , it is essential to\nidentify the secondary metabolites known to be produced by these organisms and\nwhich substances have already shown antibiotic activity. This kno wledge is mainly\ncommunicated in the scientiﬁc literature, the size and complexit y of which makes\nit diﬃcult to explore it systematically and at scale.\nWysocka et al. Page 14 of 22\nDataset\nThe investigation of the biological knowledge stored in LLMs requires a col lection of\nbiological relations that are elicited and referred in the scientiﬁc l iterature. Scientiﬁc\npublications are part of the training corpus for most LLMs, thus higher pre valence\nin literature should lead to better performance in factual knowledge extraction. In\nour study we created a dataset of biological relations accounting for the amoun t of\nsupporting evidence (number of associated papers).\nFungus-chemical pairs were extracted from the Wikidata Knowledge G raph using\nthe predicate found in taxon (p:P703), along with the number of bibliographic ref-\nerences supporting each relationship. Classiﬁcation and nomenclatur e information\non fungi were extracted from the Mycobank database [1]. Information about antibi-\notic activity of chemicals were extracted from the ChEBI ontology [2].\nA subset containing only fungal species producing chemicals with antibiotic ac-\ntivity was ﬁrst created. The pairs with the most bibliographic refer ences were pro-\ngressively integrated until obtaining 100 distinct subject fungi, w hich corresponds\nto 123 pairs. Then, a complementary subset (with an equal number of pai rs) involv-\ning produced chemicals but without antibiotic activity was added from the same\nlist of fungi. Again, the pairs with the most bibliographic references w ere selected.\nOnly molecules with a 3-STAR review in ChEBI were considered and onl y those\nthat have an annotated role in the antimicrobial agent class ( CHEBI:33281) were\nselected for positive examples of antibiotics.\nAs a result, a dataset with 246 fungus-chemical pairs equally divided b etween\nchemicals with and without antibiotic activity was obtained. For the ex periments,\nwe randomly selected ten chemicals distributed by antibiotic acti vity and number\nof references (see Additional ﬁle 1: Table S1).\nLarge Language Models\nIn this study, we evaluated nine LLMs (summarized in Additional ﬁle 9: T able S9),\nwhere six of them were released within the past year (since July 2022). The models\nvary i.a. in terms of training corpus, vocabulary size, number of parame ters, layers\nand maximum input sequence length. Below, we articulate the essen tial properties\nof each target model.\nThere are two main high-level architectures associated with language m odels:\nBERT - Bidirectional Encoder Representations from Transformers (a nd its deriva-\ntives) and GPT - ‘Generative Pre-trained Transformer’ (and its der ivatives). Exten-\nsive research has been conducted on the former in the biomedical domain , demon-\nstrating considerable success in numerous discriminative downs tream tasks. In this\npaper, we evaluate generative transformer language models pre-trained on large\nscale general literature (GPT-2, GPT-3, GPT-neo, Bloom, ChatGPT, GPT -4) and\nspeciﬁc for the biomedical domain (BioGPT and BioGPT-Large).\n[1]https://www.mycobank.org\n[2]https://www.ebi.ac.uk/chebi/downloadsForward.do\nWysocka et al. Page 15 of 22\nGPT is a language generation model that utilizes the transformer decode r archi-\ntecture for pre-training on large-scale text corpora. GPT is grounded in the next-\ntoken prediction task, in which the model learns to predict the ne xt word token\nbased on the preceding word tokens.\nGPT-2 adopts GPT-1’s architecture with some diﬀerences, includi ng the modiﬁed\ninitialization, pre-normalization, and reversible tokenization. A di ﬀerent initializa-\ntion, accounting for residual path accumulation, scales weights by 1/N, whe re N is\nthe number of residual layers. Vocabulary expands to 50,257, context siz e increases\nto 1024 tokens, and batch size grows to 512. GPT-2 used a larger architecture and a\nmore diverse corpus than GPT-1, including web pages, books, and scien tiﬁc articles.\nGPT-3 uses the same model and architecture as GPT-2, with the excep tion of the\nuse of alternating dense and sparse attention patterns in the layers of the trans-\nformer, similar to the Sparse Transformer. Compared to previous gener ative models,\nGPT-3 has a magnitude order larger parameter space (175 billion parameters) .\nGPT-Neo is an autoregressive transformer language model, which is based on the\nreplication of the GPT-3 architecture. With 2.7 billion parameters, the model was\ntrained on Pile [30, 31], a large-scale curated corpus. The architecture of Bloom\n(BigScience Large Open-science Open-access Multilingual Language Mode l [32]) is\nsimilar to GPT-3, being trained on 46 diﬀerent languages and 13 programming\nlanguages. The largest Bloom contains 176B parameters, however due to hardwar e\naccess limitations, we tested Bloom under the 560M and 3B parameter setti ng.\nBioGPT and BioGPT-large are domain-speciﬁc generative transformer language\nmodels pre-trained on large-scale biomedical literature [33], and are pr e-trained on\n15M PubMed items (each with both title and abstract) from scratch. We te sted\nboth versions: with 347M and 1.5B parameters (BioGPT-large). BioGPT uses t he\nGPT-2 architecture as its backbone. However, instead of relying on th e GPT-2\nvocabulary, it has created an in-domain vocabulary through Byte-Pair Enc oding\n(BPE) applied to the corpus, leading to a total of 42,384 word pieces. The m odel\nutilizes the GPT-2medium as its core network, featuring 24 layers, a hidden size of\n1024, and 16 attention heads. This results in a total of 347 million parameters for\nthe BioGPT model.\nGalactica [34] is model targeting the parsing of scientiﬁc discourse, developing\nparticular tokeneizers for common scientiﬁc text (e.g. equations, ch emical formulae).\nIt implements the following architectural modiﬁcations: GeLU acti vations [35], 2048-\nlength context window, no biases [36], learned positional embeddings, and 50k-token\nByte-Pair Encoding vocabulary [37] from a 2% training data subset. It i s available\nin sizes from 125M to 120B parameters. The largest version that we were able to\nrun on was 1.3B.\nBoth GPT-4 and ChatGPT builds upon the GPT-3.5 model which is then r eﬁned\nvia the Reinforcement Learning with Human Feedback (RLHF) mechanism. Both\ncorpora and human feedback alignment dataset are not reported.\nThe ﬁnal baseline set consists of: GPT-2 [5], GPT-neo (1.3B parameters ) [30] and\nBLOOM (3B parameters) using the huggingface API [3], GPT-3 [6] via the OpenAI\nAPI, and for ChatGPT and GPT-4 [14] a default OpenAI user interface was use d\nto generate outputs, each prompt in a separate session.\n[3]https://huggingface.com\nWysocka et al. Page 16 of 22\nFramework for the evaluation of Large Language Models on the encodin g of factual\nscientiﬁc knowledge\nAn intrinsic evaluation of the text generated by the models was perform ed by a\nhuman expert according to ﬁve criteria: Fluency, Prompt-alignment , Semantic co-\nherence, Factuality and Speciﬁcity [38, 39]:\n• Fluency evaluates the quality of the generated text, considering two sub-\ncriteria: syntactic correctness and style. Syntactic correctnes s assesses whether\na sentence conforms to the rules of grammar and expected syntactic str uc-\nture. Scientiﬁc style is determined by the vocabulary of the gene rated text\nconforming to a scientiﬁc theme (‘reads as a scientiﬁc text’).\n• Prompt-alignment refers to the relation of relevance and pragmatic coherence\nbetween the prompt and the generated text, whether the generated te xt is\nconsistent with the input prompt and is related to the entities and context of\nthe prompt.\n• Semantic coherence consists of two levels of analysis: (i) intra-sentence assesses\nwhether the sentence is relating terms surface to expected argum ent types for\na given predicate and (ii) inter-sentence: assessing whether adj acent sentences\nhave a coherent discourse relation [40].\n• Factuality is distinct from the meaning of a sentence which is conveyed by its\nsemantic coherence. A sentence generated by a model is true if the re exists a\nfactual statement in the scientiﬁc literature, a database, or any other trusted\nsource.\n• Speciﬁcity evaluates the alignment between the prompt and the answer regard-\ning their level of abstraction. While some answers can be factually corr ect,\nthey may not answer to the level of abstraction required by the prompt .\nWhile auto-regressive language models are by design to deliver ﬂuency , prompt-\nalignment and semantic coherence, text generation during decoding c an lead to\nrepetitive, incoherent or meaningless outputs [41]. As they are comple mentary, the\nﬂuency, prompt-alignment and semantic coherence were assessed in on e step of\nthe evaluation process (Fig. 3, STEP 1 ). Moreover, the probabilistic nature of\nthe next token prediction task also contrasts with the notion of factuali ty and\nlarge language models are prone to hallucination [42]. Hallucinations are factual ly\nincorrect statements which can be diﬃcult to be localised by non-e xperts due to\ntheir expression in a ﬂuent and semantically coherent text. In the context of this\nstudy, major hallucinations can be associated with the compound descr iption or\nrelationships with fungi, while minor hallucinations may be associat ed with the\ndate of ﬁrst isolation for instance. The factuality of the generated text w as assessed\nin the STEP 2 . Importantly, for Relation determination via entity generation , the\ncorrectness of the generated {entity 2 } is veriﬁed prior to the veriﬁcation of the\nwhole description. If incorrect, we assume that the LLM fails to deter mine the\nrelation. Speciﬁcity of the generated text is assessed in the STEP 3 . Note that only\nSTEP 1 does not require a domain expert.\nIn this study two major tasks were evaluated: Chemical compound deﬁn ition gen-\neration and Chemical-fungus relation determination via entity generat ion. Models\nwere prompted with task-speciﬁc prompts (see Additional ﬁle 2: Table S2) and the\ngenerated text was evaluated according to the previously described c riteria. The\nWysocka et al. Page 17 of 22\norder of evaluation in each task is described in a schema of the framework in Fig.\n3.\nText generation tasks\nWe investigate the ability of LLMs to act as knowledge bases and establish t he\nrelation between fungi and antibiotics. Following the evaluation frame work proposed\nin 3, we deﬁne two text generation tasks for chemical-fungus relation de termination\nvia entity generation (see the workﬂow in Fig. 2).\nThe ﬁrst task uses prompts for chemical compound deﬁnition generation, shown in\nthe Additional ﬁle 2: Table S2 as P1-P7. For the same task we deﬁne simple pr ompts\n(P1, P2) and context-based prompts, elucidating the type of the subje ct entity: ‘a\ncompound’ or ‘a substance’ (P4 and P5) [43]. According to authors’ suggestion s,\nprompts were framed as questions for Galactica, rather than sentences t o complete\n(P3, P6, P7).\nThe second task uses prompts for relation determination via entity gen eration:\n{entity 1 }- {relation} - {entity 2 }, where {entity 1 } is a chemical compound (P8-\nP19). The prompts P13-P18 contain the context at the end, guiding the mode l\ntowards a relation to a fungus, rather than to another organism capable of pro ducing\nthe compound.\nWe select ten names of chemical compounds (ﬁve chemicals with and ﬁve without\nantibiotic activity). The maximum numbers of tokens to generate, exc luding the\nnumber of tokens in the prompt is 30, except for ChatGPT and GPT-4. In total , we\ninvestigated outputs for 15 prompts for the models Bloom, GPT-2, GPT-n eo, GPT-\n3, BioGPT, BioGPT-large, ChatGPT and GPT-4; and four prompts for Galactica.\nAll prompts are presented in Additional ﬁle 2: Table S2. All outputs were an no-\ntated by two independent scientists.\nRelated Work\nLarge Language models achieve state-of-the-art performance in many NLP related -\ntask, sometimes outperforming previous baselines in few-shot sett ings[6]. However,\nthe factuality of the knowledge that can be extracted by prompting the se models\nhas been widely discussed. Since the ﬁrst demonstration by Pertr oni et al.[44] on\nMasked Language Models (MLM), several studies have examined the mechan isms\nand biases underlying these predictions, questioning their appl icability beyond their\npotential as KBs.\nCao et al.[45] showed that predictions from MLM are highly prompt-biased an d\nthat, while external context apparently helps the models, its main ly via type guid-\nance or answer leakage. In follow-up works, many domain-speciﬁc datasets an d\noriginal prompting approaches were developed for factual knowledge extr action on\nMLM [46, 47, 48, 49, 50, 51, 17, 52]. In the biomedical area, Sung et al.[53] extended\nthe work of Cao et al. on a new dataset, bioLAMA, conﬁrming their observations\nfor biological knowledge. More recently, Kalo et al.[54] extended the ev aluation on\na novel benchmark dataset (KAMEL) and to generative Language Models from the\nGPT and OPT family. Si et al. [55] evaluated the generalisability, fairn ess, cali-\nbration, and factuality of diﬀerent prompting strategies on GPT-3. Accord ing to\nMallen et al. [56], it has been observed that retaining less popular factu al knowl-\nedge is hard for LLM and simply increasing their size does not signiﬁcant ly improve\nWysocka et al. Page 18 of 22\ntheir ability to remember. Razniewski et al. [57] presented qualit ative arguments\nthat implicit LMs are not suitable as substitutes for explicit KBs, b ut may play a\nmajor role in the augmentation and curation of KBs.\nHoward et al. [58] examined the implications of generative AI for antimicrob ial\nadvisory in infection scenario-based questions and outlined the limi tations of imple-\nmenting ChatGPT for interventions due to deﬁcits in situational aw areness, infer-\nence, and consistency. Li et al. [59] reported that ChatGPT performs mod erately or\npoorly in several biomedical tests and is unreliable in actual clinic al use. Further-\nmore, implementing ChatGPT into clinical practice is associated w ith numerous\nobstacles, such as deﬁcits in situational awareness, reasoning, and cons istency[60].\nWhile the use of natural language processing in healthcare is not novel, the intro-\nduction of GPT-4 has elicited intense debate regarding its potential opportunities\nand challenges in healthcare[61].\nEthics approval and consent to participate\nNot applicable\nConsent for publication\nNot applicable\nAvailability of data and materials\nAll data generated or analysed during this study are include d in this published article [and its supplementary\ninformation ﬁles].\nCompeting interests\nThe authors declare that they have no competing interests.\nFunding\nThis project has received funding from the European Union’s Horizon 2020 research and innovation programme\nunder grant agreement No 965397. This work was supported by th e IDIAP Research Institute and has been done in\ncollaboration with the company Inﬂamalps SA and is supporte d by the Ark Foundation. The funding bodies played\nno role in the design of the study, research, writing and publ ication of the paper.\nAuthor’s contributions\nAF, VM conception of the work; MW, OW, MD design of the work; MW the acquisition of data; MW, OW the\nanalysis of data; MW, OW, MD the interpretation of data; MW, O W, MD drafted the work; AF, VM revised the\nwork; All authors read and approved the ﬁnal manuscript.\nAcknowledgements\nThe authors would like to thank the support of Jo¨ el Dumoulin , Joel Rossier and Colombine Verzat.\nAuthor details\n1digital Experimental Cancer Medicine Team, Cancer Biomark er Centre, CRUK Manchester Institute, University of\nManchester, Oxford Rd, M13 9 PL Manchester, UK. 2Department of Computer Science, University of Manchester,\nOxford Rd, M13 9 PL Manchester, UK. 3Idiap Research Institute, National University of Sciences, Rue Marconi 19,\nCH - 1920 Martigny, Switzerland. 4Inﬂamalps SA, Route de l’Ile-au-Bois 1A, CH - 1870 Monthey, S witzerland.\nReferences\n1. Torres, M.D.T., de la Fuente-Nunez, C.: Toward computer-m ade artiﬁcial antibiotics. Current Opinion in\nMicrobiology 51, 30–38 (2019). doi:10.1016/j.mib.2019.03.004. Antimicr obials\n2. Stokes, J.M., Yang, K., Swanson, K., Jin, W., Cubillos-Ru iz, A., Donghia, N.M., MacNair, C.R., French, S.,\nCarfrae, L.A., Bloom-Ackermann, Z., Tran, V.M., Chiappino -Pepe, A., Badran, A.H., Andrews, I.W., Chory,\nE.J., Church, G.M., Brown, E.D., Jaakkola, T.S., Barzilay, R., Collins, J.J.: A Deep Learning Approach to\nAntibiotic Discovery. Cell 180(4), 688–70213 (2020). doi:10.1016/j.cell.2020.01.021. Accessed 2023-03-29\n3. Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph,\nN., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., K hlaaf, H., Sastry, G., Mishkin, P., Chan, B.,\nGray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavari an, M., Winter, C., Tillet, P., Such, F.P.,\nCummings, D., Plappert, M., Chantzis, F., Barnes, E., Herber t-Voss, A., Guss, W.H., Nichol, A., Paino, A.,\nTezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Sau nders, W., Hesse, C., Carr, A.N., Leike, J., Achiam,\nJ., Misra, V., Morikawa, E., Radford, A., Knight, M., Brunda ge, M., Murati, M., Mayer, K., Welinder, P.,\nMcGrew, B., Amodei, D., McCandlish, S., Sutskever, I., Zare mba, W.: Evaluating Large Language Models\nTrained on Code (2021). 2107.03374\n4. Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Na umann, T., Gao, J., Poon, H.:\nDomain-speciﬁc language model pretraining for biomedical natural language processing. ACM Transactions on\nComputing for Healthcare 3(1), 1–23 (2021). doi:10.1145/3458754\nWysocka et al. Page 19 of 22\n5. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutsk ever, I.: Language models are unsupervised\nmultitask learners (2019)\n6. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., D hariwal, P., Neelakantan, A., Shyam, P., Sastry,\nG., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., He nighan, T., Child, R., Ramesh, A., Ziegler, D.M.,\nWu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M. , Gray, S., Chess, B., Clark, J., Berner, C.,\nMcCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Lan guage Models are Few-Shot Learners (2020).\n2005.14165\n7. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K.,\nRay, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Sim ens, M., Askell, A., Welinder, P., Christiano, P.,\nLeike, J., Lowe, R.: Training language models to follow inst ructions with human feedback. arXiv.\narXiv:2203.02155 [cs] (2022). http://arxiv.org/abs/2203 .02155 Accessed 2023-03-05\n8. OpenAI: ChatGPT: Optimizing language models for dialogu e. (2022)\n9. Gilson, A., Safranek, C.W., Huang, T., Socrates, V., Chi, L ., Taylor, R.A., Chartash, D.: How does chatgpt\nperform on the united states medical licensing examination ? the implications of large language models for\nmedical education and knowledge assessment. JMIR Med Educ 9, 45312 (2023). doi:10.2196/45312\n10. Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchel l, S.: On the dangers of stochastic parrots: Can\nlanguage models be too big? In: Proceedings of the 2021 ACM Co nference on Fairness, Accountability, and\nTransparency. FAccT ’21, pp. 610–623. Association for Comp uting Machinery, New York, NY, USA (2021).\ndoi:10.1145/3442188.3445922. https://doi.org/10.1145 /3442188.3445922\n11. Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E ., Bang, Y.J., Madotto, A., Fung, P.: Survey of\nhallucination in natural language generation. ACM Comput. Surv. 55(12) (2023). doi:10.1145/3571730\n12. Mahowald, K., Ivanova, A.A., Blank, I.A., Kanwisher, N., Tenenbaum, J.B., Fedorenko, E.: Dissociating\nlanguage and thought in large language models: a cognitive p erspective (2023). 2301.06627\n13. Weidinger, L., Uesato, J., Rauh, M., Griﬃn, C., Huang, P.- S., Mellor, J., Glaese, A., Cheng, M., Balle, B.,\nKasirzadeh, A., Biles, C., Brown, S., Kenton, Z., Hawkins, W. , Stepleton, T., Birhane, A., Hendricks, L.A.,\nRimell, L., Isaac, W., Haas, J., Legassick, S., Irving, G., Ga briel, I.: Taxonomy of Risks posed by Language\nModels. In: 2022 ACM Conference on Fairness, Accountabilit y, and Transparency, pp. 214–229. ACM, Seoul\nRepublic of Korea (2022). doi:10.1145/3531146.3533088. h ttps://dl.acm.org/doi/10.1145/3531146.3533088\nAccessed 2023-04-25\n14. OpenAI: GPT-4 Technical Report (2023). 2303.08774\n15. Jullien, M., Valentino, M., Freitas, A.: Do transformer s encode a foundational ontology? probing abstract\nclasses in natural language. arXiv preprint arXiv:2201.10 262 (2022)\n16. Rozanova, J., Valentino, M., Cordeiro, L., Freitas, A.: Interventional probing in high dimensions: An nli case\nstudy. arXiv preprint arXiv:2304.10346 (2023)\n17. Wysocki, O., Zhou, Z., O’Regan, P., Ferreira, D., Wysock a, M., Landers, D., Freitas, A.: Transformers and the\nRepresentation of Biomedical Background Knowledge. Compu tational Linguistics 49(1), 73–115 (2023).\nhttps://direct.mit.edu/coli/article-pdf/49/1/73/2069018/coli\na 00462.pdf\n18. Mousavi, B., Invasive Fungi Research Center, Mazandara n University of Medical Sciences, Sari, Iran, Hedayati,\nM.T., Invasive Fungi Research Center (IFRC), Department of Medical Mycology and Parasitology/ School of\nMedicine, Mazandaran University of Medical Sciences, Khaz arabad Road, P.O. Box 48175-1665, Sari, Iran.,\nHedayati, N., Ramsar International Branch, Mazandaran Unive rsity of Medical Sciences, Sari, Iran, Ilkit, M.,\nDivision of Mycology, Department of Microbiology, Faculty of Medicine, University of C ¸ukurova, Adana, Turkey,\nSyedmousavi, S., Department of Medical Microbiology and In fectious Diseases, Erasmus MC, the Netherlands:\nAspergillus species in indoor environments and their possi ble occupational and public health hazards. Current\nMedical Mycology 2(1), 36–42 (2016). doi:10.18869/acadpub.cmm.2.1.36. Acc essed 2023-04-11\n19. Zhou, Y., Muresanu, A.I., Han, Z., Paster, K., Pitis, S., C han, H., Ba, J.: Large Language Models Are\nHuman-Level Prompt Engineers (2023). 2211.01910\n20. Wang, F., Wang, K., Cai, L., Zhao, M., Kirk, P.M., Fan, G., Sun, Q., Li, B., Wang, S., Yu, Z., Han, D., Ma, J.,\nWu, L., Yao, Y.: Fungal names: a comprehensive nomenclatura l repository and knowledge base for fungal\ntaxonomy. Nucleic Acids Research 51(D1), 708–716 (2022). doi:10.1093/nar/gkac926.\nhttps://academic.oup.com/nar/article-pdf/51/D1/D708/48441205/gkac926.pdf\n21. Richards, T.A., Leonard, G., Wideman, J.G.: What deﬁnes the “kingdom” fungi? Microbiology Spectrum 5(3),\n5–323 (2017). doi:10.1128/microbiolspec.FUNK-0044-2017 .\nhttps://journals.asm.org/doi/pdf/10.1128/microbiolspec.FUNK-0044-2017\n22. Aime, M.C., Miller, A.N., Aoki, T., Bensch, K., Cai, L., Cr ous, P.W., Hawksworth, D.L., Hyde, K.D., Kirk,\nP.M., L¨ ucking, R.,et al.: How to publish a new fungal species, or name, version 3.0. IMA fungus 12, 1–15\n(2021)\n23. Turland, N.J., Wiersema, J.H., Barrie, F.R., Greuter, W., Hawksworth, D.L., Herendeen, P.S., Knapp, S.,\nKusber, W.-H., Li, D.-Z., Marhold, K., et al.: International Code of Nomenclature for Algae, Fungi, and Pl ants\n(Shenzhen Code) Adopted by the Nineteenth International Bot anical Congress Shenzhen, China, July 2017.\nKoeltz botanical books, ??? (2018)\n24. L¨ ucking, R., Aime, M.C., Robbertse, B., Miller, A.N., Ar iyawansa, H.A., Aoki, T., Cardinali, G., Crous, P.W.,\nDruzhinina, I.S., Geiser, D.M., et al.: Unambiguous identiﬁcation of fungi: where do we stand and h ow accurate\nand precise is fungal dna barcoding? IMA fungus 11(1), 14 (2020)\n25. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lacha ux, M.-A., Lacroix, T., Rozi` ere, B., Goyal, N., Hambro,\nE., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., Lample, G.: LLaMA: Open and Eﬃcient Foundation\nLanguage Models (2023). 2302.13971\n26. DiMasi, J.A., Grabowski, H.G., Hansen, R.W.: Innovation i n the pharmaceutical industry: New estimates of\nr&d costs. Journal of Health Economics 47, 20–33 (2016). doi:10.1016/j.jhealeco.2016.01.012\n27. Wong, C.H., Siah, K.W., Lo, A.W.: Estimation of clinical t rial success rates and related parameters.\nBiostatistics 20(2), 273–286 (2018). doi:10.1093/biostatistics/kxx069\n28. Yusuf, E., Bax, H.I., Verkaik, N.J., van Westreenen, M.: An Update on Eight “New” Antibiotics against\nWysocka et al. Page 20 of 22\nMultidrug-Resistant Gram-Negative Bacteria. Journal of Cl inical Medicine 10(5), 1068 (2021).\ndoi:10.3390/jcm10051068. Accessed 2023-03-29\n29. Oliveira, D.M.P.D., Forde, B.M., Kidd, T.J., Harris, P.N. A., Schembri, M.A., Beatson, S.A., Paterson, D.L.,\nWalker, M.J.: Antimicrobial resistance in eskape pathogen s. Clinical Microbiology Reviews 33(3), 00181–19\n(2020). doi:10.1128/CMR.00181-19. https://journals.as m.org/doi/pdf/10.1128/CMR.00181-19\n30. Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., F oster, C., Phang, J., He, H., Thite, A., Nabeshima,\nN., et al.: The pile: An 800gb dataset of diverse text for langu age modeling. arXiv preprint arXiv:2101.00027\n(2020)\n31. Biderman, S., Bicheno, K., Gao, L.: Datasheet for the pil e. arXiv preprint arXiv:2201.07311 (2022)\n32. Workshop, B., :, Scao, T.L., Fan, A., Akiki, C., Pavlick, E., Ili´ c, S., Hesslow, D., Castagn´ e, R., Luccioni, A.S.,\nYvon, F., Gall´ e, M., Tow, J., Rush, A.M., Biderman, S., Webs on, A., Ammanamanchi, P.S., Wang, T., Sagot,\nB., Muennighoﬀ, N., del Moral, A.V., Ruwase, O., Bawden, R., B ekman, S., McMillan-Major, A., Beltagy, I.,\nNguyen, H., Saulnier, L., Tan, S., Suarez, P.O., Sanh, V., Laur en¸ con, H., Jernite, Y., Launay, J., Mitchell, M.,\nRaﬀel, C., Gokaslan, A., Simhi, A., Soroa, A., Aji, A.F., Alf assy, A., Rogers, A., Nitzav, A.K., Xu, C., Mou, C.,\nEmezue, C., Klamm, C., Leong, C., van Strien, D., Adelani, D. I., Radev, D., Ponferrada, E.G., Levkovizh, E.,\nKim, E., Natan, E.B., Toni, F.D., Dupont, G., Kruszewski, G., Pistilli, G., Elsahar, H., Benyamina, H., Tran,\nH., Yu, I., Abdulmumin, I., Johnson, I., Gonzalez-Dios, I., d e la Rosa, J., Chim, J., Dodge, J., Zhu, J., Chang,\nJ., Frohberg, J., Tobing, J., Bhattacharjee, J., Almubarak , K., Chen, K., Lo, K., Werra, L.V., Weber, L., Phan,\nL., allal, L.B., Tanguy, L., Dey, M., Mu˜ noz, M.R., Masoud, M ., Grandury, M., ˇSaˇ sko, M., Huang, M., Coavoux,\nM., Singh, M., Jiang, M.T.-J., Vu, M.C., Jauhar, M.A., Ghale b, M., Subramani, N., Kassner, N., Khamis, N.,\nNguyen, O., Espejel, O., de Gibert, O., Villegas, P., Henderso n, P., Colombo, P., Amuok, P., Lhoest, Q.,\nHarliman, R., Bommasani, R., L´ opez, R.L., Ribeiro, R., Osei , S., Pyysalo, S., Nagel, S., Bose, S., Muhammad,\nS.H., Sharma, S., Longpre, S., Nikpoor, S., Silberberg, S., Pa i, S., Zink, S., Torrent, T.T., Schick, T., Thrush,\nT., Danchev, V., Nikoulina, V., Laippala, V., Lepercq, V., Pr abhu, V., Alyafeai, Z., Talat, Z., Raja, A.,\nHeinzerling, B., Si, C., Ta¸ sar, D.E., Salesky, E., Mielke, S .J., Lee, W.Y., Sharma, A., Santilli, A., Chaﬃn, A.,\nStiegler, A., Datta, D., Szczechla, E., Chhablani, G., Wang , H., Pandey, H., Strobelt, H., Fries, J.A., Rozen, J.,\nGao, L., Sutawika, L., Bari, M.S., Al-shaibani, M.S., Manic a, M., Nayak, N., Teehan, R., Albanie, S., Shen, S.,\nBen-David, S., Bach, S.H., Kim, T., Bers, T., Fevry, T., Neeraj , T., Thakker, U., Raunak, V., Tang, X., Yong,\nZ.-X., Sun, Z., Brody, S., Uri, Y., Tojarieh, H., Roberts, A., Chung, H.W., Tae, J., Phang, J., Press, O., Li, C.,\nNarayanan, D., Bourfoune, H., Casper, J., Rasley, J., Ryabini n, M., Mishra, M., Zhang, M., Shoeybi, M.,\nPeyrounette, M., Patry, N., Tazi, N., Sanseviero, O., von Plat en, P., Cornette, P., Lavall´ ee, P.F., Lacroix, R.,\nRajbhandari, S., Gandhi, S., Smith, S., Requena, S., Patil, S., Dettmers, T., Baruwa, A., Singh, A., Cheveleva,\nA., Ligozat, A.-L., Subramonian, A., N´ ev´ eol, A., Loverin g, C., Garrette, D., Tunuguntla, D., Reiter, E.,\nTaktasheva, E., Voloshina, E., Bogdanov, E., Winata, G.I., Schoelkopf, H., Kalo, J.-C., Novikova, J., Forde,\nJ.Z., Clive, J., Kasai, J., Kawamura, K., Hazan, L., Carpuat, M., Clinciu, M., Kim, N., Cheng, N., Serikov, O.,\nAntverg, O., van der Wal, O., Zhang, R., Zhang, R., Gehrmann, S., Mirkin, S., Pais, S., Shavrina, T., Scialom,\nT., Yun, T., Limisiewicz, T., Rieser, V., Protasov, V., Mikh ailov, V., Pruksachatkun, Y., Belinkov, Y.,\nBamberger, Z., Kasner, Z., Rueda, A., Pestana, A., Feizpour , A., Khan, A., Faranak, A., Santos, A., Hevia, A.,\nUnldreaj, A., Aghagol, A., Abdollahi, A., Tammour, A., HajiHo sseini, A., Behroozi, B., Ajibade, B., Saxena, B.,\nFerrandis, C.M., Contractor, D., Lansky, D., David, D., Kie la, D., Nguyen, D.A., Tan, E., Baylor, E., Ozoani,\nE., Mirza, F., Ononiwu, F., Rezanejad, H., Jones, H., Bhattach arya, I., Solaiman, I., Sedenko, I., Nejadgholi, I.,\nPassmore, J., Seltzer, J., Sanz, J.B., Dutra, L., Samagaio, M., Elbadri, M., Mieskes, M., Gerchick, M.,\nAkinlolu, M., McKenna, M., Qiu, M., Ghauri, M., Burynok, M., Abrar, N., Rajani, N., Elkott, N., Fahmy, N.,\nSamuel, O., An, R., Kromann, R., Hao, R., Alizadeh, S., Shubbe r, S., Wang, S., Roy, S., Viguier, S., Le, T.,\nOyebade, T., Le, T., Yang, Y., Nguyen, Z., Kashyap, A.R., Pala sciano, A., Callahan, A., Shukla, A.,\nMiranda-Escalada, A., Singh, A., Beilharz, B., Wang, B., Br ito, C., Zhou, C., Jain, C., Xu, C., Fourrier, C.,\nPeri˜ n´ an, D.L., Molano, D., Yu, D., Manjavacas, E., Barth, F., Fuhrimann, F., Altay, G., Bayrak, G., Burns, G.,\nVrabec, H.U., Bello, I., Dash, I., Kang, J., Giorgi, J., Golde , J., Posada, J.D., Sivaraman, K.R., Bulchandani,\nL., Liu, L., Shinzato, L., de Bykhovetz, M.H., Takeuchi, M., P ` amies, M., Castillo, M.A., Nezhurina, M.,\nS¨ anger, M., Samwald, M., Cullan, M., Weinberg, M., Wolf, M. D., Mihaljcic, M., Liu, M., Freidank, M., Kang,\nM., Seelam, N., Dahlberg, N., Broad, N.M., Muellner, N., Fung, P. , Haller, P., Chandrasekhar, R., Eisenberg,\nR., Martin, R., Canalli, R., Su, R., Su, R., Cahyawijaya, S., Garda, S., Deshmukh, S.S., Mishra, S., Kiblawi, S.,\nOtt, S., Sang-aroonsiri, S., Kumar, S., Schweter, S., Bhara ti, S., Laud, T., Gigant, T., Kainuma, T., Kusa, W.,\nLabrak, Y., Bajaj, Y.S., Venkatraman, Y., Xu, Y., Xu, Y., Xu, Y., Tan, Z., Xie, Z., Ye, Z., Bras, M., Belkada,\nY., Wolf, T.: BLOOM: A 176B-Parameter Open-Access Multilin gual Language Model (2023). 2211.05100\n33. Luo, R., Sun, L., Xia, Y., Qin, T., Zhang, S., Poon, H., Liu, T.-Y.: BioGPT: generative pre-trained transformer\nfor biomedical text generation and mining. Brieﬁngs in Bioi nformatics 23(6) (2022). doi:10.1093/bib/bbac409.\nbbac409. https://academic.oup.com/bib/article-pdf/23 /6/bbac409/47144271/bbac409.pdf\n34. Taylor, R., Kardas, M., Cucurull, G., Scialom, T., Hartsh orn, A., Saravia, E., Poulton, A., Kerkez, V., Stojnic,\nR.: Galactica: A Large Language Model for Science. arXiv. ar Xiv:2211.09085 [cs, stat] (2022).\nhttp://arxiv.org/abs/2211.09085 Accessed 2023-01-06\n35. Hendrycks, D., Gimpel, K.: Gaussian Error Linear Units (G ELUs) (2020). 1606.08415\n36. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H.W., Sutton,\nC., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., May nez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N.,\nPrabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Br adbury, J., Austin, J., Isard, M., Gur-Ari, G.,\nYin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Micha lewski, H., Garcia, X., Misra, V., Robinson, K.,\nFedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal,\nS., Omernick, M., Dai, A.M., Pillai, T.S., Pellat, M., Lewko wycz, A., Moreira, E., Child, R., Polozov, O., Lee,\nK., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catast a, M., Wei, J., Meier-Hellstern, K., Eck, D.,\nDean, J., Petrov, S., Fiedel, N.: PaLM: Scaling Language Mode ling with Pathways (2022). 2204.02311\n37. Sennrich, R., Haddow, B., Birch, A.: Neural machine transl ation of rare words with subword units. In:\nProceedings of the 54th Annual Meeting of the Association fo r Computational Linguistics (Volume 1: Long\nWysocka et al. Page 21 of 22\nPapers), pp. 1715–1725. Association for Computational Lin guistics, Berlin, Germany (2016).\ndoi:10.18653/v1/P16-1162. https://aclanthology.org/P 16-1162\n38. Celikyilmaz, A., Clark, E., Gao, J.: Evaluation of Text G eneration: A Survey. arXiv. arXiv:2006.14799 [cs]\n(2021). doi:10.48550/arXiv.2006.14799. http://arxiv.o rg/abs/2006.14799 Accessed 2023-05-03\n39. Ma, Y., Liu, J., Yi, F., Cheng, Q., Huang, Y., Lu, W., Liu, X. : AI vs. Human - Diﬀerentiation Analysis of\nScientiﬁc Content Generation\n40. Ke, P., Zhou, H., Lin, Y., Li, P., Zhou, J., Zhu, X., Huang, M. : CTRLEval: An Unsupervised Reference-Free\nMetric for Evaluating Controlled Text Generation. arXiv. a rXiv:2204.00862 [cs] (2022).\nhttp://arxiv.org/abs/2204.00862 Accessed 2023-05-03\n41. Holtzman, A., Buys, J., Du, L., Forbes, M., Choi, Y.: The Cu rious Case of Neural Text Degeneration. arXiv.\narXiv:1904.09751 [cs] (2020). http://arxiv.org/abs/1904 .09751 Accessed 2023-05-03\n42. Maynez, J., Narayan, S., Bohnet, B., McDonald, R.: On Fait hfulness and Factuality in Abstractive\nSummarization. arXiv. arXiv:2005.00661 [cs] (2020). doi:1 0.48550/arXiv.2005.00661.\nhttp://arxiv.org/abs/2005.00661 Accessed 2023-05-03\n43. Petroni, F., Lewis, P., Piktus, A., Rockt¨ aschel, T., Wu , Y., Miller, A.H., Riedel, S.: How Context Aﬀects\nLanguage Models’ Factual Predictions (2020). 2005.04611\n44. Petroni, F., Rockt¨ aschel, T., Lewis, P., Bakhtin, A., W u, Y., Miller, A.H., Riedel, S.: Language Models as\nKnowledge Bases? arXiv. arXiv:1909.01066 [cs] (2019). doi: 10.48550/arXiv.1909.01066.\nhttp://arxiv.org/abs/1909.01066 Accessed 2023-01-12\n45. Cao, B., Lin, H., Han, X., Liu, F., Sun, L.: Can Prompt Probe P retrained Language Models? Understanding the\nInvisible Risks from a Causal View. In: Proceedings of the 60 th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers), pp. 579 6–5808. Association for Computational Linguistics,\nDublin, Ireland (2022). doi:10.18653/v1/2022.acl-long. 398. https://aclanthology.org/2022.acl-long.398\nAccessed 2023-03-05\n46. Jiang, Z., Xu, F.F., Araki, J., Neubig, G.: How Can We Know Wh at Language Models Know? arXiv.\narXiv:1911.12543 [cs] (2020). http://arxiv.org/abs/1911 .12543 Accessed 2023-01-06\n47. Bouraoui, Z., Camacho-Collados, J., Schockaert, S.: In ducing Relational Knowledge from BERT. arXiv (2019).\ndoi:10.48550/ARXIV.1911.12753. https://arxiv.org/abs /1911.12753\n48. Haviv, A., Berant, J., Globerson, A.: BERTese: Learning t o Speak to BERT. arXiv (2021).\ndoi:10.48550/ARXIV.2103.05327. https://arxiv.org/abs /2103.05327\n49. Shin, T., Razeghi, Y., Logan, R.L., Wallace, E., Singh, S .: AutoPrompt: Eliciting Knowledge from Language\nModels with Automatically Generated Prompts. arXiv (2020) . doi:10.48550/ARXIV.2010.15980.\nhttps://arxiv.org/abs/2010.15980\n50. Zhong, Z., Friedman, D., Chen, D.: Factual Probing Is [MAS K]: Learning vs. Learning to Recall. arXiv (2021).\ndoi:10.48550/ARXIV.2104.05240. https://arxiv.org/abs /2104.05240\n51. Fichtel, L., Kalo, J.-C., Balke, W.-T.: Prompt Tuning or Fine-Tuning - Investigating Relational Knowledge in\nPre-Trained Language Models\n52. Jullien, M., Valentino, M., Frost, H., O’Regan, P., Lande rs, D., Freitas, A.: Semeval-2023 task 7:\nMulti-evidence natural language inference for clinical tr ial data. In: Proceedings of the 17th International\nWorkshop on Semantic Evaluation (2023)\n53. Sung, M., Lee, J., Yi, S., Jeon, M., Kim, S., Kang, J.: Can L anguage Models be Biomedical Knowledge Bases?\narXiv. arXiv:2109.07154 [cs] (2021). http://arxiv.org/ab s/2109.07154 Accessed 2023-01-12\n54. Kalo, J.-C., Fichtel, L.: KAMEL : Knowledge Analysis wit h Multitoken Entities in Language Models\n55. Si, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber , J., Wang, L.: Prompting GPT-3 To Be Reliable.\narXiv. arXiv:2210.09150 [cs] (2023). doi:10.48550/arXiv. 2210.09150. http://arxiv.org/abs/2210.09150\nAccessed 2023-05-08\n56. Mallen, A., Asai, A., Zhong, V., Das, R., Hajishirzi, H., Kh ashabi, D.: When Not to Trust Language Models:\nInvestigating Eﬀectiveness and Limitations of Parametric and Non-Parametric Memories\n57. Razniewski, S., Yates, A., Kassner, N., Weikum, G.: Langu age Models As or For Knowledge Bases. arXiv.\narXiv:2110.04888 [cs] (2021). http://arxiv.org/abs/2110 .04888 Accessed 2023-03-05\n58. Howard, A., Hope, W., Gerada, A.: ChatGPT and antimicrobia l advice: the end of the consulting infection\ndoctor? The Lancet Infectious Diseases 23(4), 405–406 (2023). doi:10.1016/S1473-3099(23)00113-5 . Accessed\n2023-05-08\n59. Li, J., Dada, A., Kleesiek, J., Egger, J.: Chatgpt in heal thcare: A taxonomy and systematic review. medRxiv\n(2023). doi:10.1101/2023.03.30.23287899.\nhttps://www.medrxiv.org/content/early/2023/03/30/2023.03.30.23287899.full.pdf\n60. Wang, J., Deng, H., Liu, B., Hu, A., Liang, J., Fan, L., Zhen g, X., Wang, T., Lei, J.: Systematic evaluation of\nresearch progress on natural language processing in medici ne over the past 20 years: Bibliometric study on\npubmed. J Med Internet Res 22(1), 16816 (2020). doi:10.2196/16816\n61. Nori, H., King, N., McKinney, S.M., Carignan, D., Horvitz, E. : Capabilities of GPT-4 on Medical Challenge\nProblems (2023). 2303.13375\nFigures\nFigure 1 The overview of the work. We investigate the ability of LLMs to encode and access\nbiological factual/relational knowledge. More speciﬁcal ly, we select a highly relevant domain of\napplication, which is motivated by antibiotic discovery.\nWysocka et al. Page 22 of 22\nFigure 2 The workﬂow of the performed analysis.\nFigure 3 The framework for qualitative and eﬃcient evaluation of the Large Language Models\nin the context of extracting biological relation from these models.\nAdditional Files\nAdditional ﬁle 1 — The dataset for the experiments\nAdditional ﬁle 2 — Prompts used in two text generation tasks\nAdditional ﬁle 3 — Examples of generated text for selected mo dels, selected compounds as input, and selected\nprompts\nAdditional ﬁle 4 — Examples of generated text for selected in put: Myriocin and selected one prompt\nAdditional ﬁle 5 — Generated fungus name in the second task fo r chemical compound equals Alternariol\nAdditional ﬁle 6 — Performance in the chemical-fungus relation determination via entity generation task\nAdditional ﬁle 7 — Generated fungus name in the second task fo r chemical compound equals Verrucarin A\nAdditional ﬁle 8 — Generated fungus name in the second task fo r chemical compound equals Ergosterol\nAdditional ﬁle 9 — Summary of the Large Language Models\nFigures\nFigure 1\nThe overview of the work. We investigate the ability of LLMs to encode and access\nbiological factual/relational knowledge. More speci\u0000cally, we select a highly relevant domain of\napplication, which is motivated by antibiotic discovery.\nFigure 2\nThe work\u0000ow of the performed analysis.\nFigure 3\nThe framework for qualitative and effcient evaluation of the Large Language Models\nin the context of extracting biological relation from these models.\nSupplementary Files\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nAdditional\u0000le1.pdf\nAdditional\u0000le2.pdf\nAdditional\u0000le3.pdf\nAdditional\u0000le4.pdf\nAdditional\u0000le5.pdf\nAdditional\u0000le6.pdf\nAdditional\u0000le7.pdf\nAdditional\u0000le8.pdf\nAdditional\u0000le9.pdf",
  "topic": "Context (archaeology)",
  "concepts": [
    {
      "name": "Context (archaeology)",
      "score": 0.7026745080947876
    },
    {
      "name": "Fluency",
      "score": 0.6130180358886719
    },
    {
      "name": "Scientific literature",
      "score": 0.53579181432724
    },
    {
      "name": "Computer science",
      "score": 0.5110636949539185
    },
    {
      "name": "Sociology of scientific knowledge",
      "score": 0.4364660382270813
    },
    {
      "name": "Coherence (philosophical gambling strategy)",
      "score": 0.430530309677124
    },
    {
      "name": "Data science",
      "score": 0.4111219644546509
    },
    {
      "name": "Natural language processing",
      "score": 0.37391960620880127
    },
    {
      "name": "Artificial intelligence",
      "score": 0.34920239448547363
    },
    {
      "name": "Psychology",
      "score": 0.29496073722839355
    },
    {
      "name": "Epistemology",
      "score": 0.28454649448394775
    },
    {
      "name": "Biology",
      "score": 0.19150981307029724
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Mathematics education",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210129527",
      "name": "Cancer Research UK Manchester Institute",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I7495430",
      "name": "Idiap Research Institute",
      "country": "CH"
    }
  ]
}