{
    "title": "Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models",
    "url": "https://openalex.org/W4389519476",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2104894238",
            "name": "Qianlong Wang",
            "affiliations": [
                "Novel (United States)",
                "Harbin Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2116895586",
            "name": "Keyang Ding",
            "affiliations": [
                "Novel (United States)",
                "Harbin Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A1926107870",
            "name": "Bin Liang",
            "affiliations": [
                "Harbin Institute of Technology",
                "Chinese University of Hong Kong",
                "Novel (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2038824294",
            "name": "Min Yang",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Shenzhen Institutes of Advanced Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2099613179",
            "name": "Ruifeng Xu",
            "affiliations": [
                "Peng Cheng Laboratory",
                "Harbin Institute of Technology",
                "Novel (United States)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2953070460",
        "https://openalex.org/W2963216553",
        "https://openalex.org/W3100561719",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W2971296908",
        "https://openalex.org/W2916076862",
        "https://openalex.org/W3035529900",
        "https://openalex.org/W1821462560",
        "https://openalex.org/W2251648804",
        "https://openalex.org/W3104169042",
        "https://openalex.org/W2971014768",
        "https://openalex.org/W2952357537",
        "https://openalex.org/W3176038554",
        "https://openalex.org/W2095705004",
        "https://openalex.org/W2970748008",
        "https://openalex.org/W2891778157",
        "https://openalex.org/W2971087444",
        "https://openalex.org/W2098697817",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2251294039",
        "https://openalex.org/W3167287584",
        "https://openalex.org/W2964303116",
        "https://openalex.org/W3034206885",
        "https://openalex.org/W3210828003",
        "https://openalex.org/W2964288660",
        "https://openalex.org/W3021336872",
        "https://openalex.org/W2963168371",
        "https://openalex.org/W4313483544",
        "https://openalex.org/W2898812668",
        "https://openalex.org/W2814589985",
        "https://openalex.org/W4385567227",
        "https://openalex.org/W2962808042",
        "https://openalex.org/W3176719207",
        "https://openalex.org/W4308410295",
        "https://openalex.org/W2875308690",
        "https://openalex.org/W2963240575",
        "https://openalex.org/W4224248112",
        "https://openalex.org/W4287854714",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3009874600",
        "https://openalex.org/W4296708197",
        "https://openalex.org/W4361806395",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2790309729",
        "https://openalex.org/W2529550020"
    ],
    "abstract": "Recently, aspect-based sentiment analysis (ABSA) models have yielded promising results. However, they are susceptible to learning spurious correlations between certain words of the input text and output labels while modeling the sentiment feature of the aspect. This spurious correlation will potentially undermine the performance of ABSA models. One direct solution for this problem is to make the model see and learn an explanation of sentiment expression rather than certain words. Motivated by this, we exploit explanations for the sentiment polarity of each aspect from large language models (LLMs) to reduce spurious correlations in ABSA. First, we formulate a prompt template that wraps the sentence, an aspect, and the sentiment label. This template is utilized to prompt LLMs to generate an appropriate explanation that states the sentiment cause. Then, we propose two straightforward yet effective methods to leverage the explanation for preventing the learning of spurious correlations. We conducted extensive comparative experiments on five datasets by integrating them with some representative ABSA models. Results show that our methods can achieve performance gains and enhance the performance and generalization ability of ABSA models.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2930â€“2941\nDecember 6-10, 2023 Â©2023 Association for Computational Linguistics\nReducing Spurious Correlations in Aspect-based Sentiment Analysis with\nExplanation from Large Language Models\nQianlong Wang1,2, Keyang Ding1,2, Bin Liang1,2,4, Min Yang3, Ruifeng Xu1,2,5âˆ—\n1Harbin Institute of Technology, Shenzhen, China\n2Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies\n3Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences\n4The Chinese University of Hong Kong 5Peng Cheng Laboratory, Shenzhen, China\nqlwang15@outlook.com, keyang.ding@stu.hit.edu.cn, bin.liang@cuhk.edu.hk,\nmin.yang@siat.ac.cn, xuruifeng@hit.edu.cn\nAbstract\nRecently, aspect-based sentiment analysis\n(ABSA) models have yielded promising results.\nHowever, they are susceptible to learning spuri-\nous correlations between certain words of the\ninput text and output labels while modeling\nthe sentiment feature of the aspect. This spuri-\nous correlation will potentially undermine the\nperformance of ABSA models. One direct so-\nlution for this problem is to make the model see\nand learn an explanation of sentiment expres-\nsion rather than certain words. Motivated by\nthis, we exploit explanations for the sentiment\npolarity of each aspect from large language\nmodels (LLMs) to reduce spurious correlations\nin ABSA. First, we formulate a prompt tem-\nplate that wraps the sentence, an aspect, and\nthe sentiment label. This template is utilized to\nprompt LLMs to generate an appropriate expla-\nnation that states the sentiment cause. Then, we\npropose two straightforward yet effective meth-\nods to leverage the explanation for preventing\nthe learning of spurious correlations. We con-\nducted extensive comparative experiments on\nfive datasets by integrating them with some rep-\nresentative ABSA models. Results show that\nour methods can achieve performance gains\nand enhance the performance and generaliza-\ntion ability of ABSA models.\n1 Introduction\nAspect-based sentiment analysis (ABSA) aims to\nidentify the sentiment polarity (e.g., positive, neu-\ntral, and negative) of a specified aspect in a review\n(Pontiki et al., 2014). For example, given a review\n\"great food but the service was dreadful!\" and two\naspects \"food\" and \"service\", this task needs to infer\ntheir sentiment polarities \"positive\" and \"negative\",\nrespectively.\nTraditional ABSA methods primarily rely on\nmachine learning techniques, which incorporate\nsome handcrafted features to enhance performance,\nâˆ— Corresponding author.\nTraining Samples Label\ncompany provides UPS [shipping], \nfast, \ngreat!\npositive\nthe [Final Cut Pro] on this laptop is so \nfast and easy.\npositive\nsuper \nfast [processor] and really nice \ngraphics card.\npositive\nTesting Sample\nthe [battery life] was \nfaster than expected.\n(prediction: positive)\nnegative\nFigure 1: Examples of the spurious correlation between\ncontext words \"fast\" and label \"positive\" in the training\nsamples. This spurious correlation does not hold for the\ntesting sample. Aspect terms are marked in parentheses.\nsuch as linguistic features (Negi and Buitelaar,\n2014). However, feature engineering could be a\ntime-consuming process, requiring significant ef-\nfort and expertise. To solve this dilemma, deep\nlearning solutions are utilized to address ABSA due\nto their powerful contextual feature modeling capa-\nbility. From conventional neural networks (Ruder\net al., 2016; Xue and Li, 2018; Ma et al., 2018) to\nattention mechanisms (Tang et al., 2016a; Li et al.,\n2018a; Gu et al., 2018; Fan et al., 2018), these\nsolutions focus on modeling the dependency rela-\ntionship between an aspect and its corresponding\nopinion expressions. With the emergence of fine-\ntuning paradigm, the attention mechanism armed\nwith pre-trained language models (PLMs) (Devlin\net al., 2019; Song et al., 2019; Wang et al., 2020;\nTian et al., 2021; Nazir et al., 2022; Zhang et al.,\n2022) further strengthens the connection between\nthe aspect and its context.\nDespite their satisfactory results, most neural net-\nwork methods may indulge in learning statistically\nspurious correlations while modeling the sentiment\nfeature of aspect on the context. Here, spurious\ncorrelation (Wang and Culotta, 2020; Wang et al.,\n2022b) refers to the dependence of the model on\n2930\ncertain words of the input text without a deeper un-\nderstanding of the contextual semantics, which has\na know-it-when-you-see-it character. Taking the ex-\nample in Figure 1 for illustration, the opinion word\n\"fast\" expresses different sentiment polarities of the\naspect terms in distinct contexts. Here, 92% of as-\npect sentiment is \"positive\" in the training samples\nwhen counting the proportion of aspect sentiment\npolarity that co-occurs with \" fast\". Due to this\nunbalanced distribution, in the training phase, the\nneural models assume that there is a strong cor-\nrelation between \"fast\" and \"positive\", especially\nfor short texts. Consequently, when faced with a\ntesting sample containing a derivative \"faster\", the\ntrained models will predict the incorrect sentiment\nlabel \"positive\" based on this spurious correlation\nlearned superficially before. Thus, most neural\nmodels may encounter difficulty in navigating spu-\nrious correlations because of a shallow understand-\ning. Besides, they lack the capacity to self-correct,\nresulting in undermining their effectiveness and\ngeneralization.\nOne straightforward solution to alleviate the spu-\nrious correlation problem is to make models attend\nto an explanation of sentiment expression rather\nthan certain words in the context. Here, explana-\ntion refers to the reasons for the sentiment polarity\nof aspect term obtained by deeply understanding\nthe contextual semantics. However, for each train-\ning sample, it is a tricky problem to derive the senti-\nment explanation given the aspect and its sentiment.\nRecently, large language models (LLMs) (Brown\net al., 2020) have achieved remarkable success in a\nwide range of NLP capabilities, including genera-\ntion and contextual understanding. In addition, they\nare knowledgeable due to the substantial linguis-\ntic (Liu et al., 2019) and factual world knowledge\nlearned. Thus, LLMs can be exploited to gener-\nate an explanation toward the sentiment of aspect\nthrough prompt-driven contextual understanding\n(Bian et al., 2023). Taking the second training sam-\nple in Figure 1 as an example, LLMs can yield\nan explanation, \"The sentiment towards â€™Final Cut\nProâ€™ is positive because the speaker praises its\nefficiency and user-friendliness on the laptop, in-\ndicating satisfaction and favorable feelings about\nthe software.\".\nInspired by this, we leverage explanations from\nLLMs to reduce spurious correlations in ABSA.\nSpecifically, we first design a prompt containing\nan aspect term and its sentiment to induce LLMs\nto provide a relevant explanation according to the\ncontext. In this way, the output explanation can\nprovide the reason for sentiment and may contain\nsome external knowledge thanks to the powerful ca-\npabilities of LLMs. Then, we propose two methods\nto employ this explanation to improve the effective-\nness and generalization of ABSA models. One\nis the augmentation-based method, which directly\ntreats these explanations containing the aspect term\nas training samples. We mix these explanations\nwith the original training samples to train a more\nrobust ABSA model. This method can not only re-\nlieve the statistical bias in original samples but also\nlearn a range of sample patterns. The other is the\ndistillation-based method, whose basic idea is to\ndistill the knowledge embedded in the explanation\ninto a student ABSA model. By the distillation loss,\nthe student ABSA model can mimic the two behav-\niors of the teacher, i.e., sentiment representation\nand output logit. In this way, the explanation can\nguide the learning of ABSA models and prevent\nthem from over-focusing on spurious correlations.\nIn summary, our contributions are as follows:\nâ€¢ To our knowledge, we are the first to induce\nLLMs to generate an explanation for the as-\npectâ€™s sentiment and use it to reduce spurious\ncorrelations in the ABSA task.\nâ€¢ We devise two straightforward methods for\nutilizing this explanation, which can be inte-\ngrated into most mainstream baselines.\nâ€¢ We conduct extensive experiments on five\nbenchmark datasets, showing that baselines\narmed with the proposed methods can achieve\nbetter performance on inference and general-\nization.\n2 Related Work\nAspect-based Sentiment Analysis. ABSA aims\nto identify the sentiment polarity of each aspect\nmentioned in the text. To solve this task, vari-\nous neural networks with the attention mechanism\nare utilized to find the semantic relation of an as-\npect and its context for capturing the corresponding\nopinion expression (Tang et al., 2016b; Ma et al.,\n2017; Li et al., 2018c; Fan et al., 2018; Tan et al.,\n2019). For instance, Fan et al. (2018) exploited a\nmulti-grained attention mechanism to capture the\nword-level interaction between the aspect and its\nrelevant context. The idea behind the attention\n2931\nLarge Language     \nModel\nstep 1. explanation generation\nSentence ğ‘¿:\nthe Final Cut Pro on this\nlaptop is so fast and easy.\nAspect ğ’‚:Final Cut Pro\nLabel ğ’š: positive\nIn the following sentence, \"the\nFinal Cut Pro on this laptop is so\nfast and easy,\", explain why the\nsentiment expressed by aspect term\n\"Final Cut Pro\" is \"positive\"?\nLimit to forty words.\nCopying adjectives from the\noriginal sentence is not allowed.\nPrompt \nTemplate\nExplanation à·¡ğ‘¿:\nThe sentiment towards 'Final\nCut Pro' is positive because the\nspeaker praises its efficiency\nand user-friendliness on the\nlaptop, indicating satisfaction\nand favorable feelings about\nthe software.\nstep 2. explanation exploitation\naugmentation-based method distillation-based method\nencoder\nclassifier\nğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ âˆª à·¡ğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ\nâ„’ğ‘ğ‘™ğ‘ \nstudent\nencoder\nclassifier\nâ„’ğ‘ğ‘™ğ‘ \nteacher\nencoder\nclassifier\nâ„’ğ‘‘ğ‘–ğ‘ \nEMA\nâ„’â„ğ‘–ğ‘‘\nğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ à·¡ğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ\nLarge Language     \nModel\nstep 1. explanation generation\nSentence ğ‘¿:\nthe Final Cut Pro on this\nlaptop is so fast and easy.\nAspect ğ’‚:Final Cut Pro\nLabel ğ’š: positive\nIn the following sentence, \"the\nFinal Cut Pro on this laptop is so\nfast and easy,\", explain why the\nsentiment expressed by aspect term\n\"Final Cut Pro\" is \"positive\"?\nLimit to forty words.\nCopying adjectives from the\noriginal sentence is not allowed.\nPrompt \nTemplate\nExplanation à·¡ğ‘¿:\nThe sentiment towards 'Final\nCut Pro' is positive because the\nspeaker praises its efficiency\nand user-friendliness on the\nlaptop, indicating satisfaction\nand favorable feelings about\nthe software.\nstep 2. explanation exploitation\naugmentation-based method distillation-based method\nencoder\nclassifier\nğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ âˆª à·¡ğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ\nâ„’ğ‘ğ‘™ğ‘ \nstudent\nencoder\nclassifier\nâ„’ğ‘ğ‘™ğ‘ \nteacher\nencoder\nclassifier\nâ„’ğ‘‘ğ‘–ğ‘ \nEMA\nâ„’â„ğ‘–ğ‘‘\nğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ à·¡ğ‘¿ğ’Š,ğ’‚ğ’Š,ğ’šğ’Š ğ’Š=ğŸ\nğ‘µ\nFigure 2: The overview of the proposed framework. This framework consists of two steps: explanation generation\nand explanation exploitation.\nmechanism is to focus on the context related to the\naspect and shield the irrelevant context. To further\npursue this idea, some studies (Song et al., 2019; Li\net al., 2020; Yan et al., 2021; Wang et al., 2022b,a)\napplied pre-trained models (PLMs) such as BERT\n(Devlin et al., 2019) to model the semantic rela-\ntionship between the given aspect and its context.\nThe internal multi-head self-attention mechanism\nin PLMs is more efficient than conventional atten-\ntion techniques (Vaswani et al., 2017). As a result,\nthese studies consistently delivered better results.\nAnother research trend is to leverage syntactic\nknowledge from syntactic trees to handle ABSA.\nThis syntactic knowledge helps to establish con-\nnections between the aspect and opinion words and\nlearn syntax-aware feature representations of the\naspect (He et al., 2018; Sun et al., 2019; Phan and\nOgunbona, 2020; Wang et al., 2020; Tian et al.,\n2021; Liang et al., 2022). The core idea of these\nstudies is to transform a constructed syntax depen-\ndency tree into a graph for posing greater attention\nto important words.\nAlthough these methods obtained promising re-\nsults by modeling semantic relationships between\naspects and contexts, they are inevitably plagued\nby statistical spurious correlations. Unlike them,\nin this paper, we aim to reduce spurious correla-\ntions with explanations from LLMs. These expla-\nnations can serve to guide ABSA models not to\nfocus on certain words in the context to prevent\nbeing trapped in the spurious correlation trap.\nLarge Language Models. With the advent of\nGPT-3 (Brown et al., 2020), LLMs break into the\nlimelight and draw enormous attention. They typ-\nically feature a vast array of model parameters\nand undergo training on immensely large volumes\nof raw data. By learning from data, they memo-\nrize and understand vast amounts of knowledge\n(Li et al., 2022) and learn to reason (Wei et al.,\n2022). Knowledge and reason are crucial for build-\ning a satisfactory NLP system that can understand\nand generate human-like language. Consequently,\nLLMs like ChatGPT can achieve substantial perfor-\nmance improvements in a wide range of NLP tasks,\nincluding inference and dialogue, by profoundly\ncomprehending the contextual semantics. Inspired\nby this, for the sentiment polarity of each aspect,\nwe here apply LLMs to generate an explanation to\nexplain its causes.\n3 Our Approach\n3.1 Problem Definition\nGiven an ABSA training set, each sample consists\nof a sentence X, an aspect a, and a sentiment label\ny. Here, the aspect is a sub-sequence token in the\nsentence. ABSA aims to learn a sentiment classifier\nthat can precisely predict a sentiment polarity yâˆˆ\n2932\n{positive, negative, neural} for each aspect term\naccording to the semantics of the sentence.1\n3.2 Overview\nAs shown in Figure 2, our framework consists of\ntwo steps. The first step is explanation generation.\nHere, for each training sample, we use a prompt\ntemplate to encapsulate the sentence, the aspect,\nand its sentiment to drive the LLMs to generate an\nexplanation to indicate the corresponding sentiment\ncause. The second step is explanation exploitation.\nHere, we propose two simple yet effective methods\nto exploit explanations for alleviating the spurious\ncorrelations in ABSA.\n3.3 Explanation Generation\nSpurious correlations are common in current\nABSA models, particularly in cases of over-\nparameterization or insufficient training data\n(Sagawa et al., 2020). The fundamental reason\nis that these models might learn statistical corre-\nlations between superficial textual cues and senti-\nment labels rather than achieving a profound com-\nprehension of contextual semantics. Consequently,\nthis problem will hurt the performance and gener-\nality of the ABSA classifier.\nIn this work, we try to reduce spurious correla-\ntions in ABSA using explanation. To achieve this,\nwe expect an explanation to have two functions: (i)\nmotivating ABSA models to infer the aspectâ€™s senti-\nment by understanding the context rather than some\nsurface words. (ii) providing additional knowledge\nas background information for better contextual\nunderstanding, especially for short texts; Recently,\nLLMs such as ChatGPT have exhibited incredible\ncontextual understanding and knowledge inference\non a wide range of NLP (Wei et al., 2022). It\ninspires us to leverage LLMs to generate an expla-\nnation for the aspectâ€™s sentiment in each training\nsample, which has not been explored in the litera-\nture. To this end, we design a prompt template to\ntrigger the understanding and inference ability of\nLLMs, which wraps the sentence X, an aspect a,\nand its sentiment y:\nIn the following sentence X, explain why\nthe sentiment expressed by aspect term\na is y. Limit to forty words. Copying\n1For sentences with multiple aspects, we treat other non-\ntargeted aspects as normal context tokens when focusing on\nthe target aspect. In other words, a sentence will be processed\nmultiple times, which is equal to the number of aspects it\ncontains.\nadjectives from the original sentence is\nnot allowed.\nWe can see that this prompt consists of three\ncomponents: task description, training sample, and\noutput limitation. They describe the task precisely\nand form a good output guide, which helps to en-\nhance the generation performance. As shown in\nthe example in Figure 2, LLM is tasked with gener-\nating a friendly explanation Ë†X for the aspect senti-\nment. This explanation not only explains why the\nsentiment occurs based on contextual semantics\n(i.e., \"user-friendliness\") but also includes some\nbackground knowledge (i.e., \"software\").\n3.4 Explanation Exploitation\nThe explanation generated by the LLM provides us\nwith a comprehensive view of the original text from\nthe perspective of contextual semantics and back-\nground knowledge. Furthermore, the explanation\ndoes not have high-frequency adjectives (e.g., fast)\ndue to the limitation in the prompt, which further\nprovides a sufficient condition to mitigate statisti-\ncal spurious correlations. Thus, we can use them\nto aid the learning of ABSA models and improve\nthe performance of the model. Here, we present\ntwo straightforward and model-agnostic methods\nto achieve this.\nAugmentation-based Method. In a sense, the\nexplanation can be considered as a paraphrase of\nthe original sentence, which has the same seman-\ntic meaning and label but a different description.\nThis different description not only facilitates the\nalleviation of statistical bias in the original sen-\ntences but also diversifies the expression of the\nsame sentiment. Thus, mixing the original train-\ning data {(Xi,ai,yi)}N\ni=1 with their explanations\n{( Ë†Xi,ai,yi)}N\ni=1 can allow for training a more ro-\nbust ABSA classifier:\nLcls = âˆ’1\n2N\n2Nâˆ‘\ni=1\nCE(y,P(Xâ€²\ni,a)) (1)\nwhere P(Xâ€²,a) is the predictive probability distri-\nbution of sentiment; Xâ€²can be either Xor Ë†X; CE\ndenotes the cross-entropy loss function.\nThe explanation is more effective than conven-\ntional data augmentation methods (Wei and Zou,\n2019) as it interprets the contextual semantics and\ncontains some knowledge.\n2933\nDistillation-based Method. Direct mixing can-\nnot align the original sentence with the correspond-\ning explanation, which results in trouble providing\ncustomized guided learning. To this end, we use a\nguidance strategy to encourage ABSA models to\nreduce spurious correlations in fitting each sample.\nThis strategy can be viewed as a knowledge distil-\nlation (Hinton et al., 2015), which aims to leverage\nthe teacher to guide the studentâ€™s training with the\nhelp of explanations.2 To achieve this guidance, we\nhere make the student model mimic two behaviors\nof the teacher one via the following two losses:\nLdis = 1\nN\nNâˆ‘\ni=1\nKL(gs(Xâ€²\ni,a),gt(Xâ€²\ni,a)) (2)\nLhid = 1\nN\nNâˆ‘\ni=1\nMSE(hs\nXâ€²\ni\n,ht\nXâ€²\ni\n) (3)\nwhere gs(Xâ€²\ni,a) and gt(Xâ€²\ni,a) (hs\nXâ€²\ni\nand ht\nXâ€²\ni\n) re-\nfer to the logits (hidden states), which come from\nstudent and teacher networks, respectively; KL\ndenotes the Kullback-Leibler divergence loss func-\ntion; MSE denotes the mean squared error loss\nfunction. By two losses, the explanation is utilized\nto facilitate the learning process of ABSA mod-\nels and mitigate overly concentrated on shortcut\nfeatures.\nTo yield better guidance, the teacher network\ntracks an exponential moving average (Tarvainen\nand Valpola, 2017) of the student network weights.\nAt the time step t, the parameters of the teacher Î¸\nare updated as follows:\nÎ¸t = Î»Â·Î¸tâˆ’1 + (1âˆ’Î») Â·Ï•t (4)\nwhere Ï•t represents all parameters in the student\nnetwork at time step t; Î»is a smoothing coefficient.\nWith this moving average, the teacherâ€™s output is\nmore reliable.\n3.5 Training and Testing\nFor the augmentation-based method, we train the\nparameters of the ABSA model directly by optimiz-\ning Lcls (Eq. 1). For the distillation-based method,\nwe update parameters of the student model by opti-\nmizing the sum of Lcls (Eq. 1), Ldis (Eq. 2), and\nLhid (Eq. 3). In the test phase, the sentence and\naspect are fed into the student network to predict\nthe label.\n2In this work, the teacher model and the student model\nhave the same framework.\n4 Experiment\n4.1 Datasets and Settings\nDatasets. We use five benchmark datasets to eval-\nuate the proposed methods: Lap14 and Rest14\nfrom Pontiki et al. (2014), Rest15 from Pontiki\net al. (2015), Rest16 from Pontiki et al. (2016),\nand MAMS from Jiang et al. (2019). All datasets\nonly involve three sentiment labels, positive, neu-\ntral, and negative. Each sample in these datasets\nis annotated with aspects and their corresponding\nsentiment polarities. Here, we adopt the official\ndata splits as done in the original papers. The basic\nstatistics are shown in Table 1.\nDataset #Pos #Neu #Neg Total\nLap14 train 994 464 870 2,328\ntest 341 169 128 638\nRest14 train 2,164 637 807 3,608\ntest 728 196 196 1,120\nRest15 train 912 36 256 1,204\ntest 326 34 182 542\nRest16 train 1,240 69 439 1,748\ntest 469 30 117 616\nMAMS\ntrain 3,380 5,042 2,764 11,186\ndev 403 604 325 1,332\ntest 400 607 329 1,336\nTable 1: The detailed statistics of datasets.\nSettings. If not otherwise specified, we use Chat-\nGPT and the pre-trained uncased BERT-base3 as\nLLM and encoder in the framework4, respectively.\nFor the classifier, the weight matrix is randomly\ninitialized by a uniform distribution. To avoid\nover-fitting, we apply the dropout (Srivastava et al.,\n2014) with a probability of 0.1. Besides, we also\nreplace the label words (i.e., positive, neutral, and\nnegative) in the explanation with [MASK] token.\nWe employ the AdamW optimizer to optimize pa-\nrameters. The epoch, batch size, learning rate, and\nsmoothing coefficient are set to 8, 24, 3e-5, and\n0.95, respectively. We limit the maximum length\nof the token sequence to 256.\nWe run the experiments five times with ran-\ndom initialization and report the averaged results.\nThe accuracy (Acc.) and macro-averaged F1 (F1)\nscores are used as the evaluation metric.\n4.2 Baselines\nTo evaluate the effectiveness and generalization\nof the proposed methods, we integrate them with\n3https://github.com/google-research/bert\n4The proposed framework only loads the LLM for infer-\nence without involving training.\n2934\nModels\nDatasets Lap14 Rest14 Rest15 Rest16 MAMS\nAcc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1\nLarge Language Models\nMOSS (zero-shot) 68.34 51.18 75.89 52.22 81.55 58.40 85.06 58.35 41.92 36.21\nMOSS (few-shot) 70.85 61.21 77.59 61.81 82.29 59.04 87.18 64.04 43.71 42.43\nChatGPT (zero-shot) 78.64 70.70 80.39 71.33 77.01 63.21 83.39 68.75 63.67 64.08\nChatGPT (few-shot) 78.90 75.61 83.74 77.08 82.80 71.31 84.83 69.90 60.18 60.57\nthe PLMs-based Models\nBERT 75.80 71.67 82.59 74.10 80.97 63.52 88.47 71.16 82.68 82.37\n+ augmentation 77.74 73.11 84.29 76.07 82.03 65.80 89.96 73.06 84.51 84.11\n+ distillation 78.68 75.19 84.66 76.18 82.63 65.97 90.12 73.69 83.68 83.38\nBERT+PT 77.59 73.14 84.16 76.62 82.83 65.81 91.73 73.93 83.48 83.10\n+ augmentation 77.90 74.66 85.71 78.37 83.50 67.48 92.75 75.48 83.86 83.73\n+ distillation 77.54 73.71 85.96 78.93 84.14 68.05 92.02 74.45 84.43 83.92\nthe Attention-based Models\nTNet 76.63 72.00 82.68 74.33 81.55 64.99 88.80 71.41 82.84 82.42\n+ augmentation 77.82 73.24 84.30 75.96 82.48 66.28 90.12 73.22 83.73 83.15\n+ distillation 78.04 73.32 84.75 76.68 82.97 66.17 90.30 73.81 83.98 83.42\nAEN 77.27 72.68 83.66 76.02 82.00 67.27 89.45 73.61 82.86 82.58\n+ augmentation 78.37 74.25 85.54 79.58 83.03 69.85 90.42 75.04 83.34 83.03\n+ distillation 78.40 73.96 84.20 77.20 82.47 67.84 91.05 75.45 83.19 82.70\nthe Graph-based Models\nRGAT 77.45 72.70 86.02 80.74 81.80 68.21 89.51 75.81 82.93 82.75\n+ augmentation 80.31 75.73 87.45 82.41 83.86 70.42 91.61 77.44 84.61 84.03\n+ distillation 78.11 74.06 86.30 81.12 82.55 69.29 90.47 77.05 83.78 83.18\nDualGCN 80.62 74.67 85.20 80.16 82.33 68.12 90.91 77.86 83.83 83.47\n+ augmentation 81.56 75.92 86.18 80.50 83.98 70.86 91.12 77.97 84.28 83.94\n+ distillation 81.22 75.43 86.37 80.63 82.69 69.43 91.45 78.12 84.68 84.23\nTable 2: Main experimental results (%) on five ABSA datasets. The zero-shot and few-shot indicate that LLM uses\n0 and 4 demonstrations in the in-context learning paradigm (Dong et al., 2022), respectively. All the results are the\naverage of five seeds. For each baseline, the best scores are in bold.\nsome representative ABSA models and compare\nperformance. These ABSA models could be cat-\negorized into three groups. (1) the PLMs-based\nmodels, which includes BERT (Devlin et al., 2019)\nand BERT-PT (Xu et al., 2019). (2) the attention-\nbased models, which includes TNet (Li et al.,\n2018b) and AEN (Song et al., 2019). (3) the graph-\nbased models, which includes RGAT (Wang et al.,\n2020) and DualGCN (Li et al., 2021).\nIn addition to the ABSA models mentioned\nabove, we also introduce two LLMs (MOSS5 and\nChatGPT6) as strong competitors.\n4.3 Main Results\nTable 2 shows the experimental results of ABSA\nmodels on five datasets. We can draw the following\nconclusions from this table:\n5The snapshot version and parameters of the MOSS are\nMOSS-moon-003-sft and 16B, respectively. Please refer to\nhttps://moss.fastnlp.top/\n6The snapshot version and parameters of the ChatGPT\nare text-davinci-003 and 175B, respectively. Please refer to\nhttps://openai.com/blog/chatgpt\nFirst, ABSA models equipped with our meth-\nods ( i.e., + augmentation and + distillation )\nachieve better performance than peer competi-\ntors on both accuracy and F1. Among them,\nthe bigger improvements in accuracy and F1 are\n2.88% (BERT+distillation on the Lap14) and\n3.56% (AEN+augmentation on the Rest14), respec-\ntively. These improvements show that (i) the pro-\nposed explanation can effectively mitigate spurious\ncorrelations, and (ii) our methods can be seamlessly\ncompensated to existing ABSA models.\nSecond, the graph-based ABSA models perform\nbetter than the attention-based ones. For exam-\nple, DualGCN improves performance by 3.99%\nin accuracy and 3.67% in F1 over TNet on the\nLap14. Although the graph-based models have ob-\ntained satisfactory results, we can observe a boost\nof 0.28âˆ¼2.86% in accuracy and 0.38 âˆ¼3.03% in\nF1 when integrated with our methods. It indicates\nthat while exploiting the syntactic knowledge con-\nnecting aspects and opinion words to improve per-\nformance, they may still model shortcut features\n2935\nModels\nDatasets Lap14 Rest14 Rest15 Rest16 MAMS\nAcc. F1 Acc. F1 Acc. F1 Acc. F1 Acc. F1\nBERT 75.80 71.67 82.59 74.10 80.97 63.52 88.47 71.16 82.68 82.37\n+ SW AP 77.03 72.33 83.24 75.15 81.32 64.68 89.58 72.42 82.76 83.00\n+ ADD 77.21 72.46 83.80 75.71 81.55 64.81 89.10 72.59 83.31 82.85\n+ DELETE 76.84 72.56 82.95 73.22 80.63 63.02 89.26 71.57 83.03 82.88\n+ MASK 76.65 72.64 83.57 74.70 79.15 60.50 89.12 71.58 83.06 82.80\n+ TRANSLATION 77.27 72.80 84.08 74.90 81.52 65.18 89.49 72.75 82.91 83.07\n+ augmentation 77.74 73.11 84.29 76.07 82.03 65.80 89.96 73.06 84.51 84.11\n+ distillation 78.68 75.19 84.66 76.18 82.63 65.97 90.12 73.69 83.68 83.38\nTable 3: Comparison of our methods with five popular data augmentation baselines on the ABSA task. SWAP:\nrandomly swap two tokens; ADD: randomly insert some sampled tokens; DELETE: randomly remove some tokens;\nMASK: first replace some tokens with [MASK] token and then use BERT to complete the mask language task\n(Devlin et al., 2019); TRANSLATION (Sennrich et al., 2016): first translate the text into Chinese and then translate\nthe output into English. The best scores are in bold.\nbecause of a shallow understanding of some words.\nThird, LLMs can yield impressive results using\nfew demonstrations. Compared with PLMs, they\nare scaling up in depth and width. It causes them to\nbecome increasingly computationally and storage-\nintensive, making deployment difficult. This is why\nwe leverage explanations from LLMs to reduce the\nspurious correlations in ABSA rather than using\nthem directly to solve it.\nFourth, we find that the augmentation-based\nmethod and distillation-based one could not tell\nwho wins and who loses. Each has its own ad-\nvantages and merits. For example, although the\ndistillation-based method yields higher results than\nthe augmentation-based method in some cases, the\nlatter is superior with respect to efficiency. In ad-\ndition, the augmentation-based method is more ap-\nplicable in different ABSA models. Therefore, we\nwill subsequently focus more on the augmentation-\nbased method for future research.\nLap14 Rest14\nBERT 14.8 14.5\n+ augmentation 12.7 11.6\n+ distillation 13.0 11.4\nAEN 16.3 16.4\n+ augmentation 15.2 14.8\n+ distillation 15.3 15.0\nTable 4: The proportion (%) of spurious correlations\npresent in the dataset. The lower the better.\n5 Discussion\nPercentage of Spurious Correlations in the\nDataset. In this work, spurious correlation (Wang\net al., 2022b) refers to the dependence of the model\non certain words in the input text without a deeper\nunderstanding of the contextual semantics. A ques-\ntion naturally arises how much of the correlation\nactually is in used datasets? To answer this ques-\ntion, we conduct a simple probe experiment on the\nAspect Robustness Test Set (ARTS) (Xing et al.,\n2020). ARTS enrich the initial test sets from Lap14\nand Rest14 by employing three adversarial strate-\ngies7. Here, if a model predicts the same sentiment\nlabels for an original sample as well as its adver-\nsarial samples (their true labels are different), we\nwill assume that there is a spurious correlation be-\ntween certain contextual words and the predicted\nlabel for this original sample. In other words, the\npredicted label does not change with the contextual\nsemantics because the model only focuses on cer-\ntain words. Based on this assumption, we count the\npercentage of original samples in the test set that\ncontain spurious correlations.8 According to Table\n4, we can see that spurious correlations do exist\nin the Lap14 and Rest14 datasets. Moreover, we\ncan observe that the proposed methods reduce the\npercentage of original samples containing spurious\ncorrelations. This may suggest that the generated\nexplanations can alleviate the spurious correlations\nproblem in the ABSA task.\nComparison with Data Augmentation Baselines.\nThis work aims to exploit the explanation from\nLLMs to reduce spurious correlations, which could\nbe viewed as an augmented instance of the original\nsentence. To evaluate its effectiveness, we compare\nthe proposed methods with five data augmentation\n7They are (1) reversing the original sentiment of the tar-\ngeted aspect; (2) reversing the sentiment of the non-targeted\naspects; and (3) generating more non-targeted aspects with\nopposite sentiment polarities from the targeted aspect.\n8It is worth reminding that this percentage is not the actual\npercentage of spurious correlations in the dataset, which is\nonly an estimate under this assumption.\n2936\nModels\nDatasets L â‡’ R R â‡’ L\nAcc. F1 Acc. F1\nBERT 77.02 63.83 73.82 68.74\n+ augmentation 78.93 66.33 76.33 72.02\n+ distillation 79.11 64.93 75.55 70.99\nBERT+PT 78.82 70.74 74.55 68.62\n+ augmentation 81.25 71.42 75.55 69.91\n+ distillation 82.68 75.37 73.20 66.53\nTable 5: The generalization results of ABSA models.\nL â‡’R (or R â‡’L) refer to that the model is trained\non Lap14 (or Rest14) training data and then tested on\nRest14 (or Lap14) test data. The best scores for each\nbaseline are in bold.\nbaselines.9 Table 3 reports the experimental results.\nIt can be seen that our methods perform better than\nall baselines, achieving the biggest improvements\nof 3.48% and 5.47% in accuracy and F1, respec-\ntively. This shows that the explanation from LLMs\nis more effective because of including not only a\ncontextual understanding of sentiments but also\nexternal knowledge. Besides, we find that these\naugmentation baselines often consistently improve\nthe performance of BERT, showing that modifying\nthe original text may bring gains, despite the noise.\nGeneralization Analysis. We evaluate the pro-\nposed methods in the cross-domain scenario to\ncheck their effectiveness on generalizability. The\nexperimental results are presented in Table 5. We\ncan observe that: (1) Our methods significantly\nenhance the generalization ability of the peer base-\nlines by a substantial margin. We attribute it to the\nexplanations of aspect sentiment that can reduce\nthe spurious correlations in ABSA. (2) Overall,\nthe augmentation method is more effective than\nthe distillation one. A possible reason for this is\nthat explanations containing external knowledge\nare directly involved in the training, allowing the\nlearning of better transfer features.\nEffectiveness in Low-Resource Scenario. Here,\nwe carry out an experiment to observe the perfor-\nmance improvements achieved by our proposed\nmethods in low-resource settings. To this end, we\nvary the percentage of training data from 10% to\n100% in increments of 10% and depict results in\nFigure 3. We can see that: (1) Overall, being armed\nwith our methods can improve the performance of\nBERT. It shows that introducing an explanation for\nsentiment is useful in low-resource scenarios. (2)\nThe performance gradually improves as the per-\n9We add augmented versions directly to the existing set.\nThus, the training set size will be doubled after this operation.\n58\n63\n68\n73\n78\n10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\nBERT\n    +augmentation\n    +distillation\npercentage of training data\nF1 (%)\nlap14\n(a) On Lap14 dataset.\n50\n57\n64\n71\n78\n10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\nBERT\n    +augmentation\n    +distillation\npercentage of training data\nF1 (%)\nrest14\n(b) On Rest14 dataset.\nFigure 3: Experiments in low-resource scenarios. We\nlimit the percentage of training data when fine-tuning.\ncentage increases before the training size surpasses\n50%, indicating that the more training data, the\nbetter the model is trained. Nevertheless, upon\nsurpassing this point, the performance fluctuates\nmoderately.\n58\n65\n72\n79\n[0,20) [20,40) [40,60)\nBERT\n    +augmentation\n    +distillation\ntext length\nF1 (%)\nlap14\n(a) On Lap14 dataset.\n55\n62\n69\n76\n[0,20) [20,40) [40,60)\nBERT\n    +augmentation\n    +distillation\ntext length\nF1 (%)\nrest14 (b) On Rest14 dataset.\nFigure 4: Length-wise performance comparison. Here,\n[20, 40) indicates that the token number of the sample\nsatisfies the condition of greater than or equal to 20 and\nless than 40. The other meanings are similar.\nLength-wise Performance Analysis. Spurious\ncorrelations are prone to occur when predicting the\nshort text as the model tends to resort to the learned\nstatistical bias facing a low-informative context.\nHere, we test length-wise performance to reveal\nthe noticeable advantages of the proposed methods\non short texts. Figure 4 provides the test results.\nWe can see that the proposed methods significantly\nimprove the performance of BERT, especially on\nshort texts. It shows that the explanation provided\nby LLMs for the training samples motivates the\nABSA model to be trained effectively, thus allow-\ning for a better contextual understanding of short\ntexts at testing.\n2937\nThe Appendix has more discussion and anal-\nysis, i.e., Quality of the Automatically-Generated\nExplanations, Effect of Different Prompt Templates\non Performance, and Error Analysis.\n6 Conclusion\nIn this paper, we introduce an effective two-step\nframework to mitigate spurious correlations in\nABSA. First, we formulate a prompt template to in-\nduce LLMs to generate an appropriate explanation\nthat states the sentiment cause. Subsequently, we\npropose two straightforward methods that utilize\nthe generated explanation to prevent the assimila-\ntion of spurious correlations. Our comprehensive\nexperiments on five ABSA datasets show that base-\nlines armed with our methods outperform peers in\nprediction performance and generalization.\nLimitations\nIn this section, we list two limitations to understand\nthis work more comprehensively:\n1. The prompt template designed in this work\nconsists of three components: the task descrip-\ntion, the training sample, and the output limi-\ntation. Generally speaking, a prompt-rich tem-\nplate allows LLMs to generate more helpful\nexplanations about sentiment and richer rele-\nvant external knowledge. In this work, we did\nnot design a prompt-rich template because this\nmanual design process is time-consuming and\ncumbersome. In addition, designing a com-\nplex and information-rich prompt template is\nnot the research focus of this work.\n2. We leverage explanations to reduce spuri-\nous correlations in the ABSA task. In this\nwork, we generate an explanation for the sen-\ntiment label in each training sample, which\nsubsequently participates in the model train-\ning process. Although spurious correlations\nare caused by statistical bias during training,\nnot all training samples bring bias interference\nto the model. Therefore, the participation of\nall explanations in model training is an exten-\nsive operation, which somehow results in a\nwaste of training resources. How to identify\nwhether a training sample potentially brings\nspurious correlation interference can be a di-\nrection for subsequent research.\nAcknowledgements\nThis work was partially supported by the National\nNatural Science Foundation of China (62006062,\n62176076), Natural Science Foundation of Guang-\ndong 2023A1515012922, Shenzhen Foundational\nResearch Funding JCYJ20210324115614039 and\nJCYJ20220818102415032, Guangdong Provincial\nKey Laboratory of Novel Security Intelligence\nTechnologies 2022B1212010005.\nReferences\nNing Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie\nLu, and Ben He. 2023. Chatgpt is a knowledgeable\nbut inexperienced solver: An investigation of com-\nmonsense problem in large language models. arXiv\npreprint arXiv:2303.16421.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. NeurIPS, 33:1877â€“1901.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In NAACL, pages 4171â€“4186.\nQingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiy-\nong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and\nZhifang Sui. 2022. A survey for in-context learning.\narXiv preprint arXiv:2301.00234.\nFeifan Fan, Yansong Feng, and Dongyan Zhao. 2018.\nMulti-grained attention network for aspect-level sen-\ntiment classification. In EMNLP, pages 3433â€“3442.\nShuqin Gu, Lipeng Zhang, Yuexian Hou, and Yin Song.\n2018. A position-aware bidirectional attention net-\nwork for aspect-level sentiment analysis. In COL-\nING, pages 774â€“784.\nRuidan He, Wee Sun Lee, Hwee Tou Ng, and Daniel\nDahlmeier. 2018. Effective attention modeling for\naspect-level sentiment classification. In COLING,\npages 1121â€“1131.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015.\nDistilling the knowledge in a neural network. arXiv\npreprint arXiv:1503.02531.\nQingnan Jiang, Lei Chen, Ruifeng Xu, Xiang Ao, and\nMin Yang. 2019. A challenge dataset and effec-\ntive models for aspect-based sentiment analysis. In\nEMNLP, pages 6280â€“6285.\nLishuang Li, Yang Liu, and AnQiao Zhou. 2018a. Hier-\narchical attention-based position-aware network for\naspect-level sentiment analysis. In COLING, pages\n181â€“189.\n2938\nRuifan Li, Hao Chen, Fangxiang Feng, Zhanyu Ma,\nXiaojie Wang, and Eduard Hovy. 2021. Dual graph\nconvolutional networks for aspect-based sentiment\nanalysis. In ACL, pages 6319â€“6329.\nXiang Lorraine Li, Adhiguna Kuncoro, Jordan Hoff-\nmann, Cyprien de Masson dâ€™Autume, Phil Blunsom,\nand Aida Nematzadeh. 2022. A systematic investiga-\ntion of commonsense knowledge in large language\nmodels. In EMNLP, pages 11838â€“11855.\nXin Li, Lidong Bing, Wai Lam, and Bei Shi. 2018b.\nTransformation networks for target-oriented senti-\nment classification. In ACL, pages 946â€“956.\nXin Li, Lidong Bing, Piji Li, Wai Lam, and Zhimou\nYang. 2018c. Aspect term extraction with history at-\ntention and selective transformation. In IJCAI, pages\n4194â€“4200.\nXinlong Li, Xingyu Fu, Guangluan Xu, Yang Yang,\nJiuniu Wang, Li Jin, Qing Liu, and Tianyuan Xiang.\n2020. Enhancing bert representation with context-\naware embedding for aspect-based sentiment analysis.\nIEEE Access, 8:46868â€“46876.\nBin Liang, Hang Su, Lin Gui, Erik Cambria, and\nRuifeng Xu. 2022. Aspect-based sentiment anal-\nysis via affective knowledge enhanced graph con-\nvolutional networks. Knowledge-Based Systems ,\n235:107643.\nNelson F Liu, Matt Gardner, Yonatan Belinkov,\nMatthew E Peters, and Noah A Smith. 2019. Lin-\nguistic knowledge and transferability of contextual\nrepresentations. In NAACL, pages 1073â€“1094.\nDehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng\nWang. 2017. Interactive attention networks for\naspect-level sentiment classification. In IJCAI, pages\n4068â€“4074.\nYukun Ma, Haiyun Peng, Tahir Khan, Erik Cambria,\nand Amir Hussain. 2018. Sentic lstm: A hybrid\nnetwork for targeted aspect-based sentiment analysis.\nCognitive Computation, 10:639â€“650.\nAmbreen Nazir, Yuan Rao, Lianwei Wu, and Ling Sun.\n2022. Iaf-lg: An interactive attention fusion network\nwith local and global perspective for aspect-based\nsentiment analysis. IEEE Transactions on Affective\nComputing, 13(4):1730â€“1742.\nSapna Negi and Paul Buitelaar. 2014. Insight galway:\nSyntactic and lexical features for aspect based senti-\nment analysis. In SemEval, pages 346â€“350.\nMinh Hieu Phan and Philip O Ogunbona. 2020. Mod-\nelling context and syntactical features for aspect-\nbased sentiment analysis. In ACL, pages 3211â€“3220.\nMaria Pontiki, Dimitrios Galanis, Harris Papageorgiou,\nIon Androutsopoulos, and et al. 2016. Semeval-2016\ntask 5: Aspect based sentiment analysis. In SemEval,\npages 19â€“30.\nMaria Pontiki, Dimitrios Galanis, Harris Papageorgiou,\nSuresh Manandhar, and Ion Androutsopoulos. 2015.\nSemeval-2015 task 12: Aspect based sentiment anal-\nysis. In SemEval, pages 486â€“495.\nMaria Pontiki, Dimitrios Galanis, John Pavlopoulos,\nHarris Papageorgiou, Ion Androutsopoulos, and\nSuresh Manandhar. 2014. Semeval-2014 task 4: As-\npect based sentiment analysis. In SemEval, pages\n27â€“35.\nSebastian Ruder, Parsa Ghaffari, and John G Breslin.\n2016. A hierarchical model of reviews for aspect-\nbased sentiment analysis. In EMNLP, pages 999â€“\n1005.\nShiori Sagawa, Aditi Raghunathan, Pang Wei Koh, and\nPercy Liang. 2020. An investigation of why overpa-\nrameterization exacerbates spurious correlations. In\nICML, pages 8346â€“8356. PMLR.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Improving neural machine translation models\nwith monolingual data. In ACL, pages 86â€“96.\nYouwei Song, Jiahai Wang, Tao Jiang, Zhiyue Liu, and\nYanghui Rao. 2019. Attentional encoder network\nfor targeted sentiment classification. arXiv preprint\narXiv:1902.09314.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,\nIlya Sutskever, and Ruslan Salakhutdinov. 2014.\nDropout: A simple way to prevent neural networks\nfrom overfitting. The journal of machine learning\nresearch, 15(1):1929â€“1958.\nKai Sun, Richong Zhang, Samuel Mensah, Yongyi Mao,\nand Xudong Liu. 2019. Aspect-level sentiment analy-\nsis via convolution over dependency tree. In EMNLP,\npages 5679â€“5688.\nXingwei Tan, Yi Cai, and Changxi Zhu. 2019. Recog-\nnizing conflict opinions in aspect-level sentiment clas-\nsification with dual attention networks. In EMNLP,\npages 3426â€“3431.\nDuyu Tang, Bing Qin, Xiaocheng Feng, and Ting Liu.\n2016a. Effective lstms for target-dependent senti-\nment classification. In COLING, pages 3298â€“3307.\nDuyu Tang, Bing Qin, and Ting Liu. 2016b. Aspect\nlevel sentiment classification with deep memory net-\nwork. In EMNLP, pages 214â€“224.\nAntti Tarvainen and Harri Valpola. 2017. Mean teachers\nare better role models: Weight-averaged consistency\ntargets improve semi-supervised deep learning re-\nsults. NeurIPS, 30.\nYuanhe Tian, Guimin Chen, and Yan Song. 2021.\nAspect-based sentiment analysis with type-aware\ngraph convolutional networks and layer ensemble.\nIn NAACL, pages 2910â€“2922.\n2939\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Åukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. NeurIPS, 30.\nBing Wang, Liang Ding, Qihuang Zhong, Ximing\nLi, and Dacheng Tao. 2022a. A contrastive cross-\nchannel data augmentation framework for aspect-\nbased sentiment analysis. In COLING, pages 6691â€“\n6704.\nKai Wang, Weizhou Shen, Yunyi Yang, Xiaojun Quan,\nand Rui Wang. 2020. Relational graph attention net-\nwork for aspect-based sentiment analysis. In ACL,\npages 3229â€“3238.\nTianlu Wang, Rohit Sridhar, Diyi Yang, and Xuezhi\nWang. 2022b. Identifying and mitigating spurious\ncorrelations for improving robustness in nlp models.\nIn Findings of NAACL, pages 1719â€“1729.\nZhao Wang and Aron Culotta. 2020. Identifying spu-\nrious correlations for robust text classification. In\nFindings of EMNLP, pages 3431â€“3440.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed H Chi, Quoc V Le, Denny Zhou,\net al. 2022. Chain-of-thought prompting elicits rea-\nsoning in large language models. In NeurIPS.\nJason Wei and Kai Zou. 2019. Eda: Easy data augmen-\ntation techniques for boosting performance on text\nclassification tasks. In EMNLP, pages 6382â€“6388.\nXiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang,\nQi Zhang, and Xuan-Jing Huang. 2020. Tasty burg-\ners, soggy fries: Probing aspect robustness in aspect-\nbased sentiment analysis. In EMNLP, pages 3594â€“\n3605.\nHu Xu, Bing Liu, Lei Shu, and S Yu Philip. 2019. Bert\npost-training for review reading comprehension and\naspect-based sentiment analysis. In NAACL, pages\n2324â€“2335.\nWei Xue and Tao Li. 2018. Aspect based sentiment\nanalysis with gated convolutional networks. In ACL,\npages 2514â€“2523.\nHang Yan, Junqi Dai, Tuo Ji, Xipeng Qiu, and Zheng\nZhang. 2021. A unified generative framework for\naspect-based sentiment analysis. In ACL, pages 2416â€“\n2429.\nZheng Zhang, Zili Zhou, and Yanna Wang. 2022.\nSsegcn: Syntactic and semantic enhanced graph con-\nvolutional network for aspect-based sentiment analy-\nsis. In NAACL, pages 4916â€“4925.\n7 Appendix\nQuality of the Automatically-Generated Expla-\nnations. Large language models may generate\nless accurate or even irrelevant explanations for the\nsentiment of the aspect. Such explanations may\nhave negative effects if they exist and are involved\nin training. In this work, we only randomly selected\nnearly fifty explanations for hand-checking. We\nfind that the quality of the generated explanations\nis accurate and comprehensive (see examples in\nTable 6). In addition, We observe that these expla-\nnations are richly expressive (e.g., \"not reasonable\nor affordable\").\nEffect of Different Prompt Templates on Perfor-\nmance. In this work, the prompt template is de-\nsigned based on two points: (1) including a task de-\nscription (i.e., \"explain the sentiment expressed by\naspect term\"), which is used to trigger the LLMâ€™s\nability to understand the task; (2) including the\noutput limitation (i.e., \"Limit to forty words. Copy-\ning adjectives from the original sentence is not\nallowed.\"), which is used as an output guide and\nprevents LLM from rephrasing the sentiment ex-\npression. Here, to explore the effect of different\nprompt templates on performance, we try other\nwell-designed templates and perform comparison\nexperiments. These prompt templates are described\nin detail below:\nâ€¢ Prompt 1 (used in this paper): In the follow-\ning sentence X, explain why the sentiment\nexpressed by aspect term ais y. Limit to forty\nwords. Copying adjectives from the original\nsentence is not allowed.\nâ€¢ Prompt 2: In the following sentence X, ex-\nplain why the sentiment expressed by aspect\nterm ais y.\nâ€¢ Prompt 3: In the following sentence X, the\nsentiment expressed by aspect term a is y.\nBased on this prompt, explain its reasoning.\nLimit to forty words. Copying adjectives from\nthe original sentence is not allowed.\nHere, for simplicity, we choose BERT as the\nbaseline model and BERT+augmentation as our\nmethod. Table 8 presents the experimental results.\nFrom this table, we can find that although the tem-\nplate used in this paper yields the best results, there\nis not much difference between the scores of the\ndifferent templates (see Prompt 1 vs. Prompt 3).\nMoreover, we observe that imposing an output con-\nstraint in the template favors the performance (see\nPrompt 1 vs. Prompt 2).\nError Analysis. An error analysis can provide\nreaders with a deeper understanding of whether our\n2940\nDataset Sample Aspect Sentiment Explanation\nLap14\nThe machine is slow to boot up and occa-\nsionally crashes completely.\nboot up negative The phrase \"boot up\" implies that the ma-\nchine is taking a long time to start, which\nis a negative experience.\nRest14 Even though its good seafood, the prices\nare too high.\nprices negative The prices are too high, which implies that\nthey are not reasonable or affordable.\nMAMS\nUSC has a cold smoker and smoked the\navocado in order to make the dish more\ncomplex.\ndish negative The dish is negative because the avocado\nwas smoked, which could make the dish\ntaste unpleasant or unappetizing.\nTable 6: Examples of generating explanations. We can see that the explanation elucidates the reason ( italicized\ncontent) for the sentiment of the aspect, grounded in contextual semantics.\nSample BERT BERT+augmentation\nThe [staff ]negative should be a bit more friendly. positive( âœ—) negative( âœ“)\nI needed a laptop with big[storage]neutral, a nice screen and fast so I can Photoshop\nwithout any problem.\npositive(âœ—) positive( âœ—)\nTable 7: A simple error analysis. Aspect terms are marked in parentheses, and the subscript indicates the corre-\nsponding sentiment polarity.\nModels\nDatasets Lap14 Rest14\nAcc. F1 Acc. F1\nBERT 75.80 71.67 82.59 74.10\nBERT + augmentation\n+ Prompt 1 77.74 73.11 84.29 76.07\n+ Prompt 2 77.46 72.60 83.78 75.60\n+ Prompt 3 77.50 72.94 84.08 75.72\nTable 8: Performance comparison of\nBERT+augmentation using different prompts.\nThe best scores are in bold.\nmethods have successfully reduced errors arising\nfrom statistical spurious correlations. Thus, we\npresent a simple error analysis in Table 7. Taking\nthe first sample as an example, BERT makes an\nincorrect prediction possibly because of focusing\non the word \"friendly\" only. We suspect this is\nbecause, in the training samples which contain the\nword \"friendly\", 94.6% of aspect sentiments are\n\"positive\", i.e., statistically spurious correlation.\nMoreover, we find that the proposed method also\nmakes a few wrong predictions, especially when\nthe true label is neutral, as shown in the second\nsample. The potential reason may be that when\nthe label is neutral, the language model generates\nexplanations with slight sentiments due to its own\nbias, which would mislead the model.\n2941"
}