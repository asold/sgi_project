{
  "title": "Large Language Models for Code: Security Hardening and Adversarial Testing",
  "url": "https://openalex.org/W4320560161",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2519601088",
      "name": "He, Jingxuan",
      "affiliations": [
        "ETH Zurich"
      ]
    },
    {
      "id": "https://openalex.org/A3160990653",
      "name": "Vechev, Martin",
      "affiliations": [
        "ETH Zurich"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6600438464",
    "https://openalex.org/W4287644588",
    "https://openalex.org/W6785515443",
    "https://openalex.org/W3183469243",
    "https://openalex.org/W3166095789",
    "https://openalex.org/W6600050674",
    "https://openalex.org/W3156480510",
    "https://openalex.org/W4384345694",
    "https://openalex.org/W2515236103",
    "https://openalex.org/W3091588759",
    "https://openalex.org/W2807730630",
    "https://openalex.org/W3173591235",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W4205635927",
    "https://openalex.org/W6600175266",
    "https://openalex.org/W2885030880",
    "https://openalex.org/W3033777149",
    "https://openalex.org/W6602670149",
    "https://openalex.org/W2979357014",
    "https://openalex.org/W3195703954",
    "https://openalex.org/W4308643013",
    "https://openalex.org/W4288057765",
    "https://openalex.org/W6629009121",
    "https://openalex.org/W4308627645",
    "https://openalex.org/W2130758759",
    "https://openalex.org/W3210860486",
    "https://openalex.org/W4225108562",
    "https://openalex.org/W4205733352",
    "https://openalex.org/W4281763794",
    "https://openalex.org/W3112486745",
    "https://openalex.org/W4221144473",
    "https://openalex.org/W4284664028",
    "https://openalex.org/W3166846774",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4315706637",
    "https://openalex.org/W2973049837",
    "https://openalex.org/W4226485558",
    "https://openalex.org/W4300989059",
    "https://openalex.org/W3085190015",
    "https://openalex.org/W4391307510",
    "https://openalex.org/W4385187279",
    "https://openalex.org/W4287024925",
    "https://openalex.org/W3207263623",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4297795751",
    "https://openalex.org/W4224321081",
    "https://openalex.org/W4292956935",
    "https://openalex.org/W4376167329",
    "https://openalex.org/W3174770825",
    "https://openalex.org/W4311887664",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3174784402",
    "https://openalex.org/W2997195635",
    "https://openalex.org/W4224060952",
    "https://openalex.org/W3101228802",
    "https://openalex.org/W4310638782",
    "https://openalex.org/W3155981360",
    "https://openalex.org/W4288804596",
    "https://openalex.org/W3198685994",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W2972135640",
    "https://openalex.org/W4385245566"
  ],
  "abstract": "Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN closely matches the original LMs in functional correctness.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8630725145339966
    },
    {
      "name": "Correctness",
      "score": 0.6948349475860596
    },
    {
      "name": "Adversarial system",
      "score": 0.6264618635177612
    },
    {
      "name": "Code (set theory)",
      "score": 0.5707406997680664
    },
    {
      "name": "Parametric statistics",
      "score": 0.5201171636581421
    },
    {
      "name": "Computer engineering",
      "score": 0.4671556353569031
    },
    {
      "name": "Theoretical computer science",
      "score": 0.36175838112831116
    },
    {
      "name": "Algorithm",
      "score": 0.2680578827857971
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2519580125808716
    },
    {
      "name": "Programming language",
      "score": 0.22939103841781616
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Statistics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I35440088",
      "name": "ETH Zurich",
      "country": "CH"
    }
  ]
}