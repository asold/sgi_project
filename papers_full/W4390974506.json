{
  "title": "Forward Learning of Large Language Models by Consumer Devices",
  "url": "https://openalex.org/W4390974506",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2477697885",
      "name": "Danilo Pietro Pau",
      "affiliations": [
        "STMicroelectronics (Italy)"
      ]
    },
    {
      "id": "https://openalex.org/A4382249549",
      "name": "Fabrizio Maria Aymone",
      "affiliations": [
        "STMicroelectronics (Italy)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2985884876",
    "https://openalex.org/W2119144962",
    "https://openalex.org/W2962851801",
    "https://openalex.org/W2982479999",
    "https://openalex.org/W4220851938",
    "https://openalex.org/W4382236987",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W1498436455",
    "https://openalex.org/W4385325027",
    "https://openalex.org/W2555428947",
    "https://openalex.org/W6685158001",
    "https://openalex.org/W6683738474",
    "https://openalex.org/W2963563735",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W4322775118",
    "https://openalex.org/W4402671659",
    "https://openalex.org/W3007007518",
    "https://openalex.org/W3034457371",
    "https://openalex.org/W3105966348",
    "https://openalex.org/W4387607788",
    "https://openalex.org/W4312438982",
    "https://openalex.org/W6785440099",
    "https://openalex.org/W6838539104",
    "https://openalex.org/W4312868944",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W2003357516",
    "https://openalex.org/W3016391357",
    "https://openalex.org/W2552737632",
    "https://openalex.org/W2507556850",
    "https://openalex.org/W2128420087",
    "https://openalex.org/W2516591743",
    "https://openalex.org/W2592867566",
    "https://openalex.org/W2949405272",
    "https://openalex.org/W3106061119",
    "https://openalex.org/W6859666387",
    "https://openalex.org/W3014285442",
    "https://openalex.org/W4380881154",
    "https://openalex.org/W3113151582",
    "https://openalex.org/W2952230511",
    "https://openalex.org/W4390051181",
    "https://openalex.org/W3035204084",
    "https://openalex.org/W4297797035",
    "https://openalex.org/W4283766928"
  ],
  "abstract": "Large Language Models achieve state of art performances on a broad variety of Natural Language Processing tasks. In the pervasive IoT era, their deployment on edge devices is more compelling than ever. However, their gigantic model footprint has hindered on-device learning applications which enable AI models to continuously learn and adapt to changes over time. Back-propagation, in use by the majority of deep learning frameworks, is computationally intensive and requires storing intermediate activations into memory to cope with the model’s weights update. Recently, “Forward-only algorithms” have been proposed since they are biologically plausible alternatives. By applying more “forward” passes, this class of algorithms can achieve memory reductions with respect to more naive forward-only approaches and by removing the need to store intermediate activations. This comes at the expense of increased computational complexity. This paper considered three Large Language Model: DistilBERT, GPT-3 Small and AlexaTM. It investigated quantitatively any improvements about memory usage and computational complexity brought by known approaches named PEPITA and MEMPEPITA with respect to backpropagation. For low number of tokens in context, and depending on the model, PEPITA increases marginally or reduces substantially arithmetic operations. On the other hand, for large number of tokens in context, PEPITA reduces computational complexity by 30% to 50%. MEMPEPITA increases PEPITA’s complexity by one third. About memory, PEPITA and backpropagation, require a comparable amount of memory to store activations, while MEMPEPITA reduces it by 50% to 94% with the benefits being more evident for architectures with a long sequence of blocks. In various real case scenarios, MEMPEPITA’s memory reduction was essential for meeting the tight memory requirements of 128 MB equipped edge consumer devices, which are commonly available as smartphone and industrial application multi processors.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8202877044677734
    },
    {
      "name": "Memory footprint",
      "score": 0.7099637985229492
    },
    {
      "name": "Context (archaeology)",
      "score": 0.634966254234314
    },
    {
      "name": "Backpropagation",
      "score": 0.5279202461242676
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49594172835350037
    },
    {
      "name": "Computational complexity theory",
      "score": 0.48324593901634216
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.4701530933380127
    },
    {
      "name": "Language model",
      "score": 0.45445016026496887
    },
    {
      "name": "High memory",
      "score": 0.4430282711982727
    },
    {
      "name": "Sequence (biology)",
      "score": 0.4364651143550873
    },
    {
      "name": "Deep learning",
      "score": 0.4325471818447113
    },
    {
      "name": "Artificial neural network",
      "score": 0.4067363142967224
    },
    {
      "name": "Machine learning",
      "score": 0.35008758306503296
    },
    {
      "name": "Parallel computing",
      "score": 0.18810570240020752
    },
    {
      "name": "Algorithm",
      "score": 0.17372459173202515
    },
    {
      "name": "Programming language",
      "score": 0.0931042730808258
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210154781",
      "name": "STMicroelectronics (Italy)",
      "country": "IT"
    }
  ],
  "cited_by": 5
}