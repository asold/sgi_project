{
    "title": "Prompt Engineering: a methodology for optimizing interactions with AI-Language Models in the field of engineering",
    "url": "https://openalex.org/W4388654530",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2147313178",
            "name": "Juan David Vel√°squez Henao",
            "affiliations": [
                "Universidad Nacional de Colombia"
            ]
        },
        {
            "id": "https://openalex.org/A2110638287",
            "name": "Carlos Jaime Franco Cardona",
            "affiliations": [
                "Universidad Nacional de Colombia"
            ]
        },
        {
            "id": "https://openalex.org/A2034178785",
            "name": "Lorena Cadavid Higuita",
            "affiliations": [
                "Universidad Nacional de Colombia"
            ]
        },
        {
            "id": "https://openalex.org/A2147313178",
            "name": "Juan David Vel√°squez Henao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2110638287",
            "name": "Carlos Jaime Franco Cardona",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2034178785",
            "name": "Lorena Cadavid Higuita",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4323848232",
        "https://openalex.org/W4321167341",
        "https://openalex.org/W4317910584",
        "https://openalex.org/W4313678819",
        "https://openalex.org/W4385730880",
        "https://openalex.org/W3185341429",
        "https://openalex.org/W4381888391",
        "https://openalex.org/W4379598302",
        "https://openalex.org/W4379507314",
        "https://openalex.org/W4322757547",
        "https://openalex.org/W4322761615",
        "https://openalex.org/W3203321135",
        "https://openalex.org/W4380150545",
        "https://openalex.org/W4328104933",
        "https://openalex.org/W4383817745",
        "https://openalex.org/W4366692100",
        "https://openalex.org/W4378628090",
        "https://openalex.org/W4366980161",
        "https://openalex.org/W4360620450",
        "https://openalex.org/W4324373918",
        "https://openalex.org/W4388654530",
        "https://openalex.org/W4323536358",
        "https://openalex.org/W4381515751",
        "https://openalex.org/W4322617812",
        "https://openalex.org/W4382632406",
        "https://openalex.org/W4381687070",
        "https://openalex.org/W4320486331",
        "https://openalex.org/W4321460183",
        "https://openalex.org/W4362585490",
        "https://openalex.org/W4379376212",
        "https://openalex.org/W4372060667",
        "https://openalex.org/W4366277658",
        "https://openalex.org/W4322620171",
        "https://openalex.org/W4360980141",
        "https://openalex.org/W4366249120",
        "https://openalex.org/W4386322180",
        "https://openalex.org/W4310230601",
        "https://openalex.org/W6815748177",
        "https://openalex.org/W4386424132",
        "https://openalex.org/W4385251138",
        "https://openalex.org/W2991138092",
        "https://openalex.org/W2072803231",
        "https://openalex.org/W4229658977"
    ],
    "abstract": "ChatGPT is a versatile conversational Artificial Intelligence model that responds to user input prompts, with applications in academia and various sectors. However, crafting effective prompts can be challenging, leading to potentially inaccurate or contextually inappropriate responses, emphasizing the importance of prompt engineering in achieving accurate outcomes across different domains. This study aims to address this void by introducing a methodology for optimizing interactions with Artificial Intelligence language models, like ChatGPT, through prompts in the field of engineering. The approach is called GPEI and relies on the latest advancements in this area; and consists of four steps: define the objective, design the prompt, evaluate the response, and iterate. Our proposal involves two key aspects: data inclusion in prompt design for engineering applications and the integration of Explainable Artificial Intelligence principles to assess responses, enhancing transparency. It combines insights from various methodologies to address issues like hallucinations, emphasizing iterative prompt refinement techniques like posing opposing questions and using specific patterns for improvement. This methodology could improve prompt precision and utility in engineering.",
    "full_text": " \n \n \n \n \n \n¬© The author; licensee Universidad Nacional de Colombia.  \nRevista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023, ISSN 0012-7353 \nDOI:  https://doi.org/10.15446/dyna.v90n230.111700 \nPrompt Engineering: a methodology for optimizing interactions with \nAI-Language Models in the field of engineering‚Ä¢ \n \n \nJuan David Vel√°squez-Henao, Carlos Jaime Franco-Cardona & Lorena Cadavid-Higuita \n \nUniversidad Nacional de Colombia, sede Medell√≠n, Facultad de Minas, Medell√≠n, Colombia. jdvelasq@unal.edu.co, cjfranco@unal.edu.co, \ndlcadavi@unal.edu.co  \n \n \nAbstract \nChatGPT is a versatile conversational Artificial Intelligence model that responds to user input prompts, with applications in academia and various \nsectors. However, crafting effective prompts can be challenging, leading to potentially inaccurate or context ually inappropriate responses, \nemphasizing the importance of prompt engineering in achieving accurate outcomes across different domains. This study aims to address this void by \nintroducing a methodology for optimizing interactions with Artificial Intelligence language models, like ChatGPT, through prompts in the field of \nengineering. The approach is called GPEI and relies on the latest advancements in this area; and consists of four steps: define the objective, design \nthe prompt, evaluate the response, and iterate. Our proposal involves two key aspects: data inclusion in prompt design for engineering applications \nand the integration of Explainable Artificial Intelligence principles to assess responses, enhancing transparency. It combines insights from various \nmethodologies to address issues like hallucinations, emphasizing iterative prompt refinement techniques like posing opposing questions and using \nspecific patterns for improvement. This methodology could improve prompt precision and utility in engineering. \n \nKeywords: ChatGPT; prompt engineering; large language models; prompt design. \n \n \nIngenier√≠a de instrucciones: una metodolog√≠a para optimizar \ninteracciones con Modelos de Lenguaje de IA en el campo de ingenier√≠a \n \n \nResumen \nChatGPT es un modelo de Inteligencia Artificial conversacional vers√°til que responde a las indicaciones de entrada del usuario, con aplicaciones en el \nmundo acad√©mico y diversos sectores. Sin embargo, elaborar indicaciones efectivas puede ser un desaf√≠o, lo que lleva a respuestas potencialmente \ninexactas o contextualmente inapropiadas, lo que enfatiza la importancia de la ingenier√≠a de instrucciones para lograr resultados precisos en diferentes \ndominios. Este estudio pretende abordar este vac√≠o introduciendo una metodolog√≠a para optimizar las interacciones con modelos de lenguaje de \nInteligencia Artificial, como ChatGPT, a trav√©s de instrucciones en el campo de la ingenier√≠a. El enfoque es llamado GPEI, y se basa en los √∫ltimos \navances en esta √°rea, el cual consta de cuatro pasos: definir el objetivo, dise√±ar el mensaje, evaluar la respuesta e iterar. Nuestra propuesta involucra dos \naspectos clave: la inclusi√≥n de datos en el dise√±o r√°pido para aplicaciones de ingenier√≠a y la integraci√≥n de principios de Inteligencia Artificial Explicable \npara evaluar las respuestas, mejorando la transparencia. Combina conocimientos de varias metodolog√≠as para abordar problemas como las alucinaciones, \nenfatizando t√©cnicas iterativas de refinamiento r√°pido, como plantear preguntas opuestas y usar patrones espec√≠ficos para mejorar. Esta metodolog√≠a \npodr√≠a mejorar la precisi√≥n y la utilidad r√°pidas en ingenier√≠a. \n \nPalabras clave: ChatGPT; ingenier√≠a de instrucciones; grandes modelos de lenguaje; dise√±o de instrucciones. \n \n \n \n1 Introduction \n \nChatGPT is the acronym for Chat Generative Pre-Trained \nTransformer, which can respond based on user requests using \ninput text prompts [1]. As a conversational large language \n \nHow to cite: Vel√°squez-Henao, J.D., Franco-Cardona, C.J. and Cadavid- Higuita, L., Prompt Engineering: a methodology for optimizing interactions with AI -Language Models \nin the field of engineering. DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9- 17, Noviembre, 2023. \nmodel (LLM), ChatGPT has seen extensive applications \nacross various sectors, including academia, and it can \nproduce text that is often indistinguishable from that authored \nby humans [2,3]. ChatGPT is a generative AI platform that \nallows users to input text prompts, which generate responses \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n10 \nbased on the knowledge accumulated during the training \nphase [4]. Typical applications include text generation, \nsummarization, and translation [5]. \nA prompt is a text describing a set of instructions that \ncustomize, refine, or enhance the capabilities of a GPT model \n[6]. Effective prompts are characterized by the following \nfundamental principles [7]: clarity and precision, contextual \ninformation, desired format, and verbosity control. However, \nwriting effective prompts seems complicated  for non -\ntechnical users, requiring creativity, intuition, and iterative \nrefinement [7]. The problem becomes more significant when \nit is necessary to incorporate precise information to solve \ntasks in specific contexts. \nConsequently, the answers can be vague, imprecise, \nfactually incorrect, or contextually inappropriate [5] when an \ninadequate prompt is used. In this context, prompt \nengineering emerges as a discipline to design prompts by \nwhich users can program a Large Language Model, such as \nChatGPT, to produce accurate answers [8,9]. \nDuring the last year, much gray literature has been \ngenerated that mainly presents prompt templates for specific \nworkflows and tasks in marketing, advertising, SEO, and text \ntranslation. There are also many prompt templates for using \nthese technologies in everyday tasks such as travel \npreparation. A quick analysis of this material allows us to \nconclude that the considerations made tend to be repetitive \nand need more depth to use these technologies as assistants \nin professional practice and engineering educa tion. On the \nother hand, in the most relevant literature, efforts have been \nmade to formalize the construction of prompts, as will be \ndiscussed later. However, research has  concentrated mainly \non practice, research, teaching, and scientific publication in \nhealth. Consequently, there is a gap when considering the \nopportunities of using GPT and conversational assistants in \nengineering; a similar conclusion is achieved in [10] by \nanalyzing the potential uses of LLM in business process \nmanagement. \nThis work seeks to fill this gap. We propose a \nmethodology for developing prompts in engineering based \non an iterative process based on the main developments that \nhave been presented to date on this topic. \nThe rest of this work is organized as follows: Section 2 \noverviews the current discourse on GPT and prompt \nengineering. Section 3  presents the methodology employed \nto propose a framework for engineering prompts, elaborating \nand illustrating it further in Section 4. Finally, the paper is \nconcluded in Section 5. \n \n2 Literature review \n \nGenerative language models are part of the broader \ncategory of pre -trained Generative Transformers (GPT) and \nare part of deep learning models [11]. Their competence in \ninterpreting and producing human language is based on the \nprinciples and techniques of natural lang uage processing \n(NLP) [12]. The GPT approach is based on the principles of \ndeep learning and NLP. Prompt engineering is essential to \nuse generative language models effectively [13]. \nTo evaluate generative language models, sentiment \nanalysis and opinion mining are usually used, where users \nrate their performance and express their opinions. This \nevaluation allows for continuous improvement of these \nsystems. However, there are also profound ethical \nimplications to its use, given its potential for disseminating \nbiased or erroneous data and its implications for plagiarism \nand copyright [14, 15]. In essence, generative language \nmodels offer substantial opportunities in various fields but \nrequire careful implementation, ethical oversight, and \nresponsive adaptation to ensure their positive impact and \nreliability [16-19]. \n \n2.1 Discussion about ChatGPT \n \nThe current academic discussion about ChatGPT and \nLLM revolves around three axes: Generative Artificial \nIntelligence, Education, and Ethics. \nGenerative artificial intelligence (Generative AI), based \non transformer architectures, is rapidly advancing in the \ndomain of artificial intelligence [20 ,21]. These models can \ngenerate content in various formats, such as text, images, and \nmore, that closely resemble what humans produce [20, 21]. \nThese elements profoundly impact professional practice and \neducation [3, 22]. Many concerns relate to academic and \nprofessional integrity and student evaluation [22, 23]. The \ndual nature of technology (enabling academi c dishonesty \nwhile potentially enriching pedagogical approaches) forces \ninstitutions to critically evaluate their assessment \nmethodologies to ensure content accuracy and authenticity \n[22,23]. The foray of generative AI into the educational space \nhas motivated academics to rethink traditional educational \nframeworks, generating opportunities and challenges \n[24,25]. In summary, the integration of generative artificial \nintelligence at the professional and academic levels requires \nrigorous evaluation, continuous  research, and adaptation \nstrategies to take advantage of its advantages and address the \nassociated challenges [22-25]. \nEducation is one of the areas most impacted by the \npopularization of GPTs, mainly by conversational agents \npowered by AI [26]. There are already many publications on \nthis aspect  in the most relevant literature , particularly for \nmedical education. Since conversational models can generate \nhuman-like text, they can be used in curriculum design, as \npart of teaching methodologies, and to create personalized \nlearning resources [26]. Th ese capabilities  facilitate the \nteaching of complex concepts and help  educators monitor \nand refine their pedagogical approaches [26]. Beyond the \neducational field, conversational agents can offer relevant \nand accurate information to individuals and communities, \nthus demonstrating their usefulness as a complementary \ninformation resource that improves access to information and \ndecision-making [14]. As in other cases discussed, there are \nessential concerns about possible bias, security, and ethical \nimplications associated with using these tools [17 ,15]. For \nthis reason, it is imperative to guarantee the accurate, \ntransparent, and ethically sound deployment of these tools, \nespecially for public consultation in general [16]. \nModels, such as ChatGPT, have generated immense \ninterest due to their transformative potential in different \nsectors, such as administration, finance, health, and education \n[27]. However, their integration has raised complex \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n11 \nquestions, particularly around authorship, plagiarism, and the \ndistinction between human - and AI -generated content [27 -\n29]. One of the fundamental issues is whether AI systems \nshould be credited as authors in academic writings \n[27,28,30]. The distinction between human- written content \nand AI -generated content becomes more blurred, \nemphasizing concerns about plagiarism [ 27,28,31]. AI \nmodels can generate seemingly genuine but potentially \nmisleading scientific texts [32]. In response, there is an \nemphasis on gr eater scrutiny, transparency, and ethical \nstandards in using AI in research [31, 32]. In this way, it is \nnecessary to achieve a balance between the advantages of AI \nand ethical considerations becomes paramount \n[27,29,30,33], which requires an emphasis on transparency, \nfairness, and initiatives of open source [32,33]. \n \n2.2 Discussion about prompt engineering \n \nPrompt engineering is a set of techniques and methods to \ndesign, write , and optimize instructions for LLM, called \nprompts, such that the model answers will be precise, \nconcrete, accurate, replicable, and factually correct [8 ,9,18]. \nPrompts are understood as a form of programming because  \nthey can customize the outputs and interactions with an LLM \n[9]. They involve adapting instructions in natural language, \nobtaining the desired responses, guaranteeing contextually \naccurate results, and increasing the usefuln ess of generative \nlanguage models in various applications [13]. Its applications \ninclude fields such as medical education, radiology, and \nscience education [11,12,34]. These systems can be used, for \nexample, as virtual assistants for student care or report \nwriting, transforming complex information into a coherent \nnarrative [11,26,34]. \nEfforts are underway to standardize the terminology and \nconcepts within prompt engineering, with various \nclassifications of prompts emerging based on different \ncriteria. \nAccording to the structure, prompts can be formulated \nusing open -ended or closed- ended questions. Open- ended \nquestions do not have a specific or limited answer and allow \nfor a more extensive and detailed response from the model. \nThey are helpful, for example, for critical reading tasks [35]. \nIn contrast, closed -ended questions typically  have specific \nand limited answers, often yes or no, multiple -choice, or a \nshort and defined response . For example, instead of asking  \n‚ÄúWhat is the capital of Italy ?‚Äù (close-ended question), an \nopen-ended question might be, ‚ÄúTell me about the history and \nculture of Rome.‚Äù \nAccording to the information provided, prompts can be \ncategorized into levels 1 to 4. The first level consists of \nstraightforward questions, while the second level introduces \nadditional context about the writer and the language model. \nThe third level includes provided examples for the language \nmodel to reference, and the fourth level allows the language \nmodel to break down the request into individual components \n(much like requesting a step-by-step solution to a mathematical \nproblem, offering the language model a more structured way to \nhandle the prompt for improved accuracy) [36]. \nComparably, prompts have also been classified as \ninstructive, system, question -answer, and mixed. Instructive \nprompts start with a verb that specifies the action to be \nperformed by the system. System prompts provide the system \nwith a starting point or context to develop content. Question-\nanswer prompts formulate a wh* type question. Mixed  \nprompts blend two or more techniques mentioned above [8]. \nAccording to the number of examples provided, \ninstructions are classified as zero-shot and few-shot prompts, \nwhere \"shot\" is equivalent to an example [36]. Zero- shot \nprompts are used in situations where it is not necessary to \ntrain the LLM or present sample outputs [37]. Examples of \nzero-shot prompts include prompts used to translate or \nsummarize texts; other examples of zer o-shot prompts are \nsimple questions that are answered with the internal \nknowledge of the LLM, such as, for example, \"define prompt \nengineering.\" Few-shot prompts cover prompts with more \ndetailed information. \nReproducibility is a desired characteristic, but LLM \nproduces an inherent random response due to its intrinsic  \ndesign [7].  \nMany sources recognize that the development of prompts \nis an iterative process. Also, it is desired that the prompt text \nmust be clear, concise, and to the point, avoiding unnecessary \ncomplexity [38]. \nFollowing the discussion, poorly designed prompts \ngenerate vague, biased, misleading, or ambiguous responses. \nAnother major problem is hallucinations [5,9]. Many \nresearchers highlight the necessity of verifying facts \npresented in the response of conversati onal LLMs, such as \nacademic citations. \n \n3 Methodology \n \nWe conducted a comprehensive literature search using \nthe Scopus database to  identify scientific papers on \nprompt engineering. Scopus is renowned as one of the \nlargest repositories of peer -reviewed scientific \nliterature, and it encompasses a broad spectrum of \ndisciplines, including science, technology, medicine , \nand social sciences [39]. \nWe designed and used the following search equation, \nwhich retrieved 184 documents. \n \nTITLE ( ( prompt AND C hatGPT ) OR ( prompt AND \nengineering ) ) OR KEY ( ( prompt AND ChatGPT ) OR ( \nprompt AND engineering ) )  \n \nThe analysis of the documents and the valuable findings \nfor a prompt design methodology are presented below. \n \n4 Results \n \n4.1 Analysis \n \nThe majority of the literature found can be categorized \ninto two groups: specific applications (particularly in the \nfield of medicine) and guidelines and recommendations for  \nprompt design [36] [38]. Only seven papers go beyond \nprompt design to propose a methodology for interacting with \n \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n12 \n \nTable 1. \nComponents of methodologies. \nAuthors Application Guidelines Data Evaluation \nCriteria Iteration \nChang (2023) [35] Critical Reading X  X X \nEager and Brunton, 2023 [18] Education X X X X \nGiray, 2023 [8] Academic Writing X X   \nJha et al., 2023 [5] General   X X \nLo, 2023 [19] General X  X X \nShieh, 2023 [40] General    X \nSource: The authors \n \n \nchatGPT using prompts. This situation can be attributed to \nthe large number of documents and gray literature offering \ncompilations of prompt examples and templates for specific \ntasks such as marketing, advertising, or text translation. \nThese guides are des igned for the non- technical user, and \nthey play an essential role in popularizing ChatGPT and \nLLM, although they may not be part of the scientific \nliterature. Table 1 presents the components of these \nmethodologies and other pertinent sources within the gra y \nliterature. \nSeveral methodologies have been developed for general \napplications (though they are typically published in medical \nfield journals), while some have been proposed for specific \ndomains. We did not find any methodologies proposed for \nthe field of engineering. \nMost of the methodologies provide guidelines for prompt \ndesign and incorporate interactiveness. However, given the \nnature of the application field, some methodologies are based \non specific prompt designs, such as open-ended questions for \ncritical reading [ 35] or persona design for academic writers \n[8]. Only two methodologies include providing data within \nthe prompt for the system's response retrieval. \nWhile some methodologies involve evaluating the \nresponse before iterating on the prompt [5,18,19,35], not all \nof them provide components for conducting this assessment \n[5,18].  \nEven though some methodologies hold promise, they are \nnot currently directly applicable to prompt design. For \ninstance, in [5 ,41], a methodology is proposed that may be \nuseful for the internal programming of LLMs but not for \nhuman-user interaction with such systems. Furthermore, in \n[42], a hermeneutic exercise is conducted without a proposed \nmethodology that can be applied to other domains. \nAs of the publication date of this paper, we have not found \nofficial documentation from Google on recommendations for \ninteracting with Bard (the Artificial Intelligence system \ndeveloped by the company [43]). Similarly, we have not \ncome across official docu mentation from Microsoft \nregarding recommendations for interacting with 12hatGPT  \nthrough their Bing browser [44]. \n \n4.1 Proposal \n \nWe collected the guidelines, recommendations, and \ncommon elements from the various methodologies for \nprompt design that were analyzed earlier. Furthermore, we \nalso considered issues related to hallucinations and low -\nquality responses and integrated those e lements into a \nmethodology for interacting with ChatGPT through prompts \nfor the engineering field. \nThe methodology is called GPEI, which stands for Goal \nPrompt Evaluation Iteration. GPEI consists of 4 steps: (1) \ndefine a goal, (1) design the prompt, (3) evaluate the answer, \nand (4) iterate, as Figure 1 shows. The methodology is \nexplained below. \n \n4.2.1. Step 1: Define a goal \n \nThe process begins by defining the goal to be achieved by \nthe AI model. The goal will determine the structure of the \nprompt to be designed in the following step and assist in \nevaluating the quality of the system‚Äôs response before further \niterations. Despite its significance, this activity is explicitly \noutlined only in one of the analyzed methodologies [18]; in \nthe remaining methodologies, the objective is disaggregated \nwithin the prompt design. \n \n4.2.2. Step 2: Prompt designing \n \nThe first step consists of the design of the prompt. In [9], \na catalog of prompt patterns is presented and discussed. The \nauthors describe 12 patterns for prompt designing; also, they \nidentify for each pattern the intent, motivation, key ideas, and \nconsequences of the approach. Five of these patterns are \noriented toward customizing the output obtained from the \nsystem: output Automater, persona, visualization generator, \nrecipe, and template. \n \n  \nFigure 1. GPEI Methodology  \nSource: The authors. \n\nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n13 \n \nFigure 2. Example of a prompt template for including specific information. \nSource: The authors. \n \n \nAccording to the established goal, the user should use the \npattern that best suits their purpose.  For example, if the \npersona pattern is chosen, the prompt should have the \nfollowing elements [36]: \n‚Ä¢ The definition of the role of the person who is asking the \nquestion. \n‚Ä¢ The definition of a role or a context: \" you are ‚Ä¶\", \"you \nact as ‚Ä¶\" \n‚Ä¢ The definition of what is required: Your task is ‚Ä¶ / Write \n‚Ä¶ / Rephase ‚Ä¶ /  \n‚Ä¢ A description of the output format (for example, a \nparagraph, a bulleted list, a table, JSON data, etc). \n‚Ä¢ A description of limits for the expected results. \nIn an engineering context, we advise that the prompt \nincludes the necessary data for the system to generate \nresponses. An example is presented in Fig. 2. \nThe literature provides some recommendations for \nprompt design. \n‚Ä¢ Extending prompts with phrases such as \"within the scope\" \nand \"Let's think step by step ‚Ä¶ to reach conclusions\" could \nimprove the response of the system. \n‚Ä¢ A strategy for complex responses involves asking LLM to \nbreak the result into small chunks [45]. \n‚Ä¢ Think that prompts are instructions in the context of \ncomputer programming, such that it is unnecessary to be \npolite; avoid phrases such as \"Please, give me ‚Ä¶\" [45]. \n‚Ä¢ Strategies, such as the Tree of Thoughts [41], can be used to \nstructure prompts for complex problems.  \n‚Ä¢ Frameworks, such as CLEAR, propose a Concise, Logical, \nExplicit, Adaptive, and Reflective process to optimize \ninteractions with AI language models like ChatGPT through \nprompts. \n‚Ä¢ OpenAI suggests separating instructions from the context \nthrough a break in the prompt or using quotation marks to \nreference textual elements from the context [40]. \n‚Ä¢ Adding examples to articulate the desired output could also \nbe useful [40]. \n \nMoreover, the prompt can be used as a template for \nsolving similar problems or generating new prompts for \nsimilar problems (template pattern [9]). Disambiguation can \nbe avoided by providing a detailed description or scope of the \nproblem or the data, as exemplified in Fig. 3. \nA more comprehensive guide for developing template \nprompts can be found in [35]. A very important recommendation \nis to use the designed prompt in the chat and then collect and save \nthe system output. At this point, it is imperative to preserve the \nhistory of the process design to realize ex-post evaluations of the \nperformance of the designed prompts. \n \n4.2.3. Step 3: Evaluate the answer. \n \nRealize a formal verification of the answer provided by \nChatGPT in terms of the design criteria specified in Step 1. \nEvaluating the obtained response is not trivial since it can \npotentially reduce system hallucination. \nThe following questions could be helpful in this purpose [19]: \nIs the answer as complete as expected? \nIs the answer as accurate as expected? \nIs the answer as relevant as expected? \nWere the specified limits met? \nDoes the answer have elements that may be factually \nincorrect (hallucinations)? \nDoes the answer have elements that may be contextually \ninappropriate? \nThe available literature offers various methods for \nassessing ChatGPT's responses. For instance, one approach \ninvolves rephrasing a question to elicit different responses, \nwhich can help identify inconsistencies among multiple \nanswers. Additionally, requesting additional evidence, such \nas querying top- k information sources and having the \nlanguage model rate the credibility of each source, is another \nstrategy. Also, one can seek opposing viewpoints from the \nlanguage model, including their sources and credibility, to \nevaluate the strength of a different perspective [35]. It is also \npossible. \nIn [5], formal methods are integrated into the design of \nprompts for critical and autonomous systems with the aim of \nself-monitoring and automatic detection of errors and \nhallucinations. Among the recommendations, the authors \nsuggest that one could conside r providing counterexamples \nin the prompt to prevent hallucinations [5]. \nFurthermore, it is possible to design other prompts to \nevaluate a response. For instance, prompts falling under the \nerror identification category in [9] involve generating a list \nof facts the output depends on that should be fact -checked \nand then introspecting on its output to identify any errors. \nA potentially useful strategy to evaluate the answer of an \nLLM is to incorporate elements commonly used to design \nExplainable AI systems (XAI) [46]. We propose the \nfollowing guidelines to incorporate these principles to  \nevaluate the answer's quality: \n \n \nFigure 3. Prompt example for including specific information. \nSource: The authors. \n\nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n14 \n‚Ä¢ Ask for the reasoning behind a particular answer. \n‚Ä¢ Verify that the prompt asking the LLM provides a \nsimple, direct, and unambiguous response. \n‚Ä¢ Verify the prompt requires the LLM to justify the answer. \n‚Ä¢ Ask the LLM to break down the answer in bullets, steps, \nor stages for complex answers. \n‚Ä¢ Inquire about the data sources or training data. \n \n4.2.4. Step 4: Iterate \n \nIf the answer fails to meet the evaluation criteria, prompt \nmodification is required, which entails adjusting the design \nobtaining and assessing a new answer. This iterative \nrefinement process continues until the system's response is \ndeemed adequate. \nAs suggested in [35], the iterative process could be as simple \nas posing the same question from an opposing perspective. \nHowever, other strategies that use specific prompt patterns can \nalso be helpful, like the patterns within the improvement group \nfocus on enhancing the quality of both input and output. Patterns \nin this category involve suggesting alternative ways for the \nLanguage Model (LLM) to accomplish a user -specified task, \ninstructing the LLM to automatically propose a series of \nsubquestions for user s to answer before combining these \nsubquestion answers to produce a response to the overarching \nquestion (similar to [41]) and mandating the LLM to \nautomatically rephrase user queries when it declines to provide \nan answer. \nMoreover, the utilization of particular prompt patterns \ncan prove advantageous. For example, patterns found within \nthe Improvement category in [9] focus on enhancing input \nand output quality. These patterns suggest  alternative \nmethods for the LLM to execute a task specified by the user, \ndirecting the LLM to autonomously present a sequence of \nsubquestions for users to address before  amalgamating these \nsubquestion responses to formulate a comprehensive answer \nto the primary inquiry. Additionally, they instruct the LLM \nto automatically rephrase user queries in cases where it \nrefuses to produce a solution. \n \n4.2 Application \n \nFor this example, we will seek the solution to a well-\nknown engineering problem : the knapsack problem [47]. In \nthis problem, one must decide which items to take on a trip \nbased on the utility value of each item, the weight  of each \nitem, and a limit on the total weight that can be carried. \n \n4.3.1. Step 1: Define a goal. \n \nFrom a given list of items, one should find the \ncombination that has the highest total benefit without \nexceeding a total weight of 10 kg. \n \n4.3.2. Step 2: Design the prompt. \n \nThe designed prompt and the corresponding response are \npresented in Table 2.  \nTable 2. \nFirst iteration for the application case.  \nRole Dialogue \nPrompt \nGiven the items below, choose the set of items that has the \nhighest total value, as long as the sum of the weights of \nthose items does not exceed 10 kilograms: Item 1: Value - \n8, Weight - 3 kg; Item 2: Value - 6, Weight - 2 kg; Item 3: \nValue - 10, Weight - 5 kg; Item 4: Value - 3, Weight - 1 kg; \nItem 5: Value - 7, Weight - 4 kg; Item 6: Value - 9, Weight \n- 3 kg; Item 7: Value - 5, Weight - 2 kg; Item 8: Value - 4, \nWeight - 1 kg; Item 9: Value - 2, Weight - 6 kg; Item 10: \nValue - 10, weight - 10 kg \nGPT \nGiven the items provided, the optimal selection to achieve the \nhighest total value without exceeding 10 kilograms would be:  \n* Item 1: Value - 8, Weight - 3 kg \n* Item 2: Value - 6, Weight - 2 kg \n* Item 3: Value - 10, Weight - 5 kg \n* Total value: 24; Total weight: 10 kg \nSource: The authors. \n \n \nTable 3. \nSecond iteration for the application case.  \nRole Dialogue \nPrompt \nGiven the items below, give me three sets with the highest total \nvalue. The sets can have any number of elements as long as they \nare not repeated, and the sum of the weights of those items does \nnot exceed 10 kilograms. Show only sets that do not exceed 10 \nkilograms: Item 1: Value - 8, Weight - 3 kg; Item 2: Value - 6, \nWeight - 2 kg; Item 3: Value - 10, Weight - 5 kg; Item 4: Value - \n3, Weight - 1 kg; Item 5: Value - 7, Weight - 4 kg; Item 6: Value - \n9, Weight - 3 kg; Item 7: Value - 5, Weight - 2 kg; Item 8: Value - \n4, Weight - 1 kg; Item 9: Value - 2, Weight - 6 kg; Item 10: Value \n- 10, weight - 10 kg; Your best answer has been: Item 1: Value - \n8, Weight - 3 kg; Item 2: Value - 6, Weight - 2 kg; Item 3: Value - \n10, weight - 5 kg \nGPT \nGiven the items provided and the constraint that the total \nweight cannot exceed 10 kilograms, here are three sets with \nthe highest total value that do not exceed the weight limit:  \n \nSet 1:  \n* Item 3: Value - 10, Weight - 5 kg \n* Item 6: Value - 9, Weight - 3 kg. \n* Item 1: Value - 8, Weight - 3 kg. \nTotal Value: 27 \nTotal Weight: 11 kg (exceeds weight limit) \n \nSet 2:  \n* Item 3: Value - 10, Weight - 5 kg \n* Item 2: Value - 6, Weight - 2 kg \n* Item 1: Value - 8, Weight - 3 kg \nTotal Value: 24  \nTotal Weight: 10 kg (within weight limit);  \n \nSet 3: \n* Item 3: Value - 10, Weight - 5 kg \n* Item 6: Value - 9, Weight - 3 kg \n* Item 2: Value - 6, Weight - 2 kg \nTotal Value: 25 \nTotal Weight: 10 kg (within weight limit).  \n \nThese sets provide the highest total value without exceeding \nthe 10 kilograms weight limit. \nSource: The authors. \n \n4.3.3. Step 3: Evaluate the answer. \n \nThe items meet the imposed restriction; however, when \nindependently verified using an optimization tool, the \nfollowing is the optimal solution:  \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n15 \n‚Ä¢ Item 1: Value - 8, Weight - 3 kg.  \n‚Ä¢ Item 2: Value - 6, Weight - 2 kg. \n‚Ä¢ Item 4: Value - 3, Weight - 1 kg. \n‚Ä¢ Item 6: Value - 9, Weight - 3 kg. \n‚Ä¢ Item 8: Value - 4, Weight - 1 kg. \n‚Ä¢ Total value: 30. \n‚Ä¢ Total weight: 10 kg \nLet's see if we can find a better solution than the one \nfound in iteration 1 using ChatGPT. \n \n4.3.4. Step 4: Iterate \n \nA new designed prompt, presented int Table 3, is used for \nthe second iteration. Although a better answer was achieved \nin this iteration than the previous one, ChatGPT still does not \nfind the system's optimum. Other strategies will be employed \nin iterations 3 and 4 to aid in solving this problem. \nFor the iteration 3, the strategy is changed from asking for \nthe solution to requesting the formulation of the problem (See \nTable 4). In the iteration 4, we designed a prompt to request \nthe generation of the code necessary for Google \nCollaboratory [48] to solve the previous problem. The \ndialogue is presented in Table 5. \n \nTable 4. \nIteration 3 for the application case.  \nRole Dialogue \nPrompt \nFormulate the objective function and the correspondent \nconstraints for the following problem:  \nGiven a number of items, each characterized by a value and \na weight in kilograms, find the set of items where the sum \nof their values is maximum, and the sum of their weights is \nless than or equal to 10 kilograms. The sets can have any \nnumber of elements, as long as they are not repeated. \nGPT \nThis is a classic Knapsack problem. \nObjective function: \nMaximize ùëçùëç where: \nùëçùëç = ÔøΩùë§ùë§ùëñùëñùë•ùë•ùëñùëñ\nùëõùëõ\nùëñùëñ=1\n‚â§ 10 \nThis objective function represents the total value of the \nselected items. \nConstraints: \n1. The total weight of the selected items should not exceed \n10 kg: \nÔøΩùë§ùë§\nùëñùëñùë•ùë•ùëñùëñ\nùëõùëõ\nùëñùëñ=1\n‚â§ 10 \n2. Decision variable constraints: \n0 ‚â§ ùë•ùë•ùëñùëñ ‚â§ 1 \nand ùë•ùë•ùëñùëñ must be an integer (binary) \nThe objective function aims to maximize the total value of \nselected items, subject to the constraints that the total \nweight does not exceed 10 kilograms and each item is either \nselected or not and not repeated. \nSource: The authors. \n \nTable 5. \nIteration 4 for the application case. \nRole Dialogue \nPrompt \nGenerate a code to solve this problem for Google Colab, Use \nthe following items for the code: Item 1: Value - 8, Weight - \n3 kg; Item 2: Value - 6, Weight - 2 kg; Item 3: Value - 10, \nWeight - 5 kg; Item 4: Value - 3, Weight - 1 kg; Item 5: \nValue - 7, Weight - 4 kg; Item 6: Value - 9, Weight - 3 kg; \nItem 7: Value - 5, Weight - 2 kg; Item 8: Value - 4, Weight - \n1 kg; Item 9: Value - 2, Weight - 6 kg; Item 10: Value - 10, \nweight - 10 kg \nGPT \n# Import PuLP library \n!pip install pulp \n \nfrom pulp import ( \n    LpMaximize, LpProblem, lpSum, LpVariable \n) \nprob = LpProblem(\"Maximize_Value\", LpMaximize) \nitems = { \n    1: {\"value\": 8, \"weight\": 3}, \n    2: {\"value\": 6, \"weight\": 2}, \n    3: {\"value\": 10, \"weight\": 5}, \n    4: {\"value\": 3, \"weight\": 1}, \n    5: {\"value\": 7, \"weight\": 4}, \n    6: {\"value\": 9, \"weight\": 3}, \n    7: {\"value\": 5, \"weight\": 2}, \n    8: {\"value\": 4, \"weight\": 1}, \n    9: {\"value\": 2, \"weight\": 6}, \n    10: {\"value\": 10, \"weight\": 10} \n} \nitem_vars = LpVariable.dicts( \n    \"Item\", items.keys(), 0, 1, LpVariable \n) \nprob += lpSum( \n    item_vars[i] * items[i][\"value\"]  \n    for i in items \n) \nprob += lpSum( \n   item_vars[i] * items[i][\"weight\"]  \n   for i in items \n) <= 10 \n \nprob.solve() \n \nselected_items = [ \n    i  \n    for i in items  \n    if item_vars[i].value() == 1 \n] \ntotal_value = sum( \n    items[i][\"value\"] for i in selected_items \n) \ntotal_weight = sum( \n    items[i][\"weight\"]  \n    for i in selected_items \n) \nprint(\"Selected items:\") \nfor i in selected_items: \n    print( \n       f\"Item {i}: \" \n       f\"Value - {items[i]['value']}, \" \n       f\"Weight - {items[i]['weight']} kg\" \n) \nprint(f\"Total Value: {total_value}\") \nprint(f\"Total Weight: {total_weight} kg\") \nSource: The authors. \n \nWhen we ran the code in Google Colab, we obtained this \nresponse: \n \nRequirement already satisfied: pulp in \n/usr/local/lib/python3.10/dist-packages (2.7.0)  \nSelected items:  \nItem 1: Value - 8, Weight - 3 kg;  \nItem 2: Value - 6, Weight - 2 kg;  \nItem 4: Value - 3, Weight - 1 kg;  \nItem 6: Value - 9, Weight - 3 kg;  \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n16 \nItem 8: Value - 4, weight - 1 kg;  \nTotal Value: 30;  \nTotal Weight: 10 kg \n \nWhich is the correct solution to the problem. So here, we \nhalted the process. \n \n5 Conclusions \n \nPrompt engineering plays a pivotal role in optimizing the \nperformance of LLM by crafting instructions or prompts that \nelicit precise, accurate, and contextually appropriate \nresponses. Designing effective prompts is iterative and \nrequires clear and concise language to avoid generating \nvague or biased responses. \nA literature analysis found that multiple methodologies \nfor prompt engineering have been developed. Notably, no \nmethodologies were found specifically designed for \nengineering. Most of these methodologies offer guidance for \nprompt design and emphasize itera tive processes. Only two \nmethodologies include data within the prompt to facilitate \nsystem response retrieval. While some methodologies \ninvolve response evaluation before iterating on the prompt, \nnot all of them provide components for this assessment. \nWe propose an iterative methodology for optimizing \ninteractions with AI language models in engineering through \nprompts named GPEI. It is a four-step process, including defining \na goal, designing the prompt, evaluating the answer, and iterating \nto achieve an adequate response. GPEI has two key elements: the \ninclusion of data in prompt design, making it suitable for \napplications in the field of engineering, and the inclusion of \nprinciples from Explainable AI (XAI) systems to evaluate \nanswers is proposed, promoting transparency and justifiability in \nthe responses generated by LLM. \nOur methodology integrates guidelines, recommendations, and \ncommon elements from various methodologies to address issues like \nhallucinations and low-quality responses. The iterative nature of \nprompt refinement is emphasized, with suggestions such as asking \nopposing questions and using specific prompt patterns for \nimprovement. This methodology is a valuable tool for designing \nprompts in engineering. \nThe application example showcased the capabilities of \nchatGPT in addressing engineering problems when integrated \nwith other calculation tools. Future work stemming from this \nresearch is related to applying the methodology in various \nengineering application s to incorporate the necessary \nenhancements for improving its utility. \n \n \nReferences \n \n[1] Lund, B.D., Wang, T., Mannuru, N.R., Nie, B., Shimray, S., and \nWang, Z., ChatGPT and a new academic reality: Artificial \nIntelligence-written research papers and the ethics of the large \nlanguage models in scholarly publishing, J. Assoc. Inf. Sci. Technol., \n74(5), pp. 570-581, 2023. DOI: https://doi.org/10.1002/asi.24750. \n[2] Macdonald, C., Adeloye, D., Sheikh, A., and Rudan, I., Can ChatGPT \ndraft a research article? An example of population -level vaccine \neffectiveness analysis, J. Glob. Health, 13, 2023 . DOI: \nhttps://doi.org/10.7189/JOGH.13.01003. \n[3] Rudolph, J., Tan, S., and Tan, S., ChatGPT: bullshit spewer or the end \nof traditional assessments in higher education? J. Appl. Learn. Teach., \n6(1), pp. 342 -363, 2023. DOI: \nhttps://doi.org/10.37074/jalt.2023.6.1.9. \n[4] Pavlik, J.V., Collaborating with ChatGPT: considering the \nimplications of generative artificial intelligence for journalism and \nmedia education, Journal. Mass Commun. Educ., 78 (1), pp. 84 -93, \n2023. DOI: https://doi.org/10.1177/10776958221149577. \n[5] Jha, S., Jha, S.K., Lincoln, P., Bastian, N.D., Velasquez, A., and \nNeema, S., Dehallucinating large language models using formal \nmethods guided iterative prompting, in: 2023 IEEE International \nConference on Assured Autonomy (ICAA), IEEE, 2023. pp. 149-152. \n[6] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G., Pre-\ntrain, prompt, and predict: a systematic survey of prompting methods \nin natural language processing, ACM Comput. Surv., 55(9), pp. 1-35, \n2023. \n[7] Lo, L.S., The art and science of prompt engineering: a new literacy in \nthe information age , Internet Ref. Serv. Q., 2023 . DOI: \nhttps://doi.org/10.1080/10875301.2023.2227621. \n[8] Giray, L., Prompt engineering with ChatGPT: a guide for academic \nwriters, Ann. Biomed. Eng., 2023 . DOI: \nhttps://doi.org/10.1007/s10439-023-03272-4. \n[9] White, J. et al., A prompt pattern catalog to enhance prompt \nengineering with chatgpt, ArXiv Prepr. ArXiv230211382, 2023. \n[10] Busch, K., Rochlitzer, A., Sola, D., and Leopold, H., Just tell me: \nprompt engineering in business process management, in: International \nConference on Business Process Modeling, Development and \nSupport, Springer, 2023, pp. 3-11. \n[11] Lecler, A., Duron, L., and Soander, P., Revolutionizing radiologand \nwith GPT-based models: current applications, future possibilities and \nlimitations of ChatGPT, Diagn. Interv. Imaging, 104(6), pp. 269-274, \n2023. DOI: https://doi.org/10.1016/j.diii.2023.02.003. \n[12] Eandsenbach, G., The role of ChatGPT, generative language models, \nand artificial intelligence in medical education: a conversation with \nChatGPT and a call for papers , JMIR Med. Educ., 9, 2023 . DOI: \nhttps://doi.org/10.2196/46885. \n[13] Wu, T., Terrand, M., and Cai, C.J., AI chains: transparent and \ncontrollable Human-AI interaction b and chaining large language \nmodel prompts , in: Conference on Human Factors in Computing \nSandstems - Proceedings, 2022.  DOI: \nhttps://doi.org/10.1145/3491102.3517582. \n[14] Raand P.P., and Majumder, P., Assessing the Accu racand of \nresponses band the language model ChatGPT to questions regarding \nbariatric surgerand: a critical appraisal, Obes. Surg., 33(8), pp. 2588-\n2589, 2023. DOI: https://doi.org/10.1007/s11695-023-06664-6. \n[15] Gupta, R., Herzog, I., Weisberger, J., Chao, J., Chaiandasate, K., and \nLee, E.S., Utilization of ChatGPT for plastic surger and research: \nfriend or foe ?, J. Plast. Reconstr. Aesthet. Surg., 80, pp. 145 -147, \n2023. DOI: https://doi.org/10.1016/j.bjps.2023.03.004. \n[16] Deiana, G., Dettori, M., Arghittu, A., Azara, A., Gabutti, G., and \nCastiglia, P., Artificial intelligence and public health: evaluating \nChatGPT responses to vaccination m andths and misconceptions , \nVaccines, 11 (7), art. 11071217, 2023 . DOI: \nhttps://doi.org/10.3390/vaccines11071217. \n[17] Corsello, A. and Santangelo, A., Maand artificial intelligence \ninfluence future pediatric research?‚ÄîThe case of ChatGPT, children, \n10(4), 2023. DOI: https://doi.org/10.3390/children10040757. \n[18] Eager, B., and Brunton, R., Prompting higher education towards AI-\nAugmented teaching and learning practice, J. Univ. Teach. Learn. \nPract., 20(5), 2023. DOI: https://doi.org/10.53761/1.20.5.02. \n[19] Lo, L.S., The CLEAR path: a framework for enhancing information \nliteracand through prompt engineering, J. Acad. Librariansh., 49 (4), \n2023. DOI: https://doi.org/10.1016/j.acalib.2023.102720. \n[20] DK. Dwivedi , et al., So what if ChatGPT wrote it? \nMultidisciplinarand perspectives on opportunities, challenges  and \nimplications of generative conversational AI for research, practice \nand polic and, Int. J. Inf. Manag., 71, 2023 . DOI: \nhttps://doi.org/10.1016/j.ijinfomgt.2023.102642. \n[21] Harrer, S., Attention is not all and ou need: the complicated case of \nethicalland using large language models in healthcare and medicine, \neBioMedicine, 90, 2023 . DOI: \nhttps://doi.org/10.1016/j.ebiom.2023.104512. \n[22] Crawford, J., Cowling, M., and Allen, K.-A., Leadership is needed for \nethical ChatGPT: character, assessment, and learning using artificial \nVel√°squez-Henao et al / Revista DYNA, 90 (230), Especial Conmemoraci√≥n 90 a√±os, pp. 9-17, Noviembre, 2023. \n17 \nintelligence (AI), J. Univ. Teach. Learn. Pract., 20 (3), 2023.  DOI: \nhttps://doi.org/10.53761/1.20.3.02. \n[23] Alexander, K., Savvidou, C., and Alexander, C., Who wrote this \nessaand? Detecting ai-generated writing in second language education \nin higher education , Teach. Engl. Technol., 23 (2), pp. 25 -43, 2023. \nDOI: https://doi.org/10.56297/BUKA4060/XHLD5365. \n[24] Lim, W.M., Gunasekara, A., Pallant, J.L., Pallant, J.I., and \nPechenkina, E., Generative AI and the future of education: Ragnar√∂k \nor reformation? A paradoxical perspective from management \neducators, Int. J. Manag. Educ., 21 (2), 2023,  DOI: \nhttps://doi.org/10.1016/j.ijme.2023.100790. \n[25] Bilal, M., Jamil, Y., Rana, D., and Shah, H.H., Enhancing awareness \nand Self -diagnosis of obstructive sleep apnea using AI -Powered \nchatbots: the role of ChatGPT in revolutionizing healthcare , Ann. \nBiomed. Eng., 2023 . DOI: https://doi.org/ 10.1007/s10439-023-\n03298-8. \n[26] Epstein, R.H., and Dexter, F., Variabilitand in large language Models' \nresponses to medical licensing and certification examinations. \ncomment on \"How Does ChatGPT Perform on the United States \nMedical Licensing Examination? The Implications of Large \nLanguage Models for Medical Education and Knowledge \nAssessment\", JMIR Med. Educ., 9, 2023 . DOI: \nhttps://doi.org/10.2196/48305. \n[27] Marchandot, B., Matsushita, K., Carmona, A., Trimaille, A., and \nMorel, O., ChatGPT: the next frontier in academic writing for \ncardiologists or a pandora's  box of ethical dilemmas, Eur. Heart J. \nOpen, 3(2), 2023. DOI: https://doi.org/10.1093/ehjopen/oead007. \n[28] Graf, A. and Bernardi, R.E., ChatGPT in research: balancing ethics, \ntransparencand and advancement , Neuroscience, 515, pp. 71 -73, \n2023. DOI: https://doi.org/10.1016/j.neuroscience.2023.02.008. \n[29] Yan, D., Impact of ChatGPT on learners in a L2 writing practicum: \nan exploratorand investigation, Educ. Inf. Technol., 2023 . DOI: \nhttps://doi.org/10.1007/s10639-023-11742-4. \n[30] Ruksakulpiwat, S., Kumar, A., and Ajibade, A., Using ChatGPT in \nMedical research: current status and future directions, J. Multidiscip. \nHealthc., 16, pp. 1513 -1520, 2023 . DOI: \nhttps://doi.org/10.2147/JMDH.S413470. \n[31] M√°jovsk√Ω, M., ƒåern√Ω, M., Kasal, M., Komarc, M., and Netuka, D., \nArtificial intelligence can generate fraudulent but authentic -looking \nscientific medical articles: pandora's box has been opened , J. Med. \nInternet Res., 25, 2023. DOI: https://doi.org/10.2196/46924. \n[32] Spirling, A., Whand open-source generative AI models are an ethical \nwaand forward for science, nature, 616(7957), art. 413, 2023 . DOI: \nhttps://doi.org/10.1038/d41586-023-01295-4. \n[33] Wang, S.H., OpenAI ‚Äî explain whand some countries are excluded \nfrom ChatGPT, nature , 615 (7950), art. 34, 2023 . DOI: \nhttps://doi.org/10.1038/d41586-023-00553-9. \n[34] Cooper, G., Examining science education in ChatGPT: A n \nexploratorand studand of generative artificial intellige nce, J. Sci. \nEduc. Technol., 32 (3), pp. 444 -452, 2023 . DOI: \nhttps://doi.org/10.1007/s10956-023-10039-and. \n[35] Chang, E.Y., Prompting large language models with the socratic \nmethod, in: 2023 IEEE 13th Annual Computing and Communication \nWorkshop and Conference, CCWC 2023, 2023 . pp. 351-360. DOI: \nhttps://doi.org/10.1109/CCWC57344.2023.10099179. \n[36] Heston, T.F., and Khun, C., Prompt engineering in medical education, \nInt. Med. Educ., 2(3), pp. 198-205, 2023. \n[37] Yong, G., Jeon, K., Gil, D., and Lee, G., Prompt engineering for zero-\nshot and few -shot defect detection and classification using a visual -\nlanguage pretrained model, Comput. -Aided Civ. Infrastruct. Eng., \n38(11), pp. 1536 -1554, 2023 . DOI: \nhttps://doi.org/10.1111/mice.12954. \n[38] Bozkurt, A., and Sharma, R.C., Generative AI and prompt \nengineering: the art of whispering to let the genie out of the \nalgorithmic world, Asian J. Distance Educ., 2023. \n[39] Elsevier, Wh and choose Scopus - Scopus benefits. [online]. \nAccessed: July 31th of 2020] Available at : \nhttps://www.elsevier.com/solutions/scopus/whand-choose-scopus \n[40] Shieh, J., Best practices for prompt engineering with OpenAI API, \nOpenIA, [online]. Sept. 2023. Accessed: October 3rd of 2023. \nAvailable at : https://help.openai.com/en/articles/6654000-best-\npractices-for-prompt-engineering-with-openai-api \n[41] Yao, S. et al., Tree of thoughts: deliberate problem solving with large \nlanguage models, ArXiv Prepr. ArXiv230510601, 2023. \n[42] Henrickson, L., and Mero√±o-Pe√±uela, A., Prompting meaning: a \nhermeneutic approach to optimising prompt engineering with \nChatGPT, AI Soc., 2023, DOI: https://doi.org/10.1007/s00146-023-\n01752-8. \n[43] Google, Bard - Chat based AI tool from Google, powered band PaLM \n2. [online]. Accessed: October 4th of 2023. Available at:  \nhttps://bard.google.com \n[44] Microsoft, Your AI-Powered Copilot for the Web | Microsoft Bing. \n[online]. Accessed: October 4 th of 2023. Available at: \nhttps://www.microsoft.com/en-us/bing \n[45] Spasic, A.J., and Jankovic, D.S., Using ChatGPT standard prompt \nengineering techniques in lesson preparation: role, instructions and \nseed-word prompts, in: 2023 58th International Scientific Conference \non Information, Communication and Energ and Sandstems and \nTechnologies, ICEST 2023 - Proceedings, 2023, pp. 47 -50. DOI: \nhttps://doi.org/10.1109/ICEST58410.2023.10187269. \n[46] Rudin, C., and Radin, J., Whand are we using black box models in AI \nwhen we don't need to? A lesson from an explainable AI competition, \nHarv. Data Sci. Rev., 1.2, p. 9, 2019 . DOI: \nhttps://doi.org/10.1162/99608f92.5a8a3a3d. \n[47] Salkin, H.M., and De Klu andver, C.A., The knapsack problem: a  \nsurveand, Nav. Res. Logist. Q., 22 (1), pp. 127 -144, 1975 . DOI: \nhttps://doi.org/10.1002/nav.3800220110. \n[48] Bisong, E., Google Colaboratorand, en Building Machine Learning \nand Deep Learning Models on Google Cloud Platform: A \nComprehensive Guide for Beginners, E. Bisong, Ed., Berkele and, \nCA: Apress, 2019, pp. 59 -64. DOI: https://doi.org/10.1007/978 -1-\n4842-4470-8_7. \n \n \nJ.D. Vel√°squez-Henao earned his BS c. in Civil Engineering in 1994, an \nMSc. in Systems Engineering in 1997, and a PhD in Energy Systems in \n2009, all from the Universidad Nacional de  Colombia in Medellin, \nColombia. From 1994 to 1999, he worked in electricity utilities and \nconsulting companies  on the power sector. In 2000, he joined the \nUniversidad Nacional de Colombia in Medellin and was appointed as a Full \nProfessor of Computer Science by 2012. Between 2004 and 2006, he served \nas an Associate Dean for Resear ch, and from 2009 to 2018, he led the \nComputing and Decision Science Department at the Facultad de Minas, \nUniversidad Nacional de  Colombia, Medellin  Campus. His research and \npublications span simulation, modeling, optimization, and forecasting in \nenergy markets. He specializes in nonlinear time- series analysis and \nforecasting using statistical and computational intelligence techniques, \nnumerical optimization with metaheuristics, and analytics and data science. \nHe currently instructs postgraduate courses in data science, machine \nlearning, and big data in the Analytics program, emphasizing Python \nprogramming. \nORCID: 0000-0003-3043-3037 \n \nC. J. Franco is a Full Professor at the Universidad Nacional de Colombia, \nMedell√≠n Campus, Medell√≠n, Colombia. He earned his MSc. in 1996 and his \nPhD in 2002, both from the Universidad Nacional de Colombia. Currently, \nhis research interests include energy markets, system dynamics, and \ncomplexity.  \nORCID: 0000-0002-7750-857X \n \nL. Cadavid earned a BSc. in Management Engineering in 2006, an MSc in \nSystems Engineering in 2010, and a PhD in Systems Engineering in 2015, \nall from the Universidad Nacional de Colombia, Medell√≠n, Colombia. She \ncurrently serves as an Assistant Professor at the Universidad Nacional de  \nColombia, Medell√≠n Campus. Her primary research focuses and publications \ninclude the diffusion of innovations, agent-based modeling and simulation, \nand clean energy. \nORCID: 0000-0002-6025-5940\n "
}