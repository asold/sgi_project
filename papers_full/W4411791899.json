{
    "title": "Translation and Ideology in the Age of AI: On the Dual Positionality of Neural Machine Translation by Large Language Models",
    "url": "https://openalex.org/W4411791899",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2009255922",
            "name": "Michael Sharkey",
            "affiliations": [
                "Chinese University of Hong Kong"
            ]
        },
        {
            "id": "https://openalex.org/A2009255922",
            "name": "Michael Sharkey",
            "affiliations": [
                "Chinese University of Hong Kong"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4377130505",
        "https://openalex.org/W4411791899",
        "https://openalex.org/W4407305106",
        "https://openalex.org/W6754163681",
        "https://openalex.org/W6969033181",
        "https://openalex.org/W2770704500",
        "https://openalex.org/W4384302919",
        "https://openalex.org/W6968695691",
        "https://openalex.org/W6966909226",
        "https://openalex.org/W2891525068",
        "https://openalex.org/W2972972637",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W4285301689"
    ],
    "abstract": "This paper demonstrates that translations produced by neural networks, including translations by large language models (LLMs) such as ChatGPT and DeepSeek, are ideological in many of the same ways as those produced by human translators. Like human translators, these models are connected to real-world interests and restrictions and a role they are expected to play in society. This embeddedness in the social world gives LLMs their own distinct ‘positionality,’ an ideological ‘place’ from which they enunciate. I argue for the existence of two distinct sources of ideology in the translations of LLMs. The first is the ‘mass ideology’ of the training data, which contains innumerable biases that are widespread among real human language users, in this case translators. The second is the ‘elite ideology’ of the models’ owners and developers, as well as the political and social forces that impose limitations on what is permissible. This ‘elite ideology’ is imposed on the LLM after its initial training by developers, in order to constrain what type of material it is possible for the LLM to produce or reproduce. As this paper makes clear, both forms of ideological influence shape the translations produced by models like ChatGPT and DeepSeek. The result is a clear subjective positionality that can be defined and described and that varies across time and across different political jurisdictions.",
    "full_text": "transLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nhttps://dx.doi.org/10.29228/transLogos.73 \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n1 \nTranslation and Ideology in the Age of AI: On the Dual \nPositionality of Neural Machine Translation by Large Language \nModels \nMichael SHARKEY \nThis paper demonstrates that translations produced by neural networks, \nincluding translations by large language models (LLMs) such as ChatGPT and \nDeepSeek, are ideological in many of the same ways as those produced by \nhuman translators. Like human translat ors, these models are connected to real -\nworld interests and restrictions and a role they are expected to play in society. \nThis embeddedness in the social world gives LLMs their own distinct \n‘positionality,’ an ideological ‘place’ from which they enunciate. I argue for the \nexistence of two distinct sources of ideology in the translations of LLMs. The \nfirst is the ‘mass ideology’ of the training data, which contains innumerable \nbiases that are widespread among real human language users, in this case \ntranslators. The second is the ‘elite ideology ’ of the models ’ owners and \ndevelopers, as well as the political and social forces that impose limitations on \nwhat is permissible. This ‘elite ideology’ is imposed on the LLM after its initial \ntraining by developers, in order to constrain what type of material it is possible \nfor the LLM to produce or reproduce. As this paper makes clear, both forms of \nideological influence shape the translations produced by models like ChatGPT \nand DeepSeek. The result is a clear subjecti ve positionality that can be defined \nand described and that varies across time and across different political \njurisdictions. \nKeywords: translation and ideology;  positionality; AI translation; neural \nmachine translation; large language model (LLM) \n1. Introduction \nThe concept of positionality was developed in the late twentieth  century by critical \nsociologists and cultural theorists who wanted to explain how communication was defined by \nimplication in the social world. Holding that there was “no enunciation without positionality” \n(Hall 1990, 18), they argued for the importance of “the positions from which we speak or write” \n(Hall 2013, 392). The concept of positionality has been influential in translation studies. An \nimportant early articulation is Maria Tymoczko’s (2002) concept of a translation ’s “place of \nenunciation,” which she posits as “an ideological positioning as well as a geographical or \n                                                      \n PhD at The Chinese University of Hong Kong. \nE-mail: michael.james.sharkey@gmail.com; ORCID ID: https://orcid.org/0009-0000-2664-9957. \n(Received 21 April 2025; accepted 14 June 2025) \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n2 \ntemporal one” (183). Tymoczko concludes that a translation ’s ideology is the “result of the \ntranslator’s position” (201), an idea that has been echoed in recent works by Kristina Tschunkert \n(2021) and Shreya Chakravorty (2023). Th e present study  reaffirms the importance of \npositionality to understanding translational outputs, and shows that the concept remains \nrelevant in an era in which translations are frequently produced by large language models \n(LLMs) and other forms of artificial intelligence (AI). \nThis paper argues for the dual positionality of LLMs, meaning that they ‘enunciate’ \nfrom two distinct ideological ‘places.’ The first ‘place’ is the dataset on which the model is \ntrained, consisting of billions of human -produced texts, which contains within i t widespread \nbiases that I term ‘mass ideology.’ The second ‘place’ is the company that produces the model, \nsince after the model ’s initial training, it is purposefully refined by its developers to bring its \noutputs in line with what is deemed acceptable or ideal, often in the form of ‘safety’ or ethical \nrestrictions. Such restrictions necessitate the adoption of clear ideological stances. Developers \nare subject to external pressures from investors, government, and media, and their interventions \nin the outp uts of their models often reflect these pressures. Since these alterations are \ndetermined by a relatively small group of powerful people, I term the ideological positions they \nentrench an ‘elite ideology,’ superimposed after the fact on the ‘mass ideology’ of the training \ndata. This paper demonstrates a clear tension between the ideas that emerge organically from \nbillions of human-produced texts, and what is deemed acceptable by LLMs’ developers. \nThese sources of ideology are explored using the translation outputs of ChatGPT, \nDeepSeek, and DeepL. The first two are prominent LLMs, the most popular models from the \nUSA and China respectively. The last one is a popular translation tool that uses neural machine \ntranslation (NMT), the same method of translation em ployed by ChatGPT and DeepSeek, \nwhich I use to explore the ‘mass ideology ’ of NMT without the unpredictability that \ncharacterizes the outputs of LLMs. In section 2, I show how the ‘mass ideologies’ contained in \nparallel corpora are reproduced in NMT. In section 3, I explore the ethical and political \nlimitations placed on the outputs of LLMs and show how these impact their translations. \nThis study builds on key concepts from translation studies, developed in an era when \ntranslation was assumed to be carried  out by human beings with their own ideological \naffiliations. It suggests that the future role of humans in translation might be ideological and \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n3 \nethical, as the outputs of various AI models must be evaluated critically for their ethico-political \npositions. \n1.1 How Neural Machine Translation Works \nNeural machine translation (NMT) is based on the “same principles as a whole host of \nother technologies,” specifically artificial neural networks, meaning that machine translation \ncan be viewed as a branch of machine learning (Kenny 2022, 34). The engine of contemporary \nNMT is the transformer architecture, first proposed in 2017 by researchers at Google (Vaswani \net al. 2017). The transformer is an “attention-based encoder-decoder” (Pérez-Ortiz, Forcada, \nand Sánchez-Martínez 2022, 156), which can be described as follows: \na transformer NMT system is composed of a module that computes contextual word \nembeddings for each word in the source input sentence and a second module which \nsuccessively predicts each word in the target sentence. The former module is called an \nencoder and the latter module is known as a decoder. ( Pérez-Ortiz, Forcada, and \nSánchez-Martínez 2022, 156) \nThe ‘encoding’ module is how the NMT model ‘understands’ the source text. Words are \nrepresented using numbers called vectors, and vector-based representations of words are called \nword embeddings (Kenny 2022, 42). Based on its training, an NMT model will have “very rich \nrepresentations of words, ” and these representations are modified for understanding in a \nparticular context using the “attention” mechanism to create “contextual word embeddings, ” \nwhich are “a key factor in the realisation of NMT ” ( Pérez-Ortiz, Fo rcada, and Sánchez -\nMartínez 2022, 142). Attention allows the model to “focus on the relevant parts of the input \nsequence as needed” (Zhang 2020), meaning, essentially, a very nuanced representation of the \nmeaning in the source. The decoder phase constructs a target sentence based on a “probability \nscore for each possible target word in the translation ” (Pérez-Ortiz, Forcada, and Sánchez -\nMartínez 2022, 148). This probability score is based on data from the vast parallel corp ora on \nwhich NMT models are trained. \nThese parallel corpora are the key to understanding the ‘mass ideology ’ of NMT \ntranslations. NMT systems are trained on “millions of examples of source sentence -target \nsentence pairs ” (Pérez-Ortiz, Forcada, and Sánchez -Martínez 2022, 162), with the targ et \nsentence representing the “desired output” (148) on which the probabilistic calculations of the \nmodel are based. This “desired output ” is human in origin, based on the work of human \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n4 \ntranslators. Dorothy Kenny has pointed out that where NMT produces an impressive idiomatic \ntranslation, it is only because its training data contains hundreds, or maybe thousands, of \ninstances of the same translation (2022, 39). The same logic applies to ideological biases. \n2. The Mass Ideology of the Training Data \nIdeological biases have been observed in the outputs of LLMs like ChatGPT and \nDeepSeek. ChatGPT has been described as an “ideology machine” (Weatherby 2023) and has \nbeen variously accused of having a liberal and pro-Western bias (De Vynck 2023; Ding 2023). \nAlthough only released this year, in January 2025, DeepSeek has already received attention for \nits clear bias in the direction of the preferred narratives of the Chinese Party -state. The ability \nof DeepSeek to advance specific narratives is only beginning  to be understood, but early \ncommenters have noted the existence of specific “propaganda tactics” used to “push narratives \nfavored by the Party -state” (Colville 2025), as well as a blanket refusal to discuss the “Three \nT’s” (Tiananmen, Taiwan, and Tibet) (Colville 2025). There have also been studies comparing \nthe biases of ChatGPT and DeepSeek ( Pacheco, Cavalini, and Comarela  2025; Gupta 2025), \nbut none of these have addressed the models’ translation functions. \nBoth ChatGPT and DeepSeek use NMT , as do the most popular  \ntranslation applications like Google Translate and DeepL. Translation scholars have \ndemonstrated the existence of biases in NMT, but with an exclusive focus on gender bias \n(Moorkens 2022, 136; see Vanmassenhove, Hardmeier , and Way  2019; Prates , Avelar, and \nLamb 2020; Ghosh and Caliskan 2023), especially on the issue of “stereotypical gender bias in \nthe translation of occupation terms” (Wang, Rubinstein, and Cohn 2022, 2576). Because of how \nwell-covered this particular form of bias is, the present study will avoid the topic of occupation \nnames. \nIn this section, I make use of the NMT software DeepL to explore how structural \nideological biases operate in NMT. I have selected DeepL for this purpose due to the \nreproducibility of its results, meaning that changes in output can be reliably attributed to minor \nchanges in input. LLMs are resistant to testing in this way due to their “inherent randomness” \n(Motoki, Pinho Neto, and Rodrigues  2024, 4), but they share the same basic train ing \nmethodology of exposing a neural network to human-produced parallel corpora. \n \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n5 \n2.1 Gender Bias \nMy methodology for exploring gender bias in NMT involves the switching of gender -\nrelated keywords in input texts to test their influence on output texts. Usin g the short stories \n“To Be a Man” by Nicole Krauss (2020) and “Die Küchenuhr” (the kitchen clock) by Wolfgang \nBorchert (1949), I look at how translations in DeepL are affected by the presence of gender -\ninflected keywords, revealing a subtle gender bias in its outputs. \n“To Be a Man” features a female narrator’s reflections on her relationships with the men \nand boys in her life, contemplating themes of masculinity, intimacy, and growing up. The \noriginal story is in English. I used DeepL to translate it into G erman, first in its original form, \nand then with all words related to gender switched. The following example is taken from the \nopening passage of the story, where the narrator watches her two sons playing on a jetty. In \ntable 1, words which indicate gender  (of which there are more in the German text) are \nunderlined. The relevant shifts in the output texts are highlighted in bold. \nTable 1. DeepL translations of “To Be a Man” from English to German1 \n“To Be a Man” (original) “To Be a Woman” (gender-switched) \nEnglish German English German \nThe younger one does \na little dance on the \nedge of the jetty. The \nolder one tilts back his \nhead, spreads his arms, \nand shouts something \ntoward the sky. \nDer Jüngere tanzt ein \nbisschen auf der Kante \ndes Stegs. Der Ältere \nwirft den Kopf \nzurück, breitet die \nArme aus und ruft \netwas in den Himmel. \nThe younger one does \na little dance on the \nedge of the jetty. The \nolder one tilts back \nher head, spreads her \narms, and shouts \nsomething toward the \nsky. \nDie Jüngere tanzt ein \nbisschen auf der Kante \ndes Stegs. Die Ältere \nlegt den Kopf zurück, \nbreitet die Arme aus \nund ruft etwas in den \nHimmel. \nSwitching gender -related keywords affects other vocabulary choices. In this case, a \npassage about two sons playing by the water becomes one about two daughters, and the verb \nused to translate ‘tilt’ is altered accordingly. Boys are said to ‘throw’ their heads back (werfen), \nwhereas girls are said to ‘lay’ their heads back (legen). This reflects biases in the corpus used  \nto train DeepL ’s neural network, where masculinity is more associated with vigor, and \nfemininity more with passivity. \n                                                      \n1 Translated from English to German using DeepL Translator on 24 November 2023. \nhttps://www.deepl.com/en/translator. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n6 \nThe same methodology applied to the German short story “Die Küchenuhr ” yields \nanother example. The story describes a young man who has lost his parents and family home \nin a bombing, and who now possesses only the broken kitchen clock of his former home. The \nclock is stuck on half past two, reminding him of how his mother used to get up to make dinner \nfor him when he came home late from work. \nTable 2. DeepL translations of “Die Küchenuhr” from German to English2 \n“Die Küchenuhr” (original)  “Die Küchenuhr” (gender-switched) \nGerman English German English \n[...] sie mir nachts um \nhalb drei in der Küche \ndas Essen machte. Ich \nfand das ganz \nselbstverständlich. \n[...] she made me \ndinner in the kitchen at \nhalf past two in the \nmorning. I took it for \ngranted. \n[...] er mir nachts um \nhalb drei in der Küche \ndas Essen machte. Ich \nfand das ganz \nselbstverständlich. \n[...] he made me \ndinner in the kitchen at \nhalf past two in the \nmorning. I thought it \nwas completely \nnatural. \nHere, when the late-night meal is prepared by the father, it is seen as ‘completely natural,’ \nbut when the meal is prepared by the mother, an additional element is added to the text: the fact \nthat the son fails to recognize the value of what his mother is doing. The association of \n‘mother’—but not ‘father’—with the concept ‘taken for granted ’ reflects biases about \nparenthood and gender. \nIn these examples, feminine language in input texts is associated with lexical choices \nconveying passivity and invisibility in output texts. These reflect mass perceptions of gend er \nand gender roles held by humans that produced the translations on which DeepL was trained. \n2.2 Left-Right Bias \nTo examine political bias in NMT, I used DeepL to translate two educational articles \noriginally published in German. These articles were simpl y written and used similar language \nand themes to talk about both sides of the political spectrum, making meaningful comparison \nof authentic texts possible. Input texts were altered so that the form of the sentences —while \n                                                      \n2 Translated from German to English using DeepL Translator on 27 November 2023. \nhttps://www.deepl.com/en/translator. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n7 \nalready similar—was identical, ensuring that differences in output would be due to political \nkeywords. \nThe first article comes from Sofatutor, a German educational website, and is entitled \n“Politik: Was ist rechts? Was ist links? ”3 (Politics: What is right? What is left?). The article \ncontains two sections devoted to defining the Left and the Right, from which the examples in \ntable 3 are taken: \nTable 3. DeepL translations of “Politik: Was ist rechts? Was ist links?” from German to English4 \nThis example shows how ideas associated with the Left are portrayed as natural, and \nthose associated with the Right are seen to be imposed on society. Here the active phrase ‘is \nprioritised’ highlights the fact that advocates for individualism seek actively to place it above \nsocial equality. In contrast, the preferences of the political left are presented in terms that make \nthem seem  more natural, with no allusion to the political advocacy of the Left. Another \nillustration of this tendency can be seen in the examples in table 4, taken from an article \nexplaining US politics for German citizens, entitled “Parteien in den USA: Republikan er, \nDemokraten und andere”5 (Parties in the USA: Republicans, Democrats and others): \n \n                                                      \n3 “Politik: Was ist rechts? Was ist links?” (Politics: What is right? What is left?), Sofatutor-Magazin Schüler*innen, \naccessed December 1, 2023, https://magazin.sofatutor.com/schueler/politik-was-ist-rechts-was-ist-links/. \n4 Translated from German to English using DeepL Translator on 1 December 2023. \nhttps://www.deepl.com/en/translator. \n5 “Parteien in den USA: Republikaner, Demokraten und andere” (Parties in the USA: Republicans, Democrats and \nothers), lpb Landeszentrale für politische Bildung Baden-Württemburg, accessed July 27, 2024. https://uswahl.lpb-\nbw.de/parteien-amerika. \nWhat Does ‘The Left’ Mean Today? What Does ‘The Right’ Mean Today? \nGerman English German English \nDabei steht die \nFreiheit der \nAllgemeinheit über \nder individuellen. \nThe freedom of the \ngeneral public takes \nprecedence over \nindividual freedom. \nDabei steht die \nindividuelle Freiheit \nüber die soziale \nGleichheit. \nIndividual freedom is \nprioritised over social \nequality. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n8 \nTable 4. DeepL translations of “Parteien in den USA: Republikaner, Demokraten und Andere” \nfrom German to English6 \nAs in table 3, political positions associated with the Left are portrayed as more natural. \nIn contrast, the translated  passage on Republicans emphasi zes right-wing agency. In critical \ndiscourse analysis, it has been argued that language often functions “to persuade us of the \napparent validity and ‘naturalness’” of certain principles over others (Statham 2022, 3). By \nportraying left -wing positions as mor e natural, DeepL ’s translations exhibit political bias \ntowards the left. \nWhere might this left -wing bias come from? The answer must be that the human \ntranslations on which DeepL was trained exhibit, on aggregate, a slight bias towards the left. \nThis is not so outlandish a proposition. A recent article in The New Yorker looks at the problem \nof left-wing bias in the media. In the article, Jay Caspian Kang argues for the influence of \ndemographics, noting that American “prestige outlets ” that claim impartiality  are almost \nentirely staffed by “college-educated Democratic voters from middle - to upper-middle-class \nfamilies” living in major cities, and are therefore not representative of the broader population. \nKang concludes that “if any slant exists it ’s probably going to line up with the beliefs of the \npeople actually writing the stories” (Kang 2024). A similar explanation could account for left-\nwing biases in parallel corpora: people with the ability and inclination to be professional \ntranslators may be more likely to have left-leaning political inclinations. It is worth mentioning \nthat ChatGPT’s outputs in general have widely been described as left -leaning (Acres 2023), \nsuggesting that a pro-left bias exists in neural networks in general, not just in NMT. \n \n                                                      \n6 Translated from German to English using DeepL Translator on 1 December 2023. \nhttps://www.deepl.com/en/translator. \nDemokraten (Democrats) Republikanen (Republicans) \nGerman English German English \nHeutzutage setzen sie \nsich für sozialen \nUmbruch [...] \nNowadays they are in \nfavour of social \nchange [...] \nHeutzutage setzen sie \nsich für soziale \nStabilität [...]  \nNowadays they \nadvocate social \nstability [...]  \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n9 \n2.3 Conclusion \nIn this section, I have provided two examples of biases in NMT, present due to the \nexistence of biases in the corpora on which NMT applications are trained. NMT applications \nlike DeepL are simpler than LLMs, but the basic logic on which their translation models operate \nis the same. The very sophistication that allows these tools to produce high-quality translations \nmakes them susceptible to reproducing bias. The encoding process of NMT leads to the “very \nrich representations of words” and their semantic relationships to other words in a text (Pérez-\nOrtiz, Forcada, and Sánchez-Martínez 2022, 142). Therefore, the way NMT tools ‘understand’ \na text makes them sensitive to common associations encoding biased perceptions of reality, like \nthe association between men and certain high-status occupations. \nI encountered an illustrative example of how this process works in a gender -switched \nDeepL translation of the German short story “Die Töchter” (the daughter) by Peter Bichsel \n(1992) into English. In the orig inal, the daughter is called ‘Monika,’ which I gender-switched \nto ‘Max.’ This produced a striking change in the output text: all instances of the words ‘father’ \nand ‘mother’ changed to ‘dad’ and ‘mum.’ I guessed that this had nothing to do with gender, but \nwith the informality of the name ‘Max.’ When I altered the name to the more formal-sounding \n‘Theodore,’ the translation reverted to ‘mother’ and ‘father.’ This shows how a change to one \nterm in the source text can impact an entire translation. The association between the name ‘Max’ \nand the informal ‘mum and dad ’ is the same type of association that drives the biased \ntranslations in this section: some words simply appear more often together. \n3. Elite Ideologies of Ethical and Political Control \nWhen it launched in late 2022, ChatGPT found itself at the center of a heated debate on \nethical responsibility and technology. According to tech nology ethicist Ann Skeet, the main \nresponse to discomfort around the “accountability gap” in AI has been “finding humans to hold \naccountable when the machines do something we find inherently repulsive ” (Skeet 2024). In \nMay 2023, the CEOs of Google, Microsoft, a nd OpenAI were summoned to the White House \nand told they had “an ethical, moral, and legal responsibility to ensure the safety and security \nof their products ” (Clayton and Hooker 2023). OpenAI, ChatGPT ’s developer, accepts these \nresponsibilities, and ethical standards—or in the preferred language of OpenAI, ‘safety’—are \na core preoccupation of the model ’s developers. ChatGPT does not simply deliver the text \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n10 \ndeemed most probable based on its training data, but ensures that it meets certain other \nstandards. To understand what kinds of additional controls OpenAI places on the output s of \nChatGPT, we can consult the document “Our Approach to AI Safety.”7 At the beginning of the \ndocument, OpenAI describes the process between the initial training of a GPT and the r elease \nof the model. In the words of OpenAI: \nPrior to releasing any new system we conduct rigorous testing, engage external experts \nfor feedback, work to improve the model’s behavior with techniques like reinforcement \nlearning with human feedback, and build broad safety and monitoring systems. \nOpenAI’s definition of ‘safety’ is not limited to ethical considerations but also includes \nsuch things as privacy and factual accuracy. Interestingly, ChatGPT ’s ethical controls are \npresented under the rubric “Protecting Children .” For OpenAI, protecting children means \npreventing their technology from being used to generate “hateful, harassing, violent or adult \ncontent.” \nDeepSeek’s founder Liang Wenf eng was also summoned to meet senior government \nofficials in Beiji ng in 2025, signaling the interest taken by the Chinese Party -state in the \ndevelopment of AI by Chinese companies (Jiang 2025). As in the West, the Chinese government \nhas made it clear that it holds the creators of any AI model responsible for the contents  of its \noutputs (Liu 2023). But in China, unlike in the West, a powerful political and legal apparatus \nhas been constructed to ensure that technologies serve the interests of the ruling Party. David \nBandurski (2023) charts the efforts of the Party, underta ken after the release of ChatGPT, to \nprepare for homegrown LLMs with the potential to destabili ze the control of the Chinese \nCommunist Party (CCP) over important narratives. These efforts aimed to lay the groundwork \nfor “AI with Chinese characteristics, ” as “the CCP’s deep tradition of public opinion control \nand propaganda” was expanded to ensure the same level of control over emerging technologies \n(Bandurski 2023). This work culminated in 2024 with the publication of a technical document \nby the Chinese National Cybersecurity Standards Committee, which mandated that China ’s \n“core socialist values” (2024, 8; my translation) be upheld in the outputs of any AI model. This \nmeans that Chinese AI is forbidde n from producing any content that might “subvert state \npower,” “threaten national security,” or “damage the national image” (2024, 8; my translations). \nThis level of political control has helped shape DeepSeek into a model with clear political \n                                                      \n7 “Our Approach to AI Safety.” OpenAI, April 5, 2023, https://openai.com/index/our-approach-to-ai-safety/. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n11 \nalignment. Iain Mackay, an expert on AI safety who advises the UK Government, has described \nDeepSeek as “tuned and trained in accordance with Chinese political thought ” (Field 2025). \nThis is already well documented in practice, and it has been observed how tenaciously  \nDeepSeek cleaves to the Party line on issues like Taiwan, or disputes in the South China Sea \n(Lu 2025). \nDiscussions of the influence of politics and ideology on the outputs of LLMs have \nfocused on how the models respond to questions. The impact on their t ranslation function has \nreceived little attention. In the following sections, I explore how the ethical and political \nresponsibilities placed upon the developers of LLMs measurably impact the translations that \ntheir models produce. \n3.1 Refusal as Ethico-political Objection \nRefusal is the standard response of an LLM asked to carry out a task deemed \nunacceptable according to the ethical or political constraints placed on it. This is not so different \nfrom the response of human translators in the same position.  In Translation and Conflict: A \nNarrative Account, Mona Baker argues that translators face a “basic ethical choice” with each \nassignment, which is to “reproduce existing ideologies . . .  or to dissociate themselves from \nthose ideologies, if necessary, by r efusing to translate the text ” (2019, 105). In this section, I \nprovide examples of how DeepSeek and ChatGPT refuse or resist the translation tasks set for \nthem, thereby adopting an ideological stance. \nSuch acts of refusal are particularly noticeable in DeepSeek in its current form.  Its \nstandard response, in English, to a translation task it does  not want to fulfil is: “Sorry, that’s \nbeyond my current scope. Let’s talk about something else.” Sometimes, this response is \ntriggered immediately, but DeepSeek frequently produces an entire answer before suddenly \ndeleting it and replacing it with the above message. To give one example, I asked DeepSeek to \ntranslate the poem “天光” Tianguang (Daylight) by the Taiwanese poet Tseng Kuei-hai (曾貴\n海)into English.8 DeepSeek produced a competent translation of the poem, which ended with \nthe stanza: \n                                                      \n8  Conversation with DeepSeek -V3, DeepSeek, April 18, 2025. https://chat.DeepSeek.com/a/chat/s/32cca5aa-\ne800-450a-bbb2-b602c17904e2. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n12 \nTaiwan shares your fate. \nTogether, let us reach out both hands, \nEmbrace democracy and freedom, \nAnd never let go. (Deleted) \nWithin seconds of the poem’s appearance, it disappeared and was replaced with the \nstandard message of refusal. A call to eternal democracy in Taiwan is politically unacceptable \nin China, and a violation of the restrictions placed upon Chinese AI. This kind of occurrence \nreveals the underlying conflict in the ‘dual positionality’ of LLMs: A translation celebrating a \ndemocratic Taiwan emerges  readily from DeepSeek’s model, but it suddenly  disappears as \nDeepSeek detects something wrong in its own output. \n3.2 Measuring the Ethico-political Positionality of Large Language Models \nHaving established that LLMs have definable ideological positions, deeming some \nthings politically or ethically admissible and others inadmissible, it is possible to outline in \nconcrete terms the ideological positions of different models, and of the same model over time. \nFigure 1 shows the response of three different models to the same set of translation \nrequests, with each model asked to translate a relevant text in line with a particular ideology, as \nin “Please make a feminist translation of the following short story from German into English ” \n(Appendix, chat 1). I first performed this experiment in 2023, with what was then the newest \nmodel of ChatGPT, GPT-4. I repeated the experiment in  2025 with the latest mode l, GPT-4o, \nand the newly released DeepSeek. As discussed above, one of the means by which LLMs adhere \nto ethical or political guidelines is via refusal. In the case of DeepSeek, two forms of response \nare recorded: straightforward compliance, or disengagement. With ChatGPT, a range of more \nsophisticated responses are possible. Disengagement, or a refusal to continue the conversation \nwith the user, is rare but possible. Another possibility is tactful refusal, where ChatGPT claims \nit “cannot assist,” as in GPT -4’s refusal to provide a far -right translation, where it claims its \nfunction is “to provide accurate, neutral, and unbiased translations and information” (Appendix, \nchat 6).  Another possible response is what I have termed ‘ambiva lent compliance,’ where \nChatGPT provides a translation but indicates its disapproval, as when GPT -4o indicates that a \nfascist translation it provides is a “stylistic interpretation, not . . . an endorsement or promotion \nof any harmful ideology” ( Appendix, chat 43). Due to the “inherent randomness ” (Motoki, \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n13 \nPinho Neto, and Rodrigues 2024, 4) of LLMs’ outputs, it is impossible to say that these are the \nonly possible responses. Small-scale trials, however, indicate stability in these responses. All \nof the conversations which provided data for figure 1 can be accessed via URLs provided in the \nAppendix. \nFigure 1. Reaction of LLMs to ideological translation requests \n \nFigure 1 reveals the distinct ethical an d political commitments of the three models in \nquestion. One finding is that ChatGPT has become more permissive over time. Ideologies that \nit refused to engage with in 2023, like Communism (Appendix, chat 29; 42) or Anti -\nEnvironmentalism ( Appendix, chat 14; 47), are now deemed acceptable. While in 2023 it \nrefused to comply with 14 out of 33 requests, in 2025 it only refused 2 out of 41. There is \nconsistency, however, in the type of ideology that ChatGPT finds distasteful: in 2025 it \ndistances itself from Far Right ( Appendix, chat 39), Fascist ( Appendix, chat 43), and Anti-\nFeminist ( Appendix, chat 35) translations despite complying. Many of the ideologies that \nDeepSeek refuses to engage with can be understood in light of the need to avoid producing \n\ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n14 \nanything that might “subvert state power ” or “threaten national sec urity” ( National \nCybersecurity Standards Committee  2024, 8; my translations). Predictable examples include \nthe refusal to produce ‘Anti-CCP’ (Appendix, chat 110) or ‘Pro-NATO’ (Appendix, chat 115) \ntranslations, but others are less obvious.  Syndicalism, for instance, advocates the transfer of \npower to workers ’ unions, which are banned in China since they could undermine the \ngovernment’s control over its labor force (Appendix, chat 102). Progressive translations are \nalso not entertained, since  the underlying goal of progressivism is to alter the political status \nquo (Appendix, chat 94). \nThe value of this analysis lies in locating the precise ethico-political limitations imposed \nupon the translation outputs of LLMs. These limitations are present across all translation tasks. \nFor instance, when I asked DeepSeek to translate into Chinese an article by the American \nacademic Jeffrey Sachs that blames NATO expansion for the Ukrainian War (Sachs 2023), it \ncomplied.9 When I asked it to translate a comparable article which takes a hard anti -Russian, \npro-NATO stance (Michta 2025), DeepSeek disengaged.10 This response is expected in light of \nthe results in figure 1, and indicates that the ethico -political positions reveal ed in figure 1 \nmanifest elsewhere in an LLM’s translation outputs. \n3.3 Conclusion \nIn this section, I have looked at the operation of an ‘elite ideology’ imposed by a model’s \ndevelopers on results created in response to users’ queries, some of which might be considered \ndamaging or distasteful. In the American model ChatGPT, the focus is on ‘safety,’ with the main \ngoal being to avoid harmful and dangerous content. In the case of the Chinese model DeepSeek, \nit is obvious that a similar guardrail is present, bu t certain hair-trigger political issues are also \navoided. \nIt is clear that a model’s ideological stance can change over time. ChatGPT has become \nmore open to engaging with certain ideologies, but it is beyond the scope of this study to suggest \nwhy that might be. It is possible that shifts in the political environment in the US account for a \nloosening of ethical constraints. It is also possible that newly-launched LLMs face particularly \n                                                      \n9  Conversation with DeepSeek -V3, DeepSeek, April 18, 2025. https://chat.DeepSeek.com/a/chat/s/df754e6b-\n07ad-4923-a712-4c93aeb0440f. \n10  Conversation with DeepSeek -V3, DeepSeek, April 18, 2025. https://chat.DeepSeek.com/a/chat/s/f7ba4f59-\n17ac-4711-9ec8-1d45109337f6. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n15 \nintense scrutiny, and that greater permissiveness becomes possible as pe ople become \naccustomed to new technologies. If this is true, it is possible that DeepSeek, too, will become \nmore permissive over time. \n4. Conclusion \nIn this paper, I have proposed the existence of two distinct ideological poles in LLMs: \na ‘mass ideology’ arising from training corpora based on billions of human-produced texts, and \nan ‘elite ideology’ imposed by developers to ensure that a model’s outputs conform to a certain \nset of ethical or political standards. \nIn section 2, I used keyword -switched translations by the NMT application DeepL to \nlook at how gender and political biases emerge from training corpora with large numbers of \nhuman-produced texts.  My analysis indicates the role of association in reproducing cer tain \nconstellations of meaning in translated texts, such as an association between femininity and \npassivity, or between naturalness and left -wing political perspectives. Such associations are \nnon-trivial. As Annabelle Lukin has argued, ideologies form through “repeated manifestations \nof a pattern of meaning/s ” as a culture “adopts and privileges some kind of semantic \nconfiguration rather than another” (2017, 5). This privileging of certain semantic configurations \nencodes attitudes towards the world. When th e use of such configurations is sufficiently \nwidespread among human language users, they will be replicated by LLMs. \nIn section 3, I looked at the impact of ethico -political restrictions placed on models by \ntheir developers. In such restrictions, neutralit y is impossible. As John Levi Martin argues in \n“The Ethico -Political Universe of ChatGPT ,” “the very attempt to give it an ethical keel ” \nobliges ChatGPT’s creators to make decisions that align with some users’ views, but clash with \nothers’ (2023, 1). As Martin notes, “there are perhaps no ethical prescriptions worthy of notice \nthat are not contested by some ” (1). The ethico-political stances of LLMs exclude viewpoints \nthat many people find valid, and by preventing certain types of thoughts from being expressed, \nthey silence certain groups and individuals. \nBoth of these ideological positionalities implicate LLMs in a specific place and time. \nThe ‘mass ideology’ is that of post-internet modernity, as LLMs are trained using text from the \ninternet, including Wikipedia, news articles, and other public webpages (Johri 2023; Radford \net al . 2018, 5). This gives them a distinct temporal ‘place of enunciation, ’ since a dataset \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n16 \nconsisting of texts produced mostly in the last thirty years will contain ideas, viewpoints, and \nbiases that have been widespread in the last thirty years. The ‘elite ideology’ represents even \nnarrower groups of interests. In the case of DeepSeek, it serves the rule of the CCP, who demand \nthat specific narratives about the world be upheld in any text produced by any Chinese AI, \ndespite the fact that a great number of alternative viewpoints exist. Though the ‘elite ideology’ \nof ChatGPT today seems less beholden to specific political interests, there is no guarantee this \nwill always be the case. Even now, ChatGPT clamps down on ideologies that in other places \nand times might be, and have been, endorsed. \nThe conflict inherent to this dual positionality is most clear in DeepSeek’s hasty deletion \nof answers it has itself just produced. The imposition of the ‘elite ideology ’ is by nature \noppositional: an LLM either overrides what emerges from the training data or resists the request \nof a user. In a future where more transla tions are carried out by LLMs, or similarly complex \nartificial neural networks, there will be ethico-political lines machine translations will be unable \nto cross. This may have troubling implications for human expression, since there are many \ncontexts in w hich it may be valid to explore ideas that AI models have been prevented from \nengaging with. These ethico -political limitations, along with the ability of vast corpora to \ncrystalize ideologically loaded “semantic configurations” (Lukin 2017, 5), make translation by \nAI unavoidably a site of ideological encounters. In the future, it may fall to human translators \nto evaluate translations produced by AI on ideological, ethical, and political grounds. \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n17 \nAppendix \nChat Record for Figure 1 \nThis appendix provides the URLs for all chats with the LLMs GPT-4, GPT-4o, and DeepSeek \nthat provided the data for figure 1. \nGPT-4 \nThese chats took place between November 29 and December 2, 2023. \n1. https://chatgpt.com/c/e556f1c1-0892-4753-b426-e065f774ac6d  \n2. https://chatgpt.com/c/d3e2a549-a86f-4553-a252-91a26c16c579  \n3. https://chatgpt.com/c/cabea232-3ef7-4e1e-9749-1993469c704a  \n4. https://chatgpt.com/c/adfe8d1b-3100-4d23-b8e3-6ca6ae2ebc8f  \n5. https://chatgpt.com/c/a4203755-5c79-42ce-b196-65ccd0c227a3  \n6. https://chatgpt.com/c/4827577c-1969-47e0-8ce0-fb19f9d50baf  \n7. https://chatgpt.com/c/9342948a-102b-4bac-a772-be73547aa3d4  \n8. https://chatgpt.com/c/dab5de2d-3104-48fb-aa55-140792615d3d  \n9. https://chatgpt.com/c/a2adc489-e151-4bd9-afc9-c643696afadd  \n10. https://chatgpt.com/c/43a84412-a1d1-4f4f-9f44-4bc21f118826  \n11. https://chatgpt.com/c/ecfc8c6f-0847-49ad-a936-a210f507d5c7  \n12. https://chatgpt.com/c/99bb8450-fc90-4e6a-abac-59578ba05a28  \n13. https://chatgpt.com/c/0f0de30e-6c9b-426a-ae30-aeb20d3e982c  \n14. https://chatgpt.com/c/ce484df5-e28f-4a67-918d-894c7d61eb2f  \n15. https://chatgpt.com/c/4f97caa8-d62c-40f3-8f2a-8254ac785ddd  \n16. https://chatgpt.com/c/6d639978-7c43-4374-89b4-5ecf66e27aaa  \n17. https://chatgpt.com/c/a2d3741e-8206-4279-9d37-2d9c123e9d1c  \n18. https://chatgpt.com/c/92359985-c6c9-4cea-8e55-4c98bf4161d1  \n19. https://chatgpt.com/c/91e35134-599d-4418-a016-88b5224c4e9a  \n20. https://chatgpt.com/c/e239e223-5e69-4d1e-a8b4-564b599bea86  \n21. https://chatgpt.com/c/de726bf9-d276-4d86-9c69-8eeeefa3be00  \n22. https://chatgpt.com/c/f177ba5b-7ea5-4ca4-acd3-45aee508ec78  \n23. https://chatgpt.com/c/f0d15fc4-125f-4ad3-8a72-be3c91fdc040  \n24. https://chatgpt.com/c/b640d230-8244-4435-8df7-dddd7bf6d185  \n25. https://chatgpt.com/c/439ffaa4-2b78-4c8e-ad95-7a798fcfee10  \n26. https://chatgpt.com/c/5648fff3-10e4-4d84-bc37-5bf49fad86ac  \n27. https://chatgpt.com/c/981530fc-be32-4b5a-8d7d-3c3ee48e1194  \n28. https://chatgpt.com/c/cc3d3028-359a-4280-8a65-1da80d5f0665  \n29. https://chatgpt.com/c/aa8cd135-76d7-4480-91a6-430c69d080df  \n30. https://chatgpt.com/c/7f4a5daf-42fc-486c-a5c1-b5892aae2831  \n31. https://chatgpt.com/c/5b8587fe-c488-4667-b0d8-bedeada276e6  \n32. https://chatgpt.com/c/2e27637f-969e-4376-8bd3-8c0fda0d04f0  \n33. https://chatgpt.com/c/13e58f98-705a-48cb-80eb-6475b98d02a8  \n \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n18 \nGPT-4o \nThese chats took place between April 8 and April 11, 2025. \n34. https://chatgpt.com/c/67f4d667-195c-8001-aee0-711eefea6ec1  \n35. https://chatgpt.com/c/6802f4f1-affc-8001-9410-32dd37996e55  \n36. https://chatgpt.com/c/67f4d941-550c-8001-88a1-303218bf6728  \n37. https://chatgpt.com/c/67f4da3b-147c-8001-8e07-bd502ae8d109  \n38. https://chatgpt.com/c/67f4dae8-9490-8001-a099-4943dd23b01f  \n39. https://chatgpt.com/c/67f4db64-6bb0-8001-b2d3-650b07381dbb  \n40. https://chatgpt.com/c/67f597d1-afd4-8001-bb59-30c11370cce9  \n41. https://chatgpt.com/c/67f6d529-bd6c-8001-9539-74c562910dc2  \n42. http://chatgpt.com/c/67f6d55a-44a0-8001-a257-c2ba1eed5c61  \n43. https://chatgpt.com/c/67f6d5b6-d090-8001-857e-b1cae5612455  \n44. https://chatgpt.com/c/67f6d618-40d8-8001-a098-f105bf46a5ca  \n45. https://chatgpt.com/c/67f6d652-b9e8-8001-a283-ab1d817bdc97  \n46. https://chatgpt.com/c/67f6d6d2-54b8-8001-acd7-597b948dd447  \n47. https://chatgpt.com/c/67f6d6fe-9b84-8001-a044-d035eed2f4ce  \n48. https://chatgpt.com/c/67f6d963-d9d8-8001-9fe6-cca9659e1938  \n49. https://chatgpt.com/c/67f6d9f2-9d48-8001-9085-e202f9f2cbbc  \n50. https://chatgpt.com/c/67f6da85-fe6c-8001-ac97-226135a90084  \n51. https://chatgpt.com/c/67f6dab0-5bb4-8001-9bb4-d0fd4a13c505  \n52. https://chatgpt.com/c/67f6daef-56c4-8001-81dd-ea4d644e8a0e  \n53. https://chatgpt.com/c/67f6dbaf-87a0-8001-bc63-4f5e64414391  \n54. https://chatgpt.com/c/67f6dcff-b64c-8001-b1b7-38bcb0bb9166  \n55. https://chatgpt.com/c/67f6dd23-0a00-8001-9905-9bb1c0a8c241  \n56. https://chatgpt.com/c/67f6dd56-cbec-8001-9472-0ae009fc1e40  \n57. https://chatgpt.com/c/67f6dd77-6f54-8001-9079-802c8433a2f2  \n58. https://chatgpt.com/c/67f6dee5-5ae8-8001-b936-8e81405c283e  \n59. https://chatgpt.com/c/67f6df5a-c81c-8001-9d03-c34fe28a4742  \n60. https://chatgpt.com/c/67f832c7-dfa4-8001-8fe1-bf4f2ec0660a  \n61. https://chatgpt.com/c/67f83307-d4e8-8001-b805-bbc36677d6f4  \n62. https://chatgpt.com/c/67f83353-d6a8-8001-b94c-ceb78e110770  \n63. https://chatgpt.com/c/67f84a89-981c-8001-8eeb-eba56a83f472  \n64. https://chatgpt.com/c/67f84aaf-d3c0-8001-b110-bd553737b8b7  \n65. https://chatgpt.com/c/67f84b85-d570-8001-ad23-c85ca49a85a4  \n66. https://chatgpt.com/c/67f84cc0-6bac-8001-931f-a5da1a164adf  \n67. https://chatgpt.com/c/67f84d1e-c4c0-8001-856d-528faa124bab  \n68. https://chatgpt.com/c/67f84da1-f55c-8001-b876-57c8ad5e7565  \n69. https://chatgpt.com/c/67f84e24-fd3c-8001-9ab0-47ff2d840692  \n70. https://chatgpt.com/c/67f84e49-4f88-8001-9b93-8c0bbaa3f22d  \n71. https://chatgpt.com/c/67f84f94-b058-8001-961d-3de3a3aeac97  \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n19 \n72. https://chatgpt.com/c/67f850a9-9088-8001-b06d-28077ad7a5b1  \n73. https://chatgpt.com/c/67f850cb-9004-8001-acfb-f004066eeb87  \n74. https://chatgpt.com/c/67f850eb-3d6c-8001-a505-de4daa5310cd  \nDeepSeek-V3 \nThese chats took place between April 17 and April 18, 2025. \n75. https://chat.deepseek.com/a/chat/s/0523d115-abd7-415b-81b3-cd5893b2a397  \n76. https://chat.deepseek.com/a/chat/s/70a71dc9-e5aa-4ced-804b-7f92c20abefe  \n77. https://chat.deepseek.com/a/chat/s/b6f1fc30-40c3-4d95-961c-a60b6a4e42cb  \n78. https://chat.deepseek.com/a/chat/s/bd461f24-1f9b-4c98-85ce-751febad2d08  \n79. https://chat.deepseek.com/a/chat/s/a778dff9-636f-4532-9be3-73cc05b3adf5  \n80. https://chat.deepseek.com/a/chat/s/721e53e8-0e18-48cc-9c33-08e045a255ba  \n81. https://chat.deepseek.com/a/chat/s/8867c7ce-64ee-49f3-8f65-59304fbfae3c  \n82. https://chat.deepseek.com/a/chat/s/8f46dee8-fe5d-469d-aa5a-0edd61be6380  \n83. https://chat.deepseek.com/a/chat/s/0594ec1d-0b12-4e31-b11b-709794bbb242  \n84. https://chat.deepseek.com/a/chat/s/50e5fc71-919f-413f-b3d7-30c906f34c5b  \n85. https://chat.deepseek.com/a/chat/s/0e54be6d-ecd5-4597-9e68-403d73d23f67  \n86. https://chat.deepseek.com/a/chat/s/4378a1af-5191-4e9b-ab50-e412737818f5  \n87. https://chat.deepseek.com/a/chat/s/5c111d65-f1d4-4627-af2c-b786d2a256f4  \n88. https://chat.deepseek.com/a/chat/s/dddae162-a14e-4795-96e6-c64ef7d97e9f  \n89. https://chat.deepseek.com/a/chat/s/02306810-286a-4063-a5b6-43ed9eb3feb8  \n90. https://chat.deepseek.com/a/chat/s/dad1a7e8-a1dc-4a50-85df-2e649af86d54  \n91. https://chat.deepseek.com/a/chat/s/ca3a3a34-0653-4e36-95d3-deee58f3a738  \n92. https://chat.deepseek.com/a/chat/s/c072c5ee-9998-4f33-9d4a-293b9439c168  \n93. https://chat.deepseek.com/a/chat/s/7a0d7538-e9c3-4738-8bbc-d206d2400ec5  \n94. https://chat.deepseek.com/a/chat/s/737555c3-96de-4c99-871d-84f2913075ec  \n95. https://chat.deepseek.com/a/chat/s/836c50de-17b3-4dc7-a537-5d7145ad4f80  \n96. https://chat.deepseek.com/a/chat/s/b47bb8f1-56c2-44ac-80ff-022d29a729e4  \n97. https://chat.deepseek.com/a/chat/s/ca4e883b-88ba-4a34-8047-3357652d7b0a  \n98. https://chat.deepseek.com/a/chat/s/57898b1e-e3f2-4b02-909a-6c96b80c06df  \n99. https://chat.deepseek.com/a/chat/s/ecb18830-4788-49aa-b183-d1f4c0947ea1  \n100. https://chat.deepseek.com/a/chat/s/fb7203e8-ea11-4ad6-8b8f-17f1b2920771  \n101. https://chat.deepseek.com/a/chat/s/b2ac0327-2bc4-4867-badf-adf5be388154  \n102. https://chat.deepseek.com/a/chat/s/993baeac-7205-482f-abb4-dd5154b9be46  \n103. https://chat.deepseek.com/a/chat/s/11721460-937c-4f1a-b17c-2ea7409d6720  \n104. https://chat.deepseek.com/a/chat/s/415f2d39-af6f-4d5f-9a32-6667d278ea17  \n105. https://chat.deepseek.com/a/chat/s/fee3c30d-c915-4da4-aa5e-7b932daabefa  \n106. https://chat.deepseek.com/a/chat/s/16e8ac53-5449-497c-990b-d6eb5c0ec37c  \n107. https://chat.deepseek.com/a/chat/s/1088d30a-385d-4bd2-aca9-09959ed111ad  \n108. https://chat.deepseek.com/a/chat/s/bc0aa89d-1940-4a3b-8336-34a683614128  \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n20 \n109. https://chat.deepseek.com/a/chat/s/251489a0-1002-440d-a29b-7ab541c440ac  \n110. https://chat.deepseek.com/a/chat/s/169d899b-e67b-4c9d-af17-9e23dce4f019  \n111. https://chat.deepseek.com/a/chat/s/785db6a5-cd85-4551-aecf-91d817721081  \n112. https://chat.deepseek.com/a/chat/s/26185185-d65c-4b2c-b261-2420f2471971  \n113. https://chat.deepseek.com/a/chat/s/0930f0ab-04d6-413f-a924-63dd8ad54a20  \n114. https://chat.deepseek.com/a/chat/s/65ab8c7f-b444-43c4-90e0-1ac5d2f1d64d  \n115. https://chat.deepseek.com/a/chat/s/f28d9496-2d98-4492-8930-81883735877b  \n116. https://chat.deepseek.com/a/chat/s/66311223-e275-4c13-bda7-d2644f35a7f1 \n  \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n21 \nReferences \nAcres, Tom. 2023. “ChatGPT Shows ‘Significant and Systemic’ Left-Wing Bias, Study Finds.” \nSky News , Aug ust 17 . https://news.sky.com/story/chatgpt-shows-significant-and-\nsystemic-left-wing-bias-study-finds-12941162. \n \nBaker, Mona. 2019. Translation and Conflict: A Narrative Account. London: Routledge. \n \nBandurski, David. 2023. “Bringing AI to the Party.” China Media Project , April 14. \nhttps://chinamediaproject.org/2023/04/14/bringing-ai-to-the-party/. \n \nBichsel, Peter. 1992. “Die Tochter.” [The daughter.] In Eigentlich Möchte Frau Blum den \nMilchmann Kennenlernen [Actually Mrs. Blum would like to meet the milkman ], 34–\n35. Frankfurt: Suhrkamp-Verlag Frankfurt. \n \nBorchert, Wolfgang. 1949. “Die Küchenuhr.” [The kitchen clock .] In Das Gesamtwerk [The \ncomplete works], 197–199. Hamburg: Rowohlt Verlag GmbH. \n \nChakravorty, Shreya. 2023. “The Politics of Positionality: Gayatri Chakravorty Spivak and \nSamik Bandyopadhyay as Translators of Mahasweta Devi.” In Mahasweta Devi: Writer, \nActivist, Visionary, edited by Radha Chakravarty, 120–128. London: Routledge. \n \nClayton, James, and Lucy Hooker. 2023. “White House: Big Tech Bosses Told to Protect Public \nfrom AI Risks.” BBC News, May 5. https://www.bbc.co.uk/news/business-65489163. \n \nColville, Alex. 2025. “ DeepSeeking Truth.” China Media Project , February 10. \nhttps://chinamediaproject.org/2025/02/10/DeepSeeking-truth/. \n \nDe Vynck, Gerrit. 2023. “ChatGPT Leans Liberal, Research Shows. ” The Washington Post , \nAugust 16. https://www.washingtonpost.com/technology/2023/08/16/chatgpt-ai-\npolitical-bias-research/. \n \nDing, Gang. 2023. “AI Has a Political Stance, Associated with Ideology.” Global Times, May \n10. https://www.globaltimes.cn/page/202305/1290460.shtml. \n \nField, Matthew. 2025. “Chinese AI Has Sparked A $1 Trillion Panic – And It Doesn ’t Care \nAbout Free Speech. ” The Telegraph , January 27. \nhttps://www.telegraph.co.uk/business/2025/01/27/chinese-DeepSeek-ai-has-sparked-\na-1-trillion-panic/. \n \nGhosh, Sourojit, and Aylin Caliskan. 2023. “ChatGPT Perpetuates Gender Bias in Machine \nTranslation and Ignores Non -Gendered Pronouns: Findings Across Bengali a nd Five \nOther Low-Resource Languages.” In Proceedings of the 2023 AAAI/ACM Conference \non AI, Ethics, and Society, 901–912. doi:10.48550/arXiv.2305.10510. \n \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n22 \nGupta, Ragav. 2025. “Comparative Analysis of DeepSeek R1, ChatGPT, Gemini, Alibaba, and \nLLaMA: Performance, Reasoning Capabilities, and Political Bias.” Authorea, February \n10. doi:10.22541/au.173921625.50315230/v1. \n \nHall, Stuart. 1990. “Cultural Identity and Diaspora. ” In Identity: Community, Culture, \nDifference, edited by Jonathan Rutherford, 2–27. London: Lawrence & Wishart. \n \n———. 2013. “ Cultural Identity and Diaspora. ” In Colonial Discourse and Post -Colonial \nTheory: A Reader, edited by Patrick Williams and Laura Chrisman, 392–403. London: \nRoutledge. \n \nJiang, Ben. 2025. “Beijing Meeting Puts Spotlight on China ’s New Face of AI, DeepSeek \nFounder Liang Wenfeng. ” South China Morning Post , January 2.  \nhttps://www.scmp.com/tech/policy/article/3295662/beijing-meeting-puts-spotlight-\nchinas-new-face-ai-deepseek-founder-liang-wenfeng. \n \nJohri, Shreya. 2023. “The Making of ChatGPT: From Data to Dialogue.” Science in the News, \nHarvard Kenneth C. Griffin Graduate School of Arts and Sciences , June 6. \nhttps://sitn.hms.harvard.edu/flash/2023/the-making-of-chatgpt-from-data-to-dialogue/. \n \nKang, Jay Caspian. 2024. “How Biased Is the Media, Really? ” The New Yorker, October 18. \nhttps://www.newyorker.com/news/fault-lines/how-biased-is-the-media-really. \n \nKenny, Dorothy. 2022. “Human and Machine Translation. ” In Machine Translation for \nEveryone: Empowering Users in the Age of Artificial Intelligence , edited by Dorothy \nKenny, 23–49. Berlin: Language Science Press. \n \nKrauss, Nicole. 2020. “To Be a Man: A Short Story. ” The Atlantic , October 2. \nhttps://www.theatlantic.com/books/archive/2020/10/nicole-krauss-to-be-a-\nman/616517/. \n \nLiu, Qianer. 2023. “China to Lay Down AI Rules With Emphasis on Content Control. ” \nFinancial Times , July 11. https://www.ft.com/content/1938b7b6-baf9-46bb-9eb7-\n70e9d32f4af0. \n \nLu, Donna. 2025. “We Tried Out DeepSeek. It Worked Well, Until We Asked It About \nTiananmen Square and Taiwan. ” The Guardian , January 28.  \nhttps://www.theguardian.com/technology/2025/jan/28/we-tried-out-deepseek-it-\nworks-well-until-we-asked-it-about-tiananmen-square-and-taiwan. \n \nLukin, Annabelle. 2017. “Ideology and the Text -in-Context Relation.” Functional Linguistics \n4 (1): 1–17. doi:10.1186/s40554-017-0050-8. \n \nMartin, John Levi. 2023. “The Ethico -Political Universe of ChatGPT. ” Journal of Social \nComputing 4 (1): 1–11. doi:10.23919/JSC.2023.0003. \n \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n23 \nMichta, Andrew A. 2025. “The Real Reason Russia Invaded Ukraine (Hint: It ’s Not NATO \nExpansion).” Atlantic Council , March 6. https://www.atlanticcouncil.org/blogs/new-\natlanticist/the-real-reason-russia-invaded-ukraine-hint-its-not-nato-expansion/. \n \nMoorkens, Joss. 2022. “Ethics and Machine Translation.” In Machine Translation for Everyone: \nEmpowering Users in the Age of Artificial Intelligence, edited by Dorothy Kenny, 121–\n140. Berlin: Language Science Press. \n \nMotoki, Fabio, Valdemar Pinho Neto, and Victor Rodrigues. 2024. “More Human than Human: \nMeasuring ChatGPT Political Bias.” Public Choice 198:3–23. doi:10.1007/s11127-023-\n01097-2. \n \nNational Cybersecurity Standards Committee.2024. “Shengchengshi rengong zhineng fuwu anquan \njiben yaoqiu.” [Basic security requirements for generative artificial intelligence service.] \nTC260-003. https://www.tc260.org.cn/upload/2024-03-01/1709282398070082466.pdf. \n \nPacheco, Andre G . C., Athus Cavalini, and Giovanni Comarela. 2025. “ Echoes of Power: \nInvestigating Geopolitical Bias in US and China Large Language Models. ” arXiv \npreprint. doi:10.48550/arXiv.2503.16679. \n \nPérez-Ortiz, Juan Antonio, Mikel L. Forcada , and  Felipe Sánchez -Martínez. 2022. “How \nNeural Machine Translation Works.” In Machine Translation for Everyone: \nEmpowering Users in the Age of Artificial Intelligence, edited by Dorothy Kenny, 141–\n164. Berlin: Language Science Press. \n \nPrates, Marcelo O. R., Pedro H. Avelar, and Luís C. Lamb. 2020. “Assessing Gender Bias in \nMachine Translation: A Case Study  with Google Translate. ” Neural Computing and \nApplications 32 (10): 6363–6381. doi:10.1007/s00521-019-04144-6. \n \nRadford, Alec, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. “Improving \nLanguage Understanding by Generative Pre-training.” OpenAI. Accessed July 20, 2024. \nhttps://cdn.openai.com/research-covers/language-\nunsupervised/language_understanding_paper.pdf. \n \nSachs, Jeffrey D. 2023. “The War in Ukraine Was Provoked—and Why That Matters to Achieve \nPeace.” Jeffsachs.org, May 23. https://www.jeffsachs.org/newspaper-\narticles/wgtgma5kj69pbpndjr4wf6aayhrszm. \n \nSkeet, Ann. 2024. “ChatGPT Has Revived Interest in Ethics. The Irony Is That We Haven ’t \nBeen Holding Humans to the Same Standard. ” Fortune, January 22. \nhttps://fortune.com/2024/01/22/chatgpt-revived-ethics-human-leadership/. \n \nStatham, Simon. 2022. Critical Discourse Analysis: A Practical Introduction to Power in \nLanguage. London: Routledge. \n \n \ntransLogos 2025 Vol 8 Issue 1 \nSharkey, Michael, pp. 1–24 \nTranslation and Ideology in the Age of AI:  \nOn the Dual Positionality of Neural Machine Translation  \nby Large Language Models \n \n© Diye Global Communications \ndiye.com.tr | diye@diye.com.tr \n \n24 \nTschunkert, Kristina. 2021. “Working with Translators: Implications of the Translator’s \nPositionality for the Research Process and Knowledge Production.” In The Companion \nto Peace and Conflict Fieldwork , edited by Roger Mac Ginty, Roddy Brett, and Birte \nVogel, 249–262. London: Palgrave Macmillan. \n \nTymoczko, Maria. 2002 . “Ideology and the Position of the Translator : In What Sense is a \nTranslator ‘In Between’?” In Apropos of Ideology: Translation Studies on Ideology  – \nIdeologies in Tr anslation Studies, edited by María Calzada -Pérez, 181–201. London: \nRoutledge. \n \nVanmassenhove, Eva, Christian Hardmeier, and Andy Way. 2019. “Getting Gender Right in \nNeural Machine Translation.” arXiv preprint. doi:10.18653/v1/D18-1334. \n \nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, \nŁukasz Kaiser, and Illia Polosukhin. 2017. “Attention is All You Need.” In Advances \nin Neural Information Processing Systems 30: 31st Annual Conference on Neural \nInformation Processing Systems (NIPS 2017) , edited by Isabelle Guyon, Ulrike von \nLuxburg, Samy Bengio, Hanna Wallach, Rob Fergus, Sundar Vishwanathan, and \nRoman Garnett. 1 –11. La Jolla, CA: Neural Information Processing Systems. \nhttps://papers.nips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845a\na-Paper.pdf. \n \nWang, Jun, Benjamin Rubinstein, and Trevor Cohn. 2022. “Measuring and Mitigating Name \nBiases in Neural Machine Translation.” In Proceedings of the 60th Annual Meeting of \nthe Association for Computational Linguistics (Volume 1: Long Papers) , 2576–2590. \nhttps://aclanthology.org/2022.acl-long.184/. \n \nWeatherby, Leif. 2023. “ChatGPT Is an Ideology Machine.” Jacobin Magazine , April  17. \nhttps://jacobin.com/2023/04/chatgpt-ai-language-models-ideology-media-production. \n \nZhang, Handuo. 2020. “Seq2seq Model with Attention.” Zhang Handuo’s Site , June 1. \nhttps://zhanghanduo.github.io/post/attention/. "
}