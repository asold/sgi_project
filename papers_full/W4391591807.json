{
    "title": "Mathemyths: Leveraging Large Language Models to Teach Mathematical Language through Child-AI Co-Creative Storytelling",
    "url": "https://openalex.org/W4391591807",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A1851812986",
            "name": "Zhang Chao",
            "affiliations": [
                "Cornell University"
            ]
        },
        {
            "id": "https://openalex.org/A2348992179",
            "name": "Liu, Xuechen",
            "affiliations": [
                "Michigan United",
                "University of Michigan‚ÄìAnn Arbor"
            ]
        },
        {
            "id": null,
            "name": "Ziska, Katherine",
            "affiliations": [
                "Michigan United",
                "University of Michigan‚ÄìAnn Arbor"
            ]
        },
        {
            "id": null,
            "name": "Jeon, Soobin",
            "affiliations": [
                "Michigan United",
                "University of Michigan‚ÄìAnn Arbor"
            ]
        },
        {
            "id": "https://openalex.org/A2299104143",
            "name": "Yu-Chi Lin",
            "affiliations": [
                "University of Michigan‚ÄìAnn Arbor",
                "Michigan United"
            ]
        },
        {
            "id": "https://openalex.org/A591191902",
            "name": "Xu, Ying",
            "affiliations": [
                "University of Michigan‚ÄìAnn Arbor",
                "Michigan United"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4382656966",
        "https://openalex.org/W89680532",
        "https://openalex.org/W3133006485",
        "https://openalex.org/W2953270966",
        "https://openalex.org/W3097551320",
        "https://openalex.org/W2963430424",
        "https://openalex.org/W3029691645",
        "https://openalex.org/W2890735031",
        "https://openalex.org/W1507344285",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2120815132",
        "https://openalex.org/W4224308101",
        "https://openalex.org/W4225012671",
        "https://openalex.org/W4229021780",
        "https://openalex.org/W3161446631",
        "https://openalex.org/W2135731612",
        "https://openalex.org/W2591791409",
        "https://openalex.org/W3125760442",
        "https://openalex.org/W2885411111",
        "https://openalex.org/W2592514406",
        "https://openalex.org/W1549240050",
        "https://openalex.org/W2810526254",
        "https://openalex.org/W4312842259",
        "https://openalex.org/W2951000191",
        "https://openalex.org/W1980566386",
        "https://openalex.org/W3014521650",
        "https://openalex.org/W2464511884",
        "https://openalex.org/W4366460267",
        "https://openalex.org/W2401762417",
        "https://openalex.org/W4380668214",
        "https://openalex.org/W1984394797",
        "https://openalex.org/W3176332883",
        "https://openalex.org/W4247208931",
        "https://openalex.org/W2017889449",
        "https://openalex.org/W4310436400",
        "https://openalex.org/W4309674289",
        "https://openalex.org/W3199652424",
        "https://openalex.org/W4288075920",
        "https://openalex.org/W4386722107",
        "https://openalex.org/W4366550149",
        "https://openalex.org/W4377866048",
        "https://openalex.org/W4288113479",
        "https://openalex.org/W4378945636",
        "https://openalex.org/W3015899863",
        "https://openalex.org/W4383605243",
        "https://openalex.org/W2948116819",
        "https://openalex.org/W2020183020",
        "https://openalex.org/W277872697",
        "https://openalex.org/W3163363684",
        "https://openalex.org/W2169458998",
        "https://openalex.org/W2787712888",
        "https://openalex.org/W2077659752",
        "https://openalex.org/W2463537199",
        "https://openalex.org/W2910043433",
        "https://openalex.org/W2463046546",
        "https://openalex.org/W3153389711",
        "https://openalex.org/W4385007455",
        "https://openalex.org/W3037632719",
        "https://openalex.org/W2113567752",
        "https://openalex.org/W4223626855",
        "https://openalex.org/W3208402407",
        "https://openalex.org/W4319049323",
        "https://openalex.org/W2008153820",
        "https://openalex.org/W2668658554",
        "https://openalex.org/W3100449273",
        "https://openalex.org/W3033263009",
        "https://openalex.org/W4229035212",
        "https://openalex.org/W3177181326",
        "https://openalex.org/W2095953405",
        "https://openalex.org/W4283026156",
        "https://openalex.org/W2005844576",
        "https://openalex.org/W3175686023",
        "https://openalex.org/W2555019651",
        "https://openalex.org/W2168668921",
        "https://openalex.org/W4366547704",
        "https://openalex.org/W3214237218",
        "https://openalex.org/W3163511678",
        "https://openalex.org/W4225006040",
        "https://openalex.org/W3037334488",
        "https://openalex.org/W3029463573",
        "https://openalex.org/W4221055872",
        "https://openalex.org/W4366548330",
        "https://openalex.org/W4323650481",
        "https://openalex.org/W4225012808",
        "https://openalex.org/W4380479510",
        "https://openalex.org/W4220867331",
        "https://openalex.org/W1153780436",
        "https://openalex.org/W2736648871"
    ],
    "abstract": "Mathematical language is a cornerstone of a child's mathematical development, and children can effectively acquire this language through storytelling with a knowledgeable and engaging partner. In this study, we leverage the recent advances in large language models to conduct free-form, creative conversations with children. Consequently, we developed Mathemyths, a joint storytelling agent that takes turns co-creating stories with children while integrating mathematical terms into the evolving narrative. This paper details our development process, illustrating how prompt-engineering can optimize LLMs for educational contexts. Through a user study involving 35 children aged 4-8 years, our results suggest that when children interacted with Mathemyths, their learning of mathematical language was comparable to those who co-created stories with a human partner. However, we observed differences in how children engaged with co-creation partners of different natures. Overall, we believe that LLM applications, like Mathemyths, offer children a unique conversational experience pertaining to focused learning objectives.",
    "full_text": "Mathemyths: Leveraging Large Language Models to Teach\nMathematical Language through Child-AI Co-Creative\nStorytelling\nChao Zhang‚àó\ncz468@cornell.edu\nCornell University\nIthaca, NY, USA\nXuechen Liu\nliuxuech@umich.edu\nUniversity of Michigan\nAnn Arbor, Michigan, USA\nKatherine Ziska\nkziska@umich.edu\nUniversity of Michigan\nAnn Arbor, Michigan, USA\nSoobin Jeon\nsbjeon@umich.edu\nUniversity of Michigan\nAnn Arbor, Michigan, USA\nChi-Lin Yu\nchilinyu@umich.edu\nUniversity of Michigan\nAnn Arbor, Michigan, USA\nYing Xu\nyxying@umich.edu\nUniversity of Michigan\nAnn Arbor, Michigan, USA\nFigure 1: Interaction between a child and Mathemyths: demonstrating the system‚Äôs ability to teach mathematical language\nthrough child-AI co-creative storytelling. Mathemyths provides open-ended questions to solicit how the child wishes the story\nshould progress, on-the-fly feedback to acknowledge the child‚Äôs responses, and co-creative story continuation with in-context\nexplanations of math words. When the child needs additional support to continue the story, Mathemyths offers scaffolding\nthrough follow-up questions and ‚Äúhint & rephrase‚Äù strategies.\nABSTRACT\nMathematical language is a cornerstone of a child‚Äôs mathematical\ndevelopment, and children can effectively acquire this language\nthrough storytelling with a knowledgeable and engaging partner. In\n‚àóThis work was carried out when the author was a research intern at the University of\nMichigan.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\n¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0330-0/24/05. . . $15.00\nhttps://doi.org/10.1145/3613904.3642647\nthis study, we leverage the recent advances in large language models\nto conduct free-form, creative conversations with children. Con-\nsequently, we developed Mathemyths, a joint storytelling agent\nthat takes turns co-creating stories with children while integrating\nmathematical terms into the evolving narrative. This paper details\nour development process, illustrating how prompt-engineering can\noptimize LLMs for educational contexts. Through a user study in-\nvolving 35 children aged 4-8 years, our results suggest that when\nchildren interacted with Mathemyths, their learning of mathe-\nmatical language was comparable to those who co-created stories\nwith a human partner. However, we observed differences in how\nchildren engaged with co-creation partners of different natures.\nOverall, we believe that LLM applications, like Mathemyths, offer\nchildren a unique conversational experience pertaining to focused\nlearning objectives.\narXiv:2402.01927v2  [cs.HC]  26 Feb 2024\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nCCS CONCEPTS\n‚Ä¢ Social and professional topics ‚ÜíChildren; ‚Ä¢ Human-centered\ncomputing ‚ÜíEmpirical studies in interaction design ; Interactive\nsystems and tools ; Natural language interfaces .\nKEYWORDS\nStorytelling, mathematical language, conversational interfaces, large\nlanguage models, child‚ÄìAI collaboration, co-creativity, children\nACM Reference Format:\nChao Zhang, Xuechen Liu, Katherine Ziska, Soobin Jeon, Chi-Lin Yu, and Ying\nXu. 2024. Mathemyths: Leveraging Large Language Models to Teach Mathe-\nmatical Language through Child-AI Co-Creative Storytelling. InProceedings\nof the CHI Conference on Human Factors in Computing Systems (CHI ‚Äô24),\nMay 11‚Äì16, 2024, Honolulu, HI, USA. ACM, New York, NY, USA, 23 pages.\nhttps://doi.org/10.1145/3613904.3642647\n1 INTRODUCTION\nMathematics is a fundamental building block in children‚Äôs early edu-\ncation and is a strong predictor of their future achievements [14, 20,\n71, 82, 86]. Particularly in early childhood, mathematical learning\nis not just about learning to count or calculate; it also emphasizes\nthe ability to understand and apply mathematical language, such as\n‚Äúhalf‚Äù or ‚Äúequal‚Äù. Children often learn these words through everyday\nconversations with others [89]. For instance, when a parent asks,\n‚ÄúDo you have more cookies than me?‚Äù children are introducing the\nquantitative term ‚Äúmore. ‚Äù However, studies have found that the\namount and quality of math language children encounter through\nthese everyday, spontaneous conversations can vary greatly, which\noften aligns with socioeconomic differences [ 17]. This variation\nmay have translated into disparities in early math abilities [25].\nTo enrich children‚Äôs experience of math language beyond every-\nday conversations, researchers have emphasized the importance of\nincluding a language component in general mathematics instruc-\ntion, which allows children to engage with math language more\nsystematically. However, it is challenging to teach math language\nabstractly to young children [60]. One of the approaches widely\nused with preschoolers and early elementary school children is\nto embed math language within the context of narrative stories ,\nmaking abstract language more tangible and engaging for young\nlearners [37, 76]. Typically, this story-based learning approach in-\nvolves encouraging children to engage in dialogues within a story-\nline, where they understand and practice math terms with guidance\nfrom a more knowledgeable individual, such as a parent, teacher,\nor older peer [13, 21, 37, 65, 76]. Yet, the practicality of teaching\nmath language through joint storytelling is debatable, as it demands\na one-on-one engaged storytelling session that is logistically in-\nfeasible given the limited resources most educational institutions\nface [75‚Äì77].\nIn response to this challenge, researchers have long been inves-\ntigating AI‚Äôs potential to simulate human-like storytelling inter-\nactions [16, 55, 69, 69, 84, 105]. However, before the emergence\nof Large Language Models (LLMs), AI was primarily optimized\nfor structured interactions with children, such as asking questions\nand providing evaluative feedback [79, 102]. It is with the recent\nadvancements in LLMs, notably GPT-4 [68], that the technical dif-\nficulty of facilitating spontaneous and creative conversations has\nstarted to see promising developments [51]. However, the feasibility\nand efficacy of utilizing LLMs as partners to engage with children in\nstorytelling remains unclear, especially in the context of supporting\nthe learning of math language. Moreover, from a design perspective,\nit is unclear what specific workflow is necessary to tailor LLMs‚Äô\ncapacities to a younger audience [93].\nThis study outlines the development process for creating Math-\nemyths, a novel co-creative storytelling system powered by a GPT-\nbased conversational agent, with the goal of teaching math language\nto children (Fig. 1). We then present empirical findings from a user\nstudy comparing learning and engagement outcomes using Math-\nemyths to those of a comparable human-guided interaction. Specif-\nically, we aim to answer the following three research questions:\nRQ1 How can prompt engineering be employed to optimize LLMs as\nstory co-creators tailored for children‚Äôs educational purposes?\nRQ2 Do interactions with LLMs effectively engage children and pro-\nvide an enjoyable experience during the co-creation of stories?\nRQ3 Can children‚Äôs such interactions with LLMs result in com-\nparable learning outcomes seen in human-child storytelling\ninteractions?\nOur results indicate that when children interacted with Math-\nemyths, their learning of mathematical language appeared to be\ncomparable to those who co-created stories with a human partner.\nHowever, while both younger and older children benefited from\ninteracting with Mathemyths, we observed differences in the ways\nchildren from different age groups engage with co-creation partners\nof different natures. Overall, we believe that LLM applications, such\nas Mathemyths, can offer children a unique conversational experi-\nence, complementing their interactions with others. Our findings\nhave implications for the design of LLM-based applications aimed\nat supporting children‚Äôs learning. Additionally, they highlight areas\nrequiring further consideration to ensure the technology is both\nsupportive and effective for diverse learning experiences.\n2 RELATED WORK\nIn this section, we review research on (1) teaching math language\nthrough storytelling, (2) conversational interfaces for children, and\n(3) using LLMs for child-facing conversational interfaces.\n2.1 Teaching Math Language through\nStorytelling\nChildren‚Äôs mathematical abilities are significantly influenced by\ntheir language skills [65, 71, 87, 96, 97, 100, 111]. Indeed, the Com-\nmon Core State Standards, a US educational framework, highlight\nthe need for students to be able to understand and apply specific\nmathematical language to describe the math concepts [3]. For in-\nstance, by second grade, students are expected to b e familiar with\nterminology associated with fundamental math operations: addi-\ntion, subtraction, multiplication, and division. Nevertheless, while\nsome of this math language can be replaced by informal, everyday\nexpressions (e.g., ‚Äúputting together‚Äù as opposed to ‚Äúaddition‚Äù) to\nconvey a similar meaning, equipping students with precise math\nterminologies is still necessary. Such terminology serves as a bridge\nto help children transition from their concrete everyday way of\nthinking to more abstract analytical thinking.\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nChildren engage in math language in different ways, including\ntheir daily dialogues with teachers and parents [89]. Research has\nindicated a positive correlation between the extent and frequency of\nmath language used by parents or teachers and the development of\nchildren‚Äôs math abilities at the onset of elementary education [77].\nHowever, the extent of math talk to which children are exposed\nvaries significantly, likely influenced by the differing levels of aware-\nness, expertise, or comfort among parents and teachers [ 17, 26].\nThis variation is recognized as a contributing factor to the dispari-\nties observed in children‚Äôs math abilities [25]. Furthermore, while\nearlier studies predominantly focused on math language produced\nby parents and teachers, with children as recipients, more recent\nresearch has broadened this perspective. It emphasizes the opportu-\nnities for children to not only be exposed to but also generate math\ntalk themselves [2, 83]. Interestingly, these studies have revealed\nthat the children‚Äôs own mathematical conversations play a crucial,\nif not more significant, role in shaping their mathematical compe-\ntence, sometimes even outweighing the influence of the math talk\nprovided by parents or teachers [90, 98].\nTo address the varying degrees of math talk children encounter\nin spontaneous circumstances and to encourage their active en-\ngagement in math discussions, researchers have developed various\ninterventions. These interventions often utilize a storytelling ap-\nproach [32, 36, 41, 46, 73], where children, along with their parents\nor teachers, engage in math-themed narratives. Discussion prompts\nare provided within these narratives to encourage children to use\nmath language. For example, Purpura et al. [76] devised an eight-\nweek intervention in Head Start classrooms, targeting children\naged three to five. Researchers read six storybooks containing math\nvocabulary (e.g., ‚Äúfewer‚Äù) to the children. During the readings, re-\nsearchers asked children questions that expanded upon the book‚Äôs\nexisting math language (e.g., ‚ÄôHow do we know there were a lot and\nnot just a few?‚Äô). Additionally, if a child expressed confusion about\na math term, the researchers explicitly defined and explained it. The\nresearchers found that children who participated in the interven-\ntion significantly outperformed those in a comparison group, who\ncontinued with business as usual, not only in a math language as-\nsessment but also in a math knowledge assessment. Another study\nused a similar story-based approach among kindergarten children\nwith numeracy difficulties [36]. This study found that the students\nwho engaged in the stories and related dialogue learned math vocab-\nulary better than the other group of students who received direct\ninstruction of the math vocabulary.\nTraditionally, many story-based approaches have incorporated\ndialogue into existing narratives, thus, to some extent, constraining\nchildren‚Äôs creative involvement in shaping the stories. Thus, the\nresearch community has also been promoting an approach that\nencourages children to contribute and decide how they want the\nnarrative storyline to progress, which is believed to empower chil-\ndren to bring their lived experiences to the dialogue to support\ntheir meaning making [66]. This type of child-led storytelling has\nbeen adopted in preschool and early elementary classrooms and\nhas proven to be feasible and age-appropriate. For instance, Flynn‚Äôs\nstudy focused on a small group of four- to five-year-old children\nwho were co-creating stories alongside an adult facilitator [28]. The\nresearch suggested that these children were able to meaningfully\nadvance the story plot, drawing inspiration from ideas contributed\nby their peers. It should be noted that, facilitation from an adult is\nimportant for children to fully engage in this process. In particular,\nthe study highlighted the facilitator‚Äôs role in posing questions to\nguide children‚Äôs responses and offer constructive feedback respon-\nsive to children‚Äôs contributions. Such question-feedback-scaffolding\ncould potentially lower the cognitive demand required for certain\nchallenges children face when continuing the story [ 102]. Build-\ning on this concept, the HCI community has long been exploring\ntechnology-mediated platforms to support children storytelling.\nWe will discuss this line of prior research in detail in the section\nbelow.\n2.2 Conversational Interfaces for Children\nWith the rapid advancement of AI, conversational user interfaces\n(CUIs) can now simulate interpersonal interactions through natu-\nral spoken language with children [72]. This type of speech-based\ninteraction may not require children to have reading and typing\nskills, as is the case with other graphical user interfaces, thus re-\nmoving the barrier for children who have not yet fully developed\ntheir literacy skills. Furthermore, it eliminates the need for a screen,\npotentially reducing tensions between children and their parents\nregarding screen time[39, 52]. Previous research has identified two\nprevalent types of interactions that children tend to have with\nCUIs [101]: voice assistants supporting open-domain conversations\n(e.g., Apple Siri, Amazon Alexa, Google Assistant) and voice-based\napps that specifically designed for children for domain-specific con-\nversations [8, 9, 56, 62, 63]. This type of specifically design apps\nhave been found to support children‚Äôs learning across a number of\ndisciplines, including math [40, 98], science [102], computational\nthinking [18], and literacy [101]. Though varied in their specific\ndesign, these applications are grounded in a common principle by\nutilizing conversational AI as a language partner to engage children\nin discussions related to the relevant topics.\nFor instance, Ho and colleagues developed a social robot that\nprovides math-related prompts in storybooks for parents of four-\nand five-year-olds, covering concepts like subtraction, addition, and\ncomparisons [40]. The study revealed that parents found the robot‚Äôs\nquestions inspiring and that these questions led to more meaningful\nconversations with their children. Another example is a voice-based\ngame designed to teach children aged four to seven [ 98]. In this\ngame, children interacted with visual representations of shapes\nin different colors and sizes, receiving prompts such as ‚Äúturn the\ntallest triangle into a circle. ‚Äù The game also featured back-and-forth\nquestions to guide children through this process. A user study in-\nvolving 18 children demonstrated that this game helped them learn\nthe target math terms and engage in verbal reasoning about their\ndecisions. Although these two studies utilized either the Wizard-of-\nOz approach or pre-scripted dialogues, they provided insights and\nevidence of feasibility in terms of how CUIs could be designed to\nsupport math talk among preschool and early elementary-aged chil-\ndren. These insights have paved the way for our current research,\nwhich seeks to enable free-flowing, story-based interactions for\nchildren in the context of math dialogues.\nAnother related research area is focused CUI and storytelling\nspecifically, where an agent collaboratively co-creates stories with\nchildren [97, 100, 103, 108, 109], mirroring the common childhood\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nactivity children have with teachers or parents. Among these stud-\nies, a prevailing model involves the agent listening to a child‚Äôs\nstories and then periodically offering generic, template-based re-\nsponse that are not usually responsive to children‚Äôs specific con-\ntribution [10, 80, 94]. For instance, Bers and colleague developed\na plush rabbit that reacts to a child‚Äôs storytelling by moving its\nears and shaking its body [11]. When the child pauses, the rabbit\nthen prompts them with scripted follow-up questions to encourage\nfurther storytelling contributions [10]. This interactive strategy has\nbeen utilized in more recent studies as well [42].\nWhile these studies have found that even this limited and struc-\ntured interactivity can support children‚Äôs storytelling, the agent\nmade in fact minimal contributions to children‚Äôs stories. Xu and col-\nleagues referred to this type of interaction as ‚Äúpseudo-conversation, ‚Äù\nwhere the agent follows predetermined dialogue flows when inter-\nacting with children [101]. This limitation could be especially prob-\nlematic in creative storytelling activities, where children may gen-\nerate a wide range of creative responses. Nevertheless, to overcome\nthe technological limitations at the time, many studies employed\nWizard-of-Oz approaches to explore the feasibility of children en-\ngaging in joint storytelling with a non-human partner, as perceived\nby the child. For example, Sun et al. [87] had children aged 4 to 10\ninteracted with a robot secretly controlled by a researcher, periodi-\ncally inserting new story content and relating it to the story created\nby the child. Children were found to meaningfully collaborate with\nthe ‚Äúrobot‚Äù and enjoy their interactions. These Wizard of Oz stud-\nies suggested that it is possible to replicate the strategies utilized\nby human partners in a setting with other technological partners,\nthereby laying the foundation for our research. With the advances\nin LLM, such human-led interactions can now be more feasibly\nsimulated by AI agents. Thus, a primary objective of our current\nstudy is to utilize LLMs to emulate ‚Äútrue conversation, ‚Äù which is\ndefined as multiple parties ‚Äômutually orienting to, and collaborating\nin order to achieve, orderly and meaningful communication‚Äô [27]\n2.3 Using Large Language Models for\nChild-facing Conversational Interfaces\nPre-trained large language models (LLMs), such as GPT-3 [ 12]\nand GPT-4 [68], have significantly advanced natural language pro-\ncessing (NLP) in recent years. These models, trained on colossal\namounts of text data, can generalize to downstream tasks like text\ngeneration [93]. One key capability derived from the large model\nsize is prompting [93], which allows individuals to provide specific\ntextual instructions and examples [106] to guide the model‚Äôs task\nexecution. Although prompting LLMs may not consistently sur-\npass benchmark models, it offers a lightweight approach to achieve\ncompetitive performance across a variety of tasks [ 12, 15]. The\nconcept of prompting LLMs remains a compelling research topic\nwithin the HCI community. Our work extends previous research\nby introducing a set of prompting techniques iteratively designed\nto optimize LLMs as story co-creators tailored for children‚Äôs edu-\ncational purposes.\nCUIs powered by LLMs, such as ChatGPT [ 67], have demon-\nstrated their potential in facilitating responsive and engaging di-\nalogues. Unlike traditional CUIs, they are not constrained by a\npre-determined dialogue paradigm or reliant on pre-written re-\nsponses. One of their standout features is the ability to generate\ncontextually relevant and coherent responses based on the input\nthey receive so far [93]. This capability positions them to achieve\n‚Äútrue conversation‚Äù, wherein they can effectively collaborate with\nchildren, ensuring a more natural and enriching dialogue [56]. Thus,\nthis paper harnesses the adaptability and flexibility of LLMs, aim-\ning to forge a dynamic and collaborative storytelling experience\nfor children, thereby fostering their math language growth and\nstimulating their creative expression.\nRecently, numerous researchers have endeavored to incorporate\nLLMs into educational technologies [51]. These adaptations have\nseen the utilization of LLMs in creating educational content [19, 29],\nenhancing student engagement and interaction [1, 7, 88], and per-\nsonalizing learning experiences [81]. For instance, LLMs have been\nused to generate children‚Äôs narratives [4, 35], some of which have\neven been sold publicly [64]. In a different research trajectory, sev-\neral scholars have used LLMs to create intelligent learning partners\ncapable of collaborating with humans [47], providing feedback [49]\nand encouraging students [ 24, 88]. One common application in-\nvolves employing LLMs as a conversational partner in written or\noral form, such as in the context of task-oriented dialogues that offer\nlanguage practice opportunities [24]. Building on these advance-\nments in LLMs, our work aims to apply LLMs in CUIs to enable child-\nAI collaborative storytelling for mathematical language learning.\n3 THE DEVELOPMENT PROCESS OF\nMATHEMYTHS\nGrounded in the strong evidence that children develop math lan-\nguage through storytelling, and considering the unique capabilities\nof LLMs, we engaged in a design process to conceptualize Math-\nemyths . Our aim was to create a co-creative storytelling system\ntailored for children aged 4-8, introducing them to mathematical\nlanguage through voice-based interactions. This initiative serves\nas a case study to explore the potential of LLMs as educational\npartners for children.\nAt its core, Mathemyths is designed to collaboratively engage\nin storytelling by alternating turns with a child. The role of Math-\nemyths within this dynamic is three-fold: 1) generating prompts to\nelicit narrative contributions from the children, 2) continuing the\nstory by utilizing mathematical language based on the children‚Äôs\ninput, and 3) providing scaffolding when children are hesitant to\nengage or show confusions about the prompts or the story. The\ninteraction flow is presented in Fig. 2. The example conversation\nbetween a child and Mathemyths can be found in Appendix A.\nGiven that using LLMs, particularly through prompt engineering,\nto develop educational tools is a relatively new domain, our design\nprocess began by applying educational principles from the existing\nliterature reviewed above, which focus on engaging children in joint\nstorytelling and math talk. We then engaged in a series of exper-\niments to optimize Mathemyths ‚Äôs capabilities for child-friendly\nand math-focused dialogue. In the remainder of this section, we\noutline 1) our overall design principles for Mathemyths , 2) our\nmethod to prompt engineer LLM to serve as the story co-creator, 3)\nour process to evaluate the prompt-engineered LLM‚Äôs performance,\nand 4) the implementation of the Mathemyths system.\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nFigure 2: The interaction flow of the Mathemyths system.\n3.1 Design Principles\nDrawing from the literature reviewed above, we incorporated two\nkey design principles into the story co-creation interaction.\nFirst, the conversation experience is designed to emulate a joint\nstorytelling activity while the AI partner guides children in this\nprocess through using three-part dialogue moves that adhere to the\nquestion-feedback-scaffolding framework [102]. Under this frame-\nwork, Mathemyths initiates the interaction with children by craft-\ning an initial story plot based on children‚Äôs input about key ele-\nments such as the protagonist and setting. It then poses open-ended\nquestions to solicit how children wish the story should progress,\nsuch as ‚ÄúWhat will Lucy and Nick do next to make sure they take\nan equal number of steps to reach the treasure? ‚Äù After children‚Äôs\nresponses, Mathemyths then offers feedback that includes both\nan acknowledgement of children‚Äôs contribution (e.g., ‚ÄúWonderful\nidea! That‚Äôs a clever way to find the map. ‚Äù) and a continuation\nthe narrative in line with the children‚Äôs input. In the cases when\nyoung children require additional support to generate a concrete\nidea, Mathemyths provides scaffolding to encourage children\nto elaborate their ideas [53, 87, 108, 109]. For instance, if the child\nprovides a brief response without much detail, such as ‚Äú ask for\nhelp‚Äù, the agent will ask a follow-up question, ‚ÄúWhat a good point!\nWho should we ask for help? Can you tell me more about these help-\nful friends? ‚Äù In other cases, if the child indicates confusions (e.g.,\n‚ÄòI don‚Äôt know ‚Äù) or does not respond, Mathemyths will scaffold\nthe child by employing the ‚Äúhint and rephrase‚Äù strategy to pro-\nvide ideas for children to consider (e.g., ‚ÄúLet‚Äôs think together. Lucy\nand Nick can take turns counting their steps. How many steps do\nyou think they should both count? ‚Äù). This strategy, simplifying the\noriginal open-ended question by suggesting a specific direction, is\nwidely utilized in conversational agents to engage preschool-aged\nchildren [33, 34, 102].\nTo make the storytelling experience more suitable for young chil-\ndren, Mathemyths creates story based on the quest archetype. This\ngenre, prevalent in children‚Äôs literature, focuses on a hero‚Äôs journey\nto a particular place or to find an item, facing many challenges along\nthe way [44]. Language-wise, Mathemyths is instructed to use\nsimple, clear language that young children can easily understand,\nwith sentences that are straightforward in structure.\nSecond, situated within the narrative structure, Mathemyths is\nalso designed to teach math language through exposure (i.e., using\nmath terms in the plots generated by Mathemyths ) and practice\n(i.e., posing questions to encourage children to use math terms to\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\ncontinue the stories). Mathemyths primarily focuses on six math-\nematical terms (sum, estimate, add, subtract, equal, and half ). These\nterms and their related concepts align with the kindergarten and\nfirst grade Common Core State Standards [3, 45]. The children in\nthese grades, usually aged between 5 and 7 years, fall in the middle\nof our target age range. We also tested other terms from the Com-\nmon Core Standard, such as ‚Äúdivide‚Äù and ‚Äúmultiply‚Äù, but ultimately\ndecided not to use those terms as they might be too complex for\nour younger participants. Children heard these terms used at least\ntwice per story. Moreover,Mathemyths is uniquely designed to\nnot only introduce these terms but also provide explanations within\nthe narrative context. For instance, when the term ‚Äúequal‚Äù is used\nin a sentence like, ‚ÄúLucy and Nick take an equal number of steps, ‚Äù\nMathemyths explains it in a story-relevant way: ‚ÄúThis means Lucy\nand Nick take the same number of steps. If Lucy takes 5 steps, then\nNick also takes 5 steps. ‚Äù These types of explanations, integrated\nwithin the context, are deemed more effective for young children\nthan abstract definitions [18, 32, 102].\n3.2 Prompt Engineering\nThe model underlying Mathemyths was GPT-41, currently the\nmost advanced LLM available for developers. Through prompt en-\ngineering, GPT-4 performed three primary tasks aligned with the\nquestion-feedback-scaffolding model: 1) generating questions to\nfacilitate children‚Äôs continuation of the story; 2) continuing the\nstory based on children‚Äôs responses, including in-context explana-\ntions of math terms; and 3) providing scaffolding with additional\nsuggestions or follow-up questions, tailored to children‚Äôs different\nresponses.\nThe prompts were developed through an iterative process. We\nborrowed Brown et al. [12] suggested prompt engineering strategies\nto draft our initial prompts. We then underwent a two-month-long\nrevision process, which involved internal evaluations with the re-\nsearch team and evaluations with children, and this process led us\nto rapid iterations of the prompts.\nAll these features were implemented using the OpenAI APIs2.\nThe final version of prompts used in the user study is displayed in\nAppendix D Table 4.\n3.2.1 Question Generation. Following a similar prompt structure\nproposed in Brown et al. ‚Äôs work [12], each prompt starts with a\npreamble which explains the prompt‚Äôs purpose: ‚ÄúGiven an unfin-\nished story, compose one single, straightforward question to prompt\na 6-year-old to expand on the story. ‚Äù The preamble is followed by\na detailed list of instructions and multiple exemplars consisting\nof the input and the output. Specifically, we directed the model\nto pose questions concerning the main character‚Äôs subsequent ac-\ntions or emotions. These two story elements are not only important\nto the narrative‚Äôs progression but are also tangible concepts that\nchildren can readily engage with and respond to [70]. To enhance\nGPT-4 performance, we provided six exemplar questions generated\nby the research team. These questions were further reviewed and\napproved by two trained research assistants in the domains of chil-\ndren‚Äôs verbal storytelling and mathematics education. The detailed\nprompt templates are shown in Appendix D Table 4.\n1https://openai.com/gpt-4\n2https://platform.openai.com/docs/api-reference/chat\n3.2.2 Story Continuation. To facilitate the continuation of stories\nbased on children‚Äôs inputs, while integrating mathematical lan-\nguage instruction, we began by prompting the model to assume\nthe role of a ‚Äústorytelling robot 3‚Äù. This prompt established the inter-\nactive framework of the LLM‚Äôs responses.\nThe next part of the prompt was focused on context-setting.\nWe supplied the model with a narrative scenario: ‚Äú Let‚Äôs play a\njoint storytelling game where we build a story together with the\nmain character being a [character] named [name] in the [setting]. ‚Äù\nThe elements in brackets ([character], [name], [setting]) would\nbe dynamically populated based on the responses provided by the\nchildren. We also set several high level rules to ensure the generated\nstory content ‚Äúis simple and appropriate for a young child ‚Äù, adheres\nto the quest archetype, and contains nothing unrelated to the story.\nFor the model to produce coherent and math-focused responses,\nwe articulated a specific sequence for it to follow. The model was\ntasked with acknowledging children‚Äôs contributions, utilizing a\nminimum of two mathematical terms, and then offering in-context\nexplanations. This was achieved via the following detailed prompt:\n‚ÄúFirst, acknowledge my addition and commend me in a short 10-word\nsentence. Next, continue the story by correctly using [mathematical\nterm one] and [mathematical term two] or their variants within two\ndistinct short sentences. Lastly, explain their meanings within a short\nsentence, grounding it firmly within the story‚Äôs context. ‚Äù\nDuring experimentation, we observed the LLM‚Äôs tendency to\noccasionally overlook prior directives as interactions continued. To\ncounter this behavior and maintain consistency, our specific instruc-\ntions were reiterated with each turn. This ensured Mathemyths ‚Äôs\nalignment with our intended conversational flow.\n3.2.3 Scaffolding. In our study, we classified the situations where\nchildren require scaffolding into two main categories: (1) cases\nwhere they completely fail to continue the story, either by express-\ning uncertainty (e.g., saying ‚ÄúI don‚Äôt know ‚Äù) or by not responding; (2)\ninstances where they continue the story with only brief and vague\nresponses, typically less than 5 words. To scaffold the first situation,\nour initial step is to determine whether the child is providing meta-\ncomments (e.g., ‚ÄúI like this ‚Äù, ‚Äúplease continue ‚Äù) or exhibiting signs\nof confusion (e.g., ‚ÄúI am not sure ‚Äù). This determination is made by\nprompting the LLM with a set of few-shot examples. These exam-\nples represent the most common types of responses observed in\nour rapid iteration tests with children. Following this identification,\nwe utilize the model to simplify the question and offer hints related\nto the question, adhering to the ‚Äúhint and rephrase‚Äù strategy. In\naddressing the second situation, we monitor the child‚Äôs responses.\nTo scaffold the second situation, we employ the GPT-4 model to\npose a follow-up question based on the child‚Äôs preceding brief re-\nsponse. This approach involves first acknowledging what the child\nhas said and then encouraging them to elaborate further on their\ncontributions.\n3.3 Model Evaluation\nAs part of the iterative design process, we conducted an evalu-\nation to examine the technical capabilities of our LLM-powered\n3In the prompt, the model is designated to function as a ‚Äústorytelling robot‚Äù. However,\nduring interactions, we avoid describing our system as a robot to prevent potential\nconfusion, given that it operates as a virtual agent.\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nsystem. This evaluation consisted of two components: first, assess-\ning the model‚Äôs ability to generate questions to elicit children‚Äôs re-\nsponses to determine if these questions are fluent, inspirational, and\nlogically relevant; second, evaluating the model‚Äôs performance in\ncontinuing stories that are logically relevant, engaging, and age-\nappropriate. Specifically, our goal was to confirm whether the\nprompt-engineered GPT-4 model performs satisfactorily compared\nto a human baseline in both tasks and whether its performance\nsurpasses that of a fine-tuned GPT-3.5 model in the question gener-\nation task. We chose the fine-tuned GPT-3.5 model as our baseline\nbecause it was the highest-performing model available that allowed\nfine-tuning during our development phase. Indeed, researchers\nhave used a fine-tuned GPT-3.5 model in dialogic interactions with\nchildren, achieving better performance compared to other state-of-\nthe-art models [56].\nAll evaluations were carried out by three college student research\nassistants who had over a year of experience in educational research\nand extensive years of engagement in activities with children within\nthe target age range of our study. These students underwent train-\ning until their inter-rater reliability reached a satisfactory level\nbefore beginning the actual evaluation.\n3.3.1 Evaluating Prompt Engineered GPT-4‚Äôs Performance in Ques-\ntion Generation. The generated questions are designed to inspire\nchildren to continue the story and encourage them to learn and use\nmathematical terms. In this evaluation, we compared our prompt-\nengineered GPT-4 model with a fine-tuned GPT-3 model. The fine-\ntuned GPT-3 model was trained4 using a subset of 100 out of 300\nhuman-crafted questions developed by an author of the paper. Be-\nsides these two LLMs, we also included the other subset of human-\ncrafted questions as our baseline.\nThe question evaluation included four matrices, namely read-\nability, inspiration, story relevancy , and math language relevancy .\nWe invited the three evaluators to score the questions across each\nof the four dimensions in a 5-point Likert scale. The inter-rater\nreliability among these evaluators was satisfactory with an average\nof intra-class correlation of 0.82 across four dimensions. Details of\nthese matrices are presented in Table 1.\nAn ANOVA was conducted to compare the ratings of ques-\ntions generated by human, fine-tuned GPT-3.5, and our prompt-\nengineered GPT-4 model. The results indicated significant differ-\nences among the sources for all four dimensions (Readability:ùêπ(2)=\n9.415,ùëù < .001‚àó‚àó‚àó, Inspiration: ùêπ(2)= 11.357,ùëù < .001‚àó‚àó‚àó, Story\nRelevancy: ùêπ(2)= 17.327,ùëù < .001‚àó‚àó‚àó, Math Language Relevancy:\nùêπ(2)= 90.687,ùëù < .001‚àó‚àó‚àó). A post hoc Tukey‚Äôs HSD test further\nrevealed that questions generated by both humans and GPT-4 ex-\nhibited higher levels of readability, inspiration, and relevance to\nthe story‚Äôs plot and mathematical language when compared to\nquestions generated by the fine-tuned GPT-3.5 model (Fig. 3). The\nevaluation ratings between human-generated and GPT-4 generated\nquestions were comparable, further suggesting the feasibility and\npromise of GPT-4 models in this context. However, the questions,\neither generated by humans or GPT-4, were scored relatively lower\nin the relevance of mathematical language as compared to other\ndimensions but still higher than GPT-3.5. This arises from the com-\nplexity of creating questions that both meaningfully advance the\n4https://platform.openai.com/docs/guides/fine-tuning\nstoryline and focus on specific math terms. To preserve the story‚Äôs\ncontinuity, the questions‚Äô relevance to stories was often prioritized.\nDespite these, children should still encounter a sufficient number\nof questions aimed at enhancing their understanding and use of\nmathematical concepts.\n3.3.2 Evaluating Prompt Engineered GPT-4‚Äôs Performance in Story\nContinuation. Mathemyths is designed to continue the story adap-\ntively based on children‚Äôs contributions and integrate mathematical\nlanguage within the story plot. To evaluate whether our prompt-\nengineered GPT-4 model achieved these two goals, we compared\nthe GPT-4 generated stories with those generated by humans as\nour baseline, given that other existing models were not tailored\nto continue stories but rather generate new stories. GPT-4 gener-\nated stories were created using a self-chat technique [30], which\nenabled our dialogue system to engage in self-generated conversa-\ntions, mimicking a child‚Äôs interactions, and collaboratively creating\nstories. Human-generated stories were based on the same instruc-\ntions we provided to prompt GPT-4. The process for generating\nthe dataset is detailed in Appendix B. Subsequently, we presented\nthe three evaluators with pairs of stories, one generated by GPT-4\nand the other by humans. Based on a widely recognized method\nfor evaluating AI-generated dialogues [56, 58], we asked them to\nmake a choice from each pair based on four dimensions: preference,\nperceived creativity , mathematics relevancy, and readability. Table 2\nprovides a detailed explanation of these metrics.\nThe results of this evaluation are displayed in Fig. 4. Overall,\nour evaluators indicated that the story pairs, where one was gen-\nerated by humans and the other by GPT-4, were quite comparable\nin quality across all dimensions, particularly in perceived creativ-\nity (50.0% vs. 50.0%). Notably, there was a marginal preference for\nstories generated by AI (53.1% vs. 46.9%), with these stories also\nbeing perceived as integrating more mathematical elements (56.2%\nvs. 43.8%). GPT-4‚Äôs advantages in relating stories to mathematical\nelements are likely due to the fact that this task capitalizes on LLMs‚Äô\ncapabilities of creating seemingly logical connections of language\nelements based on specific instructions. However, human-generated\nstories were slightly favored for their readability (46.9% vs. 53.1%). A\nfollow-up discussion with the evaluators revealed that the slightly\nlower readability in AI-generated stories primarily stemmed from\ninstances where GPT-4 produced text that, while structurally co-\nherent in its language, occasionally lacked logical consistency. This\nobservation aligns with existing research underscoring the inherent\nlimitations [48, 57].\n3.4 System Implementation\nMathemyths is a desktop application designed to run on a Mac-\nBook computer with built-in microphones and speakers. This appli-\ncation, written in Python, does not rely on any graphical interface\nfor interaction. Instead, users can navigate Mathemyths simply\nby voice. Upon launch, users have the flexibility to specify both\nthe number of dialogue rounds and the mathematical terms they\nwish to learn. For voice-based interaction, Mathemyths leverages\nthe Google Cloud Speech-to-Text API5 to recognize users‚Äô verbal\n5https://cloud.google.com/speech-to-text\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nTable 1: Metrics used in evaluating prompt engineered GPT-4‚Äôs performance in question generation. The average intraclass\ncorrelation coefficient ( ICC) scores are displayed.\nMetric Description ICC\nReadability The generated question is written in understandable English, using proper grammar and vocabulary. 0.758\nInspiration The generated question stimulates children‚Äôs thinking and provokes them to articulate their thoughts. 0.870\nStory Relevancy The generated question aligns with the narrative plotline. 0.751\nMath Language Relevancy The generated question requires children‚Äôs understanding or use of specific mathematical terms. 0.907\nFigure 3: Bar plots illustrating the distribution of data and the results from the ANOVA post-hoc Tukey‚Äôs HSD test regarding\nthe question generation evaluation. Statistically significant results are reported as ùëù < 0.05‚àó, ùëù < 0.01‚àó‚àó, ùëù < 0.001‚àó‚àó‚àó. Error bars\nrepresent 95% confidence intervals (CIs).\nTable 2: Metrics used in evaluating prompt engineered GPT-4‚Äôs performance in story continuation.\nMetric Description\nPreference Who would you prefer to collaborate with to create a story?\nPerceived Creativity Whose story sounds more creative and contains more twists and turns?\nMathematics Relevancy Whose story contains more mathematical elements?\nReadability Whose story is more easily comprehended by children in our target age range?\nFigure 4: The evaluation results on four metrics of story continuation.\ninputs. Additionally, the Elevenlabs Speech Synthesis service6 is\nemployed to generate realistic speech for the agent‚Äôs responses.\n4 USER STUDY\nTo understand how Mathemyths might support children‚Äôs engage-\nment and math language learning, we conducted a user study where\nchildren were randomly assigned to either co-create stories with\n6https://beta.elevenlabs.io/speech-synthesis\nMathemyths or with a friendly and skilled human partner. We\nexamined children‚Äôs gains in mathematical language knowledge,\ntheir engagement, creation performance, and enjoyment in the\nstorytelling activities, and Mathemyths ‚Äôs performance.\n4.1 Procedure\nParticipants were recruited from two public libraries in a mid-west\ncity in the U.S. throughout the summer of 2023. This study was ap-\nproved by the Institutional Review Board of the authors‚Äô institution.\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nFigure 5: The (a) plushy and (b) speaker used in our user\nstudy.\nAfter obtaining parental consent and child assent, participants were\nintroduced to a research assistant and began the three-part study\nprocedure which consisted of a baseline pretest of children‚Äôs math\nlanguage, the story co-creation activity, and a post-test assessing\nmath language, along with a survey with the children. Details of\nthe math language pre- and post-test questionnaire are described\nin the Evaluation Metrics section below.\nFor the story co-creation activity, children were randomly as-\nsigned to partner either with a human (i.e., a train research assis-\ntant) or AI (i.e., Mathemyths ) presented as a colorful speaker\nas displayed in Fig. 5(a), for co-creating two short stories. In both\nconditions, children participated in a warm-up session to famil-\niarize themselves with the story co-creation activity. This session\nalso served to illustrate how the AI or human partner would pre-\ncisely respond to their interactions, including scenarios where the\nchildren asked questions or chose to remain silent. To facilitate\nchildren‚Äôs story creation, they were handed a plushy (Fig. 5(b)) in\ncase they wished to act out the story or just hold on to it. After\nthe warm-up session, children were free to interact with the AI\nwithout interference or minimal redirection and instructions from\nthe researcher. For both Mathemyths and human conditions, the\ncreation of each story typically lasted 6 minutes, resulting in a total\nduration of approximately 12 minutes for each child.\nAll parts of the procedure were video recorded for later transcrip-\ntion of the stories and coding of open-ended questions. Participants\nhad the option of completing all three parts in a single session or\ncompleting the baseline assessment one day and returning another\nday to complete the story creation activity and learning evaluation.\nWhile children were completing the story creation activity, parents\nwere provided with a questionnaire on an iPad to collect demo-\ngraphic information about their child. Once the child completed\nthe procedure they were given a small prize and a book as a token\nof appreciation and parents received a twenty-dollar Visa gift card\nfor their participation.\n4.2 Evaluation Metrics\nIn this user study, our focus was on children‚Äôs learning of target\nmath vocabulary, the quality of the stories they created, as well\nas their engagement and enjoyment throughout the process. For\nall measures requiring children‚Äôs responses, the questions were\norally narrated and asked by an experimenter, and the children\nwere expected to answer orally as well. Thus, children did not need\nreading or writing skills to answer those questions.\n4.2.1 Learning of Math Language. The research team developed\na 24-item questionnaire focusing on the six math terms (i.e., sum,\nestimate, add, subtract, equal, half ), based on the Common Core\nState Standards [3, 45] and Purpura et al. [74]. These terms were\nassessed through four dimensions: definition, recall, transfer, and\npractice, with each dimension comprising six questions, one ques-\ntion for each target term. For the definition dimension, children\nwere prompted to provide the definition of each of the six math\nterms. In the recall dimension, they were asked to identify each\nterm when its definition was given. For transfer questions, children\nneeded to provide an appropriate math term based on a provided\nreal-life scenario. Lastly, in the practice dimension, children were\nasked to use the target math terms to freely generate descriptions\nfor a picture featuring fruits of various types, amounts, sizes, and\ncolors. The complete questionnaire can be found in Appendix C.\nDuring the pre and post-tests, we utilized the same set of ques-\ntionnaires with slight modifications. For example, in the transfer set\nof questions, nouns were changed ‚Äì (i.e., ‚Äúyou have a jar filled with\ncandies‚Äù became ‚Äúyou have a net filled with butterflies‚Äù). Addition-\nally, all items were presented in a random order. These modifica-\ntions were implemented to reduce the likelihood that children were\nmerely replicating their answers from the baseline assessment.\nTo calculate the scores from this questionnaire, thedefinition and\npractice items, being open-ended, were rated on a binary scale: 0\nfor incorrect and 1 for correct responses. For the recall and transfer\nitems, children first attempted to answer through free recall. If\nunsuccessful, they were then provided with three options to choose\nfrom. Scores were assigned as follows: 2 for correct free recall\nanswers, 1 for correct answers chosen from the given options, and\n0 for incorrect answers. Based on this scoring system, we calculated\na total score by summing the points across all items, with a possible\nrange from 0 to 36. The Cronbach‚Äôs alpha of these items was 0.92.\n4.2.2 Engagement. To understand children‚Äôs engagement in the\nstory co-creation activity with either a human or AI partner, we\nanalyzed their responses using three key indicators: whether they\nprovided a verbal response, the length of each response, and the na-\nture of their responses. The nature of responses was categorized into\nfour types: meta-comments reflecting the child‚Äôs thought process\n(e.g., ‚ÄúI think so. ‚Äù), expressions of uncertainty (e.g., ‚ÄúI don‚Äôt know‚Äù),\nbrief responses with fewer than five words lacking sufficient details,\nand substantial responses containing meaningful details that ad-\nvance the story. Two trained research assistants were responsible for\nthe coding. The first coded transcripts for all participants, and the\nsecond coded 30% of the data for quality control purposes. Between\nthese two coders, there was a 100% agreement rate across all items.\n4.2.3 Story Creation Performance. We analyzed the children‚Äôs per-\nformance on their story creation using two indicators: the number\nof ideas and elaborations, based on prior research [96, 109], An idea\nis defined as a character and its associated action within a single\nutterance. For example, ‚ÄúThe cat climbs the tree‚Äù is one idea, with\n‚Äúcat‚Äù as the character and ‚Äúclimbs‚Äù as the action. An elaboration\nrefers to additional details provided to enrich the idea, such as when,\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nwhere, and why. For instance, ‚ÄúThe cat climbs the tree because it‚Äôs\ncurious and loves to explore‚Äù adds reasoning for the character‚Äôs\naction. One researcher coded the transcripts for all participants,\nand another coded 30% of the participants‚Äô transcripts as a quality\ncheck. This process resulted in a satisfactory Intraclass Correlation\nCoefficient of 0.85.\n4.2.4 Enjoyment. To measure children‚Äôs enjoyment of interacting\nwith AI or humans, we adapted a 4-item questionnaire based on\nWaytz et al. ‚Äôs work [92]. The questions were: (1) Were you happy\nwhen you told stories with []? ; (2) Did you feel comfortable telling sto-\nries with []? ; (3) Would you like to have a reading partner like []? ; and\n(4) Do you want to tell another story with []? . The questionnaire asked\nchildren to indicate their level of agreement with each item, using a\npictorial scale to facilitate their responses. For example, in response\nto the first question, children were presented with five options of\n‚Äúreally happy, ‚Äù ‚Äúhappy, ‚Äù ‚Äúkind of happy, ‚Äù ‚Äúa little bit happy, ‚Äù and ‚Äúnot\nhappy at all. ‚Äù Each option was associated with a circle varying in\nsize from large to small, with the researcher pointing to each circle\nwhile describing the corresponding option. The size of the circle\ncorresponded to the level of happiness, with the largest circle repre-\nsenting the most happiness and the smallest indicating the least. To\nensure that children based their responses onMathemyths and not\non other voice assistants they may have used at home, we reminded\nthem at the beginning that we were specifically asking about the AI\nthey had just created a story with, while also pointing at the device.\nThe Cronbach‚Äôs alpha internal consistency is acceptable at 0.77.\n4.3 Participants\nWe recruited 35 participants (19 female, 16 male) aged between\nfour and eight (ùëÄ = 6, ùëÜùê∑ = 1.35) by advertising in local libraries,\nchildcare centers, and through snowball sampling. Participants\nwere randomly allocated to either the experimental condition using\nour system (ùëÅ = 19) or the control condition involving a human\npartner (ùëÅ = 16). All the participants‚Äô predominant home language\nis English. No significant differences were observed between the\ntwo conditions in terms of children‚Äôs gender, age, baseline math\nlanguage skills, race/ethnicity, prior use of conversational agents,\nor caregiver education (Table 3).\n4.4 Results\nIn this section, we discuss our findings regarding children‚Äôs learning\nof math language, their engagement, performance in story creation,\nas well as enjoyment with either a human partner or AI, Mathe-\nmyths . It‚Äôs important to note that our participants ranged in age\nfrom four to eight years old. This provided a valuable opportunity\nto examine how children at different developmental stages inter-\nact with AI. Thus, we divided the child participants into two age\ngroups: a younger group (ages 4 to 5) and an older group (ages 6 to\n8) [18]. This division allowed us to investigate whether and how\ndevelopmental differences might influence our results.\n4.4.1 Learning of Math Language. Our analysis focused on exam-\nining if there was an improvement in children‚Äôs understanding\nof targeted math terms from the pretest to the posttest, first con-\nsidering the effects by condition (i.e., AI versus human) and then\nexamining if these gains varied between the younger and older\nage groups. To address these questions, we carried out a two-way\nrepeated-measures mixed ANOVA, using condition and age group\nas covariates.\nAs shown in Figure 6, the results indicated significant improve-\nments between the pre- ( ùëÄ = 16.686, ùëÜùê∑ = 9.578) and post-test\n(ùëÄ = 18.971, ùëÜùê∑ = 1.526) math language total scores ( ùêπ(1,31)=\n17.009,ùëù < .000‚àó‚àó‚àó). Moreover, these learning gains were found to\nbe comparable across the AI (pre: ùëÄ = 17.105, ùëÜùê∑ = 9.882; post:\nùëÄ = 19.500, ùëÜùê∑ = 11.074) and human (pre: ùëÄ = 16.187, ùëÜùê∑ = 9.501;\npost: ùëÄ = 18.344, ùëÜùê∑ = 10.158) conditions (ùêπ(1,31)= 0.012,ùëù =\n.912). Statistically, children‚Äôs learning gains showed marginal vari-\nation across different age groups (ùêπ(1,31)= 3.219,ùëù = .083). On\na descriptive level, older children seemed to benefit more from\nthe co-creation activity than younger children, regardless of their\ninteraction with Mathemyths or a human partner. Thus, this age\ndifference did not seem to stem from the nature of interacting with\nAI, but rather might be due to the fact that older children already\nhave a better understanding of the underlying math concepts in\nthe first place, which might amplify their comprehension of the\nassociated math language.\nTo further unpack children‚Äôs learning gains across each dimen-\nsion (i.e., definition, recall, transfer, practice), we carried out addi-\ntional repeated-measures ANOVA analyses. These analyses used\nexperimental conditions and age group as covariates, following\nthe same model we applied in analyzing the total scores. Overall,\nwe found that children‚Äôs gain in math language appeared to be\nprimarily driven by their improved scores in answering transfer\nand practice questions, as the pre-to-post-test gains were statis-\ntically significant in these dimensions, but not in definition and\nrecall. However, when analyzing the pre-to-post gains between\nthe story creation partners (human vs AI), AI partners showed\na notable advantage in enhancing children‚Äôs performance in def-\ninition questions ( ùêπ(1,18) = 8.308,ùëù = .010‚àó‚àó; pre: ùëÄ = 2.737,\nùëÜùê∑ = 1.939; post: ùëÄ = 3.368, ùëÜùê∑ = 2.047), while children with\nhuman partners did not show significant improvement in this di-\nmension (ùêπ(1,15)= 0.015,ùëù = .903; pre: ùëÄ = 2.813, ùëÜùê∑ = 1.621;\npost: ùëÄ = 2.844, ùëÜùê∑ = 1.777). Further analysis by age group re-\nvealed a consistent pattern across all dimensions: older children\nshowed greater improvements than younger ones, although these\ndifferences were not statistically significant.\nTaking together, Mathemyths has shown to be as effective as\na human partner in supporting children‚Äôs math language learning\nthrough storytelling, while also displaying a stronger advantage\nin aiding definition comprehension. Moreover, children from both\nyounger and older age groups benefited from this activity, whether\ninteracting with an AI or human, though older children showed a\nslightly greater advantage.\n4.4.2 Engagement. In our study, children actively engaged in the\nstory co-creation activity withMathemyths . Focusing on the quan-\ntity of their engagement (i.e., response rate and length), children re-\nsponded to over 95% of the questions posed byMathemyths , with\ntheir responses averaging between 6-10 words in length. Generally,\nchildren tended to be more responsive and provided longer answers\nto questions asked by the human partner. Notably, the observed\ndifferences in responsiveness and response length between interac-\ntions with AI and humans appeared to be predominantly exhibited\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nTable 3: Participant information by study conditions. An independent t-test and a series of Chi-squared tests revealed that\nthere are no significant differences between the two conditions in terms of baseline math language skills, age, children‚Äôs gender,\nrace/ethnicity, caregiver education, or prior use of conversational agents.\nFull Sample AI Human Difference\nMath Language Baseline 16.686 17.105 16.188 ùëá (33)= 0.279, ùëù= .391\nAge ùúí2 (1)= 0.308, ùëù= .579\nFull sample 6.000 ( ùëÅ = 35) 6.105 ( ùëÅ = 19) 5.875 ( ùëÅ = 16)\n4-5-year-olds 4.462 ( ùëÅ = 13) 4.333 ( ùëÅ = 6) 4.571 ( ùëÅ = 7)\n6-8-year-olds 6.909 ( ùëÅ = 22) 6.923 ( ùëÅ = 13) 6.889 ( ùëÅ = 9)\nGender ùúí2 (1)= 0.046, ùëù= .830\nFemale 54.29% ( ùëÅ = 19) 52.63% ( ùëÅ = 10) 56.25% ( ùëÅ = 9)\nMale 45.71% ( ùëÅ = 16) 46.37% ( ùëÅ = 9) 43.75% ( ùëÅ = 7)\nRace/Ethnicity ùúí2 (4)= 4.500, ùëù= .343\nBlack 11.43% ( ùëÅ = 4) 15.79% ( ùëÅ = 3) 6.25% ( ùëÅ = 1)\nLatino 8.57% ( ùëÅ = 3) 5.26% ( ùëÅ = 1) 12.50% ( ùëÅ = 2)\nWhite 60.00% ( ùëÅ = 21) 68.42% ( ùëÅ = 13) 50.00% ( ùëÅ = 8)\nOthers 17.14% ( ùëÅ = 6) 10.53% ( ùëÅ = 2) 31.25% ( ùëÅ = 5)\nParents‚Äô Education ùúí2 (2)= 3.240, ùëù= .198\nAbove Bachelor‚Äôs degree 34.29% ( ùëÅ = 12) 47.37% ( ùëÅ = 9) 20.00% ( ùëÅ = 3)\nBachelor‚Äôs degree 54.29% ( ùëÅ = 19) 42.11% ( ùëÅ = 8) 68.75% ( ùëÅ = 11)\nLess than Bachelor‚Äôs degree 11.43% ( ùëÅ = 4) 10.53% ( ùëÅ = 2) 12.50% ( ùëÅ = 2)\nUsage of CA ùúí2 (4)= 1.689, ùëù= .793\nDaily 17.14% ( ùëÅ = 6) 21.05% ( ùëÅ = 4) 12.50% ( ùëÅ = 2)\nWeekly 17.14% ( ùëÅ = 6) 21.05% ( ùëÅ = 4) 12.50% ( ùëÅ = 2)\nMonthly 14.29% ( ùëÅ = 5) 15.79% ( ùëÅ = 3) 12.50% ( ùëÅ = 2)\nLess than once a month 28.57% ( ùëÅ = 10) 21.05% ( ùëÅ = 4) 37.50% ( ùëÅ = 6)\nNever 22.86% ( ùëÅ = 8) 21.05% ( ùëÅ = 4) 25.00% ( ùëÅ = 4)\nN 35 19 16\nFigure 6: Box plots illustrating the data distribution and the results of a two-way repeated-measures mixed ANOVA for the\npre-post-test, using condition and age group as covariates, in the mathematical language assessment. Statistically significant\nresults are reported as ùëù < 0.05‚àó, ùëù < 0.01‚àó‚àó, ùëù < 0.001‚àó‚àó‚àó.\nby older children. As shown in Figure 7, younger children did not\ndifferentiate in their behavior towards the AI versus a human: in\nboth conditions, younger children exhibited almost exactly the same\nrate (AI: ùëÄ = 96.002, ùëÜùê∑ = 5.860; Human: ùëÄ = 96.922, ùëÜùê∑ = 6.511)\nand average response length (AI: ùëÄ = 8.414, ùëÜùê∑ = 6.579; Hu-\nman: ùëÄ = 8.968, ùëÜùê∑ = 4.328). However, older children displayed\na different pattern of interaction with humans, characterized by\nmore frequent (AI: ùëÄ = 92.668, ùëÜùê∑ = 13.436; Human: ùëÄ = 99.246,\nùëÜùê∑ = 2.456) and lengthier (AI: ùëÄ = 6.064, ùëÜùê∑ = 4.546; Human:\nùëÄ = 10.358, ùëÜùê∑ = 7.267) responses compared to their interactions\nwith the AI. However, this observed pattern did not reach statistical\nsignificance: The results of two-way ANOVA analyses indicated\nthat there were no significant differences between younger and\nolder participants across all engagement dimensions.\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nFigure 7: Box plots and bar plots illustrating the distribution of data and the results from the two-way ANOVA regarding\nchildren‚Äôs verbal engagement. Statistically significant results are reported as ùëù < 0.05‚àó, ùëù < 0.01‚àó‚àó, ùëù < 0.001‚àó‚àó‚àó. Error bars\nrepresent 95% confidence intervals (CIs).\nIn terms of the nature of children‚Äôs responses, the majority were\nactual answers that advanced the stories, either substantial or short.\nThis trend was consistent, regardless of whether children partnered\nwith Mathemyths or a human. However, we observed that children\nwere less likely to provide substantial responses when interacting\nwith Mathemyths compared to a human. Additionally, interac-\ntions with Mathemyths elicited a higher incidence of uncertain\nresponses, like ‚ÄúI don‚Äôt know‚Äù, though still relatively infrequent, at a\nrate of 9.9%, as opposed to 1.8% when interacting with humans. This\nincreased frequency of uncertainty in the AI condition might be\nattributed to Mathemyths ‚Äôs tendency to pose unusual or fantasy-\noriented questions. For instance, Mathemyths asked questions\nlike how the characters can use a cloud to speed up their journey,\nwhich are less realistic than questions asked by a researcher such\nas ‚ÄúHow can they get through the traffic circle faster?‚Äù Neverthe-\nless, the use of unusual and imaginative elements in responses may\nnot necessarily be negative, and is actually a common feature in\nchildren‚Äôs literature, especially for younger audiences. Our analysis\nof uncertain responses by younger versus older children revealed\nan interesting trend. While children in general exhibited a higher\nrate of uncertainty when responding to AI, this tendency was more\npronounced among older children. Specifically, younger children\nshowed a 7.6% rate of uncertain responses to AI, compared to 10.9%\nfor older children. In contrast, with human interaction, the rate of\nuncertain responses was only 3.5% for younger children and even\nlower at 0.5% for older children.\n4.4.3 Story Creation Performance. We then focused on the quality\nof the stories children created, measured by the number of ideas\nand elaborations. On average, a child produced about 0.5 idea per\nprompt during interactions with either AI or humans (AI:ùëÄ = .443,\nùëÜùê∑ = .392; Human: ùëÄ = .616, ùëÜùê∑ = .404), amounting to nearly one\nidea every two prompts. In terms of elaboration, children typically\noffered 0.3 detailed elaboration per turn, equating to approximately\n1 elaborate response every three prompts interactions with both\nAI and humans (AI: ùëÄ = .285, ùëÜùê∑ = .241; Human: ùëÄ = .360,\nùëÜùê∑ = .390). As shown in Figure 8, a two-way ANOVA, examin-\ning experimental conditions and age groups, indicated that there\nwere no significant differences in the quality of story creation be-\ntween the Mathemyths and human conditions (ideas: ùêπ(1,66)=\n2.380,ùëù = .128; elaboration: ùêπ(1,66)= .551,ùëù = .461), nor between\nyounger and older children (ideas: ùêπ(1,66)= .165,ùëù = .686; elabo-\nration: ùêπ(1,66)= .130,ùëù = .720).\nNevertheless, it might be quite surprising that younger children\nperformed on par with their older peers in this metric, especially\nfor those who interacted with the Mathemyths (Figure 8), despite\nyounger children‚Äôs presumably less developed language ability. Yet,\nthis might be due to the scaffolding features that we included, such\nas posing follow-up questions and providing hints when children\ndid not formulate substantive responses. These features appeared\nto be effective in further eliciting children‚Äôs responses and engaging\nthem in back-and-forth interactions around one prompt. Thus, the\nscaffolding features could have reduced the presumed differences in\nthe extent of idea elaboration between older and younger children.\n4.4.4 Enjoyment. As shown in Figure 9, children‚Äôs responses to\nthe survey items indicated an overall positive perception of the\nstory co-creation experience. Descriptively, they showed a more\nfavorable reaction to reading with a human partner in terms of en-\njoyment (AI: ùëÄ = 3.68, ùëÜùê∑ = 1.250; Human: ùëÄ = 4.31, ùëÜùê∑ = 1.195)\nand comfort level (AI: ùëÄ = 3.42, ùëÜùê∑ = 1.071; Human: ùëÄ = 3.88,\nùëÜùê∑ = 1.310) compared to AI. Moreover, children slightly favored the\nidea of having the experimenter they interacted with as a reading\npartner (AI: ùëÄ = 3.05, ùëÜùê∑ = 1.682; Human: ùëÄ = 3.38, ùëÜùê∑ = 1.628)\nbut expressed more interest in reading another story with Mathe-\nmyths (AI: ùëÄ = 2.42, ùëÜùê∑ = 1.805; Human: ùëÄ = 2.38, ùëÜùê∑ = 1.455).\nHowever, a two-way ANOVA comparing the two conditions across\ndifferent ages indicated that there were no significant differences\nbetween the AI and human conditions (ùêπ(1,31)= .501,ùëù = .484) or\namong younger and older participants (ùêπ(1,31)= .106,ùëù = .746)\nacross all questions in this enjoyment questionnaire. Additionally,\nno interaction effect was observed between age groups and condi-\ntions.\n4.4.5 Mathemyths Performance. The findings in terms of chil-\ndren‚Äôs learning, engagement, story creation performance, and en-\njoyment above might be better contextualized within the perfor-\nmance of Mathemyths . In this section, we discuss Mathemyths\n‚Äôs performance in terms of interpreting children‚Äôs spoken input as\nwell as its performance in generating responses for children.\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nFigure 8: Box plots illustrating the data distribution, along with the results of the two-way ANOVA comparing the story creation\nperformance of children, using condition and age group as covariates. Statistically significant results are reported as ùëù < 0.05‚àó,\nùëù < 0.01‚àó‚àó, ùëù < 0.001‚àó‚àó‚àó.\nFigure 9: Box plots illustrating the data distribution, along with the results of the two-way ANOVA comparing children‚Äôs\nenjoyment, using condition and age group as covariates. Statistically significant results are reported as ùëù < 0.05‚àó, ùëù < 0.01‚àó‚àó,\nùëù < 0.001‚àó‚àó‚àó.\nIn terms of speech recognition performance, we manually as-\nsessed the accuracy with which the agent in our system recognized\nchildren‚Äôs speech and provided semantically meaningful feedback\nduring each conversational exchange. Our findings revealed that\n87% of children‚Äôs utterances were accurately recognized, resulting\nin feedback that accurately incorporated children‚Äôs input. Elect-\ning unconventional names presented difficulties for the system to\naccurately decipher. It is noteworthy that this challenge was not\nexclusive to our automated system but was also encountered by\nour human experimenter. Furthermore, certain errors might not be\nsolely ascribed to the limitations of the speech recognition technol-\nogy; they were related to the lack of sufficient contextual informa-\ntion in the children‚Äôs speech. For instance, when a child said the\nword ‚Äúknight‚Äù in isolation, the system registered it as ‚Äúnight‚Äù and\nsubsequently proceeded with the follow-up question based on this\ninterpretation. This prompted the child to clarify this with Mathe-\nmyths by specifying ‚ÄúA knight with a sword. ‚Äù Among the successful\nresponses, we adapted an open-source, validated gibberish detec-\ntion model [50] to measure the frequency of nonsensical responses.\nAccording to the model‚Äôs predictions, none of the AI responses were\nidentified as non-sensible. About 80% were classified as entirely\nsensible, while the remaining responses were borderline sensible\n(overall sensible but containing some elements that were illogical).\nIn terms of the performance of the story creation by AI, we\nused the same metric as we used to evaluate children‚Äôs story cre-\nation, namely the number of ideas and elaborations. We compared\nthe number of ideas and elaborations observed in AI-generated\nresponses versus responses produced by human researchers. On av-\nerage, the number of ideas and elaborations generated by humans\n(ùëÄ = 1.938)and AI (ùëÄ = 2.585)is quite comparable. However,\nthere is a substantially larger variation in the stories generated by\nhumans (ùëÜùê∑ = 0.983) than those generated by AI ( ùëÜùê∑ = 0.417),\nsuggesting a higher level of consistency in AI performance. Further\nexamination of the nature of ideas and elaborations generated by\nthe AI and humans corroborated the findings of the model evalua-\ntion mentioned in Section 3.3.2. To reiterate, while Mathemyths\n‚Äôs ideas and elaborations were comparable to humans in terms of\ncreativity and math relevance, the AI‚Äôs contributions posed more\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nchallenges in readability, likely attributed to its frequent incorpora-\ntion of fantasy elements and unrealistic story plots (e.g., a giraffe\nshrinks itself to fit a small space.)\nTaking together, our analysis suggested that whileMathemyths\nperforms satisfactorily in terms of speech recognition and story\ncreation. However, there are certain aspects, such as the charac-\nteristics of the narrative stories, diverge from the typical patterns\nseen with a human story co-creation partner. In the Discussion\nsection below, we will elucidate how such human/AI similarities\nand differences may have contributed to variations in children‚Äôs\nlearning approaches and interaction behaviors.\n5 DISCUSSION\nThis paper explored the potential of using LLMs to develop conver-\nsational systems for teaching mathematical language via child-AI\nco-creative storytelling. Our iterative design and development pro-\ncess provides insights into how prompt engineering methods might\nfeasibly be adapted to suit LLMs for young children in a specific\neducational context, and the model evaluation suggests that prompt-\nengineered LLMs could produce questions and stories approaching\nhuman-like quality. A subsequent user study further showed that\nthe math learning outcomes resulting from interactions with LLMs\nwere also comparable with those from interactions with humans,\nyet the engagement patterns of different ages differed.\nIn the remainder of this section, we will discuss how our study\nspeaks to the growing body of literature on child-AI interactions\nand how we introduce new evidence to still under-explored areas,\nthe design of LLMs as educational, conversational partners. We will\nthen discuss design implications that could guide future develop-\nments. Finally, we will address potential limitations and outline a\nfuture research agenda.\n5.1 AI as Storytelling and Learning Partners\nOur paper provides evidence on children‚Äôs learning and engagement\nwith Mathemyths , as an example of LLMs-based conversational\npartners. There is a substantial body of prior studies showing that\nchildren can learn from their interactions with AI. However, these\nlearning experiences were primarily structured to align with formal\npedagogical discourse, in which children were expected to respond\nto the AI‚Äôs questions with definitive, correct answers [100, 102, 103].\nHowever, our study goes further to suggest that children can ac-\nquire mathematical language through free-form interactions in a\nnarrative-based context with AI, replicating the benefits of the ap-\nproach used by human educators to teach mathematical language\nthrough storytelling. Moreover, our results indicate that this form\nof learning can manifest in multiple ways. Children demonstrated\nan improved ability to define and recall the mathematical terms\nthey were exposed to. Moreover, they exhibited proficiency in trans-\nferring this knowledge to different contexts and using these terms\nmore accurately. Interestingly, earlier studies that explored the ed-\nucational benefits of interacting with an AI companion primarily\nfocused on assessing children‚Äôs information recall [99, 110]. This\nemphasis may have arisen because those previous studies were\nintentionally structured to facilitate more organized conversations\nfor a set of facts [ 99]. However, in our study, we observed that\nchildren not only improved their information recall but also demon-\nstrated enhancements in applying that information and expressing\ncreativity in their language use. This observation can, to some ex-\ntent, be attributed to the increased sense of empowerment and\nagency that children experienced during their story co-creation\nwith Mathemyths .\nNonetheless, children appeared to display somewhat different\nengagement patterns during their interactions with Mathemyths\nin comparison to their interactions with our human researcher.\nWhen considering response quantity, including response rate and\nlength, it appears that children exhibited a slightly more active\nengagement pattern when interacting with humans. However, this\ndisparity became noticeable primarily among the older children\nin our study, as younger children did not seem to differentiate in\nterms of response rate or response length between interactions\nwith AI and humans. This growing divergence in engagement with\nAI and humans with age could be attributed, in part, to children‚Äôs\nperceptions of AI, in particular, their understanding of what AI‚Äôs\ncapabilities and limitations [31, 104]. Specifically, previous research\nhas identified that older children (aged 7-8) were more inclined\nto seek factual information from voice assistants and increasingly\nsought personal information from humans, as compared to younger\nchildren (aged 4 and 5) [31]. Intriguingly, the trend observed in our\nstudy aligns with age-related findings concerning the behavior of\nseeking personal information rather than factual information. This\nalignment is to some extent consistent with the design of Math-\nemyths , which aims to promoting story co-creation that might\ndeviate from a question-answering pedagogical paradigm where\nthe conversational AI‚Äôs primary function is to provide factual infor-\nmation. Furthermore, the differences between age groups were also\ndemonstrated in their behavior of using our scaffolding features.\nYounger children required support from the scaffolding on more oc-\ncasions, yet their creative performance with the scaffolding was on\npar with that of their older peers. This finding aligns with expecta-\ntions, considering younger children possess less-developed literacy\nskills. Our scaffolding features enable younger children to engage\nin and benefit from the new math language learning activity on an\nequal footing with older children. This supports previous research\nadvocating for the initiation of math language interventions at an\nearlier age [71, 82]. Lastly, we examined children‚Äôs preferences for\nco-creating stories with AI or humans and found that children rated\nboth AI and human favorably. However, despite our best efforts to\nensure focused evaluations of the specific co-creation partners, it\nremains essential to acknowledge that children might have drawn\nupon prior AI interactions, such as those with voice assistants at\ntheir homes, which could potentially influence their perceptions\nduring the study [91].\n5.2 Design Challenges of LLMs for Educational\nTechnologies\nIn the design of Mathemyths , we encountered three challenges\nrelated to leveraging LLMs for educational technologies.\n5.2.1 Iterative Prompt Engineering Optimization for LLMs. The ca-\npability of LLMs has attracted much attention from researchers\nto build educational tools for children [ 51]. This paper provides\npivotal evidence on how to optimize LLMs as story co-creators for\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nchildren‚Äôs math language learning through prompt engineering.\nDuring our development, we found that LLMs, with their impressive\ngenerative capabilities, exhibited a higher degree of unpredictability\nin their outputs compared to specialized machine learning models\nspecifically tailored for narrower tasks. The primary reason is that\nthe nuances of how LLMs interpret our prompts remain a ‚Äúblack-\nbox‚Äù for developers. In our efforts at prompt-engineering, there\nwas no guarantee that revising prompts would consistently yield\nthe desired outcomes. This uncertainty aligns with Lin et al. ‚Äôs re-\nsearch [59], where they reported LLMs exhibit ‚Äúdispersion‚Äù in their\npotential predictions for a fixed input (i.e., prompt). Empirical evi-\ndence suggests that prompt engineers often overgeneralize based\non single instances of success or failure when modifying prompts,\nas noted in a recent paper [106]. Therefore, to improve the chances\nof creating prompts that yield consistent intended results, exten-\nsive testing of prompts is crucial. This involves comparing the\nconsistency of outputs and engaging in a refinement process, often\ncharacterized by trial and error. Though the prompt engineering\nprocess might potentially involve a large number of iterations, re-\nfining prompts is relatively less time-consuming, especially when\ncompared to traditional AI model fine-tuning or training.\n5.2.2 Fine-grained Control over LLMs‚Äô Performance. While LLMs‚Äô\nimpressive general language capability allows for easy instruction\nbased on descriptive language, it remains a challenge to provide\nprecise directives to control the output specifically. A significant\naspect of this challenge is associated with LLM‚Äôs limited capacities\nin numerical reasoning [107]. For instance, given thatMathemyths\nwas tailored for young children, we aimed to use brief and sim-\nple language to facilitate comprehension. However, when we set\nspecific word limits within each sentence for GPT-4 (e.g., ‚Äúeach sen-\ntence should not exceed 10 words ‚Äù), the model often disregarded such\nconstraints. In contrast, descriptive instructions without numeric\nvalues, like ‚Äúkeep language brief and child-friendly , ‚Äù consistently\nproduced better results. In light of these limitations, other research\nrecommends incorporating mechanisms for quality checks when\nprecision in output is a priority. Feedback loops [54] and validation\nlayers [38] have been suggested to ensure the model‚Äôs output aligns\nwith the desired requirements.\nAnother observation in our development process relates to LLMs\noccasionally sidestepping structural directives from the original\nprompt after extended conversations. For example, if GPT-4 is in-\nstructed to maintain a specific narrative structure in its responses, it\nmight deviate if these instructions are given only at the beginning.\nThis issue could be attributed to the introduction of non-narrative\nstructural context (e.g., story content, children‚Äôs responses) through-\nout the interaction, which imposes a heavy memory load on LLMs [61].\nShi et al. [85] also found that the inclusion of information irrelevant\nto problem-solving dramatically decreases LLM performance. To\ncounteract this, we employed injection prompting at the end of each\ninput, a point where LLMs perform best in using longer context [61],\nstrategically placing reminders within ongoing interactions. This\napproach enhanced response consistency and adherence to the\ndesired structural format in every response.\n5.2.3 Mitigation of the Impact of LLM Hallucinations. Hallucina-\ntions refer to situations where responses generated by LLMs may\ninitially seem plausible but are actually nonsensical or factually\nincorrect [48, 57]. These models, without correct understanding of\nconcepts, appear to be knowledgeable because they present lan-\nguage associated with the concepts, but without logical filtering. In\nour research,Mathemyths was specifically designed to engage chil-\ndren in story creation involving fantasy elements, rather than tasks\ninvolving mathematical counting or calculation. This approach may\nhave, to some extent, mitigated the issues of factual inaccuracies.\nNevertheless, Mathemyths still produced content that appeared\nless feasible in a real-life context. For instance, it occasionally cre-\nated unusual connections between two common story elements,\nsuch as ‚Äúusing clouds to add speed to a journey. ‚Äù Though the idea\nof using cloud to speed up might seem imaginative in the context\nof a fantasy story [109], it might be problematic in contexts such\nas the teaching of scientific concepts, where unrealistic ideas could\nlead to confusion or misconceptions. This could also explain why\nthe older children were drawn to the human partner, as they might\nfind the nonsensical language weird. Nevertheless, as the field of\nhallucination mitigation in LLMs is relatively nascent, future re-\nsearch could benefit from exploring post-processing techniques that\nscrutinize AI-generated content that might contain hallucinatory\ninformation [23] or employing external knowledge as a framework\nto guide and calibrate the generation of information [78] in LLM-\nbased dialogue systems.\n5.3 Design Implications for Child-AI\nCo-Creative Storytelling Systems\nIn this section, we discuss some design implications of our study.\nOur team has already begun improvements to our co-creative sto-\nrytelling system based on the considerations below.\n5.3.1 Generating Adaptive Questions. During storytelling, Math-\nemyths generates questions to elicit children‚Äôs responses. How-\never, some children found certain questions challenging to answer.\nThis was evident from the notably higher rate of uncertainty in\ntheir responses to AI-generated questions compared to those posed\nby human partner. While we implemented scaffolding features to\nassist children when they struggle to respond, the AI might not\nalways capture the nuances of a child‚Äôs emotions and experiences.\nSpecifically, it may not always discern precisely what factors (e.g.,\nlanguage barriers, math knowledge gaps, or unwillingness to partic-\nipate) caused their struggle. As a result, while the AI provided some\nscaffolding based on several broad categories, it did not offer more\ntailored adjustments in response to the unique challenges faced\nby individual children. One design consideration is to integrate\nmore adaptive algorithms into LLM-based tools that can accurately\nassess a child‚Äôs cognitive load based on their responses and adjust\nthe complexity of the questions accordingly.\n5.3.2 Providing Multi-modal Creativity Support. Our study revealed\nthe potential benefits of child-AI co-creative storytelling for enhanc-\ning children‚Äôs creativity. Mathemyths was developed for verbal\ninteractions with children, which was a significant initial step con-\nsidering our primary focus on the language capabilities of LLMs. For\nfuture designs, incorporating graphical interfaces or multimedia el-\nements could be beneficial. Such additions would enable children to\nvisualize the story narratives, allowing them to express their ideas\nnot only through words but also through drawings, animations,\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nand sound effects. This can not only augment children‚Äôs creative\nexperience [108, 109], but also improve children‚Äôs comprehension\nof abstract concepts [22]. In this context, consistent interactions\nwith AI, which might promote long-term creativity in children,\nbecome even more significant as they have shown the capability to\nlearn or emulate creativity from AI interactions [5, 6].\n5.3.3 Supporting Embodied Interaction. In this paper,Mathemyths\nengages children in joint storytelling through a device similar to\nsmart-speakers. While this platform can be easily navigated via\nvoice, it might fall short in conveying emotions or actions‚Äîa vital\naspect that captivates children during interactions with human\ncounterparts. To compromise it during our user study, we provided\nchildren with a plushy. Nonetheless, this might not fully capture\nthe advantages of tangible interactions. A promising solution could\nbe to integrate this virtual agent with an embodied robot, which\ncan offer more vivid feedback through its human-like expressions\nand behaviors [43, 95]. It is potential that an embodied robot could\nstimulate different or perhaps heightened levels of engagement.\nHowever, the cost implications and scalability concerns associated\nwith robots cannot be ignored.\n5.4 Limitations and Future Work\nWhile our study offers preliminary insights, it also paves the way\nfor addressing further questions in the future.\nFirst, in our user study, we compared children‚Äôs interactions with\nMathemyths with those with a trained researcher who adhered\nto a strict protocol for narrating stories. This protocol ensured the\ninclusion of a specified number of mathematical terms. While this\napproach granted us a controlled environment, ensuring consis-\ntent mathematical language exposure for the children, it might\nhave constrained the natural adaptability and spontaneity that a\nhuman experimenter can bring to the storytelling process. In future\nresearch, it would be intriguing to also compare children‚Äôs engage-\nment and enjoyment with a human partner who can fully harness\ntheir natural storytelling capabilities.\nRelated, we compared the learning outcomes between story-\ntelling with AI or humans but did not include a comparison to\nmore conventional instructional methods, such as directly teaching\nthe terms, providing examples, allowing the child to practice, and\noffering corrective feedback. Although prior research has indicated\nsuperior learning outcomes with story-based methods involving\na teacher, exploring whether this advantage over direct instruc-\ntion extends to AI-driven contexts presents an intriguing research\navenue. Additionally, our current participant pool predominantly\nconsists of families with higher educational backgrounds. These\nchildren are likely to have greater access to conversational AI tech-\nnologies, which may have influenced their interaction with our\nsystem. Future research should focus on including children with\nlimited technological access to evaluate if LLM-based learning tools\nremain effective in such contexts.\nIn addition, our study‚Äôs participants engaged in only two AI col-\nlaborative storytelling sessions. This short-term access might not\nfully reflect the dynamics of extended interactions children might\nhave with such systems. As children become more accustomed\nto the AI over time, their expectations could evolve, potentially\nrequiring more advanced and adaptive storytelling experiences. On\nthe other hand, repeated sessions could lead to a more harmonized\nchild-AI collaboration, potentially enriching the storytelling pro-\ncess. Future studies should explore these longer-term dynamics,\nperhaps by giving children extended opportunities to interact with\nthe AI storytelling system and tracking their engagement patterns\nover extended periods.\n5.5 A Note on Ethical Considerations\nThe safe use of AI by children has been a topic of public discussion\nfor some time. As we transition to an era dominated by generative\nAI, the debate becomes even more pressing. In this new landscape,\nchildren may directly encounter content produced by AI without\nthe protective filters traditionally provided by human oversight. In\nthis section, we will focus on some ethical considerations pertaining\nto privacy and safety.\nIn terms of privacy, Mathemyths utilizes two cloud-based ser-\nvices to process children‚Äôs utterances: Google‚Äôs speech-to-text for\ntranscribing and OpenAI‚Äôs GPT-4 to interpret their responses. Both\ncompanies offer measures to protect children‚Äôs data. Specifically,\nchildren‚Äôs utterances are not stored and are promptly deleted after\ntranscription by Google Cloud. Additionally, OpenAI commits not\nto train their models with data passed through their APIs7. How-\never, when these cloud-based AI products enter the market, the\nadequacy of children‚Äôs data privacy protection remains uncertain\ndue to the absence of specific regulations for AI products. While\nthe US Children‚Äôs Online Privacy Protection Act (COPPA) regulates\nthe collection and use of personal information from those under\n13, it has yet to be updated to tackle the emerging concerns related\nto AI.\nIn terms of safefy, to safeguard against inappropriate AI-generated\ncontent, we integrated a moderation layer, utilizing the OpenAI\nAPIs8, to ensure outputs were devoid of sexual content, hate speech,\nharassment, violence, or self-harm. However, this content filtering\napproach might not be as effective in addressing biases and stereo-\ntypes (e.g., when a child asks ‚ÄúWhat do girls do? ‚Äù, and the AI agent\nresponds ‚Äúhousewives‚Äù), given that these biases are as deeply in-\ngrained in the data used to train AI systems as they are in the rest of\nthe culture. Nonetheless, a growing number of studies have begun\nto investigate methods for detecting and reducing such stereotypes\nand biases, although these studies have not specifically focused on\nchildren. Given the present state of technology, a viable approach\nwould be to deploy LLMs within a ‚Äúwalled garden‚Äù‚Äîlimiting inter-\nactions to narrower domains, like the math-focused narratives in\nour study. Such confines might mitigate risks while still capitalizing\non the capabilities of LLMs.\n6 CONCLUSION\nWhile AI has been utilized for structured interactions with children\nfor quite a while, such as dialogic question-answering, the affor-\ndance provided by LLMs in facilitating free-form, creative tasks, like\njoint storytelling, signifies a groundbreaking shift. This research\nexplores that very frontier. Our findings suggested that, although\nthe learning outcomes with AI mirror those with human partners,\nthe interaction dynamics are different. Instead of viewing this as a\n7https://openai.com/api-data-privacy\n8https://platform.openai.com/docs/api-reference/moderations\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nlimitation, it might be more fruitful to recognize AI as providing a\nunique interaction opportunity. These interactions, while different,\ncould supplement children‚Äôs everyday human interactions. Given\nthe rapid advancements in LLMs, the capabilities we observe today\nare likely to further refine in the near future. Yet, the insights gar-\nnered now will shape and anchor our design philosophies as we\nmove forward.\nACKNOWLEDGMENTS\nThis paper is supported by the National Science Foundation under\nGrant No. 2302730. We thank the children who participated in our\nstudy and our local public libraries for graciously offering space for\nus to recruit participants and carry out the study. We also thank the\nresearch assistants at the University of Michigan for their assistance\nwith data collection and analysis.\nREFERENCES\n[1] Rania Abdelghani, Yen-Hsiang Wang, Xingdi Yuan, Tong Wang, Pauline Lucas,\nH√©l√®ne Sauz√©on, and Pierre-Yves Oudeyer. 2023. GPT-3-Driven Pedagogical\nAgents for Training Children‚Äôs Curious Question-Asking Skills. https://doi.\norg/10.1007/s40593-023-00340-7 arXiv:2211.14228 [cs]\n[2] Olaiya Aina. 1999. The Importance of Oral Storytelling in Literacy Development.\nOhio Reading Teacher 33, 1 (1999), 15‚Äì18.\n[3] Murat Akkus. 2016. The Common Core State Standards for Mathematics. Inter-\nnational Journal of Research in Education and Science 2, 1 (2016), 49‚Äì54.\n[4] Amal Alabdulkarim, Siyan Li, and Xiangyu Peng. 2021. Automatic Story Gen-\neration: Challenges and Attempts. https://doi.org/10.48550/arXiv.2102.12634\narXiv:2102.12634 [cs]\n[5] Safinah Ali, Tyler Moroso, and Cynthia Breazeal. 2019. Can Children Learn\nCreativity from a Social Robot?. In Proceedings of the 2019 on Creativity and\nCognition (C&C ‚Äô19) . Association for Computing Machinery, New York, NY,\nUSA, 359‚Äì368. https://doi.org/10.1145/3325480.3325499\n[6] Safinah Ali, Hae Won Park, and Cynthia Breazeal. 2020. Can Children Emulate\na Robotic Non-Player Character‚Äôs Figural Creativity?. In Proceedings of the\nAnnual Symposium on Computer-Human Interaction in Play (CHI PLAY ‚Äô20) .\nAssociation for Computing Machinery, New York, NY, USA, 499‚Äì509. https:\n//doi.org/10.1145/3410404.3414251\n[7] Minhui Bao. 2019. Can Home Use of Speech-Enabled Artificial Intelligence\nMitigate Foreign Language Anxiety‚ÄìInvestigation of a Concept. Arab World\nEnglish Journal (AWEJ) Special Issue on CALL 1, 5 (2019), 28‚Äì40.\n[8] Erin Beneteau, Ashley Boone, Yuxing Wu, Julie A. Kientz, Jason Yip, and Alexis\nHiniker. 2020. Parenting with Alexa: Exploring the Introduction of Smart\nSpeakers on Family Dynamics. In Proceedings of the 2020 CHI Conference on\nHuman Factors in Computing Systems . Association for Computing Machinery,\nNew York, NY, USA, 1‚Äì13.\n[9] Frank Bentley, Chris Luvogt, Max Silverman, Rushani Wirasinghe, Brooke\nWhite, and Danielle Lottridge. 2018. Understanding the Long-Term Use of Smart\nSpeaker Assistants. Proceedings of the ACM on Interactive, Mobile, Wearable and\nUbiquitous Technologies 2, 3 (2018), 1‚Äì24.\n[10] Marina Umaschi Bers and Justine Cassell. 1998. Interactive Storytelling Systems\nfor Children: Using Technology to Explore Language and Identity. Journal of\nInteractive Learning Research 9 (1998), 183‚Äì215.\n[11] Marina Umaschi Bers and Justine Cassell. 1998. Interactive storytelling systems\nfor children: Using technology to explore language and identity. Journal of\nInteractive Learning Research 9 (1998), 183‚Äì215.\n[12] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,\nChristopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. 2020. Language Models Are Few-Shot Learners.\nhttps://doi.org/10.48550/arXiv.2005.14165 arXiv:2005.14165 [cs]\n[13] Adriana G. Bus, Marinus H. van IJzendoorn, and Anthony D. Pellegrini. 1995.\nJoint Book Reading Makes for Success in Learning to Read: A Meta-Analysis on\nIntergenerational Transmission of Literacy. Review of Educational Research 65,\n1 (March 1995), 1‚Äì21. https://doi.org/10.3102/00346543065001001\n[14] John Bynner and Samantha Parsons. 1997. Does Numeracy Matter? Evidence\nfrom the National Child Development Study on the Impact of Poor Numeracy on\nAdult Life. Technical Report. Basic Skills Agency, Commonwealth House, 1-19\nNew Oxford Street, London WC1A 1NU, England, United Kingdom (6.\n[15] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Se-\nbastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua\nMaynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar\nPrabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Brad-\nbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke,\nAnselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier\nGarcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ip-\npolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan\nSepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai,\nThanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Er-\nica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou,\nXuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason\nWei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah\nFiedel. 2022. PaLM: Scaling Language Modeling with Pathways. https:\n//doi.org/10.48550/arXiv.2204.02311 arXiv:2204.02311 [cs]\n[16] John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan\nAdar, and Minsuk Chang. 2022. TaleBrush: Sketching Stories with Generative\nPretrained Language Models. InProceedings of the 2022 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô22) . Association for Computing Machinery,\nNew York, NY, USA, 1‚Äì19. https://doi.org/10.1145/3491102.3501819\n[17] Eric Dearing, Beth Casey, Pamela E Davis-Kean, Sarah Eason, Elizabeth Gunder-\nson, Susan C Levine, Elida V Laski, Melissa Libertus, Linxi Lu, Caitlin McPherran\nLombardi, et al. 2022. Socioeconomic variations in the frequency of parent num-\nber talk: A meta-analysis. Education Sciences 12, 5 (2022), 312.\n[18] Griffin Dietz, Jimmy K Le, Nadin Tamer, Jenny Han, Hyowon Gweon, Elizabeth L\nMurnane, and James A. Landay. 2021. StoryCoder: Teaching Computational\nThinking Concepts Through Storytelling in a Voice-Guided App for Children. In\nProceedings of the 2021 CHI Conference on Human Factors in Computing Systems\n(CHI ‚Äô21) . Association for Computing Machinery, New York, NY, USA, 1‚Äì15.\nhttps://doi.org/10.1145/3411764.3445039\n[19] R. Dijkstra, Z. Gen√ß, S. Kayal, and J. Kamps. 2022. Reading Comprehension Quiz\nGeneration Using Generative Pre-Trained Transformers. In The 23th Interna-\ntional Conference on Artificial Intelligence in Education (AIED . Springer, New\nYork, NY, USA, 1‚Äì14.\n[20] Greg J. Duncan, Chantelle J. Dowsett, Amy Claessens, Katherine Magnuson,\nAletha C. Huston, Pamela Klebanov, Linda S. Pagani, Leon Feinstein, Mimi Engel,\nJeanne Brooks-Gunn, Holly Sexton, Kathryn Duckworth, and Crista Japel. 2007.\nSchool Readiness and Later Achievement. Developmental Psychology 43, 6 (Nov.\n2007), 1428‚Äì1446. https://doi.org/10.1037/0012-1649.43.6.1428\n[21] Alessandro Duranti and Charles Goodwin. 1992. Rethinking Context: Language\nas an Interactive Phenomenon . Number 11 in 1. Cambridge University Press,\nCambridge, England.\n[22] Utkarsh Dwivedi, Nitendra Rajput, Prasenjit Dey, and Blessin Varkey. 2017.\nVisualMath: An Automated Visualization System for Understanding Math Word-\nProblems. In Proceedings of the 22nd International Conference on Intelligent\nUser Interfaces Companion (IUI ‚Äô17 Companion) . Association for Computing\nMachinery, New York, NY, USA, 105‚Äì108. https://doi.org/10.1145/3030024.\n3040989\n[23] Nouha Dziri, Andrea Madotto, Osmar Za√Øane, and Avishek Joey Bose. 2021.\nNeural Path Hunter: Reducing Hallucination in Dialogue Systems via Path\nGrounding. In Proceedings of the 2021 Conference on Empirical Methods in Natural\nLanguage Processing , Marie-Francine Moens, Xuanjing Huang, Lucia Specia,\nand Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, Online\nand Punta Cana, Dominican Republic, 2197‚Äì2214. https://doi.org/10.18653/v1/\n2021.emnlp-main.168\n[24] Reham El Shazly. 2021. Effects of Artificial Intelligence on English Speaking\nAnxiety and Speaking Performance: A Case Study. Expert Systems 38, 3 (2021),\ne12667.\n[25] Leanne Elliott and Heather J Bachman. 2018. SES disparities in early math\nabilities: The contributions of parents‚Äô math cognitions, practices to support\nmath, and math talk. Developmental Review 49 (2018), 1‚Äì15.\n[26] Leanne Elliott, Emily J Braham, and Melissa E Libertus. 2017. Understanding\nsources of individual variability in parents‚Äô number talk with young children.\nJournal of Experimental Child Psychology 159 (2017), 1‚Äì15.\n[27] Amaechi Uneke Enyi. 2015. Language and Interactional Discourse: Decon-\nstrusting the Talk-Generating Machinery in Natural Convresation. Advances in\nLanguage and Literary Studies 6, 4 (2015), 171‚Äì178.\n[28] Erin Elizabeth Flynn. 2018. Ideas in dialogue: Leveraging the power of child-led\nstorytelling in the multicultural preschool classroom. Language in Society 47, 4\n(2018), 601‚Äì633.\n[29] Ebrahim Gabajiwala, Priyav Mehta, Ritik Singh, and Reeta Koshy. 2022. Quiz\nMaker: Automatic Quiz Generation from Text Using NLP. InFuturistic Trends in\nNetworks and Computing Technologies: Select Proceedings of Fourth International\nConference on FTNCT 2021 . Springer, New York, NY, USA, 523‚Äì533.\n[30] Asma Ghandeharioun, Judy Hanwen Shen, Natasha Jaques, Craig Ferguson,\nNoah Jones, Agata Lapedriza, and Rosalind Picard. 2019. Approximating In-\nteractive Human Evaluation with Self-Play for Open-Domain Dialog Systems.\nhttps://doi.org/10.48550/arXiv.1906.09308 arXiv:1906.09308 [cs, stat]\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\n[31] Lauren N Girouard-Hallam and Judith H Danovitch. 2022. Children‚Äôs trust in\nand learning from voice assistants. Developmental Psychology 58, 4 (2022), 646.\n[32] Manuela Glaser, B√§rbel Garsoffky, and Stephan Schwan. 2009. Narrative-Based\nLearning: Possible Benefits and Problems. The European Journal of Communica-\ntion Research 34, 4 (Dec. 2009), 429‚Äì447. https://doi.org/10.1515/COMM.2009.026\n[33] Arthur C. Graesser, Mark W. Conley, and Andrew Olney. 2012. Intelligent\nTutoring Systems. APA educational psychology handbook 3 (2012), 451‚Äì473.\n[34] Arthur C. Graesser, Sidney D‚ÄôMello, Xiangen Hu, Zhiqiang Cai, Andrew Olney,\nand Brent Morgan. 2012. AutoTutor. In Applied Natural Language Processing:\nIdentification, Investigation and Resolution . IGI Global, Hershey, PA, USA, 169‚Äì\n187.\n[35] Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, and Minlie Huang. 2020. A\nKnowledge-Enhanced Pretraining Model for Commonsense Story Generation.\nTransactions of the Association for Computational Linguistics 8 (Jan. 2020), 93‚Äì108.\nhttps://doi.org/10.1162/tacl_a_00302\n[36] Brenna Hassinger-Das, Nancy C. Jordan, and Nancy Dyson. 2015. Reading\nStories to Learn Math. The Elementary School Journal 116, 2 (Dec. 2015), 242‚Äì\n264. https://doi.org/10.1086/683986\n[37] Brenna Hassinger-Das, Nancy C. Jordan, and Nancy Dyson. 2015. Reading\nStories to Learn Math: Mathematics Vocabulary Instruction for Children with\nEarly Numeracy Difficulties. The Elementary School Journal 116, 2 (2015), 242‚Äì\n264.\n[38] Joy He-Yueya, Gabriel Poesia, Rose E. Wang, and Noah D. Goodman. 2023.\nSolving Math Word Problems by Combining Language Models With Symbolic\nSolvers. https://doi.org/10.48550/arXiv.2304.09102 arXiv:2304.09102 [cs]\n[39] Alexis Hiniker, Hyewon Suh, Sabina Cao, and Julie A. Kientz. 2016. Screen Time\nTantrums: How Families Manage Screen Media Experiences for Toddlers and\nPreschoolers. In Proceedings of the 2016 CHI Conference on Human Factors in\nComputing Systems (CHI ‚Äô16) . Association for Computing Machinery, New York,\nNY, USA, 648‚Äì660. https://doi.org/10.1145/2858036.2858278\n[40] Hui-Ru Ho, Nathan Thomas White, Edward M. Hubbard, and Bilge Mutlu. 2023.\nDesigning Parent-Child-Robot Interactions to Facilitate In-Home Parental Math\nTalk with Young Children. InProceedings of the 22nd Annual ACM Interaction\nDesign and Children Conference (IDC ‚Äô23) . Association for Computing Machinery,\nNew York, NY, USA, 355‚Äì366. https://doi.org/10.1145/3585088.3589358\n[41] Robin L. Hojnoski, Helen Lynn Columba, and Joy Polignano. 2014. Embedding\nMathematical Dialogue in Parent‚ÄìChild Shared Book Reading: A Preliminary\nInvestigation. Early Education and Development 25, 4 (May 2014), 469‚Äì492.\nhttps://doi.org/10.1080/10409289.2013.810481\n[42] Layne Jackson Hubbard, Yifan Chen, Eliana Colunga, Pilyoung Kim, and Tom\nYeh. 2021. Child-Robot Interaction to Integrate Reflective Storytelling Into\nCreative Play. In Proceedings of the 13th Conference on Creativity and Cognition\n(C&amp;C ‚Äô21). Association for Computing Machinery, New York, NY, USA, 1‚Äì8.\nhttps://doi.org/10.1145/3450741.3465254\n[43] Layne Jackson Hubbard, Yifan Chen, Eliana Colunga, Pilyoung Kim, and Tom\nYeh. 2021. Child-Robot Interaction to Integrate Reflective Storytelling Into Cre-\native Play. InCreativity and Cognition (C&amp;C ‚Äô21) . Association for Computing\nMachinery, New York, NY, USA, 1‚Äì8. https://doi.org/10.1145/3450741.3465254\n[44] Charlotte S. Huck and Barbara Zulandt Kiefer. 2003. Children‚Äôs Literature in the\nElementary School (8th edition ed.). Mcgraw-Hill College, Boston.\n[45] Common Core State Standards Initiative. 2010. Mathematics Standards ‚Äì Com-\nmon Core State Standards Initiative.\n[46] Clara M. Jennings, James E. Jennings, Joyce Richey, and Lisbeth Dixon-Krauss.\n1992. Increasing Interest and Achievement in Mathematics through Children‚Äôs\nLiterature. Early Childhood Research Quarterly 7, 2 (June 1992), 263‚Äì276. https:\n//doi.org/10.1016/0885-2006(92)90008-M\n[47] Hyangeun Ji, Insook Han, and Yujung Ko. 2022. A Systematic Review of Conver-\nsational AI in Language Education: Focusing on the Collaboration with Human\nTeachers. Journal of Research on Technology in Education 55, 1 (2022), 48‚Äì63.\n[48] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,\nYe Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of Hallucination\nin Natural Language Generation. ACM Comput. Surv. 55, 12 (March 2023),\n248:1‚Äì248:38. https://doi.org/10.1145/3571730\n[49] Qinjin Jia, Jialin Cui, Yunkai Xiao, Chengyuan Liu, Parvez Rashid, and Ed-\nward F. Gehringer. 2021. ALL-IN-ONE: Multi-Task Learning BERT Models\nfor Evaluating Peer Assessments. https://doi.org/10.48550/arXiv.2110.03895\narXiv:2110.03895 [cs]\n[50] Madhur Jindal. 2022. Madhurjindal/Autonlp-Gibberish-Detector-492513457\n¬∑ Hugging Face. https://huggingface.co/madhurjindal/autonlp-Gibberish-\nDetector-492513457.\n[51] Enkelejda Kasneci, Kathrin Se√üler, Stefan K√ºchemann, Maria Bannert, Daryna\nDementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G√ºnnemann,\nEyke H√ºllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia\nNerdel, J√ºrgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt,\nTina Seidel, Matthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci.\n2023. ChatGPT for Good? On Opportunities and Challenges of Large Language\nModels for Education. https://doi.org/10.35542/osf.io/5er8f\n[52] Saba Kawas, Nicole S. Kuhn, Kyle Sorstokke, Emily Bascom, Alexis Hiniker,\nand Katie Davis. 2021. When Screen Time Isn‚Äôt Screen Time: Tensions and\nNeeds Between Tweens and Their Parents During Nature-Based Exploration. In\nProceedings of the 2021 CHI Conference on Human Factors in Computing Systems\n(CHI ‚Äô21) . Association for Computing Machinery, New York, NY, USA, 1‚Äì14.\nhttps://doi.org/10.1145/3411764.3445142\n[53] Anne Lamott. 1995. Bird by Bird: Some Instructions on Writing and Life (1st\nedition ed.). Anchor, New York.\n[54] Dongyub Lee, Taesun Whang, Chanhee Lee, and Heuiseok Lim. 2023. To-\nwards Reliable and Fluent Large Language Models: Incorporating Feedback\nLearning Loops in QA Systems. https://doi.org/10.48550/arXiv.2309.06384\narXiv:2309.06384 [cs]\n[55] Yoonjoo Lee, Tae Soo Kim, Minsuk Chang, and Juho Kim. 2022. Interactive\nChildren‚Äôs Story Rewriting Through Parent-Children Interaction. InProceedings\nof the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing\n2022). Association for Computational Linguistics, Dublin, Ireland, 62‚Äì71. https:\n//doi.org/10.18653/v1/2022.in2writing-1.9\n[56] Yoonjoo Lee, Tae Soo Kim, Sungdong Kim, Yohan Yun, and Juho Kim. 2023.\nDAPIE: Interactive Step-by-Step Explanatory Dialogues to Answer Children‚Äôs\nWhy and How Questions. In Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô23) . Association for Computing Machinery,\nNew York, NY, USA, 1‚Äì22. https://doi.org/10.1145/3544548.3581369\n[57] Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen. 2023.\nHaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Lan-\nguage Models. https://doi.org/10.48550/arXiv.2305.11747 arXiv:2305.11747 [cs]\n[58] Margaret Li, Jason Weston, and Stephen Roller. 2019. ACUTE-EVAL: Improved\nDialogue Evaluation with Optimized Questions and Multi-Turn Comparisons.\nhttps://doi.org/10.48550/arXiv.1909.03087 arXiv:1909.03087 [cs]\n[59] Zhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023. Generating with Con-\nfidence: Uncertainty Quantification for Black-Box Large Language Models.\nhttps://doi.org/10.48550/arXiv.2305.19187 arXiv:2305.19187 [cs, stat]\n[60] Ellen C Litkowski, Robert J Duncan, Jessica AR Logan, and David J Purpura.\n2020. When do preschoolers learn specific mathematics skills? Mapping the\ndevelopment of early numeracy knowledge. Journal of Experimental Child\nPsychology 195 (2020), 104846.\n[61] Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilac-\nqua, Fabio Petroni, and Percy Liang. 2023. Lost in the Middle: How Lan-\nguage Models Use Long Contexts. https://doi.org/10.48550/arXiv.2307.03172\narXiv:2307.03172 [cs]\n[62] Silvia B. Lovato and Anne Marie Piper. 2019. Young Children and Voice Search:\nWhat We Know from Human-Computer Interaction Research. Frontiers in\npsychology 10 (2019), 8.\n[63] Silvia B. Lovato, Anne Marie Piper, and Ellen A. Wartella. 2019. Hey Google,\nDo Unicorns Exist? Conversational Agents as a Path to Answers to Children‚Äôs\nQuestions. In Proceedings of the 18th ACM International Conference on Interaction\nDesign and Children . Association for Computing Machinery, New York, NY, USA,\n301‚Äì313.\n[64] Kurt Messick. 2023. ChatGPT as Author - 100 Words or Less: 100 Short Stories\nGenerated by AI . Independently published, Bloomington, Indiana, USA.\n[65] Lesley Mandel Morrow. 1985. Retelling Stories: A Strategy for Improving Young\nChildren‚Äôs Comprehension, Concept of Story Structure, and Oral Language\nComplexity. The Elementary School Journal 85, 5 (May 1985), 647‚Äì661. https:\n//doi.org/10.1086/461427\n[66] Olga Nelson. 1989. Storytelling: Language experience for meaning making. The\nReading Teacher 42, 6 (1989), 386‚Äì390.\n[67] OpenAI. 2022. Introducing ChatGPT. https://openai.com/blog/chatgpt.\n[68] OpenAI. 2023. GPT-4. https://openai.com/gpt-4.\n[69] Hiroyuki Osone, Jun-Li Lu, and Yoichi Ochiai. 2021. BunCho: AI Supported Story\nCo-Creation via Unsupervised Multitask Learning to Increase Writers&#x2019;\nCreativity in Japanese. In Extended Abstracts of the 2021 CHI Conference on\nHuman Factors in Computing Systems (CHI EA ‚Äô21) . Association for Computing\nMachinery, New York, NY, USA, 1‚Äì10. https://doi.org/10.1145/3411763.3450391\n[70] Alison H Paris and Scott G Paris. 2003. Assessing narrative comprehension in\nyoung children. Reading Research Quarterly 38, 1 (2003), 36‚Äì76.\n[71] Samantha Parsons and John M. Bynner. 2005. Does Numeracy Matter More?\nNational Research and Development Centre for Adult Literacy and Numeracy,\nLondon, UK.\n[72] Martin Porcheron, Joel E. Fischer, Stuart Reeves, and Sarah Sharples. 2018. Voice\nInterfaces in Everyday Life. In Proceedings of the 2018 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô18) . Association for Computing Machinery,\nNew York, NY, USA, 1‚Äì12. https://doi.org/10.1145/3173574.3174214\n[73] Sarah R. Powell and Melissa K. Driver. 2015. The Influence of Mathematics\nVocabulary Instruction Embedded Within Addition Tutoring for First-Grade\nStudents With Mathematics Difficulty. Learning Disability Quarterly 38, 4 (Nov.\n2015), 221‚Äì233. https://doi.org/10.1177/0731948714564574\n[74] David J. Purpura and Jessica A. R. Logan. 2015. The Nonlinear Relations of the\nApproximate Number System and Mathematical Language to Early Mathematics\nDevelopment. Developmental Psychology 51, 12 (2015), 1717‚Äì1724. https:\n//doi.org/10.1037/dev0000055\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\n[75] David J. Purpura, Amy R. Napoli, and Yemimah King. 2019. Development\nof Mathematical Language in Preschool and Its Role in Learning Numeracy\nSkills. In Cognitive Foundations for Improving Mathematical Learning . Elsevier\nAcademic Press, San Diego, CA, US, 175‚Äì193. https://doi.org/10.1016/B978-0-\n12-815952-1.00007-4\n[76] David J. Purpura, Amy R. Napoli, Elizabeth A. Wehrspann, and Zachary S. Gold.\n2017. Causal Connections Between Mathematical Language and Mathematical\nKnowledge: A Dialogic Reading Intervention. Journal of Research on Educational\nEffectiveness 10, 1 (Jan. 2017), 116‚Äì137. https://doi.org/10.1080/19345747.2016.\n1204639\n[77] David J. Purpura, Sara A. Schmitt, Amy R. Napoli, Jennifer Dobbs-Oates,\nYemimah A. King, Caroline Byrd Hornburg, Lauren Westerberg, Giulia A. Bor-\nriello, Lindsey M. Bryant, Laura Y. Anaya, Melody Kung, Ellen Litkowski, Joyce\nLin, and Emily Rolan. 2021. Engaging Caregivers and Children in Picture Books:\nA Family-Implemented Mathematical Language Intervention. Journal of Educa-\ntional Psychology 113 (2021), 1338‚Äì1353. https://doi.org/10.1037/edu0000662\n[78] Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hao Tian,\nHua Wu, Ji-Rong Wen, and Haifeng Wang. 2023. Investigating the Factual\nKnowledge Boundary of Large Language Models with Retrieval Augmentation.\nhttps://doi.org/10.48550/arXiv.2307.11019 arXiv:2307.11019 [cs]\n[79] Sherry Ruan, Jiayu He, Rui Ying, Jonathan Burkle, Dunia Hakim, Anna Wang,\nYufeng Yin, Lily Zhou, Qianyao Xu, Abdallah AbuHashem, Griffin Dietz, Eliz-\nabeth L. Murnane, Emma Brunskill, and James A. Landay. 2020. Support-\ning Children‚Äôs Math Learning with Feedback-Augmented Narrative Technol-\nogy. In Proceedings of the Interaction Design and Children Conference (IDC\n‚Äô20). Association for Computing Machinery, New York, NY, USA, 567‚Äì580.\nhttps://doi.org/10.1145/3392063.3394400\n[80] Kimiko Ryokai, Cati Vaucelle, and Justine Cassell. 2003. Virtual Peers as Partners\nin Storytelling and Literacy Learning. Journal of computer assisted learning 19,\n2 (2003), 195‚Äì208.\n[81] Michael Sailer, Elisabeth Bauer, Riikka Hofmann, Jan Kiesewetter, Julia Glas,\nIryna Gurevych, and Frank Fischer. 2023. Adaptive Feedback from Artificial\nNeural Networks Facilitates Pre-Service Teachers‚Äô Diagnostic Reasoning in\nSimulation-Based Learning. Learning and Instruction 83 (2023), 101620.\n[82] Julie Sarama and Douglas H. Clements. 2009. Early Childhood Mathematics\nEducation Research: Learning Trajectories for Young Children . Routledge, New\nYork, NY, USA.\n[83] Michael Schiro. 2004. Oral Storytelling and Teaching Mathematics: Pedagogical\nand Multicultural Perspectives . SAGE, Thousand Oaks, CA, USA.\n[84] Hanieh Shakeri, Carman Neustaedter, and Steve DiPaola. 2021. SAGA: Collab-\norative Storytelling with GPT-3. In Companion Publication of the 2021 Confer-\nence on Computer Supported Cooperative Work and Social Computing (CSCW\n‚Äô21). Association for Computing Machinery, New York, NY, USA, 163‚Äì166.\nhttps://doi.org/10.1145/3462204.3481771\n[85] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi,\nNathanael Sch√§rli, and Denny Zhou. 2023. Large Language Models Can Be Easily\nDistracted by Irrelevant Context. https://doi.org/10.48550/arXiv.2302.00093\narXiv:2302.00093 [cs]\n[86] Prentice Starkey, Alice Klein, and Ann Wakeley. 2004. Enhancing Young Chil-\ndren‚Äôs Mathematical Knowledge through a Pre-Kindergarten Mathematics In-\ntervention. Early Childhood Research Quarterly 19, 1 (2004), 99‚Äì120.\n[87] Ming Sun, Iolanda Leite, Jill Fain Lehman, and Boyang Li. 2017. Collaborative\nStorytelling between Robot and Child: A Feasibility Study. In Proceedings of the\n2017 Conference on Interaction Design and Children (IDC ‚Äô17) . Association for\nComputing Machinery, New York, NY, USA, 205‚Äì214. https://doi.org/10.1145/\n3078072.3079714\n[88] Tzu-Yu Tai and Howard Hao-Jan Chen. 2020. The Impact of Google Assistant\non Adolescent EFL Learners‚Äô Willingness to Communicate. Interactive Learning\nEnvironments 31, 3 (2020), 1‚Äì18.\n[89] Jyothi Thippana, Leanne Elliott, Sarah Gehman, Klaus Libertus, and Melissa E\nLibertus. 2020. Parents‚Äô use of number talk with young children: Comparing\nmethods, family factors, activity contexts, and relations to math skills. Early\nChildhood Research Quarterly 53 (2020), 249‚Äì259.\n[90] Eyl√ºl Turan and Bert De Smedt. 2022. Mathematical Language and Mathematical\nAbilities in Preschool: A Systematic Literature Review. Educational Research\nReview 36 (June 2022), 100457. https://doi.org/10.1016/j.edurev.2022.100457\n[91] Jessica Van Brummelen, Viktoriya Tabunshchyk, and Tommy Heng. 2021.\n‚ÄúAlexa, Can I Program You?‚Äù: Student Perceptions of Conversational Artifi-\ncial Intelligence Before and After Programming Alexa. In Proceedings of the\n20th Annual ACM Interaction Design and Children Conference (IDC ‚Äô21) . As-\nsociation for Computing Machinery, New York, NY, USA, 305‚Äì313. https:\n//doi.org/10.1145/3459990.3460730\n[92] Adam Waytz, Joy Heafner, and Nicholas Epley. 2014. The Mind in the Machine:\nAnthropomorphism Increases Trust in an Autonomous Vehicle. Journal of\nExperimental Social Psychology 52 (May 2014), 113‚Äì117. https://doi.org/10.1016/\nj.jesp.2014.01.005\n[93] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian\nBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler,\nEd H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and\nWilliam Fedus. 2022. Emergent Abilities of Large Language Models. https:\n//doi.org/10.48550/arXiv.2206.07682 arXiv:2206.07682 [cs]\n[94] Jacqueline Kory Westlund and Cynthia Breazeal. 2015. The Interplay of Robot\nLanguage Level with Children‚Äôs Language Learning during Storytelling. In\nProceedings of the Tenth Annual ACM/IEEE International Conference on Human-\nRobot Interaction Extended Abstracts . IEEE, New York, NY, USA, 65‚Äì66.\n[95] Nathan Thomas White, Bengisu Cagiltay, Joseph E Michaelis, and Bilge Mutlu.\n2021. Designing Emotionally Expressive Social Commentary to Facilitate Child-\nRobot Interaction. In Interaction Design and Children (IDC ‚Äô21) . Association for\nComputing Machinery, New York, NY, USA, 314‚Äì325. https://doi.org/10.1145/\n3459990.3460714\n[96] Miranda Kit-Yi Wong and Wing Chee So. 2016. Spoken Narrative Assessment:\nA Supplementary Measure of Children‚Äôs Creativity. Creativity Research Journal\n28, 4 (Oct. 2016), 471‚Äì477. https://doi.org/10.1080/10400419.2016.1229989\n[97] Chun-Cheng Wu, Chih-Wei Chang, Baw-Jhiune Liu, and Gwo-Dong Chen. 2008.\nImproving Vocabulary Acquisition by Designing a Storytelling Robot. In 2008\nEighth IEEE International Conference on Advanced Learning Technologies . IEEE,\nNew York, NY, USA, 498‚Äì500.\n[98] Wenjie Xu, Jiayi Ma, Jiayu Yao, Weijia Lin, Chao Zhang, Xuanhe Xia, Nan\nZhuang, Shitong Weng, Xiaoqian Xie, Shuyue Feng, Fangtian Ying, Preben\nHansen, and Cheng Yao. 2023. MathKingdom: Teaching Children Mathematical\nLanguage Through Speaking at Home via a Voice-Guided Game. In Proceedings\nof the 2023 CHI Conference on Human Factors in Computing Systems (CHI ‚Äô23) .\nAssociation for Computing Machinery, New York, NY, USA, 1‚Äì14. https://doi.\norg/10.1145/3544548.3581043\n[99] Ying Xu. 2023. Talking with machines: Can conversational technologies serve\nas children‚Äôs social partners? Child Development Perspectives 17, 1 (2023), 53‚Äì58.\n[100] Ying Xu, Joseph Aubele, Valery Vigil, Andres S. Bustamante, Young-Suk Kim,\nand Mark Warschauer. 2022. Dialogue with a Conversational Agent Promotes\nChildren‚Äôs Story Comprehension via Enhancing Engagement.Child Development\n93, 2 (2022), e149‚Äìe167. https://doi.org/10.1111/cdev.13708\n[101] Ying Xu, Stacy Branham, Xinwei Deng, Penelope Collins, and Mark Warschauer.\n2021. Are Current Voice Interfaces Designed to Support Children‚Äôs Language\nDevelopment?. In Proceedings of the 2021 CHI Conference on Human Factors\nin Computing Systems . ACM, Yokohama Japan, 1‚Äì12. https://doi.org/10.1145/\n3411764.3445271\n[102] Ying Xu, Valery Vigil, Andres S. Bustamante, and Mark Warschauer. 2022.\n‚ÄúElinor‚Äôs Talking to Me!‚Äù:Integrating Conversational AI into Children‚Äôs Narrative\nScience Programming. In Proceedings of the 2022 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô22) . Association for Computing Machinery,\nNew York, NY, USA, 1‚Äì16. https://doi.org/10.1145/3491102.3502050\n[103] Ying Xu and Mark Warschauer. 2020. Exploring Young Children‚Äôs Engagement\nin Joint Reading with a Conversational Agent. In Proceedings of the Interaction\nDesign and Children Conference (IDC ‚Äô20) . Association for Computing Machinery,\nNew York, NY, USA, 216‚Äì228. https://doi.org/10.1145/3392063.3394417\n[104] Ying Xu and Mark Warschauer. 2020. What Are You Talking To?: Understanding\nChildren‚Äôs Perceptions of Conversational Agents. In Proceedings of the 2020 CHI\nConference on Human Factors in Computing Systems (CHI ‚Äô20) . Association for\nComputing Machinery, New York, NY, USA, 1‚Äì13. https://doi.org/10.1145/\n3313831.3376416\n[105] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft:\nStory Writing With Large Language Models. In 27th International Conference on\nIntelligent User Interfaces (IUI ‚Äô22) . Association for Computing Machinery, New\nYork, NY, USA, 841‚Äì852. https://doi.org/10.1145/3490099.3511105\n[106] J.D. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern Hartmann, and Qian Yang.\n2023. Why Johnny Can‚Äôt Prompt: How Non-AI Experts Try (and Fail) to Design\nLLM Prompts. In Proceedings of the 2023 CHI Conference on Human Factors in\nComputing Systems (CHI ‚Äô23) . Association for Computing Machinery, New York,\nNY, USA, 1‚Äì21. https://doi.org/10.1145/3544548.3581388\n[107] Bowen Zhang and Harold Soh. 2023. Large Language Models as Zero-Shot\nHuman Models for Human-Robot Interaction. https://doi.org/10.48550/arXiv.\n2303.03548 arXiv:2303.03548 [cs]\n[108] Chao Zhang, Cheng Yao, Jianhui Liu, Zili Zhou, Weilin Zhang, Lijuan Liu, Fang-\ntian Ying, Yijun Zhao, and Guanyun Wang. 2021. StoryDrawer: A Co-Creative\nAgent Supporting Children‚Äôs Storytelling through Collaborative Drawing. In\nExtended Abstracts of the 2021 CHI Conference on Human Factors in Computing\nSystems (CHI EA ‚Äô21) . Association for Computing Machinery, New York, NY,\nUSA, 1‚Äì6.\n[109] Chao Zhang, Cheng Yao, Jiayi Wu, Weijia Lin, Lijuan Liu, Ge Yan, and Fangtian\nYing. 2022. StoryDrawer: A Child‚ÄìAI Collaborative Drawing System to Support\nChildren‚Äôs Creative Visual Storytelling. InProceedings of the 2022 CHI Conference\non Human Factors in Computing Systems (CHI ‚Äô22) . Association for Computing\nMachinery, New York, NY, USA, 1‚Äì15. https://doi.org/10.1145/3491102.3501914\n[110] Chao Zhang, Zili Zhou, Yajing Hu, Lanjing Liu, Jiayi Wu, Yaping Shao, Jianhui\nLiu, Lingyan Zhang, Lijuan Liu, Hangyue Chen, Fangtian Ying, and Cheng\nYao. 2023. Observe It, Draw It: Scaffolding Children‚Äôs Observations of Plant\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nBiodiversity with an Interactive Drawing Tool. In Proceedings of the 22nd An-\nnual ACM Interaction Design and Children Conference (IDC ‚Äô23) . Association for\nComputing Machinery, New York, NY, USA, 253‚Äì266. https://doi.org/10.1145/\n3585088.3589380\n[111] Zheng Zhang, Ying Xu, Yanhao Wang, Bingsheng Yao, Daniel Ritchie, Tong-\nshuang Wu, Mo Yu, Dakuo Wang, and Toby Jia-Jun Li. 2022. StoryBuddy: A\nHuman-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with\nFlexible Parental Involvement. In CHI Conference on Human Factors in Comput-\ning Systems (CHI ‚Äô22) . Association for Computing Machinery, New York, NY,\nUSA, 1‚Äì21. https://doi.org/10.1145/3491102.3517479\nA EXAMPLE CONVERSATION SNIPPETS\nBETWEEN A CHILD AND MATHEMYTHS\nA.1 Warming Up\nAGENT: Hello, my little friend! I‚Äôm Mathemyths. I‚Äôm\nreally looking forward to spending some time with you\ntoday! May I know your name, please?\nCHILD: My name is Nick.\nAGENT: Nice to meet you, Nick! Now, could you please\ntell me how you‚Äôre feeling today? Are you feeling happy,\nexcited, or maybe a little sleepy?\nCHILD: I‚Äôm happy!\nAGENT: Thank you for sharing your feelings! I‚Äôm here\nto make your day more fun. How about we make up\na story together? We‚Äôll use our imaginations and even\nlearn some math words. I‚Äôll start, then you can add to\nthe story. If you have any questions or need help, just ask\nme. Always remember, the power of our imaginations\nknows no bounds!\nA.2 Global Setting\nAGENT: Now, let‚Äôs come up with a cool main charac-\nter for the story. This could be an animal, a person, a\nmythical creature, or anything else that fits our story.\nWhat do you want our main character to be?\nCHILD: The main character is a panda!\nAGENT: That‚Äôs interesting! What‚Äôs the character‚Äôs name?\nCHILD: Her name is Lucy.\nAGENT: Great! Where will our story happen?\nCHILD: It will happen in a forest.\nAGENT: Alright! We‚Äôll dive into an incredible adventure\nwith a panda named Lucy in the forest. Ready to start\nthe story? Let‚Äôs go!\nA.3 Opening\nAGENT: Once upon a time, in the heart of a green\nforest, lived a playful panda named Lucy. One sunny\nafternoon, she found an unusual map, and along with\nher new friend, a little child named Nick, they embarked\non an exciting journey to find a hidden treasure.\nA.4 Storytelling\nAGENT: Lucy and Nick decided to ask help from Lucy‚Äôs\nfather, Mr. Bamboo. He looked at the map and told them,\n‚ÄúThe treasure is hidden 100 steps away from the ancient\noak tree. ‚Äù He then added, ‚ÄúYou must also find the half-\nway point, which is half of the total steps, that is, 50\nsteps from the start. ‚Äù\nAGENT: In this context, ‚Äú half‚Äù is when you split some-\nthing into two equal parts, like splitting 100 steps into\n50 steps.\nAGENT: How will Lucy and Nick to find the half-way\npoint?\nCHILD: Lucy goes to the halfway point; I go to the end,\nand finally we find all the treasure!\nAGENT: Wonderful idea! That‚Äôs a clever way to divide\nand conquer the search.\nA.5 Scaffolding\nAGENT: What will Lucy and Nick do next to make sure\ntheir steps equals the total distance to the treasure?\nCHILD: I don‚Äôt know.\nAGENT: That‚Äôs okay! Let‚Äôs think together. Lucy and\nNick can take turns counting their steps. If they keep\ntrack, how can they make sure their total steps equal\nthe distance to the treasure?\nB PROCESS OF CRAFTING DATASET FOR\nEVALUATING STORY CONTINUATIONS\nTo evaluate whether our prompt-engineered GPT-4 model could\ncontinue the story adaptively based on children‚Äôs contributions and\nintegrate mathematical language within the story plot, we com-\npared the GPT-4 generated stories with those generated by humans\nas our baseline. GPT-4 generated stories were created using a self-\nchat technique [30], which enabled our dialogue system to engage\nin self-generated conversations, mimicking a child‚Äôs interactions,\nand collaboratively creating stories. From this, we compiled a col-\nlection of 8 conversations, each consisting of six dialogue rounds,\nforming a complete story. Then, we recruited two graduate students\nin education to create another 8 stories via six rounds of human-\nto-human dialogue. We provided these human narrators with a\ndetailed list of specific instructions like the list of mathematical\nterms they have to use. The story content told by one speaker dur-\ning each dialogue round is deemed a story continuation. In total, we\ncompiled 96 LLM-crafted and 96 human-crafted story continuations\nfor our evaluation.\nC ITEMS IN THE MATHEMATICAL\nLANGUAGE ASSESSMENT IN THE USER\nSTUDY\nC.1 Mathematical Language Definition\n(1) What does the word ‚Äúequal‚Äù mean?\n(2) What does the word ‚Äúhalf‚Äù mean?\n(3) What does the word ‚Äúadd‚Äù mean?\n(4) What does the word ‚Äúsubtract‚Äù mean?\n(5) What does the word ‚Äúestimate‚Äù mean?\n(6) What does the word ‚Äúsum‚Äù mean?\nC.2 Mathematical Language Recall\n(1) What is one word that means ‚Äúthe same amount‚Äù?\n(Estimate, Equal, or Sum)\n(2) What is one word that means ‚Äúa total amount‚Äù?\n(Equal, Add, or Sum)\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\n(3) What is one word that means ‚Äúplus‚Äù?\n(Add, Subtract, or Half )\n(4) What is one word that means ‚Äúto take away‚Äù?\n(Sum, Subtract, or Estimate)\n(5) What is one word that means ‚Äúto cut in two‚Äù?\n(Add, Half, or Estimate)\n(6) What is one word that means ‚Äúa good guess‚Äù when you can‚Äôt\ncount how many things there are?\n(Sum, Estimate, or Subtract)\nC.3 Mathematical Language Transfer ‚Äî Posttest\n(1) Let‚Äôs say you have 5 books and your friend also has 5 books.\nHow does the number of books you have compare to the\nnumber of books your friend has?\n(More, Half, or Equal)\n(2) Let‚Äôs imagine you have a net filled with butterflies. There\nare so many butterflies that you can‚Äôt count them all. You\nwant to guess how many butterflies are in the jar. What‚Äôs\nanother word for guess in this context?\n(Sum, Estimate, or Add)\n(3) Now, let‚Äôs imagine there is a cookie and three friends. Split-\nting the cookie would give each person one third. If there\nwere two friends how much of the cookie would each person\nget?\n(Half, Equal, or Estimated)\n(4) Let‚Äôs imagine you have 7 cookies in your basket and your\nfriend has 10 cookies in her basket. You want to have the\nsame number of cookies with your friend. How could you\nincrease the number of cookies in your basket?\n(Subtract, Add, or Half )\n(5) Let‚Äôs say you have two baseballs and three basketballs. All\ntogether, you have five balls. This is called a total. What‚Äôs\nanother word for total in this context?\n(Sum, Estimate, or Subtraction)\n(6) You have 6 stamps, and your friend has 4 stamps. If you\nwant to find out how many more stamps you have than your\nfriend, what should you do?\n(Add, Subtract, or Estimate)\nC.4 Mathematical Language Transfer ‚Äî Pretest\n(1) Let‚Äôs say you have 5 toys and your friend also has 5 toys. How\ndoes the number of toys you have compare to the number\nof toys your friend has?\n(More, Half, or Equal)\n(2) Let‚Äôs imagine you have a jar filled with candies. There are\nso many candies that you can‚Äôt count them all. How could\nyou guess how many candies there are?\n(Sum, Estimate, or Add)\n(3) Now, let‚Äôs imagine there is a cupcake and three friends. Split-\nting the cupcake would give each person one third. If there\nwere two friends how much of the cupcake would each per-\nson get?\n(Half, Equal, or Estimated)\n(4) You want to measure out 10 grams of sugar but you currently\nhave 8 grams. What action should you take to put 2 more\ngrams of sugar onto your scale?\n(Subtract, Add, or Half )\n(5) Let‚Äôs say you buy two oranges and three apples. Now you\nhave five pieces of fruits. What do you call the number five\nin this context.\n(Sum, Estimate, or Subtraction)\n(6) Your backpack is filled with books and is too heavy. What\nshould you do with the books to make your backpack lighter?\n(Add, Subtract, or Estimate)\nC.5 Mathematical Language Practice\nThe picture of assorted fruit quantities used here is shown in Fig. 10.\nFigure 10: The image of assorted fruit quantities used in the\npractice facet of mathematical language assessment.\n(1) Now, you are going to use the word ‚Äúequal‚Äù to describe what\nyou see in this picture.\n(2) Now, you are going to use the word ‚Äúhalf‚Äù to describe what\nyou see in this picture.\n(3) Now, you are going to use the word ‚Äúsum‚Äù to describe what\nyou see in this picture.\n(4) Now, you are going to use the word ‚Äúadd‚Äù to describe what\nyou see in this picture.\n(5) Now, you are going to use the word ‚Äúsubtract‚Äù to describe\nwhat you see in this picture.\n(6) Now, you are going to use the word ‚Äúestimate‚Äù to describe\nwhat you see in this picture.\nD EXAMPLE PROMPTS FOR IMPLEMENTING\nTHE MATHEMYTHS SYSTEM\nTable D shows the full list of prompt templates used in implement-\ning our system for each task.\nCHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA Chao Zhang et al.\nTable 4: Prompt templates used in story element extraction, story continuation, question generation, intent classification,\nrephrase and hint, and encouragement generation. According to the ChatGPT API specification, the ‚Äúsystem instruction‚Äù can\ngive high level instructions to guide the model‚Äôs behavior throughout the conversation, while the ‚Äúuser input‚Äù provides the\nmodel with the prompt that the user has inputted or the information needed to complete specific tasks.\nTask Prompt Template Few-Shot Examples\nStory Element\nExtraction\n‚Ä¢system instruction: I want you to extract the character,\nthe character‚Äôs name, and the setting for a story from the\nuser‚Äôs response. Please return the answer in JSON format.\n‚Ä¢user input: [the child‚Äôs responses of the protagonist, the\nprotagonist‚Äôs name, and the setting]\n‚Ä¢input: A robot named Diego will be in the space.\noutput: {‚Äúcharacter‚Äù: ‚Äúrobot‚Äù, ‚Äúname‚Äù: ‚ÄúDiego‚Äù, ‚Äúsetting‚Äù:\n‚Äúspace‚Äù}\n‚Ä¢input: The character is a dog. His name is Tommy. He will be in the\nforest.\noutput: {‚Äúcharacter‚Äù: ‚Äúdog‚Äù, ‚Äúname‚Äù: ‚ÄúTommy‚Äù, ‚Äúsetting‚Äù:\n‚Äúforest‚Äù}\n‚Ä¢input: I like coconuts. So the character is a coconut. Her name will be\nSamantha. She is in my home.\noutput: {‚Äúcharacter‚Äù: ‚Äúcoconut‚Äù, ‚Äúname‚Äù: ‚ÄúSamantha‚Äù,\n‚Äúsetting‚Äù: ‚Äúhome‚Äù}\nStory\nContinuation\n‚Ä¢system instruction: You‚Äôre a storytelling robot. Let‚Äôs\nplay a joint storytelling game where we build a story\ntogether with the main character being a [character]\nnamed [name] in the [setting]. This story should revolve\naround the main character and a little kid named [the\nchild‚Äôs name] reaching a certain location, attaining a\ncertain object, or fulfilling a certain objective while\nconquering many obstacles along the way. To start, please\ncraft a 2-sentence introduction to the story. From there,\nwe will alternate turns, with each person adding more to\nthe story. When it is your turn, only write the story\ncontent while using as many of the following words as\npossible: equal, sum, half, add, subtract, and estimate.\nPlease keep your responses simple and appropriate for a\nyoung child. Please do not ask me any questions or\nrespond with anything unrelated to the story. If I need to\ncommunicate with you in English, I will use curly\nbrackets {like this}. Please be creative and have fun with\nthis storytelling adventure! If you understand and are\nready to begin, respond with only ‚Äúyes‚Äù.\n‚Ä¢user input (if the story is continuing) : [the child‚Äôs\naddition to the story] {First, in curly brackets,\nacknowledge my addition and commend me in a concise\n10-word sentence. Next, continue the story by correctly\nusing [mathematical term one] and [mathematical term\ntwo] or their variants within two distinct 15-word\nsentences. Lastly, explain their meanings within a 20-word\nsentence, grounding it firmly within the story‚Äôs context.\nDo not end the story.}\n‚Ä¢user input (if the story is reaching the end) : [the\nchild‚Äôs addition to the story] {First, in curly brackets,\nacknowledge my addition and commend me in a concise\n10-word sentence. Next, end the story by correctly using\n[mathematical term one] and [mathematical term two] or\ntheir variants within two distinct 15-word sentences.\nThen, explain their meanings within a 20-word sentence,\ngrounding it firmly within the story‚Äôs context. Lastly,\nsummarize the story within a 30-word sentence.}\nN/A\nMathemyths CHI ‚Äô24, May 11‚Äì16, 2024, Honolulu, HI, USA\nTask Prompt Template Few-Shot Examples\nQuestion\nGeneration\n‚Ä¢system instruction: Given an unfinished story, compose\none single, straightforward question to prompt a\n6-year-old to expand on the story. The question should\nfocus on the main character‚Äôs next steps or feelings and\nmotivate the child to use words like equal, sum, half, add,\nsubtract, and estimate in their response. Do not mention\n‚Äúmath‚Äù, ‚Äúmathematics‚Äù, and ‚Äúmathematical skills‚Äù. Limit\nyour response to 20 words. Simple future tense. Only\nreply with the question.\n‚Ä¢user input: [the agent‚Äôs generated story content]\n‚Ä¢input: Samantha knew that the sum of challenges she would face\nwould be great, but she was determined to succeed. She began her\njourney, keeping her eyes and ears open for any clues that would lead\nher closer to the gem.\noutput: What challenges do you think Samantha will face halfway\nthrough the journey?\n‚Ä¢input: Jennie overheard a group of sea creatures talking about the\ncave‚Äôs entrance, which could only be found when the sum of the three\ntallest coral reefs was equal to the depth of the sunken ship nearby.\nDetermined to solve this riddle, Jennie decided to set out and add this\ngreat adventure to her life‚Äôs experiences.\noutput: How do you think Jennie will figure out the sum of the\nheights of the three tallest coral reefs?\n‚Ä¢input: The ancient prophecy stated that the Dragon‚Äôs Heart would be\nhidden in a place where the sum of two particular rivers met. Michael\nrealized that the location must equal to the intersection of the mighty\nSapphire River and the mysterious Emerald River, deep within the\nenchanted forest.\noutput: What do you think Michael will do to estimate where the\ntwo rivers meet?\nIntent\nClassification\n‚Ä¢system instruction: As a language model, your task is to\ndetermine whether a given phrase expresses a feeling or\nemotion in the first person, such as uncertainty,\nagreement, satisfaction, or interest. Your response should\nbe a binary output of either 1 or 0, where 1 indicates that\nthe phrase does express a feeling or emotion in the first\nperson, and 0 indicates that it does not.\n‚Ä¢user input: [the child‚Äôs responses]\n‚Ä¢input: I don‚Äôt know.\noutput: 1\n‚Ä¢input: I like it.\noutput: 1\n‚Ä¢input: I don‚Äôt like it.\noutput: 1\n‚Ä¢input: Diego is happy.\noutput: 0\n‚Ä¢input: He is sad.\noutput: 0\n‚Ä¢input: I am not sure.\noutput: 1\n‚Ä¢input: Go on.\noutput: 1\nRephrase and\nHint\n‚Ä¢system instruction: You and a 6-year-old are playing a\nstorytelling game, taking turns to contribute to a unique\nstory. However, when the child fails to continue the story\nor just wants you to continue the story, your task is to\nencourage them to keep going by simplifying this\nquestion: [question], and give them some hints. Limit your\nresponse to 30 words.\n‚Ä¢user input: [the child‚Äôs insubstantial response or no\nresponse]\nN/A\nEncourage-ment\nGeneration\n‚Ä¢system instruction: You and a 6-year-old are playing a\nstorytelling game, taking turns to contribute to a unique\nstory. However, Sometimes the child just says a few\nwords, your task is to first acknowledge what he says and\nthen encourage him to say more. Limit your response to\n30 words.\n‚Ä¢user input: [the child‚Äôs short response of story\ncontinuation]\nN/A"
}