{
    "title": "Language models align with human judgments on key grammatical constructions",
    "url": "https://openalex.org/W4391591605",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A4302924757",
            "name": "Hu, Jennifer",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A4222840105",
            "name": "Mahowald, Kyle",
            "affiliations": [
                "The University of Texas at Austin"
            ]
        },
        {
            "id": null,
            "name": "Lupyan, Gary",
            "affiliations": [
                "University of Wisconsinâ€“Madison"
            ]
        },
        {
            "id": "https://openalex.org/A2318000672",
            "name": "Ivanova, Anna",
            "affiliations": [
                "Georgia Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2511155128",
            "name": "Levy, Roger",
            "affiliations": [
                "Massachusetts Institute of Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4389669106",
        "https://openalex.org/W4290978113",
        "https://openalex.org/W1490063261",
        "https://openalex.org/W2888922637",
        "https://openalex.org/W2996728628",
        "https://openalex.org/W3034510440",
        "https://openalex.org/W4389518756"
    ],
    "abstract": "Do large language models (LLMs) make human-like linguistic generalizations?\\nDentella et al. (2023) (\"DGL\") prompt several LLMs (\"Is the following sentence\\ngrammatically correct in English?\") to elicit grammaticality judgments of 80\\nEnglish sentences, concluding that LLMs demonstrate a \"yes-response bias\" and a\\n\"failure to distinguish grammatical from ungrammatical sentences\". We\\nre-evaluate LLM performance using well-established practices and find that\\nDGL's data in fact provide evidence for just how well LLMs capture human\\nbehaviors. Models not only achieve high accuracy overall, but also capture\\nfine-grained variation in human linguistic judgments.\\n",
    "full_text": null
}