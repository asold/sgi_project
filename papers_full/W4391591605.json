{
  "title": "Language models align with human judgments on key grammatical constructions",
  "url": "https://openalex.org/W4391591605",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4302924757",
      "name": "Hu, Jennifer",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A4222840105",
      "name": "Mahowald, Kyle",
      "affiliations": [
        "The University of Texas at Austin"
      ]
    },
    {
      "id": null,
      "name": "Lupyan, Gary",
      "affiliations": [
        "University of Wisconsinâ€“Madison"
      ]
    },
    {
      "id": "https://openalex.org/A2318000672",
      "name": "Ivanova, Anna",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2511155128",
      "name": "Levy, Roger",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4389669106",
    "https://openalex.org/W4290978113",
    "https://openalex.org/W1490063261",
    "https://openalex.org/W2888922637",
    "https://openalex.org/W2996728628",
    "https://openalex.org/W3034510440",
    "https://openalex.org/W4389518756"
  ],
  "abstract": "Do large language models (LLMs) make human-like linguistic generalizations?\\nDentella et al. (2023) (\"DGL\") prompt several LLMs (\"Is the following sentence\\ngrammatically correct in English?\") to elicit grammaticality judgments of 80\\nEnglish sentences, concluding that LLMs demonstrate a \"yes-response bias\" and a\\n\"failure to distinguish grammatical from ungrammatical sentences\". We\\nre-evaluate LLM performance using well-established practices and find that\\nDGL's data in fact provide evidence for just how well LLMs capture human\\nbehaviors. Models not only achieve high accuracy overall, but also capture\\nfine-grained variation in human linguistic judgments.\\n",
  "full_text": null,
  "topic": "Key (lock)",
  "concepts": [
    {
      "name": "Key (lock)",
      "score": 0.7101958990097046
    },
    {
      "name": "Linguistics",
      "score": 0.5657966732978821
    },
    {
      "name": "Computer science",
      "score": 0.4940471947193146
    },
    {
      "name": "Natural language processing",
      "score": 0.4195847809314728
    },
    {
      "name": "Psychology",
      "score": 0.3576012849807739
    },
    {
      "name": "Cognitive science",
      "score": 0.33402085304260254
    },
    {
      "name": "Philosophy",
      "score": 0.14531639218330383
    },
    {
      "name": "Computer security",
      "score": 0.0
    }
  ],
  "institutions": []
}