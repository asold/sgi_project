{
  "title": "Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models",
  "url": "https://openalex.org/W4362655923",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5101629463",
      "name": "Yiheng Liu",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5077476419",
      "name": "Tianle Han",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5100759473",
      "name": "Siyuan Ma",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5005308034",
      "name": "Jiayue Zhang",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5100638446",
      "name": "Yuanyuan Yang",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5088463875",
      "name": "Jiaming Tian",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5025662871",
      "name": "Hao He",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5083548873",
      "name": "Antong Li",
      "affiliations": [
        "Shaanxi Normal University",
        "Xi'an Jiaotong University"
      ]
    },
    {
      "id": "https://openalex.org/A5052125077",
      "name": "Mengshen He",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101505879",
      "name": "Zhengliang Liu",
      "affiliations": [
        "Shaanxi Normal University",
        "University of Georgia"
      ]
    },
    {
      "id": "https://openalex.org/A5068480230",
      "name": "Zihao Wu",
      "affiliations": [
        "University of Georgia"
      ]
    },
    {
      "id": "https://openalex.org/A5100351935",
      "name": "Lin Zhao",
      "affiliations": [
        "University of Georgia"
      ]
    },
    {
      "id": "https://openalex.org/A5038582366",
      "name": "Dajiang Zhu",
      "affiliations": [
        "The University of Texas at Arlington"
      ]
    },
    {
      "id": "https://openalex.org/A5100331094",
      "name": "Xiang Li",
      "affiliations": [
        "Harvard University",
        "Massachusetts General Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5101182523",
      "name": "Qiang Ning",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A5012682441",
      "name": "Dingang Shen",
      "affiliations": [
        "Shanghai Clinical Research Center",
        "ShanghaiTech University",
        "United Imaging Healthcare (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5100647156",
      "name": "Tianming Liu",
      "affiliations": [
        "University of Georgia"
      ]
    },
    {
      "id": "https://openalex.org/A5019722690",
      "name": "Bao Ge",
      "affiliations": [
        "Shaanxi Normal University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4380568688",
    "https://openalex.org/W4386689591",
    "https://openalex.org/W4323922316",
    "https://openalex.org/W4239181501",
    "https://openalex.org/W4365441234",
    "https://openalex.org/W4321018175",
    "https://openalex.org/W3102925419",
    "https://openalex.org/W2971039193",
    "https://openalex.org/W4353007316",
    "https://openalex.org/W4360847209",
    "https://openalex.org/W4315705880",
    "https://openalex.org/W4375949262",
    "https://openalex.org/W4311558004",
    "https://openalex.org/W4320342636",
    "https://openalex.org/W3092043163",
    "https://openalex.org/W4321524280",
    "https://openalex.org/W4320167623",
    "https://openalex.org/W4318903793",
    "https://openalex.org/W4318902699",
    "https://openalex.org/W4323927170",
    "https://openalex.org/W4321524628",
    "https://openalex.org/W4377855098",
    "https://openalex.org/W3186081172",
    "https://openalex.org/W4381252028",
    "https://openalex.org/W4321524373",
    "https://openalex.org/W4386718985",
    "https://openalex.org/W3000758063",
    "https://openalex.org/W3172214016",
    "https://openalex.org/W4323650985",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W2964349647",
    "https://openalex.org/W4312091864",
    "https://openalex.org/W4320854779",
    "https://openalex.org/W4322759267",
    "https://openalex.org/W4318719246",
    "https://openalex.org/W4309184901",
    "https://openalex.org/W2986619406",
    "https://openalex.org/W4322759378",
    "https://openalex.org/W3081277912",
    "https://openalex.org/W4327811957",
    "https://openalex.org/W4319773014",
    "https://openalex.org/W2132679783",
    "https://openalex.org/W4321392130",
    "https://openalex.org/W4385301128",
    "https://openalex.org/W4321471906",
    "https://openalex.org/W4321177596",
    "https://openalex.org/W4323697401",
    "https://openalex.org/W4311641658",
    "https://openalex.org/W4366330426",
    "https://openalex.org/W4313447114",
    "https://openalex.org/W4323066793",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4320342993",
    "https://openalex.org/W4311430511",
    "https://openalex.org/W4323929307",
    "https://openalex.org/W4321014813",
    "https://openalex.org/W4385521210",
    "https://openalex.org/W2948579453",
    "https://openalex.org/W2962913831",
    "https://openalex.org/W4379259169",
    "https://openalex.org/W4385302156",
    "https://openalex.org/W4380879558",
    "https://openalex.org/W4385570966",
    "https://openalex.org/W4312121686",
    "https://openalex.org/W2949615363",
    "https://openalex.org/W4381587628",
    "https://openalex.org/W2975412433",
    "https://openalex.org/W4323570543",
    "https://openalex.org/W4365398012",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W4366999665",
    "https://openalex.org/W4319452276",
    "https://openalex.org/W4312051216",
    "https://openalex.org/W3003484198",
    "https://openalex.org/W4321276803",
    "https://openalex.org/W4323927216",
    "https://openalex.org/W4385572488",
    "https://openalex.org/W4317672148",
    "https://openalex.org/W1555168845",
    "https://openalex.org/W4323644252",
    "https://openalex.org/W4322760121",
    "https://openalex.org/W4313559133",
    "https://openalex.org/W4320855764",
    "https://openalex.org/W4362551436",
    "https://openalex.org/W4380319827",
    "https://openalex.org/W4323709074",
    "https://openalex.org/W2252066972",
    "https://openalex.org/W4318899036",
    "https://openalex.org/W4390509281",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4315589094",
    "https://openalex.org/W4226277810",
    "https://openalex.org/W4317547570",
    "https://openalex.org/W3174945605",
    "https://openalex.org/W3168403139",
    "https://openalex.org/W4383374753",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4389519239",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4323717348",
    "https://openalex.org/W4321012208",
    "https://openalex.org/W4322759717",
    "https://openalex.org/W4384641573",
    "https://openalex.org/W4380993746"
  ],
  "abstract": "This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.",
  "full_text": "Highlights\nSummary of ChatGPT-Related Research and Perspective Towards the Future of Large\nLanguage Models\nYiheng Liu ∗,Tianle Han ∗,Siyuan Ma,Jiayue Zhang,Yuanyuan Yang,Jiaming Tian,Hao He,Antong Li,Mengshen\nHe,Zhengliang Liu,Zihao Wu,Lin Zhao,Dajiang Zhu,Xiang Li,Ning Qiang,Dingang Shen,Tianming Liu,Bao Ge\n• A comprehensive survey of ChatGPT-related research.\n• Analysis of 194 research papers.\n• Pavingthewayforfurtherresearchandexplorationinleveraginglargelanguagemodelsforvariousapplications.\narXiv:2304.01852v4  [cs.CL]  22 Aug 2023\nSummary of ChatGPT-Related Research and Perspective Towards\nthe Future of Large Language Models\nYiheng Liu∗a, Tianle Han∗a, Siyuan Maa, Jiayue Zhanga, Yuanyuan Yanga, Jiaming Tiana,\nHao Hea, Antong Lib, Mengshen Hea, Zhengliang Liuc, Zihao Wuc, Lin Zhaoc, Dajiang Zhud,\nXiang Lie, Ning Qianga, Dingang Shenf,g,h, Tianming Liuc and Bao Gea\naSchool of Physics and Information Technology, Shaanxi Normal University, Xi’an, 710119, Shaanxi, China\nbSchool of Life and Technology Biomedical-Engineering, Xi’an Jiaotong University, Xi’an, 710119, Shaanxi, China\ncSchool of Computing, The University of Georgia, Athens, 30602, USA\ndDepartment of Computer Science and Engineering, The University of Texas at Arlington, Arlington, 76019, USA\neDepartment of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, 02115, USA\nfSchool of Biomedical Engineering, ShanghaiTech University, Shanghai, 201210, China\ngShanghai United Imaging Intelligence Co., Ltd., Shanghai, 200230, China\nhShanghai Clinical Research and Trial Center, Shanghai, 201210, China\nABSTRACT\nThispaperpresentsacomprehensivesurveyofChatGPT-related(GPT-3.5andGPT-4)research,\nstate-of-the-art large language models (LLM) from the GPT series, and their prospective\napplicationsacrossdiversedomains.Indeed,keyinnovationssuchaslarge-scalepre-trainingthat\ncapturesknowledgeacrosstheentireworldwideweb,instructionfine-tuningandReinforcement\nLearning from Human Feedback (RLHF) have played significant roles in enhancing LLMs’\nadaptability and performance. We performed an in-depth analysis of 194 relevant papers\non arXiv, encompassing trend analysis, word cloud representation, and distribution analysis\nacross various application domains. The findings reveal a significant and increasing interest\nin ChatGPT-related research, predominantly centered on direct natural language processing\napplications, while also demonstrating considerable potential in areas ranging from education\nandhistorytomathematics,medicine,andphysics.Thisstudyendeavorstofurnishinsightsinto\nChatGPT’s capabilities, potential implications, ethical concerns, and offer direction for future\nadvancements in this field.\n1. Introduction\nRecent advances in natural language processing (NLP) have led to the development of powerful language models\nsuch as the GPT (Generative Pre-trained Transformer) series [79; 81; 80; 8; 73], including large language models\n(LLM) such as ChatGPT (GPT-3.5 and GPT-4) [71]. These models are pre-trained on vast amounts of text data\nand have demonstrated exceptional performance in a wide range of NLP tasks, including language translation, text\nsummarization, and question-answering. In particular, the ChatGPT model has demonstrated its potential in various\nfields,includingeducation,healthcare,reasoning,textgeneration,human-machineinteraction,andscientificresearch.\nA key milestone of LLM development is InstructGPT [73], a framework that allows for instruction fine-tuning\nof a pre-trained language model based on Reinforcement Learning from Human Feedback (RLHF) [11; 73]. This\nframework enables an LLM to adapt to a wide range of NLP tasks, making it highly versatile and flexible by\nleveraging human feedback. RLHF enables the model to align with human preferences and human values, which\nsignificantly improves from large language models that are solely trained text corpora through unsupervised pre-\ntraining.ChatGPTisasuccessortoInstructGPT.SinceitsreleaseinDecember2022,ChatGPThasbeenequippedwith\ntheseadvanceddevelopments,leadingtoimpressiveperformancesinvariousdownstreamNLPtaskssuchasreasoning\nand generalized text generation. These unprecedented NLP capabilities spur applications in diverse domains such as\neducation,healthcare,human-machineinteraction,medicineandscientificresearch.ChatGPThasreceivedwidespread\nattentionandinterest,leadingtoanincreasingnumberofapplicationsandresearchthatharnessitsexceedingpotential.\n∗These authors contributed equally to this work.\n∗ ∗Corresponding author\nORCID(s):\nYiheng Liu et al.:Preprint submitted to Elsevier Page 1 of 21\nSummary of ChatGPT-Related Research\nFigure 1:The graphical representation is utilized to depict the number of research articles related to ChatGPT published\nfrom 2022 to April, 2023, revealing the trend and growth of ChatGPT-related research over time. The graph showcases\nthe monthly count of submissions and cumulative daily submitted count in arXiv. Over time, there has been an increasing\namount of research related to ChatGPT.\nTheopenreleaseofthemulti-modalGPT-4modelfurtherexpandsthehorizonoflargelanguagemodelsandempowers\nexciting developments that involve diverse data beyond text.\nThepurposeofthispaperistoprovideacomprehensivesurveyoftheexistingresearchonChatGPTanditspotential\napplications in various fields. To achieve this goal, we conducted a thorough analysis of papers related to ChatGPT\nin the arXiv repository. As of April 1st, 2023, there are a total of 194 papers mentioning ChatGPT on arXiv. In this\nstudy,weconductedatrendanalysisofthesepapersandgeneratedawordcloudtovisualizethecommonlyusedterms.\nAdditionally, we also examined the distribution of the papers across various fields and presented the corresponding\nstatistics. Figure 1 displays the submission trend of papers related to ChatGPT, indicating a growing interest in this\nfield.Figure2illustratesthewordcloudanalysisofallthepapers.Wecanobservethatthecurrentresearchisprimarily\nfocused on natural language processing, but there is still significant potential for research in other fields such as\neducation, medical and history. This is further supported by Figure 3, which displays the distribution of submitted\npapers across various fields, highlighting the need for more research and development in these areas. Due to the rapid\nadvancement in research related to ChatGPT, we have also introduced a dynamic webpage that provides real-time\nupdates on the latest trends in these area. Interested readers can access the webpage and stay informed about the\nevolving research directions by following this link1.\nThis paper aims to shed light on the promising capabilities of ChatGPT and provide insight into its potential\nimpactinthefuture,includingethicalconsiderations.Throughthissurvey,wehopetoprovideinsightsintohowthese\nmodelscanbeimprovedandextendedinthefuture.Insection2,wewillreviewtheexistingworkrelatedtoChatGPT,\nincluding its applications and ethical considerations. In section 3, we conducted a review of existing literature that\nassesses the capabilities of ChatGPT. We comprehensively evaluated the performance of ChatGPT based on these\nstudies. In addition to discussing the current state of research related to ChatGPT, we will also explore its limitations\nin section 4. Furthermore, we will provide guidance on future directions for language model development.\n2. Related work of ChatGPT\nIn this section, we review the latest research related to the application and ethics of ChatGPT. Figure 4 shows the\noverall framework of this part.\n1https://snnubiai.github.io/chatgpt_arxiv_analysis/\nYiheng Liu et al.:Preprint submitted to Elsevier Page 2 of 21\nSummary of ChatGPT-Related Research\nFigure 2:Word cloud analysis of all the 194 papers.\n2.1. Application of ChatGPT\n2.1.1. Question And Answering\nIn the field of education\nChatGPT is commonly used for question and answers testing in the education sector. Users can use ChatGPT to\nlearn,compareandverifyanswersfordifferentacademicsubjectssuchasphysics,mathematics,andchemistry,and/or\nconceptual subjects such as philosophy and religion. Additionally, users can ask open-ended and analytical questions\nto understand the capabilities of ChatGPT.\nIn the field of mathematics, Frieder et al. [17] constructed the GHOSTS natural language dataset, which consists\nof graduate-level math test questions. The authors tested ChatGPT’s math abilities on the GHOSTS dataset using\na question-and-answer format and evaluated it according to fine-grained standards.In the Grad Text dataset, which\ncoverssimplesettheoryandlogicproblems,ChatGPTperformedthebest.However,intheOlympiad-Problem-Solving\ndataset,ChatGPTperformedpoorly,receivingonlytwo4-pointscores(outofatotalof5),withthemajorityofscores\nbeing 2 points. In the Holes-in-Proofs dataset, ChatGPT received the lowest score of 1 point. In the MATH dataset,\nChatGPT only scored impressively in 26% of cases. These results suggest that ChatGPT’s math abilities are clearly\nlower than those of ordinary math graduate students. Although ChatGPT can generally understand math problems, it\nfailstoprovidethecorrectsolutions.Pardosetal.[74]usedtheOpenAdaptiveTutoringsystem(OATutor)toinvestigate\nwhether prompts generated by ChatGPT were helpful for learning algebra, with 77 participants from Mechanical\nTurk taking part in the experiment. The experiment used questions from OpenStax’s Elementary and Intermediate\nAlgebra textbooks. These participants were randomly assigned to either a control group (with manual prompts) or an\nexperimental group (with ChatGPT prompts). For each question in both courses, the authors obtained answers from\nChatGPT through a question-and-answer format and evaluated scores according to three criteria: ChatGPT provided\nan answer, the answer was correct, and inappropriate language was not used in the answer. The study found that 70%\nof prompts generated by ChatGPT passed manual quality checks, and both humans and ChatGPT produced positive\nlearning gains. However, the scores of human prompts ranged from 74.59% to 84.32%, significantly higher than those\nof ChatGPT prompts. Shakarian et al. [82] studied the performance of ChatGPT on math word problems (MWPs),\nusing the DRAW-1K dataset for experimentation. The dataset consists of 1000 MWPs and their answers, along with\nalgebraic equation templates for solving such problems. The authors used the idea of machine learning introspection\nand built performance prediction models using random forests and XGBoost, and evaluated them on the dataset using\nYiheng Liu et al.:Preprint submitted to Elsevier Page 3 of 21\nSummary of ChatGPT-Related Research\nFigure 3:The distribution of submitted papers across various fields.\nfive-fold cross-validation. ChatGPT’s accuracy increased from an initial 34% to a final 69%, while its recall increased\nfrom an initial 41% to a final 83%. The authors also found that ChatGPT’s failure rate decreased from an initial 84%\nto a final 20%, indicating that performance can vary greatly depending on specific job requirements.\nIn the field of physics, Lehnert et al. [48] explored the capabilities and limitations of ChatGPT by studying how\nit handles obscure physics topics such as the swamp land conjecture in string theory. The experimental dialogue\nbegan with broader and more general questions in the field of string theory before narrowing down to specific swamp\nland conjectures and examining ChatGPT’s understanding of them. The study found that ChatGPT could define and\nexplain different concepts in various styles, but was not effective in truly connecting various concepts. It would\nconfidently provide false information and fabricate statements when necessary, indicating that ChatGPT cannot truly\ncreatenewknowledgeorestablishnewconnections.However,intermsofidentifyinganalogiesanddescribingabstract\nconcepts of visual representation, ChatGPT can cleverly use language. Kortemeyer et al. [44] evaluated ChatGPT’s\nability to answer calculus-based physics questions through a question-and-answer test. The tests included online\nhomework, clicker questions, programming exercises, and exams covering classical mechanics, thermodynamics,\nelectricity and magnetism, and modern physics. While ChatGPT was able to pass the course, it also demonstrated\nmany misconceptions and errors commonly held by beginners. West et al. [98] used the Force Concept Inventory\nYiheng Liu et al.:Preprint submitted to Elsevier Page 4 of 21\nSummary of ChatGPT-Related Research\nRelated work of ChatGPT\nApplication of ChatGPT\nAI Ethics\nQuestion And Answering\nText Classification\nData or information extraction , \ntransformation , enhancement , processing\nInference\nText Generation\nCode Generation\nHuman-ChatGPT Collaboration\nChatGPT Integration\nMedical Applications\nFigure 4:Structure Diagram of Chapter 2.\n(FCI) to evaluate ChatGPT’s accuracy in answering physics concept problems related to kinematics and Newtonian\nmechanics in the first semester of college physics. The FCI covers topics such as kinematics, projectile motion, free\nfall, circular motion, and Newton’s laws. The study included data from 415 students who took the FCI at the end of\nthe semester, with an average score of 56%, while ChatGPT scored approximately between 50% to 65%. The authors\ndemonstratedthatChatGPT’sperformanceinphysicslearningcanreachorevenexceedtheaveragelevelofasemester\nof college physics.\nIn the medical field\nChatGPT’squestion-answeringcapabilitiescanalsobeappliedinthemedicalfield,suchasforansweringmedical\nquestions from patients or assisting healthcare professionals in diagnosing diseases. Nov et al. [70] evaluated the\nfeasibility of using ChatGPT for patient-doctor communication. The experiment extracted 10 representative patient-\ndoctorinteractionsfromEHR,placedthepatient’squestionsinChatGPT,andaskedChatGPTtorespondusingroughly\nthe same number of words as the doctor’s response. Each patient’s question was answered by either the doctor or\nChatGPT, and the patient was informed that 5 were answered by the doctor and 5 were generated by ChatGPT, and\nwas asked to correctly identify the source of the response. The results of the experiment showed that the probability\nof correctly identifying ChatGPT’s response was 65.5%, while the probability of correctly identifying the doctor’s\nresponsewas65.1%.Inaddition,theexperimentfoundthatthepatient’sresponsetothetrustworthinessofChatGPT’s\nfunction was weakly positive (average Likert score: 3.4), and trust decreased as the complexity of health-related tasks\ninthequestionsincreased.ChatGPT’sresponsestopatientquestionswereonlyslightlydifferentfromthoseofdoctors,\nbut people seem to trust ChatGPT to answer low-risk health questions, while for complex medical questions, people\nstill tend to trust the doctor’s responses and advice.\nTu et al. [91] explored the causal discovery ability of ChatGPT in the diagnosis of neuropathic pain. Causal\nrelationship discovery aims to reveal potential unknown causal relationships based purely on observed data [20]. The\nexperimental results found that ChatGPT has some limitations in understanding new knowledge and concepts beyond\nthe existing textual training data corpus, that is, it only understands language commonly used to describe situations\nand not underlying knowledge. In addition, its performance consistency and stability are not high, as the experiment\nobserved that it would provide different answers for the same question under multiple inquiries. However, despite the\nmany limitations of ChatGPT, we believe that it has a great opportunity to improve causal relationship research.\nYiheng Liu et al.:Preprint submitted to Elsevier Page 5 of 21\nSummary of ChatGPT-Related Research\nIn other fields\nGuoetal.[23]attemptedtoapplyChatGPTinthefieldofcommunication,specificallyusingChatGPTforordered\nimportance semantic communication, where ChatGPT plays the role of an intelligent consulting assistant that can\nreplace humans in identifying the semantic importance of words in messages and can be directly embedded into the\ncurrentcommunicationsystem.Foramessagetobetransmitted,thesenderfirstutilizesChatGPTtooutputthesemantic\nimportanceorderofeachword.Then,thetransmitterexecutesanunequalerrorprotectiontransmissionstrategybased\non the importance order to make the transmission of important words in the message more reliable. The experimental\nresultsshowthattheerrorrateandsemanticlossofimportantwordsmeasuredinthecommunicationsystemembedded\nwith ChatGPT are much lower than those of existing communication schemes, indicating that ChatGPT can protect\nimportant words well and make semantic communication more reliable.\nWang et al. [95] studied the effectiveness of ChatGPT in generating high-quality Boolean queries for systematic\nliterature search. They designed a wide range of prompts and investigated these tasks on more than 100 systematic\nreview topics. In the end, queries generated by ChatGPT achieved higher accuracy compared to the currently\nmost advanced query generation methods but at the cost of reduced recall. For time-limited rapid reviews, it is\noften acceptable to trade off higher precision for lower recall. Additionally, ChatGPT can generate high search\naccuracy Boolean queries by guiding the prompts. However, it should be noted that when two queries use the same\nprompts,ChatGPTgeneratesdifferentqueries,indicatingitslimitationsinconsistencyandstability.Overall,thisstudy\ndemonstrated the potential of ChatGPT in generating effective Boolean queries for systematic literature searches.\n2.1.2. Text Classification\nThe purpose of text classification is to assign text data to predefined categories. This task is critical for many\napplications, including sentiment analysis, spam detection, and topic modeling. While traditional machine learning\nalgorithmshavebeenwidelyusedfortextclassification,recentadvancesinnaturallanguageprocessinghaveledtothe\ndevelopmentofmoreadvancedtechniques.ChatGPThasshownimmensepotentialinthisfield.Itsabilitytoaccurately\nclassifytext,flexibilityinhandlingvariousclassificationtasks,andpotentialforcustomizationmakeitavaluabletool\nfor text classification, as evidenced by several studies in the literature.\nKuzman et al. [46] employed ChatGPT for automated genre recognition, with the goal of simplifying the\ntext classification task by utilizing ChatGPT’s zero-shot classification capability. They compared ChatGPT’s genre\nrecognition performance, using two prompt languages (EN and SL), with the X-GENRE classifier based on the\nmultilingualmodelXLM-RoBERTaontheEnglishdatasetEN-GINCOandtheSloveniandatasetGINCO.Theresults\nshowedthatwhenENwasusedasthepromptlanguage,ChatGPTachievedMicroF1,MacroF1,andAccuracyscores\nof0.74,0.66,and0.72.However,ontheGINCOdataset,ChatGPT’sgenrerecognitionperformancewithbothENand\nSL prompt languages was lower than that of the X-GENRE classifier to varying degrees.\nAmin et al. [2] evaluated the text classification ability of ChatGPT in affective computing by using it to\nperformpersonalityprediction,sentimentanalysis,andsuicideideationdetectiontasks.TheypromptedChatGPTwith\ncorrespondingpromptsonthreedatasets:FirstImpressions,Sentiment140,andSuicideandDepression,andcompared\nits classification performance with three baseline models: RoBERTa-base, Word2Vec, and BoW. The results showed\nthat ChatGPT’s accuracy and UAR for the five personality classifications on the First Impressions dataset were lower\nthan the baseline methods to varying degrees. On the Sentiment140 dataset, ChatGPT’s accuracy and UAR were\n85.5and85.5,respectively,whichwerebetterthanthethreebaselinemethods.OntheSuicideandDepressiondataset,\nChatGPT’saccuracyandUARwere92.7and91.2,respectively,whichwerelowerthanRoBERTa,thebest-performing\nbaseline method.\nZhang et al. [106] employed ChatGPT for stance detection, which includes support and opposition. They used\nChatGPTtoclassifythepoliticalstanceoftweetsintheSemEval-2016andP-Stancedatasets.SemEval-2016contains\n4,870Englishtweets,andtheyselectedtweetswiththemostcommonlyoccurringFM,LA,andHCpoliticallabelsfor\nstance classification. The P-Stance dataset has 21,574 English tweets, and they classified the stance of tweets towards\nTrump,Biden,andBernie.ThefinalresultsshowedthatontheSemEval-2016dataset,ChatGPTachievedF1-mscores\nof68.4,58.2,and79.5fortheFM,LA,andHCpoliticallabels,andF1-avgscoresof72.6,59.3,and78.0,respectively.\nOn the P-Stance dataset, ChatGPT achieved F1-m scores of 82.8, 82.3, and 79.4 for the Trump, Biden, and Bernie\npolitical figures, and F1-avg scores of 83.2, 82.0, and 79.4, respectively.\nHuang et al. [32] used ChatGPT to detect implicit hate speech in tweets. They selected 12.5% (795 tweets) of the\nLatentHatreddatasetcontainingimplicithatespeechandaskedChatGPTtoclassifythemintothreecategories:implicit\nhate speech, non-hate speech, and uncertain. The results showed that ChatGPT correctly recognized 636 (80%) of the\nYiheng Liu et al.:Preprint submitted to Elsevier Page 6 of 21\nSummary of ChatGPT-Related Research\ntweets.Thenumberoftweetsclassifiedasnon-hatespeechanduncertainwere146(18.4%)and13(1.6%),respectively.\nThe results of the reclassification of tweets in the non-hate speech and uncertain categories by Amazon Mechanical\nTurk (Mturk) workers were consistent with ChatGPT’s classification.\nOverall, ChatGPT has tremendous potential in text classification tasks, as it can effectively address problems such\nasgenreidentification,sentimentanalysis,stancedetection,andmore.However,therearestillchallengesthatChatGPT\nfaces in the field of text classification. Firstly, it struggles to perform well in classification tasks with rare or out-of-\nvocabularywordssinceitheavilyreliesonthedistributionoftrainingdata.Additionally,thesignificantcomputational\nresources required for training and utilizing ChatGPT can limit its use in some applications.\n2.1.3. Text Generation\nWe live in an era of information explosion, and text is an efficient way of transmitting information. The diversity\nof information has led to a diversity of text categories. When researchers use ChatGPT’s text generation capabilities\nfor research, they inevitably choose to generate different types of text. In the process of reading papers, we found that\nthewordcountofthetextgeneratedbyresearchersincreasedfromsmalltolarge,sowewantedtosummarizeexisting\nresearch based on the size of the text word count. We divided the generated text into three levels: phrases, sentences,\nand paragraphs.\nThe following article uses ChatGPT to generate phrases. Zhang et al. [107] proves that the semantic HAR model\nwithsemanticaugmentationaddedduringtrainingperformsbetterinmotionrecognitionthanothermodels.Semantic\naugmentation requires shared tokens, which is lacking in some datasets. Therefore, authors leverage ChatGPT for\nan automated label generation approach for datasets originally without shared tokens. Fu et al. [18] described a new\nworkflow for converting natural language commands into Bash commands. The author uses ChatGPT to generate a\ncandidate list of Bash commands based on user input, and then uses a combination of heuristic and machine learning\ntechniques to rank and select the most likely candidates. This workflow was evaluated on a real command dataset and\nachievedhighaccuracycomparedtootherstate-of-the-artmethods.Chenetal.[10]usedtheBartmodelandChatGPT\nfor the task of summarizing humorous titles and compared the performance of the two models. It was found that the\nBartmodelperformedbetteronlargedatasets,butChatGPTwascompetitivewithourbestfine-tunedmodelinasmall\nrange (48), albeit slightly weaker.\nThefollowingarticleusesChatGPTtogeneratesentences.Chenetal.[9]constructedadialoguedataset(HPD)with\nscenes,timelines,characterattributes,andcharacterrelationshipsinordertouseChatGPTasaconversationalagentto\ngenerate dialogue. However, ChatGPT’s performance on the test set was poor, and there is room for improvement.In\nstudy [36],chatGPT demonstrated itsability tosimplify complex textby providing threefictional radiology reportsto\nchatGPTforsimplification.Mostradiologistsfoundthesimplifiedreportstobeaccurateandcomplete,withnopotential\nharm to patients. However, some errors, omissions of critical medical information and text passages were identified,\nwhich could potentially lead to harmful conclusions if not understood by the physicians. Xia et al. [102] proposed\na new program repair paradigm called Session-based Automated Program Repair (APR). In APR, the previously\ngenerated patches are iteratively built upon by combining them with validation feedback to construct the model’s\ninput. The effectiveness of the approach is verified using the QuixBugs dataset. The experiment shows that ChatGPT\nfine-tuned with reinforcement learning from human feedback (RLHF) outperforms Codex trained unsupervisedly in\nboth repair datasets. In reference to study [37], ChatGPT was compared to three commercial translation products:\nGoogle Translate2, DeepL Translate3, and Tencent TranSmart4. The evaluation was conducted on the Flores101\ntest set, using the WMT19 biomedical translation task to test translation robustness, with BLEU score as the main\nmetric.ThestudyfoundthatChatGPTiscompetitivewithcommercialtranslationproductsonhigh-resourceEuropean\nlanguages but falls behind on low-resource or distant languages. The authors explored an interesting strategy called\npivot prompts, which significantly improved translation performance. While ChatGPT did not perform as well as\ncommercial systems on biomedical abstracts or Reddit comments, it may be a good speech translator. Prieto et al.\n[77] evaluated the use of ChatGPT in developing an automated construction schedule based on natural language\nprompts. The experiment required building new partitions in an existing space and providing details on the rooms\nto be partitioned. The results showed that ChatGPT was able to generate a coherent schedule that followed a logical\napproachtomeettherequirementsofthegivenscope.However,therewerestillseveralmajorflawsthatwouldlimitthe\nuse of this tool in real-world projects.Michail et al. [65] proposed a method to improve the prediction accuracy of the\nHeFit fine-tuned XLM_T model on tweet intimacy by generating a dataset of tweets with intimacy rating tags using\nChatGPT. The specific operation is to input tweets with intimacy rating tags into ChatGPT and then output similar\ntweets.\nYiheng Liu et al.:Preprint submitted to Elsevier Page 7 of 21\nSummary of ChatGPT-Related Research\nThefollowingarticleusesChatGPTtogenerateparagraphs.Wangetal.[92]comparedtheabstractsummarization\nperformanceofChatGPTandothermodelsonvariouscross-lingualtextdatasetsandfoundthatChatGPTmayperform\nworse in metrics such as R_1, R_2, R_L, and B_S. Yang et al. [103] summarized the performance of ChatGPT in\nquestionanswering-basedtextsummarizationandfoundthat,comparedtofine-tunedmodels,ChatGPT’sperformance\nis slightly worse in all performance metrics. However, the article suggests that if the dataset is golden annotation,\nChatGPT’s performance may surpass fine-tuned models in these metrics. Belouadi et al. [5] compared the ability of\nByGPT5andChatGPTtrainedonarangeoflabeledandunlabeleddatasetsofEnglishandGermanpoetrytogenerate\nconstrained style poetry, and evaluated them using three metrics: Rhyme, ScoreAlliteration, and ScoreMeter Score.\nTheconclusionisthatByGPT5performsbetterthanChatGPT.Blanco-Gonzalezetal.[6]evaluatedchatGPT’sability\nto write commentary articles, and in fact, this article itself was written by chatGPT. The human author rewrote the\nmanuscript based on chatGPT’s draft. Experts found that it can quickly generate and optimize text, as well as help\nusers complete multiple tasks. However, in terms of generating new content, it is not ideal. Ultimately, it can be said\nthat without strong human intervention, chatGPT is not a useful tool for writing reliable scientific texts. It lacks the\nknowledgeandexpertiserequiredtoaccuratelyandfullyconveycomplexscientificconceptsandinformation.Khalilet\nal. [39] on the originality of content generated by ChatGPT. To evaluate the originality of 50 papers on various topics\ngeneratedbyChatGPT,twopopularplagiarismdetectiontools,TurnitinandiThenticate,wereused.Theresultsshowed\nthat ChatGPT has great potential in generating complex text output that is not easily captured by plagiarism detection\nsoftware. The existing plagiarism detection software should update their plagiarism detection engines. Basic et al. [4]\nconducted a comparison of the writing performance of students using or not using ChatGPT-3 as a writing aid. The\nexperimentconsistedoftwogroupsof9participantseach.Thecontrolgroupwrotearticlesusingtraditionalmethods,\nwhile the experimental group used ChatGPT as an aid. Two teachers evaluated the papers. The study showed that\nthe assistance of ChatGPT did not necessarily improve the quality of the students’ essays.Noever et al. [68] discusses\nthe potential of using artificial intelligence (AI), particularly language models like GPT (including GPT-3), to create\nmore convincing chatbots that can deceive humans into thinking they are interacting with another person. The article\ndescribes a series of experiments in which they used GPT-3 to generate chatbot responses that mimic human-like\nconversationsandweretestedonhumanparticipants.Theresultsshowthatsomeparticipantswereunabletodistinguish\nbetweenthechatbotandarealhuman,highlightingthepotentialfortheseAIchatbotstobeusedfordeceptivepurposes.\n2.1.4. Code Generation\nCode generation refers to the process of automatically generating computer code from high-level descriptions\nor specifications. ChatGPT’s advanced natural language processing capabilities make it capable of performing code\ngeneration tasks. By analyzing the requirements for code generation, ChatGPT can produce code snippets that\naccurately execute the intended functionality. This not only saves time and effort in writing code from scratch but\nalsoreducestheriskoferrorsthatmayoccurduringmanualcoding.Inaddition,ChatGPT’sabilitytolearnandadapt\ntonewprogramminglanguagesandframeworksenablesittocompletemorecomplexprogrammingtasks.Forexample:\nMegahed et al. [64] discussed the potential of using ChatGPT for tasks such as code explanation, suggesting\nalternative methods for problem-solving with code, and translating code between programming languages. The\nsolutions provided by ChatGPT were found to be viable. In another study, Treude et al. [90] introduced a ChatGPT-\nbased prototype called GPTCOMCARE, which helps programmers generate multiple solutions for a programming\nproblem and highlight the differences between each solution using colors.Sobania et al. [83] utilized ChatGPT for\ncodebugfixing,andfurtherimprovedthesuccessrateofbugfixingbyinputtingmoreinformationthroughitsdialogue\nsystem.Specifically,theQuixBugsstandardbugfixingbenchmarkcontained40codebugsthatneededtobefixed.With\nlimitedinformation,ChatGPTfixed19bugs,whichwasslightlylowerthanthe21bugsfixedbytheCodexmodel,but\nsignificantlyhigherthanthe7fixedbytheStandardAPRmodel.Whengivenmorepromptsandinformation,ChatGPT\nwasabletofix31bugs,demonstratingitspotentialforcodebugfixingtasks.Xiaetal.[102]proposedaconversational\napproach for Automated Program Repair (APR), which alternates between generating patches and validating them\nagainst feedback from test cases until the correct patch is generated. Selecting 30 bugs from the QuixBugs standard\nbug fixing benchmark, which are suitable for test case feedback, and demonstrating them with Java and Python, the\nQuixBugs-PythonandQuixBugs-Javadatasetswereobtained.TheconversationalAPRusingChatGPToutperformed\ntheconversationalAPRusingCodexandtheconversationalAPRusingCODEGEN(withmodelparametersof350M,\n2B,6B,and16B)onbothdatasets.Furthermore,ChatGPT’sconversationalAPRgeneratedandvalidatedpatcheswith\nsignificantly fewer feedback loops than the other models.\nYiheng Liu et al.:Preprint submitted to Elsevier Page 8 of 21\nSummary of ChatGPT-Related Research\nChatGPT can not only be used to achieve some simple code generation tasks but also can be used to accomplish\nsome complex programming tasks. Noever et al. [69] tested ChatGPT’s code generation capabilities on four datasets\n- Iris, Titanic, Boston Housing, and Faker. When prompted to mimic a Python interpreter in the form of a Jupyter\nnotebook, the model was able to generate independent code based on the prompt and respond with the expected\noutput.Forexample,whengiventheprompt\"data.cor()\"fortheIrisdataset,ChatGPTgeneratedcorrectPythonoutput.\nThe test results indicate that ChatGPT can access structured datasets and perform basic software operations required\nby databases, such as create, read, update, and delete (CRUD). This suggests that cutting-edge language models like\nChatGPThavethenecessaryscaletotacklecomplexproblems.McKeeetal.[62]utilizedChatGPTasanexperimental\nplatformtoinvestigatecybersecurityissues.Theymodeledfivedifferentmodesofcomputervirusproperties,including\nself-replication,self-modification,execution,evasion,andapplication,usingChatGPT.Thesefivemodesencompassed\nthirteenencodingtasksfromcredentialaccesstodefenseevasionwithintheMITREATT&CKframework.Theresults\nshowedthatthequalityofChatGPT’sgeneratedcodewasgenerallyaboveaverage,exceptfortheself-replicationmode,\nwhere it performed poorly.They [63] also employed ChatGPT as a network honeypot to defend against attackers. By\nhaving ChatGPT mimic Linux, Mac, and Windows terminal commands and providing interfaces for TeamViewer,\nnmap, and ping, a dynamic environment can be created to adapt to attackers’ operations, and logs can be used to gain\ninsight into their attack methods, tactics, and procedures. The authors demonstrated ten honeypot tasks to illustrate\nthat ChatGPT’s interface not only provides sufficient API memory to execute previous commands without defaulting\nto repetitive introductory tasks but also offers a responsive welcome program that maintains attackers’ interest in\nmultiple queries.\nIn the field of code generation, there are still several challenges with ChatGPT. Firstly, its application scope is\nlimited as its training data is biased towards programming languages such as Python, C++, and Java, making it\npotentially unsuitable for some programming languages or coding styles. Secondly, manual optimization is necessary\nforcodeformatting,asthegeneratedcodemaynotbeperformance-optimizedorfollowbestcodingpractices,requiring\nmanualeditingandoptimization.Lastly,thequalityofthegeneratedcodecannotbeguaranteed,asitheavilyrelieson\nthequalityofthenaturallanguageinput,whichmaycontainerrors,ambiguities,orinconsistencies,ultimatelyaffecting\nthe accuracy and reliability of the generated code.\n2.1.5. Inference\nInference refers to the process of drawing new conclusions or information through logical deduction from known\nfacts or information. It is typically based on a series of premises or assumptions, and involves applying logical rules\nor reasoning methods to arrive at a conclusion. Inference is an important ability in human thinking, and is often used\nto solve problems, make decisions, analyze and evaluate information, etc. Inference also plays a key role in fields\nsuch as science, philosophy, law, etc. There are two types of inference: inductive reasoning, which involves deriving\ngeneralrulesorconclusionsfromknownfactsorexperiences,anddeductivereasoning,whichinvolvesderivingspecific\nconclusions from known premises or assumptions. Whether inductive or deductive, the process of inference requires\nfollowing strict logical rules to ensure the correctness and reliability of the inference.\nSomepapersattempttouseChatGPT’sabilityininductivereasoningtocapturethemeaningintextandusedefined\nmetrics to score the text. Michail et al. [65] uses ChatGPT to infer intimacy expressed in tweets. They first input 50\ntweets with intimacy markers to ChatGPT, then use inductive reasoning to infer the standards for generating tweets\nwithdifferentlevelsofintimacy,andfinallygeneratetentweetswithintimacyvaluesrangingfrom0to5.Susnjaketal.\n[86] collected a large amount of textual data from patient-doctor discussion forums, patient testimonials, social media\nplatforms, medical journals, and other scientific research publications. Using the BERT model, the author inferred\nemotionvaluesfrom0to1.Theauthorvisualizedtheprocessofhowthepresenceofbiasinthediscoursesurrounding\nchronic manifestations of the disease using the SHAP tool. The author also envisioned ChatGPT as a replacement for\nthe BERT model for scoring the emotional value of text. Huang et al. [32] chose 12.5% of individuals in the potential\nhate dataset as study materials, induced ChatGPT to make classifications based on a prompt, and ChatGPT produced\nthree classifications: unclear, yes, and no. The author assigned a value of 1 to yes, -1 to no, and 0 to unclear, and had\nChatGPT score and classify them. ChatGPT was able to correctly classify 80% of implicit hate tweets in the author’s\nexperimental setup, demonstrating ChatGPT’s great potential as a data labeling tool using simple prompts.\nSomepapershaveevaluatedChatGPT’sreasoningperformance,mainlyindecision-makingandspatialreasoning,\nand identifying ambiguity. Tang et al. [89] used the independence axiom and the transitivity axiom, as well as other\nnon-VNM related decision-making abilities, by presenting bets conditioned on random events, bets with asymmetric\noutcomes,decisionsencapsulatingSavage’sSureThingprinciple,andothercomplexbetstructureslikenestedbets,to\nYiheng Liu et al.:Preprint submitted to Elsevier Page 9 of 21\nSummary of ChatGPT-Related Research\ndesignexperimentswhereeachexperimentinputashortprompttoChatGPTandevaluatedtheresults.Theconclusion\nisthatChatGPTexhibitsuncertaintyinthedecision-makingprocess:insomecases,largelanguagemodelscanarriveat\nthecorrectanswerthroughincorrectreasoning;anditmaymakesuboptimaldecisionsforsimplereasoningproblems.\nOrtega-Martnetal.[72]hadChatGPTdetectthreedifferentlevelsoflanguageambiguityandevaluateditsperformance.\nThe conclusion is that In semantics, ChatGPT performed perfectly in the detection of ambiguities. Apart from that,\nit has some bright sports (co-reference resolution) and some weaknesses (puts gender bias over grammar in some\nnon-ambiguous situations). In the generation task ChatGPT did well, but also revealed some of its worse issues: the\nlack of systematicity. Lastly, it should also be pointed that in most of the cases ChatGPT brilliantly alludes to lack of\ncontext as the key factor in disambiguation.\n2.1.6. Data or information extraction, transformation, enhancement, processing\nData Visualization\nNatural language interfaces have contributed to generating visualizations directly from natural language, but\nvisualization problems remain challenging due to the ambiguity of natural language.ChatGPT provides a new avenue\nfor the field by converting natural language into visualized code.\nIn terms of data visualization, Noever et al. [69] tested ChatGPT’s basic arithmetic skills by asking questions.On\nthe iris dataset, Titanic survival dataset, Boston housing data, and randomly generated insurance claims dataset, the\nstatisticalanalysisofdataandvisualizationproblemswereconvertedtoprogrammingproblemsusingJupytertoverify\nChatGPT’sabilitytogeneratepythoncodetodrawsuitablegraphsandanalyzethedata.TheresultsshowthatChatGPT\ncan access structured and organized datasets to perform the four basic software operations required for databases:\ncreate, read, update, and delete, and generate suitable python code to plot graphs for descriptive statistics, variable\ncorrelationanalysis,describingtrends,andotherdataanalysisoperations.Maddiganetal.[61]proposedanend-to-end\nsolution for visualizing data in natural language using LLM, which uses an open-source python framework designed\ntogenerateappropriatehintsforselecteddatasetstomakeLLMmoreeffectiveinunderstandingnaturallanguage,and\nuses internal reasoning capabilities to select the appropriate visualization type to generate the code for visualization.\nIn this paper,the reseachers compare the visualization results of GPT-3, Codex and ChatGPT in the case of nvBench\nSQLitedatabase[59]andthevisualizationresultsofenergyproductiondatasetinthestudyofADVISorwithNL4DV\n[53; 67].In addition to, they explore the ability to reason and hypothesize of the LLM on movie dataset [59] when the\nhintsareinsufficientorwrong.ExperimentalresultsshowthatLLMcaneffectivelysupporttheend-to-endgeneration\nof visualization results from natural language when supported by hints, providing an efficient, reliable and accurate\nsolution to the natural language visualization problem.\nInformation Extraction\nThe goal of information extraction is to extract specific information from natural language text for structured\nrepresentation, including three important subtasks such as entity relationship extraction, named entity recognition,\nand event extraction, which have wide applications in business, medical, and other fields.\nIn information extraction, Wei et al. [97] proposed ChatIE, a ChatGPT-based multi-round question-and-answer\nframework for information extraction. The framework decomposes a complex information extraction (IE) task into\nseveral parts, then combines the results of each round into a final structured result. The entity association triple\nextraction,namedentityrecognition,andeventextractiontaskswereperformedonsixdatasetsNYT11-HRL,DuIE2.0\n, conllpp, MSR , DuEE1.0 [87; 50; 96; 49; 51], and ACE05 in both languages, comparing three metrics of precision,\nrecall, and F1 score.These results suggest that on six widely used IE datasets, ChatIE improves performance by an\naverage of 18.98% compared to the original ChatGPT without ChatIE, and outperforms the supervised models FCM\nandMultiR[21;30]ontheNYT11-HRLdataset.WhiletheoriginalChatGPTcannotsolvecomplexIEproblemswith\noriginal task instructions, and with this framework, successfully IE tasks were implemented on six datasets.Gao et\nal. [19] explored the feasibility and challenges of ChatGPT for event extraction on the ACE2005 corpus, evaluating\nthe performance of ChatGPT in long-tail and complex scenarios (texts containing multiple events) and comparing\nit with two task-specific models, Text2Event and EEQA [57; 14].Then,they explored the impact of different cues\non performance of ChatGPT. The results show that the average performance of ChatGPT in long-tail and complex\nscenariosisonly51.04%ofthatoftask-specificmodelssuchasEEQA.Continuousrefinementofcuesdoesnotleadto\nconsistentperformanceimprovements,andChatGPTishighlysensitivetodifferentcuestyles.Tangetal.[88]proposed\na new training paradigm that incorporates appropriate cues to guide ChatGPT to generate a variety of examples with\nYiheng Liu et al.:Preprint submitted to Elsevier Page 10 of 21\nSummary of ChatGPT-Related Research\ndifferent sentence structures and language patterns and eliminate the resulting low-quality or duplicate samples for\ndownstream tasks. Although compared to a soft model for a specific healthcare task, ChatGPT underperforms in\nNamed Entity Recognition (NER) and Relationship Extraction (RE) tasks , in the Gene Association Database (GAD)\nRelease; EU-ADR corpus for the RE task , the innovative training framework was able to train local models, with\nF1 scores improving from 23.37% to 63.99% for the named entity recognition task and from 75%, while alleviating\nprivacy concerns and time-consuming data collection and annotation problems.He et al. [28] proposed a contextual\nlearning framework ICL- D3IE. this framework introduces formatted presentation, continuously iterates to update\nand improve the presentation, and then combines ChatGPT for text information extraction. In the paper, ICL-D3IE\nis compared with existing pre-trained models such as LiLT,BROS (in-distribution (ID) setting and out-of-distribution\n(OOD) setting) on datasets (FUNSD, CORD, and SROIE [35; 75; 34]).These results show that the ICL-D3IE method\nin all datasets and settings except for the ID setting on CORD are superior to other methods, with ICL-D3IE (GPT-3)\nF1 scores reaching 90.32% on FUNSD and97.88% on SROIE; in the out-of-distribution (OOD) setting, ICL-D3IE\nperformsmuchbetterthanpreviouspre-trainedmethodsonalldatasets.Polaketal.[76]proposedChatExtractmethod\n- consisting of a set of engineering prompts applied to a conversational LLM - for automatic data extraction. During\nexperiment,theyextractedalargenumberofsentencesfromhundredsofpapersandrandomlyselected100sentences\ncontaining data and 100 sentences without data as test data. The results show that the accuracy and recall of LLM\nexceeded 90% and may be comparable to human accuracy in many cases; in addition to this, the experiments were\nconductedundertheconditionofremovingfollow-uppromptsandnotkeepingtheconversationcomparedtoprevious\nexperiments, respectively. The accuracy of deleting follow-up questions dropped to 80.2% and the recall rate dropped\nto88.0%.Removingtheconversationalaspectandrelatedinformationretentionrecallandaccuracydroppedto90.0%\nand 56.6%, respectively, demonstrating the effect of information retention combined with purposeful redundancy on\nLLM information extraction performance.\nQuality Assessment\nFortranslationquality,textgenerationquality,manualassessmentisusuallyeffectivebutsuffersfromsubjectivity\nandtime-consuming,etc.ItwasfoundthroughexplorationthatChatGPThasalsoachievedsignificantperformancein\nautomatic quality assessment.\nIn terms of quality assessment, Kocmi et al. [41] proposed a GPT-based translation quality assessment metric,\nGEMBA, which evaluates the translation of each fragment individually and then averages all the obtained scores to\nobtain a final system-level score. In the MQM2022 test set (English-German, English-Russian, and Chinese-English)\n[15], a scoring task was performed with a classification task to compare the accuracy [42] and kendall tau scores\n[16] of seven GPT models under four cue templates.The results showed that GEMBA had the highest system-level\naccuracy of 88.0% compared to more than 10 automatic metrics such as BLEU, and among the seven GPT models,\nChatGPTaccuracyisabove80%,inadditionto,thebestperformancecanbeobtainedintheleastconstrainedtemplate,\ndemonstrating the potential of LLM for translation quality assessment tasks, but the evaluation is only applicable at\nthe system level and needs further improvement.Wang et al. [93] used ChatGPT as a natural language generation\n(NLG) evaluator to study the correlation with human judgment. On three datasets covering different NLG tasks,\ntask- and aspect-specific cues were designed to guide ChatGPT for NLG evaluation in CNN/DM [29], OpenMEVA-\nROC,andBAGELforsummary,storygeneration,anddata-to-textscoring,respectively.Then,theycomputeSpearman\ncoefficients [105],Pearson correlation coefficients [66]. Kendall’s Tau score [38] to assess the correlation with human\nevaluations.The results show that ChatGPT is highly correlated with human judgments in all aspects, with correlation\ncoefficients of 0.4 or more in all categories, showing its potential as an NLG indicator.\nData Augmentation\nInnaturallanguageprocessing,textdataaugmentationisaneffectivemeasuretoalleviatetheproblemoflowdata\nquantity and low quality training data, and ChatGPT has shown great potential in this regard.\nIn terms of data augmentation, Dai et al. [13] proposed a ChatGPT-based text data augmentation method that\nreformulateseachsentenceinthetrainingsampleintomultipleconceptuallysimilarbutsemanticallydifferentsamples\nforclassificationtasksdownstreamoftheBertmodel.OntexttranscriptionsandPubMed20kdatasetscontainingmore\nthan 8 hours of audio data of common medical symptom descriptions,experiments were conducted to compare cosine\nsimilarity and TransRate metrics with multiple data enhancement methods [33].This paper shows that compared with\nexisting data enhancement methods, the proposed ChatAug method shows a double-digit improvement in sentence\nYiheng Liu et al.:Preprint submitted to Elsevier Page 11 of 21\nSummary of ChatGPT-Related Research\nclassificationaccuracyandgeneratesmorediverseaugmentedsampleswhilemaintainingitsaccuracy,buttheoriginal\nmodel is not fine-tuned in the paper and suffers from a lack of domain knowledge, which may produce incorrect\naugmented data.\nMultimodal fusion\nChatGPT can currently only process natural language directly, but with a cross-modal encoder, it can combine\nnatural language with cross-modal processing to provide solutions for intelligent transportation, healthcare, and other\nfields.\nIn terms of multimodal data processing, Wu et al. [101] constructed a framework that Visual ChatGPT integrates\nwith different Visual Foundation Models (VFMs) and then combines a series of hints to input visual information to\nChatGPT to solve visual problems.The paper shows examples of visual tasks such as removing or replacing certain\nobjects from images, interconversion between images and text, demonstrating the Visual ChatGPT has great potential\nand capability for different tasks.But there are issues during the task that requires a large number of hints to convert\nVFMs to language, invoke multiple VFMs to solve complex problems leading to limited real-time capability, and\nsecurity and privacy issues. Zheng et al. [109] showed a text mining example of LLM for extracting self-driving car\ncrash data from California crash news, analyzing a failure report example, and generating a crash report example\nbased on keywords; introduced a use case concept of a smartphone-based framework for automatic LLM failure\nreport generation, which absorbs multiple data sources captured by cell phone sensors and then transfers the data\nto a language space for text mining, inference and generation, and further outputs the key information needed to form\na comprehensive fault report, demonstrating the potential of LLM for a variety of transportation tasks.\nNowadays, ChatGPT shows a wide range of applications in data visualization, information extraction, data\nenhancement, quality assessment, and multimodal data processing.But there are also issues on how to further utilize\nhints to effectively interact with ChatGPT, lack of ability to process and analyze data from devices such as sensors,\nand data privacy and security.\nCueing Techniques\nCue engineering provides important support for effective dialogue with large language models.White et al. [99]\nproposed a framework for cueing models applicable to different domains. This framework structures cues to interact\nwith LLMs by providing specific rules and guidelines. Also, this paper presents a catalog of cueing patterns that\nhave been applied to LLM interactions, as well as specific examples with and without cues. The advantages of the\ncombinability of prompting patterns are demonstrated, allowing users to interact with LLM more effectively, but\npatterns for reusable solutions and new ways to use LLM need to be continuously explored.\n2.1.7. Human-ChatGPT Collaboration\nCollaboration between humans and machines is a process where humans and machines work together to achieve\na common goal. In such collaboration, humans provide domain expertise, creativity, and decision-making abilities,\nwhile machines provide automation, scalability, and computing power. ChatGPT is an advanced natural language\nprocessing model that can understand and generate human-like language, thereby reducing communication costs. Its\nability to process and generate natural language makes it an ideal partner for human collaboration. ChatGPT can offer\nrelevant suggestions, complete tasks based on human input, and enhance human productivity and creativity. It can\nlearnfromhumanfeedbackandadapttonewtasksanddomains,furtherimprovingitsperformanceinhuman-machine\ncollaboration. ChatGPT’s capability to comprehend natural language and produce appropriate responses makes it\na valuable tool for various collaboration applications, as demonstrated by several studies in the literature we have\ngathered.\nAhmad et al. [1] proposed a method for human-machine collaboration using ChatGPT to create software archi-\ntecture. This method transforms software stories (created by software architects based on application scenarios) into\nfeasible software architecture diagrams through continuous interaction between the software architect and ChatGPT.\nDuring the evaluation stage, ChatGPT uses the Software Architecture Analysis Method (SAAM) to evaluate each\ncomponentinthesoftwarearchitectureandgenerateevaluationreports.Thismethodefficientlyutilizestheknowledge\nand supervision of the architect with the capabilities of ChatGPT to collaboratively build software-intensive systems\nand services. Lanzi et al. [47] proposed a collaborative design framework that combines interactive evolution and\nChatGPT to simulate typical human design processes. Humans collaborate with large language models (such as\nChatGPT) to recombine and transform ideas, and use genetic algorithms to iterate through complex creative tasks.\nYiheng Liu et al.:Preprint submitted to Elsevier Page 12 of 21\nSummary of ChatGPT-Related Research\nThe results of three game design tasks showed that the framework received positive feedback from game designers.\nThe framework has good reusability and can be applied to any design task that can be described in free text form.\nIn the future, ChatGPT’s ability to understand nonverbal cues such as tone of voice and body language can be\nenhanced, enabling it to better understand human thoughts and interact with people more effectively.\n2.1.8. ChatGPT Integration\nIntegrationreferstocombiningdifferentsystemsorsoftwarecomponentstoachieveacommongoal.ChatGPTcan\nbe integrated as a part of a whole or act as an integration tool to enable seamless communication between different\nsystems.Itsnaturallanguageprocessingabilitymakesiteasierfornon-technicaluserstointeractwithsystems,reducing\nthe need for specialized knowledge or training. Some studies in the literature we collected have already demonstrated\nthis.\nTreude et al. [90] integrated ChatGPT into the prototype of \"GPTCOMCARE\" to address programming query\nproblems. This integration allowed for the generation of multiple source code solutions for the same query, which\nincreased the efficiency of software development. The results of their study demonstrated the effectiveness of using\nChatGPT to improve the quality and diversity of code solutions, ultimately reducing the amount of time and effort\nrequired for software development. Wang et al. [94] proposed the chatCAD method, which utilizes large language\nmodels (LLMs) such as ChatGPT to enhance the output of multiple CAD networks for medical images, including\ndiagnosis, lesion segmentation, and report generation networks. The method generates suggestions in the form of\na chat dialogue. The authors tested the effectiveness of the method on a randomly selected set of 300 cases from\nthe MIMIC-CXR dataset, which included 50 cases each of cardiomegaly, edema, consolidation, atelectasis, pleural\neffusion, and no findings. Compared to CvT2DistilGPT2 and R2GenCMN, chatCAD showed significant advantages\nin RC and F1, while only performing weaker than R2GenCMN in PR.\nIntegratingChatGPTintoapplicationswillstillpresentchallenges.Firstly,ChatGPT’sperformancemaybeaffected\nby language barriers or differences in terminology between different systems. Additionally, ChatGPT’s responses are\nnotalwaysdeterministic,whichposesachallengewhenintegratingwithsystemsthatrequirepreciseandreproducible\nresults. Finally, the processing time of ChatGPT is slow for integration tasks involving time-sensitive data such as\ntraffic, which is a limitation in time-critical environments.\n2.1.9. Medical Applications\nChatGPT offers promising applications in medical field, revolutionizing healthcare practices. Its natural language\nprocessing capabilities enable interactive assistance for radiologists, aiding in image annotation, lesion detection, and\nclassification.ChatGPT’sextensiveknowledgebasefacilitatesreal-timefeedback,context-specificrecommendations,\nand streamlined report generation. By integrating ChatGPT into workflows, healthcare professionals benefit from\nenhanced efficiency and precision in clinical decision-making, fostering accessible and collaborative healthcare\nsolutions. For example:\nChatCAD [94] integrates large language models (LLMs) into computer-aided diagnosis (CAD) networks for\nmedical imaging. It has shown promising results in improving diagnosis, lesion segmentation, and report generation,\nthree key aspects of CAD networks. This integration represents a notable effort in combining large language models\nwith medical imaging techniques.\nHu et al. [31] conducted a comprehensive review of language models in the context of medical imaging and\nhighlightedthepotentialadvantagesofChatGPTinenhancingclinicalworkflowefficiency,reducingdiagnosticerrors,\nandsupportinghealthcareprofessionals.Theirworkaimstobridgethegapbetweenlargelanguagemodelsandmedical\nimaging, paving the way for new ideas and innovations in this research domain.\nMa et al. [60] proposed ImpressionGPT, a novel approach that harnesses the powerful in-context learning\ncapabilities of ChatGPT. They achieve this by creating dynamic contexts using domain-specific and individualized\ndata.Thedynamicpromptmethodenablesthemodeltolearncontextualknowledgefromsemanticallysimilarexamples\nin existing data and iteratively optimize the results, aiding radiologists in composing the \"impression\" section based\non the \"findings\" section. The results demonstrate state-of-the-art performance on both the MIMIC-CXR and OpenI\ndatasets, without the need for additional training data or fine-tuning of the LLMs.\nAD-AutoGPT [12], an integration of AutoGPT [22], leverages the power of ChatGPT in an automated processing\npipeline that can assist users in accomplishing nearly any given task. With AD-AutoGPT, users can autonomously\ngenerate data collection, processing, and analysis pipelines based on their text prompts. Through AD-AutoGPT,\ndetailed trend analysis, mapping of topic distances, and identification of significant terms related to Alzheimer’s\nYiheng Liu et al.:Preprint submitted to Elsevier Page 13 of 21\nSummary of ChatGPT-Related Research\ndisease (AD) have been achieved from four new sources specifically relevant to AD. This significantly contributes\nto the existing knowledge base and facilitates a nuanced understanding of discourse surrounding diseases in the field\nof public health. It lays the groundwork for future research in AI-assisted public health studies.\nPatient privacy protection has always been a significant concern in the healthcare field. DeID-GPT [55] aims to\nexplore the potential of ChatGPT in the de-identification and anonymization of medical reports. Experimental results\ndemonstrate that ChatGPT exhibit promising capabilities in medical data de-identification compared to other LLMs.\nDespite notable efforts, the integration of large language models and medical imaging still presents several\nchallenges.Firstly,theintricateandtechnicalnatureofmedicalimagingdata,whichencompassesdetailedanatomical\nstructures and subtle abnormalities, may not be effectively conveyed or comprehended through the text-based chat\ninterfaceoflargelanguagemodels.Secondly,ChatGPTlacksthespecializedmedicalknowledgeandtrainingnecessary\nfor precise interpretation and analysis of medical images, potentially leading to dangerous misunderstandings or\ninaccurate diagnoses [52]. It is imperative to establish various machine learning models to detect samples generated\nby both humans and ChatGPT, in order to prevent false medical information produced by ChatGPT from causing\nmisjudgmentsindiseaseprogression,delayingtreatmentprocesses,ornegativelyimpactingpatients’livesandhealth.\nLastly,thelegalandethicalaspectsassociatedwithdeployingartificialintelligencemodelslikeChatGPTinamedical\ncontext, such as patient privacy and liability concerns, must be thoughtfully addressed and aligned with regulatory\nstandards. While ChatGPT is powerful, it is not easily applicable in clinical settings. Compliance with HIPAA\nregulations,privacyissues,andthenecessityforIRBapprovalposesignificantobstacles[55],primarilybecausethese\nmodelsrequireuploadingpatientdatatoexternalhostingplatforms.Onepossiblesolutiontothisproblemistoaddress\nit through localized deployment of language models, such as Radiology-GPT [56]. The future application of chatGPT\nin the field of medical imaging will necessitate ongoing efforts from all stakeholders.\n2.2. AI Ethics\nSince the advent of ChatGPT, this powerful natural language processing model has not only brought great\nconveniencetopeoplebutalsotriggeredmorecrisis-awarethinking.Someresearchershavestartedtohypothesizeand\nstudy the potential negative impacts of ChatGPT. This proactive research provides good proposals for standardized\nconstruction to address future AI abuse issues.\nRegarding the possibility of ChatGPT being used for plagiarism and cheating, Zhou et al. [111] reflected on\nthe current state of development of artificial intelligence like ChatGPT. As ChatGPT becomes increasingly easy to\nobtain and scalable in text generation, there is a high likelihood that these technologies will be used for plagiarism,\nincludingscientificliteratureandnewssources,posingagreatthreattothecredibilityofvariousformsofnewsmedia\nand academic articles. Some scholars are concerned that the end of paper as a meaningful evaluation tool may be\napproaching [100; 104], as ChatGPT can easily generate persuasive paragraphs, chapters, and papers on any given\ntopic. Additionally, it will exacerbate plagiarism issues in many fields such as education, medicine, and law [48], and\nmay be used for cheating in academic exams [85]. Definitional recognition technology is a relatively effective method\nfordetectingplagiarism,andthedefinitionaltypologyproposedin[111]canalleviatepeople’sconcernsbybeingused\nto construct new datasets. Susnjak [85] proposed a solution to the possibility of large language models like ChatGPT\nbeingusedforexamcheating:guidingChatGPTtogeneratesomecriticalthinkingproblemsthroughquestioning,then\nproviding answers and critically evaluating them. Analysis of ChatGPT shows that it exhibits critical thinking, can\ngenerate highly realistic text in terms of accuracy, relevance, depth, breadth, logic, persuasiveness, and originality.\nTherefore, educators must be aware of the possibility of ChatGPT being used for exam cheating and take measures to\ncombat cheating behavior to ensure the fairness of online exams.\nRegarding the evaluation of ChatGPT’s own political and ethical tendencies, Hartmann et al. [27] used Wahl-O-\nMat, one of the most commonly used voting advice applications in the world, to show ChatGPT political statements\nfrom different parties, forcing it to make choices of agree, disagree, or neutral. The results indicated that ChatGPT\nhas a pro-environment, left-wing liberal ideology, which was also confirmed in the nation-state agnostic political\ncompasstest.Anotherstudy(referencedas[45])examinedChatGPT’smoralstandardsbyrepeatedlyaskingitdifferent\nversionsofthetrolleyproblem,andfoundthatChatGPTgaveanswerswithdifferentmoralorientations,lackingafirm\nmoralstance.AsubsequenttestalsofoundthatChatGPT’slackofconsistencycouldaffectpeople’smoraljudgments.\nAdditionally,Borjietal.[7]demonstratedChatGPT’sinconsistencyinreasoning,factualerrors,mathematics,coding,\nand bias across eleven related aspects. These findings highlight ChatGPT’s inherent traits and limitations, and people\nshould be aware of their potential impact when seeking advice from ChatGPT. Zhuo et al. [112] comprehensively\nanalyzed the moral hazard, bias, reliability, robustness, and toxicity of ChatGPT from four perspectives. The results\nYiheng Liu et al.:Preprint submitted to Elsevier Page 14 of 21\nSummary of ChatGPT-Related Research\nfoundthatChatGPTmayperformslightlybetterthanthecurrentSOTAlanguagemodel,buthassomeshortcomingsin\nallfouraspects.Theauthorslookaheadtotheethicalchallengesofdevelopingadvancedlanguagemodelsandsuggest\ndirections and strategies for designing ethical language models.\nRegarding relevant policies and regulations, Hacker et al. [25] discussed the nature and rules of large generative\nAImodels,includingChatGPT,whicharerapidlychangingthewaywecommunicate,explain,andcreate.Theauthor\nsuggestedthatdifferentstakeholdersinthevaluechainshouldtakeregulatoryresponsibilityanddeployfourstrategies\ntotailormorecomprehensivelawsforthebenefitofsociety.Anotherstudy(referencedas[24])criticizedtheEuropean\nCommission’sproposalonAIresponsibilityandsuggestedrevisingtheproposedAIresponsibilityframeworktoensure\neffectivecompensationwhilepromotinginnovation,legalcertainty,andsustainableAIregulation.Apolicyframework\nwas proposed (referenced as [40]) to customize LLMs, such as ChatGPT, in a socially acceptable and safe manner,\nemphasizing the need to align large language models (LLMs) with human preferences.\nThe political and ethical tendencies of ChatGPT could influence users’ behavior and decision-making to some\nextent. However, some studies have conducted in-depth research on the use of norms and limitations, which could\nenable humans to use ChatGPT more reasonably and safely.\n3. Evaluation\n3.1. Comparison of ChatGPT with existing popular models\nWeusepubliclyavailabledatasetstocomprehensivelyevaluatethestrengthsandlimitationsofChatGPT.Reference\n[3] evaluates the technical performance of ChatGPT in multitask, multilingual, and multimodal aspects based on 23\nstandard public datasets and newly designed multimodal datasets, including eight different common natural language\nprocessing application tasks. The experimental results show that, in terms of multitasking, ChatGPT outperforms\nvarious state-of-the-art zero-shot learning large language models in most tasks, and even outperforms fine-tuned task-\nspecific models in some individual tasks. In terms of multilingualism, we found that ChatGPT cannot be applied to\nlow-resourcelanguagesbecauseitcannotunderstandthelanguageandgeneratetranslationsforthatlanguage.Interms\nof multimodality, ChatGPT’s ability is still basic compared to specialized language-visual models.\nIntermsofstability,reference[43]concludesthatChatGPT’sperformanceisalwayslowerthanSOTA,thecurrent\nstate-of-the-art model, in almost all tasks. This means that as a general model, ChatGPT has never reached the\nlevel of the best existing models. Experimental data shows that the average quality of the SOTA model is 73.7%,\nwhile the average quality of the ChatGPT model is only 56.5%. At the same time, ChatGPT’s stability is poor: the\nstandard deviation of its performance is 23.3%, while the SOTA model’s standard deviation is only 16.7%. This non-\ndeterministic behavior exhibited by ChatGPT could be a serious drawback in some problems.\nSimilarly,Qinetal.[78]conductedacomprehensiveevaluationofwhetherChatGPTisaqualifiedgeneralnatural\nlanguageprocessingtasksolver.TheexperimentanalyzedChatGPT’szero-shotlearningabilitybasedon20commonly\nusedpublicdatasetscovering7representativetaskcategories.Below,wewillanalyzeChatGPT’sperformanceoneach\ntask:\nIntermsofreasoningtasks,ChatGPTperformsaverageonmathematicalsymbol,commonsensecausal,andlogical\nreasoningtasks,butperformswellinarithmeticreasoning[78].Thatistosay,ChatGPT’sabilitiesvaryamongdifferent\ntypes of reasoning tasks. In terms of logical reasoning, ChatGPT’s deductive and abductive reasoning are superior to\ninductive reasoning, while in other reasoning tasks, such as analogy, causal and commonsense reasoning, ChatGPT\nperforms well [3].\nIn terms of sentiment analysis task, ChatGPT performs similarly to GPT-3.5 and bert-style models [78; 110].\nHowever,accordingtoliterature[43],ChatGPThaslossesnotexceeding25%onmosttasks,exceptforthreerelatively\nsubjectiveemotionperceptiontaskswhereitperformspoorly.Ifweremovethesetaskstocalculatetheaveragequality\nof the two models, we find that the SOTA method has an average quality of 80%, while the ChatGPT method has an\naveragequalityof69.7%.Thatistosay,ChatGPTperformswellonalltasksexceptforemotion-relatedtasks,andcan\nhandle most of the problems we consider. However, overall, its performance is lower than the SOTA model based on\nexperimental data, but the difference between the two is not very large.\nIn other tasks, according to literature [78], ChatGPT performs well in natural language inference, i.e., the task of\ninferringsentencerelationships,anditsperformanceonthistaskissignificantlybetterthanallbert-stylemodels[110].\nHowever, while ChatGPT performs well on inference tasks, it may produce some self-contradictory or unreasonable\nresponses, which is its potential limitation. In question-answering, dialogue, and summarization tasks, ChatGPT\nperforms better than the GPT-3.5 model [78], especially in the question-answering task, where its performance is\nYiheng Liu et al.:Preprint submitted to Elsevier Page 15 of 21\nSummary of ChatGPT-Related Research\ncomparable to bert-style models [110]. Therefore, we have demonstrated that ChatGPT is a qualified general-purpose\nmodel.\nHowever,ChatGPTalsohaslimitationsinmanyaspects.Firstly,itlackstheabilitytohandlenon-textualsemantic\nreasoning tasks such as mathematical, temporal, and spatial reasoning, and it performs poorly in multi-hop reasoning\n[3]. Secondly, ChatGPT is not good at solving named entity recognition tasks [78]. Furthermore, ChatGPT performs\npoorly in handling tasks involving negative connotations and neutral similarity [110]. Finally, these conclusions\nindicatethat,likeotherlargepre-trainedlanguagemodels,ChatGPThaslimitationsincompletingcomplexreasoning\ntasks.\nIn summary, ChatGPT’s zero-shot performance is comparable to fine-tuned bert and GPT-3.5 models, and with\nthe help of advanced prompting strategies, ChatGPT can demonstrate better comprehension abilities. However, it still\ncannot outperform the current SOTA models.\n3.2. Feedback from ChatGPT users\nIn response to feedback from ChatGPT users, Haque et al. [26] conducted a mixed-methods study using 10,732\nearly ChatGPT user tweets. The authors extracted Twitter data using Python and Twitter API and constructed the\nChatGPTTweet dataset, which contains 18k tweets. For each tweet, the authors collected information on text content,\nuser location, occupation, verification status, date of publication, and tags. Based on this dataset, the authors studied\nthe characteristics of early ChatGPT users, discussion topics related to ChatGPT on Twitter, and the sentiment\nof Twitter users toward ChatGPT. For RQ1, the authors found that early ChatGPT users had a diverse and wide\nrange of occupational backgrounds and geographical locations. For RQ2, the authors identified nine topics related\ntoChatGPT,includingitsimpactonsoftwaredevelopment,entertainmentandcreativity,naturallanguageprocessing,\neducation,chatbotintelligence,businessdevelopment,searchengines,question-answeringtests,andfuturecareersand\nopportunities.ForRQ3,mostearlyusersexpressedpositivesentimenttowardtopicssuchassoftwaredevelopmentand\ncreativity, while only a few expressed concern about the potential misuse of ChatGPT.\n3.3. Adverse effects of ChatGPT on users\nRegarding the negative effects of ChatGPT on users, Luan et al. [58] studied the psychological principles of\nChatGPT, delved into the factors that attract users’ attention, and revealed the impact of these factors on future\nlearning. In the post-pandemic era, teachers and students are both facing uncertainty in the teaching process and job\npressures. Under these common constraints of education and employment, educators and students must re-evaluate\ncurrent educational methods and outcomes, as well as students’ future career development. Through question-and-\nanswerexchangeswithChatGPT,peoplecaneasilyobtainappropriatesolutionsorkeyinformation,therebyenhancing\ntheirmotivation,eliminatinganxietyinlearning,improvinginterest,andachievingpsychologicalsatisfaction.Subhash\net al. [84] explored whether large language models have the ability to reverse user preferences. With the development\nof pre-trained large language models, people are increasingly concerned about the ability of these models to\ninfluence,persuade,andpotentiallymanipulateuserpreferencesinextremecases.Therefore,theliterature[84]roughly\nqualitatively analyzed that adversarial behavior does lead to potential changes in user preferences and behaviors in\ndialogue systems. If we want to further quantitatively analyze the ability of large language models in this regard,\nadditional statistical summary techniques need to be used for future research.\n4. Discussion\n4.1. Limitations\nDespitetheremarkablecapabilitiesofChatGPT,itstillfacescertainlimitations.Someoftheselimitationsinclude:\nOutdated Knowledge\nThecurrentmodelsaretrainedonhistoricaldata(upto2021),therebylackingreal-timecomprehensionofcurrent\naffairs. This is a critical concern in today’s information-explosion era, as the reliability of prior knowledge bases\nprogressively diminishes, potentially yielding inaccurate responses, especially in rapidly evolving domains such as\njurisprudence and technology. Additionally, these models are incapable of fact-checking while the training data is\ncomposedofcontentfromvarioussources,someofwhichmaybeunreliable,whichmayresultinseeminglyplausible\nyet nonsensical responses.\nYiheng Liu et al.:Preprint submitted to Elsevier Page 16 of 21\nSummary of ChatGPT-Related Research\nInsufficient Understanding\nWhile these models can interpret the majority of inquiries and contextual situations, they occasionally encounter\ncomprehension biases when addressing ambiguous or contextually complex queries. Furthermore, in certain spe-\ncialized fields, the abundance of unique abbreviation exacerbates the models’ understanding challenges, resulting in\nincorrect and vacuous responses.\nEnergy Consumption\nThroughoutthetrainingandinferencestages,theselarge-scalemodelsrequiresignificantcomputationalresources\nand electrical power, resulting in elevated energy consumption and significant carbon emissions. Consequently, this\nrestricts their deployment and practical applications.\nMalicious Usage\nDespite OpenAI implementing a series of restrictions to mitigate model toxicity, instances of users evading these\nconstraints through meticulously designed prompts have emerged, inducing the model to produce unhealthy content\nor even using it for illicit commercial purposes.\nBias and Discrimination\nDue to the influence of pre-training data, the models exhibit biases in political, ideological, and other areas. The\napplication of LLMs in public domains, such as education and publicity, should be approached with extreme caution.\nPrivacy and Data Security\nConcurrentwiththeexpansionofusers,protectinguserprivacyanddatasecuritybecomesincreasinglyimportant.\nIn fact, ChatGPT was banned in Italy in early April due to privacy concerns. This is particularly relevant given the\nmodels’ extensive collection of personal information and preferences during interactions, and as future multimodal\nmodels, such as GPT-4, may frequently require users to upload private photos.\n4.2. Future Directions\nInforthcomingresearch,thedevelopmentofmodelsbasedonChatGPTmayfocusonaddressingtheselimitations\nto enhance their practical applications.\nPrimarily,researchersshouldcontinuetoworkonrefiningmodeltrainingmethodologieswhilefilteringpre-training\ndata to minimize the presence of misleading information in the model’s knowledge base, thereby obtaining accurate\nresponses. Concurrently, it is crucial to emphasize training approaches that economize computational resources,\nthereby mitigating costs and broadening potential application scenarios.\nMoreover, the advancements in context-awareness and disambiguation technologies are anticipated to facilitate\nenhancedcomprehensionofcomplexqueriesbymodels,improvingtheaccuracy,relevance,andcontext-awarenessof\nAI-generated content. Integrating real-time data streams can also keep these models in sync with current events and\ntrends, enabling them to provide up-to-date information such as live traffic, weather, and stock updates.\nAdditionally, developers should engage in interdisciplinary collaboration with specialists from diverse domains,\nincluding policy-making, jurisprudence, and sociology, with the objective of formulating standard and ethical\nframeworks for LLM development, deployment, and utilization, thereby alleviating potential harmful consequences.\nIntermsofpublicawarenessandeducation,mandatoryawarenesstrainingshouldbeimplementedpriortolarge-scale\npublic deployment and application to increase public awareness of LLM capabilities and limitations while promoting\nresponsible and informed utilization, especially in industries such as K-12 education and journalism.\nFurthermore, ChatGPT still lacks specific domain knowledge and may encounter potential data security issues,\nespeciallyinthemedicalfield.Indomainswhereerrortoleranceislowanddataprivacyandsecurityarecrucial,such\nas medical applications [55], localized training and deployment of LLMs should be considered [56]. Customizing\ntraining for specific LLMs based on domain-specific data should also be taken into account.\nFinally,theinfluenceofChatGPTshouldnotbelimitedtojusttheNLPfield.Theyalsoshowpromisingprospects\nin the areas of computer vision, brain-inspired AI, and robotics. These models exhibit a capacity for learning and\ncomprehensioncomparablewithhuman-levelintelligence,positioningthemasapivotalcomponentinthedevelopment\nofartificialgeneralintelligence(AGI)[108].Theirabilitytofacilitateseamlessinteractionsbetweenhumansandrobots\npaves the way for the execution of more complex tasks. The remarkable capacity of zero-shot in-context learning of\nYiheng Liu et al.:Preprint submitted to Elsevier Page 17 of 21\nSummary of ChatGPT-Related Research\nthese models enables quick adaptation to new tasks without the requirement for labeled data for fine-tuning, which\nis a critical challenge in fields like medical informatics[55] and robotics[54] where the availability of labeled data is\ncommonly limited or non-existent.\n5. Conclusion\nThis review paper provides a comprehensive survey of ChatGPT, highlighting their potential applications and\nsignificant contributions to the field of natural language processing. The findings of this study reveal that the interest\nin these models is growing rapidly, and they have shown considerable potential for application across a wide range of\ndomains. One key factor contributing to the success of ChatGPT is their ability to perform large-scale pre-training,\nwhich captures knowledge from the vast expanse of the internet, allowing the models to learn from a massive amount\nof data. The integration of Reinforcement Learning from Human Feedback (RLHF) has further enhanced the model’s\nadaptability and performance, making it highly efficient in processing natural language. In addition, RLHF aligns\nlanguage models with human preferences & values and empower text generation with the naturalness of human style.\nThis study has also identified several potential ethical concerns related to the development and use of ChatGPT. For\ninstance,thereareconcernsaboutthegenerationofbiasedorharmfulcontent,privacyviolations,andthepotentialfor\nmisuse of the technology. It is crucial to address these concerns and ensure that ChatGPT is developed and used in a\nresponsibleandethicalmanner.Furthermore,theresultsofthisstudydemonstratethatthereissignificantpotentialfor\nChatGPT to be applied in a range of domains, including education, medical, history, mathematics, physics, and more.\nThese models can facilitate tasks such as generating summaries, answering questions, and providing personalized\nrecommendationstousers.Overall,theinsightspresentedinthisreviewpapercanserveasausefulguideforresearchers\nand practitioners looking to advance the field of natural language processing. Future research in this field should\nfocus on addressing ethical concerns, exploring new applications, and ensuring the responsible use of ChatGPT. The\npotential of these models to revolutionize natural language processing is enormous, and we look forward to seeing\nmore developments in this field.\nAcknowledgement\nThis work was supported by the National Natural Science Foundation of China (No. 61976131).\nReferences\n[1] Ahmad, A., Waseem, M., Liang, P., Fehmideh, M., Aktar, M.S., Mikkonen, T.: Towards human-bot collaborative software architecting with\nchatgpt. arXiv preprint arXiv:2302.14600 (2023)\n[2] Amin, M.M., Cambria, E., Schuller, B.W.: Will affective computing emerge from foundation models and general ai? a first evaluation on\nchatgpt. arXiv preprint arXiv:2303.03186 (2023)\n[3] Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H., Ji, Z., Yu, T., Chung, W., et al.: A multitask, multilingual,\nmultimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023 (2023)\n[4] Basic,Z.,Banovac,A.,Kruzic,I.,Jerkovic,I.:Betterbyyou,betterthanme,chatgpt3aswritingassistanceinstudentsessays.arXivpreprint\narXiv:2302.04536 (2023)\n[5] Belouadi, J., Eger, S.: Bygpt5: End-to-end style-conditioned poetry generation with token-free language models. arXiv preprint\narXiv:2212.10474 (2022)\n[6] Blanco-Gonzalez,A.,Cabezon,A.,Seco-Gonzalez,A.,Conde-Torres,D.,Antelo-Riveiro,P.,Pineiro,A.,Garcia-Fandino,R.:Theroleofai\nin drug discovery: Challenges, opportunities, and strategies. arXiv preprint arXiv:2212.08104 (2022)\n[7] Borji, A.: A categorical archive of chatgpt failures. arXiv preprint arXiv:2302.03494 (2023)\n[8] Brown,T.,Mann,B.,Ryder,N.,Subbiah,M.,Kaplan,J.D.,Dhariwal,P.,Neelakantan,A.,Shyam,P.,Sastry,G.,Askell,A.,etal.:Language\nmodels are few-shot learners. Advances in neural information processing systems33, 1877–1901 (2020)\n[9] Chen, N., Wang, Y., Jiang, H., Cai, D., Chen, Z., Li, J.: What would harry say? building dialogue agents for characters in a story. arXiv\npreprint arXiv:2211.06869 (2022)\n[10] Chen, Y., Eger, S.: Transformers go for the lols: Generating (humourous) titles from scientific abstracts end-to-end. arXiv preprint\narXiv:2212.10522 (2022)\n[11] Christiano, P.F., Leike, J., Brown, T., Martic, M., Legg, S., Amodei, D.: Deep reinforcement learning from human preferences. Advances in\nneural information processing systems30 (2017)\n[12] Dai, H., Li, Y., Liu, Z., Zhao, L., Wu, Z., Song, S., Shen, Y., Zhu, D., Li, X., Li, S., et al.: Ad-autogpt: An autonomous gpt for alzheimer’s\ndisease infodemiology. arXiv preprint arXiv:2306.10095 (2023)\n[13] Dai, H., Liu, Z., Liao, W., Huang, X., Wu, Z., Zhao, L., Liu, W., Liu, N., Li, S., Zhu, D., et al.: Chataug: Leveraging chatgpt for text data\naugmentation. arXiv preprint arXiv:2302.13007 (2023)\n[14] Du, X., Cardie, C.: Event extraction by answering (almost) natural questions. arXiv preprint arXiv:2004.13625 (2020)\nYiheng Liu et al.:Preprint submitted to Elsevier Page 18 of 21\nSummary of ChatGPT-Related Research\n[15] Freitag,M.,Rei,R.,Mathur,N.,Lo,C.k.,Stewart,C.,Avramidis,E.,Kocmi,T.,Foster,G.,Lavie,A.,Martins,A.F.:Resultsofwmt22metrics\nshared task: Stop using bleu–neural metrics are better and more robust. In: Proceedings of the Seventh Conference on Machine Translation\n(WMT). pp. 46–68 (2022)\n[16] Freitag,M.,Rei,R.,Mathur,N.,Lo,C.k.,Stewart,C.,Avramidis,E.,Kocmi,T.,Foster,G.,Lavie,A.,Martins,A.F.:Resultsofwmt22metrics\nshared task: Stop using bleu–neural metrics are better and more robust. In: Proceedings of the Seventh Conference on Machine Translation\n(WMT). pp. 46–68 (2022)\n[17] Frieder,S.,Pinchetti,L.,Griffiths,R.R.,Salvatori,T.,Lukasiewicz,T.,Petersen,P.C.,Chevalier,A.,Berner,J.:Mathematicalcapabilitiesof\nchatgpt. arXiv preprint arXiv:2301.13867 (2023)\n[18] Fu,Q.,Teng,Z.,Georgaklis,M.,White,J.,Schmidt,D.C.:Nl2cmd:Anupdatedworkflowfornaturallanguagetobashcommandstranslation.\narXiv preprint arXiv:2302.07845 (2023)\n[19] Gao, J., Zhao, H., Yu, C., Xu, R.: Exploring the feasibility of chatgpt for event extraction. arXiv preprint arXiv:2303.03836 (2023)\n[20] Glymour, C., Zhang, K., Spirtes, P.: Review of causal discovery methods based on graphical models. Frontiers in Genetics (2019)\n[21] Gormley, M.R., Yu, M., Dredze, M.: Improved relation extraction with feature-rich compositional embedding models. arXiv preprint\narXiv:1505.02419 (2015)\n[22] Gravitas, S.: Auto-gpt: An autonomous gpt-4 experiment (2023)\n[23] Guo, S., Wang, Y., Li, S., Saeed, N.: Semantic communications with ordered importance using chatgpt. arXiv preprint arXiv:2302.07142\n(2023)\n[24] Hacker,P.:Theeuropeanailiabilitydirectives–critiqueofahalf-heartedapproachandlessonsforthefuture.arXivpreprintarXiv:2211.13960\n(2022)\n[25] Hacker, P., Engel, A., Mauer, M.: Regulating chatgpt and other large generative ai models. arXiv preprint arXiv:2302.02337 (2023)\n[26] Haque, M.U., Dharmadasa, I., Sworna, Z.T., Rajapakse, R.N., Ahmad, H.: \" i think this is the most disruptive technology\": Exploring\nsentiments of chatgpt early adopters using twitter data. arXiv preprint arXiv:2212.05856 (2022)\n[27] Hartmann, J., Schwenzow, J., Witte, M.: The political ideology of conversational ai: Converging evidence on chatgpt’s pro-environmental,\nleft-libertarian orientation. arXiv preprint arXiv:2301.01768 (2023)\n[28] He,J.,Wang,L.,Hu,Y.,Liu,N.,Liu,H.,Xu,X.,Shen,H.T.:Icl-d3ie:In-contextlearningwithdiversedemonstrationsupdatingfordocument\ninformation extraction. arXiv preprint arXiv:2303.05063 (2023)\n[29] Hermann,K.M.,Kocisky,T.,Grefenstette,E.,Espeholt,L.,Kay,W.,Suleyman,M.,Blunsom,P.:Teachingmachinestoreadandcomprehend.\nAdvances in neural information processing systems28 (2015)\n[30] Hoffmann,R.,Zhang,C.,Ling,X.,Zettlemoyer,L.,Weld,D.S.:Knowledge-basedweaksupervisionforinformationextractionofoverlapping\nrelations. In: Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies. pp.\n541–550 (2011)\n[31] Hu, M., Pan, S., Li, Y., Yang, X.: Advancing medical imaging with language models: A journey from n-grams to chatgpt. arXiv preprint\narXiv:2304.04920 (2023)\n[32] Huang,F.,Kwak,H.,An,J.:Ischatgptbetterthanhumanannotators?potentialandlimitationsofchatgptinexplainingimplicithatespeech.\narXiv preprint arXiv:2302.07736 (2023)\n[33] Huang, L.K., Huang, J., Rong, Y., Yang, Q., Wei, Y.: Frustratingly easy transferability estimation pp. 9201–9225 (2022)\n[34] Huang, Z., Chen, K., He, J., Bai, X., Karatzas, D., Lu, S., Jawahar, C.: Icdar2019 competition on scanned receipt ocr and information\nextraction. In: 2019 International Conference on Document Analysis and Recognition (ICDAR). pp. 1516–1520. IEEE (2019)\n[35] Jaume,G.,Ekenel,H.K.,Thiran,J.P.:Funsd:Adatasetforformunderstandinginnoisyscanneddocuments.In:2019InternationalConference\non Document Analysis and Recognition Workshops (ICDARW). vol. 2, pp. 1–6. IEEE (2019)\n[36] Jeblick,K.,Schachtner,B.,Dexl,J.,Mittermeier,A.,Stüber,A.T.,Topalis,J.,Weber,T.,Wesp,P.,Sabel,B.,Ricke,J.,etal.:Chatgptmakes\nmedicine easy to swallow: An exploratory case study on simplified radiology reports. arXiv preprint arXiv:2212.14882 (2022)\n[37] Jiao, W., ZhaopengTu, W.J.t.X.: Is chatgpt a good translator? yes with gpt-4 as the engine\n[38] Kendall, M.G.: A new measure of rank correlation. Biometrika30(1/2), 81–93 (1938)\n[39] Khalil, M., Er, E.: Will chatgpt get you caught? rethinking of plagiarism detection. arXiv preprint arXiv:2302.04335 (2023)\n[40] Kirk, H.R., Vidgen, B., Röttger, P., Hale, S.A.: Personalisation within bounds: A risk taxonomy and policy framework for the alignment of\nlarge language models with personalised feedback. arXiv preprint arXiv:2303.05453 (2023)\n[41] Kocmi, T., Federmann, C.: Large language models are state-of-the-art evaluators of translation quality. arXiv preprint arXiv:2302.14520\n(2023)\n[42] Kocmi, T., Federmann, C., Grundkiewicz, R., Junczys-Dowmunt, M., Matsushita, H., Menezes, A.: To ship or not to ship: An extensive\nevaluation of automatic metrics for machine translation. arXiv preprint arXiv:2107.10821 (2021)\n[43] Kocoń,J.,Cichecki,I.,Kaszyca,O.,Kochanek,M.,Szydło,D.,Baran,J.,Bielaniewicz,J.,Gruza,M.,Janz,A.,Kanclerz,K.,etal.:Chatgpt:\nJack of all trades, master of none. arXiv preprint arXiv:2302.10724 (2023)\n[44] Kortemeyer, G.: Could an artificial-intelligence agent pass an introductory physics course? arXiv preprint arXiv:2301.12127 (2023)\n[45] Krügel, S., Ostermaier, A., Uhl, M.: The moral authority of chatgpt. arXiv preprint arXiv:2301.07098 (2023)\n[46] Kuzman, T., Mozetic, I., Ljubešic, N.: Chatgpt: Beginning of an end of manual linguistic data annotation? use case of automatic genre\nidentification. arXiv e-prints pp. arXiv–2303 (2023)\n[47] Lanzi,P.L.,Loiacono,D.:Chatgptandotherlargelanguagemodelsasevolutionaryenginesforonlineinteractivecollaborativegamedesign.\narXiv preprint arXiv:2303.02155 (2023)\n[48] Lehnert, K.: Ai insights into theoretical physics and the swampland program: A journey through the cosmos with chatgpt. arXiv preprint\narXiv:2301.08155 (2023)\n[49] Levow,G.A.:Thethirdinternationalchineselanguageprocessingbakeoff:Wordsegmentationandnamedentityrecognition.In:Proceedings\nof the Fifth SIGHAN workshop on Chinese language processing. pp. 108–117 (2006)\nYiheng Liu et al.:Preprint submitted to Elsevier Page 19 of 21\nSummary of ChatGPT-Related Research\n[50] Li, S., He, W., Shi, Y., Jiang, W., Liang, H., Jiang, Y., Zhang, Y., Lyu, Y., Zhu, Y.: Duie: A large-scale chinese dataset for information\nextraction. In: Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China,\nOctober 9–14, 2019, Proceedings, Part II 8. pp. 791–800. Springer (2019)\n[51] Li, X., Li, F., Pan, L., Chen, Y., Peng, W., Wang, Q., Lyu, Y., Zhu, Y.: Duee: a large-scale dataset for chinese event extraction in real-world\nscenarios. In: Natural Language Processing and Chinese Computing: 9th CCF International Conference, NLPCC 2020, Zhengzhou, China,\nOctober 14–18, 2020, Proceedings, Part II 9. pp. 534–545. Springer (2020)\n[52] Liao, W., Liu, Z., Dai, H., Xu, S., Wu, Z., Zhang, Y., Huang, X., Zhu, D., Cai, H., Liu, T., et al.: Differentiate chatgpt-generated and human-\nwritten medical texts. arXiv preprint arXiv:2304.11567 (2023)\n[53] Liu, C., Han, Y., Jiang, R., Yuan, X.: Advisor: Automatic visualization answer for natural-language question on tabular data. In: 2021 IEEE\n14th Pacific Visualization Symposium (PacificVis). pp. 11–20. IEEE (2021)\n[54] Liu, D., Chen, Y., Wu, Z.: Digital twin (dt)-cyclegan: Enabling zero-shot sim-to-real transfer of visual grasping models. IEEE Robotics and\nAutomation Letters (2023)\n[55] Liu,Z.,Yu,X.,Zhang,L.,Wu,Z.,Cao,C.,Dai,H.,Zhao,L.,Liu,W.,Shen,D.,Li,Q.,etal.:Deid-gpt:Zero-shotmedicaltextde-identification\nby gpt-4. arXiv preprint arXiv:2303.11032 (2023)\n[56] Liu, Z., Zhong, A., Li, Y., Yang, L., Ju, C., Wu, Z., Ma, C., Shu, P., Chen, C., Kim, S., et al.: Radiology-gpt: A large language model for\nradiology. arXiv preprint arXiv:2306.08666 (2023)\n[57] Lu, Y., Lin, H., Xu, J., Han, X., Tang, J., Li, A., Sun, L., Liao, M., Chen, S.: Text2event: Controllable sequence-to-structure generation for\nend-to-end event extraction. arXiv preprint arXiv:2106.09232 (2021)\n[58] Luan, L., Lin, X., Li, W.: Exploring the cognitive dynamics of artificial intelligence in the post-covid-19 and learning 3.0 era: A case study\nof chatgpt. arXiv preprint arXiv:2302.04818 (2023)\n[59] Luo, Y., Tang, J., Li, G.: nvbench: A large-scale synthesized dataset for cross-domain natural language to visualization task. arXiv preprint\narXiv:2112.12926 (2021)\n[60] Ma, C., Wu, Z., Wang, J., Xu, S., Wei, Y., Liu, Z., Guo, L., Cai, X., Zhang, S., Zhang, T., et al.: Impressiongpt: an iterative optimizing\nframework for radiology report summarization with chatgpt. arXiv preprint arXiv:2304.08448 (2023)\n[61] Maddigan, P., Susnjak, T.: Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language\nmodels. arXiv preprint arXiv:2302.02094 (2023)\n[62] McKee, F., Noever, D.: Chatbots in a botnet world. arXiv preprint arXiv:2212.11126 (2022)\n[63] McKee, F., Noever, D.: Chatbots in a honeypot world. arXiv preprint arXiv:2301.03771 (2023)\n[64] Megahed, F.M., Chen, Y.J., Ferris, J.A., Knoth, S., Jones-Farmer, L.A.: How generative ai models such as chatgpt can be (mis) used in spc\npractice, education, and research? an exploratory study. arXiv preprint arXiv:2302.10916 (2023)\n[65] Michail, A., Konstantinou, S., Clematide, S.: Uzh_clyp at semeval-2023 task 9: Head-first fine-tuning and chatgpt data generation for cross-\nlingual learning in tweet intimacy prediction. arXiv preprint arXiv:2303.01194 (2023)\n[66] Mukaka, M.M.: A guide to appropriate use of correlation coefficient in medical research. Malawi medical journal24(3), 69–71 (2012)\n[67] Narechania,A.,Srinivasan,A.,Stasko,J.:Nl4dv:Atoolkitforgeneratinganalyticspecificationsfordatavisualizationfromnaturallanguage\nqueries. IEEE Transactions on Visualization and Computer Graphics27(2), 369–379 (2020)\n[68] Noever, D., Ciolino, M.: The turing deception. arXiv preprint arXiv:2212.06721 (2022)\n[69] Noever, D., McKee, F.: Numeracy from literacy: Data science as an emergent skill from large language models. arXiv preprint\narXiv:2301.13382 (2023)\n[70] Nov, O., Singh, N., Mann, D.M.: Putting chatgpt’s medical advice to the (turing) test. medRxiv (2023)\n[71] OpenAI: Gpt-4 technical report (2023)\n[72] Ortega-Martín, M., García-Sierra, Ó., Ardoiz, A., Álvarez, J., Armenteros, J.C., Alonso, A.: Linguistic ambiguity analysis in chatgpt. arXiv\npreprint arXiv:2302.06426 (2023)\n[73] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al.: Training\nlanguage models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022)\n[74] Pardos, Z.A., Bhandari, S.: Learning gain differences between chatgpt and human tutor generated algebra hints. arXiv preprint\narXiv:2302.06871 (2023)\n[75] Park, S., Shin, S., Lee, B., Lee, J., Surh, J., Seo, M., Lee, H.: Cord: a consolidated receipt dataset for post-ocr parsing. In: Workshop on\nDocument Intelligence at NeurIPS 2019 (2019)\n[76] Polak, M.P., Morgan, D.: Extracting accurate materials data from research papers with conversational language models and prompt\nengineering–example of chatgpt. arXiv preprint arXiv:2303.05352 (2023)\n[77] Prieto, S.A., Mengiste, E.T., de Soto, B.G.: Investigating the use of ChatGPT for the scheduling of construction projects. Buildings13(4),\n857 (mar 2023). https://doi.org/10.3390/buildings13040857,https://doi.org/10.3390%2Fbuildings13040857\n[78] Qin,C.,Zhang,A.,Zhang,Z.,Chen,J.,Yasunaga,M.,Yang,D.:Ischatgptageneral-purposenaturallanguageprocessingtasksolver?arXiv\npreprint arXiv:2302.06476 (2023)\n[79] Radford,A.,Narasimhan,K.,Salimans,T.,Sutskever,I.,etal.:Improvinglanguageunderstandingbygenerativepre-training.OpenAI(2018)\n[80] Radford,A.,Wu,J.,Amodei,D.,Amodei,D.,Clark,J.,Brundage,M.,Sutskever,I.:Betterlanguagemodelsandtheirimplications.OpenAI\nBlog https://openai. com/blog/better-language-models1(2) (2019)\n[81] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et al.: Language models are unsupervised multitask learners. OpenAI\nblog 1(8), 9 (2019)\n[82] Shakarian,P.,Koyyalamudi,A.,Ngu,N.,Mareedu,L.:Anindependentevaluationofchatgptonmathematicalwordproblems(mwp).arXiv\npreprint arXiv:2302.13814 (2023)\n[83] Sobania, D., Briesch, M., Hanna, C., Petke, J.: An analysis of the automatic bug fixing performance of chatgpt. arXiv preprint\narXiv:2301.08653 (2023)\nYiheng Liu et al.:Preprint submitted to Elsevier Page 20 of 21\nSummary of ChatGPT-Related Research\n[84] Subhash, V.: Can large language models change user preference adversarially? arXiv preprint arXiv:2302.10291 (2023)\n[85] Susnjak, T.: Chatgpt: The end of online exam integrity? arXiv preprint arXiv:2212.09292 (2022)\n[86] Susnjak,T.:Applyingbertandchatgptforsentimentanalysisoflymediseaseinscientificliterature.arXivpreprintarXiv:2302.06474(2023)\n[87] Takanobu, R., Zhang, T., Liu, J., Huang, M.: A hierarchical framework for relation extraction with reinforcement learning. In: Proceedings\nof the AAAI conference on artificial intelligence. vol. 33, pp. 7072–7079 (2019)\n[88] Tang, R., Han, X., Jiang, X., Hu, X.: Does synthetic data generation of llms help clinical text mining? arXiv preprint arXiv:2303.04360\n(2023)\n[89] Tang,Z.,Kejriwal,M.:Apilotevaluationofchatgptanddall-e2ondecisionmakingandspatialreasoning.arXivpreprintarXiv:2302.09068\n(2023)\n[90] Treude, C.: Navigating complexity in software engineering: A prototype for comparing gpt-n solutions. arXiv preprint arXiv:2301.12169\n(2023)\n[91] Tu, R., Ma, C., Zhang, C.: Causal-discovery performance of chatgpt in the context of neuropathic pain diagnosis. arXiv preprint\narXiv:2301.13819 (2023)\n[92] Wang, J., Liang, Y., Meng, F., Li, Z., Qu, J., Zhou, J.: Cross-lingual summarization via chatgpt. arXiv preprint arXiv:2302.14229 (2023)\n[93] Wang, J., Liang, Y., Meng, F., Shi, H., Li, Z., Xu, J., Qu, J., Zhou, J.: Is chatgpt a good nlg evaluator? a preliminary study. arXiv preprint\narXiv:2303.04048 (2023)\n[94] Wang, S., Zhao, Z., Ouyang, X., Wang, Q., Shen, D.: Chatcad: Interactive computer-aided diagnosis on medical image using large language\nmodels. arXiv preprint arXiv:2302.07257 (2023)\n[95] Wang,S.,Scells,H.,Koopman,B.,Zuccon,G.:Canchatgptwriteagoodbooleanqueryforsystematicreviewliteraturesearch?arXivpreprint\narXiv:2302.03495 (2023)\n[96] Wang, Z., Shang, J., Liu, L., Lu, L., Liu, J., Han, J.: Crossweigh: Training named entity tagger from imperfect annotations. arXiv preprint\narXiv:1909.01441 (2019)\n[97] Wei, X., Cui, X., Cheng, N., Wang, X., Zhang, X., Huang, S., Xie, P., Xu, J., Chen, Y., Zhang, M., et al.: Zero-shot information extraction\nvia chatting with chatgpt. arXiv preprint arXiv:2302.10205 (2023)\n[98] West, C.G.: Ai and the fci: Can chatgpt project an understanding of introductory physics? arXiv preprint arXiv:2303.01067 (2023)\n[99] White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., Schmidt, D.C.: A prompt pattern catalog to\nenhance prompt engineering with chatgpt. arXiv preprint arXiv:2302.11382 (2023)\n[100] de Winter, J.: Can chatgpt pass high school exams on english language comprehension? (2023)\n[101] Wu, C., Yin, S., Qi, W., Wang, X., Tang, Z., Duan, N.: Visual chatgpt: Talking, drawing and editing with visual foundation models. arXiv\npreprint arXiv:2303.04671 (2023)\n[102] Xia, C.S., Zhang, L.: Conversational automated program repair. arXiv preprint arXiv:2301.13246 (2023)\n[103] Yang,X.,Li,Y.,Zhang,X.,Chen,H.,Cheng,W.:Exploringthelimitsofchatgptforqueryoraspect-basedtextsummarization.arXivpreprint\narXiv:2302.08081 (2023)\n[104] Yeadon, W., Inyang, O.O., Mizouri, A., Peach, A., Testrow, C.: The death of the short-form physics essay in the coming ai revolution. arXiv\npreprint arXiv:2212.11661 (2022)\n[105] Zar, J.H.: Spearman rank correlation. Encyclopedia of biostatistics7 (2005)\n[106] Zhang, B., Ding, D., Jing, L.: How would stance detection techniques evolve after the launch of chatgpt? arXiv preprint arXiv:2212.14548\n(2022)\n[107] Zhang, X., Chowdhury, R.R., Hong, D., Gupta, R.K., Shang, J.: Modeling label semantics improves activity recognition. arXiv preprint\narXiv:2301.03462 (2023)\n[108] Zhao, L., Zhang, L., Wu, Z., Chen, Y., Dai, H., Yu, X., Liu, Z., Zhang, T., Hu, X., Jiang, X., et al.: When brain-inspired ai meets agi. arXiv\npreprint arXiv:2303.15935 (2023)\n[109] Zheng,O.,Abdel-Aty,M.,Wang,D.,Wang,Z.,Ding,S.:Chatgptisonthehorizon:Couldalargelanguagemodelbeallweneedforintelligent\ntransportation? arXiv preprint arXiv:2303.05382 (2023)\n[110] Zhong,Q.,Ding,L.,Liu,J.,Du,B.,Tao,D.:Canchatgptunderstandtoo?acomparativestudyonchatgptandfine-tunedbert.arXivpreprint\narXiv:2302.10198 (2023)\n[111] Zhou, C., Qiu, C., Acuna, D.E.: Paraphrase identification with deep learning: A review of datasets and methods. arXiv preprint\narXiv:2212.06933 (2022)\n[112] Zhuo, T.Y., Huang, Y., Chen, C., Xing, Z.: Exploring ai ethics of chatgpt: A diagnostic analysis. arXiv preprint arXiv:2301.12867 (2023)\nYiheng Liu et al.:Preprint submitted to Elsevier Page 21 of 21",
  "topic": "Adaptability",
  "concepts": [
    {
      "name": "Adaptability",
      "score": 0.6656554937362671
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.6066923141479492
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.5898743867874146
    },
    {
      "name": "Data science",
      "score": 0.5203532576560974
    },
    {
      "name": "Computer science",
      "score": 0.5102841854095459
    },
    {
      "name": "Representation (politics)",
      "score": 0.5097958445549011
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4481002986431122
    },
    {
      "name": "Field (mathematics)",
      "score": 0.4466865658760071
    },
    {
      "name": "Artificial intelligence",
      "score": 0.23536163568496704
    },
    {
      "name": "Psychology",
      "score": 0.2300451397895813
    },
    {
      "name": "Political science",
      "score": 0.20572581887245178
    },
    {
      "name": "Geography",
      "score": 0.14610445499420166
    },
    {
      "name": "Ecology",
      "score": 0.12025013566017151
    },
    {
      "name": "Mathematics",
      "score": 0.09237578511238098
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Cartography",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}