{
  "title": "Democratizing protein language models with parameter-efficient fine-tuning",
  "url": "https://openalex.org/W4399849668",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3194097210",
      "name": "Samuel Sledzieski",
      "affiliations": [
        "Microsoft (United States)",
        "Massachusetts Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2004269926",
      "name": "Meghana Kshirsagar",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2472350544",
      "name": "Minkyung Baek",
      "affiliations": [
        "Seoul National University"
      ]
    },
    {
      "id": "https://openalex.org/A1995994163",
      "name": "Rahul Dodhia",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2183540531",
      "name": "Juan Lavista Ferres",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2315546843",
      "name": "Bonnie Berger",
      "affiliations": [
        "Massachusetts Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3166142427",
    "https://openalex.org/W4388024559",
    "https://openalex.org/W4327550249",
    "https://openalex.org/W3119866685",
    "https://openalex.org/W4205991051",
    "https://openalex.org/W4394567450",
    "https://openalex.org/W4318071656",
    "https://openalex.org/W4322766882",
    "https://openalex.org/W2913946806",
    "https://openalex.org/W3194093337",
    "https://openalex.org/W2957436444",
    "https://openalex.org/W3199468887",
    "https://openalex.org/W4283716699",
    "https://openalex.org/W4392500220",
    "https://openalex.org/W2980789587",
    "https://openalex.org/W3177500196",
    "https://openalex.org/W3146944767",
    "https://openalex.org/W4297243391",
    "https://openalex.org/W4367602258",
    "https://openalex.org/W4378838672",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W3177828909",
    "https://openalex.org/W3186179742",
    "https://openalex.org/W4286669150",
    "https://openalex.org/W3202105508",
    "https://openalex.org/W2128674962",
    "https://openalex.org/W4380272022",
    "https://openalex.org/W4362508790",
    "https://openalex.org/W4383216409",
    "https://openalex.org/W4226343290",
    "https://openalex.org/W4317802023",
    "https://openalex.org/W4388007030",
    "https://openalex.org/W3015964336",
    "https://openalex.org/W4391652655",
    "https://openalex.org/W4395674144",
    "https://openalex.org/W2058601882",
    "https://openalex.org/W4392351837",
    "https://openalex.org/W4392559428",
    "https://openalex.org/W4367040840",
    "https://openalex.org/W4379932151",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W2008840001",
    "https://openalex.org/W2130479394",
    "https://openalex.org/W2950954328",
    "https://openalex.org/W4391554849",
    "https://openalex.org/W4388656332",
    "https://openalex.org/W4391563878",
    "https://openalex.org/W4287391717",
    "https://openalex.org/W4394579747",
    "https://openalex.org/W4392168151"
  ],
  "abstract": "Proteomics has been revolutionized by large protein language models (PLMs), which learn unsupervised representations from large corpora of sequences. These models are typically fine-tuned in a supervised setting to adapt the model to specific downstream tasks. However, the computational and memory footprint of fine-tuning (FT) large PLMs presents a barrier for many research groups with limited computational resources. Natural language processing has seen a similar explosion in the size of models, where these challenges have been addressed by methods for parameter-efficient fine-tuning (PEFT). In this work, we introduce this paradigm to proteomics through leveraging the parameter-efficient method LoRA and training new models for two important tasks: predicting proteinâ€“protein interactions (PPIs) and predicting the symmetry of homooligomer quaternary structures. We show that these approaches are competitive with traditional FT while requiring reduced memory and substantially fewer parameters. We additionally show that for the PPI prediction task, training only the classification head also remains competitive with full FT, using five orders of magnitude fewer parameters, and that each of these methods outperform state-of-the-art PPI prediction methods with substantially reduced compute. We further perform a comprehensive evaluation of the hyperparameter space, demonstrate that PEFT of PLMs is robust to variations in these hyperparameters, and elucidate where best practices for PEFT in proteomics differ from those in natural language processing. All our model adaptation and evaluation code is available open-source at https://github.com/microsoft/peft_proteomics . Thus, we provide a blueprint to democratize the power of PLM adaptation to groups with limited computational resources.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7838706970214844
    },
    {
      "name": "Hyperparameter",
      "score": 0.649409294128418
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5253127217292786
    },
    {
      "name": "Machine learning",
      "score": 0.5208771228790283
    },
    {
      "name": "Heuristics",
      "score": 0.4421067237854004
    },
    {
      "name": "Language model",
      "score": 0.4354330599308014
    },
    {
      "name": "Source code",
      "score": 0.4248090386390686
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.4232596755027771
    },
    {
      "name": "Programming language",
      "score": 0.08684340119361877
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I63966007",
      "name": "Massachusetts Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I139264467",
      "name": "Seoul National University",
      "country": "KR"
    }
  ],
  "cited_by": 51
}