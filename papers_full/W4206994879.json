{
  "title": "Transformer Model for Remaining Useful Life Prediction of Aeroengine",
  "url": "https://openalex.org/W4206994879",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2097871721",
      "name": "Qinghua Li",
      "affiliations": [
        "Guangxi University"
      ]
    },
    {
      "id": "https://openalex.org/A2100299964",
      "name": "Ying Yang",
      "affiliations": [
        "Guangxi University"
      ]
    },
    {
      "id": "https://openalex.org/A2097871721",
      "name": "Qinghua Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2100299964",
      "name": "Ying Yang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3045935064",
    "https://openalex.org/W3006585575",
    "https://openalex.org/W2914488306",
    "https://openalex.org/W2975851144",
    "https://openalex.org/W2985380938",
    "https://openalex.org/W3012153518",
    "https://openalex.org/W3021048621",
    "https://openalex.org/W3014146531",
    "https://openalex.org/W6772050067",
    "https://openalex.org/W2997783880"
  ],
  "abstract": "Abstract Accurate aeroengine remaining useful life (RUL) prediction plays a vital role in ensuring safe operation and reducing maintenance losses. In order to improve the accuracy of aeroengine RUL prediction, an aeroengine RUL prediction method based on the Transformer model is proposed, which gives greater weight to the characteristics of important time steps through self attention mechanism, and solves the memory degradation problem caused by too long sequence in engine RUL prediction, and excavates the complex mapping relationship between input features and aeroengine RUL. Experiments on the C-MAPSS data set show that the Transformer model can better predict the aeroengine RUL based on the aeroengine degradation data. Compared with the long short term memory network model, the root mean square error of the two sub data sets is reduced by 6.57% and 5.63% respectively.",
  "full_text": "Journal of Physics:\nConference Series\n       \nPAPER • OPEN ACCESS\nTransformer Model for Remaining Useful Life\nPrediction of Aeroengine\nTo cite this article: Qinghua Li and Ying Yang 2022 J. Phys.: Conf. Ser. 2171 012072\n \nView the article online for updates and enhancements.\nYou may also like\nAutomatic damage recognition and\nsegmentation in aeroengine borescope\nvideos fusing YOLOX and Mask\nDonghuan Wang and Hong Xiao\n-\nMulti-head self-attention bidirectional\ngated recurrent unit for end-to-end\nremaining useful life prediction of\nmechanical equipment\nChangchang Che, Huawei Wang, Xiaomei\nNi et al.\n-\nAeroengine intelligent gas path simulation\nand diagnosis based on feature fusion and\nmeta learning\nZepeng Wang, Jinghui Xu, Xizhen Wang\net al.\n-\n \nThis content was downloaded from IP address 91.100.61.210 on 05/11/2025 at 19:05\nContent from this work may be used under the terms of the Creative Commons Attribution 3.0 licence. Any further distribution\nof this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI.\nPublished under licence by IOP Publishing Ltd\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n1\nTransformer Model for Remaining Useful Life Prediction of\nAeroengine\nQinghua Li1, Ying Yang1,*\n1School of Computer and Electronic Information, Guangxi University, No.100,U\nniversity East Road, Nanning, Guangxi, China, 530004\n*email: yingy2004@126.com\nAbstract. Accurate aeroengine remaining useful life (RUL) prediction plays a vital role in\nensuring safe operation and reducing maintenance losses. In order to improve the accuracy of\naeroengine RUL prediction, an aeroengine RUL prediction method based on the Transformer\nmodel is proposed, which gives greater weight to the characteristics of important time steps\nthrough self attention mechanism, and solves the memory degradation problem caused by too\nlong sequence in engine RUL prediction, and excavates the complex mapping relationship\nbetween input features and aeroengine RUL. Experiments on the C-MAPSS data set show that\nthe Transformer model can better predict the aeroengine RUL based on the aeroengine\ndegradation data. Compared with the long short term memory network model, the root mean\nsquare error of the two sub data sets is reduced by 6.57% and 5.63% respectively.\n1. Introduction\nAeroengine is the core component of aviation aircraft. Its performance and quality directly affect the\nsafety and reliability of aviation equipment. However, its internal structure is complex and the\nworking environment is harsh. The various parts of the aeroengine will degrade to varying degrees. In\norder to avoid aeroengine failure caused by insufficient maintenance requires accurate and timely\nprediction of the remaining useful life(RUL) of the aeroengine, and a suitable maintenance plan[1].\nAccording to the existing research, aeroengine RUL prediction methods are mainly divided into\ntwo types: model-based methods and data-driven methods[2]. The model-based prediction method is\nto study the internal mechanism of equipment failure and establish a physical failure model to predict\nthe RUL of the equipment. Due to the complex structure of aerospace engines and various failure\nmechanisms, it is complicated to establish an accurate aeroengine model, and the prediction accuracy\nis affected, so this method has limitations. The data-driven method refers to the use of mathematical\nstatistics and machine learning methods that can bypass the difficulties as mentioned above[3], and\ndirectly use the mapping relationship between aeroengine condition monitoring data and aeroengine\nRUL for life prediction.\nIn the data-driven method[4-6], because the aeroengine RUL prediction is essentially a time series\nforecasting problem, and the Recurrent Neural Network (RNN) is good at capturing time information\nand has apparent advantages in time series forecasting, long and short-term memory Network(LSTM)\nis a type of RNN, which is widely used in the field of RUL prediction[7]. Nevertheless, LSTM still\nhas shortcomings in RUL prediction. The output of LSTM depends on the output at the previous\nmoment and the state at the last moment. The characteristics of the previous moment are lost along\nwith long-term transmission, resulting in the information characteristics of the last moment that have a\ngreat impact on RUL. And the contribution of information features at different moments to the final\nRUL prediction is different, which affects the prediction accuracy.\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n2\nSo as to make up for the shortcomings of the existing methods, this paper presents an aeroengine\nresidual life prediction method based on transformer model, which uses its core self-attention\nmechanism to acquire the dependencies between any features in the input sequence[8], and is not\naffected by the distance between features. Influence, thereby improving the accuracy of aeroengine\nRUL prediction[9]. And it was applied to the C-MAPSS public data collection to realize the prediction\nof the RUL of aeroengine, and achieved the expected results, providing new ideas for accurate and\nstable prediction of aeroengine RUL.\n2. RUL prediction method based on Transformer\nThe Transformer is a neural network based on the attention mechanism, which has achieved good\nresults in NLP, CV and other fields. When predicting RUL, the attention mechanism can also make the\nneural network pay more attention to essential time steps and features[10]. The Transformer model is a\ndeep neural network model that does not use RNN but uses the attention mechanism to build. Its\nunique structure limits its direct application in the RUL prediction field. In this paper, improvements\nare made to the Transformer model for aeroengine RUL prediction scenario.\nFig. 1 Aeroengine RUL prediction model based on Transformer\nThe structure of aeroengine RUL prediction neural network based on transformer is shown in\nFigure 1. Its core lies in the structure of its encoder and decoder. Both the encoder and decoder are\nstacked with N layers of the same layer. Each layer of the encoder contains two sub-layers: the\nmulti-headed self-attention mechanism and the feed-forward neural network. Each layer of the\ndecoder includes three sub-layers: masked multi-head self-attention mechanism, decoder multi-head\nattention mechanism, and feed-forward neural network.\nThe encoder first encodes the input aeroengine sensor data by position encoding, allowing the\nnetwork to identify different cycles in the data, and then calculates them in multiple self-attention\nblocks to learn the correlation within each engine sensor feature sequence, filter out a small amount of\nimportant information, and assign greater weight to important time step features, so that the model can\nsolve long-distance time steps The problem of losing feature weight.\nThe multi-head attention mechanism consists of a stack of multiple attention networks. The\ncalculation formula (1) of the attention weight of a single attention network is:\n(1)\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n3\nWhere: Q, K and V are query, key and value matrix respectively; d is the scaling factor. In the\nmodel proposed in this paper, Q, K, and V are all aeroengine sensor data. First, the index matrix Q and\nthe key matrix K are dot-producted.Normalize with SoftMax to calculate the weight coefficient, and\nthen perform a weighted summation on the value matrix V according to the weight coefficient, So that\nthe model focuses on the important information of the sensor data.\nIn addition, to make the model learn higher-level timing features in Aeroengine sensor data, the\nmulti-head attention mechanism is used to multiply Q, K, and V with different weight matrices to\nobtain different attention heads. The information of different positions is learned separately, and then\nmultiple attention heads are spliced. Get the matrix of the multi-head attention. The calculation\nformula (2)-(3) is:\n(2)\n(3)\nWhere: ℎ is the i-th attention head; \n、\n、\n and  are different network weight\nmatrices; k is the total attention head number, and the Concat function is used to splice the output\nvalue calculated by each attention head.\nThen the model inputs the aeroengine RUL label information into the occlusion multi-head\nself-attention mechanism in the decoder. Through the occlusion operation, the model cannot learn the\nlabel data of future time steps.The model can comprehensively learn the dependence between sensor\ndata and label data at each time step, and effectively use the data for Aeroengine RUL prediction.\nFinally, the dimension of the model is reduced by fully connected neural network to obtain the RUL\nprediction of the engine.\nCompared with LSTM, the Transformer model uses an attention mechanism, which not only solves\nthe problem of long-distance weakening of time series feature information, but also avoids the use of\ntime step loop structure and speeds up the model training process . In the meantime, compared with\nthe LSTM model, the model parameters are also greatly reduced.\n3. Experiment Evaluation\n3.1. C-MAPSS Date Set\nThe experiment uses the C-MAPSS data set obtained on the aeroengine simulation system proposed\nby NASA to assess the performance of the aeroengine RUL prediction method. This datasets describes\nthe degradation process of aeroengine and contains four sub-data sets, including different operating\nconditions and failure types. Each sub-data contains 21 sensor measurement values, such as the total\ntemperature of the fan inlet, fan speed, turbine air-conditioning flow, etc., in addition to 3 operating\ncondition measurement values, such as flight altitude, Mach number, etc., and the degradation of\ndifferent engines from normal operation to failure under different working conditions and failure\nmodes is simulated. The training datasets provided the complete timing data of the aeroengine from\nnormal operation to failure. At the same time, the test set is a piece of data randomly selected from the\nengine operation to failure. Different working conditions and failure modes will have different effects\non the degradation process of the engine. For the sake of simplicity of the experiment, this paper only\nuses the data subsets FD001 and FD003 with fewer working conditions and failure models for\nexperiments.\n3.2. Evaluation\nThe performance of model prediction RUL is usually quantitatively measured by evaluation standards.\nIn the RUL prediction problem in this paper, when the predicted value is overestimated, it will\nmisjudge the engine maintenance strategy, which will cause economic losses and even cause safety\nproblems in practical applications. In the evaluation process of the model, it is necessary to impose\nmore penalties on the overestimated predicted value to generate more negative effects in the\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n4\nevaluation standard. Here, the scoring function score is used to evaluate the model, and the above\nrequirements are met through the characteristics of its asymmetric function. so this paper take the root\nmean square error(RMSE) and the Score function to measure degree of model prediction performance.\nTheir definitions are shown in formulas (4)-(5):\n(4)\n(5)\nIn the two formulas,  is the actual RUL value of aeroengine, \u0000 is the aeroengine predicted\nRUL value given by the model, and N is the number of data.\n3.3. Remaining use life prediction result\nBefore training the RUL prediction model, first preprocess the aeroengine degradation process data.\nThe data contains 21 sensors. Some of the sensor data remain basically constant during the\ndegradation process and have no impact on the aeroengine degradation. Therefore, they are excluded\nfrom the data. And different sensor data has different physical characteristic values, and there are huge\ndifferences in the data size range. Direct use for model training will reduce the effect of neural\nnetwork training. Normalization processing is required before the data is input to the prediction model,\nso that each sensor data Scale to between [0,1] to eliminate the dimensional influence between\nfeatures.\nDuring model training process, the datasets are split into train set and validation set in the light of\nthe ratio of 9:1. After sliding window processing, it is input into the model. The RMSE is used as loss\nfunction, and that earlystop mechanism is used to prevent the model from overfitting. If the error of\nthe validation set is within 10 Epoch, the training will stop immediately if it is not optimized. After the\ntraining is completed, the After the training, the transformer network is applied to predict the\naeroengine RUL of the test sets of two aeroengine FD001 and FD003. The RUL prediction results of\nthe space engine are shown in Figure 2 and Figure 3.\nFig. 2 Actual RUL and predicted RUL on FD001 test datasets\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n5\nFig. 3 Actual RUL and predicted RUL on FD003 test datasets\nThe aeroengine predicted RUL on the two test datasets FD001 and FD003 is shown in Figure 2 and\nFigure 3, the actual value of the aeroengine RUL is not much different from the predicted value, which\nshows that the improved Transformer model can effectively capture the characteristic information in\nthe time series characteristics of the degradation process, and can make accurate predictions for the\nRUL of aeroengine.\nAs mentioned earlier, the improved Transformer model has advantages in long-term sequence\nprediction compared to the recurrent neural network. For the sake of intuitively reflecting the RUL\nprediction performance of the model, a performance comparison experiment with the LSTM neural\nnetwork prediction model is carried out. The following table indicates the comparison results of the\nRUL prediction capability of the improved Transformer model and the LSTM model on the FD001\nand FD003 test datasets.\nTab. 1 The experimental results with two models\nNetWork FD001 FD003\nRMSE Score RMSE Score\nLSTM 32.182 1782 43.113 2838\nTransformer 30.067 1543 40.682 2467\nTable 1 shown that the improved Transformer model on the two data sets reduces the root mean\nsquare error by 6.57% and 5.63% respectively, Compared with the LSTM model. Apart from this, the\nimproved Transformer model in the Score function angle prediction error is also lower than the LSTM\nmodel.When the Score function is smaller, the prediction results provided by the model are closer to\nthe real results, and the possibility of overestimation of the prediction results is smaller, which is\nparticularly important in practical use, which can make the maintenance plan of the engine more\nreasonable. Reasons for the above results is the improved Transformer model can capture the deep\ninformation in the timing features, thereby extracting more effective and complete The time series\ncharacteristics of, improve the accuracy of predicting the RUL of aeroengine, so the method proposed\nin this paper has a good prediction effect on both datasets.The performance of the model on the data\nset FD003 is slightly poor, because the engine working conditions of the data set FD003 are more\ncomplex than those on the data set FD001, and there are more fault modes on the data set FD003,\nwhich requires a larger data set for model training to improve the performance of the model.\n4. Conclusion\nAccurately predicting the remaining useful life of aeroengine is of great significance for formulating a\nreasonable maintenance strategy and reducing maintenance costs. How to estimate the RUL of the\naeroengine to assist in maintenance has become a concern. This paper presents a prediction method of\naeroengine RUL based on the transformer model. Take the aeroengine sensor data as input, and use the\nTransformer-based model to predict the aeroengine RUL. Experiments have proved that in the same\nICCBDAI-2021\nJournal of Physics: Conference Series 2171 (2022) 012072\nIOP Publishing\ndoi:10.1088/1742-6596/2171/1/012072\n6\nsituation, the prediction model in this paper has achieved better experimental results than the LSTM\nprediction model. Because of its powerful self attention mechanism, it can better dig out the complex\nmapping relationship between sensor features and space aeroengine RUL, and more accurately predict\nthat the aeroengine RUL has a certain degree of accuracy. It provides feasible support for the effective\nmaintenance of aeroengine.\nAcknowledgments\nThe research work in this paper are funded. by Guangxi’s innovation-driven development \"‘Internet +’\nEngine Intelligent Manufacturing Platform R&D and Industrialization Application Demonstration\"\n(Guike AA20302002), and Guangxi Science and Technology Base and Talent Special\n\"China-Cambodia Intelligent Manufacturing Technology Joint Laboratory Construction\" (Guike\nAD21076002)\nReferences\n[1] Montero J, Juan J, Schwartz S, et al. 2020 Towards multi-model approaches to predictive\nmaintenance: A systematic literature survey on diagnostics and prognostics Journal of\nManufacturing Systems 56 pp 339-358\n[2] Chen Z 2021 Machine remaining useful life prediction via an attention based deep learning\napproach IEEE Transactions on Industrial Electronics 68(3) pp 2521-2531\n[3] Cheng Y, Zhu H, Wu J, et al 2019 Machine health monitoring using adaptive kernel spectral\nclustering and deep long short-term memory recurrent neural networks IEEE Transactions\non Industrial Informatics 15(2) pp 987-997\n[4] Wang C, Lu N, Cheng Y 2021 A Data-Driven Aero-Engine Degradation Prognostic Strategy\nIEEE transactions on cybernetics 53(1) pp 1531-1541\n[5] Wang B, Lei Y, Yan T, et al 2020 Recurrent convolutional neural net-work: A new framework\nfor remaining useful life prediction of machinery Neurocomputing 379 pp 117-129\n[6] Liu X, Liu L S, Liu D T, et al 2020 A Hybrid Method of Remaining Useful Life Prediction for\nAircraft Auxiliary Power Unit IEEE Sensors Journal 20(14) pp 7848-7858\n[7] Ma M, Mao Z 2021 Deep-Convolution-Based LSTM Network for Re-maining Useful Life\nPrediction IEEE Transactions on Indust-rial Informatics 17(3) pp 1658-1667\n[8] Liu H, Liu Z, Jia W, et al 2021 Remaining useful life prediction using a novel feature-attention\nbased end-to-end Approach IEEE Transactions on Industrial Informatics 17(2) pp 1197-1207\n[9] Jiang J, Lee J, Zeng Y 2020 Time series multiple channel convolutional neural network with\nattention- based long short-term memory for predicting bearing remaining useful life Sensors\n20 (1) pp 1-166\n[10] Liu H, Liu Z, Jia W, et al 2021 Remaining useful life prediction using a novel feature-attention\nbased end-to-end Approach IEEE Transactions on Industrial Informatics 17(2) pp 1197-1207",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.719529926776886
    },
    {
      "name": "Aero engine",
      "score": 0.5613702535629272
    },
    {
      "name": "Long short term memory",
      "score": 0.4994373321533203
    },
    {
      "name": "Reliability engineering",
      "score": 0.48834797739982605
    },
    {
      "name": "Engineering",
      "score": 0.4305911064147949
    },
    {
      "name": "Computer science",
      "score": 0.3631730079650879
    },
    {
      "name": "Machine learning",
      "score": 0.2524438202381134
    },
    {
      "name": "Artificial neural network",
      "score": 0.19724881649017334
    },
    {
      "name": "Voltage",
      "score": 0.0968484878540039
    },
    {
      "name": "Electrical engineering",
      "score": 0.07973885536193848
    },
    {
      "name": "Mechanical engineering",
      "score": 0.06212133169174194
    },
    {
      "name": "Recurrent neural network",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I150807315",
      "name": "Guangxi University",
      "country": "CN"
    }
  ]
}