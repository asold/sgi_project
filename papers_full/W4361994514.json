{
  "title": "Large Fourth-Generation Language Models as a New Tool in Scientific Research",
  "url": "https://openalex.org/W4361994514",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2964601198",
      "name": "Alexey Bragin",
      "affiliations": [
        "Central Economics and Mathematics Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6640035786",
    "https://openalex.org/W4313479734",
    "https://openalex.org/W4319301446",
    "https://openalex.org/W3011574394",
    "https://openalex.org/W4317910584",
    "https://openalex.org/W4312377687",
    "https://openalex.org/W4319227726",
    "https://openalex.org/W3124528386",
    "https://openalex.org/W3125358881",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W4319773014",
    "https://openalex.org/W2023217192"
  ],
  "abstract": "In this study, the latest achievements in the field of deep learning, including convolutional, recurrent, and graph neural networks and attention mechanisms, as well as their contribution to the development of pre-trained language models, are examined. A brief literature review is presented, discussing the use of pre-trained language models in scientific research and education in various fields of science. Experiments are conducted on the application of ChatGPT in the field of economics. The authors present an analysis of the advantages and limitations associated with ChatGPT, providing recommendations for its use in scientific work. Additionally, the article demonstrates the ability of ChatGPT to generate C# programs for agent-based models (ABM) and computable general equilibrium (CGE) models, highlighting its potential for interdisciplinary research and practical applications in economics and computational modeling.",
  "full_text": "Искусственные общества. 2013-2025\nISSN 2077-5180\nURL - http://artsoc.jes.su\nВсе права защищены\nВыпуск 1 Том 18. 2023\nВыпуск 1 Том 18 - 2023\nБольшие языковые модели четвёртого поколения как\nновый инструмент в научной работе\nБрагин Алексей Владимирович\nЦентральный экономико-математический институт Российской академии наук\nРоссийская Федерация, Москва\nБахтизин Альберт Рауфович\nЦентральный экономико-математический институт Российской академии наук\nРоссийская Федерация, Москва\nМакаров Валерий Леонидович\nНаучный руководитель Центрального экономико-математического института\nРоссийской академии наук\nРоссийская Федерация, Москва\nАннотация\nВ данном исследовании рассматриваются новейшие достижения в области\nглубокого обучения, включая сверточные, рекуррентные и графовые нейронные\nсети и механизмы внимания, а также их вклад в развитие предварительно-\nобученных языковых моделей. Представлен краткий обзор литературы, в котором\nобсуждается использование предварительно обученных языковых моделей в\nнаучных исследованиях и образовании в различных областях науки. Проведены\nэксперименты по применению ChatGPT в области экономики. Авторы\nпредставляют анализ преимуществ и ограничений, связанных с ChatGPT,\nпредоставляя рекомендации для его использования  в научной работе. Кроме того,\nстатья демонстрирует способность ChatGPT генерировать программы на C# для\nагент-ориентированных моделей (ABM) и расчётных моделей общего равновесия\n(CGE), подчеркивая его потенциал для междисциплинарных исследований и\nпрактических приложений в экономике и вычислительном моделировании.\nКлючевые слова: языковые модели, chatgpt, llm, агент-ориентированное\nмоделирование\n\n1\n2\n3\n4\n5\nДата публикации: 31.03.2023\nСсылка для цитирования:\nБрагин А. В., Бахтизин А. Р., Макаров В. Л. Большие языковые модели четвёртого\nпоколения как новый инструмент в научной работе // Искусственные общества.\n2023. T. 18. Выпуск 1. URL: https://artsoc.jes.su/s207751800025046-9-1/ DOI:\n10.18254/S207751800025046-9\nВведение\nРазвитие глубокого обучения привело к широкому использованию различных\nнейронных сетей для решения задач обработки естественного языка (NLP),\nвключая свёрточные нейронные сети (CNN), рекуррентные нейронные сети\n(RNN), нейронные сети на основе графов (GNN) и механизмы внимания [12].\nКлючевым преимуществом этих нейронных моделей является их способность в\nнекотором роде упростить разработку модели. Традиционные не-нейронные\nподходы к задаче NLP, как правило, в значительной степени зависят от\nдискретных, вручную создаваемых функций, в то время как нейросетевые методы\nобычно используют низкоразмерные и плотные векторы (также называемые\nраспределенным представлением) для неявного представления синтаксических\nили семантических аспектов языка.\nБольшое количество исследований проведённых за последнее время\nпоказало, что предварительно обученные (pre-trained models – PTM) модели на\nбольших корпусах текстов могут обучиться универсальным языковым\nпредставлениям, которые полезны для последующих задач NLP и позволяют\nизбежать обучения новой модели с нуля. С развитием вычислительной мощности,\nпоявлением глубоких моделей и постоянным совершенствованием навыков\nобучения архитектура PTM продвинулась от поверхностной к глубокой.\nВ статье рассматриваются история разработки и текущее состояние\nбольших языковых моделей, приводятся примеры использования таких моделей в\nработе учёных и исследователей в области экономики, а также проведения\nимитационного моделирования.\nСтатья организована следующим образом. Сначала рассматриваются\nсуществующие на данный момент поколения предварительно обученных моделей\nPTM. В основной части статьи рассматриваются теоретические основы\nреализации генеративных предварительно-обученных больших языковых моделей\nна архитектуре трансформер и даются примеры использования реализации такой\nмодели в научной и практической работе. В завершение приводится анализ\nсложившейся ситуации и даются предположения по дальнейшему развитию таких\nмоделей.\nПоколения предварительно обученных моделей\nПервое поколение PTM стремилось получить векторное представление слов.\nПоскольку эти модели не нужны для последующих задач, они обычно очень\n6\n7\n8\nнеглубоки с точки зрения вычислительной эффективности. Примерами таких\nмоделей являются Skip-Gram и GloVe. Хотя эти предварительно обученные\nвекторы могут передать семантические значения слов, они не зависят от контекста\nи не могут уловить более высокоуровневые концепции в контексте, такие как\nразрешение многозначности, синтаксические структуры и семантические роли.\nВторое поколение PTM сосредоточено на изучении контекстных\nвекторных представлений слов. Примерами таких моделей являются CoVe, ELMo,\nOpenAI GPT и BERT. Эти обученные модели по-прежнему необходимы для\nпредставления слов в контексте в последующих задачах NLP. Кроме того, также\nпредлагаются различные задачи предварительного обучения для изучения PTM с\nразными целями.\nPTM третьего поколения основываются на втором поколении, повышают\nпроизводительность модели и устраняют некоторые ограничения. Хотя строгого\nопределения или списка моделей, подпадающих под третье поколение, не\nсуществует, некоторые характеристики включают в себя:\nУлучшенное понимание контекста: PTM третьего поколения могут\nвключать в себя более продвинутые методы для лучшего понимания\nконтекста и захвата сложных семантических отношений.\nМультимодальное обучение: эти модели могут интегрировать\nинформацию из нескольких источников или модальностей, таких как текст,\nизображения и аудио, для лучшего понимания и представления.\nМасштабируемость и эффективность: PTM третьего поколения могут\nсосредоточиться на улучшении масштабируемости моделей при сохранении\nили повышении производительности, например, с помощью методов сжатия\nмоделей или более эффективных архитектур.\nБолее сложные задачи предварительного обучения: они могут включать\nв себя более сложные цели или задачи предварительного обучения,\nнаправленные на лучшее улавливание лингвистических и структурных\nсвойств входных данных.\nНовейшим является четвёртое поколение моделей PTM. В дополнение к\nосновным достижениям третьего поколения, добавляется следующее:\nБольше данных для обучения и больше параметров: PTM четвертого\nпоколения, такие как GPT-4, используют еще большие наборы данных и\nимеют значительно большее количество параметров по сравнению с их\nпредшественниками. Это позволяет им улавливать более широкий спектр\nязыковых моделей и нюансов.\nУлучшенные возможности понимания и генерации: эти модели\nдемонстрируют лучшее понимание контекста, грамматики и семантики, что\nприводит к более связному и контекстуально точному созданию текста.\nУсовершенствованная точная настройка и перенос обучения: PTM\nчетвертого поколения можно более эффективно настраивать для конкретных\nзадач, демонстрируя улучшенную производительность в широком спектре\nпоследующих приложений, таких как перевод, реферирование и ответы на\nвопросы.\n9\n10\n11\n12\n13\nПостоянное внимание к масштабируемости и эффективности: хотя эти\nмодели больше и сложнее, они также стремятся сбалансировать\nмасштабируемость и эффективность, часто используя методы оптимизации\nобучения и логических выводов.\nНа данный момент к четвёртому поколению моделей PTM относится\nтолько GPT-4 от компании OpenAI, а наиболее распространёнными моделями\nтретьего поколения являются BERT и LLama. Эти модели можно рассматривать\nкак универсальный инструмент для научной работы, а также как средство и метод\nдля выполнения более специализированных задач в какой-либо конкретной\nобласти, например агент-ориентированного моделирования в экономике.\nОчевидно, что существуют как серьёзные ограничения применения такого\nинструмента, так и потрясающие новые возможности помощи учёным и\nисследователям в разных областях науки.\nПрактика применения языковых моделей в научной работе в мире\nДанная тема сейчас является горячо обсуждаемой в научных кругах. Но в силу\nтого, что публикационная активность по этой тематике значительно возросла\nтолько в течение последних нескольких месяцев, то число значимых и\nкачественных работ в этой области пока ещё не высоко. Рассмотрим публикации\nнаиболее авторитетных источников по этой тематике в разных областях науки.\nЭтические проблемы создания научного контента с помощью ChatGPT в\nмедицине опубликованы в статье [9] в журнале The Lancet. Также другой автор в\nдругой работе [8] по медицинской тематике предостерегает студентов от\nчрезмерного использования ChatGPT во время обучения. Потенциальное влияние\nязыковых моделей типа ChatGPT на индустрию образования в целом изложено в\n[5], а также в статье [13], имеющей довольно резкое для научных публикаций\nназвание, которое можно художественно перевести на русский язык как «ChatGPT:\nГенератор чуши или конец традиционным ценностям высшего образования?».\nПроблема плагиата публиковалась в [6] ещё за несколько лет до того, как большие\nязыковые модели обрели такую популярность, и продолжает быть очень\nактуальной, о чём подробно написано в препринте [7]. Некоторые исследователи\nуже провели эксперименты относительно использования ChatGPT в разных\nобластях науки. Например, в Индии в области медицины в [11] описывается\nинтересный опыт генерации научной статьи по результатам проведённых\nисследований.\nКлючевым выводом подобных экспериментов является то, что результаты\nработы ChatGPT обязательно должны проверяться человеком. Модель ChatGPT\nчасто генерирует совершенно верно оформленные ссылки на литературу, однако в\nпроцессе проверки выясняется, что в реальности либо у авторов нет таких\nпубликаций, либо это вообще несуществующие авторы. То же самое касается и\nфактов, напрямую влияющих на результаты исследования.\nВозможности применения ChatGPT в экономике\n14\n15\n16\nОшибочность некоторых суждений и фактов, выдаваемых системой ChatGPT\nподтверждается и собственными примерами из области агент-ориентированного\nмоделирования. Системе ChatGPT было дано указание рассказать в каких научных\nстатьях описывается агент-ориентированная модель Швейцарии под названием\nMIMOSE для последующей ссылки в научных работах. Текс запроса на\nанглийском языке показан на рисунке 1.\nРис. 1. Запрос на список статей для цитирования по модели MIMOSE\nВажно упомянуть, что этот вопрос был задан в контексте беседы, которая\nначалась с нескольких вопросов про большие агент-ориентированные модели\nстран и регионов (более подробно в [1] и [2]), и ChatGPT уже самостоятельно\nпредоставил описание агент-ориентированной модели MIMOSE. Полный текст\nответа на этот вопрос показан на рисунке 2.\nРис. 2. Ответ ChatGPT на запрос статей для цитирования о модели MIMOSE\n17\n18\n19\n20\n21\n22\nВ первом же предложении ChatGPT утверждает, что оригинальная статья,\nв которой описывается модель MIMOSE это [3]. Такая статья действительно\nсуществует и имеет такое же название, однако во-первых, она была опубликована в\n2003 году, а не в 2012, во-вторых, не в Скандинавском журнале экономики\n(Scandinavian Journal of Economics), в-третьих статья хоть и является статьей по\nтематике агент-ориентированного моделирования, но никак не затрагивает модель\nШвейцарии под названием MIMOSE. Стоит отметить с какой\nбезапелляционностью ChatGPT заявляет об обратном.\nСледующая статья [4] из списка тоже существует в реальности, также не\nимеет отношения к модели MIMOSE, однако система верно указала год\nпубликации, но опять ошиблась с журналом указав реально существующий\nакадемический журнал Resource and Energy Economics, вместо Journal of\nEnvironmental Economics and Management.\nСтатьи за авторством Karydas, Katsikas et al найти вообще не удалось, но\nдаже судя по названию она не соответствует заявленной тематике вопроса.\nЗаключительная ссылка на статью авторов Rutherford и Tarr также является\nвымыслом системы, хотя такие авторы существуют в реальности и публикуют\nстатьи на схожие тематики.\nДалее системе ChatGPT был задан уточняющий вопрос, показанный на\nрисунке 3.\nРис. 3. Уточняющий вопрос системе ChatGPT\nВопрос был задан в рамках той же беседы с контекстом, и между ними не\nбыло никаких дополнительных разговоров. Ответ представлен на рисунке 4.\n23\n24\n25\n26\nРис. 4. Ответ на уточняющий вопрос про модель MIMOSE\nChatGPT извиняется за свою ошибку, хотя ни в одном запросе не\nупоминается об ошибочности выданных системой информации. И снова выдаёт\nновую вариацию на статью авторов Bretschger et al, утверждая, что в ней даётся\nисчерпывающий обзор агент-ориентированной модели MIMOSE, особенностей её\nреализации, структуры модели, включая используемые типы агентов. Стоит снова\nобратить внимание на то, с какой уверенностью подаётся абсолютно ложная\nинформация, даже после уточняющего вопроса.\nОсновная ценность состоит не только в умении ChatGPT переписывать,\nперефразировать и переводить тексты, а в анализе огромнейшего массива\nинформации и поиске в нём той нужной части, которую и ищет исследователь, и\nобъяснение её тем «языком», который требуется. ChatGPT не должен и не может\nбыть автором или соавтором той или иной научной работы, а является\nинструментом в работе учёного. Таким же, как, например, поисковые системы\nGoogle, Яндекс, более продвинутые системы, как Wolfram Alpha, системы\nцитирования и индексирования РИНЦ, Web of Science и Scopus. Автор всегда\nдолжен проверять и брать на себя ответственность за тот материал, который он\nсоздаёт, вне зависимости от того инструмента, которым он пользуется.\nПрименение ChatGPT как инструмента генерации программного кода\nВозможности ChatGPT не ограничиваются только написанием текста и\nпоисковыми функциями по огромному массиву данных, но и распространяются на\nанализ изображений (только в версии 4.0) и генерации программного кода.\nПоследняя особенность является наиболее интересной с точки зрения экономики и\nимитационного моделирования. Для оценки способностей системы зададим в\n27\nновой беседе задачу построить программу экономической агент-ориентированной\nмодели города. Запрос будет написан следующим образом: Please write an\neconomical agent-based model of large city in C# и исполнен моделью GPT 4.0.\nРезультат выполнения этого запроса показан на листинге ниже.\n\n28\n29\nРис. 5. Программный код на языке C# сгенерированный ChatGPT 4.0\nПрограмма является хорошо комментированной, разбита на классы в\nсоответствии с идеологией объект-ориентированного программирования, и\n30\n31\n32\n33\nвключает агенты двух типов – жители города и организации, работающие в нём.\nОчевидно, что качество такой программы является очень хорошим для\nдемонстрации основных возможностей агент-ориентированного моделирования и\nидеально подходит для целей обучения студентов и научных сотрудников основам\nагент-ориентированного моделирования. Все последующие уточнения и\nнововведения автору придётся делать самостоятельно, отчасти из-за ограничения\nна максимальный размер создаваемой программы, а отчасти из-за несовершенства\nмеханизма генерации программного кода системы ChatGPT.\nЕщё одним интересным экспериментом является использования ChatGPT\nкак метода и инструмента в области расчётных моделей общего равновесия (CGE).\nCGE модели – это класс экономических моделей, используемых для анализа\nэкономической политики и прогнозирования. Они основаны на теории общего\nравновесия, которая рассматривает взаимодействие между различными\nэкономическими агентами, такими как домохозяйства, предприятия и\nправительство. Модели учитывают взаимосвязи между производством,\nпотреблением и инвестициями, а также взаимодействие между отраслями и\nстранами. CGE-модели позволяют исследователям проводить количественный\nанализ воздействия различных экономических политик, таких как изменение\nналогов, тарифов или субсидий, на экономические показатели, такие как\nпроизводство, занятость, торговый баланс и благосостояние. Создание таких\nмоделей представляет собой сложную задачу. В качестве эксперимента, обратимся\nк версии 4 модели ChatGPT в новой беседе с запросом на построение программы\nCGE моделирования на языке C# с использованием любых библиотек, которые она\nсочтёт необходимыми и реализующей пример с 5 странами и 10 секторами. Запрос\nбыл написан следующим образом: Please write C# application implementing CGE\nmodel with 10 sectors and 5 countries, using any libraries you consider useful.\nВ результате выполнения запроса ChatGPT выдал несколько листингов\nпрограммы, сопроводив это вспомогательным текстом. В начале сообщается о том,\nчто ChatGPT может реализовать только общую часть программы и некоторый код\nдля примера, который нужно будет самостоятельно доработать в дальнейшем.\nЗатем указывается список библиотек, которые будут использованы в программе, а\nименно MathNet.Numerics и CvsHelper, вместе с краткой инструкцией по их\nустановке. Затем идёт первый блок кода, в котором объявляется простая структура\nдля хранения данных о секторе и стране (см. Рис. 6)\nРис. 6. Структура данных для хранения информации о секторах и странах\n34\n35\nПосле этого идёт код создания основного класса CGEModel:\nРис. 7. Код реализующий класс расчётной модели общего равновесия\n36\n37\n38\n39\nКак видно из этого кода, большинство методов класса CGEModel являются\nт.н. «заглушками», о чём ChatGPT и предупредил в самом начале. Тем не менее, из\nкомментариев становится понятно, что в SaveResults предполагается сохранение\nрезультатов в файле в формате CSV, а в методе LoadResults даже реализована\nзагрузка данных из файла в этом формате. Самая важная часть – метод RunModel\nоказался полностью нереализованным. Для получения его реализации системе был\nвыдан следующий запрос: Implement RunModel method from CGEModel class.\nНа что ChatGPT снова ответил абзацем текста о том, что реализация CGE\nмоделей является сложной задачей, которая требует глубокого понимания\nэкономической теории и особых уравнений модели. За ним последовала\nреализация метода RunModel, который полностью состоит из вызовов других\nметодов (см. Рис. 8).\nРис. 8. Код, реализующий метод RunModel\nНаконец, на запрос реализовать метод CalculateEquilibrium() модель\nChatGPT переходит непосредственно к объяснению баланса спроса и предложения\nи приводит довольно примерную, но всё же реальную реализацию этого метода\n(см. Рис. 9).\n40\n41\n42\nРис. 9. Реализация метода расчёта равновесия\nТаким образом, итеративно, можно использовать ChatGPT для получения\nзаготовки для последующей разработки полноценной CGE модели. Несмотря на\nвсю абстрактность реализованного кода, он тем не менее представляет интерес и\nможно сделать вывод о том, что ChatGPT действительно может быть хорошим\nвспомогательным (но не основным!) инструментов в работе учёного-экономиста.\nЗаключение\nВ этой статье приведен перечень поколений языковых моделей и отклик в научной\nсреде на самую популярную модель ChatGPT. В результате проведённых\nэкспериментов было показано, что использование ChatGPT в научной работе хоть\nи связано с определёнными сложностями, однако уже сейчас даёт большие\nпреимущества. Особое внимание уделено ошибкам и недостаткам системы, о\nкоторых должен знать любой исследователь, использующий ChatGPT. Учитывая\nдальнейшее развитие (на данный момент уже доступна следующая версия модели\nGPT 4.0), а также появление новых общих и специализированных систем есть все\nвозможности для дальнейшего улучшения этого инструмента.\nБиблиография:\n1. Бахтизин А.Р. Агент-ориентированные модели экономики. М.: Экономика, 2008.\n– 279 c.\n2. Брагин А.В., Бахтизин А.Р., Макаров В.Л. Современные программные средства\nагент-ориентированного моделирования // Искусственные общества. 2022, Т. 17, №\n4. DOI 10.18254/S207751800023501-0\n3. Bretschger, L., & Smulders, S. Sustainability and substitution of exhaustible natural\nresources: how resource prices affect long-term R&D?investments. 2003.\n4. Bretschger L., Valente S. Endogenous growth, asymmetric trade and resource\ndependence //Journal of Environmental Economics and Management. 2012, vol 64, №. 3\n5. Cotton D. R. E., Cotton P. A., Shipway J. R. Chatting and Cheating: Ensuring\nacademic integrity in the era of ChatGPT //Innovations in Education and Teaching\nInternational. 2023\n6. Dehouche N. Plagiarism in the age of massive Generative Pre-trained Transformers\n(GPT-3) // Ethics in Science and Environmental Politics. 2021, vol. 21\n7. Khalil M., Er E. Will ChatGPT get you caught? Rethinking of Plagiarism Detection //\narXiv preprint arXiv:2302.04335. 2023.\n8. King M.R., chatGPT. A conversation on artificial intelligence, chatbots, and\nplagiarism in higher education // Cellular and Molecular Bioengineering. 2023.\n9. Liebrenz M. et al. Generating scholarly content with ChatGPT: ethical challenges for\nmedical publishing //The Lancet Digital Health. 2023, vol. 5, №. 3\n10. Lund B. D., Wang T. Chatting about ChatGPT: how may AI and GPT impact\nacademia and libraries? // Library Hi Tech News. 2023.\n11. Manohar N., Prasad S. S. Use of ChatGPT in Academic Publishing: A Rare Case of\nSeronegative Systemic Lupus Erythematosus in a Patient With HIV Infection // Cureus\nJournal of Medical Science. 2023, vol. 15, №. 2.\n12. Qiu X. et al. Pre-trained models for natural language processing: A survey // Science\nChina Technological Sciences. 2020, vol. 63, №. 10.\n13. Rudolph J., Tan S., Tan S. ChatGPT: Bullshit spewer or the end of traditional\nassessments in higher education? // Journal of Applied Learning and Teaching. 2023, Т.\n6, №. 1.\n \nLarge Fourth-Generation Language Models as a New\nTool in Scientific Research\nAlexey Bragin\nCentral Economics and Mathematics Institute of the Russian Academy of Sciences\nRussian Federation, Moscow\nAlbert Bakhtizin\nCentral Economics and Mathematics Institute of the Russian Academy of Sciences\nRussian Federation, Moscow\nValery Makarov\nCentral Economics and Mathematics Institute of the Russian Academy of Sciences\nRussian Federation, Moscow\nAbstract\nIn this study, the latest achievements in the field of deep learning, including\nconvolutional, recurrent, and graph neural networks and attention mechanisms, as well\nas their contribution to the development of pre-trained language models, are examined.\nA brief literature review is presented, discussing the use of pre-trained language models\nin scientific research and education in various fields of science. Experiments are\nconducted on the application of ChatGPT in the field of economics. The authors present\nan analysis of the advantages and limitations associated with ChatGPT, providing\nrecommendations for its use in scientific work. Additionally, the article demonstrates the\nability of ChatGPT to generate C# programs for agent-based models (ABM) and\ncomputable general equilibrium (CGE) models, highlighting its potential for\ninterdisciplinary research and practical applications in economics and computational\nmodeling.\nKeywords: language models, chatgpt, llm, agent-based modeling\nDate of publication: 31.03.2023\nCitation link:\nBragin A., Bakhtizin A., Makarov V. Large Fourth-Generation Language Models as a\nNew Tool in Scientific Research // Artificial societies. 2023. Vol. 18. Issue 1.\nURL: https://artsoc.jes.su/s207751800025046-9-1/ DOI: 10.18254/S207751800025046-\n9\nКод пользователя: 0; Дата выгрузки: 05.11.2025; URL - http://artsoc.jes.su/s207751800025046-9-1/ Все права\nзащищены.",
  "topic": "Computable general equilibrium",
  "concepts": [
    {
      "name": "Computable general equilibrium",
      "score": 0.7423750162124634
    },
    {
      "name": "Computer science",
      "score": 0.6703457832336426
    },
    {
      "name": "Field (mathematics)",
      "score": 0.6186261177062988
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5101907253265381
    },
    {
      "name": "Management science",
      "score": 0.49177148938179016
    },
    {
      "name": "Data science",
      "score": 0.47575753927230835
    },
    {
      "name": "Deep learning",
      "score": 0.4473068118095398
    },
    {
      "name": "Language model",
      "score": 0.42721328139305115
    },
    {
      "name": "Convolutional neural network",
      "score": 0.4136753976345062
    },
    {
      "name": "Machine learning",
      "score": 0.3670879304409027
    },
    {
      "name": "Engineering",
      "score": 0.11640378832817078
    },
    {
      "name": "Economics",
      "score": 0.08621913194656372
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Macroeconomics",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ]
}