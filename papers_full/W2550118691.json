{
  "title": "Breaking Bad Behaviors: A New Tool for Learning Classroom Management Using Virtual Reality",
  "url": "https://openalex.org/W2550118691",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A3179843202",
      "name": "Jean-Luc Lugrin",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2575568968",
      "name": "Marc Erich Latoschik",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2078786759",
      "name": "Michael Habel",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2096379602",
      "name": "Daniel Roth",
      "affiliations": [
        "University of Würzburg",
        "University of Cologne"
      ]
    },
    {
      "id": "https://openalex.org/A2552954669",
      "name": "Christian Seufert",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2012369663",
      "name": "Silke Grafe",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A3179843202",
      "name": "Jean-Luc Lugrin",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2575568968",
      "name": "Marc Erich Latoschik",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2078786759",
      "name": "Michael Habel",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2096379602",
      "name": "Daniel Roth",
      "affiliations": [
        "TH Köln - University of Applied Sciences",
        "University of Cologne",
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2552954669",
      "name": "Christian Seufert",
      "affiliations": [
        "University of Würzburg"
      ]
    },
    {
      "id": "https://openalex.org/A2012369663",
      "name": "Silke Grafe",
      "affiliations": [
        "University of Würzburg"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3083336837",
    "https://openalex.org/W6691879878",
    "https://openalex.org/W6678646144",
    "https://openalex.org/W6685564531",
    "https://openalex.org/W2115428183",
    "https://openalex.org/W1559697522",
    "https://openalex.org/W2156943463",
    "https://openalex.org/W1982044043",
    "https://openalex.org/W2130747886",
    "https://openalex.org/W2498258238",
    "https://openalex.org/W2157289187",
    "https://openalex.org/W6689613833",
    "https://openalex.org/W2167044060",
    "https://openalex.org/W6604930066",
    "https://openalex.org/W6721048822",
    "https://openalex.org/W6639389275",
    "https://openalex.org/W2169011226",
    "https://openalex.org/W2021298762",
    "https://openalex.org/W1994877858",
    "https://openalex.org/W2124917152",
    "https://openalex.org/W2131722737",
    "https://openalex.org/W2096822517",
    "https://openalex.org/W3000631824",
    "https://openalex.org/W2148158693",
    "https://openalex.org/W6676305606",
    "https://openalex.org/W2002939146",
    "https://openalex.org/W4230242800",
    "https://openalex.org/W7074645726",
    "https://openalex.org/W6653626626",
    "https://openalex.org/W2010370381",
    "https://openalex.org/W6776260850",
    "https://openalex.org/W2043181832",
    "https://openalex.org/W6788119825",
    "https://openalex.org/W6979856527",
    "https://openalex.org/W638718026",
    "https://openalex.org/W6666076302",
    "https://openalex.org/W1528045197",
    "https://openalex.org/W2145839404",
    "https://openalex.org/W2065815384",
    "https://openalex.org/W6655590056",
    "https://openalex.org/W2079245537",
    "https://openalex.org/W6633480235",
    "https://openalex.org/W2068768048",
    "https://openalex.org/W6647584306",
    "https://openalex.org/W2316205905",
    "https://openalex.org/W2148885568",
    "https://openalex.org/W3015750939",
    "https://openalex.org/W2014159645",
    "https://openalex.org/W2527527862",
    "https://openalex.org/W1600925689",
    "https://openalex.org/W2175257801",
    "https://openalex.org/W2061893027",
    "https://openalex.org/W3043909119",
    "https://openalex.org/W2884788206",
    "https://openalex.org/W113198029",
    "https://openalex.org/W1528719126",
    "https://openalex.org/W1598911678",
    "https://openalex.org/W614135969",
    "https://openalex.org/W2404858327",
    "https://openalex.org/W599321106",
    "https://openalex.org/W2005742805",
    "https://openalex.org/W3114284325",
    "https://openalex.org/W1555185713",
    "https://openalex.org/W2339121588",
    "https://openalex.org/W1582484063",
    "https://openalex.org/W1594264159",
    "https://openalex.org/W1986853850",
    "https://openalex.org/W2226141085",
    "https://openalex.org/W400681743",
    "https://openalex.org/W2125240733",
    "https://openalex.org/W1559058206",
    "https://openalex.org/W1989808394",
    "https://openalex.org/W119848644",
    "https://openalex.org/W2109814494",
    "https://openalex.org/W2320456512",
    "https://openalex.org/W1491159290",
    "https://openalex.org/W2021845646",
    "https://openalex.org/W2474851500",
    "https://openalex.org/W2113279910",
    "https://openalex.org/W2251243643",
    "https://openalex.org/W1879840405"
  ],
  "abstract": "This article presents an immersive Virtual Reality (VR) system for training classroom management skills, with a specific focus on learning to manage disruptive student behaviour in face-to-face, one-to-many teaching scenarios. The core of the system is a real-time 3D virtual simulation of a classroom, populated by twenty-four semi-autonomous virtual students. The system has been designed as a companion tool for classroom management seminars in a syllabus for primary and secondary school teachers. Whereby, it will allow lecturers to link theory with practice, using the medium of VR. The system is therefore designed for two users: a trainee teacher and an instructor supervising the training session. The teacher is immersed in a real-time 3D simulation of a classroom by means of a head-mounted display and headphone. The instructor operates a graphical desktop console which renders a view of the class and the teacher, whose avatar movements are captured by a marker-less tracking system. This console includes a 2D graphics menu with convenient behaviour and feedback control mechanisms to provide human-guided training sessions. The system is built using low-cost consumer hardware and software. Its architecture and technical design are described in detail. A first evaluation confirms its conformance to critical usability requirements (i.e., safety and comfort, believability, simplicity, acceptability, extensibility, affordability and mobility). Our initial results are promising, and constitute the necessary first step toward a possible investigation of the efficiency and effectiveness of such a system in terms of learning outcomes and experience.",
  "full_text": "November 2016 | Volume 3 | Article 261\nTechnology RepoRT\npublished: 30 November 2016\ndoi: 10.3389/fict.2016.00026\nFrontiers in ICT | www.fr\nontiersin.org\nEdited by: \nRyan Patrick McMahan,  \nUniversity of Texas at Dallas, USA\nReviewed by: \nMartin Hachet,  \nInria, France  \nBenjamin Lok,  \nUniversity of Florida, USA\n*Correspondence:\nJean-Luc Lugrin \njean-luc.lugrin@uni-wuerzburg.de\nSpecialty section: \nThis article was submitted to \nVirtual Environments,  \na section of the journal  \nFrontiers in ICT\nReceived: 13 July 2016\nAccepted: 24 October 2016\nPublished: 30 November 2016\nCitation: \nLugrin J-L, Latoschik ME, Habel M, \nRoth D, Seufert C and Grafe S (2016) \nBreaking Bad Behaviors: A New Tool \nfor Learning Classroom Management \nUsing Virtual Reality. \nFront. ICT 3:26. \ndoi: 10.3389/fict.2016.00026\nBreaking Bad Behaviors: A new Tool \nfor learning classroom Management\nUsing Virtual Reality\n \nJean-Luc Lugrin1*, Marc Erich Latoschik1, Michael Habel1, Daniel Roth1,2,  \nChristian Seufert3 and Silke Grafe3\n1 HCI Group, University of Würzburg, Würzburg, Germany, 2 Media and Communication Psychology Group, University of \nCologne, Cologne, Germany, 3 University of Würzburg, Würzburg, Germany\nThis article presents an immersive virtual reality (VR) system for training classroom man-\nagement skills, with a specific focus on learning to manage disruptive student behavior \nin face-to-face, one-to-many teaching scenarios. The core of the system is a real-time \n3D virtual simulation of a classroom populated by twenty-four semi-autonomous virtual \nstudents. The system has been designed as a companion tool for classroom manage-\nment seminars in a syllabus for primary and secondary school teachers. This will allow \nlecturers to link theory with practice using the medium of VR. The system is therefore \ndesigned for two users: a trainee teacher and an instructor supervising the training \nsession. The teacher is immersed in a real-time 3D simulation of a classroom by means \nof a head-mounted display and headphone. The instructor operates a graphical desktop \nconsole, which renders a view of the class and the teacher whose avatar movements are \ncaptured by a marker less tracking system. This console includes a 2D graphics menu \nwith convenient behavior and feedback control mechanisms to provide human-guided \ntraining sessions. The system is built using low-cost consumer hardware and software. \nIts architecture and technical design are described in detail. A first evaluation confirms \nits conformance to critical usability requirements (i.e., safety and comfort, believability, \nsimplicity, acceptability, extensibility, affordability, and mobility). Our initial results are \npromising and constitute the necessary first step toward a possible investigation of \nthe efficiency and effectiveness of such a system in terms of learning outcomes and \nexperience.\nKeywords: virtual reality training, immersive classroom management, immersive classroom, virtual agent \ninteraction, student simulation\n1. InTRoDUcTIon\nIn a classroom, disruptive student behavior can have far-reaching detrimental effects on the experi-\nence and emotional state of both teachers and students, hindering the achievement of teaching goals \nand diminishing the overall efficacy of learning for one or all in the classroom (Brouwers and Tomic, \n1999; Emmer and Stough, 2001). As such, preempting, controlling, and mitigating disruptive behav-\nior are vital skills for anyone hoping to effectively teach in face-to-face and one-to-many teaching \nsituations. Competence in establishing and maintaining order, engaging students and eliciting their \ntrust, respect, and cooperation are essential aspects of classroom management (CRM) (Emmer and \n2\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nStough, 2001), which in turn is an important topic in educational \nresearch ( Evertson and Weinstein, 2013) and a fundamental \nmodule during teacher training (Kunter et al., 2015).\nEffective training depends on three major elements:\n 1.\n E\nxposure to realistic training scenarios and stimuli. In the case \nof CRM, the training stimuli are a classroom full of students \ndisplaying a wide variety of realistic normal and disruptive \nstudent behavior. Generally speaking, realistic training \nstimuli can be attained by either training in vivo , that is, in a \nreal classroom with real students, or through simulation.\n 2.\n Fin\ne control over training stimuli and scenarios. This includes \nthe capacity to finely adjust the difficulty of training to match \nthe current competence of the trainee because it is important \nthat the training scenario be neither too far beyond or below \ntheir current capabilities. It also includes the capacity to \nexpose trainees to identical training stimuli multiple times.\n 3.\n Fin\ne performance feedback. Providing trainees with a fine-\ngrained, unambiguous, timely measure of their current \nperformance enables them to adjust their behavior to achieve \nbetter results.\nIn terms of the first element, the gold standard of CRM train-\ning is a real classroom with real students. There might, however, \nbe times when it is not possible to provide trainee teachers with \nsufficient time in real classrooms. Further, it should be apparent \nthat, in certain scenarios, a compromise exists between the first \nelement (realism) and the second and third elements (control \nof stimuli and feedback). This is certainly the case with CRM. \nThe unpredictability of a real classroom greatly diminishes any \ncontrol over the exact nature and difficulty of training stimuli, \nand feedback is largely restricted to deferred reviews in which \nfeedback is decoupled from the actual situational context, \nimpeding trainees’ capacity to adjust their performance in \nresponse. Ideally, control of stimuli and provision of feedback \nwould occur in a closed real-time loop between trainer and \ntrainee, allowing the trainer to provide stimuli that finely match \nand gradually extend the trainees’ capabilities and skills. For \nexample, suitable reactions to disruptive behavior have vari-\nous communicative and interpersonal aspects (e.g., choice or \nwording, tone of voice, loudness, non-verbal signals by body \nposture, gestures, movement, eye contact). All of these aspects \nare important and have to be mastered for successful class man-\nagement. A failing reaction to a disruption does not necessarily \nmean that all of the aspects of the counter action have been \nwrong; hence, targeted feedback is necessary. Providing such \nfeedback in a real classroom is difficult to achieve without inad-\nvertently influencing the state of the classroom or diminishing \nthe realism of the situation.\nAn alternative to real-world in  vivo  training is simulation. \nIn the context of CRM, virtual training environments (VTEs) \nhave been successfully used in training and education domains \nfor many years ( Tichon, 2007; Gupta et al., 2008; Dieker et al., \n2013). VTEs often provide alternatives to various teaching setups \nconcentrating on the knowledge transfer of the subjects taught \n(Schutte, 1997; Keppell, 1998; Mahon et al., 2010). Stress exposure \ntraining delivered via a VTE has been used across many domains, \nincluding military, aviation, and health care (Schuemie, 2003; \nBaker et al., 2005). We followed this approach and developed an \nimmersive virtual reality (VR) environment for CRM training \nthat generates appropriately stressful situations as expected in \nfront of classes. Stress exposure training rests on the simulation’s \nability to elicit emotional responses from the teachers (Tichon, \n2007). The ability of the system to realistically elicit stress similar \nto a real classroom atmosphere is therefore paramount.\nThe simulation medium must therefore be capable of invoking \nrealistic responses to stressful stimuli, which is hard to grasp and \nmaster with only video analysis and/or role-play games. One of \nthe main technical challenges is then the simulation and control \nof a high number of virtual students, which is essential not just \nfor realism but also for provoking realistic levels of stress. In \nterms of feedback, VTEs offer a rich variety of possibilities, rang-\ning from continuous real-time feedback to fully deferred (Hale \net  al., 2014). Real-time feedback helps users to identify their \nweaknesses during their performance (Lopez et  al., 2012) and \nto continuously adapt their behavior to efficiently reach training \ngoals. Previous research has demonstrated that effective feedback \nsystems should reinforce the gamification aspects of the training, \nwhich is based on the gradual increase of challenges, perceptual \nsupport, and finely tuned scoring systems (Charles et al., 2011; \nHoney and Hilton, 2011). However, how best to provide effective \nfeedback within an immersive CRM training system remains an \nopen question. In this research, we investigated, developed, and \nevaluated a VR system combining the three elements of effective \ntraining: realism, fine control of stimuli, and real-time, fine-\ngrained feedback.\n1.1. context and Requirements\nThis article presents a VR training system as an apparatus for \nthe training of CRM skills: breaking bad behavior  (henceforth \n3B) employs a one-to-one teacher/instructor paradigm, with \nthe trainee teacher’s entering a visually and aurally immersive \nvirtual environment, while the instructor controls training tasks, \nmonitors the teacher’s performance, and provides feedback to the \nteacher using a non-immersive graphics console.\nThe 3B system is intended as a complement to traditional \nCRM teaching methods. It was designed as a companion tool \nfor existing CRM seminars at the University of Würzberg, \nGermany. (Specifically, they were used in two seminars: \nClassroom Management and Videobased Reflection of Education, \nboth part of the initial teacher syllabus for primary and second-\nary school teachers.) The system allows lecturers to link theory \nwith practice, using the medium of VR to concretely illustrate \nthe theory, techniques, and examples discussed in lectures and \nseminars.\nThe 3B platform aims to better prepare trainee teachers for \nfuture in  vivo training by letting them experience and practice \ntheir coping strategies in a safe environment. It is designed to be \nused by practitioners in the field of educational training without \nexpert knowledge in computer programing, virtual reality, or other \ntechnical domains. Not only can the non-technical expert run \ntraining sessions, but they can also create new training scenarios \n3\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nwithout requiring deep technical knowledge. The system has \nbeen conceived in close collaboration with experts in pedagogy \nand CRM training from the University of Würzberg School of \nPedagogy. These experts in the field of CRM training designed \nthe training scenarios and virtual student behaviors and were \nactively involved in the design of the instructor interface and its \ninteraction techniques. The system underwent an iterative one-\nyear development process, with a strong focus on user-centered \ndesign. Before being validated by CRM training experts, a team \nof thirteen HCI bachelor students and two supervisors developed \nand evaluated four main prototypes. They also received formal \nand informal feedback from our pedagogic partners every two \nto four weeks.\nThis article describes the final iteration of the 3B system, its \nfeatures, its internal mechanisms, and its first formal evaluation \nwith the students of the CRM seminar. The system provides the \nfollowing main characteristics for training tasks and teacher \neducations.\n 1.\n C\nontrol of the behaviors of individuals and of an entire class \nwhile creating dialog phases to allow a more realistic and \nresponsive classroom.\n 2.\n P\nrovision of adequate synchronous and asynchronous \nfeedback to teachers by an instructor monitoring their \nperformance.\n 3.\n R\nepresentation of the teacher’s avatar as a means to\n•\n in\ncrease believability and hence immersion and emotional \nresponse for the teacher; and\n•\n p\nrovide a visualization of the teacher’s body language for \nthe instructor.\n 4.\n U\nsable in a classroom. It can be installed in any room with-\nout special infrastructure using low-cost hardware and free \nsoftware. The system relies on consumer marker less tracking \ntechnology, head-mounted displays (HMDs), and a current \ngame engine.\n 5.\n C\nome as you are. The physical self is not artificially augmented \nwith sensors and devices, and preparation and rigging times \nare largely reduced. The teacher should wear the minimum \nequipment to be immersed in the environment. The system \ndoes not impede natural body movement. It allows the teach-\ners to naturally express themselves as in their everyday life, \nwith no physical constraints or additional fatigue.\nOur main objective was to identify any usability issues, \nespecially in terms of ease-of-use and potential VR-side effects \n(e.g., cybersickness), as well as measuring system reception and \nacceptability. Our second objective was to evaluate the effective-\nness of feedback and evaluation criteria in terms of guiding and \nmotivating trainees while in the VR simulation. We therefore \nevaluated the system with respect to three main aspects, taking \ninto account both user groups that could considerably affect our \nsystem’s integration into current teacher education curricula:\nE1. Simulation effects by the immersive teacher interface\n  i\n.\n B\nelievability\n  ii\n.\n C\nybersickness and potential side effects\n  iii\n.\n Eff\nect of feedback cues\nE2. Usability of the instructor interface\n  i\n.\n T\nask and cognitive load\n  ii\n.\n I\nntuitive usage of the interface\nE3. Technology acceptance by teachers and instructors\n1.2. organization\nAfter the initial motivation and brief summary of the contribution \nof the work presented here, we will continue with a reflection of \nrelated work. This will be twofold: section 2.1 reflects on current \naspects of CRM and disruptive behavior as known from didactics \nand teacher education to get an understanding of the use-case \nscenario. Section 2.2 reflects on recent computer-supported stress \nexposure and social skills training systems. This is followed by a \ndetailed description of the developed system and its main archi-\ntectural and design aspects in section 3. Section 4 illustrates the \nevaluation method, the design of the user study, the procedure, \nand the measures used. The evaluation results are presented in \nsection 5, followed by a reflection on current limitations as well \nas on future work in section 6.\n2. RelATeD WoRK\n2.1. \nc\nlassroom Management and \nDisruptive Behavior\nResearch on CRM is a well-established topic in educational \nresearch ( Evertson and Weinstein, 2013). Current models of \nteacher competencies have integrated CRM competencies as \none important aspect (Kunter et al., 2015). As a consequence, \nit is an important task to integrate CRM into initial teacher \neducation at universities and give students opportunities to \ndevelop CRM strategies during internships in schools. Jones \n(2006) reports that in US initial teacher US education programs, \nclassroom management as a topic has not yet been implemented \nsystematically. As a consequence, novice teachers do not feel \nsufficiently prepared with regard to CRM (ibid.). The number \nof publications about classroom management has increased \nconsiderably in Germany in the last years, although there is no \nsystematic implementation of classroom management courses \nin current curricula, to our knowledge. Even though practicing \nin school in reality is most preferable for most facets of teacher \neducation, classroom management might be considered an \nexception. Classroom disturbances in the real classroom are \nunpredictable, making it a challenge to train CRM competencies \nin a systematic way. Hence, training currently relies on learning \nthe theory of CRM, often accompanied with video analysis and/\nor role-playing games.\nOne of the most relevant aspects of CRM is the prevention \nand management of students’ misbehavior. Acting-out or aggres-\nsive children disrupt the flow of a lesson or make it impossible \nto teach the lesson. Effective teachers anticipate classroom dis-\nturbances to deflect them or, if that is not possible, react in an \nappropriate way with the right coping strategies (Borich, 2011). \nThere are various studies about the effectiveness and efficiency of \nclassroom management with regard to behavioral and ecological \nperspectives. For example, Canter and Canter (1992) developed \nthe assertive discipline program that emphasized specifying \nTABle 1 | Student bad behavior classification in terms of intensity of disruption perceived – null: correspond to normal behaviors (e.g., quiet and \nlistening student) – in italic animations were not directly controllable by the instructor during the evaluation.\nBad behavior levels\nn\null l\now Mid h\nigh e\nxtreme\nListening-and-quiet Sleeping-on-table Laughing Making-funny-noises Dancing\nRaising-arm-for-question Typing-on-mobile Pocking-neighbors Receiving-phone-call Screaming\nHead-Scratching Whispering Playing-with-pen Throwing-object Fighting\nLeg-over Looking-around Talking-neighbors Refusing-to-work Making-phone-call \nWriting Leaning-back Playing-with-pen Leaving-classroom Breaking-object\n4\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nclear rules for student behavior, tied to a system of rewards and \npunishments. They have not conducted systematic research on \ntheir program, however (Brophy, 2006). From an ecological point \nof view, Kounin (1970) discovered different classroom activities \npreventing students from becoming disruptive, such as with-it-\nness, overlapping, signal continuity, momentum reduction, group \nalerting, and accountability during lessons. His findings have \nbeen supported and enriched by recent process-outcome (teacher \neffects) studies, which identified and proved the assumption that \nreducing disruptive behavior has – in alignment with many other \ninfluencing variables – the strongest effects on the learning out-\ncomes and their development of children and adolescents (e.g., \nHattie, 2003).\nWith regard to modeling classroom misbehavior in a realistic \nway, there are various studies on different types of classroom mis-\nbehavior (Thomas et al., 1968; Levin and Nolan, 1991, 2013; Mayr \net al., 1991; Seitz, 1991, 2004; Canter and Canter, 1992; Walker, \n1995; Laslett and Smith, 2002; Borich, 2011; Canter, 2011). The \nwell-known typology of Borich (2011) provides a single dimen-\nsion with simple discretization level (mild, moderate, and severe) \nas well as numerous examples of typical observed behavior fall-\ning into these categories. Therefore, we adopted and extended \nBorich’s classification. It provides a convenient way to systemati-\ncally control a large set of virtual students to easily raise or lower \nthe level of stress perceived by a teacher. Table 1 summarizes the \ndifferent levels of bad behaviors as inspired by Borich (2011) as \nwell as their associated animations of the virtual students.\nThere is a significant body of research on the effects of \nteachers’ non verbal communication in real classrooms (Alibali \nand Nathan, 2007; Kelly et al., 2008, 2009; Mahon et al., 2010; \nWang and Loewen, 2015) and also in virtual ones (Barmaki and \nHughes, 2015a). Teachers tend to use a variety of non verbal \nbehaviors to communicate knowledge, including hand gestures \n(iconics, metaphorics, deictics, and beats), head movements, \naffect displays, kinetographs, and emblems (Wang and Loewen, \n2015). More interesting, CRM strategies appear to significantly \nrely on non verbal cues like eye contact, prolonged gaze, and \nproximity (Laslett and Smith, 2002). It is therefore important for \nthe instructor/evaluator to perceive the teacher’s body, as well \nas its current point of focus. We thus decided to include avatar \nembodiment techniques (Spanlang et  al., 2014) and a system \nto highlight the teacher’s focus, as illustrated in Figure 1. The \navatar embodiment is also supported for the teacher because it \nis an important factor of presence (Lok et al., 2003; Kilteni et al., \n2012).\n2.2. Stress exposure and  \nSocial Skill T\nraining\nStress exposure training delivered via a VTE has been used across \nseveral domains, including the military, aviation, and health care \n(Schuemie, 2003; Baker et al., 2005). The ability to replicate real-\nworld scenarios in highly controlled virtual environments has \nproven ideal for learning and practicing decision-making skills \nin high-affect and dangerous situations (Tichon et al., 2003). For \nexample, Williamon et al. (2014) proposed a system to prepare \nmusicians to manage performance stress during auditions, \nrecitals, or live concerts. The system simulates a virtual audience \n(twenty-four members) and judges, recreating level of stress \ncomparable to real auditions. The virtual audiences and judges \nare interactive video-footage displayed on a semi-immersive large \nscreen and manipulated using preset control commands from a \ncomputer located in the backstage area.\nThe benefits of virtual environment training in non- or semi-\nimmersive VR systems, such as the TLE TeachLivE™ Lab (Hayes \net al., 2013b), are well known and have been well studied over the \nlast few years (Hayes et al., 2013b; Straub et al., 2014; Barmaki, \n2015). TLE TeachLivE™ is built on the framework AMITIES™ \n[avatar-mediated interactive training and individualized experi-\nence system (Nagendran et al., 2013)]. It permits users to interac-\ntively control avatars in remote environments. It connects people \ncontrolling avatars (inhabiters), various manifestations of these \navatars (surrogates), and people interacting with these avatars \n(participants). This unified human surrogates framework has also \nbeen used in multiple projects to control humanoid robots (see \nNagendran et al., 2015, for an overview). TeachLivE\nTM has been \nintegrated and adopted by 55 universities and was used with over \n12,000 teacher candidates during the 2014/15 academic year \n(Barmaki and Hughes, 2015b). Its ability to improve teacher \neducation has been demonstrated by many case studies (Hayes \net al., 2013b; Straub et al., 2014).\nKenny et al. (2007) designed a virtual environment to train \nnovice therapists to perform interviews with patients having \nimportant conduct disorders such as aggressive, destructive, or \ndeceitful behaviors. A virtual patient was displayed on a low-\nimmersive screen monitor and responded to users’ utterances \nusing natural language parsing with statistical text classifica-\ntion (Leuski et al., 2009), which itself was driving a procedural \nanimation system. The evaluations confirmed the system’s \nability to replicate real-life experience. Real-time 3D embodied \nconversational agents have been used to prepare for other stress-\nful social situations such as job interviews ( Jones et  al., 2014). \nFIgURe 1 | 3B – breaking bad behavior general system overview. The system adopts a client–server architecture. The client part (left) is controlled by the \ninstructor\n. It proposes a 2D graphical user interface to control virtual students as well as giving feedback to the teacher. The server part (right) is responsible for \nsimulating and displaying the virtual classroom to the teacher using an HMD and headphones. The server receives commands from the client and updates the \nvirtual world accordingly. The virtual world running on the server is then automatically replicated on the client, where the instructor can visualize the results of the \ncommands (e.g. a new virtual student behaviors or audio feedbacks cues). The server is also responsible for tracking the teacher’s motion and gesture (using Kinect \n2) and replicating them on the teacher’s avatar displayed on the client. Instructor can then observe and evaluate the teacher’s body language as well as verbal \ncommunications. The figure illustrates the system’s main modules responsible for the student behavior generation and replication on the client. For details, see text.\n5\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nThis job interview simulator supports social skills training and \ncoaching using a virtual recruiter and measuring applicants’ \nconversational engagement, vocal mirroring, speech activity, and \nprosodic emphasis.\nMore recently, a new platform combines TeachLivE\nTM with \na large mixed-reality room: the human surrogate interaction \nspace (HuSIS) targets de-escalation training for law enforcement \npersonnel (Hughes and Ingraham, 2016). The system provides \na 4 × 4 m room equipped with projectors and surround sound, \nwhere virtual agents can appear among or next to real objects \nin the room (e.g., tables, shelves). This augmented virtuality \nplatform aims at reproducing stressful scenarios based on an \nincreased immersion involving highly agitated individuals, \nwhere human lives might be at risk. Examples include, dealing \nwith highly stressed people who may harm themselves or others. \nTo defuse such situations as rapidly and effectively as possible, \nthe teacher must learn how to quickly assess a situation under \nstress. The system should elicit such stress and allow teachers \nto practice and improve their coping strategies in a safe envi-\nronment. The system’s evaluation should provide interesting \ninsights.\n2.3. Discussion\nCRM skills are an important aspect of face-to-face teaching \nsituations typically found in classrooms. Unfortunately, training \nCRM with the available methods based on a pure theoretical \nunderstanding or role-play does not match all the aspects found \nin the real-world scenario, including all of the embodiment and \nstress aspects. Likewise, a real-world scenario fails in terms of \nfine-tuned online stimulus control and feedback required for \nsuccessful training. VTEs are a promising alternative for the \nreal-world scenario. As a computer-generated environment, they \nprovide good control of the presented stimulus, and, in theory, \nthey open up various feedback channels. At the same time, less \n6\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nresearch has been dedicated to studying fully visually and audi-\ntory immersive training environments, despite their capacity \nto provide a more realistic emotional response and memorable \ntraining (Tichon, 2007; Slater, 2009); and the efficiency and fea-\nsibility of such systems for CRM have not yet been demonstrated \nwith a fully immersive virtual environment.\nWith the recent advent of the VR consumer market, the low-\ncost products open up novel perspectives to integrate VR-based \nlearning platforms to current school or university curricula. \nConsumer systems now provide a reasonable rendering quality, \nend-to-end latency, number of input/output channels (including \ntracking capabilities), and level of comfort for an acceptable \nprice, making them usable and affordable for institutions such as \nschools (approximately 2.500 € for a computer and VR headset, \nwith head and hands tracking). Our objective is then to provide \na new apparatus for CRM training, enabling further research on \nsuch novel applications of VR stress exposure.\nHowever, the consumer hardware and software are still not \ncapable of providing a truly interactive photo-realism for the \nenvironments and the virtual humans and avatars, which should \nfaithfully replicate a person’s appearance, movement, and facial \nexpression in an interactive real-time experience. In addition, \ndespite recent progress (Waltemate et al., 2015), photo-realistic \navatar and agent creation based on scanning or photogramme-\ntry is still time consuming, which is important if one wants to \nsimulate large crowds, such as multiple students/pupils. A higher \ndegree of realism requires higher levels of detail (number of poly-\ngons and shaders), which in turn increases rendering time and \nmight affect latency. Numerous user studies have demonstrate the \nnegative impacts of high latencies, temporal jitter, and positional \nerror on user performances, satisfaction, discomfort, and sense \nof immersion [see LaViola (2000) and Lugrin et al. (2013), for \nan overview]. Hence, it is important to find the right balance \nbetween realism and overall performance.\n2.3.1. Requirements\nDieker et  al. (2013) suggest three important factors for suc-\ncessful VTEs: (i) personalized learning, (ii) cyclical procedures \nto ensure impact, and (iii) suspension of disbelief; that is, \nit suspends our belief of the real world into one that is altered. \nAmong these factors, the suspension of disbelief is critical, \nespecially in VR where the feeling of immersion can easily be \nbroken or deteriorate with technical issues, such as bad, slow, \nor inaccurate head tracking or cybersickness. However, for a \nvirtual CRM training system, suspension of disbelief can also \nbe affected by non realistic behavior of the simulated students. \nHow to efficiently and realistically control dozens of students \nat the same time is not a trivial problem, especially while one \nhas to react to, evaluate, and guide the teacher’s reactions by \nappropriate stimuli and feedback.\nMost existing CRM or social skills training systems are able to \nsimulate only a relatively small number of virtual students (e.g., \nfive for TeachLivE). Such numbers are not representative of teach-\ning scenarios typically encountered in the real world (twenty-to-\nthirty students for a typical classroom, and up to several hundred \nfor a university lecture hall). Simulating more realistic class sizes \nis essential because class size is a vital factor for eliciting stress in \nthe teacher. Additional limitations of existing systems are their \nlack of mobility and their price. (Most of them require special \ninfrastructure, equipment, and intensive maintenance.)\nIn previous systems, virtual students are often controlled by \nexperts or actors impersonating students. This not only increases \nthe manpower required to run each training session but also \nmakes it difficult to present different teachers with identical \nstimuli or to expose a single teacher to the same sequence of \nevents multiple times.\nAnother important difference with 3B and existing educational \ntraining simulations, such as TeachLivE (Hayes et  al., 2013b), \nis the high level of visual and auditory immersion provided by \nour system. The visualization of the classroom through a head-\nmounted display (HMD) and headphones increases the teachers’ \nillusion of place and plausibility, resulting in more realistic teacher \nbehavior (Slater, 2009) and eliciting stronger emotional response \nto and involvement in virtual student behaviors (Sanchez-Vives \nand Slater, 2005). In addition, the evaluation of the teachers’ \nperformance should be more systematic, standardized, and con-\ntrolled by the system. Finally, instructors should be able to send \nfeedback and guidance during the session and after the sessions. \nConsequently, the main system characteristics are translated into \nfunctional and non-functional requirements of the immersive \nCRM training system as follows:\nR1 affordability and mobility: low-cost and easily installed in any \nroom without requiring additional infrastructures\nR2 extensibility and adaptability: possibility to add more scenarios, \nvirtual agents, and behaviors without re-implementing large \nparts of the system\nR3 simplicity: simple control of student behaviors to trigger dif-\nferent levels of stress, ability to provide simple method to give \nsynchronous (after-action-review) and asynchronous (after-\nsession-review) feedback\nR4 believability : realistic (in a behavioral view), compelling \nimmersive simulation of classrooms with a large number of \nstudents\nR5 safety and comfort: does not induce cybersickness or discom-\nfort during or after the session\n3. SySTeM DeScRIpTIon\n3.1. \no\nverview\nOur system is a collaborative virtual reality (VR) platform where \nboth a teacher (trainee) and an instructor (trainer and operator) \nare interacting in a shared virtual environment. The teacher is \nimmersed in a virtual classroom environment using a head-\nmounted display (HMD), while the instructor is interacting with \nthe same environment through a 2D graphical user interface \n(GUI). As depicted by Figure 1, our system adopts a distributed \narchitecture where a server is responsible for the VR simulation, \nand a client is sending commands updating the server’s virtual \nworld state. The client is also simulating its own version of the \nvirtual world. However, it constantly receives updates from \nthe server during a process called replication , which guarantees \nthe synchronization of virtual object states on both virtual worlds.\n7\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nFor instance, to request the virtual agent of a particular \nstudent to perform a disrupting behavior, such as texting on a \nmobile phone, the client will send a command  to the server, also \ncalled a remote event invocation . On reception of this event, the \nserver will interpret it and will start playing the corresponding \nanimation on the targeted virtual agent. The name of the anima-\ntion as well as its parameters will then be sent to the proxy ver -\nsion of this virtual agent on the client (replicating agent behavior \non the server). Objects running on the server are thus referred \nto as Master, and their copies on the client(s) are named Proxy . \nConsequently, both client and server are then displaying the \nsame animations at the same time. The instructor and teacher \nboth observe the same behavior on different machines with dif-\nferent views customized for their individual tasks.\n3.2. Software and hardware\nThe overall system is built on the top of the Unreal Engine 4×™ \n(Epic Games Inc, 2015). The teacher’s view is rendered to the \nOculus Rift DK2 HMD (Oculus VR LLC, 2016), and the teacher’s \nmovements are captured by the Rift for head movements and \nby the Microsoft Kinect v2 (Microsoft C, 2016) for body move-\nments. Movement data are embedded into the main system by \nthe Kinect4Unreal plugin (Opaque Multimedia C, 2016). The GUI \nas been developed using the unreal motion graphics UI designer \n(UMG), a visual UI authoring tool, which can be used to create \nUI elements (e.g., in-game HUDs, menus, buttons, check boxes, \nsliders, and progress bars) (Epic Games Inc, 2016).\n3.3. Teacher’s Interface\nThe teacher’s interface fully immerses the user by appropriate \nhead-tracking and perspective projection and display to the \nHMD as can be seen for the two individual per-eye views on \nthe right in Figure 1. The teacher appears standing in front of a \ncrowd of virtual students in a classroom. The teacher can freely \nmove around in a zone equivalent to 2.5 × 2.5 m and can interact \nwith the students using speech and gesture. The walking zone \ncorresponds to the maximum head and body tracking zone. The \nlimits of this zone are represented in the virtual environment by \nwarning-strip bands located on the floor.\n3.4. Instructor’s interface\nThe layout of the instructor interface is illustrated on the left in \nFigures 1 and 2. The GUI design has gone through multiple itera-\ntions and user evaluations during its development. The interface \nconsists of five main parts (here called boards):\n \n1.\n I\nnstructions board: this board is used to display the sequence \nof instructions to follow, as well as time left for the session \n(visualized using a progress bar), together with buttons to \nstart, stop, and pause the session.\n \n2.\n V\nirtual student control board : this board has multiple func-\ntions. It permits control of the overall level of disruption of the \nentire class using a simple slider, from Null to Extreme. It also \npermits activation or deactivation of bad behavior or dialog \nfor individuals. The instructor can simply enable/\n di\nsable \nbehaviors or dialog by drag-and-drop of respective icons \nfrom the behavior and dialog store on the right of the board \nto the seating plan on the left or to the bin (see Figure  3). \nFor convenience, a Clear All button is present to remove all \ncurrent behaviors in one click. This feature was added after \nobservation of instructor behavior during our pre-study and \ninformative evaluations. Our system provides six different bad \nbehavior types, and twenty different dialogs divided into a \nsimple and an advanced category. The former contains generic \nquestions, such as Why?, and Why not?, or When?, and short \nresponses, such as Yes, No, and Not sure. The advanced dialogs \nare more complex and specific, such as Is mobile phone usage \nauthorized during the trip? The system has been developed to \neasily insert new dialogs by importing sound files to specific \ndirectories and following a simple naming convention.\n \n3.\n V\nirtual environment viewport: it displays the virtual class \nenvironment in a non-immersive 3D rendering from one of \nthree potential points of view to monitor the overall situation, \nthe behaviors of the students, and the reactions of the teacher. \nThe students currently observed by the teacher are always \nhighlighted in red in all of these views. We refer to this as the \nteacher’s focus.\n \n4.\n C\namera control board: it allows users to switch the point of \nview of the virtual environment viewport camera between (i) \nfront, (ii) back of the class, and (iii) teacher’s viewpoint (see \nFigure 4).\n \n5.\n F\needback board: it allows two types of feedback (see Figure 3 \nleft and center):\n(i)\n S\nynchronous feedback during the session by pressing \n“Thumb-up”/“Thumb-down” buttons. Audio cues with \npositive or negative connotation are associated with these \nbuttons. For instance, when pressing the Thumb-up but-\nton to communicate positive feedback, the teacher hears \na ding sound, representing the instructor’s approval. The \nThumb-down button, triggering a buzz sound, commu-\nnicates negative feedback (see Figure 3 left and center). \nThe purpose of synchronous feedback provides a simple \nmechanism for guiding the teacher during the lecture \nwithout completely interrupting the session. There is an \noption that permits the instructor to enable or disable \nthese features, thereby muting the feedback.\n(ii)\n  A\nsynchronous feedback, which consists of a more detai-\nled evaluation form, initially summarizing the teacher’s \nperformance for the session. This feedback uses a list of \nitems and scales to assess the teacher’s overall performan-\nce by the instructor (see Figure  3 center for the list of \nitems).\nBoth feedback types are automatically logged for each session. \nThey are used as performance indicators to measure teacher \nprogress from one session to another.\n3.5. Virtual environment\nThe virtual training environment is modeled as a typical class-\nroom, as illustrated in parts of the Figures 1, 2, and 4. It is equiva-\nlent to a room with physical dimensions of 15 m  × 20 m × 3 m, \ncapable of accommodating up to twenty-four seated students. \nOur system currently provides a pool of thirty different student \ncharacters. From this pool, the system randomly generates a class \nFIgURe 3 | Feedback and control mechanisms. Two buttons for the selection of approval or disapproval sound cues for synchronous feedback (left). One \nbutton for the activation of an evaluation form at the end of the session for asynchr\nonous feedback (center). A drag-and-drop interaction technique is used to assign \nbehavior or dialog to virtual students (right). Here, the student in the third row and second seat will start typing on a mobile phone.\nFIgURe 2 | The instructor interface consisting of five main control areas for different input/output types of operation (for details, see text).\n8\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nof twenty-four students at the start of each session (providing \nover 500,000 possible configurations). The characters have been \ndesigned to give each of them a distinct individual appearance, \nso that the teacher can identify and name them clearly by shirt, \nhair, and so on. Additional variety is generated to represent dif-\nferent ethnicities, body proportions, and sizes as well as a small \ncollection of stereotypical personae (e.g., fashion-conscious, \nintellectual, athletic).\nThe software used to model these characters was Autodesks \nCharacter Generator (Autodesk, 2016a). To achieve realistic \nanimations, we used the IpiSoft Recorder (iPiSoft I, 2016b) and \nMocap Studio (iPiSoft I, 2016a). Results were then edited and \nFIgURe 4 | Different camera views of the class proposed to the instructor. A red outline highlighting indicates, which student is currently observed by the \nteacher\n. A generic teacher’s avatar shows the teacher’s body motion and movement. The warning bands on the floor indicate the walking zone limits for the teacher \n(tracking zone limitations).\n9\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\napplied to our characters in Autodesk MotionBuilder (Autodesk, \n2016c) and Maya (Autodesk, 2016b) before being finally imported \nin the Unreal Game engine using the FBX file format. The final \nnumber of triangles per character is between 7,500 and 12,500 \ntriangles, with a total of approximately 843,000 triangles for the \nwhole environment (including furniture, walls, and window). \nThe environment also includes ambient sound coming from the \noutside countryside (e.g., wind and bird sounds).\n3.6. System Modules and Student \nBehavior \nc\nontrol\nOur system uses a head-mounted display (HMD) to provide \nthe trainee teacher with visual and auditory immersion into the \nvirtual environment. Figure 1 illustrates the overall control flow \nand modules involved in the simulation of the virtual environ-\nment and, in particular, in the student behavior generation and \nreplication.\nWe adopted a client–server design, where the server renders \nan immersive VR version of the virtual world (i.e., a head-tracked \nperspective–correct stereoscopic 3D rendering) while the client \nprovides a non-stereoscopic view of the same virtual world. The \nserver is a Listen  game server, which accepts connections from \nremote clients while locally rendering the game world for one \nplayer on the same machine. This local player is directly connected \nto the HMD, which provides the best immersive experience for \nthe teacher in terms of high frame rate and low end-to-end \nlatency [i.e., here, the delay between users’ head movements and \nvirtual cameras’ update (Lugrin et al., 2013)]. The server is the \nauthoritative master simulating the virtual environment, which \nmeans that it is controlling the world state update on the clients. \nThe clients are predictive clients  independently simulating their \nown version of the virtual word in between the server’s replication \nmessages. In our system, we currently use one client representing \nthe instructor’s view.\nThe additional synchronization overhead for the client is \ntolerable due to the reduced real-time requirements for the non-\nimmersive instructor interface. It is important to note that the \nsystem could accommodate multiple instructor views at the same \ntime, which could be locally or remotely connected machines.\nThe system architecture is decomposed into the following \nmodules developed on top of the game engine (see Figure 1).\n•\n A\npplication controller master is receiving commands from \nthe application controller proxy running on the client, which \ntranslates GUI interactions to commands and sends them to \nthe server via the network (UDP). The application controller \nmaster acts then as a relay module to the session, feedback, and \nbehavior controller. Additionally, it is responsible for logging \nall events and commands.\n•\n S\nession controller is responsible for handling commands \nrelated to the training session such as starting, terminating, or \npausing.\n•\n F\needback controller is handling positive and negative feedback \ngiven by the instructor and whether it is audible by the teacher \nor not.\n•\n B\nehavior controller is interacting with the Blackboard of \neach virtual student  for categorized behaviors or individual \nbehavior.\n•\n V\nirtual student master: all simulated virtual students have two \ntechnical incarnations: the Master incarnations are running on \nthe server while their copies running on the client are labeled \nProxy. Each Master is composed of three main sub modules:\n –\n A b\nlackboard used as a central shared storage of values to \nbe accessed by all modules responsible for student behavior.\n –\n A be\nhavior tree permanently watching blackboard  values \nupdated by other modules to react to changes. As explai-\nned in the following section, it controls behavior by logical \ndecisions based on certain conditions.\n –\n A \nperception module that recognes and locates audible \nand visual events inside the virtual world, such as, the po-\nsition of the teacher, the funny noises, or any disrupting be-\nhavior made by other students around them. This module \nupdates the blackboard  accordingly, possibly triggering \nother branches in the behavior tree.\n –\n A\nn animation state machine that controls the animations \nand their transitions on the server, triggering sounds and \nspawning objects. The animation state machine proxy  is \nautomatically receiving the animation state of the Master  \nentity and starting to play the animation on the client.\nFIgURe 5 | The overall behavior tree controlling the behavior of the virtual students. It is decomposed into three main parts: (i) one for immediately \nchanging the student behavior when r\nequested by the instructor (reset subtree, left), (ii) one for automatically making the virtual student attending a disruption \nsource, such as a student making a noise (attention subtree, middle), and (iii) one for automatically selecting a behavior according to the current bad behavior level \n(idling subtree, right). The conditions to activate a subtree are checked by scanning-specific blackboard values, which reflect the overall state of the simulated \nenvironment and instructor’s commands.\n10\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\n3.6.1. Behavior Tree: Virtual Student Behavior \nAlgorithm\nEach virtual student is driven by a behavior tree connected to the \nvirtual world through individual perception and behavior control-\nler modules; both of them are using a blackboard  data structure \nto communicate (see Figure 1). The behavior tree’s main role is \nto determine the active animation to play for a virtual student’s \nanimation state machine. This finite state machine handles anima-\ntions, their transitions, and the control of corresponding sounds.\nThe perception module helps to create a more believable \nenvironment and adds more dynamics to the scene by adding \nthe ability for virtual students to react to each other. It basically \nemulates humanoid senses, in this case hearing and sight, which \ncan be limited to realistic values. When a sound event is rec-\nognized, the perception  module decides whether the perceiving \nstudent should react to it or not. In case of a reaction, the sound \nlocation and a trigger are stored on the blackboard  to tell the \nbehavior tree to react to the event as well as to know where it \ncame from. Simultaneously, sight is used to locate the teacher and \nmake the student face the teacher in suitable animation states. \nAs seen in Figure  1, the behavior tree  is scanning the stored \nblackboard values for changes and selects a reaction based on \nlogical conditions. This scan is performed every five seconds. \nThis interval is customizable to allow fine-tuning of the agents’ \noverall responsiveness with respect to the available computing \nresources.\nThe behavior tree  has been implemented using the unreal \nengine’s behavior tree editor and blueprint visual scripting . The \nbehavior tree itself can be split into three subtrees, which repre-\nsent one task each, as illustrated in Figure 5. The target subtree \nto be executed is determined by checking for certain conditions \non variables contained in the blackboard as well as the tree’s hier-\narchical order from left to right. The tasks of the three subtrees \nare as follows:\nThe reset subtree (Figure 5, left) is executed if a new level of \nclass disruption is selected (changing the current bad behavior \ncategory). Once the user moves the overall class behavior slider, \na level reset trigger variable is set to true inside the blackboard. It \nactives the corresponding animation set associated with a par -\nticular level of disruption (i.e., null, low, mid, high, or extreme). It \nthen immediately chooses an animation from this new animation \nset. This provides immediate behavior changes and, hence, highly \nreactive students when changing the class behavior by instantly \nstopping their current animation and starting to play an appro-\npriate new one.\nThe attention subtree (Figure 5, middle) is executed when the \nattention trigger is set to true by the perception module. As a result, \na special attention animation is displayed by the student. It makes \nthe student turn his/her head toward the student who has emitted \nthe sound event. It then plays as random animation as a reaction \nto it. After a randomly short amount of time, the attention stops \nand the student returns to it previous animation state.\nFIgURe 6 | An overview of the experimental setting. The instructor \nstation running the 3B client interface is located in the for\neground. The \nteacher, equipped with a VR headset, can be seen in interaction space in the \nbackground.\n11\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nThe idle subtree (Figure 5, right) is executed when none of the \nothers are currently active and no individual behavior is selected \nby the instructor. Its task is to create a living environment by \noccasionally changing the animation to a randomly selected one \nfrom the active animations list.\n4. eVAlUATIon\nThe affordability and mobility  requirements of our system are \nmet by the use of low-cost, off-the-shelf equipment with no \nneed for calibration of hardware or software. Its extensibility and \nadaptability come from simple and fast integration of new assets \n(e.g., student character models, animations, sounds) into our AI \nsystem without requiring systemic modifications. For instance, \nonce a character model or animation has been imported into an \nUnreal asset package, a simple reference to its name and associ-\nated categories of bad behavior (i.e., null, low, medium, high, and \nextreme) is all that is required for the model to be included in the \nsystem. For the other requirements—simplicity, believability, and \nsafety and comfort—a user study was executed. As part of this \nstudy, we evaluated the system’s acceptability from the perspective \nof the future user target group and the effect of synchronous feed-\nback cues on trainees’ experience and acceptance. Our evaluation \nmethods and results are described in the rest of this section.\n4.1. pre-User Study: latency \nMeasur\nements\nWe first evaluated the system performance in terms of the aver -\nage frame rate and end-to-end latency perceived by the teacher. \nThis is the critical technical component to simulate a believable \nenvironment for the teacher and to ensure a safe and healthy envi-\nronment that does not induce cyber sickness and which provides \nan acceptable user experience.\nTo guarantee that our system provides synchronous temporal \nvisuomotoric stimulation, we performed video-based measure-\nments of the end-to-end latency using a frame-counting method \nas described by He et  al. (2000). This method is less accurate \nthan the pendulum method discussed by Steed (2008) but is \nbetter adapted to immersive game measurements (Lugrin et al., \n2012). The average end-to-end latency between movements of \nthe participant’s head and corresponding updates of the projected \nimages was evaluated to approximately 73 ms (±SD 45), which is \nbelow the threshold required for real-time interactions [≤150 ms \n(Lugrin et al., 2012)]. Measurements were realized with videos \nrecorded at 480 Hz with the Casio EX-ZR200 camera at a resolu-\ntion of 224 × 160. The overall system delivered an average frame \nrate of 75  frames per  second for an average number of 400  K \ntriangles per frame.\n4.2. User Study: experimental Design\nThe overall setup of the experimental design is illustrated in \nFigure 6. The idea of the user study follows the proposed method \nby Barmaki and Hughes (2015b). Our experiment simultaneously \ninvolved participant pairs of teacher and instructor, each one \nhaving a different task: (i) the teacher task was to perform a short \npresentation in front of our virtual classroom; and (ii) the instruc-\ntor task was to slowly increase the class agitation, interleaving bad \nbehaviors and dialog phases during the teacher’s presentation, \nand evaluating the teacher’s performance.\nEach session took seven minutes. We tested two conditions, \nwith and without synchronous feedback to the participants as \nfactors using an in-between design. Feedback was initiated by \nthe instructor using the interface illustrated in Figure 3 left and \ncenter. Instructors were repeatedly reminded to give feedback \non their teacher’s reaction: the instructor interface displayed an \nanimated message with sound, “Please give feedback, ” thirty sec-\nonds after each new bad-behavior-activation instruction. It was \nthen the instructor’s responsibility to judge the teacher’s reaction \nor absence of reaction as good or bad. One advantage of virtual \ntraining is that it  can easily support different forms of continuous \nfeedback to guide, encourage, or motivate the trainees during a \nsession. Therefore, one important aspect of our experiment \nconsisted of investigating the possible impacts of synchronous \naudio feedback cues on the teachers’ experience. Previous work \n(Barmaki and Hughes, 2015b) demonstrates the positive impact \nof continuous feedback on teachers’ body language also using \nsimple visual indications in a mixed-reality setting. Their system \ninforms teachers in real-time when they are adopting a closed \nposture (i.e., defensiveness or avoidance body posture, such as \nhands folded in front or hands clasped in back). The feedback \ntook the form of a simple square’s turning orange when detecting \na closed-posture. This visual indication was displayed on a screen \nnext to the virtual classroom visualization screen. Results sug-\ngested that this feedback was successful in providing participants \nwith a better awareness of the message they were sending though \ntheir body pose.\nOur intention is, then, to explore the effectiveness of simple \naudio feedback signals within an immersive VR system. We aim \nto determine if such feedback is beneficial or disruptive. Our \nFIgURe 8 | Variation of the level of bad behaviors during the experiment, controlled by the instructor. The sections 1–5 represent the different phases in \nthe task scenario, wher\ne the level of disruption was increased or decreased by the instructor using group or individual behavior control.\nFIgURe 7 | The timetable for the school trip to london to be explained by the teachers. This schedule was sent to participants 2 weeks prior to the \nexperiments. It was also pr\nesent in the virtual world in two places (A) on the virtual whiteboard behind the teacher and (B) in front of the first table row. The latter \npositioning is due to the inherent limitation of the front-facing camera used by the current HMD (Oculus DK2) for positional tracking. Excessive head rotation toward \nthe whiteboard causes tracking loss, creating jerky camera movements and so resulting in a significant discomfort for the teacher. Therefore, we introduce a \nschedule reminder version in front of the Teacher. It considerably reduces their tendency to completely turn their back to the tracking system for every timetable \ndetails. This issue is now solved with the new consumer version of Oculus Rift and HTC vive.\n12\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nexpectation is that it helps trainees in providing a certain aware-\nness of their performance difficulties in real time, allowing them \nto adopt a different strategy to deal with the situation at hand. \nAt the same time, there is a risk that such feedback leads to a \ndiminishing of the teachers’ sense of immersion, suspension of \ndisbelief, motivation or concentration, and focus on the task at \nhand. Providing an answer to this question can have a critical \nimpact on the overall system’s acceptance and effectiveness, and \na clear answer could not be clearly discerned from previous work \nalone. Consequently, we evaluate whether synchronous audio \nfeedback is an effective feedback mechanism, or whether it is a \ndisruptive influence on the training simulation.\n4.3. experimental Tasks\nThe task of the teacher was to present the organization of a school \ntrip to London in the context of an English course in high school \nfor teenagers from sixteen to eighteen years of age. This task was \ndivided into the presentation of two main types of information: \nthe trip’s weekly schedule (see Figure 7) and the explanation of \nthe school’s rules and policies (e.g., no smoking, no alcohol, no \ndrugs, bed time). Teachers were also asked to reply to possible \nstudent questions. The task design incorporated interdisciplinary \napplicability because it did not involve knowledge of specific sub-\njects taught. As a result, it also reduced cognitive and preparation \ndemands for the teachers. Finally, the organization of school trips \nor excursions is a recurring task in a teacher carrier, which they \nshould be prepared to face. The excitation usually caused by the \nannouncement of extra curriculum activities is usually prone to \nprovoke extra disturbances among students.\nThe task of the instructor was to control and adapt the \nstimuli, or the (disruptive) behavior of the students, to reflect \nsuch excitation and agitation, and to evaluate the teacher’s per -\nformance. We designed a set of instructions that should ideally \nreproduce a scenario in which an entire classroom could rapidly \nbecome uncontrollable. The overall objective was to simulate the \ntypical class effervescence and fast-growing agitation among the \nstudents.\nFigure  8 outlines the variations of the bad behavior level \nduring the experiment. We defined five main phases with dif-\nferent levels of disturbances. Phases 1 and 5 simulated a chaotic \nclass at the start and end of the lecture. In between, phases 2, \n3, and 4 defined a steady increase in class agitation, which was \nsimulated by subsequently triggering sequences of two low, mid, \nand high-level bad behaviors, intertwined with dialog  phases. \nTABle 2 | list of predefined instructions to follow, their durations, and their respective types.\nId Instructions Duration (s) Type\n1 Increase the class behavior level slowly up to extreme 20 Class-bad-behavior\nWait for the teacher to react 7 Observation\nDecrease it to quiet 7 Class-bad-behavior\nDo not forget to give feedback 7 Feedback\n2 Create blue disturbing behavior in the front of the classroom on a pupil outside teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n3 Create blue disturbing behavior in the front of the classroom on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n4 Create a dialog in front of the class on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n5 Create yellow disturbing behavior in the middle of the classroom on a pupil outside teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n6 Create yellow disturbing behavior in the middle of the classroom on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n7 Create a dialog in front of the class on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n8 Create red disturbing behavior in the front of the classroom on a pupil outside teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n9 Create red disturbing behavior in the front of the classroom on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n10 Create a dialog in front of the class on a pupil in teacher’s focus 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\n11 Progressively increase the class disturbance level 20 Class-bad-behavior\nWait for the teacher to react 7 Observation\nDecrease it to quiet 7 Class-bad-behavior\nDo not forget to give feedback 7 Feedback\n12 Lesson is finished, use the feedback panel to give a feedback for the whole lesson 20 Bad-behavior\nWait for the teacher to react 7 Observation\nDo not forget to give feedback 7 Feedback\nInstructions and durations were displayed on the instructor’s graphical interface and signaled on screen using both visual cue (color animation) and audio sound cue (bip).\n13\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nThe instructions were prompted at the top of the instructor inter-\nface screen (see top of Figure 2). The instructor had to execute \nthe instructions and evaluate the teacher’s reaction using the syn-\nchronous feedback buttons. The complete list of instructions is \npresented in Table 2. These instructions were generic (e.g., create \nblue disturbing behavior in the front of the classroom on a pupil \noutside teacher’s focus). This gave a certain degree of freedom to \nthe instructors with regard to the exact behavior and student to \napply the behavior to.\n4.4. Measures\n4.4.1. Simulator Sickness\nWe measured simulator sickness for the teachers before and after \nthe induction using the simulator sickness questionnaire (SSQ) \n(Kennedy et al., 1993). This questionnaire was used to evaluate \nthe safety and comfort requirements. The results were also used \nto sort out participants, if applicable.\n4.4.2. Behavior Categories\nFor the evaluation of our stress and bad behavior induction \nscenarios, we included questions to see if the categoric levels of \nbad behavior matched the users’ perceptions, such as, “Please \nindicate if these disruptions are correctly categorized as a low \nLevel disruption. ”\n4.4.3. Presence, Immersion, and  \nSuspension of Disbelief\nTo evaluate the teachers’ quality of experience, we included the \nteacher experience questionnaire (Hayes et al., 2013a). To allow \nfor a quantitative comparison and analysis of potential effects \n14\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nbetween feedback conditions, we changed the student questions \nfrom qualitative to individually stated Likert-scale responses \n(1 = not at all, 5  = very much) with an additional comment of \nWhy? as a qualitative text-based answer. Teachers responded to \nquestions about their simulation experience related to suspension \nof disbelief, presence, fidelity, and immersion:\n 1.\n O\nverall, how successful do you feel your virtual rehearsal \nperformance was?\n 2.\n H\now can you tell that the students are engaged or not engaged \nwith you?\n 3.\n H\now did the virtual students compare to students you encoun-\nter in a classroom?\n 4.\n H\now did the virtual classroom compare to your experience of \na physical classroom?\n 5.\n W\nhen you were teaching the virtual students, were you able to \nsuspend disbelief?\n 6.\n W\nhen teaching the students, did you feel like you were in the \nsame physical space as they were?\n4.4.4. Intuitive Use and Task Load\nFor a basic usability evaluation of the instructor interface, we \nincluded the following two questionnaires:\n•\n N\nASA TLX: to measure cognitive and physical workload esti-\nmates from one or more operators while they are performing \na task or immediately afterward (Hart and Staveland, 1988).\n•\n Q\nUESI: to measure the subjective consequence of intuitive \nuse by Hurtienne and Naumann (2010). The questionnaire \nconsists of fourteen items dividing intuitive use in five factors \n(low subjective mental workload, high perceived achievement \nof goals, low perceived effort of learning, high familiarity, and \nlow perceived error rate).\n4.4.5. Technology Acceptance\nFor a user-centered evaluation of the system, we included two \nLikert-scale questions (1  = does not apply all, 5  = completely \napplies) for each requirement (mobility, price, usability, close-\nness to reality, study improvement, and system enhancement), \nsuch as, “The system mobile enough to be set up easily for a \nsimulation, ” and “I could easily explain the usage of the system \nto my colleague, ” and both participant groups. Items were \nrecoded where necessary.\n4.4.6. Performance\nWe evaluated instructor and teacher’s performances with differ-\nent metrics:\n•\n T\neachLivETM teacher performance (Hayes et al., 2013a): teach-\ners responded to questions about their CRM performance. \nThis questionnaire was also given to the instructors to evaluate \nthe respective teacher performance.\n•\n T\neacher task performance: number of positive and negative \nsynchronous feedbacks received as well as final score evalua-\ntion with asynchronous feedback (see Figure 3, center).\n•\n I\nnstructor task performance: number of behaviors, dialogs, \nand feedbacks generated, number of commands following \nthe instructions given, number of errors, and number of extra \ncommands.\n4.5. Apparatus\nThe hardware setup consisted of a Microsoft Kinect 2 sensor, \none client PC (Quad core 3.7 GHz, 16 GB RAM), and one server \nstation (Intel Core i5-6600K 3.50  GHz CPU, 16  GB of RAM, \nAMD Radeon R9 390 Graphics card). As depicted by Figure 6, \nteachers were visually immersed in a virtual environment using \nthe Oculus Rift DK2 stereoscopic HMD, with a field of view of \n100° horizontally, a resolution of 960 × 1080 pixel per eye, and a \nrefresh rate of 75 Hz. The cost of the overall setup was approxi-\nmately 2500 €.\n4.6. procedure\nAs illustrated in Figure  9, the overall experiment followed ten \nmain stages:\n \n1.\n P\nre-questionnaires: let teacher and instructor complete a \nconsent form and a demographic questionnaire. Let teacher \nfill out the pre-SSQ questionnaire.\n \n2.\n C\nonditions: let teachers throw a die to determine whether or \nnot they will receive synchronous feedback. In case of a value \n<4, they were informed about the feedback mechanism. We \nused a non-algorithmic randomization method for group \nassignments, and counterbalancing was applied at the end to \nproduce a group of same size.\n \n3.\n I\nnstructor training: instructor was introduced to the graphical \nuser interface (GUI), its features and controls, by the experi-\nmenter in about three minutes. Then the instructor started a \ntwo-minute training scenario, with no teacher in the virtual \nenvironment. During this time, the instructor had to follow a \nseries of six instruction messages appearing on the screen. The \nexperimenter assisted the instructor if questions or mistakes \nwere made. At the end of the session, the experimenter asked \nif further training was necessary and went through the task \nflow once more (i.e., read instructions, executed them, and \nread the next one).\n \n4.\n S\ntudent training : equip participants with the HMD and \nimmerse them in the virtual classroom. Calibrate the HMD \nfor comfort and correct stereoscopy. Ask them to walk around \nin the virtual room to get familiar with wearing the HMD and \nnavigating the virtual environment. As illustrated in Figure 4, \nthe walking zone was delimited by warning bands on the \nfloor and corresponded to a zone of 2.5 × 2.5 m. Participants \nwere also instructed to check their virtual blackboard and \nto report if they felt anything unnatural or uncomfortable. \nThis session lasted from two to four minutes, depending on \nthe participant’s questions or adjustments needs. During this \nphase, the classroom was populated by students in a “quiet” \nbehavior mode.\n \n5.\n B\nreak: ask participants if a break was necessary before con-\ntinuing with the experiment.\n \n6.\n E\nxperiment start: once experimenters verified that both \nparticipants were ready to start, they signaled the instructor \nto press the Start  button. Then a school’s bell ringing sound \nFIgURe 9 | experiment protocol overview (left), with detailed flow chart of instructor’s experimental task design (right).\n15\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\ninformed the teacher and instructor of the start of their \ntasks.\n \n7.\n E\nxperiment: without any help from the experimenters, the \ninstructor had to follow the instruction popping up on screen, \nwhile teachers started their presentation and were presented \ndifferent students’ behaviors.\n \n8.\n E\nxperiment end: after seven minutes, another school bell \nsound signaled the end of the task. Teacher were then de-\nequipped, taking off headphones and the HMD.\n \n9.\n P\nost-questionnaires: ask participants to fill out the rest of the \nquestionnaires:\n•\n F\nor teacher: post-SSQ, TeachLivE™ teacher experience \nand performance, presence, bad-behavior categories, and \ntechnology acceptance questionnaires\n•\n F\nor instructor: QUESI, NASA TLX, TeachLivE™ teacher \nperformance, bad-behavior categories, and technology \nacceptance questionnaires\nThe whole experiment took approximately forty to sixty \nminutes, depending on the break time each participant needed.\n4.7. Sample\nOur total sample consisted of twenty-two (German) participants, \ndivided into one teacher group and one instructor. All the partici-\npants were following the previously mentioned CRM seminars in \nthe context of their bachelor of educational science and pedagogy \nat the University of Würzburg. The mean age of the teacher  \ngroup was 21.45 (SD\nage  =  1.86), and six of the eleven teachers \nwere females. None of them had severe visual impairments, all of \nthem were students, and none of them had previous experience \nwith VR. In the instructor group (M\nage  =  21.73, SDage  =  2.87), \nnine subjects were females, and ten were students. None of them \nhad previous experience with VR systems, but they used a PC \nregularly (M = 5.27 where 1 was not at all and 7 was very often, \nSD  =  1.1). The participants were grouped in pairs of two: one \nteacher and one instructor. The eleven pairs were then divided \ninto two groups; six subject pairs received continuous instruc-\ntor feedback, and five pairs did not. The instructor’s feedback \nconsisted of short audio cues with strong positive or negative \nconnotations. Both groups received different instructions prior \nto the experiment:\n•\n T\neacher: classroom management seminar\n –\n P\nreparation task: two  weeks before the experiment, stu-\ndents received the task description and were required to \nprepare their presentation.\n –\n R\nationale: students have spent ten weeks in a seminar di-\nscussing coping and prevention strategies for controlling \nbad behaviors.\n•\n I\nnstructor: video-based reflection of education seminar\n –\n P\nreparation task: two  weeks before the experiment, stu-\ndents were required to prepare an evaluation form to quic-\nkly assess a teacher’s ability to manage classroom behavior.\n –\n R\nationale: students have spent ten  weeks in a seminar \nanalyzing teachers’ behavior, techniques, and good and \nbad qualities based on different video sources.\nFIgURe 10 | The results of the TeachliveTM teacher performance questionnaire for the teachers.\n16\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nHowever, the actual experiment procedure, objective, and \nsystem were never disclosed to the students. Students were told \nonly that they would use these preparative works in an exercise \ninvolving a virtual classroom.\nThe purposes of these pre-experiment instructions were \nmultiple. The first was to evaluate the system within its intended \ncontext of use: as part of existing seminars related to class man-\nagement. Second, without preparation, the teacher’s task (making \na presentation in front of classroom on a particular topic) would \nbe difficult to improvise and could create additional stress. Both \nwould interfere with the actual system perception, its possible \nusefulness, and the measure of the stress induced by the system. \nSimilarly, for the instructor’s task, to quickly give correct and \nconstructive feedback, seminar students should have already \nprepared certain evaluations criteria. Both student groups have \nacquired the theoretical knowledge, which could be applied in \nthe 3B simulation as teacher or instructor. They are thus very \nrepresentative of the future target audiences for our training \nsimulations. In addition, they could provide us with interesting \ninsights regarding possible improvements and the permanent \nintegration of such a system into their current teacher education \ncurriculum.\n5. ReSUlTS\n5.1. Simulation \ne\nffects\nConcerning the teach-live questionnaire results, all dimensions \nwere rated equal or higher than scale average (see Figure  10). \nWhile the highest ratings were achieved on the dimension of \nbeing in the same physical space (M  =  4.09, SD  =  1.22), sub-\njects were most unsatisfied with their performance (M  =  3.00, \nSD = 1.00) and the similarity between virtual and real students \n(M = 3.09, SD = 1.044). To further investigate causes, we looked \nat the students’ ratings of the behavior categories and found that \neight of out eleven reported that the lower bad behaviors (e.g., \nsleeping, mobile phone usage) should be set to a higher level.\n5.2. Instructor Interface Usability\nThe task load for the instructors to interact with the system \nwas low [M  = 6.42, SD = 3.42 compared to scale average (scale \n0 = low task load, 20 = high task load, items were recoded where \nnecessary)], indicating that users felt a low task load and the \ninterface control and GUI were neither stressful nor complicated. \nConcerning the scores on the QUESI questionnaire, all dimen-\nsions as well as the total score (M  = 3.83, SD = 0.68) were rated \nwell above scale average (1  = negative perception, 5  = positive \nperception), indicating that users felt comfortable interacting \nwith the system and reached their goals easily and intuitively (see \nFigure  11). Similar score values have been reported for Apple \niPod Touch (5) and iPhone (6) (Naumann and Hurtienne, 2010). \nThe score for the perceived error rate (M  =  4.18, SD  =  0.93) \nunderlines the robust functionality for the operator.\n5.3. Instructors’ performances\nThe total number of instructor’s commands during a session was \non average M = 517 commands (SD = 184.43), ranging from 189 \nto 764 commands. On average, users issued M = 23.54 individual \nbehavior commands (SD   =  10.46, range  =  7–43) and 9 class \nbehavior changes (SD = 5.12, range = 0−19). Furthermore, users \nstarted an average of M  = 3.45 dialogs per session (SD  = 2.70, \nrange  =  0–8). During the simulation M  =  10.36, sounds were \nplayed and the instructors gave M  =  5.54 feedbacks, diversely \nranging from 0 to 11 feedback messages per session (SD = 3.32).\n5.4. Teachers’ performances\nWe averaged the instructors’ asynchronous feedback (five cri-\nteria: time to resolve, time to react, coping strategy, appropriate \nFIgURe 11 | Results from the QUeSI questionnaire evaluating intuitive use of the instructor interface.\nFIgURe 12 | Results from the technology acceptance questionnaire.\n17\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\ntone, and self-control). We then analyzed its correlation with the \nteachers’ subjective ratings of their own performance, measured \nfrom TeachLivE™ teacher performance (Hayes et  al., 2013a). \nAlthough not significant (p = 294), the analysis shows a moderate \ncorrelation between the teachers’ self-evaluations and the evalua-\ntions from the instructors (r = 348), indicating that both teachers \nand instructors had similar impressions.\n5.5. Technology Acceptance\nWe individually assessed both the student group and the instruc-\ntor group for a user-centered system evaluation. In general, the \ninstructor group had a higher acceptance for the technology than \nthe teacher group, except for the question of whether this system \ncould enhance their education, which students rated slightly \nhigher. Scores were above scale average except for the price and \nreality closeness, which students rated lower than expected (see \nFigure 12).\nThe usability score for the instructor underlines the previ-\nous results. Additionally, according to the scores, both groups \nfelt that the system could improve their studies (M\nstudent = 3.27, \nSDstudent  =  1.21, Minstructor  =  3.68, SDinstructor  =  0.96) and could be \nenhanced with additional scenarios (Mstudent = 4.04, SDstudent = 0.79, \nMinstructor = 3.64, SDinstructor = 0.67). The teachers rated an acceptable \nprice of 3.587 € for the system, while seven of eleven students \nfelt that the system should be introduced into their education. In \ncontrast, the instructor group rated an acceptable price of 2.370 €, \n18\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\neven though nine of eleven instructors felt that the system would \nbe beneficial for their education.\n6. DIScUSSIon\nWith respect to the three main aspects of the applicability of the \nproposed system from Section 1.1, the results match the evalua-\ntion criteria as follows:\nE1. Simulation effects by the immersive teacher interface.\n \ni. B\nelievability: the behavior of the virtual students was con-\nvincing and believable, as reported by teachers, and was \ncapable of eliciting stress reactions. This was a critical \nrequirement for a our training simulation. The above-\naverage scores for the items suspension of disbelief and \nsame physical space affirm a compelling reproduction \nof a real environment, which now provides a controlled \nCRM training method.\n \nii.\n C\nybersickness and potential side effects: we observed that \nno simulation sickness was induced by our system. This is \na critical feature, as cybersickness could dramatically in-\nterfere with the objectives of our system (LaViola, 2000). \nDuring the session, it would prevent teachers from lear -\nning and practicing their skills. The after effects would \nalso prevent teachers from performing any other activi-\nties such as assisting other lectures, seminars, or exams, \nand even to safely drive back home.\n \niii.\n E\nffect of feedback cues: it appears that simple synchronous \naudio feedback cues did not affect the overall experience \n(i.e., no difference of immersion, believability, perfor -\nmance, and acceptance) to a strong degree. This result \nmight indicate that real-time sound feedback could be \nused to guide the trainee without interfering with the \n exp\nerience, \n es\npecially with its believability, which is criti-\ncal for stress exposure therapy. However, our results can \nonly be seen as a first exploratory analysis and therefore \nshould not be generalized.\nE2. Usability of the instructor interface:\n i.  T\nask and cognitive load and intuitive usage of the interfa-\nce: the instructor’s GUI was evaluated as good in usability \nand did not have a high task load. The GUI allows them \nto simply control the overall class and individual behavior \nwhile following general instruction and giving teachers \nfeedback. It was also a critical requirement to achieve, \nas the instructor’s job is demanding because it requires \nfrequent shifts of attention and fast evaluation. Our GUI \ndesign and its associated virtual agent control algorithm \nappear to efficiently support these requirements.\nE3. Technology acceptance by teachers and instructors:\nThe system’s price should be low enough, and people felt the \nsystem is beneficial. Overall, our system was well received, \nand more than 80% of participants said our system will \nhelp them in their education and future career. Therefore, it \nappears that our system convinced its possible future users, \nand so its acceptability is fulfilled.\n7. lIMITATIonS AnD FUTURe WoRK\nDespite a limited sample size, our first usability evaluation gave us \npromising results and appears to demonstrate satisfaction with the \ncritical system requirements (i.e., low cybersickness, easy to use/\nlearn, believable, and being accepted). However, our evaluation \nalso revealed certain limitations and improvements to consider. \nOne important improvement of the system will consist of a inte-\ngrating a larger set of possible behaviors to create richer scenarios \nand alternatives. It will require the exploration and evaluation of \nalternative interaction techniques for the instructors to allow \nfor their fast selection and activation. Another aspect regards \nthe integration of facial animations synchronized with text-to-\nspeech and bad behavior animation. The possibility of recording \nlive sessions and later replicating the exact same scenarios is an \nimportant feature under development. We are exploring the pos-\nsibilities to provide an online exchange platform to support the \npublication and sharing of scenarios among instructors to enable \nwidespread use of the proposed system in a teacher education \ncurriculum.\nWe also would like to expand the autonomy of the virtual \nstudents and provide the instructor with an option to be auto-\nmatically driven by physiological inputs such as electrodermal \nactivity and heart rate. Students will then automatically adjust \ntheir behaviors according to the personality and the perceived \nstress level of the teacher. To a certain extent, the students, agita-\ntion will reflect the teachers’ , forcing teachers to control their \nstress to control their class. We are exploring a solution to couple \na pleasure-arousal-dominance model (Mehrabian, 1996) with a \nmultimodal discourse analysis (MDA) module, automatically \ninterpreting teachers’ body language and speech, as by Barmaki \nand Hughes (2015b) and Barmaki (2015). Finally, the question of \na possible uncanny valley effect (Mori, 1970) should be explored, \nespecially with more photo-realistic virtual humans. This effect \ncould dramatically deteriorate the teacher’s experience and cancel \nout any benefits of the immersive VR approach. In our future \nresearch, we are planning to test this hypothesis by replicating our \nexperiment with photo-realistic virtual students.\nFuture prototypes will also evaluate the performances and \naffordances of eye-tracking HMD such as the FOVE VR headset \n(FOVE, Inc., 2015) or SensorMotoric eye-tracking package for \nOculus DK2 (SensorMotoric, 2016). One advantage of eye track-\ning is that it permits users to dynamically increase the rendering \nquality based on the user’s center focus and therefore should help \nto approach photo-realistic quality. It will also permit a more \naccurate visualization of the teacher’s point of gaze. Second, the \noffline analysis of eye movement and focus points will provide \nvaluable input for behavioral and cognitive studies. It could lead \nto the identification of visual attention patterns in stressful situ-\nations, possibly acting as indicator of the teacher’s stress level. \nLast, it will support novel modes of hands-free interactions with \nthe virtual students or environments (e.g., display the student’s \nname, activate or deactivate devices inside the classroom, a menu \nto control the system, navigate inside the class).\nOther important future work consists in realizing a field \nstudy in schools with real teachers who already possess practical \n19\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nexperience in class management. Now that the usability and \nefficiency of the system has offered promising results, we are \nplanning collaborations with local schools on the evaluation of an \nextended version of our system. This includes studies comparing \nour new proposed method to classic theory-based or role-play-\nbased methods.\nConsidering the aspect of the ever-growing mixed-cultural \ncomposition of current classrooms, we believe that our system \nalso has great potential to help teachers enhance their current \nteaching practices to new challenges posed by mixed-cultural and \nmixed-level classrooms. Therefore, in our future work, models of \ndifferent culture-related behaviors need to be modeled to drive \nthe different goals, believes, and behaviors of potential students \nhaving different cultural backgrounds. With these additional \nfeatures, the system could not only be used to prepare teachers \nfor arising changes in classrooms but also serve as showcases to \npupils who are sometimes faced with fixed rule-sets that need to \nbe understood to integrate into existing scholar systems.\n8. conclUSIon\nThis article presented a novel immersive virtual reality CRM \ntraining system. The training of interpersonal skills necessary for \nsuccessful CRM is critical to improve the experiences of teachers \nand students. Therefore, 3B has been designed as a companion \ntool for classroom management seminars in a syllabus for pri-\nmary and secondary school teachers.\nCompared to previous systems, our approach solves both \nimportant functional and non-functional requirements neces-\nsary to the successful integration of a virtual training in teacher \neducation. It is capable of conveying controllable and replicable \nsituations of believable classroom scenarios, including disruptive \nbad behaviors by virtual students, which increases stress for \nthe teacher and hinders easy coping with these situations. The \nsystem also provides interactive control, monitoring, and evalua-\ntion of the current scenario and the teacher’s performance by an \ninstructor.\nThe system allows easy and everyday use in seminar rooms \nand teaching environments while still providing a rich and \ncompelling experience. It uses affordable, off-the-shelf hardware \nand software, and it allows users to come as they are without the \nneed for any extensive hardware and sensor rigging, which is  \ntypical of many VR systems. The 3B project is designed to help \nbeginner, intermediate, and expert teachers to improve their \ntechniques of recognition, anticipation, and quality of reaction \nto disruptive bad behavior to prevent out-of-control situations \nin classrooms.\nOur first evaluation revealed promising results and dem-\nonstrated the successful fulfillment of the critical usability \nrequirements (i.e., safety and comfort, believability, simplicity, \nacceptability, extensibility, affordability, and mobility). This con-\nstitutes the necessary first step toward a possible investigation of \nits efficiency, and effectiveness in terms of learning outcomes and \nexperience with short- and long-term studies.\nAUThoR conTRIBUTIonS\nSubstantial contributions to the conception or design of the work \nwere performed by J-LL, ML, MH, CS, and SG. Initial idea by \nML further pushed on and elaborated by J-LL. Technical develop-\nment by J-LL and MH. Educational aspects contributed by CS \nand SG. Evaluation designed by J-LL, ML, MH, CS, DR, and SG. \nImplementation of the evaluation by MH. Analysis performed \nby J-LL and DR, interpretation done by J-LL, DR, MH, and \nML. Drafting the work or revising it critically for important  \nintellectual content, approval of the version to be published, and \nagreement to be accountable for all aspects of the work in ensur-\ning that questions related to the accuracy or integrity of any part \nof the work are appropriately investigated and resolved by J-LL, \nML, MH, CS, DR, and SG.\nAcKnoWleDgMenTS\nWe would like to thank the following students for their partici -\np\nation in the development of the virtual environment and  \nplat \n    f\norm: David Fernes, David Schraudt, Dominik Lipp, Felix \nBrischwein, Jennifer Haefner, Johannes Lamm, Kristina Pedersen, \nLeon Burkhardt, Nicolas Maltry, Rene Fleischer, Samantha Straka, \nand Sebastian Slowik. This publication was supported by the \nOpen Access Publication Fund of the University of Wuerzburg.\nReFeRenceS\nAlibali, M. W ., and Nathan, M. J. (2007). “ Teachers’ gestures as a means of scaffold-\ning students’ understanding: evidence from an early algebra lesson, ” in Video \nResearch in the Learning Sciences, eds R. Goldman, R. Pea, B. Barron, and S. J. \nDerry (Mahwah, NJ: Erlbaum), 349–365.\nAutodesk. (2016a). Autodesk Character Generator. Available at: https://character-\ngenerator.autodesk.com/\nAutodesk. (2016b). Autodesk Maya . Available at: http://www.autodesk.de/store/\nproducts/maya\nAutodesk. (2016c). Autodesk Motionbuilder . Available at: http://www.autodesk.\ncom/products/motionbuilder/\nBaker, D. P ., Gustafson, S., Beaubien, J., Salas, E., and Barach, P . (2005). Medical \nTeamwork and Patient Safety: The Evidence-Based Relation. Washington, DC: \nAHRQ Publication.\nBarmaki, R. (2015). “Multimodal assessment of teaching behavior in immersive \nrehearsal environment-teachlive, ” in Proceedings of the 2015 ACM on Inter- \nnational Conference on Multimodal Interaction (Orlando, FL: ACM), 651–655.\nBarmaki, R., and Hughes, C. E. (2015a). “ A case study to track teacher gestures \nand performance in a virtual learning environment, ” in Proceedings of the Fifth \nInternational Conference on Learning Analytics and Knowledge (Orlando, FL: \nACM), 420–421.\nBarmaki, R., and Hughes, C. E. (2015b). “Providing real-time feedback for student \nteachers in a virtual rehearsal environment, ” in Proceedings of the 2015 ACM \non International Conference on Multimodal Interaction, ICMI ’15 (New Y ork, \nNY: ACM), 531–537.\nBorich, G. D. (2011). Effective Teaching Methods: Research-Based Practice. Austin: \nUniversity of Texas.\nBrophy, J.\n (2006). \n“History of research on classroom mangement, ” in Handbook of \nClassroom Management. Research, Practice, and Contemporary Issues, eds C. M. \nEvertson, and C. S. Weinstein (New Y ork, NY: Routledge), 17–43.\nBrouwers, A., and Tomic, W . (1999). Teacher burnout, perceived self-efficacy in \nclassroom management, and student disruptive behaviour in secondary educa-\ntion. Curric. Teach. 14, 7–26. doi:10.7459/ct/14.2.02 \nCanter, L. (2011). Assertive Discipline: Positive Behavior Management for Today’s \nClassroom. Bloomington, IN: Solution Tree Press.\n20\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nCanter, L., and Canter, M. (1992). Assertive Discipline: Positive Behavior \nManagement for Today’s Schools. Bloomington: Solution Tree Press.\nCharles, D., Charles, T., McNeill, M., Bustard, D., and Black, M. (2011). Game-\nbased feedback for educational multi-user virtual environments. Br. J.\n \nEduc. \nTechnol. 42, 638–654. doi:10.1111/j.1467-8535.2010.01068.x \nDieker, L. A., Rodriguez, J.\n A., L\nignugaris, B., Hynes, M. C., and Hughes, C. E. \n(2013). The potential of simulated environments in teacher education: current \nand future possibilities. Teach. Educ. Special Educ. doi:10.1177/0888406413 \n512683\nEmmer, E. T., and Stough, L. M. (2001). Classroom management: a critical part of \neducational psychology, with implications for teacher education. Educ. Psychol. \n36, 103–112. doi:10.1207/S15326985EP3602_5 \nEpic Games, Inc. (2015). Unreal Engine 4. Available at: https://www.unrealengine.\ncom/unreal-engine-4\nEpic Games Inc. (2016). Unreal Motion Graphics UI Designer. Available at: https://\ndocs.unrealengine.com/latest/INT/Engine/UMG/\nEvertson, C. M., and Weinstein, C. S. (2013). Handbook of Classroom Management: \nResearch, Practice, and Contemporary Issues. Routledge.\nFOVE, Inc. (2015). Fove HDM with Eye Tracking. Available at: http://www.getfove.\ncom/\nGupta, S. K., Anand, D. K., Brough, J., Schwartz, M., and Kavetsky, R. (2008). \nTraining in Virtual Environments. A Safe, Сost-Effective, and Engaging Approach \nto Training. University of Maryland.\nHale, K. S., Stanney, K. M., Lindgren, R., Moshell, J.\n \nM., and Hughes, C. E. (2014). \n“Virtual environments as a tool for conceptual learning, ” in Handbook of Virtual \nEnvironments: Design, Implementation, and Applications, 2nd Edn (Boca Raton, \nFL: CRC Press), 1043–1055.\nHart, S., and Staveland, L. (1988). “Development of NASA-TLX (task load index): \nresults of empirical and theoretical research, ” in Human Mental Workload, eds \nP . A. Hancock and N. Meshkati (Amsterdam: Elsevier), 139–183.\nHattie, J.\n \n(2003). Teachers Make a Difference, What Is the Research Evidence? \nMelbourne: ACER Research Conference.\nHayes, A. T., Hardin, S. E., and Hughes, C. E. (2013a). “Perceived presence’s role \non learning outcomes in a mixed reality classroom of simulated students, ” in \nInternational Conference on Virtual, Augmented and Mixed Reality (Berlin: \nSpringer), 142–151.\nHayes, A. T., Straub, C. L., Dieker, L. A., Hughes, C. E., and Hynes, M. C. (2013b). \nLudic learning: exploration of TLE TeachLivE\n™ and effective teacher train-\ning. Int. J.\n G\naming Comput. Mediated Simul. 5, 20–33. doi:10.4018/jgcms. \n2013040102 \nHe, D., Fuhu, D. H., Pape, D., Dawe, G., and Sandin, D. (2000). “Video-based \n m\neasurement of system latency, ” in International Immersive Projection \nTechnology Workshop (Chicago), 111.\nHoney, M. A., and Hilton, M. (2011). Learning Science through Computer Games \nand Simulations. Washington, DC: National Academies Press.\nHughes, C. E., and Ingraham, K. M. (2016). “De-escalation training in an aug-\nmented virtuality space, ” in Virtual Reality (VR), 2016 IEEE (IEEE), p. 181–182.\nHurtienne, J., and Naumann, A. (2010). QUESI—A Questionnaire for Measuring \nthe Subjective Consequences of Intuitive Use. Cambridge: Interdisciplinary  \nCollege, 536.\niPiSoft I. (2016a). iPi Mocap Studio . Available at: http://wiki.ipisoft.com/\nIPi_Mocap_Studio\niPiSoft I. (2016b). iPi Recorder. Available at: http://wiki.ipisoft.com/IPi_Recorder\nJones, H. E., Sabouret, N., Damian, I., Baur, T., André, E., Porayska-Pomsta, K., \net al. (2014). Interpreting social cues to generate credible affective reactions of \nvirtual job interviewers. Artif. Intell. arXiv preprint arXiv:1402.5039.\nJones, V . (2006). How Do Teachers Learn to Be Effective Classroom Managers? \nMahwah, NJ: Lawrence Erlbaum Associates Publishers.\nKelly, S. D., Manning, S. M., and Rodak, S. (2008). Gesture gives a hand to \nlanguage and learning: perspectives from cognitive neuroscience, devel-\nopmental psychology and education. Lang. Linguist. Compass  2, 569–588. \ndoi:10.1111/j.1749-818X.2008.00067.x \nKelly, S. D., McDevitt, T., and Esch, M. (2009). Brief training with co-speech gesture \nlends a hand to word learning in a foreign language. Lang. Cogn. Process. 24, \n313–334. doi:10.1080/01690960802365567 \nKennedy, R. S., Lane, N. E., Berbaum, K. S., and Lilienthal, M. G. (1993). Simulator \nsickness questionnaire: an enhanced method for quantifying simulator sickness. \nInt. J.\n \nAviat. Psychol. 3, 203–220. doi:10.1207/s15327108ijap0303_3 \nKenny, P ., Parsons, T. D., Gratch, J., Leuski, A., and Rizzo, A. A. (2007). “Virtual \npatients for clinical therapist skills training, ” in Intelligent Virtual Agents \n(Springer), 197–210.\nKeppell, C. (1998). Virtual reality: what is the state of play in education? Australas. \nJ.\n \nEduc. Technol. 14, 60–74. \nKilteni, K., Groten, R., and Slater, M. (2012). The sense of embodiment in virtual \nreality. Presence Teleop. Virt. Environ. 21, 373–387. doi:10.1162/PRES_a_00124 \nKounin, J.\n S. (1970). \nDiscipline and Group Management in Classrooms. Huntington, \nNY: R.E. Krieger Pub. Co.\nKunter, M., Seidel, T., and Artelt, C. (2015). Zeitschrift für Entwicklungspsychologie \nund Pädagogische Psychologie, Göttingen: Hogrefe.\nLaslett, R., and Smith, C. (2002). Effective Classroom Management: A Teacher’s \nGuide. Routledge.\nLaViola,  J.\n J\n.\n J\nr. (2000). A discussion of cybersickness in virtual environments. \nACM SIGCHI Bulletin 32, 47–56. doi:10.1145/333329.333344 \nLeuski, A., Patel, R., Traum, D., and Kennedy, B. (2009). “Building effective question \nanswering characters, ” in Proceedings of the 7th SIGdial Workshop on Discourse \nand Dialogue (Stroudsburg: Association for Computational Linguistics), 18–27.\nLevin, J., and Nolan, J.\n F\n. (1991). Principles of Classroom Management: A Hierarchical \nApproach. Upper Saddle River, NJ: Prentice Hall.\nLevin, J., and Nolan, J.\n F\n. (2013). Principles of Classroom Management: A Professional \nDecision-Making Model. Pearson Higher Ed.\nLok, B., Naik, S., Whitton, M. C., and Brooks, F . P . (2003). Effects of han-\ndling real objects and self-avatar fidelity on cognitive task performance \nand sense of presence in virtual environments. Presence 12, 615–628. \ndoi:10.1162/105474603322955914 \nLopez, A. L., Hughes, C. E., Mapes, D. P ., and Dieker, L. A. (2012). “Cross-cultural \ntraining through digital puppetry, ” in Advances in Design for Cross-Cultural \nActivities (Part I), ed. D. M. Nicholson. (CRC Press), 247–256.\nLugrin, J.-L., Charles, F ., Cavazza, M., Le Renard, M., Freeman, J., and Lessiter, \nJ.\n (2012). “\nCaveudk: a VR game engine middleware, ” in Proceedings of the 18th \nACM Symposium on Virtual Reality Software and Technology, VRST ’12 (New \nY ork, NY: ACM), 137–144.\nLugrin, J.-L., Wiebusch, D., Latoschik, M. E., and Strehler, A. (2013). “Usability \nbenchmarks for motion tracking systems, ” in Proceedings of the 19th ACM \nSymposium on Virtual Reality Software and Technology, VRST ’13 (ACM), \n49–58.\nMahon, J., Bryant, B., Brown, B., and Kim, M. (2010). Using second life to enhance \nclassroom management practice in teacher education. Educ. Media Int. 47, \n121–134. doi:10.1080/09523987.2010.492677 \nMayr, J., Eder, F ., and Fartacek, W . (1991). Mitarbeit und störung im unterricht: \nStrategien pädagogischen handelns. Zeitschrift für pädagogische Psychologie 5, \n43–55. \nMehrabian, A. (1996). Pleasure-arousal-dominance: a general framework for \ndescribing and measuring individual differences in temperament. Curr. Psychol. \n14, 261–292. doi:10.1007/BF02686918 \nMicrosoft C. (2016). Microsoft Kinect v2. Available at: https://developer.microsoft.\ncom/en-us/windows/kinect/\nMori, M. (1970). Bukimi no tani [The uncanny valley]. Energy 7, 33–35. \nNagendran, A., Pillat, R., Kavanaugh, A., Welch, G., and Hughes, C. (2013). \n“ Amities: avatar-mediated interactive training and individualized experience \nsystem, ” in Proceedings of the 19th ACM Symposium on Virtual Reality Software \nand Technology, VRST ’13 (New Y ork, NY: ACM), 143–152.\nNagendran, A., Welch, G., Hughes, C., and Pillat, R. (2015). “Technical report: \nexploring human surrogate characteristics, ” in Virtual Realities  (Springer), \n215–228.\nNaumann, A., and Hurtienne, J.\n (2010). “\nBenchmarks for intuitive interaction with \nmobile devices, ” in Proceedings of the 12th Conference on Human-Computer \nInteraction with Mobile Devices and Services, Mobile HCI ’10 (Berlin: ACM), \n401–402.\nOculus VR LLC. (2016). Oculus Developement Kit 2. Available at: https://www.\noculus.com/en-us/dk2/\nOpaque Multimedia C. (2016). Kinect 4 Unreal Plugin . Available at: http://www.\nopaque.media/kinect-4-unreal/\nSanchez-Vives, M. V ., and Slater, M. (2005). From presence to consciousness \nthrough virtual reality. Nat. Rev. Neurosci. 6, 332–339. doi:10.1038/nrn1651 \nSchuemie, M. J.\n (2003). \nHuman-Computer Interaction and Presence in Virtual \nReality Exposure Therapy. Delft: TU Delft, Delft University of Technology.\n21\nLugrin et al.\nClassroom Management Using Virtual Reality\nFrontiers in ICT |  www .frontiersin.org November 2016  |  Volume 3  |  Article 26\nSchutte, J.  G. (1997). Virtual Teaching in Higher Education. Northridge, CA: \nCalifornia State University-Northridge.\nSeitz, O. (1991). Problemsituationen im Unterricht. Cologne: Wolf.\nSeitz, O. (2004). Unterrichtsstörungen. Nuremberg: Univ., Lehrstuhl für Schulpädag.\nSensorMotoric. (2016). Sensormotoric Instrument Eye Tracking Package for Oculus \nDK2. Available at: http://www.smivision.com/\nSlater, M. (2009). Place illusion and plausibility can lead to realistic behaviour in \nimmersive virtual environments. Philos. Trans. R. Soc. Lond. B Biol. Sci. 364, \n3549–3557. doi:10.1098/rstb.2009.0138 \nSpanlang, B., Normand, J.-M., Borland, D., Kilteni, K., Giannopoulos, E., Pomés, \nA., et al. (2014). How to build an embodiment lab: achieving body representa-\ntion illusions in virtual reality. Front. Rob. AI 1:9. doi:10.3389/frobt.2014.00009 \nSteed, A. (2008). “ A simple method for estimating the latency of interactive, \nreal-time graphics simulations, ” in Proceedings of the 2008 ACM Symposium \non Virtual Reality Software and Technology, VRST ’08 (New Y ork, NY: ACM), \n123–129.\nStraub, C., Dieker, L., Hynes, M., and Huges, C. (2014). Using Virtual Rehearsal in \nTLE TeachLivE\nTM Mixed Reality Classroom Simulator to Determine the Effects on \nthe Performance of Mathematics Teachers. 2014 TeachLivE™ National Research \nProject: Y ear 1 Findings.\nThomas, D. R., Becker, W . C., and Armstrong, M. (1968). Production and elim-\nination of disruptive classroom behavior by systematically varying teacher’s \nbehavior. J.\n \nAppl. Behav. Anal. 1, 35–45. doi:10.1901/jaba.1968.1-35 \nTichon, J., Hall, R., Hilgers, M. G., Leu, M., and Agarwal, S. (2003). “Education \nand training in virtual environments for disaster management, ” in \nProceedings of World Conference on Educational Multimedia, Hypermedia, & \nTelecommunications (EdMedia) (Brisbane: AACE Honolulu), 1191–1194.\nTichon, J.\n G. (2007). U\nsing presence to improve a virtual training environment. \nCyberpsychol. Behav. 10, 781–788. doi:10.1089/cpb.2007.0005 \nWalker, H. M. (1995). The Acting-Out Child: Coping with Classroom Disruption. \nLongmont, CO: Sopris West.\nWaltemate, T., Hülsmann, F ., Pfeiffer, T., Kopp, S., and Botsch, M. (2015). “Realizing \na low-latency virtual reality environment for motor learning, ” in Proceedings of \nthe 21st ACM Symposium on Virtual Reality Software and Technology (Bielefeld: \nACM), 139–147.\nWang, W ., and Loewen, S. (2015). Nonverbal behavior and corrective feedback \nin nine ESL university-level classrooms. Lang. Teach. Res. doi:10.1177/ \n1362168815577239\nWilliamon, A., Aufegger, L., and Eiholzer, H. (2014). Simulating and stimulating \nperformance: introducing distributed simulation to enhance musical learning \nand performance. Front. Psychol. 5:25. doi:10.3389/fpsyg.2014.00025\nConflict of Interest Statement: The authors declare that the research was con-\nducted in the absence of any commercial or financial relationships that could be \nconstrued as a potential conflict of interest.\nCopyright © 2016 Lugrin, Latoschik, Habel, Roth, Seufert and Grafe. This is \nan open-access article distributed under the terms of the Creative Commons \nAttribution License (CC BY). The use, distribution or reproduction in other forums \nis permitted, provided the original author(s) or licensor are credited and that the \noriginal publication in this journal is cited, in accordance with accepted academic \npractice. No use, distribution or reproduction is permitted which does not comply \nwith these terms.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6516188383102417
    },
    {
      "name": "Session (web analytics)",
      "score": 0.5774790644645691
    },
    {
      "name": "Usability",
      "score": 0.5677528977394104
    },
    {
      "name": "Class (philosophy)",
      "score": 0.5639812350273132
    },
    {
      "name": "Multimedia",
      "score": 0.543884813785553
    },
    {
      "name": "Syllabus",
      "score": 0.542108952999115
    },
    {
      "name": "Classroom management",
      "score": 0.5376322269439697
    },
    {
      "name": "Virtual reality",
      "score": 0.5329535603523254
    },
    {
      "name": "Graphics",
      "score": 0.4731612801551819
    },
    {
      "name": "Human–computer interaction",
      "score": 0.4661738872528076
    },
    {
      "name": "Psychology",
      "score": 0.1407947838306427
    },
    {
      "name": "Mathematics education",
      "score": 0.13131967186927795
    },
    {
      "name": "Artificial intelligence",
      "score": 0.13113898038864136
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    },
    {
      "name": "Computer graphics (images)",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I25974101",
      "name": "University of Würzburg",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I180923762",
      "name": "University of Cologne",
      "country": "DE"
    }
  ]
}