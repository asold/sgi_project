{
  "title": "A Financial Time-Series Prediction Model Based on Multiplex Attention and Linear Transformer Structure",
  "url": "https://openalex.org/W4366771045",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4364080356",
      "name": "Caosen Xu",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2125169707",
      "name": "Jingyuan Li",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1996396285",
      "name": "Bing Feng",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2243263508",
      "name": "Baoli Lu",
      "affiliations": [
        "University of Portsmouth",
        "Chinese Academy of Sciences",
        "Institute of Semiconductors"
      ]
    },
    {
      "id": "https://openalex.org/A4364080356",
      "name": "Caosen Xu",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2125169707",
      "name": "Jingyuan Li",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1996396285",
      "name": "Bing Feng",
      "affiliations": [
        "Wuhan Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2243263508",
      "name": "Baoli Lu",
      "affiliations": [
        "University of Portsmouth",
        "Institute of Semiconductors",
        "Chinese Academy of Sciences"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2006487144",
    "https://openalex.org/W1974716003",
    "https://openalex.org/W3126008443",
    "https://openalex.org/W2021938316",
    "https://openalex.org/W2012079387",
    "https://openalex.org/W2895960091",
    "https://openalex.org/W3084016763",
    "https://openalex.org/W3208196388",
    "https://openalex.org/W6804297678",
    "https://openalex.org/W4310844203",
    "https://openalex.org/W4205830265",
    "https://openalex.org/W4306317232",
    "https://openalex.org/W4229366080",
    "https://openalex.org/W3176130152",
    "https://openalex.org/W2794582201",
    "https://openalex.org/W4318822142",
    "https://openalex.org/W4283379722",
    "https://openalex.org/W4293023328",
    "https://openalex.org/W2773013922",
    "https://openalex.org/W2759498455",
    "https://openalex.org/W2889548492",
    "https://openalex.org/W4388488561",
    "https://openalex.org/W2978228831",
    "https://openalex.org/W2012971904",
    "https://openalex.org/W3126456610",
    "https://openalex.org/W4285814498",
    "https://openalex.org/W2798617837",
    "https://openalex.org/W4361276271",
    "https://openalex.org/W4311118478",
    "https://openalex.org/W6784835917",
    "https://openalex.org/W6735284998",
    "https://openalex.org/W6684193618",
    "https://openalex.org/W2905238323",
    "https://openalex.org/W2116341502",
    "https://openalex.org/W3097294131",
    "https://openalex.org/W2164512879",
    "https://openalex.org/W2599534045",
    "https://openalex.org/W3213421678"
  ],
  "abstract": "Financial time-series prediction has been an important topic in deep learning, and the prediction of financial time series is of great importance to investors, commercial banks and regulators. This paper proposes a model based on multiplexed attention mechanisms and linear transformers to predict financial time series. The linear transformer model has a faster model training efficiency and a long-time forecasting capability. Using a linear transformer reduces the original transformer’s complexity and preserves the decoder’s multiplexed attention mechanism. The results show that the proposed method can effectively improve the prediction accuracy of the model, increase the inference speed of the model and reduce the number of operations, which has new implications for the prediction of financial time series.",
  "full_text": null,
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6020544767379761
    },
    {
      "name": "Computer science",
      "score": 0.587602972984314
    },
    {
      "name": "Inference",
      "score": 0.5053556561470032
    },
    {
      "name": "Time series",
      "score": 0.4923132658004761
    },
    {
      "name": "Econometrics",
      "score": 0.3715057671070099
    },
    {
      "name": "Finance",
      "score": 0.3615613281726837
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2999173402786255
    },
    {
      "name": "Machine learning",
      "score": 0.2978268265724182
    },
    {
      "name": "Mathematics",
      "score": 0.17586737871170044
    },
    {
      "name": "Engineering",
      "score": 0.1738482415676117
    },
    {
      "name": "Voltage",
      "score": 0.15209972858428955
    },
    {
      "name": "Economics",
      "score": 0.12125968933105469
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}