{
  "title": "Large language models for disease diagnosis: a scoping review",
  "url": "https://openalex.org/W4411147644",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2130719219",
      "name": "Zhou Shuang",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A3207166912",
      "name": "Xu Zidu",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A2277209169",
      "name": "Zhang Mian",
      "affiliations": [
        "The University of Texas at Dallas"
      ]
    },
    {
      "id": "https://openalex.org/A4322820219",
      "name": "Xu, Chunpu",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A2361426158",
      "name": "Guo Yawen",
      "affiliations": [
        "University of California, Irvine"
      ]
    },
    {
      "id": null,
      "name": "Zhan, Zaifu",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A2002353627",
      "name": "Fang Yi",
      "affiliations": [
        "New York University Shanghai"
      ]
    },
    {
      "id": "https://openalex.org/A3169485310",
      "name": "Ding, Sirui",
      "affiliations": [
        "University of California, San Francisco"
      ]
    },
    {
      "id": "https://openalex.org/A4297435459",
      "name": "Wang Jiashuo",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4378773826",
      "name": "Xu, Kaishuai",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4225598233",
      "name": "Xia, Liqiao",
      "affiliations": [
        "Hong Kong Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A4378944516",
      "name": "Yeung, Jeremy",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A4226852436",
      "name": "Zha, Daochen",
      "affiliations": [
        "Film Independent"
      ]
    },
    {
      "id": "https://openalex.org/A2354800430",
      "name": "Cai Dongming",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A4302413338",
      "name": "Melton Genevieve B.",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A4222700404",
      "name": "Lin, Mingquan",
      "affiliations": [
        "University of Minnesota"
      ]
    },
    {
      "id": "https://openalex.org/A1956316200",
      "name": "Zhang Rui",
      "affiliations": [
        "University of Minnesota"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3025011581",
    "https://openalex.org/W3025948831",
    "https://openalex.org/W3122000782",
    "https://openalex.org/W4390739195",
    "https://openalex.org/W3023079706",
    "https://openalex.org/W4230779446",
    "https://openalex.org/W3034674374",
    "https://openalex.org/W2580767461",
    "https://openalex.org/W2883944442",
    "https://openalex.org/W4406088527",
    "https://openalex.org/W2104787607",
    "https://openalex.org/W3010274200",
    "https://openalex.org/W4308885870",
    "https://openalex.org/W3150212014",
    "https://openalex.org/W3043374725",
    "https://openalex.org/W4387104519",
    "https://openalex.org/W4366549962",
    "https://openalex.org/W4400721814",
    "https://openalex.org/W4200594220",
    "https://openalex.org/W2902644322",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4401042729",
    "https://openalex.org/W4396929025",
    "https://openalex.org/W4406288888",
    "https://openalex.org/W6869501992",
    "https://openalex.org/W4400837480",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4395052272",
    "https://openalex.org/W4406602253",
    "https://openalex.org/W4398223047",
    "https://openalex.org/W4394009806",
    "https://openalex.org/W4399052098",
    "https://openalex.org/W4393021028",
    "https://openalex.org/W4392983247",
    "https://openalex.org/W4399912477",
    "https://openalex.org/W4387627515",
    "https://openalex.org/W4399363701",
    "https://openalex.org/W4392099631",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4393571956",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W4384337834",
    "https://openalex.org/W4390314481",
    "https://openalex.org/W4403353492",
    "https://openalex.org/W4400530541",
    "https://openalex.org/W4394843589",
    "https://openalex.org/W4399107553",
    "https://openalex.org/W4394844846",
    "https://openalex.org/W4400696650",
    "https://openalex.org/W3188404242",
    "https://openalex.org/W4401028610",
    "https://openalex.org/W4396700254",
    "https://openalex.org/W4396577162",
    "https://openalex.org/W4389480329",
    "https://openalex.org/W4400456285",
    "https://openalex.org/W4386897626",
    "https://openalex.org/W4405717809",
    "https://openalex.org/W4399973052",
    "https://openalex.org/W4383313218",
    "https://openalex.org/W4391383134",
    "https://openalex.org/W4400806824",
    "https://openalex.org/W4389708586",
    "https://openalex.org/W4387346544",
    "https://openalex.org/W4402671983",
    "https://openalex.org/W4393055550",
    "https://openalex.org/W4395050972",
    "https://openalex.org/W4394764048",
    "https://openalex.org/W4392544551",
    "https://openalex.org/W4404783798",
    "https://openalex.org/W4393388987",
    "https://openalex.org/W4389559041",
    "https://openalex.org/W4394653911",
    "https://openalex.org/W4401726216",
    "https://openalex.org/W4385230595",
    "https://openalex.org/W4399353927",
    "https://openalex.org/W4406982964",
    "https://openalex.org/W6851592950",
    "https://openalex.org/W6600248585",
    "https://openalex.org/W4402670279",
    "https://openalex.org/W4393160078",
    "https://openalex.org/W4398201291",
    "https://openalex.org/W4400362569",
    "https://openalex.org/W4393159297",
    "https://openalex.org/W4404783176",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W6600310816",
    "https://openalex.org/W4389520259",
    "https://openalex.org/W3101223450",
    "https://openalex.org/W4403322149",
    "https://openalex.org/W2754517384",
    "https://openalex.org/W4378771755",
    "https://openalex.org/W4399198691",
    "https://openalex.org/W4395444023",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W4396832118",
    "https://openalex.org/W4312220150",
    "https://openalex.org/W4391940656",
    "https://openalex.org/W4399492636",
    "https://openalex.org/W4389267014",
    "https://openalex.org/W4402324956",
    "https://openalex.org/W4402727705",
    "https://openalex.org/W4404782407",
    "https://openalex.org/W4401793114",
    "https://openalex.org/W4409283601",
    "https://openalex.org/W4392748894",
    "https://openalex.org/W4403089476",
    "https://openalex.org/W4409767213",
    "https://openalex.org/W4391170193",
    "https://openalex.org/W4408165783",
    "https://openalex.org/W4393153123",
    "https://openalex.org/W4392013164",
    "https://openalex.org/W4392504747",
    "https://openalex.org/W4388092701",
    "https://openalex.org/W4396833509",
    "https://openalex.org/W4396920249",
    "https://openalex.org/W2104198823",
    "https://openalex.org/W4401043301",
    "https://openalex.org/W4200109803",
    "https://openalex.org/W4402670788",
    "https://openalex.org/W6600266142",
    "https://openalex.org/W4401810439",
    "https://openalex.org/W4408559929",
    "https://openalex.org/W2014283149",
    "https://openalex.org/W4401752680",
    "https://openalex.org/W4408559909",
    "https://openalex.org/W4409283616",
    "https://openalex.org/W4393119065",
    "https://openalex.org/W6809662878",
    "https://openalex.org/W3102237985",
    "https://openalex.org/W4396723505",
    "https://openalex.org/W4395659193",
    "https://openalex.org/W4404781870",
    "https://openalex.org/W4403577370",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4399759422",
    "https://openalex.org/W4389132345",
    "https://openalex.org/W3042614271",
    "https://openalex.org/W4389520084",
    "https://openalex.org/W4401326040",
    "https://openalex.org/W4385255855",
    "https://openalex.org/W4402909345",
    "https://openalex.org/W4396707035",
    "https://openalex.org/W4392655718",
    "https://openalex.org/W4398180562",
    "https://openalex.org/W6630379773",
    "https://openalex.org/W4399553982",
    "https://openalex.org/W4400727806",
    "https://openalex.org/W4389519882",
    "https://openalex.org/W4401042702",
    "https://openalex.org/W4401042554",
    "https://openalex.org/W4389000204",
    "https://openalex.org/W4400074001",
    "https://openalex.org/W4389314653",
    "https://openalex.org/W4399864536",
    "https://openalex.org/W6600529467",
    "https://openalex.org/W4402670852",
    "https://openalex.org/W6605485274",
    "https://openalex.org/W4401397240",
    "https://openalex.org/W4407251580",
    "https://openalex.org/W4361792156",
    "https://openalex.org/W4392928544",
    "https://openalex.org/W4389040134",
    "https://openalex.org/W4391573229",
    "https://openalex.org/W4385347692",
    "https://openalex.org/W4378770755",
    "https://openalex.org/W4387779028",
    "https://openalex.org/W4403650311",
    "https://openalex.org/W4400136387",
    "https://openalex.org/W4392186538",
    "https://openalex.org/W3198282417",
    "https://openalex.org/W4392563420",
    "https://openalex.org/W4399874906",
    "https://openalex.org/W4400663251",
    "https://openalex.org/W4396605652",
    "https://openalex.org/W4383186888",
    "https://openalex.org/W4401042726",
    "https://openalex.org/W4392984569",
    "https://openalex.org/W4377010595",
    "https://openalex.org/W4400549596",
    "https://openalex.org/W4394661002",
    "https://openalex.org/W4393336030",
    "https://openalex.org/W2990138404"
  ],
  "abstract": null,
  "full_text": "npj |artiﬁcial intelligence Review\nhttps://doi.org/10.1038/s44387-025-00011-z\nLarge language models for disease\ndiagnosis: a scoping review\nCheck for updates\nShuang Zhou1,13,Z i d uX u2,13,M i a nZ h a n g3,13,C h u n p uX u4,13, Yawen Guo5,Z a i f uZ h a n6,Y iF a n g7,S i r u iD i n g8,\nJiashuo Wang4,K a i s h u a iX u4,L i q i a oX i a9,J e r e m yY e u n g1, Daochen Zha10,D o n g m i n gC a i11,\nGenevieve B. Melton12,M i n g q u a nL i n1 & Rui Zhang1\nAutomatic disease diagnosis has become increasingly valuable in clinical practice. The advent of large\nlanguage models (LLMs) has catalyzed a paradigm shift in artiﬁcial intelligence, with growing evidence\nsupporting the efﬁcacy of LLMs in diagnostic tasks. Despite the increasing attention in thisﬁeld, a\nholistic view is still lacking. Many critical aspects remain unclear, such as the diseases and clinical data\nto which LLMs have been applied, the LLM techniques employed, and the evaluation methods used. In\nthis article, we perform a comprehensive review of LLM-based methods for disease diagnosis. Our\nreview examines the existing literature across various dimensions, including disease types and\nassociated clinical specialties, clinical data, LLM techniques, and evaluation methods. Additionally,\nwe offer recommendations for applying and evaluating LLMs for diagnostic tasks. Furthermore, we\nassess the limitations of current research and discuss future directions. To our knowledge, this is the\nﬁrst comprehensive review for LLM-based disease diagnosis.\nAutomatic disease diagnosis is pivotal in clinical practice, leveraging clinical\ndata to generate potential diagnoses with minimal human input1.I t\nenhances diagnostic accuracy, supports clinical decision-making, and\naddresses healthcare disparities by providing high-quality diagnostic\nservices\n2.A d d i t i o n a l l y ,i tb o o s t se fﬁciency, especially for clinicians mana-\nging aging populations with multiple comorbidities3– 5. For example,\nDXplain6 analyzes patient data to generate diagnoses with justiﬁcations.\nOnline services also promote early diagnosis and large-scale screening for\ndiseases like mental health disorders, raising awareness and mitigating\nrisks\n4,7– 10.\nAdvances in artiﬁcial intelligence (AI) have driven two waves of\nautomated diagnostic systems11– 14. Early approaches utilized machine\nlearning techniques like support vector machines and decision trees15,16.\nWith larger datasets and computational power, deep learning (DL) models,\nsuch as convolutional, recurrent, and generative adversarial networks,\nbecame predominant\n1,2,17– 20. However, these models require extensive\nlabeled data and are task-speciﬁc, limiting theirﬂexibility1,19,21. The rise of\ngenerative large language models (LLMs), like GPT22 and LLaMA23,p r e -\ntrained on extensive corpora, has demonstrated signiﬁcant potential in\nvarious clinical applications,such as question answering24,25 and informa-\ntion retrieval26,27. These models are increasingly applied to diagnostics. For\nexample, PathChat28, a vision-language LLMﬁne-tuned with comprehen-\nsive instructions, set new benchmarksin pathology. Similarly, Kim et al.29\nreported that GPT-4 outperformed mental health professionals in diag-\nnosing obsessive-compulsive disorder,underscoring its potential in mental\nhealth diagnostics.\nDespite growing interest, severalkey questions remain unresolved:\nWhich diseases and medical data have been explored for LLM-based\ndiagnostics (Q1)? What LLM techniques are most effective for diagnostic\ntasks (see Box1), and how should they be selected (Q2)? What evaluation\nmethods best assess performance of various diagnostic tasks (Q3)? Many\nr e v i e w sh a v ee x p l o r e dt h eu s eo fL L M si nm e d i c i n e30– 37, but they typically\nprovide broad overviews of diverse clinical applications rather than focusing\nspeciﬁcally on disease diagnosis. For instance, Pressman et al.38 highlighted\n1Division of Computational Health Sciences, Department of Surgery, University of Minnesota, Minneapolis, MN, USA.2School of Nursing, Columbia University,\nNew York, New York, USA.3Erik Jonsson School of Engineering and Computer Science, University of Texas at Dallas, Richardson, TX, USA.4Department of\nComputing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong SAR.5Department of Informatics, University of California, Irvine, Irvine, CA, USA.\n6Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA.7Department of Computer Science, New York University\n(Shanghai), Shanghai, China.8Bakar Computational Health Sciences Institute, University of California San Francisco, San Francisco, CA, USA.9Department of\nIndustrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, Hong Kong SAR.10Independent Researcher, San Francisco, CA, USA.\n11Department of Neurology, University of Minnesota, Minneapolis, MN, USA.12Institute for Health Informatics and Division of Colon and Rectal Surgery,\nDepartment of Surgery, University of Minnesota, Minneapolis, MN, USA.13These authors contributed equally: Shuang Zhou, Zidu Xu, Mian Zhang, Chunpu Xu.\ne-mail: ruizhang@umn.edu\nnpj Artiﬁcial Intelligence|             (2025) 1:9 1\n1234567890():,;\n1234567890():,;\nintroducing various clinical applications of LLMs, e.g., pre-consultation,\ntreatment, and patient education. These reviews tend to overlook the\nnuanced development of LLMs for diagnostic tasks and do not analyze the\ndistinct merits and challenges in this area, revealing a critical research gap.\nSome reviews\n39,40 have focused on speciﬁc specialties,such as digestive or\ninfectious diseases, but failed to offer a comprehensive perspective that\nspans multiple specialties, data types, LLM techniques, and diagnostic tasks\nto fully address the critical questions at hand.\nThis review addresses the gap by offering a comprehensive examination\nof LLMs in disease diagnosis through in-depth analyses. First, we system-\natically investigated a wide range of disease types, corresponding clinical\nspecialties, medical data, data modalities, LLM techniques, and evaluation\nmethods utilized in existing diagnostic studies. Second, we critically evaluated\nthe strengths and limitations of prevalent LLM techniques and evaluation\nstrategies, providing recommendations for data preparation, technique\nselection, and evaluation approaches tailored to different contexts. Addi-\ntionally, we identify the shortcomingsof current studies and outline future\nchallenges and directions. To the best of our knowledge, this is theﬁrst review\ndedicated exclusively to LLM-based disease diagnosis, presenting a holistic\nperspective and a blueprint for future research in this domain.\nResults\nOverview of the scope\nThis section outlines the scope of our review and keyﬁndings. Figure1\nprovides an overview of disease types, clinical specialties, data types, and\nmodalities (Q1), and introduces the applied LLM techniques (Q2) and\nevaluation methods (Q3), addressingthe key questions. Our analysis spans\n19 clinical specialties and over 15 types of clinical data in diagnostic tasks,\ncovering modalities such as text, image, video, audio, time series, and\nmultimodal data. We categorized existing works based on LLM techniques,\nwhich fall into four categories: prompting, retrieval-augmented generation\n(RAG), ﬁne-tuning, and pre-training, with the latter three further sub-\ndivided. Table1 summarizes the taxonomy of mainstream LLM techniques.\nFigure2 illustrates the associations between clinical specialties, modalities of\nutilized data, and LLM techniques in the included papers. Additionally,\nFig. 3 presents a meta-analysis, covering publication trends, widely-used\nLLMs for training and inference, and statistics on data sources, evaluation\nmethods, data privacy, and data sizes. Collectively, these analyses compre-\nhensively depict the development of LLM-based disease diagnosis.\nStudy characteristics\nAs shown in Fig.2, the included studies span all 19 clinical specialties, and\nsome specialties receive particular attention, such as pulmonology and\nneurology. While most studies leveraged text modality, multi-modal data,\nsuch as text-image41 and text-tabular data42, are widely adopted for diag-\nnostic tasks. Another observation isthat various LLM techniques have been\napplied to diagnostic tasks, and all have been used with multi-modal data\n(Table 1). Additionally, we ﬁnd an increasing number of LLM-based\ndiagnostic studies all over the world, reﬂecting the ﬁeld’s growing sig-\nniﬁcance (Fig. 3a). Among these studies, GPT\n22 and LLaMA23 families\ndominate inference tasks, while LLaMA and ChatGLM43 are commonly\nadopted for model training (Fig.3b). Figure3c shows that most datasets\noriginate from North America (50.6%) and Asia (33.9%), and 50.4% of the\nstudies used public datasets (Fig.3e). Evaluation methods vary: 66.8% rely\non automated evaluation, 28.1% on human assessment, and 5.1% on LLM-\nbased evaluation (Fig.3d). Figure 3f reveals that the included studies\nemployed large datasets (e.g., 5 × 105 samples) for pre-training diagnostic\nmodels, surpassing those primarily usingﬁne-tuning or RAG. This phe-\nnomenon aligns with another observation that over half of pre-training\nmodels used data from multiple specialties.\nPrompt-based disease diagnosis\nA customized prompt typically includes four components: instruction (task\nspeciﬁcation), context (scenario or domain), input data (data to process),\nand output indicators (desired style or role). In this review, over 60% (N =\n278) of studies employed prompt-based techniques, categorized as hard\nprompts and soft prompts. Hard prompts are static, interpretable, and\nwritten in natural language. The most common methods included zero-shot\n(N = 194), Chain-of-Thought (CoT) (N = 37), and few-shot prompting (N =\n35). Among them, CoT prompting excels in thoroughly digesting input\nclinical cues in manageable steps to make a coherent diagnosis decision.\nParticularly, in differential diagnosis tasks, CoT reasoning allows the LLM to\nsequentially analyze medical images, radiology reports, and clinical history,\ngenerating intermediate outputs that lead to a holistic decision, with an\naccuracy of 64%\n44. Self-consistency prompting was used in a few studies (N =\n4). For instance, a study combined self-consistency with CoT prompting to\nimprove depression prediction by synthesizing diverse data sources through\nmultiple reasoning paths. This hybrid approach reduced the mean absolute\nerror by nearly 50% compared to standard CoT methods45.\nBox 1 | Terms and Concepts\nDisease diagnosis:receiving clinical data, such as patient symptoms,\nmedical history, and diagnostic tests, as input and identifying which\ndisease explains the symptoms and signs.\nDiagnostic tasks:a type of tasks that generate disease diagnoses or\nprobability estimates for speciﬁc conditions, such as differential diag-\nnosis and conversational diagnosis.\nLarge language models:a type of AI models using deep neural networks\nto learn the relationships between words in natural language, using large\ndatasets of text to train.\nHallucination: an AI-generated output that is plausible but factually\nincorrect or unrelated to the input, arising from limitations in training or\nreasoning.\nPrompt: an input or instruction provided to an AI model to guide its\nresponse, often designed to elicit speciﬁc or task-relevant outputs.\nChain-of-thought: a technique enabling AI to generate multi-step rea-\nsoning by breaking down complex tasks into sequential steps for\nimproved accuracy.\nSelf-consistency prompt:a method that samples diverse reasoning\npaths and selects the most consistent solution to enhance the reliability\nof outputs in reasoning tasks.\nSoft prompt:a learnable embedding added to the input space of a pre-\ntrained model to guide its behavior without modifying the model’s\nparameters.\nRetrieval-augmented generation:integrates retrieved data into LLMs,\nenhancing responses by leveraging external information for improved\ncontext and accuracy in content generation.\nFine-tuning: the process of adapting a pre-trained model to a speciﬁc\ntask by training it further on a smaller, task-speciﬁc dataset.\nSupervised ﬁne-tuning: reﬁning a pre-trained model for a task using\nlabeled data to enhance task-speciﬁc performance.\nParameter-efﬁcient ﬁne-tuning: adapting pre-trained models to new\ntasks by updating limited parameters (e.g., adapters), reducing compu-\ntational costs while preserving performance.\nReinforcement learning from human feedback:a method where\nmodels improve outputs by learning from human-provided feedback,\naligning behavior with human goals through reinforcement learning.\nPre-training: the foundational training phase of a model on a large,\ngeneral dataset to learn broad patterns, features, and representations,\nwhich can later be adapted to speciﬁc tasks throughﬁne-tuning.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 2\nIn contrast, soft prompts (N = 6) are continuous vector embeddings\ntrained to adapt the behavior of LLMs for speciﬁct a s k s46. These prompts\neffectively integrate external knowledge, such as medical concept embed-\ndings and clinical proﬁles, making them well-suited for complex diagnostic\ntasks requiring nuanced analysis. This knowledge-enhanced approach\nachieved F1 scores exceeding 0.94 for diagnosing common diseases like\nhypertension and coronary artery disease and demonstrated superiority in\nrare disease diagnosis\n47.\nMost prompt-based studies (N = 221) focused on unimodal data,\npredominantly text (N = 171). Clinical text sources like clinical notes48,\nimaging reports49– 51, and case reports52,53 were commonly used. These stu-\ndies often prompted LLMs with clinical notes or case reports to predict\npotential diagnoses54– 57. A smaller subset (N = 19) applied prompt engi-\nneering to medical image data, analyzing CT scans58,X - r a y s59,60,M R I\nscans58,61, and pathological images62,63 to detect abnormalities and provide\nevidence for differential diagnoses62,64– 66.\nQ: Am I infected with \nany disease?\nA: COVID-19. As\nyou had signs …\nQ: Am I infected with \nany disease?\nA: COVID-19. As\nyou had signs …\nPrompt (Zero-shot) RAG (Database)\nClinical Data\nData Modality\nLLM Technique\nClinical Specialty\nClinical note X-ray Pathological image ECG Ultrasound Genetic data Lab test\nOncology Rheumatology\nNeurology Psychiatry\nOrthopedics Ophthalmology\nAlzheimer's disease,\nParkinson's disease\nPulmonology Dermatology\nCardiology Endocrinology\nNephrology Gastroenterology\nArrhythmia,\nHeart failure\nSchizophrenia,\nDepression\nSpondyloarthritis, \nFracture\nBreast cancer,\nPancreatic cancer\nGlaucoma, Lacrimal \ndrainage disorders\nRheumatic disease,\nSjögren’s syndrome\nAcute kidney injury,\nKidney stones\nPulmonary embolism,\nCOVID-19\nType-2 diabetes,\nThyroid nodules\nAppendicitis,\nBoston Bowel\nPsoriasis, Eczema,\nActinic keratosis\nMRI Speech\n…\nTex t Tex t + Im age Text + Time series Text + Tabular data Text + Image + Video\n…\nQ: Am I infected with \nany disease?\n1\n2 COVID\n3\nPrompt (CoT)\nEvaluation Method\nPrediction\nAutomated Evaluation Human Evaluation LLM Evaluation\nQ: What is the possible disease? Q: What is the\npossible disease?\nPrediction: COVID-19.\nAs he had signs …\nPrediction: COVID-19.\nAs he had signs …\nGround-truth: \nLung cancer.\nSince he had\nsigns …\nLabel\nCOVID-19\nNormal\nNormal\nNormal\nCOVID-19\nNormal\n… …\nFine-tuning (SFT)\n…\nPrompting RAG Fine-tuning Pre-training\n…\nFig. 1 | Overview of the investigated scope.It illustrated disease types and the associated clinical specialties, clinical data types, modalities of the utilized data, the applied\nLLM techniques, and evaluation methods. We only presented part of the clinical specialties, some representative diseases, and partial LLM techniques.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 3\nWith the advancement of multimodal LLMs, 57 studies explored their\napplication in disease diagnosis through prompt engineering. Visual-\nlanguage models (VLMs) like GPT-4V, LLaVA, and Flamingo (N =3 7 )\nintegrated medical images (e.g., radiology scans) with textual descriptions\n(e.g., clinical notes)67– 69. For example, incorporating ophthalmologist feed-\nback and contextual details with eye movement images signiﬁcantly\nimproved GPT-4V’s diagnostic accuracy for amblyopia64.\nBeyond image-text data, more advanced multimodal LLMs (e.g., GPT-\n4o and Gemini-1.5 Pro) have also integrated other data types to support\ndisease diagnosis in complex clinical scenarios. Audio and video data have\nbeen used to diagnose neurological and neurodegenerative disorders, such\nas autism\n70,71 and dementia59,72. Time-series data, such as ECG signals and\nwearable sensor outputs, were used to support arrhythmia detection73,74.\nWith the integration of tabular data such as user demographics75,76,a n dl a b\ntest results47,77, the applications have been extended to depression and\nanxiety screening45. Omics data has been integrated to aid in identifying rare\ngenetic disorders78 and diagnose Alzheimer’sd i s e a s e76.S o m es t u d i e sf u r t h e r\nenhanced diagnostic capabilities by integrating medical concept graphs to\nprovide a richer context for conditions such as neurological disorders59.\nRetrieval-augmented LLMs for diagnosis\nTo enhance the accuracy and credibility of the diagnosis, alleviate halluci-\nnation issues, and update LLMs’stored medical knowledge without needing\nre-training, recent studies 79– 81 have incorporated external medical\nTable 1 | Overview of LLM techniques for diagnostic tasks\nTechniques Types Representative studies\nPrompting Zero-shot Text 196,197, image65,198, audio70,72, text-image52, text-time series73,199, text-tabular200\nFew-shot Text 25,187, image58, text-image41,201, text-image-tabular153\nCoT Text 51,202, audio203, time series155, text-image44,204\nSelf-consistency Text 89, audio205, text-image-tabular-time series45\nSoft prompt Text 206, image207, tabular-time series47,208, text-image-graph59\nRAG Knowledge graph Text 81, text-time series94\nCorpus Text 85,87, text-image64,86, text-time series83\nDatabase Text 80,93, text-image90\nFine-tuning SFT Text 98,209,210, text-image133,211,212, text-video102,112, text-audio111,213, text-tabular42,200\nRLHF Text 116,117,214, text-image115\nPEFT Text 98,124,215, text-image104\nPre-training - Text 124,129,131, text-image109,133,137, text-tabular135,200, text-video213, text-omics109\nSFT supervised ﬁne-tuning, RLHF reinforcement learning from human feedback,PEFT parameter-efﬁcient ﬁne-tuning.\nFig. 2 |Summary of the association between clinical specialties (left), data modalities (middle), and LLM techniques (right) across the included studies on disease diagnosis.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 4\nknowledge into diagnostic tasks. The external knowledge primarily comes\nfrom corpus64,79,82– 88, databases74,80,89– 93, and knowledge graph81,94,i nt h e\nincluded papers. Based on the data modality, these RAG-based studies can\nbe roughly categorized into text-based, text-image-based, and time-series-\nbased augmentations.\nIn text-based RAG, most studies\n80,82,84,85,91– 93 utilized basic retrieval\nmethods where external knowledge was encoded as vector representations\nusing sentence transformers, such as OpenAI’s text-embedding-ada-002.\nQueries were similarly encoded, and relevant knowledge was retrieved based\non vector similarities. The retrieved data was then input into LLMs with\nspeciﬁc prompts to produce diagnostic outcomes. In contrast, Li et al.\n88\ndeveloped guideline-based GPT agents for retrieving and summarizing\ncontent related to diagnosing traumatic brain injury. They found that these\nguideline-based GPT-4 agents signiﬁcantly outperformed the off-the-shelf\nGPT-4 in terms of accuracy, explainability, and empathy evaluation.\nSimilarly, Thompson et al.\n79 employed regular expressions to extract rele-\nvant knowledge for diagnosing pulmonary hypertension, achieving about a\n20% improvement compared to structured methods. Additionally, Wen\net al.81 integrated knowledge graph retrieval with LLMs to enable diagnostic\ninference by combining implicit and external knowledge, achieving an\nF1 score of 0.79.\nIn text-image data processing, a common approach\n87,91 involved\nextracting image features and text features and aligning them within a\nshared semantic space. For instance, Ferber et al.91 used GPT-4V to extract\ncrucial image data for oncology diagnostics, achieving a 94% completeness\nrate and an 89.2% helpfulness rate. Similarly, Ranjit et al.87 utilized multi-\nmodal models to compute image-text similarities for chest X-ray analysis,\nleading to a 5% absolute improvement in the BERTScore metric. Notably,\none studyﬁne-tuned LLMs with retrieved documents to enhance X-ray\ndiagnostics\n86, attaining an average accuracyof 0.86 across three datasets.\nFor time-series RAG, most studies focused on the electrocardiogram\n(ECG) analysis74,83. For example, Yu et al.83 transformed fundamental ECG\nconditions into enhanced text descriptions by utilizing relevant information\nfor ECG analysis, resulting in an average AUC of 0.96 across two arrhythmia\ndetection datasets. Additionally, Chen et al.\n95 integrated retrieved disease\nrecords with ECG data to facilitate the diagnosis of hypertension and\nmyocardial infarction.\nFine-tuning LLMs for diagnosis\nFine-tuning an LLM typically encompasses two pivotal stages: supervised\nﬁne-tuning (SFT) and reinforcement learning from human feedback\n(RLHF). SFT trains models on task-speciﬁc instruction-response pairs,\nenabling it to interpret instructions and generate outputs across diverse\nmodalities. This phase establishes afoundational understanding, ensuring\nthe model processes inputs effectively. RLHF further reﬁnes the model by\naligning its behavior with human pr eferences. Using reinforcement\nFig. 3 | Metadata of information from LLM-based diagnostic studies in the\nscoping review. aQuarterly breakdown of LLM-based diagnostic studies. Since the\ninformation for 2024-Q3 is incomplete, our statistics only cover up to 2024-Q2.\nb The top 5 widely-used LLMs for inference and training.c Breakdown of the data\nsource by regions.d Breakdown of evaluation methods (note that some papers\nutilized multiple evaluation methods).e Breakdown of the employed datasets by\nprivacy status.f Distribution of data size used for LLM techniques. The red line\nindicates the median value, while the box limits represent the interquartile range\n(IQR) from theﬁrst to third quartiles. Notably, pre-trained diagnostic models were\noften followed by other LLM techniques (e.g.,ﬁne-tuning), yet thisﬁgure only\nincludes studies that primarily usedﬁne-tuning or RAG. Statistics for prompting\nmethods are not included because: (i) hard prompts generally utilize zero or very few\ndemonstration samples, and (ii) although soft prompts require more training data,\nthe number of relevant studies is insufﬁcient for meaningful distribution analysis.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 5\nlearning, the model is optimized to produce responses that are helpful,\ntruthful, and aligned with societal and ethical standards96.\nIn medical applications, SFT enhancesin-context learning, reasoning,\nplanning, and role-playingcapabilities, improving diagnostic performance.\nThis process integrates inputs from various data modalities into the LLM’s\nword embedding space. For example, following the LLaVA approach97,\nvisual data is converted into token embeddings using an image encoder and\nprojector, then fed into the LLM for end-to-end training. In this review,\n49 studies focused on SFT using medical texts, such as clinical notes\n98,\nmedical dialogs99– 101,o rr e p o r t s102– 104. Additionally, 43 studies combined\nmedical texts with images, including X-rays102,105– 107,M R I s104,107,108,o r\npathology images109– 111. A few studies explored disease detection from\nmedical videos102,112, where video frames were sampled and converted into\nvisual token embeddings. Generally, effective SFT requires collecting high-\nquality, diverse responses to task-speciﬁc instructions to ensure compre-\nhensive training.\nRLHF methods are categorized as online or ofﬂine. Online RLHF,\nintegral to ChatGPT’ss u c c e s s113, involves training a reward model on\ndatasets of prompts and human preferences and using reinforcement\nlearning algorithms like Proximal Policy Optimization (PPO)\n114 to optimize\nthe LLM. Studies have shown its potential in improving medical LLMs for\ndiagnostic tasks\n115– 117. For instance, Zhang et al.117 aligned their model with\nphysician characteristics, achieving strong performance in disease diagnosis\nand etiological analysis; the diagnostic performance of their model, Hua-\ntuoGPT, surpassed GPT-3.5 in over 60% of cases of Meddialog\n118. However,\nonline RLHF’s effectiveness depends heavily on the reward model’s quality,\nwhich may suffer from over-optimization119 and data distribution shifts120.\nAdditionally, reinforcement learningoften faces instability and control\nchallenges121.O fﬂine RLHF, such as Direct Preference Optimization\n(DPO)122, frames RLHF as optimizing a classiﬁcation loss, bypassing the\nneed for a reward model. This approachis more stable and computationally\nefﬁcient, proving valuable for aligning medical LLMs123,124.Y a n ge ta l .124\nreported signiﬁcant performance drops on pediatric benchmarks when the\nofﬂine RLHF phase was omitted. A high-quality dataset of prompts and\nhuman preferences is essential for online RLHF reward model calibration125\nor the convergence of ofﬂine methods like DPO126, whether sourced from\nexperts113 or advanced AI models127.\nSince full training of LLMs is challenging due to high GPU demands,\nparameter-efﬁcient ﬁne-tuning (PEFT) reduces the number of tunable\nparameters. The most common PEFT method, Low-Rank Adaptation\n(LoRA)\n128, introduces trainable rank decomposition matrices into each layer\nwithout altering the model architecture or adding inference latency. In this\nreview, all PEFT-based studies (N = 7) used LoRA to reduce training\ncosts98,104,124.\nPre-training LLMs for diagnosis\nPre-training medical LLMs involves training on large-scale, unlabeled\nmedical corpora to develop a comprehensive understanding of the structure,\nsemantics, and context of medical language. Unlikeﬁne-tuning, pre-\ntraining enables the acquisition of extensive medical knowledge, enhancing\ngeneralization to unseen cases and improving robustness across diverse\ndiagnostic tasks. In this review,ﬁve studies performed text-only pretraining\non the LLMs from different sources\n129– 132,s u c ha sc l i n i c a ln o t e s ,m e d i c a lQ A\ntexts, dialogs, and Wikipedia. Moreover, eight studies injected medical\nvisual knowledge into multimodal LLMs via pretraining109,133– 137.F o r\ninstance, Chen et al.137 employed an off-the-shelf multimodal LLM to\nreformat image-text pairs from PubMed into VQA data points for training\ntheir diagnostic model. To improve the quality of the image encoder, pre-\ntraining tasks like reconstructing images at tile-level or slide-level\n109,a n d\naligning similar images or image-text pairs133 are common choices.\nPerformance evaluation\nEvaluation methods for diagnostic tasks generally fall into three categories\n(Table 2): automated evaluation138, human evaluation138,a n dL L M\nevaluation139, each with distinct advantages and limitations (Fig.4).\nIn this review, most studies (N = 266) relied on automated evaluation,\nwhich is efﬁcient, scalable, and well-suited for large datasets. These metrics\ncan be grouped into three types. (1) Classiﬁcation-based metrics, such as\naccuracy, precision, and recall, are commonly used for disease diagnosis. For\ninstance, Liu et al.133 evaluated COVID-19 diagnostic performance using\nAUC, accuracy, and F1 score. (2) Differential diagnosis metrics, including\ntop-k precision, assess ranked diagnosis lists. Tu et al.\n140 employed top-k\naccuracy to evaluate the correctness of differential diagnosis predictions. (3)\nRegression-based metrics, such as mean squared error (MSE)141,q u a n t i f y\ndeviations between predicted and actual values142. Despite their efﬁciency,\nautomated metrics rely on ground-truth diagnoses143,w h i c hm a yb eu n a -\nvailable, and cannot understand contexts, such as the readability of diag-\nnostic explanations or their clinical utility144.T h e ya l s os t r u g g l ew i t h\ncomplex tasks, such as evaluating the medical correctness of diagnostic\nreasoning\n145.\nH u m a ne v a l u a t i o n(N = 112), conducted by medical experts24,138,d o e s\nnot require ground-truth labels and integrates expert judgment, making it\nsuitable for complex, nuanced assessments. However, it is costly, time-\nconsuming, and prone to subjectivity, limiting its feasibility for large-scale\nevaluation. Recent studies haveexplored using LLM evaluation (N =2 0 ) ,\na.k.a. LLM-as-Judges\n139, to replace human expertsin evaluation and com-\nbine the interpretative depth of LLM judgment with the efﬁciency of\nautomated evaluation. While ground-truth accessibility is not strictly\nnecessary99,116, its inclusion improves reliability143. Popular LLMs used for\nthis purpose include GPT-3.5, GPT-4, and LLaMA-3. However, this\napproach remains constrained by LLM limitations, including susceptibility\nto hallucinations\n99 and difﬁculties in handling complex diagnostic\nreasoning146. In summary, each evaluation approach has distinct advantages\nand limitations, with the choice dependent on the speciﬁc requirements of\nthe task. Figure4 guides the selection of suitable evaluation approaches for\ndifferent scenarios.\nDiscussion\nThis section analyzes keyﬁndings from the included studies, discusses the\nsuitability of mainstream LLM techniques for varying resource constraints\nand data preparation, and outlines challenges and future research directions.\nThe rapid rise of LLM-baseddiagnosis studies (Fig.3a) might partially\nbe attributed to the increased availability of public datasets147 and advanced\noff-the-shelf LLMs57.B e s i d e s ,t h et o pﬁve LLMs used for training and\ninference differ signiﬁcantly (Fig. 3b), reﬂecting the interplay between\neffectiveness and accessibility. Generally, closed-source LLMs, with their\nvast parameters and superior performance143, are favored for LLM inference,\nwhile open-source LLMs are essential for developing domain-speciﬁc\nmodels due to their adaptability148. These factors underscore the dual\ninﬂuence of effectiveness and accessibility on diagnostic applications.\nAdditionally, the regional analysis of datasets (Fig.3c) reveals that 84.5% of\ndatasets originate from North America and Asia, potentially introducing\nracial biases in this research domain\n149.\nMost studies employed prompting for disease diagnosis (Fig.2),\nleveraging its advantages, such as minimal data requirements, ease of use,\nand low computational demands\n150.M e a n w h i l e ,L L M s’ extensive medical\nknowledge allowed them to perform competitively across diverse diagnostic\nt a s k sw h e ne f f e c t i v e l ya p p l i e d24,143. For example, a study fed two data sam-\nples into GPT-4 for depression detection151, and the performance sig-\nniﬁcantly exceeded traditional DL-based models. In summary, prompting\nLLMs facilitates the development of effective diagnostic systems with\nminimal effort, contrasting with conventional DL-based approaches that\nrequire extensive supervised training on large datasets\n2,17.\nWe then compare the advantages and limitations of mainstream LLM\ntechniques to indicate their suitability for varying resource constraints,\nalong with a discussion of data preparation. Generally, the choice of LLM\ntechnique for diagnostic systems depends on the quality and quantity of\navailable data. Prompt engineering is particularly effective in few-data\nscenarios (e.g., zero or three cases with ground-truth diagnoses), requiring\nminimal setup\n24,152. RAG relies on a high-quality external knowledge base,\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 6\nTable 2 | Overview of evaluation metrics for diagnostic tasks\nType Evaluation metric Purpose Scenario Representative task\nAutomated evaluation Accuracy 216 The ratio of all correct predictions to the total predictions G DD 154, DDx217,C D218,R P219, DRG105, MHD220\nPrecision55 The ratio of true positives to the total number of positive predictions G DD 55,C D221, MIC44,R P219, DRG105\nRecall55 The ratio of true positives to the total number of actual positive cases G DD 55,C D221,R P219, DRG105\nF1133 Calculated as the harmonic mean of precision and recall G DD 55, DDx222,C D221, MIC223,R P219, DRG105\nAUC224 The area under the Receiver Operating Characteristic curve G DD 59,C D225, MIC226,R P219, DRG105, MHD227\nAUPR228 The area under the precision-recall curve G DD 229, MIC228,R P230, DRG229\nTop-k accuracy140 The ratio of instances with the true label in the top k predictions to total instances G DD 140, DDx168\nTop-k precision60 The ratio of true positives to total positive predictions within the top k predictions G DD 140, DDx222\nTop-k recall231 The ratio of true positives within the top k predictions to actual positive cases G DD 140, DDx222\nMean square error142 The average of the squared differences between predicted and actual values G DD 142,R P141\nMean absolute error141 The average of the absolute differences between predicted and actual values G DD 142,R P141\nCohen’s κ232 Measure the agreement between predicted score and actual score G DD 232\nBLUE115 Calculate precision by matching n-grams between reference and generated text T DD 233,C D234, MIC235, DRG115\nROUGE187 Calculate F1-score by matching n-grams between reference and generated text T DD 233,C D187, MIC235, DRG115\nCIDEr102 Evaluate n-gram similarity, emphasizing alignment across multiple reference texts T CD 102, MIC236, DRG237\nBERTScore81 Measure similarity by comparing embeddings of reference and generated text T DD 238, DDx143,C D187, DRG87\nMETEOR234 Evaluate text similarity by considering precision, recall, word order, and synonym matches T DDx 143,C D234, MIC236, DRG115\nHuman evaluation Necessity 187 Whether the response or prediction assists in advancing the diagnosis T CD 187\nAcceptance239 The degree of acceptance of the response without any revision T DD 54,C D240\nReliability176 The trustworthiness of the evidence in the response or prediction T DD 144,C D176\nExplainability88 Whether the response or prediction is explainable T DDx 241,C D218\nHuman or LLM evaluation Correctness 242 Whether the response or prediction is medically correct T DD 134, DDx217,C D187, DRG243, MHD176\nConsistency99 Whether the response or prediction is consistent with the ground-truth or input T DD 108, DDx241,C D99, MHD176\nClarity80 Whether the response or prediction is clearly clariﬁed T DD 149,C D244\nProfessionality176 The rationality of the evidence based on domain knowledge T CD 149, MHD176\nCompleteness187 Whether the response or prediction is sufﬁcient and comprehensive T DDx 143,C D218, DRG243\nSatisfaction245 Whether the response or prediction is satisfying T CD 240, DRG237\nHallucination99 Response contains inconsistent or unmentioned information with previous context T DDx 222,C D218, DRG246\nRelevance80 Whether the response or prediction is relevant to the context T CD 80, DRG246\nCoherence247 Assess logical consistency with the dialog history T CD 100, DRG190\nSince diagnostic tasks might include explanations alongside the predicted diagnosis, existing studies also evaluated these explanatory descriptions. We categorized the metrics based on their application scenarios: G denotes that the metric requires ground-truth diagnosis\nfor evaluation, while T indicates those applicable to textual descriptions (e.g., generated explanations). Notably, we only present a selection ofrepresentative diagnostic tasks from the included papers: disease diagnosis (DD), differential diagnosis (DDx), conversational\ndiagnosis (CD), medical image classiﬁcation (MIC), risk prediction (RP), mental health disorder detection (MHD), and diagnostic report generation (DRG).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 7\nsuch as databases80 or corpora82, to retrieve accurate information during\ninference. Fine-tuning requires well-annotated datasets with sufﬁcient\nlabeled diagnostic cases133. Pre-training, by contrast, utilizes diverse corpora,\nincluding unstructured text (e.g., clinical notes, literature) and structured\ndata (e.g., lab results), to establish a robust knowledge foundation via\nunsupervised language modeling\n42,153.A l t h o u g hﬁne-tuning and pre-\ntraining facilitate high performance and reliability133, they demand sig-\nniﬁcant resources, including advanced hardware and extensive biomedical\ndata (see Fig.3f), which are costly and often hard to obtain24. In practice, not\nall diagnostic scenarios require expert-level accuracy. Applications such as\nlarge-scale screenings154, mobile health risk alerts155, or public health\neducation30 prioritize cost-effectiveness and scalability. Overall, balancing\naccuracy with resource constraints depends on the speciﬁc use case.\nDespite advances in LLM-based methods for disease diagnosis, this\nscoping review highlighted several barriers to their clinical utility (Fig.5). One\nlimitation lies in information gathering. Most studies implicitly assume that\nthe available patient information is sufﬁcient for diagnosis, which often\nfails156,e s p e c i a l l yi ni n i t i a lc o n s u l t a t i o n so rw i t hc o m p l e xd i s e a s e s ,i n c r e a s i n g\nthe risk of misdiagnosis157. In practice, clinical information gathering is\niterative, starting with initial data (e.g., subjective symptoms), reﬁning diag-\nnoses, and conducting further tests or screenings158. This process relies heavily\non experienced clinicians140. To reduce this dependence, recent studies have\nexplored multi-round diagnostic dialogs to collect relevant information159,160.\nFor example, AIME140 uses LLMs for clinical history-taking and diagnostic\ndialog, while Sun et al.160 utilized reinforcement learning to formulate disease\nscreening questions. Future efforts could further embed awareness of infor-\nmation incompleteness into models or develop techniques for automatic\ndiagnostic queries\n161. Another limitation arises from the reliance on single\ndata modalities, whereas clinicians typically synthesize information from\nmultiple modalities for accurate diagnosis44.A d d i t i o n a l l y ,r e a l - w o r l dh e a l t h\nsystems often operate in isolated data silos, with patient information dis-\ntributed across institutions\n26. Addressing these issues will require efforts to\ncollect and integrate multi-modal data and establish uniﬁed health systems\nthat facilitate seamless data sharing across institutions162.\nBarriers also exist in the information integration process. Some studies\nutilized clinical vignettes for diagnostic tasks without fulﬁlling the SOAP\nstandard163. While adhering to clinical guidelines is crucial142, limited studies\nhave incorporated this factor into diagnostic systems164. For example,\nKresevic et al.82 sought to enhance clinical decision support systems by\naccurately explaining guidelines for chronic Hepatitis C management.\nBesides, the integration and interpretation of lab test results pose signiﬁcant\nvalue in healthcare165. For example, Bhasuran et al.166 reported that incor-\nporating lab data enhanced the diagnostic accuracy of GPT-4 by up to 30%.\nA future direction is the effective integration of lab test results into LLM-\nbased diagnostic systems.\nExploring clinician-patient-diagnostic system interactions offers a\npromising research direction\n167. Diagnostic systems are desired to assist\nclinicians by providing Supplementary information to improve accuracy\nand efﬁciency58,168, incorporating expert feedback for continuous reﬁne-\nment. A user-friendly interface is essential for effective human-machine\ninteraction, enabling clinicians to input data and engage in discussions with\nthe system. Human language interaction further enhances usability by\nallowing natural conversation with LLM-based diagnostic tools168, reducing\ncognitive load. Additionally, LLM-aided explanations improve transpar-\nency by providing rationales for suggested diagnoses\n145, fostering trust, and\nfacilitating informed decision-making among clinicians and patients.\nMost of the studies focused on diagnostic accuracy, but overlooked\nethical considerations, like explainability, trustworthiness, privacy protec-\ntion, and fairness169. Providing diagnostic predictions alone is insufﬁcient in\nclinical scenarios, as the black-boxnature of LLMs often undermines trust99.\nDesigning diagnostic models with explainability is desired145. For example,\nDual-Inf is a prompt-based framework that offers potential diagnoses while\nexplaining its reasoning143. Besides, since LLMs suffer from hallucinations,\nhow to enhance users’ trustworthiness toward LLM-based diagnostic\nmodels is worth exploring170. Potential solutions include using fact-checking\ntools to verify the output’s factuality171. Regarding privacy, adherence to\nregulations like HIPAA and GDPR, including de-identifying sensitive data,\nis essential\n26,172. For example, SkinGPT-4, a dermatology diagnostic system,\nwas designed for local deployment to ensure privacy protection173. Fairness\nis another concern, as patients should not face discrimination based on\ngender, age, or race\n169, but research on fairness in LLM-based diagnostics\nremains scarce174.\nIn the context of modeling, building superior models for accurate and\nreliable diagnosis remains an exploration. While pre-training on extensive\nmedical datasets beneﬁts diagnostic reasoning175, many medical LLMs\ngenerally lag behind general-domain counterparts in parameter scale148,176,\nunderscoring the potential of developing large-scale generalist models for\ndisease diagnosis. Besides, LLMs are prone to catastrophic forgetting\n177,\nwhere previously acquired knowledge or skills are lost when learning new\ninformation. Addressing this issue facilitates the development of generalist\ndiagnostic models but requires incorporating robust continuous learning\ncapabilities\n178. One alternative approach for accurate diagnosis involves\ncoordinating multiple specialized models, simulating interdisciplinary\nclinical discussions to tackle complex cases179. For example, Med-MoE180 is a\nmixture-of-experts framework leveraging medical texts and images and\nachieved an accuracy of 91.4% in medical image classiﬁcation. Additionally,\nhallucinations in LLMs undermine diagnostic reliability170, necessitating\nsolutions such as knowledge editing181, external knowledge retrieval82,a n d\nnovel model architectures or pre-training strategies175. Another promising\navenue is longitudinal data modeling, as clinicians routinely analyze EHRs\nFig. 4 |Summary of the evaluation approaches for diagnostic tasks.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 8\nspanning multiple years to inform decision-making182,183. Besides, modeling\ntemporal data helps with early diagnosis56,184 to improve patient outcomes.\nFor example, early detection of lung adenocarcinoma might increase the\n5-year survival rate to 52%\n185. However, challenges like irregular sampling\nintervals and missing data persist186, necessitating advanced methodologies\nto effectively capture temporal dependencies25.\nAnother challenge in developing diagnostic models is benchmark\navailability147. In this review, 49.6% of the included studies relied on pri-\nvate datasets, which were often inaccessible due to privacy concerns82.\nAdditionally, the scarcity of annotated data limits progress, as well-\nannotated datasets with ground-truth diagnosis enable automated eva-\nluation, reducing reliance on human assessment\n143. Hence, constructing\nand releasing annotated benchmark datasets would greatly support the\nresearch community\n147. Regarding performance evaluation, some studies\neither used small-scale data57 or unrealistic data, such as snippets from\ncollege books145 and LLM-generated clinical notes147, for disease diagnosis,\nwhile large-scale real-world data can truly validate diagnostic\ncapabilities\n182. Besides, the lack of uniﬁed qualitative metrics is another\nissue. For example, the evaluation of diagnostic explanation varies in\ndifferent studies 143,187, including necessity 187, consistency 108, and\ncompeleteness143. Unifying qualitative metrics foster a fair comparison.\nAdditionally, many included studies failed to compare with conventional\ndiagnostic models, while recent studies reported that traditional models,\ne.g., Transformer\n188, might beat LLM-based counterparts in clinical\nprediction189. Therefore, future studies should compare with traditional\nbaselines for comprehensive evaluation.\nRegarding the deployment of diagnostic systems, several challenges\nwarrant further investigation, including model stability, generalizability,\nand efﬁciency. Current studies have highlighted that LLMs often struggle\nwith diagnosis stability182, fail to generalize well across data from different\ninstitutions190, and encounter efﬁciency limitations191. For instance, even\nminor variations in instructions, such as from asking“ﬁnal diagnosis” to\n“primary diagnosis”, can drop the accuracy 10.6% on cholecystitis\ndiagnosis182. Addressing these limitations will advance the reliability and\napplicability of diagnostic models. Another promising avenue is deploying\ndiagnostic algorithms on edge devices\n192. Such systems could enable the real-\ntime collection of health data, such as ECG rhythms19, to support con-\ntinuous health monitoring95. However, regulatory barriers, including the\nstringent approval standards imposed by agencies such as the U.S. Food and\nDrug Administration (FDA) and the European Union’s Medical Device\nRegulation (MDR)\n193,r e m a i nas i g n iﬁcant obstacle to clinical adoption.\nOvercoming these challenges will be vital to ensure the safe and effective\nintegration of LLM-based diagnostics into clinical practice.\nIn conclusion, our study provided a comprehensive review of LLM-\nbased methods for disease diagnosis. Our contributions were multifaceted.\nFirst, we summarized the disease types,the associated clinical specialties,\nclinical data, the employed LLM techniques, and evaluation methods within\nthis research domain. Second, we compared the advantages and limitations\nInformation gathering\n/g153Limited availability of  multi-\nmodal data 173\n/g153Dependence on expert \nknowledge 140\n/g153Incomplete information 156\n/g153Fragmented and siloed data 26\nInformation integration\n/g153Deviation from SOAP standard 163\n/g153Non-adherence to clinical guidelines 164\n/g153Neglect of lab result integration 166\nDecision-making\n/g153Limited data validation 49\n/g153Absence of ethical considerations 169\n/g153Insufficient real-world evaluation 147\nSymptom\npresentation Develop care plan\nCurrent Limitations in the Diagnostic Pipeline\nFuture Directions\nInformation gathering\n/g153Multi-modal data collection\n/g153Automatic clinical query\n/g153Missing info. awareness\n/g153Unified collection platform\nDeployment\n/g153System stability\n/g153Model generalizability\n/g153Model efficiency\n/g153Edge device deployment\n/g153Regulatory hurdle\nEthical consideration\n/g153Trustworthiness\n/g153Explainability and clarity\n/g153Privacy protection\n/g153Equity (e.g., fairness)\nModeling\n/g153Large generalist model\n/g153Continual learning\n/g153Mixture-of-experts\n/g153Knowledge editing\n/g153Longitudinal data modeling\nBenchmarks\n/g153Public dataset\n/g153Well-annotated dataset\n/g153Multi-modal dataset\n/g153Unified qualitative metrics\n/g153Comprehensive evaluation\nAutomatic\ndiagnosis\nHuman-machine interaction\n/g153Patient involvement\n/g153Adaptive interaction interface\n/g153Human language interaction\n/g153LLM-aided explanation\nFig. 5 |Summary of the limitations and future directions for LLM-based disease diagnosis.\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 9\nof mainstream LLM techniques and evaluation methods, offering recom-\nmendations for developing diagnostic systems based on varying user\ndemands. Third, we identiﬁed intriguing phenomena from the current\nstudies and provided insights into their underlying causes. Lastly, we ana-\nlyzed the current challenges and outlined the future directions of this\nresearch ﬁeld. In summary, our review presented an in-depth analysis of\nLLM-based disease diagnosis, outlined its blueprint, inspired future\nresearch, and helped streamline efforts in developing diagnostic systems.\nMethods\nSearch strategy and selection criteria\nThis scoping review followed the PRISMA guidelines, as shown in Fig.6.W e\nconducted a literature search for relevant articles published between January\n1, 2019, and July 18, 2024, across seven electronic databases: PubMed,\nCINAHL, Scopus, Web of Science, Google Scholar, ACM Digital Library,\nand IEEE Xplore. Search terms were selected based on expert consensus (see\nSupplementary Data 1).\nA two-stage screening process focused on LLMs for human disease\ndiagnosis. The ﬁrst stage involved title and abstract screening by two\nindependent reviewers, excluding papers based on the following cri-\nteria: (a) articles unrelated to LL M so rf o u n d a t i o nm o d e l s ,a n d( b )\narticles irrelevant to the health domain. The second stage was full-text\nscreening, emphasizing language models for diagnosis-related tasks\n(Supplementary Data 2), excluding non-English articles, review\npapers, editorials, and studies not explicitly focused on disease diag-\nnosis. The scope included studies that predicted probability values of\ndiseases (e.g., the probability of depression) and the studies in which\nthe foundation models involved text modalities (e.g., vision-language\nmodels) and utilized non-text data (e.g., medical images) as input. Our\nreview excluded the foundation models without text modality, such as\nvision foundation models, because the scope highlighted“language”\nmodels. Following related works\n194, we further excluded studies purely\nbuilt on non-generative language models, like BERT 188 and\nRoBERTa195, since the generative capability is a critical characteristic of\nLLMs to facilitate the development of the diagnostic system in the era\nof generative AI30,31. Final eligibility was determined by at least two\nindependent reviewers, with disagreements resolved by consensus or a\nthird reviewer.\nData extraction\nInformation from the articles was categorized into four groups: (1) Basic\ninformation: title, publication venue, publication date (year and month),\nand region of correspondence. (2) Data-related information: data sources\n(continents), dataset type, modality (e.g., text, image, video, text-image),\nclinical specialty, disease name, data availability (private or public), and data\nsize. (3) Model-related information: base LLM type, parameter size, and\ntechnique type. (4) Evaluation: evaluation scheme (e.g., automated or\nhuman) and evaluation metrics (e.g.,accuracy, precision). See Supple-\nmentary Table 1 for the data extraction form.\nData synthesis\nWe synthesized insights from the data extraction to highlight key themes\nin LLM-based disease diagnosis. First, we presented the review scope,\ncovering disease-associated clinical specialties, clinical data, data mod-\nalities, and LLM techniques. We also analyzed meta-information,\nincluding development trends, the most widely used LLMs, and data\nsource distribution. Next, we summarized various LLM-based techni-\nques and evaluation strategies, discussing their strengths and weaknesses\nand offering targeted recommendations. We categorized modeling\napproaches into four areas (prompt-based methods, RAG,ﬁne-tuning,\nand pre-training), with detailed subtypes. Additionally, we examined\nchallenges in current research and outlined potential future directions.\nIn summary, our synthesis covered data, LLM techniques, performance\nevaluation, and application scenarios, in line with established reporting\nstandards.\nData availability\nThe analyzed data are included in this article. Aggregate data analyzed in\nthis study is available athttps://github.com/betterzhou/Awesome-LLM-\nDisease-Diagnosis\nFig. 6 | PRISMAﬂowchart of study records.\nPRISMA ﬂowchart showing the study selection\nprocess.\nnoitacifitnedIgnineercSytilibigilE\nIdentified articles from databases\n(n = 11,170)\n PubMed (2,171)\n CINAHL (227)\n Scopus (143)\n ACM Digital Library (1,009)\n IEEE Xplore (346)\n Google Scholar (6,399)\n Web of Science (875)\nRemove\n Duplicate articles\n(n = 5,334)\nTitle and abstract screening\n(n = 5,836)\nExclude\n Irrelevant topics\n(n = 3,928)\nScreening by full texts\n(n = 1,908)\nExclude\n Irrelevant to disease diagnosis\n(n = 954)\n Not LLM-based (n = 223)\n Reviews or editorials (n = 323)\n Non-English papers (n = 10)\ndedulcnI\nStudies included in the review\n(n = 398)\nIdentification of studies via databases\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 10\nReceived: 22 December 2024; Accepted: 17 May 2025;\nReferences\n1. Liu, Y. et al. A deep learning system for differential diagnosis of skin\ndiseases. Nat. Med.26, 900–908 (2020).\n2. Mei, X. et al. Arti ﬁcial intelligence–enabled rapid diagnosis of\npatients with covid-19.Nat. Med.26, 1224–1228 (2020).\n3. Li, X. et al. Arti ﬁcial intelligence-assisted reduction in patients’\nwaiting time for outpatient process: a retrospective cohort study.\nBMC health Serv. Res.21,1 –11 (2021).\n4. Li, B. et al. The performance of a deep learning system in assisting\njunior ophthalmologists in diagnosing 13 major fundus diseases: a\nprospective multi-center clinical trial.npj Digit. Med.7, 8 (2024).\n5. Qiu, S. et al. Development and validation of an interpretable deep\nlearning framework for alzheimer’s disease classiﬁcation. Brain 143,\n1920–1933 (2020).\n6. Barnett, G. O., Cimino, J. J., Hupp, J. A. & Hoffer, E. P. Dxplain: an\nevolving diagnostic decision-support system.JAMA 258,6 7–74\n(1987).\n7. Su, C., Xu, Z., Pathak, J. & Wang, F. Deep learning in mental health\noutcome research: a scoping review.Transl. Psychiatry10, 116\n(2020).\n8. Gkotsis, G. et al. Characterisation of mental health conditions in\nsocial media using informed deep learning.Sci. Rep.7,1 –11 (2017).\n9. Du, J. et al. Extracting psychiatric stressors for suicide from social\nmedia using deep learning.BMC Med. Inform. Decis. Mak.18,7 7–87\n(2018).\n10. Caraballo, P. J. et al. Trustworthiness of a machine learning early\nwarning model in medical and surgical inpatients.JAMIA Open8,\nooae156 (2025).\n11. Sajda, P. Machine learning for detection and diagnosis of disease.\nAnnu. Rev. Biomed. Eng.8, 537–565 (2006).\n12. Stafford, I. S. et al. A systematic review of the applications of artiﬁcial\nintelligence and machine learning in autoimmune diseases.NPJ\nDigit. Med.3, 30 (2020).\n13. Kline, A. et al. Multimodal machine learning in precision health: A\nscoping review.npj Digit. Med.5, 171 (2022).\n14. Aggarwal, R. et al. Diagnostic accuracy of deep learning in medical\nimaging: a systematic review and meta-analysis.NPJ Digit. Med.\n4,\n65 (2021).\n15. Myszczynska, M. A. et al. Applications of machine learning to\ndiagnosis and treatment of neurodegenerative diseases.Nat. Rev.\nNeurol. 16, 440–456 (2020).\n16. Fatima, M. & Pasha, M. Survey of machine learning algorithms for\ndisease diagnostic.J. Intell. Learn. Syst. Appl.9,1 –16 (2017).\n17. Choy, S. P. et al. Systematic review of deep learning image analyses\nfor the diagnosis and monitoring of skin disease.NPJ Digit. Med.6,\n180 (2023).\n18. Mei, X. et al. Interstitial lung disease diagnosis and prognosis using\nan AI system integrating longitudinal data.Nature communications\n14.1, 2272 (2023).\n19. Zhou, S. et al. Open-world electrocardiogram classiﬁcation via\ndomain knowledge-driven contrastive learning.Neural Netw179,\n106551 (2024).\n20. Zhou, Q. et al. A machine and human reader study on ai diagnosis\nmodel safety under attacks of adversarial images.Nat. Commun.12,\n7281 (2021).\n21. Hannun, A. Y. et al. Cardiologist-level arrhythmia detection and\nclassiﬁcation in ambulatory electrocardiograms using a deep neural\nnetwork. Nat. Med.25,6 5–69 (2019).\n22. Brown, T. et al. Language models are few-shot learners. InAdvances\nin Neural Information Processing Systems, vol. 33 (2020).\n23. Touvron, H. et al. Llama: Open and efﬁcient foundation language\nmodels. arXiv preprint arXiv:2302.13971(2023).\n24. Singhal, K. et al. Large language models encode clinical knowledge.\nNature 620, 172–180 (2023).\n25. Yang, Z., Mitra, A., Kwon, S. & Yu, H. ClinicalMamba: A generative\nclinical language model on longitudinal clinical notes. In\nProceedings of the 6th Clinical Natural Language Processing\nWorkshop,5 4–63 (Association for Computational Linguistics, 2024).\n26. Peng, L. et al. An in-depth evaluation of federated learning on\nbiomedical natural language processing for information extraction.\nNPJ Digit. Med.7, 127 (2024).\n27. Zhan, Z., Zhou, S., Li, M. & Zhang, R. Ramie: retrieval-augmented\nmulti-task information extraction with large language models on\ndietary supplements.Journal of the American Medical Informatics\nAssociation ocaf002 (2025).\n28. Lu, M. Y. et al. A multimodal generative AI copilot for human\npathology. Nature 1–3 (2024).\n29. Kim, J. et al. Large language models outperform mental and medical\nhealth care professionals in identifying obsessive-compulsive\ndisorder. NPJ Digit. Med.7, 193 (2024).\n30. Thirunavukarasu, A. J. et al. Large language models in medicine.Nat.\nMed. 29, 1930\n–1940 (2023).\n31. Zhou, H. et al. A survey of large language models in medicine:\nProgress, application, and challenge.arXiv preprint\narXiv:2311.05112 (2023).\n32. Meng, X. et al. The application of large language models in medicine:\nA scoping review.Iscience 27, (2024).\n33. Zhang, Y. et al. Data-centric foundation models in computational\nhealthcare: A survey.arXiv preprint arXiv:2401.02458(2024).\n34. Du, X. et al. Generative large language models in electronic health\nrecords for patient care since 2023: A systematic review.medRxiv\n2024–08 (2024).\n35. Wang, C. et al. A survey for large language models in biomedicine.\narXiv preprint arXiv:2409.00133(2024).\n36. Li, L. et al. A scoping review of using large language models (LLMs) to\ninvestigate electronic health records (EHRs).arXiv preprint\narXiv:2405.03066 (2024).\n37. He, Kai, et al. A survey of large language models for healthcare: from\ndata, technology, and applications to accountability and ethics.\nInformation Fusion (2025): 102963.\n38. Pressman, S. M. et al. Clinical and surgical applications of large\nlanguage models: A systematic review.J. Clin. Med.13, 3041 (2024).\n39. Omar, M., Brin, D., Glicksberg, B. & Klang, E. Utilizing natural\nlanguage processing and large language models in the diagnosis\nand prediction of infectious diseases: A systematic review.Am J\nInfect Control52, 992–1001 (2024).\n40. Giuffrè, M. et al. Systematic review: The use of large language\nmodels as medical chatbots in digestive diseases.Alimentary\npharmacology & therapeutics60.2, 144–166 (2024).\n41. Mai, A. S., Adnan, K. & Mohammad, Y. Medpromptx: Grounded\nmultimodal prompting for chest x-ray diagnosis.ArXiv abs/\n2403.15585 (2024).\n42. Kraljevic, Z. et al. Foresight— a generative pretrained transformer for\nmodelling of patient timelines using electronic health records: a\nretrospective modelling study.Lancet Digital Health6, e281–e290\n(2024).\n43. GLM, T. et al. Chatglm: A family of large language models from glm-\n130b to glm-4 all tools.arXiv preprint arXiv:2406.12793(2024).\n44. Busch, F. et al. Integrating text and image analysis: Exploring GPT-\n4v’s capabilities in advanced radiological applications across\nsubspecialties. J. Med Internet Res.26, e54948 (2024).\n45. Kim, Y., Xu, X., McDuff, D., Breazeal, C. & Park, H. W. Health-llm:\nLarge language models for health prediction via wearable sensor\ndata. Conference on Health, Inference, and Learning(2024).\n46. Gao, Z., Hu, Y., Tan, C. & Li, S. Z. Preﬁxmol: Target- and chemistry-\naware molecule design via preﬁx embedding.ArXiv preprintabs/\n2302.07120 (2023).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 11\n47. Niu, S. et al. Ehr-knowgen: Knowledge-enhanced multimodal\nlearning for disease diagnosis generation.Inf. Fusion102, 102069\n(2024).\n48. Chung, P. et al. Large language model capabilities in perioperative\nrisk prediction and prognostication.JAMA surgery159.8, 928–937\n(2024).\n49. Delsoz, M. et al. Performance of ChatGPT in diagnosis of corneal eye\ndiseases. Cornea 43.5, 664–670 (2024).\n50. Fink, M. A. et al. Potential of chatgpt and gpt-4 for data mining of\nfree-text ct reports on lung cancer.Radiology 308, e231362 (2023).\n51. Moallem, G., Gonzalez, A. D. L. M., Desai, A. & Rusu, M. Automated\nlabeling of spondylolisthesis cases through spinal mri radiology\nreport interpretation using ChatGPT. InMedical Imaging 2024:\nComputer-Aided Diagnosis, vol. 12927, 702–706 (SPIE, 2024).\n52. Benary, M. et al. Leveraging large language models for decision\nsupport in personalized oncology.JAMA Netw. Open6,\ne2343689–e2343689 (2023).\n53. Reese, J. T. et al. On the limitations of large language models in\nclinical diagnosis.medRxiv 2023-07 (2024).\n54. Sarangi, P. K., Irodi, A., Panda, S., Nayak, D. S. K. & Mondal, H.\nRadiological differential diagnoses based on cardiovascular and\nthoracic imaging patterns: perspectives of four large language\nmodels. Indian J. Radiol. Imaging34, 269–275 (2024).\n55. Wang, J. et al. Augmented risk prediction for the onset of alzheimer’s\ndisease from electronic health records with large language models.\narXiv preprint arXiv:2405.16413(2024).\n56. Du, X. et al. Enhancing early detection of cognitive decline in the\nelderly: a comparative study utilizing large language models in\nclinical notes.eBioMedicine 109, 105401 (2024).\n57. Haider, S. A. et al. Evaluating large language model (LLM)\nperformance on established breast classiﬁcation systems.\nDiagnostics 14, 1491 (2024).\n58. Siepmann, R. et al. The virtual reference radiologist: comprehensive\nAI assistance for clinical image reading and interpretation.European\nRadiology 34, 6652–6666 (2024).\n59. Peng, L. et al. Mmgpl: Multimodal medical data analysis with graph\nprompt learning.Med. Image Anal.97, 103225 (2024).\n60. Xu, S. et al. Elixr: Towards a general purpose x-ray artiﬁcial\nintelligence system through alignment of large language models and\nradiology vision encoders.arXiv preprint arXiv:2308.01317(2023).\n61. Gertz, R. J. et al. Potential of GPT-4 for detecting errors in radiology\nreports: Implications for reporting accuracy.Radiology 311,\ne232714 (2024).\n62. Ono, D., Dickson, D. W. & Koga, S. Evaluating the efﬁcacy of few-\nshot learning for GPT-4vision in neurodegenerative disease\nhistopathology: A comparative analysis with convolutional neural\nnetwork model.Neuropathol. Appl Neurobiol.50, e12997 (2024).\n63. Dai, Y., Gao, Y. & Liu, F. Transmed: Transformers advance multi-\nmodal medical image classiﬁcation. Diagnostics 11, 1384 (2021).\n64. Upadhyaya, D. P. et al. A 360° View for Large Language Models:\nEarly Detection of Amblyopia in Children Using Multi-view Eye\nMovement Recordings. InInternational Conference on Artiﬁcial\nIntelligence in Medicine(pp. 165-175). (Cham: Springer Nature,\nSwitzerland, 2024).\n65. Noda, M. et al. Feasibility of multimodal artiﬁcial intelligence using\nGPT-4 vision for the classiﬁcation of middle ear disease: Qualitative\nstudy and validation.JMIR AI3, e58342 (2024).\n66. Antaki, F., Chopra, R. & Keane, P. A. Vision-language models for\nfeature detection of macular diseases on optical coherence\ntomography. JAMA Ophthalmol142, 573–576 (2024).\n67. Peng, Z. et al. Development and evaluation of multimodal AI for\ndiagnosis and triage of ophthalmic diseases using ChatGPT and\nanterior segment images: protocol for a two-stage cross-sectional\nstudy. Front. Artif. Intell.6, 1323924 (2023).\n68. Suh, P. S. et al. Comparing diagnostic accuracy of radiologists\nversus GPT-4v and Gemini Pro Vision using image inputs from\ndiagnosis please cases.Radiology 312, e240273 (2024).\n69. Pugliese, G. et al. Are artiﬁcial intelligence large language models a\nreliable tool for difﬁcult differential diagnosis? An a posteriori\nanalysis of a peculiar case of necrotizing otitis externa.Clin. Case\nRep. 11, e7933 (2023).\n70. Hu, C. et al. Exploiting ChatGPT for diagnosing autism-associated\nlanguage disorders and identifying distinct features.arXiv preprint\narXiv:2405.01799 (2024).\n71. Deng, S. et al. Hear me, see me, understand me: Audio-visual autism\nbehavior recognition. (IEEE Transactions on Multimedia, 2024).\n72. Rezaii, N. et al. Artiﬁcial intelligence classiﬁes primary progressive\naphasia from connected speech.Brain 147, 3070–3082 (2024).\n73. Liu, C., Ma, Y., Kothur, K., Nikpour, A. & Kavehei, O. Biosignal\ncopilot: Leveraging the power of LLMs in drafting reports for\nbiomedical signals.medRxiv 2023.06.28.23291916 (2023).\n74. Yu, H., Guo, P. & Sano, A. Zero-shot ECG diagnosis with large\nlanguage models and retrieval-augmented generation. In\nML4H@NeurIPS (2023).\n75. Wu, D. et al. Multimodal machine learning combining facial images\nand clinical texts improves the diagnosis of rare genetic diseases.\narXiv preprint arXiv:2312.15320(2023).\n76. Feng, Y., Xu, X., Zhuang, Y. & Zhang, M. Large language models\nimprove alzheimer’s disease diagnosis using multi-modality data. In\n2023 IEEE International Conference on Medical Artiﬁcial Intelligence\n(MedAI),6 1–66 (IEEE, 2023).\n77. Ma, M. D. et al. Clibench: Multifaceted evaluation of large language\nmodels in clinical decisions on diagnoses, procedures, lab tests\norders and prescriptions.arXiv preprint arXiv:2406.09923(2024).\n78. Liang, L. et al. Genetic transformer: An innovative large language\nmodel driven approach for rapid and accurate identiﬁcation of\ncausative variants in rare genetic diseases.medRxiv 2024-07 (2024).\n79. Thompson, W. et al. Large language models with retrieval-\naugmented generation for zero-shot disease phenotyping. InDeep\nGenerative Models for Health Workshop NeurIPS 2023(2023).\n80. Shi, W. et al. Retrieval-augmented large language models for\nadolescent idiopathic scoliosis patients in shared decision-making.\nIn Proceedings of the 14th ACM International Conference on\nBioinformatics, Computational Biology, and Health Informatics,\n1–10 (2023).\n81. Wen, Y., Wang, Z. & Sun, J. MindMap: Knowledge graph prompting\nsparks graph of thoughts in large language models. InProceedings\nof the 62nd Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), 10370–10388 (Association for\nComputational Linguistics, Bangkok, Thailand, 2024).\n82. Kresevic, S. et al. Optimization of hepatological clinical guidelines\ninterpretation by large language models: a retrieval augmented\ngeneration-based framework.NPJ Digit. Med.7, 102 (2024).\n83. Yu, H., Guo, P. & Sano, A. ECG semantic integrator (ESI): A\nfoundation ECG model pretrained with LLM-enhanced cardiological\ntext. Trans. Mach. Learn. Res. (2024).\n84. Ghersin, I. et al. Comparative evaluation of a language model and\nhuman specialists in the application of European guidelines for the\nmanagement of inﬂammatory bowel diseases and malignancies.\nEndoscopy 56, 706–709 (2024).\n85. Ge, J. et al. Development of a liver disease–speciﬁc large language\nmodel chat interface using retrieval-augmented generation.\nHepatology 80, 1158–1168 (2024).\n86. Xia, P. et al. RULE: Reliable multimodal RAG for factuality in medical\nvision language models. In Al-Onaizan, Y., Bansal, M. & Chen, Y.-N.\n(eds.) Proceedings of the 2024 Conference on Empirical Methods in\nNatural Language Processing, 1081–1093 (Association for\nComputational Linguistics, Miami, Florida, USA, 2024).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 12\n87. Ranjit, M., Ganapathy, G., Manuel, R. & Ganu, T. Retrieval\naugmented chest x-ray report generation using openai gpt models.\nIn Deshpande, K. et al. (eds.)Proceedings of the 8th Machine\nLearning for Healthcare Conference, vol. 219 ofProceedings of\nMachine Learning Research, 650–666 (PMLR, 2023).s\n88. Li, Z., Zhang, J., Zhou, W., Zheng, J. & Xia, Y. Gpt-agents based on\nmedical guidelines can improve the responsiveness and\nexplainability of outcomes for traumatic brain injury rehabilitation.\nSci. Rep.14, 7626 (2024).\n89. Abdullahi, T. et al. Learning to make rare and complex diagnoses\nwith generative ai assistance: qualitative study of popular large\nlanguage models.JMIR Med. Educ.10, e51391 (2024).\n90. Rifat Ahmmad Rashid, M. et al. A respiratory disease management\nframework by combining large language models and convolutional\nneural networks for effective diagnosis.Int. J. Comput. Digit. Syst.\n16, 189–202 (2024).\n91. Ferber, D. et al. Autonomous artiﬁcial intelligence agents for clinical\ndecision making in oncology.ArXiv abs/2404.04667 (2024).\n92. Soong, D. et al. Improving accuracy of GPT-3/4 results on\nbiomedical data using a retrieval-augmented language model.PLOS\nDigital Health3, e0000568 (2024).\n93. Rau, A. et al. A context-based chatbot surpasses trained radiologists\nand generic ChatGPT in following the ACR appropriateness\nguidelines. Radiology 308, e230970 (2023).\n94. Zhu, Y. et al. Emerge: Integrating RAG for improved multimodal EHR\npredictive modeling.ArXiv abs/2406.00036 (2024).\n95. Chen, C. et al. Large Language Model-Informed ECG Dual Attention\nNetwork for Heart Failure Risk Prediction.IEEE Transactions on Big\nData 11, 948–960 (2024).\n96. Askell, A. et al. A general language assistant as a laboratory for\nalignment. arXiv preprint arXiv:2112.00861 (2021).\n97. Liu, H. et al. Visual instruction tuning.Advances in neural information\nprocessing systems36, 34892–34916 (2023).\n98. Toma, A. et al. Clinical camel: An open expert-level medical\nlanguage model with dialogue-based knowledge encoding. arXiv\npreprint arXiv:2305.12031 (2023).\n99. Wu, J., Wu, X., Zheng, Y. & Yang, J. Medkp: Medical dialogue with\nknowledge enhancement and clinical pathway encoding.arXiv\npreprint arXiv:2403.06611(2024).\n100. He, Y., Zhang, Y., He, S. & Wan, J. BP4ER: Bootstrap Prompting for\nExplicit Reasoning in Medical Dialogue Generation. InProceedings\nof the 2024 Joint International Conference on Computational\nLinguistics, Language Resources and Evaluation (LREC-COLING\n2024), pages 2480–2492 (ELRA and ICCL, Torino, Italia, 2024).\n101. Xu, K., Cheng, Y., Hou, W ., Tan, Q. & Li, W. Reasoning Like a Doctor:\nImproving Medical Dialogue Systems via Diagnostic Reasoning\nProcess Alignment. InFindings of the Association for Computational\nLinguistics: ACL 2024, pages 6796–6814 (Association for\nComputational Linguistics, Bangkok, Thailand, 2024).\n102. Yang, L. et al. Advancing multimodal medical capabilities of Gemini.\narXiv preprint arXiv:2405.03162(2024).\n103. He, S. et al. Meddr: Diagnosis-guided bootstrapping for large-scale\nmedical vision-language learning. arXiv e-prints (2024): arXiv-2404.\n104. Chen, Z. et al. Dia-LLaMA: Towards large language model-driven ct\nreport generation. arXiv preprint arXiv:2403.16386 (2024).\n105. Liu, Z. et al. Radiology-llama2: Best-in-class large language model\nfor radiology.arXiv preprint arXiv:2309.06419(2023).\n106. Alkhaldi, A. et al. Minigpt-med: Large language model as a general\ninterface for radiology diagnosis. arXiv preprint arXiv:2407.04106\n(2024).\n107. Lee, S., Youn, J., Kim, H., Kim, M. & Yoon, S. H. CXR-LLAVA: a\nmultimodal large language model for interpreting chest X-ray\nimages. arXiv (2023).\n108. Kwon, T. et al. Large language models are clinical reasoners:\nReasoning-aware diagnosis framework with prompt-generated\nrationales. InProceedings of the AAAI Conference on Artiﬁcial\nIntelligence, vol. 38, 18417–18425 (2024).\n109. Xu, H. et al. A whole-slide foundation model for digital pathology\nfrom real-world data.Nature 630, 181–188 (2024).\n110. Zhou, J. et al. Pre-trained multimodal large language model\nenhances dermatological diagnosis using SkinGPT-4.Nat.\nCommun. 15, 5649 (2024).\n111. Sun, Y. et al. Pathasst: A generative foundation ai assistant towards\nartiﬁcial general intelligence of pathology. InProceedings of the\nAAAI Conference on Artiﬁcial Intelligence, 38, 5034–5042 (2024).\n112. Zhang, X. et al. When LLMs Meets Acoustic Landmarks: An Efﬁcient\nApproach to Integrate Speech into Large Language Models for\nDepression Detection. InProceedings of the 2024 Conference on\nEmpirical Methods in Natural Language Processing, pages 146–158\n(Association for Computational Linguistics, Miami, Florida, USA,\n2024).\n113. Ouyang, L. et al. Training language models to follow instructions with\nhuman feedback.Advances in neural information processing\nsystems 35, 27730–27744 (2022).\n114. Schulman, J. et al. Proximal policy optimization algorithms. arXiv\npreprint arXiv:1707.06347 (2017).\n115. Zhou, Z. et al. Large model driven radiology report generation with\nclinical quality reinforcement learning.arXiv preprint\narXiv:2403.06728 (2024).\n116. Wang, G., Yang, G., Du, Z., Fan, L. & Li, X. Clinicalgpt: large language\nmodels ﬁnetuned with diverse medical data and comprehensive\nevaluation. arXiv preprint arXiv:2306.09968(2023).\n117. Zhang, H. et al. HuatuoGPT, Towards Taming Language Model to Be\na Doctor. InFindings of the Association for Computational\nLinguistics: EMNLP 2023, pages 10859–10885 (Association for\nComputational Linguistics, Singapore, 2023).\n118. Zeng, G. et al. MedDialog: Large-scale Medical Dialogue Datasets.\nIn Proceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing (EMNLP), pages 9241–9250, Online.\n(Association for Computational Linguistics, 2020).\n119. Gao, L., Schulman, J. & Hilton, J. Scaling laws for reward model\noveroptimization. InInternational Conference on Machine Learning,\npages 10835–10866 (PMLR, 2023).\n120. Ye, Z. et al. Beyond Scalar Reward Model: Learning Generative\nJudge from Preference Data. ArXiv abs/2410.03742 (2024).\n121. Henderson, P. et al. Deep reinforcement learning that matters.\nProceedings of the AAAI conference on artiﬁcial intelligence. 32 (2018).\n122. Rafailov, R. et al. Direct preference optimization: Your language\nmodel is secretly a reward model.Advances in Neural Information\nProcessing Systems36, 53728–53741 (2023).\n123. Ye, Q. et al. Qilin-med: Multi-stage knowledge injection advanced\nmedical large language model. arXiv preprint arXiv:2310.09089 (2023).\n124. Yang, D. et al. Pediatricsgpt: Large language models as chinese\nmedical assistants for pediatric applications.Advances in Neural\nInformation Processing Systems37, 138632–138662 (2024).\n125. Guo, C., Pleiss, G., Sun, Y. & Weinberger, K. Q. On calibration of\nmodern neural networks. In Precup, D. & Teh, Y. W. (eds.)\nProceedings of the 34th International Conference on Machine\nLearning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017,\nvol. 70 ofProceedings of Machine Learning Research, 1321–1330\n(PMLR, 2017).\n126. Tajwar, F. et al. Preferenceﬁne-tuning of LLMs should leverage\nsuboptimal, on-policy data. InProceedings of the 41st International\nConference on Machine Learning (ICML’24), Vol. 235, 47441–47474\n(JMLR.org, 2024).\n127. Bai, Y. et al. Constitutional ai: Harmlessness from ai feedback. arXiv\npreprint arXiv:2212.08073 (2022).\n128. Hu, E. J. et al. Lora: Low-rank adaptation of large language models.\nIn The Tenth International Conference on Learning Representations,\nICLR 2022, Virtual Event, April 25-29, 2022(OpenReview.net, 2022).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 13\n129. Rajashekar, N. C. et al. Human-algorithmic interaction using a large\nlanguage model-augmented artiﬁcial intelligence clinical decision\nsupport system. InProceedings of the CHI Conference on Human\nFactors in Computing Systems, vol. 37, 1–20 (ACM, New York, NY,\nUSA, 2024).s\n130. Yang, X. et al. A large language model for electronic health records.\nNPJ digital medicine5, 194 (2022).\n131. Labrak, Y. et al. BioMistral: A Collection of Open-Source Pretrained\nLarge Language Models for Medical Domains. InFindings of the\nAssociation for Computational Linguistics: ACL 2024, pages\n5848–5864 (Association for Computational Linguistics, Bangkok,\nThailand, 2024).\n132. Wang, J., Seng, K. P., Shen, Y., Ang, L.-M. & Huang, D. Image to label\nto answer: An efﬁcient framework for enhanced clinical applications\nin medical visual question answering.Electronics 13, 2273 (2024).\n133. Liu, F. et al. A medical multimodal large language model for future\npandemics. NPJ Digit. Med.6, 226 (2023).\n134. Wu, C. et al. Towards generalist foundation model for radiology by\nleveraging web-scale 2D&3D medical data. arXiv preprint\narXiv:2308.02463 (2023).\n135. Ding, J.-E. et al. Large language multimodal models for new-onset\ntype 2 diabetes prediction usingﬁve-year cohort electronic health\nrecords. Scientiﬁc Reports14, 20774 (2024).\n136. Phan, V. M. H. et al. Decomposing disease descriptions for\nenhanced pathology detection: A multi-aspect vision-language pre-\ntraining framework. InProceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition, pages. 11492–11501\n(2024).\n137. Chen, J. et al. Towards Injecting Medical Visual Knowledge into\nMultimodal LLMs at Scale. InProceedings of the 2024 Conference\non Empirical Methods in Natural Language Processing, pages\n7346–7370 (Association for Computational Linguistics, Miami,\nFlorida, USA, 2024).\n138. Lu, Z. et al. Large language models in biomedicine and health:\ncurrent research landscape and future directions.J. Am. Med.\nInform. Assoc.31, 1801–1811 (2024).\n139. Li, H. et al. Llms-as-judges: a comprehensive survey on llm-based\nevaluation methods.arXiv preprint arXiv:2412.05579(2024).\n140. Tu, T. et al. Towards conversational diagnostic artiﬁcial\nintelligence[J]. Nature 1–9 (2025).\n141. Safranek, C. W. et al. Automated heart score determination via\nchatgpt: Honing a framework for iterative prompt development.J.\nAm. Coll. Emerg. Phys. Open5, e13133 (2024).\n142. Zhang, T. et al. Incorporating Clinical Guidelines Through Adapting\nMulti-modal Large Language Model for Prostate Cancer PI-RADS\nScoring. International Conference on Medical Image Computing and\nComputer-Assisted Intervention. (Cham: Springer Nature,\nSwitzerland, 2024).\n143. Zhou, S. et al. Explainable differential diagnosis with dual-inference\nlarge language models.npj Health Systems\n2, 12 (2025).\n144. Chen, X. et al. EyeGPT: Ophthalmic assistant with large language\nmodels. arXiv preprint arXiv:2403.00840(2024).\n145. Savage, T., Nayak, A., Gallo, R., Rangan, E. & Chen, J. H. Diagnostic\nreasoning prompts reveal the potential for large language model\ninterpretability in medicine.NPJ Digit. Med.7, 20 (2024).\n146. Li, S. S. et al. MediQ: Question-Asking LLMs and a Benchmark for\nReliable Interactive Clinical Reasoning. (Neural Information\nProcessing Systems, 2024).\n147. Fansi Tchango, A., Goel, R., Wen, Z., Martel, J. & Ghosn, J. Ddxplus:\nA new dataset for automatic medical diagnosis.Adv. neural Inf.\nProcess. Syst.35, 31306–31318 (2022).\n148. Xie, Q. et al. Medical foundation large language models for\ncomprehensive text analysis and beyond.npj Digit. Med.8, 141\n(2025).\n149. Yang, S. et al. Zhongjing: Enhancing the chinese medical capabilities\nof large language model through expert feedback and real-world\nmulti-turn dialogue.Proceedings of the AAAI conference on artiﬁcial\nintelligence. Vol. 38. No. 17. (2024).\n150. Mohammadi, S. S. & Nguyen, Q. D. A user-friendly approach for the\ndiagnosis of diabetic retinopathy using ChatGPT and automated\nmachine learning.Ophthalmol. Sci.4, 100495 (2024).\n151. Tank, C. et al. Depression detection and analysis using large\nlanguage models on textual and audio-visual modalities.arXiv\npreprint arXiv:2407.06125(2024).\n152. Sandmann, S., Riepenhausen, S., Plagwitz, L. & Varghese, J.\nSystematic analysis of ChatGPT, Google search and Llama 2 for\nclinical decision support tasks.Nat. Commun.15, 2050 (2024).\n153. Bae, S. et al. Ehrxqa: A multi-modal question answering dataset for\nelectronic health records with chest x-ray images.Advances in\nNeural Information Processing Systems36, 3867–3880 (2023).\n154. Hu, J. et al. Designing scaffolding strategies for conversational\nagents in dialog task of neurocognitive disorders screening. In\nProceedings of the CHI Conference on Human Factors in Computing\nSystems,1 –21 (2024).\n155. Englhardt, Z. et al. From classiﬁcation to clinical insights: Towards\nanalyzing and reasoning about mobile and behavioral health data\nwith large language models.Proc. ACM Interact., Mob. Wearable\nUbiquitous Technol.8,1 –25 (2024).\n156. Smith, P. C. et al. Missing clinical information during primary care\nvisits. JAMA 293, 565–571 (2005).\n157. McInerney, D. et al. Towards reducing diagnostic errors with\ninterpretable risk prediction.Proceedings of the conference.\nAssociation for Computational Linguistics. North American Chapter.\nMeeting. Vol. 2024, 2024).\n158. Adler-Milstein, J., Chen, J. H. & Dhaliwal, G. Next-generation\nartiﬁcial intelligence for diagnosis: from predicting diagnostic labels\nto “wayﬁnding”. JAMA 326, 2467–2468 (2021).\n159. Shi, X. et al. Medical dialogue system: A survey of categories,\nmethods, evaluation and challenges. InFindings of the Association\nfor Computational Linguistics ACL 2024(2024).\n160. Sun, Z., Luo, C. & Huang, Z. Conversational disease diagnosis via\nexternal planner-controlled large language models.arXiv preprint\narXiv:2404.04292 (2024).\n161. Zou, X. et al. AI-driven diagnostic assistance in medical inquiry:\nReinforcement learning algorithm development and validation.J.\nMed. Internet Res.26, e54616 (2024).\n162. Zhang, R. et al. Making shiny objects illuminating: the promise and\nchallenges of large language models in us health systems.npj Health\nSyst 2, 8 (2025).\n163. Cameron, S. & Turtle-Song, I. Learning to write case notes using the\nsoap format.J. Counsel. Dev.80, 286–292 (2002).\n164. Oniani, D. et al. Enhancing large language models for clinical\ndecision support by incorporating clinical practice guidelines. In\n2024 IEEE 12th International Conference on Healthcare Informatics\n(ICHI), 694–702 (IEEE, 2024).\n165. Sallam, M., Al-Salahat, K. & Al-Ajlouni, E. ChatGPT performance in\ndiagnostic clinical microbiology laboratory-oriented case scenarios.\ncureus 15, e50629 (2023).\n166. Bhasuran, B. et al. Preliminary analysis of the impact of lab results on\nlarge language model generated differential diagnoses.npj Digit.\nMed. 8, 166 (2025).\n167. Yi, Z. et al. A survey on recent advances in LM-based multi-turn\ndialogue systems.arXiv preprint arXiv:2402.18013(2024).\n168. McDuff, D. et al. Towards accurate differential diagnosis with large\nlanguage models.Nature 1–7 (2025).\n169. Haltaufderheide, J. & Ranisch, R. The ethics of ChatGPT in medicine\nand healthcare: a systematic review on large language models (llms).\nNPJ Digit. Med.7, 183 (2024).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 14\n170. Dou, C. et al. Detection, diagnosis, and explanation: A benchmark\nfor Chinese medical hallucination evaluation. InProceedings of the\n2024 Joint International Conference on Computational Linguistics,\nLanguage Resources and Evaluation (LREC-COLING 2024),\n4784–4794 (2024).\n171. Tran, H., Wang, J., Ting, Y., Huang, W. & Chen, T. Leaf: Learning and\nevaluation augmented by fact-checking to improve factualness in\nlarge language models.arXiv preprint arXiv:2410.23526(2024).\n172. Yue, X. & Zhou, S. Phicon: Improving generalization of clinical text\nde-identiﬁcation models via data augmentation. InClinical Natural\nLanguage Processing Workshop(2020).\n173. Zhou, J. et al. Pre-trained multimodal large language model\nenhances dermatological diagnosis using SkinGPT-4.Nat.\nCommun. 15, 5649 (2024).\n174. Spitale, M., Cheong, J. & Gunes, H. Underneath the Numbers:\nQuantitative and Qualitative Gender Fairness in LLMs for Depression\nPrediction. arXiv preprint arXiv:2406.08183 (2024).\n175. Chen, Z. et al. Meditron-70b: Scaling medical pretraining for large\nlanguage models.arXiv preprint arXiv:2311.16079(2023).\n176. Yang, K. et al. Mentallama: interpretable mental health analysis on\nsocial media with large language models. InProceedings of the ACM\non Web Conference 2024, 4489–4500 (2024).\n177. Peng, J. et al. Continually evolved multimodal foundation models for\ncancer prognosis.arXiv preprint arXiv:2501.18170(2025).\n178. Yi, H. et al. Towards general purpose medical AI: Continual learning\nmedical foundation model.arXiv preprint arXiv:2303.06580(2023).\n179. Kim, Y. et al. Adaptive collaboration strategy for LLMs in medical\ndecision making.NeurIPS (2024).\n180. Jiang, S. et al. Med-MoE: Mixture of domain-speciﬁc experts for\nlightweight medical vision-language models. InFindings of the\nAssociation for Computational Linguistics: EMNLP 2024,\n3843–3860 (Association for Computational Linguistics, Miami,\nFlorida, USA, 2024).\n181. Xu, D. et al. Editing factual knowledge and explanatory ability of\nmedical large language models.Proceedings of the 33rd ACM\nInternational Conference on Information and Knowledge\nManagement (2024).\n182. Hager, P. et al. Evaluation and mitigation of the limitations of large\nlanguage models in clinical decision-making.Nat. Med.1 –10 (2024).\n183. Kuratov, Y. et al. Babilong: Testing the limits of LLMs with long\ncontext reasoning-in-a-haystack.Adv. Neural Inf. Process. Syst.37,\n106519–106554 (2024).\n184. Yang, Z., Mitra, A., Liu, W., Berlowitz, D. & Yu, H. Transformehr:\ntransformer-based encoder-decoder generative model to enhance\nprediction of disease outcomes using electronic health records.Nat.\nCommun. 14, 7857 (2023).\n185. Huang, L. et al. Machine learning of serum metabolic patterns\nencodes early-stage lung adenocarcinoma.Nat. Commun.11, 3556\n(2020).\n186. Cui, H. et al. Timer: Temporal instruction modeling and evaluation for\nlongitudinal clinical records.arXiv preprint arXiv:2503.04176(2025).\n187. Dou, C. et al. PlugMed: Improving Speciﬁcity in Patient-Centered\nMedical Dialogue Generation using In-Context Learning.\nConference on Empirical Methods in Natural Language Processing\n(2023).\n188. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. Bert: Pre-training\nof deep bidirectional transformers for language understanding. In\nNorth American Chapter of the Association for Computational\nLinguistics (2019).\n189. Chen, C. et al. Clinicalbench: Can LLMs beat traditional ML models\nin clinical prediction?arXiv preprint arXiv:2411.06469(2024).\n190. Zhong, T. et al. Chatradio-valuer: A chat large language model for\ngeneralizable radiology report generation based on multi-institution\nand multi-system data.arXiv preprint arXiv:2310.05242(2023).\n191. Zhan, Z., Zhou, S., Zhou, H., Liu, Z. & Zhang, R. Epee: Towards\nefﬁcient and effective foundation models in biomedicine.arXiv\npreprint arXiv:2503.02053(2025).\n192. Ferrara, E. Large language models for wearable sensor-based\nhuman activity recognition, health monitoring, and behavioral\nmodeling: a survey of early trends, datasets, and challenges.\nSensors 24, 5045 (2024).\n193. Hulstaert, F. et al. Gaps in the evidence underpinning high-risk\nmedical devices in Europe at market entry, and potential solutions.\nOrphanet J. Rare Dis.18, 212 (2023).\n194. Tam, T. Y. C. et al. A framework for human evaluation of large\nlanguage models in healthcare derived from literature review.npj\nDigit. Med.7, 258 (2024).\n195. Liu, Y. et al. Roberta: A robustly optimized bert pretraining approach.\narXiv preprint arXiv:1907.11692 (2019).\n196. Wu, D. et al. GestaltMML: Enhancing Rare Genetic Disease\nDiagnosis through Multimodal Machine Learning Combining Facial\nImages and Clinical Texts. ArXiv (2024): arXiv-2312.\n197. Mizuta, K., Hirosawa, T., Harada, Y. & Shimizu, T. Can chatgpt-4\nevaluate whether a differential diagnosis list contains the correct\ndiagnosis as accurately as a physician?Diagnosis 11, 321–324\n(2024).\n198. Olesen, A. S. O. et al. How does ChatGPT-4 match radiologists in\ndetecting pulmonary congestion on chest X-ray?J Med Arti Intell7,\n(2024).\n199. Liu, X. et al. Large language models are few-shot health learners.\narXiv preprint arXiv:2305.15525(2023).\n200. Slack, D. & Singh, S. Tablet: Learning from instructions for tabular\ndata. arXiv preprint arXiv:2304.13188(2023).\n201. Xia, P. et al. Cares: A comprehensive benchmark of trustworthiness\nin medical vision language models.Advances in Neural Information\nProcessing Systems37, 140334–140365 (2024).\n202. Wada, A. et al. Optimizing GPT-4 turbo diagnostic accuracy in\nneuroradiology through prompt engineering and conﬁdence\nthresholds. Diagnostics 14, 1541 (2024).\n203. Chen, Z., Lu, Y. & Wang, W. Empowering Psychotherapy with Large\nLanguage Models: Cognitive Distortion Detection through\nDiagnosis of Thought Prompting. InFindings of the Association for\nComputational Linguistics: EMNLP 2023, pages 4295–4304\n(Association for Computational Linguistics, Singapore, 2023).\n204. Vashisht, P. et al. UMass-BioNLP at MEDIQA-M3G 2024:\nDermPrompt - A Systematic Exploration of Prompt Engineering with\nGPT-4V for Dermatological Diagnosis. InProceedings of the 6th\nClinical Natural Language Processing Workshop, pages 502–525\n(Association for Computational Linguistics, Mexico City, Mexico,\n2024).\n205. Lim, S., Kim, Y., Choi, C-H., Sohn, J-Y. & Kim, B-H. ERD: A\nFramework for Improving LLM Reasoning for Cognitive Distortion\nClassiﬁcation. InProceedings of the 6th Clinical Natural Language\nProcessing Workshop, pages 292–\n300 (Association for\nComputational Linguistics, Mexico City, Mexico, 2024).\n206. Peng, C. et al. Improving generalizability of extracting social\ndeterminants of health using large language models through\nprompt-tuning. arXiv preprint arXiv:2403.12374(2024).\n207. Zhou, W. et al. Transferring Pre-Trained Large Language-Image\nModel for Medical Image Captioning. InCLEF (Working Notes),\npages 1776–1784, (2023).\n208. Belyaeva, A. et al. Multimodal LLMs for health grounded in\nindividual-speciﬁc data. InWorkshop on Machine Learning for\nMultimodal Healthcare Data,8 6–102 (Springer, 2023).\n209. Ong, J. C. L. et al. Development and testing of a novel large language\nmodel-based clinical decision support systems for medication\nsafety in 12 clinical specialties. arXiv preprint arXiv:2402.01741\n(2024).\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 15\n210. Vithanage, D. et al. Evaluating machine learning approaches for\nmulti-label classiﬁcation of unstructured electronic health records\nwith a generative large language model. medRxiv (2024).\n211. Liu, J. et al. Large language model locallyﬁne-tuning (LLMLF) on\nChinese medical imaging reports. InProceedings of the 2023 6th\nInternational Conference on Big Data Technologies(ACM, New\nYork, NY, USA, 2023).\n212. Song, M. et al. PneumoLLM: Harnessing the power of large language\nmodel for pneumoconiosis diagnosis.Med. Image Anal.97, 103248\n(2024).\n213. Liu, W. & Zuo, Y. Stone needle: A general multimodal large-scale\nmodel framework towards healthcare.arXiv preprint\narXiv:2306.16034 (2023).\n214. Dou, C. et al. Integrating Physician Diagnostic Logic into Large\nLanguage Models: Preference Learning from Process Feedback. In\nFindings of the Association for Computational Linguistics: ACL\n2024, pages 2453–2473 (Association for Computational Linguistics,\nBangkok, Thailand, 2024).\n215. Sun, M. LlamaCare: A Large Medical Language Model for Enhancing\nHealthcare Knowledge Sharing. arXiv preprint arXiv:2406.02350\n(2024).\n216. Zhang, K. et al. A generalist vision–language foundation model for\ndiverse biomedical tasks.Nat Med30, 3129–3141 (2024).\n217. Wu, C.-K., Chen, W.-L. & Chen, H.-H. Large language models\nperform diagnostic reasoning. Tiny Papers @ ICLR 2023.\n218. Yang, Z. et al. Unveiling GPT-4V’s hidden challenges behind high\naccuracy on USMLE questions: Observational Study.Journal of\nMedical Internet Research27, e65146 (2025).\n219. Chen, Z. et al. Narrative Feature or Structured Feature? A Study of\nLarge Language Models to Identify Cancer Patients at Risk of Heart\nFailure. arXiv preprint arXiv:2403.11425 (2024).\n220. Hayati, M. F. M., Ali, M. A. M. & Rosli, A. N. M. Depression detection\non Malay dialects using GPT-3. In2022 IEEE-EMBS Conference on\nBiomedical Engineering and Sciences (IECBES), 360–364 (IEEE,\n2022).\n221. Liu, S. et al. Leveraging large language models for generating\nresponses to patient messages-a subjective analysis.J. Am. Med.\nInform. Assoc.31, 1367–1379 (2024).\n222. Gao, Y. et al. Large language models and medical knowledge\ngrounding for diagnosis prediction. medRxiv 2023-11 (2023).\n223. Sushil, M. et al. A comparative study of zero-shot inference with\nlarge language models and supervised modeling in breast cancer\npathology classiﬁcation. Research Square (2024).\n224. Zhang, X., Wu, C., Zhang, Y., Xie, W. & Wang, Y. Knowledge-\nenhanced visual-language pre-training on chest radiology images.\nNat. Commun.14, 4542 (2023).\n225. Kotelanski, M., Gallo, R., Nayak, A. & Savage, T. Methods to estimate\nlarge language model conﬁdence. arXiv preprint arXiv:2312.03733\n(2023).\n226. Qu, L. et al. The rise of AI language pathologists: Exploring two-level\nprompt learning for few-shot weakly-supervised whole slide image\nclassiﬁcation. Adv. Neural Inf. Process. Syst.36, 67551–67564\n(2023).\n227. Dekel, S. et al. ChatGPT Demonstrates Potential for Identifying\nPsychiatric Disorders: Application to Childbirth-Related Post-\nTraumatic Stress Disorder. Research Square (2023).\n228. Du, J. et al. Ret-clip: A retinal image foundation model pre-trained\nwith clinical diagnostic reports.\nInternational Conference on Medical\nImage Computing and Computer-Assisted Intervention. (Cham:\nSpringer Nature, Switzerland, 2024).\n229. Blankemeier, L. et al. Merlin: A vision language foundation model for\n3d computed tomography. Research Square (2024).\n230. Acharya, A. et al. Clinical risk prediction using language models:\nbeneﬁts and considerations.Journal of the American Medical\nInformatics Association31, 1856–1864 (2024).\n231. Chen, P.-F. et al. Automatic ICD-10 coding and training system:\ndeep neural network based on supervised learning.JMIR Med.\nInform. 9, e23230 (2021).\n232. Pedro, T. et al. Exploring the use of ChatGPT in predicting anterior\ncirculation stroke functional outcomes after mechanical\nthrombectomy: a pilot study.Journal of NeuroInterventional Surgery\n(2024).\n233. Ren, X. et al. ChatASD: LLM-based AI therapist for ASD. In\nCommunications in Computer and Information Science,\nCommunications in computer and information science, 312–324\n(Springer Nature Singapore, Singapore, 2024).\n234. Weng, Y. et al. Large language models need holistically thought in\nmedical conversational qa.arXiv preprint arXiv:2305.05410(2023).\n235. Panagoulias, D. P., Virvou, M. & Tsihrintzis, G. A. Evaluating\nILM–generated multimodal diagnosis from medical images and\nsymptom analysis.arXiv preprint arXiv:2402.01730(2024).\n236. Liu, Y. et al. Asystematic evaluation of GPT-4v’s multimodal capability\nfor chest x-ray image analysis.Meta-Radiol2, 100099 (2024).\n237. Chen, X. et al. Ffa-gpt: an automated pipeline for fundusﬂuorescein\nangiography interpretation and question-answer.npj Digit. Med.7,\n111 (2024).\n238. Hill, B. L. et al. Chiron: A generative foundation model for structured\nsequential medical data. InDeep Generative Models for Health\nWorkshop NeurIPS 2023.\n239. Kottlors, J. et al. Feasibility of differential diagnosis based on\nimaging patterns using a large language model.Radiology 308,\ne231167 (2023).\n240. Nair, V. et al. DERA: Enhancing Large Language Model Completions\nwith Dialog-Enabled Resolving Agents.Clinical Natural Language\nProcessing Workshop(2023).\n241. Umerenkov, D., Zubkova, G. & Nesterov, A. Deciphering diagnoses:\nhow large language models explanations inﬂuence clinical decision\nmaking. arXiv preprint arXiv:2310.01708(2023).\n242. Chen, X. et al. ICGA-GPT: report generation and question answering\nfor indocyanine green angiography images.Br J Ophthalmolog108,\n1450–1456 (2024).\n243. Lyu, Q. et al. Translating radiology reports into plain language using\nChatGPT and gpt-4 with prompt learning: results, limitations, and\npotential. Vis. Comput. Ind. Biomed. Art.6, 9 (2023).\n244. Jo, E. et al. Assessing GPT-4’s performance in delivering medical\nadvice: comparative analysis with human experts.JMIR Med. Educ.\n10, e51282 (2024).\n245. Guo, S. et al. Comparing ChatGPT’s and Surgeon’s Responses to\nThyroid-related Questions From Patients.J Clin Endocrinol Metab\n110, e841–e850 (2025).\n246. Kang, S. et al. WoLF: Wide-scope Large Language Model\nFramework for CXR Understanding. arXiv preprint arXiv:2403.15456\n(2024).\n247. He, Y. et al. BP4ER: Bootstrap Prompting for Explicit Reasoning in\nMedical Dialogue Generation.International Conference on\nLanguage Resources and Evaluation(2024).\nAcknowledgements\nThis work was supported by the National Institutes of Health’s National Center\nfor Complementary and Integrative Health under grant number R01AT009457,\nNational Institute on Aging under grant number R01AG078154, and National\nCancer Institute under grant number R01CA287413. The content is solely the\nresponsibility of the authors and does not represent the ofﬁcial views of the\nNational Institutes of Health. We also acknowledge the support from the Center\nfor Learning Health System Sciences.\nAuthor contributions\nS.Z. conceptualized the study and led the work. Z.Z., S.Z., J.Y., and M.Z.\nsearched papers. S.Z., Z.X., M.Z., C.X., Y.G., Z.Z., S.D., J.W., K.X., Y.F., L.X.,\nand J.Y. conducted paper screening and data extraction. S.Z., Z.X., M.Z.,\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 16\nand C.X. performed data synthesis and contributed to the writing. S.Z., Z.X.,\nM.Z., C.X., D.Z., G.M., and R.Z. revised the manuscript. R.Z. supervised the\nstudy. All authors read and approved theﬁnal version.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s44387-025-00011-z\n.\nCorrespondenceand requests for materials should be addressed to\nRui Zhang.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2025\nhttps://doi.org/10.1038/s44387-025-00011-z Review\nnpj Artiﬁcial Intelligence|             (2025) 1:9 17",
  "topic": "Disease",
  "concepts": [
    {
      "name": "Disease",
      "score": 0.6342614889144897
    },
    {
      "name": "Data science",
      "score": 0.4080701172351837
    },
    {
      "name": "Medicine",
      "score": 0.3998974561691284
    },
    {
      "name": "Management science",
      "score": 0.3582136034965515
    },
    {
      "name": "Computer science",
      "score": 0.34480834007263184
    },
    {
      "name": "Pathology",
      "score": 0.2136414349079132
    },
    {
      "name": "Engineering",
      "score": 0.09939566254615784
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130238516",
      "name": "University of Minnesota",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I78577930",
      "name": "Columbia University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I162577319",
      "name": "The University of Texas at Dallas",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I14243506",
      "name": "Hong Kong Polytechnic University",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I204250578",
      "name": "University of California, Irvine",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I258800397",
      "name": "New York University Shanghai",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I180670191",
      "name": "University of California, San Francisco",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210121988",
      "name": "Film Independent",
      "country": "US"
    }
  ]
}