{
  "title": "Predicate logic as a modeling language: modeling and solving some machine learning and data mining problems with<i>IDP3</i>",
  "url": "https://openalex.org/W2036981717",
  "year": 2014,
  "authors": [
    {
      "id": "https://openalex.org/A4287401337",
      "name": "Bruynooghe, Maurice",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4227207796",
      "name": "Blockeel, Hendrik",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A2567133856",
      "name": "Bogaerts, Bart",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4295915470",
      "name": "De Cat, Broes",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4298951408",
      "name": "De Pooter, Stef",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4289168736",
      "name": "Jansen, Joachim",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4299192883",
      "name": "Labarre, Anthony",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A4290798725",
      "name": "Ramon, Jan",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A2565060662",
      "name": "Denecker, Marc",
      "affiliations": [
        "KU Leuven"
      ]
    },
    {
      "id": "https://openalex.org/A2750549088",
      "name": "Verwer, Sicco",
      "affiliations": [
        "Radboud University Nijmegen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2076343783",
    "https://openalex.org/W1976055110",
    "https://openalex.org/W6645811064",
    "https://openalex.org/W2017603160",
    "https://openalex.org/W1924767599",
    "https://openalex.org/W2528578028",
    "https://openalex.org/W2016030731",
    "https://openalex.org/W1992119405",
    "https://openalex.org/W1506935337",
    "https://openalex.org/W2104756827",
    "https://openalex.org/W2000059300",
    "https://openalex.org/W1597298151",
    "https://openalex.org/W2091138122",
    "https://openalex.org/W2264300191",
    "https://openalex.org/W4254268221",
    "https://openalex.org/W2022846948",
    "https://openalex.org/W1983909040",
    "https://openalex.org/W2151485489",
    "https://openalex.org/W2136233667",
    "https://openalex.org/W6675110475",
    "https://openalex.org/W2040411190",
    "https://openalex.org/W1757790192",
    "https://openalex.org/W2154334459",
    "https://openalex.org/W2120437191",
    "https://openalex.org/W2042629502",
    "https://openalex.org/W2166822586",
    "https://openalex.org/W2035811095",
    "https://openalex.org/W2141811956",
    "https://openalex.org/W2165876990",
    "https://openalex.org/W1968513265",
    "https://openalex.org/W2066021026",
    "https://openalex.org/W1514469540",
    "https://openalex.org/W1929859906",
    "https://openalex.org/W2164032435",
    "https://openalex.org/W2130883786",
    "https://openalex.org/W2520571003",
    "https://openalex.org/W4246883707",
    "https://openalex.org/W2151290962",
    "https://openalex.org/W1513230022",
    "https://openalex.org/W1540443495",
    "https://openalex.org/W2594755931",
    "https://openalex.org/W78027104",
    "https://openalex.org/W584191950",
    "https://openalex.org/W4297951654",
    "https://openalex.org/W1518705996",
    "https://openalex.org/W2011388930",
    "https://openalex.org/W1607801167",
    "https://openalex.org/W2117888397",
    "https://openalex.org/W2097758523",
    "https://openalex.org/W2098800875",
    "https://openalex.org/W2249048248",
    "https://openalex.org/W605775221",
    "https://openalex.org/W2951110081",
    "https://openalex.org/W2006653030",
    "https://openalex.org/W1578088218",
    "https://openalex.org/W2109419864",
    "https://openalex.org/W4233815609",
    "https://openalex.org/W19153916",
    "https://openalex.org/W4302085967",
    "https://openalex.org/W2114108519",
    "https://openalex.org/W1981404401",
    "https://openalex.org/W2184463008",
    "https://openalex.org/W3105494749",
    "https://openalex.org/W1672891595",
    "https://openalex.org/W134248041",
    "https://openalex.org/W4295915260",
    "https://openalex.org/W2112400707"
  ],
  "abstract": "Abstract This paper provides a gentle introduction to problem-solving with the IDP3 system. The core of IDP3 is a finite model generator that supports first-order logic enriched with types, inductive definitions, aggregates and partial functions. It offers its users a modeling language that is a slight extension of predicate logic and allows them to solve a wide range of search problems. Apart from a small introductory example, applications are selected from problems that arose within machine learning and data mining research. These research areas have recently shown a strong interest in declarative modeling and constraint-solving as opposed to algorithmic approaches. The paper illustrates that the IDP3 system can be a valuable tool for researchers with such an interest. The first problem is in the domain of stemmatology, a domain of philology concerned with the relationship between surviving variant versions of text. The second problem is about a somewhat related problem within biology where phylogenetic trees are used to represent the evolution of species. The third and final problem concerns the classical problem of learning a minimal automaton consistent with a given set of strings. For this last problem, we show that the performance of our solution comes very close to that of the state-of-the art solution. For each of these applications, we analyze the problem, illustrate the development of a logic-based model and explore how alternatives can affect the performance.",
  "full_text": "TLP 15 (6): 783–817, 2015. C⃝ Cambridge University Press 2014\ndoi:10.1017/S147106841400009X First published online 14 May 2014\n783\nPredicate logic as a modeling language:\nmodeling and solving some machine learning\nand data mining problems withIDP3\nMAURICE BRUYNOOGHE, HENDRIK BLOCKEEL, BART BOGAERTS,\nBROES DE CAT, STEF DE POOTER, JOACHIM JANSEN,\nANTHONY LABARRE, JAN RAMON and MARC DENECKER\nDepartment of Computer Science, KU Leuven, Heverlee, Belgium\n(e-mail: Maurice.Bruynooghe@cs.kuleuven.be, Hendrik.Blockeel@cs.kuleuven.be,\nBart.Bogaerts@cs.kuleuven.be, Broes.DeCat@cs.kuleuven.be,\nStef.De.Pooter@cs.kuleuven.be, Joachim.Jansen@cs.kuleuven.be,\nlabarre.anthony@gmail.com, Jan.Ramon@cs.kuleuven.be,\nMarc.Denecker@cs.kuleuven.be)\nSICCO VERWER\nInstitute for Computing and Information Sciences, Radboud Universiteit Nijmegen, Toernooiveld, Nijmegen,\nthe Netherlands\n(e-mail: siccoverwer@gmail.com)\nsubmitted 22 March 2013; revised 3 February 2014; accepted 6 March 2014\nAbstract\nThis paper provides a gentle introduction to problem-solving with the IDP3 system. The\ncore of IDP3 is a ﬁnite model generator that supports ﬁrst-order logic enriched with types,\ninductive deﬁnitions, aggregates and partial functions. It oﬀers its users a modeling language\nthat is a slight extension of predicate logic and allows them to solve a wide range of search\nproblems. Apart from a small introductory example, applications are selected from problems\nthat arose within machine learning and data mining research. These research areas have\nrecently shown a strong interest in declarative modeling and constraint-solving as opposed\nto algorithmic approaches. The paper illustrates that the IDP3 system can be a valuable tool\nfor researchers with such an interest. The ﬁrst problem is in the domain of stemmatology,\na domain of philology concerned with the relationship between surviving variant versions\nof text. The second problem is about a somewhat related problem within biology where\nphylogenetic trees are used to represent the evolution of species. The third and ﬁnal problem\nconcerns the classical problem of learning a minimal automaton consistent with a given set\nof strings. For this last problem, we show that the performance of our solution comes very\nclose to that of the state-of-the art solution. For each of these applications, we analyze the\nproblem, illustrate the development of a logic-based model and explore how alternatives can\naﬀect the performance.\nKEYWORDS: knowledge representation and reasoning, declarative modeling, logic pro-\ngramming, knowledge base systems, FO(·), IDP system, stemmatology, phylogenetic tree,\ndeterministic ﬁnite state automaton\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n784 M. Bruynooghe et al.\n1 Introduction\nIn his seminal paper, Kowalski (1974) proposed to use ﬁrst-order predicate logic\n(FO) as a programming language. He argued that it is possible to use deduction for\ncomputation by associating a procedural interpretation to the Horn clause subset\nof ﬁrst-order logic. These ideas found their incarnation in the language Prolog.\nWhereas Prolog uses deduction as an inference method, other inference methods\nalso exist. Most prominent is the model generation as used in propositional\nSAT solvers. Also, the inference method of Constraint Programming (CP) can\nbe considered as model generation; indeed, its solvers attempt to assign values\nto variables while satisfying a set of constraints. The last decades have wit-\nnessed tremendous progress in solver technology for Constraint Programming\nand SAT solving. In Constraint Programming, this progress is at the basis of a\nshift from Constraint Programming to Constraint Modeling.\n1 Notorious examples\nare Essence (Frisch et al. 2008) and Zinc (Marriott et al. 2008). Within logic\nprogramming, the introduction of stable semantics (Gelfond and Lifschitz 1988)\neventually led to the Answer Set Programming (ASP) paradigm (Brewkaet al. 2011)\nthat, similar to SAT, uses model generation instead of deduction for inference. Many\nASP-based systems exist. Examples are DLV (Leone et al. 2002), clasp (Gebser\net al. 2007) and Smodels (Syrj¨anen and Niemel¨a 2001).\nAll this progress raises the question as to what is the status of logic as a modeling\nlanguage. SAT is restricted to propositional logic. It can be considered as the\nassembler language for modeling. Indeed, there are many examples of programs\nthat generate SAT encodings to obtain the state-of-the-art solvers for various\nclasses of problems. One can ﬁnd examples in the areas of planning and generating\ndeterministic ﬁnite automata, to name just a few. However, SAT is not suited as a\nlanguage for developing models. For what concerns ASP, it is an expressive high-level\nlanguage, but it is not based on predicate logic. Today, many intricacies of stable\nmodel semantics are hidden in high-level ASP constructs such as constraints and\nchoice rules; however, its two forms of negation (“not” and strong negation) (Brewka\net al. 2011) clearly distinguish it from the ﬁrst-order logic; the deviation from ﬁrst-\norder-logic semantics could be an obstacle for newcomers.\nHistorically, predicate logic was always viewed as a very expressive modeling\nlanguage. This is remarkable, given that anyone who used it for modeling a practical\ndomain will have experienced its inconvenience in expressing certain common\npropositions. A clear weakness is in expressing inductively deﬁnable concepts such as\nthe transitive closure of a binary relation. Another deﬁciency is in expressing bounds\non the cardinality or the sum of sets. Practical modeling languages in Constraint\nProgramming or ASP therefore support some of these propositions. While ASP\ncan express inductive deﬁnitions, it is built on radically diﬀerent foundations than\nFO. A more conservative solution that preserves FO’s foundations is to extend it\n1 In this paper, we use the word model in two diﬀerent meanings. First, a model is a structure that\nsatisﬁes the theory, as in “model generation.” Second, a model is the result of modeling a problem\ndomain. It is a theory in logic, a formal speciﬁcation of the problem domain. It should be clear from\nthe context what is intended.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 785\nwith suitable language constructs. For instance, it was argued in several works,\nfor example by Denecker and Ternovska (2008) and Denecker and Vennekens\n(to appear), that a rule set formalism under an extension of the well-founded\nsemantics (Van Gelder et al. 1991) is a natural formalism to express the most\ncommon forms of inductive deﬁnitions. Such a formalism can be integrated with FO\nin a conceptually clean way. The resulting logic was named FO(ID) by Denecker\nand Ternovska (2008). The link between FO(ID) and ASP was recently studied by\nDenecker et al. (2012). Below, we use the notation FO(·) to denote the family of\nextensions of ﬁrst-order logic.\nIn this paper, we explore the use ofFO(·)\nIDP3, the instance of theFO(·) family that\nis supported by IDP3, the current version of the IDP Knowledge Base System (De\nPooter et al. 2011). FO(·)IDP3 extends ﬁrst-order logic with inductive deﬁnitions,\npartial functions, types and aggregates. The IDP system supports model generation\nand model expansion (Mitchell and Ternovska 2005; Wittocxet al.2013) as inference\nmethods and is one of the fastest such systems (Calimeri et al. 2011). Particular to\nthe modeling language used here is the combination of a purely declarative modeling\nlanguage with a procedural language that handles interaction with the outside world.\nIndeed, in contrast to Prolog, the control of the search can be left to the solver, and\nthe user can concentrate on modeling. As we will illustrate in the paper, this does\nnot mean that any correct model will do; when performance matters, models have\nto be designed with care.\nAs for the organization of the paper, we start Section 2 with recalling the FO(·)\nfamily of extensions of predicate logic. Next, we introduce the FO(·)\nIDP3 instance of\nFO(·) and the IDP knowledge base system that supports FO(·)IDP3 as a modeling\nlanguage. The section continues with the shortest path problem as an illustrative\nexample. After describing a very basic model, it explores how alternative models\naﬀect the performance of the underlying solver.\nThe other sections explore the use of the IDP system for solving some real-\nworld problems encountered in the domain of machine learning and data mining by\nsome of the authors. Researchers in this domain have become increasingly aware\nof the fact that data analysis problems come in many diﬀerent variants, which do\nnot always ﬁt the standard algorithms well. It is infeasible to develop algorithms\nfor each speciﬁc variant, but recently it has been shown that some standard data\nmining problems, as well as their variants, can be modeled as constraint problems,\nand solved by general-purpose solvers with performance comparable to that of\ndedicated algorithms (Guns et al. 2011). Our discussion on the use of IDP for three\ndiﬀerent tasks adds support for the claim that declarative modeling may have an\nimportant role to play in machine learning and data mining.\nThe ﬁrst task, addressed in Section 3, is in the domain of a stemmatology, a part\nof philology that studies the relationship between surviving variant versions of a\ntext. A stemma is a family tree that shows how diﬀerent copies of the same text\nrelate to each other. These copies – manuscripts – are not identical, but evolve.\nManuscripts often do not have a single parent, diﬀerent parts can be copied from\ndiﬀerent parents, so a stemma is in fact a directed acyclic graph. A typical task\nis to analyze the plausibility of a stemma hypothesis. For this task, the philologist\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n786 M. Bruynooghe et al.\ncollects datasets describing features of the text. The values of a feature represent\nvariant readings of a fragment of the text. A common assumption is that the stemma\nhas, for each variant, a unique manuscript that is the source of the variant. The\nfeature value is unknown for some manuscripts, and the question is whether these\nunknown values can be assigned such that there is indeed a unique source for each\nfeature value. In working out this task, we also illustrate how the procedural side of\nFO(·)\nIDP3 allows the user to organize a complete workﬂow.\nThe second task (Section 4), although in the very diﬀerent domain of biology,\nis somewhat related to the previous one as it is concerned with phylogenetic trees.\nPhylogeny is an area in which many problems arise. Several problems have been\ntackled by means of ASP, see Erdem (2011) for an overview. Here we address a\nnew problem in this area. Phylogenetic trees have in their leaves a set of current\nspecies and the tree represents the evolutionary relationship between them. Often\nthere are several equally plausible evolutionary explanations and hence diﬀerent\nphylogenetic trees. The question addressed here is: what is the minimal supergraph\nthat represents each of the individual trees? What makes the problem diﬃcult is\nthat the correspondence between the internal nodes of diﬀerent trees is unknown\nand has to be guessed. Diﬀerent guesses result in diﬀerent supergraphs.\nIn Section 5, we study the well-known problem of learning a minimal deterministic\nﬁnite state automaton (DFA) that is consistent with a given set of accepted and\nrejected strings. This is a classical machine learning task for which competitions\nare organized. The state-of-the-art method (Heule and Verwer 2010; Heule and\nVerwer 2012), winner of the 2010 Stamina competition (Stamina 2010), solves it\nby a problem-speciﬁc program that iteratively creates a SAT encoding and applies\na SAT-solver for an increasing number of states until a model is found. Here\nwe explore to what extent a high level FO(·) formalization can compete with a\nlaboriously constructed encoding as a propositional SAT problem.\nThese three problems can be abstracted as graph problems and are nondeter-\nministic polynomial time (NP)-complete. Solving them inherently involves search;\nheuristics are needed to guide the search toward solutions. Developing an algorithm\nin a procedural language is time-consuming, error-prone and challenging. The use of\na declarative modeling language liberates the programmer from the task and allows\nhim to devote more time to proper formalization. Moreover, the default heuristics\nof the underlying solvers are often suﬃcient to obtain adequate solutions.\nIn Section 6, we reﬂect on our achievements and discuss where there is potential\nfor further improvement. Some of the material in this paper is based on the work of\nBlockeel et al. (2012), and for stemmatology, on the work of Andrews et al. (2012).\n2F O (·) and the IDP system\nFirst-order logic has a long tradition and a well-understood semantics but also some\nlimitations with regard to its expressiveness, which makes it not so well suited as\na language for knowledge representation. The most notorious problem is that it\ncannot naturally express transitive closures such as “x is reachable from y if either\nx and y are connected or there exists a z such that x and z are connected and x is\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 787\nreachable from z.” Note that Prolog programmers can cope with transitive closure\nand that the least Herbrand interpretation captures its meaning; actually, in the ﬁrst\nyears of logic programming, many Prolog programmers did not realize that it was\nan issue in the knowledge representation community; at the same time, many in\nthe latter community were ignorant about Prolog’s expressiveness. In the knowledge\nrepresentation community, there are two ways to work around the limitation. On the\none hand, one can introduce knowledge representation languages with a semantics\ndiﬀerent from ﬁrst-order logic; on the other hand, one can enhance ﬁrst-order logic\nwith additional constructs. The former approach is taken by the ASP community;\nthe latter approach has been advocated in Denecker and Ternovska (2008), where\nﬁrst-order logic was extended with (not necessarily monotone) inductive deﬁnitions.\nIt was argued that this extension resulted in a very natural and expressive language\nwhose meaning was captured by a generalization of the well-founded semantics\nintroduced by Van Gelder et al. (1991). This extension was named FO(ID) and\nlater work used the notation FO(·) for a family of languages extending ﬁrst-order\nlogic.\nThe FO extension used as a modeling language throughout this paper includes\nnot only inductive deﬁnitions but also partial functions, types and aggregates. It is\nthe extension supported by the IDP3 version of the IDP Knowledge Base System\nthat was for the ﬁrst time described by De Pooter et al. (2011).\n2 We denote this\nextension as FO(·)IDP3.\nFunctions, of which constants are a special case, are very convenient in modeling.\nThey are used in all the modeling examples of the paper. While n-ary functions\ncan be considered as syntactic sugar for predicates with n + 1 arguments, the use\nof functions makes models more concise and readable. Indeed, when functions are\nrepresented as predicates, the functional dependency between the input arguments\nand the result needs to be represented as a separate constraint. Partial functions\ngive extra ﬂexibility to the modeler. An example can be found in the model of ﬁnite\nstate automata in Section 5, where a state doesn’t need a transition for all symbols\nin the automaton’s input alphabet.\nIn almost all applications, the universe is not uniform but contains diﬀerent types.\nRelations are typed. Quantiﬁcation is “naturally” typed, namely, we quantify over\nobjects of a type. It is not diﬃcult to make typing explicit in untyped predicate logic.\nYet, it requires an extra discipline of the user to make the types in her quantiﬁcations\nand her relations and functions explicit. By introducing an explicit type system, even\na simple many-sorted type system, and a type checking and inference system (to\ndiscover type clashes and to guess the types of variables and/or parameters), theories\nbecome more compact and graceful. Moreover, a number of bugs can be detected:\nsyntactic errors in variable names, swapped or missing arguments, unintended reuse\nof variables etc. This is common wisdom. Indeed, well-typed theories go wrong less\noften (Milner 1978). The type system of IDP3 is not needed from a computational\npoint of view, but for above-mentioned reasons, we often ﬁnd it convenient.\n2 The examples used throughout the paper make use of IDP version 3.2.0.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n788 M. Bruynooghe et al.\nAggregates are another extensions that contribute to the readability and con-\nciseness of models. Consider, for example, the constraint expressing the functional\ndependency. One needs to express that there is exactly one value (or in the case of\na partial function at most one value) for each combination of input arguments. The\navailability of aggregates makes it a lot more convenient to express such constraints.\nA study about the semantics of aggregates in deﬁnitions, including the case of\nrecursion, has been made by Pelov et al. (2007).\n2.1 The logical components of an FO(·)\nIDP3 model\nIn this section, we introduce the basic notions of an FO(·)IDP3 model. We restrict\nourselves to what is needed to understand the examples later on in the paper.\nAn FO(·)IDP3 model comprises a number of logical components, namely vocabu-\nlaries, structures, terms and theories. A vocabulary declares the symbols to be used.3\nA structure is used to specify the domain and the data; it can be viewed as a sort\nof database, it provides a partial (three-valued) interpretation of the symbols in the\nvocabulary. In the context of optimization problems, a term component declares\nthe numerical cost term to be optimized. A theory comprises FO formulas and\ndeﬁnitions. A deﬁnition is a set of rules of the form ∀¯x : P(¯x) ← ϕ(¯x). where ϕ\nis an FO(·)\nIDP3 formula.4 An FO(·)IDP3 formula diﬀers from FO formulas in two\nways. First, FO(·)IDP3 is a many-sorted logic: every variable has an associated type\nand every type has an associated domain. Moreover, it is order-sorted: types can be\nsubtypes of others. Second, besides the standard terms in FO,FO(·)\nIDP3 formulas can\nalso have aggregate terms: functions over a set of domain elements and associated\nnumeric values that map to the sum, product, cardinality, maximum or minimum\nvalue of the set.\nWe write M| = T to denote that structure M satisﬁes theory T. With x\nM,w e\ndenote the interpretation ofx under M,w h e r ex can be a formula or a term. Without\ngoing in full details, M satisﬁes T when (i) every FO formula F of T is satisﬁed\nin M (FM is true), and (ii) every deﬁnition of T is satisﬁed in M. A structure M\nsatisﬁes a deﬁnition D when the well-founded model construction onD (Van Gelder\net al. 1991) that starts from O, the restriction of M to the predicates not deﬁned in\nD, results in M. See De Cat et al. (2014) for more details.\n2.2 The IDP3 system\nThe IDP3 system (De Pooter et al. 2011) is a Knowledge Base System (KBS) that\nintends to oﬀer the user a range of inference methods, such as model expansion,\noptimization, veriﬁcation, symmetry breaking and grounding, and to make use\nof diﬀerent state of the art technologies, including SAT, SAT Modulo Theo-\nries (Nieuwenhuis et al. 2006), Constraint Programming and various technologies\nfrom logic programming.\n3 Contrary to Prolog and ASP, the ﬁrst character of a symbol has no bearing on its kind.\n4 Deﬁnitions have a lot in common with pure Prolog rules.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 789\nIn this paper, we make use of the inference methods model expansion, satisﬁability\nchecking and model minimization. The most important inference method is model\nexpansion discussed by Mitchell and Ternovska (2005) and further extended by\nWittocx et al. (2013). The idea of model expansion is to extend a partial structure\n(an interpretation) into a full structure that satisﬁes all constraints speciﬁed by the\nFO(·)\nIDP3 model. More formally, the task of model expansion is, given a vocabulary\nV,at h e o r yT over V and a partial structure S over V (at least interpreting all\ntypes), to ﬁnd a structure M that satisﬁes T and expands S, i.e., M is a model of\nthe theory and the input structure S is a subset of M.I nt h eIDP3 system, this task\nis executed by modelexpand(T,S). The result of the modelexpand procedure is a list\nof models of T that expands S. If the option nbmodels is set to a value n diﬀerent\nfrom 0, IDP3 will stop searching for more models once it has found n models.\nSatisﬁability checking is related to model expansion. Calling sat(T,S) in the IDP3\nsystem will return true if and only if modelexpand(T,S) would have returned at\nleast one model. However, since we are not interested in the actual models, some\noptimizations can be done to speed up this inference.\nIn case of model minimization, also a numerical cost term t is given. The task is to\nﬁnd a model M of T that expands S such that, for all other models M’ expanding\nS, t\nM /p54tM′\n. Model minimization is activated by minimize(T,S,t) with t referring to\nthe term component deﬁning the term.\nThe IDP3 system allows users to specifyFO(·)IDP3 problem descriptions. The basic\noverall structure of the logical components is as in the following schema.\nvocabulary V { ... } theory T: V { ... }\nterm t: V { ... } structure S: V { ... }\nThis schema deﬁnes a vocabularyV, which is then used as a context in the theoryT,\nthe term t and the structure S. In general, several vocabularies can be deﬁned, even\nextending other vocabularies.\nWe use IDP syntax in the examples throughout the paper. Each IDP operator has\nan associated logical operator, the main (non-obvious) operators being: &(∧), |(∨),\n∼(¬), !(∀), ?(∃), <=>(≡), ∼=(̸=).\nA distinguishing feature ofFO(·)IDP3 models is that they not only comprises logical\ncomponents but also have one or more procedural components. These procedural\ncomponents comprises procedural code that can perform actions. Actions include\nthe execution of an inference method on a particular logical theory, but also the\npresentation of results to the user. Procedures allow to glue together a sequence of\nactions in a process that performs a task for the user. The convention is that the\nuser’s task is performed by invoking the procedure\nmain(). Such a task can start with\nprocedural code to prepare one or more structures from input ﬁles or databases,\ncontinue with performing a number of inference task on combinations of theories\nwith structures and end with presenting the results to the user. The procedural\nlanguage has to be a ﬂexible and extensible scripting language that oﬀers a smooth\nintegration with the C++ solvers of the IDP system. The IDP system (De Pooter\net al. 2011) makes use of the Lua (Ierusalimschy et al. 1996) scripting language for\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n790 M. Bruynooghe et al.\nthis purpose. It allows us to treat the various logical components of an FO(·)IDP3\ntheory as objects that can be manipulated from within the procedures.\nMore information on the IDP system and in particular its IDP3 version as\ngiven by Wittocx et al. (2008) and De Pooter et al. (2011) can be found at\nhttp://dtai.cs.kuleuven.be/krr/software/idp3.\n2.3 An example: the shortest path problem\nAs an illustration, we model the shortest path problem (Listing 1). The vocabulary\ncomprises a single type, two constants and three predicates. The structure speciﬁes\nthe given graph: the interpretation of the type node (the domain elements A,\nB, C and D) and the predicate edge(node,node) (the domain atoms edge(A,B),\nedge(B,C), edge(C,D) and edge(A,D)) as well as the constantsfrom (the domain\nelement A)a n dto (the domain element D), which identify the begin- and endpoint of\nthe path searched for. The predicate edgeOnPath(node,node) is used to represent\nthe edges that participate in the shortest path. It provides the base case of the\ntransitive relation reaches(node,node), which is deﬁned in the theory component.\nDeﬁnitions are given between “{” and “}.” Note that we use the most basic deﬁnition\nfor transitive closure: we join the reaches relation with itself.\nBesides this inductive (recursive) deﬁnition, the theory also speciﬁes the constraints\nexpressing that the edgeOnPath/2 atoms included in a model of the theory indeed\ncompose a simple path fromfrom to to. The ﬁrst constraint, a universally quantiﬁed\nimplication, ensures that edgeOnPath/2 atoms are indeed edge/2 atoms. This\nconstraint explicitly mentions the type of the quantiﬁed variables; however, this\nis optional; these types can be inferred from the type declarations of the predicates\nof the formula. The types of the quantiﬁed variables are omitted in the following\nconstraints. The second constraint, a simple fact, imposes that reaches/2 includes\nthe pair (from,to). The third constraint, a conjunction of negated formulas, states\nthat the edgeOnPath/2 atoms should neither include an edge arriving in from nor\nan edge leaving to. The fourth constraint is a universally quantiﬁed conjunction of\ntwo cardinality constraints; it expresses that every node has less than two incoming\nedges and less than two outgoing edges (i.e., the path is simple). The notation?<2y\n: edgeOnPath(y,x) means that there are strictly less than two y’s that have an edge\nto x in the path. This is syntactic sugar for the aggregate#{ y : edgeOnPath(y,x)}\n<2 . This aggregate is a more concise formulation of the FO constraint !y 1y 2\n: edgeOnPath(y1,x) & edgeOnPath(y2,x) => y1=y2. Finally, the last constraint,\nanother universally quantiﬁed implication, states that the endpoints of selected edges\nare reachable from from (i.e., no edges are selected that do not contribute to the\npath).\nThe term component of the model deﬁnes the termlengthOfPath as an aggregate\nexpression counting the number of tuples in the edgeOnPath relation of a model of\nthe theory. Minimizing this term ensures that the path described in a model of the\ntheory is indeed the shortest path.\nThe procedure component shows the Lua code invoking the model minimization\ntask and printing the result. The Lua code treats the logical components as ﬁrst-class\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 791\ncitizens and uses them as parameters in the method call activating the solver. The\nannotation [1] directs the solver to return at most one solution.\nListing 1. Calling main() solves the shortest path problem for the given data.\nvocabulary sp voc {\ntype node\nfrom , to : node\nedge (node , node)\nedgeOnPath(node , node)\nreaches (node , node)\n}\ntheory sp theory1 : sp voc {\n{ !xy:r e a c h e s ( x , y ) <− edgeOnPath(x , y ).\n! x y z : reaches(x,y) <− reaches(x,z) & reaches(z ,y). }\n! x[node] y[node] : edgeOnPath(x , y) = > edge(x ,y ). // (1)\nreaches(from , to ). // (2)\n˜(? x : edgeOnPath(x , from )) & ˜(? x : edgeOnPath(to , x ) ) . // (3)\n!x:( ? <2 y : edgeOnPath(y , x )) &\n(?<2 y : edgeOnPath(x , y ) ) . // (4)\n! x y : edgeOnPath(x , y) = > reaches(from ,y). // (5)\n}\nstructure sp struct : sp voc {\nnode = {A..D } // shorthand for A,B,C,D\nedge = {A,B; B,C; C,D; A,D } // ‘; ’ separated list of tuples\nfrom = A\nto = D\n}\nterm lengthOfPath : sp voc { #{ x y : edgeOnPath(x , y) }}\nprocedure main () {\n/∗ Search a minimal model ∗/\nsol = minimize(sp theory1 , sp struct , lengthOfPath )[1]\n/∗ If no result is returned , no models exist ∗/\nif (sol = = nil)\nthen print( \"No models exist . \\ n\" )\nelse print(sol)\nend\n}\nThe IDP3 system performs model expansion and model minimization by ﬁrst\nreducing the problem to extended CNF, using the grounder GidL (Wittocx et al.\n2010) and subsequently calling the solver MiniSAT(ID) (Mari¨en et al. 2008). The\ngrounding process can be ﬁne-tuned using options for symmetry breaking (Devriendt\net al. 2012), grounding with bounds (Wittocx et al. 2010), lazy grounding (De\nCat et al. 2012) etc. The solver is an extension of MiniSat (E ´en and S ¨orensson\n2003) with support for aggregate expressions, inductive deﬁnitions and branch-\nand-bound optimization. Recently, MiniSAT(ID) was extended to oﬀer support for\nﬁnite domain constraints, using the propagation techniques described in Schulte\nand Stuckey (2008), or, alternatively, interfacing with the Gecode Constraint\nProgramming engine.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n792 M. Bruynooghe et al.\n2.4 Exploring the space of models for the shortest path problem\nThe above is a correct IDP3 model that provides a declarative solution to the\nproblem at hand. However, if performance matters, or the instances are that large\nthat the grounding cannot ﬁt in memory, then other models can be preferable. In the\nlong run, perhaps an optimizer can transform a simple model in a model for which\nmodel generation has a better performance, but, with the current state of aﬀairs,\nit is up to the user to explore the design space and to look for better performing\nmodels. We do so in this section for the shortest path problem.\nListing 2. Another deﬁnition for reaches.\ntheory sp theory2 : sp voc {\n{ reaches(x,y) <− edgeOnPath(x , y ).\nreaches(x,y) <− edgeOnPath(x , z) & reaches (z , y ). }\n/∗ ... constraints as in sp theory1 ... ∗/\n}\nProlog programmers would never deﬁne the reaches/2 predicate as in theory\nsp theory1 of Listing 1 but rather as in theory sp theory2 of Listing 2. Indeed,\napart from the risk of entering an inﬁnite loop,reaches(x,z) can have many more\nsolutions than edgeOnPath(x,z) (which is bounded by the number of edges), and\nhence the search space for Prolog’s proof procedure can be substantially larger. 5\nWhile model generation cannot loop in the IDP system, the search space argument\nremains valid. Comparing the runtime of both systems (see Figure 1) reveals that\nthe heuristics of the underlying SAT solver do not compensate for the larger search\nspace and that the version of Listing 2 is substantially faster.\n6 However, there is\nanother factor contributing for the diﬀerence between both versions. Figure 1 splits\nruntime in grounding time (the vertical bar) and solving time (above the bar). For\nlarger problems, one can observe that the grounding also takes more time. The\nexplanation is the diﬀerence in grounding size (see Figure 2). The size diﬀerence\nmust be attributed to the grounding of the recursive reaches(x,z) rule. With n\nnodes, there are n\n3 instances of the recursive reaches/2 rule in sp theory1.A sf o r\nsp theory2, it follows from constraint (1) that edgeOnPath(x,z) is false whenever\nedges(x,z) is false, hence with e the number of edges, the number of instances is\nlimited to e ∗ n, which is typically substantially smaller than n3.\nAlthough the performance has improved quite a bit, we see that it is still rapidly\nincreasing with the size of the graph. Moreover (see Figure 1), most of the runtime\nis the grounding time. Can we do better? The recursive reaches/2 rule has three\nvariables and remains expensive. The grounding has n\n2 atoms reaches(n1,n2),\nexpressing whether n1a n dn2 are connected while we are only interested in paths\ngoing fromfrom to to. Hence, we should better use a unaryreachable predicate and\ndeﬁne the points that are reachable fromfrom. The new versions of thevocabulary\n5 When using a system with tabling, the order in the body of the recursive clause is better inverted (Swift\nand Warren 2012).\n6 U s i n ga nI n t e lR CoreTM i5-3550 CPU at 3.30 GHz with 7.8-GB RAM running Ubuntu with theIDP3\ndefault options.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 793\nFig. 1. (Colour online) Diﬀerent grounding and total running times for sptheory1, sp theory2\nand sp theory3. Experiments are performed on graphs with an increasing number of nodes\nbut a constant edge density. The vertical bar shows the grounding time, the part above the\nvertical bar is the solving time.\nFig. 2. (Colour online) Grounding size for sp theory1, sp theory2, sp theory3 and sp theory4.\nExperiments are performed on graphs with an increasing number of nodes but a constant\nedge density.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n794 M. Bruynooghe et al.\nand the theory are shown in Listing 3. The term and procedure parts are as in\nListing 1.\nListing 3. A unary reachable relation instead of the binary reaches relation.\nvocabulary sp voc2 {\ntype node\nfrom , to : node\nedge (node , node)\nedgeOnPath(node , node)\nreachable (node)\n}\ntheory sp theory3: sp voc2 {\n{ reachable(from).\nreachable(y) <− edgeOnPath(x , y) & reachable (x ). }\n! x[node] y[node] : edgeOnPath(x , y) = > edge(x ,y ). // (1)\nreachable(to ). // (2)\n˜(? x : edgeOnPath(x , from )) & ˜(? x : edgeOnPath(to , x ) ) . // (3)\n!x:( ? <2 y : edgeOnPath(y , x )) &\n(?<2 y : edgeOnPath(x , y ) ) . // (4)\n! x y : edgeOnPath(x , y) = > reachable(y). // (5)\n}\nAs Figure 1 shows, this modiﬁcation results in a dramatic speed-up. Also, the\ngrounding size (Figure 2) is substantially reduced.\nConstraints (3) and (4) are cardinality constraints on the number of edges\nconnected to the same node that can participate in a path. They are redundant\nwith respect to the minimization of the lengthOfPath term. Indeed, paths of\nminimal length satisfy both constraints. Dropping them, as in Listing 4, spoils the\nclarity of the model; however, it further reduces the size of the grounding as can be\nseen in Figure 2. The eﬀect on the runtime is negligible for small graphs and rather\nnegative for larger ones as one can observe in Figure 3. The explanation is that\nthe removal of these constraints increases the search space. Indeed, partial solutions\nviolating constraints (3) and (4) are not immediately rejected. This causes a lot more\nvariance in the solving times.\nListing 4. Removing redundant constraints.\ntheory sp theory4: sp voc {\n{ reachable(from).\nreachable(y) <− reachable(x) & edgeOnPath(x,y). }\n! x[node] y[node] : edgeOnPath(x , y) = > edge(x ,y ). // (1)\nreachable(to ).\n}\nThe above example, in which we solved a classical problem withIDP3, illustrates\nthe basic features of FO(·)IDP3. It shows that problem-solving with IDP3 is a quite\ndiﬀerent endeavor from problem-solving in other languages. This holds not only\nfor procedural languages but also for a declarative language such as Prolog. It also\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 795\nFig. 3. (Colour online) Diﬀerent grounding and total running times for sp theory3 and\nsp theory4. Experiments are performed on graphs with an increasing number of nodes but a\nconstant edge density.\nshows the importance of exploring various models when performance and memory\nuse matters.\n3 Stemmatology\nBefore the invention of the printing press, texts were copied manually by scribes.\nThis copying process was not perfect; scribes often modiﬁed texts, either accidentally\nor intentionally. As a result the surviving copies of many old texts vary signiﬁcantly.\nNo text written before the invention of the printing press, and even up to the end of\nthe 18th century, when the habit of circulating texts in manuscript form practically\ndisappeared, can be read without a preliminary critical analysis of its material\nwitnesses. This is the purpose of stemmatology. The Oxford English Dictionary\ndeﬁnes the ﬁeld as “the branch of study concerned with analyzing the relationship\nof surviving variant versions of a text to each other, especially so as to reconstruct\na lost original.”\nA stemma is a kind of “family tree” of a tradition, a set of related manuscripts.\nIt indicates how manuscripts (“children”) have been copied from other manuscripts\n(“parents”), and the manuscript that is the original source. It may include both\nextant (currently existing and available) and non-extant (“lost”) manuscripts. The\nstemma is not necessarily a tree: sometimes a manuscript has been copied partially\nfrom one manuscript, and partially from another, in which case the manuscript has\nmultiple parents.\nMore formally, a stemma can be deﬁned as a CRDAG, a Connected Directed\nAcyclic Graph with a single Root (Andrews and Mac ´e 2013). A dataset contains\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n796 M. Bruynooghe et al.\nthe manuscripts from one tradition. Each manuscript is described by a ﬁxed set of\nfeatures F1,..., Fn, each of which has a nominal domain Dom(Fi) (variant readings\nof feature Fi). Typically, a feature refers to a particular location or a section in a\ntext, although it can also be the spelling of a particular word, e.g., the dwelling of\n“Van den Vos Reynaerde” can be spelled as Malpertuis, Malpertus or Malpertuus.\nThe 19th century philologist Karl Lachmann was among the ﬁrst to apply a\nprincipled method for reconstructing stemmata from sets of manuscripts (Timpanaro\n2005). Nowadays, a variety of methods exist. Many are borrowed from biology, where\na similar problem, reconstruction of phylogenetic trees, is well studied. However,\nthese methods do not always ﬁt the stemmatological context well. First, they assume\nthat phylogenies are tree-shaped, while stemmata are DAGs.\n7 Second, these trees\ncontain only bifurcations, while stemmata can have multifurcations. Third, in most\nmethods, the trees are such that each extant copy is at a leaf of the tree, whereas in\nstemmatology one extant copy may be an ancestor of another (and hence should be\nan internal node). Fourth, stemmatologists often have additional information, for\ninstance, about the time or place of origin of a manuscript, which ideally should be\ntaken into account. Research continues to develop new algorithms better suited for\nthe stemmatological context (Baret et al. 2006).\n3.1 The task\nApart from reconstructing stemmata from data, stemmatologists are also interested\nin other types of analyses, which may, for instance, use a known stemma or a\nmanually constructed best-guess stemma as an input. These types of analysis can be\nvery diverse. The data mining tasks that we address in this section belong to this\ncategory.\nThe problem studied here assumes that a CRDAG representing a stemma of a\ntradition is given, as well as feature data about the manuscripts from the tradition.\nMore speciﬁcally, the data include a feature for each location where variation is\nobserved in the tradition represented by the stemma. For each extant manuscript\nin the tradition, the feature data describe its variant reading; the variant reading is\nunknown for the non-extant ones. For most features, it seems rather unlikely that the\nsame variant reading originated multiple times independently; i.e., it is reasonable\nto assume that there is one ancestor where the variant reading occurred for the ﬁrst\ntime (the “source” of the variant). Therefore, we say that the feature is consistent\nwith the stemmaif it is possible to indicate for each variant a single manuscript that\nmay have been the origin of that variant. Since for some manuscripts the value of\nthe feature is not known, checking consistency boils down to assigning a variant to\neach node in the CRDAG in such a way that, for each variant, the nodes having\nthat variant form a CRDAG themselves. Note that one can imagine exceptions to\nthe above, e.g., a new spelling of a word can be independently introduced in diﬀerent\ncopies.\n7 Some methods return phylogenetic networks, but these represent uncertainty about the real tree, which\nis diﬀerent from claiming that the network represents the actual phylogeny.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 797\nrr\nr b\nbb\nb\nb\nb\nb\nb\nr\nr\nr ryy\ny\nFig. 4. (Colour online) Left: A partial labeling showing for a given feature which manuscripts\nhave which variant readings/colors. Right: A complete extension of that labeling where each\nvariant reading is a CRDAG. Because such an extension exists, the feature is consistent with\nthe stemma.\n3.2 Consistency checking of a stemma is NP-complete\nWe learned about this problem through contacts with researchers in stemmatology.\nOne of them had developed an algorithm (implemented with a program of about\n370 lines of Perl using a graph library as a back end) to solve the basic task, did\nseveral iterations to handle yet uncovered cases and was still worried about the\ncompleteness of their approach (does the algorithm always ﬁnd a solution when a\nsolution exists?). The algorithm attempts not to make wrong decisions by initially\nassigning several variant readings to the non-extant manuscripts and, in the second\nphase, remove variant readings while preserving consistency. Once understood, the\nproblem was formalized as a graph problem and shown to be NP-complete by\none of the authors of this paper. In this formalization, the variant reading of\na text is represented as a color, and checking a stemma is a color-connected\nproblem.\nDeﬁnition 1 (Color-connected)\nTwo nodes x and y in a colored CRDAG are color-connected if a node z exists\n(z can be one of x and y) such that there is a directed path from z to x,a n d\none from z to y, and all nodes on these paths (including z, x, y) have the same\ncolor.\nGiven a partially colored CRDAG, thecolor-connected problemis to complete the\ncoloring such that every pair of nodes of the same color is color-connected.\nAn illustration is given in Figure 4. A candidate coloring can be checked in\npolynomial time, hence proving that the color-connected problem is NP-hard implies\nit is NP-complete.\nTheorem 1\nThe color-connected problem is NP-hard.\nProof\nThe proof is by showing a polynomial reduction from SAT to color-connectedness.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n798 M. Bruynooghe et al.\na1 b1\nV\nab\nr\na2 a3 a4 a5 a6 b2 b3 b4\nFig. 5. A partially colored CRDAG constructed from a CNF theory T. The black ai nodes\nrepresent the positive clauses, the whitebi nodes the negative clauses. The grey nodes represent\nthe propositional variables; they are linked to the clauses in which they participate and have\nto be colored.\nThere exists a polynomial reduction from a conjunctive normal form (CNF)\nformula to one with all clauses either positive (all literals are positive) or negative\n(all literals are negative). Indeed, replace all occurrences of a negative literals¬x by\na new positive literals notx and add for every such notx literal the clauses x ∨ notx\nand ¬x ∨¬ notx.\nSo we assume without loss of generality a CNF formula T comprising positive\nclauses T\n+ and negative clauses T−. We construct a color-connected problem\nwhose solutions correspond to the models of T.L e tT+ = C+\n1 ∧ C+\n2 ∧ ... ∧ C+\nm and\nT− = C−\n1 ∧ C−\n2 ∧ ... ∧ C−\nn with C+\n1 ,...,C +\nm positive clauses and C−\n1 ,...,C +\nn negative\nclauses. Let V be the set of propositional variables in T.\nNow we construct a DAG G comprising the nodes V(G)= r ∪ A ∪ B ∪ V\nwhere A = {a, a1,a 2,...,a m} (ai stands for clause C+\ni ; a is an extra node) and\nB = {b, b1,b 2,...,b n} (bi stands for clauseC−\ni ; b is an extra node). The directed edges\nare given by E(G)= {(v,a i)|i ∈ [1..m],v ∈ C+\ni }∪{ (v,b i)|i ∈ [1..n],v ∈ C−\nj }∪{ (a, v)|v ∈\nV}∪{ (b, v)|v ∈ V ∪{ (r, a), (r, b)}. Next we color r, a and all nodes ai black, and b\nand all nodes bi white. We obtain a partially colored CRDAG (see Figure 5 for an\nexample). Moreover, a solution to the color-connected problem encodes a solution\nto the original SAT problem. Indeed, each a\ni node, representing a positive clause,\nis connected with at least one black variable. Hence, making all black variables\ntrue satisﬁes all positive clauses. Also, each b\ni node, representing a negative clause,\nis connected with at least one white variable. Hence, making the white variables\nfalse satisﬁes all negative clauses. It follows that the color-connected problem is\nNP-hard. /ap9\nThe problem being NP-complete, it is unlikely it can be solved by a procedural\nprogram without search. The proof suggests the problem becomes hard when nodes\ncan have multiple parents. This situation is not dealt with (and therefore usually\nabstracted away) in traditional stemmatological methods. However, it does occur\nin the datasets we analyzed. Constructing small examples where several nodes have\nmultiple parents, we quickly obtained an example for which the procedural code\nerroneously claimed no connected coloring exists. So the worries of the developer\nabout the completeness of the code were grounded.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 799\n3.3 An FO(·)IDP3 Solution\nA ﬁrst FO(·)IDP3 solution used a binary relation SameVariant for representing that\ntwo manuscripts have the same variant reading and imposed two constraints: (i)\ntransitivity of SameVariant relation, and (ii) manuscripts with the same variant\nreading have a common ancestor with that variant reading and are connected to\nthat ancestor through manuscripts with that same variant reading. This resulted in\na working version that could serve as a golden standard for the procedural code,\nbut was much slower than the latter.\nAs we already noted in the shortest path problem, modeling transitive closures\nresults in large grounding sizes and runtime. Hence, a major improvement can be\nexpected when that can be avoided. Representing the variant reading as a function\nfrom manuscripts to variants allowed us to drop the transitivity constraint. The ﬁnal\nimprovement, resulting in the program below, came from learning more about the\nprocedural code: It checks for connectedness by following a path to the original\nsource manuscript of the variant reading and checks that there is a single such\nsource for the variant reading. Expressing the latter as a single constraint resulted in\na version that turned out to be faster than the incomplete procedural algorithm. The\nIDP3 model is shown in Listing 5 and explained below. We also show most of the\nprocedural code so that the reader can see how a number of satisﬁability-checking\ntasks can be embedded in a single process.\nListing 5. Checking the consistency between stemma and features.\nprocedure main () {\nprocess( \" besoin \" )\nprocess( \" parzival \" )\nprocess( \" florilegium \" )\nprocess( \" sermon158 \" )\nprocess( \" heinrichi \" )\n}\n/∗ −−−−− Knowledge base −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− ∗/\nvocabulary V {\ntype Manuscript\ntype Variant\nCopiedBy( Manuscript , Manuscript )\nVariantReading(Manuscript ): Variant\n}\nvocabulary Vtask {\nextern vocabulary V\nSourceOf( Variant ): Manuscript\n}\ntheory Ttask : Vtask {\n! x : (x ˜= SourceOf(VariantReading(x ))) = >\n? y : CopiedBy(y , x) & VariantReading (y) = VariantReading (x ).\n}\n/∗ −−−−− Check consistency between feature and stemma −−−−−−−− ∗/\nprocedure check( feature ) {\nsetvocabulary(feature ,Vtask)\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n800 M. Bruynooghe et al.\nreturn sat(Ttask , feature)\n}\n/∗ −−−−− Procedures for processing −−−−−−−−−−−−−−−−−−−−−−−−−−− ∗/\nprocedure process(tradition) {\nio . write( \" Processing \" ,tradition , \" .\\ n\" )\nlocal path = \" data/ \"\nlocal stemmafilename = path .. tradition .. \" . dot \"\nlocal featurefilename = path .. tradition .. \" .j s o n\"\nprocessFiles (stemmafilename , featurefilename )\n}\nprocedure processFiles (stemmafilename , featurefilename ) {\nlocal stemma , nbnodes , nbedges = readStemma( stemmafilename )\nio . write( \"Stemma has \" ,nbnodes , \" nodes and\n\" ,nbedges , \" edges . \\ n\" )\nlocal nbp,nbs , time = processFeatures(stemma, featurefilename)\nio . write( \"Found \" ,nbp , \" positive out of \" ,nbs , \" groupings \" )\nio . write( \" in \" ,time , \" sec . \\ n\" )\n}\nprocedure readStemma( stemmafilename ) {\n/∗ 19 lines of lua code ∗/\n}\nprocedure processFeatures(stemma, featurefilename) {\n/∗ 23 lines of lua code\na loop iterating over the features ,\n−− compute feature as stemma extended with\nthe feature specific data\n−− call check( feature )\n−− process the results\nfinally , return the overall results ∗/\n}\nThe logical model is described in the “Knowledge base” section of the code. The\nvocabulary has been split in two parts. The vocabulary V is used to represent the\ninput data: the stemma and the feature. It introduces the types Manuscript and\nVariant, the binary relation CopiedBy representing the parent–child pairs in the\ngiven structure of the stemma and the function VariantReading representing the\nknown data about variant readings of manuscripts. The vocabulary Vtask extends\nV with the task-speciﬁc vocabulary. Only one extra function is needed, namely\nsourceOf which maps a variant reading to the manuscript that is the source of\nthat variant reading. The theory Ttask comprises a single constraint; it states that\na manuscript that is not the source of its own variant reading must have a parent\nwith the same variant reading.\nThe remainder is procedural code. The proceduremain iterates over all traditions\nto be analyzed and calls the procedure process for each of those. The latter\nprocedure uses concatenation to construct two ﬁlenames from the name of the\ntradition and passes these ﬁle names to the processFiles procedure; the “.dot”\nﬁle contains the stemma data; the “.json” ﬁle the feature data. The readStemma\nprocedure (code omitted) returns the input structure describing the stemma as\nwell as the number of manuscripts (nodes) and parent–child pairs (edges). The\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 801\nTable 1. The ﬁve traditions used in this work\n#Variant readings\n#Manu- #Parent–child\nName scripts pairs #Features maximum average\nNotre Besoin 13 13 44 5 2.18\nParzival 21 20 122 6 2.59\nFlorilegium 22 21 547 5 2.19\nSermon 158 34 33 270 3 2.12\nHeinrichi 48 51 1042 17 4.84\nprocessFeatures procedure (code omitted) iterates over the features in the ﬁle. For\neach feature, it constructs a feature structure by extending the stemma structure\nwith the feature-speciﬁc data. It then calls the check procedure. This proce-\ndure extends the feature structure with the symbols from the Vtask vocabulary\n(setvocabulary(feature,Vtask)) and then checks the color-connectedness of the\nfeature (sat(Ttask,feature)). The yes/no result is returned to the processFiles\nprocedure which collects and returns the global results: number of consistent\n(positive) features, total number of features and time. TheprocessFiles procedure\nprints these global data and returns to main.\nAs can be seen in themain() procedure, we used the code to perform consistency\nchecking for the features of ﬁve traditions; two of them, Sermon 158 and Florilegium\nare real traditions, with stemmata that have been constructed according to current\nphilological best practice; the other three are artiﬁcial traditions, produced under\ntest conditions by volunteers for the purposes of empirical research into stemmato-\nlogical methods. We received the data from Tara Andrews (at the time of writing\nemployed at the KULeuven). A website where such stemma data can be found is\nhttp://byzantini.st/stemmaweb/. Some information about the stemma we used\nis given in Table 1.\nThe IDP program determines consistency for all features and datasets in a matter\nof seconds\n8:\n> main()\nProcessing besoin.\nStemma has 13 nodes and 13 edges.\nFound 26 positive out of 44 groupings in 0 sec.\nProcessing parzival.\nStemma has 21 nodes and 20 edges.\nFound 45 positive out of 122 groupings in 1 sec.\nProcessing florilegium.\nStemma has 22 nodes and 21 edges.\nFound 431 positive out of 547 groupings in 2 sec.\nProcessing sermon158.\nStemma has 34 nodes and 33 edges.\nFound 64 positive out of 270 groupings in 2 sec.\nProcessing heinrichi.\nStemma has 48 nodes and 51 edges.\nFound 1 positive out of 1,042 groupings in 12 sec.\n>\n8 Using an Intel R CoreTM 2 Duo CPU at 3.00 GHz with 3.7 GB of RAM running Ubuntu\nwith the IDP3 options stdoptions.groundwithbounds = false (disabling bounded grounding) and\nstdoptions.liftedunitpropagation = false (disabling lifted unit propagation).\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n802 M. Bruynooghe et al.\nOur largest benchmark is the heinrichi data set (Roos and Heikkil ¨a 2009). This\nstemma about old Finnish texts includes 48 manuscripts, 51 copiedBy tuples and\ninformation about 1,042 features. Processing all features takes 12 sec with the IDP\nsystem, while it took 25 sec with the original procedural code.\nOne can observe that rather few features are consistent with the stemma. This\nraises the question, what is the minimal number of sources needed to explain the\ndata. To solve that inference task, it suﬃces to replace the vocabulary extension\nVtask and the theory Ttask in the knowledge base and to introduce the term to be\nminimized. As core procedure, Check is replaced by minSources and the processing\nof results has to be adjusted. The most relevant new parts are shown in Listing 6.\nThe IsSource predicate is deﬁned as manuscripts that do not have a parent with\nthe same variant reading.\nListing 6. Minimize the number of sources.\n/∗ −−−−− new parts of Knowledge base −−−−−−−−−−−−−−−−−−−−−−−−− ∗/\nvocabulary Vms {\nextern vocabulary V\nIsSource(Manuscript)\n}\ntheory Tms : Vms {\n{ ! x : IsSource(x) <− ˜? y : CopiedBy(y , x) &\nVariantReading(y) = VariantReading(x). }\n}\nterm NbOfSources : Vms {\n#{ x : IsSource(x) }\n}\n/∗ −−−−− the core procedure −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− ∗/\nprocedure minSources( feature ) {\nsetvocabulary(feature ,V m s)\nreturn minimize (Tms, feature , NbOfSources )[1]\n}\nAlthough this is a minimization problem, processing the traditions is still a matter\nof seconds, except for the larger Heinrichi dataset, which now requires about 5 min\nto process its 1,042 features.\nOther variations are of interest to the researchers. One variation, mentioned by\nAndrews et al. (2012), considers the possibility that the scribe has copied from an\nolder ancestor than the direct parent, thus reintroducing a variant. Playing with the\nrelative penalty of introducing a new variant versus reverting to an older variant,\none can obtain various explanations of interest to the stemmatologist. All these can\nbe achieved with modifying a handful of lines in the model. Interesting about the\nabove variant is that it uses a predicate IndirectAncestor that is deﬁned in terms\nof the stemma data, so it can be computed once and reused when processing each\nof the features. As illustrated in Listing 7, the tight integration of the knowledge\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 803\nbase with the procedural code makes this very easy. 9 The procedure readStemma,\nwhich constructs the stemma structure from the inputﬁle, is extended with the call\nmodelexpand(T,stemma)[1]. The resulting model is the stemma structure extended\nwith the true IndirectAncestor atoms. This structure, together with the other\noutputs of readStemma, is returned to the procedure processFiles which uses it\nto handle the features one by one.\nListing 7. Materializing a deﬁnition once and using the materialization many times.\nvocabulary V {\n/∗ ... a s i n Listing 5 ... ∗/\nIndirectAncestor(Manuscript ,Manuscript)\n}\ntheory T:V {\n{ ! x y : IndirectAncestor(x,y) <−\n? z : CopiedBy(x , z) & IndirectAncestor (z , y ).\n! x y : IndirectAncestor(x,y) <−\n? z : CopiedBy(x , z) & CopiedBy(z , y ). }\n}\nprocedure readStemma( stemmafilename ) {\nlocal stemma = newstructure(V, \" stemma \" )\n/∗ ... r e a d i n g t h e s t e m m a d a t a ... ∗/\nreturn modelexpand(T, stemma)[1] , #nodes , #edges\n}\n4 Minimum common supergraphs of partially labeled trees\nPhylogenetic trees, extensively surveyed by Felsenstein (2004), are the traditional\ntool for representing the evolution of a given set of species. However, there exist\nsituations in which a tree representation is inadequate. One reason is the presence\nof evolutionary events that cannot be displayed by a tree: genes may be duplicated,\ntransferred or lost, and recombination events (i.e., the breaking of a DNA strand\nfollowed by its reinsertion into a diﬀerent DNA molecule) as well as hybridization\nevents (i.e., the combination of genetic material from several species) are known\nto occur. The second reason is that even when evolution is indeed tree-like, there\nare cases in which a relatively large number of tree topologies are “equally good”\naccording to the chosen criterion, and that not enough information is available to\ndiscriminate between those trees. One solution that has been proposed to address\nthe latter issue is the use of consensus trees, where the idea is to ﬁnd a tree that\nrepresents a compromise between the given topologies. Another approach, the focus\nof this section, consists in building a network that is compatible with all topologies\nof interest. A somewhat loose description of the variant we are interested in, which\nwill be stated in a more formal way below, is to ﬁnd the smallest graph that contains\n9 With a more recent version of IDP3, the user can leave this optimization to the system (Jansen et al.\n2013).\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n804 M. Bruynooghe et al.\n1 3\n4\n2\n1 3\n4\n2\n1 3\n4\n2\n1\n3\n4 2\nT1 T2 G1 G2\nFig. 6. Two 7-graphs, T1 and T2, and two of their common supergraphs. G1 is a minimum\ncommon supergraph.\na given set of evolutionary trees. For more information aboutphylogenetic networks,\nsee the recent book by Huson et al. (2010) and the online, up-to-date annotated\nbibliography maintained by Gambette (2010).\n4.1 The problem\nThe studied problem is about the evolution of a ﬁxed set of m species. The input is\na set of phylogenetic trees, each tree showing a plausible relationship between the\nm species. All trees have n (>m ) nodes, m of them are labeled with the name of\nthe species (typically, in the leaves, but also internal nodes can be labeled). Given\nn − m extra names, the labeling of each tree can be extended to a full labeling. Now\nwe can consider the union of these full labelings: a network with m labeled nodes\nand edges which are induced by the bijections between the fully labeled trees and\nthe network. Obviously, the number of edges of the network depends on the chosen\nfull labelings of the trees. The task is to ﬁnd a network with a minimum number of\nedges. Below, we formulate the problem as a slightly more general graph problem\nwhere we do not ﬁx the size of the initial labeling.\nDeﬁnition 2 (Common supergraph of partially labeledn-graphs)\nGiven is a set N of n names and a set of graphs {G\n1,G 2,...,G t} where each graph\nGi =( V,E i, Li)h a sn vertices (the set V), edges connecting pairs of vertices (the set\nEi) and where some of the vertices are labeled by names (an injective partial function\nLi : V → N) .Ag r a p h(N,EN )i sa common supergraph of {G1,G 2,...,G t} if there\nexists, for eachi, a bijection L′\ni : V → N that extends Li and such that {v,w }∈ EN\niﬀ there exists an i such that {v′,w ′}∈ Ei and {v,w } = {(L′\ni(v′), L′\ni(w′))}.\nA common supergraph ( N,EN )i sa minimum common supergraph if no other\ncommon supergraph (N,EN ′) exists for which |EN′| < |EN|.\nNote that every labeling function L′\ni induces an injection Ei → EN, hence the\nname common supergraph. Figure 6 shows two partially labeled 7-graphs, along\nwith two of their common supergraphs. G\n2 is not a minimum common supergraph\nsince it has more edges than G1; G1 is a minimum common supergraph since T1\nand T2 are not isomorphic and G1 has only one more edge than each ofT1 and T2.\nNow we can consider the following decision problem: Given a set of partially\nlabeled n-graphs, can the labelings be completed such that the n-graphs have a\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 805\ncommon supergraph with at most k edges? Labarre and Verwer (to appear) prove\nthat this problem is NP-hard, even if the n-graphs are trees with all leaves labeled.\n4.2 An FO(·)IDP3 solution\nListing 8 shows a simple model inspired by Labarre and Verwer (to appear). It\nmakes use of three types, tree, vertex and name. The latter two types have the\nsame number of elements in a correct input structure. The structure of the given\ntrees is described by the ternary predicateedge (the ﬁrst argument refers to the tree\nto which the edge belongs), the structure of the common supergraph (over the names\nthemselves) by the predicate arc. The labeling is described by the function label\nfrom the nodes of the given trees to the names. It is partially given in the input\nstructure and is completed during model expansion. The constraint in the theory,\nstating that, for each name nm and each tree t, there exists exactly one node nd\n(denoted\n?1n d ) such that its label is nm, ensures that the labeling is bijective. The\narc atoms can be deﬁned as the pairs of names induced by the labels on the nodes\nof an edge of the tree (the deﬁnition in the theory). However, as the minimization is\non the number of arc atoms in a model, some care is required. One should ensure\nthat either arc is a symmetric relation or there is at most onearc atom for each pair\nof names. The latter approach is taken as it gives a somewhat smaller grounding.\nIt is achieved by exploiting the total order that exists over each domain (the tests\nlabel(t ,x) < label(t ,y) ).\nListing 8. Modeling cs-plt in FO(·)IDP3.\nvocabulary CsPltVoc {\ntype tree\ntype vertex\ntype name // Isomorphic to vertex\nedge ( tree , node , node) // trees , given in input structure\narc(name,name) // the induced network\nlabel ( tree , node ): name // the labeling ,\n// partially given in the input structure\n}\ntheory CsPltTheory : CsPltVoc {\n{ // induced network; arc is anti −symmetric\n!txy:a r c ( l a b e l ( t , x ) , l a b e l ( t , y ) ) <− edge(t ,x ,y) &\nlabel(t ,x) < label(t ,y).\n!txy:a r c ( l a b e l ( t , x ) , l a b e l ( t , y ) ) <− edge(t ,y ,x) &\nlabel(t ,x) < label(t ,y).\n}\n! t nm : ?1 nd : l a b e l ( t , nd ) = nm . // label is bijective\n}\nterm SizeOfSupergraph : CsPltVoc { #{ xy:a r c ( x , y ) }}\nprocedure main () {\nprint (minimize(CsPltTheory , CsPltStructure , SizeOfSupergraph )[1])\n}\nIn this solution, each rule of the arc deﬁnition has two occurrences of the terms\nlabel(t ,x) and label(t ,y) . The current grounder naively associates a distinct symbol\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n806 M. Bruynooghe et al.\nwith each occurrence, which boils down to grounding a clause of the following\nform:\nListing 9. One of the arc rules after initial processing by the grounder.\n! t x y lx1 lx2 ly1 ly2 : arc(lx1 , ly1) <− lx1=label (t ,x) &\nly1=label (t ,y) & lx2=label (t ,x) & ly2=label (t ,y) &\nedge(t ,x ,y) & lx2 < ly2 .\nThis approach creates extra variables and very large groundings. To avoid this\nbehavior, on can rewrite the deﬁnition as follows:\nListing 10. Better performing deﬁnition of arc.\n{ // induced network\n! t x y lx ly : arc(lx , ly) <− lx=label(t ,x) & ly=label(t ,y) &\nedge(t ,x ,y) & lx < ly .\n! t x y lx ly : arc(lx , ly) <− lx=label(t ,x) & ly=label(t ,y) &\nedge(t ,y ,x) & lx < ly .\n}\nWhile the formulation is less elegant, the eﬀect on the size of the grounding and\nthe solving time is dramatic; e.g., the grounding is reduced from 620,798 to 6,024\npropositional clauses, and the solving time from 144 sec to 8 sec on a problem with\nﬁve trees of eight vertices and four initial labels.\nOne can explore several other variations. As mentioned above, one could use a\nsymmetric arc relation. Also, as the arc deﬁnition is free of recursion,\none could replace it with the two implications of the completion. Then, exploiting\nthe minimization on the number of arc atoms, one could drop the only-if part of\nthe completion. The eﬀect on solving time of all these variations is rather marginal.\n4.3 An approximate solution\nThe solving time is exponential in the number of nodes and, if several trees are\ninvolved, the program becomes impractical on real-world problems, even if the best\nsolution found so far is returned when some time budget is exceeded. However, the\nversatility of the IDP system allowed us to experiment with various strategies for\ngreedily searching an approximate solution. This led to the following quite natural\nsolution that performed very well with respect to both running time and quality of\nthe solution.\n1. Find a minimum common supergraph (MCS) for every pair of trees.\n2. Pick an MCS with minimum size (say G) and remove the two trees that are the\ninput for G.\n3. Find an MCS between G and every remaining tree.\n4. Replace G\n10 by an MCS with minimum size, remove the tree that is the input\nfor this MCS and go back to step 3 if any tree remains.\n10 This way, the MCS is assembled by each time incorporating one additional original tree.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 807\nTable 2. Randomly generated instances of the minimum common subgraph problem solved with\na time bound of 2,000 sec. Sizes of MCS (average over four runs) for exact and greedy approach\n*Approximate solution due to time out\n#Initial Exact Greedy\n#Trees #Nodes labels #edges #edges\n55 5 5 130 131.25\n56 0 1 0 128 132.75\n5 75 25 207.75 * 184.75\n10 55 5 183.75 * 154.50\n10 60 10 177.75 * 154.75\n10 75 25 270.00 * 269.25\n20 55 5 241.50 * 171.75\n20 60 10 232.00 * 152.25\n20 75 25 346.25 * 279.00\nSteps 1 and 3 of this simple procedure are performed by IDP3 using a model\nvery similar to that of Listing 8 (see Labarre and Verwer (to appear) for the actual\nmodel).11 This greedy approach works very well. Indeed, for large instances and\na ﬁxed time budget, the exact method runs out of time and returns a suboptimal\nsolution, while the greedy method completes and returns a solution that, although\nsuboptimal, is typically much smaller. Table 2 shows some experimental results on\nrandomly generated data with various parameters. A timeout was set to 2,000 sec,\n12\nand the average number of edges were recorded over four runs for each instance for\nboth exact and greedy methods.\n5 Learning deterministic ﬁnite state automata\nThe third task is about learning a DFA. The goal is to ﬁnd a (non-unique) smallest\nDFA that is consistent with a given set of positive and negative examples. It is one\nof the best studied problems in grammatical inference (de la Higuera 2005), has\nmany application areas and is known to be NP-complete (Gold 1978). Interestingly,\none of the ﬁrst algorithms proposed to solve this problem was based on a translation\nto constraint programming (Biermann and Feldman 1972). Much later, translations\nof this problem to graph coloring (Coste and Nicolas 1997; Costa Flor ˆencio and\nVerwer 2012) and satisﬁability (Grinchteinet al. 2006; Heule and Verwer 2010) were\nproposed. Although the DFA learning problem is typically tackled using greedy\napproaches (de la Higuera 2005), Heule and Verwer (2012) recently won the 2010\nStamina DFA learning competition (Stamina 2010) by an improved translation to\na SAT problem and running an oﬀ-the-shelf SAT solver. Here we explore to what\nextent an FO(·)\nIDP3 formalization can compete with this competition winner.\n11 The whole method can be implemented as an IDP3 procedure; however, the scripts had been\nimplemented before the Lua interface was available.\n12 Using an Intel R CoreTM i7 CPU 870 at 2.93 GHz with 8 GB of RAM running Ubuntu; default\nsettings for IDP3.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n808 M. Bruynooghe et al.\nb\nb\na a\na\nb\nb accepting\nrejecting\nFig. 7. An augmented preﬁx tree acceptor (APTA) for\nS =( S+ = {a, abaa, bb},S − = {abb, b}). The start state (annotated with incoming arrow) is\nthe root of the APTA.\n5.1 The problem\nA DFA is a directed graph comprising a set ofstates Q (nodes) and labeledtransitions\nT (directed edges). The root is the start state and any state is either an accepting\nor a rejecting state. In each state, there is exactly one transition for each symbol.\nA DFA deﬁnes a language, the set of strings it accepts. It can be used to generate\nor verify sequences of symbols (strings) using a process called DFA computation.\nWhen verifying strings, the symbols of the input string determine a path through the\ngraph. When the ﬁnal state is an accepting state, the string is accepted, otherwise it\nis rejected.\nGiven a pair of ﬁnite sets of positive example strings S\n+ and negative example\nstrings S− (the input sample), the goal of DFA identiﬁcation (or learning) is to ﬁnd a\n(non-unique) smallest DFA A that is consistent with S = {S+,S −}, i.e., every string\nin S+ is accepted, and every string in S− is rejected by A. Typically, the size of a\nDFA is measured by |Q|, the number of states it contains.\nMost DFA learning algorithms are based on the method of state-merging. This\nmethod ﬁrst constructs a tree-shaped automaton called the augmented preﬁx tree\nacceptor (APTA). As can be seen in Figure 7, the APTA accepts the positive examples\nand rejects the negative ones. Other strings either end up in a non-ﬁnal state or\ncannot be processed due to a missing transition. The APTA automaton can be\ncompleted to obtain a DFA with the same number of states by (arbitrarily) labeling\nthe non-ﬁnal states and adding the missing transitions. When all non-ﬁnal states are\nlabeled as reject and all extra transitions target a reject state with no path to an\naccepting state, this DFA accepts only the positive examples.\nA smaller DFA, accepting more strings, can be constructed by state-merging\non the APTA. Merging states under the constraints that the automaton remains\ndeterministic (at most one transition/label in each state) and accepting and rejecting\nstates cannot be merged preserves consistency with the input sample. State-merging\nincreases the number of strings accepted by the automaton, and hence generalizes\nthe language accepted by the DFA that completes the automaton.\nStates of the ﬁnal automaton are thus equivalence classes of states of the APTA.\nCalling the states of the ﬁnal automaton colors, the problem becomes that of\nﬁnding a coloring of the states of the APTA that is consistent with the input sample.\nFollowing Coste and Nicolas (1997), Heule and Verwer (2010) take this approach.\nThey formulate constraints expressing which pairs of states are incompatible, and\nabstract the problem as a graph. The nodes of this graph are the states of the\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 809\nAPTA and the edges are the incompatible pairs. The decision problem, whether\nthere exists an automaton with k states, becomes a graph coloring problem for k\ncolors. They use a clever SAT encoding to solve this decision problem and embed\nit in a workﬂow to solve the minimization problem. For really large problems, the\nSAT formulation becomes too big (hundreds of colors, resulting in over 100 million\nclauses) to be handled by a SAT solver (Heule and Verwer 2010). To reduce the\nproblem size, they used a greedy heuristic procedural method based on state-merging.\nEvery merge performed by this method reduces the size of the APTA and therefore\nalso the size of the encoding. In addition, this preprocessing identiﬁes a clique of\npairwise incompatible states in the APTA. For states in this clique, the colors can\nbe ﬁxed in advance. The eﬀect is to break the symmetries between these colors\nand thus to further reduce the size of the problem. The preprocessing also deduces\nthat certain state/color combinations cannot result in a solution. A preprocessed\nproblem instance is then extended with a set of SAT clauses and is the input for\nthe SAT solver. The SAT clauses express the constraints of the problem and are\ngenerated from the instance.\n5.2 An FO(·)\nIDP3 solution\nOur goal is not to set up the complete workﬂow described above, but to compare the\nperformance of the native SAT encoding of Heule and Verwer (2010) and Heule and\nVerwer (2012) with the performance of an FO(·)\nIDP3 model on the same problem\ninstances as obtained after the preprocessing. Our FO(·)IDP3 model for solving a\nsingle instance is shown in Listing 11.\nListing 11. Modeling DFA in FO(·)IDP3.\nvocabulary dfaVoc {\ntype state // states used in APTA\ntype label // symbols triggering transitions\ntype color // available states for resulting automaton\npartial trans(state , label ): state // transitions of APTA\nacc( state ) // accepting states of A P T A\nrej(state) // rejecting states of A P T A\ncolorOf( state ): color // fixed in input for c olors in clique\n// the resulting automaton:\npartial colorTrans(color , label ): color // transitions of D F A\naccColor( color ) // accepting states\n}\ntheory dfaTheory : dfaVoc {\n!x:a c c ( x )= > accColor(colorOf(x )).\n!x:r e j ( x )= > ˜accColor(colorOf(x )).\n// trans induces colorTrans:\n!xlz :t r a n s ( x , l ) = z = >\n! i j : colorOf(x)=i & colorOf(z)=j = > colorTrans(i , l)=j .\n}\nprocedure main () {\nprint (modelexpand(dfaTheory , instance )[1])\n}\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n810 M. Bruynooghe et al.\nThe types state, label, the function trans and the predicates acc and rej\ndescribe the given input samples (and hence the APTA). Note that trans is partial\nas it is only deﬁned for the transitions present in the input sample. The states of the\nresulting automaton are the elements of the typecolor. Its transitions are described\nby the function colorTrans. This function is also declared as a partial function.\nTo obtain a complete DFA, the function colorTrans has to be extended with the\nmissing transitions. Which one is assigned does not matter, as it does not aﬀect\nthe processing of the strings in the input sample (although it has an eﬀect on the\nlanguage that is accepted). The function colorOf maps the states of the APTA\non the states (colors) of the DFA. The predicate accColor describes the accepting\nstates of the resulting automaton.\nThe theory expresses two constraints onaccColor: accepting states of the APTA\nmust and rejecting states cannot be mapped to an accepting state of the DFA.\nThe third constraint states that each transition in the APTA induces a transition\n(between colors) in the DFA.\nThe input structure, which is omitted, not only completely deﬁnes the types\ncolor, state and label but also the APTA. That implies that the IDP3 grounder\nhas complete knowledge about the relations accept and reject and the function\ntrans. Hence, for example, the grounder only grounds the formula\ncolorTrans(colorOf(x), l)=colorOf(z) for tuples(x,l,z) for which trans(x, l)=z is true in\nthe input structure. Further, the input structure also contains the partial information\nabout colorOf and colorTrans that has been derived by preprocessing.\nThe main procedure assumes that the input structure is named instance; it calls\nthe solver to search for a model, and prints it.\nThe above model is a very natural formulation of the problem and corresponds\nquite closely to a “decompilation” of the SAT clauses expressing the constraints\nof the problem (Table 1 in both Heule and Verwer (2010) and Heule and Verwer\n(2012)). The most noticeable diﬀerence is in a redundant constraint, which can be\ndecompiled into:\nListing 12. Redundant constraint\n!v l w: trans(w, l)=v = >\n!j : colorTrans(colorOf(w) , l)=j = > colorOf(v)=j .\nThis formula can be derived from the last formula in our theory together with the\nfact that colorOf is a total function.\nIn FO(·)IDP3, it is very straightforward to extend the model with a term counting\nthe number of colors used and to minimize that number. This makes our FO(·)IDP3\nmethod very similar to the optimization method used by Heule and Verwer (2010,\n2012). IDP, however, has several advantages over an encoding constructed by hand.\nFor instance, variants of the model such as minimizing the number of transitions\nin the DFA instead of the number of states are very straightforward to obtain,\nbut would require a major re-engineering of the SAT encoding. This has practical\nvalue as diﬀerent application domains of DFA prefer diﬀerent optimization criteria.\nFurthermore, it is much easier to introduce bugs in handmade encodings than in\nthe few lines of IDP code. In fact, by analyzing and comparing the results of IDP\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 811\nFig. 8. (Colour online) Solving time for the SAT encoding (DFASAT), the FO(·)IDP3 model\nof Listing 11 (IDP) and the model extended with the redundant constraint of Listing 12\n(IDP+RED). Time in each system is monotonically increasing, so the order of problem\ninstances is diﬀerent for each system. Timeout is set at 5,000 sec. Sixty-nine problems are\nsolved by DFASAT, 59 by IDP and IDP+RED.\nand the handmade encoding, we discovered some subtle bugs in the handmade\ntranslation that caused an incorrect answer in rare occasions.\n5.3 Experiments\nWe compared the performance of our model with that of the SAT encoding,\ndenoted DFASAT, for 100 tough problems (the DFA is restricted to have only ﬁve\nstates on top of those in the initial clique) from the 2010 Stamina DFA learning\ncompetition (Stamina 2010).\n13\nFigure 8 compares the solving time of DFASAT with that of two FO(·)IDP3\nmodels. The ﬁrst one is as shown in Listing 11 (IDP); the second one extends the\nmodel with the redundant constraint of Listing 12 (IDP+RED). One can observe\nthat the redundant constraint improves the performance of the IDP3 system and\nthat the performance comes quite close to that of DFASAT. Still, DFASAT can\nsolve more problems than IDP+RED (69 versus 59). We also have to add that the\ndedicated preprocessing that generates the SAT instances requires on average 5 sec,\nwhile the grounding takes substantially more time. For the IDP version, it is on\naverage 124 sec; for ID+RED, the average is 168 sec. The results reported here\nare substantially better than those reported in Blockeel et al. (2012). By analyzing\n13 U s i n ga nI n t e lR CoreTM i5-2500 CPU at 3.30 GHz with 7.7 GB of RAM Running Ubuntu. Memory\nuse was limited to 4 GB, time to 5000 sec. IDP3 was ran with standard options.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n812 M. Bruynooghe et al.\nthese earlier results, we unraveled that the large performance gap was due to\nour grounding being three times the size of the SAT encoding. This was caused\nby the introduction of unneeded auxiliary predicates (so-called Tseitins) during\nthe grounding. The problem was repaired in a new version of the grounder. As\nmentioned before, our detailed analysis also revealed subtle bugs in the dedicated\npreprocessing which generates the SAT encodings for DFASAT. Thus, using anIDP\nimplementation of a hard problem such as DFA learning and comparing it with a\nfast competition winning SAT translation was not only useful for improving IDP\nbut also for improving the competition winner.\nIt is very encouraging to observe that the performance of a tiny and comprehen-\nsible predicate logic model comes very close to that of an ingeniously tuned SAT\nencoding that is a key component of a competition winner.\n6 Conclusions\nIn this paper, we presented theIDP3 system from a user’s perspective. We introduced\nthe various components of anFO(·)\nIDP3 model and illustrated their use in a model for\nthe shortest path problem. We also showed models for some problems encountered\nby researchers in data mining and machine learning. In the ﬁrst problem from\nstemmatology, FO(·)\nIDP3 models proved to be of invaluable help for researchers\ntrying to cope with stemma that go beyond tree structures (Andrewset al. 2012). We\nobtained a model that not only correctly handles arbitrary directed acyclic graphs\nbut also achieved better performance than the original (incomplete) procedural code.\nIn the second problem, about phylogenetic trees,FO(·)\nIDP3 models helped researchers\nto explore approximate solutions for an NP-hard problem (Labarre and Verwer to\nappear). The third problem that we modeled is the classical problem of learning\na DFA. We compared an FO(·)\nIDP3 model with the state-of-the-art SAT encoding\nof the problem. Here we found that the performance of an IDP3 solution comes\npretty close to that of a highly tuned SAT encoding. These applications illustrate\nthat FO(·)\nIDP3 models are a valuable alternative for dedicated procedural code when\nnovel data needs to be analyzed and explored. Interestingly, in both problems,\nwhere we compared with an existing solution (stemmatology and DFA learning),\nwe uncovered some bugs in those solutions. It is fair to add that we also uncovered\nsome cases where the grounder of the IDP3 system performed a suboptimal job. In\nthe minimum common supergraph application we found that it deals poorly with\nmultiple occurrences of the same term in a formula; in the DFA application we\nfound that it introduced unneeded auxiliary symbols. While the latter problem has\nalready been solved, the former is, at the time of writing, still on the to-do list of\nthe implementation team.\nOur work is a further indication that the IDP3 system is coming of age. It was\nalready known from the ASP-competitions that it compares pretty well with ASP\nsystems in terms of performance (Denecker et al. 2009; Calimeri et al. 2011). In\ncontrast to ASP, which relies on the stable semantics (Gelfond and Lifschitz 1988),\nit is based on the ﬁrst-order logic. The informal semantics of FO’s connectives and\nthe novel language constructs is clear and easy to understand. This probably makes\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 813\nit easier for newcomers to start modeling. For example, the authors of the minimum\ncommon supergraph problem (Labarre and Verwer to appear) were neither familiar\nwith Prolog nor withFO(·)\nIDP3 and hardly needed any help from the IDP team. The\ncore of an FO(·)IDP3 model consists on the one hand of formulas in the ﬁrst-order\nlogic, which act as constraints, and on the other hand of deﬁnitions, which are close\nto the rules of traditional logic programs. Given interpretations for open predicates\n(the predicates that are not deﬁned in the theory), the deﬁnitions determine a unique\nmodel through the well-founded semantics (Van Gelder et al. 1991). The search\nresults in an interpretation of the open predicates and hence a model of the theory\nthat is consistent with the constraints. What distinguishes FO(·) from traditional\nlogic programming is the use of non-Herbrand interpretations, and correspondingly\nthe lack of constructor functions. This often leads to a simpler data representation\nand gives rise to elegant model formulations. On the other hand, there are cases\nwhere rich data structures that arise in the Herbrand interpretations (compound\nt e r m s ,l i s t s ,t r e e s ,...)a r eu s e f u lt o oa n dt h e s ec u r r e n t l yc annot easily be modeled\nin IDP3. Another distinction is that the IDP framework oﬀers other forms of\ninference, most notably model expansion and model minimization. A feature of the\nIDP3 system is the integration of procedures in FO(·)\nIDP3 models (De Pooter et al.\n2011) and the clean separation between declarative and procedural components. As\nwe illustrated in the stemmatology application, this allows a user to develop a whole\nworkﬂow in an FO(·)\nIDP3 model.\nThe logic of FO(·)IDP3 extends predicate logic with inductive deﬁnitions, types,\narithmetic, aggregates and partial functions. Of these, inductive deﬁnition is the\nmost fundamental one. The basis of the language is predicate logic. In fact, in\nmany applications, the extensions only serve for making models more readable. For\nexample, the aggregates (in the form of quantiﬁcations ? < 2) in the shortest path\nproblem are directly translatable to FO and the (non-recursive) deﬁnition in the\nminimum common supergraph problem is equivalent with its completion. Hence,\nthree out of the four problems that we describe in this text are in fact solved with\npure predicate logic models.\nOur work on applications taught us also a few things about good models. In all\nproblems that we solved in this paper, a class of objects is separated in equivalence\nclasses. (In the shortest path problem there is the class of edges participating in the\npath, and the class of other edges.) It is tempting to represent these equivalence\nclasses by the transitive closure of some relation. However, the transitive closure of\na binary relation is expensive. It gives rise to large groundings and this, together\nwith the cost of checking for unfounded sets, results in poor performance. Binary\ntransitive closures arise naturally during modeling, but they are better avoided in the\nIDP3 system. In the shortest path problem our ﬁrst solution had a binary transitive\nreaches relation. It required some creative tinkering and awareness that binary\ntransitive closures are harmful to make the switch to the solution we presented.\nReplacing it with the unary reachable relation had a major impact on eﬃciency.\nAlso, our ﬁrst solution to the stemmatology problem had a transitive closure. Here\ntransitive closure could be avoided altogether. It was a major step forward in\neﬃciency to replace it by a coloring function for the nodes in the stemma graph.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n814 M. Bruynooghe et al.\nThe other two problems also use functions (label and colorOf respectively) whose\nrange deﬁnes membership in an equivalence class.\nThe preference of a unary transitive relation over a binary one is an illustration\nof another general principle: less variables is better in rules and constraints. One\nshould try to break up complex rules and constraints in simpler ones requiring less\nvariables and explore whether one can do with predicates and functions having less\narguments. Another important point is that one should not be satisﬁed with the ﬁrst\ncorrect model. Often, major improvements are possible, as we illustrated in several\nof our applications.\nThe IDP3 system is an evolving research system and further improvements are on\nthe way. A lot of ongoing work aims at making the performance less dependent on\nclever modeling. One recent feature is symmetry breaking. Predicate-level symmetry\ndetection and dynamic symmetry breaking (during search) automatically exploit\nsymmetries present in the problem (Devriendt et al. 2012) (symmetry is present in\nthe DFA problem: permuting the colors gives another solution; however it was\nbroken in an ad hoc way in the SAT encoding and hence also in the input structure\nof our instances). One recent feature is to avoid complete proposionalization during\ngrounding, on one hand by keeping function terms in the grounding (De Cat et al.\n2013), and, on the other hand through lazy, demand-driven grounding during search\n(De Catet al.2012, 2014). Another feature is the detection of functional dependencies\nand their use to reduce the arity of predicates (De Cat and Bruynooghe 2013).\nAcknowledgements\nCaroline Mac´e and Tara Andrews introduced some of the authors to stemmatology\nand provided the data sets; Tara also explained the working of the procedural code.\nThis work was supported by Research Foundation – Flanders (FWO-Vlaanderen)\nand the Research Council of KU Leuven (GOA/08/008 and GOA 13/010).\nReferences\nAndrews, T., Blockeel, H., Bogaerts, B., Bruynooghe, M. , Denecker, M. , De Pooter,\nS., Mac´e, C. and Ramon, J. 2012. Analyzing manuscript traditions using constraint-based\ndata mining. In COmbining COnstraint solving with MIning and LEarning (CoCoMile).\nMontpellier, France, 27 August 2012, Proceedings First Workshop on Combining Constraint\nSolving with Mining and Learning (CoCoMile). (ECAI 2012 Workshop), 15–20.\nAndrews, T. and Mac ´e, C. 2013. Beyond the tree of texts: Building an empirical model\nof scribal variation through graph analysis of texts and stemmata. Literary and Linguistic\nComputing 28, 4, 504–521.\nBaret, P., Mac´e, C., Robinson, P., Peersman, C. , Mazza, R., Noret, J., Wattel, E., Van\nMulken,M . , Robinson, P. , Lantin, A-C. , Canettieri, P., Loreto, V., Windram, H. ,\nSpencer, M., Howe, C., Albu, M. and Dress, A. 2006. Testing methods on an artiﬁcially\ncreated textual tradition. In The Evolution of Texts: Confronting Stemmatological and\nGenetical Methods, Proceedings of the International Workshop, Louvain-la-Neuve. Istituti\neditoriali e poligraﬁci internazionali, Pisa, Italy, 255–283.\nBiermann, A. W. and Feldman, J. A. 1972, June. On the synthesis of ﬁnite-state machines\nfrom samples of their behavior. IEEE Transactions on Computers 21,6, 592–597.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 815\nBlockeel, H., Bogaerts, B., Bruynooghe, M., De Cat, B., De Pooter, S., Denecker, M.,\nLabarre, A., Ramon, J. and Verwer, S.2012. Modeling machine learning and data mining\nproblems with FO(·).I n Technical Communications of the 28th International Conference on\nLogic Programming (ICLP 2012), Budapest, Hungary, September 4–8, 2012, A. Dovier and\nV. S. Costa, Eds., LIPIcs, vol. 17. Schloss Dagstuhl – Leibniz-Zentrum fuer Informatik,\nWadern, Germany, 14–25.\nBrewka, G., Eiter, T. and Truszczy ´nski, M. 2011. Answer set programming at a glance.\nCommunications of the ACM 54,12, 92–103.\nCalimeri, F., Ianni, G., Ricca, F., Alviano, M., Bria, A., Catalano, G., Cozza, S., Faber,\nW., Febbraro, O., Leone, N., Manna, M., Martello, A., Panetta, C., Perri, S., Reale,\nK., Santoro, M. C., Sirianni, M., Terracina, G. and Veltri, P. 2011. The third answer\nset programming system competition: Preliminary report of the system competition track.\nIn Proceedings of the International Conference on Logic Programming and Nonmonotonic\nReasoning (LPNMR). Springer, Berlin, Germany, 388–403.\nCosta Flor ˆencio, C. and Verwer, S. 2012. Regular inference as vertex coloring. In\nAlgorithmic Learning Theory, N. Bshouty, G. Stoltz, N. Vayatis and T. Zeugmann, Eds.,\nLecture Notes in Computer Science, vol. 7568. Springer, Berlin, Germany, 81–95.\nCoste, F. and Nicolas, J. 1997. Regular inference as a graph coloring problem. In\nICML Workshop on Grammatical Inference, Automata Induction, and Language Acquisition.\nWorkshop on Automata Induction, Grammatical Inference, and Language Acquisition at\nThe Fourteenth International Conference on Machine Learning (ICML-97) July 12, 1997,\nNashville, Tennessee, 6 pages.\nDe Cat, B., Bogaerts, B., Bruynooghe, M. and Denecker, M. 2014. Predicate logic as a\nmodelling language: The IDP system. CoRR abs/1401.6312.\nDe Cat, B., Bogaerts, B.,\nDenecker, M. and Devriendt, J. 2013. Model expansion in the\npresence of function symbols using constraint programming. In 25th IEEE International\nConference on Tools with Artiﬁcial Intelligence (ICTAI 2013), Washinton, WA, November\n4–6, 2013. 1068–1075.\nDe Cat, B. and Bruynooghe, M.2013. Detection and exploitation of functional dependencies\nfor model generation. Theory and Practice of Logic Programming 13,4–5, 471–485.\nDe Cat, B. , Denecker, M. and Stuckey, P. 2012. Lazy model expansion by incremental\ngrounding. In Technical Communications of the 28th International Conference on Logic\nProgramming (ICLP 2012), Budapest, Hungary, September 4–8, 2012, A. Dovier and\nV. S. Costa, Eds., LIPIcs, vol. 17. Schloss Dagstuhl – Leibniz-Zentrum fuer Informatik,\nWadern, Germany, 201–211.\nDe Cat, B., Denecker, M., Stuckey, P. J. and Bruynooghe, M.2014. Lazy model expansion:\nInterleaving grounding with search. CoRR abs/1402.6889.\nde la Higuera, C. 2005. A bibliographical study of grammatical inference. Pattern\nRecognition 38, 9, 1332–1348.\nDenecker, M. , Lierler, Y. , Truszczynski, M. and Vennekens, J. 2012. A Tarskian\ninformal semantics for Answer Set Programming. In Technical Communications of the\n28th International Conference on Logic Programming (ICLP 2012), Budapest, Hungary,\nSeptember 4–8, 2012, A. Dovier and V. S. Costa, Eds. LIPIcs, vol. 17. Schloss Dagstuhl –\nLeibniz-Zentrum fuer Informatik, Wadern, Germany, 277–289.\nDenecker, M. and Ternovska, E.2008, April. A logic of nonmonotone inductive deﬁnitions.\nACM Transactions on Computational Logic (TOCL) 9,2, 14:1–14:52.\nDenecker, M. and Vennekens, J. To appear. The well-founded semantics is the principle of\ninductive deﬁnition, revisited. In 14th International Conference on Principles of Knowledge\nRepresentation and Reasoning, Vienna, Austria, July 20–24, 2014, AAAI press.\nDenecker, M. , Vennekens, J. , Bond, S. , Gebser, M. and Truszczy ´nski, M. 2009. The\nsecond Answer Set Programming competition. In 10th International Conference on Logic\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\n816 M. Bruynooghe et al.\nProgramming and Non-Monotonic Reasoning (LPNMR),E .E r d e m ,F .L i na n dT .S c h a u b ,\nEds. LNCS, vol. 5753. Springer, Berlin, Germany, 637–654.\nDe Pooter, S. , Wittocx, J. and Denecker, M. 2011. A prototype of a knowledge-\nbased programming environment. InInternational Conference on Applications of Declarative\nProgramming and Knowledge Management. Lecture Notes in Computer Science, vol. 7773.\nSpringer, Berlin, Germany, 279–286.\nDevriendt, J. , Bogaerts, B., Mears, C., Cat, B. D. and Denecker, M. 2012. Symmetry\npropagation: Improved dynamic symmetry breaking in SAT. In Proceedings of the 24th\nIEEE International Conference on Tools with Artiﬁcial Intelligence (ICTAI’12) ,A t h e n s ,\nGreece, IEEE Press, 49–56.\nDovier, A. and Costa, V. S., Eds. 2012. Technical Communications of the 28th International\nConference on Logic Programming (ICLP 2012), Budapest, Hungary, September 4–8, 2012.\nLIPIcs, vol. 17. Schloss Dagstuhl – Leibniz-Zentrum fuer Informatik, Wadern, Germany.\nE´en, N. and S ¨orensson, N. 2003. An extensible SAT-solver. In International Conference,\nSAT, E. Giunchiglia and A. Tacchella, Eds. LNCS, vol. 2919. Springer, Berlin, Germany,\n502–518.\nErdem, E. 2011. Applications of answer set programming in phylogenetic systematics. InLogic\nProgramming, Knowledge Representation, and Nonmonotonic Reasoning – Essays Dedicated\nto Michael Gelfond on the Occasion of His 65th Birthday , Lecture Notes in Computer\nScience, vol. 6565, Springer, 415–431.\nFelsenstein, J. 2004. Inferring Phylogenies. Sinauer, Sunderland, MA.\nF r i s c h ,A .M ., Harvey, W., Jefferson, C., Hern´andez, B. M. and Miguel, I.2008. Essence:\nA constraint language for specifying combinatorial problems. Constraints 13, 3, 268–306.\nGambette, P. 2010. Who is who in phylogenetic networks: Articles, authors and\nprograms. Published electronically. Accessed 2011. URL:http://www.atgc-montpellier.\nfr/phylnet.\nGebser, M. , Kaufmann, B., Neumann, A. and Schaub, T. 2007. clasp: A conﬂict-driven\nanswer set solver. In LPNMR, C. Baral, G. Brewka and J. S. Schlipf, Eds. LNCS, vol. 4483.\nSpringer, Berlin, Germany, 260–265.\nGelfond, M. and Lifschitz, V. 1988. The stable model semantics for logic programming. In\nICLP/SLP, R. A. Kowalski and K. A. Bowen, Eds. MIT Press, Cambridge, MA, 1070–1080.\nGold, E. M. 1978. Complexity of automaton identiﬁcation from given data. Information and\nControl 37, 3, 302–320.\nGrinchtein, O. , Leucker, M. and Piterman, N. 2006. Inferring network invariants\nautomatically. In Automated Reasoning, U. Furbach and N. Shankar, Eds. Lecture Notes\nin Computer Science, vol. 4130. Springer, Berlin, Germany, 483–497.\nGuns, T.\n, Nijssen, S. and Raedt, L. D. 2011. Itemset mining: A constraint programming\nperspective. Artiﬁcial Intelligence 175, 12–13, 1951–1983.\nHeule, M. and Verwer, S.2010. Exact DFA identiﬁcation using SAT solvers. InGrammatical\nInference: Theoretical Results and Applications (ICGI 2010), 66–79.\nHeule, M. J. H. and Verwer, S. 2012. Software model synthesis using satisﬁability solvers.\nEmpirical Software Engineering, August, 1–32. doi: http://dx.doi.org/10.1007/s10664-012-\n9222-z.\nHuson, D. H. , Rupp, R. and Scornavacca, C. 2010. Phylogenetic Networks: Concepts,\nAlgorithms and Applications. Cambridge University Press, Cambridge, UK.\nIerusalimschy, R., de Figueiredo, L. H. and Celes, W. 1996. Lua – an extensible extension\nlanguage. Software: Practice and Experience 26,6, 635–652.\nJansen, J., Jorissen, A. and Janssens, G. 2013. Compiling input* FO(·) inductive deﬁnitions\ninto tabled Prolog rules for IDP3. Theory and Practice of Logic Programming 13, 4–5,\n691–704.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press\nPredicate logic as a modeling language 817\nKowalski, R. A. 1974. Predicate logic as programming language. In IFIP Congress,J .L .\nRosenfeld, Ed. Information Processing 74, Proceedings of IFIP Congress 74, Stockholm,\nSweden, August 5–10, 1974. North-Holland, 1974, 569–574.\nLabarre, A. and Verwer, S. To appear. Merging partially labelled trees: Hardness and\nan eﬃcient practical solution. IEEE/ACM Transactions on Computational Biology and\nBioinformatics.\nLeone, N. , Pfeifer, G. , Faber, W., Eiter, T., Gottlob, G., Perri, S. and Scarcello, F.\n2002. The DLV system for knowledge representation and reasoning.ACM Transactions on\nComputational Logic 7, 499–562.\nMari¨en, M., Wittocx, J., Denecker, M. and Bruynooghe, M. 2008. SAT(ID): Satisﬁability\nof propositional logic extended with inductive deﬁnitions. In SAT,H .K l e i n eB¨uning and\nX. Zhao, Eds. LNCS, vol. 4996. Springer, Berlin, Germany, 211–224.\nMarriott, K., Nethercote, N., Rafeh, R., Stuckey, P. J., Garcia de la Banda, M. and\nWallace, M. 2008. The design of the Zinc modelling language. Constraints 13, 3, 229–267.\nMilner, R. 1978. A theory of type polymorphism in programming. Journal of Computer and\nSystem Sciences 17, 3, 348–375.\nMitchell, D. G. and Ternovska, E. 2005. A framework for representing and solving NP\nsearch problems. In Twentieth AAAI National Conference on Artiﬁcial Intelligence (AAAI-\n05), M. M. Veloso and S. Kambhampati, Eds. MIT Press, Cambridge, MA, 430–435.\nNieuwenhuis, R., Oliveras, A. and Tinelli, C.2006. Solving SAT and SAT modulo theories:\nFrom an abstract Davis–Putnam–Logemann–Loveland procedure to DPLL(T). Journal of\nthe ACM 53, 6, 937–977.\nPelov, N., Denecker, M. and Bruynooghe, M. 2007. Well-founded and stable semantics of\nlogic programs with aggregates. Theory and Practice of Logic Programming (TPLP) 7,3,\n301–353.\nRoos, T. and Heikkil ¨a, T. 2009. Evaluating methods for computer-assisted stemmatology\nusing artiﬁcial benchmark data sets. Literary and Linguistic Computing 24,4, 417–433.\nSchulte, C. and Stuckey, P. J. 2008. Eﬃcient constraint propagation engines. ACM\nTransactions on Programming Languages and Systems 31,1.\nStamina 2010. The StaMinA competition, learning regular languages with large alphabets.\nAccessed 2012. URL: http://stamina.chefbe.net/.\nSwift, T. and Warren, D. S. 2012. XSB: Extending Prolog with tabled logic programming.\nTheory and Practice of Logic Programming 12,1–2, 157–187.\nSyrj¨anen, T. and Niemel¨a, I. 2001. The smodels system. In LPNMR,T .E i t e r ,W .F a b e ra n d\nM. Truszczy´nski, Eds. LNCS, vol. 2173. Springer, Berlin, Germany, 434–438.\nTimpanaro, S. 2005. The Genesis of Lachmann’s Method, G. W. Most, Trans. University of\nChicago Press, Chicago, IL.\nVan Gelder, A., Ross, K. A. and Schlipf, J. S.1991. The well-founded semantics for general\nlogic programs. Journal of the ACM 38,3, 620–650.\nWittocx, J., Denecker, M. and Bruynooghe, M.2013. Constraint propagation for ﬁrst-order\nlogic and inductive deﬁnitions. ACM Transactions on Computational Logic 14,3.\nWittocx, J., Mari¨en, M. and Denecker, M. 2008. The IDP system: A model expansion\nsystem for an extension of classical logic. In The 2nd International Workshop on Logic and\nSearch (LaSh 2008), M. Denecker, Ed. November 6–7, 2008, Leuven, Belgium, 153–165.\nWittocx, J., Mari¨e n ,M .a n dD e n e c k e r ,M .2010. Grounding FO and FO(ID) with bounds.\nJournal of Artiﬁcial Intelligence Research 38, 223–269.\nhttps://doi.org/10.1017/S147106841400009X Published online by Cambridge University Press",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8051782846450806
    },
    {
      "name": "First-order logic",
      "score": 0.6613436341285706
    },
    {
      "name": "Inductive logic programming",
      "score": 0.6580802202224731
    },
    {
      "name": "Predicate (mathematical logic)",
      "score": 0.5298746824264526
    },
    {
      "name": "Theoretical computer science",
      "score": 0.502140998840332
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45416882634162903
    },
    {
      "name": "Programming language",
      "score": 0.37725967168807983
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99464096",
      "name": "KU Leuven",
      "country": "BE"
    },
    {
      "id": "https://openalex.org/I145872427",
      "name": "Radboud University Nijmegen",
      "country": "NL"
    }
  ],
  "cited_by": 41
}