{
  "title": "Computational Argumentation Synthesis as a Language Modeling Task",
  "url": "https://openalex.org/W2991127892",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2868341778",
      "name": "Roxanne El Baff",
      "affiliations": [
        "Bauhaus-Universität Weimar"
      ]
    },
    {
      "id": "https://openalex.org/A2009299615",
      "name": "Henning Wachsmuth",
      "affiliations": [
        "Paderborn University"
      ]
    },
    {
      "id": "https://openalex.org/A2223261679",
      "name": "Khalid Al-Khatib",
      "affiliations": [
        "Bauhaus-Universität Weimar"
      ]
    },
    {
      "id": "https://openalex.org/A739021993",
      "name": "Manfred Stede",
      "affiliations": [
        "University of Potsdam"
      ]
    },
    {
      "id": "https://openalex.org/A2134393620",
      "name": "Benno Stein",
      "affiliations": [
        "Bauhaus-Universität Weimar"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2264742718",
    "https://openalex.org/W2145610967",
    "https://openalex.org/W2048529682",
    "https://openalex.org/W2963480675",
    "https://openalex.org/W2140910804",
    "https://openalex.org/W2250309026",
    "https://openalex.org/W2508469894",
    "https://openalex.org/W2138107261",
    "https://openalex.org/W2759690420",
    "https://openalex.org/W2091034860",
    "https://openalex.org/W2518510348",
    "https://openalex.org/W1493371713",
    "https://openalex.org/W99991519",
    "https://openalex.org/W2040467972",
    "https://openalex.org/W2062342610",
    "https://openalex.org/W2898884341",
    "https://openalex.org/W2066064791",
    "https://openalex.org/W1978078764",
    "https://openalex.org/W2029698681",
    "https://openalex.org/W2878573333",
    "https://openalex.org/W2963283805",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2250404077",
    "https://openalex.org/W2251159917",
    "https://openalex.org/W2963721761",
    "https://openalex.org/W1997210479",
    "https://openalex.org/W2252055876",
    "https://openalex.org/W2517275502",
    "https://openalex.org/W2915177913"
  ],
  "abstract": "Synthesis approaches in computational argumentation so far are restricted to generating claim-like argument units or short summaries of debates. Ultimately, however, we expect computers to generate whole new arguments for a given stance towards some topic, backing up claims following argumentative and rhetorical considerations. In this paper, we approach such an argumentation synthesis as a language modeling task. In our language model, argumentative discourse units are the “words”, and arguments represent the “sentences”. Given a pool of units for any unseen topic-stance pair, the model selects a set of unit types according to a basic rhetorical strategy (logos vs. pathos), arranges the structure of the types based on the units’ argumentative roles, and finally “phrases” an argument by instantiating the structure with semantically coherent units from the pool. Our evaluation suggests that the model can, to some extent, mimic the human synthesis of strategy-specific arguments.",
  "full_text": "Proceedings of The 12th International Conference on Natural Language Generation, pages 54–64,\nTokyo, Japan, 28 Oct - 1 Nov, 2019.c⃝2019 Association for Computational Linguistics\n54\nComputational Argumentation Synthesis as a Language Modeling Task\nRoxanne El Baff1 Henning Wachsmuth2 Khalid Al-Khatib1\nManfred Stede3 Benno Stein1\n1 Bauhaus-Universität Weimar, Weimar, Germany,<first> { .<last> }+@uni-weimar.de\n2 Paderborn University, Paderborn, Germany,henningw@upb.de\n3 University of Potsdam, Potsdam, Germany, stede@uni-potsdam.de\nAbstract\nSynthesis approaches in computational argu-\nmentation so far are restricted to generating\nclaim-like argument units or short summaries\nof debates. Ultimately, however, we expect\ncomputers to generate whole new arguments\nfor a given stance towards some topic, backing\nup claims following argumentative and rhetor-\nical considerations. In this paper, we approach\nsuch an argumentation synthesis as a language\nmodeling task. In our language model, argu-\nmentative discourse units are the “words”, and\narguments represent the “sentences”. Given\na pool of units for any unseen topic-stance\npair, the model selects a set of unit types ac-\ncording to a basic rhetorical strategy (logos\nvs. pathos), arranges the structure of the types\nbased on the units’ argumentative roles, and ﬁ-\nnally “phrases” an argument by instantiating\nthe structure with semantically coherent units\nfrom the pool. Our evaluation suggests that the\nmodel can, to some extent, mimic the human\nsynthesis of strategy-speciﬁc arguments.\n1 Introduction\nExisting research on computational argumentation\nlargely focuses on the analysis side. Various analy-\nsis tasks are widely studied including identifying\nthe claims along with their supporting premises\n(Stab and Gurevych, 2014), ﬁnding the relation\nbetween argumentative units (Cocarascu and Toni,\n2017), and assessing the persuasiveness of argu-\nments (Habernal and Gurevych, 2016).\nDiverse downstream applications, however, ne-\ncessitate the development of argumentation synthe-\nsis technologies. For example, synthesis is needed\nto produce a summary of arguments for a given\ntopic (Wang and Ling, 2016) or to build a debat-\ning system where new arguments are exchanged\nbetween the users and the system (Le et al., 2018).\nAs a result, a number of recent studies addresses\nthe argumentation synthesis task. These studies\nhave proposed different approaches to generating\nclaims or reasons for a given topic, partly with a par-\nticular stance towards the topic (Bilu and Slonim,\n2016; Hua and Wang, 2018). However, the next\nimportant synthesis step is still missing in the liter-\nature, namely, to generate complete texts including\nboth argumentative and rhetorical considerations.\nWith the latter, we refer to Aristotle’s three means\nof persuasion: logos (providing logical arguments),\nethos (demonstrating credibility), and pathos (evok-\ning emotions). As discussed by Wachsmuth et al.\n(2018), following a rhetorical strategy is key to\nachieving persuasion with argumentative texts.\nThis paper proposes a new computational ap-\nproach that synthesizes argumentative texts follow-\ning a rhetorical strategy. We do not tackle this task\nimmediately “in the wild”, i.e., generating an en-\ntirely new argumentative text for a freely-chosen\ntopic and a possibly complex strategy. Rather, we\nconsider a “controlled” synthesis setting, with the\ngoal of successively creating models that are able\nto deal with more complex settings later on.\nIn particular, given a pool of argumentative dis-\ncourse units (ADUs), our approach generates argu-\nments for any unseen pair of topic and stance (e.g.,\n“con abortion”) as well as a basic rhetorical strat-\negy (i.e., logos-oriented vs. pathos-oriented).1 To\nabstract from the arguments’ topics during training,\nwe ﬁrst identify different ADU types using cluster-\ning. Our approach then learns to select unit types\nmatching the given strategy and to arrange them\naccording to their argumentative roles. Both steps\nare realized as a language model where ADUs rep-\nresent words and arguments are sentences. Finally,\nour approach “phrases” an argument by predict-\ning the best set of semantically related ADUs for\nthe arranged structure using supervised regression.\nThereby, we ensure that the synthesized texts are\n1We consider a single argument to be a sequence of ADUs\nwhere each ADU has a speciﬁc role: thesis, con, or pro.\n55\ncomposed of meaningful units, a property that neu-\nral generation methods barely achieve so far.\nIn our evaluation, we utilize the dataset of\nWachsmuth et al. (2018). This dataset contains 260\nargumentative texts on 10 topic-stance pairs, where\neach text composes ﬁve ADUs in a logos-oriented\nor pathos-oriented manner. In our experiments, we\ntrain our approach on nine topic-stance pairs and\nthen generate an argument for the tenth. The re-\nsults demonstrate that our approach successfully\nmanages to combine pairs of ADUs, but its perfor-\nmance on longer sequences of ADUs is limited.\nAltogether, our contribution is three-fold:\n1. A new view of argumentation synthesis that\nrepresents argumentative and rhetorical con-\nsiderations with language modeling.\n2. A novel approach that selects, arranges, and\nphrases ADUs to synthesize strategy-speciﬁc\narguments for any topic and stance.\n3. First experimental evidence that arguments\nwith basic rhetorical strategies can be synthe-\nsized computationally.2\n2 Related Work\nRecently, some researchers have tackled argumen-\ntation synthesis statistically with neural networks.\nFor instance, Wang and Ling (2016) employed\na sequence-to-sequence model to generate sum-\nmaries of argumentative texts, and Hua and Wang\n(2018) did similar to generate counterarguments.\nUsing neural methods in text generation, it is possi-\nble to achieve output that is on topic and grammat-\nically (more or less) correct. However, when the\ndesired text is to span multiple sentences, the gen-\nerated text regularly suffers from incoherence and\nrepetitiveness, as for instance discussed by Holtz-\nman et al. (2018) who examine texts that were pro-\nduced by RNNs in various domains. While these\nproblems may be tolerable to some extent in some\napplications, such as chatbots, bad text cannot be\naccepted in an argumentative or debating scenario,\nwhere the goal is to convince or persuade a reader\n(rather than to merely inform or entertain).\nHoltzman et al. (2018) propose to alleviate in-\ncoherence and repetitiveness by training a set of\ndiscriminators, which aim to ensure that a text re-\nspects the Gricean maxims of quantity, quality, re-\nlation, and manner (Grice, 1975). To this end, they\n2The code for running the experiments is avail-\nable here: https://github.com/webis-de/\ninlg19-argumentation-synthesis\nemploy speciﬁc datasets, such as one that opposes\nauthentic text continuation to randomly-sampled\ntext. The discriminators learn optimal weightings\nfor the various models and their combination, such\nthat overall text quality is maximized. For argu-\nmentation, we hypothesize that one needs to go\neven further and eventually account for the author,\nimplementing her underlying intention in the dif-\nferent parts of an argumentative text as well as in\nthe relations between the parts.\nIn the past times of rule-based text generation,\nargumentation synthesis was a popular task (Zuker-\nman et al., 2000). Approaches involved much hand-\ncrafted (linguistic and domain) knowledge and user\nmodeling. For example, the system of Carenini\nand Moore (2006) compares attributes of houses\n(from a database) to desired target attributes (from\na user model), to then recommend a house to the\nreader in a convincing text following the Gricean\nmaxims. To this end, it selected house attributes\npotentially interesting to the user, arranged, and\nﬁnally phrased them. The resulting texts resembled\nthe arguments we work with here, which have been\nmanually composed by experts (Wachsmuth et al.,\n2018) from the claims, evidence, and objections\nin the arg-microtext corpus (Peldszus and Stede,\n2016). To achieve a similar level of output control,\ntoday’s text-to-text generation models need to ac-\ncount for the various interdependencies between\nthe text units to be combined.\nMost related to our approach is the system of\nSato et al. (2015), where a user can enter a claim-\nlike topic along with a stance. The system then\ngenerates argumentative paragraphs on speciﬁc as-\npects of the topic by selecting sentences from 10\nmillion news texts of the Gigaword corpus. Poten-\ntially relevant aspects are those that trigger eval-\nuative judgment in the reader. The sentences are\narranged so that the text starts with a claim sentence\nand is followed by support sentences, employing\nthe approach of Yanase et al. (2015). The support\nsentences are ordered by maximizing the seman-\ntic connectivity between sentences. Finally, some\nrephrasing is done in terms of certain aspects of sur-\nface realization. In a manual evaluation, however,\nno text was seen as sounding natural, underlining\nthe difﬁculty of the task. In contrast to Sato et al.\n(2015), we learn directly from input data what ar-\ngumentative discourse units to combine and how\nto arrange them. We leave surface realization aside\nto keep the focus on the argument composition.\n56\nRole ID Argumentative Discourse Unit\nThesis t 1 German universities should on no account charge tuition fees\nt2 the universities in Germany should not under any circumstances charge tuition fees\nt3 tuition fees should not generally be charged by universities\nt4 universities should not charge tuition fees in Germany\nCon c 1 one could argue that an increase in tuition fees would allow institutions to be better equipped\nc2 those who study later decide this early on, anyway\nc3 to oblige non-academics to ﬁnance others’ degrees through taxes is not just\nc4 unfortunately sponsoring can lead to disagreeable dependencies in some cases\nPro p 1 education and training are fundamental rights which the state, the society must provide\np2 education must not be a question of money in a wealthy society such as Germany\np3 fees result in longer durations of studies\np4 funding-wise it ought to be considered how costs incurred by students from other (federal) states can be\nreimbursed\np5 if a university lacks the funds, sponsors must be found\np6 longer durations of studies are costly\np7 studying and taking higher degrees must remain a basic right for everyone\np8 there are other instruments to motivate tighter discipline while studying\np9 this would impede or prevent access to those who are ﬁnancially weaker\np10 this would mean that only those people with wealthy parents or a previous education and a part-time job\nwhile studying would be able to apply for a degree programme in the ﬁrst place\np11 universities are for all citizens, independent of their ﬁnances\np12 what is the good of a wonderfully outﬁtted university if it doesn’t actually allow the majority of clever people\nto broaden their horizons with all that great equipment\nTopic Should all universities in Germany charge tuition fees? Stance Con\nTable 1: The candidate thesis, con, and pro units for one topic-stance pair in the dataset of Wachsmuth et al. (2018).\nSome other approaches have been proposed that\nrecompose existing text segments in new argu-\nments. In particular, Bilu and Slonim (2016) gener-\nated new claims by “recycling” topics and pred-\nicates that were found in a database of claims.\nClaim selection involves preferring predicates that\nare generally amenable to claim units and that are\nrelevant for the target topic. Egan et al. (2016)\ncreated summaries of the main points in a debate,\nand Reisert et al. (2015) synthesized complete argu-\nments from a set of manually curated topic-stance\nrelations based on the ﬁne-grained argument model\nof Toulmin (1958). However, we are not aware\nof any approach that synthesizes arguments fully\nautomatically, let alone that follows rhetorical con-\nsiderations in the synthesis process.\n3 Data\nTo develop our model for argumentation synthe-\nsis, we exploit the dataset recently developed by\nWachsmuth et al. (2018). The dataset comprises\n260 manually generated argumentative texts. The\ngeneration of each text, for one topic-stance pair,\nhas been conducted in a systematic fashion follow-\ning the three canons of rhetoric (Aristotle, 2007):\n1. Inventio ∼Selecting a subset of argumentative\ndiscourse units (ADUs) from a pool of given\nADUs for a topic-stance pair.\n2. Dispositio ∼Arranging the selected ADUs in\na sequential order.\n3. Elocutio ∼Phrasing the arranged ADUs by\nadding connectives at unit-initial or unit-ﬁnal\npositions.\nSpeciﬁcally, Wachsmuth et al. (2018) selected\na pool of 200 ADUs for 10 pairs of controversial\ntopic and stance from the English version of the\narg-microtexts corpus (Peldszus and Stede, 2016).\nAs a preprocessing step, they “decontextualized”\nthese ADUs manually by removing connectives,\nresolving pronouns, and similar. Each topic-stance\npair comes with 20 such ADUs: four theses, four\ncon units, and 12 pro units. Table 1 shows the ADU\nlist for one topic-stance pair.\n26 participants were asked by Wachsmuth et al.\n(2018) to create short argumentative texts for each\ntopic-stance pair following one of two basic rhetor-\nical strategies: (1) logos-oriented, i.e., arguing log-\nically, and (2) pathos-oriented, i.e., arguing based\non emotional appeals. For each topic-stance pair\nthey created an argument by selecting one the-\nsis, one con and three pro units that they thought\ncould best form a persuasive argument following\nthe given strategies. Table 2 shows two samples of\ngenerated arguments in the dataset.\nThe dataset contains 130 logos-oriented and 130\n57\nStrategy ID Text Manually Synthesized From Five Argumentative Discourse Units\nLogos-oriented c 1 one could argue that an increase in tuition fees would allow institutions to be better equipped,\nt1 however German universities should on no account charge tuition fees.\np1 education and training are fundamental rights which the state, the society must provide,\np12 because what is the good of a wonderfully outﬁtted university if it doesn’t actually allow the majority\nof clever people to broaden their horizons with all that great equipment.\np4 Besides, funding-wise it ought to be considered how costs incurred by students from other (federal)\nstates can be reimbursed.\nPathos-oriented p 1 education and training are fundamental rights which the state, the society must provide.\nt2 This is why the universities in Germany should not under any circumstances charge tuition fees.\nc1 one could argue that an increase in tuition fees would allow institutions to be better equipped,\np3 however fees result in longer durations of studies\np6 and longer durations of studies are costly.\nTable 2: two sample arguments manually synthesized from the ADUs in Table 1, which are included in the dataset\nof Wachsmuth et al. (2018). The italiced connectives were added by the participants; they arenot part of the ADUs.\npathos-oriented argumentative texts. We use these\n260 texts to develop and evaluate our computational\nmodel for argumentation synthesis.\n4 Approach\nThis section presents our computational approach\nto synthesize arguments for any pair of topic and\nstance, following one of two basic rhetorical strate-\ngies: arguing logically (logos-oriented) or arguing\nemotionally (pathos-oriented). A black-box view\nof the approach is shown in Figure 1.\nAs input, our approach takes a strategy as well\nas a pool of argumentative discourse units (ADUs)\nfor any speciﬁc topic-stance pair x. Each ADU has\nthe role of a thesis (in terms of claim with a stance\non the topic), a con point (objecting the thesis), or\na pro point (supporting the thesis). The approach\nthen imitates the human selection, arrangement,\nand “phrasing” of a sequence ofn ADUs, in order\nto synthesize an argument. Phrasing is done only in\nterms of picking semantically coherent ADUs for\nthe arranged sequence; the addition of connectives\nbetween ADUs is left to future work.\nBelow, we detail how we realize each step (se-\nlection, arrangement, and phrasing) with a topic-\nindependent model. For each step, we explain how\nit is trained (illustrated in Figure 2) and how it is\napplied to an unseen topic-stance pair (Figure 3).\n4.1 Selection Language Model\nThis model handles the selection of a set ofn ADUs\nfor a topic-stance pair x and a rhetorical strategy.\nWe approach the selection as a language modeling\ntask where each ADU is a “word” of our language\nmodel and each argument a “sentence”. To abstract\nfrom topic, the model actually selects ADU types,\nas explained in the following.\nArgumentation synthesis\nThex,3 Prox,4 Prox,2 Prox,5Conx,1\nInput Thex,1\nThex,t\n...\nConx,1\nConx,c\nProx,1\nProx,p\nPool of\nADUs\n...\n...Rhetorical\nstrategy\nOutput Strategy-specific arg’\nLogos\nor\nPathos\nFigure 1: Black-box view of our argumentation synthe-\nsis approach. The input is a rhetorical strategy as well\nas a pool of thesis, con, and pro ADUs for some topic-\nstance pair x. The approach outputs a strategy-speciﬁc\nsequence of n ADUs as an argument forx (here, n= 5).\n4.1.1 Training of the Model\nWe start from a training set of ADUs for a set of\nm topic-stance pairs. To generalize the language\nmodel beyond the covered topics, each ADU is rep-\nresented using features that aim to capture general\nemotion-related and logic-related characteristics,\naccounting for the two given strategies.\nIn particular, we ﬁrst cluster the pool of all train-\ning ADUs based on their feature representation. As\na result, each ADU is represented by a cluster label\n(A–F in Figure 2), where each label represents one\nADU type. Now, for each of the strategies, we map\neach manually-generated sequence of ADUs to a\nsequence of cluster labels. Using these sequences\nof labels, we train one separated selection language\nmodel for each strategy.\nFor clustering, we rely on topic-independent fea-\ntures that we expect to implicitly encode logical\nand emotional strategies: (1) psychological mean-\ningfulness (Pennebaker et al., 2015), (2) eight basic\nemotions (Plutchik, 1980; Mohammad and Turney,\n2013), and (3) argumentativeness (Somasundaran\net al., 2007). In the following, we elaborate on the\nconcrete features that we extract:\n58\n→\n1. Selection Language Model\n→\n2. Arrangement Language Model\n→\n3. Phrasing Regression Model\n1-grams P(A) = 0.30\n2-grams\nP(F) = 0.25...\nP(A | A) = 0.00 P(F | A) = 0.13...\nP(A | F) = 0.13 P(F | F) = 0.06...\n…\n...\n...\n1-grams\n2-grams\n…\nP(   ) = 0.20 P(   ) = 0.60...\nP(   |   ) = 0.00 P(   |   ) = 0.06...\nP(   |   ) = 0.19 P(   |   ) = 0.38...\n...\n...\n1-grams\n2-grams\n…\n→ 0.12 Pron,1 → 0.02...\nPro1,2The1,2\nThe1,2\n→ 0.04 ... ...\nPron,1Conn,8 → 0.07\nThe1,2 Pro1,2 Pro1,6 Pro1,7 Con1,2 The1,3Pro1,1 Pro1,6 Pro1,2Con1,2...\nThen,4Pron,2 Pron,1 Pron,3 Conn,2Conn,2 Pron,8 Pron,1Then,2 Pron,7...\nTopic+stance 1\nTopic+stance m\n…\nArgument corpus\nArgumentm,1 Argumentm,j\nArgument1,1 Argument1,i\nADU clustering\nB\nA\nC D\nEF\n... ...\nFigure 2: Illustration of training the three models of our argumentation synthesis approach. The input is a corpus of\nargumentative texts for m topic-stance pairs, each decomposed into a sequence of theses, con units, and pro units.\nInitially, the set of all these ADUs is clustered to obtain a set topic-independent ADU types, called A–F here.\n(1) Selection language model: Each argument is converted from a sequence of ADUs to a sequence of ADU types,\nwhere a language model is trained on these type sequences. (2) Arrangement language model: Each argument is\nconverted from a sequence of ADUs to a sequence of ADU roles (thesis, pro, and con) where a language model is\ntrained on these ADU role sequences. (3) Phrasing regression model: A linear regression model is trained which\nscores each ADU sequence with respect to its semantic coherence.\nLinguistic Inquiry and Word Count (LIWC)\nLIWC is a lexicon-based text analysis that counts\nwords in psychologically meaningful categories\n(Tausczik and Pennebaker, 2010). We use the ver-\nsion by Pennebaker et al. (2015), which contains\nthe following 15 dimensions:\n1. Language metrics, e.g., words per sentence.\n2. Function words, e.g., pronouns and auxiliary\nverbs.\n3. Other grammar, e.g., common verbs and com-\nparisons.\n4. Affect words, e.g., positive emotion words.\n5. Social words, e.g., “family” and “friends”.\n6. Cognitive processes, e.g., “discrepancies” and\n“certainty”.\n7. Perceptual processes, e.g., “feeling”.\n8. Biological processes, e.g., “health”.\n9. Core drives and needs, e.g., “power” and “re-\nward focused”.\n10. Time orientation, e.g., past-focused.\n11. Relativity, e.g., “time” and “space”.\n12. Personal concerns, e.g., “work” and “leisure”.\n13. Informal speech, e.g., ﬁllers and nonﬂuencies.\n14. Punctuation, e.g., periods and commas.\n15. Summary variables, as detailed below.\nThere are four summary variables, each of which\nis derived from various LIWC dimensions: (1) an-\nalytical thinking (Pennebaker et al., 2014), i.e., the\ndegree to which people use narrative language (low\nvalue), or more logical and formal language (high);\n(2) clout (Kacewicz et al., 2014), i.e., the relative\nsocial status, conﬁdence, and leadership displayed\nin a text; (3) authenticity (Newman et al., 2003),\ni.e., the degree to which people reveal themselves\nin an authentic way; and (4) emotional tone (Cohn\net al., 2004), i.e., negative for values lower than 50\nand positive otherwise.\nNRC Emotional and Sentiment Lexicons We\nuse the NRC lexicon of Mohammad and Turney\n(2013). The lexicon has been compiled manually\nusing crowdsourcing and contains a set of English\nwords and their associations with (1)sentiment, i.e.,\nnegative and positive polarities, and (2)emotions,\ni.e., the eight basic emotions deﬁned by Plutchik\n(1980): anger, anticipation, disgust, fear, joy, sur-\nprise, sadness, and trust. These features are repre-\nsented as the count of words associated with each\ncategory (e.g., the count of sad words in an ADU).\nMPQA Arguing Lexicon Somasundaran et al.\n(2007) constructed a lexicon that includes the fol-\nlowing arguing patterns: assessments, doubt, au-\nthority, emphasis, necessity, causation, generaliza-\ntion, structure, conditionals, inconsistency, possi-\nbility, wants, contrast, priority, difﬁculty, inyour-\n59\nThex,1\nThex,2\nThex,3\nThex,t\n...\npredict\nA\nA\nC\nE\nConx,1\nConx,2\nConx,3\nConx,c\n...\npredict\nD\nB\nA\nC\nProx,1\nProx,2\nProx,3\nProx,p ...\npredict\nB\nC\nC\nD\nRhetorical strategy + ADUs of topic-stance pair xInput\n1. Selection Language Model\nmore probable\nA B C D C\nA B C D C\nA B C D C\nThex,3Prox,1 Prox,pProx,3Conx,3\nThex,1 Prox,2 Prox,3Prox,pConx,2\nThex,2 Prox,2 Prox,3Prox,pConx,2\n2. Arrangement Language Model\ngenerate Candidate arguments\nmore probable\ngenerate\n......\nThex,1 Prox,2 Prox,3Prox,pConx,2\nThex,2 Prox,2 Prox,3Prox,pConx,2\n3. Phrasing Regression Model\nFiltered candidates\nhigher score\npredict\nThex,1 Prox,2 Prox,3Prox,pConx,2\nThex,2 Prox,2 Prox,3Prox,pConx,2 Thex,2 Prox,2 Prox,3Prox,pConx,2\nOutput\nLogos\nor\nPathos\nFigure 3: Illustration of applying our synthesis ap-\nproach. Given the predicted type of each input ADU\nof the given topic-stance pair x, (1) the selection gener-\nates the most probable type sequence, (A, B, C, D, C).\nFrom the type sequence, a set of candidate arguments\nis decoded. (2) The arrangement ﬁlters out candidates\nnot matching the most probable ADU role sequence,\n(Thesis, Con, Pro, Pro, Pro). (3) Phrasing scores\neach remaining argument and outputs the top argument.\nshoes, rhetorical question. We use the count of\neach arguing pattern in text as one feature (e.g.,\nnumber of assessments patterns in an ADU).\n4.1.2 Application of the Model\nAs shown in Figure 3, the selection language model\ntakes the ADUs of an unseen topic-stance x as\ninput. It then outputs a set of candidate arguments,\nin terms of sequences of ADUs. Each ADU is\nencoded into a cluster label (representing an ADU\ntype). For example, one might have the following\nmappings, given the six labels A–F from Figure 2:\nA ←{Thex,1, Thex,2, Conx,3}\nB ←{Conx,2, Prox,1}\nC ←{Thex,3, Conx,c, Prox,2, Prox,3}\nD ←{Pro x,p, Conx,1}\nE ←{Thex,t}\nF ←{Thex,4, Conx,4, Prox,4}\nThe language model for either of the two rhetor-\nical strategies generates a set of arguments where\neach argument is composed of n cluster labels, e.g.,\n(A, B, C, D, C) for n = 5in Figure 3. This set is\nranked by probability of the associated sequence.\nFor example, assume that (A, B, C, D, C) is most\nprobable. Then we decode all possible ADU se-\nquences for topic-stance x from (A, B, C, D, C)\nto a set of candidate arguments:\n(A, B, C, D, C) →\n{Thex,1, Thex,2, Conx,3}\n×{Conx,2, Prox,1}\n×{Thex,3, Conx,c, Prox,2, Prox,3}\n×{Pro x,p, Conx,1}\n×{Thex,3, Conx,c, Prox,2, Prox,3}\nThe output of the model is a set of candidate\narguments, which becomes the input of the arrange-\nment language model.\n4.2 Arrangement Language Model\nIn the arrangement process, we aim to imitate the\nhuman behavior of arranging ADUs for a speciﬁc\ntopic-stance following a rhetorical strategy (here,\nlogos or pathos). Again, we approach this problem\nas a language modeling task. Each ADU role (the-\nsis, pro, or con) is a word of the language model\nand each argument a sentence.\n4.2.1 Training of the Model\nAs sketched in Figure 2, we ﬁrst convert the human-\ngenerated arguments from a sequence of ADUs to\na sequence of ADU roles. Then, we use these se-\nquences to train a language model for each strategy.\n4.2.2 Application of the Model\nAs shown in Figure 3, the arrangement language\nmodel takes as input the candidate arguments that\nwe get from the selection language model and out-\nputs a set of ﬁltered candidate arguments.\nThe language model for a speciﬁc strategy gen-\nerates a set of argument structures where each\nsuch structure is a sequence of n ADU roles, e.g.,\n(Thesis, Con, Pro, Pro, Pro) for n = 5 in Fig-\nure 3. This set is ranked by the probability of the\nsequences. For example, assume that the most fre-\nquent sequence is (Thesis, Con, Pro, Pro, Pro).\n60\nUsing the output from the selection language\nmodel, we ﬁlter out all candidate arguments that do\nnot match (Thesis, Con, Pro, Pro, Pro), ending\nup with the following ﬁltered arguments:\n{Thex,1, Thex,2}×{Conx,2}\n×{Pro x,2, Prox,3}×{Pro x,p}\n×{Pro x,2, Prox,3}\nThe output of the model is a ﬁltered set of can-\ndidate arguments, which becomes the input of the\nphrasing regression model.\n4.3 Phrasing Regression Model\nThe set of arguments resulting from the selection\nand arrangement language models are based on\ntopic-independent features. The missing step is to\nentail the topical relationship between the ADUs\nin each generated argument. We approach this task\nwith supervised regression. As indicated above, our\nmodel does not really phrase an argument. Rather,\nit aims to choose the best among the given set of\ncandidates in terms of semantic coherence.\n4.3.1 Training of the Model\nFor each argument, we opt for a feature represen-\ntation that embeds the content properties of ADUs\nin order to capture their content relationship. Con-\ncretely, we represent each argument by calculating\nthe semantic similarities of each adjacent bigram\nin a human-generated argument. We train a linear\nregression model where each instance represents\nthe features of one argument. To this end, we set\na score to be the sum of the probabilities of ADU\nbigrams occurring in one argument.\nThe phrasing model scores each of the ﬁltered ar-\nguments given as output by the arrangement model.\nThe argument with the highest score is the ﬁnal\ngenerated argument.\n4.3.2 Application of the Model\nAt this point, the phrasing model is provided by\nthe ﬁltered arguments from the arrangement model.\nFor each ﬁltered argument, we extract the bigram\nfeatures (semantic similarities). Next, using the\nphrasing model, we predict the score of each se-\nquence. The sequence with the highest score is the\ngenerated argument. In Figure 3, this is:\n(Thex,2, Conx,2, Prox,2, Prox,p, Prox,3)\n5 Experiments\nIn this section, we report the results of evaluating\nthe introduced approach to argumentation synthesis\nStrategy 2-grams 3-grams\nLogos-oriented 9,110.6 9,466.3\nPathos-oriented 7,939.5 10,279.6\nTable 3: Selection. Perplexity of the 2-gram and 3-\ngram language models for each strategy, averaged over\n10 leave-one-topic-out runs using Laplace smoothing.\nbased on the dataset described in Section 3.\n5.1 Experimental Set-up\nOur experiments are designed in leave-one-topic-\nout cross-validation setting: From the 10 topic-\nstance pairs in the dataset, we use nine for training\nand the last as the test fold, and we repeat this once\nfor each possible fold. This way, no topic-speciﬁc\nknowledge can be used in the synthesis process.\nFor each given basic rhetorical strategy (logos-\noriented and pathos-oriented), we train one model\neach for the selection, the arrangement, and the\n“phrasing” of argumentative discourse units (ADUs)\non the nine training folds. The arguments syn-\nthesized by their combination are then evaluated\nagainst the human-generated arguments in the test\nfolds. The evaluation covers all three models as\nwell as the ﬁnal generated argument for each strat-\negy. We report the average accuracy across all ten\nfolds for each of the models.\n5.2 Training: Selection Language Model\nIn each training/test experiment for one of the two\nstrategies, we ﬁrst abstract all ADUs across all\nstrategy-speciﬁc topic-stance pairs by extracting\nthe LIWC, NRC, and MPQA features, as described\nin Section 4.1. Then, we cluster the given training\nset using standard k-means (Ostrovsky et al., 2012).\nAfter some initial experiments, we decide to set k\nto 6, because this best balanced the distribution of\narguments over clusters, and showed clear strategy-\nspeciﬁc differences.3 Using the resulting clustering\nmodel, we predicted the type A–F of each ADU in\nthe test set (the tenth topic).\nGiven the ADU types, we next converted the\nhuman-generated training and test arguments from\na sequence of ADUs to a sequence of ADU types.\nAfter that, we trained one 2-gram and one 3-gram\nselection language.4 In Table 3, we report the mean\nperplexity of the models for both strategies.\n3A more thorough evaluation of k is left to future work.\n4We did not consider 1-grams, because arguments are in-\nherently relational, hence requiring at least two ADUs.\n61\nStrategy 2-grams 3-grams\nLogos 54.5 33.5\nPathos 45.9 23.9\nTable 4: Arrangement. Perplexity of the 2-gram and 3-\ngram language models for each strategy, averaged over\n10 leave-one-topic-out runs using Laplace smoothing.\nAs shown, the 2-gram perplexity is lower than\nthe 3-gram perplexity in both cases. We assume\nthat the reason lies in the limited size of the dataset\nand the narrow setting: Only 117 sentences (ADUs)\nare given per strategy for training, with a vocabu-\nlary size of 6 (number of ADU types). Based on\nthe results, we decided to use the 2-gram selection\nlanguage model to generate candidate arguments.\n5.3 Training: Arrangement Language Model\nTo train arrangement as described in Section 4.2,\nwe took all arguments of the nine training topics\nin each experiment. We converted each argument\nfrom a sequence of ADUs to a sequence of ADU\nroles (thesis, pro, and con). After that, we trained a\n2-gram and 3-gram language model for each strat-\negy. Table 4 lists the mean perplexity values over\nthe 10 folds.\nHere, the perplexity is lower for 3-grams than for\n2-grams, which can be expected to yield better per-\nformance. Therefore, we used the 3-gram language\nmodel to ﬁlter the set of candidate arguments.\n5.4 Training: Phrasing Regression Model\nFor phrasing (in terms of choosing the best ADU\nsequence), we ﬁrst extracted features from each\ncandidate, as described in Section 4.3. Then, we\ncalculated the semantic similarities between each\npair of adjacent ADUs as follows:\n1. We obtained a 300-dimensional word embed-\nding for each word in an ADU using the\npre-trained GloVe common-crawl model (Pen-\nnington et al., 2014).5\n2. We averaged the embeddings of all words in\nan ADU, resulted in one vector representing\nthe ADU.\n3. For each adjacent pair of ADUs, we computed\nthe cosine similarity of their vectors.\nFigure 4 shows a histogram of the distribution\nof the cosine similarities of each adjacent pair of\n5The used model can be found here: http://nlp.\nstanford.edu/data/glove.42B.300d.zip.\nPathos Logos\n0.75 0.8 0.85 0.9 0.95\n2\n4\n6\n8\n10\n12\nCosine similarity\nFigure 4: Histogram of the cosine similarity of the av-\nerage word embeddings of adjacent pairs of ADUs in\nlogos-oriented and in pathos-oriented arguments.\nADUs (i.e., each ADU 2-gram) in logos-oriented ar-\nguments and in pathos-oriented arguments. We ob-\nserve a generally high similarity between neighbor-\ning ADUs for both strategies, with logos-oriented\n2-grams being slightly more similar on average.\nGiven the ADU 2-grams, we train a linear regres-\nsion model that predicts the sum of ADU 2-gram\nprobabilities in each argument. In case of the logos\nstrategy, the model has a mean squared error (MSE)\nof 0.05. In case of pathos the MSE is 0.03.\n5.5 Results: Argumentation Synthesis\nUp to this point, we trained all selection, arrange-\nment, and phrasing models 10 times. Combining\nthe three models for each strategy, we ﬁnally gener-\nated one argument per strategy for the topic-stance\npair left out in each experiments. Hence, we ended\nup with 10 computationally synthesized arguments\nper strategy in total.\nWe evaluate each of these arguments by check-\ning whether it matches any of the 13 human-\ngenerated ground-truth arguments given per topic-\nstance pair. The matching is quantiﬁed in terms of\nn-gram overlap with n = {1, . . . ,5}.\nFor comparison, we consider a baseline that ran-\ndomly generates arguments for each topic-stance\npair as follows:\n1. Select a random thesis unit from t 1 to t4.\n2. Select a random con unit from c 1 to c4.\n3. Select three random pro units from p 1 to p12.\n4. Randomly arrange the selected units.\nTable 5 presents the accuracy of n-gram over-\nlaps between each of the 13 human-generated argu-\nments per topic-stance pair and the arguments com-\nputationally synthesized arguments by our model\n62\nSequential Non-Sequential\nStrategy Approach 1-gram 2-gram 3-gram 4-gram 5-gram 1-gram 2-gram 3-gram 4-gram 5-gram\nLogos Our model 80.0% 15.0% 0.0% 0.0% 0.0% 80.0% 39.0% 9.0% 0.0% 0.0%\nBaseline 76.0% 10.0% 0.7% 0.0% 0.0% 76.0% 3.1% 8.8% 2.0% 0.0%\nPathos Our model 88.0% 20.0% 0.0% 0.0% 0.0% 88.0% 48.0% 17.0% 4.0% 0.0%\nBaseline 82.0% 11.5% 0.7% 0.0% 0.0% 82.0% 38.9% 10.7% 1.6% 0.0%\nTable 5: Accuracy ofn-gram overlaps between the human-generated arguments for each strategy and the arguments\ncomputationally synthesized by our model and the baseline. In the sequential case, the ordering is considered, in\nthe non-sequential case, it is ignored. The better result in each experiment is marked bold, if any.\nStrategy ID Argument Computationally Synthesized from Five Argumentative Discourse Units\nLogos t 4 universities should not charge tuition fees in Germany.\nc3 to oblige non-academics to ﬁnance others’ degrees through taxes is not just.\np9 this would impede or prevent access to those who are ﬁnancially weaker.\np5 if a university lacks the funds, sponsors must be found.\np8 there are other instruments to motivate tighter discipline while studying.\nPathos p 2 education must not be a question of money in a wealthy society such as Germany.\nc1 one could argue that an increase in tuition fees would allow institutions to be better equipped.\np7 studying and taking higher degrees must remain a basic right for everyone.\np6 longer durations of studies are costly.\nt2 the universities in Germany should not under any circumstances charge tuition fees.\nTable 6: Comparison of two con arguments computationally synthesized with our model for the topic Should all\nuniversities in Germany charge tuition fees? , each being a sequence of ﬁve ADUs. A logos-oriented argument\n(t4, c3, p9, p5, p8) and a pathos-oriented argument (p2, c1, p7, p6, t2). The thesis of each argument is marked bold.\nand by the baseline, with and without considering\nthe ordering of ADUs. Our models outperform the\nbaseline for 1-grams and 2-grams in all cases. For\nsequential 3-grams, however, it did not achieve any\noverlap with the human-generated arguments for ei-\nther strategy. This may be explained by the fact that\nthe employed selection and phrasing models are\nbased on 2-grams only. For n ≥2, the synthesis\ngenerally does not work well anymore. We believe\nthat the small data size is a main cause behind this,\nalthough it may also point to the limitation of com-\nposing ADUs based on surface features. In the\nnon-sequential case, though, our model performs\ncomparably well for 3-grams, and it even manages\nto correctly synthesize some ADU 4-grams.\nIn Table 6, we exemplify the top-scored argu-\nments for one topic-stance pair, synthesized by\nour approach for logos and for pathos respectively.\nThey indicate that our model was able to learn\nstrategy-speciﬁc differences. 6 In particular, the\nlogos argument starts with the thesis (t2), as argu-\nmentation guidelines suggest. It then reasons based\non consequences and alternatives. Matching intu-\n6Notice that the coherence of the arguments may be opti-\nmized by inserting discourse markers, such as a “but” before\np7 in the pathos argument. As stated above, however, this is\nbeyond the scope of the paper at hand.\nition, the pathos argument appeals more to emotion,\nreﬂected in phrases such as “wealthy society\" and\n“under any circumstances”. Particularly the thesis\n(t4) has a more intense tonality than t2, and putting\nit at the end creates additional emphasis.\n6 Conclusion\nThis paper has presented a topic-independent com-\nputational approach to imitate the process of se-\nlecting, arranging, and phrasing argumentative dis-\ncourse units (ADUs) — so to speak, to synthesize\narguments. We have proposed to operationalize\nthe necessary synthesis knowledge in the form of a\ncombined language and regression model that pre-\ndicts ADU sequences. So far, we have evaluated\nour approach on a small dataset only that contains\n260 argumentative texts following either of two\nrhetorical strategies. For a controlled experiment\nsetting based on this data, we have reported prelim-\ninary results of medium effectiveness regarding the\nimitation of human-generated arguments.\nA big challenge for the future is to move from\nsuch a controlled setting to a real-world scenario,\nwhere arguments have to be formed for a freely-\nchosen topic from material that is mined from the\nweb. Still, our topic-independent approach deﬁnes\na ﬁrst substantial step in this direction.\n63\nReferences\nAristotle. 2007. On Rhetoric: A Theory of Civic Dis-\ncourse (George A. Kennedy, Translator). Clarendon\nAristotle series. Oxford University Press.\nYonatan Bilu and Noam Slonim. 2016. Claim synthe-\nsis via predicate recycling. In Proceedings of the\n54th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 2: Short Papers), pages\n525–530. Association for Computational Linguis-\ntics.\nGiuseppe Carenini and Johanna D. Moore. 2006. Gen-\nerating and evaluating evaluative arguments. Artiﬁ-\ncial Intelligence, 170(11):925–952.\nOana Cocarascu and Francesca Toni. 2017. Identify-\ning attack and support argumentative relations us-\ning deep learning. In Proceedings of the 2017 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 1374–1379. Association for Com-\nputational Linguistics.\nMichael A Cohn, Matthias R Mehl, and James W Pen-\nnebaker. 2004. Linguistic markers of psychological\nchange surrounding September 11, 2001. Psycho-\nlogical science, 15(10):687–693.\nCharlie Egan, Advaith Siddharthan, and Adam Wyner.\n2016. Summarising the points made in online po-\nlitical debates. In Proceedings of the Third Work-\nshop on Argument Mining (ArgMining2016) , pages\n134–143, Berlin, Germany. Association for Compu-\ntational Linguistics.\nH. Paul Grice. 1975. Logic and conversation. In Peter\nCole and Jerry L. Morgan, editors, Syntax and Se-\nmantics, Vol. 3, pages 41–58. Academic Press, New\nYork.\nIvan Habernal and Iryna Gurevych. 2016. Which ar-\ngument is more convincing? Analyzing and predict-\ning convincingness of web arguments using bidirec-\ntional LSTM. In Proceedings of the 54th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1589–1599.\nAssociation for Computational Linguistics.\nAri Holtzman, Jan Buys, Maxwell Forbes, Antoine\nBosselut, David Golub, and Yejin Choi. 2018.\nLearning to write with cooperative discriminators.\nTechnical Report 1805.06087, arXiv.\nXinyu Hua and Lu Wang. 2018. Neural argument\ngeneration augmented with externally retrieved evi-\ndence. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 219–230. Association\nfor Computational Linguistics.\nEwa Kacewicz, James W Pennebaker, Matthew Davis,\nMoongee Jeon, and Arthur C Graesser. 2014.\nPronoun use reﬂects standings in social hierar-\nchies. Journal of Language and Social Psychology ,\n33(2):125–143.\nDieu Thu Le, Cam-Tu Nguyen, and Kim Anh Nguyen.\n2018. Dave the debater: a retrieval-based and gen-\nerative argumentative dialogue agent. In Proceed-\nings of the 5th Workshop on Argument Mining, pages\n121–130, Brussels, Belgium. Association for Com-\nputational Linguistics.\nSaif M Mohammad and Peter D Turney. 2013. Crowd-\nsourcing a word–emotion association lexicon. Com-\nputational Intelligence, 29(3):436–465.\nMatthew L Newman, James W Pennebaker, Diane S\nBerry, and Jane M Richards. 2003. Lying words:\nPredicting deception from linguistic styles. Person-\nality and social psychology bulletin, 29(5):665–675.\nRafail Ostrovsky, Yuval Rabani, Leonard J Schulman,\nand Chaitanya Swamy. 2012. The effectiveness of\nlloyd-type methods for the k-means problem. Jour-\nnal of the ACM (JACM), 59(6):28.\nAndreas Peldszus and Manfred Stede. 2016. An anno-\ntated corpus of argumentative microtexts. In Argu-\nmentation and Reasoned Action: 1st European Con-\nference on Argumentation (ECA 16). College Publi-\ncations.\nJames W Pennebaker, Ryan L Boyd, Kayla Jordan, and\nKate Blackburn. 2015. The Development and Psy-\nchometric Properties of LIWC2015.\nJames W Pennebaker, Cindy K Chung, Joey Frazee,\nGary M Lavergne, and David I Beaver. 2014.\nWhen small words foretell academic success: The\ncase of college admissions essays. PloS one ,\n9(12):e115844.\nJeffrey Pennington, Richard Socher, and Christopher D.\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 1532–1543.\nRobert Plutchik. 1980. A general psychoevolutionary\ntheory of emotion. In Theories of emotion , pages\n3–33. Elsevier.\nPaul Reisert, Naoya Inoue, Naoaki Okazaki, and Ken-\ntaro Inui. 2015. A computational approach for gen-\nerating Toulmin model argumentation. In Proceed-\nings of the 2nd Workshop on Argumentation Mining,\npages 45–55. Association for Computational Lin-\nguistics.\nMisa Sato, Kohsuke Yanai, Toshinori Miyoshi, Toshi-\nhiko Yanase, Makoto Iwayama, Qinghua Sun, and\nYoshiki Niwa. 2015. End-to-end argument genera-\ntion system in debating. In Proc. ACL-IJCNLP 2015\nSystem Demonstrations.\nSwapna Somasundaran, Josef Ruppenhofer, and Janyce\nWiebe. 2007. Detecting arguing and sentiment in\nmeetings. In Proceedings of the SIGdial Workshop\non Discourse and Dialogue, volume 6.\n64\nChristian Stab and Iryna Gurevych. 2014. Identifying\nargumentative discourse structures in persuasive es-\nsays. In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 46–56. Association for Computa-\ntional Linguistics.\nYla R Tausczik and James W Pennebaker. 2010. The\npsychological meaning of words: LIWC and com-\nputerized text analysis methods. Journal of lan-\nguage and social psychology, 29(1):24–54.\nStephen E. Toulmin. 1958. The Uses of Argument .\nCambridge University Press.\nHenning Wachsmuth, Manfred Stede, Roxanne El Baff,\nKhalid Al Khatib, Maria Skeppstedt, and Benno\nStein. 2018. Argumentation synthesis following\nrhetorical strategies. In Proceedings of COLING\n2018, the 27th International Conference on Compu-\ntational Linguistics. The COLING 2018 Organizing\nCommittee. To appear.\nLu Wang and Wang Ling. 2016. Neural network-based\nabstract generation for opinions and arguments. In\nProceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 47–57. Association for Computational Lin-\nguistics.\nToshihiko Yanase, Toshinori Miyoshi, Kohsuke Yanai,\nMisa Sato, Makoto Iwayama, Yoshiki Niwa, Paul\nReisert, and Kentaro Inui. 2015. Learning sentence\nordering for opinion generation of debate. In Pro-\nceedings of the 2nd Workshop on Argumentation\nMining, pages 94–103. Association for Computa-\ntional Linguistics.\nIngrid Zukerman, Richard McConachy, and Kevin B.\nKorb. 2000. Using argumentation strategies in au-\ntomated argument generation. In First International\nConference on Natural Language Generation (INLG\n00), pages 55–62.",
  "topic": "Argumentative",
  "concepts": [
    {
      "name": "Argumentative",
      "score": 0.9718822836875916
    },
    {
      "name": "Argumentation theory",
      "score": 0.893948495388031
    },
    {
      "name": "Rhetorical question",
      "score": 0.7806721329689026
    },
    {
      "name": "Computer science",
      "score": 0.7752792835235596
    },
    {
      "name": "Argument (complex analysis)",
      "score": 0.7333518862724304
    },
    {
      "name": "Natural language processing",
      "score": 0.5631766319274902
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5623928904533386
    },
    {
      "name": "Task (project management)",
      "score": 0.46266746520996094
    },
    {
      "name": "Pathos",
      "score": 0.46082982420921326
    },
    {
      "name": "Logos Bible Software",
      "score": 0.42775362730026245
    },
    {
      "name": "Linguistics",
      "score": 0.3919999301433563
    },
    {
      "name": "Philosophy",
      "score": 0.11292043328285217
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ]
}