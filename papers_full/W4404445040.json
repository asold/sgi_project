{
  "title": "NarrativeGenie: Generating Narrative Beats and Dynamic Storytelling with Large Language Models",
  "url": "https://openalex.org/W4404445040",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2639121613",
      "name": "Vikram Kumaran",
      "affiliations": [
        "North Carolina State University"
      ]
    },
    {
      "id": "https://openalex.org/A2104780850",
      "name": "Jonathan Rowe",
      "affiliations": [
        "North Carolina State University"
      ]
    },
    {
      "id": "https://openalex.org/A2128592643",
      "name": "James Lester",
      "affiliations": [
        "North Carolina State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3093524609",
    "https://openalex.org/W2972244901",
    "https://openalex.org/W4225012671",
    "https://openalex.org/W4378510404",
    "https://openalex.org/W4306759153",
    "https://openalex.org/W3164562127",
    "https://openalex.org/W4387394725",
    "https://openalex.org/W6855737792",
    "https://openalex.org/W6682631176",
    "https://openalex.org/W3212560870",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W2538192737",
    "https://openalex.org/W4298187623",
    "https://openalex.org/W2984803355",
    "https://openalex.org/W6755316025",
    "https://openalex.org/W4312941580",
    "https://openalex.org/W6865474770",
    "https://openalex.org/W3162324357",
    "https://openalex.org/W2115451979",
    "https://openalex.org/W3021347125",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W1561304027",
    "https://openalex.org/W6685125084",
    "https://openalex.org/W2902539999",
    "https://openalex.org/W4392539761",
    "https://openalex.org/W2982451789",
    "https://openalex.org/W2900557941"
  ],
  "abstract": "Interactive narrative in games utilize a combination of dynamic adaptability and predefined story elements to support player agency and enhance player engagement. However, crafting such narratives requires significant manual authoring and coding effort to translate scripts to playable game levels. Advances in pretrained large language models (LLMs) have introduced the opportunity to procedurally generate narratives. This paper presents NarrativeGenie, a framework to generate narrative beats as a cohesive, partially ordered sequence of events that shapes narrative progressions from brief natural language instructions. By leveraging LLMs for reasoning and generation, NarrativeGenie, translates a designer’s story overview into a partially ordered event graph to enable player-driven narrative beat sequencing. Our findings indicate that NarrativeGenie can provide an easy and effective way for designers to generate an interactive game episode with narrative events that align with the intended story arc while at the same time granting players agency in their game experience. We extend our framework to dynamically direct the narrative flow by adapting real-time narrative interactions based on the current game state and player actions. Results demonstrate that NarrativeGenie generates narratives that are coherent and aligned with the designer’s vision.",
  "full_text": "NARRATIVE GENIE : Generating Narrative Beats and Dynamic Storytelling with\nLarge Language Models\nVikram Kumaran, Jonathan Rowe, James Lester\nNorth Carolina State University\n{vkumara, jprowe, lester}@ncsu.edu\nAbstract\nInteractive narrative in games utilize a combination of dy-\nnamic adaptability and predefined story elements to support\nplayer agency and enhance player engagement. However,\ncrafting such narratives requires significant manual authoring\nand coding effort to translate scripts to playable game lev-\nels. Advances in pretrained large language models (LLMs)\nhave introduced the opportunity to procedurally generate nar-\nratives. This paper presents NARRATIVE GENIE , a framework\nto generate narrative beats as a cohesive, partially ordered se-\nquence of events that shapes narrative progressions from brief\nnatural language instructions. By leveraging LLMs for rea-\nsoning and generation, N ARRATIVE GENIE , translates a de-\nsigner’s story overview into a partially ordered event graph\nto enable player-driven narrative beat sequencing. Our find-\nings indicate that NARRATIVE GENIE can provide an easy and\neffective way for designers to generate an interactive game\nepisode with narrative events that align with the intended\nstory arc while at the same time granting players agency in\ntheir game experience. We extend our framework to dynami-\ncally direct the narrative flow by adapting real-time narrative\ninteractions based on the current game state and player ac-\ntions. Results demonstrate that NARRATIVE GENIE generates\nnarratives that are coherent and aligned with the designer’s\nvision.\nIntroduction\nInteractive narrative has been integral to games since the\nadvent of “choose your path” text adventures (Crowther,\nWoods, and Black 1977; Koenitz 2023) to provide play-\ners with agency and engagement. Interactive narratives have\nplayed a significant role in entertainment and educational\ngames (Naul and Liu 2020; Koenitz 2023). Beyond manual\nauthorship, planning-based methods used to procedurally\ngenerate these games focused on coherent event sequences,\noften failing to produce engaging stories (Young et al. 2013;\nRamirez and Bulitko 2014; Porteous et al. 2021).The emer-\ngence of LLMs has revolutionized narrative content genera-\ntion. Recently, LLMs have been used to generate scenes with\nbranching dialogues for interactions between players and\nnon-player characters (NPCs) (Kumaran et al. 2023; Gao\nand Emami 2023; Akoury, Salz, and Iyyer 2023). However,\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nNPC interaction scenes that involve only clicking through\nlinear dialogue lack player agency and feel more like nar-\nrated stories. On the other hand, long narrative arcs pose\nchallenges due to the impracticality of predefining all out-\ncomes. Our research addresses these challenges by creat-\ning a framework that generates playable 3D Unity-based\ngame episodes that include player-triggered narrative beats\nand real-time narrative adaptations that respond to player\nchoices, thereby offering engaging, interactive narrative ex-\nperiences generated from natural language narrative arcs\nspecified by designers.\nCreating engaging game narratives has traditionally been\nresource-heavy and required significant expertise. Procedu-\nral content generation (PCG) has sought to ease this bur-\nden, though early planning-based methods mainly focused\non linking event sequences by meeting local conditions, pay-\ning less attention to the overall narrative structure (Young\net al. 2013; Ramirez and Bulitko 2014; Kreminski, Wardrip-\nFruin, and Mateas 2020). Recent advances in large lan-\nguage models (LLMs) have revolutionized narrative gener-\nation by offering internalized world knowledge, instruction-\nfollowing, and semantic event-tracking abilities (Guan et al.\n2023; OpenAI 2023). These models generate coherent dia-\nlogue, structured outputs, and transform high-level outlines\ninto interactive game scripts (Liu et al. 2023; Kumaran et al.\n2023).\nLanguage models have shown promise in co-creating dia-\nlogues, stories (Chung et al. 2022), and co-write screenplays\n(Mirowski et al. 2023). However, balancing the overall story\nwith player agency in interactive narratives is crucial (Riedl\nand Bulitko 2013). We address this with a narrative gener-\nation framework for designers to provide high-level story\nguidance in natural language and then translating it into a\npartially ordered event graph using LLM reasoning capabil-\nities. The events feature NPC interactions through dialogue,\nemotes, and gestures. Our framework also supports runtime\nadaptation of scenes based on player gameplay history to\nhandle the combinatorial expansion of possible paths due to\nplayer decisions.\nThe primary contributions of our framework, N ARRA -\nTIVE GENIE , are the following:\n• Simplifies and automates creating a 3D virtual interactive\nnarrative game from a natural language narrative arc.\n• The generated interactive narrative balances player\nProceedings of the Twentieth AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE2024)\n76\nFigure 1: The NARRATIVE GENIE interactive narrative generation framework.\nagency and narrative progression with limited out-of-\norder interaction.\n• The generated narrative allows player exploration and\nplayer-initiated NPC and game element interactions to\nprogress the narrative.\n• Adapts scenes dynamically to player choices during\ngameplay.\n• Demonstrates effectiveness, validated through both hu-\nman participant assessments and automated evaluations.\nRelated Work\nThe interactive narrative research community focuses on\ncrafting engaging storylines and immersive experiences\n(Riedl and Bulitko 2013; Riedl and Young 2010; Kreminski,\nWardrip-Fruin, and Mateas 2020; Stefnisson and Thue\n2018). Interactive narrative frameworks foster player en-\ngagement by allowing exploration to control the narrative’s\nprogression. One technique to blend player input with nar-\nrative progression is using experience managers, which dy-\nnamically revise narrative elements to maintain the overall\narc (Riedl and Bulitko 2013). Researchers often frame this\ntask as an automated planning problem to balance player\nactions with authorial goals (Ramirez and Bulitko 2014;\nRiedl and Young 2010). Another approach is representing\ninteractive narratives as story graphs, with story states con-\nnected through causal edges, allowing experience managers\nto track and control narrative progress (Riedl and Young\n2010). Techniques like pruning are used on these graphs to\ncontrol the story experience (Ware et al. 2022). Our frame-\nwork employs a story-graph paradigm in the generation pro-\ncess to represent the partial order and relationships between\nnarrative events. Our real-time adaptation of narrative inter-\nactions is generated by providing this graph and the player’s\ngameplay history as context to the language model.\nResearchers are exploring evolving stories through au-\ntonomous agents in a story world, followed by story sifting\nto identify compelling event patterns (Kreminski, Wardrip-\nFruin, and Mateas 2020). The synergy of human gameplay\nwith autonomous NPCs driven by LLMs has been used to\ncreate emergent narrative events in text-adventure games\n(Peng et al. 2024). Another approach involves players con-\ntrolling NPC goals through conversational actions (Oliver\nand Mateas 2021). AI is often used during the authoring\nphase, suggesting narrative ideas, next steps for characters,\nor their final objective based on the current story context\n(Stefnisson and Thue 2018; Akoury et al. 2020; Kreminski\net al. 2022; Martin, Harrison, and Riedl 2016).\nRecent research has shown the effectiveness of neural\nnetwork-based models in generating coherent narratives by\nlinking high-level plot points with narrative events (Rashkin\net al. 2020; Yao et al. 2019; Wang, Durrett, and Erk 2020).\nGenerating events first, followed by sentences, has been\nshown to enhance story coherence (Ammanabrolu et al.\n2020). Pre-trained language models have notably influenced\nnarrative generation. Calderwood et al. (2022) finetuned a\npre-trained language model on Twine stories to create a\nmixed-initiative tool for interactive stories. Author-provided\ncontrol codes have been used to blend human and language\nmodel creativity in story generation (Lin and Riedl 2021).\nProfessional writers have found these pre-trained models\nhelpful for co-writing screenplays (Mirowski et al. 2023).\nOur framework adopts a similar hierarchical approach using\nLLMs to translate a narrative arc into event graphs. Subse-\nquently, these events are translated into narrative interactions\nfor players in virtual environments.\nLLMs like OpenAI’s GPT have shown remarkable\nhuman-level potential in text generation, understanding nat-\nural language semantics, and creating executable program\nsnippets (OpenAI 2023; Chowdhery et al. 2023; Liu et al.\n2023; Bubeck et al. 2023). LLMs are begining to have an im-\npact on game design and development (Sweetser 2024), uti-\nlizing their vast pre-trained world knowledge and language\ngeneration capabilities to create autonomous NPCs that ex-\nhibit emergent behavior (Peng et al. 2024; Buongiorno et al.\n2024). LLMs have been shown to generate dialogues that\ncan pass as human-created content (Gao and Emami 2023)\nand produce code and dialogues for story progression (Ak-\noury, Salz, and Iyyer 2023). They can also be trained to gen-\nerate dialogues matching specific speaking styles (Latouche,\nMarcotte, and Swanson 2023). Kumaran et al. (2023) show-\ncased a framework for automating the conversion of author\ninstructions into playable scenes with generated dialogues\nin a Unity virtual environment. For immersive and engag-\ning NPC interactions, dialogues must follow a plot sequence\nand adapt to player actions. Our framework enhances LLM-\ngenerated NPC interaction scenes by generating an overar-\n77\nDesigner Narrative Arc input\nThe player is tasked with unraveling the mystery of\nabnormal behavior and death observed in Tilapia on a\nlush island. They interact with various characters, such\nas researchers and farmers, to gather clues and solve the\nmystery.\nTable 1: Example designer input used to generate game\nepisode.\nching narrative beat graph. This graph supports out-of-order\ninteractions and enables real-time adaptive dialogues, ensur-\ning a cohesive and flexible narrative experience in a virtual\n3D environment.\nNARRATIVE GENIE\nFigure 1 presents the N ARRATIVE GENIE architecture that\ntakes as input the designer’s narrative arc, a natural lan-\nguage text typically ranging from 20 to 30 words. The Nar-\nrative Beat Generator then processes this narrative arc using\nLLMs to convert it into a series of partially ordered narrative\nevents. Following this, the Event Dependency Resolver an-\nalyzes these events, pinpointing the necessary and sufficient\nconditions for the event to unfold successfully. Another crit-\nical component, the Character Prop Locator, examines the\nrequisite characters and props for each narrative event, as-\nsessing whether they need to be relocated as a precondition\nfor the event to happen. TheScene Generator enriches these\nnarrative events with detailed interaction dialogue, gestures,\nemotes, and other elements, filling out the narrative. Finally,\nthe Game Level Generatorcompiles these elements, drafting\nthe Ink 1 script components required for the Playable Level\nGenerator. This process ends in the creation of interactive\nplayable game levels.\nNarrative Beat Generator\nThe Narrative Beat Generator is designed to automate the\ndeconstruction of a story into events within interactive nar-\nratives. Narrative beats are key events that drive a story for-\nward, often marked by character development, plot advance-\nment, or critical information revelation. The generator first\ninterprets the designer provided input describing a narrative\narc. An example input shown in Table 1. Based on the story\ndetails, using LLMs to match story details to available assets\nin the library, it selects a location, setting, and characters.\nThe locations and characters in the library are given descrip-\ntions that the LLMs leverage to match with story events. The\ninitial input acts as a blueprint, instructing the LLM to craft\na short story centered around the main protagonist’s experi-\nences through these settings, each inhabited by one to two\nadditional characters who are constant within their respec-\ntive settings while the protagonist navigates between them.\nFollowing the initial story generation, the component’s\nnext task is to distill this story into a partially ordered se-\n1Ink (https://www.inklestudios.com/ink), a narrative scripting\nlanguage for games extended to support Unity functions.\nFigure 2: Example of an individual generated narrative beat.\nquence of narrative events or beats. By analyzing the gener-\nated story, the LLM outlines five to ten key events, each in-\nvolving up to three characters. These events are not strictly\nlinear but are designed to offer multiple pathways through\nthe story, thus enabling a dynamic storytelling experience\nwhere the sequence of events can vary, giving players choice\nand variability in how the narrative unfolds. Each narrative\nbeat generated by the LLM is returned as a structured Python\nobject comprising several fields shown in the example (Fig-\nure 2). This multi-stage prompting approach is meant to fa-\ncilitate the logical progression of the story and also enrich\neach narrative event by emphasizing the evolution of char-\nacters and the impact of their decisions or experiences. The\nculmination of this process is a partially ordered sequence\nthat realizes the author’s intended narrative arc. This se-\nquence is a partially ordered set of events that the player\ncan navigate in multiple ways. The output from the Narra-\ntive Beat Generator lays the foundation for the remaining\ncomponents.\nEvent Dependency Resolver\nThe Event Dependency Resolver is a component within\nthe framework designed to ensure a coherent progression\nthrough a story’s events by managing dependencies between\nnarrative beats. At its core, the Event Dependency Resolver\nanalyzes narrative beats to delineate the necessary and suf-\nficient conditions required for each beat’s completion. This\nanalysis involves identifying ‘next\nids’ and ‘prev ids’ lists\nassociated with each beat description, employing these lists\nto construct a directed graph that explains the requisite event\ndependencies. A beat can have multiple parents or a sin-\ngle parent. When they have multiple parents, the sufficiency\ncondition is satisfied if any of its parent beats have com-\npleted. If a beat has a single parent, then it can progress if\nthat parent beat has completed.\nAnother responsibility of the Event Dependency Resolver\nis to dynamically generate alternate NPC dialogues for sce-\nnarios where the player attempts to progress through the nar-\nrative out of order. This feature is achieved by prompting\nLLMs with the established narrative event order and the rea-\nsoned explanations behind this order. The LLMs then gen-\nerate contextually appropriate dialogues for NPCs to guide\nthe player back on track, ensuring the narrative unfolds co-\nherently.\n78\nFigure 3: Example of an NPC (Andrea) movement to match\nnarrative context of each beat.\nFinally, the Event Dependency Resolver generates a\nPython-based data structure that systematically tracks the\nconditions and alternate dialogues associated with each nar-\nrative event. This data structure supplements the original\nnarrative beat description during Ink script generation.\nCharacter and Prop Locator\nThe Character and Prop Locator validates that NPC and\nprops are not static but dynamically positioned through-\nout the game environment to ensure seamless narrative pas-\nsage. This component matches narrative elements with the\ngame’s physical environment, making narrative progression\ncoherent. The alignment is achieved by interpreting the se-\nquence of narrative beats, which detail the characters in-\nvolved in each event and the settings in which these events\noccur. The component first addresses potential character sets\nand location mismatches to maintain consistency and avoid\ndiscrepancies between the game’s narrative and available\ngame assets in the visual representation. The framework re-\nstricts character and location setting choices to those avail-\nable within the game’s asset library by leveraging LLMs as\nzero-shot classifiers that map generated elements to asset li-\nbrary elements based on the context provided by each narra-\ntive beat.\nThe Character and Prop Locator carefully manages the\nnumber of characters in each scene, ensuring that there is\nalways at least one character within the scene besides the\nplayer. This management extends to aligning the number of\ncharacters with the spawn points available within the game’s\nassets, thereby preventing overcrowding. Character move-\nment is another aspect the Character and Prop Locatorhan-\ndles. Initially placing NPCs at specific spawn points based\non their first interaction within the narrative and then adjust-\ning their positions based on the player’s interactions and the\nchronological order of narrative events, the system guaran-\ntees that characters move logically within the game world.\nThis NPC location mapping includes moving characters to\navailable empty slots to prevent an incoherent visual expe-\nrience. Figure 3 shows an example scenario. All these op-\nerations, including character, location mappings, and move-\nments, are recorded in a Python data object. This object gen-\nerates the Ink script to control the game’s mechanics. This\nPython object, along with the data structures generated by\nthe Event Dependency Resolver and Narrative Beat Gener-\nator, is combined in subsequent components to build the in-\nteractive narrative game level.\nScene Generator\nGiven the scene location, the characters, and their motiva-\ntion and goal of a scene, theSCENE GENERATOR uses LLMs\nto generate scenes with dialogues between the characters,\nalong with NPC gestures and emotes that match each NPC\nutterance. Each narrative beat, as shown in Figure 2, con-\ntains all the necessary information to generate a scene. The\nframework iteratively invokesScene Generator for each nar-\nrative beat to flesh out the details of the interaction. The\nprompts provided to the LLMs ensure narrative coherence\nand consistency across the overall storyline and between\nnarrative beats. This is achieved by including the overarch-\ning plot and a high-level summary of preceding and subse-\nquent events within the LLM context, which helps gener-\nate scene dialogues that are contextually relevant and seam-\nlessly integrated into the narrative. Each scene is built as\na separate Ink script with the dialogue flow. The Playable\nGame Generator supports interaction triggers enabled in-\ngame entities to start the scene when the player starts a\nconversation with the corresponding NPC or interacts with\na game object. The Scene Generator also sets or modifies\nglobal variables that record the game state as interactions\nare triggered. These variables are checked against criteria es-\ntablished by the Event Dependency Resolver generated data\nstructure, ensuring that the necessary and sufficient condi-\ntions are met before triggering narrative beats. This mecha-\nnism streamlines the narrative flow and enhances the game’s\ndynamics, allowing for an engaging player experience.\nPlayable Game Level Generator\nThe Playable Game Generator is a realization of the Sto-\nryLoom architecture (Mott et al. 2019) and uses a textual\nrepresentation of in-game interactions as a script. The tool\ncombines two key asset types to render the game. The first\nset of assets are game world assets corresponding to physical\nentities in the game. It could be the location layout, the char-\nacters present, and props like books, food, and other items\nwith which the players can interact. The other types of assets\nare the narrative scripts that represent the flow of conversa-\ntion in a scene and mappings of the game interactions that\ntrigger narrative beats recorded in spreadsheets, called beat\nsheets. The scene scripts are the dialogue graph of character\nconversations, narrations, and instructions on character ges-\ntures, emotes, movement, and other aspects necessary to run\nthe scene. Our extended version of the Ink narrative scripting\nlanguage supports text-based dialogue trees by adding the\nability to call custom-defined Unity functions. These func-\ntions enable the framework to place characters and props in\nthe environment, control the camera, trigger the movement\nof game objects, and change the game state, among other\nactions, primarily through the ink script. The beat sheet is\n79\nFigure 4: Screenshots from game episodes generated by NARRATIVE GENIE .\nFigure 5: NARRATIVE GENIE dynamic narrative interaction\ngeneration framework architecture.\nrepresented as a spreadsheet mapping the game element that\ntriggers the event, the preconditions to trigger the corre-\nsponding scene script, which then describes the next steps\nalong with the game elements to be rendered for the scene.\nThe framework uses 3D character models and physical ob-\njects from an asset library created by artists and game de-\nsigners. Transactional events are conveyed through dialogue\nrather than visuals. State changes at the beat level are man-\naged by Unity state variables in the Ink script (Figure 2). The\nentire game-level generation process is automated, requiring\nno manual input beyond selecting library assets.\nThe narrative beats and corresponding scene details gen-\nerated by the previous components are translated into the\nInk script by the Script to Game Engine for each scene and\nmapped in the beat spreadsheet with the corresponding trig-\nger and trigger rule. The scene scripts and beat sheet are\nrendered by the Playable Game Generator as a 3D game\nepisode in unity. Figure 4 shows a sequence of screenshots\nfrom one such generated game episode.\nNARRATIVE GENIE Adaptive Dialogue\nManager\nWhen creating branching narratives, it is difficult to accom-\nmodate all possible combinations of player actions at design\ntime. We extend N ARRATIVE GENIE to support dynamic\nadaptation of narrative interactions using the Adaptive Di-\nalogue Manager as shown in Figure 5.\nAdaptive Dialogue Manager\nIn the previous section, we discussed the design-time gener-\nation of narrative structures and beats. Here, we extend this\nframework (Figure 5) to include dynamic NPC interactions\nat explicitly designated points in the narrative. These interac-\ntions are generated in real-time using theAdaptive Dialogue\nManager, which is integrated with the game engine via a\nREST interface. When dynamic NPC interaction is indicated\nin the Ink script, the game engine calls the Dialogue Gener-\nation Service, sending a detailed gameplay history log. This\nservice then uses LLMs to craft a context-aware prompt,\ngenerating appropriate NPC dialogues, gestures, and emotes\nbased on the current game state.\nGiven that this generation process is time-consuming, it\nis implemented asynchronously to maintain the interactiv-\nity of the game experience. This design choice ensures that\nthe narrative pacing can accommodate the delay inherent in\ngenerating NPC interactions, thus preventing any disruption\nto the player’s immersion. Integrating LLMs by the Adap-\ntive Dialogue Manager component allows the framework to\nadapt NPC interactions in real-time based on the player’s\njourney through the game thus far. The LLM’s prompt in-\ncorporates the original story prompt crafted by the designer\nand the current game state. This dual context enables the\nLLM to generate responses that are not only coherent but\nalso aligned with designer goals, guiding the narrative for-\nward in a manner that feels both natural and engaging to the\nplayer.\nEvaluation\nOur evaluation methodology employs automated and hu-\nman evaluation techniques to assess the generated game\nepisodes. Automated evaluation, while efficient, poses sig-\nnificant challenges in accurately gauging semantic under-\nstanding, coherence, and cohesion across extended text pas-\nsages. This limitation underscores the necessity of human\nevaluation. We evaluate the generation capabilities of NAR-\nRATIVE GENIE and the dynamic real-time narrative adapta-\ntions of the NARRATIVE GENIE Adaptive Dialogue Manager\nindependently.\nNARRATIVE GENIE Evaluation Approach\nOur automated evaluation of N ARRATIVE GENIE utilizes a\ndataset comprising ten diverse prompts, each yielding five\npartially ordered narrative beats, to analyze the generated\ntext’s quality.\n80\nFigure 6: (a) Background of human study participants. (b)\nGame-playing experience among human study participants.\nAlong with automated evaluation, human evaluators ex-\namine the end-to-end generation process by actively playing\nthrough the generated game levels. The end-to-end review\noffers insights into the overall player experience and narra-\ntive alignment to instruction. This dual approach compre-\nhensively assesses the generated content’s quality and the\nframework’s generative potential.\nNARRATIVE GENIE Automated Evaluation\nWe evaluate our system’s creativity by comparing generated\nbeat text using ROUGE-L scores (Lin 2004).We generated\nmultiple narrative beat sets from designer-provided narra-\ntive arcs and analyzed the ROUGE-L score distributions.\nOne distribution compared beat pairs from the same narra-\ntive arc, while the other compared beat pairs from different\nnarrative arcs. We expect the beats from the same narrative\narc to be more alike than those from different arcs. We use\nan independent t-test to evaluate the separation between the\ndistributions (Student 1908).\nTo evaluate how well the system aligns with designer in-\nputs, we use Sentence-BERT (Reimers and Gurevych 2019)\nto create sentence embeddings from both the designer’s nar-\nrative arc and the generated texts. By comparing cosine sim-\nilarity distributions between narrative-arc-to-generated text\nand narrative-arc-to-unrelated text, we assess the alignment\nof generated texts with their input narrative arc.\nNARRATIVE GENIE Human Evaluation\nA purposive sampling method was used for the study recruit-\nment, leveraging the researcher’s professional and academic\nnetwork. 19 participants (aged 25 to 53) with diverse experi-\nence levels in playing and developing games evaluated NAR-\nRATIVE GENIE . Participants were asked to categorize them-\nselves as Computer Scientists/Software Engineers, Educa-\ntors, Game Developers or Designers, Researchers, or Other,\nwith the option to select multiple categories. Figure 6(a) dis-\nplays the histogram of participant categories. Additionally,\nparticipants rated their video game experience on a scale of\n1 to 7, as shown in the histogram in Figure 6(b). Each partic-\nipant engaged with the framework during a 1-hour session,\nstarting with an introduction to the framework and instruc-\ntions on providing an author story summary for game-level\ngeneration. After recording their story prompt using the on-\nline web interface, participants waited 5-10 minutes for the\nframework to generate the game episode. They then played\nFigure 7: ROUGE-L distribution narrative beats compar-\nisons between those generated from the same and unrelated\ndesigner inputs.\nthe episode and answered five questions about their expe-\nrience on a 1 to 7 Likert scale and had the option to give\nqualitative feedback.\nThe participants were asked to answer the following\nquestions adapted from the User Experience Questionnaire\n(UEQ) (Schrepp et al., 2017). The UEQ is a validated in-\nstrument for assessing the psychometric aspects of a user’s\nexperience with a product.\n• How would you rate the ease of generating new narra-\ntives using the tool (Ease-of-Use)? From ‘Complicated’\nto ‘Easy’.\n• How engaging and unexpected did you find the generated\ngame (Creativity)? From ‘Dull’ to ‘Creative’.\n• To what extent did the interaction in the game accu-\nrately represent and respond to your intent (Adaptabil-\nity)? From ‘Unsatisfactory’ to ‘Satisfactory’.\n• How would you evaluate the game’s characters and sto-\nryline in terms of their believability, coherence, and en-\ngagement (Dependability)? From ‘Not Interesting’ to\n‘Interesting’.\n• Overall, how satisfied are you with the generated game\nepisode (Satisfaction)? From ‘Not Satisfied’ to ‘Satis-\nfied’.\nAdaptive Dialogue Manager Evaluation Approach\nAdaptive Dialogue Manager is evaluated by asking the par-\nticipant to play a game episode that dynamically adapts\nbased on gameplay. The participant is introduced to this set-\nting with the mission of helping to solve the mystery be-\nhind the theft. The episode’s narrative is structured around a\nfixed set of narrative beats and a predefined story arc, ensur-\ning a consistent storyline to minimize variability introduced\nby an open-ended generated narrative. This narrative scaf-\nfold introduces players to three pivotal characters, each play-\ning a role in the unfolding mystery. Kim provides the con-\ntext regarding the stolen artifact, including details about the\nensemble of characters. Through interactive dialogue, Elise\nprovides all pertinent clues about the case, functioning as\na dynamic repository of information regarding the suspect\n81\nFigure 8: Cosine distance between designer input string em-\nbedding and generated narrative beat embedding.\ndetails, potential motives, and other clues. The game’s de-\nsign incorporates up to 16 clues, categorized across multiple\ndimensions, including deliberately placed red herrings, to\nchallenge the player’s deductive reasoning. As players navi-\ngate these clues, they are encouraged to formulate hypothe-\nses regarding the perpetrator’s identity. Through the Adap-\ntive Dialogue Manager intervention, Elise provides timely\nhints that nudge the player towards asking more pointed\nquestions. Upon deciding on a suspect, the narrative arc pro-\ngresses to an interaction with the chief investigator, Robert,\nwho summarizes the gathered evidence. This synthesized\nsummary is not static but dynamically generated in real-\ntime by theAdaptive Dialogue Managerbased on gameplay.\nOur evaluation methodology employs automated and human\nevaluation techniques to assess the generated real-time nar-\nrative adaptations of the N ARRATIVE GENIE Adaptive Dia-\nlogue Manager.\nAdaptive Dialogue Manager Automated Evaluation\nOur study analyzes 30 gameplay samples featuring hint\nand summary generation to evaluate our automated system.\nOur setup involves simulating a gameplay history where the\nplayer has encountered 2 to 3 clues, followed by the provi-\nsion of a hint, and culminating in a summary and resolution\nof the mystery. First, we assess the relevance of the hints\nprovided to the player by categorizing all the clues within\nthe game as either ‘relevant’ or ‘irrelevant’, with the former\nbeing defined as clues that contribute to solving the mys-\ntery. We postulate that hints will exhibit a closer semantic\nproximity to relevant clues, measured through cosine dis-\ntance between sentence embeddings. Second, to determine\nwhether the hints offer new information to the player, we ex-\namine the cosine distance between clues already discovered\nby the player and those that remain unknown but marked as\nrelevant. Our hypothesis suggests that the hint should be se-\nmantically further from known clues and closer to unknown\nbut relevant clues. Lastly, we evaluate the coherence of the\nsummarization with the player’s gameplay history by com-\nparing the cosine distance between the summary text and\nalready discovered and undiscovered clues.\nFigure 9: Score distribution for human evaluation of N AR-\nRATIVE GENIE .\nAdaptive Dialogue Manager Human Evaluation\nThe 19 participants played and completed the mystery game\nepisode and responded to four questions on a Likert scale\n(1-7). Additionally, the survey allowed for qualitative feed-\nback, enabling participants to elaborate on their ratings. The\nparticipants answered the following questions in the post-\nsurvey:\n• How engaging and unexpected did you find the mystery\ngame (Engaging)?\n• Were the hints from Elise and the overall summarization\nfrom Robert coherent (Coherence)?\n• How would you evaluate the game’s characters and sto-\nryline in terms of their believability, coherence, and en-\ngagement (Believability)?\n• Overall, how satisfied are you with the generated game\nepisode (Satisfaction)?\nResults and Discussion\nWe evaluate the capabilities of NARRATIVE GENIE to gener-\nate novel game interactions that align with the author’s intent\nand the Adaptive Dialogue Manager’s ability to generate in-\nteractions in real-time based on a player’s gameplay history.\nVariability and Creativity\nWe use the ROUGE-L score to analyze the similarity be-\ntween generated narrative beats. ROUGE-L evaluates the\nlongest common subsequence between texts, making it suit-\nable for assessing generated content similarity. Instead of a\nreference based comparison, we use ROUGE-L to do a rel-\native comparison between narrative beats from identical and\ndifferent input prompts. Figure 7 illustrates the distribution\nof ROUGE-L scores, showing higher similarity between nar-\nrative beats derived from the same prompts than those from\nunrelated ones.\nWe generate five narrative beats for ten prompts and cal-\nculate the similarity distance to build the distribution. Our\nfindings confirm that narrative beats from the same prompts\nshow higher similarity, reflected by higher ROUGE-L\nscores, than those from different prompts. This difference\nis statistically significant (p <0.001) via an independent t-\ntest. We use a parametric test due to the sample size (hun-\ndreds), continuous variables, and near-normal distribution.\n82\nFigure 10: (a) Cosine distances: Hint texts vs. ‘Relevant’/‘Irrelevant’ clues. (b) Cosine distances: Hint texts vs.\n‘Known’/‘Undiscovered’ clues. (c) Summary dialogues vs ‘Known’/‘Unknown’ clues.\nThis result highlights the effectiveness of the script gener-\nation process. Notably, the high standard deviation within\nscores for same-prompt (0.046) is slightly greater than for\ndifferent-prompt (0.038). Overlapping ROUGE-L score dis-\ntributions suggest that while the generation process produces\nsimilar beats from identical prompts, it also creates diverse\nnarratives, adding novelty and diversity, which will be fur-\nther substantiated by human evaluations.\nAlignment with Designer Intent\nWe evaluated the alignment between designers’ narrative in-\ntentions, as expressed in their story summaries, and the nar-\nrative beats produced by our framework. This involved as-\nsessing the semantic coherence between the prompts and\ntheir narrative outcomes. Alignment measured through co-\nsine similarity between designer prompt and generated script\nsentence embedding supports our hypothesis. Designer’s ini-\ntial input shows higher semantic similarity with the corre-\nsponding narrative beats than those generated from unre-\nlated inputs. Figure 8 shows the cosine distance distribution\nfor designer input to generated beats versus input to unre-\nlated beats. These distributions reveal a significant differ-\nence (p-value <0.001) in cosine distance between an input\nand its corresponding generated beats compared to unrelated\nbeats. This result confirms our framework’s effectiveness in\npreserving the designer’s intent in the narrative output.\nInterestingly, Figure 8 reveals a small peak indicating\nhigher cosine distance between some prompts and their gen-\nerated beats. This variance was traced back to one particu-\nlarly vague prompt (“A competition to create the most in-\nnovative scientific project brings out unexpected talents”),\nwhich led to a broad range of narrative beats. This outlier\nhighlights the challenge of generating tightly aligned content\nfrom non-specific inputs. Conclusively, our automated eval-\nuation metrics show that the framework can generate narra-\ntive beats that align with the designers’ original intent, en-\nsuring the content reflects the initial creative vision. In a later\nsection, we will further investigate this through a human-\ncentric evaluation.\nHuman Evaluation of NARRATIVE GENIE\nFigure 9 presents results from a human study, showing\nscores from 19 participants across five metrics: Ease-of-Use,\nCreativity, Alignment, Believability, and Overall Satisfac-\ntion. Ease-of-Use had the highest average rating (mean =\n5.42), indicating the framework was user-friendly. However,\noutliers affected this average due to a code bug requiring\nusers to regenerate episodes. Creativity and Alignment with\nthe designer’s intention averaged 4.63, indicating moder-\nate originality and adherence to inputs. Believability scored\nslightly lower (mean = 4.58), suggesting participant skepti-\ncism.\nThe Creativity metric showed high score variance (stan-\ndard deviation = 1.7), indicating subjective perceptions\nbased on varying user experiences or expectations. Maxi-\nmum scores consistently reached 7 across all metrics, show-\ning some users perceived the system to excel in all evaluated\naspects. Overall, the dataset presents a generally favorable\nview of the system’s usability and effectiveness, with areas\nfor improvement in perceived Creativity, Alignment with in-\nput, and Believability.\nAfter reviewing the reasons for low scores (<4.0), Cre-\nativity was rated poorly twice due to monotony and shal-\nlow character interactions. Despite using designer-specified\ntopics, the narrative was criticized for repetitive and vague\ndialogue, lacking engaging elements, resulting in redundant\ntasks with no satisfying conclusion. One case of low Align-\nment with designer intent highlighted a mismatch between\nuser expectations and the story output, suggesting that open-\nended prompts may lead to misaligned narratives. Low Be-\nlievability scores were due to repetitive dialogue and a dis-\nconnect between visuals and dialogues, likely caused by the\nLLM generating scenes independently without a complete\ndialogue history.\nThe small sample size limits robust statistical conclusions\nat the subgroup level, but some trends are evident. Partici-\npants with significant gaming experience rated Ease-of-Use\nhigher (mean = 5.818) than those with less experience (mean\n= 4.875), indicating that familiarity with games enhances\nunderstanding of game development and appreciation for\nautomation frameworks. Conversely, the most experienced\n83\nFigure 11: Score distribution for each of the human evalua-\ntion questions for Adaptive Dialogue Manager.\ngamers rated Creativity lower (mean = 4.091) than less ex-\nperienced participants (mean = 5.375), suggesting greater\nexposure may lead to more critical assessments. Similarly,\ncomputer scientists rated Ease-of-Use higher (mean = 5.67)\nthan non-computer scientists (mean = 5.2), possibly reflect-\ning their understanding of game development. A larger sam-\nple size might confirm these findings, emphasizing the need\nto consider designers’ backgrounds in future framework im-\nplementations.\nAdaptive Dialogue Manager Hint and Summary\nTo evaluate the Adaptive Dialogue Manager, we analyzed\n30 mystery episode gameplay sessions to generate a distri-\nbution of cosine distances between generated hint texts and\nclues classified as ‘Relevant’ and ‘Irrelevant’. The results,\ndepicted in Figure 10(a), demonstrate a clear distinction in\nthe distribution of distances. Specifically, the distance be-\ntween the hint text and ‘Irrelevant’ clues is significantly (p\n<0.001) higher than between the hint text and ‘Relevant’\nclues, aligning with our hypothesis that hints presented are\nrelevant to solving the mystery. Continuing with the same\n30 gameplay samples, we generated a distribution of cosine\ndistances between the hint text and clues discovered by the\nplayer (‘Known clues’) versus clues relevant to solving the\npuzzle but not yet revealed to the player. Figure 10(b) visu-\nally illustrates the hint text is closer (p<0.001) to ‘Relevant’\nbut undiscovered clues. This result indicates that the hints\nprovide new, helpful information to assist players in solving\nthe mystery. Further analysis involved examining whether\nthe generated summary dialogues, which help resolve the\nmystery, reference clues observed by the player during the\ngame. We applied the same cosine distance methodology to\nassess the relationships. Figure 10(c) displays the distance\ndistributions between the summary dialogues and ‘Known\nclues’ versus other clues. A statistically significant separa-\ntion (p <0.001) reveals that the summary is more closely\naligned with ‘Known clues’, indicating its coherence and\nthat it incorporates facts from the player’s actions within the\ngame.\nHuman Evaluation of Interaction Intervention\nFigure 11 shows the scores from the human evaluation of\nthe Adaptive Dialogue Manager. The mean scores suggest\nthat coherence was rated highest among the four metrics,\nwith a mean score of 6.53. This indicates that participants\nfound the narrative threads generated by the framework to\nbe logical and consistent. The low standard deviation (0.772)\nsupports this high mean, indicating a tight clustering of re-\nsponses around the mean and showcasing a consensus on the\nframework’s ability to maintain narrative coherence despite\ninteractions generated on the fly based on gameplay history.\nMany participants specifically appreciated Robert’s sum-\nmary, feeling it effectively consolidated all the plot points.\nEngagement and satisfaction had similar mean scores of\n5.37 and 5.53, indicating participants found the narrative\ngame engaging and satisfying but saw room for improve-\nment. Those who rated these aspects lower wanted more\ndiverse characters and a more challenging way to obtain\nclues beyond interacting with Elise. They also mentioned\nthat some hints were too obvious, sometimes making the\ngame feel too easy.\nBelievability scored slightly lower, with a mean of 5.42\nand the highest standard deviation (1.465) among the met-\nrics. This higher variance in the narrative’s believability\nscore may be attributed to instances where some participants\nquickly uncovered the correct clues, rendering the game too\nsimple and predictable.\nConclusion\nNARRATIVE GENIE harnesses the power of LLMs to auto-\nmate and streamline the creation of engaging, interactive\nplayer-driven narratives. By transforming high-level story\noutlines into partially ordered event graphs, N ARRATIVE -\nGENIE maintains narrative coherence while allowing for\nplayer agency through interactive gameplay. It supports dy-\nnamic runtime adaptation, ensuring player choices influence\nthe unfolding narrative, thereby enhancing the player expe-\nrience. Empirical evaluations using automated and human\nmetrics demonstrate that NARRATIVE GENIE is easy to use,\nwith the generated narratives aligning with designers’ nat-\nural language instructions, effectively balancing narrative\nstructure and player agency.\nSeveral directions for future work are promising. First, it\nwill be instructive to explore approaches for enabling de-\nsigners to provide guidance during the intermediate stages\nof narrative generation, improving creativity and alignment.\nSecond, investigating customization of subject matter, plot\ndetails, and character inputs rather than requiring a single\ncomprehensive prompt offers another important direction\nfor future work. This could enhance the believability and\nengagement of generated stories. Finally, exploring an ex-\npanded range of real-time narrative interventions could en-\nable more complex experience management and create a\nricher, more immersive player experience.\nAcknowledgments\nThis work is supported by the National Science Founda-\ntion under award DRL-2112635. Any opinions, findings,\nand conclusions or recommendations expressed in this ma-\nterial are those of the authors and do not necessarily reflect\nthe views of the National Science Foundation.\n84\nReferences\nAkoury, N.; Salz, R.; and Iyyer, M. 2023. Towards Grounded\nDialogue Generation in Video Game Environments. In Cre-\native AI Across Modalities Workshop, AAAI.\nAkoury, N.; Wang, S.; Whiting, J.; Hood, S.; Peng, N.; and\nIyyer, M. 2020. STORIUM: A Dataset and Evaluation Plat-\nform for Machine-in-the-Loop Story Generation. In Pro-\nceedings of the 2020 Conference on Empirical Methods in\nNatural Language Processing, (EMNLP), 6470–6484.\nAmmanabrolu, P.; Tien, E.; Cheung, W.; Luo, Z.; Ma, W.;\nMartin, L. J.; and Riedl, M. O. 2020. Story realization:\nExpanding plot events into sentences. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, volume 34,\n7375–7382.\nBubeck, S.; Chandrasekaran, V .; Eldan, R.; Gehrke, J.;\nHorvitz, E.; Kamar, E.; Lee, P.; Lee, Y . T.; Li, Y .; Lundberg,\nS.; Nori, H.; Palangi, H.; Ribeiro, M. T.; and Zhang, Y . 2023.\nSparks of Artificial General Intelligence: Early experiments\nwith GPT-4. arXiv:2303.12712.\nBuongiorno, S.; Klinkert, L. J.; Chawla, T.; Zhuang, Z.; and\nClark, C. 2024. PANGeA: Procedural Artificial Narrative\nusing Generative AI for Turn-Based Video Games. arXiv\npreprint arXiv:2404.19721.\nCalderwood, A.; Wardrip-Fruin, N.; and Mateas, M. 2022.\nSpinning Coherent Interactive Fiction through Foundation\nModel Prompts. In Proceedings of the 13th International\nConference on Computational Creativity, Bozen-Bolzano,\nItaly, June 27 - July 1, 2022, 44–53. Association for Com-\nputational Creativity (ACC).\nChowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,\nG.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;\nGehrmann, S.; et al. 2023. Palm: Scaling language model-\ning with pathways. Journal of Machine Learning Research,\n24(240): 1–113.\nChung, J. J. Y .; Kim, W.; Yoo, K. M.; Lee, H.; Adar, E.; and\nChang, M. 2022. TaleBrush: Sketching stories with genera-\ntive pretrained language models. In Proceedings of the 2022\nCHI Conference on Human Factors in Computing Systems ,\n1–19.\nCrowther, W.; Woods, D.; and Black, K. 1977. Colossal\nCave Adventure [Video game]. PDP-10.\nGao, Q. C.; and Emami, A. 2023. The Turing Quest:\nCan Transformers Make Good NPCs? In Padmakumar, V .;\nVallejo, G.; and Fu, Y ., eds.,Proceedings of the 61st Annual\nMeeting of the Association for Computational Linguistics\n(Volume 4: Student Research Workshop), 93–103. Associ-\nation for Computational Linguistics.\nGuan, L.; Valmeekam, K.; Sreedharan, S.; and Kambham-\npati, S. 2023. Leveraging pre-trained large language models\nto construct and utilize world models for model-based task\nplanning. Advances in Neural Information Processing Sys-\ntems, 36: 79081–79094.\nKoenitz, H. 2023. Understanding interactive digital narra-\ntive: immersive expressions for a complex time. Routledge.\nKreminski, M.; Dickinson, M.; Wardrip-Fruin, N.; and\nMateas, M. 2022. Loose Ends: a mixed-initiative creative\ninterface for playful storytelling. InProceedings of the AAAI\nConference on Artificial Intelligence and Interactive Digital\nEntertainment, volume 18, 120–128.\nKreminski, M.; Wardrip-Fruin, N.; and Mateas, M. 2020.\nToward Example-Driven Program Synthesis of Story Sifting\nPatterns. In AIIDE Workshops.\nKumaran, V .; Rowe, J.; Mott, B.; and Lester, J. 2023.\nSCENECRAFT: automating interactive narrative scene gen-\neration in digital games with large language models. In Pro-\nceedings of the AAAI Conference on Artificial Intelligence\nand Interactive Digital Entertainment, volume 19, 86–96.\nLatouche, G. L.; Marcotte, L.; and Swanson, B. 2023. Gen-\nerating Video Game Scripts with Style. In The 61st Annual\nMeeting Of The Association For Computational Linguistics.\nLin, C.-Y . 2004. ROUGE: A Package for Automatic Evalu-\nation of Summaries. In Text Summarization Branches Out,\n74–81. Barcelona, Spain: Association for Computational\nLinguistics.\nLin, Z.; and Riedl, M. O. 2021. Plug-and-blend: a frame-\nwork for plug-and-play controllable story generation with\nsketches. In Proceedings of the AAAI Conference on Artifi-\ncial Intelligence and Interactive Digital Entertainment, vol-\nume 17, 58–65.\nLiu, P.; Yuan, W.; Fu, J.; Jiang, Z.; Hayashi, H.; and Neubig,\nG. 2023. Pre-train, prompt, and predict: A systematic survey\nof prompting methods in natural language processing. ACM\nComputing Surveys, 55(9): 1–35.\nMartin, L. J.; Harrison, B.; and Riedl, M. O. 2016. Im-\nprovisational computational storytelling in open worlds. In\nInteractive Storytelling: 9th International Conference on\nInteractive Digital Storytelling, ICIDS 2016, Los Angeles,\nCA, USA, November 15–18, 2016, Proceedings 9, 73–84.\nSpringer.\nMirowski, P.; Mathewson, K. W.; Pittman, J.; and Evans,\nR. 2023. Co-Writing Screenplays and Theatre Scripts with\nLanguage Models: Evaluation by Industry Professionals. In\nProceedings of the 2023 CHI Conference on Human Factors\nin Computing Systems, 1–34.\nMott, B. W.; Taylor, R. G.; Lee, S. Y .; Rowe, J. P.; Saleh,\nA.; Glazewski, K. D.; Hmelo-Silver, C. E.; and Lester, J. C.\n2019. Designing and developing interactive narratives for\ncollaborative problem-based learning. In Interactive Story-\ntelling: 12th International Conference on Interactive Dig-\nital Storytelling, ICIDS 2019, Little Cottonwood Canyon,\nUT, USA, November 19–22, 2019, Proceedings 12, 86–100.\nSpringer.\nNaul, E.; and Liu, M. 2020. Why story matters: A review of\nnarrative in serious games. Journal of Educational Comput-\ning Research, 58(3): 687–707.\nOliver, E.; and Mateas, M. 2021. Crosston tavern: modulat-\ning autonomous characters behaviour through player-NPC\nconversation. In Proceedings of the AAAI Conference on\nArtificial Intelligence and Interactive Digital Entertainment,\nvolume 17, 179–186.\nOpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774.\n85\nPeng, X.; Quaye, J.; Rao, S.; Xu, W.; Botchway, P.; Brockett,\nC.; Jojic, N.; DesGarennes, G.; Lobb, K.; Xu, M.; Leandro,\nJ.; Jin, C.; and Dolan, B. 2024. Player-Driven Emergence in\nLLM-Driven Game Narrative. In Proceedings of the 2024\nIEEE Conference on Games.\nPorteous, J.; Ferreira, J. F.; Lindsay, A.; and Cavazza, M.\n2021. Automated narrative planning model extension. Au-\ntonomous Agents and Multi-Agent Systems, 35(2): 19.\nRamirez, A.; and Bulitko, V . 2014. Automated planning and\nplayer modeling for interactive storytelling. IEEE Transac-\ntions on Computational Intelligence and AI in Games, 7(4):\n375–386.\nRashkin, H.; Celikyilmaz, A.; Choi, Y .; and Gao, J. 2020.\nPlotMachines: Outline-Conditioned Generation with Dy-\nnamic Plot State Tracking. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language Pro-\ncessing (EMNLP), 4274–4295.\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT:\nSentence Embeddings using Siamese BERT-Networks. In\nProceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), 3982–3992.\nRiedl, M. O.; and Bulitko, V . 2013. Interactive narrative: An\nintelligent systems approach. Ai Magazine, 34(1): 67–67.\nRiedl, M. O.; and Young, R. M. 2010. Narrative planning:\nBalancing plot and character. Journal of Artificial Intelli-\ngence Research, 39: 217–268.\nStefnisson, I.; and Thue, D. 2018. Mimisbrunnur: AI-\nassisted authoring for interactive storytelling. In Proceed-\nings of the AAAI Conference on artificial Intelligence and\nInteractive Digital entertainment, volume 14, 236–242.\nStudent. 1908. The probable error of a mean. Biometrika,\n1–25.\nSweetser, P. 2024. Large language models and video games:\nA preliminary scoping review. Proceedings of the 6th ACM\nConference on Conversational User Interfaces.\nWang, S.; Durrett, G.; and Erk, K. 2020. Narrative interpola-\ntion for generating and understanding stories.arXiv preprint\narXiv:2008.07466.\nWare, S.; Garcia, E. T.; Fisher, M.; Shirvani, A.; and Farrell,\nR. 2022. Multiagent Narrative Experience Management as\nStory Graph Pruning. IEEE Transactions on Games, 15(3):\n378–387.\nYao, L.; Peng, N.; Weischedel, R.; Knight, K.; Zhao, D.; and\nYan, R. 2019. Plan-and-write: Towards better automatic sto-\nrytelling. In Proceedings of the AAAI Conference on Artifi-\ncial Intelligence, volume 33, 7378–7385.\nYoung, R. M.; Ware, S. G.; Cassell, B. A.; and Robertson,\nJ. 2013. Plans and planning in narrative generation: a re-\nview of plan-based approaches to the generation of story,\ndiscourse and interactivity in narratives.Sprache und Daten-\nverarbeitung, Special Issue on Formal and Computational\nModels of Narrative, 37(1-2): 41–64.\n86",
  "topic": "Storytelling",
  "concepts": [
    {
      "name": "Storytelling",
      "score": 0.8643629550933838
    },
    {
      "name": "Narrative",
      "score": 0.7789540886878967
    },
    {
      "name": "Linguistics",
      "score": 0.4245496988296509
    },
    {
      "name": "Computer science",
      "score": 0.3892388343811035
    },
    {
      "name": "History",
      "score": 0.32797005772590637
    },
    {
      "name": "Literature",
      "score": 0.30407941341400146
    },
    {
      "name": "Art",
      "score": 0.24337029457092285
    },
    {
      "name": "Philosophy",
      "score": 0.10724738240242004
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I137902535",
      "name": "North Carolina State University",
      "country": "US"
    }
  ]
}