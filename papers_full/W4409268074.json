{
  "title": "Constructing surrogates for atomistic simulations via deep learning and generative large language models",
  "url": "https://openalex.org/W4409268074",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3170496880",
      "name": "Mahshad Fani",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A2756548406",
      "name": "William Chadwell",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A5115429320",
      "name": "Nishad Tasnim",
      "affiliations": [
        "University of Wyoming"
      ]
    },
    {
      "id": "https://openalex.org/A2045332956",
      "name": "Xin Wang",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A5108962311",
      "name": "Mohammad Younes Araghi",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A2105227144",
      "name": "Kun Lu",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A2252742774",
      "name": "Zejian Zhou",
      "affiliations": [
        "University of Wyoming"
      ]
    },
    {
      "id": "https://openalex.org/A2350059043",
      "name": "Tang Gu",
      "affiliations": [
        "Institut Polytechnique des Sciences Avancées"
      ]
    },
    {
      "id": "https://openalex.org/A2315523210",
      "name": "Shuozhi Xu",
      "affiliations": [
        "University of Oklahoma"
      ]
    },
    {
      "id": "https://openalex.org/A3170496880",
      "name": "Mahshad Fani",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2756548406",
      "name": "William Chadwell",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5115429320",
      "name": "Nishad Tasnim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2045332956",
      "name": "Xin Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5108962311",
      "name": "Mohammad Younes Araghi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105227144",
      "name": "Kun Lu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2252742774",
      "name": "Zejian Zhou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2350059043",
      "name": "Tang Gu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2315523210",
      "name": "Shuozhi Xu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1996132665",
    "https://openalex.org/W1560780428",
    "https://openalex.org/W3176458381",
    "https://openalex.org/W2937681869",
    "https://openalex.org/W3011981335",
    "https://openalex.org/W4394678435",
    "https://openalex.org/W4401452192",
    "https://openalex.org/W4384824093",
    "https://openalex.org/W3016401366",
    "https://openalex.org/W2017778996",
    "https://openalex.org/W2902390267",
    "https://openalex.org/W2766761250",
    "https://openalex.org/W4403230932",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W4386827094",
    "https://openalex.org/W4385671288",
    "https://openalex.org/W4402897562",
    "https://openalex.org/W2104384632",
    "https://openalex.org/W2051112733",
    "https://openalex.org/W1997924408",
    "https://openalex.org/W3157330132",
    "https://openalex.org/W2086827153",
    "https://openalex.org/W2016463190",
    "https://openalex.org/W3147228474",
    "https://openalex.org/W2018347659",
    "https://openalex.org/W4391629679",
    "https://openalex.org/W2925264567",
    "https://openalex.org/W2093058042",
    "https://openalex.org/W1983536681",
    "https://openalex.org/W2128732414",
    "https://openalex.org/W2067276122",
    "https://openalex.org/W2018561599",
    "https://openalex.org/W2051374593",
    "https://openalex.org/W2051463006",
    "https://openalex.org/W2014313073",
    "https://openalex.org/W2018967680",
    "https://openalex.org/W2059724452",
    "https://openalex.org/W2010578443",
    "https://openalex.org/W2036803776",
    "https://openalex.org/W2067046004",
    "https://openalex.org/W2016750335",
    "https://openalex.org/W2033751639",
    "https://openalex.org/W3211905072",
    "https://openalex.org/W2018648397",
    "https://openalex.org/W2481086620",
    "https://openalex.org/W1982640357",
    "https://openalex.org/W2073826139",
    "https://openalex.org/W2593464740",
    "https://openalex.org/W2488449690",
    "https://openalex.org/W1971809356",
    "https://openalex.org/W2280643632",
    "https://openalex.org/W2464953426",
    "https://openalex.org/W2080099522",
    "https://openalex.org/W2095450859",
    "https://openalex.org/W2551840043",
    "https://openalex.org/W2062148074",
    "https://openalex.org/W1976347296",
    "https://openalex.org/W3201073812",
    "https://openalex.org/W2797017014",
    "https://openalex.org/W4385358403",
    "https://openalex.org/W2033086537",
    "https://openalex.org/W1480048606",
    "https://openalex.org/W2518696367",
    "https://openalex.org/W2013207720",
    "https://openalex.org/W3099820838",
    "https://openalex.org/W4295308222",
    "https://openalex.org/W3104729934"
  ],
  "abstract": "Abstract Atomistic simulations offer insights into material behavior at the atomic level. However, they can be computationally intensive. In this paper, two deep learning models, deep symbolic optimization (DSO) and deep neural networks (DNN), and one generative large language model, GPT-4o, are employed to construct surrogates for atomistic simulations. Specifically, atomistic simulations are first performed to investigate the collapse of a nanovoid under hydrostatic pressure. We focus on the role of initial void radius and material characteristics, such as intrinsic and unstable stacking fault energies and surface energy (SE). We find that the critical pressure required for void collapse spans from 17.05 to 19.62 GPa, with the highest values corresponding to the maximum USFE. Additionally, an intermediate SE value (1068.13 $$\\hbox {mJ/m}^2$$ <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"> <mml:msup> <mml:mtext>mJ/m</mml:mtext> <mml:mn>2</mml:mn> </mml:msup> </mml:math> ) minimizes the critical pressure. Based on the simulation results, surrogate models based on DSO, DNN, and GPT-4o are constructed, concluding that the SE affects the critical pressure the most. Graphical abstract",
  "full_text": "  Journal of Materials Research  2025  www.mrs.org/jmr\nVol.:(0123456789)\n DOI:10.1557/s43578-025-01571-1\n AnnuAl Issue\n© The Author(s) 2025. \nArticle\nConstructing surrogates for atomistic simulations \nvia deep learning and generative large language models\nMahshad Fani1, William Chadwell2, Nishad Tasnim3, Xin Wang4, Mohammad Y ounes Araghi1, \nKun Lu4, Zejian Zhou3, Tang Gu5, Shuozhi Xu1,a) \n1 School of Aerospace and Mechanical Engineering, University of Oklahoma, Norman, OK 73019, USA\n2 Engineering Physics Program, University of Oklahoma, Norman, OK 73019, USA\n3 Electrical Engineering and Computer Science Department, University of Wyoming, Laramie, WY 82071, USA\n4 School of Library and Information Studies, University of Oklahoma, Norman, OK 73019, USA\n5 Institute of Polytechnic Science and Aeronautics (IPSA), 94200 Ivry‑Sur‑Seine, France\na) Address all correspondence to this author. e-mail: shuozhixu@ou.edu\nReceived: 4 July 2024; accepted: 24 March 2025\nAtomistic simulations offer insights into material behavior at the atomic level. However, they can be \ncomputationally intensive. In this paper, two deep learning models, deep symbolic optimization (DSO) \nand deep neural networks (DNN), and one generative large language model, GPT-4o, are employed to \nconstruct surrogates for atomistic simulations. Specifically, atomistic simulations are first performed to \ninvestigate the collapse of a nanovoid under hydrostatic pressure. We focus on the role of initial void \nradius and material characteristics, such as intrinsic and unstable stacking fault energies and surface \nenergy (SE). We find that the critical pressure required for void collapse spans from 17.05 to 19.62 GPa, \nwith the highest values corresponding to the maximum USFE. Additionally, an intermediate SE value \n(1068.13 mJ/m 2 ) minimizes the critical pressure. Based on the simulation results, surrogate models based \non DSO, DNN, and GPT-4o are constructed, concluding that the SE affects the critical pressure the most.\nShuozhi Xu received his Ph.D. degree in Mechanical Engineering from the Georgia Institute of \nTechnology in 2016. After spending several years at the University of California, Santa Barbara as a \nPostdoctoral Scholar, he joined the University of Oklahoma (OU) in 2023 as a tenure-track Assistant \nProfessor in the School of Aerospace and Mechanical Engineering. He leads the OU Computational \nMaterials, Mechanics, and Manufacturing Lab, where he advances multi-physics and data-driven \nmaterials modeling methods from subatomic to macro scale and applies them to understanding \nprocessing-structure-property relations in chemically and structurally complex materials. For the \nprocessing-structure relation, he focuses on melt-based additive manufacturing of metals and ceram-\nics. For the structure-property relation, he mainly works with two multiscale modeling frameworks. \nThe first framework involves concurrent multiscale modeling based on the concurrent atomistic-\ncontinuum (CAC) method. He has advanced CAC for robust modeling of defect dynamics and used \nCAC to address micro-scale mechanical and thermal problems in materials. To help the scientific \ncommunity run CAC simulations, he developed a software package named PyCAC and built a website \n(www. pycac. org) to host its user’s manual. The second framework concerns sequential multiscale \nmodeling, which links density functional theory, atomistic simulation methods, phase-field models, \nand crystal plasticity models. He has used it to investigate submicron-scale deformation of structural \nmaterials such as multi-principal element alloys, nano-laminated materials, and additively manufac-\ntured alloys. He has won prestigious awards such as the Materials Research Society Graduate Student \nAward, Georgia Tech Sigma Xi Best Ph.D. Thesis Award, UC Santa Barbara Elings Prize Fellowship \nin Science, and Finalist for the Rising Stars in Computational Materials Science.\nEARLY CAREER SCHOLARS IN MATERIALS SCIENCE, 2026\nShuozhi Xu\n\n  Journal of Materials Research  2025  www.mrs.org/jmr\n© The Author(s) 2025. 2\nArticle\nIntroduction\nAtomistic simulations model materials at the atomic level, cap-\nturing detailed interactions between atoms, making them pow-\nerful tools for predicting material properties and mechanisms \nthat are challenging to observe experimentally [1 ]. However, \nthey are often slow and computationally demanding, especially \nfor large systems or long timescales [ 2]. Surrogate models help \naddress this limitation by approximating simulation outcomes \nwith significantly reduced computational costs [3 ]. Machine \nlearning (ML) approaches, such as neural networks (NNs) and \nGaussian processes, are commonly used to build these sur -\nrogates [ 4]. For example, Kadupitiya et al. [ 5] developed NN \nmodels as surrogates for atomistic simulations of soft materials, \nwhile Ruiz et al. [6 ] employed multivariate Gaussian process \nregression as surrogates to predict basic structural parameters in \nnon-dilute random alloys. Despite the growing number of sur-\nrogate models for atomistic simulations, new research remains \nvaluable. For instance, while highly effective and easy to imple-\nment, shallow learning models were recently found to underper-\nform in extrapolation on materials datasets compared to deep \nlearning models [7].\nIn this paper, two deep learning techniques are utilized: deep \nsymbolic optimization (DSO) and deep neural networks (DNN). \nDSO is an advanced technique that uncovers mathematical \nexpressions from data using deep learning methods [8]. It gen-\nerates potential mathematical expressions, which are then evalu-\nated based on their fit to the given dataset. The DSO method \noptimizes these expressions through a novel risk-seeking policy \ngradient algorithm, enhancing the best-performing expressions \n[9]. This method surpasses traditional symbolic regression tools, \nlike the Eureqa algorithm, by efficiently navigating the search \nspace of potential expressions [10]. The flexibility and accuracy \nof DSO make it a powerful tool for identifying interpretable and \nprecise mathematical models from complex datasets [11]. On \nthe other hand, an NN is an artificial intelligence (AI) method \nthat processes data inspired by the human brain, using artificial \nneurons that work together [12]. NNs learn by adjusting con-\nnection weights through backpropagation, minimizing the loss \nfunction and improving performance. Equipped with multiple \nlayers of neurons, DNNs outperform traditional ML methods in \nterms of generalization and accuracy [13]. The most important \ndifference between DSO and DNN is output representation in \nthat the former generates interpretable mathematical expres-\nsions or symbolic formulas that explicitly describe the relation-\nships within the data while the latter produces outputs based \non learned patterns within the network, typically resulting in a \n“black box” model that lacks explicit interpretability [14].\nAnother emerging AI tool is the generative large language \nmodels (LLMs), which originate in the subfield of natural lan-\nguage process (NLP). They are pre-trained on massive amount \nof text data using the transformer architecture [15]. With addi-\ntional supervised fine-tuning and reinforcement learning from \nhuman feedback, the resulting LLMs have shown impressive \ncapabilities in language understanding and generation. Since \nthe advent of ChatGPT in November 2022 [16], generative LLMs \nhave attracted wide attention from many fields due to their user-\nfriendly interfaces and ability to respond reasonably to a variety \nof questions. Materials scientists have applied generative LLMs \nto tasks such as extracting data from unstructured text in sci-\nentific literature [ 17, 18]. In addition to NLP tasks, generative \nLLMs have also been used to answer materials questions to assist \nscientific discoveries in materials science owing to their ability \nto understand human language and generate relevant responses \n[19, 20]. More recently, Hao et al. [21] used LLMs as surrogate \nmodels in evolutionary algorithms. To our best knowledge, \nhowever, there hasn’t been any work where LLMs were used \nas surrogate models for atomistic simulations. Here, a popular \nLLM, GPT-4o, will be applied to atomistic datasets to assess its \nperformance.\nThe specific materials problem to be studied in this work \nconcerns the collapse of a void subject to hydrostatic compres-\nsion of a Cu single crystal. In metals, voids are ubiquitous. They \ncan be formed during melting and solidification processes due \nto shrinkage and gas entrapment [22, 23] or as a result of stress \nconcentration [24] at heterogeneities such as inclusions, pre-\ncipitates, and grain boundaries [25]. When the metal undergoes \nplastic deformation, voids can grow and coalesce, ultimately \nresulting in crack propagation and failure of the material [26]. \nThe voids may also collapse, leading to local densification and \naltering the mechanical properties of the metal [27]. Therefore, \nit is crucial to understand the deformation of void-containing \nmetals to predict their behavior under stress and to develop \nalloys that are more resilient to deformation [28– 33]. The \nmechanical response of metals is influenced by the change in \nvoid geometry. A smaller void inhibits dislocation motion more \neffectively, requiring a higher resolved shear stress for disloca-\ntions to bypass it compared to a larger void [33, 34]. Factors \nsuch as void ellipticity and orientation can also influence stress \ndistribution and defect nucleation patterns [35]. Recently, Chen \net al. [36] developed a convolutional NN model that automati -\ncally detects voids in Cu-Sn solder joints. Combining this model \nwith finite element analyses helped identify stress concentration \nzones in solder joints. Similarly, Kong et al. [37] used ML algo-\nrithms along with hybrid metrology techniques to identify voids \nin copper lines, while Saleh et al. [38] used a combination of ML \nand computational simulations to improve traditional models \nfor predicting void nucleation and growth.\nAtomistic simulations have been applied to nanovoids in \nsingle crystals to analyze ductile fracture [39–43]. A single crys-\ntalline face-centered cubic (FCC) metallic material containing \n  Journal of Materials Research  2025  www.mrs.org/jmr\n© The Author(s) 2025. 3\nArticle\nspherical voids exhibits dislocation emission during yield, which \nis caused by the absence of alternative nucleation sites [39, 44]. \nIt was revealed that the loading mode influences void growth \nand coalescence [ 45, 46] and that variations in specimen size \naltered dislocation patterns, void aspect ratios, and stress–strain \nresponses [41 , 47]. The interactions between nanovoids and \nneighboring voids frequently lead to coalescence or collapse \nof the nanovoids, which can eventually lead to the formation \nof cracks or shear bands [48]. The emission of dislocation is \nthe primary mechanism driving the growth of voids in single \ncrystals using discrete dislocation dynamics modeling technique \n[47]. It was determined that the elastic moduli of materials with \nspherical voids are linearly related to the void volume fraction, \nwhile the atomic stress concentration factor is affected by the \nvoid geometry [49].\nMuch work has been devoted to gaining valuable insights \ninto the physics of void growth and collapse influenced by \nporous structures (e.g., void shape/size/porosity) [50–53], prop-\nerties of matrix materials (e.g., Y oung’s modulus) [ 54], plastic \nanisotropy [55], non-local effects that incorporate material size \nscales [ 56], strain rate [57], and crystallographic orientations \n[58–61]. Among material properties are intrinsic stacking fault \nenergy (ISFE) and unstable stacking fault energy (USFE), which \nare essential in defining the mechanisms of plastic deformation \nin metals, particularly those of FCC materials. USFE is the high-\nest energy obstacle that must be overcome for the leading partial \ndislocation to form a stacking fault [62]. ISFE affects dislocation \nnucleation, which is essential for understanding the mechanical \nproperties of these materials [63]. In addition, the surface energy \n(SE) of a metal can influence the stability and evolution of voids, \nthereby affecting the yield strength. It has been demonstrated \nthat variations in SE resulting from lattice orientation can result \nin voids exhibiting faceted morphologies with rounded corners \nin both single crystals and nanocrystalline structures, demon-\nstrating the critical role that SE plays in void evolution across \ngrain orientations [64].\nMost previous work on void-containing metals and alloys \nfocused on either varying porous structures (e.g., initial void \nsize and shape) within the same material or on different material \nproperties (e.g., ISFE and SE) across different metals. However, \nthere is a lack of systematic studies of both sets of factors in a \nunified manner. This task is difficult because different materials \nusually differ in dozens of properties. In this work, we utilize \na set of eleven interatomic potentials that differ only in ISFE, \nUSFE, and SE while all other properties are those of Cu. This \nway, our work analyzes different factors within a single frame-\nwork. Atomistic simulations using these potentials are carried \nout to investigate the plastic deformation process of a void-\ncontaining Cu single crystal under hydrostatic compression. \nDespite that real materials frequently contain multiple voids and \nother defects, we focus on the case of a single void to isolate and \nunderstand the fundamental mechanisms that govern the void \ncollapse process. Another reason to choose a relatively simple \natomistic system is that at least half of this paper is focused on \nconstructing surrogate models. Based on the simulation data, \nwe build surrogate models to establish the linkage among initial \nvoid radius, ISFE, USFE, SE, and critical pressure. All surrogate \nmodels conclude that SE is the most important factor affecting \nthe critical pressure. This piece of information would allow us \nto design stronger, more reliable materials that are less likely to \nfail due to voids.\nResults and discussion\nPressure‑dilatation response\nWe first investigate the dilatation-pressure responses. Figure  1 \nshows some representative cases, including the minimum ISFE \n(i.e., the Cu1 potential), maximum ISFE (i.e., Cu7), minimum \nUSFE (i.e., Cu31), and maximum USFE (i.e., Cu34). Note that \nCu7 and Cu31, respectively, also lead to the minimum and maxi-\nmum SEs. In all cases, when the dilatation is small, the pressure \nincreases smoothly (but not linearly). However, when the dila-\ntation is sufficiently large, the pressure experiences a significant \ndrop. At that point, the void collapses completely and the corre-\nsponding pressure is termed the critical pressure. It is consistent \nwith the findings in Ref. [46], where similar trends in void collapse \nwere identified under different loading conditions. The portion of \nthe dilatation-pressure curve prior to the yield point is approxi-\nmately the same for different void radii for the same potential. \nAcross potentials, Fig. 1(e) and (f) demonstrate that the initial \nportion of the dilatation-pressure curve does not change much \nas the ISFE varies (i.e., from Cu1 to Cu7) while its slope increases \nwith the USFE (i.e., from Cu31 to Cu34). There is evidence to sup-\nport this behavior in Ref. [65], which showed that an increase in \nUSFE can affect dislocation motion. We also observe that, the crit-\nical pressure occurs at approximately the same dilatation in Cu1 to \nCu7 which have differing ISFE. For example, when R = 2.316 nm, \nthe critical dilatation is 0.1815 for Cu1, while it is at 0.1932 for \nCu7. Our finding that the ISFE variations did not significantly \naffect the collapse thresholds is in line with Ref. [39]. In contrast, a \nsignificant difference in the critical dilatation is observed between \nCu31 and Cu34. For example, when R = 0.772 nm, the critical \ndilatation is 0.2427 for Cu31, whereas it is at 0.1628 for Cu34. \nOur findings are in accordance with Ref. [64] which indicated that \nthe SE is related to the stabilization of the void structure, thereby \naffecting the critical pressures.\nPorosity‑dilatation response\nWe then analyze the porosity-dilatation responses. Figure  2 \npresents results for two different initial void sizes with all \neleven interatomic potentials. It is observed that the porosity \n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 4\nexperiences two sharp drops. The first drop occurs at e ≈ 0.08 , \ncorresponding to the yield point where dislocations are nucle-\nated from the void surface. The second drop occurs at e ≈ 0.18 , \ncorresponding to the complete closure of the void, which is also \nwhere the critical pressure occurs. From Cu1 to Cu7, a larger \nISFE is found to delay the void closure, in line with a higher \ncritical pressure [Fig.  1(e)]. From Cu31 to Cu34, dislocations \nstart to nucleate at an increasingly larger dilation while the void \nFigure 1:  Pressure-dilatation curves based on different interatomic potentials and/or different initial void radius R. \n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 5\ncollapses at an increasingly smaller dilatation, the latter of which \nis aligned with smaller critical dilatation in Fig.  1(f). The same \ntrends are found for different initial void sizes.\nSelected atomistic structures for the evolution of void with \nR = 2.316 nm are presented in Fig.  3. It is shown that the void \nis first transformed into a stacking fault tetrahedra (SFT), which \nis in agreement with a previous finding in Cu [66], followed by \nthat the SFT is completely closed while more dislocations are \nemitted into the system.\nCritical pressure\nFigure 4 visualizes the relationship among void size, ISFE, USFE, \nSE, and critical pressure. Qualitatively, it is shown that the critical \npressure increases as the ISFE increases or the USFE decreases \nwhich aligns with observations in Ref. [67]. Additionally, there \nexists an intermediate SE that corresponds to the minimum \ncritical pressure. To provide a more quantitative understanding, we \nemploy several surrogate models in the remainder of this section.\nDSO\nIn what follows, we define the normalized initial void radius as \nthe ˜x1 , the three normalized energies as ˜x2 , ˜x3 , and ˜x4 , while the \nnormalized critical pressure as ˜y . The normalization process is \ndescribed in Sect. “DSO”.\nOur DSO regression finds that the following equation estab-\nlishes the relationship between ˜x1 and ˜y , with the help of five con-\nstants ( C1 to C5 ), i.e.,\nThese five constants are related to the three energy terms, i.e., \nnormalized ISFE, normalized USFE, and normalized SE, as \nfollows,\n(1)\n˜yDSO =C1 log(˜x1) − 0.08˜x2.75\n1 + C2 ˜x1.75\n1 + C3 ˜x0.75\n1\n−˜x0.5\n1 −˜x0.25\n1 + C4 ˜x−0.25\n1 + C5\nFigure 2:  Porosity-dilatation curves for (a, b) R = 0.772 nm and (c, d) R = 2.316 nm based on eleven interatomic potentials.\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 6\n(2)C1 = 1√˜x3\n(3)C2 = 0.23˜x2 + 0.29˜x3 + 1.17˜x4 − 0.91\n(4)\nC3 = 8.68˜x2\n2 − 5.64˜x2x3 + 44.81˜x2 ˜x4 − 40.25˜x2 − 14.42˜x2\n3\n− 14.05˜x3 ˜x4 + 37.18˜x3 + 56.35˜x2\n4 − 102.83˜x4 + 36.62\n(5)\nC4 = 0.28˜x3\n2 + 0.58˜x2\n2 ˜x3 − 0.36˜x2\n2 ˜x4 − 1.25˜x2\n2\n− 0.10˜x2 ˜x2\n3 − 1.61˜x2 ˜x3 ˜x4\n− 0.02˜x2 ˜x3 − 0.31˜x2 ˜x2\n4 + 0.63˜x2 ˜x4 + 1.21˜x2\n− 3.23˜x3\n3 + 3.43˜x2\n3 ˜x4 + 3.38˜x2\n3\n− 4.83˜x3 ˜x2\n4 − 2.18˜x3 ˜x4 + 0.86˜x3\n+ 2.42˜x3\n4 + 0.03˜x2\n4 − 0.03˜x4 + 1.61\nThis way, the porous structure (i.e., void radius) is separated \nfrom the material properties (i.e., ISFE, USFE, and SE) in Eq. 1. \nIn the final model, the mean squared error (MSE) and R-squared \nscore are calculated as 0.17 and 0.85, respectively, as shown in \nTable 1.\nDNN\nEach performance metric is averaged over 10 folds to provide \na reliable estimate of model performance. It is found that the \naverage MSE and average R-squared score are 0.124 and 0.956, \nrespectively, as shown in Table 1, indicating that it makes more \naccurate predictions than the DSO model. Specifically after 100 \nepochs, the R-squared scores for training data, validation data, \n(6)C5 =\n√\n˜x4\nFigure 3:  Evolution of the void ( R = 0.772 nm) as a function of the dilatation e based on the (a–c) Cu1 and (a’–c’) Cu34 potentials, respectively. Top row: \nFCC and body-centered cubic atoms are deleted, while hexagonal close-packed atoms indicate dislocations. Bottom row shows the change in void \nshape and size.\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 7\nand testing data are 0.94, 0.91, and 0.8652, respectively, as shown \nin Fig. 5(a). The parity plots of DNN predictions are shown in \nFig. 5(b).\nGPT‑4o\nAs shown in Table  1, the GPT-4o-original model demon-\nstrates the highest performance among the three fine-tuned \nGPT models, achieving an MSE of 0.441 and an R-squared \nscore of 0.872. It is also the fine-tuned GPT model that most \nclosely matches DNN predictions. This indicates that GPT-\n4o-original, equipped with full contextual information, can \neffectively capture the relationships among variables. The high \nR-squared score suggests a strong explanatory power that the \nmodel is able to take advantage of the labels and units of the \ndomain-specific variables to understand complex dependen -\ncies within the data. The relatively low MSE value also shows \nthat GPT-4o-original is beneficial in retaining explicit contex-\ntual cues in the data.\nFigure 4:  Critical pressure as a function of initial void radius and one material property (ISFE or USFE or SE). In each subfigure, different values of \nmaterial property are colored differently.\nTABle 1:  MSE and R-squared score in DSO, DNN, and three GPT-4o mod-\nels. Outputs (in GPa) of the reference point x1 = 2.6248  nm, x2 = 44.1 , \nx3 = 232.01 , x4 = 1169.61  mJ/m 2 from the five models are presented \nin the last row. The atomistic simulation-based value for that reference \npoint is 13.75 GPa.\nDSO DNN\nGPT-4o-orig-\ninal\nGPT-4o-ge-\nneric\nGPT-\n4o-random\nMSE 0.17 0.124 0.441 0.903 0.788\nR-squared 0.85 0.956 0.872 0.738 0.771\nOutput 13.62 13.73 13.63 13.62 13.78\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 8\nAmong the three fine-tuned GPT-4o models, the GPT-\n4o-generic model performs the worst, with a high MSE of \n0.903 and a low R-squared score of 0.738. The lack of explicit \nvariable names and units limits the model’s ability to capture \nthe full complexity of the data. GPT-4o-generic only can rely \non numerical relationships by using variables 1–4 instead of \ndomain-specific labels. This suggests that while the model can \nstill learn patterns in the absence of explicit context, the loss of \ndescriptive variable labels reduces performance.\nThe last model, GPT-4o-random, shows an intermediate \nlevel of performance, with an MSE of 0.788 and an R-squared \nscore of 0.771. The variable names in GPT-4o-random are \ncompletely random strings, with no inherent order or mean-\ning. This extreme abstraction requires the model to explore \nrelationships between numerical values, without being misled \nby generic labels like “variable 1. ” However, the lack of seman-\ntic information probably prevents it from fully optimizing its \nprediction.\nA comparison among the five surrogate models\nBased on the MSE and R-squared score, the performance among \nthe five surrogate models is ranked as: DNN > DSO > GPT-\n4o-original > GPT-4o-random > GPT-4o-generic. Their relative \nperformance can also be assessed by predicting output based \non inputs at a reference point, i.e., 2.6248 nm, 44.1, 232.01, \n1169.61  mJ/m 2 , for which the atomistic simulation output is \n13.75 GPa. Results, summarized in the last row of Table 1, con-\nfirm that the DNN model has the best performance.\nFactors affecting the critical pressure\nTo assess how each input (initial void radius R, ISFE, USFE, and \nSE) affects the output (critical pressure), we apply a perturbation \nmethod, i.e., we individually change each input by ±10 %. As \nshown in Fig. 6, the predicted critical pressure either decreases \nor increases due to the perturbation. The average changes in the \ncritical pressure from the three models (whereas only the mean \nvalue of the three fine-tuned GPT-4o models are shown) are \nsummarized in Table 2. The most accurate model, DNN, shows \nthat SE has the greatest impact on the critical pressure, followed \nby USFE and ISFE, while R has the least impact on the critical \npressure. The importance of the four input parameters is ranked \nthe same according to DSO, but not GPT-4o. For example, the \nthree fine-tuned GPT-4o models, on average, predict USFE as \nthe least important input parameter. Nevertheless, all models \nhighlight the primary role of SE in determining the critical pres-\nsure. The finding is physically intuitive because the critical pres-\nsure corresponds to the complete collapse of the voids, which is \nstrongly associated with the SE. Specifically, a void with a high \nSE requires a large energy penalty to close, while a void with a \nsmall SE requires a higher pressure for the dislocation nuclea-\ntion, postponing the yield event and delaying the void collapse.\nConclusion\nIn this paper, a combined atomistic simulation and surro -\ngate model approach is employed to investigate the effects of \nporous structure and material properties in a void-containing \nFigure 5:  (a) Average R-squared scores for different datasets as a function of epoch. (b) Parity plots of the DNN predictions versus actual data for the \ncritical pressures.\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 9\nCu single crystal. By systematically varying the initial void \nradius, ISFE, USFE, and SE by over one order of magnitude, \natomistic simulations provide 352 sets of data. Subsequently, \ntwo deep learning models (DSO and DNN) and one generative \nLLM (GPT-4o) are applied to provide a quantitative analysis of \nthe data. It is found that (i) a higher ISFE and/or a lower USFE \nlead to a higher critical pressure corresponding to complete \nvoid closure, (ii) there exists an SE (1068.13  mJ/m 2 ) that is \nassociated with the minimum critical pressure (13.25 GPa), \nand (iii) among the four factors (i.e., initial void radius, ISFE, \nUSFE, and SE), SE is the most important factor in determining \nthe critical pressure. We also found that the DNN model out-\nperforms DSO and GPT-4o, with an MSE of 0.124 and an \nR-squared score of 0.956, suggesting that DNN is able to cap-\nture complex, nonlinear relationships among input parameters \nused in our atomistic simulations. The novelty of our work lies \nin systematically combining atomistic simulations with sur -\nrogate models to elucidate the role of multiple factors on void \nbehavior, demonstrating the significant impact of integrating \nphysics-based and data-driven approaches.\nThe current work is not without limitations. First, it is \nimportant to note that the use of quasi-static simulations at \n0 K neglects the influence of thermal vibrations and dynamic \neffects on the behavior of voids under real-world conditions. \nSecond, the controlled variation of only ISFE, USFE, and SE, \nwhile maintaining other material properties constant, may not \nbe sufficient to capture the full complexity of real materials \nwhere multiple properties vary simultaneously. Third, the semi-\nempirical interatomic potentials employed here, while serving \nthe purpose of isolating certain material properties, may not \nbe sufficiently accurate compared with ML-based interatomic \npotentials. These limitations may be addressed in future research \nby incorporating dynamic simulations to model multiple voids, \nFigure 6:  Red dots represent actual data points projected on 2D graphs. Blue, green, and orange lines indicate predictions by DSO, DNN, and GPT-4o \nmodels, respectively, when each input parameter (normalized initial void radius, normalized ISFE, normalized USFE, and normalized SE) is perturbed by \n±10 %. The shaded region indicates the standard deviation around three fine-tuned GPT-4o models.\nTABle 2:  Average change in the critical pressure (in GPa) as a result of \nadding a ±10 % perturbation to each factor — initial void radius R, ISFE, \nUSFE, and SE—with respect to the reference point: 2.6248  nm, 44.1, \n232.01, 1169.61 mJ/m 2 . GPT-4o data are average among three fine-tuned \nmodels.\nModel R ( ±10%) ISFE ( ±10%) USFE ( ±10%) SE ( ±10%)\nDSO 0.008 0.048 1.222 6.141\nDNN 0.093 0.25 0.598 2.29\nGPT-4o 0.219 0.17 0.164 0.467\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 10\nand by expanding the variation of material properties based on \nmore accurate interatomic potentials to enhance generalizability.\nMaterials and methods\nAtomistic simulations\nAtomistic simulations based on the molecular statics (MS) \nmethod [68] are employed here. MS is advantageous to molec-\nular dynamics (MD) that was used in some void-related work \nbecause it can minimize the energy of the voided structure at \neach strain [69]. Thus, MS results provide critical atomic-scale \ninsights into the mechanisms driving void evolution and how \nit affects the critical pressure, without reaching any overdriven \nstate which is common in MD modeling [70]. The open-source \nsoftware package LAMMPS [71] is used. All atomic configura -\ntions are visualized using OVITO [72]. The adaptive common \nneighbor analysis method [73] is used to highlight defects in the \natomistic structure.\nFigure 7(a) illustrates a cubic simulation cell of an FCC sin-\ngle crystal containing a nanovoid. The crystallographic orienta-\ntions are x [100], y[010], and z[001], with periodic boundary \nconditions applied in all directions. Lx0 , Ly0 , and Lz0 , which all \nFigure 7:  (a) Simulation cell of a Cu single crystal containing a spherical nanovoid subject to hydrostatic compression. (b, c) Pressure-dilatation curves \nfor various scaling factors in two simulation cells with the Cu3 potential.\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 11\nequal L0 , are the initial edge lengths of the cell along the x, y, and \nz directions, respectively. Within the cell, a spherical void is cre-\nated by removing all atoms within a specified radius (R) from the \ncentroid. A series of 32 cells are created, with L0 varying from L, \n2L,..., to 32L, where L = 1.456 nm. In each cell, the initial void \nradius R is set such that the initial porosity stays the same, i.e.,\nwhere an initial porosity of 0.5% is chosen as a typical value in \nCu because Kumar et al. [74] found that as-built Cu has a poros-\nity ranging from 0.26 to 1.29%, while heat-treated Cu possesses \na reduced porosity of 0.09–0.1%. In another work, Prithivirajan \net al. [75] found that a porosity of 1% would likely lead to the \nformation of fatigue cracks. As a result of the 0.5% initial poros-\nity in this work, the initial void radius R ranged from 0.1544 to \n4.9408 nm.\nThe material considered in this paper is Cu, which is mod-\neled using eleven embedded-atom method interatomic potentials \n[77]. The first seven potentials, denoted as Cu1, Cu2,..., Cu7, pos-\nsess differing ISFE and SE while the USFE remains approximately \nconstant at 230 mJ/m 2 [78]. The last four potentials, denoted as \nCu31, Cu32, Cu33, and Cu34, were built to predict different \nUSFE and SE while ISFE is constant at about 44  mJ/m 2 [67]. \nDetailed values of the ISFEs, USFEs, and SEs for these potentials \nare presented in Table 3. Prior density functional theory calcu-\nlations in Cu found that its ISFE, USFE [79], and mean SE [80] \nvalues are 41.83, 160.52, and 1456.67  mJ/m 2 , respectively. This \nsuggests that the Cu31 potential is the best in terms of ISFE and \nUSFE, while no potential is associated with a good mean SE.\nAll other material properties, such as lattice parameters, \nelastic constants, and vacancy migration/formation energies, \nare about the same among the eleven potentials. For example, \na uniform lattice parameter a0 = 3.639 Å is used to build the \natomistic structures. In total, 32 void/cell sizes and eleven poten-\ntials are considered, resulting in 352 simulations. In all surrogate \nmodels employed in this paper, the initial void radius R , ISFE, \nUSFE, and SE are treated as input parameters x1 , x2 , x3 , and \nx4 , respectively, while the critical pressure is the only output \nparameter y.\nAfter creating the void by removing atoms within a specified \nsphere, the remaining atomic structure may experience local \nstresses due to the sudden absence of neighboring atoms. To sta-\nbilize the structure, we apply the conjugate gradient algorithm to \nminimize the system’s energy. As a result, the atoms surrounding \nthe void can adjust their positions before any external deforma-\ntion is applied. No structural collapse was observed in any case \nat this time. It follows that, in each simulation, a hydrostatic \ncompressive loading is applied to the cell. A constant scaling \nfactor δ is used such that the three edge lengths are multiplied \n(7)R =\n(\nL3\n0 × 0.005\n4\n3 × π\n)1\n3\nby δ at each MS step, followed by energy minimization using \nthe conjugate gradient algorithm. As δ is closer to 1, the change \nto the simulation cell will be smaller between simulation steps, \nthereby minimizing the artifacts associated with the discrete \nnature of the simulation. However, a small δ will also result in a \nhigh computational cost. To select an appropriate δ , we applied \nmultiple values individually, from 0.999 to 0.9999999, to two \ncells containing a void with R = 0.1544 nm and R = 4.632 nm, \nrespectively, with the Cu3 potential. Results, shown in Fig. 7(b) \nand (c), illustrate that the dilatation-pressure curve converges \nas 1 >δ ≥ 0.999999  . Thus, that threshold δ value is adopted in \nthe remainder of this paper.\nAt each MS step, the three normal strains ( ǫx , ǫy , ǫz ) along \nthe three orthogonal directions are calculated by:\nwhere Lx , Ly , and Lz denote the current edge length of the com-\npressed simulation cell.\nThe three normal strains are related to the dilatation e , \nwhich is the change in the volume of a material, by\nAs the dilatation e  increases, the void size (and porosity) will \ndecrease until the void collapses completely. To measure the \nporosity at any given e , we need to quantify the void volume \nfrom the corresponding atomistic structure. To that end, the \nsimulation cell is divided into many cubic voxels with an edge \nlength of 3.4657 Å, which is between the first nearest neighbor \ndistance (i.e., a0/\n√\n2 ) and the second nearest neighbor distance \n(i.e., a0 ). A voxel is considered part of the void if it is empty, i.e., \nthere is no atom within it [81]. The porosity is then calculated \nas the fraction of empty voxels among the total number of vox-\nels. Since some partially filled voxels will be considered as non-\nempty voxels, the estimated porosity will be smaller than the the \n(8)ǫx = Lx − Lx0\nLx0\n,ǫy = Ly − Ly0\nLy0\n,ǫz = Lz − Lz0\nLz0\n(9)e = ǫx + ǫy + ǫz\nTABle 3:  ISFE, USFE, and SE calculated by eleven interatomic potentials. \nValues of ISFE and USFE were taken from Ref. [76] while those of SE were \nmean values among {100}, {110}, and {111} planes [67].\nPotentials ISFE ( mJ/m 2) USFE ( mJ/m 2) SE ( mJ/m 2)\nCu1 14.63 235.8 1228.35\nCu2 24.89 235.14 1212.33\nCu3 44.1 232.01 1169.61\nCu4 61.54 229.17 1121.54\nCu5 94.41 225.84 1030.75\nCu6 149.61 223.66 907.91\nCu7 185.55 231.83 822.46\nCu31 44.43 159.96 1292.44\nCu32 44.27 197.87 1223.01\nCu33 44.04 266.78 1142.9\nCu34 43.96 302.18 1068.13\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 12\nactual value. As shown in Sect. “ Porosity-dilatation response”,  \nthe estimated initial porosity, around 0.46%, is smaller than the \nactual value, 0.5%. To keep the error consistent, the voxel size \nwill decrease as the simulation cell is compressed.\nDSO\nTo avoid issues with units in the complex expressions, we first \nnormalize the input and output variables by dividing each by \ntheir respective maximum values from the original data. This \nnormalization ensures that all variables are between 0 and \n1, simplifying the mathematical expressions. The maximum \nvalues for void radius, ISFE, USFE, SE, and critical pressure \nare 4.9408 nm, 185.55, 302.18, 1292.44  mJ/m 2 , and 19.62 GPa, \nrespectively. As a result, a data set with values 0.1544 nm, \n44.43, 159.96, 1292.44  mJ/m 2 , and 19.62 GPa would be nor -\nmalized to 0.031, 0.239, 0.529, 1.0, and 1.0, respectively.\nDSO leverages deep learning, specifically a recurrent NN \n(RNN), to generate and optimize mathematical expressions. \nThe process can be broken down into the following steps: \n1. Expression representation.  Mathematical expressions are \nrepresented as trees where internal nodes are operators \n(e.g., +, −, ×, ÷ ) and leaf nodes are either constants or vari-\nables. These trees can be linearized into sequences of tokens \nusing pre-order traversal.\n2. RNN‑based generation. An RNN generates expressions by \nemitting a sequence of tokens. Each token is sampled from a \ncategorical distribution conditioned on the previously gen-\nerated tokens. This process allows the RNN to construct a \ndiverse set of candidate expressions.\n3. Fitness evaluation. Each generated expression is instantiated \nand evaluated based on its fitness, which is the MSE, which \nmeasures the average squared difference between actual and \npredicted values. Formally, the fitness F of an expression f  \nis defined as \n where N is the number of data points, X i is the i-th input, \nand yi is the corresponding output.\n4. Policy gradient optimization. The RNN is trained using a \nrisk-seeking policy gradient algorithm, which optimizes for \nbest-case performance rather than expected performance. \nThe policy gradient update can be expressed as \n where θ represents the parameters of the RNN, p θ (f) is \nthe probability of generating expression f  , and J (θ ) is the \nobjective function.\n(10)F(f) =− 1\nN\nN∑\ni=1\n(\nyi − f(X i)\n)2\n(11)∇θ J(θ ) = Epθ (f)\n[\nF (f)∇θ log pθ (f)\n]\n5. Sampling and training.  During training, expressions are \nsampled from the RNN’s distribution, evaluated, and used \nto update the RNN’s parameters. Over time, the RNN \nadjusts the probabilities to favor expressions with higher fit-\nness scores, thus converging to an optimal or near-optimal \nsolution.\nThe training process of DSO involves iteratively generating, \nevaluating, and refining mathematical expressions. Here are \nthe detailed steps: \n1. Initialization: Initialize the RNN with random parameters.\n2. Expression sampling:  Generate a batch of expressions by \nsampling from the RNN.\n3. Fitness calculation:  Evaluate the fitness of each sampled \nexpression using the dataset.\n4. Policy update: Update the RNN parameters using the risk-\nseeking policy gradient method to maximize the fitness.\n5. Iteration: Repeat the process of sampling, evaluating, and \nupdating until convergence or a predefined stopping crite-\nrion is met.\nRegarding parameter settings, the task type was set to regres ‑\nsion, aiming to derive mathematical expressions that best fit \nthe given dataset. The function_set  was configured to include \nbasic arithmetic operations and other mathematical functions, \nspecifically: [add, sub, mul, div, poly, sqrt, \nlog, const]. The optimization process included a polyno-\nmial optimizer, activated because the poly function was part of \nthe function_set. The polynomial degree was capped at 3, with a \ncoefficient tolerance of 10−6 , using the dso_least_squares \nregressor for fitting the data. This selection provides a diverse \nset of building blocks for constructing the symbolic expressions.\nThe primary metric for the reward function was the inverse \nnormalized root MSE (inv_nrmse), which optimizes the expres-\nsions by minimizing the error between the predicted and actual val-\nues. The metric parameters were set to [1.0]. Training hyperparam-\neters were crucial for effective model learning. A large sample size \nof 2,000,000 was used, with a batch size of 1000, and the ǫ parameter \nwas set to 0.05 to balance exploration and exploitation. The compu-\ntations were performed using a single core (n_cores_batch set to 1), \nalthough utilizing more cores is recommended for enhanced per-\nformance, especially when the const token is included. The policy \noptimizer’s learning rate was 0.0005, with an entropy weight of 0.03 \nand an entropy decay factor (entropy_gamma) of 0.7. These set-\ntings help maintain a balance between exploring new expressions \nand refining the best-performing ones, ensuring that the resulting \nsymbolic expressions were both accurate and interpretable, provid-\ning meaningful insights into the relationship between void radius \nand critical pressure, as influenced by material parameters. Two \nperformance metrics are used: MSE and R-squared score, the latter \n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 13\nof which indicates the proportion of variance in the dependent vari-\nable predictable from the independent variables.\nDNN\nFor data preprocessing, normalization was applied, and the input \ndata and target output are separated. To approximate the func-\ntion y = f(x1 ,x2 ,x3 ,x4 ) , the following layers are used: an input \nlayer with 4 neurons corresponding to the inputs from the data-\nset, a first hidden layer with 50 neurons, a second hidden layer \nwith 40 neurons, and an output layer with 1 neuron correspond-\ning to the output y . The forward pass computations for each \nlayer are as follows: the first hidden layer activations are given by \na1 = σ( W1x + b1) , the second hidden layer activations are given \nby a2 = σ( W2a1 + b2) , and the output layer activations are given \nby y= φ(W 3a2 + b3) , where x =[ x1 ,x2 ,x3 ,x4 ]T is the input vec-\ntor, W1 ,W2 ,W3 are the weight matrices for the respective layers, \nb1 ,b2 ,b3 are the bias vectors for the respective layers, σ is the acti-\nvation function for the hidden layers, and φ is the linear activation \nfunction for the output layer [82].\nThe backpropagation algorithm is utilized to update the net-\nwork’s weights and biases, minimizing the loss function, which is \nthe MSE, i.e.,\nwhere yi is the actual output, ˆyi is the predicted output by the \nnetwork, and n is the number of training samples. The back-\npropagation steps are as follows. The gradient of the loss with \nrespect to the predicted output is computed as:\nThe error is then propagated backward through the network as:\nWith the gradient descent method, the MSE is reduced by \nupdating the weights and bias in the descent direction. The \nweights and biases of the output and hidden layers are updated \nusing the following equations:\n(12)MSE = 1\nn\nn∑\ni=1\n(yi −ˆyi)2\n(13)δoutput= ∂MSE\n∂ ˆy =− 2(y −ˆy)\n(14)δ2 = δoutput · φ ′(W3a2 + b3)\n(15)δ1 = (δ2W T\n2 ) · σ ′(W1x + b1)\n(16)W3 := W3 − η · δoutputaT\n2\n(17)b3 := b3 − η · δoutput\n(18)W2 := W2 − η · δ2aT\n1\n(19)b2 := b2 − η · δ2\n(20)W1 := W1 − η · δ1xT\nwhere η is the learning rate which controls how much the \nweights of an NN change during each iteration. Here, η = 0.01 \nby which the model learns accurately to help the optimization \nprocess converge. σ′ and φ′ are the derivatives of the activa-\ntion functions. To evaluate the model’s generalization capability, \n10-fold cross-validation is employed. The dataset is partitioned \ninto 10 subsets, and the model is trained and validated 10 times, \neach time using a different subset for validation and the remain-\ning subsets for training. The DNN model is trained using 80% \nof the data for training, 10% for validation and 10% for testing. \nSimilar to the DSO model, the DNN model’s performance is \nassessed on unseen dataset using the two metrics: MSE, shown \nin Eq. 12, and R-squared score.\nGPT‑4o\nA popular generative LLM, GPT-4o, is employed. A recent \nstudy found that LLMs’ mathematical reasoning capability may \nbe affected by trivial changes such as those in variable names \n[83]. Hence, we consider three datasets, differing only in how \neach type of data is named. In the first dataset, each data type is \nassociated with an index name (e.g., critical pressure) and units \n(e.g., GPa). This enables the model to interpret and learn rela-\ntionships among variables in a contextually rich setting. In the \nsecond dataset, each type of input data is anonymized by assign-\ning generic names, i.e., “variable 1” through “variable 4, ” while \nthe output (i.e., critical pressure) is renamed as “result, ” with \nall units removed. By eliminating specific contextual clues, this \nsetting intends to assess the model’s adaptability to decontextu-\nalized inputs and to challenge it to identify relationships among \nvariables without relying on units or domain-specific indices. In \nthe third dataset, each type of data is represented by an arbitrary \nalphanumeric string with symbols, such as “#aL@5p!Qx” and \n“G &3*l∧QjZ, ” with units similarly removed. This highest level \nof anonymization presents the model with minimal interpreta-\ntive context. As such, the model needs to learn the numerical \nrelationships between input and output. The goal is to push the \nmodel to its abstraction limits, where both naming conventions \nand units are stripped.\nWith each of these three datasets, we fine-tune a GPT-4o \nmodel, specifically gpt-4o-2024-08-06. As a result, three \ndistinct models are obtained: GPT-4o-original, GPT-4o-generic, \nand GPT-4o-random. Similar to DSO and DNN models, the \nfine-tuned GPT-4o models’ performances are assessed using \nMSE and R-squared score. OpenAI’s auto-configured param-\neter settings are utilized throughout the fine-tuning process. \nTake the second model as an example, its dialogue examples are \nconstructed as follows:\n(21)b1 := b1 − η · δ1\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 14\nAcknowledgments \nThis work used Bridges-2 at the Pittsburgh Supercomputing \nCenter through allocation # MAT230058 from the Advanced \nCyberinfrastructure Coordination Ecosystem: Services & \nSupport (ACCESS) program, which is supported by National \nScience Foundation grants #2138259, #2138286, #2138307, \n#2137603, and #2138296. Some of the computing for this project \nwas performed at the OU Supercomputing Center for Education \n& Research (OSCER) at the University of Oklahoma (OU).\nAuthor contributions \nS.X. designed the project. M.F . and W .C. conducted atom-\nistic simulations. N.T. and Z.Z. developed the DNN model. \nM.Y .A. and T.G. developed the DSO model. X.W . and K.L. fine-\ntuned the GPT-4o model. M.F ., T.G., Z.Z., and X.W . drafted the \nmanuscript. S.X. and M.F . reviewed and edited the manuscript. \nAll authors have read and agreed to the published version of \nthe manuscript.\nFunding \nWe acknowledge the support of the Vice President for \nResearch and Partnerships of the University of Oklahoma (OU) \nand the Data Institute for Societal Challenges. S.X. was sup-\nported by a grant from the Research Council of the OU Norman \nCampus. M.F ., M.Y .A., and S.X. are grateful for the startup funds \nprovided by OU.\nData availability \nThe data presented in this study are openly available at \nhttps:// github. com/ shuoz hixu/ FYRE2 024.\nDeclarations \nConflict of interest The authors declare no conflict of interest.\nOpen Access\nThis article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Com-\nmons licence, and indicate if changes were made. The images \nor other third party material in this article are included in the \narticle’s Creative Commons licence, unless indicated otherwise \nin a credit line to the material. If material is not included in the \narticle’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, \nyou will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit http://creativecom-\nmons.org/licenses/by/4.0/.\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 15\nReferences\n 1. D. Farkas, Atomistic simulations of metallic microstructures. \nCurr. Opin. Solid State Mater. Sci. 17, 284–297 (2013). https:// \ndoi. org/ 10. 1016/j. cossms. 2013. 11. 002\n 2. D. Perez, B.P . Uberuaga, Y . Shim, J.G. Amar, A.F . Voter, Chap-\nter 4 Accelerated Molecular Dynamics Methods: Introduction \nand Recent Developments, in Annual Reports in Computational \nChemistry, vol. 5, ed. by R.A. Wheeler (Elsevier, Amsterdam, \n2009), pp.79–98. https:// doi. org/ 10. 1016/ S1574- 1400(09) 00504-0\n 3. E.A. Barros de Moraes, J.L. Suzuki, M. Zayernouri, Atomistic-to-\nmeso multi-scale data-driven graph surrogate modeling of dislo-\ncation glide. Comput. Mater. Sci. 197, 110569 (2021). https:// doi. \norg/ 10. 1016/j. comma tsci. 2021. 110569\n 4. C. Nyshadham, M. Rupp, B. Bekker, A.V . Shapeev, T. Muel-\nler, C.W . Rosenbrock, G. Csányi, D.W . Wingate, G.L.W . Hart, \nMachine-learned multi-system surrogate models for materials \nprediction. npj Comput. Mater. 5, 51 (2019). https:// doi. org/ 10. \n1038/ s41524- 019- 0189-9\n 5. J.C.S. Kadupitiya, F . Sun, G. Fox, V . Jadhao, Machine learning \nsurrogates for molecular dynamics simulations of soft materials. \nJ. Comput. Sci. 42, 101107 (2020). https:// doi. org/ 10. 1016/j. jocs. \n2020. 101107\n 6. C. Ruiz, A. Raj, S. Xu, Multivariate Gaussian process surro-\ngates for predicting basic structural parameters of refractory \nnon-dilute random alloys. APL Mach. Learn. 2, 026107 (2024). \nhttps:// doi. org/ 10. 1063/5. 01860 45\n 7. S. Liu, B. Bocklund, J. Diffenderfer, S. Chaganti, B. Kailkhura, \nS.K. McCall, B. Gallagher, A. Perron, J.T. McKeown, A compara-\ntive study of predicting high entropy alloy phase fractions with \ntraditional machine learning and deep neural networks. npj \nComput. Mater. 10, 172 (2024)\n 8. K.N. Petersen, M.L. Landajuela, T.N. Mundhenk, C. Pineda \nSantiago, S. Kim, J.J. Thiagarajan, Deep Symbolic Regression: \nRecovering Mathematical Expressions from Data via Risk-\nSeeking Policy Gradients, in Proceedings of the 9th International \nConference on Learning Representations, ICLR, Virtual Confer‑\nence. (2021), https:// openr eview. net/ forum? id= Qlgo4 g5Yh1\n 9. F .L. da Silva, A. Goncalves, S. Nguyen, D. Vashchenko, R. Glatt, \nT. Desautels, M. Landajuela, D. Faissol, B. Petersen, Language \nmodel-accelerated deep symbolic optimization. Neural Comput. \nAppl. (2023). https:// doi. org/ 10. 1007/ s00521- 023- 08802-8\n 10. S.-M. Udrescu, M. Tegmark, A.I. Feynman, A physics-inspired \nmethod for symbolic regression. Sci. Adv. 6 , eaay2631 (2020)\n 11. Z. Xu, N. Yuktanan, M. Liu, T. Gu, M. Shi, Characterization of \nmicrostructures and micromechanical properties of Ti6Al4V \npowders. Powder Technol. 448, 120352 (2024)\n 12. W . Sha, K. Edwards, The use of artificial neural networks in \nmaterials science based research. Mater. Des. 28, 1747–1752 \n(2007)\n 13. S. Feng, H. Zhou, H. Dong, Using deep neural network with \nsmall dataset to predict material defects. Mater. Des. 162, \n300–310 (2019)\n 14. A. Korotcov, V . Tkachenko, D.P . Russo, S. Ekins, Comparison \nof deep learning with multiple machine learning methods and \nmetrics using diverse drug discovery data sets. Mol. Pharm. \n14, 4462–4475 (2017)\n 15. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. \nGomez, Ł Kaiser, I. Polosukhin, Attention is all you need. Adv. \nNeural. Inf. Process. Syst. 30, 5998–6008 (2017)\n 16. A. Radford, Improving language understanding by generative \npre-training, OpenAI Technical Report (2018), https://  cdn. \nopenai. com/ resea rch- covers/ langu age- unsup ervis ed/ langu \nage_ under stand ing_ paper. pdf\n 17. X. Wang, L. Huang, S. Xu, K. Lu, How does a generative large \nlanguage model perform on domain-specific information \nextraction?-a comparison between gpt-4 and a rule-based \nmethod on band gap extraction. J. Chem. Inf. Model. 64, \n7895–7904 (2024). https:// doi.  org/ 10. 1021/ acs. jcim. 4c008 82\n 18. M.P . Polak, D. Morgan, Extracting accurate materials data \nfrom research papers with conversational language models and \nprompt engineering. Nat. Commun. 15, 1569 (2024)\n 19. Y .J. Park, D. Kaplan, Z. Ren, C.-W . Hsu, C. Li, H. Xu, S. Li, J. \nLi, Can ChatGPT be used to generate scientific hypotheses? J. \nMateriomics 10, 578–584 (2024)\n 20. K.M. Jablonka, Q. Ai, A. Al-Feghali, S. Badhwar, J.D. Bocarsly, \nA.M. Bran, S. Bringuier, L.C. Brinson, K. Choudhary, D. Circi \net al., 14 examples of how LLMs can transform materials sci -\nence and chemistry: a reflection on a large language model \nhackathon. Digit. Discov. 2 , 1233–1250 (2023)\n 21. H. Hao, X. Zhang, A. Zhou, Large language models as sur -\nrogate models in evolutionary algorithms: a preliminary study. \nSwarm Evol. Comput. 91, 101741 (2024). https://  doi. org/ 10. \n1016/j. swevo. 2024. 101741\n 22. C. Crussard, J. Plateau, R. Tamhankar, G. Henry, D. Lajeu-\nnesse, A Comparison of Ductile and Fatigue Fractures, in Frac ‑\nture, vol. 1, ed. by E. Name (Wiley, New Y ork, 1959), pp.31–37\n 23. H. Rogers, The tensile fracture of ductile metals. Metal. Soc. \nAIME 218, 498–506 (1960)\n 24. M.F . Horstemeyer, A.M. Gokhale, A void-crack nucleation \nmodel for ductile metals. Int. J. Solids Struct. 36, 5029–5055 \n(1999)\n 25. M. Ashby, C. Gandhi, D. Taplin, Overview No. 3 fracture-mech-\nanism maps and their construction for FCC metals and alloys. \nActa Metall. 27, 699–729 (1979)\n 26. R.N. Gardner, T. Pollock, H. Wilsdorf, Crack initiation at dislo-\ncation cell boundaries in the ductile fracture of metals. Mater. \nSci. Eng. 29, 169–174 (1977)\n 27. M.R.G. Prasad, A. Neogi, N. Vajragupta, R. Janisch, A. Hart-\nmaier, Influence of temperature on void collapse in single crystal \nnickel under hydrostatic compression. Materials 14, 2369 (2021)\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 16\n 28. G.R. Johnson, W .H. Cook, Fracture characteristics of three met-\nals subjected to various strains, strain rates, temperatures and \npressures. Eng. Fract. Mech. 21, 31–48 (1985)\n 29. J.R. Rice, D.M. Tracey, On the ductile enlargement of voids in \ntriaxial stress fields. J. Mech. Phys. Solids 17, 201–217 (1969)\n 30. Y . Guo, C. Paramatmuni, E. Avcu, Void nucleation and growth \nfrom heterophases and the exploitation of new toughening \nmechanisms in metals. Curr. Comput. Aided Drug Des. 13, 860 \n(2023)\n 31. J. Leclerc, M. Marteleur, M.-S. Colla, T. Pardoen, L. Noels, V .-D. \nNguyen, Ductile fracture of high strength steels with morpho-\nlogical anisotropy, Part II: Nonlocal micromechanics-based \nmodeling. Eng. Fract. Mech. 248, 107716 (2021)\n 32. N. Bonora, G. Testa, Plasticity damage self-consistent model \nincorporating stress triaxiality and shear controlled fracture \nmechanisms—model formulation. Eng. Fract. Mech. 271, 108634 \n(2022)\n 33. S. Xu, Y . Su, S.Z. Chavoshi, Deformation of periodic nanovoid \nstructures in Mg single crystals. Mater. Res. Express 5, 016523 \n(2018)\n 34. L. Xiong, S. Xu, D.L. McDowell, Y . Chen, Concurrent atomistic-\ncontinuum simulations of dislocation-void interactions in FCC \ncrystals. Int. J. Plast. 65, 33–42 (2015)\n 35. S. Xu, Y . Su, Nanovoid growth in bcc α-fe: influences of initial \nvoid geometry. Model. Simul. Mater. Sci. Eng. 24, 085015 (2016)\n 36. K. Chen, Y . Zhang, G. Cheng, Y . Zhang, A machine learning and \nfinite element simulation-based void inspection for higher solder \njoint reliability. Microelectron. Reliab. 154, 115323 (2024)\n 37. D. Kong, K. Motoyama, H. Huang, B. Mendoza, M. Breton, G.R. \nMuthinti, H. Shobha, L. Jiang, J. Li, J.J. Demarest et al., Machine \nLearning and Hybrid Metrology Using Scatterometry and LE-\nXRF to Detect Voids in Copper Lines, in Metrology, Inspection, \nand Process Control for Microlithography XXXIII, vol. 10959 \n(SPIE, 2019), pp. 37–50\n 38. A. Saleh, H. Zahedmanesh, H. Ceric, K. Croes, I. De Wolf, \nDynamics of Electromigration Voids in Cu Interconnects: Inves-\ntigation Using a Physics-Based Model Augmented by Neural \nNetworks, in IEEE International Interconnect Technology Confer‑\nence (IITC). (IEEE, 2022), pp.25–27\n 39. G. Potirniche, M. Horstemeyer, G. Wagner, P . Gullett, A molecu-\nlar dynamics study of void growth and coalescence in single \ncrystal nickel. Int. J. Plast 22, 257–278 (2006)\n 40. K. Zhao, C. Chen, Y . Shen, T. Lu, Molecular dynamics study on \nthe nano-void growth in face-centered cubic single crystal cop -\nper. Comput. Mater. Sci. 46, 749–754 (2009)\n 41. S. Traiviratana, E.M. Bringa, D.J. Benson, M.A. Meyers, Void \ngrowth in metals: atomistic calculations. Acta Mater. 56, \n3874–3886 (2008)\n 42. T. Tang, S. Kim, M. Horstemeyer, Fatigue crack growth in mag-\nnesium single crystals under cyclic loading: molecular dynamics \nsimulation. Comput. Mater. Sci. 48, 426–439 (2010)\n 43. T. Tang, S. Kim, M. Horstemeyer, Molecular dynamics simula-\ntions of void growth and coalescence in single crystal magne -\nsium. Acta Mater. 58, 4742–4759 (2010)\n 44. G. Potirniche, J. Hearndon, M. Horstemeyer, X. Ling, Lattice \norientation effects on void growth and coalescence in FCC single \ncrystals. Int. J. Plast 22, 921–942 (2006)\n 45. R. Rudd, E. Seppälä, L. Dupuy, J. Belak, Void coalescence pro-\ncesses quantified through atomistic and multiscale simulation,. J. \nComput. Aided Mater. Des. 14, 425–434 (2007)\n 46. R.E. Rudd, Void growth in bcc metals simulated with molecular \ndynamics using the finnis-sinclair potential. Philos. Mag. 89, \n3133–3161 (2009)\n 47. J. Segurado, J. LLorca, Discrete dislocation dynamics analysis of \nthe effect of lattice orientation on void growth in single crystals. \nInt. J. Plast 26, 806–819 (2010)\n 48. X.-X. Zhang, Z.-S. Cui, Theoretical study of void closure in non-\nlinear plastic materials. Appl. Math. Mech. 30, 631–642 (2009)\n 49. X. Y ang, T. Zhou, C. Chen, Effective elastic modulus and atomic \nstress concentration of single crystal nano-plate with void. Com-\nput. Mater. Sci. 40, 51–56 (2007)\n 50. A. Needleman, Void growth in an elastic-plastic medium. J. Appl. \nMech. 39, 964–970 (1972)\n 51. T. Pardoen, J. Hutchinson, An extended model for void growth \nand coalescence. J. Mech. Phys. Solids 48, 2467–2512 (2000)\n 52. M. Kuna, D. Sun, Three-dimensional cell model analyses of void \ngrowth in ductile materials. Int. J. Fract. 81, 235–258 (1996)\n 53. M. Worswick, R. Pick, Void growth and constitutive softening \nin a periodically voided solid. J. Mech. Phys. Solids 38, 601–625 \n(1990)\n 54. N. Hosseini, J.C. Nieto-Fuentes, M. Dakshinamurthy, J.A. \nRodríguez-Martínez, G. Vadillo, The effect of material orienta-\ntion on void growth. Int. J. Plast 148, 103149 (2022)\n 55. V . Monchiet, O. Cazacu, E. Charkaluk, D. Kondo, Macroscopic \nyield criteria for plastic anisotropic materials containing spheroi-\ndal voids. Int. J. Plast 24, 1158–1189 (2008)\n 56. A.A. Benzerga, J.-B. Leblond, A. Needleman, V . Tvergaard, Duc-\ntile failure modeling. Int. J. Fract. 201, 29–80 (2016)\n 57. S. Xu, Z. Hao, Y . Su, Y . Yu, Q. Wan, W . Hu, An analysis on nano-\nvoid growth in body-centered cubic single crystalline vanadium. \nComput. Mater. Sci. 50, 2411–2421 (2011)\n 58. M. Bhatia, K. Solanki, A. Moitra, M. Tschopp, Investigating \ndamage evolution at the nanoscale: molecular dynamics simu-\nlations of nanovoid growth in single-crystal aluminum. Metall. \nMater. Trans. A 44, 617–626 (2013)\n 59. J. Wang, Z. Yue, Z. Wen, D. Zhang, C. Liu, Orientation effects \non the tensile properties of single crystal nickel with nanovoid: \natomistic simulation. Comput. Mater. Sci. 132, 116–124 (2017)\n 60. Y . Zhang, S. Jiang, X. Zhu, D. Sun, Orientation dependence of \nvoid growth at triple junction of grain boundaries in nanoscale \ntricrystal nickel film subjected to uniaxial tensile loading. J. \nPhys. Chem. Solids 98, 220–232 (2016)\n  Journal of Materials Research  2025  www.mrs.org/jmr\nArticle\n© The Author(s) 2025. 17\n 61. W . Liu, X. Zhang, J. Tang, Y . Du, Simulation of void growth \nand coalescence behavior with 3D crystal plasticity theory. \nComput. Mater. Sci. 40, 130–139 (2007)\n 62. P .M. Anderson, J.P . Hirth, J. Lothe, Theory of Dislocations, 3rd \nedn. (Cambridge University Press, Cambridge, 2017)\n 63. W . Li, S. Lu, Q.-M. Hu, B. Johansson, S.K. Kwon, M. Grehk, J.Y . \nJohnsson, L. Vitos, Generalized stacking fault energy of γ-Fe. \nPhilos. Mag. 96, 524–541 (2016)\n 64. W . Liu, N. Wang, Y . Ji, P . Song, C. Zhang, Z. Y ang, L. Chen, \nEffects of surface energy anisotropy on void evolution during \nirradiation: a phase-field model. J. Nucl. Mater. 479, 316–322 \n(2016)\n 65. M.A. Meyers, A. Mishra, D.J. Benson, Mechanical properties of \nnanocrystalline materials. Prog. Mater Sci. 51, 427–556 (2006)\n 66. B.P . Uberuaga, R.G. Hoagland, A.F . Voter, S.M. Valone, Direct \ntransformation of vacancy voids to stacking fault tetrahedra. \nPhys. Rev. Lett. 99, 135501 (2007)\n 67. V . Borovikov, M.I. Mendelev, A.H. King, Effects of stable and \nunstable stacking fault energy on dislocation nucleation in \nnano-crystalline metals. Model. Simul. Mater. Sci. Eng. 24, \n085017 (2016)\n 68. Y .-R. Jeng, C.-M. Tan, Computer simulation of tension experi -\nments of a thin film using an atomic model. Phys. Rev. B 65, \n174107 (2002)\n 69. O. Vinogradov, A static analog of molecular dynamics method \nfor crystals. Int. J. Comput. Methods 3 , 153–161 (2006)\n 70. H.-J. Lee, B.D. Wirth, Molecular dynamics simulation of \ndislocation-void interactions in BCC Mo. J. Nucl. Mater. 386, \n115–118 (2009)\n 71. A.P . Thompson, H.M. Aktulga, R. Berger, D.S. Bolintineanu, \nW .M. Brown, P .S. Crozier, P .J. Int Veld, A. Kohlmeyer, S.G. \nMoore, T.D. Nguyen et al., LAMMPS-a flexible simulation tool \nfor particle-based materials modeling at the atomic, meso, and \ncontinuum scales. Comput. Phys. Comm. 271, 108171 (2022)\n 72. A. Stukowski, Visualization and analysis of atomistic simula-\ntion data with ovito-the open visualization tool. Model. Simul. \nMater. Sci. Eng. 18, 015012 (2009)\n 73. A. Stukowski, Structure identification methods for atomistic \nsimulations of crystalline materials. Model. Simul. Mater. Sci. \nEng. 20, 045021 (2012)\n 74. A. Kumar, Y . Bai, A. Eklund, C.B. Williams, Effects of hot iso-\nstatic pressing on copper parts fabricated via binder jetting. Proc. \nManuf. 10, 935–944 (2017)\n 75. V . Prithivirajan, M.D. Sangid, The role of defects and critical pore \nsize analysis in the fatigue response of additively manufactured \nIN718 via crystal plasticity. Mater. Des. 150, 139–153 (2018)\n 76. W . Ji, W .-R. Jian, Y . Su, S. Xu, I.J. Beyerlein, Role of stacking fault \nenergy in confined layer slip in nanolaminated Cu. J. Mater. Sci. \n59, 4775–4787 (2024)\n 77. M.S. Daw, M.I. Baskes, Embedded-atom method: Derivation and \napplication to impurities, surfaces, and other defects in metals. \nPhys. Rev. B 29, 6443 (1984)\n 78. V . Borovikov, M.I. Mendelev, A.H. King, R. LeSar, Effect of \nstacking fault energy on mechanism of plastic deformation in \nnanotwinned FCC metals. Model. Simul. Mater. Sci. Eng. 23, \n055003 (2015)\n 79. Y . Su, S. Xu, I.J. Beyerlein, Density functional theory calculations \nof generalized stacking fault energy surfaces for eight face-cen -\ntered cubic transition metals. J. Appl. Phys. 126, 10 (2019)\n 80. R. Tran, Z. Xu, B. Radhakrishnan, D. Winston, W . Sun, K.A. \nPersson, S.P . Ong, Surface energies of elemental crystals. Sci. \nData 3, 160080 (2016). https:// doi. org/ 10. 1038/ sdata. 2016. 80\n 81. A.M. Dongare, A.M. Rajendran, B. LaMattina, M.A. Zikry, D.W . \nBrenner, Atomic scale studies of spall behavior in nanocrystal-\nline Cu. J. Appl. Phys. 108, 113518 (2010)\n 82. I. Goodfellow, Y . Bengio, A. Courville, Deep Learning (MIT \nPress, Cambridge, Massachusetts, 2016)\n 83. I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, \nM. Farajtabar, GSM-Symbolic: Understanding the limitations \nof mathematical reasoning in large language models (2024), \nPreprint at http:// arxiv. org/ abs/ 2410. 05229\nPublisher’s Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.773505687713623
    },
    {
      "name": "Computer science",
      "score": 0.529964029788971
    },
    {
      "name": "Generative model",
      "score": 0.4890194833278656
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4867684841156006
    },
    {
      "name": "Natural language processing",
      "score": 0.33569443225860596
    },
    {
      "name": "Cognitive science",
      "score": 0.3274979293346405
    },
    {
      "name": "Psychology",
      "score": 0.2565386891365051
    }
  ],
  "institutions": [],
  "cited_by": 1
}