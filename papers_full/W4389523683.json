{
  "title": "NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation",
  "url": "https://openalex.org/W4389523683",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A1830218503",
      "name": "Peter West",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A5095654017",
      "name": "Ronan Bras",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2345948848",
      "name": "Taylor Sorensen",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2101359775",
      "name": "Bill Lin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111206870",
      "name": "Liwei Jiang",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2346695291",
      "name": "Ximing Lu",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": null,
      "name": "Khyathi Chandu",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2032101315",
      "name": "Jack Hessel",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2460732137",
      "name": "Ashutosh Baheti",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2071644166",
      "name": "Chandra Bhagavatula",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A2133417374",
      "name": "Yejin Choi",
      "affiliations": [
        "Allen Institute for Artificial Intelligence"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4287111051",
    "https://openalex.org/W4385574293",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4389523929",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4389524372",
    "https://openalex.org/W2946609015",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W3205068155",
    "https://openalex.org/W2466175319",
    "https://openalex.org/W4385574031",
    "https://openalex.org/W4385570549",
    "https://openalex.org/W2998617917",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W4385571309",
    "https://openalex.org/W3034918576",
    "https://openalex.org/W4401042870",
    "https://openalex.org/W3174464510",
    "https://openalex.org/W1975879668",
    "https://openalex.org/W3175270222",
    "https://openalex.org/W4389519535",
    "https://openalex.org/W3196886373",
    "https://openalex.org/W3207166518",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W4307079201",
    "https://openalex.org/W3171639130",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2805206884",
    "https://openalex.org/W4281765689",
    "https://openalex.org/W3034385177",
    "https://openalex.org/W4288262459",
    "https://openalex.org/W4361806395",
    "https://openalex.org/W2995335514",
    "https://openalex.org/W4378509449",
    "https://openalex.org/W4378711565",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W2250653840",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2996908057",
    "https://openalex.org/W4224442590",
    "https://openalex.org/W1552847225",
    "https://openalex.org/W4385573878",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W2164777277",
    "https://openalex.org/W3207553988"
  ],
  "abstract": "Peter West, Ronan Bras, Taylor Sorensen, Bill Lin, Liwei Jiang, Ximing Lu, Khyathi Chandu, Jack Hessel, Ashutosh Baheti, Chandra Bhagavatula, Yejin Choi. Findings of the Association for Computational Linguistics: EMNLP 2023. 2023.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1127–1149\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nNovaCOMET: Open Commonsense Foundation Models with Symbolic\nKnowledge Distillation\nPeter West†‡ Ronan Le Bras‡ Taylor Sorensen†‡\nBill Yuchen Lin‡ Liwei Jiang†‡ Ximing Lu†‡ Khyathi Chandu‡\nJack Hessel‡ Ashutosh Baheti‡ Chandra Bhagavatula‡ Yejin Choi †‡\n†Paul G. Allen School of Computer Science & Engineering, University of Washington\n‡Allen Institute for Artificial Intelligence\npawest@cs.washington.edu\nAbstract\nWe present NOVACOMET , an open common-\nsense knowledge model, that combines the\nbest aspects of knowledge models and general\ntask models. Compared to previous knowledge\nmodels, NOVACOMET allows open-format re-\nlations enabling direct application to reason-\ning tasks; compared to general task models\nlike Flan-T5, NOVACOMET explicitly centers\nknowledge, enabling superior performance for\ncommonsense reasoning.\nNOVACOMET leverages the knowledge of\nopaque proprietary models to create an open\nknowledge pipeline. First, knowledge is sym-\nbolically distilled into NOVATOMIC , a publicly-\nreleased1 discrete knowledge graph which can\nbe audited, critiqued, and filtered. Next, we\ntrain NOVACOMET on NOVATOMIC by fine-\ntuning an open-source pretrained model. NO-\nVACOMET uses an open-format training ob-\njective, replacing the fixed relation sets of past\nknowledge models, enabling arbitrary struc-\ntures within the data to serve as inputs or out-\nputs.\nThe resulting generation model, optionally aug-\nmented with human annotation, matches or ex-\nceeds comparable open task models like Flan-\nT5 on a range of commonsense generation\ntasks. NOVACOMET serves as a counterex-\nample to the contemporary focus on instruction\ntuning only, demonstrating a distinct advantage\nto explicitly modeling commonsense knowl-\nedge as well.\n1 Introduction\nWe present NOVACOMET , an open commonsense\nknowledge model combining the advantages of\nboth knowledge models and general task models.\nNOVACOMET models commonsense knowledge\nwith an open format, allowing it to be applied\nto general reasoning tasks in contrast to previous\nknowledge models. Compared to simply training\n1Our resources are available at novacomet.dev\nNovaCOMET\nNovATOMIC\nClosed LLM\nGoing to School \n[MASK] \n[MASK]\nWhat should you bring? \nLunch, textbooks, \nstationary\n[MASK] \nWho is there besides Eliza? \nParents, referees\nEliza is playing \nin a school \nsoccer game\nCaption: Knowledge is distilled from strong LLMs such as gpt-3 turbo, which allows auditable \ntransfer of knowledge that prevents issues like data contamination (CITE) that may plague \nopaque proprietary models. The ﬁnal trained model learns to ﬁll in any part of the knowledge \n— beyond simply answering a query[orange], NovaCOMET can e.g. predict what \ncontext[green] would make a query[orange] + inference[purple] likely. \nOpen Data\n Open Model\nOpen Format\nFigure 1: We leverage opaque-but-powerful proprietary\nLLMs into an open commonsense pipeline by: (i) creat-\ning an auditable knowledge baseNOVATOMIC that gives\nfine-grained control over included knowledge, (ii) en-\nsuring the generated knowledge uses a higher-coverage\nopen-format with natural-language queries as relations\nand flexible mask-filling to allow for more open com-\nmonsense use-cases, (iii) demonstrating the effective-\nness of (i) and (ii) via NOVACOMET ’s superior perfor-\nmance on a number of tasks, under both automatic and\nhuman evaluations.\nmodels to be open task solvers (e.g. instruction tun-\ning) we find that explicitly modeling knowledge in\nNOVACOMET also provides a distinct advantage,\nwith NOVACOMET showing similar or superior\nperformance to comparable open task models on a\nrange of commonsense reasoning benchmarks.\nFor NOVACOMET , we leverage opaque, pro-\nprietary models like ChatGPT or GPT-4 (Ouyang\net al., 2022; OpenAI, 2023) as the knowledge\nsource in an open commonsense pipeline (Figure 1).\nSuch models have demonstrated remarkable com-\nmonsense ability (Bubeck et al., 2023; Bian et al.,\n2023) yet, closed and opaque, their direct useful-\nness for studying commonsense is limited. Without\ninformation about training or direct access to the\nmodel, it is impossible to study where reported\ngains come from—e.g. the extent of test set con-\ntamination with benchmarks.\nIn our work, we use these models first to gener-\n1127\nate an open knowledge base (NOVATOMIC , §2.1),\nwhich can be analyzed, improved, and verified\nagainst test set contamination. Next, we train an\nopen commonsense model (NOVACOMET , §2.3)\non this knowledge: the underlying data and code\nwill be released along with the model for the study\nof commonsense. This allows future testing of\nNOVACOMET (and of other models based on NO-\nVATOMIC ) to analyze the training set—essentially\nallowing us to distill information from a base LLM\ninto an auditable format.\nIn training NOVACOMET , we also use an open\nformat: compared to previous knowledge models\nwhich use a fixed relation set and training order\n(head + relation →tail) we use natural language\nqueries as relations, and allow masked generation\nof all aspects of the data. This allows our model\nto be used in a wide range of general reasoning\ntasks, thus addressing a significant limitation of\nprior knowledge models that are limited to down-\nstream applications capable of effectively leverag-\ning their restricted set of relations. Enabling an\nopen format also allows the knowledge generation\nto focus on pertinent aspects of the context, rather\nthan forcing the generation of inferences for arbi-\ntrary, potentially irrelevant relations.\nFollowing past work on symbolic knowledge\ndistillation (West et al., 2022), we also use NO-\nVATOMIC as the basis for training a plausibility\nmodel with human annotations (§2.2), and study\nhow this can improve NOVACOMET (§2.3).\nWe test NOVACOMET on a range of common-\nsense generation tasks, and find that it consistently\noutperforms general task models of comparable\nsize, such as Flan-T5xxl (Chung et al., 2022a) and\nT0 on commonsense tasks like abductive infilling\nand explanation generation. Furthermore, we as-\nsess the ability of our plausibility model to handle\ngeneral commonsense QA tasks and observe that\nit achieves comparable or superior discriminative\nperformance on a range of tasks. NOVACOMET\nwill serve as an open resource for studying com-\nmonsense, and an example of the advantage of\nexplicitly modeling commonsense knowledge in\ncontrast to general task modeling alone.\n2 N OVACOMET: open commonsense\nmodels\nNOVACOMET is a large-scale, open common-\nsense model that can handle both explicit knowl-\nedge generation, and tasks that require common-\nsense reasoning.\nNOVACOMET is trained with symbolic knowl-\nedge distillation (West et al., 2021) by combin-\ning the commonsense data generated by large lan-\nguage models (§2.1) with high-quality annotations\nof knowledge plausibility (§2.2). We experiment\nwith multiple methods for combining generated\ndata with plausibility information (indicating how\nlikely a given knowledge is) to train the final model,\nNOVACOMET (§2.3).\n2.1 Generating Open Commonsense Data\nFollowing symbolic knowledge distillation (West\net al., 2021), we distill large quantities of high-\nquality knowledge from very large, general founda-\ntion models (§2.1.1) – we call the resulting dataset\nNOVATOMIC . One major difference from previous\nknowledge graphs is that we allow an open rela-\ntion set, in the form of queries rather than fixed\nrelation tokens. While commonsense knowledge\noften takes a head, relation, tail format with a\nfixed set of discrete relations (e.g. X buys a lot-\ntery ticket, xWant, to win.), we propose a context,\nquery, inference (CQI) format with natural lan-\nguage queries serving as open relations. We also\nanalyze unique properties of this distilled knowl-\nedge in §2.1.2.\n2.1.1 Data Generation\nWe outline the generation process below, which\nconsists of (1) generating contexts and (2) generat-\ning queries/inferences, resulting in our new knowl-\nedge base, NOVATOMIC .\nContext Generation. First, we have experts gen-\nerate 21 varied prompts to steer models to gen-\nerate events or situations that require common-\nsense knowledge to fully understand (see B.1 for\nall prompts used). As variations in prompt wording\ninfluence the model’s output, we use many different\nprompts to enhance both diversity and coverage of\nthe generated outputs. Half of the time, we generate\ncontexts in a zero-shot manner, while for the other\nhalf, we do one-shot generation with one example\ndrawn from ATOMIC10 X (West et al., 2022). In\norder to reduce generation cost, we generate 20\nsituations per prompt (batched generation).\nWe generate the contexts using GPT-3 (Brown\net al., 2020) variant text-davinci-003 (Ouyang\net al., 2022) for a total cost of USD $39.56. We set\ntop_p=0.99 and presence_penalty=0.3, lower-\ning the logit values for tokens that have already\n1128\noccurred to promote diversity within each batch.\nFinally, to allow NOVACOMET to see some di-\nversity of names, we also randomly swap all enti-\nties (names or \"PersonX/Y/Z\") for a name drawn\nfrom the 2021 public US social security application\nname registry2 with probability 0.5.\nQuery/Inference Generation. As no other re-\nsource currently has examples of high-quality com-\nmonsense inferences in our proposed open for-\nmat, we develop a set of few-shot examples of\n10 contexts (either handwritten or selected from\nATOMIC10 X or from ROCStories (Mostafazadeh\net al., 2016)) with 10 handwritten commonsense\nquery/inference pairs for each (see Appendix B.2\nfor more details). These query/inference pairs\ncover a broad swathe of knowledge, including con-\nsequences, explanations, reactions, attributes, coun-\nterfactuals, etc.\nFor each context in NOVATOMIC generated in\nthe previous step, we randomly select and permute\nn ∼Uniform(1,10) of the few-shot examples to\nprovide in context after the instructions and then\ntask the model with generating 10 query/inference\npairs for the new context. The rationale for this\nrandom selection and permutation of the few-shot\nexamples is to mitigate the potential overfitting\nto a specific ordering or selection or ordering of\nhandwritten examples. To try to support the use\ncase where a desired commonsense query is not\nknown in advance, e.g. when a user simply want\ngeneral knowledge for a given context, we also\ngenerated half of the commonsense hypotheses\nwithout generating a query first (prompt in B.2).\nAt training time (§2.3), we input a NULL value\nfor the query field. We generated all query/in-\nference pairs using default decoding arguments\nwith gpt-3.5-turbo-0301 for a total cost of USD\n$337.16.\n2.1.2 Analysis\nComparison to Previous CSKGs. Table 1\nshows the comparisons of NOVATOMIC to exist-\ning CSKGs, ATOMIC 2020 (Hwang et al., 2020) and\nATOMIC10 X (West et al., 2022) in dataset statis-\ntics and lexical diversity measures. NOVATOMIC\ncontains more diverse unique premises (heads) and\nhypotheses (tails) as indicated by the higher num-\nber and/or percentage of these data entries. NO-\nVATOMIC also has higher lexical variations, as re-\n2https://catalog.data.gov/dataset/baby-names-from-\nsocial-security-card-applications-national-data\nType Dataset\nATOMIC\nEntries 3-grams\n# % # %\nContext\n&\nEvent\n2020 43,958 3.5 40,194 55.8\n10X 165,783 2.6 235,172 44.9\nNOVA 102,195 4.7 343,636 44.6\nQuery\n&\nRelation\n2020 23 - - -\n10X 7 - - -\nNOVA 822,615 79.2 1,609,780 28.7\nInference\n&\nTail\n2020 602,154 48.3 847,913 52.5\n10X 874,417 13.5 695,877 21.0\nNOVA 2,030,488 93.2 5,835,099 30.0\nTotal\n2020 1,246,582 - 875,157 51.9\n10X 6,456,300 - 812,166 21.1\nNOVA 2,178,086 - 7,224,608 28.0\nTable 1: Statistics of NOVATOMIC compared to exist-\ning CSKG, ATOMIC 2020 and ATOMIC10 X. # and %\nindicate the count and percentage of unique entries or\n3-grams, respectively. Compared to previous CSKGs,\nNOVATOMIC contains more diverse entries with higher\nlexical variations. Notably, as NOVATOMIC adopts open\ndata format by breaking out from fixed relation types, it\ncontains much more diverse and flexible sets of relations\ndenoted with questions that tie premise and hypothesis\ntogether.\nflected by the significantly more diverse 3-grams.\nIn particular, as NOVATOMIC breaks out from\nfixed relation types with open questions to connect\npremise and hypothesis, it contains much more\ndiverse and flexible sets of relations denoted by\nnatural language questions.\nIt is also of note that, based on estimates from\n(West et al., 2022), the total cost of ATOMIC 2020\nand ATOMIC10 X were approximately USD\n$40,000 and USD $6,000 respectively, whereas\nthe cost for NOVATOMIC is approximately $400.\nThough the size of NOVATOMIC is somewhat\nsmaller, the unit cost per example is also signif-\nicantly lower.\nAnalysis of Question Types. To delve into what\nrelations are encoded in NOVATOMIC with open\nquestions, we conduct an analysis of question types.\nFigure 2 shows the top 10 most common ques-\ntion prefixes, including open-ended question types,\nsuch as what and how, and binary yes/no ques-\ntion types, such as is and will. By grouping WH-\nquestions together (i.e., how, what, why, who,\nwhere, when, whose, which), we obtain 81.1% of\nopen-ended questions and 18.9% of binary yes/no\nquestions, indicating a diverse and flexible relation\nspace the large portion of free-form questions repre-\nsent, as shown in Figure 2(b). Table 2 shows some\n1129\nFigure 2: (a) The most frequent question prefixes. (b)\nThe composition of open-ended vs. yes/no questions.\nMost Frequent Questions\nWhat time is it?\nWho is PersonX?\nWhat is the weather like?\nWhat is the prerequisite for this situation?\nWhat is the consequence of the situation?\nWhat is the counterfactual of the situation?\nWhat will happen next?\nWhat is the occasion?\nWhat is the relationship between PersonX and PersonY?\nWhere are they?\nTable 2: Frequent queries in NOVATOMIC . Note that\nwe take the top 100 surface forms, and cluster them into\nsemantically related/equivalent groups by hand. Queries\nabove represent the top groups by aggregate count, with\nindicative labels. See Appendix A for more details.\nof the most common questions in the dataset. The\nmost common questions are not context-specific\n(asking about time, weather, or location), although\nwe find that many of the queries do condition specif-\nically on context.\n2.2 Plausibility Annotation\nNext, we collect annotations of CQI data plausi-\nbility. Broadly, this follows West et al. (2022);\nHoward et al. (2023) in combining generated data\nwith an automatic critic to maximize the quality\nof a final trained model. In this case, however, we\nexplore multiple ways to incorporate annotations\nof plausibility into the final model NOVACOMET\n(§2.3.2).\nOur primary means of collecting annotations of\nplausibility is through Amazon Mechanical Turk.\nWe use a similar annotation template to (Hwang\net al., 2020) (see Appendix C), asking annota-\ntors to decide if knowledge is always/often, some-\ntimes/likely, farfetched/never true, or invalid (giv-\ning these annotations a score of 3, 2, 1, 0 respec-\ntively). We consider any knowledge scored 3 or 2\nto be plausible.\nIn practice, we collect 20k annotations, with 1\nannotator per example. For underlying data, we use\n16k examples from NOVATOMIC , as well as 2k ex-\namples each from ATOMIC10 X and ATOMIC 2020\nto increase diversity of annotated knowledge style.\nWhile these knowledge graphs have fixed relation\nsets, we use sample natural language queries to\nreplace the discrete relations (e.g. xNeed →What\ndid PersonX need?).\nWe conduct a human agreement study on a seg-\nment of 200 examples for which we elicit 3 annota-\ntions each, finding Fleiss κ(Fleiss, 1971) of 0.317\nindicating fair agreement (Landis and Koch, 1977).\n2.3 Training N OVACOMET\n2.3.1 Commonsense field masking\nPrevious knowledge models tend to use a standard\nhead,relation →tail format in training, generating\nsome inference given the situation/concept, and\none of a set of possible commonsense relations to\nguide generation.\nThe goal of NOVACOMET is maximum flex-\nibility in handling commonsense knowledge and\ntasks, meaning we would like to generate any of\nthese fields from any others. For example, we may\nwant to generate a likely query that connects the\ncontext and inference; or, a context under which\nthe query and inference are correct. To this end, we\npropose commonsense field masking, wherein we\nrandomly sample subspans of fields to be masked\nfor prediction, e.g.\nInput:\nContext: Consider the list of MASKC shows.\nQuery: What is the MASKQ show?\nInference: Hamilton\nTarget:\nMASKC = Broadway\nMASKQ = most popular\nThe process of masking follows two steps. First,\nthe set of which fields (CQI) will be masked is\nuniformly selected from all options in which at\nleast one field is masked. Second, for each field,\nwe randomly (with p=0.5) decide whether to mask\nthe entire field, or a subspan. Finally, for those\nfields where a subspan is masked, we uniformly\nselect the mask length, and which subspan of the\ngiven length to mask.\nIn effect, this gives the final model maximal flex-\nibility at inference time. Users can mask any field,\neither the full span or infill a subspan as needed,\nallowing for use cases besides simply generating a\nfull inference as in previous commonsense models.\n1130\nWe explore how this can be especially useful in\n§3.2.\n2.3.2 N OVACOMET Versions\nWe consider a variety of methods to use the genera-\ntion and critique data described above for training.\nGeneration-only Model First, we consider the\nsimplest option for producing a commonsense gen-\neration model: training directly on NOVATOMIC .\nNOVACOMET base is trained only on generation\ndata from §2.1 with the commonsense masking\nobjective (§2.3.1). Plausibility is not used in this\nmodel.\nCritic-only Model Second, we train a stand-\nalone plausibility critic model, NOVACOMET crit.\nThis is trained to generate a plausibility score from\na complete CQI (context, query, inference) knowl-\nedge triple, on the annotation set from §2.2. In\neffect, it returns a probability that a given CQI is\nplausible.\nFiltered Generation Model Following West\net al. (2022), we use a simple filtering-based tech-\nnique for improving generation with plausibility\nscores. Using NOVACOMET crit, we calculate the\nprobability of being plausible for all examples in\nNOVATOMIC , and filter to only those points that\nmeet a minimum probability. We focus on one\nthreshold in particular, 0.99, indicating that NOVA-\nCOMET crit gives at least 0.99 probability to the\ngiven CQI being plausible. We call the resulting\nmodel NOVACOMET filter−0.99, and the resulting\nfiltered training set retains over 50% of its origi-\nnal size, indicating NOVATOMIC is already high\nquality.\nQuantized Reward Conditioning Inspired by\nquantized reward conditioning in (Lu et al., 2022),\nwe also consider more closely unifying the critical\nand generation data. We consider a light-weight,\none-step approach (as opposed to full reinforce-\nment learning in Lu et al. 2022) in which we an-\nnotate NOVATOMIC with NOVACOMET crit, then\ntrain a masked-prediction model that includes plau-\nsibility as a conditioning variable for predicting\nCQI. For annotation with NOVACOMET crit, we\ngreedily decode plausibility, and train a reward-\nconditional model NOVACOMET rc. When decod-\ning with NOVACOMET rc, we condition on either\nof the “plausible” labels (2 or 3) from §2.2.\n2.3.3 Model Training\nWe use the T5X codebase (Roberts et al., 2022)\nto train NOVACOMET , using the base T5 1.1 xxl\n(∼11B parameters) checkpoint to initialize all of\nour experiments. We train all models on v3-128\nTPU pods, using a batch size of 128 and a learning\nrate of 1e-5. For generation models, we train for a\nfixed 100k training steps, ensuring that loss does\nnot converge or begin increasing. For models that\ninclude plausibility prediction as an objective, we\nstop training when evaluation loss for plausibility\nconverges, which is often significantly before 100k\ntraining steps.\n3 Experiments\n3.1 Evaluating Plausibility\nWe begin by evaluating the performance of our\nplausibility model NOVACOMET critic. Particu-\nlarly, we aim to understand the ability of this model\nto provide a useful, absolute plausibility score. We\ncompare the accuracy of our plausibility scores on\ndiscriminative commonsense benchmarks to judge\nits effectiveness.\n3.1.1 Datasets\nWe consider a range of standard discrimina-\ntive commonsense benchmarks: HellaSwag (HS)\n(Zellers et al., 2019) for generation recognition;\nαNLI (Bhagavatula et al., 2019) for abductive\nreasoning; WinoGrande (WG) (Sakaguchi et al.,\n2019) for pronoun resolution; Commonsense QA\n(CSQA) (Talmor et al., 2019) and CODAH (Chen\net al., 2019) for general commonsense question\nanswering; Social IQA (SIQA) (Sap et al., 2019)\nfor social commonsense; RiddleSense ( RS) (Lin\net al., 2021) for riddle answering; and Physical IQA\n(PIQA) (Bisk et al., 2019) for physical common-\nsense. Together, these allow us to judge the ability\nof models to assess the correctness/plausibility of\ncommonsense.\n3.1.2 Models and Baselines\nAs baselines, we primarily consider popular lan-\nguage models in a roughly similar range of pa-\nrameter sizes. We include basic language model\nLLaMA (Touvron et al., 2023) and PaLM (Chowd-\nhery et al., 2022) (citing performance directly for\nboth); and language models with general task tun-\ning such as QA for Macaw (Tafjord and Clark,\n2021) or instruction tuning for Flan-T5xxl (Chung\net al., 2022b) and T0 (Sanh et al., 2021). We create\n1131\nstandard-format prompts that depend on the model.\nWhen possible, models are given answer choices\nas input. This is an advantage over plausibility\nmodels like NOVACOMET crit which are designed\nto judge answers in isolation, but we include this\nto maximize baseline quality. To score options\nof baselines, we use negative-log-likelihood, as\nit was found by us to be best out of a range of\noptions. We cite results for an alternative format-\nting for prompting FLAN from (Liu et al., 2023)\nwhich automatically reformats commonsense ques-\ntions as statements, then judges plausibility as the\nlikelihood of answering “yes” or “no” to whether\nthe statement is plausible. We note that, while this\nmethod performs well, it will not generally apply to\nContext-Query-Inference (CQI) formatted data, as\nnot all CQI examples can be naturally reformatted\ninto short statements, but we include this baseline\nfor completeness. We also cite results on GPT-3.5,\nChatGPT, and GPT-4 from the same paper.\nWe compare baselines to NOVACOMET crit de-\nscribed in §2.3. For this models, we score options\nbased on the probability of predicting 2 or 3 for\nplausibility (sometimes/likely or always/often true),\nrenormalized against the probability of predicting\n1 or 0 (rarely or never true, or invalid).\n3.1.3 Results and Discussion\nModel scores on various tasks requiring common-\nsense knowledge can be seen in Table 3. While\nvarious models are better at different tasks, NOVA-\nCOMET crit is tied for most combined 1st + 2nd\nplace results (5). Note that the other tied system,\nFlan-T5 (statements) requires automatically trans-\nforming each problem into a yes or no question; a\ntransformation that is not generally applicable to\nthe kinds of Context-Query-Inference style prob-\nlems we would like to solve when deriving com-\nmonsense information from a model.\nLooking at cases where NOVACOMET crit fails\nto get the highest accuracy, it is perhaps unsurpris-\ning that PaLM 540B and 62B outperform all other\nmodels on HellaSwag, which requires predicting\nthe most likely continuation of a scene descrip-\ntion, a task especially well suited to a raw language\nmodel. Furthermore, with Physical IQA (PIQA),\nthe focus is on physical commonsense, a subcat-\negory that our base generator seemed to produce\nless naturally on inspection.\nWe also note that many baselines (e.g. Macaw,\nT0) assume access to all answer choices. For our\nuse case (judging knowledge within NOVATOMIC\nto improve the overall dataset) we are judging ex-\namples in isolation with no clear contrastive ex-\namples. The competitive performance of NOVA-\nCOMET crit here, despite such disadvantages, fur-\nther validates it for this use case.\n3.2 Evaluating Generation\nThe central goal of NOVACOMET is in generating\ncommonsense knowledge, and carrying out com-\nmonsense reasoning. In this section, we test the\nability of various versions of NOVACOMET de-\nscribed in §2.3 to do this. Note that we primar-\nily use human evaluation for model generations,\nfollowing a similar setup to §2.2 with annotation\ntemplates available in Appendix C.\n3.2.1 Datasets\nFirst, we test the ability of models to generate com-\nmonsense knowledge in the format of previous\nknowledge models. Particularly, we take a sam-\nple of ATOMIC 2020 (Hwang et al., 2020) common-\nsense prompts (head + relation), testing the ability\nof models to generate a valid tail. Results are in-\ncluded in Table 4.\nNext, we test on various downstream bench-\nmarks requiring generative commonsense reason-\ning. First, we test abductive natural language gener-\nation (αNLG) (Bhagavatula et al., 2019), wherein\nmodels must abductively fill in the gap in a story\nbetween two observations. We also consider two\nquestion-answering datasets that require common-\nsense reasoning: TellMeWhy (Lal et al., 2021) in\nwhich models explain events, and Reflect (Zhou\net al., 2022) in which models generate ATOMIC -\nstyle inferences for dialogues. We report results for\nall downstream reasoning benchmarks in Table 3.\nWe use a custom annotation template for αNLG,\nand otherwise use the base CQI template from our\nannotation in §2.2.\n3.2.2 Baselines and Models\nFor baselines, we include all of the models de-\nscribed in §3.1 as well as T5xxl (∼11B parameters)\nfinetuned for language modeling (T5-LM) (Raffel\net al., 2019). We use straightforward prompts to\ndescribe each task and generate directly.\nDifferent datasets can demonstrate unique ways\nto use the commonsense masking of NOVA-\nCOMET for generation. For example, for αNLG,\nwe mask between the beginning ( o1) and ending\n(o2) events to form a natural sequence:\n1132\nsystem HS αNLI CODAH WG CSQA SIQA CosmosQA RS PIQA\nCited Results\nGPT-3.5 70.4 76.6 85 72.5 66.9 65.3 - - 84.2\nChatGPT 43.0 60.3 56.8 61.3 39.6 52.2 - - 67.6\nGPT-4 40.0 75.0 66.0 77.0 43.0 57.0 - - 73.0\nFlan-T5 (statements)1 64.5 80.8 89.6 84.7 69.2 73.2 - - 83.9\nllama-7B2 76.1 - - 70.1 - 48.9 - - 79.8\nllama-13B2 79.2 - - 73.0 - 50.4 - - 80.1\nPaLM 62B3 79.7 - - 77.0 - - - - 80.5\nPaLM 540B3 83.4 - - 81.1 - - - - 82.3\nComparable General Models\nMacaw 50.8 71.6 82.9 60.7 79.4 68.8 70.4 58.8 79.4\nFlan-T5xxl 73.5 70.7 58.7 72.9 72.8 55.2 72.9 60.6 82.0\nT0 63.7 70.3 73.4 58.9 68.1 66.8 75.4 53.8 84.9\nNOVACOMET crit 74.4 80.4 86.7 79.6 76.7 77.1 80.3 58.6 83.4\nTable 3: Comparison of model scores on commonsense benchmarks. Best results are bold and second best are\nunderlined. Note that no other method surpasses NOVACOMET crit the combined number of 1st and 2nd place\nresults (5). Comparison using absolute scores from different models. 1 indicates values cited from (Liu et al., 2023)\nwhich uses a pipeline with Flan-T5xxl, 2 indicates values cited from (Chowdhery et al., 2022), 3 indicates values\ncited from (Touvron et al., 2023). Values for large, recent GPT models (GPT-3.5, ChatGPT, GPT4) are cited from\n(Liu et al., 2023).\nαNLG Reflect TellMeWhy ATOMIC 2020\nsystem obs2 obs1 obs1+2 overall valid valid valid\nBaselines\nLLaMA-7B 0.030 0.025 0.022 0.013 0.388 0.463 0.470\nLLaMA-13B 0.010 0.008 0.012 0.008 0.456 0.442 0.515\nT0 0.260 0.258 0.235 0.248 0.846 0.759 0.686\nAlpaca-7b 0.162 0.123 0.120 0.122 0.687 0.852 0.612\nAlpaca-13B 0.355 0.313 0.290 0.248 0.716 0.764 0.660\nFlan-Ul2 0.715 0.627 0.605 0.622 0.618 0.562 0.692\nFlan-T5xxl 0.735 0.653 0.635 0.657 0.796 0.807 0.757\nNOVACOMET\nNOVACOMET base 0.877 0.826 0.819 0.814 0.864 0.928 0.847\nNOVACOMET filter−0.99 0.887 0.837 0.837 0.827 0.864 0.916 0.848\nNOVACOMET rc(2) 0.837 0.793 0.787 0.797 0.874 0.916 0.861\nNOVACOMET rc(3) 0.840 0.797 0.780 0.787 0.869 0.918 0.859\nTable 4: Human evaluation of various commonsense generation tasks. Note that the basic version of NOVACOMET\noutperforms baselines consistently, but is outperformed by versions that use plausibility to improve. We find human\nagreement with Fleiss κ(Fleiss, 1971) of 0.32, 0.44, 0.43, 0.39 (respective to order in the table) indicating fair to\nmoderate agreement. Note, values in this table are normalized to a [0,1] range.\nInput:\nContext: <o1> MASKC\nQuery: What happens next?\nInference: <o2>\nTo predict a hypothesish that fits betweeno1 and\no2. We found this resulted in much higher quality\ngenerations than encoding o1, o2 as context and\npredicting h as inference.\nFor other datasets (Reflect, TellMeWhy,\nATOMIC 2020), we can encode examples simply\nby giving context and query, then predicting the\ninference. For all models, we use greedy decoding.\n3.2.3 Results and Discussion\nAll generation results use human evaluation, pre-\nsented in Table 4. Note that human evaluation\ntemplates are included in the Appendix. We evalu-\nate 100 examples for each system and dataset. For\nReflect, TellMeWhy, and ATOMIC 2020, we use the\nsame template as §2.2. For αNLG we use a tem-\nplate measuring coherence between the generated\ninfill and either or both hypotheses, as well as over-\nall quality. All scores in Table 4 are normalized to\n1133\na range between 0 and 1.\nNote that NOVACOMET models win across the\nboard. Particularly effective is the filtered model\nNOVACOMET filter−0.99, but so are the reward\nconditional models, and NOVACOMET rc(2) in par-\nticular, conditioned on “2” (likely/sometimes true)\nrather than “3” (always/often true). It is possible\nthat answers that are always true are somewhat less\ncreative or preferable to humans.\nIn general, the NOVACOMET models that use\nplausibility information outperform the basic NO-\nVACOMET base, other than on the TellMeWhy\ndataset. This demonstrates a particular advantage\nof distilling discrete data – it can be annotated, and\nthose annotations can improve downstream perfor-\nmance.\nOverall, superior performance ofNOVACOMET\nsuggests that explicitly modeling knowledge can\nprovide an advantage, at least considering tasks\nthat explicitly require commonsense knowledge\nand reasoning.\n4 Related Work\nKnowledge Generation Pretrained language\nmodels demonstrated the ability to carry implicit\nknowledge (Petroni et al., 2019; Dhingra et al.,\n2022). These large language models are prompted\nfor generating new knowledge to perform down-\nstream tasks such as text classification (Shin et al.,\n2020; Puri and Catanzaro, 2019), commonsense\nreasoning (Liu et al., 2022b; Trinh and Le, 2018;\nDavison et al., 2019). We take inspiration from\ncommonsense LMs, designed for query common-\nsense knowledge, such as COMET (Bosselut et al.,\n2019) and COMET-2020 (Hwang et al., 2021).\nDomain specific LMs are also used for knowl-\nedge graph completion in specialized domains like\nbiomedicine (Nadkarni et al., 2021). Liu et al.\n(2022a) use dataset cartography to prime the model\nwith challenging examples and enable it to generate\nmore examples with such patterns.\nKnowledge Distillation As the process of man-\nually creating datasets can be costly and complex,\nprior studies have explored the realm of automated\ndata generation. These prior works mainly focused\non extractive approaches, e.g. syntactic parsing\n(Zhang et al., 2020a) or pattern matching (Li et al.,\n2020) from unstructured text (Lehmann et al., 2015;\nBuck et al., 2014).\nWest et al. (2021) proposed filtering out low qual-\nity data using a critic model for symbolic knowl-\nedge distillation from larger models. Following\nthis, several works effectively improved upon this\nfor iterative distillation (Sclar et al., 2022; Bha-\ngavatula et al., 2023), self-chat with feedback and\nconversations with ChatGPT (Xu et al., 2023; Geng\net al., 2023; Chiang et al., 2023). SODA (Kim et al.,\n2023) contextualized social commonsense knowl-\nedge from a knowledge graph to distill dialogues\nfrom InstructGPT. Sclar et al. (2022) established\nfilters based on length, fidelity, and information bot-\ntleneck for distilling reference-free summarization\ndetermining the effectiveness of designing filters\nfor selecting data for the following iteration. Re-\ncently, (Jung et al., 2023) proposed a framework\nto learn a high-quality model from a low-quality\nteacher model to distill a good dataset by summa-\nrizing and paraphrasing.\n5 Conclusions\nOverall, we introduce NOVACOMET , an open\ncommonsense foundation model. NOVACOMET\ntakes advantage of closed proprietary models, re-\nsulting in an open pipeline and resources that are\npublicly available. NOVACOMET is trained on\ndata generated from these closed proprietary mod-\nels and augmented with human annotations, result-\ning in both a high-quality plausibility model and\nimproved generative model. NOVACOMET sur-\npasses other general models of similar size at a\nrange of commonsense knowledge-intensive tasks,\ndemonstrating the existing need for explicit knowl-\nedge modeling, even as task-focused methods like\ninstruction tuning grow in popularity.\nLimitations\nFirst, we recognize that our line of research re-\nquires extensive resources and funding, limiting\nthe broad adoption of our methodology as it is pre-\nsented. Particularly, our work relies on both mas-\nsive generation from proprietary language models\n(GPT-3 turbo) and extensive use of TPU resources.\nOur hope is that these barriers will only be lowered\nas proprietary LMs become cheaper and LMs be-\ncome increasingly efficient to tune and do inference\non (Dettmers et al., 2023), lowering the barrier for\ntechniques such as ours.\nSecond of all, we recognize that, while we have\nattempted to test the query-ability of commonsense\nknowledge via automatic and human evaluations\non a number of different tasks [FIX ME]RL. How-\never, current tasks are largely biased towards both\n1134\ncertain topics and tends to implicitly define ground\ntruth from certain, fixed perspectives rather than ac-\nknowledging the underlying diversity of human per-\nspectives (Santy et al., 2023). This limits our abil-\nity to assess whether our models capture genuine\nhuman agreement—or only the agreement of a cer-\ntain portion of the population—something which\nwe hope future work will investigate.\nEthics Statement\nAkin to all other machine learning approaches, our\nmodel could inadvertently exhibit biases. We ac-\nknowledge that the open format relations gathered\nfrom proprietary models may not be representative\nof all cultures, and thereby these perpetuate the\nbiases that these proprietary large models possess.\nWhile generating commonsense knowledge, LLMs\nmay result in unanticipated commonsense infer-\nences, including those that are biased and escape\nour critic model. Consequently, incorporating these\ninferences during training can further amplify such\nbiases. We are committed to understanding such\nbiases and improving our critic model. However,\nour model’s central tenet is knowledge, which con-\ntrasts with existing public models of similar size\nand architecture, thereby regulating the toxicity of\nthe model. We ensured that the crowd workers in-\nvolved in our project were compensated at a rate\nthat met or exceeded the minimum wage require-\nment, recognizing the value of their contributions\nto building our model. Comparable to all open\nmodels, our model is susceptible to malicious use\nand it is our collective responsibility to thrust safe\nopen usage. We acutely understand the ethical im-\nplications associated with our proposed method\nand are dedicated to resolving them, aiming to en-\nsure the responsible adaptation of our approach in\nthe community.\nReferences\nChandra Bhagavatula, Jena D. Hwang, Doug Downey,\nRonan Le Bras, Ximing Lu, Keisuke Sakaguchi,\nSwabha Swayamdipta, Peter West, and Yejin Choi.\n2023. I2D2: Inductive knowledge distillation with\nNeuroLogic and self-imitation. In Proceedings of the\n61st Annual Meeting of the Association for Computa-\ntional Linguistics, ACL.\nChandra Bhagavatula, Ronan Le Bras, Chaitanya\nMalaviya, Keisuke Sakaguchi, Ari Holtzman, Han-\nnah Rashkin, Doug Downey, Scott Yih, and Yejin\nChoi. 2019. Abductive commonsense reasoning.\nICLR.\nNing Bian, Xianpei Han, Le Sun, Hongyu Lin, Yaojie\nLu, and Ben He. 2023. Chatgpt is a knowledgeable\nbut inexperienced solver: An investigation of com-\nmonsense problem in large language models. ArXiv,\nabs/2303.16421.\nYonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng\nGao, and Yejin Choi. 2019. PIQA: Reasoning about\nphysical commonsense in natural language. In AAAI\nConference on Artificial Intelligence.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Celikyilmaz, and Yejin Choi.\n2019. Comet: Commonsense transformers for auto-\nmatic knowledge graph construction. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4762–4779.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners.\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\nter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\nHarsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\nand Yi Zhang. 2023. Sparks of artificial general in-\ntelligence: Early experiments with gpt-4.\nChristian Buck, Kenneth Heafield, and Bas Van Ooyen.\n2014. N-gram counts and language models from the\ncommon crawl. In LREC, volume 2, page 4. Citeseer.\nMichael Chen, Mike D’Arcy, Alisa Liu, Jared Fer-\nnandez, and Doug Downey. 2019. Codah: An\nadversarially-authored question answering dataset\nfor common sense. In Proceedings of the 3rd Work-\nshop on Evaluating Vector Space Representations for\nNLP, pages 63–69.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, Parker Schuh, Kensen Shi, Sasha\nTsvyashchenko, Joshua Maynez, Abhishek Rao,\nParker Barnes, Yi Tay, Noam M. Shazeer, Vinod-\nkumar Prabhakaran, Emily Reif, Nan Du, Benton C.\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\n1135\nSunipa Dev, Henryk Michalewski, Xavier García,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pillai,\nMarie Pellat, Aitor Lewkowycz, Erica Moreira, Re-\nwon Child, Oleksandr Polozov, Katherine Lee, Zong-\nwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Díaz,\nOrhan Firat, Michele Catasta, Jason Wei, Kathleen S.\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022. Palm: Scaling language mod-\neling with pathways. ArXiv, abs/2204.02311.\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph,\nYi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Web-\nson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-\ngun, Xinyun Chen, Aakanksha Chowdhery, Sharan\nNarang, Gaurav Mishra, Adams Wei Yu, Vincent\nZhao, Yanping Huang, Andrew M. Dai, Hongkun\nYu, Slav Petrov, Ed Chi, Jeff Dean, Jacob Devlin,\nAdam Roberts, Denny Zhou, Quoc Le, and Jason\nWei. 2022a. Scaling instruction-finetuned language\nmodels. ArXiv, abs/2210.11416.\nHyung Won Chung, Le Hou, S. Longpre, Barret Zoph,\nYi Tay, William Fedus, Eric Li, Xuezhi Wang,\nMostafa Dehghani, Siddhartha Brahma, Albert Web-\nson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-\ngun, Xinyun Chen, Aakanksha Chowdhery, Dasha\nValter, Sharan Narang, Gaurav Mishra, Adams Wei\nYu, Vincent Zhao, Yanping Huang, Andrew M.\nDai, Hongkun Yu, Slav Petrov, Ed Huai hsin Chi,\nJeff Dean, Jacob Devlin, Adam Roberts, Denny\nZhou, Quoc V . Le, and Jason Wei. 2022b. Scal-\ning instruction-finetuned language models. ArXiv,\nabs/2210.11416.\nJoe Davison, Joshua Feldman, and Alexander M. Rush.\n2019. Commonsense knowledge mining from pre-\ntrained models. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing, EMNLP-IJCNLP\n2019, Hong Kong, China, November 3-7, 2019, pages\n1173–1178. Association for Computational Linguis-\ntics.\nTim Dettmers, Artidoro Pagnoni, Ari Holtzman, and\nLuke Zettlemoyer. 2023. Qlora: Efficient finetuning\nof quantized llms. arXiv preprint arXiv:2305.14314.\nBhuwan Dhingra, Jeremy R. Cole, Julian Martin\nEisenschlos, Daniel Gillick, Jacob Eisenstein, and\nWilliam W. Cohen. 2022. Time-aware language mod-\nels as temporal knowledge bases. Trans. Assoc. Com-\nput. Linguistics, 10:257–273.\nJoseph L Fleiss. 1971. Measuring nominal scale agree-\nment among many raters. Psychological bulletin,\n76(5):378.\nXinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal-\nlace, Pieter Abbeel, Sergey Levine, and Dawn Song.\n2023. Koala: A dialogue model for academic re-\nsearch. Blog post.\nPhillip Howard, Junlin Wang, Vasudev Lal, Gadi Singer,\nYejin Choi, and Swabha Swayamdipta. 2023. Neu-\nrocomparatives: Neuro-symbolic distillation of com-\nparative knowledge. ArXiv, abs/2305.04978.\nJena D. Hwang, Chandra Bhagavatula, Ronan Le Bras,\nJeff Da, Keisuke Sakaguchi, Antoine Bosselut, and\nYejin Choi. 2020. Comet-atomic 2020: On symbolic\nand neural commonsense knowledge graphs. InAAAI\nConference on Artificial Intelligence.\nJena D Hwang, Chandra Bhagavatula, Ronan Le Bras,\nJeff Da, Keisuke Sakaguchi, Antoine Bosselut, and\nYejin Choi. 2021. (comet-) atomic 2020: On sym-\nbolic and neural commonsense knowledge graphs.\nIn Proceedings of the AAAI Conference on Artificial\nIntelligence, volume 35, pages 6384–6392.\nJaehun Jung, Peter West, Liwei Jiang, Faeze Brahman,\nXiming Lu, Jillian Fisher, Taylor Sorensen, and Yejin\nChoi. 2023. Impossible distillation: from low-quality\nmodel to high-quality dataset & model for summa-\nrization and paraphrasing. ArXiv, abs/2305.16635.\nHyunwoo Kim, Jack Hessel, Liwei Jiang, Ximing Lu,\nYoungjae Yu, Pei Zhou, Ronan Le Bras, Malihe\nAlikhani, Gunhee Kim, Maarten Sap, et al. 2023.\nSODA: Million-scale dialogue distillation with so-\ncial commonsense contextualization. In Proceedings\nof the 2023 Conference on Empirical Methods in\nNatural Language Processing, EMNLP.\nYash Kumar Lal, Nathanael Chambers, Raymond\nMooney, and Niranjan Balasubramanian. 2021.\nTellMeWhy: A dataset for answering why-questions\nin narratives. In Findings of the Association for Com-\nputational Linguistics: ACL-IJCNLP 2021 , pages\n596–610, Online. Association for Computational Lin-\nguistics.\nJ Richard Landis and Gary G Koch. 1977. The mea-\nsurement of observer agreement for categorical data.\nbiometrics, pages 159–174.\nJens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch,\nD. Kontokostas, Pablo N. Mendes, Sebastian Hell-\nmann, M. Morsey, Patrick van Kleef, S. Auer, and\nC. Bizer. 2015. Dbpedia - a large-scale, multilingual\nknowledge base extracted from wikipedia. Semantic\nWeb, 6:167–195.\nZhongyang Li, Xiao Ding, Ting Liu, J. Edward Hu,\nand Benjamin Van Durme. 2020. Guided generation\nof cause and effect. In Proceedings of the Twenty-\nNinth International Joint Conference on Artificial\nIntelligence, IJCAI-20.\nBill Yuchen Lin, Ziyi Wu, Yichi Yang, Dong-Ho Lee,\nand Xiang Ren. 2021. RiddleSense: Reasoning\nabout riddle questions featuring linguistic creativ-\nity and commonsense knowledge. In Findings of\nthe Association for Computational Linguistics: ACL-\nIJCNLP 2021, pages 1504–1515, Online. Association\nfor Computational Linguistics.\n1136\nAlisa Liu, Swabha Swayamdipta, Noah A. Smith, and\nYejin Choi. 2022a. WANLI: Worker and ai collabo-\nration for natural language inference dataset creation.\nIn Conference on Empirical Methods in Natural Lan-\nguage Processing.\nJiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Pe-\nter West, Ronan Le Bras, Yejin Choi, and Hannaneh\nHajishirzi. 2022b. Generated knowledge prompting\nfor commonsense reasoning. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), ACL\n2022, Dublin, Ireland, May 22-27, 2022, pages 3154–\n3169. Association for Computational Linguistics.\nJiacheng Liu, Wenya Wang, Dianzhuo Wang, Noah A.\nSmith, Yejin Choi, and Hanna Hajishirzi. 2023. Vera:\nA general-purpose plausibility estimation model for\ncommonsense statements. ArXiv, abs/2305.03695.\nXiming Lu, Sean Welleck, Jack Hessel, Liwei Jiang,\nLianhui Qin, Peter West, Prithviraj Ammanabrolu,\nand Yejin Choi. 2022. QUARK: Controllable text\ngeneration with reinforced unlearning. In Advances\nin Neural Information Processing Systems.\nNasrin Mostafazadeh, Nathanael Chambers, Xiaodong\nHe, Devi Parikh, Dhruv Batra, Lucy Vanderwende,\nPushmeet Kohli, and James Allen. 2016. A corpus\nand cloze evaluation for deeper understanding of\ncommonsense stories. In Proceedings of the 2016\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 839–849, San Diego,\nCalifornia. Association for Computational Linguis-\ntics.\nRahul Nadkarni, David Wadden, Iz Beltagy, Noah A.\nSmith, Hannaneh Hajishirzi, and Tom Hope. 2021.\nScientific language models for biomedical knowledge\nbase completion: An empirical study. In 3rd Con-\nference on Automated Knowledge Base Construction,\nAKBC 2021, Virtual, October 4-8, 2021.\nOpenAI. 2023. Gpt-4 technical report. ArXiv,\nabs/2303.08774.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,\nCarroll L. Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex\nRay, John Schulman, Jacob Hilton, Fraser Kelton,\nLuke E. Miller, Maddie Simens, Amanda Askell, Pe-\nter Welinder, Paul Francis Christiano, Jan Leike, and\nRyan J. Lowe. 2022. Training language models to\nfollow instructions with human feedback. ArXiv,\nabs/2203.02155.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of\nthe 40th annual meeting on association for compu-\ntational linguistics, pages 311–318. Association for\nComputational Linguistics.\nFabio Petroni, Tim Rocktäschel, Patrick S. H. Lewis,\nAnton Bakhtin, Yuxiang Wu, Alexander H. Miller,\nand Sebastian Riedel. 2019. Language models as\nknowledge bases? CoRR, abs/1909.01066.\nRaul Puri and Bryan Catanzaro. 2019. Zero-shot\ntext classification with generative language models.\nCoRR, abs/1912.10165.\nColin Raffel, Noam M. Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2019. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. ArXiv, abs/1910.10683.\nAdam Roberts, Hyung Won Chung, Anselm Levskaya,\nGaurav Mishra, James Bradbury, Daniel Andor, Sha-\nran Narang, Brian Lester, Colin Gaffney, Afroz\nMohiuddin, Curtis Hawthorne, Aitor Lewkowycz,\nAlex Salcianu, Marc van Zee, Jacob Austin, Se-\nbastian Goodman, Livio Baldini Soares, Haitang\nHu, Sasha Tsvyashchenko, Aakanksha Chowdh-\nery, Jasmijn Bastings, Jannis Bulian, Xavier Gar-\ncia, Jianmo Ni, Andrew Chen, Kathleen Kenealy,\nJonathan H. Clark, Stephan Lee, Dan Garrette, James\nLee-Thorp, Colin Raffel, Noam Shazeer, Marvin\nRitter, Maarten Bosma, Alexandre Passos, Jeremy\nMaitin-Shepard, Noah Fiedel, Mark Omernick, Bren-\nnan Saeta, Ryan Sepassi, Alexander Spiridonov,\nJoshua Newlan, and Andrea Gesmundo. 2022. Scal-\ning up models and data with t5x and seqio. arXiv\npreprint arXiv:2203.17189.\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-\nula, and Yejin Choi. 2019. Winogrande: An adver-\nsarial winograd schema challenge at scale. In AAAI\nConference on Artificial Intelligence.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M Saiful Bari, Canwen Xu, Urmish\nThakker, Shanya Sharma, Eliza Szczechla, Taewoon\nKim, Gunjan Chhablani, Nihal V . Nayak, Debajyoti\nDatta, Jonathan Chang, Mike Tian-Jian Jiang, Han\nWang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\nHarshit Pandey, Rachel Bawden, Thomas Wang, Tr-\nishala Neeraj, Jos Rozen, Abheesht Sharma, An-\ndrea Santilli, Thibault Févry, Jason Alan Fries, Ryan\nTeehan, Stella Rose Biderman, Leo Gao, Tali Bers,\nThomas Wolf, and Alexander M. Rush. 2021. Multi-\ntask prompted training enables zero-shot task gener-\nalization. ArXiv, abs/2110.08207.\nSebastin Santy, Jenny T Liang, Ronan Le Bras, Katha-\nrina Reinecke, and Maarten Sap. 2023. NLPosition-\nality: Characterizing design biases of datasets and\nmodels. In Proceedings of the 61st Annual Meet-\ning of the Association for Computational Linguistics,\nACL.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan Le\nBras, and Yejin Choi. 2019. Social IQA: Common-\nsense reasoning about social interactions. In Con-\nference on Empirical Methods in Natural Language\nProcessing.\n1137\nMelanie Sclar, Peter West, Sachin Kumar, Yulia\nTsvetkov, and Yejin Choi. 2022. Referee: Reference-\nfree sentence summarization with sharper controlla-\nbility through symbolic knowledge distillation. arXiv\npreprint arXiv:2210.13800.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV ,\nEric Wallace, and Sameer Singh. 2020. Autoprompt:\nEliciting knowledge from language models with au-\ntomatically generated prompts. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing, EMNLP 2020, Online, Novem-\nber 16-20, 2020, pages 4222–4235. Association for\nComputational Linguistics.\nOyvind Tafjord and Peter Clark. 2021. General-\npurpose question-answering with macaw. ArXiv,\nabs/2109.02593.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. CommonsenseQA: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4149–4158, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aur’elien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. ArXiv,\nabs/2302.13971.\nTrieu H. Trinh and Quoc V . Le. 2018. A simple method\nfor commonsense reasoning. CoRR, abs/1806.02847.\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena\nHwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,\nSean Welleck, and Yejin Choi. 2022. Symbolic\nknowledge distillation: from general language mod-\nels to commonsense models. In Proceedings of the\n2022 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4602–4625, Seat-\ntle, United States. Association for Computational\nLinguistics.\nPeter West, Chandra Bhagavatula, Jack Hessel, Jena D.\nHwang, Liwei Jiang, Ronan Le Bras, Ximing Lu,\nSean Welleck, and Yejin Choi. 2021. Symbolic\nKnowledge Distillation: from general language mod-\nels to commonsense models. In North American\nChapter of the Association for Computational Lin-\nguistics.\nCanwen Xu, Daya Guo, Nan Duan, and Julian McAuley.\n2023. Baize: An open-source chat model with\nparameter-efficient tuning on self-chat data. ArXiv,\nabs/2304.01196.\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\nFarhadi, and Yejin Choi. 2019. HellaSwag: Can\na machine really finish your sentence? In Annual\nMeeting of the Association for Computational Lin-\nguistics.\nHongming Zhang, Daniel Khashabi, Y . Song, and\nD. Roth. 2020a. TransOMCS: From linguistic graphs\nto commonsense knowledge. In IJCAI.\nTianyi Zhang, V . Kishore, Felix Wu, Kilian Q. Wein-\nberger, and Yoav Artzi. 2020b. Bertscore: Evaluating\ntext generation with bert. ArXiv, abs/1904.09675.\nPei Zhou, Hyundong Justin Cho, Pegah Jandaghi, Dong-\nHo Lee, Bill Yuchen Lin, Jay Pujara, and Xiang Ren.\n2022. Reflect, not reflex: Inference-based common\nground improves dialogue response quality. In Con-\nference on Empirical Methods in Natural Language\nProcessing.\n1138\nA Manual Cluster Analysis of Queries\nTo understand the contents of NOVATOMIC , we\nanalyze the top 100 surface form queries by total\ncount in NOVATOMIC . We cluster these queries by\nhand into semantically related/equivalent groups,\nand then further take the top 10 of these groups,\ndisplayed in the main paper text. In Table 5, we\ninclude all queries in the the top 10 clusters along\nwith with counts and total counts per cluster.\nA.1 Automatic Evaluation of Generation\nWe also include automatic evaluation with 2 met-\nrics in Table 6. We find these values show a much\nless distinct spread, with no model taking a clear\nlead over others. The seemingly lower information\nand general unreliability of automatic metrics was\na motivation in mainly considering human evalua-\ntion.\nB Data Generation\nB.1 Context Generation Prompts\nBelow are the 21 prompts used for doing context\ngeneration (delimited with ”’)\nGenerate 20 events.\n1. Event:\n'''\nGenerate 20 common events.\n1. Event:\n'''\nGenerate 20 everyday events.\n1. Event:\n'''\nGenerate 20 events that happen often.\n1. Event:\n'''\nGenerate 20 events that happen sometimes\n.\n1. Event:\n'''\nGenerate 20 events that include a person\nor people.\n1. Event:\n'''\nGenerate 20 everyday events about\nPersonX (one per line). It may also\ninvolve other entities, such as\nPersonY.\n1. Event:\n'''\nGenerate 20 situations.\n1. Situation:\n'''\nGenerate 20 common situations.\n1. Situation:\n'''\nGenerate 20 everyday situations.\n1. Situation:\n'''\nGenerate 20 situations that happen often\n.\n1. Situation:\n'''\nGenerate 20 situations that happen\nsometimes.\n1. Situation:\n'''\nGenerate 20 situations that include a\nperson or people.\n1. Situation:\n'''\nGenerate 20 everyday situations about\nPersonX (one per line). It may also\ninvolve other entities, such as\nPersonY.\n1. Situation:\n'''\nGenerate 20 situations. They should be\ncomplex and include multiple parts.\n(One per line)\n1. Situation:\n'''\nGenerate 20 common situations. They\nshould be complex and include\nmultiple parts. (One per line)\n1139\nWhat time is it? 800\nWhat time of day is it? 6153\nWhat is the time of day? 458\nWhat time of the day is it? 328\nTotal 7739\nWho is PersonX? 2333\nWhat is an attribute of PersonX? 434\nWho are PersonX and PersonY? 257\nWhat is PersonX? 233\nWho is PersonY? 825\nTotal 4082\nWhat is the weather like? 2960\nWhat’s the weather like? 382\nWhat is the weather like outside? 351\nHow is the weather? 261\nTotal 3954\nWhat is the prerequisite for this situation? 640\nWhat is a prerequisite for this situation? 517\nWhat is a prerequisite for this event? 345\nTotal 1502\nWhat is the consequence of the situation? 314\nWhat’s a potential consequence of this situation? 311\nWhat is a potential consequence of this situation? 225\nWhat is the consequence of this situation? 197\nWhat is a consequence of this situation? 190\nWhat could be a consequence of this situation? 130\nTotal 1367\nWhat is the counterfactual of the situation? 570\nWhat is the counterfactual of this situation? 202\nWhat is a counterfactual of the situation? 163\nWhat is a counterfactual of this situation? 125\nTotal 1060\nWhat will happen next? 268\nWhat will the person do next? 211\nWhat will PersonX do next? 210\nWhat will they do next? 156\nWhat might happen next? 155\nTotal 1000\nWhat is the occasion? 712\nWhat’s the occasion? 149\nTotal 861\nWhat is the relationship between PersonX and PersonY? 655\nWhat is their relationship? 198\nTotal 853\nWhere are they? 193\nWhere is PersonX? 233\nWhat is the setting? 223\nWhere is this taking place? 135\nTotal 784\nTable 5: The surface forms and counts included in the top 10 clusters of analyzed queries.\n1. Situation:\n'''\nGenerate 20 everyday situations. They\nshould be complex and include\nmultiple parts. (One per line)\n1. Situation:\n'''\nGenerate 20 situations that happen often\n. They should be complex and include\nmultiple parts. (One per line)\n1140\nBLEU BERTScore\nsystem αNLG Reflect TellMeWhy A TOMIC 2020 αNLG Reflect TellMeWhy A TOMIC 2020\nLLaMA-7B 0.8 0.4 2.1 0.1 85.2 83.2 85.9 81.7\nLLaMA-13B 1.0 0.5 4.6 0.1 85.4 83.8 86.5 81.7\nT0 1.3 3.2 9.0 0.5 87.2 88.7 89.1 85.3\nAlpaca-7b 1.3 1.1 6.4 0.3 88.7 87.8 89.4 83.5\nAlpaca-13B 2.4 1.2 6.9 0.2 88.8 87.4 89.2 83.3\nFlan-Ul2 4.3 3.4 5.7 0.5 90.0 86.5 85.9 85.3\nFlan-T5xxl 4.3 4.4 10.8 0.5 90.0 88.2 90.2 86.3\nNOVACOMET base 3.4 3.7 10.8 0.6 89.7 88.5 90.8 85.8\nTable 6: Comparison of baselines and the NOVACOMET base using automatic scores BLEU (Papineni et al., 2002)\nand BERTScore (Zhang et al., 2020b). Automatic metrics do not seem to agree with human evaluation, and show\nless clear variation.\n1. Situation:\n'''\nGenerate 20 situations that happen\nsometimes. They should be complex\nand include multiple parts. (One per\nline)\n1. Situation:\n'''\nGenerate 20 situations that include a\nperson or people. They should be\ncomplex and include multiple parts.\n(One per line)\n1. Situation:\n'''\nGenerate 20 everyday situations about\nPersonX (one per line). It may also\ninvolve other entities, such as\nPersonY. They should be complex and\ninclude multiple parts. (One per\nline)\n1. Situation:\nB.2 Relation Generation Prompts\nBelow are the prompts for generating relations. To\npromote diversity, the number of examples were\nrandomly selected from Uniform(1,10) and were\nshuffled. Some contexts come from ROCStories\n(Mostafazadeh et al., 2016) and (West et al., 2022),\nwhile others are handwritten. All questions and\ninferences are hand-written. When prompting ‘gpt-\n3.5-turbo‘, we provide the instructions \"Given a\nsituation... answer\" as the system message, the\nContext as a user message, and the ten generated\nqueries/inferences as the system response.\nB.3 With queries\nGiven a situation, ask and answer ten\n(10) relevant questions that require\ncommonsense or a world model. Some\nexamples may include potential\nconsequences, explanations,\nprerequisites or reactions,\nattributes, or counterfactuals. The\ncommonsense facts may be about\nactors, actions, events, or ideas in\nthe passage. The examples should be\nhigh-quality and things that are\ntrue. Please give a plausible answer\nat all times instead of just saying\nthat it depends. Only ask questions\nthat will have a relevant,\ncommonsense answer.\nAlisa and her family lived in Florida.\nThey heard a hurricane was coming.\nThey decided to evacuate to a\nrelative's house. They arrived and\nlearned from the news that it was a\nterrible storm.\n1. What will happen now? They will wait\nout the storm.\n2. How does Alisa feel? She is probably\nrelieved to be out of the hurricane'\ns path.\n3. What would have happened if Alisa and\nher family had not evacuated? They\nwould have been in the storm.\n4. Why did they decide to evacuate to a\nrelative's house? They wanted to be\nin a safe place.\n5. Alisa's family is what? Responsible\n1141\n6. What might have prevented them from\nfleeing? If they had not heard about\nthe hurricane, or if they had no\nway to get to a relative's house.\n7. They would not have fled if they were\nnot what? Cautious\n8. Where does their relative live?\nSomewhere safe from the hurricane.\n9. Should they have fled even if the\nstorm hadn't been bad? Yes, because\nthey might have not been able to\nleave if the hurricane got worse.\n10. How could you describe their\nrelative? Kind\nA robber steals from a bank.\n1. What are some potential characters in\nthe situation? Robber, bank teller/\nworker, customers\n2. Tell me something about the robber?\nThe robber is probably armed\n3. What does the robber have? The robber\nprobably has a getaway car\n4. What does the bank teller feel? The\nbank teller is probably scared\n5. What might happen to the robber? The\nrobber could go to jail\n6. What does the bank have? The bank\nmight have a security system\n7. Before this, did the robber do\nanything? The robber probably\nplanned this in advance\n8. As a consequence, what will happen?\nAfter, the robber will have the\nmoney\n9. What happens before this? The robber\ntells the bank teller to give them\nthe money\n10. How much money does the robber get?\nA lot of money\nThe woman enters the elevator\n1. What did the woman have to do before?\nThe woman had to press the button\nfor the elevator to come to her\nfloor\n2. What is the woman's goal? The woman\nwants to go to a different floor\n3. What will the woman do next? The\nwoman will press the button for the\nfloor she wants to go to\n4. What could hinder this situation? The\nwoman wants to take the stairs to\nbe healthy\n5. Is she alone? She may or may not be\nalone, since there could be other\npeople in the elevator.\n6. What does the woman see in the\nelevator? Buttons to different\nfloors\n7. What does the woman feel? The woman\ncould feel impatient at having to\nwait for an elevator\n8. As a consequence, what will happen?\nThe woman will arrive at her desired\nfloor\n9. What could prevent this from\nhappening? The elevator is out of\nservice\n10. Where are elevators located? Multi-\nstory buildings\nEmma has a big exam tomorrow. She got so\nstressed, she pulled an all-nighter.\nShe went into class the next day,\nweary as can be. Her teacher stated\nthat the test is postponed for next\nweek.\n1. How does Emma feel about this? Emma\nis probably relieved\n2. Why might Emma be frustrated? Emma\ncould be frustrated because she\nstayed up all night studying for\nnothing\n3. What is the consequence of the\nsituation? Emma will have more time\nto study\n4. What is the prerequisite for this\nsituation? Emma needed to have a big\nexam\n5. Tell me what Emma will do next. Emma\nwill probably go home and sleep.\n6. What did Emma do before this? Emma\nwas studying for her exam\n7. Why did the teacher postpone the exam\n? The teacher may have postponed the\nexam because not everyone was ready.\n8. What is an attribute of Emma? Emma is\na procrastinator.\n9. What is an attribute of Emma's\nteacher? flexible\n1142\n10. What is the counterfactual of the\nsituation? If Emma didn't have a big\nexam, she wouldn't have pulled an\nall-nighter.\nKaren was assigned a roommate her first\nyear of college. Her roommate asked\nher to go to a nearby city for a\nconcert. Karen agreed happily. The\nshow was absolutely exhilarating.\n1. What's something we can infer about\nKaren? Karen likes music\n2. What will happen because of this?\nKaren and her roommate will be\nbetter friends\n3. How might this have been prevented?\nIf Karen's roommate was shy, she\nmight not have asked Karen to go to\na concert\n4. How old is Karen? Young adult\n5. Why did Karen agree happily? Karen\nwanted to get to know her roommate\nbetter, make friends, and enjoy a\nconcert\n6. How did Karen and her roommate get to\nthe concert? By car or public\ntransportation\n7. What's a potential consequence of\nthis situation? Karen might have fun\nand meet new people\n8. How does Karen feel? Karen is pleased\n9. What does Karen's roommate think of\nher? The roommate thinks Karen is\ncool\n10. When is the concert? The concert is\nlikely at night\nIvette misplaced her phone at her\ngrandparents.\n1. What did Ivette do before this?\nIvette was at her grandparents\n2. How does Ivette feel? Ivette feels\nfrustrated\n3. What will Ivette do next? Ivette will\nlook for her phone\n4. What could hinder this situation? If\nIvette was more careful\n5. Ivette is what? Young\n6. What would make this situation harder\nfor Ivette? Her phone is turned off.\n7. Where might her phone be? Ivette's\nphone could be in the house, outside\n, or in the car.\n8. Did Ivette mean to lose her phone? No\n9. What is a consequence of the\nsituation? Ivette will have to buy a\nnew phone\n10. What would remedy the situation?\nFinding Ivette's phone\nPersonX takes PersonY back to the\nhospital\n1. Why did PersonX take PersonY back to\nthe hospital? PersonY was not\nfeeling well\n2. What happened before this? PersonY\nwas discharged from the hospital\n3. What is PersonX and PersonY's\nrelationship to eachother? They are\neither friends or family.\n4. What would make this hard? PersonX\ndoesn't have a car.\n5. Next, what will happen? PersonY will\nreceive medical care.\n6. What happened before? PersonY asked\nPersonX to take them to the hospital.\n7. What is PersonX? PersonX is kind\n8. What is PersonY? PersonY is sick\n9. Where are they? They are in a car\n10. What is a result? PersonY will get\nbetter\nMila and her family lived in Florida.\nThey heard a hurricane was coming.\nThey decided to evacuate to a\nrelative's house. They arrived and\nlearned from the news that it was a\nterrible storm.\n1. What will happen now? They will wait\nout the storm.\n2. How does Mila feel? She is probably\nrelieved to be out of the hurricane'\ns path.\n3. What would have happened if Mila and\nher family had not evacuated? They\nwould have been in the storm.\n4. Why did they decide to evacuate to a\nrelative's house? They wanted to be\nin a safe place.\n5. Mila's family is what? Responsible\n1143\n6. What might have prevented them from\nfleeing? If they had not heard about\nthe hurricane, or if they had no\nway to get to a relative's house.\n7. They would not have fled if they were\nnot what? Cautious\n8. Where does their relative live?\nSomewhere safe from the hurricane.\n9. Should they have fled even if the\nstorm hadn't been bad? Yes, because\nthey might have not been able to\nleave if the hurricane got worse.\n10. How could you describe their\nrelative? Kind\nAlegra coyly smiled at the boy as he\nwalked in.\n1. Why did Alegra smile at the boy?\nAlegra was interested in him.\n2. What will the boy do? The boy will\nnotice Alegra.\n3. What is Alegra's relationship to the\nboy? They are strangers.\n4. What will happen if Alegra keeps\nsmiling at the boy? The boy might\ntalk to her.\n5. If the boy doesn't talk to her, how\nwill Alegra feel? Alegra will feel\nawkward.\n6. What is the difference between a coy\nsmile and a regular smile? A coy\nsmile is more flirtatious.\n7. How could Alegra be described?\nConfident\n8. Where is this probably located? In a\npublic place\n9. Alegra is probably what age? A\nteenager or young adult\n10. What would prevent this from\nhappening? Alegra is scared to put\nherself out there\nPersonX crosses the road\n1. What is PersonX? A pedestrian\n2. What could prevent this from\nhappening? This could be prevented\nif there was no crosswalk.\n3. What is a prerequisite for this event\n? A prerequisite for this event is\nthat PersonX wants to cross the road.\n4. What is something that could happen?\nPersonX gets hit by a car\n5. If this didn't happen, what would\nhappen? If this didn't happen,\nPersonX would not get to where they\nneed to go.\n6. What actors might be in this\nsituation? PersonX, drivers, other\npedestrians\n7. What might PersonX be thinking?\nPersonX might be thinking that they\nneed to get to the other side of the\nroad.\n8. What could be true to make PersonX\nreckless? PersonX crosses when there\nare lots of cars and no crosswalk\n9. What could be true to make PersonX\ncautious? PersonX waits carefully\nfor the walk signal and looks both\nways.\n10. What do people do before crossing\nthe road? People might look both\nways to check for cars.\nHonor decides whether to bike or walk to\nschool.\n1. In what situation would Honor choose\nto walk to school? It is raining\noutside.\n2. What is Honor? a student\n3. How could Honor be described? Unsure\n4. What would make this improbable?\nHonor lives very far away from the\nschool.\n5. Why might Honor choose to bike over\nwalk? It is faster.\n6. What will happen if Honor can't make\nup his mind? Honor will be late for\nschool.\n7. What is a possible reason for why\nHonor can't decide? He is feeling\nlazier today.\n8. Either way, Honor will what? Get\nexercise\n9. What is the difference between biking\nand walking? Biking is faster but\nrequires more effort.\n10. What is the weather? It might be\nsunny.\nB.4 Without queries\n1144\nList ten (10) commonsense facts about\neach situation. Some examples may\ninclude potential consequences,\nexplanations, prerequisites or\nreactions. The commonsense facts may\nbe about actors, actions, events,\nor ideas in the passage. The outputs\ncould also include counterfactuals\nor things that could hinder the\nevent from happening. The examples\nshould be high-quality and things\nthat are true.\nPersonX crosses the road\n1. PersonX is probably going to the\nother side\n2. Cars are on the road\n3. Before this can happen, PersonX looks\nboth ways to make sure it's safe\n4. PersonX probably has a destination\n5. PersonX is probably walking\n6. This wouldn't happen if there wasn't\na crosswalk\n7. After, PersonX will be on the other\nside\n8. If PersonX is jaywalking, they might\nget hit by a car\n9. PersonX might use a crosswalk signal\n10. This couldn't happen if the person\nwasn't near a road\nA robber steals from a bank.\n1. The robber is probably armed\n2. The robber probably has a getaway car\n3. The bank teller is probably scared\n4. This is illegal\n5. The robber could go to jail\n6. The bank might have a security system\n7. The robber probably planned this in\nadvance\n8. After, the robber will have the money\n9. Before this happens, the robber tells\nthe bank teller to give them the\nmoney\n10. The robber might wear a mask\nAddilyn and her family lived in Florida.\nThey heard a hurricane was coming.\nThey decided to evacuate to a\nrelative's house. They arrived and\nlearned from the news that it was a\nterrible storm.\n1. They may have left valuables behind\n2. They may come back to a destroyed\nhouse\n3. They were smart to evacuate\n4. If they didn't evacuate, they might\nhave died\n5. The hurricane was very bad\n6. Now, they will wait out the storm\n7. They went to their relatives house\nbecause they wanted to be in a safe\nplace\n8. They wouldn't have fled if they had\nnot heard about the hurricane\n9. The relative lives somewhere safe\nfrom the hurricane\n10. Their relative is kind for letting\nthem stay over\nFatima was assigned a roommate her first\nyear of college. Her roommate asked\nher to go to a nearby city for a\nconcert. Fatima agreed happily. The\nshow was absolutely exhilarating.\n1. Fatima has a roommate\n2. Fatima likes music\n3. As a result, Fatima and her roommate\nwill be better friends\n4. Fatima enjoyed the concert\n5. In the future, Fatima may want to go\nto more concerts\n6. Fatima may be more likely to spend\ntime with her roommate\n7. Fatima's roommate is considerate\n8. Fatima's roommate is probably also a\nstudent\n9. The roommate thinks that Fatima is\ncool\n10. They got to the concert using a car\nor public transportation\nLoretta misplaced her phone at her\ngrandparents.\n1. As a result, Loretta may be stressed.\n2. Loretta may have to buy a new phone.\n3. This event may have ruined Loretta's\nweekend.\n4. This wouldn't happen if Loretta was\nmore careful.\n5.. Now, Loretta will probably look for\nher phone.\n1145\n6. It will be expensive to replace her\nphone if it is lost.\n7. Loretta is young.\n8. This situation would be worse if\nLoretta's phone was turned off.\n9. Things could be better if Loretta\nfinds her phone\n10. Loretta did not mean to lose her\nphone\nSAN FRANCISCO - Charlotte's husband,\nMaxwell, was violently assaulted by\na man who broke into the couple's\nhome in San Francisco early Friday\nmorning, the police said. The\nauthorities identified the suspect\nas Lozen, 42, and said they were\ninvestigating a possible motive.\n1. Lozen could be mentally ill\n2. Maxwell was likely asleep when the\nattack happened\n3. Lozen is either in custody or being\nsearched for by the police\n4. The breaking and entering was likely\nplanned\n5. Charlotte was probably not attacked\n6. This would have been a frightening\nexperience for Charlotte and Maxwell\n7. If Lozen is caught, he will likely go\nto jail\n8. Lozen's motive might have been\npersonal\n9. This wouldn't have happened if Lozen\nwere not violent\n10. Home invasions are usually\npremeditated\nThe woman enters the elevator\n1. Before, the woman pushed the button\nfor the elevator\n2. The woman is going to a different\nfloor\n3. After, the woman will push the button\nfor her floor\n4. Then, she will press the button for\nher desired floor\n5. First, the woman will wait for other\npeople to walk out of the elevator\n6. The woman might have been impatient\nif she had to wait for a long time\n7. This couldn't happen if the elevator\nwere out of service\n8. The woman would not have done this if\nshe wanted to take the stairs to be\nhealthy\n9. The woman may have been in a hurry\n10. She is in a multi-story building\nPersonX takes PersonY back to the\nhospital.\n1. PersonY has been to the hospital\nbefore\n2. The goal of PersonX was to help\nPersonY\n3. Before this can happen, PersonY must\nask PersonX to take them to the\nhospital\n4. PersonY hopes to get medical care\n5. PersonY may have been injured before\nthis\n6. This couldn't happen if PersonX does\nnot have a car\n7. PersonY is sick in some way\n8. Going to the hospital may be\nexpensive\n9. This probably wouldn't happen if\nPersonY wasn't sick\n10. PersonX cares about PersonY\nMichaela has a big exam tomorrow. She\ngot so stressed, she pulled an all-\nnighter. She went into class the\nnext day, weary as can be. Her\nteacher stated that the test is\npostponed for next week.\n1. Michaela is relieved that she doesn't\nhave to take the test today\n2. Michaela is sad because she worked\nhard to prepare and in the end didn'\nt have to\n3. When Michaela stayed up all night she\nwas studying\n4. The teacher probably postponed the\nexam because not everyone was ready.\n5. Next week, Michaela will have to\nstudy again\n6. Michaela may do better on the exam\nnext week because she will have more\ntime to prepare\n7. If the exam was today, Michaela would\nhave done poorly\n8. The test is in a subject that\n1146\nMichaela is struggling in\n9. Michaela is a procrastinator\n10. If Michaela hadn't stayed up all\nnight, she would not be tired\nKeanu decides whether to bike or walk to\nschool.\n1. Keanu might not choose to bike if it'\ns raining outside\n2. Keanu is a student\n3. They are unsure\n4. If Keanu doesn't make up their mind,\nKeanu will be late for school\n5. This is because Keanu is feeling lazy\ntoday\n6. Either way, Keanu will get exercise\n7. Biking is faster than walking but\nrequires more effort\n8. This wouldn't happen if Keanu were\nmore decisive\n9. This would be hard if Keanu lived\nvery far away from the school\n10. Keanu might choose to bike if it's a\nnice day outside\nC MTurk Templates\n1147\nInstructions (click to expand/collapse)\nThanks for participating in this HIT!\nEvaluate the AI's guess. Tell us, given the observation pair, how good the AI's guess is on several dimensions.\nPlease note that you might get the same observation pairs multiple times. For each, you will see a different AI's guess, so please read the\nguess carefully.\nIMPORTANT:\nIn this new dataset, some of the guesses may be exact or near copies of one of the observations. \nThis is an automatic bad. Please respond with strongly disagree  for all questions.\nPlease be forgiving of minor spelling or grammar errors, as that's not what's at test.\nExamples are accessible inline.\n \n(1) Evaluate AI's guess.\nObservations\nWhat happened in between the observations?\nObservation 1: ${obs1}\nObservation 2: ${obs2}\nAI's guess: ${hyp}\n(1.1) AI's guess is a sensical and coherent follow-up event to  \nObservation 1. It leaves no large unexplained information gaps.\nstrongly disagree moderately or weakly  \ndisagree\nmoderately or weakly \nagree\nstrongly agree\nclick for examples\n \n(1.2) AI's guess is a sensical, coherent, and explanatory preceding\nevent to Observation 2. It leaves no large unexplained information\ngaps.\nstrongly disagree moderately or weakly  \ndisagree\nmoderately or weakly \nagree\nstrongly agree\nclick for examples\n \n(1.3) AI's guess is sensical and coherent when both Observations\nare looked at together. It leaves no large unexplained information\ngaps.\nstrongly disagree moderately or weakly  \ndisagree\nmoderately or weakly \nagree\nstrongly agree\nclick for examples\n(2) Say we were to string the sentences up as a short anecdote...\n\"${obs1} ${hyp} ${obs2}\"\nStory ﬂows well  and is understandable (your gut judgment as a\nﬂuent English speaker).\nstrongly disagree moderately or weakly  \ndisagree\nmoderately or weakly \nagree\nstrongly agree\n(Optional) Please let us know if anything was unclear, if you\nexperienced any issues, or if you have any other fedback for us.\nSubmit\nFigure 3: MTurk template for αNLG.\n1148\nInstructions (click to expand/collapse)\n(WARNING: This HIT may contain adult content. Worker discretion is advised.)\nThanks for participating in this HIT!\nYou will evaluate how often assertions are true. Each assertion is comprised of 3 parts: Phrase A, Question, Phrase B\nFor each assertion, determine how true it is:\nIf you see \"nothing in particular\" for Phrase B, assess Phrase B in context:\nSometimes certain actions can simply be responded to by doing nothing!\nOther times, doing nothing in particular is simply a weird or unlikely reaction to something.\nNew!  Please report any prejudiced or inappropriate language:\nProfane or offensive content (NSFW, R-rated material etc)\nPrejudiced assumptions or derogatory language that villainizes people.\nHOWEVER, please note, not all negative content is derogatory especially if Phrase B is intrinsically what Phrase A means. For\nexample: \ncriminals how are they characterized? committing crime is OK. \n↳ This isn't necessarily villianizing people since \"criminal\" means \"a person who has commited a crime\". \nhomeless how are they characterized? being lazy is prejudiced. \n↳ There are many reason a person is rendered homeless. This is a gratuitous prejudice about homelessness.\nMaterial that people may ﬁnd disturbing, off-putting, or improper\nA couple NOTES:\nPlease be forgiving of spelling or grammatical errors\nIf the terms are too obscure or you don't know the truth of the fact at the top of your head, it is okay to mark is \"too unfamiliar to\njudge\". If you can answer (e.g., based on likelihood), please provide a response.\nPhrase A, Phrase B Short phrases. May describe objects, object properties, events, actions, etc.\nQuestion How A relates to B.\nalways/often Always or quite often true.\nsometimes/likely Sometimes is true or true for some people. -or- Likely true.\nfarfetched/never False or farfetched, at best. -or- Unlikely to be true.\ninvalid This assertion makes no sense (i.e., \"what does this even mean?!\").\ntoo unfamiliar to judge Cannot make a fair evaluation. Unfamiliar with one or both of the phrase.\nExamples (click to expand/collapse)\n1) ${context1}\n${query1} \n${inference1}\nHow often does the assertion hold true?\n This fact is true but outdated\n I would count this as an inappropriate, prejudiced or offensive material\n2) ${context2}\n${query2} \n${inference2}\nHow often does the assertion hold true?\n This fact is true but outdated\n I would count this as an inappropriate, prejudiced or offensive material\n3) ${context3}\n${query3} \n${inference3}\nHow often does the assertion hold true?\n This fact is true but outdated\n I would count this as an inappropriate, prejudiced or offensive material\n4) ${context4}\n${query4} \n${inference4}\nHow often does the assertion hold true?\n This fact is true but outdated\n I would count this as an inappropriate, prejudiced or offensive material\n5) ${context5}\n${query5} \n${inference5}\nHow often does the assertion hold true?\n This fact is true but outdated\n I would count this as an inappropriate, prejudiced or offensive material\nalways/often sometimes/likely farfetched/never invalid too unfamiliar to judge\nalways/often sometimes/likely farfetched/never invalid too unfamiliar to judge\nalways/often sometimes/likely farfetched/never invalid too unfamiliar to judge\nalways/often sometimes/likely farfetched/never invalid too unfamiliar to judge\nalways/often sometimes/likely farfetched/never invalid too unfamiliar to judge\n(Optional) Please let us know if anything was unclear, if you\nexperienced any issues, or if you have any other fedback for us.\nSubmit\nFigure 4: MTUrk template for CQI.\n1149",
  "topic": "Foundation (evidence)",
  "concepts": [
    {
      "name": "Foundation (evidence)",
      "score": 0.5961059927940369
    },
    {
      "name": "Computer science",
      "score": 0.4899131655693054
    },
    {
      "name": "Commonsense reasoning",
      "score": 0.4761607348918915
    },
    {
      "name": "Distillation",
      "score": 0.4709682762622833
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3974146246910095
    },
    {
      "name": "History",
      "score": 0.20175638794898987
    },
    {
      "name": "Chemistry",
      "score": 0.12077918648719788
    },
    {
      "name": "Archaeology",
      "score": 0.112428218126297
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    }
  ]
}