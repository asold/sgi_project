{
    "title": "Towards an AI tutor for undergraduate geotechnical engineering: a comparative study of evaluating the efficiency of large language model application programming interfaces",
    "url": "https://openalex.org/W4410273208",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2618068506",
            "name": "Amir Tophel",
            "affiliations": [
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A2114394059",
            "name": "Liuxin Chen",
            "affiliations": [
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A5097332600",
            "name": "Umidu Hettiyadura",
            "affiliations": [
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A2009188072",
            "name": "Jayantha Kodikara",
            "affiliations": [
                "Monash University"
            ]
        },
        {
            "id": "https://openalex.org/A2618068506",
            "name": "Amir Tophel",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2114394059",
            "name": "Liuxin Chen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5097332600",
            "name": "Umidu Hettiyadura",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2009188072",
            "name": "Jayantha Kodikara",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W4360976735",
        "https://openalex.org/W4362584541",
        "https://openalex.org/W4388550745",
        "https://openalex.org/W4386285997",
        "https://openalex.org/W4392938853",
        "https://openalex.org/W4367189069",
        "https://openalex.org/W4388490623",
        "https://openalex.org/W4406658467",
        "https://openalex.org/W4392850382",
        "https://openalex.org/W4407812587",
        "https://openalex.org/W4403734358",
        "https://openalex.org/W4400995904",
        "https://openalex.org/W4389374673",
        "https://openalex.org/W4387736592",
        "https://openalex.org/W4388046560",
        "https://openalex.org/W4396797136",
        "https://openalex.org/W4388212670",
        "https://openalex.org/W4390098547",
        "https://openalex.org/W4392544551",
        "https://openalex.org/W4390486238",
        "https://openalex.org/W4391569503",
        "https://openalex.org/W4391855109",
        "https://openalex.org/W4407996445",
        "https://openalex.org/W2162821268",
        "https://openalex.org/W2123766055",
        "https://openalex.org/W4385067052",
        "https://openalex.org/W4388896754",
        "https://openalex.org/W4403323424",
        "https://openalex.org/W2911122285",
        "https://openalex.org/W4392151225",
        "https://openalex.org/W4391114895",
        "https://openalex.org/W4385287322",
        "https://openalex.org/W4389915126",
        "https://openalex.org/W4388287351",
        "https://openalex.org/W4389258291",
        "https://openalex.org/W4323717344",
        "https://openalex.org/W2020018978",
        "https://openalex.org/W3005411327",
        "https://openalex.org/W6762837409",
        "https://openalex.org/W4255697435",
        "https://openalex.org/W2117766479",
        "https://openalex.org/W1569102739",
        "https://openalex.org/W4387494566",
        "https://openalex.org/W4372184941",
        "https://openalex.org/W1573210768"
    ],
    "abstract": "Abstract This study investigates the efficiency of large language model (LLM) application programming interfaces (APIs)—specifically GPT-4 and Llama-3—as AI tutors for undergraduate Geotechnical Engineering education. As educational needs in specialised fields like Geotechnical Engineering become increasingly complex, innovative teaching tools that provide personalised learning experiences are essential. Unlike previous studies on AI-driven education, our research uniquely focuses on assessing the role of retrieval-augmented generation (RAG) in improving the accuracy of LLM-generated solutions to Geotechnical problems. A dataset of 391 questions from the related textbook written by Das and Sobhan (Das B, Sobhan K. Principles of Geotechnical engineering, Eight Edition. In: Cengage Learning. 2014) was used for evaluation, with solutions sourced from the textbook’s manual. Performance benchmarking focused on 20 challenging questions previously identified by Chen et al. (Chen et al. in Geotechnics 4:470–498, 2024) as problematic for GPT-4 in Zero Shot tasks. GPT-4 with API support demonstrated superior accuracy, achieving accuracy rates of 95% at a temperature setting of 0.1, 82.5% at 0.5, and 60% at 1. In comparison, Llama-3 achieved an accuracy of 25% in Zero Shot tasks and 45% with API support at a temperature setting of 0.1. The findings highlight GPT-4’s potential as an AI tutor for Geotechnical Engineering education while demonstrating the need for domain-specific optimisation and advanced formula integration techniques. This study contributes to the ongoing discourse on AI in education by providing empirical evidence supporting the deployment of LLMs as personalised, adaptive teaching aids in engineering disciplines. Future work should explore optimised formula integration strategies, expanded domain knowledge bases, and long-term student learning outcomes.",
    "full_text": "Vol.:(0123456789)\n Discover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nDiscover Computing\nResearch\nTowards an AI tutor for undergraduate geotechnical engineering: \na comparative study of evaluating the efficiency of large language \nmodel application programming interfaces\nAmir Tophel1 · Liuxin Chen1 · Umidu Hettiyadura2 · Jayantha Kodikara1\nReceived: 9 January 2025 / Accepted: 28 April 2025\n© The Author(s) 2025  OPEN\nAbstract\nThis study investigates the efficiency of large language model (LLM) application programming interfaces (APIs)—specifi-\ncally GPT-4 and Llama-3—as AI tutors for undergraduate Geotechnical Engineering education. As educational needs in \nspecialised fields like Geotechnical Engineering become increasingly complex, innovative teaching tools that provide \npersonalised learning experiences are essential. Unlike previous studies on AI-driven education, our research uniquely \nfocuses on assessing the role of retrieval-augmented generation (RAG) in improving the accuracy of LLM-generated solu-\ntions to Geotechnical problems. A dataset of 391 questions from the related textbook written by Das and Sobhan (Das \nB, Sobhan K. Principles of Geotechnical engineering, Eight Edition. In: Cengage Learning. 2014) was used for evaluation, \nwith solutions sourced from the textbook’s manual. Performance benchmarking focused on 20 challenging questions \npreviously identified by Chen et al. (Chen et al. in Geotechnics 4:470–498, 2024) as problematic for GPT-4 in Zero Shot \ntasks. GPT-4 with API support demonstrated superior accuracy, achieving accuracy rates of 95% at a temperature set -\nting of 0.1, 82.5% at 0.5, and 60% at 1. In comparison, Llama-3 achieved an accuracy of 25% in Zero Shot tasks and 45% \nwith API support at a temperature setting of 0.1. The findings highlight GPT-4’s potential as an AI tutor for Geotechnical \nEngineering education while demonstrating the need for domain-specific optimisation and advanced formula integra-\ntion techniques. This study contributes to the ongoing discourse on AI in education by providing empirical evidence \nsupporting the deployment of LLMs as personalised, adaptive teaching aids in engineering disciplines. Future work \nshould explore optimised formula integration strategies, expanded domain knowledge bases, and long-term student \nlearning outcomes.\nKeywords Large language models (LLMs) · Application programming interfaces (APIs) · Retrieval-augmented \ngeneration (RAG) · Geotechnical engineering education · AI tutors\n * Liuxin Chen, Liuxin.Chen@monash.edu; Amir Tophel, amir.tophel@monash.edu; Umidu Hettiyadura, ufer0001@student.monash.edu; \nJayantha Kodikara, Jayantha.Kodikara@monash.edu | 1ARC Industrial Transformation Research Hub (ITRH)–SPARC Hub, Department of Civil \nEngineering, Monash University, Clayton, VIC 3800, Australia. 2Department of Civil Engineering, Monash University, Clayton, VIC 3800, \nAustralia.\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\n1 Introduction\nArtificial Intelligence (AI), particularly through Large Language Models (LLMs) such as GPT-4 and Llama-3, rapidly trans-\nforms education by enhancing student engagement, problem-solving capabilities, and personalised learning experi-\nences. LLMs have shown exceptional proficiency in natural language processing and generating structured explanations, \npositioning them as promising tools for addressing educational challenges across various disciplines [1 –6].\nRecent studies have assessed LLM performance in STEM-related standardised tests, including engineering licensure \nexams, graduate entrance exams, and mathematics assessments. These studies offer valuable insights into LLMs’ strengths \nand limitations in structured problem-solving and conceptual reasoning. For example, Pursnani et al. [7] evaluated Chat-\nGPT’s performance on the US Fundamentals of Engineering (FE) Exam, showing that prompt modifications significantly \nenhance AI accuracy, but domain-specific challenges remain. VarastehNezhad et al. [8 ] assessed GPT-4, Claude 3.5, and \nLlama-3 on computer science graduate entrance exams, finding that LLMs excel at structured problems but struggle with \nhigher-order reasoning. Similarly, Maitland et al. [9 ] tested GPT-4 on the MRCP medical exams, revealing high accuracy \nin structured multiple-choice formats but frequent factual and omission errors in open-ended questions. Additionally, \nHonig et al. [10] examined student adoption of GPT-powered AI tutors in engineering education, emphasising the need \nfor adaptive AI-human hybrid models to enhance learning engagement. These insights highlight the importance of \nexploring domain-specific adaptations to optimise the educational utility of AI tools.\nWithin Geotechnical Engineering, a discipline characterised by specialised knowledge and complex analytical \nproblem-solving, LLMs offer considerable potential. For instance, Xu et al. [11] introduced GeoLLM, a specialised \nmodel designed for intelligent geotechnical design automation. GeoLLM has demonstrated the ability to perform \ncalculations related to bearing capacity and settlement analysis, showcasing its effectiveness in processing profes-\nsional geotechnical knowledge. Similarly, Wu et al. [12] investigated LLM integration into geotechnical workflows and \nfound that these models enhance problem-solving efficiency by supporting decision-making and data interpretation. \nHowever, Kumar [3] identified key limitations of ChatGPT in handling geotechnical queries, including hallucinations, \nunit conversion errors, and challenges in interpreting engineering constraints, suggesting a need for continued \nrefinement of AI tools within this specialised field.\nDespite significant advancements, the utilisation of LLMs as educational tools within Geotechnical Engineering \nremains relatively underexplored. The discipline’s reliance on complex formulas and rigorous analytical problem-\nsolving necessitates continuous student guidance, which traditional teaching methods often fail to provide com-\nprehensively [13]. LLMs have the potential to bridge this gap by offering personalised learning experiences and \ndynamically adapting content to individual student needs [14]. However, implementing AI tutors in geotechnical \neducation presents several challenges:\n(1) Institutional Resistance: Universities and educators express concerns regarding student over-reliance on AI and \npotential academic integrity issues.\n(2) Accuracy and Trust Issues: LLMs, including GPT-4 and Llama-3, sometimes generate incorrect responses (hallucina-\ntions), particularly in complex problem-solving scenarios requiring engineering judgment [3 ].\n(3) Integration with Existing Learning Platforms: AI tutors must be compatible with learning management systems \n(LMS), grading rubrics, and curricula, often requiring significant customisation [12].\nTo enhance the reliability of AI tutors, recent research has explored strategies for improving LLM performance in educa-\ntional settings. Studies have shown that techniques such as Chain of Thought (CoT) prompting and custom instructional \nframeworks can significantly enhance model accuracy [7, 15, 16]. The authors’ previous study showed how the efficiency \nof GPT-4 can be improved by incorporating CoT and our proposed custom instruction techniques. The authors showed \nthat by utilising these two techniques, the accuracy of GPT-4 was improved from 29 to 34% and 67% for CoT and custom \ninstruction, respectively [17]. Despite these improvements, other development methods may offer unique benefits that \nenhance the effectiveness and reliability of AI-driven educational tools. For instance, building a domain-specific LLM \nfrom scratch allows for deep customisation but requires extensive resources and expertise in AI training processes, which \ncan be a major drawback [18]. In contrast, fine-tuning existing LLMs on specialised datasets can improve performance \nin specific domains but risks overfitting and limits broader applicability [19].\nAddressing these challenges requires advanced AI-human hybrid learning models and real-time retrieval-based \nAI frameworks, such as Retrieval-Augmented Generation (RAG), to enhance reliability in AI tutoring [20– 23]. This \nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\napproach balances enhancing response accuracy and specificity through dynamic information retrieval, ensuring \nthat content remains current and aligned with the latest developments in the field [24, 24]. These various develop -\nment methods, each with their distinct advantages and challenges, are systematically presented in Table  1. This \ntable provides a comparative analysis of LLM development methods, highlighting aspects such as customisation, \nresource requirements, and scalability.\nThere are more benefits of using APIs with RAG as follows. APIs with RAG significantly improve the reliability and \ntrustworthiness of AI-generated content. RAG-enabled APIs can cite sources and provide references for retrieved infor -\nmation, akin to footnotes in academic papers. This transparency allows users to verify the information, fostering greater \ntrust in the AI system. Conversely, a standalone LLM, such as GPT-4, operates as a black box with responses that do not \ninherently include source citations or verifiable references.\nMoreover, the flexibility and adaptability of APIs with RAG are advantageous. These APIs allow for hot-swapping vari-\nous knowledge bases tailored to different subjects or domains, making them versatile tools in education. Educators can \nintegrate specialised databases, technical manuals, or recent research publications to customise the AI’s knowledge base \nto their teaching needs. This adaptability is not feasible with a standalone LLM, constrained by its fixed training data and \ncannot integrate new knowledge dynamically [14, 25].\nIn addition, APIs with RAG offer a cost-effective and efficient solution for maintaining and updating AI systems. Retrain-\ning an LLM like GPT-4 with new data can be resource-intensive and time-consuming. In contrast, RAG-enabled APIs \ncontinuously update their vector databases with new information, ensuring the AI remains current without extensive \nretraining [26, 27].\nThis study builds upon the aforementioned advancements by integrating RAG with LLM-based tutoring in Geotechni-\ncal Engineering. Key innovations of our approach include:\n(1) Context-Aware Problem-Solving: Unlike conventional AI tutors, the RAG-enhanced system retrieves real-time geo-\ntechnical references and equations, minimising outdated or inaccurate responses [28].\n(2) Improved Conceptual Explanations: AI-generated answers are structured to align with Bloom’s Taxonomy proposed \nby Krathwohl [29], ensuring a step-by-step approach to learning.\n(3) Adaptive Learning Responses: The system dynamically adjusts its explanations based on student input, making \ninteractions more effective than static AI tutors.\nIn addition, we evaluate the efficiency of various LLM APIs, including GPT-4 and Llama-3, as AI tutors in undergradu-\nate Geotechnical Engineering education. We compare these models based on their ability to integrate and apply Geo -\ntechnical Engineering formulas, provide accurate explanations, and adapt to different learning styles and needs [30]. \nAlthough this research is focused on undergraduate-level problems in Geotechnical Engineering, it offers insights that \ncould potentially enhance understanding of LLMs’ applications across broader educational contexts [31]. By providing \ndetailed examinations of these specific areas, the study aims to contribute valuable perspectives on the potential and \nlimitations of LLMs as effective educational tools in the engineering field.\n2  Methodology\n2.1  Evaluation criteria\nThe efficiency of the LLM APIs equipped with RAG as AI tutors is evaluated using a set of criteria. These criteria are \ndesigned to assess various aspects of the LLMs’ performance, pivotal for their effective deployment in educational set -\ntings, specifically in Geotechnical Engineering. The evaluation metrics include:\n(1) Accuracy of Content: The precision with which the LLMs deliver correct information. This metric is important for the \neducational AI system because inaccurate content can mislead learners and erode trust in the tool. Prior studies on \nAI tutors have therefore used answer correctness as a primary performance indicator. For example, Rosoł et al. [32] \nevaluated GPT-4’s tutoring abilities by its accuracy on medical exam questions—reporting about 80% of answers \ncorrect. Such findings highlight that high content accuracy is indispensable for effective learning support.\n(2) Formula Integration Capability: The ability of LLMs to correctly incorporate and apply Geotechnical Engineering \nformulas within their responses. In a technical domain like geotechnics, correctly using domain-specific formulas \nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nTable 1  Comparison of three primary LLM development approaches—building from scratch, fine-tuning, and using RAG with API keys\nWhere ML represents Machine Learning and NLP denotes Natural Language Processing\nAspect/Method LLM development methods\nBuilding from Scratch Fine-Tuning Existing LLM Using RAG with API keys\nCustomisation High: Is fully tailored for specific needs Moderate: Enhances base models with specific \nfeatures\nLow to Moderate: Varies with API capabilities\nData privacy Full Control: Complete autonomy over data man-\nagement\nGood Control: Depends on model constraints Dependent: Subject to third-party policies\nModel uniqueness Tailored: Specifically designed for precise require-\nments\nBeneficial: Utilises a strong base model with added \nspecificity\nStandard: Access to the latest models with minimal \neffort\nResource requirement High: Requires significant computational power, \ndata, and expertise\nModerate: Utilises existing models and infrastruc-\nture\nLow: Mainly financial costs for API usage\nTime to deployment Long: Involves extensive data collection and train-\ning\nModerate: Reasonably-fast deployment using pre-\nbuilt models, still requires setup\nShort: Quick setup and integration\nTechnical expertise Very High: Needs deep ML and NLP knowledge High: Requires knowledge of model fine-tuning Moderate: Primarily involves API integration and \nmanagement\nScalability Variable: Highly dependent on organisational \ninfrastructure\nVariable: Depends on existing infrastructure capa-\nbilities\nHigh: Managed by the service provider, easily scal-\nable\nOngoing maintenance High: Continuous updates and infrastructure main-\ntenance required\nModerate: Needs periodic updates and retraining Low: Maintenance predominantly handled by the \nservice provider\nCosts Very High: Significant investment in infrastructure \nand personnel\nModerate to High: Low initial costs but ongoing \noperational expenses\nCost-Effective: Operates on a pay-as-you-go or sub-\nscription basis\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\nis essential for solving problems, so the AI tutor must demonstrate this skill. Previous research in STEM education \nhas explicitly assessed LLMs on their capacity to handle mathematical and engineering formulas, highlighting the \nimportance of this criterion. For instance, Pursnani et al. [7 ] noted that improvements in ChatGPT’s mathematical \nproblem-solving (e.g., applying formulas correctly) were key to tackling engineering exam questions.\n(3) Clarity and Utility of Explanations: How effectively the LLMs understandably explain complex concepts and solu-\ntions. Evaluating explanation clarity is significant in educational contexts, as a correct answer has limited value if \nthe student cannot follow the reasoning Chiasson et al. [33].\n(4) Adaptability to Various Problem Types: The flexibility of the LLMs in handling a diverse range of question types and \nproblem scenarios within the discipline. An effective AI tutor should perform well across different kinds of prob -\nlems—from straightforward factual queries to complex, multi-step analytical questions. This adaptability reflects \nthe model’s generalisation capability, which has been a focus of prior evaluations of AI in education. Studies suggest \nthat AI tutors need to adjust to diverse learning tasks and styles to be broadly useful [34].\nA dataset of 391 questions, sourced from the geotechnical textbook by Das and Sobhan [35], a widely adopted \nundergraduate textbook, was used as the foundation for evaluation. Solutions to these questions were obtained \nfrom the textbook’s manual to ensure accuracy. The selection aimed to provide comprehensive coverage of key \ngeotechnical topics, including phase relationships, soil classification, consolidation, and shear strength, ensuring \na balanced representation of theoretical and applied problem-solving. Questions were chosen to reflect a range of \ndifficulty levels (i.e., basic, intermediate and advanced), following Bloom’s taxonomy, to evaluate AI tutors’ ability to \nrecall, apply, and analyse concepts. Furthermore, the dataset includes a variety of calculation-based and conceptual \nquestions to assess AI models’ proficiency in formula application, numerical accuracy, and explanatory depth.\nPerformance benchmarking focused on a subset of 20 challenging questions, previously identified by Chen et al. \n[17] as problematic for GPT-4, developed by OpenAI [36], under the Zero Shot prompting strategy. These questions \nwere intentionally selected to cover a range of Geotechnical Engineering topics, from phase relationships to shear \nstrength parameters, as shown in Fig.  1. The selected questions—2.3b, 2.8c, 2.9d, 3.5c, 3.6a, 3.7d, 3.7e, 3.12c, 4.5, 5.2, \n6.6b, 6.7a, 6.10a, 6.10b, 7.9, 11.4a, 11.18a, 12.8, 12.10, and 12.16—correspond directly to those listed in the textbook. \nUpon detailed analysis, we found that the majority of questions fell within the lower cognitive levels of Bloom’s \nframework—specifically, Apply (80%) and Analyse (20%), as they primarily required recall and direct application of \nformulas rather than complex synthesis or evaluation.\nWe further analysed the semantic structure of the questions:\n(1) Symbolic Logic with High Semantic Density: Some questions explicitly specified the variables given and required \nstudents to recall a specific equation and perform direct calculations. These questions primarily fell under the Apply \nlevel of Bloom’s Taxonomy.\n(2) Language-Based Logic with Lower Semantic Density: Other questions required interpretation of problem state -\nments, identifying relevant information and determining the appropriate formula or method before performing \ncalculations. These questions required a higher level of conceptual understanding, classifying them under Analyse \nlevels.\nFig. 1  Distribution of ques-\ntions tested in this study with \ntheir percentages across dif-\nferent topics\n\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nFor this study, all 20 evaluated questions were manually typed into the LLMs as text-based inputs. No questions \nincluded graphs, images, or visual representations, meaning the AI models were assessed purely on their ability to \ninterpret and solve textual problem descriptions.\nFigure  2 illustrates the distribution of error types in the responses provided by GPT-4 when using the Zero Shot \nprompting strategy. The chart is divided into three segments, each representing a different type of error:\n(1) Grounding Errors (60%): This is the largest segment. Grounding Errors indicate that the majority of errors made by \nGPT-4 under Zero Shot conditions are due to grounding issues, where the model retrieves incorrect equations or \nconstraints for the question posed.\n(2) Conceptual Errors (20%): This segment represents errors arising from GPT-4’s inability to obtain necessary concepts \nor facts for solving the question.\n(3) Calculation Errors (20%): This segment, also comprising 20% of the errors, involves mistakes in algebraic and arith-\nmetic operations. Calculation Errors highlight difficulties in the computational aspects of problem-solving by the \nmodel.\nThis visual representation effectively communicates the relative frequency of each error type, underscoring \ngrounding as the predominant challenge faced by GPT-4 in Zero Shot scenarios.\n2.2  Overview of APIs\n2.2.1  GPT‑4 vs Llama‑3\nWhen comparing the GPT-4 API and the Llama-3 API, several key differences and advantages emerge, reflecting \nthe strengths and weaknesses of each LLM in practical applications. The GPT-4 API, developed by OpenAI [37], is \nrenowned for its advanced natural language understanding and generation capabilities, built upon extensive training \non diverse datasets. This enables GPT-4 to excel in generating coherent, contextually appropriate, and highly accu-\nrate responses across a wide range of topics. Its sophisticated architecture supports complex problem-solving and \ndetailed explanations, making it particularly effective for applications in education, technical writing, and customer \nsupport. Furthermore, GPT-4’s robust API infrastructure provides reliable performance and seamless integration \nwith various software applications, enhancing its usability for developers and end-users. However, it is essential to \nnote that the GPT-4 API is a paid service, which can be a significant consideration for organisations managing their \noperational budgets.\nIn contrast, the Llama-3 API with 70 billion parameters, developed by Meta AI, offers a compelling alternative \nemphasising efficiency and customisation. Llama-3 is free, which can be a significant advantage for organisations \nlooking to implement AI solutions without incurring subscription costs. Additionally, Llama-3 supports fine-tuning, \nallowing users to adapt the model to specific domains or tasks, enhancing its relevance and accuracy for specialised \napplications. However, running Llama-3 locally can incur initial setup costs, requiring significant hardware capabilities \nto operate effectively. This can involve investment in high-performance computing resources, which might offset the \ncost benefits of the free API. Unlike GPT-4, which runs on the cloud and does not require local hardware investments, \nLlama-3’s local deployment can be resource-intensive. GPT-3.5 was excluded due to its limited performance and the \nstudy’s focus on evaluating Llama as a free and locally deployable alternative to GPT-4.\nFig. 2  Error type distribution \nvisualisation in the responses \nprovided by GPT4 using the \nZero Shot prompting strategy\n\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\n2.3  Integration of APIs and RAG using LangChain\nLangChain is an advanced framework designed to facilitate the integration of APIs with RAG systems, significantly \nenhancing the capabilities of LLMs like GPT-4 and Llama-3 [38– 40]. By leveraging LangChain, developers can seam-\nlessly connect LLMs to external data sources, enabling dynamic retrieval of relevant information to augment the \nmodel’s responses [41– 43]. This integration is particularly beneficial in applications requiring up-to-date, specific, \nand accurate information, such as educational tools, customer support systems, and technical documentation.\nLangChain creates a pipeline combining LLMs with embedding models and vector databases. When a user submits \na query to an LLM, the model first converts this query into a numeric format known as an embedding. This embed-\nding represents the query in a way that machines can process. The embedding is then compared to a vector database \ncontaining embeddings of a vast array of documents or information sources. This comparison helps identify the most \nrelevant documents or data related to the query. Once the appropriate documents are identified, the information \nis fetched from these external sources. This process ensures that the most current and specific information is avail-\nable to generate a response. The retrieved data is combined with the LLM’s pre-existing knowledge to develop a \ncomprehensive and accurate response to the user’s query. The final output can also include citations or references \nto the retrieved information sources, enhancing trust and transparency.\n2.4  RAG with LangChain\nFigure 3 illustrates the workflow of the RAG system using LangChain. The process begins with a user posing a ques-\ntion, which is input into the system. The system performs an intelligent search involving vector similarity search within \na knowledge graph to find relevant information. This information and the original question are then passed to LLM \nfor processing. The LLM, represented by a parrot, processes the input to generate a coherent and accurate response. \nThe final output, depicted by a lightbulb, represents the generated answer based on the provided documents and \nrelevant information. This flowchart encapsulates the steps from initial query to final answer generation, showcas-\ning the integration of intelligent search techniques and LLM capabilities to enhance the accuracy and relevance of \nthe responses.\nThis study follows the steps to implement RAG with LangChain as described in Table  2.\nFig. 3  Retrieval Augmented Generation (RAG) Flowchart demonstration\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\n3  Results and discussions\n3.1  Temperature settings in GPT API\nThe temperature parameter in LLMs like GPT-4 plays a pivotal role in defining the behaviour of generated text. Tem-\nperature controls the randomness in the model’s responses by influencing the probability distribution over potential \nsubsequent words [44, 45]. In practical applications, especially when using APIs, setting the appropriate temperature \nis crucial for optimising output quality [46].\nAt lower temperature settings, the model’s outputs become more deterministic and focused [32]. This characteristic \nis particularly beneficial in technical and factual domains such as Geotechnical Engineering, where precision and \nreliability are paramount. By reducing randomness, the model adheres more strictly to the most probable sequences \nof words, thereby enhancing the accuracy of the information provided. Conversely, higher temperature settings \nintroduce greater randomness, allowing the model to explore a broader range of responses. While this exploration \ncan be advantageous for creative applications, it often leads to less accurate and relevant content due to the model \ngenerating text that diverges from core knowledge and retrieved information. This increased variability can introduce \nerrors and reduce consistency. Moreover, at higher temperatures, there is an increased likelihood of hallucinations, \nwhere the model produces responses that are plausible in form but incorrect or irrelevant in substance.\n3.2  Impact of temperature on accuracy\nTo assess the impact of temperature settings on the accuracy of LLM outputs, experiments were conducted with \nGPT-4 under Zero Shot and API configurations at three temperature settings: Temp = 0.1, Temp = 0.5, and Temp = 1. \nThe top_p parameter was consistently set to its default value of 1, as altering both parameters simultaneously is \nnot recommended [47]. The accuracy rates achieved for each configuration are illustrated in Fig.  4. The API with \nTemp = 0.1 setting improves the GPT-4’s performance significantly from an accuracy rate of 0% under Zero Shot \nconditions to the highest accuracy at 95%, demonstrating that this low-temperature setting enhances performance \nby reducing output variability. The Temp = 0.5 setting shows a slightly lower accuracy at 82.5%, suggesting that \nmoderate temperatures still maintain high accuracy but with some variability. The Temp = 1 setting results in a 60% \nTable 2  Step-by-step implementation of Retrieval-Augmented Generation (RAG) using LangChain\nStep Description\nStep 1: Environment Setup A new virtual environment was created to manage the dependencies for the project. This \nensures that all required libraries and packages are in a dedicated environment, avoiding \nconflicts with other projects\nStep 2: Library Installation The necessary libraries for the project were installed. These libraries include tools for loading \nand processing documents, creating embeddings, and building conversational AI models\nStep 3: API Key Configuration An OpenAI API key was required to access GPT-4. The API key was stored in a separate file \nnamed constants.py for security purposes. The key was then loaded into the environment, \nensuring secure and easy access to the API\nStep 4: Data Preparation A directory named data was created to store the documents (PDF, DOCX, TXT) used by the \nchatbot. The script was designed to iterate through this directory and load the content of \neach file type using appropriate loaders\nStep 5: Document Processing The loaded documents were split into manageable chunks to facilitate efficient processing \nand retrieval. This was achieved using the CharacterTextSplitter class with chunk_size set at \n200 and chunk_overlap at 10\nStep 6: Vector Database Creation A vector database was created from the document chunks using OpenAI embeddings, \nenabling efficient searching and retrieval of relevant document sections. FAISS was used \nfor efficient similarity search\nStep 7: Conversational Retrieval Chain Setup A conversational retrieval chain was set up using the GPT-4 and Llama-3 models. The chain \nintegrates a language model with a retrieval system and requires hyperparameters like \ntemperature and search_kwargs\nStep 8: Chatbot A chatbot generates the response and formats it for the users\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\naccuracy rate, the lowest among the temperature settings, indicating that higher temperatures introduce too much \nvariability, reducing accuracy. Overall, GPT-4’s accuracy improves with lower temperature settings. For high precision \nand factual correctness in applications like Geotechnical Engineering, a lower temperature setting is advisable to \nensure reliable and effective outputs.\n3.3  Comparison of GPT API and Llama API\nFigure 5 illustrates the accuracy rates achieved by GPT-4 and Llama-3 under Zero Shot conditions and with API configu-\nrations, with temperature values set at 0.1. Under Zero Shot conditions, Llama-3 performs better than GPT-4, achieving \nan accuracy rate of 25% compared to GPT-4’s 0%. Although this rate is still relatively low, it suggests that Llama-3 can \nmanage some accuracy without prior input.\nHowever, the improvements seen with API configurations show a slightly different trend. The Llama-3 API configura-\ntion shows an improvement, reaching an accuracy rate of 45%, up from 25% in its Zero Shot performance, marking a \n20% increase. In contrast, the GPT-4 API configuration demonstrates a remarkable jump, soaring from 0% in Zero Shot to \n95% correct with the API, indicating a 95% improvement. This substantial increase underscores the enhanced accuracy \nand reliability of the GPT-4 API when properly configured.\nThe figure highlights that GPT-4 and Llama-3 benefit significantly from API configurations, with notable improvements \nin their accuracy rates. However, GPT-4 shows a more substantial enhancement, reaching near-perfect accuracy with its \nAPI setup. This comparison suggests that API configurations are crucial for optimising the performance of these LLMs, \nparticularly for tasks that require high precision and reliability. The outcome also implies that while both models improve \nwith API configurations, GPT-4 has more potential for achieving higher accuracy in practical applications.\nFig. 4  Accuracy rate achieved \nby GPT-4 with the Zero Shot \ncondition and GPT-4 API with \ndifferent temperature settings\n0.0%\n95.0%\n82.5 %\n60.0 %\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nZero Sho tT emp=0. 1T emp=0. 5T emp= 1\nAccuracy Rate\nGPT4 API Conﬁgura/g415o n\nFig. 5  Comparison of accu-\nracy rate achieved by GPT-4 \nand Llama-3 with Zero Shot \nand API\n0%\n95%\n25%\n45%\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nGPT-4 Zero Shot GPT-4 APIL lama-3 Zero\nshot\nLlama-3 API\nAccuracy Rate\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nFigure  6 displays the error percentage distribution across four error types for both GPT-4 and Llama-3 models \nunder Zero Shot and API configurations. Regarding Conceptual Errors, GPT-4 exhibits a significant reduction when \nmoving from Zero Shot to API configuration, dropping from 20 to 0%. This improvement underscores the model’s \nenhanced ability to retrieve and apply necessary concepts with API support. Conversely, Llama-3 maintains a lower \nlevel of Conceptual Errors, at 5% in both Zero Shot and API configuration, indicating a relatively stable performance \nin this category. Calculation Errors also show a significant decrease for GPT-4, from 20% in Zero Shot to 0% in API \nconfiguration. This reduction highlights the model’s improved accuracy in algebraic and arithmetic manipulations \nwith API support. Llama-3, however, shows a slight increase in Calculation Errors from 10% in Zero Shot to 15% in API \nconfiguration, suggesting some challenges in maintaining computational accuracy under API settings. Grounding \nErrors are notably high in both models under Zero Shot conditions, with both GPT-4 and Llama-3 exhibiting a 60% \nerror rate. With API support, these errors drastically decrease to 5% for GPT-4 and 30% for Llama-3. This significant \nreduction indicates that API configurations substantially enhance the models’ ability to apply retrieved concepts cor -\nrectly within equations or constraints. Deficiency Errors are absent in the Zero Shot configurations for both models \nbut appear in the Llama-3 API configuration at a rate of 5%. This outcome suggests that while API support generally \nimproves model performance, it may also introduce new challenges in interpreting images, graphs, and charts for \nLlama-3. Overall, the figure illustrates that both GPT-4 and Llama-3 benefit from API configurations, with GPT-4 show -\ning a more pronounced improvement across all error types. The reduction in Grounding Errors is particularly notable, \nunderscoring the critical role of API configurations in enhancing model performance. However, the emergence of \nDeficiency Errors in the Llama-3 API configuration highlights areas for further improvement, suggesting that while \nAPI configurations are beneficial, they also present new challenges that need to be addressed.\nThe comparative analysis of GPT-4 API and Llama-3 API highlights the importance of specialised formula integra-\ntion in AI-driven educational tools for engineering disciplines. The RAG approach emerged as a promising method \nfor enhancing the accuracy of AI responses, suggesting that the effectiveness of LLMs in educational settings can \nbe significantly improved by leveraging external databases and structured knowledge.\nUltimately, the choice between GPT-4 API and Llama-3 API depends on the specific requirements and constraints of \nthe application. GPT-4 is ideal for scenarios demanding high accuracy, nuanced understanding, and seamless cloud-\nbased integration, offering reliable performance without substantial local hardware. On the other hand, Llama-3 \nprovides a cost-effective, customisable solution suitable for targeted applications requiring specialised adjustments \nand efficient resource use. However, it necessitates an initial investment in hardware for local deployment.\nTo reinforce the reliability of the accuracy evaluation, we conducted statistical significance tests to assess differ -\nences between model performances. To quantify uncertainty in the accuracy estimates, we computed 95% confidence \nintervals (CIs) for each model using the Wilson Score Interval proposed by Wilson [48]. The results are summarised \nin Table 3.\nTo assess whether the observed differences in model accuracy are statistically significant, we conducted a chi-square \ntest comparing GPT-4 (Temp = 0.1) and Llama-3 API.\nFig. 6  Error percentage distri-\nbution by error type for GPT-4 \nand Llama-3 under Zero Shot \nand API configurations\n20%2 0%\n60%\n0%0% 0%\n5%\n0%\n5%\n10%\n60%\n0%\n5%\n15%\n30%\n5%\n0%\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nConceptual Calcula/g415on Grounding Deﬁciency\nError Percentage\nError Type\nGPT-4 Zero Shot\nGPT-4 AP I\nLlama-3 Zero shot\nLlama-3 AP I\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\n(1) Null Hypothesis (H₀): There is no significant difference in accuracy between GPT-4 (Temp = 0.1) and Llama-3 API.\n(2) Alternative Hypothesis (H₁): There is a statistically significant difference in accuracy between these models.\nThe results of the chi-square test are summarised in Table 4.\nSince the p-value (0.0019) is less than 0.05, we reject the null hypothesis and conclude that GPT-4 (Temp = 0.1) significantly \noutperforms Llama-3 API in accuracy. This analysis strengthens the validity of our findings and confirms that the performance \ndifferences observed in our study are statistically significant.\n3.4  Tutor capabilities\nIn developing the AI tutor, we focused on the following key attributes to maximise its effectiveness in personalised educa-\ntion. The design objectives were to ensure adaptability to the learner’s pace and preferences, enhance engagement, and \nmaintain an environment conducive to diverse learning needs [34, 49].\n(1) Personalised Learning Experiences: The AI tutor is engineered to tailor responses based on individual student profiles, \nwhich include their learning pace, preferences, and previous interactions. This customisation enhances the relevance \nand effectiveness of the educational content, making it more accessible to students from various skill sets.\n(2) Interactive Engagement: By using clear and accessible language, the tutor maintains a high level of interaction. \nEngaging students in this manner helps to keep them motivated and improves retention of the material covered.\n(3) Support and Feedback: Integral to the AI tutor’s functionality is its ability to provide constructive feedback. By clearly \nexplaining concepts and offering positive reinforcement, the tutor supports continuous learning and encourages \nacademic exploration.\n(4) Resourcefulness and Flexibility: The tutor is designed to suggest additional materials and alternative learning paths. \nThis capability aids in the comprehension of complex topics and allows students to explore related areas indepen-\ndently, fostering a richer educational experience.\n(5) Safe and Ethical Learning Environment: Adherence to privacy and ethical guidelines ensures that the learning envi-\nronment remains secure, protecting student data and promoting a safe educational space.\nThese attributes are embedded within the prompt template that dictates the AI tutor’s interactions with students, as \ndemonstrated in Listing 1. This template serves as the operational foundation, ensuring that the AI’s responses are accurate, \ninformative, and specifically tailored to enhance the personalised learning experience. The effectiveness of this approach is \nsupported by the following core educational theories:\n(1) Constructivism\nThis theory, pioneered by Piaget [50] and Vygotsky and Luria [51], posits that learners construct knowledge actively \nrather than passively absorbing information. LLM-powered tutors align with this theory by facilitating interactive \nTable 3  Accuracy rates of \ndifferent LLM configurations \nin solving Geotechnical \nEngineering problems\nModel & Setting Accuracy (%) 95% CI Lower 95% CI Upper\nGPT-4 (Temp = 0.1) 95.0 76.4 99.4\nGPT-4 (Temp = 0.5) 82.5 61.4 93.8\nGPT-4 (Temp = 1) 60.0 37.8 79.2\nLlama-3 API 45.0 24.5 67.3\nLlama-3 Zero-Shot 25.0 10.9 47.1\nTable 4  Chi-Square test results assessing the statistical significance of accuracy differences between AI models\nStatistic Value\nChi-square (χ2) 9.64\np-value 0.0019\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nlearning experiences where students can engage in problem-solving and inquiry-based learning. The adaptability \nof AI tutors allows personalised scaffolding, similar to Vygotsky’s concept of the Zone of Proximal Development.\n(2) Cognitive Load Theory\nThe Cognitive Load Theory was proposed by Sweller [52]. This theory emphasises the importance of managing \nintrinsic, extraneous, and germane cognitive loads to optimise learning. LLM-powered tutors can help mitigate \nextraneous load by simplifying complex explanations and tailoring responses to a learner’s proficiency level. The RAG \napproach used in this study enhances information processing efficiency by integrating external resources, reducing \ncognitive overload.\n(3) Self-Regulated Learning Theory (SRL)\nSelf-Regulated Learning Theory, which was proposed by Zimmerman [53] and Schunk and Zimmerman [54], high-\nlights goal setting, self-monitoring, and metacognitive reflection. AI tutoring systems encourage self-regulated learn-\ning by providing immediate feedback, personalised hints, and adaptive questioning. The ability of LLM-powered \ntutors to track student progress and adjust their instructional approach aligns with SRL.\nTable  5 presents sample interactions between the GPT-4 API and students, illustrating how the implemented \nprompt template from Listing 1 effectively facilitates these engagements.\nTable 5  Sample interactions \nbetween GPT-4 API and \nuser using the implemented \nprompt template from Listing 1\nPrompted Question (i.e., Q12.10 from the book written by Das and Sobhan [35]:\nIn a consolidated-drained triaxial test on a clay, the specimen failed at a deviator stress of 124 kN∕m 2 . If \nthe effective stress friction angle is known to be 31°, what was the effective confining pressure at failure?\nGPT-4’s Response:\nUnderstanding the Problem\nIn a consolidated-drained triaxial test, the failure of a specimen occurs when a particular stress state, defined \nby the deviator stress and the confining pressure, meets the failure criterion dictated by the soil’s friction \nangle. The deviator stress (Δ/u1D70E) in a triaxial test is defined as the difference between the axial stress (/u1D70E1) and the \nconfining pressure (/u1D70E3), or:\nΔ/u1D70E= /u1D70E1 − /u1D70E3\nGiven:\n- Deviator stress (Δ/u1D70E) = 124 kN/m2; and—Effective stress friction angle (ϕ’) = 31°\nCalculating Effective Confining Pressure at Failure\nTo relate these variables to the Mohr–Coulomb failure criterion, we express the principal stresses at failure in \nterms of the angle of internal friction. From the theory, we know that:\n/u1D70E1 =Δ /u1D70E+ /u1D70E3\nThe Mohr–Coulomb failure criterion for maximum and minimum principal stresses is given, in its simplest form \n(ignoring cohesion for purely frictional material), by:\n/u1D70E1 = /u1D70E3 × tan2(45◦ + /u1D719�\n2 )\nReplacing (/u1D70E1) in the equation gives us:\nΔ/u1D70E+ /u1D70E3 = /u1D70E3 × tan2(45◦ + /u1D719�\n2 )\nFrom this, we can solve for (/u1D70E3), the effective confining pressure at failure. Let’s start rearranging this equation to \nisolate (/u1D70E3)\nStep-by-step Rearrangement\nTo isolate /u1D70E3, we can modify the equation as follows:\nΔ/u1D70E= /u1D70E3 ×( tan2\n/parenleft.s2\n45◦ + /u1D719�\n2\n/parenright.s2\n− 1)\nThis equation will give us the value of /u1D70E3 if we substitute the values of Δ/u1D70E and /u1D719/uni2032.var\nNext Steps\n- Calculate tan2\n/parenleft.s2\n45◦ + /u1D719�\n2\n/parenright.s2\n. Could you go ahead and compute this value based on the given friction angle (ϕ’) \nof 31°?\n- Once you have that calculation, use it to find the effective confining pressure /u1D70E3 using the rearranged formula\nThis calculation will incorporate the theory we’ve discussed, and I’m here to help guide you through each step if \nyou need further assistance!\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\nListing 1   AI tutor prompt template\n3.5  GPT API vs CustomGPT\nSimilar to GPT API, CustomGPT is an alternative feature offered by OpenAI, designed to enhance GPT’s functionality by \nallowing the integration of external knowledge for more accurate responses. We also compared GPT API and CustomGPT \nas follows:\n(1) Ease of Use: CustomGPT is more accessible to build and requires no code, while the GPT API offers more flexibility \nand customisation.\n(2) Extended Knowledge and Tools: Both options provide extended knowledge and tools, such as data retrieval and \ncode execution.\n(3) User Interface: CustomGPT uses the familiar chat interface, while the GPT API allows for a customised user experi-\nence.\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\n(4) Maintenance: Maintenance is more straightforward with CustomGPT, as OpenAI handles hosting and updates. The \nGPT API requires managing the application.\n(5) Business Opportunities: The GPT API offers more business opportunities, such as providing paid tiers, while Custom \nGPTs may have revenue sharing in the future.\n(6) Developer Experience: CustomGPT requires no coding and can be built entirely within the chat interface, while the \nGPT API requires creating an application and hosting the code externally.\n(7) Classroom Impact: GPT API in classrooms is cost-effective for short-term use as users do not need a ChatGPT Plus \naccount. CustomGPT can be shared with students if account credentials are provided, though this can be problem-\natic due to query limits per hour in CustomGPT.\n3.6  Ethical considerations\nThe deployment of AI-powered tutors in undergraduate Geotechnical Engineering and education broadly necessitates \na thorough examination of the ethical implications associated with its use [55– 57]. Data privacy, algorithmic bias, and \nthe impact on traditional teaching roles are three primary areas of concern, as detailed below.\n(1) Data Privacy: Using LLMs like GPT-4 and Llama-3 requires processing vast amounts of personal and academic data \nfrom students to tailor educational experiences effectively. Ensuring the confidentiality and security of this data is \nparamount. Transparency data handling and storage policies must be in place, adhering to regulations such as the \nGeneral Data Protection Regulation (GDPR) in the European Union or Family Educational Rights and Privacy Act \n(FERPA) in the United States. Additionally, the consent of students and educators must be obtained, clearly outlining \nhow their data will be used and the measures taken to protect it.\n(2) Algorithmic Bias: AI models, including LLMs, are trained on large datasets that may contain historical biases. These \nbiases can be inadvertently perpetuated and amplified by AI, leading to unfair or discriminatory educational experi-\nences. Continuous monitoring and updating of AI models are crucial to identify and mitigate any embedded biases, \nensuring that AI tutors provide equitable educational support to all students.\n(3) Impact on Traditional Teaching Roles: Integrating AI tutors in education introduces concerns about the potential \ndisplacement of traditional teaching roles and the devaluation of human educators. It is crucial to frame AI tutors \nnot as replacements but as supplements to human educators, enhancing the educational experience by providing \nadditional support for personalised attention and immediate feedback. Educators play a crucial role in interpreting \nAI-generated content, providing context, and fostering critical thinking and emotional intelligence skills that AI \ncannot replicate.\n3.7  LLM APIs limitations\nThe LLM APIs, while advanced, present their own set of limitations. GPT-4’s impressive performance, particularly with \nthe RAG approach, underscores the potential of integrating external knowledge sources. However, this reliance also \nhighlights a critical limitation: the model’s understanding and responses are as good as the data it can access, which \nmay sometimes be outdated or biased. Furthermore, the RAG approach requires significant computational resources \nand sophisticated data management strategies, potentially limiting its accessibility for some educational institutions.\nLlama-3’s Zero Shot capabilities demonstrate the model’s adaptability and the potential for wide application without \nextensive customisation. Yet, this strength is also a weakness, as the lack of domain-specific tuning can lead to inaccura-\ncies or oversimplified explanations that might not meet the educational standards required for complex engineering \nconcepts.\n3.8  Study limitations and areas for AI tutor enhancement\nThe scope of this research is confined to undergraduate Geotechnical Engineering education, which may not fully repre-\nsent the challenges and opportunities of using LLM APIs in other engineering disciplines or educational levels. Moreover, \nthe comparative analysis primarily focused on two LLM APIs—GPT-4 and Llama-3—selected for their prominence and \naccessibility. This selection excludes other emerging LLMs that offer unique advantages or drawbacks in educational \ncontexts. The study’s methodology, emphasising formula integration and problem-solving, may also overlook other \ncritical aspects of learning, such as fostering creativity, critical thinking, and collaboration among students.\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\nOne other limitation of this study is the exclusive use of text-based questions. In Geotechnical Engineering, many \nproblems involve graphical data representations, such as Mohr’s circles, soil classification charts, and stress–strain curves. \nSince no images or graphs were provided as input, the AI models were unable to demonstrate their ability to process \nvisual information—a key aspect of real-world engineering problem-solving.\nFuture studies should explore multimodal AI models, such as GPT-4V (Vision) or Claude Opus, which can analyse both \ntext and images. Evaluating LLM performance on graph-based geotechnical problems would provide deeper insights \ninto their practical applicability in engineering education.  \nThe limitations identified above point to several key areas for improvement in AI tutor development. Enhancing the \nquality and diversity of datasets used to train LLMs can address biases and ensure that AI tutors provide more accurate, \ninclusive, and contextually relevant support. Developing more sophisticated data integration and processing techniques \ncan improve the models’ ability to handle complex, formula-driven problems typical in engineering education.\nAdditionally, there is a pressing need for mechanisms that allow educators to easily update and customise AI tutors, \nensuring that the content remains current with the latest scientific developments and pedagogical strategies. Finally, \nfostering interdisciplinary collaboration between AI researchers, educators, and students can lead to the development \nof more effective, user-friendly, and ethically responsible AI educational tools.\n4  Conclusion and implications for future research\nThis study demonstrates that both GPT-4, as a commercial model, and Llama-3, as an open-source model, can effectively \ngenerate accurate answers and step-by-step explanations for typical Geotechnical Engineering problems. These capabili-\nties suggest that LLMs may serve as a useful supplementary resource, akin to textbooks or solution manuals, for students \nseeking additional guidance outside the classroom. Llama-3 showed a reasonable understanding of the subject matter, \nalbeit with slightly less precision in formula application than GPT-4. If Llama-3 is augmented with math capability, the \naccuracy might improve as it might reduce its deficiency in solving complex maths problems.\nOur results also provide new insights into how LLMs perform on Geotechnical Engineering problems, particularly \nin relation to formula application, conceptual reasoning, and physics-based problem-solving. A notable finding of this \nresearch is that GPT-4 with Retrieval-Augmented Generation (RAG) achieved a 95% accuracy rate on formula-driven \nproblems, demonstrating that LLMs can successfully retrieve and apply standard Geotechnical equations when properly \nprompted. However, accuracy declined when problems required higher-order conceptual reasoning, particularly when:\n(1) Interpreting problem constraints from textual descriptions (e.g., determining which soil parameters to use when \nmultiple is provided).\n(2) Applying multi-step physical principles, such as stress–strain relationships and seepage analysis.\n(3) Understanding implicit assumptions in soil behaviour, such as the role of effective stress versus total stress in con-\nsolidation problems.\nThe evaluation based on the set criteria—accuracy of content, formula integration, clarity of explanations, and adapt-\nability—revealed that while no model perfectly addresses all educational needs in Geotechnical Engineering, each has \nunique strengths that contribute to their potential as AI tutors. This study demonstrates that GPT-4 with RAG can func -\ntion as a supplementary learning tool for Geotechnical Engineering students, particularly in solving structured numeri-\ncal problems with well-defined parameters. However, its limitations in contextual reasoning, multi-step dependency \nproblems, and boundary condition interpretation suggest that AI tutors should be used as assistive tools rather than \nreplacements for traditional instruction. Future work should explore how AI models can be optimised for conceptual \nunderstanding and decision-making in engineering applications.\nImportantly, this study demonstrates that AI tutors can provide structured guidance and interactive problem-solving \nsupport, rather than merely offering solutions. By encouraging student engagement, prompting step-by-step calcula-\ntions, and offering conceptual reinforcement, the AI tutor functions as a true learning aid rather than a static answer \nprovider. The 24/7 availability of these AI tutors further ensures that students can access learning support at any time, \nfostering independent problem-solving and deeper conceptual understanding.\nThe potential of LLM APIs, such as GPT-4 and Llama-3, in transforming Geotechnical Engineering education is evident. \nAs AI technology continues to evolve, so will its capabilities to support and enrich the learning journey of engineering \nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\nstudents. By harnessing these advancements, educators can look forward to more personalised, engaging, and effective \nteaching tools tailored to the challenges of educating the next generation of engineers.\nWhile this study highlights the promise of AI tutors in Geotechnical Engineering, several areas warrant further \nexploration:\n(1) Content Development: The technique could also be used to develop exam questions, rubric development for assign-\nments, role-playing scenarios such as Geotechnical professional evaluations, providing feedback on assignments, \nand brainstorming ideas.\n(2) Experimental Designs: Future studies could employ longitudinal designs to assess the long-term effectiveness of \nAI tutors in Geotechnical Engineering education in the real-world environment. Tracking students’ progress over \nsemesters or years could provide deeper insights into how AI tutoring impacts knowledge retention, conceptual \nunderstanding, and practical application skills over time. Additionally, experimental designs incorporating control \ngroups—where some students receive AI tutoring, and others do not—could offer more definitive conclusions \nabout the efficacy of these tools.\n(3) Datasets: Developing and validating specialised datasets for training LLMs in Geotechnical Engineering are crucial. \nFuture research should focus on curating high-quality, diverse datasets that cover a broad spectrum of Geotechnical \nEngineering topics, including emerging areas of research and development. These datasets should also aim to be \ninclusive, representing a wide range of geographical regions, soil types, and engineering challenges to ensure the \nmodels’ applicability across different contexts.\n(4) Formula Integration Techniques: Exploring advanced formula integration techniques is another vital area for future \nresearch. This includes the development of novel algorithms that can better understand and process complex math-\nematical expressions, diagrams, and data tables common in Geotechnical Engineering. Investigating the integra-\ntion of symbolic computation libraries with LLMs could enhance their ability to solve complex numerical problems \naccurately. Moreover, using augmented reality and virtual reality technologies to visualise complex geotechnical \nprocesses and simulations in tandem with AI tutors could revolutionise how students interact with and understand \nthe subject matter.\n(5) Broader Educational Contexts: Future studies should also consider the application of AI tutors in a broader range of \neducational settings, including vocational training programs, continuing education for professionals, and interdis-\nciplinary engineering courses. Evaluating the effectiveness of AI tutors across different learning environments, such \nas online learning platforms, hybrid classrooms, and traditional lecture halls, could provide insights into how these \ntools can be best implemented to suit various educational needs.\n(6) Ethical and Social Implications: Further research is needed to explore the ethical and social implications of deploy -\ning AI tutors in education. This includes studying the impact of AI on educational equity, student privacy, and the \ndigital divide. Developing frameworks for ethical AI use in academic settings, addressing bias in AI algorithms, and \nensuring that AI tutors are accessible to all students regardless of their socio-economic background are critical areas \nfor investigation.\nThe findings of this study provide actionable insights for educators and institutions looking to integrate AI-driven \ntools into engineering education. By leveraging GPT-4 with RAG-based optimisation, educators can improve the \naccuracy and reliability of AI tutors, ensuring that students receive precise and context-aware explanations for Geo -\ntechnical Engineering problems. This approach can be particularly beneficial in flipped classroom models or blended \nlearning environments, where AI tutors serve as on-demand learning assistants, allowing instructors to focus on \nhigher-order conceptual discussions rather than repetitive problem-solving.\nAdditionally, the study highlights the potential for multimodal AI integration—combining text-based LLM \nresponses with visual aids, diagrams, and interactive simulations—to enhance student engagement and compre -\nhension. Educators can adopt these techniques by incorporating AI-generated explanations into digital learning \nplatforms, integrating automated assessment tools, and using AI tutors for scaffolded learning experiences in STEM \ncourses.\nThese findings highlight the growing role of AI in reshaping traditional engineering education, and future research \nshould explore best practices for AI implementation, including pedagogical strategies for effectively incorporating \nAI tutors into real-world classrooms.\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\nAcknowledgements During the preparation of this manuscript, the authors utilised GPT-4 to assist with editing. Subsequent to using this \ntool, the authors carefully reviewed and revised the content as necessary. Full responsibility for the final content of this publication rests with \nthe authors.\nAuthor contributions Conceptualisation, A.T., L.C., U.H. and J.K.; methodology, L.C., A.T., U.H. and J.K.; software, A.T., L.C. and U.H.; validation, \nA.T. and L.C.; formal analysis, L.C., A.T. and U.H.; investigation, L.C., A.T., U.H. and J.K.; resources, A.T.; data curation, L.C.; writing—original draft \npreparation, L.C. and A.T.; writing—review and editing, J.K.; visualisation, A.T., L.C. and U.H.; supervision, J.K.; project administration, J.K.; fund-\ning acquisition, J.K. All authors have read and agreed to the published version of the manuscript.\nFunding Open Access funding enabled and organized by CAUL and its Member Institutions. This research work was sponsored by the SPARC \nHub (https://sparchub.org.au), which is affiliated with the Department of Civil Engineering at Monash University. This project is supported \nunder the Australian Research Council (ARC) Industrial Transformation Research Hub (ITRH) Scheme (Project ID: IH180100010). We extend our \nsincere gratitude to Monash University and the SPARC Hub for their financial and in-kind support.\nData availability Data sets generated during the current study are available from the corresponding author on reasonable request.\nDeclarations \nEthics approval and consent to participate Not applicable.\nConsent for publications Not applicable.\nCompeting interests The authors declare no competing interests.\nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article \nare included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Harry A. Role of AI in education. Interdicip J Humman INJURITY. 2023. https:// doi. org/ 10. 58631/ injur ity. v2i3. 52.\n 2. Kohnke L, Moorhouse BL, Zou D. ChatGPT for language teaching and learning. RELC J. 2023. https:// doi. org/ 10. 1177/ 00336 88223 11628 \n68.\n 3. Kumar K. Geotechnical parrot tales (GPT): harnessing large language models in geotechnical engineering. J Geotech Geoenviron Eng. \n2024. https:// doi. org/ 10. 1061/ JGGEFK. GTENG- 11828.\n 4. Saputra I, Astuti M, Sayuti M, Kusumastuti D. Integration of artificial intelligence in education: opportunities, challenges, threats and \nobstacles: a literature review. Indones J Computer Sci. 2023. https:// doi. org/ 10. 33022/ ijcs. v12i4. 3266.\n 5. Song Y. Redefining STEM education in the post-ChatGPT era—case studies and perspectives. SSRN Electron J. 2024. https:// doi. org/ 10. \n2139/ ssrn. 47336 85.\n 6. Wang X, Li L, Tan SC, Yang L, Lei J. Preparing for AI-enhanced education: conceptualizing and empirically examining teachers’ AI readiness. \nComputers Hum Behav. 2023. https:// doi. org/ 10. 1016/j. chb. 2023. 107798.\n 7. Pursnani V, Sermet Y, Kurt M, Demir I. Performance of ChatGPT on the US fundamentals of engineering exam: comprehensive assessment \nof proficiency and potential implications for professional environmental engineering practice. Computers Educ Artif Intell. 2023. https:// \ndoi. org/ 10. 1016/j. caeai. 2023. 100183.\n 8. VarastehNezhad A, Tavasoli R, Masumi M, Taghiyareh F. LLM performance assessment in computer science graduate entrance exams. In: \n2024 11th International Symposium on Telecommunications (IST). IEEE; 2024. pp. 232–7.\n 9. Maitland A, Fowkes R, Maitland S. Can ChatGPT pass the MRCP (UK) written examinations? Analysis of performance and errors using a \nclinical decision-reasoning framework. BMJ Open. 2024. https:// doi. org/ 10. 1136/ bmjop en- 2023- 080558.\n 10. Honig C, Rios S, Desu A. Generative AI in engineering education: understanding acceptance and use of new GPT teaching tools within a \nUTAUT framework. Australas J Eng Educ. 2025. https:// doi. org/ 10. 1080/ 22054 952. 2025. 24675 00.\n 11. Xu HR, Zhang N, Yin ZY, Guy Atangana Njock P . GeoLLM: a specialized large language model framework for intelligent geotechnical design. \nComputers Geotech. 2025. https:// doi. org/ 10. 1016/j. compg eo. 2024. 106849.\n 12. Wu S, Otake Y, Mizutani D, Liu C, Asano K, Sato N, Saito T, Baba H, Fukunaga Y, Higo Y, Kamura A, Kodama S, Metoki M, Nakamura T, Naka-\nzato Y, Shioi A, Takenobu M, Tsukioka K, Yoshikawa R. Future-proofing geotechnics workflows: accelerating problem-solving with large \nlanguage models. Georisk. 2024. https:// doi. org/ 10. 1080/ 17499 518. 2024. 23810 26.\n 13. Nguyen DV, Nguyen QN. Evaluating the symbol binding ability of large language models for multiple-choice questions in vietnamese \ngeneral education. In: ACM International Conference Proceeding Series. Association for Computing Machinery. 2023; pp. 379–86.\nVol:.(1234567890)\nResearch  \nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8\n 14. Yang R, Yang B, Ouyang S, She T, Feng A, Jiang Y, Lecue F, Lu J, Li I. Leveraging large language models for concept graph recovery and \nquestion answering in NLP education. 2024.\n 15. Cain W. Prompting change: exploring prompt engineering in large language model AI and its potential to transform education. TechTrends. \n2024;68(1):47–57. https:// doi. org/ 10. 1007/ s11528- 023- 00896-0.\n 16. Lee U, Jung H, Jeon Y, Sohn Y, Hwang W, Moon J, Kim H. Few-shot is enough: exploring ChatGPT prompt engineering method for \nautomatic question generation in English education. Educ Inf Technol. 2023. https:// doi. org/ 10. 1007/ s10639- 023- 12249-8.\n 17. Chen L, Tophel A, Hettiyadura U, Kodikara J. An investigation into the utility of large language models in geotechnical education and \nproblem solving. Geotechnics. 2024;4(2):470–98. https:// doi. org/ 10. 3390/ geote chnic s4020 026.\n 18. Lu J, Yu L, Li X, Yang L, Zuo C. LLaMA-reviewer: advancing code review automation with large language models through parameter-\nefficient fine-tuning. In: Proceedings—International Symposium on Software Reliability Engineering, ISSRE. 2023.\n 19. Chen B, Yi F, Varró D. Prompting or fine-tuning? A comparative study of large language models for taxonomy construction. In: 2023 \nACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C). IEEE; 2023. pp. \n588–96.\n 20. Ge J, Sun S, Owens J, Galvez V, Gologorskaya O, Lai JC, Pletcher MJ, Lai K. Development of a liver disease–specific large language model \nchat interface using retrieval-augmented generation. Hepatology. 2024. https:// doi. org/ 10. 1097/ hep. 00000 00000 000834.\n 21. Jeong C. A study on the implementation of generative AI services using an enterprise data-based LLM application architecture. Adv Artif \nIntell Mach Learn. 2023. https:// doi. org/ 10. 54364/ aaiml. 2023. 1191.\n 22. Thompson WE, Vidmar DM, De Freitas JK, Pfeifer JM, Fornwalt BK, Chen R, Altay G, Manghnani K, Nelsen AC, Morland K, Stumpe MC, Miotto \nR. Large language models with retrieval-augmented generation for zero-shot disease phenotyping. 2023.\n 23. Zhang Y, Zhu M, Gong Y, Ding R. Optimizing science question ranking through model and retrieval-augmented generation. Int J Computer \nSci Inform Technol. 2023. https:// doi. org/ 10. 62051/ ijcsit. v1n1. 17.\n 24. Lewis P , Perez E, Piktus A, Petroni F, Karpukhin V, Goyal N, Küttler H, Lewis M, Yih W, Rocktäschel T, Riedel S, Kiela D. Retrieval-augmented \ngeneration for knowledge-intensive NLP tasks. 2020.\n 25. Minaee S, Mikolov T, Nikzad N, Chenaghlu M, Socher R, Amatriain X, Gao J. Large language models: a survey. 2024.\n 26. Raiaan MAK, Mukta MSH, Fatema K, Fahad NM, Sakib S, Mim MMJ, Ahmad J, Ali ME, Azam S. A review on large language models: archi-\ntectures, applications, taxonomies, open issues and challenges. IEEE Access. 2024;12:26839–74. https:// doi. org/ 10. 1109/ ACCESS. 2024. \n33657 42.\n 27. Xu X, Li M, Tao C, Shen T, Cheng R, Li J, Xu C, Tao D, Zhou T. A survey on knowledge distillation of large language models. 2024.\n 28. Chai SH, Chen I, Huang J, Yacoub T. Large language model for geotechnical engineering applications using retrieval augmented genera-\ntion. In: Geotechnical frontiers. Reston: American Society of Civil Engineers; 2025. pp. 1–10.\n 29. Krathwohl DR. A revision of bloom’s taxonomy: an overview. Theory Into Practice. 2002;41(4):212–8. https:// doi. org/ 10. 1207/ s1543 0421t \nip4104_2.\n 30. Ranaldi L, Freitas A. Aligning large and small language models via chain-of-thought reasoning. In: 18th Conference of the European \nChapter of the Association for Computational Linguistics. Long Papers. 2024. pp. 1812–27.\n 31. Hadi MU, Qureshi R, Shah A, Irfan M, Zafar A, Shaikh MB, Akhtar N, Wu J, Mirjalili S. Large language models: a comprehensive survey of \nits applications, challenges, limitations, and future prospects. Authorea Preprints. Authorea. 2023.\n 32. Rosoł M, Gąsior JS, Łaba J, Korzeniewski K, Młyńczak M. Evaluation of the performance of GPT-3.5 and GPT-4 on the Polish Medical Final \nExamination. Sci Rep. 2023. https:// doi. org/ 10. 1038/ s41598- 023- 46995-z.\n 33. Chiasson RM, Goodboy AK, Vendemia MA, Beer N, Meisz GC, Cooper L, Arnold A, Lincoski A, George W, Zuckerman C, Schrout J. Does the \nhuman professor or artificial intelligence (AI) offer better explanations to students? Evidence from three within-subject experiments. \nCommun Educ. 2024;73(4):343–70. https:// doi. org/ 10. 1080/ 03634 523. 2024. 23981 05.\n 34. Afzal S, Dempsey B, D’Helon C, Mukhi N, Pribic M, Sickler A, Strong P , Vanchiswar M, Wilde L. The personality of ai systems in education: \nexperiences with the watson tutor, a one-on-one virtual tutoring system. Child Educ. 2019. https:// doi. org/ 10. 1080/ 00094 056. 2019. 15658 \n09.\n 35. Das B, Sobhan K. Principles of Geotechnical engineering, Eight Edition. In: Cengage Learning. 2014.\n 36. OpenAI. GPT-4 Technical Report. 2023;4: 1–100.\n 37. OpenAI. Models—OpenAI API. 2023.\n 38. Nascimento E, García G, Victorio W, Lemos M, Izquierdo Y, Garcia R, Paes Leme LAP , Casanova MA. A family of natural language interfaces \nfor databases based on ChatGPT and LangChain. In: CEUR Workshop Proceedings. 2023.\n 39. Neira-Maldonado P , Quisi-Peralta D, Salgado-Guerrero J, Murillo-Valarezo J, Cárdenas-Arichábala T, Galan-Mena J, Pulla-Sanchez D. Intel-\nligent educational agent for education support using long language models through Langchain. In: Lecture Notes in Networks and \nSystems. 2024.\n 40. Soygazi F, Oguz D. An analysis of large language models and LangChain in mathematics education. In: ACM International Conference \nProceeding Series. 2023.\n 41. Auffarth B. Generative AI with LangChain: build large language model (LLM) apps with Python, ChatGPT, and other LLMs. Birmingham: \nPackt Publishing; 2023.\n 42. Topsakal O, Akinci TC. Creating large language model applications utilizing LangChain: a primer on developing LLM apps fast. Int Conf \nAppl Eng Nat Sci. 2023. https:// doi. org/ 10. 59287/ icaens. 1127.\n 43. Workman AD, Rathi VK, Lerner DK, Palmer JN, Adappa ND, Cohen NA. Utility of a LangChain and OpenAI GPT-powered chatbot based on \nthe international consensus statement on allergy and rhinology: rhinosinusitis. Int Forum Allergy Rhinol. 2023. https:// doi. org/ 10. 1002/ \nalr. 23310.\n 44. Antaki F, Milad D, Chia MA, Giguère CÉ, Touma S, El-Khoury J, Keane PA, Duval R. Capabilities of GPT-4 in ophthalmology: an analy -\nsis of model entropy and progress towards human-level medical question answering. Br J Ophthalmol. 2023. https:// doi. org/ 10. 1136/ \nbjo- 2023- 324438.\nVol.:(0123456789)\nDiscover Computing           (2025) 28:76  | https://doi.org/10.1007/s10791-025-09580-8 \n \n Research\n 45. Civettini I, Zappaterra A, Ramazzotti D, Granelli BM, Rindone G, Aroldi A, Bonfanti S, Colombo F, Fedele M, Grillo G, Parma M, Perfetti P , \nTerruzzi E, Gambacorti-Passerini C, Cavalca F. Evaluating the performance of large language models in hematopoietic stem cell trans-\nplantation decision making. Blood. 2023. https:// doi. org/ 10. 1182/ blood- 2023- 185854.\n 46. Wang C, Liu SX, Awadallah AH. Cost-effective hyperparameter optimization for large language model generation inference. In: Proceed-\nings of Machine Learning Research. 2023.\n 47. OpenAI. OpenAI Platform. 2024. https:// platf orm. openai. com/ docs/ api- refer ence/ chat/ create. Accessed 6 Oct 2024.\n 48. Wilson EB. Probable inference, the law of succession, and statistical inference. J Am Stat Assoc. 1927. https:// doi. org/ 10. 1080/ 01621 459. \n1927. 10502 953.\n 49. Kim WH, Kim JH. Individualized AI tutor based on developmental learning networks. IEEE Access. 2020. https:// doi. org/ 10. 1109/ ACCESS. \n2020. 29721 67.\n 50. Piaget J. To understand is to invent: the future of education. London: Penguin Books; 1976.\n 51. Vygotsky L, Luria A. Tool and symbol in child development. Mind in Society. 1978.\n 52. Sweller J. Cognitive load during problem solving: effects on learning. Cognit Sci. 1988. https:// doi. org/ 10. 1016/ 0364- 0213(88) 90023-7.\n 53. Zimmerman BJ. Becoming a self-regulated learner: an overview. Theory Pract. 2002. https:// doi. org/ 10. 1207/ s1543 0421t ip4102_2.\n 54. Schunk DH, Zimmerman BJ. Motivation and self-regulated learning: theory, research, and applications. In: Schunk DH, Zimmerman BJ, \neditors. Motivation and self-regulated learning: theory, research, and applications. Milton Park: Routledge; 2012.\n 55. Guleria A, Krishan K, Sharma V, Kanchan T. ChatGPT: ethical concerns and challenges in academics and research. J Infect Dev Ctries. 2023. \nhttps:// doi. org/ 10. 3855/ jidc. 18738.\n 56. Liyanage UP , Ranaweera ND. Ethical considerations and potential risks in the deployment of large language models in diverse societal \ncontexts. J Comput Soc Dyn. 2023;8(11):15–25.\n 57. Vidhya NG, Devi D, Nithya A, Manju T. Prognosis of exploration on Chat GPT with artificial intelligence ethics. Braz J Sci. 2023. https:// doi. \norg/ 10. 14295/ bjs. v2i9. 372.\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations."
}