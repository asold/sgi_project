{
  "title": "A Trust Model with Statistical Foundation",
  "url": "https://openalex.org/W1529085936",
  "year": 2005,
  "authors": [
    {
      "id": "https://openalex.org/A2101770671",
      "name": "Jianqiang Shi",
      "affiliations": [
        "University of Ottawa"
      ]
    },
    {
      "id": "https://openalex.org/A2646245592",
      "name": "GREGOR V. BOCHMANN",
      "affiliations": [
        "University of Ottawa"
      ]
    },
    {
      "id": "https://openalex.org/A2122389175",
      "name": "Carlisle Adams",
      "affiliations": [
        "University of Ottawa"
      ]
    },
    {
      "id": "https://openalex.org/A2101770671",
      "name": "Jianqiang Shi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2646245592",
      "name": "GREGOR V. BOCHMANN",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122389175",
      "name": "Carlisle Adams",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1551191033",
    "https://openalex.org/W1541900693",
    "https://openalex.org/W1593553581",
    "https://openalex.org/W2098685442",
    "https://openalex.org/W2134661798",
    "https://openalex.org/W46433006",
    "https://openalex.org/W1975621626",
    "https://openalex.org/W2158701542",
    "https://openalex.org/W2157038946",
    "https://openalex.org/W2140615073",
    "https://openalex.org/W1517105885",
    "https://openalex.org/W4242500534",
    "https://openalex.org/W2483117857",
    "https://openalex.org/W2100107987"
  ],
  "abstract": null,
  "full_text": "A Trust Model with Statistical Foundation\nJianqiang Shi1 , Gregor v. Bochmann2 and Carlisle Adams 2\n'Systems Science; 2School of Information Technology andEngineehng (SITE)\nUniversity ofOttawa\nOttawa, Ontario, Canada KIN 6N5\n{jianqshi, bochmann, cadams}@site.uottawa.ca\nKey words:trust, utility, decision making\nAbstract: The widespread use of the Internet signals the need for a better understanding of trust\nas a basis for secure on-line interaction. In the face of increasing uncertainty and risk, users and\nmachines must be allowed to reason effectively about the trustworthiness of other entities. In this\npaper, we propose a trust model that assists users and machines with decision-making in online\ninteractions by using past behavior as a predictor of likely füture behavior. We develop a general\nmethod to automatically compute trust based on self-experience and the recommendations of\nothers. Furthermore, we apply our trust model to several utility models to increase the accuracy of\ndecision-making in different contexts of Web Services.\n1. INTRODUCTION\nWith the expansion of the Internet, users and services are often required to\ninteract with unknown entities. This is so in application areas such as e-\ncommerce, knowledge sharing, and even game playing. Because the entities are\nautonomous and potentially subject to different administrative and legal domains,\nit is important for each user to identify trustworthy entities or correspondents\n146 Formal Aspects ofSecurity and Trust\nwith whom he/she should interact, and untrustworthy correspondents with whom\nhe/she should avoid interaction [6].\nTrust models have emerged as an important risk management mechanism in such\nonline communities. The goal of a trust model is to assist users with decision-\nmaking in online interactions by using past behavior as a predictor of likely\nfuture behavior. Most electronic marketplaces on the Internet, such as eBay,\nYahoo Auction, Amazon, and Epinions, support some form of trust management\nmechanism. eBay, for example, encourages both parties of each transaction to\nrate the other participant with a positive (+1), neutral (0), or negative (-1) rating.\neBay makes the cumulative ratings of its members publicly known to every\nregistered user [10]. Epinions provides a mechanism to weave \"the web of trust\",\na network of members whose reviews and ratings have been consistently found\nvaluable. Each member can write a review on any topic and product. Reviews\ncan be rated as \"Not Helpful\", \"Somewhat Helpful\", \"Helpful\", and \"Very\nHelpfül\". The Web of Trust mimics the way people share word-of-mouth advice\nevery day. Shareaza, a P2P flle sharing system, allows members to write\ncomments and ratings with respect to shared files. Thus, Shareaza allows\nmembers to avoid those that are fakes and download good quality, accurately\nrepresented files.\nOur goal is to develop a general trust model that can be used for making rational\ndecisions in order to make optimal choices. It should be usable in the context of\nWeb Services and online transactions that meet real people's needs. We have\nopted for a trust model that is based on stochastic models of Web Services. We\nwill explain how trust can be built up from experimental evidence and how\nstatistical methods can be applied, together with utility functions, to make\nrational choices between different service providers or different strategies for\nproblem solving. Our trust model is scalable in the number of users and services,\nand is usable, both for people and artificial autonomous agents.\nThe rest of\n this paper is organized as follows. Section 2 summarizes some related\nwork on trust models. Section 3 introduces our approach, a trust model with a\nstatistical foundation, giving the key deflnitions for the state space of possible\noutcomes of actions, trust update, and outcome space mapping. Section 4\npresents some decision models. Section 5 briefly introduces recommendations\nand their evaluation. Section 6 concludes the paper and discusses potential\ndirections for future work.\nA Trust Model with Statistical Foundation 147\n2. EXISTING DEFINITIONS OF TRUST AND RELATED\nWORK\nDue to limited space, this section is abridged from the full paper (available at\nhttp://www.site.uottawa.ca/~cadams/papers/TrustStat.pdf).\nWe write T a(ß,ö) for the trust an entity a has in another entity ß with respect to a\ngiven situation S. General trust represents the trust an entity a has in an entity ß\nover all situations. We write T a(ß) for the general trust of entity a in entity ß.\nBasic trust is the general trusting disposition of the entity. We write T a for the\nbasic trust of entity a.\n3. A TRUST MODEL WITH A STATISTICAL\nFOUNDATION\nIn this section we propose a statistical foundation for a trust model. Such a\nfoundation is intuitive and useful in many practical situations, as will be shown in\nSection 4.\n3.1 A model of the trusted entity\nOur trust model is based on a model of the trusted entity ß. We discuss the space\nof possible outcomes with respect to a service performed by ß and then propose a\nstochastic model for ß.\n3.1.1 The space of possible outcomes\nOur trust model is based on an abstract model of the trusted entity. We assume\nthat the trust concerns the execution of a certain action by the entity. In most\ncases, the execution of the action corresponds to a specific service that is\nprovided by the trusted entity. There may be different outcomes of the action.\nThe trust is concerned with some form of prediction of what the outcome will\nprobably be. In the case of situational trust, we are concerned with a particular\naction in a certain situation; in the case of general trust, the action represents any\naction of the trusted entity that may be of interest.\nIt is important to identify the space of possible outcomes. This space determines\nthe nature of the associated trust model. We note that the granularity of this space\ndetermines the precision with which any prediction of future behavior can be\nmade. We give in the following some typical examples.\n148 Formal Aspects ofSecurity and Trust\na) Discrete categories\nIn this case, the outcomes are classifled into a flnite set of categories. For\ninstance, the eBay trust model foresees the three categories: \"positive\", \"neutral\",\nand \"negative\". In the case of trust concerning the quality of the food in a\nrestaurant, the categories may be \"excellent\", \"good\", \"average\", \"bad\", and \"very\nbad\". The case of two-valued outcomes is a special case of discrete categories;\nhere the outcomes are classified into two categories, which may be called \"good\"\nand \"bad\".\nWhile in the above examples, the different categories were ordered according to\nsome intuitive \"goodness\" relationship (\"good\" being better than \"average\", for\ninstance), there are cases in which such an ordering does not necessarily exist.\nWe may consider the example where the outcomes are classifled into the\nfollowing categories: \"normal: all options OK\", \"option A failed\", and \"option B\nfailed\". Here it is not clear which of the last two categories would be better.\nb) Numeric outcomes\nThere are many cases in which the outcome can be characterized by a numerical\nvalue. For instance, the trust may concern the response time of a Web server, or\nthe delivery delay of a parcel delivery service. In these cases, we are interested in\nthe delay for completing the action, and this delay may be measured in fractions\nof seconds, minutes, or hours, depending on the precision that is reasonable for\nthe application. In these cases, the number of different outcomes is in principle\ninflnite.\nOther examples where the outcomes can be classifled by a numerical value are\nthe following: (1) What percentage of cost overruns can one expect in a\nconstruction contract? - or (2) What is the expected quality of a video obtained\nfrom a video-on-demand service?\nc) Multidimensional outcome characterization\nIn many situations, the outcome of the action of interest has several parameters\nthat are important to consider. Each of these parameters can usually be\ncharacterized either by a value from discrete value space, or a numerical (integer\nor real) value. In this case, we say that the space of the possible outcomes is\nmulti-dimensional (one dimension for each parameter). Here are two examples:\n1. Restaurant service with several evaluation criteria: (i) quality of food, (ii)\nservice, and (iii) environment. For each of these three criteria, the restaurant may\nbe classified into a certain number of discrete values, such as \"excellent\" down to\n\"very bad\". Therefore, the outcome of a restaurant experience may be classifled\nas a point in this three-dimensional space, where each coordinate in this space is\ndefined by a value between \"excellent\" and \"very bad\".\nA Trust Model with Statistical Foundation 149\n2. Multimedia presentation quality: As explained in [14] and [15], the quality of\na multimedia presentation may be characterized by three values: (i) frame rate (in\nvideo frames per second), (ii) resolution (number of pixels within a frame), and\n(iii) color quality (number of colors distinguished per pixel). Therefore, the\noutcome of a video presentation obtained from a video-on-demand service may\nbe characterized by three numerical values corresponding to these three quality\nof service parameters.\n3.1.2 A stochastic model of the trusted entity\nWe assume that the trusted entity behaves like a stochastic process, in the sense\nthat the outcome of an action of interest cannot be predicted exactly, that the\noutcome of one execution of an action of interest is statistically independent of\nthe outcome of previous executions of that action, and that, over the long run, the\nprobability that the outcome for the next execution of the action will be a\nparticular point within the space of possible outcomes is described by a\nprobability distribution, which we call the outcome distribution of the trusted\nentity, and which we represent by  Dß. The value of  Dß for a particular outcome o\ne O (where O is the space of possible outcomes) is written as  Dß(o). The outcome\ndistribution is a distribution over the space of possible outcomes. Therefore the\nsum over all possible outcomes of the outcome distribution must be equal to one.\nIn the case of discrete outcome spaces, one usually does not make any\nassumptions about relationships between the outcome probabilities for different\noutcomes (except that they must sum to one). However, in the case of numerical\noutcomes, one may introduce additional assumptions. For instance, in Figure 1, a\nGaussian outcome distribution is assumed, and the parameters of the Gaussian\ndistribution are determined from a histogram of the outcomes observed during\nmultiple experiments.\nProbability\nAverage Good VeryGood Excellent\nFigure 1\n150 Formal Aspects ofSecurity and Trust\n3.2 Building trust from experience\nWe now deflne trust and propose  a model to build trust from prior experiences.\n3.2.1 Definitionoftrust\nDefinition of trust: The trust of an entity a in the outcome of an action of entity\nß is an estimation of the outcome distribution Dß  for the execution of the action\nby entity ß.\nThe basic mechanism for building trust is by experience, that is, by observing the\nexecution of the action of interest by the entity ß a certain number  of times. Let\nus assume that the space  of possible outcomes O is finite and that N observations\nhave been made, where the outcome of the i-th observation was  O\\. If we rnake no\nassumptions about relationships between outcome probabilities  for  different\noutcomes, then the best estimation  of  Dß, the trust of the observing entity  a, is\ngiven by the formula\nTa(ß) (o) = (number of times that the outcome o, was equal  to ö) IN (for all o\neO)\nIn the  case that  the  space  of  possible outcomes includes  a  dimension with  a\nnumerical coordinate, the set of possible outcomes becomes infmite.  In this case,\nthe above simple average value calculation  is not possible. Instead, the numerical\ncoordinate is usually partitioned into  a discrete number of intervals, as shown in\nFigure 1. Each interval is then treated like a discrete value and the above formula\ncan be applied. If  the model  of  the trusted entity includes  an assumption about\nthe fimctional form of the outcome distribution function  D ß then the trust should\nbe of the same form,  and the  parameters of  this function should  be adjusted to\nbest flt the experimental data.\nInstead of keeping in memory all previous experimental outcomes,  one may use\nan incremental trust update formula.  The  following incremental formula  is\nequivalent to the  comprehensive formula above.  For  calculating  the  trust\nincrementally, we keep in memory the current trust T a(ß)(o) for each o e O and\nthe number of observations to date. When a new experience yielding outcome  o\nis observed, the values of Ta(ß) and TVwill be updated as follows:\nTa (ß) (o) =(Ta (ß)  (o) *7V+ 1)/(N+ 1)\nTa (ß) (o') = T a (ß) (o') *N/(N+ 1) for o'  different from o\nN = N+ 1\nNote that the incremental formula and the comprehensive formula are applicable\nto both situational trust  and  general trust.  In the  case  of the  independent\nK\nmultidimensional outcome space, T a(ß)(o) =  P(o) = J^ P(o^) where P(o) is\nk=\\\nA Trust Model with Statistical Foundation 151\nthe probability of outcome o, o=  (OI,O 2,..-,OK) and o k is the outcome in k-th\ndimension. Here the marginal distribution of o k can be used instead of the joint\ndistribution of o because the dimensions are independent.\nConsider the example of restaurant service ß whose three-dimensional outcomes\nare independent. Entity a has situational trust in restaurant ß based on nine\nexperiences (N=9) as follows\nTable 1\nDistribution T(o)\nexcellent\ngood\nbad\nvery bad\nQualityoffood7/foJ\n6/9\n2/9\n1/9\n0\nService T2(o)\n2/9\n4/9\n2/9\n1/9\nEnvironment T3(o)\n4/9\n3/9\n1/9\n1/9\nAfter entity a obtains one outcome such as o= (\"Quality offood\"= \"excellent\",\n\"service\"=\"good\", \"environment\"=\"bad\"), entity a updates situational trust\naccording to the incremental trust update formula and obtains the following trust\n(N=10)\nTable 2\nDistribution T(o)\nexcellent\ngood\nbad\nvery bad\nQualityoffoodryfoj\n7/10\n2/10\n1/10\n0\nService T2(o)\n2/10\n5/10\n2/10\n1/10\nEnvironment T3(o)\n4/10\n3/10\n2/10\n1/10\n3.2.2 Estimating the error of the trust value\nGenerally the trusting entity estimates the true trust value with some uncertainty,\nboth because of inherent product or service variability and because of imperfect\ninformation. Thus, it is necessary to have a method of determining the standard\nerror of experimental outcomes. The main objective is to obtain both a desirable\naccuracy and a desirable confidence level with minimum cost - number of\nexperiences.\nFor an outcome with a score of 0 or 1 for no or yes (Bernoulli Distribution), the\nstandard error (SE) of the estimated proportion p, based on random sample\nobservations, is given by: SE = [p(l-p)/N] 12 where/7 is the proportion obtaining\na score of 1, and  A^ is the sample size [16]. This SE is the standard deviation of\nthe range of possible estimate values. The SE is at its maximum when p = 0.5,\ntherefore the worst case scenario occurs when 50% are yes, and 50% are no.\nUnder this extreme condition, the sample size, N, can then be expressed as the\nlargest integer less than or equal to\n 0.25/SE2. To have some notion of the sample\n152 Formal Aspects ofSecurity and Trust\nsize, note that for SE to be 0.04 (i.e. 4%), a sample size of 156 will be needed;\n5%, 100; 10%, 25.\n3.2.3 Considering trusted entities with evolving performance\nIf it can be assumed that the performance of the trusted entity is not constant, but\nevolving over time, then the basic assumption about a given outcome distribution\nfor the actions of the entity, valid over all times, is not true any more. In this\ncase, we must take into account that the outcome distribution of the trusted entity\nevolves over time. If the trusting entity knows the speed of this evolution,\npossibly defined by a given characteristic time delay, then the trusting entity may\ninclude in the trust calculation only recent experiments not older than the\ncharacteristic time delay.\nIt is also possible to give different weights to the different experiments, either\naccording to their age or their order. The following incremental trust update\nformula based on the order of the experiments may be used:\nTa(ß)(o) =  (Ta(ß)(o) +y)/(l+y)\nTa (ß) (o') = T a (ß) (o')  /(1+y) for  o' different from o\nwhere the value of  y determines the weight of the last experience compared with\nthe previous trust estimation.\n3.2.4 Initial trust values\nIn two cases, entity a needs to set his/her initial trust values in entity ß. (i) When\nentities a and ß have no previous relationship (in any situation) and entity a has\nno knowledge about entity ß, then entity a needs to initialize his/her general trust\nand situational trust in entity ß. (ii) When entities a and ß have no previous\nrelationship in a new situation but entity a has general trust in entity ß, then\nentity a needs to initialize his/her new situational trust in entity ß. To address\nthese problems, a mapping between different spaces is needed. Mapping to initial\ntrust for a particular entity or situation depends on the space of possible outcomes\nof that situation.\n3.2.5 Mapping between spaces\nIn many cases, entity a needs to map between different spaces. (i) In the case of\nsetting initial trust values, entity a needs to map his/her basic trust space to\nhis/her general trust space, as well as his/her general trust space to his/her\nsituational trust space. (ii) In the case of general trust update, entity a needs to\nmap his/her situational trust space to his/her general trust space. (iii) There may\nA Trust Model with Statistical Foundation 153\nalso be cases in which entity a will update his/her basic trust as a result of  a large\nnumber of general or situational trust experiences. We focus in the following\ntwo mappings:\n1. Generalization mapping: from situational trust space to general trust space for\nthe purpose of general trust update. We write G(o) for the outcome of general\ntrust when the situational trust outcome is o. Using G(o) one can update his/her\ngeneral trust T a(ß)(G(o)). Note that this kind of generalization mapping causes\ninformation loss since the general trust would be more \"general\" (abstract) in\nnature and the mapping is usually a many-to-one mapping, which implies that the\nnumber of discrete outcomes of general trust space must be no more than that of\nthe situational trust space.\n2. Specialization mapping: from basic trust space to general trust space and from\ngeneral trust space to situational trust space for the purpose of setting initial trust\nvalues. We write S(o) for the outcome of situational trust when the general trust\noutcome is o. We also write S(o) for the outcome of general trust when the basic\ntrust outcome is o. Using S(o) one can set initial situational trust T a(ß,ö)(S(o)) and\ninitial general trust T a(ß)(S(o)). Note that the specialization mapping is the\nreverse process of the generalization mapping. It usually is a one-to-many\nmapping. An example of a mapping from the general trust to the situational trust\nis illustrated in the following flgure.\n! I\n1\n1\n1\n1\n1\nlllll\n1\n1\n11 I\n1 i\n1\n1\n|\ni ! 1\nIII|| !\n1 1  ! —•\nFigure 2\nIn this example, the entity a will map his/her general trust to situational trust by\ndefining the mapping S(o):\n- outcome \"Good\" in general trust maps to outcomes \"average\" or higher in\nsituational trust\n- outcome \"Bad\" in general trust maps to outcomes \"Bad\" or lower in situational\ntrust\nNote that the areas must be the same; that is,  Ta(ß)(o) = Ta(ß,ö)(S(o)). Thus\n154 Formal Aspects ofSecurity and Trust\nTa(ß)(\"Good\") = T a(ß,ö)(\"Excellent\")+ T a(ßfö)(\"Very Good\")+\nTa(ß,ö)(\"Good\") + T a(ß,ö)(\"Average\") = 80%, and\nTa(ß)(\"Bad\") = T a(ß,ö)(\"Bad\")+ T a(ß,ö)((iVery Bad\") = 20%.\nThis histogram is then the initial set of values for situational trust outcomes (i.e.,\nN ~ N inu) that will be updated over time as entity a has further interactions with\nservice ß.\n4. DECISION MAKING\nDecision making is often a question of selecting the optimal choice among a\nnumber of alternatives. It is therefore important to understand how different\nalternatives are evaluated in order to determine which is optimal. This means that\nfor each alternative, a utility must be defined so that the alternative with the\nhighest utility can be chosen. These kinds of approaches have been used in\ndifferent areas.\nIn this section, we apply our trust model to several utility models to show how\nour trust model can be used for rational decision making. For most economic\nscenarios, the highest expected current utility model [13] is appropriate. For\nsome critical scenarios, the lowest expected failure rate model [17] is\nappropriate. For some service scenarios, the total satisfaction model [14] is\nappropriate.\nExpected Utility Theory (EUT) [12] states that the decision maker (DM) chooses\nbetween risky or uncertain prospects by comparing their expected utility values,\ni.e., the weighted sums obtained by adding the utility values of outcomes\nmultiplied by their respective probabilities. The most popular expected utility\nfimction is the linear compensatory model in which preference for a product or\nservice is represented by Xj = ^^w\nkyJk where x, is the preference for a product\nk=\\\nor servicey, y jk is the amount of attribute k in product or servicey, and w k is the\nimportance weight assigned to attribute k [13]. In quality of service negotiation\n[14], a user satisfaction function plays a similar role.\nBased on our trust model, we propose the following: if entity a wants to use\nhis/her trust for decision making, the entity should first establish the utility of the\naction of a trusted entity ß for each possible outcome. We write U a(o) for the\nutility when the outcome is o. Then it is clear that the expected utility obtained\nfrom the execution of  an action by entity ß for which the trust is T a (ß,ö) can be\ncalculated by the formula\nA Trust Model with Statistical Foundation 155\noeO\nIn the case of multi-dimensional outcome spaces, the different dimensions may\nhave their own utility mapping fimctions, and the overall utility may be the sum\nof the single-dimension utilities, adjusted with weight factors for the different\ndimensions. We then get an analogous formula to the one given in [13]. If all\ndimensional outcomes are independent, then the above expected utility formula\nK\ncan be generalized to U a{ß) = ^U^iföxw™ where  U (\na\nk\\ß)is the\nk=\\\nexpected k-th dimensional utility, w^ is the subjective weight ofk-th dimension\n(we assume that the sum of all weights is equal to 1).\nWe note that the latter formula corresponds to the formula for the expected utility\nquoted from [13] above. u^\\ß) in our formula corresponds to the value  jy* in the\nformula above.\nWe give three examples of making decisions and choosing the utility mapping\nfunction Ua(o).\n1. Consider the example of restaurant service ß. Entity a assumes that all three\nevaluation criteria are independent. Let us assume that entity a adopts the\nfollowing mapping fimctions and dimensional weights with the following values:\n*1* = 0.6;  W< 2) = 0.3; FF^ = 0.1.\nTable 3\nUtility Mapping U(o)\nexcellent\ngood\nbad\nvery bad\nQualityoffoodt/ yVoj\n5.6\n2.7\n0\n-4\nService l/ 2)(o)\n3\n1\n-0.5\n-2\nEnvironment l/ 3)(o)\n2\n1\n0\n-1\nThe weighted \"quality of food\" dimension utility can be calculated using the trust\nvalues from the table in Section 3.2.1 as follows\nUl = sum over all o in dimension \"quality of food\" of ( jJ J)(o) * Tl(o) *\n) = ( 5.6 * (7/10) + 2.7 * (2/10) + 0.0 * (1/10) + (-4) * 0 ) * 0.6 = 2.676\nSimilarly, the weighted \"service\" dimension utility U2 has the value 0.24, and\nthe weighted \"environment\" dimension utility U3 has the value 0.1. Therefore\nthe utility for entity a of this restaurant service ß is U a(ß) = Ul + U2 + U3 =\n2.676 + 0.24 + 0.1=3.016\nFollowing the same process, entity a can calculate the utility of other restaurant\nservices. Entity a would choose the restaurant service with the highest utility\nvalue.\n156 Formal Aspects of Security and Trust\n2. Consider the example of multimedia presentations. Based on the multi-\ndimensional outcome space discussed at the end of Section  3.1.1,  we could use\nthe above formula to calculate the overall utility. However, Richards et al. [14]\npropose another formula. They call satisfaction s k what we call utility lf k\\ and\nthey assume that the values of satisfaction range between zero (unacceptable\nquality) and one (ideal quality). Instead of the weighted summation formula\nabove, they propose to calculate the overall satisfaction  byS total = K/^—. The\nk=\\ S k\nreason for proposing this formula is the following argument: If the satisfaction\nfor one dimension is zero, then the total satisfaction should be zero (which is not\nsatisfied by our formula). Both formulae satisfy the following property: If the\nsatisfaction for all dimensions has the same value, then the overall satisfaction\nhas that same value. Richards' formula can be extended to include weights.\n3. Consider the previous example of restaurant service ß. Entity a, this time, uses\na failure probability model similar to failure rate as proposed in [17] for decision\nmaking. Entity a first maps the outcome space to a consideration space which\nconsists of 2 outcomes, namely \"success\" and \"failure\"; for instance, we may\nassume that we have \"failure\" when the value of U a(o) is less than zero. The\nservice failure probability is the proportion of outcome \"failure\" and can be\nrepresented byi^ = ^T a(ß,ö)(o). The service with the lowest failure\nUa (o)=\"  faili4re\"\nprobability can be chosen. Note that one can consider this model as a special case\nof expected utility model in which the utility mapping has only two values,\n\"success\" and \"failure\".\n5. ISSUES RELATED TO RECOMMENDATIONS\nEntity a can build up his/her situational and general trust from past experiences,\nas has been discussed in the previous sections. Due to the limitation of resources,\nentity a may need to rely on recommendations from other entities in order to\nobtain trust with sufficient confidence. Entity a could get many independent\nrecommendations from different entities. Some of these recommendations will\nprobably conflict with each other. To address the conflict, a recommendation\nevaluation and combination algorithm is necessary. A recommendation need not\nnecessarily represent the real belief of the recommending entity. In fact,\nrecommenders may lie or give out contradictory recommendations to different\nentities.\nA Trust Model with Statistical Foundation 157\nFollowing Yu and Singh [11], we define local trust and global trust (reputation).\nAn entity's local trust with respect to another entity is from his/her direct\nexperiences. The local trust consists of situational trust which can be propagated\nto others upon request. An entity's global trust (reputation) with respect to\nanother entity combines the local trust (if any) with recommendations received\nfrom other entities.\nHow to find recommenders is another issue. Yu and Singh [11] proposed an\nalgorithm to find acyclic paths between a querying entity and recommenders. The\nnumber of possible paths is related to the connections between entities. If the\nentities are densely connected, the number of paths is quite large. If the entities\nare sparsely connected, the number of paths could be quite small or even zero.\n6. CONCLUSIONS AND FUTURE WORK\nWe have addressed the problem of building a general trust model for online\nentities based on their direct experiences and the recommendations of other\nentities. Considering trust a complex and multi-faceted thing, we use the\nestimated distribution in a multidimensional outcome space to represent trust.\nThe statistical characterizations of trust (incremental trust update, estimated\nerror, outcome space mapping) are discussed. Our trust model can be used by\ndifferent decision models (utility, failure probability, satisfaction) for rational\ndecision making in different scenarios.\nFor füture research, we plan to investigate how the recommendations from\ndifferent entities can be combined, how malicious recommendations can be\ndetected, and how recommenders can be found. We intend to test the behavior of\nour trust model using simulations.\n7. REFERENCES\n[1] Stephen Paul Marsh. Formalising Trust as a Computational Concept. Ph.D. Thesis, University\nofStirling, April 1994\n[2] Catholijn M. Jonker, Jan Treur. Formal Analysis ofModelsfor the Dynamics ofTrust based on\nExperiences. 2 nd Workshop on Deception, Fraud and Trust In Agent Societies, pp.  221-231,  1999\n[3] Greg Elofson. Developing Trust with Intelligent Agents: An Exploratory Study. In Proceedings\nof the l st International Workshop on Trust, pp. 125 - 139, 1998\n[4] Miquel Montaner, Beatriz Löpez, Josep Lluis de la Rosa. Opinion-Based Filtering Through\nTrust. In proceedings of the 6th International Workshop on Cooperative Information Agents VI, pp.\n164-178,2002\n[5] Alfarez Abdul-Rahman, Stephen Hailes. Supporting Trust in Virtual Communities. In\nProceedings of the  33 rd Hawaii International Conferences on System Sciences - Volume 6, 2000\n158 Formal Aspects of Security and Trust\n[6] Bin Yu, Munindar P. Singh. An Evidential Model of Distributed Reputation Management. In\nProceedings of the first international joint conference on Autonomous agents and multiagent\nsystems, pp. 294 -  301,  July 2002\n[7] Thomas Tran, Robin Cohen. Learning Algorithms for Software Agents in Uncertain and\nUntrusted Market Environments. In Proceedings of the Eighteenth International Joint Conference\non Artificial Intelligence (IJCAI-03), pp. 1475 - 1476, August 2003\n[8] Mao Chen, Jaswinder Pal Singh. Computing and Using Reputations for Internet Ratings.\nEC'01,  pp. 154 - 162, October 2001\n[9] Y.H. Tan and W. Thoen. Towards a Genehc Model of Trust for Electronic Commerce. In\nProceedings of the  12111 International Bled Electronic Commerce Conference, Vol. 1, pp. 346 - 359,\nBled Slovenia, 1999\n[10] Chrysanthos Dellarocas. Immunzizing Online Reputation Reporting Systems Against Unfair\nRatings and Discriminatory Behavior. EC'00, pp. 150 - 157, October 2000\n[11] Bin Yu, Munindar P. Singh. Detecting Deception in Reputation management. AAMAS'03, pp.\n73-80,  July2003\n[12] Philippe Mongin. Expected Utility Theory.\nhttp://expected-utility-theory.behaviouralfinance.net/Mong.pdf\n[13] John H. Roberts, Glen L. Urban. New Consumer Durable Brand Choice: Modeling\nMultiattribute Utility,  Risk, and Dynamics. Management Science Volume 34, Issue 2, 1988\n[14] Antony Richards, Glynn Rogers, Mark Antoniades, Varuni Vitana. Mapping User Level QoS\nfrom a Single Parameter. In proceedings of the 2 nd IFIP/IEEE International Conference on\nManagement of Multimedia Networks and Services'98, Nov. 1998\n[15] Abdelhakim Hafid, Gregor v. Bochmann. An Approach to Quality ofService Management in\nDistributed Multimedia Application: Design and an Implementation. Multimedia Tools Appl. 9(2),\n1999, pp. 167-191\n[16] Hossein Arsham. Statistical Thinkingfor Managerial Decision Making.\nhttp://home.ubalt.edu/ntsbarsh/Business-stat/opre504.htm#rssss\n[17] NIST/SEMATECH. Engineering Statistics Handbook\nhttp://www.itl.nist.gov/div898/handbook/apr/section  1/aprl 81 .htm",
  "topic": "Trustworthiness",
  "concepts": [
    {
      "name": "Trustworthiness",
      "score": 0.7877800464630127
    },
    {
      "name": "Computer science",
      "score": 0.7359916567802429
    },
    {
      "name": "Foundation (evidence)",
      "score": 0.6061927080154419
    },
    {
      "name": "The Internet",
      "score": 0.5044821500778198
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.49897170066833496
    },
    {
      "name": "Data science",
      "score": 0.3213936686515808
    },
    {
      "name": "Internet privacy",
      "score": 0.29694804549217224
    },
    {
      "name": "World Wide Web",
      "score": 0.20274686813354492
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I153718931",
      "name": "University of Ottawa",
      "country": "CA"
    }
  ]
}