{
    "title": "<scp>ChatGPT</scp> and a new academic reality: <scp>Artificial Intelligence‐written</scp> research papers and the ethics of the large language models in scholarly publishing",
    "url": "https://openalex.org/W4323848232",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A3006477922",
            "name": "Lund Brady",
            "affiliations": [
                "University of North Texas"
            ]
        },
        {
            "id": "https://openalex.org/A1971344964",
            "name": "Wang Ting",
            "affiliations": [
                "Emporia State University"
            ]
        },
        {
            "id": null,
            "name": "Mannuru, Nishith Reddy",
            "affiliations": [
                "University of North Texas"
            ]
        },
        {
            "id": "https://openalex.org/A2361878486",
            "name": "Nie Bing",
            "affiliations": [
                "Zhejiang Tongji Vocational College of Science and Technology"
            ]
        },
        {
            "id": null,
            "name": "Shimray, Somipam",
            "affiliations": [
                "Babasaheb Bhimrao Ambedkar University"
            ]
        },
        {
            "id": "https://openalex.org/A3161315462",
            "name": "Wang Ziang",
            "affiliations": [
                "Baker University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4214927078",
        "https://openalex.org/W3028999579",
        "https://openalex.org/W3103891289",
        "https://openalex.org/W4238112704",
        "https://openalex.org/W4321116084",
        "https://openalex.org/W3124461674",
        "https://openalex.org/W4212885981",
        "https://openalex.org/W2972668795",
        "https://openalex.org/W2013364555",
        "https://openalex.org/W2035104656",
        "https://openalex.org/W3133702157",
        "https://openalex.org/W2766505384",
        "https://openalex.org/W4394666657",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W2988647680",
        "https://openalex.org/W3144293453",
        "https://openalex.org/W4221001772",
        "https://openalex.org/W2584278128",
        "https://openalex.org/W3112103703",
        "https://openalex.org/W3125358881",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W3085332162",
        "https://openalex.org/W2138857742",
        "https://openalex.org/W2727964008",
        "https://openalex.org/W3095319910",
        "https://openalex.org/W2785615365",
        "https://openalex.org/W2726628440",
        "https://openalex.org/W3157428307",
        "https://openalex.org/W4318678040",
        "https://openalex.org/W3134095442",
        "https://openalex.org/W4312114420",
        "https://openalex.org/W4293180267",
        "https://openalex.org/W2963849010",
        "https://openalex.org/W3003802619",
        "https://openalex.org/W4311430511",
        "https://openalex.org/W2939675123",
        "https://openalex.org/W2620857596",
        "https://openalex.org/W3203833719",
        "https://openalex.org/W3035296331",
        "https://openalex.org/W3135012552",
        "https://openalex.org/W2090017022",
        "https://openalex.org/W4312106697",
        "https://openalex.org/W4320167623",
        "https://openalex.org/W2953522645",
        "https://openalex.org/W1901616594",
        "https://openalex.org/W4291178460",
        "https://openalex.org/W2902367810",
        "https://openalex.org/W4312212221",
        "https://openalex.org/W4313479734",
        "https://openalex.org/W4313422136",
        "https://openalex.org/W3122241445",
        "https://openalex.org/W4297795751",
        "https://openalex.org/W4224979739",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2912185124",
        "https://openalex.org/W3168771811",
        "https://openalex.org/W3147065828",
        "https://openalex.org/W4400134761",
        "https://openalex.org/W2582336686",
        "https://openalex.org/W4225314275",
        "https://openalex.org/W4292887282",
        "https://openalex.org/W2011889799",
        "https://openalex.org/W2916559661",
        "https://openalex.org/W2794944797",
        "https://openalex.org/W3020595455",
        "https://openalex.org/W4242308908",
        "https://openalex.org/W2124836818",
        "https://openalex.org/W2100464830",
        "https://openalex.org/W4298277077",
        "https://openalex.org/W3125255202",
        "https://openalex.org/W4319332853",
        "https://openalex.org/W2963809228",
        "https://openalex.org/W4318263917",
        "https://openalex.org/W2749119382",
        "https://openalex.org/W3116890626",
        "https://openalex.org/W4210786107",
        "https://openalex.org/W4318224940",
        "https://openalex.org/W2950813464",
        "https://openalex.org/W3120664440",
        "https://openalex.org/W2926555354",
        "https://openalex.org/W3154710343",
        "https://openalex.org/W2023754051",
        "https://openalex.org/W4320495408",
        "https://openalex.org/W4288029087",
        "https://openalex.org/W4288283129",
        "https://openalex.org/W3022125597",
        "https://openalex.org/W4287868032",
        "https://openalex.org/W1663984431",
        "https://openalex.org/W2970597249",
        "https://openalex.org/W4312090747",
        "https://openalex.org/W363882687",
        "https://openalex.org/W2943978521",
        "https://openalex.org/W2169818249",
        "https://openalex.org/W2913954081",
        "https://openalex.org/W4308900200",
        "https://openalex.org/W2897311201",
        "https://openalex.org/W3098123823",
        "https://openalex.org/W569872894",
        "https://openalex.org/W4292779060"
    ],
    "abstract": "Abstract This article discusses OpenAI's ChatGPT, a generative pre‐trained transformer, which uses natural language processing to fulfill text‐based user requests (i.e., a “chatbot”). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT‐3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.",
    "full_text": " \nChatGPT and a New Academic Reality: AI-Written Research Papers and the Ethics of the \nLarge Language Models in Scholarly Publishing \nBrady D. Lund1*, Ting Wang2, Nishith Reddy Mannuru1, Bing Nie3, Somipam Shimray4, Ziang \nWang5 \n \n1University of North Texas, Department of Information Science, Denton, TX, USA \n2Emporia State University, School of Library and Information Management, Emporia, KS, USA \n3Zhejiang Tongji Vocational College of Science and Technology, Hangzhou, China \n4Babasaheb Bhimrao Ambedkar University, Department of Library and Information Science, \nLucknow, India \n5Baker University, School of Education, Baldwin City, KS, USA \n*Corresponding Author, brady.lund@unt.edu  \n \nPublished in the Journal of the Association for Information Science and Technology  \nAbstract \nThis paper discusses OpenAI’s ChatGPT, a generative pre-trained transformer, which uses \nnatural language processing to fulfill text-based user requests (i.e., a “chatbot”). The history and \nprinciples behind ChatGPT and similar models are discussed. This technology is then discussed \nin relation to its potential impact on academia and scholarly research and publishing. ChatGPT is \nseen as a potential model for the automated preparation of essays and other types of scholarly \nmanuscripts. Potential ethical issues that could arise with the emergence of large language \nmodels like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and \nresearchers, are discussed and situated within the context of broader advancements in artificial \nintelligence, machine learning, and natural language processing for research and scholarly \npublishing.  \nKeywords: GPT-3, ChatGPT, Generative Pre-Trained Transformer, Natural Language \nProcessing, Scholarly Publishing, Publishing Ethics  \nChatGPT and related technologies have been identified as disruptive innovations with the \npotential to revolutionize academia and scholarly publishing (Haque et al., 2022). As a natural \nlanguage processing tool developed by OpenAI, ChatGPT can automate the preparation of \nessays and other scholarly manuscripts. However, the ethical implications of this technology and \nits underlying GPT-3 technology have not yet been fully considered (Gonzalez-Padilla, 2022). \nThis paper addresses the significant ethical issues that could arise with the use of GPT-3 and \nplaces these concerns in the context of broader advancements in artificial intelligence, machine \nlearning, and natural language processing for research and scholarly publishing. \nOur analysis reveals that the potential for bias in the training data and coding process of AI-\ndriven language models such as GPT-3 poses a threat to the integrity of science. Additionally, \nethical considerations include issues of copyright, citation practices, and the potential impact on \nthe \"Matthew Effect\" in scholarly publishing. Ownership of the content generated by the model \nand the use of third-party content within the generated manuscripts are also major ethical \nconcerns. While ChatGPT can assist editors and peer reviewers in completing repetitive or \ntedious tasks, there is a risk that it may not mitigate existing biases and that human judgment \ncalls are still necessary. Furthermore, the use of AI-driven language models raises concerns \nabout the reproducibility and transparency of research. \nIt is crucial to carefully consider all of these ethical considerations to ensure that these \ntechnologies are used responsibly and ethically in the context of academic research and \npublishing. Researchers, publishers, and the developers of AI-driven language models must \ncollaborate to establish guidelines and protocols to ensure that the use of these technologies is \nethical, transparent, and accountable. Failure to do so may undermine public trust in the \nscientific process and have far-reaching consequences for the future of research and innovation. \nA Brief Introduction to Underlying AI Concepts \nArtificial intelligence, machine learning, and natural language processing are rapidly advancing \nfields that are having a significant impact on a wide range of industries and applications (Wamba \net al., 2021). Chatbots, which are computer programs designed to mimic human conversation, are \none example of the practical uses of these technologies (Adamopoulou & Moussiades, 2020a). \nThe following paragraphs provide a brief overview of artificial intelligence, machine learning, \nand natural language processing –as well as the ways in which chatbots are utilizing these \ntechnologies to interact with users in a more human-like manner – in order to ensure that all \nreaders have a basically familiarity with the technology and concepts that underpin large \nlanguage models like the Generative Pretrained Transformer and ChatGPT.   \nArtificial intelligence (AI) is a multidisciplinary and interdisciplinary field that has grown \ntremendously since the introduction of manually operated computers in the 1950s (Haenlein & \nKaplan, 2019). It has the potential to revolutionize various industries, and is defined as any \ntheory, method, or approach that assists machines, particularly computers, in analyzing, \nsimulating, exploiting, and exploring human thought processes and behaviors (Lu, 2019). AI \ninvolves the simulation of intelligent behavior in machines, with the goal of creating machines \nthat can mimic human intellect in important ways such as language comprehension, reasoning, \nand problem-solving (Chowdhary, 2020). Self-learning is a key component of AI, allowing \nsystems to acquire new information and improve their knowledge-based judgments and \nconclusions through experience and data (Mintz & Brodie, 2019). Machine learning and deep \nlearning techniques have become the standard approach to advancing AI, with artificial neural \nnetworks (ANNs) allowing robots to learn and reason like humans and perform increasingly \ncomplex tasks (Lu, 2019). AI has already had a significant impact on various industries such as \npharmaceutical, industrial, financial, medical, and managerial, and is expected to play a crucial \nrole in helping businesses of all sizes stay competitive in the global economy (Makridakis, \n2017). AI encompasses a range of specialized domains including machine learning (ML) and \nnatural language processing (NLP). \nThe volume of data being generated from various sources, including people, devices, and \ncomputers, continues to grow at an exponential rate (Beath et al., 2012). As the amount of data \nbecomes too large for individuals to make sense of and draw meaningful insights from, it \nbecomes necessary to automate systems that can learn from the data to provide valuable insights. \nThis is where machine learning (ML) comes in. ML is a key component of artificial intelligence \n(AI) and involves the development of computational theories for learning processes that allow \nmachines to learn from experience without being explicitly programmed to do so (Chowdhary, \n2020; Mahesh, 2020). It is at the intersection of computer science and statistics and is used to \ncreate programs that can automatically learn from data, acquire knowledge from experience, and \ncontinuously improve their learning behavior to make predictions based on new data (Jordan & \nMitchell, 2015). ML is a useful technique in various areas of AI, including computer vision, \nvoice recognition, and natural language processing (NLP). In this paper, we focus on ChatGPT, \nan AI technology that uses NLP to enable computers to engage in natural language conversations \n(Radford et al., 2018). ML is an essential part of ChatGPT, as it allows the system to learn from \ndata and improve its language processing abilities over time, leading to more effective \ncommunication and interaction between humans and computers. \nArtificial intelligence (AI) has become a part of everyday life with the advancement of \nprocessing power and the use of intelligent agents (Adamopoulou & Moussiades, 2020b). \nIntelligent agents are programs that can act independently and make decisions based on their \nobservations of the environment, human input, and internal knowledge. Chatbots, also known as \nconversational artificial intelligence bots, are a type of intelligent agent that can respond to \nconversations through text or voice as if they were sentient beings, and they have gained \npopularity due to their usefulness in various applications such as customer service, healthcare, \neducation, and personal support (Brandtzaeg & Følstad, 2017; Nagarhalli et al., 2020). Chatbots \nhave been developed using natural language processing (NLP) techniques, which allow them to \nunderstand and interpret human language input (Khanna et al., 2015). In recent years, chatbots \nhave become more popular, particularly among younger generations who prefer instant, one-on-\none communication through short messages (Lokman & Ameedeen, 2018). This paper focuses \non ChatGPT, a chatbot that uses NLP and AI to generate natural language conversations, and \nspecifically on how it can be used in academia to create and write research and scholarly articles, \nand the ethical issues associated with this development. \nIntroducing ChatGPT \nOpenAI is a research laboratory that has made significant contributions to the field of artificial \nintelligence, including the development of the highly advanced language model, GPT-3. In \naddition to GPT-3, OpenAI has also released ChatGPT, a chatbot that uses natural language \nprocessing to generate responses to user inputs. Both GPT-3 and ChatGPT have garnered \nsignificant attention and have the potential to revolutionize a wide range of language-related \ntasks. In this section, we will delve into the details of OpenAI, GPT-3, and ChatGPT, exploring \ntheir capabilities, limitations, and potential applications. \nOpenAI and Early Developments \nEstablished in 2015, OpenAI is a research laboratory focused on the development of AI products \nfor the common good (OpenAI, 2022). The laboratory has received significant support from \nindividuals such as founding donor Elon Musk and the Microsoft Corporation, which invested \none billion U.S. dollars in exchange for exclusive access to some of OpenAI's products \n(Brockman et al., 2016). As a result, the laboratory has made rapid progress in the development \nof its AI technologies. OpenAI has released a number of machine learning products for the \ngeneral public, with DALL-E and ChatGPT being among the most well-known (Devlin et al., \n2018). \nDALL-E is a machine learning technology that generates images based on user inputs and was \nmade widely available to the public, preceding ChatGPT in its availability (Marcus et al., 2022). \nIt uses Artificial Neural Networks with multimodal neurons to understand and create novel \nimages. These neurons are so tolerant of different expressions of a concept that they open up a \nworld of variation (Goh et al., 2021). This innovation, introduced by OpenAI, represents how the \nlab seeks to change the game with smart AI. Availability to the public, key to the popularity of \nDALL-E, is also responsible for the rapid popularity of ChatGPT, which gained over one million \nunique users in less than one week after its launch (Mollman, 2022). \n \nChatGPT \nGenerative Pre-Trained Transformer, or GPT, is a language model that understands human \ninputs (as described with DALL-E above) and then produces response text that is nearly \nindistinguishable from natural human language (Dale, 2021). The concepts behind GPT are not \ntoo complex, by NLP/ML standards, thought they are refined by OpenAI (Radford et al., 2018). \nThe creation and fine-tuning of the algorithm occurs in a couple of steps: \n• Generative, unsupervised, pretraining, where the data used for training is unlabeled and \nlearning occurs naturally (like when you walk into an entirely new situation with no \nbackground knowledge and fill in pieces as you explore) as opposed to supervised and \nguided training (where each aspect of the learning process is curated like a teacher in a \nclassroom) (Erhan et al., 2010).  \n• Discriminative, supervised, fine-tuning, where, following the pretraining, the algorithm is \nrefined by its creators to perform better on necessary tasks (Budzianowski & Vulić, \n2019).  \nFigure 1 illustrates at a technical level how ChatGPT works, based on an initial GPT model, as \nwell as the concepts of supervised fine-tuned modeling, rewards modeling, and proximal policy \noptimization modeling (PPO). As demonstrated here, development of a useful ChatGPT interface \nis an iterative process.  \nFigure 1. Diagram of the GPT Implementation Process\n \nGPT stands out as a large language model due to its exceptional scale and the sheer amount of \ndata used to train it. The algorithm underlying GPT has access to the entire Internet, which \nmeans that it is built upon billions of data sources, making it one of the largest language models \nin the world (Floridi & Chiriatti, 2020). GPT is a versatile tool that has been designed to perform \nvarious language-based tasks such as text generation, question answering, and translation. It uses \ndeep learning techniques and sophisticated algorithms that enable it to understand the context of \na piece of text and generate human-like responses, making it unique among language processing \ntools. \nChatGPT is a public tool developed by OpenAI that is based on the GPT technology (Kirmani, \n2022). Essentially, it is a highly sophisticated chatbot that can fulfill almost any text-based \nrequest (Liu et al., 2021). However, ChatGPT is capable of much more than just answering \nsimple questions. It can also fulfill more advanced requests, leveraging its extensive data stores \nand efficient design. For example, if you are unsure of what to write in a thank you card to a \ncoworker, you can simply ask ChatGPT to write one for you, and it will quickly generate a well-\nwritten, multi-paragraph letter. ChatGPT can even help with more challenging tasks, such as \n\ncomposing a note to address a coworker's lack of productivity. It is only a small leap (and in the \n“mind” of ChatGPT, no leap at all) to ask GPT to write “an essay on the value of artificial \nintelligence.”  \nIn less than one minute, GPT can compose an essay of hundreds of words, written at professional \nresearcher quality. An article could easily be written entirely by GPT by breaking the main topic \ninto subtopics and then having GPT write each section. If the capacity of GPT is truly harnessed \n(through a full version that would allow for responses of several thousand words instead of just \nseveral hundred words), then an entire paper could be written in minutes with very minimal \nprompting from a researcher. This innovation could cut the time for composing research essays \nfrom several dozen hours to a couple dozen seconds, or even render the professional \nauthor/researcher obsolete.  \nAppendix 1 is an essay written by ChatGPT based on the simple prompt “write an essay about \nthe value of AI.” The essay is short, but is indistinguishable from a human-written response, \nperhaps even exceeding the average quality of a doctoral-level student.  \nOf course, there are a few limitations to GPT, even when ethical issues (which will be discussed \nin the rest of this paper) are set aside. Although the accuracy of natural language processing \nmodels is generally quite good, there are still errors that occur in interpreting meaning or creating \naccurate information – the models are not infallible, and GPT certainly has had its fair share of \nissues (Brown et al., 2020; Strubell et al., 2019). For instance, ambiguous terms, terms with \nmultiple meanings (such as “construct”), as well as compound terms (such as “digital \nimmigrant”) can cause issues with interpretation of meaning by the GPT model. Additionally, \nthese algorithms and data stores take a lot of energy to operate, especially at the scale that \nOpenAI is operating them (Zhou et al., 2021). OpenAI has also encountered several ethical \npitfalls during the creation of GPT and the ChatGPT platform, which raise concerns about the \norganization’s adherence to principles of responsible creation and maintenance of these \ntechnologies (Perrigo, 2023). There is also a risk that GPT could lead to biases a proliferation of \nmisinformation, as many NLP algorithms are not yet skilled at understanding misinformation \nthat may exist in its data stores and provide no resistance when asked to falsify or distort reality \n(Dale, 2017; Lucy & Bamman, 2021).  \nComparison of GPT/ChatGPT to Other Existing Language Models \nCompared to other language models like BERT, RoBERTa, and XLNet, ChatGPT and GPT-3 \nhave several advantages. One of GPT-3's key strengths is its scale, with billions of parameters \nand access to vast amounts of data, it can perform an extensive range of language-related tasks \nwith high accuracy. Additionally, GPT-3 is highly versatile and can be fine-tuned for various \ntasks such as translation, summarization, and question answering. It also uses data efficiently and \nachieves good results with relatively small amounts of training data. Furthermore, GPT-3 can \ngenerate human-like language, making it challenging to distinguish from text written by a \nhuman. While other language models may have similar objectives, none have achieved the same \nlevel of mastery as GPT-3 in these areas. Also, none that are close to achieving GPT-3's \ncapabilities are as widely available to the public (Nature Machine Intelligence Editorial Board, \n2020; Liu et al., 2019; Liu et al., 2022; Yang et al., 2019; Elkins & Chun, 2020). \n \nBenefits of ChatGPT for Scholarly Publishing \nBefore discussing some of the ethical issues and concerns that emerge with using ChatGPT in \nscholarly publishing, it is important to stress the benefits that ChatGPT and similar large \nlanguage models (BERT, XLNet) may bring to this field. As the building blocks of academic \ndatabases and the research environment, journals can contribute to the published articles' peer \nreview and review ethics. ChatGPT can assist editors in completing repetitive or tedious tasks \n(e.g., correcting grammatical errors) and avoid making biased judgments about articles (Hosseini \net al., 2022; Stokel-Walker, 2023). However, it is worth noting that if biased individuals train \nChatGPT, it is unclear whether or how ChatGPT mitigates existing issues. Editors may still need \njudgment calls to reduce bias. On the other hand, peer reviewers sometimes fail to provide \nsolutions in review reports due to a lack of motivation or capability (Horner & Lines, 2019; \nWaggoner, 2018). ChatGPT can improve the availability of review reports by providing \nsolutions based on article contents. Since the collaborative review process (the process by which \nreviews from peer reviewers, editors, and other contributors are poled to provide a \ncomprehensive set of recommendations for authors) is the primary mechanism for defining and \nhelping to form a cognitive community (Woods et al., 2023), ChatGPT’s positive role in the \nprocess may have a positive impact on the academic community, the research environment, and \nsociety as a whole (Thigpen & Funk, 2019).  \nChatGPT can support the dissemination and diffusion of new research ideas through the creation \nof better metadata, indexing, and summaries of research findings (Lund & Wang, 2023). \nAssuming there is trust and usability among the public, this may support the diffusion of research \nfindings through the translation of research into lay language that can be understood by members \nof the general public (Wang et al., 2022). ChatGPT can also be used as a sort of recommender \nsystem, helping with the identification of relevant research studies based on a user’s query. This \nwould be particularly helpful with highly interdisciplinary topics where searching across \nmultiple indices and use of many synonymous search terms related to the jargon of different \ndisciplines could be simplified by utilizing the capabilities of an interface like ChatGPT.  \nCertainly, ChatGPT can also benefit authors when used responsibly. ChatGPT should not be a \nsubstitute for one’s knowledge of a topic, but it could be used to save time and expenses by \ncomposing descriptions of findings and structuring a paper according to various journal style \nguidelines. This is different from the use of ChatGPT for plagiarism – which will be discuss in \nthe following sections – in that the platform is being used to save time and improve quality of \ncommunication, not reproduce unoriginal ideas (Gilat & Cole, 2023). An author would input \nparagraphs they have already written and then ask ChatGPT to “revise to improve clarity.” \nSimilarly, ChatGPT could be used for translation or revision of imperfect English in manuscripts \nin order to attain publication in higher quality journals (Jiao et al., 2023).  \nEthical Issues with Using ChatGPT for Scholarly Publishing \nThe development of ChatGPT and other AI-driven technology brings with it great power and \nthus great responsibility. In light of this, ethical considerations must be taken into account. \nAlthough ChatGPT's massive Internet data set offers a wide range of perspectives and voices, \nEmily Bender, a computational linguist, has noted that size does not guarantee diversity (Bender \net al., 2021). Additionally, AI-driven language models have been described as \"stochastic \nparrots,\" regurgitating what they hear, often distorted by randomness (Hutson, 2021). Therefore, \nany ethical considerations of ChatGPT must also consider its potential for distortion. From an \nethical standpoint, research papers created using ChatGPT can be seen as unoriginal and \npotentially problematic. Several studies have revealed that the training data and coding process \nof language models such as GPT-3, which are usually sourced from large web-based datasets, \ncan contain bias with regard to gender, race, ethnicity, and disability status (Basta et al., 2019; \nFounta et al., 2018; Hutchinson et al., 2020; Tan & Celis, 2019; Zhao et al., 2019). Such a bias \ncan be inadvertently perpetuated when these models are used to generate academic research, \nleading to the dissemination of hidden and unwitting prejudice. For thousands of years, human \nscience has relied on verifiable evidence and an established system of checks and balances to \nensure accuracy and fairness in the results of research. However, the increasing use of AI-\ngenerated research papers, which can be quickly produced in large numbers, poses a threat to the \nintegrity of science by introducing potential biases and errors that are difficult to identify and \ncorrect (Muller, 2021). This can lead to further inequities in research outcomes and a potential \nundermining of the foundations of scientific knowledge. \nIn this section, the ethical implications of using ChatGPT and related technologies in academia \nand scholarly research and publishing will be examined. Specifically, issues of copyright, \ncitation practices, and the potential impact on the \"Matthew Effect\" in scholarly publishing will \nbe focused on. The potential impact of ChatGPT on research productivity and the value placed \non human expertise will also be considered. It is important to carefully consider these ethical \nconsiderations in order to ensure that these technologies are used responsibly and ethically in the \ncontext of academic research and publishing. \nAuthorship, Copyright, and Plagiarism \nAuthorship attribution is a major issue concerning the generation of new knowledge by \nintelligent agents. There may be questions about the ownership of the content generated by the \nmodel (Schönberger, 2018). If a user provides input data to the model and the model generates \ncontent based on that input, it could be argued that the user owns the copyright to the generated \ncontent. However, if the model generates content independently of user input, the input provided \nis very limited (e.g., “write an essay on this topic”), or if the content is significantly edited by \nsomeone other than the user, it may be more difficult to determine ownership (Yanisky-Ravid, \n2017). In these cases, it may depend upon the agreement reached with the developer of the model \nthat generates the content; it may be necessary, at minimum, to include the model as a coauthor \nof the manuscript (Hugenholtz & Quintais, 2021). It is beneficial to contact the developer, should \nthere be any question relating to the extent of the model’s involvement in the creation of the \nknowledge.  \nIn terms of copyright, there may be concerns about the use of third-party content within the \ngenerated manuscripts (Beaza-Yates, 2022). If the language model incorporates quotes, data, or \nother materials from external sources, it is important to ensure that this use is in compliance with \ncopyright laws and that proper attribution is given (Gillotte, 2019). Depending on the nature of \nthe use, it may be necessary to obtain permission from the copyright owner or to rely on a \ndefense such as fair use. When using a tool like ChatGPT, it can be impossible to know the \nextent to which data from the training set may be quoted or otherwise used in the output \ngenerated by the tool (Dehouche, 2021). Some language models are trained with data from a \nspecific source, like Wikipedia articles. In these cases, it would be relatively easy to identify the \noriginal source. However, models like GPT-3 are trained on a massive corpus of data from \nacross the Internet, making the capacity to track the source virtually impossible.   In other words, \nit may be possible that the model itself could be responsible for infringing on copyright and the \nrisk from this infringement may be passed on to the author if they replicate it in a scholarly \npublication. \nPlagiarism concerns arise from copyright issues, and AI has been previously known in \njournalism for plagiarism. As a result, the ethics of using ChatGPT to generate scientific articles \nhave been widely discussed (Anderson et al., 2023). Plagiarism is not limited to copying text but \nalso includes paraphrasing text, methods, graphics, ideas, and any other product of intelligence \nthat belongs to another person (Gasparyan et al., 2017). However, ChatGPT-generated texts are \nbased on published literature, and citation practice is encouraged in scholarly publishing. \nTherefore, if the original authors are credited in the text, plagiarism may not be involved (Pertile \net al., 2015). Furthermore, ChatGPT's working principle allows it to access, understand, and \nsynthesize the best human thoughts in just a few seconds (Dehouche, 2021). \nSome publishers are considering removing open-access scientific research papers to prevent AI, \nsuch as ChatGPT, from accessing the articles, in an attempt to mitigate ethical concerns \n(Anderson et al., 2023). However, if publicly funded research and relevant papers are not \navailable to the public, it may lead to different ethical discussions about open access policies \n(Dehouche, 2021). Other publishers have simply made clear their policies regarding the usage \n(or suspected usage) of ChatGPT and similar large language models in scholarly publications. \nFor instance, editors from the renowned publication Science have prohibited the use of any text \ngenerated by ChatGPT or any other AI tools in papers published in the journal (Thorp, 2023).  \nCitation Practices \nCitation practices in academia are an essential aspect of scholarly work, as they serve several \npurposes. Citing sources demonstrates the writer's expertise in their field, showing that they are \nfamiliar with the existing research on a particular topic (Santini, 2018). It also showcases the \nbreadth and extent of the research that has been conducted in a particular field, as the writer is \nable to refer to multiple sources in their work (Hyland, 1999). Citing sources is also a way to \nrespect the work of others, as it gives credit to the researchers whose ideas and findings are being \nused in the writer's own work (Ha, 2022). \nProviding accurate and detailed citations is also important for maintaining the integrity of \nacademic research. When readers or editors have doubts about the validity of a claim or \nargument, they can use the provided citations to verify the sources and assess the credibility of \nthe work (Santini, 2018). This is particularly important in the context of academic progression \nand tenure, as citations are often used to evaluate, assess, and rank the work of researchers \n(Moher et al., 2018). \nChatGPT can utilize natural language processing (NLP) to scan academic papers and suggest \nappropriate citations for identified source materials (King, 2022). This tool has the potential to \nsignificantly streamline the citation process and reduce errors, as it can help researchers identify \nthe sources they should be citing and suggest the proper formatting for the citations. \nAdditionally, ChatGPT may also help researchers discover new sources of information and stay \nup to date with current advances in their fields. \nHowever, it is worth noting that ChatGPT has been found to produce academic essays with \nmissing references (see Appendix 1 as an example). While ChatGPT may be able to provide in-\ntext references in future versions, it is important to consider the potential consequences of \nrelying solely on an automated tool like ChatGPT instead of reviewing the literature in depth \n(King, 2023). The lack of references in early versions of ChatGPT could lead to disorder in \nscholarly publishing, as the integrity and credibility of the research may be called into question \nwithout proper citations. \nScholarly publishing platforms like ChatGPT have the potential to impact the \"Matthew Effect,\" \nwhich refers to the tendency for successful researchers with high citation counts to continue to be \nsuccessful and cited frequently, while lesser-known researchers struggle to gain recognition and \ncitations (Merton, 1968). This phenomenon can perpetuate existing inequalities in academia \n(Perc, 2014). Google Scholar uses a ranking system based on citations, and the Matthew Effect is \nparticularly noticeable, with highly cited articles appearing first in search results. As a result, \nmost people only look at the first few pages of search results, leading to a self-reinforcing cycle \nin which articles with the most citations continue to receive more citations (Perc, 2014). \nConsider when one enters “COVID-19” in Google Scholar (or ChatGPT), they receive mostly \noutdated articles from 2020 and 2021, written by U.S. authors, but these articles have a lot of \ncitations so are ranked highly; this, in turn, leads to these same outdated articles continuing to be \ncited as opposed to those which may be more relevant with recent developments with the \ndisease.  \n \nPlatforms like ChatGPT, which use citation counts as a factor in determining which publications \nto cite, may exacerbate this effect. Therefore, it is crucial that researchers continue to engage in \ncareful and thorough review of the literature, even when using tools like ChatGPT to assist with \nthe citation process. This will help to ensure the quality and rigor of academic work and prevent \nthe perpetuation of inequalities in the field (Lund, 2022). \nImpact on Academic Job Expectations, Tenure, and Promotion \nEvaluation of a researcher's work for the purposes of hiring, promotion, and tenure often focuses \non factors such as the number and value of funded grants, the number of published papers, and \nthe number of citations (Moher et al., 2018). Miller et al. (2011) have noted that tenure-track \nfaculty often feel pressure to publish a large number of papers in peer-reviewed journals, as those \nwho do not publish in such journals may be denied tenure. This emphasis on publication has led \nto the enduring belief that \"publish or perish\" is an important principle in academia (Caplow & \nMcGee, 1958). However, the focus on the number of publications and the prestige of the journals \nin which they are published can stifle creativity and innovation, as editors and reviewers may be \nmore likely to favor work that supports mainstream theories and methods (Augier et al., 2005; \nBedeian, 2004). Limitations on creativity and innovation in academic research can lead to a lack \nof meaning and relevance, which can hinder scientific progress (Bedeian, 1996). Additionally, \nthe emphasis on publication may lead to a disconnect between academic research and practice, as \nresearchers may prioritize their own standing among their peers rather than the promotion of best \npractices (Alutto, 2008; Miller et al., 2011). \nChatGPT is a machine learning tool that uses regression language modeling to predict future \nwords based on a preexisting knowledge of language (Olsson & Engelbrektsson, 2022). In the \ncontext of academic writing, ChatGPT generates new papers based on existing papers and \nresearchers' needs. This could potentially exacerbate the lack of innovation and disconnection \nfrom practice in academic research (Kaltenbrunner et al., 2022). While there has been \nlongstanding debate about the importance of publications and citations in academia, the advent \nof ChatGPT may be a turning point in this debate. \nThere are several steps that could be taken to address the challenges posed by ChatGPT. First, \nacademic journal publishers could work with computer science professionals to develop anti-\nChatGPT software similar to adblockers, which would be able to detect papers generated by \nChatGPT (Abd-Elaal et al., 2022). This could be achieved through the following process: \n• Upload a paper to the software. \n• The software will identify keywords in the paper. \n• Use AI to generate relevant papers by following multiple paths, using the identified \nkeywords as input. \n• Compare the similarity between the uploaded paper and the generated papers to identify \nany potential match with ChatGPT-generated content. \nSecond, academic and research institutions and academic journals could encourage more creative \nand innovative research. This could help to add vitality to the academic community and broaden \nthe range of research topics being explored. It could also reduce the likelihood that papers \nsubmitted to journals were produced by ChatGPT. \nThird, changing the criteria for evaluating tenure or reevaluating the purpose of tenure in higher \neducation and research institutions could be a fundamental solution to the ethical issues of \nscholarly publishing that arise from ChatGPT. Tenure is typically granted to protect academic \nfreedom and allow faculty to explore and express controversial or unpopular ideas without fear \nof retribution (American Association of University Professors, n.d.; Nolan, 2004). However, if \nresearchers are motivated primarily by the pursuit of tenure and are not concerned with the \nquality or relevance of their work, the purpose of academic research – to increase our \nunderstanding of the world and find ways to improve it – may be compromised (University of \nNorth Carolina, n.d.). Instead of relying solely on the number of papers published and the \nprestige of the journals in which they appear, higher education and research institutions could \nconsider alternative criteria for evaluating tenure, such as the potential impact and relevance of \nthe research to practice or its potential to make significant contributions to the field. By shifting \nthe focus away from quantity and prestige and towards the quality and relevance of research, \ninstitutions can discourage the use of ChatGPT and encourage more ethical practices in scholarly \npublishing. \nDiscussion \nThe comparison of GPT/ChatGPT to other existing language models has demonstrated the \nstrengths of these models in various language-related tasks. GPT-3 has shown itself to be highly \nversatile, efficient in using data, and capable of generating human-like language, making it a \nvaluable tool for tasks such as translation, summarization, and question answering (Liu et al., \n2022). Meanwhile, ChatGPT has the potential to improve research productivity and the quality \nof academic publications by streamlining the citation process and helping researchers accurately \nidentify and properly format citations. These capabilities make GPT/ChatGPT useful and \nvaluable tools for researchers and academics. \nHowever, the use of GPT/ChatGPT also raises several ethical concerns that must be considered \n(Zech, 2021). One issue is the ownership of the content generated by these models, as it is \nunclear who holds the rights to the generated text. There may also be concerns about the \nincorporation of third-party materials, such as quotes or data, and the need to ensure compliance \nwith copyright laws and proper attribution. The use of GPT/ChatGPT may impact traditional \npractices and the evaluation of research, as it has the potential to streamline the citation process \nand may raise questions about the value placed on human expertise (Etzioni, 2017). While \nChatGPT can be a useful tool for helping researchers identify and properly format citations, it is \nimportant to consider the potential for reliance on automated tools and the impact on traditional \npractices. It is crucial to address these ethical issues in order to ensure responsible and ethical use \nof GPT/ChatGPT in academia (Hancock et al., 2020).  \nThe ethical concerns related to the use of GPT/ChatGPT, such as ownership of generated content \nand compliance with copyright laws, are applicable to AI, NLP, and chatbots as a whole (Jarrahi \net al., 2022; Jobin, 2019). These concerns apply to any situation in which AI and chatbot \ntechnology is used to generate content or perform tasks that may have legal or ethical \nimplications (Wang et al., 2022). In terms of ownership of generated content, the issue of who \nholds the rights to text or other content produced by AI and chatbots is a broader concern that \napplies to the use of these technologies in various contexts. Similarly, the need to ensure \ncompliance with copyright laws and proper attribution is a concern that is relevant to any \nsituation in which AI and chatbots are used to incorporate third-party materials (Hristov, 2016). \nThe impact of AI and chatbots on traditional citation practices and the evaluation of research is \nalso a concern that is applicable to these technologies as a whole (Cox, 2022). As AI and \nchatbots become more prevalent, it is important to consider the potential implications for \ntraditional practices and to ensure that the value placed on human expertise is appropriately \nbalanced with the use of these technologies. \nThere are also limitations to this paper, as the comparison of GPT/ChatGPT to other language \nmodels may only be applicable at the time of writing. As new language models are developed, \nthe relative strengths and weaknesses of GPT/ChatGPT may change. Future research could \nexplore the use of GPT/ChatGPT in conjunction with other language models or technologies in \norder to enhance their capabilities and performance. Additionally, it would be worthwhile to \ninvestigate the use of GPT/ChatGPT in different tasks and domains, as well as to consider the \nfull range of existing language models. By expanding the scope of the study and exploring these \nareas, it may be possible to gain a more comprehensive understanding of the strengths and \nlimitations of GPT/ChatGPT and other language models. \nConclusion \nChatGPT and related technologies have the potential to significantly impact academia and \nscholarly research and publishing. However, it is important to carefully consider the ethical \nimplications of these technologies, particularly in regard to the use of GPT-3 by academics and \nresearchers. While ChatGPT and GPT-3 represent major advancements in artificial intelligence, \nmachine learning, and natural language processing, it is necessary to ensure that they are used \nethically and responsibly for scholarly research and publishing. Many questions about the ethics \nof using GPT in academia and its impact on research productivity remain unanswered. This \npaper aimed to provide a comprehensive overview of the current state of these discussions and to \nencourage further exploration of the ethical considerations surrounding the use of GPT and \nsimilar technologies in academia. \n \n \n  \nReferences \nAbd-Elaal, E., Gamage, S., Mills, J. E. (2022). Assisting academics to identify computer \ngenerated writing. European Journal of Engineering Education, 47(5), 725-745. \nhttps://doi.org/10.1080/03043797.2022.2046709  \nAdamopoulou, E., & Moussiades, L. (2020a). An overview of chatbot technology. In IFIP \nInternational Conference on Artificial Intelligence Applications and Innovations (pp. \n373-383). Springer. \nAdamopoulou, E., & Moussiades, L. (2020b). Chatbots: History, technology, and applications. \nMachine Learning with Applications, 2, article 100006. \nhttps://doi.org/10.1016/j.mlwa.2020.100006  \nAlutto, J.A. (2008). Final Report of the AACSB International Impact of Research Task Force. \nThe Association to Advance Collegiate Schools of Business, Tampa, FL. \nhttps://www.aacsb.edu/insights/reports/impact-of-research   \nAmerican Association of University Professors. (n.d.). Tenure. \nhttps://www.aaup.org/issues/tenure#:~:text=Why%20is%20tenure%20important%3F,con\nduct%20research%20in%20higher%20education.  \nAnderson, N., Belavy, D. L., Perle, S. M., Hendricks, S., Hespanhol, L., Verhagen, E., & \nMemon, A. R. (2023). AI did not write this manuscript, or did it? Can we trick the AI text \ndetector into generated texts? The potential future of ChatGPT and AI in Sports & \nExercise Medicine manuscript generation. BMJ Open Sport & Exercise Medicine, 9(1), \ne001568. \nAugier, M., March, J. G., & Sullivan, B. N. (2005). Notes on the evolution of a research \ncommunity: Organization studies in Anglophone North America, 1945–2000. \nOrganization Science, 16(1), 85-95. https://doi.org/10.1287/orsc.1040.0108  \nBasta, C., Costa-jussà, M. R., & Casas, N. (2019). Evaluating the Underlying Gender Bias in \nContextualized Word Embeddings. Proceedings of the Workshop on Gender Bias in \nNatural Language Processing, 1, 33–39. https://doi.org/10.18653/v1/W19-3805 \nBeath, C., Becerra-Fernandez, I., Ross, J., & Short, J. (2012). Finding value in the information \nexplosion. MIT Sloan Management Review, 53(4), 18-20.  \nBedeian, A. G. (1996). Thoughts on the making and remaking of the management discipline. \nJournal of Management Inquiry, 5(4), 311-318. \nhttps://doi.org/10.1177/105649269654003  \nBedeian, A. G. (2004). Peer review and the social construction of knowledge in the management \ndiscipline. Academy of Management Learning & Education, 3(2), 198-216. \nBender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the Dangers of \nStochastic Parrots: Can Language Models Be Too Big? Proceedings of the ACM \nConference on Fairness, Accountability, and Transparency, 2021, 610–623. \nhttps://doi.org/10.1145/3442188.3445922 \nBrandtzaeg, P. B., & Følstad, A. (2017). Why people use chatbots. In International conference \non internet science (pp. 377-392). Springer. \nBrockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., & Zaremba, W. \n(2016). Openai gym. arXiv. https://doi.org/10.48550/arXiv.1606.01540  \nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. \n(2020). Language models are few-shot learners. Advances in Neural Information \nProcessing Systems, 33, 1877-1901. \nBudzianowski, P., & Vulić, I. (2019). Hello, it's GPT-2--how can I help you? towards the use of \npretrained language models for task-oriented dialogue systems. arXiv. \nhttps://doi.org/10.48550/arXiv.1907.05774  \nCaplow, T., & McGee, R.J. (1958). The Academic Marketplace. New York, NY: Basic Books. \nCherian, A., Peng, K. C., Lohit, S., Smith, K., & Tenenbaum, J. B. (2022). Are Deep Neural \nNetworks SMARTer than Second Graders?. arXiv. \nhttps://doi.org/10.48550/arXiv.2212.09993  \nChiusano, F. (2022, September 20). A Brief Timeline of NLP. NLPlanet. \nhttps://medium.com/nlplanet/a-brief-timeline-of-nlp-bc45b640f07d  \nChowdhary, K. (2020). Natural language processing. In Fundamentals of artificial intelligence \n(p. 603-649). Springer.  \nCox, A. (2022). How artificial intelligence might change academic library work: Applying the \ncompetencies literature and the theory of the professions. Journal of the Association for \nInformation Science and Technology. https://doi.org/10.1002/asi.24635  \nDale, R. (2017). NLP in a post-truth world. Natural Language Engineering, 23(2), 319-324. \nhttps://doi.org/10.1017/S1351324917000018  \nDale, R. (2021). GPT-3 What’s it good for? Natural Language Engineering, 27(1), 113-118. \nhttps://doi.org/10.1017/S1351324920000601  \nDehouche, N. (2021). Plagiarism in the age of massive Generative Pre-Trained Transformers \n(GPT-3). Ethics in Science and Environmental Politics, 21, 17-23. \nhttps://doi.org/10.3354/esep00195  \nDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep \nbidirectional transformers for language understanding. arXiv. \nhttps://doi.org/10.48550/arXiv.1810.04805  \nElkins, K., & Chun, J. (2020). Can GPT-3 pass a Writer’s turing test? Journal of Cultural \nAnalytics, 5(2), 17212. https://doi.org/10.22148/001c.17212  \nErhan, D., Bengio, Y., Courville, A., Manzagol, P., & Vincent, P. (2010). Why does \nunsupervised pre-training help deep learning. Journal of Machine Learning Research, 11, \n625-660.  \nEtzioni, O. (2017). AI zooms in on highly influential citations. Nature, 547, article 32. \nhttps://doi.org/10.1038/547032a  \nFloridi, L., & Chiriatti, M. (2020). GPT-3: Its nature, scope, limits, and consequences. Minds and \nMachines, 30(4), 681-694. https://doi.org/10.1007/s11023-020-09548-1  \nFounta, A.-M., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G., Vakali, \nA., Sirivianos, M., & Kourtellis, N. (2018). Large Scale Crowdsourcing and \nCharacterization of Twitter Abusive Behavior (arXiv:1802.00393). arXiv. \nhttp://arxiv.org/abs/1802.00393 \n \nGasparyan, A. Y., Nurmashev, B., Seksenbayev, B., Trukhachev, V. I., Kostyukova, E. I., & \nKitas, G. D. (2017). Plagiarism in the context of education and evolving detection \nstrategies. Journal of Korean Medical Science, 32(8), 1220-1227. \nGillotte, J. L. (2019). Copyright infringement in ai-generated artworks. UC Davis Law Review, \n53, 2655-2676. \nGilot, R., & Cole, B. J. (2023). How will artificial intelligence affect scientific writing, reviewing \nand editing? The future is here. Arthroscopy. https://doi.org/10.1016/j.arthro.2023.01.014  \nGoh, G., Cammarata, N., Voss, C., Carter, S., Petrov, M., Schubert, L., Radford, A., & Olah, C. \n(2021). Multimodal neurons in artificial neural networks. Retrieved from \nhttps://doi.org/10.23915/distill.00030  \nGonzález-Padilla, D. A. (2022). Concerns About the Potential Risks of Artificial Intelligence in \nManuscript Writing. The Journal of Urology, 10-1097. \nhttps://doi.org/10.1097/JU.0000000000003131  \nHa, T. (2022). An explainable artificial-intelligence-based approach to investigating factors that \ninfluence the citation of papers. Technological Forecasting and Social Change, 184, \narticle 121974. \nHaenlein, M., & Kaplan, A. (2019). A brief history of artificial intelligence: On the past, present, \nand future of artificial intelligence. California Management Review, 61(4), 5-14. \nhttps://doi.org/10.1177/0008125619864925  \nHancock, J. T., Naaman, M., & Levy, K. (2020). AI-mediated communication: Definition, \nresearch agenda, and ethical considerations. Journal of Computer-Mediated \nCommunication, 25(1), 89-100. https://doi.org/10.1093/jcmc/zmz022  \nHaque, M. U., Dharmadasa, I., Sworna, Z. T., Rajapakse, R. N., & Ahmad, H. (2022). \" I think \nthis is the most disruptive technology\": Exploring Sentiments of ChatGPT Early \nAdopters using Twitter Data. arXiv. https://doi.org/10.48550/arXiv.2212.05856  \nHirschberg, J., & Manning, C. D. (2015). Advances in natural language processing. Science, \n349(6245), 261–266. https://doi.org/10.1126/science.aaa8685  \nHorner, R. D., & Lines, L. M. (2019). Anatomy of Constructive Peer Review. Medical Care, \n57(6), 399-400. \nHristov, K. (2016). Artificial intelligence and the copyright dilemma. IDEA: The Intellectual \nProperty Law Review, 57(3), 431-454.  \nHugenholtz, P. B., & Quintais, J. P. (2021). Copyright and artificial creation: Does EU copyright \nlaw protect AI-assisted output? International Review of Intellectual Property and \nCompetition Law, 52, 1190-1216. https://doi.org/10.1007/s40319-021-01115-0  \nHutchinson, B., Prabhakaran, V., Denton, E., Webster, K., Zhong, Y., & Denuyl, S. (2020). \nSocial Biases in NLP Models as Barriers for Persons with Disabilities. Proceedings of the \nAnnual Meeting of the Association for Computational Linguistics, 58, 5491–5501. \nhttps://doi.org/10.18653/v1/2020.acl-main.487  \nHutson, M. (2021). Robo-writers: The rise and risks of language-generating AI. Nature, \n591(7848), 22–25. https://doi.org/10.1038/d41586-021-00530-0 \nHyland, K. (1999). Academic attribution: Citation and the construction of disciplinary \nknowledge. Applied Linguistics, 20(3), 341-367.  \nJarrahi, M. H., Lutz, C., Boyd, K., Oesterlund, C., & Willis, M. (2022). Artificial intelligence in \nthe work context. Journal of the Association for Information Science and Technology. \nhttps://doi.org/10.1002/asi.24730  \nJiao, W., Wang, W., Huang, J., Wang, X., & Tu, Z. (2023). Is ChatGPT a good translator? A \npreliminary study. Arxiv. https://doi.org/10.48550/arXiv.2301.08745  \nJobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature \nMachine Intelligence, 1, 389-399. https://doi.org/10.1038/s42256-019-0088-2  \nJordan, M. I., & Mitchell, T. M. (2015). Machine learning: Trends, perspectives, and prospects. \nScience, 349(6245), 255–260. https://doi.org/10.1126/science.aaa8415  \nKaltenbrunner, W., Pinfield, S., Waltman, L., Woods, H. B., & Brumberg, J. (2022). Innovating \npeer review, reconfiguring scholarly communication: An analytical overview of ongoing \npeer review innovation activities. Journal of Documentation, 78(7), 429-449. \nhttps://doi.org/10.1108/JD-01-2022-0022  \nKalyanathaya, K. P., Akila, D., & Rajesh, P. (2019). Advances in natural language processing: A \nsurvey of current research trends, development tools and industry applications. \nInternational Journal of Recent Technology and Engineering, 7(5C), 199-201.  \nKhanna, A., Pandey, B., Vashishta, K., Kalia, K., Pradeepkumar, B., & Das, T. (2015). A Study \nof Today’s A.I. through Chatbots and Rediscovery of Machine Intelligence. International \nJournal of U- and e-Service, Science and Technology, 8(7), 277–284. \nhttps://doi.org/10.14257/ijunesst.2015.8.7.28  \nKing, M. R. (2022). The future of AI in medicine: A perspective from a chatbot. Annals of \nBiomedical Engineering. https://doi.org/10.1007/s10439-022-03121-w  \nKing, M. R. (2023). A conversation on artificial intelligence, chatbots, and plagiarism in higher \neducation. Cellular and Molecular Bioengineering. https://doi.org/10.1007/s12195-022-\n00754-8  \nKirmani, A. R. (2022). Artificial intelligence-enabled science poetry. ACS Energy Letters, 8, \n574-576. https://doi.org/10.1021/acsenergylett.2c02758  \nLiu, J., Shen, D., Zhang, Y., Dolan, W. B., Carin, L., & Chen, W. (2022). What Makes Good In-\nContext Examples for GPT-3?. Proceedings of Deep Learning Inside Out (DeeLIO \n2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning \nArchitectures, 3, 100-114.  \nLiu, X., Zheng, Y., Du, Z., Ding, M., Qian, Y., Yang, Z., & Tang, J. (2021). GPT understands, \ntoo. arXiv. https://doi.org/10.48550/arXiv.2103.10385  \nLiu, Y., Mittal, A., Yang, D., & Bruckman, A. (2022). Will AI console me when I lose my pet? \nUnderstanding perceptions of AI-mediated email writing. Proceedings of the CHI \nConference on Human Factors in Computing Systems, 2022, article 474. \nhttps://doi.org/10.1145/3491102.3517731  \nLiu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). Roberta: A \nrobustly optimized bert pretraining approach. arXiv. \nhttps://doi.org/10.48550/arXiv.1907.11692  \nLokman, A. S., & Ameedeen, M. A. (2018, November). Modern chatbot systems: A technical \nreview. In Proceedings of the future technologies conference (pp. 1012-1023). Springer, \nCham. \nLu, Y. (2019). Artificial intelligence: A survey on evolution, models, applications and future \ntrends. Journal of Management Analytics, 6(1), 1–29. \nhttps://doi.org/10.1080/23270012.2019.1570365  \nLucy, L., & Bamman, D. (2021). Gender and representation bias in GPT-3 generated stories. \nProceedings of the Workshop on Narrative Understanding, 3, 48-55.  \nLund, B. D. (2022). Is academic research and publishing still leaving developing countries \nbehind? Accountability in Research, 29(4), 224-231. \nhttps://doi.org/10.1080/08989621.2021.1913124  \nLund, B. D., & Wang, T. (2023). Chatting about ChatGPT: How may AI and GPT impact \nacademia and libraries? Library Hi Tech News. https://doi.org/10.1108/LHTN-01-2023-\n0009  \nMahesh, B. (2020). Machine learning algorithms-a review. International Journal of Science and \nResearch (IJSR), 9, 381-386. \nMakridakis, S. (2017). The forthcoming artificial intelligence (AI) revolution: Its impact on \nsociety and firms. Futures, 90, 46-60. https://doi.org/10.1016/j.futures.2017.03.006  \nMarcus, G., Davis, E., & Aaronson, S. (2022). A very preliminary analysis of DALL-E 2. ArXiv \npre-print. Retrieved from https://doi.org/10.48550/arXiv.2204.13807  \nMerton, R. K. (1968). The Matthew Effect in Science: The reward and communication systems \nof science are considered. Science, 159(3810), 56-63. \nMiller, A. N., Taylor, S. G., & Bedeian, A. G. (2011). Publish or perish: Academic life as \nmanagement faculty live it. Career Development International, 16(5), 422-445. \nMintz, Y., & Brodie, R. (2019). Introduction to artificial intelligence in medicine. Minimally \nInvasive Therapy & Allied Technologies, 28(2), 73–81. \nhttps://doi.org/10.1080/13645706.2019.1575882  \nMollman, S. (2022). ChatGPT gained 1 million users in under a week. Retrieved from \nhttps://www.yahoo.com/lifestyle/chatgpt-gained-1-million-followers  \nMüller, V. C. (2021). Ethics of Artificial Intelligence and Robotics. E. N. Zalta, The Stanford \nEncyclopedia of Philosophy (Summer 2021). Metaphysics Research Lab, Stanford \nUniversity. https://plato.stanford.edu/archives/sum2021/entries/ethics-ai/  \nNadkarni, P. M., Ohno-Machado, L., & Chapman, W. W. (2011). Natural language processing: \nAn introduction. Journal of the American Medical Informatics Association, 18(5), 544–\n551. https://doi.org/10.1136/amiajnl-2011-000464  \nNagarhalli, T. P., Vaze, V., & Rana, N. K. (2020). A Review of Current Trends in the \nDevelopment of Chatbot Systems. In 2020 International Conference on Advanced \nComputing and Communication Systems (ICACCS), 6,, 706–710. \nhttps://doi.org/10.1109/ICACCS48705.2020.9074420  \nNature Machine Intelligence Editorial Board. (2020). Next chapter in artificial writing. Nature \nMachine Intelligence, 2, 419.  \nNolan, C. W. (2004). Tenure-Track or Tenure Trap?. In P.K. Shontz (Ed.), The librarian's career \nguidebook (p. 281-290). Lanham, MD: Scarecrow Press. \nOlsson, A., & Engelbrektsson, O. (2022). A thesis that writes itself: On the threat of AI-\ngenerated essays within academia. (Bachelor Thesis). https://www.diva-\nportal.org/smash/get/diva2:1669744/FULLTEXT02  \nOpenAI. (2022). OpenAI about page. Retrieved from https://openai.com/about/  \nPerc, M. (2014). The Matthew effect in empirical data. Journal of the Royal Society Interface, \n11(98). https://doi.org/10.1098/rsif.2014.0378  \nPerrigo, B. (2023). OpenAI used Kenyan workers on less than $2 per hour to make ChatGPT less \ntoxic. Retrieved from https://time.com/6247678/openai-chatgpt-kenya-workers/  \nPertile, S., Moreira, V. P., & Rosso, P. (2015). Comparing and combing content- and citation-\nbased approaches for plagiarism detection. Journal of the Association for Information \nScience and Technology, 67(10), 2511-2526.  \nRadford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language \nunderstanding by generative pre-training. Retrieved from \nhttps://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf  \nSantini, A. (2018). The importance of referencing. The Journal of Critical Care Medicine, 4(1), \n3. https://doi.org/10.2478/jccm-2018-0002  \nSchönberger, D. (2018). Deep copyright: Up- and downstream questions related to artificial \nintelligence (AI) and machine learning (ML). SSRN. Retrieved from \nhttps://papers.ssrn.com/sol3/papers.cfm?abstract_id=3098315  \nStokel-Walker, C., & Van Noorden, R. (2023). What ChatGPT and generative AI mean for \nscience. Nature, 614(7947), 214-216. \nStrubell, E., Ganesh, A., & McCallum, A. (2019). Energy and policy considerations for deep \nlearning in NLP. Proceedings of the Annual Meeting of the Association for \nComputational Linguistics, 57, 3645-3650.  \nTan, Y. C., & Celis, L. E. (2019). Assessing social and intersectional biases in contextualized \nword representations. Proceedings of the 33rd International Conference on Neural \nInformation Processing Systems (pp.13230–13241). Curran Associates Inc. \nThigpen, C., & Funk, C. (2019). Most Americans says science has brought benefits to society \nand expect more to come. https://www.pewresearch.org/fact-tank/2019/08/27/most-\namericans-say-science-has-brought-benefits-to-society-and-expect-more-to-come/  \nThorp, H. H. (2023). ChatGPT is fun, but not an author. Science, 379(6630), 313. \nhttps://doi.org/10.1126/science.adg7879  \nUniversity of North Carolina. (n.d.). What is Sociology?.  \nhttps://sociology.unc.edu/undergraduate-program/sociology-major/what-is-sociology/  \nWaggoner, A. (2018). Improving the quality of constructive peer feedback. College Teaching, \n66(1), 22-23. \nWamba, S. F., Bawack, R. E., Guthrie, C., Queiroz, M. M., & Carillo, K. D. (2021). Are we \npreparing for a good AI society? A bibliometric review and research agenda. \nTechnological Forecasting and Social Change, 164, article 120482. \nhttps://doi.org/10.1016/j.techfore.2020.120482  \nWang, X., Lin, X., & Shao, B. (2022). Artificial intelligence changes the way we work: A close \nlook at innovating with chatbots. Journal of the Association for Information Science and \nTechnology, 74(3), 339-353. https://doi.org/10.1002/asi.24621  \nWoods, H. B., Brumberg, J., Kaltenbrunner, W., Pinfield, S., & Waltman, L. (2023). An \noverview of innovations in the external peer review of journal manuscripts. Wellcome \nOpen Research, 7(82), 82. \nYang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. V. (2019). XLNet: \ngeneralized autoregressive pretraining for language understanding. Proceedings of the \n33rd International Conference on Neural Information Processing Systems, 33, 5753-\n5763. \nYanisky-Ravid, S. (2017). Generating Rembrandt: Artificial intelligence, copyright, and \naccountability in the 3A Era: The human-like authors are already here. Michigan State \nLaw Review, Review 659. \nZech, H. (2021). Liability for AI: Public policy considerations. ERA Forum, 22, 147-158. \nhttps://doi.org/10.1007/s12027-020-00648-0  \nZhao, J., Wang, T., Yatskar, M., Cotterell, R., Ordonez, V., & Chang, K.-W. (2019). Gender \nBias in Contextualized Word Embeddings. Proceedings of the 2019 Conference of the \nNorth American Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies, Volume 1 (Long and Short Papers), 629–634. \nhttps://doi.org/10.18653/v1/N19-1064 \nZhou, X., Chen, Z., Jin, X., & Wang, W. Y. (2021). HULK: An energy efficiency benchmark \nplatform for responsible natural language processing. Proceedings of the Conference of \nthe European Chapter of the Association for Computational Linguistics: System \nDemonstrations, 16, 329-336.   \nAppendix 1. ChaptGPT’s essay on the value of AI (written entirely by ChatGPT, without \nany human editing) \nArtificial intelligence (AI) refers to the development of computer systems that are able to \nperform tasks that normally require human intelligence, such as learning, problem-solving, and \ndecision making. In recent years, AI has made significant strides in a wide range of fields, and its \npotential to revolutionize and improve many aspects of our lives is vast. \nOne of the main values of AI is its ability to automate and streamline processes, freeing up time \nand resources for more complex or high-value tasks. For example, AI can be used to analyze \nlarge amounts of data, identify patterns and trends, and make predictions or recommendations, \nall tasks that would be time-consuming and resource-intensive for humans to perform. This can \nenable organizations and individuals to make more informed decisions and to operate more \nefficiently. \nAnother key value of AI is its ability to augment and enhance human capabilities. For example, \nAI-powered assistants and chatbots can help people to access information and services more \nquickly and easily, while AI-powered tools and devices can help people to communicate, \ncollaborate, and work more effectively. \nAI also has the potential to drive innovation and progress in a wide range of fields, from \nhealthcare and education to transportation and energy. For example, AI-powered tools and \nalgorithms can help researchers and scientists to analyze data, make discoveries, and develop \nnew therapies and treatments, while AI-powered systems and devices can help to improve the \nefficiency, safety, and sustainability of various industries and sectors. \nIn conclusion, AI has the potential to bring many benefits and improvements to our lives and \nsociety as a whole. By harnessing the power of AI and using it responsibly and ethically, we can \nhelp to shape a brighter and more prosperous future. "
}