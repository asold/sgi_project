{
  "title": "The impact of large language models on radiology: a guide for radiologists on the latest innovations in AI",
  "url": "https://openalex.org/W4393317046",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2742770852",
      "name": "Nakaura Takeshi",
      "affiliations": [
        "Kumamoto University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2749435655",
      "name": "Ito Rintaro",
      "affiliations": [
        "Nagoya University"
      ]
    },
    {
      "id": "https://openalex.org/A4313370934",
      "name": "Ueda, Daiju",
      "affiliations": [
        "Osaka Metropolitan University"
      ]
    },
    {
      "id": "https://openalex.org/A2594688953",
      "name": "Nozaki Taiki",
      "affiliations": [
        "Keio University"
      ]
    },
    {
      "id": "https://openalex.org/A2613545413",
      "name": "Fushimi Yasutaka",
      "affiliations": [
        "Kyoto University"
      ]
    },
    {
      "id": "https://openalex.org/A2596607923",
      "name": "Matsui, Yusuke",
      "affiliations": [
        "Okayama University"
      ]
    },
    {
      "id": "https://openalex.org/A2324982695",
      "name": "Yanagawa Masahiro",
      "affiliations": [
        "Osaka University"
      ]
    },
    {
      "id": "https://openalex.org/A2106115791",
      "name": "Yamada Akira",
      "affiliations": [
        "Shinshu University"
      ]
    },
    {
      "id": "https://openalex.org/A2747629706",
      "name": "Tsuboyama Takahiro",
      "affiliations": [
        "Osaka University"
      ]
    },
    {
      "id": "https://openalex.org/A2743687927",
      "name": "Fujima Noriyuki",
      "affiliations": [
        "Hokkaido University Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2742005259",
      "name": "Tatsugami Fuminari",
      "affiliations": [
        "Hiroshima University"
      ]
    },
    {
      "id": "https://openalex.org/A2581069957",
      "name": "Hirata Kenji",
      "affiliations": [
        "Hokkaido University"
      ]
    },
    {
      "id": "https://openalex.org/A2466524925",
      "name": "Fujita, Shohei",
      "affiliations": [
        "The University of Tokyo"
      ]
    },
    {
      "id": "https://openalex.org/A2746053066",
      "name": "Kamagata Koji",
      "affiliations": [
        "Juntendo University"
      ]
    },
    {
      "id": "https://openalex.org/A2746179153",
      "name": "Fujioka Tomoyuki",
      "affiliations": [
        "Tokyo Medical and Dental University"
      ]
    },
    {
      "id": "https://openalex.org/A2746225128",
      "name": "Kawamura Mariko",
      "affiliations": [
        "Nagoya University"
      ]
    },
    {
      "id": "https://openalex.org/A2747414228",
      "name": "Naganawa Shinji",
      "affiliations": [
        "Nagoya University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3097447949",
    "https://openalex.org/W2016589492",
    "https://openalex.org/W4240516607",
    "https://openalex.org/W2903444831",
    "https://openalex.org/W4220749425",
    "https://openalex.org/W4297964600",
    "https://openalex.org/W4296331181",
    "https://openalex.org/W3184019679",
    "https://openalex.org/W4284988499",
    "https://openalex.org/W3214912989",
    "https://openalex.org/W4220787270",
    "https://openalex.org/W4322759027",
    "https://openalex.org/W4385294740",
    "https://openalex.org/W4294839427",
    "https://openalex.org/W4378781316",
    "https://openalex.org/W4210480444",
    "https://openalex.org/W4296330952",
    "https://openalex.org/W3217231380",
    "https://openalex.org/W4366241065",
    "https://openalex.org/W4313649627",
    "https://openalex.org/W4225611710",
    "https://openalex.org/W3198549915",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W4389524555",
    "https://openalex.org/W4313045155",
    "https://openalex.org/W3206387060",
    "https://openalex.org/W4364363895",
    "https://openalex.org/W4389519585",
    "https://openalex.org/W4353015365",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4385564466",
    "https://openalex.org/W4313451803",
    "https://openalex.org/W4367310920",
    "https://openalex.org/W2965300902",
    "https://openalex.org/W4376640725",
    "https://openalex.org/W4387326101",
    "https://openalex.org/W4386874181",
    "https://openalex.org/W4323360926",
    "https://openalex.org/W4387327030",
    "https://openalex.org/W4293206507",
    "https://openalex.org/W4226376045",
    "https://openalex.org/W4206491499",
    "https://openalex.org/W4380422747",
    "https://openalex.org/W4361286180",
    "https://openalex.org/W4362522726",
    "https://openalex.org/W4377010595",
    "https://openalex.org/W2963967185",
    "https://openalex.org/W3151410070",
    "https://openalex.org/W4206368078",
    "https://openalex.org/W4386757338",
    "https://openalex.org/W3089474066",
    "https://openalex.org/W4315784554",
    "https://openalex.org/W4387029265",
    "https://openalex.org/W4317390716",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4387296225",
    "https://openalex.org/W4387949708",
    "https://openalex.org/W4365511667",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4387472386"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nJapanese Journal of Radiology (2024) 42:685–696 \nhttps://doi.org/10.1007/s11604-024-01552-0\nINVITED REVIEW\nThe impact of large language models on radiology: a guide \nfor radiologists on the latest innovations in AI\nTakeshi Nakaura1  · Rintaro Ito2 · Daiju Ueda3 · Taiki Nozaki4 · Yasutaka Fushimi5 · Yusuke Matsui6 · \nMasahiro Yanagawa7 · Akira Yamada8 · Takahiro Tsuboyama7 · Noriyuki Fujima9 · Fuminari Tatsugami10 · \nKenji Hirata11 · Shohei Fujita12 · Koji Kamagata13 · Tomoyuki Fujioka14 · Mariko Kawamura2 · Shinji Naganawa2\nReceived: 15 November 2023 / Accepted: 21 February 2024 / Published online: 29 March 2024 \n© The Author(s) 2024\nAbstract\nThe advent of Deep Learning (DL) has significantly propelled the field of diagnostic radiology forward by enhancing \nimage analysis and interpretation. The introduction of the Transformer architecture, followed by the development of Large \nLanguage Models (LLMs), has further revolutionized this domain. LLMs now possess the potential to automate and refine \nthe radiology workflow, extending from report generation to assistance in diagnostics and patient care. The integration of \nmultimodal technology with LLMs could potentially leapfrog these applications to unprecedented levels.\nHowever, LLMs come with unresolved challenges such as information hallucinations and biases, which can affect \nclinical reliability. Despite these issues, the legislative and guideline frameworks have yet to catch up with technological \nadvancements. Radiologists must acquire a thorough understanding of these technologies to leverage LLMs’ potential to the \nfullest while maintaining medical safety and ethics. This review aims to aid in that endeavor.\nKeywords Diagnostic radiology · Artificial intelligence · Deep learning · Large language model · Radiological workflow\nAbbreviations\nAI  Artificial intelligence\nBERT  Bidirectional encoder representations from \ntransformers\nCNN  Convolutional neural networks\nCT  Computed tomography\nDL  Deep learning\nGPT  Generative pre-trained transformer\nICLR  International conference on learning \nrepresentations\n * Takeshi Nakaura \n kff00712@nifty.com\n1 Department of Central Radiology, Kumamoto University \nHospital, Honjo 1-1-1, Kumamoto 860-8556, Japan\n2 Department of Radiology, Nagoya University Graduate \nSchool of Medicine, Nagoya, Aichi, Japan\n3 Department of Diagnostic and Interventional Radiology, \nGraduate School of Medicine, Osaka Metropolitan \nUniversity, 1-4-3 Asahi-Machi, Abeno-ku, Osaka 545-8585, \nJapan\n4 Department of Radiology, Keio University School \nof Medicine, Shinjuku-ku, Tokyo, Japan\n5 Department of Diagnostic Imaging and Nuclear Medicine, \nKyoto University Graduate School of Medicine, Sakyoku, \nKyoto, Japan\n6 Department of Radiology, Faculty of Medicine, Dentistry \nand Pharmaceutical Sciences, Okayama University, Kita-ku, \nOkayama, Japan\n7 Department of Radiology, Osaka University Graduate School \nof Medicine, Suita City, Osaka, Japan\n8 Department of Radiology, Shinshu University School \nof Medicine, Matsumoto, Nagano, Japan\n9 Department of Diagnostic and Interventional Radiology, \nHokkaido University Hospital, Sapporo, Japan\n10 Department of Diagnostic Radiology, Hiroshima University, \nMinami-ku, Hiroshima, Japan\n11 Department of Diagnostic Imaging, Graduate School \nof Medicine, Hokkaido University, Kita-ku, Sapporo, \nHokkaido, Japan\n12 Department of Radiology, University of Tokyo, Bunkyo-ku, \nTokyo, Japan\n13 Department of Radiology, Juntendo University Graduate \nSchool of Medicine, Bunkyo-ku, Tokyo, Japan\n14 Department of Diagnostic Radiology, Tokyo Medical \nand Dental University, Bunkyo-ku, Tokyo, Japan\n686 Japanese Journal of Radiology (2024) 42:685–696\nJRBE  Japan radiology board examination\nLLM  Large language models\nLSTM  Long short-term memory\nMRI  Magnetic resonance imaging\nNLP  Natural language processing\nRNN  Recurrent neural networks\nRLHF  Reinforcement learning from human feedback\nRSNA  Radiological society of North America\nUSMLE  United States medical licensing examination\nIntroduction\nThe inception of Deep Learning (DL) has catalyzed a \nsignificant progression in artificial intelligence (AI) [1 ], \nunlocking numerous possibilities, especially in diagnostic \nradiology—an arena pivotal for accurate imaging data \ninterpretation. This progression is attributed mainly to the \nemergence of Convolutional Neural Networks (CNNs) \n[2, 3], which have markedly enhanced image recognition, \nsegmentation, analysis, and improvement of image quality \n[1, 4–15]. This represents a foundational shift in automated \nfeature extraction from imaging data, consequently reducing \nthe time and expertise required for interpreting medical \nimages. Additionally, DL-powered tools have demonstrated \ntheir efficacy in improving diagnostic accuracy by aiding \nradiologists in precisely detecting anomalies such as tumors, \nexternal injuries, and other pathological conditions [16–20]. \nThese advancements not only accelerate the diagnostic \nprocess but also contribute substantially to prognostic \nevaluations, thus playing a crucial role in elevating patient \ncare and outcomes [21].\nThe introduction of the Transformer architecture has \nbeen a significant milestone in machine learning, paving \nthe way for the development of Large Language Models \n(LLMs) such as the Generative Pre-trained Transformer \n(GPT) series. The architecture’s proficiency in handling \nsequential data efficiently through attention mechanisms \nhas expedited the evolution of LLMs, which now possess \nthe ability to understand and generate human-like text with \nremarkable accuracy. The subsequent advent of ChatGPT \nfurther accentuated the popularity and utility of LLMs \nby showcasing their capability to engage in more natural, \ndynamic dialogues, thus expanding the scope of applications \nacross various fields. In diagnostic radiology, LLMs might \noffer a promising pathway for enhancing multiple aspects of \nthe radiology workflow. Their capability to automate report \ngeneration and expedite information retrieval can potentially \nsave significant time for radiologists, thereby ameliorating \nthe efficiency and accuracy of diagnostic processes.\nDespite the undeniable utility of LLMs, there has been \na scarcity of reviews describing the rapid development of \nLLMs for clinical radiologists. This article delineates a brief \nhistory of contemporary LLMs and provides a synopsis of \ntheir application in radiology for the clinical radiologist.\nOverview of DL and LLM before transformer \narchitecture\nNatural Language Processing (NLP), CNN-based image \nprocessing, is a branch of AI. Recently, DL has been \nemployed extensively in NLP tasks. This wide applicabil-\nity of DL can be attributed to the universal approximation \ntheorem [22]. This theorem suggests that a neural network, \nprovided with enough layers and neurons, can approxi-\nmate any reasonable function with a high degree of accu-\nracy. DL thus operates by approximating an ideal func -\ntion capable of transforming various data types, such as \nimages, music, and text, into other forms of data (Fig.  1). \nIn broad terms, the current LLM process involves gener -\nating a response sentence from a given request sentence, \nFig. 1  Overview of the Deep Learning Process. If there is some relationship between the matrices representing input and output data, Deep \nLearning can learn it given a myriad of training data by the “universal approximation theorem”\n687Japanese Journal of Radiology (2024) 42:685–696 \nessentially transforming multi-dimensional vectors repre -\nsenting the request sentence into multi-dimensional vec-\ntors representing the response sentence. Despite the devel-\nopment of various DL models for language processing \napplications, this fundamental concept remains constant.\nBefore the inception of the Transformer architecture, \nthe domain of NLP chiefly relied on architectural \nframeworks such as Recurrent Neural Networks (RNNs) \n[2], Long Short-Term Memory networks (LSTMs) [23], \nand CNNs. RNNs, with their intrinsic capability to \nencapsulate sequential information, were predominantly \nemployed for an array of NLP tasks including but not \nlimited to translation, sentiment analysis, and named \nentity recognition. However, they frequently encountered \nchallenges with long-term dependencies owing to the \nvanishing or exploding gradient dilemma. To alleviate \nthese issues, LSTMs were introduced as a special kind \nof RNN capable of learning long-term dependencies, \nproviding a more robust framework for handling sequences \nand time-series data. Nonetheless, while LSTMs mitigated \nthe gradient problem to an extent, they still entailed a \nsignificant computational and temporal demand, especially \nas data complexity increased. Conversely, CNNs were \nmore adept at local pattern recognition within data and \nfound their application in certain NLP tasks, yet they \ntoo were encumbered by limitations in capturing long-\nrange dependencies within text sequences. Moreover, the \ncomputational and temporal demands of training these \nnetworks escalated significantly, especially in the face of \nthe burgeoning size and intricacy of data.\nRecently, it has been elucidated that the efficacy of modi-\nfied RNN can be commensurate with that of newer models \n[24], contingent upon the scale. However, the formidable \ncomputational costs associated with their operation pose a \nsignificant deterrent, leading to their diminished utilization \nin recent times. It is also recognized that the architectural \ndistinctions among these models exert a lesser impact on \nperformance compared to the magnitude of parameters \nencompassed [25]. Hence, the details of the structure of \nthese models are omitted from this review. The cornerstone \nof operation for these NLP frameworks, inclusive of the \nsubsequent Transformer architecture delineated, hinges on \nthe initial transmutation of textual sentences into a numeri-\ncal sequence termed as tokens, facilitated by a tokenizer. \nFigure  2 shows an example of sentence conversion by an \nonline Tokenizer (https:// platf orm. openai. com/ token izer). \nThis token sequence subsequently undergoes a further trans-\nmutation into an alternate numerical sequence. This tokeni-\nzation process has been used in NLP even before the rapid \ndevelopment of Deep Learning, and the basic principle is \nthe same in recent LLM.\nAdvent and evolution of the transformer \narchitecture for LLM\nThe advent of the Transformer architecture marked a signifi-\ncant milestone in the realms of NLP and machine learning \n[26–28]. Unlike previous architectures, the Transformer was \ndesigned to efficiently handle parallel processing, making it \nespecially suitable for training on graphics processing units. \nThis novel design facilitated a substantial reduction in training \ntimes and effective management of large datasets, enabling the \ntraining of large-scale models that were previously unfeasible. \nFurthermore, this escalation in learning scale elucidated rela-\ntionships known as scaling laws (Fig. 3), which delineate the \nrelationships between model size, dataset size, and the amount \nof computing used for training [25]. This study reported the \nperformance of language models on the cross-entropy loss \nscales according to a power-law to these factors.\nThe scalability and parallel processing capabilities of the \nTransformer architecture accelerated the development of \nlarge-scale neural network models. Notably, the Generative \nPre-trained Transformer (GPT) [25, 29, 30] and Bidirectional \nEncoder Representations from Transformers (BERT) [31] \nstand as exemplary embodiments of the large-scale expansion \nand advancement of the Transformer. GPT, developed by \nOpenAI, is an LLM based on the Transformer architecture, \nfocusing on predicting the next word in a given text sequence. \nIt is generally pre-trained on a vast text corpus and then fine-\ntuned for specific tasks. The GPT series (GPT-1, 2, 3, 3.5, \nand 4) aims to enhance performance by augmenting model \nsize, with GPT-3 boasting 175 billion parameters [25]. On \nthe other hand, BERT, developed by Google, also leverages \nthe Transformer architecture but adopts a different approach. \nBy considering bidirectional context, BERT achieves superior \nperformance on specific NLP tasks, which is particularly \nadvantageous in tasks like question-answering and named \nentity recognition.\nIn any case, as the scale increases, the performance \nof language models on tasks has significantly improved. \nParticularly, large-scale models like GPT-3 have been \nreported to exhibit excellent performance on entirely new \ntasks without retraining or with just a few demonstrations \n[25]. This burgeoning performance with scale underscores \nthe remarkable potential and evolution propelled by the \nTransformer architecture, contributing to the broad spectrum \nof advancements in NLP and machine learning fields.\nLLM limitations\nDespite the remarkable achievements, LLMs have inherent \nlimitations. One of the notable issues is hallucination, where \nthe model generates incorrect or fictional information that \n688 Japanese Journal of Radiology (2024) 42:685–696\n\n689Japanese Journal of Radiology (2024) 42:685–696 \nwasn’t present in the training data [32– 36]. This problem \narises due to several underlying factors and poses challenges \nto the implementation and trustworthiness of LLMs, espe-\ncially in critical fields like healthcare. A notable cause of \nhallucination, the source-reference divergence, arises from \nheuristic data collection methods or inherent challenges in \ncertain natural language generation tasks, leading to devia-\ntions from the provided source during text generation. Simi-\nlarly, exploitation through 'jailbreak' prompts that were not \nintended by the developers, which manipulate the model’s \nbehavior or output, and reliance on datasets with incom-\nplete or contradictory information significantly influence the \nLLM’s generated responses. These issues are exacerbated \nby misleading training data, where incorrect, outdated, or \nbiased information is propagated into the generated outputs, \nfurther undermining the reliability of LLMs in a clinical set-\nting. Mitigation strategies aimed at reducing hallucination in \nLLMs include the employment of regularization techniques, \naugmenting training data, and leveraging few-shot learning \nstrategies. However, completely preventing hallucination \nremains a formidable challenge due to the inherent limi-\ntations of the current LLM architectures and the vast and \nvaried nature of the training data.\nInductive biases [37] refer to the set of assumptions that \na model makes to predict outputs for unseen data. In LLMs, \nthese biases might arise from the training data, leading the \nmodel to generate outputs that may not align with real-world \nscenarios. The performance and the model’s capacity to \ngeneralize across varying contexts can be adversely affected \nby these biases. Additionally, the “black box” nature of \nLLMs denotes the lack of transparency in understanding \nhow the model arrives at a particular decision, which is a \ncritical requirement for real-world applications, particularly \nin fields demanding explainability like medical fields.\nThe output generated by LLM can be inaccurate \nand misleading due to these limitations and can lead to \nmisguided clinical problems [38], and LLM output should \nbe carefully evaluated by professionals.\nRelease of ChatGPT and its application \nto medical fields\nThe public release of ChatGPT on November 30, 2022, \ndeveloped by Open AI, heralded a new era of accessibility, \ndrawing a plethora of users from diverse fields. The \ntransition to GPT-3.5 used in ChatGPT was a pivotal \nmoment, as the incorporation of Reinforcement Learning \nfrom Human Feedback (RLHF) [39] played a crucial role in \nrefining the model's responses, making them more coherent \nand contextually appropriate. This widespread adoption \ntriggered a boom, as the model's potential in various \napplications was explored extensively. Additionally, GPT-4 \nis slated for public availability on March 14, 2023. While \nthe specific architectural details remain undisclosed, it is \nanticipated that GPT-4 will herald enhanced performance \nacross diverse domains, marking a substantial advancement \nfrom its predecessor, GPT-3.5.\nIn the medical field, ChatGPT showcased an impressive \naptitude by excelling in medical examinations [40], a \ntestament to its proficiency in handling medical knowledge. \nFurthermore, studies have highlighted its competence \nin real-world medication consultations [41], where it \ndisplayed a higher appropriateness rate in responding to \npublic consultation questions compared to those posed \nby healthcare providers in a hospital setting. Although \nChatGPT’s official warnings mention its use in diagnostics, \nsaying, “Making automated decisions in domains that affect \nan individual’s rights or well-being (e.g., law enforcement, \nmigration, management of critical infrastructure, safety \ncomponents of products, essential services, credit, \nemployment, housing, education, social scoring, or \ninsurance)” (https:// openai. com/ polic ies/ usage- polic ies) and \nthe use of ChatGPT on WWW may have a serious concern \nof data leaking unless user manifest opt-out (https:// priva  \ncy. openai. com/ polic ies), these achievements highlight \nChatGPT’s potential in giving important medical insights.\nCapable applications of LLM in the radiology \nfield\nRadiologists routinely engage with a substantial volume of \ntextual information encompassing diagnostic request forms, \nmedical charts, reports from other examinations, references \nto various guidelines and past literature, diagnostic imaging \nreports, and the generation of scholarly articles. However, \nrecent years have witnessed an uptrend in the utilization of \nimaging diagnostic modalities across numerous countries. \nThe ensuing amplification in image interpretation and \nreporting duties has precipitated concerns surrounding \nburnout among radiologists [42]. Despite the aforementioned \nlimitations, LLMs hold promise as potential adjunctive tools \nto ameliorate the burden associated with such radiological \nendeavors.\nThe accelerated development and refinement of LLMs \nsuch as ChatGPT have catalyzed a notable performance \nin medical examinations. For instance, an evaluation of \nChatGPT on the United States Medical Licensing Exam \nFig. 2  Various Language Processing with Large Language Model. \nExamples of a computation, b conversation, and c translation, respec-\ntively. All of these different language processing tasks can be accom-\nplished using the same process: converting input data into a matrix \nusing a tokenizer, transforming it into another matrix using a Large \nLanguage Model, and then converting it back into output data\n◂\n690 Japanese Journal of Radiology (2024) 42:685–696\n(USMLE) revealed that it performed at or near the passing \nthreshold across all three exams without any specialized \ntraining or reinforcement [40]. Moreover, in a radiology \nboard-style examination, ChatGPT nearly met the passing \ncriteria without specific radiology pre-training, while a \nGPT-4 demonstrated superior performance compared to \nGPT-3.5, indicating a significant advancement in model \ncapability [43]. ChatGPT based on GPT-4 scored 65% when \nanswering Japanese questions from the Japan Radiology \nBoard Examination (JRBE) [44]. Another study evaluated \nChatGPT's performance on the Polish specialty exam in \nradiology and diagnostic imaging. Although ChatGPT \ndid not reach the passing threshold of 52%, it came close \nin certain question categories [ 45]. Although the precise \nperformance of LLMs may exhibit variance based on \nlanguage [46], these facts suggest that LLMs may be able \nto play a supplementary role even in quite specialized \nradiology work, even if only for text data at this point.\nGiven the demonstrated capabilities of LLMs, there exists \na potential to significantly enhance radiological workflow. \nThis enhancement may manifest through proficient \nsummarization of medical records, streamlined diagnostic \nimaging studies, clinical decision-making, rewriting, and \ngeneration of radiology reports [47, 48]. For instance, while \nnot a general-purpose LLM akin to GPT-4, an LLM trained \nspecifically on medical data, known as PubMedBERT [49], \nhas been reported to accurately predict mortality within 24 h \nof admission for patients in intensive care units using solely \nmedical record data [50]. This demonstrates the capacity of \nLLMs to adeptly handle and derive meaningful insights from \ntextual data such as medical records, extending promise \nfor their application in critical care settings. Additionally, \nThere is a preliminary study that helps to automatically \ndetermine imaging studies and protocols based on the \nradiology department's request form [51]. Another paper \ndemonstrates that the DL-based NLP model can accurately \nclassify the status of bone metastasis in Japanese radiology \nreports, providing a potential tool for the early and efficient \ndetection of patients with bone metastasis. [52] Given such \ncapabilities, it is conceivable that soon, LLMs could semi-\nautomatically configure protocols for imaging examinations \nsuch as CT or MRI, based on the information extracted from \nexamination request forms, medical chart data, and other \ndiagnostic data.\nFurthermore, there are several reports of rewriting \nradiology reports written by radiologists using LLM. \nThe utility of structured reporting in radiology has been \nacknowledged, yet it has also been reported that LLMs \ncan rewrite free-style reports into structured reports [53]. \nThis not only holds promise for daily clinical practice but \nalso for the education of radiology residents. Additionally, \nwhile the interpretation of radiology reports necessitates \nspecialized knowledge, it has been reported that LLMs \nare capable of translating these specialized reports into \nmore comprehensible language for a general patient [54]. \nThis potential application anticipates aiding in patient \ncommunication and comprehension, further extending \nthe scope of LLMs in enhancing patient-centered care in \nradiology.\nReport generation assistance through LLMs\nOne of the most direct applications of LLMs in reducing \nworkload within the clinical setting could arguably be in \nassisting with the generation of imaging diagnostic reports \nthemselves. While there have been numerous reports on \nthis subject from earlier times [55– 57], the advent of the \nGPT series has marked a notable advancement. It has been \nreported that LLMs can autonomously generate human-\nlike radiology reports from merely brief keywords, and \nthe differential diagnoses provided are relatively reliable \n[58]. This suggests a significant potential for augmenting \nthe efficiency and accuracy of report generation, a critical \ncomponent of the radiological workflow.\nThe approach delineated in this paper [58] for aiding \nthe generation of radiology reports hinges solely on \nthe utilization of ChatGPT, obviating the need for any \nspecialized training and hence, rendering it a reproducible \nFig. 3  Schema of Scaling Law. The performance of the Transformer \nfollows a simple power law, where the parameters, dataset size and \ncomputational resources are considered as variables. For instance, if \nthe other two variables are not the bottleneck, doubling the number \nof parameters results in a performance improvement by a power of 2. \n(Graphs are plotted on logarithmic scales)\n691Japanese Journal of Radiology (2024) 42:685–696 \nmethodology accessible to all. The requisite inputs for this \nprocess are limited to basic demographic data such as age \nand gender, keywords embodying the imaging findings, \nand a prompt tailored for report generation. However, it is \nnoteworthy that the prompt necessitates customization for \nimaging report generation; the prompt utilized in this paper \nfollows a structured format aimed at aiding the generation \nof radiology reports using ChatGPT. This structure \nencompasses three pivotal components: (1) establishing the \nrole of the LLM as a radiology specialist, (2) specifying \nthe output sections (Findings, Impression, Differential \nDiagnosis), and (3) elaborating on the content for each \nof these sections. This structured approach is predicated \non previously reported guidelines for radiology reporting \n[59], thereby adhering to the established norms within the \nradiological community.\nFigure 4 shows the simplified prompt for generating radi-\nology reports and usage examples. The prompt used in this \nreview is as follows: “As a radiologist, create a radiology \nreport following the given format. Include up to 5 differen-\ntial diagnoses based on the information provided. Findings: \nDescribe the factual observations from the imaging study \nusing precise technical language. This sets the groundwork \nfor the diagnosis. Impression: Summarize the meaning \nof the findings to arrive at a diagnosis or list of possible \ndiagnoses. Give recommendations for the next steps, using \nclear language. Differential Diagnosis: List up to 5 possi-\nble diagnoses without describing the diseases, ranked by \nlevel of suspicion.” By typing simple keywords followed by \na prompt like this on OpenAI's ChatGPT site (https:// chat.  \nopenai. com/), anyone can generate something like a radiol-\nogy report without any additional training.\nHowever, there are inherent challenges that must be \naddressed to ensure the safe and effective deployment \nof LLMs in this context. One such challenge is the \nphenomenon of hallucination, where the model generates \nincorrect or misleading information. This aspect necessitates \na cautious approach to employing LLMs for diagnostic \nreporting. The potential for hallucinations to misguide \nclinical interpretations underscores the importance of having \nappropriate regulatory frameworks in place to mitigate risks \nassociated with the use of LLMs in clinical settings.\nMoreover, the legal and ethical frameworks surrounding \nthe application of LLMs for diagnostic reporting need to \nbe robustly established. As described above, today, even \nthose without a background in diagnostic radiology can \neasily generate a large number of reports that are difficult \nto distinguish from diagnostic reports using LLMs. This \nhas significant implications for the medical field. Given the \npotential for misinterpretation or misuse of these reports, \nit is crucial that regulations are put in place to ensure that \nonly qualified professionals are authorized to interpret and \napply these findings. Ensuring the responsible use of LLMs \nwhile maximizing their potential to reduce the workload and \nimprove the accuracy and efficiency of diagnostic reporting \nrequires a balanced approach. The evolution of legal and \nprofessional guidelines, in tandem with technological \nadvancements, is imperative to foster a conducive \nenvironment for the integration of LLMs in radiological \npractice, ensuring both patient safety and enhanced clinical \nworkflow.\nPotential of LLMs in research work\nThe advent of LLMs like ChatGPT might also bring \nforth a promising avenue for alleviating the burgeoning \nworkload in radiological research. It has been reported \nthat LLM’s text generation capability has reached a level \nclose to that of humans in the research field [60]. In this \nstudy, researchers asked a chatbot to generate 50 medical \nresearch abstracts based on excerpts published in JAMA, \nThe New England Journal of Medicine, BMJ, The Lancet, \nand Nature Medicine. They then compared these generated \nabstracts with the original ones and asked a group of medical \nresearchers to identify any fabricated abstracts. Scientists \nfared a correct identification rate of 68% for generated \nabstracts and 86% for genuine ones; however, they also \nmade mistakes, incorrectly classifying 32% of the generated \nabstracts as genuine and 14% of the genuine abstracts as \ngenerated. An emblematic instance is that a pre-peer review \nversion of the paper evaluating ChatGPT's performance at \nUSMLE added ChatGPT to the authors [40]. Furthermore, \nLLMs can serve as invaluable adjuncts in review processes, \nassisting researchers and reviewers in tasks such as text \nsummarization, extraction, and past literature retrieval. This \nassistance could be particularly beneficial for non-native \nauthors, facilitating a smoother and more coherent review \nprocess [61].\nOn the contrary, a very recent pre-peer review paper \nexamines the possibility of replacing the entire peer review \nprocess with LLM [62]. In this study, authors compared the \nfeedback generated by GPT-4 and human peer reviewers, \nit was found that the overlap rate of points identified by \nGPT-4 and human reviewers was 30.85% on average in the \nNature journal and 39.23% in the International Conference \non Learning Representations (ICLR) conference. These rates \nwere comparable to the overlap rate between two human \nreviewers, which averaged 28.58% in the Nature journal and \n35.25% in the ICLR conference. Overall, 57.4% of users \nevaluated the feedback from GPT-4 as useful or very useful, \nand 82.4% felt that the feedback from GPT-4 was more \nbeneficial than at least some of the feedback from human \nreviewers.\nHowever, the integration of LLMs into the scholarly \nlandscape is not devoid of ethical and procedural \n692 Japanese Journal of Radiology (2024) 42:685–696\nFig. 4  Example of Radiology Report Generated by GPT-4. a Prompts and b Corresponding generated reports. Providing specific instructions on \nthe desired role, format, and content of output items within the prompts can enhance the quality of GPT-4 output\n693Japanese Journal of Radiology (2024) 42:685–696 \nconsiderations. One primary concern pertains to authorship, \nas LLMs, lacking the capacity for responsibility, cannot \nbe listed as authors despite their substantial contribution \nto manuscript creation [63, 64]. Most academic papers’ \nsubmission guidelines have acknowledged this concern \nby mandating a detailed disclosure if LLMs are employed \nin the manuscript preparation, ensuring a transparent \nacknowledgment of LLM assistance. Moreover, a cautious \napproach towards the utilization of LLMs in review \nprocesses is advocated to mitigate risks associated with \nconfidentiality and other potential malfeasances. While there \nhas been a paucity of guidelines on the prudent use of LLMs \nin reviews, the recently published guidelines by Radiology \n[65] underline the importance of cautious employment, with \na particular emphasis on maintaining confidentiality. This \nprudent approach towards LLM utilization not only fortifies \nthe integrity of the review process but also sets a precedent \nfor fostering responsible AI integration in radiological \nresearch.\nFuture outlook of LLMs in radiology\nLLM is currently evolving rapidly, and multimodal \ntechnology seems to be one of the most notable and relevant \nin the field of radiology. Like LLM, this technology is based \non transformer architecture, but it can also handle image \ndata in a unified manner. Microsoft's Bing AI is currently \ncompatible with this multimodal technology and is also \navailable to paid users of Open AI’s GPT-4. Currently, the \nmain reports revolve around annotations of images and \nvideos. However, there is also mention of the potential of AI \ntrained on medical data [66]. The integration of multimodal \ntechnology into LLM, or AI in medical imaging, might bring \na new dimension to radiology. According to prior research, \nthe integration of multimodal technology has the potential \nto revolutionize the precision of image diagnosis in the field \nof diagnostic radiology [67]. Moreover, its implementation \ncould substantially reduce the time required for image \nanalysis. However, given that, as with research work, LLMs \nare not responsible and may produce reports that seem \nauthoritative with a completely different meaning through \nhallucinations, etc., and given that multimodal technology \nis prepared to be used by people with no knowledge of the \nradiology field, it Given that multimodal technology may \nprepare people with no knowledge of radiology to use it, \nlegal development and guidelines might be needed for the \napplication of this technology in radiology.\nAnother very promising outcome is the mitigation of \nLLM hallucinations. One way to overcome hallucinations \nin LLMs is by improving the training data. The quality and \ndiversity of the training data play a significant role in the \nperformance of these models. There have been reports on \nLLMs specific to the medical side, and if these models are \ndeveloped, hallucination could be significantly reduced. \nAnother method is to combine with search. The integration \nof search into LLMs can help in reducing the frequency of \nhallucinations by recognizing and rectifying incorrect or \nnonsensical generated text. The third approach is to refine \nthe model architecture and learning methods of the neural \nnetwork. Recent literature has reported the potential for \nsignificantly improved performance over existing LLMs \nby combining conventional neural network methods with \nmeta-learning for compositionality [68]. For instance, it \nhas the potential to operate efficiently even when faced \nwith unfamiliar words or concepts, thereby substantially \nminimizing the requisite volume of learning data. It is \nanticipated that such advancements will persistently \nemerge in the future.\nAs the development of LLMs is expected to advance \nfurther, it is also anticipated that the potential risks \nassociated with this will increase. As mentioned earlier, \nexamples such as radiology report generation, scientific \nreview, and medical consultation on social media, there \nis a possibility that LLMs will be used not as copilots, \nbut as almost independent agents for some purposes, and \nin extreme cases, it cannot be denied that even those who \nhave no knowledge of radiology or medicine may provide \nservices. However, there is no method to completely \nsolve the problems of LLMs such as hallucinations and \nbiases at present. In addition, LLMs implicitly memorize \nthe information contained in the training data, and there \nis a possibility that personal information or medical \ninformation may be included in the generated text. \nEven if LLMs develop, their output may be inaccurate \nor inappropriate and may affect the health and safety of \npatients. Developers and users of LLMs in radiology work \nshould use them with a correct understanding of their \ncapabilities and limitations, and checking the output of \nLLMs by radiologists will continue to be essential in the \nfuture.\nLLMs have the potential to bring innovation to the \nmedical field, but on the other hand, they also have \nthe potential to bring crisis to the medical field. The \ndevelopment and application of LLMs to the medical field \nshould be done carefully and responsibly, but at present, \nthe rapid development of technology has not caught up \nwith the establishment of guidelines and laws for the use \nof LLMs in radiology work. As guidelines and submission \nrules have been changed for the paper submission and \nthe scientific review, similar preparations are urgently \nneeded for daily radiology work considering the future \ndevelopment of LLMs.\n694 Japanese Journal of Radiology (2024) 42:685–696\nConclusion\nAs LLM continues to mature and evolve, its incorporation \ninto diagnostic radiology harbors immense potential for \nadvancing this field. However, the speed at which technology \nhas developed has outpaced the establishment of consensus, \nguidelines, and legislation for LLM use. Currently, LLM \nmodels serve a “copilot” role, but shortly, they will gain \nthe ability to function as an autonomous “agent”. as \ndemonstrated by tasks such as report generation and paper \nreview mentioned earlier. Nevertheless, this advancement \nencompasses an array of potential pitfalls concerning \nmedical safety and ethics. A thorough understanding of LLM \nby radiologists and collaboration with experts is crucial for \nsuccessfully integrating LLM into radiology.\nAcknowledgements We used the DeepL and GPT-4 for Japanese-\nEnglish translation and English proofreading. The generated text was \nread, revised, and proofed by the authors.\nFunding No funding.\nDeclarations \nConflict of interest No conflicts of interest statement.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\nReferences\n 1. Nakaura T, Higaki T, Awai K, Ikeda O, Yamashita Y. A primer \nfor understanding radiology articles about machine learning and \ndeep learning. Diagn Interv Imaging. 2020;101:765–70.\n 2. Williams RJ, Zipser D. A learning algorithm for continu-\nally running fully recurrent neural networks. Neural Comput. \n1989;1:270–80.\n 3. Lu L, Wang X, Carneiro G, Yang L. Deep learning and convolu-\ntional neural networks for medical imaging and clinical informat-\nics. Cham: Springer Nature; 2019.\n 4. Higaki T, Nakamura Y, Tatsugami F, Nakaura T, Awai K. \nImprovement of image quality at CT and MRI using deep learn-\ning. Jpn J Radiol. 2019;37:73–80.\n 5. Ozaki J, Fujioka T, Yamaga E, Hayashi A, Kujiraoka Y, Imokawa \nT, et al. Deep learning method with a convolutional neural network \nfor image classification of normal and metastatic axillary lymph \nnodes on breast ultrasonography. Jpn J Radiol. 2022;40:814–22.\n 6. Ishihara M, Shiiba M, Maruno H, Kato M, Ohmoto-Sekine Y, \nAntoine C, et al. Detection of intracranial aneurysms using deep \nlearning-based CAD system: usefulness of the scores of CNN’s \nfinal layer for distinguishing between aneurysm and infundibular \ndilatation. Jpn J Radiol. 2023;41:131–41.\n 7. Koretsune Y, Sone M, Sugawara S, Wakatsuki Y, Ishihara T, Hat-\ntori C, et al. Validation of a convolutional neural network for the \nautomated creation of curved planar reconstruction images along \nthe main pancreatic duct. Jpn J Radiol. 2023;41:228–34.\n 8. Kitahara H, Nagatani Y, Otani H, Nakayama R, Kida Y, Sonoda \nA, et al. A novel strategy to develop deep learning for image \nsuper-resolution using original ultra-high-resolution computed \ntomography images of lung as training dataset. Jpn J Radiol. \n2022;40:38–47.\n 9. Nai Y-H, Loi HY, O’Doherty S, Tan TH, Reilhac A. Compari-\nson of the performances of machine learning and deep learning \nin improving the quality of low dose lung cancer PET images. \nJpn J Radiol. 2022;40:1290–9.\n 10. Yasaka K, Akai H, Sugawara H, Tajima T, Akahane M, Yosh-\nioka N, et al. Impact of deep learning reconstruction on intrac-\nranial 1.5 T magnetic resonance angiography. Jpn J Radiol. \n2022;40:476–83.\n 11. Kaga T, Noda Y, Mori T, Kawai N, Miyoshi T, Hyodo F, et al. \nUnenhanced abdominal low-dose CT reconstructed with deep \nlearning-based image reconstruction: image quality and ana-\ntomical structure depiction. Jpn J Radiol. 2022;40:703–11.\n 12. Hosoi R, Yasaka K, Mizuki M, Yamaguchi H, Miyo R, Hamada \nA, et al. Deep learning reconstruction with single-energy metal \nartifact reduction in pelvic computed tomography for patients \nwith metal hip prostheses. Jpn J Radiol. 2023;41:863–71.\n 13. Hamabuchi N, Ohno Y, Kimata H, Ito Y, Fujii K, Akino N, et al. \nEffectiveness of deep learning reconstruction on standard to \nultra-low-dose high-definition chest CT images [Internet]. Jpn \nJ Radiol. 2023. https:// doi. org/ 10. 1007/ s11604- 023- 01470-7.\n 14. Uematsu T, Nakashima K, Harada TL, Nasu H, Igarashi T. Com-\nparisons between artificial intelligence computer-aided detec -\ntion synthesized mammograms and digital mammograms when \nused alone and in combination with tomosynthesis images in a \nvirtual screening setting. Jpn J Radiol. 2022;41:63–70.\n 15. Oshima S, Fushimi Y, Miyake KK, Nakajima S, Sakata A, \nOkuchi S, et al. Denoising approach with deep learning-based \nreconstruction for neuromelanin-sensitive MRI: image quality \nand diagnostic performance. Jpn J Radiol. 2023;41:1216–25.\n 16. Nakao T, Hanaoka S, Nomura Y, Hayashi N, Abe O. Anomaly \ndetection in chest 18F-FDG PET/CT by Bayesian deep learning. \nJpn J Radiol. 2022;40:730–9.\n 17. Toda N, Hashimoto M, Iwabuchi Y, Nagasaka M, Takeshita R, \nYamada M, et al. Validation of deep learning-based computer-\naided detection software use for interpretation of pulmonary \nabnormalities on chest radiographs and examination of factors \nthat influence readers’ performance and final diagnosis. Jpn J \nRadiol. 2023;41:38–44.\n 18. Azuma M, Nakada H, Takei M, Nakamura K, Katsuragawa S, \nShinkawa N, et al. Detection of acute rib fractures on CT images \nwith convolutional neural networks: effect of location and type \nof fracture and reader’s experience. Emerg Radiol [Internet]. \n2022. Accessed 3 Nov 2023;29. Available from: https:// pubmed. \nncbi. nlm. nih. gov/ 34855 002/\n 19. Goto M, Sakai K, Toyama Y, Nakai Y, Yamada K. Use of a deep \nlearning algorithm for non-mass enhancement on breast MRI: \ncomparison with radiologists’ interpretations at various levels. \nJpn J Radiol. 2023;41:1094–103.\n 20. Chen J, Li K, Peng X, Li L, Yang H, Huang L, et al. A transfer \nlearning approach for staging diagnosis of anterior cruciate liga-\nment injury on a new modified MR dual precision positioning \n695Japanese Journal of Radiology (2024) 42:685–696 \nof thin-slice oblique sagittal FS-PDWI sequence. Jpn J Radiol. \n2023;41:637–47.\n 21. Liu Z, Liu Y, Zhang W, Hong Y, Meng J, Wang J, et al. Deep \nlearning for prediction of hepatocellular carcinoma recurrence \nafter resection or liver transplantation: a discovery and valida-\ntion study. Hepatol Int. 2022;16:577.\n 22. Zeng GL. A deep-network piecewise linear approximation for -\nmula. IEEE Access. 2021;9:120665–74.\n 23. Hochreiter S, Schmidhuber J. Long short-term memory. Neural \nComput. 1997;9:1735–80.\n 24. Peng B, Alcaide E, Anthony Q, Albalak A, Arcadinho S, Cao H, \net al. RWKV: reinventing RNNs for the transformer era [Inter -\nnet]. 2023. Accessed 31 Oct 2023] Available from: http:// arxiv. \norg/ abs/ 2305. 13048.\n 25. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P, \net al. Language Models are Few-Shot Learners [Internet]. 2020 \n[Accessed 31 Oct 2023]. Available from: http:// arxiv. org/ abs/  \n2005. 14165.\n 26. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez \nAN, et al. Attention is all you need [Internet]. 2017 [Accessed 31 \nOct 2023]. Available from: http:// arxiv. org/ abs/ 1706. 03762.\n 27. Jain SM. Introduction to transformers for NLP: with the hugging \nface library and models to solve problems. Apress; 2022\n 28. Ross Gruetzemacher Wichita State University, W. Frank Barton \nSchool of Business, David Paradice Auburn University, Harbert \nCollege of Business. Deep transfer learning & beyond: trans-\nformer language models in information systems research. ACM \nComput Surv (CSUR). 2022. https:// doi. org/ 10. 1145/ 35052 45.\n 29. Improving language understanding with unsupervised learning \n[Internet]. Accessed 31 Oct 2023. Available from: https:// openai. \ncom/ resea rch/ langu age- unsup ervis ed\n 30. Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. \nLanguage Models are unsupervised multitask learners. 2019. \nAccessed 31 Oct 2023. Available from: https:// www. seman ticsc \nholar. org/ paper/ Langu age- Models- are- Unsup ervis ed- Multi task- \nLearn ers- Radfo rd- Wu/ 9405c c0d61 69988 371b2 755e5 73cc2 8650d \n14dfe\n 31. Devlin J, Chang M-W, Lee K, Toutanova K. BERT: Pre-training \nof Deep Bidirectional Transformers for Language Understanding \n[Internet]. 2018 [Accessed 31 Oct 2023]. Available from: http://  \narxiv. org/ abs/ 1810. 04805\n 32. Agrawal A, Suzgun M, Mackey L, Kalai AT. Do language mod-\nels know when they’re hallucinating references? [Internet]. 2023. \nAccessed 31 Oct 2023. Available from: http:// arxiv. org/ abs/ 2305. \n18248\n 33. Athaluri SA, Manthena SV, Kesapragada VSRKM, Yarlagadda V, \nDave T, Duddumpudi RTS. Exploring the boundaries of reality: \ninvestigating the phenomenon of artificial intelligence hallucina-\ntion in scientific writing through ChatGPT references. Cureus. \n2023;15:e37432.\n 34. McKenna N, Li T, Cheng L, Hosseini MJ, Johnson M, Steedman \nM. Sources of Hallucination by Large Language Models on Infer-\nence Tasks [Internet]. 2023 [Accessed 31 Oct 2023]. Available \nfrom: http:// arxiv. org/ abs/ 2305. 14552\n 35. Azamfirei R, Kudchadkar SR, Fackler J. Large language models \nand the perils of their hallucinations. Crit Care. 2023;27:120.\n 36. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan \nTF, Ting DSW. Large language models in medicine. Nat Med. \n2023;29:1930–40.\n 37. Battaglia PW, Hamrick JB, Bapst V, Sanchez-Gonzalez A, Zam-\nbaldi V, Malinowski M, et al. Relational inductive biases, deep \nlearning, and graph networks [Internet]. 2018. Accessed Oct 31 \n2023. Available from: http:// arxiv. org/ abs/ 1806. 01261\n 38. Ueda D, Kakinuma T, Fujita S, Kamagata K, Fushimi Y, Ito R, \net al. Fairness of artificial intelligence in healthcare: review and \nrecommendations. Jpn J Radiol. 2023;42:1–13.\n 39. Stiennon N, Ouyang L, Wu J, Ziegler DM, Lowe R, Voss C, et al. \nLearning to summarize from human feedback [Internet]. 2020. \nAccessed 31 Oct 2023. Available from: http:// arxiv. org/ abs/ 2009. \n01325\n 40. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, \nElepaño C, et al. Performance of ChatGPT on USMLE: potential \nfor AI-assisted medical education using large language models. \nPLOS Digit Health. 2023;2: e0000198.\n 41. Ayers JW, Poliak A, Dredze M, Leas EC, Zhu Z, Kelley JB, et al. \nComparing physician and artificial intelligence chatbot responses \nto patient questions posted to a public social media forum. JAMA \nIntern Med. 2023;183:589–96.\n 42. Parikh JR, Wolfman D, Bender CE, Arleo E. Radiologist burn -\nout according to surveyed radiology practice leaders. J Am Coll \nRadiol. 2020;17:78–81.\n 43. Bhayana R, Krishna S, Bleakney RR. Performance of ChatGPT \non a radiology board-style examination: insights into current \nstrengths and limitations. Radiology. 2023;307: e230582.\n 44. Toyama Y, Harigai A, Abe M, Nagano M, Kawabata M, Seki Y, \net al. Performance evaluation of ChatGPT, GPT-4, and Bard on \nthe official board examination of the Japan Radiology Society. Jpn \nJ Radiol. 2023. https:// doi. org/ 10. 1007/ s11604- 023- 01491-2.\n 45. Kufel J, Paszkiewicz I, Bielówka M, Bartnikowska W, Janik M, \nStencel M, et al. Will ChatGPT pass the Polish specialty exam \nin radiology and diagnostic imaging? Insights into strengths and \nlimitations. Pol J Radiol. 2023;88:e430–4.\n 46. Seghier ML. ChatGPT: not all languages are equal. Nature. \n2023;615:216.\n 47. Akinci D’ Antonoli T, Stanzione A, Bluethgen C, Vernuccio F, \nUgga L, Klontzas ME, et al. Large language models in radiol-\nogy: fundamentals, applications, ethical considerations, risks, and \nfuture directions. Diagn Interv Radiol. 2023. https:// doi. org/ 10. \n4274/ dir. 2023. 232417.\n 48. López-Úbeda P, Martín-Noguerol T, Juluru K, Luna A. Natural \nlanguage processing in radiology: update on clinical applications. \nJ Am Coll Radiol. 2022;19:1271–85.\n 49. Tinn R, Cheng H, Gu Y, Usuyama N, Liu X, Naumann T, et al. \nFine-tuning large neural language models for biomedical natural \nlanguage processing. Patterns (N Y). 2023;4: 100729.\n 50. Mahbub M, Srinivasan S, Danciu I, Peluso A, Begoli E, Tamang \nS, et al. Unstructured clinical notes within the 24 hours since \nadmission predict short, mid & long-term mortality in adult ICU \npatients. PLoS ONE. 2022;17: e0262182.\n 51. Gertz RJ, Bunck AC, Lennartz S, Dratsch T, Iuga A-I, Maintz D, \net al. GPT-4 for automated determination of radiological study \nand protocol based on radiology request forms: a feasibility study. \nRadiology. 2023;307: e230877.\n 52. Doi K, Takegawa H, Yui M, Anetai Y, Koike Y, Nakamura S, et al. \nDeep learning-based detection of patients with bone metastasis \nfrom Japanese radiology reports. Jpn J Radiol. 2023;41:900–8.\n 53. Adams LC, Truhn D, Busch F, Kader A, Niehues SM, Makowski \nMR, et al. Leveraging GPT-4 for post hoc transformation of free-\ntext radiology reports into structured reporting: a multilingual \nfeasibility study. Radiology. 2023;307: e230725.\n 54. Lyu Q, Tan J, Zapadka ME, Ponnatapura J, Niu C, Myers KJ, et al. \nTranslating radiology reports into plain language using ChatGPT \nand GPT-4 with prompt learning: results, limitations, and poten-\ntial. Vis Comput Ind Biomed Art. 2023;6:9.\n 55. Wang X, Peng Y, Lu L, Lu Z, Summers RM. TieNet: Text-image \nembedding network for common thorax disease classification \nand reporting in chest X-rays. 2018 IEEE/CVF conference on \ncomputer vision and pattern recognition [Internet]. IEEE; 2018 \n696 Japanese Journal of Radiology (2024) 42:685–696\n[Accessed 26 Oct 2023]. Available from: https:// ieeex plore. ieee. \norg/ docum ent/ 85790 41/.\n 56. Alfarghaly O, Khaled R, Elkorany A, Helal M, Fahmy A. Auto-\nmated radiology report generation using conditioned transformers. \nInform Med Unlocked. 2021;24: 100557.\n 57. Sirshar M, Paracha MFK, Akram MU, Alghamdi NS, Zaidi SZY, \nFatima T. Attention based automated radiology report generation \nusing CNN and LSTM. PLoS ONE. 2022;17: e0262209.\n 58. Nakaura T, Yoshida N, Kobayashi N, Shiraishi K, Nagayama Y, \nUetani H, et al. Preliminary assessment of automated radiology \nreport generation with generative pre-trained transformers: com-\nparing results to radiologist-generated reports. Jpn J Radiol. 2023. \nhttps:// doi. org/ 10. 1007/ s11604- 023- 01487-y.\n 59. Hartung MP, Bickle IC, Gaillard F, Kanne JP. How to create a \ngreat radiology report. Radiographics. 2020;40:1658–70.\n 60. Else H. Abstracts written by ChatGPT fool scientists. Nature. \n2023;613:423–423.\n 61. Hwang SI, Lim JS, Lee RW, Matsui Y, Iguchi T, Hiraki T, et al. Is \nChatGPT a “Fire of prometheus” for non-native english-speaking \nresearchers in academic writing? Korean J Radiol. 2023;24:952–9.\n 62. Liang W, Zhang Y, Cao H, Wang B, Ding D, Yang X, et al. \nCan large language models provide useful feedback on research \npapers? A large-scale empirical analysis [Internet]. arXiv.org. \n2023. Accessed 27 Oct 2023. Available from: https:// arxiv. org/  \npdf/ 2310. 01783. pdf\n 63. Stokel-Walker C. ChatGPT listed as author on research papers: \nmany scientists disapprove. Nature. 2023. https:// doi. org/ 10. 1038/ \nd41586- 023- 00107-z.\n 64. Thorp HH. ChatGPT is fun, but not an author. Science. \n2023;379:313.\n 65. Moy L. Guidelines for use of large language models by authors, \nreviewers, and editors: considerations for imaging journals. Radi-\nology. 2023;309: e239024.\n 66. Tu T, Azizi S, Driess D, Schaekermann M, Amin M, Chang \nP-C, et al. Towards generalist Biomedical AI [Internet]. 2023. \nAccessed 30 Oct 2023. Available from: http:// arxiv. org/ abs/ 2307. \n14334\n 67. Khader F, Müller-Franzes G, Wang T, Han T, Tayebi Arasteh \nS, Haarburger C, et al. Multimodal deep learning for integrating \nchest radiographs and clinical parameters: a case for transformers. \nRadiology. 2023;309: e230806.\n 68. Lake BM, Baroni M. Human-like systematic generalization \nthrough a meta-learning neural network. Nature. 2023. https://  \ndoi. org/ 10. 1038/ s41586- 023- 06668-3.\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Workflow",
  "concepts": [
    {
      "name": "Workflow",
      "score": 0.59389728307724
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.4677177965641022
    },
    {
      "name": "Medicine",
      "score": 0.43927255272865295
    },
    {
      "name": "Computer science",
      "score": 0.34735873341560364
    },
    {
      "name": "Engineering ethics",
      "score": 0.34636467695236206
    },
    {
      "name": "Engineering",
      "score": 0.2004764974117279
    },
    {
      "name": "Artificial intelligence",
      "score": 0.1687702238559723
    },
    {
      "name": "Database",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210122547",
      "name": "Kumamoto University Hospital",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I60134161",
      "name": "Nagoya University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4387152983",
      "name": "Osaka Metropolitan University",
      "country": null
    },
    {
      "id": "https://openalex.org/I203951103",
      "name": "Keio University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I22299242",
      "name": "Kyoto University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I163770644",
      "name": "Okayama University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I98285908",
      "name": "The University of Osaka",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I137975476",
      "name": "Shinshu University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I4210141669",
      "name": "Hokkaido University Hospital",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I113306721",
      "name": "Hiroshima University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I205349734",
      "name": "Hokkaido University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I74801974",
      "name": "The University of Tokyo",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I34077901",
      "name": "Juntendo University",
      "country": "JP"
    },
    {
      "id": "https://openalex.org/I125602781",
      "name": "Tokyo Medical and Dental University",
      "country": "JP"
    }
  ],
  "cited_by": 70
}