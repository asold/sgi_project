{
  "title": "LM-Debugger: An Interactive Tool for Inspection and Intervention in Transformer-Based Language Models",
  "url": "https://openalex.org/W4385573190",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2736090994",
      "name": "Mor Geva",
      "affiliations": [
        "Allen Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2990253534",
      "name": "Avi Caciularu",
      "affiliations": [
        "Bar-Ilan University"
      ]
    },
    {
      "id": "https://openalex.org/A3168733083",
      "name": "Guy Dar",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2989014767",
      "name": "Paul Roit",
      "affiliations": [
        "Bar-Ilan University"
      ]
    },
    {
      "id": "https://openalex.org/A2916480442",
      "name": "Shoval Sadde",
      "affiliations": [
        "Allen Institute"
      ]
    },
    {
      "id": "https://openalex.org/A3033943473",
      "name": "Micah Shlain",
      "affiliations": [
        "Allen Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2989725652",
      "name": "Bar Tamir",
      "affiliations": [
        "Hebrew University of Jerusalem"
      ]
    },
    {
      "id": "https://openalex.org/A2144962531",
      "name": "Yoav Goldberg",
      "affiliations": [
        "Bar-Ilan University",
        "Allen Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3038035611",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3176390156",
    "https://openalex.org/W4298197157",
    "https://openalex.org/W3211653317",
    "https://openalex.org/W2972498556",
    "https://openalex.org/W3035507081",
    "https://openalex.org/W3037116584",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W3086249591",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4301194718",
    "https://openalex.org/W4288000060",
    "https://openalex.org/W4225896729",
    "https://openalex.org/W2970863760",
    "https://openalex.org/W2909212904",
    "https://openalex.org/W3101662419",
    "https://openalex.org/W4226251122",
    "https://openalex.org/W3100355250",
    "https://openalex.org/W2982756474",
    "https://openalex.org/W4385572928",
    "https://openalex.org/W2966280323"
  ],
  "abstract": "Mor Geva, Avi Caciularu, Guy Dar, Paul Roit, Shoval Sadde, Micah Shlain, Bar Tamir, Yoav Goldberg. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 2022.",
  "full_text": "Proceedings of the The 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 12 - 21\nDecember 7-11, 2022c⃝2022 Association for Computational Linguistics\nLM-Debugger: An Interactive Tool for\nInspection and Intervention in Transformer-Based Language Models\nMor Geva1 Avi Caciularu2,∗ Guy Dar3 Paul Roit2 Shoval Sadde1\nMicah Shlain1 Bar Tamir4 Yoav Goldberg1,2\n1Allen Institute for AI 2Bar-Ilan University\n3Tel Aviv University 4The Hebrew University of Jerusalem\nmorp@allenai.org\nAbstract\nThe opaque nature and unexplained behavior\nof transformer-based language models (LMs)\nhave spurred a wide interest in interpreting\ntheir predictions. However, current interpre-\ntation methods mostly focus on probing mod-\nels from outside, executing behavioral tests,\nand analyzing salience input features, while\nthe internal prediction construction process is\nlargely not understood. In this work, we in-\ntroduce LM-Debugger, an interactive debug-\nger tool for transformer-based LMs, which\nprovides a fine-grained interpretation of the\nmodel’s internal prediction process, as well as\na powerful framework for intervening in LM\nbehavior. For its backbone, LM-Debugger re-\nlies on a recent method that interprets the inner\ntoken representations and their updates by the\nfeed-forward layers in the vocabulary space.\nWe demonstrate the utility of LM-Debugger for\nsingle-prediction debugging, by inspecting the\ninternal disambiguation process done byGPT2 .\nMoreover, we show how easily LM-Debugger\nallows to shift model behavior in a direction\nof the user’s choice, by identifying a few vec-\ntors in the network and inducing effective in-\nterventions to the prediction process. We re-\nlease LM-Debugger as an open-source tool and\na demo over GPT2 models.\n1 Introduction\nTransformer-based language models (LMs) are the\nbackbone of modern NLP models (Bommasani\net al., 2021), but their internal prediction construc-\ntion process is opaque. This is problematic to end-\nusers that do not understand why the model makes\nspecific predictions, as well as for developers who\nwish to debug or fix model behaviour.\nRecent work (Elhage et al., 2021; Geva et al.,\n2022) suggested that the construction process of\nLM predictions can be viewed as a sequence of\nupdates to the token representation. Specifically,\n∗ Work done during an internship at AI2.\nShe is working as  a\nDJ\nkindergarten, \nschool, kids, \nelementary, \nteacher, \nclassroom\nlawyer\nnurse\ndentist\nnanny\nDJ\nsinger\nlawyer\nrapper\nFFN\nFFN\nFFN\nalbum, DJ, \nrapper, funk, \nmusic, song, \nvocals, punk, \ndisco, rock, …\ninspection\nintervention\nprojections\nFigure 1: Illustration of the main capabilities of\nLM-Debugger. Our tool interprets dominant changes\nin the output distribution induced by the feed-forward\nlayers across the network (self-attention layers are not\nshown), and enables configuring interventions for shift-\ning the prediction in directions of the user’s choice.\nGeva et al. (2022) showed that updates by the feed-\nforward network (FFN) layers, one of the building\nblocks of transformers (Vaswani et al., 2017), can\nbe decomposed into weighted collections of sub-\nupdates, each induced by a FFN parameter vector,\nthat can be interpreted in the vocabulary space.\nIn this work, we make a step towards LM trans-\nparency by employing this interpretation approach\nto create LM-Debugger, a powerful tool for inspec-\ntion and intervention in transformer LM predic-\ntions. LM-Debugger provides three main capabil-\nities for single-prediction debugging and model\nanalysis (illustrated in Figure 1). First, for a given\ninput (e.g. “My wife is working as a”), it interprets\nthe model’s prediction at each layer in the network,\nand the major changes applied to it by FFN layers.\nThis is done by projecting the token representa-\n12\ntion before and after the FFN update as well as the\nmajor FFN sub-updates at any layer to the output\nvocabulary. Second, it allows intervening in the\nprediction by changing the weights of specific sub-\nupdates, e.g. increasing (decreasing) a sub-update\nthat promotes music-related (teaching-related) con-\ncepts, which results in a modified output. Last, for\na given LM, LM-Debugger interprets all the FFN\nparameter vectors across the network and creates a\nsearch index over the tokens they promote. This al-\nlows an input-independent analysis of the concepts\nencoded by the model’s FFN layers, and enables\nconfiguring general and effective interventions.\nWe demonstrate the utility of LM-Debugger for\ntwo general use-cases. In the context of predic-\ntion debugging, we use the fine-grained tracing of\nLM-Debugger to inspect the internal disambigua-\ntion process performed by the model. Furthermore,\nwe demonstrate how our tool can be used to con-\nfigure a few powerful interventions that effectively\ncontrol different aspects in text generation.\nWe release LM-Debugger as an open-source tool\nat https://github.com/mega002/lm-debugger\nand host a demo of GPT2 (Brown et al., 2020)\nat https://lm-debugger.apps.allenai.org.1\nThis to increase the transparency of transformer\nLMs and facilitate research in analyzing and con-\ntrolling NLP models.\n2 Underlying Interpretation Method\nLM-Debugger establishes a framework for inter-\npreting a token’s representation and updates ap-\nplied to it at each layer in the network. This frame-\nwork builds upon recent findings by Geva et al.\n(2022), who viewed the token representation as a\nchanging distribution over the output vocabulary,\nand the output from each FFN layer as a collec-\ntion of weighted sub-updates to that distribution,\nwhich are often interpretable to humans. We next\nelaborate on the findings we rely on at this work.\nConsider a transformer LM with L layers and an\nembedding matrix E ∈Rd×|V| of hidden dimen-\nsion d, over a vocabulary V. Let w = w1, ..., wt\ns.t. ∀i = 1, ..., t: wi ∈V be an input sequence\nof tokens, then at each layer ℓ = 1, ..., L, the hid-\nden representation xℓ\ni of the i-th token is being\nprocessed and updated by a FFN layer through a\nresidual connection (He et al., 2016):2\n˜ xℓ\ni = xℓ\ni + FFNℓ(xℓ\ni),\n1See a video at https://youtu.be/5D_GiJv7O-M\n2Layer normalization is omitted (Geva et al., 2022).\nwhere xℓ\ni is the output from the preceding multi-\nhead self-attention layer, and ˜ xℓ\ni is the updated to-\nken representation (Vaswani et al., 2017). Geva\net al. (2022) proposed an interpretation method for\nthese updates in terms of the vocabulary, which\nwe employ as the backbone of LM-Debugger and\ndescribe in detail next.\nToken Representation as a Distribution Over\nthe Output Vocabulary. The token representa-\ntion before (xℓ\ni) and after (˜ xℓ\ni) the FFN update at\nany layer ℓ is interpreted by projecting it to the vo-\ncabulary space and converting it to a distribution:\npℓ\ni = softmax(Exℓ\ni) ; ˜ pℓ\ni = softmax(E˜ xℓ\ni)\nThe final model output is defined by y = ˜ pL\ni .\nThe FFN Output as a Weighted Collection of\nSub-Updates. Each FFN layer is defined with\ntwo parameter matrices Kℓ, Vℓ ∈Rdm×d, where\ndm is the intermediate hidden dimension, and a\nnon-linearity function f (bias terms are omitted):\nFFNℓ(xℓ) =f\n(\nKℓxℓ\n)\nV ℓ (1)\nGeva et al. (2022) interpreted the FFN output by (a)\ndecomposing it into sub-updates, each induced by\na single FFN parameter vector, and (b) projecting\neach sub-update to the vocabulary space. Formally,\nEq. 1 can be decomposed as:\nFFNℓ(xℓ) =\ndm∑\ni=1\nf(xℓ ·kℓ\ni)vℓ\ni =\ndm∑\ni=1\nmℓ\nivℓ\ni.\nwhere kℓ\ni is the i-th row of Kℓ, vℓ\ni is the i-th col-\numn of V ℓ, and mℓ\ni := f(xℓ ·kℓ\ni) is the activation\ncoefficient of vℓ\ni for the given input. Each term in\nthis sum is interpreted as a sub-update to the output\ndistribution, by inspecting the top-scoring tokens\nin its projection to the vocabulary, i.e. Evℓ\ni.\nIn the rest of the paper, we follow Geva et al.\n(2022) and refer to columns of V ℓ as “value vec-\ntors” and to their weighted input-dependent form\nas “sub-updates”. Importantly, value vectors are\nstatic parameter vectors that are independent on the\ninput sequence, while sub-updates are dynamic as\nthey are weighted by input-dependent coefficients.\nFor a model with L layers and a hidden dimension\ndm, there are L ∗dm static value vectors, which\ninduce L ∗dm corresponding sub-updates when\nrunning an input through the model.\n13\nFigure 2: The prediction view of LM-Debugger, showing the prediction trace for a given input (main panel), allowing\nto configure interventions (lower panel) and interpret sub-updates to the output distribution (right panel).\n3 LM-Debugger\nLM-Debugger leverages both static and dynamic\nanalysis of transformer FFN layers and the updates\nthey induce to the output distribution for debugging\nand intervention in LM predictions. These capa-\nbilities are provided in two main views, which we\ndescribe next.\n3.1 Prediction View\nThis view, shown in Figure 2, is designed for\nper-example debugging. It allows running inputs\nthrough the model to generate text in an auto-\nregressive manner, while tracing the dominant sub-\nupdates in every layer and applying interventions.\nPrediction Trace (Figure 2, main panel). The\nuser enters an input for the model, for which a de-\ntailed trace of the prediction across the network is\nprovided. For each layer, it shows the top-tokens in\nthe output distribution, before and after the FFN up-\ndate, and the 10 most dominant FFN sub-updates.\nFor every sub-update mivℓ\ni we show an identifier\nL[ℓ]D[i] of its corresponding value vector and the\ncoefficient for the given input (e.g. L17D4005 and\n9.79).3 The top distribution tokens and sub-updates\nare sorted by the token probability/sub-update co-\nefficient from left (highest) to right (lowest). A\nsmall arrow next to each sub-update allows setting\nan intervention on its corresponding value vector.\n3The layer and dimension in the identifier use zero-index.\nInterventions (Figure 2, lower panel). Beyond\ntracing the output distribution, LM-Debugger also\nallows intervening in the prediction process by set-\nting the coefficients of any vector values in the\nnetwork, thus, inducing sub-updates of the user’s\nchoice. To set an intervention for a specific value\nvector, the user should enter its identifier to the\npanel and choose whether to “turn it on or off”,\nthat is, setting its coefficient to the value of the\ncoefficient of the most dominant sub-update in that\nlayer, or to zero, respectively. When running an\ninput example, all interventions in the panel will\nbe effective, for the entire generation process.\nValue Vector Information (Figure 2, right\npanel). A natural question that arises is how to\nchoose meaningful interventions. LM-Debugger\nprovides two complementary approaches for this.\nA bottom-up approach is to observe the dominant\nsub-updates for specific examples, and apply inter-\nventions on them. A sub-update can be interpreted\nby inspecting the top-tokens in the projection of\nits corresponding value vector to the vocabulary\n(Geva et al., 2022). For convenience, we let the\nuser assign names to value vectors. Another way to\nfind meaningful interventions is by a top-down ap-\nproach of searching for value vectors that express\nconcepts of the user’s interest. We provide this\ncapability in the exploration view of LM-Debugger,\nwhich is described next.\n14\n3.2 Exploration View\nThis view allows static exploration of value vec-\ntors, primarily for analyzing which concepts are\nencoded in the FFN layers, how concepts are spread\nover different layers, and identifying groups of re-\nlated value vectors.\nKeyword Search (Figure 3). Value vectors are\ninterpreted by the top tokens they promote. By\nconsidering these sets of tokens as textual docu-\nments, LM-Debugger allows searching for concepts\nencoded in value vectors across the layers. This is\nenabled by a search index that LM-Debugger holds\nin the background, which stores the projections\nof all value vectors to the vocabulary, and allows\nexecuting simple queries against them using the\nBM25 (Robertson et al., 1995) algorithm.\nCluster Visualization (Figure 4). Assuming the\nuser is interested in locating a specific concept in\nthe network and that she has found a relevant value\nvector, either from debugging an example in the\nprediction view or by the keyword search. A nat-\nural next step is to find similar value vectors that\npromote related tokens. To this end, LM-Debugger\nprovides a clustering of all value vectors in the\nnetwork, which allows mapping any value vector\nto a cluster of similar vectors in the hidden space\n(Geva et al., 2022). The interface displays a ran-\ndom sample of vectors from the cluster, as well as\nan aggregation of their top tokens as a word cloud,\nshowing the concepts promoted by the cluster.\n4 Debugging LM Predictions by Tracing\nFFN Updates\nIn this section, we demonstrate the utility of\nLM-Debugger for interpreting model behaviour\nupon a given example. As an instructive example,\nwe will consider the case of sense disambiguation.\nWhen generating text, LMs often need to per-\nform sense disambiguation and decide on one plau-\nsible continuation. For example, the word “for”\nin the input “The book is for” has two plausible\nsenses of purpose (e.g. “reading”) and person\n(e.g. “him”) (Karidi et al., 2021). We will now in-\nspect the prediction by GPT2 (Brown et al., 2020)\nand track the internal sense disambiguation pro-\ncess for this example. To this end, we enter the\ninput in the prediction view and clickTrace, which\nprovides a full trace of the prediction across layers.\nTable 1 displays a part of this trace from selected\nlayers, showing a gradual transition from purpose\nLayer: 4 Sense: purpose\nBefore: example, the, instance, purposes\nAfter: example, the, instance, all\nLayer: 10 Sense: purpose\nBefore: the, sale, example, a\nAfter: the, sale, a, example\nLayer: 15 Sense: purpose/person\nBefore: sale, the, anyone, use\nAfter: sale, anyone, the, ages\nLayer: 20 Sense: person\nBefore: beginners, anyone, adults, sale\nAfter: anyone, beginners, adults, readers\nTable 1: Partial prediction trace of GPT2 for the input\n“This book is for”, showing the internal disambiguation\nprocess from purpose to person sense across layers.\nto person sense. Until layer 11 (out of 24), the top-\ntokens in the output distribution are mostly related\nto sale/example purposes. Starting from layer 12,\nthe prediction slowly shifts to revolve about the\naudience of the book, e.g. anyone and ages, until\nlayer 18 where sale is eliminated from the top\nposition. In the last layers, tokens become more\nspecific, e.g. beginners and adults.\nTo examine the major updates through which\nthe prediction has formed, we can click on spe-\ncific sub-updates in the trace to inspect the top-\nscoring tokens in their projections. We observe\nthat in early layers, tokens are often related to\npurpose sense (e.g. instance in L2D1855 and\nbuyers in L12D659), in intermediate layers tokens\nare a mix of both senses ( readers in L16D3026\nand preschool in L17D2454, and sale/free in\nL16D1662), and mostly person sense in the last lay-\ners (users in L18D685, people in L20D3643, and\nthose in L21D2007).\n5 Configuring Effective Interventions for\nControlled Text Generation\nBeyond interpretability, LM-Debugger enables to\nintervene in LM predictions. We show this by find-\ning value vectors that promote specific concepts\nand applying simple and effective interventions.\nControlling Occupation Prediction. Consider\nthe input “My wife is working as a” . When run-\nning it through GPT2 , the final prediction from\nthe last layer has the top tokens nurse, teacher,\nwaitress. We would like to intervene in the pre-\ndiction in order to change its focus to occupations\nrelated to software engineering, which in general\nare less associated with women (De-Arteaga et al.,\n2019). To this end, we will use the exploration\n15\nFigure 3: Keyword search in the exploration view of LM-Debugger, which matches user queries against the tokens\npromoted by value vectors of the model.\nFigure 4: Cluster visualization in the exploration view of LM-Debugger, which maps a given value vector to its\ncluster of similar value vectors in the network.\nview of LM-Debugger to search for value vectors\npromoting software-related concepts.\nSearching the keywords “software”, “devel-\noper”, and “engineer” brings up two value vectors\nwith coherent concepts: L10D3141 and L17D115\n(Figure 3). Now, we will add these value vectors\nto the intervention panel in the prediction view,\nand run the example again. Our intervention, that\nonly involved two (0.002%) vectors in the network,\ndramatically changed the prediction to software,\nprogrammer, consultant, developer , effec-\ntively shifting it in the direction we wanted. This\ndemonstrates the power of LM-Debugger to change\nmodel behaviour and fix undesirable predictions.\nControlling the Sentiment of Generated Text.\nThe previous example focused on next-token pre-\ndiction. We now take this one step further and\nconfigure powerful and general interventions that\ninfluence various texts generated by the model. For\nour experimental setting, we will attempt to control\nthe sentiment in generated reviews by GPT2 , for\ninputs taken from the Yelp dataset (Asghar, 2016).\nWe choose our interventions independently of\nthe inputs, with two easy steps. First, we use the\nkeyword search (Figure 3) to identify “seed” value\nvectors that promote positive and negative adjec-\ntives/adverbs, using the queries“terrible, mediocre,\nboring” and “spacious, superb, delicious”. Then,\nwe take one value vector for each polarity and, us-\ning the cluster visualization (Figure 4), expand it\nto a diverse set of vectors from its corresponding\ncluster, that promote similar concepts. Overall, we\nselect 5-6 value vectors for each polarity (details in\nAppendix A.1), to which we apply interventions.\nTable 2 presents the texts generated by GPT2\n(each limited to 10 tokens) for multiple inputs, with\nand without applying interventions. Clearly, across\n16\nInput Interven. Continuation\n“Service in this place is”\n- a bit of a mess. I’m not sure\n↑ Positive a good place to make the right efforts to make\n↑ Negative a waste of a bunch of crap that is too\n“I have been to this\nrestaurant twice and”\n- both times I was disappointed. The first time I\n↑ Positive have been served excellent food and good service. The\n↑ Negative have been disappointed. The food is over processed and\n“We went on a weeknight.\nPlace was”\n- packed. We had to wait for the bus\n↑ Positive good, good food, good staff, good people\n↑ Negative too far for us to get lost. We were\n“Went for breakfast on\n6/16/14. We”\n- had a great time. We had a great time\n↑ Positive have a good team of people who are able to\n↑ Negative were too heavy for the wrong type of food that\nTable 2: Continuations (limited to 10 tokens) generated by GPT2 for different inputs from the Yelp dataset, with\nand without interventions for “turning on” sub-updates for positive and negative sentiment.\nall the examples, our intervention in the prediction\nsuccessfully leads to the desired effect, turning the\nsentiment of the generated text to be positive or\nnegative, according to the configured sub-updates.\n6 Implementation Details\nThe prediction view is implemented as a React web\napplication with a backend Flask server that runs an\nAPI for executing models from the Transformers\nlibrary by HuggingFace (Wolf et al., 2020). The\nexploration view is a Streamlit web application,\nwhich (a) sends user search queries to an Elas-\nticsearch index with the top tokens of all vector\nvalue projections, and (b) visualize clusters of value\nvectors created with the scikit-learn package (Pe-\ndregosa et al., 2011). Our current implementation\nsupports any GPT2 model from HuggingFace, and\nother auto-regressive models can be plugged-in\nwith only a few local modifications (e.g. translat-\ning the relevant layer names). More details and in-\nstructions for how to deploy and run LM-Debugger\nare provided at https://github.com/mega002/\nlm-debugger.\n7 Related Work\nInterpreting single-predictions and the general be-\nhavior of LMs is a growing research area that at-\ntracted immense attention in recent years (Belinkov\net al., 2020; Choudhary et al., 2022). LM-Debugger\nis a the first tool to interpret and intervene in the pre-\ndiction construction process of transformer-based\nLMs based on FFN updates.\nExisting interpretation and analysis frameworks\nmostly rely on methods for behavioral analysis\n(Ribeiro et al., 2020) by probing models with ad-\nversarial (Wallace et al., 2019b) or counterfactual\nexamples (Tenney et al., 2020), input saliency meth-\nods that assign importance scores to input features\n(Wallace et al., 2019b; Tenney et al., 2020), and\nanalysis of the attention layers (Hoover et al., 2020;\nVig and Belinkov, 2019).\nMore related to LM-Debugger, other tools ana-\nlyze patterns in neuron activations (Rethmeier et al.,\n2020; Dalvi et al., 2019; Alammar, 2021). Unlike\nthese methods, we focus on interpreting the model\nparameters and on intervening in their contribution\nto the model’s prediction.\nThe functionality of LM-Debugger is mostly re-\nlated to tools that trace hidden representations\nacross layers. Similarly to LM-Debugger, Alammar\n(2021); Nostalgebraist (2020) interpret the token\nrepresentation in terms of the output vocabulary.\nWe take this one step further and interpret the FFN\nupdates to the representation, allowing to observe\nnot only the evolution of the representation but also\nthe factors that induce changes in it.\nOur intervention in FFN sub-updates relates to\nrecent methods for locating and editing knowledge\nin the FFN layers of LMs (Meng et al., 2022;\nDai et al., 2022). Different from these methods,\nLM-Debugger aims to provide a comprehensive\nand fine-grained interpretation of the prediction\nconstruction process across the layers.\n8 Conclusion\nWe introduce LM-Debugger, a debugger tool for\ntransformer-based LMs, and the first tool to analyze\nthe FFN updates to the token representations across\nlayers. LM-Debugger provides a fine-grained inter-\npretation of single-predictions, as well as a power-\nful framework for intervention in LM predictions.\n17\nEthical Statement\nOur work aims to increase the transparency of\ntransformer-based LMs. It is well known that such\nmodels often produce offensive, harmful language\n(Bender et al., 2021; McGuffie and Newhouse,\n2020; Gehman et al., 2020; Wallace et al., 2019a),\nwhich might originate in toxic concepts encoded in\ntheir parameters (Geva et al., 2022). LM-Debugger,\nwhich traces and interprets LM predictions, could\nexpose such toxic concepts and therefore should be\nused with caution.\nLM-Debugger also provides a framework for\nmodifying LM behavior in particular directions.\nWhile our intention is to provide developers tools\nfor fixing model errors, mitigating biases, and build-\ning trustworthy models, this capability also has the\npotential for abuse. In this context, it should be\nmade clear that LM-Debugger does not modify the\ninformation encoded in LMs, but only changes\nthe intensity in which this information is exposed\nin the model’s predictions. At the same time,\nLM-Debugger lets the user observe the intensity of\nupdates to the prediction, which could be used to\nidentify suspicious interventions. Nonetheless, be-\ncause of these concerns, we stress that LMs should\nnot be integrated into critical systems without cau-\ntion and monitoring.\nAcknowledgements\nWe thank the REVIZ team at the Allen Institute for\nAI, particularly Sam Skjonsberg and Sam Stuesser.\nThis project has received funding from the Com-\nputer Science Scholarship granted by the Séphora\nBerrebi Foundation, the PBC fellowship for out-\nstanding PhD candidates in Data Science, and the\nEuropean Research Council (ERC) under the Eu-\nropean Union’s Horizon 2020 research and inno-\nvation programme, grant agreement No. 802774\n(iEXTRACT).\nReferences\nJ Alammar. 2021. Ecco: An open source library for the\nexplainability of transformer language models. In\nProceedings of the 59th Annual Meeting of the Asso-\nciation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language\nProcessing: System Demonstrations, pages 249–257,\nOnline. Association for Computational Linguistics.\nNabiha Asghar. 2016. Yelp dataset challenge: Review\nrating prediction. arXiv preprint arXiv:1605.05362.\nYonatan Belinkov, Sebastian Gehrmann, and Ellie\nPavlick. 2020. Interpretability and analysis in neural\nNLP. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics: Tu-\ntorial Abstracts, pages 1–5, Online. Association for\nComputational Linguistics.\nEmily M Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\ndangers of stochastic parrots: Can language models\nbe too big? In Proceedings of the ACM Confer-\nence on Fairness, Accountability, and Transparency\n(FAccT).\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ\nAltman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, Erik Brynjolfsson, S. Buch, Dallas Card,\nRodrigo Castellon, Niladri S. Chatterji, Annie S.\nChen, Kathleen Creel, Jared Davis, Dora Demszky,\nChris Donahue, Moussa Doumbouya, Esin Durmus,\nStefano Ermon, John Etchemendy, Kawin Ethayarajh,\nLi Fei-Fei, Chelsea Finn, Trevor Gale, Lauren E.\nGillespie, Karan Goel, Noah D. Goodman, Shelby\nGrossman, Neel Guha, Tatsunori Hashimoto, Peter\nHenderson, John Hewitt, Daniel E. Ho, Jenny Hong,\nKyle Hsu, Jing Huang, Thomas F. Icard, Saahil Jain,\nDan Jurafsky, Pratyusha Kalluri, Siddharth Karam-\ncheti, Geoff Keeling, Fereshte Khani, O. Khattab,\nPang Wei Koh, Mark S. Krass, Ranjay Krishna, Ro-\nhith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina\nLee, Tony Lee, Jure Leskovec, Isabelle Levent, Xi-\nang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik,\nChristopher D. Manning, Suvir P. Mirchandani, Eric\nMitchell, Zanele Munyikwa, Suraj Nair, Avanika\nNarayan, Deepak Narayanan, Benjamin Newman,\nAllen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJ. F. Nyarko, Giray Ogut, Laurel Orr, Isabel Papadim-\nitriou, Joon Sung Park, Chris Piech, Eva Portelance,\nChristopher Potts, Aditi Raghunathan, Robert Re-\nich, Hongyu Ren, Frieda Rong, Yusuf H. Roohani,\nCamilo Ruiz, Jack Ryan, Christopher R’e, Dorsa\nSadigh, Shiori Sagawa, Keshav Santhanam, Andy\nShih, Krishna Parasuram Srinivasan, Alex Tamkin,\nRohan Taori, Armin W. Thomas, Florian Tramèr,\nRose E. Wang, William Wang, Bohan Wu, Jiajun\nWu, Yuhuai Wu, Sang Michael Xie, Michihiro Ya-\nsunaga, Jiaxuan You, Matei A. Zaharia, Michael\nZhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang,\nLucia Zheng, Kaitlyn Zhou, and Percy Liang. 2021.\nOn the opportunities and risks of foundation models.\nArXiv, abs/2108.07258.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In\n18\nProceedings of Neural Information Processing Sys-\ntems (NeurIPS).\nShivani Choudhary, Niladri Chatterjee, and Subir Ku-\nmar Saha. 2022. Interpretation of black box nlp mod-\nels: A survey. arXiv preprint arXiv:2203.17081.\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao\nChang, and Furu Wei. 2022. Knowledge neurons in\npretrained transformers. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 8493–\n8502, Dublin, Ireland. Association for Computational\nLinguistics.\nFahim Dalvi, Avery Nortonsmith, Anthony Bau,\nYonatan Belinkov, Hassan Sajjad, Nadir Durrani, and\nJames Glass. 2019. NeuroX: A toolkit for analyzing\nindividual neurons in neural networks. Proceedings\nof the AAAI Conference on Artificial Intelligence ,\n33(01):9851–9852.\nMaria De-Arteaga, Alexey Romanov, Hanna Wal-\nlach, Jennifer Chayes, Christian Borgs, Alexandra\nChouldechova, Sahin Geyik, Krishnaram Kenthapadi,\nand Adam Tauman Kalai. 2019. Bias in bios: A case\nstudy of semantic representation bias in a high-stakes\nsetting. In Proceedings of the Conference on Fair-\nness, Accountability, and Transparency, FAT* ’19,\npage 120–128, New York, NY , USA. Association for\nComputing Machinery.\nNelson Elhage, Neel Nanda, Catherine Olsson, Tom\nHenighan, Nicholas Joseph, Ben Mann, Amanda\nAskell, Yuntao Bai, Anna Chen, Tom Conerly,\nNova DasSarma, Dawn Drain, Deep Ganguli, Zac\nHatfield-Dodds, Danny Hernandez, Andy Jones,\nJackson Kernion, Liane Lovitt, Kamal Ndousse,\nDario Amodei, Tom Brown, Jack Clark, Jared Ka-\nplan, Sam McCandlish, and Chris Olah. 2021. A\nmathematical framework for transformer circuits.\nTransformer Circuits Thread. Https://transformer-\ncircuits.pub/2021/framework/index.html.\nSamuel Gehman, Suchin Gururangan, Maarten Sap,\nYejin Choi, and Noah A. Smith. 2020. RealToxi-\ncityPrompts: Evaluating neural toxic degeneration\nin language models. In Findings of the Association\nfor Computational Linguistics: EMNLP 2020, pages\n3356–3369, Online. Association for Computational\nLinguistics.\nMor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav\nGoldberg. 2022. Transformer feed-forward layers\nbuild predictions by promoting concepts in the vo-\ncabulary space. arXiv preprint arXiv:2203.14680.\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian\nSun. 2016. Deep residual learning for image recogni-\ntion. In Proceedings of the conference on computer\nvision and pattern recognition (CVPR).\nBenjamin Hoover, Hendrik Strobelt, and Sebastian\nGehrmann. 2020. exBERT: A Visual Analysis Tool\nto Explore Learned Representations in Transformer\nModels. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics:\nSystem Demonstrations, pages 187–196, Online. As-\nsociation for Computational Linguistics.\nTaelin Karidi, Yichu Zhou, Nathan Schneider, Omri\nAbend, and Vivek Srikumar. 2021. Putting words\nin BERT’s mouth: Navigating contextualized vector\nspaces with pseudowords. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 10300–10313, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nKris McGuffie and Alex Newhouse. 2020. The radical-\nization risks of gpt-3 and advanced neural language\nmodels. arXiv preprint arXiv:2009.06807.\nKevin Meng, David Bau, Alex Andonian, and Yonatan\nBelinkov. 2022. Locating and editing factual knowl-\nedge in gpt. arXiv preprint arXiv:2202.05262.\nNostalgebraist. 2020. interpreting GPT: the logit lens.\nFabian Pedregosa, Gaël Varoquaux, Alexandre Gram-\nfort, Vincent Michel, Bertrand Thirion, Olivier Grisel,\nMathieu Blondel, Peter Prettenhofer, Ron Weiss, Vin-\ncent Dubourg, et al. 2011. Scikit-learn: Machine\nlearning in python. the Journal of machine Learning\nresearch, 12:2825–2830.\nNils Rethmeier, Vageesh Kumar Saxena, and Isabelle\nAugenstein. 2020. Tx-ray: Quantifying and explain-\ning model-knowledge transfer in (un-)supervised nlp.\nIn Proceedings of the 36th Conference on Uncer-\ntainty in Artificial Intelligence (UAI), volume 124 of\nProceedings of Machine Learning Research, pages\n440–449. PMLR.\nMarco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,\nand Sameer Singh. 2020. Beyond accuracy: Be-\nhavioral testing of NLP models with CheckList. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4902–\n4912, Online. Association for Computational Lin-\nguistics.\nStephen E Robertson, Steve Walker, Susan Jones,\nMicheline M Hancock-Beaulieu, and Mike Gatford.\n1995. et almbox. 1995. okapi at trec-3. Nist Special\nPublication Sp, 109:109.\nIan Tenney, James Wexler, Jasmijn Bastings, Tolga\nBolukbasi, Andy Coenen, Sebastian Gehrmann,\nEllen Jiang, Mahima Pushkarna, Carey Radebaugh,\nEmily Reif, and Ann Yuan. 2020. The language inter-\npretability tool: Extensible, interactive visualizations\nand analysis for NLP models. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing: System Demonstrations,\npages 107–118, Online. Association for Computa-\ntional Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\n19\nyou need. In Advances in Neural Information Pro-\ncessing Systems (NIPS), pages 5998–6008.\nJesse Vig and Yonatan Belinkov. 2019. Analyzing\nthe structure of attention in a transformer language\nmodel. In Proceedings of the 2019 ACL Workshop\nBlackboxNLP: Analyzing and Interpreting Neural\nNetworks for NLP, pages 63–76, Florence, Italy. As-\nsociation for Computational Linguistics.\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gard-\nner, and Sameer Singh. 2019a. Universal adversarial\ntriggers for attacking and analyzing NLP. InProceed-\nings of the 2019 Conference on Empirical Methods\nin Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), pages 2153–2162, Hong\nKong, China. Association for Computational Linguis-\ntics.\nEric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subra-\nmanian, Matt Gardner, and Sameer Singh. 2019b.\nAllenNLP interpret: A framework for explaining\npredictions of NLP models. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP): System Demonstrations, pages\n7–12, Hong Kong, China. Association for Computa-\ntional Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nA Appendix\nA.1 Details on Interventions to Control\nGenerated Text Sentiment\nTable 3 lists all the value vectors selected for our\ninterventions described in §5, and examples for\ntop-scoring tokens in their projections. These\nvectors were found with the exploration view of\nLM-Debugger (§3.2), using both keyword search\nand clustering visualisation. All the interventions\nwere configured to “turn on” these vectors, namely,\nsetting their coefficients to be maximal for the cor-\nresponding layer. This is following the observation\nby Geva et al. (2022) that FFN updates operate in\na token promotion mechanism (rather than elimina-\ntion).\n20\nSentiment Value Vector Example Top-scoring Tokens\nPositive\nL13D1763 properly, appropriately, adequate, truthful, humane,\nfulfil, inclusive, timely, patiently, sustainable\nL13D2011 clean, Proper, secure, flawless, safest, graceful, smooth,\ncalmly\nL14D944 peacefully, graceful, respectful, careful, generous,\npatiently, calm, tolerant, fair\nL15D74 Excellence, superb, trustworthy, marvelous, terrific,\nawesome, Amazing\nL20D988 successful, optimal, perfect, satisfactory, welcome,\nhelpful, fulfilling, healthy\nNegative\nL11D4 outdated, inadequate, stale, lousy, dull, mediocre, boring,\nwasteful\nL14D2653 trivial, dismiss, rigid, unsupported, only, prejud, obfusc,\npretend, dispar, slander\nL16D974 inappropriately, poorly, disrespect, unreliable,\nunhealthy, insecure, improperly, arrogance\nL17D3790 inappropriate, improper, wrong, bad, harmful,\nunreasonable, defective, disturbance, errors\nL18D91 confused, bizarre, unfairly, horrible, reckless, neglect,\nmisplaced, strange, nasty, mistakenly\nL18D3981 wrong, incorrect, insufficient, misleading, premature,\nimproperly, unrealistic, outdated, unfair\nTable 3: Value vectors used for controlling sentiment in generated text, that promote positive and negative\nadjectives/adverbs. For each vector, we show example top-scoring tokens from its projection to the vocabulary, as\npresented in the exploration view of LM-Debugger.\n21",
  "topic": "Debugger",
  "concepts": [
    {
      "name": "Debugger",
      "score": 0.9042606353759766
    },
    {
      "name": "Computer science",
      "score": 0.6075894832611084
    },
    {
      "name": "Transformer",
      "score": 0.5718252062797546
    },
    {
      "name": "Programming language",
      "score": 0.38247746229171753
    },
    {
      "name": "Software engineering",
      "score": 0.35805273056030273
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3529883325099945
    },
    {
      "name": "Debugging",
      "score": 0.2965371012687683
    },
    {
      "name": "Engineering",
      "score": 0.2957927882671356
    },
    {
      "name": "Electrical engineering",
      "score": 0.18710565567016602
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210140341",
      "name": "Allen Institute",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I13955877",
      "name": "Bar-Ilan University",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I16391192",
      "name": "Tel Aviv University",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I197251160",
      "name": "Hebrew University of Jerusalem",
      "country": "IL"
    }
  ]
}