{
  "title": "Generative AI and large language models in health care: pathways to implementation",
  "url": "https://openalex.org/W4392557826",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3164511044",
      "name": "Marium M. Raza",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A2982400380",
      "name": "Kaushik P Venkatesh",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A2080077413",
      "name": "Joseph C. Kvedar",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A3164511044",
      "name": "Marium M. Raza",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A2982400380",
      "name": "Kaushik P Venkatesh",
      "affiliations": [
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A2080077413",
      "name": "Joseph C. Kvedar",
      "affiliations": [
        "Harvard University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386347795",
    "https://openalex.org/W4323652488",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4321167341",
    "https://openalex.org/W3213708588",
    "https://openalex.org/W4385381606",
    "https://openalex.org/W4383301640",
    "https://openalex.org/W4296613139",
    "https://openalex.org/W4383346782"
  ],
  "abstract": null,
  "full_text": "EDITORIAL OPEN\nGenerative AI and large language models in health care:\npathways to implementation\nGenerative AI is designed to create new content from trained parameters. Learning from large amounts of data, many of these\nmodels aim to simulate human conversation. Generative AI is being applied to many different sectors. Within healthcare there has\nbeen innovation speciﬁcally towards generative AI models trained on electronic medical record data. A recent review characterizes\nthese models, their strengths, and weaknesses. Inspired by that work, we present our evaluation checklist for generative AI models\napplied to electronic medical records.\nnpj Digital Medicine            (2024) 7:62 ; https://doi.org/\n10.1038/s41746-023-00988-4\nINTRODUCTION\nIn November 2022, OpenAI launched ChatGPT, an arti ﬁcial\nintelligence (AI) chatbot and search tool. ChatGPT is a tool that\nuses generative AI: AI that is designed to create or generate new\ncontent, such as text, images, or music from trained parameters\n1.\nTools like ChatGPT use“large language models” (LLMs), multi-layer\nneural networks that are trained on large amounts of data to\nsimulate human conversation2. Other LLM tools include Google’s\nBard, Microsoft Bing, Chatsonic, Github Copilot, and ChatSonic to\nname just a few. LLMs themselves are an example of a“foundation\nmodel,” a broader term for an AI model trained on a large quantity\nof data at scale.\nThe buzz around generative AI has skyrocketed, with ChatGPT\nexpanding to have over 100 million users3. Over the past year,\nmany have shown excitement for potential generative AI\napplications to healthcare. LLMs have already been used to pass\nthe United States Medical Licensing Examination4, write research\narticles5, and interpret electronic medical record data6. This last\nuse case is perhaps closest to the bedside. Generative AI models\ntrained on EMR data, such as notes, lab values, and billing codes,\nhold the promise of better predictive performance, simpler model\ndevelopment (with less labeled data required) and cheaper model\ndeployment7. At the same time, those critiquing the utility of\nthese applications have argued that generative AI is simply\nanother health-tech fad, with many roadblocks preventing its\nimplementation8. One valid concern for example is regarding\ngenerative AI models‘hallucinating,’ or inventing responses when\nthey do not have sufﬁcient information9.\nEVALUATING GENERATIVE AI MODELS FOR EMRS\nIn their review, Wornow et al. explore the current state of\ngenerative AI models for EMRs 7. Speci ﬁcally, Wornow et al.\nconducted a review of 84 foundation models trained on clinical\nstructured text data from EMRs. This is the largest review of\nfoundation models within health care to date. To deﬁne the key\ncharacteristics of the models, Wornow et al. make the distinction\nbetween (i) clinical language models, which intake, and output\nclinical text, and (ii) EMR models that intake a patient’s entire EMR\nto output a machine-understandable‘representation’ for a patient,\nsimilar to a digital twin10.\nWornow et al. found evidence that both types of models enable\nmore accurate model predictions, but authors also found\nlimitations. Currently, nearly all clinical text models are trained\non either a single relatively small database or the entirety of\nPubMed. The ‘representation’ models are trained on small public\ndatasets only or a single private healthcare system’s EMR. Thus,\nWornow et al. found that current uses of generative AI within\nhealthcare are limited by their lack of generalizability and issues of\ndata privacy. Speciﬁcally, AI models based on data from different\nEMR systems are not generalizable, and very few AI models have\nhad details, such as model weights, published due to data privacy\nconcerns. Additionally, minimal work has been conducted to\nvalidate whether other, potentially more valuable beneﬁts of FMs\nwill be realized in healthcare (Table1).\nNoting those limitations, Wornow et al. propose an improved\nframework to evaluate generative AI models for healthcare\nsettings. They elaborate upon six criteria: predictive performance,\ndata labeling, model deployment, emergent clinical applications,\nmultimodality, and novel human-AI interfaces. By evaluating\nmodels around these criteria, Wornow et al. argue that health\nsystems will be better able to judge which are best for more\nstratiﬁed clinical needs.\nAPPLYING THE WORNOW ET AL. FRAMEWORK\nThis work comes at a time when exciting new EMR LLMs are being\nlaunched. For example, in April Microsoft announced a partnership\nintegrating its OpenAI service with the Epic EHR. This collaboration\nmay involve using generative AI to auto-draft responses to\ncommon and/or time-intensive patient messages\n11. Oracle Cerner\nhas also integrated generative AI into its EHR. Recently, (Nov\n2023), Oracle Cerner announced the Oracle Clinical Digital\nAssistant tool, a multimodal voice and screen-based tool that will\nparticipate in appointments by automating notetaking and\nproposing actions such as medication orders, labs, and follow-\nup appointments. Providers should be able to talk to the tool to\naccess elements of a patient’s EHR, while patients should be able\nto talk to the tool to book appointments and ask questions\n12.I n\ndeciding to implement either Epic or Oracle Cerner’s generative AI\napplications, Wornow et al. ’s evaluation framework becomes\nimportant to assess each model’s true clinical value. Below is a\nchecklist to be used while conducting a model evaluation,\nstemming from Wornow et al.’s six points. This type of checklist\ncould be modiﬁed based on a speciﬁc generative AI model or\nclinical setting, and then could be used regularly for model\nevaluation.\nwww.nature.com/npjdigitalmed\nPublished in partnership with Seoul National University Bundang Hospital\n1234567890():,;\nTHE PATHWAY FORWARD: LEADERSHIP, INCENTIVES, AND\nREGULATION\nThe improved evaluation framework Wornow et al. propose is one\nimportant step forward. To truly make generative AI more than\njust a fad within healthcare, a broader pathway to implementation\nis required. This pathway must include de ﬁned leadership for\ndevelopment, adoption incentives, and continued regulation.\nLeadership will be required ﬁrst and foremost to push\ncontinued model development, validation, and implementation.\nCurrently, generative AI models have been developed by startup\ncompanies, research groups, as well as academic healthcare\nsystems. Given these varied developers, guidance from a leader-\nship body is needed to clarify the practical path towards\nimplementation. Leadership should focus on developing guide-\nlines for model performance (i.e. minimizing model hallucination),\ndata sharing, ﬁnding the optimal healthcare settings for clinical\ntrials using generative AI tools, as well as clarifying the needs of\ndifferent healthcare settings (i.e. community vs. academic, private\nvs. public institutions). Ideally, this type of leadership will come\nfrom an organization involving physicians, healthcare adminis-\ntrators, developers, and investors. A sub-committee within the\nFDA could be well positioned to undertake such responsibility.ßß\nAlongside leadership, continued regulation will be required to\nbalance the interests of developers, healthcare systems, payers,\nand patients. The continued evaluation of tools based on\nframeworks such as that developed by Wornow et al. must be\nconducted on the scale of individual health institutions so that\ntools with clinical relevance are prioritized. On the larger scale, as\nwith other AI tools, policies surrounding liability, data privacy, and\nbias within predictive modeling must be clariﬁed before insights\nfrom generative AI tools can be put into practice. While the FDA\nhas begun to adapt its regulatory framework to address AI\ntechnology as medical devices it must move from discussion to\naction, and provide speciﬁc guidance for LLMs\n13,14. The FDA can\nlearn from the strengths as well as the criticisms of the EU’s AI Act,\none of theﬁrst formal regulations for generative AI15.\nFinally, as with any other healthcare technology, payer\nincentives must be present before widespread implementation.\nGenerative AI tools will likely be considered a capital expense in\nthe books of most providers and can follow along the same or\nsimilar ﬁnancing path as EHR systems. Additionally, given that the\ncost to create and evaluate generative AI tools remains somewhat\nprohibitive, both private and public investment will be required to\ntruly push theﬁeld forward.\nThe time is now to capitalize on the excitement around generative\nAI and LLMs. The weakness of the generative AI space that Wornow\net al. highlight, including those around model generalizability and\nevaluation, should be taken as guideposts for improvement. With\nleadership, incentivization, and regulation, generative AI within\nhealthcare can be put on a feasible pathway for implementation.\nDATA AVAILABILITY\nNo datasets were produced or analyzed for this article.\nCODE AVAILABILITY\nNo computer code was produced or analyzed for this article.\nReceived: 17 October 2023; Accepted: 6 December 2023;\nMarium M. Raza 1 ✉, Kaushik P. Venkatesh 1 and\nJoseph C. Kvedar 1\n1Harvard Medical School, Boston, MA, USA.\n✉email: mraza@hms.harvard.edu\nREFERENCES\n1. Boscardin C. K., Gin B., Golde P. B. & Hauer K. E. ChatGPT and generative artiﬁcial\nintelligence for medical education: potential impact and opportunity.Acad Med\nhttps://doi.org/10.1097/ACM.0000000000005439 (2023).\n2. Alberts, IanL. et al. Large language models (LLM) and ChatGPT: what will the\nimpact on nuclear medicine be?Eur. J. Nuclear Med. Mol. Imag.50, 1549– 1552\n(2023).\n3. Hu, K. ChatGPt sets record for fastest-growing user base. Reuters\nwww.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-\nanalyst-note-2023-02-01/ (2023).\n4. Kung, T. H. et al. Performance of ChatGPT on USMLE: potential for AI-assisted\nmedical education using large language models.PLoS Digit Health 2, e0000198\n(2023).\n5. Macdonald, C., Adeloye, D., Sheikh, A. & Rudan, I. Can ChatGPT draft a research\narticle? An example of population-level vaccine effectiveness analysis. J. Glob.\nHealth 13, 01003 (2023).\n6. Pang, C. et al. CEHR-BERT: Incorporating temporal information from structured\nEHR data to improve prediction tasks. arXiv https://doi.org/10.48550/\narXiv.2111.08585 (2021)\n7. Wornow, M. et al. The shaky foundations of large language models and foun-\ndation models for electronic health records.npj Digit. Med.6, 135 (2023).\n8. Duffourc, M. & Gerke, S. Generative Ai in health care and liability risks for phy-\nsicians and safety concerns for patients. JAMA. 330, 313– 314, https://doi.org/\n10.1001/jama.2023.9630 (2023).\n9. Weise K. & Metz C. When A.I. Chatbots Hallucinate.The New York Times. The New\nYork Times Companyhttps://www.nytimes.com/2023/05/01/business/ai-chatbots-\nhallucination.html (2023).\n10. Venkatesh, K. P., Raza, M. M. & Kvedar, J. C. Health digital twins as tools for\nprecision medicine: Considerations for computation, implementation, and reg-\nulation. npj Digit. Med.5, 150 (2022).\nTable 1. Generative AI model evaluation checklist\nPredictive performance & Multimodality Auto-draft response accuracy (i.e. Epic system) measured\nPredicted orders/labs accuracy (i.e. Oracle Cerner system) measured\nAccuracy rate stratiﬁed by data type i.e. text vs voice vs image vs video\nManual user correction rate measured\nModel hallucination rate quantiﬁed\n☐\n☐\n☐\n☐\n☐\nLess labeled data Cost/volume of training data required before clinical use calculated\nImplementation time (from model acquisition to clinical use) measured\n☐\n☐\nSimpliﬁed model deployment Cost of model implementation calculated\nClinician hours/administration hours saved calculated\nTraining time and training resources before clinical use quantiﬁed\nCost of technological support needed during clinical use calculated\n☐\n☐\n☐\n☐\nEmergent clinical applications Number of new/innovative clinical applications identi ﬁed ☐\nNovel human-AI interface Clinician satisfaction surveyed\nPatient satisfaction surveyed\nQualitative points of feedback synthesized into report for model improvement\n☐\n☐\n☐\nM.M. Raza et al.\n2\nnpj Digital Medicine (2024)    62 Published in partnership with Seoul National University Bundang Hospital\n1234567890():,;\n11. Microsoft News Center. Microsoft and epic expand strategic collaboration with\nintegration of azure openai service. Microsoft News , Microsoft.\nnews.microsoft.com/2023/04/17/microsoft-and-epic-expand-strategic-\ncollaboration-with-integration-of-azure-openai-service/ (2023).\n12. Landi, H. Oracle Health integrates generative AI, voice tech into EHR system to\nautomate medical note-taking. Fierce Healthcare . Questex LLC https://\nwww.ﬁercehealthcare.com/ai-and-machine-learning/oracle-health-integrates-\ngenerative-ai-conversational-voice-tech-ehr-system (2023).\n13. FDA. Software as a Medical Device (SAMD): Clinical Evaluation . https://\nwww.fda.gov/media/100714/download (2017).\n14. Meskó, B. & Topol, E. J. The imperative for regulatory oversight of large language\nmodels (or generative AI) in healthcare.npj Digit. Med.6, 120 (2023).\n15. EU AI Act:ﬁrst regulation on artiﬁcial intelligence. European Parliament. https://\nwww.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-\nact-ﬁrst-regulation-on-artiﬁcial-intelligence (2023).\nAUTHOR CONTRIBUTIONS\nFirst draft by M.M.R. Critical revisions by K.P.V. and J.C.K. All authors approved the\nﬁnal draft.\nCOMPETING INTERESTS\nJ.C.K. is the Editor-in-Chief of npj Digital Medicine. The other authors declare no\ncompeting interests.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this licence, visit http://\ncreativecommons.org/licenses/by/4.0/.\n© The Author(s) 2024\nM.M. Raza et al.\n3\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)    62 ",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.9092810153961182
    },
    {
      "name": "Conversation",
      "score": 0.656035304069519
    },
    {
      "name": "Checklist",
      "score": 0.6319617033004761
    },
    {
      "name": "Computer science",
      "score": 0.6235642433166504
    },
    {
      "name": "Generative model",
      "score": 0.6068115830421448
    },
    {
      "name": "Artificial intelligence",
      "score": 0.545103132724762
    },
    {
      "name": "Health records",
      "score": 0.45753318071365356
    },
    {
      "name": "Strengths and weaknesses",
      "score": 0.44755107164382935
    },
    {
      "name": "Data science",
      "score": 0.41884732246398926
    },
    {
      "name": "Health care",
      "score": 0.41756996512413025
    },
    {
      "name": "Natural language processing",
      "score": 0.3705625534057617
    },
    {
      "name": "Psychology",
      "score": 0.13795027136802673
    },
    {
      "name": "Communication",
      "score": 0.0864129364490509
    },
    {
      "name": "Cognitive psychology",
      "score": 0.0
    },
    {
      "name": "Social psychology",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    }
  ]
}