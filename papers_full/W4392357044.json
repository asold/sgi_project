{
  "title": "A Survey of Knowledge Enhanced Pre-trained Language Models",
  "url": "https://openalex.org/W4392357044",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1942304213",
      "name": "Jian Yang",
      "affiliations": [
        "Xidian University"
      ]
    },
    {
      "id": "https://openalex.org/A2110965601",
      "name": "Hu Xinyu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1914011975",
      "name": "Gang Xiao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2127333047",
      "name": "Yulong Shen",
      "affiliations": [
        "Xidian University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2493916176",
    "https://openalex.org/W68132019",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W2972324944",
    "https://openalex.org/W6797076564",
    "https://openalex.org/W3092475443",
    "https://openalex.org/W2728059831",
    "https://openalex.org/W3204880256",
    "https://openalex.org/W3014521650",
    "https://openalex.org/W2963026768",
    "https://openalex.org/W2948947170",
    "https://openalex.org/W2250342289",
    "https://openalex.org/W3105111366",
    "https://openalex.org/W1505839237",
    "https://openalex.org/W2184957013",
    "https://openalex.org/W2998385486",
    "https://openalex.org/W3176750236",
    "https://openalex.org/W2951048068",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W2157735936",
    "https://openalex.org/W2081580037",
    "https://openalex.org/W2951105272",
    "https://openalex.org/W2949972983",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W2970986510",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W3118485687",
    "https://openalex.org/W2950393809",
    "https://openalex.org/W3090716330",
    "https://openalex.org/W3114916066",
    "https://openalex.org/W2997200074",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W3151929433",
    "https://openalex.org/W2283196293",
    "https://openalex.org/W2620787630",
    "https://openalex.org/W3104415840",
    "https://openalex.org/W2950813464",
    "https://openalex.org/W4307003748",
    "https://openalex.org/W1840106123",
    "https://openalex.org/W2953356739",
    "https://openalex.org/W4300011764",
    "https://openalex.org/W3003265726",
    "https://openalex.org/W2489487449",
    "https://openalex.org/W2072128103",
    "https://openalex.org/W2912083425",
    "https://openalex.org/W23685451",
    "https://openalex.org/W3175277088",
    "https://openalex.org/W2747329762",
    "https://openalex.org/W3154735894",
    "https://openalex.org/W2799915114",
    "https://openalex.org/W4365799947",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2964303913",
    "https://openalex.org/W2912512851",
    "https://openalex.org/W2752294398",
    "https://openalex.org/W2915480215",
    "https://openalex.org/W2511959214",
    "https://openalex.org/W2750779823",
    "https://openalex.org/W4205807230",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W4294170691",
    "https://openalex.org/W2325605806",
    "https://openalex.org/W2531563875",
    "https://openalex.org/W4214566146",
    "https://openalex.org/W2175268987",
    "https://openalex.org/W4239019441",
    "https://openalex.org/W4238846128",
    "https://openalex.org/W4233907442"
  ],
  "abstract": "Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.",
  "full_text": null,
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.9474852085113525
    },
    {
      "name": "Computer science",
      "score": 0.7619341611862183
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7067710161209106
    },
    {
      "name": "Natural language processing",
      "score": 0.6200466156005859
    },
    {
      "name": "Categorization",
      "score": 0.6138893365859985
    },
    {
      "name": "Language model",
      "score": 0.5460895895957947
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.4898952841758728
    },
    {
      "name": "Language understanding",
      "score": 0.4677797555923462
    },
    {
      "name": "Natural language understanding",
      "score": 0.4511295557022095
    },
    {
      "name": "Natural language",
      "score": 0.40876367688179016
    },
    {
      "name": "Machine learning",
      "score": 0.33272063732147217
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I149594827",
      "name": "Xidian University",
      "country": "CN"
    }
  ]
}