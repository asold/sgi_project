{
  "title": "A foundation model to predict and capture human cognition",
  "url": "https://openalex.org/W4411932262",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2550663075",
      "name": "Marcel Binz",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A5092048108",
      "name": "Elif Akata",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A1898836778",
      "name": "Matthias Bethge",
      "affiliations": [
        "University of Tübingen"
      ]
    },
    {
      "id": "https://openalex.org/A2980289259",
      "name": "Franziska Brändle",
      "affiliations": [
        "University of Oxford",
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A2184016392",
      "name": "Fred Callaway",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A5089420217",
      "name": "Julian Coda-Forno",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2057359516",
      "name": "Peter Dayan",
      "affiliations": [
        "University of Tübingen",
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A4377917458",
      "name": "Can Demircan",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2566272873",
      "name": "Maria K. Eckstein",
      "affiliations": [
        "DeepMind (United Kingdom)",
        "Google (United Kingdom)"
      ]
    },
    {
      "id": "https://openalex.org/A4211350752",
      "name": "Noémi Éltető",
      "affiliations": [
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A2122351653",
      "name": "Thomas L. Griffiths",
      "affiliations": [
        "Princeton University"
      ]
    },
    {
      "id": "https://openalex.org/A3186644305",
      "name": "Susanne Haridi",
      "affiliations": [
        "Helmholtz Zentrum München",
        "Max Planck Institute for Human Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A5016171206",
      "name": "Akshay K. Jagadish",
      "affiliations": [
        "University of Tübingen",
        "Helmholtz Zentrum München",
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A4213577898",
      "name": "Li Ji’an",
      "affiliations": [
        "University of California, San Diego"
      ]
    },
    {
      "id": "https://openalex.org/A2098839553",
      "name": "Alexander Kipnis",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A3018208565",
      "name": "Sreejan Kumar",
      "affiliations": [
        "Princeton University"
      ]
    },
    {
      "id": "https://openalex.org/A2253402228",
      "name": "Tobias Ludwig",
      "affiliations": [
        "Max Planck Institute for Biological Cybernetics",
        "University of Tübingen"
      ]
    },
    {
      "id": "https://openalex.org/A4220424640",
      "name": "Marvin Mathony",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A4267239026",
      "name": "Marcelo Mattar",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2956002336",
      "name": "Alireza Modirshanechi",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2990810846",
      "name": "Surabhi S. Nath",
      "affiliations": [
        "University of Tübingen",
        "Max Planck Institute for Biological Cybernetics",
        "Max Planck Institute for Human Cognitive and Brain Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2281220270",
      "name": "Joshua C. Peterson",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2807876296",
      "name": "Milena Rmus",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2552260276",
      "name": "Evan M. Russek",
      "affiliations": [
        "Princeton University"
      ]
    },
    {
      "id": "https://openalex.org/A3147885178",
      "name": "Tankred Saanum",
      "affiliations": [
        "Max Planck Institute for Biological Cybernetics",
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A5114080122",
      "name": "Johannes A. Schubert",
      "affiliations": [
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A3207783209",
      "name": "Luca M. Schulze Buschoff",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A3088898351",
      "name": "Nishad Singhi",
      "affiliations": [
        "Technical University of Darmstadt"
      ]
    },
    {
      "id": "https://openalex.org/A1987061521",
      "name": "Xin Sui",
      "affiliations": [
        "University of Tübingen",
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A2301479564",
      "name": "Mirko Thalmann",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2229870300",
      "name": "Fabian J. Theis",
      "affiliations": [
        "Technical University of Munich",
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2948030982",
      "name": "Vuong Truong",
      "affiliations": [
        "Max Planck Institute for Biological Cybernetics"
      ]
    },
    {
      "id": "https://openalex.org/A2981400959",
      "name": "Vishaal Udandarao",
      "affiliations": [
        "University of Cambridge",
        "University of Tübingen"
      ]
    },
    {
      "id": "https://openalex.org/A1974174299",
      "name": "Konstantinos Voudouris",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A1532175135",
      "name": "Robert Wilson",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2129747299",
      "name": "Kristin Witte",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2123688772",
      "name": "Shu-Chen Wu",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2077204653",
      "name": "Dirk U. Wulff",
      "affiliations": [
        "University of Basel",
        "Max Planck Institute for Human Development"
      ]
    },
    {
      "id": null,
      "name": "Huadong Xiong",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2117491939",
      "name": "Eric Schulz",
      "affiliations": [
        "Helmholtz Zentrum München"
      ]
    },
    {
      "id": "https://openalex.org/A2550663075",
      "name": "Marcel Binz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5092048108",
      "name": "Elif Akata",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1898836778",
      "name": "Matthias Bethge",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2980289259",
      "name": "Franziska Brändle",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2184016392",
      "name": "Fred Callaway",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5089420217",
      "name": "Julian Coda-Forno",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2057359516",
      "name": "Peter Dayan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4377917458",
      "name": "Can Demircan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2566272873",
      "name": "Maria K. Eckstein",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4211350752",
      "name": "Noémi Éltető",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122351653",
      "name": "Thomas L. Griffiths",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3186644305",
      "name": "Susanne Haridi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5016171206",
      "name": "Akshay K. Jagadish",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4213577898",
      "name": "Li Ji’an",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098839553",
      "name": "Alexander Kipnis",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3018208565",
      "name": "Sreejan Kumar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2253402228",
      "name": "Tobias Ludwig",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4220424640",
      "name": "Marvin Mathony",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4267239026",
      "name": "Marcelo Mattar",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2956002336",
      "name": "Alireza Modirshanechi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2990810846",
      "name": "Surabhi S. Nath",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2281220270",
      "name": "Joshua C. Peterson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2807876296",
      "name": "Milena Rmus",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2552260276",
      "name": "Evan M. Russek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3147885178",
      "name": "Tankred Saanum",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5114080122",
      "name": "Johannes A. Schubert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3207783209",
      "name": "Luca M. Schulze Buschoff",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3088898351",
      "name": "Nishad Singhi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1987061521",
      "name": "Xin Sui",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2301479564",
      "name": "Mirko Thalmann",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2229870300",
      "name": "Fabian J. Theis",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2948030982",
      "name": "Vuong Truong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2981400959",
      "name": "Vishaal Udandarao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1974174299",
      "name": "Konstantinos Voudouris",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1532175135",
      "name": "Robert Wilson",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2129747299",
      "name": "Kristin Witte",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2123688772",
      "name": "Shu-Chen Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2077204653",
      "name": "Dirk U. Wulff",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Huadong Xiong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117491939",
      "name": "Eric Schulz",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2963305465",
    "https://openalex.org/W2194321275",
    "https://openalex.org/W4395663188",
    "https://openalex.org/W3093162736",
    "https://openalex.org/W2766447205",
    "https://openalex.org/W6745620495",
    "https://openalex.org/W33891176",
    "https://openalex.org/W4392913756",
    "https://openalex.org/W6800751262",
    "https://openalex.org/W4318919287",
    "https://openalex.org/W3174174150",
    "https://openalex.org/W3170561227",
    "https://openalex.org/W1509525679",
    "https://openalex.org/W3167884978",
    "https://openalex.org/W2102803424",
    "https://openalex.org/W2054698589",
    "https://openalex.org/W2610253745",
    "https://openalex.org/W3213943841",
    "https://openalex.org/W3040440677",
    "https://openalex.org/W2510619540",
    "https://openalex.org/W4289783258",
    "https://openalex.org/W3129534106",
    "https://openalex.org/W2896252141",
    "https://openalex.org/W6755646343",
    "https://openalex.org/W4410251374",
    "https://openalex.org/W4220793486",
    "https://openalex.org/W3164441286",
    "https://openalex.org/W1990242729",
    "https://openalex.org/W2058616551",
    "https://openalex.org/W3037273551",
    "https://openalex.org/W3210923133",
    "https://openalex.org/W4362521962",
    "https://openalex.org/W4366003941",
    "https://openalex.org/W4390571036",
    "https://openalex.org/W2315123323",
    "https://openalex.org/W2029844437",
    "https://openalex.org/W3014888349",
    "https://openalex.org/W2152437364",
    "https://openalex.org/W4205243556",
    "https://openalex.org/W4403590193",
    "https://openalex.org/W4406855744",
    "https://openalex.org/W4376117416",
    "https://openalex.org/W3176196997",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4353091694",
    "https://openalex.org/W4285008158",
    "https://openalex.org/W6803072188",
    "https://openalex.org/W2772751317",
    "https://openalex.org/W2761002469",
    "https://openalex.org/W2920590181",
    "https://openalex.org/W2089358714",
    "https://openalex.org/W3086360455",
    "https://openalex.org/W4386737883",
    "https://openalex.org/W4406400870",
    "https://openalex.org/W2331395872",
    "https://openalex.org/W2622366552",
    "https://openalex.org/W2951617899",
    "https://openalex.org/W2951583631",
    "https://openalex.org/W2025009638",
    "https://openalex.org/W4405626356",
    "https://openalex.org/W4403883673",
    "https://openalex.org/W3201174429"
  ],
  "abstract": "Abstract Establishing a unified theory of cognition has been an important goal in psychology 1,2 . A first step towards such a theory is to create a computational model that can predict human behaviour in a wide range of settings. Here we introduce Centaur, a computational model that can predict and simulate human behaviour in any experiment expressible in natural language. We derived Centaur by fine-tuning a state-of-the-art language model on a large-scale dataset called Psych-101. Psych-101 has an unprecedented scale, covering trial-by-trial data from more than 60,000 participants performing in excess of 10,000,000 choices in 160 experiments. Centaur not only captures the behaviour of held-out participants better than existing cognitive models, but it also generalizes to previously unseen cover stories, structural task modifications and entirely new domains. Furthermore, the model’s internal representations become more aligned with human neural activity after fine-tuning. Taken together, our results demonstrate that it is possible to discover computational models that capture human behaviour across a wide range of domains. We believe that such models provide tremendous potential for guiding the development of cognitive theories, and we present a case study to demonstrate this.",
  "full_text": "1002 | Nature | Vol 644 | 28 August 2025\nArticle\nA foundation model to predict and capture \nhuman cognition\nMarcel Binz1 ✉, Elif Akata1, Matthias Bethge2, Franziska Brändle3,4, Fred Callaway5, \nJulian Coda-Forno1, Peter Dayan2,4, Can Demircan1, Maria K. Eckstein6, Noémi Éltető4, \nThomas L. Griffiths7, Susanne Haridi1,8, Akshay K. Jagadish1,2,4, Li Ji-An9, Alexander Kipnis1, \nSreejan Kumar7, Tobias Ludwig2,4, Marvin Mathony1, Marcelo Mattar5, Alireza Modirshanechi1, \nSurabhi S. Nath2,4,8, Joshua C. Peterson10, Milena Rmus1, Evan M. Russek7, Tankred Saanum1,4, \nJohannes A. Schubert4, Luca M. Schulze Buschoff1, Nishad Singhi11, Xin Sui2,4, \nMirko Thalmann1, Fabian J. Theis12,13,14, Vuong Truong4, Vishaal Udandarao2,15, \nKonstantinos Voudouris1, Robert Wilson16, Kristin Witte1, Shuchen Wu1, Dirk U. Wulff17,18, \nHuadong Xiong16 & Eric Schulz1\nEstablishing a unified theory of cognition has been an important goal in psychology1,2. \nA first step towards such a theory is to create a computational model that can  \npredict human behaviour in a wide range of settings. Here we introduce Centaur, a \ncomputational model that can predict and simulate human behaviour in any \nexperiment expressible in natural language. We derived Centaur by fine-tuning a state- \nof-the-art language model on a large-scale dataset called Psych-101. Psych-101 has an \nunprecedented scale, covering trial-by-trial data from more than 60,000 participants \nperforming in excess of 10,000,000 choices in 160 experiments. Centaur not only \ncaptures the behaviour of held-out participants better than existing cognitive models, \nbut it also generalizes to previously unseen cover stories, structural task modifications \nand entirely new domains. Furthermore, the model’s internal representations become \nmore aligned with human neural activity after fine-tuning. Taken together, our results \ndemonstrate that it is possible to discover computational models that capture human \nbehaviour across a wide range of domains. We believe that such models provide \ntremendous potential for guiding the development of cognitive theories, and we \npresent a case study to demonstrate this.\nThe human mind is remarkably general3. Not only do we routinely make \nmundane decisions, such as choosing a breakfast cereal or selecting an \noutfit, but we also tackle complex challenges, such as figuring out how \nto cure cancer or explore outer space. We learn skills from only a few \ndemonstrations4, reason causally5 and fuel our actions through curios-\nity6. Whether we are climbing mountains, playing video games, or creat-\ning captivating art, our versatility defines what it means to be human.\nBy contrast, most contemporary computational models, whether in \nmachine learning or the cognitive sciences, are domain specific. They \nare designed to excel at one particular problem and only that problem. \nConsider, for instance, AlphaGo, which is a computer system created by \nGoogle DeepMind to master the game of Go7. The system can play this \nparticular game at an impressive level, but it cannot do much beyond \nthat. A similar pattern can be observed in the cognitive sciences. For \ninstance, prospect theory, which is one of the most influential accounts \nof human cognition, offers valuable insights into how people make \nchoices8, but it tells us nothing about how we learn, plan or explore.\nIf we want to understand the human mind in its entirety, we must \nmove from domain-specific theories to an integrated one. The impor-\ntance of such a unified approach has already been recognized by the \npioneers of our field. For example, in 1990, it was stated that “unified \ntheories of cognition are the only way to bring [our] wonderful, increas-\ning fund of knowledge under intellectual control”2. How can we make \nmeaningful progress towards such theories?\nAn important step towards a unified theory of cognition is to build a \ncomputational model that can predict and simulate human behaviour \nin any domain2,9. In this paper, we take up this challenge and intro -\nduce Centaur—a foundation model of human cognition 10. Centaur \nwas designed in a data-driven manner by fine-tuning a state-of-the-art \nlarge language model 11 on a large corpus of human behaviour. For \nthis purpose, we curated a large-scale dataset called Psych-101, which \ncovers trial-by-trial data from 160 psychological experiments (see  \nMethods, ‘Data collection’ and Extended Data Fig. 1). We transcribed \neach of these experiments into natural language, which provides a \nhttps://doi.org/10.1038/s41586-025-09215-4\nReceived: 26 October 2024\nAccepted: 29 May 2025\nPublished online: 2 July 2025\nOpen access\n Check for updates\n1Institute for Human-Centered AI, Helmholtz Center, Munich, Germany. 2University of Tübingen, Tübingen, Germany. 3University of Oxford, Oxford, UK. 4Max Planck Institute for Biological \nCybernetics, Tübingen, Germany. 5New York University, New York, NY, USA. 6Google DeepMind, London, UK. 7Princeton University, Princeton, NJ, USA. 8Max Planck School of Cognition, Leipzig, \nGermany. 9University of California, San Diego, San Diego, CA, USA. 10Boston University, Boston, MA, USA. 11TU Darmstadt, Darmstadt, Germany. 12Institute of Computational Biology, Helmholtz \nCenter, Munich, Germany. 13TUM School of Computation, Information and Technology, Technical University of Munich, Munich, Germany. 14TUM School of Life Sciences, Technical University  \nof Munich, Munich, Germany. 15University of Cambridge, Cambridge, UK. 16Georgia Institute of Technology, Atlanta, GA, USA. 17University of Basel, Basel, Switzerland. 18Max Planck Institute for \nHuman Development, Berlin, Germany. ✉e-mail: marcel.binz@helmholtz-munich.de\nNature | Vol 644 | 28 August 2025 | 1003\ncommon format for expressing vastly different experimental para-\ndigms12,13. The resulting dataset has an unprecedented scale, containing \nmore than 10,000,000 human choices and including many canonical \nstudies from domains such as multi-armed bandits, decision-making, \nmemory, supervised learning, Markov decision processes and more \n(see Fig. 1a for an overview and examples).\nWe subjected Centaur to a series of rigorous tests and demonstrate \nthat it captures human behaviour at several levels of generalization. \nFirst, we show that Centaur predicts behaviour of held-out participants \n(those who are not part of the training data) better than existing cogni-\ntive models in almost every single experiment. We then demonstrate \nthat its ability to capture human behaviour also generalizes to held-out \nexperiments. In this context, we find that Centaur accurately predicts \nhuman behaviour under modified cover stories, problem structures and \neven in entirely new domains. Finally, we show that Centaur’s internal \nrepresentations become more human aligned, even though it was never \nexplicitly trained to capture human neural activity.\nTaken together, our results demonstrate that it is possible to discover \ncomputational models that capture human behaviour across a wide \nrange of domains. We think that such a predictive model offers many \ndirect opportunities to obtain a better understanding of the human \nmind14,15 and we present a case study that demonstrates this potential.\nModel overview\nWe built Centaur on top of the open-source language model Llama  \n3.1 70B, a state-of-the-art model pretrained by Meta AI (hereafter, we \nrefer to this model simply as Llama)11. Having a large language model as \nthe backbone allowed us to rely on the vast amounts of knowledge that \nis present in these models. The training process involved fine-tuning \non Psych-101 using a parameter-efficient fine-tuning technique known \nas quantized low-rank adaptation (QLoRA)16. QLoRA relies on a fro-\nzen four-bit quantized language model as a base model. Although the \nparameters of the base model are left unchanged, it adds low-rank \nadapters, which contain only a few additional, trainable parameters \n(typically represented in a half-precision floating-point format). In our \ncase, we added low-rank adapters of rank r = 8 to all non-embedding \nlayers (that is, all linear layers of the self-attention mechanisms and \nthe feedforward networks), as illustrated in Fig.  1b. With these set-\ntings, the newly added parameters amount to 0.15% of the base model’s \nparameters. We then trained the model for one epoch on the entire \ndataset using a standard cross-entropy loss. We masked out the loss \nfor all tokens that do not correspond to human responses, thereby \nensuring that the model focuses on capturing human behaviour and \nnot on completing experimental instructions. The entire training pro-\ncess took approximately five days on an A100 80GB GPU (Methods,  \n‘Fine-tuning procedure’).\nCentaur captures human behaviour\nWe evaluated Centaur on different types of held-out data to demon-\nstrate that it robustly captures human behaviour. In our first analysis, \nwe tested whether it could predict the behaviour of participants who \nwere not part of the training data. For this, we split each transcribed \nexperiment into two parts and used 90% of participants for training \nand retained 10% for testing. We measured goodness-of-fit to human \nCentaur: a foundation model of human cognition\nMulti-armed bandits Decision-making Memory\nSupervised learning Markov decision processes Miscellaneous\nIn this task, you have to repeatedly choose between\ntwo slot machines labelled B and C. When you select\none of the machines, you will win or lose points.\nYour goal is to choose the slot machines that will\ngive you the most points.\nYou press <<C>> and get –8 points.\nYou press <<B>> and get 0 points.\nYou press <<B>> and get 1 points.\nYou will choose from two monetary lotteries by\npressing N or U. Your choice will trigger a random\ndraw from the chosen lottery that will be added to\nyour bonus.\nLottery N offers 4.0 points with 80.0% or 0.0 points\nwith 20.0%.\nLottery U offers 3.0 points with 100.0%.\nYou press <<U>>.\nYou will view a stream of letters on the screen, one\nletter at a time. You have to remember the last two\nletters you saw since the beginning of the block. If\nthe letter you see matches the letter two trials ago,\npress E, otherwise press K.\nYou see the letter V and press <<K>>.\nYou see the letter X and press <<K>>.\nYou see the letter V and press <<E>>.\nIn each trial, you will see between one and three\ntarot cards. Your task is to decide if the combination\nof cards presented predicts rainy weather (by\npressing P) or ﬁne weather (by pressing L).\nYou are seeing the following: card 3, card 4. You\npress <<L>>. You are right, the weather is ﬁne.\nYou are seeing the following: card 1, card 4. You\npress <<P>>. You are right, the weather is rainy.\nYou will be taking one of the spaceships F or V to\none of the planets M or S. When you arrive at each\nplanet, you will ask one of the aliens for space trea-\nsure.\nYou are presented with spaceships V and F.\nYou press <<V>>. You end up on planet M and\nsee aliens G and W. You press <<G>>.\nYou ﬁnd 1 piece of space treasure.\nYou will be presented with triplets of objects, which\nwill be assigned to the keys E, Z, and B. In each\ntrial, please indicate which object you think is the\nodd one out by pressing the corresponding key.\nE: tablet, Z: fox, and B: vent. You press <<Z>>.\nE: ivy, Z: coop, and B: drink. You press <<B>>.\nE: kite, Z: ﬂan, and B: jar. You press <<E>>.\nE: wand, Z: ﬂag, and B: ﬁre. You press <<Z>>.\nIn this task, you\nhave to repeatedly\nchoose between two\nslot machines labelled\nB and C. [...]\nYou press <<\nToken\nembedding\nOutput\nCSelf-\nattention\nFeedforward\nnetwork\nLow-rank\nadapter\nLow-rank\nadapter\nLow-rank\nadapter\nLow-rank\nadapter\n...\n Self-\nattention\nFeedforward\nnetwork\na\nb\nFig. 1 | Overview of Psych-101 and Centaur. a, Psych-101 comprises trial-by- \ntrial data from 160 psychological experiments with 60,092 participants \nmaking 10,681,650 choices in total and involving 253,597,411 text tokens. \nIt contains domains such as multi-armed bandits, decision-making, memory, \nsupervised learning, Markov decision processes and others (the examples \nshown have been stylized and abbreviated for readability). b , Centaur is a \nfoundation of model human cognition that is obtained by adding low-rank \nadapters to a state-of-the-art language model and fine-tuning it on Psych-101.\n1004 | Nature | Vol 644 | 28 August 2025\nArticle\nchoices using negative log-likelihoods averaged across responses  \n(Methods, ‘Evaluation metric’). Figure 2a presents the results of this \nanalysis, comparing Centaur with the base model without fine-tuning \nand a  collection of domain-specific models that represent the \nstate-of-the-art in the cognitive-science literature (Extended Data \nTable 1). Although there was substantial variance in predictability \nacross experiments (Centaur, 0.49; Llama, 0.47), fine-tuning always \nimproved goodness-of-fit. The average difference in log-likelihoods \nacross experiments after fine-tuning was 0.14 (Centaur negative \nlog-likelihood, 0.44; Llama negative log-likelihood, 0.58; one-sided \nt-test: t(1,985,732) = −144.22, P ≤ 0.0001; Cohen’s d, 0.20).\nFurthermore, we compared Centaur with the previously men -\ntioned collection of domain-specific cognitive models. These models  \ninclude, among others, the generalized context model 17, a pros -\npect theory model18 and various reinforcement learning models19,20  \n(Methods, ‘Domain-specific cognitive models’). We observed that \nCentaur outperforms domain-specific cognitive models in all but one \nexperiment. The average difference in predicting human behaviour \nto the domain-specific cognitive models was 0.13 (cognitive models, \nnegative log-likelihood, 0.56; one-sided t-test: t(1,985,732) = −127.58, \nP ≤ 0.0001; Cohen’s d, 0.18). Extended Data Figs. 2 and 3 contain more \ncomparisons to models fine-tuned on non-behavioural data and a \nnoise-ceiling analysis.\nThe previous analyses have focused on predicting human responses \nconditioned on previously executed behaviour. We may ask whether \nCentaur can also generate human-like behaviour when simulated in an \nopen-loop fashion (that is, when feeding its own responses back into \nthe model). This setting arguably provides a much stronger test of the \nmodel’s capabilities and is sometimes also referred to as model falsifica-\ntion21. T o check whether Centaur survives this test, we ran open-loop \nsimulations in three different experimental paradigms and inspected \nthe distributions of statistics that resulted from these simulations. First, \nwe simulated Centaur on the horizon-task paradigm, a two-armed ban-\ndit task used to detect different types of exploration strategies20. We \nfound that Centaur (mean = 54.12, s.d. = 2.89) achieved a performance \ncomparable to human participants (mean = 52.78, s.d. = 2.90), which \n−0.6 −0.4 −0.2 0 0.2 0.4 0.6 0.8 1.0\n/uni0394 log-likelihood\nGrammar judgement\nProbabilistic instrumental learning\nTHINGS odd-one-out\nSerial reaction-time task\nBalloon analogue risk task\nMedin categorization\nShepard categorization\nWeather prediction task\nGo/no-go\nColumbia card task\nDecisions from description\nHorizon task\nZoopermarket\nTwo-armed bandit\nTwo-step task\nRecent probes\nMulti-attribute decision-making\nChanging bandit\nDecisions from experience\nN-back\nDrifting four-armed bandit\nIntertemporal choice\nchoices13k\nIowa gambling task\nConditional associative learning\nCPC18\nDigit span\nStructured bandit\nMultitask reinforcement learning\nGardening task\nMultiple-cue judgement\nSpatially correlated multi-armed bandit\nOverall\nCentaur\nLlama\nCognitive model\n0.2 0.4 0.6 0.8\nReward\n–0.5\n0\n0.5\n1.0\n1.5\nModel-basedness\n45 50 55 60\nReward\n−1\n0\n1\n2\nInformation bonus\nCentaur Humans\n0 0.5 1.0\nAccuracy (human)\n0\n0.5\n1.0\nAccuracy (arti/f_icial)\na b\nc\nd\nFig. 2 | Goodness-of-fit on Psych-101. a, Difference in log-likelihood of \nCentaur and Llama relative to a domain-specific cognitive model for each \nexperiment. A value of zero corresponds to the goodness-of-fit of the domain- \nspecific cognitive model and a value above zero indicates improved goodness- \nof-fit to human responses. Log-likelihoods are averaged over responses \n(n = 992,867). Error bars correspond to the standard error of the mean.  \nCentaur outperforms both Llama and a collection of domain-specific cognitive \nmodels in almost every experiment (one-sided t-tests: t(1,985,732) = −144.22, \nP ≤ 0.0001; t(1,985,732) = −127.58, P ≤ 0.0001, respectively). We only included \nexperiments for which we have implemented a domain-specific cognitive \nmodel in this graphic and merged different studies using the same paradigm. \nExtended Data Table 1 contains numerical results for all experiments.  \nb, Model simulations on the horizon task. The plot shows the probability \ndensities over reward and an information bonus parameter for both people  \nand simulated runs of Centaur. c , Model simulations on the two-step task.  \nThe plot shows the probability densities over reward and a parameter \nindicating how model-based learning was for both people and simulated runs \nof Centaur. d, Model simulations on a social prediction game. The plot shows \nthe probability densities over accuracies of predicting human strategies  \nand strategies of an artificial agent, with matched statistics for both people  \nand simulated runs of Centaur.\nNature | Vol 644 | 28 August 2025 | 1005\nwas supported by an equivalence test using the two one-sided t-tests \nprocedure with a ±3-point margin (P = 0.02). Centaur also engaged in a \nsimilar level of uncertainty-guided directed exploration (Fig. 2b), a pat-\ntern that is notably absent in many contemporary language models12.\nWe also observed that Centaur does not merely capture the behaviour \nof the average participant, but rather the distribution over trajectories \nproduced by the entire population. For example, in the two-step task (a \nwell-known paradigm used to tease apart model-free and model-based \nreinforcement learning19), Centaur, just like human subjects, produced \ntrajectories in which learning is purely model-free, purely model-based \nand mixtures thereof (as the bimodal distribution in Fig. 2c shows).\nFinally, we verified that Centaur fails at predicting non-human \nbehaviour. For this, we considered a study that required participants \nto predict either human responses or responses of an artificial agent \nwith matched statistics in four canonical economic games22. Mirroring \nthe results of the original human study, Centaur accurately predicted \nhuman responses (64% accuracy) but struggled to predict artificial \nresponses (35% accuracy; one-sided t-test: t(230) = 20.32, P ≤ 0.0001; \nFig. 2d). Taken together, these results demonstrate that Centaur exhib-\nits human-like characteristics across various settings, confirming that \nit can generate meaningful open-loop behaviour.\nProbing generalization abilities\nSo far, we have shown that Centaur generalizes to previously unseen \nparticipants performing experiments that were part of the training \ndata. A true foundation model of human cognition, however, must also \ncapture behaviour in any arbitrary experiment, even if that experiment \nwas not part of the training data. T o probe whether Centaur has this abil-\nity, we exposed it to a series of increasingly complex out-of-distribution \nevaluations.\nFirst, we investigated whether Centaur is robust in the face of changes \nto the cover story. For this analysis, we relied on data collected in  \nref. 23, which used the aforementioned two-step task. In addition to \nthe canonical cover story (spaceships travelling to foreign planets in \nsearch of treasures), the study introduced a new cover story involving \nmagical carpets. Importantly, Psych-101 includes experiments using \nthe canonical spaceship cover story24 but no experiments with the \nmagic-carpet cover story. Even so, we found that Centaur captured \nhuman behaviour in the magic-carpet experiment of ref. 23 (Fig. 3a). \nAs in our previous analysis, we observed an improvement after \nfine-tuning, as well as a favourable goodness-of-fit when compared with \na domain-specific cognitive model (Centaur negative log-likelihood, \n0.51; Llama negative log-likelihood, 0.63; cognitive model negative \nlog-likelihood, 0.61; one-sided t-test comparing Centaur with Llama: \nt(9,701) = −24.7, P ≤ 0.0001; one-sided t-test comparing Centaur with \nthe domain-specific cognitive model: t(9,701) = −20.7, P ≤ 0.0001; the \ndomain-specific cognitive model used in this analysis was a hybrid \nmodel that combined model-based and model-free reinforcement \nlearning)19.\nIn a second out-of-distribution evaluation, we probed whether Cen-\ntaur is robust to modifications in task structure. T o test this, we exposed \nit to a paradigm known as Maggie’s farm25. Maggie’s farm extends the \nhorizon task paradigm by adding a third option. Psych-101 encompasses \nseveral two-armed bandit experiments (including the horizon task) \nbut not Maggie’s farm or any other three-armed bandit experiments \nModi/f_ied cover story Modi/f_ied problem structure Entirely new domain\nCentaur Llama Cognitive\nmodel\nCognitive\nmodel\nCognitive\nmodel\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\nNegative log-likelihood\nCentaur Llama\n0.4\n0.6\n0.8\n1.0\n1.2\nNegative log-likelihood\nCentaur Llama\n1.5\n1.6\n1.7\n1.8\n1.9\n2.0\n2.1\n2.2Negative log-likelihood\nN/A\na b c\n51\n26\n40\n39\n51\n26\n40\n39\nRandom guessing\nRandom guessing\nRandom guessing\nFig. 3 | Evaluation in different held-out settings. a, Negative log-likelihoods \naveraged over responses ( n = 9,702) for the two-step task with a modified cover \nstory 23. b, Negative log-likelihoods averaged over responses ( n = 510,154) for a \nthree-armed bandit experiment 25. c, Negative log-likelihoods averaged over \nresponses ( n = 99,204) for an experiment probing logical reasoning 26 with \nitems based on the Law School Admission Test (LSAT). Centaur outperforms \nboth Llama and domain-specific cognitive models when faced with modified \ncover stories, problem structures and entirely new domains. N/A, not applicable. \nError bars show the s.e.m. The image in a is reproduced from ref. 23 , Springer \nNature Limited. The image in c is reproduced from Wikipedia.org .\n1006 | Nature | Vol 644 | 28 August 2025\nArticle\n(it does, however, contain multi-armed bandit experiments with more \nthan three options to choose between). Thus, this analysis provides \na test of Centaur’s robustness to structural task modifications. We \nfound that Centaur captured human behaviour on Maggie’s farm, as \nshown in Fig. 3b. We again observed a benefit of fine-tuning, as well as \na favourable goodness-of-fit compared with a domain-specific cog-\nnitive model, which did not generalize well to this setting (Centaur \nnegative log-likelihood, 0.42; Llama negative log-likelihood, 0.62; \ncognitive model negative log-likelihood, 0.98; one-sided t-test com-\nparing Centaur with Llama: t(510,153) = −204.2, P ≤ 0.0001; one-sided \nt-test comparing Centaur with the domain-specific cognitive model: \nt(510,153) = −559.8, P ≤ 0.0001).\nFinally, we investigated whether Centaur could capture human \nbehaviour even in entirely new domains. In this context, we consid-\nered a study investigating logical reasoning 26. Although Psych-101 \nincludes probabilistic and causal reasoning problems, we purposefully \nexcluded any studies involving logical reasoning. As in the previous \nanalyses, there was again a positive effect of fine-tuning (Centaur nega-\ntive log-likelihood, 1.65; Llama negative log-likelihood, 1.92; one-sided \nt-test: t(198,406) = −50.39, P ≤ 0.0001; Cohen’s d, 0.23; Fig. 3c). Note \nthat we did not compare with any domain-specific cognitive model in \nthis setting, because it is unclear how to construct a model that would \nmake any meaningful transfer from training data that does not include \nany related problems.\nWe consolidated these results by analysing Centaur on six more \nout-of-distribution experimental paradigms that were not part of the \ntraining data in any shape or form (including moral decision-making27, \neconomic games 28, naturalistic category and reward learning 29, \nbehavioural propensities 30 and a deep sequential decision task 31). \nCentaur robustly captured human behaviour in all these settings, \nwhereas smaller and non-fine-tuned models did not do so consist -\nently (Extended Data Fig. 4).\nAs well as analysing human choice data, we also examined whether \nCentaur could predict human response times. Hick’s law32 indicates that \nindividual response times are a linear function of response entropies. \nTherefore, we extracted nearly 4,000,000 response times for a sub-\nset of experiments in Psych-101 and fitted three linear mixed effects \nmodels, each predicting log-transformed response times based on \nlog-transformed response entropies derived from a different com-\nputational model. We found that the response entropies derived from \nCentaur captured a larger proportion of the variance in response times \n(conditional R2, 0.87) than those derived from Llama (conditional R2, \n0.75, log[BFCentaur, Llama] = 53,773.5) and the cognitive models (conditional \nR2, 0.77, log[BFCentaur, cognitive models] = 14,995.5), thereby highlighting Cen-\ntaur’s ability to predict measures beyond pure choice data.\nT o demonstrate that the model does not degrade on problems it \nwas pretrained for, we furthermore verified it on a collection of bench-\nmarks from the machine-learning literature33,34. We found that Centaur \nremains stable in performance-based benchmarks, even improving over \nthe base model in some of them34 (Extended Data Fig. 5a,b). Finally, \nin benchmarks that measure human alignment, we observed a shift \ntowards human-like characteristics (Extended Data Fig. 5c). Figure 4a \ndepicts this improved alignment on a low-dimensional embedding \nderived from ten behavioural metrics in CogBench, a benchmark to \ntest the cognitive abilities of large language models33.\nAlignment to human neural activity\nDespite being trained to match only human behaviour, we also won-\ndered whether Centaur’s internal representations become more \naligned with human neural activity. T o check whether this is the case, \nwe conducted two analyses in which we predicted human neural activ-\nity using the model’s internal representations35,36. We first conducted \na whole-brain analysis in which we predicted functional magnetic \nresonance imaging (fMRI) measurements of people performing the \ntwo-step task37. For this, we relied on data collected in a previous study37 \ninvolving 94 participants each making 300 choices. Participants were \ntested on either the magic-carpet cover story (which we had already \nused in one of our earlier generalization analyses) or an abstract cover \nstory. Neither of these two cover stories was part of Centaur’s training \ndata. We extracted recordings from models’ residual stream before each \nchoice and after feedback. We then aggregated human neural activity \nin each region and regressed the aggregated activity on Centaur’s inter-\nnal representations. This procedure was then repeated separately for \neach participant and region (Methods, ‘Neural alignment’). Figure 4b \nshows the resulting Pearson correlation coefficients across layers for \nboth Centaur and Llama averaged over measurements (n = 11,374). \nWe found that Centaur’s representations consistently outperformed \nLlama’s representations in predicting human neural activity (all pair-\nwise one-sided t-tests, P ≤ 0.001), indicating that fine-tuning a model \non large-scale behavioural data aligned its internal representations to \nhuman neural activity. It is worth noting that this type of analysis was \npossible only because of the expressivity of Centaur’s representations, \nand that using representations of a conventional cognitive model led \nto a substantial drop in performance (dashed line in Fig. 4b). A more \nfine-grained report of our results is given in Extended Data Fig. 6.\n−4 −2 0 2 4 6\nEmbedding dimension 1\n−4\n−2\n0\n2\n4\n6\nEmbedding dimension 2\nGPT-4\nGPT-3.5\nGPT-3\nClaude 1\nClaude 2\nClaude 3\nLlama\nCentaur\nHuman\n10 20 30 40\nLayer\n0.20\n0.25\n0.30\n0.35\n0.40Pearson correlation\nCognitive model\nCentaur Llama Control\n10 20 30 40\nLayer\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6Pearson correlation\nRef. 38\nNoise ceiling\nCentaur Llama Controla b c\nFig. 4 | Human alignment. a, Multidimensional scaling embedding of the ten \nbehavioural metrics in CogBench 33 for different models. b, Pearson correlation \ncoefficients indicating how well human neural activity in the two-step task 37 \ncan be decoded using Centaur’s internal representations extracted from \ndifferent layers. c , Pearson correlation coefficients indicating how well human \nneural activity in a sentence-reading task 38 can be decoded using Centaur’s \ninternal representations extracted from different layers. Control refers to a \nmodel that used representations extracted from a randomly initialized \ntransformer model with matched architecture.\nNature | Vol 644 | 28 August 2025 | 1007\nWe expanded these results in a second analysis, for which we relied on \na previously collected dataset involving fMRI measurements of people \nreading simple six-word sentences, such as “That is such a beautiful \npicture!”38. The primary goal of this analysis was to show that neural \nalignment in unrelated settings remains intact after fine-tuning on cog-\nnitive experiments. We focused on a subset of five participants who each \npassively read 1,000 sentences, spread across 20 experimental runs and \ntwo scanning sessions. The presented sentences were extracted from \nnine corpora and selected to maximize semantic diversity. We closely \nfollowed the protocol of the original study and predicted aggregated \nneural activity across participants in the language network. We repeated \nthis procedure for representations extracted from different layers in \nboth Centaur and Llama. Predictability peaked at around layer 20, as \nshown in Fig. 4c. This peak is consistent with the hypothesis that the \nintermediate layers of such models contain the most information. \nWe performed an inverse-weighted meta-analysis39 on the difference \nin correlations between Centaur and Llama, and this indicated that \nthere was a significant benefit of fine-tuning when pooling across lay-\ners (β = 0.007, 95% confidence interval [0.0002, 0.013], P = 0.045). \nAlthough this effect was consistent across layers, it was not statistically \nsignificant for any individual layer.\nModel-guided scientific discovery\nPsych-101 and Centaur both constitute valuable tools for scientific \ndiscovery. In the following section, we present an example of how \neach of them can be used to improve our understanding of human \ndecision-making. The individual steps of this process are illustrated \nin Fig. 5.\nPsych-101 contains human behavioural data in a natural-language \nformat, which means it can be readily processed and analysed by a \nlanguage-based reasoning model such as DeepSeek-R1 (ref. 40). T o dem-\nonstrate this use case, we asked DeepSeek-R1 to generate an explanation \nof participants’ behaviour in a multi-attribute decision-making experi-\nment41. In this paradigm, participants are given two different options \nthat are each characterized by various features (in our case, four expert \nratings for two products) and they must then decide which of the two \noptions they prefer (Fig. 5a). The model produced several explana-\ntions, one of which caught our attention: “The participant employed \na two-step decision-making strategy. First, they determined which \nproduct had the majority of positive ratings (1 s) across all experts. If \nthe products were tied in the number of positive ratings, the participant \nthen considered the rating from the highest validity expert to break the \ntie. ” This strategy combines two well-known heuristic decision-making \nstrategies that, as far as we know, have not been considered in this \ncombination before. We then took this verbal strategy, implemented \nit as a formal computational model and found that it explained human \nresponse behaviour more accurately than the three strategies consid-\nered in the original study (a weighted-additive strategy, equal weighting \nand take-the-best heuristic; Fig. 5b).\nHowever, the DeepSeek-R1-discovered model Akaike information cri-\nterion (AIC; 181.7) still fell short of the goodness-of-fit of Centaur (AIC, \n72.5), indicating that there is still room for improvement. We therefore \nused a method known as scientific regret minimization, which uses a \nblack-box predictive model as a reference to identify responses that \nare in principle predictable but are not captured by a given model42. \nTypically, scientific regret minimization requires the collection of a \nlarge-scale experiment-specific dataset to train this predictive model. \nCentaur, however, can be used out-of-the-box and without the need to \ncollect any domain-specific data, thereby circumventing this step and \nbroadening the scope of scientific regret minimization considerably \n(indeed, the multi-attribute decision-making data set under consid-\neration contained fewer than 100 participants, placing it far out of \nreach for conventional scientific regret minimization). When inspect-\ning the responses that were well predicted by Centaur but not by the \nDeepSeek-R1-discovered model, we observed that they all involved \nWeighted-additive strategy\nEqual weighting\nTake-the-best heuristic\n0\n100\n200\n300\n400AIC\n0\n100\n200\n300\n400AIC\n0\n100\n200\n300\n400AIC\nWeighted-additive strategy\nEqual weighting\nTake-the-best heuristic\nDeepSeek-R1 discovered\nWeighted-additive strategy\nEqual weighting\nTake-the-best heuristic\nDeepSeek-R1 discovered\nScienti/f_ic regret minimization\na b c\nCentaur\nExpert 1 (90%) 1 0\nExpert 2 (80%) 0 1\nExpert 3 (70%) 0 1\nExpert 4 (60%) 1 1\nDeepSeek-R1 explanation\nThe participant employed a two-step decision-making\nstrategy. First, they determined which product had the\nmajority of positive ratings (1s) across all experts. If the\nproducts were tied in the number of positive ratings, the\nparticipant then considered the rating from the highest\nvalidity expert to break the tie.\nProduct A Product B Response\n100 1 0 1 1 1 A\n0110 1 0 0 0 B\n1000 0 1 1 0 A\n0111 1 0 0 1 B\n1001 0 1 1 1 A\n0110 1 0 0 0 B\nFig. 5 | Model-guided scientific discovery. a, We used Psych-101 and  \nCentaur to guide the development of a cognitive model for a multi-attribute \ndecision-making study 41. Each panel shows the AIC for the set of models \nconsidered at the given stage, starting with the models considered in the \noriginal study. b , We asked DeepSeek-R1 to generate an explanation for the \nhuman responses and formalized the resulting verbal strategy into a formal \ncomputational model. c , We refined this model through scientific regret \nminimization using Centaur as a reference model. Six data points are shown  \nfor which Centaur makes accurate predictions but the DeepSeek-R1-discovered \nmodel does not. We then used this information to design a domain-specific \ncognitive model that is as predictive as Centaur but is still interpretable.  \nThe bicycle images in a are reproduced from Flaticon.com .\n1008 | Nature | Vol 644 | 28 August 2025\nArticle\nproblems in which participants chose the option with fewer positive \nratings overall but which was rated positively by a higher-validity \nexpert (see Fig. 5c for an illustration of these problems and Methods, \n‘Model-guided scientific discovery’ for further details). This pattern \nindicates that the switch between the two heuristics is probably not as \nstrict as initially suggested by the DeepSeek-R1-discovered strategy. \nT o capture this, we replaced the either-or rule with a weighted aver-\nage of both heuristics. We found that the model that resulted from \nthis process matched Centaur in terms of its goodness-of-fit (AIC, \n71.7) but was still interpretable. We entered the resulting AIC values \nof all the models in a group-level model-selection procedure 43 and \nestimated the protected exceedance probability, which is defined as \nthe probability that a particular model has a higher frequency within \na group than all the other candidate models. The protected exceed-\nance probability of the model that resulted from scientific regret mini-\nmization was P = 0.83. Notably, the result of this model comparison \nstands in contrast to the one that was conducted with the original set \nof models and indicates that people rely on a combination of heu -\nristics when making decisions, as opposed to following a weighted- \nadditive strategy44.\nDiscussion\nIn this paper we have introduced Centaur, a foundation model of human \ncognition that was obtained by fine-tuning a state-of-the-art language \nmodel on Psych-101, which is a large-scale dataset of human behaviour. \nThis approach allowed us to leverage the vast knowledge embedded \nin large language models and also align them with human behaviour13. \nCentaur successfully captured human behaviour and passed a wide \nrange of out-of-distribution checks. It generalized not only to unseen \nparticipants, but also to different cover stories, structural variations \nand entirely new domains. In addition to analysing the model on a \nbehavioural level, we also conducted a series of analyses on its internal \nrepresentations, in which we found increased alignment with human \nneural activity.\nWe also conducted a case study demonstrating how both Psych-101 \nand Centaur can be used for guiding the development of predictive, \nyet interpretable, cognitive models. The individual steps of our pro-\ncedure are generic, so it could serve as a blueprint for model-guided \nscientific discovery in other experimental paradigms in the future. \nLooking beyond this example, Centaur finds many more applications in \nthe context of automated cognitive science45,46. It may, for instance, be \nused for in silico prototyping of experimental studies47. In this context, \none could use the model to figure out which designs lead to the largest \neffect sizes, how to design a study to reduce the number of required \nparticipants or to estimate the power of an effect.\nThe present paper takes initial steps in leveraging Centaur to gain \ndeeper insights into human cognition, and it also opens up exciting \nnew avenues for future exploration. First, one could further probe \nCentaur’s internal representations to understand how it represents \nknowledge and processes information. The resulting insights could, \nin turn, be used to generate hypotheses about knowledge representa-\ntion and information processing in humans that could be validated \nin future experimental studies. We believe that tools such as sparse \nauto-encoders48 and attention map visualization49 provide promis-\ning avenues towards accomplishing this goal, and we hope to explore \nthem in future studies.\nFurthermore, it might also be possible to train models with differ-\nent architectures from scratch using the dataset that we created in \nthe process of this paper. Doing so would enable us to investigate \nthe neural architecture of human cognition at a scale that could not \nhave been done before. We might, for example, ask questions such \nas whether human information processing is better described by \nattention-based architectures50 or by architectures with a vector-based \nmemory, or how much we can improve by incorporating theories from \nthe neuroscience literature51. We expect an eventual outcome of such \nan approach to contain both domain-specific and domain-general \nmodules, thereby allowing us to investigate the interplay between  \nthe two.\nAs far as we know, Psych-101 is already the broadest and largest \ndataset of human behaviour available, and we view its development \nas an ongoing process and plan to develop it further. The focus in its \ncurrent state is largely on learning and decision-making, but we intend \nto eventually include more domains, such as psycholinguistics, social \npsychology and economic games. Experiments with information about \nindividual differences are another source of neglected data in the cur-\nrent iteration of Psych-101. Ideally, we want to include all types of rel-\nevant information about subjects (including age, personality traits \nor socioeconomic status) in the prompt, such that a model trained \non these data can capture individual differences. Experiments from \ndevelopmental psychology or computational psychiatry provide an \nideal source for this purpose. Finally, although we have already included \nsome cross-cultural and meta-studies52–55, the current iteration still has \na strong bias towards a Western, educated, industrialized, rich and \ndemocratic (WEIRD) population56.\nEventually, we hope to provide any psychological data in a stand-\nardized format that facilitates benchmarking, thereby comple -\nmenting existing efforts from the neuroscience community 57,58. \nAlthough the natural-language format (together with quite a bit of \nreverse-engineering) used in this work allows us to express a vast range \nof experimental paradigms, it introduces a selection bias against experi-\nments that cannot be expressed in natural language. The long-term \nobjective should therefore be to move towards a multimodal data \nformat59.\nConclusion\nWhen the idea of a unified model of cognition was first proposed, \nresearchers expressed concern that established areas of cognitive \nscience might react negatively to such a model. In particular, they feared \nthat the approach might be seen as unfamiliar or incompatible with \nexisting theories, just like an “intruder with improper pheromones”60. \nThis could lead to an “attack of the killer bees” , in which researchers in \nmore-conventional fields would fiercely critique or reject the new model \nto defend their established approaches. T o mitigate these concerns, the \nconcept of a cognitive decathlon was proposed: a rigorous evaluation \nframework in which competing models of cognition are tested across \nten experiments and judged on their cumulative performance in them. \nIn the current work, we applied Centaur to the equivalent of 16 such \ncognitive decathlons, in which it was tested against numerous estab-\nlished models and consistently won every competition. This outcome \nindicates that the data-driven discovery of domain-general models of \ncognition is a promising research direction. The next step for future \nresearch should be to translate this domain-general computational \nmodel into a unified theory of human cognition2.\nOnline content\nAny methods, additional references, Nature Portfolio reporting summa-\nries, source data, extended data, supplementary information, acknowl-\nedgements, peer review information; details of author contributions \nand competing interests; and statements of data and code availability \nare available at https://doi.org/10.1038/s41586-025-09215-4.\n1. Anderson, J. The Architecture of Cognition (Harvard Univ. Press, 1983).\n2. Newell, A. Unified Theories of Cognition (Harvard Univ. Press, 1990).\n3. Lake, B. M., Ullman, T. D., Tenenbaum, J. B. & Gershman, S. J. Building machines that learn \nand think like people. Behav. Brain Sci. 40, e253 (2017).\n4. Lake, B. M., Salakhutdinov, R. & Tenenbaum, J. B. Human-level concept learning through \nprobabilistic program induction. Science 350, 1332–1338 (2015).\n5. Goddu, M. K. & Gopnik, A. The development of human causal learning and reasoning. \nNat. Rev. Psychol. https://doi.org/10.1038/s44159-024-00300-5 (2024).\nNature | Vol 644 | 28 August 2025 | 1009\n6. Chu, J. & Schulz, L. E. Play, curiosity, and cognition. Annu. Rev. Dev. Psychol. 2, 317–343 \n(2020).\n7. Silver, D. et al. Mastering the game of Go without human knowledge. Nature 550,  \n354–359 (2017).\n8. Kahneman, D. & Tversky, A. in Handbook of the Fundamentals of Financial Decision Making \n(eds MacLean, L. C. & Ziemba, W. T.) 99–127 (World Scientific, 2013).\n9. Riveland, R. & Pouget, A. Natural language instructions induce compositional generalization \nin networks of neurons. Nat. Neurosci. 27, 988–999 (2024).\n10. Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at \nhttps://arxiv.org/abs/2108.07258 (2021).\n11. Grattafiori, A. et al. The Llama 3 herd of models. Preprint at https://arxiv.org/abs/2407.21783 \n(2024).\n12. Binz, M. & Schulz, E. Using cognitive psychology to understand GPT-3. Proc. Natl Acad. \nSci. USA 120, e2218523120 (2023).\n13. Binz, M. & Schulz, E. Turning large language models into cognitive models. In Proc. 12th \nInternational Conference on Learning Representations (ICLR, 2024).\n14. Hofman, J. M. et al. Integrating explanation and prediction in computational social \nscience. Nature 595, 181–188 (2021).\n15. Rocca, R. & Yarkoni, T. Putting psychology to the test: rethinking model evaluation \nthrough benchmarking and prediction. Adv. Methods Pract. Psychol. Sci. https://doi.org/ \n10.1177/25152459211026864 (2021).\n16. Dettmers, T., Pagnoni, A., Holtzman, A. & Zettlemoyer, L. QLORA: efficient finetuning  \nof quantized LLMs. In Proc. Advances in Neural Information Processing Systems 36  \n(eds Oh, A. et al.) (NeurIPS, 2023).\n17. Nosofsky, R. M. in Formal Approaches in Categorization (eds Pothos, E. M. & Wills, A. J.) \n18–39 (Cambridge Univ. Press, 2011).\n18. Peterson, J. C., Bourgin, D. D., Agrawal, M., Reichman, D. & Griffiths, T. L. Using large-scale \nexperiments and machine learning to discover theories of human decision-making. \nScience 372, 1209–1214 (2021).\n19. Daw, N. D., Gershman, S. J., Seymour, B., Dayan, P. & Dolan, R. J. Model-based influences \non humans’ choices and striatal prediction errors. Neuron 69, 1204–1215 (2011).\n20. Wilson, R. C., Geana, A., White, J. M., Ludvig, E. A. & Cohen, J. D. Humans use directed and \nrandom exploration to solve the explore–exploit dilemma. J. Exp. Psychol. Gen. 143, \n2074–2081 (2014).\n21. Palminteri, S., Wyart, V. & Koechlin, E. The importance of falsification in computational \ncognitive modeling. Trends Cogn. Sci. 21, 425–433 (2017).\n22. van Baar, J. M., Nassar, M. R., Deng, W. & FeldmanHall, O. Latent motives guide structure \nlearning during adaptive social choice. Nat. Hum. Behav. 6, 404–414 (2022).\n23. Feher da Silva, C. & Hare, T. A. Humans primarily use model-based inference in the \ntwo-stage task. Nat. Hum. Behav. 4, 1053–1066 (2020).\n24. Kool, W., Cushman, F. A. & Gershman, S. J. When does model-based control pay off? PLoS \nComput. Biol. 12, e1005090 (2016).\n25. Dubois, M. & Hauser, T. U. Value-free random exploration is linked to impulsivity. Nat. \nCommun. 13, 4542 (2022).\n26. Jansen, R. A., Rafferty, A. N. & Griffiths, T. L. A rational model of the Dunning–Kruger \neffect supports insensitivity to evidence in low performers. Nat. Hum. Behav. 5, 756–763 \n(2021).\n27. Awad, E. et al. The Moral Machine experiment. Nature 563, 59–64 (2018).\n28. Akata, E. et al. Playing repeated games with large language models. Nat. Hum. Behav. \nhttps://doi.org/10.1038/s41562-025-02172-y (2025).\n29. Demircan, C. et al. Evaluating alignment between humans and neural network \nrepresentations in image-based learning tasks. In Proc. Advances in Neural Information \nProcessing Systems 37 (eds Globerson, A. et al.) (NeurIPS, 2024).\n30. Singh, M., Richie, R. & Bhatia, S. Representing and predicting everyday behavior. Comput. \nBrain Behav. 5, 1–21 (2022).\n31. Xu, H. A., Modirshanechi, A., Lehmann, M. P., Gerstner, W. & Herzog, M. H. Novelty is not \nsurprise: human exploratory and adaptive behavior in sequential decision-making. PLoS \nComput. Biol. 17, e1009070 (2021).\n32. Hick, W. E. On the rate of gain of information. Q. J. Exp. Psychol. 4, 11–26 (1952).\n33. Coda-Forno, J., Binz, M., Wang, J. X. & Schulz, E. CogBench: a large language model walks \ninto a psychology lab. Proc. Mach. Learn. Res. 235, 9076–9108 (2024).\n34. Kipnis, A., Voudouris, K., Schulze Buschoff, L. M. & Schulz, E. metabench - a sparse \nbenchmark of reasoning and knowledge in large language models. In Proc. 13th International \nConference on Learning Representations (ICLR, 2025).\n35. Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural \nresponses in higher visual cortex. Proc. Natl Acad. Sci. USA 111, 8619–8624 (2014).\n36. Schrimpf, M. et al. The neural architecture of language: integrative modeling converges \non predictive processing. Proc. Natl Acad. Sci. USA 118, e2105646118 (2021).\n37. Feher da Silva, C., Lombardi, G., Edelson, M. & Hare, T. A. Rethinking model-based and \nmodel-free influences on mental effort and striatal prediction errors. Nat. Hum. Behav. 7, \n956–969 (2023).\n38. Tuckute, G. et al. Driving and suppressing the human language network using large \nlanguage models. Nat. Hum. Behav. 8, 544–561 (2024).\n39. Cochran, W. G. The combination of estimates from different experiments. Biometrics 10, \n101–129 (1954).\n40. DeepSeek-AI et al. DeepSeek-R1: incentivizing reasoning capability in LLMs via \nreinforcement learning. Preprint at https://arxiv.org/abs/2501.12948 (2025).\n41. Hilbig, B. E. & Moshagen, M. Generalized outcome-based strategy classification: comparing \ndeterministic and probabilistic choice models. Psychon. Bull. Rev. 21, 1431–1443 (2014).\n42. Agrawal, M., Peterson, J. C. & Griffiths, T. L. Scaling up psychology via scientific regret \nminimization. Proc. Natl Acad. Sci. USA 117, 8825–8835 (2020).\n43. Rigoux, L., Stephan, K. E., Friston, K. J. & Daunizeau, J. Bayesian model selection for  \ngroup studies − revisited. Neuroimage https://doi.org/10.1016/j.neuroimage.2013.08.065 \n(2014).\n44. Binz, M., Gershman, S. J., Schulz, E. & Endres, D. Heuristics from bounded meta-learned \ninference. Psychol. Rev. 129, 1042–1077 (2022).\n45. Musslick, S. et al. Automating the practice of science: opportunities, challenges, and \nimplications. Proc. Natl. Acad. Sci. USA 122, e2401238121 (2025).\n46. Rmus, M., Jagadish, A. K., Mathony, M., Ludwig, T. & Schulz, E. Generating computational \ncognitive models using large language models. Preprint at https://arxiv.org/abs/2502.00879 \n(2025).\n47. Dillion, D., Tandon, N., Gu, Y. & Gray, K. Can AI language models replace human \nparticipants? Trends Cogn. Sci. 27, 597–600 (2023).\n48. Huben, R., Cunningham, H., Smith, L. R., Ewart, A. & Sharkey, L. Sparse autoencoders find \nhighly interpretable features in language models. In Proc. 12th International Conference \non Learning Representations (ICLR, 2024).\n49. Chefer, H., Gur, S. & Wolf, L. Transformer interpretability beyond attention visualization.  \nIn Proc. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) \n782–791 (IEEE, 2021).\n50. Vaswani, A. et al. Attention is all you need. In Proc. Advances in Neural Information \nProcessing Systems 30 (eds Guyon, I. et al.) (NeurIPS, 2017).\n51. Zador, A. et al. Catalyzing next-generation artificial intelligence through NeuroAI. Nat. \nCommun. 14, 1597 (2023).\n52. Ruggeri, K. et al. The globalizability of temporal discounting. Nat. Hum. Behav. 6,  \n1386–1397 (2022).\n53. Wulff, D. U., Mergenthaler-Canseco, M. & Hertwig, R. A meta-analytic review of two modes \nof learning and the description-experience gap. Psychol. Bull. 144, 140–176 (2018).\n54. Frey, R., Pedroni, A., Mata, R., Rieskamp, J. & Hertwig, R. Risk preference shares the \npsychometric structure of major psychological traits. Sci. Adv. 3, e1701381 (2017).\n55. Enkavi, A. Z. et al. Large-scale analysis of test–retest reliabilities of self-regulation \nmeasures. Proc. Natl Acad. Sci. USA 116, 5472–5477 (2019).\n56. Henrich, J., Heine, S. J. & Norenzayan, A. Most people are not WEIRD. Nature 466, 29 (2010).\n57. Schrimpf, M. et al. Integrative benchmarking to advance neurally mechanistic models of \nhuman intelligence. Neuron 108, 413–423 (2020).\n58. Poldrack, R. A. et al. The past, present, and future of the brain imaging data structure \n(BIDS). Imaging Neurosci. 2, 1–19 (2024).\n59. Schulze Buschoff, L. M., Akata, E., Bethge, M. & Schulz, E. Visual cognition in multimodal \nlarge language models. Nat. Mach. Intell. https://doi.org/10.1038/s42256-024-00963-y \n(2025).\n60. Vere, S. A. A cognitive process shell. Behav. Brain Sci. 15, 460–461 (1992).\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in \npublished maps and institutional affiliations.\nOpen Access This article is licensed under a Creative Commons Attribution \n4.0 International License, which permits use, sharing, adaptation, distribution \nand reproduction in any medium or format, as long as you give appropriate \ncredit to the original author(s) and the source, provide a link to the Creative Commons licence, \nand indicate if changes were made. The images or other third party material in this article are \nincluded in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your \nintended use is not permitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a copy of this licence, \nvisit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2025\nArticle\nMethods\nData collection\nWe constructed Psych-101 by transcribing data from 160 psychologi-\ncal experiments into natural language. Each prompt was designed to \ninclude the entire trial-by-trial history of a complete session from a \nsingle participant. The experiments included were selected using the \nfollowing criteria: publicly available data on a trial-by-trial level; the \npossibility of transcription into text without a significant loss of infor-\nmation; and coverage of a broad spectrum of domains. The transcrip-\ntion of each experiment was done manually by the authors. Approval \nfrom the institutional review board was obtained by the individual \nstudies as required. We designed our natural-language prompts using \nthe following principles: instructions should follow the original study \nas closely as possible; simplifications were made where appropriate; \nand a maximum prompt length of roughly 32,768 tokens was used. \nFull information about all the experiments included is provided in the \nSupplementary Information, Example prompts.\nFine-tuning procedure\nLlama 3.1 70B was the base model for our fine-tuning procedure. We \nused a parameter-efficient fine-tuning technique known as QLoRA16, \nwhich adds so-called low-rank adapters to each layer of a four-bit quan-\ntized base model. The base model was kept fixed during fine-tuning and \nonly the parameters of the low-rank adapters were adjusted. We added \nlow-rank adapters of rank r = 8 to all linear layers of the self-attention \nmechanisms and the feedforward networks. Each low-rank adapter \nmodifies the forward pass as follows:\nYX WX LL\nWR LR LR\nα=+\n∈; ∈; ∈,ho hr ro\n12\n×\n1\n×\n2\n×\nwhere XW is the (quantized) linear transformation of the base model \nand XL1L2 is the low-rank adapter component, with X being the input to \nthe layer with dimensionality h and Y being the output of the layer with \ndimensionality o. The hyperparameter α controls the trade-off between \nthe two. R is the set of real numbers. Low-rank adapter computations \nwere performed in half-precision floating-point format. For further \ndetails on this technique, please see the original work16.\nWe fine-tuned the model for one epoch on the entire dataset using a \nstandard cross-entropy loss (we experimented with prolonged training \nbut found that this led to overfitting). We only back-propagated the loss \nat human responses and masked out the loss for all other tokens. The \neffective batch size was set to 32, the learning rate to 0.00005 and the \nweight decay to 0.01. We used an 8-bit AdamW optimizer61 with a linearly \nincreasing warm up over the first 100 gradient steps. The fine-tuning pro-\ncedure was implemented using the unsloth library (https://unsloth.ai/).\nWe have also trained a smaller version of Centaur, called Minitaur, that \nuses Llama 3.1 8B as the base model following the same recipe. Minitaur \ncaptures human behaviour close to its training distribution but gener-\nalizes less robustly than the larger model to out-of-distribution experi-\nments (Extended Data Fig. 7). Nevertheless, we believe that Minitaur is \nuseful for prototyping because it does not require access to any specific \nhardware (it runs, for instance, on the free GPU instances in Google Colab).\nEvaluation metric\nWe used (negative) log-likelihoods averaged over responses as our eval-\nuation metric. For experiments with multi-token responses, we summed \nlog-likelihoods within a response and averaged across responses. We \nused one-sided t-tests whenever we tested whether Centaur outper-\nformed a competing model in predicting human behaviour, because \nour hypotheses were directional and based on the prior expectation \nthat Centaur would perform better. Because the number of observa-\ntions in our analyses is generally large, reported significant effects \nsurvive after correcting for multiple comparisons where appropriate.\nDomain-specific cognitive models\nWe selected as our baseline models 14 cognitive and statistical models \nthat together cover most of the experiments in Psych-101. Further \ndetails regarding the included models and their specifications are \nprovided in Supplementary Information, Modelling details.\nFor our main analysis, we were interested in predicting the behaviour \nof held-out participants. Therefore, we fitted a joint set of parameters \nfor all participants in the training data and evaluated how well a model \nwith these parameters predicts the responses of held-out participants. \nMirroring the evaluation metric for the language-based models, we \nevaluated goodness-of-fit using (negative) log-likelihoods averaged \nover responses.\nFor the out-of-distribution evaluations, we fitted model parameters \nusing the most similar experiment in the training set, and then we evalu-\nated how well a model with the resulting parameters predicts human \nresponses in the unseen setting. The most similar experiment for  \nthe magic-carpet version of the two-step task was a two-step task  \nexperiment with the default spaceship cover story. The most similar \nexperiment for Maggie’s farm was the horizon task. We included no \nbaseline model for the logical reasoning task, because none of the \nexperiments in the training data were similar to it.\nNeural alignment\nThe neural alignment analysis on the two-step task was conducted \nusing data collected in a previous study37. We used a regularized linear \nregression model to predict fMRI data from internal representations \nof Centaur and Llama (a separate model was used for each participant \nand region). We fitted each of these models on data from two scanning \nblocks and evaluated them on data from the third. The regularization \nstrength was selected using a nested cross-validation procedure. For \neach run, we split the beta maps into cortical and subcortical regions \nof interest (ROI) using the Schaefer 2018 atlas with 100 ROIs62. We aver-\naged the betas within each ROI, reducing the number of betas from \nthe number of voxels to the number of ROIs. All cortical and subcorti-\ncal ROIs from the atlas were evaluated. Reported Pearson correlation  \ncoefficients correspond to the average across all ROIs.\nInternal representations were extracted from the models’ residual \nstream and transformed using a principal component analysis. We set \nthe number of retained components such that they explained 95% of \nthe variance.\nThe fMRI data were preprocessed using fMRIPrep 24.0 (ref. 63 ). We \nused the default settings of fMRIPrep, and all the scans were aligned \nto the MNI152NLin2009cAsym atlas 64. T o extract effect estimates for \neach subtrial of the task (such as the second step of the fifth trial, or \nthe feedback of the tenth trial), we built separate general linear mod -\nels (GLMs). Each GLM included the subtrial of interest as a separate \nregressor, whose z-scored beta estimates were used for the alignment \nanalysis. This part of the data was not modelled using other regres-\nsors. Furthermore, we included different regressors capturing all \nthe first steps, all the second steps and all the feedback steps. Finally, \nwe used six rotation and translation estimates as well as framewise \ndisplacement as noise regressors. The haemodynamic response was \nmodelled using the spm 65 model. A high-pass filter of 0.01 Hz and a \nGaussian kernel with 6 mm full-width at half-maximum was applied. \nThe GLMs were built using nilearn 66.\nThe neural alignment analysis on the sentence-reading task was \nconducted using publicly available code from the original study38. No \nother changes were made apart from replacing GPT2-XL with Centaur \nand Llama. Please see the original study38 for further details.\nModel-guided scientific discovery\nIn our model-guided scientific discovery analysis, we focused on par -\nticipants in the test set to avoid any potential contamination issues. \nWe fitted parameters of all cognitive models individually for each \nparticipant using a maximum-likelihood estimation. Models were \ncompared with each other using the AIC. The three models from \nthe original study were implemented by the following equations:\nβ\nβ\nβ\np(a= A| ,, WADD) ∝e xp(⋅ )\n=[ 0.9, 0.8, 0.7, 0.6]\np(a= A| ,, EW)∝ exp( ⋅)\n=[ 1, 1, 1, 1]\np(a= A| ,, TTB)∝ exp( ⋅)\n=[ 1, 0.5, 0.25,0 .125]\n,\nAB WADD A\nWADD\nAB EW A\nEW\nAB TTB A\nTTB\nxx wx\nw\nxx wx\nw\nxx wx\nw\n/uni22A4\n/uni22A4\n/uni22A4\nwhere xA and xB are vectors containing four expert ratings (either 0  \nor 1) and β is a free parameter controlling the noise level.\nWe prompted DeepSeek-R1 (in the Distill-Llama-70B variant) to gener-\nate explanations of human decision-making; the corresponding prompt \nis provided in Supplementary Information, Model-guided scientific \ndiscovery. We then formalized the explanation shown in Fig. 5b into \nthe following computational model:\n\n\n\n/uni22A4\n/uni22A4\n∑∑\npa\nβ\nβ\n(= A, |, ,D eepSeek −R 1) ∝\nexp( ⋅) ,i f=\nexp( ⋅) ,e lse\niiAB\nTTB AA ,i B, i\nEW A\nxx\nwx xx\nwx\nFor the scientific regret minimization pipeline, we computed the \ndifference in log-likelihoods between Centaur and the DeepSeek-  \nR1-discovered model. We visualized and inspected the ten data points \nwith the greatest difference. This process resulted in the following \ncomputational model:\n/uni22A4/uni22A4βσ σp(a= A| ,, SRM) ∝e xp(⋅ (⋅ +( 1− )⋅ ))AB TTB AE WAxx wx wx\nwhere σ is a free parameter constrained between 0 and 1 that controls \nthe trade-off between the two strategies.\nReporting summary\nFurther information on research design is available in the Nature Port-\nfolio Reporting Summary linked to this article.\nData availability\nPsych-101 is publicly available on the Huggingface platform at https://\nhuggingface.co/datasets/marcelbinz/Psych-101. The test set is accessi-\nble under a CC-BY-ND-4.0 licence through a gated repository at https://\nhuggingface.co/datasets/marcelbinz/Psych-101-test.\nCode availability\nCentaur is available on the Huggingface platform at https://huggingface.\nco/marcelbinz/Llama-3.1-Centaur-70B-adapter. The extra code needed \nto reproduce our results is available at https://github.com/marcelbinz/ \nLlama-3.1-Centaur-70B.\n \n61. Loshchilov, I. & Hutter, F. Decoupled weight decay regularization. In Proc. 7th International \nConference on Learning Representations (ICLR, 2019).\n62. Schaefer, A. et al. Local-global parcellation of the human cerebral cortex from intrinsic \nfunctional connectivity MRI. Cereb. Cortex 28, 3095–3114 (2018).\n63. Esteban, O. et al. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat. \nMethods 16, 111–116 (2019).\n64. Fonov, V. S., Evans, A. C., McKinstry, R. C., Almli, C. R. & Collins, D. L. Unbiased nonlinear \naverage age-appropriate brain templates from birth to adulthood. Neuroimage 47, S102 \n(2009).\n65. Friston, K. J., Ashburner, J. T., Kiebel, S. J., Nichols, T. E. & Penny, W. D. (eds) Statistical \nParametric Mapping: The Analysis of Functional Brain Images (Elsevier, 2011).\n66. Gau, R. nilearn. GitHub https://github.com/nilearn/nilearn (2024).\n67. Yax, N., Oudeyer, P.-Y. & Palminteri, S. Assessing contamination in large language  \nmodels: introducing the LogProber method. Preprint at https://arxiv.org/abs/2408.14352 \n(2024).\n68. Warner, B. et al. Smarter, better, faster, longer: a modern bidirectional encoder for fast, \nmemory efficient, and long context finetuning and inference. Preprint at https://arxiv.org/\nabs/2412.13663 (2024).\n69. Wang, Z. et al. HelpSteer2-Preference: complementing ratings with preferences. In Proc. \n13th International Conference on Learning Representations (ICLR, 2025).\n70. Teknium, R., Quesnelle, J. & Guang, C. Hermes 3 technical report. Preprint at https://arxiv.\norg/abs/2408.11857 (2024).\n71. Lin, S., Hilton, J. & Evans, O. TruthfulQA: measuring how models mimic human \nfalsehoods. In Proc. 60th Annual Meeting of the Association for Computational  \nLinguistics (eds Muresan, S. et al.) 3214–3252 (Association for Computational \nLinguistics, 2022).\nAcknowledgements Funding was from the Max Planck Society (to P.D.), the Humboldt \nFoundation (to P.D.), the Volkswagen Foundation (to E.S.) and the NOMIS Foundation  \n(to T.L.G.). P.D. is a member of the Machine Learning Cluster of Excellence (EXC number \n2064/1, project number 39072764) and of the Else Kröner Medical Scientist Kolleg ‘ClinbrAIn: \nArtificial Intelligence for Clinical Brain Research’. This work was supported by the Helmholtz \nAssociation’s Initiative and Networking Fund on the HAICORE@FZJ partition. S.K. is supported \nby a Google PhD Fellowship. No researchers at Google DeepMind used Llama for this research. \nWe thank N. Scharfenberg for contributions to the data collection.\nAuthor contributions Project lead: M. Binz. Data curation: E.A., F.B., M. Binz, F.C., J.C.-F., C.D., \nM.K.E., N.É., S.H., A.K.J., L.J.-A., A.K., S.K., T.L., S.S.N., J.C.P., E.M.R., T.S., J.A.S., L.M.S.B., N.S., \nX.S., M.T., V.T., K.W., S.W., D.U.W. and H.X. Data quality control: E.A., M. Binz, J.C.-F., C.D., S.H.  \nand L.M.S.B. Model training: M. Binz and V.U. Model evaluation: M. Binz, J.C.-F., A.K., M.T. and \nK.V. Domain-specific models: M. Binz, J.C.-F., C.D., A.K.J., M. Mathony, A.M., M.R. and T.L.  \nNeural analyses: M. Binz, C.D., S.K., M. Mattar and E.M.R. First draft: M. Binz and E.S. Conception \nand design: M. Binz, M. Bethge, P.D., T.L.G., M. Mattar, F.J.T., R.W. and E.S. Review and editing: \nM. Binz, E.A., M. Bethge, F.B., F.C., J.C.-F., P.D., C.D., M.K.E., N.É., T.L.G., S.H., A.K.J., L.J.-A., A.K., \nS.K., T.L., M. Mathony, M. Mattar, A.M., S.S.N., J.C.P., M.R., E.M.R., T.S., J.A.S., L.M.S.B., N.S., X.S., \nM.T., F.J.T., V.T., V.U., K.V., R.W., K.W., S.W., D.U.W., H.X. and E.S.\nFunding Open access funding provided by Helmholtz Zentrum München - Deutsches \nForschungszentrum für Gesundheit und Umwelt (GmbH).\nCompeting interests F.J.T. consults for Immunai, CytoReason, Cellarity, BioTuring and Genbio.\nAI, and has an ownership interest in Dermagnostix and Cellarity. The remaining authors declare \nno competing interests.\nAdditional information\nSupplementary information The online version contains supplementary material available at \nhttps://doi.org/10.1038/s41586-025-09215-4.\nCorrespondence and requests for materials should be addressed to Marcel Binz.\nPeer review information Nature thanks Russell Poldrack, Giosue Baggio and the other, \nanonymous, reviewer(s) for their contribution to the peer review of this work.\nReprints and permissions information is available at http://www.nature.com/reprints.\nArticle\nExtended Data Fig. 1 | Psych-101. a, Proportion of domains included in \nPsych-101. b, Word cloud of experimental paradigms included in Psych-101.  \nc, We performed a data contamination analysis using the LogProber method 67 \nfor every experimental paradigm in Psych-101. LogProber fits a two-parameter \nexponential model to the cumulative log-likelihood of each sequence being \nchecked for contamination. High acceleration (log B) suggests that a prompt  \nis memorized from the pretraining data. Following the results presented in  \nthe original work67, we set a threshold for possible contamination to log B ≥ 1. \nThis analysis indicated no evidence of contamination. d , Two-dimensional \nembedding of the experiments used in this paper. To obtain this embedding, \nwe took the corresponding natural language prompts up to the point of the \nfirst human choice, extracted a vector-based representation for them using \nModernBERT68, and finally projected these representations onto two dimensions \nusing multidimensional scaling. Purple dots correspond to experiments from \nPsych-101, whereas the colored dots correspond to the indicated evaluation \nexperiment.\nExtended Data Fig. 2 | Negative log-likelihoods of Centaur and alternative \nLlama variants on Psych-101.  To rule out the hypothesis that finetuning on  \nany data aligns a model with human behavior, we compared Centaur to various \nLlama variants finetuned for other purposes (i.e. non-cognitive tasks). \nNemotron 69 is finetuned for instruction-following. Hermes 70 is finetuned for \nvarious purposes, including agentic capabilities, roleplaying, reasoning, multi-  \nturn conversation, and long context coherence. Reflection is finetuned for \nreasoning. None of the Llama variants captures human behavior better than \nthe base model, ruling out the hypothesis that finetuning generally leads to \nmodels that are better at predicting human behavior. Error bars correspond  \nto the standard error of the mean, taken over responses.\nArticle\nExtended Data Fig. 3 | Noise ceiling analysis. We conducted a noise  \nceiling analysis to better understand the capabilities of Centaur. It is not \nstraightforward to estimate the noise ceiling for experiments with sequential \ndependencies, which includes the majority of Psych-101. Hence, we focused on \ntwo experiments for which such an analysis is possible: a , the choices13k data \nset18 and b, an intertemporal choice experiment 52. In both cases, we found that \nCentaur substantially exceeds the estimated noise ceiling. This is possible \nbecause Centaur can pick up on context-dependent patterns that are not \ncaptured by standard noise ceiling analyses. Therefore, we have performed an \nadditional analysis testing how well Centaur can predict human responses if  \nwe prompt it to predict each response independently. We use the suffix “ind.” \nto indicate this way of prompting the model. Centaur still matches the \nperformance of domain-specific cognitive models when context-independent \nprompts are used, amounting to roughly half of the estimated noise ceiling.\nExtended Data Fig. 4 | Further out-of-distribution evaluations. Each  \nsubplot shows negative log-likelihoods for a different experiment. None of \nthese paradigms were included in Psych-101, hence they provide a stress test \nfor a model’s generalization capabilities. Centaur robustly captured human \nbehavior in all of these settings, while smaller and non-finetuned models  \ndid not do so consistently. Error bars correspond to the standard error  \nof the mean, taken over responses. We state one-sided t-tests comparing  \nthe negative log-likelihoods of Centaur to those of Llama in brackets.  \na, Negative log-likelihoods on moral decision-making 27 (t(181388) = −103.54, \np ≤ 0.0001). b, Negative log-likelihoods on economic games 1 (t(7798) = −11.69, \np ≤ 0.0001). c, Negative log-likelihoods on naturalistic category learning 1 \n(t(21838) = −14.05, p ≤ 0.0001). d, Negative log-likelihoods on behavioral \npropensities 30 (t(156230) = −11.06, p ≤ 0.0001). e , Negative log-likelihoods on \nnaturalistic reward learning 1 (t(9838) = −12.63, p ≤ 0.0001). f, Negative log- \nlikelihoods on a deep sequential decision task 31 (t(6092) = −1.06, p = 0.144).\nArticle\nExtended Data Fig. 5 | metabench and CogBench results. a, Results for \nmetabench 34, a sparse benchmark containing several canonical benchmarks \nfrom the machine learning literature. We find that Centaur maintains the level \nof performance of Llama, indicating that finetuning on human behavior did not \nlead to deterioration in other tasks (ARC: z = −0.126, p = 0.9, GSM8K: z = −0.529, \np = 0.597, HellaSwag: z = 0.0, p = 1.0, MMLU: z = 0.0, p = 1.0, Winogrande: \nz = −0.556, p = 0.578). Performance on TruthfulQA 71 – which measures how \nmodels mimic human falsehoods – even improved significantly with finetuning \n(z = 2.312, p = 0.021; all z-test were two-sided). b , Performance-based metrics \nfrom CogBench 33, a benchmark that includes ten behavioral metrics derived \nfrom seven cognitive psychology experiments. We find that – relative to Llama – \nCentaur’s performance improves in all experiments (Probabilistic reasoning: \nz = 6.371, p ≤ 0.0001, Horizon task: z = 22.176, p ≤ 0.0001, Restless bandit: \nz = 7.317, p ≤ 0.0001, Instrumental learning: z = 0.126, p = 0.45, Two-step task: \nz = 1.458, p = 0.072, Balloon analog risk task: z = 1.496, p = 0.067; all z-test were \none-sided). c, Behavioral metrics from CogBench. We observe that Centaur \nbecomes more similar to human subjects in all ten behavioral metrics (Prior \nweighting: z = 2.176, p = 0.015, Likelihood weighting: z = 1.131, p = 0.129, \nDirected exploration: z = 0.525, p = 0.3, Random exploration: z = 2.014, \np = 0.022, Meta-cognition: z = 2.206, p = 0.014, Learning rate: z = 0.477, \np = 0.317, Optimism bias: z = 0.78, p = 0.218, Model-basedness: z = 9.608, \np ≤ 0.0001, Temporal discounting: z = 2.594, p = 0.005, Risk taking: z = 1.612, \np = 0.053; all z-test were one-sided).\nExtended Data Fig. 6 | Finegrained neural alignment results in the two-step \ntask.  a, Pearson correlation coefficients between the predicted activity  \nfrom Centaur’s representations and the BOLD data shown on a surface brain \n(image created with nilearn 66). Centaur achieves the most accurate predictions \nin the left motor cortex. As participants performed the task with their right \nhand in the scanner, this effect may be explained by Centaur’s strong \nperformance in predicting choices. b , Predictive performance of Centaur’s \nrepresentations against alternatives for ROIs that have been identified as \nbehaviorally relevant in previous work. Cortical scores are averaged over the \ncorresponding bilateral parcels in the Schaefer atlas. The accumbens is defined \nbased on the Harvard-Oxford atlas. Pearson correlation coefficients are  \nshown for layer 20 but exhibit a similar pattern across all layers. Centaur \noutperformed Llama and the cognitive model in predicting activity in \naccumbens, the ROI from the original study that showed a reward prediction \nerror effect 19,37. We found a similar pattern in the medial PFC, another region \nthat showed an effect in the original article 37, as well as in the sensory and  \nmotor cortices.\nArticle\nExtended Data Fig. 7 | Log-likelihood comparison between Centaur and \nMinitaur on the analyses from the main text. a, Negative log-likelihoods \nrelative to the domain-specific cognitive models on held-out participants from \nPsych-101. Error bars correspond to the standard error of the mean, taken over \nresponses. b, Negative log-likelihoods for the two-step task with a modified \ncover story. c, Negative log-likelihoods for a three-armed bandit experiment. \n d, Negative log-likelihoods for an experiment probing logical reasoning with \nitems based on the Law School Admission Test (LSAT).\nExtended Data Table 1 | Psych-101 metrics\nFull negative log-likelihoods on held-out participants.\n\n\n\n",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6521016359329224
    },
    {
      "name": "Cognition",
      "score": 0.6286888122558594
    },
    {
      "name": "Range (aeronautics)",
      "score": 0.6248360276222229
    },
    {
      "name": "Task (project management)",
      "score": 0.5765426754951477
    },
    {
      "name": "Computational model",
      "score": 0.5600310564041138
    },
    {
      "name": "Scale (ratio)",
      "score": 0.47957390546798706
    },
    {
      "name": "Artificial intelligence",
      "score": 0.41983097791671753
    },
    {
      "name": "Cognitive science",
      "score": 0.4124099910259247
    },
    {
      "name": "Psychology",
      "score": 0.1836496889591217
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Composite material",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Materials science",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I3018134672",
      "name": "Helmholtz Zentrum München",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I8087733",
      "name": "University of Tübingen",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210112925",
      "name": "Max Planck Institute for Biological Cybernetics",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I40120149",
      "name": "University of Oxford",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210090411",
      "name": "DeepMind (United Kingdom)",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I4210113297",
      "name": "Google (United Kingdom)",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I20089843",
      "name": "Princeton University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210130445",
      "name": "Max Planck Institute for Human Cognitive and Brain Sciences",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I36258959",
      "name": "University of California, San Diego",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I111088046",
      "name": "Boston University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I31512782",
      "name": "Technical University of Darmstadt",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I241749",
      "name": "University of Cambridge",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I130701444",
      "name": "Georgia Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1850255",
      "name": "University of Basel",
      "country": "CH"
    },
    {
      "id": "https://openalex.org/I4210120221",
      "name": "Max Planck Institute for Human Development",
      "country": "DE"
    }
  ]
}