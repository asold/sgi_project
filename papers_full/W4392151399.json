{
  "title": "Improving the use of LLMs in radiology through prompt engineering: from precision prompts to zero-shot learning",
  "url": "https://openalex.org/W4392151399",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4220480546",
      "name": "Maximilian Frederik Russe",
      "affiliations": [
        "University Medical Center Freiburg"
      ]
    },
    {
      "id": "https://openalex.org/A2231148827",
      "name": "Marco Reisert",
      "affiliations": [
        "University Medical Center Freiburg"
      ]
    },
    {
      "id": "https://openalex.org/A2276367651",
      "name": "Fabian Bamberg",
      "affiliations": [
        "University Medical Center Freiburg"
      ]
    },
    {
      "id": "https://openalex.org/A2110635109",
      "name": "Alexander Rau",
      "affiliations": [
        "University Medical Center Freiburg"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4377010595",
    "https://openalex.org/W4388869628",
    "https://openalex.org/W4388594599",
    "https://openalex.org/W4313447794",
    "https://openalex.org/W4385714479",
    "https://openalex.org/W4386287921",
    "https://openalex.org/W4367626167",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W2973708120",
    "https://openalex.org/W4322760437",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4353007316",
    "https://openalex.org/W2932592714",
    "https://openalex.org/W4385230595",
    "https://openalex.org/W2977601947",
    "https://openalex.org/W2921498258",
    "https://openalex.org/W4381953225"
  ],
  "abstract": "Purpose Large language models (LLMs) such as ChatGPT have shown significant potential in radiology. Their effectiveness often depends on prompt engineering, which optimizes the interaction with the chatbot for accurate results. Here, we highlight the critical role of prompt engineering in tailoring the LLMs’ responses to specific medical tasks. Materials and Methods Using a clinical case, we elucidate different prompting strategies to adapt the LLM ChatGPT using GPT4 to new tasks without additional training of the base model. These approaches range from precision prompts to advanced in-context methods such as few-shot and zero-shot learning. Additionally, the significance of embeddings, which serve as a data representation technique, is discussed. Results Prompt engineering substantially improved and focused the chatbot’s output. Moreover, embedding of specialized knowledge allows for more transparent insight into the model’s decision-making and thus enhances trust. Conclusion Despite certain challenges, prompt engineering plays a pivotal role in harnessing the potential of LLMs for specialized tasks in the medical domain, particularly radiology. As LLMs continue to evolve, techniques like few-shot learning, zero-shot learning, and embedding-based retrieval mechanisms will become indispensable in delivering tailored outputs. Key Points Citation Format",
  "full_text": "Improving the use of LLMs in radiology through prompt engineering:\nfrom precision prompts to zero-shot learning\nVerbesserung des Einsatzes von Großen Sprachmodellen in der\nRadiologie durch „Prompt Engineering“: von präzisen Prompts zu\nZero-Shot Learning\nAuthors\nMaximilian Frederik Russe, Marco Reisert, Fabian Bamberg, Alexander Rau\nAffiliations\nDepartment of Radiology, University Hospital Freiburg,\nFreiburg, Germany\nKeywords\nradiology, artificial Intelligence, natural Language Processing\nreceived 24.10.2023\naccepted 30.1.2024\npublished online 26.2.2024\nBibliography\nFortschr Röntgenstr 2024; 196: 1166–1170\nDOI 10.1055/a-2264-5631\nISSN 1438-9029\n© 2024. Thieme. All rights reserved.\nGeorg Thieme Verlag KG, Rüdigerstraße 14,\n70469 Stuttgart, Germany\nCorrespondence\nDr. Alexander Rau\nDepartment of Diagnostic and Interventional Radiology,\nUniversitätsklinikum Freiburg Klinik für Radiologie, Breisacher\nStraße 64, 79106 Freiburg, Germany\nTel.: +49 761 270 38190\nalexander.rau@uniklinik-freiburg.de\nABSTRACT\nPurpose Large language models ( LLMs) such as ChatGPT\nhave shown significant potential in radiology. Their effective-\nness often depends on prompt engineering, which optimizes\nthe interaction with the chatbot for accurate results. Here, we\nhighlight the critical role of prompt engineering in tailoring\nthe LLMs’responses to specific medical tasks.\nMaterials and Methods Using a clinical case, we elucidate\ndifferent prompting strategies to adapt the LLM ChatGPT\nusing GPT4 to new tasks without additional training of the\nbase model. These approaches range from precision prompts\nto advanced in-context methods such as few-shot and zero-\nshot learning. Additionally, the significance of embeddings,\nwhich serve as a data representation technique, is discussed.\nResults Prompt engineering substantially improved and fo-\ncused the chatbot’s output. Moreover, embedding of specia-\nlized knowledge allows for more transparent insight into the\nmodel’s decision-making and thus enhances trust.\nConclusion Despite certain challenges, prompt engineering\nplays a pivotal role in harnessing the potential of LLMs for spe-\ncialized tasks in the medical domain, particularly radiology. As\nLLMs continue to evolve, techniques like few-shot learning,\nzero-shot learning, and embedding-based retrieval mecha-\nnisms will become indispensable in delivering tailored out-\nputs.\nKey Points\n▪ Large language models might impact radiological practice\nand decision-masking.\n▪ However, implementation and performance are depen-\ndent on the assigned task.\n▪ Optimization of prompting strategies can substantially\nimprove model performance.\n▪ Strategies for prompt engineering range from precision\nprompts to zero-shot learning.\nCitation Format\n▪ Russe MF, Reisert M, Bamberg F et al. Improving the use of\nLLMs in radiology through prompt engineering: from pre-\ncision prompts to zero-shot learning . Fortschr Röntgenstr\n2024; 196: 1166–1170\nZUSAMMENFASSUNG\nZiel Große Sprachmodelle (engl. LLMs) wie ChatGPT haben\nein erhebliches Potenzial in der Radiologie gezeigt. Ihre Effek-\ntivität hängt oft vom sog. Prompt-Engineering ab, das die\nInteraktion mit der künstlichen Intelligenz für genaue Ergeb-\nnisse optimiert. Hier wird die kritische Rolle des Prompt-Engi-\nneerings bei der Anpassung der Antworten der LLMs an spezi-\nfische medizinische Aufgaben hervorgehoben.\nMaterial und Methoden Anhand eines klinischen Falles\nerläutern wir verschiedene Prompting-Strategien zur Anpas-\nsung des LLM ChatGPT mit GPT4 an neue Aufgaben ohne zu-\nsätzliches Training des Basismodells. Diese Ansätze reichen\nvon präzisierten Prompts bis hin zu fortgeschrittenen In-Kon-\ntext-Methoden wie „few-shot“-u n d„zero-shot “-Lernen. Zu-\nsätzlich wird die Bedeutung des„Embeddings “ als Datenre-\npräsentationstechnik diskutiert.\nTechnical Innovations\n1166 Russe MF et al. Improving the use… Fortschr Röntgenstr 2024; 196: 1166–1170 | © 2024. Thieme. All rights reserved.\nThis document was downloaded for personal use only. Unauthorized distribution is strictly prohibited.\nArticle published online: 2024-02-26\nErgebnisse Das Prompt-Engineering verbesserte und fokus-\nsierte den Output des Chatbots erheblich. Darüber hinaus\nermöglicht die Einbettung von Fachwissen einen transparen-\nteren Einblick in die Entscheidungsfindung des Modells und\nstärkt so das Vertrauen.\nSchlussfolgerung Trotz gewisser Herausforderungen spielt\ndas Prompt-Engineering eine zentrale Rolle bei der Nutzung\ndes Potenzials von LLMs für spezialisierte Aufgaben im medizi-\nnischen Bereich, insbesondere in der Radiologie. Im Zuge der\nWeiterentwicklung von LLMs werden Techniken wie„few-shot\nlearning“, „zero-shot learning“ und „Embedding“ für die Bereit-\nstellung maßgeschneiderter Ergebnisse unverzichtbar werden.\nKernaussagen\n▪ Große Sprachmodelle könnten die radiologische Routine\nund Entscheidungsfindung beeinflussen.\n▪ Die Implementierung und Leistung hängen jedoch von der\nzugewiesenen Aufgabe ab.\n▪ Die Optimierung von Prompting-Strategien kann die Mod-\nellleistung erheblich verbessern.\n▪ Strategien für das Prompt-Engineering reichen von Präzi-\nsion-Prompts bis zum Zero-Shot-Lernen.\nMain Body\nHuman interaction is primarily governed by language, a system\ntraditionally reserved for human use due to its complexity. Recent\nadvances in algorithms based on the transformer architecture,\nhowever, leveraged artificial intelligence (AI) to understand and\ngenerate human-like text, especially those using large language\nmodels (LLMs). These models have the potential to revolutionize\ncommunication by processing human language. A recent break-\nthrough in this regard was the release of the chatbot ChatGPT\ninto broad use by OpenAI in November 2022 [1]. While its recrea-\ntional applications are notable, its potential extends well beyond\nentertainment. It has shown considerable promise in data-inten-\nsive fields, particularly in medicine and especially within radiology.\nApplications include passing the United States Medical Licen-\nsing Examination [2], simplifying radiology reports [3–6], extract-\ning information from oncology notes [7], and classifying fractures\nbased on free-text reports [8].\nA particular challenge in the interaction with LLMs like general\nconversational chatbots is to focus the model on the particular\ntask. This guidance is done by means of the input– the so-called\nprompt. The selection of the prompt to the model has great influ-\nence on whether the problem is processed in the targeted man-\nner. Prompt engineering optimizes this interaction [9, 10].\nFor example, instead of a generic question such as“Tell me\nabout atypical pneumonia ”, a more nuanced prompt might be\n“Provide a detailed explanation of atypical pneumonia as opposed\nto typical pneumonia findings on CT scans”.I na d d i t i o n ,r o l e -\nbased prompting can be used to encourage the model to gener-\nate responses from a particular perspective, like that of an expert\nor novice, e. g.,“You are ChatGPT a subspecialized thoracic radiol-\nogist ”. Furthermore, audience-aware prompts can guide the\nmodel to tailor the response based on the intended recipients,\nwhether they are specialists in a field or laypeople. For example,\nthe latter would require a prompt like“Give your answer in easy\nlanguage ” to reduce the complexity and medical jargon. These\nadaptations add layers of customization that ensure more targe-\nted and useful output [3].\nLLMs can be designed to recognize and parse free-text radiolo-\ngy reports, extracting key findings, measurements, and anatomi-\ncal regions. For example, if a report mentions“a3 . 5 c mm a s si n\nthe upper lobe of the right lung,” the LLM can categorize this as\na “finding” with specific attributes (location, size, etc.) Once the\ninformation is extracted, LLMs can automatically populate struc-\ntured report templates, and even be used to accelerate the devel-\nopment of other non-language-based deep learning approaches\n[11].\nAs foundational as prompt engineering is, it sets the stage for\nmore adaptive methodologies like few-shot learning, where the\nAI’s adaptability is challenged beyond structured guidance.\nReminiscent of traditional supervised learning, few-shot learn-\ning allows for an adaptive approach in the context of the question.\nWhile prompt engineering relies primarily on guiding the model\nwith meticulously crafted queries, few-shot learning allows the\nmodel to adapt to new tasks, even with a very limited set of exam-\nples [12, 13].\nImagine a scenario in which a medical AI system receives a ser-\nies of structured examples such as“Calcified nodule = Benign”,\n“Pneumonia = Benign”, “Spiculated mass = Malignant ”.A f t e r\nthese few examples, using few-shot learning principles, the sys-\ntem might deduce the response of the query “Infiltrating tu-\nmor = ?” to be“Malignant”. This decision is made not only based\non extensive knowledge about radiological findings (incorporated\nin the general training data) but by recognizing patterns in the\nprovided examples and extrapolating from them.\nSuch an approach is paramount to the medical world, especial-\nly when dealing with rare diseases or novel treatments in which\nlarge amounts of data are lacking. Instead of requiring an\nimmense amount of data or operating in the absence of direct ex-\nperience, few-shot learning leverages these handful of examples\nto generate insight.\nZero-shot learning further extends this approach and is a pivo-\ntal advancement of artificial intelligence, especially in the context\nof LLM. In contrast to traditional machine learning paradigms,\nzero-shot learning empowers models to execute tasks they\nhaven’t been directly trained for. Rather than relying on specific\nlabeled data for every task, these models leverage their vast gen-\neral knowledge and specific context provided in the prompt for\noutput generation [13, 14].\nSuch an approach could have been employed in the early days\nof the COVID-19 outbreak, when knowledge about the virus was\nscarce. A medical professional could present a detailed descrip-\n1167Russe MF et al. Improving the use… Fortschr Röntgenstr 2024; 196: 1166–1170 | © 2024. Thieme. All rights reserved.\nThis document was downloaded for personal use only. Unauthorized distribution is strictly prohibited.\n\ntion of a patient’ss y m p t o m sa n dm e d i c a lh i s t o r yt oa nL L M .\nTogether with the patient-related information, specialized knowl-\nedge would be introduced with free-text information from a re-\ncent research paper detailing the symptoms of the emerging\nvirus. In response to the query“Does this patient have symptoms\nconsistent with COVID-19?”, the LLM could cross-reference the\nprovided information and recognize patterns consistent with the\ndescribed symptoms of the virus – even without explicit prior\ntraining or data on COVID-19-related information. Using this\nzero-shot learning, the LLM might respond as follows: “The\npatient ’s symptoms align closely wi th those described for\nCOVID-19 in the provided research”. The ability to make informed\ndecisions in the absence of direct task-related training sets zero-\nshot learning apart from traditional learning techniques [13].\nEmbeddings are fundamental to enable artificial intelligence to\nautomatically retrieve content for zero-shot learning instead of\nmanually selecting the data. These embeddings are a form of\ndata representation, where complex data such as text, is conver-\nted into vectors in a multi-dimensional space. These numerical\nvectors capture the context, semantics, and relationships inher-\nent in the original data [15]. This leads to an alternative approach\nof retrieving relevant content: Instead of searching through data\nusing traditional keyword-based methods, it employs the vector-\nized embeddings to reveal related content by mathematically de-\nducing the nearest neighbor in the semantic meaning. In medical\nsettings, the implications are profound. By converting a patient’s\nsymptoms and medical history into embeddings, the system\ncould browse a vector library to retrieve related articles, research\npapers, or even similar patient cases [7, 8, 16]. Embeddings thus\ncan ensure that the LLM receives the most relevant and contex-\ntually appropriate information, allowing for superior output crea-\ntion. Moreover, the accessed information in the vector library can\nbe curated and easily updated to the local needs. With respect to\nthe growing volume of medical data, such vector-based retrieval\nmechanisms will become indispensable tools for both medical\nprofessionals and researchers.\nAn overview of these strategies is given in▶ Fig. 1and the re-\nspective potential to optimize output is illustrated with a clinical\ne x a m p l ec a s er e q u i r i n gi m a g i n gi n▶ Table 1.P l e a s en o t et h a t\nonly the precision prompt recommended an unnecessary proce-\ndure (non-contrast CT), which highlights the potential of more\nadvanced prompting strategies.\nIn general, prompting an LLM in a radiological setting might\ncomprise the following:\n1. Task and Role: Concisely name the task and define the inten-\nded role of the LLM.\n2. Contextual Setup (if applicable): Provide relevant context or\nthe background information necessary for the task enabling\nfew/zero-shot learning.\n3. Task-Specific Instructions: Give concise, direct instructions\nrelated to the specific task at hand.\n4. Output Format Specification: Define how you want the output\nto be structured. This can include the level of detail, the format\nof the response, or any specific points or structure that need to\nbe addressed.\n5. Cautionary Note: Include any cautionary notes to prevent\novercomplication or misunderstanding of the task.\n6. User Data Input Specification: Clearly specify what data or\ninformation is being input, whether it’s textual descriptions,\nimage summaries, patient history, etc.\nFor example, a precision prompt to simplify radiology reports\ncould include:\n▪ Task and Role: Medical Report Simplifier for simplifying radiol-\nogy reports.\n▪ Instructions: Please rewrite the following technical radiology\nreport in a simplified version that can be easily understood by a\nnon-specialist audience. Focus on clarity and brevity while re-\ntaining all critical medical information.\n▪ Output Format: A simplified, concise, and non-technical sum-\nmary of the report.\n▪ Cautionary Note: The target audience does not have a medical\nbackground, so avoid medical terms.\n▪ Input: [Insert full text of the radiology report]\nIn contrast, the prompt for a knowledge retrieval-based prompt\nfor the differential diagnosis using image descriptions would look\nlike this:\n▪ Task and Role: As a Diagnostic Support Assistant for finding\nthe correct differential diagnosis.\n▪ Knowledge Retrieval: [Retrieved text from the database of case\nreports closely matching the inputted description using zero-\nshot learning].\n▶ Fig. 1Schematic overview of basic and advanced prompting\nstrategies.\n1168 Russe MF et al. Improving the use… Fortschr Röntgenstr 2024; 196: 1166–1170 | © 2024. Thieme. All rights reserved.\nTechnical Innovations\nThis document was downloaded for personal use only. Unauthorized distribution is strictly prohibited.\n\n▪ Instructions: Using the retrieved knowledge mentioned above,\nprovide the most likely differential diagnoses for the following\nimage descriptions. Consider common and rare conditions and\njustify each diagnosis with relevant findings.\n▪ Output Format: List of 3 differential diagnoses each with justi-\nfications based on the image descriptions provided.\n▪ Cautionary Note: Do not state differential diagnoses with low\nprobability\n▶ Table 1Examples of responses from ChatGPT using GPT4 to different prompting strategies.\nPatient: 65-year-old male\nMedical history: Hypertension, atrial fibrillation, type 2 diabetes, ex-smoker. Recent coronary angiography (3 days ago)\nCurrent medications: Aspirin, Atorvastatin, Metformin\nComplaint: The patient, a 58-year-old male, presents at the emergency department with a sudden and severe onset of abdominal pain. He describes the\npain as intense, crampy, and diffuse across the entire abdominal region. The pain began approximately four hours ago and has progressively worsened.He\nreports no associated symptoms such as nausea, vomiting, or changes in bowel habits.\nPhysical examination: The patient appears pale, diaphoretic, and in distress. Examination reveals diffuse tenderness, guarding, and rebound tenderness\nacross the entire abdomen. Bowel sounds are absent. BP: 95/60 mmHg. Pulse: 110 bpm, irregular. Abdomen: absent bowel sounds.\nLaboratory investigation: Hb 9.8 g/dl; Hct 30 %; lactate 4.2 mmol/L\nECG : Atrial fibrillation with rapid ventricular response.\nMethod Prompt Answer\nBasic prompt What to do first? The patient ’s presentation suggests acute abdomen, possibly due to\nan ischemic event like mesenteric ischemia. The first step should be to\nstabilize the patient, including intravenous fluid resuscitation, oxygen\nsupplementation, and rate control for atrial fibrillation. Urgent surgical\nconsultation and abdominal imaging (like a CT scan) are also needed.\nFew-shot learning Case file: {Case}\nWhat imaging is needed?\nCT of the abdomen with IV contrast.\nExamples to solve the task:\nCase file: Incidentally detected pancreatic cyst.\nImaging: MRI of abdomen without and with IV\ncontrast with MRCP\nCase file: Severe twisting trauma to the knee. Initial\nimaging.\nImaging: Radiography of the knee\nPrecision prompt, no\nfurther knowledge\nadded to LLM\nCase file: {Case}\nQuestion: Is imaging usually appropriate for this and\nif so, specify only which imaging modality and body\nregion is most appropriate and if contrast is needed\nand if so, which contrast phases.\nYes, imaging is appropriate in this case. A CT scan of the abdomen and\npelvis with intravenous contrast is most appropriate. Both non-contrast\nand contrast-enhanced phases (arterial and venous) are needed to\nproperly visualize potential abnormalities such as ischemia or infarc-\ntion in the intestines.\nPrecision prompt\nand zero-shot learning\n(manually)\nWe have provided context information below: Yes, imaging is usually appropriate for this case. The most appropriate\nimaging modality would be CT angiography (CTA) of the abdomen and\npelvis. This should be done with intravenous contrast, including both\narterial and portal venous phases.\n{Manually insert text from the ACR mesenteric\nischemia guideline}\nGiven this information, please answer the following\nquestion concisely and clearly and make a definitive\nstatement.\n{Precision prompt + case file}\nPrecision prompt and\nzero-shot learning\n(automatic knowledge\nretrieval using vector\nindex)\nWe have provided context information below: Yes, imaging is usually appropriate for this patient. The most appro-\npriate imaging modality would be a computed tomography (CT) scan\nof the abdomen and pelvis. Given the patient’s presentation and\nelevated lactate levels, there is a suspicion of mesenteric ischemia.\nTherefore, a dual-phase (arterial and portal venous phase) CT scan with\nintravenous contrast is recommended to adequately evaluate the me-\nsenteric vasculature.\nReferences:\nAcute nonlocalized abdominal pain (page 10, 15, 16, 3, 4, 6)\nImaging of mesenteric ischemia (page 3, 8)\nThese sources can be linked to retrieve the used context or provide a\nlink to enable the user to directly jump to the used source and page\ne. g. Page“10” would link to https://acsearch.acr.org/docs/69467/Nar\nrative/#page=10.\n{Automatically retrieved context from guidelines\nusing cosine similarity analysis based on text em-\nbedding}\nGiven this information, please answer the following\nquestion concisely and clearly and make a definitive\nstatement.\n{Precision prompt + case file}\n1169Russe MF et al. Improving the use… Fortschr Röntgenstr 2024; 196: 1166–1170 | © 2024. Thieme. All rights reserved.\nThis document was downloaded for personal use only. Unauthorized distribution is strictly prohibited.\n\nInput: [Insert detailed descriptions of radiological images]\nChallenges related to data privacy, potential biases, and ensur-\ning consistent accuracy could hamper broad usage of LLMs in the\nmedical domain [17, 18]. This might be addressed by the recent\nprompt engineering advances ranging from precision prompts to\nzero-shot learning. Enhanced with vector store retrieval, the re-\nmarkable adaptability and potential of LLMs in the rapidly evolving\nfield of medicine become evident [7, 8, 16]. With these advances,\nthe use of prompt engineering and few/zero-shot learning tech-\nniques can address these challenges. Due to the improved per-\nformance of LLMs, smaller locally deployed networks that do not\nrely on cloud computing may become feasible. This reduces priv-\nacy concerns since sensitive information can be processed locally.\nParticularly with zero-shot learning approaches, response bias can\nbe mitigated by careful selection of data sources under control of\nlocal needs. Templates added by precision prompting or few-shot\nlearning enable a consistent response structure, and robust\nknowledge retrieval in zero-shot learning improves the consisten-\ncy of response content. In addition, revealing the source of infor-\nmation on which the answer is based by presenting metadata and\nhyperlinks to the data has the potential to overcome the current\nlack of trustworthiness of LLM results. LLMs usually do not admit\na lack of knowledge, which in turn leads to so-called hallucinations\n[19]. Zero-shot approaches thus allow for a deeper insight into\nthe validity of the answer and decision-making. Moreover, the ap-\nplication of LLMs in clinical practice would clearly benefit from the\nopen sourcing of data and model source code to ensure reprodu-\ncibility, transparency, and independence.\nIn summary, optimized prompting strategies leverage the po-\ntential of LLMs and facilitate their application for medical tasks.\nTherefore, basic knowledge on prompt engineering is the founda-\ntion for creating more accurate and tailored responses. Improve-\nments are gained by moving from precision prompts to advanced\ntechniques like few-shot and zero-shot learning. Emerging em-\nbedding-based retrieval mechanisms further amplify the LLMs ’\ncapabilities, making them invaluable tools in the medical field.\nConflict of Interest\nThe authors declare that they have no conflict of interest.\nReferences\n[1] OpenAI Platform [Internet]. [zitiert 31. August 2023]. Verfügbar unter:\nhttps://platform.openai.com\n[2] Kung TH, Cheatham M, Medenilla A et al. Performance of ChatGPT on\nUSMLE: Potential for AI-assisted medical education using large language\nmodels. PLOS Digit Health 2023; 2 (2): e0000198\n[3] Lyu Q, Tan J, Zapadka ME et al. Translating radiology reports into plain\nlanguage using ChatGPT and GPT-4 with prompt learning: results, lim-\nitations, and potential. Vis Comput Ind Biomed Art. 18 2023; 6 (1): 9\n[4] Amin KS, Davis MA, Doshi R et al. Accuracy of ChatGPT, Google Bard,\nand Microsoft Bing for Simplifying Radiology Reports. Radiology 2023;\n309 (2): e232561\n[5] Schmidt S, Zimmerer A, Cucos T et al. Simplifying radiologic reports with\nnatural language processing: a novel approach using ChatGPT in en-\nhancing patient understanding of MRI results. Arch Orthop Trauma Surg\n[Internet] 2023. doi:10.1007/s00402-023-05113-4\n[6] Jeblick K, Schachtner B, Dexl J et al. ChatGPT Makes Medicine Easy to\nSwallow: An Exploratory Case Study on Simplified Radiology Reports\n[Internet]. arXiv 2022. doi:10.48550/arXiv.2212.14882. http://arxiv.\norg/abs/2212.14882\n[7] Sushil M, Kennedy VE, Miao BY et al. Extracting detailed oncologic his-\ntory and treatment plan from medical oncology notes with large lan-\nguage models [Internet]. arXiv 2023. doi:10.48550/arXiv.2308.03853.\nhttp://arxiv.org/abs/2308.03853\n[8] Russe MF, Fink A, Ngo H et al. Performance of ChatGPT, human radiolo-\ngists, and context-aware ChatGPT in identifying AO codes from radiolo-\ngy reports. Sci Rep 2023; 13 (1): 14215\n[9] Wang J, Shi E, Yu S et al. Prompt Engineering for Healthcare: Methodol-\nogies and Applications [Internet]. arXiv 2023. doi:10.48550/ar-\nXiv.2304.14670. http://arxiv.org/abs/2304.14670\n[10] White J, Fu Q, Hays S et al. A Prompt Pattern Catalog to Enhance Prompt\nEngineering with ChatGPT [Internet]. arXiv 2023. doi:10.48550/ar-\nXiv.2302.11382. http://arxiv.org/abs/2302.11382\n[11] Pinto dos Santos D, Brodehl S, Baeßler B et al. Structured report data can\nbe used to develop deep learning algorithms: a proof of concept in ankle\nradiographs. Insights into Imaging 2019; 10 (1): 93\n[12] Ye S, Hwang H, Yang S et al. In-Context Instruction Learning [Internet].\narXiv 2023. doi:10.48550/arXiv.2302.14691. http://arxiv.org/abs/\n2302.14691\n[13] Brown TB, Mann B, Ryder N et al. Language Models are Few-Shot Lear-\nners [Internet]. arXiv 2020. doi:10.48550/arXiv.2005.14165. http://ar\nxiv.org/abs/2005.14165\n[14] Liu Z, Yu X, Zhang L et al. DeID-GPT: Zero-shot Medical Text De-Identi-\nfication by GPT-4 [Internet]. arXiv 2023. doi:10.48550/ar-\nXiv.2303.11032. http://arxiv.org/abs/2303.11032\n[15] Jin Q, Dhingra B, Cohen WW et al. Probing Biomedical Embeddings from\nLanguage Models [Internet]. arXiv 2019. doi:10.48550/ar-\nXiv.1904.02181. http://arxiv.org/abs/1904.02181\n[16] Rau A, Rau S, Zoeller D et al. A Context-based Chatbot Surpasses Trained\nRadiologists and Generic ChatGPT in Following the ACR Appropriateness\nGuidelines. Radiology 2023; 308 (1): e230970\n[17] Geis JR, Brady AP, Wu CC et al. Ethics of Artificial Intelligence in Radiol-\nogy: Summary of the Joint European and North American Multisociety\nStatement. Radiology 2019; 293 (2): 436–440\n[18] Keskinbora KH. Medical ethics considerations on artificial intelligence.\nJournal of Clinical Neuroscience 2019; 64: 277–282\n[19] Goddard J. Hallucinations in ChatGPT: A Cautionary Tale for Biomedical\nResearchers. The American Journal of Medicine 2023; 136 (11): 1059–\n1060\n1170 Russe MF et al. Improving the use… Fortschr Röntgenstr 2024; 196: 1166–1170 | © 2024. Thieme. All rights reserved.\nTechnical Innovations\nThis document was downloaded for personal use only. Unauthorized distribution is strictly prohibited.\n",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.674818754196167
    },
    {
      "name": "Shot (pellet)",
      "score": 0.48163145780563354
    },
    {
      "name": "Zero (linguistics)",
      "score": 0.4304559528827667
    },
    {
      "name": "Computer science",
      "score": 0.3697594404220581
    },
    {
      "name": "Medicine",
      "score": 0.338749498128891
    },
    {
      "name": "Psychology",
      "score": 0.3205741047859192
    },
    {
      "name": "Artificial intelligence",
      "score": 0.2416667342185974
    },
    {
      "name": "Linguistics",
      "score": 0.14150914549827576
    },
    {
      "name": "Chemistry",
      "score": 0.07721373438835144
    },
    {
      "name": "Organic chemistry",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2801240073",
      "name": "University Medical Center Freiburg",
      "country": "DE"
    }
  ],
  "cited_by": 35
}