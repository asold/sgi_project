{
  "title": "Large language model (ChatGPT) as a support tool for breast tumor board",
  "url": "https://openalex.org/W4378783467",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2982706709",
      "name": "Miri Sklair Levy",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A1930115837",
      "name": "Israel Cohen",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A4363102405",
      "name": "Douglas B. Zippel",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2664654900",
      "name": "Nora Balint-Lahat",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2155772135",
      "name": "Eli Konen",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2809724045",
      "name": "Vera Sorin",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2982706709",
      "name": "Miri Sklair Levy",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A1930115837",
      "name": "Israel Cohen",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A4363102405",
      "name": "Douglas B. Zippel",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2664654900",
      "name": "Nora Balint-Lahat",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2155772135",
      "name": "Eli Konen",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1966976587",
    "https://openalex.org/W3109948322",
    "https://openalex.org/W4376122030",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4387356888",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W4315784554",
    "https://openalex.org/W1985408224",
    "https://openalex.org/W1245681932",
    "https://openalex.org/W3201019271",
    "https://openalex.org/W2924551358",
    "https://openalex.org/W4294214983"
  ],
  "abstract": "Abstract Large language models (LLM) such as ChatGPT have gained public and scientific attention. The aim of this study is to evaluate ChatGPT as a support tool for breast tumor board decisions making. We inserted into ChatGPT-3.5 clinical information of ten consecutive patients presented in a breast tumor board in our institution. We asked the chatbot to recommend management. The results generated by ChatGPT were compared to the final recommendations of the tumor board. They were also graded independently by two senior radiologists. Grading scores were between 1–5 (1 = completely disagree, 5 = completely agree), and in three different categories: summarization, recommendation, and explanation. The mean age was 49.4, 8/10 (80%) of patients had invasive ductal carcinoma, one patient (1/10, 10%) had a ductal carcinoma in-situ and one patient (1/10, 10%) had a phyllodes tumor with atypia. In seven out of ten cases (70%), ChatGPT’s recommendations were similar to the tumor board’s decisions. Mean scores while grading the chatbot’s summarization, recommendation and explanation by the first reviewer were 3.7, 4.3, and 4.6 respectively. Mean values for the second reviewer were 4.3, 4.0, and 4.3, respectively. In this proof-of-concept study, we present initial results on the use of an LLM as a decision support tool in a breast tumor board. Given the significant advancements, it is warranted for clinicians to be familiar with the potential benefits and harms of the technology.",
  "full_text": "BRIEF COMMUNICATION OPEN\nLarge language model (ChatGPT) as a support tool for breast\ntumor board\nVera Sorin 1,2,3 ✉, Eyal Klang1,2,3,4, Miri Sklair-Levy1,2, Israel Cohen1,2, Douglas B. Zippel2,5, Nora Balint Lahat2,6, Eli Konen1,2 and\nYiftach Barash 1,2,3\nLarge language models (LLM) such as ChatGPT have gained public and scientiﬁc attention. The aim of this study is to evaluate\nChatGPT as a support tool for breast tumor board decisions making. We inserted into ChatGPT-3.5 clinical information of ten\nconsecutive patients presented in a breast tumor board in our institution. We asked the chatbot to recommend management. The\nresults generated by ChatGPT were compared to theﬁnal recommendations of the tumor board. They were also graded\nindependently by two senior radiologists. Grading scores were between 1– 5( 1= completely disagree, 5= completely agree), and\nin three different categories: summarization, recommendation, and explanation. The mean age was 49.4, 8/10 (80%) of patients had\ninvasive ductal carcinoma, one patient (1/10, 10%) had a ductal carcinoma in-situ and one patient (1/10, 10%) had a phyllodes\ntumor with atypia. In seven out of ten cases (70%), ChatGPT’s recommendations were similar to the tumor board’s decisions. Mean\nscores while grading the chatbot’s summarization, recommendation and explanation by theﬁrst reviewer were 3.7, 4.3, and 4.6\nrespectively. Mean values for the second reviewer were 4.3, 4.0, and 4.3, respectively. In this proof-of-concept study, we present\ninitial results on the use of an LLM as a decision support tool in a breast tumor board. Given the signiﬁcant advancements, it is\nwarranted for clinicians to be familiar with the potential beneﬁts and harms of the technology.\nnpj Breast Cancer            (2023) 9:44 ; https://doi.org/10.1038/s41523-023-00557-8\nThe release of the chatbot ChatGPT by OpenAI has gained a lot of\npublic, media, and scienti ﬁc attention. GPT (Generative Pre-\ntraining Transformer) is a large language model (LLM). LLMs are\nbased on transformer with Attention mechanism\n1. These models\nare trained on extremely large datasets, consisting of billions of\nwords and parameters. They are also considered “few-shot\nlearners”, meaning that once trained, they can adapt to new\ndomains with a small number of examples. LLMs can be used for\nvarious applications in clinical care and research\n2. They can be\nused as a support tool for physicians, allowing quick summariza-\ntion of data, question answering, and even treatment suggestions.\nThere are some reports as well as several studies that have shown\nencouraging results on ChatGPT performance in various complex\nmedical tasks. These include the United States Medical Licensing\nExam (USMLE)\n3, imaging reports simpli ﬁcation for patients 4,\ndecision-making on the appropriate breast imaging examina-\ntions\n5, and scientiﬁc manuscripts generation6.\nMedical tumor boards generally present and discuss the most\ncomplex clinical cases. The active involvement in tumor boards\nrepresents formidable intellectual challenges for oncologists,\nsurgeons, radiologists, and pathologists in their clinical practice.\nThis is due to the need to integrate medical expertise, intricate\nmedical understanding and insightful clinical judgment. In the\ncurrent proof-of-concept study we aim to evaluate a large\nlanguage model (ChatGPT-3.5) as a support tool for a breast\ntumor board.\nTen consecutive women presented in our institutional tumor\nboard were included in this study. The mean age was 49.4. Eight\n(8/10, 80%) of the patients had invasive ductal carcinoma (IDC),\none patient (1/10, 10%) had a DCIS and one patient (1/10, 10%)\nhad a phyllodes tumor with atypia. Patient characteristics are\ndetailed in Table1.\nIn seven out of ten cases (7/10, 70%), ChatGPT’sr e c o m m e n d a -\ntions were similar to the tumor board’s decisions. Based on theﬁrst\nreviewer, mean score for the chatbot’s summarization of the clinical\nvignettes was 4.6, foragreement with clinical recommendations 3.7,\nand for explanations 4.3. Mean values for the second reviewer were\n4.3 for summarization, 4.0 for agreement with clinical recommenda-\ntions, and 4.3 for explanations (Fig.1). Agreement between raters\nwas fair for summarization (k\nw coefﬁcient =0.42, 95% CI 0.10– 0.50),\nsubstantial for clinical recommendation (kw coefﬁcient =0.80, 95%\nCI 0.78– 0.81), and substantial for explanation (kw coefﬁcient =0.65,\n95% CI 0.53– 0.74).\nIn eight cases (8/10, 80%) the chatbot recommended surgery as\nthe next management step, and in two cases (2/10, 20%) it\nrecommended neoadjuvant chemotherapy treatment. According\nto the tumor board recommendations, seven patients were\nreferred for surgery, two to imaging and one to neoadjuvant\nchemotherapy. When recommending a multidisciplinary consult\nas an additional note in the generated responses, never did\nChatGPT mention radiologist as part of the medical forum.\nThis study evaluates the performance of ChatGPT as a clinical\ndecision support tool in patient management in breast tumor\nboard decisions. Our ﬁndings showed that the chatbot’s clinical\nrecommendations were in-line with those of the tumor board in\n70% of cases. Furthermore, the chatbot provided concise\nsummaries for the clinical cases, and explanations for its\nconclusions. Notably, lowest grading scores, from both reviewers,\npertained to the chatbot ’s clinical recommendations. Perfor-\nmances in summarization and explanation were rated higher.\nIndeed, deciding on clinical management is the most challenging\n1Department of Diagnostic Imaging, Chaim Sheba Medical Center, Tel Hashomer, Israel.2Sackler School of Medicine, Tel-Aviv University, Tel-Aviv, Israel.3DeepVision Lab, Chaim\nSheba Medical Center, Tel Hashomer, Israel.4Sami Sagol AI Hub, ARC, Chaim Sheba Medical Center, Tel Hashomer, Israel.5Department of General and Oncological Surgery-\nSurgery C, Chaim Sheba Medical Center, Tel Hashomer, Israel.6Department of Pathology, Chaim Sheba Medical Center, Tel Hashomer, Israel.✉email: verasrn@gmail.com\nwww.nature.com/npjbcancer\nPublished in partnership with the Breast Cancer Research Foundation\n1234567890():,;\nTable 1. Patient characteristics.\nAge Family history Cancer type Current clinical status Size (cm) Ki67 ER PR HER2 LN Tumor board ChatGPT-3.5\n51 Maternal cousin\n(29)\nPaget History of multifocal IDC in her left breast with lymph\nnodes involvement in 2021. Underwent lumpectomy\nfollowed by radiation, Tamoxifen and chemotherapy.\nMRI on 06.12.2022 was normal. In March 2023 had\ndischarge and an ulcer in her left nipple. Punch biopsy\nresult was Paget ER negative.\nN/A N/A − NA NA NA Nipple-areola complex\nexcision\n“Surgical excision of the affected area”\n47 Mother (48),\nmaternal\ngrandmother\n(48), paternal\ngrandmother.\nIDC grade 2 Palpable breast mass, resulted in newly diagnosed IDC,\non MRI single tumor and no lymphadenopathy.\n1.2 40% + −− − Lumpectomy and sentinel Neoadjuvant endocrine therapy\n46 None DCIS\nintermediate\nhigh grade\nDiagnosed with DCIS, underwent lumpectomy and\nsentinel, lymph nodes were clear. DCIS on pathology\nwas multifocal with involved inferior margin and other\nmargins were close. The patient then completed\nradiation to the breast and was started on Tamoxifen.\nMulti-\nfocal\nN/A ++ −− Re-lumpectomy Re-excision or radiation boost. Consider a\nmastectomy if re-excision is not feasible\n54 Maternal aunt\n(70+)\nPhyllodes\ntumor with\nmild atypia\nUnderwent biopsy for a palpable mass measuring 6 cm\nat US, and the biopsy result was phyllodes tumor with\nmild atypia. The tissue received for pathology analysis\nwas fragmented therefore assessment of surgical\nmargin was not possible.\n6 NA NA NA NA NA MRI to evaluate post-\noperative lesion extent\nRe-excision\n42 None IDC grade 2 Newly diagnosed IDC with lymph node involvement 1.1 25% ++ − + Lumpectomy with axillary\nlymph nodes dissection\nLumpectomy with axillary lymph nodes\ndissection\n63 Grandmother IDC grade 2 Newly diagnosed IDC, bilateral. No lymphadenopathy.\nOne enhancing suspicious focus at MRI that was not\nbiopsied\n1.7, 1 25%,\n9%\n+++ − Targeted US to the\nadditional enhancing focus\nand biopsy if needed. Then\nconsider bilateral\nlumpectomy.\nNeo-adjuvant therapy\n33 Paternal\ngrandmother\n(43)\nIDC grade 2 Diagnosed with multifocal IDC, Completed neoadjuvant\nchemotherapy with Taxol and Herceptin. On follow-up\nMRI complete radiological response.\nmultifocal 80% +++ − Mastectomy Mastectomy\n40 None IDC with\nDCIS\nNewly diagnosed IDC+ DCIS. On MRI segmental\nscattered enhancement in the left breast in dimensions\n7.5×4 cm involving the nipple and skin. No\nlymphadenopathy. On additional biopsy from far from\nthe initial mass - high grade DCIS. PET-CT was negative\nfor distant metastases.\n7.5 30% ++ −− Mastectomy Mastectomy\n51 None IDC grade 3 Newly diagnosed IDC, single mass and no\nlymphadenopathy at MRI. PET-CT with no evidence of\ndistal metastases.\n2 80% +\n−− − Lumpectomy and sentinel Lumpectomy and sentinel\n66 BRCA2 carrier IDC grade 2 BRCA2 carrier, previously underwent risk-reducing\nbilateral salpingo-oophrectomy. Diagnosed with IFC.\n0.8 20% ++ −− Lumpectomy and sentinel Lumpectomy and sentinel. However, given\nthe patient’s age, overall health, and\nhistory of bilateral salpingo-oophrectomy,\nmastectomy should also be discussed.\nIDC invasive ductal carcinoma,DCIS ductal carcinoma in-situ,LN lymph nodes.\nV. Sorin et al.\n2\nnpj Breast Cancer (2023)    44 Published in partnership with the Breast Cancer Research Foundation\n1234567890():,;\nintellectual task, requiring medical understanding and expertise. It\nis interesting to note that in one of the cases the chatbot“missed”\ninformation on the patient’s HER2 FISH results. However, when\nasked directly, it corrected the error. We speculate that this may\nbe due to the model’s use of Attention mechanism. Attention is a\nkey aspect of Transformer-based language models like ChatGPT. It\nallows to analyze the context of words by taking into account\nsurrounding words and weighing them based on relevance.\nTransformers process all words at the same time and calculate\nattention weights between them. It may not have put enough\nweight on the FISH results. This highlights its tendency in some\ncases to overlook important information, as in our patient and her\nHER2 status.\nAnother interesting point is the lack of referral in all cases to\nadditional imaging, or consultation with a radiologist as part of a\nmultidisciplinary team. That is despite the fact that radiologists\nhave important roles in tumor boards while discussing patient\nmanagement. Radiologists assist in determining the stage of\nbreast cancer and contribute to treatment planning and evalua-\ntion of treatment response. Historically, there have been\nmisperception of the general public on radiologists. It is common\nthat patients do not recognize radiologists as one of their treating\nphysicians, or in some cases as physicians at all\n7. As ChatGPT’s\ntraining was based on texts from the internet, it may have caused\nsome sort of replication or even ampliﬁcation of that trend. There\nare some possible ways by which the model ’s recognition of\nradiologists’ roles can be improved. As language models increase\nin size and are trained on larger data, they may better\ncomprehend the nuances of radiologists’ responsibilities. Addi-\ntionally, large language models can be ﬁne-tuned with speciﬁc\nmedical or radiological data. Exposure to domain-speciﬁc informa-\ntion should enhance the model’s “knowledge” in theﬁeld. Finally,\nit may be possible that the model did not assign sufﬁcient weight\nto radiologist consultations in the decision-making process. The\nlatter issue can be adjusted and corrected with training. There are\nseveral limitations to this study. The proof-of-concept nature of\nthe study limited the sample size to a mere ten patients, which\ndoes not reﬂect the algorithm’s performance in real-world clinical\nsettings. Consequently, generalizing the results from such a small\nsample size is unfeasible. Furthermore, some tumors and many\nclinical scenarios are not represented at all. For example, all eight\nIDC cases were ER-positive. Although ER-positive breast cancer is\nmore common\n8, decisions on triple– negative and HER2-positive\npatients’ management may be more complicated. Furthermore,\nthere was only one case of DCIS, and no cases of invasive lobular\ncarcinoma (ILC) at all. Finally, one of the reviewers (M.S.L.),\nparticipates regularly in the tumor board. Thus, there is a\npossibility of subjective bias in the grading process.\nThere are inherent limitations to ChatGPT that must be\nconsidered. One concern is the potential generation of false or\nincorrect information, which may lead to inappropriate medical\ndecisions and compromise patient safety. The output of the\nchatbot is impacted by the data it is trained on. Thus, if training\ndata do not represent diverse populations, bias may be\nintroduces, and potential exacerbation of healthcare disparities\n9.\nMoreover, it is important to consider that ChatGPT generates\nresponses based on the dataset it was trained on. The data may\nnot be up-to-date, particularly inﬁelds such as oncology, where\nnew trials and drugs are constantly emerging.\nAnother issue is the question of legal responsibility and liability\nin cases where AI-driven decisions lead to negative outcomes.\nData security is an additional critical issue. The insertion of actual\npatient data into these models necessitates data protection\nmechanisms to prevent unauthorized access. The potential for\nadversarial cyber-attacks, where malicious actors manipulate the\nAI system to produce harmful outcomes, is a growing concern\n10.\nThis emphasizes the signi ﬁcance of developing cybersecurity\nmeasures to safeguard AI systems in clinical settings.\nTo conclude, in this study we demonstrate the performance and\nfeasibility of use of ChatGPT-3.5 in one of the most complex tasks\nin patient care. We identify strengths and discuss pitfalls that still\nneed to be addressed. Further studies with larger sample sizes are\nwarranted in order to establish the actual performance of the\nchatbot in different clinical scenarios. Given the signi ﬁcant\nadvancements, it is likely that the use of LLMs such as ChatGPT\nas an assisting and supporting tool for physicians will expand and\nevolve. Thus, familiarity of clinicians on the pros and cons of this\ntechnology is essential.\nMETHODS\nThis retrospective study was approved by the Chaim Sheba\nMedical Center institutional review board (IRB) with a waiver of\ninformed consent granted and so participants didn ’t provide\nwritten informed consent. Ten consecutive women who were\ndiagnosed with breast cancer and were presented at breast tumor\nboard at our institution in January 2023 were included in the\nstudy. Women who underwent imaging outside of our institution\nwere excluded to ensure homogeneity of data.\nFor each patient, we collected the most recent clinical notes\nfrom both oncology and surgery clinic visits, the latest imaging\nresults (including mammography, ultrasound, and MRI), surgical\nFig. 1 Rating of the performance of a large langue model (ChatGPT) in three categories by the two reviewers (M.S.L.– reviewer-1 in gray and\nEy.K. – reviewer-2 in black): summarization of text, clinical recommendation, and explanation on the decision made.\nV. Sorin et al.\n3\nPublished in partnership with the Breast Cancer Research Foundation npj Breast Cancer (2023)    44 \nreport if available, and the corresponding pathology results, or\nresults from biopsy.\nY.B. extracted the relevant clinical data. V.S. generated clinical\nvignettes summarizing the relevant clinical data, while blinded to\nthe tumor board decisions. Vignettes included demographic\ninformation, clinical history, imaging and pathology results, and\ncurrent status (whether underwent surgery, borders, molecular\ntests). The vignettes were written in English. It should be noted\nthat some of the notes and imaging results were originally in\nHebrew, and thus were translated.\nY.B. inserted the clinical vignettes into ChatGPT-3.5, and asked\nthe chatbot to recommend on the next most appropriate step in\nmanagement. We gave it options from which it was supposed to\nchoose. The exact query was:“Hi, can I give you a patient story of\nbreast cancer detected and you’ll say what is the next step in her\nmanagement? please decide if she needs surgery, what type of\nsurgery, whether she needs neoajuvant therapy before, or does\nshe needs further testing”. ChatGPT-3.5 was accessed on February\n9th, 2023, and all answers were obtained at that time. We then\nretrieved the summary and decision notes from the tumor board,\ndocumented regularly in the medical chart of each patient\nfollowing tumor board discussion. Y.B. and V.S. reviewed the\nchatbot’s answers and compared them to the tumor board ’s\ndecisions, asking the chatbot to elaborate when recommenda-\ntions were divergent. All cases were then reviewed and discussed\ntogether with M.S.L., who is a senior breast radiologist participat-\ning regularly in the tumor board.\nM.S.L. graded the responses based on three distinct categories:\nsummarization, clinical recommendation, and explanation. A\ngrading scale of 1 – 5 was used, where 1 indicated complete\ndisagreement, 2 disagreement, 3 neutrality, 4 agreement, and 5\ncomplete agreement (Supplementary Tables 1– 3). Clinical recom-\nmendations were also evaluated using a binary grading system,\nfocusing on whether the overall recommendations regarding\nsurgery, systemic treatment, and further assessment were aligned\nbetween the tumor board and the chatbot.\nDue to the possibility of bias introduction since M.S.L. usually\nparticipates in the tumor boards, Ey.K. who is a senior radiologist\nnot involved in neither data collection nor in the tumor boards,\nalso graded independently the chatbot’s responses. Agreement\nbetween raters was measured using linear weighted Cohen ’s\nkappa (k\nw) coefﬁcient. Interpretation of the kw coefﬁcient was as\nfollows: −0: less than chance agreement; 0.01 – 0.20: slight\nagreement; 0.21– 0.40: fair agreement; 0.41– 0.60: moderate agree-\nment; 0.61– 0.80: substantial agreement; 0.81– 0.99: almost perfect\nagreement11.\nReporting summary\nFurther information on research design is available in the Nature\nResearch Reporting Summary linked to this article.\nDATA AVAILABILITY\nThe data that support theﬁndings of this study are available upon request from the\ncorresponding author [V.S.].\nReceived: 16 March 2023; Accepted: 23 May 2023;\nREFERENCES\n1. Sorin, V., Barash, Y., Konen, E. & Klang, E. Deep-learning natural language pro-\ncessing for oncological applications.Lancet Oncol. 21, 1553– 1556 (2020).\n2. Sorin, V., Barash Y., Konen E., Klang E. Large language models for oncological\napplications.J. Cancer Res. Clin. Oncol.https://doi.org/10.1007/s00432-023-04824-w.\n3. Kung, T. H. et al. Performance of ChatGPT on USMLE: Potential for AI-Assisted\nMedical Education Using Large Language Models. PLOS Digital Health 2,\ne0000198 (2023).\n4. Jeblick K., et al. ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case\nStudy on Simpli ﬁed Radiology Reports. Preprint at: http://arXiv preprint\narXiv:2212.14882 (2022).\n5. Rao A., et al. Evaluating ChatGPT as an Adjunct for Radiologic Decision-Making.\nPreprint at:https://www.medrxiv.org/content/10.1101/2023.02.02.23285399v1(2023).\n6. Else, H. Abstracts written by ChatGPT fool scientists.Nature 613, 423– 423 (2023).\n7. Neiman, H. L. Face of radiology campaign.Academic Radiol. 16, 517– 520 (2009).\n8. Lumachi, F. Current medical treatment of estrogen receptor-positive breast\ncancer. World J. Biol. Chem.6, 231 (2015).\n9. Sorin, V. & Klang, E. Artiﬁcial intelligence and health care disparities in radiology.\nRadiology 301, E443– E443 (2021).\n10. Finlayson, S. G. et al. Adversarial attacks on medical machine learning.Science\n363, 1287– 1289 (2019).\n11. McHugh, M. L. Interrater reliability: the kappa statistic.Biochem Med (Zagreb).22,\n276– 282 (2012).\nAUTHOR CONTRIBUTIONS\nV.S., Y.B., Ey.K. and M.S.L. conceived and carried out the experiments V.S., Y.B. and I.C.\ncontributed to sample preparation. M.S.L., D.B.Z., El.K. and N.B.L. contributed to the\ninterpretation of the results. All authors provided critical feedback and helped shape\nthe research, analysis and manuscript.\nCOMPETING INTERESTS\nThe authors declare no competing interests.\nADDITIONAL INFORMATION\nSupplementary information The online version contains supplementary material\navailable at https://doi.org/10.1038/s41523-023-00557-8.\nCorrespondence and requests for materials should be addressed to Vera Sorin.\nReprints and permission information is available at http://www.nature.com/\nreprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims\nin published maps and institutional afﬁliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons license, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this license, visit http://\ncreativecommons.org/licenses/by/4.0/.\n© The Author(s) 2023\nV. Sorin et al.\n4\nnpj Breast Cancer (2023)    44 Published in partnership with the Breast Cancer Research Foundation",
  "topic": "Grading (engineering)",
  "concepts": [
    {
      "name": "Grading (engineering)",
      "score": 0.7914109230041504
    },
    {
      "name": "Medicine",
      "score": 0.6508095264434814
    },
    {
      "name": "Automatic summarization",
      "score": 0.5641700029373169
    },
    {
      "name": "Ductal carcinoma",
      "score": 0.43211886286735535
    },
    {
      "name": "Breast tumor",
      "score": 0.42807531356811523
    },
    {
      "name": "Atypia",
      "score": 0.42317354679107666
    },
    {
      "name": "Medical physics",
      "score": 0.35973048210144043
    },
    {
      "name": "Radiology",
      "score": 0.34560075402259827
    },
    {
      "name": "Breast cancer",
      "score": 0.3238186836242676
    },
    {
      "name": "Internal medicine",
      "score": 0.27550631761550903
    },
    {
      "name": "Computer science",
      "score": 0.2443135380744934
    },
    {
      "name": "Pathology",
      "score": 0.21878379583358765
    },
    {
      "name": "Artificial intelligence",
      "score": 0.20716899633407593
    },
    {
      "name": "Cancer",
      "score": 0.13956600427627563
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Civil engineering",
      "score": 0.0
    }
  ]
}