{
  "title": "Emotion Classification in German Plays with Transformer-based Language Models Pretrained on Historical and Contemporary Language",
  "url": "https://openalex.org/W3211635632",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A1922475528",
      "name": "Thomas Schmidt",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2278507781",
      "name": "Katrin Dennerlein",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1987201335",
      "name": "Christian Wolff",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3126929359",
    "https://openalex.org/W4287824654",
    "https://openalex.org/W3011574394",
    "https://openalex.org/W2962802054",
    "https://openalex.org/W2964930441",
    "https://openalex.org/W2883222227",
    "https://openalex.org/W3037323282",
    "https://openalex.org/W3128480051",
    "https://openalex.org/W2884941335",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W3211217078",
    "https://openalex.org/W3164156383",
    "https://openalex.org/W2802909724",
    "https://openalex.org/W3144991328",
    "https://openalex.org/W2575717474",
    "https://openalex.org/W3152974926",
    "https://openalex.org/W2164777277",
    "https://openalex.org/W2971301409",
    "https://openalex.org/W3132583477",
    "https://openalex.org/W2971292190",
    "https://openalex.org/W3114950584",
    "https://openalex.org/W3102944297",
    "https://openalex.org/W3102444842",
    "https://openalex.org/W3205211811",
    "https://openalex.org/W2990119823",
    "https://openalex.org/W1836023969",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W2767106145",
    "https://openalex.org/W2098667769",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W4287240090",
    "https://openalex.org/W2955740278",
    "https://openalex.org/W3037547477",
    "https://openalex.org/W2807086361",
    "https://openalex.org/W2886186188",
    "https://openalex.org/W2974630751",
    "https://openalex.org/W2947036351",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3004417295",
    "https://openalex.org/W3196782920",
    "https://openalex.org/W3030236966",
    "https://openalex.org/W3030030185",
    "https://openalex.org/W3207323579",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2798838888",
    "https://openalex.org/W1894439685",
    "https://openalex.org/W3100779964"
  ],
  "abstract": "We present results of a project on emotion classification on historical German plays of Enlightenment, Storm and Stress, and German Classicism. We have developed a hierarchical annotation scheme consisting of 13 sub-emotions like suffering, love and joy that sum up to 6 main and 2 polarity classes (positive/negative). We have conducted textual annotations on 11 German plays and have acquired over 13,000 emotion annotations by two annotators per play. We have evaluated multiple traditional machine learning approaches as well as transformer-based models pretrained on historical and contemporary language for a single-label text sequence emotion classification for the different emotion categories. The evaluation is carried out on three different instances of the corpus: (1) taking all annotations, (2) filtering overlapping annotations by annotators, (3) applying a heuristic for speech-based analysis. Best results are achieved on the filtered corpus with the best models being large transformer-based models pretrained on contemporary German language. For the polarity classification accuracies of up to 90% are achieved. The accuracies become lower for settings with a higher number of classes, achieving 66% for 13 sub-emotions. Further pretraining of a historical model with a corpus of dramatic texts led to no improvements.",
  "full_text": "Proceedings of LaTeCH-CLfL 2021, pages 67–79\nPunta Cana, Dominican Republic (Online), November 11, 2021.\n67\nEmotion Classiﬁcation in German Plays with Transformer-based\nLanguage Models Pretrained on Historical and Contemporary Language\nThomas Schmidt\nMedia Informatics Group\nUniversity of Regensburg, Germany\nthomas.schmidt@ur.de\nKatrin Dennerlein\nGerman Literary Studies\nUniversity of Würzburg, Germany\nkatrin.dennerlein\n@uni-wuerzburg.de\nChristian Wolff\nMedia Informatics Group\nUniversity of Regensburg, Germany\nchristian.wolff@ur.de\nAbstract\nWe present results of a project on emotion clas-\nsiﬁcation on historical German plays of En-\nlightenment, Storm and Stress , and German\nClassicism. We have developed a hierarchi-\ncal annotation scheme consisting of 13 sub-\nemotions like suffering, love and joy that sum\nup to 6 main and 2 polarity classes (posi-\ntive/negative). We have conducted textual an-\nnotations on 11 German plays and have ac-\nquired over 13,000 emotion annotations by\ntwo annotators per play. We have evalu-\nated multiple traditional machine learning ap-\nproaches as well as transformer-based models\npretrained on historical and contemporary lan-\nguage for a single-label text sequence emo-\ntion classiﬁcation for the different emotion cat-\negories. The evaluation is carried out on three\ndifferent instances of the corpus: (1) taking\nall annotations, (2) ﬁltering overlapping anno-\ntations by annotators, (3) applying a heuris-\ntic for speech-based analysis. Best results are\nachieved on the ﬁltered corpus with the best\nmodels being large transformer-based models\npretrained on contemporary German language.\nFor the polarity classiﬁcation accuracies of up\nto 90% are achieved. The accuracies become\nlower for settings with a higher number of\nclasses, achieving 66% for 13 sub-emotions.\nFurther pretraining of a historical model with\na corpus of dramatic texts led to no improve-\nments.\n1 Introduction\nTransformer-based language models like BERT\n(Devlin et al., 2019) and ELECTRA (Clark et al.,\n2019) have recently gained a lot of attention and\nachieve state-of-the-art results for various tasks\nin natural language processing (NLP) (Qiu et al.,\n2020). These language models are usually trained\nvia deep learning on large amounts of texts ac-\nquired from the internet. Unlike previous methods\nin NLP, these models use context-sensitive word\nrepresentations and they can better deal with out-of-\nvocabulary words. These attributes are, of course,\nadvantageous for various text sorts in digital hu-\nmanities (DH) and computational literary studies\n(CLS). Furthermore, transformer-based language\nmodels can be adapted to speciﬁc domain texts\nby either training a model from scratch on large\namounts of these texts or taking an existing model\nand further pretraining it with domain-speciﬁc texts\n(Beltagy et al., 2019; Gururangan et al., 2020; Ri-\netzler et al., 2020). Transformer-based models as\nwell as these approaches have been successfully\napplied in DH contexts with historical or poetic\nGerman texts for named entity recognition (NER)\n(Schweter and Baiter, 2019; Labusch et al., 2019)\nand speech type recognition (Brunner et al., 2020).\nWe present a study for the task of textual emotion\nclassiﬁcation in the same line of research for the\nuse case of German historical plays.\nEmotion classiﬁcation deals with the prediction\nof (multiple) emotion categories in text. Its neigh-\nbouring ﬁeld sentiment analysis primarily focuses\non the prediction of the overall polarity (or valence)\nof a text, meaning if it is rather positive or nega-\ntive (Mäntylä et al., 2018). Both methods have\nbeen explored in DH and CLS to analyze emo-\ntion/sentiment distributions and progressions in so-\ncial media (Schmidt et al., 2020b) or literary texts\nlike plays (Nalisnick and Baird, 2013; Schmidt and\nBurghardt, 2018; Schmidt et al., 2019b; Schmidt,\n2019), novels (Zehe et al., 2016; Reagan et al.,\n2016) and fairy tales (Alm and Sproat, 2005; Mo-\n68\nhammad, 2011) (see Kim and Klinger (2019) for\nan in-depth review of this research area). However,\nas the review of Kim and Klinger (2019) and re-\ncent tool developments in DH show (Schmidt et al.,\n2021a), the application of rather basic lexicon-\nbased methods is frequent although these meth-\nods are usually outperformed by more modern ap-\nproaches in sentiment and emotion classiﬁcation\n(Cao et al., 2020; Dang et al., 2020; Cortiz, 2021;\nGonzález-Carvajal and Garrido-Merchán, 2021)\nand are especially problematic for literary texts\n(Fehle et al., 2021). Furthermore, performance\nevaluation of computational approaches compared\nto human annotations (\"gold standard\") are rare.\nThus, we present an evaluation study for the use\ncase of German historical plays (from Enlighten-\nment, Storm and Stressand German Classicism) for\nemotion classiﬁcation. Our goal is to develop emo-\ntion classiﬁcation algorithms with a satisfactory\nperformance for the described use case to investi-\ngate in later stages of our research, for example,\nemotion progressions throughout time or genre-\nbased differences concerning emotion distributions\non a larger set of plays. We primarily focus on\ncurrent state-of-the-art transformer-based language\nmodels.\nThe main contributions of this paper are as fol-\nlows: (1) the development of an emotion anno-\ntation scheme directed towards the interest of lit-\nerary scholars for the time frame of our corpus,\n(2) the annotation results for the annotation of 11\nplays by 2 annotators for each play, (3) a systematic\nevaluation of traditional textual machine learning\n(ML)-approaches, transformer-based models pre-\ntrained on contemporary and historical language\nand further pretrained on dramatic texts on differ-\nent instances of the annotated corpus. The goal\nof this contribution is to work towards the devel-\nopment of emotion classiﬁcation algorithms with\na satisfactory performance for the described use\ncase.\n2 Training and Evaluation Corpus\nIn the following section, we describe the concep-\ntual framework and process for the acquisition of\nthe annotated corpus that serves as training and\nevaluation corpus for the emotion classiﬁcation\n(\"Gold Standard\").\n2.1 Emotion Scheme\nThe main goal of the scheme development was to\ncreate an annotation scheme that includes the in-\nterests of literary scholars and the interpretative\nand historical dimensions of these literary texts.\nCommon emotion annotation schemes in NLP are\nmostly inspired by psychology, oftentimes consist-\ning of 6-8 established emotion classes (cf. Wood\net al., 2018a,b). However, we regard these concept\nsets as unﬁt for our speciﬁc case, since important\nemotion and affect concepts from the perspective of\nliterary criticism for the time of our plays are miss-\ning, while other concepts are not speciﬁcally impor-\ntant for our text genre. Thus, we developed a novel\nannotation scheme based on literary theory and re-\ndesigned the scheme in an iterative process of small\npilot annotations and discussions. Our ﬁnal scheme\ndeviates heavily from more common schemes in\nemotion annotation in NLP. Some concepts well-\nknown in NLP and psychology are included like\njoy, fear or anger while other standard emotion\nconcepts like disgust and surprise showed in pilot\nannotations to be not of great importance. Con-\ncepts, important for literary critique for that time\nthat are not usually regarded as emotions, that we\ninclude are desire, suffering or compassion. Please\nrefer to Schmidt et al., (2021b) for more informa-\ntion about the scheme creation and the annotation\nprocess.\nThe ﬁnal scheme consists of 13 sub-emotions\nthat are hierarchically clustered including one spe-\ncial concept ( emotional movement ). The sub-\nemotions are summarized in sixmain classes which\ncan then be clustered in a ﬁnal binary setting of two\nclasses (similar to sentiment): (per default) positive\nand negative emotions (marked in the upcoming\nlist as + and - respectively; we refer to this con-\ncept as polarity). In the following list we name\nthe sub-emotions and main classes with the orig-\ninal German term in brackets (since we perform\nannotations in German) and an English translation.\n• emotions of affection (Emotionen der Zunei-\ngung)\n– desire (Lust) (+)\n– love (Liebe) (+)\n– friendship (Freundschaft) (+)\n– admiration (Verehrung)(+)\n• emotions of joy (Emotionen der Freude)\n– joy (Freude) (+)\n69\n– Schadenfreude (The joy about the mis-\nfortune of others) (+)\n• emotions of fear (Emotionen der Angst)\n– fear (Angst) (-)\n– despair (Verzweiﬂung) (-)\n• emotions of rejection (Emotionen der\nAblehnung)\n– anger (Ärger) (-)\n– hate, disgust (Hass, Abscheu) (-)\n• emotions of suffering (Emotionen des Leids)\n– suffering (Leid) (-)\n– compassion (Mitleid) (-)\n• emotional movement\nEmotional movement has no polarity and is used\nto describe astonishment, emotional turmoil, excita-\ntion and oscillation between several emotions. We\nwill refer to the combination of the positive- and\nthe negative-class as well as emotional movement\nas triple polarity. The various hierarchical struc-\ntures are later used for classiﬁcation approaches\nwith different class numbers.\n2.2 Annotation Process\nAnnotators are instructed to assign sub-emotions,\nas deﬁned in our scheme, to text. We regard the\ncharacter’s state of mind as expressed in the text\nas the emotion to be annotated. Annotations are\nperformed context-sensitive, meaning annotators\nshould take into account the plot and content of\nthe entire play and annotate what the character re-\nally means as determined by the literary interpre-\ntation. Thus, plays are read and annotated from\nbeginning to end concerning stage directions and\nspeeches (single utterances of characters separated\nby the utterances of other characters). Depending\non the emotional expression in the text, annotators\ncan mark text sequences of varied lengths (ranging\nfrom one word to an entire speech) and are not\nlimited to a concrete annotation size. Furthermore,\nannotators can annotate multiple annotations per\ntext sequence fully or partially (see ﬁgure 1) and\nadjust the default polarity of sub-emotions for cer-\ntain cases. The annotation procedure just presented\nis closer to the interpretation process of literary\nscholars than context-free approaches with ﬁxed\ntext sizes for annotation attribution that are more\ncommon in NLP (Mäntylä et al., 2018). It has been\ndeemed as more ﬁtting throughout multiple pilot\nannotations with literary scholars.\nFigure 1: Example annotation in CATMA. The annota-\ntor marked two lines as suffering (purple), and the last\npart additionally as love (blue). (Excerpt from Canut)\nThe annotation process itself is performed with\nthe tool CATMA1 (Gius et al., 2020). Two anno-\ntators annotate each play independently from each\nother in a time span of 1-2 weeks depending on the\nlength of the play. All annotators are students of\nGerman literary studies and are compensated mon-\netarily for the annotation. They have access to an\nannotation instruction manual with descriptions of\nthe scheme and examples. They also participated in\ntest annotations under the guidance of an expert lit-\nerary scholar. Indeed, the entire annotation process\nis iterative (cf. Reiter, 2020) meaning scheme and\ninstructions changed based on feedback throughout\nthe project cycle and might be due to change (the\nstudy presented here has been performed consis-\ntently in the way described, however).\n2.3 Annotated Plays\nAs part of our larger project, we intend to ana-\nlyze emotion classiﬁcation on historical German\nplays between 1650-1815. Our current corpus of\nplays consists of around 300 digitized plays. For\nthis evaluation study, we annotated a representa-\ntive sub-corpus of 11 plays of varying epochs and\ngenres. However, we focus on more recent plays\nfor this ﬁrst evaluation study since older ones are\nmore likely to pose more challenges to the applied\nlanguage models:\n• Das Testament by Gottsched (1745/comedy)\n• Canut by Schlegel (1746/tragedy)\n• Die zärtlichen Schwestern by Gellert\n(1747/comedy)\n• Lucie Woodvil by Pfeil (1757/tragedy)\n1https://catma.de/\n70\n• Der Freigeist by Brawe (1758/tragedy)\n• Minna von Barnhelm by Lessing (1767/com-\nedy)\n• Der Postzug by Ayrenhoff (1769/comedy)\n• Kabale und Liebe by Schiller (1784/tragedy)\n• Kasperl’ der Mandolettikrämer by Eberl\n(1789/tragedy)\n• Menschenhass und Reue by Kotzebue\n(1790/comedy)\n• Faust by Goethe (1807/tragedy)\nMost of the plays were acquired as part of the\nGerDracor-Corpus (Fischer et al., 2019) except\nfor Kasperl’ der Mandolettikrämerwhich was ac-\nquired via an open web repository.2\n2.4 Annotation Statistics\nDepending on the length of a play, the annotation\nduration for each play was 8-15 hours in absolute\nnumbers. We collected 13,264 annotations of vary-\ning lengths. Table 1 illustrates the distributions for\nthe sub-emotions as well as the resulting sums for\nthe main classes.\nThe most frequent sub-emotion are suffering\n(16%) and love (13%) and the emotions of rejec-\ntion and (23%) affection (22%) for the main classes\nrespectively. The overall distribution is rather im-\nbalanced with certain sub-emotions being rarely\nannotated (e.g. desire). Considering the overall\ntriple polarity, the majority of annotations are neg-\native (53%), followed by positive (37%) and emo-\ntional movement (11%). We also examined token\nstatistics about annotation lengths: On average an\nannotation consists of 25 tokens, however with a\nlarge variance ranging from 1-token annotations to\nmultiple sentences consisting of over 500 tokens.\nThis shows that annotators make signiﬁcant use of\nthe possibility of varied annotation lengths.\nDue to the varied annotation lengths, calculat-\ning inter-annotator agreement is not possible with\ncommon metrics. However, to get an overall under-\nstanding of the agreement we calculate agreement\naccording to the following speech-based heuristic:\nFor each speech, the emotion that is annotated the\nmost per speech (measured in number of tokens) is\nassigned the speciﬁc emotion (or a neutral class if\n2http://lithes.uni-graz.at/maezene/\neberl_mandolettikraemer.html\nEmotion category absolute %\nMC: emotions of affection 2,928 22\ndesire 52 0\nlove 1,755 13\nfriendship 345 3\nadmiration 776 6\nMC: emotions of joy 1,943 15\njoy 1,619 12\nSchadenfreude 324 2\nMC: emotions of fear 1,257 9\nfear 721 5\ndespair 536 4\nMC: emotions of rejection 3,028 23\nanger 1,625 12\nhate, disgust 1,403 11\nMC: emotions of suffering 2,700 20\nsuffering 2,069 16\ncompassion 631 5\nemotional movement 1,408 11\nOverall 13,264 100\nTable 1: Distribution of emotion categories. First, the\nsummed results of the main classes (MC; marked in\nbold) are listed followed by the sub-emotions. Percent-\nages are rounded.\nno emotion is annotated) for each annotator. This\nresults in a Cohen’sκ value of 0.5 for polarity (per-\ncentage wise agreement: 68%) and 0.4 for main\nclasses (62%) and sub-emotions (58%) respectively.\nThis is regarded as moderate agreement (Landis\nand Koch, 1977), which is low compared with sen-\ntiment analysis research with other text sorts (cf.\nMäntylä et al., 2018) but in line with similar annota-\ntion projects with literary and historical texts (Alm\nand Sproat, 2005; Sprugnoli et al., 2015; Schmidt\net al., 2018, 2019a,c; Öhman, 2020; Schmidt et al.,\n2020a).\n2.5 Corpus Manifestations\nDue to the varied annotation text sequence lengths\nand the moderate agreement statistics, we evalu-\nated and trained the chosen emotion classiﬁcation\napproaches on different \"manifestations\" of our\ncorpus. We refer to the ﬁrst one as full corpus.\nThis manifestation includes all text annotations of\nthe two annotators for every play. Thus, it does in-\nclude annotations for which the annotators disagree\nupon fully or partially. This is the largest corpus\nmanifestation consisting of 13,264 annotations (for\nmore statistics see table 1). For the classiﬁcation of\n71\npolarity, we reduce corpora by ﬁltering out anno-\ntations with emotional movement, which results in\n11,883 annotations for the full corpus. The second\nmanifestation is referred to as ﬁltered corpus. For\nthis corpus instance, we ﬁlter out all annotations\nfor which annotators either fully or partially dis-\nagree, meaning annotations of different categories\nthat overlap at least for one token. We do not ﬁlter\nout annotated text sequences by one annotator that\nare not annotated by the other one. We do how-\never ﬁlter all overlapping contrary annotations by a\nsingle annotator. While our annotation scheme en-\nables these kind of annotations, we want to evaluate\nhow the ﬁltering of all contrary overlaps inﬂuences\nemotion classiﬁcation. Depending of the emotion\nhierarchy, this results in different annotation num-\nbers for the ﬁnal ﬁltered corpus: 9,962 ( polarity),\n10,247 (triple polarity), 8,552 (main class), 7,503\n(sub-emotions). Thus, the ﬁltering reduces the cor-\npus size between 15-44% depending of the categor-\nical system.\nThe last manifestation, the speech corpus, is fo-\ncused on the central units of plays: speeches and\nstage directions. It is designed as follows: Each\nspeech (we include stage directions in the follow-\ning when speaking about speeches) of the plays is\nassigned with the emotion category that is anno-\ntated the most by both annotators (as measured by\nnumber of tokens). If tied among multiple classes,\nthe class is assigned that is overall chosen the least\n(to counteract class imbalances). The entire corpus\nconsists of 11,617 speeches; we ﬁlter out speeches\nwith no annotation by either annotator to avoid\nadding an extra neutral-like class to our already\nmulti-class setting (adding neutrality is something\nwe intend to explore in future work). This reduces\nthe amount of speeches to 6,741 and affects espe-\ncially stage directions which are rarely annotated.\nWe apply the above heuristic to acquire emotion\nassignments. Please note that emotion distribu-\ntions change compared to the other manifestations\nsince underrepresented classes become even more\nrare due to the applied heuristic; thus the class im-\nbalances intensify. Distribution statistics for the\nﬁltered and speech corpus can be found in the ap-\npendix (table 6, 7, 8).\nWe separate the corpus in these three manifesta-\ntions in order to explore performance on different\nclassiﬁcation levels and text sizes, which will in-\nﬂuence our decision for later large-scale emotion\nprediction tasks on larger corpora of plays which\nwe plan for future stages of our project.\n3 Emotion Classiﬁcation Methods\nWe regard the emotion classiﬁcation as single-label\nclassiﬁcation on text sequences of varied lengths.\nThe amount of classes differs depending on the\nhierarchical system: polarity (2 classes), triple va-\nlence (3 classes), main classes (6), sub-emotions\n(13). We have implemented reference baselines\nbased on traditional ML-approaches but otherwise\nfocus on transformer-based language models for\nGerman pretrained on contemporary and histori-\ncal texts since transformer-based models have been\nshown to achieve state-of-the-art results for emo-\ntion classiﬁcation (Shmueli and Ku, 2019; Yang\net al., 2019; Cao et al., 2020) and performed best\nin a pre-study (Schmidt et al., 2021c). We also ex-\nplore further ﬁne-tuning/pretraining of a pretrained\nmodel with our domain texts since research sug-\ngests performance improvements for this method\n(Beltagy et al., 2019; Gururangan et al., 2020; Riet-\nzler et al., 2020).\n3.1 Baseline Methods\nThe following \"classical\" ML-methods for text are\nimplemented (methods like this are usually outper-\nformed by transformer-based approaches in other\nsettings (González-Carvajal and Garrido-Merchán,\n2021) and thus serve as lower baselines in the fol-\nlowing evaluation): (1) Representation of text units\nwith term frequencies in a bag-of-words model and\nsubsequently Multinomial Naive Bayes as training\nalgorithm. (2) Same representation format as above\nbut Support Vector Machines as training algorithm.\nWe implemented the approaches with the scikit-\nlearn machine learning library3 (Pedregosa et al.,\n2011) and trained and evaluated the algorithms in a\nstratiﬁed 5x5 cross evaluation setting. We refer to\nthe ﬁrst approach as bow-nb and the second one as\nbow-svm. We will also report the random and ma-\njority baseline for each classiﬁcation task. Please\nnote that depending on the corpus type, these val-\nues migh vary.\n3.2 Transformer-based Models\nWe selected the (to our knowledge) most well-\nknown and established transformer-based language\nmodels in German that are freely available. Table\n2 summarizes the selected models (the identiﬁers\n3https://scikit-learn.org/stable/\n72\nare used in the following to reference the mod-\nels). All models are acquired via the Hugging Face\nplatform4 and are also implemented with the corre-\nsponding library (Wolf et al., 2020).\nOne main point of interest are performance dif-\nferences between models pretrained on contempo-\nrary texts (e.g. like the Wikipedia, subtitles etc.)\nfor general purpose tasks and models pretrained on\nhistorical texts (e.g. historical newspapers, histori-\ncal ﬁctional texts). In Table 2 we attribute the label\n\"historical\" to a model if a signiﬁcant part of the\ntexts dates from before the 20th century. We want\nto evaluate if these models perform better since the\nlanguage is closer to the ones of our plays, which\nare of the 18th and 19th century.\nFor the contemporary models, we evaluate,\namong others, the models gbert-large and gelectra-\nlarge by Deepset5 which achieve state-of-the-art\nresults in standardized NLP-tasks (Chan et al.,\n2020) and are, to our knowledge, the largest Ger-\nman BERT- and ELECTRA-based models. On\nthe historical side, we evaluate two models pro-\nvided by the European Digital Library Europeana\npretrained on historical newspaper (Schweter and\nBaiter, 2019; Schweter, 2020) and a model focused\non ﬁctional texts (Brunner et al., 2020). To per-\nform the training and evaluation, each model is\nﬁne-tuned to the downstream task of emotion clas-\nsiﬁcation for the speciﬁc hierarchy and corpus. We\napply the recommended settings for the training of\ndownstream tasks, depending on the architecture:\nBERT (Devlin et al., 2019) or ELECTRA (Clark\net al., 2019) as well as by the Hugging Face-library.\nEach model is ﬁne-tuned for 4 epochs, a batch size\nof 32, learning rate of 4e-5 and Adam optimizer for\nstochastic gradient descent. The models are trained\nand evaluated in a 5x5 cross evaluation setting, thus\naverages over 5 runs are reported. As GPU a Tesla\nP100 was used.\nAll of the above models are trained from scratch\non large amounts of texts. However, recent re-\nsearch also suggests further pretraining of already\nexisting models with texts that are close to the\ntexts of the downstream task may improve results\n(domain-speciﬁc ﬁne-tuning) (Gururangan et al.,\n2020; Rietzler et al., 2020). We explore this ap-\nproach and further pretrain the model bert-base-\ngerman-europeana-cased solely with German dra-\nmatic texts that we acquired of our corpus sources\n4https://huggingface.co/\n5https://deepset.ai/german-bert\n(including the annotated texts). The texts consist\nof all German plays of GerDracor (Fischer et al.,\n2019), the platform TextGrid6 and around 60 plays\nwe acquired via various other sources. Altogether\nthe texts sum up to 300 MB consisting of 1,224\nplays that range from the 16th to the 20th century.\nWe use the simpletransformer-library7 and further\npretrain the model bert-base-german-europeana-\ncased for 10 epochs. The setting and parameters\nfor the emotion classiﬁcation training are the same\nas for the general models. We refer to this model\nas bert-europeana-further-pretrained.\n4 Results\nWe report accuracies and F1-scores for all models\nand category systems as well as corpus manifesta-\ntions in tables 3, 4 and 5. Considering F1-scores,\nwe report weighted F1 due to the imbalanced class\ndistributions.\nIn general, transformer-based models outper-\nform traditional ML-approaches. For every cor-\npus manifestation the performance of the different\ntransformer-based models is rather similar regard-\nless whether contemporary or historical language\nis the basis for the pretraining. The best mod-\nels are the large contemporary models gbert-large\nand gelectra-large achieving up to 90% for polar-\nity (2 classes), 85% for triple polarity (3 classes),\n75% for main classes (6 classes) and 66% for sub-\nemotions (13 classes) on the ﬁltered corpus. The\nhistorical models perform rather similar but consis-\ntently slightly below the large contemporary ones,\nbut also slightly above the smaller contemporary\nmodel bert-base-german-europeana-cased. Con-\nsidering the different corpus manifestations, all\nmodels perform best on the ﬁltered corpus and\nworst for the speech-based prediction. The differ-\nence becomes larger with increasing number of\nclasses. For example, gbert-large achieves an accu-\nracy of 75% for main class prediction on theﬁltered\ncorpus which reduces to 51% on the speech corpus.\nAs the analysis of recall and F1-macro statistics\nshow, this is mostly due to the bad prediction accu-\nracies for low-frequency classes.8\nFurther pretraining the model bert-base-german-\neuropeana-cased with dramatic texts did not result\n6https://textgrid.de/\ndigitale-bibliothek\n7https://simpletransformers.ai/\n8Additional data about the results can be found\nvia the following repository: https://github.com/\nlauchblatt/Emotions_in_Drama\n73\nIdentiﬁer Hugging\nFace-identiﬁer\nPretrained\nlanguage\nPretrained texts and size if\nreported\nRelated paper (if\navailable) and\nprovider\nbert-base bert-base-german-\ncased contemporary Wikipedia, legal texts, news\n(∼12 GB) Deepset\ngbert-large gbert-large contemporary\nCrawled web data, Wikipedia,\nsubtitles, book, legal texts\n(∼161 GB)\nDeepset (Chan\net al., 2020)\ngelectra-large gelectra-large contemporary\nCrawled web data, Wikipedia,\nsubtitles, book, legal texts\n(∼161 GB)\nDeepset (Chan\net al., 2020)\nbert-europeana bert-base-german-\neuropeana-cased historical Europeana newspaper (51 GB)\nMDZ Digital\nLibrary (Schweter,\n2020)\nelectra-europeana\nelectra-base-\ngerman-europeana-\ncased-discriminator\nhistorical Europeana newspaper (51 GB)\nMDZ Digital\nLibrary (Schweter,\n2020)\nbert-historical-rw bert-base-historical-\ngerman-rw-cased historical\nFairy tales, historical\nnewspapers, magazine articles,\nnarrative texts, texts of Projekt\nGutenberg\n(Brunner et al.,\n2020)\nbert-europeana-\nfurther-pretrained -\ncontemporary,\nfurther\npretrained on\nhistorical texts\nBased on bert-base-german-\neuropeana-cased. Further\npretrained with dramatic texts\nof GerDracor, TextGrid and\nother (300 MB)\n-\nTable 2: Transformer-based models for the evaluation. Hugging Face-identiﬁer can be used to retrieve the models\nfrom the Hugging Face-platform, bert-europeana-further-pretrained was created by the authors of this paper via\nfurther pretraining.\nin improvements. Indeed, the accuracies become\nslightly worse and signiﬁcantly lower looking at\nsettings with multiple classes (e.g. 29% for sub-\nemotions on the ﬁltered corpus).\n5 Discussion and Future Work\nAs the results show, we can conﬁrm general ﬁnd-\nings of NLP-research for classiﬁcation tasks for\nvarious text genres, in the sense that transformer-\nbased models perform better than traditional tex-\ntual ML-approaches in our setting with German\nhistorical plays. However, we cannot conﬁrm our\nassumption that models pretrained on historical\nlanguage achieve better results because they are\ncloser to the language of our annotated material.\nIndeed, the best performing models are gbert-large\nand gelectra-large by deepset (Chan et al., 2020).\nThese are, to our knowledge, the largest German\nmodels trained on contemporary texts, primarly\ninternet texts. The difference between historical\nand these contemporary models is however small.\nSince the differences in the amount of text for the\npretraining are signiﬁcant (around 20 GB) it opens\nup the question if the performance of historical\nmodels improves with similarly large amounts of\ntexts.\nConsidering the different corpus instances, we\nshowed that ﬁltering out overlapping annotations\nannotators disagree upon results into the strongest\nperformance boost, although the training and test\nsize become smaller. Thus, it is crucial for our\nproject to ﬁnd ways to deal with disagreements\namong annotators. Due to the varied and overlap-\nping annotation lengths, we cannot rely on stan-\ndard solutions like majority voting. Furthermore,\nthe inherent subjectivity of literary texts and the\nresulting low agreement among annotators is a spe-\nciﬁc feature of these kind of texts. We do however\nthink that we can reduce disagreement with further\ntraining of the annotators and also by implement-\ning a subsequent step after the ﬁrst annotations\nof two annotators, in which a literary scholar ex-\npert creates a consensus annotation resolving dis-\nagreement. Additionally, we intend to switch from\nsingle-label classiﬁcation to multi-label emotion\nclassiﬁcation since this is more in line with the\nannotation process. This will open up further pos-\nsibilities to deal with overlapping annotations and\nintegrates this phenomenon into the classiﬁcation\ntask. Applying a heuristic to map single emotion\nclasses to entire speeches led to the models per-\nforming rather poorly compared to the other corpus\nmanifestations. For sub-emotion prediction with 13\nclasses, accuracies became 25% worse for certain\n74\nMethod acc\n(pol)\nF1\n(pol)\nacc\n(t-p)\nF1\n(t-p)\nacc\n(m-c)\nF1\n(m-c)\nacc\n(s-e)\nF1\n(s-e)\nrandom baseline 0.50 - 0.33 - 0.17 - 0.08 -\nmajority baseline 0.59 - 0.53 - 0.23 - 0.16 -\nbow-svm 0.74 0.72 0.66 0.62 0.47 0.45 0.35 0.32\nbow-bayes 0.78 0.78 0.70 0.68 0.52 0.50 0.39 0.35\nbert-base 0.83 0.83 0.76 0.76 0.60 0.60 0.49 0.48\nbert-europeana 0.84 0.84 0.76 0.76 0.61 0.61 0.50 0.49\nelectra-europeana 0.84 0.84 0.77 0.76 0.61 0.61 0.50 0.48\nbert-historical-rw 0.84 0.84 0.76 0.76 0.61 0.61 0.51 0.50\ngbert-large 0.85 0.85 0.78 0.77 0.63 0.63 0.52 0.52\ngelectra-large 0.85 0.85 0.78 0.78 0.64 0.64 0.53 0.52\nbert-europeana-\nfurther-pretrained 0.81 0.81 0.74 0.71 0.53 0.50 0.38 0.32\nTable 3: Evaluation results for the full corpus. F1-scores are weighted F1. pol= polarity, t-p=triple polarity, m-\nc=main class, s-e=sub-emotion. Best result per classiﬁcation is marked in bold for accuracies.\nMethod acc\n(pol)\nF1\n(pol)\nacc\n(t-p)\nF1\n(t-p)\nacc\n(m-c)\nF1\n(m-c)\nacc\n(s-e)\nF1\n(s-e)\nrandom baseline 0.50 - 0.33 - 0.17 - 0.08 -\nmajority baseline 0.60 - 0.55 - 0.25 - 0.15 -\nbow-svm 0.77 0.75 0.70 0.66 0.53 0.51 0.41 0.38\nbow-bayes 0.83 0.83 0.76 0.74 0.59 0.56 0.46 0.41\nbert-base 0.88 0.88 0.83 0.83 0.70 0.70 0.61 0.60\nbert-europeana 0.88 0.88 0.83 0.83 0.71 0.70 0.60 0.59\nelectra-europeana/acute.ts10.89 0.89 0.83 0.83 0.70 0.69 0.56 0.53\nbert-historical-rw 0.88 0.88 0.83 0.83 0.72 0.72 0.63 0.63\ngbert-large 0.89 0.89 0.84 0.84 0.75 0.75 0.66 0.66\ngelectra-large 0.90 0.90 0.85 0.85 0.74 0.74 0.64 0.63\nbert-europeana-\nfurther-pretrained 0.83 0.83 0.76 0.74 0.45 0.38 0.29 0.23\nTable 4: Evaluation results for the ﬁltered corpus. F1-scores are weighted F1. pol= polarity, t-p=triple polarity,\nm-c=main class, s-e=sub-emotion. Best result per classiﬁcation is marked in bold for accuracies.\nmodels. While one reason is that this corpus is the\nsmallest of all manifestations, we argue that the\nmain problem is, as annotations showed, that most\nspeeches consist of multiple, oftentimes differing\nemotion categories. Mapping them heuristically to\none results in text units including various emotional\nexpressions that are falsely mapped to one emo-\ntion. This problem intensiﬁes due to the fact that\nmany speeches are rather long and that the class\nimbalances for main classes and sub-emotions are\nsigniﬁcant. Thus, we plan to focus on smaller text\nunit sizes like sentences or n-grams in the future\nemotion prediction task over the entire corpus.\nConsidering the results for ﬁltered and full cor-\npus, the transformer-based models achieve state-\nof-the-art accuracies for polarity classiﬁcation (88-\n90%) compared to results with sentiment analysis\nwith similar amounts of classes on contemporary\nGerman (Chan et al., 2020). The results achieved\nby the transformer-based models for polarity are\nalso around 20% above results on German dramatic\ntexts predicted by lexicon-based sentiment anal-\nysis, which yields results around 70% (Schmidt\nand Burghardt, 2018). For the main class and\nsub-emotion classiﬁcation, results are, however,\nfor the best models (75% for main classes, 66%\nfor sub-emotions), below state-of-the-art results on\nemotion classiﬁcation tasks with 4 or more classes\nfor contemporary English texts for which accura-\ncies of up to 86% are reported (Shmueli and Ku,\n75\nMethod acc\n(pol)\nF1\n(pol)\nacc\n(t-p)\nF1\n(t-p)\nacc\n(m-c)\nF1\n(m-c)\nacc\n(s-e)\nF1\n(s-e)\nrandom baseline 0.50 - 0.33 - 0.17 - 0.08 -\nmajority baseline 0.60 - 0.51 - 0.23 - 0.16 -\nbow-svm 0.62 0.53 0.53 0.42 0.28 0.23 0.22 0.16\nbow-bayes 0.70 0.69 0.59 0.55 0.39 0.36 0.29 0.25\nbert-base 0.73 0.73 0.63 0.62 0.46 0.45 0.36 0.34\nbert-europeana 0.72 0.69 0.66 0.65 0.48 0.47 0.37 0.35\nelectra-europeana 0.74 0.74 0.66 0.65 0.46 0.45 0.36 0.32\nbert-historical-rw 0.74 0.74 0.64 0.64 0.47 0.47 0.39 0.37\ngbert-large 0.77 0.77 0.67 0.67 0.51 0.51 0.40 0.39\ngelectra-large 0.77 0.77 0.68 0.67 0.51 0.51 0.39 0.36\nbert-europeana-\nfurther-pretrained 0.65 0.57 0.54 0.43 0.29 0.23 0.19 0.12\nTable 5: Evaluation results for the speech corpus. F1-scores are weighted F1. pol= polarity, t-p=triple polarity,\nm-c=main class, s-e=sub-emotion. Best result per classiﬁcation is marked in bold for accuracies.\n2019; Yang et al., 2019; Cao et al., 2020), how-\never, for the most part, with larger training corpora\nand fewer classes as in our setting. We intend to\nimprove the performance to satisfactory levels by\nhyperparameter-tuning and especially by exploring\nrecommended ML-methods like over- and under-\nsampling to deal with the class imbalances (Buda\net al., 2018), which is one of the main problems of\nthe main class and sub-emotion classiﬁcation.\nAmong all transformer-based models, the bert-\neuropeana-model further pretrained on dramatic\ntexts yields the lowest accuracies. The performance\nbecomes especially low for main classes and sub-\nemotions (see table 4). A reason might be that,\nwhile research argues that further pretraining with\neven low amount of texts can show improvements,\nthe amount of text used in our setting (300 MB)\nis below the amounts reported in similar research\n(Kameswara Sarma et al., 2018; Gururangan et al.,\n2020; Rietzler et al., 2020). The usage of solely\ndramatic texts instead of varied forms of texts for\ntraining might also lead to problems in generaliz-\ning the speciﬁc language of the annotated mate-\nrial. Furthermore, a signiﬁcant proportion of the\nselected dramatic texts is actually of the middle\nto the end of the 19 th century and also of the be-\nginning of the 20 th century. Thus, the language\nmight again deviate strongly from the time span of\nour plays (1745-1807). This might also be a rea-\nson why the historical transformer-based models\nin our evaluation show no relevant improvements.\nInvestigating the training corpora for these models\n(Schweter, 2020; Brunner et al., 2020) shows that\nlarge proportions of the texts are actually of the\n19th and 20th century. For our future studies, we\nplan to continue our exploration of domain-speciﬁc\nﬁne-tuning by acquiring larger amounts of general\ntext material (and not only dramatic texts) focused\non the time span of our interest, 1650-1815, to\ntrain models from scratch and evaluate if we can\nidentify performance improvements. We intend to\nachieve satisfactory levels of accuracies to perform\nlarge-scale analysis of emotion distributions and\nprogressions for our entire corpus of around 300\nplays.\nAcknowledgements\nWe want to thank the following student annotators\nfor their contributions to this project: Carlina Eizen-\nberger, Viola Hipler, Emma Ruß, Leon Sautter and\nLisa Schattmann.\nFunding\nThis research is part of the project \"Emotions in\nDrama\" (Emotionen im Drama), funded by the Ger-\nman Research Foundation (DFG) and part of the\npriority programme SPP 2207 Computational Lit-\nerary Studies (CLS).\nReferences\nCecilia Ovesdotter Alm and Richard Sproat. 2005.\nEmotional Sequencing and Development in Fairy\nTales. In Affective Computing and Intelligent Inter-\naction, Lecture Notes in Computer Science, pages\n668–674, Berlin, Heidelberg. Springer.\n76\nIz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB-\nERT: A Pretrained Language Model for Scientiﬁc\nText. arXiv:1903.10676 [cs]. ArXiv: 1903.10676.\nAnnelen Brunner, Ngoc Duyen Tanja Tu, Lukas\nWeimer, and Fotis Jannidis. 2020. To bert or not\nto bert-comparing contextual embeddings in a deep\nlearning architecture for the automatic recognition\nof four types of speech, thought and writing repre-\nsentation. In SwissText/KONVENS.\nMateusz Buda, Atsuto Maki, and Maciej A.\nMazurowski. 2018. A systematic study of the\nclass imbalance problem in convolutional neural\nnetworks. Neural Networks, 106:249–259. ArXiv:\n1710.05381.\nLihong Cao, Sancheng Peng, Pengfei Yin, Yongmei\nZhou, Aimin Yang, and Xinguang Li. 2020. A Sur-\nvey of Emotion Analysis in Text Based on Deep\nLearning. In 2020 IEEE 8th International Con-\nference on Smart City and Informatization (iSCI) ,\npages 81–88, Guangzhou, China. IEEE.\nBranden Chan, Stefan Schweter, and Timo\nMöller. 2020. German’s Next Language Model.\narXiv:2010.10906 [cs]. ArXiv: 2010.10906.\nKevin Clark, Minh-Thang Luong, Quoc V . Le, and\nChristopher D. Manning. 2019. ELECTRA: Pre-\ntraining Text Encoders as Discriminators Rather\nThan Generators.\nDiogo Cortiz. 2021. Exploring Transformers in\nEmotion Recognition: a comparison of BERT,\nDistillBERT, RoBERTa, XLNet and ELECTRA.\narXiv:2104.02041 [cs]. ArXiv: 2104.02041.\nNhan Cach Dang, María N. Moreno-García, and Fer-\nnando De la Prieta. 2020. Sentiment Analysis Based\non Deep Learning: A Comparative Study. Electron-\nics, 9(3):483. ArXiv: 2006.03541.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nJakob Fehle, Thomas Schmidt, and Christian Wolff.\n2021. Lexicon-based sentiment analysis in german:\nSystematic evaluation of resources and preprocess-\ning techniques. In Proceedings of the 17th Confer-\nence on Natural Language Processing (KONVENS\n2021), Düsseldorf, Germany.\nFrank Fischer, Ingo Börner, Mathias Göbel, Ange-\nlika Hechtl, Christopher Kittel, Carsten Milling, and\nPeer Trilcke. 2019. Programmable Corpora: Intro-\nducing DraCor, an Infrastructure for the Research\non European Drama. Conference Name: Digital Hu-\nmanities 2019: \"Complexities\" (DH2019) Publisher:\nZenodo.\nEvelyn Gius, Jan Christoph Meister, Marco Petris,\nMalte Meister, Christian Bruck, Janina Jacke,\nMareike Schuhmacher, Marie Flüh, and Jan\nHorstmann. 2020. CATMA.\nSantiago González-Carvajal and Eduardo C. Garrido-\nMerchán. 2021. Comparing BERT against\ntraditional machine learning text classiﬁcation.\narXiv:2005.13012 [cs, stat]. ArXiv: 2005.13012.\nSuchin Gururangan, Ana Marasovi ´c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A. Smith. 2020. Don’t Stop Pretraining:\nAdapt Language Models to Domains and Tasks.\narXiv:2004.10964 [cs]. ArXiv: 2004.10964.\nPrathusha Kameswara Sarma, Yingyu Liang, and Bill\nSethares. 2018. Domain Adapted Word Embed-\ndings for Improved Sentiment Classiﬁcation. In\nProceedings of the Workshop on Deep Learning Ap-\nproaches for Low-Resource NLP, pages 51–59, Mel-\nbourne. Association for Computational Linguistics.\nEvgeny Kim and Roman Klinger. 2019. A Survey on\nSentiment and Emotion Analysis for Computational\nLiterary Studies. Zeitschrift für digitale Geisteswis-\nsenschaften. ArXiv: 1808.03137.\nKai Labusch, Clemens Neudecker, and David Zellhofer.\n2019. BERT for Named Entity Recognition in Con-\ntemporary and Historical German. page 9.\nJ. Richard Landis and Gary G. Koch. 1977. The Mea-\nsurement of Observer Agreement for Categorical\nData. Biometrics, 33(1):159–174. Publisher: [Wi-\nley, International Biometric Society].\nSaif Mohammad. 2011. From Once Upon a Time to\nHappily Ever After: Tracking Emotions in Novels\nand Fairy Tales. In Proceedings of the 5th ACL-HLT\nWorkshop on Language Technology for Cultural Her-\nitage, Social Sciences, and Humanities , pages 105–\n114, Portland, OR, USA. Association for Computa-\ntional Linguistics.\nMika V . Mäntylä, Daniel Graziotin, and Miikka Kuu-\ntila. 2018. The evolution of sentiment analysis—A\nreview of research topics, venues, and top cited pa-\npers. Computer Science Review, 27:16–32.\nEric T. Nalisnick and Henry S. Baird. 2013. Character-\nto-Character Sentiment Analysis in Shakespeare’s\nPlays. In Proceedings of the 51st Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 2: Short Papers) , pages 479–483, Soﬁa, Bul-\ngaria. Association for Computational Linguistics.\nFabian Pedregosa, Gaël Varoquaux, Alexandre Gram-\nfort, Vincent Michel, Bertrand Thirion, Olivier\nGrisel, Mathieu Blondel, Peter Prettenhofer, Ron\nWeiss, Vincent Dubourg, and others. 2011. Scikit-\nlearn: Machine learning in Python. Journal of ma-\nchine learning research, 12(Oct):2825–2830.\n77\nXipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao,\nNing Dai, and Xuanjing Huang. 2020. Pre-trained\nModels for Natural Language Processing: A Survey.\narXiv:2003.08271 [cs]. ArXiv: 2003.08271.\nAndrew J. Reagan, Lewis Mitchell, Dilan Kiley,\nChristopher M. Danforth, and Peter Sheridan Dodds.\n2016. The emotional arcs of stories are dominated\nby six basic shapes. EPJ Data Science , 5(1):31.\nArXiv: 1606.07772.\nNils Reiter. 2020. Anleitung zur Erstellung von Anno-\ntationsrichtlinien, pages 193–202. De Gruyter.\nAlexander Rietzler, Sebastian Stabinger, Paul Opitz,\nand Stefan Engl. 2020. Adapt or Get Left Be-\nhind: Domain Adaptation through BERT Language\nModel Finetuning for Aspect-Target Sentiment Clas-\nsiﬁcation. In Proceedings of the 12th Language\nResources and Evaluation Conference, pages 4933–\n4941, Marseille, France. European Language Re-\nsources Association.\nThomas Schmidt. 2019. Distant reading sentiments\nand emotions in historic german plays. In Ab-\nstract Booklet, DH_Budapest_2019 , pages 57–60.\nBudapest, Hungary.\nThomas Schmidt and Manuel Burghardt. 2018. An\nEvaluation of Lexicon-based Sentiment Analysis\nTechniques for the Plays of Gotthold Ephraim Less-\ning. In Proceedings of the Second Joint SIGHUM\nWorkshop on Computational Linguistics for Cultural\nHeritage, Social Sciences, Humanities and Litera-\nture, pages 139–149, Santa Fe, New Mexico. Asso-\nciation for Computational Linguistics.\nThomas Schmidt, Manuel Burghardt, and Katrin Den-\nnerlein. 2018. Sentiment Annotation of Historic\nGerman Plays: An Empirical Study on Annotation\nBehavior. In Sandra Kübler and Heike Zinsmeister,\neditors, Proceedings of the Workshop on Annotation\nin Digital Humanities 2018 (annDH 2018) , pages\n47–52. RWTH Aachen, Soﬁa, Bulgaria.\nThomas Schmidt, Manuel Burghardt, Katrin Denner-\nlein, and Christian Wolff. 2019a. Sentiment Anno-\ntation for Lessing’s Plays: Towards a Language Re-\nsource for Sentiment Analysis on German Literary\nTexts. In Thierry Declerck and John P. McCrae, edi-\ntors, 2nd Conference on Language, Data and Knowl-\nedge (LDK 2019), pages 45–50. Leipzig, Germany.\nThomas Schmidt, Manuel Burghardt, and Christian\nWolff. 2019b. Toward Multimodal Sentiment Anal-\nysis of Historic Plays: A Case Study with Text and\nAudio for Lessing’s Emilia Galotti. In Proceedings\nof the Digital Humanities in the Nordic Countries\n4th Conference, volume 2364 of CEUR Workshop\nProceedings, pages 405–414, Copenhagen, Den-\nmark. CEUR-WS.org.\nThomas Schmidt, Johanna Dangel, and Christian Wolff.\n2021a. Senttext: A tool for lexicon-based sentiment\nanalysis in digital humanities. In Thomas Schmidt\nand Christian Wolff, editors, Information Science\nand its Neighbors from Data Science to Digital\nHumanities. Proceedings of the 16th International\nSymposium of Information Science (ISI 2021) , vol-\nume 74, pages 156–172. Werner Hülsbusch, Glück-\nstadt.\nThomas Schmidt, Katrin Dennerlein, and Christian\nWolff. 2021b. Towards a Corpus of Historical Ger-\nman Plays with Emotion Annotations. In 3rd Con-\nference on Language, Data and Knowledge (LDK\n2021), volume 93 ofOpen Access Series in Informat-\nics (OASIcs), pages 9:1–9:11, Dagstuhl, Germany.\nSchloss Dagstuhl – Leibniz-Zentrum für Informatik.\nThomas Schmidt, Katrin Dennerlein, and Christian\nWolff. 2021c. Using Deep Learning for Emotion\nAnalysis of 18th and 19th Century German Plays.\nIn Manuel Burghardt, Lisa Dieckmann, Timo Steyer,\nPeer Trilcke, Niels-Oliver Walkowski, Joëlle Weis,\nand Ulrike Wuttke, editors, Fabrikation von Erken-\nntnis. Experimente in den Digital Humanities.\nThomas Schmidt, Isabella Engl, David Halbhuber, and\nChristian Wolff. 2020a. Comparing live sentiment\nannotation of movies via arduino and a slider with\ntextual annotation of subtitles. In Post-Proceedings\nof the 5th Conference Digital Humanities in the\nNordic Countries (DHN 2020), pages 212–223.\nThomas Schmidt, Florian Kaindl, and Christian Wolff.\n2020b. Distant reading of religious online commu-\nnities: A case study for three religious forums on\nreddit. In Proceedings of the Digital Humanities in\nthe Nordic Countries 5th Conference (DHN 2020) ,\npages 157–172, Riga, Latvia.\nThomas Schmidt, Brigitte Winterl, Milena Maul,\nAlina Schark, Andrea Vlad, and Christian Wolff.\n2019c. Inter-rater agreement and usability: A\ncomparative evaluation of annotation tools for sen-\ntiment annotation. In INFORMATIK 2019: 50\nJahre Gesellschaft für Informatik – Informatik für\nGesellschaft (Workshop-Beiträge), pages 121–133,\nBonn. Gesellschaft für Informatik e.V .\nStefan Schweter. 2020. Europeana BERT and ELEC-\nTRA models.\nStefan Schweter and Johannes Baiter. 2019. Towards\nRobust Named Entity Recognition for Historic Ger-\nman. In Proceedings of the 4th Workshop on Rep-\nresentation Learning for NLP (RepL4NLP-2019) ,\npages 96–103, Florence, Italy. Association for Com-\nputational Linguistics.\nBoaz Shmueli and Lun-Wei Ku. 2019. SocialNLP\nEmotionX 2019 Challenge Overview: Predict-\ning Emotions in Spoken Dialogues and Chats.\narXiv:1909.07734 [cs]. ArXiv: 1909.07734.\nRachele Sprugnoli, Sara Tonelli, Alessandro Marchetti,\nand Giovanni Moretti. 2015. Towards sentiment\nanalysis for historical texts. Digital Scholarship in\nthe Humanities , 31:762–772. Publisher: Oxford :\nOxford University Press.\n78\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nHuggingFace’s Transformers: State-of-the-art Nat-\nural Language Processing. arXiv:1910.03771 [cs].\nArXiv: 1910.03771.\nIan Wood, John McCrae, Vladimir Andryushechkin,\nand Paul Buitelaar. 2018a. A Comparison of Emo-\ntion Annotation Approaches for Text. Information,\n9(5):117.\nIan Wood, John P. McCrae, Vladimir Andryushechkin,\nand Paul Buitelaar. 2018b. A Comparison Of Emo-\ntion Annotation Schemes And A New Annotated\nData Set. In Proceedings of the Eleventh Interna-\ntional Conference on Language Resources and Eval-\nuation (LREC 2018) , Miyazaki, Japan. European\nLanguage Resources Association (ELRA).\nKisu Yang, Dongyub Lee, Taesun Whang, Seolhwa\nLee, and Heuiseok Lim. 2019. EmotionX-KU:\nBERT-Max based Contextual Emotion Classiﬁer.\narXiv:1906.11565 [cs]. ArXiv: 1906.11565.\nAlbin Zehe, Martin Becker, Lena Hettinger, Andreas\nHotho, Isabella Reger, and Fotis Jannidis. 2016. Pre-\ndiction of Happy Endings in German Novels. In\nDMNLP@PKDD/ECML.\nEmily Öhman. 2020. Challenges in Annotation: An-\nnotator Experiences from a Crowdsourced Emotion\nAnnotation Task. In Proceedings of the Digital Hu-\nmanities in the Nordic Countries 5th Conference ,\npages 293–301. CEUR Workshop Proceedings.\n79\nA Appendix: Class Distributions for\nCorpus Manifestations\nEmotion category absolute %\nMC: emotions of affection 1,965 23\nMC: emotions of joy 1,348 16\nMC: emotions of fear 614 7\nMC: emotions of rejection 2,153 25\nMC: emotions of suffering 1,566 18\nemotional movement 906 9\nOverall 8,552 100\nTable 6: Distributions of main classes for the ﬁltered\ncorpus. Percentages are rounded.\nEmotion category absolute %\ndesire 28 0\nlove 1,032 14\nfriendship 185 2\nadmiration 468 6\njoy 1,103 15\nSchadenfreude 181 2\nfear 390 5\ndespair 160 2\nanger 1,002 13\nhate, disgust 690 9\nsuffering 1,045 14\ncompassion 313 4\nemotional movement 906 9\nOverall 7,503 100\nTable 7: Distributions of sub-emotions for the ﬁltered\ncorpus. Polarity distribution is 6,018 negative (60%)\nand 3,944 positive (40%). Percentages are rounded.\nEmotion category absolute %\nMC: emotions of affection 1,198 18\ndesire 27 0\nlove 602 9\nfriendship 126 2\nadmiration 441 7\nMC: emotions of joy 1,088 16\njoy 881 13\nSchadenfreude 201 3\nMC: emotions of fear 725 11\nfear 391 6\ndespair 339 5\nMC: emotions of rejection 1,538 23\nanger 919 14\nhate, disgust 660 10\nMC: emotions of suffering 1,175 17\nsuffering 833 12\ncompassion 297 4\nemotional movement 1,022 15\nOverall 6,741 100\nTable 8: Distributions of emotions for the speech cor-\npus. Polarity distribution is 3,414 negative (60%) and\n2,305 positive (40%). Percentages are rounded.",
  "topic": "German",
  "concepts": [
    {
      "name": "German",
      "score": 0.7672111988067627
    },
    {
      "name": "Computer science",
      "score": 0.7321759462356567
    },
    {
      "name": "Language model",
      "score": 0.714083194732666
    },
    {
      "name": "Natural language processing",
      "score": 0.7034627199172974
    },
    {
      "name": "Transformer",
      "score": 0.6966625452041626
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6019905209541321
    },
    {
      "name": "Annotation",
      "score": 0.5176734924316406
    },
    {
      "name": "Sentiment analysis",
      "score": 0.48857006430625916
    },
    {
      "name": "Linguistics",
      "score": 0.34038323163986206
    },
    {
      "name": "Speech recognition",
      "score": 0.32849347591400146
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I60668342",
      "name": "University of Regensburg",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I25974101",
      "name": "University of Würzburg",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210095662",
      "name": "Faculty of Media",
      "country": "SI"
    }
  ]
}