{
  "title": "Embedding Search for Quranic Texts based on Large Language Models",
  "url": "https://openalex.org/W4393170045",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2338736176",
      "name": "Mohammed Alqarni",
      "affiliations": [
        "Jeddah University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3179463712",
    "https://openalex.org/W2914384366",
    "https://openalex.org/W6903792086",
    "https://openalex.org/W2464904837",
    "https://openalex.org/W3182591145",
    "https://openalex.org/W2940091806",
    "https://openalex.org/W2120286714",
    "https://openalex.org/W6903555815",
    "https://openalex.org/W2328123973",
    "https://openalex.org/W2999262142",
    "https://openalex.org/W4225631575",
    "https://openalex.org/W2948002067",
    "https://openalex.org/W4288116810",
    "https://openalex.org/W3023002518",
    "https://openalex.org/W2156448467",
    "https://openalex.org/W4205401909",
    "https://openalex.org/W4366559971",
    "https://openalex.org/W2785249538",
    "https://openalex.org/W2304100715",
    "https://openalex.org/W3032265246",
    "https://openalex.org/W3120859818"
  ],
  "abstract": "Semantic search is the process of retrieving relevant information from a large corpus of texts based on the meaning and context of the query. This paper is introduced in order to explore the use of large language models for semantic search of Quranic texts. The Quran, which is the central religious text of Islam, contains rich and complex linguistic and semantic features that pose challenges for traditional keyword-based search methods. This study investigates a semantic search approach utilizing. Large Language Models (LLM) embedding and assess the performance of LLM embedding in comparison to a baseline embedding-based search method using a set of queries that represent different semantic search levels. In addition, this study will also discuss the limitations and implications of using large language models for semantic search of Quranic texts and suggest directions for future research. A significant finding in this study is the consistent effectiveness of the LLM embedding across varying semantic complexities. This suggests that embedding using LLMs can capture deep semantic connections effectively. On the other hand, as a second finding, the state-of-the-art transformer, AraT5, outperforms LLM embeddings in low-level semantic searches, indicating potential for further LLM fine-tuning on Arabic text corpora.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.9078353643417358
    },
    {
      "name": "Embedding",
      "score": 0.7237181067466736
    },
    {
      "name": "Language model",
      "score": 0.45586445927619934
    },
    {
      "name": "Natural language processing",
      "score": 0.45311224460601807
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4095383286476135
    },
    {
      "name": "Programming language",
      "score": 0.3572681248188019
    }
  ]
}