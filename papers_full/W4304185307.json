{
  "title": "ASRS-CMFS vs. RoBERTa: Comparing Two Pre-Trained Language Models to Predict Anomalies in Aviation Occurrence Reports with a Low Volume of In-Domain Data Available",
  "url": "https://openalex.org/W4304185307",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5082223661",
      "name": "Samuel Kierszbaum",
      "affiliations": [
        "École Nationale de l’Aviation Civile"
      ]
    },
    {
      "id": "https://openalex.org/A5083638199",
      "name": "Thierry Klein",
      "affiliations": [
        "Institut de Mathématiques de Toulouse"
      ]
    },
    {
      "id": "https://openalex.org/A5018831676",
      "name": "Laurent Lapasset",
      "affiliations": [
        "Capgemini (France)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2971277088",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W3099950029",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3105069964",
    "https://openalex.org/W2120530657",
    "https://openalex.org/W3168194750",
    "https://openalex.org/W2460755166",
    "https://openalex.org/W3127899369",
    "https://openalex.org/W3113833985",
    "https://openalex.org/W3136624224",
    "https://openalex.org/W2970442950",
    "https://openalex.org/W1499582806",
    "https://openalex.org/W2999309192",
    "https://openalex.org/W3105424285",
    "https://openalex.org/W3166904074",
    "https://openalex.org/W2781900029",
    "https://openalex.org/W2970971581"
  ],
  "abstract": "We consider the problem of solving Natural Language Understanding (NLU) tasks characterized by domain-specific data. An effective approach consists of pre-training Transformer-based language models from scratch using domain-specific data before fine-tuning them on the task at hand. A low domain-specific data volume is problematic in this context, given that the performance of language models relies heavily on the abundance of data during pre-training. To study this problem, we create a benchmark replicating realistic field use of language models to classify aviation occurrences extracted from the Aviation Safety Reporting System (ASRS) corpus. We compare two language models on this new benchmark: ASRS-CMFS, a compact model inspired from RoBERTa, pre-trained from scratch using only little domain-specific data, and the regular RoBERTa model, with no domain-specific pre-training. The RoBERTa model benefits from its size advantage, while the ASRS-CMFS benefits from the pre-training from scratch strategy. We find no compelling statistical evidence that RoBERTa outperforms ASRS-CMFS, but we show that ASRS-CMFS is more compute-efficient than RoBERTa. We suggest that pre-training a compact model from scratch is a good strategy for solving domain-specific NLU tasks using Transformer-based language models in the context of domain-specific data scarcity.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6791344285011292
    },
    {
      "name": "Scratch",
      "score": 0.6738452911376953
    },
    {
      "name": "Aviation",
      "score": 0.6529196500778198
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.6521522998809814
    },
    {
      "name": "Language model",
      "score": 0.6179884672164917
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5721002221107483
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5608331561088562
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48149001598358154
    },
    {
      "name": "Transformer",
      "score": 0.4692029356956482
    },
    {
      "name": "Natural language processing",
      "score": 0.4158073663711548
    },
    {
      "name": "Data mining",
      "score": 0.3291091024875641
    },
    {
      "name": "Machine learning",
      "score": 0.3268442153930664
    },
    {
      "name": "Engineering",
      "score": 0.14711979031562805
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Aerospace engineering",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I100296615",
      "name": "École Nationale de l’Aviation Civile",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I84500057",
      "name": "Institut de Mathématiques de Toulouse",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210136798",
      "name": "Capgemini (France)",
      "country": "FR"
    }
  ]
}