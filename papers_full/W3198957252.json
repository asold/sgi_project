{
    "title": "LM-Critic: Language Models for Unsupervised Grammatical Error Correction",
    "url": "https://openalex.org/W3198957252",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A2656961764",
            "name": "Michihiro Yasunaga",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A1878631932",
            "name": "Jure Leskovec",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2171686691",
            "name": "Percy Liang",
            "affiliations": [
                "Stanford University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3034999214",
        "https://openalex.org/W2170240176",
        "https://openalex.org/W2470324779",
        "https://openalex.org/W2963012544",
        "https://openalex.org/W2963881719",
        "https://openalex.org/W2925188774",
        "https://openalex.org/W2970868759",
        "https://openalex.org/W2153013403",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W3103735191",
        "https://openalex.org/W2964258094",
        "https://openalex.org/W2982756474",
        "https://openalex.org/W2936695845",
        "https://openalex.org/W2986388218",
        "https://openalex.org/W2321916036",
        "https://openalex.org/W2962901607",
        "https://openalex.org/W2947415936",
        "https://openalex.org/W2120708938",
        "https://openalex.org/W2803237843",
        "https://openalex.org/W2124725212",
        "https://openalex.org/W2098297786",
        "https://openalex.org/W3035441470",
        "https://openalex.org/W2170527467",
        "https://openalex.org/W108011198",
        "https://openalex.org/W2315316408",
        "https://openalex.org/W2978670439",
        "https://openalex.org/W2785047343",
        "https://openalex.org/W2611669587",
        "https://openalex.org/W2971332944",
        "https://openalex.org/W2963602293",
        "https://openalex.org/W2168776871",
        "https://openalex.org/W2972963535",
        "https://openalex.org/W3001279689",
        "https://openalex.org/W4298393544",
        "https://openalex.org/W3037162118",
        "https://openalex.org/W2948335087",
        "https://openalex.org/W2964003257",
        "https://openalex.org/W2964121744",
        "https://openalex.org/W2963216553",
        "https://openalex.org/W3104633006",
        "https://openalex.org/W2964153729",
        "https://openalex.org/W2125616599",
        "https://openalex.org/W2972799129",
        "https://openalex.org/W2798416860",
        "https://openalex.org/W3169504754",
        "https://openalex.org/W2294498899",
        "https://openalex.org/W2946417913",
        "https://openalex.org/W2144950812",
        "https://openalex.org/W2970521905",
        "https://openalex.org/W2931749839",
        "https://openalex.org/W2530291685",
        "https://openalex.org/W4385245566",
        "https://openalex.org/W2589277916",
        "https://openalex.org/W2964082031",
        "https://openalex.org/W2951714314",
        "https://openalex.org/W2806120502",
        "https://openalex.org/W43022990",
        "https://openalex.org/W1673923490",
        "https://openalex.org/W2996403597",
        "https://openalex.org/W2936597270",
        "https://openalex.org/W2971124360",
        "https://openalex.org/W2970429618",
        "https://openalex.org/W2946359678",
        "https://openalex.org/W2892228078",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W1815076433",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W2741494657",
        "https://openalex.org/W2466204975"
    ],
    "abstract": "Grammatical error correction (GEC) requires a set of labeled ungrammatical / grammatical sentence pairs for training, but obtaining such annotation can be prohibitively expensive. Recently, the Break-It-Fix-It (BIFI) framework has demonstrated strong results on learning to repair a broken program without any labeled examples, but this relies on a perfect critic (e.g., a compiler) that returns whether an example is valid or not, which does not exist for the GEC task. In this work, we show how to leverage a pretrained language model (LM) in defining an LM-Critic, which judges a sentence to be grammatical if the LM assigns it a higher probability than its local perturbations. We apply this LM-Critic and BIFI along with a large set of unlabeled sentences to bootstrap realistic ungrammatical / grammatical pairs for training a corrector. We evaluate our approach on GEC datasets on multiple domains (CoNLL-2014, BEA-2019, GMEG-wiki and GMEG-yahoo) and show that it outperforms existing methods in both the unsupervised setting (+7.7 F0.5) and the supervised setting (+0.5 F0.5).",
    "full_text": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7752–7763\nNovember 7–11, 2021.c⃝2021 Association for Computational Linguistics\n7752\nLM-Critic:\nLanguage Models for Unsupervised Grammatical Error Correction\nMichihiro Yasunaga Jure Leskovec Percy Liang\nStanford University\n{myasu,jure,pliang}@cs.stanford.edu\nAbstract\nTraining a model for grammatical error correc-\ntion (GEC) requires a set of labeled ungram-\nmatical / grammatical sentence pairs, but man-\nually annotating such pairs can be expensive.\nRecently, the Break-It-Fix-It (BIFI) framework\nhas demonstrated strong results on learning to\nrepair a broken program without any labeled ex-\namples, but this relies on a perfect critic ( e.g.,\na compiler) that returns whether an example is\nvalid or not, which does not exist for the GEC\ntask. In this work, we show how to leverage a\npretrained language model (LM) in deﬁning an\nLM-Critic, which judges a sentence to be gram-\nmatical if the LM assigns it a higher probability\nthan its local perturbations. We apply this LM-\nCritic and BIFI along with a large set of unla-\nbeled sentences to bootstrap realistic ungram-\nmatical/grammatical pairs for training a correc-\ntor. We evaluate our approach on GEC datasets\nacross multiple domains (CoNLL-2014, BEA-\n2019, GMEG-wiki and GMEG-yahoo) and\nshow that it outperforms existing methods in\nboth the unsupervised setting (+7.7 F 0.5) and\nthe supervised setting (+0.5 F0.5).\n1 Introduction\nGrammatical error correction (GEC) is the task\nof ﬁxing grammatical errors in text, such as typos,\ntense and article mistakes. Recent works cast GEC\nas a translation problem, using encoder-decoder\nmodels to map bad (ungrammatical) sentences\ninto good (grammatical) sentences (Yuan and\nBriscoe, 2016; Xie et al., 2016; Ji et al., 2017;\nChollampatt and Ng, 2018; Junczys-Dowmunt\net al., 2018). These methods rely on a combination\nof human-labeled data ( i.e., ⟨bad, good ⟩pairs)\n(Nicholls, 2003; Yannakoudakis et al., 2011; Bryant\net al., 2019) and synthetic data, which are generated\nby corrupting good sentences into ⟨synthetic bad,\ngood⟩pairs (Awasthi et al., 2019; Kiyono et al.,\n2019). Human-labeled pairs are representative\nof real human errors but are expensive to obtain,\nwhile synthetic pairs are cheap but are unrealistic,\ndeviating from the distribution of grammatical\n(a) Grammatical error correction (GEC) via LM-Critic\nShe like cats. ✘ Bad (ungrammatical)\n✓  Good (grammatical)\nCritic\nSentence\nBad\nFixerShe like cats. She likes cats.\nGood\nLM-Critic\nGEC system\n(b) Idea behind LM-Critic: Local optimum criterion\nFigure 1: Illustration of LM-Critic. (a) In this work, we train\na ﬁxer for grammatical error correction (GEC) by leveraging\nLM-Critic that assesses the grammaticality. (b) LM-Critic\ndeems a sentence to be grammatical if a pretrained language\nmodel ( e.g., GPT2) assigns it a higher probability than\ncandidates in its local neighborhood (e.g., edit distance 1).\nerrors humans make (Grundkiewicz et al., 2019).\nHow to obtain inexpensive yet realistic paired data\nto improve GEC remains a key challenge, especially\nin domains or languages with no labeled GEC data\n(Napoles et al., 2019; Náplava and Straka, 2019).\nBreak-It-Fix-It (BIFI; Yasunaga and Liang\n(2021)) is a recent method to obtain realistic paired\ndata from unlabeled data, which has shown promise\nin the task of source code repair. The idea of BIFI\nis that using an initial ﬁxer ( e.g., trained on syn-\nthetic data) and a critic that tells if an input is bad\nor good (e.g., compiler, which checks if code has an\nerror), BIFI iteratively trains the ﬁxer and a breaker\nto generate better paired data. Speciﬁcally, BIFI (1)\napplies the ﬁxer to bad examples and keeps outputs\naccepted by the critic, (2) trains a breaker on the re-\n7753\nsulting paired data and uses it to generate more pairs,\nand (3) trains the ﬁxer on the pairs generated in Step\n(1) and (2). This way, BIFI adapts the ﬁxer to more\nrealistic distributions of⟨bad, good⟩pairs, only us-\ning unlabeled data. However, BIFI is not directly\napplicable to GEC because it requires an oracle critic\n(e.g., compiler), which does not exist for GEC.\nIn this work, we proposeLM-Critic, a simple ap-\nproximate critic for assessing grammaticality (§3),\nand apply it with BIFI to learn GEC from unlabeled\ndata (§4). Speciﬁcally, motivated by recent progress\nin large language models (LMs) (e.g., GPT2, GPT3;\nRadford et al. (2019); Brown et al. (2020)) and an\nintuition that a good LM assigns a higher probability\nto grammatical sentences than ungrammatical\ncounterparts, we use an LM’s probability to deﬁne\na critic for grammaticality. A naive approach is to\ndeem a sentence as grammatical if its probability\nexceeds an absolute threshold, but this does not\nwork in practice,e.g., LMs may assign a high prob-\nability just because the sentence has more common\nwords. We hence compare probabilities in local\nneighborhood of sentences. Concretely, LM-Critic\nis deﬁned by two components, an LM (e.g., GPT2)\nand a neighborhood function ( e.g., edit distance\n1), and deems a sentence to be grammatical if the\nLM assigns it the highest probability in its local\nneighborhood (Figure 1; local optimum criterion).\nUsing this LM-Critic, we apply BIFI to the GEC\ntask. Notably, our approach, both the LM-Critic\nand GEC learning, does not require labeled data.\nWe evaluate our proposed approach on GEC\nbenchmarks across multiple domains, CoNLL-2014\n(Ng et al., 2014), BEA-2019 (Bryant et al., 2019),\nGMEG-yahoo, and GMEG-wiki (Napoles et al.,\n2019). We achieve strong performance in the\nunsupervised setting ( i.e., no labeled data), out-\nperforming the baseline ﬁxer trained on synthetic\ndata by 7.7 F 0.5 on average. We also evaluate in\nthe supervised setting, where we take the state-\nof-the-art model GECToR (Omelianchuk et al.,\n2020) as the baseline ﬁxer, and further ﬁne-tune\nit by applying our approach using unlabeled data.\nWe achieve 65.8 / 72.9 F 0.5 on CoNLL-2014 /\nBEA-2019, outperforming GECToR by 0.5 F 0.5.\nOur results also suggest that while existing BIFI\nassumed access to an oracle critic (i.e., compiler),\nan approximate critic (i.e., LM-Critic) can also help\nto improve model learning.\n2 Problem setup\nThe task of grammatical error correction (GEC)\nis to map an ungrammatical sentence xbad into a\ngrammatical version of it, xgood (one that has the\nsame intended meaning). A GEC model (ﬁxer) f\naims to learn this mapping, typically using apaired\ndataset Dpair = {(xbad(i),xgood(i))}. In particular,\nwe call itlabeled if the pairs are human-annotated.\nIn contrast, we call unlabeled data a set of raw\nsentences Dunlabel ={x(i)}. For simplicity, we use\n“good”/“bad” to mean grammatical/ungrammatical\ninterchangeably. Unlike a ﬁxer, which maps xbad\nto xgood, a critic cmerely assesses whether an input\nis good or bad: for a sentencex,\nc(x)=\n{\n1 if xis good\n0 if xis bad. (1)\nGiven unlabeled data x’s (some of which are\ngood, some of which are bad), and a language model\n(LM), which returns a probability distributionp(x)\nover sentencesx, we aim to deﬁne the critic (§3; LM-\nCritic) and use that to obtain the ﬁxer (§4; BIFI).\n3 LM-Critic\nThe core of our approach to GEC is a critic, which\nreturns whether a sentence is good (grammatical) or\nbad (ungrammatical). Motivated by recent progress\nin large-scale pre-trained LMs (e.g., GPT2, GPT3;\nRadford et al. (2019); Brown et al. (2020)), we aim\nto use an LM’s probability score to deﬁne a critic for\ngrammaticality. Speciﬁcally, we propose a criterion\nthat deems a sentence to be good if it has the\nhighest probability within its local neighborhood\n(local optimum criterion; §3.1). We implement\nthis criterion using a pretrained LM and a sentence\nperturbation function (LM-Critic; §3.2). We then\ndo an intrinsic study on how well LM-Critic works\nin practice (§3.3).\n3.1 Local optimum criterion of grammaticality\nOur starting point is the idea that a good LM assigns\na higher probability to grammatical sentences than\nungrammatical ones. With this idea, a naive way\nto judge grammaticality might be to ﬁnd a threshold\n(δ) for the absolute probability, and let the critic be:\nAbsThr-Critic(x)=\n{\n1 if p(x)>δ\n0 otherwise. (2)\nHowever, this does not work in practice. In Figure\n1, for instance, “Alice likes cats” (4th sentence) is\ngrammatical but has a lower probability (according\nto GPT2) than “Better that it” (2nd sentence), which\nis ungrammatical. This is because the two sentences\nhave different meanings and are not directly compa-\nrable. We also empirically ﬁnd that this critic based\non absolute threshold does not work well (§3.3.3).\nThis observation motivates us to compare\nsentences with the same intended meaning, and\n7754\nleads to the following two reﬁned intuitions.\nIntuition 1 (Correlation of grammaticality and\nprobability). For a grammatical sentence,xgood,\nand an ungrammaticalversion of it (with the same\nintended meaning), xbad, we have\np(xbad)<p(xgood). (3)\nIntuition 2 (Local neighborhood of sentences).\nAssume for simplicity that every sentence has\nexactly one grammatical version of it ( i.e., if the\nsentence is grammatical, itself; if not, its corrected\nversion).1 For each sentence x, there is a set\nof sentences, B(x) (local neighborhood ), that\nconsists of the grammatical version and all other\nungrammatical versions ofx.\nAssuming the above two intuitions, we obtain the\nfollowing criterion for judging grammaticality,\nwhere the idea is to compare sentences within the\nmeaning-preserving local neighborhood.\nLocal optimum criterion of grammaticality.\nFor each sentencex, we letB(x) be its local neigh-\nborhood as deﬁned in Intuition 2. We then have\nxis grammatical iff x=argmax\nx′∈B(x)\np(x′). (4)\nThe justiﬁcation is as follows. Ifxis grammatical,\nthen by Intuition 1,xhas a higher probability than\nany other sentences in B(x), as they are ungram-\nmatical; hence, we have the RHS of iff. On the other\nhand, if xis ungrammatical, then by Intuition 1, the\ngrammatical version of xhas a higher probability\nthan x, which contradicts with the RHS of iff.\nThe idea is to deem a sentence to be grammatical\nif it has the highest probability within its meaning-\npreserving local neighborhood (Figure 1). We will\nnext describe how to implement this criterion in\npractice.\n3.2 Implementation of LM-Critic\nWe implement LM-Critic by approximating the\nlocal optimum criterion. First, for the sentence prob-\nability p(x), we use a pretrained LM’s probability\nscore. As obtaining the ground-truth local neighbor-\nhood B(x) is difﬁcult, we aim to get an approximate,\nˆB(x): we implement a sentence perturbation func-\ntion b, and let ˆB(x) be samples fromb(x). To check\n1We acknowledge that this assumption may not hold in\nsome cases, e.g., an ungrammatical sentence may have no\ncorrection (“asdfghgfdsa”—just a random typo?) or multiple\ncorrections (“The cat sleep.”—change “sleep” to the present\ntense or past?). We accept this assumption considering that\nit is often sufﬁcient in common GEC datasets, and leave the\nrelaxation of the assumption for future work.\nthe grammaticality of a sentence, we apply the local\noptimum criterion (Eq 4) using ˆB(x):\nLM-Critic(x)=\n\n\n\n1 if x=argmax\nx′∈ˆB(x)\np(x′)\n0 otherwise.\n(5)\nThere are three decisions for implementing\nLM-Critic: choice of a pretrained LM, perturbation\nfunction b, and sampling method of perturbations.\nPretrained LM. We experiment with various\nsizes of GPT2 models (Radford et al., 2019)—\nGPT2 (117M parameters), GPT2-medium (345M),\nGPT2-large (774M), GPT2-xl (1.6B). These LMs\nwere trained on a large set of web text (40GB).\nPerturbation function. We study three variants:\n•ED1. Given a sentence, we generate edit-distance\none (ED1) perturbations in the character space.\nFollowing prior works in typo generation (Pruthi\net al., 2019; Jones et al., 2020), we randomly in-\nsert a lowercase letter, delete a character, replace\na character, or swap two adjacent characters.\n•ED1 + Word-level heuristics (all). ED1 can\ncover most of the character-level typos but may\nnot cover word-level grammatical errors, such as\nmissing an article. Besides ED1, here we include\nheuristics for word-level perturbations used in\nAwasthi et al. (2019), which randomly inserts,\ndeletes, or replaces a word based on its dictionary.\nPlease refer to Awasthi et al. for more details.\n•ED1 + Word-level heuristics. We noticed\nthat the above word-level heuristics include\nperturbations that may alter the meaning of the\noriginal sentence (e.g., deleting/inserting “not”).\nTherefore, we remove such heuristics here.\nSampling perturbations. As the output space\nof the perturbation function bis large, we obtain\nsamples from b(x) to be ˆB(x). We experiment with\nrandom sampling with sizes of 100, 200 and 400,\nmotivated by the ﬁnding that with the GPT2 models,\na batch size of 100 sentences can ﬁt into a single\nGPU of 11GB memory. Other (potentially more\nefﬁcient) sampling methods include gradient-based\nsampling which picks perturbation sentences in\na direction that increases the sentence probability\n(analogous to adversarial perturbations; Szegedy\net al. (2013); Wallace et al. (2019)), but we focus\non random sampling in this work.\nThe advantage of LM-Critic is that as LMs can\nbe trained on a wide range of unlabeled corpora, it is\nunsupervised and usable in various domains of text.\n7755\n300\n 250\n 200\n 150\n 100\n 50\n 0\nlog p(s)\nDensity\nSentence likelihood\nGrammatical\nUngrammatical\nFigure 2: Probability of grammatical (green) and ungrammat-\nical (red) sentences, computed by a pretrained LM (GPT2).\nPretrained LM How oftenp(xbad)<p(xgood)?\nGPT2 94.7%GPT2-medium 95.0%GPT2-large 95.9%GPT2-xl 96.0%\nTable 1:How well sentence probability returned by pretrained\nLMs correlates with grammaticality empirically.\n3.3 Empirical analysis\nWe study how well our LM-Critic works in practice.\nWe prepare an evaluation data for judging grammat-\nicality in §3.3.1. We ﬁrst perform a simple check\nto make sure that LMs’ probability score correlates\nwith grammaticality (§3.3.2). We then study the\nperformance of LM-Critic judging grammaticality\n(§3.3.3). The analysis we conduct in this section\nis just an intrinsic evaluation of LM-Critic. Our\nmain goal is to use LM-Critic with BIFI for learning\nGEC, which we describe and evaluate in §4.\n3.3.1 Evaluation data\nTo gain insights into how well LM-Critic judges\ngrammaticality, we prepare a simple evaluation\ndata consisting of (xbad,xgood) sentence pairs. As\nexperimenting with multiple datasets is desired in\nGEC (Ge et al., 2018), we construct a combined\nevaluation set from the dev sets of multiple GEC\nbenchmarks, GMEG-wiki (Napoles et al., 2019),\nGMEG-yahoo, and BEA-2019 (Bryant et al., 2019),\nwhich span the domains of Wikipedia, Yahoo!An-\nswers, and essay/learner English. Speciﬁcally, we\nsampled ∼600 labeled pairs of(xbad,xgood) in total\nfrom the three benchmarks. We ﬁlter out examples\nwhere xbad =xgood in this process. We acknowledge\nthat while we use annotated (xbad,xgood) pairs for\nthe evaluation here, this does not fully match the\nway LM-Critic will be used in BIFI (§4), where the\ncritic is run on unlabeled sentences; our study here\nis just to gain intrinsic insights into LM-Critic.\n3.3.2 Analysis of LM probability\nUsing the evaluation data, we ﬁrst make sure\nthat pretrained LMs’ probability correlates with\ngrammaticality. Figure 2 shows a histogram for\nthe probability log p(x) of grammatical (green)\nand ungrammatical (red) sentences computed by\nGPT2. In Table 1, we study how often pretrained\nPerturbationRecognize “Good” Recognize “Bad”\nP R F 0.5 P R F 0.5\nED1 58.7 90.1 63.1 78.8 36.8 64.2ED1 + word(all) 69.7 10.2 32.2 51.5 95.5 56.7ED1 + word 68.4 75.569.7 72.7 65.171.1\nSample sizeRecognize “Good” Recognize “Bad”\nP R F 0.5 P R F 0.5\n100 68.4 75.5 69.7 72.7 65.1 71.1200 71.3 71.5 71.4 71.4 71.3 71.4400 72.6 68.7 71.8 70.3 74.0 71.0\nPretrained LMRecognize “Good” Recognize “Bad”\nF0.5 F0.5\nGPT2 69.7 71.1GPT2-medium 69.9 71.0GPT2-large 70.3 71.3GPT2-xl 69.9 71.0\nTable 2: Performance of LM-Critic, when using different\nchoices of a perturbation function, sample size, and pretrained\nLM described in §3.2.(Top)We set the LM to be GPT2 and the\nperturbation sample size to be 100, and vary the perturbation\nfunction b. “ED1 + word” achieves the best F0.5. Henceforth,\nwe use this perturbation function.(Middle) We set the LM to\nbe GPT2 and vary the perturbation sample size. Increasing the\nsampling size improves the performance slightly. (Bottom)\nWe vary the LM. Increasing the LM size makes slight or no\nimprovement in F0.5 on the dataset we used.\nExamples ofp(xbad)>p(xgood)\n(Comma)xbad: The video was ﬁlmed on January 22 and is set to premiere on February 22.xgood:The video was ﬁlmed on January 22, and is set to premiere on February 22.\n(Quotation)xbad: Uprising is a 1980 roots reggae album by Bob Marley & The Wailers.xgood:“Uprising” is a 1980 roots reggae album by Bob Marley & The Wailers.\n(British spelling)xbad: The blast could be heard across the whole city centre.xgood:The blast could be heard across the whole citycenter.\nExamples ofp(x′)>p(xgood), x′∈ˆB(xgood)\n(Singular/plural)x′: They are afﬁliated to either the state boards or to national education boards.xgood:They are afﬁliated to either the state board or to national education boards.\n(Tense)x′: As well as touring Europe, they tour with such acts as Green Day.xgood:As well as touring Europe, they toured with such acts as Green Day.\nTable 3: Failure cases of LM-Critic. (Top) GPT2 assigns\na higher probability to bad sentences. (Bottom) our neigh-\nborhood function (“ED1 + word”) includes sentences with a\nhigher LM probability than the original good sentence.\nLMs actually assign a higher probability to xgood\nthan xbad on the evaluation pairs(xbad,xgood). We\nﬁnd that the LMs satisfy p(xbad) <p(xgood) about\n94% of the time, with a slight increase when using\na larger model (from GPT2 to GPT2-xl). We ﬁnd\nthat the remaining pairs with p(xbad) > p(xgood)\nconsist mostly of cases wherexgood adds commas\nor quotations toxbad (see Table 3 top for examples).\n3.3.3 Performance of LM-Critic\nIn §3.3.2 we simply made sure that pretrained LMs’\nprobability correlates with grammaticality. Here we\nstudy LM-Critic’s performance ofjudging bad/good\nsentences, on the evaluation set{(xbad(i),xgood(i))}.\n7756\nWe treat the label ofxbad’s andxgood’s to be “bad”\nand “good”, respectively, and measure the precision\n(P), recall (R), F0.5 of LM-Critic recognizing “bad”\nand “good”. Denoting the critic asc, precision and\nrecall for “bad” are deﬁned as\nP(bad)= |{x: c(x)=0}|∩|{xbad}|\n|{x: c(x)=0}| , (6)\nR(bad)= |{x: c(x)=0}|∩|{xbad}|\n|{xbad}| . (7)\nP(good) and R(good) are deﬁned similarly. F0.5 score is\na combined metric of P and R that is commonly used\nin grammatical error detection/correction literature.\nBaseline critic. First, as a baseline, we evaluate\nthe critic based on absolute threshold, described\nin Eq 2. We set the threshold δ as the average\nprobability of all good and bad sentences in the\nevaluation data. This method achieves 54.3 F0.5(bad)\nand 56.0 F0.5(good), using GPT2.\nProposed LM-Critic. Table 2 shows the results\nof our proposed LM-Critic, using different choices\nof a perturbation function, sample size, and\npretrained LM. Recall that LM-Critic predicts\n“bad” correctly if it ﬁnds a perturbed sentence with\nhigher probability, and predicts “good” correctly\nif the input has the highest probability among the\nsampled perturbations.\n•Perturbation function b (top table). We set the\npretrained LM to be GPT2 and the perturbation\nsample size to be 100, and vary the perturbation\nfunction. We ﬁnd that when the perturbation\nspace is small (“ED1”), LM-Critic may make\nfalse predictions of “good”, leading to lowP(good)\nand low R(bad). When the perturbation space\nis large (“ED1 + word(all)”), LM-Critic may\nmake false predictions of “bad”, leading to low\nR(good) and lowP(bad). “ED1 + word” is the most\nbalanced and achieves the best F0.5; henceforth,\nwe use this perturbation method for all our\nexperiments. Overall, our LM-Critic outperforms\nthe baseline critic by substantial margins.\n•Sample size of perturbations (middle table).\nWe set the LM to be GPT2 and vary the pertur-\nbation sample size. Increasing the sample size\ntends to improveP(good) and R(bad), and improve\nthe overall F0.5 performance slightly.\n•Pretrained LM (bottom table). We vary the\nLM. Increasing the LM size makes slight or no\nimprovement in F0.5 on the dataset we used.\nWe also analyze when LM-Critic fails. When\nLM-Critic predicts a false “good” (labeled “bad”\nbut predicted “good”), it is commonly because of\np(xbad) >p(xgood) (as described in §3.3.2; Table\n3 top), or perturbation sampling not hitting a better\nversion of the inputxbad. When LM-Critic predicts\na false “bad” (labeled “good” but predicted “bad”),\nit is because some perturbation x′ ∈ ˆB(xgood)\nyields p(x′) > p(xgood). Common examples are\nthe change of tense or singular/plural (see Table\n3 bottom for examples). This indicates that even\nif we use a conservative edit-distance like ED1,\nthere may be unnecessary perturbations (tense,\nsingular/plural) that pretrained LMs prefer, which\nis a limitation of our current LM-Critic.\nThe analysis done in this section is an intrinsic\nevaluation of LM-Critic. Our main goal is to use\nLM-Critic with BIFI for learning GEC, which we\ndescribe in §4. While LM-Critic is not perfect\nin itself as we have seen in this section (it is an\napproximate critic), we will show that it is helpful\nfor obtaining realistic paired data to improve the\ndownstream GEC performance. Henceforth, we\nuse the “ED1 + word” perturbation, a sample size\nof 100, and GPT2 for our LM-Critic.\n4 Learning GEC with LM-Critic\nBreak-It-Fix-It (BIFI; Yasunaga and Liang (2021))\nis an existing method that uses a critic to obtain\nrealistic paired data from unlabeled data. BIFI was\noriginally studied in the source code repair task\nwhere an oracle critic ( e.g., compiler) exists, but\nthere is no oracle critic in GEC. Here, we propose to\napply BIFI to the GEC task by using LM-Critic as\nthe critic (§4.1), and evaluate this approach on GEC\nbenchmarks (§4.2). The difference from the original\nBIFI is that our task is GEC rather than code repair,\nand we use an approximate critic (i.e., LM-Critic)\ninstead of an oracle critic (i.e., compiler).\n4.1 Approach\nOur goal is to learn a ﬁxerfthat maps an ungram-\nmatical sentence xbad into the grammatical version\nxgood. A common method to obtain paired data for\nGEC from unlabeled text is to heuristically corrupt\ngood sentences (synthetic data) (Awasthi et al.,\n2019; Kiyono et al., 2019). However, such synthetic\nerrors do not match the distributions of real\ngrammatical errors humans make, which may result\nin accuracy drops (Daume III and Marcu, 2006). To\nmitigate this mismatch, BIFI aims to obtain more\nrealistic paired data and train the ﬁxer on it.\nSpeciﬁcally, BIFI takes as inputs:\n•Critic c, for which we use LM-Critic\n•Unlabeled data Dunlabel. Using the critic c,\nexamples in Dunlabel can be split into bad ones\n7757\nDbad ={x|x∈Dunlabel,c(x)=0 }and good ones\nDgood ={y|y∈Dunlabel,c(y)=1 }\n•Initial ﬁxer f0, which could be trained on\nsynthetic data (unsupervised setting; §4.2.2) or\nlabeled data (supervised setting; §4.2.3)\nand improves the ﬁxer by performing a cycle of\ndata generation and training: (1) we apply the ﬁxer\nfto the bad examplesDbad, which consists of real\ngrammatical errors made by humans, and use the\ncritic to assess if the ﬁxer’s output is good—if good,\nwe keep the pair; (2) we train a breaker bon the\nresulting paired data—consequently, the breaker\ncan generate more realistic errors than the initial\nsynthetic data; (3) we apply the breaker to the good\nexamples Dgood; (4) we ﬁnally train the ﬁxer on\nthe newly-generated paired data in (1) and (3). This\ncycle can be iterated to improve the ﬁxer and the\nbreaker simultaneously. Formally, BIFI does the\nfollowing in each roundk(=1,2,...,K):\nP(f)\nk ={(x,fk−1(x))|x∈Dbad,c(fk−1(x))=1} (8)\nbk =TRAINgood→bad(P(f)\nk ) (9)\nP(b)\nk ={(bk(y),y)|y∈Dgood,c(bk(y))=0} (10)\nfk =TRAINbad→good(P(f)\nk ∪P(b)\nk ), (11)\nwhere each equation corresponds to the steps (1)–(4)\nin the description above.TRAIN good→bad(P) trains\nan encoder-decoder model that maps “good”-side\nexamples to “bad”-side examples in paired data\nP, and TRAIN bad→good(P) does the reverse. Red\nfont indicates the use of critic. The key intuition\nof BIFI is that thanks to the critic, (i) we can\nextract Dbad from the unlabeled data Dunlabel and\nincorporate realistic grammatical errors into our\ndata (as opposed to the synthetic data), and (ii) we\ncan verify if the “bad”-side and “good”-side of the\ngenerated pairs are actually “bad” and “good” (Eq\n8, 10; red font), which improves the correctness\nof generated training data compared to vanilla\nbacktranslation (Sennrich et al., 2016; Lample et al.,\n2018). We refer readers to Yasunaga and Liang\n(2021) for more details.\n4.2 Experiments\nWe study our proposed approach (BIFI with LM-\nCritic) on GEC benchmarks, in both unsupervised\nand supervised settings.\n4.2.1 Evaluation data\nWe evaluate on four GEC benchmarks, CoNLL-\n2014 test (Ng et al., 2014), BEA-2019 dev / test\n(Bryant et al., 2019), GMEG-yahoo and GMEG-\nwiki tests (Napoles et al., 2019), which span do-\nmains of essay/learner English, Wikipedia, and Ya-\nhoo!Answers. For CoNLL-2014, we use the ofﬁcial\nM2 scorer (Dahlmeier and Ng, 2012), and for others\nwe use the ERRANT metric (Bryant et al., 2017).\nWe describe the training data separately for unsuper-\nvised (§4.2.2) and supervised (§4.2.3) settings.\n4.2.2 Unsupervised setting\nSetup and data. We consider the setup with no\nlabeled training data. Existing GEC works ( e.g.,\nAwasthi et al. (2019); Omelianchuk et al. (2020))\nprepare synthetic paired data by heuristically cor-\nrupting sentences from the One-billion-word corpus\n(Chelba et al., 2013). We follow the same procedure,\nand train an encoder-decoder Transformer (Vaswani\net al., 2017) on this synthetic data to be ourbaseline\nﬁxer. The size of the synthetic data is 9M pairs.\nWe then apply the BIFI training on top of the\nbaseline ﬁxer. As our unlabeled data to be used\nfor BIFI, we want text that is likely to contain both\nungrammatical and grammatical sentences. Hence,\nwe take 10M sentences in total from the Yahoo!An-\nswers corpus (Zhang et al., 2015) and the Wikipedia\nhistories data (Grundkiewicz and Junczys-\nDowmunt, 2014) for which we take sentences prior\nto revisions.2 This unlabeled data is in the domains\nof two of our benchmarks (GMEG-wiki and GMEG-\nyahoo) but not of CoNLL-2014 and BEA-2019.\nImplementation details. The encoder-decoder\nTransformer architecture has 12 layers, 16 attention\nheads and hidden state size of 768. The model\nparameters are initialized with the BART-base\nrelease (Lewis et al., 2020), and then optimized by\nAdam (Kingma and Ba, 2015), with batch size of\n512 sequences, learning rate 0.0001, and gradient\nclipping 1.0 (Pascanu et al., 2013), on a single GTX\nTitan X GPU. For generation, we use beam search\nwith beam size 10. We run the BIFI algorithm for\nK=1 round. The total training time takes 2 days.\nResults. Table 4 shows the results on the four\nGEC benchmarks. “Transformers” is our baseline\nﬁxer, trained on the synthetic paired data. Our pro-\nposed approach (“+BIFI”) outperforms the baseline\nby substantial margins across the benchmarks,e.g.,\n+8 F0.5 on GMEG-wiki and yahoo.\nSince our method (“+BIFI”) uses more (unla-\nbeled) data than the baseline (“Transformer”), to\nbe fully fair, we also conduct an experiment that\ncontrols the amount of training data seen by the\nmodel: Speciﬁcally, we apply BIFI to the baseline\nﬁxer without the critic, i.e., the model sees the\nsame amount of newly-generated paired data as\n2This is not paired data, as we only take sentences pre\nrevision, not post revision.\n7758\nGEC system CoNLL-2014 (test) BEA-2019 (dev) GMEG-wiki (test) GMEG-yahoo (test)\nP R F 0.5 P R F 0.5 P R F 0.5 P R F 0.5\nTransformer 59.2 29.2 49.1 44.2 17.9 34.1 52.1 26.5 43.7 44.4 36.9 42.7\n+ BIFI with no critic 58.2 29.9 48.9 43.8 18.7 34.5 53.5 27.4 44.9 45.1 38.5 43.6\n+BIFI (ours) 64.4 35.6 55.5 51.6 24.7 42.4 57.9 33.6 50.6 53.7 47.1 52.2\nTable 4: GEC results in the unsupervised setting (§4.2.2). “Transformers” is trained on synthetic paired data as in Awasthi\net al. (2019). If we train it on more realistic paired data generated by BIFI (bottom row), it achieves improved results.\nGEC system Ens. CoNLL-2014 (test) BEA-2019 (test)\nP R F 0.5 P R F 0.5\nGPT3 (175B) with prompting 62.4 25.0 48.0 50.8 38.2 47.6\nZhao et al. (2019) 67.7 40.6 59.8 - - -Awasthi et al. (2019) 66.1 43.0 59.7 - - -Kiyono et al. (2019) 67.9 44.161.3 65.559.464.2\nZhao et al. (2019) ✓ 74.1 36.3 61.3 - - -Awasthi et al. (2019) ✓ 68.3 43.2 61.2 - - -Grundkiewicz et al. (2019)✓ - - 64.2 72.3 60.1 69.5Kiyono et al. (2019) ✓ 72.4 46.1 65.0 74.7 56.7 70.2Kantor et al. (2019) ✓ - - - 78.3 58.0 73.2\nGECToR (Omelianchuk et al., 2020) 77.5 40.1 65.3 79.2 53.9 72.4\nGECToR (our base) 77.5 40.1 65.3 79.2 53.9 72.4+BIFI (ours) 78.0 40.665.8 79.455.072.9\nTable 5: GEC results in the supervised setting with labeled data available\n(§4.2.3). “Ens.” indicates an ensemble system.\n0 1k 10k 100k 1,000k\nLabeled training data\n40\n50GEC result  F0.5\nno BIFI\nBIFI\nFigure 3: GEC results (y-axis) when varying\nthe amount of labeled data available for\ntraining (x-axis). BIFI is particularly helpful\nin low-resource regimes.\n“+BIFI” but they are not veriﬁed by LM-Critic. This\nsystem (“+BIFI with no critic”) did not improve\non the baseline much. These results indicate that\nthe paired data generated by BIFI with LM-Critic\nis indeed more realistic and helpful than the initial\nsynthetic data or pairs generated without LM-Critic.\nThe improved results in this unsupervised setting\nsuggest that our approach is especially useful in\ndomains with no labeled GEC data for training (e.g.,\nGMEG-wiki and yahoo; CoNLL-2014 and BEA-\n2019 have labeled data, which we use in §4.2.3).\nOur results also suggest that while existing BIFI\nassumed access to an oracle critic (i.e., compiler),\nan approximate critic (i.e., LM-Critic) can also help\nto improve model learning. Our conjecture is that as\nlong as the LM-Critic is better than random guessing\n(e.g., 70 F0.5 as shown in §3.3.3), it is useful for im-\nproving the quality of GEC training data generated\nin BIFI (Eq 8, 10), which in turns improves GEC per-\nformance. An interesting future direction is to use\nthe breaker learned in BIFI (Eq 9 for the perturbation\nfunction in LM-Critic (§3.2) to further improve the\ncritic, which may in turn help BIFI as well as GEC\nperformance, creating a positive loop of learning.\n4.2.3 Supervised setting\nSetup and data. We also consider the common\nleaderboard setup that uses labeled training data and\nevaluates on CoNLL-2014 and BEA-2019. We take\nthe state-of-the-art model, GECToR (Omelianchuk\net al., 2020), as our baseline ﬁxer . Following\nOmelianchuk et al. (2020), GECToR is ﬁrst trained\non the synthetic paired data described in §4.2.2, and\nis then trained on the labeled data available for the\nBEA-2019 task, which is the combination of:\n•NUS Corpus of Learner English (NUCLE)\n(Dahlmeier et al., 2013)\n•Lang-8 Corpus of Learner English (Lang-8)\n(Mizumoto et al., 2011; Tajiri et al., 2012)\n•FCE dataset (Yannakoudakis et al., 2011)\n•Write & Improve + LOCNESS Corpus (W&I +\nLOCNESS) (Bryant et al., 2019)\nThey are all in the domain of CoNLL-2014 and\nBEA-2019 (learner/essay English). The total size\nof the labeled data is 1M pairs.\nWe then apply the BIFI training on top of\nGECToR. As our unlabeled data to be used for\nBIFI, we use 10M sentences taken from Yahoo!\nAnswers and Wikipedia histories (same as §4.2.2).\nImplementation details. We use the same hyper-\nparameters and training procedures for GECToR\nas in Omelianchuk et al. (2020). We run the BIFI\nalgorithm for K=1 round. The total training time\ntakes 4 days, on a single GTX Titan X GPU.\nResults. Table 5 shows our results on CoNLL-\n2014 test and BEA-2019 test, along with existing\nsystems on the leaderboard. Our approach\n(“+BIFI”) provides an additional boost over our\nbase model (“GECToR”). This suggests that\nBIFI with LM-Critic is helpful not only in the\nunsupervised setting but also when a substantial\namount of labeled data (1M pairs) is available.\n4.2.4 Analysis\nVarying the amount of labeled data. We have\nstudied GEC results when we have no labeled data\n(§4.2.2) and when we use all the labeled data (1M\n7759\n(a) Pairs generated by synthetic corruption\nxbad: We look forwardthe to better treatments in the future.xgood:We look forward to better treatments in the future.\nxbad: The president-elect stayed away so as not toforegin mattersuntil Bush.xgood:The president-elect stayed away so as not to complicate matters for Bush.\n(b) Pairs generated by BIFIwithoutLM-Critic\nxbad: If anyone is interested, here’s the kink.xgood:If anyone is interested, here’s the kinks.\nxbad: If you can’t ﬁnd a match yourself, horse trader will helps.xgood:If you can’t ﬁnd a match yourself, horse traders will help.\n(c) Pairs generated by BIFI with LM-Critic (Ours)\nxbad: First Light is a award-winning novel by Sunil Gangopadhyay.xgood:First Light is an award-winning novel by Sunil Gangopadhyay.\nxbad: Except latter, the rivers are in underground tubes and not visible.xgood:Exceptforthe latter, the rivers are in underground tubes and not visible.\nTable 6: Examples of paired data generated by (a) synthetic\ncorruption, (b) BIFI without critic, and (c) BIFI with LM-Critic.\n(a) tends to deviate from the type of grammatical errors humans\nmake. (b) tends to have pairs where xgood is broken ( e.g.,\nthe ﬁrst pair) or xbad is already grammatical, as pairs are not\nveriﬁed by a critic. (c) is the most realistic.\n(Input)The system is designed to use amplitude comparision for height ﬁnding.(Baseline)The system is designed to use amplitude comparison for heightﬁnd.(BIFI)The system is designed to use amplitude comparison for height ﬁnding.\n(Input)Lugu Lake, set in the subalpine zone in Hengduan is a landscape ofpine-covered ecoregion.(Baseline)Lugu Lake, set in the subalpine zone in Hengduan, istheir landscape ofpine-covered ecoregion.(BIFI)Lugu Lake, set in the subalpine zone in Hengduan, is a landscape ofpine-covered ecoregion.\nTable 7: Examples where the baseline ﬁxer trained with\nsynthetic data fails but BIFI succeeds. The baseline tends\nto make unnecessary edits (e.g., changing verb inﬂection or\narticles, due to heuristics used when generating synthetic data).\npairs) (§4.2.3). Here we analyze the interpolation.\nIn Figure 3, we show the GEC performance (F0.5)\non the BEA-2019 dev set, when varying the amount\nof labeled data available for training from 0 to 1M.\nThe blue line indicates a Transformer model ﬁrst\ntrained on the synthetic data and then trained on\nthe available labeled data, which is our baseline.\nThe orange line indicates that this baseline model\nis further trained with BIFI. We observe that\nBIFI outperforms the baseline consistently and is\nparticularly helpful in low-resource regimes.\nPairs generated by BIFI. We quantitatively\nsaw in §4.2.2 that the paired data generated by\nBIFI is helpful for learning GEC. Here we provide\nqualitative examples to compare the paired data\ngenerated by (a) synthetic corruption, (b) BIFI\nwithout critic, and (c) BIFI with LM-Critic (Table 6).\nWe observe that (a) tends to deviate from the type\nof grammatical errors humans make (e.g., inserting\n/replacing words arbitrarily); (b) tends to have pairs\nwhere xgood is broken (e.g., the ﬁrst pair in Table\n6(b)) or xbad is actually grammatical, as pairs are\nnot veriﬁed by a critic; and (c) is the most realistic.\nGEC model outputs. In Table 7, we analyze\nexamples where the baseline ﬁxer trained on\nsynthetic data (“Transformer”) fails but our model\n(“+BIFI”) succeeds. We ﬁnd that the baseline tends\nto make unnecessary edits (e.g., changing verb\ninﬂection or articles), due to the heuristics used\nwhen generating synthetic data. In contrast, BIFI\nachieves higher precision.\n5 Related work and discussion\nGrammatical error correction (GEC). GEC\nmodels are commonly trained from human-labeled\ndata (Nicholls, 2003; Dahlmeier et al., 2013;\nYannakoudakis et al., 2011; Bryant et al., 2019), or\nsynthetic data generated by heuristically corrupting\nunlabeled sentences (Awasthi et al., 2019; Zhao\net al., 2019; Grundkiewicz et al., 2019; Katsumata\nand Komachi, 2019; Omelianchuk et al., 2020).\nSeveral works aim to improve the methods for\ngenerating paired data, such as learning a breaker\nfrom existing labeled data (Lichtarge et al., 2019),\napplying backtranslation (Sennrich et al., 2016) to\nGEC (Xie et al., 2018; Kiyono et al., 2019), and\nsynthesizing extra paired data by comparing model\npredictions and references (Ge et al., 2018). Differ-\nent from the above works, our method (i) does not re-\nquire labeled data (works for both unsupervised and\nsupervised settings), and (ii) uses LM-Critic to ﬁlter\nthe “bad”-side and “good”-side of generated pairs.\nAutomatic text evaluation. Popular metrics\nused to assess the quality of text in GEC include\nGLEU (Napoles et al., 2015, 2017), M2 (Dahlmeier\nand Ng, 2012), ERRANT (Bryant et al., 2017)\nand I-measure (Felice and Briscoe, 2015). While\nthese methods require reference text to compare to,\nLM-Critic does not. Several prior works also study\nreference-less methods to assess grammaticality\nof text: Wan et al. (2005); Mutton et al. (2007);\nVadlapudi and Katragadda (2010) use part-of-\nspeech (POS) tagger or parser predictions to score\ngrammaticality; Napoles et al. (2016); Warstadt\net al. (2018); Katinskaia et al. (2019); Niu and Penn\n(2020) train grammatical error detection (GED) or\nacceptability judgement systems. However, these\nworks require POS taggers, parsers or GED systems\ntrained on labeled data, which may not scale or\ngeneralize well beyond the domain of training data.\nIn contrast, LM-Critic only requires an LM, which\nis unsupervised and can be pretrained on various\ndomains of unlabeled corpora.\nPretrained LM for text evaluation. Several\nworks use pretrained LMs for text evaluation. For\nreference-based metrics, Zhang et al. (2020) use an\nLM’s embeddings to measure the similarity between\ninput text and reference text. For reference-less\n7760\nmetrics, several works (Kann et al., 2018; Stahlberg\net al., 2019) use an LM’s probability as a ﬂuency\nscore of text. While this provides a continuous score\nfor ﬂuency, it in itself cannot classify grammatical\n/ ungrammatical sentences. Our LM-Critic goes\na step further to consider the local optimum\ncriterion for classifying grammaticality. The reason\nwe want a classiﬁer (critic) is that we work on\nunsupervised learning of GEC. In the unsupervised\nsetting, there is a distributional shift problem—the\nsynthetically-generated paired data does not match\nthe distribution of grammatical errors humans make.\nBIFI is a solution for obtaining realistic paired\ndata in an unsupervised way, but it requires a critic.\nThis led us to design a critic for GEC in this work.\nWe note that LM-Critic is not meant to replace\nexisting evaluation metrics for GEC, but rather is\nan approximate critic to assess grammaticality and\nhelp the learning of GEC.\nSeparately, several works (Tenney et al., 2019;\nHewitt and Manning, 2019; Yasunaga and Lafferty,\n2019; Cao et al., 2020) induce grammar or syntactic\nstructures from LMs, suggesting that LMs can\nlearn about grammaticality in an unsupervised\nway. As this capacity is likely to grow with the\nsize of LMs (Radford et al., 2019; Brown et al.,\n2020; Kaplan et al., 2020), we think that how to\nleverage pretrained LMs for GEC will become an\nincreasingly important research problem.\n6 Conclusion\nWe presented LM-Critic, a method that uses a\npretrained language model (LM) as a critic for as-\nsessing sentence grammaticality. Using LM-Critic\nand the BIFI algorithm, we learn grammatical error\ncorrection (GEC) by generating realistic training\ndata from unlabeled text. Notably, our approach\ndoes not require labeled data, and can also be\nviewed as an unsupervised method to turn a (GPT2-\nscale) pretrained LM into an actual GEC system.\nUsing multiple GEC datasets, we showed that our\napproach achieves strong performance on unsuper-\nvised GEC, suggesting the promise of our method\nfor domains and languages with no labeled GEC\ndata. We hope this work opens up research avenues\nin LM-based critics and unsupervised GEC.\nAcknowledgments\nWe thank Pang Wei Koh, Tianyi Zhang, Rodrigo\nCastellon, members of the Stanford P-Lambda,\nSNAP and NLP groups, as well as our anonymous\nreviewers for valuable feedback. This work was\nsupported in part by a Funai Foundation Scholarship\nand NSF CAREER Award IIS-1552635.\nReproducibility\nCode and data are available at\nhttps://github.com/michiyasunaga/\nLM-Critic.\nExperiments are available at\nhttps://worksheets.\ncodalab.org/worksheets/\n0x94456a63e1ee4ccfaabdc7f6a356cc82.\nReferences\nAbhijeet Awasthi, Sunita Sarawagi, Rasna Goyal,\nSabyasachi Ghosh, and Vihari Piratla. 2019. Parallel\niterative edit models for local sequence transduc-\ntion. In Empirical Methods in Natural Language\nProcessing (EMNLP).\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-\nshot learners. In Advances in Neural Information\nProcessing Systems (NeurIPS).\nChristopher Bryant, Mariano Felice, Øistein E Ander-\nsen, and Ted Briscoe. 2019. The bea-2019 shared\ntask on grammatical error correction. InProceedings\nof the Fourteenth Workshop on Innovative Use of\nNLP for Building Educational Applications.\nChristopher Bryant, Mariano Felice, and Edward\nBriscoe. 2017. Automatic annotation and evaluation\nof error types for grammatical error correction. In\nAssociation for Computational Linguistics (ACL).\nSteven Cao, Nikita Kitaev, and Dan Klein. 2020. Unsu-\npervised parsing via constituency tests. InEmpirical\nMethods in Natural Language Processing (EMNLP).\nCiprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge,\nThorsten Brants, Phillipp Koehn, and Tony Robinson.\n2013. One billion word benchmark for measuring\nprogress in statistical language modeling. arXiv\npreprint arXiv:1312.3005.\nShamil Chollampatt and Hwee Tou Ng. 2018. A multi-\nlayer convolutional encoder-decoder neural network\nfor grammatical error correction. In Proceedings of\nthe AAAI Conference on Artiﬁcial Intelligence.\nDaniel Dahlmeier and Hwee Tou Ng. 2012. Better\nevaluation for grammatical error correction. In\nNorth American Chapter of the Association for\nComputational Linguistics (NAACL).\nDaniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.\n2013. Building a large annotated corpus of learner\nenglish: The nus corpus of learner english. In\nProceedings of the eighth workshop on innovative\nuse of NLP for building educational applications.\nHal Daume III and Daniel Marcu. 2006. Domain\nadaptation for statistical classiﬁers. Journal of\nartiﬁcial Intelligence research.\n7761\nMariano Felice and Ted Briscoe. 2015. Towards a\nstandard evaluation method for grammatical error\ndetection and correction. In North American Chap-\nter of the Association for Computational Linguistics\n(NAACL).\nTao Ge, Furu Wei, and Ming Zhou. 2018. Fluency\nboost learning and inference for neural grammatical\nerror correction. In Association for Computational\nLinguistics (ACL).\nRoman Grundkiewicz and Marcin Junczys-Dowmunt.\n2014. The wiked error corpus: A corpus of corrective\nwikipedia edits and its application to grammatical\nerror correction. In International Conference on\nNatural Language Processing.\nRoman Grundkiewicz, Marcin Junczys-Dowmunt, and\nKenneth Heaﬁeld. 2019. Neural grammatical error\ncorrection systems with unsupervised pre-training\non synthetic data. In Proceedings of the Fourteenth\nWorkshop on Innovative Use of NLP for Building\nEducational Applications.\nJohn Hewitt and Christopher D Manning. 2019. A struc-\ntural probe for ﬁnding syntax in word representations.\nIn North American Chapter of the Association for\nComputational Linguistics (NAACL).\nJianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen\nGong, Steven Truong, and Jianfeng Gao. 2017. A\nnested attention neural hybrid model for grammatical\nerror correction. In Association for Computational\nLinguistics (ACL).\nErik Jones, Robin Jia, Aditi Raghunathan, and Percy\nLiang. 2020. Robust encodings: A framework for\ncombating adversarial typos. In Association for\nComputational Linguistics (ACL).\nMarcin Junczys-Dowmunt, Roman Grundkiewicz,\nShubha Guha, and Kenneth Heaﬁeld. 2018. Ap-\nproaching neural grammatical error correction\nas a low-resource machine translation task. In\nNorth American Chapter of the Association for\nComputational Linguistics (NAACL).\nKatharina Kann, Sascha Rothe, and Katja Filippova.\n2018. Sentence-level ﬂuency evaluation: References\nhelp, but can be spared! In Conference on Computa-\ntional Natural Language Learning (CoNLL).\nYoav Kantor, Yoav Katz, Leshem Choshen, Edo\nCohen-Karlik, Naftali Liberman, Assaf Toledo,\nAmir Menczel, and Noam Slonim. 2019. Learning\nto combine grammatical error corrections. In Pro-\nceedings of the Fourteenth Workshop on Innovative\nUse of NLP for Building Educational Applications.\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\nScaling laws for neural language models. arXiv\npreprint arXiv:2001.08361.\nAnisia Katinskaia, Sardana Ivanova, Roman Yangarber,\net al. 2019. Multiple admissibility in language\nlearning: Judging grammaticality using unlabeled\ndata. In The 7th Workshop on Balto-Slavic Natural\nLanguage Processing Proceedings of the Workshop.\nSatoru Katsumata and Mamoru Komachi. 2019. (al-\nmost) unsupervised grammatical error correction\nusing synthetic comparable corpus. In Proceedings\nof the Fourteenth Workshop on Innovative Use of\nNLP for Building Educational Applications.\nDiederik Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In International\nConference on Learning Representations (ICLR).\nShun Kiyono, Jun Suzuki, Masato Mita, Tomoya\nMizumoto, and Kentaro Inui. 2019. An empirical\nstudy of incorporating pseudo data into grammatical\nerror correction. In Empirical Methods in Natural\nLanguage Processing (EMNLP).\nGuillaume Lample, Alexis Conneau, Ludovic Denoyer,\nand Marc’Aurelio Ranzato. 2018. Unsupervised\nmachine translation using monolingual corpora\nonly. In International Conference on Learning\nRepresentations (ICLR).\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer\nLevy, Ves Stoyanov, and Luke Zettlemoyer. 2020.\nBart: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and\ncomprehension. In Association for Computational\nLinguistics (ACL).\nJared Lichtarge, Chris Alberti, Shankar Kumar, Noam\nShazeer, Niki Parmar, and Simon Tong. 2019.\nCorpora generation for grammatical error correction.\nIn North American Chapter of the Association for\nComputational Linguistics (NAACL).\nTomoya Mizumoto, Mamoru Komachi, Masaaki\nNagata, and Yuji Matsumoto. 2011. Mining revision\nlog of language learning sns for automated japanese\nerror correction of second language learners. In\nInternational Joint Conference on Natural Language\nProcessing (IJCNLP).\nAndrew Mutton, Mark Dras, Stephen Wan, and Robert\nDale. 2007. Gleu: Automatic evaluation of sentence-\nlevel ﬂuency. In Association of Computational\nLinguistics (ACL).\nJakub Náplava and Milan Straka. 2019. Grammat-\nical error correction in low-resource scenarios.\nIn Proceedings of the 5th Workshop on Noisy\nUser-generated Text (W-NUT 2019).\nCourtney Napoles, Maria N ˘adejde, and Joel Tetreault.\n2019. Enabling robust grammatical error correction\nin new domains: Data sets, metrics, and analyses.\nTransactions of the Association for Computational\nLinguistics.\n7762\nCourtney Napoles, Keisuke Sakaguchi, Matt Post,\nand Joel Tetreault. 2015. Ground truth for gram-\nmatical error correction metrics. In Association of\nComputational Linguistics (ACL).\nCourtney Napoles, Keisuke Sakaguchi, and Joel\nTetreault. 2016. There’s no comparison: Reference-\nless evaluation metrics in grammatical error\ncorrection. In Empirical Methods in Natural\nLanguage Processing (EMNLP).\nCourtney Napoles, Keisuke Sakaguchi, and Joel\nTetreault. 2017. Jﬂeg: A ﬂuency corpus and bench-\nmark for grammatical error correction. In European\nChapter of the Association for Computational\nLinguistics (EACL).\nHwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian\nHadiwinoto, Raymond Hendy Susanto, and Christo-\npher Bryant. 2014. The conll-2014 shared task on\ngrammatical error correction. InConference on Com-\nputational Natural Language Learning (CoNLL).\nDiane Nicholls. 2003. The cambridge learner corpus:\nError coding and analysis for lexicography and\nelt. In Proceedings of the Corpus Linguistics 2003\nconference.\nJingcheng Niu and Gerald Penn. 2020. Grammaticality\nand language modelling. In Proceedings of the First\nWorkshop on Evaluation and Comparison of NLP\nSystems.\nKostiantyn Omelianchuk, Vitaliy Atrasevych, Artem\nChernodub, and Oleksandr Skurzhanskyi. 2020.\nGector–grammatical error correction: Tag, not\nrewrite. In Proceedings of the 15th Workshop on\nInnovative Use of NLP for Building Educational\nApplications.\nRazvan Pascanu, Tomas Mikolov, and Yoshua Bengio.\n2013. On the difﬁculty of training recurrent neural\nnetworks. In International Conference on Machine\nLearning (ICML), pages 1310–1318.\nDanish Pruthi, Bhuwan Dhingra, and Zachary C\nLipton. 2019. Combating adversarial misspellings\nwith robust word recognition. In Association for\nComputational Linguistics (ACL).\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Improving neural machine translation mod-\nels with monolingual data. In Association for\nComputational Linguistics (ACL).\nFelix Stahlberg, Christopher Bryant, and Bill Byrne.\n2019. Neural grammatical error correction with\nﬁnite state transducers. In North American Associa-\ntion for Computational Linguistics (NAACL).\nChristian Szegedy, Wojciech Zaremba, Ilya Sutskever,\nJoan Bruna, Dumitru Erhan, Ian Goodfellow, and\nRob Fergus. 2013. Intriguing properties of neural\nnetworks. arXiv preprint arXiv:1312.6199.\nToshikazu Tajiri, Mamoru Komachi, and Yuji Mat-\nsumoto. 2012. Tense and aspect error correction for\nesl learners using global context. In Association for\nComputational Linguistics (ACL).\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019. Bert\nrediscovers the classical nlp pipeline. In Association\nfor Computational Linguistics (ACL).\nRavikiran Vadlapudi and Rahul Katragadda. 2010. On\nautomated evaluation of readability of summaries:\nCapturing grammaticality, focus, structure and\ncoherence. In Proceedings of the NAACL HLT 2010\nstudent research workshop.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N. Gomez, Lukasz\nKaiser, and Illia Polosukhin. 2017. Attention is\nall you need. In Advances in Neural Information\nProcessing Systems (NeurIPS).\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner,\nand Sameer Singh. 2019. Universal adversarial trig-\ngers for attacking and analyzing nlp. In Empirical\nMethods in Natural Language Processing (EMNLP).\nStephen Wan, Robert Dale, and Mark Dras. 2005.\nSearching for grammaticality: Propagating depen-\ndencies in the viterbi algorithm. In Proceedings of\nthe Tenth European Workshop on Natural Language\nGeneration (ENLG-05).\nAlex Warstadt, Amanpreet Singh, and Samuel R Bow-\nman. 2018. Neural network acceptability judgments.\narXiv preprint arXiv:1805.12471.\nZiang Xie, Anand Avati, Naveen Arivazhagan, Dan\nJurafsky, and Andrew Y Ng. 2016. Neural language\ncorrection with character-based attention. arXiv\npreprint arXiv:1603.09727.\nZiang Xie, Guillaume Genthial, Stanley Xie, Andrew Y\nNg, and Dan Jurafsky. 2018. Noising and denoising\nnatural language: Diverse backtranslation for gram-\nmar correction. In North American Chapter of the\nAssociation for Computational Linguistics (NAACL).\nHelen Yannakoudakis, Ted Briscoe, and Ben Medlock.\n2011. A new dataset and method for automatically\ngrading esol texts. In Association for Computational\nLinguistics (ACL).\nMichihiro Yasunaga and John D Lafferty. 2019. Top-\niceq: A joint topic and mathematical equation model\nfor scientiﬁc texts. In Proceedings of the AAAI\nConference on Artiﬁcial Intelligence.\nMichihiro Yasunaga and Percy Liang. 2021. Break-It-\nFix-It: Unsupervised Learning for Program Repair.\nIn International Conference on Machine Learning\n(ICML).\n7763\nZheng Yuan and Ted Briscoe. 2016. Grammatical\nerror correction using neural machine translation.\nIn North American Chapter of the Association for\nComputational Linguistics (NAACL).\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q\nWeinberger, and Yoav Artzi. 2020. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations (ICLR).\nXiang Zhang, Junbo Zhao, and Yann LeCun. 2015.\nCharacter-level convolutional networks for text\nclassiﬁcation. In Advances in Neural Information\nProcessing Systems (NeurIPS).\nWei Zhao, Liang Wang, Kewei Shen, Ruoyu Jia,\nand Jingming Liu. 2019. Improving grammatical\nerror correction via pre-training a copy-augmented\narchitecture with unlabeled data. In North American\nAssociation for Computational Linguistics (NAACL)."
}