{
  "title": "Robustification of Multilingual Language Models to Real-world Noise in Crosslingual Zero-shot Settings with Robust Contrastive Pretraining",
  "url": "https://openalex.org/W4386566801",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2914247037",
      "name": "Asa Cooper Stickland",
      "affiliations": [
        "New York University",
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2225296427",
      "name": "Sailik Sengupta",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2970710846",
      "name": "Jason Krone",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2131603063",
      "name": "Saab Mansour",
      "affiliations": [
        "New York University"
      ]
    },
    {
      "id": "https://openalex.org/A2105465932",
      "name": "He He",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3093517588",
    "https://openalex.org/W3169483174",
    "https://openalex.org/W3174828871",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2952638691",
    "https://openalex.org/W3203669811",
    "https://openalex.org/W3098101716",
    "https://openalex.org/W3174418826",
    "https://openalex.org/W3183932535",
    "https://openalex.org/W3175898847",
    "https://openalex.org/W3097455551",
    "https://openalex.org/W3099126561",
    "https://openalex.org/W2742113707",
    "https://openalex.org/W3034238904",
    "https://openalex.org/W2891555348",
    "https://openalex.org/W3173783447",
    "https://openalex.org/W3114632476",
    "https://openalex.org/W2971160427",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W2997214274",
    "https://openalex.org/W3164045210",
    "https://openalex.org/W3173154122",
    "https://openalex.org/W3035579820",
    "https://openalex.org/W4287751617",
    "https://openalex.org/W2970854433",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W4308669975",
    "https://openalex.org/W3034318565",
    "https://openalex.org/W2555897561",
    "https://openalex.org/W3171975879",
    "https://openalex.org/W2767899794",
    "https://openalex.org/W4288024749",
    "https://openalex.org/W3217234915",
    "https://openalex.org/W3214729786",
    "https://openalex.org/W2964116600",
    "https://openalex.org/W3154790171",
    "https://openalex.org/W2984051011",
    "https://openalex.org/W3035390927",
    "https://openalex.org/W3037128534",
    "https://openalex.org/W1522301498"
  ],
  "abstract": "Advances in neural modeling have achieved state-of-the-art (SOTA) results on public natural language processing (NLP) benchmarks, at times surpassing human performance. However, there is a gap between public benchmarks and real-world applications where noise, such as typographical or grammatical mistakes, is abundant and can result in degraded performance. Unfortunately, works which evaluate the robustness of neural models on noisy data and propose improvements, are limited to the English language. Upon analyzing noise in different languages, we observe that noise types vary greatly across languages. Thus, existing investigations do not generalize trivially to multilingual settings. To benchmark the performance of pretrained multilingual language models, we construct noisy datasets covering five languages and four NLP tasks and observe a clear gap in the performance between clean and noisy data in the zero-shot cross-lingual setting. After investigating several ways to boost the robustness of multilingual models in this setting, we propose Robust Contrastive Pretraining (RCP). RCP combines data augmentation with a contrastive loss term at the pretraining stage and achieves large improvements on noisy (and original test data) across two sentence-level (+3.2%) and two sequence-labeling (+10 F1-score) multilingual classification tasks.",
  "full_text": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 1375–1391\nMay 2-6, 2023 ©2023 Association for Computational Linguistics\nRobustification of Multilingual Language Models to Real-world Noise in\nCrosslingual Zero-shot Settings with Robust Contrastive Pretraining\nAsa Cooper Stickland⋆¶†, Sailik Sengupta⋆‡, Jason Krone¶‡, He He‡♢, Saab Mansour‡\n†University of Edinburgh, ‡WS AI Labs, ♢New York University\na.cooper.stickland@ed.ac.uk,{sailiks,saabm,hehea}@amazon.com\nAbstract\nAdvances in neural modeling have achieved\nstate-of-the-art (SOTA) results on public nat-\nural language processing (NLP) benchmarks,\nat times surpassing human performance. How-\never, there is a gap between public benchmarks\nand real-world applications where noise, such\nas typographical or grammatical mistakes, is\nabundant and can result in degraded perfor-\nmance. Unfortunately, works which evaluate\nthe robustness of neural models on noisy data\nand propose improvements, are limited to the\nEnglish language. Upon analyzing noise in dif-\nferent languages, we observe that noise types\nvary greatly across languages. Thus, exist-\ning investigations do not generalize trivially\nto multilingual settings. To benchmark the per-\nformance of pretrained multilingual language\nmodels, we construct noisy datasets covering\nfive languages and four NLP tasks and observe\na clear gap in the performance between clean\nand noisy data in the zero-shot cross-lingual set-\nting. After investigating several ways to boost\nthe robustness of multilingual models in this\nsetting, we propose Robust Contrastive Pre-\ntraining (RCP). RCP combines data augmenta-\ntion with a contrastive loss term at the pretrain-\ning stage and achieves large improvements on\nnoisy (& original test data) across two sentence-\nlevel (+3.2%) and two sequence-labeling (+10\nF1-score) multilingual classification tasks.\n1 Introduction\nRecently, multilingual pre-trained language mod-\nels like mBERT (Devlin et al., 2019), XLM-R\n(Conneau et al., 2020) and various others (Chi\net al., 2021; Xue et al., 2021; Chi et al., 2022)\nhave improved multilingual language understand-\ning by pretraining large Transformer models on\nweb-scale corpora (such as Wikipedia, Common-\nCrawl). These models achieve state-of-the-art per-\nformance on cross-lingual transfer and many mul-\ntilingual NLP tasks (Wu and Dredze, 2019; Pires\n⋆ Equal Contribution, ¶ Work done while at Amazon.\net al., 2019). However, a real-world system will\nencounter real-world noise, such as linguistic vari-\nations and common errors observed in textual data,\nthat are often absent from benchmark datasets.\nWhile prior works focused on this issue of ro-\nbustness in monolingual settings (Peng et al., 2021;\nSengupta et al., 2021; Tan et al., 2020), investiga-\ntion has been scarce for multilingual settings. In\nthis paper, we study the effect of realistic noise\nin multilingual settings and propose methods to\nboost the robustness of multilingual language mod-\nels across four NLP tasks: Intent Classification\n(IC), Slot Labeling (SL), Named Entity Recogni-\ntion (NER) and Natural Language Inference (NLI).\nDue to the lack of multilingual noisy evaluation\ndata, we synthesize benchmarks by mining noise\nfrom publicly available corpora and injecting them\ninto the test sets associated with each of the four\ntasks. We conduct human validation to ensure that\nthis noised data is indeed realistic (see examples\nfrom MultiATIS++ in Figure 1) and identify the\nvariety of noise-types seen across languages (in §3).\nThese analyses highlight the potential of our test-\nset in evaluating (and motivating future research\non) multilingual robustness.\nTo benchmark the performance of multilingual\nsystems, we consider accuracy metrics on two\nutterance-level tasks (IC% and NLI%) and F1-\nscores on two token-level classification tasks (SL-\nF1 and NER-F1). Specifically, we seek to evaluate\nthe model’s performance on the noised version of\nthe test datasets in a zero-shot cross-lingual setting.\nIn this scenario, we have training data for a task\navailable only in one language (in our case, En-\nglish) and test-data in various languages (Liu et al.,\n2019, 2020).\nWhile training data augmentation increases\nmodel robustness for monolingual (i.e. English)\nsettings, it is not immediately obvious if these ro-\nbustness gains can transfer across languages, as\nerror types can often be language-specific. For ex-\n1375\nLanguage Noise\nInjection\nRatio\nRealistic\nUtt. %\nRealistic Examples (test-set) Unrealistic Examples (test-set)\nFrench\n(fr)\n0.1 95.4%\nMe montré les vols directs de Charlotte à Min-\nneapolis mardi matin .\nQuelle compagnie aérienne fut YX\nMe montré des vols entre Détroiter St. Louis sur\nDelta Northwest US Air est United Airlines .\nLister des vols de Las V egas àSon Diego\nGerman\n(de)\n0.2 94.5%\nZeige mir der Flüge zwischen Housten und Or-\nlando\nW elche Flüge gibt esvom T acoma nach San Jose\nZeige mit alle Flüge vor Charlotte nach Minnea-\npolis zum Dienstag morgen\nZeige mit Flüge an Milwaukee nach W ashington\nDC v .12 Uhr\nSpanish\n(es)\n0.1 96.9%\nqué aerolíneas vuelan de baltimore a san fran-\ncesc\nmuéstrame vuelos entr toronto y san diego\nnecesito información de un vuelo y la tarifa de\noakland a salt lake city para el jueves antese sus\n8 am\nde nuevo york a las vegas el domingocon la tarde\nHindi\n(hi)\n0.05 95.4%\nमुझे डेल्‍टा उड़ानों क े बारे में बताइए जो कोच क े\nयाित्रयों को नाश्‍तादेता हों\nमुझे मेिम्‍फस से लास वेगास तक उड़ान कीजरूरत है\nसोमवार दोपहरने लॉस एंिजल्‍स से िपट्सबगर्\nरिववार दोपहर को िमयामीमें क्‍लीवलैंड\nJapanese\n(jp)\n0.1 92.3%\nট\u0000ඣᤩರƎǁȉǌǏǍǜƹԚǍǁǊྛŰ\nƊǍǁǊ Ƒ ໶ᗥ 7ሢźƉa\u0000ƭ\nƑǫǿƺǞůଡᤩರƑǫǿƺǞ\nȅǍȉǞȉ Ƶ ǉȃȉǦǏᾇƑżƜƉƑǫ\nǿƺǞƑ≓ ƒŧŲƬ\nۖƑ๲ᤩರerrު1 ℭƎ\nԛ\u0000żƮ US ƾƸ\u0000ƑǫǿƺǞƵȀǏǞƸ\nǙǭźƉ\nඣᤩರƑǫƽǡǙǅǏ\u0000ǵȁƼƿ\u0000ǃ\u0000\n൜Ű\nChinese\n(zh)\n0.1 86.2%\n໡ླေ 4ׄު ᄝ֥\nϫ\nສࠏϫ\nطૄ฿ഈ໶ 10ສ࿰\nหধն\n࿰ ਔഒఫ\nFigure 1: MultiATIS++ test set injected with real-world noise mined from Wikipedia edits. The highest error\ninjection ratio found to be realistic by human experts is shown alongside the realistic utterance percentage. We do\nnot include the noisy test sets for Chinese and Japanese in our analysis owing to low (<95%) realism.\nample, typos in Devanagari script can differ from\nthose seen in Latin scripts (e.g. /halfsa/ka/uumatra/la→/sa/kau/la\nin Devanagari showcases that a joined character\nis incorrectly separated into two characters in the\nword ‘school’).\nThus, to improve the robustness of pretrained\nmultilingual models across noise in all languages,\nwe propose Robust Constrastive Pretraining (RCP)\nthat couples multilingual noisy data-augmentation\nwith a contrastive learning loss term during pre-\ntraining; this encourages the model to develop sim-\nilar representations for the original and the noised\nversion of a sentence.\nOn the noisy test sets, our method improves the\nmultilingual model performance across all metrics\nand multilingual tasks– IC% by 4.9% on Multi-\nATIS++, 4.1% on MultiSNIPS; SL-F1 by 18.4 on\nMultiATIS++, 8.6 on MultiSNIPS; NER-F1 by 2.9\non WikiANN; NLI% by 0.7% on XNLI. In sum-\nmary, our primary contributions are:\n1. We construct multilingual test data to evaluate\nthe robustness of NLP models to noise (§3).\n2. We show that the performance of existing mul-\ntilingual language models deteriorates on four\ntasks when tested on the noisy test data (§5.1).\n3. We introduce Robust Contrastive Pretraining\n(RCP) to boost the robustness of existing mul-\ntilingual language models (§5.2).\nOur code and data is available on Github (repo:\namazon-science/multilingual-robust-contrastive-\npretraining) .\n2 Related Work\nMany prior works demonstrate the brittleness\nof neural models on different noise phenomena\nsuch as misspellings (Belinkov and Bisk, 2017;\nKarpukhin et al., 2019; Moradi et al., 2021), cas-\ning variation (van Miltenburg et al., 2020), para-\nphrases (Einolghozati et al., 2019), morphologi-\ncal variance (Tan et al., 2020), synonyms (Sen-\ngupta et al., 2021), and dialectical variance (Sarkar\net al., 2022). A popular approach to improve the\nrobustness to noise is fine-tuning models with data\naugmentation (Feng et al., 2021) at either the pre-\ntraining (Tan et al., 2020; Sarkar et al., 2022) or the\ntask-training stage (Peng et al., 2021). These works\nconsider monolingual pre-trained models and pri-\nmarily focus on English. While recent works on\ntoken-free models motivate robustness in multilin-\ngual settings (Clark et al., 2021; Xue et al., 2022;\nTay et al., 2021),examining the robustness of SOTA\n1376\nmultilingual pre-trained models (and improving\nthem) remains unexplored. Hence, we investigate–\n(1) are multilingual models robust to noise seen in\ndifferent languages (that may be dissimilar to noise\ntypes seen in English)? (2) can we get and leverage\nmulti-lingual noise data to improve multilingual\nmodels? and (3) do automatic data-augmentation\nmethods designed for English improve robustness\nto multilingual noise?\nTo boost the robustness of multilingual models\nto diverse multilingual noise, we leverage multilin-\ngual data augmentation at the pretraining stage and\nuse contrastive learning. Our effort complements\nwork in computer vision that showcases contrastive\nlearning with adversarial learning at task-training\n(Fan et al., 2021; Ghosh and Lan, 2021) and pre-\ntraining time (Jiang et al., 2020; Kim et al., 2020)\ncan improve model robustness. NLP has also seen\na plethora of work that leverages contrastive learn-\ning, but seldom to alleviate robustness concerns\n(Jaiswal et al., 2020). Similar concepts, such as Ad-\nversarial Logit Pairing (Einolghozati et al., 2019),\nused at task-training time have proven to be less\neffective than data augmentation approaches (Sen-\ngupta et al., 2021) in boosting robustness.\nAll the aforementioned works lack in at least\none of the two novel aspects of this paper– ro-\nbustness to real-world (as opposed to adversarial)\nnoise, and/or multilinguality. Lastly, the aspect\nof cross-lingual knowledge transfer has been stud-\nied in the context of different NLP tasks; typically,\nfrom a high-resource language to a low-resource\none, as exemplified by the XTREME benchmark\n(Hu et al., 2020). In this paper, we investigate the\ncross-lingual transferability of robustness to real-\nworld noise.\n3 Constructing Noisy Test Data\nAs no existing benchmarks exist to evaluate the ro-\nbustness of multilingual models, we construct noisy\ntest sets in multiple languages for four tasks. First,\nwe construct a word-level error-and–correction dic-\ntionary by leveraging the Wikipedia edit corpora.\nThen, we sample replacements from this dictio-\nnary and inject them into the test data for the var-\nious multilingual tasks, focusing on replacements\nthat only affect individual words but do not change\nword order. Finally, we conduct human evalua-\ntion to filter out test sets that are not deemed to be\nrealistic by language experts.\n3.1 Wiki-edit Mining\nWikipedia2 is a public encyclopedia available in\nmultiple languages. Wikipedia editors create and\niteratively edit its contents. We leverage these ed-\nits to construct error-correction word dictionaries\n(later used to create noisy test data). Our approach\nto mining edits is similar to Tanaka et al. (2020),\nbut we consider multiple languages (as opposed to\nonly Japanese), and additionally create dictionaries\nof word-level edits.\nTo isolate likely useful edits, we first consider\neach revision page of an article and split it into a list\nof sentences using NLTK (Bird et al., 2009). Sec-\nond, we filter out sentence pairs from two consecu-\ntive edit versions ensuring both sentences have (1)\n2-120 tokens, (2) a difference if<5 tokens, and (3)\na relative edit-distance within 30% of the shorter\nsentence. Third, we leverage language-specific\ntokenizes difflib3 to extract exact token-level\ndeltas between the sentence pair. At last, we en-\nsure word pairs (in these deltas) that have at least\none character-level Levenshtein edit-distance from\neach other4 and none of words are only numbers or\npunctuation tokens. Note that edits to Wikipedia in-\nvolve changes to factual information, such as dates,\nrather than incorrect spelling or grammar; thus, the\nlast step is necessary.\nWe can finally create a noise dictionary of\ncorrect-to-incorrect words that has frequency\ninformation about the different errors. For\nexample, an element of the dictionary (in Spanish)\nlooks like {de: [(del, 0.52), (se,\n0.32), (do, 0.1), (dë, 0.04),\n(en, 0.02)]}.\n3.2 Injecting Noise into Test sets\nWe use the noise dictionaries to create a noised\nversion of the original test data for the four\ntasks– MultiATIS++ (Xu et al., 2020), MultiSNIPS,\nWikiANN (Pan et al., 2017) and XNLI (Conneau\net al., 2018). After tokenization, we sample tokens\nrandomly without replacement. In each sampling\nstep, we sample based on a uniform probability dis-\ntribution over the individual tokens and then check\nif the token exists in the noise dictionary. If so,\nwe replace it with a noised version from the dic-\n2https://meta.wikimedia.org/wiki/List_\nof_Wikipedias\n3https://docs.python.org/3/library/\ndifflib.html\n4For Chinese characters, including Kanji, even a single\ncharacter distance could imply a different word.\n1377\ntionary; the noised version is sampled based on its\nprobability in the noise dictionary (that is propor-\ntional to the frequency of its occurrence in the noisy\ncorpora). This procedure continues till we noise\na particular number of tokens, precisely between\n1 and min(4,pL) where pa controllable fraction\n(chosen as a hyperparameter at first, and finalized\nbased on human evaluation described in §3.3), and\nLis the number of words in the sentence.\n3.3 Human Verification of Noised Test-sets\nDuring human evaluation, we analyse the noisy\ndata created for the MultiATIS++ dataset. We\nasked the language expert to assume that a user\nwho may not be a native speaker, or in a hurry,\nor sloppy, was trying to find out flight informa-\ntion via text chat, and evaluate realism with this in\nmind. Note that analysis of noise types for Multi-\nATIS++ generalizes well to other datasets as we use\nthe same error-correction dictionaries for injecting\nnoise into all the test-sets.\nOur language experts have graduate/doctoral de-\ngrees in linguistics, computational linguistics, or\nnatural language processing and are fluent/native\nspeakers of the respective languages. We employed\nthe human experts and compensated them fairly to\nconduct this study (see §7 for details). The experts\nare given 45 examples without being told that 15\nexamples have 5%, 15 have 10%, and 15 have 20%\nnoised tokens and asked three questions about each\nexample. (1) Is the noised sentence realistic, mod-\nerately realistic, or unrealistic? (2) What type of\nnoise is present in the sentence (we supply an ini-\ntial list and let them add more)? and (3) Are the\nintent and slot labels unchanged? Based on their\ninitial feedback, we choose the most realistic noise\nfraction (i.e. 5, 10 or 20%) and provide them with\n60 more examples from that set. We considered 15\nutterances enough to determine the noise fraction,\nbut used the ratings on 75 utterances for evaluating\nrealism (see realistic utterance % in Figure 1).\nIn Figure 1, we summarize the results of the hu-\nman evaluation. Column two shows the error injec-\ntion ratio that was deemed to have more than 95%\nrealistic utterances. We set a high cut-off of 95%\nto ensure we can make confident statements about\nthe robustness of multilingual models to realistic\nalterations exhibited in our benchmarks. Hence,\nChinese and Japanese (with a realism of 86.2%\nand 92.3% resp.) are omitted in our benchmarks.\nThe last two columns highlight examples deemed\nFigure 2: The column-wise color density (which adds\nup to one) shows the percentage of a different noise\ntypes observed for a particular language. The row-wise\nvalues show that some noise types (eg. homophononic)\nis only present for a single language (eg. zh).\nas realistic and unrealistic by human experts with\nthe noised tokens highlighted in orange.\nGiven the sentence length and similarity in task\ntypes, we use the error injection percentage deter-\nmined to be the most realistic for MultiATIS++ as\nthe error injection percentage for MultiSNIPS and\nWiki-ann. For XNLI, experts deemed higher noise\ninjection ratios (of >0.05) to be unrealistic (15%\nfor 0.1, 27% for 0.2) because (1) the premise, usu-\nally much longer than sentences in MultiATIS++,\nhad (impractically high) number of noise tokens,\nand (2) the classification label (implies/neutral/-\ncontradicts) sometimes changed with large noise\nadditions. Thus, for XNLI, we choose 0.05 to be\nthe default noise injection ratio. Finally, one expert\nnoted the Turkish data for MultiATIS++ lacked\nmany diacritic characters, muddling the distinction\nbetween noise injected by our procedure and exist-\ning misspellings; hence, it was ignored.\nIn Figure 2, we list the noise-types identified\nby our experts in different languages. While cer-\ntain noise-types, such as typographical errors, mis-\nspellings are common across multiple languages,\n1378\n[CLS] sc [CLS] sn\nPLM (f) PLM (f)\n○ ○. . . ○ ○ ○. . . ○\nLMLM −original LMLM −noisy\n⨁ (g) ⨁ (g)\nLcontrastive+ +\nFigure 3: Loss function for fine-tuning a Pretrained\nLanguage Model (PLM) using Robust Contrastive Pre-\ntraining (RCP).\nthere are various language-specific noise-types,\nsuch as homophonic errors (for zh), Kanji con-\nversion errors (for ja), anglicization (for tr) (we\nshowcase some examples in Appendix A). Given\ndisjoint noise types across languages, we expect\nthat augmentation with errors seen in English (us-\ning approaches proposed by prior works) will gen-\neralize better to languages that share error types.\n4 Robust Contrastive Pre-training (RCP)\nMotivation and Approach While task-time data\naugmentation (aka adversarial training) has been\neffective to boost the robustness of pre-trained mod-\nels for English, we face two major challenges– (1)\nlack of supervised multilingual training data in our\nzero-shot setting, and (2) lack of approaches to\nsynthetically generate noise data for non-English\nlanguages. We overcome these with a multilingual\ndata-augmentation approach at pre-training time\nthat uses the multilingual Wikipedia edit corpus\nto expose our models to human errors during pre-\ntraining. Here, the need of ex-situ injection of noise\n(for test-data creation §3) is unnecessary as our edit\ncorpus contains pairs of similar sentences, i.e. a\nversion of the sentence before and after revision\nby a Wikipedia contributor (§3.1). To encourage\nthe model to align the representations of these two\nsentences in the encoder’s output space, we use a\ncontrastive loss term (see Figure 3). Building on\nprevious work on contrastive learning (Giorgi et al.,\n2021), Robust Contrastive Pre-training (RCP) con-\nsiders the original and edited version of a sentence\nas positive examples and other unrelated sentences\nas the negative examples.\nSimilar to Giorgi et al. (2021) and Reimers and\nGurevych (2019)), we map variable length sen-\ntences to fixed-length embeddings with a pooler\nei = g(f(si)), where f(·) is a transformer encoder,\nand g(·) is the mean of the token-level embeddings.\nGiven a batch of N (noisy, clean) sentence tuples,\nwe set our original sentence sc as the anchor and\nthe noisy version sn as the corresponding positive\npair. 5 Other sentences in the batch (i.e. ̸= sn)\nare deemed to be negative examples. We consider\nthe InfoNCE/NT-Xent loss (Sohn, 2016) for our\nper-example contrastive loss:\nℓ(i,j) =−log exp(sim(ei,ej))∑\ni̸=k exp(sim(ei,ek)/τ) (1)\nwhere sim(u,v) = uT v/||u||2||v||2 denotes the\ncosine similarity of two vectors uand vand τ >0\ndenotes the temperature hyper-parameter. Thus,\nour final contrastive loss function is\nLcontrastive =\nN∑\ni=1\nℓ(c,n) +ℓ(n,c)\nWe additionally use the standard MLM loss at pre-\ntraining time, masking 15% of the input tokens of\nevery sentence (i.e. both noisy and clean) indepen-\ndently. Therefore, our final loss function is\nL= Lcontrastive + LMLM-noisy + LMLM-original\nLMLM-original is the MLM loss on original sentences,\nand ensures the model does not ‘forget’ its original\npre-training task. LMLM-noisy is the MLM loss on\nnoisy sentences, and can be thought of as data-\naugmentation at pre-training time.\nPre-training Details Following the Domain\nAdaptive Pre-Training (DAPT) approach (Guru-\nrangan et al., 2020), we start with an existing mul-\ntilingual pre-trained model and fine tune it with\nour RCP objective. Unlike DAPT, we are not inter-\nested in specializing in a particular domain, but in\nincreasing robustness to errors. As mentioned be-\nfore, we use (unfiltered) pairs of correct/incorrect\nsentences from the multilingual Wikipedia archive\nand include sentences from the Lang8 corpus.6 The\nLang8 corpora consists of a smaller number of\nsentences compared to the Wikipedia corpus, but\nproves to be apt for our purpose; it consists of pairs\nof sentences– one written by a non-native speaker\nwho is learning the language (eg. “As the winter\n5One obvious choice would be for clean sentence with\nindex 2i, the noisy sentence has index 2i − 1.\n6https://sites.google.com/site/\nnaistlang8corpora/\n1379\nDataset Task Size (training) Languages Epochs Learning Rate Seeds\nMultiATIS++ (Xu et al., 2020) IC/SL 5k de,en,es,fr,hi 80 1E-04 5\n+ training data aug. 18k de,en,es,fr,hi 20 1E-04 5\nMultiSNIPS IC/SL 13k en,es,fr,hi 40 1E-04 5\n+ training data aug. 72k en,es,fr,hi 10 1E-04 5\nWikiANN (Pan et al., 2017) NER 20k de,en,es,fr,hi,tr 3 2E-05 5\nXNLI (Conneau et al., 2018) NLI 392k de,es,fr,hi,tr 5 2E-05 5\nTable 1: Data-set characteristics and hyper-parameters for our experiments.\nModel Original/ Noisy MultiATIS++ MultiSNIPS Wiki-ann XNLI\nIC% SL-F1 IC% SL-F1 NER-F1 NLI%\nXLM-Rbase Original 90.68 71.45 92.93 68.01 74.14 76.69\nNoisy 89.65 62.3 90.46 61.63 69.48 74.38\nmBERT Original 86.29 64.95 78.65 59.05 73.92 70.82\nNoisy 85.42 55.17 75.35 53.71 69.38 68.44\nTable 2: Performance of pre-trained multilingual models on the four multilingual datasets averaged across languages\nand 5 seeds. XLM-Rbase outperforms mBERT on Original and Noisy test data across all metrics.\nis coming, I’m getting to feel better.”) and a re-\nwrite of this sentence by a native speaker (eg. “as\nthe winter is coming, I’m starting to feel better.”).\nMore details about the individual corpora can be\nfound in Appendix C.\nWe note that the pre-training corpus is not ex-\nactly the same set of sentences used to construct\nour noise dictionaries in §3.1. In this case, the\nonly criteria for inclusion is a length difference of\n<5 tokens, and a relative edit-distance of 30% of\nthe shorter sentence (see appendix C for more de-\ntails). Hence, we incorporate training data from the\ncorpora that exhibit changes beyond simple typos\n(such as paraphrasing, sentence-level morphologi-\ncal variance) in the pre-training stage.7\nSimilar to Gururangan et al. (2020), we fine\ntune for 25k steps with a batch size of 2048\nsentences to create two pretrained models– one\nwith Lcontrastive +LMLM-noisy +LMLM-clean (referred\nto as Robust Contrastive Pre-training or RCP)\nand an ablation without the contrastive term, i.e.\nLMLM-noisy + LMLM-clean. The latter setting rep-\nresents a pure (pre-training time) data augmenta-\ntion approach such as Tan et al. (2020) (termed\np(aug) in Table 3). See Appendix D for more hyper-\nparameters and settings.\n5 Experiments and Results\nWe divide this section into three parts. In §5.1,\nwe analyze the robustness of popular multilingual\nlanguage models in the zero-shot cross-lingual set-\n7Unfortunately, the benefit of including sentence-level\nnoise in the pre-training phase is not directly examined by\nour benchmarks, which focus more on word-level noise.\nting. In §5.2, we show that Robust Contrastive Pre-\ntraining (RCP) improves the robustness of existing\nbaselines on noisy test-data for all tasks– joint in-\ntent classification and slot labeling (IC-SL), Slot-\nLabeling (SL) Named Entity Recognition (NER)\nand Natural Language Inference (NLI)– and (not\nonly maintains but) improves performance on the\noriginal test data. Finally, in §5.3, we conduct fail-\nure mode analysis for MultiATIS++ and discover\nthat the model trained with RCP makes more ex-\nplicable sequence-labeling errors (for slot-value\nprediction) in comparison to existing baselines.\nSetup We consider four datasets (shown in Ta-\nble 1) and four metrics for evaluation. Two of these\nmetrics consider sentence classification accuracy–\nIntent classification Accuracy (IC%) for the goal-\noriented dialog text datasets MultiATIS++ and Mul-\ntiSNIPS, and classification accuracy (NLI%) for\nXNLI. We also consider F-score for sequence-\nlabeling tasks– Slot Labelling (SL-F1) for Mul-\ntiATIS++ and Multi-SNIPS++ and Named En-\ntity Recognition (NER-F1) for Wiki-ann. Table 1\nshows the languages present in the noisy test data\nand the size of the English training data used in\nour zero-shot cross-lingual setting. Note that for\ntask-time data augmentation, we follow the strat-\negy of aggregate noise augmentation proposed in\n(Sengupta et al., 2021) for English, which involves\naugmenting training data with a variety of synthetic\nnoise types such as typos, making words ALL-\nCAPS, abbreviations etc. As this augmentation\nprocedure increases the size of the training data-set\n≈3.5 times for MultiATIS++ and ≈5.5 times for\n1380\nTask Metric XLMR XLMR\n+p(aug)\nXLMR\n+t(En-aug)\nXLMR\n+RCP\n(Ours)\nXLMR\n+RCP+t\n(Ours)\nGain\nMultiATIS++ IC% 89.65 93.10 91.26 93.80 94.57 +4.92\nSL-F1 62.30 67.47 74.62 67.45 80.68 +18.38\nMultiSNIPS IC% 90.46 93.98 91.60 93.79 94.53 +4.07\nSL-F1 61.63 66.67 66.44 67.69 70.20 +8.57\nWiki-ann NER-F1 69.48 72.32 - 72.37 - +2.89\nXNLI NLI% 74.38 74.83 - 75.06 - +0.68\nTable 3: Average performance across languages and five seeds. We abbreviate the baselines, multi-lingual pre-\ntraining time augmentation as p(aug), and English task-time (aggregate) data augmentation as t(En-aug). ‘RCP’\nstands for ‘Robust Contrastive Pre-training’, and ‘RCP + t’ means combining RCP with task-time data augmentation.\n‘Gain’ refers to the increase in performance of the best method vs. XLM-Rbase.\nMultiSNIPS, we find that training for fewer epochs\nyields the best results.\n5.1 Robustness of Multilingual Models\nWe compare the robustness of two popular pre-\ntrained language models– XLM-R base and multi-\nlingual BERT in the zero-shot cross-lingual set-\nting.8 In this setup, we fine-tune the pretrained\nlanguage models on the task-training data in En-\nglish and test (zero-shot) on multilingual test sets.\nThe results reported in Table 2 are averaged across\nmultiple languages for brevity (and provide a de-\ntailed breakdown in Appendix E). A secondary\ngoal of this experiment was to decide which pre-\ntrained model to use for further experiments and\nwe base our judgements on twelve metrics across\nfour datasets.\nNoise always leads to a decrease in performance.\nOn average, the accuracy of both models decreases\nby ≈2% for sentence-level tasks (IC%, NLI%),\nand by ≈6.6 F1-points on sequence-labeling tasks\n(SL, NER), on noisy data compared to clean data.\nThis can perhaps be explained by the ability to\nignore a particular token for sentence-level tasks,\nwhereas every token, including noisy ones, need to\nbe assigned a label for sequence-labeling tasks.\nWe observe that XLM-R base outperforms\nmBERT on all the twelve metrics. For sentence-\nlevel tasks (i.e. IC%, NLI%), XLM-R base outper-\nforms mBERT by 8.43% on average on the noisy\ntest-sets and for sequence-tagging tasks (i.e. SL,\nNER), XLM-Rbase outperforms mBERT by 5.1 F1-\npoints. In general, XLM-Rbase also seems to be a\nmodel better suited for these tasks in the zero-shot\ncross-lingual setting, as we also see similar gains\nwhen using XLM-Rbase on the clean data.\n8We also considered Canine-c (Clark et al., 2021), a token-\nfree baseline, but observed poor performance compared to\nXLM-Rbase and BERT on IC-SL tasks (see Table 10).\nTask Metric XLMR Ours Gain\nMultiATIS++ IC% 90.68 95.32 +4.64\nSL-F1 71.45 84.07 +12.62\nMultiSNIPS IC% 92.93 95.66 +2.73\nSL-F1 68.01 74.39 +6.38\nWiki-ann NER-F1 74.14 76.34 +2.2\nXNLI NLI% 76.69 76.75 +0.06\nTable 4: Comparison of our RCP method with the base-\nline XLM-Rbase model on the original (clean) test data.\nBreaking the results down by language (see Ap-\npendix E for detailed results), XLM-Rbase outper-\nforms mBERT on average across all languages.\nSpecifically XLM-Rbase outperforms mBERT on\nGerman (in 6/8 metrics), on Spanish (10/10), on\nFrench (8/12), on Hindi (12/12), and on Turkish\n(4/4). As German is missing in MultiATIS++ and\nTurkish is only present in WikiANN and XNLI\namong the four datasets, the overall number of met-\nrics is less than 12 for these two languages. Given\nthese results, we consider XLM-Rbase as the base-\nline multilingual language model in the rest of our\nexperiments.\n5.2 Robust Contrastive Pre-training Results\nTo showcase the efficacy of our RCP approach,\nwe compare our approach to a popular multilin-\ngual model XLM-Rbase, which performed best in\nthe previous section, and two augmentation solu-\ntions that were proposed earlier and shown to im-\nprove robustness of English language models to\nreal-world noise. First, we consider a pre-training\ntime data augmentation approach, similar to Tan\net al. (2020), by continuing to pre-train XLM-Rbase\non noisy multilingual data; see section 4. Next, we\nconsider augmenting task-time data with a combi-\nnation of various noise types, following Sengupta\net al. (2021) that shows using this aggregate data\naugmentation during task-time finetuning improved\n1381\nError Type Utterance Slot-lables\nHallucination Ichs brauche einen Flug von Memphis nach Tacoma, der\nuber Los Angeles fliegt\n/O (über)\n/ec♀aatnairline_code\nContextual Zeige mit der Erste-Klasse und Coach-Flüge vom JFK nach\nMiami\n/fromloc.airport_code\n/ec♀aatntoloc.airport_code\nTable 5: Examples of slot labeling errors in German– errors are in italics; misclassified tokens are bold.\nperformance on both noisy and clean data for IC-SL\ntasks like ATIS and SNIPS. For the latter, we treat it\nas a baseline for zero-shot cross-lingual transfer for\nthe dialog-datasets–MultiATIS++ and MultiSNIPS–\nand also combine it with our pre-training time ap-\nproaches.\nAs shown in Table 3, our approach can improve\nthe performance of current multilingual models\nacross all 4 tasks and datasets. For the multilin-\ngual goal-oriented dialog datasets, our approach\ncoupled with task-time augmentation outperforms\nall the other methods. We observe that the gain for\nSL tasks is higher than that obtained for IC tasks.\nAlthough we analyze the SL results further in §5.3,\nwe highlight that IC accuracy is less affected by\nnoise than SL F1; this provides more headroom\nfor improving SL metrics. The highest gains are\nobserved for Hindi where the XLM-R base model\nhas the worst SL performance on noisy data (42.86\nfor MultiATIS++, 36.93 for MultiSNIPS). Like-\nwise, we also observe improvement on XNLI%\nand NER-F1; the largest improvement is again seen\non the noisy data for Hindi. Overall, the gain on\nsequence-labelling tasks is larger than the gain on\nsentence-level classification tasks.\nDoes this improvement on noisy data come at\nthe cost of worse performance on clean data? In\nTable 4, we show that the best performing mod-\nels shown in Table 3 (XLMR+RCP+t for Multi-\nATIS++ and MultiSNIPS, and XLMR+RCT for\nWikiANN and XNLI) also improve the perfor-\nmance on clean test data. Further, the magnitude\nof growth seen on clean data is like the ones seen\non the noisy test data. For slot-labeling errors, we\nobserve a particular kind error which occurs on\nboth clean and noisy data that our model mitigates;\nwe provide more details on this in the next section.\nFor IC and XNLI, we found no specific error pat-\ntern that distinguishes between XLM-Rbase and our\nmodel. Thus, we believe that our approach mostly\nimproves the overall quality of the model’s repre-\nsentation rather than just its downstream robustness.\nIn the future, one can consider if an upper bound\non model quality exists beyond which the tension\n0 10 20 30 40 50 60 70\nde\nes\nfr\nhi\nNumber of slot labels→\n24\n31\n31\n32\n12\n12\n8\n12\n34\n27\n31\n26\nOur model is better| Baseline (XLMR) is better| Equal\nFigure 4: Comparing the number of slot labels for which\nour model vs. the baseline performs better.\nbetween accuracy on clean data and robustness to\nreal-world noise emerges (Tsipras et al., 2018).\nFinally, we note that beyond improving perfor-\nmance on clean and noisy data, our approach re-\nduces the disparity in performance between the\nclean and noisy test sets. For MultiATIS++, the\ndisparity reduces by 0.3% for IC% and 5.76 for\nSL-F1; for MultiSNIPS, it reduces by 1.34% for\nIC% and 2.19 for SL-F1; for WikiANN, it reduces\nby 0.68 for NER-F1; and for XNLI, it reduces by\n0.9% for NLI%.\n5.3 Result Analysis\nGiven the large improvement seen on sequence\nlabeling tasks, we zoom in on the SL metrics for\nMultiATIS++. In Figure 4, we show the number of\nslot labels on which our method outperforms (has\nfewer misclassifications than) the baseline, vice\nversa, and where they perform equally. Our method\nclearly out-performs the baseline on at least twice\nthe number of slot-labels– 2×better on German,\n≈2.6×times on Spanish and on Hindi, and ≈4×\non French. Across all languages, our model always\noutperforms XLM-Rbase on eight slot-labels. These\nslots correspond to relative times (‘leaves in the\nevening’), relative dates (‘traveling the day after\ntomorrow’), relative costs (‘cheap flights’), meal\nnames (‘flights that offer breakfast’), and carrier\ntokens/non-slot values (‘that offer breakfast’). We\npostulate these slot values are more common in the\n1382\nN/O Model de es fr hi\nNoisy XLMR 315 358 413 671\nXLMR+RCP+t 21 123 33 204\nOriginal XLMR 208 262 334 460\nXLMR+RCP+t 19 106 22 180\nTable 6: Reduction in hallucination error (i.e. model\nidentifies irrelevant tokens as a slot value) counts.\nLanguages de es fr hi\n(r1) Top-confusion changes\nto no-label (w/ RCP)\n7 8 6 17\n(r2) Confusions becomes\nmore explicable (w/ RCP)\n8 3 3 4\nTable 7: Number of slot-labels that our model misclassi-\nfied to (r1) a no-slot or (r2) a more explicable slot-label.\npre-training data compared to proper nouns such as\nairline, airport or city names and thus, understood\nin noisy contexts. In turn, variations of these words\nare mapped closer in the embedding space and the\nclassifier is more robust to such errors.\nUpon further analysis, we observe two distinct\npatterns– (1) reduction in hallucination errors, i.e.\nerrors where an irrelevant carrier phrase token is la-\nbeled to be a slot value, and (2) errors become more\ncontextual– misclassification is to related classes\n(see examples in Table 5).\nIn Table 6, we highlight the distribution of hallu-\ncination errors and observe that the number of car-\nrier phrase tokens that the baseline XLM-Rbase mis-\nclassifies as a slot-value reduces (by > 10×for\nGerman and French, and ≈2-3×for Hindi and\nSpanish) with our approach on both the original\nand the noisy test data. This observation aligns\nwith our initial reasoning that the contrastive loss\nterm at pre-training time helps the model develop\na better understanding of non-slot words as the\nmodel learns to identify such words (and their noisy\nforms) in both linguistically correct and noisy con-\ntexts. Note that the latter signal is missing for the\nXLM-Rbase baseline.\nFor a subset of the slot labels, the class to\nwhich it was misclassified (with the highest fre-\nquency) differed between the XLM-Rbase baseline\nand our model. In Table 7, we highlight two\nscenarios where the most-confused label changed\nfrom (r1) an incorrect slot label (eg. meal_code\n→ airline_code) to no-label (i.e. meal_code\n→O), and (r2) from an inexplicable slot label\n(state_code →transport_type) to a more explica-\nble one (state_code →state_name) when the RCP\nmethod is used (we use the explicable/inexplicable\nterminology of Olmo et al. (2020)). Thus, our ap-\nproach inadvertently improves the explicability of\nthe failures made during slot-labeling.\n6 Conclusion\nIn this paper, we investigate the robustness of pre-\ntrained multilingual models in the zero-shot cross-\nlingual setting on four tasks– intent classification,\nslot labeling, named entity recognition, and natural\nlanguage inference. Given the dearth of existing\ndatasets to benchmark the robustness of existing\nmultilingual models, we develop noisy test data\nby injecting errors mined from an edit corpus (and\nconduct expert evaluation for quality assurance).\nOur identification of noise types across various lan-\nguages motivates the necessity of language specific\ninvestigation in the future. Finally, demonstrate\nexisting baselines perform poorly in the presence\nof noise in the test data and propose Robust Con-\ntrastive Pretraining to boost the robustness of these\nmultilingual models.\n7 Ethical Considerations\nFor the human annotation tasks of (1) identify-\ning language-specific noise types, and (2) rank-\ning their realism, we leveraged the effort of full-\ntime employees at Amazon. The annotators had\nadvanced degrees in linguistics or natural language\nprocessing, and were fluent/native in the languages\nthey annotated. Amazon compensated them un-\nder a competitive industry rate, which is above the\nminimum hourly pay rate, for their particular job\nrole (which included Applied/Research Scientists,\nSoftware/Language Engineers, Linguists, and Lan-\nguage Consultants).\nAcknowledgements A special thanks to Saab,\nBatool Haider and M. Saiful Bari for sharing with\nus the MultiSNIPS dataset. In addition, we want\nto express our gratitude to members of the AWS\nAI Lab for their valuable comments, suggestions,\nand participation in our pilot and human label-\ning studies (in no particular order)– Sebastien\nJean, V olha Belash, Arshit Gupta, Berk Sarioz,\nMaansi Shandilya, Raphael Shu, Abhilash Pani-\ngrahi, Lorenzo Lambertino, and Yi Zhang. Finally,\nwe are grateful to the anonymous reviewers who\nhave helped us improve this paper.\n1383\n8 Limitations\n8.1 The Umbrella of Realistic Noise\n‘Realistic noise’ is too abstract a category. We\nmostly concern ourselves with real-world errors\nand their corrections appearing in existing corpora\n(with criteria like a small character-level edit dis-\ntance). But this could include things like better\nparaphrasing, use of more appropriate synonyms\nor morphology that can be viewed as language vari-\nation rather than noise; this could be one reason\nwe notice improvements on the original (i.e. un-\nnoised) test data. Yet, to distinguish ourselves from\nthe terminology of synthetic or adversarial noise,\nwe choose this (imperfect) terminology of real-\nworld/realistic noise as in Sengupta et al. (2021) to\nbracket all our noise types under a single class.\n8.2 Language Choice and Diversity\nThis work considers (relatively) high-resource lan-\nguages. This makes it easier for us to find publicly\navailable corpora from where we can mine error/-\ncorrection data and use it to improve the model’s\nunderstanding of errors and, in turn, boost their\nrobustness to real-world noise. But this is only\nthe first step towards developing an understanding\nof noise phenomena in languages beyond English,\nbench-marking multi-lingual model performance\nin such settings, and improving their robustness.\nFurther, we do notice that Hindi (and, to some ex-\ntent, Turkish) are relatively low resource languages\nwhen it comes to pre-training data (see Table 8 in\nAppendix). We hope future work builds on this and\nexplores a greater variety of languages.\n8.3 Zooming-in on Individual Tasks\nMany of our human studies are based on a subset\nof datasets (eg. MultiATIS, XNLI). It is possi-\nble individual tasks and further, individual datasets\nneed more fine-grained human attention. Given\nlanguage expertise for several datasets and several\nlanguages is difficult/costly, we made the choice\nto concentrate on a smaller number of datasets in\norder to provide a more rigorous analysis. We\nhope future work can expand the number of tasks\nand datasets covered so we have a more compre-\nhensive analysis of how multilingual noise affects\npre-trained models.\nReferences\nYonatan Belinkov and Yonatan Bisk. 2017. Synthetic\nand natural noise both break neural machine transla-\ntion. arXiv preprint arXiv:1711.02173.\nSteven Bird, Ewan Klein, and Edward Loper. 2009.Nat-\nural language processing with Python: analyzing text\nwith the natural language toolkit. \" O’Reilly Media,\nInc.\".\nZewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham\nSinghal, Wenhui Wang, Xia Song, Xian-Ling Mao,\nHeyan Huang, and Ming Zhou. 2021. InfoXLM: An\ninformation-theoretic framework for cross-lingual\nlanguage model pre-training. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 3576–3588, On-\nline. Association for Computational Linguistics.\nZewen Chi, Shaohan Huang, Li Dong, Shuming Ma,\nBo Zheng, Saksham Singhal, Payal Bajaj, Xia Song,\nXian-Ling Mao, Heyan Huang, and Furu Wei. 2022.\nXLM-E: Cross-lingual language model pre-training\nvia ELECTRA. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 6170–6182,\nDublin, Ireland. Association for Computational Lin-\nguistics.\nJonathan H. Clark, Dan Garrette, Iulia Turc, and John\nWieting. 2021. CANINE: pre-training an efficient\ntokenization-free encoder for language representa-\ntion. CoRR, abs/2103.06874.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nAlexis Conneau, Ruty Rinott, Guillaume Lample, Adina\nWilliams, Samuel Bowman, Holger Schwenk, and\nVeselin Stoyanov. 2018. XNLI: Evaluating cross-\nlingual sentence representations. In Proceedings of\nthe 2018 Conference on Empirical Methods in Nat-\nural Language Processing, pages 2475–2485, Brus-\nsels, Belgium. Association for Computational Lin-\nguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\n1384\nArash Einolghozati, Sonal Gupta, Mrinal Mohit,\nand Rushin Shah. 2019. Improving robustness\nof task oriented dialog systems. arXiv preprint\narXiv:1911.05153.\nLijie Fan, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, and\nChuang Gan. 2021. When does contrastive learning\npreserve adversarial robustness from pretraining to\nfinetuning? Advances in Neural Information Pro-\ncessing Systems, 34.\nSteven Y . Feng, Varun Gangal, Jason Wei, Sarath Chan-\ndar, Soroush V osoughi, Teruko Mitamura, and Ed-\nuard Hovy. 2021. A survey of data augmentation\napproaches for NLP. In Findings of the Association\nfor Computational Linguistics: ACL-IJCNLP 2021,\npages 968–988, Online. Association for Computa-\ntional Linguistics.\nAritra Ghosh and Andrew Lan. 2021. Contrastive learn-\ning improves model robustness under label noise. In\nProceedings of the IEEE/CVF Conference on Com-\nputer Vision and Pattern Recognition, pages 2703–\n2708.\nJohn Giorgi, Osvald Nitski, Bo Wang, and Gary Bader.\n2021. DeCLUTR: Deep contrastive learning for un-\nsupervised textual representations. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 879–895, Online.\nAssociation for Computational Linguistics.\nSuchin Gururangan, Ana Marasovi ´c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A. Smith. 2020. Don’t stop pretraining:\nAdapt language models to domains and tasks. In\nProceedings of the 58th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n8342–8360, Online. Association for Computational\nLinguistics.\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-\nham Neubig, Orhan Firat, and Melvin Johnson.\n2020. Xtreme: A massively multilingual multi-task\nbenchmark for evaluating cross-lingual generalisa-\ntion. In International Conference on Machine Learn-\ning, pages 4411–4421. PMLR.\nAshish Jaiswal, Ashwin Ramesh Babu, Moham-\nmad Zaki Zadeh, Debapriya Banerjee, and Fillia\nMakedon. 2020. A survey on contrastive self-\nsupervised learning. Technologies, 9(1):2.\nZiyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang\nWang. 2020. Robust pre-training by adversarial con-\ntrastive learning. Advances in Neural Information\nProcessing Systems, 33:16199–16210.\nVladimir Karpukhin, Omer Levy, Jacob Eisenstein, and\nMarjan Ghazvininejad. 2019. Training on synthetic\nnoise improves robustness to natural noise in machine\ntranslation. arXiv preprint arXiv:1902.01509.\nMinseon Kim, Jihoon Tack, and Sung Ju Hwang. 2020.\nAdversarial self-supervised contrastive learning. Ad-\nvances in Neural Information Processing Systems ,\n33:2983–2994.\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A\nmethod for stochastic optimization. In ICLR (Poster).\nZihan Liu, Jamin Shin, Yan Xu, Genta Indra Winata,\nPeng Xu, Andrea Madotto, and Pascale Fung. 2019.\nZero-shot cross-lingual dialogue systems with trans-\nferable latent variables. In Proceedings of the\n2019 Conference on Empirical Methods in Natu-\nral Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 1297–1303, Hong Kong,\nChina. Association for Computational Linguistics.\nZihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng\nXu, and Pascale Fung. 2020. Attention-informed\nmixed-language training for zero-shot cross-lingual\ntask-oriented dialogue systems. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 34, pages 8433–8440.\nPooya Moradi, Nishant Kambhatla, and Anoop Sarkar.\n2021. Measuring and improving faithfulness of at-\ntention in neural machine translation. In Proceedings\nof the 16th Conference of the European Chapter of\nthe Association for Computational Linguistics: Main\nVolume, pages 2791–2802, Online. Association for\nComputational Linguistics.\nAlberto Olmo, Sailik Sengupta, and Subbarao Kamb-\nhampati. 2020. Not all failure modes are created\nequal: Training deep neural networks for explicable\n(mis) classification. ICML Workshop on Uncertainty\nand Robustness in Deep Learning.\nXiaoman Pan, Boliang Zhang, Jonathan May, Joel Noth-\nman, Kevin Knight, and Heng Ji. 2017. Cross-lingual\nname tagging and linking for 282 languages. In Pro-\nceedings of the 55th Annual Meeting of the Associa-\ntion for Computational Linguistics (Volume 1: Long\nPapers), pages 1946–1958, Vancouver, Canada. As-\nsociation for Computational Linguistics.\nBaolin Peng, Chunyuan Li, Zhu Zhang, Chenguang\nZhu, Jinchao Li, and Jianfeng Gao. 2021. RADDLE:\nAn evaluation benchmark and analysis platform for\nrobust task-oriented dialog systems. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 4418–4429, Online.\nAssociation for Computational Linguistics.\nTelmo Pires, Eva Schlinger, and Dan Garrette. 2019.\nHow multilingual is multilingual BERT? In Proceed-\nings of the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4996–5001, Flo-\nrence, Italy. Association for Computational Linguis-\ntics.\n1385\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n3982–3992, Hong Kong, China. Association for Com-\nputational Linguistics.\nSoumajyoti Sarkar, Kaixiang Lin, Sailik Sengupta,\nLeonard Lausen, Sheng Zha, and Saab Mansour.\n2022. Parameter and data efficient continual pre-\ntraining for robustness to dialectal variance in arabic.\nIn NeurIPS 2022 Workshop on Efficient Natural Lan-\nguage and Speech Processing (ENLSP).\nSailik Sengupta, Jason Krone, and Saab Mansour. 2021.\nOn the robustness of intent classification and slot la-\nbeling in goal-oriented dialog systems to real-world\nnoise. In Proceedings of the 3rd Workshop on Nat-\nural Language Processing for Conversational AI ,\npages 68–79, Online. Association for Computational\nLinguistics.\nKihyuk Sohn. 2016. Improved deep metric learning\nwith multi-class n-pair loss objective. Advances in\nneural information processing systems, 29.\nSamson Tan, Shafiq Joty, Min-Yen Kan, and Richard\nSocher. 2020. It’s morphin’ time! Combating lin-\nguistic discrimination with inflectional perturbations.\nIn Proceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics, pages 2920–\n2935, Online. Association for Computational Lin-\nguistics.\nYu Tanaka, Yugo Murawaki, Daisuke Kawahara, and\nSadao Kurohashi. 2020. Building a Japanese typo\ndataset from Wikipedia’s revision history. In Pro-\nceedings of the 58th Annual Meeting of the Associa-\ntion for Computational Linguistics: Student Research\nWorkshop, pages 230–236, Online. Association for\nComputational Linguistics.\nYi Tay, Vinh Q Tran, Sebastian Ruder, Jai Gupta,\nHyung Won Chung, Dara Bahri, Zhen Qin, Si-\nmon Baumgartner, Cong Yu, and Donald Metzler.\n2021. Charformer: Fast character transformers via\ngradient-based subword tokenization. arXiv preprint\narXiv:2106.12672.\nDimitris Tsipras, Shibani Santurkar, Logan Engstrom,\nAlexander Turner, and Aleksander Madry. 2018.\nRobustness may be at odds with accuracy. arXiv\npreprint arXiv:1805.12152.\nEmiel van Miltenburg, Chris van der Lee, Thiago Castro-\nFerreira, and Emiel Krahmer. 2020. Evaluation rules!\non the use of grammars and rule-based systems for\nNLG evaluation. In Proceedings of the 1st Workshop\non Evaluating NLG Evaluation , pages 17–27, On-\nline (Dublin, Ireland). Association for Computational\nLinguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nShijie Wu and Mark Dredze. 2019. Beto, bentz, becas:\nThe surprising cross-lingual effectiveness of BERT.\nIn Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 833–844, Hong\nKong, China. Association for Computational Linguis-\ntics.\nWeijia Xu, Batool Haider, and Saab Mansour. 2020.\nEnd-to-end slot alignment and recognition for cross-\nlingual NLU. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP), pages 5052–5063, Online. Association\nfor Computational Linguistics.\nLinting Xue, Aditya Barua, Noah Constant, Rami Al-\nRfou, Sharan Narang, Mihir Kale, Adam Roberts,\nand Colin Raffel. 2022. ByT5: Towards a token-free\nfuture with pre-trained byte-to-byte models. Transac-\ntions of the Association for Computational Linguis-\ntics, 10:291–306.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A massively multilingual\npre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 483–498, On-\nline. Association for Computational Linguistics.\n1386\nA Examples of Noise/Errors in the test set\nIn this section, we highlight an example of some of the unique noise types observed for certain languages\nshown in Figure 5.\nFigure 5: Noise types seen across various languages.\nA.1 Typographic Errors (Typos)\nTwo examples follow for Hindi and Chinese, where experts evaluated based on the Indic Script and the\nPinyin keyboards (which is what they use regularly) respectively.\nLanguage Examples\nHindi (hi) सोमवार को बरबैंक [से|क े] िमल्‍वौकी तक उड़ानें\u0000\u0000\u0000\u0000\u0000\u0000\nChinese (zh)ϫ [ਙԛ | ২ԛ]ॢᇛ೘Ֆ\nϫ\nA.2 Preposition Errors\nWe noticed language experts tagged preposition errors for French and German. Examples follow:\nLanguage Examples\nFrench (fr) Je veux un vol aller-retour [de | à] Memphis à Seattle .\nGerman (de) Wie sieht es [am | im] Mittwoch morgen mit Flügen von DC nach Oakland aus\n1387\nA.3 Diacritic Errors\nSome languages use diacritic characters; although even these diacritics may greatly differ depending on\nscript. Examples from Hindi and Spanish follow.\nLanguage Examples\nSpanish (es) ¿puedo tomar el vuelo [más |mas] corto de milwaukee a orlando ?\nHindi (hi) d9s िकस [तरह |तरह्] का िवमान हैं\nA.4 Conversion Errors\nKanji conversion error. This error was unique to the Japanese language. Examples follow.\nLanguage Examples\nJapanese (ja)ᤩರ໶ᗥ 2 ℭ 30ٳ[ၛభ | ၇ಖ] Ƒǫ\nǿƺǞ\nA.5 Homophonic Errors\nThis error was unique to Chinese. Words with the same pronunciation (potentially with different tones),\nbut different spelling. Examples follow.\nLanguage Examples\nChinese (zh) ౨ਙԛՖ[ઌ೵ᨢ|ࠏ]ϫ\nA.6 Synonym\nExperts marked these as use of a different synonym in Spanish and Chinese only. Note that such variations\nmay not be erroneous but is still considered a noise given they are not used in the original training/testing\ndata in the given context as much. Examples follow.\nLanguage Examples\nSpanish (es) el próximo miércoles , me gustaría salir de kansas city en [un | el] viaje a chicago que\nllegue a chicago alrededor de las 7 p m.\nChinese (zh) ౨ਙԛՖewr [֞|֞]๙\nA.7 Anglicized\nWe observed this errors only for Turkish and noticed that experts marked scenarios where an alphabet in\nthe native script was replaced with a particular one in the latin script. Examples follow (note that Turkish\nexamples are drawn from the XNLI dataset, while the others were drawn from MultiATIS++).\nLanguage Examples\nT urkish (tr) Sonrasında, ilk ziyareti yapmış olan aynı temsilci, soruları cevaplamak ve şikayet\nörneğinde not edilen sorunları tartışmak [için | icin] yeni sağlayıcıyı yeniden ziyaret eder.\nKonfederasyonun hukuk felsefesi, hem maddi hem de üslupla [karşı |karsi] karşıya geldi.\n1388\nB Chinese and Japanese Edit Mining\nOur two character edit distance criteria for obtaining word-level correct-noisy pairs of words does not\nwork well for Chinese characters, including Kanji for Japanese. This is because words are made up of only\na small number of characters (relative to e.g. latin scripts). So we can completely change the semantics\nwith only a small character-level edit distance. We therefore used different noise types: Homophonic\nand Synonym errors for Chinese and Kanji Conversion errors for Japanese, with brief descriptions and\nexamples in Appendix A. In order to collect homophonic errors we converted words to pinyin9 (without\ntone markers) and checked if they were the same in pinyin but different in Chinese characters. To collect\nsynonym noise we labelled words with part-of-speech (POS) tags 10, and kept words that weren’t labeled\nas nouns, verbs, adverbs, keeping e.g. prepositions and conjunctions, with the hope that these would be\nless likely to involve the kind of big semantic changes you might get with changes to e.g. proper nouns\nlike place names.\nHowever this process was largely driven by trial and error and more work is needed to create a principled\npipeline that creates a realistic noise dictionary for these languages.\nFinally for Kanji we re-use the criteria of Tanaka et al. (2020) as we re-use their dataset of sentence\npairs: checking if the two sentences (containing Kanji) have the same reading.\nC Data Details\nLanguage Lang8 Wikipedia Total\nen 2.5 3.8 6.3\nde 0.2 13 13.2\nes 0.2 7.6 7.8\nfr 0.2 10.7 10.9\nhi 0.001 0.1 0.101\nja 4.2 1 5.2\ntr 0.02 0.4 0.42\nzh 0.6 1.9 2.5\nTable 8: Number of sentences (in millions) used for pre-\ntraining.\nTable 8 shows the number of Wikipedia and\nLang8 sentences (in Millions) we used for fine-\ntuning the multilingual models in the pre-training\nstage (§4). As stated earlier, the proportion\nof data obtained from the Lang8 corpus is less\nthan Wikipedia for most languages except En-\nglish (where it is comparable) and Japanese\n(where Lang8 has ≈4x the data compared to\nthe Wikipedia corpus). In general, Hindi (and\nTurkish) stand out as a relatively low-resource\nlanguage in our investigation with less than 0.5\nMillion sentences.\nLanguage # Pairs (in Millions)\nen 0.13\nde 0.33\nes 0.21\nfr 0.27\nhi 0.04\nja 0.05\ntr 0.25\nzh 0.01\nTable 9: Number of Error pairs by language.\nTable 9 lists the number of correct/incorrect pairs (in\nMillions) used for noise dictionaries to create the test-sets\nfor the various languages (§3). Here too, we can observe\nthat the number of corrections are relatively less for Hindi.\nInterestingly, the number of errors for Chinese are the least\nalthough it representation is significantly more compared to\nHindi. This low number of errors is inline with our human\nstudies where even the 5% error injection was deemed to\nbe unrealistic; futher, such low pairs of errors also reduced\nthe diversity of our test set, which would eventually results\nin a lower-quality test-set. Hence, we drop it from our\nevaluation benchmarks.\nD Pre-training Settings\nFor our experiments with Robust Contrasting Pretraining (§4) and variants we use the following hyperpa-\nrameters and setup. We train on 4 Nvidea V100 GPUs, with a per-gpu batch size of 8 sentences with a\nmaximum sequence length of 128 tokens, and 64 gradient accumulation steps, for an overall batch size\nof 64 ×8 ×4 = 2048sentences. We use a masked language modeling mask probability of 15% and a\n9Using the pinyin Python package https://pypi.org/project/pinyin/\n10With the jieba Python package https://pypi.org/project/jieba/.\n1389\nlearning rate of 1e-4 with the Adam optimizer (Kingma and Ba, 2015), and used 16-bit floating point\noperations. See below for the arguments of the Huggingface transformers (Wolf et al., 2020) masked\nlanguage modelling script which we modified11\npython -m torch.distributed.launch --nproc_per_node 4 run_mlm.py \\\n--model_name_or_path xlm-roberta-base \\\n--gradient_accumulation_steps 64 \\\n--validation_split_percentage 1 \\\n--per_gpu_train_batch_size 8 \\\n--dataloader_num_workers 32 \\\n--model_type xlm-roberta \\\n--mlm-probability 0.15 \\\n--learning_rate 1e-4 \\\n--num_train_epochs 5 \\\n--max_seq_length 128 \\\n--line_by_line \\\n--do_train \\\n--do_eval \\\n--seed 42 \\\n--fp16\nE Per-language Results\nTable 10 shows the performance of multilingual models like m-BERT and XLM-R base on individual\nlanguages. We note that the reduction in performance for high-resource language (e.g. German, French,\nEnglish) is higher than low-resource languages for several settings. To explain this seemingly surprising\nresult, first notice that the metrics on low-resource languages are already bad, even on clean data. Second,\nthe variety of noise seen for low resource languages is less (see Table 9) compared to high-resource\nsettings. Hence, the effect of less diverse noise in low-resource languages doesn’t have as large an adverse\neffect on already poorly performing models.12\nAnother hypothesis, pending future investigation, is that multi-lingual models trained on more high-\nresource language data overfit to clean test-sets for these languages and fail to generalize better when\nfaced with noise. For low resource languages, the performance on clean data is already poor because of a\nlack of sufficient language understanding that prevents over-fitting.\n11https://github.com/huggingface/transformers/blob/main/examples/pytorch/\nlanguage-modeling/run_mlm.py\n12We are told a saying goes (coincidentally) in Hindi, mare hue ko kya maroge, saheb?. It implies you cannot do much (by\nadding noise) to kill the (model that is already) dead.\n1390\nDataset Model Metric C/N de en es fr hi tr Avg.\nMultiATIS++ XLMR IC% C 92.4 98.7 92.0 90.6 79.6 - 90.7\nN 90.9 97.6 91.8 89.5 78.4 - 89.6\nSL-F1 C 74.4 96.0 73.6 70.4 42.9 - 71.5\nN 67.3 82.2 68.2 65.6 38.2 - 62.3\nmBERT\nIC% C 83.3 98.3 84.7 88.8 76.3 - 86.3\nN 81.2 97.6 84.3 87.9 76.1 - 85.4\nSL-F1 C 59.9 96.0 65.1 69.8 33.9 - 65.0\nN 51.6 78.5 60.2 64.3 31.3 - 55.2\n(XLMR vs mBERT) 4,0 1,3 4,0 4,0 4,0\nCanine-c IC% C 66.32 96.51 78.41 76.06 71.55 - 77.77\nN 65.13 95.90 78.08 75.06 71.15 - 77.06\nSL-F1 C 31.56 92.19 19.52 23.67 22.81 - 37.95\nN 32.42 78.51 20.25 24.41 22.45 - 35.61\nMultiSNIPS++ XLMR IC% C - 98.8 94.0 91.3 87.6 - 92.9\nN - 98.4 92.4 87.0 84.1 - 90.5\nSL-F1 C - 96.9 72.0 66.2 36.9 - 68.0\nN - 92.7 63.3 57.7 32.8 - 61.6\nmBERT\nIC% C - 98.9 88.0 88.5 39.3 - 78.6\nN - 98.2 84.1 82.9 36.2 - 75.4\nSL-F1 C - 96.5 65.4 59.9 14.5 - 59.1\nN - 91.3 58.1 52.4 13.0 - 53.7\n(XLMR vs mBERT) 3,1 4,0 2,2 4,0\nCanine-c IC% C - 69.39 32.88 36.39 23.28 - 40.48\nN - 69.30 32.57 34.99 23.68 - 40.13\nSL-F1 C - 0.89.31 24.09 23.06 6.93 - 35.85\nN - 87.86 22.3 21.49 7.02 - 34.67\nWikiANN XLMR NER-F1 C 74.9 - 75.2 77.2 67.5 75.9 74.1\nN 71.6 - 70.0 71.1 65.1 69.5 69.1\nmBERT\nNER-F1 C 78.6 - 72.1 79.5 66.2 73.1 73.9\nN 75.4 - 67.1 74.2 63.0 67.3 69.4\n(XLMR vs mBERT) 0,2 2,0 0,2 2,0 2,0\nXNLI XLMR NLI% C 76.4 84.6 78.8 77.9 69.7 72.9 76.7\nN 72.6 80.7 76.4 75.7 70.3 70.6 74.4\nmBERT\nNLI% C 71.1 82.0 74.9 74.2 60.5 62.2 70.8\nN 67.5 77.9 73.1 71.8 61.5 59.1 68.4\n(XLMR vs mBERT) 2,0 2,0 2,0 2,0 2,0 2,0\nTable 10: Per-language results of cross-lingual transfer from English data (average of 5 random seeds) across 4\ndatasets analyzed in §5.1 to compare between existing pre-trained multilingual models.\n1391",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8201035261154175
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.7478399276733398
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6239756345748901
    },
    {
      "name": "Natural language processing",
      "score": 0.6039940714836121
    },
    {
      "name": "Sentence",
      "score": 0.5498538017272949
    },
    {
      "name": "Noisy data",
      "score": 0.4932247996330261
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.4514996111392975
    },
    {
      "name": "Language model",
      "score": 0.4434276521205902
    },
    {
      "name": "Deep neural networks",
      "score": 0.44006478786468506
    },
    {
      "name": "Noise (video)",
      "score": 0.42422935366630554
    },
    {
      "name": "Speech recognition",
      "score": 0.3659305274486542
    },
    {
      "name": "Artificial neural network",
      "score": 0.28948235511779785
    },
    {
      "name": "Image (mathematics)",
      "score": 0.08805373311042786
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98677209",
      "name": "University of Edinburgh",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I57206974",
      "name": "New York University",
      "country": "US"
    }
  ],
  "cited_by": 5
}