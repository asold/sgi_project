{
    "title": "A hybrid input-type recurrent neural network for LVCSR language modeling",
    "url": "https://openalex.org/W2513592917",
    "year": 2016,
    "authors": [
        {
            "id": "https://openalex.org/A334598903",
            "name": "Vataya Chunwijitra",
            "affiliations": [
                "National Electronics and Computer Technology Center",
                "National Science and Technology Development Agency"
            ]
        },
        {
            "id": "https://openalex.org/A2273362510",
            "name": "Ananlada Chotimongkol",
            "affiliations": [
                "National Electronics and Computer Technology Center",
                "National Science and Technology Development Agency"
            ]
        },
        {
            "id": "https://openalex.org/A2312053255",
            "name": "Chai Wutiwiwatchai",
            "affiliations": [
                "National Science and Technology Development Agency",
                "National Electronics and Computer Technology Center"
            ]
        },
        {
            "id": "https://openalex.org/A334598903",
            "name": "Vataya Chunwijitra",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2273362510",
            "name": "Ananlada Chotimongkol",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2312053255",
            "name": "Chai Wutiwiwatchai",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2096257473",
        "https://openalex.org/W2166221226",
        "https://openalex.org/W2023289124",
        "https://openalex.org/W2407106884",
        "https://openalex.org/W2001331936",
        "https://openalex.org/W2009840120",
        "https://openalex.org/W2399344342",
        "https://openalex.org/W2112844297",
        "https://openalex.org/W179875071",
        "https://openalex.org/W2160807445",
        "https://openalex.org/W2160914720",
        "https://openalex.org/W2171928131",
        "https://openalex.org/W2150907703",
        "https://openalex.org/W2026149468",
        "https://openalex.org/W2091981305",
        "https://openalex.org/W2474824677",
        "https://openalex.org/W186939825",
        "https://openalex.org/W1498436455",
        "https://openalex.org/W1524333225",
        "https://openalex.org/W206967138"
    ],
    "abstract": "Substantial amounts of resources are usually required to robustly develop a language model for an open vocabulary speech recognition system as out-of-vocabulary (OOV) words can hurt recognition accuracy. In this work, we applied a hybrid lexicon of word and sub-word units to resolve the problem of OOV words in a resource-efficient way. As sub-lexical units can be combined to form new words, a compact set of hybrid vocabulary can be used while still maintaining a low OOV rate. For Thai, a syllable-based unit called pseudo-morpheme (PM) was chosen as a sub-word unit. To also benefit from different levels of linguistic information embedded in different input types, a hybrid recurrent neural network language model (RNNLM) framework is proposed. An RNNLM can model not only information from multiple-type input units through a hybrid input vector of words and PMs, but can also capture long context history through recurrent connections. Several hybrid input representations were also explored to optimize both recognition accuracy and computational time. The hybrid LM has shown to be both resource-efficient and well-performed on two Thai LVCSR tasks: broadcast news transcription and speech-to-speech translation. The proposed hybrid lexicon can constitute an open vocabulary for Thai LVCSR as it can greatly reduce the OOV rate to less than 1 % while using only 42 % of the vocabulary size of the word-based lexicon. In terms of recognition performance, the best proposed hybrid RNNLM, which uses a mixed word-PM input, obtained 1.54 % relative WER reduction when compared with a conventional word-based RNNLM. In terms of computational time, the best hybrid RNNLM has the lowest training and decoding time among all RNNLMs including the word-based RNNLM. The overall relative reduction on WER of the proposed hybrid RNNLM over a traditional n-gram model is 6.91 %.",
    "full_text": "Chunwijitra et al. EURASIP Journal on Audio, Speech, and Music\nProcessing  (2016) 2016:15 \nDOI 10.1186/s13636-016-0093-x\nRESEARCH Open Access\nA hybrid input-type recurrent neural\nnetwork for LVCSR language modeling\nVataya Chunwijitra*, Ananlada Chotimongkol and Chai Wutiwiwatchai\nAbstract\nSubstantial amounts of resources are usually required to robustly develop a language model for an open vocabulary\nspeech recognition system as out-of-vocabulary (OOV) words can hurt recognition accuracy. In this work, we applied\na hybrid lexicon of word and sub-word units to resolve the problem of OOV words in a resource-efficient way. As\nsub-lexical units can be combined to form new words, a compact set of hybrid vocabulary can be used while still\nmaintaining a low OOV rate. For Thai, a syllable-based unit called pseudo-morpheme (PM) was chosen as a sub-word\nunit. To also benefit from different levels of linguistic information embedded in different input types, a hybrid\nrecurrent neural network language model (RNNLM) framework is proposed. An RNNLM can model not only\ninformation from multiple-type input units through a hybrid input vector of words and PMs, but can also capture long\ncontext history through recurrent connections. Several hybrid input representations were also explored to optimize\nboth recognition accuracy and computational time. The hybrid LM has shown to be both resource-efficient and\nwell-performed on two Thai LVCSR tasks: broadcast news transcription and speech-to-speech translation. The\nproposed hybrid lexicon can constitute an open vocabulary for Thai LVCSR as it can greatly reduce the OOV rate to\nless than 1 % while using only 42 % of the vocabulary size of the word-based lexicon. In terms of recognition\nperformance, the best proposed hybrid RNNLM, which uses a mixed word-PM input, obtained 1.54 % relative WER\nreduction when compared with a conventional word-based RNNLM. In terms of computational time, the best hybrid\nRNNLM has the lowest training and decoding time among all RNNLMs including the word-based RNNLM. The overall\nrelative reduction on WER of the proposed hybrid RNNLM over a traditional n-gram model is 6.91 %.\nKeywords: Recurrent neural network language model, Pseudo-morpheme, Hybrid language model, LVCSR\n1 Introduction\nT h ev o c a b u l a r yo fa n ya c t i v el a n g u a g ec o n t i n u e st og r o w\nas new words, such as person names, place names, and\nnew technical terms, are introduced everyday. This poses\na challenge on building a language model (LM) for a large\nvocabulary continuous speech recognition (LVCSR) sys-\ntem. Substantial amount of resources, e.g., memory and\ncomputational time, for both training and decoding are\nrequiredtohandleanopenvocabularyLM;otherwise,the\nperformance of an LVCSR system could be hurt by a high\nout-of-vocabulary (OOV) rate. A hybrid LM of word and\nsub-word units has been shown to be resource-efficient\nfor an LVSCR system in various languages [1–5] as sub-\nlexical units can be combined to form new words; thus,\n*Correspondence: vataya.chunwijitra@nectec.or.th\nNECTEC, National Science and Technology Development Agency (NSTDA),\n112 Pahonyothin Road, Pathumthani 12120, Thailand\na compact set of vocabulary can be used while still main-\ntainingalowOOVrate.Onanotheraspect,differenttypes\nof lexical units in a hybrid LM provide different levels of\nlinguistic information which can be combined to better\npredict word probability. In [6, 7], characters were com-\nbined with words to add another type of constraint in\nChinesehybridLMs.\nIn this paper, we apply a hybrid LM of word and sub-\nword units to a Thai LVCSR system with two goals in\nmind, to alleviate the problem of OOV words and to\nimproverecognitionaccuracy,bothinaresource-efficient\nway. A suitable sub-lexical unit depends largely on the\ncharacteristicofeachlanguage.InThai,sincethereisnei-\nther inflection nor derivative, a syllable-based unit called\npseudo-morpheme (PM) is used as a sub-lexical unit in\nthe proposed hybrid LM instead of a morpheme-based\nunit as in morphologically rich languages. According to\n© 2016 The Author(s).Open AccessThis article is distributed under the terms of the Creative Commons Attribution 4.0\nInternational License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and\nreproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the\nCreative Commons license, and indicate if changes were made.\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 2 of 12\nThai writing rules, PM is more deterministic when com-\npared with word and has been shown to alleviate a word\nsegmentationproblem[8].\nTo benefit from different levels of linguistic informa-\ntion embedded in word and sub-word units, an approach\nwhich can naturally model multiple-type input units is\nconsidered. In this work, a recurrent neural network\n( R N N )i su s e dt om o d e lah y b r i dw o r d - P ML Ma st h e r e\nisn or es t rict ionont heRNNin pu tt ypes.M or eov er ,RNN\nis chosen from its ability to model longer history not\nonlyn − 1 previous words through recurrent connections\nbetweenitshiddenlayerandinputlayerasdetailedin[9].\nAsaresult,RNNcancapturelongcontextpatternsinstead\nof fixed-length contexts as in a traditional neural network\n(NN)LM[7].\nI no u rp r o p o s e dh y b r i dR N N L M ,ah y b r i dv e c t o ro f\nw o r d sa n dP M si su s e da sa ni n p u tv e c t o r .U n l i k et h e\nhybridNNLMin[7],theoutputfromourhybridRNNLM\ncanc on tainbot hwor dsan dP Msinor dert ohan dleOOV\nwords. In the first-pass decoding, a hybrid n-gram LM\nsimilarto[4]isutilizedtocreateahybridn-bestlistwhere\nOOV words could be recognized as a sequence of PMs.\nA hybrid RNNLM, which can consider information from\ndifferent types of input units together, is then applied in\nthe second-pass to re-score the hybrid n-best list for bet-\nter recognition accuracy. Besides the application of RNN,\nwe also explore several hybrid input representations to\noptimize both recognition accuracy and computational\ntime. In addition to a full-hybrid RNNLM which takes\nboth a word sequence and a PM sequence as its input,\ntwo variations of reduced-hybrid RNNLMs are proposed\ntodecreasecomputationalcomplexity.Byusingtwotypes\nof units, the vocabulary size of the full-hybrid RNNLM\ncould be twice the size of the word-based RNNLM. In\nthefirstreduced-hybridRNNLMvariation,thesizeofthe\nhybridvocabularyisreducedtobeequaltothesizeofthe\nword-based RNNLM vocabulary by including only fre-\nquent words and PMs. In the other variation, a mix of\nwordandPMsequenceisusedasaninputinstead.\nThis paper is organized as follows: Section 2 explains\nthe characteristics of Thai text together with a pseudo-\nmorpheme (PM), a sub-lexical unit in Thai. Section 3\ndescribes our proposed hybrid RNNLM framework for\ncombining different input unit types. Section 4 describes\nthe recognition process of the hybrid RNNLM. Recogni-\ntion results on two Thai LVCSR tasks are then discussed\nin Section 5. We finally conclude our work and discuss\nfuturedirectionsinSection6.\n2 Thai lexical\n2.1 Lexical structure and vocabulary growth\nThai is a non-segmented script language, i.e., there is no\nboundary marker between words. Furthermore, there is\nno capital letter to indicate the beginning of a sentence\nor a proper noun. The definition of word unit is often\nambiguous due to the presence of compound words.\nThese characteristics become a challenge when process-\ningThaitext.\nThe vocabulary growth of Thai text is illustrated by a\ntype-token curve in Fig. 1. This curve is plotted from\n5 million words randomly selected from three text and\nspeech corpora: BEST [10], LOTUS-BN [11], and HIT-\nBTEC [12]. To balance the amount of data from differ-\nent corpora and domains, 500K words are selected from\neach of the eight genres in BEST and 500 K words each\nare selected from LOTUS-BN and HIT-BTEC. The total\nbecomes 5 millions words from ten different genres. We\ncanseefromthetype-tokencurvethatevenwith5million\nwords, the vocabulary continues to grow. New names are\nthe main cause of the vocabulary growth. In LOTUS-BN,\nwhere named entities were annotated with specific tags,\nthe type-tokenratio for named-entity alone is0.357while\nthetype-tokenratioforallwordsis0.044.Newwordsalso\narise from transliterated words and abbreviations. Since\nmany named-entities are a compound word, this type of\nOOV word should be able to be modeled by sub-lexical\nunits.\n2.2 Pseudo-morpheme\nT h ed e s i g no fas u b - l e x i c a lu n i td e p e n d sl a r g e l yo nt h e\ncharacteristics of each language. In Thai, there is neither\ninflection nor derivative; hence, another type of sub-\nlexical unit should be used instead of morpheme. As a\nletter in Thai is a phonogram which roughly represents a\nphoneme or combination of phonemes, Thai word could\nbesegmentedintoasequenceofsyllable-likeunits.\nA basic Thai textual syllable composes of four com-\nponents, represented in the form of{Ci,V,C f,T},w h e r e\nCi,V,C f and T denote an initial consonant, a vowel, a\nfinal consonant, and a tone, respectively, as shown in\nFig.2.Thecorrespondingphoneme(orphonemes)ofeach\ncomponentinIPAisalsoillustrated.\nThe word /bâ:n - phrá:w/, which is a village name, in\nFig. 2 consists of two syllables: /bâ:n/ and /phrá:w/. The\nFig. 1Type-token. Type-token curve of Thai text\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 3 of 12\nFig. 2Thai-syllable. An example of Thai word and sub-word units\nfirstsyllable/bâ:n/hasabasicsyllablepatternwithallfour\ncomponents{b,a:,n,ˆ}.Sometextualsyllablesmayhave\nmultiple initial consonants, vowel forms or final conso-\nnantswhilesomesyllablesmayhavecomponentsomitted.\nThe second syllable /phrá:w/ has two initial consonants;\n/ph/ and /r/. Nevertheless, patterns of syllables can be\ndefined and are known to be finite. Thai writing rules can\nbe used to identify syllables and their components in a\ngiven text.\nApseudo-morpheme(PM)definedasasyllable-likeunit\nin a written form is used as a sub-lexical unit for Thai [8].\nThe example word in Fig. 2 consists of two PMs /bâ:n/\nand/phrá:w/.AccordingtoThaiwritingrules,PMismore\ndeterministicwhencomparedwithword.Givenawordor\na string of text, PMs can be determined quite accurately\nwith an automatic segmentation tool [13]. More exam-\nples of words and theirs corresponding PMs are given\nin Fig. 3 where PMs are separated by “|”. A PM must\nnot be confused with a phonetic syllable in word pro-\nnunciation as a PM may correspond to multiple phonetic\nsyllables. For example the first word /júp - pháP | râ:t/\nin Fig. 3, its first PM corresponds to two phonetic syl-\nlables /júp - pháP/. Phonetic syllables are separated by\n‘-’ in the third column. Words in Fig. 3 are examples of\nOOV words found in our test sets. The first and sec-\nond words are proper names while the last word is a\nloanwordfromtheword“pollresult”.Named-entitiesand\nloan words are known to be the main causes of OOV.\nBy modeling an OOV word with a sequence of PMs,\nthese OOV words could be correctly recognized by our\nhybrid LM.\n3 Hybrid recurrent neural network language\nmodel\nThe purpose of a language model (LM) employed in an\nASR system is to provide the probability of a word given\nthe history of its preceding words. For an LM to effi-\nciently predict the next word, it is well-known that long\nword history should be utilized to capture long context\npatterns, syntactic and semantic dependencies. A recur-\nrent neural network (RNN) [9] can learn an effective\nrepresentation of history from the training data through\nrecurrent connections between a hidden layer and an\ninput layer as shown in Fig. 4. With a recurrent con-\nnection through s(t − 1), the hidden layer or context\nlayer s of RNNLM can capture longer word history than\nFig. 3Thai-PMs. Examples of words, their corresponding PMs, and their pronunciations\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 4 of 12\nFig. 4Hybrid-RNNLM. Hybrid RNNLM architecture\nfixed-length context in an NNLM or an n-gram LM. To\nbe able to model multiple-type input units in the pro-\nposed hybrid RNNLM, some modifications are made to\na conventional RNNLM framework. The model struc-\nture of the hybrid RNNLM is illustrated in Section 3.1.\nThe input vector of our proposed hybrid RNNLM is a\nconcatenated vector of word and PM vectors. A hybrid\ninput representation and its variations are described in\nSection3.2.\n3.1 A model framework\nThe architecture of the proposed RNNLM is demon-\nstrated in Fig. 4. The network is represented by three\nlayers (input layer, hidden layer and output layer) and\ncorresponding weight matrices (matrix U between the\ninput layer and the hidden layer, and matrices V and\nZ between the hidden layer and the output layer). In\nthis work, we employ a standard class-based RNNLM\n[14], where word classes are introduced in the output\nlayer to reduce the computational bottleneck between\nthe hidden layer and the output layer. Each word is\nassigned to exactly one class based on its frequency in\ntraining data. A class can be considered as a frequency\nbin.\nUnlike a conventional word-based RNNLM, the input\nvector x(t) of the hybrid RNNLM is formed by concate-\nnating a hybrid vector h(t), instead of a word vector w(t),\nwith a vector s(t − 1) as represented by the following\nequations:\nx(t) =\n[\nh(t)T s(t − 1)T\n]T\n(1)\nh(t) =\n[\nw(t)T p(t)T\n]T\n,( 2 )\nwhere h(t) is a concatenated vector of a word vector w(t)\nand a PM vector p(t),a n ds(t − 1) is the output from the\nhidden layer at timet − 1. By using the hybrid vector,\nthehybridRNNLMcansimultaneouslyintegratemultiple\ninputtypesinitsinputlayer.\nThe hidden layer compresses the information from two\nsources,h(t) ands(t−1) andcomputesanewcontextrep-\nresentations(t) whichwillbeaninputofthenextiteration\nthroughrecurrentconnections.Thehiddenlayeremploys\nasigmoidactivationfunction:\nsj(t) = f\n(∑\ni\nxi(t)uji\n)\n, f (a) = 1\n1+ e−a ,( 3 )\nwhereuji isanelementinmatrix U,i isanindextohybrid\nunitsinthetheinputvectorx (t) andj isanindextohidden\nneuronsinthehiddenlayerss (t).\nIn a class-based RNNLM, the output probability is fac-\ntorized into two parts, the first part is the probability\ndistribution over all classes, c(t), and the second part is\nthe probability distribution over all hybrid units, b(t),i n\na single class, the one that contains the predicted hybrid\nunit:\ncm(t) = g\n⎛\n⎝∑\nj\nsj(t)zmj\n⎞\n⎠ (4)\nbk(t) = g\n⎛\n⎝∑\nj\nsj(t)vkj\n⎞\n⎠,( 5 )\nwhere zmj and vkj are an element in matrix Z and V,\nrespectively. To ensure that all output values are between\n0and1,andtheirsummationisequalto1,theoutputlayer\nemploysasoftmaxactivationfunction:\ng(aq) = eaq\n∑\np eap (6)\nAftertheprobabilitydistributionoverallclassesandthe\nprobabilitydistributionofhybridunitswithintheclassare\nobtained,the probability of the predicted hybrid unithi is\nthen computed as\nP(hi|history) = P(hi|ci,s(t)) P(ci|s(t)),( 7 )\nwherei isanindexofthepredictedhybridunit hi andci is\nitsclass.\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 5 of 12\n3.2 Input features for model training\nIn this section, we discuss a representation of RNNLM\ni n p u tf e a t u r e sa n dav o c a b u l a ryl i s t .A sah y b r i dR N N L M\ncantaketwotypesofinputunits,thetrainingtextconsists\nof two sets: a word sequence set and a PM sequence set.\nBoth data sets share the same content, but have different\nsegmentations. Figure 5 illustrates various segmentation\ntypes of the same text utterance /ph¯on - th¯o: - sùP -w í t\n-t h¯a:n - ráP - rû:p/. The same text is segmented into a\nsequenc eofwor dsin(a)andasequenc eofP Msin(b).\nAfter specifying training data, a vocabulary list is con-\nstructed. Typically, not every word found in the training\ndata is included in the vocabulary list as low frequency\nwordscouldbetypos.Inpractice,onlythetop- N mostfre-\nquentwordsareincluded.InahybridRNNLM,eachinput\ntype has its own set of vocabulary. LetN be the size of\nwordvocabularyand M bethesizeofPMvocabulary.The\nvocabulary size of a hybrid word-PM RNNLM isN + M\nwhich could be twice the size of the word-based RNNLM\nas shown in Fig. 6a. The size of the vector h(t) in Eq. 1 is\nequalthevocabularysize.ThehybridRNNLMwhichuses\na full vocabulary of both word and PM similar to [7], or a\nfull-hybrid RNNLM, may suffer from the cost of compu-\ntationalcomplexity.Moreover,asourhybridRNNLMalso\nhas a hybrid output, the output layer b(t) has the same\ndimensionality as h(t). As the output layer contains one\nneuron for each word or PM in the vocabulary, it may be\ninfeasibletotrainthemodelwithlargevocabularysize.\nTo decrease computational complexity of the full-\nhybrid RNNLM (H-F), two variations ofreduced-hybrid\nRNNLMs are proposed. In the first variation (H-R1), the\nvocabulary size is reduced to be equal to the size of the\nword-based RNNLM vocabulary (N) by including only\nfrequent words and PMs as shown in Fig. 6a. LetN’ and\nM’ be the size of the top-N’ most frequent words and the\ntop-M’ most frequent PMs, respectively,N′ + M′ = N in\nH-R1. In the second variation (H-R2), a hybrid word-PM\nsequence is used as an input instead of two separate word\nandPMsequencesasshowninFig.6b.Itsvocabularysize\nisalsolimitedto N.ThedifferencefromH-R1isthecom-\nposition of the vocabulary. Since the input text of H-R2 is\nam ixo fw o r dsa n dP M s,t h et o p -N” most frequent words\nare determined first and kept as word units in the vocab-\nulary. Next, the less frequent words are segmented into\nPMs. The top-M” most frequent PMs from this list are\nthen added into the vocabulary whereN′′ + M′′ = N.\nFigure 5c illustrates a hybrid sequence where the first\nword /ph¯on - th¯o:/ (lieutenant general), which is a fre-\nquent word, is kept as a word while the second and third\nword /sùP - wít/ (first name) and /th¯a:n - ráP -r ˆu:p/ (last\nname), which are infrequent words, are segmented into\na set of PMs { /sùP/, /wít/ } and { /th¯a:n - ráP/, /rˆu:p/ },\nrespectively. IfN′ = N′′ then word units in H-R1 and H-\nR2 are the same. However, PM units are different as the\nlist of PMs and their frequency in H-R2 come from the\nless frequent words not all words in the training data as\nin H-R1. In both H-R1 and H-R2, the size of the vector\nh(t) is decreased. The reduction in computational time\ncomparing with the full-hybrid RNNLM is discussed in\nSection5.5.\n4 Lattice decoding and re-scoring\nTo perform automatic speech recognition with the pro-\nposed hybrid RNNLM, we employ a two-pass decoding\nscheme. In the first-pass decoding, a hybrid n-gram LM\nsimilarto[4]isutilizedtocreateahybridn-bestlistwhere\nOOV words could be recognized as a sequence of PMs.\nIn the second-pass, a hybrid RNNLM which can consider\ndifferent levels of linguistic information from different\ntypes of input units, i.e., word and PM, together is then\nappliedtore-scorethehybridn-bestlisttoimproverecog-\nnition accuracy. The two recognition steps are discussed\nindetailbelow.\n4.1 First-pass decoding with a hybrid n-gram LM\nConventionally, in the first pass, a decoder uses an acous-\ntic model and a word-based n-gram language model to\ngenerate multiple recognition hypotheses which can be\n(a)\n(b)\n(c)\nFig. 5Thai-segmentation. An illustration of different unit segmentations (a)w o r d ,(b) PM, and (c)h y b r i d\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 6 of 12\n(a)\n(b)\nFig. 6Input-RNNLM. Input feature representations of 3 hybrid RNNLM variations (a) hybrid input representation for H-F and H-R1, and (b)h y b r i d\ninput representation for H-R2\ncompactlyrepresentedinadatastructurecalledwordlat-\ntice asillustrated inFig. 7a.In this paper,a hybridn-gram\nLM is used instead in order to handle OOV words. To\ntrainahybridn-gramLM,ahybridsequenceofwordsand\nPMs similar to the one in Fig. 5c is used as LM training\ndata. The vocabulary of our hybrid LM consists of fre-\nquent words and PMs from less frequent words. Words\nthat occur more frequently than a threshold are kept as\nword units in the vocabulary while words that occur less\noften are segmented into PMs. All unique PMs are then\nadded to the hybrid vocabulary. We note that some PMs\ncouldbesimilartoshortwordsinthevocabulary.Toavoid\nredundancy,thesePMsareexcluded.\nIn Fig. 7a, the utterance /ph¯on - th¯o: - sùP -wí t-t h¯a:n -\nráP -rû:p/cannotberecognizedbytheword-basedlattice\nas the word /th¯a:n - ráP - rû:p/ is an OOV word. When a\n(a)\n(b)\nFig. 7Lattice. Word and hybrid lattices in the first-pass decoding (a)w o r dl a t t i c e ,a n d(b)h y b r i dw o r d - P Ml a t t i c e\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 7 of 12\nhybrid n-gram LM is used to generate a hybrid lattice as\nillustrated in Fig. 7b, the OOV word /th¯a:n - ráP -r û : p /\ncan be recognized as a sequence of PMs /th¯a:n - ráP/a n d\n/rû:p/.\n4.2 Second-pass re-scoring with an RNNLM\nIn multi-pass decoding, an LM trained with higher order\nknowledgesourcesisusedtore-scorethelatticegenerated\nby an LM trained with simpler or lower order knowl-\nedge sources from the preceding pass. In this work, an\nRNNLM which is considered more complex is applied\nto re-score a hybrid lattice generated by the hybrid n-\ngram LM described in the previous section. Since the\nhybrid RNNLMs described in Section 3.2 use different\ninput feature representations, the lattice generated from\nthe first-pass decoding has to be converted accordingly.\nAn n-best hypothesis list is first extracted from the lat-\ntice,thenconvertedintoasuitablerepresentationforeach\nhybridRNNLM as shown in Fig. 8. A conventional n-best\nlist extracted from a word-based lattice is also presented\nin Fig. 8a for comparison. For the full-hybrid RNNLM\nwhich takes both a word sequence and a PM sequence\nas its input, a PM sequence is obtained by splitting all\nwordsinthehypothesesintoPMsasshowninFig.8b.The\nacousticscoreandLMscoreofeachPMarecalculatedby\na uniform distribution of the corresponding word scores.\nWhen the hypotheses are extracted from a hybrid lat-\ntice, a word sequence may contain some PMs similar to\na hybrid sequence in Fig. 8c. The reduced-hybrid H-R1\nwhich takes the same input representation as H-F but use\na reduced vocabulary set also uses the word-PM n-best\nlist shown in Fig. 8b. For the reduced-hybrid H-R2 where\nfrequent words are represented as word units while infre-\nquent words are represented as PM units, a hybrid n-best\nlist illustrated in Fig. 8c is used in the second-pass re-\nscoring.Inthiscase,itcanbeseenthatonlyaninfrequent\nw o r d/ n â :-t ì t-t¯a:m/ is segmented to PMs as /nâ:/, /tìt/\nand/t ¯a:m/.\nIn the second-pass re-scoring, a new LM score is\nobtained by interpolating the probability from RNNLM\nwith the first-pass n-gram LM score. Then, the hybrid n-\nbest list with the new LM scores is reconstructed into\na hybrid lattice. Finally, the new best hypothesis is cho-\nsen based on the re-scored score. For instance, after\nre-scoring with the hybrid RNNLM (H-R2), the 2-best\nhypothesis in Fig. 8c, which is the correct one, becomes\nthe 1-best hypothesis and is chosen as a recognition\nresult.\n(a)\n(b)\n(c)\nFig. 8N-best. N-best list representations in the second-pass re-scoring of different types (a) conventional N-best list, (b) word-PM N-best list, and\n(c)h y b r i dN - b e s tl i s t\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 8 of 12\n5 Experiments\nWe evaluated the performance of the proposed hybrid\nRNNLMs on both recognition accuracy and computa-\ntional efficiency. Training and test data along with the\nexperimental conditions are described in Section 5.1.\nRecognition accuracy of the first-pass decoding, the\nsecond-pass re-scoring together with the experimental\nanalysis are reported in Sections 5.2, 5.3, and 5.4, respec-\ntively, while the model run-time efficiency is discussed in\nSection5.5.\n5.1 Experimental conditions\nWe evaluated our approach with two different recog-\nnition tasks: broadcast news transcription and speech-\nto-speech translation. Acoustic model training data of\nour speech recognizer composes of 224 hours of speech\nfrom LOTUS [15], LOTUS-BN [11], and VoiceTra4U-\nM. VoiceTra4U-M is a speech translation application\nin sport and travel domains developed under the\nUniversal Speech Translation Advanced Research (U-\nSTAR) project (http://www.ustar-consortium.com/qws/\nslot/u50227/index.html). Twenty-two hours of speech\nwere recorded on mobile devices in real environment.\nWe used the Kaldi Speech Recognition Toolkit [16] to\nfirst train a conventional GMM-based acoustic model.\nWe then applied the minimum phone error (MPE) dis-\ncriminative training technique described in [17]. Each\nframe of speech data was converted into a sequence of\n39 dimensional feature vectors of 12 MFCCs augmented\nwithlogenergy,theirfirstandsecondderivatives.Weused\na2 5m i l l i s e c o n df r a m el e n g t hw i t h1 0m i l l i s e c o n dw i n -\ndow shift each time. Features from a context window of\n3 frames to the left and right were also included. A linear\ndiscriminateanalysis(LDA)wasalsoappliedtothefeature\nspacetoreducefeaturedimensionsto40.\nLM training data contain 9.4M words from three cor-\npora, BEST [10], LOTUS-BN [11], and HIT-BTEC [12].\nAs these corpora cover variety of domains, e.g. law, news,\nandtravel,withthevocabularysizeof121K,theyaregood\nresources for training a hybrid LM for an open-domain\nLVCSR system.\nThe test set of the broadcast news transcription task\n(BN)consistsof3140utterancesoftwomalespeakersand\nonefemalespeakertakenfromtheLOTUS-BNevaluation\nset. For the speech-to-speech translation task (VT), the\ntest set consists of 1916 utterances of VoiceTra4U-M data\nnotincludedinthetrainingset.\n5.2 Recognition performance of the first-pass decoding\nThree 3-gram LMs were experimented to investigate the\neffect of different lexical units on the first-pass decoding\nperformance of a Thai LVCSR system. A word-based LM\n(f-W) is a baseline LM which includes all word units in\nthe training data in its lexicon. A PM-based LM (f-PM)\nuses PM as a lexicon unit instead of word. The training\ndata were segmented into PMs and then used to train an\nn-gram model in the same way as a word-based LM. All\nPMunitswereincludedinthef-PMlexicon.AhybridLM\n(f-H) uses a hybrid lexicon which includes only the words\nthat occur more than three times in the training data and\nthe PMs from less frequent words. The amounts of word\nand PM units used in each LM are shown in the second\nand third row, respectively, in Table 1. All 3-gram LMs\nwere trained using Kaldi LM toolkit [16] with modified\nKneser-Neysmoothing.\nThe performance of the 3-gram LMs in the first-pass\ndecodingismeasuredintermsofaccuracyandOOVrate.\nSince mixed types of units are used in the LMs, we report\nboth PM Error Rate (PER)and Word Error Rate (WER)\nin all experiments. To recover word units from a hybrid\noutput, we concatenate multiple-type output units into\na string of text and then re-segment it into words using\na word segmentation tool. OOV rate (OOV) is used to\nmeasure the coverage of a given lexicon over a test set.\nOOV reported in this section is an effective OOV rate\nwhichaccountsforthepercentageofwordsthatarenotin\nthe full-word lexicon and cannot be constructed from the\nPMs.\nFrom the results shown in Table 1, we can clearly see\nthatthehybridLM,f-H,cangreatlyreducetheOOVrates\nwhen compared with f-W in both test sets by using only\n42 % of the vocabulary size (51 K vs. 121 K). In terms of\nPER and WER, among the 3 LMs, f-H achieved the best\nresults on both test sets. On average, the hybrid LM can\nreduce PER by 0.21 % absolute and 1.02 % relative while\nreduce WER by 0.16 % absolute and 0.69 % relative when\ncompared with the word-based LM, f-W. The PM-based,\nf-PM, has the lowest OOV rates on both test sets. How-\never, it produced the highest error rates, both PER and\nWER. From the result, we can say that PM units are too\nsmall to capture context history and language dependen-\ncies especially with the fixed context length in an n-gram\nTable 1Recognition results of first-pass decoding\nTasks\nLMs f-W f-PM f-H\n#Word 121 K 0 K 30 K\n#PM 0 K 25 K 21 K\nBN PER (%) 20.64 23.76 20.54\nWER (%) 24.05 27.30 24.01\nOOV (%) 2.08 0.41 0.54\nVT PER (%) 19.71 20.99 19.40\nWER (%) 22.56 23.94 22.28\nOOV (%) 0.85 0.11 0.15\nAVG PER (%) 20.18 22.38 19.97\nWER (%) 23.31 25.62 23.15\nOOV (%) 1.96 0.39 0.51\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 9 of 12\nmodel. This experiment shows that the hybrid lexicon\nof words and PMs is a resource-efficient representation\nthat not only can greatly reduces the OOV rate but also\nimprovesrecognitionaccuracy.Examplesofcorrectlyrec-\nognizedOOVwords,suchaspropernameandloanword,\nareshowninFig.3.\n5.3 Recognition performance of the second-pass\nre-scoring\nFivevariationsofRNNLMswereinvestigated:word-based\n(W), PM-based (PM), full-hybrid (H-F), and two vari-\nations of reduced-hybrid (H-R1 and H-R2). The PM\nRNNLM was trained in the same fashion as the con-\nventional word RNNLM except that the input unit is\nPM instead of word. In all experiments, the class-based\nRNNLMs were trained by the RNNLM toolkit [18] with\nfive iterations of Back-propagation through time (BPTT)\n[19],400hiddenneurons,and400classes.Inthetraining,\n1 % or 10K words were excluded from the training set for\nvalidationtesting.Thesizeofthen-bestlistobtainedfrom\nthe first-pass decoding is set to be at most 100 hypothe-\nses for each utterance. In the second-pass re-scoring,\nRNNLMs were interpolated with the 3-gram LM using a\nweightof0.25forRNNLMS.\nWe first examined the appropriate hybrid vocabulary\nfor H-R1 and H-R2, namely the number of word units\n(N′ and N′′) and the number of PM units ( M′ and\nM′′). In the first-pass decoding experiment discussed\nin Section 5.2, all PMs from less frequent words were\nincluded in the hybrid 3-gram model. Since an RNNLM\nrequires much larger training resources, only frequent\nPMs should be included in the vocabulary. Three hybrid\nlexicons with different amounts of words and PMs were\nexperimented. For fair comparison, the sizes of the lex-\ni c o n sa r ek e p tt h es a m ea t3 5Ku n i t s .T h eh y b r i dl e x -\nicons include words that occur more than three, four,\nand seven times and PMs that occur more than five,\nthree, and two times, respectively. The amounts of cor-\nresponding words and PMs in each hybrid lexicon are\nshown in the second and third rows in Table 2. The\neffectofdifferentword/PMratiosinthehybridlexiconsin\nTable 2Recognition performance with various hybrid lexicons\nTasks\nLM H-R1 H-R2\n#Word 30 K 25 K 20 K 30 K 25 K 20 K\n# P M 5K 1 0K 1 5K 5K 1 0K 1 5K\nBN PER (%) 18.84 18.85 18.89 18.84 18.81 18.86\nWER (%) 22.16 22.19 22.24 22.15 22.13 22.18\nVT PER (%) 18.79 18.86 18.76 18.41 18.41 18.56\nWER (%) 21.57 21.66 21.57 21.27 21.27 21.47\nAVG. PER (%) 18.82 18.86 18.83 18.63 18.61 18.71\nWER (%) 21.87 21.93 21.91 21.71 21.70 21.83\nterms of PER and WER in the second-pass re-scoring are\nreported.\nForH-R1,onaverage,thebestresultwasobtainedfrom\nthe vocabulary which contains 30 K words and 5 K PMs.\nFor H-R2, the best result was obtained from the vocabu-\nlary which contains 25 K words and 10 K PMs. We note\nt h a tb o t hP E Ra n dW E Rd on o tc h a n g em u c hw i t hd i f -\nferent word/PM ratios. Nevertheless, we chose the ratio\nthat yields the best recognition performance for the next\nexperiment. For comparison, the vocabulary size of the\nword-based RNNLM (N) is set to 35 K while the vocab-\nulary size of the PM-based RNNLM (M)i ss e tt o2 5K ,\ntheamountofallPMunits.ForH-F,thevocabularysizeis\nN + M whichis60KasdetailedinSection3.2.\nTable 3 shows recognition results of the second-pass\nre-scoring using a hybrid 4-gram LM (s-H) and five vari-\nations of RNNLMs. As expected, all the second-pass\nre-scoring results were better than the first-pass result\nwhich used a hybrid 3-gram LM (f-H). When compared\nRNNLMswithahybrid4-gramLMinthesecond-passre-\nscoring, all RNNLMs obtained better recognition results\nastheycancapturelongercontexthistorythanthe4-gram\nmodel. Among various RNNLMs, H-F achieved the low-\nest error rate in the BN test set while H-R2 gave the best\nrecognition result in the VT test set and also on average.\nH-R2 is preferable as it is more computational efficient as\ndiscussed in Section 5.5. When compared with a conven-\ntionalword-basedRNNLM(W),thebestproposedhybrid\nRNNLM, H-R2, obtained 2.41 % relative PER reduction\nand 1.54 % relative WER reduction on average. The per-\nformance improvements of the proposed hybrid input\nRNNLMoverthetraditionalword-basedRNNLMaresta-\ntistically significant at the 0.01 (1 %) level for PER and at\nt he0.05(5%)leve lf orWER.\nFrom result analysis, we found that the word-based\nRNNLM sometimes made mistake by choosing a long\nword or a compound word when its can be acoustically\nconfused with correct words in an input utterance. A\nhybrid word-PM RNNLM, on the other hand, has more\nTable 3Recognition performance of second-pass re-scoring\nTasks\nLM 4gr RNNLMs\ns-H W PM H-F H-R1 H-R2\n# W o r d 3 0K 3 5K 0K 3 5K 3 0K 2 5K\n# P M 2 1K 0K 2 5K 2 5K 5K 1 0K\nBN PER (%) 19.60 19.11 19.12 18.73 18.84 18.81\nWER (%) 22.92 22.22 22.23 22.05 22.16 22.13\nVT PER (%) 19.02 19.02 19.26 18.89 18.79 18.41\nWER (%) 21.75 21.85 22.17 21.69 21.57 21.27\nAVG. PER (%) 19.31 19.07 19.19 18.81 18.82 18.61\nWER (%) 22.34 22.04 22.20 21.87 21.87 21.70\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 10 of 12\nTable 4Positive and negative effects on recognition results\nTasks LM RNNLMs\nW H-R2\nBN COOV (%) - 21.38\nMIV (%) 21.87 21.84\nVT COOV (%) - 35.14\nMIV (%) 21.62 21.03\nAVG. COOV (%) - 21.81\nMIV (%) 21.85 21.77\nflexible unit choices as it can output both word and sub-\nwordunits,andthuscanavoidthiskindofmistakes.With\nthe use of RNN for combining information from different\ntypes of units, 6.81 % relative improvement on PER and\n6.26%onWERcanbeobtainedcomparedwiththehybrid\nn-gramLM(f-H).\n5.4 Experimental analysis\nTofurtheranalyzetherecognitionimprovementachieved\nb yt h ep r o p o s e dh y b r i df r a m e w o r k ,w ea l s or e p o r t e d\nCOOV (correctlyrecognizedOOVs)and MIV (misrecog-\nnizedin-vocabularywords)inTable4.Thebestproposed\nhybrid RNNLM (H-R2), reported in Section 5.3, is com-\nparedagainsttheconventionalword-basedRNNLM(W).\nIn this experiment, a word is considered an OOV word if\nit is not found in the 121K full-vocabulary of the training\ndata. The OOV rates of the BN task and the VT task are\n2.08 and 0.85 %, respectively, while the average OOV rate\nis1.96%asshowninTable1.TheCOOVsinTable4show\nthattheproposedhybridframeworkofwordandPMunits\ncan alleviate the problem of OOV words by correctly rec-\nognized 21.38 % of them in the BN task and 35.14 %\nof them in the VT task while the traditional word-based\nRNNLM cannot. We also show examples of recognition\nresults of the word-based system against the hybrid sys-\ntem in Fig. 9. Words and PMs are separated by “-” and “|”,\nrespectively. Words in the Fig. 9 are OOV words found in\nthe test sets. These words could correctly be recognized\nby the proposed hybrid framework, but could not be rec-\nognized by the word-based RNNLM framework and thus\nintroduce recognition errors. The first and second rows\narepersonnameswhilethelastrowisaThaitransliterated\nword of the word “alliance”. Named-entities and translit-\nerated words are known to be the main causes of OOV.\nBymodelinganOOVwordwithasequenceofPMs,these\nOOV words could be correctly recognized by our hybrid\nRNNLM.\nWhen consider in-vocabulary words, we found that the\nMIV of our proposed hybrid RNNLM is not higher than\nthat of the word-based one, thus there is no negative\neffect due to lexical confusion from including PMs in\nthe language model. Furthermore, the misrecognition of\nin-vocabulary words was reduced by 0.35 % relatively in\nthehybridframework(H-R2)overtheword-basedframe-\nwork(W).Theimprovementinin-vocabularyrecognition\ncould come from different levels of linguistic information\nembedded in multiple-type input units which can be uti-\nlized by the proposed hybrid RNNLM framework. From\nthe analysis of results shown in Table 4, we could say that\ntheimprovementinWERandPERofthehybridRNNLM\n(H-R2) over the word-based RNNLM (W) comes from\nbothbetterCOOVandMIV.\n5.5 Computational efficiency\nInthissection,weanalyzedthecomputationaltimeofthe\nRNNLMs. Table 5 shows the amount of training time and\nthe second-pass decoding time on a PC with 98 GB of\nmemoryand24cores2.67GHzCPU.\nSinceH-FandH-R1usedbothwordandPMsequences\nas an input when trained the models, they used much\nlonger training time than other types of RNNLMs. Their\ndecodingtimesarealsoalmosttwicewhencomparedwith\nother models. H-R2 which takes a single hybrid sequence\nof words and PMs as its input has the lowest training and\ndecodingtimeamongallRNNLMvariations.Whencom-\npared among three hybrid RNNLM variations, both the\ntraininganddecodingtimecanbesavedbymorethanhalf\nin H-R2 without affecting recognition accuracy. When\ncompared with the 4-gram LM, which has about 6 min\ntrainingtimeand17mindecodingtime,allRNNLMshave\nmuch longer training time but have faster decoding time\nwhile also achieve better recognition results. The 4-gram\nLM has longer decoding time due to its larger vocabulary\nsize.\nFig. 9Recog Results. Recognized results samples of OOVs from word-based and hybrid RNNLM\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 11 of 12\nTable 5Training and decoding time (h=hour, m=minute,\ns=second)\nRNNLMs W PM H-F H-R1 H-R2\n# W o r d 3 5K 0K 3 5K 3 0K 2 5K\n#PM 0 K 25 K 25 K 5 K 10 K\nTraining 36 h 35 m 38 h 13 m 67 h 19 m 63 h 12 m 28 h 20 m\nDecoding 08 m 25 s 10 m 22 s 17 m 47 s 15 m 48 s 08 m 15 s\n6C o n c l u s i o n s\nWe proposed a hybrid RNNLM framework for model-\ningmultiple-typeinputunits,namelywordandsub-word.\nA hybrid lexicon was utilized to alleviate the problem of\nOOVwordsandtoimproverecognitionaccuracythrough\nadditionallinguisticinformationfrommultipleunittypes.\nPseudo-morpheme (PM), a syllable-based unit, was cho-\nsen as an appropriate sub-word unit for Thai. A concate-\nnated vector of word and PM vectors, or a hybrid vector,\nis used as an input vector instead of a word vector in\nthe proposed hybrid RNNLM framework. Several hybrid\ninputrepresentationswerealsoexploredtooptimizeboth\nrecognitionaccuracyandcomputationaltime.\nThe hybrid LM has shown to be both resource-efficient\nand well-performed on two Thai LVCSR tasks: broadcast\nnewstranscriptionandspeech-to-speechtranslation.The\nproposed hybrid lexicon can constitute an open vocab-\nulary for Thai LVCSR as it can greatly reduce the OOV\nrate to less than 1 % while using only 42 % of the vocab-\nulary size of the word-based lexicon. In terms of recog-\nnition performance, the best proposed hybrid RNNLM,\na reduced-hybrid which uses a mixed input sequence of\nwords and PMs, obtained 1.54 % relative WER reduction\nwhencomparedwithaconventionalword-basedRNNLM\nas hybrid input types provide more flexible unit choices\nfor LM re-scoring. The improvement obtained with the\nproposed hybrid input RNNLM is statistically significant\nat the 0.05level.Furthermore, the hybridRNNLM frame-\nwork has shown to be able to alleviate the problem of\nOOVwordsbycorrectlyrecognize21.81%ofOOVwords\ncompared to the word-based system on the evaluation\ncorpora. When only frequent words and PMs from less\nfrequent words are used, the size of the input vector\nof the reduced-hybrid RNNLM can be reduced by half\nwhencomparedwiththefull-hybridRNNLMwhichtakes\ntwo input streams, both word and PM sequences. The\nhybrid input representation can considerably save both\ntraining and decoding time while still achieving slightly\nbetter recognition accuracy. In the future, we plan to\napply more complex lattice re-scoring algorithms, such\na st h eo n ed e s c r i b e di n[ 2 0 ] ,t ot h eh y b r i dR N N L Mt o\nfurther improve recognition performance. A cache-based\nRNNLM which can be used straightaway in the first-pass\ndecoding[21]willalsobeconsidered.\nCompeting interests\nThe authors declare that they have no competing interests.\nReceived: 2 February 2016 Accepted: 19 July 2016\nReferences\n1. A El-Desoky, C Gollan, D Rybach, R Schlüter, H Ney, inINTERSPEECH.\nInvestigating the use of morphological decomposition and diacritization\nfor improving Arabic LVCSR, (2009), pp. 2679–2682. https://scholar.\ngoogle.co.th/scholar_lookup?title=Investigating+the+use+of+\nmorphological+decomposition+and+diacritization+for+improving+\nArabic+LVCSR&btnG=.\n2. MAB Shaik, AE-D Mousa, R Schlüter, H Ney, inINTERSPEECH.H y b r i d\nlanguage models using mixed types of sub-lexical units for open\nvocabulary German LVCSR, (2011), pp. 1441–1444. https://scholar.google.\ncom/scholar_lookup?title=Hybrid+language+models+using+mixed+\ntypes+of+sublexical+units+for+open+vocabulary+German+LVCSR&\nbtnG=&hl=th&as_sdt=0%2C5.\n3. M Rondeau, R Rose, inInformation Science, Signal Processing and Their\nApplications (ISSPA), 2012 11th International Conference On. Developing a\nhybrid language model for open vocabulary automatic speech\nrecognition in a lecture speech task (IEEE, 2012), pp. 114–119. https://\nscholar.google.co.th/scholar_lookup?title=Developing+a+hybrid+\nlanguage+model+for+open+vocabulary+automatic+speech+\nrecognition+in+a+lecture+speech+task&btnG=&hl=th&as_sdt=0%2C5.\n4. K Thangthai, A Chotimongkol, C Wutiwiwatchai, inINTERSPEECH. A hybrid\nlanguage model for open-vocabulary Thai LVCSR, (2013), pp. 2207–2211.\nhttps://scholar.google.com/scholar_lookup?title=A+hybrid+language+\nmodel+for+openvocabulary+Thai+LVCSR&btnG=&hl=th&as_sdt=0\n%2C5.\n5. Y He, B Hutchinson, P Baumann, M Ostendorf, E Fosler-Lussier, J\nPierrehumbert, inICASSP. Subword-based modeling for handling OOV\nwords inkeyword spotting (IEEE, 2014), pp. 7864–7868. https://scholar.\ngoogle.co.th/scholar_lookup?title=Subwordbased+modeling+for+\nhandling+OOV+words+inkeyword+spotting&btnG=&hl=th&as_sdt=0\n%2C5.\n6. X Liu, JL Hieronymus, MJ Gales, PC Woodland, Syllable language models\nfor Mandarin speech recognition: Exploiting character language models.\nJ. Acoust. Soc. Am.133(1), 519–528 (2013)\n7. M Kang, T Ng, L Nguyen, inINTERSPEECH. Mandarin word-character\nhybrid-input neural network language model, (2011), pp. 625–628.\nhttps://scholar.google.com/scholar_lookup?title=Mandarin+word-\ncharacter+hybridinput+neural+network+language+model&btnG=&hl=\nth&as_sdt=0%2C5.\n8. M Jongtaveesataporn, I Thienlikit, C Wutiwiwatchai, S Furui, Lexical units\nfor Thai LVCSR. Speech Comm.51(4), 379–389 (2009)\n9. T Mikolov, M Karafiát, L Burget, J Cernocký, S Khudanpur, inINTERSPEECH.\nRecurrent neural network based language model, (2010), pp. 1045–1048.\nhttps://scholar.google.com/scholar_lookup?title=Recurrent+neural+\nnetwork+based+language+model&btnG=&hl=th&as_sdt=0%2C5.\n10. K Kosawat, M Boriboon, P Chootrakool, A Chotimongkol, S Klaithin, S\nKongyoung, K Kriengket, S Phaholphinyo, S Purodakananda, T\nThanakulwarapas, C Wutiwiwatchai, inSNLP. BEST 2009: Thai word\nsegmentation software contest, (2009), pp. 83–88. https://scholar.google.\ncom/scholar_lookup?title=BEST+2009%3A+Thai+word+segmentation+\nsoftware+contest&btnG=&hl=th&as_sdt=0%2C5.\n11. A Chotimongkol, K Saykhum, P Chootrakool, N Thatphithakkul, C\nWutiwiwatchai, inOriental COCOSDA. LOTUS-BN: A Thai broadcast news\ncorpus and its research applications, (2009), pp. 44–50. https://scholar.\ngoogle.com/scholar_lookup?title=LOTUS-BN%3A+A+Thai+broadcast+\nnews+corpus+and+its+research+applications&btnG=&hl=th&as_sdt=0\n%2C5.\n12. G Kikui, E Sumita, T Takezawa, S Yamamoto, inINTERSPEECH.C r e a t i n g\ncorpora for speech-to-speech translation, (2003). https://scholar.google.\ncom/scholar_lookup?title=Creating+corpora+for+speech-tospeech+\ntranslation&btnG=&hl=th&as_sdt=0%2C5.\n13. W Aroonmanakun, inOriental COCOSDA. Collocation and Thai word\nsegmentation, (2002), pp. 68–75. https://scholar.google.com/\nscholar_lookup?title=Collocation+and+Thai+word+segmentation&\nbtnG=&hl=th&as_sdt=0%2C5.\nChunwijitra et al. EURASIP Journal on Audio, Speech, and Music Processing (2016) 2016:15 Page 12 of 12\n14. T Mikolov, S Kombrink, L Burget, J Cernocký, S Khudanpur, inICASSP.\nExtensions of recurrent neural network language model, (2011),\npp. 5528–5531. https://scholar.google.com/scholar_lookup?title=\nExtensions+of+recurrent+neural+network+language+model&btnG=&\nhl=th&as_sdt=0%2C5.\n15. S Kasuriya, V Sornlertlamvanich, P Cotsomrong, S Kanokphara, N\nThatphithakkul, inOriental COCOSDA. Thai speech corpus for Thai speech\nrecognition, (2003), pp. 54–61. https://scholar.google.com/\nscholar_lookup?title=Thai+speech+corpus+for+Thai+speech+\nrecognition&btnG=&hl=th&as_sdt=0%2C5.\n16. D Povey, A Ghoshal, G Boulianne, L Burget, O Glembek, N Goel, M\nHannemann, P Motlicek, Y Qian, P Schwarz, J Silovsky, G Stemmer, K\nVesely, inIEEE 2011 Workshop on Automatic Speech Recognition and\nUnderstanding. The Kaldi speech recognition toolkit, (2011). https://\nscholar.google.com//scholar_lookup?title=The+Kaldi+speech+\nrecognition+toolkit.&btnG=&hl=th&as_sdt=0%2C5.\n17. D Povey, PC Woodland, inICASSP. Minimum phone error and I-smoothing\nfor improved discriminative training, vol. 1, (2002), pp. 105–108. https://\nscholar.google.com/scholar_lookup?title=Minimum+phone+error+and+\nIsmoothing+for+improved+discriminative+training&btnG=&hl=th&\nas_sdt=0%2C5.\n18. T Mikolov, S Kombrink, A Deoras, L Burget, JH Cernocky, inIEEE 2011\nWorkshop on Automatic Speech Recognition and Understanding. RNNLM -\nrecurrent neural network language modeling toolkit, (2011), pp. 1–4.\nhttps://scholar.google.com/scholar_lookup?title=RNNLM+-+recurrent+\nneural+network+language+modeling+toolkit&btnG=&hl=th&as_sdt=0\n%2C5.\n19. DE Rumelhart, GE Hinton, RJ Williams, inNeurocomputing: Foundations of\nResearch. Learning representations by back-propagating errors, (1988),\npp. 696–699. https://scholar.google.com/scholar_lookup?title=Learning+\nrepresentations+by+backpropagating+errors&btnG=&hl=th&as_sdt=0\n%2C5.\n20. X Liu, Y Wang, X Chen, MJF Gales, PC Woodland, inICASSP. Efficient lattice\nrescoring using recurrent neural network language models, (2014),\npp. 4908–4912. https://scholar.google.com/scholar_lookup?title=\nEfficient+lattice+rescoring+using+recurrent+neural+network+\nlanguage+models&btnG=.\n21. Z Huang, G Zweig, B Dumoulin, inICASSP. Cache based recurrent neural\nnetwork language model inference for first pass speech recognition,\n(2014). https://scholar.google.com/scholar_lookup?title=Cache+based+\nrecurrent+neural+network+language+model+inference+for+first+\npass+speech+recognition&btnG=&hl=th&as_sdt=0%2C5&scioq=\nLearning+representations+by+backpropagating+errors.\nSubmit your manuscript to a \njournal and beneﬁ t from:\n7 Convenient online submission\n7 Rigorous peer review\n7 Immediate publication on acceptance\n7 Open access: articles freely available online\n7 High visibility within the ﬁ  eld\n7 Retaining the copyright to your article\n    Submit your next manuscript at 7 springeropen.com"
}