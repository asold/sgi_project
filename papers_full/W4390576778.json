{
  "title": "A Transformer Network With Sparse Augmented Data Representation and Cross Entropy Loss for AIS-Based Vessel Trajectory Prediction",
  "url": "https://openalex.org/W4390576778",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5102961976",
      "name": "Duong Nguyen",
      "affiliations": [
        "IMT Atlantique",
        "Laboratoire des Sciences et Techniques de l’Information de la Communication et de la Connaissance",
        "Université de Bretagne Occidentale"
      ]
    },
    {
      "id": "https://openalex.org/A5075497720",
      "name": "Ronan Fablet",
      "affiliations": [
        "Université de Bretagne Occidentale"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2103527399",
    "https://openalex.org/W2879698168",
    "https://openalex.org/W1568160967",
    "https://openalex.org/W2753820606",
    "https://openalex.org/W4220707949",
    "https://openalex.org/W4385453337",
    "https://openalex.org/W2076089699",
    "https://openalex.org/W3094009967",
    "https://openalex.org/W3209951855",
    "https://openalex.org/W3199820141",
    "https://openalex.org/W6679329542",
    "https://openalex.org/W2215617441",
    "https://openalex.org/W2944791333",
    "https://openalex.org/W3015961574",
    "https://openalex.org/W3133666622",
    "https://openalex.org/W3138659144",
    "https://openalex.org/W3200599341",
    "https://openalex.org/W3207160263",
    "https://openalex.org/W3165782304",
    "https://openalex.org/W1589221530",
    "https://openalex.org/W2572270144",
    "https://openalex.org/W6782468546",
    "https://openalex.org/W3136121014",
    "https://openalex.org/W3204875639",
    "https://openalex.org/W2963001155",
    "https://openalex.org/W2766836212",
    "https://openalex.org/W2962687116",
    "https://openalex.org/W2940129212",
    "https://openalex.org/W3116651890",
    "https://openalex.org/W4226213199",
    "https://openalex.org/W4206338773",
    "https://openalex.org/W2790115023",
    "https://openalex.org/W6761261503",
    "https://openalex.org/W2002158386",
    "https://openalex.org/W3084233918",
    "https://openalex.org/W2022603014",
    "https://openalex.org/W2990868438",
    "https://openalex.org/W4288064704",
    "https://openalex.org/W3109182714",
    "https://openalex.org/W2982564563",
    "https://openalex.org/W2972599895",
    "https://openalex.org/W2886960696",
    "https://openalex.org/W2083442964",
    "https://openalex.org/W2990822052",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W4311415873",
    "https://openalex.org/W299440670",
    "https://openalex.org/W6727654133",
    "https://openalex.org/W6780593937",
    "https://openalex.org/W6839899322",
    "https://openalex.org/W3033790618",
    "https://openalex.org/W6757817989",
    "https://openalex.org/W6726497184",
    "https://openalex.org/W3047895711",
    "https://openalex.org/W6737778391",
    "https://openalex.org/W6617744952",
    "https://openalex.org/W2944924828",
    "https://openalex.org/W2891503716",
    "https://openalex.org/W2981731882",
    "https://openalex.org/W2965862774",
    "https://openalex.org/W3034368386",
    "https://openalex.org/W3161292270",
    "https://openalex.org/W3189199724",
    "https://openalex.org/W2985871763",
    "https://openalex.org/W2058815839",
    "https://openalex.org/W2168175751",
    "https://openalex.org/W1500470240",
    "https://openalex.org/W2505756961",
    "https://openalex.org/W2005256561",
    "https://openalex.org/W6748581759",
    "https://openalex.org/W6756091659",
    "https://openalex.org/W2559655401",
    "https://openalex.org/W2963263347",
    "https://openalex.org/W4286224767",
    "https://openalex.org/W3138154797",
    "https://openalex.org/W3101129902",
    "https://openalex.org/W2963090522",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W2908510526"
  ],
  "abstract": "Vessel trajectory prediction plays a pivotal role in numerous maritime applications and services. While the Automatic Identification System (AIS) offers a rich source of information to address this task, forecasting vessel trajectory using AIS data remains challenging, even for modern machine learning techniques, because of the inherent heterogeneous and multimodal nature of motion data. In this paper, we propose a novel approach to tackle these challenges. We introduce a discrete, high-dimensional representation of AIS data and a new loss function designed to explicitly address heterogeneity and multimodality. The proposed model&#x2014;referred to as TrAISformer &#x2014;is a modified transformer network that extracts long-term temporal patterns in AIS vessel trajectories in the proposed enriched space to forecast the positions of vessels several hours ahead. We report experimental results on real, publicly available AIS data. TrAISformer significantly outperforms state-of-the-art methods, with an average prediction performance below 10 nautical miles up to &#x007E;10 hours.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identiﬁer xxx\nA Transformer Network with Sparse\nAugmented Data Representation and\nCross Entropy Loss for AIS-based\nVessel Trajectory Prediction\nDUONG NGUYEN1, (Member, IEEE), AND RONAN FABLET1, (Senior Member, IEEE)\n1Duong Nguyen and Ronan Fablet are with IMT Atlantique, Lab-STICC, 29238 Brest, France (email: nvduong0512@gmail.com and\nronan.fablet@imt-atlantique.fr)\nCorresponding author: Ronan Fablet (e-mail: ronan.fablet@imt-atlantique.fr).\nThis work was supported by public funds (Ministère de l’Education Nationale, de l’Enseignement Supérieur et de la Recherche, FEDER,\nRégion Bretagne, Conseil Général du Finistère, Brest Métropole). It beneﬁted from HPC and GPU resources from Azure (Microsoft EU\nOcean awards) and from GENCI-IDRIS (Grant 2020-101030). The authors also acknowledge the support of ANR (French Agence\nNationale de la Recherche) under reference ANR AI Chair OceaniX (ANR-19-CHIA-0016).\nABSTRACT\nVessel trajectory prediction plays a pivotal role in numerous maritime applications and services. While the\nAutomatic Identiﬁcation System (AIS) offers a rich source of information to address this task, forecasting\nvessel trajectory using AIS data remains challenging, even for modern machine learning techniques, because\nof the inherent heterogeneous and multimodal nature of motion data. In this paper, we propose a novel\napproach to tackle these challenges. We introduce a discrete, high-dimensional representation of AIS data\nand a new loss function designed to explicitly address heterogeneity and multimodality. The proposed\nmodel—referred to as TrAISformer—is a modiﬁed transformer network that extracts long-term temporal\npatterns in AIS vessel trajectories in the proposed enriched space to forecast the positions of vessels several\nhours ahead. We report experimental results on real, publicly available AIS data. TrAISformer signiﬁcantly\noutperforms state-of-the-art methods, with an average prediction performance below 10 nautical miles up\nto ∼10 hours.\nINDEX TERMSAIS, vessel trajectory, trajectory prediction, maritime surveillance, multimodal data, deep\nlearning, transformer.\nI. INTRODUCTION\nI\nN the last decades, the development of maritime ac-\ntivities has raised signiﬁcant concerns relating to Mar-\nitime Surveillance (MS) and Maritime Situational Awareness\n(MSA), with vessel trajectory prediction being a focal point.\nAnticipating the direction of vessels and their approximate\nlocations at medium-range time horizons, ranging from a\nfew tens of minutes to tens of hours ahead, is at the core of\ndiverse MS and MSA applications, including but not limited\nto search and rescue [1], [2], trafﬁc control [3], path planning\n[4]–[6], port congestion avoidance [7]–[9], pollution moni-\ntoring [10].\nThe Automatic Identiﬁcation System—AIS provides in-\nvaluable information for the monitoring and surveillance of\nmaritime trafﬁc. AIS data provide vessels’ kinetic informa-\ntion (the current position indicated by the latitude and lon-\ngitude coordinates, the current Speed Over Ground—SOG,\nthe current Course Over Ground–COG,etc.), the information\nof the voyages, as well as the static information (the iden-\ntiﬁcation number in the format a Maritime Mobile Service\nIdentity—MMSI number, the name of the vessel, etc.) of\nvessels in the vicinity. Vessel trajectory prediction using AIS\ndata has been studied for more than a decade [11]–[18].\nHowever, the achievements thus far have been still limited.\nMost state-of-the-art schemes reach a relevant prediction\nperformance only for short time horizons (ranging from a\nfew minutes to half an hour) [14], [19], or for longer time\nhorizons under particular movement patterns corresponding\nto predeﬁned maritime routes [20], [21] or unimodal move-\nment patterns [18], [19]. Due to the complexity of vessel\nmovement patterns and the heterogeneous nature of AIS data,\nforecasting vessel positions above several hours remains\nVOLUME x, 2016 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nFIGURE 1: Illustration of long-term1dependence patterns\nin AIS vessel trajectories:At E, vessels typically follow\none of the two main maritime routes indicated by the red\nand the yellow dashed arrows. In order to forecast whether\na vessel will continue straight ahead (the red path) or turn\nright (the yellow path), the prediction model may need to\nroll back several time steps to D, C, B, and A to understand\nthe vessel’s previous movements. Moreover, if the prediction\nmodel is not multimodal, it may output as a prediction an\nunusual green dashed path, which is a merged path of the\ntrue red and yellow ones.\nhighly challenging. As an illustration, we report in Fig. 1 two\nvessel paths with very similar movement patterns on segment\nC→D but heading to two different destinations.\nTrajectory prediction has gained signiﬁcant attention in\nrecent years, particularly in the context of pedestrian and\nvehicle movement patterns [22]–[25]. In this context, deep\nlearning schemes have emerged as the state-of-the-art ap-\nproach [26]–[30]. These recent advances however barely\ntransfer to AIS-based vessel trajectory prediction [31], [32].\nFirst, the targeted space-time scales strongly differ (e.g.,\nmeters and a few seconds to a few minutes for pedestrian\nmovements vs. kilometers and hours for vessel movements).\nSecond, while interaction factors are critical to understanding\nand predicting pedestrian and vehicle trajectories, they have\nnegligible effects on vessels’ movements in the open sea.\nBesides, long-term dependencies are key factors for the latter\nand need to be explicitly addressed in AIS-based vessel\ntrajectory prediction models.\nIn the open sea, vessels often follow some common move-\nment patterns in order to optimize fuel consumption and to\n1In this paper, we use the terms “medium-range time horizon”, “medium-\nrange forecasting”, etc. to indicate the prediction horizons ranging from a\nfew tens of minutes to tens of hours. The terms “long-term dependency”,\n“long-term correlation”, etc., on the other hand, indicate the correlations\nacross several time steps in the series.\nconform with maritime trafﬁc regulations [33], [34]. How-\never, the analysis of the maritime trafﬁc according to a ﬁnite\nset of interconnected maritime routes using clustering-based\napproaches [18]–[21] appears too simplistic to account for\nthe heterogeneous and multimodal characteristics of real-\nworld AIS data. The core challenge of vessel trajectory\nprediction for the targeted time horizon in this paper (ranging\nfrom half an hour to tens of hours) revolves around accu-\nrately predicting the turning direction at the “intersections\"—\ncommonly referred to as waypoints—along maritime routes\n(see Fig. 1). From a mathematical perspective, this involves\ndeveloping a method that effectively represents the multi-\nmodal nature of AIS data at these waypoints, where each\nturning direction corresponds to a distinct mode of the data\ndistribution. In order to forecast the trajectory correctly, the\nprediction model may need to backtrack several time steps to\nknow where the vessel comes from and to fully understand\nlarge-scale movement patterns. In essence, we can identify\ntwo primary methodological challenges: i) learning how to\nrepresent maritime trafﬁc ﬂows beyond a fully-structured\nnetwork of maritime routes; and ii) capturing multi-scale\npatterns in vessel trajectories.\nTo address these challenges, we propose a novel deep\nlearning model, referred to as TrAISformer. Our key contri-\nbutions are as follows:\n• TrAISformer exploits a speciﬁc sparse, high-dimensional\nrepresentation of AIS data and frames the prediction\ntask as a classiﬁcation problem to explicitly model the\nheterogeneity of AIS data and the multimodality of\nvessel trajectories.\n• We leverage a probabilistic transformer architecture to\ncapture long-term dependencies in AIS vessel trajecto-\nries.\n• We benchmark TrAISformer w.r.t. state-of-the-art\nschemes on a real AIS dataset and report a prediction\nerror below 10 nmi (nautical mile) up to 10 hours,\nwhich signiﬁcantly outperforms previous works [14],\n[18], [19].\nThe paper is organized as follows. Section II states the\nproblem and gives an overview of the related work and\ncurrent limitations for AIS-based vessel trajectory prediction.\nWe present the proposed approach in Section III. Section IV\ndetails our numerical experiments. We further discuss our\nmain contributions and future work in Section V.\nII. PROBLEM STATEMENT AND RELATED WORK\nAIS-based vessel trajectory prediction involves forecasting\nthe future positions of vessels over a speciﬁc time horizon,\nusing a series of historical AIS data. Formally, let us denote\nby xt an AIS observation at time step t, where xt comprises\nthe position of the vessel (indicated by the latitude and the\nlongitude coordinates), its Speed Over Ground—SOG, and\n2 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nits Course Over Ground—COG 2.\nxt ≜ [lat,lon,SOG,COG ]T . (1)\nAn AIS vessel trajectory is then represented by a series\nof observations {xt0 ,xt1 ,...xtT }where ti < tj if i <\nj. One can use some simple interpolation method to get\na series of T + 1 equally sampled observations x0:T ≜\n{xt0 ,xt0+∆t,xt0+2∗∆t,..., xt0+T∗∆t}. The time step ∆t is\nchosen such that the error inherited from the interpolation\nhas a negligible effect on downstream tasks. In this paper, we\nﬁx the time step at 10 minutes and omit ∆t for the sake of\nnotation simplicity, i.e. xt0+n∗∆t ≜ xt+n.\nThe L-step-ahead prediction problem comes to predict the\ntrajectory xT+1:T+L ≜ {xT+1,xT+2,..., xT+L}given T+1\nobservations x0:T ≜ {x0,x1,..., xT }up to time T. Given\nthe nature of the prediction problem, it naturally arises as the\nsampling of the following conditional distribution:\np(xT+1:T+L|x0:T ). (2)\nWe may point out that this probabilistic formulation also cov-\ners deterministic prediction models [14], [36], which reduce\npto Dirac distributions.\nThere are two primary categories of approaches to AIS-\nbased vessel trajectory prediction. The ﬁrst one relies on a\nstate-space formulation, which combines a dynamical prior\non vessel movements with a ﬁltering method to infer or sam-\nple the posterior (2). Models following this approach have\ncertain limitations. Firstly, the dynamical prior often relies\non a simplistic model, such as the Curvilinear Motion Model\n(CMM) [37], which cannot account for complex patterns\nincluding turning points. Secondly, ﬁltering methods, such\nas the Kalman ﬁlter [37], [38] or the particle ﬁlter [11], are\nprone to error propagation issues. Consequently, they seem\nless suitable for medium-range prediction.\nIn recent years, the second approach, known as the\nlearning-based approach, has gained substantial popularity\n[39]. [40], [41], [42] leveraged LSTM (Long Short-Term\nMemory) and GRU (Gated Recurrent Unit) to learn the\ntemporal patterns in x0:T . However, given the multi-path\npatterns exhibited in AIS data, such schemes are likely\nto fail [43]. More sophisticated models take into account\nthe interactions between vessels. [32] used a customized\npooling layer—referred to as Collision-Free Social Pooling\n(CFSP), while [31] employed Graph Convolutional Neural\nNetworks (GCN) to model the interactions between vessels\nin proximity. These models demonstrate improved prediction\nperformance in dense trafﬁc scenarios with relatively short\nprediction horizons, typically below one hour. However, in\nthe open sea, where vessel density is signiﬁcantly lower, and\nfor medium-range horizons (spanning from a few hours to\ntens of hours), the impacts of the interactions between vessels\nare less pronounced. Furthermore, since the surrounding\nenvironment of a vessel may change as vessels enter or exit\n2We let the reader refer to [35] for a more detailed presentation of AIS\ndata streams.\nthe considered zone, it is intractable to explicitly model such\ninteractions for these time horizons (see the Appendix).\nTo address the heterogeneous and multimodal nature of\nAIS data, several methods rely on clustering [12], [14], [18],\n[19], [44]. They assume that maritime trafﬁc in a given area\ncan be represented as a graph, where each node corresponds\nto a waypoint and each edge represents the maritime route\nbetween two nodes. The prediction problem then resorts to\nexploiting a forecasting model over the deﬁned graph. A\nrich literature exists and exploits among others the constant\nvelocity model and the particle ﬁlter [12], Gaussian Processes\n[13] and neural networks [18], [19]. However, all those\nschemes face a common limitation: they rely on a route-based\nrepresentation of maritime trafﬁc, which is viable only when\nthe trafﬁc is highly organized and structured. In real life, a\nsigniﬁcant fraction of AIS trajectories cannot be assigned to\npredeﬁned routes [43], [45], limiting the practical application\nof clustering-based techniques in operational systems.\nIn this paper, we present a novel model for AIS-based\nvessel trajectory prediction, referred to as TrAISformer. To\ntackle the complexity and multimodality of AIS vessel tra-\njectories, we propose a new data representation and har-\nness the modeling capabilities of deep learning, speciﬁcally\ntransformer architectures [46]. Contrary to clustering-based\nmodels which constrain the trajectories to a maritime trafﬁc\ngraph structure [12], [14], [18], [19], [44], TrAISformer is\napplicable to any trajectory within the region of interest,\nwithout imposing constraints on an explicit graph of mar-\nitime routes. Additionally, we re-frame the prediction as\na classiﬁcation-based learning problem to best forecast the\npositions of maritime vessels several hours into the future.\nIII. PROPOSED APPROACH\nIn this section, we detail the proposed approach. We intro-\nduce a new representation of AIS data, derive a new loss\nfunction, and provide a brief introduction of the transformer\narchitecture used in TrAISformer.\nA. DISCRETE AND SPARSE REPRESENTATION OF AIS\nDATA\nOne of the primary challenges in trajectory prediction in\ngeneral, and AIS-based vessel trajectory prediction in par-\nticular, is the modeling of the heterogeneous and multimodal\nnature of motion data given relatively low-dimensional ob-\nservations. Here, we introduce a novel representation of AIS\ndata, which addresses the heterogeneity aspect. The multi-\nmodality part will be addressed in the next subsection with a\nclassiﬁcation-based training loss.\nThe most prevalent way to represent an AIS message is\nto use a 4-dimensional real-valued vector composed of the\nposition and the velocity of the vessel, as in (1).\nHowever, as discussed in [43] and [45], it is challenging\nto encode complex vessel movement patterns in this feature\nspace. A natural approach is to expand the feature space\nto a higher dimensional one. Speciﬁcally, instead of mod-\neling the conditional probability distribution of the future\nVOLUME x, 2016 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nFIGURE 2: Proposed representation of AIS data: To\novercome the challenge of representing the heterogeneous\nand multimodal nature of motion data with relatively low-\ndimensional observations in AIS-based vessel trajectory pre-\ndiction, a new representation of AIS data is proposed in this\nstudy. For each attribute att ∈{lat,lon,SOG,COG }), the\nobserved value (which is continuous) is discretized into a\none-hot vector hatt\nt . Each hatt\nt is then associated with a high\ndimensional real-valued embedding vector eatt\nt .\ntrajectory given the past p(xT+1:T+L|x0:T ), we consider\np(eT+1:T+L|e0:T ), where et ∈ Rde represents a high-\ndimensional embedding vector of xt. Recently, variational\nautoencoders have been very successful in learning such\neffective mappings that encode et from xt, and decode xt\nfrom et [47]–[52]. However, when the dimension of et is\nmuch higher than that of xt, the training becomes extremely\ndifﬁcult and prone to overﬁtting.\nTo overcome the overﬁtting problem, we exploit the “four-\nhot” representation vector ht, deﬁned in our previous works\n[43], [45]. Speciﬁcally, we discretize the latitude, the longi-\ntude, the SOG, and the COG into Nlat, Nlon, NSOG, and\nNCOG bins, respectively. We then build a one-hot vector for\neach attribute {lat,lon,SOG,COG }. The “four-hot” vector\nht is the concatenation of the four one-hot vectors.\nht ≜ [1lat\nt ,1lon\nt ,1SOG\nt ,1COG\nt ]T (3)\nwith 1att\nt (att∈{lat,lon,SOG,COG }) being the one-hot\nvector of att. The details are presented in Algorithm 1.\nEach attribute bin of ht will be associated with a high\ndimensional embedding vector, denoted as eatt\nt . The em-\nbedding vector et of an AIS observation xt is the concate-\nnation of eatt\nt . This mapping is illustrated in Fig. 2. The\nproposed approach ensures that in the embedding space, only\nNlat ×Nlon ×NSOG ×NCOG values of et will be used. By\nimposing this sparsity constraint, we effectively regularize\nthe mapping and avoid overﬁtting when augmenting the\noriginal 4-dimensional AIS observation xt to a much higher\ndimensional space ofet [53]. An AIS vessel trajectory is then\nrepresented by e0:T ≜ {e0,e1,..., eT }.\nNote that the mapping ht → et is one-to-one, and ob-\ntaining ht from xt is a straightforward process. However, in\nthe reverse direction, it is not possible ﬁnd the exact xt from\nht because of the discretization. In this paper, we employ a\nsimplifying approximation where we use the mid-points of\nthe bins speciﬁed by ht to estimate xt. This approximation\nintroduces an error equivalent to half of the resolution of the\nht bins in the estimation ofxt, even when the bins estimation\nis perfect. Nevertheless, we argue that this inherent error\nis negligible for medium-range vessel trajectory prediction\napplications such as search and rescue, trafﬁc control, path\nplanning, and port congestion avoidance. To provide an il-\nlustration, let’s consider a resolution of 0.01° for lat and\nlon. The approximation introduces an error of around 0.15\nnautical miles (nmi). This level of error does not signiﬁcantly\nimpact the aforementioned applications, as it remains well\nwithin acceptable limits.\nB. TRANSFORMER ARCHITECTURE\nAs depicted in Fig. 1, in order to forecast the trajectory of a\nvessel correctly, a prediction model needs to capture possible\nlong-term dependencies in the historical AIS observations.\nIn this regard, transformer neural networks [46] naturally\narise as highly suitable candidates. In this work, we adopt a\ntransformer architecture akin to the GPT models [54]. The\nmodel’s architecture is brieﬂy presented in the following\nparagraphs. Interested readers are encouraged to refer to [55]\nfor a more complete and formal introduction to transformer.\nThe transformer network in TrAISformer consists of a\nseries of attention layers that are stacked together. Each layer\nfunctions as an auto-regressive model that employs the dot-\nproduct multiple-head self-attention mechanism:\nAttention(Q,K,V ) = softmax\n(QKT\n√de\n)\nV, (4)\nwhere Q,K,V are linear projections of the input sequence\n(which is {et}for the ﬁrst layer, or the output sequence of\nthe previous layer for other layers), and de is the model size,\ni.e. the dimension of et. At each layer, the input sequence is\nprojected into a new space V, and the output of the attention\nblock is a weighted sum in V, where the weights signify\nthe relative contribution of each time step. These weights\nare computed as the softmax on the dot product of Q and\nK, normalized by √de. The projection operators of Q,K,V\nare learned during the training phase, and the calculation is\nperformed in parallel. The parallel processing capability al-\nlows the model to directly retrieve information from multiple\npast time steps simultaneously. This is a critical advantage\ncompared to recurrent networks, where the model has to\nprocess data sequentially and may not be able to retrieve\nlong-term information.\nThe output of the transformer’s ﬁnal layer is a vector\nlt with the same dimension as ht. We will present in the\nnext section how TrAISformer uses this output to model\np(hT+l|e0:T+l−1).\nC. LEARNING SCHEME\nIn the learning literature, trajectory prediction is commonly\nformulated as a regression problem where a model aims to\noutput the best possible continuous-valued eT+1:T+L (or\nxT+1:T+L) given the input e0:T (or x0:T ) [14], [18]. Within\na deterministic setting, the most common loss function is the\n4 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nFIGURE 3: Example of multi-resolution “four-hot” vec-\ntors for AIS data:The model uses the ﬁne-resolution vector\nht in the embedding module (see Fig.2), while the loss\nfunction uses both ht and a coarse-resolution h′\nt.\nmean square error, which measures the squared difference\nbetween the predicted and the actual values [14], [19], [56]:\nLMSE = 1\nL\nL∑\nl=1\n||xpred\nT+l −xtrue\nT+l ||2\n2, (5)\nwhere ||.||2 denotes the Euclidean norm L2. However, this\nL2 loss function (which can be interpreted w.r.t. Gaussian as-\nsumption on the conditional likelihood p(eT+l|e0:T+l−1) or\np(xT+l|x0:T+l−1)) may not be appropriate for posterior dis-\ntributions that exhibit multimodality, as illustrated by vessels’\ntrajectories in Fig.1. To explicitly account for multimodal\nposteriors, we propose a classiﬁcation-based formulation that\ninvolves modeling p(eT:T+l|e0:T+l−1) as a concatenation\nof four categorical distributions, each corresponding to an\nattribute {lat,lon,SOG,COG }. Speciﬁcally, because the\nmapping ht →et is one-to-one, we have:\np(hT+l|e0:T+l−1) = p(eT+l|e0:T+l−1). (6)\nAs ht is a “four-hot” vector, this transforms the prediction\ninto a classiﬁcation problem with four heads, each corre-\nsponding to one component of the one-hot vector ht). Let\nus denote pT+l ≜ p(hT+l|e0:T+l−1) = p(eT+l|e0:T+l−1),\nthe loss function is deﬁned as:\nLCE ≜\nL∑\nl=1\nCE(hT+l,pT+l), (7)\nwith CE being the cross-entropy function. The details are\npresented in Algorithm 2. We demonstrate how the proposed\nloss function helps maintain the multimodal characteristics\nof the data in Fig. 4.\nNote that ht is a discrete representation of the continuous\nxt. This discretization can be performed at different resolu-\ntions. We empirically observed that the prediction could be\nmarginally improved if we use a multi-resolution version of\nLCE as follows (see Fig. 3) :\nLCE =\nL∑\nl=1\nCE(pT+l,hT+l) + βCE(p′\nT+l,h′\nT+l). (8)\nwhere p′\nT+l ≜ p(h′\nT+l|e0:T+l−1), h′\nT+l is a coarser version\nof hT+l, βis a scalar balancing the relative importance of the\ncoarse-resolution loss.\nThe training procedure’s speciﬁcs are outlined in Algo-\nrithm 3. For the sake of notation simplicity, we present the\nFIGURE 4: Illustration of the loss functionLCE to ac-\ncount for multimodal posterior: Let’s consider a scenario\nwhere at a speciﬁcwaypoint, half of the vessels in the training\nset turn left and the other half turn right. The true distribution\nof the longitude at the next time step forms a bimodal normal\ndistribution, depicted by the blue curve. If we use a real-\nvalued scalar to represent the longitude and use LMSE as\nthe loss function, the implicit distribution of the model is\nan unimodal Gaussian distribution. Consequently, the model\ntends to merge the two modes of the true distribution, as\nillustrated by the orange curve. By contrast, if we use a one-\nhot vector to represent the longitude and use LCE as the loss\nfunction, the implicit distribution of the model is a categorical\ndistribution. With this distribution, the model preserves the\ntwo modes, as shown by the green curve.\ntraining on a per-series basis. In practice, the model processes\nthe data in batches.\nThe proposed model is applied recursively. To predict a\nvessel position at time T + l, we sample a “four-hot” vector\nhpred\nT+l from p(hT+l|e0:T+l−1):\nhpred\nT+l ∼p(hT+l|e0:T+l−1) (9)\nand compute the “pseudo-inverse” of the sampled \"four-hot\"\nvector to output the new position xpred\nT+l . The latter is subse-\nquently fed into the network to sample similarly a position\nat the next time step. We repeat this sampling procedure until\nwe achieve the desired trajectory length. Multiple runs of this\nsampling procedure can be performed for a given AIS vessel\ntrajectory to generate different possible predicted paths. This\nstochastic procedure allows us to address the fact that two\nvessels currently having similar movement patterns at present\nmay diverge in their trajectories at the next waypoint. The de-\ntails are presented in Algorithm 4. We demonstrate in Section\nIV that if we do not sample hpred\nT+l from p(hT+l|e0:T+l−1)\naccording to (9), the performance of the model will degrade.\nA sketch of the resulting TrAISformer architecture is\nshown in Fig. 5.\nIV. EXPERIMENTS AND RESULTS\nIn this section, we report the experimental results of our\nmodel on a real AIS dataset introduced in [18]. We include\nVOLUME x, 2016 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nFIGURE 5: Sketch of theTrAISformer architecture: each\nAIS observation xt is discretized into a “four-hot” vector\nht (for visualization purposes, we illustrate a one-hot vector\ninstead of a “four-hot” vector for ht). Subsequently, each\nht is paired with a high dimensional real-valued embedding\nvector et. The sequence of embeddings the e0:t will be fed\ninto a transformer network to predict pt+1 ≜ p(ht+1|e0:t).\nDuring the training phase, the model is optimized to mini-\nmize the cross-entropy loss between the true value ht+1 and\npt+1. To enhance prediction accuracy, we introduce a “multi-\nresolution” loss. This involves calculating the cross-entropy\nat different spatial resolutions of ht+1. In the forecasting\nphase, we generate vessel positions recursively. We sample\nhpred\nt+1 from pt+1, calculate the “pseudo-inverse” of it to de-\nrive xpred\nt+1 . The predicted xpred\nt+1 is fed back into the network\nto sample the next position (as shown by the red path in the\ndiagram). This iterative process continues until we reach the\ndesired prediction horizon L.\na benchmarking w.r.t state-of-the-art methods for a predic-\ntion horizon up to 15 hours. Additionally, we also present\nan ablation study to assess the relevance of each compo-\nnent of the proposed model. To facilitate the reproducibility\nof the work in this paper, we chose a publicly available\nAIS dataset and made the code of the model available at\nhttps://github.com/CIA-Oceanix/TrAISformer.\nA. EXPERIMENTAL SET-UP\nDataset: We tested TrAISformer on a public AIS dataset\nprovided by the Danish Maritime Authority (DMA) 3. The\ndataset comprises AIS observations of cargo and tanker ves-\nsels from January 01, 2019 to March 31, 2019. The Region\nof Interest (ROI) is a rectangle from (55.5°, 10.3°) to (58.0°,\n13.0°). Prior to preprocessing, the raw dataset contained\napproximately 712 million AIS messages. We used AIS data\nfrom January 01, 2019 to March 10, 2019 and from March\n11, 2019 to March 20, 2019 to train the model and tune the\nhyper-parameters, respectively. The test set comprises AIS\ndata from March 21, 2019 to March 31, 2019. A subset of\n3https://dma.dk/safety-at-sea/navigational-information/ais-data\nAlgorithm 1:fourhot(xt,R,SOGmax,N).\nDescription: Create \"four-hot\" vector.\nInput: AIS observation\nxt ≜ [lat,lon,SOG,COG ]T ,\nthe limits of the ROI\nR ≜ [latmin,latmax,lonmin,lonmax]T ,\nSOGmax,\nthe numbers of bins\nN ≜ [Nlat, Nlon, NSOG, NCOG]T .\nOutput: “Four-hot” vectorht.\n// Create the one-hot vector for\neach attribute.\n1lat\nt = onehot(xlat\nt ,latmin,latmax,Nlat)\n1lon\nt = onehot(xlon\nt ,lonmin,lonmax,Nlon)\n1SOG\nt = onehot(xSOG\nt ,0,SOGmax,NSOG)\n1COG\nt = onehot(xCOG\nt ,0,360,NCOG)\n// Concatenate the one-hot vectors\nht = [1lat\nt ,1lon\nt ,1SOG\nt ,1COG\nt ]T\nReturn: ht\nAlgorithm 2:ce_loss(ht, lt,N).\nDescription: Calculate the cross-entropy loss LCE .\nInput: \"four-hot\" vector ht,\nthe output of the transformer lt,\nthe numbers of bins N.\nOutput: the cross-entropy CE(ht,lt).\n// Split ht back into 4 one-hot\nvectors, each corresponding to an\nattribute of the AIS observation.\n1lat\nt ,1lat\nt ,1SOG\nt ,1COG\nt = split(ht,N)\n// Split lt into 4 heads.\nllat\nt ,llon\nt ,lSOG\nt ,lCOG\nt = split(lt,N)\n// Calculate the cross-entropy for\neach head.\nplat\nt = CE(Categorical(logit = llat\nt ),1lat\nt )\nplon\nt = CE(Categorical(logit = llon\nt ),1lon\nt )\npSOG\nt = CE(Categorical(logit = lSOG\nt ),1SOG\nt )\npCOG\nt = CE(Categorical(logit = lCOG\nt ),1COG\nt )\n// Calculate “total” cross-entropy.\nce_with_logit(ht,lt) = plat\nt ∗plon\nt ∗pSOG\nt ∗pCOG\nt\nReturn: ce_with_logit(ht,lt)\nthis dataset was exploited in [18] to evaluate state-of-the-art\nmodels for AIS-based vessel trajectory prediction, including\ndeep learning models.\nData pre-processing: AIS data often contain outliers and\nmissing data, which can pose challenges to the prediction.\nIn the training phase, the presence of outliers and missing\ndata introduces additional noise and uncertainty, potentially\naffecting the convergence of the learning process. During the\nevaluation phase, missing data prevents us from calculating\nthe prediction errors, while outliers can lead to an inaccurate\nassessment of prediction accuracy. To mitigate the impact\n6 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nAlgorithm 3: trAISformer_train({x0:T+L}, Θ, R,\nSOGmax, N, β).\nDescription: Train TrAISformer.\nInput: The training set {x0:T+L},\nthe set of TrAISformer’s parametersΘ,\nthe limits of the ROI R,\nSOGmax,\nthe numbers of bins N,\ncoefﬁcient β.\nOutput: The learned set of parameters Θ.\nfor x0:T+L in {x0:T+L}do\n// Create the \"four-hot\" vectors\nat different resolutions.\nfor tin 0 : T + Ldo\nht = fourhot(xt,R,SOGmax,N)\nh′\nt = fourhot(xt,R,SOGmax,N/3)\nend\n// Get the embeddings and apply\nthe transformer.\ne0:T+L−1 = embedding(h0:T+L−1)\nl1:T+L = transformer(e0:T+L−1)\nl′\n1:T+L = conv1d(l1:T+L,kernel =\n[1/3,1/3,1/3]T ,stride = 3)\n// Calculate the loss.\nLCE = 0\nfor lin 1 : Ldo\nce(ht,lt) = ce_loss(ht,lt,N)\nce(h′\nt,l′\nt) = ce_loss(h′\nt,l′\nt,N/3)\nLCE = LCE + ce(ht,lt) + β∗ce(h′\nt,l′\nt)\nend\n// Optimize Θ.\nΘ = AdamW(LCE ,Θ,x0:T+L)\nend\nReturn: Θ\nof outliers and missing data, we implemented the following\npreprocessing steps:\n• Remove AIS messages with unrealistic speed values\n(SOG ≥30 knots);\n• Remove moored or at-anchor vessels;\n• Remove AIS observations within 1 nautical mile dis-\ntance to the coastline;\n• Split non-contiguous voyages into contiguous ones. A\ncontiguous voyage [43], [45] is a voyage whose the\nmaximum interval between two consecutive AIS mes-\nsages is smaller than a predeﬁned value, here 2 hours;\n• Remove AIS voyages whose length is smaller than 20\nor those that last less than 4h;\n• Remove abnormal messages. An AIS message is con-\nsidered abnormal if the empirical speed (calculated by\ndividing the distance traveled by the corresponding in-\nterval between the two consecutive messages) is unreal-\nistic, here above 40 knots;\n• Down-sample AIS data with a sampling rate of 10-\nminute;\nAlgorithm 4: trAISformer_predict(x0:T , Θ, R,\nSOGmax, N, L).\nDescription: Use TrAISformer to predict vessel\ntrajectory.\nInput: The initial segment of the trajectory to predict\nx0:T ,\nthe trained TrAISformer’s parametersΘ,\nthe limits of the ROI R,\nSOGmax,\nthe numbers of bins N,\nthe prediction horizon L.\nOutput: The predicted trajectory x0:T+L.\n// Create the \"four-hot\" vectors of\nthe initial segment.\nfor tin 0 : T do\nht = fourhot(xt,R,SOGmax,N)\nend\n// Get the embeddings of the initial\nsegment.\ne0:T = embedding(h0:T )\n// Iterate over the prediction\nhorizon.\nfor lin 1 : Ldo\nl1:T+l = transformer(e0:T+l−1)\n// Split lT+l into 4 heads.\nllat\nT+l,llon\nT+l,lSOG\nT+l ,lCOG\nT+l = split(lT+l,N)\n// Create the categorical\ndistributions and sample hatt\nT+l\nfrom them.\nfor attin {lat,lon,SOG,COG }do\nhatt\nT+l ∼Categorical(logit = latt\nT+l)\nend\n// Get the predicted hT+l, eT+l,\nand xT+l\nhT+l = [hlat\nT+l,hlon\nT+l,hSOG\nT+l ,hCOG\nT+l ]T\neT+l = embedding(hT+l)\nxT+l = pseudo-inverse(hT+l)\nend\nReturn: x0:T+L\n• Split long voyages into shorter ones with a maximum\nsequence length of 20 hours.\nHyper-parameters: the results reported in this paper were\nobtained using a transformer architecture with 8 layers. Each\nlayer contains 8 attention heads. The resolution of the “four-\nhot” vector ht was set to 0.01° for lat and lon, 1 knot for\nSOG and 5° for COG. With this resolution, the correspond-\ning sizes of elat\nt ,elon\nt ,eSOG\nt ,eCOG\nt were 256,256,128 and\n128 for the ROI reported in this paper. This resulted in a\n768-dimensional embedding et. The coarse vector h′\nt was\nobtained by merging three consecutive bins ofht. We noticed\nthat when we reduced or increased the resolution of ht by\n2, the difference in the results was negligible. The historical\nsequence length T was set to 3 hours and the prediction\nVOLUME x, 2016 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nhorizon Lwas up to 15 hours. The model was trained using\nAdamW optimizer [57] with cyclic cosine decay learning\nrate scheduler [58]. The learning rate was set to 6e−4. Other\nimplementation details can be found in the GitHub repository\nthat we shared above. We trained the model on a single GTX\n1080 Ti GPU over 50 epochs with early stopping. In terms of\ncomputational complexity, it took∼60 minutes to process 10\ndays of data in the test set, which suggests that the model can\nrun in real-time [59].\nBenchmark models: we compare the performance of\nTrAISformer against different state-of-the-art deep learning\nmodels: LSTM seq2seq [14], convolutional seq2seq [60],\nseq2seq with attention [18], [19], GeoTrackNet [45].\nIt is challenging to conduct a fair quantitative compar-\nison with clustering-based methods [12], [14], [18], [19],\n[36], [44]. First, those methods did not state clearly how to\naddress clustering noise and small clusters. Second, most\nof them use a DBSCAN clustering, which is sensitive to\nhyper-parameters [12], [19], [36]. Different sets of hyper-\nparameters could lead to very different results. Third, as\nmentioned in Section II, clustering-based approaches, such\nas [19], assume vessels’ trajectories belong to a predeﬁned\ngraph of maritime routes. This assumption does not hold for\nthe considered dataset. This is the reason why [18] restricted\ntheir analysis to a subset of the whole dataset. That subset\nis composed of tankers’ trajectories for a few predeﬁned\nroutes4. Though they only involve a subset of trajectories\ncompared with the other benchmarked approaches, we regard\nthe resulting score in [18] as a score under a best-case sce-\nnario for clustering-based methods for the considered ROI.\nAs the benchmarked models are not public, we conducted\nan independent implementation and ﬁne-tuned each model to\nget optimal outcomes.\nEvaluation criteria: for each prediction, the prediction\nerror at time step t is calculated as the haversine distance\nbetween the true position and the predicted one:\ndk = 2Rarcsin\n(√\nsin2(¯φ) + cos(φ1)cos(φ2)sin2(¯λ)\n)\n,\n(10)\nwith R the radius of the Earth, ¯φ ≜ 0.5(φ2 −φ1), ¯λ ≜\n0.5(λ2 −λ1), φ1 and φ2 denote the latitudes, λ1 and λ2\ndenote the longitudes of the predicted position and the true\nposition, respectively.\nWe used a best-of-N criterion, i.e. for each model, we\nsampled Npredictions for each target trajectory and reported\nthe best result. In this paper, N = 16. This criterion allows\nus to account for the effect of multimodality.\nB. RESULTS\nTable 1 shows the average prediction errors evaluated at 1,\n2, and 3 hours ahead horizons. The ROI contains several\nwaypoints, rendering prediction for time horizons ranging\n4We may point out that, contrary to the whole dataset, that subset has not\nbeen made available.\nfrom 1 to 15 hours highly challenging. In the case of in-\ncorrect prediction of turning directions at the waypoints,\nthe prediction errors of a model increase signiﬁcantly, often\nabove a few nautical miles (nmi), as demonstrated by the\nbenchmarked models in Table 1. TrAISformer outperforms\nall the benchmarked models by a large margin. For instance,\nfor the 2-hour-ahead prediction, it is the only model with an\naverage error below one nautical mile (41% better than the\nsecond best model GeoTracknet). These results conﬁrm the\ncapability of TrAISformer to capture the multimodal nature of\nvessel trajectories, extract pertinent long-term dependencies,\nand deliver accurate predictions of vessel paths.\nTrAISformer improves by a factor of 2 the performance\nof the model proposed in [18], which is one of the current\nstate-of-the-art schemes, with respective scores of 0.94 nmi\nand 1.93 nmi. We may recall that the performance of this\nclustering-based scheme refers to a best-case scenario, as it\nonly involves tankers’ trajectories for a few maritime routes\nin the case-study region. We also note that the direct appli-\ncation of state-of-the-art deep learning schemes on the 4-\ndimensional AIS feature vector, namely LSTM seq2seq [14],\nconvolutional seq2seq [60], seq2seq with attention [18], [19],\ntransformer [46], [54] (see Table. 2) leads to poor prediction\nperformances (mean error greater than 6 nmi for a 2-hour-\nahead prediction). The second best approach is our previous\nwork GeoTrackNet [43], [45]. It shares two key features with\nTrAISformer: i) a similar sparse high-dimensional represen-\ntation of AIS data and ii) a probabilistic neural-network-\nbased learning scheme. However, GeoTrackNet uses a Vari-\national Recurrent Neural Network (VRNN) [61] instead of\na transformer architecture to capture the temporal patterns\nin the AIS data. The improved performance of TrAISformer\nover GeoTrackNet suggests that transformers may be a better\nneural architecture for AIS data than VRNN.\nTo further highlight the importance of the probabilis-\ntic feature of TrAISformer, we report the performance\nof a deterministic version—denoted as TrAISformer_No-\nStoch—of TrAISformer. This model outputs the \"four-\nhot\" vector with the highest probability, i.e. hpred\nT+l =\nargmaxh p(hT+l|e0:T+l−1), instead of sampling hpred\nT+l like\nin (9). The decrease in the prediction performance (from\n0.94 to 2.88 for the 2-hour-ahead prediction) demonstrates\nthe importance of a multimodal representation of vessels’\ntrajectories for the considered case-study. As pointed out\npreviously, two vessels departing from the same port, having\nthe same current position and velocity, may follow different\npaths at the next waypoint, making it impossible for the\nprediction model to produce correct deterministic forecasts\nall the time. Models that are capable of predicting multiple\npossibilities are more relevant. Yet, the deterministic version\nof TrAISformer is still much better than standard seq2seq\nmodels, which again stresses the relevance of the transformer\narchitecture as well as of the considered representation of\nAIS feature vector.\nIn maritime downstream tasks, a crucial factor to consider\n8 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nTABLE 1: Mean prediction performance of the bench-\nmarked models (in nautical miles).\nModel 1h 2h 3h\nLSTM_seq2seq 5.83 8.39 11.64\nConv_seq2seq 4.23 6.77 9.66\nLSTM_seq2seq_att 3.35 6.41 9.65\nClustering_LSTM_seq2seq_att1[18] 0.78 1.93 3.66\nGeoTrackNet [45] 0.72 1.59 2.67\nTrAISformer 0.48 0.94 1.64\nTrAISformer_No-Stoch 1.28 2.88 5.02\n1 The result from [18] was evaluated on a subset of the whole\ndataset, which comprises only tankers’ trajectories for a prede-\nﬁned number of maritime routes. As such, this is regarded as a\nbest-case scenario for clustering-based models.\nFIGURE 6: Prediction performance w.r.t. prediction time\nhorizon: we plot for each benchmarked model the mean\nprediction performance for prediction time horizons from 10\nminutes to 15 hours. We also highlight the time horizon up to\nwhich the performance of a given model remains below the\nmaximum visibility under good weather conditions (i.e., 10\nnmi).\nwhen using a prediction model is the maximum meaningful\nprediction horizon, which is the longest time horizon where\na prediction is still useful. In some scenarios, such as search\nand rescue operations, a prediction is deemed helpful if the\nprediction error is smaller than the visibility, which is gen-\nerally assumed to be 10 nmi under clear weather conditions\n[62]. Fig. 6 depicts such prediction horizons of the bench-\nmarked models. In the best case scenario, TrAISformer can\nextend the prediction horizon by a factor of ∼5.8 compared\nwith current state-of-the-art methods (9.67h for TrAISformer\nvs. 1.67h for LSTM_seq2seq_att).\nFig. 7 displays some examples of the predictions made\nby TrAISformer and the other benchmarked methods. TrA-\nISformer successfully samples realistic turning directions to\nforecast the potential paths taken by vessels. We recall here\nthat for probabilistic models such as GeoTrackNet, TrAIS-\nformer, we report among 16 sampled trajectories the one\nclosest to the real trajectory. We may highlight that the model\napplies not only to the main maritime routes (the ﬁrst three\ncolumns) but also to less frequent ones (the last column).\nBy contrast, clustering-based methods struggle in such cases.\nThe four examples show the relatively poor performance of\nthe direct application of sequence-to-sequence deep learning\nmodels. GeoTrackNet samples realistic trajectories for the\nﬁrst three examples, though not as close to the real ones\nas the ones predicted by TrAISformer. However, for the last\nexample, it performs poorly, whileTrAISformer still succeeds\nin sampling a realistic path.\nWe further analyze in Fig. 8 the behavior of TrAISformer\nthrough the activation of an attention block in the ﬁrst layer\nof TrAISformer for the trajectory shown in Fig. 1. Each\nrow shows the relative importance of each time step in the\npredicted output. Some remarks raised from this analysis:\n• On straight lines, only the information from recent time\nsteps is used to predict the next time step, which is\nsimilar to constant velocity models [63];\n• At the waypoints, the model needs to retrieve infor-\nmation from much earlier time steps, especially at the\nprevious waypoints to predict the next time step. For\nexample, row 40 (the red rectangle) depicts the attention\nweights to compute the prediction at E. The model pays\nmore attention to the inputs at A, B, C, D, and E. One\nintuitive explanation is that the model needs to know\nwhere the vessel comes from (points A, B, C), what the\nmovement pattern of the vessel is in the current segment\n(point D), as well as the current position and velocity\n(point E) to guess the movement pattern to come.\nAs such, this example demonstrates the ability of TrAIS-\nformer to extract relevant long-term dependencies to predict\nvessel trajectories.\nC. ABLATION STUDY\nTo evaluate the signiﬁcance of the different components of\nTrAISformer architecture, we conducted an ablation study:\n• Firstly, we removed et and ht to demonstrate the sig-\nniﬁcance of the high-dimensional encoding. This is\nequivalent to applying directly a GPT model [54] to 4-\ndimensional AIS data streams.\n• Secondly, we kept et but removed ht to assess the\nrelevance of the sparsity constraint. The embedding\nxt → et in this model is a MultiLayer Perceptron\n(MLP).\n• Finally, we tested a model with the same architecture as\nTrAISformer but used a regression loss as the training\nloss to demonstrate the criticality of the classiﬁcation\nloss.\nThe results in Tab. 2 show that all the ablated models lead\nto signiﬁcantly worse performance compared with TrAIS-\nformer. Interestingly, the performance degradation is in the\nsame order of magnitude for the three ablated models, though\nthe impact of the classiﬁcation-based loss is slightly greater.\nVOLUME x, 2016 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nLSTM_seq2seq_att\nGeoTrackNet\nStandard transformer\nWithout ht\nWithout LCE\nTrAISformer\nFIGURE 7: Examples of AIS-based vessel trajectory predictions: each column depicts the predictions of a given real\nvessel trajectory. The rows correspond to the various models used for benchmarking. For each example, we display the AIS\nobservations x0:T used as the input by all models — , the real vessel trajectory -- , and the predicted trajectory •.\n10 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nTABLE 2: Mean prediction performance (in nautical miles) of the models in the ablation study.\nModel AIS data representation Embedding xt → ek Loss function 1h 2h 3h\nWithout et and ht (standard transformer) [lat, lon, SOG, COG]T None LMSE 4.75 8.36 11.40\nWithout ht [lat, lon, SOG, COG]T → et MLP LMSE 5.02 9.69 15.04\nWithout the classiﬁcation loss LCE “four-hot“ vector→ et Via ht LMSE 5.53 10.64 16.06\nTrAISformer “four-hot“ vector→ et Via ht LCE 0.48 0.94 1.64\nFIGURE 8: Relative importance of each time step in the\nprediction: Visualization of the activation of one attention\nblock of TrAISformer for the trajectory shown in Fig. 1.\nHorizontal axis: input time step; vertical axis: output time\nstep. Each row shows which parts of the input that the\nmodel pays attention to in order to compute the output at the\ncorresponding time step.\nOverall, these results highlight the importance of integrating\nall the components of our architecture for achieving the best\nprediction performance.\nV. CONCLUSIONS AND FUTURE WORK\nIn this paper, we presented a novel model—referred to as\nTrAISformer, for vessel trajectory prediction using AIS data.\nThe model uses an augmented, sparse, and high-dimensional\nrepresentation of AIS data as well as a state-of-the-art trans-\nformer network architecture to learn complex patterns in\nvessel trajectories. Using a classiﬁcation-based training loss,\nTrAISformer can capture the multimodal nature of trajectory\ndata. Experiments on real, public AIS data showTrAISformer\noutperforms existing methods by a signiﬁcant margin. With\na 9-hour-ahead prediction error below 10 nmi on a real AIS\ndataset in a case-study region involving dense and complex\nmaritime trafﬁc patterns, these results open new research\navenues for various applications such as search and rescue,\nport congestion avoidance, and maritime surveillance.\nThrough an ablation study, we have shown that all the\nabove-mentioned components of TrAISformer have critical\nroles in the reported performance. Though transformer ar-\nchitectures are likely not fully explainable [64], [65], we\nhave also shown that the intermediate attention weights of\nthe transformer architecture provide a natural way to explore\nhow TrAISformer exploits the past AIS data to compute\nits predictions of the future trajectory. This supports that\nthe learned transformer representation could be of interest\nbeyond the considered application to prediction tasks.\nFuture work could further improve the architecture and\ndevelop the applications of TrAISformer framework. Among\nothers, we may cite the learning of conditional TrAISformer\nw.r.t. weather conditions as the latter clearly impact ves-\nsels’ movement. While we currently omit the inﬂuence of\nvessel interactions, future work could study the possibility\nof integrating those interactions into the model. We may\nalso stress that the proposed TrAISformer architecture is\nsigniﬁcantly more complex (see Tab. 3) with ∼300 times\nmore parameters than the second most complex architecture\namong the benchmarked ones. While the greater complexity\nlikely contributes to the signiﬁcant gain, recent advances\nin model compression techniques, such as Neural Network\nPruning [66] and Knowledge Distillation [67], suggest that\nwe could reduce the model’s size typically by a factor of\ntens to hundreds without compromising its performance. This\nwould promote the assessment and adoption of TrAISformer\nin operational systems. The combination ofTrAISformer with\nother learning-based modules for classiﬁcation and anomaly\ndetections [45] is also of interest. Recent advances in the\nexploitation of AIS data for the inversion of sea surface pa-\nrameters [68], [69] may also be an appealing line of research\nfor our future work.\nAPPENDIX. WHY PEDESTRIAN AND VEHICLE\nTRAJECTORY PREDICTION MODELS DO NOT APPLY TO\nMEDIUM-RANGE AIS-BASED VESSEL TRAJECTORY\nPREDICTION\nIn this appendix, we present a mathematical demonstration\nexplaining why pedestrian and vehicle trajectory prediction\nmodels are not directly applicable to medium-range AIS-\nbased vessel trajectory prediction.\nLet us denote by xsi\nt an observation of an agent si at\ntime t. For instance, in pedestrian and vehicle trajectory\nprediction, si can represent either a pedestrian or a vehicle,\nand xsi\nt corresponds to their respective positions on the map.\nIn AIS trajectory prediction, si represents a vessel, and xsi\nt\nrepresents its AIS message. The trajectory of agent si from\nt1 to t2 (t2 > t1) is then represented by a sequence of\nobservations xsi\nt1:t2 = {xsi\nt1 ,xsi\nt1+1,..., xsi\nt2 }. At time t, we\ndenote the group of other agents in the vicinity of si as Vi\nt,\nVOLUME x, 2016 11\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\nFIGURE 9: Illustration of the intractability of the model-\ning of the interactions between agents in medium-range\ntrajectory prediction. Consider the scenario where we aim\nto predict the medium-range trajectory of agent s1 (denoted\nby the green dot). At time T, there are six other agents\n(s2,...,s 6) within its vicinity (enclosed by the dashed rect-\nangle). The interactions between s1 and these agents are\ndepicted by the double-headed arrows. As we project into the\nmedium-range future at time T + l−1, s2 and s6 will have\nmoved away from s1; and a new, unknown agents7 (denoted\nby the red dot) may appear near s1. The prediction model\nwould have no knowledge of this new vicinity, making the\nmodeling of interactions between agents intractable.\nand their historical trajectories are denoted as xVi\nt\n0:t .\nIn the context of this paper, using these notations, trajec-\ntory prediction refers to forecasting the trajectory of an agent\nsi for Ltimesteps ahead, based on the historical observations\nof this agent and the others in the vicinity up to time T, by\nmaximizing the likelihood:\np(xsi\nT+1:T+L|xsi\n0:T ,xVi\nt\n0:T ). (11)\nHere we use pin the broad sense, which includes determin-\nistic models.\nThe conditioning side of (11) encompasses two crucial\ncomponents: the xsi\n0:T component embeds the intention of\nthe agent, while the xVi\nt\n0:T part embeds the interactions with\nthe environment. State-of-the-art methods for pedestrian and\nvehicle trajectory prediction are centered on effectively mod-\neling and integrating these two terms. Prominent examples\ninclude S-LSTM [26], S-GAN [26], S-ATTN [27], SoPhie\n[28], MATF [29], Trajection [70], Trajectron++ [30], etc.\nThose models leverage deep neural networks such as LSTM\nor GAN (Generative Adversarial Network) to capture cor-\nrelations in historical data, and some pooling techniques to\nembed the interactions between agents. This idea has been\nadopted for short-term AIS-based vessel trajectory prediction\n[31], [32]. Although those methods have shown promising\nresults on the corresponding datasets, they are not suitable\nfor medium-range vessel trajectory prediction. First, the pre-\ndiction horizons considered in those works are from a few\nTABLE 3: AIC SBIC, and HQIC of the studied models.\nModel # parameters AIC BIC HQIC\nLSTM_seq2seq 1.2k -6.4M -6.4M -6.4M\nConv_seq2seq 56.3k -7.7M -7.1M -7.5M\nLSTM_seq2seq_att 33.7k -7.7M -7.4M -7.6M\nGeoTrackNet [45] 179.8k -3.5M -1.5M -3.0M\nTrAISformer 57.4M 111.0M 753.9M 292.4M\nseconds to a few minutes, which are too short for maritime\napplications. Second, those works address different types of\nmaneuvers, of which the movement of an agent depends\nhighly on the interactions with other agents and the sur-\nrounding environment. For maritime trafﬁc contexts, and at\nmedium-range time horizons, the path that a vessel will make\ndepends mainly on where it wants to go. It is barely affected\nby the interactions with other vessels in the vicinity at the\ncurrent moment. Mathematically, this means at time T we\nhave the approximation:\np(xsi\nT+l|xsi\n0:T ,xVi\nt\n0:T ) ≈p(xsi\nT+l|xsi\n0:T )\n⏐⏐⏐\nl»1\n. (12)\nOne may argue that we could use the predicted value of\nx\nVi\nT+l−1\n0:T+l−1 and xsi\n0:T+l−1 to estimate xsi\nT+l. However, in order\nto predict x\nVi\nT+l−1\n0:T+l−1, we need to predict the trajectory of all\nthe agents in the vicinity ofsi at T+l−1. This is an expensive\nor even intractable approach. For example, an unknown agent\nmay join the ROI, as illustrated in Fig. 9).\nIt’s important to note that if we remove xVi\nt\n0:T from (11),\nthis objective function simpliﬁes (2), which is the objective\nfunction used in medium-range AIS-based vessel trajectory\nprediction. Likewise, if we remove the module that encodes\nthe interactions between agents in some of the pedestrian and\nvehicle trajectory prediction models mentioned above, we\nget models that have similar architectures to those designed\nfor AIS trajectory prediction. For example, if we remove\nthe interactions between agents part in Trajectron [70], it\nbecomes an LSTM_seq2seq model.\nAPPENDIX. MODEL SELECTION STRATEGY\nIn this work, we used cross-validation as the model selection\nstrategy.\nAs suggested by Reviewers, another approach is to use\ninformation criteria such as the Akaike Information Criterion\n(AIC) [71], the Bayesian Information Criterion (BIC) [72],\nthe Hannan-Quinn Information Criterion (HQIC) [73].\nWe have calculated these criteria, the result is shown in\nTab.3.\nThe details of the calculation are as follows:\n• For deterministic models (LSTM_seq2seq, Conv_seq2seq,\nLSTM_seq2seq_att), we calculated the approximated\nlikelihood as ˆL = RSS/n, with RSS being the\nResidual Sum Squares of the ﬁtting and n being the\nnumber of observations [74].\n12 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\n• Although GeoTrackNet and TrAISformer are proba-\nbilistic models, they use transformed data. Hence, we\nalso used RSS/n to approximate the likelihood in the\noriginal data space.\n• Since the model in [18] (Clustering_LSTM_seq2seq_att)\nworks in a reduced scope, we did not include this model\nin this comparison (because we can not compare the\ninformation criteria of models trained on different data).\n• TrAISformer_No-stoch is TrAISformer with a dif-\nferent inference strategy. The information criteria of\nTrAISformer_No-stoch are the same as TrAISformer’s.\nWe can see that the values are dominated by the\npenalty terms and more speciﬁcally the number of param-\neters. The AIC, SBIC, and HQIC in Tab 3 favor mod-\nels with fewer parameters (LSTM_seq2seq, Conv_seq2seq,\nLSTM_seq2seq_att). This is in line with the objective of\ninformation criteria: to identify overparameterized models\n[75]. By contrast, neural networks can often be regarded\nas over-parameterized. This motivates the exploitation of\nregularization schemes during the training phase to avoid\noverﬁtting patterns. To some extent, overparametrization can\nyield positive effects [76], [77]).\nREFERENCES\n[1] Z. Ou and J. Zhu, “AIS Database Powered by GIS Technology for\nMaritime Safety and Security,” The Journal of Navigation, vol. 61, no. 4,\npp. 655–665, Oct. 2008, publisher: Cambridge University Press.\n[2] I. Varlamis, K. Tserpes, and C. Sardianos, “Detecting Search and Rescue\nMissions from AIS Data,” in 2018 IEEE 34th International Conference\non Data Engineering Workshops (ICDEW) , Apr. 2018, pp. 60–65, iSSN:\n2473-3490.\n[3] T. Fabbri, R. Vicen-Bueno, R. Grasso, G. Pallotta, L. M. Milleﬁori, and\nL. Cazzanti, “Optimization of surveillance vessel network planning in\nmaritime command and control systems by fusing METOC & AIS vessel\ntrafﬁc information,” in OCEANS 2015 - Genova, May 2015, pp. 1–7.\n[4] E. Tu, G. Zhang, L. Rachmawati, E. Rajabally, and G.-B. Huang, “Ex-\nploiting AIS Data for Intelligent Maritime Navigation: A Comprehensive\nSurvey,”IEEE Transactions on Intelligent Transportation Systems, 2017.\n[5] X. K. Dang, H. N. Truong, and V . D. Do, “A path planning control\nfor a vessel dynamic positioning system based on robust adaptive fuzzy\nstrategy,”Automatika, vol. 63, no. 3, pp. 580–592, Jul. 2022.\n[6] X.-P. Nguyen, X.-K. Dang, V .-D. Do, J. M. Corchado, and H.-N. Truong,\n“Robust Adaptive Fuzzy-Free Fault-Tolerant Path Planning Control for a\nSemi-Submersible Platform Dynamic Positioning System With Actuator\nConstraints,” IEEE Transactions on Intelligent Transportation Systems ,\nvol. 24, no. 11, pp. 12 701–12 715, Nov. 2023, conference Name: IEEE\nTransactions on Intelligent Transportation Systems.\n[7] J. M. Mou, C. v. d. Tak, and H. Ligteringen, “Study on collision avoidance\nin busy waterways by using AIS data,”Ocean Engineering, vol. 37, no. 5,\npp. 483–490, Apr. 2010.\n[8] C. Liu, J. Liu, X. Zhou, Z. Zhao, C. Wan, and Z. Liu, “AIS data-driven\napproach to estimate navigable capacity of busy waterways focusing on\nships entering and leaving port,”Ocean Engineering, vol. 218, p. 108215,\nDec. 2020.\n[9] M. J. Kang, S. Zohoori, M. Hamidi, and X. Wu, “Study of narrow water-\nways congestion based on automatic identiﬁcation system (AIS) data: A\ncase study of Houston Ship Channel,” Journal of Ocean Engineering and\nScience, Oct. 2021.\n[10] G. Soldi, D. Gaglione, N. Forti, A. Di Simone, F. C. DafﬁnÃ , G. Bottini,\nD. Quattrociocchi, L. M. Milleﬁori, P. Braca, S. Carniel, P. Willett,\nA. Iodice, D. Riccio, and A. Farina, “Space-based Global Maritime\nSurveillance. Part II: Artiﬁcial Intelligence and Data Fusion Techniques,”\nIEEE Aerospace and Electronic Systems Magazine, vol. 36, no. 9, pp. 30–\n42, Sep. 2021, arXiv:2011.11338 [eess].\n[11] B. Ristic, B. La Scala, M. Morelande, and N. Gordon, “Statistical analysis\nof motion patterns in AIS Data: Anomaly detection and motion predic-\ntion,” in 2008 11th International Conference on Information Fusion , Jun.\n2008, pp. 1–7.\n[12] F. Mazzarella, V . F. Arguedas, and M. Vespe, “Knowledge-based vessel\nposition prediction using historical AIS data,” in 2015 Sensor Data Fu-\nsion: Trends, Solutions, Applications (SDF), Oct. 2015, pp. 1–6.\n[13] H. Rong, A. P. Teixeira, and C. Guedes Soares, “Ship trajectory uncertainty\nprediction based on a Gaussian Process model,” Ocean Engineering, vol.\n182, pp. 499–511, Jun. 2019.\n[14] N. Forti, L. M. Milleﬁori, P. Braca, and P. Willett, “Prediction oof Vessel\nTrajectories From AIS Data Via Sequence-To-Sequence Recurrent Neural\nNetworks,” in ICASSP 2020 - 2020 IEEE International Conference on\nAcoustics, Speech and Signal Processing (ICASSP), May 2020, pp. 8936–\n8940, iSSN: 2379-190X.\n[15] T. A. V olkova, Y . E. Balykina, and A. Bespalov, “Predicting ship trajectory\nbased on neural networks using AIS data,” Journal of Marine Science\nand Engineering, vol. 9, no. 3, p. 254, 2021, iSBN: 2077-1312 Publisher:\nMDPI.\n[16] B. Murray and L. P. Perera, “Ship behavior prediction via trajectory\nextraction-based clustering for maritime situation awareness,” Journal of\nOcean Engineering and Science, Mar. 2021.\n[17] J. Park, J. Jeong, and Y . Park, “Ship trajectory prediction based on bi-\nLSTM using spectral-clustered AIS data,” Journal of Marine Science and\nEngineering, vol. 9, no. 9, p. 1037, 2021, iSBN: 2077-1312 Publisher:\nMDPI.\n[18] S. Capobianco, L. M. Milleﬁori, N. Forti, P. Braca, and P. Willett, “Deep\nLearning Methods for Vessel Trajectory Prediction based on Recurrent\nNeural Networks,” IEEE Transactions on Aerospace and Electronic Sys-\ntems, pp. 1–1, 2021, conference Name: IEEE Transactions on Aerospace\nand Electronic Systems.\n[19] B. Murray and L. P. Perera, “An AIS-based deep learning framework\nfor regional ship behavior prediction,” Reliability Engineering & System\nSafety, p. 107819, May 2021.\n[20] L. M. Milleﬁori, G. Pallotta, P. Braca, S. Horn, and K. Bryan, “Validation\nof the Ornstein-Uhlenbeck route propagation model in the Mediterranean\nSea,” inOCEANS 2015 - Genova, May 2015, pp. 1–6.\n[21] L. M. Milleﬁori, P. Braca, K. Bryan, and P. Willett, “Modeling vessel kine-\nmatics using a stochastic mean-reverting process for long-term prediction,”\nIEEE Transactions on Aerospace and Electronic Systems , vol. 52, no. 5,\npp. 2313–2330, Oct. 2016.\n[22] A. Rudenko, L. Palmieri, M. Herman, K. M. Kitani, D. M. Gavrila,\nand K. O. Arras, “Human motion trajectory prediction: a survey,” The\nInternational Journal of Robotics Research , vol. 39, no. 8, pp. 895–935,\nJul. 2020, publisher: SAGE Publications Ltd STM.\n[23] H. Zhao, J. Gao, T. Lan, C. Sun, B. Sapp, B. Varadarajan, Y . Shen,\nY . Shen, Y . Chai, C. Schmid, C. Li, and D. Anguelov, “TNT: Target-driven\nTrajectory Prediction,” in Proceedings of the 2020 Conference on Robot\nLearning. PMLR, Oct. 2021, pp. 895–904, iSSN: 2640-3498.\n[24] F. Leon and M. Gavrilescu, “A Review of Tracking and Trajectory Pre-\ndiction Methods for Autonomous Driving,” Mathematics, vol. 9, no. 6, p.\n660, Jan. 2021, number: 6 Publisher: Multidisciplinary Digital Publishing\nInstitute.\n[25] J. Gu, C. Sun, and H. Zhao, “DenseTNT: End-to-End Trajectory Prediction\nFrom Dense Goal Sets,” 2021, pp. 15 303–15 312.\n[26] A. Gupta, J. Johnson, L. Fei-Fei, S. Savarese, and A. Alahi, “Social GAN:\nSocially Acceptable Trajectories With Generative Adversarial Networks,”\n2018, pp. 2255–2264.\n[27] A. Vemula, K. Muelling, and J. Oh, “Social Attention: Modeling Attention\nin Human Crowds,” in 2018 IEEE International Conference on Robotics\nand Automation (ICRA), May 2018, pp. 4601–4607, iSSN: 2577-087X.\n[28] A. Sadeghian, V . Kosaraju, A. Sadeghian, N. Hirose, H. Rezatoﬁghi, and\nS. Savarese, “SoPhie: An Attentive GAN for Predicting Paths Compliant\nto Social and Physical Constraints,” 2019, pp. 1349–1358.\n[29] T. Zhao, Y . Xu, M. Monfort, W. Choi, C. Baker, Y . Zhao, Y . Wang,\nand Y . N. Wu, “Multi-Agent Tensor Fusion for Contextual Trajectory\nPrediction,” 2019, pp. 12 126–12 134.\n[30] T. Salzmann, B. Ivanovic, P. Chakravarty, and M. Pavone, “Trajectron++:\nDynamically-Feasible Trajectory Forecasting With Heterogeneous Data,”\narXiv:2001.03093 [cs], Jan. 2021, arXiv: 2001.03093.\n[31] R. W. Liu, M. Liang, J. Nie, Y . Yuan, Z. Xiong, H. Yu, and N. Guizani,\n“STMGCN: Mobile Edge Computing-Empowered Vessel Trajectory Pre-\ndiction Using Spatio-Temporal Multigraph Convolutional Network,”IEEE\nTransactions on Industrial Informatics , vol. 18, no. 11, pp. 7977–7987,\nNov. 2022, conference Name: IEEE Transactions on Industrial Informat-\nics.\nVOLUME x, 2016 13\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\n[32] R. W. Liu, M. Liang, J. Nie, W. Y . B. Lim, Y . Zhang, and M. Guizani,\n“Deep Learning-Powered Vessel Trajectory Prediction for Improving\nSmart Trafﬁc Services in Maritime Internet of Things,”IEEE Transactions\non Network Science and Engineering , vol. 9, no. 5, pp. 3080–3094, Sep.\n2022, conference Name: IEEE Transactions on Network Science and\nEngineering.\n[33] P. Coscia, P. Braca, L. M. Milleﬁori, F. A. N. Palmieri, and P. Willett,\n“Multiple Ornstein-Uhlenbeck Processes for Maritime Trafﬁc Graph Rep-\nresentation,”IEEE Transactions on Aerospace and Electronic Systems, pp.\n1–1, 2018.\n[34] I. Varlamis, K. Tserpes, M. Etemad, A. S. JÃºnior, and S. Matwin,\n“A Network Abstraction of Multi-vessel Trajectory Data for Detecting\nAnomalies.” inEDBT/ICDT Workshops, 2019.\n[35] R. Bosnjak, L. Simunovic, and Z. Kavran, “Automatic identiﬁcation\nsystem in maritime trafﬁc and error analysis,” Transactions on maritime\nscience, vol. 1, no. 02, pp. 77–84, 2012, iSBN: 1848-3305 Publisher:\nPomorski fakultet u Splitu.\n[36] Y . Suo, W. Chen, C. Claramunt, and S. Yang, “A Ship Trajectory Predic-\ntion Framework Based on a Recurrent Neural Network,” Sensors, vol. 20,\nno. 18, p. 5133, Jan. 2020, number: 18 Publisher: Multidisciplinary Digital\nPublishing Institute.\n[37] L. P. Perera, P. Oliveira, and C. G. Soares, “Maritime Trafﬁc Monitoring\nBased on Vessel Detection, Tracking, State Estimation, and Trajectory\nPrediction,” IEEE Transactions on Intelligent Transportation Systems ,\nvol. 13, no. 3, pp. 1188–1200, Sep. 2012.\n[38] S. Fossen and T. I. Fossen, “Extended Kalman Filter Design and Motion\nPrediction of Ships Using Live Automatic Identiﬁcation System (AIS)\nData,” in 2018 2nd European Conference on Electrical Engineering and\nComputer Science (EECS), Dec. 2018, pp. 464–470.\n[39] X. Zhang, X. Fu, Z. Xiao, H. Xu, and Z. Qin, “Vessel Trajectory Pre-\ndiction in Maritime Transportation: Current Approaches and Beyond,”\nIEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 11,\npp. 19 980–19 998, Nov. 2022, conference Name: IEEE Transactions on\nIntelligent Transportation Systems.\n[40] C. Wang, H. Ren, and H. Li, “Vessel trajectory prediction based on\nAIS data and bidirectional GRU,” in 2020 International Conference on\nComputer Vision, Image and Deep Learning (CVIDL), Jul. 2020, pp. 260–\n264.\n[41] W. Li, C. Zhang, J. Ma, and C. Jia, “Long-term Vessel Motion Predication\nby Modeling Trajectory Patterns with AIS Data,” in2019 5th International\nConference on Transportation Information and Safety (ICTIS) , Jul. 2019,\npp. 1389–1394.\n[42] H. Tang, Y . Yin, and H. Shen, “A model for vessel trajectory prediction\nbased on long short-term memory neural network,”Journal of Marine En-\ngineering & Technology, vol. 0, no. 0, pp. 1–10, Sep. 2019, publisher: Tay-\nlor & Francis _eprint: https://doi.org/10.1080/20464177.2019.1665258.\n[43] D. Nguyen, R. Vadaine, G. Hajduch, R. Garello, and R. Fablet, “A Multi-\ntask Deep Learning Architecture for Maritime Surveillance using AIS\nData Streams,” in 2018 IEEE International Conference on Data Science\nand Advanced Analytics (DSAA), Oct. 2018.\n[44] G. Pallotta, M. Vespe, and K. Bryan, “Vessel Pattern Knowledge Discovery\nfrom AIS Data: A Framework for Anomaly Detection and Route Predic-\ntion,”Entropy, vol. 15, no. 6, pp. 2218–2245, Jun. 2013.\n[45] D. Nguyen, R. Vadaine, G. Hajduch, R. Garello, and R. Fablet,\n“GeoTrackNet-A Maritime Anomaly Detector using Probabilistic Neural\nNetwork Representation of AIS Tracks and A Contrario Detection,”IEEE\nTransactions on Intelligent Transportation Systems, Feb. 2021.\n[46] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nÅ. Kaiser, and I. Polosukhin, “Attention is All you Need,” in Advances in\nNeural Information Processing Systems, vol. 30. Curran Associates, Inc.,\n2017.\n[47] Y . LeCun, Y . Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521,\nno. 7553, pp. 436–444, May 2015.\n[48] I. Goodfellow, Y . Bengio, and A. Courville, Deep learning. MIT press,\n2016.\n[49] D. P. Kingma and M. Welling, “Auto-Encoding Variational Bayes,”\narXiv:1312.6114 [cs, stat], Dec. 2013, arXiv: 1312.6114.\n[50] D. J. Rezende and S. Mohamed, “Variational inference with normalizing\nﬂows,” arXiv preprint arXiv:1505.05770, 2015.\n[51] Y . Pu, Z. Gan, R. Henao, X. Yuan, C. Li, A. Stevens, and L. Carin, “Varia-\ntional Autoencoder for Deep Learning of Images, Labels and Captions,”\nin Advances in Neural Information Processing Systems 29 , D. D. Lee,\nM. Sugiyama, U. V . Luxburg, I. Guyon, and R. Garnett, Eds. Curran\nAssociates, Inc., 2016, pp. 2352–2360.\n[52] A. Vahdat and J. Kautz, “NV AE: A Deep Hierarchical Variational Autoen-\ncoder,” in Advances in Neural Information Processing Systems , vol. 33.\nCurran Associates, Inc., 2020, pp. 19 667–19 679.\n[53] A. Ng, “Sparse autoencoder,” CS294A Lecture notes, vol. 72, no. 2011, pp.\n1–19, 2011.\n[54] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving\nLanguage Understanding by Generative Pre-Training,” p. 12, 2018.\n[55] M. Phuong and M. Hutter, “Formal Algorithms for Transformers,” arXiv\npreprint arXiv:2207.09238, 2022.\n[56] P. Dijt and P. Mettes, “Trajectory Prediction Network for Future Antici-\npation of Ships,” in Proceedings of the 2020 International Conference on\nMultimedia Retrieval, ser. ICMR ’20. New York, NY , USA: Association\nfor Computing Machinery, Jun. 2020, pp. 73–81.\n[57] I. Loshchilov and F. Hutter, “Decoupled Weight Decay Regularization,”\narXiv:1711.05101 [cs, math], Jan. 2019, arXiv: 1711.05101.\n[58] ——, “SGDR: Stochastic Gradient Descent with Warm Restarts,”\narXiv:1608.03983 [cs, math], May 2017, arXiv: 1608.03983.\n[59] D. Nguyen, M. Simonin, G. Hajduch, R. Vadaine, C. Tedeschi, and\nR. Fablet, “Detection of Abnormal Vessel Behaviors from AIS data using\nGeoTrackNet: from the Laboratory to the Ocean,” in 21st IEEE Interna-\ntional Conference on Mobile Data Management (MDM), 2020.\n[60] J. Gehring, M. Auli, D. Grangier, D. Yarats, and Y . N. Dauphin, “Convo-\nlutional Sequence to Sequence Learning,” in International Conference on\nMachine Learning. PMLR, Jul. 2017, pp. 1243–1252, iSSN: 2640-3498.\n[61] J. Chung, K. Kastner, L. Dinh, K. Goel, A. Courville, and Y . Bengio,\n“A Recurrent Latent Variable Model for Sequential Data,” in Advances\nin neural information processing systems, Jun. 2015, pp. 2980–2988.\n[62] C. A. Blance, Norie’s Nautical Tables. Imray, Laurie, Norie and Wilson\nLtd, 2019.\n[63] Z. Xiao, X. Fu, L. Zhang, and R. S. M. Goh, “Trafﬁc Pattern Mining\nand Forecasting Technologies in Maritime Trafﬁc Service Networks: A\nComprehensive Survey,”IEEE Transactions on Intelligent Transportation\nSystems, vol. 21, no. 5, pp. 1796–1825, May 2020, conference Name: IEEE\nTransactions on Intelligent Transportation Systems.\n[64] A. Adadi and M. Berrada, “Peeking Inside the Black-Box: A Survey\non Explainable Artiﬁcial Intelligence (XAI),” IEEE Access , vol. 6, pp.\n52 138–52 160, 2018, conference Name: IEEE Access.\n[65] A. Barredo Arrieta, N. DÃaz-RodrÃguez, J. Del Ser, A. Bennetot,\nS. Tabik, A. Barbado, S. Garcia, S. Gil-Lopez, D. Molina, R. Benjamins,\nR. Chatila, and F. Herrera, “Explainable Artiﬁcial Intelligence (XAI):\nConcepts, taxonomies, opportunities and challenges toward responsible\nAI,”Information Fusion, vol. 58, pp. 82–115, Jun. 2020.\n[66] P. Molchanov, A. Mallya, S. Tyree, I. Frosio, and J. Kautz, “Im-\nportance Estimation for Neural Network Pruning,” arXiv, Tech. Rep.\narXiv:1906.10771, Jun. 2019, arXiv:1906.10771 [cs, stat] type: article.\n[67] J. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge Distillation: A\nSurvey,” International Journal of Computer Vision , vol. 129, no. 6, pp.\n1789–1819, Jun. 2021.\n[68] S. Benaichouche, C. Le Goff, Y . Guichoux, F. Rousseau, and R. Fablet,\n“Unsupervised Reconstruction of Sea Surface Currents from AIS Maritime\nTrafﬁc Data Using Learnable Variational Models,” in ICASSP 2021 -\n2021 IEEE International Conference on Acoustics, Speech and Signal\nProcessing (ICASSP), Jun. 2021, pp. 4100–4104, iSSN: 2379-190X.\n[69] S. Benaichouche, C. Legoff, Y . Guichoux, F. Rousseau, and R. Fablet,\n“Unsupervised Reconstruction of Sea Surface Currents from AIS Mar-\nitime Trafﬁc Data Using Trainable Variational Models,” Remote Sensing,\nvol. 13, no. 16, p. 3162, Jan. 2021, number: 16 Publisher: Multidisciplinary\nDigital Publishing Institute.\n[70] B. Ivanovic and M. Pavone, “The Trajectron: Probabilistic Multi-Agent\nTrajectory Modeling With Dynamic Spatiotemporal Graphs,” in 2019\nIEEE/CVF International Conference on Computer Vision (ICCV). Seoul,\nKorea (South): IEEE, Oct. 2019, pp. 2375–2384.\n[71] H. Akaike, “Information theory and an extension of the maximum likeli-\nhood principle,” in Selected papers of hirotugu akaike . Springer, 1998,\npp. 199–213.\n[72] G. Schwarz, “Estimating the dimension of a model,” The annals of\nstatistics, pp. 461–464, 1978, iSBN: 0090-5364 Publisher: JSTOR.\n[73] E. J. Hannan and B. G. Quinn, “The determination of the order of\nan autoregression,” Journal of the Royal Statistical Society: Series B\n(Methodological), vol. 41, no. 2, pp. 190–195, 1979, iSBN: 0035-9246\nPublisher: Wiley Online Library.\n[74] K. P. Burnham and D. R. Anderson, “Model selection and multimodel\ninference,”A practical information-theoretic approach, vol. 2, 2004.\n14 VOLUME x, 2016\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nDuong Nguyen and Ronan Fablet: TrAISformer\n[75] U. Anders and O. Korn, “Model selection in neural networks,” Neural\nnetworks, vol. 12, no. 2, pp. 309–323, 1999, iSBN: 0893-6080 Publisher:\nElsevier.\n[76] S. Arora, N. Cohen, and E. Hazan, “On the optimization of deep networks:\nImplicit acceleration by overparameterization,” in International Confer-\nence on Machine Learning. PMLR, 2018, pp. 244–253.\n[77] Z. Allen-Zhu, Y . Li, and Z. Song, “A convergence theory for deep learning\nvia over-parameterization,” inInternational conference on machine learn-\ning. PMLR, 2019, pp. 242–252.\nDUONG NGUYEN received the Diplôme\nd’Ingénieur in machine learning from Télécom\nBretagne, the M.Sc. degree (summa cum laude) in\nsignal and image processing from the University\nof Rennes 1, and the Ph.D. degree in machine\nlearning from IMT Atlantique. His research inter-\nests focus on the study of machine learning (deep\nlearning) for time series modeling and analysis,\nwith applications to dynamical system identiﬁca-\ntion and maritime trafﬁc surveillance.\nDuong Nguyen has published several papers on vessel trajectory analysis\nand anomaly detection. One of them has gained widespread adoption in\nindustry and is being used as the foundation model to build maritime trafﬁc\nanomaly detection systems.\nRONAN FABLETgraduated with MSc. and En-\ngineer degrees in Space Aeronautics and Applied\nMath from ISAE/SUPAERO in 1997 and with a\nPhD in Signal Processing and Computer Vision\nfrom University of Rennes/INRIA in 2001. After\nan INRIA postdoctoral fellowship with Brown\nUniversity (RI, USA), he was a full-time research\nscientist at Ifremer (the French Institute for Sea\nResearch) from 2003 to 2007. He joined IMT\nAtlantique in 2008 and currently holds a Professor\nposition in the Mathematical and Electrical Engineering Department. He\nhas been developing research activities at the interface between signal\nprocessing, machine learning and marine science. He has led national and\ninternational programs (e.g., EU STREP AFISA, ANR MN EMOCEAN,\nANR ASTRID SESAME) and co-authored more than 200 articles and com-\nmunications in peer-reviewed conferences and journals. His current research\ninterest covers physics-informed deep learning, data-driven approaches to\ninverse problems, ocean remote sensing, and maritime surveillance.\nVOLUME x, 2016 15\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3349957\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7154527306556702
    },
    {
      "name": "Automatic Identification System",
      "score": 0.6174045205116272
    },
    {
      "name": "Trajectory",
      "score": 0.5235226154327393
    },
    {
      "name": "Cross entropy",
      "score": 0.5179244875907898
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4810936152935028
    },
    {
      "name": "Representation (politics)",
      "score": 0.4752233624458313
    },
    {
      "name": "Transformer",
      "score": 0.42461562156677246
    },
    {
      "name": "Data mining",
      "score": 0.3816990852355957
    },
    {
      "name": "Machine learning",
      "score": 0.3618847727775574
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.2193574607372284
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Astronomy",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210127572",
      "name": "IMT Atlantique",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210123702",
      "name": "Laboratoire des Sciences et Techniques de l’Information de la Communication et de la Connaissance",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I161929037",
      "name": "Université de Bretagne Occidentale",
      "country": "FR"
    }
  ],
  "cited_by": 43
}