{
  "title": "TGEA: An Error-Annotated Dataset and Benchmark Tasks for TextGeneration from Pretrained Language Models",
  "url": "https://openalex.org/W3174445427",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2101486419",
      "name": "Jie He",
      "affiliations": [
        "Tianjin University"
      ]
    },
    {
      "id": "https://openalex.org/A1969033575",
      "name": "Bo Peng",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2096215548",
      "name": "Yi Liao",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2109590494",
      "name": "Qun Liu",
      "affiliations": [
        "Huawei Technologies (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2139156831",
      "name": "Deyi Xiong",
      "affiliations": [
        "Tianjin University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2891012317",
    "https://openalex.org/W2998696444",
    "https://openalex.org/W2766078582",
    "https://openalex.org/W3030258889",
    "https://openalex.org/W3175363122",
    "https://openalex.org/W2990704537",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W3035010485",
    "https://openalex.org/W3022814719",
    "https://openalex.org/W2964079512",
    "https://openalex.org/W2996403597",
    "https://openalex.org/W2963115613",
    "https://openalex.org/W3035733645",
    "https://openalex.org/W2995643077",
    "https://openalex.org/W3035372073",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W3033187248",
    "https://openalex.org/W2589277916",
    "https://openalex.org/W3035027743",
    "https://openalex.org/W3103543556",
    "https://openalex.org/W2997763445",
    "https://openalex.org/W2963310665",
    "https://openalex.org/W3114651185",
    "https://openalex.org/W3100590161",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3099771192",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W3122890974",
    "https://openalex.org/W2946609015",
    "https://openalex.org/W3001393026",
    "https://openalex.org/W2996908057",
    "https://openalex.org/W2936695845",
    "https://openalex.org/W2153013403",
    "https://openalex.org/W2739046565",
    "https://openalex.org/W4288262459",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W2810578980",
    "https://openalex.org/W2998617917",
    "https://openalex.org/W3102725307",
    "https://openalex.org/W3098495697",
    "https://openalex.org/W3034446185",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3106859150",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W4287608575",
    "https://openalex.org/W3114083009",
    "https://openalex.org/W3101068439",
    "https://openalex.org/W2943552823",
    "https://openalex.org/W2996728628",
    "https://openalex.org/W2970062726",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W2517375502",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W2970780738",
    "https://openalex.org/W1599016936",
    "https://openalex.org/W3098903812",
    "https://openalex.org/W2951936329",
    "https://openalex.org/W2972799129",
    "https://openalex.org/W2886474102",
    "https://openalex.org/W2124725212",
    "https://openalex.org/W2970419734",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2963204221",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2971141916",
    "https://openalex.org/W3035164567",
    "https://openalex.org/W2145755360"
  ],
  "abstract": "Jie He, Bo Peng, Yi Liao, Qun Liu, Deyi Xiong. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.",
  "full_text": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natural Language Processing, pages 6012–6025\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6012\nTGEA: An Error-Annotated Dataset and Benchmark Tasks for Text\nGeneration from Pretrained Language Models\nJie He†∗, Bo Peng§∗, Yi Liao§, Qun Liu§and Deyi Xiong†\n†College of Intelligence and Computing, Tianjin University, Tianjin, China\n§Huawei Noah’s Ark Lab, Hong Kong, China\n{jieh, dyxiong}@tju.edu.cn,\n{peng.bo2, liaoyi9, qun.liu}@huawei.com\nAbstract\nIn order to deeply understand the capability\nof pretrained language models in text genera-\ntion and conduct a diagnostic evaluation, we\npropose TGEA 1, an error-annotated dataset\nwith multiple benchmark tasks for text genera-\ntion from pretrained language models (PLMs).\nWe use carefully selected prompt words to\nguide GPT-2 to generate candidate sentences,\nfrom which we select 47K for error annota-\ntion. Crowdsourced workers manually check\neach of these sentences and detect 12k erro-\nneous sentences. We create an error taxon-\nomy to cover 24 types of errors occurring in\nthese erroneous sentences according to the na-\nture of errors with respect to linguistics and\nknowledge (e.g., common sense). For each\nerroneous span in PLM-generated sentences,\nwe also detect another span that is closely as-\nsociated with it. Each error is hence manu-\nally labeled with comprehensive annotations,\nincluding the span of the error, the associated\nspan, minimal correction to the error, the type\nof the error, and rationale behind the error.\nApart from the fully annotated dataset, we also\npresent a detailed description of the data col-\nlection procedure, statistics and analysis of the\ndataset. This is the ﬁrst dataset with compre-\nhensive annotations for PLM-generated texts,\nwhich facilitates the diagnostic evaluation of\nPLM-based text generation. Furthermore, we\nuse TGEA as a benchmark dataset and propose\na series of automatic diagnosis tasks, includ-\ning error detection, error type classiﬁcation, as-\nsociated span detection, error rationale genera-\ntion, to further promote future study on the au-\ntomatic error detection and correction on texts\ngenerated by pretrained language models.\n∗Equal Contributions.\n1The The dataset is available at\nhttps://download.mindspore.cn/dataset/TGEA/.\n1 Introduction\nPretrained language models (Devlin et al., 2019;\nLiu et al., 2019; Raffel et al., 2020; Brown et al.,\n2020), which are trained on a huge amount of data\nvia self-supervised learning, have made remarkable\nprogress on both natural language understanding\n(NLU) (Wang et al., 2018, 2019) and natural lan-\nguage generation (NLG) (Liu and Lapata, 2019;\nWeng et al., 2020; Cao et al., 2020).\nOn several NLU datasets, PLM-based neural\nmodels have gradually achieved human-level per-\nformance in terms of automatic evaluation met-\nrics (e.g., accuracy, F1) (He et al., 2020; Zhang\net al., 2021). In order to deeply understand and\nanalyze the capability of PLMs on NLU, a variety\nof more challenging NLU datasets have been pro-\nposed (Warstadt et al., 2020; Cui et al., 2020a; Jain\net al., 2020; Talmor et al., 2020). These datasets\ncan be used not only to obtain knowledge on how\nPLM-based models work and what they learn, but\nalso to deﬁne new NLU tasks and to serve as a\nbenchmark for future progress. For example, evalu-\nating and analyzing PLM-based models on learning\ndocument structures with a carefully created bench-\nmark test suite (Chen et al., 2019), helps to develop\nnew methods to enhance the capability of these\nmodels on discourse modeling (Iter et al., 2020).\nKnowing the weakness of current PLM-based mod-\nels in commonsense reasoning (Zhou et al., 2020)\nhas inspired people to develop various reasoning\ndatasets (Cui et al., 2020a; Zhang et al., 2020b).\nOn the other hand, state-of-the-art PLMs are\nable to generate texts that are even not distinguish-\nable from human-written texts by human evaluators\n(Radford et al., 2019; Brown et al., 2020). This\nmakes us curious about the capability of PLMs on\ntext generation. Are they really reaching human-\nlevel performance on text generation? In contrast\nto the studies of PLMs on NLU, research on the\n6013\ncapability of PLMs on NLG is quite limited, espe-\ncially in dataset building and diagnostic evaluation\nof text generation errors.\nIn this paper, in order to recognize the perime-\nter of text generation capability of PLMs, we pro-\npose TGEA, an error-annotated dataset with multi-\nple benchmark tasks for text generation from pre-\ntrained language models. The original raw data are\ncollected from texts generated by a Chinese GPT-2\nmodel. The entire data collection and annotation\nprocedure is visualized in Figure 1. The goals and\ncontributions of building TGEA are as follows.\n• TGEA, to the best of our knowledge, is the\nﬁrst dataset built on machine-generated texts\nfrom state-of-the-art pretrained language mod-\nels with rich annotations. The key interest of\nthis dataset is detecting and annotating text\ngeneration errors from PLMs. Therefore it\nis different from conventional text genera-\ntion datasets (e.g., Multi-News (Fabbri et al.,\n2019), TextCaps (Sidorov et al., 2020)) that\nare constructed to train models to learn text\ngeneration (e.g., generating texts from images\nor long documents). It is also different from\ngrammatical error correction (GEC) datasets\n(Zhao et al., 2018; Flachs et al., 2020) that\nare built from human-written texts usually by\nsecond language learners.\n• TGEA provides rich semantic information for\ntext generation errors, including error types,\nassociated text spans, error corrections and\nrationals behind errors, as shown in Figure\n1. Marking text spans that are closely related\nto erroneous words allows us to detect long-\ndistance dependencies of errors or reasoning\nchains related to errors. Rationales behind er-\nrors directly explain why errors are annotated.\nAll these error-centered manual annotations\nnot only increase the interpretability of our\ndataset, but also facilitate a comprehensive\ndiagnostic evaluation of pretrained language\nmodels on text generation.\n• We created an error taxonomy for TGEA,\nwhich covers 24 error types in a two-level\nhierarchy. With this error taxonomy, we not\nonly obtain a high agreement on manual er-\nror annotation but also recognize the strengths\nand weaknesses of GPT-2 on text generation\nby estimating a distribution over these 24 er-\nror types. Comparing our dataset with GEC\ndatasets, we ﬁnd that humans and GPT-2 have\nTL_[ PYVTW[: \nCVYYec[\nIUcVYYec[\n④ EYYVY [`We \nCSaZZifica[iVU\n②\u0000EYYVUeV\\Z aUd   AZZVcia[ed SWaU\n     De[ec[iVU\n③\u0000EYYVY cVYYec[iVU\n ⑤ Ra[iVUaS GeUeYa[iVU\nCOPULZL \nGPT-2\n揇䌅⎎⬆䪯䭽别不同。\nShoW pXW and archer\\ are of \ndifferenW caWegorieV.\n㓧㘮䖆⬆䪯廒动员☪⡵⩒揇䌅㫖屝中効⺙冠军。\nJapanese archery players won the championship in women's shot \nput competition.\n㓧㘮䖆⬆䪯廒动员☪⡵⩒揇䌅\n㫖屝中効⺙冠军。\nJapanese archery players won the \nchampionship in women's shot \nput competition.\n㓧㘮䖆揇䌅廒动员☪⡵⩒揇䌅㫖屝\n中効⺙冠军。\nJapanese shot putters won the \nchampionship in women's shot put \ncompetition.\n㓧㘮\nJapan\n䭽别不匹恏\nCategory \nmismatch\nTe_[ GeUeYa[iVU\n①\u0000EYYVUeV\\Z Te_[\n     De[ec[iVU\nFigure 1: The different stages of the annotation pro-\ncess for each machine-generated text according to the\nprompt in TGEA. Better viewed in color.\na very different error distribution, especially\non errors related to commonsense reasoning.\n• TGEA not only exhibits text generation errors\nfrom pretrained language models, but also can\nserve as a dataset to train various models to\nautomatically detect and correct these errors,\nlike GEC datasets for training models to au-\ntomatically correct human errors. We deﬁne\n5 benchmark tasks over our dataset, i.e., er-\nroneous sentence detection, erroneous span\nand associated span detection, error type clas-\nsiﬁcation, error correction and error rationale\ngeneration. For all these tasks, we provide ex-\nperimental results using state-of-the-art mod-\nels as baselines.\n2 Related Work\nOur work is related to GEC datasets in error annota-\ntion and correction (machine vs. human errors). It\nis also partially related to commonsense reasoning\ndatasets that have been proposed recently in that\nour dataset includes commonsense reasoning errors\nand rationales behind these errors. Our dataset is\nnot related to conventional text generation datasets\n(V ougiouklis et al., 2017; Wiseman et al., 2017;\nParikh et al., 2020) for training text generation mod-\nels. A comprehensive comparison to GEC datasets\nand commonsense reasoning datasets is shown in\nTable 1.\n6014\nDataset Task Commonsense\nReasoning Rationales Machine-Generated\nTexts Domain #Sentences Language\nFCE GEC \u0016 \u0016 \u0016 Essay 34K EN\nAESW GEC \u0016 \u0016 \u0016 Journal articles 1.2M EN\nJFLEG GEC \u0016 \u0016 \u0016 TOFEL Exam 1,511 EN\nCMEG GEC \u0016 \u0016 \u0016 Web doc/Essay 8K EN\nCWEB GEC \u0016 \u0016 \u0016 Web doc 13K EN\nCGEC GEC \u0016 \u0016 \u0016 Essay 0.71M ZH\nWSC Coreference Resolution \u0013 \u0016 \u0016 Open 273 EN\nHellaSwag Plausible Inference \u0013 \u0016\n WikiHow articles 70K EN\nSocial IQA Question Answering \u0013 \u0016 \u0016 Social situations 38K EN\nCosmosQA Reading comprehension \u0013 \u0016 \u0016 Narratives 35K EN\nPIQA Plausible Inference \u0013 \u0016 \u0016 Physical situations 21K EN\nAbductive NLI Plausible Inference \u0013 \u0016 \u0016 ROCStories 200K EN\nWinoWhy Reason Explanation \u0013 \u0013\n Open 2,865 EN\nTGEA (ours) Multiple tasks\n \u0013 \u0013 Open 47K ZH\nTable 1: Comparison between our dataset and other datasets.\n2.1 Grammatical Error Correction Datasets\nFCE (Yannakoudakis et al., 2011) is an early large-\nscale English grammatical error correction dataset,\nwhere raw texts are produced by English learn-\ners taking the First Certiﬁcate in English exams.\nAESW (Daudaravicius et al., 2016) is a GEC\ndataset from a professional editing company. In\naddition to common grammatical errors, AESW\ncovers style issues as it contains texts mainly from\nscholarly papers. JFLEG (Napoles et al., 2017) is a\nGEC dataset built from TOFEL Exams, which does\nnot force annotators to make minimal edits, prefer-\nring holistic ﬂuency rewrites. CMEG (Napoles\net al., 2019) is different from general grammatical\nerror correction datasets with texts from second\nlanguage learners. It uses articles or blogs (e.g.,\nWiki, Yahoo)) written by native English speakers\nto explore grammatical error phenomena in dif-\nferent domains. CWEB (Flachs et al., 2020) also\nuses website texts in English, such as blogs. The\ndifference between CWEB and CMEG is that the\npercentage of erroneous tokens in the former is\nsmaller than the latter as the purpose of CWEB is\nto study grammatical error correction in low error\ndensity domains. CGEC (Zhao et al., 2018) is a\nlarge-scale Chinese grammatical error correction\ndataset, derived from wrong sentences written by\nChinese learners in the process of learning Chinese\nas a second language.\nIn addition to the difference in text sources (i.e.,\nhuman-written vs. machine-generated), other sig-\nniﬁcant differences between our dataset and ex-\nisting GEC datasets are that our dataset contains\ncommonsense reasoning errors and provides associ-\nated text span annotations and rationales for errors,\nas shown in Table 1.\n2.2 Commonsense Datasets\nA variety of commonsense datasets have been pro-\nposed. Roemmele et al. (2011) introduce COPA\nthat focuses on commonsense causal reasoning.\nLevesque et al. (2012) present Winograd Scheme\nChallenge (WSC), a dataset testing commonsense\nreasoning in the form of anaphora resolution. Wino-\ngrande, a larger version of WSC, is introduced by\nSakaguchi et al. (2020), which contains ∼44, 000\nexamples. Winowhy (Zhang et al., 2020a) asks\nannotators to provide reasons for their decisions to\nWSC. In this aspect, the differences of our dataset\nfrom Winowhy are twofold. First, we provide\nreasons for errors rather than correct decisions to\nanaphora. Second, we provide reasons for all text\ngeneration errors, rather than only errors related to\ncommonsense reasoning.\nIn addition to COPA and WSC-style datasets,\nmany large crowdsourced datasets have been also\nproposed recently. CommonsenseQA (Talmor\net al., 2019), a commonsense question answering\ndataset, has been constructed from ConceptNet.\nHellaSwag (Zellers et al., 2019b) and Abductive\nNLI (Bhagavatula et al., 2020) evaluate common-\nsense reasoning in the form of natural language\ninference. CosmosQA (Huang et al., 2019) is a\ndataset with multi-choice questions that require\ncommonsense reading comprehension.\nBeyond datasets for evaluating commonsense\nreasoning, there are other datasets providing com-\nmonsense knowledge. PIQA (Bisk et al., 2020) fo-\ncuses on physical commonsense knowledge while\nSocialIQA (Sap et al., 2019) on social common-\nsense knowledge.\nCommonsense datasets in multiple languages or\nlanguages other than English have also been cre-\nated recently. XCOPA (Ponti et al., 2020) is a mul-\ntilingual dataset for causal commonsense reasoning\nin 11 typologically different languages. Chinese\n6015\nLevel-1 Error Type Example\nInappropriate combination 医生当即将刘莉的:::手术[囊肿]切除，并建议患者住院观察。\nThe doctor removed Liu Li’s::::::surgery [tumor] and suggested that the patient be hospitalized\nfor observation.\nMissing 在这里,有众多新闻记者和游客参加:[活动]。\nHere, many journalists and tourists are taking part in::[activities].\nRedundancy 一些企业减员::::增效[]增效,使得企业利润增长了10%以上。\nSome enterprises have reduced staff and ::::::increased::::::::efﬁciency[] increased efﬁciency, making\ntheir proﬁts increase by more than 10%.\nDiscourse Error 他说自己最喜欢安阳的乡间小路，是最美的::::山峦[路]。\nHe said that he likes the country roads in Anyang best, and it is the most beautiful\n:::::::mountain [road].\nCommonsense Error 在国际市场上，如果信用等级越::高 [低]，投资者在投资时就越不会太放心。\nIn the international market, the ::::higher [lower] the credit rating, the less reassured\ninvestors are.\nTable 2: Examples of level-1 error types in TGEA. Underwaved words are erroneous words while underlined\nwords are associated words. Words in “[]” are corrections to erroneous words.\ncommonsense datasets, such as Mandarinograd\n(Bernard and Han, 2020) consisting of 154 Chinese\nWinograd scheme examples and CLUEWSC2020\n(Xu et al., 2020) containing 1838 Winograd scheme\nexamples, have been proposed.\nIn the aspect of commonsense reasoning, our\ndataset is different from the mentioned common-\nsense datasets in that we detect and annotate errors\nin machine-generated texts, which violates com-\nmon sense, rather than creating examples to exam-\nine the commonsense reasoning ability of machines.\n3 Dataset Creation\n3.1 Error Taxonomy\nBefore crowdsourced workers manually annotate\nerrors in machine-generated texts, we need to cre-\nate an error taxonomy for such error coding. Three\nprinciples are used to guide the design of the er-\nror taxonomy: coverage, exclusiveness and eas-\niness. The coverage rule requires that the error\nsystem can cover almost all different types of er-\nrors in machine-generated texts. The exclusiveness\nrequirement indicates that each error type is not\noverlapping with other error types in the taxonomy.\nThe ﬁnal easiness principle means that the error\ncoding system is easy to be used by annotators.\nWith these three principles and aid from a linguist,\nwe created an error taxonomy in a two-level hi-\nerarchy, which was revised in our pre-annotation\nstage.\nThe ﬁrst level of the error taxonomy includes 5\nerror types.\n• Inappropriate combination. This type of er-\nrors suggests that two words/phrases are syn-\ntactically or lexically inappropriately com-\nbined in a sentence. Such errors include not\nonly lexical collocation errors but also long-\ndistance syntactic constituency combination\nerrors (e.g., inappropriate subject-object com-\nbination). This error type is similar to “replac-\ning” error in some GEC datasets (e.g., CWEB\n(Flachs et al., 2020)) as one element of an\ninappropriate combination should be usually\nreplaced with other expressions. As we want\nto ﬁnd text spans associated with erroneous\nwords/phrases, we term this error type as “in-\nappropriate combination”. We further divide\nthis error type into ﬁve subtypes at the second\nlevel.\n• Missing. Grammatical constituencies or\nwords are missing. 5 subtypes are deﬁned\nunder this error type.\n• Redundancy. Words or phrases are unneces-\nsary. 5 subtypes are also deﬁned.\n• Discourse Error. This error type is deﬁned\nfor inter-sentential cohesion/coherence errors\n(e.g., coreference errors, incorrect discourse\nconnectives).\n• Commonsense Error. This error code is for\nerrors related to commonsense reasoning. We\ndivide this error type into 8 subtypes accord-\ning to the type of commonsense knowledge\ntype required (e.g., time, spatial, number).\nAll other errors that cannot be categorized into\nthe aforementioned error types are grouped into\n“Other”. Table 2 displays examples for the above\ndeﬁned error types. 24 error subtypes are displayed\nin Figure 2 and examples of these subtypes are\nshown in Appendix.\n6016\n3.2 Machine-Generated Text Collection\nRaw texts in our dataset are collected from a pre-\ntrained Chinese GPT-2 (NEZHA-Gen)2, which gen-\nerates texts according to a system prompt. NEZHA-\nGen has 12 layers and 12 attention heads and is\ntrained on Chinese Wikipedia and news data (see\nAppendix for more details on the hyperparameters\nof NEZHA-Gen). As it is easy for NEZHA-Gen\nto generate high-quality texts with high-frequency\nprompt words, we create a list of prompt words\naccording to their frequency to guarantee that there\nare sufﬁcient erroneous sentences in collected raw\ntexts. By doing so, we have found that GPT has\na better chance to generate wrong sentences with\nsuch prompts. Speciﬁcally, we have randomly sam-\npled 2M sentences from the data used to train\nNEZHA-Gen. The sampled sentences are then\nword-segmented and POS-tagged by Baidu LAC\ntool3 (Jiao et al., 2018). We then select and sort\nnouns in a descending order according to their fre-\nquencies in the sampled corpus. Nouns ranking\nin the range of top [40%, 60%] are selected as\nprompts.\nWe further ﬁlter out noisy texts from texts gener-\nated with these selected prompts. Noisy texts are\neither texts containing no more than 15 characters\nor texts where Chinese characters account for less\n70% of all characters.\n3.3 Error Annotation\nThere are 5 stages in error annotation, as shown\nin Figure 1. We introduce each of them in this\nsubsection.\n(1) Erroneous text detection. Texts generated\nby NEZHA-Gen with prompt words are present to\nannotators one by one. The ﬁrst stage of annotation\nis hence to detect erroneous texts for subsequent\nannotations. Corresponding tags are annotated for\ntexts being manually checked.\n(2) Erroneous and associated span detection.\nThe next task for annotators is to detect erroneous\nand associated text spans in detected erroneous\ntexts. For erroneous span detection, as a text may\ncontain several spans that can be edited or the text\ncan be corrected in different ways, which span\nshould be regarded as erroneous is closely related\nto the way that we correct the text. Therefore, the\nbasic principle that guides the annotation of erro-\n2github.com/huawei-noah/Pretrained-Language-\nModel/tree/master/NEZHA-Gen-TensorFlow\n3github.com/baidu/lac\nneous spans is also the rule that we use for error\ncorrection: making minimal edits, which is also\nused in GEC datasets (Flachs et al., 2020; Napoles\net al., 2017). In addition to the minimal edit prin-\nciple, we also provide the following speciﬁc rules\nfor annotators:\n• If annotators feel that a text is ambiguous and\nthat it is difﬁcult to correct the text, the text\ncan be discarded without any further annota-\ntions.\n• If there are several spans that can be edited,\nthe ﬁrst erroneous span is preferred to be\nedited.\n• If the number of errors to be corrected in a\ntext is larger than 4, the text is removed.\nFollowing these rules, annotators have removed\n4,291 texts, which account for only 8.36% of all\ndetected erroneous texts in the ﬁrst stage.\nIn addition to erroneous span annotation, unlike\nGEC datasets (Daudaravicius et al., 2016; Zhao\net al., 2018), we also detect a text span that is\nclosely related to the already detected erroneous\nspan with respect to the error, and term this span as\n“associated span”. In Table 2, we show examples\nwith annotated erroneous and associated text spans.\nFor an inappropriate combination, the associated\nspan is usually a span that should not co-occur with\nthe erroneous span.\n(3) Error correction. After detecting erroneous\nspans in a given text, annotators are required to\nmake corrections following the minimal edit prin-\nciple. Annotators are also required to use common\nwords for error correction to make the corrected\ntext as ﬂuent as possible.\n(4) Error type classiﬁcation. Once annotators\ndetect both erroneous and associated spans as well\nas provide corrections, they are becoming quite\naware of these errors. Hence, we now ask them\nto categorize the annotated errors into error types\ndeﬁned in our error taxonomy. First, they select the\nprimary type from the level-1 error types. Then,\nif there are level-2 error subtypes, annotators con-\ntinue to select a subtype. We observe that errors\nannotated with “other” only account for 5.70%,\nsuggesting that our error taxonomy has good cov-\nerage.\n(5) Rationale generation. Partially inspired by\nprevious datasets that provide explanations together\nwith corresponding annotations, e.g., e-SNLI (Cam-\nburu et al., 2018), Winowhy (Zhang et al., 2020a)\n6017\nTask IAA (%) Kappa (%)\nErroneous text detection 87.5 62.1\nErroneous and associated\nspan detection 51.2 –\nError type classiﬁcation 73.3 55.7\nTable 3: Inter-annotator agreement results.\nand R4C (Inoue et al., 2020), we ask annotators\nto give a reason for each error to justify their an-\nnotations. To the best of our knowledge, no GEC\ndatasets provide explanations for error corrections.\nWe believe that annotated rationales can be used\nto improve the interpretability of neural models\ntrained on our dataset.\n3.4 Annotation Quality Control\nIn order to ensure the quality of error annotations,\nwe have adopted a very strict quality control proto-\ncol during annotation. First, we train two reviewers\nwith 1K machine-generated texts. The annotation\nconsistency of the two reviewers on the 1K texts\nis very high, with an average IAA of 92.3% and\nCohen’s Kappa (McHugh, 2012) of 82.6% across\nthe annotation tasks (1), (2) and (4). For the texts\nannotated by the two reviewers, we have conducted\nan evaluation. The average accuracy of all tasks is\n96.3% and 97.4% respectively.\nSecond, 200 candidate workers participate in\na pre-annotation stage. The two reviewers will\nreview annotations from these participants to dis-\ntinguish whether the annotation is correct or not.\nOnly participants who have reached an accuracy of\n>90% in every tasks can join in the next stage. As\na result, 20 participants have passed the training in\nthe pre-annotation stage. We then divide them into\ntwo groups and ask them to annotate the same 500\ntexts. The inter-annotator IAA and Cohen’s Kappa\nare shown in Table 3, which suggests that the 20\nannotators are ready for ﬁnal annotation.\nThird, in order to further ensure annotation qual-\nity, we have carried out iterative veriﬁcation and\namendment. The two reviewers will review each\nannotated text. If they found the annotation is\nwrong, the unqualiﬁed data will be returned for\namendment until they are qualiﬁed.\nFollowing this strict quality control protocol, we\ncomplete the annotation on 47K selected machine-\ngenerated texts. We randomly sample 1K annotated\ntexts. The average accuracy over the three tasks\n(i.e., (1), (2) and (4)) is 89.6%, 88.5%, 84.3% re-\nspectively.\nTrain Dev Test All\n#text 37,646 4,706 4,706 47,058\nw/ 0 error 27,906 3,488 3,488 34,882\nw/ 1 error 8,413 1,055 1,052 10,520\nw/ 2 error 1,169 141 149 1,459\nw/ 3 error 141 18 15 174\nw/ 4 error 17 4 2 23\nTokens 966,765 120,889 121,065 1,208,719\nV ocab 44,598 16,899 16,745 48,547\nAvg. tokens 25.68 25.69 25.73 25.68\nAvg. t.err 2.92 3.09 2.95 2.94\nAvg. t.assoc 4.30 4.39 3.89 4.27\nAvg. d.e-a 6.99 7.29 7.10 7.03\nAvg. t.rationale 8.74 8.72 8.75 8.74\nTable 4: Data statistics of TGEA. Avg.t.err/Avg.t.assoc:\nthe average number of tokens in erroneous/associated\ntext spans. Avg.t.rationale: the average number of to-\nkens in rationales. Avg.d.e-a: the average distance be-\ntween a erroneous span and its associated span.\nTGEA\nIUaWWYVWYPa[L CVTIPUa[PVU\n               25.23%\n       MPZZPUN        8.00%\n      RLK\\UKaUJ` \n          31.62%\nDPZJV\\YZL EYYVY\n      10.48%\nCVTTVUZLUZL EYYVY\n            18.96%\nS\\I-PYLK\nPYLK-OIQ\nS\\I-OIQ\nMVKPMPLY\nF\\UJ[PVU WVYK\nS\\I\nPYLK\nOIQ\nMVKPMPLYF\\UJ[PVU WVYK\nS\\I\nPYLKOIQ\nM\nVKPMPLYF\\UJ[PVU WVYK\nCVYLMLYLUJL\nTPTL\nSWaJL\nN\\TILY\nMV[P]a[PVU\nETV[PVUaS RLaJ[PVU Ca\\Za[PVU\nTa_VUVT`\nBLOa]PVYZ\nO[OLY EYYVY\n      5.70%\nO[OLY EYYVY\nFigure 2: Distribution over the level-1 and level-2 error\ntypes in TGEA.\n4 Dataset Analysis\n4.1 Dataset Statistics\nOverall statistics. We reshufﬂe all annotated texts\nand divide them into the training/dev/test sets with\na proportion of 8:1:1. As shown in Table 4, the\ntraining set contains 27,096 correct texts and 9,740\nerroneous texts. Both the development and test set\ncontain 4,706 texts, among which 1,218 texts are\nerroneous. Not surprisingly, most erroneous texts\ncontain only one error.\nAfter Chinese word segmentation via Jieba 4,\nthere are 1,208,719 tokens in total. On average,\nthere are 25.68 tokens in each text.\nAnnotation statistics. As shown in Table 4, each\nerroneous text span contains 2.94 tokens while each\nassociated span is composed of 4.27 tokens. The\naverage distance from an erroneous text span to its\nassociated span is 7.03 tokens, which is about 1/3\nof the average text length.\n4github.com/fxsjy/jieba\n6018\n4.2 Error Type Distribution\nWe further show the percentages of both level-1\nand level-2 error types in Figure 2. We observe\nthat only 5.7% cases cannot be categorized into\nour deﬁned error types. The inappropriate combi-\nnation, missing and redundancy error, which are\nthe main error types in GEC datasets, account for\n64.85% in our dataset. In addition to these errors,\nwe see 18.96% commonsense errors and 10.48%\ndiscourse errors, which are usually not very com-\nmon in GEC datasets. However, these two types\nof errors with high percentages in our dataset sug-\ngest that pretrained language models can be further\nimproved on both commonsense reasoning and dis-\ncourse modeling.\n5 TGEA as a Benchmark\nWe use our dataset as a benchmark and propose 5\ntasks that are deﬁned for errors in texts generated\nby PLMs. We provide baseline results for these\ntasks in this section.\nWe employ three BERT-style Chinese PLMs as\nbaselines in our experiments, namely BERT-wwm-\next, RoBERTa-wwm-ext-large developed by Cui\net al. (2020b) 5 and ALBERT-Chinese-large6. For\nnotational simiplicity, we denote them as BERTzh,\nRoBERTazh and ALBERTzh respectively. Please\nrefer to the Appendix for the model hyperparameter\nsettings of each task.\n5.1 Erroneous Text Detection\nTask deﬁnition. This is a text classiﬁcation task to\njudge whether a given text is erroneous. In order to\navoid data imbalance, we use the same number of\ncorrect and erroneous texts for training.\nModel. The three Chinese PLMs are used with\nstandard text-classiﬁcation ﬁne-tuning.\nResults. All models perform just <14% better\nthan chance (random guessing), as shown in Ta-\nble 5. We also provide human performance on\nthis task. The best model RoBERTazh is worse\nthan human performance by 26 points. This sug-\ngests that automatically detecting erroneous texts\ngenerated by pretrained language models is very\nchallenging even in the balanced classiﬁcation sce-\nnario.\n5github.com/ymcui/Chinese-BERT-wwm\n6huggingface.co/voidful/albert chinese large\n5.2 Erroneous Span and Associated Span\nDetection\nTask deﬁnition. We deﬁne the detection of the two\ntypes of spans as a joint task as they are closely\nrelated to each other. The joint task is similar to\nnamed entity recognition (NER) (a sequence label-\ning task) and it requires to recognize the erroneous\nand associated text spans simultaneously. NER-\nstyle word-level tags are hence annotated for each\nerroneous text.\nModel. The three Chinese PLMs with NER-like\nﬁne-tuning are evaluated for this task. Since this is\na 3-class token classiﬁcation task, we report class-\nF1 on erroneous and associated span. The class-\nF1 on class X is calculated like a normal F1 for\na binary classiﬁcation task, by treating the target\nclass X as the positive class and all other classes\nas negative.\nResults. As shown in Table 5, all models are very\npoor in this task, indicating the difﬁculty of auto-\nmatically detecting erroneous and associated spans.\nHowever, we have found that models can beneﬁt\nmuch from the joint detection over the detection\nof a single type of span (either erroneous or asso-\nciated span). Our preliminary experiments on the\ndetection of only erroneous span show that the best\nmodel can only achieve 26.42% erroneous class-F1\non the test set, while the joint task achieves 27.66%\nerroneous class-F1 on the test set.\n5.3 Error Type Classiﬁcation\nTask deﬁnition. Again this is a text classiﬁcation\ntask. We only perform classiﬁcation over level-1\nerror types in the form of 5-way classiﬁcation.\nModel. We use models similar to the ﬁrst task.\nResults. The overall accuracy and Macro- F1\n(shown in Table 5) are very low. However, we\nﬁnd some error types are easier than others. The\naccuracy on the classiﬁcation of redundancy errors\nis 53.91%, the highest among all error types.\n5.4 Error Correction\nTask deﬁnition. This task is the same as GEC,\nwhich transforms an erroneous text into a correct\nsequence.\nModel. we use the state-of-the-art BERT-GEC\nmodel (Kaneko et al., 2020) as the baseline for this\ntask, which is an encoder-decoder model using rep-\nresentations learned by PLMs as additional inputs.\nFollowing Wang et al. (2020)，we feed represen-\ntations learned by BERTzh and RoBERTazh into\n6019\nTask Model Dev Test\nAccuracy (%) Accuracy (%)\nErroneous\ntext detection\nRandom 50.00 50.00\nALBERTzh 63.59 63.30\nBERTzh 65.15 64.94\nRoBERTazh 66.67 66.79\nHuman 92.35 93.57\nErroneous\nclass-F1 (%)\nAssociated\nclass-F1 (%)\nErroneous\nclass-F1 (%)\nAssociated\nclass-F1 (%)\nErroneous and\nassociated\nspan detection\nRandom 01.71 04.23 01.74 04.22\nALBERTzh 27.36 27.44 28.10 26.24\nBERTzh 27.85 26.93 27.66 25.30\nRoBERTazh 28.17 27.08 27.75 27.12\nAccuracy (%) Macro- F1 (%) Accuracy (%) Macro- F1 (%)\nError type\nclassiﬁcation\nRandom 24.25 20.00 24.25 20.00\nALBERTzh 34.76 21.04 34.38 20.56\nBERTzh 44.35 33.01 41.31 31.05\nRoBERTazh 44.44 36.10 44.16 37.20\nP (%) R (%) F0.5 (%) P (%) R (%) F0.5 (%)\nError correction BERTzh GEC 0.62 6.49 0.76 0.60 6.30 0.74\nRoBERTazh GEC 0.78 4.07 0.93 0.82 4.15 0.98\nBLEU Rouge-L BERT Score BLEU Rouge-L BERT Score\nRationale generation NEZHA-Gen 0.06% 9.17% 56.58% 0.06% 9.02% 56.17%\nTable 5: Performance of benchmark models on the development and test set.\nthe BERT-GEC model.\nResults. We report precision, recall andF0.5 scores\nusing the ofﬁcial Max-Match tool (Dahlmeier\nand Ng, 2012). As shown in Table 5, the best\nRoBERTazh GEC model achieves a very lowF0.5\nof 0.93% and 0.98% on the development and test\nset respectively. We speculate that the reasons for\nthis are twofold. First, comparing with GEC data\non human-written texts, our dataset is relatively\nsmall. Second, our dataset contains error types\nthat are very different from those in previous GEC\ndatasets (Zhao et al., 2018; Flachs et al., 2020).\nPunctuation, spelling and other word-character-\nlevel errors, which are easy to be corrected, are\nrare in TGEA although they are quite common\nin GEC datasets. In contrast, TGEA contains\nmore complicated errors that can only be corrected\nwith knowledge of common sense, long-distance\nor inter-sentential dependencies, etc.\n5.5 Rationale Generation\nTask deﬁnition. This is a text generation task that\ndirectly generate an explanation with respect to text\ngeneration errors from an erroneous text.\nModel. We use NEZHA-Gen as the base-\nline for this task. We restructure an-\nnotated texts in our dataset in the form\nof {T, 这句话错误的原因是：, R} ({T,\nThe reason behind the errors in this sentence is:,\nR}), where T is an erroneous sentence, while R\nis the error rational provided by annotators. We\nthen ﬁne-tune NEZHA-Gen on the reformatted\ntraining set and evaluate the ﬁne-tuned model\non the reformatted development and test set. We\nreport BLEU (Papineni et al., 2002), Rouge-L (Lin,\n2004) and BERT Score (Zhang et al., 2020c).\nResults. It can be expected that results in these\nmetrics will be very low due to the high difﬁ-\nculty of this task. We analyze generated texts\nfrom the baseline and ﬁnd that generated ratio-\nnales are usually much longer than reference ra-\ntionales provided by human annotators. This could\nresult in the low BLEU score since long hypothe-\nses are penalized in BLEU computation. We also\nexperiment zero-shot generation on the test set.\nThe results are {BLEU = 0.04%, Rouge-L =\n6.83%, BERT Score = 54.27%}, indicating that\nﬁne-tuning on the annotated training set can im-\nprove this task. We suggest that this generation task\ncould be reformulated as a multi-choice question\nanswering task by providing alternative rationales\nas distractors, similar to VCR (Zellers et al., 2019a).\nWe leave this to our future work.\n6 Discussion\nSince we use machine-generated texts for error\nannotation, hyperparameters of models (e.g., sam-\npling strategies, model size), model types (e.g.,\nGPT-2, GPT-3 or other PLMs for text generation),\nand genres of texts used to train PLMs, etc., all\n6020\nhave impacts on generated texts and hence on error\ntypes and error distribution.\nA straightforward way to mitigate this issue is to\ncollect raw texts from multiple models with differ-\nent hyperparameters, neural architectures and text\ngenres. This will lead to an expanded dataset with\na much larger number of instances to be manually\nannotated, which is expensive and time-consuming.\nYet another issue with this is that it may result in a\nbunch of data due to inconsistency across different\nmodels and difﬁculty in setting the proportion of\neach data source.\nInstead, we focus on consistently annotating er-\nrors for texts generated from a single source. In\norder to make TGEA as general and representative\nas possible, we use GPT-2 that is not only currently\nstate of the art in text generation but also easily\navailable. We also adopt standard and widely-used\nhyperparameters (see Appendix for more details)\nfor NEZHA-Gen to generate texts.\nAdditionally, we use a random sampling strategy\nwith top k = 30. For setting k, we have analyzed\n500 examples with different values of k, and found\nthat adjusting k has a reasonable impact on the\npercentage of redundancy errors. Except for the ex-\ntreme case of k = 1, the types of errors and the dis-\ntribution of them do not change signiﬁcantly. Take\ncommonsense errors as an example, which is the\nbiggest difference from human-written texts. When\nk varies in a range of {5, 10, 20, 30, 50}, the per-\ncentage of commonsense errors is 18.6% ±5.8%.\nRedundancy errors account for >95% when k = 1\n(while commonsense errors account for 0.8%), but\nsharply drop to 37.4% as k = 5, and the form of\nrepetition changes from same-word repetition to a\nmixed repetition of “synonymous/same-word”, sug-\ngesting that a simple repetition penalty may not be\nsufﬁcient to deal with semantic redundancy. When\nk ∈{10, 20, 30, 50}, the percentage of redundancy\nerrors is very close to the result reported in Figure\n2. When k > 30, many generated sentences are\ncompletely incomprehensible. A larger k will also\nreduce the generation efﬁciency. Therefore, we\nchose a sampling strategy of k = 30, which is\nthe trade-off between text quality and generation\nefﬁciency.\n7 Conclusions\nIn this paper, we have presented TGEA, the ﬁrst\ndataset with a variety of manual annotations on\nerrors occurring texts generated by pretrained lan-\nguage models. For each erroneous text generated\nby a Chinese GPT-2 model, our crowdsourced an-\nnotators detect erroneous text spans with their as-\nsociated text spans and provide error types deﬁned\nin a two-level hierarchical taxonomy as well as ra-\ntionales behind detected errors. We elaborate the 5\nannotation stages for building TGEA with a strict\nannotation quality control protocol. We also re-\nport baseline results of the 5 benchmark tasks on\nTGEA. The low results suggest that our dataset is\na challenging testbed for future work on automatic\ndetection of erroneous spans and types as well as\nproducing error corrections and rationales for texts\ngenerated by PLMs. TGEA is featured with wide\nerror type coverage, rich semantic annotation and\nfunctional diversity, which can not only be used\nfor deep diagnostic analysis on the text generation\ncapability of pretrained language models, but also\nfacilitate and promote the research of automatic and\ninterpretable error correction for PLM-generated\ntexts.\nAcknowledgments\nThe present research was supported by Huawei. We\nwould like to thank the anonymous reviewers for\ntheir insightful comments. We also want to thank\nMindSpore7 for the partial suppoort of this work,\nwhich is a new deep learning computing frame-\nwork. The corresponding author is Deyi Xiong\n(dyxiong@tju.edu.cn).\nReferences\nTimoth´ee Bernard and Ting Han. 2020. Mandarino-\ngrad: A chinese collection of winograd schemas. In\nProceedings of the 12th Language Resources and\nEvaluation Conference, pages 21–26. European Lan-\nguage Resources Association.\nChandra Bhagavatula, Ronan Le Bras, Chaitanya\nMalaviya, Keisuke Sakaguchi, Ari Holtzman, Han-\nnah Rashkin, Doug Downey, Scott Wen-tau Yi, and\nYejin Choi. 2020. Abductive commonsense reason-\ning. International Conference on Learning Repre-\nsentations.\nYonatan Bisk, Rowan Zellers, Ronan LeBras, Jian-\nfeng Gao, and Yejin Choi. 2020. PIQA: Reasoning\nabout physical commonsense in natural language. In\nAAAI, pages 7432–7439.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry,\n72020. MindSpore. https://www.mindspore.cn/\n6021\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-\nV oss, Gretchen Krueger, Tom Henighan, Rewon\nChild, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\nClemens Winter, Chris Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In\nAdvances in Neural Information Processing Systems,\nvolume 33, pages 1876–1900. Curran Associates,\nInc.\nOana-Maria Camburu, Tim Rockt ¨aschel, Thomas\nLukasiewicz, and Phil Blunsom. 2018. e-snli: Nat-\nural language inference with natural language expla-\nnations. In S. Bengio, H. Wallach, H. Larochelle,\nK. Grauman, N. Cesa-Bianchi, and R. Garnett, ed-\nitors, Advances in Neural Information Processing\nSystems 31 , pages 9539–9549. Curran Associates,\nInc.\nYu Cao, Wei Bi, Meng Fang, and Dacheng Tao. 2020.\nPretrained language models for dialogue generation\nwith multiple input sources. In Findings of the As-\nsociation for Computational Linguistics: EMNLP\n2020, pages 909–917, Online. Association for Com-\nputational Linguistics.\nMingda Chen, Zewei Chu, and Kevin Gimpel. 2019.\nEvaluation benchmarks and learning criteria for\ndiscourse-aware sentence representations. In Pro-\nceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 649–\n662, Hong Kong, China. Association for Computa-\ntional Linguistics.\nLeyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming\nZhou. 2020a. MuTual: A dataset for multi-turn dia-\nlogue reasoning. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 1406–1416, Online. Association for\nComputational Linguistics.\nYiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shi-\njin Wang, and Guoping Hu. 2020b. Revisiting pre-\ntrained models for Chinese natural language process-\ning. In Proceedings of the 2020 Conference on Em-\npirical Methods in Natural Language Processing:\nFindings, pages 657–668, Online. Association for\nComputational Linguistics.\nDaniel Dahlmeier and Hwee Tou Ng. 2012. Better\nevaluation for grammatical error correction. In Pro-\nceedings of the 2012 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n568–572, Montr ´eal, Canada. Association for Com-\nputational Linguistics.\nVidas Daudaravicius, Rafael E. Banchs, Elena V olod-\nina, and Courtney Napoles. 2016. A report on the au-\ntomatic evaluation of scientiﬁc writing shared task.\nIn Proceedings of the 11th Workshop on Innovative\nUse of NLP for Building Educational Applications ,\npages 53–62, San Diego, CA. Association for Com-\nputational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nAlexander Fabbri, Irene Li, Tianwei She, Suyi Li, and\nDragomir Radev. 2019. Multi-news: A large-scale\nmulti-document summarization dataset and abstrac-\ntive hierarchical model. In Proceedings of the 57th\nAnnual Meeting of the Association for Computa-\ntional Linguistics, pages 1074–1084, Florence, Italy.\nAssociation for Computational Linguistics.\nSimon Flachs, Oph´elie Lacroix, Helen Yannakoudakis,\nMarek Rei, and Anders Søgaard. 2020. Grammati-\ncal error correction in low error density domains: A\nnew benchmark and analyses. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 8467–8478,\nOnline. Association for Computational Linguistics.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding-enhanced\nbert with disentangled attention.\nLifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\nYejin Choi. 2019. Cosmos QA: Machine reading\ncomprehension with contextual commonsense rea-\nsoning. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP), pages\n2391–2401, Hong Kong, China. Association for\nComputational Linguistics.\nNaoya Inoue, Pontus Stenetorp, and Kentaro Inui. 2020.\nR4C: A benchmark for evaluating RC systems to get\nthe right answer for the right reason. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics , pages 6740–6750, On-\nline. Association for Computational Linguistics.\nDan Iter, Kelvin Guu, Larry Lansing, and Dan Jurafsky.\n2020. Pretraining with contrastive sentence objec-\ntives improves discourse performance of language\nmodels. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4859–4870, Online. Association for Computa-\ntional Linguistics.\nSarthak Jain, Madeleine van Zuylen, Hannaneh Ha-\njishirzi, and Iz Beltagy. 2020. SciREX: A chal-\nlenge dataset for document-level information extrac-\ntion. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics ,\npages 7506–7516, Online. Association for Compu-\ntational Linguistics.\n6022\nZhenyu Jiao, Shuqi Sun, and Ke Sun. 2018. Chinese\nlexical analysis with deep bi-gru-crf network. arXiv\npreprint arXiv:1807.01882.\nMasahiro Kaneko, Masato Mita, Shun Kiyono, Jun\nSuzuki, and Kentaro Inui. 2020. Encoder-decoder\nmodels can beneﬁt from pre-trained masked lan-\nguage models in grammatical error correction. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4248–\n4254, Online. Association for Computational Lin-\nguistics.\nHector J. Levesque, Ernest Davis, and Leora Morgen-\nstern. 2012. The winograd schema challenge. In\nProceedings of the Thirteenth International Confer-\nence on Principles of Knowledge Representation\nand Reasoning, KR’12, page 552–561. AAAI Press.\nChin-Yew Lin. 2004. Rouge: A package for automatic\nevaluation of summaries. In Text summarization\nbranches out, pages 74–81.\nYang Liu and Mirella Lapata. 2019. Text summariza-\ntion with pretrained encoders. In Proceedings of\nthe 2019 Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 3730–3740, Hong Kong,\nChina. Association for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining ap-\nproach. CoRR, abs/1907.11692.\nMary McHugh. 2012. Interrater reliability: The kappa\nstatistic. Biochemia medica : ˇcasopis Hrvatskoga\ndruˇstva medicinskih biokemi ˇcara / HDMB, 22:276–\n82.\nCourtney Napoles, Maria Nadejde, and Joel Tetreault.\n2019. Enabling robust grammatical error correction\nin new domains: Datasets, metrics, and analyses.\nTransactions of the Association for Computational\nLinguistics, 7(0):551–566.\nCourtney Napoles, Keisuke Sakaguchi, and Joel\nTetreault. 2017. JFLEG: A ﬂuency corpus and\nbenchmark for grammatical error correction. In Pro-\nceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Volume 2, Short Papers , pages 229–234,\nValencia, Spain. Association for Computational Lin-\nguistics.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic eval-\nuation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Compu-\ntational Linguistics, pages 311–318.\nAnkur Parikh, Xuezhi Wang, Sebastian Gehrmann,\nManaal Faruqui, Bhuwan Dhingra, Diyi Yang, and\nDipanjan Das. 2020. ToTTo: A controlled table-to-\ntext generation dataset. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 1173–1186, On-\nline. Association for Computational Linguistics.\nEdoardo Maria Ponti, Goran Glava ˇs, Olga Majewska,\nQianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.\nXCOPA: A multilingual dataset for causal common-\nsense reasoning. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 2362–2376, Online. As-\nsociation for Computational Linguistics.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring\nthe limits of transfer learning with a uniﬁed text-to-\ntext transformer. Journal of Machine Learning Re-\nsearch, 21(140):1–67.\nMelissa Roemmele, Cosmin Adrian Bejan, and An-\ndrew S Gordon. 2011. Choice of plausible alterna-\ntives: An evaluation of commonsense causal reason-\ning. In AAAI spring symposium: logical formaliza-\ntions of commonsense reasoning, pages 90–95.\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-\nula, and Yejin Choi. 2020. WinoGrande: An adver-\nsarial winograd schema challenge at scale. In Pro-\nceedings of the AAAI Conference on Artiﬁcial Intel-\nligence, volume 34, pages 8732–8740. Issue: 05.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019. Social IQa: Com-\nmonsense reasoning about social interactions. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 4463–\n4473, Hong Kong, China. Association for Computa-\ntional Linguistics.\nOleksii Sidorov, Ronghang Hu, Marcus Rohrbach, and\nAmanpreet Singh. 2020. Textcaps: a dataset for im-\nage captioning with reading comprehension. CoRR,\nabs/2003.12462.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. olmpics-on what language\nmodel pre-training captures. Transactions of the As-\nsociation for Computational Linguistics, 8:743–758.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. CommonsenseQA: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long and Short Pa-\npers), pages 4149–4158. Association for Computa-\ntional Linguistics.\n6023\nPavlos V ougiouklis, Hady ElSahar, Lucie-Aim ´ee\nKaffee, Christophe Gravier, Fr ´ed´erique Laforest,\nJonathon S. Hare, and Elena Simperl. 2017. Neu-\nral wikipedian: Generating textual summaries from\nknowledge base triples. CoRR, abs/1711.00155.\nAlex Wang, Yada Pruksachatkun, Nikita Nangia,\nAmanpreet Singh, Julian Michael, Felix Hill, Omer\nLevy, and Samuel Bowman. 2019. Superglue: A\nstickier benchmark for general-purpose language un-\nderstanding systems. In Advances in Neural Infor-\nmation Processing Systems, volume 32, pages 3266–\n3280. Curran Associates, Inc.\nAlex Wang, Amanpreet Singh, Julian Michael, Fe-\nlix Hill, Omer Levy, and Samuel Bowman. 2018.\nGLUE: A multi-task benchmark and analysis plat-\nform for natural language understanding. In Pro-\nceedings of the 2018 EMNLP Workshop Black-\nboxNLP: Analyzing and Interpreting Neural Net-\nworks for NLP , pages 353–355, Brussels, Belgium.\nAssociation for Computational Linguistics.\nHongfei Wang, Michiki Kurosawa, Satoru Katsumata,\nand Mamoru Komachi. 2020. Chinese grammatical\ncorrection using BERT-based pre-trained model. In\nProceedings of the 1st Conference of the Asia-Paciﬁc\nChapter of the Association for Computational Lin-\nguistics and the 10th International Joint Conference\non Natural Language Processing , pages 163–168,\nSuzhou, China. Association for Computational Lin-\nguistics.\nAlex Warstadt, Alicia Parrish, Haokun Liu, Anhad Mo-\nhananey, Wei Peng, Sheng-Fu Wang, and Samuel R.\nBowman. 2020. BLiMP: The benchmark of linguis-\ntic minimal pairs for English. Transactions of the As-\nsociation for Computational Linguistics, 8:377–392.\nRongxiang Weng, Heng Yu, Shujian Huang, Shanbo\nCheng, and Weihua Luo. 2020. Acquiring knowl-\nedge from pre-trained model to neural machine\ntranslation. Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, 34(05):9266–9273.\nSam Wiseman, Stuart Shieber, and Alexander Rush.\n2017. Challenges in data-to-document generation.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2253–2263, Copenhagen, Denmark. Association for\nComputational Linguistics.\nLiang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chenjie\nCao, Yudong Li, Yechen Xu, Kai Sun, Dian Yu,\nCong Yu, Yin Tian, Qianqian Dong, Weitang Liu,\nBo Shi, Yiming Cui, Junyi Li, Jun Zeng, Rongzhao\nWang, Weijian Xie, Yanting Li, Yina Patterson,\nZuoyu Tian, Yiwen Zhang, He Zhou, Shaoweihua\nLiu, Zhe Zhao, Qipeng Zhao, Cong Yue, Xinrui\nZhang, Zhengliang Yang, Kyle Richardson, and\nZhenzhong Lan. 2020. CLUE: A Chinese language\nunderstanding evaluation benchmark. In Proceed-\nings of the 28th International Conference on Com-\nputational Linguistics, pages 4762–4772, Barcelona,\nSpain (Online). International Committee on Compu-\ntational Linguistics.\nHelen Yannakoudakis, Ted Briscoe, and Ben Medlock.\n2011. A new dataset and method for automatically\ngrading ESOL texts. In Proceedings of the 49th An-\nnual Meeting of the Association for Computational\nLinguistics: Human Language Technologies , pages\n180–189, Portland, Oregon, USA. Association for\nComputational Linguistics.\nRowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin\nChoi. 2019a. From recognition to cognition: Vi-\nsual commonsense reasoning. In Proceedings of the\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition, pages 6720–6731.\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\nFarhadi, and Yejin Choi. 2019b. HellaSwag: Can\na machine really ﬁnish your sentence? In Pro-\nceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 4791–\n4800, Florence, Italy. Association for Computational\nLinguistics.\nHongming Zhang, Xinran Zhao, and Yangqiu Song.\n2020a. WinoWhy: A deep diagnosis of essential\ncommonsense knowledge for answering Winograd\nschema challenge. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 5736–5745, Online. Association\nfor Computational Linguistics.\nLi Zhang, Qing Lyu, and Chris Callison-Burch. 2020b.\nReasoning about goals, steps, and temporal ordering\nwith WikiHow. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language\nProcessing (EMNLP), pages 4630–4639, Online. As-\nsociation for Computational Linguistics.\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\nWeinberger, and Yoav Artzi. 2020c. Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations.\nZhuosheng Zhang, Junjie Yang, and Hai Zhao. 2021.\nRetrospective reader for machine reading compre-\nhension. In The Thirty-Fifth AAAI Conference on\nArtiﬁcial Intelligence (AAAI-21).\nYuanyuan Zhao, Nan Jiang, Weiwei Sun, and Xiao-\njun Wan. 2018. Overview of the NLPCC 2018\nShared Task: Grammatical Error Correction: 7th\nCCF International Conference, NLPCC 2018, Ho-\nhhot, China, August 26–30, 2018, Proceedings, Part\nII, pages 439–445.\nXuhui Zhou, Yue Zhang, Leyang Cui, and Dandan\nHuang. 2020. Evaluating commonsense in pre-\ntrained language models. In The Thirty-Fourth\nAAAI Conference on Artiﬁcial Intelligence, AAAI\n2020, The Thirty-Second Innovative Applications of\nArtiﬁcial Intelligence Conference, IAAI 2020, The\nTenth AAAI Symposium on Educational Advances\nin Artiﬁcial Intelligence, EAAI 2020, New York, NY,\nUSA, February 7-12, 2020, pages 9733–9740. AAAI\nPress.\n6024\nA Appendix\nA.1 NEZHA-Gen Hyperparameters\nTable 1 show the conﬁguration of the generative\nmodel (NEZHA-Gen).\nModel NEZHA-Gen\nhidden size 768\nnum hidden layers 12\nnum attention heads 12\nintermediate size 3072\nhidden act gelu\nhidden dropout prob 0.1\nattention probs dropout prob 0.1\nmax position embeddings 512\ntype vocab size 16\ninitializer range 0.02\nTable 1: Conﬁguration of NEZHA-Gen.\nA.2 Training Setting\nTable 2, 3, 4, 5, 6 show the training settings\nof the baseline models for each task. In these\ntables, ALBERTzh, BERTzh, RoBERTazh rep-\nresent ALBERT-chinese, RoBerta-wwm-ext and\nRoBerta-wwm-ext respectively.\nModel ALBERTzh BERTzh RoBERTazh\nModel size large base large\nLearning rate 2 × 10−5\nBatch size 8\nOptimizer Adam\nAdam β1 0.9\nAdam β2 0.98\nAdam ϵ 1 × 10−8\nMax epochs 50\nLoss function cross-entropy\nDropout 0.1\nTable 2: Training details for the Erroneous Text Detec-\ntion task.\nModel ALBERTzh BERTzh RoBERTazh\nModel size base base base\nLearning rate 2 × 10−5\nBatch size 32\nOptimizer Adam\nAdam β1 0.9\nAdam β2 0.999\nAdam ϵ 1 × 10−6\nMax epochs 5\nLoss function cross-entropy\nDropout 0.1\nTable 3: Training details for the Erroneous and Associ-\nated Span Detection task.\nModel ALBERTzh BERTzh RoBERTazh\nModel size large base large\nLearning rate 2 × 10−5\nBatch size 8\nOptimizer Adam\nAdam β1 0.9\nAdam β2 0.98\nAdam ϵ 1 × 10−8\nMax epochs 50\nLoss function cross-entropy\nDropout 0.1\nTable 4: Training details for the Error Type Classiﬁca-\ntion task.\nBERTzh GEC RoBERTazh GEC\nModel BERT-wwm-ext RoBERTa-wwm-ext-large\nArchitecture Transformer (big)\nLearning rate 3 × 10−5\nBatch size 16\nOptimizer Adam\nAdam β1 0.9\nAdam β2 0.98\nAdam ϵ 1 × 10−8\nMax epochs 50\nLoss function label smoothed cross-entropy (ϵls = 0.1)\nDropout 0.3\nTable 5: Training details for the Error Correction task.\nModel NEZHA-Gen\nLearning rate 5 × 10−5\nBatch size 4\nOptimizer Adam\nAdam β1 0.9\nAdam β2 0.999\nAdam ϵ 1 × 10−6\nMax epochs 3\nDropout 0.1\nTable 6: Training details for the Rationale Generation\ntask.\nA.3 Examples of Level-2 Error Types\nTable 7 shows examples of level-2 error types in\nTGEA.\n6025\nLevel-1 Error Type Level-2 Error Type Example\nInappropriate\nCombination\nSubject-Predicate 目前,该市的:::小说 [话剧]《我是党员、我的团员》、《我是小老头》、《小小老师》、《小\n小一个农家娃》正在上演。\nAt present, the city’s:::novels [drama] I am a Party member and This is My League Member, Little Old\nMan Like Me, Little Teacher, A Little Farm Boy are on stage.\nPredicate-Object 由我主持，我要带大家去感受一下大赛主题设置的:::感受[氛围]。\nAs a host, I will take you to experience the ::feel [atmosphere] shown from the theme of the competi-\ntion.\nSubject-Object 女足的 ::队员[任务] 就是一个球，能够把球踢好，就是她们最大的资本。\nThe::::players [task] of women’s football team is a ball, and playing the ball well is their biggest\ncapitals.\nModiﬁer 另一方面，煤炭企业面临着煤矿安全的:::矛盾[问题]。\nOn the other hand, coal enterprises are facing the ::::::contradiction [problem] of coal mine safety.\nFunction Word 因此，我:对[因为]自身的过错作出了自己应当承担的责任。\nTherefore,:to [because of] my own fault, I took my own responsibility.\nMisssing\nSubject 当他回到车间时， :[车间]已经有了明显的变化。\nWhen he returned to the workshop,:[the place] had been a marked change\nPredicate 这时候我们一开始就有机会扳平比分，但是我们没有 :[抓住]机会。\nWe had a chance to equalise at the beginning, but we didn’t :[caught] chance.\nObject 一、坚持解放思想,转变观念,推进社会主义物质文明和精神 :[文明]。\n1. Persisting in emancipating the mind, changing ideas and promoting socialist material civilization\nand spiritual: [civilization].\nModiﬁer 在国内成立水牛研究中心，有利于增强: [水牛对]自然条件和人工环境的适应能力。\nThe establishment of Buffalo Research Center in China is conducive to enhancethe adaptability [of\nbuffalo] to natural conditions and artiﬁcial environment.\nFunction Word 他的儿子:[在]上一届奥运会夺得冠军，并且获得当年世界锦标杯赛金牌。\nHis son won champion:[in] the last Olympic Games and won the gold medal in the World Champi-\nonship Cup that year.\nRedundancy\nSubject 但一些外资银行::::::::::，尤其是外资银行[]，对我国民营经济的发展还有不少误解或偏见。\nHowever, some foreign banks:, :::::especially :::foreign:::banks[], still have many misunderstandings or prej-\nudices about the development of China’s private economy.\nPredicate 这也是所有::关心[]关心孩子成长的人的共同心声。\nThis is also the common voice of all those who ::care:::about[] care about children’s growth\nObject 同时，学校也开展丰富多彩、有益于学生的社会实践活动::::::、社会实践[]，丰富他们的课余生\n活。\nAt the same time, the school also carries out colorful and beneﬁcial social practice activities,:::social\n::::practice[] to enrich their after-school life.\nModiﬁer 它们的皮毛很有光泽,可以用肉眼:::很难[]看出来。\nTheir fur is so shiny that we can see with naked eyes :::hardly[].\nFunction Word 他是被迫进入位于市中心的一个警察局的，::随后[]他被带到警察局，并遭到了手铐和警犬的\n威吓。\nHe was forced into a police station in the center of the city, ::then[] he was taken to the police station,\nwhere he was intimidated by handcuffs and police dogs.\nDiscourse\nError Coreference 在婚姻变得更为不好的时候，对她来说这是痛苦的。但是当::她[它]发生变化时，她必须做出\n调整。\nIt was painful for her when the marriage got worse. But when ::she [it] changed, she had to adjust.\nCommonsense\nError\nSpace 他说,中美两国是::近邻[朋友],关系很好,中美合作富有创造性。\nHe said thatChina and the United States are close ::::neighbors [friends] with good relations and creative\ncooperation.\nTime ::国庆 [元旦]假期期间，各大汽车经销商将会以怎么样的姿态迎接新的一年？\nDuring the:::::National ::Day [New Year’s Day] holiday, how will major auto dealers greetthe new year?\nNumber 而在4月份，中国石化、招商银行、万科、上海汽车、g长安和g天威成为了最活跃的:5 [6]只\n股票。\nIn April, Sinopec, China Merchants Bank, Vanke,SAIC, G Changan and G Tianwei became the most\nactive:5 [6] stocks.\nMotivation 近日，李老的胃疼难忍，为治疗病情已连续::工作[休息]两天了，而且病情非常严重，他一躺\n就是几天。\nRecently, Lao Li’s stomach ache is unbearable. He has been ::::working [resting] for two consecutive\ndays to treat his illness, and his illness is very serious. He has been lying down for several days.\nEmotional Reactions 对于学校为了保障广大师生员工的安全，采取这些措施，我们深感::遗憾[欣慰]。\nWe are very::sorry [pleased] that the school has taken these measures to ensure the safety of students,\nteachers, and other staff.\nCausation 据悉，由于身价:::低廉[高昂]，子淇在国内是很少有人请得到的大牌艺人之一。\nIt is reported that Ziqi is one of the few famous artists that are difﬁcult to invite in China because of\nhis :low [high] value.\nTaxonomy :酱 [花生] 油是植物油中的一种，食用后可以对皮肤有非常好的润泽效果。\n::Soy:::sauce [Peanut Oil] is a kind of vegetable oil, which has a very good moisturizing effect on the\nskin after eating.\nBehaviors 一位中国官员表示：我们将在近期和俄罗斯::::、中国 [法国] 等国合作进一步推广这一系列行\n动，以此来缓解人们对恐怖主义威胁的忧虑。\nIn the near future, we will work with Russia, :::China [France] and other countries to further promote\nthis series of actions to ease people’s concerns about the threat of terrorism, aChinese ofﬁcial said.\nTable 7: Examples of level-2 error types in TGEA. :::::::::::Underwaved :::::words are erroneous words while underlined\nwords are associated words. Words in ”[]” are corrections to erroneous words.",
  "topic": "Benchmark (surveying)",
  "concepts": [
    {
      "name": "Benchmark (surveying)",
      "score": 0.8277811408042908
    },
    {
      "name": "Computer science",
      "score": 0.7492088675498962
    },
    {
      "name": "Natural language processing",
      "score": 0.7183866500854492
    },
    {
      "name": "Computational linguistics",
      "score": 0.626059889793396
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5919167399406433
    },
    {
      "name": "Volume (thermodynamics)",
      "score": 0.5223799347877502
    },
    {
      "name": "Association (psychology)",
      "score": 0.4855203628540039
    },
    {
      "name": "Joint (building)",
      "score": 0.4741869866847992
    },
    {
      "name": "Language model",
      "score": 0.42269012331962585
    },
    {
      "name": "Linguistics",
      "score": 0.35209017992019653
    },
    {
      "name": "Psychology",
      "score": 0.10013645887374878
    },
    {
      "name": "Philosophy",
      "score": 0.07115733623504639
    },
    {
      "name": "Engineering",
      "score": 0.05543592572212219
    },
    {
      "name": "Geography",
      "score": 0.05395421385765076
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Psychotherapist",
      "score": 0.0
    },
    {
      "name": "Architectural engineering",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I162868743",
      "name": "Tianjin University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I2250955327",
      "name": "Huawei Technologies (China)",
      "country": "CN"
    }
  ]
}