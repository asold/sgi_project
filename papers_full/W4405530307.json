{
  "title": "The journey from natural language processing to large language models: key insights for radiologists",
  "url": "https://openalex.org/W4405530307",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3168298148",
      "name": "Salvatore Claudio Fanni",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A4207852874",
      "name": "Lorenzo Tumminello",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2007562242",
      "name": "Valentina Formica",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A4361072951",
      "name": "Francesca Pia Caputo",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2462041209",
      "name": "Gayane Aghakhanyan",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2638003249",
      "name": "Ilaria Ambrosini",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A3007770114",
      "name": "Roberto Francischello",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A1945985501",
      "name": "Lorenzo FAGGIONI",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2137310742",
      "name": "Dania Cioni",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2166203090",
      "name": "Emanuele Neri",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A3168298148",
      "name": "Salvatore Claudio Fanni",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A4207852874",
      "name": "Lorenzo Tumminello",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2007562242",
      "name": "Valentina Formica",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A4361072951",
      "name": "Francesca Pia Caputo",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2462041209",
      "name": "Gayane Aghakhanyan",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2638003249",
      "name": "Ilaria Ambrosini",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A3007770114",
      "name": "Roberto Francischello",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A1945985501",
      "name": "Lorenzo FAGGIONI",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2137310742",
      "name": "Dania Cioni",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A2166203090",
      "name": "Emanuele Neri",
      "affiliations": [
        "University of Pisa"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2338526423",
    "https://openalex.org/W4386764545",
    "https://openalex.org/W2746791326",
    "https://openalex.org/W3129922404",
    "https://openalex.org/W2114063639",
    "https://openalex.org/W2108017642",
    "https://openalex.org/W4323276468",
    "https://openalex.org/W2511665394",
    "https://openalex.org/W4375861655",
    "https://openalex.org/W2238966896",
    "https://openalex.org/W1978394996",
    "https://openalex.org/W4393317046",
    "https://openalex.org/W2747680751",
    "https://openalex.org/W4387327030",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4390919701",
    "https://openalex.org/W4285098448",
    "https://openalex.org/W2926850261",
    "https://openalex.org/W2156518033",
    "https://openalex.org/W2016000869",
    "https://openalex.org/W2976259715",
    "https://openalex.org/W4385251726",
    "https://openalex.org/W4327677054",
    "https://openalex.org/W4403626237",
    "https://openalex.org/W4366124521",
    "https://openalex.org/W4378672794",
    "https://openalex.org/W4391174596",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4382182493",
    "https://openalex.org/W4383186888",
    "https://openalex.org/W4282983782",
    "https://openalex.org/W4385230595",
    "https://openalex.org/W4322757547",
    "https://openalex.org/W4376872703",
    "https://openalex.org/W3164323420",
    "https://openalex.org/W4211187366"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nJournal of Medical Imaging and Interventional Radiology           (2024) 11:43  \nhttps://doi.org/10.1007/s44326-024-00043-w\nREVIEW ARTICLE\nThe journey from natural language processing to large language \nmodels: key insights for radiologists\nSalvatore Claudio Fanni1  · Lorenzo Tumminello1 · Valentina Formica1 · Francesca Pia Caputo1 · \nGayane Aghakhanyan1 · Ilaria Ambrosini1 · Roberto Francischello1 · Lorenzo Faggioni1 · Dania Cioni1 · \nEmanuele Neri1\nReceived: 29 October 2024 / Accepted: 28 November 2024 \n© The Author(s) 2024\nAbstract\nArtificial intelligence (AI) has undergone cycles of enthusiasm and stagnation, often referred to as “AI winters.” The introduc-\ntion of large language models (LLMs), such as OpenAI’s ChatGPT in late 2022, has revitalized interest in AI, particularly \nwithin health-care applications, including radiology. The roots of AI in language processing can be traced back to Alan \nTuring’s 1950 work, which established foundational principles for natural language processing (NLP). Early iterations of \nNLP primarily concentrated on natural language understanding (NLU) and natural language generation (NLG), but they faced \nsignificant challenges related to contextual comprehension and the handling of lengthy text sequences. Recent advancements \nin NLP have demonstrated considerable promise in automating the analysis of unstructured data, including electronic health \nrecords and radiology reports. LLMs, which are based on the transformer architecture introduced in 2017, excel at capturing \ncomplex language dependencies and facilitating tasks, such as report generation and clinical decision support. This review \ncritically examines the evolution from traditional NLP to LLMs, highlighting their transformative potential within the field \nof radiology. Despite the advantages presented by LLMs, challenges persist, including concerns regarding data privacy, the \npotential for generating misinformation, and the imperative for rigorous validation protocols. Addressing these challenges \nis crucial for harnessing the full potential of LLMs to enhance diagnostic precision and workflow efficiency in radiology, \nultimately improving patient care and outcomes.\nKeywords Natural language processing · Large language models · Recurrent neural networks · Transformers · Structured \nreporting\nIntroduction\nArtificial intelligence (AI) has experienced several waves \nof enthusiasm followed by periods of stagnation, often \nreferred to as “AI winters.” The term was first introduced by \nLighthill in 1973 to describe times when progress in AI fell \nshort of expectations [1 ]. These periods of stagnation were \ncaused by unmet expectations and limitations in technologi-\ncal progress. However, this notion of AI underperformance \nremained largely in the past, especially with the advent of \nlarge language models (LLMs) like OpenAI’s ChatGPT, \nlaunched in November 2022. This marked a turning point, \nespecially in fields such as health care, where AI tools now \ndemonstrate real-world applicability. LLMs, exemplified \nby models such as ChatGPT, have showcased remarkable \nabilities in processing complex tasks, prompting radiologists \nand other specialists to explore how these models might be \nintegrated into their workflows [2, 3].\nThe origins of AI’s journey into language processing can \nbe traced back to Alan Turing’s 1950 work, “Computing \nMachinery and Intelligence.” In this paper, Turing posed a \nquestion central to AI research: can machines “think”? He \nintroduced the Turing Test, a way to evaluate a machine’s \nability to exhibit human-like intelligence. This foundational \nwork laid the groundwork for natural language processing \n(NLP), which has since evolved into a powerful interface \nbetween human language and computers [4, 5].\nIn its early days, NLP focused on two major compo-\nnents: natural language understanding (NLU), which \n * Salvatore Claudio Fanni \n fannisalvatoreclaudio@gmail.com\n1 Department of Translational Research, Academic Radiology, \nUniversity of Pisa, Pisa, Italy\n Journal of Medical Imaging and Interventional Radiology           (2024) 11:43 \n   43  Page 2 of 10\nconverts free-text data into structured formats, and natural \nlanguage generation (NLG), which produces coherent text \nfrom structured data [6 ]. Another significant milestone is \nthe introduction of machine learning (ML) in the 1990s, \nwhich led to the use of data-driven models that could learn \nlinguistic patterns from large text corpora [4 ]. However, \neven with these advancements, traditional NLP systems \nstruggled with tasks that required understanding the con-\ntext or reasoning over long sequences of text. [7 ]\nNLP’s potential in health care was particularly demon-\nstrated in handling vast amounts of unstructured data, such \nas electronic health records (EHRs), clinical trial data, \nand diagnostic reports [7 ]. These types of data are often \nunorganized, making them challenging to be analyzed on \na large scale. Radiology, in particular, stands to benefit \nsignificantly from NLP, as it allows for the automated \nextraction of critical diagnostic insights from free-form \ntext radiology reports, thus alleviating the growing burden \nof radiologists [5 , 8, 9]. A key goal in radiology has been \nstructured reporting, which standardizes the format and \ncontent of radiology reports to improve consistency. Tools \nlike the RadLex lexicon, developed by the Radiological \nSociety of North America (RSNA), are part of this move-\nment [10, 11]. However, LLMs go beyond these structured \nsystems by providing a flexible and nuanced interpretation \nof free-text reports [2 , 12].\nThe shift from basic NLP to LLMs in radiology occurred \nin key phases. Early NLP systems focused on simple key -\nword extraction and medical term identification. As deep \nlearning (DL) methods advanced, radiology-specific NLP \nsystems were developed to classify reports and predict diag-\nnoses, but these systems were limited by their inability to \ngeneralize across different tasks [4]. With the introduction of \nthe transformer architecture in 2017 by Vaswani et al., LLMs \ngained the capacity to process complex, long-range depend-\nencies in language [2]. This architecture laid the foundation \nfor the subsequent development of LLMs like GPT-3 and \nGPT-4 that enabled AI models to process complex, long-\nrange dependencies in medical language. These LLMs can \nperform tasks such as report generation, diagnostic support, \nand clinical decision-making with minimal human supervi-\nsion [13].\nIn radiology, where imaging data is growing exponen-\ntially, the need for AI tools that can enhance diagnostic \naccuracy and streamline workflows is increasingly critical \n[11]. The Italian Society of Medical Radiology (SIRM) has \nemphasized the importance of integrating AI technologies \nlike LLMs into radiological practice, highlighting the poten-\ntial of these models to improve both diagnostic precision and \noperational efficiency [14, 15].\nThis narrative review traces the journey from the early \ndays of NLP to the latest advancements in LLMs, particu-\nlarly in the context of radiology. These advancements hold \ntransformative potential for radiological workflows, enhanc-\ning diagnostic accuracy and operational efficiency.\nNatural language processing pipeline\nThe process of understanding, interpreting, and generating \nhuman language involves a series of interconnected steps, \nknown as pipeline, which basically convert raw text data \n(such as unstructured radiology reports) into structured \noutput [6]. The NLP pipeline typically includes three main \nstages: preprocessing, feature extraction, and modeling \n[12]. This pipeline is not always a linear process, as it often \nrequires moving back and forth between stages. For exam-\nple, if the results from the modeling stage are unsatisfactory, \nrevisiting the preprocessing or feature extraction steps may \nbe necessary to enhance data quality [16]. The NLP pipeline \nis resumed in Fig. 1.\nText preprocessing\nPreprocessing refers to the series of steps taken to refine the \ntext, remove noise, and enhance the quality of the data for \nbetter analysis and modeling [6].\nNoise removal is used to remove unwanted or irrelevant \ndata, such as punctuation, special characters, duplicate text, \nand headers.\nThe next step, tokenization, is the process of breaking \ndown text into smaller, manageable units called tokens, \nwhich can be sentences (i.e., sentence tokenization) or words \n(i.e., word tokenization). It typically involves splitting the \ntext by spaces or punctuation to create a list of tokens. The \nprocess often begins with sentence tokenization followed by \nword tokenization, resulting in a list of lists [9].\nLowercasing is the process of converting all texts to low-\nercase letters to achieve uniformity in text analysis, as case \nsensitivity can affect certain NLP tasks.\nStop words removal is the process of eliminating common \nwords, irrelevant to the meaning of the text (stop words), to \nfocus on more meaningful words. Stop words, such as “the,” \n“and,” and “is,” frequently occur in language but carry little \nsemantic significance and can introduce noise into the data. \nMost NLP libraries provide a predefined set of stop words to \nstreamline this process, often determined by word frequency \nto assess a word’s significance.\nStemming and lemmatization are techniques employed to \nreduce derived words to their base or root forms, simplify -\ning text and minimizing vocabulary size. Stemming utilizes \na heuristic approach to remove suffixes and prefixes from \nwords, producing their stem forms, which may not always \ncorrespond to valid words. A prominent example of stem-\nming is Porter’s algorithm, which efficiently processes words \nthrough five sequential phases. In contrast, lemmatization \nJournal of Medical Imaging and Interventional Radiology           (2024) 11:43  \n Page 3 of 10    43 \naccurately converts words to their canonical base forms \n(lemmas) based on their part of speech, using the context \nalong with a vocabulary and morphological analysis to \nachieve greater precision [17]. Lemmatization tends to be \nmore accurate but also more computationally intensive com-\npared to stemming. This is because lemmatization requires \ndefining the part of speech and relies on a corpus, a large \nset of linguistic data that provides key information such as \nword forms, meanings, and grammatical rules, to ensure that \nwords are reduced to their proper base forms according to \nthe context. The main distinction between the two techniques \nis that a lemma is always a valid word, whereas a stem may \nnot be, making stemming a faster but less precise process \n[17] (Fig. 2).\nFig. 1  The natural language \nprocessing pipeline stages and \nsteps\nFig. 2  Pros and cons of stemming and lemmatization\n Journal of Medical Imaging and Interventional Radiology           (2024) 11:43 \n   43  Page 4 of 10\nPart of speech (POS) tagging is the process of assigning \npart of speech tags, such as nouns, verbs, and adjectives, \nto each word in a text. This step provides insights into the \nsyntactic structure of the text and helps in understanding the \ngrammatical categories of the words, helping to differentiate \nbetween similar-sounding terms or understanding the sig -\nnificance of specific findings in the report. Finally, named \nentity recognition (NER) process involves identifying and \nclassifying named entities in text, such as medical condi-\ntions, anatomical locations, and patient identifiers, enhanc-\ning information extraction and improving the overall under-\nstanding of a report’s content [6].\nFeature extraction\nFeature engineering in NLP involves transforming raw text \ndata into numerical features that DL models can compre-\nhend and utilize effectively. Feature extraction can be done \nthrough various techniques, such as frequency-based meth-\nods or dense representations. Among the frequency-based \nmethods, Bag of Words (BoW) and Term Frequency-Inverse \nDocument Frequency (TF-IDF) are some of the most fre-\nquently used.\nThis BoW approach is based on counting the frequency \nof occurrences of the tokens within a document [18]. The \nfinal result is a matrix, called a document-feature matrix, \nwhich is a two-dimensional array where each row represents \na document and each column corresponds to the tokens, spe-\ncific words from the vocabulary made of the complete set of \nunique words present in the corpus (Fig.  3). The entries in \nthis matrix reflect how often each word appears in a given \ndocument. As a result, each document leads to a sparse rep-\nresentation, meaning that the data is encoded in a way where \nthe majority of elements are zero: This happens because, in \na typical document collection, there are thousands of unique \nwords, but each document contains only a small subset of \nthem.\nTo further enhance the BoW model, the TF-IDF method \nis employed [19]. This approach not only considers the \nraw frequency of a word, hence term  (i.e., term frequency, \nTF), but also adjusts for how common or rare the word is \nacross the entire document corpus (i.e., inverse document \nfrequency, IDF).\nBy considering as t the term and d as the document, it is \npossible to calculate the term frequency factor (TF) using \nthe following formula:\nIf N is the total number of documents and df is the num-\nber of documents with the term t, the inverse document fre-\nquency (IDF) can be defined as follows:\nAs a result, the term frequency–inverse document fre-\nquency (TF-IDF) is\nIn plain words, the IDF value increases for words that \nappear in fewer documents, which helps in highlighting the \nmost informative and significant terms in each document.\nOnce the document-feature matrix is obtained, regardless \nof the method used, various operations can be performed. \nA key task is to evaluate the similarity between documents, \nwhich can be achieved by comparing the vectors represent-\ning the documents in the matrix. Common similarity meas-\nures include Euclidean Distance, Jaccard Similarity, and \nCosine Similarity [20].\nTF (t,d) = frequency of tin d\ntotal number of tin d\nIDF (t,d)= log N\n1 + df\nTF (t, d) − IDF (t, d) = TF (t, d) ∗ IDF (t) data\nFig. 3  A document-feature matrix representing the frequency of each token (columns) in different sentences (row)\nJournal of Medical Imaging and Interventional Radiology           (2024) 11:43  \n Page 5 of 10    43 \nHowever, the high dimensionality of vectors generated \nthrough these techniques carries with it a range of limita-\ntions. Specifically, the elevated dimensionality hinders the \nefficient representation of text, leading to challenges in pro-\ncessing and analyzing large datasets. Furthermore, these \nrepresentations fail in capturing the semantic relationships \nbetween terms within a sentence, as they treat each word \nindependently, regardless of the context in which they \nappear.\nConsequently, there has been a significant transition in \nNLP toward dense representations, which provide a more \ncompact and meaningful encoding of language. Dense rep-\nresentations refer to a way of encoding data where each item \nis represented as a compact vector in a continuous space. \nWhen the items of these representations are the words of \na document, they are referred to as word embeddings [21]. \nDense representations use a fixed number of dimensions to \ncapture the essential features and the semantic and syntactic \nrelationships between words. A very popular model used \nto generate word embeddings is Word2Vec, which employs \ntechniques such as Continuous BoW (CBOW) and Skip-\nGram to produce vector representations that effectively cap-\nture word meanings based on their contextual usage [21].\nCBOW and Skip-Gram are complementary approaches \nwithin the Word2Vec framework, operating in opposite \ndirections. CBOW aims to predict a target word based on \nits surrounding context words, while Skip-Gram does the \nreverse, attempting to predict the surrounding context words \nfrom a given target word (Fig. 4).\nBoth methods generate vector representations of words \nthat effectively capture their semantic meanings, allowing \nwords with similar contexts to be positioned closely in the \nresulting vector space.\nThe CBOW and Skip-Gram models offer distinct advan-\ntages depending on the specific application. CBOW is com-\nputationally more efficient, allowing for faster training times, \nwhich makes it particularly useful when dealing with large \ndatasets. It performs well with frequent words but may strug-\ngle to capture nuanced relationships for rare words. In con-\ntrast, the Skip-Gram model, though more computationally \ndemanding, excels at generating high-quality representations \nfor rare words and phrases. By predicting the surrounding \ncontext from a target word, Skip-Gram effectively captures \nthe nuances of infrequent terms, even in smaller training \ndatasets.\nIn conclusion, CBOW is a good choice for tasks that need \nspeed and focus on common words, while Skip-Gram works \nbetter for tasks that need more detail with rare or specific \nwords.\nModeling: from recurrent neural networks to large \nlanguage models\nModeling is the final step in the NLP pipeline, where ML or \nDL models are applied to analyze and categorize text.\nBefore the introduction of the Transformer architec-\nture, the field of NLP primarily relied on recurrent neural \nnetworks (RNNs) and long short-term memory networks \n(LSTMs), to analyze and categorize text by capturing \nsequential information in the data [22]. Limitations in han-\ndling long-term dependencies led to the development of \nLSTM networks, which provided better performance in pro-\ncessing complex language. More recently, the emergence of \nLLMs has marked a major breakthrough, with these models \ncapable of understanding the context, syntax, and semantics \nat a much deeper level [23]. This progression from RNNs to \nFig. 4  Continuous Bag of Words (CBOW) and Skip-Gram produce vector representations based on word contextual usage. CBOW (left) aims to \npredict a target word based on its surrounding context words, while Skip-Gram attempts to predict the context from a target word\n Journal of Medical Imaging and Interventional Radiology           (2024) 11:43 \n   43  Page 6 of 10\nLSTMs and now to LLMs reflects a historical evolution in \nNLP, making LLMs the current state of the art for analyzing \nand interpreting medical text with unprecedented accuracy \nand depth [7, 24].\nRNNs\nRNNs are a particular class of artificial neural networks \ndesigned to process sequential or time series data, making \nthem highly suitable for tasks in natural language process-\ning. Unlike traditional feedforward neural networks, RNNs \npossess a loop or cycle in their architecture, functioning \nas a form of “memory” that enables them to capture the \nsequential context in data, which is critical for understanding \nnatural language [6].\nThe fundamental concept behind RNNs is their ability to \nprocess input sequences one element at a time while main-\ntaining a hidden state that summarizes information about \nthe previous elements in the sequence. Mathematically, an \nRNN is described as a series of equations that update the \nhidden state at each time step. The core component of the \nRNN, the recurrent neuron, receives two inputs: the current \ninput vector and the previous hidden state. It generates a \nnew hidden state as output, which is then passed along to the \nnext recurrent neuron in the sequence. This recursive nature \nallows RNNs to preserve information from the earlier parts \nof the sequence.\nDespite their advantages, RNNs encounter difficulties \nwith long-term dependencies due to the vanishing and \nexploding gradient problems. In the vanishing gradient \nproblem, the gradients become too small to effectively train \nthe network, making it difficult to learn long-term dependen-\ncies. As the model processes sequences, the significance of \nearlier tokens in the sequence diminishes, making it hard to \nmaintain meaningful connections between distant tokens. In \naddition, RNNs can also suffer from the exploding gradient \nproblem, in which the gradients become excessively large, \ncausing the weight updates to destabilize the learning pro-\ncess. Both of these gradient issues limit the ability of RNNs \nto retain and utilize information from the earlier parts of a \nsequence as it grows, which limits their scalability to large \ndatasets. To address the limitations of standard RNNs, gated \narchitectures like LSTM networks were developed.\nLSTM\nLSTM networks [25] are a specialized type of RNNs \ndesigned to effectively learn long-term dependencies. Intro-\nduced by Hochreiter and Schmidhuber in 1997, LSTMs \naddress the challenges associated with the vanishing gra-\ndient problem faced by traditional RNNs, particularly \nwhen trained on long data sequences [25]. This is achieved \nthrough the incorporation of a set of “memory cells,” which \nstore information and transmit it across time steps, alongside \na system of gates that regulate the flow of data into and out \nof these cells. An LSTM network consists of recurrent units \nthat incorporate a cell state along with three types of gates: \nthe input gate, the forget gate, and the output gate. The input \ngate regulates the flow of new information into the cell state, \nensuring that relevant data can be incorporated. In contrast, \nthe forget gate controls the retention of information that is no \nlonger pertinent, allowing the model to discard unnecessary \ndetails. The output gate manages the flow of information \nfrom the cell state to the unit’s output, determining which \ninformation will be passed to subsequent layers. At each \ntime step, the cell state is updated through a combination of \nthe input, forget, and output gates, along with the previous \ncell state.\nThis mechanism enables the LSTM network to selectively \nremember or forget information over extended periods, mak-\ning it effective in maintaining the context and improving the \naccuracy of predictions, even in long sequences. Despite \ntheir effectiveness, LSTMs still face computational chal-\nlenges, particularly as data complexity increases. They can \nbe resource-intensive, leading to efficiency issues.\nTransformers\nThe introduction of the Transformer architecture has marked \na significant milestone in ML, enabling the development \nof LLMs [2 ]. Unlike previous architectures, transformers \nare designed to efficiently handle parallel processing, mak -\ning them especially suitable for NLP. LLMs like genera-\ntive pre-trained transformer (GPT) series and bidirectional \nencoder representations from transformers (BERT) are \nhighly advanced computational models trained on massive \namounts of text data from the Internet, learning patterns, and \nassociations between words to predict subsequent tokens in a \nsequence. The training process involves iteratively adjusting \nmodel parameters to maximize the probability of predicting \nthe next token, a method facilitated by self-learning tech-\nniques [3, 26].\nTransformers use attention mechanisms to manage con-\ntextual relationships between different parts of the input, \naddressing the inefficiencies of traditional RNN and LSTM \nnetworks. While RNNs and LSTMs process sequences \nsequentially, leading to limited contextual understanding, \ntransformers analyze tokens in parallel [2 ]. This parallel \nprocessing is enhanced by positional encodings, which pre-\nserve the order of words, and self-attention mechanisms, \nwhich weigh the significance of the different parts of the \ninput when producing outputs.\nOne of the key features of LLMs is their ability to be fine-\ntuned for specific tasks after extensive pre-training on large \ncorpora. For instance, BERT and GPT have been trained \non billions of tokens, allowing them to transfer learned \nJournal of Medical Imaging and Interventional Radiology           (2024) 11:43  \n Page 7 of 10    43 \nknowledge to specialized applications where data may be \nlimited. This capability revolutionizes how LLMs tackle \ndata-sparse tasks, marking a paradigm shift in NLP.\nThe attention mechanism within the transformer archi-\ntecture allows for a more profound understanding of the \nrelationships between tokens by focusing on specific parts \nof the input data. This mimics human cognition, where we \nselectively focus on parts of a sentence during comprehen-\nsion. The introduction of multiple attention heads further \nenhances the model’s ability to capture diverse aspects of \nthe input data, enabling the simultaneous consideration of \nmultiple relationships.\nLLMs can also be multimodal, meaning they have the \nability to interpret both text and image data, closely resem-\nbling the way humans process and learn from real-world \ninformation. This feature aligns well with current diagnostic \npathways in medicine, where clinical and imaging findings \nare considered concurrently. The transformative potential \nof LLMs in medicine has been widely discussed, with the \ncapacity to enhance clinical practice and research by sup-\nporting radiologists, clinicians, patients, and researchers \n[27].\nNLP and LLM applications in radiology\nIn the past few years, NLP has found wide applications in \nradiology [ 5]. The radiology report serves as the primary \ncommunication tool among health-care providers and \nbetween providers and patients [14]. Despite the advent of \nEHRs facilitating access to digital data for text extraction, \nclassification, and syntactic analysis, radiology reports are \nstill typically written in a free-form format [28].\nNLP may enhance radiological workflows and improve \ncancer care through information retrieval, classification, \nsummarization, question–answering, and text generation. \nNLP can be used to detect specific diagnoses within the con-\ntext of a radiology report, as demonstrated by Wang et al., \nwho implemented NLP to identify specific osteoporotic \nskeletal fractures and patients at high risk from aggregate \nradiology reports [29]. Hripcsak et al. utilized MedLEE for \nlarge-scale research on radiology reports to test four distinct \nhypotheses. This automated analysis enabled the examina-\ntion of a vast dataset, totaling 889,921 chest X-ray reports \n[30].\nNLP tools have proven valuable in radiology for enhanc-\ning diagnostic surveillance by issuing alerts for specific find-\nings or conditions, thereby reducing the risk of clinicians \noverlooking critical observations. Rink et al. developed a \nmethod to detect appendicitis by analyzing each individual \nstatement in a report. Their approach combined a custom-\nized lexicon, manually defined patterns, and a support vector \nmachine model, achieving a sensitivity of 91% and a positive \npredictive value of 83% [31].\nIn addition, NLP can be useful in assessing the quality \nof radiologic practice. These tools can identify key quality \nindicators that support internal quality assurance, ensure \ncompliance with guidelines, and serve legal purposes. For \nexample, Lacson et al. employed the iSCOUT tool to flag \nreports with pulmonary nodules, allowing them to evaluate \ntheir alignment with the Fleischner Society Guidelines for \nnodule management [32].\nNLP has also been investigated for the automated conver-\nsion of free-form text into structured reports. In 2019, Span-\ndorfer et al. developed a DL algorithm to convert free-form \ncomputed tomography (CT) pulmonary angiography reports \ninto structured reports. Trained on 475 manually structured \nreports, the model achieved 91.6%–95.9% per-statement \naccuracy on a test set of 400 CT scans, depending on the cri-\nteria applied [33]. A similar approach was adopted by Fanni \net al., who developed a DL method to convert unstructured \nCOVID-19 chest CT reports into structured formats. Tested \non 202 reports, the model achieved a mean accuracy of 95% \n[34]. An additional step in the application of NLU to radio-\nlogical reporting was taken by Jorg et al., who automatically \nconverted dictated free text into a structured report for CT \nimaging of urolithiasis, achieving an F1 score of 0.90. Fur -\nthermore, the authors integrated an NLG component capable \nof interacting with the radiologist and identifying sections of \nthe structured report that were not addressed in the dictated \ntext [35].\nSimilarly, as highlighted by Bush et al. in a systematic \nreview, LLMs may further enhance the efficiency and accu-\nracy of structured reporting in radiology report processing \n[36]. LLMs have been tested not only for the automated con-\nversion of free-form text radiological reports into structured \nreports [37] but also for generating structured reporting tem-\nplates for different clinical scenarios [38].\nGiven the increasing interest for LLMs, several appli-\ncations have been hypothesized and investigated, beyond \nstructured reporting, including report generation, transla-\ntion, and summarization of medical information. LLMs have \nproven ability in significantly improving voice-to-text report \ngeneration by detecting and correcting speech recognition \nerrors [39]. In addition, LLMs are valuable for answering \nradiology-related questions, providing explanations of spe-\ncific imaging findings, details about radiological procedures, \nand information on different imaging modalities. Another \nimportant use of LLMs in radiology is data mining automa-\ntion. These models can retrieve and extract critical medi-\ncal information to create large datasets for research [40]. In \nterms of report generation, a recent study evaluated LLMs’ \nperformance in producing comprehensive impressions \nfrom radiology reports, showing promising results. This \nstudy highlighted the potential for LLMs to create coherent, \n Journal of Medical Imaging and Interventional Radiology           (2024) 11:43 \n   43  Page 8 of 10\nconsistent, and factually accurate summaries, making them \na feasible tool for improving radiology documentation and \nanalysis [41].\nFinally, LLMs may be a valuable supporting tool for radi-\nologists in diagnostic processes. By evaluating imaging data \nin combination with a patient’s medical history, these mod-\nels can propose likely diagnoses, consider differential diag-\nnoses, and also recommend possible treatment options [42].\nCurrent limitations of LLMs\nThe widespread application of LLMs in health care, includ-\ning radiology, remains constrained by several significant \nlimitations that warrant discussion [24].\nThe first limitation involves privacy concerns, which arise \nwhen using patient data, including radiological reports and \nimages. These practices pose ethical challenges and heighten \nthe risk of exposing sensitive information. To mitigate the \nprivacy concern, LLMs used in health care must be compli-\nant with the Health Insurance Portability and Accountability \nAct (HIPAA). In addition, rigorous anonymization protocols \nare essential to protect patient confidentiality and support the \nsecure use of data in health-care applications, especially in \nradiology, where the potential for re-identifying de-identified \ndata remains a concern.\nA further risk to patient safety involves the issue of hal-\nlucination, which has become notorious with the spread of \nLLMs. Hallucination refers to the generation of misinfor -\nmation, such as inaccurate interpretations of radiological \nreports or erroneous diagnostic suggestions. This misinfor -\nmation poses risks to patient care by potentially leading to \nmisinformed clinical decisions. To mitigate hallucinations \nin LLMs, several options can be employed, ranging from \nlower to higher complexity and cost. These include prompt \nengineering, retrieval-augmented generation, and fine-tuning \n[27].\nAnother strategy includes enhancing the interpretability \nand transparency of LLMs and implementing rigorous vali-\ndation protocols to verify the accuracy of LLM-generated \ncontent [43].\nSuch issues become even more prominent when the \nmodel has not been trained with optimal quantity and qual-\nity of data, or when the patient is the direct user of such \ntools. LLMs may lack accuracy when not trained on medi-\ncal data or do not rely on up-to-date medical information. \nFor this reason, radiology-specific models have been devel-\noped [27]. Radiology-GPT, an LLM optimized on paired \nreport-impression datasets, demonstrated greater clinical \nutility compared to ChatGPT [ 44]. RadBERT, a family of \ntransformer-based models pre-trained on over 4 million radi-\nology reports and fine-tuned for radiology-specific language \ntasks, outperformed standard baseline models [45]. Finally, \na chatbot leveraging retrieval-augmented generation and \nintegrated with the American College of Radiology appro-\npriateness guidelines outperformed both radiologists and \nChatGPT in accurately applying these guidelines to clinical \ncase scenarios [46].\nIn addition, patient overconfidence in using LLMs, e.g., \nwhen translating a radiological report in common speaking, \ncould cause loss of relevant medical information. Moreover, \ncontradictory answers can come from the same query, thus \ncausing confusion in clinical decision-making [47, 48].\nLack of evaluation of the ethical implication of the incor-\nrect generated content could lead to misdiagnoses and wrong \ntreatment strategy and lead to medico-legal implications.\nNonetheless, the financial aspect must be kept in mind \nsince LLM training is costly and hence a regulation on the \nuse and training of LLMs would be needed [49].\nConclusions\nIn conclusion, the journey from NLP to LLMs represents a \nsignificant advancement in radiology, enhancing tasks such \nas report generation and clinical decision support. Through \nvarious stages of increasing complexity, starting from BoW, \npassing through RNNs to LLMs, increasingly performant \nmodels have been developed, whose impact in health care, \nincluding radiology, can be extremely important. While \nLLMs offer improved contextual understanding and scal-\nability, challenges such as data privacy, interpretability, and \npotential biases remain.\nAuthor contribution All authors contributed to the study conception \nand design. Material preparation and data collection and analysis were \nperformed by Salvatore Claudio Fanni, Lorenzo Tumminello, Valentina \nFormica, Francesca Pia Caputo, Gayane Aghakhanyan, Ilaria Ambro-\nsini, and Roberto Francischello. The first draft of the manuscript was \nwritten by Salvatore Claudio Fanni, Lorenzo Tumminello, Valentina \nFormica, Francesca Pia Caputo, Gayane Aghakhanyan, Ilaria Ambro-\nsini, and Roberto Francischello, and all authors commented on the pre-\nvious versions of the manuscript. Lorenzo Faggioni, Dania Cioni, and \nEmanuele Neri supervised and critically revised the work. All authors \nread and approved the final manuscript.\nFunding No funds, grants, or other support was received.\nData availability All data supporting the findings of this study are \navailable and referenced within the paper.\nDeclarations \nConflict of interest The authors have no competing interests to declare \nthat are relevant to the content of this article.\nEthical approval Not applicable.\nConsent to participate Not applicable.\nJournal of Medical Imaging and Interventional Radiology           (2024) 11:43  \n Page 9 of 10    43 \nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Lighthill J (1973) Artificial intelligence: a general survey. Science \nResearch Council.\n 2. Vaswani A, Shazeer N, Parmar N, et al (2017) Attention Is All \nYou Need. ArXiv. https:// arxiv. org/ abs/ 1706. 03762\n 3. Brown TB, Mann B, Ryder N, et al (2020) Language models are \nfew-shot learners. ArXiv. https:// arxiv. org/ abs/ 2005. 14165\n 4. Jurafsky D, Martin JH (2024) Speech and language processing: \nan introduction to natural language processing, computational \nlinguistics, and speech recognition with language models, 3rd \nedition. https:// web. stanf ord. edu/ ~juraf sky/ slp3\n 5. Pons E, Braun LMM, Hunink MGM, Kors JA (2016) Natural \nlanguage processing in radiology: A systematic review. Radiology \n279:329–343\n 6. Fanni SC, Febi M, Aghakhanyan G, Neri E (2023) Natural lan-\nguage processing. Introduction to artificial intelligence. Springer, \nCham, pp 87–99\n 7. Zhang X, Kim J, Patzer RE et al (2017) Prediction of emergency \ndepartment hospital admission based on natural language process-\ning and neural networks. Methods Inf Med 56:377–389. https://  \ndoi. org/ 10. 3414/ ME17- 01- 0024\n 8. Casey A, Davidson E, Poon M et  al (2021) A systematic \nreview of natural language processing applied to radiology \nreports. BMC Med Inform Decis Mak. https:// doi. org/ 10. 1186/ \ns12911- 021- 01533-7\n 9. Fanni SC, Gabelloni M, Alberich-Bayarri A, Neri E (2022) Struc-\ntured reporting and artificial intelligence. Springer International \nPublishing, Cham, pp 169–183\n 10. Langlotz CP (2006) RadLex: A new method for indexing online \neducational materials. Radiographics 26:1595–1597\n 11. Kahn CE, Langlotz CP, Burnside ES et al (2009) Toward best \npractices in radiology reporting. Radiology 252:852–856. https:// \ndoi. org/ 10. 1148/ radiol. 25230 81992\n 12. Bobba PS, Sailer A, Pruneski JA et al (2023) Natural language \nprocessing in radiology: Clinical applications and future direc-\ntions. Clin Imaging 97:55–61\n 13. Nori H, King N, McKinney SM, et al (2023) Capabilities of \nGPT-4 on medical challenge problems. ArXiv. https:// arxiv. org/ \nabs/ 2303. 13375\n 14. Faggioni L, Coppola F, Ferrari R et al (2017) Usage of struc-\ntured reporting in radiological practice: results from an Italian \nonline survey. Eur Radiol 27:1934–1943. https:// doi. org/ 10. 1007/ \ns00330- 016- 4553-6\n 15. Neri E, Aghakhanyan G, Zerunian M et al (2023) Explainable AI \nin radiology: a white paper of the Italian Society of Medical and \nInterventional Radiology. Radiol Med 128:755–764. https:// doi.  \norg/ 10. 1007/ s11547- 023- 01634-5\n 16. Cai T, Giannopoulos AA, Yu S et al (2016) Natural language \nprocessing technologies in radiology research and clinical \napplications. Radiographics 36:176–191. https:// doi. org/ 10.  \n1148/ rg. 20161 50080\n 17. Torres-Moreno J-M (2012) Beyond stemming and lemmatiza -\ntion: ultra-stemming to improve automatic text summarization\n 18 Salton G, Wong A, Yang CS (1975) AVector space model for \nautomatic indexing. Commun ACM. https:// doi. org/ 10. 1145/  \n36121 93612 20\n 19 Salton G, Buckley C (1988) Term-weighting approaches in auto-\nmatic text Retrieval. Inform Process Manage 24:513–523\n 20. Jiawei Han MK and JP (2012) Data mining: concepts and tech-\nniques. 3rd Edition eBook ISBN: 9780123814807\n 21. Mikolov T, Chen K, Corrado G, Dean J (2013) Efficient esti-\nmation of word representations in vector space. ArXiv. https://  \narxiv. org/ abs/ 1301. 3781\n 22. Nakaura T, Ito R, Ueda D et al (2024) The impact of large \nlanguage models on radiology: a guide for radiologists on the \nlatest innovations in AI. Jpn J Radiol 42:685–696\n 23. Khurana D, Koli A, Khatter K, Singh S (2023) Natural lan-\nguage processing: state of the art, current trends and challenges. \nMultimed Tools Appl 82:3713–3744. https:// doi. org/ 10. 1007/  \ns11042- 022- 13428-4\n 24. Akinci D’ Antonoli T, Stanzione A, Bluethgen C et al (2024) \nLarge language models in radiology: fundamentals, applica-\ntions, ethical considerations, risks, and future directions. Diagn \nInterv Radiol 30:80–90\n 25. Hochreiter S, Urgen Schmidhuber J (1997) Long short-term \nmemory. Neural Comput 9(8):1735–1780 https:// doi. org/ 10.  \n1162/ neco. 1997.9. 8. 1735\n 26. Devlin J, Chang M-W, Lee K, Toutanova K (2018) BERT: Pre-\ntraining of deep bidirectional transformers for language under -\nstanding. https:// doi. org/ 10. 48550/ arXiv. 1810. 04805\n 27. Bhayana R (2024) Chatbots and large language models in radi -\nology: a practical primer for clinical and research applications. \nRadiology 310\n 28 Fanni SC, Colligiani L, Spina N et al (2022) Current knowledge \nof radiological structured reporting. J Radiol Rev. https:// doi.  \norg/ 10. 23736/ s2723- 9284. 22. 00189-1\n 29 Wang Y, Mehrabi S, Sohn S et al (2019) Natural language pro-\ncessing of radiology reports for identification of skeletal site-\nspecific fractures. BMC Med Inform Decis Mak. https:// doi. org/ \n10. 1186/ s12911- 019- 0780-5\n 30. Hripcsak G, Austin JHM, Alderson PO, Friedman C (2002) Use \nof natural language processing to translate clinical information \nfrom a database of 889,921 chest radiographic reports. Radiol-\nogy 224:157–163. https:// doi. org/ 10. 1148/ radiol. 22410 11118\n 31. Rink B, Roberts K, Harabagiu S, et al Extracting actionable \nfindings of appendicitis from radiology reports using natural \nlanguage processing. AMIA Jt Summits Transl Sci Proc. PMID: \n24303268\n 32. Lacson R, Prevedello LM, Andriole KP et al (2012) Factors \nassociated with radiologists’ adherence to Fleischner Society \nguidelines for management of pulmonary nodules. J Am Coll \nRadiol 9:468–473. https:// doi. org/ 10. 1016/j. jacr. 2012. 03. 009\n 33 Spandorfer A, Branch C, Sharma P et al (2019) Deep learn-\ning to convert unstructured CT pulmonary angiography reports \ninto structured reports. Eur Radiol Exp. https:// doi. org/ 10. 1186/ \ns41747- 019- 0118-1\n 34. Fanni SC, Romei C, Ferrando G et al (2023) Natural language \nprocessing to convert unstructured COVID-19 chest-CT reports \ninto structured reports. Eur J Radiol Open. https:// doi. org/ 10.  \n1016/j. ejro. 2023. 100512\n 35 Jorg T, Kämpgen B, Feiler D et al (2023) Efficient structured \nreporting in radiology using an intelligent dialogue system \nbased on speech recognition and natural language processing. \nInsights Imaging. https:// doi. org/ 10. 1186/ s13244- 023- 01392-y\n Journal of Medical Imaging and Interventional Radiology           (2024) 11:43 \n   43  Page 10 of 10\n 36 Busch F, Hoffmann L, dos Santos DP et al (2024) Large language \nmodels for structured reporting in radiology: past, present, and \nfuture. Eur Radiol. https:// doi. org/ 10. 1007/ s00330- 024- 11107-6\n 37. Bosbach WA, Senge JF, Nemeth B et al (2024) Ability of Chat -\nGPT to generate competent radiology reports for distal radius frac-\nture by use of RSNA template items and integrated AO classifier. \nCurr Probl Diagn Radiol 53:102–110. https:// doi. org/ 10. 1067/j. \ncprad iol. 2023. 04. 001\n 38. Mallio CA, Sertorio AC, Bernetti C, Beomonte Zobel B (2023) \nLarge language models for structured reporting in radiology: per-\nformance of GPT-4, ChatGPT-3.5. Perplexity Bing Radiol Med \n128:808–812. https:// doi. org/ 10. 1007/ s11547- 023- 01651-4\n 39. Schmidt RA, Seah JCY, Cao K et al (2024) Generative large lan-\nguage models for detection of speech recognition errors in radi-\nology reports. Radiol Artif Intell. https:// doi. org/ 10. 1148/ ryai. \n230205\n 40. Fink MA, Bischoff A, Fink CA et al (2023) Potential of ChatGPT \nand GPT-4 for data mining of free-text CT reports on lung cancer. \nRadiology. https:// doi. org/ 10. 1148/ radiol. 231362\n 41 Sun Z, Ong H, Kennedy P et al (2023) Evaluating GPT-4 on \nimpressions generation in radiology reports. Radiology. https://  \ndoi. org/ 10. 1148/ radiol. 231259\n 42 Kottlors J, Bratke G, Rauen P et al (2023) Feasibility of differen-\ntial diagnosis based on imaging patterns using a large language \nmodel. Radiology. https:// doi. org/ 10. 1148/ RADIOL. 231167\n 43. Zihao L (2023) The Dark Side of ChatGPT: Legal and ethical \nchallenges from stochastic parrots and hallucination. ArXiv. \nhttps:// arxiv. org/ abs/ 2304. 14347\n 44. Liu Z, Zhong A, Li Y, et al (2023) Radiology-GPT: a large lan-\nguage model for radiology. ArXiv. https:// arxiv. org/ abs/ 2306. \n08666\n 45 Yan A, McAuley J, Lu X et al (2022) RadBERT: adapting trans-\nformer-based language models to radiology. Radiol Artif Intell. \nhttps:// doi. org/ 10. 1148/ ryai. 210258\n 46 Rau A, Rau S, Zöller D et al (2023) A context-based Chatbot \nsurpasses radiologists and generic ChatGPT in following the ACR \nappropriateness guidelines. Radiology. https:// doi. org/ 10. 1148/ \nradiol. 230970\n 47. Singhal K, Tu T, Gottweis J, et al (2023) Towards expert-level \nmedical question answering with large language models\n 48. Lecler A, Duron L, Soyer P (2023) Revolutionizing radiology \nwith GPT-based models: Current applications, future possibilities \nand limitations of ChatGPT. Diagn Interv Imaging 104:269–274. \nhttps:// doi. org/ 10. 1016/j. diii. 2023. 02. 003\n 49 Shahsavar Y, Choudhury A (2023) User intentions to Use Chat-\nGPT for self-diagnosis and health-related purposes: cross-sec-\ntional survey study. JMIR Hum Factors. https:// doi. org/ 10. 2196/ \n47564\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations.",
  "topic": "Key (lock)",
  "concepts": [
    {
      "name": "Key (lock)",
      "score": 0.7034125924110413
    },
    {
      "name": "Computer science",
      "score": 0.562023937702179
    },
    {
      "name": "Natural (archaeology)",
      "score": 0.5024561882019043
    },
    {
      "name": "Natural language",
      "score": 0.43772491812705994
    },
    {
      "name": "Natural language processing",
      "score": 0.413968950510025
    },
    {
      "name": "Linguistics",
      "score": 0.35772812366485596
    },
    {
      "name": "Artificial intelligence",
      "score": 0.32339179515838623
    },
    {
      "name": "History",
      "score": 0.1820278763771057
    },
    {
      "name": "Archaeology",
      "score": 0.07742124795913696
    },
    {
      "name": "Philosophy",
      "score": 0.0769926905632019
    },
    {
      "name": "Computer security",
      "score": 0.06061166524887085
    }
  ]
}