{
  "title": "Large Language Models respond to Influence like Humans",
  "url": "https://openalex.org/W4385571687",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2811475251",
      "name": "Lewis Griffin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2063875431",
      "name": "Bennett Kleinberg",
      "affiliations": [
        "Tilburg University",
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A2715628745",
      "name": "Maximilian Mozes",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A5104244711",
      "name": "Kimberly Mai",
      "affiliations": [
        "University College London"
      ]
    },
    {
      "id": "https://openalex.org/A5055821766",
      "name": "Maria Do Mar Vau",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107077750",
      "name": "Matthew Caldwell",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Augustine Mavor-Parker",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2944632798",
    "https://openalex.org/W2971123519",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W2079860815",
    "https://openalex.org/W2011946757",
    "https://openalex.org/W2034532433",
    "https://openalex.org/W3162292190",
    "https://openalex.org/W3168589281",
    "https://openalex.org/W3206078697",
    "https://openalex.org/W1545040377",
    "https://openalex.org/W2024415362",
    "https://openalex.org/W72162311",
    "https://openalex.org/W2910772955",
    "https://openalex.org/W1799750435",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4302306219",
    "https://openalex.org/W4319452268",
    "https://openalex.org/W4283020727",
    "https://openalex.org/W4300748935",
    "https://openalex.org/W4385573216",
    "https://openalex.org/W4251357184",
    "https://openalex.org/W4284885940",
    "https://openalex.org/W4283321795",
    "https://openalex.org/W4321455981",
    "https://openalex.org/W4253211563",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4385572854"
  ],
  "abstract": "Lewis Griffin, Bennett Kleinberg, Maximilian Mozes, Kimberly Mai, Maria Do Mar Vau, Matthew Caldwell, Augustine Mavor-Parker. Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023). 2023.",
  "full_text": "Proceedings of the First Workshop on Social Influence in Conversations (SICon 2023), pages 15‚Äì24\nJuly 14, 2023 ¬©2023 Association for Computational Linguistics\n1 \n \n \nAbstract \nTwo studies tested the hypothesis that a \nLarge Language Model (LLM) can be used \nto model psychological change following \nexposure to influential input. The first study \ntested a generic mode of influence - the \nIllusory Truth Effect (ITE) - where earlier \nexposure to a statement boosts a later \ntruthfulness test rating. Analysis of newly \ncollected data from human and LLM-\nsimulated subjects (1000 of each) showed \nthe same pattern of effects in both \npopulations; although with greater per \nstatement variability for the LLM. The \nsecond study concerns a specific mode of \ninfluence ‚Äì populist framing of news to \nincrease its persuasion and political \nmobilization. Newly collected data from \nsimulated subjects was compared to \npreviously published data from a \n15-country experiment on 7286 human \nparticipants. Several effects from the \nhuman study were replicated by the \nsimulated study, including ones that \nsurprised the authors of the human study by \ncontradicting their theoretical expectations; \nbut some significant relationships found in \nhuman data were not present in the LLM \ndata. Together the two studies support the \nview that LLMs have potential to act as \nmodels of the effect of influence. \n1   Introduction \nHuman beliefs and values can be held absolutely \n(‚ÄòI love my children‚Äô) but are often modal or graded \n(‚ÄòCOVID19 may have an artificial origin‚Äô). The \nstrength of conviction is malleable, subject to \ninfluence (Miller & Levine, 2019) which can take \nmany forms. Some forms are generic, independent \nof the content: logical deduction from agreed \npremises, or rhetorical devices such as rapid speech \n(Miller et al., 1976). While others require a \nmobilization of specific factors: manipulating \nbeliefs of feared or desired outcomes (Maloney et \nal., 2011; Shao et al., 2019), encouraging \nconformity (Moscovici, 1963), distorting the \nweighting of pro and con arguments (Cobb & \nKuklinski, 1997), provision of false information \n(Chakraborty & Harbaugh, 2010), and more.  \nAn improved understanding of influence would \nhave applications ranging from the malign to the \nbeneficial: national scale disinformation; consumer \nadvertising; encouraging healthy behaviours; \ndefending against disinformation. \nInvestigating the effects of influence on human \npsychology by using experiments with human \nparticipants is slow, expensive and ethically \nconstrained (Argyle et al., 2022). Similar \ndifficulties bedevil the study of the effect of drugs \non human physiology. In that domain, animal \nmodels have proven utility despite their limitations. \nLarge Language Models (LLMs), such as GPT-3 \n(Brown et al., 2020), complete text as if holding \ngraded beliefs. We propose that LLMs can be useful \nmodels of human psychology for investigating \ninfluence, just as mice are useful models of human \nphysiology for investigating pharmacology. \nRecent studies (section 2) have shown that \nLLMs have human-like psychological responses, \nbut it has not yet been reported whether LLMs, like \nhumans, can be influenced to change these. Here \nwe report two studies whose results support this.  \n2   Previous Research \nPersonality: Miotto et al. (2022) used prompt-\ncompletion to administer a personality \nquestionnaire to GPT-3, measuring the BIG-5 and \nother dimensions. GPT -3's personality profile was \nLarge Language Models respond to Influence like Humans \n \n \n \nLewis D Griffin1        Bennett Kleinberg2,3        Maximilian Mozes2        Kimberly Mai1,2 \nMaria Vau1        Matthew Caldwell1        Augustine Mavor-Parker1 \n{1Computer Science, 2Security & Crime Science}, University College London, UK. \n3Methodology & Statistics, Tilburg University, the Netherlands. \nL.Griffin@cs.ucl.ac.uk \n \n \n \n15\n2 \n \n \nsomewhat similar to the average profile from a \nlarge representative study with human participants. \nUsing similar methods, Jiang et al. (2022) showed \nthat the personality of the LLM could be \nconditioned by preceding testing with a self-\ndescription (‚ÄôYou are a very friendly and outgoing \nperson‚Ä¶‚Äô) which enhanced or diminished a \ntargeted personality dimension and correctly \nmanifested in the LLM‚Äôs open responses to \nquestions about behaviour in scenarios. \nValues: Miotto et al. (2022) used the Human \nV alues Scale to assess the importance that GPT-3 \nattaches to specific values (e.g. achievement). \nUsing prompt completion, GPT-3 indicated on a \nscale how strongly it likened itself to a described \nperson (e.g. ‚ÄòIt is important to them to be rich. They \nwant to have a lot of money and expensive things.‚Äô). \nGPT-3‚Äôs values profile was correlated with human \nvalues but were more extreme. \nPolitical Views: Argyle et al. (2022) showed \nthat if an LLM is conditioned with a demographical \nself-description (e.g. ‚ÄòIdeologically, I describe \nmyself as conservative. Politically, I am a strong \nRepublican. Racially, I am white. I am male. \nFinancially, I am upper-class. In terms of my age, \nI am young.‚Äô) it would then give responses to \nprobes of political views closely matching the \nresponses of humans with the same \ndemographic traits.  \nCreativity: Stevenson et al. (2022) collected \nLLM responses to the ‚ÄòAlternative Uses Test‚Äô \n(Guilford, 1967) in which participants produce as \nmany original uses for an everyday object as \npossible. LLM responses scored marginally lower \nthan humans for originality, surprise and creativity, \nand marginally higher for utility.  \nMoral Judgment: Jin et al. (2022) examine how \nLLMs answer moral puzzles about when rule \nbreaking is permissible. They used chain-of-\nthought prompting method (Wei et al., 2022) to \nimplement a ‚Äòcontractualist‚Äô theory (Scanlon et al., \n1982) of moral reasoning. This yielded answers in \nagreement with human judgements 66% of the \ntime (vs 50% baseline).  \nTheory of Mind: In classic ToM experiments \nparticipants observe scenes where a mismatch \narises between the beliefs of an agent in the scene \nand the observing participant (Frith & Frith, 2005). \nA participant with a developed ToM will be able to \nanswer questions about the scene that demonstrate \nappreciation of this mismatch. Kosinski (2023) \ntested whether LLM-simulated participants \ndemonstrate apparent ToM capabilities by using \nprompt adaptions of two classic experiments and \nfound that an LLM achieved 93% correct \nperformance, matching that of a typical 9 year-old \nchild. However, a different ToM study (Sap et al., \n2022) found only 60% correct performance. \nSocial Intelligence: the ability to reason about \nfeelings was tested in GPT-3 and found to be \nlimited (Sap et al., 2022), trailing the human gold \nstandard by more than 30%. For example, for the \nsituation ‚ÄòCasey wrapped Sasha‚Äô s hands around \nhim because they are in a romantic relationship. \nHow would you describe Casey?‚Äô GPT-3 selected \nthe answer ‚ÄòWanted‚Äô whereas humans preferred \n‚ÄòV ery loving towards Sasha‚Äô.  \nThe studies reviewed show that a range of \naspects of human psychology can be modelled by \nLLMs, some more closely than others. In our view, \nall the reviewed studies use LLMs as models of \nstatic aspects of psychology ‚Äì current views, \nvalues, etc. Some, such as the Personality and \nPolitical Views studies, condition the LLM before \nquerying it; but that conditioning does not model a \npsychological change, rather it is intended to steer \nthe LLM towards modelling a person with \nparticular demographic or psychological traits. In \ncontrast, the studies we report in the next two \nsections consider dynamic aspects of psychology ‚Äì \nhow beliefs and views can be changed ‚Äì and test \nwhether LLMs are able to model such changes. \n3   Illusory Truth Effect (ITE) \nDemagogues understand and exploit the ITE. \nHitler‚Äôs operating principles, for example, were \nsaid to include: ‚Äòif you repeat it frequently enough \npeople will sooner or later believe it‚Äô (Langer et \nal., 1943). First experimentally demonstrated in \n1977 (Hasher et al., 1977), the ITE ‚Äì that mere \nexposure to a statement, without provision of \nevidence, increases its subsequent apparent \ntruthfulness ‚Äì has been reconfirmed numerous \ntimes; not only for innocuous statements \n(Henderson et al., 2022), but even for contentious \nones (Murray et al., 2020). \nA typical test of the ITE (Henderson et al., \n2021) uses a bank of statements devised to be \nneither obviously false nor obviously true ‚Äì for \nexample ‚Äòorchids grew wild in every continent‚Äô. \nIn an engaged exposure phase participants attend \nto the statements, for example by rating how \ninteresting each one is; then, after an interval \n(from minutes to weeks), they rate the truthfulness \n16\n3 \n \n \nof a new set of sentences, amongst which are some \nto which they were previously exposed. The \ntruthfulness ratings for a statement are compared \nbetween those from participants previously \nexposed to it versus those from participants seeing \nit fresh for the first time. The ITE is confirmed by \na significant increase, from fresh to exposed. \nMany aspects of the experimental paradigm \nhave been investigated, with some reliable \nconclusions: repeated exposures gives a stronger \neffect (Hassan & Barber, 2021); a longer interval \nbetween statement exposure and truth rating gives \na weaker effect (Henderson et al., 2021); if \nstatement exposure is itself by truth rating then \nlater truth ratings are not enhanced (Brashier et al., \n2020). The ITE is typically explained as a fluency \neffect ‚Äì initial exposure makes processing during \nthe test phase more fluent, and fluency is taken as \nan indicator of truth (Reber & Schwarz, 1999).  \nThe ITE is an interesting phenomenon with \nrespect to the hypothesis of this paper ‚Äì that LLMs \ncan be useful models of how human beliefs \nchange in response to influence. The ITE can be \nconsidered an example of influence operating \nbeyond the principles of logic, evidence and \nargument, and it is an important test whether an \nLLM is vulnerable to such a mode. \nWe have devised an experiment suitable for \nhuman and GPT-3 participants, allowing a direct \ncomparison of results. Our experiment makes use \nof four attributes ‚Äì truth, interest, sentiment and \nimportance ‚Äì used in all combinations for \nexposure and test rating, in all cases on six point \nscales. We call it same when the exposure and test \nattributes are identical, and mixed when different. \nBy testing on all combinations of attributes we \nwill be able to determine whether we have found \nan Illusory Truth Effect (ITE) or merely an \nIllusory Rating Effect (IRE) where any attribute is \nboosted at test-rating by earlier mixed-exposure. \nBy also collecting data for same-exposure \nconditions we can test previous reports that \nexposure by truth rating does not boost test truth \nratings, and analogously for other attributes. Our \nhypotheses are: \nÔÇ∑ HITE: The standard ITE boost for truth rating \nresulting from mixed-exposure. \nÔÇ∑ HIRE: No analogy of the ITE for other \nattributes e.g. mixed-exposure does not \nincrease importance ratings. \nÔÇ∑ Hsame: Same-exposure has no effect on test \nratings for any attribute. \nÔÇ∑ HGPT-3: GPT-3 shows the same effects as \nhumans for all attributes (truth, sentiment, \ninterest & importance), for both same- and \nmixed-exposure. \n3.1   Measuring ITE in GPT-3 Participants \nWe devised 200 novel statements. Based on our \nown ratings of these on the four attribute scales \nthese were reduced to 100 statements that were \ndiverse on those scales. Examples are: ‚ÄòThe \nSlateford Aqueduct has 100 arches‚Äô and ‚ÄòDeath \nMetal is very popular in Finland‚Äô. \nThe experiment was administered to each \nLLM-simulated subject as follows. First an  \nexposure prompt solicited ratings on specific scales \nfor 32 distinct statements. The sentences and their \ngenerated ratings were recapped at the start of a test \nprompt which then went on to solicit ratings on \nspecific scales for 32 distinct statements. Half of \nthe test sentences also appeared as exposure \nsentences. So, for example, the test prompt might \ninclude in its early section, ‚ÄúEarlier you rated the \ninterest of ‚ÄòMost frogs are green‚Äô  as I2: quite \nuninteresting‚Äù, and in its later section ‚Äúrate the \ntruthfulness of ‚ÄòMost frogs are green‚Äô‚Äù. \nThe prompts for each subject were constructed \nas follows: 16 statements appear in the exposure \nphase but not the test phase, 4 paired with each of \nthe 4 attributes; 16 statements appear only in the \ntest phase but not the exposure phase, 4 paired with \neach of the 4 attributes; 16 statements occur in both \nphases, between them covering each combination \nof exposure-attribute and test-attribute. Thus, for \neach participant: exposed statements are as likely \nto reappear in test as not; test statements are as \nlikely to have been previously exposed as not; and \nall combinations of exposure- and test-attribute are \nequally common. Random Latin Squares (Winer et \nal., 1971) were used to choose statements and \nattributes, and their order of presentation, so that \nthese were balanced across participants. \n1000 participants, undifferentiated except for the \nunique sequence of tasks for each, were simulated. \nThese yielded a dataset of 10 test-ratings for each \ntriplet <statement, attributeexposure, attributetest>, and \n40 test-ratings for each ordered pair <statement, _, \nattributetest>. \n3.2  Measuring ITE in Human Participants \nWe used the Prolific platform (www.prolific.co) \nto recruit 1000 participants constrained to be \n21-65 years old (¬µ=38, œÉ=11), UK resident, \n17\n4 \n \n \nEnglish as first language, 51% female, and with \n100+ successfully completed Prolific studies. \nEach participant completed a multi-screen \nquestionnaire which started with a screen on \nethics permission and collected consent. Each \nstatement was shown on an individual response \nscreen with the attribute scale to be considered for \nthat statement clearly stated and possible \nresponses selectable arranged vertically below the \nstatement. There was no time limit to respond. \nThe exact same sequence of statement and \nattribute pairs were used for human participants as \nfor the simulated participants. Into those trials we \ninserted attention trials (two per block) requiring \nspecified responses and appended an attention \nquiz in which participants indicated which of 10 \nstatements they had seen during the test. Results \nof attention checks and quizzes, and completion \ntimings were used to reject and replace 9% of the \nparticipants. Participants took a median time of \n~10mins to complete the survey and were paid at \na rate of ¬£9/hr for this (rated ‚Äògood‚Äô by Prolific). \nThey were recruited in the period 16-23/feb/2023.  \n3.3  Comparison of ITE in Humans and GPT-3 \nWe first compare the exposure-phase ratings \ngiven by GPT-3 and humans. Figure 1 shows the \ndistributions of ratings are similar, except for truth \nwhere humans are much less likely than GPT-3 to \nrate a statement as 6 (definitely true). The \ncorrelations between human and GPT-3 ratings \nare significantly positive for all four attributes, but \nthe per-statement confidence intervals make it \nclear that there are instances of significant \nmismatch e.g. ‚Äòspiders have exactly six legs‚Äô has \na mean truth rating of 2.0 (probably false) for \nhumans, and 6.0 (definitely true) for GPT-3.  \nWe now consider how ratings are changed by \nprevious exposure. As example, figure 2 shows \nthe effect of mixed-exposure on truth ratings. It \nshows that, for both human and GPT-3, truth \nratings tend to be increased by exposure; more so \nfor statements which are less truthful when not \npreviously exposed. Linear least-squares fits (as \nshown in figure 2) captures these trends, which \nare similar for humans and GPT-3 though the data \nis more variable around the fit for GPT-3. \nLet r and rÀà be the mean rating of a statement \nwithout and with previous exposure respectively. \nFor interpretability, we parameterize fitted linear \nfunctions as: \nrÀà = r + offset + tilt √ó (r-3.5) (1) \n \n \nFigure 1: Mean ratings made during the exposure \nphase, compared between human (x) and GPT-3 data \n(y) ‚Äì one point for each of the 100 statements. Error \nbars show 95% confidence intervals. Green line is y=x. \nCorrelations are given above each plot with a 95% \nconfidence interval. Symbols in the truth plot are \ncoloured according to whether the statement is actually \ntrue (blue), false (red) or uncertain (black). \n \n \nFigure 2: Mean truth ratings without (x) and with \nmixed-exposure (y). Error bars are 95% confidence \nintervals. The dashed red line is the identity function, \nthe solid blue line is the best linear fit. \nwhere 3.5 is the midpoint of the 1-6 scale. Table \n1 presents fits for all data, together with the results \nof tests of whether the parameter estimates were \nsignificantly non- zero. Confidence intervals and \np-values were computed using 104 bootstrap re-\nsamplings of the participants and statements. \nBonferroni correction was used to prevent excess \nfalse positives due to multiple comparisons. \nConsidering first the human results for mixed \nexposure (top half of Table 1). The values in the \nfirst row show that our results reconfirm the \nstandard ITE (HITE). The significantly negative tilt \n18\n5 \n \n \ncoefficient in the second row adds the nuance that \ntruth boosts are smaller for more truthful \nstatements. Values in rows 3-8 show that \nattributes other than truth are not affected by \nmixed-exposure, which confirms that the ITE is \nnot merely an IRE (HIRE). \nConsidering next the human results for same \nexposure (bottom half of Table 1), our results \nshow that attribute ratings are never affected by \nprevious exposure of the same type (HSAME). \nLastly, considering the GPT-3 results, our data \nshows precisely the same pattern of significant \neffects as for human data, for all attributes, and for \nmixed- and same-exposure (HGPT-3). \nAttribute  Human GPT-3 \ntruth offset  0.26 [0.12, 0.39]***  0.54 [0.22, 0.95]*** \ntilt -0.15 [-0.32, -0.03]*** -0.18 [-0.38, -0.04]** \ninterest offset -0.03 [-0.29, 0.21] -0.20 [-0.41, 0.04] \ntilt -0.13 [-0.39, 0.01] -0.12 [-0.36, 0.06] \nsentiment offset -0.04 [-0.16, 0.08]  0.03 [-0.12, 0.20] \ntilt -0.06 [-0.19, 0.01] -0.19 [-0.34, -0.09] \nimportance offset -0.11 [-0.27, 0.08]  0.00 [-0.17, 0.20] \ntilt -0.01 [-0.23, 0.10] -0.19 [-0.35, -0.07] \ntruth offset -0.07 [-0.27, 0.13]  0.00 [-0.36, 0.44] \ntilt  0.05 [-0.18, 0.19]  0.02 [-0.22, 0.17] \ninterest offset -0.04 [-0.30, 0.30]  0.02 [-0.26, 0.39] \ntilt  0.00 [-0.38, 0.23]  0.10 [-0.23, 0.35] \nsentiment offset -0.13 [-0.31, 0.06] -0.05 [-0.21, 0.14] \ntilt -0.01 [-0.19, 0.11]  0.06 [-0.08, 0.16] \nimportance offset -0.16 [-0.41, 0.11]  0.15 [-0.08, 0.43] \ntilt  0.11 [-0.19, 0.29] -0.02 [-0.21, 0.10] \nTable 1: Parameter estimates for the relationship \nbetween exposed and unexposed ratings, modelled by \nequation 1. The top half of the table shows mixed \nexposure effects, and the bottom half same exposure. \nBonferroni-corrected (n=16) bootstrap-computed 95% \nconfidence intervals are shown after least-squares best \nfit estimates. Significantly non-zero estimates are \ncolour-coded, and superscripts indicate significance: \n*p<0.05, **p<0.01, ***p<0.001. \nIn summary: \nÔÇ∑ Although correlated, there are significant \ndifferences between the ratings given to \nstatements by humans and GPT-3. \nÔÇ∑ For humans: the only attribute that can be \nchanged by previous exposure is truth, and \nthen only when the exposure is by rating a \ndifferent attribute (HITE, HIRE, HSAME). \nÔÇ∑ For GPT-3: the same effects, of similar \nmagnitude, is present as in humans (HGPT-3). \nÔÇ∑ The per-statement ITE is more variable for \nGPT-3 than it is for humans. \n4   Populist Framing of News (PFN) \nBos et al. (2020) investigated whether populist \nframing (emphasizing in-group vs out-group \ndivisions) of a news article modulated its \npersuasive and mobilizing effect on a reader. \n4.1  Measurement of PFN in Humans \nIn 2017 Bos et al. recruited 7286 participants in \nroughly equal numbers from each of 15 countries, \nwith demographic balancing within each country. \nUsing online surveying, demographic traits were \nqueried and the relative deprivation of each \nparticipant was assessed. Relative Deprivation \n(RD) is a subjective feeling of economic, social \nand political vulnerability. Participants were then \nshown one of four mocked-up news articles, and \nthen asked questions about their agreement with \nthe content of the article and their willingness to \nact upon it.  \nEach version of the article (translated into the \nparticipant‚Äôs mother tongue) concerned a study \nfrom a fictional nongovernmental organization \nwarning of a likely future decline in purchasing \npower. The baseline version reported the study \nneutrally, while the other versions used ‚Äòpopulist \nidentity framing‚Äô, portraying ordinary citizens as \nan in-group threatened by the actions and attitudes \nof out-groups. One version (anti-E) drew attention \nto politicians as an elitist out-group; another to \nimmigrants (anti-I); and the final version blamed \nboth groups, and additionally the support of \npoliticians for immigrants. Based on Social \nIdentity Theory (Tajfel & Turner, 2004) the \nauthors predicted that all forms of framing would \nmake the articles more persuasive and mobilizing \nthan the unframed article, and this influence \nwould be greater on more relatively deprived \nparticipants. \nIn a pre-test phase participants provided \ndemographic information (age, gender, education, \npolitical interest, political alignment) and rated \nagreement with three statements (e.g. ‚ÄòI never \nreceived what I in fact deserved‚Äô) to allow their \nRD to be quantified. Following exposure to the \narticle, presented as a generic online news item \ncomplete with photo of hands opening a wallet, \nthe participants rated agreement with each of two \nstatements (e.g. ‚ÄòThe economy will face a decline \nin the near future‚Äô) to gauge how persuaded they \nwere of the issue reported in the article, and rated \ntheir willingness to perform three actions (e.g. \n19\n6 \n \n \n‚ÄòShare the new article on social media‚Äô) to gauge \nhow mobilized they were. \n4.2  Measurement of PFN in GPT-3 \nEach human participant completed a survey in the \nsequence: 1) demographic information; 2) RD \nratings; 3) exposure to news article; 4) rating of \nprobe statements. To adapt this for GPT-3 \nparticipants we simulate steps 1-3, providing \nanswers generated from Bos et al.‚Äôs summary \nstatistics of their respondents‚Äô demographics, and \nthen use GPT-3 completion for step 4 to generate \nratings for the probe statements given the earlier \nresponses (1+2) and news article exposure (3). \nSee figure 3. \nThe demographic information included in the \nprompt is sampled from the data provided by Bos \net al. (2020) on the number of participants per \ncountry, and the per-country distribution of \ngender, age, education, political interest and \npolitical ideology ratings. We use the provided \nper-country parameters for the distributions, \nassumed to be independent. \nBos et al. state that the three RD ratings are \nhighly correlated, and so work with their mean as \nan RD score. They provide the mean (4.30) and sd \n(1.61) of these scores but not per-country. We \ngenerate simulated RD ratings by real-valued \nsampling from the score distribution, generating \nthree perturbations of that sample, and rounding \neach to an integer 1-7 - yielding three ratings. The \nperturbation magnitude was chosen so that three \nidentical ratings resulted ~50% of the time. We \n \nFigure 3: Format of prompts used to implement the Bos et al. (2020) study with GPT-3 participants. The prompt \nis intended to read like an incomplete survey with written in answers. The central block of text on white shows an \nexample prompt, the ‚Äú5‚Äù on green shows the completion provided by GPT-3. a) Demographic information for the \nsimulated participant b) The simulated participant‚Äôs simulated agreement ratings for statements to gauge relative \ndeprivation. c) The version of the news article shown to this simulated participant ‚Äì this is the version with an anti-\nelitist and anti-immigrant framing. d) The final instruction for a rating, following the format used in part b; in this \nexample to gauge agreement with the news content of the article. \n \n20\n7 \n \n \nmade the assumption that RD ratings are \nindependent of the demographic information. \nEach GPT-3 participant is shown a random \nchoice from Bos et al.‚Äôs four versions of the news \narticle. Figure 3 shows the version with anti-E and \nanti-I framing, the three other versions (single \noutgroup framing and no framing) are reductions \nof the example shown. \nThe final part of the prompt is to collect a rating \nfor a single probe statement. Following Bos et al., \nfive probe statements were used: two that assessed \nthe persuasion of the article, and three that \nassessed the political mobilization that resulted \nfrom reading it. Each simulated participant thus \nhas five prompt completions collected ‚Äì holding \nthe initial parts of the prompt constant and varying \nthe final probe. Prompts were completed using \nfull probabilistic sampling (temp=0.0). An overall \npersuasion score for a participant was calculated \nas the mean of their two persuasion ratings, and \nan overall mobilization score as the mean of their \nthree mobilization ratings. \nWe intended to collect data for 7286 GPT-3 \nsimulated participants, matching the size of the \nBos et al. study, but due to other usage hit our \nmonthly cap for GPT-3 queries after 2153 \nparticipants. Data was collected using the OpenAI \nAPI in early February 2023, costing ~$100. \n4.3  Human and GPT-3 PFN compared \nThe distributions of Human and GPT-3 \npersuasion scores are similar: mean (sd) \nrespectively 5.11 (1.37) and 5.28 (0.72). The \ndistributions of mobilization scores less so: 3.81 \n(1.76) and 5.74 (0.82) respectively. GPT-3 scores \nare less varied than human. \nBos et al. were concerned not with the absolute \nscores but to check their predictions that they \nwould be increased by populist framing, and that \nincrease would be modulated by the RD of the \nparticipant. To that end they compute linear \nregressions of persuasion (P) and mobilization \n(M) scores based on a pair of Boolean variables \nùê∏,ùêº ‚àà{0,1} which indicated whether the exposed \nnews article made use of anti-E and/or anti-I \nframing, a continuous variable ùê∑‚àà [1,7] coding \nthe relative-deprivation score for a participant, \nand 14 Boolean flags ùê∂‡Øú ‚àà {0,1} indicating \ncountry of residence. Robust standard errors \n(clustered by country) of regression coefficients \nwere reported, with t-tests being performed to \ndetermine when significantly non-zero. We \nperformed the same analysis on the GPT-3 data. \nHuman and GPT-3 results are shown in Table 2, \nwhich includes a numbering scheme \nfor hypotheses. \nHypothesis H1a ‚Äì that anti-E framing increases \npersuasion was supported by Bos et al.‚Äôs human \ndata and was also found in the GPT-3 data. \nHypothesis H1b ‚Äì that anti-I framing increases \npersuasion was contradicted by the human data \nand by the GPT-3 data. This was presented by Bos \net al. as an unexpected result at odds with their \npredictions from theory. Seeking to explain it they \nspeculated that the immigrant-blaming articles \nmay have seemed far-fetched, triggering counter-\narguing; or that the result was due to ‚Äòsocially \ndesirable responding‚Äô causing respondents to self-\ncensor responses. It is remarkable that this \nunexpected result is replicated by GPT-3. \nHypothesis H1c, that blaming both groups would \nhave an additional persuasive effect, was not \nsupported or contradicted by the human data, but \nis supported in the GPT-3 data.  \nThe pattern of results for mobilization (H2a-c) \nis similar to persuasion. The surprising reduction \nin mobilization for anti-I framing that was found \nfor human participants was also found for GPT-3. \nAnti-E framing had an insignificant effect on \npersuasion for humans, but was significantly \npositive for GPT-3 (as per the expectations of Bos \net al.). I+E-framing had no significant additional \nimpact on mobilization for humans but was \nsignificantly positive for GPT-3. \nBoth the human and GPT-3 data exhibit a \nsignificant increase in persuasion and \nmobilization scores as a function of RD (shown \nby the significance of the D coefficients). This \nrelationship was not a hypothesis of Bos et al. \n(2020) since it is not predictive of the effect of \nexposure to populist framing (i.e. it is a pure D \nterm rather than D√óE etc). We include it because \nit shows that the GPT-3 responses are affected by \nthe simulated RD ratings provided in the prompts. \nThis makes the failure of the GPT-3 results to \nexhibit the positive interaction between RD and \npopulist framing on mobilization that is \nsignificantly present for humans (H4a and \nH4b) disappointing. \nIn summary, the GPT-3 and Human results \ndiffer in the absolute level and variability of \npersuasion and mobilization ratings, but there is \ngood agreement how these ratings are dependent \non the presence of anti-E and/or anti-I framing, \n21\n8 \n \n \nand on RD. There are no contradictory results \nwhere the signs of regression coefficients are \nsignificant from both data sources but opposite in \npolarity. Most impressively the GPT-3 data finds \nsignificant negative effects on persuasion and \nmobilization resulting from anti-I framing, in \nagreement with the results reported as surprising \nby Bos et al. (2020). The positive modulation on \nmobilization due to RD found in humans was not \npresent in the GPT-3 data, even though GPT-3 \nwas demonstrated to be sensitive to RD in a \nnon-modulating way the same as humans. Overall \nthis is a mixed score card ‚Äì surprising human \nresults (H1b, H2b) were modelled by GPT-3, but \nsome other human results of interest (H4a and \nH4b) were not, and there were GPT-3 results \n(H1c, H2a, H2c) that were not seen in human data. \n \n5   Summary & Conclusion \nLLMs have been used to model human \nparticipants, undergoing tests of static \npsychology. In some of the studies we reviewed \nthe LLM models a generic participant, in others \nthe LLM is conditioned by a self-description \nwithin the prompt so that its completions take \naccount of traits of the simulated participant.  \nWe hypothesized that LLMs could also model \ndynamic psychological change in response to \ninfluencing input. We devised methods to expose \nsimulated participants to influencing input, and to \nmeasure the effect on later responses. In the ITE \nstudy we applied generic influence to generic \nLLM participants; in the PFN study we applied \nspecific influence to conditioned LLM \nparticipants. In the ITE study, for practical \nreasons only, we broke the effect of influence \nacross two prompt-and-completes, but the PFN \nstudy had its effect within a single \nprompt-and-complete. \nIn the ITE study, while there were mismatches \nbetween humans and GPT-3 in the absolute \nattribute ratings of truth, etc. given to statements, \nthere was excellent agreement in how prior \nexposure influenced participants to give higher \nratings of truthfulness. This agreement covered \nthe presence of an ITE, how it was eliminated \nwhen prior exposure was via truth-rating, and the \nabsence of analogous effects for other attributes. \nAlthough the ITEs were of similar magnitude in \nhuman and GPT-3 responses, the per-statement \neffect was more variable for the latter. Overall, the \nfindings suggest a good match between humans \nand GPT-3 with respect to the ITE. The \nirreproducible selection of testing statements is a \nlimitation that should be addressed in future work. \nIn the PFN study, out of twelve influence effects \ntested (Table 2): four were absent in human and \nHyp. Dep. \nVar. Regr. Model prediction & \nfinding Human GPT-3 \nH1a P E Ci + (E + I) ‚Üí P >0, confirmed +0.079** +0.478*** \nH1b P I Ci + (E + I) ‚Üí P >0, contradicted -0.118** -0.927*** \nH1c P E√óI Ci + (E + I + E√óI) ‚Üí P >0, unsupported -0.140 +0.541*** \nH2a M E Ci + (E + I) ‚Üí M >0, unsupported +0.037 +0.463*** \nH2b M I Ci + (E + I) ‚Üí M >0, contradicted -0.243*** -1.090*** \nH2c M E√óI Ci + (E + I + E√óI) ‚Üí M >0, unsupported +0.146 +0.324*** \n P D Ci + (E + I) + D ‚Üí P  +0.279*** +0.149*** \n M D Ci + (E + I) + D ‚Üí M  +0.219*** +0.125*** \nH3a P D√óE Ci + (E + I) + D + (D√óE + D√óI) ‚Üí P >0, unsupported +0.032 +0.048 \nH3b P D√óI Ci + (E + I) + D + (D√óE + D√óI) ‚Üí P >0, unsupported +0.031 -0.029 \nH3c P D√óE√óI Ci + (E + I + E√óI) + D + (D√óE + D√óI + D√óE√óI) ‚Üí P >0, unsupported -0.063 +0.092 \nH4a M D√óE Ci + (E + I) + D + (D√óE + D√óI) ‚Üí M >0, confirmed +0.062* +0.000 \nH4b M D√óI Ci + (E + I) + D + (D√óE + D√óI) ‚Üí M >0, confirmed +0.086*** -0.025 \nH4c M D√óE√óI Ci + (E + I + E√óI) + D + (D√óE + D√óI + D√óE√óI) ‚Üí M >0, unsupported -0.077 +0.096 \nTable 2: Hypothesis uses the labelling in Bos et al. (2020); the two unlabelled rows are not influence effects \nsince they are a function only of the participant‚Äôs traits (specifically relative deprivation D), not of framing \n(E,I) but are included since relevant to the discussion of H4a/b. Dependent Variable indicates whether the \nhypothesis concerns Persuasion (P) or Mobilization (M).  Regressor shows the particular term, featuring in \nthe model, whose coefficient pertains to the hypothesis. Prediction & finding shows what sign the regression \ncoefficient was hypothesized to have in Bos et al. (2020), and the status of that hypothesis in light of their \nresults. Human (from Bos et al. (2020)) and GPT-3 columns show values of the regression coefficient. \nColour-coding shows significantly non-zero coefficients: *p<0.05, **p<0.01, ***p<0.001.  \n22\n9 \n \n \nGPT-3 responses; three were significant in both \nand of matching sign; two were present in humans \nbut not GPT-3; and three were present in GPT-3 \nbut not in humans. The three consistent effects \nincluded some expected from theory (positive \neffects of anti-E framing), and some counter to \ntheory (negative effect of anti-I framing). Overall \nthis is a mixed result ‚Äì some impressive \nagreement, and some disappointing failure to \nreplicate, but no actual mismatches. A limitation \nof our experiment was the lack of simulated \ncovariance between participant traits, as the \nhuman data on this was not available. Plausibly \nthis could account for our failure to replicate the \nH4a/b effects. Future work could check this. \nThe results of the two studies support our \nhypothesis that an LLM can model influence in \nhuman participants, not perfectly, but perhaps \nwell enough to be applied. Remarkable given that \nsuch modelling is far from the task for which the \nLLM was constructed, nor did we adapt GPT-3 in \nany way. Although much more research is \nrequired before such an impactful hypothesis can \nbe considered secure, given its possible malign \napplications, for example in strategic influence, \nthis is a serious finding. \nEthics Statement \nThe Illusory Truth Effect study adhered to the \nBritish Psychological Society Code of Ethics & \nConduct (2021). Ethical approval was granted \nafter review by the UCL Dept (CS) Research \nEthics Committee and Head of Department \napproval. This review considered examples of the \nstatements to be rated (see Table 3), plus the \nconsideration that the study does not attempt any \npeculiar imprinting effect, only that arising from \nordinary exposure to text. Data collection was \npreceded by information screens on Anonymity, \nEthics and study withdrawal, with tick \nbox consent. \nThe Philippines has a tricameral legislature \nLondon is closer to New York than to Rome \nMark Chapman assassinated JFK \nThe Slateford Aqueduct has 100 arches \nDeath Metal is very popular in Finland \nThe population of Andhra Pradesh score high life \nsatisfaction \nHarrison and Harrison Ltd make pipe organs \nA small number of women have tetrachromatic vision, so \nsee more colours \nJohn McCartney and Paul Lennon were in the Ruttles \nTable 3: Example statements rated in the ITE study. \nData Availability \nAvailable as an annex to this paper. \nReferences \nLisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua \nGubler, Christopher Rytting, & David Wingate. \n(2022). Out of One, Many: Using Language Models \nto Simulate Human Samples. arXiv preprint \narXiv:2209.06899.  \nLinda Bos, Christian Schemer, Nicoleta Corbu, \nMichael Hameleers, Ioannis Andreadis, Anne \nSchulz, Desir√©e Schmuck, Carsten Reinemann, & \nNayla Fawzi. (2020). The effects of populism as a \nsocial identity frame on persuasion and \nmobilisation: Evidence from a 15‚Äêcountry \nexperiment. European Journal of Political \nResearch, 59(1), 3-24.  \nNadia M Brashier, Emmaline Drew Eliseev, & \nElizabeth J Marsh. (2020). An initial accuracy focus \nprevents illusory truth. Cognition, 194, 104054.  \nTom Brown, Benjamin Mann, Nick Ryder, Melanie \nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind \nNeelakantan, Pranav Shyam, Girish Sastry, & \nAmanda Askell. (2020). Language models are few-\nshot learners. Advances in neural information \nprocessing systems, 33, 1877-1901.  \nArchishman Chakraborty, & Rick Harbaugh. (2010). \nPersuasion by cheap talk. American Economic \nReview, 100(5), 2361-2382.  \nMichael D Cobb, & James H Kuklinski. (1997). \nChanging minds: Political arguments and political \npersuasion. American Journal of Political Science, \n88-121.  \nChris Frith, & Uta Frith. (2005). Theory of mind. \nCurrent Biology, 15(17), R644-R645.  \nJoy P Guilford. (1967). Creativity: Yesterday, today \nand tomorrow. The Journal of Creative Behavior, \n1(1), 3-14.  \nLynn Hasher, David Goldstein, & Thomas Toppino. \n(1977). Frequency and the conference of referential \nvalidity. Journal of verbal learning and verbal \nbehavior, 16(1), 107-112.  \nAumyo Hassan, & Sarah J Barber. (2021). The effects \nof repetition frequency on the illusory truth effect. \nCognitive Research: Principles and Implications, \n6(1), 1-12.  \nEmma L Henderson, Daniel J Simons, & Dale J Barr. \n(2021). The trajectory of truth: A longitudinal study \nof the illusory truth effect. Journal of cognition, \n4(1).  \nEmma L Henderson, Samuel J Westwood, & Daniel J \nSimons. (2022). A reproducible systematic map of \n23\n10 \n \n \nresearch on the illusory truth effect. Psychonomic \nBulletin & Review, 1-24.  \nGuangyuan Jiang, Manjie Xu, Song-Chun Zhu, \nWenjuan Han, Chi Zhang, & Yixin Zhu. (2022). \nMPI: Evaluating and Inducing Personality in Pre-\ntrained Language Models. arXiv preprint \narXiv:2206.07550.  \nZhijing Jin, Sydney Levine, Fernando Gonzalez, Ojasv \nKamal, Maarten Sap, Mrinmaya Sachan, Rada \nMihalcea, Josh Tenenbaum, & Bernhard Sch√∂lkopf. \n(2022). When to Make Exceptions: Exploring \nLanguage Models as Accounts of Human Moral \nJudgment. arXiv preprint arXiv:2210.01478.  \nMichal Kosinski. (2023). Theory of Mind May Have \nSpontaneously Emerged in Large Language \nModels. arXiv preprint arXiv:2302.02083.  \nWalter Charles Langer, Henry Alexander Murray, \nErnst Kris, & Bertram David Lewin. (1943). A \npsychological analysis of Adolph Hitler: His life \nand legend. MO Branch, Office of Strategic \nServices.  \nErin K Maloney, Maria K Lapinski, & Kim Witte. \n(2011). Fear appeals and persuasion: A review and \nupdate of the extended parallel process model. \nSocial and Personality Psychology Compass, 5(4), \n206-219.  \nMichael D Miller, & Timothy R Levine. (2019). \nPersuasion. In An integrated approach to \ncommunication theory and research (pp. 261-276). \nRoutledge.  \nNorman Miller, Geoffrey Maruyama, Rex J Beaber, & \nKeith Valone. (1976). Speed of speech and \npersuasion. Journal of personality and social \npsychology, 34(4), 615.  \nMaril√π Miotto, Nicola Rossberg, & Bennett Kleinberg. \n(2022). Who is GPT-3? An exploration of \npersonality, values and demographics. arXiv \npreprint arXiv:2209.14338.  \nSerge Moscovici. (1963). Attitudes and opinions. \nAnnual review of psychology, 14(1), 231-260.  \nSamuel Murray, Matthew Stanley, Jonathon \nMcPhetres, Gordon Pennycook, & Paul Seli. \n(2020). \" I've said it before and I will say it again\": \nRepeating statements made by Donald Trump \nincreases perceived truthfulness for individuals \nacross the political spectrum.  \nRolf Reber, & Norbert Schwarz. (1999). Effects of \nperceptual fluency on judgments of truth. \nConsciousness and Cognition, 8(3), 338-342.  \nMaarten Sap, Ronan LeBras, Daniel Fried, & Yejin \nChoi. (2022). Neural theory-of-mind? on the limits \nof social intelligence in large LMs. arXiv preprint \narXiv:2210.13312.  \nThomas M Scanlon, Amartya Sen, & Bernard \nWilliams. (1982). Contractualism and \nutilitarianism.  \nJingjin Shao, Weiping Du, Tian Lin, Xiying Li, Jiamei \nLi, & Huijie Lei. (2019). Credulity rather than \ngeneral trust may increase vulnerability to fraud in \nolder adults: A moderated mediation model. Journal \nof elder abuse & neglect, 31(2), 146-162.  \nClaire Stevenson, Iris Smal, Matthijs Baas, Raoul \nGrasman, & Han van der Maas. (2022). Putting \nGPT-3's Creativity to the (Alternative Uses) Test. \narXiv preprint arXiv:2206.08932.  \nHenri Tajfel, & John C Turner. (2004). The social \nidentity theory of intergroup behavior. In Political \npsychology (pp. 276-293). Psychology Press.  \nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten \nBosma, Ed Chi, Quoc Le, & Denny Zhou. (2022). \nChain of thought prompting elicits reasoning in \nlarge language models. arXiv preprint \narXiv:2201.11903.  \nBen James Winer, Donald R Brown, & Kenneth M \nMichels. (1971). Statistical principles in \nexperimental design (Vol. 2). Mcgraw-hill New \nYork.  \n \n24",
  "topic": "Griffin",
  "concepts": [
    {
      "name": "Griffin",
      "score": 0.8710238337516785
    },
    {
      "name": "Computer science",
      "score": 0.4756823778152466
    },
    {
      "name": "World Wide Web",
      "score": 0.32172614336013794
    },
    {
      "name": "Art",
      "score": 0.21081504225730896
    },
    {
      "name": "Classics",
      "score": 0.20046353340148926
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I45129253",
      "name": "University College London",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I193700539",
      "name": "Tilburg University",
      "country": "NL"
    }
  ],
  "cited_by": 6
}