{
  "title": "Discriminative pruning of language models for Chinese word segmentation",
  "url": "https://openalex.org/W2103407879",
  "year": 2006,
  "authors": [
    {
      "id": "https://openalex.org/A5100462010",
      "name": "Jianfeng Li",
      "affiliations": [
        "Toshiba (Japan)"
      ]
    },
    {
      "id": "https://openalex.org/A5100386394",
      "name": "Haifeng Wang",
      "affiliations": [
        "Toshiba (Japan)"
      ]
    },
    {
      "id": "https://openalex.org/A5065930552",
      "name": "Dengjun Ren",
      "affiliations": [
        "Toshiba (Japan)"
      ]
    },
    {
      "id": "https://openalex.org/A5108616690",
      "name": "Guohua Li",
      "affiliations": [
        "Toshiba (Japan)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2158148237",
    "https://openalex.org/W2154124206",
    "https://openalex.org/W1797288984",
    "https://openalex.org/W2140016149",
    "https://openalex.org/W4302312245",
    "https://openalex.org/W287031571",
    "https://openalex.org/W2036516910",
    "https://openalex.org/W3021452258",
    "https://openalex.org/W2441154163",
    "https://openalex.org/W1982498087",
    "https://openalex.org/W2108220507",
    "https://openalex.org/W1903115690",
    "https://openalex.org/W2005076803",
    "https://openalex.org/W2086628205",
    "https://openalex.org/W1549285799",
    "https://openalex.org/W1558333962",
    "https://openalex.org/W2169418696"
  ],
  "abstract": "This paper presents a discriminative pruning method of n-gram language model for Chinese word segmentation. To reduce the size of the language model that is used in a Chinese word segmentation system, importance of each bigram is computed in terms of discriminative pruning criterion that is related to the performance loss caused by pruning the bigram. Then we propose a step-by-step growing algorithm to build the language model of desired size. Experimental results show that the discriminative pruning method leads to a much smaller model compared with the model pruned using the state-of-the-art method. At the same Chinese word segmentation F-measure, the number of bigrams in the model can be reduced by up to 90%. Correlation between language model perplexity and word segmentation performance is also discussed.",
  "full_text": null,
  "topic": "Bigram",
  "concepts": [
    {
      "name": "Bigram",
      "score": 0.9701176285743713
    },
    {
      "name": "Perplexity",
      "score": 0.8871423006057739
    },
    {
      "name": "Discriminative model",
      "score": 0.8821877241134644
    },
    {
      "name": "Language model",
      "score": 0.8205010890960693
    },
    {
      "name": "Computer science",
      "score": 0.753990650177002
    },
    {
      "name": "Pruning",
      "score": 0.7370857000350952
    },
    {
      "name": "Artificial intelligence",
      "score": 0.7075777649879456
    },
    {
      "name": "Word (group theory)",
      "score": 0.6482948064804077
    },
    {
      "name": "Text segmentation",
      "score": 0.556887686252594
    },
    {
      "name": "Segmentation",
      "score": 0.5551983118057251
    },
    {
      "name": "Natural language processing",
      "score": 0.4512367844581604
    },
    {
      "name": "Speech recognition",
      "score": 0.4394019842147827
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.40116602182388306
    },
    {
      "name": "Trigram",
      "score": 0.19038790464401245
    },
    {
      "name": "Mathematics",
      "score": 0.18324780464172363
    },
    {
      "name": "Geometry",
      "score": 0.0
    },
    {
      "name": "Agronomy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1292669757",
      "name": "Toshiba (Japan)",
      "country": "JP"
    }
  ],
  "cited_by": 6
}