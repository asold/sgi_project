{
  "title": "Pretrained Transformer Language Models Versus Pretrained Word Embeddings for the Detection of Accurate Health Information on Arabic Social Media: Comparative Study",
  "url": "https://openalex.org/W4226316739",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2979455463",
      "name": "Yahya Albalawi",
      "affiliations": [
        "Taibah University",
        "University of Limerick"
      ]
    },
    {
      "id": "https://openalex.org/A2150185657",
      "name": "Nikola S. Nikolov",
      "affiliations": [
        "University of Limerick"
      ]
    },
    {
      "id": "https://openalex.org/A2129448502",
      "name": "Jim Buckley",
      "affiliations": [
        "University of Limerick"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2566625606",
    "https://openalex.org/W2909837903",
    "https://openalex.org/W2565488655",
    "https://openalex.org/W2921698205",
    "https://openalex.org/W2917667443",
    "https://openalex.org/W1963262760",
    "https://openalex.org/W2607331151",
    "https://openalex.org/W3081962606",
    "https://openalex.org/W2772789967",
    "https://openalex.org/W3092238560",
    "https://openalex.org/W3193221073",
    "https://openalex.org/W2979657322",
    "https://openalex.org/W2537021188",
    "https://openalex.org/W2164900082",
    "https://openalex.org/W3021204441",
    "https://openalex.org/W2022783018",
    "https://openalex.org/W3080590497",
    "https://openalex.org/W2744425746",
    "https://openalex.org/W2963704837",
    "https://openalex.org/W2974087526",
    "https://openalex.org/W2806383939",
    "https://openalex.org/W2520689564",
    "https://openalex.org/W2900471836",
    "https://openalex.org/W1731358280",
    "https://openalex.org/W2132553681",
    "https://openalex.org/W3164313594",
    "https://openalex.org/W3005149564",
    "https://openalex.org/W2118388899",
    "https://openalex.org/W3182965314",
    "https://openalex.org/W3011574394",
    "https://openalex.org/W3111704875",
    "https://openalex.org/W3130015284",
    "https://openalex.org/W3129207397",
    "https://openalex.org/W3138823115",
    "https://openalex.org/W4239353262",
    "https://openalex.org/W4205316473",
    "https://openalex.org/W2612007440",
    "https://openalex.org/W2767784948",
    "https://openalex.org/W2955603559",
    "https://openalex.org/W2964573145",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3107997909",
    "https://openalex.org/W3116641301",
    "https://openalex.org/W2531638282",
    "https://openalex.org/W3176169354",
    "https://openalex.org/W2037789405",
    "https://openalex.org/W2576287494",
    "https://openalex.org/W3176972212",
    "https://openalex.org/W2606460416",
    "https://openalex.org/W4200516607",
    "https://openalex.org/W4246957792",
    "https://openalex.org/W3088409176"
  ],
  "abstract": "Background In recent years, social media has become a major channel for health-related information in Saudi Arabia. Prior health informatics studies have suggested that a large proportion of health-related posts on social media are inaccurate. Given the subject matter and the scale of dissemination of such information, it is important to be able to automatically discriminate between accurate and inaccurate health-related posts in Arabic. Objective The first aim of this study is to generate a data set of generic health-related tweets in Arabic, labeled as either accurate or inaccurate health information. The second aim is to leverage this data set to train a state-of-the-art deep learning model for detecting the accuracy of health-related tweets in Arabic. In particular, this study aims to train and compare the performance of multiple deep learning models that use pretrained word embeddings and transformer language models. Methods We used 900 health-related tweets from a previously published data set extracted between July 15, 2019, and August 31, 2019. Furthermore, we applied a pretrained model to extract an additional 900 health-related tweets from a second data set collected specifically for this study between March 1, 2019, and April 15, 2019. The 1800 tweets were labeled by 2 physicians as accurate, inaccurate, or unsure. The physicians agreed on 43.3% (779/1800) of tweets, which were thus labeled as accurate or inaccurate. A total of 9 variations of the pretrained transformer language models were then trained and validated on 79.9% (623/779 tweets) of the data set and tested on 20% (156/779 tweets) of the data set. For comparison, we also trained a bidirectional long short-term memory model with 7 different pretrained word embeddings as the input layer on the same data set. The models were compared in terms of their accuracy, precision, recall, F1 score, and macroaverage of the F1 score. Results We constructed a data set of labeled tweets, 38% (296/779) of which were labeled as inaccurate health information, and 62% (483/779) of which were labeled as accurate health information. We suggest that this was highly efficacious as we did not include any tweets in which the physician annotators were unsure or in disagreement. Among the investigated deep learning models, the Transformer-based Model for Arabic Language Understanding version 0.2 (AraBERTv0.2)-large model was the most accurate, with an F1 score of 87%, followed by AraBERT version 2–large and AraBERTv0.2-base. Conclusions Our results indicate that the pretrained language model AraBERTv0.2 is the best model for classifying tweets as carrying either inaccurate or accurate health information. Future studies should consider applying ensemble learning to combine the best models as it may produce better results.",
  "full_text": "Original Paper\nPretrained Transformer Language Models Versus Pretrained Word\nEmbeddings for the Detection of Accurate Health Information on\nArabic Social Media: Comparative Study\nYahya Albalawi1,2,3, MSc; Nikola S Nikolov1, PhD; Jim Buckley1,3, PhD\n1Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland\n2Department of Computer and Information Sciences, College of Arts and Science, University of Taibah, Al-Ula, Saudi Arabia\n3The Irish Software Research Centre, Lero, University of Limerick, Limerick, Ireland\nCorresponding Author:\nYahya Albalawi, MSc\nDepartment of Computer Science and Information Systems\nUniversity of Limerick\nTierney Building\nLimerick, V94 T9PX\nIreland\nPhone: 353 61213028 ext 3724\nEmail: yahalbalawi@gmail.com\nAbstract\nBackground: In recent years, social media has become a major channel for health-related information in Saudi Arabia. Prior\nhealth informatics studies have suggested that a large proportion of health-related posts on social media are inaccurate. Given\nthe subject matter and the scale of dissemination of such information, it is important to be able to automatically discriminate\nbetween accurate and inaccurate health-related posts in Arabic.\nObjective: The first aim of this study is to generate a data set of generic health-related tweets in Arabic, labeled as either accurate\nor inaccurate health information. The second aim is to leverage this data set to train a state-of-the-art deep learning model for\ndetecting the accuracy of health-related tweets in Arabic. In particular, this study aims to train and compare the performance of\nmultiple deep learning models that use pretrained word embeddings and transformer language models.\nMethods: We used 900 health-related tweets from a previously published data set extracted between July 15, 2019, and August\n31, 2019. Furthermore, we applied a pretrained model to extract an additional 900 health-related tweets from a second data set\ncollected specifically for this study between March 1, 2019, and April 15, 2019. The 1800 tweets were labeled by 2 physicians\nas accurate, inaccurate, or unsure. The physicians agreed on 43.3% (779/1800) of tweets, which were thus labeled as accurate\nor inaccurate. A total of 9 variations of the pretrained transformer language models were then trained and validated on 79.9%\n(623/779 tweets) of the data set and tested on 20% (156/779 tweets) of the data set. For comparison, we also trained a bidirectional\nlong short-term memory model with 7 different pretrained word embeddings as the input layer on the same data set. The models\nwere compared in terms of their accuracy, precision, recall, F1 score, and macroaverage of the F1 score.\nResults: We constructed a data set of labeled tweets, 38% (296/779) of which were labeled as inaccurate health information,\nand 62% (483/779) of which were labeled as accurate health information. We suggest that this was highly efficacious as we did\nnot include any tweets in which the physician annotators were unsure or in disagreement. Among the investigated deep learning\nmodels, the Transformer-based Model for Arabic Language Understanding version 0.2 (AraBERTv0.2)-large model was the\nmost accurate, with an F1 score of 87%, followed by AraBERT version 2–large and AraBERTv0.2-base.\nConclusions: Our results indicate that the pretrained language model AraBERTv0.2 is the best model for classifying tweets as\ncarrying either inaccurate or accurate health information. Future studies should consider applying ensemble learning to combine\nthe best models as it may produce better results.\n(JMIR Form Res 2022;6(6):e34834) doi: 10.2196/34834\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 1https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nKEYWORDS\nsocial media; machine learning; pretrained language models; bidirectional encoder representations from transformers; BERT;\ndeep learning; health information; infodemiology; tweets; language model; health informatics; misinformation\nIntroduction\nBackground\nIn the past 2 decades, there has been a dramatic increase in the\nnumber of people who use social media (SM) to participate in\ndiscussions on various topics, such as politics [1], health [2],\nand education [3]. Regarding health-related information, several\nrecent studies from Saudi Arabia found that Twitter is the\npreferred SM platform for communicating and accessing medical\ninformation. For example, it was preferred by orthopedic\nsurgeons to reply to (personal and professional) medical\nquestions [4], by dental practitioners for medical consultations\n[5], by patients with diabetes to search for health information\n[6], by female students at a university in Saudi Arabia to read\nabout systemic lupus erythematosus [7], and by adolescents to\nsearch for oral health information [2].\nA significant problem with this form of communication is that\nthere is no quality control over the medium, and most of the\nhealth information presented on Twitter seems inaccurate, as\nillustrated by the various studies summarized in Table 1. Indeed,\nmultiple data science studies have used data sets of\nhealth-related communication on SM to study this phenomenon,\nand some studies [8-10] went further to design frameworks for\ndetecting the accuracy of health information on SM.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 2https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nTable 1. Summary of studies that analyzed the accuracy of health information on social media.\nType of studyTopics cov-\nered\nPercentage of the\naccuracy\nLanguage\ncovered\nMethods to labelSourcesNumber of\ntweets or\ndocuments\nStudies\nExploratoryCOVID-1925.4% inaccurateEnglishExpert votes; relabeling in cases\nof disagreement\nTwitter358Swetland et al\n[11]\nQuantitative\npilot study\nGeneral31% inaccurateArabicTwo physicians; delete if there is\na disagreement\nTwitter109Albalawi et al\n[12]\nMLaCancer38% inaccurateArabicExpert votes; relabeling in cases\nof disagreement\nTwitter208Saeed et al [8]\nQuantitativeZika12% inaccurateEnglishTwo physicians; delete if there is\na disagreement\nFacebook183Sharma et al\n[13]\nQuantitative\nand explorato-\nry study\nOnly tweets\nfrom health\nprofessionals\n50% inaccurateArabicVote if the experts do not agreeTwitter625Alnemer et al\n[14]\nMLAutism11.4% misinforma-\ntion\nChineseAnnotator voting; in addition,\nconsulted an expert to validate in-\nformation labeled as misleading\nHealth fo-\nrum\n5000Zhao et al [10]\nQuantitativeEbola10% inaccurateEnglishCoders checked the interagreement\non 200 tweets\nTwitter2460Sell et al [15]\nExploratoryH1N14.5% inaccurateEnglishCoder checked agreement on 125\ntweets; unsubstantiated by the fol-\nlowing reference standards: the\nCDCb and Public Health Agency\nof Canada for scientific claims and\na panel of credible web-based\nnews sources (eg, CNNc and\nBBCd) for news-related claims\nTwitter5395Chew and Ey-\nsenbach [16]\nMLZikaUnknownEnglishAnnotator’s agreement; relabeling\nin cases of disagreement; here, the\ndefinition for misinformation was\n“news items without a source”\nTwitter800Sicilia et al [9]\nQuantitativeEbola25% of the ana-\nlyzed tweets were\nspeculative\nEnglishType of hashtagsTwitter47 millionKalyanam et\nal [17]\nMLCOVID-1970% uncredibleNot noted,\nbut the key-\nwords were\nin English\nAlthough they used coders, their\ndefinition of a rumor included lack\nof a source; hence, unconfirmed\ninformation was automatically\nclassified as uncredible; in addi-\ntion, tweets were classified by only\n1 coder who checked interagree-\nment on 20 tweets\nTwitter;\nkeywords\n409,484Al-Rakhami\nand Al-Amri\n[18]\nMLCOVID-1921%EnglishFact-checking websites and offi-\ncial websites\nVarious\nwebsites\n7486Elhadad et al\n[19]\nExploratoryZika23%EnglishCoders’ agreementInstagram500Seltzer et al\n[20]\nMLZika32%EnglishDefined keywords to the extracted\ntweets based on rumors identified\nfrom the WHOe website; then, the\ncoders labeled the tweets\nTwitter26,728Ghenai et al\n[21]\naML: machine learning.\nbCDC: Centers for Disease Control and Prevention.\ncCNN: Cable News Network.\ndBBC: British Broadcasting Corporation.\neWHO: World Health Organization.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 3https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nPrevious studies have focused on specific health issues and\nsometimes on specific types of rumors [8,18,19,21,22]. This\nsuggests the need for a more general framework that can detect\nthe accuracy of health information across known and previously\nunknown health conditions, such as during the outbreak of a\npreviously unknown infectious disease.\nGiven the prevalent use of Twitter for the spreading of health\ninformation in Saudi Arabia [2,4-7,23,24], we aimed to inform\nthe development of a new and more generic framework that is\nnot bound to a specific disease or rumor type and detect the\naccuracy of a broad base of health-related tweets in Arabic.\nRelated Work\nIn this section, we review the methods used to label\nhealth-related tweets as either accurate or inaccurate to create\nlabeled data sets. We also review previously proposed machine\nlearning (ML) models for detecting the accuracy of\nhealth-related tweets, including deep learning (DL).\nMethods Used to Label Health-Related Tweets\nStudies addressing the accuracy of health-related tweets can be\nclassified into 3 groups. The first group comprised studies that\nlabeled health-related tweets according to the information they\ncontained, regardless of the source of the information. The\nsecond group comprised studies that relied on external\n(fact-checking or very reputable) websites. The last group\ncomprised studies that relied on various characteristics of the\ntweets or only on the source of the information to judge the\naccuracy of the tweets.\nRegarding the concepts of accuracy and misinformation, Chou\net al [25] defined misinformation as information that lacks\nscientific evidence. A more precise definition can be found in\nthe study by Tan et al [26], where the authors defined inaccurate\ninformation or misinformation as “explicitly false,” according\nto what would be deemed incorrect by expert consensus. In the\nstudy by Nyhan and Reifler [27], the authors combined these\ndefinitions to describe misinformation or inaccurate health\ninformation as information that is not supported by clear\nevidence and expert opinion.\nStudies relying on the opinions of experts seemed to indirectly\nor directly use these definitions to assess accuracy; however, it\nshould be noted that, although misinformation is inaccurate, it\nis not necessarily intended to be so. In contrast, disinformation\nis information that is intentionally deceptive [28]. Examples of\nopinions of experts studies are included in Table 1 [8,10,11,14].\nThese involved labeling health-related tweets based on the\nopinions of health experts. The tweets were labeled as inaccurate\nor accurate by at least two experts. A third expert was typically\ninvolved when there was a disagreement between the original\n2 experts: this expert cast the deciding vote for controversial\ntweets.\nVraga and Bode [29] criticized the abovementioned definition\nof misinformation, raising the point that there are many issues\non which experts do not agree. However, they state that as long\nas there is more evidence supporting the information, the\nagreement rate between experts will increase. Taking a stricter\napproach, Albalawi et al [12] and Sharma et al [13] excluded\ntweets on which experts disagreed in an attempt to exclude\nuncertainty from their data sets. Table 1 summarizes these\nstudies.\nUnsurprisingly, studies that relied on expert opinion used\nrelatively small data sets (ranging from 109 to 625 tweets)\ncompared with studies that used other labeling methods (Table\n1). Even those that used nonexperts but used manual coding\n(performed by nonexpert annotators) tended to work on a small\nsample of the data set [9,20].\nThe second group comprised studies that relied on an external\nwebsite, such as a fact-checking website, to label the tweets.\nOne such example is the study by Elhaddad et al [19], which\nrelied on a fact-checking website to identify misleading\ninformation. A similar method was used by Ghenai et al [21],\nwho relied on the website of the World Health Organization\n(WHO) to identify 6 rumors. From these rumors, they derived\nkeywords to extract relevant tweets. The drawback of this\nmethod is that only tweets relevant to specific rumors were\nextracted; thus, the model was trained only on this limited\nnumber of rumors. Furthermore, these methods are highly\nlanguage restricted: both studies referred to in Table 1 were\nperformed in English, as mandated by the WHO website and\nthe fact-checking website.\nOther methods relied on various characteristics of the tweets or\nonly on the source of the information without judging the actual\ninformation. For example, in the study by Kalyanam et al [17],\nthe authors identified tweets as credible if they included hashtags\nthat indicated that they originated from noted agencies or other\nreliable sources, and tweets were identified as speculative if\nthey included hashtags that implied an increase in fear, rumors,\nor scams.\nSimilarly, Sicilia et al [9], Al-Rakhami and Al-Amri [18], and\nChew and Eysenbach [16] defined credible tweets as tweets\nthat have information from a confirmed, reliable source, such\nas the WHO, Centers for Disease Control, or another official\nhealth agency. This method differs from the method used by\nthe second group mentioned previously as it first identified a\ntweet and then examined its source. In contrast, the methods in\nthe second group first identified a trustworthy website and then\nused the information on the website to identify tweets of interest.\nMore generally, Yin et al [30] stated that a website is trustworthy\nif it provides correct information and suggests that information\nis likely to be true if it is provided by a trustworthy website.\nStudies that relied on trustworthy websites to identify rumors\n[9,18,21] seemed to follow this definition, even if they did not\nexplicitly state it.\nIt should be noted that based on the data in Table 1, all Arabic\nstudies that relied only on expert opinion [8,12,14] were small\nscale and qualitative; therefore, it would be impossible to scale\nthem up. Notably, the percentage of inaccurate tweets for\nEnglish studies that rely on expert opinions is in the range of\n10% to 25%, whereas the corresponding range for Arabic studies\nis 31% to 50%. This finding suggests a greater occurrence of\ninaccurate health-related tweets in Arabic than in English.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 4https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nML Approaches\nOf the 14 studies reported in Table 1, which analyzed the\naccuracy of health-related tweets in general, 6 (43%) proceeded\nto train an ML model to detect the accuracy of health\ninformation, as shown in Table 2.\nTable 2. Summary of studies that developed MLa models to detect the accuracy of health-related information.\nLabeling typeResultsML approachStudy\nGround truth data from websites99.99% (F1 score)Deep learning multimodel, GRUb,\nLSTMc, and CNNd\nElhadad et al [19]\nCrowdsource agreement but keywords are based on\n4 WHOe website-identified rumors\n94.5% (weighted average for\nF1 score)\nRandom forestGhenai et al [21]\nSingle annotator only after confirming source97.8% (accuracy)Ensemble learning and random for-\nest+SVMf\nAl-Rakhami and Al-\nAmri [18]\nAnnotator vote; in addition, consulted an expert to\nvalidate misleading information\n84.4% (F1 score)Random forestZhao et al [10]\nAgreement of a health expert69.9% (F1 score)Random forestSicilia et al [9]\nAgreement of a health expert83.5% (accuracy)Random forestSaeed et al [8]\naML: machine learning.\nbGRU: gated recurrent unit.\ncLSTM: long short-term memory.\ndCNN: convolutional neural network.\neWHO: World Health Organization.\nfSVM: support vector machine.\nStudies reporting on training ML models included Elhadad et\nal [19] and Al-Rakhami and Al-Amri [18], who used ensemble\nlearning on an English data set. Elhadad et al [19] used ensemble\nlearning that involved multiple DL architectures, and\nAl-Rakhami and Al-Amri [18] trained ensemble models\ncomprising traditional ML algorithms, such as support vector\nmachine (SVM) and random forest (RF). Another similarity\nbetween these studies is the method used to identify misleading\ninformation. Elhadad et al [19] built their data set by extracting\nground truth data and rumors from fact-checking websites.\nAl-Rakhami and Al-Amri [18] considered tweets credible if\nthey have a reliable source and misleading otherwise. Both\nmodels reported a high level of accuracy (>97%), as shown in\nTable 2.\nFrom Tables 1 and 2, it is clear that studies that relied on a\nfact-checking website [19,21] and studies that determined the\naccuracy of a tweet based on its source [18] obtained a high\nlevel of accuracy, possibly as these models were trained on\nrelatively large data sets.\nFor example, Al-Rakhami and Al-Amri [18] trained their model\nusing 409,484 tweets. However, automated labeling left open\nthe possibility of incorrect labeling, and all these studies were\nconducted in English.\nMost of the studies that developed ML models focused on\noutbreaks (4/6, 67% of studies). Studies that developed ML\nmodels for nonoutbreak conditions [8,10] obtained less accurate\nresults compared with outbreak conditions. This might be\nbecause these nonoutbreak condition models were trained on a\nlimited number of documents compared with the outbreak\nmodels. We also found that the level of accuracy obtained for\nnonoutbreak data sets was approximately 84% (Table 2). It is\nalso notable that all of these studies trained an RF model.\nTable 2 (and our associated literature review) suggests that\nrecent advancements in DL have not been sufficiently applied\nto the detection of misleading Arabic health information. In our\nprevious work, we have shown that DL architectures using word\nembedding as an input layer outperform other traditional ML\nmodels, such as SVM and naive Bayes, in the detection of\nArabic health-related information on SM [31]; however, in this\npaper, we move past that to the classification of Arabic\nhealth-related tweets based on their accuracy.\nWord embedding is a learned representation of words in natural\nlanguage processing (NLP) [32]. Words with similar meanings\ntypically have similar numbers in their vectors. The closer the\nwords are in meaning, the shorter the distance between the 2\nvectors representing them. One of the main criticisms of the\nword embedding approach is that it is considered context free;\nthat is, the embedding of a word is not affected by its position\nin the sentence [33]. Hence, it is also referred to as static word\nembedding. However, in practice, the meaning of a word may\ndepend on its position in a sentence.\nIn recent years, pretrained language models have been proven\nto work well for many NLP tasks, including entity recognition,\nlanguage translation, and text classification [34]. Unlike static\nword embedding techniques, such as Skip-Gram and Continuous\nBag of Words, language models can learn the context of the\nwords and thus assign different values for the words depending\non their context [33]. There are different types of language\nmodels, including contextual word vectors and embeddings\nfrom language models [33]. One of the most popular language\nmodels is the bidirectional encoder representations from\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 5https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\ntransformers (BERT), which has been proven to perform well\nin text classification tasks.\nThe superiority of transformer models compared with other text\nclassification methods is well documented, especially in the\nrecent literature. Multiple studies have compared transformer\nmodels with other DL models [35-39], and the results showed\nthat transformers outperformed the ML models, including\ndifferent DL architectures and traditional ML models, such as\nSVMs and RF. This indicates the potential capability of\ntransformers to better detect the accuracy of Arabic health\ninformation on SM.\nTherefore, in this study, we aimed to contribute to this field by\ndeveloping a data set of certified accurate or inaccurate Arabic\nhealth-related tweets and investigating the ability of the BERT\nor pretrained word embedding model to detect the accuracy of\nArabic health-related tweets across a wide range of\nhealth-related issues.\nMethods\nOverview\nThe empirical method comprised 2 parts. The first part addressed\nthe extraction of health-related tweets using the model proposed\nin our previous study [31]. In that study, we used a health\nlexicon that focused more on general health keywords rather\nthan specific outbreaks, as a recent study suggested that general\nhealth misinformation is more likely to spread than, for example,\nCOVID-19 [40]. In contrast, Table 1 illustrates that most studies\nin this area focused on a specific domain or disease outbreak.\nThe extracted health-related tweets were labeled by health\nexperts as either accurate or inaccurate. Figure 1 presents an\noverview of this portion of the study.\nFigure 1. Overview of the process followed in labeling tweets as either accurate or inaccurate [31]. ML: machine learning.\nIn the second part, we propose 2 types of\ntrustworthiness—detecting models to automatically classify\nhealth-related tweets as either accurate or inaccurate—and\nevaluate them: bidirectional long short-term memory (BLSTM)\nDL models and pretrained transformer language models.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 6https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nBuilding Data Sets of Trustworthy Health-Related\nTweets\nIn this study, we used 2 data sets containing health-related\ntweets. The first data set was the result of our previous study\n[31].\nThe first data set was extracted from 297,928 tweets posted\nbetween July 15 and August 31, 2019. Of these 297,928 tweets,\n5000 (1.68%) were randomly sampled and labeled by 2\nannotators as either health-related or not health-related. A third\nannotator resolved disagreements between the 2 annotators.\nThe first data set was extracted during the summer holidays in\nSaudi Arabia for 45 consecutive days. To assess generality, we\nextracted the second data set for a different timeframe: during\nHajj and Eid al Adha (Muslim holy days) and during school\ndays between March 1 and April 15, 2019. The second set of\n900 tweets used the ML methodology proposed in the same\nstudy [31], as the availability of health professionals was\nconstrained by the ongoing COVID-19 pandemic and the ML\nmodel derived in that study achieved a high-quality result (93%\naccuracy).\nThe methodology proposed in the study by Albalawi et al [31]\ncomprised extracting tweets from a set of collected tweets with\nthe help of a health lexicon and then further filtering out tweets\nnot related to health with the help of an ML model. On the basis\nof the health lexicon, 217,702 tweets were extracted. Of the\n217,702 tweets, we sampled 5000 (2.3%) tweets and applied\nthe ML model to extract 900 (0.41%) health-related tweets.\nFinally, we added 900 tweets from the second data set to 900\ntweets sampled from the first data set and had those 1800 tweets\nlabeled as either accurate or inaccurate health information by\n2 medical physicians.\nLabeling Accurate or Inaccurate Tweets\nThe physicians were asked to manually label each of the 1800\nhealth-related tweets into one of the following categories:\naccurate health information, inaccurate health information,\nand not sure about the accuracy.\nWe followed the protocol of relying on the opinions of experts\nto define the accuracy of the information collected. Taking into\naccount the points made by Vraga and Bode [29], every tweet\nwas assessed by 2 experts, and a tweet was included in the final\ndata set for this study only if both experts agreed on its accuracy;\nthat is, we reduced uncertainty by excluding information that\nwas not sanctioned by all experts (indeed, later show that\nbetween-physician reliability in this coding was limited,\nbuttressing the need for increased certainty when using human\nclassification, as stated by Vraga and Bode [32]). The not sure\noption was offered to the physicians to avoid forcing them to\nevaluate the tweets if they did not have enough relevant health\nknowledge to accurately evaluate them or if the tweets were\nambiguous.\nAlthough other studies invited a third annotator to resolve\ndisagreements, our approach was stricter in reducing uncertainty\nin the data set by excluding tweets for which there was a\ndisagreement between the 2 annotators. Of 1800 tweets, the 2\nphysicians agreed on 779 (43.3%) tweets, which were labeled\nas containing either accurate or inaccurate health information.\nThe physicians disagreed on 9.1% (163/1800) of tweets. The\nremaining 47.7% (858/1800) of tweets were labeled as unsure\nby at least one physician. We dropped the tweets on which at\nleast one of the physicians was unsure and used the remaining\n779 tweets in our experiments.\nAlthough the 779 tweets constituted a relatively small data set,\nmost of the data sets constructed in the literature based on\nagreements between health experts were relatively small. As\nshown in Table 1, the highest number of health-related tweets\njudged by health experts in other studies was 625 in the study\nby Alnemer et al [14].\nThese 779 tweets, labeled as either accurate or inaccurate, can\nbe found in Multimedia Appendix 1. Please note that we only\nshare tweet IDs and labels as the Twitter policy prevents the\ncontent of the tweets from being redistributed. These tweet IDs\ncan be used to obtain the text of tweets using the Twitter\napplication programming interface [41].\nConsidered DL Models\nOverview\nAfter completing the annotation of the health-related tweets as\neither accurate or inaccurate, we trained 16 classification\nmodels, 7 (44%) of which used a BLSTM architecture with\npretrained word embeddings as their input layers, and 9 (56%)\nof which used a pretrained transformer language model. Figure\n2 illustrates the steps implemented during this stage. Further\ndetails are provided in the following sections.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 7https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nFigure 2. Overview of the process used to train and select machine learning models. BLSTM: bidirectional long short-term memory.\nThe BLSTM Architecture\nFor 44% (7/16) of the trained models, we used a BLSTM\narchitecture with pretrained word embeddings as the input layer.\nLong short-term memory (LSTM) is a type of recurrent neural\nnetwork that takes advantage of dependencies between parts of\nthe input sequence and can learn these dependencies. LSTM\nalso preserves the information of past input. The BLSTM\nvariation differs from LSTM because of its ability to learn the\ndependencies between past and future elements [42]. BLSTM\nhas been found to perform well in many NLP tasks, including\ntext classification [43]. The BLSTM model begins with input\nand embedding layers to which a dropout layer is added,\nfollowed by a BLSTM layer with another added dropout layer\n[31]. BLSTM has been shown to perform better than traditional\nML models (SVM, naive Bayes, k-nearest neighbors, and\nlogistic regression) and conventional neural networks in a\nprevious study on detecting Arabic health-related tweets [31].\nFor the input layer, we used 7 pretrained word embedding\nmodels for Arabic [44-47]. It should be noted that AraVec,\nMazajak, and ArWordVec come in 2 variations: Continuous\nBag of Words and Skip-Gram and, finally, BLSTM fastText.\nTransformer Models\nBERT is a transformer language model that has shown\nsuperiority in many NLP tasks.\nDifferent Arabic pretrained language models exist, which are\nbased on transformers that have been developed recently by the\nArabic NLP community. Most of these pretrained language\nmodels were built on top of the BERT-base model. Some of\nthem also provided a version based on BERT-large.\nThe difference between BERT-base and BERT-large is that\nBERT-base uses 12 layers, 768 hidden layers, 12 heads, and\napproximately 136 million parameters, whereas the BERT-large\nmodel uses 24 layers, 1024 hidden layers, 16 heads, and\napproximately 370 million parameters [48]. All models may\nnot leverage BERT-large as it is more difficult to train and\ncomes with a higher computational cost than BERT-base [49].\nExamples of pretrained Arabic language representation models\nthat offer both base and large variants are ArabicBERT [50]\nand Transformer-based Model for Arabic Language\nUnderstanding (AraBERT) [51]. AraBERT was considered the\nfirst Arabic-specific transformer language model introduced in\n2020 by Antoun et al [51]. In 2021, an updated version of\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 8https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nAraBERT was released [52]. AraBERT is considered one of\nthe best transformer language models for NLP, outperforming\nother models for Arabic sentiment analysis [53]. AraBERT\nversion 2 (AraBERTv2) preprocesses text using Farasa\nsegmentation. Farasa segmentation involves breaking the words\nbased on the prefix and suffix [54], whereas AraBERT version\n0.2 (AraBERTv0.2) preprocesses the text without using Farasa\nsegmentation. In this study, we experimented with these 6\nmodels: AraBERTv2, AraBERTv0.2, and ArabicBERT in both\nvariants of BERT (base and large).\nIn addition to 6 models, we also investigated 3 other\nstate-of-the-art pretrained language models, namely QARiB\n[55], MARBERT, and ARBERT [56], which are based only on\nBERT-base. These models reportedly perform well on text\nclassification tasks [50,55-57]. Table 3 summarizes the\ncharacteristics of the pretrained language models used in this\nstudy.\nTable 3. Pretrained language models.\nCorpusSizeBasisName\n61 GB of MSAb text (6.5 billion tokens)BERTa-baseARBERT [56] • Books and news (news and Wikipedia articles)\n128 GB of text (15.6 billion tokens)BERT-baseMARBERT [56] • 1 billion Arabic tweets\n14 billion tokens; vocabulary: 64,000BERT-baseQARiB [55] • 420 million tweets and approximately 180 million sen-\ntences of text from Arabic Giga Word, Abulkhair Arabic\nCorpus, and OPUSc\n95 GB of text and 8.2 billion wordsBERT-base and\nBERT-large\nArabicBERT [50] • Arabic OSCARd version, Wikipedia, and other re-\nsources\n77 GB, 200,095,961 lines, 8,655,948,860\nwords, or 82,232,988,358 characters\nBERT-base and\nBERT-large\nAraBERTv0.2e [52] • OSCAR unshuffled and filtered\n• Arabic Wikipedia articles\n• The 1.5 billion words Arabic Corpus\n• The OSIANf corpus\n• Assafir news articles\n77 GB, 200,095,961 lines, 8,655,948,860\nwords, or 82,232,988,358 characters\nBERT-base and\nBERT-large\nAraBERTv2g [52] • OSCAR, unshuffled and filtered\n• Arabic Wikipedia articles\n• The 1.5 billion words Arabic corpus\n• The OSIAN corpus\n• Assafir news articles\naBERT: bidirectional encoder representations from transformers.\nbMSA: Modern Standard Arabic.\ncOPUS: open parallel corpus.\ndOSCAR: Open Superlarge Crawled Aggregated corpus.\neAraBERTv0.2: Transformer-based Model for Arabic Language Understanding version 0.2version 0.2.\nfOSIAN: Open Source International Arabic News.\ngAraBERTv2: Transformer-based Model for Arabic Language Understanding version 0.2 version 2.\nEvaluation Metrics\nThe F1 score, recall, precision, accuracy, and macroaverage of\nthe F1 score were used to evaluate the ML models, as detailed\nin Textbox 1. The macroaveraged F1 score is the averaged F1\nscore across all classes, which are accurate and inaccurate\nhealth-related tweets [58].\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 9https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nTextbox 1. Metrics used to evaluate the machine learning models.\nRecall\n• True positives / (true positives + false negatives)\nPrecision\n• True positives / (true positives + false positives)\nF1 score\n• (2 × precision × recall) / (precision + recall)\nAccuracy\n• (true positives + true negatives) / total sample\nMacroaveraged F1 score\n•\n (1), where N is the number of classes\nPreprocessing Data\nIn this study, text was preprocessed following the procedure\noutlined by the authors of the corresponding pretrained word\nembedding models. Li et al [59] found that this is the best text\npreprocessing practice when working with pretrained word\nembeddings. Similarly, for all pretrained word embedding\nmodels [44-47] and pretrained language models [50,52,55,56],\nwe followed the steps provided by the original studies.\nOf the 779 tweets, we split the data set into training, validation,\nand test data sets in ratios of 507 tweets (65.1%) for training,\n116 tweets (14.9%) for validating the model, and 156 tweets\n(20%) for testing.\nEthics Approval\nThis study did not require institutional review board approval\nfrom the Science and Engineering Research committee at the\nUniversity of Limerick because ethical approval is not required\nfor publicly available data. It should be emphasized, during the\nstudy, that any associated text that can be used to identify the\nauthors of the tweets has been removed from the text (eg,\n@name, user ID).\nResults\nData Set Description\nThe κ coefficient for all categories was 0.377, which is in fair\nagreement according to Cohen [60]. However, the benchmark\nscale proposed by Fleiss et al [61] to evaluate the agreement\nindicates that such a coefficient is poor (<0.40=poor,\n0.40-0.75=intermediate to good, and >0.75=excellent). Given\nthe low κ coefficients across the 3 categories, we considered\nonly cases where both physicians were explicitly in agreement,\nas they were on 779 tweets from the original data sets.\nOf the 1021 tweets that were excluded, 874 (48.6%) were\nlabeled not sure by at least one physician, and in the case of\n147 (14.4%) tweets, the physicians disagreed regarding the\naccuracy of the tweets.\nOf the 779 tweets physicians agreed on in our data set, 296\n(38%) were labeled as inaccurate and 483 (62%) were labeled\nas accurate. This finding is similar to the inaccuracies reported\nin other studies (Table 1).\nTextbox 2 presents examples of accurate and inaccurate\nhealth-related tweets. As can be seen from the tweets in the\ntextbox, they cover a wide range of topics, including but not\nlimited to psychology and cancer. Interestingly, in the third\naccurate tweet example, the difficulty for nonexperts in\ndiscerning accurate from inaccurate health information is\nillustrated, as advice against taking antidiarrhea drugs in the\nevent of food poisoning is slightly counterintuitive.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 10https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nTextbox 2. Examples of inaccurate and accurate health-related tweets.\nAccurate\n• “Tomorrow enjoys the feast. and get closer to God with your sacrifice\nAnd eat but do not extravagant and feed the contented and be merciful as God has commanded you\nEating too much red meat might:\nRaise the level of triglycerides\nRaise cholesterol\nIncrease uric salt in the blood Increases gout attacks in the joints”\n• “Symptoms of social phobia\nSometimes, social phobia can be accompanied by physical signs and symptoms, which may include:\nFlashness\nRapid heart palpitations\nShivering and sweating\nUpset stomach or nausea\nDifficulty catching breath\nDizziness or lightheadedness\nFeeling like your mind has gone blank\nMuscle tension”\n• “In the event of food poisoning, please take care not to use antidiarrheal medicines, as they may worsen the condition”\n• “Hemoglobin is a group of proteins in red blood cells whose function is to transport oxygen from the lungs to the body, return carbon dioxide\nfrom the body, and transport it to the lungs and get rid of it through breathing.\nIron is an important element and enters the composition of hemoglobin, so if iron deficiency, hemoglobin decreases, and anemia occurs.”\n• “Among the ways to prevent lung cancer:\nStay away from smoking\nAvoid passive smoking\nAvoid carcinogenic and radioactive materials.”\nInaccurate\n• “Scientific research,\nThe research says that Zamzam water bears the name (water), but it differs radically from water compounds, as all the waters of the world belong\nto the acidic compound, except for (Zamzam water).\nIt is (alkaline!) Glory be to God. There is no other alkaline water on the face of the earth. So, when you drink it in abundance, the human body\nhas a strong immunity against viruses!!”\n• “When Western scholars searched for the causes of mental illness, they found only two reasons (fear and sadness) fear of the future and sadness\nof the past, both of which are the opposite of happiness.”\n• “Did you know that a 5-minute tantrum is so stressful that it weakens the immune system for more than 6 hours”\n• “Cupping helps smokers to quit smoking or reduce the negative impact on the body through:\nRemoving excess hemoglobin from the body by excreting aging red blood cells, and thus the disappearance of the pathological symptoms of\nhigh hemoglobin caused by smoking”\n• “Just a spoonful of cinnamon daily:\nRich in anti-inflammatory and antioxidants\nPrevents all types of cancer\nPrevents heart disease\nAnti-diabetes”\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 11https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nSome tweets claimed the benefits of some traditional foods and\nspices. For example, some tweets promoted Zamzam (holy water\nfor Muslims), claiming there was scientific research that stated\nthat it could strengthen the human immune system; experts\nclassified the information as inaccurate.\nIn addition, the examples of accurate tweets presented here\nsuggest that accurate health-related tweets tend to be more\npreventive in nature, a finding supported by the wider sampling\nof accurate tweets. As shown in Textbox 2, the accurate tweets\nadvised users to stop eating too much red meat as it causes gout\nor increases cholesterol, stop smoking to prevent lung cancer,\nand stop taking anti-inflammatory drugs in the event of food\npoisoning. In contrast, as noted earlier, inaccurate tweets\npromoted natural and alternative medicine such as curbing eating\nand drinking Zamzam water for their health benefits. An\ninteresting example was in relation to cancer, where accurate\ntweets advised readers to stop smoking; however, some of the\ninaccurate tweets were also preventive, and they advised taking\na spoonful of cinnamon to prevent all types of cancer.\nDL Models\nIn terms of the comparison of models, we observed that overall,\nBERT models performed better than BLSTM models based on\nthe accuracy and the F1 score for both classes (when referring\nto the metric accuracy in this section, we will call it model\naccuracy to disambiguate it from the accurate or inaccurate\nclassification). Overall, AraBERTv0.2-large performed better\nthan all other models. Specifically, the best model was\nAraBERTv0.2-large (macro F1 score 87%), followed by\nAraBERTv2-large (macro F1 score 86%) and\nAraBERTv0.2-base (macro F1 score 85%), as shown in Table\n4. These findings hide larger but still small variations in the\nprecision and recall scores of individual techniques for\ninaccurate and accurate tweets. For example, although\nAraBERTv0.2-base achieved a recall of 78% for inaccurate\ntweets, AraBERTv0.2-large achieved a recall of >83%.\nThe results also suggest that, in general, BERT-large models\ntended to be better at detecting inaccurate tweets than the\nBERT-base models. The large AraBERTv2, AraBERTv0.2,\nand ArabicBERT models performed better than their base\nversions at detecting inaccurate health tweets, as shown in Table\n4. In contrast, the BERT-base models might be better at\ndetecting accurate tweets, except for the AraBERTv2, whose\nlarge and base versions performed similarly.\nOf the pretrained word embeddings, the results in Table 4 show\nthat Mazajak Skip-Gram is the best based on model accuracy\nand F1 score.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 12https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nTable 4. Comparison of the performance of machine learning models for detecting the accuracy of health-related tweets.\nModel accuracyMacroaverageF1 scoreRecallPrecisionModel and class\nAraBERTv2a-base\n0.83970.82790.78260.76270.804Inaccurate\n0.83970.82790.87310.88660.86Accurate\nAraBERTv2-large\n0.8654b0.8564b0.8205b0.8136b0.8276Inaccurate\n0.8654b0.8564b0.89230.89690.8878Accurate\nAraBERTv0.2c-base\n0.8654b0.8543b0.81420.77970.8519Inaccurate\n0.8654b0.8543b0.89450.91750.8725Accurate\nAraBERTv0.2-large\n0.8782d0.8701d0.8376d0.8305d0.8448Inaccurate\n0.8782d0.8701d0.9025d0.90720.898dAccurate\nMARBERT\n0.82690.81540.76920.76270.7759Inaccurate\n0.82690.81540.86150.8660.8571Accurate\nARBERT\n0.85260.84470.80990.8305d0.7903Inaccurate\n0.85260.84470.87960.8660.8936Accurate\nQARiB\n0.83330.82280.77970.77970.7797Inaccurate\n0.83330.82280.8660.8660.866Accurate\nArabicBERTe-large\n0.8654b0.85320.81080.76270.8654Inaccurate\n0.8654b0.85320.8955b0.9278b0.8654Accurate\nArabicBERT-base\n0.85250.834920.7810.69490.8913dInaccurate\n0.85250.834920.88890.9485d0.8364Accurate\nBLSTMf Mazajak CBOWg\n0.82050.80790.75860.74580.7719Inaccurate\n0.82050.80790.85710.8660.8485Accurate\nBLSTM Mazajak Skip-Gram\n0.83970.82220.76640.69490.8542Inaccurate\n0.83970.82220.87800.9278b0.8333Accurate\nBLSTM ArWordVec Skip-Gram\n0.81410.79190.72380.64410.8261Inaccurate\n0.81410.79190.81480.91750.8091Accurate\nBLSTM ArWordVec CBOW\n0.82050.8050.750.71190.7925Inaccurate\n0.82050.8050.860.88660.835Accurate\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 13https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nModel accuracyMacroaverageF1 scoreRecallPrecisionModel and class\nBLSTM AraVec CBOW\n0.78210.77370.73020.77970.6865Inaccurate\n0.78210.77370.81720.8660.8571Accurate\nBLSTM AraVec Skip-Gram\n0.82050.81360.77770.8305d0.7313Inaccurate\n0.82050.81360.84940.81440.8144Accurate\nBLSTM fastText\n0.77560.73820.63920.52540.8158Inaccurate\n0.77560.73820.83720.9278b0.7627Accurate\naAraBERTv2: Transformer-based Model for Arabic Language Understanding version 2.\nbRepresents the second-best value.\ncAraBERTv0.2: Transformer-based Model for Arabic Language Understanding version 0.2.\ndIndicates the best value.\neBERT: bidirectional encoder representations from transformers.\nfBLSTM: bidirectional long short-term memory.\ngCBOW: Continuous Bag of Words.\nDiscussion\nPrincipal Findings\nAs noted earlier, the examples given in the Results section\nshowed that accurate tweets were more focused on preventive\nmedicine, whereas inaccurate tweets were more focused on\nalternative and natural medicine. However, it could be argued\nthat this is because of the keywords used in extracting and\nfiltering the tweets or because of the selected tweet examples.\nNevertheless, a previous study mentioned that the prevalence\nof natural alternatives and alternative medicine compared with\nmedicine provided by the health care system [62] may be\nharmful. To illustrate the importance of this with respect to\nspecific patients, there was a reported case of a patient with\ncancer who took alternative medicine promoted on SM, which\ncaused the hospital to temporarily stop her cancer treatment to\nrepair the damage caused by that medicine [63]. At a more\ngeneral level, going forward, insights such as these could\nprovide additional levers with which to detect inaccurate health\ntweets.\nThe results of BLSTM with pretrained word embedding models\n(AraVec, Skip-Gram, and Mazajak) are comparable with the\nresults of some BERT models, including MARBERT, QARiB,\nand ArabicBERT-large. Indeed, this has been previously\nreported in the literature, where MARBERT and QARiB\noutperformed some of the other transformer models, such as\nArabicBERT and AraBERT [55,56]. Again, a takeaway from\nthis is that pretrained word embeddings might outperform\npretrained BERT models in this first comparative study directed\nat Arabic. There is no guaranteed best model between pretrained\nword embeddings and pretrained transformer models for this\nlanguage.\nHowever, in general, the results showed the superiority of the\nBERT models over BLSTM with pretrained word embedding\nmodels. Overall, 19 best or second-best results were obtained\nby the 9 BERT-based approaches, whereas only 3 best or\nsecond-best results were obtained by the 7 pretrained word\nembedding models.\nMost models performed better at detecting accurate health tweets\nthan inaccurate tweets. The detection rate (recall) for accurate\ntweets ranged from 0.9485 to 0.8144. This means that most of\nthe models missed only approximately 5% to 19% of the\naccurate tweets, which is a promising result. In contrast, the\ndetection rate for inaccurate tweets was lower and had a wider\nrange, from 0.8305 to 0.5254, implying that the best models\nmissed up to 17% of inaccurate tweets. This is concerning as\nwe would like to successfully identify all inaccurate tweets, and\neven the best model missed 17% of them.\nThe flip side of this is precision: how many accurate or\ninaccurate tweets identified by the technique are actually\naccurate or inaccurate. In terms of inaccurate tweets, the\napproaches ranged from 0.7759 to 0.89130—quite a large span,\nwhich means that if the wrong technique is chosen,\napproximately one-quarter of the tweets identified as inaccurate\nis incorrectly classified. Probably, more of a concern is the\nnumber of tweets identified as accurate that are not. Similarly,\nhere, the span ranged from 0.8913 to 0.7627, again implying\nthat if the wrong technique is chosen, this could be problematic.\nSome models that had high detection rates for accurate health\ntweets could have low detection rates for inaccurate tweets. For\nexample, the ArabicBERT-base and BLSTM fastText models\nwere the best and second best for accurately detecting tweets,\nwith success rates of 0.9485 and 0.9278, respectively. However,\nin detecting inaccurate tweets, BLSTM fastText had the lowest\ndetection rate (52%) and the ArabicBERT-Base model had the\nsecond-lowest detection rate (69%). In other words, a\npractitioner who uses the best model for identifying accurate\nhealth tweets might miss approximately 30% to 48% of\ninaccurate tweets.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 14https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nSimilarly, the ARBERT and AraVec Skip-Gram models\nperformed similarly to the AraBERTv0.2-large model in terms\nof precision when detecting inaccurate health-related tweets;\nhowever, these 2 models did not perform as well on the other\nmetrics. For example, the AraVec Skip-Gram model had the\nsecond-lowest rate of model accuracy in classifying accurate\ntweets as inaccurate. Although the ARBERT model performed\nwell compared with the BLSTM models, with regard to\nclassifying accurate tweets as inaccurate, it had the third-lowest\nrate of model accuracy among the 9 BERT models tested in\nthis study. In other words, the ARBERT models incorrectly\nclassified accurate tweets as inaccurate at a higher rate than the\n6 other BERT models, as shown in Table 4.\nIdeally, a technique would provide high precision in both\nidentification and recall; however, this did occur in the data set\nfor accurate or inaccurate tweets. AraBERTv0.2-large came\nclosest in this regard with high-accuracy tweet precision and\nrecall, best recall for inaccurate tweets, and suboptimal precision\nfor inaccurate tweets. Similarly, AraBERTv2-large performed\nquite well across accurate tweets but did not perform quite well\non inaccurate tweets.\nHowever, these models (AraBERTv0.2-large and\nAraBERTv2-large) consume relatively more resources, being\nbased on BERT-large. Among the base models,\nAraBERTv0.2-base has an F1 score of 0.8543, which is good,\nand also has a similar model accuracy to AraBERTv2-large.\nThese models can be considered as an alternative if resources\nare an important consideration.\nRegarding the performance of pretrained word embeddings, we\nfound that Mazajak Skip-Gram was the best. We made the same\nobservation in our previous work on the detection of\nhealth-related tweets [31].\nFinally, with respect to the accuracy of the best model in our\nstudy (ie, AraBERTv0.2-large), our results are satisfactory when\ncompared with the results of previous studies [8-10] that make\nuse of expert opinion. The F1 score of our best model was 87%,\nwhereas the best F1 score reported in the study by Zhao et al\n[10] was 84%, as shown in Table 2. Furthermore, although these\nprevious studies targeted a specific health topic (such as cancer\n[8] or autism [10]), we used a data set of tweets on a wide range\nof health care topics, suggesting that it would be more difficult\nto classify our data set.\nIt should be noted that all 3 studies with model accuracy or F1\nscores >90% did not rely on expert opinion (Tables 1 and 2).\nIn addition, 2 of these 3 studies [18,19] targeted a specific\noutbreak condition (COVID-19), and their models were trained\non a larger data set (eg, Al-Rakhami and Al-Amri [18] trained\ntheir model on 409,484 tweets). For the third study [21], the\nkeywords used to extract initial tweets were derived from 6\npreidentified rumors related to Zika. The size and nature of the\ndata used to train these models might explain why they seemed\nto achieve better accuracy than the model proposed here. In this\nstudy, we trained a model to detect the accuracy of generic\nhealth-related information, making the approach applicable to\ntweets that are more or less categorical in their labeling (as\nillustrated in the samples in Textbox 2).\nLimitations\nThis study only considered tweets agreed upon by experts.\nAlthough this helps us reduce the uncertainty in our data set, it\nmight be a limitation as the model is not trained or tested on\ntweets that are more marginal—tweets about which the experts\nare unsure.\nOne of the strengths of this model is that it was trained on\ngeneral health-related tweets. The accuracy of the model for\neach health condition or topic may vary, and future studies\nshould evaluate the model for specific health topics.\nAll models used here are language dependent and might not be\ndirectly applicable to other languages. However, there are BERT\nalternatives for many languages, and there is evidence that\nBERT outperforms word embedding-based models. Therefore,\nwe believe that this model could perform similarly in other\nlanguages.\nRegarding the metrics used to evaluate the models, it should be\nnoted that the F1 measure has been subjected to some criticism.\nAlthough we showed the F1 score for both classes (accurate and\ninaccurate health tweets), it should be noted that the measure\ngives equal importance to both classes (accurate and inaccurate\nhealth tweets). Moreover, the F1 score generally does not\nconsider true negatives in its equation [64,65].\nConclusions\nThe goal of this study was to develop and evaluate a\nstate-of-the-art ML model for detecting the medical\ntrustworthiness of health-related tweets in Arabic. To achieve\nthis, we first constructed a labeled data set to train the classifiers.\nWe then compared 2 different DL approaches for training a\nclassification model, namely, 6 pretrained word embedding\nmodels as an input model for BLSTM and 11 pretrained\ntransformer language models. The percentage of inaccurate\nhealth tweets in the data is approximately 38% (296/799), which\nis comparable with previous studies that used data sets with a\nnumber of inaccurate health-related tweets in the range of 30%\nto 50%. Our AraBERTv0.2-large model achieved 87.7% model\naccuracy on the test data set, which is satisfactory. Overall, our\nresults clearly indicate that the AraBERTv0.2-large model\noutperforms the other models in detecting the medical accuracy\nof health-related tweets.\nThis study established an ML model to identify the accuracy\nof health-related tweets in response to the proliferation of health\nmisinformation on SM. Although misinformation detection has\nbeen researched, only 1 study was concerned with detecting the\naccuracy of Arabic health-related tweets, and it was only for a\nspecific topic (cancer). Furthermore, no DL model has been\nevaluated in prior studies to detect the accuracy of Arabic\nhealth-related tweets. In this study, we used a more extensive\ndata set to develop a more general model using state-of-the-art\nML models that have not been implemented before for this type\nof problem.\nThe potential of such work cannot be overstated. If a robust\nmodel can be built, it will allow for the detection and\ndissemination of accurate tweets. Similarly, this would allow\nfor the flagging of inaccurate tweets. Both measures would\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 15https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\nsignificantly improve health information dissemination on\nTwitter. However, it should be noted that although this work\nwill improve the situation, it will still inaccurately classify 13%\nof the tweets.\nMoreover, the examples in Textbox 2 imply disparities between\naccurate and inaccurate information in terms of the topics\ncovered across the data set—a trend supported by the informal\nsampling of that data set. Accurate tweets seem to be more\npreventive, whereas inaccurate health tweets seem to promote\nnatural and alternative medicine. Thus, it might be more feasible\nto develop a model for detecting health topics in combination\nwith a model for detecting the accuracy of health information\nand thus improving accuracy.\nTo further improve the accuracy of the developed model,\nensemble learning can yield better results by combining models\nthat perform well (ArabicBERT-large, ARBERT, and AraVec\nSkip-Gram). However, ArabicBERT and AraBERTv0.2 were\ntrained on a similar corpus, as shown in Table 3. Another\napproach could be to combine models pretrained on different\ncorpora, such as ArabicBERT-large and MARABER\n(ArabicBERT pretrained on Wikipedia articles and news articles;\nMARBERT pretrained on 1 billion tweets).\nAcknowledgments\nThe authors would like to thank all physicians who participated in the process of evaluating the health tweets in this study. This\nwork was supported, in part, by Taibah University, Al-Ula, Saudi Arabia, and by a grant from the Science Foundation Ireland\n(grant 13/RC/2094).\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nTweet IDs with their labels used in the study.\n[XLSX File (Microsoft Excel File), 26 KB-Multimedia Appendix 1]\nReferences\n1. Ott BL. The age of Twitter: Donald J. Trump and the politics of debasement. Critical Stud Media Commun 2016 Dec\n23;34(1):59-68. [doi: 10.1080/15295036.2016.1266686]\n2. El Tantawi M, Bakhurji E, Al-Ansari A, AlSubaie A, Al Subaie HA, AlAli A. Indicators of adolescents' preference to\nreceive oral health information using social media. Acta Odontol Scand 2019 Apr;77(3):213-218. [doi:\n10.1080/00016357.2018.1536803] [Medline: 30632864]\n3. Tang Y, Hew KF. Using Twitter for education: beneficial or simply a waste of time? Comput Educ 2017 Mar;106:97-118.\n[doi: 10.1016/j.compedu.2016.12.004]\n4. Justinia T, Alyami A, Al-Qahtani S, Bashanfar M, El-Khatib M, Yahya A, et al. Social media and the orthopaedic surgeon:\na mixed methods study. Acta Inform Med 2019 Mar;27(1):23-28 [FREE Full text] [doi: 10.5455/aim.2019.27.23-28]\n[Medline: 31213739]\n5. Hamasha AA, Alghofaili N, Obaid A, Alhamdan M, Alotaibi A, Aleissa M, et al. Social media utilization among dental\npractitioner in Riyadh, Saudi Arabia. Open Dentistry J 2019 Feb 28;13(1):101-106. [doi: 10.2174/1874210601913010101]\n6. Jamal A, Khan SA, AlHumud A, Al-Duhyyim A, Alrashed M, Bin Shabr F, et al. Association of online health\ninformation-seeking behavior and self-care activities among type 2 diabetic patients in Saudi Arabia. J Med Internet Res\n2015 Aug 12;17(8):e196 [FREE Full text] [doi: 10.2196/jmir.4312] [Medline: 26268425]\n7. Omair MA, AlOhaly RY, Alashgar LM. Awareness and misconceptions of female students in King Saud University on\nsystemic lupus erythematosus. Rheumatology (Sunnyvale) 2015;05(03):165. [doi: 10.4172/2161-1149.1000165]\n8. Saeed F, Yafooz W, Al-Sarem M, Hezzam E. Detecting health-related rumors on Twitter using machine learning methods.\nInt J Advanced Comput Sci Application 2020;11(8). [doi: 10.14569/ijacsa.2020.0110842]\n9. Sicilia R, Giudice S, Pei Y, Pechenizkiy M, Soda P. Health-related rumour detection on Twitter. In: Proceedings of the\n2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2017 Presented at: 2017 IEEE International\nConference on Bioinformatics and Biomedicine (BIBM); Nov 13-16, 2017; Kansas City, MO, USA. [doi:\n10.1109/bibm.2017.8217899]\n10. Zhao Y, Da J, Yan J. Detecting health misinformation in online health communities: incorporating behavioral features into\nmachine learning based approaches. Inf Process Manag 2021 Jan;58(1):102390. [doi: 10.1016/j.ipm.2020.102390]\n11. Swetland SB, Rothrock AN, Andris H, Davis B, Nguyen L, Davis P, et al. Accuracy of health-related information regarding\nCOVID-19 on Twitter during a global pandemic. World Med Health Policy 2021 Jul 29;13(3):503-517 [FREE Full text]\n[doi: 10.1002/wmh3.468] [Medline: 34540337]\n12. Albalawi Y, Nikolov NS, Buckley J. Trustworthy health-related tweets on social media in Saudi Arabia: tweet metadata\nanalysis. J Med Internet Res 2019 Oct 08;21(10):e14731 [FREE Full text] [doi: 10.2196/14731] [Medline: 31596242]\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 16https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\n13. Sharma M, Yadav K, Yadav N, Ferdinand KC. Zika virus pandemic-analysis of Facebook as a social media health information\nplatform. Am J Infect Control 2017 Mar 01;45(3):301-302. [doi: 10.1016/j.ajic.2016.08.022] [Medline: 27776823]\n14. Alnemer KA, Alhuzaim WM, Alnemer AA, Alharbi BB, Bawazir AS, Barayyan OR, et al. Are health-related tweets\nevidence based? Review and analysis of health-related tweets on twitter. J Med Internet Res 2015 Oct 29;17(10):e246\n[FREE Full text] [doi: 10.2196/jmir.4898] [Medline: 26515535]\n15. Sell TK, Hosangadi D, Trotochaud M. Misinformation and the US Ebola communication crisis: analyzing the veracity and\ncontent of social media messages related to a fear-inducing infectious disease outbreak. BMC Public Health 2020 May\n07;20(1):550 [FREE Full text] [doi: 10.1186/s12889-020-08697-3] [Medline: 32375715]\n16. Chew C, Eysenbach G. Pandemics in the age of Twitter: content analysis of Tweets during the 2009 H1N1 outbreak. PLoS\nOne 2010 Nov 29;5(11):e14118 [FREE Full text] [doi: 10.1371/journal.pone.0014118] [Medline: 21124761]\n17. Kalyanam J, Velupillai S, Doan S, Conway M, Lanckriet G. Facts and fabrications about Ebola: a Twitter based study. In:\nProceedings of the KDD ’15. 2015 Presented at: KDD ’15; Aug 10 – 13, 2015; Sydney, Australia.\n18. Al-Rakhami MS, Al-Amri AM. Lies kill, facts save: detecting COVID-19 misinformation in Twitter. IEEE Access\n2020;8:155961-155970. [doi: 10.1109/access.2020.3019600]\n19. Elhadad M, Li K, Gebali F. An ensemble deep learning technique to detect COVID-19 misleading information. In: Advances\nin Networked-Based Information Systems. Cham: Springer; 2021.\n20. Seltzer E, Horst-Martz E, Lu M, Merchant R. Public sentiment and discourse about Zika virus on Instagram. Public Health\n2017 Sep;150:170-175. [doi: 10.1016/j.puhe.2017.07.015] [Medline: 28806618]\n21. Ghenai A, Mejova Y. Catching zika fever: application of crowdsourcing and machine learning for tracking health\nmisinformation on Twitter. In: Proceedings of the 2017 IEEE International Conference on Healthcare Informatics (ICHI).\n2017 Presented at: 2017 IEEE International Conference on Healthcare Informatics (ICHI); Aug 23-26, 2017; Park City,\nUT, USA. [doi: 10.1109/ichi.2017.58]\n22. Wang Y, McKee M, Torbica A, Stuckler D. Systematic literature review on the spread of health-related misinformation\non social media. Soc Sci Med 2019 Nov;240:112552 [FREE Full text] [doi: 10.1016/j.socscimed.2019.112552] [Medline:\n31561111]\n23. Alhaddad MS. The use of social media among Saudi residents for medicines related information. Saudi Pharm J 2018\nDec;26(8):1106-1111 [FREE Full text] [doi: 10.1016/j.jsps.2018.05.021] [Medline: 30510470]\n24. Alsobayel H. Use of social media for professional development by health care professionals: a cross-sectional web-based\nsurvey. JMIR Med Educ 2016 Sep 12;2(2):e15 [FREE Full text] [doi: 10.2196/mededu.6232] [Medline: 27731855]\n25. Chou WS, Oh A, Klein WM. Addressing health-related misinformation on social media. JAMA 2018 Dec\n18;320(23):2417-2418. [doi: 10.1001/jama.2018.16865] [Medline: 30428002]\n26. Tan AS, Lee C, Chae J. Exposure to health (mis)information: lagged effects on young adults' health behaviors and potential\npathways. J Commun 2015 Jul 06;65(4):674-698. [doi: 10.1111/jcom.12163]\n27. Nyhan B, Reifler J. When corrections fail: the persistence of political misperceptions. Polit Behav 2010 Mar 30;32(2):303-330.\n[doi: 10.1007/s11109-010-9112-2]\n28. Pool J, Fatehi F, Akhlaghpour S. Infodemic, misinformation and disinformation in pandemics: scientific landscape and the\nroad ahead for public health informatics research. Stud Health Technol Inform 2021 May 27;281:764-768. [doi:\n10.3233/SHTI210278] [Medline: 34042681]\n29. Vraga EK, Bode L. Defining misinformation and understanding its bounded nature: using expertise and evidence for\ndescribing misinformation. Political Commun 2020 Feb 06;37(1):136-144. [doi: 10.1080/10584609.2020.1716500]\n30. Yin X, Han J, Yu P. Truth discovery with multiple conflicting information providers on the web. IEEE Trans Knowl Data\nEng 2008 Jun;20(6):796-808. [doi: 10.1109/tkde.2007.190745]\n31. Albalawi Y, Buckley J, Nikolov NS. Investigating the impact of pre-processing techniques and pre-trained word embeddings\nin detecting Arabic health information on social media. J Big Data 2021 Jul 02;8(1):95 [FREE Full text] [doi:\n10.1186/s40537-021-00488-w] [Medline: 34249602]\n32. Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. In: Proceedings of\nWorkshop at ICLR. 2013 Presented at: Workshop at ICLR; May 2-4, 2013; Scottsdale, Arizona, USA URL: https://ui.\nadsabs.harvard.edu/abs/2013arXiv1301.3781M\n33. Qiu X, Sun T, Xu Y, Shao Y, Dai N, Huang X. Pre-trained models for natural language processing: a survey. Sci China\nTechnol Sci 2020 Sep 15;63(10):1872-1897. [doi: 10.1007/s11431-020-1647-3]\n34. Azzouza N, Akli-Astouati K, Ibrahim R. TwitterBERT: framework for Twitter sentiment analysis based on pre-trained\nlanguage model representations. In: Emerging Trends in Intelligent Computing and Informatics. Cham: Springer; 2020.\n35. Abu Farha I, Magdy W. A comparative study of effective approaches for Arabic sentiment analysis. Inf Process Manag\n2021 Mar;58(2):102438. [doi: 10.1016/j.ipm.2020.102438]\n36. Al-Twairesh N. The evolution of language models applied to emotion analysis of Arabic Tweets. Information 2021 Feb\n17;12(2):84. [doi: 10.3390/info12020084]\n37. El-Alami F, Ouatik El Alaoui S, En Nahnahi N. Contextual semantic embeddings based on fine-tuned AraBERT model\nfor Arabic text multi-class categorization. J King Saud University Comput Inf Sci 2021 Feb (forthcoming). [doi:\n10.1016/j.jksuci.2021.02.005]\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 17https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\n38. El-Razzaz M, Fakhr MW, Maghraby FA. Arabic gloss WSD using BERT. Applied Sci 2021 Mar 13;11(6):2567. [doi:\n10.3390/app11062567]\n39. Gomez-Perez J, Denaux R, Garcia-Silva A. Understanding word embeddings and language models. In: A Practical Guide\nto Hybrid Natural Language Processing. Cham: Springer; 2020.\n40. Broniatowski DA, Kerchner D, Farooq F, Huang X, Jamison AM, Dredze M, et al. Twitter and Facebook posts about\nCOVID-19 are less likely to spread misinformation compared to other health topics. PLoS One 2022 Jan 12;17(1):e0261768\n[FREE Full text] [doi: 10.1371/journal.pone.0261768] [Medline: 35020727]\n41. Developer agreement and policy. Developer Platform. URL: https://developer.twitter.com/en/developer-terms/\nagreement-and-policy [accessed 2021-03-06]\n42. Xu K, Xie L, Yao K. Investigating LSTM for punctuation prediction. In: Proceedings of the 2016 10th International\nSymposium on Chinese Spoken Language Processing (ISCSLP). 2016 Presented at: 2016 10th International Symposium\non Chinese Spoken Language Processing (ISCSLP); Oct 17-20, 2016; Tianjin, China. [doi: 10.1109/iscslp.2016.7918492]\n43. Gulli A, Kapoor A, Pal S. Deep Learning with TensorFlow 2 and Keras Regression, ConvNets, GANs, RNNs, NLP, and\nMore with TensorFlow 2 and the Keras API, 2nd Edition. Birmingham, United Kingdom: Packt Publishing; 2019.\n44. Soliman AB, Eissa K, El-Beltagy SR. AraVec: a set of Arabic word embedding models for use in Arabic NLP. Procedia\nComput Sci 2017;117:256-265. [doi: 10.1016/j.procs.2017.10.117]\n45. Grave E, Bojanowski P, Gupta P, Joulin A, Mikolov T. Learning word vectors for 157 languages. In: Proceedings of the\nEleventh International Conference on Language Resources and Evaluation (LREC 2018). 2018 Presented at: Eleventh\nInternational Conference on Language Resources and Evaluation (LREC 2018); May 7-12, 2018; Miyazaki, Japan.\n46. Fouad MM, Mahany A, Aljohani N, Abbasi RA, Hassan S. ArWordVec: efficient word embedding models for Arabic\ntweets. Soft Comput 2019 Jun 26;24(11):8061-8068. [doi: 10.1007/s00500-019-04153-6]\n47. Farha I, Magdy W. Mazajak: an online Arabic sentiment analyser. In: Proceedings of the Fourth Arabic Natural Language\nProcessing Workshop. 2019 Presented at: Fourth Arabic Natural Language Processing Workshop; Jul 28-Aug 2, 2019;\nFlorence, Italy. [doi: 10.18653/v1/w19-4621]\n48. Devlin J, Chang M, Lee K, Toutanova K. BERT: pre-training of deep bidirectional transformers for language understanding.\nIn: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and Short Papers). 2019 Presented at: 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long\nand Short Papers); Jun 2-7, 2019; Minneapolis, Minnesota. [doi: 10.18653/v1/N19-1423]\n49. Shi S, Tang Z, Chu X, Liu C, Wang W, Li B. A quantitative survey of communication optimizations in distributed deep\nlearning. IEEE Network 2021 May;35(3):230-237. [doi: 10.1109/mnet.011.2000530]\n50. Safaya A, Abdullatif M, Yuret D. KUISAIL at SemEval-2020 Task 12: BERT-CNN for Offensive Speech Identification\nin Social Media. In: Proceedings of the Fourteenth Workshop on Semantic Evaluation. 2020 Presented at: Proceedings of\nthe Fourteenth Workshop on Semantic Evaluation; Dec 12-13, 2020; Online. [doi: 10.18653/v1/2020.semeval-1.271]\n51. Antoun W, Baly F, Hajj H. AraBERT: transformer-based model for Arabic language understanding. In: Proceedings of the\n4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection.\n2020 Presented at: Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared\nTask on Offensive Language Detection; May, 2020; Marseille, France.\n52. Hugging Face. URL: https://huggingface.co/aubmindlab/bert-large-arabertv2 [accessed 2021-06-15]\n53. Faraj D, Faraj D, Abdullah M. SarcasmDet at sarcasm detection task 2021 in Arabic using AraBERT pretrained model. In:\nProceedings of the Sixth Arabic Natural Language Processing Workshop. 2021 Presented at: Proceedings of the Sixth\nArabic Natural Language Processing Workshop; Apr 19, 2021; Kyiv, Ukraine (Virtual).\n54. Darwish K, Mubarak H. Farasa: a new fast and accurate Arabic word segmenter. In: Proceedings of the Tenth International\nConference on Language Resources and Evaluation (LREC'16). 2016 Presented at: Proceedings of the Tenth International\nConference on Language Resources and Evaluation (LREC'16); May 2016; Portorož, Slovenia.\n55. Abdelali A, Hassan S, Mubarak H, Darwish K, Samih Y. Pre-training BERT on Arabic tweets: practical considerations.\narXiv 2021.\n56. Abdul-Mageed M, Elmadany A, Nagoudi E. Proceedings of the 59th Annual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2011\nPresented at: The 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint\nConference on Natural Language Processing; Aug, 2021; Online. [doi: 10.18653/v1/2021.acl-long.551]\n57. Abu FI, Magdy W. Benchmarking transformer-based language models for Arabic sentiment and sarcasm detection. In:\nProceedings of the Sixth Arabic Natural Language Processing Workshop. 2021 Presented at: Proceedings of the Sixth\nArabic Natural Language Processing Workshop; Apr, 2021; Kyiv, Ukraine (Virtual).\n58. Zhenyan L, Dan M, Weiping W, Chunxia Z. A supervised parameter estimation method of LDA. In: Proceedings of the\nAsia-Pacific Web Conference. 2015 Presented at: Asia-Pacific Web Conference; 2015; Guangzhou, China. [doi:\nhttps://doi.org/10.1007/978-3-319-25255-1_33]\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 18https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX\n59. Li H, Caragea D, Li X, Caragea C. Comparison of word embeddings and sentence encodings as generalized representations\nfor crisis Tweet classification tasks. In: Proceedings of the ISCRAM Asian Pacific 2018 Conference. 2018 Presented at:\nISCRAM Asian Pacific 2018 Conference; Nov, 2018; Wellington, New Zealand.\n60. Cohen J. Weighted kappa: nominal scale agreement with provision for scaled disagreement or partial credit. Psychol Bull\n1968 Oct;70(4):213-220. [doi: 10.1037/h0026256] [Medline: 19673146]\n61. The measurement of interrater agreement. In: Statistical Methods for Rates and Proportions. Hoboken, New Jersey, United\nStates: Wiley; 2003.\n62. Nastasi A, Bryant T, Canner JK, Dredze M, Camp MS, Nagarajan N. Breast cancer screening and social media: a content\nanalysis of evidence use and guideline opinions on twitter. J Cancer Educ 2018 Jun;33(3):695-702. [doi:\n10.1007/s13187-017-1168-9] [Medline: 28097527]\n63. Yamaguchi T, Shimizu J, Oya Y, Horio Y, Hida T. Drug-induced liver injury in a patient with nonsmall cell lung cancer\nafter the self-administration of fenbendazole based on social media information. Case Rep Oncol 2021 Jun 17;14(2):886-891\n[FREE Full text] [doi: 10.1159/000516276] [Medline: 34248555]\n64. Powers D. J Mach Learn Technol 2011;2(1):37-63 [FREE Full text]\n65. Hand D, Christen P. A note on using the F-measure for evaluating record linkage algorithms. Stat Comput 2017 Apr\n19;28(3):539-547. [doi: 10.1007/s11222-017-9746-6]\nAbbreviations\nAraBERT: Transformer-based Model for Arabic Language Understanding\nAraBERTv0.2: Transformer-based Model for Arabic Language Understanding version 0.2\nAraBERTv2: Transformer-based Model for Arabic Language Understanding version 2\nBERT: bidirectional encoder representations from transformers\nBLSTM: bidirectional long short-term memory\nDL: deep learning\nLSTM: long short-term memory\nML: machine learning\nNLP: natural language processing\nRF: random forest\nSM: social media\nSVM: support vector machine\nWHO: World Health Organization\nEdited by A Mavragani; submitted 09.11.21; peer-reviewed by S Wei, A Rovetta, X Zhou; comments to author 08.02.22; revised version\nreceived 04.04.22; accepted 21.04.22; published 29.06.22\nPlease cite as:\nAlbalawi Y, Nikolov NS, Buckley J\nPretrained Transformer Language Models Versus Pretrained Word Embeddings for the Detection of Accurate Health Information\non Arabic Social Media: Comparative Study\nJMIR Form Res 2022;6(6):e34834\nURL: https://formative.jmir.org/2022/6/e34834\ndoi: 10.2196/34834\nPMID:\n©Yahya Albalawi, Nikola S Nikolov, Jim Buckley. Originally published in JMIR Formative Research (https://formative.jmir.org),\n29.06.2022. This is an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work, first published in JMIR Formative Research, is properly cited. The complete bibliographic information,\na link to the original publication on https://formative.jmir.org, as well as this copyright and license information must be included.\nJMIR Form Res 2022 | vol. 6 | iss. 6 | e34834 | p. 19https://formative.jmir.org/2022/6/e34834\n(page number not for citation purposes)\nAlbalawi et alJMIR FORMATIVE RESEARCH\nXSL•FO\nRenderX",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6836628913879395
    },
    {
      "name": "Social media",
      "score": 0.6793644428253174
    },
    {
      "name": "Natural language processing",
      "score": 0.6434177160263062
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.6434065103530884
    },
    {
      "name": "Language model",
      "score": 0.5983926057815552
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5932859778404236
    },
    {
      "name": "Transformer",
      "score": 0.5556002855300903
    },
    {
      "name": "Arabic",
      "score": 0.5092036128044128
    },
    {
      "name": "Health informatics",
      "score": 0.4398612976074219
    },
    {
      "name": "Machine learning",
      "score": 0.375559538602829
    },
    {
      "name": "Information retrieval",
      "score": 0.3472919166088104
    },
    {
      "name": "World Wide Web",
      "score": 0.16175982356071472
    },
    {
      "name": "Linguistics",
      "score": 0.13558802008628845
    },
    {
      "name": "Medicine",
      "score": 0.11875486373901367
    },
    {
      "name": "Public health",
      "score": 0.09779122471809387
    },
    {
      "name": "Nursing",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I230495080",
      "name": "University of Limerick",
      "country": "IE"
    },
    {
      "id": "https://openalex.org/I23075662",
      "name": "Taibah University",
      "country": "SA"
    }
  ]
}