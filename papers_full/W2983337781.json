{
  "title": "Two-Stage Short-Term Load Forecasting for Power Transformers Under Different Substation Operating Conditions",
  "url": "https://openalex.org/W2983337781",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2102382644",
      "name": "Hang Liu",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A2125436611",
      "name": "Youyuan Wang",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A1994148300",
      "name": "Chao Wei",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2123138064",
      "name": "Jiansheng Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2229802815",
      "name": "Yuandi Lin",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2102382644",
      "name": "Hang Liu",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A2125436611",
      "name": "Youyuan Wang",
      "affiliations": [
        "Chongqing University"
      ]
    },
    {
      "id": "https://openalex.org/A1994148300",
      "name": "Chao Wei",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2123138064",
      "name": "Jiansheng Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A2229802815",
      "name": "Yuandi Lin",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2100483895",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W2343586331",
    "https://openalex.org/W2754252319",
    "https://openalex.org/W2597866042",
    "https://openalex.org/W2913651970",
    "https://openalex.org/W3103064492",
    "https://openalex.org/W1993863450",
    "https://openalex.org/W2553165053",
    "https://openalex.org/W2013570992",
    "https://openalex.org/W2019949418",
    "https://openalex.org/W2151767444",
    "https://openalex.org/W2103504194",
    "https://openalex.org/W2111072639",
    "https://openalex.org/W1988725814",
    "https://openalex.org/W2313169588",
    "https://openalex.org/W6728510257",
    "https://openalex.org/W2893532431",
    "https://openalex.org/W2527136714",
    "https://openalex.org/W2064650039",
    "https://openalex.org/W2782547758",
    "https://openalex.org/W2075846637",
    "https://openalex.org/W1832982222",
    "https://openalex.org/W2269227734",
    "https://openalex.org/W2343259376",
    "https://openalex.org/W2472174378",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W6630010926",
    "https://openalex.org/W6674330103",
    "https://openalex.org/W2136848157",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W1501225717",
    "https://openalex.org/W2537436678"
  ],
  "abstract": "The load of transformers shows higher volatility and uncertainty than do the system-level and substation-level loads. This paper proposes a two-stage short-term load forecasting (STLF) model for power transformers. 1) Three state-of-the-art technologies are applied to predict the aggregated substation-level load by taking the historical load, weather, and calendar data as inputs. In this stage, no specific STLF model needs to be developed, which allows the forecasters to select the most accurate prediction results for transformer-level load forecasting. 2) The load distribution factor (LDF) is defined as the ratio of the transformer load to the substation load. The relationship between LDF and substation load is captured by nonlinear regression functions under different substation operating conditions, and the load of each parallel transformer is predicted using these nonlinear regression functions. Each nonlinear function can be accurately established even if the historical load data are scarce under some irregular operating conditions. Three application examples show the effectiveness and rationality of the proposed method. The third example demonstrates that STLF of transformers is necessary because it provides important information for optimizing substation operating schemes and equipment maintenance plans.",
  "full_text": "Received September 12, 2019, accepted October 28, 2019, date of publication November 4, 2019,\ndate of current version November 15, 2019.\nDigital Object Identifier 10.1 109/ACCESS.2019.2951422\nTwo-Stage Short-Term Load Forecasting for\nPower Transformers Under Different\nSubstation Operating Conditions\nHANG LIU\n1, YOUYUAN WANG1, CHAO WEI2, JIANSHENG LI2, AND YUANDI LIN2\n1State Key Laboratory of Power Transmission Equipment and System Security and New Technology, Chongqing University, Chongqing 400044, China\n2Jiangsu Electric Power Company Research Institute, Nanjing 211103, China\nCorresponding author: Hang Liu (liuhangsheep@163.com)\nThis work was supported in part by the National Natural Science Foundation of China under Grant 51637004, and in part by the China\nState Grid Corporation of Science and Technology Project under Grant 5210EF18000Z.\nABSTRACT The load of transformers shows higher volatility and uncertainty than do the system-level and\nsubstation-level loads. This paper proposes a two-stage short-term load forecasting (STLF) model for power\ntransformers. 1) Three state-of-the-art technologies are applied to predict the aggregated substation-level load\nby taking the historical load, weather, and calendar data as inputs. In this stage, no speciﬁc STLF model needs\nto be developed, which allows the forecasters to select the most accurate prediction results for transformer-\nlevel load forecasting. 2) The load distribution factor (LDF) is deﬁned as the ratio of the transformer\nload to the substation load. The relationship between LDF and substation load is captured by nonlinear\nregression functions under different substation operating conditions, and the load of each parallel transformer\nis predicted using these nonlinear regression functions. Each nonlinear function can be accurately established\neven if the historical load data are scarce under some irregular operating conditions. Three application\nexamples show the effectiveness and rationality of the proposed method. The third example demonstrates\nthat STLF of transformers is necessary because it provides important information for optimizing substation\noperating schemes and equipment maintenance plans.\nINDEX TERMS Load distribution factor, nonlinear regression function, short-term load forecasting,\nsubstation operating condition, transformer.\nI. INTRODUCTION\nShort-term load forecasting (STLF) commonly consists of\nhourly prediction of the load from one day to one week ahead.\nIt is a recognized fact that the load of transformers is a key fac-\ntor in the aging of an insulation system. When a transformer is\noverloaded beyond its nameplate ratings, there are high risks\nthat can originate failures and reduce the remaining useful life\nof the transformer [1], [2]. Any failure or unplanned outage\nmay reduce the reliability of the power system and cause\nconsiderable economic loss due to the importance and cost of\npower transformers. Therefore, high-quality load forecasting\nis of great signiﬁcance for optimization of substation operat-\ning schemes and equipment maintenance plans.\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Marta Cimitile\n.\nDuring the last few decades, dozens of techniques have\nbeen developed for STLF at the system level. The con-\nventional models include autoregressive integrated moving\naverage [3]–[5] and regression analysis [6]–[8]. With the\ndevelopment of big data technologies and artiﬁcial intelli-\ngence, artiﬁcial neural networks (ANNs) have been widely\napplied because of their strong ability to approximate nonlin-\near functions by learning historical data. ANN-based mod-\nels learn the relationship between the current load and the\nprevious load, weather, and calendar variables. According to\nthe prediction process, these STLF models can be roughly\ngrouped into two categories: (1) stepwise extrapolation fore-\ncasting models and (2) aggregation of the similar historical\ndaily load segments.\nTypically, a stepwise extrapolation forecasting model takes\nmultiple previous daily load segments and weather and calen-\ndar variables as inputs. The output is the daily load segment\n161424 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nof the current day. To predict the load segment of the next\nday, the predicted load segment of the current day should be\nconsidered as the input data. The stepwise extrapolation is\nimplemented iteratively until all of the daily load segments\nin the next few days are predicted. In practical applications,\nthe stepwise extrapolation forecasting model can be estab-\nlished using different ANNs. For instance, the extreme learn-\ning machine (ELM) is applied to realize STLF by inputting\nprevious daily load segments, temperature, and day type [9].\nA wavelet neural network is employed to predict the load\nby inputting similar historical daily load segments, forecast\nweather indices, and week indices [10]. Recently, deep learn-\ning technologies have become popular in load forecasting,\nsuch as long short-term memory (LSTM) recurrent neural\nnetworks (RNNs), which take multiple previous daily load\nsegments, day indices, and week indices as inputs [11], [12].\nOther deep learning models used for STLF include gated\nrecurrent neural networks [13] and deep belief networks [14].\nWhen implementing load forecasting, the ANN-based mod-\nels only need to be trained once, and then multiple future daily\nload segments can be sequentially predicted. However, two\nshortcomings should be mentioned. (1) The prediction error\nmay accumulate with the increase of extrapolation times.\n(2) When training the ANN-based models, the historical data\nused for model training should be sufﬁcient and consecu-\ntive. This requirement is difﬁcult to meet because missing\nvalues inevitably exist in original datasets due to various\nfactors during the data acquisition process [15]. Insufﬁcient\ndata or incomplete data will greatly reduce the performance\nof ANN-based models.\nAggregation of similar historical daily load segments con-\nsists of two steps. The similar historical daily load seg-\nments are ﬁrst selected, and then the selected segments are\naggregated. For instance, distance metrics are widely applied\nfor similarity calculation, and the load is commonly pre-\ndicted using a weighted average or an arithmetic average\nof the selected segments [16]–[19]. For other technologies,\nan STLF framework based on big data technologies is pre-\nsented in [20]. The classiﬁcation rules between daily load\npatterns and critical inﬂuential factors are established by a\ndecision tree. These rules are applied to select the similar\nload segments, which are aggregated using support vector\nmachine. In [21], an artiﬁcial immune system is employed\nfor STLF. K-means clustering and least squares support\nvector machine are applied for similar load segment selec-\ntion and aggregation in [22]. In contrast to the stepwise\nextrapolation forecasting model, the aggregation of simi-\nlar load segments has no training process in many cases,\nwhich can be utilized when historical load data are insuf-\nﬁcient or nonconsecutive. However, this method becomes\ncomplicated and time-consuming in large datasets because\nload selection and aggregation should be implemented for\neach segment to be predicted. In summary, it is recom-\nmended to apply the stepwise extrapolation forecasting model\nin large datasets with high data quality. When the histori-\ncal data are insufﬁcient or nonconsecutive, the aggregation\nof similar historical load segments should be considered\npreferentially.\nIn practice, the transformer-level load shows higher\nvolatility and uncertainty than the substation-level load.\nSTLF for transformers is much more difﬁcult due to the\ninﬂuence of substation operating conditions. For example,\nsingle-component failure events hardly cause the load curtail-\nment of the substation because a single-contingency criterion\n(the N-1 principle) is satisﬁed [23]. However, the load\nbetween different parallel transformers will be reconﬁgured,\nand the unexpected increase in the load of the transformers\nmay cause overloading and accelerated aging [1], [2]. Unfor-\ntunately, most system-level STLF models are unsuitable for\nload forecasting of transformers because they fail to con-\nsider the inﬂuence of substation operating conditions. The\nhousehold load forecasting models in [11], [12], [19] are also\nnot practical because the irregular load data are too scarce\nto establish an ANN-based model under various irregular\nconditions.\nTo solve these difﬁculties, a hierarchical load forecasting\nstructure is proposed. The aggregated load at the substation\nlevel is ﬁrst forecast and selected using existing state-of-\nthe-art technologies. Then, the relationship between the load\ndistribution factor (LDF) and substation load is captured\nby different nonlinear regression functions under different\nsubstation operating conditions. Finally, the load of parallel\ntransformers is predicted using these functions. In summary,\nour contributions are as follows:\n(1) The load of each parallel transformer in a substation is\npredicted by a two-stage procedure, which is more efﬁcient\nand rational in practical applications than designing a special\nSTLF model for each transformer.\n(2) The nonlinear regression functions can be established\nbased on scarce irregular load data. The load can be predicted\ninstantly without any time delay or transition process once the\nsubstation operating condition changes.\n(3) Three application examples demonstrate that STLF\nof transformers can provide important information for opti-\nmizing substation operating schemes and equipment mainte-\nnance plans.\nThe rest of the paper is organized as follows. Section II\nintroduces three state-of-the-art STLF technologies and\npresents the detail prediction process for substation load.\nBased on different nonlinear regression functions, the trans-\nformer load forecasting method is proposed in Section III.\nThree application examples are presented in Section IV , and\nconclusions are drawn in Section V .\nII. LOAD FORECASTING AT THE SUBSTATION LEVEL\nThe load data are measured every half hour by smart meters\nand stored in the energy management system (EMS). To pre-\ndict the daily load, one must predict the load at 48 time points.\nIt is necessary to think of the daily load recorded at these\ntime points as a segment. Prediction is performed for the\nentire segment rather than for each one of these time points\nseparately [18], [19].\nVOLUME 7, 2019 161425\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nTABLE 1. Weather and calendar variables.\nA. BASIC INFORMATION AND DATA PREPROCESSING\nLoad is a typical time series X =(X(t); t ∈R), which is\nobserved over an interval [0, T ]. One would like to predict\nthe load of the entire interval [T +1, T +d ×P], where\nd is the number of load segments to be predicted. P, which is\nequal to 48, is the number of time points in each load segment.\nThe load over the interval [0, T ] can be divided into different\ndaily load segments, as shown in (1):\nS =[S1,S2,..., SL ] , (1)\nwhere L (L =T /P) is the number of load segments of the\ninterval [0, T ]. The nth segment Sn is denoted by (2):\nSn =[X (P ·(n −1)+1),...,\nX (P ·(n −1)+i),..., X (P ·n)], (2)\nwhere n =1, 2, ..., L. and i =1, ..., P.\nThe daily load of the substation is mainly affected by\nweather and calendar variables. Four types of weather vari-\nables, provided by the local meteorology department, and\ntwo types of calendar variables are shown in Table 1. These\nexternal variables are collected at a certain time frequency\nof one day, which is more limited than the load frequency.\nAccording to Table 1, the variable vector of the nth day is\nVn =[Vn(1), ..., Vn(j), ..., Vn(6)], where j =1, 2, ..., 6.\nIt is necessary to standardize each type of variable because\nANN-based models are sensitive to data scale. For discrete\ncalendar variables, one hot encoder is implemented. For\nnumerical weather variables and historical load data, the\nz-score method is applied. The normalization of the\njth numerical variable is shown in (3):\nV (std)\nn (j)=Vn (j)−Mean [Vn (j)]\nStd [Vn (j)] , (3)\nwhere V (std)\nn (j) is the nth normalized observation of the\njth variable. Mean[V n(j)] and Std[V n(j)] are the mean and\nstandard deviation values of the jth variable, respectively.\nB. THE STEPWISE EXTRAPOLATION FORECASTING\nMODEL BASED ON AN LSTM NETWORK\n1) LSTM NETWORK\nLSTM networks have been widely applied in time series\nforecasting. The network consists of ﬁve layers and is shown\nin Fig. 1(a). Each layer is introduced as follows.\nFIGURE 1. Structure of an LSTM network. (a) Five layers. (b) LSTM block.\n(1) The input layer is used to accept the input data, and the\nnumber of neurons corresponds to the dimensions of the input\ndata.\n(2) An LSTM layer is used to construct an LSTM block\nwith HLSTM hidden neurons, as shown in Fig. 1(b) [24], [25].\nThe formulations of all nodes in an LSTM block are given\nby (4) to (9). In practice, a deep-RNN model can be estab-\nlished by stacking multiple LSTM layers:\ni (t)=σ\n(\nWi ·[h (t −1),x (t)]T +bi\n)\n, (4)\nf (t)=σ\n(\nWf ·[h (t −1),x (t)]T +bf\n)\n, (5)\no (t)=σ\n(\nWo ·[h (t −1),x (t)]T +bo\n)\n, (6)\ng (t)=tanh\n(\nWg[h (t −1),x (t)]T +bg\n)\n, (7)\nc (t)=f (t)⊙c (t −1)+i (t)⊙g (t), (8)\nh (t)=o (t)⊙tanh (c (t)), (9)\nwhere i(t) is the input gate, f (t) is the forget gate, o(t) is the\noutput gate, and g(t) is the cell candidate. Wi, Wf , Wo, and\nWg are input weight matrices for the corresponding gates.\nbi, bf , bo, and bg are the biases for the corresponding\ngates. σ and tanh represent the sigmoid activation function\nand the hyperbolic tangent activation function, respectively.\n(3) The dropout layer is used to prevent the network from\noverﬁtting [26]. During network training, the dropout layer\nrandomly sets input elements from the LSTM layer to zero\nbased on the dropout probability Pdrop, and then the remain-\ning elements are scaled by 1/(1-P drop). The default value\nof Pdrop is 0.5.\n(4) Fully connected layer: The neurons in the fully con-\nnected layer are connected to all neurons of the previous layer.\nFor regression, the output size is equal to the dimensions of\nthe output data.\n(5) The output layer is used to output the prediction\nresults.\n161426 VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nFIGURE 2. Load forecasting framework based on the LSTM network.\nFIGURE 3. Structure of ELM.\n2) LOAD FORECASTING BASED ON THE LSTM NETWORK\nThe STLF framework based on the LSTM network is\nshown in Fig. 2, and the detailed procedure is described\nin Algorithm 1. The weather data in [ VL+1, ..., VL+d ] for\nthe next d days are predicted by the meteorology department,\nand the calendar variables are easily obtained by consulting\nthe calendar.\nC. THE STEPWISE EXTRAPOLATION FORECASTING\nMODEL BASED ON ELM\n1) ELM THEORY\nELM is a single-hidden-layer feedforward network, which\nconsists of an input, hidden, and output layer, as shown\nin Fig. 3 [9], [27]. For N samples (x j, tj), j = 1, ..., N,\nthe output function with HELM hidden nodes and activation\nfunction g(x) is as follows:\nHELM∑\ni=1\nβig\n(\nwi ·xj +bi\n)\n=tj, (10)\nwhere wi, bi, and βi are the input weight vector, threshold,\nand output weight vector of the ith hidden node, respectively.\nThe above N equations can be written compactly as follows:\nHβ=T (11)\nUnlike the traditional iterative back-propagation (BP)\nlearning algorithm, wi and bi are randomly assigned to cal-\nculate the hidden-layer output matrix H. Then, the output\nweight matrix βis estimated by (12):\n¯β=H†T, (12)\nwhere ¯β is the estimated β. H†, which can be calculated\nby singular value decomposition method, is the Moore–\nPenrose generalized inverse of matrix H. ELM has better\nAlgorithm 1Load Forecasting Based on the LSTM Network\nInput:\nS =[S1, ..., Sn, ..., SL ]: The historical daily load\nsegments.\nV =[V1, ..., Vn, ..., VL , VL+1, ..., VL+d ]: The daily\nvariable dataset.\nK: Time step.\nmodelLSTM_h(t): The LSTM network with the hidden\nstate of h(t).\nd: The number of load segments to be predicted.\nOutput:\nS =[SL+1, ..., SL+d ]: The daily load segments in the\nnext d days.\nModel Training\nStart:\n1: Generate the training dataset.\n2: For m =1: L −K\n3: The mth input sample:\nInputm =[Sm, ..., Sm+K−1, Vm+K ].\n// Straighten into a vector\n4: The mth output sample:\nOutputm =Sm+K\n5: End\n6: Train modelLSTM by using data from the Input and\nOutput sets.\n7: The trained modelLSTM_h(0).\nTraining End.\nLoad Forecasting\nStart\n1: LSTM network initialization:\nInput data from the Input set into\nmodelLSTM_h(0) to obtain modelLSTM_h(L).\n2: The Lth input sample: PinputL\n=[SL−K+1, ..., SL , VL ].\n3: For t =L+1 to L +d\n4: Input Pinputt−1 into modelLSTM_h(t −1) to\npredict St .\n5: Update the hidden state to h(t).\n6: UpdatePinput t−1 to Pinputt :\nPop out the oldest load segment St−K and\nthen push in St .\nReplace Vt−1 by Vt .\n7: End\n8: S =[SL+1, ..., St , ..., SL+d ].\nForecasting End.\nTerminate\ngeneralization performance, and the learning speed is\nextremely fast [27]. Therefore, it is applied for substation-\nlevel load forecasting in this paper.\n2) LOAD FORECASTING BASED ON ELM\nThe ELM-based stepwise extrapolation forecasting proce-\ndure is similar to Algorithm 1. However, the steps of network\nVOLUME 7, 2019 161427\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\ninitialization and hidden state updating should be omitted\nbecause ELM has no hidden state h(t).\nD. LOAD FORECASTING BY AGGREGATING THE SIMILAR\nHISTORICAL LOAD SEGMENTS\nThe kNN algorithm is applied to aggregate the simi-\nlar historical daily load segments based on the methods\nin [16], [17]. The detailed forecasting procedure is shown\nin Algorithm 2. The similar historical load segments are\nselected by comparing the Euclidian distances between their\ndaily variable vectors. For example, the distance between Vt\nand Vn is calculated by (13):\nD (Vt ,Vn)=\n√\n6∑\nj=1\n(\nV (std)\nt (j)−V (std)\nn (j)\n)2\n, (13)\nwhere t =L +1, ..., L +d. n =1, ..., L.\nThe k similar historical load segments with minimum\nEuclidian distance results are selected. The load forecasting\nof the tth day is performed using an average of k selected\nsegments, as shown in (14):\nSt =1\nk\nk∑\ni=1\nS(i,t), (14)\nwhere S(i,t) is the ith similar load segment of the tth day.\nIII. LOAD FORECASTING OF TRANSFORMERS BASED ON\nNONLINEAR REGRESSION FUNCTIONS\nA. EFFECT OF SUBSTATION OPERATING CONDITIONS ON\nTHE LOAD OF PARALLEL TRANSFORMERS\nA substation commonly consists of more than one parallel\ntransformer. An example is shown in Fig. 4, the substation\nconsists of N parallel transformers (named T1-TN , respec-\ntively, where N ≥2). All of the transformers are in service\nunder the normal operating condition.\nThe normal condition will change to an irregular condition\ndue to maintenance or unplanned outage of the equipment.\nFor instance, single-component failure events commonly\noccur in the substation and cause an unexpected increase\nin load for the rest of the transformers. Fig. 5 shows an\nexample of a 500-kV substation (named Station 1), which con-\nsists of four parallel transformers (525/230±2×2.5%/36 kV ,\n750 MV A) named T1 −T4, respectively. After 7:30 on a\ncertain day, T3 was out of service, and the load of the rest\nof the transformers increased obviously.\nAlthough the substation satisﬁes the single-contingency\ncriterion and the transformers have overload capability,\nthe unexpected rise in load will cause higher operating tem-\nperature and accelerating aging of the transformers. There-\nfore, load forecasting of transformers under different irregular\noperating conditions is of great importance because it pro-\nvides important information for optimizing substation oper-\nating schemes and equipment maintenance plans, especially\nin the two following scenarios.\nAlgorithm 2 Load Forecasting by Aggregating k Similar\nHistorical Load Segments\nInput:\nS =[S1, ..., Sn, ..., SL ]: The historical daily load\nsegments.\nV =[V1, ..., Vn, ..., VL , VL+1, ..., VL+d ]: The daily\nvariable dataset.\nk: The number of similar historical daily load\nsegments.\nd: The number of load segments to be predicted.\nOutput:\nS =[SL+1, ..., SL+d ]: The daily load segments in the\nnext d days.\nLoad Forecasting\nStart:\n1: For t =L +1 to L +d\n2: For n =1 to L\n3: Calculate the distance D(Vt , Vn) using (13).\n4: End\n5: Rank the distance results in ascending order\n[D(1,t), ..., D(L,t)].\n6: Select the front k daily load segments\n[S(1,t), ..., S(k,t)].\n7: Predict St by inputting [S (1,t), ..., S(k,t)] into (14).\n8: End\n9: S =[SL+1, ..., St , ..., SL+d ].\nForecasting End.\nTerminate\nFIGURE 4. Parallel transformers in a substation.\nFIGURE 5. Effect of a single-component failure event on transformer load.\n(1) If an unplanned outage of the equipment (transformer,\ncircuit breaker, or line) occurs, the substation dispatchers\ncan predict the irregular load of the rest of the transformers\n161428 VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nTABLE 2. Historical load data of station1.\nand compare the predicted values with their nameplate\nratings. If the predicted load exceeds the capacity lim-\nits, load transfer or load curtailment should be imple-\nmented to avoid overloading and to protect the safety of\ntransformers.\n(2) Maintenance plan optimization: The equipment in the\nsubstation should be placed out of service and maintained\naccording to the maintenance plans. In this case, the sub-\nstation will operate in a known irregular condition. Load\nforecasting of transformers will provide important informa-\ntion for maintenance plan optimization. For instance, if the\npredicted irregular load of the rest of the transformers is\nlower than their nameplate ratings, the maintenance can be\nimplemented as planned. However, if the predicted values\nare higher than the nameplate ratings, the maintenance can\nbe properly postponed until the substation load is at a low\nlevel. If postponement is not allowed, load transfer or load\ncurtailment should be implemented before maintaining the\nequipment.\nIn most cases, irregular load data are much scarcer than\nregular load data. For instance, the historical data of Station 1\nunder different operating conditions from 2015 to 2016 are\npresented in Table 2. According to the characteristics of\nthe irregular transformer load data, most of the existing\nSTLF models, including the three proposed models in\nsection II, are inappropriate for transformer load forecasting\ndue to the following reasons.\n(1) STLF is performed for daily load segments rather\nthan load values at each time point. However, the substation\noperating condition may change unexpectedly at any point in\ntime. Therefore, each load value of the transformer should be\npredicted independently.\n(2) The irregular load data are too scarce to train the\nANN-based model. Moreover, once the substation oper-\nating condition changes, it is necessary to retrain the\nANN model using a certain amount of data under the\nnew condition. This is especially unacceptable for irregular\nload because the data used for model training cannot be\npredicted.\nTo solve the above problems, in this section, nonlinear\nregression functions are applied to predict the load of parallel\ntransformers instead of using ANN-based models.\nB. LOAD DISTRIBUTION FACTOR\nIn a certain operating condition Cj, the load distribution factor\n(LDF) is the ratio of the transformer load to the substation\nFIGURE 6. Load of Station1 and the LDF values of four parallel\ntransformers.\nload [10]. LDF can be calculated by (15):\nLDFt\n(\nTn,Cj\n)\n=Xt\n(\nTn,Cj\n)\nXt (Sta) = Xt\n(\nTn,Cj\n)\nTN∑\nTn=1\nXt\n(\nTn,Cj\n), (15)\nwhere LDFt (Tn, Cj) is the LDF value of transformer Tn at\ntime t (t ∈[1, T +d ×P]). Xt (Tn, Cj) is the load of Tn. Xt (Sta)\nis the load of the substation.\nLDF changes dynamically with the substation-level load.\nFor example, the LDF values of four transformers and X(Sta)\nbetween 13/09/2015 and 17/09/2015 are shown in Fig. 6.\nFrom Fig. 6, the relationship between the LDF of each\ntransformer and X(Sta) exhibits signiﬁcant differences under\ndifferent operating conditions. In addition, it is obvious that\nthe LDF values of T1 and T2 show a signiﬁcant positive\ncorrelation with X(Sta), whereas the LDF values of T3 and\nT4 show a negative correlation with X(Sta). Taking T1 and\nT4 as examples, the scatter plots in Fig. 7(a) and (b) show\nthe relationship under condition C0. The relationship of T1,\nT2, and T4 under condition C3 is shown in Fig. 8(a) to (c),\nrespectively. It should be noted that the LDF value of\nT3 becomes zero because T3 is out of service under\ncondition C3.\nAccording to the related theory, when the rated capacities\nof parallel transformers are the same, the LDF is inversely\nproportional to the per unit values of short-circuit impedance.\nDuring equipment operation, the substation load and other\nfactors have a greater effect on the actual short-circuit\nimpedance. However, the relationship between substation\nload and short-circuit impedance is difﬁcult to quantify using\nan accurate physical model because the measured values of\nshort-circuit impedance and the potential inﬂuencing factors\ncannot be obtained. To solve this challenge, a data-driven\nmodel is established to quantify the nonlinear correlation\nbetween the LDF and substation-level load using a nonlinear\nregression function, as shown in (16):\nLDFt\n(\nTn,Cj\n)\n=G\n(\nX (Sta),Tn,Cj\n)\n+εt , (16)\nwhere εt is the prediction error between the predicted value\nLDFt (Tn,Cj) and the actual value LDFt (Tn, Cj) at time t.\nG(X(Sta), Tn, Cj) is a special nonlinear regression func-\ntion of Tn under condition Cj. In this paper, four types of\nnonlinear regression functions are applied, as shown in (17)\nVOLUME 7, 2019 161429\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nFIGURE 7. Relationship between the LDF and substation-level load under\ncondition C0. (a)T1. (b)T4.\nthrough (20):\nG1 (X)=a1 ·Xa2 +a0, (17)\nG2 (X)=b3 ·X3 +b2 ·X2 +b1 ·X +b0, (18)\nG3 (X)=c0 ·exp (c1 ·X), (19)\nG4 (X)=d2 ·exp\n[\n−\n(X −d0\nd1\n)2]\n(20)\nG1(X) through G 4(X) are a power function with a constant\nterm, a cubic polynomial function, an exponential function,\nand a Gaussian function, respectively. a0 through d2 are the\nparameters of each function. The parameters can be estimated\nusing the nonlinear least squares method based on the his-\ntorical load observations. These four types of functions are\nsuitable for scarce irregular load data because they are simple\nand have few parameters.\nHowever, these functions cannot be applied in some sce-\nnarios with extremely scarce observations. For example, there\nare only two observations under condition C4 in Table 2.\nTherefore, the regression function is further simpliﬁed to an\naverage of historical LDF values, as shown in (21):\nG\n(\nX (Sta),Tn,Cj\n)\n=mean\n[\nLDFt (Tn,Cj)\n]\n(21)\nC. LOAD FORECASTING OF THE TRANSFORMER\nThe load value of Tn at time t under condition Cj can be\npredicted using (22):\n¯Xt\n(\nTn,Cj\n)\n=G\n(\nX (Sta),Tn,Cj\n)\n·¯Xt (Sta), (22)\nwhere ¯Xt\n(\nTn,Cj\n)\nand ¯Xt (Sta) are the predicted load value\nof Tn and the substation at time t, respectively. When\nthe operating condition changes, the load forecasting\nis performed by simply adjusting the corresponding\nfunction G(X (Sta), Tn, Cj).\nFIGURE 8. Relationship between the LDF and substation-level load under\ncondition C3. (a)T1. (b)T2. (c)T4.\nIV. APPLICATION EXAMPLE\nIn this section, three examples are provided to verify the\neffectiveness of the proposed method. All of the experiments\nare conducted in MATLAB 2018b. The Deep Learning Tool-\nbox of MATLAB is applied to establish the LSTM network.\nA. BASIC INFORMATION AND PERFORMACE METRICS\nThe historical daily load segments and the daily variable\nvectors of Station 1 from 2015 to 2016 are obtained. Three\nnumerical experiments are implemented using the historical\nload data from 09/01/2016 to 07/09/2016, as shown in Fig. 9.\nFour weather variables in the same period are shown in\nFig. 10. During this period, two irregular operating conditions\noccurred, indicated by the yellow and blue boxes, respec-\ntively.\n(1) T3 was out of service from 7:00 on 03/06/2016 to\n20:30 on 04/06/2016.\n(2)T2 was out of service from 6:30 on 02/09/2016 to\n17:00 on 04/09/2016.\nIn examples 1 and 2, the normal load data of 2015 are\napplied for hyperparameter selection of LSTM, ELM,\n161430 VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nFIGURE 9. Historical load of four parallel transformers in 2016. (a)T1. (b)T2. (c)T3. (d)T4.\nFIGURE 10. Weather variables. (a) Daily maximum and minimum\ntemperature. (b) Daily average pressure. (c) Daily precipitation.\nand kNN. The normal load data from 2015 to 2016 are applied\nfor parameter estimation of nonlinear regression functions\nunder the normal operating condition. The irregular load\ndata except those used in examples 1 and 2 are applied for\nparameter estimation of the nonlinear regression functions\nunder irregular operating conditions.\nWe employ the conventional multilayer perceptron (MLP)\nto serve as a naive benchmark to provide an impartial ref-\nerence. MLP has been widely applied in SLTF for many\nyears [28], [29]. However, the randomly selected parameters\nof the MLP will cause instability of the predicted results,\nwhich is the same as ELM [9]. To ensure stability and prevent\noverﬁtting, we establish an MLP ensemble (MLPE) model\nbased on the method proposed in [9]. The ﬁnal load forecast-\ning result is taken as the median value of the ten MLP outputs.\nRoot mean square error (RMSE) and mean absolute per-\ncentage error (MAPE) are employed for performance eval-\nuation and are calculated by (23) and (24), respectively.\nLower values of MAPE and RMSE indicate more precise\nprediction results:\nRMSE =\n√\n1\nm\nm∑\nt=1\n(\nXt −¯Xt\n)2, (23)\nMAPE =100%\nm\nm∑\nt=1\n⏐\n⏐Xt −¯Xt\n⏐\n⏐\nXt\n, (24)\nwhere m is the number of predicted load values.\nB. HYPERPARAMETER SELECTION\n1) HYPERPARAMETER SELECTION FOR THE LSTM NETWORK\nThe key hyperparameters of the LSTM network include the\nnumber of LSTM layers NLSTM , the learning rate Lr, and the\ntime step K. When training the LSTM network, the number\nof training iterations is set to 300. HLSTM is set to 100, and\nLr is initialized to 0.001. The Adam optimizer is used for\nmodel training [30]. To prevent the gradients from exploding,\nthe gradient threshold is set to 1. The early stopping technique\nis implemented to prevent overﬁtting when selecting NLSTM\nand Lr. The dropout layer with 0.5 dropout probability is\nadded to the forecasting framework instead of using the early\nstopping technique when selecting K.\nThe normal load data in 2015 are partitioned into 10 pairs\nof training and validation sets by the 10-fold cross-validation\nresampling method. During each cross-validation process, the\nvalidation frequency is set to 20, and the validation patience\nis set to 5 when using the early stopping technique. The loss\nfunction is the mean squared error (MSE), which is calculated\nby (25):\nMSE = 1\nmv\nmv∑\nt=1\n(\nXt −¯Xt\n)2, (25)\nwhere mv is the number of validation observations.\nVOLUME 7, 2019 161431\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nFIGURE 11. Hyperparameter selection for the LSTM network. (a)NLSTM.\n(b) Lr. (c)K.\nThe cross-validation results of NLSTM , Lr, and K are shown\nin Fig. 11(a) to (c), respectively. From Fig. 11(a), it is obvious\nthat the MSE becomes larger with the increase of NLSTM .\nIn Fig. 11(b), the curve of MSE exhibits an asymmetric\nU shape. With the increase of Lr, the MSE shows a rapid\ndecline at ﬁrst, and then it swings steadily between 0.001\nand 0.1. Finally, it rises dramatically when Lr >0.1. For K,\nthe MSE shows an approximately linear growth trend, which\nindicates that the prediction results will become less pre-\ncise with the increase of time step. According to the cross-\nvalidation results, the values of NLSTM , Lr, and K are selected\nas 1, 0.0063, and 1, respectively. In addition, when using a\ndropout layer instead of the early stopping strategy, the MSE\ndecreases from 23.09 to 13.74, indicating that the dropout\nlayer is superior to the early stopping technology.\n2) HYPERPARAMETER SELECTION FOR ELM, KNN AND MLPE\nThe hyperparameters of ELM include HELM and K. Accord-\ning to the cross-validation results shown in Fig. 12 (a) and (b),\nHELM and K are selected as 30 and 1, respectively. From\nFig. 11(c) and 12(b), it is obvious that the two curves have\nsimilar increasing trends.\nThe number of similar daily load segments k is the unique\nhyperparameter in the kNN model. The MSE obtains a local\nminimum when k =3 in Fig. 13, and if k is greater than 6,\nthe MSE curve shows a slow declining trend. However,\nthe computational complexity will increase when using an\noverly large k. Therefore, k is selected as 3.\nFIGURE 12. Hyperparameter selection for ELM. (a)HELM . (b)K.\nFIGURE 13. Hyperparameter selection for kNN.\nAs for MLPE, the structure of each MLP is the same\nas ELM. The number of hidden nodes HMLP is selected\nas 500.\nC. RELATIONSHIP BETWEEN THE LDF AND\nSUBSTATION-LEVEL LOAD\nTo select the appropriate nonlinear regression functions,\nthe goodness of ﬁt is evaluated using the R 2 coefﬁcient.\nA higher R 2 indicates a better goodness of ﬁt. According\nto the historical load data, the R 2 results of the four types\nof nonlinear regression functions under four operating con-\nditions are calculated and shown in Table 3. It is obvious\nthat the power function G 1(X) outperforms the other three\nfunctions under the normal operating condition. The cubic\npolynomial function G 2(X) has the highest R 2 values under\nall of the irregular conditions, whereas the R 2 values of the\npower function are slightly lower than those of the cubic\npolynomial function.\nDifferent function curves of G(X (Sta), T1, C0), G(X (Sta),\nT4, C0), G(X (Sta), T1, C3), G(X (Sta), T2, C3), and G(X (Sta),\nT4, C3) are shown in Fig. 7(a), 7(b), 8(a), 8(b), and 8(c),\nrespectively. In these ﬁgures, the curves of the exponential\nfunction G3(X) and Gaussian function G 4(X) are too smooth\nto ﬁt the original data. Therefore, G 1(X) and G 2(X) are\napplied for transformer load forecasting.\nD. EXAMPLE 1: LOAD FORECASTING UNDER\nCONDITION C3\n1) TRANSFORMER LOAD FORECASTING UNDER NORMAL\nOPERATING CONDITION\nIn this subsection, the loads of the substation and transformers\nfrom 01/06/2016 to 07/06/2016 are predicted to evaluate the\n161432 VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nTABLE 3. R2 results of different nonlinear regression functions.\nTABLE 4. RMSE and MAPE of the substation load forecasting results.\nperformance of the proposed model. The normal load of each\ntransformer can be forecast using the following two methods.\nMethod (1): The substation load is ﬁrstly predicted\nusing the ANN-based model, and then the load of\neach transformer is predicted using the power function\nG1(X(Sta), Tn, C0) or cubic polynomial function G 2(X(Sta),\nTn, C0). The historical load of Station 1 from 09/01/2016 to\n31/05/2016 is applied to train three ANN-based models. The\nRMSE and MAPE of each predicted load segment are shown\nin Table 4. It is obvious that LSTM outperforms ELM and\nkNN. Therefore, the substation load predicted by the LSTM\nnetwork is input into (22) to calculate the load of the four\nparallel transformers.\nMethod (2): The load of the four parallel transformers\nis independently predicted using three ANN-based models.\nAccording to the RMSE and MAPE of the forecast results,\nthe most accurate loads of T1, T2, and T3 are predicted by\nthe LSTM-based model, whereas the most accurate results\nof T4 are obtained by the kNN-based model.\nThe MAPE of each predicted load segment is shown\nin Table 5. It is obvious that the MAPE results of method (1)\nand method (2) exhibit slight differences, indicating that these\ntwo methods are effective and rational for load forecasting of\nparallel transformers. In addition, the MAPE of June 3 and 4\nis much higher than that of other dates because the substation\noperating condition changed from C0 to C3 during this period,\nindicating that method (1) and method (2) cannot accurately\npredict the irregular load.\nAccording to the ﬁtting curves in Fig. 7 and R2 results\nin Table 3, G 1(X) and G 2(X) can accurately quantify the\nrelationship between the LDF and substation load. Therefore,\nthe load of each transformer can be accurately obtained using\nG1(X) and G 2(X), indicating the rationality and effectiveness\nof method (1).\nAlthough method (2) can also accurately predict the trans-\nformer load, it is not recommended for practical applications\ndue to the following shortcomings.\n(1) ANN-based models should be independently estab-\nlished, optimized, selected, and trained for each trans-\nformer when using method (2), which is time-consuming and\nrequires more computing resources than method (1) because\nthe structure of an ANN is more complex than that of a\nnonlinear regression function. In addition, the number of\nparameters of an ANN is far greater than that of a nonlinear\nregression function. Therefore, more computer memory and\nstorage space are required when using method (2).\n(2) Compared to the substation-level load, the consecu-\ntiveness of normal transformer load is more easily disrupted\nby different irregular operating conditions. The performance\nof stepwise extrapolation forecasting models (e.g., LSTM\nand ELM) will be degraded when the training data are non-\nconsecutive.\n2) TRANSFORMER LOAD FORECASTING UNDER IRREGULAR\nOPERATING CONDITIONS\nThe load of three transformers under condition C3 during\nJune 3 and 4 is predicted using method (1), and the MAPE\nof the prediction results is shown in Table 6. However,\nthe MAPE values of June 3 and 4 still remain higher when\nusing G(X (Sta), Tn, C3) instead of G(X (Sta), Tn, C0). Theo-\nretically, this phenomenon is abnormal, so an investigation is\nconducted for these two days.\nTABLE 5. MAPE of the transformer load forecasting results.\nVOLUME 7, 2019 161433\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nTABLE 6. MAPE of the prediction results.\nFIGURE 14. Load prediction results ofT1 under conditionC3.\nThe actual load values of Station 1 are input into G(X (Sta),\nTn, Cj) instead of the predicted values. When using G(X (Sta),\nTn, C3) instead of G(X (Sta), Tn, C0), the MAPE of the predic-\ntion results shows a rapid decline in Table 6, indicating that\nG1(X) and G 2(X) are still effective.\nFig. 14 shows the prediction results of T1. It should be\nmentioned that the actual load of Station 1 on June 3 and 4 is\nquite lower than usual. When T3 is out of service, the low\nload of T1 is ﬁlled by the partial load of T3, and the actual\nload of T1 seems to reach the normal load under condition C0.\nIn this case, the MAPE will not decrease because the higher\npredicted load values are obtained using G(X (Sta), Tn, C3).\nIn summary, the prediction error of the transformer-level\nload is mainly affected by the predicted substation-level load\nrather than the nonlinear regression functions. Therefore, it is\nof great signiﬁcance to ensure the prediction accuracy of the\nsubstation-level load.\nIn Fig. 14, although the R 2 values (shown in Table 3) of\nthe cubic polynomial function G 2(X) are slightly higher than\nthose of the power function G 1(X) under irregular conditions,\nthe ﬁtting error of G 2(X) is dramatically increased when\nthe substation-level load is too high or too low, as shown\nin Figs. 7 and 8. For example, the MAPE of the predicted\nload in June 4 is much higher when using G 2(X) because\nthe predicted load of Station 1 is higher during this period.\nAccording to the performances of the four nonlinear regres-\nsion functions, G1(X) should be preferentially considered for\ntransformer load forecasting.\nAn extra experiment is proposed using the mean LDF value\ninstead of G 1(X) and G 2(X). The MAPE of the prediction\nresults is shown in the rightmost column of Table 6. It is\nTABLE 7. MAPE of each predicted load segment.\nFIGURE 15. Load prediction results ofT1 under conditionC2.\ndemonstrated that the nonlinear regression functions are more\nprecise than the mean LDF value. In practical applications,\nthe nonlinear regression functions should be preferentially\nconsidered unless the historical data are extremely scarce,\nsuch as the irregular condition of C4.\nE. EXAMPLE 2: LOAD FORECASTING UNDER\nCONDITION C2\nThe loads of Station 1 and four parallel transformers are\npredicted using method (1) from 01/09/2016 to 07/09/2016.\nThe load data from 08/06/2016 to 31/08/2016 are applied\nfor model training. The RMSE and MAPE of each predicted\nload segment are shown in Table 7. In this example, kNN\nshows superior accuracy over LSTM and ELM. It should\nbe mentioned that the MAPE values of the substation load\nprediction results in example 2 are much higher than those in\nexample 1 (shown in Table 4) when using MLPE.\nThe load of Station 1 predicted by kNN is applied to pre-\ndict the load of the four parallel transformers using G 1(X)\nand G 2(X). During the outage of T2, G(X (Sta), Tn, C0) is\nreplaced by G(X (Sta), Tn, C2). Taking T1 as an example,\nthe prediction results are shown in Fig. 15. It is obvious that,\nwhen the prediction accuracy of the substation-level load is\nensured, the load of the parallel transformers can be accu-\nrately predicted using G 1(X) or G2(X). In Fig. 15, we observe\na sharp increase in the active power of T1 under condi-\ntion C2. The peak load value is close to its nameplate rating\non September 2. Therefore, T1 should be carefully monitored\nto prevent overheating or insulation faults during this period.\n161434 VOLUME 7, 2019\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\nFIGURE 16. Load prediction results of parallel transformers under\ncondition C3.\nWe observe that LSTM performs better in example 1,\nwhereas kNN performs better in example 2. In addition,\nthe performance of MLPE shows signiﬁcant differences in\nexamples 1 and 2. This fact can be captured in the ‘no\nfree lunch’ theorem [31], which indicates that any ANN-\nbased model will not maintain the same performance in dif-\nferent datasets, and none of the STLF models outperform\nthe other STLF models in all scenarios. In Figs. 9 and 10,\nthe data of load and weather variables used in examples\n1 and 2 show obvious differences. Therefore, it is not surpris-\ning that the performance of each ANN-based model shows\ndifferences in these two datasets. In practical applications,\nit is recommended that the forecasters select the appropriate\nANN-based STLF model for each dataset according to the\nperformance evaluation results rather than using the same\nmodel for different scenarios.\nF. EXAMPLE 3: EFFECT OF LOAD FORECASTING ON\nMAINTENANCE PLAN OPTIMIZATION\nIn this subsection, a simulation experiment is presented\nto show the effect of load forecasting on optimization of\nthe equipment maintenance plan. The load data applied\nto the experiment during the period from 01/08/2016 to\n12/08/2016 are shown in the orange box in Fig. 9. In this\nperiod, it is assumed that T3 should be out of service and\nmaintained for 5 days. During the maintenance, the operating\ncondition of Station1 will change from C0 to C3. The question\nfaced by maintenance engineers is: should T3 be maintained\nfrom August 1 to 5?\nThe actual load values of Station 1 are input into the power\nfunction G1(X(Sta), Tn, C3), and the load forecasting results\nof T1, T2, and T4 are shown in Fig. 16. T4 is obviously over-\nloaded from August 3 to 6. To avoid any possible overloading,\nthe following two strategies are considered:\n(1) Strategy 1: The maintenance is properly postponed and\nstarts after August 6.\n(2) Strategy 2: If the postponement is not allowed due to\nsome factors, such as severe faults or defects of T3, then\nload transfer or load curtailment should be considered to\nreduce the load of Station 1. For instance, the overloading\nof T4 can be avoided when the substation load is reduced by\napproximately 20% from August 3 to 6.\nThe decision-making associated with the maintenance\nof equipment has been a challenge for power systems.\nAccording to example 3, it is demonstrated that transformer\nload forecasting is helpful for the maintenance plan\noptimization.\nV. CONCLUSION\nThis paper presents a two-stage STLF model for power trans-\nformers. The substation-level load is ﬁrst predicted by three\nstate-of-the-art STLF technologies. The nonlinear regression\nfunctions are applied to capture the relationship between the\nload distribution factor and substation-level load under differ-\nent substation operating conditions. Finally, the load of paral-\nlel transformers is predicted using these regression functions.\nThree application examples demonstrate the effectiveness\nand accuracy of the proposed model, and the load forecasting\nresults can provide important information for optimizing sub-\nstation operating schemes and equipment maintenance plans.\nAlthough single-component failure events are considered in\nthis paper, the approach is general and can be applied to\nother scenarios, such as multiple-component failure events,\nthe retirement of old equipment, or the installation of new\nequipment.\nAs future work, the STLF models should be further devel-\noped and applied to substations in which the transformers\ndo not work in parallel. For example, a substation is typi-\ncally sectionalized in the distribution networks. In addition,\nthe hierarchical structure will be expanded to multiple levels\nranging from the entire system to feeders, substations, trans-\nformers and the customers.\nREFERENCES\n[1] R. Godina, E. M. G. Rodrigues, J. C. O. Matias, and J. P. S. Catalão, ‘‘Effect\nof loads and other key factors on oil-transformer ageing: Sustainability\nbeneﬁts and challenges,’’ Energies, vol. 10, no. 8, pp. 12147–12186,\nAug. 2015.\n[2] A. Bracale, G. Carpinelli, M. Pagano, and P. De Falco, ‘‘A probabilistic\napproach for forecasting the allowable current of oil-immersed transform-\ners,’’IEEE Trans. Power Del., vol. 33, no. 4, pp. 1825–1834, Aug. 2018.\n[3] B. A. Høverstad, A. Tidemann, H. Langseth, and P. Ötürk, ‘‘Short-term\nload forecasting with seasonal decomposition using evolution for param-\neter tuning,’’ IEEE Trans. Smart Grid, vol. 6, no. 4, pp. 1904–1913,\nJul. 2015.\n[4] J. W. Taylor, ‘‘Triple seasonal methods for short-term electricity demand\nforecasting,’’Eur. J. Oper. Res., vol. 204, no. 1, pp. 139–152, Jul. 2010.\n[5] J. C. López, M. J. Rider, and Q. Wu, ‘‘Parsimonious short-term load fore-\ncasting for optimal operation planning of electrical distribution systems,’’\nIEEE Trans. Power Syst., vol. 34, no. 2, pp. 1427–1437, Mar. 2019.\n[6] P. Wang, B. Liu, and T. Hong, ‘‘Electric load forecasting with recency\neffect: A big data approach,’’ Int. J. Forecasting, vol. 32, no. 3,\npp. 585–597, Sep. 2015.\n[7] T. Hong and P. Wang, ‘‘Fuzzy interaction regression for short term load\nforecasting,’’ Fuzzy Optim. Decis. Making, vol. 13, no. 1, pp. 91–103,\nSep. 2013.\n[8] B. Liu, J. Nowotarski, T. Hong, and R. Weron, ‘‘Probabilistic load fore-\ncasting via quantile regression averaging on sister forecasts,’’ IEEE Trans.\nSmart Grid, vol. 8, no. 2, pp. 730–737, Mar. 2017.\n[9] R. Zhang, ‘‘Short-term load forecasting of Australian national electricity\nmarket by an ensemble model of extreme learning machine,’’ IET Gener.,\nTransmiss. Distrib., vol. 7, no. 6, pp. 391–397, Apr. 2013.\n[10] X. Sun, P. B. Luh, K. W. Cheung, W. Guan, L. D. Michel, S. S. Venkata, and\nM. T. Miller, ‘‘An efﬁcient approach to short-term load forecasting at the\ndistribution level,’’IEEE Trans. Power Syst., vol. 31, no. 4, pp. 2526–2537,\nJul. 2016.\n[11] W. Kong, Z. Dong, Y . Jia, D. J. Hill, Y . Xu, and Y . Zhang, ‘‘Short-term\nresidential load forecasting based on LSTM recurrent neural network,’’\nIEEE Trans. Smart Grid, vol. 10, no. 1, pp. 841–851, Jan. 2019.\nVOLUME 7, 2019 161435\nH. Liuet al.: Two-Stage STLF for Power Transformers Under Different Substation Operating Conditions\n[12] H. Shi, M. Xu, and R. Li, ‘‘Deep learning for household load forecasting—\nA novel pooling deep RNN,’’ IEEE Trans. Smart Grid, vol. 9, no. 5,\npp. 5271–5280, Sep. 2018.\n[13] Z. Yu, Z. Niu, W. Tang, and Q. Wu, ‘‘Deep learning for daily peak load\nforecasting—A novel gated recurrent neural network combining dynamic\ntime warping,’’ IEEE Access, vol. 7, pp. 17184–17194, Feb. 2019.\n[14] T. Ouyang, Y . He, H. Li, Z. Sun, and S. Baek, ‘‘Modeling and forecasting\nshort-term power load with copula model and deep belief network,’’ IEEE\nTrans. Emerg. Topics Comput. Intell., vol. 3, no. 2, pp. 127–136, Apr. 2019.\n[15] J. Chen, W. Li, A. Lau, J. Cao, and K. Wang, ‘‘Automated load curve\ndata cleansing in power systems,’’ IEEE Trans. Smart Grid, vol. 1, no. 2,\npp. 213–221, Sep. 2010.\n[16] F. H. A. Qahtani and S. F. Crone, ‘‘Multivariate k-nearest neighbour regres-\nsion for time series data—A novel algorithm for forecasting UK electricity\ndemand,’’ in Proc. IJCNN, Dallas, TX, USA, Aug. 2013, pp. 1–8.\n[17] R. Zhang, Y . Xu, Z. Dong, W. Kong, and K. P. Wong, ‘‘A composite\nk-nearest neighbor model for day-ahead load forecasting with limited\ntemperature forecasts,’’ in Proc. PESGM, Boston, MA, USA, Jul. 2016,\npp. 1–5.\n[18] E. Paparoditis and T. Sapatinas, ‘‘Short-term load forecasting: The similar\nshape functional time-series predictor,’’ IEEE Trans. Power Syst., vol. 28,\nno. 4, pp. 3818–3825, Nov. 2013.\n[19] M. Chaouch, ‘‘Clustering-based improvement of nonparametric functional\ntime series forecasting: Application to intra-day household-level load\ncurves,’’IEEE Trans. Smart Grid, vol. 5, no. 1, pp. 411–419, Jan. 2014.\n[20] P. Zhang, X. Wu, X. Wang, and S. Bi, ‘‘Short-term load forecasting based\non big data technologies,’’ CSEE J. Power Energy Syst., vol. 1, no. 3,\npp. 59–67, Sep. 2015.\n[21] G. Dudek, ‘‘Artiﬁcial immune system with local feature selection for\nshort-term load forecasting,’’ IEEE Trans. Evol. Comput., vol. 21, no. 1,\npp. 116–130, Feb. 2017.\n[22] X. Wang, W. J. Lee, H. Huang, R. L. Szabados, D. Y . Wang, and\nP. V . Olinda, ‘‘Factors that impact the accuracy of clustering-based load\nforecasting,’’ IEEE Trans. Ind. Appl., vol. 52, no. 5, pp. 3625–3630,\nSep. 2016.\n[23] W. Li, ‘‘Application of risk evaluation to transmission development plan-\nning,’’ in Risk Assessment of Power Systems: Models, Methods, and Appli-\ncations, vol. 6. New York, NY , USA: IEEE Press, 2008, pp. 127–150.\n[24] S. Hochreiter and J. Schmidhuber, ‘‘Long short-term memory,’’ Neural\nComput., vol. 9, no. 8, pp. 1735–1780, Nov. 1997.\n[25] F. A. Gers, J. Schmidhuber, and F. Cummins, ‘‘Learning to forget:\nContinual prediction with LSTM,’’ Neural Comput., vol. 12, no. 10,\npp. 2451–2471, Oct. 2000.\n[26] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and\nR. Salakhutdinov, ‘‘Dropout: A simple way to prevent neural networks\nfrom overﬁtting,’’ J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929–1958,\n2014.\n[27] G.-B. Huang, Q.-Y . Zhu, and C.-K. Siew, ‘‘Extreme learning machine: The-\nory and applications,’’ Neurocomputing, vol. 70, nos. 1–3, pp. 489–501,\nDec. 2006.\n[28] H. S. Hippert, C. E. Pedreira, and R. C. Souza, ‘‘Neural networks for short-\nterm load forecasting: A review and evaluation,’’ IEEE Trans. Power Syst.,\nvol. 16, no. 1, pp. 44–55, Feb. 2001.\n[29] S. Valero, J. Aparicio, C. Senabre, M. Ortiz, J. Sancho, and A. Gabaldon,\n‘‘Comparative analysis of self organizing maps vs. multilayer percep-\ntron neural networks for short-term load forecasting,’’ in Proc. MEPS,\nWroclaw, Poland, Sep. 2010, pp. 1–5.\n[30] D. P. Kingma and J. L. Ba, ‘‘Adam: A method for stochastic optimization,’’\nin Proc. ICLR, San Diego, CA, USA, 2015, pp. 1–15.\n[31] D. H. Wolpert, ‘‘The lack of a prioridistinctions between learning algo-\nrithms,’’Neural Comput., vol. 8, no. 7, pp. 1341–1390, 1996.\nHANG LIU was born in Yunnan, China, in 1992.\nHe received the B.Sc. degree from Chongqing\nUniversity, China, in 2014, where he is currently\npursuing the Ph.D. degree with the School of Elec-\ntrical Engineering. His major research interests\ninclude the ﬁeld of on-line monitoring and fault\ndiagnosis for power equipment.\nYOUYUAN WANGreceived the M.S. and Ph.D.\ndegrees in electrical engineering from Chongqing\nUniversity, Chongqing, China, in 2003 and 2008,\nrespectively. He is currently a Professor with the\nHigh V oltage and Insulation Technology Depart-\nment, Chongqing University. His major research\ninterests include dielectric properties and space\ncharge behavior of nanocomposites, online detec-\ntion of insulation condition in electrical devices,\nand insulation fault diagnosis for high voltage\nequipment. He is also the author or coauthor of more than 50 journal articles\nand 30 papers published in proceedings of international conferences.\nCHAO WEI was born in Shandong, China,\nin 1984. He received the B.Sc. and M.Sc. degrees\nin electrical engineering from Chongqing Univer-\nsity, Chongqing, China, in 2007 and 2010, respec-\ntively. He is currently with the State Grid Jiangsu\nElectric Power Research Institute, Nanjing, China.\nHis major research interests include on-line mon-\nitoring of insulation condition, fault diagnosis for\nhigh voltage apparatus, and ageing mechanism and\ndiagnosis for power transformers.\nJIANSHENG LI was born in Shandong, China,\nin 1986. He received the Ph.D. degree in electri-\ncal engineering from Shandong University, Jinan,\nChina, in 2014. He is currently with the State Grid\nJiangsu Electric Power Research Institute, Nan-\njing, China. His major research interest includes\noperating analysis and maintaining of power trans-\nformers and reactors.\nYUANDI LINwas born in Anhui, China, in 1988.\nHe received the B.Sc. degree in electrical engi-\nneering from the China University of Mining and\nTechnology, Jiangsu, China, in 2012, and the Ph.D.\ndegree in electrical engineering from Chongqing\nUniversity, Chongqing, China, in 2017. He is cur-\nrently with the State Grid Jiangsu Electric Power\nResearch Institute, Nanjing, China. His major\nresearch interests include online detection of insu-\nlation condition of electrical devices and insulation\nfault diagnosis for high voltage equipment.\n161436 VOLUME 7, 2019",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7435675263404846
    },
    {
      "name": "Reliability engineering",
      "score": 0.6028463840484619
    },
    {
      "name": "Computer science",
      "score": 0.5635372400283813
    },
    {
      "name": "Nonlinear system",
      "score": 0.5590728521347046
    },
    {
      "name": "Electric power system",
      "score": 0.48161953687667847
    },
    {
      "name": "Engineering",
      "score": 0.29813045263290405
    },
    {
      "name": "Electrical engineering",
      "score": 0.18936043977737427
    },
    {
      "name": "Power (physics)",
      "score": 0.18439576029777527
    },
    {
      "name": "Voltage",
      "score": 0.11729010939598083
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I158842170",
      "name": "Chongqing University",
      "country": "CN"
    }
  ],
  "cited_by": 16
}