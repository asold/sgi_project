{
  "title": "A language model for Amdo Tibetan speech recognition",
  "url": "https://openalex.org/W3131143456",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A3131976860",
      "name": "Taiben Suan",
      "affiliations": [
        "Qinghai Normal University",
        "Qinghai Tibetan Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2225893258",
      "name": "Rangzhuoma Cai",
      "affiliations": [
        "Southwest Minzu University",
        "Qinghai Tibetan Hospital",
        "Qinghai Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A2159609497",
      "name": "Zhi-jie Cai",
      "affiliations": [
        "Southwest Minzu University",
        "Qinghai Normal University",
        "Qinghai Tibetan Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3129593787",
      "name": "Ba Zu",
      "affiliations": [
        "Qinghai Tibetan Hospital",
        "Qinghai Normal University"
      ]
    },
    {
      "id": "https://openalex.org/A3129341991",
      "name": "Baojia Gong",
      "affiliations": [
        "Qinghai Normal University",
        "Qinghai Tibetan Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A3131976860",
      "name": "Taiben Suan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2225893258",
      "name": "Rangzhuoma Cai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2159609497",
      "name": "Zhi-jie Cai",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3129593787",
      "name": "Ba Zu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3129341991",
      "name": "Baojia Gong",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2136922672",
    "https://openalex.org/W2951444698",
    "https://openalex.org/W2697044473",
    "https://openalex.org/W2984865357",
    "https://openalex.org/W2963403868"
  ],
  "abstract": "We built a language model which is based on Transformer network architecture, used attention mechanisms to dispensing with recurrence and convalutions entirely. Through the transliteration of Tibetan to International Phonetic Alphabets, the language model was trained using the syllables and phonemes of the Tibetan word as modeling units to predict corresponding Tibetan sentences according to the context semantics of IPA. And it combined with the acoustic model as the Tibetan speech recognition was compared with end-to-end Tibetan speech recognition.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7484641671180725
    },
    {
      "name": "Transliteration",
      "score": 0.6808369755744934
    },
    {
      "name": "Transformer",
      "score": 0.6101554036140442
    },
    {
      "name": "Speech recognition",
      "score": 0.6057981252670288
    },
    {
      "name": "Natural language processing",
      "score": 0.5931106209754944
    },
    {
      "name": "Language model",
      "score": 0.5685283541679382
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48052796721458435
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.44976410269737244
    },
    {
      "name": "Context (archaeology)",
      "score": 0.43852266669273376
    },
    {
      "name": "History",
      "score": 0.09287938475608826
    },
    {
      "name": "Engineering",
      "score": 0.08047124743461609
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}