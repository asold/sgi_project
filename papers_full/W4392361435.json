{
  "title": "Ten simple rules to leverage large language models for getting grants",
  "url": "https://openalex.org/W4392361435",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A1992441618",
      "name": "Elizabeth Seckel",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2595150714",
      "name": "Brandi Y. Stephens",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2102057105",
      "name": "Fatima Rodriguez",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A1992441618",
      "name": "Elizabeth Seckel",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2595150714",
      "name": "Brandi Y. Stephens",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102057105",
      "name": "Fatima Rodriguez",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4385238793",
    "https://openalex.org/W6853504174",
    "https://openalex.org/W4383551192",
    "https://openalex.org/W4376224599",
    "https://openalex.org/W4317390716",
    "https://openalex.org/W4293496409",
    "https://openalex.org/W4384663467",
    "https://openalex.org/W4322008312",
    "https://openalex.org/W4317853296",
    "https://openalex.org/W4320728115",
    "https://openalex.org/W2747680751",
    "https://openalex.org/W2144795396",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4383500999",
    "https://openalex.org/W4386001316",
    "https://openalex.org/W4364363895",
    "https://openalex.org/W4377115988",
    "https://openalex.org/W4224947616",
    "https://openalex.org/W4290852327",
    "https://openalex.org/W2996610311",
    "https://openalex.org/W2771730919",
    "https://openalex.org/W2471603218",
    "https://openalex.org/W4323812846",
    "https://openalex.org/W4321351832",
    "https://openalex.org/W4379089685"
  ],
  "abstract": null,
  "full_text": "EDUCATIO N\nTen simple rules to leverage large language\nmodels for getting grants\nElizabeth Seckel\nID\n*, Brandi Y. Stephens, Fatima Rodriguez\nDivision of Cardiovascula r Medicine, Stanford University School of Medicine, Stanford, California, United\nStates of America\n* esecke l@stanford.e du\nIntroductionAU : Pl eas econ firm tha tall hea ding lev els are repr ese nted cor rec tly:\nThe recent leap in performance of large language models (LLMs), a subclass of artificial intelli-\ngence (AI) algorithms that includes OpenAI’s ChatGPT, Google Bard, and Microsoft’s Copilot\n(formerly Bing Chat), ushered a revolution in artificial text generation. These systems, trained\non billions of documents, are sophisticated enough to fool human users into thinking they are\nconversing with other humans [1,2].\nIn academia, LLM-driven chatbots have become popular tools to help draft and revise sci-\nentific text [3,4], with some going as far as including them as coauthors [5]. Enthusiasts high-\nlight the ability of these systems to summarize entire articles, simplify jargon-laden\nparagraphs, and improve the clarity and conciseness of drafts, particularly for non-native\nEnglish writers [6–8]. On the other hand, others have advocated for strict boundaries and\nrestrictions [5,9,10], citing ethical and privacy concerns as well as the tendency of these tools\nto “hallucinate”—or confabulate and fabricate—facts and references [11]. LLMs are fed enor-\nmous amounts of information and use statistics to predict the next word in a sentence [12]. By\ndoing so, they generate grammatically and semantically correct text in response to prompts\nbut are unable to estimate the uncertainty or truth of their predictions—resulting in hallucina-\ntions. This also means that the generated text can be borrowed verbatim from existing sources,\nwhich has led to a growing number of copyright lawsuits [13,14].\nAs writers of scientific proposals, we believe that writing proposals is a very personal exer-\ncise where the final product is best when imbued with the ideas, style, and personality of the\nwriter. The iterative process of drafting and refining also helps develop scientific writing skills\n[15], which are essential for a successful long-term career in academia. We also believe, how-\never, that scientists can benefit immensely from including AI in this process, as assistants or\nmakeshift reviewers, in particular as the algorithms that power these systems become better\nand more widely available. This article aims to strike a delicate balance—an enthusiastic yet\ncautionary tale outlining 10 best practice tips (summarized in Fig 1) for using LLMs during\nyour grant writing journey.\nRule 1: Check the guidelines of the funding agency regarding AI\nSeveral publishers and funding agencies have issued specific—but diverse—guidelines regard-\ning the use of AI chatbots in publications and grant applications. While publishers such as Sci-\nence initially took a very restrictive stance, equating using AI to plagiarism and forbidding its\nuse in any submissions to its journals [16], many now simply forbid chatbots from being listed\nas authors but allow their use in publications if properly acknowledged [9,17]. Going a step\nfurther, Springer Nature has recently released Curie, a new AI-powered writing assistant for\nacademic researchers, especially for those whose first language is not English [18]. For grants,\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 1 / 7\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Seckel E, Stephens BY, Rodrig uez F\n(2024) Ten simple rules to leverage large language\nmodels for getting grants. PLoS Comput Biol\n20(3): e1011863. https:// doi.org/10.1371 /journal.\npcbi.1011863\nEditor: Russell Schwartz, Carnegie Mellon\nUniversity , UNITED STATES\nPublished: March 1, 2024\nCopyright: © 2024 Seckel et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nFunding: F.R. was funded by grants from the NIH\nNational Heart, Lung, and Blood Institute\n(1K01HL1 44607; https://ww w.nhlbi.nih.gov /), the\nAmerican Heart Association/ Harold Amos Faculty\nDevelopmen t program 20AMFD P35430002\n(https://w ww.amfdp.o rg/), and the Doris Duke\nFoundation (Grant #2022051; https://www.\ndorisduke.or g/). The funders had no role in study\ndesign, data collection and analysis, decision to\npublish, or preparation of the manuscript.\nCompeting interests : The authors have declared\nthat no competing interests exist.\nthe American Heart Association allows writers to use AI freely as long as they disclose it at the\ntime of submission [19]. The National Science Foundation encourages submitters to indicate\nif and how generative AI technology was used to develop their proposals while cautioning that\nthis technology can introduce fabrication, falsification, or plagiarism, which would constitute\nresearch misconduct [20]. The National Institutes of Health, on the other hand, do “not know,\nor ask, who wrote an application” but warns that scientists using AI tools to help write applica-\ntions do so at their own risk due to automated systems checking for plagiarism or false infor-\nmation [21]. As more and more institutions draft their own guidelines regarding AI usage,\nand given that existing policies are likely to change over time, it is imperative that you continu-\nously check the rules for the funding agency where you are submitting your grant. Whether\nthe funder requests this or not, we recommend disclosing any AI usage in your grant\napplications.\nFig 1. Ten rules for leveragin g LLMs for getting grants. Proposal developme nt timeline to illustrate at what point in your grant writing journey to\nincorpora te each rule. Light bulb and coal icons used in Fig 1 were adapted from https://www. svgrepo.com/ svg/52467 6/lightbulb-m inimalistic and https://\nwww.svgrep o.com/svg/ 398225/rock, respectively.\nhttps://do i.org/10.1371/j ournal.pc bi.1011863. g001\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 2 / 7\nRule 2: Consider data privacy limitations\nAI chatbots improve by learning from interactions with their users. Indeed, all the publicly\navailable AI chatbots, including ChatGPT and Google Bard, save your prompts and conversa-\ntions with the explicit goal of improving their algorithms. For example, although ChatGPT\noffers a way to delete your data, the company still advises users to refrain from sharing sensi-\ntive information with the AI. We argue that your grant application is, from draft to submis-\nsion, extremely sensitive information that you would not want to share freely with a\nconversational AI. Your ideas and approach could be suggested to another user—a competi-\ntor!—in a future iteration of the chatbot. To this end, we urge you to weigh the benefits of\nusing publicly available AI chatbots to help you with your grant application. Always check the\ndata storage settings before using any of the chatbots. Finally, if available at your institution, or\nyou have the computational resources, a self-hosted LLM restricted to offline access may offer\nimproved security and privacy, although at a cost of accuracy and/or performance.\nRule 3: Don’t use AI to write your grant\nA good rule of thumb is the first draft of any section must come from you. Because of how\nthese LLMs are trained, their output is not guaranteed to be original or scientifically valid. So,\nwhile it can be tempting to ask the LLM to generate an initial draft for you starting from an\nidea or a couple of sentences, avoiding the dreaded “blank page,” we do not recommend\nengaging with the AI until you have a draft and are ready to start the revision stage of the writ-\ning process. This advice applies both to the entire grant and to individual sections. Ultimately,\nyour grant must reflect you as a scientist—your scientific ideas, your preliminary data, and\nyour novel approach, described in your own words.\nRule 4: Use custom prompts for specific feedback\nJust as when requesting feedback from your human colleagues and mentors, the more specific\nyou are in what and how you would like them to review, the better, more focused, and ulti-\nmately more helpful feedback you receive. Requesting feedback from an LLM is no different.\nIn our experience, we found LLMs excel when provided with instructions to narrow down\ntheir focus to a specific task or section, which you can achieve by using custom prompts. Writ-\ning that you are a postdoctoral fellow applying for a career development award from the Amer-\nican Heart Association and that you would like feedback on how closely aligned your text is\nwith their mission can help the LLM make better and more appropriate comments and adjust-\nments to your text. Then, narrow down the focus of the LLM to each specific section, instead\nof dumping your entire application on the screen. You can then finish by asking it to evaluate\nif the different sections make up a coherent and cohesive story. Moreover, if you are a non-\nnative English writer, you can ask the LLM to improve grammar and spelling in your proposal\nand lessen the burden of writing in a foreign language. Finally, make use of specific prompt\nfeatures of each LLM; for example, ChatGPT allows you to use custom prompts to set rules for\nthe LLM to use in all its subsequent answers, helping you get more coherent and specific feed-\nback [22]. We include these and other ideas for specific prompts (generated by us) in Table 1\nbelow to help get you started.\nRule 5: Fact check everything\nGenerative AI models such as LLMs are known to “hallucinate”—or fabricate—facts and refer-\nences in response to prompts, given the nature of their training [11,23]. Although these models\nare steadily improving—ChatGPT 4.0 is reportedly 40% better at not hallucinating compared\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 3 / 7\nto previous versions [24]—there is still a non-negligible chance that they will produce outright\nfake information. For example, when writing this article, we asked the free and paid versions\nof ChatGPT to give us references for their best grant writing tips. The former returned a\ncompletely fake reference whose DOI resolved to a publication on C. elegans development,\nwhile the latter cited an earlier publication in PLoS Comp Bio on grant writing, but added a\nDOI to a paper on computational models of cerebellar Purkinje cells. Others have had similar\nexperiences: In several studies evaluating the ability of LLMs to provide accurate references,\nthe large majority of them were incorrect, and an alarming number were fabricated [23,25–\n27]. Following the advice in the previous rule, we suggest incorporating a statement in your\ncustom instructions similar to the following from Twitter/X user @MushtaqBilalPhD: “You\nwill respond like an academic colleague, citing claims, opinions, and figures from authentic,\npublished sources. Avoid inventing sources, and if uncertain, acknowledge so.” [28]. Nonethe-\nless, the bottom line is, always fact check, regardless of how convincing the AI writes.\nRule 6: Don’t copy-paste; use the AI-generated text as inspiration\nLLMs work by simply predicting what the next word should be. As such, they cannot inter-\npret or understand content. However, this does not stop them from sounding very convinc-\ning. Besides hallucinating fake information, AIs can and will plagiarize existing text and will\noften contain biases—e.g., racial and gender bias—due to the nature of their training data-\nsets [29,30]. On a less harmful note, LLMs tend to generate “fluff” unless specifically asked\nto be concise. For these reasons and those listed in Rules 3 and 5, you should not simply\ncopy-paste text directly from the LLM into your grant application. Instead, exercise your\ncritical thinking skills and read through the text carefully, using it as inspiration to make\nstrategic edits to your own draft (see Rule 7 below). This step-by-step approach also helps\nyou maintain control over the text and be on the lookout for potential unwanted changes to\nyour application.\nWe do note, however, that websites like ChatGPT or Google Bard do not yet support text\ncomparison (i.e., track changes) so it can be difficult to ascertain exactly what did change. One\ncurrent workaround is to use the Compare Documents feature of Word or Google Docs and\ncreate a third document to highlight the differences before and after LLM editing.\nTable 1. Large language model sample prompt text.\nTo enhance text clarity\n“As a non-native English speaker, kindly help me revise the following text for improved understandin g and clarity.\nPlease check for spelling and sentence structure errors and suggest alternative s.”\n“What suggestion s do you have to enhance the clarity of my text?”\n“Please identify any parts of my writing that may be difficult for a lay audience to understand. ”\nTo make text more compellin g\n“Please provide feedback on my writing style and how I can make it more persuasive and compelling for the grant\nreviewer.”\n“I’m trying to hook my reader with a strong introduction. Can you suggest a more captivating first sentence to draw\nthem in from the start?”\nTo improve structure and flow of text\n“I want to improve the overall structure of my Specif ic Aims. What tips do you have to structure it more effectivel y?”\nTo better align with the funding agency’s mission\n“I’m working on a postdoctora l fellowship applicati on. Can you please review my closing paragraph and suggest\nways to better align it with the American Heart Associatio n’s mission?”\nTo better align with the review criteria\n“I am applying to <<inser t fellowship name>>. Please provide me feedback on how well I am addressing this\nreview criteria: <<insert specific review criteria>> , and suggest ions for what I am missing and how I can\nimprove. ”\nhttps://d oi.org/10.1371/j ournal.pc bi.1011863. t001\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 4 / 7\nRule 7: Use this iterative process to become a better grant writer\nHumans and AIs alike learn by consuming data and iterating. After every response from the\nAI, go over each suggested change and ask yourself: Would this change strengthens my appli-\ncation? Is this phrasing really easier to understand? Was it consistent in the changes it applied\nthroughout the text, for example, by using mostly active voice instead of passive voice? In this\nway, much like the AIs, you can detect patterns in the suggestions and supervise your own\n“reinforcement learning.” By iterating back and forth with the AI, you will learn to express\nyour ideas more clearly and concisely, as well as to anticipate, respond to, and incorporate\nfeedback, all essential skills for a long-term career in science [15]. Consider other ways that\nAIs are trained—how can you leverage these techniques to improve your grant writing skills\nfurther? For example, perhaps you can develop your own “training sets” with successful exam-\nples of the grant mechanism you are targeting. In reviewing these examples, do you notice pat-\nterns in what kind of text or ideas get funded?\nRule 8: Use the AI for inspiration in developing figures\nGenerative AI tools are not restricted to text and words. Tools such as DALL-E-3 or Midjour-\nney can create images based on text prompts. For example, you can describe a particular dia-\ngram or image you have in mind and use the result as inspiration for an actual figure in your\ngrant. Alternatively, you can provide one of your own images and ask the AI how it interprets\nit, or if a specific aspect you wanted to emphasize is clear. Nonetheless, Rules 5 and 6 always\napply; much like text generators, image generators suffer from issues with plagiarism and sci-\nentific correctness. We also refer the reader back to Rule 1: if using AI to help with figure gen-\neration, ensure this is permitted by the funding agency. Finally, while most of the most\npopular image generators come at a cost, some offer free trials that are ideal for experimenting.\nRule 9: Don’t forget to interact with humans\nWhile it can be exhilarating to have a lightning-fast assistant at your fingertips, always remem-\nber that no AI is a substitute for expert human review. It remains crucial to receive feedback\nfrom real humans—your peers and/or your mentors—during the many steps of your grant\nwriting journey [31–33]. These individuals are much better equipped to pick up scientific and\ntechnical errors that otherwise might only be caught during the review process. This advice is\nespecially important for junior scientists newer to grant writing. Requesting feedback, review-\ning it carefully, and incorporating it in your draft is critical for your development as a scientist\nand in the creation of a strong and competitive proposal.\nRule 10: Play!\nThe best way to learn how to use AI for grant writing is by playing and tinkering with it. Both\nOpenAI’s ChatGPT 3.5 and Google’s Bard, perhaps the most famous among many other gen-\nerative AIs, allow you to create accounts and interact with the LLMs at no cost. Keeping in\nmind the advice in Rule 2, tinker with the prompts that you feed the AI and learn which work\nbest. Experiment using different custom prompts, asking the same question in slightly differ-\nent ways or to different chatbots. Ask questions for which you know the answer, to test the lim-\nitations of these generative models and learn how to fact check their responses. After all,\ngenerative models are here to stay and the sooner you get acquainted with their advantages\nand disadvantages, the faster you can unlock their potential to help you improve your grant\napplications and other scientific writing.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 5 / 7\nIn conclusion, we hope this article has achieved the appropriate balance of caution and\nenthusiasm. By following these 10 simple rules, you can help avoid what we worry most about\n—having your AI-generated grant administratively rejected for plagiarism or your precious\ngrant text incorporated into data training sets and suggested to your competitors asking simi-\nlar prompts in the future. On a more positive note, we believe this technology has tremendous\npotential and are eager to see it better democratize the grant writing process—providing no\n(or low) cost grant writing aids to those of us without full-time grant writers at our beck and\ncall, and helping non-native English writers overcome language barriers that are detrimental\nto equity in science [7,34].\nTo help kick-start this democratization, we have created a GitHub repository to collate and\ncurate resources on this topic—https://github.com/es eckel/ai-for-grant-writing/—and we\ninvite you to browse and contribute as you work on your next grant submission.\nAcknowledgmen ts\nThe authors are grateful to João Rodrigues and Michael Levitt for their invaluable feedback.\nAuthor Contributions\nConceptualization: Elizabeth Seckel, Brandi Y. Stephens.\nWriting – original draft: Elizabeth Seckel, Brandi Y. Stephens.\nWriting – review & editing: Elizabeth Seckel, Brandi Y. Stephens, Fatima Rodriguez.\nReferences\n1. Biever C. ChatGPT broke the Turing test—the race is on for new ways to assess AI. Nature. 2023 Jul\n25; 619(7971) :686–68 9. https://doi.or g/10.1038 /d41586-023 -02361-7 PMID: 37491395\n2. Jannai D, Meron A, Lenz B, Levine Y, Shoham Y. Human or Not? A Gamified Approac h to the Turing\nTest. ArXiv Prepr ArXiv23 0520010. 2023.\n3. Conroy G. Scientists used ChatGP T to generat e an entire paper from scratch—bu t is it any good?\nNature. 2023 Jul 7; 619(7970 ):443–444. https://doi.or g/10.103 8/d41586-02 3-02218-z PMID: 37419951\n4. Huang J, Tan M. The role of ChatGP T in scientific commu nication: writing better scientific review arti-\ncles. Am J Cancer Res. 2023; 13(4):1148 . PMID: 371683 39\n5. Stokel-W alker C. ChatGPT listed as author on research papers: many scientist s disapprov e. Nature.\n2023 Jan 18; 613(7945) :620–621. https://do i.org/10.1038 /d41586-023 -00107-z PMID: 36653617\n6. Katsnelso n A. Poor English skills? New AIs help researchers to write better. Nature. 2022 Aug 29; 609\n(7925):208 –209. https:// doi.org/10.10 38/d415 86-022-0276 7-9 PMID: 36038730\n7. Amano T, Ramı ´ rez-Castañ eda V, Berdejo-Es pinola V, Borokini I, Chowdhu ry S, Golivets M, et al. The\nmanifold costs of being a non-nativ e English speaker in science. PLoS Biol. 2023 Jul 18; 21(7):\ne3002184. https:// doi.org/10.13 71/journal.p bio.300 2184 PMID: 37463136\n8. Salvagno M, Taccone FS, Gerli AG. Can artificia l intelligence help for scientific writing? Crit Care. 2023\nFeb 25; 27(1):75. https://doi.or g/10.1186/ s13054-023- 04380-2 PMID: 3684184 0\n9. Tools such as ChatGPT threaten transparent science ; here are our ground rules for their use. Nature.\n2023 Jan 24; 613(7945) :612–612. https://do i.org/10.1038 /d41586-023 -00191-1 PMID: 36694020\n10. Gaggioli A. Ethics: disclose use of AI in scientific manuscripts. Nature. 2023 Feb 14; 614(7948) :413–\n413. https://do i.org/10.1038 /d41586-023 -00381-x PMID: 36788370\n11. Alkaissi H, McFarlane SI. Artificial hallucinations in ChatGPT : implication s in scientific writing. 2023; 15\n(Cureus, 2).\n12. Khurana D, Koli A, Khatter K, Singh S. Natural language processing : state of the art, current trends and\nchallenges . Multimed Tools Appl. 2023; 82(3):3713 –3744. https:// doi.org/10.10 07/s1104 2-022-134 28-4\nPMID: 358557 71\n13. Authors Guild Supports Nonfic tion Writers in Lawsuit Against OpenAI [Internet]. The Authors Guild.\n[cited 2024 Jan 14]. Available from: https:// authorsguild.o rg/news/a g-supports-no nfiction- writers-in-\nlawsuit-ag ainst-open ai/.\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 6 / 7\n14. Grynbaum MM, Mac R. The Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighte d Work. The\nNew York Times [Interne t]. 2023 Dec 27 [cited 2024 Jan 14]. Available from: https://www .nytimes.co m/\n2023/12/ 27/busines s/media/new -york-times- open-ai-micr osoft-lawsu it.html.\n15. Quitadam o IJ, Kurtz MJ. Learning to improve: using writing to increase critical thinking performa nce in\ngeneral education biology. CBE Life Sci Educ. 2007; 6(2):140–1 54. https://doi.or g/10.118 7/cbe.06-11 -\n0203 PMID: 175488 76\n16. Thorp HH. ChatGP T is fun, but not an author. Science. 2023 Jan 27; 379(6630) :313. https:/ /doi.org/10.\n1126/scien ce.adg78 79 PMID: 36701446\n17. Change to policy on the use of generat ive AI and large language models [Internet ]. [cited 2024 Jan 14].\nAvailable from: https://www .science.org /content/blo g-post/chan ge-polic y-use-genera tive-ai-and- large-\nlanguage-m odels.\n18. Springer Nature introduc es Curie, its AI-powere d scientific writing assista nt. Springer Nature Group |\nSpringer Nature [Interne t]. [cited 2024 Jan 14]. Available from: https:/ /group.spring ernature.c om/gp/\ngroup/me dia/press-rel eases/ai-p owered-s cientific-wri ting-assita nt-launched/26 176230.\n19. profession al.heart.org [Interne t]. [cited 2023 Jul 26]. 2024 AHA Postdoctor al Fellowship. Available from:\nhttps://profe ssional.he art.org/en /research-pr ograms/ah a-funding- opportunitie s/postdoc toral-\nfellowship.\n20. Notice to research community : Use of generative artificia l intelligence technolog y in the NSF merit\nreview process | NSF—Nationa l Science Founda tion [Internet]. 2023 [cited 2024 Jan 14]. Availab le\nfrom: https://new. nsf.gov/new s/notice-to- the-research- community -on-ai.\n21. Using AI in Peer Review Is a Breach of Confidenti ality–NIH Extramur al Nexus [Internet] . 2023 [cited\n2023 Jul 26]. Available from: https://nexus .od.nih.gov /all/2023/06/23 /using-ai-in- peer-revie w-is-a-\nbreach-of-c onfidentiality/ .\n22. Custom instruction s for ChatGPT [Internet]. [cited 2023 Jul 26]. Available from: https://opena i.com/blog/\ncustom-ins tructions-fo r-chatgpt.\n23. McGowan A, Gui Y, Dobbs M, Shuster S, Cotter M, Selloni A, et al. ChatGPT and Bard exhibit sponta-\nneous citation fabricati on during psychiatry literature search. Psychiatry Res. 2023 Aug; 326:115 334.\nhttps://doi.or g/10.101 6/j.psychres. 2023.115334 PMID: 374992 82\n24. GPT-4 [Internet] . [cited 2023 Jul 27]. Available from: https://opena i.com/res earch/gpt-4.\n25. Emsley R. ChatGPT : these are not hallucin ations–the y’re fabrications and falsification s. Schizoph renia.\n2023 Aug 19; 9(1):1–2.\n26. Athaluri SA, Manthena SV, Kesapragada VSRKM, Yarlagadd a V, Dave T, Duddum pudi RTS. Exploring\nthe Boundarie s of Reality: Investigating the Phenom enon of Artificial Intellig ence Hallucinatio n in Scien-\ntific Writing Through ChatGP T References. Cureus. 2023 Apr; 15(4):e37 432. https://doi.or g/10.775 9/\ncureus.37 432 PMID: 371820 55\n27. Bhattacha ryya M, Miller VM, Bhattachary ya D, Miller LE. High Rates of Fabricated and Inaccurate Ref-\nerences in ChatGPT-Ge nerated Medical Content. Cureus. 15(5):e392 38. https://doi.or g/10.7759/\ncureus.39 238 PMID: 373374 80\n28. Mushtaq Bilal, PhD [@MushtaqBil alPhD]. 1. Start by training to act as your research assista nt. You can\ndo this with Custom Instructions. Open ChatGPT , click on your profile photo, and select Custom Instruc-\ntions. Paste the following Custom Instructions in ChatGP T along with your relevant details and a short\nwriting. . . https://t.co/ NRyjfWc7M R [Interne t]. Twitter. 2023 [cited 2024 Jan 14]. Available from: https:/ /\ntwitter.com /MushtaqBi lalPhD/statu s/172045 0829788 856652.\n29. Straw I, Wu H. Investigating for bias in healthcar e algorithms : a sex-stratifie d analysis of supervised\nmachine learning models in liver disease predicti on. BMJ Health Care Inform. 2022 Apr 24; 29(1):\ne100457. https:// doi.org/10.11 36/bmjhci- 2021-10045 7 PMID: 354701 33\n30. Daneshjou R, Vodrahall i K, Novoa RA, Jenkins M, Liang W, Rotemberg V, et al. Disparities in dermatol -\nogy AI perform ance on a diverse, curated clinical image set. Sci Adv. 2022 Aug 12; 8(32):eabq 6147.\nhttps://doi.or g/10.112 6/sciadv.abq6 147 PMID: 35960806\n31. Sohn E. Secrets to writing a winning grant. Nature. 2020; 577(7788) :133–13 5. https://doi.or g/10.103 8/\nd41586-019 -03914-5 PMID: 318630 64\n32. Botham CM, Arribere JA, Brubaker SW, Beier KT. Ten simple rules for writing a career developme nt\naward proposa l. PLoS Comput Biol. 2017; 13(12):e10 05863. https://doi.or g/10.137 1/journal.pcbi .\n1005863 PMID: 29240828\n33. Yuan K, Cai L, Ngok SP, Ma L, Botham CM. Ten simple rules for writing a postdoctora l fellowship. PLoS\nComput Biol. 2016; 12(7):e100 4934. https://doi.or g/10.137 1/journal.pcbi .100493 4 PMID: 27415752\n34. Berdejo-E spinola V, Amano T. AI tools can improve equity in science. Science. 2023 Mar 10; 379\n(6636):991 –991. https:// doi.org/10.11 26/science .adg9714 PMID: 3689324 8\nPLOS COMP UTATIONAL  BIOLOGY\nPLOS Computationa l Biology | https:/ /doi.org/10.13 71/journal.p cbi.1011863 March 1, 2024 7 / 7",
  "topic": "Leverage (statistics)",
  "concepts": [
    {
      "name": "Leverage (statistics)",
      "score": 0.8216410875320435
    },
    {
      "name": "Simple (philosophy)",
      "score": 0.7063259482383728
    },
    {
      "name": "Computer science",
      "score": 0.4844939410686493
    },
    {
      "name": "Business",
      "score": 0.3281090259552002
    },
    {
      "name": "Data science",
      "score": 0.32246845960617065
    },
    {
      "name": "Artificial intelligence",
      "score": 0.17931756377220154
    },
    {
      "name": "Epistemology",
      "score": 0.07301923632621765
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ]
}