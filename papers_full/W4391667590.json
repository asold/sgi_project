{
  "title": "Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy",
  "url": "https://openalex.org/W4391667590",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2947226727",
      "name": "Efe Bozkir",
      "affiliations": [
        "Technical University of Munich",
        "University of Tübingen"
      ]
    },
    {
      "id": "https://openalex.org/A2954765235",
      "name": "Suleyman Ozdel",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A5054852235",
      "name": "Ka Hei Carrie Lau",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2096829243",
      "name": "Wang Mengdi",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A2098714404",
      "name": "Hong Gao",
      "affiliations": [
        "Technical University of Munich"
      ]
    },
    {
      "id": "https://openalex.org/A1926909824",
      "name": "Enkelejda Kasneci",
      "affiliations": [
        "Technical University of Munich"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3120112715",
    "https://openalex.org/W4389256419",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W2133860960",
    "https://openalex.org/W4386080721",
    "https://openalex.org/W4220671882",
    "https://openalex.org/W2967996127",
    "https://openalex.org/W3007364799",
    "https://openalex.org/W3162947752",
    "https://openalex.org/W4378508626",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3127185310",
    "https://openalex.org/W3212411258",
    "https://openalex.org/W2127681657",
    "https://openalex.org/W3130230035",
    "https://openalex.org/W2015504626",
    "https://openalex.org/W4387221840",
    "https://openalex.org/W2107643854",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W2207474706",
    "https://openalex.org/W4385522451",
    "https://openalex.org/W3125061134",
    "https://openalex.org/W4389296503",
    "https://openalex.org/W4309505466",
    "https://openalex.org/W4308346809",
    "https://openalex.org/W4364361752",
    "https://openalex.org/W4399144550",
    "https://openalex.org/W3197722859",
    "https://openalex.org/W4224279826",
    "https://openalex.org/W3162134105",
    "https://openalex.org/W3199166097",
    "https://openalex.org/W4324299451",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W1971007088",
    "https://openalex.org/W2604471723",
    "https://openalex.org/W3012028083",
    "https://openalex.org/W2794966952",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4396833730",
    "https://openalex.org/W4361020491",
    "https://openalex.org/W2004687611",
    "https://openalex.org/W4234833891",
    "https://openalex.org/W2996683616",
    "https://openalex.org/W3034854287",
    "https://openalex.org/W4388585319",
    "https://openalex.org/W4387801411",
    "https://openalex.org/W4389713789",
    "https://openalex.org/W4319837288",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W4205646675",
    "https://openalex.org/W3006405772",
    "https://openalex.org/W4378105483",
    "https://openalex.org/W1963673608",
    "https://openalex.org/W2781762021",
    "https://openalex.org/W2611455491",
    "https://openalex.org/W3025478288",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4387355380",
    "https://openalex.org/W4387993511",
    "https://openalex.org/W4386977975",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4389300776",
    "https://openalex.org/W4297659111",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W4386755313",
    "https://openalex.org/W3128334038",
    "https://openalex.org/W4388994355",
    "https://openalex.org/W4396832466"
  ],
  "abstract": "Advances in artificial intelligence and human-computer interaction will\\nlikely lead to extended reality (XR) becoming pervasive. While XR can provide\\nusers with interactive, engaging, and immersive experiences, non-player\\ncharacters are often utilized in pre-scripted and conventional ways. This paper\\nargues for using large language models (LLMs) in XR by embedding them in\\navatars or as narratives to facilitate inclusion through prompt engineering and\\nfine-tuning the LLMs. We argue that this inclusion will promote diversity for\\nXR use. Furthermore, the versatile conversational capabilities of LLMs will\\nlikely increase engagement in XR, helping XR become ubiquitous. Lastly, we\\nspeculate that combining the information provided to LLM-powered spaces by\\nusers and the biometric data obtained might lead to novel privacy invasions.\\nWhile exploring potential privacy breaches, examining user privacy concerns and\\npreferences is also essential. Therefore, despite challenges, LLM-powered XR is\\na promising area with several opportunities.\\n",
  "full_text": "Embedding Large Language Models into Extended Reality:\nOpportunities and Challenges for Inclusion, Engagement, and\nPrivacy\nEfe Bozkir\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\nefe.bozkir@tum.de\nHuman-Computer Interaction\nUniversity of Tübingen\nTübingen, Germany\nefe.bozkir@uni-tuebingen.de\nSüleyman Özdel\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\nozdelsuleyman@tum.de\nKa Hei Carrie Lau\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\ncarrie.lau@tum.de\nMengdi Wang\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\nmengdi.wang@tum.de\nHong Gao\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\nhong.gao@tum.de\nEnkelejda Kasneci\nHuman-Centered Technologies for\nLearning\nTechnical University of Munich\nMunich, Germany\nenkelejda.kasneci@tum.de\nABSTRACT\nAdvances in artificial intelligence and human-computer interaction\nwill likely lead to extended reality (XR) becoming pervasive. While\nXR can provide users with interactive, engaging, and immersive\nexperiences, non-player characters are often utilized in pre-scripted\nand conventional ways. This paper argues for using large language\nmodels (LLMs) in XR by embedding them in avatars or as narratives\nto facilitate inclusion through prompt engineering and fine-tuning\nthe LLMs. We argue that this inclusion will promote diversity for\nXR use. Furthermore, the versatile conversational capabilities of\nLLMs will likely increase engagement in XR, helping XR become\nubiquitous. Lastly, we speculate that combining the information\nprovided to LLM-powered spaces by users and the biometric data\nobtained might lead to novel privacy invasions. While exploring\npotential privacy breaches, examining user privacy concerns and\npreferences is also essential. Therefore, despite challenges, LLM-\npowered XR is a promising area with several opportunities.\nCCS CONCEPTS\n• Computing methodologies →Virtual reality; Mixed / aug-\nmented reality ; Artificial intelligence ; Natural language pro-\ncessing; • Human-centered computing →Human computer in-\nteraction (HCI) .\nCUI ’24, July 8–10, 2024, Luxembourg, Luxembourg\n© 2024 Copyright held by the owner/author(s).\nThis is the author’s version of the work. It is posted here for your personal use. Not for\nredistribution. The definitive Version of Record was published in ACM Conversational\nUser Interfaces 2024 (CUI ’24), July 8–10, 2024, Luxembourg, Luxembourg , https://doi.\norg/10.1145/3640794.3665563.\nKEYWORDS\nextended reality, virtual reality, augmented reality, large language\nmodels, artificial intelligence, generative AI, ChatGPT, inclusion,\nengagement, privacy\nACM Reference Format:\nEfe Bozkir, Süleyman Özdel, Ka Hei Carrie Lau, Mengdi Wang, Hong Gao,\nand Enkelejda Kasneci. 2024. Embedding Large Language Models into Ex-\ntended Reality: Opportunities and Challenges for Inclusion, Engagement,\nand Privacy. In ACM Conversational User Interfaces 2024 (CUI ’24), July\n8–10, 2024, Luxembourg, Luxembourg. ACM, New York, NY, USA, 7 pages.\nhttps://doi.org/10.1145/3640794.3665563\n1 INTRODUCTION\nWith research and development in computer graphics, artificial\nintelligence (AI), and human-computer interaction fields, virtual,\nmixed, and augmented reality (VR/MR/AR) and head-mounted dis-\nplays (HMDs) have started to become pervasive in everyday life.\nEspecially with big tech companies like Apple and Meta bringing\ntheir HMDs into the market for vast use (e.g., Apple Vision Pro,\nMeta Quest 3), it is likely that HMDs will soon become similar to to-\nday’s smartphones, smartwatches, or tablets. Yet, with HMDs, users\noften experience highly immersive virtual scenes, making their\ninteraction and societal aspects different from the other devices.\nExtended reality, covering the wide spectrum of VR, AR, and MR,\nhas been used for different purposes in various domains, such as\neducation [9, 23, 30], medicine [31, 59, 78], entertainment [4, 33, 37],\ntransportation [7, 14, 45], and business [1, 27, 46]. One of the ad-\nvantages of XR and HMDs, especially in understanding human be-\nhaviors and interactions, is the possibility of obtaining fine-grained\nmotion sensor data, such as eye- and head-tracking [44], possibly\nwith controlled stimuli [6]. This allows a better understanding of\narXiv:2402.03907v2  [cs.HC]  20 Jun 2024\nCUI ’24, July 8–10, 2024, Luxembourg, Luxembourg Bozkir, et al.\nhow humans behave and perceive in XR and provides an oppor-\ntunity for real-time and adaptive user support. Combining such\nreal-time and adaptive interaction experiences with high presence,\nimmersion, and sociality levels might lead to positive user experi-\nences, motivating users to use XR and HMDs frequently.\nDespite several advantages, one of the issues in terms of sociality\nwith virtual and mixed spaces that include non-player characters\n(NPCs), even those powered by AI and machine learning, is the lim-\nited conversational capabilities of the characters. These characters\nare often designed as pre-programmed agents [25] or trained for\nparticular use with relevant training data [36]. However, these can-\nnot be utilized flexibly for open-ended conversations or open-world\nsettings. Furthermore, when the audience changes (e.g., adults to\nchildren), conversational scripts or trained models must be updated\nalmost from scratch, requiring significant human labor to create\nscripts or label training data.\nEmbedding large language models (LLMs) as chat agents into\nXR spaces can significantly solve these issues and help these spaces\nprovide more inclusive and engaging experiences. LLMs are trained\nwith a good portion of the Internet and fed with a diverse set of\ntext data hence, they can converse about various topics. In addition,\nthe possibility of fine-tuning such models with use-case-specific\nsmall datasets and prompt engineering helps them be utilized for\na broader range of tasks. Especially with ChatGPT being publicly\nintroduced in 2022 [50], a wide audience has also observed how\npowerful LLMs are and the human-like text they can generate.\nPossibilities and opportunities have been emphasized for different\ndomains, such as education [35] and medicine [65]. However, they\nhave not been addressed and studied in depth for XR yet, except\nfrom few works mentioning their potential as conversation agents\nin XR [2, 67, 72] or demonstrating their abilities to produce and\nedit objects, and scenes in MR [68]. One of the reasons might be the\nuncommon use of textual interaction in XR compared to auditory\nand visual.\nDespite the higher likelihood of auditory and visual informa-\ntion use in XR than text, it is trivial to build automated processing\npipelines, with speech-to-text [60], large language [69], and text-\nto-speech [60] models, to process audio data through LLMs for XR.\nAdditionally, with the emergence of multimodal LLMs, such as GPT-\n4 [53] and Gemini [28], the use of LLMs within XR spaces to facili-\ntate conversations will be more intuitive than pre-programming the\navatars or using conventional AI techniques. Therefore, this paper\nargues for embedding LLMs in XR as virtual avatars or narratives.\nThis process will promote more inclusive, diverse, and engaging\nexperiences with three main implications, as in the following.\n•We first argue that embedding LLMs into XR as NPCs or\nnarratives with different prompting strategies and model\nfine-tuning will support designing more inclusive settings.\nThis will also support diversity and equity in XR.\n•We state that with the multifaceted conversational abilities\nof LLMs, LLM-powered spaces will facilitate more engaging\nXR experiences for users, a step towards pervasive XR.\n•Increased engagement with NPCs and XR likely means that\nusers will provide more information about themselves. We\nstate that combining this information with the biometric sen-\nsor data from XR will cause novel privacy invasions. These\npossible invasions should be investigated, along with user\nprivacy concerns, to enable user-centered XR spaces.\n2 RELATED WORKS\nAs we argue for using LLMs in XR by embedding them into NPCs\nor treating them as narratives to facilitate inclusion, diversity, and\nengagement by taking ethical aspects, especially privacy, into ac-\ncount, we summarize previous literature in two folds. We first\ndiscuss the recent works on LLMs in Section 2.1. Then, we provide\nprevious literature on inclusion, diversity, equity, and privacy in\nXR in Section 2.2.\n2.1 Large Language Models\nLarge language models are specific types of artificial neural net-\nworks trained with massive amounts of data, usually by scrap-\nping a significant portion of the Internet, and they can generate\nhuman-like text and facilitate natural conversations [35]. One of\nthe reasons that LLMs are successful in natural language processing\n(NLP) tasks is the transformer architecture and the self-attention\nmechanism [71]. Particularly, a transformer is a self-supervised\nencoder-decoder model, and the self-attention mechanism assumes\nthat some words are more related to each other than others and\noperates according to this assumption to find the relationships. Due\nto massive amounts of training data and these methods, LLMs can\noperate in various tasks very well, especially for tasks whose data\nis widely available online.\nPrevalent examples of LLMs are OpenAI’s GPT-3 [20], Meta’s\nLLaMa [69], Google’s PaLM [3, 12], and more recently multimodal\nLLMs such as GPT-4 [53] and DeepMind’s Gemini [28]. In addition\nto these general-purpose pre-trained LLMs, to facilitate chat sce-\nnarios, researchers further iterated the LLMs to achieve naturalistic\ninteractions by fine-tuning them to align them in the conversa-\ntions [70]. Different techniques also exist for facilitating this with\nother steps, such as aligning language models to follow instruc-\ntions [55]. Yet, fine-tuning these models with high-quality labels is\noften necessary to facilitate specific uses and personalization.\nSeveral works fine-tuned pre-trained LLMs for particular pur-\nposes, including software bug fixing [34], dialogue summarization\nin customer services [79], understanding patients’ needs and provid-\ning informed advice [42], and legal knowledge understanding [18].\nThese works showed evidence that fine-tuned models enhance task\nperformance, hinting at better personalization. Apart from fine-\ntuning, it is also known that different prompting techniques can\nsignificantly help in getting more tailored responses, even without\nfine-tuning [5, 54, 74, 76]. It is also possible to create LLM-based\nmechanisms that access external knowledge sources [40], which can\nfacilitate adaptive solutions. While the users can partially carry out\nthese methods, automating these processes based on the user char-\nacteristics in the backend is essential for LLM use in XR. Apart from\nthe scientific literature, OpenAI launching a GPT app store [ 75]\nand smart NPCs powered by OpenAI or users’ language models\nbeing integrated into Unreal Engine [56] are other examples that\nLLMs can be utilized in XR. Yet, despite the opportunities, several\nchallenges exist to facilitating useful processes.\nEmbedding Large Language Models into Extended Reality CUI ’24, July 8–10, 2024, Luxembourg, Luxembourg\n2.2 Inclusion, Diversity, Equity, and Privacy in\nXR\nInclusion means providing equal opportunities to benefits and re-\nsources regardless of individual differences such as ethnicity, gender,\nhealth, or sexual orientation. Facilitating inclusion often promotes\ndiversity and equality. There have been different focus points re-\ngarding inclusion and diversity in XR research. For instance, Peck et\nal. [58] found that recent XR research includes significantly under-\nrepresented women as authors and experiment participants. Later,\nPeck et al. [57] highlighted differences between underrepresented\ngroups compared to commonly studied populations regarding us-\nability and depicted the lack of generalizability of previous VR\nresearch. While engaging the underrepresented populations in XR\nresearch and conducting studies with representative samples differ\nfrom supporting populations according to individual needs in XR,\nthe latter is needed to personalize the XR experiences and attract\nunderrepresented populations to XR. With this aim, Ajri et al. [2]\nbuilt a VR-based tool that leverages LLMs for interview preparation\nfor underrepresented individuals. With their versatile nature, fine-\ntuning opportunities, and different prompting techniques, LLMs\ncan provide a good step to achieve this goal.\nTo support diverse user populations, it is essential to understand\nthe differences between user groups in XR, especially in how they\nperceive and behave in XR. To this end, researchers analyzed dif-\nferent user characteristics such as gender [26, 63], health [16, 62],\nexpertise [24, 32], sexual orientation [21, 61], and race [17, 64]. For\ninstance, Gao et al. [26] found with explainable machine learning\nthat girls and boys visually behave differently when they attend\na lesson in VR. Furthermore, Hosp et al. [ 32] could distinguish\ndifferent goalkeeper expertise levels in the VR context using eye\nmovements.\nRegarding health-related scenarios, the usability and acceptabil-\nity of smartglasses have been assessed with children with autism\nspectrum disorder (ASD) and their caregivers [62]. While the au-\nthors found that their audience found the smartglasses acceptable\nand usable, the reason the study was conducted in the first place is\nthat people with ASD often have issues with social communication\nand interaction, leading to different ways of learning, moving, or\npaying attention [11]. Similar trends were found in race and sex\nresearch as well, with humans remembering faces of their race\nbetter than the other faces [17], and visual behaviors being repre-\nsentative of sexual preferences [21]. While sensor data revealing\ndifferent user characteristics are not only limited to XR [17, 21] and\naforementioned user attributes [38, 43], previous research indicates\nthat there is no one-size-fits-all approach for personalizing the 3D\nuser interfaces and creating adaptive support for the users consid-\nering the distinct behaviors. Customizing LLMs with fine-tuning\nand prompt engineering can facilitate efficient support for different\nuser populations and profiles. Recent work in the context of AR\nand LLMs [29] also emphasized the potential of personalization\nwith LLMs for language learning.\nStudying different populations and providing personalized expe-\nriences might lead to accurately identifying users, especially with\nmachine learning techniques. This identification is convenient for\nsupporting the utility of adaptive interfaces; however, it can also\nbe considered a privacy invasion. To address this, a good chunk\nof research focused on protecting privacy, especially considering\nbiometric sensor data, such as eye movements [6, 10], with statisti-\ncal notions such as differential privacy [8] and empirical ways of\nstreaming the sensor data [13]. Other research investigated going\nincognito in VR by leveraging differential privacy [ 49] and deep\nmotion masking that facilitates real-time anonymization [48] and\nshowed that practical privacy-utility trade-offs are possible.\nBeyond the technical approaches focusing on the conundrum\nbetween privacy and utility, it is equally vital to understand the\nprivacy behaviors of users so that human-centered solutions can\nbe designed. Focusing on user privacy concerns about AR glasses,\nGallardo et al. [22] found that when different data types and uses\nare considered, user privacy attitudes and reservations are context-\ndependent. Denning et al. [15] studied user privacy perspectives\nfor AR and indicated participants’ requests to be asked before being\nrecorded. Lebeck et al. [39] showed that bystander privacy is an\nimportant concern in a multi-user AR. More recently, O’Hagan\net al. [52] stated the importance of user activity and its relation\nwith bystanders in everyday AR. Considering the research on the\ntechnical solutions and usable privacy in XR, it is an open question\nwhether utilizing LLMs with user sensor data in XR will lead to\nnovel privacy leaks and how users’ privacy attitudes will be in\nthese situations. The research community has very recently started\nto emphasize the importance of the need for research on human\naspects of privacy issues of LLMs, such as understanding users’\nmental models and preferences for privacy controls [41]. The same\nneed also exists when LLMs are embedded into XR in immersive\nsettings.\n3 OPPORTUNITIES, RESEARCH DIRECTIONS,\nAND CHALLENGES\nLarge language models, with their versatile conversation capabili-\nties, fine-tuning possibilities, and prompting techniques, hold an\nimmense upside for XR, particularly if such models are utilized\nas NPCs or narratives. However, not much research has been con-\nducted to this end. In the very naive scenario, to integrate LLMs\nin XR, it is essential to utilize speech-to-text and text-to-speech\nmodels [60] to enable information transition from the user to LLM-\npowered NPCs and vice versa in an auditory way. Figure 1 depicts\nan example processing pipeline. While there might be some draw-\nbacks to such a pipeline, like latency issues if online services are\nused for obtaining the responses from LLMs or the requirement of\na significant amount of storage in case LLMs are deployed locally\nwithin the XR spaces as they can easily occupy several hundreds\nof gigabytes, these issues can be solved by good engineering prac-\ntices and deploying customized models on a shared location com-\nmunicated efficiently via web services. Furthermore, multimodal\nLLMs [28, 53] might utilize such a pipeline end-to-end, mitigating is-\nsues like latency. Therefore, considering these issues can be handled\ncommendably, we argue that using LLMs will facilitate inclusion\nin XR and promote more diverse, equal, and engaging XR spaces.\nHowever, we also state that having more inclusive and engaging\nspaces will lead users to spend more time in XR spaces. As a result,\nmore data and likely more sensitive information will be available\nduring the interaction experience. While more research is needed\nto validate this, we foresee that such an amount of data combined\nCUI ’24, July 8–10, 2024, Luxembourg, Luxembourg Bozkir, et al.\nFigure 1: An example of a possible data processing pipeline.\nwith the already available sensory data from XR (e.g., eye- and\nhand-tracking) will lead to novel privacy invasions. Considering\nall, we provide three sets of opportunities and challenges, including\nseveral research opportunities. However, each of those should be\nevaluated cautiously, and the arguments need to be verified with\nuser studies and empirical data.\nInclusion, diversity, and equity: We argue that pre-scripted\nand conventional NPCs require a lot of manual labor to serve dif-\nferent user characteristics in XR. For instance, in a skill training\nscenario, a novice and an expert will have different needs when\ncommunicating with an NPC. Conventionally, two scripts or AI\nagents must be created to support these two users. Still, such agents\nmight be perceived as fictitious regarding their knowledge or the\noverall conversation quality due to rule-based conversation gen-\neration or agents trained with small datasets for particular uses.\nIn contrast, even the pre-trained LLMs without fine-tuning can\nprovide personalized experiences to users if they are prompted for\nspecific uses [54], such as “When I ask for help, provide a response\nconsidering I am an [expert/novice] in XR. ” With fine-tuning, LLMs\ncan even provide more adaptive responses, and we argue that such\nLLM-powered XR spaces will be more inclusive by motivating and\nattracting diverse types of users. Additionally, as any user char-\nacteristics can be supported in a personalized manner with LLMs,\nthis will facilitate equal opportunities for users.\nTherefore, the major research direction concerns how differ-\nent user characteristics perceive the LLM-powered XR spaces and\nwhether such spaces can motivate users with different character-\nistics comparably and facilitate diversity and equality. However,\nLLMs can also hallucinate [77], and it is a challenge to mitigate the\neffects of hallucinations.\nUser engagement: We think that LLM-powered XR spaces\nthrough NPCs or narratives will engage users more than conven-\ntional conversational agents due to LLMs’ abilities to create human-\nlike responses. As a result, the overall immersion and interactivity\nwithin the XR spaces will be enhanced. Consequently, these en-\nhancements will likely captivate users’ attention and encourage\nthem to spend more time within XR spaces. The rich and dynamic\nnarratives and realistic interactions facilitated by LLMs would ele-\nvate the engagement value of XR and open up new ways for creative\nstorytelling and interaction, transforming how users perceive and\nbehave in XR spaces.\nThe major research direction concerning user engagement is\nunderstanding whether LLM-powered spaces can significantly in-\ncrease user engagement compared to conventional XR. When this\nis the case, users likely provide more information about themselves\nduring their conversations with the NPCs in XR. This might include\nmore sensitive information about themselves, leading to ethical\nchallenges regarding data privacy.\nPrivacy: We hypothesize that LLM-powered XR will engage\nusers more, and the users will provide more information about\nthemselves, including the sensitive ones, due to the increased en-\ngagement and interaction time. As a result, we expect that such\nsensitive information obtained during the interaction combined\nwith other sensor data will likely end up with novel privacy in-\nvasions about users. It is already known that LLMs have several\nprivacy issues [51, 66], and a more in-depth investigation should be\ncarried out, as in our case, XR will combine data from LLM interac-\ntion and multimodal sensor data. Furthermore, we argue that such\nprivacy invasions should be addressed by also asking users about\ntheir privacy concerns and preferences as it has been done in other\ndomains [19, 22, 47] by observing whether or not there is a gap\nbetween privacy expectations and behaviors [73]. Very recent work\nalso emphasized the usable privacy aspects of conversational agents\nthat are powered by LLMs, and the authors stated that human-like\ninteractions encourage more privacy-sensitive disclosures [80], as\nwe also argue. However, previous research has not considered the\nXR aspect, and to this end, a greater number of empirical evalua-\ntions are needed to validate privacy-related issues. Therefore, such\naspects form opportunities, especially for designing privacy-aware\nand user-centric XR spaces.\nTherefore, the research direction we identified under the privacy\nand ethics umbrella concerns understanding whether novel privacy\ninvasions and leaks occur in these novel spaces, understanding\nusers’ general privacy attitudes, and designing privacy-enhancing\nmethods when the former is the case. However, since the LLM\nresearch is moving very fast compared to others, some aspects\nmight need to be evaluated in a longitudinal manner, which is a\nchallenge.\n4 CONCLUSION\nThis paper argues for embedding LLMs as NPCs or narratives into\nXR. We state that due to the versatile conversational capabilities of\nLLMs, as they are trained with a massive amount of text data from\nthe Internet, prompting techniques, and fine-tuning possibilities,\nLLM-powered NPCs and narratives will provide significantly im-\nproved personalized experiences in XR, regardless of different user\ncharacteristics. We argue that these will enhance the motivation to\nuse XR more frequently in an engaged way and facilitate inclusion,\nleading to more diverse populations using XR. Furthermore, as such\npersonalization can support any user type, LLM-powered XR spaces\nwill also promote equity. Lastly, we underline the importance of\nprivacy and claim that possible novel privacy invasions and users’\nprivacy attitudes should be investigated.\nREFERENCES\n[1] Karim Rejeb Abderahman Rejeb and John G. Keogh. 2021. Enablers of Augmented\nReality in the Food Supply Chain: A Systematic Literature Review. Journal of\nEmbedding Large Language Models into Extended Reality CUI ’24, July 8–10, 2024, Luxembourg, Luxembourg\nFoodservice Business Research 24, 4 (2021), 415–444. https://doi.org/10.1080/\n15378020.2020.1859973\n[2] Siddhanth Jayaraj Ajri, Dat Nguyen, Swati Agarwal, Arun Kumar Reddy Padala,\nand Caglar Yildirim. 2023. Virtual AIVantage: Leveraging Large Language Models\nfor Enhanced VR Interview Preparation among Underrepresented Professionals\nin Computing. In Proceedings of the 22nd International Conference on Mobile and\nUbiquitous Multimedia . ACM, 535–537. https://doi.org/10.1145/3626705.3631799\n[3] Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin,\nAlexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,\nEric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-\nHellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Se-\nbastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Her-\nnandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James\nBradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin\nCherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy,\nShachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan\nDu, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Fre-\nitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven\nHand, Hadi Hashemi, Le Hou, Joshua Howland, Andrea Hu, Jeffrey Hui, Jeremy\nHurwitz, Michael Isard, Abe Ittycheriah, Matthew Jagielski, Wenhao Jia, Kath-\nleen Kenealy, Maxim Krikun, Sneha Kudugunta, Chang Lan, Katherine Lee,\nBenjamin Lee, Eric Li, Music Li, Wei Li, YaGuang Li, Jian Li, Hyeontaek Lim,\nHanzhao Lin, Zhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma Mahen-\ndru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado, John\nNham, Eric Ni, Andrew Nystrom, Alicia Parrish, Marie Pellat, Martin Polacek,\nAlex Polozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan Richter, Parker Riley,\nAlex Castro Ros, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Renee Shelby,\nAmbrose Slone, Daniel Smilkov, David R. So, Daniel Sohn, Simon Tokumine,\nDasha Valter, Vijay Vasudevan, Kiran Vodrahalli, Xuezhi Wang, Pidong Wang,\nZirui Wang, Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan Xu, Linting\nXue, Pengcheng Yin, Jiahui Yu, Qiao Zhang, Steven Zheng, Ce Zheng, Weikang\nZhou, Denny Zhou, Slav Petrov, and Yonghui Wu. 2023. PaLM 2 Technical Report.\nhttps://doi.org/10.48550/arXiv.2305.10403\n[4] Joseph Bates. 1992. Virtual Reality, Art, and Entertainment.Presence: Teleoperators\nand Virtual Environments 1, 1 (1992), 133–138. https://doi.org/10.1162/pres.1992.\n1.1.133\n[5] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi,\nJoanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski,\nPiotr Nyczyk, and Torsten Hoefler. 2023. Graph of Thoughts: Solving Elaborate\nProblems with Large Language Models. https://doi.org/10.48550/arXiv.2308.\n09687 Proceedings of the AAAI Conference on Artificial Intelligence 2024.\n[6] Efe Bozkir. 2022. Towards Everyday Virtual Reality through Eye Tracking. https:\n//doi.org/10.48550/arXiv.2203.15703 University of Tübingen.\n[7] Efe Bozkir, David Geisler, and Enkelejda Kasneci. 2019. Person Independent,\nPrivacy Preserving, and Real Time Assessment of Cognitive Load using Eye\nTracking in a Virtual Reality Setup. In 2019 IEEE Conference on Virtual Reality\nand 3D User Interfaces (VR) . 1834–1837. https://doi.org/10.1109/VR.2019.8797758\n[8] Efe Bozkir, Onur Günlü, Wolfgang Fuhl, Rafael F. Schaefer, and Enkelejda Kasneci.\n2021. Differential privacy for eye tracking with temporal correlations. PLOS ONE\n16, 8 (2021), 1–22. https://doi.org/10.1371/journal.pone.0255979\n[9] Efe Bozkir, Philipp Stark, Hong Gao, Lisa Hasenbein, Jens-Uwe Hahn, Enkelejda\nKasneci, and Richard Göllner. 2021. Exploiting Object-of-Interest Information\nto Understand Attention in VR Classrooms. In 2021 IEEE Virtual Reality and 3D\nUser Interfaces (VR) . 597–605. https://doi.org/10.1109/VR50410.2021.00085\n[10] Efe Bozkir, Süleyman Özdel, Mengdi Wang, Brendan David-John, Hong Gao,\nKevin Butler, Eakta Jain, and Enkelejda Kasneci. 2023. Eye-tracked Virtual\nReality: A Comprehensive Survey on Methods and Privacy Challenges. https:\n//doi.org/10.48550/arXiv.2305.14080\n[11] Centers for Disease Control and Prevention. Last accessed 11/01/2024. Signs and\nSymptoms of Autism Spectrum Disorder. https://www.cdc.gov/ncbddd/autism/\nsigns.html.\n[12] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav\nMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez,\nAbhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran,\nEmily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin,\nMichael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay\nGhemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin\nRobinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek\nLim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani\nAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana\nPillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr\nPolozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz,\nOrhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck,\nJeff Dean, Slav Petrov, and Noah Fiedel. 2022. PaLM: Scaling Language Modeling\nwith Pathways. https://doi.org/10.48550/arXiv.2204.02311\n[13] Brendan David-John, Diane Hosfelt, Kevin Butler, and Eakta Jain. 2021. A\nprivacy-preserving approach to streaming eye-tracking data. IEEE Transac-\ntions on Visualization and Computer Graphics 27, 5 (2021), 2555–2565. https:\n//doi.org/10.1109/TVCG.2021.3067787\n[14] Nayara de Oliveira Faria, Coleman Merenda, Richard Greatbatch, Kyle Tanous,\nChihiro Suga, Kumar Akash, Teruhisa Misu, and Joseph Gabbard. 2021. The Effect\nof Augmented Reality Cues on Glance Behavior and Driver-Initiated Takeover\non SAE Level 2 Automated-Driving. Proceedings of the Human Factors and\nErgonomics Society Annual Meeting 65, 1 (2021), 1342–1346. https://doi.org/10.\n1177/1071181321651004\n[15] Tamara Denning, Zakariya Dehlawi, and Tadayoshi Kohno. 2014. In Situ with\nBystanders of Augmented Reality Glasses: Perspectives on Recording and Privacy-\nMediating Technologies. In Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems . ACM, 2377–2386. https://doi.org/10.1145/2556288.\n2557352\n[16] Paul M. G. Emmelkamp and Katharina Meyerbröker. 2021. Virtual Reality Therapy\nin Mental Health. Annual Review of Clinical Psychology 17, 1 (2021), 495–519.\nhttps://doi.org/10.1146/annurev-clinpsy-081219-115923\n[17] Bruno Laeng Esther Xiu Wen Wu and Svein Magnussen. 2012. Through the eyes of\nthe own-race bias: Eye-tracking and pupillometry during face recognition. Social\nNeuroscience 7, 2 (2012), 202–216. https://doi.org/10.1080/17470919.2011.596946\n[18] Zhiwei Fei, Xiaoyu Shen, Dawei Zhu, Fengzhe Zhou, Zhuo Han, Songyang Zhang,\nKai Chen, Zongwen Shen, and Jidong Ge. 2023. LawBench: Benchmarking Legal\nKnowledge of Large Language Models. https://doi.org/10.48550/arXiv.2309.16289\n[19] Adrienne Porter Felt, Serge Egelman, and David Wagner. 2012. I’ve Got 99\nProblems, but Vibration Ain’t One: A Survey of Smartphone Users’ Concerns. In\nProceedings of the Second ACM Workshop on Security and Privacy in Smartphones\nand Mobile Devices . ACM, 33–44. https://doi.org/10.1145/2381934.2381943\n[20] Luciano Floridi and Massimo Chiriatti. 2020. GPT-3: Its Nature, Scope, Limits,\nand Consequences. Minds and Machines 30, 4 (2020), 681–694. https://doi.org/\n10.1007/s11023-020-09548-1\n[21] Peer Briken Frederike Wenzlaff and Arne Dekker. 2016. Video-Based Eye Tracking\nin Sex Research: A Systematic Literature Review. The Journal of Sex Research 53,\n8 (2016), 1008–1019. https://doi.org/10.1080/00224499.2015.1107524\n[22] Andrea Gallardo, Christopher Choy, Jaideep Juneja, Efe Bozkir, Camille Cobb,\nLujo Bauer, and Lorrie Faith Cranor. 2023. Speculative privacy attitudes and\nconcerns about AR glasses data collection. Proceedings on Privacy Enhancing\nTechnologies 2023, 4 (2023). https://doi.org/10.56553/popets-2023-0117\n[23] Hong Gao, Efe Bozkir, Lisa Hasenbein, Jens-Uwe Hahn, Richard Göllner, and\nEnkelejda Kasneci. 2021. Digital Transformations of Classrooms in Virtual Reality.\nIn Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems .\nACM. https://doi.org/10.1145/3411764.3445596\n[24] Hong Gao, Efe Bozkir, Philipp Stark, Patricia Goldberg, Gerrit Meixner, Enkelejda\nKasneci, and Richard Göllner. 2023. Detecting Teacher Expertise in an Immersive\nVR Classroom: Leveraging Fused Sensor Data with Explainable Machine Learning\nModels. In 2023 IEEE International Symposium on Mixed and Augmented Reality\n(ISMAR). 683–692. https://doi.org/10.1109/ISMAR59233.2023.00083\n[25] Hong Gao, Lisa Hasenbein, Efe Bozkir, Richard Göllner, and Enkelejda Kasneci.\n2022. Evaluating the Effects of Virtual Human Animation on Students in an\nImmersive VR Classroom Using Eye Movements. In Proceedings of the 28th ACM\nSymposium on Virtual Reality Software and Technology . ACM. https://doi.org/10.\n1145/3562939.3565623\n[26] Hong Gao, Lisa Hasenbein, Efe Bozkir, Richard Göllner, and Enkelejda Kasneci.\n2023. Exploring Gender Differences in Computational Thinking Learning in a VR\nClassroom: Developing Machine Learning Models Using Eye-Tracking Data and\nExplaining the Models. International Journal of Artificial Intelligence in Education\n33, 4 (2023), 929–954. https://doi.org/10.1007/s40593-022-00316-z\n[27] Cristina Gil-López, Jaime Guixeres, Javier Marín-Morales, Carmen Torrecilla, Edu\nWilliams, and Mariano Alcañiz. 2023. Is mixed reality technology an effective\ntool for retail? A vividness and interaction perspective.Frontiers in Virtual Reality\n4 (2023). https://doi.org/10.3389/frvir.2023.1067932\n[28] Google DeepMind. Last accessed 22/05/2024. Gemini Models. https://deepmind.\ngoogle/technologies/gemini/.\n[29] Shirin Hajahmadi, Luca Clementi, Marıa Dolores Jiménez López, and Gustavo\nMarfia. 2024. ARELE-bot: Inclusive Learning of Spanish as a Foreign Language\nThrough a Mobile App Integrating Augmented Reality and ChatGPT. IEEE\nConference Virtual Reality and 3D User Interfaces (VR) Workshops. http://www.\nleelisle.com/wp-content/uploads/2024/03/ARELE-bot.pdf.\n[30] Aleshia Taylor Hayes, Tetyana Kucher Dhimolea, Nanxi Meng, and Geneva Tesh.\n2021. Levels of Immersion for Language Learning from 2D to Highly Immersive\nInteractive VR . Springer Singapore, 71–89. https://doi.org/10.1007/978-981-16-\n3416-1_4\n[31] Jan Hombeck, Monique Meuschke, Lennert Zyla, André-Joel Heuser, Justus\nToader, Felix Popp, Christiane J. Bruns, Christian Hansen, Rabi R. Datta, and\nKai Lawonn. 2022. Evaluating Perceptional Tasks for Medicine: A Comparative\nUser Study Between a Virtual Reality and a Desktop Application. In 2022 IEEE\nConference on Virtual Reality and 3D User Interfaces (VR) . 514–523. https://doi.\norg/10.1109/VR51125.2022.00071\nCUI ’24, July 8–10, 2024, Luxembourg, Luxembourg Bozkir, et al.\n[32] Benedikt W. Hosp, Florian Schultz, Oliver Höner, and Enkelejda Kasneci. 2021.\nSoccer goalkeeper expertise identification based on eye movements. PLOS ONE\n16, 5 (2021), 1–22. https://doi.org/10.1371/journal.pone.0251070\n[33] Shiu-Wan Hung, Che-Wei Chang, and Yu-Chen Ma. 2021. A new reality: Explor-\ning continuance intention to use mobile augmented reality for entertainment\npurposes. Technology in Society 67 (2021), 101757. https://doi.org/10.1016/j.\ntechsoc.2021.101757\n[34] Matthew Jin, Syed Shahriar, Michele Tufano, Xin Shi, Shuai Lu, Neel Sundaresan,\nand Alexey Svyatkovskiy. 2023. InferFix: End-to-End Program Repair with LLMs.\nhttps://doi.org/10.48550/arXiv.2303.07263\n[35] Enkelejda Kasneci, Kathrin Sessler, Stefan Küchemann, Maria Bannert, Daryna\nDementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan Günnemann, Eyke\nHüllermeier, Stephan Krusche, Gitta Kutyniok, Tilman Michaeli, Claudia Nerdel,\nJürgen Pfeffer, Oleksandra Poquet, Michael Sailer, Albrecht Schmidt, Tina Seidel,\nMatthias Stadler, Jochen Weller, Jochen Kuhn, and Gjergji Kasneci. 2023. ChatGPT\nfor good? On opportunities and challenges of large language models for education.\nLearning and Individual Differences 103 (2023), 102274. https://doi.org/10.1016/j.\nlindif.2023.102274\n[36] Iason Kastanis and Mel Slater. 2012. Reinforcement Learning Utilizes Proxemics:\nAn Avatar Learns to Manipulate the Position of People in Immersive Virtual\nReality. ACM Transactions on Applied Perception 9, 1 (2012). https://doi.org/10.\n1145/2134203.2134206\n[37] Ryo Kodama, Masahiro Koge, Shun Taguchi, and Hiroyuki Kajimoto. 2017. COMS-\nVR: Mobile virtual reality entertainment system using electric car and head-\nmounted display. In 2017 IEEE Symposium on 3D User Interfaces (3DUI) . 130–133.\nhttps://doi.org/10.1109/3DUI.2017.7893329\n[38] Jacob Leon Kröger, Otto Hans-Martin Lutz, and Florian Müller. 2020. What\nDoes Your Gaze Reveal About You? On the Privacy Implications of Eye Tracking .\nSpringer International Publishing, 226–241. https://doi.org/10.1007/978-3-030-\n42504-3_15\n[39] Kiron Lebeck, Kimberly Ruth, Tadayoshi Kohno, and Franziska Roesner. 2018.\nTowards Security and Privacy for Multi-user Augmented Reality: Foundations\nwith End Users. In 2018 IEEE Symposium on Security and Privacy (SP) . 392–408.\nhttps://doi.org/10.1109/SP.2018.00051\n[40] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,\nNaman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel,\nSebastian Riedel, and Douwe Kiela. 2020. Retrieval-Augmented Generation for\nKnowledge-Intensive NLP Tasks. In Advances in Neural Information Processing\nSystems, Vol. 33. Curran Associates, Inc., 9459–9474. https://doi.org/10.48550/\narXiv.2005.11401\n[41] Tianshi Li, Sauvik Das, Hao-Ping Lee, Dakuo Wang, Bingsheng Yao, and Zhiping\nZhang. 2024. Human-Centered Privacy Research in the Age of Large Language\nModels. In Extended Abstracts of the CHI Conference on HumanFactors in Comput-\ning Systems (CHI EA ’24) . ACM. https://doi.org/10.1145/3613905.3643983\n[42] Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve Jiang, and You Zhang. 2023.\nChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model\nMeta-AI (LLaMA) Using Medical Domain Knowledge. https://doi.org/10.48550/\narXiv.2303.14070\n[43] Daniel J. Liebling and Sören Preibusch. 2014. Privacy Considerations for a\nPervasive Eye Tracking World. InProceedings of the 2014 ACM International Joint\nConference on Pervasive and Ubiquitous Computing: Adjunct Publication . ACM,\n1169–1177. https://doi.org/10.1145/2638728.2641688\n[44] Feiyu Lu, Shakiba Davari, Lee Lisle, Yuan Li, and Doug A. Bowman. 2020. Glance-\nable AR: Evaluating Information Access Methods for Head-Worn Augmented\nReality. In 2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR) .\n930–939. https://doi.org/10.1109/VR46266.2020.00113\n[45] Mark McGill, Julie Williamson, Alexander Ng, Frank Pollick, and Stephen\nBrewster. 2020. Challenges in passenger use of mixed reality headsets in\ncars and other transportation. Virtual Reality 24, 4 (2020), 583–603. https:\n//doi.org/10.1007/s10055-019-00420-x\n[46] Martin Meißner, Jella Pfeiffer, Christian Peukert, Holger Dietrich, and Thies\nPfeiffer. 2020. How virtual reality affects consumer choice. Journal of Business\nResearch 117 (2020), 219–231. https://doi.org/10.1016/j.jbusres.2020.06.004\n[47] Pardis Emami Naeini, Sruti Bhagavatula, Hana Habib, Martin Degeling, Lujo\nBauer, Lorrie Faith Cranor, and Norman Sadeh. 2017. Privacy expectations and\npreferences in an IoT world. In Thirteenth Symposium on Usable Privacy and\nSecurity (SOUPS 2017) . USENIX Association, 399–412. https://www.usenix.org/\nconference/soups2017/technical-sessions/presentation/naeini\n[48] Vivek Nair, Wenbo Guo, James F. O’Brien, Louis Rosenberg, and Dawn Song. 2023.\nDeep Motion Masking for Secure, Usable, and Scalable Real-Time Anonymization\nof Virtual Reality Motion Data. https://doi.org/10.48550/arXiv.2311.05090\n[49] Vivek C Nair, Gonzalo Munilla-Garrido, and Dawn Song. 2023. Going Incognito\nin the Metaverse: Achieving Theoretically Optimal Privacy-Usability Tradeoffs in\nVR. In Proceedings of the 36th Annual ACM Symposium on User Interface Software\nand Technology. ACM. https://doi.org/10.1145/3586183.3606754\n[50] John Naughton. 2023. ChatGPT exploded into public life a year ago. Now\nwe know what went on behind the scenes. https://www.theguardian.com/\ncommentisfree/2023/dec/09/chatgpt-ai-pearl-harbor-moment-sam-altman. Last\naccessed 10/01/2024.\n[51] Seth Neel and Peter Chang. 2023. Privacy Issues in Large Language Models: A\nSurvey. https://doi.org/10.48550/arXiv.2312.06717\n[52] Joseph O’Hagan, Pejman Saeghe, Jan Gugenheimer, Daniel Medeiros, Karola\nMarky, Mohamed Khamis, and Mark McGill. 2023. Privacy-Enhancing Tech-\nnology and Everyday Augmented Reality: Understanding Bystanders’ Varying\nNeeds for Awareness and Consent. Proc. ACM Interact. Mob. Wearable Ubiquitous\nTechnol. 6, 4 (2023), 177:1–177:35. https://doi.org/10.1145/3569501\n[53] OpenAI. 2023. GPT-4V(ision) System Card . Technical Report. OpenAI. https:\n//openai.com/index/gpt-4v-system-card/\n[54] OpenAI. 2023. Prompt Engineering. https://platform.openai.com/docs/guides/\nprompt-engineering. Last accessed 09/01/2024.\n[55] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda\nAskell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Train-\ning language models to follow instructions with human feedback. https:\n//doi.org/10.48550/arXiv.2203.02155\n[56] Hunor Pal. 2023. Replica Studios introduces AI-Powered Smart\nNPCs for Unreal Engine. https://europeangaming.eu/portal/latest-\nnews/2023/05/29/136470/replica-studios-introduces-ai-powered-smart-npcs-\nfor-unreal-engine/. Last accessed 10/01/2024.\n[57] Tabitha C. Peck, Kyla A. McMullen, and John Quarles. 2021. DiVRsify: Break the\nCycle and Develop VR for Everyone. IEEE Computer Graphics and Applications\n41, 6 (2021), 133–142. https://doi.org/10.1109/MCG.2021.3113455\n[58] Tabitha C. Peck, Laura E. Sockol, and Sarah M. Hancock. 2020. Mind the Gap:\nThe Underrepresentation of Female Participants and Authors in Virtual Reality\nResearch. IEEE Transactions on Visualization and Computer Graphics 26, 5 (2020),\n1945–1954. https://doi.org/10.1109/TVCG.2020.2973498\n[59] Terry M Peters, Cristian A Linte, Ziv Yaniv, and Jacqueline Williams. 2018.Mixed\nand augmented reality in medicine . CRC Press.\n[60] Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, Sayani\nKundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi, Alexei\nBaevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau, and Michael\nAuli. 2023. Scaling Speech Technology to 1,000+ Languages. https://doi.org/10.\n48550/arXiv.2305.13516\n[61] Qazi Rahman and Johanna Koerting. 2008. Sexual orientation-related differences\nin allocentric spatial memory tasks. Hippocampus 18, 1 (2008), 55–63. https:\n//doi.org/10.1002/hipo.20375\n[62] Ned T Sahin, Neha U Keshav, Joseph P Salisbury, and Arshya Vahabzadeh. 2018.\nSecond version of google glass as a wearable socio-affective aid: Positive school\ndesirability, high usability, and theoretical framework in a sample of children\nwith autism. JMIR human factors 5, 1 (2018), e8785. https://doi.org/10.2196/\nhumanfactors.8785\n[63] Valentin Schwind, Pascal Knierim, Cagri Tasci, Patrick Franczak, Nico Haas,\nand Niels Henze. 2017. \"These Are Not My Hands!\": Effect of Gender on the\nPerception of Avatar Hands in Virtual Reality. In Proceedings of the 2017 CHI\nConference on Human Factors in Computing Systems . ACM, 1577–1582. https:\n//doi.org/10.1145/3025453.3025602\n[64] Katharina R. Seitz, Jessica J. Good, and Tabitha C. Peck. 2020. Shooter Bias in\nVirtual Reality: The Effect of Avatar Race and Socioeconomic Status on Shooting\nDecisions. In 2020 IEEE Conference on Virtual Reality and 3D User Interfaces\nAbstracts and Workshops (VRW) . 606–607. https://doi.org/10.1109/VRW50115.\n2020.00154\n[65] Karan Singhal, Shekoofeh Azizi, Tao Tu, S. Sara Mahdavi, Jason Wei, Hyung Won\nChung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry\nPayne, Martin Seneviratne, Paul Gamble, Chris Kelly, Abubakr Babiker, Nathanael\nSchärli, Aakanksha Chowdhery, Philip Mansfield, Dina Demner-Fushman, Blaise\nAgüera y Arcas, Dale Webster, Greg S. Corrado, Yossi Matias, Katherine Chou,\nJuraj Gottweis, Nenad Tomasev, Yun Liu, Alvin Rajkomar, Joelle Barral, Christo-\npher Semturs, Alan Karthikesalingam, and Vivek Natarajan. 2023. Large lan-\nguage models encode clinical knowledge. Nature 620, 7972 (2023), 172–180.\nhttps://doi.org/10.1038/s41586-023-06291-2\n[66] Victoria Smith, Ali Shahin Shamsabadi, Carolyn Ashurst, and Adrian Weller. 2023.\nIdentifying and Mitigating Privacy Risks Stemming from Language Models: A\nSurvey. https://doi.org/10.48550/arXiv.2310.01424\n[67] Ryo Suzuki, Mar Gonzalez-Franco, Misha Sra, and David Lindlbauer. 2023. XR and\nAI: AI-Enabled Virtual, Augmented, and Mixed Reality. In Adjunct Proceedings\nof the 36th Annual ACM Symposium on User Interface Software and Technology .\nACM. https://doi.org/10.1145/3586182.3617432\n[68] Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-\nFahey, Judith Amores Fernandez, and Jaron Lanier. 2023. LLMR: Real-time\nPrompting of Interactive Worlds using Large Language Models. https://doi.org/\n10.48550/arXiv.2309.12276\n[69] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne\nLachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,\nFaisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guil-\nlaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models.\nEmbedding Large Language Models into Extended Reality CUI ’24, July 8–10, 2024, Luxembourg, Luxembourg\nhttps://doi.org/10.48550/arXiv.2302.13971\n[70] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucu-\nrull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia\nGao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini,\nRui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel\nKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut\nLavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton,\nJeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva,\nEric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,\nYuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2:\nOpen Foundation and Fine-Tuned Chat Models. https://doi.org/10.48550/arXiv.\n2307.09288\n[71] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing systems 30 (2017). https:\n//doi.org/10.48550/arXiv.1706.03762\n[72] Ethan Waisberg, Joshua Ong, Mouayad Masalkhi, Nasif Zaman, Prithul Sarker,\nAndrew G. Lee, and Alireza Tavakkoli. 2023. Meta smart glasses—large language\nmodels and the future for assistive glasses for individuals with vision impairments.\nEye (2023). https://doi.org/10.1038/s41433-023-02842-z\n[73] Chris Warin and Delphine Reinhardt. 2022. Vision: Usable Privacy for XR in the\nEra of the Metaverse. In Proceedings of the 2022 European Symposium on Usable\nSecurity. ACM, 111–116. https://doi.org/10.1145/3549015.3554212\n[74] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter,\nFei Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought\nPrompting Elicits Reasoning in Large Language Models. In Advances in\nNeural Information Processing Systems , Vol. 35. Curran Associates, Inc.,\n24824–24837. https://proceedings.neurips.cc/paper_files/paper/2022/file/\n9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf\n[75] Kyle Wiggers. 2024. OpenAI’s app store for GPTs will launch next\nweek. https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-\nlaunch-next-week. Last accessed 09/01/2024.\n[76] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan\nCao, and Karthik Narasimhan. 2023. Tree of Thoughts: Deliberate Problem\nSolving with Large Language Models. https://doi.org/10.48550/arXiv.2305.10601\nAdvances in Neural Information Processing Systems.\n[77] Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, and Weiqiang Jia. 2023. Cognitive\nMirage: A Review of Hallucinations in Large Language Models. https://doi.org/\n10.48550/arXiv.2309.06794 Last accessed 10/01/2024.\n[78] Andy Wai Kan Yeung, Anela Tosevska, Elisabeth Klager, Fabian Eibensteiner,\nDaniel Laxar, Jivko Stoyanov, Marija Glisic, Sebastian Zeiner, Stefan Tino Kulnik,\nRik Crutzen, Oliver Kimberger, Maria Kletecka-Pulker, Atanas G Atanasov, and\nHarald Willschke. 2021. Virtual and Augmented Reality Applications in Medicine:\nAnalysis of the Scientific Literature. Journal of medical internet research 23, 2\n(2021). https://doi.org/10.2196/25499\n[79] Jiseon Yun, Jae Eui Sohn, and Sunghyon Kyeong. 2023. Fine-Tuning Pretrained\nLanguage Models to Enhance Dialogue Summarization in Customer Service\nCenters. In Proceedings of the Fourth ACM International Conference on AI in\nFinance. ACM, 365–373. https://doi.org/10.1145/3604237.3626838\n[80] Zhiping Zhang, Michelle Jia, Hao-Ping (Hank) Lee, Bingsheng Yao, Sauvik Das,\nAda Lerner, Dakuo Wang, and Tianshi Li. 2024. “It’s a Fair Game”, or Is It?\nExamining How Users Navigate Disclosure Risks and Benefits When Using LLM-\nBased Conversational Agents. In Proceedings of the CHI Conference on Human\nFactors in Computing Systems . ACM. https://doi.org/10.1145/3613904.3642385",
  "topic": "Inclusion (mineral)",
  "concepts": [
    {
      "name": "Inclusion (mineral)",
      "score": 0.8320672512054443
    },
    {
      "name": "Embedding",
      "score": 0.8252928256988525
    },
    {
      "name": "Internet privacy",
      "score": 0.5928555727005005
    },
    {
      "name": "Financial inclusion",
      "score": 0.42267778515815735
    },
    {
      "name": "Computer science",
      "score": 0.38305607438087463
    },
    {
      "name": "Computer security",
      "score": 0.32779058814048767
    },
    {
      "name": "Psychology",
      "score": 0.2863730788230896
    },
    {
      "name": "Business",
      "score": 0.27153533697128296
    },
    {
      "name": "Social psychology",
      "score": 0.13930261135101318
    },
    {
      "name": "Artificial intelligence",
      "score": 0.11665600538253784
    },
    {
      "name": "Financial services",
      "score": 0.0
    },
    {
      "name": "Finance",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 33
}