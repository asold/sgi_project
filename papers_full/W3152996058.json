{
  "title": "Relational World Knowledge Representation in Contextual Language Models: A Review",
  "url": "https://openalex.org/W3152996058",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2584705907",
      "name": "Tara Safavi",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A1524801041",
      "name": "Danai Koutra",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2998696444",
    "https://openalex.org/W3165066581",
    "https://openalex.org/W2984147501",
    "https://openalex.org/W4230553559",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W3166986030",
    "https://openalex.org/W3119595285",
    "https://openalex.org/W3151929433",
    "https://openalex.org/W2985797697",
    "https://openalex.org/W2994915912",
    "https://openalex.org/W3104499181",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W2121773050",
    "https://openalex.org/W3119866685",
    "https://openalex.org/W3105082862",
    "https://openalex.org/W2561529111",
    "https://openalex.org/W3117339789",
    "https://openalex.org/W3173169192",
    "https://openalex.org/W3176750236",
    "https://openalex.org/W1964189668",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W4229543565",
    "https://openalex.org/W3104163040",
    "https://openalex.org/W3153094109",
    "https://openalex.org/W2161915178",
    "https://openalex.org/W3100283070",
    "https://openalex.org/W3126974869",
    "https://openalex.org/W2107598941",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W4287366208",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W2805516822",
    "https://openalex.org/W2107658650",
    "https://openalex.org/W2964207259",
    "https://openalex.org/W3099655892",
    "https://openalex.org/W2953356739",
    "https://openalex.org/W3021533447",
    "https://openalex.org/W1532325895",
    "https://openalex.org/W3175604467",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3127227595",
    "https://openalex.org/W2786660442",
    "https://openalex.org/W2991223644",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W3139080614",
    "https://openalex.org/W3091432621",
    "https://openalex.org/W3098266846",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W2968908603",
    "https://openalex.org/W2998557616",
    "https://openalex.org/W3202712981",
    "https://openalex.org/W3104178968",
    "https://openalex.org/W3146844750",
    "https://openalex.org/W3104415840",
    "https://openalex.org/W2998385486",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3171899052",
    "https://openalex.org/W3166846774",
    "https://openalex.org/W3105093672",
    "https://openalex.org/W3119212036",
    "https://openalex.org/W2963101081",
    "https://openalex.org/W2964022985",
    "https://openalex.org/W3104748221",
    "https://openalex.org/W3100843744",
    "https://openalex.org/W3039578880",
    "https://openalex.org/W2982399380",
    "https://openalex.org/W3169283738",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W2016089260",
    "https://openalex.org/W2094728533",
    "https://openalex.org/W3155001903",
    "https://openalex.org/W3164972323",
    "https://openalex.org/W3114219454",
    "https://openalex.org/W2952826391",
    "https://openalex.org/W3035290244",
    "https://openalex.org/W1480810164",
    "https://openalex.org/W3101204082",
    "https://openalex.org/W4287758766",
    "https://openalex.org/W3102999298",
    "https://openalex.org/W2963305465",
    "https://openalex.org/W2970986510",
    "https://openalex.org/W3173673636",
    "https://openalex.org/W3034830866",
    "https://openalex.org/W3176229980",
    "https://openalex.org/W4311398011",
    "https://openalex.org/W3034671305",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W3113633418",
    "https://openalex.org/W2153579005",
    "https://openalex.org/W4287747814",
    "https://openalex.org/W3111372685",
    "https://openalex.org/W3180536457",
    "https://openalex.org/W2153595771",
    "https://openalex.org/W3148437589",
    "https://openalex.org/W2997200074",
    "https://openalex.org/W2038721957",
    "https://openalex.org/W2970161131",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3102844651",
    "https://openalex.org/W3176793246",
    "https://openalex.org/W2167187514",
    "https://openalex.org/W3033176962",
    "https://openalex.org/W3154735894",
    "https://openalex.org/W4297795751",
    "https://openalex.org/W3156170450",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3014521650",
    "https://openalex.org/W2126539437",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2080133951",
    "https://openalex.org/W3020987135",
    "https://openalex.org/W3176825161",
    "https://openalex.org/W2998901379",
    "https://openalex.org/W3102859667",
    "https://openalex.org/W3169602049",
    "https://openalex.org/W2972167903",
    "https://openalex.org/W3119164154",
    "https://openalex.org/W3042876905",
    "https://openalex.org/W3174464510",
    "https://openalex.org/W3092288641",
    "https://openalex.org/W2909137510",
    "https://openalex.org/W3040558716",
    "https://openalex.org/W3094245336",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W2963310665",
    "https://openalex.org/W3100353583",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2270070752",
    "https://openalex.org/W2888236192",
    "https://openalex.org/W3154903254",
    "https://openalex.org/W3098267758",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W3113587353"
  ],
  "abstract": "Relational knowledge bases (KBs) are commonly used to represent world knowledge in machines. However, while advantageous for their high degree of precision and interpretability, KBs are usually organized according to manually-defined schemas, which limit their expressiveness and require significant human efforts to engineer and maintain. In this review, we take a natural language processing perspective to these limitations, examining how they may be addressed in part by training deep contextual language models (LMs) to internalize and express relational knowledge in more flexible forms. We propose to organize knowledge representation strategies in LMs by the level of KB supervision provided, from no KB supervision at all to entity- and relation-level supervision. Our contributions are threefold: (1) We provide a high-level, extensible taxonomy for knowledge representation in LMs; (2) Within our taxonomy, we highlight notable models, evaluation tasks, and findings, in order to provide an up-to-date review of current knowledge representation capabilities in LMs; and (3) We suggest future research directions that build upon the complementary aspects of LMs and KBs as knowledge representations.",
  "full_text": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1053–1067\nNovember 7–11, 2021.c⃝2021 Association for Computational Linguistics\n1053\nRelational World Knowledge Representation\nin Contextual Language Models: A Review\nTara Safavi, Danai Koutra\nUniversity of Michigan, Ann Arbor\n{tsafavi,dkoutra}@umich.edu\nAbstract\nRelational knowledge bases (KBs) are com-\nmonly used to represent world knowledge in\nmachines. However, while advantageous for\ntheir high degree of precision and interpretabil-\nity, KBs are usually organized according to\nmanually-deﬁned schemas, which limit their\nexpressiveness and require signiﬁcant human\nefforts to engineer and maintain. In this review,\nwe take a natural language processing perspec-\ntive to these limitations, examining how they\nmay be addressed in part by training deep con-\ntextual language models (LMs) to internalize\nand express relational knowledge in more ﬂex-\nible forms. We propose to organize knowl-\nedge representation strategies in LMs by the\nlevel of KB supervision provided, from no KB\nsupervision at all to entity- and relation-level\nsupervision. Our contributions are threefold:\n(1) We provide a high-level, extensible tax-\nonomy for knowledge representation in LMs;\n(2) Within our taxonomy, we highlight notable\nmodels, evaluation tasks, and ﬁndings, in or-\nder to provide an up-to-date review of current\nknowledge representation capabilities in LMs;\nand (3) We suggest future research directions\nthat build upon the complementary aspects of\nLMs and KBs as knowledge representations.\n1 Introduction\nKnowledge bases ( KBs) are data structures that\nconnect pairs of entities or concepts by seman-\ntically meaningful symbolic relations. Decades’\nworth of research have been invested into using\nKBs as tools for relational world knowledge repre-\nsentation in machines (Minsky, 1974; Lenat, 1995;\nLiu and Singh, 2004; Bollacker et al., 2008; Vran-\ndeˇci´c and Krötzsch, 2014; Speer et al., 2017; Sap\net al., 2019; Ilievski et al., 2021).\nMost large-scale modern KBs are organized ac-\ncording to a manually engineered schema that spec-\niﬁes which entity and relation types are permitted,\nand how such types may interact with one another.\nThis explicit enforcement of relational structure is\nboth an advantage and a drawback (Halevy et al.,\n2003). On one hand, schemas support complex\nqueries over the data with accurate, consistent, and\ninterpretable answers. On the other hand, schemas\nare “ontological commitments” (Davis et al., 1993)\nthat limit ﬂexibility in how knowledge is stored, ex-\npressed, and accessed. Handcrafted schemas also\nrequire signiﬁcant human engineering effort to con-\nstruct and maintain, and are therefore often highly\nincomplete (Weikum et al., 2021).\nLanguage models as KBs? The tension be-\ntween structured and unstructured knowledge rep-\nresentations is not new in natural language process-\ning (Banko and Etzioni, 2008; Fader et al., 2011).\nHowever, only recently has an especially promis-\ning solution emerged, brought about by break-\nthroughs in machine learning software, hardware,\nand data. Speciﬁcally, deep contextual language\nmodels (LMs) like BERT (Devlin et al., 2019) and\nGPT-3 (Brown et al., 2020) have shown to be ca-\npable of internalizing a degree of relational world\nknowledge within their parameters, and express-\ning this knowledge across various mediums and\ntasks—in some cases, without the need for a prede-\nﬁned entity-relation schema (Petroni et al., 2019;\nRoberts et al., 2020). Consequently, some have be-\ngun to wonder whether LMs will partially or even\nfully replace KBs, given sufﬁciently large training\nbudgets and parameter capacities.\nPresent work In this review, we summarize re-\ncent compelling progress in machine representation\nof relational world knowledge with LMs. We pro-\npose to organize relevant work by the level of KB\nsupervision provided to the LM (Figure 1):\n• Word-level supervision (§ 3): At this level,\nLMs are not explicitly supervised on a KB, but\nmay be indirectly exposed to KB-like knowl-\nedge via word associations in the training cor-\npus. Here, we cover techniques for probing\n1054\nFigure 1: A high-level overview of our taxonomy, orga-\nnized by level of KB supervision provided.\nand utilizing this implicitly acquired knowl-\nedge.\n• Entity-level supervision (§ 4): At this level,\nLMs are supervised to acquire knowledge of\nKB entities. Here, we organize strategies from\n“less symbolic” to “more symbolic”: Less sym-\nbolic approaches train LMs with entity-aware\nlanguage modeling losses, but never explicitly\nrequire the LM to link entity mentions to the\nKB. By contrast, more symbolic approaches\ninvolve linking, and may also integrate entity\nembeddings into the LM’s parameters.\n• Relation-level supervision (§ 5): At this\nlevel, LMs are supervised to acquire knowl-\nedge of KB triples and paths. Again, we or-\nganize strategies from less to more symbolic,\nwhere less symbolic approaches treat triples as\nfully natural language statements, and more\nsymbolic approaches incorporate dedicated\nembeddings of KB relation types.\nFor each supervision level, we provide notable ex-\namples in terms of methodology and/or ﬁndings,\nand compare the beneﬁts and drawbacks of differ-\nent approaches. We conclude in § 6 with our vision\nof the future, emphasizing the complementary roles\nof LMs and KBs as knowledge representations.\nRelated work As this topic is relatively nascent,\nfew related surveys exist. Closest to our own\nwork, Colon-Hernandez et al. (2021) cover meth-\nods for combining contextual language representa-\ntions with graph representations, albeit with a com-\nparatively narrow scope and no discussion of im-\nplicit knowledge. Liu et al. (2021a) survey prompt-\nbased learning in LMs, which overlaps with our\ndiscussion of cloze prompting in § 3.1, although\nrelational world knowledge is not their main focus.\n2 Preliminaries\nWe brieﬂy review preliminaries and assumptions\nnecessary for our survey.\nKnowledge bases We use the term “knowledge\nbase” (KB) to refer to a relational data structure\ncomprising a set of entities E, relation types R,\nand triples (s, r, o) ∈E ×R ×E, where s, o∈E\nare subject and object entities, respectively.1 We\nconsider two types of KBs under the umbrella of\n“relational world knowledge.”Encyclopedic KBs\nstore facts about typed, disambiguated entities; a\nwell-known example is the Wikidata KB (Vran-\ndeˇci´c and Krötzsch, 2014), which, like its sister\nproject Wikipedia, is publicly accessible and col-\nlaboratively constructed. By contrast, in common-\nsense KBs, “entities” are typically represented by\nnon-canonicalized free-text phrases. Examples in-\nclude the publicly accessible, crowdsourced Con-\nceptNet (Liu and Singh, 2004; Speer et al., 2017)\nand ATOMIC (Sap et al., 2019) KBs.\nLanguage models Following the contemporary\nNLP literature, we use the term “language model”\n(LM) to refer to a deep neural network that is\ntrained to learn contextual text representations.\nLMs generally come pretrained, with parame-\nters pre-initialized for generic text representation\nvia self-supervised training on large corpora, and\nmay be used as-is after pretraining, or further ﬁne-\ntuned with supervision on downstream task(s).\nThis work considers LMs based on the Trans-\nformer architecture (Vaswani et al., 2017), ex-\namples of which include the encoder-only BERT\nfamily (Devlin et al., 2019; Liu et al., 2019), the\ndecoder-only GPT family (Brown et al., 2020), and\nthe encoder-decoder T5 (Raffel et al., 2020) and\nBART (Lewis et al., 2020) families.\n3 Word-level supervision\nThe standard language modeling task is to predict\nthe n-th word in a sequence of n words—that is,\na conditional probability estimation task (Radford\net al., 2019). While many variants of this task\nhave been proposed to allow LMs to condition their\npredictions on different inputs (Devlin et al., 2019;\nRaffel et al., 2020; Lewis et al., 2020), a notable\nfeature of all such approaches is that they operate\nat the word (and subword) level.\nIf these supervision techniques do not incorpo-\nrate KBs at all, how are they relevant when con-\nsidering LMs as relational knowledge representa-\ntions? The answer is simple. Typical language\n1For our purposes, we consider the terms “knowledge base”\nand “knowledge graph” as interchangeable.\n1055\nTable 1: Taxonomy and representative examples for extracting relational knowledge in word-level pretrained LMs,\nwith evaluation tasks that have been conducted in the referenced papers. Glossary of evaluation tasks : KP—\nknowledge probing; QA—question answering; CR—compositional reasoning; KC—knowledge base construction.\nKnowledge extracted via... Extraction strategy Representative examples Evaluation task(s)\nKP QA CR KC\nCloze prompts (§ 3.1)\nPrompt handcrafting (Petroni et al., 2019; Dufter et al., 2021)\u0013\nAutomatic prompt engineering(Jiang et al., 2020b; Shin et al., 2020; Zhong\net al., 2021; Qin and Eisner, 2021) \u0013\nAdversarial prompt modiﬁcation(Kassner and Schütze, 2020; Petroni et al.,\n2020; Poerner et al., 2020; Cao et al., 2021)\u0013\nVarying base prompts (Elazar et al., 2021; Heinzerling and Inui,\n2021; Jiang et al., 2020a; Kassner et al., 2021)\u0013\nSymbolic rule-based prompting (Kassner et al., 2020; Talmor et al., 2020a)\u0013 \u0013\nStatement scores (§ 3.2)Single-LM scoring (Tamborrino et al., 2020; Zhou et al., 2020) \u0013 \u0013\nDual-LM scoring (Davison et al., 2019; Shwartz et al., 2020) \u0013 \u0013\nmodeling corpora like Wikipedia are known to con-\ntain KB-like assertions about the world (Da and\nKasai, 2019). LMs trained on enough such data\ncan be expected to acquire some KB-like knowl-\nedge, even without targeted entity- or relation-level\nsupervision. Therefore, in order to motivate the\nnecessity (if at all) of KB supervision, it is crucial\nto ﬁrst understand what relational world “knowl-\nedge” LMs acquire from word-level pretraining.\nIn this section, we cover strategies to extract and\nutilize this knowledge under the cloze prompting\n(§ 3.1) and statement scoring (§ 3.2) protocols. Ta-\nble 1 provides a taxonomy for this section, with\nrepresentative examples and evaluation tasks.\n3.1 Cloze prompting\nThe cloze prompting protocol (Taylor, 1953 and\nFigure 2) is a direct approach for extracting and\nevaluating KB-like knowledge in pretrained LMs.\nUnder this protocol, KB triples are ﬁrst converted\nto natural language assertions using (e.g.) relation\ntemplates. For each assertion, the token(s) corre-\nsponding to the object entity are held out. A frozen\npretrained LM then ranks candidate tokens within\nits vocabulary by the probability that they ﬁll in\nthe empty slot(s). Accuracy is typically measured\nby the proportion of prompts for which the cor-\nrect answer appears in the LM’s top-k predictions,\nwith the assumption that better performance im-\nplies more pretrained knowledge within the LM.\nHandcrafted prompts in English with single-\ntoken answers make up LAMA (Petroni et al.,\n2019), one of the earliest and most widely-used LM\ncloze probes. LAMA , which is mapped primarily\nto Wikidata and ConceptNet triples, was initially\nused to compare pretrained LMs’ knowledge to off-\nthe-shelf KB question answering systems. Petroni\net al. (2019) showed that pretrained BERT is com-\nFigure 2: Probing relational knowledge in pretrained\nLMs with cloze prompts generated from KB triples.\npetitive with a supervised relation extraction model\nthat has been provided an oracle for entity link-\ning, particularly for 1-1 queries. Subsequent work\nhas experimented with handcrafted templates for\nprobing the knowledge of both very large (hundred-\nbillion parameter) LMs (Brown et al., 2020) as well\nas non-contextual word embeddings, i.e., as a sim-\nple control baseline for LMs (Dufter et al., 2021).\nBoth studies demonstrate some success, particu-\nlarly in cases where the probed model is provided\na small amount of extra context in the form of con-\nditioning examples (Brown et al., 2020) or entity\ntype information (Dufter et al., 2021).\nAutomatic prompt engineering is a promising al-\nternative to prompt handcrafting for knowledge\nextraction in LMs (Liu et al., 2021a), as prompts\nengineered using discrete (Jiang et al., 2020b;\nShin et al., 2020; Haviv et al., 2021) and continu-\nous (Zhong et al., 2021; Qin and Eisner, 2021; Liu\net al., 2021b) optimization have improved LMs’\nlower-bound performance on LAMA ’s underlying\nqueries. Note, however, that optimized prompts\nare not always grammatical or intelligible (Shin\net al., 2020). Prompt optimization methods may\nalso confound knowledge probes by overﬁtting\nto the probes’ answer distributions during train-\n1056\ning (Zhong et al., 2021; Cao et al., 2021), and often\nrequire large validation sets for tuning, which may\nnot be feasible in practice (Perez et al., 2021).\nAdversarial modiﬁcation of LAMA prompts has\nuncovered weaknesses in pretrained LMs’ world\n“knowledge,” for example that BERT’s accuracy\ndrops precipitously when irrelevant statements or\nnegation words are added to prompts (Kassner and\nSchütze, 2020; Lin et al., 2020; Petroni et al., 2020),\nand that it can “guess” answers using shallow lex-\nical cues or benchmark artifacts (Poerner et al.,\n2020; Cao et al., 2021). However, the adversarial\nrobustness of LM knowledge improves greatly with\nsupervision in both the pretraining (Petroni et al.,\n2020) and ﬁne-tuning (Kassner and Schütze, 2020)\nstages, suggesting that explicit KB-level supervi-\nsion is a viable remedy to input sensitivity.\nSeveral collections of prompt variations, includ-\ning paraphrased sets of base prompts (Elazar et al.,\n2021; Heinzerling and Inui, 2021) and multilingual\nsets of base (English) prompts (Jiang et al., 2020a;\nKassner et al., 2021) have been released to expand\nthe original research questions posed by LAMA .\nFor the former, it has been found that pretrained\nBERT-based LMs typically do not output consis-\ntent answers for prompt paraphrases, although their\nconsistency can again be greatly improved by tar-\ngeted pretraining (Elazar et al., 2021; Heinzerling\nand Inui, 2021). For the latter, initial results on\nprompts beyond English indicate high variability\nin pretrained LM performance across languages\nand poor performance on prompts with multi-token\nanswers (Jiang et al., 2020a; Kassner et al., 2021).\nPrompts generated with symbolic rules have\nbeen used to test pretrained LMs’ abilities to learn,\ne.g., equivalence, implication, composition, and\nconjunction. Existing studies vary the degrees of\nexperimental control: Talmor et al. (2020a) use\nBERT-based models with their publicly-available\npretrained weights, whereas Kassner et al. (2020)\npretrain BERT from scratch on synthetic KB triples\nonly. Both studies observe mixed results, conclud-\ning that word-level pretraining alone (at least on\nBERT) does not lead to strong “reasoning” skills.\n3.2 Statement scoring\nBeyond probing, pretrained LM “knowledge” can\nbe purposed toward downstream KB-level tasks in\na zero-shot manner via statement scoring. Here, a\npretrained LM is fed natural language statements\ncorresponding to KB triples, and its token proba-\nbilities across each statement are pooled to yield\nstatement scores. These scores are then treated\nas input to a downstream decision, mirroring the\nway that supervised LMs can be trained to out-\nput probabilities for triple-level prediction tasks\n(§ 5). We categorize statement scoring strategies\nas single- or dual-LM approaches. The single-LM\napproach pools the pretrained LM’s token scores\nover a candidate set of sequences, then takes the\nhighest-scoring sequence as the LM’s “prediction”\nor choice (Tamborrino et al., 2020; Bouraoui et al.,\n2020; Zhou et al., 2020; Brown et al., 2020). The\ndual-LM framework ﬁrst uses one pretrained LM\nto generate useful context (e.g., clariﬁcation text)\nfor the task, then feeds this context to another,\npossibly different pretrained LM to obtain a ﬁnal\nscore (Davison et al., 2019; Shwartz et al., 2020).\nBoth categories have shown promise over com-\nparable unsupervised (and, under some conditions,\nsupervised) methods for tasks like multiple-choice\nQA (Tamborrino et al., 2020; Shwartz et al., 2020;\nBrown et al., 2020) and commonsense KB comple-\ntion (Davison et al., 2019). However, LM scores\nhave also shown to be sensitive to small perturba-\ntions in text (Zhou et al., 2020), so this approach\nmay be less effective on noisy or long-tail inputs.\n3.3 Summary and outlook\nThere is still broad disagreement over the nature of\nacquired “knowledge” in pretrained LMs. Whereas\nsome studies suggest that word-level pretraining\nmay be enough to endow LMs with KB-like knowl-\nedge (Petroni et al., 2019; Tamborrino et al., 2020),\nin particular given enough parameters and the right\nset of prompts (Brown et al., 2020), others con-\nclude that such pretraining alone does not yield suf-\nﬁciently precise or robust LM knowledge (Elazar\net al., 2021; Cao et al., 2021)—directly motivating\nthe targeted supervision strategies discussed in the\nremainder of this paper. We observe that differ-\nent studies independently set objectives for what a\npretrained LM should “know,” and thus naturally\nreach different conclusions. We believe that future\nstudies must reach consensus on standardized tasks\nand benchmarks, addressing questions like: What\ndegree of overlap between a pretraining corpus and\na knowledge probe is permissible, and how can\nthis be accurately uncovered and quantiﬁed? What\nlexical cues or correlations should be allowed in\nknowledge probes? Progress in this direction will\n1057\nTable 2: Taxonomy and representative examples of entity-level supervision in LMs, with evaluation tasks that\nhave been conducted in the referenced papers. Glossary of evaluation tasks: KP—knowledge probing; EL—entity\nlinking; ET—entity typing; RC—relation classiﬁcation; QA—question answering; GL—the General Language\nUnderstanding Evaluation or GLUE benchmark (Wang et al., 2019), which covers multiple subtasks.\nEntities as... Supervision strategy Representative examples Evaluation task(s)KP EL ET RC QA GL\nToken mention-spans (§ 4.1)Masked token prediction (Roberts et al., 2020; Guu et al., 2020) \u0013Contrastive learning (Xiong et al., 2020; Shen et al., 2020)\u0013 \u0013 \u0013\nText-to-KB links—late fusion (§ 4.2)Linking w/o external info (Broscheit, 2019; Ling et al., 2020)\u0013 \u0013Linking w/ textual metadata (Wu et al., 2020; De Cao et al., 2021)\u0013 \u0013 \u0013Linking w/ external embeddings (Zhang et al., 2019; Chen et al., 2020)\u0013 \u0013 \u0013 \u0013\nText-to-KB links—mid/early fusion (§ 4.3)Entity embedding retrieval (Peters et al., 2019; Févry et al., 2020)\u0013 \u0013 \u0013 \u0013 \u0013Treating entities as tokens (Yamada et al., 2020; Poerner et al., 2020)\u0013 \u0013 \u0013 \u0013 \u0013\nnot only further our understanding of the effects of\nword-level supervision on LM knowledge acquisi-\ntion, but will also provide appropriate yardsticks\nfor measuring the beneﬁts of targeted entity- and\nrelation-level supervision.\n4 Entity-level supervision\nWe next review entity-level supervision strategies\nfor LMs, most often toward improving perfor-\nmance in knowledge probes like LAMA (§ 3.1)\nand canonical NLP tasks like entity typing, entity\nlinking, and question answering. We roughly cate-\ngorize approaches from “least symbolic” to “most\nsymbolic.” On the former end of the spectrum, the\nLM is exposed to entity mentions in text but not\nrequired to link these mentions to an external entity\nbank (§ 4.1). On the latter end, the LM is trained\nto link mentions to the KB using late (§ 4.2) or\nmid-to-early fusion approaches (§ 4.3). Table 2\nprovides a taxonomy of supervision strategies for\nthis section with representative examples.\n4.1 Modeling entities without linking\nThe “least symbolic” entity supervision approaches\nthat we consider input textual contexts containing\nentity mention-spans to the LM, and incorporate\nthese mention-spans into their losses. However,\nthey do not require the LM to link these mentions\nto the KB’s entity set, so the LM is never directly\nexposed to the KB. Figures 3a and 3b provide exam-\nples of input and output for this class of approaches.\nMasking tokens in mention-spans and training\nLMs to predict these tokens may promote knowl-\nedge memorization (Sun et al., 2020). Roberts et al.\n(2020) investigate this strategy using a simple mask-\ning strategy whereby an LM is trained to predict\nthe tokens comprising named entities and dates in\ntext (Figure 3a, originally proposed by Guu et al.,\n2020). The authors ﬁnd that the largest (11 billion\nparameter) version of T5 generates exact-match\nanswers on open-domain question answering (QA)\nbenchmarks with higher accuracy than extractive\nsystems—even without access to external context\ndocuments, simulating a “closed-book” exam.\nContrastive learningtechniques, which have been\nused for LM supervision at the word and sentence\nlevel (Devlin et al., 2019), have also been devised\nfor supervision on entity mentions (Shen et al.,\n2020). For example, Xiong et al. (2020) replace\na proportion of entity mentions in the pretraining\ncorpus with the names of negatively-sampled en-\ntities of the same type, and train an LM to predict\nwhether the entity in the span has been replaced\n(Figure 3b). Although the previously discussed\nclosed-book T5 model (Roberts et al., 2020) out-\nperforms Xiong et al. (2020)’s open-book BERT\npretrained with contrastive entity replacement on\nopen-domain QA, the latter may generalize better:\nT5’s performance degrades considerably for facts\nnot observed during training, whereas open-book\napproaches appear more robust (Lewis et al., 2021).\n4.2 Linking with late fusion\nThe next-strongest level of entity supervision is\nto train the LM to link entity-centric textual con-\ntexts to a KB’s entity set E. Here, we cover late\nfusion approaches, which operate at the word level\nin terms of input to the LM and incorporate en-\ntities at the LM’s output layer only, as exempli-\nﬁed in Figure 3c. The simplest representatives\nof this category train LMs to match individual to-\nkens (Broscheit, 2019) or mentions (Ling et al.,\n2020) in a text corpus to an entity bank, without any\nexternal resources. The minimally “entity-aware”\nBERT proposed by Broscheit (2019), which adds\na single classiﬁcation layer on top of a pretrained\nBERT encoder, achieves competitive results with a\nstate-of-the-art specialized entity linking architec-\n1058\n(a) Mention-span masking\n (b) Contrastive learning\n (c) Linking—late fusion\n (d) Linking—early fusion\nFigure 3: Examples of entity-level supervision in LMs, ranging from “less symbolic” to “more symbolic.”\nture (Kolitsas et al., 2018).\nEntity meta-information such as names and de-\nscriptions are viable external resources for LM-\npowered entity linking (Botha et al., 2020). For\nexample, in zero-shot entity linking (Logeswaran\net al., 2019), textual mentions must be linked to\nentities unseen during training using only entity\ndescriptions as additional data. Here, competi-\ntive solutions train separate BERT models to se-\nlect and rank candidate entities by encoding their\ndescriptions (Logeswaran et al., 2019; Wu et al.,\n2020). More recently, encoder-decoder LMs have\nbeen trained to retrieve entities by generating their\nunique names (De Cao et al., 2021), which has the\nadvantage of scaling with the LM’s vocabulary size\n(usually tens of thousands) instead of the KB entity\nset size (potentially tens of millions). De Cao et al.\n(2021) achieve results competitive to discriminative\napproaches on entity linking and QA, suggesting\nthe potential of generative entity-aware LMs.\nExternal entity embeddings pretrained by a sepa-\nrate model have been used as strong sources of in-\nductive bias for LMs. For example, several variants\nof BERT further pretrain the base model by linearly\nfusing external entity embeddings with contextual\nword representations at the output of the BERT en-\ncoder (Zhang et al., 2019; He et al., 2020). BERT\nhas also been ﬁne-tuned to match its output token\nrepresentations to external entity embeddings for\nthe task of end-to-end entity linking (Chen et al.,\n2020). Such approaches rely heavily on the qual-\nity of the externally-learned embeddings, which is\nboth a strength and a drawback: Such embeddings\nmay contain useful implicit structural information\nabout the KB, but on the other hand may propagate\nerrors into the LM (Shen et al., 2020).\n4.3 Linking with middle or early fusion\nThe last and strongest category of entity supervi-\nsion techniques that we consider are also linking-\nbased, but fuse entity information at earlier stages\nof text encoding. Mid-fusion approaches retrieve\nexternal entity representations in between hidden\nlayers and re-contextualize them into the LM,\nwhereas early fusion approaches simply treat entity\nsymbols as tokens in the vocabulary. Figure 3d pro-\nvides an example of input/output for early fusion.\nRetrieving entity embeddings and integrating\nthem into an LM’s hidden word representations\nis a middle-fusion technique that has the advantage\nof modeling ﬂexibility: It allows the practitioner\nto choose where (i.e., at which layer) the entity\nembeddings are integrated, and how the entity em-\nbeddings are learned and re-contextualized into\nthe LM. Peters et al. (2019) integrate externally\npre-trained, frozen entity embeddings into BERT’s\nﬁnal hidden layers using a word-to-entity attention\nmechanism. Févry et al. (2020) learn the external\nentity embeddings jointly during pretraining, and\nperform the integration in BERT’s earlier hidden\nlayers using an attention-weighted sum. The lat-\nter approach is competitive with a 30×larger T5\nLM in closed-book QA (§ 4.1), suggesting that\nLMs and KB embeddings can be trained jointly to\nenhance and complement each other.\nTreating entities as “tokens” by appending spe-\ncial reserved entity symbols to the LM’s vocab-\nulary is the earliest of entity fusion approaches\n(Figure 3d). For instance, Yamada et al. (2020)\ninput entity “tokens” alongside textual contexts\nthat mention these entities to RoBERTa, and use\nspecialized word-to-entity and entity-to-entity at-\ntention matrices within its hidden layers. Other ap-\nproaches leave the base LM’s internal architecture\ncompletely unchanged and focus only on aligning\nthe LM’s word and entity embedding spaces at the\ninput level (Rosset et al., 2020; Poerner et al., 2020).\nNote, however, that this approach may signiﬁcantly\nenlarge the LM’s vocabulary. For example, plain\nBERT’s vocabulary is around 30k tokens, whereas\n1059\nTable 3: Taxonomy and representative examples of relation-level supervision in LMs, with evaluation tasks con-\nducted in the respective referenced papers. Glossary of evaluation tasks : KP—knowledge probing; ET—entity\ntyping; RC—relation classiﬁcation; QA—question answering; CR—compositional reasoning; KC—knowledge\nbase construction; TG—text generation; GL—the GLUE family of language tasks (Wang et al., 2019).\nRelations as... Supervision strategy Representative examples Evaluation task(s)KP ET RC QA CR KC TG GL\nTemplated sentences (§ 5.1)Lexicalizing triples (Thorne et al., 2021; Guan et al., 2020) \u0013 \u0013 \u0013Lexicalizing paths (Clark et al., 2020; Talmor et al., 2020a,b)\u0013 \u0013\nLinearized sequences (§ 5.2)Training on triple sequences (Yao et al., 2019; Agarwal et al., 2021)\u0013 \u0013 \u0013 \u0013Injecting triples into text (Liu et al., 2020) \u0013\nDedicated embeddings (§ 5.3)Pooling entity representations (Baldini Soares et al., 2019; Qin et al., 2021)\u0013 \u0013 \u0013Embedding relations externally (Wang et al., 2021d; Daza et al., 2021)\u0013 \u0013 \u0013 \u0013Treating relations as tokens (Bosselut et al., 2019; Hwang et al., 2021) \u0013\nEnglish Wikipedia has around 6 million entities.\nThis can make pretraining on a larger vocabulary\nexpensive in terms of both time and memory us-\nage (Yamada et al., 2020; Dufter et al., 2021).\n4.4 Summary and outlook\nThe literature on entity supervision in LMs is\ngrowing rapidly. In line with recent trends in\nNLP (Khashabi et al., 2020), a growing number\nof entity supervision strategies use generative mod-\nels (Roberts et al., 2020; De Cao et al., 2021),\nwhich are attractive because they allow for a high\nlevel of ﬂexibility in output and circumvent the\nneed for classiﬁcation over potentially millions of\nentities. However, some studies ﬁnd that generative\nmodels currently do not perform well beyond what\nthey have memorized from the training set (Wang\net al., 2021b; Lewis et al., 2021). These ﬁndings\nsuggest that storing some entity knowledge exter-\nnally (e.g., in a dense memory, Févry et al., 2020)\nmay be more robust, for example by allowing for ef-\nﬁcient updates to the LM’s knowledge (Verga et al.,\n2020). We believe that future work will need to\nanalyze the tradeoffs between fully-parametric and\nretrieval-based entity modeling in terms of pure\naccuracy, parameter and training efﬁciency, and\nability to generalize beyond the training set.\n5 Relation-level supervision\nFinally, we consider methods that utilize KB triples\nor paths to supervise LMs for complex, often com-\npositional tasks like relation classiﬁcation, text gen-\neration, and rule-based inference. We again orga-\nnize methods in the order of less to more symbolic.\nIn this context, less symbolic approaches treat\ntriples and paths as fully natural language (§ 5.1,\n5.2). By contrast, more symbolic approaches learn\ndistinct embeddings for relation types in the KB\n(§ 5.3). Table 3 provides a taxonomy of this section\nwith representative examples and evaluation tasks.\n5.1 Relations as templated assertions\nTemplate-based lexicalization is a popular relation\nsupervision strategy that does not directly expose\nthe LM to the KB. Similar to how KB queries are\nconverted to cloze prompts for knowledge prob-\ning (§ 3.1), triples are ﬁrst converted to natural\nlanguage assertions using relation templates, usu-\nally handcrafted. These assertions are then fed as\ninput to the LM, which is trained with any num-\nber of task-speciﬁc losses. Figure 4 provides an\ninput/output example for this class of approach.\nLexicalized triples from Wikidata have been used\nas LM training data in proof-of-concept studies\ndemonstrating that LMs can serve as natural lan-\nguage querying interfaces to KBs under controlled\nconditions (Heinzerling and Inui, 2021). A promis-\ning approach in this direction uses encoder-decoder\nLMs to generate answer sets to natural language\nqueries over lexicalized Wikidata triples (Thorne\net al., 2020, 2021), toward handling multi-answer\nKB queries with LMs—thus far an understudied\ntask in the LM knowledge querying literature.\nOther approaches convert KB triples to sentences\nusing relation templates in order to construct task-\nspeciﬁc training datasets for improved performance\nin, e.g., story generation (Guan et al., 2020), com-\nmonsense QA (Ye et al., 2020; Ma et al., 2021),\nand relation classiﬁcation (Bouraoui et al., 2020).\nWhile most of these approaches rely on template\nhandcrafting, a few automatically mine templates\nusing distant supervision on Wikipedia, achieving\ncompetitive results in tasks like relation classiﬁ-\ncation (Bouraoui et al., 2020) and commonsense\nQA (Ye et al., 2020).\nCompositional paths spanning multiple atoms of\nsymbolic knowledge may also be lexicalized and\ninput to an LM (Lauscher et al., 2020; Talmor\net al., 2020a) in order to train LMs for soft com-\n1060\nFigure 4: Strategies for representing relations as se-\nquences: Templating (§ 5.1) and linearization (§ 5.2).\npositional reasoning (Clark et al., 2020; Talmor\net al., 2020b). Notably, when RoBERTa is ﬁne-\ntuned on sentences expressing (real or synthetic)\nfacts and rules from a KB, it can answer entailment\nqueries with high accuracy (Clark et al., 2020; Tal-\nmor et al., 2020b). However, as Clark et al. (2020)\nnote, these results do not necessarily conﬁrm that\nLMs can “reason,” but rather that they can at least\nemulate soft reasoning—raising an open question\nabout how to develop probes and metrics to verify\nwhether LMs can actually reason compositionally.\n5.2 Linearizing KB triples\nThe main advantage of templating is that it con-\nverts symbolic triples into sequences, which can\nbe straightforwardly input to LMs. However, hand-\ncrafting templates is a manual process, and distant\nsupervision can be noisy. To maintain the advan-\ntage of templates while avoiding the drawbacks,\ntriples can alternatively be fed to an LM by lineariz-\ning them—that is, ﬂattening the subject, relation,\nand object into an input sequence (Figure 4). With\nlinearization, relation-level supervision becomes\nas simple as feeding the linearized sequences\nto the LM and training again with task-speciﬁc\nlosses (Yao et al., 2019; Kim et al., 2020; Ribeiro\net al., 2020; Wang et al., 2021a) or injecting the\nsequences into the pretraining corpus(Liu et al.,\n2020). A notable recent example of the former\napproach (Agarwal et al., 2021) trains T5 on lin-\nearized Wikidata triples in order to generate fully\nnatural language versions of those triples. These\nverbalized triples are used as retrieval “documents”\nfor improved LM-based QA over traditional doc-\nument corpora; note, however, that they can also\nbe used as LM training data for other downstream\ntasks in place of handcrafted templates (§ 5.1).\n5.3 Relations as dedicated embeddings\nThe strategies discussed thus far treat KB triples\nand paths as natural language sequences. A “more\nsymbolic” approach is to represent KB relation\ntypes with dedicated embeddings, and integrate\nthese embeddings into the LM using late, middle,\nor early fusion approaches. Figures 5a and 5b pro-\nvide input/output examples for late fusion, whereby\nrelation textual contexts are input to the LM, and\nrelation embeddings are constructed or integrated\nat the LM’s output. Figure 5c exempliﬁes early fu-\nsion, whereby relations are treated as input tokens.\nContextual representations of entity mention-\nspans may be pooled at an LM’s output layer to\nrepresent a relation (Wang et al., 2021c; Yu et al.,\n2020). For example, Baldini Soares et al. (2019)\nconcatenate the contextual representations of spe-\ncial entity-start markers inserted adjacent to textual\nentity mentions, and ﬁne-tune BERT to output sim-\nilar relation representations for statements ranging\nover the same entity pairs (Figure 5a). This ap-\nproach, which proved highly successful for relation\nclassiﬁcation, has been applied to the same task\nin languages beyond English (Köksal and Özgür,\n2020; Ananthram et al., 2020), and as an additional\nLM pretraining objective (Qin et al., 2021).\nNon-contextual relation embeddings may be\nlearned by deﬁning a separate relation embedding\nmatrix with |R|rows and fusing this matrix into\nthe LM. One advantage of this approach, similar\nto methods for retrieving external entity embed-\ndings (§ 4.3), is that it supports fusion at both the\nlate (Wang et al., 2021d; Daza et al., 2021) and\nmiddle (Liu et al., 2021c) stages. As an exam-\nple of the former, Wang et al. (2021d) propose\nan LM pretraining objective whereby textual de-\nscriptions of KB entities are input to and encoded\nby an LM, then combined with externally-learned\nrelation embeddings at the output using a link pre-\ndiction loss (Figure 5b). Combined with standard\nword-level language modeling objectives, this ap-\nproach enables generalization across both sentence-\nlevel tasks like relation classiﬁcation, and graph-\nlevel tasks like KB completion.\nTreating relations as “tokens,” toward early fu-\nsion of relations in LMs, is achieved by append-\ning the KB’s relation types to the LM’s vocabu-\nlary (Figure 5c). A notable instantiation of this\napproach is the COMET commonsense KB con-\nstruction framework (Bosselut et al., 2019; Hwang\net al., 2021; Jiang et al., 2021). Given a subject\nphrase/relation token as input, COMET ﬁne-tunes\nan LM to generate object phrases. COMET demon-\n1061\n(a) Late fusion—pooling\n (b) Late fusion—external embeddings\n (c) Early fusion—relations as “tokens”\nFigure 5: Examples of relation supervision strategies that incorporate dedicated embeddings of relation types.\nstrates promising improvements over 400×larger\nLMs not trained for KB construction (Hwang et al.,\n2021). However, templating (§ 5.1) may yield bet-\nter results than adding special tokens to the vocab-\nulary when the COMET framework is trained and\ntested in a few-shot setting (Da et al., 2021).\n5.4 Summary and outlook\nRelation-level supervision in LMs is exciting be-\ncause it enables a wide variety of complex NLP\ntasks (Table 3). A unifying theme across many of\nthese tasks is that of compositionality, or the idea\nthat smaller “building blocks” of evidence can be\ncombined to arrive at novel knowledge. As compo-\nsitionality is thought to be key to machine general-\nization (Lake et al., 2017), we believe that further\nfundamental research in understanding and improv-\ning LMs’ soft “reasoning” skills (Clark et al., 2020;\nTalmor et al., 2020b, § 5.1) will be crucial.\nFinally, while most of the open directions we dis-\ncuss involve improving LM knowledge with KBs,\nwe ﬁnd the direction of generating KBs with LMs\nequally intriguing—reﬂecting the fact that LMs\nand KBs can complement each other in “both direc-\ntions,” as automating and scaling out the construc-\ntion of KBs will ultimately provide LMs with more\nrelational training data. The generative COMET\nframework (Bosselut et al., 2019, § 5.3) has made\ninroads in commonsense KB construction, but the\nsame progress has not yet been observed for en-\ncyclopedic knowledge. The latter entails unique\nchallenges: Whereas commonsense entities are not\ndisambiguated and triples need only be plausible\nrather than always true, encyclopedic entities are\nusually disambiguated and facts are often binary\ntrue/false. We look forward to future research that\naddresses these challenges, perhaps building on\nrecent breakthroughs in generative factual entity\nretrieval (De Cao et al., 2021, § 4.2).\n6 Conclusion and vision\nIn this review, we provide an overview of how LMs\nmay acquire relational world knowledge during\npretraining and ﬁne-tuning. We propose a novel\ntaxonomy that classiﬁes knowledge representation\nmethodologies based on the level of KB supervi-\nsion provided to an LM, from no explicit supervi-\nsion at all to entity- and relation-level supervision.\nIn the future, we envision a stronger synergy\nbetween the perspectives and tools from the lan-\nguage modeling and knowledge bases communities.\nIn particular, we expect powerful and expressive\nLMs, which are actively being developed in NLP,\nto be increasingly combined with large-scale KB\nresources to improve their knowledge recall and\nreasoning abilities. On the converse, we expect\nsuch KB resources to be increasingly generated di-\nrectly by LMs. Within both of these directions, we\nhope that future work will continue to explore the\nthemes discussed in this paper, in particular that\nof delineating and testing KB-level memorization\nversus generalization in LMs. We also expect that\nmore standardized benchmarks and tasks for evalu-\nating LM knowledge will be developed, a direction\nthat has recently seen some progress (Petroni et al.,\n2021). As research at the intersection of LMs and\nKBs is rapidly progressing, we look forward to\nnew research that better develops and combines the\nstrengths of both knowledge representations.\nAcknowledgements\nWe thank the reviewers for their thoughtful feed-\nback. This material is based upon work supported\nby the National Science Foundation under a Grad-\nuate Research Fellowship and CAREER Grant\nNo. IIS 1845491, the Advanced Machine Learning\nCollaborative Grant from Procter & Gamble, and\nan Amazon faculty award.\n1062\nReferences\nOshin Agarwal, Heming Ge, Siamak Shakeri, and\nRami Al-Rfou. 2021. Large scale knowledge graph\nbased synthetic corpus generation for knowledge-\nenhanced language model pre-training. In Proceed-\nings of the 2021 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics.\nAmith Ananthram, Emily Allaway, and Kathleen McK-\neown. 2020. Event-guided denoising for multilin-\ngual relation learning. In Proceedings of the 28th\nInternational Conference on Computational Linguis-\ntics, pages 1505–1512, Barcelona, Spain (Online).\nInternational Committee on Computational Linguis-\ntics.\nLivio Baldini Soares, Nicholas FitzGerald, Jeffrey\nLing, and Tom Kwiatkowski. 2019. Matching the\nblanks: Distributional similarity for relation learn-\ning. In Proceedings of the 57th Annual Meeting\nof the Association for Computational Linguistics ,\npages 2895–2905, Florence, Italy. Association for\nComputational Linguistics.\nMichele Banko and Oren Etzioni. 2008. The tradeoffs\nbetween open and traditional relation extraction. In\nProceedings of ACL-08: HLT, pages 28–36, Colum-\nbus, Ohio. Association for Computational Linguis-\ntics.\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim\nSturge, and Jamie Taylor. 2008. Freebase: a col-\nlaboratively created graph database for structuring\nhuman knowledge. In SIGMOD, pages 1247–1250.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Celikyilmaz, and Yejin Choi.\n2019. COMET: Commonsense transformers for au-\ntomatic knowledge graph construction. In Proceed-\nings of the 57th Annual Meeting of the Association\nfor Computational Linguistics , pages 4762–4779,\nFlorence, Italy. Association for Computational Lin-\nguistics.\nJan A. Botha, Zifei Shan, and Daniel Gillick. 2020. En-\ntity Linking in 100 Languages. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 7833–\n7845, Online. Association for Computational Lin-\nguistics.\nZied Bouraoui, Jose Camacho-Collados, and Steven\nSchockaert. 2020. Inducing relational knowledge\nfrom bert. In Proceedings of the AAAI Conference\non Artiﬁcial Intelligence , volume 34, pages 7456–\n7463.\nSamuel Broscheit. 2019. Investigating entity knowl-\nedge in BERT with simple neural end-to-end en-\ntity linking. In Proceedings of the 23rd Confer-\nence on Computational Natural Language Learning\n(CoNLL), pages 677–685, Hong Kong, China. Asso-\nciation for Computational Linguistics.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. In Advances in Neural Information Pro-\ncessing Systems 33 pre-proceedings.\nBoxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingy-\nong Yan, Meng Liao, Tong Xue, and Jin Xu. 2021.\nKnowledgeable or educated guess? revisiting lan-\nguage models as knowledge bases. In Proceed-\nings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (Volume 1: Long Papers), pages 1860–1874,\nOnline. Association for Computational Linguistics.\nHaotian Chen, Xi Li, Andrej Zukov Gregoric, and Sahil\nWadhwa. 2020. Contextualized end-to-end neural\nentity linking. In Proceedings of the 1st Confer-\nence of the Asia-Paciﬁc Chapter of the Association\nfor Computational Linguistics and the 10th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing, pages 637–642, Suzhou, China. Associa-\ntion for Computational Linguistics.\nPeter Clark, Oyvind Tafjord, and Kyle Richardson.\n2020. Transformers as soft reasoners over language.\nIn Proceedings of the Twenty-Ninth International\nJoint Conference on Artiﬁcial Intelligence , pages\n3882–3890.\nPedro Colon-Hernandez, Catherine Havasi, Jason\nAlonso, Matthew Huggins, and Cynthia Breazeal.\n2021. Combining pre-trained language mod-\nels and structured knowledge. arXiv preprint\narXiv:2101.12294.\nJeff Da, Ronan Le Bras, Ximing Lu, Yejin Choi, and\nAntoine Bosselut. 2021. Understanding few-shot\ncommonsense knowledge models. arXiv preprint\narXiv:2101.00297.\nJeff Da and Jungo Kasai. 2019. Cracking the contex-\ntual commonsense code: Understanding common-\nsense reasoning aptitude of deep contextual repre-\nsentations. In Proceedings of the First Workshop on\nCommonsense Inference in Natural Language Pro-\ncessing, pages 1–12, Hong Kong, China. Associa-\ntion for Computational Linguistics.\nRandall Davis, Howard Shrobe, and Peter Szolovits.\n1993. What is a knowledge representation? AI mag-\nazine, 14(1):17–17.\nJoe Davison, Joshua Feldman, and Alexander Rush.\n2019. Commonsense knowledge mining from pre-\ntrained models. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 1173–1178, Hong Kong, China. As-\nsociation for Computational Linguistics.\n1063\nDaniel Daza, Michael Cochez, and Paul Groth. 2021.\nInductive entity representations from text via link\nprediction. In Proceedings of the Web Conference\n2021, pages 798–808.\nNicola De Cao, Gautier Izacard, Sebastian Riedel, and\nFabio Petroni. 2021. Autoregressive entity retrieval.\nIn International Conference on Learning Represen-\ntations.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171–4186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nPhilipp Dufter, Nora Kassner, and Hinrich Schütze.\n2021. Static embeddings as efﬁcient knowledge\nbases? In Proceedings of the 2021 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics, Online. Association for\nComputational Linguistics.\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhi-\nlasha Ravichander, Eduard Hovy, Hinrich Schütze,\nand Yoav Goldberg. 2021. Measuring and im-\nproving consistency in pretrained language models.\narXiv preprint arXiv:2102.01017.\nAnthony Fader, Stephen Soderland, and Oren Etzioni.\n2011. Identifying relations for open information ex-\ntraction. In Proceedings of the 2011 Conference on\nEmpirical Methods in Natural Language Processing,\npages 1535–1545, Edinburgh, Scotland, UK. Associ-\nation for Computational Linguistics.\nThibault Févry, Livio Baldini Soares, Nicholas FitzGer-\nald, Eunsol Choi, and Tom Kwiatkowski. 2020. En-\ntities as experts: Sparse memory access with entity\nsupervision. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Process-\ning (EMNLP) , pages 4937–4951, Online. Associa-\ntion for Computational Linguistics.\nJian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, and\nMinlie Huang. 2020. A knowledge-enhanced pre-\ntraining model for commonsense story generation.\nTransactions of the Association for Computational\nLinguistics, 8:93–108.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pa-\nsupat, and Mingwei Chang. 2020. Retrieval aug-\nmented language model pre-training. In Inter-\nnational Conference on Machine Learning , pages\n3929–3938. PMLR.\nAlon Y Halevy, Oren Etzioni, AnHai Doan, Zachary G\nIves, Jayant Madhavan, Luke K McDowell, and Igor\nTatarinov. 2003. Crossing the structure chasm. In\nConference on Innovative Data Systems Research.\nAdi Haviv, Jonathan Berant, and Amir Globerson.\n2021. BERTese: Learning to speak to BERT. In\nProceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 3618–3623, Online.\nAssociation for Computational Linguistics.\nBin He, Di Zhou, Jinghui Xiao, Xin Jiang, Qun Liu,\nNicholas Jing Yuan, and Tong Xu. 2020. BERT-\nMK: Integrating graph contextualized knowledge\ninto pre-trained language models. In Findings of the\nAssociation for Computational Linguistics: EMNLP\n2020, pages 2281–2290, Online. Association for\nComputational Linguistics.\nBenjamin Heinzerling and Kentaro Inui. 2021. Lan-\nguage models as knowledge bases: On entity\nrepresentations, storage capacity, and paraphrased\nqueries. In Proceedings of the 16th Conference of\nthe European Chapter of the Association for Com-\nputational Linguistics: Main Volume , pages 1772–\n1791, Online. Association for Computational Lin-\nguistics.\nJena D Hwang, Chandra Bhagavatula, Ronan Le Bras,\nJeff Da, Keisuke Sakaguchi, Antoine Bosselut, and\nYejin Choi. 2021. Comet-atomic 2020: On symbolic\nand neural commonsense knowledge graphs. In Pro-\nceedings of the AAAI Conference on Artiﬁcial Intel-\nligence.\nFilip Ilievski, Pedro Szekely, and Bin Zhang. 2021.\nCskg: The commonsense knowledge graph. Euro-\npean Semantic Web Conference.\nLiwei Jiang, Antoine Bosselut, Chandra Bhagavatula,\nand Yejin Choi. 2021. \"i’m not mad\": Common-\nsense implications of negation and contradiction. In\nProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics, Online. Association for Computa-\ntional Linguistics.\nZhengbao Jiang, Antonios Anastasopoulos, Jun Araki,\nHaibo Ding, and Graham Neubig. 2020a. X-\nFACTR: Multilingual factual knowledge retrieval\nfrom pretrained language models. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 5943–\n5959, Online. Association for Computational Lin-\nguistics.\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020b. How can we know what language\nmodels know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nNora Kassner, Philipp Dufter, and Hinrich Schütze.\n2021. Multilingual lama: Investigating knowledge\nin multilingual pretrained language models. In The\n16th Conference of the European Chapter of the As-\nsociation for Computational Linguistics.\n1064\nNora Kassner, Benno Krojer, and Hinrich Schütze.\n2020. Are pretrained language models symbolic\nreasoners over knowledge? In Proceedings of\nthe 24th Conference on Computational Natural Lan-\nguage Learning , pages 552–564, Online. Associa-\ntion for Computational Linguistics.\nNora Kassner and Hinrich Schütze. 2020. Negated and\nmisprimed probes for pretrained language models:\nBirds can talk, but cannot ﬂy. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 7811–7818, Online. As-\nsociation for Computational Linguistics.\nDaniel Khashabi, Sewon Min, Tushar Khot, Ashish\nSabharwal, Oyvind Tafjord, Peter Clark, and Han-\nnaneh Hajishirzi. 2020. UNIFIEDQA: Crossing for-\nmat boundaries with a single QA system. In Find-\nings of the Association for Computational Linguis-\ntics: EMNLP 2020 , pages 1896–1907, Online. As-\nsociation for Computational Linguistics.\nBosung Kim, Taesuk Hong, Youngjoong Ko, and\nJungyun Seo. 2020. Multi-task learning for knowl-\nedge graph completion with pre-trained language\nmodels. In Proceedings of the 28th International\nConference on Computational Linguistics , pages\n1737–1743, Barcelona, Spain (Online). International\nCommittee on Computational Linguistics.\nAbdullatif Köksal and Arzucan Özgür. 2020. The\nRELX dataset and matching the multilingual blanks\nfor cross-lingual relation classiﬁcation. In Findings\nof the Association for Computational Linguistics:\nEMNLP 2020, pages 340–350, Online. Association\nfor Computational Linguistics.\nNikolaos Kolitsas, Octavian-Eugen Ganea, and\nThomas Hofmann. 2018. End-to-end neural entity\nlinking. In Proceedings of the 22nd Conference\non Computational Natural Language Learning ,\npages 519–529, Brussels, Belgium. Association for\nComputational Linguistics.\nBrenden M Lake, Tomer D Ullman, Joshua B Tenen-\nbaum, and Samuel J Gershman. 2017. Building ma-\nchines that learn and think like people. Behavioral\nand brain sciences, 40.\nAnne Lauscher, Olga Majewska, Leonardo F. R.\nRibeiro, Iryna Gurevych, Nikolai Rozanov, and\nGoran Glavaš. 2020. Common sense or world\nknowledge? investigating adapter-based knowledge\ninjection into pretrained transformers. In Proceed-\nings of Deep Learning Inside Out (DeeLIO): The\nFirst Workshop on Knowledge Extraction and Inte-\ngration for Deep Learning Architectures, pages 43–\n49, Online. Association for Computational Linguis-\ntics.\nDouglas B Lenat. 1995. Cyc: A large-scale investment\nin knowledge infrastructure. Communications of the\nACM, 38(11):33–38.\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer\nLevy, Veselin Stoyanov, and Luke Zettlemoyer.\n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation,\nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 7871–7880, Online. Association\nfor Computational Linguistics.\nPatrick Lewis, Pontus Stenetorp, and Sebastian Riedel.\n2021. Question and answer test-train overlap in\nopen-domain question answering datasets. In Pro-\nceedings of the 16th Conference of the European\nChapter of the Association for Computational Lin-\nguistics: Main Volume , pages 1000–1008, Online.\nAssociation for Computational Linguistics.\nBill Yuchen Lin, Seyeon Lee, Rahul Khanna, and Xi-\nang Ren. 2020. Birds have four legs?! NumerSense:\nProbing Numerical Commonsense Knowledge of\nPre-Trained Language Models. In Proceedings of\nthe 2020 Conference on Empirical Methods in Nat-\nural Language Processing (EMNLP) , pages 6862–\n6868, Online. Association for Computational Lin-\nguistics.\nJeffrey Ling, Nicholas FitzGerald, Zifei Shan,\nLivio Baldini Soares, Thibault Févry, David Weiss,\nand Tom Kwiatkowski. 2020. Learning cross-\ncontext entity representations from text. arXiv\npreprint arXiv:2001.03765.\nHugo Liu and Push Singh. 2004. Conceptnet—a practi-\ncal commonsense reasoning tool-kit. BT technology\njournal, 22(4):211–226.\nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,\nHiroaki Hayashi, and Graham Neubig. 2021a. Pre-\ntrain, prompt, and predict: A systematic survey of\nprompting methods in natural language processing.\narXiv preprint arXiv:2107.13586.\nWeijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju,\nHaotang Deng, and Ping Wang. 2020. K-bert:\nEnabling language representation with knowledge\ngraph. In Proceedings of the AAAI Conference on\nArtiﬁcial Intelligence, volume 34, pages 2901–2908.\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding,\nYujie Qian, Zhilin Yang, and Jie Tang. 2021b. Gpt\nunderstands, too. arXiv preprint arXiv:2103.10385.\nYe Liu, Yao Wan, Lifang He, Hao Peng, and Philip S\nYu. 2021c. Kg-bart: Knowledge graph-augmented\nbart for generative commonsense reasoning. In Pro-\nceedings of the AAAI Conference on Artiﬁcial Intel-\nligence.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\n1065\nLajanugen Logeswaran, Ming-Wei Chang, Kenton Lee,\nKristina Toutanova, Jacob Devlin, and Honglak Lee.\n2019. Zero-shot entity linking by reading entity de-\nscriptions. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 3449–3460, Florence, Italy. Association for\nComputational Linguistics.\nKaixin Ma, Filip Ilievski, Jonathan Francis, Yonatan\nBisk, Eric Nyberg, and Alessandro Oltramari. 2021.\nKnowledge-driven data construction for zero-shot\nevaluation in commonsense question answering. In\nProceedings of the AAAI Conference on Artiﬁcial In-\ntelligence.\nMarvin Minsky. 1974. A framework for representing\nknowledge.\nEthan Perez, Douwe Kiela, and Kyunghyun Cho. 2021.\nTrue few-shot learning with language models. arXiv\npreprint arXiv:2105.11447.\nMatthew E. Peters, Mark Neumann, Robert Logan, Roy\nSchwartz, Vidur Joshi, Sameer Singh, and Noah A.\nSmith. 2019. Knowledge enhanced contextual word\nrepresentations. In Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 43–54, Hong Kong, China. Associ-\nation for Computational Linguistics.\nFabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim\nRocktäschel, Yuxiang Wu, Alexander H. Miller, and\nSebastian Riedel. 2020. How context affects lan-\nguage models’ factual predictions. In Automated\nKnowledge Base Construction.\nFabio Petroni, Aleksandra Piktus, Angela Fan, Patrick\nLewis, Majid Yazdani, Nicola De Cao, James\nThorne, Yacine Jernite, Vladimir Karpukhin, Jean\nMaillard, Vassilis Plachouras, Tim Rocktäschel, and\nSebastian Riedel. 2021. KILT: a benchmark for\nknowledge intensive language tasks. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies , pages 2523–2544,\nOnline. Association for Computational Linguistics.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Confer-\nence on Natural Language Processing (EMNLP-\nIJCNLP), pages 2463–2473, Hong Kong, China. As-\nsociation for Computational Linguistics.\nNina Poerner, Ulli Waltinger, and Hinrich Schütze.\n2020. E-BERT: Efﬁcient-yet-effective entity em-\nbeddings for BERT. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2020 ,\npages 803–818, Online. Association for Computa-\ntional Linguistics.\nGuanghui Qin and Jason Eisner. 2021. Learning how\nto ask: Querying LMs with mixtures of soft prompts.\nIn Proceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 5203–5212, Online. Association for Compu-\ntational Linguistics.\nYujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu,\nPeng Li, Heng Ji, Minlie Huang, Maosong Sun, and\nJie Zhou. 2021. ERICA: Improving entity and re-\nlation understanding for pre-trained language mod-\nels via contrastive learning. In Proceedings of the\n59th Annual Meeting of the Association for Compu-\ntational Linguistics and the 11th International Joint\nConference on Natural Language Processing (Vol-\nume 1: Long Papers), pages 3350–3363, Online. As-\nsociation for Computational Linguistics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. Journal of Machine Learning Research ,\n21:1–67.\nLeonardo FR Ribeiro, Martin Schmitt, Hinrich Schütze,\nand Iryna Gurevych. 2020. Investigating pretrained\nlanguage models for graph-to-text generation. arXiv\npreprint arXiv:2007.08426.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the param-\neters of a language model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5418–5426,\nOnline. Association for Computational Linguistics.\nCorby Rosset, Chenyan Xiong, Minh Phan, Xia\nSong, Paul Bennett, and Saurabh Tiwary. 2020.\nKnowledge-aware language model pretraining.\narXiv preprint arXiv:2007.00655.\nMaarten Sap, Ronan Le Bras, Emily Allaway, Chan-\ndra Bhagavatula, Nicholas Lourie, Hannah Rashkin,\nBrendan Roof, Noah A Smith, and Yejin Choi. 2019.\nAtomic: An atlas of machine commonsense for if-\nthen reasoning. In Proceedings of the AAAI Con-\nference on Artiﬁcial Intelligence , volume 33, pages\n3027–3035.\nTao Shen, Yi Mao, Pengcheng He, Guodong Long,\nAdam Trischler, and Weizhu Chen. 2020. Exploit-\ning structured knowledge in text via graph-guided\nrepresentation learning. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 8980–8994, On-\nline. Association for Computational Linguistics.\n1066\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV ,\nEric Wallace, and Sameer Singh. 2020. AutoPrompt:\nEliciting Knowledge from Language Models with\nAutomatically Generated Prompts. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n4222–4235, Online. Association for Computational\nLinguistics.\nVered Shwartz, Peter West, Ronan Le Bras, Chandra\nBhagavatula, and Yejin Choi. 2020. Unsupervised\ncommonsense question answering with self-talk. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 4615–4629, Online. Association for Computa-\ntional Linguistics.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of gen-\neral knowledge. In Proceedings of the AAAI Confer-\nence on Artiﬁcial Intelligence, volume 31.\nYu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao\nTian, Hua Wu, and Haifeng Wang. 2020. Ernie 2.0:\nA continual pre-training framework for language un-\nderstanding. In Proceedings of the AAAI Conference\non Artiﬁcial Intelligence , volume 34, pages 8968–\n8975.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020a. olmpics-on what language\nmodel pre-training captures. Transactions of the As-\nsociation for Computational Linguistics, 8:743–758.\nAlon Talmor, Oyvind Tafjord, Peter Clark, Yoav Gold-\nberg, and Jonathan Berant. 2020b. Leap-of-thought:\nTeaching pre-trained models to systematically rea-\nson over implicit knowledge. In 34th Conference\non Neural Information Processing Systems.\nAlexandre Tamborrino, Nicola Pellicanò, Baptiste Pan-\nnier, Pascal V oitot, and Louise Naudin. 2020. Pre-\ntraining is (almost) all you need: An application\nto commonsense reasoning. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 3878–3887, Online. As-\nsociation for Computational Linguistics.\nWilson L Taylor. 1953. “cloze procedure”: A new\ntool for measuring readability. Journalism quar-\nterly, 30(4):415–433.\nJames Thorne, Majid Yazdani, Marzieh Saeidi, Fab-\nrizio Silvestri, Sebastian Riedel, and Alon Halevy.\n2020. From natural language processing to neural\ndatabases. Proceedings of the VLDB Endowment ,\n14(6):1033–1039.\nJames Thorne, Majid Yazdani, Marzieh Saeidi, Fab-\nrizio Silvestri, Sebastian Riedel, and Alon Halevy.\n2021. Database reasoning over text. In Proceed-\nings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (Volume 1: Long Papers), pages 3091–3104,\nOnline. Association for Computational Linguistics.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Proceedings of the 31st International\nConference on Neural Information Processing Sys-\ntems, pages 6000–6010.\nPat Verga, Haitian Sun, Livio Baldini Soares, and\nWilliam W Cohen. 2020. Facts as experts: Adapt-\nable and interpretable neural memory over symbolic\nknowledge. arXiv preprint arXiv:2007.00849.\nDenny Vrande ˇci´c and Markus Krötzsch. 2014. Wiki-\ndata: a free collaborative knowledgebase. Commu-\nnications of the ACM, 57(10):78–85.\nAlex Wang, Amanpreet Singh, Julian Michael, Felix\nHill, Omer Levy, and Samuel R Bowman. 2019.\nGlue: A multi-task benchmark and analysis platform\nfor natural language understanding. In 7th Inter-\nnational Conference on Learning Representations,\nICLR 2019.\nBo Wang, Tao Shen, Guodong Long, Tianyi Zhou,\nYing Wang, and Yi Chang. 2021a. Structure-\naugmented text representation learning for efﬁcient\nknowledge graph completion. In Proceedings of the\nWeb Conference 2021, pages 1737–1748.\nCunxiang Wang, Pai Liu, and Yue Zhang. 2021b.\nCan generative pre-trained language models serve as\nknowledge bases for closed-book QA? In Proceed-\nings of the 59th Annual Meeting of the Association\nfor Computational Linguistics and the 11th Interna-\ntional Joint Conference on Natural Language Pro-\ncessing (Volume 1: Long Papers), pages 3241–3251,\nOnline. Association for Computational Linguistics.\nRuize Wang, Duyu Tang, Nan Duan, Zhongyu Wei,\nXuanjing Huang, Jianshu Ji, Guihong Cao, Daxin\nJiang, and Ming Zhou. 2021c. K-adapter: Infusing\nknowledge into pre-trained models with adapters. In\nFindings of the Association for Computational Lin-\nguistics: ACL/IJCNLP 2021, Online Event, August\n1-6, 2021 , volume ACL/IJCNLP 2021 of Findings\nof ACL, pages 1405–1418. Association for Compu-\ntational Linguistics.\nXiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan\nZhang, Zhiyuan Liu, Juanzi Li, and Jian Tang.\n2021d. KEPLER: A uniﬁed model for knowledge\nembedding and pre-trained language representation.\nTrans. Assoc. Comput. Linguistics, 9:176–194.\nGerhard Weikum, Xin Luna Dong, Simon Razniewski,\nand Fabian M. Suchanek. 2021. Machine knowl-\nedge: Creation and curation of comprehensive\nknowledge bases. Found. Trends Databases, 10(2-\n4):108–490.\nLedell Wu, Fabio Petroni, Martin Josifoski, Sebastian\nRiedel, and Luke Zettlemoyer. 2020. Scalable zero-\nshot entity linking with dense entity retrieval. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 6397–6407, Online. Association for Computa-\ntional Linguistics.\n1067\nWenhan Xiong, Jingfei Du, William Yang Wang, and\nVeselin Stoyanov. 2020. Pretrained encyclopedia:\nWeakly supervised knowledge-pretrained language\nmodel. In International Conference on Learning\nRepresentations.\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki\nTakeda, and Yuji Matsumoto. 2020. LUKE: Deep\ncontextualized entity representations with entity-\naware self-attention. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 6442–6454, On-\nline. Association for Computational Linguistics.\nLiang Yao, Chengsheng Mao, and Yuan Luo. 2019. Kg-\nbert: Bert for knowledge graph completion. arXiv\npreprint arXiv:1909.03193.\nZhi-Xiu Ye, Qian Chen, Wen Wang, and Zhen-Hua\nLing. 2020. Align, mask and select: A simple\nmethod for incorporating commonsense knowledge\ninto language representation models. arXiv preprint\narXiv:1908.06725.\nDonghan Yu, Chenguang Zhu, Yiming Yang, and\nMichael Zeng. 2020. Jaket: Joint pre-training\nof knowledge graph and language understanding.\narXiv preprint arXiv:2010.00796.\nZhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang,\nMaosong Sun, and Qun Liu. 2019. ERNIE: En-\nhanced language representation with informative en-\ntities. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguis-\ntics, pages 1441–1451, Florence, Italy. Association\nfor Computational Linguistics.\nZexuan Zhong, Dan Friedman, and Danqi Chen. 2021.\nFactual probing is [MASK]: Learning vs. learning\nto recall. In Proceedings of the 2021 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 5017–5033, Online. Association for\nComputational Linguistics.\nXuhui Zhou, Yue Zhang, Leyang Cui, and Dandan\nHuang. 2020. Evaluating commonsense in pre-\ntrained language models. In Proceedings of the\nAAAI Conference on Artiﬁcial Intelligence , vol-\nume 34, pages 9733–9740.",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.8062188625335693
    },
    {
      "name": "Computer science",
      "score": 0.7592325210571289
    },
    {
      "name": "Knowledge representation and reasoning",
      "score": 0.6223741769790649
    },
    {
      "name": "Taxonomy (biology)",
      "score": 0.5168367028236389
    },
    {
      "name": "Domain knowledge",
      "score": 0.5132656097412109
    },
    {
      "name": "Representation (politics)",
      "score": 0.4805643856525421
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4426906108856201
    },
    {
      "name": "Relation (database)",
      "score": 0.4386875033378601
    },
    {
      "name": "Knowledge management",
      "score": 0.4240679144859314
    },
    {
      "name": "Natural language processing",
      "score": 0.38857001066207886
    },
    {
      "name": "Human–computer interaction",
      "score": 0.3210771679878235
    },
    {
      "name": "Data mining",
      "score": 0.09130766987800598
    },
    {
      "name": "Botany",
      "score": 0.0
    },
    {
      "name": "Politics",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I27837315",
      "name": "University of Michigan",
      "country": "US"
    }
  ]
}