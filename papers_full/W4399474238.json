{
  "title": "RAG based Chatbot using LLMs",
  "url": "https://openalex.org/W4399474238",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5002326257",
      "name": "G Ananya",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3192269127",
    "https://openalex.org/W4391944944",
    "https://openalex.org/W4390961148",
    "https://openalex.org/W4386501406",
    "https://openalex.org/W4400485091",
    "https://openalex.org/W4385262068",
    "https://openalex.org/W4386556635",
    "https://openalex.org/W4376167008",
    "https://openalex.org/W4381332452",
    "https://openalex.org/W2120738518",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4391631359",
    "https://openalex.org/W6788556936",
    "https://openalex.org/W4391294261",
    "https://openalex.org/W6852993079",
    "https://openalex.org/W4392911072",
    "https://openalex.org/W6791676059",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W6906809101",
    "https://openalex.org/W4391784296",
    "https://openalex.org/W4401042558",
    "https://openalex.org/W3138794547",
    "https://openalex.org/W2891778370",
    "https://openalex.org/W4389984066",
    "https://openalex.org/W4389523787",
    "https://openalex.org/W4390486238",
    "https://openalex.org/W4392632244",
    "https://openalex.org/W4393147129",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4392933327",
    "https://openalex.org/W4206706211"
  ],
  "abstract": "Historically, Artificial Intelligence (AI) was used to understand and recommend information. Now, Generative AI can also help us create new content. Generative AI builds on existing technologies, like Large Language Models (LLMs) which are trained on large amounts of text and learn to predict the next word in a sentence. Generative AI can not only create new text, but also images, videos, or audio. This project focuses on the implementation of a chatbot based the concepts of Generative AI and Large Language Models which can answer any query regarding the content provided in the PDFs. The primary technologies utilized include Python libraries like LangChain, PyTorch for model training, and Hugging Face’s Transformers library for accessing pre-trained models like Llama2, GPT- 3.5 (Generative Pre-trained Transformer) architectures. The re- sponses are generated using the Retrieval Augmented Generation (RAG) approach. The project aims to develop a chatbot which can generate the sensible responses from the data in the form of PDF files. The project demonstrates the capabilities and applications of advanced Natural Language Processing (NLP) techniques in creating conversational agents that can be deployed across various platforms in the corporation, to enhance user interaction and support automated tasks. Index Terms—Generative AI, Artificial Intelligence, Natural Language Processing, Large Language Model, Llama2, Tran- formers, Document Loaders, Retrieval Augmented Generation, Vector Database, Langchain, Chainlit",
  "full_text": "          International Journal of Scientific Research in Engineering and Management (IJSREM) \n             Volume: 08 Issue: 06 | June - 2024                                 SJIF Rating: 8.448                                          ISSN: 2582-3930                                                                                                                                               \n \n© 2024, IJSREM      | www.ijsrem.com                                 DOI: 10.55041/IJSREM35600                         |        Page 1 \nRAG based Chatbot using LLMs \n \nAnanya G \nDepartment of ISE \nR V College of Engineering \nBengaluru, India \nDr. Vanishree K \nDepartment of ISE \nR V College of Engineering \nBengaluru, India \n \n \nAbstract—Historically, Artificial Intelligence (AI) was used to \nunderstand and recommend information. Now, Generative AI can \nalso help us create new content. Generative AI builds on existing \ntechnologies, like Large Language Models (LLMs) which are \ntrained on large amounts of text and learn to predict the next \nword in a sentence. Generative AI can not only create new text, \nbut also images, videos, or audio. This project focuses on the \nimplementation of a chatbot based the concepts of Generative \nAI and Large Language Models which can answer any query \nregarding the content provided in the PDFs. The primary \ntechnologies utilized include Python libraries like LangChain, \nPyTorch for model training, and Hugging Face’s Transformers \nlibrary for accessing pre-trained models like Llama2, GPT- \n3.5 (Generative Pre -trained Transformer) architectures. The re - \nsponses are generated using the Retrieval Augmented Generation \n(RAG) approach. The project aims to develop a chatbot which can \ngenerate the sensible responses from the data in the form of PDF \nfiles. The project demonstrates the capabilities and applications \nof advanced Natural Language Processing (NLP) techniques \nin creating conversational agents that can be deployed across \nvarious platforms in the corporation, to enhance user interaction \nand support automated tasks. \nIndex Terms —Generative AI, Artificial Intelligence, Natural \nLanguage Processing, Large Language Model, Llama2, Tran - \nformers, Document Loaders, Retrieval Augmented Generation, \nVector Database, Langchain, Chainlit \n \nI. INTRODUCTION \nIn today’s digital age, the demand for intelligent conver - \nsational agents, known as chatbots, has surged dramatically. \nThese chatbots, powered by cutting -edge technologies such  \nas Large Language Models (LLMs) and advanced Natural \nLanguage Processing (NLP) techniques, have revolutionized \nhow businesses and organizations interact with their customers \nand users. In line with this technology, the project aims to \ndevelop a sophisticated chatbot utilizing LLMs and related \ntechnologies, specifically trained on a set of emails. Lever - \naging the Retrieval -Augmented Generation (RAG) approach \nwithin the Python programming language, the chatbot will \nbe capable of understanding user queries, retrieving relevant \ninformation from a corpus of email data, and generating \ncontextually appropriate responses. The utilization of LLMs, \nsuch as Llama2, Llama3, Mistral, GPT (Generative Pretrained \nTransformer), combined with the RAG architecture, offers \nunparalleled capabilities in natural language understanding  \nand generation. By training the chatbot on a specific set of \nemails, it is ensured that the chatbot is tailored to the domain - \nspecific needs and queries encountered in real -world email \ncommunications. This approach enables the chatbot to provide \naccurate and relevant responses to user inquiries, thereby \nenhancing user experience and streamlining communication \nprocesses. \nBy harnessing the power of LLMs, the project aims to  \ncreate a chatbot that can understand natural language queries, \ngenerate contextually relevant responses, and provide valuable \nassistance to users within the company. The project idea is \nproposed in the desire to leverage cutting -edge AI advance - \nments to enhance user interactions and streamline commu - \nnication processes. Understanding LLMs and NLP is essen - \ntial for developing advanced AI systems, chatbots, language \nmodels, and applications that require robust natural language \nunderstanding and generation capabilities. These technologies \nare revolutionizing how computers interact with and process \nhuman language, enabling a wide range of innovative applica - \ntions across industries, which opens a wide range of learning \nopportunities. \nII. LITERATURE REVIEW \n[1] The review suggested that chatbots can be used ev - \nerywhere because of its accuracy, lack of dependability on \nhuman resources and 24x7 accessibility. In recent years, ad - \nvancements in technologies such as Artificial Intelligence (AI), \nBig Data, and Internet of Things (IoT) have revolutionized \nvarious industries. Among these innovations, Chatbots, or \nconversational AIs, have emerged as a significant application. \nChatbots, powered by AI and Natural Language Processing \n(NLP), simulate human conversation, offering automation and \nefficiency across diverse domains like education, healthcare, \nand business. Through a review of existing literature, this study \nexplores the types, advantages, and disadvantages of chatbots, \nhighlighting their versatility, accuracy, and ability to operate \ncontinuously without reliance on human resources. \n[2] The paper presents a college inquiry chatbot as a solution \nto challenges in locating specific information, especially for \nnon-affiliated visitors in the college website. While GUI and \nweb-based interfaces are mainstream, alternative interfaces \noccasionally emerge to address specific needs. Powered by  \nAI and NLP algorithms, the developed chatbot intelligently \nhandle queries related to various college activities, including \nexamination cell, admission, academics, attendance, place - \nment, and more. \n[3] The paper talks about the challenges posed by the \npandemic, accessing health -care services has become increas - \ningly difficult. To address this issue, a chatbot application \n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n             Volume: 08 Issue: 06 | June - 2024                                 SJIF Rating: 8.448                                          ISSN: 2582-3930                                                                                                                                               \n \n© 2024, IJSREM      | www.ijsrem.com                                 DOI: 10.55041/IJSREM35600                         |        Page 2 \nleveraging Natural Language Processing (NLP) and machine \nlearning concepts is proposed. This chatbot system, developed \nusing supervised machine learning, aims to provide disease \ndiagnosis and treatment recommendations with detailed de - \nscriptions of various illnesses before consulting with a doctor. \nThe application features a GUI -based text assistant for user - \nfriendly interaction, allowing users to input symptoms and risk \nfactors for their condition. The chatbot then offers personalized \nsuggestions, including analgesics and advice on when to seek \nphysical medical attention. \n[4] This paper introduces a Retrieval Augmented Generation \n(RAG) approach for constructing a chatbot that addresses  \nuser queries using Frequently Asked Questions (FAQ) data. \nLeveraging Large Language Models (LLMs), particularly a \npaid ChatGPT model, the system utilizes contextual question \nanswering capabilities acquired through training. The paper \noutlines the training of an in-house retrieval embedding model \nusing infoNCE loss, showcasing its superior performance  \nover a general -purpose public embedding model in terms of \nretrieval accuracy and Out-of-Domain (OOD) query detection. \nFurthermore, the paper explores the optimization of LLM to - \nken usage and associated costs using Reinforcement Learning \n(RL), proposing a policy -based model external to the RAG \npipeline. This model interacts with the pipeline through policy \nactions, updating policies to optimize costs. \n[5] This study addresses the challenge of integrating Large \nLanguage Models (LLMs) into corporate environments where \ninternal data utilization is limited. It proposes a method for \nimplementing generative AI services using LLMs within the \nLangChain framework. The study explores various strategies \nto leverage LLMs, focusing on fine-tuning and direct use \nof document information. It details information storage and \nretrieval methods, employing the Retrieval Augmented Gener- \nation (RAG) model for context recommendation and Question- \nAnswering (QA) systems. By enhancing understanding of gen- \nerative AI technology, the study enables active utilization of \nLLMs in corporate service implementation, offering valuable \ninsights for practical applications. \nIII. METHODOLOGY \nThe methodology of the project involves preprocessing pdf \ndata, segmenting text, and generating embeddings for semantic \nunderstanding. Leveraging Retrieval Augmented Generation \n(RAG), Retrievers bridge generative models and external \nknowledge sources. the users interact with the LLM using a \nweb application which integrates with the database and the \ngenerative model. \nA. Preprocessing of PDF Data \nThe data is provided to the model in the form of PDF files. \nPDF documents contain text data that needs to be extracted  \nfor analysis. Text extraction techniques are used to convert the \ntextual content of PDFs into a format that can be processed  \nby the chatbot. Preprocessing steps may be applied to the \nextracted text to clean and standardize it. This can involve \nremoving irrelevant content, such as headers, footers, and \n \n \nFig. 1. Methodology for the proposed system \n \n \nnon-text elements, as well as handling special characters and \nformatting issues. \nB. Text Segmentation and Embedding Generation \nThe extracted text from the text files undergoes segmenta - \ntion into smaller units, enhancing the efficiency of subsequent \nprocessing and analysis. This segmentation divides the text \ninto manageable chunks, enabling the system to focus on \nspecific aspects of the information. Following segmentation, \nthe system generates embeddings for the segmented text. \nEmbeddings are numerical representations of text that capture \nthe semantic meaning of the information. By encoding the un - \nderlying context and relationships within the text, embeddings \nenable the system to interpret and understand the content more \neffectively. This transformation of textual data into numerical \nvectors facilitates various downstream tasks, such as semantic \nsearch and contextually enriched content generation. \nC. Creation of Vector Store Databases \nVector Store Databases serve as foundational components  \nof the chatbot system, enabling efficient storage and retrieval \nof textual embeddings. These databases store the numerical \nrepresentations of text, known as embeddings, which encap - \nsulate the semantic meaning of the information.The embed - \ndings stored in Vector Store Databases enable the Retriever - \nAugmented Generation (RAG) systems to retrieve and inte - \ngrate relevant information into the generated outputs. RAG \nsystems leverage the complementary strengths of retrieval - \nbased and generation -based approaches to produce more con - \ntextually accurate and informative responses compared to \ntraditional generation models. \nD. Retrievers in RAG Framework \nIn the RAG framework, Retrievers serve as essential com - \nponents that bridge the gap between the generative model and \nexternal knowledge sources. Their role is pivotal in enriching \n\n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n             Volume: 08 Issue: 06 | June - 2024                                 SJIF Rating: 8.448                                          ISSN: 2582-3930                                                                                                                                               \n \n© 2024, IJSREM      | www.ijsrem.com                                 DOI: 10.55041/IJSREM35600                         |        Page 3 \nthe content generation process by facilitating access to relevant \ninformation from external sources. Retrievers accomplish this \nby employing various techniques such as semantic search \nand information retrieval to identify and retrieve pertinent \ninformation based on user queries. By accessing external \nknowledge sources, Retrievers enhance the comprehensiveness \nand accuracy of the generated responses. \nE. User Interaction with Large Language Model (LLM) \nUser Interaction with the Large Language Model (LLM) \nis facilitated through a dedicated web -based interface tailored \nfor seamless communication. Upon receiving user queries,  \nthe LLM undertakes comprehension, transforming them into \nquery embeddings that encapsulate the semantic essence of the \ninquiries. Leveraging these embeddings, the system conducts \nsemantic searches to retrieve pertinent context, subsequently \ncrafting responses that adeptly address the users’ queries. \nThrough this iterative process, the LLM ensures effective and \ncontextually relevant interactions, enhancing user satisfaction \nand system usability \nIV. IMPLEMENTATION AND RESULTS \nPython’s versatility, combined with its robust community \nsupport and cross -platform compatibility, has made itself \nwidely utilized in training Large Language Models (LLMs). \nPython 3.x (Python 3.8 or higher) is used for development in \nthis project. \nDeep Learning Libraries like PyTorch, LangChain as the \nprimary deep learning framework for model development and \ntraining. LangChain is a deep learning framework primar- \nily focused on natural language processing (NLP) tasks. It \nprovides a set of tools and utilities specifically tailored for \nNLP applications, including text preprocessing, tokenization, \nsequence modeling, and language generation. LangChain aims \nto simplify the development and deployment of NLP models \nby offering high -level abstractions and pre -built components \nfor common NLP tasks. \nTransformers are the architectural backbone that powers \nLLMs, enabling them to process and understand text at scale. \nTransformers Library like Hugging Face Transformers library, \nopen-source library developed by Hugging Face, a company \nspecializing in natural language processing (NLP) technolo - \ngies, which provides easy -to-use interfaces for working with \ntransformer-based models, including both pre -trained models \nand tools for fine -tuning them on custom datasets. The library \nsupports a wide range of transformer architectures, including \nBERT, GPT, RoBERTa, T5, and more. \nChainlit is the open -source Python libraries that allows to \ncreate web applications for machine learning and data science \nprojects with minimal effort. It’s designed to make it easy \nfor developers to build interactive web apps without requiring \nexpertise in web development. \nUtilizing the mentioned technologies, the chatbot has been \ndeveloped which takes the PDF as input and answers any \nqueries asked by the user. The following mentions the features \nof the developed web application: \n• The web application enables users to upload any PDF  \nfile they wish to query. The PDF data undergoes parsing \nto extract the relevant content. This involves removing \nunnecessary elements such as headers, footers, and any \nother extraneous details. \n• The pre-processed text is segmented into smaller units \nor chunks to facilitate efficient processing and analysis. \nThis segmentation helps in managing large volumes of \ntext data. Embeddings, which are vector representations \nof the text, are generated using libraries like sentence - \ntransformers. These embeddings encode the semantic \nmeaning of the text, making it suitable for retrieval and \ngeneration tasks. \n• The generated embeddings are stored in vector store \ndatabases like FAISS. These databases serve as reposi - \ntories for the embeddings, allowing quick and efficient \nretrieval based on semantic similarity. \n• The embeddings in the vector store enable the Retriever - \nAugmented Generation (RAG) system to retrieve relevant \ninformation, enhancing the contextuality and accuracy of \nthe chatbot’s responses. When a user query is received,  \nit is converted into query embeddings, which are used to \nperform a semantic search in the vector store to retrieve \nrelevant context. \n• The project utilizes pre -trained LLM, Llama2 -7B model. \nThe model is obtained from the Hugging Face Trans - \nformers library, which provides tools for fine -tuning and \ndeployment. \n• The retrieved context, along with the user query, is \nfed into the LLM to generate coherent and contextually \nrelevant responses. The system uses RAG to integrate \nexternal knowledge sources seamlessly. \n• A user -friendly web -based interface is developed using \nframework, Chainlit. This interface allows users to inter - \nact with the chatbot in real-time. \n \nFig. 2. User interface for the Chatbot \n          International Journal of Scientific Research in Engineering and Management (IJSREM) \n             Volume: 08 Issue: 06 | June - 2024                                 SJIF Rating: 8.448                                          ISSN: 2582-3930                                                                                                                                               \n \n© 2024, IJSREM      | www.ijsrem.com                                 DOI: 10.55041/IJSREM35600                         |        Page 4 \nThe implementation of the RAG framework significantly \nimproved the chatbot’s ability to provide accurate and contex- \ntually relevant responses. This approach used Reinforcement \nLearning to minimize the number of LLM tokens required, \nreducing the overall computational cost. The web -based in - \nterface provided a seamless and interactive user experience. \nUsers could query the chatbot and receive prompt responses, \nenhancing their overall interaction with the system. \nFigure 2 Shows the chatbot interface using which the users \ncan interact with the LLM. The chatbot responds to the query \nusing the data provided in the PDF files. \nV. CONCLUSION \nThe chatbot is designed to engage in natural language \nconversations, providing intelligent responses to the queries \nrelated to uploaded PDFs. The chatbot is expected to answer \nthe queries based on the the PDF data. The responses are \ngenerated using the Retrieval Augmented Generation (RAG) \napproach. \nIn conclusion, the implementation of the chatbot using \nLLMs and the RAG framework demonstrated the potential of \nadvanced NLP techniques in creating efficient and effective \nconversational agents. The project achieved significant im - \nprovements in response accuracy and efficiency by employing \nthe RAG framework, which integrated external knowledge \nsources to enrich the chatbot’s contextual understanding. The \nuse of a policy -based model for optimizing LLM token usage \ndemonstrated substantial cost savings while maintaining high \nresponse quality. The results of this project highlight the \neffectiveness of combining LLMs with retrieval mechanisms to \ncreate sophisticated conversational agents capable of handling \ncomplex queries. The chatbot not only automated routine \nquery responses but also provided a scalable solution for  \nfuture expansion and enhancement. The implementation sets  \na foundation for future research and development in the field \nof AI-driven conversational systems, paving the way for more \nsophisticated and efficient automated support solutions. \nREFERENCES \n[1] S. Meshram, N. Naik, M. VR, T. More and S. Kharche, ”Con - \nversational AI: Chatbots,” 2021 International Conference on Intel - \nligent Technologies (CONIT), Hubli, India, 2021, pp. 1 -6, doi:  \n10.1109/CONIT51480.2021.9498508. \n[2] Lalwani, Tarun and Bhalotia, Shashank and Pal, Ashish and Rathod,  \nVasundhara and Bisen, Shreya, Implementation of a Chatbot System  \nusing AI and NLP (May 31, 2018). International Journal of Innovative  \nResearch in Computer Science & Technology (IJIRCST) Volume -6, \nIssue-3, May-2018. \n[3] Bal, Sauvik & Jash, Kiran & Mandal, Lopa. (2024). An Implementation \nof Machine Learning -Based Healthcare Chabot for Disease Prediction  \n(MIBOT). 10.1007/978-981-99-6866-4-32. \n[4] Kulkarni, Mandar, Praveen Tangarajan, Kyung Kim, and Anusua Trivedi. \n”Reinforcement learning for optimizing rag for domain chatbots.”.arXiv \npreprint arXiv:2401.06800.(2024). \n[5] C. Jeong, “Generative AI service implementation using LLM application \narchitecture: based on RAG model and LangChain framework,” Journal  \nof Intelligence and Information Systems, vol. 29, no. 4, pp. 129 –164, \nDec. 2023. \n[6] Jeong, Cheonsu. (2023). A Study on the Implementation of Generative  \nAI Services Using an Enterprise Data -Based LLM Application Archi - \ntecture. Advances in Artificial Intelligence and Machine Learning. 3.  \n1588-1618. 10.54364/AAIML.2023.1191. \n[7] Afzal, Anum & Kowsik, Alexander & Fani, Rajna & Matthes, Florian.  \n(2024). Towards Optimizing and Evaluating a Retrieval Augmented QA \nChatbot using LLMs with Human-in-the-Loop. \n[8] Bacciu, A.; Cocunasu, F.; Siciliano, F.; Silvestri, F.; Tonellotto, N.; \nand Trappolini, G. 2023. RRAML: Reinforced Retrieval Augmented  \nMachine Learning. \n[9] Chen, Jiawei & Lin, Hongyu & Han, Xianpei & Sun, Le. (2024). \nBenchmarking Large Language Models in Retrieval -Augmented Gen - \neration. Proceedings of the AAAI Conference on Artificial Intelligence. \n38. 17754-17762. 10.1609/aaai.v38i16.29728. \n[10] Li, Xianzhi & Chan, Samuel & Zhu, Xiaodan & Pei, Yulong & Ma,  \nZhiqiang & Liu, Xiaomo & Shah, Sameena. (2023). Are ChatGPT \nand GPT -4 General -Purpose Solvers for Financial Text Analytics? A  \nStudy on Several Typical Tasks. 408 -422. 10.18653/v1/2023.emnlp - \nindustry.39. \n[11] Zhihan Lv, Generative artificial intelligence in the metaverse \nera,  Cognitive  Robotics,  Volume  3,  2023,  Pages  208-217, \nISSN 2667-2413, https://doi.org/10.1016/j.cogr.2023.06.001. \n(https://www.sciencedirect.com/science/article/pii/S2667241323000198) \n[12] Zant, Tijn & Kouw, Matthijs & Schomaker, Lambert. (2012). Generative \nArtificial Intelligence. 10.1007/978-3-642-31674-6-8. \n[13] Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion  \nJones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. ”Attention \nis all you need.” Advances in neural information processing systems 30  \n(2017). \n[14] Rackauckas, Zackary. ”RAG -Fusion: a New Take on Retrieval- \nAugmented Generation.” arXiv preprint arXiv:2402.03367 (2024). \n[15] Khan, Salman, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, \nFahad Shahbaz Khan, and Mubarak Shah. ”Transformers in vision: A  \nsurvey.” ACM computing surveys (CSUR) 54, no. 10s (2022): 1-41. \n[16] Goldman, Sharon M. ”Transformers.” Journal of Consumer Marketing  \n27, no. 5 (2010): 469-473. \n[17] Alan, Ahmet Yusuf, Enis Karaarslan, and Omer Aydin. ”A RAG- \nbased Question Answering System Proposal for Understanding Islam:  \nMufassirQAS LLM.” arXiv preprint arXiv:2401.15378 (2024). \n[18] Feuerriegel, Stefan & Hartmann, Jochen & Janiesch, Christian &  \nZschech, Patrick. (2023). Generative AI. \n[19] Quidwai, Mujahid Ali, and Alessandro Lagana. ”A RAG Chatbot for  \nPrecision Medicine of Multiple Myeloma.” medRxiv (2024): 2024-03. \n[20] Bras¸oveanu, Adrian MP, and Ra˘zvan Andonie. ”Visualizing transformers \nfor nlp: a brief survey.” In 2020 24th International Conference Informa - \ntion Visualisation (IV), pp. 270-279. IEEE, 2020. \n[21] Wolf, Thomas, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement \nDelangue, Anthony Moi, Pierric Cistac et al. ”Huggingface’s trans - \nformers: State -of-the-art natural language processing.” arXiv preprint  \narXiv:1910.03771 (2019). \n[22] Fill, Hans-Georg & Fettke, Peter & Ko¨pke, Julius. (2023). Conceptual \nModeling and Large Language Models: Impressions From First Exper - \niments With ChatGPT. Enterprise Modelling and Information Systems  \nArchitectures. 18. 1-15. 10.18417/emisa.18.3. \n[23] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J. \nand Wang, H., 2023. Retrieval-augmented generation for large language \nmodels: A survey. arXiv preprint arXiv:2312.10997. \n[24] Li, J., Yuan, Y. and Zhang, Z., 2024. Enhancing LLM Factual Accuracy \nwith RAG to Counter Hallucinations: A Case Study on Domain-Specific \nQueries in Private Knowledge-Bases. arXiv preprint arXiv:2403.10446. ",
  "topic": "Chatbot",
  "concepts": [
    {
      "name": "Chatbot",
      "score": 0.8696390390396118
    },
    {
      "name": "Computer science",
      "score": 0.8230457901954651
    },
    {
      "name": "Generative grammar",
      "score": 0.6793083548545837
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6332326531410217
    },
    {
      "name": "Natural language processing",
      "score": 0.5525305271148682
    },
    {
      "name": "Transformer",
      "score": 0.5065363645553589
    },
    {
      "name": "Sentence",
      "score": 0.48773106932640076
    },
    {
      "name": "Natural language",
      "score": 0.4359343647956848
    },
    {
      "name": "Generative model",
      "score": 0.42783066630363464
    },
    {
      "name": "Language model",
      "score": 0.4141339063644409
    },
    {
      "name": "World Wide Web",
      "score": 0.36897173523902893
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 3
}