{
  "title": "Rewriting Conversational Utterances with Instructed Large Language Models",
  "url": "https://openalex.org/W4389982212",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5093538313",
      "name": "Elnara Galimzhanova",
      "affiliations": [
        "University of Pisa"
      ]
    },
    {
      "id": "https://openalex.org/A1982023417",
      "name": "Cristina Ioana Muntean",
      "affiliations": [
        "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
      ]
    },
    {
      "id": "https://openalex.org/A689896360",
      "name": "Franco Maria Nardini",
      "affiliations": [
        "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
      ]
    },
    {
      "id": "https://openalex.org/A1650486011",
      "name": "Raffaele Perego",
      "affiliations": [
        "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
      ]
    },
    {
      "id": "https://openalex.org/A4315177001",
      "name": "Guido Rocchietti",
      "affiliations": [
        "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\""
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3044364015",
    "https://openalex.org/W6797005584",
    "https://openalex.org/W6775416058",
    "https://openalex.org/W3034649133",
    "https://openalex.org/W3184285541",
    "https://openalex.org/W2533180076",
    "https://openalex.org/W6741315002",
    "https://openalex.org/W2995200518",
    "https://openalex.org/W3027639267",
    "https://openalex.org/W4389938928",
    "https://openalex.org/W3035169992",
    "https://openalex.org/W4385573111",
    "https://openalex.org/W3115037692",
    "https://openalex.org/W2952855649",
    "https://openalex.org/W4327640211",
    "https://openalex.org/W6779872132",
    "https://openalex.org/W3155895380",
    "https://openalex.org/W3154898636",
    "https://openalex.org/W2998702515",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W4385988359",
    "https://openalex.org/W4389523765",
    "https://openalex.org/W4389519413",
    "https://openalex.org/W3209981429",
    "https://openalex.org/W2105157020",
    "https://openalex.org/W6788088100",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W1995423294",
    "https://openalex.org/W4321524373",
    "https://openalex.org/W3100907046",
    "https://openalex.org/W2737088691",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3012014212",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3118831779",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "Many recent studies have shown the ability of large language models (LLMs) to\\nachieve state-of-the-art performance on many NLP tasks, such as question\\nanswering, text summarization, coding, and translation. In some cases, the\\nresults provided by LLMs are on par with those of human experts. These models'\\nmost disruptive innovation is their ability to perform tasks via zero-shot or\\nfew-shot prompting. This capability has been successfully exploited to train\\ninstructed LLMs, where reinforcement learning with human feedback is used to\\nguide the model to follow the user's requests directly. In this paper, we\\ninvestigate the ability of instructed LLMs to improve conversational search\\neffectiveness by rewriting user questions in a conversational setting. We study\\nwhich prompts provide the most informative rewritten utterances that lead to\\nthe best retrieval performance. Reproducible experiments are conducted on\\npublicly-available TREC CAST datasets. The results show that rewriting\\nconversational utterances with instructed LLMs achieves significant\\nimprovements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and\\n11.5% in Recall@500 over state-of-the-art techniques.\\n",
  "full_text": "Rewriting Conversational Utterances with\nInstructed Large Language Models\nElnara Galimzhanova\nUniversity of Pisa, Pisa, Italy\ne.galimzhanova@studenti.unipi.it\nCristina Ioana Muntean, Franco Maria Nardini,\nRaffaele Perego, Guido Rocchietti\nISTI-CNR, Pisa, Italy\n{name.surname}@isti.cnr.it\nAbstract—Many recent studies have shown the ability of\nlarge language models (LLMs) to achieve state-of-the-art per-\nformance on many NLP tasks, such as question answering,\ntext summarization, coding, and translation. In some cases, the\nresults provided by LLMs are on par with those of human\nexperts. These models’ most disruptive innovation is their ability\nto perform tasks via zero-shot or few-shot prompting. This\ncapability has been successfully exploited to train instructed LLMs,\nwhere reinforcement learning with human feedback is used to\nguide the model to follow the user’s requests directly. In this\npaper, we investigate the ability of instructed LLMs to improve\nconversational search effectiveness by rewriting user questions\nin a conversational setting. We study which prompts provide\nthe most informative rewritten utterances that lead to the best\nretrieval performance. Reproducible experiments are conducted\non publicly-available TREC CAST datasets. The results show\nthat rewriting conversational utterances with instructed LLMs\nachieves significant improvements of up to 25.2% in MRR, 31.7%\nin Precision@1, 27% in NDCG@3, and 11.5% in Recall@500\nover state-of-the-art techniques.\nIndex Terms—conversational systems, query rewriting, LLMs,\nChatGPT, information retrieval\nI. I NTRODUCTION\nSince their introduction, Large Language Models (LLMs)\nhave impressed with their capabilities in dealing with tasks\nsuch as question answering, text summarization, coding, and\ntranslation, with performances that are comparable to those of\nhuman annotators. Thanks to their ability to perform tasks via\nfew-shot learning, LLMs can learn from just a few examples,\nconsiderably expanding the range of applications supported and\nlowering the effort needed for targeting novel tasks. This feature\nhas been successfully exploited to train Instructed LLMs, where\nmethods from reinforcement learning with human feedback\n(RLHF) are used to directly instruct the model to act following\nthe user’s intention [1].\nAs a result, we assisted a new gold rush for part of the\nmajor tech companies to show their new intelligent systems.\nAt first, we witness the introduction of ChatGPT, powered by\na GPT-3.5 model. Then, we witness the release of a novel\nversion of Bing search powered by GPT-4. The availability of\nthe GPT-4-powered Bing search engine sets a definitive shift\nfrom a search paradigm based on “ten blue links” returned\nas an answer to a user query to a natural-language answer\nthat is then returned to the user. Such an autonomous system\nautomatically chooses the most relevant documents and extracts\nand elaborates the relevant information that is then presented\nto the user in the form of an answer to her/his query. This\nnovel paradigm that exploits the dialogue to interact between\nthe user and the search system can indeed provide a more\nfriendly and natural way of interacting with the search service.\nIn this paper, we move a step forward in an orthogonal\ndirection by studying the ability of instructed LLMs to improve\nthe retrieval effectiveness of a state-of-the-art search engine in\na conversational setting [2]–[4]. We aim to answer two main\nresearch questions:\nRQ1 Can an instructed LLM improve conversational search\neffectiveness by automatically rewriting the users’ ut-\nterances to allow the search engine to retrieve more\nprecise and relevant results?\nRQ2 Which prompting template performs best in order\nto generate rewritten queries that enhance retrieval\nperformance?\nWe investigate the research questions above by adopting the\nConversational Assistance Track (CAsT) framework provided\nby TREC for training and evaluating models in open-domain\ninformation-centric conversational dialogues [2].\nThe characteristics of conversational utterances, i.e., missing\ncontext from previous questions, topic shifts [5], [6], and\nimplied concepts from previous answers, pose new challenges\nto deal with, which are a direct consequence of the paradigm\nshift introduced by conversational search. They heavily impact\nthe performance of standard information retrieval techniques.\nQuery rewriting techniques applied on a per-utterance level\nanswer these challenges as they help propagate the context\nthroughout the conversation and deal with possible topic shifts.\nThe novel contributions of this work are thus the following:\n• We investigate utterance rewriting in conversational search\nusing an instructed LLM and specifically designed prompt-\ning templates. Given an utterance and its context, we\nprompt the model asking to generate a rewriting of\nthe utterance with the goal of enhancing the retrieval\neffectiveness of a state-of-the-art information retrieval\nsystem. This approach allows us to evaluate the ability\nof an instructed LLM to deal with the context of a\nconversation and possible topic shifts that may occur.\nAt the same time, we inspect its ability to rewrite natural\nlanguage utterances containing ambiguities, coreferences,\nomissions, acronyms, and colloquial grammar misuses.\n• We present five different prompting templates to rewrite\nthe utterances. Each prompt has been evaluated in an end-\narXiv:2410.07797v1  [cs.CL]  10 Oct 2024\nto-end retrieval framework to assess its ability to improve\nthe effectiveness of the conversational search system. All\nof the prompts have been tested in different conditions to\nestablish the best way of prompting an LLM.\n• We report the results of a comprehensive and reproducible\nexperimental evaluation conducted using the publicly-\navailable TREC CAsT datasets. Results show that rewrit-\ning utterances with the chosen instructed LLM achieves\nsignificant improvements of up to 31.7% in Precision@1,\n25.2% in MRR, 27% in NDCG@3, and 11.5 % in\nRecall@500 over state-of-the-art rewriting techniques in\nconversational search.\nThe rest of the paper is organized as follows. Section II\ndiscusses related work, while Section III introduces our\nmethodology. In Section IV we discuss the details of the\nprompting templates designed for query rewriting, the datasets,\nthe baselines and competitors, and the two-stage retrieval\narchitecture. The end-to-end performance of the proposed query\nrewriting pipeline is comprehensively assessed in Section V.\nFinally, Section VI presents the concluding remarks.\nII. R ELATED WORK\na) Conversational search: Query rewriting is central in\nmodern web search as it better models the user’s information\nneed and enhances retrieval effectiveness [7]. Similar challenges\narise in conversational search, since utterances, like queries,\nmay be ambiguous or poorly formulated.\nConversational utterance rewriting aims to reformulate a\nconcise request in a conversational context to a fully specified,\ncontext-independent query dealing with anaphoras, ellipses,\nand other linguistic phenomena [5], [8]. These techniques aim\nat identifying terms previously mentioned in the conversation to\nexpand the current utterance profitably [6], [9]–[11]. In this line,\nAliannejadi et al. propose a novel neural utterance relevance\nmodel based on BERT that helps identify the utterances relevant\nto a given turn [9]. V oskarideset al.[10] model query rewriting\nfor conversational search as a binary term classification task\nand introduce QuReTeC, a Bi-LSTM model that selects the\nvaluable terms in context to enrich the query.\nOther approaches rewrite the utterances by exploiting a fine-\ntuned neural model [12]–[15]. Yu et al. presents CQR, a few-\nshot generative approach to solve coreference and omissions\nin conversational query rewriting [12]. The authors propose\ntwo methods to solve coreference and omissions to generate\nweak supervision data that are then used to fine-tune GPT-2\nto rewrite conversational queries. Results show that on the\nTREC CAsT Track a weakly-supervised finetuning of GPT-2\nimproves the ranking accuracy by 12%.\nVakulenko et al. [14] approach the problem by tackling\nconversational question answering. The authors propose a\nquestion-rewriting technique that translates ambiguous requests\ninto semantically-equivalent unambiguous questions.\nIn more recent works, several papers exploit pre-trained\nlanguage models to represent queries and documents in the\nsame dense latent vector space and then use the inner product\nto compute the relevance score of a document to a given query.\nIn conversational search, the representation of a query can be\ncomputed in two different ways. In one case, a stand-alone\ncontextual query understanding module reformulates the user\nquery into a rewritten query, exploiting the context history [16],\nand then a query embedding is computed, e.g. using embedding\nmodels such as ANCE [17] or STAR [18]. Alternatively, the\nlearned representation function is trained to receive as input\nthe query together with its context history and to generate a\nquery embedding that is more similar to the manual query\nembeddings [19]. In both cases, dense retrieval methods are\nused to compute the query-document similarity by deploying\nefficient nearest neighbor techniques over specialized indexes,\nsuch as those provided by the FAISS toolkit [20].\nb) Large Language Models: LLMs based on transformer\narchitectures such as GPT are trained on large corpora of\ntext data to comprehend and produce natural language [21],\n[22]. The pre-trained models produced with unsupervised\ntraining [23] can be easily fine-tuned for various tasks in a\nsupervised setting. InstructGPT, based on GPT-3, has been fine-\ntuned using human feedback to make it better at following user\nintentions [1]. Bidirectional and Auto-Regressive Transformer\n(BART) integrate the strengths of two established models, i.e.,\nBERT and GPT-2, and are trained using a denoising autoen-\ncoder approach to understand text structure and semantics,\nas well as generate fluent and coherent text [24]. Another\ninstructed LLM model of the GPT family is ChatGPT 1, which\nis explicitly tailored for conversational applications [25].\nInstructed LLMs such as ChatGPT are easily adaptable to\nnew tasks and domains, making them very useful in various\ntasks. Wei et al. [26] propose ChatIE, a framework that\nemploys ChatGPT to perform zero-shot Information Extraction\n(IE) tasks via multi-turn question-answering and claim that\ntheir method can achieve impressive results and surpass some\nfull-shot models across three IE tasks. Sun et al. [27] found\nthat ChatGPT can perform as well as, or better than, supervised\nmethods in information retrieval relevance ranking when guided\nby domain-specific guidelines. The models mentioned earlier\nachieve impressive results in many NLP tasks, and their\napplications are many, from medicine to finance and beyond.\nWith proper instructions, these models can solve a vast variety\nof tasks, making them valuable tools for researchers and\ndevelopers alike. ChatGPT is the instructed LLM we use in\nour experiments.\nLately Mao et al. [28] conducted a work that studies the\nimpact of LLMs. They focus on capturing the contextual\nconversational search intent through the use of GPT-3. The\nauthors evaluate their findings in an ad-hoc dense retrieval\nscenario, using ANCE embeddings [17] for computing the\nsimilarity scores between documents and queries. We use their\nbest-performing prompt in our experimental setting to see its\neffectiveness in our framework.\nOur Contribution . This work contributes to the line of\nrewriting conversational utterances with generative models.\nDifferently from previous works, we assess the capabilities of\n1https://chat.openai.com/\nTABLE I\nNOTATION .\nSymbol Definition\nU A multi-turn conversation composed of a sequence of\nutterances asked by a user to a conversational assistant.\nΘ An instructed LLM that we use for utterance rewriting,\nalso referred to as Assistant.\nui The current original utterance at turn i in U.\nˆui The current utterance rewritten by Θ.\nu1, . . . , ui−1 The previous original utterances in U.\nˆu1, . . . ,ˆui−1 The previous utterances in U rewritten by Θ.\n¯u1, . . . ,¯ui−1 The previous manually-rewritten utterances in U.\nˆr1, . . . ,ˆri−1 Responses to the previous utterances generated by Θ.\nC The Context which is composed of the alternation\nbetween u1, . . . , ui−1 and ˆu1, . . . ,ˆui−1, or even\nadding ˆr1, . . . ,ˆri−1. An example can be seen in\nFigure 1.\nE The Example comprises original utterances u1, . . . ,\nui−1 and their corresponding manually rewritten utter-\nances ¯u1, . . . ,¯ui−1.\ns The scope that explains our goal to the rewriting LLM\nΘ, also referred to as System.\np The actual Prompt that, given ui, specifies the instruc-\ntion to Θ, namely, to rewrite the query.\nan instructed LLM such as ChatGPT in rewriting utterances\nafter few-shot training. We experiment with different prompts\nand instructions to offer the model different amounts and\nkinds of information for obtaining utterance rewritings that are\ncompetitive with—or better than—the state-of-the-art.\nIn this study, we evaluate ChatGPT’s performance in explicit\nutterance rewriting. We conduct a comparative analysis with\nother state-of-the-art models employing explicit rewriting tech-\nniques [10], [12]. We acknowledge the potential contribution\nof dense retrieval approaches for utterance rewriting, as they\ncan be applied after explicitly rewriting utterances. These\napproaches will be assessed in future research.\nIII. M ETHODOLOGY\nOur goal is to understand to which extent a state-of-the-\nart instructed LLM can be used to improve conversational\nsearch effectiveness. To this respect, this work assesses with\nreproducible experiments the rewriting capabilities of ChatGPT\n(RQ1) and investigates the impact of different prompts and\ninstructions on the effectiveness of a two-stage conversational\nsearch pipeline (RQ2). In Table I, we introduce the notation\nused to describe our task. Our rewriting system Θ, based on\nan instructed LLM, can take as input many of the elements\ndescribed in the table in order to perform the rewriting of the\ncurrent utterance ui into a rewritten version ˆui. More formally,\na typical rewriting request consists of the following:\nΘ(s, E, C, p, ui) = ˆui, (1)\nwhere s represents the scope, i.e., the general task instruc-\ntions of how we want the system to behave, E is a conversation\nexample different from the current one, C is the context of\nui, and p is the prompt accompanying ui, which explicitly\ninstructs Θ detailing the rewriting request by adding specific\ndesired characteristics, e.g., “concise”, “verbose”, and “self-\nexplanatory”.\nA. Instructed LLM\nWe employ ChatGPT as the instantiation of Θ. Specifically,\nwe employ the gpt-3.5-turbo model. As indicated in\nthe ChatGPT API description 2, the model takes “a series of\nmessages as input and returns a model-generated message as\noutput”. Since the model does not provide memory or session\nretention, in each interaction, we enclose the interaction history\nof previous turns of the conversation into the current request.\nThis leads to having a conversational-style request, similar to\nan actual dialog.\nWe adapt our utterance rewriting requests to the input\nstructure of the gpt-3.5-turbo model. The requests are\ncomposed of three main elements: system, user, and assistant.\nThe “system” content is provided at the start of the session\nto specify the scope of the following interactions, in our case\ns. The “user” and “assistant”, on the other hand, indicate the\ninteractions between the user and ChatGPT, as a series of user\ninstructions/requests consisting of prompt and current original\nutterance (p, ui), and the corresponding assistant response\ncontaining the rewritten utterance ˆui.\nTo better understand what the best way of prompting the\nsystem is, we experiment with different ways of providing\nChatGPT with the prompt and the context.\nB. Prompting ChatGPT\nWe present five different prompts p to ask the instructed\nLLM to rewrite the utterances of a conversation U.\nThe typical request submitted through the ChatGPT APIs 3\ncontains the elements detailed in Eq. 1, namely, scope, example,\ncontext, prompt, and current utterance. For all five prompts\nthe example E consists of an exemplary conversation, chosen\nrandomly from the dataset and not related with U, where the\nuser inputs are the original utterances, and the assistant inputs\nare instead the same utterances rewritten manually. Moreover,\nthe context C consists of the previous utterances of U, where\nthe user inputs are the original utterances u1, . . . , ui−1, and\nthe assistant inputs are instead the same utterances rewritten\nby the model, ˆu1, . . . ,ˆui−1. The only exception to this request\ntemplate is the prompt P1, where the context consists of the\nprevious utterances u1, . . . , ui−1, and the assistant inputs\nconsist of the previous utterances rewritten by the model\nˆu1, . . . ,ˆui−1 together with the generated answers ˆr1, . . . ,ˆri−1.\nIn Figure 1, we report a visual example of a typical rewriting\nrequest. We can see how the first block represents the system,\nthe second one is the example and the third is the context\nof the current conversation, while the last one contains the\nprompt and current question, followed by the answer (rewritten\nutterance) provided by the assistant.\nThe above structure of the requests allows us to assess\nnot only the rewriting capabilities of the model but also its\nproficiency in retaining and exploiting the context information\nfed to the system. We now detail the five prompts with their\nspecific characteristics and the intuition behind each of them.\n2https://platform.openai.com/docs/guides/chat/instructing-chat-models\n3https://platform.openai.com/docs/api-reference\nTABLE II\nEXAMPLE OF CONVERSATION TAKEN FROM THE CAST 2019 EVALUATION DATASET . THE “QID ” COLUMN IDENTIFIES THE CONVERSATIONAL TURN , THE\nFIRST NUMBER REFERS TO THE CONVERSATION WHILE THE SECOND TO THE DIALOGICAL TURN . THE “RAW UTTERANCE ” COLUMN REPORTS THE\nORIGINAL UTTERANCE , THE “MANUALLY -REWRITTEN UTTERANCE ” COLUMN REPORTS THE HUMAN ASSESSOR REWRITINGS , AND THE\n“AUTOMATICALLY -REWRITTEN UTTERANCE ” COLUMN REPORTS AN EXAMPLE OF REWRITING GENERATED BY CHATGPT WITH OUR PROPOSED PROMPT P5.\nqid Raw utterance Manually-rewritten utterance Automatically-rewritten utterance\n31 1 What is throat cancer? What is throat cancer? What is throat cancer?\n31 2 Is it treatable? Is throat cancer treatable? Is throat cancer treatable?\n31 3 Tell me about lung cancer. Tell me about lung cancer. Tell me about throat cancer.\n31 4 What are its symptoms? What are lung cancer’s symptoms? What are the symptoms of throat cancer?\n31 5 Can it spread to the throat? Can lung cancer spread to the throat? Can throat cancer spread to other areas of the throat?\n31 6 What causes throat cancer? What causes throat cancer? What causes throat cancer to spread to other areas\nof the throat?\n31 7 What is the first sign of it? What is the first sign of throat cancer? What are the early signs of throat cancer?\n31 8 Is it the same as esophageal cancer? Is throat cancer the same as esophageal cancer? Is throat cancer the same as esophageal cancer?\n31 9 What’s the difference in their symp-\ntoms?\nWhat’s the difference in throat cancer and\nesophageal cancer’s symptoms?\nWhat are the differences in the symptoms of\nesophageal cancer and throat cancer?\nSystem \nInput\nRewrite the given sentence to \nbe self-explanatory.\nWhat is the definition of lung \ncancer?\nAssistant\nAssistant\nAssistant\nAssistant\nSystem \nAnswer\nHow do you know when your \ngarage door opener is going \nbad?\nHow do you know when your \ngarage door opener is going \nbad?\nNow it stopped working. Why?\nNow my garage door opener \nstopped working. Why?\nWhat is throat cancer?\nWhat is the definition of \nthroat cancer?\nCan it be treated?\nRewrite the given sentence to \nbe self-explanatory.Tell me \nabout lung cancer.\nCan throat cancer be treated?\nUser\nUser\nUser\nUser\nUser\nSystem Input In a multi-turn dialog system, rewrite the given \nsentence to be self-explanatory following the \npattern of the previous interactions.\nWhat is the definition of throat cancer?\nAssistant\nAssistant\nAssistant\nAssistant\nSystem Answer\nHow do you know when your garage door \nopener is going bad?\nHow do you know when your garage door \nopener is going bad?\nNow it stopped working. Why?\nNow my garage door opener stopped working. \nWhy?\nHow much does it cost for someone to fix \nit?\nHow much does it cost for someone to \nrepair a garage door opener?\nHow about replacing it instead?\nIn a multi-turn dialog system, rewrite the \ngiven sentence to be self-explanatory \nfollowing the pattern of the previous \ninteractions.What is throat cancer?\nHow much does it cost to replace a garage \ndoor opener?\nUser\nUser\nUser\nUser\nUser\nScope\nExample \nUser: original \nutterance \nAssistant: \nmanually \nrewritten one\nContext \nUser: original \nutterance \nAssistant: \nAutomatically \nrewritten \nutterance\nUser \nInstruction \nPrompt and \ncurrent \nutterance ui\nRewritten \nutterance ûi  \nFig. 1. Main elements of an utterance rewriting request. The Scope indicates\nthe task that the model should perform. The Example is the artificial part of\nthe interaction where the user part is the query to rewrite and the assistant part\nis the query rewritten by a human. The Context is composed of the previous\nqueries rewritten by our model. The last section represents the current prompt\nand the output of the system.\nP1 Prompt: “Rewrite the following question to be clear and\ncomplete and then provide an answer. Use the previous\nquestions and answers to rewrite the question.”\nRationale: P1 aims to instruct the model to generate a self-\nexplanatory sentence using not only the information provided\nby the previous utterances but also by the generated answers.\nP2 Prompt: “Rewrite the following question adding keywords\nfor a retrieval system. Use the information from the previous\nquestions. Return only the rewritten question.”\nRationale: P2 aims to specify the final goal of the rewriting\nwhile keeping track of the context to see if the model is able\nto maximize the retrieval results.\nP3 Prompt: “Rephrase the current question into a more concise\nand context-free form that is suitable for a multi-turn\ninformation search dialog using the context of the previous\nquestion. Do not add any extra sentences or notes.”\nRationale: P3 aims to specify the final goal of the rewriting in\nthe prompt and to instruct the model to generate a complete\nand concise rewriting of the given utterance.\nP4 Prompt: “Reformulate the current question following the\nexamples. [a list of 8 example pairs where each pair has\nthe format “ Question: raw question. Rewritten: manually\nrewritten question”].”\nRationale: P4 aims at reproducing the pattern given in\nthe prompt to better rewrite the given utterances. Besides\nproviding the example E within the request, we also repeat\nit in the prompt.\nP5 Prompt: “In a multi-turn dialog system, rewrite the given\nsentence to be self-explanatory following the pattern of the\nprevious interactions.”\nRationale: P5 aims at reproducing the pattern given by\nthe previous interactions between the user and the model,\nassuming that they are proficient in the rewriting task.\nMoreover, we experiment in our setting also the best-\nperforming prompt presented in the work of Mao et al. [28].\nE “Reformulate the current question into a de-contextualized\nrewrite under the multi-turn information-seeking dialog\ncontext. Then generate a correct response. Print also the\nreformulated question.”\nWe use the prompts above to generate rewritten utterances\nand test their effectiveness. We rewrite all the utterances of a\nconversation except the first one, u1. In fact, several studies\nhave shown that the first utterance of each conversation is\nalready a self-explanatory sentence [6].\nBefore selecting the five prompts, we tested several other\nconfigurations not reported for the sake of brevity but resulting\nin worse performance. For example, we tried to use the prompt\np only as system input and not in every user input ui. We\nalso tested prompts not providing rewriting examples or using\ndifferent textual instructions. As a general consideration, we\nnotice that explaining the input to ChatGPT in a detailed\nway (e.g., by specifying “In some cases, I will provide the\nquestions previously made by the user. Use them to better\nreformulate the question. ”) improves the performance and\navoids some rewritings errors. Finally, we observe that the\noutput of ChatGPT sometimes contains additional elements\n(e.g., clarifying questions) or it directly includes an answer to\nthe utterance. For this reason, we post-process the output and\nkeep only the actual rewritten utterance, ˆui.\nIV. E XPERIMENTAL SETUP\nTo assess the utterance rewriting quality, we submit ˆui as a\nquery to a two-stage information retrieval pipeline. We evaluate\nthe effectiveness of the different rewriting strategies using the\nTREC CAsT framework [2]–[4], which allows us to perform an\nobjective evaluation by comparing our results to those obtained\nby state-of-the-art competitors 4.\nA. Conversational Datasets\nOur experiments are based on the TREC Conversational\nAssistant Track (CAsT) 2019 and 2020 5 datasets. The CAsT\n2019 [2] dataset consists of 20 human-assessed test conversa-\ntions, while CAsT 2020 [3] includes 25 conversations, with\nan average of 10 turns per conversation. The CAsT 2019\nand 2020 datasets include relevance judgments at the passage\nlevel. Conversations are provided with original and manually-\nrewritten utterances. The manually-rewritten utterances are the\nsame conversational utterances as the original ones, where\nhuman assessors resolve missing keywords or references to\nprevious topics. Relevance judgments have a three-point graded\nscale and refer to passages of the TREC CAR (TREC Complex\nAnswer Retrieval), the MS-MARCO (MAchine Reading COm-\nprehension) and the WaPo (TREC Washington Post Corpus)\ncollections for CAsT 2019 and 2020 for a total of 38,636,520\npassage. In these datasets, questions within a conversation are\ncharacterized by anaphora and ellipses. They imply a big part\nof the context and miss explicit references to the current topic.\nTable II reports some examples of utterances from the CAsT\n2019 dataset. We can see that manually-rewritten utterances\nare concise and rephrase the original utterance by adding the\nmissing tokens to make it self-explanatory. On the other hand,\ndepending on the prompt, automatically-rewritten utterances\ntend to be more verbose although well-formed natural language\nquestions.\nB. Baselines\nWe assess the retrieval effectiveness of original, manually-\nrewritten, and automatically-rewritten utterances. In detail, we\nconsider the following rewriting methods and baselines:\n• Original utterances: raw utterances provided by TREC\nCAsT.\n4We will release the code used for the experiments and the full set of\nrewritten utterances tested to favor the reproducibility of results.\n5Conversational Assistant Track, https://www.treccast.ai/\n• Manual utterances: manually-rewritten utterances by hu-\nman annotators provided by TREC CAsT.\n• QuReTeC [10]: utterances are rewritten with a BiLSTM\nsequence to sequence model trained for query resolution.\n• CQR self-learn cv[12]: utterances are generated in two\nsteps, first with a GPT-2 model trained with self-supervised\nlearning to generate contextual utterances containing few\ninformation presented in previous utterances. The second\nstep is performed with a GPT-2 model fine-tuned on\nmanual rewrites via five-fold cross-validation.\n• CQR rule-based cv[12]: utterances are generated in two\nsteps, first with a rule-base approach that deals with\nomissions and coreference and successively rewritten with\na GPT-2 model fine-tuned on manual rewrites via five-fold\ncross-validation.\n• Prompt E [28]: although the results by Mao et al. are\nachieved on a different generative model, i.e., GPT-3,\nwe use their prompt in our experimental framework to\ncompare its retrieval performance against ours.\nC. Two-stage Retrieval\nTo evaluate and compare the different utterance rewritings,\nwe index the TREC CAsT collections by removing stopwords\nand applying Porter’s English stemmer. We use PyTerrier [29]\nto build the information retrieval pipeline, which is composed\nof two stages:\n• The first stage performs document retrieval on the indexed\ncollection with the DPH weighting model [30], using the\nraw, manually, and automatically-rewritten utterances;\n• The second stage performs reranking of the top- 1000\ncandidates retrieved by the first stage by using the MonoT5\nmodel [31] made available in PyTerrier 6.\nWe measure the retrieval effectiveness of the first stage\nand of the second stage using the following metrics: Mean\nReciprocal Rank (MRR), Precision@1 (P@1), Normalized\nDiscounted Cumulative Gain@3 (NDCG@3), and Recall@500\n(R@500). MRR and NDCG@3 are standard metrics used for\nevaluation purposes in the TREC CAsT framework while the\nothers are included to provide a more comprehensive evaluation\nof the retrieval capabilities of the first-stage (R@500) and the\nreranking capabilities of the second-stage (P@1).\nV. R ESULTS AND DISCUSSION\nIn this section, we discuss the experimental results on CAsT\n2019 and 2020 datasets to assess the various rewriting strategies\nand compare them with the baselines.\nA. First-stage Retrieval\nIn Table III, we report the results obtained when performing\ndocument retrieval using the DPH weighting model [30].\nResults refer to the first-stage retrieval pipeline on both the\nCAsT 2019 and CAsT 2020 datasets. We also experiment with\nother weighting models, i.e., BM25 [32]. We do not report\nthem as their results are worse than those achieved by DPH.\n6https://github.com/terrierteam/pyterrier t5\nTABLE III\nFIRST -STAGE RETRIEVAL RESULTS IN TERMS OF MRR, P@1, NDCG@3 AND R@500 ON CAST 2019 AND CAST 2020 DATASETS . IN BOLD , WE REPORT\nTHE BEST RESULTS ACHIEVED FOR EACH METRIC , EXCEPT MANUAL . WE MARK STATISTICALLY -SIGNIFICANT PERFORMANCE GAIN /LOSS , CALCULATED\nWITH THE TWO -PAIRED t-TEST (p-VALUE < 0.05) WITH BONFERRONI CORRECTION , OF OUR METHODS WITH RESPECT TO THE QURETEC AND CQR\nSELF -LEARN CV BASELINES WITH THE SYMBOLS ▲ AND ▼ FOR THE FIRST , △ AND ▽ FOR THE LATTER .\nCAsT 2019 CAsT 2020\nPrompt MRR P@1 NDCG@3 R@500 MRR P@1 NDCG@3 R@500\nManual 0.6753△ 0.5491 0.4002 △ 0.7374△▲ 0.6220▲ 0.5048▲ 0.3277▲ 0.6682▲\nOriginal 0.3334▽▼ 0.2254▽▼ 0.1617▽▼ 0.3815▽▼ 0.2177▼ 0.1587▼ 0.0998▼ 0.2532▼\nP1 0.6327 0.5260 0.3664 0.6446 0.5353▲ 0.4231▲ 0.2512 0.5710\nP2 0.5887 0.4624 0.2921 0.5775 ▽▼ 0.4838 0.3750 0.2406 0.5488\nP3 0.6129 0.5087 0.3363 0.6036 ▼ 0.4580 0.3150 0.2153 0.5009\nP4 0.6221 0.5116 0.3449 0.6311 0.4302 0.3317 0.2109 0.4963\nP5 0.6359 0.5145 0.3331 0.6499 0.4775 0.3894 0.2266 0.5133\nE 0.5837 0.4798 0.3094 0.5772 ▼ 0.4520 0.3558 0.2181 0.5029\nQuReTec [10] 0.6251 0.4913 0.3494 0.6704 0.4399 0.3221 0.2145 0.5163\nCQR self-learn cv [12] 0.5915 0.4682 0.3336 0.6617 - - - -\nCQR rule-based cv [12] 0.5629 0.4162 0.3111 0.6569 - - - -\nThe performance of our methods and baselines range between\nthe ones obtained for the original and the manually-rewritten\nutterances. Considering CAsT 2019, P5 is the best-performing\nprompt when looking at MRR while P1 is the best-performing\nprompt in terms of Precision@1 and NDCG@3. Regarding\nR@500, the QuReTec baseline is the best-performing method.\nWhen performing the statistical significance evaluation using\na two-paired t-test ( p-value < 0.05) with the Bonferroni\ncorrection [33], the results achieved by our prompts are not\nstatistically different from the state-of-the-art baselines, except\nfor R@500 for P2, P3, and E.\nImproved results are achieved when rewriting the utterances\nof the CAsT 2020 evaluation dataset. The best-performing\nrewriting method is based on P1, where all metrics show\nconsiderable gains over the QuReTec baseline. For P@1\nand MRR, the improvement achieved by P1 is statistically\nsignificant when compared to the QuReTec baseline, with a\n21.6% gain in MRR and 31.7% in P@1. NDCG@3 and R@500\nincrease by 17.1% and 10.6%, respectively. We remind the\nreader that P1 also considers the generated answers to the\npreviously rewritten questions to produce the current rewriting.\nIn fact, it is worth noting that, compared to CAsT 2019\nwhere most relevant concepts could be found in the previous\nutterances, for CAsT 2020, some missing relevant concepts\nthat fill out the context, can be found only in the responses and\nnot in the utterance history. Results show that by generating\nthe answers to the user requests and instructing the model to\nuse them in the rewriting phase, we obtain improved results.\nThe fact that, independently of the dataset considered, our\nfew-shot rewriting system obtains results as good as—or better\nthan—state-of-the-art techniques should be further exploited\nin future work.\nB. Second-stage Retrieval\nIn Table IV, we report the end-to-end results obtained with\nCAsT 2019 and 2020 when performing document re-ranking\nusing the MonoT5 model in the second-stage retrieval pipeline.\nOur intuition is that because our rewriting techniques\nproduce verbose and well-formed utterance rewritings, it\nwould be beneficial to use a LLM-based model such as T5,\nso as to effectively exploit the information added by the\ngpt-3.5-turbo model. We can see that the performance\nobtained by the generated rewritings achieves higher results\nthan those obtained by the CQR and QuReTec competitors for\nprompts such as P1, P5 for CAsT 2019, and for all prompts\nfor CAsT 2020.\nThe winning method for CAsT 2019 is P5, with an MRR\nof 0.8119 (3.3% increase), P@1 of 0.7283 (5.9% increase),\nNDCG@3 of 0.5343 that is slightly better than the one provided\nby QuRETec, i.e., 0.5330. Consistent with the first stage, also\nin the second-stage retrieval, the results are better with respect\nto the QuReTec baseline, except for R@500, although not\nstatistically significant.\nWhen considering the CAsT 2020 evaluation dataset, our\nrewriting methods show significant improvements after rerank-\ning. In this case, we have a clear winner, i.e., P1, for which\nall metrics improve over QuReTec in a statistically-significant\nway. The MRR increases by 25.2%, the P@1 by 31.7%, the\nNDCG@3 by 27.0%, and the R@500 by 11.5%. Also, for P2,\nwe have a statistically-significant improvement of 22.17% in\nterms of NDCG@3.\nEven in the second stage of retrieval, we obtain results as\ngood as—or better than—state-of-the-art competitors, confirm-\ning that instructed LLMs are effective in rewriting utterances\nin a multi-turn conversational setting.\nC. Answering our Research Questions\nRQ1. We affirm that using an instructed LLM to rewrite\nutterances helps the effectiveness of the retrieval system. In\nfact, we can observe that for the CAsT 2020 dataset, we obtain\nsignificant improvements over the QuReTeC baseline, while\nfor the CAsT 2019 we achieve the same results, and in some\ncases, we outperform QuReTeC and the two CQR competitors.\nThe results achieved also show that, although the LLM\nhas not been fine-tuned explicitly for utterance rewriting, it\nTABLE IV\nSECOND -STAGE RETRIEVAL RESULTS IN TERMS OF MRR, P@1, NDCG@3 AND R@500 ON CAST 2019 AND CAST 2020 DATASETS . IN BOLD , WE\nREPORT THE BEST RESULTS ACHIEVED FOR EACH METRIC , EXCEPT MANUAL . WE MARK STATISTICALLY -SIGNIFICANT PERFORMANCE GAIN /LOSS ,\nCALCULATED WITH THE PAIRED t-TEST (p-VALUE < 0.05) WITH BONFERRONI CORRECTION , OF OUR CORRESPONDING METHODS WITH RESPECT TO THE\nQURETEC AND CQR SELF -LEARN CV BASELINES WITH THE SYMBOLS ▲ AND ▼ FOR THE FIRST , △ AND ▽ FOR THE LATTER .\nCAsT 2019 CAsT 2020\nPrompt MRR P@1 NDCG@3 R@500 MRR P@1 NDCG@3 R@500\nManual 0.8849△▲ 0.8266△▲ 0.6053△▲ 0.7705△▲ 0.8161▲ 0.7308▲ 0.5381▲ 0.7361▲\nOriginal 0.4643▽▼ 0.3989▽▼ 0.2791▽▼ 0.4060▽▼ 0.3301▼ 0.2212▼ 0.1813▼ 0.2834▼\nP1 0.7909 0.6936 0.5193 0.6974 0.7249▲ 0.6394▲ 0.4386▲ 0.6287▲\nP2 0.7440 0.6358 0.4829 ▼ 0.6347▼ 0.6758 0.5962 0.4220 ▲ 0.6091\nP3 0.7377 0.6647 0.4867 0.6419 ▼ 0.6022 0.5144 0.3542 0.5597\nP4 0.7575 0.6532 0.5155 0.6710 0.6086 0.5240 0.3601 0.5469\nP5 0.8119 0.7283 0.5343 0.7059 0.6536 0.5721 0.4046 0.5650\nE 0.6863 0.5954 0.4507 0.6157 ▼ 0.6163 0.5481 0.3855 0.5572\nQuReTec [10] 0.7858 0.6879 0.5330 0.7111 0.5788 0.4856 0.3454 0.5639\nCQR self-learn cv [12] 0.7780 0.7052 0.5286 0.6938 - - - -\nCQR rule-based cv [12] 0.7630 0.6821 0.5109 0.6853 - - - -\nprovides competitive results compared to the state of the art.\nThis confirms the ability of these models to perform a variety\nof tasks via few-shot learning, thus lowering the effort needed\nfor targeting novel tasks. In fact, custom-made models for\nutterance rewriting in conversational search, i.e., QuReTec,\nreach worse results on CAsT 2020 than an instructed LLM\nwith well-designed prompts. We explain these results as a\nconsequence of the capability of an LLM to deal with different\ndatasets and domains, keeping a rewriting quality higher than\nother systems trained on limited data and thus characterized\nby a lower generalization power.\nRQ2. For what concerns the best way of prompting the LLM,\nthe best results are obtained with P1 for CAsT 2020, while\nwith P1 and P5 for CAsT 2019. While for some of the prompts\ndiscussed we clearly explicit the scope of the rewriting (e.g.\n”[...]for a retrieval system[...]” in P2), in both P1 and P5\nthis information is not explicit, suggesting that this kind of\ninstruction is not useful to obtain better rewritings.\nMoreover, in both cases, there is a clear indication of how\nto exploit examples and context from the previous interactions.\nThe difference is that P1 explicitly asks the model to also\nadd previously generated answers to the context and use all\nthe information for generating the rewriting ˆui. This proved\nparticularly effective in the case of CAsT 2020. This could also\nbe the reason why QuReTec underperforms as, by design, it\nonly focuses on the previous utterance and does not integrate the\ncontent of the answers for generating the rewriting. Therefore,\nafter establishing the best-performing prompts and observing\nthat they both make use of the context, we can conclude\nthat providing examples can have a significant impact on the\nmodel’s capabilities in performing the chosen task.\nVI. C ONCLUSIONS AND FUTURE WORK\nIn this paper, we proposed several methods for using an\ninstructed LLM for the conversational utterance rewriting task.\nWe focused on assessing if such type of model is suitable for\nthis task and if it is competitive with the current state-of-the-art\nrewriting techniques, which use models specifically fine-tuned\nfor the task. We also studied different prompting techniques\nto assess the most effective ways to instruct the model using\n5 prompt formulations.\nWe evaluate our proposals on the publicly-available TREC\nCAsT 2019 and CAsT 2020 datasets. We provide a com-\nprehensive experimental evaluation of our proposed five\nways of prompting the instructed LLM and state-of-the-art\nconversational rewriting baselines by assessing their retrieval\neffectiveness in a two-stage retrieval pipeline.\nExperiments show that, in most cases, our proposed rewriting\nmethods outperform the baselines. The largest gain is achieved\nfor CAsT 2020 with increases in MRR by 25.2%, in P@1\nby 31.7%, in NDCG@3 by 27.0%, and in R@500 by 11.5%.\nThese results are obtained using prompt P1, in which the\nsystem is also required to consider previous answers when\nrewriting the current utterance. We can conclude that using\nan instructed LLM is beneficial for the utterance rewriting\ntask in conversational search. These models can become a\nuseful tool to further expand rewriting approaches and set new\nstate-of-the-art standards.\nFuture Work. As future work, we are interested in studying\nhow instructed LLMs can be used to generate synthetic data that\ncan be exploited in other tasks of conversational search or even\nfor enriching conversational datasets with weak supervision\nlabels. The limited number of assessed conversations is in\nfact one of the main limitations in the conversational search\ndomain. Moreover, we are interested in assessing the sensibility\nof prompting, i.e., how the utterance rewriting changes with\nrespect to variations in the prompt and how it influences the\nretrieval performance, in a systematic and comprehensive way.\nAcknowledgements. Funding for this research has been pro-\nvided by: PNRR - M4C2 - Investimento 1.3, Partenariato Esteso\nPE00000013 - “FAIR - Future Artificial Intelligence Research” -\nSpoke 1 ”Human-centered AI” funded by the European Union\n(EU) under the NextGeneration EU programme; the EU’s\nHorizon Europe research and innovation programme EFRA\n(Grant Agreement Number 101093026). Views and opinions\nexpressed are however those of the author(s) only and do not\nnecessarily reflect those of the EU or European Commission-\nEU. Neither the EU nor the granting authority can be held\nresponsible for them.\nREFERENCES\n[1] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin,\nC. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton,\nL. Miller, M. Simens, A. Askell, P. Welinder, P. Christiano, J. Leike, and\nR. Lowe, “Training language models to follow instructions with human\nfeedback,” 2022.\n[2] J. Dalton, C. Xiong, V . Kumar, and J. Callan, “CAsT-19: A dataset\nfor conversational information seeking,” in Proceedings of the 43rd\nInternational ACM SIGIR Conference on Research and Development\nin Information Retrieval . ACM, Jul. 2020. [Online]. Available:\nhttps://doi.org/10.1145/3397271.3401206\n[3] J. Dalton, C. Xiong, and J. Callan, “CAsT 2020: The conversational\nassistance track overview.” TREC’20, Virtual, 2020. [Online]. Available:\nhttps://trec.nist.gov/pubs/trec29/papers/OVERVIEW.C.pdf\n[4] ——, “TREC CAsT 2021: The conversational assistance track\noverview.” TREC’21, Virtual, 2021. [Online]. Available: https:\n//trec.nist.gov/pubs/trec30/papers/Overview-CAsT.pdf\n[5] I. Mele, C. I. Muntean, F. M. Nardini, R. Perego, N. Tonellotto, and\nO. Frieder, “Topic propagation in conversational search,” in Proceedings\nof the 43rd International ACM SIGIR conference on research and\ndevelopment in Information Retrieval, SIGIR 2020, Virtual Event, China,\nJuly 25-30, 2020, J. X. Huang, Y . Chang, X. Cheng, J. Kamps,\nV . Murdock, J. Wen, and Y . Liu, Eds. ACM, 2020, pp. 2057–2060.\n[Online]. Available: https://doi.org/10.1145/3397271.3401268\n[6] ——, “Adaptive utterance rewriting for conversational search,” Inf.\nProcess. Manag., vol. 58, no. 6, p. 102682, 2021. [Online]. Available:\nhttps://doi.org/10.1016/j.ipm.2021.102682\n[7] Y . He, J. Tang, H. Ouyang, C. Kang, D. Yin, and Y . Chang, “Learning\nto rewrite queries,” in Proceedings of the 25th ACM International on\nConference on Information and Knowledge Management, 2016, pp. 1443–\n1452.\n[8] L. Yang, H. Zamani, Y . Zhang, J. Guo, and W. B. Croft, “Neural matching\nmodels for question retrieval and next question prediction in conversation,”\nArXiv Preprint 1707.05409, 2017.\n[9] M. Aliannejadi, M. Chakraborty, E. A. R ´ıssola, and F. Crestani,\n“Harnessing evolution of multi-turn conversations for effective answer\nretrieval,” in Proceedings of the 2020 Conference on Human\nInformation Interaction and Retrieval, ser. CHIIR ’20. Association\nfor Computing Machinery, 2020, pp. 33–42. [Online]. Available:\nhttps://doi.org/10.1145/3343413.3377968\n[10] N. V oskarides, D. Li, P. Ren, E. Kanoulas, and M. de Rijke, “Query\nresolution for conversational search with limited supervision,” in\nProceedings of the 43rd International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, ser. SIGIR ’20.\nNew York, NY , USA: Association for Computing Machinery, 2020, p.\n921–930. [Online]. Available: https://doi.org/10.1145/3397271.3401130\n[11] G. Rocchietti, O. Frieder, C. I. Muntean, F. M. Nardini, and R. Perego,\n“Commonsense injection in conversational systems: An adaptable frame-\nwork for query expansion.” in IEEE/WIC International Conference on\nWeb Intelligence and Intelligent Agent Technology, 2023.\n[12] S. Yu, J. Liu, J. Yang, C. Xiong, P. Bennett, J. Gao, and Z. Liu,\n“Few-shot generative conversational query rewriting,” in Proceedings\nof the 43rd International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval, ser. SIGIR ’20. New York,\nNY , USA: Association for Computing Machinery, 2020, p. 1933–1936.\n[Online]. Available: https://doi.org/10.1145/3397271.3401323\n[13] J. Hao, Y . Liu, X. Fan, S. Gupta, S. Soltan, R. CHADA, P. Natarajan,\nE. Guo, and G. Tur, “Cgf: Constrained generation framework for query\nrewriting in conversational ai,” in EMNLP 2022, 2022.\n[14] S. Vakulenko, S. Longpre, Z. Tu, and R. Anantha, “Question\nrewriting for conversational question answering,” in Proceedings\nof the 14th ACM International Conference on Web Search and\nData Mining . ACM, 2021, pp. 355–363. [Online]. Available:\nhttps://dl.acm.org/doi/10.1145/3437963.3441748\n[15] H. Su, X. Shen, R. Zhang, F. Sun, P. Hu, C. Niu, and J. Zhou,\n“Improving multi-turn dialogue modelling with utterance ReWriter,”\nin Proceedings of the 57th Annual Meeting of the Association for\nComputational Linguistics. Association for Computational Linguistics,\n2019, pp. 22–31. [Online]. Available: https://aclanthology.org/P19-1003\n[16] J. Gao, C. Xiong, P. Bennett, and N. Craswell, “Neural approaches to\nconversational information retrieval,” CoRR, vol. abs/2201.05176, 2022.\n[Online]. Available: https://arxiv.org/abs/2201.05176\n[17] L. Xiong, C. Xiong, Y . Li, K. Tang, J. Liu, P. N. Bennett, J. Ahmed,\nand A. Overwijk, “Approximate nearest neighbor negative contrastive\nlearning for dense text retrieval,” CoRR, vol. abs/2007.00808, 2020.\n[Online]. Available: https://arxiv.org/abs/2007.00808\n[18] J. Zhan, J. Mao, Y . Liu, J. Guo, M. Zhang, and S. Ma, “Optimizing\ndense retrieval model training with hard negatives,” in Proceedings\nof the 44th International ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval, ser. SIGIR ’21. New York,\nNY , USA: Association for Computing Machinery, 2021, p. 1503–1512.\n[Online]. Available: https://doi.org/10.1145/3404835.3462880\n[19] S. Yu, Z. Liu, C. Xiong, T. Feng, and Z. Liu, “Few-shot conversational\ndense retrieval,” in Proceedings of the 44th International ACM\nSIGIR Conference on Research and Development in Information\nRetrieval, ser. SIGIR ’21. New York, NY , USA: Association\nfor Computing Machinery, 2021, p. 829–838. [Online]. Available:\nhttps://doi.org/10.1145/3404835.3462856\n[20] J. Johnson, M. Douze, and H. Jegou, “Billion-scale similarity search\nwith gpus,” IEEE Trans. Big Data, vol. 7, no. 03, pp. 535–547, 2021.\n[21] R. Alec, N. Karthik, S. Tim, and S. Ilya, “Improving\nlanguage understanding by generative pre-training,” 2018.\n[Online]. Available: https://www.cs.ubc.ca/∼amuham01/LING530/papers/\nradford2018improving.pdf\n[22] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\nL. Kaiser, and I. Polosukhin, “Attention is all you need,” arXiv, 2017.\n[23] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-\nV oss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler,\nJ. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,\nB. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever,\nand D. Amodei, “Language models are few-shot learners,” 2020.\n[24] M. Lewis, Y . Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,\nV . Stoyanov, and L. Zettlemoyer, “Bart: Denoising sequence-to-sequence\npre-training for natural language generation, translation, and comprehen-\nsion,” 2019.\n[25] Y . Liu, T. Han, S. Ma, J. Zhang, Y . Yang, J. Tian, H. He, A. Li, M. He,\nZ. Liu, Z. Wu, D. Zhu, X. Li, N. Qiang, D. Shen, T. Liu, and B. Ge,\n“Summary of chatgpt/gpt-4 research and perspective towards the future\nof large language models,” 2023.\n[26] X. Wei, X. Cui, N. Cheng, X. Wang, X. Zhang, S. Huang, P. Xie,\nJ. Xu, Y . Chen, M. Zhang, Y . Jiang, and W. Han, “Zero-shot information\nextraction via chatting with chatgpt,” 2023.\n[27] W. Sun, L. Yan, X. Ma, P. Ren, D. Yin, and Z. Ren, “Is chatgpt good at\nsearch? investigating large language models as re-ranking agent,” 2023.\n[28] K. Mao, Z. Dou, H. Chen, F. Mo, and H. Qian, “Large language\nmodels know your contextual search intent: A prompting framework for\nconversational search,” 2023.\n[29] C. Macdonald, N. Tonellotto, S. MacAvaney, and I. Ounis, “PyTerrier:\nDeclarative experimentation in python from BM25 to dense retrieval,”\nin Proceedings of the 30th ACM International Conference on\nInformation & Knowledge Management, ser. CIKM ’21. Association\nfor Computing Machinery, 2021, pp. 4526–4533. [Online]. Available:\nhttps://doi.org/10.1145/3459637.3482013\n[30] G. Amati and C. J. Van Rijsbergen, “Probabilistic models of information\nretrieval based on measuring the divergence from randomness,” ACM\nTrans. Inf. Syst., vol. 20, no. 4, p. 357–389, oct 2002. [Online].\nAvailable: https://doi.org/10.1145/582415.582416\n[31] R. Pradeep, R. Nogueira, and J. J. Lin, “The expando-mono-duo design\npattern for text ranking with pretrained sequence-to-sequence models,”\nArXiv, vol. abs/2101.05667, 2021.\n[32] S. Robertson and H. Zaragoza, “The probabilistic relevance framework:\nBm25 and beyond,” Found. Trends Inf. Retr., vol. 3, no. 4, p. 333–389,\napr 2009. [Online]. Available: https://doi.org/10.1561/1500000019\n[33] P. Sedgwick, “Multiple significance tests: the bonferroni correction,” BMJ\n(online), vol. 344, pp. e509–e509, 01 2012.",
  "topic": "Rewriting",
  "concepts": [
    {
      "name": "Rewriting",
      "score": 0.8433973789215088
    },
    {
      "name": "Computer science",
      "score": 0.7894881963729858
    },
    {
      "name": "Automatic summarization",
      "score": 0.7033489346504211
    },
    {
      "name": "Natural language processing",
      "score": 0.5608270168304443
    },
    {
      "name": "Recall",
      "score": 0.5070209503173828
    },
    {
      "name": "Artificial intelligence",
      "score": 0.48731741309165955
    },
    {
      "name": "Task (project management)",
      "score": 0.48291537165641785
    },
    {
      "name": "Language model",
      "score": 0.45058414340019226
    },
    {
      "name": "Spoken language",
      "score": 0.4374634623527527
    },
    {
      "name": "Cognitive psychology",
      "score": 0.1720663607120514
    },
    {
      "name": "Programming language",
      "score": 0.17203202843666077
    },
    {
      "name": "Psychology",
      "score": 0.14624541997909546
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I108290504",
      "name": "University of Pisa",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I122991210",
      "name": "Istituto di Scienza e Tecnologie dell'Informazione \"Alessandro Faedo\"",
      "country": "IT"
    }
  ],
  "cited_by": 3
}