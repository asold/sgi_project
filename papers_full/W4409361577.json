{
  "title": "Artificial intelligence orchestration for text-based ultrasonic simulation via self-review by multi-large language model agents",
  "url": "https://openalex.org/W4409361577",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2119269380",
      "name": "So-Yeon Kim",
      "affiliations": [
        "Korea Atomic Energy Research Institute",
        "Korea University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2107661419",
      "name": "Yonggyun Yu",
      "affiliations": [
        "Korea Atomic Energy Research Institute",
        "Korea University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2150581037",
      "name": "Hogeon Seo",
      "affiliations": [
        "Korea Atomic Energy Research Institute",
        "Korea University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2119269380",
      "name": "So-Yeon Kim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2107661419",
      "name": "Yonggyun Yu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2150581037",
      "name": "Hogeon Seo",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3130194937",
    "https://openalex.org/W4293266824",
    "https://openalex.org/W4320837757",
    "https://openalex.org/W4322774620",
    "https://openalex.org/W4361006859",
    "https://openalex.org/W4387151404",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4392799721",
    "https://openalex.org/W2172047305",
    "https://openalex.org/W4255783477",
    "https://openalex.org/W3023007900",
    "https://openalex.org/W4228997196",
    "https://openalex.org/W4382498938",
    "https://openalex.org/W4387245383",
    "https://openalex.org/W2968772574",
    "https://openalex.org/W4404782367",
    "https://openalex.org/W4391417118",
    "https://openalex.org/W4402753889",
    "https://openalex.org/W6600538214",
    "https://openalex.org/W4392941879",
    "https://openalex.org/W3183902529",
    "https://openalex.org/W4399767172",
    "https://openalex.org/W1983801113",
    "https://openalex.org/W2799899844",
    "https://openalex.org/W2107544712",
    "https://openalex.org/W2795867901",
    "https://openalex.org/W3103178756",
    "https://openalex.org/W4221161695",
    "https://openalex.org/W4396832345"
  ],
  "abstract": "Abstract Widely used ultrasonic simulation systems often rely on complex graphical user interfaces (GUIs) or scripting, resulting in substantial time investments and reduced accessibility for new users. In this study, we propose a novel text-based simulation control architecture, which leverages a large language model (LLM) and the ground artificial intelligence (AI) approach to streamline the control of ultrasonic simulation systems. By modularizing the functionalities of the SimNDT program into discrete functions and enabling natural language-based command interpretation, the proposed method reduces the average simulation configuration time by approximately 75%. To further mitigate task failures in scenario generation using the LLM, we introduce the ground AI approach, which employs self-review mechanisms and multi-agent collaboration to improve task completion rates. In particular, when vectorized output lengths deviate from the standard, we regenerate outputs using multiple LLM agents, reducing the scenario generation error rate from 23.89 to 1.48% and enhancing reliability significantly. These advancements underscore the potential of AI-driven methods in reducing operational costs and enhancing reliability in simulation frameworks. By integrating text-based control and Ground AI mechanisms, the proposed approach provides an efficient and scalable alternative to traditional GUI-based control methods, particularly in time-sensitive applications such as digital twin systems.",
  "full_text": "Artificial intelligence orchestration \nfor text-based ultrasonic \nsimulation via self-review by multi-\nlarge language model agents\nSoyeon Kim1,2, Yonggyun Yu1,2 & Hogeon Seo1,2\nWidely used ultrasonic simulation systems often rely on complex graphical user interfaces (GUIs) \nor scripting, resulting in substantial time investments and reduced accessibility for new users. In \nthis study, we propose a novel text-based simulation control architecture, which leverages a large \nlanguage model (LLM) and the ground artificial intelligence (AI) approach to streamline the control \nof ultrasonic simulation systems. By modularizing the functionalities of the SimNDT program into \ndiscrete functions and enabling natural language-based command interpretation, the proposed \nmethod reduces the average simulation configuration time by approximately 75%. To further mitigate \ntask failures in scenario generation using the LLM, we introduce the ground AI approach, which \nemploys self-review mechanisms and multi-agent collaboration to improve task completion rates. In \nparticular, when vectorized output lengths deviate from the standard, we regenerate outputs using \nmultiple LLM agents, reducing the scenario generation error rate from 23.89 to 1.48% and enhancing \nreliability significantly. These advancements underscore the potential of AI-driven methods in reducing \noperational costs and enhancing reliability in simulation frameworks. By integrating text-based control \nand Ground AI mechanisms, the proposed approach provides an efficient and scalable alternative to \ntraditional GUI-based control methods, particularly in time-sensitive applications such as digital twin \nsystems.\nKeywords Simulation, Large language models, Multi-agents, Natural language commands, Text-based \ncontrol, Automation\nIn engineering, simulations are indispensable tools for analyzing and predicting the behavior of complex systems. \nThey are widely utilized in fluid dynamics, structural analysis, and energy systems to support decision-making \nand enhance design processes. However, generating large amounts of diverse simulation data for practical \napplications requires expert manipulation and remains challenging owing to the inherently time-consuming \nand complex nature of repetitive simulation control. Prevailing methodologies rely heavily on graphical user \ninterfaces (GUIs), necessitating manual user interaction, which limits automation and scalability when extensive \ndatasets are required1–6.\nIntegrating large language models (LLMs) into simulation workflows offers the potential to address these \nchallenges. LLMs, such as the generative pre-trained transformers (GPTs) 7,8, have demonstrated remarkable \ncapabilities based on training on extensive datasets, enabling rapid and efficient text processing9. By leveraging \nLLMs for natural language-based simulation control, repetitive tasks may be automated, parameter tuning may \nbe optimized, and data generation processes may be streamlined significantly. This approach could revolutionize \nsimulation management, enhancing efficiency and scalability across various engineering applications.\nTo this end, we propose a text-based simulation control framework by leveraging LLMs. By modularizing \nthe functionalities of SimNDT: Ultrasound NDT simulation tool (Version: 0.52) 10 into callable functions, we \nenable users to control simulations via natural language commands. For instance, when a user might input: \n”Simulate ultrasonic wave propagation in a rectangular object with a width of 10 and a height of 5, ” the system \ninterprets the prompt and executes the corresponding simulation scenario. This novel method simplifies \nsimulation control and facilitates more intuitive interactions compared to traditional GUI-based methods. \nHowever, despite initial results suggesting significant improvements in efficiency and usability, challenges such \n1Korea Atomic Energy Research Institute, 111, Daedeok-daero 989beon-gil, Daejeon 34057, Republic of Korea. \n2University of Science & Technology, 217, Gajeong-ro, Yuseong-gu, Daejeon 34113, Republic of Korea. email: \nhogeony@hogeony.com\nOPEN\nScientific Reports |        (2025) 15:12474 1| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports\n\nas those regarding accuracy and reliability of LLM-generated scenarios persist. To address these, we develop \nstrategies based on Ground artificial intelligence (AI), which enhances LLM-driven systems by incorporating \nself-review mechanisms and multi-agent strategies to improve decision-making accuracy and reduce errors 11. \nIn this approach, LLMs refine their outputs iteratively or collaborate with other agents to generate more reliable \nresults, providing a robust framework for addressing their inherent limitations in complex tasks.\nIn this work, we propose a novel text-based simulation control method that draws on large language models \nto address the constraints of traditional GUI-based approaches. We also develop a systematic integration of \nGround AI principles-ranging from single-agent methods to multi-agent collaborations-and demonstrate how \nthese strategies can reduce inaccuracies in LLM outputs. Furthermore, we validate the practical feasibility of \nour framework by incorporating it into SimNDT and assessing its performance under realistic ultrasonic wave \npropagation scenarios. By integrating sophisticated AI methodologies with ultrasonic simulation, this research \npresents a scalable, efficient alternative for managing complex engineering simulations, thereby expanding the \npotential of AI-powered tools in computational science and engineering.\nThe remainder of this paper is organized as follows. The implementation of the proposed LLM-based text \nsimulation control architecture is discussed in Section 2, besides the text command-based approach, the modular \nstructure for LLM function calls, and practical examples of text-based control. In Section 3, error reduction \ntechniques based on the Ground AI approach are described, along with the concept, experimental configuration, \nand results of various error mitigation strategies. The overall results are presented and discussed in Section 4, \nhighlighting the contributions and implications of our work. Finally, the paper is concluded in Section 5 by \nsummarizing key findings and suggesting future research directions.\nLiterature review\nInterest in AI models and their utilization12,13 have steadily increased over the past few years, spanning a wide \nrange of industries, including economics and healthcare. The emergence of LLMs, e.g., the attention 14-based \narchitectures, BERT9 and GPT 7,8, has not only motivated significant advancements in AI performance but \nalso accelerated efforts to integrate these models within industrial applications. Organizations and research \ninstitutions are actively adopting large language models to achieve objectives such as increased productivity, \ncost reduction, personalized customer services, and precision medicine. The scope of real-world applications \nof LLMs is expanding rapidly, from medical diagnosis support systems and financial analysis to automated \ntranslation and AI-driven customer service chatbots 12,15,16. This trend transcends mere AI adoption; it is \nfundamentally reshaping industrial processes and serving as a catalyst for innovation across sectors 17–19. \nHowever, as AI technology continues to evolve, new concerns regarding ethics, privacy, and algorithmic bias \nare emerging. Addressing these concerns requires the establishment of proper guidelines to ensure transparency \nand implement responsible AI operations.\nConsequently, AI, and in LLMs with their enhanced expressiveness and learning capabilities in particular, \nhas evolved from merely serving static functions into a crucial tool for creative problem-solving and complex \ndecision-making. This trend is expected to accelerate further in the coming years, leading to the continuous \nexpansion of the scope of AI applications and profound transformations in various industries 11,15,16,20. With \nthe advancement of AI, autonomous controlling systems on this basis have gained prominence, leading to the \ndevelopment of the concept known as ’ orchestration. ’ Orchestration refers to the process of coordinating and \nmanaging the deployment, integration, and interaction of various AI components. Additionally, LLMs are \nassigned roles specific to individual agents, facilitating collaboration between humans and AI (often referred \nto as human-AI interaction) and expanding research related to agents. This approach enables AI agents to act \nautonomously and perform complex tasks without human intervention. Thus, AI orchestration and agent-based \nmethodologies enhance the autonomy and efficiency of AI systems, elevating human-AI collaboration21–31 to a \nnew dimension.\nTraditional simulation automation frameworks11,12,15,20,32, such as MyCrunchGPT19 and the AI-based design \nsystem32, have made significant progress in data analysis, model recommendations, and single-step optimization. \nHowever, they lack a structured framework capable of fully orchestrating iterative simulations in a feedback-\ndriven manner26. MyCrunchGPT leverages LLMs for scientific machine learning tasks, primarily focusing on \ndata analysis and model selection rather than on direct simulation execution. Similarly, the approach proposed \nby Park et al. employs a single-model generative AI pipeline integrated with an optimization solver, but does \nnot incorporate a multi-agent system16,33,34, limiting its ability to conduct continuous, feedback-driven iterative \nexperimentation.\nIn contrast, the framework proposed in this paper adopts a multi-agent architecture, where one agent \ntranslates natural language input of the user into executable commands, another executes the simulation based \non these commands, and a third evaluates the results to refine inputs for subsequent iterations28. This automated \nworkflow transcends single-step analysis or static optimization by continuously leveraging previous simulation \nresults to guide subsequent iterations. Unlike existing approaches that operate within a fixed input-output loop, \nthe proposed framework ensures that iterative feedback influences future simulation conditions dynamically, \nenabling a more autonomous and self-improving process. Moreover, the proposed framework adopts a modular \norchestration strategy, allowing LLMs to control each stage of the simulation pipeline rather than being restricted \nto auxiliary functions. This design enhances simulation flexibility by enabling the framework to incorporate \nresponses from another model automatically to refine the decision-making process when an intermediate \nresult is determined to be erroneous 23. This self-review mechanism not only improves simulation reliability \nbut also significantly reduces the need for human intervention for error handling and adjustments. As a result, \nthe proposed framework fosters a more efficient, robust, and autonomous simulation automation environment. \nTable 1 provides a comparison between existing research approaches, their limitations, the necessity of our work, \nScientific Reports |        (2025) 15:12474 2| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nand our proposed methods that overcome these challenges through structured function calling, schema-based \nvalidation, and self-review mechanisms.\nImplementation of LLM-based text simulation control architecture\nTo control the program using LLMs, we modularize the various functionalities of the SimNDT program into \ncallable functions and design a code-based controllable structure. This enables the programmatic control \nof multiple tasks, including simulation configuration, execution, and result output. In this work, we adopt a \nmodular architecture for the SimNDT program by separating core functionalities into distinct classes or \nfunctions. Specifically, components such as Scenario, Material, Boundary, Transducer, Signal, and Simulation \nare each implemented as individual modules, which are collectively packaged based on a SimPack object. \nUsing this design, an LLM (e.g., GPT-4o) provides natural language inputs that are subsequently mapped to the \ncorresponding modules, thereby orchestrating simulation tasks, such as configuration, execution, and output \nhandling in a step-by-step, programmatic manner. Further, low-level details, such as the physics engine or \npostprocessing routines, are encapsulated under the SimNDT.engine folder, allowing independent functionalities, \ne.g., the EFIT2D solver, to operate without directly coupling with the high-level control. In practice, higher-\nlevel classes, such as EngineController or SIM Custom, coordinate with these modules to run and manage the \nsimulation. As a result, the LLM-based interface focuses on parameter delivery and orchestration logic, while the \nactual computation or physics modeling is handled by separate, specialized modules. This code-based structure \nnot only enhances flexibility and scalability in ultrasonic simulation but also simplifies the extension to other \ndomains (e.g., thermal or structural analysis) if needed.\nWith this modular design, we implemented an environment that interprets natural language text commands \nusing the GPT-4o model of OpenAI to orchestrate simulations. Users can execute simulations based on simple \ntext inputs without complex code or GUI operations, greatly enhancing user experience. LLMs translate the \ninput natural language commands into SimNDT function calls, and the simulation engine executes them to \nyield the results.\nText command-based simulation control architecture\nThe text command-based simulation control comprises three primary components—prompt input, LLM, and \nthe simulation engine. The entire process is depicted in Fig. 1. The prompt input is the medium in which users \nenter text prompts, i.e., natural language commands that specify the desired simulation tasks. Using the prompt \ninput, users can easily instruct the system on the simulations they wish to perform without the need for complex \ncoding or GUI navigation. LLM functions as the interpreter within the text-based simulation control framework. \nIt processes the input text commands and translates them into code or specific function calls comprehensible to \nthe simulation engine. This translation is crucial as it bridges the gap between human language and machine-\nexecutable instructions, enabling seamless interaction between the user and the simulation engine. Finally, \nthe simulation engine receives the code or function calls generated by LLM and executes the corresponding \nsimulations, returning the results to the user. This component performs the computational tasks required for \nthe simulations, serving as the core component of the system that delivers the outcomes to the user. Integrating \nthese components allows users to control simulations using simple text prompts, simplifying the simulation \nconfiguration and execution processes significantly.\nExisting research Limitations Necessity of our work Proposed method (ours)\nTransformer-based \nLLM7–9,14\nHigh computational cost and complexity; issues \nwith factual accuracy, reasoning, and biases\nNeed for accurate translation from natural \nlanguage to structured commands to mitigate \nmisinterpretations\nUsing GPT-4o with structured function \ncalling and predefined simulation schemas to \nimprove accuracy and reduce ambiguity\nHuman-AI interaction \n(HAI) basedprogram \ncontrol21,22,24,27\nLimited real-world applicability and insufficient \nstructured command handling; limited \ngeneralization and robustness\nRobust, structured, and verifiable command \ninterpretation required for practical program control\nEmploying structured prompt inputs and \nLLM-driven function calling mechanisms \ncombined with schema-based validation\nMulti-Agent and \nautonomous AI \nsystems16,25,26,28\nHigh complexity, limited resource efficiency, \npoor generalization across diverse scenarios\nEfficient single-agent solutions needed for reliable \nscenario generation and resource optimization\nIntegrating Ground AI verification with single \nand multi-LLM agent configurations to ensure \nreliability while controlling resource usage\nHuman-feedback based \nlearning29–31\nLimited scalability and generalization to \ncomplex tasks; lack of structured command \nverification\nAutomatic validation and self-correction of \nstructured commands required for complex tasks\nSelf-review mechanisms and structural \nschema validation embedded in LLM-\ngenerated function calls\nAI-based \nsimulations12,13,19,32\nComplexity in simulation setup, limited \naccessibility, insufficient verification of \nsimulation parameters\nSimplified and accessible methods for configuring \nand running accurate simulations needed\nPrompt-based natural language inputs \nmapped automatically via Simulation Variable \nSchema to structured executable commands\nLanguage-based data \nvisualization andAI \ntools15,17,18,23\nLimited handling of complex computational \ntasks; insufficient real-world validation\nEffective integration of natural language commands \nwith computational tasks, providing realistic and \nvalidated results\nStructured parameter generation via \npredefined schemas linked directly to \ncomputational tasks within simulations\nTable 1. Flow of developments: existing research limitations and our improvements.\n \nScientific Reports |        (2025) 15:12474 3| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nAlgorithm 1. LLM-driven simulation configuration and execution\nProgram control through LLM function calling structure\nTo control the program effectively, we employ the function calling mechanism provided by the LLM, GPT-\n4o. This feature enables the LLM to generate structured data that adheres to predefined function signatures, \nfacilitating seamless integration between natural language inputs and programmatic function calls. In the \nimplementation described here, the SimNDT program is transformed into a set of modular functions, each \ncorresponding to a specific simulation task. To this end, a Simulation Variable Schema is developed as shown in \nSupplementary Figures (Figs. S1-3), which describes the variables necessary for these functions and facilitates \ntheir functionization. The schema includes comprehensive descriptions for each variable, which help the LLM \nunderstand the intended purpose and utilization of each variable, enhancing the relevance of the generated \nfunction calls.\nUpon receiving a natural language command from the user via a prompt, the LLM initiates input processing. \nThe function calling mechanism generates a function call corresponding to one of the predefined functions. \nSubsequently, the model identifies the most suitable function and populates the parameters following the input \nof the user, reflecting the intended outcome. If the user does not specify particular parameters, the model utilizes \ndefault values defined within the simulation variable schema to guarantee that the function call is complete and \nexecutable. For instance, if a user inputs the command ”Simulate ultrasonic wave propagation in a rectangular \nobject with a width of 10 and a height of 5, ” the LLM interprets this command and generates the corresponding \nsimulation scenario via function calling based on the simulation variable schema, as illustrated in Fig. 2. \nFigure 1. Flowchart of text command-based simulation control using LLM.\n \nScientific Reports |        (2025) 15:12474 4| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nThis structured output follows the predefined simulation variable schema and can be directly utilized by the \nsimulation engine to execute the simulation.\nThe proposed architecture enables the parallel generation of multiple simulation scenarios during the LLM \nprocessing stage. However, in the simulation execution phase, support for dedicated computational acceleration \n(such as GPU parallelization or cluster environments) is currently limited. Therefore, the feasibility of parallel \nexecution depends on the complexity of the simulations and the available resources. Thus, while the architecture \nallows for the efficient simultaneous creation of various simulation scenarios, the actual execution phase may \nrequire sequential processing depending on the circumstances.\nThe simulation variable schema enumerates all essential parameters, e.g., geometry definitions, material \nproperties, boundary conditions, and solver configurations, ensuring that each function call includes every \ncomponent required for a valid simulation. If certain parameters are omitted in command of the user, they are \nautomatically populated with predefined defaults specified by the schema, preventing incomplete or invalid \nconfiguration requests. Moreover, users can easily override default values using subsequent prompts or edits if \nthey wish to refine specific conditions (e.g., adjusting the wave frequency or boundary thickness). This approach \nnot only streamlines the configuration process for novices but also provides experienced users with precise \ncontrol, striking a balance between simplicity and flexibility. As a result, once the schema-based function call is \nfinalized, it can be transmitted to the underlying simulation engine seamlessly for immediate execution.\nBy leveraging the function calling mechanism, the LLM generates outputs that conform to the expected \nformat consistently, thereby reducing errors and enhancing the stability of simulation execution. Further, this \napproach enables the LLM to comprehend the variables intended to be set by the user based on their input, \nthereby improving the validity and reliability of the simulation scenarios generated by the LLM. Furthermore, \nthe simulation variable schema is constructed using the principles of functional modularization. The description \nfield within the schema included an explanation of the function and role of each variable. This helps the LLM \nFigure 2. Example of an output simulation scenario generated using function calls.\n \nScientific Reports |        (2025) 15:12474 5| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nunderstand the meaning of each variable, enabling the selection of suitable parameter configurations based on \nthe input of the user. Default values are assigned in anticipation of scenarios where users may not set specific \nvariables. This guarantees that all essential parameters for simulation execution are perpetually accessible, thereby \nenhancing the robustness of the text-based simulation control framework. Due to this structured approach, the \nLLM generates outputs following the predefined simulation variable schema consistently with each call, thereby \nensuring stability in simulation execution. The LLM accurately interpreted the input of the user to determine \nwhich variables they wished to set and generated simulation scenarios accordingly for program execution.\nEfficient text-based control and examples\nThe proposed system is an effective control tool, facilitating user interaction based on natural language prompts. \nFor instance, a user may input: ”Generate simulation configurations for a rectangular defect in air with a label \nnumber of 200 and an aluminum background with a label number of 0. The defect’s depth, width, and height \nare 200, 10, and 5, respectively. ” The LLM interprets the natural language commands and generates the requisite \ncode or function calls for execution. Subsequently, the simulation engine executes the simulations and furnishes \nthe results to the user. The outputs include the simulation geometry image, the simulation inspection condition \nanimation, and the ultrasonic simulation result data stored as npy files. The npy files represent the ultrasonic \nsimulation results stored as 2D matrices. Each value in the matrix corresponds to the signal amplitude at a \nspecific spatial coordinate. Based on the aforementioned data, supplementary images, such as B-mode and \nsynthetic aperture focusing technique (SAFT), are generated in the PNG format. The B-mode and SAFT graphs \nare generated based on the data obtained from the npy files, which visually represent the simulation results, as \ndepicted in Fig. 3.\nImplementing the proposed text-based control system reduces the time required for the configuration and \nexecution of ultrasonic wave propagation simulations using the SimNDT program significantly. The average time \nrequired to execute a particular simulation is observed to decrease from approximately two minutes, required \nFigure 3. Process flow of text-based command execution and simulation outputs.\n \nScientific Reports |        (2025) 15:12474 6| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nby the traditional GUI-based control method, to approximately 30 seconds, required to write a prompt for the \ncontrol command. This represents a 75% reduction, thereby greatly enhancing overall efficiency. In turn, this \nstreamlines the workflow, rendering the system particularly useful when large amounts of simulation data are \nrequired or when continuous execution of simulations is necessary. Thus, the execution of numerous simulations \nover a short period becomes more feasible, which is especially beneficial in applications that demand repeated \nsimulations.\nError reduction based on ground AI and experimental results\nConcept and implementation of ground AI\nGrounded AI represents an approach to ensuring that outputs generated by AI models are firmly based on \nreliable evidence rather than hallucinations or unfounded assertions. Despite their extensive training on \ndiverse datasets, large language models may produce responses that appear plausible but lack factual accuracy. \nGround AI addresses this limitation by implementing verification mechanisms that either validate outputs \nagainst trustworthy data sources or incorporate self-correction protocols, thereby minimizing potential issues \nsuch as misinformation or logical inconsistencies in AI-generated content 35,36 A detailed comparison between \nrule-based validation and Ground AI approaches is summarized in Table  2, highlighting their differences in \nalgorithmic flexibility, error management strategies, and contextual intelligence.\nIn this paper, Ground AI is employed to mitigate failures in the scenario generation process during simulation \ncontrol. Considering a single-LLM agent without Ground AI as the baseline, three distinct approaches are \nimplemented by combining Ground AI with a single-LLM agent with self-review and multi-LLM agents. The \nself-feedback method based on the single-LLM agent entails prompting the LLM to review the answer and \ncorrect it if required, encouraging it to revise and regenerate its response, as illustrated in Fig. 4. In this study, the \nself-review process of the proposed Ground AI approach focuses on the structural validation of the generated \nsimulation schema, without incorporating feedback based on simulation results. Specifically, the generated \nschema is transmitted along with an internal self-review prompt to verify and enforce compliance with \nrequirements, such as the presence of essential fields and parameter consistency. In all Ground AI approaches, a \nverification process of LLM answers is applied to ensure the integrity of the simulation scenarios. Following the \nFigure 4. Flowchart of ground AI with self-review (single agent) approach.\n \nCriteria Rule-based validation Ground AI approach\nValidation paradigm Static and predefined rule enforcement Dynamic and adaptive multi-agent verification\nAlgorithmic flexibility Constrained by predetermined logical conditions Adaptive inference with contextual recalibration\nError management strategy Deterministic binary compliance checking Iterative error detection and generative correction\nComputational complexity Low algorithmic overhead Moderate computational complexity with scalable agent configuration\nScenario adaptation capability Limited domain-specific applicability High contextual generalizability\nOutput refinement mechanism Strict output rejection Intelligent regeneration and systematic improvement\nVerification protocol Deterministic checklist-based matching Structural integrity validation with probabilistic enhancement\nContextual intelligence Minimal semantic understanding Advanced contextual reasoning and interpretative capabilities\nArchitectural scalability Challenging cross-domain implementation Modular design enabling efficient domain transposition\nArtificial intelligence integration Minimal AI model engagement Comprehensive leveraging of large language model capabilities\nTable 2. Comparative analysis of validation methodologies for rule-based and ground AI approaches.\n \nScientific Reports |        (2025) 15:12474 7| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nvectorization of the generated simulation scenario, the vector length is evaluated to ascertain its equivalence with \nthe number of keys present in the simulation variable schema (62 schema keys in this study). If the vector length \nequals the number of keys, the scenario is deemed valid and utilized to execute its corresponding simulation. \nConversely, the scenario is classified as invalid and discarded if this equivalence is not established.\nSimilarly, a structured verification mechanism is also employed in AI-powered structured query language \ngeneration platforms, e.g., Vanna.ai 37, which validates the generated queries by ensuring that all required \ncomponents are included. Taking inspiration from this approach, our study adopts a predefined schema of 62 \nkeys to evaluate the completeness of AI-generated simulation scenarios. By verifying whether each scenario \nvector satisfies the 62-length criterion, we uphold a robust check against missing or inconsistent parameters, \nthereby enhancing both the reliability and reproducibility of the AI-driven simulation process. In the self-\nfeedback method based on the single-LLM agent, if the verification is not passed, the system transmits the \ninvalid scenario, the prompt of the user, and a review message indicating that the response was incorrect38. This \nmessage instructs the LLM to correct the response and regenerate the simulation scenario to address the errors \nand enhance the validity of the generated scenarios, as shown in Fig. 4.\nIn contrast, multi-agent methods entail the utilization of multiple agents to generate responses in parallel. \nEach agent independently creates a simulation scenario, and these scenarios are validated in the order of \ngeneration. If the scenario from the initial LLM agent is deemed valid, its response proceeds to the subsequent \nphase, and the remaining agents remain inactive. If the initial scenario proposed by the first agent is deemed \ninvalid, the scenario proposed by the second agent is validated next. This process is repeated until a valid scenario \nis generated, thereby ensuring the generation of a valid scenario. This method reduces the probability of failure \nby increasing the probability of obtaining at least one valid scenario based on the combined efforts of multiple \nLLM agents. However, multi-agent methods can become computationally expensive if excessively many agents \nare employed. Accordingly, the number of agents should be optimized to achieve an equilibrium between the \ncomputational cost and the probability of generating a valid scenario. Multi-agent methods with two and three \nagents are implemented to investigate the effectiveness of the number of LLM agents in Ground AI, as illustrated \nin Figs. 5 and 6, respectively.\nExperimental configuration\nIn our experimental design, we aimed to rigorously assess the capability of LLMs to generate complex \nsimulation scenarios while adhering to strict structural requirements. The fundamental challenge lies not just \nin understanding user requests, but in consistently generating a specific, deep, hierarchical JSON schema. \nThis schema, which serves as the input for simulation execution, mandates a precise structure with nested \nparameters across multiple levels (e.g., scenario configuration, material properties, boundary conditions, defect \nspecifications). The task demands more than just plausible variable naming and value generation; it requires \nprecisely replicating the predefined schema structure in its entirety for every generation, incorporating only the \nmodifications specified by user input, while ensuring the generated values maintain physical consistency and \nadhere to simulation constraints. For instance, the defect specification alone necessitates coordinating multiple \ninterdependent parameters (shape, dimensions, position, material properties) within a specific nested hierarchy, \ndemonstrating the intricate structural integrity the LLM must preserve. Any deviation from this required \nstructure results in a simulation input error.\nExperiments are conducted to evaluate the performance of four approaches—the initially designed approach \nwithout Ground AI, and the methods incorporating the self-feedback mechanism of Ground AI using a single-\nLLM agent and multi-agent techniques using two and three agents. The performances of these methods are \nFigure 5. Flowchart of ground AI with multi-LLM agents (two agents) approach.\n \nScientific Reports |        (2025) 15:12474 8| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\ncompared by adjusting a single variable in the simulation scenario to assess their impact on error rates in \nscenario generation.\nLet us consider the following text control command (prompt) used for program control: ‘Generate simulation \nconfigurations for a rectangular defect in aluminum with a label number of 0 and air with a label number of 500. \nThe original defect’s depth, width, and height are 1, 10, and 5, respectively. ’ We aim to control the depth variable \nby assuming that it changes in increments of 1 mm. Even this simple modification of the user requirement, i.e., \nwhether the LLM can create the simulation scenarios without failures, is investigated. On this basis, the failure \nprobability of autonomous simulation control using the LLM and the periodicity can be evaluated qualitatively. \nTo specifically probe the robustness of each approach against the difficulty of modifying this complex, fixed \nstructure, we designed experiments with incremental modification demands based on user requirements. In \nthe first experiment, only the depth of the defect is varied incrementally, whereas in the second experiment, \nboth the depth and the width are varied. This dual-parameter modification significantly escalates the challenge, \ndemanding that the LLM not only adjust multiple interdependent values but do so while meticulously preserving \nthe integrity of the entire, complex, and predefined JSON structure. This stepwise approach allows for an \nassessment of the ability of the LLM to handle increasingly complex parameter changes and to understand the \nconditions under which simulation generation might fail or succeed.\nAll outputs are presented in the simulation scenario JSON results in the case of successful execution of \nthe simulation control since all the necessary variables are generated correctly. In such cases, the length of the \nvectorized JN file is equal to the number of the schema keys. Thus, these coincidences are deemed to comprise \na correct output. Otherwise, the tasks are considered failures due to input error during simulation execution. \nThe error rate can be calculated by dividing the number of failed simulations by the total number of simulations. \nThis process entails reading the critical values from the JSON files, vectorizing them, and measuring the \nlengths of the vectors. By verifying whether the vectors exhibit the expected length, the accurate generation \nof all necessary variables can be verified, thereby yielding the error rate. All experiments are conducted under \nidentical conditions and the average error rate is calculated over five iterations.\nExperimental results\nIn this section, we discuss the methodology and results of measuring error rates by vectorizing the JSON files \nand checking the lengths of the vectors to determine whether the outputs are generated correctly and can be \nexecuted as autonomous ultrasonic simulations via AI orchestration. The overall probability of error occurrence \nis observed to decrease considerably when Ground AI-based methodologies are employed, particularly in the \ncase of multi-LLM agent approaches, as illustrated in Figs. 7 and 8. The average error rate of the method that does \nnot include Ground AI is 23.89%. In contrast, Ground AI-based methods exhibit markedly lower error rates. \nIn particular, the self-feedback method based on a single-LLM agent exhibits an average error rate of 15.84%, \nthe multi-LLM agent method employing two agents exhibits that of 6.63%, and the multi-LLM agent method \nutilizing three agents exhibits the lowest average error rate of 1.48%. This suggests that incorporating Ground \nAI reduces the error rate associated with scenario generation significantly. Further, the multi-agent approaches \nyield lower error rates than the self-feedback method based on a single-LLM agent, indicating that employing \nmultiple agents enhances the reliability of the simulation control process to a greater extent than the self-review \nprompt method.\nDuring early phases of repetitive requests (call index: 0–500), the single-LLM agent-based method without \nGround AI exhibits a high initial error rate exceeding 26%, which is significantly higher than those of other \napproaches. Incorporating Ground AI based on the self-feedback method that uses a single-LLM agent to review \nand correct the answer by itself results in a notable enhancement, with an initial error rate of 16%. However, the \nmulti-LLM agent-based methods based on two or three agents exhibit even more favorable performance, with \ninitial error rates of less than 8% and 4%, respectively.\nAs the experiments proceed to the accumulated phase (call index: 500–1000), the single-LLM agent-based \nmethod without Ground AI exhibits a cumulative error rate exceeding 20%, indicating a lack of sustained \nperformance improvement. In contrast, the Ground AI-based implementation using the self-feedback method \nFigure 6. Flowchart of ground AI with multi-LLM agents (three agents) approach.\n \nScientific Reports |        (2025) 15:12474 9| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nexhibits a stabilized error rate of approximately 10%, substantiating the efficacy of Ground AI and self-review \nmechanisms in a single-agent framework. The performances of the multi-LLM agent-based approaches are even \nmore impressive, with error rates stabilizing below 5% for the two-LLM agent system and below 2% for the \nthree-LLM agent system, which represents the best performance among the compared approaches. As illustrated \nin Fig. 8, experiments involving the control of two variables demonstrate that the multi-LLM agent approaches \nmaintain impressive performance levels in all cases. Specifically, the error rates stabilize below 5% for the two-\nLLM agent system and below 2% for the three-LLM agent system, mirroring the patterns observed in the single-\nvariable control experiments.\nFurther analysis of the standard deviation of error rates highlight the advantages of Ground AI and multi-\nLLM agent methods. The single-LLM agent without Ground AI exhibits the highest variability between the initial \nand stabilized stages, reflecting inconsistent performance. In other words, achieving consistent performance \nwith a single-LLM agent without Ground AI is challenging. The Ground AI-based self-feedback method exhibits \nrelatively stable standard deviations—albeit higher than the those of the multi-agent approaches. Notably, the \nmulti-agent approach with three agents exhibits the lowest standard deviations during the early and accumulated \nFigure 8. Comparison of accumulated error rates of the four methods over 1000 calls with two-variable \ncontrol.\n \nFigure 7. Comparison of accumulated error rates of the four methods over 1000 calls with single variable \ncontrol.\n \nScientific Reports |        (2025) 15:12474 10| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nphases. This result suggests that the multi-LLM agent-based approaches with Ground AI yield more consistent \nand reliable performance in long-term practical applications.\nThe results of this study demonstrate that the integration of Ground AI in self-review and multi-agent systems \nenhances the efficiency and reliability of solutions for text-based simulation control. The superior performance \nof the multi-LLM agent-based approach with three agents indicates that employing multiple agents enhances the \nstability and reliability of autonomous ultrasonic simulation via AI orchestration and improves success rate of \nadjusting individual parameters during simulation execution. Building on these results, an additional experiment \nis conducted to explore whether increasing the number of agents beyond three enhances performance further. \nIn the initial experiment, the number of agents is gradually increased up to three, resulting in a reduction of \nthe error rate to 1.48%. Based on this observation, agents are dynamically added until the error is completely \neliminated.\nMulti-agent evaluation in a single-variable scenario\nIn this experiment, the error correction capability of a multi-LLM agent system is evaluated by conducting \nindependent trials, where 1000 executions are repeated five times. Each trial is initiated with a single agent, \nand additional agents are introduced dynamically until the simulation is successfully completed. This approach \nenables the analysis of the distribution of the number of agents required to generate an error-free output. As \nillustrated in Fig. 9, the results reveal that, similar to our previous findings, approximately 20% of the scenarios \nrequire additional agents. When two agents are employed, 173 scenarios are successfully completed. When three \nagents are used, 22 scenarios are completed without requiring additional agents. When four or more agents \nare introduced, all errors are resolved, and no cases required the use of five or more agents. This experiment \nconfirms that a multi-agent LLM system is significantly more robust than a single-agent approach and that, in a \nsingle-variable control environment, employing up to four agents is sufficient to eliminate all errors.\nCost analysis for single-agent vs. multi-agent approaches\nAlthough the primary goal of this study is to reduce errors, resource expenditure also plays a crucial role in \nselecting an optimal agent configuration. To quantify cost implications in a single-agent environment, 5000 \nsimulation scenarios are considered and all application programming interface (API)-related expenses are \nrecorded. According to the API usage logs provided by OpenAI, the total cost for generating these simulations \namount to $37.85 (approximately 38 dollars), translating to an average cost of about $0.00757 (0.76 cents) \nper simulation. This result serves as a baseline for subsequent cost efficiency analysis of multi-agent systems. \nConsidering that a single agent generates 1000 simulation scenarios in our experiment, the cost for a single-agent \narchitecture is calculated to be approximately $7.57. As the number of agents is increased up to a maximum of \nfive, the costs increase linearly to $7.57, $15.14, $22.71, $30.28, and $37.85, respectively. In other words, although \ndeploying multiple agents reduces scenario generation errors, the cost increases linearly with each additional \nagent. Therefore, determining the optimal number of agents is crucial to balance cost and efficiency effectively.\nFigure 9. Comparison of empirical results of dynamic agent generation while controlling a single variable.\n \nScientific Reports |        (2025) 15:12474 11| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\nDiscussion\nThe experimental results demonstrate that although the methods integrating Ground AI concepts, particularly \nthe multi-LLM agent approach utilizing three agents, are highly effective in reducing error rates in scenarios \nwhere a single variable is controlled, there is potential for further optimization of the performance of the system. \nSpecifically, although the multi-LLM agent approach yields low error rates, further enhancements can be achieved \nby refining the decision-making mechanisms among the agents. In particular, improvements to the coordination \nstrategies between agents may facilitate more effective consensus and more accurate scenario generation, thereby \nreducing residual errors and increasing the efficiency of the system. In particular, the multi-LLM agent-based \napproach with three agents is identified as the most effective method in our experiments in simulation scenarios \ninvolving the control of a single variable. However, further reliable autonomous ultrasonic simulation can be \nrealized based on improvements to the decision-making processes among the multi-LLM agent system with \nmany LLM agents and incorporating additional evaluation metrics. This would further enhance the robustness \nand reliability of Ground AI-based approaches for text-based simulation control in complex systems where \nefficiency and accuracy are paramount.\nMoreover, the experiments in this study employ a vectorization process to measure error rates based on \nthe verification of lengths of the vectors in the JSON files. Although this approach has been demonstrated to \nbe effective, alternative evaluation metrics and methodologies should be considered to assess the ability of the \nsystem to produce outputs aligned with the intended objectives. Relying on a single metric may only partially \ncapture the nuances of generative outputs. Thus, future research should explore complementary validation \nmethods, such as expert evaluation, consistency analysis, and functional accuracy assessment. Expert evaluation, \nparticularly based on human-in-the-loop assessment, may provide deeper insights into the contextual validity \nand reliability of the generated scenarios. Additionally, consistency testing, which involves measuring variations \nacross repeated executions, could offer a quantitative measure of robustness. Further, functional accuracy \nanalysis, comparing LLM-generated commands against predefined ground truth datasets, could enhance the \nevaluation framework, ensuring that outputs are aligned with expected behaviors.\nAs the number of agents is increased, the multi-LLM agent-based method exhibits enhanced reliability \nrelative to the self-feedback method based on the single-LLM agent. These results demonstrate that the \ncombination of self-review and multi-LLM agent approaches as Ground AI orchestration has the potential to \nenhance the scalability and reliability of the simulation control process. These methods address the limitations \nof relying on the output of a single LLM agent by providing mechanisms for error correction and leveraging \nmultiple independent responses. This not only leverages the diversity of outputs obtained from multiple agents \nbut also automates the validation process, increases efficiency, and reduces the scenario generation error rate. \nsignificantly.\nFuture works\nOur immediate research priority is to develop an integrated validation framework that combines expert \nevaluation, consistency analysis, and functional accuracy assessment. Rather than merely exploring these \nmethods individually, we will focus on creating a comprehensive system that automatically selects and applies \nthe most appropriate validation technique based on simulation context. This framework will incorporate \nhuman-in-the-loop assessment protocols for high-stakes simulations while utilizing automated validation \nfor routine tasks, creating a balanced approach that maximizes both efficiency and reliability across different \noperational requirements. To enhance scalability and stability for real-time simulations, we plan to investigate the \nintegration of local LLMs, which would reduce dependency on API connections and internet connectivity. This \napproach would enable more responsive system performance and greater operational autonomy, particularly in \nenvironments with limited or unreliable network access, while also potentially reducing latency issues that could \nimpact time-sensitive simulation applications in industrial settings.\nWe aim to strengthen the Ground AI concept by enhancing the agent paradigm with domain-specific \ncapabilities rather than simply utilizing specialized LLMs. By developing specialized agents with distinct \nroles and expertise in fields such as nuclear energy, mechanical engineering, and robotics, we can create a \nmore sophisticated multi-agent ecosystem. These domain-specialized agents would possess not only relevant \nknowledge but also specific reasoning patterns and validation protocols tailored to their respective domains. \nThis approach focuses on the functional specialization of agents within the orchestration architecture, enabling \nmore organized collaboration and domain-appropriate decision-making during simulation tasks. Building upon \nthis agent specialization, we will develop an adaptive orchestration mechanism that dynamically configures the \nmulti-agent system based on both task complexity and domain characteristics. This mechanism will intelligently \ndetermine the optimal composition of specialized agents, their interaction patterns, and the most effective \nvalidation strategy for each simulation task. By creating this context-aware orchestration layer, we can address \nthe current limitations of fixed validation approaches while maintaining high accuracy standards. The system \nwill learn from past simulation experiences to continuously refine its orchestration decisions, creating a truly \nadaptive framework that evolves alongside changing simulation requirements and domain knowledge.\nConclusions\nIn this study, we propose and implement a text-based simulation control architecture utilizing GPT-4o to \nenhance the efficiency and effectiveness of ultrasonic simulation control. By modularizing the functionalities \nof the SimNDT program into discrete functions and enabling simulation control based on natural language \ncommands, the average time required for simulation configuration is reduced significantly—from two minutes \nto approximately 30 seconds. This indicates a 75% reduction in data generation costs. This improvement \nillustrates the potential for AI-driven methodologies to facilitate the optimization of simulation processes. To \nScientific Reports |        (2025) 15:12474 12| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\naddress inherent limitations in LLM-based scenario generation, we introduced the Ground AI method, which \nintegrates self-review mechanisms and multi-agent collaboration for enhanced reliability. The implementation \nof this approach enables the system to detect inconsistencies in generated scenarios and regenerate outputs \nunder self-review guidance, significantly reducing the scenario generation error rate from 23.89% to 1.48%. This \nmarked improvement underlines the effectiveness of the Ground AI approach in managing complex simulation \ntasks and highlights the importance of verification mechanisms when deploying LLMs in technical domains \nrequiring high precision and consistency. Looking ahead, the proposed framework shows promise for real-\nworld industrial settings, particularly in digital twin architectures and other time-sensitive applications. Further \nresearch could explore GPU-accelerated or distributed processing to enhance real-time scalability, as well as \ndeeper investigations into reliability and security under practical constraints. By pursuing these avenues, our text-\nbased control method and Ground AI framework can evolve into a more versatile solution for comprehensive \nand autonomous simulation control.\nData Availibility\nThe datasets generated and analyzed during the current study were produced using generative AI models. These \ndatasets are available from the corresponding authors upon reasonable request.\nReceived: 9 January 2025; Accepted: 4 April 2025\nReferences\n 1. Chen, C.-H., Lin, C., Jeng, S.-Y ., Lin, H.-Y . & Yu, C.-Y . Using ultrasonic sensors and a knowledge-based neural fuzzy controller \nfor mobile robot navigation control. Multidiscipl. Digital Publish. Inst. 10, 466–466. https://doi.org/10.3390/electronics10040466 \n(2021).\n 2. Duan, A., Victorova, M., Zhao, J., Zheng, Y . & Navarro-Alarcon, D. Ultrasound-guided assistive robots for scoliosis assessment \nwith optimization-based control and variable impedance. Cornell University https://doi.org/10.48550/arxiv.2203.02126 (2022).\n 3. Y an, X. et al. Multi-modal interaction control of ultrasound scanning robots with safe human guidance and contact recovery. \nCornell University https://doi.org/10.48550/arxiv.2302.05685 (2023).\n 4. Schrage, M., Medany, M. & Ahmed, D. Ultrasound microrobots with reinforcement learning. Wiley 8,  h t t p s : / / d o i . o r g / 1 0 . 1 0 0 2 / a d \nm t . 2 0 2 2 0 1 7 0 2     (2023).\n 5. Fang, S., Du, Y ., Zhang, Y ., Meng, F . & Ang, M. H. Research on robotic compliance control for ultrasonic strengthening of aviation \nblade surface. Multidiscipl. Digital Publish. Inst. 14, 730–730. https://doi.org/10.3390/mi14040730 (2023).\n 6. Beber, L. et al. A passive variable impedance control strategy with viscoelastic parameters estimation of soft tissues for safe \nultrasonography. Cornell University https://doi.org/10.48550/arxiv.2309.14893 (2023).\n 7. Brown, T. et al. Language models are few-shot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. & Lin, H. (eds.) \nAdvances in Neural Information Processing Systems, vol. 33, 1877–1901 (Curran Associates, Inc., Virtual, 2020).\n 8. OpenAI et al. Gpt-4 technical report (2024). arXiv: 2303.08774.\n 9. Devlin, J., Chang, M.-W ., Lee, K. & Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. \nIn Burstein, J., Doran, C. & Solorio, T. (eds.) Proceedings of the 2019 Conference of the North American Chapter of the Association \nfor Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), vol. 1, 4171–4186 (Association \nfor Computational Linguistics, Minneapolis, Minnesota, 2019).\n 10. Molero Martínez, M. SimNDT: Ultrasound NDT simulation tool (2019). Github https://github.com/mmolero/SimNDT.\n 11. De Vos, L., Nevens, J., Van Eecke, P . & Beuls, K. Construction grammar and procedural semantics for human-interpretable \ngrounded language processing. Linguistics Vanguard (2024).\n 12. Van der Zee, D.-J. & Van der Vorst, J. A modeling framework for supply chain simulation: Opportunities for improved decision \nmaking. Decis. Sci. 36, 65–95. https://doi.org/10.1111/j.1540-5915.2005.00066.x (2005).\n 13. Mustafee, N. & Taylor, S. Speeding up simulation applications using wingrid. Concurr. Comput. Practice Exp.  21, 1504–1523. \nhttps://doi.org/10.1002/cpe.1401 (2009).\n 14. Vaswani, A. Attention is all you need. Adv. Neural Inf. Process. Syst. (2017).\n 15. Zheng, S. et al. The AI economist: Improving equality and productivity with AI-driven tax policies. Res. Pap. Econ. (2020).\n 16. Zheng, S.  T., Trott, A., Srinivasa, S., Parkes, D.  C. & Socher, R. The AI economist: Taxation policy design via two-level deep \nmultiagent reinforcement learning. Sci. Adv. 8, https://doi.org/10.1126/sciadv.abk2607 (2022).\n 17. Leiter, C. et al. Chatgpt: A meta-analysis after 2.5 months.. Mach. Learn. Appl. 16, 100541 (2024).\n 18. Maddigan, P . & Susnjak, T. Chat2vis: Generating data visualizations via natural language using chatgpt, codex and gpt-3 large \nlanguage models. IEEE Access 11, 45181–45193 (2023).\n 19. Kumar, V ., Gleyzer, L., Kahana, A., Shukla, K. & Karniadakis, G. E. Mycrunchgpt: A llm assisted framework for scientific machine \nlearning. J. Mach. Learn. Model. Comput. 4 (2023).\n 20. Hummer, W . et al. Modelops: Cloud-based lifecycle management for reliable and trusted ai. In 2019 IEEE International Conference \non Cloud Engineering (IC2E), 113–120 (IEEE, 2019).\n 21. Feng, X. et al. Large language model-based human-agent collaboration for complex task solving. In Al-Onaizan, Y ., Bansal, M. & \nChen, Y .-N. (eds.) Findings of the Association for Computational Linguistics: EMNLP 2024, 1336–1357,  h t t p s : / / d o i . o r g / 1 0 . 1 8 6 5 3 / v 1 \n/ 2 0 2 4 . fi   n d i n g s - e m n l p . 7 2     (Association for Computational Linguistics, Miami, Florida, USA, 2024).\n 22. Wang, C. et al. Lami: Large language models for multi-modal human-robot interaction. In Extended Abstracts of the CHI Conference \non Human Factors in Computing Systems, 1–10 (2024).\n 23. Mehandru, N. et al. Large language models as agents in the clinic (2023). arXiv: 2309.10895.\n 24. Wei, Y . et al. Editable scene simulation for autonomous driving via collaborative llm-agents. In Proceedings of the IEEE/CVF \nConference on Computer Vision and Pattern Recognition, 15077–15087 (2024).\n 25. Pan, X. et al. Very large-scale multi-agent simulation with LLM-powered agents (2025).\n 26. Li, R., Patel, T., Wang, Q. & Du, X. Mlr-copilot: Autonomous machine learning research based on large language models agents. \narXiv preprint arXiv:2408.14033 (2024).\n 27. Zhang, Y . et al. Towards efficient llm grounding for embodied multi-agent collaboration. Cornell University  h t t p s : / / d o i . o r g / 1 0 . 4 8 5 \n5 0 / a r X i v . 2 4 0 5 .     (2024).\n 28. Luan, Z. et al. Automatic robotic development through collaborative framework by large language models. In 2023 China \nAutomation Congress (CAC), 7736–7741 (IEEE, 2023).\n 29. Ramchurn, S. D., Stein, S. & Jennings, N. R. Trustworthy human-ai partnerships https://doi.org/10.1016/j.isci.2021.102891 (2021).\n 30. Liu, H. et al. Enhancing the llm-based robot manipulation through human-robot collaboration. Inst. Electr. Electron. Eng. 9, 6904–\n6911. https://doi.org/10.1109/lra.2024.3415931 (2024).\nScientific Reports |        (2025) 15:12474 13| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/\n 31. Knox, W . B., Stone, P . & Breazeal, C. Teaching agents with human feedback: a demonstration of the tamer framework. In Proceedings \nof the Companion Publication of the 2013 International Conference on Intelligent User Interfaces Companion, 65–66 (2013).\n 32. Park, M., Bong, G., Kim, J. & Kim, G. Structural analysis and design using generative AI. Struct. Eng. Mech. 91, 393–401 (2024).\n 33. Dorri, A., Kanhere, S. S. & Jurdak, R. Multi-agent systems: a survey. IEEE Access 6, 28573–28593 (2018).\n 34. Panait, L. & Luke, S. Cooperative multi-agent learning: The state of the art. Auton. Agent. Multi-Agent Syst. 11, 387–434 (2005).\n 35. Meng, Z., Li, J., Gong, Y . & Juang, B.-H. Adversarial teacher-student learning for unsupervised domain adaptation. In 2018 IEEE \nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP) , vol. 437, 5949–5953 (IEEE Press, Calgary, AB, \nCanada, 2018).\n 36. Filippova, K. Controlled hallucinations: Learning to generate faithfully from noisy data. In Cohn, T., He, Y . & Liu, Y . (eds.) Findings \nof the Association for Computational Linguistics: EMNLP 2020 , vol. Findings of the Association for Computational Linguistics: \nEMNLP 2020, 864–870 (Association for Computational Linguistics, Online, 2020).\n 37. Vanna.ai. Vanna.ai: Ai-powered sql generation and optimization (2024).\n 38. Wang, X. et al. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference \non Learning Representations (International Conference on Learning Representations, Kigali, Rwanda, 2023).\nAcknowledgements\nThis work was supported in part by the Korea Atomic Energy Research Institute R&D Program under Grant \nKAERI-524540-25 and in part by the National Research Foundation of Korea under Grant RS-2023-00253853 \nfunded by the Korean government.\nAuthor contributions\nS.K. and H.S. conceived the experiments. S.K. conducted the experiments. S.K., Y .Y ., and H.S. analyzed the re-\nsults. S.K. and H.S. wrote the manuscript. All authors provided critical feedback and helped shape the research \nand analysis of the manuscript.\nDeclarations\n Competing Interest\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 5 - 9 7 4 9 8 - y     .  \nCorrespondence and requests for materials should be addressed to H.S.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give \nappropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and \nindicate if changes were made. The images or other third party material in this article are included in the article’s \nCreative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included \nin the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy \nof this licence, visit http://creativecommons.org/licenses/by/4.0/.\n© The Author(s) 2025 \nScientific Reports |        (2025) 15:12474 14| https://doi.org/10.1038/s41598-025-97498-y\nwww.nature.com/scientificreports/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8692014217376709
    },
    {
      "name": "Scripting language",
      "score": 0.7577894330024719
    },
    {
      "name": "Scalability",
      "score": 0.6428816914558411
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.5927517414093018
    },
    {
      "name": "Task (project management)",
      "score": 0.5645995140075684
    },
    {
      "name": "Orchestration",
      "score": 0.5480334162712097
    },
    {
      "name": "Graphical user interface",
      "score": 0.4485463500022888
    },
    {
      "name": "Distributed computing",
      "score": 0.42294424772262573
    },
    {
      "name": "Human–computer interaction",
      "score": 0.38660377264022827
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3842417895793915
    },
    {
      "name": "Programming language",
      "score": 0.16343119740486145
    },
    {
      "name": "Systems engineering",
      "score": 0.12691327929496765
    },
    {
      "name": "Database",
      "score": 0.11412706971168518
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Musical",
      "score": 0.0
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    }
  ]
}