{
  "title": "Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology",
  "url": "https://openalex.org/W4390075090",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2778343793",
      "name": "Bahareh Fatemi",
      "affiliations": [
        "University of Bergen"
      ]
    },
    {
      "id": "https://openalex.org/A1913416610",
      "name": "Fazle Rabbi",
      "affiliations": [
        "University of Bergen"
      ]
    },
    {
      "id": "https://openalex.org/A716108625",
      "name": "Andreas L. Opdahl",
      "affiliations": [
        "University of Bergen"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6778883912",
    "https://openalex.org/W6854692045",
    "https://openalex.org/W3128655363",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6843135089",
    "https://openalex.org/W6774892182",
    "https://openalex.org/W2791521493",
    "https://openalex.org/W3173617765",
    "https://openalex.org/W2963626623",
    "https://openalex.org/W2726375170",
    "https://openalex.org/W4294982692",
    "https://openalex.org/W6682691769",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W4366729084",
    "https://openalex.org/W4366826292",
    "https://openalex.org/W4389523957",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W2939100138",
    "https://openalex.org/W6768851824",
    "https://openalex.org/W6850625674",
    "https://openalex.org/W2963912736",
    "https://openalex.org/W6852016728",
    "https://openalex.org/W6800875267",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W6851445559",
    "https://openalex.org/W6849640182",
    "https://openalex.org/W4362598103",
    "https://openalex.org/W4286987939",
    "https://openalex.org/W4297435087",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2954365773",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4366735603",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W4391494845",
    "https://openalex.org/W4391136507"
  ],
  "abstract": "News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism.",
  "full_text": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1 109/ACCESS.2023.0322000\nEvaluating the Effectiveness of GPT Large\nLanguage Model for News Classification in the\nIPTC News Ontology\nBAHAREH FATEMI1 , FAZLE RABBI1, and ANDREAS L. OPDAHL1\n1 Department of Information Science and Media Studies, University of Bergen, 5007 Bergen, Norway\nCorresponding authors: Bahareh Fatemi (e-mail: Bahareh.Fatemi@uib.no) and Fazle Rabbi (Fazle.Rabbi@uib.no)\nABSTRACT News classification plays a vital role in newsrooms, as it involves the time-consuming task\nof categorizing news articles and requires domain knowledge. Effective news classification is essential\nfor categorizing and organizing a constant flow of information, serving as the foundation for subsequent\ntasks, such as news aggregation, monitoring, filtering, and organization. Automation of this process can\nsignificantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the\nGPT large language model in a zero-shot setting for multi-class classification of news articles within the\nwidely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news\nontology provides a structured framework for categorizing news, facilitating the efficient organization and\nretrieval of news content. By investigating the effectiveness of the GPT language model in this classification\ntask, we aimed to understand its capabilities and potential applications in the news domain. This study was\nconducted as part of our ongoing research in the field of automated journalism.\nINDEX TERMS IPTC media topics , Journalism, Large language models, News classification.\nI. INTRODUCTION\nL\nARGE language models (LLMs) have demonstrated\ntheir proficiency in addressing a multitude of natural\nlanguage processing (NLP) tasks such as named entity recog-\nnition [23], text summarization [27] and sentiment analysis\n[12], and researchers from different domains such as com-\nputer science, medicine and social science, have recognized\nthe utility of these models and increasingly adopted them in\ntheir work. [3]. Within the news domain, researchers have\nalso shown notable interest in using Language Models for\ntasks that used to be performed in conventional ways. For\ninstance, LLMs have been used to develop creativity support\ntools that help journalists explore angles for reporting on\npress releases [15]. Yang et al. [26] investigated whether\nGPT, a large language model, can assess the credibility of\nnews outlets and provided evidence that its credibility ratings\nalign with human expert judgments, indicating its potential\nuse in fact-checking applications. Goyal et al. [6] examined\nthe impact of large language models, particularly GPT-3 [1],\non text summarization, showing their superior performance,\nespecially in tasks that require minimal human prompts.\nEffective news classification is essential for categorizing\nand organizing a constant flow of information, serving as the\nfoundation for subsequent tasks, such as news aggregation,\nmonitoring, filtering, and organization. However, multi-class\nclassification of news articles, in which each article is as-\nsigned to one category out of several possible categories, is\na challenging task. While immensely valuable for news or-\nganizations, the process of multi-class classification of news\narticles is time-consuming and disliked by journalists because\nof the need to carefully analyze and assign categorical labels\nto articles, considering the intricate intersections of news\ntopics and the contextual subtleties embedded within them.\nLLMs are well known for their ability to capture the com-\nplexities of language and context. In our investigation, we\nexplored the potential of the GPT language model [18] as\na foundational element to enhance the efficiency of classi-\nfying news articles, particularly within the widely accepted\nand utilized International Press Telecommunications Council\n(IPTC1) news ontology.\nIPTC media topics consist of a layered classification sys-\ntem used in the news industry. It encompasses a six-level\nhierarchical structure, offering a structured approach for cate-\ngorizing news subjects. This layered approach simplifies the\norganization and retrieval of news content, making it more\n1https://cv.iptc.org/newscodes/mediatopic/\nVOLUME 11, 2023 1\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nefficient for media professionals [20]. For example, Clercq\net al. [4] employed the IPTC news media topics standard to\nimprove the granularity and diversity of news article classifi-\ncation to enhance the representation of news content in their\nstudy on automated journalism.\nThe multiple levels of granularity of the IPTC ontology can\nbe intricate and potentially perplexing, even for news journal-\nists. Consequently, classifying content into fine-grained cate-\ngories within this framework is inherently more challenging,\ntedious, and cognitively demanding. Furthermore, achieving\nfine-grained classification often requires deep understanding\nof the domain, making it essential to be a domain expert in\naddition to being a journalist.\nIn our study, given the extensive size of the hierarchy, we\nchose to concentrate on the first two levels to align with our\nprimary goal of showcasing LLM’s capabilities. In particular,\nfinding a well-balanced dataset that adequately represents\neach fine-grained category poses a considerable challenge.\nThis decision helps strike a balance between task complexity\nand data availability for effective evaluation.\nIn this investigation, our research question revolves around\nthe effectiveness of utilizing GPT pre-trained language mod-\nels in news classification. By utilizing LLMs, we not only\ncategorize news articles effectively but also streamline con-\ntent retrieval in today’s digital news landscape. This lays\nthe foundation for future applications, such as tracking event\ndevelopment, which aligns with the underlying motivation\ndiscussed later. To evaluate our classification results, we em-\nployed both supervised and unsupervised machine learning\ntechniques as proxies because of the absence of a high-quality\ngold standard. The novelty of this work lies in its exploration\nof the potential benefits of integrating GPT pre-trained lan-\nguage models into news classification tasks, which have not\nbeen extensively explored before.\nThe remainder of this paper is structured as follows. In\nSection II, we delve into related work concerning news clas-\nsification, domain, and large language models. Section III is\ndedicated to our methods. In Section IV, we present the de-\ntails of our experiments and the obtained results. In Section V,\nwe examine existing limitations and outline potential avenues\nfor future research. Finally, the conclusions are presented in\nSection VI.\nII. ERLATED WORKS\nA. NEWS CLASSIFICATION\nNews classification is a challenging task that has been exten-\nsively studied by the research community. Traditional news\nclassification methods typically rely on hand-crafted features\n(e.g., the number of unique words in the news article, the\nnumber of times certain keywords appear) and machine learn-\ning algorithms such as support vector machines and deci-\nsion trees. However, the landscape of news classification has\nevolved with the emergence of deep learning-based meth-\nods that leverage word/document embedding techniques [13],\n[22], such as [10]. Additionally, a notable shift has emerged\ntowards utilizing convolutional neural networks (CNNs) for\nsentence classification [8]. Luo [11] explored the use of Long\nShort-Term Memory (LSTM) networks for text representa-\ntions. While these methods have shown promise, it is impor-\ntant to note that the effectiveness of text classification relies\non the model’s ability to capture global word co-occurrence\ninformation, a strength notably exemplified by transformer-\nbased models, such as BERT [5] and GPT [1]. These Trans-\nformers are at the forefront of natural language processing\nbecause of their unmatched capability to understand contexts,\nadapt to specific tasks, and efficiently handle diverse con-\ntent, making them particularly suitable for news classification\ntasks.\nB. LARGE LANGUAGE MODELS\nLarge Language Models such as GPT [1], T5 [19], and BERT\n[5], are versatile natural language processing models known\nfor their ability to capture extensive semantic and syntactic\ninformation within text. There are three general ways of using\nLLMs: fine-tuned, few-shot, and zero-shot settings. Fine-\ntuning involves adapting a pre-trained language model to\nexcel in specific tasks through additional training. Few-shot\nlearning is a paradigm where models learn new tasks from\na very small number of examples, and zero-shot learning\ntests a model’s ability to tackle new tasks it hasn’t been\nexplicitly trained for, relying on its inherent understanding\nof language and context. Zero-shot learning aims to solve\nunseen tasks without labeled training examples or gradient\nupdates. Recent research indicates that LLMs are superior at\nzero-shot learning [2], [24]. The zero-shot learning capability\nof GPT for different tasks is investigated by Qin et al, [17].\nIII. METHODS\nA. DATA ANNOTATION USING GPT API\nOpenai-python package 2 was used to query the API endpoint.\nSpecifically, we chose the gpt-3.5-turbo model, which is\ntrained up to September 2021. We set the temperature param-\neter to zero to minimize the randomness of output generation.\nIn zero-shot settings, formulating effective prompts is chal-\nlenging. GPT is not specifically trained for the IPTC clas-\nsification task; therefore using it alone to classify articles\ninto specific categories within this framework could result in\nunreliable outcomes. The risk of generating hallucinated out-\ncomes makes it necessary to supplement the model with the\nactual ontology. By providing GPT with the ontology, we can\nenhance the accuracy and credibility of article classification\nwithin the IPTC framework. For this purpose, we explored\ntwo prompting strategies, as illustrated in Figure 1:\n• Simultaneous Classification: In this approach, we pro-\nvided the model with the entire ontology and tasked it\nwith the simultaneous classification of a news article\ninto one of the Level-1 categories and its corresponding\nLevel-2 subcategories.\n• Hierarchical Classification : Conversely, in the hierar-\nchical approach, we initially provided the model with\n2https://github.com/openai/openai-python\n2 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nPrompt:Classify the {NEWS_ARTICLE} in one of the following 17 categories, and on of its subsequent subcategories:1- {CATEGORY!}      {SUBCATEGORY!!}      {SUBCATEGORY!\"}      … 2- {CATEGORY\"}      {SUBCATEGORY\"!}      {SUBCATEGORY\"\"}      …3- {CATEGORY#}      {SUBCATEGORY#!}      {SUBCATEGORY#\"}      …\nPrompt:Classify the {NEWS_ARTICLE} in one of the following 17 categories, and on of its subsequent subcategories:1- {CATEGORY!}2- {CATEGORY\"}3- {CATEGORY#}                    …\nPrompt:Classify the {NEWS_ARTICLE} in one of the following categories, and on of its subsequent subcategories:1- {SUBCATEGORY$!}2- {SUBCATEGORY$!}3- {SUBCATEGORY$!}                    …\nResponse:   -{CATEGORY$}\nSimultaneous Classification\nHierarchical Classification\nResponse:   -{SUBCATEGORY$!}\nResponse:        -{CATEGORY$} -{SUBCATEGORY$!}\nFIGURE 1: Simultaneous and hierarchical classification\nprompts.\nLevel-1 categories and requested it to classify the news\narticle accordingly. Once the Level-1 category was de-\ntermined, we then supplied the subcategories belong-\ning to the chosen category. Subsequently, we asked the\nmodel to classify the news article into one of the specific\nsubcategories within the chosen category.\nIn the Simultaneous Classification approach, we encoun-\ntered certain challenges:\n• First, the error rate was notably higher, resulting in mis-\nclassification. For instance, there were cases where an\narticle was classified into Level-1 Category A and Level-\n2 Category B, while, in fact, Category B was a subcate-\ngory of Level-1 Category C. As an example, the article\nwith title ‘‘Former Bayern and Man Utd star Bastian\nSchweinsteiger retires from playing football” was clas-\nsified in the first-level category of ‘‘ sport”, and second-\nlevel category of ‘‘ retirement” while ‘‘ retirement” is a\nsubcategory of ‘‘ labour”.\n• Second, the model exhibited instances of hallucinations,\ngenerating categories that did not align with the actual\nontology. For instance, an article with the title ‘‘10 of\nthe Best Russia Holiday Destinations – Beyond Moscow\nand St Petersburg” was classified into level-1 and level-\n2 categories ‘‘ travel” and ‘‘ Eco-tourism” which do not\nexist in the ontology.\nConversely, in the Hierarchical Classification strategy, we\nachieved significant improvements: 1) the issue of misclas-\nsifications was effectively resolved and 2) the problem of\nhallucination was mitigated to a considerable extent, such\nthat we did not observe any instances of hallucination in the\nfirst-level and only a few in the second-level classification.\nThis hierarchical approach demonstrates a more accurate and\nreliable classification process than the simultaneous strategy.\nIn igure 2, we showcase a set of subtractive word cloud\nvisualizations that specifically focus on the ‘‘ Education” cat-\negory. These visualizations offer a more granular perspective\nby highlighting distinctive terminologies associated with spe-\ncific subcategories within ‘‘ Education”, namely ‘‘ Curricu-\nlum”, ‘‘School” and ‘‘ Teachers”. By subtracting the common\nterms, these word clouds effectively emphasize the unique\nvocabulary that distinguishes each subcategory.\nB. EVALUATION\nWe employed a dual evaluation approach encompassing clas-\nsification and clustering techniques to demonstrate the effec-\ntiveness of the IPTC labels generated by the GPT, ensuring\ntheir suitability for downstream tasks and applications.\n• Classification: By assessing the performance of a clas-\nsification model on a labeled dataset, we can indirectly\ngauge the reliability of the assigned labels. The perfor-\nmance of the model depends on the quality and consis-\ntency of the labels. This approach provides a means to\nevaluate the annotation quality in the absence of a pre-\ndefined gold standard, ensuring that the assigned labels\nproperly represent the content of the dataset.\nThe classification task involved a diverse range of meth-\nods, including Multinomial Naive Bayes, Logistic Re-\ngression, Support Vector Machines (SVM), and Ran-\ndom Forest, all of which were evaluated using a 5-fold\ncross-validation setting. In addition to these traditional\nclassification algorithms, we incorporated state-of-the-\nart deep learning models, namely DistilBERT [21] and\nBERT [25], based on the complexity of the task and\nsize of the dataset. These models were strategically\nchosen for their ability to capture intricate contextual\ninformation and nuances within the text, which is crucial\nfor achieving accurate classification. For conventional\nmachine learning models, we employed two embedding\nmethods: TF-IDF and Glove [14]. These methods have\nbeen used to enhance the performance of traditional\nmodels.\n• Clustering:\nIn addition to classification, we conducted a cluster anal-\nysis on the dataset to evaluate the quality of the annota-\ntions in an unsupervised manner. We utilized the MNI\n(Normalized Mutual Information) and ARI (Adjusted\nRand Index) metrics, which are traditionally used for\nassessing clustering quality when ground truth labels are\navailable. In our context, we repurposed MNI and ARI\nto evaluate the effectiveness of annotations. Higher MNI\nand ARI values indicate that the assigned labels accu-\nrately capture article groupings, showcasing the higher\nquality of annotations.\nIV. EXPERIMENTS AND RESULTS\nGruppi et al. [7] presented a news dataset for the study of\nmisinformation in news articles. Later on, Petukhova et al.\n[16] annotated 10,917 news articles from this dataset based\non IPTC news codes. We used this dataset as the basis of our\nVOLUME 11, 2023 3\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nLevel1: education\n\"curriculum\" vs. \"teachers\" and \"school\"\n\"school\" vs. \"curriculum\" and \"teachers\"\n\"teachers\" vs. \"school\" and \"curriculum\"\nFIGURE 2: Subtractive Word Cloud: Contrasting Themes of ‘‘ Curriculum”, ‘‘ Teachers” and ‘‘ school”, subcategories of\n‘‘Education”\nstudy. In addition to evaluating the performance of GPT in\nmulti-class news classification, we compared our results with\ntwo other data annotations to which we had access to. We\nconducted a comparison among the three data annotations,\nwhich included:\n• We used the GPT-3.5 Turbo model to annotate each\nnews article using a hierarchical classification strategy.\nOwing to limitations in the number of input tokens in the\nGPT-3.5 model, we had to exclude some articles from\nconsideration.\n• We used the annotations presented in [16]. The dataset\ncontained several retired categories in the annotation,\nmaking it incompatible with the latest IPTC ontology;\ntherefore, we had to remove these instances.\nAlthough it is stated that the annotation was conducted\nmanually in a process involving keyword analysis and\narticle reading, it does not appear to represent a set\nof ground truth labels. We encountered inconsisten-\ncies in annotations. For instance, an article titled ‘‘ Can\nLactobacillus fermentum, a “good” bacteria, address\nglutathione deficiency? ” which discusses how taking a\nsupplement called Lactobacillus fermentum can help in-\ncrease the levels of an important antioxidant, is misclas-\nsified in the category ‘‘ environment”, while GPT more\naccurately identifies it as a topic related to ‘‘ health”.\nSuch observations raise several questions regarding the\nspecifics of their data annotation process and the anno-\ntators involved.\n• We utilized Expert-ai 3, a natural language processing\nplatform that provides IPTC news classification models.\nThere were instances of news articles where Expert-\nai was unable to process and annotate certain articles\neffectively, therefore we had to remove them.\nA major challenge encountered was obtaining a balanced\ndataset within the second-level categories, primarily due to\nthe high number of categories at that level. Consequently,\nsome second-level categories had very few articles, which\nled us to remove them. The final dataset consisted of 4,672\nnews articles covering 17 first-level categories and 51 second-\nlevel categories. The dataset is available at https://zenodo.org/\nrecords/10058298.\nFigure 3 visually represents the overlap or agreement be-\ntween different label sources within first-level categories us-\ning two heatmaps. As illustrated, the GPT-generated labels\nare in higher agreement with the labels in [16] rather than\nthe Experi-ai labels. Figure 4 shows the level of agreement\nbetween the three labeling mechanisms.\nA. CLASSIFICATION RESULTS\nWe report the precision, recall, and F1 scores for all the mod-\nels. Precision measures the accuracy of a model’s positive\npredictions, recall quantifies the coverage capability, and the\nF1 score provides a balanced assessment of precision and\nrecall. Tables 1 and 2 list the classification results.\n3https://www.expert.ai/\n4 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nhealth\nenvironment\nsport\ncrime, law and justice\nconflict, war and peace\nscience and technology\nsociety\nweather\nreligion and belief\neducation\narts, culture, entertainment and media\nlifestyle and leisure\ndisaster, accident and emergency incident\neconomy, business and finance\nhuman interest\nlabour\npolitics\nLabels in [16]\nhealth\nenvironment\nsport\ncrime, law and justice\nconflict, war and peace\nscience and technology\nsociety\nweather\nreligion and belief\neducation\narts, culture, entertainment and media\nlifestyle and leisure\ndisaster, accident and emergency incident\neconomy, business and finance\nhuman interest\nlabour\npolitics\nGPT-3.5-turbo\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n(a)\nhealth\nenvironment\nsport\ncrime, law and justice\nconflict, war and peace\nscience and technology\nsociety\nweather\nreligion and belief\neducation\narts, culture, entertainment and media\nlifestyle and leisure\ndisaster, accident and emergency incident\neconomy, business and finance\nhuman interest\nlabour\npolitics\nExpert-ai\nhealth\nenvironment\nsport\ncrime, law and justice\nconflict, war and peace\nscience and technology\nsociety\nweather\nreligion and belief\neducation\narts, culture, entertainment and media\nlifestyle and leisure\ndisaster, accident and emergency incident\neconomy, business and finance\nhuman interest\nlabour\npolitics\nGPT-3.5-turbo\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7 (b)\nFIGURE 3: The overlap between the labels in [16] 3a, and Expert-ai labels 3b with GPT generated labels\nGpt3.5 turbo Labels in [16] Expert-ai\nGpt3.5 turboLabels in [16]Expert-ai\n1.00 0.62 0.51\n0.62 1.00 0.44\n0.51 0.44 1.00\nLevel 1\nGpt3.5 turbo Labels in [16] Expert-ai\nGpt3.5 turboLabels in [16]Expert-ai\n1.00 0.28 0.17\n0.28 1.00 0.18\n0.17 0.18 1.00\nLevel 2\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nFIGURE 4: Percentage of agreement between the three label\nsources.\nAs illustrated, GPT outperformed the baseline in the Level-\n1 classification. This demonstrates its effectiveness in cat-\negorizing news articles into broader categories. The results\nindicate that GPT can do a decent job classifying articles into\none of the 17 Level-1 categories, showing its robustness in\nhandling high-level topic distinctions.\nHowever, it is worth noting that the results for Level-2\nclassification exhibited a lower performance in all three cases.\nThis could be attributed to the inherently higher difficulty\nof distinguishing between more fine-grained and thus more\nsimilar sub-classes on Level-2. Additionally, the sharp class\nimbalance in Level-2 is a contributing factor, with some\ncategories having a significantly larger number of articles,\nlike ‘‘crime” with 200 articles, in contrast to others such as\n‘‘teachers” with as few as 25 articles.\nClass imbalance within Level-2 categories is an important\nfactor to consider. When a classification model exhibits a\nstrong bias towards predicting the majority class, in this con-\ntext, possibly ‘‘crime” due to the larger number of related ar-\nticles, it achieves high precision for that class. High precision\nimplies that the model accurately identifies a significant por-\ntion of ‘‘crime” articles. However, this bias negatively impacts\nrecall, especially for minority classes like ‘‘ teachers”, as the\nmodel might overlook or misclassify a substantial number of\n‘‘teachers” articles. Consequently, the recall of these minority\nclasses tends to be low.\nB. CLUSTERING RESULTS\nIn Tables 3 and 4, two scores NMI and ARI are reported,\nwhich are used to evaluate the performance of clustering\nalgorithms by comparing the clustering results to ground truth\nlabels:\n• NMI : measures the mutual information between the\ntrue class labels (if available) and the cluster assignments\nand is normalized to provide a score between 0 and 1.\nIt quantifies the degree of agreement between the true\nlabels and clusters.\n• ARI : (Adjusted Rand Index) is a clustering evaluation\nmetric that measures the agreement between clustering\nresults and true labels while considering chance correc-\ntion. It provides a score between -1 and 1, where 1 indi-\ncates perfect agreement, 0 implies random chance, and\nnegative values suggest worse than chance agreement.\nHigher ARI and NMI scores for the LLM-generated labels\nafter clustering indicated that the clustering results obtained\nusing this label set were more consistent with the generated\nlabels. This implies that these labels capture the underlying\nstructure and characteristics of the data better.\nTo give a visual impression of the difference between the\nthree label-sets, in Figure 5, a 2D presentation of the articles\nVOLUME 11, 2023 5\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nTABLE 1: Level-1 classificatoin results\nTF-IDF Glove DistilBert/BertEmbedding\nModel Precision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score\nGPT-3.5 Turbo\nMultinomial NB 0.78 0.75 0.75 0.74 0.62 0.64 - - -\nLogistic Regression 0.78 0.73 0.75 0.80 0.77 0.78 - - -\nSVC Classifier 0.78 0.76 0.76 0.81 0.78 0.78 - - -\nRandom Forest 0.79 0.72 0.73 0.81 0.75 0.77 - - -\nDistilBERT - - - - - - 0.81 0.77 0.78\nBERT - - - - - - 0.82 0.83 0.82\nAvg. 0.78 0.74 0.75 0.79 0.73 0.74 0.82 0.80 0.80\nLabels in [16]\nMultinomial NB 0.76 0.69 0.70 0.60 0.51 0.51 - - -\nLogistic Regression 0.79 0.69 0.71 0.74 0.70 0.71 - - -\nSVC Classifier 0.79 0.75 0.76 0.73 0.71 0.71 - - -\nRandom Forest 0.79 0.72 0.74 0.73 0.66 0.67 - - -\nDistilBERT - - - - - - 0.75 0.74 0.74\nBERT - - - - - - 0.72 0.73 0.70\nAvg. 0.78 0.71 0.73 0.68 0.65 0.65 0.74 0.74 0.72\nExpertAI\nMultinomial NB 0.58 0.54 0.52 0.45 0.43 0.42 - - -\nLogistic Regression 0.61 0.52 0.52 0.57 0.54 0.54 - - -\nSVC Classifier 0.59 0.58 0.57 0.54 0.54 0.53 - - -\nRandom Forest 0.61 0.55 0.55 0.62 0.55 0.55 - - -\nDistilBERT - - - - - - 0.58 0.58 0.58\nBERT - - - - - - 0.57 0.61 0.56\nAvg. 0.60 0.55 0.54 0.55 0.52 0.51 0.58 0.60 0.57\nTABLE 2: Level-2 classificatoin results\nModel TF-IDF Glove DistilBert Embedding\nPrecision Recall F1-Score Precision Recall F1-Score Precision Recall F1-Score\nGPT-3.5 Turbo\nMultinomial NB 0.64 0.52 0.53 0.52 0.41 0.40 - - -\nLogistic Regression 0.60 0.50 0.50 0.65 0.59 0.59 - - -\nSVC Classifier 0.65 0.59 0.59 0.62 0.59 0.59 - - -\nRandom Forest 0.62 0.52 0.52 0.63 0.55 0.56 - - -\nDistilBERT - - - - - - 0.61 0.60 0.59\nAvg. 0.63 0.53 0.54 0.61 0.54 0.54 0.61 0.60 0.59\nLabels in [16]\nMultinomial NB 0.49 0.47 0.45 0.40 0.39 0.37 - - -\nLogistic Regression 50 0.49 0.47 0.49 0.49 0.47 - - -\nSVC Classifier 0.54 0.53 0.52 0.49 0.49 0.47 - - -\nRandom Forest 0.47 0.48 0.46 0.44 0.43 0.42 - - -\nDistilBERT - - - - - - 0.51 0.50 0.49\nAvg. 0.50 0.49 0.48 0.46 0.45 0.43 0.51 0.50 0.49\nExpertAI\nMultinomial NB 0.24 0.21 0.20 0.15 0.13 0.12 - - -\nLogistic Regression 0.21 0.19 0.18 0.24 0.22 0.22 - - -\nSVC Classifier 0.33 0.30 0.29 0.27 0.27 0.26 - - -\nRandom Forest 0.32 0.24 0.25 0.31 0.24 0.25 - - -\nDistilBERT - - - - - - 0.28 0.27 0.27\nAvg. 0.28 0.24 0.23 0.24 0.22 0.21 0.28 0.27 0.27\ncolor-coded with their first-level IPTC labels is presented.\nFigure 5a shows the output of agglomerative clustering. As\nillustrated, in 5b the clusters of news articles exhibit more\ndistinct and well-defined formations and look more similar\nto the actual clusters in 5a, which confirms that the GPT-\ngenerated labels are more reliable.\nV. DISCUSSION AND FUTURE WORK\nThe utilization of fine-tuned large language models for vari-\nous tasks, including news classification, offers several advan-\ntages. First, the cost associated with using LLMs such as GPT,\nin a production environment for processing vast news archives\ncan be prohibitive. However, fine-tuning less expensive mod-\nels is a cost-efficient alternative that can deliver comparable\nor even superior results. Second, fine-tuning the language\n6 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nTABLE 3: Level-1 clustering results\nKmeans Clustering Agglomerative Clustering\nNMI ARI NMI ARI\nGPT-3.5 Turbo 0.58 0.44 0.57 0.42\nLabels in [16] 0.46 0.29 0.48 0.32\nExpert.ai 0.37 0.25 0.36 0.22\nTABLE 4: Level-2 clustering results\nKmeans Clustering Agglomerative Clustering\nNMI ARI NMI ARI\nGPT-3.5 Turbo 0.55 0.27 0.54 0.26\nLabels in [16] 0.49 0.15 0.50 0.15\nExpert.ai 0.39 0.18 0.37 0.17\n0 2 4 6 8 10 12 14\nUMAP Dimension 1\n5.0\n2.5\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\nUMAP Dimension 2\nGpt3.5 Turbo\n(a) Clusters\n0 2 4 6 8 10 12 14\nUMAP Dimension 1\n5.0\n2.5\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\nUMAP Dimension 2\nGpt3.5 Turbo (b) GPT-3.5 Turbo\n0 2 4 6 8 10 12 14\nUMAP Dimension 1\n5.0\n2.5\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\nUMAP Dimension 2\nManual\n(c) Manual labels\n0 2 4 6 8 10 12 14\nUMAP Dimension 1\n5.0\n2.5\n0.0\n2.5\n5.0\n7.5\n10.0\n12.5\nUMAP Dimension 2\nExpert.ai (d) Expert.ai\nFIGURE 5: 2D visualization of the of the news articles color-coded by their labels\nmodels in a few-shot settings reduces the need for prompt\nengineering. By using null prompts, that contain neither task-\nspecific templates nor training examples, competitive accu-\nracy can be achieved across a wide range of tasks [9]. This\napproach simplifies the process of fine-tuning and eliminates\nthe need for extensive manual prompt tuning, thereby saving\ntime and effort in the classification process. Third, adopting\nfine-tuned LLMs will allow the creation of a fixed and robust\nVOLUME 11, 2023 7\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nmodel that remains consistent over time. This consistency\nis particularly crucial in the sensitive news domain, where\nreliability and predictability are paramount. Unlike generic\nLLMs which may undergo changes or updates, a fine-tuned\nmodel can maintain its stability, and ensure consistent and\nreliable news analysis. This feature is essential in scenarios\nwhere dynamic model behavior is undesirable, such as news\ncontent analysis.\nFurthermore, the task of analyzing news data extends be-\nyond mere text comprehension; it requires a deep understand-\ning of the events being reported and their broader contextual\nimplications. large language models, while being adept at\nprocessing text, lack embedded knowledge of the historical\nand contextual factors shaping news stories. As an example,\nthe GPT classified the article with the title ‘‘Syria’s Post-\nWar Reconstruction: 600 Establishments Resume Work at\nAleppo Industrial City, Sheikh Najjar” into the ‘‘ economy,\nbusiness and finance, economy ” category because it discusses\nthe recovery and development of Aleppo’s industrial city,\ninvestments, and various business establishments resuming\ntheir operations with limited emphasis on the conflict aspect\ndue to mentions of war and sanctions. However, the lack of\ncontextual information prevented it from being categorized\nunder ‘‘ conflict, war, and peace, post-war reconstruction ”\na more contextually accurate classification. Therefore, there\nis a growing need to enhance the functionality of LLMs\nby incorporating background information, thereby enabling\nthem to trace the development of news over time. Contextual\nawareness not only empowers LLMs to categorize news arti-\ncles more accurately but also offers a deeper comprehension\nof how various events interrelate within a larger narrative.\nOur future research will involve a more comprehensive\napproach to classifying news articles, encompassing other\nlevels of the IPTC ontology. This will allow us to analyze\nnews content more effectively and accurately, enabling us to\nextract significant information about various events occurring\nworldwide. This would contribute to enhancing our knowl-\nedge and decision-making processes in various domains, such\nas conflict resolution, disaster management, public health and\nenvironmental policies.\nVI. CONCLUSION\nIn conclusion, our study highlights the potential of large\nlanguage models in news classification within the field of\njournalism and media research, addressing the need for au-\ntomation in this task. The desirable performance demon-\nstrated by these models suggests that they can alleviate the\nworkload of journalists and media researchers by automating\nthe time-consuming and labor-intensive classification pro-\ncess. By leveraging the capabilities of large language models,\njournalists can focus their efforts on more critical aspects\nof news reporting, such as investigative journalism and in-\ndepth analysis. Moreover, our experiment, conducted in a\n‘‘zero-shot” setting, emphasizes the versatility of these mod-\nels, as they achieved impressive results without task-specific\ntraining. This underscores the potential usefulness of large\nlanguage models in improving the efficiency and accuracy\nin journalism and media research, ultimately enabling jour-\nnalists to deliver news more effectively to their audiences. As\nthe field continues to evolve, the integration of large language\nmodels holds promise for revolutionizing the way news is\nanalyzed and processed, meeting the growing demand for\nautomated solutions in journalism.\nVII. ACKNOWLEDGMENT\nThis research is funded by SFI MediaFutures partners and the\nResearch Council of Norway (grant number 309339).\nREFERENCES\n[1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D\nKaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish\nSastry, Amanda Askell, et al. Language models are few-shot learners.\nAdvances in neural information processing systems , 33:1877–1901, 2020.\n[2] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-V oss, Gretchen Krueger,\nT. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff\nWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz\nLitwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam\nMcCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language\nmodels are few-shot learners. ArXiv, abs/2005.14165, 2020.\n[3] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen,\nLinyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. A survey\non evaluation of large language models. arXiv preprint arXiv:2307.03109 ,\n2023.\n[4] Orphée De Clercq, Luna De Bruyne, and Véronique Hoste. News topic\nclassification as a first step towards diverse news recommendation. Com-\nputational Linguistics in the Netherlands Journal , 10:37–55, 2020.\n[5] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:\nPre-training of deep bidirectional transformers for language understanding.\nIn North American Chapter of the Association for Computational Linguis-\ntics, 2019.\n[6] Tanya Goyal, Junyi Jessy Li, and Greg Durrett. News summarization and\nevaluation in the era of gpt-3. arXiv preprint arXiv:2209.12356 , 2022.\n[7] Maurício Gruppi, Benjamin D. Horne, and Sibel Adalı. Nela-gt-2019: A\nlarge multi-labelled news dataset for the study of misinformation in news\narticles, 2020.\n[8] Abdalraouf Hassan and Ausif Mahmood. Convolutional recurrent deep\nlearning model for sentence classification. Ieee Access , 6:13949–13957,\n2018.\n[9] Robert L Logan IV , Ivana Balavzevi’c, Eric Wallace, Fabio Petroni, Sameer\nSingh, and Sebastian Riedel. Cutting down on prompts and parameters:\nSimple few-shot learning with language models. In Findings, 2021.\n[10] Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov.\nBag of tricks for efficient text classification. In Proceedings of the 15th\nConference of the European Chapter of the Association for Computational\nLinguistics: Volume 2, Short Papers, pages 427–431, Valencia, Spain, April\n2017. Association for Computational Linguistics.\n[11] Yuan Luo. Recurrent neural networks for classifying relations in clinical\nnotes. Journal of biomedical informatics , 72:85–95, 2017.\n[12] Rui Mao, Qian Liu, Kai He, Wei Li, and Erik Cambria. The biases of pre-\ntrained language models: An empirical study on prompt-based sentiment\nanalysis and emotion detection. IEEE Transactions on Affective Comput-\ning, 2022.\n[13] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean.\nDistributed representations of words and phrases and their compositional-\nity. Advances in neural information processing systems , 26, 2013.\n[14] Jeffrey Pennington, Richard Socher, and Christopher Manning. GloVe:\nGlobal vectors for word representation. In Proceedings of the 2014 Con-\nference on Empirical Methods in Natural Language Processing (EMNLP) ,\npages 1532–1543, Doha, Qatar, October 2014. Association for Computa-\ntional Linguistics.\n[15] Savvas Petridis, Nicholas Diakopoulos, Kevin Crowston, Mark Hansen,\nKeren Henderson, Stan Jastrzebski, Jeffrey V Nickerson, and Lydia B\nChilton. Anglekindling: Supporting journalistic angle ideation with large\n8 VOLUME 11, 2023\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/\nlanguage models. In Proceedings of the 2023 CHI Conference on Human\nFactors in Computing Systems , pages 1–16, 2023.\n[16] Alina Petukhova and Nuno Fachada. Mn-ds: A multilabeled news dataset\nfor news articles hierarchical classification. Data, 8(5):74, 2023.\n[17] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro\nYasunaga, and Diyi Yang. Is chatgpt a general-purpose natural language\nprocessing task solver? arXiv preprint arXiv:2302.06476 , 2023.\n[18] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.\nImproving language understanding by generative pre-training. 2018.\n[19] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\nNarang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring\nthe limits of transfer learning with a unified text-to-text transformer. J.\nMach. Learn. Res. , 21(1), jan 2020.\n[20] Charlotte Rudnik, Thibault Ehrhart, Olivier Ferret, Denis Teyssou, Raphael\nTroncy, and Xavier Tannier. Searching news articles using an event\nknowledge graph leveraged by wikidata. In Companion Proceedings of\nThe 2019 World Wide Web Conference , WWW ’19, page 1232–1239, New\nYork, NY , USA, 2019. Association for Computing Machinery.\n[21] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distil-\nbert, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR,\nabs/1910.01108, 2019.\n[22] Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen,\nXinyuan Zhang, Ricardo Henao, and Lawrence Carin. Joint embedding of\nwords and labels for text classification. arXiv preprint arXiv:1805.04174 ,\n2018.\n[23] Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei\nZhang, Jiwei Li, and Guoyin Wang. Gpt-ner: Named entity recognition via\nlarge language models. arXiv preprint arXiv:2304.10428 , 2023.\n[24] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu,\nBrian Lester, Nan Du, Andrew M. Dai, and Quoc V . Le. Finetuned language\nmodels are zero-shot learners. ArXiv, abs/2109.01652, 2021.\n[25] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement\nDelangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan\nFuntowicz, et al. Transformers: State-of-the-art natural language process-\ning. In Proceedings of the 2020 conference on empirical methods in natural\nlanguage processing: system demonstrations , pages 38–45, 2020.\n[26] Kai-Cheng Yang and Filippo Menczer. Large language models can rate\nnews outlet credibility, 2023.\n[27] Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McK-\neown, and Tatsunori B Hashimoto. Benchmarking large language models\nfor news summarization. arXiv preprint arXiv:2301.13848 , 2023.\nBAHAREH FATEMIreceived her master’s degree\nin information technology engineering (Network\nscience branch) from the University of Tehran,\nTeheran, Iran. She is currently pursuing her Ph.D.\nin the department of information science and me-\ndia studies at the University of Bergen, Norway.\nHer research interests include machine learning,\ntextual content analysis and network science.\nFAZLE RABBIFAZLE RABBI received the Doc-\ntor of Philosophy (Ph.D.) degree in software en-\ngineering from the University of Oslo. He is cur-\nrently an Associate Professor at the University of\nBergen, Norway. He has long and varied expe-\nrience with software development in smaller and\nlarger projects within a large spectrum of domain\nareas and technological solutions. His research in-\nterests include model-based software engineering,\ndata mining, and machine learning, with emphasis\non addressing the information science problems in the society. His research\nportfolio includes software engineering related research: workflow modeling\nand its verification, metamodeling, building decision support systems, multi-\nagent systems, and process engineering.\nANDREAS L. OPDAHL received the Ph.D. de-\ngree from the Norwegian University of Science\nand Technology (NTNU), in 1992. He is currently\na Professor in information systems development\nat the University of Bergen, Norway, where he\nheads the Research Group for Intelligent Informa-\ntion Systems (I2S). His research interests include\nontologies and knowledge graphs, enterprise, and\nIS modeling and their applications to media pro-\nduction. He is the author, the coauthor, or a co-\neditor of more than a 100 peer-reviewed and widely cited research papers.\nHe is a member of IFIP WG5.8 on Enterprise Interoperability and WG8.1\non Design and Evaluation of Information Systems. He serves as an associate\neditor or renowned international journals and as an organizer of renowned\ninternational conferences and workshops.\nVOLUME 11, 2023 9\nThis article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and \ncontent may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2023.3345414\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License. For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7803747653961182
    },
    {
      "name": "Ontology",
      "score": 0.6124269366264343
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5360671877861023
    },
    {
      "name": "Task (project management)",
      "score": 0.4805786609649658
    },
    {
      "name": "Information retrieval",
      "score": 0.4306839108467102
    },
    {
      "name": "Process (computing)",
      "score": 0.4264158308506012
    },
    {
      "name": "Field (mathematics)",
      "score": 0.4207311272621155
    },
    {
      "name": "Engineering",
      "score": 0.07358196377754211
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4432739",
      "name": "University of Bergen",
      "country": "NO"
    }
  ]
}