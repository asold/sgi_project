{
    "title": "Ensembling Transformers for Cross-domain Automatic Term Extraction",
    "url": "https://openalex.org/W4311429496",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A5007410381",
            "name": "Hanh Thi Hong Tran",
            "affiliations": [
                "Jožef Stefan International Postgraduate School"
            ]
        },
        {
            "id": "https://openalex.org/A5000491019",
            "name": "Matej Martinc",
            "affiliations": [
                "Jožef Stefan International Postgraduate School"
            ]
        },
        {
            "id": "https://openalex.org/A5006308310",
            "name": "Andraž Pelicon",
            "affiliations": [
                "Jožef Stefan International Postgraduate School"
            ]
        },
        {
            "id": "https://openalex.org/A5033491986",
            "name": "Antoine Doucet",
            "affiliations": [
                "La Rochelle Université"
            ]
        },
        {
            "id": "https://openalex.org/A5074881863",
            "name": "Senja Pollak",
            "affiliations": [
                "Jožef Stefan Institute"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3171975879",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W2129706127",
        "https://openalex.org/W1993241979",
        "https://openalex.org/W6702248584",
        "https://openalex.org/W3088048224",
        "https://openalex.org/W1537288903",
        "https://openalex.org/W2977455704",
        "https://openalex.org/W2044070623",
        "https://openalex.org/W2999134449",
        "https://openalex.org/W2888790259",
        "https://openalex.org/W2296283641",
        "https://openalex.org/W3176491997",
        "https://openalex.org/W2994980856",
        "https://openalex.org/W2019937474",
        "https://openalex.org/W2131041446",
        "https://openalex.org/W2973833293",
        "https://openalex.org/W2986154550",
        "https://openalex.org/W2135737105",
        "https://openalex.org/W1556255569",
        "https://openalex.org/W2963848110",
        "https://openalex.org/W2924225635",
        "https://openalex.org/W3195449034",
        "https://openalex.org/W4312318284",
        "https://openalex.org/W4311429496",
        "https://openalex.org/W3216786839",
        "https://openalex.org/W2047917219",
        "https://openalex.org/W2616647696",
        "https://openalex.org/W2996854111",
        "https://openalex.org/W6601141708",
        "https://openalex.org/W2796219422",
        "https://openalex.org/W3103187652"
    ],
    "abstract": null,
    "full_text": "Ensembling Transformers for Cross-domain\nAutomatic Term Extraction\nHanh Thi Hong Tran1,2,3[0000−0002−5993−1630], Matej\nMartinc1[0000−0002−7384−8112], Andraz Pelicon1[0000−0002−2060−6670], Antoine\nDoucet3[0000−0001−6160−3356], and Senja Pollak2[0000−0002−4380−0863]\n1 Jožef Stefan International Postgraduate School,\nJamova cesta 39, 1000 Ljubljana, Slovenia\ntran.hanh@ijs.si\n2 Jožef Stefan Institute,\nJamova cesta 39, 1000 Ljubljana, Slovenia\n3 University of La Rochelle,\n23 Av. Albert Einstein, La Rochelle, France\nPlease cite the paper as:\nHanhThiHongTRAN,MatejMARTINC,AndrazPELICON,Antoine\nDOUCET and Senja POLLAK (2022): Ensembling Transformers for\nCross-domain Automatic Term Extraction In: Tseng, YH., Katsurai,\nM., Nguyen, H.N. (eds.) From Born-Physical to Born-Virtual: Aug-\nmenting Intelligence in Digital Libraries. ICADL 2022. Lecture Notes\nin Computer Science, vol 13636, pp. pp. 90–100, 2022. Springer, Cham.\nhttps://doi.org/10.1007/978-3-031-21756-2_7.\nAbstract. Automatic term extraction plays an essential role in domain\nlanguage understanding and several natural language processing down-\nstream tasks. In this paper, we propose a comparative study on the\npredictive power of Transformers-based pretrained language models to-\nward term extraction in a multi-language cross-domain setting. Besides\nevaluating the ability of monolingual models to extract single- and multi-\nword terms, we also experiment with ensembles of mono- and multilin-\ngual models by conducting the intersection or union on the term output\nsets of diﬀerent language models. Our experiments have been conducted\non the ACTER corpus covering four specialized domains (Corruption,\nWind energy, Equitation, and Heart failure) and three languages (En-\nglish, French, and Dutch), and on the RSDO5 Slovenian corpus cover-\ning four additional domains (Biomechanics, Chemistry, Veterinary, and\nLinguistics). The results show that the strategy of employing monolin-\ngual models outperforms the state-of-the-art approaches from the related\nwork leveraging multilingual models, regarding all the languages except\nDutch and French if the term extraction task excludes the extraction of\nnamed entity terms. Furthermore, by combining the outputs of the two\nbest performing models, we achieve signiﬁcant improvements.\nKeywords: Automatic term extraction· ATE· low resource· ACTER\n· RSDO5 · monolingual · cross-domain.\narXiv:2212.05696v1  [cs.CL]  12 Dec 2022\n2 Tran et al.\n1 Introduction\nAutomatic Term Extraction (ATE) is the task of identifying specialized termi-\nnology from the domain-speciﬁc corpora. By easing the time and eﬀort needed\nto manually extract the terms, ATE is not only widely used for terminograph-\nical tasks (e.g., glossary construction [26], specialized dictionary creation [22],\netc.) but it also contributes to several complex downstream tasks (e.g., machine\ntranslation [40], information retrieval [23], sentiment analysis [28], to cite a few).\nWith recent advances in natural language processing (NLP), a new family of\ndeep neural approaches, namely Transformers [38], has been pushing the state-\nof-the-art (SOTA) in several sequence-labeling semantic tasks, e.g., named entity\nrecognition (NER) [18,37] and machine translation [41], among others. The Ter-\nmEval 2020 Shared Task on Automatic Term Extraction, organized as part of\nthe CompuTerm workshop [31], presented one of the ﬁrst opportunities to sys-\ntematically study and compare various ATE systems with the advent of The\nAnnotated Corpora for Term Extraction Research (ACTER) dataset [31,32], a\nnovel corpora covering four domains and three languages. Regarding Slovenian,\nthe RSDO54 corpus [13] was created with texts from four specialized domains.\nInspired by the success of Transformers for ATE in the TermEval 2020, we pro-\npose an extensive study of their performance in a cross-domain sequence-labeling\nsetting and evaluate diﬀerent factors that inﬂuence extraction eﬀectiveness. The\nexperiments are conducted on two datasets: ACTER and RSDO5 corpora.\nOur major contributions can be summarized as the three following points:\n– AnempiricalevaluationofseveralmonolingualandmultilingualTransformer-\nbased language models, including both masked (e.g., BERT and its variants)\nand autoregressive (e.g., XLNet) models, on the cross-domain ATE tasks;\n– Filling the research gap in ATE task for Slovenian by experimenting with\ndiﬀerent models to achieve a new SOTA in the RSDO5 corpus.\n– An ensembling Transformer-based model for ATE that further improves the\nSOTA in the ﬁeld.\nThis paper is organized as follows: Section 2 presents the related work in\nterm extraction. Next, we introduce our methodology in Section 3, including\nthe dataset description, the workﬂow, and experimental settings, as well as the\nevaluation metrics. The corresponding results are presented in Section 4. Finally,\nwe conclude the paper and present future directions in Section 5.\n2 Related work\nThe research into monolingual ATE was ﬁrst introduced during the 1990s [6,15]\nand the methods at the time included the following two-step procedure: (1) ex-\ntracting a list of candidate terms; and (2) determining which of these candidate\nterms are correct using either supervised or unsupervised techniques. We brieﬂy\nsummarize diﬀerent supervised ATE techniques according to their evolution be-\nlow.\n4 https://www.clarin.si/repository/xmlui/handle/11356/1470\nEnsembling Transformers for Cross-domain Automatic Term Extraction 3\n2.1 Approaches based on term characteristics and statistics\nThe ﬁrst ATE approaches leveraged linguistic knowledge and distinctive linguis-\ntic aspects of terms to extract a possible candidate list. Several NLP techniques\nare employed to obtain the term’s linguistic proﬁle (e.g., tokenization, lemmati-\nzation, stemming, chunking, etc.). On the other hand, several studies proposed\nstatistical approaches toward ATE, mostly relying on the assumption that a\nhigher candidate term frequency in a domain-speciﬁc corpus (compared to the\nfrequency in the general corpus) implies a higher likelihood that a candidate is\nan actual term. Some popular statistical measures include termhood [39], unit-\nhood [5] or C-value [10]. Many current systems still apply their variations or rely\non a hybrid approach combining linguistic and statistical information [16,30].\n2.2 Approaches based on machine learning and deep learning\nThe recent advances in word embeddings and deep neural networks have also in-\nﬂuenced the ﬁeld of term extraction. Several embeddings have been investigated\nfor the task at hand, e.g., non-contextual [43,1], contextual [17] word embed-\ndings, and the combination of both [11]. The use of language models for ATE\ntasks is ﬁrst documented in the TermEval 2020 [31] on the trilingual ACTER\ndataset. While the Dutch corpus winner used BiLSTM-based neural architecture\nwith GloVe word embeddings, the English corpus winner [12] fed all possible ex-\ntracted n-gram combinations into a BERT binary classiﬁer. Several Transformer\nvariations have also been investigated [12] (e.g., BERT, RoBERTa, Camem-\nBERT, etc.) but no systematic comparison of their performance has been con-\nducted. Later, the HAMLET approach [33] proposed a hybrid adaptable machine\nlearning system that combines linguistic and statistical clues to detect terms. Re-\ncently, sequence-labeling approaches became the most popular modeling option.\nThey were ﬁrst introduced by [17] and then employed by [20] to compare several\nATE methods (e.g., binary sequence classiﬁer, sequence classiﬁer, token classi-\nﬁer). Finally, cross-lingual sequence labeling proposed in [4,20,35] demonstrates\nthe capability of multilingual models and the potential of cross-lingual learning.\n2.3 Approaches for Slovenian term extraction\nThe ATE research for the less-resourced languages, especially Slovenian, is still\nhindered by the lack of gold standard corpora and the limited use of neural\nmethods. Regarding the corpora, the recently compiled Slovenian KAS corpus\n[8] was quickly followed by the domain-speciﬁc RSDO5 corpus [14]. Regarding\nthe methodologies, techniques evolved from purely statistical [39] to more ma-\nchinelearningbasedapproaches.Forexample,[25]extractedtheinitialcandidate\nterms using the CollTerm tool [29], a rule-based system employing a language-\nspeciﬁc set of term patterns from the Slovenian SketchEngine module [9]. The\nderived candidate list was then ﬁltered using a machine learning classiﬁer with\nfeatures representing statistical measures. Another recent approach [30] focused\non the evolutionary algorithm for term extraction and alignment. Finally, [36]\nwas one of the ﬁrst to explore the deep neural approaches for Slovenian term\nextraction, employing XLMRoBERTa in cross- and multilingual settings.\n4 Tran et al.\n3 Methods\nWe brieﬂy describe our chosen datasets in Section 3.1, the general methodology\nin Section 3.2 and the chosen evaluation metrics in Section 3.3.\n3.1 Datasets\nThe experiments have been conducted on two datasets: ACTER v1.5 [31] and\nRSDO5 v1.1 [13]. The ACTER dataset is a manually annotated collection of 12\ncorpora covering four domains, Corruption (corp), Dressage (equi), Wind energy\n(wind), and Heart failure (htﬂ), in three languages, English (en), French (fr),\nand Dutch (nl). It has two versions of gold standard annotations: one including\nboth terms and named entities (NES), and the other containing only terms\n(ANN). Meanwhile, the RSDO5 corpus v1.1 [13] includes texts in Slovenian\n(sl), a less-resourced Slavic language with rich morphology. Compiled during the\nRSDOnationalproject,thecorpuscontains12documentscoveringfourdomains,\nBiomechanics (bim), Chemistry (kem), Veterinary (vet), and Linguistics (ling).\n3.2 Workﬂow\nWe consider ATE as a sequence-labeling task [35] with IOB labeling regime\n[33,20]. The model is ﬁrst trained to predict a label for each token in the input\ntext sequence and then applied to theunseen testdata. From the token sequences\nlabeled as terms, the ﬁnal candidate term list for the test data is composed.\n3.2.1 Empirical evaluation of pretrained language modelsWe conduct\na systematic evaluation of mono- and multilingual Transformers-based mod-\nels on the ATE task modeled as sequence labeling. The models were obtained\nfrom Huggingface5 according to the number of downloads and likes criteria.\nThe chosen models are presented in Fig. 1. Regarding the multilingual systems,\nwe investigate the performance of mBERT [7] (bert-base-multilingual-uncased),\nmDistilBERT [34] (distilbert-base-multilingual-cased), InforXLM [2] (microsoft/\ninfoxlm-base), and XLMRoBERTa [3] (xlm-roberta-base). All the chosen multi-\nlingual models are ﬁne-tuned in a monolingual fashion due to ﬁndings from the\nrelated work [20,35] showing that no (or only marginal) gains are obtained if the\nmodel is ﬁne-tuned on the multilingual training data.\nRegarding the monolingual models, we evaluate several English autoencoding\nTransformer-based models, including ALBERT [19] (albert-base-v1 and albert-\nbase-v2),BERT[7]( bert-base-uncased),DistilBERT[34]( distilbert-base-uncased),\nELECTRA (electra-small-generator) and RoBERTa [24] (xlm-roberta-base), and\none autoregressive model, XLNet [42] (xlnet-base-cased). For French, we use\nCamemBERT[27]( camembert-base)andFlauBERT[21]( ﬂaubert_base_uncased),\nforDutch,weemployBERTje( bert-base-dutch-cased)andRobBERT( robBERT-\nbase and robbert-v2-dutch-base) models, and for Slovenian, we choose SloBERTa\n(sloberta), the RoBERTa-based model trained on a large Slovenian corpus.\n5 https://huggingface.co/models\nEnsembling Transformers for Cross-domain Automatic Term Extraction 5\nFig.1: Empirical evaluation of pretrained language models on the ATE task.\n3.2.2 EnsembleofTransformermodels RegardingresultsinSection3.2.1,\nwe propose a novel ensembling approach based on Transformer models for ATE\ntask as we observe the general tendency for Precision to be better than Recall\nfor all but few monolingual and multilingual models tested (see Tables 1 and\n2). This leads us to believe that by combing the outputs of diﬀerent models,\nwe could achieve improvements in Recall and by extension also in the overall\nF1-score. We consider two strategies for combining the outputs from diﬀerent\nmodels of the ensemble, namely the union and the intersection of the candidate\nterm lists from the models of the ensemble. See the entire procedure in Fig. 2.\nFig.2: The general ensembling workﬂow.\nWe hypothesize that by combining the outputs of two models, we might be\nabletosigniﬁcantlyimprovetheRecallofthetermextractionsystem.Tovalidate\nthis hypothesis, we test three combinations: Combine the outputs of the (1) best\nmono- and multilingual models; (2) two best monolingual models; and (3) two\nbest multilingual models.\n3.3 Evaluation metrics\nWe evaluate each term extraction system by comparing the aggregated list of\ncandidate terms extracted on the level of the whole test set with the manually\nannotated gold standard term list using Precision, Recall, and F1-score. These\nevaluation metrics have also been used in the related work [12,20,31].\n6 Tran et al.\n4 Results\nWe ﬁrst present the results of mono- and multilingual Transformer-based models\nobtained on ACTER and RSDO5 test sets compared with the SOTAs. Then, we\ndemonstrate the impact of the ensemble post-processing step.\n4.1 Monolingual evaluation\n4.1.1 ACTER corpus Not many approaches have been tested on the AC-\nTER corpus v1.5 due to its novelty. Thus, we apply the approach proposed by\n[20] (i.e., employing XLMRoBERTa as a token classiﬁer), which achieved SOTA\non the previous corpus version, and consider it as a baseline. The Heart failure\ndomain is used as a test set, the same as in TermEval 2020.\nTable 1: Results of monolingual term extraction on the ACTER dataset.\nModels ANN NESPrecision Recall F1-scorePrecision Recall F1-score\nMono\nalbert-base-v1 52.58 47.40 49.8654.42 54.63 54.52albert-base-v2 49.85 48.50 49.1757.01 55.13 56.05bert-base-uncased59.0632.44 41.8861.42 47.50 53.57distilbert-base-uncased58.24 38.75 46.5461.06 48.24 53.90electra-small-generator56.46 46.80 51.1858.17 47.31 52.18roberta-base 58.10 51.04 54.3462.2856.3059.14xlnet-base-cased56.5053.92 55.1858.3457.3057.82\nMultibert-base-multilingual-uncased55.21 35.24 43.0262.0649.44 55.04distilbert-base-multilingual-cased55.14 45.45 49.8357.10 54.20 55.61infoxlm-base 57.67 54.64 56.1161.1854.48 57.64xlm-roberta-base (baseline)57.3451.4654.24 58.8055.5257.11\n(a) English corpus\nModels ANN NESPrecision Recall F1-scorePrecision Recall F1-score\nMono camembert-base70.51 44.97 54.9270.74 52.23 60.09ﬂauberta 75.91 26.17 38.9275.28 39.01 51.39\nMultibert-base-multilingual-uncased67.77 37.66 48.4269.3948.9957.43distilbert-base-multilingual-cased64.45 43.45 51.9165.20 48.78 55.81infoxlm-base 68.74 39.77 50.3971.1048.9057.95xlm-roberta-base (baseline)68.8548.6156.9970.7146.4656.08\n(b) French corpus\nModels ANN NESPrecision Recall F1-scorePrecision Recall F1-score\nMono bert-base-dutch-cased65.5965.53 65.5667.6166.02 66.81robBERT-base69.58 36.84 48.1771.63 55.01 62.23robbert-v2-dutch-base71.5636.40 48.2573.5855.72 63.42\nMultibert-base-multilingual-uncased70.6762.49 66.3372.34 63.71 67.75distilbert-base-multilingual-cased69.80 61.28 65.2669.4566.1567.76infoxlm-base 70.43 66.7368.5373.47 64.2468.55xlm-roberta-base (baseline)68.5367.9468.2373.9360.6566.63\n(c) Dutch corpus\nIn general, multilingual pretrained models outperform the monolingual ones\nin Recall and F1-score when applied for extraction of the ANN annotations in\nall three languages. If named entities are included (NES), monolingual models\noutperform multilingual models in two (English and French) out of three lan-\nguages in the ACTER dataset. When it comes to individual models, InfoXLM\noutperforms other mono- and multilingual models in the F1-score on the Dutch\ncorpus (for both ANN and NES) and on the English corpus (for ANN). If we\ncompare the results of our study with the XLMRoBERTa baseline using the\nsame monolingual settings from [20], our best-performing models surpass the\nbaseline in all cases (e.g., the F1-score increases by 1.87% on ANN and 1.5% on\nEnsembling Transformers for Cross-domain Automatic Term Extraction 7\nNES in the English corpus; 4.01% on French NES; 0.3% on ANN and 1.92% on\nNES in the Dutch corpus) except for the French ANN annotations.\n4.1.2 RSDO5 corpus We also compare the performance of diﬀerent mono-\nand multilingual models on the RSDO5 corpus, Here, we evaluate the models\non all domains as demonstrated in Table 2. By using two domains from the\nRSDO5 corpus for training, the third one for validation, and the last one for\ntesting, all the models prove to have relatively consistent performance across\ndiﬀerent combinations. The monolingual SloBERTa model outperforms other\napproaches (including the XLMRoBERTa baseline from [36]) in all cases by a\nrelatively large margin in F1-score. By employing this model and looking at the\nbest performing train/validation combinations for each test domain, we improve\nthe SOTA baseline in the Linguistics domain by 2.21%, in Veterinary by 2.35%,\nin Chemistry by 5.26%, and in Biomechanics by 2.66% regarding F1-score. Our\nresults, thus, set a new SOTA on the Slovenian corpus.\nTable 2: Results of monolingual term extraction on the RSDO5 dataset.\nTrainingValTest xlm-roberta-base sloberta infoxlm-basePrecion Recall F1-scorePrecion Recall F1-scorePrecion Recall F1-score\nbim + kemvetling 69.55 64.05 66.69 73.23 70.51 71.84 68.37 71.38 69.84bim + vetkemling 66.20 72.38 69.15 73.91 73.53 73.72 67.74 71.46 69.55kem + vetbimling 69.48 73.66 71.51 74.45 73.96 74.2073.71 66.90 70.14\nbim + kemlingvet 71.06 66.72 68.82 77.56 65.96 71.2971.04 63.69 67.16bim + lingkemvet 72.66 65.59 68.94 78.3365.31 71.23 66.88 68.93 67.89ling + kembimvet 69.30 68.07 68.68 76.66 64.89 70.29 72.69 63.63 67.86\nbim + vetlingkem 68.67 55.13 61.16 72.14 65.88 68.87 67.77 60.40 63.87bim + lingvetkem 70.23 59.24 64.27 70.29 68.45 69.36 72.00 56.58 63.37ling + vetbimkem 70.14 60.27 64.83 73.5266.96 70.09 71.22 59.49 64.83\nvet + kemlingbim 62.25 65.20 63.69 67.97 67.36 67.66 63.60 60.59 62.06vet + lingkembim 62.35 63.99 63.16 68.9766.62 67.77 56.66 67.53 61.62ling + kemvetbim 63.51 66.80 65.11 67.15 67.79 67.47 60.61 64.04 62.28\nTrainingValTestbert-base-multilingual-uncaseddistilbert-base-multilingual-casedPrecion Recall F1-scorePrecion Recall F1-score\nbim + kemvetling 66.77 65.86 66.31 61.82 53.38 57.29bim + vetkemling 66.80 68.01 67.40 59.14 67.20 62.91kem + vetbimling 65.97 69.62 67.75 60.94 58.16 59.52\nbim + kemlingvet 68.18 61.56 64.70 63.76 58.70 61.13bim + lingkemvet 68.58 65.46 66.98 65.83 58.15 61.75ling + kembimvet 69.12 60.61 64.59 66.01 54.02 59.42\nbim + vetlingkem 65.35 59.73 62.41 55.73 60.52 58.03bim + lingvetkem 65.53 63.22 64.35 60.15 55.83 57.91ling + vetbimkem 67.32 53.96 59.90 59.53 57.70 58.60\nvet + kemlingbim 62.63 60.85 61.73 57.84 55.84 56.82vet + lingkembim 65.25 58.30 61.58 60.62 56.36 58.41ling + kemvetbim 62.69 63.61 63.15 62.04 52.44 56.84\n4.2 Transformer ensembling\nWealsoevaluatetheperformanceoftheproposedensemblingapproachdescribed\nin Section 3.2.2. The improvements/decline in performance over the best single\nmodel on diﬀerent languages of the ACTER dataset are shown in Fig. 3. The\nresults indicate that combining the acquired term sets of the two best-performing\nclassiﬁers (no matter what type of classiﬁers they are) using the union always\nresults in the biggest gain.\n8 Tran et al.\nFig.3: F1-score improvement by combining two best classiﬁers in ACTER.\n5 Conclusion\nWeproposedanempiricalevaluationofdiﬀerentmono-andmultilingualTransformers-\nbased models on the monolingual sequence-labeling cross-domain term extrac-\ntion. The experiments were conducted on the trilingual ACTER dataset and\nthe Slovenian RSDO5 dataset. Furthermore, we tested how ensembling diﬀerent\nmono- or multilingual models aﬀects the performance of the overall term extrac-\ntor. The results demonstrate that multilingual models outperform the monolin-\ngual ones in Recall and F1-score when applied for ANN extraction. Meanwhile,\nmonolingual models capture the information about terms better than multilin-\ngual ones when it comes to the extraction of NES annotations. We also showed\nthat by ensembling diﬀerent Transformer models we can obtain further boosts in\nperformance for all languages. As a consequence, we established the new SOTA\non the ACTER and RSDO5 datasets.\nIn the future, we would like to take advantage of prompt engineering by\nconsidering ATE as a language model ranking problem in a sequence-to-sequence\nframework, where original sentences and statement templates ﬁlled by candidate\nterms are regarded as the source sequence and the target.\nAcknowledgementsThe work was partially supported by the Slovenian Re-\nsearch Agency (ARRS) core research programme Knowledge Technologies (P2-\n0103), and the Ministry of Culture of the Republic of Slovenia through the\nproject Development of Slovene in Digital Environment (RSDO). The ﬁrst au-\nEnsembling Transformers for Cross-domain Automatic Term Extraction 9\nthor was partly funded by Region Nouvelle Aquitaine. This work has also been\nsupported by the TERMITRAD (2020-2019-8510010) project funded by the\nNouvelle-Aquitaine Region, France.\nReferences\n1. Amjadian, E., Inkpen, D., Paribakht, T., Faez, F.: Local-Global Vectors to Im-\nprove Unigram Terminology Extraction. In: Proceedings of the 5th International\nWorkshop on Computational Terminology (Computerm2016). pp. 2–11 (2016)\n2. Chi, Z., Dong, L., Wei, F., Yang, N., Singhal, S., Wang, W., Song, X., Mao, X.L.,\nHuang, H.Y., Zhou, M.: Infoxlm: An information-theoretic framework for cross-\nlingual language model pre-training. In: Proceedings of the 2021 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies. pp. 3576–3588 (2021)\n3. Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán,\nF., Grave, E., Ott, M., Zettlemoyer, L., Stoyanov, V.: Unsupervised cross-lingual\nrepresentation learning at scale. arXiv preprint arXiv:1911.02116 (2019)\n4. Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán,\nF., Grave, E., Ott, M., Zettlemoyer, L., Stoyanov, V.: Unsupervised cross-lingual\nrepresentation learning at scale. In: ACL (2020)\n5. Daille, B., Gaussier, É., Langé, J.M.: Towards Automatic Extraction of Monolin-\ngual and Bilingual Terminology. In: COLING 1994 Volume 1: The 15th Interna-\ntional Conference on Computational Linguistics (1994)\n6. Damerau, F.J.: Evaluating computer-generated domain-oriented vocabularies. In-\nformation processing & management26(6), 791–801 (1990)\n7. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of\nDeep Bidirectional Transformers for Language Understanding. arXiv preprint\narXiv:1810.04805 (2018)\n8. Erjavec, T., Fišer, D., Ljubešić, N.: The kas corpus of slovenian academic writing.\nLanguage Resources and Evaluation55(2), 551–583 (2021)\n9. Fišer, D., Suchomel, V., Jakubícek, M.: Terminology extraction for academic\nslovene using sketch engine. In: Tenth Workshop on Recent Advances in Slavonic\nNatural Language Processing, RASLAN 2016. pp. 135–141 (2016)\n10. Frantzi, K.T., Ananiadou, S., Tsujii, J.: The c-value/nc-value method of automatic\nrecognition for multi-word terms. In: International conference on theory and prac-\ntice of digital libraries. pp. 585–604. Springer (1998)\n11. Gao, Y., Yuan, Y.: Feature-less End-to-end Nested Term extraction. In: CCF In-\nternational Conference on Natural Language Processing and Chinese Computing.\npp. 607–616. Springer (2019)\n12. Hazem, A., Bouhandi, M., Boudin, F., Daille, B.: TermEval 2020: TALN-LS2N\nSystem for Automatic Term Extraction. In: Proceedings of the 6th International\nWorkshop on Computational Terminology. pp. 95–100 (2020)\n13. Jemec Tomazin, M., Trojar, M., Atelšek, S., Fajfar, T., Erjavec, T., Žagar Karer,\nM.: Corpus of term-annotated texts RSDO5 1.1 (2021),http://hdl.handle.net/\n11356/1470, slovenian language resource repository CLARIN.SI\n14. Jemec Tomazin, M., Trojar, M., Žagar, M., Atelšek, S., Fajfar, T., Erjavec, T.:\nCorpus of term-annotated texts rsdo5 1.0 (2021)\n15. Justeson, J.S., Katz, S.M.: Technical Terminology: Some Linguistic Properties and\nan Algorithm for Identiﬁcation in Text. Natural language engineering1(1), 9–27\n(1995)\n10 Tran et al.\n16. Kessler,R.,Béchet,N.,Berio,G.:Extractionofterminologyintheﬁeldofconstruc-\ntion. In: 2019 First International Conference on Digital Data Processing (DDP).\npp. 22–26. IEEE (2019)\n17. Kucza, M., Niehues, J., Zenkel, T., Waibel, A., Stüker, S.: Term Extraction via\nNeural Sequence Labeling a Comparative Evaluation of Strategies Using Recurrent\nNeural Networks. In: INTERSPEECH. pp. 2072–2076 (2018)\n18. Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., Dyer, C.: Neural Ar-\nchitectures for Named Entity Recognition. In: Proceedings of the 2016 Conference\nof the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies. pp. 260–270 (2016)\n19. Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.: Albert: A\nlite bert for self-supervised learning of language representations. arXiv preprint\narXiv:1909.11942 (2019)\n20. Lang, C., Wachowiak, L., Heinisch, B., Gromann, D.: Transforming term ex-\ntraction: Transformer-based approaches to multilingual term extraction across\ndomains. In: Findings of the Association for Computational Linguistics: ACL-\nIJCNLP 2021. pp. 3607–3620 (2021)\n21. Le, H., Vial, L., Frej, J., Segonne, V., Coavoux, M., Lecouteux, B., Allauzen, A.,\nCrabbe, B., Besacier, L., Schwab, D.: Flaubert: Unsupervised language model pre-\ntraining for french. In: LREC (2020)\n22. Le Serrec, A., L’Homme, M.C., Drouin, P., Kraif, O.: Automating the compila-\ntion of specialized dictionaries: Use and analysis of term extraction and lexical\nalignment. Terminology. International Journal of Theoretical and Applied Issues\nin Specialized Communication16(1), 77–106 (2010)\n23. Lingpeng, Y., Donghong, J., Guodong, Z., Yu, N.: Improving retrieval eﬀective-\nness by using key terms in top retrieved documents. In: European Conference on\nInformation Retrieval. pp. 169–184. Springer (2005)\n24. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,\nZettlemoyer, L., Stoyanov, V.: RoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach. arXiv preprint arXiv:1907.11692 (2019)\n25. Ljubešić, N., Fišer, D., Erjavec, T.: Kas-term: Extracting Slovene Terms from\nDoctoral Theses via Supervised Machine Learning. In: International Conference\non Text, Speech, and Dialogue. pp. 115–126. Springer (2019)\n26. Maldonado, A., Lewis, D.: Self-tuning ongoing terminology extraction retrained\non terminology validation decisions. In: Proceedings of The 12th International\nConference on Terminology and Knowledge Engineering. pp. 91–100 (2016)\n27. Martin, L., Muller, B., Suárez, P.J.O., Dupont, Y., Romary, L., de la Clergerie,\nÉ.V., Seddah, D., Sagot, B.: CamemBERT: a Tasty French Language Model. arXiv\npreprint arXiv:1911.03894 (2019)\n28. Pavlopoulos, J., Androutsopoulos, I.: Aspect term extraction for sentiment analy-\nsis: New datasets, new evaluation measures and an improved unsupervised method.\nIn: Proceedings of the 5th Workshop on Language Analysis for Social Media\n(LASM). pp. 44–52 (2014)\n29. Pinnis, M., Ljubešić, N., Ştefănescu, D., Skadin, a, I., Tadić, M., Gornostaja, T.,\nVintar, Š., Fišer, D.: Extracting data from comparable corpora. In: Using Com-\nparable Corpora for Under-Resourced Areas of Machine Translation, pp. 89–139.\nSpringer (2019)\n30. Repar, A., Podpečan, V., Vavpetič, A., Lavrač, N., Pollak, S.: TermEnsembler:\nAn Ensemble Learning Approach to Bilingual Term Extraction and Alignment.\nTerminology. International Journal of Theoretical and Applied Issues in Specialized\nCommunication 25(1), 93–120 (2019)\nEnsembling Transformers for Cross-domain Automatic Term Extraction 11\n31. Rigouts Terryn, A., Hoste, V., Drouin, P., Lefever, E.: TermEval 2020: Shared Task\non Automatic Term Extraction Using the Annotated Corpora for Term Extraction\nResearch (ACTER) Dataset. In: 6th International Workshop on Computational\nTerminology (COMPUTERM 2020). pp. 85–94. European Language Resources\nAssociation (ELRA) (2020)\n32. Rigouts Terryn, A., Hoste, V., Lefever, E.: In no uncertain terms: a dataset for\nmonolingual and multilingual automatic term extraction from comparable corpora.\nLanguage Resources and Evaluation54(2), 385–418 (2020)\n33. Rigouts Terryn, A., Hoste, V., Lefever, E.: HAMLET: Hybrid Adaptable Machine\nLearning approach to Extract Terminology. Terminology (2021)\n34. Sanh, V., Debut, L., Chaumond, J., Wolf, T.: DistilBERT, a Distilled Version\nof BERT: Smaller, Faster, Cheaper and Lighter. arXiv preprint arXiv:1910.01108\n(2019)\n35. Tran, H.T.H., Martinc, M., Doucet, A., Pollak, S.: Can cross-domain term extrac-\ntion beneﬁt from cross-lingual transfer? In: International Conference on Discovery\nScience. pp. 363–378. Springer (2022)\n36. Tran, H., Martinc, M., Doucet, A., Pollak, S.: A transformer-based sequence-\nlabeling approach to the slovenian cross-domain automatic term extraction. In:\nSubmitted to Slovenian conference on Language Technologies and Digital Human-\nities (2022, under review)\n37. Tran, T.H.H., Doucet, A., Sidere, N., Moreno, J.G., Pollak, S.: Named entity recog-\nnition architecture combining contextual and global features. In: Towards Open\nand Trustworthy Digital Societies: 23rd International Conference on Asia-Paciﬁc\nDigital Libraries, ICADL 2021, Virtual Event, December 1–3, 2021, Proceedings.\np. 264. Springer Nature (2021)\n38. Vaswani,A.,Shazeer,N.,Parmar,N.,Uszkoreit,J.,Jones,L.,Gomez,A.N.,Kaiser,\nL., Polosukhin, I.: Attention Is All You Need. arXiv preprint arXiv:1706.03762\n(2017)\n39. Vintar, S.: Bilingual Term Recognition Revisited: The Bag-of-equivalents Term\nAlignment Approach and its Evaluation. Terminology. International Journal of\nTheoretical and Applied Issues in Specialized Communication 16(2), 141–158\n(2010)\n40. Wolf, P., Bernardi, U., Federmann, C., Hunsicker, S.: From statistical term extrac-\ntion to hybrid machine translation. In: Proceedings of the 15th Annual conference\nof the European Association for Machine Translation (2011)\n41. Yang, J., Wang, M., Zhou, H., Zhao, C., Zhang, W., Yu, Y., Li, L.: Towards\nmaking the most of bert in neural machine translation. In: Proceedings of the\nAAAI conference on artiﬁcial intelligence. vol. 34, pp. 9378–9385 (2020)\n42. Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., Le, Q.V.: XL-\nNet: Generalized Autoregressive Pretraining for Language Understanding. arXiv\npreprint arXiv:1906.08237 (2019)\n43. Zhang, Z., Gao, J., Ciravegna, F.: Semre-rank: Improving automatic term ex-\ntraction by incorporating semantic relatedness with personalised pagerank. ACM\nTransactions on Knowledge Discovery from Data (TKDD)12(5), 1–41 (2018)"
}