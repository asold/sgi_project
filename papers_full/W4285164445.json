{
    "title": "Robust Lottery Tickets for Pre-trained Language Models",
    "url": "https://openalex.org/W4285164445",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A1965480461",
            "name": "Rui Zheng",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2050672564",
            "name": "Bao Rong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2132424017",
            "name": "Yuhao Zhou",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2161150583",
            "name": "Di Liang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2105896935",
            "name": "Sirui Wang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1993208100",
            "name": "Wei Wu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2117552295",
            "name": "Tao Gui",
            "affiliations": [
                "Fudan University"
            ]
        },
        {
            "id": "https://openalex.org/A1964204209",
            "name": "Qi Zhang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2161482855",
            "name": "Xuanjing Huang",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2970120757",
        "https://openalex.org/W2948947170",
        "https://openalex.org/W2949128310",
        "https://openalex.org/W3009751875",
        "https://openalex.org/W3101449015",
        "https://openalex.org/W3167304302",
        "https://openalex.org/W3207932789",
        "https://openalex.org/W2950630935",
        "https://openalex.org/W2964116600",
        "https://openalex.org/W3090615801",
        "https://openalex.org/W2548228487",
        "https://openalex.org/W2995816250",
        "https://openalex.org/W2242818861",
        "https://openalex.org/W3176647794",
        "https://openalex.org/W3104263050",
        "https://openalex.org/W2113459411",
        "https://openalex.org/W2963859254",
        "https://openalex.org/W4293846201",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W3175505246",
        "https://openalex.org/W2963828549",
        "https://openalex.org/W2982561504",
        "https://openalex.org/W2251939518",
        "https://openalex.org/W3197868468",
        "https://openalex.org/W3092642435",
        "https://openalex.org/W3118485687",
        "https://openalex.org/W2962818281",
        "https://openalex.org/W2170240176",
        "https://openalex.org/W3035204084",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W3103754749",
        "https://openalex.org/W2995197005",
        "https://openalex.org/W3177190797",
        "https://openalex.org/W3105604018",
        "https://openalex.org/W2990844796",
        "https://openalex.org/W2805003733",
        "https://openalex.org/W2908510526",
        "https://openalex.org/W3153955842",
        "https://openalex.org/W3104423855",
        "https://openalex.org/W3007685714",
        "https://openalex.org/W2965373594",
        "https://openalex.org/W2996851481",
        "https://openalex.org/W3035736465",
        "https://openalex.org/W4288347855",
        "https://openalex.org/W2948130861",
        "https://openalex.org/W2547875792",
        "https://openalex.org/W4287864863"
    ],
    "abstract": "Recent works on Lottery Ticket Hypothesis have shown that pre-trained\\nlanguage models (PLMs) contain smaller matching subnetworks(winning tickets)\\nwhich are capable of reaching accuracy comparable to the original models.\\nHowever, these tickets are proved to be notrobust to adversarial examples, and\\neven worse than their PLM counterparts. To address this problem, we propose a\\nnovel method based on learning binary weight masks to identify robust tickets\\nhidden in the original PLMs. Since the loss is not differentiable for the\\nbinary mask, we assign the hard concrete distribution to the masks and\\nencourage their sparsity using a smoothing approximation of L0\\nregularization.Furthermore, we design an adversarial loss objective to guide\\nthe search for robust tickets and ensure that the tickets perform well bothin\\naccuracy and robustness. Experimental results show the significant improvement\\nof the proposed method over previous work on adversarial robustness evaluation.\\n",
    "full_text": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nVolume 1: Long Papers, pages 2211 - 2224\nMay 22-27, 2022c⃝2022 Association for Computational Linguistics\nRobust Lottery Tickets for Pre-trained Language Models\nRui Zheng⋆∗, Rong Bao⋆∗, Yuhao Zhou⋆, Di Liang♠, Sirui Wang♠,\nWei Wu♠, Tao Gui♦†, Qi Zhang⋆,♣, Xuanjing Huang⋆\n⋆ School of Computer Science, Fudan University, Shanghai, China\n♦ Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China\n♣ Shanghai Collaborative Innovation Center of Intelligent Visual Computing, Fudan University\n♠ Meituan Inc., Beijing, China\n{rzheng20,rbao18,tgui,qz,xjhuang}@fudan.edu.cn\nzhouyh21@m.fudan.edu.cn\nAbstract\nRecent works on Lottery Ticket Hypothesis\nhave shown that pre-trained language models\n(PLMs) contain smaller matching subnetworks\n(winning tickets) which are capable of reaching\naccuracy comparable to the original models.\nHowever, these tickets are proved to be not\nrobust to adversarial examples, and even worse\nthan their PLM counterparts. To address this\nproblem, we propose a novel method based on\nlearning binary weight masks to identify robust\ntickets hidden in the original PLMs. Since the\nloss is not differentiable for the binary mask,\nwe assign the hard concrete distribution to the\nmasks and encourage their sparsity using a\nsmoothing approximation of L0 regularization.\nFurthermore, we design an adversarial loss\nobjective to guide the search for robust tickets\nand ensure that the tickets perform well both\nin accuracy and robustness. Experimental\nresults show the significant improvement of\nthe proposed method over previous work on\nadversarial robustness evaluation.\n1 Introduction\nLarge-scale pre-trained language models (PLMs),\nsuch as BERT (Devlin et al., 2019), Roberta\n(Liu et al., 2019) and T5 (Raffel et al., 2019)\nhave achieved great success in the field of natural\nlanguage processing. As more transformer layers\nare stacked with larger self-attention blocks, the\ncomplexity of PLMs increases rapidly. Due to the\nover-parametrization of PLMs, some Transformer\nheads and even layers can be pruned without\nsignificant losses in performance (Michel et al.,\n2019; Kovaleva et al., 2019; Rogers et al., 2020).\nThe Lottery Ticket Hypothesis suggests an over-\nparameterized network contains certain subnet-\nworks (i.e., winning tickets) that can match the\nperformance of the original model when trained\nin isolation (Frankle and Carbin, 2019). Chen\n∗ ∗Equal contribution.\n†Corresponding authors.\net al. (2020); Prasanna et al. (2020) also find\nthese winning tickets exist in PLMs. Chen et al.\n(2020) prune BERT in an unstructured fashion\nand obtain winning tickets at sparsity from 40%\nto 90%. Prasanna et al. (2020) aim at finding\nstructurally sparse tickets for BERT by pruning\nentire attention heads and MLP. Previous works\nmainly focused on using winning tickets to reduce\nmodel size and speed up training time (Chen et al.,\n2021), while little work has been done to explore\nmore benefits, such as better adversarial robustness\nthan the original model.\nAs we all know, PLMs are vulnerable to\nadversarial examples that are legitimately crafted\nby imposing imperceptible perturbations on normal\nexamples (Jin et al., 2020; Garg and Ramakrishnan,\n2020; Wang et al., 2021). Recent studies have\nshown that pruned subnetworks of PLMs are even\nless robust than their PLM counterparts (Xu et al.,\n2021; Du et al., 2021). Xu et al. (2021) observe\nthat when fine-tuning the pruned model again,\nthe model yields a lower robustness. Du et al.\n(2021) clarify the above phenomenon further: the\ncompressed models overfit on shortcut samples\nand thus perform consistently less robust than the\nuncompressed large model on adversarial test sets.\nIn this work, our goal is to find robust PLM\ntickets that, when fine-tuned on downstream tasks,\nachieve matching test performance but are more\nrobust than the original PLMs. In order to make\nthe topology structure of tickets learnable, we\nassign binary masks to pre-trained weights to\ndetermine which connections need to be removed.\nTo solve discrete optimization problem of binary\nmasks, we assume the masks follow a hard\nconcrete distribution (a soft version of the Bernoulli\ndistribution), which can be solved using Gumbel-\nSoftmax trick (Louizos et al., 2018). We then\nuse an adversarial loss objective to guide the\nsearch for robust tickets and an approximate LO\nregularization is used to encourage the sparsity\n2211\nof robust tickets. Robust tickets can be used as\na robust substitute of original PLMs to fine-tune\ndownstream tasks. Experimental results show that\nrobust tickets achieve a significant improvement\nin adversarial robustness on various tasks and\nmaintain a matching accuracy. Our codes are\npublicly available at Github1.\nThe main contributions of our work are summa-\nrized as follows:\n• We demonstrate that PLMs contain robust\ntickets with matching accuracy but better\nrobustness than the original network.\n• We propose a novel and effective technique\nto find the robust tickets based on learnable\nbinary masks rather than the traditional\niterative magnitude-based pruning.\n• We provide a new perspective to explain\nthe vulnerability of PLMs on adversarial\nexamples: some weights of PLMs do not\ncontribute to the accuracy but may harm the\nrobustness.\n2 Related Work\n2.1 Textual Adversarial Attack and Defense\nTextual attacks typically generate explicit adver-\nsarial examples by replacing the components of\nsentences with their counterparts and maintaining\na high similarity in semantics (Ren et al., 2019)\nor embedding space (Li et al., 2020). These\nadversarial attackers can be divided into character-\nlevel (Gao et al., 2018), word-level (Ren et al.,\n2019; Zang et al., 2020; Jin et al., 2020; Li et al.,\n2020) and multi-level (Li et al., 2018). In response\nto adversarial attackers, various adversarial defense\nmethods are proposed to improve model robustness.\nAdversarial training solves a min-max robust\noptimization and is generally considered as one of\nthe strongest defense methods (Madry et al., 2018;\nZhu et al., 2020; Li and Qiu, 2020). Adversarial\ndata augmentation (ADA) has been widely adopted\nto improve robustness by adding textual adversarial\nexamples during training (Jin et al., 2020; Si et al.,\n2021). However, ADA is not sufficient to cover\nthe entire perturbed search space, which grows\nexponentially with the length of the input text.\nSome regularization methods, such as smoothness-\ninducing regularization (Jiang et al., 2020) and\ninformation bottleneck regularization (Wang et al.,\n1https://github.com/ruizheng20/robust_ticket\n2020), are also beneficial for robustness. Different\nfrom the above methods, we dig robust tickets from\noriginal BERT, and the subnetworks we find have\nbetter robustness after fine-tuning.\n2.2 Lottery Ticket Hypothesis\nLottery Ticket Hypothesis (LTH) suggests the\nexistence of certain sparse subnetworks (i.e.,\nwinning tickets) at initialization that can achieve\nalmost the same test performance compared to the\noriginal model (Frankle and Carbin, 2019). In the\nfield of NLP, previous works find that the winning\ntickets also exist in Transformers and LSTM (Yu\net al., 2020; Renda et al., 2020). Evci et al.\n(2020) propose a method to optimize the topology\nof the sparse network during training without\nsacrificing accuracy relative to existing dense-to-\nsparse training methods. Chen et al. (2020) find\nthat PLMs such as BERT contain winning tickets\nwith a sparsity of 40% to 90%, and the winning\ntickets found in the mask language modeling task\ncan universally be transfered to other downstream\ntasks. Prasanna et al. (2020) find structurally sparse\nwinning tickets for BERT, and they notice that all\nsubnetworks (winning tickets and randomly pruned\nsubnetworks) have comparable performance when\nfine-tuned on downstream tasks. Chen et al. (2021)\npropose an efficient BERT training method using\nEarly-bird lottery tickets to reduce the training\ntime and inference time. Some recent studies have\ntried to dig out more features of winning tickets.\nZhang et al. (2021) demonstrate that even in biased\nmodels (which focus on spurious correlations)\nthere still exist unbiased winning tickets. Liang\net al. (2021) observe that at a certain sparsity, the\ngeneralization performance of the winning tickets\ncan not only match but also exceed that of the full\nmodel. (Du et al., 2021; Xu et al., 2021) show that\nthe winning tickets that only consider accuracy are\nover-fitting on easy samples and generalize poorly\non adversarial examples. Our work makes the first\nattempt to find the robust winning tickets for PLMs.\n2.3 Robustness in Model Pruning\nLearning to identify a subnetwork with high\nadversarial robustness is widely discussed in the\nfield of computer vision. Post-train pruning\napproaches require a pre-trained model with ad-\nversarial robustness before pruning (Sehwag et al.,\n2019; Gui et al., 2019). In-train pruning methods\nintegrate the pruning process into the robust\nlearning process, which jointly optimize the model\n2212\nparameters and pruning connections (Vemparala\net al., 2021; Ye et al., 2019). Sehwag et al. (2020)\nintegrate the robust training objective into the\npruning process and remove the connections based\non importance scores. In our work, we focus on\nfinding robust tickets hidden in original PLMs\nrather than pruning subnetworks from a robust\nmodel.\n3 The Robust Ticket Framework\nIn this section, we propose a novel pruning method\nto extract robust tickets of PLMs by learning\nbinary weights masks with an adversarial loss\nobjective. Furthermore, we articulate the Robust\nLottery Ticket Hypothesis: the full PLM contains\nsubnetworks (robust tickets) that can achieve better\nadversarial robustness and comparable accuracy.\n3.1 Revisiting Lottery Ticket Hypothesis\nDenote f(θ) as a PLM with parameters θ that\nhas been fine-tuned on a downstream task. A\nsubnetwork of f(θ) can be denoted as f(m ⊙ θ),\nwhere m are binary masks with the same dimension\nas θ and ⊙ is the Hadamard product operator. LTH\nsuggests that, for a network initialized with θ0, the\nIterative Magnitude Pruning (IMP) can identify a\nmask m, such that the subnetwork f(x; m ⊙ θ0)\ncan be trained to almost the same performance\nto the full model f(θ0) in a comparable number\nof iterations. Such a subnetwork f(x; m ⊙ θ0)\nis called as winning tickets , including both the\nstructure mask m and initialization θ0. IMP\niteratively removes the weights with the smallest\nmagnitudes from m ⊙ θ until a certain sparsity is\nreached. However, the magnitude-based pruning\nis not suitable for robustness-aware techniques\n(Vemparala et al., 2021; Sehwag et al., 2020).\n3.2 Discovering Robust Tickets\nOur goal is to learn the sparse subnetwork, however,\nthe training loss is not differentiable for the binary\nmasks. A simple choice is to adopt a straight-\nthrough estimator to approximate the derivative\n(Bengio et al., 2013). Unfortunately, this approach\nignores the Heaviside function in the likelihood\nand results in biased gradients. Thus, we resort to\na practical method to learn sparse neural networks\n(Louizos et al., 2018).\nIn our method, we assume each mask mi to be a\nindependent random variable that follows a hard\nconcrete distribution HardConcrete(log αi, βi)\nwith temperature βi and location αi (Louizos et al.,\n2018):\nµi ∼ U(0, 1) , (1)\nsi = σ\n\u0012 1\nβi\n\u0012\nlog µi\n1 − µi\n+ logαi\n\u0013\u0013\n, (2)\nmi = min (1, max (0, si (ζ − γ) +γ)) , (3)\nwhere σ denotes the sigmoid function, γ = −0.1,\nζ = 1.1 are constants, and ui is the sample drawn\nfrom uniform distribution U(0, 1). The random\nvariable si follows a binary concrete (or Gumbel-\nSoftmax) distribution, which is a smoothing\napproximation of the discrete Bernoulli distribution\n(Maddison et al., 2017; Jang et al., 2017). Samples\nfrom the binary concrete distribution are identical\nto samples from a Bernoulli distribution with\nprobability αi as βi → 0. The location αi in\n(2) allows for gradient-based optimization through\nreparametrization tricks. Using (3), the si larger\nthan 1−γ\nζ−γ is rounded to 1, whereas the value smaller\nthan −γ\nζ−γ is rounded to 0. To encourage the sparsity,\nwe penalize the L0 complexity of masks based on\nthe probability which are non-zero:\nR(m) = 1\n|m|\n|m|X\ni=1\nσ\n\u0012\nlog αi − βi log −γ\nζ\n\u0013\n. (4)\nDuring the inference stage, the mask ˆmi can be\nestimated through a hard concrete gate:\nmin (1, max (0, σ(log αi) (ζ − γ) +γ)) . (5)\n3.2.1 Adversarial Loss Objective\nTo find the connections responsible for adversarial\nrobustness, we incorporate the adversarial loss into\nthe mask learning objective:\nmin\nm\nE(x,y)∼D max\n∥δ∥≤ϵ\nL(f(x + δ; m ⊙ θ), y)\n| {z }\nLadv(m)\n, (6)\nwhere (x, y) is a data point from dataset D, δ is the\nperturbation that constrained within the ϵ ball. The\ninner maximization problem in (6) is to find the\nworst-case adversarial examples to maximize the\nclassification loss, while the outer minimization\nproblem in (6) aims at optimizing the masks to\nminimize the loss of adversarial examples, i.e.,\nLadv(m).\nAdversarial attack method, typically with PGD,\ncan be used to solve the inner maximization\n2213\nproblem. PGD applies the K-step stochastic\ngradient descent to search for the perturbation δ\n(Madry et al., 2018):\nδk+1 =\nY\n∥δ∥≤ϵ\n\u0012\nδk + η g (δk)\n∥g (δk)∥\n\u0013\n, (7)\nwhere g (δk) = ∇xL(f(x + δk; m ⊙ θ), y), δk\nis the perturbation in k-th step and Q\n∥δ∥≤ϵ(·)\nprojects the perturbation back onto the Frobenius\nnormalization ball. Then robust training optimizes\nthe network on adversarially perturbed inputx+δK.\nThrough the above process, we can conveniently\nobtain a large number of adversarial examples for\ntraining.\nBy integrating theL0 complexity regularizer into\nthe training process of masks, our adversarial loss\nobjective becomes:\nmin\nm\nLadv(m) +R(m), (8)\nwhere λ denotes regularization strength.\n3.2.2 Effect of Regularization Strength\nThe selection of the regularization strength λ\ndecides the quality of robust tickets. Results carried\non SST-2 in Fig.1 show that eventually more than\n90% of the masks will be very close to 0 or 1, and\nthe L0 complexity regularizer R(m) will converge\nto a fixed value. As λ increases, R(m) decreases\n(the sparsity of the subnetwork increases). The\ntraining of the adversarial loss objective in (8) is\ninsensitive to the λ, and in all experiments, λ is\nchosen in the range [0.1, 1]. In the Appendix A, we\nshow more details about mask learning process.\n3.3 Drawing and Retraining Winning Tickets\nAfter training the masks m, we use the location\nparameters log α of masks to extract robust tickets.\nFor the Gumbel-Softmax distribution in (2), αi is\nthe expectation (confidence) of random variable\nsi, i.e, E{si} = αi. Thus, we prune the weights\nwhose masks have the smallest expectation. We\nprune all attention heads and intermediate neurons\nin an unstructured manner, which empirically has\nbetter performance than structured pruning. Unlike\nthe Lottery Ticket Hypothesis that requires iterative\nmagnitude pruning, the proposed method is a one-\nshot pruning method that can obtain subnetworks\nof any sparsity. Then we retrain (i.e., fine-tune) the\nrobust tickets f(m ⊙ θ0) on downstream tasks.\n1 4 8 12 16 20\nepoch\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9Regularizer\nregularizer\n=0.1\n =0.25\n =0.5\n =0.9\n0.2\n0.4\n0.6\n0.8\n1.0\npercentage of binary masks\npercentage of binary masks\n=0.1\n =0.25\n =0.5\n =0.9\nFigure 1: Effect of regularization strength λ on\nregularizer R(m), and the percentage of masks that\nexact 0 and 1.\n3.4 Robust Lottery Tickets Hypothesis\nIn the context of adversarial robustness, we\nseek winning tickets that balance accuracy and\nrobustness, and then we state and demonstrate\nRobust Lottery Tickets Hypothesis.\nRobust Lottery Tickets Hypothesis: A pre-\ntrained language model, such as BERT, contains\nsome subnetworks (robust tickets) initialized by\npre-trained weights, and when these subnetworks\nare trained in isolation, they can achieve better\nadversarial robustness and comparable accuracy.\nIn addition, robust tickets retain an important\ncharacteristic of traditional lottery tickets —the\nability to speed up the training process.\nThe practical merits of Robust Lottery Ticket\nHypothesis: 1) It provides an effective pruning\nmethod that can reduce memory constraints during\ninference time by identifying well-performing\nsmaller networks which can fit in memory. 2)\nOur proposed robust ticket is more robust than the\nexisting defense methods, so it can be used as a\ndefense method.\n4 Experiments\nWe conduct several experiments to demonstrate\nthe effectiveness of our method. We first compare\nthe proposed method with baseline methods in\nterms of clean accuracy and robust evaluation.\nThen, we perform an ablation study to illustrate\nthe role of sparse mask learning and adversarial\nloss objective in our method. In addition, we try to\nfurther flesh out our method with several additional\nanalysis experiments. Following the official BERT\nimplementation (Devlin et al., 2019; Wolf et al.,\n2020), we use BERTBASE as our backbone model\nfor all experiments.\n2214\n4.1 Datasets\nWe evaluate our method mainly on three text\nclassification datasets: Internet Movie Database\n(IMDB, Maas et al., 2011) , AG News corpus\n(AGNEWS, Zhang et al., 2015) and Stanford\nSentiment Treebank of binary classification (SST-\n2, Socher et al., 2013). We also test our method\non other types of tasks in GLUE, such as MNLI,\nQNLI, QQP. The labels of GLUE test sets are not\navailable, so GLUE test sets cannot be used for\nadversarial attacks. The results of GLUE tasks\nare tested on the official development set, and we\ndivide 10% training data as the development set.\n4.2 Baselines\nWe compare our RobustT (Robust Tickets) with\nrecently proposed adversarial defense methods and\nthe standard lottery ticket.\nFine-tune (Devlin et al., 2019): The offi-\ncial BERT implementation on downstream tasks.\nFreeLB (Zhu et al., 2020): An enhanced gradient-\nbased adversarial training method which is not\ntargeted at specific attack methods. InfoBERT\n(Wang et al., 2020): A learning framework for\nrobust model fine-tuning from an information-\ntheoretic perspective. This method claims that\nit has obtained a better representation of data\nfeatures. LTH (Chen et al., 2020): For a range\nof downstream tasks, BERT contains winning\nlottery tickets at 40% to 90% sparsity. Random:\nSubnetworks with the same layer-wise sparsity\nof the above RobustT, but their structures are\nrandomly pruned from the original BERT.\n4.3 Robust Evaluation\nThree widely accepted attack methods are used to\nverify the ability of our proposed method against\nbaselines (Li et al., 2021). BERT-Attack (Li\net al., 2020) is a method using BERT to generate\nadversarial text, and thus the generated adversarial\nexamples are fluent and semantically preserved.\nTextFooler (Jin et al., 2020) first identify the\nimportant words in the sentences, and then replace\nthem with synonyms that are semantically similar\nand grammatically correct until the prediction\nchanges. TextBugger (Li et al., 2018) is an\nadversarial attack method that generates misspelled\nwords by using character-level and word-level\nperturbations.\nThe evaluation metrics adopted in our exper-\nimental analyses are listed as follows: Clean\naccuracy (Clean%) denotes the accuracy on\nthe clean test dataset. Accuracy under attack\n(Aua%) refers to the model’s prediction accuracy\nfacing specific adversarial attacks. Attack success\nrate (Suc%) is the ratio of the number of texts\nsuccessfully perturbed by an attack method to the\ntotal number of texts to be attempted. Number\nof Queries (#Query)is the average number of\ntimes the attacker queries the model, which means\nthe more the average query number is, the harder\nthe defense model is to be compromised. For a\nrobust method, higher clean accuracy, accuracy\nunder attack, and query times are expected, as well\nas lower attack success rate.\n4.4 Implementation Details\nWe fine-tune the original BERT using the default\nsettings on downstream tasks. We train 20 epochs\nto discover the robust tickets from the fine-tuned\nBERT, and then we retrain the robust tickets using\ndefault settings of BERT-base. The K-step PGD\nrequires K forward-backward passes through the\nnetwork, which is time consuming. Thus, we\nturn to FreeLB, which accumulates gradients in\nmultiple forward passes and then passing gradients\nbackward once. For our approach, we prune robust\ntickets in the range of 10% and 90% sparsity and\nreport the best one in terms of robustness in our\nmain experiments. For a fair comparison, the\nsparsity of LTH is the same as that of robust tickets.\nAll experimental results are the average of 5 trials\nwith different seeds. More implementation details\nand hyperparameters are provided in the Appendix\nB. We implement all models in MindSpore.\n4.5 Main Results on Robustness Evaluation\nTable 1 shows the results of robust tickets and other\nbaselines under adversarial attack. We can observe\nthat: 1) Original BERT and BERT-tickets fail to\nperform well on adversarial robustness evaluation,\nand the BERT-tickets even show lower robustness\nthan BERT, indicating that it is difficult for the\npruned subnetworks to fight against adversarial\nattacks when only test accuracy is considered.\nThis result is consistent with the results in (Du\net al., 2021; Xu et al., 2021). 2) The proposed\nrobust ticket achieves a significant improvement\nof robustness over the original BERT and other\nadversarial defense methods. Robust tickets use a\nbetter robust structure to resist adversarial attacks,\nwhich is different from the previous methods aimed\nat solving robust optimization problems. 3) In\n2215\nDataset Method Clean% BERT-Attack TextFooler TextBugger\nAua% Suc% #Query Aua% Suc% #Query Aua% Suc% #Query\nIMDB\nFine-tune 94.1 7.8 91 .7 1572 .2 12.2 87 .0 1209 .8 25.8 72 .5 783 .2\nLTH20% 94.0 3.6 96 .2 1074 .44 7.2 92 .3 894 .1 16.0 83 .0 574 .0\nFreeLB 94.8 22.6 76 .2 1954 .7 27.2 71 .3 1479 .1 36.0 62 .0 907 .3\nInfoBERT 95.2 26.0 72 .7 2326 .0 32.4 66 .0 1572 .2 43.6 54 .2 969 .8\nRand20% 93.1 6.8 92 .8 731 .5 7.4 92 .1 598 .7 8.4 91 .9 464 .3\nRobustT20% 93.8 55.2 41 .2 3128 .0 55.6 40 .7 1988 .4 57.6 38 .6 1149 .1\nAGNEWS\nFine-tune 94.7 3.8 96 .0 436 .7 14.9 84 .2 333 .2 41.5 56 .1 178 .3\nLTH40% 93.7 2.5 97 .3 394 .4 11.0 88 .3 295 .2 36.8 60 .7 179 .7\nFreeLB 95.2 10.8 88 .6 563 .9 24.3 74 .4 394 .6 51.7 45 .5 190 .4\nInfoBERT 94.4 11.1 88 .3 517 .0 25.1 73 .4 374 .7 47.9 49 .3 193 .1\nRand40% 94.0 1.3 98 .6 357 .2 6.3 93 .2 275 .1 27.5 70 .1 148 .7\nRobustT40% 94.9 12.1 87 .2 607 .7 28.5 70 .0 442 .1 53.4 43 .7 207 .8\nSST-2\nFine-tune 92.0 2.9 96 .8 114 .2 5.0 94 .6 98 .4 29.4 68 .3 49 .7\nLTH30% 92.1 2.2 97 .6 98 .9 4.1 95 .5 90 .5 29.1 68 .4 49 .6\nFreeLB 91.6 10.2 88 .9 154 .6 14.4 84 .2 123 .8 42.4 53 .7 54 .9\nInfoBERT 92.1 14.4 84 .4 162 .3 18.3 80 .1 121 .4 40.3 56 .3 51 .2\nRand30% 83.2 2.1 97 .5 89 .4 2.4 97 .1 75 .6 16.5 80 .2 44 .2\nRobustT30% 90.9 17.9 80 .3 164 .9 26.7 70 .6 149 .8 42.1 53 .7 53 .9\nTable 1: Main results on adversarial robustness evaluation. Fine-tuning RobustT for downstream tasks achieves a\nsignificant improvement of robustness. The percentage on the subscript denotes the sparsity of the subnetworks.\nThe best performance is marked in bold. Suc% lower is better.\nDataset Method Clean% Aua%\nTextFooler TextBugger\nQNLI\nFine-tune 91.6 4.7 10.5\nFreeLB 90.5 12.8 12.0\nInfoBERT 91.5 16.4 20.9\nRobustT30% 91.5 17.0 25.9\nMNLI\nFine-tune 84.4 7.7 4.3\nFreeLB 82.9 11.0 8.4\nInfoBERT 84.1 10.8 8.4\nRobustT30% 84.0 18.4 22.6\nQQP\nFine-tune 91.3 24.8 27.8\nFreeLB 91.2 27.4 28.1\nInfoBERT 91.9 34.4 35.9\nRobustT30% 91.5 47.2 46.0\nTable 2: Adversarial robustness evaluation of RobustT\non QNLI, MNLI and QQP datasets. Compare with the\noriginal BERT, fine-tuning on robust tickets improves\nthe adversarial robustness.\nboth AGNEWS and IMDB, the randomly pruned\nsubnetwork loses only about 1 performance point\nin test accuracy, but performs poorly in adversarial\nrobustness. This suggests that robust tickets\nare more difficult to discovered than traditional\nlottery tickets. 4) Robust tickets sacrifice accuracy\nperformance in SST-2 and IMDB. We speculate\nthat this may be due to the trade-off between\naccuracy and robustness (Tsipras et al., 2019).\nWe also evaluate the performance of our pro-\nDataset Method Clean % Aua%\nIMDB\nRobustT20% 93.8 55.6\nw/o Mask Leaning 94.0 15.1\nw/o Adv 93.4 5 .4\nAGNEWS\nRobustT40% 94.9 28 .5\nw/o Mask Learning 94.2 16 .1\nw/o Adv 94.5 8 .8\nSST-2\nRobustT30% 90.9 26.7\nw/o Mask Learning 92.2 6.2\nw/o Adv 91.2 3 .5\nTable 3: Ablation study on text classification datasets.\nAua% is obtained after using TextFooler attack.\nposed method on more tasks. From Table 2, we can\nsee that our proposed method yields significant\nimprovements of robustness over the original\nBERT on QNLI, MNLI and QQP datasets. There\nis a significant improvement even compared with\nInfoBERT and FreeLB.\n4.6 Ablation Study\nTo better illustrate the contribution of each com-\nponent of our method, we perform the ablation\nstudy by removing the following components:\nsparse mask learning (but with IMP instead) and\nadversarial loss objective (Adv). The test results\nare shown in Table 3. We can observe that: 1)\n2216\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni0000001b/uni0000001b\n/uni0000001b/uni0000001c\n/uni0000001c/uni00000013\n/uni0000001c/uni00000014\n/uni0000001c/uni00000015\n/uni0000001c/uni00000016\n/uni0000001c/uni00000017\n/uni0000001c/uni00000018/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n(a) IMDB\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000018\n/uni00000014/uni00000013\n/uni00000014/uni00000018\n/uni00000015/uni00000013\n/uni00000015/uni00000018/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni0000001c/uni00000015/uni00000011/uni00000013\n/uni0000001c/uni00000015/uni00000011/uni00000018\n/uni0000001c/uni00000016/uni00000011/uni00000013\n/uni0000001c/uni00000016/uni00000011/uni00000018\n/uni0000001c/uni00000017/uni00000011/uni00000013\n/uni0000001c/uni00000017/uni00000011/uni00000018\n/uni0000001c/uni00000018/uni00000011/uni00000013/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048 (b) AGNEWS\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000018\n/uni00000014/uni00000013\n/uni00000014/uni00000018\n/uni00000015/uni00000013\n/uni00000015/uni00000018/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000011/uni00000014/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000016/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000018/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni0000001b/uni00000015\n/uni0000001b/uni00000017\n/uni0000001b/uni00000019\n/uni0000001b/uni0000001b\n/uni0000001c/uni00000013\n/uni0000001c/uni00000015/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048 (c) SST-2\nFigure 2: Fine-tuning evaluation results of the robust ticket, the traditional lottery ticket, FreeLB and the original\nBERT fine-tuning under various sparsity levels. The adversarial robustness improves as the compression ratio grows\nuntil a certain threshold, then the robustness deteriorates. Aua% is obtained after using TextFooler attack.\nMask learning is important for performance and\nIMP does not identify robust subnetworks well\n(Vemparala et al., 2021). 2) Without adversarial\nloss objective, the proposed method identifies\nsubnetworks that perform well in terms of clean\naccuracy, but does not provide any improvement in\nterms of robustness.\n5 Discussion\nIn this section, we study how the implementation\nof robust tickets affects the model’s robustness.\n5.1 Impact of Sparsity on Robust Tickets\nThe proposed method can prune out a subnetwork\nwith arbitrary sparsity based on the confidence of\nmasks. In Fig.2, we compare the robust tickets\nand traditional lottery tickets across all sparsities.\nWhen the sparsity increases to a certain level,\nthe robustness decreases faster than the accuracy,\nwhich indicates that the robustness is more likely to\nbe affected by the model structure than the accuracy.\nTherefore, it is more difficult to find a robust ticket\nfrom BERT. The accuracy of the subnetwork is\nslowly decreasing with increasing sparsity, but the\nrobustness shows a different trend. The change in\nrobustness can be roughly divided into three phases:\nThe robustness improves as the sparsity grows\nuntil a certain threshold; beyond this threshold, the\nrobustness deteriorates but is still better than that\nof the lottery tickets. In the end, when being highly\ncompressed, the robust network collapses into a\nlottery network. A similar phenomenon is also\nbe observed (Liang et al., 2021). The robustness\nperformance curve is not as smooth as the accuracy,\nthis may be due to the gap between the adversarial\nloss objective and the real textual attacks.\n5.2 Sparsity Pattern\nFig.3 shows the sparsity patterns of robust tickets\non all six datasets. We can clearly find that\nthe pruning rate increases from bottom to top\non the text classification tasks (IMDB, SST2,\nAGNEWS), while it is more uniform in the natural\nlanguage inference tasks (MNLI and QNLI) and\nQuora question pairs (QQP). Recent works show\nthat BERT encodes a rich hierarchy of linguistic\ninformation. Taking the advantage of the probing\ntask, Jawahar et al. (2019) indicate that the surface\ninformation features are encoded at the bottom,\nsyntactic information features are in the middle\nnetwork, and semantic information features in the\ntop. Therefore, we speculate that the sparsity\npattern of robust tickets is task-dependent.\n5.3 Speedup Training Process\nAn important property of winning tickets is to\naccelerate the convergence of the training process\n(Chen et al., 2021; You et al., 2020). The training\ncurve in Fig.4 shows that the convergence speed\nof robust tickets is much faster compared with\nthe default fine-tuning and FreeLB. Moreover, the\nconvergence rate of both accuracy and robustness\n2217\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.55 0.62 0.67 0.67 0.56 0.67 0.57 0.56 0.60 0.63 0.68 0.65\n0.57 0.73 0.56 0.58 0.72 0.62 0.66 0.59 0.59 0.61 0.70 0.56\n0.71 0.71 0.59 0.59 0.54 0.67 0.59 0.63 0.58 0.71 0.62 0.69\n0.54 0.66 0.59 0.70 0.57 0.73 0.64 0.65 0.63 0.73 0.70 0.73\n0.66 0.42 0.65 0.50 0.60 0.74 0.69 0.70 0.66 0.72 0.71 0.71\n0.69 0.56 0.49 0.68 0.68 0.49 0.65 0.71 0.65 0.71 0.73 0.64\n0.63 0.64 0.63 0.61 0.63 0.71 0.70 0.64 0.63 0.71 0.66 0.69\n0.68 0.69 0.55 0.56 0.66 0.60 0.54 0.37 0.71 0.66 0.70 0.48\n0.43 0.61 0.50 0.48 0.51 0.60 0.37 0.58 0.67 0.64 0.64 0.67\n0.53 0.54 0.48 0.40 0.42 0.56 0.30 0.43 0.47 0.27 0.42 0.47\n0.09 0.26 0.04 0.10 0.27 0.06 0.08 0.06 0.03 0.04 0.11 0.23\n0.12 0.02 0.03 0.03 0.38 0.32 0.41 0.09 0.05 0.15 0.33 0.04\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.80\n0.80\n0.81\n0.82\n0.83\n0.83\n0.84\n0.84\n0.83\n0.79\n0.71\n0.73\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n(a) IMDB\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.41 0.47 0.49 0.47 0.42 0.49 0.43 0.44 0.45 0.47 0.50 0.48\n0.44 0.51 0.43 0.41 0.49 0.44 0.41 0.42 0.44 0.45 0.49 0.42\n0.47 0.50 0.42 0.42 0.43 0.45 0.40 0.47 0.43 0.47 0.44 0.46\n0.32 0.43 0.44 0.47 0.37 0.48 0.46 0.40 0.45 0.49 0.48 0.47\n0.46 0.34 0.45 0.33 0.40 0.49 0.48 0.49 0.43 0.47 0.46 0.47\n0.46 0.42 0.36 0.47 0.47 0.43 0.46 0.48 0.46 0.45 0.46 0.45\n0.44 0.40 0.44 0.41 0.44 0.47 0.45 0.44 0.42 0.45 0.44 0.44\n0.44 0.43 0.40 0.40 0.37 0.41 0.39 0.31 0.42 0.44 0.44 0.33\n0.36 0.35 0.23 0.17 0.39 0.37 0.34 0.36 0.41 0.40 0.39 0.40\n0.28 0.31 0.33 0.29 0.24 0.39 0.13 0.33 0.26 0.06 0.27 0.30\n0.09 0.11 0.06 0.14 0.29 0.10 0.06 0.14 0.06 0.14 0.06 0.29\n0.09 0.06 0.07 0.06 0.17 0.25 0.28 0.07 0.07 0.07 0.29 0.08\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.52\n0.51\n0.51\n0.51\n0.50\n0.49\n0.46\n0.42\n0.35\n0.24\n0.18\n0.18\n0.1\n0.2\n0.3\n0.4\n0.5\n (b) SST-2\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.41 0.49 0.53 0.45 0.35 0.49 0.35 0.47 0.40 0.48 0.52 0.53\n0.45 0.58 0.52 0.50 0.55 0.44 0.37 0.52 0.46 0.43 0.50 0.49\n0.50 0.59 0.48 0.48 0.50 0.50 0.48 0.52 0.44 0.50 0.58 0.52\n0.51 0.57 0.54 0.52 0.51 0.54 0.55 0.49 0.58 0.56 0.58 0.54\n0.62 0.34 0.57 0.38 0.51 0.53 0.57 0.54 0.41 0.58 0.49 0.53\n0.47 0.47 0.47 0.49 0.56 0.40 0.47 0.46 0.48 0.50 0.52 0.52\n0.46 0.52 0.49 0.41 0.47 0.49 0.46 0.50 0.51 0.56 0.45 0.50\n0.57 0.41 0.51 0.38 0.45 0.53 0.33 0.35 0.59 0.54 0.46 0.40\n0.41 0.46 0.32 0.22 0.37 0.39 0.39 0.51 0.48 0.44 0.52 0.48\n0.44 0.53 0.51 0.46 0.43 0.64 0.37 0.54 0.45 0.24 0.38 0.56\n0.29 0.39 0.37 0.38 0.51 0.05 0.53 0.53 0.10 0.14 0.31 0.43\n0.46 0.14 0.19 0.42 0.48 0.42 0.39 0.48 0.32 0.27 0.36 0.52\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.69\n0.69\n0.69\n0.69\n0.68\n0.67\n0.65\n0.62\n0.57\n0.53\n0.45\n0.38\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n (c) AGNEWS\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.70 0.69 0.68 0.69 0.71 0.68 0.72 0.71 0.70 0.70 0.68 0.68\n0.69 0.67 0.68 0.70 0.69 0.67 0.68 0.67 0.68 0.69 0.65 0.69\n0.73 0.65 0.67 0.68 0.67 0.67 0.67 0.66 0.67 0.72 0.65 0.66\n0.67 0.66 0.67 0.66 0.68 0.70 0.67 0.66 0.65 0.67 0.66 0.66\n0.65 0.68 0.66 0.66 0.65 0.66 0.66 0.66 0.66 0.65 0.66 0.67\n0.65 0.66 0.66 0.65 0.65 0.64 0.66 0.65 0.65 0.68 0.66 0.65\n0.64 0.65 0.65 0.66 0.65 0.65 0.66 0.64 0.64 0.66 0.65 0.67\n0.65 0.65 0.65 0.65 0.66 0.65 0.65 0.66 0.65 0.65 0.65 0.66\n0.65 0.64 0.65 0.64 0.65 0.65 0.65 0.64 0.65 0.64 0.65 0.64\n0.64 0.65 0.65 0.65 0.66 0.66 0.64 0.65 0.64 0.65 0.65 0.64\n0.64 0.66 0.65 0.65 0.66 0.70 0.75 0.65 0.65 0.64 0.65 0.64\n0.70 0.66 0.66 0.69 0.66 0.67 0.68 0.67 0.71 0.66 0.66 0.69\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.68\n0.67\n0.67\n0.67\n0.66\n0.66\n0.66\n0.66\n0.67\n0.71\n0.79\n0.88\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n(d) MNLI\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.57 0.59 0.64 0.63 0.58 0.61 0.56 0.59 0.59 0.63 0.65 0.62\n0.60 0.67 0.62 0.58 0.67 0.61 0.61 0.61 0.63 0.63 0.64 0.71\n0.65 0.67 0.67 0.64 0.64 0.62 0.71 0.64 0.62 0.65 0.67 0.64\n0.72 0.66 0.64 0.66 0.59 0.67 0.64 0.65 0.67 0.67 0.67 0.67\n0.66 0.65 0.66 0.71 0.65 0.68 0.66 0.67 0.64 0.68 0.66 0.67\n0.67 0.63 0.63 0.65 0.68 0.67 0.65 0.66 0.67 0.67 0.68 0.66\n0.66 0.66 0.64 0.61 0.67 0.67 0.66 0.66 0.67 0.67 0.66 0.65\n0.67 0.65 0.65 0.61 0.65 0.66 0.56 0.59 0.68 0.68 0.68 0.60\n0.60 0.65 0.63 0.66 0.63 0.65 0.61 0.66 0.63 0.68 0.68 0.67\n0.68 0.66 0.61 0.58 0.46 0.57 0.69 0.61 0.71 0.47 0.63 0.70\n0.65 0.61 0.67 0.67 0.49 0.41 0.46 0.65 0.65 0.64 0.69 0.65\n0.53 0.57 0.56 0.55 0.57 0.56 0.55 0.22 0.56 0.56 0.53 0.51\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.70\n0.71\n0.71\n0.72\n0.72\n0.72\n0.72\n0.71\n0.71\n0.70\n0.69\n0.64\n0.3\n0.4\n0.5\n0.6\n0.7\n (e) QNLI\n0 1 2 3 4 5 6 7 8 9 10 11\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLayer\n0.58 0.60 0.63 0.62 0.59 0.61 0.59 0.59 0.59 0.63 0.64 0.62\n0.61 0.65 0.61 0.59 0.64 0.61 0.59 0.61 0.63 0.63 0.62 0.69\n0.64 0.64 0.65 0.63 0.63 0.60 0.68 0.64 0.62 0.64 0.64 0.62\n0.70 0.65 0.63 0.63 0.60 0.65 0.64 0.62 0.64 0.65 0.64 0.64\n0.65 0.60 0.64 0.68 0.63 0.64 0.64 0.65 0.61 0.66 0.63 0.65\n0.64 0.63 0.63 0.64 0.67 0.64 0.63 0.64 0.64 0.64 0.65 0.63\n0.63 0.62 0.63 0.61 0.64 0.64 0.63 0.65 0.64 0.65 0.64 0.64\n0.64 0.63 0.63 0.61 0.63 0.63 0.60 0.61 0.64 0.64 0.65 0.61\n0.61 0.63 0.61 0.62 0.61 0.62 0.59 0.64 0.63 0.62 0.64 0.63\n0.64 0.62 0.60 0.62 0.49 0.62 0.64 0.63 0.67 0.60 0.61 0.67\n0.62 0.44 0.64 0.64 0.52 0.42 0.53 0.64 0.64 0.58 0.66 0.63\n0.53 0.58 0.58 0.59 0.58 0.57 0.56 0.26 0.58 0.57 0.56 0.55\nMLP\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n0.69\n0.68\n0.69\n0.69\n0.69\n0.69\n0.69\n0.69\n0.69\n0.70\n0.72\n0.81\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n (f) QQP\nFigure 3: Heatmaps of sparsity patterns found on different tasks, each cell gives the percentage of surviving weights\nin self-attention heads and MLPs. The sparsity patterns on IMDB and SST-2 are similar, which may be due to the\nfact that they are both text classification datasets based on movie reviews.\nis accelerating. The traditional lottery tickets\nconverge faster than our method, which may be due\nto the fact that robust tickets require maintaining a\ntrade-off between robustness and accuracy.\n5.4 The Importance of Robust Tickets\nInitialization and Structure\nTo better understand which factor, initialization or\nstructure, has a greater impact on the robust ticket,\nwe conduct corresponding analysis studies. We\navoid the effect of initializations by re-initializing\nthe weights of robust tickets. To avoid the effect of\nstructures and preserve the effect of initializations,\nwe use the full BERT and re-initialize the weights\nthat are not contained in the robust tickets.Aua% is\nobtained after using TextFooler attack. The results\nare shown in Table 4.\n5.4.1 Importance of initialization\nLTH suggests that the winning tickets can not be\nlearned effectively without its original initialization.\nFor our robust BERT tickets, their initializations\nare pre-trained weights. Table 4 shows the failure\nof robust tickets when the random re-initialization\nis performed.\nDataset Method Clean % Aua%\nIMDB\nRobustT20% 93.7 55 .6\nw/o Initialization 87.9 0 .2\nw/o Structure 93.7 13 .4\nw/o Structure+Longer 93.6 18 .6\nAGNEWS\nRobustT40% 94.9 28 .5\nw/o Initialization 92.4 0 .4\nw/o Structure 94.9 21 .8\nw/o Structure+Longer 94.8 24 .6\nSST-2\nRobustT30% 90.9 26 .7\nw/o Initialization 83.1 2 .1\nw/o Structure 92.0 15.7\nw/o Structure+Longer 91.9 27.5\nTable 4: Importance of robust ticket initialization and\nstructure. Our results show that the initialization of\nrobust tickets seems to be more important than the\nstructure, although both of them play a role.\n5.4.2 Importance of structure\nFrankle and Carbin (2019) hypothesize that the\nstructure of winning tickets encodes an inductive\nbias customized for the learning task at hand.\nAlthough removing this inductive bias reduces\nperformance compared to the robust tickets, it\nstill outperforms the original BERT, and its\n2218\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000013\n/uni00000014/uni00000013\n/uni00000015/uni00000013\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000001a/uni00000013\n/uni0000001b/uni00000013\n/uni0000001c/uni00000013/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n(a) IMDB\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000013\n/uni00000018\n/uni00000014/uni00000013\n/uni00000014/uni00000018\n/uni00000015/uni00000013\n/uni00000015/uni00000018/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000016/uni00000013\n/uni00000017/uni00000013\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000001a/uni00000013\n/uni0000001b/uni00000013\n/uni0000001c/uni00000013/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048 (b) AGNEWS\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000013\n/uni00000015\n/uni00000017\n/uni00000019\n/uni0000001b\n/uni00000014/uni00000013/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000003/uni00000058/uni00000051/uni00000047/uni00000048/uni00000055/uni00000003/uni00000024/uni00000057/uni00000057/uni00000044/uni00000046/uni0000004e/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048\n/uni00000013/uni00000014/uni00000013/uni00000013/uni00000015/uni00000013/uni00000013/uni00000016/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000018/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001a/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013\n/uni00000036/uni00000053/uni00000044/uni00000055/uni00000056/uni0000004c/uni00000057/uni0000005c\n/uni00000018/uni00000013\n/uni00000019/uni00000013\n/uni0000001a/uni00000013\n/uni0000001b/uni00000013\n/uni0000001c/uni00000013/uni00000026/uni0000004f/uni00000048/uni00000044/uni00000051/uni00000003/uni0000000b/uni00000008/uni0000000c\n/uni00000035/uni00000052/uni00000045/uni00000058/uni00000056/uni00000057/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni0000002f/uni00000052/uni00000057/uni00000057/uni00000048/uni00000055/uni0000005c/uni00000003/uni00000037/uni0000004c/uni00000046/uni0000004e/uni00000048/uni00000057\n/uni00000029/uni00000055/uni00000048/uni00000048/uni0000002f/uni00000025\n/uni00000029/uni0000004c/uni00000051/uni00000048/uni00000010/uni00000057/uni00000058/uni00000051/uni00000048 (c) SST-2\nFigure 4: Clean accuracy and accuracy under attack as training proceeds. Robust tickets accelerate both accuracy\nand robustness. Aua% is obtained after using TextFooler attack.\nperformance improves further with longer training\ntime (3 epochs → 10 epochs). It can be seen that\nthe initializations of some pre-training weights may\nlead to a decrease in the robustness of the model.\n6 Conclusion\nIn this paper, we articulate and demonstrate the\nRobust Lottery Ticket Hypothesis for PLMs: the\nfull PLM contains subnetworks (robust tickets) that\ncan achieve a better robustness performance. We\npropose an effective method to solve the ticket\nselection problem by encouraging weights that are\nnot responsible for robustness to become exactly\nzero. Experiments on various tasks corroborate the\neffectiveness of our method. We also find that pre-\ntrained weights may be a key factor affecting the\nrobustness on downstream tasks.\nAcknowledgements\nThe authors wish to thank the anonymous reviewers\nfor their helpful comments. This work was partially\nfunded by National Natural Science Foundation of\nChina (No. 62076069, 61976056). This research\nwas supported by Meituan, Beijing Academy of\nArtificial Intelligence(BAAI), and CAAI-Huawei\nMindSpore Open Fund.\nReferences\nYoshua Bengio, Nicholas Léonard, and Aaron C.\nCourville. 2013. Estimating or propagating\ngradients through stochastic neurons for conditional\ncomputation. ArXiv preprint, abs/1308.3432.\nTianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia\nLiu, Yang Zhang, Zhangyang Wang, and Michael\nCarbin. 2020. The lottery ticket hypothesis for\npre-trained BERT networks. In Advances in\nNeural Information Processing Systems 33: Annual\nConference on Neural Information Processing\nSystems 2020, NeurIPS 2020, December 6-12, 2020,\nvirtual.\nXiaohan Chen, Yu Cheng, Shuohang Wang, Zhe Gan,\nZhangyang Wang, and Jingjing Liu. 2021. Early-\nBERT: Efficient BERT training via early-bird lottery\ntickets. In Proceedings of the 59th Annual Meeting\nof the Association for Computational Linguistics\nand the 11th International Joint Conference on\nNatural Language Processing (Volume 1: Long\nPapers), pages 2195–2207, Online. Association for\nComputational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training\nof deep bidirectional transformers for language\nunderstanding. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short\nPapers), pages 4171–4186, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nMengnan Du, Subhabrata Mukherjee, Yu Cheng, Milad\nShokouhi, Xia Hu, and Ahmed Hassan Awadallah.\n2021. What do compressed large language models\nforget? robustness challenges in model compression.\nArXiv preprint, abs/2110.08419.\nUtku Evci, Trevor Gale, Jacob Menick, Pablo Samuel\nCastro, and Erich Elsen. 2020. Rigging the lottery:\n2219\nMaking all tickets winners. In Proceedings of the\n37th International Conference on Machine Learning,\nICML 2020, 13-18 July 2020, Virtual Event, volume\n119 of Proceedings of Machine Learning Research,\npages 2943–2952. PMLR.\nJonathan Frankle and Michael Carbin. 2019. The\nlottery ticket hypothesis: Finding sparse, trainable\nneural networks. In 7th International Conference on\nLearning Representations, ICLR 2019, New Orleans,\nLA, USA, May 6-9, 2019. OpenReview.net.\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun\nQi. 2018. Black-box generation of adversarial text\nsequences to evade deep learning classifiers. 2018\nIEEE Security and Privacy Workshops (SPW), pages\n50–56.\nSiddhant Garg and Goutham Ramakrishnan. 2020.\nBAE: BERT-based adversarial examples for text clas-\nsification. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 6174–6181, Online. Association for\nComputational Linguistics.\nShupeng Gui, Haotao Wang, Haichuan Yang, Chen\nYu, Zhangyang Wang, and Ji Liu. 2019. Model\ncompression with adversarial robustness: A unified\noptimization framework. In Advances in Neural\nInformation Processing Systems 32: Annual Confer-\nence on Neural Information Processing Systems 2019,\nNeurIPS 2019, December 8-14, 2019, Vancouver, BC,\nCanada, pages 1283–1294.\nEric Jang, Shixiang Gu, and Ben Poole. 2017.\nCategorical reparameterization with gumbel-softmax.\nIn 5th International Conference on Learning\nRepresentations, ICLR 2017, Toulon, France,\nApril 24-26, 2017, Conference Track Proceedings .\nOpenReview.net.\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.\n2019. What does BERT learn about the structure\nof language? In Proceedings of the 57th Annual\nMeeting of the Association for Computational\nLinguistics, pages 3651–3657, Florence, Italy.\nAssociation for Computational Linguistics.\nHaoming Jiang, Pengcheng He, Weizhu Chen, Xi-\naodong Liu, Jianfeng Gao, and Tuo Zhao. 2020.\nSMART: Robust and efficient fine-tuning for pre-\ntrained natural language models through principled\nregularized optimization. In Proceedings of the 58th\nAnnual Meeting of the Association for Computational\nLinguistics, pages 2177–2190, Online. Association\nfor Computational Linguistics.\nDi Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter\nSzolovits. 2020. Is BERT really robust? A\nstrong baseline for natural language attack on text\nclassification and entailment. In The Thirty-Fourth\nAAAI Conference on Artificial Intelligence, AAAI\n2020, The Thirty-Second Innovative Applications of\nArtificial Intelligence Conference, IAAI 2020, The\nTenth AAAI Symposium on Educational Advances\nin Artificial Intelligence, EAAI 2020, New York, NY,\nUSA, February 7-12, 2020, pages 8018–8025. AAAI\nPress.\nOlga Kovaleva, Alexey Romanov, Anna Rogers, and\nAnna Rumshisky. 2019. Revealing the dark secrets\nof BERT. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on\nNatural Language Processing (EMNLP-IJCNLP) ,\npages 4365–4374, Hong Kong, China. Association\nfor Computational Linguistics.\nJinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting\nWang. 2018. Textbugger: Generating adversarial\ntext against real-world applications. ArXiv preprint,\nabs/1812.05271.\nLinyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue,\nand Xipeng Qiu. 2020. BERT-ATTACK: Adversarial\nattack against BERT using BERT. In Proceedings\nof the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , pages\n6193–6202, Online. Association for Computational\nLinguistics.\nLinyang Li and Xipeng Qiu. 2020. Tavat: Token-\naware virtual adversarial training for language\nunderstanding. ArXiv preprint, abs/2004.14543.\nZongyi Li, Jianhan Xu, Jiehang Zeng, Linyang\nLi, Xiaoqing Zheng, Qi Zhang, Kai-Wei Chang,\nand Cho-Jui Hsieh. 2021. Searching for an\neffective defender: Benchmarking defense against\nadversarial word substitution. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 3137–3147, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nChen Liang, Simiao Zuo, Minshuo Chen, Haoming\nJiang, Xiaodong Liu, Pengcheng He, Tuo Zhao,\nand Weizhu Chen. 2021. Super tickets in pre-\ntrained language models: From model compression\nto improving generalization. In Proceedings of\nthe 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 6524–6538, Online.\nAssociation for Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,\nMandar Joshi, Danqi Chen, Omer Levy, Mike\nLewis, Luke Zettlemoyer, and Veselin Stoyanov.\n2019. Roberta: A robustly optimized bert pretraining\napproach. ArXiv preprint, abs/1907.11692.\nIlya Loshchilov and Frank Hutter. 2019. Decoupled\nweight decay regularization. In 7th International\nConference on Learning Representations, ICLR\n2019, New Orleans, LA, USA, May 6-9, 2019 .\nOpenReview.net.\nChristos Louizos, Max Welling, and Diederik P. Kingma.\n2018. Learning sparse neural networks through l_0\n2220\nregularization. In 6th International Conference on\nLearning Representations, ICLR 2018, Vancouver,\nBC, Canada, April 30 - May 3, 2018, Conference\nTrack Proceedings. OpenReview.net.\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher\nPotts. 2011. Learning word vectors for sentiment\nanalysis. In Proceedings of the 49th Annual\nMeeting of the Association for Computational\nLinguistics: Human Language Technologies, pages\n142–150, Portland, Oregon, USA. Association for\nComputational Linguistics.\nChris J. Maddison, Andriy Mnih, and Yee Whye Teh.\n2017. The concrete distribution: A continuous\nrelaxation of discrete random variables. In 5th\nInternational Conference on Learning Representa-\ntions, ICLR 2017, Toulon, France, April 24-26, 2017,\nConference Track Proceedings. OpenReview.net.\nAleksander Madry, Aleksandar Makelov, Ludwig\nSchmidt, Dimitris Tsipras, and Adrian Vladu.\n2018. Towards deep learning models resistant to\nadversarial attacks. In 6th International Conference\non Learning Representations, ICLR 2018, Vancouver,\nBC, Canada, April 30 - May 3, 2018, Conference\nTrack Proceedings. OpenReview.net.\nPaul Michel, Omer Levy, and Graham Neubig. 2019.\nAre sixteen heads really better than one? In\nAdvances in Neural Information Processing Systems\n32: Annual Conference on Neural Information\nProcessing Systems 2019, NeurIPS 2019, December\n8-14, 2019, Vancouver, BC, Canada, pages 14014–\n14024.\nJohn Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby,\nDi Jin, and Yanjun Qi. 2020. TextAttack: A\nframework for adversarial attacks, data augmentation,\nand adversarial training in NLP. In Proceedings\nof the 2020 Conference on Empirical Methods\nin Natural Language Processing: System Demon-\nstrations, pages 119–126, Online. Association for\nComputational Linguistics.\nSai Prasanna, Anna Rogers, and Anna Rumshisky. 2020.\nWhen BERT Plays the Lottery, All Tickets Are\nWinning. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), pages 3208–3229, Online. Association for\nComputational Linguistics.\nColin Raffel, Noam M. Shazeer, Adam Roberts,\nKatherine Lee, Sharan Narang, Michael Matena,\nYanqi Zhou, Wei Li, and Peter J. Liu. 2019.\nExploring the limits of transfer learning with a\nunified text-to-text transformer. ArXiv preprint ,\nabs/1910.10683.\nShuhuai Ren, Yihe Deng, Kun He, and Wanxiang\nChe. 2019. Generating natural language adversar-\nial examples through probability weighted word\nsaliency. In Proceedings of the 57th Annual Meeting\nof the Association for Computational Linguistics ,\npages 1085–1097, Florence, Italy. Association for\nComputational Linguistics.\nAlex Renda, Jonathan Frankle, and Michael Carbin.\n2020. Comparing rewinding and fine-tuning in neural\nnetwork pruning. In 8th International Conference on\nLearning Representations, ICLR 2020, Addis Ababa,\nEthiopia, April 26-30, 2020. OpenReview.net.\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in BERTology: What we know about\nhow BERT works. Transactions of the Association\nfor Computational Linguistics, 8:842–866.\nVikash Sehwag, Shiqi Wang, Prateek Mittal, and Suman\nJana. 2020. Hydra: Pruning adversarially robust\nneural networks. In Advances in Neural Information\nProcessing Systems, volume 33, pages 19655–19666.\nCurran Associates, Inc.\nVikash Sehwag, Shiqi Wang, Prateek Mittal, and\nSuman Sekhar Jana. 2019. Towards compact\nand robust deep neural networks. ArXiv preprint,\nabs/1906.06110.\nChenglei Si, Zhengyan Zhang, Fanchao Qi, Zhiyuan\nLiu, Yasheng Wang, Qun Liu, and Maosong\nSun. 2021. Better robustness by more coverage:\nAdversarial and mixup data augmentation for robust\nfinetuning. In Findings of the Association for Com-\nputational Linguistics: ACL-IJCNLP 2021 , pages\n1569–1576, Online. Association for Computational\nLinguistics.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Proceedings of the 2013 Conference on Empirical\nMethods in Natural Language Processing , pages\n1631–1642, Seattle, Washington, USA. Association\nfor Computational Linguistics.\nDimitris Tsipras, Shibani Santurkar, Logan Engstrom,\nAlexander Turner, and Aleksander Madry. 2019.\nRobustness may be at odds with accuracy. In 7th\nInternational Conference on Learning Representa-\ntions, ICLR 2019, New Orleans, LA, USA, May 6-9,\n2019. OpenReview.net.\nManoj Rohit Vemparala, Nael Fasfous, Alexander Frick-\nenstein, Sreetama Sarkar, Qi Zhao, Sabine Kuhn,\nLukas Frickenstein, Anmol Singh, Christian Unger,\nNaveen Shankar Nagaraja, Christian Wressnegger,\nand Walter Stechele. 2021. Adversarial robust\nmodel compression using in-train pruning. 2021\nIEEE/CVF Conference on Computer Vision and\nPattern Recognition Workshops (CVPRW), pages 66–\n75.\nBoxin Wang, Shuohang Wang, Yu Cheng, Zhe Gan,\nRuoxi Jia, Bo Li, and Jingjing Liu. 2020. Infobert:\nImproving robustness of language models from an\ninformation theoretic perspective. In International\nConference on Learning Representations.\n2221\nXiao Wang, Qin Liu, Tao Gui, Qi Zhang, Yicheng\nZou, Xin Zhou, Jiacheng Ye, Yongxin Zhang, Rui\nZheng, Zexiong Pang, Qinzhuo Wu, Zhengyan Li,\nChong Zhang, Ruotian Ma, Zichu Fei, Ruijian Cai,\nJun Zhao, Xingwu Hu, Zhiheng Yan, Yiding Tan,\nYuan Hu, Qiyuan Bian, Zhihua Liu, Shan Qin, Bolin\nZhu, Xiaoyu Xing, Jinlan Fu, Yue Zhang, Minlong\nPeng, Xiaoqing Zheng, Yaqian Zhou, Zhongyu Wei,\nXipeng Qiu, and Xuanjing Huang. 2021. TextFlint:\nUnified multilingual robustness evaluation toolkit\nfor natural language processing. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing:\nSystem Demonstrations , pages 347–355, Online.\nAssociation for Computational Linguistics.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pierric\nCistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2020.\nHuggingface’s transformers: State-of-the-art natural\nlanguage processing.\nCanwen Xu, Wangchunshu Zhou, Tao Ge, Ke Xu, Julian\nMcAuley, and Furu Wei. 2021. Beyond preserved\naccuracy: Evaluating loyalty and robustness of\nBERT compression. In Proceedings of the 2021\nConference on Empirical Methods in Natural\nLanguage Processing, pages 10653–10659, Online\nand Punta Cana, Dominican Republic. Association\nfor Computational Linguistics.\nShaokai Ye, Xue Lin, Kaidi Xu, Sijia Liu, Hao Cheng,\nJan-Henrik Lambrechts, Huan Zhang, Aojun Zhou,\nKaisheng Ma, and Yanzhi Wang. 2019. Adversarial\nrobustness vs. model compression, or both? In 2019\nIEEE/CVF International Conference on Computer\nVision, ICCV 2019, Seoul, Korea (South), October 27\n- November 2, 2019, pages 111–120. IEEE.\nHaoran You, Chaojian Li, Pengfei Xu, Yonggan Fu,\nYue Wang, Xiaohan Chen, Yingyan Lin, Zhangyang\nWang, and Richard G. Baraniuk. 2020. Drawing\nearly-bird tickets: Toward more efficient training\nof deep networks. In International Conference on\nLearning Representations.\nHaonan Yu, Sergey Edunov, Yuandong Tian, and Ari S.\nMorcos. 2020. Playing the lottery with rewards\nand multiple languages: lottery tickets in RL and\nNLP. In 8th International Conference on Learning\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\nApril 26-30, 2020. OpenReview.net.\nYuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan\nLiu, Meng Zhang, Qun Liu, and Maosong Sun.\n2020. Word-level textual adversarial attacking\nas combinatorial optimization. In Proceedings of\nthe 58th Annual Meeting of the Association for\nComputational Linguistics, pages 6066–6080, Online.\nAssociation for Computational Linguistics.\nDinghuai Zhang, Kartik Ahuja, Yilun Xu, Yisen\nWang, and Aaron C. Courville. 2021. Can\nsubnetwork structure be the key to out-of-distribution\ngeneralization? In ICML.\nXiang Zhang, Junbo Jake Zhao, and Yann LeCun.\n2015. Character-level convolutional networks for\ntext classification. In Advances in Neural Infor-\nmation Processing Systems 28: Annual Conference\non Neural Information Processing Systems 2015,\nDecember 7-12, 2015, Montreal, Quebec, Canada ,\npages 649–657.\nChen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom\nGoldstein, and Jingjing Liu. 2020. Freelb:\nEnhanced adversarial training for natural language\nunderstanding. In 8th International Conference on\nLearning Representations, ICLR 2020, Addis Ababa,\nEthiopia, April 26-30, 2020. OpenReview.net.\n2222\nA The Effect of Regularization Strength\nduring Mask Learning\nIn section 3.2.2, we show the mask learning\ncurves for various regularization strengths λ in\nSST-2 dataset. The results on more datasets are\nshown in the Fig.5, where we can observe that\nthe mask learning process is insensitive to the\nregularization strength, and the convergence of\nmasks is eventually achieved.\nB Implementation Details\nB.1 Details for Fine-tuning Models\nWe report the hyperparameters used for fine-tuning\nthe BERT-base and retraining the winning tickets\nin table 5.\nHypeparameters Values\nOptimizer Adamw(Loshchilov and Hutter, 2019)\nLearning rate 2 × 10−5\nDropout 0.1\nWeight decay 1 × 10−2\nBatch size 16 or 32\nGradient clip (−1, 1)\nEpochs 3\nBias-correction True\nTable 5: Hyperparameters used for fine-tuning the\nBERT-base and retraining the winning tickets.\nB.2 Details for Adversarial Attack\nWe use textattack (Morris et al., 2020) to implement\nthe adversarial attack methods. For all attack\nmethods, we use the default parameters of third-\nparty libraries. Adversarial robustness evaluation\nmetrics (e.g., Aua% and #Query) are evaluated\non the all 872 test samples for SST-2, 500\nrandomly selected test samples for IMDB, and\n1000 randomly selected test samples for other\ndatasets.\nB.3 Hyperparameters\nAdversarial loss objective introduces four widely\nused hyperparameters: the perturbation step size\nη, the initial magnitude of perturbations ϵ0, the\nnumber of adversarial steps s, and we do not\nconstrain the bound of perturbations. In addition,\nwe also report two important hyperparameters\nduring mask learning. They are mask learning\nrate γ and regularization penalty coefficient λ.\nThe weight decay wd in the optimizer are also\nchanged compared with default settings to make\nDatasets η γ λ ϵ 0 s wd\nSST2 0.03 0 .1 0 .5 0 .05 5 1 e − 6\nAGNEWS 0.03 0 .05 0 .5 0 .05 5 1 e − 6\nIMDB 0.03 0 .1 0 .5 0 .05 5 1 e − 6\nQQP 0.04 0 .05 0 .1 0 .05 3 1 e − 6\nQNLI 0.04 0 .05 0 .1 0 .05 3 1 e − 6\nMNLI 0.2 0 .1 0 .1 0 .05 2 1 e − 6\nTable 6: Hyperparameters used during mask learning.\nthe mask sparsity rate converge better. We list the\nhyperparameters used for each tasks in Table 6.\n2223\n1 4 8 12 16 20\nepoch\n0.4\n0.6\n0.8Regularizer\nregularizer\n=0.5\n =1.0\n0.2\n0.4\n0.6\n0.8\n1.0\npercentage of binary masks\npercentage of binary masks\n=0.5\n =1.0\n(a) IMDB\n1 4 8 12 16 20\nepoch\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9Regularizer regularizer\n=0.25\n =0.5\n0.4\n0.6\n0.8\n1.0\npercentage of binary masks\npercentage of binary masks\n=0.25\n =0.5\n (b) AGNEWS\n1 4 8 12 16 20\nepoch\n0.5\n0.6\n0.7\n0.8\n0.9Regularizer\nregularizer\n=0.1\n =0.5\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\npercentage of binary masks\npercentage of binary masks\n=0.1\n =0.5\n(c) QNLI\n1 4 8 12 16 20\nepoch\n0.5\n0.6\n0.7\n0.8Regularizer\n: regularizer\n=0.1\n =0.5\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\npercentage of binary masks\n: percentage of binary masks\n=0.1\n =0.5\n (d) QQP\nFigure 5: Effect of regularization strength during mask learning.\n2224"
}