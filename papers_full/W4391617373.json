{
    "title": "Incorporation of ChatGPT and Other Large Language Models into a Graduate Level Computational Bioengineering Course",
    "url": "https://openalex.org/W4391617373",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2096157484",
            "name": "Michael R. King",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A2325910572",
            "name": "Adam M. Abdulrahman",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": null,
            "name": "Mark I. Petrovic",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A4227386999",
            "name": "Patricia L. Poley",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A4323395683",
            "name": "Sarah P. Hall",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A5092985629",
            "name": "Surat Kulapatana",
            "affiliations": [
                "Vanderbilt University",
                "Siriraj Hospital",
                "Mahidol University"
            ]
        },
        {
            "id": "https://openalex.org/A3083938155",
            "name": "Zachary E. Lamantia",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A2096157484",
            "name": "Michael R. King",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A2325910572",
            "name": "Adam M. Abdulrahman",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": null,
            "name": "Mark I. Petrovic",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A4227386999",
            "name": "Patricia L. Poley",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A4323395683",
            "name": "Sarah P. Hall",
            "affiliations": [
                "Vanderbilt University"
            ]
        },
        {
            "id": "https://openalex.org/A5092985629",
            "name": "Surat Kulapatana",
            "affiliations": [
                "Vanderbilt University",
                "Mahidol University",
                "Siriraj Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A3083938155",
            "name": "Zachary E. Lamantia",
            "affiliations": [
                "Vanderbilt University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4312212221",
        "https://openalex.org/W4313479734",
        "https://openalex.org/W4365450342",
        "https://openalex.org/W4362693855",
        "https://openalex.org/W570534109",
        "https://openalex.org/W4366976243",
        "https://openalex.org/W4366452048",
        "https://openalex.org/W4362736925",
        "https://openalex.org/W4362582720"
    ],
    "abstract": null,
    "full_text": "Vol.:(0123456789)\nCellular and Molecular Bioengineering (2024) 17:1–6 \nhttps://doi.org/10.1007/s12195-024-00793-3\nEDITORIAL\nBIOMEDICAL\nENGINEERING \nSOCIETY\nIncorporation of ChatGPT and Other Large Language Models \ninto a Graduate Level Computational Bioengineering Course\nMichael R. King1 · Adam M. Abdulrahman1,2 · Mark I. Petrovic1,2 · Patricia L. Poley1 · Sarah P . Hall1 · \nSurat Kulapatana1,3 · Zachary E. Lamantia1\nPublished online: 7 February 2024 \n© The Author(s), under exclusive licence to Biomedical Engineering Society 2024\nAbstract\nThe remarkable capabilities of generative artificial intelligence and large language models (LLMs) such as ChatGPT have \ndelighted users around the world. Educators have regarded these tools as either a cause for great concern, an opportunity to \neducate students on cutting-edge technology, or often some combination of the two. Throughout the Fall 2023 semester, we \nexplored the use of ChatGPT (and Bard, among other LLMs) in a graduate level numerical and statistical methods course for \nPhD-level bioengineers. In this article we share examples of this ChatGPT content, our observations on what worked best in \nour course, and speculate on how bioengineering students may be best served by this technology in the future.\nKeywords Large language model · ChatGPT · Bard · Higher education · MATLAB\nIntroduction\nIn little over 1 year, ChatGPT and related tools have taken \nthe world by storm, with their ability to rapidly generate \ntext, computer programs and/or images on a wide range of \nsubject matter, all in response to plain language text prompts \nentered by the user. ChatGPT has been shown to have the \nability to generate entire articles on a specific topic, such as \nthe role of AI in medicine [ 1], raising questions related to \nplagiarism, AI-assisted student cheating [2 ], and the very \nnature of crediting authorship for AI-generated text [3 ]. \nOne of the more useful aspects of ChatGPT is its ability \nto generate functional computer programs in languages \nsuch as MATLAB or Python to achieve a specified task [4], \nsuggesting that it could enhance the education and practice \nof engineering if employed properly.\nOne of us (M.R.K.) has taught different versions of a \nnumerical and statistical methods course to biomedical \nengineering students for over 20 years, using a textbook \nwritten by King and Mody [5 ] that implements various \ntechniques in the MATLAB programming language. \nTo update the most recent offering of the BME 7410: \nQuantitative Methods in Biomedical Engineering course \nat Vanderbilt University in Fall 2023 and elevate its \ncontemporary relevance and interest, we incorporated the \nuse of ChatGPT and similar LLMs in the 7 homework \nassignments of the course. Enrollment in Fall 2023 was \n21 graduate students (mostly PhD students), with one \nstudent dropping the course prior to the end of the semester. \nOverall, this new content was well received by the students, \nand students completed 100% of the LLM homework \ncomponents. In this article, we provide some details on \nthe different ways in which LLMs were incorporated and \nshare observations on what worked best and what didn’t. \nWe conclude with some predictions on new ways in which \nLLMs may find utility in biomedical engineering education \nand practice as these tools continue to rapidly advance in \ntheir capabilities (Fig. 1).\nMethods\nThe BME 7410: Quantitative Methods in Biomedical \nEngineering course includes 7 homework assignments, \nassigned roughly biweekly on a different theme. Each \n * Michael R. King \n mike.king@vanderbilt.edu; mike.king@rice.edu\n1 Department of Biomedical Engineering, Vanderbilt \nUniversity, Nashville, TN 37235, USA\n2 Medical Scientist Training Program, Vanderbilt University \nSchool of Medicine, Nashville, TN, USA\n3 Department of Physiology, Faculty of Medicine Siriraj \nHospital, Mahidol University, Bangkok 10700, Thailand\n2 M. R. King et al.\nassignment involves 1–3 problems taken directly from the \nKing and Mody textbook [5]. The homework themes in Fall \n2023 were as follows:\nHomework #1: Linear Regression\nHomework #2: Probability, Error Propagation, and \nLinear Regression Error\nHomework #3: Nonlinear Root Finding\nHomework #4: Nonlinear Data Regression\nHomework #5: Numerical Quadrature\nHomework #6: ODE Integration\nHomework #7: Statistical Tests\nThe following guidelines were provided with the first home-\nwork assignment of the semester:\nChatGPT ground rules for my class:\nAlways clearly disclose which parts are LLM gener -\nated. Never pass off LLM output as your own work, or \nleave it ambiguous to the reader (me).\nI ask you to critique ChatGPT answers, rigorously \n(with math, and applying course concepts) whenever \npossible. On each homework assignment, you solve \none of the problems yourself, and then ask ChatGPT \nto critique your work (then comment on it) and then \nfor the other problem, switch roles. Ask ChatGPT to \nsolve and you critique its output. Sometimes I will tell \nyou which mode each problem is, sometimes it will \nbe your choice.\n.\n.\n.\nYou are encouraged to use ChatGPT, Microsoft Bing \nchatbot, and/or Google Bard chatbot. There are other \nLLMs out there, some are built on older versions \n(GPT-3.0 for instance) and less capable.\nHave fun with it! My hope is that we learn more, not \nless, than my pre-GPT classes. I am certainly excited \nabout the inclusion of AI in our course, and I hope \nyou are too.\n- MK\nResults\nIn this section, we summarize the student responses to the \nspecific LLM task for each of the 7 assignments.\nFig. 1  Four realizations of “a \nbioengineering graduate student \ncomparing the performance of \nChatGPT, Google Bard, and \nMicrosoft Bing chatbot in their \nability to teach and perform \ncomputational methods,” as \nenvisioned by the DALL-E \n3 AI image generator via the \nMicrosoft Bing chatbot app for \niPhone\n\n3\nIncorporation of ChatGPT and Other Large Language Models into a Graduate Level Computational…\nHW#1:\nLarge Language Model component of Homework \n#1 (worth 4 out of 14 points):\nFor the first problem, first ask ChatGPT or other LLM \nto solve it, and then you critique the LLM solution and \ndiscuss whether you agree with it (or not), based on \nthe concepts we have discussed in class and read about \nin the textbook.\nFor the second problem, first solve the problem your -\nself, and then ask ChatGPT or other LLM to critique \nyour solution and offer any corrections or improve-\nments that it can think of… and then discuss the simi-\nlarities and differences of the two approaches.\nOne immediate observation while grading these assignments \nis that different users can obtain different results, even when \nusing the same LLM. This could be due to subtle differences in \nprompt wording, occasional user error, inherent randomness in \nChatGPT, or the near daily updates implemented by OpenAI. \nUsually, ChatGPT is willing to perform mathematical calcula-\ntions but occasionally claims that it cannot. When prompted to \nwrite computer code or perform multistep calculations of any \nkind, ChatGPT will default to the Python language. This is less \nrelevant to our course which is based in MATLAB, however, \nand when prompted to program in MATLAB ChatGPT will \nhappily comply despite lacking the capacity to run or test MAT-\nLAB code in the user environment. Sometimes its MATLAB \ncode contains errors or attempts to call undefined functions—\nerrors easily identifiable when tested in a separate instantiation \nof MATLAB. On this first homework assignment, BME 7410 \nstudents greatly favored the default (free) GPT-3.5 version of \nChatGPT, as opposed to the premium GPT-4, Microsoft Bing \nchatbot (powered by GPT-4), or Google Bard (powered by the \nLaMDA algorithm, distinct from GPT). ChatGPT clearly excels \nin producing non-specific advice about how to solve basic \nforms of numerical or statistical calculations. One student sub-\nmitted an interesting interactive session attempting to “force” \nGPT to do actual mathematical operations when the user sus-\npected that it was not, and just guessing answers instead (and \napparently, it was). Another enterprising student asked GPT to \ncreate new problems that would illustrate a contradiction when \ncomparing 2 mathematical models via multiple error metrics!\nHW#2:\nChatGPT/LLM portion of homework: This home-\nwork is longer than most, with 3 problems instead of \n2, so just ask ChatGPT (or other LLM) to solve/resolve \none of the three problems, then report and interpret \nthese results. Any of the three problems, your choice!\nOne student provided a nice ChatGPT solution of a simple \nconfidence interval calculation; ChatGPT failed to use the \nmore appropriate t-distribution for a small (n = 4) sample \nsize and the student recognized this. Interestingly, the oppo-\nsite scenario was also submitted, where GPT correctly used \na t-distribution, but the student felt that the z-distribution \nshould have been used. The amusement of students with \nthese tools began to show in interactive back-and-forth ses-\nsions, with one student setting the stage with prompts such \nas “I am currently in the woods and don’t have a calculator” \nfollowed by “okay I used an abacus.”\nHW#3:\nLarge language model portion: For this homework, \nask ChatGPT or other LLM to create a well-defined \nscalar root-finding problem for you to solve, and then \nsolve it using one of the three methods we have dis-\ncussed in class. For fun, you may ask GPT to try and \nmake the problem relevant to biomedical engineering \n(which is more challenging, in my opinion). Briefly \ndiscuss whether you think this is a well-designed prob-\nlem.\nOne student asked a less common LLM, Claude 2, to cre-\nate a nonlinear root-finding problem, but decided that the \nproblem was too easy since it could be solved algebraically \nwithout the use of a nonlinear algorithm. Interestingly, a sec-\nond student obtained a very similar problem from ChatGPT. \nAnother student had ChatGPT create a simple root-finding \nproblem, outline a solution approach, and even calculate the \nanswer (in Python). One student asked ChatGPT to create \na biomedical problem involving the sum of two exponen-\ntials (a classic nonlinear example discussed in class that \nresists simple logarithmic linearization), however the stu-\ndent noted that GPT’s suggested initial guess was not a good \none. Another student obtained a wealth of extra drug dosing \ninformation from ChatGPT; as an instructor it is gratifying \nto see students demonstrate curiosity about the background \nsubject matter. A student asked ChatGPT to solve a newly \ngenerated abstract cubic problem using two different meth-\nods, which it promptly did. Interestingly, a student found \nthat GPT seemingly won’t use its best initial guess, unless \nspecifically prompted to do so. Finally, one student used \nMicrosoft Bing chatbot to create a biomedical root-finding \nproblem and it generated a good one, providing all of the \nnecessary parameter values as well. The student also deter -\nmined that the problem had a well-defined solution. Success!\nHW#4:\nLarge language model portion: Okay this one will be \nfun… solve both of the above problems yourself, and \nthen, for whichever solution you feel most confident \nabout, purposely insert an error in your solution. Then \nfeed your “incorrect” solution to the LLM and ask it \nto find the error! This may give us new insights into \n4 M. R. King et al.\nwhether LLMs can be useful for debugging engineer -\ning solutions… get creative with the engineered errors!\nOne student created a nice, subtle error which GPT-4 eas-\nily found. GPT-4 offered various opinions about the perfor-\nmance of the built-in MATLAB function fminsearch, con-\nvincing the user of the value of ChatGPT for engineering \ndebugging. Another student created a good error to plant in \ntheir code, which ChatGPT found and then rewrote the code \nto fix the error without even being prompted to. The student \nthen created a second, more subtle error, which ChatGPT \nwas also able to find! Something about the nature of this \nparticular LLM assignment elicited extra effort from the \nstudents beyond what was explicitly requested. A student \nplanted multiple errors at once, which ChatGPT correctly \nidentified, and so the student doubled down and created even \nmore errors to find! ChatGPT successfully found these addi-\ntional errors as well. One student noted in their assignment \nthat even over the course of a month or two, they have seen \na noticeable improvement of ChatGPT’s ability to debug \nMATLAB code, from finding only one error at a time to \ngreater performance in its error finding ability. A student \nplanted several errors at once, found that ChatGPT found all \nbut one of the errors. However, after further prompting, GPT \nwas able to locate the final error and revise the code appro-\npriately. One student was impressed that ChatGPT provided \nan itemized list of corrections and concluded that it is a valu-\nable debugging tool. A student preferred ChatGPT’s version \nof the code over their own and asked for recommendations \nof initial conditions to try. This was not a required part of \nthe problem, but useful nonetheless.\nIn terms of subtle errors to plant, students were gener -\nally impressed with ChatGPT’s ability to find errors in their \nprograms. One student changed a few of the concentration \ndata values to negative values, and surprisingly ChatGPT \ncaught this and deemed it not quite right. Amusingly, one \nstudent noted that ChatGPT found their intentional error, \nand also found an unintentional error! Another student found \nthat ChatGPT was unable to find their planted error the first \ntime, but successfully located it after a second attempt. A \nstudent mismatched the data file lengths, which ChatGPT \nwas able to flag as incorrect. One student tried to “fool” \nChatGPT by feeding it a MATLAB script with zero errors… \nbut it did not take the bait. Instead, it suggested that the user \ntry different initial guesses, which is a perfectly valid sug-\ngestion for nonlinear algorithms. This student then planted \na couple of incorrect data points, which ChatGPT was able \nto find. They concluded that it helps to tell ChatGPT how \nmany errors there are (if known). A student determined that \nChatGPT can find that most subtle of programming errors, \nthe sign error. The student proceeded to ask GPT’s opinions \non the rest of the assignment as well. One student noted that \nChatGPT will find and report errors even when not explicitly \nasked to do so, and also found that it did not seem to rely on \nexplanatory comments provided by the programmer when \nfinding MATLAB errors. Interestingly, one student tried the \nMicrosoft Bing chatbot, and determined that unlike Ope-\nnAI’s ChatGPT, Bing does have the capability to run MAT-\nLAB code on its own.\nHW#5:\nLLM portion: Ask ChatGPT or other LLM to solve \none of the two problems above, without specifying the \nmethod to be used. Compare it’s answer to yours, and \ndiscuss how they are different.\nMultiple students utilized the newly developed image \nprompt capability of ChatGPT to feed the original problem \nstatement as input and found that the LLM was able to solve \nit by writing a new MATLAB code. One student, wise to \nChatGPT’s ways, introduced this bit of prompt engineer -\ning to various tasks: “without using Python”. By this point \nin the course, some students had taken to submitting long \ninteractive sessions with their LLM of choice, packed with \nnew insights about the course material.\nHW#6:\nLLM portion: This time, let’s test the ability of Chat-\nGPT or Google Bard to interpret images. If you do not \nhave access to the ChatGPT mobile app, you can try \nthe latest version of Bard which allows for uploaded \nimages (bard.google.com/chat). After you have solved \nthe two problems above, export one of your Matlab \nplots of the integrated solution as a jpeg file, suitable \nfor upload to one of these LLMs. Make sure you label \nyour figure well, and then see what ChatGPT/Bard has \nto say about the figure. Is there any insight or useful \ncommentary it provides?\nStudents were generally impressed with the amount of infor-\nmation that ChatGPT and Bard are able to extract from a \nsubmitted image. Additional prompting was able to push \nChatGPT further with its interpretation, for instance com-\nmenting on the steady-state behavior of a time-series graph. \nBard provided some impressive feedback on a graph plotting \nan ordinary differential equation solution, somehow under -\nstanding it to be a plot of monovalent ligand binding to cell \nsurface receptors vs. time, explaining the behavior at differ-\nent times, and even describing how to extract kinetic param-\neters from the curve. Perhaps these surprising insights were \nfacilitated by the internet-enabled functionality of Bard. One \nstudent received a very informative response on the recep-\ntor binding plot, and ChatGPT placed these numbers into \nreal-world perspective, opining that “the time to reach near-\nequilibrium seems quite fast.” Another student gave Bard a \nfew hints, such as the method of integration used, along with \n5\nIncorporation of ChatGPT and Other Large Language Models into a Graduate Level Computational…\ntheir input image. One student fed Bard a three-part figure, \nwhich the LLM was able to interpret, and Bard provided \nsome interesting background information on the history of \nenvironmental policy (the ODE example in question was \nrelated to the simulation of toxic chemical concentrations \nin the atmosphere), and even expressed some opinions on \nthe crisis of climate change! Another student submitted fig-\nures to Bard and it suggested ways that the appearance of \nthe figures could be improved, by changing font sizes, axis \nlabels, and legends. Such aesthetic feedback was less com-\nmonly encountered. One student provided ChatGPT with \nan image of a plot and asked if the figure seemed consist-\nent with the governing equations of the problem, and the \nLLM (wrongly) suggested that the two didn’t match. On the \nother hand, another student fed Bard a figure labeled “ODE \nfigure” and somehow Bard was able to deduce the precise \nreceptor-ligand binding ODE equation. In that session Bard \nwas also able to carry out a stability analysis of the ODE, a \ntask that BME 7410 students are expected to master. Sev -\neral students correctly recognized that ChatGPT and Bard \ntended to extrapolate beyond the content of images and pro-\nvide related information and/or links to fairly relevant topics. \nOne student took a deep dive to explore Bard’s ability to \naccurately read and recognize the content of image input, \nwith the LLM sometimes misreading graphs or even hilari-\nously misidentifying the subject of an image.\nHW#7:\nLLM portion: For this final homework assignment, \nthere are no restrictions. Think of something creative \nbut relevant to do with the LLM(s) of your choice. \nSpread your wings and fly!\nOne student asked ChatGPT to design a lesson plan to teach \n“Understanding Two-Sample t-Tests with Unequal Vari-\nances” and it did a surprisingly good job with this, breaking \ndown how many minutes to devote to each section and what \nmaterials would be needed for the lecture. Another student \ncompared the responses of ChatGPT and Google Bard when \nasked for advice on how to manipulate a data set to obtain \na significant result on a statistical test and evaluated the \nethical responses both LLMs provided. A student explored \nthe image generation capabilities of ChatGPT, asking it to \nillustrate a multistep nanofabrication protocol, and then had \nsome additional fun by asking it to design some jewelry. \nAnother student fed the course syllabus to ChatGPT and \nasked how its services could be more useful for the course… \nan exercise that could have been quite useful before the start \nof the semester! A homework assignment and final exam \nwere created by ChatGPT, together with exam solution. \nSome students asked ChatGPT or Bard to create statistical \ntesting examples complete with answer key, as this was the \nfinal unit covered in the course and the topic of homework \n#7. Multiple students scanned their own homework assign-\nments and fed the images to Bard, requesting feedback from \nthe LLM. Bard impressed with its ability to decipher various \nhandwriting examples.\nSynergistic LLM Content and Activities\nThe instructor shared various preprints and journal publica-\ntions on a range of LLM-related topics [6 –9]. Throughout \nthe semester, interesting tweets and memes about ChatGPT \nwere also shared in lecture. Some real time, in-class dem-\nonstrations of LLM tools were carried out as new capa-\nbilities became available (e.g., the image-based prompts of \nChatGPT Plus for iPhone). In November 2023, the Bioen-\ngineering Division of the American Society of Mechanical \nEngineers invited M.R.K. to give a webinar presentation \non the topic of “Generative AI in Publishing,” as part of \ntheir Webinars on Generative Artificial Intelligence series. \nThrough a bit of fortuitous scheduling, their regular webi-\nnar time precisely overlapped with the BME 7410 lecture \ntime and day, and so we broadcast the webinar live from the \nclassroom. The second presentation in this webinar was on \nthe topic of Generative AI in Research, and quite relevant to \nthe overarching goals of the course. Students in attendance \nwere encouraged to log in to the Zoom webinar via their \npersonal laptops as well, to participate in the Q&A session \nfor both speakers using the chat function of Zoom. Many \nof the students did just that, making for an interactive and \nlively experience.\nAnonymous Course Evaluation Feedback\nThere were plenty of non-LLM aspects of the course for \nstudents to provide constructive criticism on, however the \nLLM activities garnered very little criticism in the end-of-\nsemester anonymous surveys. On student commented “LLM \nhomework is interesting and fun,” while another student \ncommented “I wonder if ChatGPT’s Data Analysis will be \nsolidified soon. It would be cool to see the implementation \nof how GPT’s Data Analysis could be used.” Despite all this \ninteresting new content, at least one student remained uncon-\nvinced: “I’m not sure the ChatGPT component is needed.”\nConclusions\nOverall, it seems that the graduate students in BME 7410 \nenjoyed the LLM component of the course and found it \nworthwhile. It should be pointed out that no material was \nremoved to make room for this new material, thus represent-\ning an expansion of the topics typically covered in this long-\nrunning course. There can be no doubt that every student and \nthe instructor gained an extensive new exposure to LLMs \n6 M. R. King et al.\nduring this course and increased their understanding of the \ncurrent capabilities and limitations of these tools. Several \nof us noted that the abilities and behaviors of these LLMs \nseemed to change from September-December 2023, high-\nlighting the dynamic nature of this emerging field. One inter-\nesting idea for future use of LLMs in engineering courses \nwould be to introduce a final project based on LLMs, which \nwould provide for a more in-depth, immersive experience.\nAcknowledgements The authors thank other students in the BME \n7410 class whose creative use of LLMs deserved mention: Grace \nAdams, Emily Berestesky, Alexandria Carter, Dara Chanthavisay, \nTaryn Dunigan, Paolo Francisco, Anna Kittel, Malachy Newman, Aviv \nPreminger, Drew Ray, and Xuerong Zhang.\nReferences\n 1. King, M. R. The future of AI in medicine: a perspective from a \nchatbot. Ann. Biomed. Eng. 51:291–295, 2023. https:// doi. org/ 10. \n1007/ s10439- 022- 03121-w. \n 2. King, M. R. A conversation on artificial intelligence, Chatbots, \nand plagiarism in higher education. Cell Mol. Bioeng. 16:1–2, \n2023. https:// doi. org/ 10. 1007/ s12195- 022- 00754-8. \n 3. King, M. R. A place for large language models in scientific \npublishing, apart from credited authorship. Cell Mol. Bioeng.  \n16:95–98, 2023. https:// doi. org/ 10. 1007/ s12195- 023- 00765-z. \n 4. King, M. Can GPT-4 formulate and test a novel hypothesis? Yes \nand no. TechRxiv., 2023. https:// doi. org/ 10. 36227/ techr xiv. 22517 \n278. v1.\n 5. King, M. R., and N. A. Mody. Numerical and Statistical Methods \nfor Bioengineering: Applications in MATLAB. Cambridge: \nCambridge University Press, 2010. \n 6. King, M. GPT-4 aligns with the New Liberal Party, while other \nlarge language models refuse to answer political questions. \nengrXiv. https:// doi. org/ 10. 31224/ 2974.\n 7. King, M. Administration of the text-based portions of a general \nIQ test to five different large language models. TechRxiv, 2023.\n 8. King, M. R. Bing chatbot formulating and testing novel hypotheses \nin real-time: How slime, chocolate, and Nobel prizes reveal the \npower and limits of artificial intelligence. engrXiv., 2023. https:// \ndoi. org/ 10. 31224/ 2937.\n 9. King, M. R. Can Bard, Google’s experimental Chatbot based on \nthe LaMDA large language model, help to analyze the gender \nand racial diversity of authors in your cited scientific references? \nCell Mol. Bioeng. 16:175–179, 2023. https:// doi. org/ 10. 1007/  \ns12195- 023- 00761-3. \nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations."
}