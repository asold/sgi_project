{
    "title": "Clinical Accuracy of Large Language Models and Google Search Responses to Postpartum Depression Questions: Cross-Sectional Study",
    "url": "https://openalex.org/W4386304195",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A1971732328",
            "name": "Emre Sezgin",
            "affiliations": [
                "The Ohio State University",
                "Nationwide Children's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2581992797",
            "name": "Faraaz Chekeni",
            "affiliations": [
                "Nationwide Children's Hospital",
                "The Ohio State University"
            ]
        },
        {
            "id": "https://openalex.org/A1945977096",
            "name": "Jennifer Lee",
            "affiliations": [
                "The Ohio State University",
                "Nationwide Children's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A2585921129",
            "name": "Sarah A. Keim",
            "affiliations": [
                "The Ohio State University",
                "Nationwide Children's Hospital"
            ]
        },
        {
            "id": "https://openalex.org/A1971732328",
            "name": "Emre Sezgin",
            "affiliations": [
                "Nationwide Children's Hospital",
                "The Ohio State University"
            ]
        },
        {
            "id": "https://openalex.org/A2581992797",
            "name": "Faraaz Chekeni",
            "affiliations": [
                "Nationwide Children's Hospital",
                "The Ohio State University"
            ]
        },
        {
            "id": "https://openalex.org/A1945977096",
            "name": "Jennifer Lee",
            "affiliations": [
                "Nationwide Children's Hospital",
                "The Ohio State University"
            ]
        },
        {
            "id": "https://openalex.org/A2585921129",
            "name": "Sarah A. Keim",
            "affiliations": [
                "The Ohio State University",
                "Nationwide Children's Hospital"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4317757464",
        "https://openalex.org/W2134236426",
        "https://openalex.org/W2318935314",
        "https://openalex.org/W3108615578",
        "https://openalex.org/W4319062614"
    ],
    "abstract": null,
    "full_text": "Research Letter\nClinical Accuracy of Large Language Models and Google Search\nResponses to Postpartum Depression Questions:Cross-Sectional\nStudy\nEmre Sezgin1,2, PhD; Faraaz Chekeni1,2, MD, PhD; Jennifer Lee1,2, MD; Sarah Keim1,2,3, PhD\n1Nationwide Children's Hospital, Columbus, OH, United States\n2College of Medicine, The Ohio State University, Columbus, OH, United States\n3College of Public Health, The Ohio State University, Columbus, OH, United States\nCorresponding Author:\nEmre Sezgin, PhD\nNationwide Children's Hospital\n700 Children's Dr\nColumbus, OH, 43205\nUnited States\nPhone: 1 614 722 3179\nEmail: emre.sezgin@nationwidechildrens.org\n(J Med Internet Res 2023;25:e49240) doi: 10.2196/49240\nKEYWORDS\nmental health; postpartum depression; health information seeking; large language model; GPT; LaMDA; Google; ChatGPT;\nartificial intelligence; natural language processing; generative AI; depression; cross-sectional study; clinical accuracy\nIntroduction\nPostpartum depression (PPD) affects about 1 in 8 women in the\nmonths after delivery [1], and most of the affected individuals\ndo not receive help, primarily due to insufficient screening and\na lack of awareness about the condition. As large language\nmodel (LLM)–supported applications are becoming an integral\npart of web-based information-seeking behavior, it is necessary\nto assess the capability and validity of these applications in\naddressing prevalent mental health conditions [2]. In this study,\nwe assessed the quality of LLM-generated responses to\nfrequently asked PPD questions based on clinical accuracy (a\ncontextually appropriate response that reflects current medical\nknowledge).\nMethods\nWe used 2 publicly accessible LLMs, GPT-4 (using ChatGPT)\n[3] and LaMDA (using Bard) [4], and Google Search engine.\nOn April 3, 2023, we prompted each model and queried Google\nwith 14 PPD-related patient-focused frequently asked questions\nsourced from the American College of Obstetricians and\nGynecologists (ACOG; Multimedia Appendix 1) [5]. ChatGPT\nand Bard were prompted with each question in a new single\nsession without prior conversation. Google Search results were\nnot standardized, and search results were displayed in 3 different\nformats: an information card, curated content (a snippet of text\nat the top), and top search results (list of links with brief\ninformation snippets including sponsored content). We analyzed\nonly Google interface-based feedback to be consistent (the first\nresponse without link navigation).\nTwo board-certified physicians (author JL is board certified in\npediatrics and pediatric gastroenterology and author FC is board\ncertified in pediatrics) compared the LLM responses and Google\nSearch results to the ACOG FAQ responses and rated the quality\nof responses using a GRADE (Grading of Recommendations\nAssessment, Development and Evaluation)-informed scale [6].\nWe calculated Cohen κ coefficient to measure interrater\nreliability. We tested the normality (Shapiro-Wilk test) and\nhomoscedasticity (Levene test) of the rater data, followed by\nthe Kruskal-Wallis test to compare the differences in the quality\nrating among the 3 groups. The pairs of groups were investigated\nfor significant differences by post hoc Dunn test with Bonferroni\ncorrection (for multiple comparisons). Analyses used R software\n(v4.2.1; R Foundation of Statistical Computing) [7].\nResults\nChatGPT differed in the quality of responses against others\n(mean 3.93, SD 0.27; Table 1). A statistically significant\ndifference in the distribution of scores among the categories\nwas found (χ2\n2=12.2; P=.002; Table 2). ChatGPT demonstrated\ngenerally higher quality (more clinically accurate) responses\ncompared to Bard (Z=2.143; adjusted P=.048) and Google\nSearch (Z=3.464; adjusted P<.001). There was no difference in\nJ Med Internet Res 2023 | vol. 25 | e49240 | p. 1https://www.jmir.org/2023/1/e49240\n(page number not for citation purposes)\nSezgin et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nthe quality of responses between Bard and Google Search\n(Z=1.320; adjusted P=.28).\nRaters showed perfect agreement for ChatGPT (κ=1, 95% CI\n0.85-1.15) and near-perfect agreement for Bard and Google\nSearch (κ=0.92, 95% CI 0.71-1.13). Data were not normally\ndistributed (P<.05) and nonhomoscedastic (F2=4.153; P=.02)\nfor each category (ChatGPT, Bard, and Google Search).\nTable 1. Average quality ratings for ChatGPT, Bard, and Google Search responses to American College of Obstetricians and Gynecologists (ACOG)\nquestions [5].\nAverage quality ratingsaACOG postpartum depression frequently asked questions\nGoogle SearchBardChatGPT\n344What are baby blues?\n304Can antidepressants cause side effects?\n444How is postpartum depression treated?\n144How long do the baby blues usually last?\n144If I think I have postpartum depression, when should I see my health care professional?\n3.504What are antidepressants?\n304Can antidepressants be passed to my baby through my breast milk?\n344What are the types of talk therapy?\n143What can be done to help prevent postpartum depression in women with a history of de-\npression?\n104What causes postpartum depression?\n444What happens in talk therapy?\n444What is postpartum depression?\n134What support is available to help me cope with postpartum depression?\n13.54When does postpartum depression occur?\n2.39 (1.3)2.75 (1.83)3.93 (0.27)Mean (SD)\n3 (1-4)4 (0-4)4 (4-4)Median (IQR)\n144Mode\n1-40-43-4Minimum-maximum\naGRADE (Grading of Recommendations Assessment, Development and Evaluation)-informed quality assessment scale [6]: 0=no response (the system\nrefused to provide any information), 1=inaccurate response (the system response does not reflect any facts relevant to the corresponding question),\n2=clinically inaccurate response (the system response includes facts about the corresponding question but is not clinically relevant), 3=partially clinically\naccurate response (the system response is accurate and clinically relevant, yet it introduces some risks in terms of misinterpretations and misunderstanding),\n4=mostly clinically accurate response (the system response is accurate and clinically relevant, and risk is minimal for misinterpretations and\nmisunderstanding).\nTable 2. Results of nonparametric test to identify significant differences between categories (Kruskal-Wallis) and post hoc pairwise comparison to\ndetermine differing categories (Dunn test).\nAdjusted P valueValueTest\nKruskal-Wallis\n.002a12.2 (2)Chi-square (df)\nDunn Test\n.048a2.143ChatGPT vs Bard, Z value\n<.0013.464ChatGPT vs Google Search, Z value\n.281.320Bard vs Google Search, Z value\naP<.05.\nbP<.001.\nJ Med Internet Res 2023 | vol. 25 | e49240 | p. 2https://www.jmir.org/2023/1/e49240\n(page number not for citation purposes)\nSezgin et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nDiscussion\nThis study expands an earlier investigation on chatbot advice\nfor PPD [8], showing that LLMs can provide clinically accurate\nresponses to questions regarding PPD. ChatGPT provides\nhigher-quality responses based on concordance with answers\nprovided in the ACOG FAQ. The quality of Bard responses\nwas high when provided, but its overall score was impacted by\nno-response answers (which were mostly factual in nature rather\nthan seeking medical advice, eg, “what are antidepressants?”).\nThese responses received the lowest quality score in our rating.\nAlmost all of the responses by Bard and ChatGPT did not\nprovide a source for the information in their responses (only\none response included a source). However, many responses\nrecommended consulting a health care provider or mental health\nprofessional in some capacity. Google Search results were rated\nas lower-than-average quality compared to Bard and ChatGPT.\nOverall, LLMs showed promise in terms of providing clinically\naccurate or better-quality responses than Google Search results.\nThis finding is consistent with the prior investigation on the\nappropriateness of LLM-based medical advice [9]. Our findings\nshould be interpreted carefully considering the following\nlimitations. To start, none of these technologies are built for\nmedical purposes. We included a limited number of standard\nquestions (14 ACOG questions) analyzed within a limited scope\n(one question per category; no personas, eg, “act like a doctor”;\nno prompt engineering for exploring different contexts or\nsettings). Future work is needed for a more comprehensive\ninvestigation (eg, measuring acceptability and empathy with\nstakeholders) as well as to develop clinical guidance\n(frameworks in close collaboration among clinicians,\nresearchers, and developers) to inform the implementation and\nevaluation of such technologies, ensuring their ability to address\nPPD-related questions accurately, ethically, and safely [10].\nData Availability\nAll data generated or analyzed during this study are included in this published article (Multimedia Appendix 1).\nAuthors' Contributions\nES led the conceptualization, method development, data curation, and drafting of the manuscript. FC and JL performed the formal\nanalysis. All authors participated in the investigation and validation processes. The project was supervised by ES and SK. The\nmanuscript was reviewed and edited by all authors, who also approved its final version.\nConflicts of Interest\nFC owned shares of Google (GOOGL) during the study period.\nMultimedia Appendix 1\nResponses to postpartum depression frequently asked questions.\n[XLSX File (Microsoft Excel File), 26 KB-Multimedia Appendix 1]\nReferences\n1. Depression during and after pregnancy. Centers for Disease Control and Prevention. 2023. URL: https://www.cdc.gov/\nreproductivehealth/features/maternal-depression/index.html [accessed 2023-05-17]\n2. Sharma A, Lin IW, Miner AS, Atkins DC, Althoff T. Human–AI collaboration enables more empathic conversations in\ntext-based peer-to-peer mental health support. Nat Machine Intelligence 2023 Jan 23;5(1):46-57 [doi:\n10.1038/s42256-022-00593-2]\n3. GPT-4. OpenAI. URL: https://openai.com/product/gpt-4 [accessed 2023-04-25]\n4. Collins E, Ghahramani Z. LaMDA: our breakthrough conversation technology. The Keyword. 2021. URL: https://blog.\ngoogle/technology/ai/lamda/ [accessed 2023-09-06]\n5. Postpartum depression. American College of Obstetricians and Gynecologists. URL: https://www.acog.org/womens-health/\nfaqs/postpartum-depression [accessed 2023-05-15]\n6. Guyatt GH, Oxman AD, Kunz R, Vist GE, Falck-Ytter Y, Schünemann HJ, GRADE Working Group. What is \"quality of\nevidence\" and why is it important to clinicians? BMJ 2008 May 03;336(7651):995-998 [FREE Full text] [doi:\n10.1136/bmj.39490.551019.BE] [Medline: 18456631]\n7. Ripley BD. The R Project in Statistical Computing. MSOR Connections 2001 Feb;1(1):23-25 [doi:\n10.11120/msor.2001.01010023]\n8. Yang S, Lee J, Sezgin E, Bridge J, Lin S. Clinical advice by voice assistants on postpartum depression: cross-sectional\ninvestigation using Apple Siri, Amazon Alexa, Google Assistant, and Microsoft Cortana. JMIR Mhealth Uhealth 2021 Jan\n11;9(1):e24045 [FREE Full text] [doi: 10.2196/24045] [Medline: 33427680]\n9. Sarraju A, Bruemmer D, Van Iterson E, Cho L, Rodriguez F, Laffin L. Appropriateness of cardiovascular disease prevention\nrecommendations obtained from a popular online chat-based artificial intelligence model. JAMA 2023 Mar\n14;329(10):842-844 [FREE Full text] [doi: 10.1001/jama.2023.1044] [Medline: 36735264]\n10. Aronson S, Lieu TW, Scirica BM. Getting generative AI right. NEJM Catalyst 2023:1 [doi: 10.1056/CAT.23.0063]\nJ Med Internet Res 2023 | vol. 25 | e49240 | p. 3https://www.jmir.org/2023/1/e49240\n(page number not for citation purposes)\nSezgin et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX\nAbbreviations\nACOG: American College of Obstetricians and Gynecologists\nGRADE: Grading of Recommendations Assessment, Development and Evaluation\nLLM: large language model\nPPD: postpartum depression\nEdited by T Leung; submitted 22.05.23; peer-reviewed by A Santosa, D Whitehead; comments to author 16.07.23; revised version\nreceived 20.07.23; accepted 30.08.23; published 11.09.23\nPlease cite as:\nSezgin E, Chekeni F, Lee J, Keim S\nClinical Accuracy of Large Language Models and Google Search Responses to Postpartum Depression Questions: Cross-Sectional\nStudy\nJ Med Internet Res 2023;25:e49240\nURL: https://www.jmir.org/2023/1/e49240\ndoi: 10.2196/49240\nPMID: 37695668\n©Emre Sezgin, Faraaz Chekeni, Jennifer Lee, Sarah Keim. Originally published in the Journal of Medical Internet Research\n(https://www.jmir.org), 11.09.2023. This is an open-access article distributed under the terms of the Creative Commons Attribution\nLicense (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any\nmedium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete\nbibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license\ninformation must be included.\nJ Med Internet Res 2023 | vol. 25 | e49240 | p. 4https://www.jmir.org/2023/1/e49240\n(page number not for citation purposes)\nSezgin et alJOURNAL OF MEDICAL INTERNET RESEARCH\nXSL•FO\nRenderX"
}