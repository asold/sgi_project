{
    "title": "Using GQM and TAM to evaluate StArt – a tool that supports Systematic Review",
    "url": "https://openalex.org/W2144326572",
    "year": 2012,
    "authors": [
        {
            "id": "https://openalex.org/A2717093549",
            "name": "Elis Hernandes",
            "affiliations": [
                "Universidade Federal de São Carlos"
            ]
        },
        {
            "id": "https://openalex.org/A2146977387",
            "name": "Augusto Zamboni",
            "affiliations": [
                "Universidade Federal de São Carlos"
            ]
        },
        {
            "id": "https://openalex.org/A2062950074",
            "name": "Sandra Fabbri",
            "affiliations": [
                "Universidade Federal de São Carlos"
            ]
        },
        {
            "id": "https://openalex.org/A2140574411",
            "name": "Andre Di Thommazo",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W6681862009",
        "https://openalex.org/W2162411541",
        "https://openalex.org/W1971654472",
        "https://openalex.org/W2106956101",
        "https://openalex.org/W6684456340",
        "https://openalex.org/W6684348881",
        "https://openalex.org/W69766824",
        "https://openalex.org/W1765982496",
        "https://openalex.org/W2065502371",
        "https://openalex.org/W1721296466",
        "https://openalex.org/W6831468876",
        "https://openalex.org/W4214443",
        "https://openalex.org/W2166878809",
        "https://openalex.org/W3134208756",
        "https://openalex.org/W2146773231",
        "https://openalex.org/W2168894761"
    ],
    "abstract": "&#x0D; &#x0D; &#x0D; Background: Although Systematic Literature Review (SLR) is a reliable way of conducting literature review, its process is laborious and composed of repetitive activities. Hence, aiming to facilitate and support the conduction of such a process, the StArt tool was developed. Objective: As any new technology should be evaluated before its use, the objective of this paper is to present an overview of this tool and describe an evaluation that was carried out aiming at characterizing its usefulness and its ease of use. Method: The evaluation, applied twice, was designed through GQM paradigm and TAM model. The participants were graduate students who had a previous knowledge on SLR and have already applied the SLR process manually. Results: In both the evaluations the results were concentrated on the answers “extremely agree” or “quite agree” both for the usefulness and for the ease of use. Conclusion: Based on the results the further actions are: improvements related to the “quite agree” answers and the conduction of an experiment for evaluating the StArt in a deeper way. Despite these needed improvements, the results provide insights that StArt indeed helps the conduction of SLR and facilitates the application of its process.&#x0D; &#x0D; &#x0D;",
    "full_text": "CLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n1 \nUsing GQM and TAM to evaluate StArt – a tool that supports \nSystematic Review \n \n \nElis Hernandes, Augusto Zamboni, Sandra Fabbri \nUniversidade Federal de São Carlos, Computing Department \nSão Carlos, Brazil, 13565-905 \n{elis_hernandes, sfabbri}@dc.ufscar.br, augusto_zamboni@comp.ufscar.br \n \nand \n \nAndré Di Thommazo \nInstituto Federal de Educação, Ciência e Tecnologia de São Paulo (IFSP) \nSão Carlos, Brazil, 13565-905 \nandredt@ifsp.edu.br\nAbstract \nBackground: Although Systematic Literature Review  (SLR) is a reliable way of conducting \nliterature review, its process is laborious and composed of repetitive activities. Hence, aiming \nto facilitate and support the conduction of such a process, the StArt tool was developed. \nObjective: As any new technology should be evaluated before its use, the objective of this \npaper is to present an overview of this tool and describe an evaluation that was carried out \naiming at characterizing its usefulness and its ease of use. Method: The evaluation, applied \ntwice, was designed through GQM paradigm and TAM model. The participants were graduate \nstudents who had a previous knowledge on SLR and have already applied the SLR process \nmanually. Results: In both the evaluations the results were concentrated on the answers \n“extremely agree” or “quite agree” both for the usefulness and for the ease of use. \nConclusion: Based on the results the further actions are: improvements related to the “quite \nagree” answers and the conduction of an experiment for evaluating the StArt in a deeper way. \nDespite these needed improvements, the results provide insights that StArt indeed helps the \nconduction of SLR and facilitates the application of its process. \n  \n Keywords: systematic literature review, SLR, ev idence-based software engineering, \ntool, literature review. \n \n 1 Introduction \nEvidence-based software engineering (EBSE) has received great attention nowadays. It focuses on the identification \nof the best research evidences, aiming at integrating them  with practical experience and human value. In addition, \nEBSE focuses on the application of this knowledge in the decision making process regarding software development \nand maintenance [1] [2] [3]. \nAccording to Kitchenham et al. [1], the term evidence corresponds to the synthesis of the best studies on a \nresearch topic provided in primary studies of literature. A way to compose this synthesis is applying Systematic \nLiterature Review (SLR), which is a type of secondary study, and makes use of a process that is reliable, rigorous \nand that allows auditing [4]. If on one hand this process pr ovides advantages to SLRs in relation to the traditional \nliterature review, on the other hand, it is laborious and error prone when applied only manually. Therefore, the \nsupport of a tool is essential to achieve the expected results of a SLR. \nBased on this context, the objective of this paper is to present a tool that supports the SLR process and comment \ntwo viability studies carried out aiming to evaluate its perceived usefulness and ease of use. This tool is named StArt \n- State of the Art through Systematic Review and has been developed at Federal University of São Carlos (UFSCar), \nin the Software Engineering Research Laboratory (LaPES). \nThe paper is organized as follows: Section 2 presents a summary on Systematic Literature Review and the \ncharacteristics that differentiate it from traditional literature review. Section 3 presents the tool StArt by exploring \nits functionalities and the way it supports the SLR process, as well as how it facilitates some tasks that should be \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nexecuted during that process. Section 4 provides an overview of related tools found in literature, Section 5 presents \nsome preliminary studies that were carried out to evaluate StArt and finally, Section 6 presents the final remarks and \nfurther work. \n \n 2 Systematic Literature Review \nAccording [5], the Systematic Literature Review is support ed by a well-defined process that makes it different from \nthe traditional literature review. Some characteristics of the SLR are: starts by defining a Protocol which must \ncontain a set of information used during the process execution, including the question being addressed; is based on a \nsearch strategy carefully defined for identifying as much of the relevant literature related to the research question; \ndocuments its search strategy such that it can be follow ed rigorously; requires that the inclusion and exclusion \ncriteria used to evaluate each potential primary study are explicitly defined in the Protocol; requires the specification \nof the quality criteria that should be used to evaluate the content of each primary study; and must always be \nconducted when a quantitative meta-analysis is required. \nDespite the advantages of a SLR, as good coverage, re plicability and reliability, its process is more laborious \nthan the one related to an informal literature research [5 ]. Thus, considering that there are several stages to be \nexecuted and several documents to be managed, computational support can facilitate the work and enable higher \nquality in the execution process. Although there are slight differences among the SLR processes commented in \nliterature, they all involve planning, execution, analysis and dissemination of results [5] [6].  \nIn the Planning stage, the aim is to define a Protocol whic h contains all the information and the necessary \nprocedures for the execution of the fo llowing stages. Examples of the inform ation and the procedures needed are: \nthe research question, the keywords, the search engines and the studies inclusion and exclusion criteria. \nIn the Execution stage, three steps must be co nducted: the Studies Identification on the search engines defined \nin the Protocol, the Selection of these studies, based on the inclusion and the exclusion criteria, and the Extraction of \ndata from the selected studies. \nIn the Summarization stage, the data extracted from the studi es are analysed and summarized aiming at \nanswering the research question defined in the Protocol. \nAfter the conclusion of these three stages, it is important to report the results through technical reports or \nscientific papers to show the state of the art of the topic in focus. \n \n 3 The Tool StArt \nSome activities in the SLR process are repetitive and require  discipline and systematic practice by the researcher. \nThe information must be registered in an organized way so that the SLR provides the expected results, is replicable, \nand allows that all the information can be packed. StArt provides support to the SLR process activities, except to the \nautomated search of primary studies in electronic databases, since this is c onsidered as a robot action, which is \nblocked by these mechanisms. Therefore, the researcher must do the search manually through the search engines \nregistered in the Protocol every time a search is necessary. The sear ch result must be exported from the search \nengine as a BibTex file which must be imported into StArt. \nFigure 1 presents a screen of the tool. In the left side a hierarchical tree shows the process stages to be followed. \nSome pieces of information in this tree are filled out dyna mically, as the researcher defines the Protocol or as the \nprocess steps are carried out. This resource of StArt helps the researcher in keeping the information updated and \nconsistent. \nThe following subsections describe the way each SLR stage is supported by the tool. \n \n 3.1 Planning \nIn this stage, the researcher must define the Protocol that will support the other SLR stages. The Protocol fields \navailable in the tool are the ones suggested by [5]. StArt has a help icon that provides the description and example of \neach field. As some fields have influence over other process stages, the tool assists in keeping these relations \ncontrolled. For instance:  \n- Source List : this field contains the list of all the search engines which will be used to gather the studies. \nMeanwhile they are inserted in the Protocol, the name of the search engi nes are automatically added in the side-tree \nof the main screen (Figure 1). The separation of the search engines allows a better organization of the studies as well \nas the information control in the studies identification step; \n- Keywords: this field contains the keywords that will be used to compose the search strings. When the studies \nare uploaded into the StArt, it uses the keywords to sc ore the studies according to the number of occurrences of \nthese words in their title, abstract and keywords. This scor e, showed in Figure 2, s uggests the studies relevance \norder; \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n- Studies Inclusion and Exclusion Criteria Definition: this field, as showed in Figure 1, contains the criteria that \nwill be used to accept or reject each st udy during the selection step. StArt ma kes them available in this step and \nallows the researcher to register the ones were applied to each of the studies, as showed in Figure 2; \n- Information Extraction Form Attributes : this field contains the attributes that will compose the form which \nmust be filled in by the researcher in the Extraction stage, as explained in subsection 3.2.3. \n \n \nHelp \nFigure 1. Part of the Protocol highlighting the source list that is added dynamically to the side-tree \n \nFigure 2. Information available in the StArt when the studies are uploaded into the tool \n \n 3.2 Execution \nOnce the Protocol is concluded, the researcher is able to perform the Execution stage that is composed of three steps: \nStudies Identification, Selection and Extraction. \n \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n 3.2.1 Studies Identification \nIn this step the objective is to gather a set of studies th at is related to the research question. Thus, the researcher \nshould: (i) apply the search strings to each of the search engines specified in the Protocol and export the results in a \nBibTex format, and (ii) import into StArt the BibTex and store the search string used by the search engine, since the \nsearch string that allows a faithful replication of the SLR. The tool also allows manually insertion of studies. \nOnce the BibTex file was imported, all the information presented in Figure 2 is available in the StArt. This \nscreen shows the search string used in this session, the number of studies identified, and a table with some attributes \nof each study, as its identification, title, author(s), status  at the Selection step, status at the Extraction step, Reading \nPriority and Score. The score, as mentioned before, is automatically calculated according to the number of times the \nkeywords defined in the Protocol Duplicated studies are also automatically identified by the tool. The two fields \nStatus must be filled by the researcher, according to the process step. \n \n 3.2.2 Selection \nIn this step the primary studies uploade d into the Start must be accepted or re jected according to the inclusion and \nexclusion criteria defined in the Protocol. Figure 3 illustrates the facility provided by the tool for doing this activity. \nThe decision should be made after reading the title, abstract and keywords of the study, which are available for each \nstudy, as shown in Figure 4. At the end of this step all the accepted studies  are automatically transferred to the \nExtraction step. Figure 5 exemplifies this fac t: see that there are seven papers as Accepted Papers in the Selection \nstep and a total of seven papers in the Extraction step. \n \n 3.2.3 Extraction \nIn this step, all the studies that have been accepted in the Selection step should be read in full and be analyzed again \na study is rejected if they are not relevant to answer the main question defined in the Protocol it must be rejected in \nthis step. The Reading Priority field that can be filled during the Selection step may help the researcher with the \nreading order. Although the full studies must be downloaded by the researcher, they can be linked to the SLR, which \nfacilitates the access to the document.  For the papers classified as Accepted in this step, the re searcher must extract \nthe information correspondent to the attributes of the Information Extraction Form , defined in the Protocol. This \nform is available in this step as shown in Figure 5.  This facility promotes a systematic way for extracting \ninformation. \n \n 3.3 Summarization \nIn this stage the researcher should describe the state of the art of the topic in focus. StArt facilita tes the access to the \ninformation extracted during the Extraction  step and provides a text editor to help in a first version of the \nsummarization document when this stage is reached some data on the whole SLR are available, as shown in Figure 6. \nIn addition, Start provides some reports that also facilitate the conduction of a SLR. \n \n \nFigure 3. Application of the Inclusion and exclusion criteria  \n \n \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nFigure 4. General data of each study \n \n \nFigure 5. Information Extraction Form \n \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nFigure 6. Some final data provided at Summarization stage \n \n 4 Related tools \nIn the literature, there are some tools to support the management of bibliographic references, which are commonly \nused by researchers to aid in the SLR process. The purpose and the coverage of these tools are different and they are \nnot related to the SLR process proposed by [5], except for SLR Tool [7]. \nOnly SLR Tool [7] focuses on Systematic Literature Re view. However, its installation requires the availability \nof a specific database management system and a pre-configuration of the environment, which can restrict its use, \nmainly by researchers of other research areas such as Medicine and Nursing, who are also users of the SLR process \nAnother characteristic of the SLR Tool is that it only works with the English and the Spanish versions of the \nWindows operating system. On the other hand, StArt does not have this restriction and can be easily installed \nthrough a wizard interface. Tabl e 1 presents the main characteristics of tool s that are being used in the context of \nliterature review. \n \nTable 1. Characterization of related tools \nTool name Free Protocol \ndefinition \nManagement \nreferences \nExport \nreferences\nCustomization of \nattributes \nAutomatic \nclassification of papers\nJabRef Y No Yes Yes Yes No \nEndNote  No No Yes Yes Yes No \nProCite  No No Yes No No No \nReference Manager No No Yes No No No \nRefWorks  No No Yes Yes No No \nBibEdt  Yes No Yes No No No \nZotero  Yes No Yes Yes Yes No \nBiblioscape  No No Yes No No No \nBookends  Yes No Yes Yes Yes No \nLibrary Master  No No Yes Yes Yes No \nMendeley No No Yes Yes Yes No \nMekentosj No No Yes Yes No No \nSLR Tool Yes Yes Yes Yes No No \nReview Manager Y Y Yes No Yes No \nStArt Y Y Yes No Yes Yes \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n 5 StArt evaluation: preliminary data on the Usefulness and Ease of Use \nAccording to [8], all proposed technology (method, technique, tool, etc.) should be evaluated before being made \navailable for use. The objective of the evaluation descri bed bellow was to characterize the two aspects of the TAM \nmodel (Technology Acceptance Model) [9], to get preliminary data on the tool viability of use. \nThe evaluation was applied twice. In both occurrences the participants were graduate students in Computer \nScience (MSc. and PhD.) who had applied the SLR process, manually, during the Research Methodology course. \nFourteen students participated of the first evaluation and thirty five participated of the second one. \nThe evaluation was planned through the GQM (Goal, Question, Metric) paradigm [10][11], which is composed \nof four steps: Planning, Definition; Data Collection; and Interpretation that are described below.  \n \n 5.1. Planning and Definition \nThe GQM model constructed for planning the evaluation consists of four goals, thirteen questions (Table 2) and \nfourteen metrics (Table 3), according to details presented in Figure 7. Based on that model, two questionnaires were \nused in the evaluation: Questinonnaire1 (Q1 to Q4) for collecting data on student’s opinion and their current contact \nwith systematic review; and Questionnaire2 (Q5 to Q13) for characterizing the usefulness and ease of use of the \ntool, according to TAM. The questions related to TAM we re inspired on the study presented in [12] and were \nevaluated according to the Likert scal e [13]. Both questionnaires contained blank fields for comments. Table 6 \npresents the interpretation model of the GQM, which should be read as follows: \"If Expression then Interpretation\". \nTaking line 9 as an example where th e question is Q4, \" If M9 + M10 + M11 ≥ M12 + M13 + M14 then the SR is \nseen as a key resource for the quality of academic research.” \n \n \nFigure 7. GQM to evaluate the StArt \n \nTable 2. Questions used in the GQM \nQuestion Description Question Description \nQ1 Which activity required in the process of systematic review do you \njudge as the most difficult? Q9 It was easy to remember how to execute a \nsystematic review through the use of StArt \nQ2 After experiencing the process of systematic review, have you \nchanged your way of doing a literature review? Q10 I think StArt is easy to use \nQ3 Have you tried to reapply the process of systematic review after the \ncourse was conducted in the second semester of 2009? Q11 \nStArt has allowed me to perform a systematic \nreview in accordance with the process defined \nin the literature \nQ4 What is your level of agreement with the statement: \"The \nsystematic review is critical to the quality of academic research\" \nQ5 It was easy to learn how to use StArt? \nQ12 \nConsidering what I have learnt about RS, using \nStArt facilitated the execution of the activities \nthat compose the systematic review process Q6 I could use StArt the way I wanted. \nQ7 I could understand  what was happening during my interaction with \nStArt Q13 I consider StArt useful to execute my \nsystematic review(s) Q8 It was easy for me to become skilful at using StArt \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nTable 3. Metrics used in the GQM \nMetric Description Metric Description \nM1 Number of people who chose \"designing the protocol\" M8 Number of people who chose “NO” \nM2 Number of people who chose “creation of search strings” M9 Number of people who chose “extremely agree” \nM3 \nNumber of people who chose “search for articles on search \nengines” M10 \nNumber of people who chose “quite agree” \nM4 \nNumber of people who chose “select items that will be read in \nfull” M11 \nNumber of people who chose “slightly agree’’ \nM5 \nNumber of people who chose “extract information from articles \nread in full” M12 \nNumber of people who chose “extremely \ndisagree’’ \nM6 \nNumber of people who chose “summarize the systematic \nreview’s results” M13 \nNumber of people who chose “quite disagree” \nM7 Number of people who chose “YES” M14 Number of people who chose “slightly disagree”\n \nTable 4. Model interpretation of the GQM \nNº Expression  Interpretation (next actions of the team) \n1 M1 > Mi , i= 2, 3, 4, 5 and 6 The activity of the greatest difficulty is designing the protocol \n2 M2 > Mi, i=1, 3, 4, 5 and 6 The activity of the greatest difficulty is  the creation of the search string  \n3 M3 > Mi, i = 1, 2, 4, 5 and 6 The most difficult activity is to search for articles on search engines \n4 M4 > Mi,  i= 1, 2, 3, 5 and 6 The most difficult  activity is to select items that will be read in full \n5 M5 > Mi, i= 1, 2, 3, 4 and 6 The most difficult activity is to extract information from articles read in full \n6 M6 > Mi, i= 1, 2, 3, 4 and 5 The most difficult activity is to summarise the results of the systematic review \n7 For Q2: M7 ≥ M8 Changes have occurred in how to conduct literature review after learning the process of \nsystematic review \n8 For Q3: M7 ≥ M8 Most of the students conducted another SLR after the course \n9 For Q4: M9 + M10 + M11 ≥  \nM12 + M13 + M14 SR is seen as a key resource for the quality of an academic research \n10 For Qi, i = 5 to 10: \nM9 ≥ M10 + M11 \nThe StArt is easy to use, and the next step is to conduct an experimental study with a new group \nof participants to test the result \n11 \nFor Qi,, i=5 to 10: \n M9 ≤ M10 + M11 and  \nM10 ≥ M11  \nThe StArt is easy to use; however, the next step is to analyse the data sent by participants \nthrough comments in order to identify improvements needed to facilitate the use of the \ntool. Once improvements are made, it could be carried out with a new group of participants \n12 \nFor Qi,, i=5 to 10: \nM9 ≤ M10 + M11 and  \nM11 ≥ M10 \nThe StArt does not have the ‘ease of use’ and so the next step is to study heuristics and usability \nstandards defined in the literature to perform a self-assessment on the tool’s interface; the \ncomments submitted by participants should be analysed and, based on that , the StArt project \nshould be reviewed and improvements implemented. The assessment should be conducted again \nwith the same group of participants to see if there was any improvement in the results \n13 For Qi,, i=11 to 13: \nM9 ≥ M10 + M11 \nthe StArt is useful to perform a systematic review, and the next step is to conduct an \nexperimental study to confirm the result \n14 \nFor Qi,, i=11 to 13: \nM9 ≤ M10 + M11 and \nM10 ≥ M11 \nThe StArt is useful, but analyse of the data sent by participants through comments must be done \nin order to identify improvements needed to make the tool useful. Once these improvements \nmade, the same assessment could be carried out with a new group of participants \n15 \nFor Qi,, i=11 to 13: \nM9 ≤ M10 + M11 and  \nM11 ≥ M10 \nThe StArt is not very useful, and therefore the team's next step is to review the design of the tool \nin order to identify whether there are features that can be implemented to provide greater utility \nto the StArt. The assessment should be conducted again with the same group of participants to \nsee if there was any improvement in the results \n16 \nFor Qi,, i= 5 to 10: \nM14 + M13 + M12 ≥ \nM9 + M10 + M11 \nThe implementation of new features in the StArt must be aborted, the comments submitted by \nparticipants should be analysed and the design of the tool must be fully reviewed by the team, \nespecially the user interface. Once the tool is modified, the same study should be conducted until \nthe participants judge the tool easy to use \n17 \nFor Qi,, i=11 to 13: \nM14 + M13 + M12 ≥ \nM9 + M10 + M11 \nThe implementation of new features in the StArt must be aborted, the comments submitted by \nparticipants should be analysed and the design of the tool must be fully reviewed by the team. \nOnce the tool is modified, the same study should be conducted until the participants judge the \ntool useful \n \n \n \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n 5.2. Data Collection  \nThe data were collected as follows: fi rstly, Questionnaire1 was sent by e- mail to the participants who, after \nanswered it, had access to two training videos about StAr t and had permission to download the tool. Hence, the \nstudents were asked to explore the tool as they have done manually during the course.  \nSecondly, the students who have finished Questionnaire1, received Questionnaire2 that was, sent by e-mail. By \nusing electronic questionnaires, at the end of the evaluation process all the an swers were available on spreadsheets, \nwhich facilitated the data collection. \nThe summary of the data collected is showed in the next tables and figures. Tables 5, 6 and 7 present the \nquestions and answers of the first questio nnaire and Figures 8, 9, 10 and 11 present charts that show the questions \nand the answers of the second one. In the charts, the order of the bars obeys the order of the questions. \n \nTable 5. Data collected in questionnaire 1 (question 1) \nQ1) Which activity required in the \nprocess of systematic review do \nyou judge as the hardest? \nProtocol \nfilling \nM1 \nCreation of \nsearch strings\nM2 \nSearch for \narticles on \nsearch engines\nM3\nSelection of \narticles that will \nbe fully read  \nM4\nExtract information / \ndata  from items read \ncompletely \nM5 \nSummarize the \nsystematic \nreview’s results \nM6\n1st Evaluation 6 5 1 0 2 0 \n2nd Evaluation 9 15 2 4 2 3 \n \nTable 6. Data collected in questionnaire 1 (questions 2 and 3) \nQ2) After knowing the process of systematic review, have you changed the way you perform literature review? Yes \nM7 \nNo \nM8 \n1st Evaluation 13 1 \n2nd Evaluation 32 3 \nQ3) Have you tried to reapply the process of systematic review after the course held in the second half of 2009?   \n1st Evaluation 6 8 \n2nd Evaluation 12 23 \n \nTable 7. Data collected in questionnaire 1 (question 4) \nQ4) What is your level of agreement with the statement: \"The \nsystematic review is critical to the quality of academic research\" \nExtremely \nagree \nM9\nQuite \nagree \nM10\nSlightly \nagree  \nM11\nSlightly \ndisagree \nM12 \nQuite \ndisagree \nM13\nExtremely \ndisagree \nM14\n1st Evaluation 7 3 4 0 0 0 \n2nd Evaluation 21 6 8 0 0 0 \n \n \nFigure 8. Questions and answers related to the ease of use – 1st Evaluation \n \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nFigure 9. Questions and answers related to the ease of use – 2nd Evaluation \n \n \nFigure 10. Questions and answers related to the usefulness – 1st Evaluation \n \n \nFigure 11. Questions and answers related to the usefulness – 2nd Evaluation \n \n 5.3 Interpretation \nApplying the interpretation model presented in Table 6 on the data collected and presented in the previous section, \nwe can assume the following about the goals: \n• G1: in relation to this goal, the results showed that in the first evaluation the protocol filling was selected as the \nmost difficult activity of the SLR process, since six partic ipants (42%) have selected this option (Table 1) and \nthis value makes the expression 1 true (Table 6). However, in the second evaluation the construction of search \nstrings was selected as the most difficult activity of th e SLR process, since fifteen participants (42%) have \nselected this option (Table 1) and this value makes the expression 2 true (Table 6). From now, we are planning \n \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nto address this issue in a deeper way, aiming to prov ide facilities that can help the researcher in doing these \nactivities. \n \n• G2: in relation to this goal, the results showed that the participants change their behaviour for conducting \nliterature review. Although most of the participants ha ve not tried to apply the SL R process after the course, \nthey consider the SLR a key for the quality of academic research. This conclusion is supported by the following \nexpressions (Table 6): \no expression 7: Q2: M7 ≥ M8, that is true for the evaluation 1 (13 ≥ 1) and for the evaluation 2 (32 ≥ 3), \naccording to the values of the Table 2; \no expression 8: Q3: M7 ≥ M8, that is false for the evaluations 1 (6 ≥ 8) and for the evaluation 2 (12 ≥ \n23), according to the values of the Table 2; \no expression 9: Q4:M9 + M10 + M11 ≥ M12 + M13 + M14, that is true for the evaluation 1 (7+3+4 ≥ \n0+0+0) and for the evaluation 2 (21+6+8 ≥ 0+0+0), according to the values of the Table 3. \n \n• G3: in relation to this goal, there ar e four expressions in the interpretation model (Table 6): 10, 11, 12 and 16. \nThe results showed that in both the evaluations, most of the participants agree with the ease of use of the StArt.  \nIn the evaluation 1 the answers of the participants were concentred in “quite agree” (Figure 8). Considering the \nanswers for questions 5 up to 10, the expression 11: Qi, i=5 to 10: M9 ≤ M10 + M11 and M10 ≥ M11 is true, \nsince 32 ≤ 34 + 12 and 34 ≥ 12. Hence, the next step should be the analysis of the comments submitted by the \nparticipants in order to identify improvements needed to  facilitate the use of the tool. Once the improvements \nare made, the evaluation could be carried out with a new group of participants. \nIn the evaluation 2 the answers of the participants were concentred in “extremely agree” (Figure 9). Considering \nthe answers for questions 5 up to 10, the expression 10: Qi, i = 5 to 10: M9 ≥ M10 + M11 is true, since 103 ≥ 70 \n+ 32. Therefore, the development team should conduct an  experimental study with a new group of participants \nto test the result of the evaluation 2. \n \n• G4: in relation to this goal, there ar e four expressions in the interpretation model (Table 6): 13, 14, 15 and 17. \nThe results showed that in both the ev aluations, the majority of the participants agree with the usefulness of the \nStArt (Figures 10 and 11).  \nConsidering the answers for questions 11 up to 13, the expression 13: Q\ni, i=11 to 13: M9 ≥ M10 + M11 is true, \nsince for the evaluation 1 (50 ≥ 17 + 2) and for the evaluation 2 (86 ≥ 16 + 3).  \nAccording to the interpretation model (Table 6) the next step is to conduct an experimental study to confirm this \nresult. \n \n 6 Final remarks and future work  \nThis paper presented the StArt tool that supports the con duction of the systematic literature review process [14] \nproviding facilities for minimizing this laborious process. It has been developed in an iterative and interactive way, \nwith constant feedback from users. For directing the next steps, an evaluation was carried out twice, aiming to \nexplore the support of the tool for conducting all the stag es of the SLR process. This evaluation involved students \nwho had already applied the SLR process manually. \nThe evaluation was planned using the GQM model and established four goals: two of them, related to the \naspects addressed by the Technology Acceptance Model (TAM) – ease of use and usefulness; one related to the \nidentification of the activity considered the most difficult among the SLR activities; and another one related to the \ninvestigation on user’s behaviour change in conducting literature review.  \nThe use of the TAM has turned the evaluation quick and objective, and disseminated the model among the \nparticipants. The use of the GQM led objectivity to the ev aluation and to the definition and elaboration of forms for \ndata collection. One of the limitations of the evaluation is the number of participants, which does not allow \ngeneralizing the results. \nAs our main objective was to explore the TAM aspects, in  relation to these issues, the evaluation indicated that \nthe StArt is useful, since 71.42% of the participants of  the evaluation 1and 81.90% of the participants of the \nevaluation 2 extremely agreed with the usefulness of the tool. For the ease of use, in the evaluation 1the answers \nwere concentrated on quite agree (45.23 %) and extremely agree (3 8.09%) and in the evalua tion 2 the answers were \nconcentrated on extremely agree (49.04%) and quite agree (33.33%). \nAccording to the GQM interpretation model, the actions that should be taken are: conducting an experimental \nstudy to confirm the results of this evaluation and analyse the qualitative data sent by the participants in order to \nidentify improvements needed to facilitate the use of the tool. In summary, the evaluation has provided evidence that \nthe tool will be accepted by users to support the conduction of SLRs. \nCLEI ELECTRONIC JOURNAL, VOLUME 15, NUMBER 1, PAPER 2, APRIL 2012 \n \nIn addition to the actions defined in the GQM interpre tation model, arose directly from the evaluation, some \nfunctionalities are already being implemented such as syst ematic mapping process support [15] and mechanisms of \ncommunication with other tools.  \nAcknowledgements \nThe authors thank the students who participated in the evaluation and CNPq, CAPES and Observatório da Educação \nProject for financial support. \nReferences \n[1] B. A. Kitchenham, T. Dyba, M. Jørgensen, “Evidence-based software engineering”, in Proc. International \nConference on Software Engineering (ICSE’04), Edinburgh, Scotland, May. 2004, pp. 273-281. \n[2] T. Dyba, B. A. Kitchenham, M. Jorgensen, “Evide nce-based software engineering for practitioners”, IEEE \nSoftware, vol. 22, pp. 58-65, Jan. Feb. 2005. \n[3] M. Jorgensen, T. Dyba, B. Kitchenham, “Teaching ev idence-based software engineering to university \nstudents”, in Proc: IEEE International Software Metrics Symposium (METRICS 2005), Como, Italy, Sep. 2005, pp. \n24. \n[4] B. Kitchenham, P. Brereton, D. Budgen, M. Turner, J. Bailey, S. G. Linkman, “Systematic literature reviews in \nsoftware engineering - a systematic literature review”: Information & Software Technology, vol. 51, pp. 7-15, Nov. \n2009. \n[5] B. A. Kitchenham, “ Procedures for Performing Systematic Reviews ”, Software Engineering Group , Keele \nUniversity, Keele, UK, Tech. Rep. TR/SE 0401, Jul. 2004. \n[6] J. Biolchini, P. G. Mian, A. C. C. Natali, G. H. Travassos, “ Systematic Review in Software Engineering ”, \nUFRJ, Rio de Janeiro, Brazil, Tech. Rep. RT–ES (679/05), May. 2005. \n[7] A. M. Fernández-Sáez, M. G. Bocco, F.P. Romero, “SLR-tool - a tool for performing systematic literature \nreviews”, in Proc: International Conference on Software and Data Technologies (ICSOFT’ 10) , Athens, Greece, \nJul. 2010, pp. 144. \n[8] V. R. Basili, S. Green, O. Laitenberger, F. Lanub ile, F. Shull, S. Sorumgard,M. Zelkowitz, “Packaging \nresearcher experience to assist rep lication of experiments”, in Proc. International Software Engineering Research \nNetwork Meeting (ISERN’96), Sydney, Australia, Aug. 1996, pp. 3-6. \n[9] F. D. Davis, “User acceptance of information techno logy: system characteristics, user perceptions and \nbehavioral impacts”, International Jounal of Man-Machine Studies, vol 38, pp. 475-487. Jan. 1993. \n[10] V. R. Basili, C. Caldiera, H.D. Rombach, “Goal Question Metric Paradigm” in Encyclopedia of Software \nEngineering, New York: John Wiley & Sons, 1994, pp. 528-532. \n[11] R. Soligen, E. Berghout, The Goal/Question/Metric Method: a practical guide for quality improvement of \nsoftware development. London, UK: McGraw W-Hill Companies, 1999. \n[12] O. Laitenberger, H. M. Dreyer, “Evaluating the Usef ulness and the Ease of Use of a Web-based Inspection \nData Collection Tool”, in Proc.: International Symposium on Software Metrics (METRICS’98) , Bethesda, \nUSA, March, 1998, pp. 122-135.  \n[13] J. P. McIver, E. G. Carmines, “Unidimensional Scaling”. London, UK: Sage Publications, 1981. \n[14] A. B. Zamboni, A. Di Thommazo, E. C. M. Hernandes, S. C. P. F. Fabbri, “StArt Uma Ferramenta \nComputacional de Apoio à Revisã o Sistemática”, in Proc.: Congresso Brasileiro de Software (CBSoft’10) , \nSalvador, Brazil, Sep. 2010.  \n[15] K. Petersen, R. Feldt, S. Mujtaba, M. Mattsson, “Systematic Mapping Studies in Software Engineering”, in \nProc.: Inter. Conf. on Evaluation and Assessment in Software Engineering (EASE’08) , Bari, Italy, Jun. 2008, \npp.26-27 \n \n \n \n "
}