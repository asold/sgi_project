{
  "title": "Cross-lingual Zero- and Few-shot Hate Speech Detection Utilising Frozen Transformer Language Models and AXEL",
  "url": "https://openalex.org/W3023443524",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4227176871",
      "name": "Stappen, Lukas",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Brunn, Fabian",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2282970931",
      "name": "Schuller, Bj√∂rn",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2908323419",
    "https://openalex.org/W1996235486",
    "https://openalex.org/W2954643340",
    "https://openalex.org/W2953553271",
    "https://openalex.org/W2914120296",
    "https://openalex.org/W2963986095",
    "https://openalex.org/W2890059736",
    "https://openalex.org/W2963790884",
    "https://openalex.org/W2921848006",
    "https://openalex.org/W3104723404",
    "https://openalex.org/W130670036",
    "https://openalex.org/W2950405925",
    "https://openalex.org/W2956147019",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2903251150",
    "https://openalex.org/W2557283755",
    "https://openalex.org/W2473555522",
    "https://openalex.org/W2953733770",
    "https://openalex.org/W2983149555",
    "https://openalex.org/W2953526793",
    "https://openalex.org/W2954333481",
    "https://openalex.org/W2891896107",
    "https://openalex.org/W2955042007",
    "https://openalex.org/W2939455697",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2893200234",
    "https://openalex.org/W2973089652",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2887782043",
    "https://openalex.org/W2563826943",
    "https://openalex.org/W3013497725",
    "https://openalex.org/W2905749056",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2955043905",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2969662548",
    "https://openalex.org/W2956090150",
    "https://openalex.org/W2781310980",
    "https://openalex.org/W2973727699",
    "https://openalex.org/W2741986357",
    "https://openalex.org/W2889256693",
    "https://openalex.org/W2884585870",
    "https://openalex.org/W2922580172",
    "https://openalex.org/W2866634454",
    "https://openalex.org/W2762484717",
    "https://openalex.org/W2915128308",
    "https://openalex.org/W2953597499",
    "https://openalex.org/W2963667932",
    "https://openalex.org/W2972740340"
  ],
  "abstract": "Detecting hate speech, especially in low-resource languages, is a non-trivial challenge. To tackle this, we developed a tailored architecture based on frozen, pre-trained Transformers to examine cross-lingual zero-shot and few-shot learning, in addition to uni-lingual learning, on the HatEval challenge data set. With our novel attention-based classification block AXEL, we demonstrate highly competitive results on the English and Spanish subsets. We also re-sample the English subset, enabling additional, meaningful comparisons in the future.",
  "full_text": "Cross-lingual Zero- and Few-shot Hate Speech Detection\nutilising frozen Transformer Language Models and AXEL\nLukas Stappen‚àó\nUniversity of Augsburg, GER\nstappen@ieee.org\nFabian Brunn‚àó\nTU Munich, GER\nfabian.brunn@tum.de\nBj¬®orn Schuller\nImperial College London, UK\nschuller@ieee.org\nAbstract\nDetecting hate speech, especially in low-\nresource languages, is a non-trivial challenge.\nTo tackle this, we developed a tailored architec-\nture based on frozen, pre-trained Transform-\ners to examine cross-lingual zero-shot and few-\nshot learning, in addition to uni-lingual learn-\ning, on the HatEval challenge data set. With\nour novel attention-based classiÔ¨Åcation block\nAXEL, we demonstrate highly competitive re-\nsults on the English and Spanish subsets. We\nalso re-sample the English subset, enabling\nadditional, meaningful comparisons in the fu-\nture.\n1 Introduction\nHate speech, discriminatory communication in-\ntended to insult and intimidate speciÔ¨Åc groups or\nindividuals due to their gender, race, sexual orien-\ntation or other characteristics has been a negative\nside effect of the growth of social media. Its ef-\nfects are not conÔ¨Åned to the virtual world; ofÔ¨Çine,\nit can result in criminal acts, including physical\nattacks (M¬®uller and Schwarz, 2018; Goolsby et al.,\n2013). In an extreme example, it has been heavily\nimplicated in inciting violence against Rohingya\nMuslims in Myanmar in 2017 (Stevenson, 2018;\nSubedar, 2018; Stecklow, 2018), which included\nthe murder of thousands of civilians and created\nclose to a million refugees (UN Human Rights\nCouncil, 2018).\nWith billions of text snippets posted daily on\nsocial media, detecting hate speech using human\nobservers is unfeasible, motivating researchers to\ndevelop natural language processing (NLP) meth-\nods to automate the task. Attempts by industry\nhave so far fallen short; according to Facebook,\ntheir detection algorithms failed in the lead-up to\nthe Rohingya crisis due to a lack of training data in\nBurmese (Murphy, 2019).\n‚àóequal contribution\nDetection approaches that work effectively with\nsmall or non-existent training data sets in the target\nlanguage, such as cross-lingual zero- and few-shot\nlearning, have not been discussed in the recent hate\nspeech literature. Goodfellow et al. (2016) deÔ¨Åned\nzero-shot learning as an extreme form of transfer\nlearning. Applying this concept to NLP, a model\ntrained on one language or domain learns to pre-\ndict samples from an unseen language using the\nlatent structures of a pre-trained language model\naligned across multiple languages. In cross-lingual\nfew-shot learning, a percentage of samples from\nthe target language is added to the training on the\nsource language, thus, strengthening cross-lingual\nand task-speciÔ¨Åc alignment (Schuster et al., 2019).\nCross-lingual approaches are expected to bridge\nthe deep learning performance gap between lan-\nguages that have large corpora available and low-\nresource languages (Adams et al., 2017) and have\nbeen named as a hot topic for the next ten years\nby Zhou et al. (2018). One possible reason for\nthe lack of application of these techniques to hate\nspeech is a lack of appropriate, publicly available\ndata sets. An additional problem is the varying\ndeÔ¨Ånition of hate speech used in different data\nsets, preventing the combined use of any given\nhigh-resource language corpus with any given low-\nresource corpus. Here, we use the data set from\nthe ACL 2019 Semantic Evaluation challenge (Se-\nmEval) Task 5 (Basile et al., 2019) that contains\nboth English (EN) and Spanish (ES) hate speech\ntweets, identiÔ¨Åed according to the same deÔ¨Ånition\nof hate speech targeting women and immigrants, to\ndevelop monolingual and cross-lingual models.\nAs hate speech detection is already very chal-\nlenging to model in an uni-language setting (MacA-\nvaney et al., 2019; Zhang and Luo, 2019; For-\ntuna and Nunes, 2018), most existing work in this\nand related Ô¨Åelds (Benballa et al., 2019; Aggar-\nwal et al., 2019; Zhou et al., 2019; Pelicon et al.,\narXiv:2004.13850v1  [cs.CL]  13 Apr 2020\nA PREPRINT - MARCH 10, 2020\n2019; Pavlopoulos et al., 2019; Wu et al., 2019;\nLiu et al., 2019) focuses on enhancing NLP state-\nof-the-art deep learning architectures, namely vari-\nations of Transformer Language Models (TLM),\nsuch as bidirectional encoder representations from\nTransformers (BERT) (Devlin et al., 2019) or cross-\nlingual language model pre-training (XLM) (Lam-\nple and Conneau, 2019). The majority of SemEval\nsubmissions that successfully detected and classi-\nÔ¨Åed offensive language on social media (Task 6)\nutilised BERT variations, Ô¨Åne-tuning them in an\nend-to-end fashion.\nIn this paper, we describe a novel approach for\nhate speech detection that uses frozen TLM archi-\ntectures to extract features ‚Äì the text representations\n‚Äì only from some of the TLM layers. By using\nTLMs purely as a feature extractor, we avoid the\ncomputation expensive, task-speciÔ¨Åc, Ô¨Åne-tuning\ntraining step, which adjusts up to 8.3 billion train-\nable parameters (Shoeybi et al., 2019). This strat-\negy is brieÔ¨Çy mentioned in the originalBERT paper\n(Devlin et al., 2019), but only Peters et al. (2019)\nhave carried out a broader evaluation. To the best\nof our knowledge, our approach is a novel idea both\nin the context of cross-lingual learning as well as\nfor hate speech detection with small data sets.\nFollowing the extraction of the representations,\nwe feed them into 12 different classiÔ¨Åcation blocks\nof varying complexity, which we install as trainable\nlayers on top of the feature extraction network. In-\nspired by the results and intuition of state-of-the-art\ncomputer vision attention blocks, we also step-wise\nderived and crafted a novel representation classiÔ¨Å-\ncation block, Attention-Maximum-Average Pool-\ning (AXEL), for this particular task.\nDuring our investigations, we noticed that good\nrecall performances often resulted in poor preci-\nsion and an unstable F1 for EN. We attribute this to\nan out-of-domain sampling and propose reshufÔ¨Çed\npartitions of the English data (EN-S). All exper-\niments were performed on both the original and\nproposed split. All associated code is openly avail-\nable1.\nOur contributions are as follows. Firstly, we\ndemonstrate that frozen TLMs can serve as pure\ndeep feature extractors for hate speech detection\nthat only need a fraction of trainable parameters\ncompared to the normal Ô¨Åne-tuning approach. Sec-\nondly, we propose a novel classiÔ¨Åcation block\nAXEL that enabled competitive results on uni-\n1Access on github.com/username/projectname\nlanguage and cross-lingual hate speech detection.\nThirdly, we demonstrated the efÔ¨Åciency of zero-\nand few-shot learning in this setting and, Ô¨Ånally,\nwe identify serious limitations in the generalisabil-\nity of models trained with the EN HatEval data and\npropose a new sampling.\n2 Network Architecture Components\nThe high-level structure of our architecture is de-\npicted in Figure 1. Initially, the network receives\nthe language tokens of the input text. This sequence\nis propagated forward through a frozen TLM archi-\ntecture (either BERT or XLM), extracting the deep\nlanguage features. In the next step, some or all of\nthe extracted representations are selected or fused\nfor further processing. For example, this can be\nthe last representation of the output layer for a pure\none dimensional classiÔ¨Åcation block or the entire\nsequence for a sequential compression. Next, these\nrepresentations are fed into a classiÔ¨Åcation block\nwhere the target is predicted.\nWe also replaced the frozen TLM by common\nword embeddings, such as, fastText (Grave et al.,\n2018), GloVe (Pennington et al., 2014) or fastText\naligned (Joulin et al., 2018) to encode the input\ntext. fastText showed better results than GloVe on\nTwitter hate speech data (van Aken et al., 2018).\nfastText aligned has multi-language capabilities.\nThe encoded representation was fed into a single\nor double recurrent neural network layer, e. g. , a\nLong short-term Memory Network (Hochreiter and\nSchmidhuber, 1997) or its bidirectional version\n(BiLSTM), which have previously proved more\neffective than Convolutional Neural Networks for\nhate speech detection (Rizos et al., 2019; van Aken\net al., 2018).\n2.1 Extracting Transformer Language Model\nFeatures\nWe do not perform a Ô¨Åne-tuning step, instead we\nuse the TLMs as a frozen language feature extrac-\ntor. For a general description of the Transformer\narchitecture we refer to Vaswani et al. (2017).\nBERT was the Ô¨Årst TLM to successfully train\ntext representations bidirectionally (Devlin et al.,\n2019). Since a Spanish version of BERT LARGE\nwas not available, we used the multilingual cased\nBERTBASE as one of our feature extractors. BERT\nis not explicitly cross-lingual pre-trained, whereas\nLample and Conneau (2019) aligned the language\nrepresentations in a two-step pre-training process\n2\nA PREPRINT - MARCH 10, 2020\n/0 /1 /2 /3 /4 \n/5 /6 /7 /5 /8 /8 /0 /1 /9 \n/10\n/10\n/11 /12\n/11 /13\n/11 /14\n/15 /12\n/15 /13\n/15 /14\n/15 /16 /11 /16\n/17 /18 /19 /1 /20 /21 /22 /18 /6 /5 /18 ‚ñ° \n/7 /24 /22 /25 /26 ‚ñ° /27 ‚ñ° /28 /29 \n/21 /5 /5 /8 /30 \n/21 /22 /18 /31 /19 /18 /8 \n/20 /22 /21 /4 /6 /19 /27 \n/32 /19 /4 /5 ‚ñ° /20 /2 /5 /5 /25 /32 \n/1 /22 ‚ñ° /32 /19 /4 /5 ‚ñ° /20 /2 /5 /5 /25 /32 \n/33 /5 \n/0 /20 \n/19\n/34 /10\n/35 /36 /37 /17 \n/6 /3 /24 /4 /0 /30 /32 /5 /19 /8 ‚ñ° /19 /4 /4 /5 /1 /4 /0 /22 /1 \n/21 /5 /5 /8 /30 /21 /22 /18 /31 /19 /18 /8 \n/38\n/22\n/22\n/24\n/0\n/1\n/9\n/39 /40 /41 /42 /43 /44 ‚ñ° /39 /43 /46 /47 /48 /40 /43 ‚ñ° /43 /49 /47 /40 /46 /50 /47 /41 /40 /51 /43 /52 /43 /50 /47 /53 /41 /44 /54 /39 /48 /51 /53 /41 /44 /50 /52 /46 /51 /51 /53 /39 /53 /50 /46 /47 /53 /41 /44 ‚ñ° /55 /52 /41 /50 /56 \n/43 /57 /58 /57 ‚ñ° /59 /43 /40 /47 /60 ‚ñ° /61 /62 /63 /43 /57 /58 /57 ‚ñ° /64 /51 /47 ‚ñ° /47 /41 /56 /43 /44 /60 ‚ñ° \n/65 /41 /41 /52 /53 /44 /58 ‚ñ° \n/43 /57 /58 /57 ‚ñ° /59 /53 /62 /66 /67 /63 /60 ‚ñ° /68 /49 /43 /52 \nFigure 1: ExempliÔ¨Åed illustration of the architecture (e. g. , BERT AvgPool). The frozen BERT model acts as a\nfeature extractor (brown frame). Next, a module selections one or many output representations e. g. , by pooling\nover the sequence (pink). The output of the selection is used as input for another representation enhancement\nmodule e. g. , a dense feed-forward layers (green).\nfor XLM. In the Ô¨Årst step, a masked language mod-\neling is trained unsupervised using byte pair to-\nkenised sub-words (Sennrich et al., 2015). In the\nsecond step, translation language modeling uses\nsentence pairs from different languages and feeds\nthem in parallel into the model.\n2.2 State-of-the-art Computer Vision\nClassiÔ¨Åcation Blocks and Derived AXEL\nOur novel classiÔ¨Åcation block was designed to efÔ¨Å-\nciently condense task-speciÔ¨Åc representations from\na sequence of context-speciÔ¨Åc, general text repre-\nsentations from a general TLM. To do this, we anal-\nysed the structure of recent state-of-the-art attention\nmodules, CAB (Zhang et al., 2018a), CBAM (Woo\net al., 2018), CSAR (Hu et al., 2019), and RAM\n(Kim et al., 2018) that can simultaneously com-\npress and enhance feature representations, e. g. , in\nimage super-resolution tasks. Most separate the\nattention block into spatial and channel attention\nlayers. They extract information across the Ô¨Ålter\ndimensions, then capture inter-dependencies in the\nfeature channels utilising a three-step squeeze, ex-\ncitation and scaling procedure (Kim et al., 2018).\nSince in our case the input data have one dimension\nless, speciÔ¨Åcally the RGB channels, we adapted the\nmodules for text representation compression. For\nthe spatial attention, we utilised a 1D convolution\noperation over the entire sequence length to com-\nbine all representations. For the channel attention,\nwe used pooling over the feature vector dimension\nto distill information from each individual sequence\nrepresentation.\nWe combine the most promising modules step-\nwise to create AXEL (cf. Figure 2). The context and\ntwo different channel attention modules enhance\nthe underlying XLM features. Sharing the weights\nbetween the two different channel attention mod-\nules results in more robust representations, while\nthe subsequent ReLU adds additional non-linearity.\nThe two resulting representations are then fused\nwith the output of a context attention module by\nstacking the three feature maps as synthetic Ô¨Ålter\nchannels. Next, a one-dimensional convolution\n(denoted 1x1) is used to deeply fuse the stacked\nÔ¨Ålters. Finally, a feed-forward layer with softmax\nactivation enabling hate speech prediction.\ninputembedding‚Ä¶‚Ñé‡¨¥‚Ñé‡¨µ‚Ñé‡¨∂ùë•‡¨¥ùë•‡¨µùë•‡¨∂ùë•‡Øç‚Ñé‡ØçTransformer block x 12\nfeed-forwardsoftmaxhate speechno hate speechHeisa.‚Ä¶XLMmulti-head attentionfeed-forwardùëé‡¨¥ùëé‡¨µùëé‡¨∂ùëé‡Øçattentionweightmeanmax‚Ä¶‚Ä¶‚Ä¶ReLU\n1x1shared\nFigure 2: The XLM1L AXEL classiÔ¨Åcation block com-\npresses and enhances XLM features. Similar to a chan-\nnel attention modules, a maximum and average pooling\non the XLM output is used, followed by a feed-forward\nlayer with shared weights and non-linear ReLU activa-\ntion. This is fused with a context attention module with\nstacked feature maps as synthetic Ô¨Ålter channels. The\nÔ¨Ålters are fused by a one-dimensional convolution (de-\nnoted 1x1).\n3\nA PREPRINT - MARCH 10, 2020\n3 Data\n3.1 HatEval Data Set\nWe evaluated the effectiveness of our proposed hate\nspeech detection models on the HatEval data set\nreleased as part of the SemEval task 5 (Basile et al.,\n2019; May et al., 2019) and focused on the Ô¨Årst sub-\ntask only. The data set deÔ¨Ånition aims at women\nand immigrants hate speech. Hate speech directed\nat other groups, e. g. , men was labelled as not hate-\nful (cf. Figure 3).\nThe dataset comprises around 13,000 EN tweets\nand 6,600 ES tweets. We performed a simple de-\nscriptive statistical analysis to verify there were no\nobvious set or label-related patterns in the data. The\ndata are slightly imbalanced; 42% were labelled as\nhate speech and 58% labelled as containing no hate\nspeech. A detailed analysis of the hate speech text\nproperties can be found in the appendix.\n3.2 Proposing New Partitioning of the\nEnglish HateEval\nAn analysis of the challenge baselines (Basile\net al., 2019), submissions, and our own initial\ntests demonstrated a large discrepancy in perfor-\nmance between EN and ES. The challenge submis-\nsions and baselines produced average F1 scores of\n44.84% and 68.21% with EN and ES respectively,\nwith no explanation provided in the subsequent ret-\nrospective account of the challenge (Basile et al.,\n2019). Consequently, we investigated EN more\nclosely and re-partitioned it before proceeding fur-\nther.\n3.2.1 Error Analysis of the English Sub-set:\nOut-of-Domain Sampling\nTo investigate the low performances obtained using\nEN, we trained a simple baseline model using fast-\nText embeddings and a BiLSTM. As expected, the\nmodel, considerably trained and tuned well on the\nvalidation partition, achieved on testing a low pre-\ncision of 43%, a high recall of 94%, and resulted\nHe is a snake ass bitch. He is a fugly slut who\nshouldn‚Äôt be trusted and I‚Äôm patiently waiting for\nhim to be 18 cuz https://t.co/NbezBfDPQ4\nTweetID 34138\nFigure 3: Example tweet declared as non-hateful but\nclearly hateful against men.\nin 1,564 false positives in 2,971 test samples.\nkey phrases train+val test\nbuild * wall 97% 35%\nMAGA 88% 29%\nillegal aliens 89% 33%\ntotal anti-immigration 92% 34%\ntotal anti-women 79% 46%\nTable 1: Occurrence of discriminate phrases, grouped\nas anti-immigration and anti-women (‚Äúbitch‚Äù), associ-\nated to hate speech on the training (train) and validation\n(val) partitions versus the test partition. The percentage\nis the hate speech ratio, the number of hate speech sam-\nples including a particular phrase divided by the total\nnumber of samples containing that phrase. ‚Äú*‚Äù denotes\nthat/the. MAGA = Make America great again.\nWhen we made spot checks of false positive\nsamples, certain repeatedly occurring signal words\nstood out. The phrases ‚Äúbitch‚Äù, ‚Äúbuild the [or that]\nwall‚Äù, ‚Äúmake America great again‚Äù and ‚Äúillegal\naliens‚Äù occurred at least once in 80% of false posi-\ntives in the test set. Table 1 compares context and\ncorresponding labels. While training and validation\nsets were very homogeneous, the test partition has\nvery different properties. We hypothesise that most\ndeep learning algorithms would learn these phrases\nas discriminative linguistic markers based on the\ntraining and validation set, which then appear in\nthe test set in a different context and cause the high\nnumber of false positives. In an example, Figure 4\nshows a pair of tweets containing the word ‚Äôbitch‚Äô;\none is from the training/validation set (left) and the\nother is from from the test partition (right).\nIn summary, we believe that out-of-domain sam-\npling of the EN test set hinders the development\nof sensible models that behave similar on all parti-\ntions and drawing of meaningful conclusions from\nqualitative analyses (e.g. model error analysis). We\nspeculate that the test set was not collected nor par-\ntitioned with the rest of the data and that different\ncriteria were applied, be they thematic or tempo-\nral, so that the domain of data distribution differs\nwidely.\n3.2.2 Proposed New English Partitions\nHaving identiÔ¨Åed a potential source of the devia-\ntions, we propose a simple approach to solve this\nissue. The goal of the new partitioning is an approx-\nimately equal distribution of data properties with\nthe previously speciÔ¨Åed key phrases taking into ac-\ncount the binary label for hate speech. This results\n4\nA PREPRINT - MARCH 10, 2020\nFeminism is cancer. #TheRedPill is\nchemo. Burn those bitches away.!\nTweetID 4881\nWomen empowering other women ‚Äì That shit\nis lit. Like yasss bitch, you are amazing, go you. We\ncan all shine TOGETHER\nTweetID 33195\nFigure 4: Typical examples including the keyword ‚Äúbitch‚Äù from training set (left) and test set (right).\nin three categories: no key phrases, one or more\nanti-immigration key phrases and anti-women key\nphrases (‚Äúbitch‚Äù) ‚Äì for hateful and not hateful data\npoints, leading to a total of six classes for partition\nstratiÔ¨Åcation. We merged all EN partitions, then\nequally re-distributed the tweets according to six\ncategories. In the end, the hate speech ratio was bal-\nanced enabling a fair and comprehensible learning\nof automated hate speech detection models ‚Äì com-\nparable to that of the Spanish subset. In general,\nsuch heavy effects of sampling indicates that the\namount of data is not enough to learn discrimina-\ntive, fully generalisable features for any ambiguous\ncontext.\n3.3 Preprocessing\nWe cleaned the tweets from the HatEval dataset\nto avoid biased training inÔ¨Çuences (Hassan et al.,\n2013), providing a description of our procedure\nin the appendix. The process markedly improved\nunique word coverage using fastText word embed-\ndings, from 44.06% to 82.41% for EN and from\n55.93% to 90.05% for ES words. In regard to the\nfull text coverage, we achieved 97.43% for the EN\nand 98.08% for ES tweets, demonstrating the effec-\ntiveness of our comprehensive procedure.\n4 Experiments\n4.1 Experiment settings\nThe models were implemented in Python 3.6 using\nPyTorch. Without Ô¨Åne-tuning, we could use a mod-\nerate hardware (NVIDIA Tesla K80). All models\nuse a cross-entropy loss function, Adam optimiser\nand early stopping. In addition, hyperparameters\nsettings (P) of the abbreviation are provided in the\nappendix. We trained the models on training parti-\ntions measuring accuracy, precision, recall, and F1,\nbut only report the latter for conciseness.\n4.2 Baselines\nThe challenge organisers provided two baselines\n(Basile et al., 2019), a Most-Frequent-ClassiÔ¨Åer\n(MFC, EN: 36.7, ES: 45.1 in % F1) and a Sup-\nport Vector Machine ( SVM) using tf-idf vectori-\nsation (SVM, EN: 45.1, ES: 70.1 in % F1). We\nhave created additional baselines (Table 2), as our\ndata pre-processing differs to Basile et al. (2019).\nAlso, we require a benchmark for our newly crafted\nEN-S partition. Finally, no deep learning baseline\nwas provided in the challenge and comparing the\nnew context to the conventional word embeddings\nseems relevant.\nTable 2: Performance comparison of our baselines,\nbased on a SVM similar to the original ( Base SVM),\nwith a slightly tuned C-value ( 3.5938), and a BiL-\nSTM with a feed-forward layer and 300 dimensional\nword embeddings, namely, GloVe (Base GV), fastText\n(Base FT) and fastText aligned ( Base FTA). We re-\nport the F1 in %.\nModel EN EN-S ES\nBase SVM 59.78 65.43 64.90\nBase GV 58.93 63.44 66.14\nBase FT 60.18 61.75 67.49\nBase FTA 58.08 58.19 63.63\nOn the EN-S data set, our Base SVM achieved\nstrong F1 scores with well balanced sub-metrics.\nWe speculate that the performance of the word em-\nbeddings may be directly related to the amount of\ntraining data used in the embedding training. This\nbehaviour is analogous to the results on the Span-\nish data set, where Base FT achieved the best\nresults. The F1 of the SVC baseline is above the\naverage result of the challenge participants (Basile\net al., 2019), and can, therefore, be considered\na strong entry-level baseline. Overall, we have\ntrained strong and robust baselines for both lan-\nguages and evaluated various word embeddings.\nBased on these results, we choose Base FT as our\nmain deep learning baseline.\n5\nA PREPRINT - MARCH 10, 2020\n4.3 Results\n4.3.1 Viability of Transformers as Deep\nFeature Extractors for Uni-Language\nHate Speech Detection\nBERT base We started with naive approaches\nutilising classiÔ¨Åcation blocks with no or few train-\nable parameters. Devlin et al. (2019) extracted\nthe Ô¨Årst token of the Ô¨Ånal BERT layer and fed\nthem into a softmax layer ( Bert1LT Dense).\nWe also examined if the most informative token\ncould be learnt by applying a global max-pooling\nlayer ( Bert1L MaxPool) over the temporal se-\nquence to limit the computational costs and mem-\nory footprint plus provides translation invariance.\nBert1L AvgPool with average pooling enabled\nus to evaluate if the the average representation is\ninformative. As evident in Table 3, all models per-\nform worse than our baseline, with the pooling\nsolutions performing better than the recommended\nÔ¨Årst token approach.\nWe utilised the entire sequence of BERT\nby feeding it into a double stacked BiLSTM\n(Bert1L 2LSTM) similar to Devlin et al. (2019),\nwhere the sequence outputs of the last four layers\nare extracted, concatenated across the layers, and\nfed into a two-layer BiLSTM (Bert4L 2LSTM).\nThe step-wise encoding of all the tokens by an\nLSTM increases the prediction performance con-\nsiderably, on the EN-S data set by more than 7%\n(Bert1L 2LSTM) and ES still marginally better\nthan our benchmark. The previous experiments\nused the Ô¨Ånal BERT layers. Thus, an entire for-\nward pass through the network was necessary. We\nevaluated the feasibility to extract only the Ô¨Årst\n(Bert1F). For the EN-S data set, both achieved re-\nsults above the benchmark and only slightly worse\nthan propagated till the Ô¨Ånal layer.\nXLM base XLM is designed to train cross-lingual\nTLMs and is the foundation for our zero- and few-\nshot approaches. We transferred the block design\none to one from BERT. Noticeable is the strong\nperformance of XLM1L Dense on all three sub-\nsets and the weak performance of XLM1L 2LSTM\n(cf. Table 3). This also stands in contrast to\nthe BERT model, where the sequential models\nwere clearly superior to the non-sequential models.\nGiven that sequential encoding does not add value\nto the use of XLM tokens, we also tried to learn\na weighted representation through an attention\nlayer XLM1L Att. However, the model showed\nTable 3: Performance of multiple models: Bert1L\nDense uses only the Ô¨Årst token and a dense\nlayer, Bert1L AvgPool uses average pooling, and\nBert1L MaxPool max pooling over the last BERT\nlayer. Bert1L 2LSTM uses one and Bert4L 2LSTM\nof the last BERT layer and feed them into an BiLSTMs,\nwhile Bert1F 1LSTM, or two Bert1F 2LSTM ex-\ntract the Ô¨Årst BERT layer. Analogous the XLM models.\nThe models are compared on the English (EN), English\nreshufÔ¨Çed (EN-S), and Spanish (ES) data set and all re-\nsults are reported in F1 %.\nModel P EN EN-S ES\nBase FT A 60.18 61.75 67.49\nBert1L Dense F 56.81 61.31 51.43\nBert1L MaxPool G 59.86 62.64 56.62\nBert1L AvgPool G 58.81 58.54 59.74\nBert1L 2LSTM D 60.55 69.04 65.23\nBert4L 2LSTM D 61.00 68.98 67.57\nBert1F 1LSTM F 59.37 67.75 64.85\nBert1F 2LSTM F 59.21 67.28 64.09\nXLM1L Dense G 60.89 67.73 64.75\nXLM1L 2LSTM H 60.20 59.27 62.37\nXLM1L Att G 61.61 67.56 62.33\ngreat performance on the EN set, but cannot beat\nXLM Dense on the EN-S and ES.\n4.3.2 Analysis of Advanced ClassiÔ¨Åcation\nBlock Designs: AXEL\nFor the development of the novel AXEL classiÔ¨Åca-\ntion block, we got inspired by the latest attention\ndevelopments in computer vision. Table 4 illus-\ntrates the performance of these blocks, whereby\nXLM RCAB performs best on the EN and ES. Look-\ning at the architectures in detail, it is the only one\nwhich does not utilise spatial attention. It can be\ndeduced that, spatial attention is not ideal for our\npurpose, while the for text adjusted channel atten-\ntion adds value to the representations. Furthermore,\nit is evident that the newly proposed AXEL clas-\nsiÔ¨Åcation block produced by far the best result,\nexceeding all other adapted blocks by at least 7%\nF1 on the EN-S and more than 2% for the ES. We\nprovide an ablation study of all AXEL components\nin the appendix.\n4.3.3 Cross-lingual learning\nZero-shot learning To evaluate zero-shot capa-\nbilities, the models are tuned on the training set\nof one language and evaluated in another. Table 5\n6\nA PREPRINT - MARCH 10, 2020\nTable 4: Comparison of XLM classiÔ¨Åcation blocks:\nRCAB (Zhang et al., 2018a), CBAM (Woo et al., 2018),\nCSAR (Hu et al., 2019), RAM (Kim et al., 2018), and\nour newly developed AXEL. All results are reported in\nF1 %.\nModel P EN EN-S ES\nXLM RCAB K 62.36 61.65 60.28\nXLM CBAM F 60.90 59.67 54.25\nXLM CSAR M 61.45 63.85 50.17\nXLM RAM M 60.30 60.67 55.21\nXLM1L AXEL F 62.03 71.16 69.70\nillustrates that XLM1L AXEL achieved the best re-\nsults except on the EN data set, whereXLM Dense\nperformed best but suffered one more time from\nhigh false positives. Overall, the models show gen-\neral learnability, however, lack generalisability and\nthe performance is much worse than in our mono-\nlingual experiments.\nTo probe if the causes of the performance loss\nare either on the data or the model side, we car-\nried out additional experiments. To rule out that\nthe different nature of the EN and ES training and\ntest partitions is the reason, we automatically trans-\nlated2 the test set into the language of the training\nset. The improved results in Table 5 indicate that\nthe partition composition is probably not the cause,\nleaving only the extracted latent representations,\nwhich seems either not perfectly aligned for our\ntask hate speech or across languages.\nTable 5: Zero-shot performance comparison of\nXLM base XLM Dense(G), XLM Att(G), and\nXLM1L AXEL (F) across languages and predictions\non the translated test set in F1 in %. This shows that\nthe latter outperforms other XLM based models as well\nas that the output latent structure for various languages\ndiffers. train ‚áítest; original ‚Üítranslation.\nDense Att AXEL\nEN‚áíES 41.31 34.37 53.42\nES‚áíEN 60.83 48.47 52.48\nES‚áíEN-S 49.38 39.10 53.24\nEN‚áí(ES‚ÜíEN) 60.59 62.40 64.39\nES‚áí(EN‚ÜíES) 56.89 49.17 58.31\nES‚áí(EN-S‚ÜíES) 56.57 49.17 65.04\n2https://aws.amazon.com/translate/\nFurthermore, we tried to learn models in similar\nfashion using fastText aligned embeddings com-\nbined with various blocks. Most classiÔ¨Åers gener-\nalised badly, resulting in unstable losses (see ap-\npendix for experiments).\nFew-shot learning The previous experiments\nhave shown that zero-shot learning works, but per-\nformed much poorer than the monolingual models.\nTherefore, we determined whether the extracted\nlatent structure can be stronger aligned or learnt\nby the classiÔ¨Åcation block, when we inject a few\npercent of the samples of the predictive language\ninto the training set.\n1 5 10 25 50 100\n0.5\n0.6\n0.7\nX% few-shot samples\nF1 %\nES + % EN‚àí ‚ÜíEN\nES + % EN-S‚àí ‚ÜíEN-S\nEN-S + % ES‚àí ‚ÜíES\nFigure 5: Few-shot performance in F1 of the\nXLM1L AXEL over percentage of added few-shot sam-\nples (detailed table in appendix). The zero-shot results\nare shown with a Ô¨Ålled circle. We added a certain per-\ncentage of the evaluation-language training set to the\nsource-language training set. 0% added equals the zero-\nshot training case. The results show that adding 1%\nsubstantially improved to zero-shot.\nFigure 5 shows that injecting only 1% of the\ndata led to a boost in performance of almost 5%\nF1. Subsequently, the training continues mostly\nas expected, improving incrementally with more\ndata. The Ô¨Ånal result for the EN-S exceeded even\nthe monolingual experiments, which we attribute to\ndata augmentation by the additional injected data.\nIn order to verify this idea, we additionally exper-\nimented with augmentation techniques, such as,\ntranslation chains, but were unsuccessful in demon-\nstrating an overarching and clearly positive effect.\nThe original EN shows an atypical behaviour, and\napparently barely improving over time due to the\nout-of-domain sampling issue (cf. section 3.2.1).\nIn order to verify that the network has actually\nlearnt cross-lingually and not only from the few in-\njected samples, the same experiments were carried\nout using exclusively the few-shot samples, thus,\nexcluding the full training-language. These clearly\nshow that the model makes use of cross-lingual\n7\nA PREPRINT - MARCH 10, 2020\nstructures. For example, at 10% few-shot train-\ning samples, we obtained results of only 58.10%\n(EN), 59.06% (EN-S), and 58.66% (ES) F1, which\nare clearly lagging behind the few-shot results for\nEN-S and ES.\n4.4 Discussion\nOne central motivation of our work was to access\nand improve cross-lingual learning, especially for\nlow-resource languages. While the models using\ncross-lingual zero-shot learning produced mixed\nresults, the beneÔ¨Åts of few-shot learning based on\nextracted features are evident. Unfortunately, we\nwere unable to use a genuinely low-resource lan-\nguage because of the limited availability of multi-\nlingual hate speech corpora using the same deÔ¨Åni-\ntion with one being of a rare language. However,\nusing our artiÔ¨Åcially reduced high-resource data\nsets, a parallel training, even with very few data\nsets, resulted in a stronger alignment of XLM repre-\nsentations.\nReducing computation during task-speciÔ¨Åc Ô¨Åne-\ntuning was another important motivator in this\nwork. When we compare the architectures pre-\nsented here with the Ô¨Åne-tuning approach, the\nBert4L 2LSTM classiÔ¨Åcation block has less than\n2M trainable parameters, while XLM AXEL has\nonly around 1M. At the same time, we have to train\n177M parameters for BERT, and 249M parame-\nters for XLM to train these networks end-to-end.\nThis insight is valuable for academia or industry\nwhere less resources are available. This is of less\nsigniÔ¨Åcance in terms of the inference time due to\nthe highly efÔ¨Åcient architecture of Transformers\n(Peters et al., 2018).\nHowever, while far less parameters are used, we\ndemonstrated that our novel AXEL classiÔ¨Åcation\nblock on frozen TLM could still easily beat our\nstrong baselines. When ranked alongside the Hat-\nEval 2019 results, our approach ranked second on\nEN and is close to the third quartile (71.65% F1)\non ES.\n5 Related Work\nIn the original paper, Devlin et al. (2019) included\nlittle information about using extracted BERT fea-\ntures for named-entity recognition. More extensive\nresearch was carried out by Peters et al. (2019),\nevaluating both Ô¨Åne-tuned features as well as fea-\ntures from the general language model on a wider\nrange of tasks. Predicting sentiment on movie re-\nviews is the closest task to hate speech detection,\nshowing that there is a slight trade-off between\nperformance and computation cost for Ô¨Åne-tuning.\nBesides these works, there appears to be no other re-\nsearch conducted on small data sets or hate speech\ndata utilising TLMs as pure feature extractors, mak-\ning it an interesting area to investigate.\nAs interest in the research community in hate\nspeech detection has grown; the number of pub-\nlicly available data sets has also increased. Waseem\n(2016) created and extended (Waseem and Hovy,\n2016) an English hate speech data set based on\ntweets. Davidson et al. (2017) also focused on\noffensive language on twitter, while de Gibert\net al. (2019) crawled the white supremacist website\nStormfront. There are multiple data sets available\nin languages other than English including Italian\n(Bosco et al., 2018), Portuguese (Fortuna et al.,\n2019), and Indonesian (Ibrohim and Budi, 2019).\nHowever, only (Basile et al., 2019) provides a cor-\npus in two languages (English and Spanish) using\nthe same deÔ¨Ånition of hate speech, enabling us to\ntackle this topic from a multilingual perspective.\nRecent detailed comparisons of traditional and\ndeep learning approaches (Kshirsagar et al., 2018;\nRobinson et al., 2018; van Aken et al., 2018; Lee\net al., 2018; Zhang et al., 2018b) have demonstrated\nsuperior performances by the later in hate speech\ndetection. Transformers became especially popu-\nlar for deeply modelling language, resulting in the\nquick and wide adoption of networks such asBERT\n(Devlin et al., 2019) and XLM (Lample and Con-\nneau, 2019). In Task 5 of SemEval-2019 for hate\nspeech detection, the second-placed submission in\nthe Spanish challenge (Gertner et al., 2019) used a\nÔ¨Åne-tuned BERT by adding additional tweets to the\ncorpus. Also in the closely related Task 6, in which\noffensive language was detected (Zampieri et al.,\n2019), six out of the top ten top submissions used\nBERT. It is noteworthy that all the published partici-\npants in these two challenge tasks who used a TLM\narchitecture Ô¨Åne-tuned their architectures (Zhang\nand Luo, 2018; Gertner et al., 2019; Benballa et al.,\n2019; Siddiqua et al., 2019; Aggarwal et al., 2019;\nZhou et al., 2019; Zhu et al., 2019; Nikolov and\nRadivchev, 2019; Pelicon et al., 2019).\nAn extensive survey of cross-lingually word\nembeddings can be found in Ruder et al. (2017).\nGrave et al. (2018) and Conneau et al. (2017) cross-\nlingual pretrained embeddings are widely used,\nlikely because they are freely available. Artetxe and\n8\nA PREPRINT - MARCH 10, 2020\nSchwenk (2018) suggested zero-shot, cross-lingual\nsentence embeddings, which showed a strong per-\nformance on some language combinations and par-\ntially competed with BERT. Wu and Dredze (2019)\nattempted to adjust the Transformer for BERT for\ncross-lingual tasks, but XLM performed superiorly.\n6 Conclusion\nThe detection of hate speech on social media plat-\nforms is vital to prevent the incitement of violence.\nA particular challenge is the development of reli-\nable, automatic detection systems, where there is a\nlack of task-speciÔ¨Åc, low-resource language data.\nThe aim of this work was to evaluate TLMs\nas deep feature extractors for this task. First, we\nbuilt strong baselines and assessed various classi-\nÔ¨Åcation blocks for the detection of uni-language\nhate speech. The performance of the TLM-based\nmodels greatly surpasses that of those based on\nconventional word embeddings and demonstrated\npromising results compared to the submissions of\nchallenge participants. On the EN, for example,\nthey ranked second. Second, the poor generaliza-\ntion behaviour we observed on the EN partitions\ncould be attributed to out-of-domain sampling and\nmotivated our proposal of a newly stratiÔ¨Åed data\nsplit. We accompanied this with a Ô¨Årst benchmark\nof EN-S partitions that we hope others will build\nupon, enabling sensible comparisons in the future.\nFinally, from our investigation of potential block\ndesigns, our results indicate two different strategies\nare required to successfully useBERT and XLM rep-\nresentations. While BERT efÔ¨Åciently utilised the\nentire sequence of representations, XLM worked\nbetter using only the Ô¨Årst token. This motivated\nAXEL, which is, derived from state-of-the-art com-\nputer vision modules, designed to extract a wide\nrange of stable features out of one compressed rep-\nresentation. We artiÔ¨Åcially simulated low language\nresources to demonstrate the cross-lingual capabil-\nities of our AXEL module that outperformed our\nbaselines by far and gave valuable insights for fu-\nture research in this Ô¨Åeld.\nInvestigations of the representational differences\nfrom an architectural and training perspective (Why\nare XLM representations less effective for sequen-\ntial blocks?) as well as general AXEL capabilities\nare interesting future research directions.\nReferences\nOliver Adams, Adam Makarucha, Graham Neubig,\nSteven Bird, and Trevor Cohn. 2017. Cross-lingual\nword embeddings for low-resource language model-\ning. In Proceedings of the 15th Conference of the\nEuropean Chapter of the Association for Computa-\ntional Linguistics: Volume 1, Long Papers, pages\n937‚Äì947, Valencia. ACL.\nPiush Aggarwal, Tobias Horsmann, Michael Wojatzki,\nand Torsten Zesch. 2019. Ltl-ude at semeval-2019\ntask 6: Bert and two-vote classiÔ¨Åcation for categoriz-\ning offensiveness. In Proceedings of the 13th Inter-\nnational Workshop on Semantic Evaluation, pages\n678‚Äì682, Minneapolis. ACL.\nBetty van Aken, Julian Risch, Ralf Krestel, and Alexan-\nder L¬®oser. 2018. Challenges for toxic comment clas-\nsiÔ¨Åcation: An in-depth error analysis. arXiv preprint\narXiv:1809.07572.\nMikel Artetxe and Holger Schwenk. 2018. Mas-\nsively multilingual sentence embeddings for zero-\nshot cross-lingual transfer and beyond. arXiv\npreprint arXiv:1812.10464.\nValerio Basile, Cristina Bosco, Elisabetta Fersini,\nDebora Nozza, Viviana Patti, Francisco Manuel\nRangel Pardo, Paolo Rosso, and Manuela San-\nguinetti. 2019. SemEval-2019 task 5: Multilin-\ngual detection of hate speech against immigrants and\nwomen in twitter. In Proceedings of the 13th Inter-\nnational Workshop on Semantic Evaluation, pages\n54‚Äì63, Minneapolis. ACL.\nMiriam Benballa, Sebastien Collet, and Romain Picot-\nClemente. 2019. Saagie at Semeval-2019 Task 5:\nFrom Universal Text Embeddings and Classical Fea-\ntures to Domain-speciÔ¨Åc Text ClassiÔ¨Åcation. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation, pages 469‚Äì475, Minneapolis.\nACL.\nCristina Bosco, Manuela Sanguinetti, Felice\nDell‚ÄôOrletta, Fabio Poletto, and Maurizio Tesconi.\n2018. Overview of the EV ALITA 2018 Hate Speech\nDetection Task. In Proceedings of the Sixth Evalua-\ntion Campaign of Natural Language processing and\nSpeech Tools for Italian, volume 2263, Turin. ACL.\nAlexis Conneau, Guillaume Lample, Marc‚ÄôAurelio\nRanzato, Ludovic Denoyer, and Herv ¬¥e J¬¥egou. 2017.\nWord translation without parallel data. arXiv\npreprint arXiv:1710.04087.\nThomas Davidson, Dana Warmsley, Michael Macy,\nand Ingmar Weber. 2017. Automated hate speech\ndetection and the problem of offensive language.\nIn Proceedings of the Eleventh International AAAI\nConference on Web and Social Media (ICWSM\n2017), pages 512‚Äì515.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\n9\nA PREPRINT - MARCH 10, 2020\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171‚Äì4186, Minneapolis. ACL.\nPaula Fortuna and S¬¥ergio Nunes. 2018. A survey on au-\ntomatic detection of hate speech in text. ACM Com-\nputing Surveys (CSUR), 51(4):85.\nPaula Fortuna, Jo Àúao Rocha da Silva, Leo Wanner,\nS¬¥ergio Nunes, et al. 2019. A hierarchically-labeled\nportuguese hate speech dataset. In Proceedings of\nthe Third Workshop on Abusive Language Online,\npages 94‚Äì104.\nAbigail Gertner, John Henderson, Elizabeth Merkhofer,\nAmy Marsh, Ben Wellner, and Guido Zarrella. 2019.\nMITRE at SemEval-2019 Task 5: Transfer Learning\nfor Multilingual Hate Speech Detection. In Proceed-\nings of the 13th International Workshop on Semantic\nEvaluation, pages 453‚Äì459, Minneapolis. ACL.\nOna de Gibert, Naiara Perez, Aitor Garc¬¥ƒ±a-Pablos, and\nMontse Cuadros. 2019. Hate Speech Dataset from a\nWhite Supremacy Forum. In Proceedings of the Sec-\nond Workshop on Abusive Language Online (ALW2),\npages 11‚Äì20, Brussels. ACL.\nIan Goodfellow, Yoshua Bengio, and Aaron Courville.\n2016. Deep Learning. MIT Press.\nRebecca Goolsby, Lea Shanley, and Aaron Lovell.\n2013. On cybersecurity, crowdsourcing, and social\ncyber-attack. Technical report, OfÔ¨Åce of Naval Re-\nsearch, Arlington.\nEdouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-\nmand Joulin, and Tomas Mikolov. 2018. Learning\nword vectors for 157 languages. In Proceedings\nof the International Conference on Language Re-\nsources and Evaluation (LREC 2018).\nAmmar Hassan, Ahmed Abbasi, and Daniel Zeng.\n2013. Twitter Sentiment Analysis. In Proceedings -\nSocialCom 2013, pages 357‚Äì364. IEEE.\nSepp Hochreiter and J ¬®urgen Schmidhuber. 1997.\nLong short-term memory. Neural computation,\n9(8):1735‚Äì1780.\nYanting Hu, Jie Li, Yuanfei Huang, and Xinbo Gao.\n2019. Channel-wise and Spatial Feature Modulation\nNetwork for Single Image Super-resolution. IEEE\nTransactions on Circuits and Systems for Video Tech-\nnology.\nMuhammad Okky Ibrohim and Indra Budi. 2019.\nMulti-label hate speech and abusive language detec-\ntion in indonesian twitter. In Proceedings of the\nThird Workshop on Abusive Language Online, pages\n46‚Äì57.\nArmand Joulin, Piotr Bojanowski, Tomas Mikolov,\nHerv¬¥e J ¬¥egou, and Edouard Grave. 2018. Loss in\ntranslation: Learning bilingual word mapping with a\nretrieval criterion. In Proceedings of the 2018 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 2979‚Äì2984.\nJun-Hyuk Kim, Jun-Ho Choi, Manri Cheon, and Jong-\nSeok Lee. 2018. Ram: Residual attention module\nfor single image super-resolution. arXiv preprint\narXiv:1811.12043.\nRohan Kshirsagar, Tyus Cukuvac, Kathleen McKeown,\nand Susan McGregor. 2018. Predictive embeddings\nfor hate speech detection on twitter. arXiv preprint\narXiv:1809.10644.\nGuillaume Lample and Alexis Conneau. 2019. Cross-\nlingual language model pretraining. arXiv preprint\narXiv:1901.07291.\nYounghun Lee, Seunghyun Yoon, and Kyomin Jung.\n2018. Comparative studies of detecting abusive lan-\nguage on twitter. arXiv preprint arXiv:1808.10245.\nPing Liu, Wen Li, and Liang Zou. 2019. NULI at\nSemEval-2019 Task 6: Transfer Learning for Offen-\nsive Language Detection using Bidirectional Trans-\nformers. In Proceedings of the 13th International\nWorkshop on Semantic Evaluation, pages 87‚Äì91,\nMinneapolis. ACL.\nSean MacAvaney, Hao-Ren Yao, Eugene Yang, Katina\nRussell, Nazli Goharian, and Ophir Frieder. 2019.\nHate speech detection: Challenges and solutions.\nPloS one, 14(8).\nJonathan May, Ekaterina Shutova, Marianna Apidi-\nanaki, and Saif Mohammad, editors. 2019. The In-\nternational Workshop on Semantic Evaluation Pro-\nceedings of the Thirteenth Workshop. ACL. ACL,\nMinneapolis.\nKarsten M ¬®uller and Carlo Schwarz. 2018. Fanning\nthe Flames of Hate: Social Media and Hate Crime.\nSSRN Electronic Journal, 3082972.\nHannah Murphy. 2019. Can facebook really rely on\nartiÔ¨Åcial intelligence to spot abuse?\nAlex Nikolov and Victor Radivchev. 2019. Nikolov-\nRadivchev at SemEval-2019 Task 6: Offensive\nTweet ClassiÔ¨Åcation with BERT and Ensembles. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation, pages 691‚Äì695, Minneapolis.\nACL.\nJohn Pavlopoulos, Nithum Thain, Lucas Dixon, and\nIon Androutsopoulos. 2019. ConvAI at SemEval-\n2019 Task 6: Offensive Language IdentiÔ¨Åcation\nand Categorization with Perspective and BERT. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation, pages 571‚Äì576, Minneapolis.\nACL.\n10\nA PREPRINT - MARCH 10, 2020\nAndraÀáz Pelicon, Matej Martinc, and Petra Kralj Novak.\n2019. Embeddia at SemEval-2019 Task 6: Detect-\ning Hate with Neural Network and Transfer Learn-\ning Approaches. In Proceedings of the 13th Inter-\nnational Workshop on Semantic Evaluation, pages\n604‚Äì610, Minneapolis. ACL.\nJeffrey Pennington, Richard Socher, and Christopher D.\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 Conference\non Empirical Methods in Natural Language Process-\ning.\nMatthew Peters, Sebastian Ruder, and Noah A. Smith.\n2019. To tune or not to tune? adapting pretrained\nrepresentations to diverse tasks. arXiv preprint\narXiv:1903.05987.\nMatthew E Peters, Mark Neumann, Luke Zettlemoyer,\nand Wen-tau Yih. 2018. Dissecting contextual word\nembeddings: Architecture and representation. arXiv\npreprint arXiv:1808.08949.\nGeorgios Rizos, Konstantin Hemker, and Bj ¬®orn\nSchuller. 2019. Augment to prevent: Short-text data\naugmentation in deep learning for hate-speech clas-\nsiÔ¨Åcation. In Proceedings of the 28th ACM Inter-\nnational Conference on Information and Knowledge\nManagement, pages 991‚Äì1000. ACM.\nDavid Robinson, Ziqi Zhang, and Jonathan Tepper.\n2018. Hate speech detection on twitter: Feature en-\ngineering vs feature selection. In European Seman-\ntic Web Conference, pages 46‚Äì49. Springer.\nSebastian Ruder, Ivan Vuli ¬¥c, and Anders S√∏gaard.\n2017. A survey of cross-lingual word embedding\nmodels. arXiv preprint arXiv:1706.04902.\nTal Schuster, Ori Ram, Regina Barzilay, and Amir\nGloberson. 2019. Cross-lingual alignment of con-\ntextual word embeddings, with applications to zero-\nshot dependency parsing. In Proceedings of the\n2019 Conference of the NAACL: Human Language\nTechnologies, Volume 1 (Long and Short Papers),\npages 1599‚Äì1613.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2015. Neural machine translation of rare words with\nsubword units. arXiv preprint arXiv:1508.07909.\nMohammad Shoeybi, Mostofa Patwary, Raul Puri,\nPatrick LeGresley, Jared Casper, and Bryan Catan-\nzaro. 2019. Megatron-lm: Training multi-billion\nparameter language models using gpu model paral-\nlelism. arXiv preprint arXiv:1909.08053.\nUmme Aymun Siddiqua, Abu Nowshed Chy, and\nMasaki Aono. 2019. KDEHatEval at SemEval-2019\nTask 5: A Neural Network Model for Detecting Hate\nSpeech in Twitter. In Proceedings of the 13th Inter-\nnational Workshop on Semantic Evaluation, pages\n365‚Äì370, Minneapolis. ACL.\nSteve Stecklow. 2018. Why facebook is losing the war\non hate speech in myanmar.\nAlexandra Stevenson. 2018. Facebook admits it was\nused to incite violence in myanmar.\nAnisa Subedar. 2018. The country where facebook\nposts whipped up hate.\nUN Human Rights Council. 2018. Report of the inde-\npendent international fact-Ô¨Ånding mission on Myan-\nmar. Technical Report A/HRC/39/64, United Na-\ntions, Geneva.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems, pages 5998‚Äì6008.\nZeerak Waseem. 2016. Are You a Racist or Am I See-\ning Things? Annotator InÔ¨Çuence on Hate Speech\nDetection on Twitter. In Proceedings of 2016\nEMNLP Workshop on Natural Language Processing\nand Computational Social Science, pages 138‚Äì142,\nAustin,. ACL.\nZeerak Waseem and Dirk Hovy. 2016. Hateful Sym-\nbols or Hateful People? Predictive Features for Hate\nSpeech Detection on Twitter. In Proceedings of\nNAACL-HLT, pages 88‚Äì93, San Diego. ACL.\nSanghyun Woo, Jongchan Park, Joon-Young Lee, and\nIn So Kweon. 2018. CBAM: Convolutional Block\nAttention Module. In Proceedings of the European\nConference on Computer Vision (ECCV), pages 3‚Äì\n19.\nShijie Wu and Mark Dredze. 2019. Beto, bentz, be-\ncas: The surprising cross-lingual effectiveness of\nbert. arXiv preprint arXiv:1904.09077.\nZhenghao Wu, Hao Zheng, Jianming Wang, Weifeng\nSu, and Jefferson Fong. 2019. BNU-HKBU UIC\nNLP Team 2 at SemEval-2019 Task 6: Detecting Of-\nfensive Language Using BERT model. In Proceed-\nings of the 13th International Workshop on Semantic\nEvaluation, pages 551‚Äì555, Minneapolis. ACL.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019. Semeval-2019 task 6: Identifying and catego-\nrizing offensive language in social media (offense-\nval). In Proceedings of the 13th International Work-\nshop on Semantic Evaluation, pages 75‚Äì86. ACL.\nYulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bi-\nneng Zhong, and Yun Fu. 2018a. Image Super-\nResolution Using Very Deep Residual Channel At-\ntention Networks. In Proceedings of the European\nConference on Computer Vision (ECCV), pages 286‚Äì\n301.\nZiqi Zhang and Lei Luo. 2018. Hate speech detection:\nA solved problem? the challenging case of long tail\non twitter. Semantic Web, pages 1‚Äì21.\nZiqi Zhang and Lei Luo. 2019. Hate speech detection:\nA solved problem? the challenging case of long tail\non twitter. Semantic Web, 10(5):925‚Äì945.\n11\nA PREPRINT - MARCH 10, 2020\nZiqi Zhang, David Robinson, and Jonathan Tepper.\n2018b. Detecting hate speech on twitter using a\nconvolution-gru based deep neural network. In Eu-\nropean Semantic Web Conference, pages 745‚Äì760.\nSpringer.\nChengjin Zhou, Jin Wang, and Xuejie Zhang. 2019.\nYNU-HPCC at SemEval-2019 Task 6: Identifying\nand Categorising Offensive Language on Twitter. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation, pages 812‚Äì817, Minneapolis.\nACL.\nMing Zhou, Nan Duan, Furu Wei, Shujie Liu, and\nDongdong Zhang. 2018. The next 10 years look\ngolden for natural language ...\nJian Zhu, Zuoyu Tian, and Sandra K ¬®ubler. 2019. UM-\nIU@LING at SemEval-2019 Task 6: Identifying Of-\nfensive Tweets Using BERT and SVMs. InProceed-\nings of the 13th International Workshop on Semantic\nEvaluation, pages 784‚Äì790, Minneapolis. ACL.\nAppendices to accompany ‚ÄùCross-lingual Zero-\nand Few-shot Hate Speech Detection utilis-\ning frozen Transformer Language Models and\nAXEL ‚Äù\nA Data set\nA.1 Data Analysis of Hate Speech Language\nProperties.\nIn the Spanish corpus, we identiÔ¨Åed two overly\nlong tweets (450 and 197 words) that contained\nobviously multiple, concatenated tweets. We re-\nmoved these outliers. Also the tweets length seem\nto be quite homogeneous between the sets: labels\nand languages with around 22 words ( ¬±11) and\napproximately 140 chars (¬±70) in EN as well as\nroughly 21 words (¬±14) and almost 129 chars (¬±\n86) in ES. We also compared the usage of all caps\nwords indicating emphasization or screaming and\nspecial characters (!, ?, #, ., @), both possible iden-\ntiÔ¨Åers for hate speech. In the EN tweets, there is\non average an almost 30% increase in the usage of\nblock capital written words in a hate speech tweet\n(1.07 ¬±2.56 vs 1.39 ¬±3.29) while in Spanish this\ndifference is insigniÔ¨Åcant (1.30 ¬±4.19 vs 1.39 ¬±\n4.68). In terms of the special characters, hateful\nEN tweets use exclamation marks nearly double\nas often than non-hateful tweets, also the usage\nof hashtags is slightly increased (0.92 vs 1.29 per\ntweet). Interestingly, this is contrary to the Spanish\ntweets, where the usage of hashtags is halved with\n0.24 hashtags for non-hateful and 0.13 for hateful\ntweets, indicating cultural differences in the usage\nof hashtags. For all others properties we could not\nÔ¨Ånd clear differences.\nA.2 Data Cleaning Procedure.\nWe eliminated all mentions (‚Äú@‚Äù) since we ex-\npect that the mentioned usernames could be asso-\nciated more closely to one of the classes. Simi-\nlar hyperlinks might be biased or, in the case of\nshortened ones have no predictive value at all, and,\nthus, are also excluded. Apostrophes, for exam-\nple, ‚ÄúTrump‚Äôs wife‚Äù indicating genitives ‚Äú‚Äôs‚Äù are\ncompletely removed, in singular form, this also\nincluded the latter.\nThe informal style of tweets makes it neces-\nsary to replace contractions by the full words\n(‚Äúyou‚Äôre‚Äù‚Üí‚Äúyou are‚Äù). Besides a few simple trans-\nformations, for instance, standardising special char-\nacters (e. g. , ‚Äú‚Äì‚Äù (en-dash) or ‚Äú‚Äî‚Äù (em-dash) ‚Üí\n‚Äú-‚Äù (hyphen), and numbers (‚Äù2nd‚Äù‚Üísecond) also\nmore complex ones were necessary. To reduce neg-\n12\nA PREPRINT - MARCH 10, 2020\native effects of colloquial word useage, we, Ô¨Årst,\ntransformed speciÔ¨Åc, rare but decisive words and\nabbreviations, such as, ‚ÄúMAGA‚Äù‚Üí‚Äúmake Amer-\nica great again‚Äù or ‚ÄúObamacare‚Äù‚Üí‚ÄúObama health-\ncare system‚Äù. Second, concatenated words and\nhash tags with capitalised letters (camel case) were\nseparated to its unique words. Finally, we used the\nPython library emoji3 to replace smileys by text.\nB Hyperparameter Abbreviation Table\nTable 6 shows the non-static hyperparameters and\nvalues for each hyperparameter abbreviation (P).\nTable 6: List of hyperparameter (P) combinations used.\nP learning\nrate\nbatch\nsize\nRNN\nfeature size\nRNN\ndropout\nA 0.001 32 128 0.0\nB 0.001 32 128 0.2\nC 0.0005 16 128 0.2\nD 0.00005 64 128 0.0\nE 0.00005 64 ‚Äì ‚Äì\nF 0.0005 64 ‚Äì ‚Äì\nG 0.00001 64 ‚Äì ‚Äì\nH 0.0005 32 64 0.2\nI 0.0005 32 128 0.2\nJ 0.0005 64 128 0.2\nK 0.00005 32 ‚Äì ‚Äì\nL 0.00005 32 128 0.0\nC Additional Results Including\nAccuracy, Precision, Recall, and F1\nC.1 Baselines.\nThe performance of the baselines including all\nmetrics are given in Table 7. It demonstrates the\nimbalanced metrics of accuracy, precision, and F1\nto the recall results.\nC.2 fastText aligned zero-shot learning.\nAligned fastText allows cross-lingual applica-\ntions. As depict in Table 8, most of the classiÔ¨Åer\nbased on aligned fastText word embeddings failed\ncompletely in hate speech detection.\nC.3 Few-short learning.\nExtensive results of our few-shot approach as de-\nscribed in section 4.3.3 are provided. We evaluated\nXLM1L AXEL for different percentages of injected\nfew-shot samples in the training set (cf. Table 9)\n3https://github.com/carpedm20/emoji/\n(accessed 6 October 2019)\nand ensured that the few-shot improvement is com-\ning from learning on the original training samples ‚Äì\nnot purely from the few-shot samples (cf. Table 10.\nC.4 Ablation study for XLM1L AXEL. Table 11\nlists full results in accuracy (ACC), precision\n(PRC), recall (REC), and F1 in % corresponding to\nthe AXEL elements.\n13\nA PREPRINT - MARCH 10, 2020\nTable 7: Performance comparison of our baselines with all metrics reported in accuracy (ACC), precision (PRC),\nrecall (REC), and F1 in %. Base SVM is based on the original baselines, with a slightly tuned C-value (3.5938).\nThe other models utilise 300 dimensional word embeddings, namely, GloVe (GV), fastText (FT) and, fastText\naligned (FTA) and a BiLSTM with a single feed-forward layer. The models are compared on the English (EN),\nEnglish reshufÔ¨Çed (EN-S), and Spanish (ES) data set.\nDataset Model ACC PRC REC F1\nEN\nBase SVM 49.95 45.19 88.26 59.78\nBase GV 46.25 43.61 93.75 58.93\nBase FT 48.43 44.77 94.80 60.18\nBase FTA 46.38 43.48 90.42 58.08\nEN-S\nBase SVM 70.27 64.11 66.81 65.43\nBase GV 60.66 52.23 82.99 63.44\nBase FT 64.72 56.17 70.37 61.75\nBase FTA 65.42 59.11 59.09 58.19\nES\nBase SVM 67.69 58.79 72.42 64.90\nBase GV 67.00 57.15 89.10 66.14\nBase FT 70.31 61.02 77.04 67.49\nBase FTA 70.69 64.91 64.01 63.63\nTable 8: Evaluation of the zero-shot performance of fastText aligned models. We trained a single LSTM layer\nFTA LSTM(I), double LSTM layer FTA 2LSTM(I), and attention layer FTA Att(I) version. Many version\nwere not efÔ¨Åciently trainable, even with early stopping, resulting in failing models indicated in italic. The models\nare compared on the English (EN), English reshufÔ¨Çed (EN-S), and Spanish (ES) data set. Full results are reported\nin accuracy (ACC), precision (PRC), recall (REC), and F1 in %.\nDataset Model ACC PRC REC F1\nTrain EN\nTest ES\nFTA LSTM 39.62 38.68 79.34 51.50\nFTA 2LSTM 39.37 39.20 85.60 53.29\nFTA Att 39.69 39.08 82.69 52.57\nTrain ES\nTest EN\nFTA LSTM 42.14 42.14 100.00 58.73\nFTA 2LSTM 42.07 42.10 99.80 58.65\nFTA Att 42.14 42.14 100.00 58.73\nTrain ES\nTest EN-S\nFTA LSTM 42.11 42.11 100.00 58.79\nFTA 2LSTM 42.09 42.10 99.96 58.77\nFTA Att 42.11 42.11 100.00 58.79\n14\nA PREPRINT - MARCH 10, 2020\nTable 9: Results of XLM1L AXEL network over percentage of added few-shot samples. A certain percentage of\nthe evaluation-language training set is added to the source-language training set. 0% added equals the zero-shot\ntraining. The models are compared on the English (EN), English reshufÔ¨Çed (EN-S), and Spanish (ES) data set.\nFull results are reported in accuracy (ACC), precision (PRC), recall (REC), and F1 in %.\nDataset % few-shot\nsamples added ACC PRC REC F1\nTrain ES\nTest EN\n0 58.80 51.06 53.99 52.48\n1 58.20 50.27 75.24 60.27\n5 58.33 50.37 75.72 60.50\n10 54.90 47.97 83.07 60.82\n25 52.61 46.77 90.34 61.63\nTrain ES\nTest EN-S\n0 61.95 55.17 51.43 53.24\n1 65.65 59.63 57.05 58.31\n5 68.94 63.51 61.68 62.58\n10 67.55 58.51 78.83 67.17\n25 70.94 64.43 69.19 66.73\nTrain EN\nTest ES\n0 49.00 42.86 70.91 53.42\n1 57.50 48.96 71.52 58.13\n5 55.56 47.93 89.24 62.36\n10 67.56 59.78 65.30 62.42\n25 69.31 60.10 76.21 67.20\nTable 10: Experiment to validate the cross-lingual learning by training XLM1L AXEL(F) purely on few-shot\nsamples. The results indicate that hate speech prediction cannot only be learnt with the few-shot samples, some\nmodels failed to train properly (italic). The models are compared on the English (EN), English reshufÔ¨Çed (EN-S),\nand Spanish (ES) data set. Full results are reported in accuracy (ACC), precision (PRC), recall (REC), and F1 in\n%.\nDataset % few-shot\ntraining samples ACC PRC REC F1\nEN\n1 42.48 42.20 98.80 59.14\n5 46.95 43.99 94.65 60.06\n10 47.56 43.80 86.26 58.10\nEN-S\n1 45.27 43.22 95.49 59.51\n5 43.09 42.52 99.82 59.63\n10 68.37 64.91 54.18 59.06\nES\n1 41.25 41.25 100.00 58.41\n5 41.25 41.25 100.00 58.41\n10 48.56 43.88 88.48 58.66\n15\nA PREPRINT - MARCH 10, 2020\nTable 11: Comparing the performance of AXEL module by removing parts of it to determine the\ncontributing factors: leaving out the max-pool module ( XLM1L AttAvgFC), leaving out the avg-\npool module ( XLM1L AttMaxFC), not sharing weights ( XLM1L AttAvgFCMaxFC), aggregating the sub-\nmodules instead of convolving ( XLM1L AttAvgFCMaxFCSum), using a tanh activation function in-\nstead of ReLU ( XLM1L AttAvgFCMaxFCTanh), adding an additional variance pooling submodule\n(XLM1L AttAvgFCMaxFCVarFC), the pure attention XLM1L Att, and XLM1L AXEL. Performed on the En-\nglish, reshufÔ¨Çed English, and Spanish data set. Adding more submodules to XLM1L Att improves the perfor-\nmance, whereas the average pooling seems to have the strongest positive inÔ¨Çuence on the result.\nModel ACC PRC REC F1\nEN\nXLM1L AXEL 51.53 46.30 93.93 62.03\nXLM1L AttAvgFCMaxFCVarFC 54.16 47.60 87.06 61.55\nXLM1L AttAvgFCMaxFCTanh 51.40 46.17 92.33 61.55\nXLM1L AttAvgFCMaxFCSum 53.55 47.24 87.62 61.39\nXLM1L AttAvgFCMaxFC 48.37 44.79 96.73 61.22\nXLM1L AttAvgFC 52.31 46.63 91.05 61.67\nXLM1L AttMaxFC 54.90 48.06 87.06 61.93\nXLM1L Att 52.84 46.89 89.78 61.61\nEN-S\nXLM1L AXEL 71.27 61.65 84.14 71.16\nXLM1L AttAvgFCMaxFCVarFC 73.28 64.79 80.05 71.62\nXLM1L AttAvgFCMaxFCTanh 74.05 67.72 73.34 70.42\nXLM1L AttAvgFCMaxFCSum 73.00 64.38 80.29 71.46\nXLM1L AttAvgFCMaxFC 74.02 68.19 71.81 69.96\nXLM1L AttAvgFC 75.05 69.13 73.64 71.31\nXLM1L AttMaxFC 73.79 67.28 73.52 70.26\nXLM1L Att 70.76 63.40 72.30 67.56\nES\nXLM1L AXEL 68.81 58.16 86.97 69.70\nXLM1L AttAvgFCMaxFCVarFC 69.62 59.55 64.22 61.79\nXLM1L AttAvgFCMaxFCTanh 69.25 60.69 72.27 65.98\nXLM1L AttAvgFCMaxFCSum 64.63 54.63 84.09 66.23\nXLM1L AttAvgFCMaxFC 73.01 65.07 68.15 67.62\nXLM1L AttAvgFC 70.44 62.97 68.79 65.75\nXLM1L AttMaxFC 69.81 64.39 60.00 62.12\nXLM1L Att 68.12 60.81 63.94 62.33\n16",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.7462186217308044
    },
    {
      "name": "Computer science",
      "score": 0.6175130605697632
    },
    {
      "name": "Single shot",
      "score": 0.571864664554596
    },
    {
      "name": "One shot",
      "score": 0.5163654088973999
    },
    {
      "name": "Natural language processing",
      "score": 0.5062293410301208
    },
    {
      "name": "Architecture",
      "score": 0.5011067390441895
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5007574558258057
    },
    {
      "name": "Speech recognition",
      "score": 0.3619579076766968
    },
    {
      "name": "Engineering",
      "score": 0.17213639616966248
    },
    {
      "name": "Geography",
      "score": 0.12059682607650757
    },
    {
      "name": "Physics",
      "score": 0.09958416223526001
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I62916508",
      "name": "Technical University of Munich",
      "country": "DE"
    }
  ]
}