{
  "title": "Transformer assisted dual U-net for seismic fault detection",
  "url": "https://openalex.org/W4360869627",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5100449947",
      "name": "Zhiwei Wang",
      "affiliations": [
        "China University of Petroleum, East China"
      ]
    },
    {
      "id": "https://openalex.org/A5078777706",
      "name": "Jiachun You",
      "affiliations": [
        "Chengdu University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5100431789",
      "name": "Wei Liu",
      "affiliations": [
        "Chengdu University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5100694635",
      "name": "Xingjian Wang",
      "affiliations": [
        "Chengdu University of Technology",
        "State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2962767316",
    "https://openalex.org/W3176258461",
    "https://openalex.org/W2014758788",
    "https://openalex.org/W2948473599",
    "https://openalex.org/W2890568727",
    "https://openalex.org/W6742657575",
    "https://openalex.org/W3157386224",
    "https://openalex.org/W6791637211",
    "https://openalex.org/W3038091703",
    "https://openalex.org/W2935135048",
    "https://openalex.org/W6838782201",
    "https://openalex.org/W2106921281",
    "https://openalex.org/W2126097500",
    "https://openalex.org/W2962914239",
    "https://openalex.org/W6658673620",
    "https://openalex.org/W2116369243",
    "https://openalex.org/W2964098128",
    "https://openalex.org/W4285059530",
    "https://openalex.org/W2939587785",
    "https://openalex.org/W2911424749",
    "https://openalex.org/W2808760859",
    "https://openalex.org/W6783865976",
    "https://openalex.org/W6781271030",
    "https://openalex.org/W3208394772",
    "https://openalex.org/W3048414469",
    "https://openalex.org/W2560311620",
    "https://openalex.org/W3160284783",
    "https://openalex.org/W3112139896",
    "https://openalex.org/W4255328724",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W4299918809",
    "https://openalex.org/W2770650758",
    "https://openalex.org/W4285790640",
    "https://openalex.org/W3127751679"
  ],
  "abstract": "Automatic seismic fault identification for seismic data is essential for oil and gas resource exploration. The traditional manual method cannot accommodate the needs of processing massive seismic data. With the development of artificial intelligence technology, deep learning techniques based on pattern recognition have become a popular research area for seismic fault identification. Despite the progress made with U-shaped neural networks (Unet), they still fall short in meeting the stringent requirements of fault prediction in complex structures. We propose a novel approach by combining a standard Unet with a transformer Unet to create a parallel dual Unet model, called Dual Unet with Transformer. To improve the accuracy of fault prediction, we compare six loss functions (including Binary Cross Entropy loss, Dice coefficient loss, Tversky loss, Local Tversky loss, Multi-scale Structural Similarity and Intersection over Union loss) using synthetic data, based on three evolution metrics involving Dice coefficient, Sensitivity and Specificity, find that the binary cross entropy loss function is the most robust one. An example comparing the prediction performance of different Unet models on synthetic data demonstrates the superior performance of our Dual Unet model, verifying the practical application value. To further validate the practical feasibility of our proposed method, we use real seismic data with a complex fault system and find that our proposed model is more accurate in predicting the fault system compared to well-developed Unet models such as the classical Unet and classical coherence cube algorithm, without transfer learning. This confirms the potential for wide-scale application of our proposed model.",
  "full_text": "Transformer assisted dual U-net\nfor seismic fault detection\nZhiwei Wang1, Jiachun You2*, Wei Liu2 and Xingjian Wang3\n1School of Petroleum Engineering, China University of Petroleum (East China), Qingdao, Shandong,\nChina, 2College of Geophysics, Chengdu University of Technology, Chengdu, Sichuan, China,3State Key\nLaboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology,\nChengdu, Sichuan, China\nAutomatic seismic fault identiﬁcation for seismic data is essential for oil and gas\nresource exploration. The traditional manual method cannot accommodate the\nneeds of processing massive seismic data. With the development of artiﬁcial\nintelligence technology, deep learning techniques based on pattern recognition\nhave become a popular research area for seismic fault identiﬁcation. Despite the\nprogress made with U-shaped neural networks (Unet), they still fall short in\nmeeting the stringent requirements of fault prediction in complex structures.\nWe propose a novel approach by combining a standard Unet with a transformer\nUnet to create a parallel dual Unet model, called Dual Unet with Transformer. To\nimprove the accuracy of fault prediction, we compare six loss functions (including\nBinary Cross Entropy loss, Dice coefﬁcient loss, Tversky loss, Local Tversky loss,\nMulti-scale Structural Similarity and Intersection over Union loss) using synthetic\ndata, based on three evolution metrics involving Dice coefﬁcient, Sensitivity and\nSpeciﬁcity, ﬁnd that the binary cross entropy loss function is the most robust one.\nAn example comparing the prediction performance of different Unet models on\nsynthetic data demonstrates the superior performance of our Dual Unet model,\nverifying the practical application value. To further validate the practical feasibility\nof our proposed method, we use real seismic data with a complex fault system and\nﬁnd that our proposed model is more accurate in predicting the fault system\ncompared to well-developed Unet models such as the classical Unet and classical\ncoherence cube algorithm, without transfer learning. This conﬁrms the potential\nfor wide-scale application of our proposed model.\nKEYWORDS\ntransformer, UNET, fault prediction, dual Unet, loss function\n1 Introduction\nSeismic fault detection is a crucial step of oil and gas reservoir exploration because faults\noften serve as pathways for hydrocarbon migration. Furthermore, faults have geological\nsigniﬁcance as they indicate changes in stress and provide valuable information for drilling.\nFault identiﬁcation technology is constantly developing with the development of seismic\nexploration technology. In the past, the discontinuity or edge of seismic images is considered\nas a sign of a fault. Therefore, many fault detection methods are proposed to enhance those\ndiscontinuities using some seismic attributes including the semblance, coherence and\ncurvature (Marfurt et al., 1998; Marfurt et al., 1999; Roberts, 2001). To pursue better\nperformance, more improved approaches are proposed including the ant tracking and\nattributes fused methods (Pedersen et al., 2002; Di et al., 2019; Yuan et al., 2020; Acuña-Uribe\net al., 2021; Yuan et al., 2022), but the results still rely heavily on the experience of\ninterpreters and the quality of the seismic attributes used. Moreover, the presence of noise in\nOPEN ACCESS\nEDITED BY\nPeng Zhenming,\nUniversity of Electronic Science and\nTechnology of China, China\nREVIEWED BY\nQiang Guo,\nChina University of Mining and\nTechnology, China\nSanyi Yuan,\nChina University of Petroleum, Beijing,\nChina\nShu Li,\nJishou University, China\n*CORRESPONDENCE\nJiachun You,\nyoujiachun@cdut.edu.cn\nSPECIALTY SECTION\nThis article was submitted to\nEnvironmental Informatics\nand Remote Sensing,\na section of the journal\nFrontiers in Earth Science\nRECEIVED 18 September 2022\nACCEPTED 13 March 2023\nPUBLISHED 24 March 2023\nCITATION\nWang Z, You J, Liu W and Wang X (2023),\nTransformer assisted dual U-net for\nseismic fault detection.\nFront. Earth Sci.11:1047626.\ndoi: 10.3389/feart.2023.1047626\nCOPYRIGHT\n© 2023 Wang, You, Liu and Wang. This is\nan open-access article distributed under\nthe terms of theCreative Commons\nAttribution License (CC BY). The use,\ndistribution or reproduction in other\nforums is permitted, provided the original\nauthor(s) and the copyright owner(s) are\ncredited and that the original publication\nin this journal is cited, in accordance with\naccepted academic practice. No use,\ndistribution or reproduction is permitted\nwhich does not comply with these terms.\nFrontiers inEarth Science frontiersin.org01\nTYPE Original Research\nPUBLISHED 24 March 2023\nDOI 10.3389/feart.2023.1047626\nseismic images can negatively impact the accuracy of fault detection.\nTherefore, it is imperative to develop an automatic fault\nidentiﬁcation method.\nWith the rapid development of deep learning, especially the deep\nconvolution neural networks (CNN), more and more attention has\nbeen paid to processing and interpreting seismic data, such as\nvelocity inversion, seismic salt interpretation and noise\nsuppression (Shi et al., 2019 ; Wu and McMechan, 2019 ; You\net al., 2020). The powerful capability of deep CNNs to establish\nnon-linear relationships between inputs and targets has made\nautomatic fault identiﬁcation based on CNN models a popular\narea of application. Seismic fault detection is essentially a\nclassiﬁcation task, with labels of“fault” and “non-fault.” Over the\nyears, researchers have developed a variety of neural network\narchitectures to tackle this task. In the early stages, support\nvector machine (SVM) and multi-layer perceptron (MLP)\nmethods were applied to deal with this task ( Di et al., 2017;\n2018). In recent years, more end-to-end fault-detection deep\nCNN models have been developed (Xiong et al., 2018). The fault\ndetection task is regarded as semantic segmentation of images, and\nthe standard Unet architecture including encoder and decoder is\nintroduced (Li et al., 2019 ; Wu et al., 2019 ). Because of the\nsuperiority of Unet models, its many variants have been\nsuccessfully applied in seismic fault detection, such as a nested\nresidual Unet, Unet 3plus and wavelet transform based CNN (Yang\net al., 2020; Gao et al., 2022; Shen et al., 2022).\nThe main feature of a CNN model is that it shares receptive\nﬁelds by usingﬁlters with limited size. Because of that, it is difﬁcult\nfor CNN-based methods to learn explicit global and long-term\nsemantic information. In cases where the fault system is complex,\nthe positive (fault) and negative (non-fault) labels in seismic images\nare highly unbalanced, and the CNN model may suffer from an\nunsatisfactory result, which seems to be unable to fully meet the\nstrict requirements of seismic fault detection. Inspired by the\nsigniﬁcant success of the transformer with attention mechanism\nin the ﬁeld of Natural Language Processing (NLP), a vision\ntransformer (ViT) module with an attention mechanism was\nintroduced (Dosovitskiy et al., 2021). However, transformers were\noriginally designed to process one-dimensional sequences and focus\non building global relationships between inputs and targets, which\nresults in a lack of localization information, which coincidentally is\nthe advantage of a CNN model. Integrating the strengths of both\nmodels is becoming a new trend, leading to the development of\ncombined CNN and transformer architectures, such as the\nTransformer-based Unet (TransUnet) and Shifted Windows\nTransformer-based Unet (Swin TransUnet) ( Cao et al., 2021 ;\nChen et al., 2021). Although these two hybrid models have been\nsuccessfully applied to medical image segmentation, there are few\nreports on their use in seismic fault prediction. Using the combined\nCNN-Transformer model to develop a new end-to-end hybrid\nstructure for seismic fault prediction is both promising and\nsigniﬁcant.\nIn our manuscript, we begin by presenting our newly developed\nhybrid CNN-Transformer architecture. Next, we investigate the loss\nfunction used in the image segmentation and compare their\nperformances. Afterwards, we detailed compare several well-\nestablished CNN architectures using synthetic data and evaluate\ntheir metrics. Lastly, we apply the developed CNN models to\nperform seismic fault prediction on real data and summarize\nour work.\nFIGURE 1\nArchitectures of (A) classical Unet, (B) TransUnet, (C) SwinUnet.\nFrontiers inEarth Science frontiersin.org02\nWang et al. 10.3389/feart.2023.1047626\n2 Methodology\n2.1 Architecture of Unet model\nIn our manuscript, for the task of semantic segmentation,\nvarious variants of the standard Unet model that incorporate\ntransformers are gaining increasing attention. Two of these well-\ndeveloped models are the TransUnet and Swin TransUnet. The\nTransUnet model integrates multiple transformer blocks into the\nbottom layer of the standard Unet model, while the Swin TransUnet\nreplaces the convolutional blocks in the encoder-decoder\ncomponents with transformer blocks. TransUnet combines the\nconvolution blocks with transformers, showing more fused\nfeatures; Swin TransUnet illustrates a purely U-shaped\nTransformer architecture. Further research is needed to\ndetermine which architecture produces better results in seismic\nfault prediction. The architectures of Unet models are shown in\nFigure 1.\nIn order to extend the applications of CNN models, a\ntransformer with attention mechanism embedded within a CNN\nis proposed and serves as a powerful tool in computer vision. In the\nlater examples of synthetical data, we can observe that predicted\nresults of the traditional Unet model are more continuity but lack\ndetailed information whereas transformer assistant Unet models are\nshort of continuity in seismic fault prediction. Due to the use of\nshared convolution kernels, conventional convolutional neural\nnetwork models such as Unet are more suitable for learning local\nfeatures of input images but have limited ability to capture global\nfeatures. The Transformer models show a good performance of\nglobal learning, but its description of local features of images is not\nideal. To take advantage of the strengths of both models, we propose\na new hybrid architecture called the Dual Unet with Transformer, as\nillustrated in Figure 2.\n2.2 Loss function\nIn deep learning, the loss function plays a crucial role. By\nminimizing the loss function, the model converges and reduces\nt h ep r e d i c t i v ee r r o ro ft h eC N Nm o d e l .T h e r e f o r e ,d i f f e r e n tl o s s\nfunctions have a signi ﬁcant impact on the model. In the case\nwhere the parameters of the deep neural network architecture\nhave been determined, there is a need for a deeper comparative\nstudy on how to select the loss function so that the deep neural\nnetwork converges to an optimal solution. In the seismic fault\ndetection, the positive (faults) and negative (no-faults) labels are\nextremely unbalanced. The selection of the loss function is crucial\nfor prediction accuracy as it has advantages in handling label\nimbalances. In our manuscript, we discuss a loss function that is\nintroduced. As seismic fault detection is a binary classiﬁcation,\nt h el o s sf u n c t i o nw ed i s c u s sb e l o n g st ot h eb i n a r ys e g m e n t a t i o n\nproblem.\nBinary Cross Entropy loss: Binary cross entropy is a classic and\nwidely used loss function in binary classiﬁcation, but for image\nsegmentation, it is deﬁned to predict a binary label at a pixel level. Its\nfunction is deﬁned as\nloss\nBCE /equals− ylog~y + 1 − ~y() log 1 − ~y()[] (1)\nWhere y and ~y are the ground truth and predicted labels,\nrespectively.\nDice coef ﬁcient loss: Dice coef ﬁcient is a widely used\nmeasurement in computer vision, which is applied to calculate\nthe similarity between two images. It has also been suggested for\nuse as a loss function (Milletari et al., 2016). The dice coefﬁcient loss\nbetween labels and outputs can be written as\nloss\nDC /equals 1 − 2y~y\ny + ~y (2)\nFIGURE 2\nArchitecture of dual Unet with transformer.\nFrontiers inEarth Science frontiersin.org03\nWang et al. 10.3389/feart.2023.1047626\nTversky loss: The loss function of dice coefﬁcient keeps an\nequal weigh between precision and recall. However, it is difﬁcult\nto train a network for highly imbalanced data by using the dice\ncoefﬁcient loss function, in which predicting small scaled seismic\nfaults is crucial. To improve p erformance, the Tversky loss\nfunction ( Salehi et al., 2017 ) based on the Tversky index is\ndeﬁned as\nloss\nT /equals 1 − y~y\ny~y + α 1 − y() ~y + βy 1 − ~y() (3)\nWhere α and β are coefﬁcients. Noted that whenα = β = 0.5, the\nTversky loss function is degenerated into the dice coefﬁcient loss\nfunction.\nLocal Tversky loss: Based on the Tversky index, to balance\nprecision and recall ratios in the small regions-of-interest and\nmake the loss function more sensitive to the small regions of\ninterest, a local Tversky loss ( Abraham and Khan, 2019 )\nis proposed with a parameter γ,a n di t sl o s sf u n c t i o ni s\ndeﬁned as\nloss\nlocal T /equals lossT()\n1\n/γ (4)\nWhere γ is in the range of 1– 3.\nMulti-scale Structural Similarity (MS-SSIM) loss: The\nstructural similarity index (SSIM) is used to measure image\nquality evaluation between a processed image and a reference\nimage. However, the SSIM index is a single-scale assessment. To\ncalculate image quality assessment more ﬂexibly, a multi-scale\nstructural similarity (MS-SSIM) index is proposed (Wang et al.,\n2003), it can be computed by combining the evaluation at\ndifferent scales using\nloss\nms−ssim /equals 1 − ly , ~y()[]\nαM\n∏\nM\nj/equals 1\ncy , ~y()[]\nβj sy , ~y()[]\nγj\n(5)\nWhere l(y, ~y)/equals\n2μxμy+C1\nμ2\nx+μ2\ny+C1\n, c(y, ~y)/equals 2σxσy+C2\nσ2x+σ2y+C2\nand\ns(y, ~y)/equals σxy+C3\nσxσy+C3\n, C1 /equals( K1L)2, C2 /equals( K2L)2 and C3 /equals C2\n2 .I n\ngenerally, L =255 and K1 ≪1, K2 ≪1.\nIntersection over Union (IoU) loss: The IoU index (Rahman and\nWang, 2016) is performed to measure a standard similarity between\nthe predicted and ground truth images for a segment issue, this loss\nfunction is generally used in object detection and its deﬁnition is\nwritten as\nloss\nIoU /equals 1 − y ∩~y\n⏐⏐⏐⏐\n⏐⏐⏐⏐\ny ∪~y\n⏐⏐\n⏐\n⏐\n⏐⏐\n⏐\n⏐ (6)\n3 Numerical experiments\n3.1 Performance of loss functions on\nsynthetic data\nThe selection of loss functions in seismic fault detection is a less\nconcerned topic. In this example, we compare the performance of\ndifferent loss functions using synthetic data, which lays a solid\nfoundation for the following works. We use synthetic 2D seismic\nimages with faults and their corresponding fault labels as training\nsamples to train a standard Unet (Wu et al., 2019). The synthetic 2D\nseismic images and their corresponding labels are shown inFigure 3.\nIn the stage of training a neural network, we employ a total of\n5,120 samples, in which 80% of them are used as training samples\nand the remaining 20% are used as validation datasets while an\nadditional 256 samples are applied to test the accuracy of neural\nnetworks. In order to quantitatively evaluate the performance of\ndifferent loss functions, we use three.\nEvaluation indexes, including dice coefﬁcient, sensitivity and\nspeciﬁcity, in evaluating the prediction results of CNN models.\nDice coefﬁcient is used to account for overlapping pixels between\nthe predicted and ground-truth images while sensitivity and\nspeciﬁcity mirror the ratios of true positive and true negative,\nrespectively. These metrics are calculated by using the following\nequations\nDC /equals\n2TP\n2TP + FP + FN,\nsensitivity /equals TP\nTP + FN\nspecificity /equals TN\nTN + FP\n(7)\nWhere TP, FP FN and TN represent the number of true positive,\nfalse positive, false negative and true negative, respectively.\nDuring the training of the neural network, we set the number of\nepochs to 30 and use the same optimization parameters, including\nAdam algorithm and learning rate of 0.0001. The loss and accuracy\ncurves using different loss functions are drawn in Figure 4 .\nAdditionally, we also compile statistics for these three metrics\nusing different loss functions, which are listed in Table 1 .\nExamining the loss and accuracy curves, it can be seen that the\nbinary cross entropy loss function achieves the lowest error and the\nhighest accuracy. In the prediction results, we obtain a best dice\ncoefﬁcient of 0.9101 by using the binary cross entropy loss, and IoU\nloss also gets a very close value, a dice coefﬁcient of 0.9050. As for\nsensitivity, binary cross entropy loss also surpasses other loss\nfunctions and IoU loss follows it closely. Except for MS-SSIM\nloss function, the speci ﬁcity of most loss functions is almost\nequal. The comparison of metrics mutually conﬁrms the accuracy\ncurves using different loss functions (Figure 4B).\nIn this test, we can conclude that it seems that a single loss\nfunction is very difﬁcult to get the best scores in all indexes. In the\nseismic fault detection task, based on the seismic fault labels, it can\nbe observed that the positive and negative labels seem to be\nimbalanced, but the binary cross entropy function outperforms\nother loss functions in most metrics and it is probably the most\nrobust one. According to manuscript ofJadon (2020), other loss\nfunctions may work better in the case of highly imbalanced data sets.\nTherefore, our further work is based on the binary-cross entropy loss\nfunction.\n3.2 Fault prediction on synthetic data using\ndifferent architectures\nAfter determining the performances of different loss functions,\nwe carry out an example to compare the performance of different\nFrontiers inEarth Science frontiersin.org04\nWang et al. 10.3389/feart.2023.1047626\nUnet architectures, including the standard Unet, transUnet,\nswinTrans Unet and dual Unet with transformer. In the neural\nnetwork training stage, we use the same training datasets in the\nexamples of comparing loss function.Figure 5shows the accuracy of\nthe validated data sets using different Unet models. By observing the\naccuracy curves, it can be seen that the predicted accuracy of the\nproposed dual Unet with transformer model is superior to the other\nUnet models. For a fair comparison, we pick up some predicted fault\nimages from the test data set by using different Unet models, which\nare shown inFigure 6. By comparing the results, we notice that the\npredicted faults from our proposed models exhibit more accurate\ninformation than that of other Unet models. In the experiment, the\nfaults predicted by the traditional Unet model have greater\ndiscreteness and less continuity, and the transUnet seems to\nproduce more artifacts. Our proposed dual Unet model combines\ncharacteristics and properties of the traditional Unet model and the\ntransUnet model. This example illustrates the superiority of our\nproposed method and provides a foundation for its application in\npractical data.\nIt is interesting to note that the purely swin transformer U-type\nmodel seems to produce an imperfect prediction. The predicted\nFIGURE 3\nSynthetic 2D seismic images and their corresponding labels,(A,C) are the seismic patch,(B,D) are their corresponding fault labels.\nAB\nFIGURE 4\nLoss (A) and accuracy(B) curves using different loss functions, the red, blue, back, green, yellow and cyan lines present dice loss, Tversky, local\nTverskry, MS-SSIM, IoU and binary cross entropy loss functions.\nTABLE 1 Evaluation metrics by using different loss functions.\nLoss function Metrics\nDC Sensitivity Speci ﬁcity\nBinary Cross-Entropy 0.9101 0.8592 0.9616\nDice 0.8688 0.7820 0.9696\nTversky 0.8887 0.8161 0.9687\nLocal Tversky 0.8730 0.7901 0.9673\nMS SSIM 0.8953 0.8375 0.9532\nIoU 0.9050 0.8473 0.9652\nFrontiers inEarth Science frontiersin.org05\nWang et al. 10.3389/feart.2023.1047626\nresults of Swin TramsUnet model have an obvious gap from those of\nother models. The emphasis on global feature extraction makes it\ndifﬁcult to consider the local continuity of seismic events in the\nlinear mapping of swin transformer blocks, and the precision curve\nof Swin TransUnet in processing validation data sets also proves this\nview. At present, we doubt that whether swinTrans Unet is able to\nachieve a better performance than other methods as described in the\nmedical image segmentation, for the seismic fault detection task\n(Cao et al., 2021). Fortunately, TransUnet seems to hold a good\naccuracy compared with the standard Unet. Because of that, we\nprefer to merge TransUnet and the standard Unet, to build a merged\nUnet architecture, the predicted accuracy and fault images verify our\njudgement.\n4 Application of real data\nIn the actual seismic data fault prediction, our work selects a\nshallow sea area in the southwest of Bohai Bay where the faults\nare relatively well developed. In terms of regional structure, the\nstudy area is located in the east of the low uplift in the Cheng Bei,\nat the junction of the Bohai Depression and Jiyang Depression.\nTo the south is the Zhendong Depression, to the north is the\nBohai Depression, and to the east and west are the Chengbei low\nuplift and the Bonan low uplift, respectively. The study area is\nrich in hidden mountains, which have experienced the evolution\nstages of ancient platform development, Triassic platform\ndisintegration, Yanshan ra pid deformation, ancient\nQuaternary faulting, and rece nt Quaternary depression. The\nFIGURE 5\nAccuracy curves of the validation date sets recorded by using\ndifferent Unet models, the black, blue and green lines indicate\naccuracy of swinUnet, standard Unet and transUnet while the red\ndashed line is the accuracy of our proposed dual Unet with\ntransformer.\nFIGURE 6\nComparison of predicted faults by using different Unet models in the test data set:(A) standard Unet;(B) TransUnet; (C) Swin TransUnet;(D) our\nproposed dual Unet with Transformer;(E) ground truth label.\nFrontiers inEarth Science frontiersin.org06\nWang et al. 10.3389/feart.2023.1047626\ninternal structure of the hidden mountain belt is quite complex,\nwith a large number of folds andfault structures, as shown in\nFigure 7 . Therefore, carrying out the characterization and\ndescription of faults in this study area is of great signi ﬁcance\nfor understanding the evolution of the hidden mountains and\npredicting oil and gas resources.\nAfter the neural network training of synthetic data is completed,\nwe try to use our pretrained Unet models to perform seismic fault\nFIGURE 7\nGeological background of the research area.\nFIGURE 8\nOriginal seismic section with manual interpreted faults.\nFrontiers inEarth Science frontiersin.org07\nWang et al. 10.3389/feart.2023.1047626\nprediction on the real data. The real seismic section is painted in\nFigure 8.I nFigure 8, some faults are easy to notice directly, which\nhave been marked by red lines. For a seismic fault detection task, we\nprefer applying the pretrained Unet models to predict the seismic\nfaults straightforwardly without transfer learning, which is a tough\nchallenge. The predicted probability of faults overlapping with the\nseismic section is shown inFigure 8. In the predicted faults, for some\nlarge-scale faults such as fault F1, three Unet models generate similar\nresults. For the case of fault F3, the TransUnet model can only\npredict it intermittently or hardly. Maybe inherited the ability of\nstandard Unet model, our proposed dual Unet with transformer can\nproduce clearer fault lines than the standard Unet and TransUnet\nmodels, especially fault F4 at 1.2– 1.4 s. To furtherly compare the\nperformance of fault prediction, we enlarge on the red dashed box\n(F4) inFigure 9and display it inFigure 10, it is obvious to see that\nour proposed model yields a better quality of fault prediction than\nother two methods. Note that because the Swin TransUnet model\nhas not obtained ideal results in the synthetic example, hence we do\nnot include it in the practical application. In order to compare the\napplication effects of neural network methods and traditional fault\nidentiﬁcation methods in practical examples, this article used the\nclassical coherence cube algorithm to process the actual example\n(Bahorich and Farmer, 1995). As shown inFigures 8, 9, the neural\nnetwork method provides a clearer and more continuous\ncharacterization of the fault compared to conventional methods.\nThis also demonstrates the necessity and superiority of conducting\ndeep research on neural network methods.\nIt is worth noting that the seismic fault prediction of actual\nseismic data using our proposed model is not performed using\ntransfer learning. The predicted results supply hard evidence to\nprove that our proposed model has a better generalization than the\nstandard Unet and TransUnet models, and it is of great signiﬁcance\nfor seismic fault prediction of practical data.\n5 Discussion\nOur target is to emphasize and raise the signiﬁcance of loss\nfunction in deep learning. L oss functions are crucial in\ndetermining the performance of a model. However, for complex\nobjectives like segmentation, it’s not feasible to choose a single,\nuniversal loss function. The optimal loss function depends mostly\non the dataset properties used for training, such as distribution,\nskewness, and boundaries. It ’s worth noting that none of the\nexisting loss functions are universally superior in all use cases.\nSpeciﬁcally, the binary-cross entropy function performs well in our\ncases, and we do not think this is a conclusion that applies to all\ndeep learning problems. It may perform well for fault detection\ntask, but for different deep learning tasks, other loss functions may\nbe more effective. In our opinion, speciﬁc deep learning tasks need\nto be analyzed in detail. For example, for deep learning tasks that\ninvolve noise suppression in seismic data, which loss function\nenables better performance of the deep neural network model, and\nrelevant numerical experiments and comparative studies need to\nbe conducted. For medical image semantic segmentation tasks,\nJadon (2020) has made a detailed comparison of the performance\nof different loss functions, whichhas a different conclusion with\nfault detection task.\nFIGURE 9\nPredicted faults by using different neural networks:(A) classical coherence cube algorithm;(B) conventional Unet;(C) TransUnet; (D) our proposed\ndual Unet with transformer.\nFrontiers inEarth Science frontiersin.org08\nWang et al. 10.3389/feart.2023.1047626\nFor the interpretation of 3D seismic data, due to the large\namount of data, manual interpretation is difﬁcult to efﬁciently and\nquickly complete the relevant interpretation tasks. Fully automatic\nor semi-automatic computer interpretation solutions have\nreceived increasing attentio n and research. In theory, 3D\nseismic data can be regarded as an unfolding form of multiple\n2D data. For seismic data interpretation, we believe that the\nsuccessful application of 2D seismic data is the basis for the\napplication of 3D seismic data. Therefore, for fault recognition\nwork, the feasibility and effectiveness of the proposed method in\nthis article were ﬁrst veriﬁed on 2D seismic data. Of course, the\ndevelopment of 3D Transformer-based fracture recognition\ntechnology is also one of our future research directions.\nCurrently, in the research of 3D medical image semantic\nsegmentation, some scholars h ave developed 3D Transformer\nmodels, which can provide references for our future research on\n3D Transformer-based fault detection (Hatamizadeh et al., 2022;\nLiang et al., 2022). However, we need to develop a 3D Transformer\nmodel suitable for fault recognition in seismic data according to\nthe characteristics of seismic data.\n6 Conclusion\nAiming at the problem of seismic fault identiﬁcation, after\nanalyzing the shortcomings of the convolution block and the\ntransformer block, we attempt to integrate a standard Unet\nmodel with a TransUnet model, and develop a dual Unet with\ntransformer. In order to discuss which kinds of loss function can\nmake CNN models converges quickly and produce a best\nperformance, we carried out a numerical example to compare the\nperformance of six loss functions andﬁnd that the binary cross\nentropy loss function has a superior performance in the task of\nseismic fault detection. In addition, a synthetic data is employed to\ncompare performaces of different Architectures, the predicted fault\nsections show that our proposed transformer assisted dual Unet\nFIGURE 10\nEnlarged images of the red dashed box inFigure 8: (A) classical coherence cube algorithm;(B) conventional Unet;(C) TransUnet; (D) our proposed\ndual Unet with transformer.\nFrontiers inEarth Science frontiersin.org09\nWang et al. 10.3389/feart.2023.1047626\ndepicts the fault system clearer than that of the standard Unet,\nTransUnet, Swin TransUnet and classical coherence cube algorithm.\nBased on that, through seismic fault prediction and qualitative\ncomparison, predicted results demonstrate that our proposed\ndual Unet with transformer model obtains a more accurate and\nconvergent fault prediction than that of the standard Unet,\nTransUnet and Swin transUnet models in a synthetical case. In\nthe application of real data, our proposed model generates a higher\nquality fault predicted image, compared with other Unet models,\nproving its practical application value.\nData availability statement\nThe raw data supporting the conclusion of this article will be\nmade available by the authors, without undue reservation.\nAuthor contributions\nJY: The conception and design of the study, manuscript editing;\nZW: Manuscript writing and revising, processing of data; WL:\nmanuscript reviewing and editing; XW: Provide the real seismic\ndata and some suggestion.\nFunding\nThis research is supported by National Natural Science\nFoundation of China (Grant Nos 42050104, 42030812 and\n42004103).\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could be\nconstrued as a potential conﬂict of interest.\nThe reviewer SY declared a shared afﬁliation with the author\nZW to the handling editor at time of review.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their af ﬁliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nReferences\nAbraham, N., and Khan, N. M. (2019).“A novel focal Tversky loss function with\nimproved attention U-net for lesion segmentation,” in 2019 IEEE 16th international\nsymposium on biomedical imaging (ISBI 2019). 683– 687.\nAcuña-Uribe, M., Pico-Forero, M. C., Goyes-Peñaﬁel, P., and Mateus, D. (2021).\nEnhanced ant tracking: Using a mult ispectral seismic attribute work ﬂow to\nimprove 3D fault detection. Lead. Edge 40 (7), 502 – 512. doi:10.1190/\ntle40070502.1\nBahorich, M., and Farmer, S. (1995). 3-D seismic discontinuity for faults and\nstratigraphic features: The coherence cube. Lead. edge 14 (10), 1053– 1058. doi:10.\n1190/1.1437077\nC a o ,H . ,W a n g ,Y . ,C h e n ,J . ,J i a n g ,D . ,Z h a n g ,X . ,T i a n ,Q . ,e ta l .( 2 0 2 1 ) .Swin-\nUnet: Unet-like pure transformer for medical image segmentation .A r X i v ,a b s /\n2105.05537.\nChen, J., Lu, Y., Yu, Q., Luo, X., Adeli, E., Wang, Y., et al. (2021).TransUNet:\nTransformers make strong encoders for medical image segmentation . ArXiv, abs/\n2102.04306.\nDi, H., Shaﬁq, M. A., Wang, Z., and Alregib, G. (2019). Improving seismic fault\ndetection by super-attribute-based classiﬁcation. Interpretation 7 (3), SE251– SE267.\nDi, H., Shaﬁq, M., and Alregib, G. (2018). “Patch-level MLP classiﬁcation for\nimproved fault detection,” in SEG technical program expanded abstracts 2018.\nDi, H., Sha ﬁq, M., and Alregib, G. (2017). “Seismic-fault detection based on\nmultiattribute support vector machine analysis,” in Seg technical program expanded\nabstracts.\nDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T.,\net al. (2021).An image is worth 16x16 words: Transformers for image recognition at scale.\nArXiv, abs/2010.11929.\nGao, K., Huang, L., and Zheng, Y. (2022). fault detection on seismic structural images\nusing a nested residual U-net.IEEE Trans. Geoscience Remote Sens.60, 1– 15. doi:10.\n1109/tgrs.2021.3073840\nHatamizadeh, A., Tang, Y., Nath, V., Yang, D., Myronenko, A., Landman, B., et al.\n(2022). “Unetr: Transformers for 3d medical image segmentation,” in Proceedings of the\nIEEE/CVF winter conference on applications of computer vision, 574– 584.\nJadon, S. (2020).“A survey of loss functions for semantic segmentation,” in 2020 IEEE\nconference on computational intelligence in bioinformatics and computational biology\n(CIBCB),1 – 7.\nLi, S., Yang, C., Sun, H., and Zhang, H. (2019). Seismic fault detection using an\nencoder– decoder convolutional neural network with a small training set.J. Geophys.\nEng. 16 (1), 175– 189. doi:10.1093/jge/gxy015\nLiang, J., Yang, C., Zhong, J., and Ye, X. (2022). “BTSwin-unet: 3D U-shaped\nsymmetrical swin transformer-based network for brain tumor segmentation with\nself-supervised pre-training,” in Neural processing letters,1 – 19. doi:10.1007/s11063-\n022-10919-1\nMarfurt, K. J., Kirlin, R. L., Farmer, S. L., and Bahorich, M. S. (1998). 3-D seismic\nattributes using a semblance-based coherency algorithm.Geophysics 63 (4), 1150– 1165.\ndoi:10.1190/1.1444415\nMarfurt, K. J., Sudhaker, V., Gersztenkorn, A., Crawford, K. D., and Nissen, S. E.\n(1999). Coherency calculations in the presence of structural dip.Geophysics 64 (1),\n104– 111. doi:10.1190/1.1444508\nMilletari, F., Navab, N., and Ahmadi, S-A. (2016).“V-Net: Fully convolutional neural\nnetworks for volumetric medical image segmentation,” in 2016 fourth international\nconference on 3D vision (3DV), 565– 571.\nPedersen, S. I., Skov, T., Randen, T., and Sønneland, L. (2002).“Automatic Fault\nextraction using artiﬁcial ants,” in Seg technical program expanded abstracts,1 0 7– 116.\nRahman, M. A., and Wang, Y. (2016).Optimizing intersection-over-union in deep\nneural networks for image segmentation, 234– 244.\nRoberts, A. (2001). Curvature attributes and their application to 3D interpreted\nhorizons. First Break 19, 85– 100. doi:10.1046/j.0263-5046.2001.00142.x\nS a l e h i ,S .S .M . ,E r d oğmuş,D . ,a n dG h o l i p o u r ,A .( 2 0 1 7 ) .Tversky loss function for\nimage segmentation using 3D fully convolutional deep networks .A r X i v ,a b s /\n1706.05721.\nShen, S., Li, H., Chen, W., Wang, X., and Huang, B. (2022). Seismic Fault\ninterpretation using 3-D scattering wavelet transform CNN. IEEE Geoscience\nRemote Sens. Lett.19, 1– 5. doi:10.1109/lgrs.2022.3183495\nShi, Y., Wu, X., and Fomel, S. (2019). SaltSeg: Automatic 3D salt segmentation using a\ndeep convolutional neural network.Interpretation 7 (3), SE113– SE122. doi:10.1190/int-\n2018-0235.1\nWang, Z., Simoncelli, E. P., and Bovik, A. C. (2003). Multiscale structural similarity for image\nquality assessment. The Thrity-Seventh Asilomar Conference on Signals.Syst. Comput.2,\n1398– 1402.\nFrontiers inEarth Science frontiersin.org10\nWang et al. 10.3389/feart.2023.1047626\nWu, G. Y., and Mcmechan, G. A. (2019). Parametric convolutional neural network-\ndomain full-waveform inversion. Geophysics.\nW u ,X . ,L i a n g ,L . ,S h i ,Y . ,a n dF o m e l ,S .( 2 0 1 9 ) .F a u l t S e g 3 D :U s i n gs y n t h e t i cd a t a\nsets to train an end-to-end convolutional neural network for 3D seismic fault\nsegmentation.\nXiong, W., Ji, X., Ma, Y., Wang, Y., Albinhassan, N. M., Ali, M. N., et al. (2018).\nSeismic fault detection with convolutional neural network. Geophysics 83 (5),\nO97– O103. doi:10.1190/geo2017-0666.1\nY a n g ,D . ,C a i ,Y . ,H u ,G . ,Y a o ,X . ,a n dZ o u ,W .( 2 0 2 0 ) .“Seismic fault detection\nbased on 3D Unet++ model, ” in Seg technical program expanded abstracts .\nYou, J., Xue, Y-J., Cao, J., and Li, C. (2020).“Attenuation of seismic swell noise using\nconvolutional neural networks in frequency domain and transfer learning, ” in\nInterpretation,1 – 77.\nY u a n ,S . ,J i a o ,X . ,L u o ,Y . ,S a n g ,W . ,a n dW a n g ,S .( 2 0 2 2 ) .D o u b l e - s c a l e\nsupervised inversion with a data-driven forward model for low-frequency\nimpedance recovery. Geophysics 87 (2), R165 – R181. doi:10.1190/geo2020-\n0421.1\nYuan, S., Wang, J., Liu, T., Xie, T., and Wang, S. (2020). 6D phase-difference attributes\nfor wide-azimuth seismic data interpretation.Geophysics 85 (6), IM37– IM49. doi:10.\n1190/geo2019-0431.1\nFrontiers inEarth Science frontiersin.org11\nWang et al. 10.3389/feart.2023.1047626",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6636484861373901
    },
    {
      "name": "Data mining",
      "score": 0.4582791030406952
    },
    {
      "name": "Artificial neural network",
      "score": 0.44672122597694397
    },
    {
      "name": "Artificial intelligence",
      "score": 0.42049315571784973
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.33341336250305176
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210162190",
      "name": "China University of Petroleum, East China",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I31595395",
      "name": "Chengdu University of Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210098205",
      "name": "State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation",
      "country": "CN"
    }
  ]
}