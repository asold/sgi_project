{
  "title": "Large language models know how the personality of public figures is perceived by the general public",
  "url": "https://openalex.org/W4392976263",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4284547777",
      "name": "Xubo Cao",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A2149302410",
      "name": "Michal Kosinski",
      "affiliations": [
        "Stanford University"
      ]
    },
    {
      "id": "https://openalex.org/A4284547777",
      "name": "Xubo Cao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2149302410",
      "name": "Michal Kosinski",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2154868463",
    "https://openalex.org/W104439893",
    "https://openalex.org/W2135772222",
    "https://openalex.org/W88719000",
    "https://openalex.org/W2515556028",
    "https://openalex.org/W2154380314",
    "https://openalex.org/W4213076034",
    "https://openalex.org/W2496868659",
    "https://openalex.org/W3123639603",
    "https://openalex.org/W2032602350",
    "https://openalex.org/W2971210088",
    "https://openalex.org/W2170703617",
    "https://openalex.org/W2318358854",
    "https://openalex.org/W3039098281",
    "https://openalex.org/W2049305807",
    "https://openalex.org/W4206069118",
    "https://openalex.org/W2034963442",
    "https://openalex.org/W2060202874",
    "https://openalex.org/W2029601846",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2981523423",
    "https://openalex.org/W2169683554",
    "https://openalex.org/W2231666394",
    "https://openalex.org/W2162090451",
    "https://openalex.org/W2327037637",
    "https://openalex.org/W4361204756",
    "https://openalex.org/W4292402161",
    "https://openalex.org/W2071310631",
    "https://openalex.org/W1965035284",
    "https://openalex.org/W2491575731",
    "https://openalex.org/W1995632010",
    "https://openalex.org/W2008037924",
    "https://openalex.org/W2153266959",
    "https://openalex.org/W4292480695",
    "https://openalex.org/W1967802941",
    "https://openalex.org/W3118485687",
    "https://openalex.org/W2769358515",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W3047278215",
    "https://openalex.org/W4382986603",
    "https://openalex.org/W4321455981",
    "https://openalex.org/W4363624465",
    "https://openalex.org/W4387378202",
    "https://openalex.org/W4381884439",
    "https://openalex.org/W3118577024",
    "https://openalex.org/W2781265533",
    "https://openalex.org/W2153803020",
    "https://openalex.org/W3124143691",
    "https://openalex.org/W3119628700",
    "https://openalex.org/W2399852725",
    "https://openalex.org/W2102015121",
    "https://openalex.org/W3101573103",
    "https://openalex.org/W4311408938"
  ],
  "abstract": "Abstract We show that people’s perceptions of public figures’ personalities can be accurately predicted from their names’ location in GPT-3’s semantic space. We collected Big Five personality perceptions of 226 public figures from 600 human raters. Cross-validated linear regression was used to predict human perceptions from public figures’ name embeddings extracted from GPT-3. The models’ accuracy ranged from r = .78 to .88 without controls and from r = .53 to .70 when controlling for public figures’ likability and demographics, after correcting for attenuation. Prediction models showed high face validity as revealed by the personality-descriptive adjectives occupying their extremes. Our findings reveal that GPT-3 word embeddings capture signals pertaining to individual differences and intimate traits.",
  "full_text": "1\nVol.:(0123456789)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports\nLarge language models know \nhow the personality of public \nfigures is perceived by the general \npublic\nXubo Cao * & Michal Kosinski \nWe show that people’s perceptions of public figures’ personalities can be accurately predicted from \ntheir names’ location in GPT-3’s semantic space. We collected Big Five personality perceptions of 226 \npublic figures from 600 human raters. Cross-validated linear regression was used to predict human \nperceptions from public figures’ name embeddings extracted from GPT-3. The models’ accuracy \nranged from r = .78 to .88 without controls and from r = .53 to .70 when controlling for public figures’ \nlikability and demographics, after correcting for attenuation. Prediction models showed high face \nvalidity as revealed by the personality-descriptive adjectives occupying their extremes. Our findings \nreveal that GPT-3 word embeddings capture signals pertaining to individual differences and intimate \ntraits.\nPeople’s success and well-being heavily depend on how their personalities are judged by others and—\nincreasingly—algorithms1. Ranging from the first impressions based on facial  appearance2 to close friends’ well-\ninformed  opinions3, others’ perceptions affect one’s personal, educational, and occupational success; social capital; \nhealth; wealth; and many other consequential  outcomes4. Importantly, others’ perceptions matter regardless of \ntheir  accuracy3,5, as illustrated by those suffering (or benefiting) from prejudice and  stereotypes6,7.\nParticularly consequential are perceptions of public figures’ personalities. Politicians’ perceived personality \ninfluences their electoral  success8, their approval  ratings9, and even  geopolitics10. CEOs’ perceived personality \ninfluences their own success but also their companies’ reputation, valuation, and  performance11,12. Celebrities’ \nperceived personality affects the recognition, consumer attitudes, and purchase intentions toward the brands \nthey  promote13. Musicians’ perceived personality drives their music’s  popularity14. Unsurprisingly, public figures \ninvest much effort and resources into shaping others’ impressions, while researchers and practitioners across \nmany disciplines study their formation and  assessment15,16.\nPerceptions of public figures’ personalities are typically measured by surveying qualified informants or the \ngeneral public, a costly and time-consuming  approach9,12. Such perceptions are also reflected in public discourse \nand  communications17. As public discourse and journalism increasingly shift to digital environments, people’s \nviews and perceptions are now increasingly recorded in written digital sources such as blog posts, tweets, \nWikipedia entries, newspaper articles, and books. This signal is further amplified, as people’s perceptions and \nactual personality cues shape others’ perceptions, leading to self-amplifying feedback loops. Taken together, these \nphenomena suggest that costly and time-consuming surveys could be supplemented with perceived personality \nestimates extracted from digital language samples.\nPast research has confirmed that perceptions of others’ personalities could be successfully extracted from \ntexts, such as social media posts, biographies, or  books18–20. The main challenge of this approach is obtaining \nthe text corpora necessary to extract personality perception cues. Y et, this challenge has been addressed by \nthe recent explosion in the size and availability of large language models (LLMs), such as Word2Vec, BERT, \nor  GPT321–23. LLMs are trained on huge and diverse text corpora that include, among other things, language \nrevealing people’s perceptions of public figures’ personalities as well as the cues to their actual personalities. For \nexample, GPT-3—the state-of-the-art LLM model used here—was trained on the contents of billions of websites, \nthe entire English Wikipedia, and over 10,000  books23. The collection and analysis of such data are beyond the \ntechnological capacity of most researchers, not to mention the associated financial and environmental costs. For \nexample, the training of GPT-3 was estimated to cost $12 million and to emit 552 tons of carbon  dioxide24,25.\nOPEN\nStanford University, Stanford, USA. *email: xcao@stanford.edu\n2\nVol:.(1234567890)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\nPast work showed that the perceptions of public figures’ warmth and competence can be extracted from \nan earlier LLM, Google’s  Word2Vec26. Here we show that word embeddings extracted from GPT-3 23 can \npredict people’s general sentiment toward public figures (likability) as well as their perceptions of their Big Five \npersonality traits (openness , conscientiousness , extraversion, agreeableness, and emotional stability ) that were \nshown to capture much variance in individual differences and reliably predict a wide range of individual and \nsocial  outcomes27.\nMethods\nOur study focused on the 300 most popular public figures from 43 countries selected from among the 11,341 \npublic figures listed in the Pantheon 1.0  dataset28. Their popularity was approximated by their Wikipedia page \nviews between 2008 and 2013. As artists were particularly popular, we limited their number to 100 to include \npublic figures from seven other domains including business and law, exploration, humanities, institutions, science \nand technology, sports, and others. The dataset includes public figures’ gender and birth year (with some missing \ndata). As raters may have been less familiar with public figures born before 1900, we did not include them in \nour studies.\nPublic figures’ names were presented to raters employed on Prolific. Each of the 600 raters rated the likability \n(on a 200-point scale from extremely negative to extremely positive) and Big Five personality traits (on the \nTen-Item Personality Inventory; TIPI) of 10 random public  Figures29. Raters could skip targets that they were \nunfamiliar with. Public figures received 18.89 ratings on average (SD = 10.38). We removed 74 public figures who \nwere recognized (and thus rated) by fewer than 10 raters. See Supplementary Materials for the rationale and the \nintraclass correlation coefficient (ICC)30, a measure of the agreement between two or more raters.\nGPT-3 stores knowledge about words’ meaning in a 12,288-dimensional semantic space, a functional \nequivalent of the semantic memory in humans. The closer two words (or phrases) are in this space, the more \nsimilar their  meaning31. For example, “Donald Trump” is similar to “arrogant, ” while “Mother Teresa” is close \nto “sympathetic. ” The embeddings of public figures’ names, representing their location in this space, were \nentered into a Ridge  regression 26 to predict human ratings. Ridge regression is suitable for the analyses of \nhigh-dimensional data, as it reduces multicollinearity between predictors by penalizing large coefficients. The \nembeddings were standardized (by column) to ensure that the penalty was applied equally to each dimension. \nTo prevent overfitting, 20-fold cross-validation was used: Predictions for each public figure were estimated using \na model trained on all other public figures. The alpha parameter was tuned within each cross-validation fold \nusing another 20-fold cross-validation.\nLike all measures, human ratings include some errors. The split-half reliability of the ratings for the six \nattributes that we measured ranges from 0.79 to 0.88. This range serves as a benchmark for the highest accuracy \nthat a predictive model might potentially achieve. Given that our interest lies in accurately predicting actual \nperceived personalities—not imperfect proxies—we adjusted the correlations using the square root of each scale’s \nreliability, a process known as correction for  attenuation32. This adjustment enables a more equitable comparison \nof the model’s performance across various traits, notwithstanding the differing levels of agreement among human \nraters about these traits. For transparency, we also report the raw, uncorrected values.\nResults\nFigure 1 (green bars) shows that GPT-3’s embeddings accurately predicted human perceptions. The Pearson \nproduct-moment correlations between models’ predictions and human ratings ranged from r  = 0.78 for \nextraversion to r = 0.88 for openness, which translates into Cohen’s d range of d = 2.49 (huge effect) to d  = 3.75 \n(huge effect) 33. Raw accuracy (i.e., the accuracy obtained without controlling for attenuation) was also high, \nranging from r = 0.7 to r = 0.8. To put models’ accuracy in perspective, consider the following well-known \ndiagnostic accuracies: The accuracy of computer tomography when detecting metastases from head and neck \nFigure 1.  The model’s accuracy in predicting public figures’ perceived personality without any controls (green \nbars) and while controlling for likability and demographics (red bars). Confidence intervals equal 95%. Values in \nparentheses represent raw accuracy (uncorrected for attenuation). All correlations are significant at the p < .001 \nlevel.\n3\nVol.:(0123456789)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\ncancer equals r = 0.64, and the accuracy of ultrasonography when detecting peripheral artery disease is r = 0.8334. \nIn other words, public figures’ perceived personalities can be inferred from the GPT-3 embeddings of their \nnames with an accuracy comparable to how some of their ailments could be diagnosed by modern medical \ndiagnostic tools. Moreover, given that individual human ratings predicted aggregate ratings with an accuracy of \nr = [0.56—0.66], embeddings predict aggregate judgments better than individual judgments do.\nPredictions were more accurate for more popular public figures. The profile similarity between human ratings \nand model predictions was correlated with the logarithm of the number of Wikipedia pageviews at the level of \nr = 0.16 (refer to Supplementary Materials for more details). This indicates that it was more accurate for more \npopular figures that, presumably, appeared more frequently in its training data.\nTable 1 shows the top and bottom 10 public figures, arranged according to their predicted perceived \npersonality traits (full list at https:// osf. io/ 854w2). It shows that the embedding-based predictions have high \nface validity. For example, individuals predicted to be perceived as the most open-minded, liberal, creative, and \nTable 1.  Top and bottom 10 public figures according to their predicted perceived traits. Full lists at https:// osf. \nio/ 854w2.\nPublic figures\nBottom (ascending) Top (descending)\nAgreeableness\nKim Jong-il\nOsama bin Laden\nSaddam Hussein\nDonald Trump\nKim Jong-un\nZodiac Killer\nVladimir Putin\nCharles Manson\nSimon Cowell\nLee Harvey Oswald\nPope John Paul II\nSteve Irwin\nAudrey Hepburn\nAnne Frank\nJulia Child\nJoseph Gordon-Levitt\nMother Teresa\nJacqueline Kennedy Onassis\nRyan Reynolds\nEmma Watson\nConscientiousness\nCharlie Sheen\nDonald Trump\nBam Margera\nCharles Manson\nAmy Winehouse\nLindsay Lohan\nO. J. Simpson\nKurt Cobain\nKanye West\nJames Franco\nSerena Williams\nBruce Lee\nNelson Mandela\nWarren Buffett\nNeil Armstrong\nJackie Chan\nY ao Ming\nStephen Hawking\nJulia Child\nBill Gates\nEmotional Stability\nZodiac Killer\nCharles Manson\nDonald Trump\nLee Harvey Oswald\nJeffrey Dahmer\nKim Jong-un\nJim Jones\nO. J. Simpson\nSaddam Hussein\nKanye West\nPope John Paul II\nNelson Mandela\nBruce Lee\nBarack Obama\nMother Teresa\nBear Grylls\nJoseph Gordon-Levitt\nJackie Chan\nIndira Gandhi\nJimmy Carter\nExtraversion\nMark Zuckerberg\nLee Harvey Oswald\nKristen Stewart\nAlan Turing\nElizabeth II of the United Kingdom\nJeffrey Dahmer\nY ao Ming\nZodiac Killer\nHoward Hughes\nStephen King\nSteve Irwin\nBam Margera\nJim Carrey\nDennis Rodman\nConan O’Brien\nNicki Minaj\nHulk Hogan\nMiley Cyrus\nOprah Winfrey\nChris Jericho\nOpenness\nKim Jong-un\nKim Jong-il\nRichard Nixon\nMitt Romney\nGeorge H. W . Bush\nMargaret Thatcher\nElizabeth II of the United Kingdom\nDonald Trump\nDick Cheney\nGeorge Bush\nFreddie Mercury\nDavid Bowie\nMichael Jackson\nLady Gaga\nJimi Hendrix\nSir Richard Branson\nBam Margera\nJulia Child\nQuentin Tarantino\nSteve Irwin\nLikability\nZodiac Killer\nTed Bundy\nJim Jones\nOsama bin Laden\nJeffrey Dahmer\nKim Jong-il\nSaddam Hussein\nLee Harvey Oswald\nCharles Manson\nKim Jong-un\nAnne Frank\nRosa Parks\nJulia Child\nSteve Irwin\nNelson Mandela\nJackie Robinson\nJoseph Gordon-Levitt\nAudrey Hepburn\nGeorge Orwell\nSimon Pegg\n4\nVol:.(1234567890)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\nartistic (i.e., high openness) included mostly artists: Freddie Mercury, David Bowie, Michael Jackson, Lady Gaga, \nJimi Hendrix, and Quentin Tarantino. In contrast, those predicted to be perceived as the most conservative and \ntraditional (i.e., low openness) included mostly autocrats (Kim Jong-un and Kim Jong-il); conservative politicians \n(Richard Nixon, Mitt Romney, George H. W . Bush, Margaret Thatcher, Donald Trump, Dick Cheney, and George \nBush); and Queen Elizabeth II.\nA closer inspection of the names presented in Table  1 suggests a link between models’ predictions and \npublic figures’ profession. Gender seems to play a role, too, with women dominating the top of the perceived \nagreeableness ranking and entirely absent from its bottom. Moreover, personality perceptions are linked with \nlikability: Many of the least likable figures (e.g., Lee Harvey Oswald, Charles Manson, and both Kims) appear \nrepeatedly on the socially undesirable (i.e., low) extrema of the perceived personality trait. As detailed in Table 2, \npublic figures’ likability, birth year, and gender significantly correlate with perceived personality in our sample. \nBirth year, for example, correlates strongly and negatively with both human ratings of extraversion (r = 0.35) \nand GPT-3’s prediction (r = 0.44).\nSuch links are not necessarily problematic, as they represent actual phenomena. Studies show that both actual \nand perceived personality correlate with profession, gender, age, and  likability35,36. Women, for example, tend to \nbe both: more agreeable than  men37 and perceived as  such7. People with desirable personalities are more likable, \nand likable people are perceived to have desirable personalities (i.e., “personality halo effect”) 38. Y et, such links \nalso imply that it is sufficient to predict demographics and likability to estimate—with some accuracy—perceived \npersonality.\nCould models predict perceived personality beyond  what is explained by likability and demographics? To \nanswer this question, we regress the human perceptions of each of the personality traits against public figures’ \nlikability and demographics. The residuals of these models represent perceived personality traits cleaned of \nthe influence of these variables. Next, we predict these residuals from public figures’ names’ embeddings using \nRidge regression.\nThe results presented in Fig. 1 (red bars) show that GPT-3 can accurately predict perceived personality even \nwhen controlling for demographics and likability. The accuracy decreased but remained very high, ranging from \nr = 0.53 for emotional stability to r = 0.70 for extraversion, which translates into Cohen’s d range of d = 1.25 (very \nlarge effect) to d = 1.96 (very large effect). The raw (uncorrected) accuracies range from r = 0.43 to r = 0.61. To \nput those results in perspective, consider the following well-known diagnostic accuracies: The accuracy of dental \nX-rays when detecting between-tooth cavities equals r = 0.43; the accuracy of ultrasound results when detecting \ndeep venous thrombosis equals r = 0.6034. In other words, even when controlling for demographics and likability, \nname embeddings allow for diagnosing public figures’ perceived personalities, as widely used medical diagnostic \ntools allow for diagnosing dental cavities or venous thrombosis. For further comparison, the accuracy of models \nemploying people’s language to predict their own self-reported Big Five scores is about r = 0.4039.\nThe regression models trained here can be further interpreted, as they span GPT-3’s semantic space filled with \ninterpretable words and concepts. For example, the line defined by the regression model predicting perceived \nextraversion stretches from the edge of semantic space occupied by public figures perceived to be the most \nintroverted to the edge occupied by those perceived to be the most extraverted. To further interpret the models, \nwe map the location of 525 person-descriptive adjectives obtained  from40 on these regression lines. (Or, in other \nwords, we computed the predicted scores for these adjectives.)\nThe adjectives maximizing and minimizing the models’ predictions can be found in Table  3 (scores for all \n525 adjectives are at https://  osf. io/ 854w2). Those results are highly congruent with the definitions of the Big \nTable 2.  Means, standard deviations, and correlations between human judgments, model predictions, and \ndemographic variables. N = 226. M and SD represent mean and standard deviation, respectively. *Indicates \np < 0.05. **Indicates p < 0.01.\nVariable M SD 1 2 3 4 5 6 7 8 9 10 11 12 13\n1. Birth year 1958.87 23.74\n2. Female 0.27 0.44 0.26**\n3. Likability 29.02 39.01 0.13 0.18**\n4. Agreeableness 4.24 1.05 0.14* 0.28** 0.89**\n5. Conscientiousness 5.25 0.79 − 0.17** 0.01 0.62** 0.56**\n6. Extraversion 5.01 0.84 0.35** 0.07 0.16* 0.10 − 0.15*\n7. Emotional Stability 4.49 0.93 − 0.08 0.04 0.75** 0.77** 0.82** − 0.05\n8. Openness 5.17 0.76 0.21** 0.12 0.62** 0.54** 0.21** 0.37** 0.25**\n9. Likability Prediction 29.09 30.43 0.20** 0.21** 0.80** 0.75** 0.48** 0.09 0.62** 0.52**\n10. Predicted Agreeableness 4.25 0.83 0.22** 0.33** 0.75** 0.80** 0.43** 0.07 0.60** 0.46** 0.90**\n11. Predicted \nConscientiousness 5.25 0.59 − 0.16* 0.03 0.50** 0.44** 0.72** − 0.21** 0.67** 0.11 0.64** 0.56**\n12. Predicted Extraversion 5.02 0.63 0.44** 0.10 0.10 0.08 − 0.20** 0.70** − 0.06 0.25** 0.24** 0.16* − 0.14*\n13. Predicted Emotional \nStability 4.49 0.70 − 0.07 0.06 0.65** 0.63** 0.67** − 0.08 0.77** 0.20** 0.76** 0.76** 0.85** − 0.05\n14. Predicted Openness 5.17 0.63 0.28** 0.14* 0.52** 0.46** 0.11 0.23** 0.19** 0.79** 0.68** 0.58** 0.19** 0.40** 0.24**\n5\nVol.:(0123456789)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\nFive personality traits. For example, adjectives at the bottom of the extraversion scale include “quiet, ” “lonely, ” \n“depressed, ” “boring, ” “lonesome, ” “thoughtful, ” “withdrawn, ” “soft-spoken, ” “philosophical, ” and “thinking”; \nwhile those on top include “entertaining, ” “hilarious, ” “lively, ” “glamorous, ” “comical, ” “sexy, ” “energetic, ” “playful, ” \nand “good-humored. ” It seems that public figures’ humor, instead of their sociability, is the most salient cue of \nextraversion to laypeople.\nInterestingly, those lists correctly captured behavioral correlates of personality. The regression models were \ntrained on human responses to a 10-item personality questionnaire that never mentioned alcohol. Y et, it ranked \n“alcoholic” as the third (out of 525) adjective most characteristic of low perceived conscientiousness, the third \nadjective most characteristic of low perceived emotional stability, and the 42nd adjective most characteristic \nof low agreeableness. This is consistent with past research findings, which linked alcohol addiction with low \nconscientiousness, low agreeableness, and low emotional  stability41. Moreover, the results reflect the correlation \nbetween the likability of a public figure and the desirability of their perceived personality (i.e., “personality halo \nTable 3.  The 10 person-descriptive adjectives maximizing and minimizing the predictions of a model trained \nto predict human perceptions. Full lists at https:// osf. io/ 854w2.\nPerson descriptive adjectives\nBottom (ascending) Top (descending)\nAgreeableness\nCorrupt\nEvil\nControversial\nViolent\nAbusive\nJealous\nInsulting\nDishonest\nTerrible\nIntimidating\nWarm-Hearted\nKind-Hearted\nCompassionate\nAffectionate\nAdorable\nGentle\nGood-Natured\nCute\nLovable\nCaring\nConscientiousness\nIrresponsible\nIncompetent\nAlcoholic\nMessy\nDisorganized\nSloppy\nEmbarrassing\nUnstable\nTroubled\nDisgusting\nSensible\nSmart\nBusinesslike\nIntelligent\nEfficient\nPunctual\nAdmirable\nWise\nRespectable\nAthletic\nEmotional Stability\nIrresponsible\nIncompetent\nAlcoholic\nMessy\nDisorganized\nSloppy\nEmbarrassing\nUnstable\nTroubled\nDisgusting\nGracious\nWarm-Hearted\nStraightforward\nWise\nSensible\nThankful\nAppreciative\nAdmirable\nCheerful\nGentle\nExtraversion\nQuiet\nLonely\nDepressed\nBoring\nLonesome\nThoughtful\nWithdrawn\nSoft-Spoken\nPhilosophical\nThinking\nEntertaining\nHilarious\nLively\nGlamorous\nComical\nSexy\nEnergetic\nPlayful\nGood-Humored\nCocky\nOpenness\nConservative\nNarrow-Minded\nClosed-Minded\nCorrupt\nTerrible\nUnfair\nPrejudiced\nStupid\nIncompetent\nUnsympathetic\nFashionable\nCreative\nArtistic\nInspirational\nEntertaining\nExpressive\nImaginative\nRomantic\nAdventurous\nGlamorous\nLikability\nEvil\nCorrupt\nTerrible\nDisgusting\nAwful\nGuilty\nViolent\nHostile\nIncompetent\nBad\nWarm-Hearted\nKind-Hearted\nInspirational\nCompassionate\nGracious\nThoughtful\nAppreciative\nRespectful\nSentimental\nGrateful\n6\nVol:.(1234567890)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\neffect”). For example, “corrupt” was associated with undesirable (low) levels of agreeableness, emotional stability, \nand openness.\nDiscussion\nOur results indicate that public figures’ perceived personality can be accurately predicted from their names’ \nlocation in GPT-3’s semantic space. Our models remained accurate even when controlling for public figures’ \ndemographics and overall likability. Moreover, the models showed high face validity as revealed by the \nexamination of public figures predicted to score at the top/bottom of each of the traits, as well as the personality-\ndescriptive adjectives occupying the models’ extremes.\nThese findings have multiple implications. First, they show that LLMs’ semantic spaces can be used to study \nand approximate people’s personality perceptions. This could be of interest to researchers and practitioners \nacross disciplines ranging from political psychology to organizational behavior. Second, the research expands \nour understanding of word embeddings, which bear some similarity to human semantic  memory31. They are \nknown to encode words’  meanings42, including information about group  stereotypes43–45. Our results show that \nthey also capture individual differences, like individuals’ perceived personality traits. Our studies add to the \ngrowing body of social science research utilizing LLMs. For example, recent studies have found that LLMs can \npredict the directional relationships between ideological  attitudes46, approximate the voting choices of different \nsocial  groups47, and mirror human behavior in economic  games48 and reasoning  tasks49, as well as pass theory \nof mind  tests50.\nOur studies focused on predicting the perceived personality of public figures with sufficient presence in the \nsample used to train GPT-3. Y et, a similar approach could be used to measure the perceived personality of people \nabsent from the training data. Given a sample of text describing an individual, one could estimate its location in \nthe model’s semantic space and convert it into perceived personality using regression models trained on public \nfigures. Another limitation of our approach is that it requires collecting human ratings to train regression models. \nY et, given the alignment between our models and personality-descriptive adjectives, it is likely that similar \nresults could be achieved without collecting human ratings. Instead, one could predict public figures’ perceived \npersonality by estimating their distance from personality-descriptive adjectives or by asking generative language \nmodels to describe a person using person-descriptive adjectives, as we did in our follow-up  study51. People similar \nto “outgoing” and dissimilar to “shy, ” for example, could be classified as extraverted. Finally, models’ predictions \nare focused on the period reflected in the training data. For example, if people changed their mind about a given \npublic figure, it would take until the next model training cycle for this change to be reflected in the embeddings.\nThe feasibility of automated extraction of perceived traits exposes a potential privacy  threat 52. Word \nembeddings may contain information about traits that the target would prefer to keep private. Even if there are \nno explicit cues in the training data, the models may still be able to extract intimate information. This mirrors \nprivacy threats pertaining to other data types. For example, people are not very accurate when predicting others’ \nintimate traits from their facial images or Facebook Likes and thus do not perceive such data as overly sensitive. \nY et, computer algorithms achieve high accuracy when extracting personality, political orientation, and even \nsexual orientation from such data  sources52–54. The current results show that the impression of intimate traits of \npublic figures can be easily extracted from widely available LLMs. As the collective impression of an individual \noften correlates with their actual traits, this could amount to a potential threat to  privacy17,55.\nData availability\nThe data and code that support the findings of this study are available at: https:// osf. io/ 854w2.\nReceived: 14 August 2023; Accepted: 15 March 2024\nReferences\n 1. Y ouyou, W ., Kosinski, M. & Stillwell, D. Computer-based personality judgments are more accurate than those made by humans. \nProc. Natl. Acad. Sci. USA 112, 1036–1040 (2015).\n 2. Todorov, A. T., Said, C. C. & Verosky, S. C. Personality Impressions from Facial Appearance (Oxford University Press, 2011).\n 3. Vazire, S. Who knows what about a person? The self-other knowledge asymmetry (SOKA) model. J. Pers. Soc. Psychol. 98, 281–300 \n(2010).\n 4. Goffman, E. The presentation of self in everyday life. In Social Theory Re-Wired (ed. Goffman, E.) (Routledge, 2016).\n 5. McAbee, S. T. & Connelly, B. S. A multi-rater framework for studying personality: The trait-reputation-identity model. Psychol. \nRev. 123, 569–591 (2016).\n 6. Eagly, A. H. & Karau, S. J. Role congruity theory of prejudice toward female leaders. Psychol. Rev. 109, 573 (2002).\n 7. Ellemers, N. Gender stereotypes. Annu. Rev. Psychol. 69, 275–298 (2018).\n 8. Bittner, A. Platform or Personality?: The Role of Party Leaders in Elections (Oxford University Press, 2011).\n 9. Klingler, J. D., Hollibaugh, G. E. & Ramey, A. J. What I like about you: Legislator personality and legislator approval. Polit. Behav. \n41, 499–525 (2019).\n 10. Kellner, D. Celebrity diplomacy, spectacle and Barack Obama. Celebr. Stud. 1, 121–123 (2010).\n 11. Harrison, J. S., Thurgood, G. R., Boivie, S. & Pfarrer, M. D. Perception is reality: How CEOs’ observed personality influences market \nperceptions of firm risk and shareholder returns. Acad. Manag. J. 63, 1166–1195 (2020).\n 12. O’Reilly, C. A., Caldwell, D. F ., Chatman, J. A. & Doerr, B. The promise and problems of organizational culture: CEO personality, \nculture, and firm performance. Group Organ. Manag. 39, 595–625 (2014).\n 13. Pradhan, D., Duraipandian, I. & Sethi, D. Celebrity endorsement: How celebrity–brand–user personality congruence affects brand \nattitude and purchase intention. J. Mark. Commun. 22, 456–473 (2016).\n 14. Greenberg, D. M., Matz, S. C., Schwartz, H. A. & Fricke, K. R. The self-congruity effect of music. J. Pers. Soc. Psychol. 121, 137–150 \n(2021).\n 15. McGraw, K. Political impressions: Formation and management. In Oxford Handbook of Political Psychology (eds Sears, D. O. et al.) \n394–432 (Oxford University Press, 2003).\n7\nVol.:(0123456789)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\n 16. Chen, C. C. & Meindl, J. R. The construction of leadership Images in the popular press: The case of Donald burr and people express. \nAdm. Sci. Q. 36, 521 (1991).\n 17. Craik, K. H. Reputation: A Network Interpretation (Oxford University PressNew Y ork, 2008).\n 18. Simonton, D. K. Presidential personality. Biographical use of the Gough Adjective Check List. J Pers Soc Psychol 51, 149 (1986).\n 19. Simonton, D. K. Historiometry in personality and social psychology. Soc. Personal. Psychol. 3, 49–63 (2009).\n 20. Tskhay, K. O. & Rule, N. O. Perceptions of personality in text-based media and OSN: A meta-analysis. J. Res. Pers. 49, 25–30 (2014).\n 21. J. Devlin, M. W . Chang, K. Lee, K. Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding. \nNAACL HLT 2019–2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human \nLanguage Technologies—Proc. of the Conference 1, 4171–4186 (2019).\n 22. TK. Mikolov. Chen, G. Corrado, J. Dean, Efficient estimation of word representations in vector space” in 1st International Conference \non Learning Representations, ICLR 2013—Workshop Track Proc. (2013).\n 23. Brown, T. B. et al. Language models are few-shot learners. Adv. Neural Inform. Process. Syst. 33, 1877 (2020).\n 24. A. Shaabana, The future of AI is decentralized, Towards Data Science . https:// towar dsdat ascie nce. com/ the- future- of- ai- is- decen \ntrali zed- 848d4 931a2 9a. (2021)\n 25. K. Wiggers, Google-led paper pushes back against claims of AI inefficiency, VentureBeat https:// ventu rebeat. com/ ai/ google- led- \npaper- pushes- back- again st- claims- of- ai- ineffi  cien cy/. (2021).\n 26. Richie, R., Zou, W . & Bhatia, S. Predicting high-level human judgment across diverse behavioral domains. Collabra. Psychol.  5, \n1–12 (2019).\n 27. Ozer, D. J. & Benet-Martínez, V . Personality and the prediction of consequential outcomes. Annu. Rev. Psychol. 57, 401–421 (2006).\n 28. Yu, A. Z., Ronen, S., Hu, K., Lu, T. & Hidalgo, C. A. Pantheon 1.0, a manually verified dataset of globally famous biographies. Sci. \nData https:// doi. org/ 10. 1038/ sdata. 2015. 75 (2016).\n 29. Gosling, S. D., Rentfrow, P . J. & Swann, W . B. A very brief measure of the big-five personality domains. J. Res. Pers. 37, 504–528 \n(2003).\n 30. Koo, T. K. & Li, M. Y . A guideline of selecting and reporting intraclass correlation coefficients for reliability research. J. Chiropr. \nMed. 15, 155–163 (2016).\n 31. Digutsch, J. & Kosinski, M. Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans. Sci. Rep. \n13, 5035 (2023).\n 32. Spearman, C. The proof and measurement of association between two things. Am. J. Psychol. 100, 441 (1987).\n 33. Sawilowsky, S. S. New effect size rules of thumb. J. Mod. Appl. Stat. Methds 8, 26 (2009).\n 34. Meyer, G. J. et al. Psychological testing and psychological assessment: A review of evidence and issues. Am. Psychol. 56, 128–165 \n(2001).\n 35. Cejka, M. A. & Eagly, A. H. Gender-stereotypic images of occupations correspond to the sex segregation of employment. Pers. \nSoc. Psychol. Bull. 25, 413–423 (1999).\n 36. Back, M. D. & Nestler, S. Accuracy of judging personality. In The Social Psychology of Perceiving Others Accurately (eds Hall, J. A. \net al.) 98–124 (Cambridge University Press, 2016).\n 37. Costa, P . T., Terracciano, A. & McCrae, R. R. Gender differences in personality traits across cultures: Robust and surprising findings. \nJ. Personal. Soc. Psychol. 81, 322–331 (2001).\n 38. Nisbett, R. E. & Wilson, T. D. The halo effect: Evidence for unconscious alteration of judgments. J. Pers. Soc. Psychol. 35, 250 (1977).\n 39. Park, G. et al. Automatic personality assessment through social media language. J. Pers. Soc. Psychol. 108, 934–952 (2015).\n 40. Saucier, G. Effects of variable selection on the factor structure of person descriptors. J. Personal. Soc. Psychol. 73, 1296–1312 (1997).\n 41. Malouff, J. M., Thorsteinsson, E. B., Rooke, S. E. & Schutte, N. S. Alcohol involvement and the Five-Factor model of personality: \nA meta-analysis. J. Drug. Educ. 37, 277–294 (2007).\n 42. Rogers, A., Kovaleva, O. & Rumshisky, A. A Primer in BERTology: What we know about how BERT works. Trans. Assoc. Comput. \nLinguist. 8, 842–866 (2020).\n 43. Garg, N., Schiebinger, L., Jurafsky, D. & Zou, J. Word embeddings quantify 100 years of gender and ethnic stereotypes. Proc. Natl. \nAcad. Sci. USA 115, E3635–E3644 (2018).\n 44. Caliskan, A., Bryson, J. J. & Narayanan, A. Semantics derived automatically from language corpora contain human-like biases. \nScience 1979(356), 183–186 (2017).\n 45. Lewis, M. & Lupyan, G. Gender stereotypes are reflected in the distributional structure of 25 languages. Nat. Hum. Behav. 4, \n1021–1028 (2020).\n 46. Rosenbusch, H., Stevenson, C. E. & van der Maas, H. L. J. How accurate are GPT-3’s hypotheses about social science phenomena?. \nDigit. Soc. https:// doi. org/ 10. 1007/ s44206- 023- 00054-2 (2023).\n 47. Argyle, L. P . et al. Out of one, many: Using language models to simulate human samples. Polit. Anal. 31, 337–351 (2023).\n 48. J. Horton, “Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?” (Cambridge, MA); \nhttp:// www. nber. org/ papers/ w31122. pdf. (2023).\n 49. Hagendorff, T., Fabi, S. & Kosinski, M. Human-like intuitive behavior and reasoning biases emerged in large language models but \ndisappeared in ChatGPT. Nat. Comput. Sci. 3, 833–838 (2023).\n 50. M. Kosinski, Theory of mind might have spontaneously emerged in large language models. Preprint at http:// arxiv. org/ abs/ 2302. \n02083. (2023).\n 51. X. Cao, M. Kosinski, ChatGPT can accurately predict public figures perceived personalities without any training. https:// doi. org/ \n10. 31234/ osf. io/ zbhyk. (2023).\n 52. Kosinski, M. Facial recognition technology can expose political orientation from naturalistic facial images. Sci. Rep. 11, 1–7 (2021).\n 53. Wang, Y . & Kosinski, M. Deep neural networks are more accurate than humans at detecting sexual orientation from facial images. \nJ. Personal. Soc. Psychol. 114, 246–257 (2018).\n 54. Kosinski, M., Stillwell, D. J. & Graepel, T. Private traits and attributes are predictable from digital records of human behavior. Proc. \nNatl. Acad. Sci. 110, 5802–5805 (2013).\n 55. Oh, I. S., Wang, G. & Mount, M. K. Validity of observer ratings of the five-factor model of personality traits: A meta-analysis. J. \nAppl. Psychol. 96, 762–773 (2011).\nAuthor contributions\nXC and MK conceived the studies and wrote the manuscript. XC conducted the statistical analyses and designed \nthe figures.\nFunding\nThe authors did not receive funding in support for this research.\nCompeting interests \nThe authors declare no competing interests.\n8\nVol:.(1234567890)Scientific Reports |         (2024) 14:6735  | https://doi.org/10.1038/s41598-024-57271-z\nwww.nature.com/scientificreports/\nAdditional information\nSupplementary Information The online version contains supplementary material available at https:// doi. org/ \n10. 1038/ s41598- 024- 57271-z.\nCorrespondence and requests for materials should be addressed to X.C.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution 4.0 International \nLicense, which permits use, sharing, adaptation, distribution and reproduction in any medium or \nformat, as long as you give appropriate credit to the original author(s) and the source, provide a link to the \nCreative Commons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the \nmaterial. If material is not included in the article’s Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from \nthe copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\n© The Author(s) 2024",
  "topic": "Perception",
  "concepts": [
    {
      "name": "Perception",
      "score": 0.6245755553245544
    },
    {
      "name": "Personality",
      "score": 0.5968949198722839
    },
    {
      "name": "Demographics",
      "score": 0.5772998929023743
    },
    {
      "name": "Personality psychology",
      "score": 0.5536825060844421
    },
    {
      "name": "Psychology",
      "score": 0.5062257647514343
    },
    {
      "name": "Big Five personality traits",
      "score": 0.48619741201400757
    },
    {
      "name": "Social psychology",
      "score": 0.4261203408241272
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.4240506887435913
    },
    {
      "name": "Computer science",
      "score": 0.3534848690032959
    },
    {
      "name": "Sociology",
      "score": 0.18011286854743958
    },
    {
      "name": "Demography",
      "score": 0.12206152081489563
    },
    {
      "name": "Social science",
      "score": 0.09898346662521362
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ]
}