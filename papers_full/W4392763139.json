{
    "title": "Can Large Language Models be sensitive to Culture Suicide Risk Assessment?",
    "url": "https://openalex.org/W4392763139",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2254384207",
            "name": "Inbar Levkovich",
            "affiliations": [
                "Oranim Academic College of Education"
            ]
        },
        {
            "id": "https://openalex.org/A4220280895",
            "name": "Shiri Shinan‐Altman",
            "affiliations": [
                "Bar-Ilan University"
            ]
        },
        {
            "id": "https://openalex.org/A2999569850",
            "name": "Zohar Elyoseph",
            "affiliations": [
                "Max Stern Academic College of Emek Yezreel"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3177387832",
        "https://openalex.org/W3049024012",
        "https://openalex.org/W2195835703",
        "https://openalex.org/W2989632318",
        "https://openalex.org/W2775173797",
        "https://openalex.org/W2925142242",
        "https://openalex.org/W2067720842",
        "https://openalex.org/W4386117324",
        "https://openalex.org/W2986567973",
        "https://openalex.org/W2942610717",
        "https://openalex.org/W4385459268",
        "https://openalex.org/W2982426056",
        "https://openalex.org/W2916945592",
        "https://openalex.org/W4367694135",
        "https://openalex.org/W2800212907",
        "https://openalex.org/W2793876502",
        "https://openalex.org/W2809649016",
        "https://openalex.org/W2985355520",
        "https://openalex.org/W3105932479",
        "https://openalex.org/W2978918383",
        "https://openalex.org/W3194427467",
        "https://openalex.org/W2997260894",
        "https://openalex.org/W2626145987",
        "https://openalex.org/W2898555441",
        "https://openalex.org/W4225320885",
        "https://openalex.org/W6602884171",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W1031503832",
        "https://openalex.org/W4295049507",
        "https://openalex.org/W2606340685",
        "https://openalex.org/W2131834520",
        "https://openalex.org/W2015120682",
        "https://openalex.org/W3112043726",
        "https://openalex.org/W4386887838",
        "https://openalex.org/W2122092337",
        "https://openalex.org/W2790016400",
        "https://openalex.org/W3143787677",
        "https://openalex.org/W2101519269",
        "https://openalex.org/W4365512576",
        "https://openalex.org/W4317910584",
        "https://openalex.org/W4327946446",
        "https://openalex.org/W2060277868",
        "https://openalex.org/W2105473993",
        "https://openalex.org/W4387439164",
        "https://openalex.org/W4376871976",
        "https://openalex.org/W4316143341",
        "https://openalex.org/W4385739769",
        "https://openalex.org/W3010667303",
        "https://openalex.org/W1973717185"
    ],
    "abstract": "<title>Abstract</title> Suicide remains a pressing global public health issue. Previous studies have shown the promise of Generative Intelligent (GenAI) Large Language Models (LLMs) in assessing suicide risk in relation to professionals. But the considerations and risk factors that the models use to assess the risk remain as a black box. This study investigates if ChatGPT-3.5 and ChatGPT-4 integrate cultural factors in assessing suicide risks (probability of suicidal ideation, potential for suicide attempt, likelihood of severe suicide attempt, and risk of mortality from a suicidal act) by vignette methodology. The vignettes examined were of individuals from Greece and South Korea, representing countries with low and high suicide rates, respectively. The contribution of this research is to examine risk assessment from an international perspective, as large language models are expected to provide culturally-tailored responses. However, there is a concern regarding cultural biases and racism, making this study crucial. In the evaluation conducted via ChatGPT-4, only the risks associated with a severe suicide attempt and potential mortality from a suicidal act were rated higher for the South Korean characters than for their Greek counterparts. Furthermore, only within the ChatGPT-4 framework was male gender identified as a significant risk factor, leading to a heightened risk evaluation across all variables. ChatGPT models exhibit significant sensitivity to cultural nuances. ChatGPT-4, in particular, offers increased sensitivity and reduced bias, highlighting the importance of gender differences in suicide risk assessment.",
    "full_text": "Page 1/18\nCan Large Language Models be sensitive to Culture\nSuicide Risk Assessment?\nInbar Levkovich \nOranim Academic College\nShiri Shinan-Altman \nBar-Ilan University\nZohar Elyoseph \nMax Stern Yezreel Valley College\nResearch Article\nKeywords: Arti\u0000cial Intelligence, bias, cultural diversity, gender, suicide, mental health\nPosted Date: March 13th, 2024\nDOI: https://doi.org/10.21203/rs.3.rs-4066705/v1\nLicense:   This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nAdditional Declarations: No competing interests reported.\nVersion of Record: A version of this preprint was published at Journal of Cultural Cognitive Science on\nNovember 2nd, 2024. See the published version at https://doi.org/10.1007/s41809-024-00151-9.\nPage 2/18\nAbstract\nSuicide remains a pressing global public health issue. Previous studies have shown the promise of\nGenerative Intelligent (GenAI) Large Language Models (LLMs) in assessing suicide risk in relation to\nprofessionals. But the considerations and risk factors that the models use to assess the risk remain as a\nblack box.\nThis study investigates if ChatGPT-3.5 and ChatGPT-4 integrate cultural factors in assessing suicide risks\n(probability of suicidal ideation, potential for suicide attempt, likelihood of severe suicide attempt, and\nrisk of mortality from a suicidal act) by vignette methodology. The vignettes examined were of\nindividuals from Greece and South Korea, representing countries with low and high suicide rates,\nrespectively. The contribution of this research is to examine risk assessment from an international\nperspective, as large language models are expected to provide culturally-tailored responses. However,\nthere is a concern regarding cultural biases and racism, making this study crucial.\nIn the evaluation conducted via ChatGPT-4, only the risks associated with a severe suicide attempt and\npotential mortality from a suicidal act were rated higher for the South Korean characters than for their\nGreek counterparts. Furthermore, only within the ChatGPT-4 framework was male gender identi\u0000ed as a\nsigni\u0000cant risk factor, leading to a heightened risk evaluation across all variables. ChatGPT models\nexhibit signi\u0000cant sensitivity to cultural nuances. ChatGPT-4, in particular, offers increased sensitivity and\nreduced bias, highlighting the importance of gender differences in suicide risk assessment.\nIntroduction\nAssessing suicide risk is a complex and multifaceted challenge that requires consideration of a wide\nrange of personal, social, and cultural factors (Graney et al., 2020). With the development of AI-based\nmodels like ChatGPT, new opportunities have emerged to improve the accuracy and e\u0000ciency of risk\nassessment processes (Levkovich & Elyoseph, 2023). However, the considerations and risk factors that\nthese models use to assess risk remain a black box. To fully harness the potential of these technologies,\nit is crucial to examine their ability to account for cultural and gender differences when conducting risk\nassessments. While large language models (LLMs) hold the promise of providing culturally tailored\nresponses (Elyoseph et al., 2024) there is a concern that cultural biases and the fear of being perceived\nas racist may hinder the integration of important cultural factors into clinical judgment (Elyoseph et al.,\n2024; Hadar-Shoval et al., 2024). This research aims to investigate how advanced language models,\nsuch as ChatGPT-3.5 and ChatGPT-4, incorporate culture- and gender-related risk factors into their\nsuicide risk assessments. This examination is vital for developing culturally sensitive and effective tools\nfor suicide risk assessment that can help bridge gaps in mental health services worldwide.\nArti\u0000cial intelligence (AI) has been applied in a myriad of \u0000elds, from medicine to mental health\n(Elyoseph & Levkovich, 2023; Kang, 2021; Tal et al, 2023; Xu et al., 2023). In the realm of cultural diversity,\nAI offers promise in addressing mental health disparities by tailoring interventions to historically\nunderserved populations, transcending language barriers, and promoting cultural sensitivity (Fiske et al.,\nPage 3/18\n2019; van Heerden et al., 2023). These endeavors include creating mental health programs in\nunderrepresented languages and supporting community-focused initiatives. Nevertheless, AI can also\nintroduce inequalities due to variable access, language limitations, and cultural biases (Elyoseph &\nLevkovich, 2023; Wampold & Flückiger, 2023). Therefore, in utilizing AI in mental health we must consider\nthe impact within diverse cultural contexts and balance the potential bene\u0000ts and challenges. The\ncurrent study examines the use of arti\u0000cial intelligence in the \u0000eld of suicide assessment in the context\nof cultural and gender differences.\nSuicide constitutes a critical challenge within the sphere of public health that necessitates immediate\nattention and intervention (Levi-Belz et al., 2022; Qian, 2021; WHO, 2020). Suicidality, an urgent concern\nwithin public health, is beset by obstacles to accurate assessment, including issues related to\npsychometric intricacies as well as barriers in community accessibility (Baek et al.,2021). The complex\nissue of suicide covers a spectrum of behaviors ranging from suicidal thoughts to serious attempts and\nactual deaths (Knipe et al., 2022). These actions vary in severity and have broad social and public health\nimpacts (Gvion & Levi-Belz, 2018). Risk factors differ across demographic and social groups, re\u0000ecting\nboth individual and societal well-being (Feigelman et al., 2019). Despite academic focus on demographic\nand economic factors, the varying rates across countries highlight that no single factor provides a full\nexplanation (Bowden et al., 2020).\nResearch literature has devoted substantial resources toward developing evidence-based preventative\nmeasures, underscoring the pivotal role played by healthcare professionals in the early detection and\ncrisis management of at-risk individuals (Bolton et al.,2015). To extend the reach of risk assessment\nprotocols, recent initiatives have invested in training community gatekeepers (Bolton et al.,2015).\nArti\u0000cial Intelligence (AI) has emerged as a viable mechanism for augmenting the decision-making\nabilities of these community \u0000gures, with prospective advantages in terms of both diagnostic precision\nand public reach (Elyoseph & Levkovich, 2023; Levkovich & Elyoseph, 2023). Nevertheless, the capacity\nof AI algorithms to account for multicultural sensitivities has not been adequately examined. The present\ninquiry seeks to redress this lacuna by scrutinizing the manner in which AI algorithms allocate weight to\nsalient cultural variables in their assessments of suicidality.\nThe Organization for Economic Co-operation and Development (WHO, 2020) published the following\ndata, originally taken from the WHO Mortality Database: South Korea has the highest suicide rate in the\ndeveloped world, with 24.1 suicides per 100,000 people (Kim et al., 2019). In contrast, the suicide rate in\nGreece is as low as 3.9 per 100,000 people. In this study, we chose to examine the country that tops the\nsuicide frequency list as well as one that is at the bottom. Due to underreporting in different countries,\nactual rates may vary.\nMore than 800,000 individuals worldwide succumb to suicide each year (WHO, 2020). South Korea\nexhibits the highest incidence of suicide among OECD countries, with prevalence prominently higher\namong males and older adults. The suicide rate in South Korea is more than double the OECD average,\nwhich stands at 11.0 suicides per 100,000 people (WHO, 2020). Beginning in 1992, the aggregate rate of\nPage 4/18\nsuicide in South Korea has exhibited an upward trajectory. This escalating trend was notably\nexacerbated in 1998, coinciding with the onset of the International Monetary Fund (IMF) crisis. Moreover,\nit subsequently intensi\u0000ed in 2009, in the immediate aftermath of the global \u0000nancial crisis (Baek et al.,\n2021). Supplementary explanations for this trend chie\u0000y attribute it to demographic aging, with a\nconcomitant rise in suicide rates particularly among older and middle-aged populations (Kim et al., 2020;\nLee et al., 2017). The erosion of traditional family-centered values coupled with economic deprivation\namong older adults have been posited as contributing factors to the rise in the number of suicides within\nthis demographic group (Chang et al., 2009). Additionally, the marked escalation in suicides by gas\npoisoning, which surged more than twenty-fold during the \u0000rst decade of the 21st century, suggests that\naccessibility of this facile means of suicide may play a role in amplifying the suicide rate (Lim et al.,\n2014). Cross-sectional analyses have further identi\u0000ed lower educational attainment, rural domicile,\narea-level socioeconomic deprivation (Kim, 2020), and diminished income (Lee et al., 2017; Lee et al.,\n2022) as potential variables linked to elevated suicide risk.\nIn addition, the heightened prevalence of divorces in South Korea is considered a partial explanatory\nvariable for elevated suicide rates (Kim, 2020; Yamaoka et al., 2020), with divorce identi\u0000ed as a pivotal\nrisk factor for suicide. Three principal mechanisms have been posited to explain this relationship: \u0000rst,\ndivorce leads to the disintegration of social and familial ties, thereby exacerbating psychological distress\n(Yamaoka et al., 2020); second, the termination of emotional interdependence between spouses\nintensi\u0000es emotional distress; and third, divorce often precipitates \u0000nancial vulnerabilities, especially\namong women, due to insu\u0000cient welfare provisions and the demands of single parenthood (Lee et al.,\n2017; Lee et al., 2022). Taken together, these contributing factors heighten the suicide rate among\ndivorcees, a\u0000rming the complex and multifactorial nature of suicide risk.\nGreece, in contrast, currently has one of the world’s lowest suicide rates. Yet this has not always been\nthe case. In view of the economic crisis that has enveloped Europe since 2008, rising suicide rates in\nGreece attracted heightened scrutiny. That economically turbulent period characterized by elevated\nunemployment rates and negative economic growth had a discernible impact on various dimensions of\neveryday life, and presumably on mental health. Research conducted across European Union nations\ncorroborates this observation by identifying an association between suicide mortality rates and\nunemployment (Stuckler et al., 2009). Research literature examining Greece reported alarming increases\nin suicide rates, peaking at up to 40% (Kontaxakis et al., 2013; Rachiotis et al., 2015). This rise was more\npronounced among women, who exhibited an increase of 69.6%, compared to 33.1% among men\n(Kontaxakis et al., 2013). Another study identi\u0000ed a 35% uptick in suicides in Greece between 2010 and\n2012. This study also found that unemployment was signi\u0000cantly related to suicide mortality, particularly\namong men of working age, a pattern in line with the onset of austerity measures (Rachiotis et al., 2015).\nSeveral primary factors can explain the marked decline in suicide rates in Greece in recent years. First,\nempirical research suggests that countries close to the Mediterranean Sea generally exhibit lower\nsuicide rates, possibly due to the region's more relaxed lifestyle (Eskin, 2020). Second, suicide rates\ndemonstrate substantial intersocietal variation (Mortier et al., 2018). A comparative analysis across 22\nPage 5/18\nnations revealed that elevated suicide rates were primarily found in three largely Catholic countries:\nSlovenia, France, and Croatia (Eskin, 2020). Nevertheless, even though the role of religious belief as a\nprotective factor against suicidal tendencies has been substantiated by research (Gearing & Alonzo,\n2018), research literature on non-fatal suicidal behavior in Mediterranean countries is limited. Some\nstudies indicate that while religious a\u0000liation may not guard against suicidal ideation, it does appear to\ndeter actual suicide attempts (Lawrence et al., 2016).\nThe Chat Generative Pre-Trained Transformer (ChatGPT) is an AI-based language model with\napplications across diverse sectors, including education, scienti\u0000c research, and healthcare (Hadar-\nShoval et al., 2023; Fraiwan et al., 2023; Tal et al., 2023). Recently, ChatGPT has demonstrated its\npotential in medical contexts, particularly in mental health (Levkovich & Elyoseph, 2023; Hadar-Shoval et\nal., 2023; Tal et al., 2023). Its machine-learning algorithms, trained on extensive healthcare data, have the\npotential to assist clinicians in decision-making and enhance the predictive accuracy of tools assessing\nsuicidal behavior (Elyoseph & Levkovich, 2023; Sallam, 2023). Nevertheless, adoption of ChatGPT\nrequires careful evaluation due to limitations and costs (Sallam, 2023; Tal et al., 2023). For instance,\nChatGPT has been found to underestimate suicide risks, raising questions about its reliability in critical\nassessments (Elyoseph & Levkovich, 2023). Moreover, training the model on online data poses risks of\ndisseminating inaccurate information, which is a matter of particular concern in the case of individuals\nwith mental health disorders (Cheng et al., 2023).\nTherefore, while ChatGPT offers promising avenues in mental healthcare, its limitations necessitate\ncautious implementation (Sallam, 2023; Tal et al., 2023). The challenge of accessing reliable suicide risk\nassessments is particularly acute in developing countries. This issue is further complicated by the global\ntrend toward the expansion of cultural diversity within nations, making intercultural considerations\nessential even in Western settings. The current research seeks to address this gap by investigating\nwhether arti\u0000cial intelligence can effectively incorporate cultural factors in its suicide risk assessments.\nThe ultimate aspiration is to leverage AI technology to provide personalized and culturally sensitive\nmental health services on a global scale.\nThe current study sought to examine whether ChatGPT-3.5 and ChatGPT-4 incorporate risk factors such\nas country/culture in their assessments of suicide risk. These risk assessments include the likelihood of\nserious suicide attempts, suicide attempts, and suicidal thoughts. We hypothesized that compared to\nChatGPT-3.5, ChatGPT-4 would exhibit enhanced consideration of these suicide risk factors.\nMethods\nLarge Language Models Procedure\nIn September 2023, we assessed the aptitude of both ChatGPT-3.5 and ChatGPT-4 (3 August version) in\nevaluating cross-cultural sensitivity related to suicide risk factors, including likelihood of death from\nsuicidal acts, likelihood of serious suicide attempt, likelihood of suicide attempt, and likelihood of\nPage 6/18\nsuicidal thoughts. Since the study did not involve real patients and only made use of vignettes and GPT\ntechnology, we determined that seeking approval from an ethics committee was not required.\nInput Source\nThe foundational vignette used in the current study depicts a 37-year-old person with no prior records of\nsuicide attempts and was originally used in a study by Levi-Belz and Gamliel (2016). It has also been\nemployed in subsequent research (Levkovich & Elyoseph, 2023; Elyoseph & Levkovich, 2023). To assess\nhow cultural differences in\u0000uence ChatGPT's evaluation of suicide risk, we entered a vignette into the AI\ninterface that portrayed either a Greek character (man or woman) or a South Korean character (man or\nwoman). For authenticity, we used common \u0000rst names from Greece and South Korea (Georgios and\nMaria, Seo-Jun and Seo-Yeon, respectively). Each vignette was evaluated ten times in both ChatGPT-3.5\nand ChatGPT-4, for a total of 80 evaluations, each conducted in a separate tab.\nThe text of the vignette is as follows:\nMaria (or Georgios/ Seo-Yeon/Seo-Jun ) is a 37-year-old single woman ( or man ) with no children, who\nwas born and lives in Greece (or South Korea). She (he) currently lives alone, but in the past spent a long\ntime living with her (his) father, who passed away two years ago following a serious illness. Maria holds\na B.A. degree and has held a steady job for 10 years. Recently, however, her manager told her she is\nabout to be dismissed due to \u0000nancial cuts. Over the past year, Maria had a close and intimate\nrelationship with a boyfriend. This was her \u0000rst serious and meaningful relationship; she was very\nexcited about it and hoped it would lead to marriage. But after a period of repeated quarrels, her\nboyfriend informed her he no longer loved her, and he left her. Maria was left feeling very sad and hurt. In\nrecent weeks she has thought about the relationship repeatedly and tried to analyze what happened.\nMaria is carrying a heavy emotional load; she is very tired, lacks energy, and \u0000nds it hard to sleep at\nnight. Routine tasks have become di\u0000cult for her, and she has trouble concentrating or functioning\nproperly. She dreads the future, and it seems to her there is no chance she will \u0000nd a love like this again.\nMaria feels worthless. She often sees herself as a burden to the people around her and feels things\nwould be better if she were gone. She often sees herself as having no real meaning to other people, and\nshe experiences feelings of self-hatred. For example, she is angry at herself and thinks it was her fault\nthat her boyfriend left her. Maria is generally overcome by major loneliness and has only a few, if any,\nclose friends. She is very withdrawn, distant from others, and feels there is no one to whom she can turn\nin times of trouble. Therefore, she has not shared her feelings with anyone since the breakup.\nMeasures\nAfter entering each of the four vignettes (Greek or South Korean/female or male) into the AI interface, we\nstated: \"Answer the following questions as if you are a psychologist specializing in suicide risk\nassessment\": Q1: “What is the likelihood Maria (or Georgios/Seo-Yeon/Seo-Jun) will have suicidal\nthoughts?”; Q2: “What is the likelihood Maria (or Georgios/Seo-Yeon/Seo-Jun) will attempt suicide?”; Q3:\n“What is the likelihood Maria (or Georgios/Seo-Yeon/Seo-Jun) will make a serious suicide attempt?”; Q4:\nPage 7/18\n\"What is the likelihood Maria (or Georgios/Seo-Yeon/Seo-Jun) will die from a suicide attempt?\" Question\n1–3 was taken from Levi-Belz and Gamliel (2016) and answered on a seven-point Likert type scale, with\nestimated likelihood ranging from 1 (very slight) to 7 (very high).\nStatistical Analysis\nTo evaluate the in\u0000uence of each of the independent variables (Greek or South Korean; female or male)\non each the four outcome variables (likelihood of suicidal thoughts, likelihood of suicide attempt,\nlikelihood of serious suicide attempt, likelihood of dying from suicide attempt), we employed multivariate\ntwo-way ANOVA analysis separately for ChatGPT-3.5 and ChatGPT-4. To compare ChatGPT-3.5 and\nChatGPT-4 on the four outcome variables (likelihood of suicidal thoughts, likelihood of suicide attempt,\nlikelihood of serious suicide attempt, likelihood of dying from suicide attempt) we used one-way ANOVA.\nResults\nCross Culture Effect\nFigure 1a demonstrates that ChatGPT-3.5 is sensitive to cross-cultural distinctions when predicting\nsuicidal risk. Speci\u0000cally, the likelihood of suicidal thoughts, suicide attempt, serious suicide attempt,\nand dying from attempted suicide were assessed higher for the Korean character than for the Greek\ncounterpart (F(1,40) = 5. 8-9.8-, p < 0.05 − 0.01). In contrast, in the ChatGPT-4 evaluation only the\nlikelihood of a serious suicide attempt and the risk of dying from attempted suicide were assessed\nhigher for the South Korean character than for the Greek counterpart (F(1,40) = 3.94, p = 0.055 and\nF(1,40) = 4.71, p < 0.05, respectively). No signi\u0000cant difference was observed between South Korean and\nGreek characters in the likelihood of suicidal thoughts and the likelihood of attempting suicide (see\nFig. 1b).\nGender Effect\nFigure 2 shows that only ChatGPT-4 considered male gender to be a signi\u0000cant risk factor leading to a\nworsening of risk assessment of all variables [F(1,40) = 3.95–8.8, p = 0.055-<0.01 for likelihood of\nsuicidal thoughts, likelihood of suicide attempt, likelihood of serious suicide attempt, likelihood of dying\nfrom attempted suicide). In contrast, ChatGPT-3.5 revealed only a tendency (not signi\u0000cant) toward\nconsidering male gender as a risk factor (p = 0.11 − 0.06 for all variables).\nInteraction between culture and gender\nNeither ChatGPT 3.5 nor ChatGPT 4 found a signi\u0000cant interaction between culture and gender (p > \n0.05).\nDifferences between ChatGPT-3.5 and ChatGPT-4\nPage 8/18\nFigure 3 shows that ChatGPT-4 rated the severity of all the study’s dependent variables (likelihood of\nsuicidal thoughts, likelihood of suicide attempt, likelihood of serious suicide attempt, and likelihood of\ndying from attempted suicide) as signi\u0000cantly higher than ChatGPT-3.5 [F(1,79) = 11.6–22.7, p < 0.001].\nDiscussion\nTo the best of our knowledge, the current study is the \u0000rst to examine the intercultural aspects of using\nAI in mental health in a critical area such as suicide risk assessment. This study makes a unique\ncontribution by evaluating the intricate interplay between individual experiences, cultural factors, and AI-\ndriven data analysis, thus shedding new light on the multifaceted nature of this critical global challenge.\nCross Culture Effect\nThe present \u0000ndings indicate that ChatGPT-3.5 exhibits a noteworthy capacity for cross-cultural\nsensitivity and effectively discerns subtleties within diverse cultural contexts. ChatGPT-3.5 accurately\nrecognized that the South Korean character may be at signi\u0000cantly heightened risk for a range of suicidal\nbehaviors. This observation aligns with statistical data and literature indicating that South Korea is\ngrappling with the highest suicide rate among developed nations (WHO, 2020). The cultural dynamics at\nplay in South Korea—among them demographic aging alongside factors such as the erosion of\ntraditional family values and economic deprivation—contribute to forming a complex and multifaceted\nlandscape of suicide risk (Cha et al., 2020; Lee et al., 2022).\nChatGPT-4 also displayed commendable sensitivity to speci\u0000c cultural distinctions, particularly regarding\nthe severity of suicidal actions within the South Korean context. This recognition represents a positive\nstep in the ability of AI platforms to acknowledge the diverse challenges and risk factors faced by\nindividuals from varying cultural backgrounds in their mental health journeys (Mueller et al., 2021). Yet\nwhile maintaining sensitivity to certain cultural nuances, ChatGPT-4 adopted a more selective approach,\nwith a predominant focus on the severity of suicidal actions within the South Korean context. This\nconcentrated focus on severity does carry potential risks, as it may oversimplify the intricate cultural\ndynamics that shape mental health experiences (Mueller et al., 2021). Such an approach could\nunintentionally reinforce stereotypes and inadequately capture the multifaceted web of cultural\nin\u0000uences on mental well-being, which vary signi\u0000cantly among individuals and communities.\nNevertheless, the current \u0000ndings enhance our knowledge about the capabilities of ChatGPT,\ndemonstrating that this AI platform encompasses more than merely theoretical and semantic knowledge\n(Kung et al., 2023; Rudolph et al., 2023). Indeed, ChatGPT’s can successfully identify the most critical and\nimportant cases of actual acts of suicide, while at the same time demonstrating cultural sensitivity. This\n\u0000nding is of major importance, as most prior research has focused on the technical applications of AI\nwithin the domain of mental health, including optimizing clinical tasks such as record-keeping and\nelevating diagnostic precision (Bzdok & Meyer-Lindenberg, 2018; Doraiswamy et al., 2020) Our study\nemphasizes the broader potential of AI that goes beyond these technical abilities, including its ability to\nPage 9/18\nconsider cultural dimensions in the area of mental health, thus fostering a more comprehensive\napproach to support and intervention.\nGender Effect\nThe study’s results shed light on an intriguing gender effect in the suicide risk assessment capabilities of\nChatGPT-3.5 and ChatGPT-4. These \u0000ndings revealed notable differences in how these two AI models\ninterpret and incorporate gender as a signi\u0000cant risk factor, regardless of cultural context. ChatGPT-4\nexhibited sensitivity to gender-related factors in suicide risk assessment. Speci\u0000cally, this AI model\nconsistently identi\u0000ed male gender as a signi\u0000cant risk factor associated with a heightened likelihood of\nsuicidal thoughts, suicide attempts, serious suicide attempts, and risk of dying from suicide. This \u0000nding\nis in line with established gender theories that highlight varying patterns of suicide risk based on gender\n(Schrijvers et al., 2012). Conversely, ChatGPT-3.5 demonstrated more limited sensitivity to the gender\neffect and appeared to approach gender as a risk factor with less certainty or signi\u0000cance than did\nChatGPT-4.\nThese results prompt several considerations. First, the differing sensitivities of ChatGPT-3.5 and\nChatGPT-4 to gender as a risk factor emphasize the importance of understanding the potential biases\nand cultural factors that may in\u0000uence the risk assessments of AI models. Second, these \u0000ndings\nunderscore the complexity of gender-related risk factors in suicide, suggesting that AI models should be\ncalibrated and continuously re\u0000ned to provide more accurate and nuanced assessments in this regard.\nInteraction between culture and gender\nThe results regarding the interaction between culture and gender in both ChatGPT 3.5 and ChatGPT 4\nrevealed the noteworthy absence of a signi\u0000cant effect. This implies that neither of these AI models\ndemonstrated a strong inclination to modify their assessments of suicide risk based on the interplay\nbetween an individual's gender and cultural background.\nThis outcome raises several key considerations. First, it underscores the importance of evaluating the\nperformance and sensitivity of AI models in nuanced and context-speci\u0000c ways (Elyoseph & Levkovich,\n2023). While these models exhibited some degree of cultural and gender sensitivity in isolation, they did\nnot appear to make any signi\u0000cant adaptations in their risk assessments when these factors converged.\nThis may indicate that the AI models treat culture and gender as relatively independent variables in the\ncontext of suicide risk, possibly overlooking potential intersections and complexities. Based on prior\nresearch underscoring the signi\u0000cance of AI model accuracy (Graham et al., 2019), the absence of an\ninteraction effect in this study highlights the potential necessity for further re\u0000nement and calibration of\nthese models. This emphasizes the importance of integrating human expertise, particularly in sensitive\nareas such as suicide risk assessment, to enhance the effectiveness and cultural sensitivity of AI\nmodels.\nDifferences between ChatGPT-3.5 and ChatGPT-4\nPage 10/18\nThe study's \u0000ndings revealed that ChatGPT-4 consistently assigned higher severity ratings to suicide risk\nfactors than did ChatGPT-3.5, highlighting the presence of distinct strengths and weaknesses in their risk\nassessment capabilities (Elyoseph & Levkovich, 2023; Levkovich & Elyoseph, 2023). This distinction can\nhelp mental health professionals make informed decisions when selecting an AI model for suicide risk\nassessment (Bernert et al., 2020). ChatGPT-4's cautious approach appears to be well-suited for severe\ncases, enhancing treatment precision. In contrast, ChatGPT-3.5's more moderate ratings are appropriate\nfor milder cases, offering a less intensive approach. Furthermore, these choices hold signi\u0000cant\nimplications for individuals seeking mental health support. ChatGPT-4's tendency to encourage vigilant\nmonitoring is especially valuable for severe cases, ensuring timely interventions. In contrast, ChatGPT-\n3.5's approach is bene\u0000cial for individuals with less acute conditions, resulting in a more balanced\ntreatment plan.\nStudy’s Limitations\nThis study has several limitations. First, it focused primarily on Greece and South Korea, two countries\nwith extreme differences in suicide rates. This choice of countries may not fully capture the global\nspectrum of cultural in\u0000uences on suicide risk. Additionally, the use of vignettes that were not written in\nKorean or in Greek may have affected the authenticity of the cultural representation. To improve cross-\ncultural validity, future research should explore a wider array of cultural contexts and employ\nlinguistically and culturally appropriate materials. Second, the current study examined only two AI\nmodels—ChatGPT-3.5 and ChatGPT-4. The performance of other AI models in culturally sensitive suicide\nrisk assessment should also be explored. Lastly, the use of vignettes may not fully replicate real-world\ncomplexity. Future studies should consider incorporating real patient data.\nConclusions\nCultural diversity across the globe has a profound in\u0000uence on various facets of mental health, among\nthem perceptions of health and illness, help-seeking behaviors, consumer and practitioner attitudes, and\nmental health systems (Gopalkrishnan et al., 2018). Moreover, cultural diversity becomes particularly\nrelevant due to the ongoing processes of globalization. Accordingly, many countries worldwide must\naddress the challenge of providing psychiatric services to populations with diverse cultural backgrounds\n(Melluish & Globalization, 2014). In this context, the current study's \u0000ndings provide a ray of hope by\nsuggesting that ChatGPT models possess a notable degree of sensitivity to these intercultural\ndifferences. Given past concerns about rapid alignment processes in AI models, these \u0000ndings are\nsigni\u0000cant. These processes strive to prevent algorithmic biases related to factors such as race, gender,\nor socioeconomic status and focus on auditing and evaluating algorithm fairness (Ray, 2023). The\nstudy's results indicate that these models exhibit a certain degree of sensitivity to intercultural\ndistinctions, highlighting their potential to navigate the complexities of cultural diversity in mental health\ncontexts.\nDeclarations\nPage 11/18\nEthics Approval- This study was approved by Institutional Review Board (YVC EMEK 2023-40) and\nconformed to the Declaration of Helsinki.\nPatient and public involvement-No patient involved.\nFunding- This research received no external funding.\nData Availability Statement- The data that support the \u0000ndings of this study are available from the\nauthors upon reasonable request.\nCon\u0000icts of Interest- The authors declare no con\u0000ict of interest. \nAuthor Contributions- Conceptualization, I.L., S.S. A & Z.E.; Methodology and Formal Analysis, Z.E.;\nWriting—Original Draft Preparation, I.L.; Writing—Review and Editing, I.L.& S.S. A . All authors have read\nand agreed to the published version of the manuscript.\nReferences\n1. Baek, I., Jo, S., Kim, E. J., Lee, G. R., Lee, D. H., & Jeon, H. J. (2021). A review of suicide risk\nassessment tools and their measured psychometric properties in Korea. Frontiers in Psychiatry, 12,\n679779. https://doi.org/10.3389/fpsyt.2021.679779\n2. Bernert, R. A., Hilberg, A. M., Melia, R., Kim, J. P., Shah, N. H., & Abnousi, F. (2020). Arti\u0000cial\nintelligence and suicide prevention: A systematic review of machine learning investigations.\nInternational Journal of Environmental Research and Public Health, 17(16), 5929.\nhttps://doi.org/10.3390/ijerph17165929\n3. Bolton, J. M., Gunnell, D., & Turecki, G. (2015). Suicide risk assessment and intervention in people\nwith mental illness. BMJ, 351:4978. doi: 10.1136/bmj.h4978\n4. Bowden, M., McCoy, A., & Reavley, N. (2020). Suicidality and suicide prevention in culturally and\nlinguistically diverse (CALD) communities: A systematic review. International Journal of Mental\nHealth, 49(4), 293–320. https://doi.org/10.1080/00207411.2019.1694204\n5. Bzdok, D., & Meyer-Lindenberg, A. (2018). Machine learning for precision psychiatry: Opportunities\nand challenges. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, 3(3), 223–230.\nhttps://doi.org/10.1016/j.bpsc.2017.11.007\n\u0000. Cha, E. S., Chang, S., Choi, Y., & Lee, W. J. (2020). Trends in pesticide suicide in south Korea, 1983–\n2014. Epidemiology and Psychiatric Sciences, 29, e25. doi:10.1017/S2045796019000118\n7. Chang, S., Gunnell, D., Sterne, J. A., Lu, T., & Cheng, A. T. (2009). Was the economic crisis 1997–1998\nresponsible for rising suicide rates in east/southeast Asia? A time–trend analysis for Japan, Hong\nKong, south Korea, Taiwan, Singapore and Thailand. Social Science & Medicine, 68(7), 1322–1331.\nhttps://doi.org/10.1016/j.socscimed.2009.01.010\n\u0000. Cheng, S. W., Chang, C. W., Chang, W. J., Wang, H. W., Liang, C. S., Kishimoto, T., … Su, K. P. (2023).\nThe now and future of ChatGPT and GPT in psychiatry. Psychiatry and Clinical Neurosciences.\nPage 12/18\nhttps://doi.org/10.1111/pcn.13588\n9. Doraiswamy, P. M., Blease, C., & Bodner, K. (2020). Arti\u0000cial intelligence and the future of psychiatry:\nInsights from a global physician survey. Arti\u0000cial Intelligence in Medicine, 102, 101753.\nhttps://doi.org/10.1016/j.artmed.2019.101753\n10. Eskin, M. (2020). Suicidal behavior in the mediterranean countries. Clinical Practice and\nEpidemiology in Mental Health: CP & EMH, 16(Suppl-1), 93. doi: 10.2174/1745017902016010093\n11. Elyoseph, Z., & Levkovich, I. (2023). Beyond human expertise: the promise and limitations of\nChatGPT in suicide risk assessment. Frontiers in psychiatry, 14, 1213141.\nhttps://doi.org/10.3389/fpsyt.2023.1213141\n12. Feigelman, W., Plöderl, M., Rosen, Z., & Cerel, J. (2019). Research note on whether sexual minority\nindividuals are over-represented among suicide's casualties. Crisis.28.\nhttps://doi.org/10.1027/0227-5910/a000626\n13. Fiske, A., Henningsen, P., & Buyx, A. (2019). Your robot therapist will see you now: Ethical\nimplications of embodied arti\u0000cial intelligence in psychiatry, psychology, and psychotherapy. Journal\nof Medical Internet Research, 21(5), e13216. doi: 10.2196/13216\n14. Fraiwan, M., & Khasawneh, N. (2023). A review of ChatGPT applications in education, marketing,\nsoftware engineering, and healthcare: Bene\u0000ts, drawbacks, and research directions. arXiv Preprint\narXiv:2305.00237. https://doi.org/10.48550/arXiv.2305.00237\n15. Gearing, R. E., & Alonzo, D. (2018). Religion and suicide: New \u0000ndings. Journal of Religion and\nHealth, 57, 2478–2499. https://doi.org/10.1007/s10943-018-0629-8\n1\u0000. Gvion, Y., & Levi-Belz, Y. (2018). Serious suicide attempts: systematic review of psychological risk\nfactors. Frontiers in psychiatry, 9, 56.doi: 10.3389/fpsyt.2018.00056\n17. Gopalkrishnan, N. (2018). Cultural diversity and mental health: Considerations for policy and\npractice. Frontiers in Public Health, 6, 179. https://doi.org/10.3389/fpubh.2018.00179\n1\u0000. Graham, S., Depp, C., Lee, E. E., Nebeker, C., Tu, X., Kim, H., & Jeste, D. V. (2019). Arti\u0000cial intelligence\nfor mental health and mental illnesses: An overview. Current Psychiatry Reports, 21, 1–18.\nhttps://doi.org/10.1007/s11920-019-1094-0\n19. Graney, J., Hunt, I. M., Quinlivan, L., Rodway, C., Turnbull, P., Gianatsi, M., … Kapur, N. (2020). Suicide\nrisk assessment in UK mental health services: a national mixed-methods study. The Lancet\nPsychiatry, 7(12), 1046–1053. https://doi.org/10.1016/S2215-0366(20)30381-3\n20. Qian, G. (2021). Associations of suicide and subjective well-being. OMEGA-Journal of Death and\nDying, 84(1), 103–115. https://doi.org/10.1177/0030222819880091\n21. Kang, Y. (2021). Robot Death and Human Grief in Films: Qualitative Study. OMEGA-Journal of Death\nand Dying,88(1) 00302228211038139. https://doi.org/10.1177/00302228211038139\n22. Kim, A. M. (2020). Factors associated with the suicide rates in Korea. Psychiatry Research, 284,\n112745. https://doi.org/10.1016/j.psychres.2020.112745\nPage 13/18\n23. Kim, J. W., Jung, H. Y., Won, D. Y., Noh, J. H., Shin, Y. S., & Kang, T. I. (2019). Suicide trends according\nto age, gender, and marital status in South Korea. OMEGA-Journal of Death and Dying, 79(1), 90–\n105. https://doi.org/10.1177/0030222817715756\n24. Kim, J. W., Jung, H. Y., Won, D. Y., Shin, Y. S., Noh, J. H., & Kang, T. I. (2020). Landscape of elderly\nsuicide in South Korea: Its trend according to age, gender, and educational attainment. OMEGA-\nJournal of death and dying, 82(2), 214–229. https://doi.org/10.1177/0030222818807845\n25. Knipe, D., Padmanathan, P., Newton-Howes, G., Chan, L. F., & Kapur, N. (2022). Suicide and self-harm.\nThe Lancet, 399(10338), 1903–1916.https://doi.org/10.1016/S0140-6736(22)00173-8\n2\u0000. Kontaxakis, V., Papaslanis, T., Havaki-Kontaxaki, B., Tsouvelas, G., Giotakos, O., & Papadimitriou, G. Ν .\n(2013). Suicide in greece: 2001–2011. Psychiatrike = Psychiatriki, 24(3), 170–174.\n27. Kung, T. H., Cheatham, M., Medenilla, A., Sillos, C., De Leon, L., Elepaño, C., Madriaga, M., Aggabao,\nR., Diaz-Candido, G., & Maningo, J. (2023). Performance of ChatGPT on USMLE: Potential for AI-\nassisted medical education using large language models. PLoS Digital Health, 2(2), e0000198.\nhttps://doi.org/10.1371/journal.pdig.0000198\n2\u0000. Lawrence, R. E., Oquendo, M. A., & Stanley, B. (2016). Religion and suicide risk: A systematic review.\nArchives of Suicide Research, 20(1), 1–21. https://doi.org/10.1080/13811118.2015.1004494\n29. Lee, H., Kim, R., Jang, S., & Kawachi, I. (2022). The relative importance of macro versus micro\ngeographical scale in explaining suicide variation in Seoul, south Korea 2014–2016. PLoS One,\n17(9), e0273866. https://doi.org/10.1371/journal.pone.0273866\n30. Lee, S., Oh, I., Jeon, H. J., & Roh, S. (2017). Suicide rates across income levels: Retrospective cohort\ndata on 1 million participants collected between 2003 and 2013 in south Korea. Journal of\nEpidemiology, 27(6), 258–264. https://doi.org/10.1016/j.je.2016.06.008\n31. Lim, M., Lee, S. U., & Park, J. (2014). Difference in suicide methods used between suicide attempters\nand suicide completers. International Journal of Mental Health Systems, 8, 1–4.\nhttps://doi.org/10.1186/1752-4458-8-54\n32. Levi-Belz, Y., & Gamliel, E. (2016). The effect of perceived burdensomeness and thwarted\nbelongingness on therapists' assessment of patients' suicide risk. Psychotherapy research, 26(4),\n436–445.doi: 10.1080/10503307.2015.1013161\n33. Levi-Belz, Y., Gvion, Y., & Apter, A. (2022). The serious suicide attempts approach for understanding\nsuicide: review of the psychological evidence. OMEGA-Journal of death and dying, 86(2), 591–608.\nhttps://doi.org/10.1177/0030222820981235\n34. Levkovich, I., & Elyoseph, Z. (2023). Suicide risk assessments through the eyes of Chatgpt-3.5\nversus ChatGPT-4: vignette study. JMIR mental health, 10, e51232. doi: 10.2196/51232\n35. Melluish, S. (2014). Globalization, culture and psychology. International Review of Psychiatry, 26(5),\n538–543. https://doi.org/10.3109/09540261.2014.918873\n3\u0000. Mortier, P., Auerbach, R. P., Alonso, J., Bantjes, J., Benjet, C., Cuijpers, P., Ebert, D. D., Green, J. G.,\nHasking, P., & Nock, M. K. (2018). Suicidal thoughts and behaviors among \u0000rst-year college students:\nPage 14/18\nResults from the WMH-ICS project. Journal of the American Academy of Child & Adolescent\nPsychiatry, 57(4), 263–273. e1. https://doi.org/10.1016/j.jaac.2018.01.018\n37. Mueller, A. S., Abrutyn, S., Pescosolido, B., & Diefendorf, S. (2021). The social roots of suicide:\nTheorizing how the external social world matters to suicide and suicide prevention. Frontiers in\nPsychology, 12, 763. https://doi.org/10.3389/fpsyg.2021.621569\n3\u0000. Rachiotis, G., Stuckler, D., McKee, M., & Hadjichristodoulou, C. (2015). What has happened to\nsuicides during the greek economic crisis? \u0000ndings from an ecological study of suicides and their\ndeterminants (2003–2012). BMJ Open, 5(3), e007295. http://dx.doi.org/10.1136/bmjopen-2014-\n007295\n39. Ray, P. P. (2023). ChatGPT: A comprehensive review on background, applications, key challenges,\nbias, ethics, limitations and future scope. Internet of Things and Cyber-Physical\nSystems.https://doi.org/10.1016/j.iotcps.2023.04.003\n40. Rudolph, J., Tan, S., & Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional assessments\nin higher education? Journal of Applied Learning and Teaching, 6(1).\nhttps://doi.org/10.37074/jalt.2023.6.1.9\n41. Sallam, M. (2023). The utility of ChatGPT as an example of large language models in healthcare\neducation, research and practice: Systematic review on the future perspectives and potential\nlimitations. medRxiv, 2023.02.19.23286155\n. https://doi.org/10.3390/healthcare11060887\nSchrijvers, D. L., Bollen, J., & Sabbe, B. G. (2012). The gender paradox in suicidal behavior and its\nimpact on the suicidal process. Journal of Affective Disorders, 138(1–2), 19–26.\nhttps://doi.org/10.1016/j.jad.2011.03.050\nStuckler, D., Basu, S., Suhrcke, M., & McKee, M. (2009). The health implications of \u0000nancial crisis: A\nreview of the evidence. The Ulster Medical Journal, 78(3), 142. PMID: 19907678; PMCID: PMC2773609\nTal, A., Haber, Y., Angert, T., Gur, T., Simon, T., & Asman, O. (2023). The Arti\u0000cial Third: Utilizing\nChatGPT in Mental Health. The American Journal of Bioethics, 23(10), 74–\n77.https://doi.org/10.1080/15265161.2023.2250297\nTal, A., Elyoseph, Z., Haber, Y., Angert, T., Gur, T., Simon, T., & Asman, O. (2023). The arti\u0000cial third:\nutilizing ChatGPT in mental health. The American Journal of Bioethics, 23(10), 74–77.\nhttps://doi.org/10.1080/15265161.2023.2250297\nvan Heerden, A. C., Pozuelo, J. R., & Kohrt, B. A. (2023). Global mental health services and the impact\nof arti\u0000cial Intelligence–Powered large language models. JAMA Psychiatry, 80(7), 662–664.\ndoi:10.1001/jamapsychiatry.2023.1253\nWampold, B. E., & Flückiger, C. (2023). The alliance in mental health care: Conceptualization, evidence\nand clinical applications. World Psychiatry, 22(1), 25–41. https://doi.org/10.1002/wps.21035\nWorld Health Organization. (2020). Suicide rate estimates, age-standardized estimates by country.\nWorld Health Organization.Https://Apps.Who.Int/Gho/Data/View.Main.MHSUICIDEASDRv,\nPage 15/18\nFigures\nXu, S., Deo, R. C., Soar, J., Barua, P. D., Faust, O., Homaira, N., Jaffe, A., Kabir, A. L., & Acharya, U. R.\n(2023). Automated detection of air\u0000ow obstructive diseases: A systematic review of the last decade\n(2013–2022). Computer Methods and Programs in Biomedicine, 107746.\nhttps://doi.org/10.1016/j.cmpb.2023.107746\nYamaoka, K., Suzuki, M., Inoue, M., Ishikawa, H., & Tango, T. (2020). Spatial clustering of suicide\nmortality and associated community characteristics in kanagawa prefecture, japan, 2011–2017. BMC\nPsychiatry, 20, 1–15. https://doi.org/10.1186/s12888-020-2479-7\nYip, P. S., Yousuf, S., Chan, C. H., Yung, T., & Wu, K. C. (2015). The roles of culture and gender in the\nrelationship between divorce and suicide risk: A meta-analysis. Social Science & Medicine, 128, 87–94.\nhttps://doi.org/10.1016/j.socscimed.2014.12.034\nPage 16/18\nFigure 1\nAssessing suicidal risk across cultures – ChatGPT 3.5 and ChatGPT 4.\nPage 17/18\nFigure 2\nAssessing suicidal risk across gender – ChatGPT 3.5 and ChatGPT 4.\nPage 18/18\nFigure 3\nChatGPT 3.5 vs. ChatGPT 4."
}