{
    "title": "Portuguese text generation using factored language models",
    "url": "https://openalex.org/W2130327745",
    "year": 2012,
    "authors": [
        {
            "id": "https://openalex.org/A2051016182",
            "name": "Eder Miranda de Novais",
            "affiliations": [
                "Universidade de São Paulo"
            ]
        },
        {
            "id": "https://openalex.org/A207621152",
            "name": "Ivandré Paraboni",
            "affiliations": [
                "Universidade de São Paulo"
            ]
        },
        {
            "id": "https://openalex.org/A2051016182",
            "name": "Eder Miranda de Novais",
            "affiliations": [
                "Instituto do Sono"
            ]
        },
        {
            "id": "https://openalex.org/A207621152",
            "name": "Ivandré Paraboni",
            "affiliations": [
                "Instituto do Sono"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2054362711",
        "https://openalex.org/W1980905708",
        "https://openalex.org/W2135363470",
        "https://openalex.org/W2101930061",
        "https://openalex.org/W1560192456",
        "https://openalex.org/W2056250865",
        "https://openalex.org/W1994911645",
        "https://openalex.org/W2043147031",
        "https://openalex.org/W1937442440",
        "https://openalex.org/W2045320784",
        "https://openalex.org/W1973042921",
        "https://openalex.org/W2052893955",
        "https://openalex.org/W4233573184",
        "https://openalex.org/W2072481766",
        "https://openalex.org/W2136518380",
        "https://openalex.org/W2211189196",
        "https://openalex.org/W1578823404",
        "https://openalex.org/W1493882948",
        "https://openalex.org/W2101105183",
        "https://openalex.org/W2125417976",
        "https://openalex.org/W88963915",
        "https://openalex.org/W4285719527",
        "https://openalex.org/W1658658360",
        "https://openalex.org/W1550436901",
        "https://openalex.org/W2078861931",
        "https://openalex.org/W2119511997",
        "https://openalex.org/W1631260214",
        "https://openalex.org/W2115459072",
        "https://openalex.org/W1931352730",
        "https://openalex.org/W2201007611",
        "https://openalex.org/W2251878092",
        "https://openalex.org/W1743173941",
        "https://openalex.org/W2004637830",
        "https://openalex.org/W2578567510",
        "https://openalex.org/W2169143855"
    ],
    "abstract": "Abstract As in many other natural language processing (NLP) fields, the use of statistical methods is now part of mainstream natural language generation (NLG). In the development of systems of this kind, however, there is the issue of data sparseness, a problem that is particularly evident in the case of morphologically-rich languages such as Portuguese. This work presents a shallow surface realisation system that makes use of factored language models (FLMs) of Portuguese to overcome some of these difficulties. The system combines FLMs trained on a large corpus with a number of NLP resources that have been made publicly available by the Brazilian NLP research community in recent years, such as corpora, dictionaries, thesauri and others. Our FLM-based approach to surface realisation has been successfully applied to the generation of Brazilian newspapers headlines, and the results are shown to outperform a number of statistical and non-statistical baseline systems alike.",
    "full_text": "J Braz Comput Soc (2013) 19:135–146\nDOI 10.1007/s13173-012-0095-1\nORIGINAL PAPER\nPortuguese text generation using factored language models\nEder Miranda de Novais · Ivandré Paraboni\nReceived: 7 May 2012 / Accepted: 6 November 2012 / Published online: 24 November 2012\n© The Brazilian Computer Society 2012\nAbstract As in many other natural language processing\n(NLP) ﬁelds, the use of statistical methods is now part of\nmainstream natural language generation (NLG). In the devel-\nopment of systems of this kind, however, there is the issue\nof data sparseness, a problem that is particularly evident\nin the case of morphologically-rich languages such as Por-\ntuguese. This work presents a shallow surface realisation sys-\ntem that makes use of factored language models (FLMs) of\nPortuguese to overcome some of these difﬁculties. The sys-\ntem combines FLMs trained on a large corpus with a number\nof NLP resources that have been made publicly available by\nthe Brazilian NLP research community in recent years, such\nas corpora, dictionaries, thesauri and others. Our FLM-based\napproach to surface realisation has been successfully applied\nto the generation of Brazilian newspapers headlines, and the\nresults are shown to outperform a number of statistical and\nnon-statistical baseline systems alike.\nKeywords Natural language generation · Text generation ·\nSurface realisation\n1 Introduction\nIn natural language generation (NLG) systems, surface reali-\nsation is known as the task of mapping abstract sentence rep-\nresentations to a surface form, that is, a sequence of words,\nFAPESP grant 2009/08499-9.\nE. M. de Novais · I. Paraboni ( B)\nSchool of Arts, Sciences and Humanities,\nUniversity of São Paulo (EACH/USP), Av. Arlindo Bettio,\n1000 São Paulo, Brazil\ne-mail: ivandre@usp.br\nE. M. de Novais\ne-mail: eder.novais@usp.br\npunctuation symbols etc., to be delivered to the document\npresentation system [ 1]. The input to the surface realisation\nmodule is a (mostly) language-independent representation of\nthe meaning of the sentence, and the output is a word string\nin the target language.\nIn recent years, as in many other NLG applications, sur-\nface realisation systems have successfully relied upon statis-\ntical methods ranging from language modelling techniques\n[2,3] to full-blown probabilistic generation-space models\n[4] and grammar acquisition [ 5]. Our own work focuses on\n2-stage, or generate-and-select NLG architectures as intro-\nduced in [ 2] and by others. Systems of this kind produce\ntext from an abstract input representation by separating the\ngeneration space from decision-making, that is, by over-\ngenerating a large number of alternative surface realisations\n(often including non grammatical or ill-formed candidates)\nand subsequently selecting the most likely output string with\nthe aid of a statistical language model.\nGenerate-and-select surface realisation shares many of\nthe well-known advantages of statistical approaches to NLP ,\nincluding lower development costs (e.g., by not requiring\ncorpus annotation etc.) and language independency. How-\never, it also shares one of its main weaknesses, namely, the\nneed for large amounts of training data to compensate for\ndata sparseness.\nIn statistical language modelling, data sparseness is par-\nticularly acute in the case of morphologically rich languages.\nFor instance, a Portuguese language model will typically\nrequire much larger amounts of training data if compared\nto, e.g., an English language model, in order to achieve com-\nparable results [ 6]. Moreover, English NLG systems may\nalso beneﬁt from state-of-art resources such as the 1-trillion\nwords Web 1T 5-gram corpus,\n1 whereas the largest publicly\n1 http://www.ldc.upenn.edu/Catalog/.\n123\n136 J Braz Comput Soc (2013) 19:135–146\navailable corpus of Brazilian Portuguese at the time of this\nwriting was the 32-million words NILC corpus [ 7].\nAs a means to overcome some of these difﬁculties, in this\nwork we address the use of factored language models (FLMs)\n[8] in the development of a shallow surface realisation system\nfor the Brazilian Portuguese language. In doing so, we would\nlike to show that FLMs may outperform standard n-gram\nmodels in a traditional generate-and-select NLG architecture,\nand may represent a viable solution to the problem of data\nsparseness in morphologically rich language generation.\nBesides the inherently greater expressive power of FLMs\nover standard n-gram counts as discussed later, our models\nare trained on a considerably larger (142-million words) cor-\npus of Brazilian Portuguese texts, and are combined with\na number of nonstatistical NLP resources developed by the\nBrazilian research community in recent years, such as dic-\ntionaries [ 9] and thesauri [ 10], making a surface realisation\nsystem that represents, to our knowledge, the ﬁrst of its kind.\nOur FLM-based approach to surface realisation is applied to\nthe generation of newspapers headlines, and the results are\nshown to outperform statistical and nonstatistical baseline\nsystems alike.\nThe rest of this paper is organised as follows. Section 2\nbrieﬂy reviews related work in the ﬁeld, and Sect. 3 describes\nthe main FLM-based approach that is the focus of the paper.\nEvaluation work is presented in Sect. 4, and its results are\ndiscussed in Sect. 5. Section 6 presents ﬁnal remarks.\n2 Related work\nSurface realisation can be viewed as the task of mapping\nabstract sentence representations to word strings in a target\nlanguage. What counts as an input representation may, how-\never, vary widely across systems, and the lack of a standard\non how a surface realisation system should be deﬁned—or\nmore speciﬁcally, on what makes its input speciﬁcation—\nhas long been the subject of debate in the NLG ﬁeld [ 1]. The\nwork in [ 2], for instance, considers its own sentence repre-\nsentation in the form of labelled directed graphs. The work\nin [11], by contrast, takes as an input logical forms represent-\ning the meaning of the sentence. More importantly, different\nsystems may consider more shallow (i.e., closer to the sur-\nface form) or deeper input representations, which implies\ndifferent functionalities.\nAs a ﬁrst initiative towards standardisation in the ﬁeld, the\nﬁrst Surface Realisation Shared Task [12] intended to eval-\nuate English surface realisation systems based on the same\ninput data (abstracted from the WSJ corpus). The shared task\nwas accomplished by ﬁve participants, being three statistical\nand two symbolic systems. Results discussed in [ 12]s h o w\nthat the statistical approaches were overall more successful.\nAlthough the goal of the shared task was to enable a direct,\nclear comparison among the participant systems, a number of\ninput-speciﬁcation issues remain to be solved. For a discus-\nsion on these difﬁculties and future improvements, see [ 13].\nOut of the ﬁve participants in the shared task, three sys-\ntems deserve special mention.\n2 T h ew o r ki n[16] is a statisti-\ncal surface realisation engine that makes use of dependency-\nbased n-gram models (i.e., as opposed to standard n-gram\ncounts) to exploit structural information and linguistic fea-\ntures to constrain the generation space. The work in [ 17]i s\nalso a statistical generator, acquiring all relevant information\nfor the surface realisation task from corpora. This informa-\ntion comprises a localised tree model, a morphological dic-\ntionary and a trigram language model. The only nonstatistical\nshallow generator in the competition was the work in [ 18],\nwhich makes use of uniﬁcation-based grammars. It should be\npointed out however that all these systems produce English\ntext from data derived from the WSJ treebank, and, therefore,\na direct comparison to our Portuguese text generator is not\npossible.\nOne useful way of distinguishing different approaches to\nsurface realisation is proposed in [ 19], in which the task is\nviewed as divided into two rather independent components:\na tactical generator in charge of deﬁning the mappings from\nsemantic inputs to morphosyntactic structures, and an oper-\national generator that, once all tactic decisions have been\nmade, performs the appropriate morphological tasks and sen-\ntence linearisation as a string in the target language [ 19].\nTactical generation tends to be more domain- or application-\ndependent, whereas operational generation tends to be more\nlanguage-dependent. However, the distinction is not always\ncrisp, and many systems still perform both tasks [ 19].\nIn [ 19], operational or shallow realisation systems are\nreferred to as surface realisation Engines, and a system called\nSimpleNLG is introduced. The system is presented as a Java\nlibrary for creating and manipulating English sentences. Gen-\nerating text with SimpleNLG consists of invoking a series\nof methods to specify every sentence constituent, how they\nshould be inﬂected, combined etc.\nS i m i l a r l yt o[19], our present system is an instance of a\nsurface realisation engine. However, our system is distinct\nfrom SimpleNLG in a number of ways. First, we consider an\nexplicit input speciﬁcation adapted from [ 12], from which a\nsentence is produced by making a single call to the language\ngenerator. In SimpleNLG, by contrast, a sentence is produced\nincrementally by making a series of calls to the system. Sec-\nond, SimpleNLG is a rule-based surface realisation engine,\nwhereas our present work combines rule-based and statistical\nmethods. Third, SimpleNLG generates English text, whereas\n2 The other two participants, the systems described in [ 14]( u s i n g\na graph-based parsing algorithm) and [ 15] (a grammar-based chart\nrealiser), focused on generation from deep input representation.\n123\nJ Braz Comput Soc (2013) 19:135–146 137\nwe focus on Portuguese (and to this end both systems encode\nlanguage-dependent rules).\nRegarding the statistical approach under consideration,\nour present work follows the generate-and-select NLG archi-\ntectures introduced in [ 2,20] and others. Systems of this kind\ngenerate surface strings from some abstract input represen-\ntation in two stages: ﬁrst, a large number of possible candi-\ndate output strings are generated from the given input, and\nthen the most likely output string is selected with the aid\nof a statistical language model. However, existing work on\n2-stage surface realisation has been traditionally based on\nn-gram models only, whereas the present work makes use\nof FLMs [ 8] instead. To our knowledge, our system is the\nonly FLM-based surface realisation engine to date, and the\nonly of its kind that has been designed for the Portuguese\nlanguage.\nOur current system is the ﬁnal product of a series of\nexperiments on surface realisation for Brazilian Portuguese.\nT h ew o r ki n[ 21] described a number of experiments on n-\ngram ﬁlters applied to individual surface realisation tasks,\nnamely, lexical choice, ordering of noun modiﬁers and verb-\ncomplement agreement. These experiments were performed\nover purpose-built sentences and their focus was on the iden-\ntiﬁcation of critical surface realisation tasks from the per-\nspective of a 2-stage generation approach based on n-gram\nmodels.\nThe n-gram approach in [ 21] was shown to perform poorly\nin three tasks: verb phrase lexicalisation, the ordering of noun\nmodiﬁers and verb-complement agreement (mainly in pas-\nsive voice). These issues were revisited in [ 6] with the intro-\nduction of FLMs applied to text generation in Brazilian Por-\ntuguese. The work in [ 6] was the ﬁrst of this kind to propose\nFLMs that outperformed standard n-gram models for Por-\ntuguese text generation. However, the work in [ 6] was still\nlimited in the sense that it was not applied to the generation\nof whole sentences taken from a corpus of actual language\nuse, and by using large, computationally expensive language\nmodels that took gender and number factors into account,\nand which we have presently improved on. 3\nFinally, the work in [22] is the closest to the present discus-\nsion, introducing a preliminary—but still purely statistical—\nversion of our system and the training and test data sets that\nwe have presently reused. However, the system presented\nin [ 22] was still lacking many of the current functionalities,\nincluding the rule-based methods to limit over-generation\nand the use of a thesaurus to exploit word synonymy. The\ncurrent system, by contrast, outperforms its early version in\n[22], but it is of course more language-dependent.\n3 As discussed in Sect. 3.4, given that our present training corpus is\nseveral times larger than the one used in [ 6] a direct comparison between\nthe computational efﬁciency of these approaches is not possible.\n3 Current work\n3.1 Overview\nThe present work concerns the development and evaluation\nof a shallow surface realisation system for the Brazilian Por-\ntuguese language based on FLMs. Systems of this kind are\nmostly applicable to text-to-text generation tasks such as text\nsummarisation [ 23], simpliﬁcation [ 24] and others, but may\nalso be embedded in a deeper generation framework [ 1].\nFigure 1 shows the system architecture, in which grey boxes\nrepresent its three main modules: symbolic pre-processing,\nsymbolic over-generation and statistical candidate selection.\nWhite boxes represent external knowledge sources as dis-\ncussed below.\nThe system takes as an input an under-speciﬁed abstract\nsentence representation (cf. Sect. 3.2). In order to estab-\nlish agreement between sentence constituents, missing input\nvalues are adjusted and/or complemented with the aid of a\nlexical database described in [ 9]. The result is a fully spec-\niﬁed sentence representation taken as the input to the next\nmodule, which over-generates alternative realisations (cf.\nSect. 3.3) based on linearisation constraints (also obtained\nfrom lexical information) and, optionally, synonymy infor-\nmation taken from a thesaurus of Brazilian Portuguese\n[10]. Finally, the set of possible candidates is submit-\nted to a language model ﬁlter and the most likely output\nsentence is selected. As discussed in Sect. 3.4,t h em a i n\ndifference between this and a more traditional generate-\nand-select architecture (e.g., [ 2]) is the use of FLMs in\nthe selection task, and not standard n-gram counts. Details\nof each of these steps are discussed in the following\nsections.\nFig. 1 System architecture\n123\n138 J Braz Comput Soc (2013) 19:135–146\n3.2 Input processing\nThe input to the system is a shallow, possibly under-speciﬁed\nsentence representation similar to the speciﬁcation consid-\nered in the Surface Realisation Shared Task [12]. As a case\nstudy, however, the input speciﬁcation is presently more lim-\nited in the sense that we will only consider sentences in\nactive voice according to a standard <NP-VP-NP >template\norder.\n4\nThe input is represented as a sentence tree in which all con-\ntent words are assumed to have been previously selected fol-\nlowing some lexical choice policy (e.g., [ 25,26]). Thus, the\ntask to be accomplished by the system mainly consists of pro-\nviding missing input information, establishing constituents\nagreement and word order in the target language (in our case,\nBrazilian Portuguese).\nThe following is a simpliﬁed example of input speciﬁca-\ntion for a target sentence ‘A cantora americana Christina\nAguillera não terá um programa de rádio semanal’ or ‘The\nAmerican singer Christina Aguillera will not have a weekly\nradio program’. The example is rendered in Prolog-like\nclauses generated automatically from a tagged corpus using\na simple conversion utility.\nThe top-level sentence representation is the sentence\nclause, in this case representing a ﬁxed order Agent-\nAction-Patient-Punctuation sentence template. Agent and\nPatient terms are deﬁned as object concepts (s 1 and p 1)\nto be realised as noun phrases (NPs). Action terms are\ndeﬁned as act(ion) concepts (v 1) to be realised as verb\nphrases (VPs). Both Patient and Punctuation terms are\noptional.\nConcepts to be realised as noun phrases (either ﬁll-\ning in Agent or Patient positions in the sentence template)\nare unordered lists of nouns, proper names, adjectives and\nprepositional phrases (PPs). The PP surface forms may be\ncomputed recursively during generation but, for reasons of\ncomputational efﬁciency, these constituents are presently\nassumed to be computed in advance. In other words, they\nare assumed to appear already in their ﬁnal surface form\n(regarding both inﬂection and order) in the input speciﬁca-\ntion. Although this may in principle be seen as a limitation of\n4 On the other hand, the more complex sentence structures considered\nin [12] require a richer input representation. This includes, for instance,\nsyntactic edges and other features that are not presently required.\nour approach, in practice nearly all (over 99 %) noun phrases\nin our test corpus (newspapers headlines, cf. Sect. 4)h a v ea t\nmost two PP modiﬁers each, making their computation rather\ntrivial. Concepts to be realised as VPs (ﬁlling in an Action\nposition) are sets of verbs with accompanying prepositions\nand adverbial modiﬁers.\nEach NP or VP term has a head constituent, to which\nall other elements are subordinated. The head constituent\nis deﬁned solely for the purpose of providing information\nfor other constituents when necessary, as discussed later,\nbut it does not follow that the head constituent needs to be\ndeﬁned according to a strict linguistic theory. Typical head\nconstituents for NPs are nouns and proper names. For VPs,\nthe head constituent is usually the main verb of the sen-\ntence.\nGiven an input speciﬁcation as above, the system starts\nby computing any missing information deemed necessary\nfor the agreement and linearisation tasks from left to right.\nMissing values are provided by examining Agent, Action\nand Patient terms individually, in that order. We assume\nthat the information provided for the Agent term drives\nthe generation process and, if necessary, will overlap any\nconﬂicting information provided by the other terms. For\ninstance, if the underlying application provides conﬂict-\ning instruction to produce a sentence whose Agent term\nshould be singular but whose Action term should be plural,\nAction will be adjusted to singular, and not the other way\nround.\nStarting from the Agent term, the system will use the gen-\nder and number provided or, if necessary, obtain these val-\nues from any nonambiguous constituent within the Agent\nterm. A constituent is considered free from gender/number\nambiguity when it occurs in a single gender/number form\nin the lexical database implemented in [ 9]. Within a given\nterm t, ﬁnding a nonambiguous constituent for which there\nis only one possible gender g and number n value implies\nthat all constituents within t must have the same gender g\nand number n values. In other words, nonambiguous gen-\nder/number values, if available, will be taken to be the oblig-\natory gender/number values for all constituents within the\nsame term.\nFor instance, concept s\n1 in the previous example includes\nnumber information (‘s’ for ‘single’), but no gender. In order\nto determine the gender of the NP , the system will make use of\nlexical information to examine proper names (which are less\nlikely to have more than one gender/number form), followed\nby nouns and adjectives, if necessary. If the proper name\n‘Christina Aguillera’ is represented in the dictionary only in\nfemale form, this will determine the gender of all constituents\nof the Agent term. If no constituent is represented in a single\nform, default values provided by the underlying application\nare attempted. Finally, if no default value is applicable (e.g.,\nif some constituents can only be realised in singular form,\n123\nJ Braz Comput Soc (2013) 19:135–146 139\nFig. 2 Linearisation rules\nand others in plural) the input is considered inconsistent and\nno text is generated. 5\nOnce gender and number values of the Agent term have\nbeen computed, these are enforced for the Action term as well\nand, in case of copula verb usage (e.g., ‘She is pretty’) also\nextended to the Patient term. This is necessary because the\nPortuguese language (unlike, e.g., English) requires subject-\ncomplement agreement in these cases, as in ‘ Ela é bonita’,\nin which the subject ( ‘Ela’, or ‘she’) agrees in gender and\nnumber with the complement ( ‘bonita’, or ‘pretty’).\nAfter establishing complete agreement within and bet-\nween terms, additional features (verb tense, mode, etc.) are\ndetermined using the same principles of inheritance and\ndefault values provided by the underlying application. The\nnext step consists of a standard over-generation approach\n[2,28,29] in which all potentially valid permutations of the\nterm set are produced.\n3.3 Over-generation\nGiven a complete input sentence speciﬁcation (i.e., with\nall relevant gender and number values in agreement, etc.)\nover-generation consists of producing a set of possible lin-\near orderings of the sentence constituents. In order to limit\nthe number of candidates under consideration, however, we\ndeﬁne valid permutations according to a number of simple\nlinearisation rules. These rules are intended both to reduce\nthe computational costs of the selection task (cf. next sec-\ntion) and also to increase the overall probability of ﬁnding\nthe most adequate output string, but are by no means to be\nseen as a substitute for more structured solutions such as\ngrammar acquisition (e.g., [ 5]). These linearisation rules are\nsummarised in Fig. 2.\nExcept for the punctuation and sentence template rules\n(r1 and r2 above), all linearisation rules are applicable to\nNPs. This choice is due to the fact that, in our system, the\nsentence under generation follows a previously chosen tem-\nplate format, and that VPs (at least as seen in our test data\non newspapers headlines, described in Sect. 4) tend to have\n5 The present use of default values provided by the application is not\nto be confused with the inference task in inheritance-based grammars\n(e.g., [ 27]).\na small number of constituents (usually one or two verbs,\nplus one occasional adverbial modiﬁer) and are generally\nwell covered by the language model ﬁlters. It was not nec-\nessary, for instance, to deﬁne a rule to prohibit VP alterna-\ntives containing a misplaced negative adverb as in ‘terá não’\n(‘will not have’), which are considered in 3 % of our test\nsentences. Ungrammatical constructions of this kind are cor-\nrectly ﬁltered out by the language models. In other words, as\nobserved in [6], it is the NP over-generation task that presents\nmost opportunities for improvement.\n6\nAn example of application of NP linearisation rules works\nas follows. Rule r3 guarantees that deﬁnite and indeﬁnite\ndeterminers are always placed at the beginning of an NP ,\nwhich rules out illegal candidates such as ‘cantora a’ (or\n‘*singer the’). Rule r4 prohibits the permutation of proper\nnames as in ‘*aguilera christina’, which are assumed to be\nalways presented in the correct linear order. As argued in [ 12],\ncomputing the word order of proper names is not an actual\nsurface realisation task. Similarly, rule r5 determines that PP\nmodiﬁers as in ‘de rádio’are to be taken as a single term,\nthat is, they are not subject to permutation as in ‘rádio de’.\nFinally, sentences in our test data often combine several\nPP or adjectival modiﬁers into a single NP , as in ‘o valor\nintegral do aumento salarial’ (‘the pay rise full amount’),\nleading to a potentially large number of NP permutations.\nSome of these alternatives, however, are clearly ungrammat-\nical, as in ‘*do aumento salarial o valor integral’, or, ‘*of\nthe pay rise the full amount’. For that reason, over-generation\nis limited by rule r6, which discards all NP permutations (in\nboth subject and object position) whose determiner is imme-\ndiately followed by a preposition (and which are, at least in\nPortuguese, unacceptable).\nThe beneﬁts of these simple NP linearisation rules to\nboth computational efﬁciency and output accuracy are self-\nevident. On the other hand, adding handcrafted rules to an\notherwise purely statistical approach may always incur a\nwell-known cost, namely, a loss in language-independency.\nAs we will argue in Sect. 5, however, we believe that at least\nin the present case the beneﬁts of linearisation rules may\n6 Alternative approaches to the task of ordering noun modiﬁers are\ndiscussed in [ 30,31].\n123\n140 J Braz Comput Soc (2013) 19:135–146\npossibly outweigh any loss of this kind. In our test data, for\ninstance, the use of one single rule ( r6, prohibiting NP deter-\nminers followed by prepositions) has decreased the candidate\nset produced during over-generation from 37,462 sentences\nto 19,869 sentences, that is, a 47 % reduction. Although this\nis much smaller than the 87 % reduction estimated in [ 22],\nin which a more liberal over-generation strategy was consid-\nered, linearisation rules are still likely to improve results,\nparticularly when combined with more expressive FLMs\n(see Sect. 3.4).\nAll constituents in all orderings are replaced by their\ninﬂected surface forms with the aid of the lexicon in [ 9], pro-\nducing a list of candidate output strings for the given input.\nFor instance, from the Action constituent set in the previous\nexample we may obtain two candidate word strings: ‘terá\nnão’ and ‘não terá’(‘will not have’). Similarly, we would\nobtain six output candidates from the Agent constituent set,\nand four candidates from Patient,\n7 m a k i n g( 6*2*4 = )4 8\ncandidate sentences in total. Some of these alternatives are\nillustrated below, among which sentence 48 happens to be\nthe expected output.\nOptionally, a candidate set as above may be further\nexpanded by considering synonymy as well. In our work\nthis is implemented with the aid of the Brazilian Por-\ntuguese thesaurus presented in [ 10]. Additional alternatives\nare generated by replacing head constituents and their mod-\niﬁers by synonymous words, and then following the same\nover-generation rules described above. However, the use of\nsynonyms is offered simply as an additional feature of our\nsystem, and it is left entirely to the underlying application to\ndecide whether to use it or not. As suggested in [ 25,26] and\nalso by our preliminary experiments in [ 21], using synonyms\nin a principled way remains an open research question, and\nin order to prevent lexicalisation issues from obscuring the\ncomparison between language models, our evaluation work\ndescribed in Sect. 4 will not cover lexicalisation.\n3.4 Language modelling\nIn order to single out the desired output sentence from\nan over-generated candidate set, 2-stage generation sys-\ntems [ 2,3,20,28,29] make use of statistical language mod-\nels to compute the most likely output sentence. Language\n7 Recall that alternatives beginning with a PP as in ‘de rádio’ are\ndisregarded.\nmodels of this kind are usually based on n-gram-counts,\nwhich are known to produce satisfactory results at least for\nless-inﬂected languages such as English. However, in the case\nof our target language—Brazilian Portuguese—we have to\ndeal not only with much greater lexical variation (making\ndata sparse) but also with the lack of sizeable training data.\nIn what follows we attempt to minimise both difﬁculties by\n(a) making use of more expressive language models and (b)\nby making use of a larger training corpus.\nFrom the language modelling perspective (a), we address\nthe issue of data sparseness by replacing standard n-gram\nmodels for Factored Language Models (or FLMs, cf. [ 8]).\nFLMs generalise the n-gram approach by incorporating infor-\nmation from various sources (and not only word counts).\nFLMs are widely used by the speech research community but,\nto our knowledge, their beneﬁts have been seldom applied to\ntext generation.\n8\nIn the FLM approach, each word wt is represented as a\nbundle of k parallel factors { f 1\nt , f 2\nt ,... f k\nt } that may convey\nany word-related information such as classes, roots, semantic\nfeatures, etc. Thus, when no exact n-gram match is found in\nthe training data (as it is often the case in morphologically-\nrich languages), an FLM will allow us to circumnavigate the\nissue of data sparseness by taking into account such alterna-\ntive knowledge sources (and not simply word counts).\nThe design of an FLM requires the deﬁnition of a set\nof individual factors and a strategy to produce an optimal\nstatistical model over them. When there is insufﬁcient data\nto fully estimate a higher-order condition, a standard n-gram\nmodel would simply backoff from a model of order n to an\norder n-1. FLMs, by contrast, may simultaneously drop one\nor more variables associated to each factor, and take different\nfactors into account at the lower level.\nFor instance, when a particular trigram does not occur (a\ncertain number of times) in the data, the model may consider\nprobabilities given by the lemma of the previous word L\nt− 1\nand the part-of-speech of the word before that Pt− 2, and\nthat these probabilities should be combined in a particular\nway to estimate the overall probability of the current word\nWt . Thus, even the simplest FLMs allow a large number of\npossible backoff paths, making directed backoff graphs as\ndiscussed in [ 8]. As we shall see, this may have signiﬁcant\nadvantages over simply backing-off down to the bigram or\nunigram level.\nWe consider bigram and trigram models taking into\naccount either word and lemma factors ( WL models) or\nword, lemma and part-of-speech factors ( WLP models) only.\nWe will call these our 2WL, 3WL, 2WLP and 3WLP mod-\nels, respectively. These models represent the best tradeoff\nbetween computational efﬁciency and output accuracy that\n8 An exception is the work in [ 32] regarding the acquisition of NLG\ngrammars aided by FLMs.\n123\nJ Braz Comput Soc (2013) 19:135–146 141\nwe could obtain over a large number of experiments in\ntext generation. Some of the alternatives to these models\nhave been described in previous work (see Sect. 2) and\ninclude both models of higher order and those using addi-\ntional factors. For instance, the experiments in text generation\ndescribed in [ 6] made use of FLMs that considered gender\nand number factors as well. However, the impact of those\nfactors on output text quality has been found to be small if\ncompared to the increase in computational costs, and for that\nreason gender and number have been presently disregarded.\nThe proposed models are summarised in Fig. 3. Unless\nspeciﬁed otherwise, all models were built using SRILM [33]\nand using the default tool parameters and a back-off strategy\nas follows. The ﬁrst model to be attempted is always the com-\nplete model (i.e., taking all available factors into account). If\nnecessary, the model will back-off to lower levels by drop-\nping one node at a time, starting from the most distant parent\nnode, and discarding the factors W, L and P in this ﬁxed order,\nthat is, from more to less informative factors as suggested\nin [ 8].\n9\nWe assume a minimum count (the gtmin parameter in\nSRILM) of 1 to establish a match, 10 and we compute model\nprobabilities by interpolation with the lower levels. For\ndetails on the mathematical background and design of FLMs\nand parallel back-off, see [ 8].\nLet us consider the above 2WLP model as an example. The\nﬁrst backoff-graph node in 2WLP corresponds to the com-\nplete model that takes all available factors into account, that\nis, the probability of a word Wt is given by the combined\nprobabilities of the previous word ( Wt− 1), lemma ( Lt− 1)\nand part-of-speech ( Pt− 1) factors. If no instantiation of these\nthree values exists (i.e., if these three particular W,L and P\nvalues do not co-occur in the data), the model will backoff\nby dropping the W factor, that is, by attempting to estimate\nprobabilities based on the previous L and P factors alone. If\nthat fails once again, the model will still attempt to estimate\nthe word probability based on the previous part-of-speech\nfactor only, the underlying assumption being that P\nt− 1 may\nstill provide some (even if rather weak) hint at the probability\nof the current word when no other source of information is\navailable. Thus, if a bigram as, e.g., ‘did fail’ does not occur\nin the data, we may still estimate some probability by consid-\nering the more general form ‘do fail’ or even ‘ <verb> fail’\nif necessary.\nWe leave to Sect. 4 to discuss to which extent the use of\nFLMs improve results in the text generation task, but ﬁrst we\nshall brieﬂy consider the corpus perspective (b). Since the\n9 Less conventional back-off strategies were also attempted in a pilot\nexperiment, but results turned out to be below those presently reported\n(cf. Sect. 4).\n10 Pilot tests with higher threshold values in [ 21] showed lower accu-\nracy rates in related tasks.\nFig. 3 Language models under consideration\ntraining data used in previous work (e.g., [ 6]) was deemed\ninsufﬁcient even in the case of standard bigram models, we\nnow intend to use more data to take full advantage of the\nFLM approach. For that reason, the present language models\nwere built from a 142-million words corpus of Brazilian Por-\ntuguese described in [ 34], which included both the original\nNILC corpus [ 7] and an additional collection of full articles\nfrom the on-line 2006–2011 editions of the Folha de São\nPaulo newspaper\n11 and the Veja magazine.12\nThe training corpus was POS-tagged using the Portuguese\ntagger available from the LACIO-WEB website project13 and\nMXPOST.14 Additionally, gender and number tags (required\nfor the pre-processing agreement task, but not used in the\nactual language models) were taken from the Brazilian\nPortuguese lexical database described in [ 9]. Tagging errors\nidentiﬁed during the preparation of the test data (particularly\nin the case of proper names, cf. next section) were also cor-\nrected in the training data to ensure consistency, but the rest\nof the training corpus was left otherwise unaltered, assuming\nthat the statistical approach should accommodate noisy data.\n11 http://www.folha.com.br.\n12 http://www.veja.com.br.\n13 http://nilc.icmc.sc.usp.br/nilc/tools/nilctaggers.html .\n14 http://www.inf.ed.ac.uk/resources/nlp/local_doc/MXPOST.html.\n123\n142 J Braz Comput Soc (2013) 19:135–146\nFig. 4 Sentence length distribution in the corpus test\n4 Evaluation\n4.1 Test data\nWe consider a test corpus comprising a separate collection of\n4,297 randomly selected online Folha de São Paulonewspa-\nper headlines from the year 2009, of up to 9 words in length\neach (7.6 words on average). The actual distribution is illus-\ntrated in Fig. 4.\nAll sentences in the test data set are in the form Agent-\nAction-Patient.T h e Patient term was not compulsory, but\nit turned out to occur in all but 18 sentences. In compari-\nson with the training corpus described in the previous sec-\ntion (containing full articles), test sentences are often sim-\npler, and one may in fact ask why we used a training corpus\nmore powerful than necessary for the task. Our reasons are\ntwofold: ﬁrst, collecting a sufﬁciently large number of indi-\nvidual headlines for training purposes may be impractical;\nsecond, as future work we intend to reuse the same models\nin the generation of newspapers sentences in general, and not\nonly headlines.\nOur Input data set was built as follows. First, the cor-\npus was tagged with POS, gender and number information\nand manually veriﬁed for correctness. This was particularly\nnecessary in the case of proper names, which occur in large\nnumbers in the newspapers domain, and were often tagged\nas nouns, etc. In addition to that, some instances of verbs\nin the participle tense were incorrectly tagged as adjectives,\nand in a few cases gender/number information taken from\nthe dictionary had to be corrected as well. This revision\nwas, however, informal in the sense that we did not seek\nto produce a 100 % accurate corpus (for instance, we did\nnot seek to achieve agreement between judges) but simply\nto identify common errors that could affect our evaluation\nwork.\nAll tagging errors identiﬁed in the test corpus were also\ncorrected in the training corpus (described in the previous\nsection) by using a purpose-built tool. Brieﬂy, the tool takes\nas an input the list of corrections previously made, and then\nperforms a simple search-and-replace operation on the train-\ning corpus, rewriting any text segment containing the iden-\ntiﬁed errors provided that there was no risk of ambiguity.\nFor instance, we did not perform any conversion from noun\n‘machado’ (‘axe’) to proper name as this could result in a tag-\nging error, even though ‘Machado’ is a common Portuguese\nname. Only after these adjustments were completed, the lan-\nguage models described in the previous section were gener-\nated.\nEach test sentence was converted into an abstract sen-\ntence representation by performing two tasks: (1) every con-\ntent word was replaced by its lemma and (2) the constituent\nordering of NP and VP modiﬁers was randomised. Similar\ntechniques for abstracting NLG input data from the expected\noutput strings were applied, for instance, in the data prepa-\nration for the First Surface Realisation Challenge Task[12].\nThe resulting abstract sentence representations are similar to\nthe previous Example 1 in Sect. 3.2.\nThe actual word strings in the corpus are taken to be our\nReference set, against which we intend to compare (therefore\nintrinsically) the output produced by 10 alternative genera-\ntion strategies: the four FLMs ( 2WL, 3WL, 2WLP and 3WLP)\ndiscussed in the previous section, and six baseline systems\nas follows.\n4.2 Procedure\nFor the purpose of evaluation, one may consider at least three\nlines of investigation: (1) how the statistical module performs\nwith and without linearisation rules; (2) how FLMs compare\nto word n-grams; and (3) how the system as a whole compares\nto others.\nThe role of linearisation rules has been addressed to some\nextent in our previous work [ 6] in the context of NP surface\nrealisation,15 in which the use of FLMs alone was found to\nbe insufﬁcient for the task. Using 2WL and 3WL models, the\nwork in [ 6] showed that candidate selection from an uncon-\nstrained set of possible realisations obtained accuracy rates\nof 0.70 and 0.60, respectively. On the other hand, by apply-\ning basic rules to reduce the candidate set, the same models\nobtained accuracy rates of 0.85 and 0.80. These results ﬁrst\nsuggested to us that the FLM approach could be improved\non by using this form of pre-selection, and for that reason\nwe presently do not seek to answer (1) directly, that is,\nwe will simply take the beneﬁts of linearisation rules for\ngranted.16\n15 Recall also that NP linearisation is the most challenging subtask for\nour system.\n16 Note also that reducing the candidate set cannot lead to lower accu-\nracy.\n123\nJ Braz Comput Soc (2013) 19:135–146 143\nQuestion (2)—representing the main claim that we intend\nto verify—is sufﬁciently straightforward: keeping other vari-\nables unaltered (namely, using always the same linearisa-\ntion rules), we will compare different versions of our sys-\ntem using various language models (FLM and word n-gram\nalike). To this end, we will consider three baseline systems\nthat use the same over-generation module but, instead of FLM\nﬁlters, use ordinary 2-, 3- and 4-gram models called 2W,\n3W e 4W. In other words, keeping all other system features\nunchanged except for the actual language model, we would\nlike to show that the FLM approach outperforms these word\nn-gram models, as suggested by some of our previous exper-\niments in [ 22].\nIt is question (3) that poses the most signiﬁcant chal-\nlenge to our evaluation work (and indeed to the evaluation\nof any language-dependent task). As discussed in Sect. 2,\ndifferences in target language and input speciﬁcation make\na direct comparison to, e.g., the participants in the Surface\nRealisation Shared Task [12]o rt o SimpleNLG [19] inap-\npropriate. Thus, in what follows we will consider a num-\nber of simple, nonstatistical baseline systems, and also a\nrule-based realisation engine developed as an independent\nproject [ 34].\nTwo of our nonstatistical baseline systems are trivial: a\nRandom strategy that selects a random permutation from\nthe set of possible candidate sentences, and a Left-to-Right\ntemplate-based approach that simply ﬁlls in the sentence tem-\nplate with matching constituents in the same order as they\noccur in the randomised input speciﬁcation.\nAs a third and more robust alternative, we will also con-\nsider a Rule-based strategy described in [ 34], which makes\nuse of Portuguese grammar rules to enforce constituents\nagreement and sentence linearisation. This system repre-\nsents a complete realisation engine and, for the purpose\nof the present evaluation task, it may be considered a rea-\nsonable approximation to SimpleNLG [19] in the sense that\nboth systems are capable of generating common sentences\nin their target languages (Portuguese and English, respec-\ntively) in similar step-by-step fashion.\n17 More importantly,\nour Rule-based system takes as an input the same represen-\ntation required by our current approach, and generates text\nin the same target language (i.e., Portuguese), which allows\nfor a direct, meaningful comparison between statistical and\nnonstatistical approaches.\nEach of the 10 systems took as an input the same Input\ndata set and produced a corresponding System set of 4,297\noutput strings. The main purpose of the evaluation was to\nmeasure the closeness between each System and Reference\n17 This is not to say, however, that these systems are functionally equiv-\nalent, since differences in target language do not allow a direct compar-\nison between the two.\nsentence pairs, and for reasons discussed in Sect. 3.3 none of\nthe systems was set to consider synonymous words during\nover-generation.\nThe actual comparison between System and Reference\nsentence pairs was carried out by using four standard string\nmetrics (which are expected to correlate): Accuracy or string\nmatch (exact word string match equals 1, or 0 otherwise);\nEdit-distance (i.e., the number of insert, delete and replace\noperations required to make both strings identical); and the\nMachine Translation (MT) metrics BLEU [ 35] and NIST\n[36],\n18 both of which measure n-gram overlap between Ref-\nerenceand System (BLEU scores range from 0 to 1, and NIST\nscores have no upper limit 19).\nA word of caution regarding the interpretation of Accu-\nracy scores: none of the systems under evaluation is cur-\nrently able to make an informed distinction between mul-\ntiple equally acceptable alternatives, as in ‘programa de\nrádio semanal’ vs. ‘programa semanal de rádio’, both of\nwhich translate to ‘weekly radio program’. In these situa-\ntions, Accuracy will heavily penalise all systems that make\nthe ‘wrong’ choice, that is, those which do not select the\nexact word string that happens to occur in the Reference set.\nEdit-distance, BLEU and NIST scores, by contrast, represent\nmore ﬁne grained metrics of closeness between System and\nReference sentences, and are therefore to be preferred. This\nlimitation notwithstanding, we will follow common practice\nin the ﬁeld (e.g., [ 37]) and provide Accuracy results for illus-\ntration purposes.\n4.3 Results\nTable 1 summarises our results. Closer proximity to the\nReference sentence is indicated by higher Accuracy, NIST\nand BLEU values, but lower Edit-distance.\nGiven that BLEU and NIST evaluate each system out-\nput set as a whole (and not individual sentence pairs), and\ngiven that Accuracy is simply a binary condition represent-\ning whether each string pair is identical, we performed one-\nway ANOV A for independent samples over Edit-distance\nvalues, which were shown to have normal distribution and\nhomogeneity of variance. This was followed by the Tukey\nHSD test ( α = 0.05).\nResults showed signiﬁcant differences between the sys-\ntems ( F(9,43) = 400.38, MSE = 51.74, p < 0.001). The\nidentiﬁed homogeneous subsets are shown in Table 2.\n18 Despite being originally proposed in the MT ﬁeld, BLEU and NIST\nhave been widely applied to the evaluation of a number of NLG surface\nrealisation tasks as well [ 12,37,38].\n19 Unlike BLEU, NIST tends to favour less frequent and possibly more\ninformative n-grams. cf. [ 36].\n123\n144 J Braz Comput Soc (2013) 19:135–146\nTable 1 Results\nSystem Accuracy Edit-dist. NIST BLEU\nRandom 0.48 8.77 11.15 0.46\nLeft-right 0.62 5.52 14.58 0.81\nRule-based 0.69 4.55 14.97 0.85\n2W 0.74 4.07 14.84 0.88\n3W 0.75 3.84 14.83 0.88\n4W 0.75 3.84 14.85 0.88\n2WL 0.87 2.10 15.02 0.94\n3WL 0.88 1.95 15.05 0.95\n2WLP 0.89 1.75 15.04 0.94\n3WLP 0.90 1.65 15.07 0.95\nTable 2 Homogeneous subsets for Edit Distance values\nStrategy Avg. edit-dist. Subsets\n3WLP 1.65 A\n2WLP 1.75 A\n3WL 1.95 A\n2WL 2.10 A\n4W 3.84 B\n3W 3.84 B\n2W 4.07 B\nRule-based 4.55 C\nLeft-right 5.52 D\nRandom 8.77 E\nSystems which do not share a letter differ signiﬁcantly at α = 0.05\n5 Discussion\nThe results of the evaluation work show that the systems\nmaking use of FLMs outperform all standard n-grams mod-\nels ( 2W, 3W e 4W) and nonstatistical (Random, Left-right\nand Rule-based) baseline systems alike. According to Table\n2 there was no statistical difference within the FLM or within\nthe n-gram groups. In the case of FLMs, this in principle\nfavours the simplest, most computationally efﬁcient 2WL\nmodel, and in the case of n-grams favours the 2W model.\nHowever, this is not to say that trigram models are not use-\nful for the present task, or that those models still suffer from\ndata sparseness. The high homogeneity in the results may be\nsimply an effect of the kind of test data used in the eval-\nuation: bigram models seem sufﬁcient for the generation\nof short newspapers headlines, but for longer sentences a\nhigher-order model may be called for. Had we considered\nlonger sentences, it might have been possible to observe\ngreater differences within the FLM and n-gram groups, as\nthe progression of Edit-distance, BLEU and NIST scores in\nprevious Table 1 seems to suggest.\nThe present results for the FLM approach are also supe-\nrior to all of our own previous work. For instance, in a pre-\nvious, purely statistical version of our system [ 22]w i t hn o\nassociated rules to limit the number of output candidates,\nEdit-distance scores ranged from 2.69 for a 2WL model to a\nmaximum 1.84 for a 3WLP model using the current test data.\nIn the present case, by contrast, our best performing model\nachieved 1.65 edit-distance. As expected, the inclusion of\nthe linearisation rules described in Sect. 3.3 does improve\nresults, arguably at the cost of a certain loss in language-\nindependency.\nAll systems that consider some kind of statistical model\n(FLMs and n-grams alike) outperform our admittedly simple\nnonstatistical baseline systems. The combination of rules and\nlanguage models, even in the simplest 2W approach, outper-\nforms the Rule-based system as well. This result had not been\nobserved when considering the purely statistical approach in\n[34], in which Rule-based surface realisation still outper-\nformed standard n-gram models.\n6 Final remarks\nThis paper presented a novel application of factored lan-\nguage models (FLMs) in the ﬁeld of text generation, in\nwhich FLMs are intended to overcome data sparseness, an\nissue that is particularly prevalent in morphologically-rich\nlanguage processing. We described a 2-stage shallow sur-\nface realisation system for Brazilian Portuguese generation\nthat takes as an input an abstract sentence representation and\nover-generates multiple candidate sentences with the aid of\na small set of language-dependent linearisation rules. Candi-\ndate selection is performed in a language-independent fash-\nion by using a statistical language model trained on a large\ncorpus of Brazilian newspapers articles, after which the lan-\nguage model ﬁlters out unsuitable alternatives and selects the\nmost likely candidate as the output sentence.\nThe system was applied to the generation of newspa-\npers headlines, in which sentences extracted from online\narticles were regenerated by a number of variations to our\nbasic approach, and also by several statistical and nonstatis-\ntical baseline systems. Results show that using FLMs for\nPortuguese text generation represents not only a novel\napplication of these models, but also suggest that the FLM-\nbased approach may be indeed superior to the use of word\nn-gram models for this task.\nOn the other hand, although not presently discussed, the\nkinds of FLM considered in this paper are signiﬁcantly more\nexpensive (from a computational perspective) than the stan-\ndard n-gram approach. Our system is currently implemented\nat a prototype level only, which may in practice limit its use\nto applications that do not require real-time language gener-\nation. Thus, as future work we intend to examine the issue of\n123\nJ Braz Comput Soc (2013) 19:135–146 145\nsearch optimisation, and also to remove the existing noise\nfrom the training corpus. With these tasks accomplished,\nwe expect to obtain more computationally efﬁcient language\nmodels for practical NLG applications.\nAcknowledgments The authors acknowledge ﬁnancial support by\nFAPESP (grant nr.2009/08499-9), and are also thankful to the anony-\nmous reviewers for their comments to improve this manuscript.\nReferences\n1. Reiter E (2007) An architecture for data-to-text systems.\nIn: European natural language generation workshop (ENLG-2007),\npp 97–104\n2. Langkilde I (2000) Forest-based statistical sentence generation.\nIn: Proceedings of ANLP-NAACL’00, pp 170–177\n3. Varges S (2006) Overgeneration and ranking for spoken dialogue\nsystems. In: Proceedings of the 4th international natural language\ngeneration conference (INLG-2006), Sydney, Australia, pp 20–22\n4. Belz A (2008) Automatic generation of weather forecast texts using\ncomprehensive probabilistic generation-space models. Nat Lang\nEng 14(4):431–455\n5. DeVault D, Traum D, Arstein R (2008) Practical grammar-based\nNLG from examples. In: Proceedings of the 5th international\nnatural language generation conference (INLG-2008), Columbus,\nUSA, pp 77–85\n6. Novais EM, Paraboni I (2011) Highly-inﬂected language genera-\ntion using factored language models. In: 12th International confer-\nence on intelligent text processing and computational linguistics\n(CICLing-2011). LNCS, vol 6608. Springer, Berlin-Heidelberg,\npp 429–438\n7. Nunes MGV , Vieira FMC, Zavaglia C, Sossolote CRC, Hernandez\nJ (1996) A construção de um léxico para o português do Brasil:\nlições aprendidas e perspectivas. II PROPOR, pp 61–70\n8. Bilmes J, Kirchhoff K (2003) Factored language models and gen-\neralized parallel backoff. In: Proceedings of HLT-NAACL-2003,\nvol 2, pp 4–6\n9. Muniz MCM (2004) A construção de recursos linguístico-\ncomputacionais para o português do Brasil: o projeto de Unitex-PB.\nMsc. dissertation, ICMC/USP\n10. Maziero EG, Pardo TAS, di Felippo A, Dias-da-Silva BC (2008)\nA Base de Dados Lexical e a Interface Web do TeP 2.0–Thesaurus\nEletrnico para o Portugus do Brasil. VI Workshop on information\nand human language technology (TIL-2008), pp 390–392\n11. Corston-Oliver S, Gamon M, Ringger E, Moore R (2002) An\noverview of Amalgam: a machine-learned generation module. In:\nProceedings of the international natural language generation con-\nference (INLG-2002), pp 33–40\n12. Belz A, White M, Espinosa D, Kow E, Hogan D, Stent A (2011)\nThe ﬁrst surface realisation shared task: overview and evaluation\nresults. In: Proceedings of the 13th European workshop on natural\nlanguage generation, pp 217–226\n13. Belz A, Bohnet B, Mille S, Wanner L, White M (2012) The surface\nrealisation task: recent developments and future plans. In: Proceed-\nings of the 7th international natural language generation conference\n(INLG-2012), pp 136–140\n14. Bohnet B, Mille S, Favre B, Wanner L (2011) StuMaBa: from deep\nrepresentation to surface. In: Proceedings of the 13th European\nworkshop on natural language generation, pp 232–235\n15. Rajkumar R, Espinosa D, White M (2011) The OSU system for\nsurface realization at generation challenges 2011. In: Proceedings\nof the 13th European workshop on natural language generation,\npp 236–238\n16. Guo Y , Hogan D, van Genabith J (2011) DCU* at genera-\ntion challenges 2011 surface realisation track. In: Proceedings\nof the 13th European workshop on natural language generation,\npp 227–229\n17. Stent A (2011) ATT-0: submission to generation challenges 2011\nsurface realization shared task. In: Proceedings of the 13th Euro-\npean workshop on natural language generation, pp 230–231\n18. Gervas P (2011) UCM submission to the surface realization chal-\nlenge. In: Proceedings of the 13th European workshop on natural\nlanguage generation, pp 239–241\n19. Gatt A, Reiter E (2009) SimpleNLG: a realization engine for prac-\ntical applications. In: European natural language generation work-\nshop (ENLG-2009), pp 90–93\n20. Langkilde-Geary I (2002) An empirical veriﬁcation of coverage\nand correctness for a general-purpose sentence generator. In: Pro-\nceedings of the international natural language generation confer-\nence (INLG-2002), pp 17–24\n21. Novais E, Tadeu TD, Paraboni I (2010) Improved text gener-\nation using N-gram statistics. In: 12th Ibero-American confer-\nence on artiﬁcial intelligence (IBERAMIA-2010). LNAI, vol 6433,\npp 316–325. Springer, Berlin-Heidelberg\n22. Novais EM, Paraboni I, da Silva Junior DFP (2012) Portuguese\ntext generation from large corpora. In: 8th International confer-\nence on language resources and evaluation (LREC-2012), Istanbul,\npp 4010–4014\n23. Abreu SC, Carbonel TI, Coelho JCB, Fuchs JT, Rino LHM,\nVieira R (2007) Summit: um corpus anotado com informaes discur-\nsivas visando sumarizao automtica. In: V Workshop on information\nand human language technology (TIL-2007), pp 1605–1610\n24. Alusio SM, Specia L, Pardo TAS, Maziero E, Fortes RPM\n(2008) Towards Brazilian Portuguese automatic text simpliﬁca-\ntion systems. The ACM Symposium on Document Engineering,\npp 240–248\n25. Reiter E, Sripada S (2002) Human variation and lexical choice.\nComput Linguist 28(4):545–553\n26. Bangalore S, Rambow O (2000) Corpus-based lexical choice\nin natural language generation. In: 38th Meeting of the ACL,\nHong Kong, pp 464–471\n27. Carpenter B (1993) Skeptical and credulous uniﬁcation with appli-\ncations to lexical templates and inheritance. In: Briscoe T, Copes-\ntake A, de Paiva V (eds) Default reasoning and lexical organization.\nCambridge University Press, Cambridge\n28. Oh A, Rudnicky A (2000) Stochastic language generation for spo-\nken dialogue systems. In: Proceedings of the ANLP-NAACL’00\nworkshop on conversational systems, pp 27–32\n29. Ratnaparkhi A (2000) Trainable methods for surface natural\nlanguage generation. In: Proceedings of ANLP-NAACL’00,\npp 194–201\n30. Malouf R (2000) The order of prenominal adjectives in natural\nlanguage generation. In: Proceedings of ACL-2000, Hong Kong,\npp 85–92\n31. Mitchell M (2009) Class-based ordering of prenominal modiﬁers.\nIn: Proceedings of the 12th European workshop on natural language\ngeneration, Athens, pp 50–57\n32. White M, Rajkumar R, Martin S (2007) Towards broad coverage\nsurface realization with CCG. In: MT Summit XI workshop using\ncorpora for natural language generation: language generation and\nmachine translation (UCNLG+MT), pp 22–30\n33. Stolcke A (2002) SRILM: an extensible language modeling toolkit.\nInt Conf Spoken Lang Process 2:901–904\n34. da Silva Junior DFP, Paraboni I, Novais EM (2012) Um Sistema de\nRealização Superﬁcial baseado em Regras para Geração de Textos\nem Português. USP-EACH technical report, pp 1–14\n35. Papineni S, Roukos T, Ward W, Zhu W (2002) Bleu: a method\nfor automatic evaluation of machine translation. In: ACL-2002,\npp 311–318\n123\n146 J Braz Comput Soc (2013) 19:135–146\n36. NIST (2002) Automatic evaluation of machine translation quality\nusing n-gram co-occurrence statistics. http://www.nist.gov/speech/\ntests/mt/doc/ngram-study.pdf (2002)\n37. Gatt A, Belz A (2010) Introducing shared tasks to NLG: the TUNA\nshared task evaluation challenges. In: Krahmer E, Theune M (eds)\nEmpirical methods in natural language generation. LNAI, vol 5980,\npp 264–293\n38. Lucena DJ, Pereira DB, Paraboni I (2010) From semantic proper-\nties to surface text: the generation of domain object descriptions.\nInteligencia Artif 14(45):48–58\n123"
}