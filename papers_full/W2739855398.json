{
    "title": "Geotagging Text Content With Language Models and Feature Mining",
    "url": "https://openalex.org/W2739855398",
    "year": 2017,
    "authors": [
        {
            "id": "https://openalex.org/A4271062298",
            "name": "Giorgos Kordopatis-Zilos",
            "affiliations": [
                "Information Technologies Institute",
                "Centre for Research and Technology Hellas"
            ]
        },
        {
            "id": "https://openalex.org/A1989922693",
            "name": "Symeon Papadopoulos",
            "affiliations": [
                "Information Technologies Institute",
                "Centre for Research and Technology Hellas"
            ]
        },
        {
            "id": "https://openalex.org/A1973679749",
            "name": "Ioannis Kompatsiaris",
            "affiliations": [
                "Information Technologies Institute",
                "Centre for Research and Technology Hellas"
            ]
        },
        {
            "id": "https://openalex.org/A4271062298",
            "name": "Giorgos Kordopatis-Zilos",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1989922693",
            "name": "Symeon Papadopoulos",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A1973679749",
            "name": "Ioannis Kompatsiaris",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W1998797494",
        "https://openalex.org/W2576959384",
        "https://openalex.org/W6712361292",
        "https://openalex.org/W6697525336",
        "https://openalex.org/W6712227673",
        "https://openalex.org/W2316346277",
        "https://openalex.org/W2085554865",
        "https://openalex.org/W2081418428",
        "https://openalex.org/W2006027035",
        "https://openalex.org/W1552847225",
        "https://openalex.org/W2576577228",
        "https://openalex.org/W6697546942",
        "https://openalex.org/W1979987551",
        "https://openalex.org/W2056797670",
        "https://openalex.org/W2295257215",
        "https://openalex.org/W2000566545",
        "https://openalex.org/W2530881456",
        "https://openalex.org/W832964431",
        "https://openalex.org/W2406278207",
        "https://openalex.org/W2080097338",
        "https://openalex.org/W2057519640",
        "https://openalex.org/W2042171707",
        "https://openalex.org/W6982054360",
        "https://openalex.org/W2055820547",
        "https://openalex.org/W2066277938",
        "https://openalex.org/W2026810221",
        "https://openalex.org/W6693528506",
        "https://openalex.org/W2291879256",
        "https://openalex.org/W6675732779",
        "https://openalex.org/W6697575987",
        "https://openalex.org/W2103163130",
        "https://openalex.org/W1905312050",
        "https://openalex.org/W2118067965",
        "https://openalex.org/W6713054044",
        "https://openalex.org/W2068040335",
        "https://openalex.org/W6713342783",
        "https://openalex.org/W2099788234",
        "https://openalex.org/W6697135090",
        "https://openalex.org/W2090420594",
        "https://openalex.org/W2103388840",
        "https://openalex.org/W1538296207",
        "https://openalex.org/W6731802969",
        "https://openalex.org/W2250384498",
        "https://openalex.org/W6712033769",
        "https://openalex.org/W2494084875",
        "https://openalex.org/W6697054221",
        "https://openalex.org/W4233014035",
        "https://openalex.org/W1966633684",
        "https://openalex.org/W2396449312",
        "https://openalex.org/W2296596345",
        "https://openalex.org/W2405831906",
        "https://openalex.org/W2402618584",
        "https://openalex.org/W2576273504",
        "https://openalex.org/W2395878513",
        "https://openalex.org/W2270098840",
        "https://openalex.org/W2129905273",
        "https://openalex.org/W2916497863",
        "https://openalex.org/W2183317442",
        "https://openalex.org/W2398905843",
        "https://openalex.org/W2015570541",
        "https://openalex.org/W2294562143",
        "https://openalex.org/W2400859668",
        "https://openalex.org/W3101000907",
        "https://openalex.org/W2398326419",
        "https://openalex.org/W2284646714",
        "https://openalex.org/W2295468312",
        "https://openalex.org/W2255455642",
        "https://openalex.org/W2296417067",
        "https://openalex.org/W2295808293",
        "https://openalex.org/W2295138512",
        "https://openalex.org/W2103455363",
        "https://openalex.org/W2400453128"
    ],
    "abstract": "The large-scale availability of user-generated content in social media platforms has recently opened up new possibilities for studying and understanding the geospatial aspects of real-world phenomena and events. Yet, the large majority of user-generated content lacks proper geographic information (in the form of latitude and longitude coordinates). As a result, the problem of multimedia geotagging, i.e., extracting location information from user-generated text items when this is not explicitly available, has attracted increasing research interest. Here, we present a highly accurate geotagging approach for estimating the locations alluded by text annotations based on refined language models that are learned from massive corpora of social media annotations. We further explore the impact of different feature selection and weighting techniques on the performance of the approach. In terms of evaluation, we employ a large benchmark collection from the MediaEval Placing Task over several years. We demonstrate the consistently superior geotagging accuracy and low median distance error of the proposed approach using various data sets and comparing it against a number of state-of-the-art systems.",
    "full_text": "See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/318848293\nGeotagging Text Content With Language Models and Feature Mining\nArticle  in   Proceedings of the IEEE · August 2017\nDOI: 10.1109/JPROC.2017.2688799\nCITATIONS\n7\nREADS\n71\n3 authors:\nSome of the authors of this publication are also working on these related projects:\nV4Design View project\nPERICLES FP7 project - Promoting and Enhancing Reuse of Information throughout the Content Lifecycle taking account of Evolving Semantics View project\nGiorgos Kordopatis-Zilos\nThe Centre for Research and Technology, Hellas\n9 PUBLICATIONS   27 CITATIONS   \nSEE PROFILE\nSymeon Papadopoulos\nThe Centre for Research and Technology, Hellas\n155 PUBLICATIONS   1,557 CITATIONS   \nSEE PROFILE\nIoannis (Yiannis) Kompatsiaris\nThe Centre for Research and Technology, Hellas\n676 PUBLICATIONS   5,846 CITATIONS   \nSEE PROFILE\nAll content following this page was uploaded by Giorgos Kordopatis-Zilos on 24 August 2017.\nThe user has requested enhancement of the downloaded file.\n1\nGeotagging Text Content with Language Models\nand Feature Mining\nGiorgos Kordopatis-Zilos, Student Member, IEEE, Symeon Papadopoulos, Member, IEEE, Ioannis (Yiannis)\nKompatsiaris, Senior Member, IEEE\nAbstract—The large-scale availability of user-generated con-\ntent in social media platforms has recently opened up new\npossibilities for studying and understanding the geospatial aspects\nof real-world phenomena and events. Yet, the large majority of\nuser-generated content lacks proper geographic information (in\nthe form of latitude and longitude coordinates). As a result,\nthe problem of multimedia geotagging, i.e. extracting location\ninformation from user-generated text items when this is not\nexplicitly available, has attracted increasing research interest.\nHere, we present a highly accurate geotagging approach for\nestimating the locations alluded by text annotations based on\nreﬁned language models that are learned from massive corpora\nof social media annotations. We further explore the impact\nof different feature selection and weighting techniques on the\nperformance of the approach. In terms of evaluation, we employ\na large benchmark collection from the MediaEval Placing Task\nover several years. We demonstrate the consistently superior\ngeotagging accuracy and low median distance error of the\nproposed approach using various datasets and comparing it\nagainst a number of state-of-the-art systems.\nIndex Terms—geotagging, geolocation, language model, feature\nselection, location estimation\nI. I NTRODUCTION\nThe ubiquitous availability and use of media capturing\ndevices (smartphones, cameras) and the increasing penetration\nof online social networking and media sharing services have\nled to massive increase in the amount of user-generated content\nand discussions related to unfolding news stories and real-\nworld events. A key element of user-generated content is\ntext, which constitutes either the only component of a social\nmedia post, e.g. a tweet, or an annotation that accompanies\na multimedia item (e.g. Flickr image, YouTube video). Text\nannotations are also an important part of online user proﬁles\n(e.g. the description ﬁeld of a Twitter account). In many cases,\nuser-generated text annotations are indicative of the location\nthey originate from or they refer to, either because they\nexplicitly mention particular geographic entities or because the\ntext contains cues that implicitly refer to particular locations.\nYet, the majority of user-generated text is not accompanied\nby proper geographic information either due to the way they\nare generated (e.g., the mobile app used to upload a tagged\nimage is set to not use the GPS coordinates of the device) or\ndue to social media platform policies (for instance, Facebook\nand Twitter remove all Exif metadata, including geolocation,\nG. Kordopatis-Zilos, S. Papadopoulos and Y . Kompatsiaris are with the\nInformation Technologies Institute (ITI), Centre for Research and Technology\nHellas (CERTH), 6th km Charilaou - Thermi, 57001, Thessaloniki, Greece.\ne-mails: {georgekordopatis, papadop, ikom }@iti.gr\nfrom any uploaded image). Being able to perform geotagging\nis often very valuable for social media monitoring applications.\nFor instance, a journalist may be able to identify and cross-\ncheck the location of a breaking news item by corroborating\nmultiple social media posts that have been automatically\ngeotagged. In another example, a business analyst may be able\nto determine the popularity of a particular brand over the globe\nby aggregating the locations that have been automatically\nextracted from social media accounts that mention the brand\nin their posts. To this end, the problem of geotagging has at-\ntracted increasing research interest and a variety of geotagging\nmethods have been proposed to tackle it [36], [56].\nThe most widely used approach for geotagging is geopars-\ning, i.e. the detection of references to known locations with the\nhelp of a gazetteer [1]. Yet, it is often extremely challenging to\nreliably infer the location alluded by an arbitrary piece of text\ncontent using such approaches due to the inherent complexity\nof the problem and the nature of social media content. In\nparticular, there is a number of limitations and challenges\nfaced by geoparsing methods (Figure 1):\n• In addition to “ﬁxed” and well-known location names\n(e.g. cities, neighbourhoods, landmarks), there is a huge\nnumber of geographic names that are often dynamic (e.g.\nshop names, emerging new hip areas). As a result, main-\ntaining a comprehensive and up-to-date list of geographic\nnames is a very challenging task.\n• More often than not, it is often possible to infer the loca-\ntion of a text description without any explicit reference to\ngeographic entities. Such cases appear for instance when\nthere are references to local food or when there is use of\nlocal slang.\n• There is often considerable ambiguity induced by geo-\ngraphic names, since the same name may refer to different\nlocations in the world. For instance, the name Athens\nrefers to more than 20 locations in the US in addition\nto the capital of Greece. Thus, the presence of a single\ngeographic name without any additional context may be\nmisleading in terms of the implied location.\nTo this end, another popular alternative to geotagging is the\nuse of Language Model-based (LM) approaches [43]. Those\nattempt to learn probabilistic text models, which given a piece\nof text, provide an estimate of the likelihood that the text\nrefers to a particular location. LM approaches hold the promise\nof alleviating a number of the above challenges faced by\ngeoparsing methods, since they do not operate on the basis of\nan explicit toponym dictionary, but are instead trained on large\n2\nFig. 1. Visual examples of the estimated locations based on a state-of-the-art geoparsing method [55] (second column) and our proposed Language Model-\nbased approach (third column). In the ﬁrst case, the geoparsing approach only managed to detect a very coarse entity (Japan) close to the true location referred\nin the text of the input image. In the second case, the geoparsing method was confused due to the ambiguity of the mentioned location. In the third case, the\ngeoparsing method could not detect any location. Instead, our proposed LM-based approach correctly estimated the true location of all three input images.\ncorpora of geotagged text, which are nowadays relatively easy\nto collect and are rich in terms of location-speciﬁc language.\nIn addition, being probabilistic in nature, LM approaches\ntake text context into account and do not rely on a speciﬁc\nterm-entity to produce a reliable estimate. However, many\nLM-based approaches suffer from two weaknesses: a) they\nare tuned to produce good estimates at a given geographic\ngranularity, e.g. region, city or at best neighbourhood, and\noften suffer from lack of precision or robustness (i.e. in case of\nan error, their estimate may be very far from the true location);\nb) they are sensitive to the training set used to generate the\nLM and often end up being dataset-speciﬁc, i.e. they suffer\nfrom overﬁtting.\nIn this paper, we address the limitations of previous LM-\nbased approaches to deliver a highly accurate and robust\ngeotagging approach. To this end, we propose two important\nextensions over previous high-performing LM-based systems:\n• Unlike previous LM-based approaches that rely on a\nsingle grid of cells , such as the geotagging system by\nPopescu [40] (which achieved the best results in the 2013\nedition of the MediaEval Placing Task), we propose the\nuse of multiple grids to capture language geographicity at\ndifferent granularities, in a way that ensures both precise\ngeotagging (i.e. providing estimates that are as close as\npossible to the true locations) and resilience in cases\nwhere this is not possible (i.e. provide the best possible\ngeotagging estimate, avoiding very large errors). As a\nresult, the precision at low granularities improved almost\n10 times. More details on the employed methods are\npresented in Sections III-B and III-E.\n• Extending previous approaches that use feature selection\nduring the LM construction step, such as our previous\napproach [23], we propose a more versatile, scalable and\npowerful feature selection and weighting scheme, which\nleads to considerable improvement in terms of geotagging\naccuracy and to increased resilience with respect to the\ntraining dataset. In particular, the impact of feature selec-\ntion is the reduction of median distance error up to ≈88%.\nThe proposed feature selection and weighting schemes\nwere applied on a training set of ≈40M geotagged text\nannotations on a commodity server. More details on the\nfeature selection and weighting methods are presented in\nSections III-C and III-D.\nMoreover, we present a comprehensive experimental study (in\nSection IV) using the YFCC100M large-scale dataset [48] and\nfour editions of the MediaEval Placing Task (2013-2016), in\nall of which the proposed method achieved the best or very\n3\nclose to best performance. In the latest edition (2016), our\nmethod achieved top performance, with P@1km=24.85% and\nmedian error equal to 28km, which was further improved to\n27.4% and 16km respectively, when training the method with\nthe full YFCC dataset. This is the highest reported geotagging\naccuracy in the history of the benchmark when using a com-\npletely independent training dataset and no external resources\n(e.g. gazetteers). In addition, we evaluate the contribution\nof a number of state-of-the-art techniques [23], [50], [51],\nas well as of increasing the size of the training set, to the\noverall performance of the geotagging process. To further drive\nresearch in the area, we publish the implementation of the\nproposed approach as an open-source project 1.\nII. R ELATED WORK\nGeotagging social media content is a challenging task,\nwhich has attracted increasing research interest in recent years.\nDetailed surveys of the ﬁeld were presented in [36] and [56],\ndiscussing a variety of geotagging approaches. Text-based\napproaches are classiﬁed into two broad categories: geoparsing\nand Language Model -based (LM). Geotagging approaches\nbased on the visual content of images, such as the ones by\nHayes et al. [16], [17], Lin et al. [35], Weyand et al. [54] and\nLi et al. [32], offer another interesting alternative solution to\nthe problem, which is, however, beyond the scope of this paper.\nSimilarly, multimodal approaches that combine both text and\nvisual content to produce location estimates, such as the ones\nby Crandall et al. [9], Kelm et al. [20], Trevisiol et al. [49] and\nCao et al. [3] are not further considered here. Yet, it is notewor-\nthy that text-based geotagging approaches are currently much\nmore accurate and reliable compared to visual-based ones,\nwhile combined approaches have at the moment only marginal\ngains compared to text-based approaches at considerable added\ncomplexity. For instance, in MediaEval 2015, the best text-\nbased submission achieved a score of P@1km = 27.3%,\nthe best visual only a score of P@1km = 5.2%, while the\nbest combined approach a score of P@1km = 27.54% [26].\nIn contrast, approaches that exploit information about the\nauthor/creator of a social media post can achieve massive gains\nin performance. For instance, Popescu et al. [41] achieved\nthe best result in MediaEval 2014 ( P@1km = 44.13% and\nm.error=1.9km), by taking into account the recent locations\n(past 24 hours) of the Flickr users that uploaded the test\nimages. However, such methods are only applicable in limited\nscenarios, and thus fall outside the scope of our research.\nA. Geoparsing\nGazetteers are essentially large dictionaries or directories\nthat contain comprehensive lists of geographic entities. These\nare described by various features, such as location, toponym\nand alternate names (when available). Gazetteers typically\ncontain high quality and precise information. However, many\nof them have limited world coverage, which makes them\ninsufﬁcient as a basis for a global geotagging solution. The\nmost well-known gazetteers are Geonames 2, OpenStreetMap3\n1https://github.com/MKLab-ITI/multimedia-geotagging\n2http://www.geonames.org/\n3https://www.openstreetmap.org\nand Yahoo! GeoPlanet 4 and DBpedia [28] (which is not\nlimited to geographical entities).\nSeveral geotagging approaches are based on gazetteers.\nOne of the earlier works in the ﬁeld was presented by\nAmitay et al. [1]. This combined different gazetteers to de-\ntermine the locations of mentioned places in web content.\nKeßler et al. [21] combined existing standards to realize a\ngazetteer infrastructure allowing for bottom-up contribution\nas well as information exchange between different gazetteers.\nThey ensured the quality of user-contributed information and\nimproved querying and navigation using a semantics-based\ninformation retrieval approach. Smart et al. [46] presented a\nframework that accesses multiple gazetteers and digital maps\nin a mediation architecture for a meta-gazetteer service using\nsimilarity matching methods to conﬂate the multiple sources\nof place data in real time. Lieberman et al. [34] introduced\na heuristic method to recognize toponyms and merging lists\nof them into comma groups . Toponyms in comma groups\nshare a common geographic attribute and determine the correct\ninterpretation of the place name. Zhang et al. [55] developed\na supervised machine learning scheme to weigh the different\nfeatures of a world gazetteer and ﬁelds of a Twitter message\nand to create a model that will prefer the correct gazetteer\ncandidate to resolve the extracted expression. Middleton et\nal. [37] employed OpenStreetMap and used spatial ﬁltering\nbased on dynamically declared focus areas to generate inverted\nindexes for the geo-spatial entity recognition.\nB. Language Models\nThe second class of geotagging approaches rely on the\nconstruction of large-scale geographical Language Models\n(LM) from geotagged corpora of text annotations, which act\nas training sets for the model. The goal of LM is to generate\na probabilistic geographic model, which, given an arbitrary\npiece of text, produces probability estimates that the input text\nwas generated (or originates) from speciﬁc locations across the\nglobe. In a typical LM approach, a large corpus of geotagged\ntext items is used for generating (training) the model. This\ntypically takes the form of a set of geographic clusters (discrete\nareas) or a regular grid of cells covering the surface of the\nearth. Each such cluster or cell is associated with keyword\nfrequency statistics that are used to generate location estimates\nfor arbitrary pieces of text.\nOne of the earliest LM approaches was presented by\nSerdyukov et al. [43], where a predeﬁned grid of cells is\nconsidered, and the prior probabilities for multimedia tags of\na training corpus are computed based on the neighborhood\nof the cells where they appear. Hauff et al. [14] attempted to\novercome the limitation of the ﬁxed grid introducing disjoint\ndynamically sized cells. O’Hare and Murdock [39] proposed\na statistical grid-based LM approach, which makes use of the\nWord-Document model, and they investigated several ways to\nestimate the models based on term and user frequency. Another\napproach was presented by Van Laere et al. [51], who ﬁrst\ncluster the training corpus and then use the χ2 feature selection\ncriterion to create a vocabulary for every cluster. They also\n4https://developer.yahoo.com/geo/geoplanet/\n4\nextended their approach in two ways: a) using the Dempster-\nShafer theory of evidence to combine estimation from different\ngranularities and to determine the most probable estimation\n[52]; b) using different term selection techniques, based on\nkernel density estimation and Ripley’s K statistic to improve\ngeotagging accuracy [50].\nC. MediaEval Placing Task\n1) Task description: MediaEval is an annual international\nbenchmarking initiative that includes a number of multimedia\nanalysis and retrieval tasks. Within its context, the Placing\nTask (PT) is dedicated to the geotagging problem using a\ncorpus of geotagged Flickr images and videos for reference.\nParticipants are challenged to estimate the locations (in terms\nof latitude and longitude) of items in a predeﬁned test set\nusing another set of items for training. Every year the released\ntraining and test sets are determined by the task organizers. In\nterms of evaluation, the submitted runs are benchmarked based\non their precision in different ranges and their median distance\nerror. The circular ranges vary from 1m to 1000km covering\ndifferent geotagging granularities. The released datasets, the\nevaluation methods and the results of the participating ap-\nproaches are further described in Section IV and are used as\nthe state-of-the-art performance to compare with.\n2) State-of-the-art geotagging systems: The participating\nsystems in MediaEval PT over four years (2013-2016) are\npresented in Table I. Systems are classiﬁed depending on\nwhether they use one or more of the popular geotagging\napproaches, namely: Language Models (LM), Textual Analysis\n(TA), Visual Analysis (V A),Multimodal Fusion (MF), User\nModelling (UM) and External Resources (ER)5. Among the\nparticipating systems, the approach presented in this paper is\nan extension of the one originally tested in MediaEval PT 2014\n[22] and then extended in PT 2015 [26] and PT 2016 [27].\nTABLE I\nPARTICIPATING SYSTEMS IN MEDIA EVAL PT CLASSIFIED BASED ON\nAPPROACH .\nApproach LM TA V A MF UM ER\nBaseline [53] ✓\nCao et al. [4] [2] ✓ ✓ ✓\nChoi et al. [7] ✓ ✓ ✓\nDavies et al. [11] ✓ ✓ ✓ ✓\nDuong-Trung et al. [12] ✓\nFerr´es et al. [13] ✓ ✓ ✓ ✓\nKelm et al. [19] ✓ ✓ ✓ ✓\nKordopatis et al. [26] [27] ✓ ✓ ✓ ✓\nKordopatis et al. [22] ✓ ✓ ✓\nKordopatis et al. [25] ✓ ✓ ✓\nL. Li et al. [30] [31] [29] ✓ ✓ ✓\nX. Li et al. [33] ✓\nMu˜noz et al. [38] ✓ ✓ ✓\nPopescu et al. [41] [40] ✓ ✓ ✓\nSingh et al. [45] ✓ ✓ ✓ ✓\nSubramanian et al. [47] ✓\nIII. P ROPOSED APPROACH\nThe proposed approach relies on a LM that is built by\ncalculating term occurrence probabilities from processing a\n5These include gazetteers, online services such as translators and geocoders,\ngeo-referenced collections, etc.\nFig. 2. Overview of proposed geotagging approach.\nmassive amount of geotagged items of a training set Dtr .\nGiven the generated model, it is then possible to estimate the\nlocation (in terms of latitude and longitude coordinates) for\nevery query item m in a set of test items Dts . In the case of\nFlickr images and videos (used as experimental test bed in this\nwork), the metadata used include the tags, title, user id, image\nid and description. The metadata used to build the LM are the\ntags and titles of the items in Dtr . The initial LM is further\nreﬁned through feature selection and weighting. Finally, the\nlocation estimation system employs two more steps (multiple\ngrids, similarity search) oriented to achieve more accurate\nestimation in ﬁner granularities. An overview of the proposed\napproach is illustrated in Figure 2. The system response can\nbe modelled as a function Gpr (m)that produces a location\nestimate for media item m. Given the ground truth location\nof item Gref (m), the geotagging precision of the system P at\nrange R is computed based on Equation 1.\nP@R = |{m|d(Gpr (m),Gref (m))< R}|\n|Dts | (1)\nwhere d(x,y)is the geodesic distance between points x and\ny and |Dts |is the total number of items in test set. Also, the\nmedian distance error is computed, which is the median of the\nestimation errors across all test items in Dts , i.e. the distances\nbetween the predicted and actual locations.\nA. Pre-processing\nA pre-processing step is ﬁrst applied to determine the term\nset Tm of every item m. In the case of Flickr images and videos,\ntheir tags and titles are utilized to form the items’ term sets.\nInitially, they are URL-decoded 6 and tokenized. All accents,\npunctuation and symbols are removed, all characters are trans-\nformed to lowercase, and all tokens consisting of numerics\nare removed. Additionally, there are multi-keyword tags, of\nwhich the keywords are linked by whitespaces. These multi-\nkeyword tags are further split to single tags (e.g., statue of\nliberty is split into statue, of and liberty) and these\nare then added to the resulting tag set (if not already included).\nAs a result, multi-keyword tags are included both as a whole\nand as separate tokens. The purpose of this operation is to\nincrease the inﬂuence of multi-keyword tags on the geotagging\n6This is speciﬁc to the MediaEval Placing Task dataset: texts in different\nlanguages are URL encoded.\n5\nresults, and reduce the one of frequently occurring terms (e.g.\nnew, san). After pre-processing, several items in Dtr are left\nwith no tags and title and are hence disregarded from the\nremaining steps.\nThe terms of the resulting term sets associated with input\nitems are considered as their representative features and are\nfurther processed for training the geotagging approach. The\nset of all unique terms of all items in Dtr is denoted as T.\nNote that the same pre-processing is applied on the test\nitems before the actual location estimation process, since the\nformat of the test set is the same. Nevertheless, for estimating\nthe location of a query item, its description is only used in\ncases where the term set from its tags and title is empty or did\nnot generate any estimated location. Item descriptions are not\nused in any other case, since this would lead to less accurate\nresults due to the fact that descriptions are sometimes very\nlong and may refer to multiple locations, often irrelevant to the\nmain location of the item. This was experimentally conﬁrmed.\nB. Language Model\nThe LM is constructed using a scheme that was originally\npresented in [40]. According to this, a rectangular grid C of\ncells is considered at granularity g and a map of term-cell\nprobabilities is generated. Figure 3 illustrates an example of\nan LM cell with its term-cell probabilities. In the cell that lays\nupon the New York city, terms nyc, manhattan, york, etc.\nhave high probability; in contrast, general interest terms (e.g.\nnew) are assigned lower probability scores, because they are\ncommonly used in many other cells around the globe. Note\nthat the particular example is just for visualization purposes\nand the illustrated grid does not accurately reﬂect reality. Since\nthe earth is ellipsoid and its projection on a 2D plane causes\ndeformation, cells become shorter as they approach the poles\ninstead of having the same side height across the entire globe.\nFor the needs of the proposed approach, four grids at\ndifferent granularities are considered. Starting from coarser\nto ﬁner granularity, we consider grid cells at the level of\nregion, city, neighborhood and street with sides\nof 1◦, 0.1◦, 0.01◦ and 0.001◦ for both latitude and longitude,\ncorresponding to geodesic distances of approximately 100km,\n10km, 1km and 100m near the equator, respectively. The\ndefault LM for our system is built at a neighborhood level,\nsince this was empirically found to lead to better results. The\nremaining grid levels are deﬁned for the following reasons:\na) to support the formulation of the multiple grids technique\n(cf. section III-E); b) to support the generation of geotagging\nmodels that are better tuned for other granularities (e.g. to\nproduce coarser or much more detailed location predictions).\nThe main purpose of the LM is to estimate the most likely\ncell c ∈C for a query item m based on its term set Tm. The\nprobability p of a term t in a particular cell c is calculated as\nthe total number of different Flickr users that used t inside c,\ndivided by the total count of users over the entire grid C. For\nsimplicity, the total count of different users over the whole grid\nC that used a speciﬁc term t will be referred as the user count\nFig. 3. Visual example of LM term-cell probabilities.\nof t. Eventually, the term-cell probability p(t|c)is calculated\nfor every term t ∈T according to Equation 2.\np(t|c)= Nu,c\nNt\n(2)\nwhere Nu,c is the number of users in Dtr that used the term t\ninside the borders of cell c, and Nt is the user count of term\nt in all cells. Note that a user can be counted in Nt more than\nonce. If a user u is found in multiple cells, every time he/she\nis found in a different cell, he/she is considered as a new user\nand increases the total count of users.\nTo assign a query item to a cell, the probability of each\ncell of C is ﬁrst calculated summing up the contributions of\neach term in T. Then, the cell with the highest probability is\nselected as the most likely cell (mlc) according to Equation 3.\nmlcm = argmax\nci ∈C\n|Tm |Õ\nk=1\np(tk |ci) (3)\nwhere Tm is the set of terms for item m, and p(tk |ci)is the\nterm-cell probability for term tk ∈Tm in cell ci ∈C. As a\nresult, the centroid of the estimated mlc may be considered as\na coarse location estimation for query item m and is denoted\nby Glm\npr (m). If during this process there is no outcome (i.e. the\nprobability for all cells is zero), then the description of the\nquery item m (in case of Flickr images and videos) is utilized.\nFor items where there is no result (e.g. images completely\nlacking text annotations), their location is set equal to the\ncentre of the most populated cell, which is a kind of maximum\nlikelihood estimation.\nC. Feature selection\nTo increase the robustness of the model and reduce its\nsize, a feature selection scheme is necessary, which reduces\nthe set of features (terms) into a compact set Ts ⊂T, with\n|Ts |<< |T |. The goal of this reﬁnement is the selection of the\nmost appropriate terms based on their ability to discriminate\ndifferent locations from each other. A ﬁrst ﬁltering step\nremoves all terms in T that are used by only one user, as they\nare considered user- and dataset-speciﬁc. The reduction of the\nterm set through this simple step is dramatic (up to 87%). The\nremaining terms are then ranked and ﬁltered on the basis of\nthree measures: accuracy, spatial entropy and locality.\n6\n1) Accuracy: This was originally proposed in [23] as a\nmeans of quantifying the geotagging capability of terms and\ncorrelating their occurrence with correct location estimates. To\ncalculate the accuracy of a term t ∈T, a scheme similar to\ncross-validation is employed. First, Dtr is partitioned into q\nfolds. The number of partitions is empirically selected; in our\nexperiments, it is set to 10. Subsequently, one partition Dp\ntr at\na time is withheld, and the remaining p −1 partitions are used\nto build the LM. Using this LM, the location of every item in\nthe withheld partition is predicted as described in subsection\nIII-B. Then, accuracy is computed as the ratio of the correctly\ngeotagged items where the term appears over the total number\nof items where the term appears (Equation 4).\nα(t)= |{m|t ∈Tm ∧d(Gpr (m),Gref (m))< R}|\nmt\n∈[0,1] (4)\nwhere α(t)is the accuracy of term t, the numerator determines\nthe total number of correctly geotagged items (within range\nR) associated with t in Dp\ntr , and mt is the total number of\nitems in Dp\ntr where the term t occurs. The selected range\nR is considered as a system hyperparameter and its effect\nis explored in Section IV-A. The grid used for the accuracy\ncalculation is always the same as the grid of the default LM.\nTo perform feature selection, terms in T are sorted in\ndescending order based on their accuracy generating a ranked\nset of terms Tα. Terms with the same accuracy score are further\nsorted based on their frequency. In that way, it is possible to\nbuild an LM with a target number of terms N by selecting the\nﬁrst N elements of Tα.\n2) Spatial Entropy: This feature selection measure attempts\nto capture the spatial ambiguity of terms [22]. The measure\nis computed by quantifying the stochasticity (or randomness)\nin the spatial distribution of the term. To this end, the spatial\nentropy of a term is computed based on the Shannon entropy\nformula on the term-cell probability distribution (Equation 5).\nse(t)= −\n|C |Õ\ni=1\np(t|ci)log p(t|ci) (5)\nwhere se(t)is the spatial entropy of term t and p(t|ci)is the\nterm-cell probability of t in cell ci ∈C. In a sense, spatial\nentropy expresses the amount of information conveyed by term\nt regarding a cell c. Terms appearing in few cells tend to have\nlow spatial entropy values (high information), while terms with\na relatively uniform distribution over many cells have high\nentropy values (low information).\nFor feature selection, the terms in T are sorted in ascending\norder based on their spatial entropy resulting in a ranked\nterm set denoted as Tse. The grid granularity that is used for\nthe calculation of spatial entropy is considered as a system\nhyperparameter and its effect is explored in Section IV-A.\nHence, the LM can be built based on a target number of N\nterms by selecting the ﬁrst N elements of Tse.\n3) Locality: In [50], Van Laere et al. introduced two\napproaches to capture the spatial discrimination of a tag: a\nmethod based on Kernel Density Estimation (KDE) [44], and\none based on Ripley’sK statistic [42]. However, both methods\nare computationally expensive. Thus, the main objective of\ndeﬁning locality has been to come up with a measure that is\nequally discriminating as the Ripley’s K statistic, but compu-\ntationally much lighter so that it is possible to compute over\nmassive datasets.\nThe computation of locality is based on the number of\ndifferent users that make use of a term in the same cells. The\nlocality score of a term is calculated based on the term user\ncount and the unique users that have used it in a cell of the\ngrid. The users that have used a term t in a cell c are assigned\nto the unique user set Ut,c of that particular cell. Every unique\nuser u ∈Ut,c is associated with all other users included in the\nset, i.e. with |Ut,c |−1 other unique users in c. Locality derives\nfrom the summation over all such user associations across all\ngrid cells divided by the total user count. As a result, cells\nwith only a single user in their set do not affect the locality\ncalculation. Locality is computed according to Equation 6:\nl(t)=\nÍ\nc∈C\nÍ\nu∈Ut,c |Ut,c |−1\nNt\n=\nÍ\nc∈C |Ut,c |(|Ut,c |−1)\nNt\n(6)\nwhere l(t)is the locality score of term t, Nt is the user count\nof t, C denotes the set of cells and Ut,c denotes the set of\nusers that used tag t in cell c.\nSimilar to the previous feature selection measures, the terms\nin set T are sorted in descending order based on locality. Terms\nwith the same locality score are further sorted based on their\nuser count. In that way, a ranked term set Tl is generated.\nThe grid granularity that is used for the calculation of locality\nis considered as a system hyperparameter and its effect is\nfurther explored in Section IV-A. Similar to the aformentioned\nmeasures, it is possible to build an LM with a target number\nof terms N by selecting the ﬁrst N elements of Tl.\nD. Feature Weighting\nFeature weighting aims to make geotagging more accurate\nby giving more importance to terms with good accuracy,\nspatial entropy and locality scores. To this end, weighting\nscores wα, wse and wl are computed for each term in the set of\nselected features Ts based on scores α, ses and l respectively.\nSince accuracy scores are already in the range [0,1], the\ngenerated weights are equal to them, i.e. wα = α.\nThe computation of spatial entropy weights is a bit more\ncomplicated. Based on our observations, terms with either too\nhigh or too low entropy values typically carry no geographic\ninformation. For instance, terms with too low entropy values\ntend to be user-speciﬁc. In contrast, very high entropy values\nindicate terms that are widely spread across the globe. Such\nterms carry no geographical interest (e.g., baby and fun)\nand therefore their inﬂuence on location estimation needs to\nbe suppressed. To this end, after experimenting with different\ndistribution functions that appeared to ﬁt the empirical spa-\ntial entropy distribution, we selected the gamma distribution\n(Equation 7) for transforming the spatial entropy values.\nF(se(t)|a,b)= 1\nbaΓ(a)se(t)a−1e\n−se (t)\nb (7)\nwhere F is the probability density function of the gamma\ndistribution, and parameters a, b are the shape and scale pa-\nrameter respectively, which are learned based on the empirical\n7\n0 1 2 3 4 5 6 7 8\nEntropy Value\n1.5\n3\n4.5\n6\n7.5Number of tags\n× 105\n0.1\n0.2\n0.3\n0.4\n0.5\nGamma Distribution\nFig. 4. Histogram of spatial entropy values based on city level grid and the\ncorresponding probability density function of the ﬁtted gamma distribution.\nspatial entropy distribution on Dtr . The transformed values are\nthen used as the spatial entropy weights. Figure 4 illustrates\nthe distribution of entropy values along with the ﬁtted density\nfunction. These weights are then normalized (by dividing them\nwith the maximum value in the new distribution) to bring them\nin the range (0,1].\nLocality scores are quite sensitive to the respective term\nfrequencies. To mitigate this sensitivity, terms in Tl (set\nof selected terms ordered by locality) are assigned weights\nproportional to their position in Tl (Equation 8).\nwl = |Tl |−( j −1)\n|Tl | (8)\nwhere wl is the weight value of term t on the j-th position in\nthe ordered set Tl. This weighting approach returns values in\nthe range (0,1].\nTo combine the three weights, a linear scheme is applied:\nwt = ωα ·wα + ωse ·wse + ωl ·wl\nωα + ωse + ωl = 1 (9)\nwhere wt is the ﬁnal term weight, wa, wse and wl are the\nweights derived based on accuracy, spatial entropy and locality,\nrespectively, and ωα, ωse and ωl are constants that determine\nthe effect of each weight, and summing to 1. The choice of\neach ω will be discussed in the evaluation Section IV.\nFinally, after the computation of the ﬁnal term weights,\nthe estimation of the most likely cell for a query item m is\nperformed using Equation 10.\nmlcm = argmax\nci ∈C\n|Tm |Õ\nk=1\nwtk p(tk |ci) (10)\nTable II presents the top 15 terms based on the generated\nweighting scores (computed at the neighborhood grid).\nTerms ranked by accuracy correspond to very speciﬁc loca-\ntions or events (Table II(a)), those ranked by the spatial entropy\nweight correspond to landmarks or points of interest, while\nlocality ranked terms correspond to cities. This means that the\nthree weighting scores capture different types of geographic\ninformation and are all valuable in deriving a total weighting\nscore that captures the importance of a term for location\nestimation.\nTABLE II\nTOP 15 TERMS BASED ON THEIR WEIGHTS .\n(a) accuracy\nbarclays center arena\nromanische kunst\nuntermyer\npassim\nrigid inﬂatable boats\ncpbrasil\nnational police week\nfestineuch\nlincoln imp\ndavid bell\ngangale\nfrannie garretson\nprotest photography\nbarnsdall art park\nbuskersbern\n(b) spatial-entropy\nkaiyukan\ncancale\ncollins street\ngatorland\nfriedrichstraße\nhow long is now\nfairford\nbeaumaris\nplaza del pilar\namarapura\nqueens house\nstintino\nmarischal\nport macquarie\nroosevelt island\n(c) locality\nlondon\nparis\nnyc\neiffel\nsan francisco\nbarcelona\nyork\nfrancisco\nberlin\nlouvre\nmanhattan\namsterdam\nrome\nbrooklyn\nnew york\nFig. 5. Depiction of the Multiple Grids technique using Singapore as example.\nE. Multiple Grids\nTo ensure more reliable and accurate estimations, the es-\ntimations based on two LMs at different granularities are\ncombined into a single estimation. The most likely cells for\nthe coarser and ﬁner granularities are denoted as mlcc and\nmlc f respectively. The combination of the two is performed\nusing the multiple grids method originally proposed in [22]:\nif the estimated ﬁne granularity cell mlc f falls within the\nborders of the estimated coarse granularity cell mlcc, then the\nprediction of the ﬁner granularity is considered reliable and the\nﬁnal estimated cell is mlc f . Otherwise, the ﬁnal estimated cell\nis mlcc, since coarser granularity LMs are considered more\nreliable by default, assuming that more data per cell are used\nfor their creation, and hence the resulting probabilistic analysis\nis more robust. The process is outlined by the Equation 11 and\nillustrated in Figure 5.\nmlcmg =\n{\nmlc f if mlc f ⊆mlcc\nmlcc otherwise (11)\nwhere mlcmg is the estimated cell from the multiple grids\ntechnique.\n8\nThe red granularity grid in Figure 5 represents the coarse\ngranularity and the blue the ﬁne one respectively. The most\nlikely cell of the red grid mlcc has been colored green. If\nthe most likely cell of the ﬁner grid mlc f is one of the blue\ncells of the particular example, then the ﬁnal estimation of the\nsystem would be based on mlc f ; otherwise, in case that mlc f\nis outside mlcc, then the whole green cell mlcc will be used\nto produce the ﬁnal estimation.\nA related but much more complicated method was used\nin [52], where the authors combined the results of multiple\ngeographic models using the Dempster-Shafer theory of evi-\ndence to determine the most reliable prediction. However, the\napproach in [52] is not based on regular grids, but on spatial\nclusterings of items using k-means for different values of k.\nF . Similarity Search\nGiven the most likely cell for a query item, a further\nreﬁnement is conducted using the similarity search technique\nof [51]. This is done by identifying the k most similar items\nto a query item from Dtr in terms of textual similarity, and\ncombining their locations (weighted by their similarity to the\nquery). To this end, we ﬁrst compute the textual similarity\nbetween the query item m and every item in Dtr that falls\ninside the borders of mlcmg by use of the Jaccard similarity\non the corresponding sets of terms (Equation 12).\nJ(Tm,Ti)= |Tm ∩Ti |\n|Tm ∪Ti |,m ∈Dts,ci = mlcmg (12)\nwhere Tm, Ti denote the term sets of items m and i, respec-\ntively, and ci is the cell of item i.\nAfter calculating the similarity with every item in the mlc,\nthe top k most similar items to the query are selected and\nthe ﬁnal estimation is the centre-of-gravity of their locations,\nweighted by the similarity values. The estimated location for\nitem m is determined by Equation 13.\nGss\npr (m)= 1\nk\nkÕ\ni=1\nJ(Tm,Ti)a ·loc(i) (13)\nwhere parameter α ∈ [0,+∞)determines how strongly the\nresult is inﬂuenced by the most similar items and loc(i)\ndenotes the vector of coordinates for item i. For the accurate\ncalculation of the average location [51] 7, the location coor-\ndinates of the k items are ﬁrst transformed to the Cartesian\n(x,y,z)system and after the computation are transformed back\nto spherical coordinates (latitude, longitude).\nIV. E VALUATION\nFor the evaluation of the proposed approach, we use the\nprecision P in various ranges R (P@R), computed by Equation\n1, and the median distance error, which is the median of the\nestimation errors across all test items in Dts in terms of the\ndistance between the predicted and the actual location.\nThe datasets used for building the LMs and testing the\napproach are all derived from YFCC100M [48]: Dtr consists\nof all the images and videos in YFCC100M that are geotagged,\n7http://www.geomidpoint.com/calculation.html\nexcluding all items of users that are also included in the test set\nto avoid over-ﬁtting and providing misleading results. Dts was\nreleased by the organizers of MediaEval PT, and its different\nversions are presented in Table III. All datasets used in this\nsection consist of images and videos (except for the 2013\nversion that contains only images). The way that both videos\nand images are processed is identical.\nTABLE III\nFOUR EDITIONS OF MEDIA EVAL PT USED FOR TESTING .\nYear Training Set Test Set Originimages videos images videos\n2013 [15] 8,539,050 - 262,000 - Flickr\n2014 [8] 5,000,000 25,000 500,000 10,000 YFCC100M\n2015 [5] 4,672,382 22,767 931,573 18,316 YFCC100M\n2016 [6] 4,991,679 24,955 1,497,464 29,934 YFCC100M\nThe calculation of geodesic distance between the estimated\nand the real location of an item is based on Karney’s algo-\nrithm [18] 8, which relies on the assumption that the shape\nof the earth is an oblate spheroid. This algorithm produces\nmore accurate distances than methods such as the great-circle\ndistance that assume the shape of the earth is spherical.\nFor the sake of brevity, we use the following short names for\nthe components of the approach: LM (Language Model), FSx\n(Feature Selection), FW (Feature Weighting), MG (Multiple\nGrid), and SS (Similarity Search).\nA. Fine Tuning\nA set of 100k items was withheld from the training set\nand was used for experimenting with different values of the\nmethod’s parameters to optimize performance in terms of\nP@1km and median distance error. In particular, parameter\ntuning was carried out with respect to the thresholding used\nfor each feature selection measure, and the ω factors used for\nfeature weighting in Equation 9.\n1) Feature Selection: In this paragraph, we evaluate the per-\nformance of an LM built at neighborhood level, involving\na certain number of terms denoted by Tα, Tse or Tl, as selected\nby the three feature selection measures of section III-C. After\nthe initial ﬁltering, where the terms used by a single user were\nremoved, the total amount of remaining terms is ≈2M. The\nobjective of this step is to minimize the median error of the\nlocation estimations by selecting a certain number of top terms\nfrom the ranked sets Tα, Tse, Tl. As described in section III-C,\nfor tuning term selection with respect to accuracy, different\nvalues of parameter R are considered (i.e. 1km, 10km and\n100km); instead, for tuning with respect to spatial entropy\nand locality, the four granularity levels are compared.\nFigure 6 depicts the performance of the different feature\nselection measures in terms of median error. The locality\nmeasure appears to lead to the best results. The minimum\nmedian error of 28km is reached when the top 600k tags are\nselected at the city grid (Figure 6(c)). Regarding accuracy,\nthe best performance is achieved for R = 100km at 1.1M tags\nwith 92km median error (Figure 6(a)). Finally, spatial entropy\nperforms the worst in comparison to the other two measures\n8http://geographiclib.sourceforge.net/geod.html\n9\n0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2\nRank of terms × 106\n101\n102\n103\n104\nMedian Distance Error (km)\nR = 1km\nR = 10km\nR = 100km\n(a) accuracy\n0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2\nRank of terms × 106\n101\n102\n103\n104\nMedian Distance Error (km)\nregion\ncity\nneighborhood\nstreet (b) spatial entropy\n0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2\nRank of terms × 106\n101\n102\n103\n104\nMedian Distance Error (km)\nregion\ncity\nneighborhood\nstreet (c) locality\nFig. 6. Median distance error (km) of the approach when selecting an increasing number of features (terms) ranked based on accuracy, spatial entropy and\nlocality scores. Accuracy metric is tuned based on the range R, spatial entropy and locality are tuned based on the granularity grid used.\n(a) ωα - ωse\n (b) ωse - ωl\n (c) ωl - ωα\nFig. 7. Geotagging precision at 1km (%) of the approach using the different values of ωα, ωse , ωl . Blue color indicates higher precision, whereas red color\nlower precision.\nfor all grid levels, since it needs almost all features to perform\nequally well as other much more succinct models produced\nusing locality and accuracy. In particular, the region grid\nperforms the best with 150km median error when the top 1.9M\ntags are selected (Figure 6(b)).\nThe ﬁnal term set used to build the LM is the intersection\nof sets Tα, Tse or Tl that maximizes geotagging performance\nin terms of median error, i.e. Ts = Tmax\nα ∩Tmax\nse ∩Tmax\nl ,\nwhere Ts is the selected term set and Tmax\nx is the subset\nof Tx that minimizes the median error. The feature selection\nscheme is initially applied to signiﬁcantly reduce the amount\nof processed terms and minimize the requirements of the\napproach in terms of computation time and storage space. The\ntotal size of the selected term set Ts is 550,050 terms, which\nequals to approximately 4% of the initial term set.\n2) Feature Weighting: The goal of this step is to deter-\nmine the combination of weight parameters that maximize\ngeotagging performace. The performance metric used for the\ntuning is P@1km, because it was found to be sensitive to\nsmall variations between the setups and hence can express\nthe differences in performance more accurately compared to\nmedian error. The results of the approach for different values\nof ωα, ωse, ωl are illustrated in Figure 7. In each plot, the\ndependence of performance on every pair of ω parameters\nis presented; at each point, the third weight value derives\nfrom the constraint of Equation 9. The triangular form is\ndue to the fact that the sum of three parameters can never\nexceed 1. Blue color corresponds to parameter values leading\nto higher P@1km, while red to parameter values leading to\nlower P@1km. The plots indicate that higher locality and\nspatial entropy weights lead to better geotagging performance.\nIn the ﬁrst parameter pair, deep blue is concentrated at the left\nside. In this area ωα is equal to zero and ωl has values 0.3-0.5\nindicating that ωse has values 0.5-0.7. This parameter set is\nfurther supported by the rest of the plots. In the ωl-ωse pair,\nthe deepest blue color is in the hypotenuse of the triangle and\nin the ωα-ωse, it is at the bottom side of the triangle. As a\nresult, the values of ωα, ωse, ωl are selected to be equal to\n0.0, 0.65, 0.35 respectively.\nIt is noteworthy that ωα is set to zero, even though accuracy\nwas found to be beneﬁcial for feature selection. In contrast,\nωse was found to have the highest weight among others,\ndespite the fact that spatial entropy scoring had only minimal\nimpact on the feature selection process. This observation\ndemonstrates the complementarity among the three feature\nselection and weighting measures and the fact that all three of\nthem contribute to optimizing the geotagging performance of\nthe approach.\nB. Performance Analysis\nThis section explores in detail the performance of the\napproach. All experiments use the parameter set that was\nselected in the previous section. The objective of the discussion\nis to highlight the contribution of each of the processing steps\ndescribed in section III to the overall geotagging performance.\nThe training dataset used for these experiments is the entire\nYFCC100M, excluding all items from users also appearing\nin the test set. Hence, the total number of items used for\ntraining is ≈40M. The test set used in all experiments is the one\n10\nTABLE IV\nGEOTAGGING PRECISION (%) FOR FIVE RANGES AND MEDIAN\nGEOTAGGING ERROR (KM) FOR DIFFERENT CONFIGURATIONS OF THE\nPROPOSED APPROACH .\nLM FS FW MG SS P@10m P@100m P@1km P@10km P@100kmm. error\n✓ 0.02 0.75 23.83 40.67 47.96 173\n✓ ✓ 0.02 0.81 26.57 47.08 55.08 20\n✓ ✓ ✓ 0.02 0.81 26.83 47.85 56.06 16\n✓ ✓ ✓ ✓ 0.18 7.15 27.18 47.85 56.06 16\n✓ ✓ ✓ ✓ ✓ 0.70 7.52 27.40 47.86 56.06 16\n0 [1, 5] [6, 10] [11, 15] [16, 20] [21, 25] [26, 30] [31, ...)\nNumber of terms\n10\n100\n1.000\n10.000Media Distance Error (km)\nLM\nLM+FS\nLM+FS+FW+MG+SS\nFig. 8. Median geotagging error (km) with respect to the number of terms\nper item for different approach variations.\nreleased by the organizers of MediaEval 2016 PT, comprising\n1,527,398 items.\nTable IV presents the performance of the framework when\ndifferent processing steps are included. The base approach\nusing solely the LM performs poorly in low ranges, e.g. it\nachieves P@100m=0.75%, and has a high median error of\n173km. Applying the feature selection scheme (FS) described\nin section IV-A, the median error is dramatically reduced to\n20km and the precision in medium/high ranges improves in\nabsolute terms by more than 10%. Applying feature weight-\ning (FW) further reduces the median error to 16km and\nleads to slight improvements in the medium/high ranges (10,\n100km). The introduction of multiple grids (MG), leads to\nsigniﬁcant improvements (almost 10-fold) in the low ranges\n(10, 100m), e.g. reaching P@100m=7.15%. Finally, the best\nresults are achieved by also integrating the similarity search\nstep (SS), which leads to a performance of P@100m=7.52%,\nP@1km=27.40% and 16km median distance error.\nFigure 8 depicts the performance of the approach on\ndifferent subsets of images that differ with respect to the\nnumber of terms associated with them. It becomes obvi-\nous that the introduction of feature selection (FS) leads to\ndramatic improvements with respect to median error: while\nin the original LM-based approach, geotagging performance\nstarts deteriorating for items with more than 15 terms, the\nFS-powered version of the system manages to retain stable\nperformance for almost all items with more than 15 terms.\nAs a result, the LM+FS version of the system achieves a\nmedian error of just 3.6km for items with a number of terms\nin the range [21,25], while applying the additional reﬁnements\n(FW+MG+SS) leads to a further decrease of the error to just\n3km for items with number of terms in the range [26,30].\nFig. 9. Spatial distribution of median distance error per cell of the best system\nconﬁguration. Deep blue color indicates median error < 100km, whereas\nbrown red color indicates median error > 1000km.\nFigure 9 illustrates the median geotagging error per cell\nacross the globe. The cells with median error less than\n100km are displayed with deep blue color, whereas those with\nmore than 1000km are displayed with brown red color. It is\nnoteworthy that in North America and Australia the dominant\ncolor is brown (very high error), despite the availability of\nmuch more training data and the prevalence of English text\n(which is expected to be easier to handle). In contrast, in\nEurope large areas are painted in blue, so in these areas the\nsystem worked considerably better. A possible explanation for\nthe high error levels in the US and Australia is the potential\nambiguity in town and city names (e.g., many American and\nAustralian towns are named after popular European ones).\nTo further delve into this performance aspect, we compute\nthe spatial entropy of terms in the test set based on the scheme\npresented in section III-C2 (at the city granularity level) and\ncreate a scatter plot of the terms’ geotagging precision at 10km\nrange in relation to their spatial entropy. The precision of a\nterm is computed over the set of items that are associated with\nthis term. The scatter plot, which is illustrated in Figure 10,\ncomprises all terms that occur more than 100 times in the\ntest set and are associated with at least two different places\nfrom the Geonames dataset 9 (in particular, the cities with a\npopulation above 1,000).\nThe plot reveals that terms with relatively large spatial\nentropy values tend to be associated with low precision scores,\nand vice versa. To further study the hypothesis that text\nannotations with ambiguous names are harder to geotag, we\ncompute the median of the spatial entropy values of ambiguous\nterms with more than 100 occurrences ( Ma=3.626) and split\nthis set in two groups, one with terms that have spatial entropy\nless than Ma and one with the remaining ones. Accordingly,\nwe generate two sets of items from the Mediaeval 2016 PT\ntest set, denoting them as low-ambiguity set (Low-AS) and\nhigh-ambiguity set (High-AS) respectively. The geotagging\nperformance for these two sets is reported in Table V. The\nresults conﬁrm our hypothesis that text annotations of low\nambiguity can be geotagged with higher precision compared to\nthose of high ambiguity. For instance, the low-ambiguity items\nwere geotagged with a P@100m=15.22% and median distance\n9http://www.geonames.org/\n11\n0 0.2 0.4 0.6 0.8 1\nGeotagging Precision\n1\n2\n3\n4\n5\n6\n7\n8Spatial Entropy\nFig. 10. Scatter plot of geotagging precision ( P@10km) in relation to spatial\nentropy for the most frequently appearing ambiguous terms. The red line\nindicates the median of the spatial entropy values.\nerror of 1.09km. The accuracy for the highly ambiguous set\nis considerably lower, but still higher than the one obtained\nusing the overall test set. This is attributed to the fact that the\noverall test set contains a considerable number of items with\nno or very little annotations, which is even more challenging\nfor text-based approaches compared to ambiguous annotations.\nTABLE V\nGEOTAGGING PRECISION (%) FOR FIVE RANGES AND MEDIAN\nGEOTAGGING ERROR (KM) OF THE PROPOSED APPROACH ON LOW - AND\nHIGH -AMBIGUITY OF ITEMS .\nP@10m P@100m P@1km P@10km P@100km m. error\nLow-AS 1.36 15.22 48.55 78.88 85.63 1.09\nHigh-AS 0.71 7.69 28.88 52.57 64.48 7.17\nFinally, we benchmarked the geotagging performance of\nthe proposed approach using either the locality or Ripley’s K\nstatistic for feature selection and weighting. The dataset used\nfor training and testing is the MediaEval PT 2016 edition. The\nlocality was calculated at the city level, while for computing\nRipley’s K a sample of 10,000 items per term was used. For\nfeature selection, the terms with either locality or Ripley’s K\nstatistic greater than zero were selected. For feature weighting,\nthe same process described at Section III-D was applied in\nboth cases.\nTable VI displays the results of the LM using either locality\nor Ripley’s K statistic. Performance is very similar for both\nmeasures, with Ripley’s K statistic performing slightly better.\nYet, the proposed locality measure comes with a huge com-\nputational beneﬁt: computing Ripley’s K statistic required 465\nmin, whereas locality took just 7 min, i.e. it was approximately\n66× faster and was calculated without any sampling. The\nsets of terms selected by the two measures (terms with value\ngreater than zero) amount to 278,240 for locality and 304,419\nfor Ripley’s K. The Jaccard similarity of the two sets is\n≈89% meaning that both measures lead to highly similar sets\n(274,359 of the 278,240 terms selected based on locality had\nbeen also selected based on Ripley’s K statistic).\nA more nuanced performance analysis of the approach is\npresented in [24], which reveals how the performance changes\ndepending on particular traits of the test dataset (e.g. when\nthe dataset consists of images from a speciﬁc location, depict\nspeciﬁc objects, etc.).\nTABLE VI\nGEOTAGGING PRECISION (%) FOR THREE RANGES AND MEDIAN\nGEOTAGGING ERROR (KM) OF THE LM USING FOR FEATURE SELECTION\nAND WEIGHTING EITHER LOCALITY OR RIPLEY ’S K STATISTC .\nP@1km P@10km P@100km m. error\nLM+FS+FW (locality) 23.94 43.44 51.48 60\nLM+FS+FW (Ripley’s K)24.02 43.72 52.02 56\nC. Comparison against geoparsing methods\nIn this section, the performance of the proposed approach is\ncompared with two state-of-the-art geoparsing approaches on\nthe MediaEval 2016 PT dataset. The results for the proposed\napproach were obtained using the LM with all the reﬁnements\nand using the entire YFCC100M for training (after excluding\nall items from users also appearing in the test set). The selected\ngeoparsing approaches are the following:\n• Zhang et al. [55]: This is a preference learning approach\nthat, given an input text, detects the GeoNames entities\n(if any) that are mentioned; the approach makes use\ngazetteer-based features and a corpus of geotagged tweets\nin order to build an accurate geoparsing model.\n• DBpedia geoparsing [28]: This is a simple geoparsing\nscheme that provides the input text as a geo-query to\nDBpedia, i.e. a query that is limited only to objects\nassociated with geographical information, and uses the\nreturned DBpedia entities as location candidates.\n• CLA VIN10: This is a widely used open-source geoparsing\nlibrary; however, it produced location estimates for only\na tiny fraction of the test items and therefore led to very\npoor results. For that reason, its results are not included\nin our comparison.\nThe same testing protocol was used as in the case of our\nproposed approach: The tags and titles of the test items\nwere fed as input to the geoparsing methods. In cases where\nno estimation was returned, the item descriptions were then\nprovided. The only text pre-processing step on the input data\nis URL-decoding. Since geoparsing methods produce a set of\ngeographical entities (each of which associated with a pair of\nlat/lon coordinates) and not necessarily a single location, it\nwas necessary to devise a location selection step to determine\na single location per input item. To this end, two variations\nwere considered:\n• optimal: The distance between all candidate locations\nand the ground truth location is computed, and then\nthe location with the smallest distance is selected. This\ncorresponds to an upper bound of performance (i.e. case\nwhere the candidate selection step would be perfect).\n• random: According to this, a random location is se-\nlected for every item among the candidate locations. This\nprocess is repeated 10 times and the mean performance\nis reported. This correspond to an average estimate of\nperformance for such methods.\nTable VII presents the results of the comparison. The\nproposed approach outperforms both geoparsing methods at\na very large margin, even in their optimal variation. In\nall ranges, especially low ones (i.e. 100m, 1km), precision\n10https://github.com/Berico-Technologies/CLA VIN\n12\nTABLE VII\nGEOTAGGING PRECISION (%) FOR FOUR RANGES AND MEDIAN\nGEOTAGGING ERROR (KM) OF THE PROPOSED APPROACH AND THE\nVARIANTS OF THE COMPETING GEOPARSING METHODS .\nP@100m P@1km P@10km P@100km m. error\nZhang (optimal) [55] 1.77 13.71 37.04 48.68 131\nZhang (random) [55] 0.68 5.78 17.65 27.87 1148\nDBpedia (optimal) [10] 1.78 10.94 29.49 37.88 891\nDBpedia (random) [10] 1.31 8.74 25.22 34.05 1151\nproposed approach 7.52 27.40 47.86 56.06 15\nscores are signiﬁcantly better. Similar results are also obtained\nwhen comparing the respective median errors: the proposed\napproach achieves >8×lower error than the second best.\nD. MediaEval Placing Task\nIn this section, the proposed system is benchmarked against\nthe participating teams in the MediaEval PT of years 2016 [6],\n2015 [5], 2014 [8] and 2013 [15]. Every year, participants\nwere asked by the organizers to submit their approaches using\nthe released dataset. However, the volume and origin of the\nreleased datasets vary from year to year. Table III presents\nthose details for every edition of the task.\nThe proposed system is tested with every one of the four\ndatasets using the corresponding evaluation setup, and its re-\nsults are compared with the reported results of the approaches\nthat participated in the respective edition. For years 2014, 2015\nand 2016, the test set of each year is a superset of the one\nused in the previous editions, i.e. 2015 test set is a superset\nof the 2014 set, and 2016 test set a superset both 2015 and\n2014 sets. Consequently, their results are presented in a single\nconcatenated table to facilitate comparison, and provide a\ncomprehensive view into the performance of all methods. The\ndetailed method results were provided by the MediaEval PT\norganizers. In all cases, the instance of the proposed approach\nwas built based on the tuning process of section IV-A. In\naddition to presenting the results when training the approach\nwith the training sets provided by the organizers each year,\nwe also report the performance of the method (under the entry\nproposed approach (YFCC) ) when it is trained with a much\nlarger set, i.e. the full YFCC100M (after removing items of\nwhich the owners appear in the test set).\n1) MediaEval 2013: The proposed approach was evaluated\nbased on the data of MediaEval 2013 Placing Task, i.e. a\ntraining set of ≈8.5M items and a test set of 262k items.\nThe results of the participating approaches are illustrated\nin Table VIII along with those of the proposed approach. In\nthis case, run1 was not strictly restricted to the use of text-\nonly information; to make comparison fair, the table includes\nonly the results from teams that submitted a text-only run. The\nproposed approach ranks ﬁrmly between the ﬁrst and second\nplace in the different precision ranges: it achieves 25.21% at\nP@1km and the second best median error (47km). Overall,\nthe proposed scheme is highly competitive and outperforms\nmost of the participating systems.\n2) MediaEval 2014, 2015, 2016: The comparative results\nof the proposed approach for each of the three editions of\nPT (2014-2016) are presented in Table IX. Three versions of\nthe proposed approach are presented given that each year a\nTABLE VIII\nGEOTAGGING PRECISION (%) FOR FIVE RANGES AND MEDIAN\nGEOTAGGING ERROR (KM) OF THE TEXT RUNS R U N1 FOR PARTICIPANTS\nIN THE MEDIA EVAL PT 2013 AND FOR THE PROPOSED APPROACH .\nP@100m P@1km P@10km P@100km m. error\nCERTH[25] 2.96 10.26 23.52 36.25 651\nUoS[11] 5.43 23.15 37.70 43.83 451\nSCUT[2] 4.90 20.74 42.95 55.26 38\nCEA LIST[40] 7.41 26.00 42.77 50.03 99\nVIT[47] 0.06 0.74 3.92 15.24 6183\nRECOD[29] 6.07 20.13 37.60 47.64 168\nproposed approach 6.23 25.21 44.02 53.25 47\np. approach (YFCC) 7.74 26.71 44.94 54.78 32\ndifferent training set was released. Note that earlier versions\nof the proposed approach had contested under the names\nSocialSensor [22] and CERTH/CEA LIST [26] [27].\nThe proposed approach ranks in the ﬁrst or second place in\nall years and performance measures; in particular, it achieves\nsigniﬁcantly better results in precision ranges P@1km and\nP@10km (P@1km = 25.45% and P@10km = 45.76% on\nthe 2014 test set), as well as the best median error (25km\non the 2014 test set). In addition to achieving top results\nagainst all state-of-the-art approaches, it is noteworthy that the\nperformance of the proposed approach is very stable across the\nvarious datasets, exhibiting only minimal variance with respect\nto the different training and test sets.\nAlso, as expected, the performance of the approach is\nfurther improved when it is trained on the much larger set.\nFor instance, in the case of MediaEval PT 2013, we achieved\nan absolute increase between 1.5% and 1.9% in terms of P@R\nand a reduction of 15km in median error. Similar gains are also\nachieved for the 2014-2016 editions of the task, with a notable\nabsolute increase of ≈2.5% in P@1km and P@10km for all\ntest sets. This observation points to an interesting trade-off and\nquestion of whether a measurable but moderate increase in the\ngeotagging performance justiﬁes the investment in a very large\nincrease (almost 10-fold) in the training set.\nE. Discussion: Geotagging on other datasets\nThrough our experimental study, we presented compelling\nevidence that the proposed approach achieved excellent geo-\ntagging accuracy, outperforming all text-based approaches that\nhave competed in MediaEval Placing Task, as well as a\ncouple of popular geoparsing approaches. However, we need\nto recognize that all tests have been carried out on Flickr\ncollections. Hence, it should not come as a surprise that\napplying the proposed approach on arbitrary (non-Flickr) text\ndata, such as tweets and news articles, may lead to suboptimal\nor even unsatisfactory performance. The main reason for such\nan expectation stems from the fact that the underlying LM was\nbuilt using a dataset of Flickr image and video annotations.\nEven though the used training sets were very large scale, one\nneeds to bear in mind that they exhibit speciﬁc characteristics\nthat are tightly associated with the “typical” content that is\npublished on Flickr (ranging from photos of touristic sites,\nevents, social activities, artistic creations, etc.).\nIt is worth mentioning that we have carried out experiments\non Twitter data with encouraging results, even though the\nunderlying LMs were the same as the ones that we used for\n13\nTABLE IX\nGEOTAGGING PRECISION (%) FOR THREE RANGES AND MEDIAN GEOTAGGING ERROR (KM) OF TEXT RUNS (R U N1) FOR PARTICIPANTS OF EACH YEAR OF\nMEDIA EVAL PT COMPARED TO THE PROPOSED APPROACH . THE APPROACHES ARE IMPLEMENTED BASED ON THE THREE TRAINING SETS AND\nEVALUATED BASED ON THE THREE TEST SETS .\nTraining\n2014\nSocialSensor[22]\nUSEMP[41]\nUQ-DKE[4]\nTALP-UPC[13]\nRECOD[31]\nICSI/TU Delft[7]\nproposed approach\nTraining\n2015\nBaseline[53]\nCERTH/CEA LIST[26]\nImCube[19]\nGeo_ML[12]\nRECOD[30]\nproposed approach\nTraining\n2016\nBaseline[53]\nCERTH/CEA LIST[27]\nRECOD[31]\nUoA[45]\nproposed approach\nYFCCproposed approach\nTest 2014\nP@100m P@1km P@10km m. error\n5.87 23.01 39.92 230\n1.61 23.50 40.80 168\n4.98 19.56 41.71 51\n4.12 16.53 34.33 84\n6.06 21.03 37.59 233\n3.15 16.65 34.70 307\n6.30 25.20 45.64 26\n4.26 18.74 40.43 61\n6.43 24.71 43.57 60\n1.84 8.68 21.34 280\n1.26 9.73 30.80 271\n5.61 20.01 37.03 292\n6.39 25.45 45.68 27\n3.90 18.31 39.72 70\n6.51 25.01 43.80 55\n6.29 21.58 38.73 227\n2.91 14.97 35.41 87\n6.23 25.26 45.76 25\n7.60 27.91 48.44 14\nTest 2015\nP@100m P@1km P@10km m. error\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n4.23 18.44 39.96 71\n6.40 24.33 43.07 69\n1.84 8.56 21.07 293\n1.25 9.51 30.03 291\n5.49 19.75 36.60 310\n6.39 25.13 45.26 30\n3.85 17.99 39.28 81\n6.57 24.84 43.36 70\n6.54 22.06 38.89 234\n2.91 14.70 35.58 99\n6.33 25.16 45.33 29\n7.66 27.79 47.87 16\nTest 2016\nP@100m P@1km P@10km m. error\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n- - - -\n3.82 17.73 39.06 80\n6.43 24.55 43.32 65\n6.06 21.01 37.91 259\n2.88 14.12 35.24 94\n6.22 24.85 45.39 28\n7.52 27.40 47.86 16\nthis work. However, as expected, there were also numerous\ncases, where the approach failed. We have found that this was\nmainly due to a large mismatch between the Flickr-based LM\nand the language used on Twitter, as well as to the highly\nirregular and dynamic linguistic patterns arising on Twitter.\nDue to space limitations, we cannot provide further details\non these tests in this paper, and we leave as future work, a\ncomprehensive performance evaluation of geotagging across\ndatasets from different sources, as well as on new methods to\nimprove cross-dataset performance.\nV. C ONCLUSIONS\nWe presented a text-based geotagging approach that\nimproves upon previous Language Model-based systems\nthanks to a number of novel feature selection and weighting\nschemes. The proposed approach was shown to consistently\noutperform or be highly competitive to the state-of-the-art\nthrough comprehensive experiments on four editions of\nthe Mediaeval Placing Task, a popular open benchmark\nfor the multimedia community, while several performance\naspects of the proposed approach were examined through\ncarefully designed experiments. By releasing the source code\nof the proposed approach along with the best performing\nLanguage Models that we generated, we aspire to provide a\nvery strong and robust state-of-the-art method to be used for\ncomparisons, and to stimulate further research on the problem.\nAcknowledgements. This work is supported by the REVEAL\nand InVID projects, partially funded by the European Com-\nmission under contract numbers 610928 and 687786.\nREFERENCES\n[1] E. Amitay, N. Har’El, R. Sivan, and A. Soffer, “Web-a-where: geotag-\nging web content,” in Proceedings of the 27th annual international ACM\nSIGIR conference on Research and development in information retrieval.\nACM, 2004, pp. 273–280.\n[2] J. Cao, “Photo Set Reﬁnement and Tag Segmentation in Georeferencing\nFlickr Photos.” in MediaEval, 2013.\n[3] J. Cao, Z. Huang, and Y . Yang, “Spatial-aware multimodal location esti-\nmation for social images,” in Proceedings of the 23rd ACM international\nconference on Multimedia . ACM, 2015, pp. 119–128.\n[4] J. Cao, Z. Huang, Y . Yang, and H. T. Shen, “UQ-DKE’s Participation\nat MediaEval 2014 Placing Task.” in MediaEval, 2014.\n[5] J. Choi, C. Hauff, O. Van Laere, and B. Thomee, “The placing task\nat mediaeval 2015,” in MediaEval 2015, Wurzen, Germany, 14-15\nSeptember 2015. CEUR, 2015.\n[6] ——, “The placing task at mediaeval 2016,” in MediaEval 2016,\nHilversum, The Netherlands, October 20-21, 2016 . CEUR, 2016.\n[7] J. Choi and X. Li, “The 2014 ICSI/TU Delft Location Estimation\nSystem.” in MediaEval, 2014.\n[8] J. Choi, B. Thomee, G. Friedland, L. Cao, K. Ni, D. Borth, B. Elizalde,\nL. Gottlieb, C. Carrano, R. Pearce et al. , “The placing task: A large-\nscale geo-estimation challenge for social-media videos and images,” in\nProceedings of the 3rd ACM Multimedia Workshop on Geotagging and\nIts Applications in Multimedia . ACM, 2014, pp. 27–31.\n[9] D. J. Crandall, L. Backstrom, D. Huttenlocher, and J. Kleinberg,\n“Mapping the world’s photos,” in Proceedings of the 18th international\nconference on World wide web . ACM, 2009, pp. 761–770.\n[10] J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes, “Improving efﬁ-\nciency and accuracy in multilingual entity extraction,” in I-SEMANTICS\n2013 - 9th International Conference on Semantic Systems, ISEM ’13,\nGraz, Austria, September 4-6, 2013 , 2013, pp. 121–124.\n[11] J. Davies, J. Hare, S. Samangooei, J. Preston, N. Jain, D. Dupplaw, and\nP. H. Lewis, “Identifying the geographic location of an image with a\nmultimodal probability density function,” in MediaEval, 2013.\n[12] N. Duong-Trung, M. Wistuba, L. R. Drumond, and L. Schmidt-Thieme,\n“Geo ML @ MediaEval Placing Task 2015,” in MediaEval, 2015.\n[13] D. Ferr ´es and H. Rodr ´ıguez, “TALP-UPC at MediaEval 2014 Placing\nTask: Combining Geographical Knowledge Bases and Language Models\nfor Large-Scale Textual Georeferencing.” in MediaEval, 2014.\n[14] C. Hauff and G.-J. Houben, “Geo-location estimation of ﬂickr images:\nsocial web based enrichment,” in European Conference on Information\nRetrieval. Springer, 2012, pp. 85–96.\n[15] C. Hauff, B. Thomee, and M. Trevisiol, “Working Notes for the Placing\nTask at MediaEval 2013.” in MediaEval, 2013.\n[16] J. Hays and A. A. Efros, “IM2GPS: estimating geographic information\nfrom a single image,” in IEEE Conference on Computer Vision and\nPattern Recognition, CVPR 2008 . IEEE, 2008, pp. 1–8.\n[17] ——, “Large-scale image geolocalization,” in Multimodal Location\nEstimation of Videos and Images . Springer, 2015, pp. 41–62.\n[18] C. F. Karney, “Algorithms for geodesics,” Journal of Geodesy , vol. 87,\nno. 1, pp. 43–55, 2013.\n[19] P. Kelm, S. Schmiedeke, and L. Goldmann, “Imcube@ MediaEval 2015\nPlacing Task: A Hierarchical Approach for Geo-referencing Large-Scale\nDatasets,” in MediaEval, 2015.\n[20] P. Kelm, S. Schmiedeke, and T. Sikora, “A hierarchical, multi-modal\napproach for placing videos on the map using millions of ﬂickr pho-\n14\ntographs,” in Proceedings of the 2011 ACM workshop on Social and\nbehavioural networked media access . ACM, 2011, pp. 15–20.\n[21] C. Keßler, K. Janowicz, and M. Bishr, “An agenda for the next gener-\nation gazetteer: Geographic information contribution and retrieval,” in\nProceedings of the 17th ACM SIGSPATIAL int. conference on advances\nin Geographic Information Systems . ACM, 2009, pp. 91–100.\n[22] G. Kordopatis-Zilos, G. Orfanidis, S. Papadopoulos, and Y . Kompat-\nsiaris, “SocialSensor at MediaEval Placing Task 2014.” in MediaEval,\n2014.\n[23] G. Kordopatis-Zilos, S. Papadopoulos, and Y . Kompatsiaris, “Geotag-\nging social media content with a reﬁned language modelling approach,”\nin Paciﬁc-Asia Workshop on Intelligence and Security Informatics .\nSpringer, 2015, pp. 21–40.\n[24] ——, “In-depth exploration of geotagging performance using sampling\nstrategies on yfcc100m,” in Proceedings of the 2016 ACM Workshop on\nMultimedia COMMONS. ACM, 2016, pp. 3–10.\n[25] G. Kordopatis-Zilos, S. Papadopoulos, E. S. Xiouﬁs, A. L. Symeonidis,\nand Y . Kompatsiaris, “CERTH at MediaEval Placing Task 2013.” in\nMediaEval, 2013.\n[26] G. Kordopatis-Zilos, A. Popescu, S. Papadopoulos, and Y . Kompatsiaris,\n“CERTH/CEA LIST at MediaEval Placing Task 2015,” in MediaEval,\n2015.\n[27] ——, “Placing Images with Reﬁned Language Models and Similarity\nSearch with PCA-reduced VGG Features,” in MediaEval, 2016.\n[28] J. Lehmann, R. Isele, M. Jakob, A. Jentzsch, D. Kontokostas, P. N.\nMendes, S. Hellmann, M. Morsey, P. van Kleef, S. Auer, and C. Bizer,\n“DBpedia - A large-scale, multilingual knowledge base extracted from\nWikipedia,” Semantic Web, vol. 6, no. 2, pp. 167–195, 2015. [Online].\nAvailable: http://dx.doi.org/10.3233/SW-140134\n[29] L. T. Li, J. Almeida, O. A. B. Penatti, R. T. Calumby, D. C. G.\nPedronette, M. A. Gonc ¸alves, and R. da Silva Torres, “Multimodal Image\nGeocoding: The 2013 RECOD’s Approach.” in MediaEval, 2013.\n[30] L. T. Li, J. A. Mu ˜noz, J. Almeida, R. T. Calumby, O. A. Penatti, ´I. C.\nDourado, K. Nogueira, P. R. M. J ´unior, L. A. Pereira, D. C. Pedronette\net al. , “RECOD @ Placing Task of MediaEval 2015,” in MediaEval,\n2015.\n[31] L. T. Li, O. A. B. Penatti, J. Almeida, G. Chiachia, R. T. Calumby, P. R.\nMendes-Junior, D. C. G. Pedronette, and R. da Silva Torres, “Multimedia\nGeocoding: The RECOD 2014 Approach.” in MediaEval, 2014.\n[32] X. Li, M. A. Larson, and A. Hanjalic, “Geo-distinctive visual el-\nement matching for location estimation of images,” arXiv preprint\narXiv:1601.07884, 2016.\n[33] X. Li, M. Riegler, M. Larson, and A. Hanjalic, “Exploration of Feature\nCombination in Geo-visual Ranking for Visual Content-based Location\nPrediction,” in MediaEval, 2013.\n[34] M. D. Lieberman, H. Samet, and J. Sankaranayananan, “Geotagging:\nusing proximity, sibling, and prominence clues to understand comma\ngroups,” in proceedings of the 6th workshop on geographic information\nretrieval. ACM, 2010, p. 6.\n[35] T.-Y . Lin, S. Belongie, and J. Hays, “Cross-view image geolocalization,”\nin Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, 2013, pp. 891–898.\n[36] J. Luo, D. Joshi, J. Yu, and A. Gallagher, “Geotagging in multimedia and\ncomputer visiona survey,” Multimedia Tools and Applications , vol. 51,\nno. 1, pp. 187–211, 2011.\n[37] S. E. Middleton and V . Krivcovs, “Geoparsing and geosemantics for\nsocial media: spatio-temporal grounding of content propagating rumours\nto support trust and veracity analysis during breaking news,” ACM\nTransactions on Information Systems , vol. 34, no. 3, pp. 1–27, 2016.\n[38] J. A. Mu ˜noz, L. T. Li, ´I. C. Dourado, K. Nogueira, S. G. Fadel, O. A.\nPenatti, J. Almeida, L. A. Pereira, R. T. Calumby, J. A. dos Santos et al.,\n“Recod@ placing task of mediaeval 2016: A ranking fusion approach\nfor geographic location prediction of multimedia objects,” in MediaEval,\n2016.\n[39] N. O’Hare and V . Murdock, “Modeling locations with social media,”\nInformation Retrieval, vol. 16, no. 1, pp. 30–62, 2013.\n[40] A. Popescu, “CEA LIST’s Participation at MediaEval 2013 Placing\nTask.” in MediaEval, 2013.\n[41] A. Popescu, S. Papadopoulos, and I. Kompatsiaris, “USEMP at Medi-\naEval Placing Task 2014.” in MediaEval, 2014.\n[42] B. D. Ripley, Spatial statistics. John Wiley & Sons, 1981.\n[43] P. Serdyukov, V . Murdock, and R. Van Zwol, “Placing ﬂickr photos on a\nmap,” in Proceedings of the 32nd international ACM SIGIR conference\non Research and development in information retrieval . ACM, 2009,\npp. 484–491.\n[44] B. W. Silverman, Density estimation for statistics and data analysis .\nCRC press, 1986, vol. 26.\n[45] S. K. Singh and D. Raﬁei, “Geotagging ﬂickr photos and videos using\nlanguage models,” in MediaEval, 2016.\n[46] P. D. Smart, C. B. Jones, and F. A. Twaroch, “Multi-source toponym data\nintegration and mediation for a meta-gazetteer service,” in International\nConference on Geographic Information Science . Springer, 2010, pp.\n234–248.\n[47] S. Subramanian, V . Vidyasagaran, and K. Chandramouli, “VIT@ Medi-\naEval 2013 Placing Task: Location Speciﬁc Tag Weighting for Language\nModel Based Placing of Images.” in MediaEval, 2013.\n[48] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland,\nD. Borth, and L.-J. Li, “YFCC100M: The new data in multimedia\nresearch,” Communications of the ACM, vol. 59, no. 2, pp. 64–73, 2016.\n[49] M. Trevisiol, H. J ´egou, J. Delhumeau, and G. Gravier, “Retrieving geo-\nlocation of videos with a divide & conquer hierarchical multimodal\napproach,” in Proceedings of the 3rd ACM conference on International\nconference on multimedia retrieval . ACM, 2013, pp. 1–8.\n[50] O. Van Laere, J. Quinn, S. Schockaert, and B. Dhoedt, “Spatially aware\nterm selection for geotagging,” IEEE transactions on Knowledge and\nData Engineering, vol. 26, no. 1, pp. 221–234, 2014.\n[51] O. Van Laere, S. Schockaert, and B. Dhoedt, “Finding locations of ﬂickr\nresources using language models and similarity search,” in Proceedings\nof the 1st ACM International Conference on Multimedia Retrieval .\nACM, 2011, p. 48.\n[52] ——, “Georeferencing ﬂickr photos using language models at different\nlevels of granularity: An evidence based approach,” Web Semantics:\nScience, Services and Agents on the World Wide Web, vol. 16, pp. 17–31,\n2012.\n[53] ——, “Georeferencing Flickr resources based on textual meta-data,”\nInformation Sciences, vol. 238, pp. 52–74, 2013.\n[54] T. Weyand, I. Kostrikov, and J. Philbin, “Planet-photo geolocation with\nconvolutional neural networks,” arXiv preprint arXiv:1602.05314, 2016.\n[55] W. Zhang and J. Gelernter, “Geocoding location expressions in twitter\nmessages: A preference learning method,” Journal of Spatial Informa-\ntion Science, vol. 2014, no. 9, pp. 37–70, 2014.\n[56] Y .-T. Zheng, Z.-J. Zha, and T.-S. Chua, “Research and applications on\ngeoreferenced multimedia: a survey,” Multimedia Tools and Applica-\ntions, vol. 51, no. 1, pp. 77–98, 2011.\nGiorgos Kordopatis-Zilos received the Diploma\ndegree in Electrical and Computer Engineering in\nthe Aristotle University of Thessaloniki (AUTH),\nGreece in 2013. Since September 2014, he has\nbeen working as a research assistant at the Informa-\ntion Technologies Institute (ITI) of the Centre for\nResearch and Technology Hellas (CERTH). He is\ncurrently pursuing his Ph.D degree in distance at\nQueen Mary University of London, on the topic of\nnear-duplicate video retrieval. His research interests\ninclude multimedia analysis, indexing and retrieval,\nweb scale data mining, geographic information retrieval and deep learning.\nHe is a Graduate Student Member of IEEE.\nSymeon Papadopoulos received the Diploma de-\ngree in Electrical and Computer Engineering in\nthe Aristotle University of Thessaloniki (AUTH),\nGreece in 2004. In 2006, he received the Profes-\nsional Doctorate in Engineering (P.D.Eng.) from the\nTechnical University of Eindhoven, the Netherlands.\nSince September 2006, he has been working as a\nresearch associate with the Information Technologies\nInstitute (ITI), part of the Centre for Research and\nTechnology Hellas (CERTH), on a wide range of\nresearch areas such as information search and re-\ntrieval, social network analysis, data mining and web multimedia knowledge\ndiscovery. In 2009, he completed a distance-learning MBA degree in the\nBlekinge Institute of Technology, Sweden. In 2012, he defended his Ph.D.\nthesis in the Informatics department of AUTH on the topic of large-scale\nknowledge discovery from social multimedia. He is currently Chair of the\nIEEE Special Technical Community on Social Networking (STCSN).\n15\nIoannis (Yiannis) Kompatsiaris is a Senior Re-\nsearcher (Researcher A) with the Information Tech-\nnologies Institute / Centre for Research and Technol-\nogy Hellas, Thessaloniki, Greece. His research inter-\nests include semantic multimedia analysis, indexing\nand retrieval, social media and big data analysis,\nknowledge structures, reasoning and personalization\nfor multimedia applications, eHealth, security and\nenvironmental applications. He received his Ph.D.\ndegree in 3-D model based image sequence coding\nfrom the Aristotle University of Thessaloniki in\n2001. He is the co-author of 90 papers in refereed journals, 38 book chapters,\n8 patents and more than 320 papers in international conferences. He has been\nthe coorganizer of various international conferences and workshops and has\nserved as a regular reviewer for a number of journals and conferences. He is\na Senior Member of IEEE and member of ACM.\nView publication statsView publication stats"
}