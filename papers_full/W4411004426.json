{
  "title": "The Role of Artificial Intelligence Large Language Models in Personalized Rehabilitation Programs for Knee Osteoarthritis: An Observational Study",
  "url": "https://openalex.org/W4411004426",
  "year": 2025,
  "authors": [
    {
      "id": null,
      "name": "Gürses, Ömer Alperen",
      "affiliations": [
        "Ahi Evran University"
      ]
    },
    {
      "id": null,
      "name": "Özüdoğru, Anıl",
      "affiliations": [
        "Ahi Evran University"
      ]
    },
    {
      "id": "https://openalex.org/A2500338040",
      "name": "Tuncay Figen",
      "affiliations": [
        "Ahi Evran University"
      ]
    },
    {
      "id": null,
      "name": "Kararti, Caner",
      "affiliations": [
        "Ahi Evran University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4386210642",
    "https://openalex.org/W4381107034",
    "https://openalex.org/W4323835279",
    "https://openalex.org/W4205865577",
    "https://openalex.org/W4402945044",
    "https://openalex.org/W4400882865",
    "https://openalex.org/W4390948973",
    "https://openalex.org/W4386592038",
    "https://openalex.org/W4394573140",
    "https://openalex.org/W4391213634",
    "https://openalex.org/W4386409641",
    "https://openalex.org/W4400493458",
    "https://openalex.org/W4313403013",
    "https://openalex.org/W4403214125",
    "https://openalex.org/W4389571209",
    "https://openalex.org/W2981485716",
    "https://openalex.org/W4404811596",
    "https://openalex.org/W4404364882",
    "https://openalex.org/W4399523741",
    "https://openalex.org/W4386725993",
    "https://openalex.org/W4280488363",
    "https://openalex.org/W2253579545",
    "https://openalex.org/W4245703231",
    "https://openalex.org/W1716794597",
    "https://openalex.org/W2053410759",
    "https://openalex.org/W2114362978",
    "https://openalex.org/W2161736885",
    "https://openalex.org/W4396856938",
    "https://openalex.org/W4389941618",
    "https://openalex.org/W4401735946",
    "https://openalex.org/W4401793992",
    "https://openalex.org/W4400163553",
    "https://openalex.org/W4401351706",
    "https://openalex.org/W4404045357",
    "https://openalex.org/W4402654426",
    "https://openalex.org/W4401367002",
    "https://openalex.org/W4402949381",
    "https://openalex.org/W4403021815",
    "https://openalex.org/W4389235809",
    "https://openalex.org/W4389519817"
  ],
  "abstract": "Abstract Background Large language models (LLMs) can contribute to treatment options and outcomes by assisting physiotherapists for conditions like osteoarthritis. Aims The objective of this early-stage cross-sectional study is to assess the alignment of large language models with physiotherapists in designing physiotherapy and rehabilitation programs for knee osteoarthritis. Methods Forty patients diagnosed with knee osteoarthritis were assessed using standardized clinical criteria. For each patient, individualized rehabilitation programs were created by three physiotherapists and by ChatGPT-4o and Gemini Advanced using structured prompts. The presence or absence of 50 clinically relevant rehabilitation parameters was recorded for each program. Chi-square tests were used to evaluate agreement rates between the LLMs and the physiotherapist-generated Consensus programs. Results ChatGPT-4o achieved a 74% agreement rate with the physiotherapists’ Consensus programs, while Gemini Advanced achieved 70%. Although both models showed high compatibility with general rehabilitation components, they demonstrated notable limitations in exercise specificity, including frequency, sets, and progression criteria. ChatGPT-4o performed as well as or better than Gemini in most phases, particularly in Phase 3, while Gemini showed lower consistency in balance and stabilization parameters. Conclusions ChatGPT-4o and Gemini Advanced demonstrate promising potential in generating personalized rehabilitation programs for knee osteoarthritis. While their outputs generally align with expert recommendations, notable gaps remain in clinical reasoning and the provision of detailed exercise parameters. These findings underscore the importance of ongoing model refinement and the necessity of expert supervision for safe and effective clinical integration.",
  "full_text": "RESEARCH\nJournal of Medical Systems           (2025) 49:73 \nhttps://doi.org/10.1007/s10916-025-02207-x\nIntroduction\nLarge language models (LLMs), a branch of artificial intel-\nligence (AI), are advanced systems that leverage deep \nlearning algorithms to process natural language and gener -\nate responses with human-like quality and consistency [ 1]. \nNotable LLMs such as ChatGPT and Gemini represent lead-\ning models in this field [2]. ChatGPT, developed by OpenAI, \nis based on the GPT architecture (versions 3.5 or 4.0) and \nfunctions both as a chatbot and a generative model, trained \non multilingual datasets [3]. Gemini, in contrast, offers real-\ntime data integration and is designed to interact with search \nengines, potentially reshaping information-seeking behav -\nior [2].\n \r Ömer Alperen Gürses\nomeralperengurses@gmail.com\nAnıl Özüdoğru\naozudogru@hotmail.com\nFigen Tuncay\nfigentuncay3206@hotmail.com\nCaner Kararti\nfzt.caner.92@gmail.com\n1 School of Physical Therapy and Rehabilitation, Department \nof Physiotherapy and Rehabilitation, Kırşehir Ahi Evran \nUniversity, Merkez, Kırşehir 40100, Türkiye\n2 Faculty of Medicine, Department of Physical Medicine and \nRehabilitation, Kırşehir Ahi Evran University,  \nMerkez, Kırşehir 40100, Türkiye\nAbstract\nBackground Large language models (LLMs) can contribute to treatment options and outcomes by assisting physiotherapists \nfor conditions like osteoarthritis.\nAims The objective of this early-stage cross-sectional study is to assess the alignment of large language models with phys -\niotherapists in designing physiotherapy and rehabilitation programs for knee osteoarthritis.\nMethods Forty patients diagnosed with knee osteoarthritis were assessed using standardized clinical criteria. For each patient, \nindividualized rehabilitation programs were created by three physiotherapists and by ChatGPT-4o and Gemini Advanced \nusing structured prompts. The presence or absence of 50 clinically relevant rehabilitation parameters was recorded for each \nprogram. Chi-square tests were used to evaluate agreement rates between the LLMs and the physiotherapist-generated Con-\nsensus programs.\nResults ChatGPT-4o achieved a 74% agreement rate with the physiotherapists’ Consensus programs, while Gemini \nAdvanced achieved 70%. Although both models showed high compatibility with general rehabilitation components, they \ndemonstrated notable limitations in exercise specificity, including frequency, sets, and progression criteria. ChatGPT-4o \nperformed as well as or better than Gemini in most phases, particularly in Phase 3, while Gemini showed lower consistency \nin balance and stabilization parameters.\nConclusions ChatGPT-4o and Gemini Advanced demonstrate promising potential in generating personalized rehabilitation \nprograms for knee osteoarthritis. While their outputs generally align with expert recommendations, notable gaps remain in \nclinical reasoning and the provision of detailed exercise parameters. These findings underscore the importance of ongoing \nmodel refinement and the necessity of expert supervision for safe and effective clinical integration.\nKeywords Artificial intelligence · Large language models · Physiotherapy · Rehabilitation program · Knee osteoarthritis\nReceived: 23 January 2025 / Accepted: 26 May 2025\n© The Author(s) 2025\nThe Role of Artificial Intelligence Large Language Models in \nPersonalized Rehabilitation Programs for Knee Osteoarthritis: An \nObservational Study\nÖmer Alperen Gürses1  · Anıl Özüdoğru1  · Figen Tuncay2  · Caner Kararti1\n1 3\n\nJournal of Medical Systems           (2025) 49:73 \nThe advent of LLMs has precipitated a surge in research \nendeavors exploring their potential applications in health -\ncare, clinical practice, and medical research [ 4, 5]. While \nconventional AI has exhibited limited involvement in \nclinical decision-making, LLMs, trained on extensive and \ndiverse human-generated datasets, have catalyzed grow -\ning interest in their role in supporting clinical workflows, \nencompassing triage, diagnosis, and treatment planning [6]. \nRecent studies have explored the application of LLMs in \nosteoarthritis management, where models like ChatGPT \nhave demonstrated moderate success in generating reha -\nbilitation programs and aligning with clinical guidelines \n[7, 8]. Similar research in stroke rehabilitation has shown \nthat LLMs are capable of mimicking clinical reasoning and \ncreating structured treatment plans based on established \nprinciples [ 9]. Furthermore, investigations into conditions \nsuch as vestibular disorders, scoliosis, and musculoskeletal \ndiagnostics suggest that these models may aid clinicians in \npatient communication, education, and treatment planning, \nparticularly when supported by appropriate professional \noversight [ 10–15]. By presenting medical information in \na clear and patient-specific manner, LLMs can support cli -\nnicians in effectively communicating physiotherapy plans \nand explaining underlying conditions. This personalised \napproach may enhance patient understanding, improve \nadherence to treatment recommendations, and contribute to \nbetter health outcomes [16].\nOsteoarthritis (OA) is one of the most common muscu -\nloskeletal diseases worldwide and has a significant effect on \nquality of life [17]. OA is a major focus of rehabilitation and \nmultidisciplinary treatment approaches. By supporting both \npatients and physiotherapists, LLMs can contribute to better \nunderstanding, improved treatment strategies, and optimized \noutcomes for conditions like OA, addressing the needs of a \nbroad patient population [18]. In particular, their potential to \ndelineate fundamental rehabilitation strategies and lucidly \nexpound treatment alternatives could assist physiotherapists \nin diminishing the time expended on repetitive documen -\ntation and preliminary programme design. Moreover, they \ncould serve as a cautionary mechanism for interventions \nthat are frequently overlooked during the planning process. \nAlthough studies on LLMs are present, research remains \nlimited in two key areas: first, there are few studies of recent \nversions that outperform previous versions [ 7, 18, 19], and \nsecond, there are few studies that focus specifically on reha-\nbilitation [9, 16, 20, 21]. This study represents an early-stage \nevaluation of large language model-based decision support \ntools by examining their alignment with physiotherapists in \nthe development of personalized rehabilitation programs for \nknee osteoarthritis, thereby addressing a current gap in the \nliterature.\nMaterials and Methods\nStudy Design\nThis cross-sectional study compared the physiotherapy \nprograms developed by three experienced physiotherapists \nwith at least five years of clinical experience in knee OA and \nthose generated by ChatGPT-4o and Gemini Advanced, two \nlarge language models, for knee OA. The study was con -\nducted between August and October 2024 at the physiother-\napy outpatient clinic. The study followed the Strengthening \nthe Reporting of Observational Studies in Epidemiology \n(STROBE) and Reporting guideline for the early stage \nclinical evaluation of decision support systems driven by \nAI (DECIDE-AI) [ 22] to ensure high-quality reporting \nstandards.\nParticipants\nThe study included 40 patients diagnosed with knee OA \nbased on the American College of Rheumatology criteria \nby a physiatrist. The patients were aged between 40 and 65 \nyears and diagnosed with grade 2 or 3 knee OA based on the \nKellgren-Lawrence classification [ 23]. Exclusion criteria \nwere previous knee surgery or joint injections within the last \n6 months, history of any physiotherapy program, cognitive \nimpairment, systemic diseases, neurological or orthopedic \nconditions affecting the lower extremities [24].\nMeasurements\nData on age, sex, body mass index (BMI), and educational \nstatus were recorded for all patients. Pain was evaluated \nusing the numeric pain rating scale. The range of motion \nof the hip and knee joints in all directions was measured \nwith a universal goniometer (Baseline-12-1000 Plastic \n360 Degree ISOM), and the strength of the quadriceps and \nhamstring muscles was assessed using an isometric dyna -\nmometer (Lafayette Hand-Held Dynamometer). Func -\ntional status was assessed using the WOMAC and Lysholm \nscores. Physical performance was measured with the Timed \nUp and Go test, 40-meter fast walk test, 30-second sit-to-\nstand test, and stair climb test [25, 26]. Balance assessments \nincluded the single-leg stance test for static balance and the \nFour Square Step Test for dynamic balance. The selection of \nthese performance tests aligns with recommendations from \nthe Osteoarthritis Research Society International (OARSI), \nwhich endorses their use as standard reliable measures for \nevaluating functional outcomes in hip and knee OA [26].\n1 3\n   73  Page 2 of 10\nJournal of Medical Systems           (2025) 49:73 \nProcedure\nTwo distinct approaches were used to create patient-based \nassessment and rehabilitation programs for all participants: \none based on physiotherapist consensus and the other gener-\nated by LLMs.\nConsensus physiotherapy programs: The data for each \npatient was independently evaluated by three physiothera -\npists, who subsequently developed preliminary programs. \nThrough structured discussion, the physiotherapists were \nable to reach a Consensus on the most appropriate treatment \nprogram for each patient, resulting in a single standardized \nprogram for each patient.\nAI-generated physiotherapy programs: The data obtained \nfrom patients after the evaluation were entered into Chat -\nGPT-4o and Gemini Advanced using prompts written in \nTurkish. The prompts were originally in Turkish to simulate \nreal-world usage scenarios in Turkey, where the primary \naudience includes Turkish-speaking physiotherapists and \npatients. The English translation of the prompts is provided \nin the main text, while the original Turkish prompts and the \nprompts related to patient data, in both Turkish and Eng -\nlish versions, are included in Supplementary Material 1 to \nensure transparency.\nThe following English translation of the prompt was \nused:\n*\"Prepare a detailed three-phase physiotherapy pro -\ngram for a knee OA patient based on the provided evalua -\ntion parameters. The program should include the following \ncomponents:\nElectrophysical agents: Specify appropriate modalities \nfor each phase.\nThermal applications: Indicate whether hot or cold treat-\nments are preferred based on the patient’ s needs.\nExercise applications: Provide a detailed exercise \nprogram for each phase , including repetitions , sets , and \npositions.\nPhase transition criteria: Define specific criteria for pro-\ngressing between phases in terms of pain , edema, balance, \nrange of motion (ROM), muscle strength, and functionality.\nDischarge criteria: Highlight the goals the patient should \nachieve by the end of the rehabilitation.“*.\nThis structured prompt format was intentionally designed \nto guide the language models to generate outputs aligned \nwith real-world physiotherapy program components. There-\nfore, the models were not producing responses entirely \nindependently, but within a standardized and directive \nframework that ensured the inclusion of clinically relevant \nrehabilitation elements. ChatGPT-4o was prompted imme -\ndiately after each patient’s evaluation. A new conversa -\ntion was initiated for each case to ensure independence of \nresponses. According to OpenAI, this is sufficient to prevent \nprior context from influencing the model’s output, even \nwithin the same session [1].\nTo ensure variety and avoid repetition, new conversations \nwere initiated for each patient when querying ChatGPT-4 \nand Gemini Advanced. Each of the 40 patient profiles was \nindividually presented to the language models, which were \nprompted to generate personalized rehabilitation programs \ntailored to the specific clinical characteristics of each case. \nFor every rehabilitation parameter and phase, the presence \nor absence of a recommendation was recorded for each \npatient. These binary data were then aggregated to calculate \nthe percentage of cases in which a given intervention was \nrecommended, allowing for item-level comparison across \nmodels and with the Consensus group. Although reported as \noverall frequencies, the data structure was built on case-spe-\ncific inputs and individualized AI responses. This approach \nensured that each AI-generated rehabilitation plan was \nbased on individualized clinical data, reflecting a tailored \ntreatment structure for every patient.\nParameter selection: Initially, 58 parameters were iden -\ntified across the rehabilitation programs developed by the \nphysiotherapists and AI models. The final list of 50 param -\neters was determined based on their clinical relevance and \nfrequency of application in knee OA rehabilitation, as sup -\nported by established guidelines and prior literature [27, 28]. \nParameters that were deemed less relevant appeared only \nin one or two patient-specific outputs, or lacked support \nin evidence-based physiotherapy practices were excluded. \nThis decision ensured that the analysis focused on the most \nmeaningful and representative components of the rehabilita-\ntion programs, allowing for comparison grounded in widely \naccepted clinical standards. A detailed list of excluded \nparameters is provided in Supplementary Material 2.\nSample Size\nThe sample size was calculated using G*Power Software \n(version 3.1.9.7) to ensure sufficient statistical power for \ndetecting differences in parameter-level agreement between \nAI-generated and Consensus programs. Based on a previ -\nous study in a similar field and using a chi-square test for \ngoodness of fit, the required sample size was calculated as \n40 patients to achieve 80% power with a 5% significance \nlevel [16].\nAgreement Evaluation\nFor each rehabilitation parameter (e.g., type of exercise, \nmodality, dosage), agreement between the AI-generated \nplans and the Consensus recommendations was assessed \nbased on frequency of usage across 40 standardized \npatient profiles. Specifically, we calculated how often each \n1 3\nPage 3 of 10    73 \nJournal of Medical Systems           (2025) 49:73 \nfrequency, showed significant differences, with Consensus \nrecommending them far more frequently than ChatGPT4o \n(p < 0.001) and Gemini Advanced ( p < 0.05). Criteria for \ntransitioning from Phase 1 to Phase 2 10% increase in quad-\nriceps and hamstring muscle strength were recommended \nsignificantly less frequently by both ChatGPT4o and Gem -\nini Advanced compared to Consensus, with both differences \nbeing statistically significant ( p < 0.001). The findings for \nPhase 1 are summarized in Table 1.\nPhase 2: TENS and interferential current, including their \nduration and frequency, were recommended significantly \nmore frequently by Consensus compared to both ChatG -\nPT4o and Gemini Advanced, with the differences being sta-\ntistically significant (p < 0.001). Balance and proprioception \nexercises, along with their set and frequency, were similarly \nrecommended more frequently by both ChatGPT4o and \nConsensus, while Gemini Advanced’s recommendations \nwere notably lower, with statistically significant differences \nobserved (p < 0.001). Hip stabilization exercises, including \ntheir set and frequency, were recommended far more fre -\nquently by Consensus compared to both ChatGPT4o and \nGemini Advanced, with all differences reaching statistical \nsignificance (p < 0.001). Findings for these parameters are \nsummarized in Table 2.\nPhase 3: NMES (Neuromuscular electrical stimulation) \nand RUS current, including their duration and frequency, \nwere recommended significantly more frequently by Chat -\nGPT4o compared to both Consensus and Gemini Advanced, \nwith all differences being statistically significant (p < 0.001). \nDynamic balance exercises, along with their set and fre -\nquency, were recommended at similar levels by ChatGPT4o \nand Consensus, whereas Gemini Advanced’s recommenda-\ntions were considerably lower, with statistically significant \ndifferences observed ( p < 0.001). The findings for Phase 3 \nare summarized in Table 3.\nWhen evaluating the overall performance across the 50 \ndifferent parameters in the three phases, ChatGPT4o dem -\nonstrated discrepancies with Consensus in 13 out of 50 \nparameters, achieving an agreement rate of 74%. In com -\nparison, Gemini Advanced exhibited discrepancies in 15 \nparameters, corresponding to an agreement rate of 70%. The \naverage percentage of recommendations for each parame -\nter has been calculated as follows: In Phase 1, 82.5% for \nConsensus, 75% for ChatGPT4o, and 76.11% for Gemini \nAdvanced; in Phase 2, 90.66% for Consensus, 72.24% for \nChatGPT4o, and 62.5% for Gemini Advanced; and in Phase \n3, 82.15% for Consensus, 84.42% for ChatGPT4o, and \n68.08% for Gemini Advanced. The findings are illustrated \nin Fig. 1.\nintervention item was recommended by the Consensus \ngroup and by the AI model, expressed as a percentage of \nthe total patient cases. Agreement was defined as a match \nin these usage frequencies, regardless of whether the rec -\nommendations were made for the same individual patients. \nThus, the analysis reflects content-level agreement rather \nthan case-specific alignment. This approach was selected \nto enable systematic comparison across a large dataset and \nto evaluate the general consistency of AI-generated outputs \nwith expert-derived protocols.\nStatistical Analysis\nThe rehabilitation programs for each patient were ana -\nlyzed across the 50 selected parameters. Each parameter \nwas recorded in SPSS Statistics 25 as either “present” or \n“absent” for the Consensus program, ChatGPT-4o, and \nGemini Advanced. Chi-square (χ²) tests were applied to \nevaluate the compatibility between AI-generated programs \nand the physiotherapists’ Consensus programs. Results were \nanalyzed at a significance level of p < 0.05 and presented \nas absolute frequencies and percentages. This parameter-\nlevel analysis allowed for the identification of agreement \nand disagreement rates, providing a detailed evaluation of \nthe alignment between the AI models and physiotherapist-\ndeveloped programs.\nResults\nOf the 52 patients referred to the study, 9 did not meet the \ninclusion criteria and 3 declined to participate. Therefore, \n40 patients who met the criteria and provided informed \nconsent were enrolled. (age: 53.3 ± 7.17 years, height: \n166 ± 9.05 cm, weight: 67.22 ± 11.7 kg, body mass index: \n24.55 ± 4.99, Kellgren-Lawrence: 24 grade 2 and 16 grade \n3)\nPhase 1: Cold pack and TENS (Transcutaneous electri -\ncal nerve stimulation) were recommended across all groups \nwith high levels of agreement (Consensus: 92.5%, ChatG -\nPT4o: 97.5%, Gemini Advanced: 95%). No significant dif -\nferences were identified for these modalities. Ultrasound \nand its duration/frequency demonstrated notable discrepan-\ncies, being recommended significantly less by Consensus \ncompared to both ChatGPT4o and Gemini Advanced, with \nboth differences being statistically significant ( p < 0.001). \nNotable differences were observed in the recommenda -\ntions for hip mobilization exercises and their set/frequency, \nwith Consensus suggesting them far more often compared \nto both ChatGPT4o and Gemini Advanced, and both differ-\nences being statistically significant ( p < 0.001). Hip abduc-\ntion exercises and hamstring curls, along with their set/\n1 3\n   73  Page 4 of 10\nJournal of Medical Systems           (2025) 49:73 \nTable 1 Phase 1 comparison of consensus and ChatGPT4o-Gemini advanced\nVariable (available %) Consensus Chat-\nGPT \n4o\nGemini \nAdvanced\np1 p2 p3\nColdpack 92.5 97.5 95 0.307 0.646 0.558\nColdpack duration/frequency 92.5 90 87.5 0.694 0.366 0.496\nTENS/Interferans current 92.5 97.5 95 0.307 0.646 0.558\nTENS/Interferans current duration/frequency 92.5 95 85 0.679 0.355 0.542\nUltrasound 5 52.5 82.5 < 0.001 < 0.001 0.004\nUltrasound duration/frequency 5 47.5 77.5 < 0.001 < 0.001 0.005\nKnee ROM exercises 97.5 92.5 95 0.307 0.558 0.646\nKnee ROM exercises set/frequency 97.5 92.5 90 0.307 0.598 0.694\nQuadriceps isometric exercise 95 97.5 90 0.558 0.529 0.168\nQuadriceps isometric exercise set/frequency 95 90 92.5 0.398 0.646 0.694\nHip mobilization exercises 85 27.5 20 < 0.001 < 0.001 0.288\nHip mobilization exercises set/frequency 85 25 17.5 < 0.001 < 0.001 0.471\nHip abduction exercises and hamstring curl 87.5 55 65 < 0.001 0.021 0.364\nHip abduction exercises and hamstring curl set/frequency 87.5 50 62.5 < 0.001 0.010 0.262\nCriteria for transition from Phase 1 to Phase 2 (No significant knee swelling) 95 92.5 90 0.679 0.398 0.694\nCriteria for transition from Phase 1 to Phase 2 (Pain NRS ≤ 3) 95 97.5 92.5 0.558 0.646 0.307\nCriteria for transition from Phase 1 to Phase 2 Knee ROM flexion ≥ 90 extension \n≤ -5 degree.\n92.5 90 97.5 0.694 0.307 0.168\nCriteria for transition from Phase 1 to Phase 2 Improvement in quadriceps and \nhamstring muscle strength.\n92.5 60 35 < 0.001 < 0.001 0.026\nAbbreviations: p1: Consensus-ChatGPT comparison; p2: Consensus-Gemini comparison; p3: ChatGPT-Gemini comparison; TENS: Transcu -\ntaneous electrical nerve stimulation; ROM: Range of motion; NRS: Numeric rating scale\nTable 2 Phase 2 comparison of consensus and ChatGPT4o-Gemini advanced\nVariable (available %) Consensus ChatGPT 4o Gemini Advanced p1 p2 p3\nHotpack 92.5 87.5 85 0.366 0.355 0.747\nHotpack duration/frequency 92.5 82.5 85 0.179 0.355 0.763\nTENS/Interferans current 92.5 20 17.5 < 0.001 < 0.001 0.775\nTENS/Interferans current duration/frequency 92.5 15 10 < 0.001 < 0.001 0.501\nNMES/RUS current 87.5 77.5 90 0.242 0.725 0.132\nNMES/RUS current duration/frequency 87.5 72.5 82.5 0.095 0.533 0.287\nCKC exercises Quadriceps strengthening 97.5 95 92.5 0.558 0.307 0.646\nCKC exercises Quadriceps strengthening set/frequency 97.5 92.5 87.5 0.646 0.366 0.458\nBalance and proprioception exercises 90 92.5 27.5 0.694 < 0.001 < 0.001\nBalance and proprioception exercises set/frequency 90 85 22.5 0.501 < 0.001 < 0.001\nLower extremity strengthening exercises 97.5 95 92.5 0.558 0.307 0.646\nLower extremity strengthening exercises set/frequency 97.5 87.5 92.5 0.091 0.773 0.458\nHip stabilization exercises 92.5 30 22.5 < 0.001 < 0.001 0.448\nHip stabilization exercises set/frequency 92.5 30 20 < 0.001 < 0.001 0.543\nHip abduction exercises and hamstring curl 70 67.5 47.5 0.844 0.092 0.137\nHip abduction exercises and hamstring curl set/frequency 70 62.5 42.5 0.562 0.041 0.144\nCriteria for transition from Phase 2 to Phase 3\n(No significant knee swelling)\n95 92.5 80 0.646 0.071 0.158\nCriteria for transition from Phase 2 to Phase 3\n(Pain at a manageable level)\n95 97.5 92.5 0.558 0.287 0.307\nCriteria for transition from Phase 2 to Phase 3\nQuadriceps and hamstring strength should support progression\n92.5 90 97.5 0.694 0.773 0.168\nAbbreviations: p1: Consensus-ChatGPT comparison; p2: Consensus-Gemini comparison; p3: ChatGPT-Gemini comparison; CKC: Closed \nKinetic Chain; TENS: Transcutaneous electrical nerve stimulation; NMES: Neuromuscular electrical stimulation; ROM: Range of motion; \nNRS: Numeric rating scale\n1 3\nPage 5 of 10    73 \nJournal of Medical Systems           (2025) 49:73 \nOA patients. Both models demonstrated strengths in gen -\nerating general recommendations; however, they exhib -\nited inconsistencies in terms of coverage and adherence to \nthe Consensus. ChatGPT-4o showed greater consistency, \nwhile Gemini Advanced showed more variability in certain \nDiscussion\nThis study is the first to examine the potential of the large \nlanguage models ChatGPT-4o and Gemini Advanced to \ncreate physiotherapy and rehabilitation programs for knee \nTable 3 Phase 3 comparison of consensus and ChatGPT4o-Gemini advanced\nVariable (available %) Consensus Chat-\nGPT \n4o\nGemini \nAdvanced\np1 p2 p3\nNMES/RUS current 17.5 65 15 < 0.001 0.808 < 0.001\nNMES/RUS current duration/frequency 17.5 62.5 12.5 < 0.001 0.619 < 0.001\nQuadriceps strengthening exercises 97.5 95 92.5 0.558 0.646 0.646\nQuadriceps strengthening exercises set/frequency 97.5 92.5 87.5 0.646 0.122 0.366\nLower extremity strengthening exercises 90 80 85 0.286 0.572 0.639\nLower extremity strengthening set/frequency 90 77.5 80 0.132 0.286 0.823\nDynamic balance exercises 90 92.5 27.5 0.694 < 0.001 < 0.001\nDynamic balance exercises set/frequency 90 85 22.5 0.572 < 0.001 < 0.001\nDLA exercises 90 87.5 97.5 0.725 0.168 0.091\nDLA exercises set/frequency 90 87.5 85 0.725 0.572 0.747\nDischarge criteria (pain-free functional activities) 95 92.5 97.5 0.739 0.739 0.739\nDischarge criteria (muscle strength age and gender appropriate level) 95 97.5 90 0.558 0.398 0.168\nDischarge criteria (significant improvement in balance and coordination \nability)\n95 82.5 92.5 0.078 0.646 0.179\nAbbreviations: p1: Consensus-ChatGPT comparison; p2: Consensus-Gemini comparison; p3: ChatGPT-Gemini comparison; NMES: Neuro -\nmuscular electrical stimulation; DLA: Daily Life Activity\nFig. 1 Mean values of parameter recommendation percentages\n \n1 3\n   73  Page 6 of 10\nJournal of Medical Systems           (2025) 49:73 \nA noteworthy finding in our study was the frequent rec -\nommendation of ultrasound in Phase 1 by the language \nmodels, although it was rarely included in the Consensus \nrecommendations. This inconsistency may be attributed to \nlimitations in the currentness of ChatGPT’s and Gemini’s \ntraining data, as well as the models’ weaknesses in review -\ning and integrating up-to-date literature [ 30]. Addition -\nally, ChatGPT demonstrated strength in providing general \nrecommendations, on the other hand it showed deficient \nconsistency in certain exercise parameters (e.g., sets and \nrepetitions). Similarly, while Gemini showed higher com -\npatibility in certain clinical modalities, it struggled with \ndefining adequate transition criteria and outcome measures. \nThese findings underline the potential of language models \nas complementary tools in clinical practice and highlight the \nneed for their optimization through the integration of more \ncurrent and evidence-based datasets.\nCompatibility with Clinical Consensus\nSeveral studies have investigated the alignment of large \nlanguage models (LLMs) with evidence-based clinical \nguidelines for osteoarthritis, revealing noteworthy findings \nregarding their level of concordance.\nOne study compared ChatGPT and Bard (Gemini) for \nconcordance with the American Academy of Orthopaedic \nSurgeons (AAOS) Clinical Practice Guidelines for hip and \nknee OA in terms of alignment with clinical questions. It \nindicated that ChatGPT achieved an 80% concordance rate \nwith AAOS guidelines. Moreover, ChatGPT outperformed \nBard, which achieved a 60% concordance rate [8].\nBeyond OA, LLMs have shown varying levels of guide-\nline adherence across other clinical areas. In this context, \none study evaluated the ability of LLMs to provide treat -\nment recommendations for rotator cuff tears and anterior \ncruciate ligament injuries in accordance with AAOS clinical \npractice guidelines, finding that ChatGPT-4 achieved a con-\ncordance rate of 79.2%, outperforming other models [ 31]. \nSimilarly, studies in other specialties—such as gastrointes -\ntinal oncology and pediatric orthopedics—have reported \nvarying degrees of guideline alignment for both ChatGPT \nand Gemini, generally ranging between 67% and 77% [ 32, \n33].\nIn this context, the results of our study demonstrated \nthat ChatGPT-4.0 and Gemini Advanced exhibited both \nstrengths and weaknesses in aligning with clinical practice \nconsensus, consistent with findings in the current literature. \nChatGPT-4.0 showed deficiencies in phase 3 NMES/RUS \nparameters, especially in terms of duration and frequency, \nwhereas Gemini Advanced showed lower accuracy partic -\nularly in phase 2 balance and proprioception exercises, in \nphase 3 dynamic balance exercises, and in set and frequency \nrecommendations. These findings highlight the need for fur-\nther refinement of such models to improve their reliability \nin clinical practice.\nTreatment Recommendation\nStudies on LLMs point out their potential in general knowl-\nedge distribution, while revealing limitations in certain \nclinical applications. In a study examining the potential of \nLLMs in knee OA treatment management, language models \nshowed limited effectiveness in tasks requiring comprehen-\nsive medical knowledge. Their performance declined when \nmoving from general to personalized tasks. In addition, \nit was determined that their performance can be notably \nimproved through the inclusion of accurate information and \nexplicit instructions [7].\nOne study showed that ChatGPT-4.0 demonstrates \nenhanced performance in responding to general OA-related \nqueries, exhibiting higher accuracy and compatibility in \nproviding rehabilitation information compared to other \nlanguage models [ 18]. Similarly, in our study, although \nChatGPT-4.0 and Gemini Advanced provided significantly \nfewer recommendations for hip mobilization and stabiliza -\ntion exercises compared to the Consensus, ChatGPT-4.0 \ndemonstrated elevated accuracy and concordance rates in \ndesigning rehabilitation programs. This difference may be \ndue to ChatGPT4o’s and Gemini Advanced’s tendency to \nfocus primarily on the affected area when designing reha -\nbilitation programs and thus their clinical reasoning may not \nhave adequately recognized the importance of hip exercises \nin meeting broader rehabilitation needs.\nFor instance, ChatGPT has been shown to effectively \ndesign rehabilitation programs based on established frame -\nworks such as FITT-VP (Frequency, Intensity, Time, Type, \nV olume, and Progression) [ 15]. In more complex sce -\nnarios such as scoliosis classification and treatment plan -\nning, ChatGPT-4 achieved high accuracy, whereas Gemini \nexhibited output inconsistencies that posed potential patient \nsafety concerns. Other studies involving various musculo -\nskeletal conditions—such as shoulder, spine, or vestibular \ndisorders—have reported that while LLMs can provide \ngeneral information, they often lack specificity and clinical \nreasoning in generating detailed exercise recommendations \n[11–14, 29].\nIn our study, the language models provided significantly \nfewer recommendations than the consensus, particularly for \nhip mobilisation, stabilisation, and abduction exercises and \nrelated parameters such as sets and frequency. These find -\nings are consistent with the literature showing the limitations \nof LLMs in generating specific exercise recommendations, \ndespite their optimistic level of accuracy in designing reha-\nbilitation programmes.\n1 3\nPage 7 of 10    73 \nJournal of Medical Systems           (2025) 49:73 \nmay be due to the decline in performance of language mod-\nels when used in languages other than English [41–43].\nLimitations and Future Work\nThe present study has several limitations. The best perfor -\nmance of language models is observed in English; however, \nin our study, the models were utilized in Turkish. While \nthe treatment programs generated by AI language models \nraise ethical concerns, their application in clinical prac -\ntice could provide clearer insights. Furthermore, our study \nfocused solely on patients with knee osteoarthritis, limiting \nthe generalizability of the findings. Additionally, the cross-\nsectional design of this study does not account for the rapid \nand continuous evolution of LLMs, particularly in premium \nversions that are regularly updated. Another limitation is \nthat the stability of LLM-generated responses was not sys -\ntematically assessed; the same input could potentially pro -\nduce varying outputs at different times. Future research on \nthe performance of language models in designing rehabilita-\ntion programs for other diseases and larger sample groups, \nin collaboration with physiotherapists, will allow for more \ncomprehensive evaluations in this area. At the same time, \nthe development of a language model specific to physio -\ntherapy and rehabilitation may also be an extraordinary plan \nfor the future.\nConclusion\nIn conclusion, the present study contributes to the growing \nevidence for the potential use of ChatGPT-4o and Gemini \nAdvanced in clinical settings, with a specific focus on the \ndesign of individualized rehabilitation programs for knee \nosteoarthritis. These models may support physiotherapists, \nphysicians, and clinicians in developing personalized treat -\nment plans. However, it is evident that there are still limi -\ntations in terms of guideline adherence and data accuracy. \nFurther refinements are required, including improvements \nin language-specific performance and integration of up-to-\ndate evidence, in order to strengthen the role of these models \nin the development of rehabilitation programs and broader \nclinical practice.\nSupplementary Information  The online version contains \nsupplementary material available at  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 1  0 9 1 6 - 0 \n2 5 - 0 2 2 0 7 - x.\nAcknowledgments We would like to thank all participants for their \nvolunteered participation.\nAuthor Contributions Omer Alperen Gurses: Writing– review & edit-\ning, Writing– original draft, Methodology, Data curation, Conceptu -\nalization. Anıl Ozudogru: Writing– review & editing, Methodology, \nparameters. Our findings revealed that ChatGPT-4.0 \nachieved a 74% concordance rate with Consensus guide -\nlines, with 13 discrepancies out of 50 parameters, while \nGemini Advanced achieved a 70% concordance rate with 15 \ndiscrepancies. These results confirm ChatGPT’s relatively \nhigher adherence to established Consensus. However, the \nclose difference between the two models may be attributed \nto similar advances in the development of their premium \nversions. Taken together, both the literature and our findings \nindicate that ChatGPT-4o and Gemini Advanced demon -\nstrate varying degrees of compatibility with clinical consen-\nsus, depending on the context. While both models perform \nadequately in general clinical applications, they exhibit \nnotable limitations in specific parameters and individual -\nized treatment planning. These findings highlight the need \nto enhance guideline adherence and improve the quality and \ncurrency of language model training datasets by integrat -\ning robust, evidence-based frameworks—particularly to \nstrengthen their utility and reliability in physiotherapy and \nrehabilitation practice.\nClinician Support\nCurrent literature suggests that LLMs like ChatGPT and \nGemini hold strong potential in supporting clinical practice. \nA 2024 study showed that ChatGPT clearly presents treat -\nment protocols and effectively explains surgical risks [ 34], \nwhile another found that both ChatGPT-4 and Gemini 1.5 \nPro successfully simplified ultrasound findings with high \naccuracy and readability [ 35]. Other condition-specific \nstudies reported varying effectiveness, with ChatGPT-4 per-\nforming well for low back pain and scoliosis, whereas Gem-\nini, though faster, showed lower accuracy in some cases [36, \n37]. Our findings support existing evidence that ChatGPT-\n4o and Gemini Advanced, each showing over 70% accuracy, \ncan assist clinicians in developing patient-centered rehabili-\ntation programs for knee osteoarthritis. These models may \nhelp with assessment, treatment planning, and patient com-\nmunication; however, their variable precision underscores \nthe need for clinician oversight to ensure safe and effective \nuse in practice.\nThe literature demonstrates that the most up-to-date ver-\nsions of LLMs tend to exhibit superior performance as com-\npared with lower versions [ 19, 38–40]. In alignment with \nthis, we hypothesize that the high concordance observed in \nour study with established Consensus may be attributed to \nthe utilization of the most up-to-date and advanced version \nof the model. However, discrepancies observed in certain \ncases may be due to limitations of the models in accessing \nand integrating up-to-date literature [ 30]. Similar to the lit -\nerature, the most important limitation identified in our study \n1 3\n   73  Page 8 of 10\nJournal of Medical Systems           (2025) 49:73 \nDomain-specific Medicine: Osteoarthritis Management with \nDocOA. arXiv preprint arXiv:240112998. 2024.\n8. Yang J, Ardavanis KS, Slack KE, Fernando ND, Della Valle \nCJ, Hernandez NM. Chat Generative Pretrained Transformer \n(ChatGPT) and Bard: artificial intelligence does not yet provide \nclinically supported answers for hip and knee osteoarthritis. The \nJournal of Arthroplasty. 2024;39(5):1184–90.\n9. Zhang L, Tashiro S, Mukaino M, Yamada S. Use of artificial \nintelligence large language models as a clinical tool in rehabilita-\ntion medicine: a comparative test case. Journal of Rehabilitation \nMedicine. 2023;55.\n10. Alhur A. Redefining healthcare with artificial intelligence (AI): \nthe contributions of ChatGPT, Gemini, and Co-pilot. Cureus. \n2024;16(4). doi:  h t t p  s : /  / d o i  . o  r g /  1 0 . 7  7 5 9  / c u  r e u s . 5 7 7 9 5.\n11. Arbel Y , Gimmon Y , Shmueli L. Evaluating the Potential of \nLarge Language Models for Vestibular Rehabilitation Educa -\ntion: A Comparison of ChatGPT, Google Gemini, and Clinicians. \nmedRxiv. 2024:2024.01. 24.24301737. doi:  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  1 \n0 1  / 2 0  2 4 . 0 1 . 2 4 . 2 4 3 0 1 7 3 7.\n12. Daher M, Koa J, Boufadel P, Singh J, Fares MY , Abboud JA. \nBreaking barriers: can ChatGPT compete with a shoulder and \nelbow specialist in diagnosis and management? JSES interna -\ntional. 2023;7(6):2534–41.\n13. Fabijan A, Zawadzka-Fabijan A, Fabijan R, Zakrzewski K, \nNowosławska E, Polis B. Assessing the Accuracy of Artifi -\ncial Intelligence Models in Scoliosis Classification and Sug -\ngested Therapeutic Approaches. Journal of Clinical Medicine. \n2024;13(14):4013.\n14. Kim J-h. Search for medical information and treatment options \nfor musculoskeletal disorders through an artificial intelligence \nchatbot: focusing on shoulder impingement syndrome. MedRxiv. \n2022:2022.12. 16.22283512.\n15. You M, Chen X, Liu D, Lin Y , Chen G, Li J. ChatGPT-4 and Wear-\nable Device Assisted Intelligent Exercise Therapy for Co-existing \nSarcopenia and Osteoarthritis (GAISO): A feasibility study and \ndesign for a randomized controlled PROBE non-inferiority trial. \nJournal of Orthopaedic Surgery and Research. 2024;19(1):635.\n16. Bilika P, Stefanouli V , Strimpakos N, Kapreli EV . Clinical reason-\ning using ChatGPT: Is it beyond credibility for physiotherapists \nuse? Physiotherapy Theory and Practice. 2023:1–20.\n17. Vitaloni M, Botto-van Bemden A, Sciortino Contreras RM, \nScotton D, Bibas M, Quintero M, et al. Global management of \npatients with knee osteoarthritis begins with quality of life assess-\nment: a systematic review. BMC musculoskeletal disorders. \n2019;20:1–12.\n18. Cao M, Wang Q, Zhang X, Lang Z, Qiu J, Yung PS-H, et al. \nLarge language models’ performances regarding common patient \nquestions about osteoarthritis: A comparative analysis of Chat -\nGPT-3.5, ChatGPT-4.0, and perplexity. Journal of Sport and \nHealth Science. 2024:101016.\n19. Uehara O, Morikawa T, Harada F, Sugiyama N, Matsuki Y , \nHiraki D, et al. Performance of ChatGPT-3.5 and ChatGPT‐\n4o in the Japanese National Dental Examination. J Dent Educ. \n2025;89(4):459–66.\n20. Maggio MG, Tartarisco G, Cardile D, Bonanno M, Bruschetta \nR, Pignolo L, et al. Exploring ChatGPT’s potential in the clinical \nstream of neurorehabilitation. Frontiers in Artificial Intelligence. \n2024;7:1407905.\n21. Rossettini G, Cook C, Palese A, Pillastrini P, Turolla A. Pros and \ncons of using artificial intelligence chatbots for musculoskeletal \nrehabilitation management. journal of orthopaedic & sports phys-\nical therapy. 2023;53(12):728–34.\n22. Vasey B, Nagendran M, Campbell B, Clifton DA, Collins GS, \nDenaxas S, et al. Reporting guideline for the early stage clinical \nevaluation of decision support systems driven by artificial intel -\nligence: DECIDE-AI. bmj. 2022;377.\nSupervision, Conceptualization. Figen Tuncay: Data curation. Caner \nKararti: Methodology, Supervision, Formal analysis\nFunding Open access funding provided by the Scientific and Techno-\nlogical Research Council of Türkiye (TÜBİTAK).\nThis research did not receive any specific grant from funding agencies \nin the public, commercial, or not-for-profit sectors.\nData Availability No datasets were generated or analysed during the \ncurrent study.\nDeclarations\nEthical Approval  The study was conducted in accordance with the \nDeclaration of Helsinki and was approved by the Ethics Committee \nof Kirsehir Ahi Evran University Faculty of Medicine Health Sciences \nScientific Research(2024-13/110). Informed consent was obtained \nfrom all participants involved in the study.\nCompeting Interests The authors declare no competing interests.\nClinical Trial Number Not applicable.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o \nr g  / l i c e n s e s / b y / 4 . 0 /.\nReferences\n1. OpenAI: Introducing ChatGPT.  h t t p  s : /  / o p e  n a  i . c  o m / b  l o g  / c h  a t g p t / \n(2023). Accessed.\n2. Nazir T, Ahmad U, Mal M, Rehman MU, Saeed R, Kalia JS. \nMicrosoft Bing vs. Google Bard in Neurology: A Comparative \nStudy of AI-Generated Patient Education Material. medRxiv. \n2023:2023.08. 25.23294641.\n3. Ismail AMA. Chat GPT in tailoring individualized lifestyle-mod-\nification programs in metabolic syndrome: potentials and difficul-\nties? Ann Biomed Eng. 2023;51(12):2634–5.\n4. Goodman RS, Patrinely JR, Osterman T, Wheless L, Johnson DB. \nOn the cusp: Considering the impact of artificial intelligence lan-\nguage models in healthcare. Med. 2023;4(3):139–40.\n5. Sezgin E, Sirrianni J, Linwood SL. Operationalizing and imple -\nmenting pretrained, large artificial intelligence linguistic models \nin the US health care system: outlook of generative pretrained \ntransformer 3 (GPT-3) as a service model. JMIR medical infor -\nmatics. 2022;10(2):e32875.\n6. Gaber F, Shaik M, Franke V , Akalin A. Evaluating large language \nmodel workflows in clinical decision support: referral, triage, and \ndiagnosis. medRxiv. 2024:2024.09. 27.24314505.\n7. Chen X, You M, Wang L, Liu W, Fu Y , Xu J, et al. Evaluat -\ning and Enhancing Large Language Models Performance in \n1 3\nPage 9 of 10    73 \nJournal of Medical Systems           (2025) 49:73 \nUltra and ChatGPT-4.0 Tamir Bresler, MD, Tyler Wilson, MD, \nTadevos Makaryan, MD.\n33. Pirkle S, Yang J, Blumberg TJ. Do ChatGPT and Gemini Provide \nAppropriate Recommendations for Pediatric Orthopaedic Condi-\ntions? Journal of Pediatric Orthopaedics. 2024:10.1097.\n34. Duran A, Cortuk O, Ok B. Future Perspective of Risk Prediction \nin Aesthetic Surgery: Is Artificial Intelligence Reliable? Aesthetic \nSurgery Journal. 2024;44(11):NP839-NP49.\n35. Güneş YC, Cesur T, Çamur E. Comparative Analysis of Large \nLanguage Models in Simplifying Turkish Ultrasound Reports to \nEnhance Patient Understanding. European Journal of Therapeu -\ntics. 2024;30(5):714–23.\n36. Lang S, Vitale J, Galbusera F, Fekete T, Boissiere L, Charles YP, \net al. Is the information provided by large language models valid \nin educating patients about adolescent idiopathic scoliosis? An \nevaluation of content, clarity, and empathy: the perspective of the \nEuropean Spine Study Group. Spine Deform. 2025;13(2):361–72.\n37. Scaff SP, Reis FJ, Ferreira GE, Jacob MF, Saragiotto BT. Assess-\ning the performance of AI chatbots in answering patients’ com -\nmon questions about low back pain. Annals of the Rheumatic \nDiseases. 2024.\n38. Hirosawa T, Harada Y , Tokumasu K, Ito T, Suzuki T, Shimizu T. \nComparative study to evaluate the accuracy of differential diag -\nnosis lists generated by gemini advanced, gemini, and bard for a \ncase report series analysis: cross-sectional study. JMIR Medical \nInformatics. 2024;12:e63010.\n39. Is EE, Menekseoglu AK. Comparative performance of artificial \nintelligence models in rheumatology board-level questions: eval-\nuating Google Gemini and ChatGPT-4o. Clinical Rheumatology. \n2024;43(11):3507–13.\n40. O’Leary DE. Do ChatGPT 4o, 4, and 3.5 Generate “Similar” \nRatings? Findings and Implications. IEEE Intelligent Systems. \n2024;39(5):78–81.\n41. Fang C, Wu Y , Fu W, Ling J, Wang Y , Liu X, et al. How does \nChatGPT-4 preform on non-English national medical licensing \nexamination? An evaluation in Chinese language. PLOS Digital \nHealth. 2023;2(12):e0000397.\n42. Howe NP. ChatGPT has a language problem-but science can fix \nit. Nature. 2024.\n43. Lai VD, Ngo NT, Veyseh APB, Man H, Dernoncourt F, Bui T, et \nal. Chatgpt beyond english: towards a comprehensive evaluation \nof large language models in multilingual learning. arXiv preprint \narXiv: 2023;230405613.\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\n23. Kohn MD, Sassoon AA, Fernando ND. Classifications in brief: \nKellgren-Lawrence classification of osteoarthritis. Clinical \nOrthopaedics and Related Research®. 2016;474:1886–93.\n24. Mc H. Guidelines for the medical management of osteoar -\nthritis. Part II. Osteoarthritis of the knee. Arthritis Rheum. \n1995;38:1541–6.\n25. Collins NJ, Misra D, Felson DT, Crossley KM, Roos EM. Mea -\nsures of knee function: International Knee Documentation Com -\nmittee (IKDC) Subjective Knee Evaluation Form, Knee Injury \nand Osteoarthritis Outcome Score (KOOS), Knee Injury and \nOsteoarthritis Outcome Score Physical Function Short Form \n(KOOS-PS), Knee Outcome Survey Activities of Daily Liv -\ning Scale (KOS‐ADL), Lysholm Knee Scoring Scale, Oxford \nKnee Score (OKS), Western Ontario and McMaster Universities \nOsteoarthritis Index (WOMAC), Activity Rating Scale (ARS), \nand Tegner Activity Score (TAS). Arthritis care & research. \n2011;63(S11):S208-S28.\n26. Dobson F, Hinman RS, Roos EM, Abbott JH, Stratford P, Davis \nAM, et al. OARSI recommended performance-based tests to \nassess physical function in people diagnosed with hip or knee \nosteoarthritis. Osteoarthritis and cartilage. 2013;21(8):1042–52.\n27. Fransen M, McConnell S, Harmer AR, Van der Esch M, Simic \nM, Bennell KL. Exercise for osteoarthritis of the knee. Cochrane \ndatabase of systematic reviews. 2015(1). doi:  h t t p s :   /  / d o  i . o  r  g  /  1 0  . 1 \n0   0 2 /  1 4 6  5 1  8  5 8 .  C D 0  0 4  3 7 6 . p u b 3.\n28. McAlindon TE, Bannuru RR, Sullivan M, Arden N, Berenbaum \nF, Bierma-Zeinstra S, et al. OARSI guidelines for the non-surgi -\ncal management of knee osteoarthritis. Osteoarthritis and carti -\nlage. 2014;22(3):363–88.\n29. Pressman SM, Borna S, Gomez-Cabello CA, Haider SA, Forte \nAJ. AI in Hand Surgery: Assessing Large Language Models in \nthe Classification and Management of Hand Injuries. Journal of \nClinical Medicine. 2024;13(10):2832.\n30. Zimmermann R, Staab M, Nasseri M, Brandtner P. Leveraging \nlarge language models for literature review tasks-A case study \nusing ChatGPT. International Conference on Advanced Research \nin Technologies, Information, Innovation and Sustainability: \nSpringer; 2024. p. 313– 23.\n31. Nwachukwu BU, Varady NH, Allen AA, Dines JS, Altchek DW, \nWilliams III RJ, et al. Currently available large language models \ndo not provide musculoskeletal treatment recommendations that \nare concordant with evidence-based clinical practice guidelines. \nArthroscopy: The Journal of Arthroscopic & Related Surgery. \n2024.\n32. Pandya S, Palmer K, Meyer R, Htway ZM, Fujita M. AI at the \nForefront: Navigating Oncologic Care for Six Gastrointestinal \nCancers According to the NCCN Guidelines Utilizing Gemini-1.0 \n1 3\n   73  Page 10 of 10",
  "topic": "Rehabilitation",
  "concepts": [
    {
      "name": "Rehabilitation",
      "score": 0.7449355125427246
    },
    {
      "name": "Osteoarthritis",
      "score": 0.6742058992385864
    },
    {
      "name": "Physical therapy",
      "score": 0.631545901298523
    },
    {
      "name": "Observational study",
      "score": 0.6283699870109558
    },
    {
      "name": "Medicine",
      "score": 0.5964990258216858
    },
    {
      "name": "Physical medicine and rehabilitation",
      "score": 0.5067391991615295
    },
    {
      "name": "Alternative medicine",
      "score": 0.1930798888206482
    },
    {
      "name": "Pathology",
      "score": 0.11532342433929443
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I204483917",
      "name": "Ahi Evran University",
      "country": "TR"
    }
  ]
}