{
  "title": "Inference Optimization of Foundation Models on AI Accelerators",
  "url": "https://openalex.org/W4401864094",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2115340931",
      "name": "Youngsuk Park",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2244427771",
      "name": "Kailash Budhathoki",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117474024",
      "name": "Liangfu CHEN",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2771828097",
      "name": "Jonas M. Kübler",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097102519",
      "name": "Jiaji Huang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A648491341",
      "name": "Matthäus Kleindessner",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2139058963",
      "name": "Jun Huan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A162253719",
      "name": "Volkan Cevher",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2161145992",
      "name": "Yida Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A219814910",
      "name": "George Karypis",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4321636575",
    "https://openalex.org/W4395110738",
    "https://openalex.org/W2294370754",
    "https://openalex.org/W4281758439",
    "https://openalex.org/W3119866685",
    "https://openalex.org/W2612387305",
    "https://openalex.org/W4210247494",
    "https://openalex.org/W3137147200",
    "https://openalex.org/W2963122961",
    "https://openalex.org/W4380874786",
    "https://openalex.org/W2888727064",
    "https://openalex.org/W2606722458",
    "https://openalex.org/W4387321091",
    "https://openalex.org/W3047848469",
    "https://openalex.org/W4386071831",
    "https://openalex.org/W4385573023",
    "https://openalex.org/W4312933868",
    "https://openalex.org/W4385571586",
    "https://openalex.org/W4386065704",
    "https://openalex.org/W4226126941",
    "https://openalex.org/W4402672007",
    "https://openalex.org/W6810737565",
    "https://openalex.org/W4237729708",
    "https://openalex.org/W4226079124",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W4287391717"
  ],
  "abstract": "Powerful foundation models, including large language models (LLMs), with Transformer architectures have ushered in a new era of Generative AI across various industries. Industry and research community have witnessed a large number of new applications, based on those foundation models. Such applications include question and answer, customer services, image and video generation, and code completions, among others. However, as the number of model parameters reaches to hundreds of billions, their deployment incurs prohibitive inference costs and high latency in real-world scenarios. As a result, the demand for cost-effective and fast inference using AI accelerators is ever more higher. To this end, our tutorial offers a comprehensive discussion on complementary inference optimization techniques using AI accelerators. Beginning with an overview of basic Transformer architectures and deep learning system frameworks, we deep dive into system optimization techniques for fast and memory-efficient attention computations and discuss how they can be implemented efficiently on AI accelerators. Next, we describe architectural elements that are key for fast transformer inference. Finally, we examine various model compression and fast decoding strategies in the same context.",
  "full_text": null,
  "topic": "Inference",
  "concepts": [
    {
      "name": "Inference",
      "score": 0.6885156631469727
    },
    {
      "name": "Computer science",
      "score": 0.6590360403060913
    },
    {
      "name": "Foundation (evidence)",
      "score": 0.5585445165634155
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4446585178375244
    },
    {
      "name": "Machine learning",
      "score": 0.346706748008728
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "History",
      "score": 0.0
    }
  ]
}