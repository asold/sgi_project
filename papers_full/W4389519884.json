{
  "title": "Harnessing the power of LLMs: Evaluating human-AI text co-creation through the lens of news headline generation",
  "url": "https://openalex.org/W4389519884",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5030488741",
      "name": "Zijian Ding",
      "affiliations": [
        "University of Maryland, College Park"
      ]
    },
    {
      "id": "https://openalex.org/A5101541372",
      "name": "Alison Smith",
      "affiliations": [
        "Dataminr (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5100454481",
      "name": "Wenjuan Zhang",
      "affiliations": [
        "Dataminr (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5038106045",
      "name": "Joel Tetreault",
      "affiliations": [
        "Dataminr (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5041492681",
      "name": "Alejandro Jaimes",
      "affiliations": [
        "Dataminr (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2892181857",
    "https://openalex.org/W2610413757",
    "https://openalex.org/W2096434649",
    "https://openalex.org/W2081265723",
    "https://openalex.org/W4246698901",
    "https://openalex.org/W4226210603",
    "https://openalex.org/W4288400169",
    "https://openalex.org/W3163363684",
    "https://openalex.org/W2796133875",
    "https://openalex.org/W2997920211",
    "https://openalex.org/W2741438349",
    "https://openalex.org/W3154248444",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W2800233718",
    "https://openalex.org/W4381104096",
    "https://openalex.org/W4382567209",
    "https://openalex.org/W1972978214",
    "https://openalex.org/W3154108532",
    "https://openalex.org/W2042160054",
    "https://openalex.org/W4283770858",
    "https://openalex.org/W2962897543",
    "https://openalex.org/W4221148519",
    "https://openalex.org/W3012910066",
    "https://openalex.org/W4323570570",
    "https://openalex.org/W4320858112",
    "https://openalex.org/W4287752039",
    "https://openalex.org/W4327485670",
    "https://openalex.org/W3195577433",
    "https://openalex.org/W4360979257",
    "https://openalex.org/W4287674181",
    "https://openalex.org/W4220747294",
    "https://openalex.org/W4247128285",
    "https://openalex.org/W2914949666",
    "https://openalex.org/W4392297945",
    "https://openalex.org/W4310510826",
    "https://openalex.org/W4287184555",
    "https://openalex.org/W2191070669",
    "https://openalex.org/W2970634364",
    "https://openalex.org/W2969282568",
    "https://openalex.org/W3204602149",
    "https://openalex.org/W4287643030",
    "https://openalex.org/W4366729084",
    "https://openalex.org/W4297435087",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4309674289"
  ],
  "abstract": "To explore how humans can best leverage LLMs for writing and how interacting with these models affects feelings of ownership and trust in the writing process, we compared common human-AI interaction types (e.g., guiding system, selecting from system outputs, post-editing outputs) in the context of LLM-assisted news headline generation. While LLMs alone can generate satisfactory news headlines, on average, human control is needed to fix undesirable model outputs. Of the interaction methods, guiding and selecting model output added the most benefit with the lowest cost (in time and effort). Further, AI assistance did not harm participants' perception of control compared to freeform editing.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 3321–3339\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nHarnessing the Power of LLMs: Evaluating Human-AI Text Co-Creation\nthrough the Lens of News Headline Generation\nZijian Ding1, Alison Smith-Renner2, Wenjuan Zhang2,\nJoel R. Tetreault2, Alejandro Jaimes2\n1University of Maryland, College Park, 2Dataminr Inc.\nAbstract\nTo explore how humans can best leverage\nLLMs for writing and how interacting with\nthese models affects feelings of ownership and\ntrust in the writing process, we compared com-\nmon human-AI interaction types (e.g., guiding\nsystem, selecting from system outputs, post-\nediting outputs) in the context of LLM-assisted\nnews headline generation. While LLMs alone\ncan generate satisfactory news headlines, on\naverage, human control is needed to fix unde-\nsirable model outputs. Of the interaction meth-\nods, guiding and selecting model output added\nthe most benefit with the lowest cost (in time\nand effort). Further, AI assistance did not harm\nparticipants’ perception of control compared to\nfreeform editing.\n1 Introduction\nRecent advancements in Large Language Mod-\nels (LLMs), including the Generative Pre-trained\nTransformer (GPT) series (Brown et al ., 2020),\nhave shattered the previous ceiling of human-like\ntext generation (Bommasani et al ., 2021). This\nhas led to a paradigm shift in NLP tasks, with\ntask-agnostic LLMs surpassing the performance\nof other state-of-the-art task-specific models (Lee\net al., 2022). However, LLM-backed systems are\nnot without their flaws, often suffering from hal-\nlucinations, bias, or occasional generation of inap-\npropriate content, such as toxic, discriminatory, or\nmisleading information (Wang et al., 2022).\nHuman-AI text co-creation—or writing with AI\nassistance—allows some control over the genera-\ntion process and the opportunity to overcome some\nLLM deficiencies. Co-creation approaches have\nshown tremendous promise in areas such as sum-\nmarization (Goyal et al., 2022; Bhaskar et al., 2022)\nand creative writing (Moore et al., 2023; Cao, 2023;\nYuan et al., 2022; Ding et al., 2023). Yet, the lack\nof accountability of AI (Shneiderman, 2022) shifts\nthe burden of responsibility to humans when mis-\ntakes arise in the text co-creation process.\nThere are several methods of human-AI inter-\naction for writing, which vary in terms of effort\nand control afforded by each (Cheng et al., 2022).\nFor example, humans might simply select from al-\nternative model outputs or have the flexibility to\nrevise them (e.g., post-editing). Recent research by\nDang et al. (2023) explored the dynamics of inter-\naction between crowdworkers and Large Language\nModels (LLMs) within the scenario of composing\nshort texts. Extending from their work, we evaluate\nhuman-AI interaction in the context of news head-\nline creation, focusing on three of the interaction\ntypes identified by Cheng et al . (2022)—guidance,\nselection, and post-editing. Our study advances\nCheng et al.’s Wizard-of-Oz framework by using\nan implemented AI system, providing more real-\nistic insights into human-AI co-creation for news\nheadline generation.\nWe explore three main aspects of co-creation\nwith LLMs, through the lens of headline generation:\nwhich type of assistance is most effective for help-\ning humans write high-quality headlines (RQ1)?\nWhich type of assistance can reduce perceived ef-\nfort for such task (RQ2)? And, how does interact-\ning with these models affect trust and feelings of\nownership of the produced headlines (RQ3)?\nIn a controlled experiment, 40 participants wrote\nnews headlines–either manually or assisted by one\nof three variants of an LLM-powered headline writ-\ning system: (1) selection, (2) guidance + selection,\nand (3) guidance + selection + post-editing . To\nexplore the balance between control and effort in\ntasks involving human-AI interaction (Figure 1),\nwe examined the different interaction types in com-\nbination rather than separately. Next, 20 evaluators\nrated the headlines generated by five methods—\nmanual, AI-only, and the three assisted conditions.\nWhile LLMs alone generated the highest qual-\nity headlines on average, they were not perfect,\nand human control is needed to overcome errors.\nThe simpler interactive condition guidance + selec-\n3321\nFigure 1: Human-AI interactions for text generation can fall within a range of no human control effort (AI-only) to\nfull human control effort (manual methods) (Ding and Chan, 2023). Selecting from model outputs (Selection) alone\nprovides less control (but also is easier) than when adding additional interactions in the form of guiding the model\n(Guidance) and post-editing the outputs.\ntion resulted in the rapid creation of high-quality\nheadlines compared to conditions involving further\nhuman intervention (i.e., post-editing or manual\nwriting). All conditions yielded similar perceived\ntrust and control in our task.\nThis work contributes: (1) a systematic eval-\nuation of three variants of human-AI interaction\nfor headline generation, (2) design guidelines for\nbuilders of these systems, and (3) a dataset1 of 840\nhuman-rated news headlines–written by humans,\nAI, or the combination, which could be used as an\nevaluation set for further leveraged with reinforce-\nment learning, e.g., RLHF (Stiennon et al., [n. d.]),\nto adapt LLMs for news headline generation tasks.\n2 Related Work\nOur study draws upon a convergence of prior re-\nsearch on news headline generation and evaluation,\nand human-AI interactions for text summarization.\n2.1 News Headline Generation and\nEvaluation\nNews headline generation, conventionally consid-\nered as a paradigm of text summarization tasks,\nhas been extensively researched (Tan et al., 2017;\nGoyal et al ., 2022). Advances in automation\nrange from heuristic approaches like parse-and-\ntrim (Dorr et al ., 2003) to sophisticated machine\nlearning algorithms like recurrent neural networks\n(Lopyrev, 2015), Universal Transformer (Gavrilov\net al., 2019), reinforcement learning (Song et al .,\n2020; Xu et al., 2019), large-scale generation mod-\nels trained with a distant supervision approach (Gu\net al., 2020), and large language models (Zhang\net al., 2023). Zhang et al. (2023) demonstrated that\nnews summaries generated by freelance writers\nor Instruct GPT-3 Davinci received an equivalent\nlevel of preference from human annotators. In these\nstudies, human involvement is for evaluation, not\n1https://github.com/JsnDg/EMNLP23-LLM-headline.\ncreation. For human-AI co-creation in the context\nof journalism, a recent study explored the potential\nof harnessing the common sense reasoning capabil-\nities inherent in LLMs to provide journalists with\na diverse range of perspectives when reporting on\npress releases (Petridis et al., 2023).\n2.2 Human-AI Interactions for Text\nSummarization\nThe taxonomy from Cheng et al. (2022) of human-\nAI interactions for text generation serves as the\nframework for our investigation. We focus on the\nfirst three types – guiding model output, selecting\nor rating model output , and post-editing, which\noffer varying degrees of control over the output\nand require different levels of human effort. Other\nidentified types, such as interactive writing, are\noutside the scope of this study.\nGuiding model output entails human interven-\ntion in the automatic text generation process, such\nas specifying crucial parts of input text to be in-\ncluded in the output (Gehrmann et al., 2019), or pro-\nviding semantic prompts or style parameters (Os-\none et al., 2021; Chang et al., 2021; Strobelt et al.,\n2022). Our study involves human guidance in head-\nline generation by specifying keyword prompts. Se-\nlecting or rating model output involves humans\nchoosing from multiple model outputs (Kreutzer\net al., 2018; Rosa et al., 2020) or rating them (Lam\net al ., 2018; Bohn and Ling, 2021). In our ex-\nperiment, participants chose from three generated\nheadlines. Post-editing refers to humans editing\ngenerated text (Chu and Komlodi, 2017; Huang\net al., 2020), which could be accompanied by addi-\ntional supports, such as suggestions for edits (Liu\net al ., 2011; Weisz et al ., 2021). Our study in-\nvestigates inline post-editing of selected headlines\nwithout any additional support.\n3322\nFigure 2: Interface for human-AI news headline co-\ncreation for guidance + selection + post-editing con-\ndition: (A) news reading panel, (B) perspectives (key-\nwords) selection panel (multiple keywords can be se-\nlected), (C) headline selection panel with post-editing\ncapability, and (D) difficulty rating slider. Note: (B),\n(C) and (D) are hidden from the user until the requisite\nstep is finished (e.g., the user does not see the difficulty\nrating slider until after finalizing the headline).\n3 Assessing Human-AI Co-creation of\nNews Headlines\nWe compared three variants of human-AI co-\ncreation for news headlines against fully manual\nand fully automatic approaches. Specifically, we\nexplored three research questions (RQs): RQ1:\nWhich type of assistance is most effective for help-\ning humans write high-quality headlines? RQ2:\nWhich type of assistance can reduce perceived ef-\nfort for such task? RQ3: How does interacting with\nthese models affect trust and feelings of ownership\nof the produced headlines?\nWe chose news headline creation as it is a\nfamiliar task—many participants would already\nhave some intuition about what constitutes a com-\npelling (or not) news headline—of manageable\ncomplexity—both in task and evaluation, compared\nto free-form creative writing or long-form summa-\nrization (e.g., authoring paper abstracts).\n3.1 Co-creation Methods, Implementation,\nand Prompts\nParticipants wrote headlines in one of four ways:\nmanually or aided by AI using one of three com-\nmon human-AI interaction types identified by pre-\nvious research (Cheng et al ., 2022): guidance of\nthe LLM’s headline generation using perspectives\n(keywords or facets), selection from three LLM-\ngenerated headlines, and post-editing the LLM-\ngenerated headlines.\nSpecifically, we developed a system for human-\nAI co-creation of news headlines with four variants\nof human-AI interactions:\n• Selection: The LLM generates three headlines\nfor each news article (generate headlines), and\nthe user selects the most appropriate one;\n• Guidance + Selection: The LLM extracts sev-\neral potential perspectives (keywords) from\neach news article (extract perspectives), the\nuser chooses one or more perspectives to em-\nphasize in the headline, the LLM then gen-\nerates three headlines for each news article\nbased on the selected perspectives (generate\nheadlines w/ perspectives ), and finally, the\nuser selects the best one;\n• Guidance + Selection + Post-editing: This is\nsimilar to Guidance + Selection, but the user\ncan further edit the selected headline (post-\nediting);\n• Manual only: The participant writes the news\nheadline without any AI assistance.\nOur goal was to create a continuum of human-AI\ninteraction methods ranging from less to more con-\ntrol. The layering approach of selection, guidance,\nand post-editing was informed by prior literature\n(Cheng et al., 2022) and allowed us to assess the\nimpact of each new layer by comparing adjacent\nconditions. Specifically, for these variants, we add\nadditional functionality as opposed to comparing\neach interaction individually to allow for a more\nexplicit comparison of conditions that afford less\ncontrol (and require less effort)—e.g., selection\nonly—opposed to more control (more effort)—e.g.,\nguidance + selection + post-editing (Figure 1).\nWe used OpenAI’s GPT-3.5 text-davinci-002\nmodel, the state-of-the-art LLM as of the study\nperiod (July 2022). Our study system directly in-\nterfaced with OpenAI’s GPT-3.5 API, employing\nprompt programming to extract perspectives (key-\nwords) and generate headlines—with and without\nsupplied perspectives—and presented the results to\nthe participants (see Figure 2).\nTo determine the optimal prompts forextract per-\nspectives, generate headlines, and generate head-\nlines w/ perspectives with the GPT-3.5 API, we\nconducted multiple configuration tests, ultimately\nselecting the zero-shot learning paradigm (with no\nexamples of news headlines included) for extensive\ncoverage of news topics. The GPT-3.5 API takes\n3323\nprompts (provided in Appendix A) and generates\nthe requested outputs.\nTo rigorously examine the LLM’s reliability, we\nused a temperature setting of 1, ensuring maximum\noutput variety. Additionally, we set a token count\nof 400, providing sufficient space for both input\ndata—which included prompts and news articles—\nand output data, encompassing several keywords\nor news headlines.\n3.2 Study Design\nThe study was structured into two phases: (1)\nhuman-AI co-creation of news headlines and (2)\nhuman evaluation of the generated headlines. The\nfirst phase utilized a between-subjects experimen-\ntal design with four conditions, ranging from mini-\nmal to maximal human control: (1) Selection, (2)\nGuidance + Selection, (3) Guidance + Selection\n+ Post-editing, and (4) Manual only. The second\nphase involved human evaluators who ranked the\nheadlines generated in the first phase alongside the\noriginal article headlines and headlines generated\nby GPT-only without any human input.\n3.2.1 Phase I: Human-AI Co-creation of\nHeadlines\nParticipants We enlisted 40 participants from the\nfreelancing platform, Upwork,2 ensuring diversity\nin gender (28 females, 11 males, 1 non-binary). All\nthe participants, who read news articles at least a\nfew times a week if not daily, had experience in\njournalism, editing, or writing. Their educational\nbackgrounds were diverse: 18 with Bachelor’s De-\ngrees, 11 with Master’s Degrees, 10 with High\nSchool education, and 1 chose not to disclose.\nProcedure Each participant was asked to create\nheadlines for 20 articles,3 published in June 2022\non Yahoo! News,4 the most popular news website\nin the US during Q1 2022. 5 The articles were\ncarefully chosen across four distinct themes: World\nPolitics, COVID-19, Climate Change, and Science,\nwith five articles each. The overall study procedure\nincluded an instruction round, a practice round,\nmain study, and a post-task survey. Participants\nwere randomly assigned to one of the four study\nconditions and compensated $20 for their 1-hour\nparticipation.\n2https://www.upwork.com/\n3The articles varied in length from 300 to 1000 words.\n4https://news.yahoo.com/\n5https://today.yougov.com/ratings/entertainment/popularity/\nnews-websites/all\nParticipants first learned how to utilize the sys-\ntem with various types of AI assistance (instruction\nround) and wrote headlines for two practice articles\n(practice round).\nDuring the main study, participants wrote head-\nlines for the designated 20 task articles with assis-\ntance based on their assigned condition. The order\nof news articles was randomized for each partic-\nipant. For each article, participants first read the\narticle and clicked “Continue to Write Headline\".\nParticipants then either wrote the headline manu-\nally (manual) or with some assistance as described\nin Section 3.1. After completing each headline,\nparticipants rated the difficulty. Figure 2 demon-\nstrates the system for the Guidance + Selection +\nPost-editing condition.\nFinally, after writing headlines for all 20 articles,\nparticipants completed a post-task survey. See the\nAppendix for all study figures, including instruc-\ntions, all conditions, and post-task survey.\n3.2.2 Phase II: Human Evaluation of\nHeadline Quality\nParticipants Another 20 evaluators were recruited\nthrough Upwork. We required that they were expe-\nrienced in reviewing or editing news headlines to\nensure high-quality evaluations.\nProcedure In total there were 840 headlines requir-\ning evaluation, including 800 headlines from Phase\nI (20 articles x 4 conditions x 10 participants per\ncondition), 20 Original headlines, and 20 headlines\ngenerated by GPT only.\nTo ensure every headline was reviewed by at\nleast two evaluators, we asked each evaluator to\nreview 120 headlines–the six headlines for 20\narticles—including 80 from Phase I, 20 Original,\nand 20 GPT only. We provided the evaluators with\nExcel forms containing instructions, news articles,\nand news headline ranking tables. For each article,\nthe evaluators ranked the quality of six different\nheadlines (the Original, GPT Only, and a headline\ngenerated by each of the four study conditions) us-\ning the Taste-Attractiveness-Clarity-Truth (TACT)\ntest 6 from 1 (best) to 6 (worst) and shared their\nreasons:\n• Taste: Is it in good taste? Is there anything\npossibly offensive in the headline? Can any-\nthing in the headline be taken the wrong way?\n6http://www.columbia.edu/itc/journalism/isaacs/client_edit/\nHeadlines.html\n3324\n• Attractiveness: Is it attractive to the reader?\nCan it be improved so it is more engaging and\ninteresting, without sacrificing accuracy?\n• Clarity: Does it communicate the key points\nof the article? Is it clear and simple? Does\nit use the active voice and active verbs? Are\nthere any odd words or double meanings that\ncould confuse the reader?\n• Truth: Is it accurate? Are the proper words or\nterms from the article used in the headline? Is\nthe headline factually correct?\nWhen two or more headlines for the same article\nwere of similar quality, evaluators were able to\nassign the same ranking to them.7 Each evaluator\nwas compensated $20 each for this task, estimated\nto take around an hour.8\n3.3 Measures\nWe measured headline quality (Section 3.2.2), per-\nceived task difficult, headline creation time, and\nperceived control and trust of the system. For com-\nparing efficiency between conditions, we care most\nabout the headline creation time (from clicking\n“Continue to Write Headline” to “Submit Head-\nline”). We further compute the article reading time\n(from starting to read the news article to clicking\n“Continue to Write Headline”) and overall time (ar-\nticle reading time + headline creation time).\nFor user experience, we measured the task\ndifficulty—after creating each headline (instance-\nlevel) and upon completing all headlines (overall),\nas well as perceived control and trust of the system.\nFor instance-level task difficulty, participants an-\nswered “How difficult was it to create this headline\nfor the news article with the system?” on a slider\nfrom 0 (very easy) to 100 (very difficult) after each\nheadline writing task.\nThe remaining subjective measures were col-\nlected in the post-task survey: For overall task dif-\nficulty, participants agreed or disagreed with “It\nwas difficult to create headlines for the news ar-\nticles with the system.” on a Likert scale from 1\n(strongly disagree) to 5 (strongly agree) and an-\nswered a follow-up question, “why do you feel this\nway?”. We operationalized perceived control and\n7A small amount of headlines (1.3%, or 11/840) were\nfound to be identical to another headline. These were due\nto participants selecting an identical GPT-generated headline\nwithout making further edits.\n8Based on our pilot, evaluating one news article with six\nheadlines took approximately three minutes.\ntrust of the system based on prior research: the\nquestion to gauge participants’ perceived control\nwas “I could influence the final headlines for the\nnews articles” (Rader et al., 2018). The question\nto gauge perceived trust was “I trusted that the\nsystem would help me create high-quality head-\nlines” (Cramer et al ., 2008), via 5-point Likert\nrating scales (from strongly disagree to strongly\nagree).\n3.4 Data Analysis\nWe employed the Kruskal-Wallis H test (Kruskal\nand Wallis, [n. d.]), the non-parametric version of a\none-way ANOV A test for data with three or more\nconditions, to assess the quantitative results of head-\nline quality rankings, task efficiency, and average\nand overall task difficulties, and perceived control\nand trust ratings. We then conducted a pairwise\ncomparison of headline quality using the Mann-\nWhitney U test (Mann and Whitney, 1947), the\nnon-parametric version of the Student t-test for two\nconditions. For headline quality, we compared the\nfour conditions (Manual, Selection, Guidance + Se-\nlection, and Guidance + Selection + Post-editing)\nagainst the original headlines ( Original) and the\nautomatic method (GPT only). For task efficiency\nand user experience, we compared only within the\nfour human study conditions. Finally, we analyzed\nparticipants’ general comments and feedback on\ntask difficulty.\n4 Results\nWe compared headline quality (RQ1), task effort\n(RQ2) and perceived control and trust (RQ3) be-\ntween the different headline writing conditions.\n4.1 RQ1: Headline Quality\nRankings from Phase II: Human Evaluation of\nHeadline Quality (Section 3.2.2) were used to as-\nsess headline quality across six conditions. Table 1\nshows number of ranking data points and average\nrankings for each condition.9\nAs shown in Table 1 and 2, an approximate rank-\ning of headline quality is as follows: Original ∼\nGPT only (best) > Guidance + Selection ∼ Guid-\nance + Selection + Post-editing> Selection ∼ Man-\nual only. The variance in quality rankings across\nthe six conditions was significant, as confirmed by\n9Rankings (from 1st to 6th place) for a total of 120 head-\nlines (20 article x 6 conditions) were obtained (as shown in\nTable 1). However, ten were missed due to annotator error,\nresulting in 2390 total data points for analysis.\n3325\nCondition / Ranking 1 2 3 4 5 6 Mean Std\nManual only 56 60 56 56 71 98 3.8 1.8\nSelection 56 53 65 67 83 75 3.7 1.7\nGuidance + Selection 71 69 64 75 63 58 3.4 1.7\nGuidance + Selection + Post-editing 70 71 74 60 65 58 3.4 1.7\nOriginal 87 75 68 65 64 38 3.2 1.7\nGPT only 70 73 89 79 51 37 3.2 1.6\nTable 1: Counts of rankings from 1 (best) to 6 (worst) across six conditions, with mean rank and standard deviation.\nLower values indicate superior rankings. Bold counts represent the highest number of 1st place rankings and the\nfewest 6th place rankings. The original headlines (Original) received the most 1st place rankings and the fewest 6th\nplace rankings, while the Manual condition received the fewest 1st place and the most 6th place rankings.\nCondition 1 > Condition 2 U-value p-value\nOriginal > Manual only 61766.0 <0.01\nOriginal > Selection 63550.0 <0.01\nOriginal > Guidance + Selection 72364.5 0.028\nOriginal > Guidance + Selection + Post-editing 72688.5 0.048\nGPT only > Manual only 63168.5 <0.01\nGPT only > Selection 64751.5 <0.01\nGuidance + Selection > Manual only 89877.5 <0.01\nGuidance + Selection > Selection 88536.5 <0.01\nGuidance + Selection + Post-editing > Manual only 89972.5 <0.01\nGuidance + Selection + Post-editing > Selection 88734.0 <0.01\nTable 2: Pairwise comparison of headline quality rankings with significant difference (p<0.05, Mann-Whitney U).\nKruskal-Wallis H tests, with an H −value = 50.8\nand a p − value < 0.01. Additional pairwise\ncomparisons (detailed in Table 2) offered more\ngranular insights into the discrepancies: headlines\npenned by participants in the Manual condition\nwere deemed the lowest quality, whereas the origi-\nnal headlines and headlines generated by GPT only\nwere deemed highest quality.\nWithin the AI-assisted conditions, human guid-\nance, in the form of selecting keyword perspectives\n(under Guidance + Selection or Guidance + Se-\nlection + Post-editing), improved headline quality\ncompared to direct Selection of AI-generated op-\ntions. Interestingly, post-editing had no significant\neffect on the quality of the headlines: no noticeable\ndifference in ranking was identified between the\nheadlines generated by Guidance + Selection and\nGuidance + Selection + Post-editing conditions.\nTo delve deeper into group comparisons, we ex-\namined the count of \"top\" (ranked 1st) and \"bot-\ntom\" (ranked 6th) rankings (as shown in Table 1).\nAs anticipated, the Original headlines of the news\narticles received the most \"top\" rankings (87) and\nthe fewest \"bottom\" rankings (38). The GPT only\ncondition had fewer \"top\" rankings than Original\n(70), but a comparable number of \"bottom\" rank-\nings (37). The Manual and Selection conditions\nhad the fewest \"top\" rankings (56), while Manual\nalso had the most \"bottom\" rankings (98).\nEvaluators comments gave additional insight\ninto the reasons behind their rankings. For exam-\nple, one annotator favored the concise headline\ngenerated by GPT only and critiqued the errors that\nundermined the Manual headline. For more details,\nsee Appendix B.\n4.2 RQ2: Task Effort\n4.2.1 Headline Creation Time\nWe used task time as an indicator of task effort\nbecause it often reflects the workload someone ex-\nperiences. Specifically, we compare headline cre-\nation time—the time spent to generate the news\nheadline, exclusive of the time it took to read the\nnews article. As expected, the Selection and Guid-\nance + Selection conditions were markedly faster\n(H−value = 13.0, p−value = 0.005) than condi-\ntions that involved manual editing, such as Manual\nand Guidance + Selection + Post-editing (Figure\n3). A detailed comparison of creation time, reading\ntime, and total time is provided in Appendix C.\n4.2.2 Perceived Task Difficulty\nOn the whole, participants felt the headline writing\ntask was easy (e.g., average overall difficulty rating\n1.9 out of 5). And, although Guidance + Selection\nhad the lowest percieved instance-level difficulty\n(M=19.7 out of 100, SD=24.3) and Manual had the\nhighest (M=30.9, SD=17.1), these differences were\nnot statistically significant—in part due to high\nvariance between participants and our small sam-\n3326\nFigure 3: News headline creation time across four hu-\nman conditions (standard deviation as error bars): Se-\nlection and Guidance + Selection are faster than the\nother two conditions which required more human edit-\ning (Manual and Guidance + Selection + Post-editing).\nple size. Additional results for instance-level and\noverall task difficulties are detailed in Appendix D.\n4.3 RQ3: Perceived Trust and Control\nWe did not observe significant difference in per-\nceived trust or control across the conditions (see\nAppendix E for more details). We had expected\nparticipants with more “control” over the final out-\nput (i.e., those writing manually or with option to\npost-edit the final output) to have more perceived\ncontrol than the other conditions. Yet, even while\nmost participants (9/10) in the Guidance + Selec-\ntion + Post-editing condition did edit at least one\nheadline during the task, with an average of 8.5\nheadlines edited (median = 7.5, std= 6.0), post-\nediting did not seem to enhance participants’ sense\nof ownership over the generated headlines. We\ndiscuss possible reasons for this in Section 5.3.\n5 Discussion\nOur study explored how diverse forms of AI assis-\ntance for news headline writing influence headline\nquality (RQ1), task effort (RQ2), and perceived\ntrust and control (RQ3). We interpret our results\nfor each of the RQs and discuss further implications\nin the following.\n5.1 RQ1: Which type of assistance helped\nhumans write high-quality headlines?\nHeadlines produced by the GPT only condition\nwere, on average, of the highest quality, whereas\nheadlines written manually were of the lowest.\nAnd, all types of AI assistance explored in the\nstudy helped participants achieve higher quality\nas compared to when no assistance was available.\nTherefore, system designers should consider lever-\naging these types of assistance to better support\nhumans performing similar writing tasks.\nWhile our findings could imply that completely\nautomated methods are adequate for generating\nheadlines, we urge system designers to critically\nevaluate when and where is appropriate to fully\nrely on AI assistance. Headlines by GPT only were\nnot flawless, receiving the lowest ranking in some\ninstances. Human intervention remains necessary\nfor editing and final decisions, particularly in high-\nstakes tasks. Upon reflection, this study focused\non overall headline quality in the evaluation task.\nAdditional evaluation on the type, quantity, and\nseverity of errors from headlines could reveal valu-\nable insights. While multiple reasons could lead to\na headline ranked as low quality, problematic hal-\nlucinations that are commonly seen with large lan-\nguage models (Bender et al., 2021; Ji et al., 2023)\ncould be more harmful than omission of details.\nAmong the AI assistance, providing Guidance\n(using keywords) resulted in higher headline qual-\nity compared to Selection alone, yet did not outper-\nform the GPT only condition.\nParticipants comments revealed that the qual-\nity of keywords given in the Guidance interaction\nplayed a crucial role in the final headline quality.\nWhen the keyword quality was poor, e.g., vague\nor not well aligned with key points of the article,\nthe generated captions were lower quality as well.\nThe design of the Guidance interaction may have\nlimited its utility. One participant noted \"it would\nhave been nice if I could go back and change the\nkeywords and see how the headlines change\", sug-\ngesting a more interactive experience could help\nthem better understand how their guidance influ-\nences the model’s output.\nHeadline evaluation is a subjective task, which\ncan influence these outcomes. To mitigate this, we\nused the TACT evaluation framework as a standard-\nized rubric, which was shared with both headline\ngenerators and evaluators. Importantly, human con-\ntrol over the final headline is a promising direction\ngiven the subjective nature (i.e., simply relying on\nthe system to pick the best headline is problematic\nif what is best differs by the audience and their\ndesired headline qualities.\n3327\nType Before Revision After Revision\n1) Hedging Is your lawn ruining the environment? Is your lawn contributing to climate change?\n2) Hedging Soldiers given second change to get vaccinated and\navoid expulsion\nSoldiers given second chance to get vaccinated and\navoid penalties\n3) Catering Mapping the Seafloor: New technologies crucial for\ncompletion\nMapping the Seafloor: New technologies crucial for\nclimate change\n4) Clarifying Forest Service employees made several mistakes\nwhen planning a controlled burn in New Mexico,\nresulting in the largest fire in the state’s history\nForest Service mistakes when planning a controlled\nburn in New Mexico, resulting in the largest fire in\nNew Mexico history\nTable 3: Examples of humans’ post-editing on AI-generated headlines.\n5.2 RQ2: Which type of assistance reduced\nperceived effort?\nIn terms of headline creating time, interactions such\nas guiding the model output and selecting generated\nheadlines were quicker than post-editing, as ex-\npected. This means when efficiency is key to a sys-\ntem’s performance, these type of interactions would\nbe most effective, especially when the model out-\nputs are generally satisfactory. Post-editing would\nlikely be more critical if the quality of the model’s\noutput was suboptimal, or when humans need the\nability to fully control the outcome.\nInterestingly, in perceived task difficulty did not\ndiffer across all conditions. This is likely because\nmost participants were experienced in headline\nwriting. While their experience level varied greatly,\nfrom working for school newspaper to being in\njournalism for more than 40 years, the hands-on ex-\nperience made the task in our study easy for them.\nFuture research direction might evaluate if such\nAI assistance can lower the expertise requirements\nfor headline writing task, enabling people with less\nexperience to write good quality headlines.\n5.3 RQ3: How does interacting with these\nmodels affect feelings of trust and\nownership of the produced headlines?\nWe did not observe any significant difference in\nperceived trust or control. While surprising, we\nexpect this might be from a flaw in our operational-\nization of perceived control; the statement \"I could\ninfluence the final headlines for the news articles\"\ndoes not specify the level or type of control one had\nover the system, and the participants could “influ-\nence the final headlines” to some extent no matter\nwhich condition they experienced. We recommend\nfuture research investigate more robust methods for\nmeasuring perceived control or sense of ownership.\nAnother reason for the lack of significant differ-\nence in this (and other subjective measures) is that\neach participant only experienced one condition\nand had no way to compare with other conditions.\nA within-subject study would be more effective for\ncomparing perceived difficulty, control, and trust\nacross multiple experiences. However, we chose\na between-subject design to avoid the fatigue of\nhaving to complete similar tasks with multiple in-\nterfaces and the confusion from switching from one\nexperience to another.\nFinally, participants may have felt they did not\nneed to exert much control for the system to per-\nform well and, therefore, did not think about the\nlevel of control critically. Counter to what the\nresults showed, we had expected post-editing to\nimprove the sense of control. Analysis of their\npost-editing process (Table 3) revealed that changes\nmade by participants during post-editing were typi-\ncally minor, falling into three categories:\n1. \"Hedging\": Participants generally avoided\nsensationalism or \"click-bait\" language, fa-\nvoring more measured phrasing. For instance,\n\"ruining the environment\" was altered to \"con-\ntributing to climate change\", and \"expulsion\"\nwas revised to \"penalties\".\n2. \"Catering\": Participants frequently tweaked\nthe headlines to make them more relevant to\nthe target audience, for instance, changing\n\"completion\" to \"climate change\".\n3. \"Clarifying\": Some edits involved minor text\nadjustments, such as replacing \"the state’s\"\nwith \"New Mexico\".\nParticipants may have associated smaller degree\nof changes with smaller level of control to the sys-\ntem output. However, we highlight that these re-\nvision types could be supported natively by future\nsystems.\n5.4 Control, Transparency, and Guardrails in\nCo-Creation\nThe interaction options we introduced extend\nbeyond mere control, instead providing both\n3328\nguardrails and a way to expose what is possible\nwith LLMs. First, both the selection and guidance\ninteractions provide a set of guardrails toward bet-\nter output opposed to freeform prompting of the\nLLM. Next, as participants can guide the model via\ntheme or keyword inputs, they are also afforded a\nlevel of transparency to comprehend the influence\nthey may exert on LLMs to yield headlines with\nvarying focuses. These approaches which combine\ncontrol and transparency seem critical to successful\nco-creation settings (Liao and Vaughan, 2023).\nWe did not evaluate a setting where users\nprompted the LLM themselves (this is a suggestion\nfor future work); instead, our settings—which in-\ncorporated optimized prompts (Appendix A) —are\nmeant to provide a more directed scenario, without\nrequiring the user to come up with possible key-\nwords from scratch. This scenario progressively ex-\nploded users to how the model works and how they\ncan control it. Future iterations of the guidance\ninteraction could benefit from additionally offer-\ning users a choice between system-suggested and\nuser-defined keywords to flexibly steer the model.\n6 Conclusion\nWe explore human-AI text co-creation through the\ncontext of news headline generation: how can hu-\nmans best harness the power of LLMs in writing\ntasks, in terms of both quality and efficiency? And,\nhow does interacting with these models affect trust\nand feelings of ownership of the produced text? 40\nparticipants with editing backgrounds wrote news\nheadlines—either manually or assisted by a variant\nof our LLM-powered headline generation system—\nutilizing some combination of three common in-\nteraction types (guiding model outputs, selecting\nfrom model outputs, and post-editing). Following\nthis, 20 expert evaluators rated the headlines gen-\nerated by five methods (human-only, AI-only, and\nthe three assisted conditions). While the LLM on\nits own can generate satisfactory news headlines on\naverage, human intervention is necessary to correct\nundesirable model outputs. Among the interac-\ntion methods, guiding model output provided the\nmost benefit with the least cost (in terms of time\nand effort). Furthermore, AI assistance did not\ndiminish participants’ perception of control com-\npared to freeform editing. Finally, while we focus\non a simpler, low-stakes text generation scenario,\nthis work lays the foundation for future research in\nmore complex areas of human-AI co-creation.\nLimitations\nThis study, while comprehensive, acknowledges\nseveral limitations that outline areas for potential\nfuture research. One of the constraints pertains to\nthe evaluation of different models. Specifically, the\nresearch primarily focused on types of human-AI\ninteraction, utilizing GPT-3.5 due to its state-of-\nthe-art performance during the research phase. The\nchoice was made to prevent the complication of the\nstudy design by introducing performance as an ad-\nditional variable, which could have overshadowed\nthe main objective of analyzing three interaction\nvariants. However, understanding the impact of\nvarying models and their performances remains\nan essential prospect for subsequent studies and\nsystem design.\nMoreover, in terms of evaluation measures, the\nstudy employed the Taste-Attractiveness-Clarity-\nTruth (TACT) framework to assess headline quality.\nDespite its standardization, this framework may\nnot fully encapsulate all the nuances of a model’s\nperformance, such as verbosity, indicating a need\nfor future work to refine these evaluation standards.\nAdditionally, the research’s scope was limited in\nterms of the number and types of articles, as it pri-\noritized the examination of interaction differences\nover article diversity. This limitation underscores\nthe importance of future studies exploring a broader\narray of articles and involving more participants\nfor an extended period. Similarly, the study did not\nevaluate the efficiency of the model in generating\ndiverse perspectives, maintaining consistency in ar-\nticle selection based on length and domain instead.\nThe assessment of content generation difficulty is\nidentified as a crucial element for more in-depth\nresearch.\nConcerning participant expertise, the study con-\nducted was a concise, one-hour session centered on\nhuman-AI collaboration in news headline creation,\ntaking into account participant expertise without\nenforcing strict control. This approach points to the\nnecessity for more extensive research, particularly\nin more complex and specialized domains.\nFinally, regarding study design and comparison,\nthe research adopted a between-subjects approach,\npreventing participants from making direct compar-\nisons of the different human-AI interaction meth-\nods. As a result, certain participants might not\nhave fully grasped how AI could potentially en-\nhance the task, as their experience was confined to\ntheir specific condition. This highlights an oppor-\n3329\ntunity for future studies to possibly implement a\nwithin-subjects design for a more holistic partici-\npant experience.\nEthics Statement\nAlthough the performance of headlines generated\nby GPT only were comparable to the original head-\nlines and those headlines did not demonstrate evi-\ndent biases or ethical issues, there is an open ques-\ntion of to what extent AI should be relied upon.\nShneiderman proposes that “we should reject the\nidea that autonomous machines can exceed or re-\nplace any meaningful notion of human intelligence,\ncreativity, and responsibility” (Shneiderman, 2022).\nWe echo that serious consideration is needed be-\nfore AI is relied upon for creating text, even for\nlow stakes tasks. It is important for humans to use\ntheir expertise and judgment when working on con-\ntent generation with AI and ensure that the content\nproduced is fair, ethical, and aligned with societal\nvalues.\nReferences\nEmily M Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On the\nDangers of Stochastic Parrots: Can Language Models\nBe Too Big?. In Proceedings of the 2021 ACM con-\nference on fairness, accountability, and transparency.\n610–623.\nAdithya Bhaskar, Alexander R. Fabbri, and Greg Dur-\nrett. 2022. Zero-Shot Opinion Summarization with\nGPT-3. http://arxiv.org/abs/2211.15914\narXiv:2211.15914 [cs].\nTanner Bohn and Charles X. Ling. 2021. Hone as\nYou Read: A Practical Type of Interactive Sum-\nmarization. http://arxiv.org/abs/2105.02923\narXiv:2105.02923 [cs].\nRishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ\nAltman, Simran Arora, Sydney von Arx, Michael S.\nBernstein, Jeannette Bohg, Antoine Bosselut, Emma\nBrunskill, Erik Brynjolfsson, Shyamal Buch, Dallas\nCard, Rodrigo Castellon, Niladri Chatterji, Annie\nChen, Kathleen Creel, Jared Quincy Davis, Dora\nDemszky, Chris Donahue, Moussa Doumbouya,\nEsin Durmus, Stefano Ermon, John Etchemendy,\nKawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor\nGale, Lauren Gillespie, Karan Goel, Noah Goodman,\nShelby Grossman, Neel Guha, Tatsunori Hashimoto,\nPeter Henderson, John Hewitt, Daniel E. Ho, Jenny\nHong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil\nJain, Dan Jurafsky, Pratyusha Kalluri, Siddharth\nKaramcheti, Geoff Keeling, Fereshte Khani, Omar\nKhattab, Pang Wei Koh, Mark Krass, Ranjay Kr-\nishna, Rohith Kuditipudi, Ananya Kumar, Faisal Lad-\nhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle\nLevent, Xiang Lisa Li, Xuechen Li, Tengyu Ma,\nAli Malik, Christopher D. Manning, Suvir Mirchan-\ndani, Eric Mitchell, Zanele Munyikwa, Suraj Nair,\nAvanika Narayan, Deepak Narayanan, Ben Newman,\nAllen Nie, Juan Carlos Niebles, Hamed Nilforoshan,\nJulian Nyarko, Giray Ogut, Laurel Orr, Isabel Pa-\npadimitriou, Joon Sung Park, Chris Piech, Eva Porte-\nlance, Christopher Potts, Aditi Raghunathan, Rob\nReich, Hongyu Ren, Frieda Rong, Yusuf Roohani,\nCamilo Ruiz, Jack Ryan, Christopher Ré, Dorsa\nSadigh, Shiori Sagawa, Keshav Santhanam, Andy\nShih, Krishnan Srinivasan, Alex Tamkin, Rohan\nTaori, Armin W. Thomas, Florian Tramèr, Rose E.\nWang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai\nWu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan\nYou, Matei Zaharia, Michael Zhang, Tianyi Zhang,\nXikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn\nZhou, and Percy Liang. 2021. On the Opportunities\nand Risks of Foundation Models. arXiv:2108.07258\n[cs] (Aug. 2021). http://arxiv.org/abs/2108.\n07258 00021 arXiv: 2108.07258.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language Models are Few-Shot Learners.\narXiv:2005.14165 [cs] (June 2020). http://arxiv.\norg/abs/2005.14165 00030 arXiv: 2005.14165.\nChen Cao. 2023. Scaffolding CS1 Courses with a Large\nLanguage Model-Powered Intelligent Tutoring Sys-\ntem. In Companion Proceedings of the 28th Inter-\nnational Conference on Intelligent User Interfaces.\n229–232.\nHaw-Shiuan Chang, Jiaming Yuan, Mohit Iyyer, and An-\ndrew McCallum. 2021. Changing the Mind of Trans-\nformers for Topically-Controllable Language Gen-\neration. http://arxiv.org/abs/2103.15335\narXiv:2103.15335 [cs].\nRuijia Cheng, Alison Smith-Renner, Ke Zhang, Joel\nTetreault, and Alejandro Jaimes-Larrarte. 2022. Map-\nping the Design Space of Human-AI Interaction in\nText Summarization. InProceedings of the 2022 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies. Association for Computational\nLinguistics, Seattle, United States, 431–455. https:\n//doi.org/10.18653/v1/2022.naacl-main.33\nPeng Chu and Anita Komlodi. 2017. TranSearch: A\nMultilingual Search User Interface Accommodating\nUser Interaction and Preference. In Proceedings of\nthe 2017 CHI Conference Extended Abstracts on Hu-\nman Factors in Computing Systems. ACM, Denver\nColorado USA, 2466–2472. https://doi.org/10.\n1145/3027063.3053262\n3330\nHenriette Cramer, Vanessa Evers, Satyan Ramlal,\nMaarten van Someren, Lloyd Rutledge, Natalia Stash,\nLora Aroyo, and Bob Wielinga. 2008. The effects of\ntransparency on trust in and acceptance of a content-\nbased art recommender. User Modeling and User-\nAdapted Interaction 18, 5 (Nov. 2008), 455–496.\nhttps://doi.org/10.1007/s11257-008-9051-3\nHai Dang, Sven Goller, Florian Lehmann, and Daniel\nBuschek. 2023. Choice over control: How users\nwrite with large language models using diegetic and\nnon-diegetic prompting. In Proceedings of the 2023\nCHI Conference on Human Factors in Computing\nSystems. 1–17.\nZijian Ding and Joel Chan. 2023. Mapping the Design\nSpace of Interactions in Human-AI Text Co-creation\nTasks. arXiv e-prints (2023), arXiv–2303.\nZijian Ding, Arvind Srinivasan, Stephen MacNeil, and\nJoel Chan. 2023. Fluid Transformers and Creative\nAnalogies: Exploring Large Language Models’ Ca-\npacity for Augmenting Cross-Domain Analogical\nCreativity. In Proceedings of the 15th Conference\non Creativity and Cognition. 489–505.\nBonnie Dorr, David Zajic, and Richard Schwartz. 2003.\nHedge Trimmer: a parse-and-trim approach to head-\nline generation. In Proceedings of the HLT-NAACL\n03 on Text summarization workshop -, V ol. 5. Associ-\nation for Computational Linguistics, Not Known, 1–8.\nhttps://doi.org/10.3115/1119467.1119468\nDaniil Gavrilov, Pavel Kalaidin, and Valentin Ma-\nlykh. 2019. Self-Attentive Model for Headline Gen-\neration. http://arxiv.org/abs/1901.07786\narXiv:1901.07786 [cs].\nSebastian Gehrmann, Hendrik Strobelt, Robert Krüger,\nHanspeter Pfister, and Alexander M. Rush. 2019. Vi-\nsual Interaction with Deep Learning Models through\nCollaborative Semantic Inference. http://arxiv.\norg/abs/1907.10739 arXiv:1907.10739 [cs].\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.\nNews Summarization and Evaluation in the Era\nof GPT-3. http://arxiv.org/abs/2209.12356\narXiv:2209.12356 [cs].\nXiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, You\nWu, Cong Yu, Daniel Finnie, Hongkun Yu, Jiaqi Zhai,\nand Nicholas Zukoski. 2020. Generating Represen-\ntative Headlines for News Stories. In Proceedings\nof The Web Conference 2020. ACM, Taipei Taiwan,\n1773–1784. https://doi.org/10.1145/3366423.\n3380247\nCheng-Zhi Anna Huang, Hendrik Vincent Koops, and\nEd Newton-Rex. 2020. AI SONG CONTEST:\nHUMAN-AI CO-CREATION IN SONGWRITING.\n(2020).\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\nMadotto, and Pascale Fung. 2023. Survey of hal-\nlucination in natural language generation. Comput.\nSurveys 55, 12 (2023), 1–38.\nJulia Kreutzer, Joshua Uyheng, and Stefan Riezler.\n2018. Reliability and Learnability of Human Bandit\nFeedback for Sequence-to-Sequence Reinforcement\nLearning. http://arxiv.org/abs/1805.10627\narXiv:1805.10627 [cs, stat].\nWilliam H Kruskal and W Allen Wallis. [n. d.]. Use of\nRanks in One-Criterion Variance Analysis. ([n. d.]).\nTsz Kin Lam, Julia Kreutzer, and Stefan Riezler. 2018.\nA Reinforcement Learning Approach to Interactive-\nPredictive Neural Machine Translation. http:\n//arxiv.org/abs/1805.01553 arXiv:1805.01553\n[cs, stat].\nMina Lee, Percy Liang, and Qian Yang. 2022. CoAu-\nthor: Designing a Human-AI Collaborative Writing\nDataset for Exploring Language Model Capabilities.\n(2022), 19. https://doi.org/10.1145/3491102.\n3502030\nQ Vera Liao and Jennifer Wortman Vaughan. 2023.\nAI Transparency in the Age of LLMs: A Human-\nCentered Research Roadmap. arXiv preprint\narXiv:2306.01941 (2023).\nChien-Liang Liu, Chia-Hoang Lee, Ssu-Han Yu, and\nChih-Wei Chen. 2011. Computer assisted writing\nsystem. Expert Systems with Applications 38, 1 (Jan.\n2011), 804–811. https://doi.org/10.1016/j.\neswa.2010.07.038\nKonstantin Lopyrev. 2015. Generating News Headlines\nwith Recurrent Neural Networks. http://arxiv.\norg/abs/1512.01712 arXiv:1512.01712 [cs].\nH. B. Mann and D. R. Whitney. 1947. On a Test of\nWhether one of Two Random Variables is Stochasti-\ncally Larger than the Other. The Annals of Math-\nematical Statistics 18, 1 (1947), 50–60. http:\n//www.jstor.org/stable/2236101\nSteven Moore, Richard Tong, Anjali Singh, Zitao Liu,\nXiangen Hu, Yu Lu, Joleen Liang, Chen Cao, Hassan\nKhosravi, Paul Denny, et al. 2023. Empowering edu-\ncation with llms-the next-gen interface and content\ngeneration. In International Conference on Artificial\nIntelligence in Education. Springer, 32–37.\nHiroyuki Osone, Jun-Li Lu, and Yoichi Ochiai. 2021.\nBunCho: AI Supported Story Co-Creation via Un-\nsupervised Multitask Learning to Increase Writers’\nCreativity in Japanese. In Extended Abstracts of\nthe 2021 CHI Conference on Human Factors in\nComputing Systems. ACM, Yokohama Japan, 1–10.\nhttps://doi.org/10.1145/3411763.3450391\nSavvas Petridis, Nicholas Diakopoulos, Kevin Crow-\nston, Mark Hansen, Keren Henderson, Stan Jastrzeb-\nski, Jeffrey V Nickerson, and Lydia B Chilton. 2023.\nAnglekindling: Supporting journalistic angle ideation\nwith large language models. In Proceedings of the\n2023 CHI Conference on Human Factors in Comput-\ning Systems. 1–16.\n3331\nEmilee Rader, Kelley Cotter, and Janghee Cho. 2018.\nExplanations as Mechanisms for Supporting Algo-\nrithmic Transparency. In Proceedings of the 2018\nCHI Conference on Human Factors in Computing\nSystems. ACM, Montreal QC Canada, 1–13. https:\n//doi.org/10.1145/3173574.3173677\nRudolf Rosa, Ond ˇrej Dušek, Tom Kocmi, David\nMareˇcek, Tomáš Musil, Patrícia Schmidtová, Do-\nminik Jurko, Ond ˇrej Bojar, Daniel Hrbek, David\nKošt’ák, Martina Kinská, Josef Doležal, and Klára\nV osecká. 2020. THEaiTRE: Artificial Intelligence\nto Write a Theatre Play. http://arxiv.org/abs/\n2006.14668 arXiv:2006.14668 [cs].\nBen Shneiderman. 2022. Human-centered AI. Oxford\nUniversity Press.\nYun-Zhu Song, Hong-Han Shuai, Sung-Lin Yeh, Yi-\nLun Wu, Lun-Wei Ku, and Wen-Chih Peng. 2020.\nAttractive or Faithful? Popularity-Reinforced Learn-\ning for Inspired Headline Generation. Proceed-\nings of the AAAI Conference on Artificial Intelli-\ngence 34, 05 (April 2020), 8910–8917. https:\n//doi.org/10.1609/aaai.v34i05.6421\nNisan Stiennon, Long Ouyang, Jeff Wu, Daniel M\nZiegler, Ryan Lowe, Chelsea V oss, Alec Radford,\nDario Amodei, and Paul Christiano. [n. d.]. Learning\nto summarize from human feedback. ([n. d.]).\nHendrik Strobelt, Jambay Kinley, Robert Krueger, Jo-\nhanna Beyer, Hanspeter Pfister, and Alexander M.\nRush. 2022. GenNI: Human-AI Collaboration for\nData-Backed Text Generation. IEEE Transactions\non Visualization and Computer Graphics 28, 1 (Jan.\n2022), 1106–1116. https://doi.org/10.1109/\nTVCG.2021.3114845 arXiv:2110.10185 [cs].\nJiwei Tan, Xiaojun Wan, and Jianguo Xiao. 2017. From\nNeural Sentence Summarization to Headline Gener-\nation: A Coarse-to-Fine Approach. In Proceedings\nof the Twenty-Sixth International Joint Conference\non Artificial Intelligence. International Joint Confer-\nences on Artificial Intelligence Organization, Mel-\nbourne, Australia, 4109–4115. https://doi.org/\n10.24963/ijcai.2017/574\nBoxin Wang, Wei Ping, Chaowei Xiao, Peng Xu,\nMostofa Patwary, Mohammad Shoeybi, Bo Li, An-\nima Anandkumar, and Bryan Catanzaro. 2022. Ex-\nploring the Limits of Domain-Adaptive Training for\nDetoxifying Large-Scale Language Models. http:\n//arxiv.org/abs/2202.04173 arXiv:2202.04173\n[cs].\nJustin D. Weisz, Michael Muller, Stephanie Houde,\nJohn Richards, Steven I. Ross, Fernando Martinez,\nMayank Agarwal, and Kartik Talamadupula. 2021.\nPerfection Not Required? Human-AI Partnerships in\nCode Translation. In 26th International Conference\non Intelligent User Interfaces. ACM, College Station\nTX USA, 402–412. https://doi.org/10.1145/\n3397481.3450656\nPeng Xu, Chien-Sheng Wu, Andrea Madotto, and Pas-\ncale Fung. 2019. Clickbait? Sensational Head-\nline Generation with Auto-tuned Reinforcement\nLearning. http://arxiv.org/abs/1909.03582\narXiv:1909.03582 [cs].\nAnn Yuan, Andy Coenen, Emily Reif, and Daphne Ip-\npolito. 2022. Wordcraft: Story Writing With Large\nLanguage Models. In 27th International Confer-\nence on Intelligent User Interfaces. ACM, Helsinki\nFinland, 841–852. https://doi.org/10.1145/\n3490099.3511105\nTianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang,\nKathleen McKeown, and Tatsunori B Hashimoto.\n2023. Benchmarking large language models for news\nsummarization. arXiv preprint arXiv:2301.13848\n(2023).\n3332\nAPPENDIX\nA Prompts for tasks\nTo determine the optimal prompts for extract per-\nspectives, generate headlines, and generate head-\nlines w/ perspectives with the GPT-3.5 API, we\nconducted multiple configuration tests, ultimately\nselecting the zero-shot learning paradigm (with no\nexamples of news headlines included) for extensive\ncoverage of news topics.\nHere are the finalized prompts for the corre-\nsponding tasks:\n• extract perspectives: \"Please identify five key-\nwords and key phrases (nouns) for the fol-\nlowing news article.\\nNews article:\\n + [news\narticle] + \\nFive keywords and key phrases\n(nouns), separated with comma:\\n\"\n• generate headlines: \"Please come up with\nthree high-quality (attractive, clear, accurate\nand inoffensive) headlines for the following\nnews article.\\nNews article:\\n\\n + [news arti-\ncle] + \\n\\nThree high-quality headlines:\\n\"\n• generate headlines w/ perspectives: \"Please\ncome up with three high-quality (attractive,\nclear, accurate and inoffensive) headlines\nfor the following news article including key-\nword(s): [keyword(s) selected by partici-\npants].\\nNews article:\\n\\n + [news article] +\n\\n\\nThree high-quality headlines:\\n\"\nB Annotator Rationale Case Study\nTable 4 illustrates the rankings assigned by an an-\nnotator to six different headlines, each generated\nunder a unique condition, for a single article. Ac-\ncompanying comments provide valuable insights\ninto the annotator’s ranking rationale.\nC Task Time\nTable 5 presents the time spent on different parts of\nthe task—reading the article, creating the headline,\nand the total time for both reading and creating the\nheadline—between conditions.\nD Perceived Task Difficulty\nTable 6 presents the self-reported instance-level and\noverall task difficulty ratings between conditions.\nE Perceived Control and Trust\nTable 7 presents the self-reported trust in the sys-\ntem (trust) and feelings of ownership over the final\nheadline (control).\nF Qualitative feedback on AI-assisted\nheadline generation\nAfter the headline generation task, participants\nwere asked for open-ended responses as a supple-\nment to their perceived task difficulty and were\ninvited to share “any other comments you want to\ntell us”. These responses illuminated perceived\nadvantages of AI assistants, for example in facili-\ntating brainstorming: \"Overall, I’d say this system\ncould definitely be helpful as long as the keyword\nlist lines up with the main keywords in the arti-\ncle. Additionally, it would always be a helpful\nbrainstorming tool for headlines.\" (P40, Guidance\n+ Selection + Post-editing)\nSome participants proposed specific considera-\ntions for the design of future AI-assisted systems:\n1) inclusion of main points in AI-generated head-\nlines \"Some of the main points were left out of\ncertain headlines, but otherwise, this proves to be\na useful tool for journalists. The main points were\ncombined into an easy-to-use database for selec-\ntion.\" (P23, Guidance + Selection); 2) high effi-\nciency but limited creativity and reasoning \"I\ncould see how this would be beneficial in situa-\ntions where time is limited, but it does not replace\nthe creativity and reasoning a human has. Some\nseemed spot on and others seemed chaotic. But\nwith a few tweaks, it was easy to create a headline.\nSome of the keywords suggested seemed totally\nunnecessary. The keywords were the weakest part\nof the system in my opinion.\" (P39,Guidance + Se-\nlection + Post-editing); 3) guidance on AI model\nand selection of AI outputs as a non-linear pro-\ncess \"I do wish I could have gone back to choose\ndifferent perspectives and see alternate variations\nthan just the 3 original headlines. If those first 3\noptions don’t really cover the central theme of the\narticle, it would be nice to go back and choose al-\nternate perspectives to see if it populates a more\nprecise headline. Overall though, this is a great tool\nto save time and many headaches. I really enjoyed\nthis experience and would love to participate again\nin future exercises.\" (P28, Guidance + Selection)\n3333\nType Title Rank Comment\nManual only National Army Guard Demands Sol-\ndiers to be Vaccinated against Covid-\n19\n6 The title of the Army is wrong and it’s\nalso not the subject of the article.\nSelection Army National Guard facing recruit-\ning crisis amid vaccination deadline\n3 This title does not include COVID\nwhich is a prominent subject and good\nfor SEO considering the article is\nabout it\nGuidance +\nSelection\nArmy National Guard misses Covid\nvaccine deadline, faces recruiting cri-\nsis\n2 This title is good as well. The topic of\nrecruiting crisis should be out before\nthe COVID vaccine deadline\nGuidance +\nSelection +\nPost-editing\nArmy National Guard Members\nRefuse Vaccine, Face Potential Expul-\nsion\n5 This is not the main subject of the ar-\nticle. Just a highlight in the article\nOriginal Deadline passes and 1 in 10 Army\nNational Guard soldiers still unvac-\ncinated for Covid. Will they be ex-\npelled?\n4 This title sums up the article but it\nneeds to be more concise. The sen-\ntence is too long.\nGPT only Army National Guard Faces Recruit-\ning Crisis Amid Covid Vaccine Dead-\nline\n1 Clear title - Contains subject and issue\nthat has arised.\nTable 4: Representative evaluation task, showing one (of 20) annotators evaluation of one (of 20) articles. Headlines\nare ranked from best (1) to worst (6).\nCondition / Time Duration (s) Reading Creating Total\nmean std mean std mean std\nManual only 1711 953 2248 1733 3959 1887\nSelection 2723 1503 644 313 3367 1417\nGuidance + Selection 1998 1581 838 379 2835 1634\nGuidance + Selection + Post-editing 1362 885 1961 1588 3324 1700\nH-value p-value H-value p-value H-value p-value\n4.2 0.24 13.0 0.005 1.9 0.59\nTable 5: Duration (in seconds) of reading time (the time spent on reading the news article), creating time (the time\nspent on generating the news headline), and total time. The differences were tested with Kruskal-Wallis H test.\nCondition / Difficulty Instance-level Overall\nmean std mean std\nManual only 30.9 17.1 1.9 1.0\nSelection 25.0 19.4 1.9 0.7\nGuidance + Selection 19.7 24.3 1.7 0.5\nGuidance + Selection + Post-editing 20.3 25.1 1.9 0.7\nH-value p-value H-value p-value\n4.0 0.26 0.4 0.94\nTable 6: Participants self-reported instance-level task difficulty rating (average across all instances, from 0 to 100)\nand overall task difficulty rating (Likert-scale, from 1 to 5) for four conditions. In both cases, higher scores means\nmore difficult.\n3334\nStatements Manual Selection Guidance Guidance H-value p-value\nonly Selection Selection\nPost-editing\n[Control] I could influence\nthe final headlines for the\nnews articles.\n3.8 (0.7) 3.4 (1.3) 3.9 (0.7) 3.9 (1.2) 1.6 0.66\n[Trust] I trusted that the\nsystem would help me create\nhigh-quality headlines.\n3.9 (1.1) 3.6 (0.7) 3.6 (0.5) 3.7 (0.8) 0.8 0.85\nTable 7: Means, standard deviation (in parenthesis) and Kruskal-Wallis H test results of users’ level of agreement to\nstatements of participants’ control and trust on a Likert scale of 1 (Strongly Disagree) to 5 (Strongly Agree) for\nCondition 0, 1, 2 and 3. No significant difference was observed for control or trust among the four study conditions.\nG Interfaces for human study\nThe screenshots of the interfaces for the human\nstudy were attached below. All the practice rounds\nand human studies shared the same interfaces and\ninteractions. We took the first round of practice\nas an example to demonstrate the interfaces for\nfour AI-assisted conditions: Manual only, Selec-\ntion, Guidance + Selection, and Guidance + Selec-\ntion + Post-editing.\n3335\nFigure G1: General task instruction for participants.\nFigure G2: Instructions on how to generate high quality news headlines for participants.\n3336\nFigure G3: Interface for news article reading (same for all conditions).\nFigure G4: Interface for Manual only condition of news headline generation.\n3337\nFigure G5: Interface for Selection condition of news headline generation.\nFigure G6: Interface for Guidance + Selection condition of news headline generation.\n3338\nFigure G7: Interface for Guidance + Selection + Post-editing condition of news headline generation.\nFigure G8: Interface of the post-study survey.\n3339",
  "topic": "Headline",
  "concepts": [
    {
      "name": "Headline",
      "score": 0.972638726234436
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.8193688988685608
    },
    {
      "name": "Harm",
      "score": 0.6263641119003296
    },
    {
      "name": "Feeling",
      "score": 0.5721004605293274
    },
    {
      "name": "Computer science",
      "score": 0.5704783201217651
    },
    {
      "name": "Perception",
      "score": 0.5451433658599854
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5077382326126099
    },
    {
      "name": "Control (management)",
      "score": 0.44051581621170044
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3843783140182495
    },
    {
      "name": "Human–computer interaction",
      "score": 0.35236304998397827
    },
    {
      "name": "Psychology",
      "score": 0.3038477897644043
    },
    {
      "name": "Social psychology",
      "score": 0.2481834888458252
    },
    {
      "name": "Advertising",
      "score": 0.21840941905975342
    },
    {
      "name": "Business",
      "score": 0.2025790810585022
    },
    {
      "name": "History",
      "score": 0.12164917588233948
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I66946132",
      "name": "University of Maryland, College Park",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4401726866",
      "name": "Dataminr (United States)",
      "country": null
    }
  ],
  "cited_by": 15
}