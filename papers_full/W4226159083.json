{
  "title": "Chemformer: a pre-trained transformer for computational chemistry",
  "url": "https://openalex.org/W4226159083",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2317361088",
      "name": "Ross Irwin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2146233909",
      "name": "Spyridon Dimitriadis",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2108660797",
      "name": "Jiazhen He",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2972792757",
      "name": "Esben Jannik Bjerrum",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W6683258052",
    "https://openalex.org/W2947423323",
    "https://openalex.org/W3088265803",
    "https://openalex.org/W3100358278",
    "https://openalex.org/W3154464317",
    "https://openalex.org/W1975147762",
    "https://openalex.org/W6786619936",
    "https://openalex.org/W6784526300",
    "https://openalex.org/W3114291043",
    "https://openalex.org/W3157265962",
    "https://openalex.org/W6774009640",
    "https://openalex.org/W6796905988",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6769311223",
    "https://openalex.org/W6762122294",
    "https://openalex.org/W6769627184",
    "https://openalex.org/W3027819927",
    "https://openalex.org/W6784313401",
    "https://openalex.org/W3038856956",
    "https://openalex.org/W3160706794",
    "https://openalex.org/W3117879109",
    "https://openalex.org/W3088999551",
    "https://openalex.org/W3032781902",
    "https://openalex.org/W3030978062",
    "https://openalex.org/W1757990252",
    "https://openalex.org/W2886791556",
    "https://openalex.org/W6736161267",
    "https://openalex.org/W6744596635",
    "https://openalex.org/W2325811289",
    "https://openalex.org/W2551217916",
    "https://openalex.org/W2900090807",
    "https://openalex.org/W3025593963",
    "https://openalex.org/W6803196593",
    "https://openalex.org/W6739365718",
    "https://openalex.org/W2594183968",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W3030970797",
    "https://openalex.org/W6766978945",
    "https://openalex.org/W6780226713",
    "https://openalex.org/W6755977528",
    "https://openalex.org/W2963587345",
    "https://openalex.org/W6631190155",
    "https://openalex.org/W4254658870",
    "https://openalex.org/W2966357564",
    "https://openalex.org/W2994678679",
    "https://openalex.org/W3119022334",
    "https://openalex.org/W6780104034",
    "https://openalex.org/W6766867396",
    "https://openalex.org/W6779235351",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W2624871570",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2899663614",
    "https://openalex.org/W2604296437",
    "https://openalex.org/W3007488165",
    "https://openalex.org/W3171707284",
    "https://openalex.org/W3091477290",
    "https://openalex.org/W3103092523",
    "https://openalex.org/W3109892317",
    "https://openalex.org/W3093934881",
    "https://openalex.org/W3035172872",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3181403764",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2998367408",
    "https://openalex.org/W3094771832",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2945260553",
    "https://openalex.org/W4295312788",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4237622019",
    "https://openalex.org/W2753921001"
  ],
  "abstract": "Abstract Transformer models coupled with a simplified molecular line entry system (SMILES) have recently proven to be a powerful combination for solving challenges in cheminformatics. These models, however, are often developed specifically for a single application and can be very resource-intensive to train. In this work we present the Chemformer modelâ€”a Transformer-based model which can be quickly applied to both sequence-to-sequence and discriminative cheminformatics tasks. Additionally, we show that self-supervised pre-training can improve performance and significantly speed up convergence on downstream tasks. On direct synthesis and retrosynthesis prediction benchmark datasets we publish state-of-the-art results for top-1 accuracy. We also improve on existing approaches for a molecular optimisation task and show that Chemformer can optimise on multiple discriminative tasks simultaneously. Models, datasets and code will be made available after publication.",
  "full_text": null,
  "topic": "Cheminformatics",
  "concepts": [
    {
      "name": "Cheminformatics",
      "score": 0.834010660648346
    },
    {
      "name": "Discriminative model",
      "score": 0.764359712600708
    },
    {
      "name": "Computer science",
      "score": 0.753429114818573
    },
    {
      "name": "Transformer",
      "score": 0.716396152973175
    },
    {
      "name": "Machine learning",
      "score": 0.6405051946640015
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.587688684463501
    },
    {
      "name": "Artificial intelligence",
      "score": 0.510973334312439
    },
    {
      "name": "Data mining",
      "score": 0.3217654824256897
    },
    {
      "name": "Engineering",
      "score": 0.14699241518974304
    },
    {
      "name": "Bioinformatics",
      "score": 0.13335126638412476
    },
    {
      "name": "Voltage",
      "score": 0.0848066508769989
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    }
  ]
}