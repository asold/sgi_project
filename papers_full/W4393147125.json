{
  "title": "PMET: Precise Model Editing in a Transformer",
  "url": "https://openalex.org/W4393147125",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2099355801",
      "name": "Xiaopeng Li",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2119574722",
      "name": "Shasha Li",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3199481046",
      "name": "Shezheng Song",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2083709059",
      "name": "Jing Yang",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2102675153",
      "name": "Jun Ma",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2106025812",
      "name": "Jie Yu",
      "affiliations": [
        "National University of Defense Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2099355801",
      "name": "Xiaopeng Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2119574722",
      "name": "Shasha Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3199481046",
      "name": "Shezheng Song",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2083709059",
      "name": "Jing Yang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102675153",
      "name": "Jun Ma",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2106025812",
      "name": "Jie Yu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4224051134",
    "https://openalex.org/W3171331476",
    "https://openalex.org/W3154575616",
    "https://openalex.org/W4221166192",
    "https://openalex.org/W3117576675",
    "https://openalex.org/W3020482686",
    "https://openalex.org/W3079786700",
    "https://openalex.org/W6810242208",
    "https://openalex.org/W6767535143",
    "https://openalex.org/W2624677889",
    "https://openalex.org/W4309798086",
    "https://openalex.org/W4384659456",
    "https://openalex.org/W6839328737",
    "https://openalex.org/W6802629465",
    "https://openalex.org/W2131099349",
    "https://openalex.org/W4205460703",
    "https://openalex.org/W4389518797",
    "https://openalex.org/W4380303532",
    "https://openalex.org/W4386044411",
    "https://openalex.org/W2962881743",
    "https://openalex.org/W4319050003",
    "https://openalex.org/W4385574383",
    "https://openalex.org/W3173787059",
    "https://openalex.org/W4286897388",
    "https://openalex.org/W2970120757",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W4206118214",
    "https://openalex.org/W3173673636",
    "https://openalex.org/W4281657280",
    "https://openalex.org/W4306313145",
    "https://openalex.org/W4389520380",
    "https://openalex.org/W4287820586",
    "https://openalex.org/W4308023630",
    "https://openalex.org/W4282980384",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W4285225959",
    "https://openalex.org/W2996514524",
    "https://openalex.org/W4394743141",
    "https://openalex.org/W4362598605",
    "https://openalex.org/W4389520370",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4385572928",
    "https://openalex.org/W3107969673",
    "https://openalex.org/W3146844750"
  ],
  "abstract": "Model editing techniques modify a minor proportion of knowledge in Large Language Models (LLMs) at a relatively low cost, which have demonstrated notable success. Existing methods assume Transformer Layer (TL) hidden states are values of key-value memories of the Feed-Forward Network (FFN). They usually optimize the TL hidden states to memorize target knowledge and use it to update the weights of the FFN in LLMs. However, the information flow of TL hidden states comes from three parts: Multi-Head Self-Attention (MHSA), FFN, and residual connections. Existing methods neglect the fact that the TL hidden states contains information not specifically required for FFN. Consequently, the performance of model editing decreases. To achieve more precise model editing, we analyze hidden states of MHSA and FFN, finding that MHSA encodes certain general knowledge extraction patterns. This implies that MHSA weights do not require updating when new knowledge is introduced. Based on above findings, we introduce PMET, which simultaneously optimizes Transformer Component (TC, namely MHSA and FFN) hidden states, while only using the optimized TC hidden states of FFN to precisely update FFN weights. Our experiments demonstrate that PMET exhibits state-of-the-art performance on both the \\textsc{counterfact} and zsRE datasets. Our ablation experiments substantiate the effectiveness of our enhancements, further reinforcing the finding that the MHSA encodes certain general knowledge extraction patterns and indicating its storage of a small amount of factual knowledge. Our code is available at \\url{https://github.com/xpq-tech/PMET}.",
  "full_text": "PMET: Precise Model Editing in a Transformer\nXiaopeng Li, Shasha Li*, Shezheng Song, Jing Yang, Jun Ma, Jie Yu∗\nNational University of Defense Technology\nChangsha, Hunan 410073 China\nxiaopeng.lyy@gmail.com, {shashali, ssz614, yj, majun}@nudt.edu.cn, yangjing2036@126.com\nAbstract\nModel editing techniques modify a minor proportion of\nknowledge in Large Language Models (LLMs) at a relatively\nlow cost, which have demonstrated notable success. Existing\nmethods assume Transformer Layer (TL) hidden states are\nvalues of key-value memories of the Feed-Forward Network\n(FFN). They usually optimize the TL hidden states to mem-\norize target knowledge and use it to update the weights of\nthe FFN in LLMs. However, the information flow of TL hid-\nden states comes from three parts: Multi-Head Self-Attention\n(MHSA), FFN, and residual connections. Existing methods\nneglect the fact that the TL hidden states contains information\nnot specifically required for FFN. Consequently, the perfor-\nmance of model editing decreases. To achieve more precise\nmodel editing, we analyze hidden states of MHSA and FFN,\nfinding that MHSA encodes certain general knowledge ex-\ntraction patterns. This implies that MHSA weights do not re-\nquire updating when new knowledge is introduced. Based on\nabove findings, we introduce PMET, which simultaneously\noptimizes Transformer Component (TC, namely MHSA and\nFFN) hidden states, while only using the optimized TC hid-\nden states of FFN to precisely update FFN weights. Our ex-\nperiments demonstrate that PMET exhibits state-of-the-art\nperformance on both the COUNTERFACT and zsRE datasets.\nOur ablation experiments substantiate the effectiveness of our\nenhancements, further reinforcing the finding that the MHSA\nencodes certain general knowledge extraction patterns and in-\ndicating its storage of a small amount of factual knowledge.\nOur code is available at https://github.com/xpq-tech/PMET.\nIntroduction\nLarge language models (LLMs), as an emerging form of\nknowledge base (Petroni et al. 2019; Heinzerling and Inui\n2021; Cao et al. 2021), are extensively employed world-\nwide, primarily addressing queries through knowledge re-\ncall. Nonetheless, these models are often criticized for fur-\nnishing erroneous information (Ji et al. 2023; Zhao et al.\n2023). The cost of fine-tuning or training from scratch to\ncorrect the minor proportion of erroneous knowledge is fre-\nquently deemed impractical. Fortunately, recent model edit-\ning techniques have demonstrated the ability to modify mi-\nnor proportion of knowledge in LLMs with relatively low\n*Corresponding Author.\nCopyright © 2024, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\ncost (Meng et al. 2022b; Mitchell et al. 2022a; Yao et al.\n2023). Model editing aims to modify the internal knowledge\nof LLMs without resorting to vanilla training or fine-tuning.\nThe success rates of model editing in edited-knowledge and\nin knowledge related to the edited-knowledge are assessed\nseparately based on efficacy and generalization, while the\npreservation of irrelevant edited-knowledge is measured by\nspecificity (also known as locality) (Mitchell et al. 2022a).\nFor the purpose of uniformity, we collectively refer to ef-\nficacy and generalization as reliability. Additionally, two\nmetrics are employed to evaluate the generative capacity\nof the post-edited model: fluency and consistency (Meng\net al. 2022a). Model editing methods can be classified into\ntwo categories based on whether the original model weights\nare modified: weight-preserved and weight-modified meth-\nods (Yao et al. 2023). Weight-preserved methods often re-\nquire additional content, whereas weight-modified methods\ndirectly edit model weights without the need for extra con-\ntent, making them a more lightweight alternative.\nThe weight-modified approaches include learning-based\n(Mitchell et al. 2022a) and optimization-based methods\n(Meng et al. 2022b). Learning-based methods utilize gradi-\nent information to update the weights, but they suffer from\npoor knowledge generalization and are prone to overfitting.\nThe optimization-based method ROME (Meng et al. 2022a)\nalleviates this by solving a optimization problem and up-\ndates FFN weights incrementally. The subsequent MEMIT\n(Meng et al. 2022b) further improves ROME, enabling mass\nediting in a single operation and demonstrating impressive\nediting performance. In detail, ROME and MEMIT view\nFFN as key-value memories (Geva et al. 2021), where the\nhidden states before and after passing through FFN weight\nW can be considered as keys k and values v, satisfying\nW k= v. ROME and MEMIT extract TC (Transformer\nComponent, namely MHSA and FFN) hidden states as keys\nand optimizes TL (Transformer Layer) hidden states as val-\nues, ultimately obtaining the desired weights by solving\na least square problem. However, the information flow of\nTL hidden states comes from three parts: Multi-Head Self-\nAttention (MHSA), FFN, and residual connections. Both\nROME and MEMIT uses optimized TL hidden states as the\nvalues (i.e., target knowledge representations) for updating\nFFN weights, which overlooks the irrelevant information\nwithin the TL hidden states that is not required by FFN,\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18564\nMHSA \nEditing Algorithm\nOptimized TL\nhidden states\nIncremental weight \n(a) Previous optimization-based method.\nMHSA \nIncremental weight Editing Algorithm\nOptimized TC\nhidden states (b) PEMT method.\nWeight &\n Hidden States WeightTL Hidden\n States\nSum of Two\nHidden States\nOptimizable\nHidden States\nUpdated InformationTC Hidden\n States\nFigure 1: Comparison between PMET and existing methods in a Transformer layer. (a) Existing optimization-based methods\nemploy optimized TL hidden states to perform vague updates on FFN weights. (b) PMET simultaneously optimizes the TC\nhidden states of both MHSA and FFN, but only uses the optimized TC hidden states of FFN to perform precise updates on FFN\nweights.\nresulting in imprecise updating of weights based on non-\naccurate target knowledge representations and compromis-\ning editing performance. To address this issue, we suggest\noptimizing the TC hidden states directly of FFN to memo-\nrize target knowledge for precise updates on FFN weights.\nBut unexpectedly, during the practical process of directly\noptimizing the TC hidden states of FFN, we encounter occa-\nsional optimization bottlenecks where the TC hidden states\ncan not be aligned with target knowledge. We attribute this\nphenomenon to the limitations imposed by the parameter\nspace of the TC hidden states of FFN. A plausible solution to\naddress this is the supplementary optimization of TC hidden\nstates within MHSA. However, this introduces a novel in-\nquiry: whether MHSA, like FFN, possesses the capability to\nstore factual knowledge (Geva et al. 2021), necessitating up-\ndates to its weights. In pursuit of this inquiry, we endeavor\nto analyze hidden states of MHSA and FFN to determine\nthe role of MHSA in LLMs’ knowledge recall. We then ob-\nserve that the knowledge contained within MHSA undergoes\nmore frequent changes compared to that within FFN. Com-\nbining previous findings of MHSA (Geva et al. 2023; Wang\net al. 2022; Hassid et al. 2022) with our observation, we be-\nlieve that MHSA works as a knowledge extractor and stores\ncertain general knowledge extraction patterns. This suggests\nthe potential for supplementary optimization of TC hidden\nstates of the MHSA to expand the function space, without\nnecessitating updates to its weights.\nBased on the above finding, we propose PMET, which\nsimultaneously optimizes TC hidden states of MHSA and\nFFN, utilizing solely the optimized TC hidden states of\nFFN as the target knowledge representations for updating\nFFN weights, enabling precise updates. The differences be-\ntween PMET and existing methods are illustrated in Fig-\nure 1. Our experiments demonstrate that PMET exhibits\nstate-of-the-art comprehensive performance in editing GPT-\nJ (6B) (Wang and Komatsuzaki 2021) and GPT-NeoX (20B)\n(Black et al. 2022) on the zsRE andCOUNTERFACT datasets.\nSpecifically, in COUNTERFACT dataset, PMET shows a\n3.3% average reliability enhancement over the state-of-the-\nart method, while in zsRE dataset, it achieves a 0.4% aver-\nage improvement. Furthermore, our series of ablation exper-\niments demonstrate that our enhancements are effective and\nPMET strikes a good balance among reliability, specificity,\nfluency, and consistency. To sum up, our main contributions\nare as follows:\n• We reveal that the MHSA works as a knowledge extrac-\ntor, encodes certain general knowledge extraction pat-\nterns, and stores a small amount of factual knowledge.\n• We propose PMET, which leverages the general knowl-\nedge extraction patterns of MHSA and simultaneously\noptimizes the TC hidden states of MHSA and FFN\nto memorize target knowledge. However, PMET only\nuses the optimized TC hidden states of FFN to update\nFFN weights due to the unnecessary updates to MHSA\nweights.\n• Our experiments with GPT-J (6B) on the zsRE and coun-\nterfact datasets highlight PMET’s superiority across mul-\ntiple dimensions. Additionally, editing GPT-NeoX (20B)\non the COUNTERFACT dataset underscores PMET’s su-\nperior reliability and consistency over exsiting methods.\nRelated Work\nModel Editing\nModel editing is an emerging field in recent years,\nmainly aimed at mitigating the high cost of model train-\ning. Model editing methods can be classified into two\ncategories: weight-modified and weight-preserved(Mitchell\net al. 2022b; Zheng et al. 2023; Hernandez, Li, and An-\ndreas 2023). Weight-preserved methods typically achieve\nthis preservation by introducing external models (Mitchell\net al. 2022b), utilizing in-context learning (Zheng et al.\n2023), or altering the LLMs’ representation space (Her-\nnandez, Li, and Andreas 2023). These approaches effec-\ntively safeguard non-target knowledge while modifying the\ntarget knowledge. However, as the number of knowledge\nmodifications increases, the required additional content also\ngrows substantially. In contrast, weight-modified methods\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18565\n(Sinitsin et al. 2020; Mitchell et al. 2022a; Meng et al.\n2022b,a) directly modify the model weights for editing,\nthereby avoiding the aforementioned content increasing is-\nsue. Initially, weight-modified methods use approaches like\nmulti-loss fine-tune (Sinitsin et al. 2020) and constrained\nfine-tune (Zhu et al. 2020). Yet these methods often suf-\nfer from overfitting. To address this issue, researchers later\nproposed meta-learning methods (De Cao, Aziz, and Titov\n2021; Mitchell et al. 2022a) and optimization-based meth-\nods (Meng et al. 2022a). Nevertheless, as the number of\nedited-knowledge increases, the efficacy and generalization\nof these methods deteriorate significantly. This challenge is\ntackled by MEMIT (Meng et al. 2022b), which further im-\nproves ROME and enable edit a large amount of knowl-\nedge in one go. The optimization-based methods are built\nupon the conclusion that FFN are key-value memories (Geva\net al. 2021) and update FFN weights by optimizing the TL\nhidden states to memorize target knowledge. While these\nmethods have achieved some success in model editing, they\nconfuse the information flow among the MHSA, FFN, and\nresidual connections, leading to a non-accurate updates on\nFFN weights. In contrast to these methods, PMET simulta-\nneously optimizes the TC hidden states of MHSA and FFN\nto memorize target knowledge, while only use the optimized\nTC hidden states of FFN, facilitating precise updates of FFN\nweights.\nPost-Hoc Explanation of Transformers\nPost-hoc explanation is a broad field, and our focus is on un-\nderstanding the roles of the two components, MHSA and\nFFN, in Transformers (Kovaleva et al. 2019; Wang et al.\n2022; Hassid et al. 2022; Geva et al. 2022; Kobayashi et al.\n2023; Hao et al. 2021; Geva et al. 2023). Currently, it is\nwidely believed that FFN serves as the main carrier for\nstoring factual knowledge(Geva et al. 2021; Meng et al.\n2022a,b), and each layer of FFN contributes to knowledge\nrecall(Geva et al. 2022, 2023). MHSA is primarily respon-\nsible for capturing the degree of association between differ-\nent tokens, focusing on interactions between content (Hao\net al. 2021; Kobayashi et al. 2023), and extracting attributes\nof subjects (Geva et al. 2023). Other studies have shown\nthat MHSA contains different levels of redundant informa-\ntion (Wang et al. 2022; Hassid et al. 2022). These findings\nimply that MHSA may store certain general patterns used\nfor knowledge extraction. However, they do not completely\nclarify this and fail to provide insights into whether MHSA\nstores factual knowledge. We endeavor to analyze the hidden\nstates of MHSA and FFN to explore these.\nMethodology\nPreliminaries\nLanguage Modeling We focus on autoregressive,\ndecoder-only LLMs denoted as Fθ. These models transform\nthe input sequence x into z tokens x1, ..., xz and then input\nthem into L layers of Transformer decoders to obtain the\nprobabilities of the next token xz+1 as follows:\nFθ(x1, ..., xz) = softmax\n\u0010\nWEγ\n\u0010\nhL−1\nz + aL\nz + mL\nz\n\u0011\u0011\n= P (xz+1|x1, ..., xz)\n(1)\nHere, WE and γ represent the embedding matrix and layer-\nnorm, respectively, and aL\nz and mL\nz are the TC hidden states\nof the MHSA and FFN of the L-th layer, respectively. Note\nthat the MHSA and FFN in (1) are parallel (Wang and Ko-\nmatsuzaki 2021; Black et al. 2022). The general forms of the\nMHSA and FFN at the l-th layer and the j-th token xl\nj are\ngiven by:\nal\nj = Wl\nOMHSA MHSAl\n\u0010\nγ\n\u0010\nhl−1\n1 , hl−1\n2 , ..., hl−1\nj\n\u0011\u0011\n,\nml\nj = Wl\nOFFN σ\n\u0010\nWl\nIγ\n\u0010\nhl−1\nj\n\u0011\u0011 (2)\nHere, Wl\nOMHSA and Wl\nOFFN are the output weights of the\nMHSA and FFN at the l-th layer, respectively, and σ rep-\nresents the non-linear activation function. We have omitted\nbias terms for simplicity.\nModel Editing Problem Previous researches on model\nediting have been limited to defining the problem solely\nbased on editing the triples (i.e., subject-relation-object)\nthemselves (Meng et al. 2022a; Mitchell et al. 2022b), over-\nlooking the knowledge contained within the triples. Conse-\nquently, the edited models are unable to reason based on the\nedited knowledge (Cohen et al. 2023). In this paper, we re-\ndefine the model editing problem from a subject-centric per-\nspective, where the edited knowledge is associated with the\nsubject, aiming to enable the edited models to reason based\non the subject.\nLet Fθ be an LLM that has learned N pieces of knowl-\nedge related to subject S, represented by the set:\nKS =\n\b\b\nxS\ni , yS\ni\n\t\n, i∈ {0,1, 2, ..., N}\n\t\n(3)\nHere, xS\ni and yS\ni represent the knowledge clue sequence\nand the knowledge point sequence, respectively, for the i-th\npiece of knowledge. For example, for subject ‘Shakespeare,’\na knowledge clue about the subject could be: “Shakespeare\nis a,” and the knowledge point about the knowledge clue is\n“playwright.” The LLM Fθ satisfies: Fθ\n\u0000\nxS\ni\n\u0001\n= yS\ni , ∀i ∈\n{0, 1, 2, ..., N}. The objective of model editing is to modify\nN′ pieces of knowledge in the LLM related to subject S to\nthe target knowledge:\nKSt =\nnn\nxSt\ni , ySt\ni\no\n, i∈ {0,1, 2, ..., N′}\no\n(4)\nwhile keeping the M(M ≫ N) pieces of knowledge in the\nset\nK¬St =\nnn\nx¬St\nj , y¬St\nj\no\n, j∈ {0,1, 2, ..., M}\no\n(5)\nthat are unrelated to the N′ pieces of model learned knowl-\nedge. Hence, the edited LLM Fθ∗ should satisfy:\nFθ∗\n\u0010\nxSt\ni\n\u0011\n= ySt\ni ∧ Fθ∗\n\u0010\nx¬St\nj\n\u0011\n= y¬St\nj ,\n∀i ∈ {0,1, 2, ..., N′}, j∈ {0,1, 2, ..., M}.\n(6)\nThe evaluation metrics for model editing can be found in\nAppendix B (Appendix will be found in (Li et al. 2023)).\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18566\nInvestigating the Role of MHSA and FFN in\nLLMs’ Knowledge Recall\nInspired by Geva et al. (Geva et al. 2023), who analyzed\ncritical subject information by mapping intermediate topic\nrepresentations to vocabulary tokens, we compare the dif-\nferences of hidden states hl−1\nz and al\nz of the last token be-\nfore and after (i.e., input and output) flowing through the\nl-th layer MHSA, both in the vector space and the vocabu-\nlary space. Similarly, we perform the same analysis on the\nhidden states hl−1\nz and ml\nz of the last token before and after\nflowing through the l-th layer FFN.\nWe use 1209 factual statements from (Meng et al. 2022a)\nas knowledge queries to explore the knowledge contained\nwithin GPT-J (6B). The last token position of each query\naggregates the information of the entire query; thus, we con-\nsider the hidden state of the last token of each query as a\nrepresentation of the key knowledge related to that query\nfrom the LLMs. We hypothesis a positive correlation be-\ntween the similarity of hidden states and the consistency of\nknowledge (Liang et al. 2020). To measure the similarity, we\ncalculate the cosine similarity of hidden states and the Jac-\ncard similarity (Murphy 1996) of the mapping to vocabulary\ntokens. Specifically, we extract the hidden states of the last\ntoken before and after each layer of MHSA and FFN, com-\npute their cosine similarity, and obtain the top-k tokens in\nthe vocabulary. Subsequently, we calculate the Jaccard simi-\nlarity between the top-k tokens of the intermediate states be-\nfore and after the process. The Jaccard similarity is defined\nas follows:\nJk (T (h1) , T(h2)) = |T (h1) ∩ T (h2)|\n|T (h1) ∪ T (h2)| (7)\nwhere T(h1) and T(h2) represent the top-k mappings of the\nhidden states h1 and h2 on the vocabulary, respectively. We\nset k = 50 in our experiments.\nThe average changes in cosine and Jaccard similarities of\nthe last tokens from 1209 factual statements across all layers\nand components of GPT-J are shown in Figure 2. In the first\n15 layers of GPT-J, both the MHSA and FFN exhibit rela-\ntively frequent changes in their hidden states. However, after\nthe 15th layer, the intermediate states of the FFN undergo a\nslower rate of change, gradually stabilizing in a specific di-\nrection. While the hidden states of the MHSA continue to\nundergo frequent changes, and their directions remain un-\ncertain throughout the knowledge extraction of GPT-J.Con-\nsidering our hypothesis regarding the relationship between\nhidden states and knowledge, this phenomenon suggests that\nthe knowledge contained in FFN’s hidden states tends to\nbecome consistent after a certain period, while the knowl-\nedge contained in MHSA’s hidden states undergoes frequent\nchanges throughout knowledge recall of GPT-J. We attribute\nthis observation to the fact thatthe MHSA continuously ex-\ntracts various types of knowledge, while the FFN primar-\nily extracts its own knowledge (Geva et al. 2021; Meng\net al. 2022a). Furthermore, considering previous findings re-\ngarding the extraction of attributes from the MHSA with ob-\nserved redundancies (Geva et al. 2023; Wang et al. 2022;\nHassid et al. 2022), we believe that the MHSA works as a\nknowledge extractor and stores certain general knowledge\n0 5 10 15 20 25\nLayer\n0.2\n0.1\n0.0\n0.1\n0.2\nAverage Cosine Similarity\nAvg. Cos. Sim. - MHSA\nAvg. Cos. Sim. - FFN\n0 5 10 15 20 25\nLayer\n0.000\n0.001\n0.002\n0.003\n0.004\n0.005\n0.006Average Jaccard Similarity\nAvg. Jac. Sim. - MHSA\nAvg. Jac. Sim. - FFN\nFigure 2: The changes in the average cosine similarity and\naverage Jaccard similarity of the hidden states before and\nafter MHSA and FFN.\nextraction patterns. Thus we suggest that when introduc-\ning new knowledge, there is no need to update the MHSA\nweights.\nPMET Method\nPMET first computes the target knowledge representations\nin the last critical layers of FFN by simultaneously opti-\nmizing the TC hidden states of both MHSA and FFN. Sec-\nondly, PMET only updates FFN weights in the critical layers\nthrough target knowledge representations. Overall, PMET\noptimizes an objective function to obtain target weights\n(Meng et al. 2022b):\nW1 ≜ argmin\nW\n nX\ni=1\n∥W ki − vi∥2 +\nn+uX\ni=n+1\n∥W ki − vi∥2\n!\n.\n(8)\nHere, ki ≜ kl\ni and vi ≜ vl\ni represent the sets of\nkeys and values, respectively, encoding the subject-related\nknowledge in the l-th layer. Pn\ni=1 ∥W ki − vi∥2 indicates\nthat we want to retain n pieces of knowledge, whilePn+u\ni=n+1 ∥W ki − vi∥2 indicates that we want to modify\nu ≫ 1 pieces of knowledge. We represent the keys and val-\nues as matrices stacked horizontally: [k1 | k2 | ··· |kn] ≜\nK and [v1 | v2 | ··· |vn] ≜ V , and we consider the target\nweight W1 as the sum of the original weight W0 and the\nincremental weight ∆, i.e., W1 = W0 + ∆. Based on the\nderivation from MEMIT (Meng et al. 2022b), the formal ex-\npression for the incremental weight is:\n∆ = RKT\n1 (C0 + K1KT\n1 )−1, (9)\nwhere R ≜ V1 − W0K1 represents the residual between the\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18567\nvalues V1 (namely target knowledge representations) corre-\nsponding to the keys K1 of the target knowledge and the\nmodel original knowledge W0K1. C0 ≜ K0KT\n0 = λEk\n\u0002\nkkT \u0003\nis an estimate of the set of previously memorized keys ob-\ntained through sampling. Here, λ is a hyperparameter which\nbalances the degree of model modification and preservation.\nTo explain clearly, let’s consider modifying theN′ knowl-\nedge instances KS related to the subject S in LLMs to the\ntarget knowledge KSt. Assuming that the set of previously\nmemorized keys C0 has already been obtained through sam-\npling, and knowledge clues xS\ni have been inputed into the\noriginal model to obtain W0K1, we then need the sets of\nkeys and values for the target knowledge, denoted as K1\nand V1, respectively. Similar to MEMIT, we calculate the\ntarget knowledge set of the last critical layer L = max(R).\nThroughout this paper, we mainly usehL\ni , mL\ni , aL\ni , and δi to\nrepresent the hidden states of the last tokens of the subjectS\nin the knowledge clues xS\ni .\nUnlike ROME and MEMIT, which add optimizable pa-\nrameters δi to the TL hidden states hL\ni at the L-th layer (as\nshown in Figure 1 (a)) and obtain the optimized TL hidden\nstates vi = hL\ni + δi through gradient descent, PMET adds\noptimizable parameters δa\ni and δm\ni to the TC hidden states\naL\ni and mL\ni of the components (i.e., MHSA and FFN) at the\nL-th layer, respectively. Then, PMET only retains the op-\ntimized TC hidden states of FFN to update FFN weights,\ndenoted as vm\ni = mL\ni + δm\ni = argmin\nvm\ni\nL(vm\ni ) (as shown in\nFigure 1 (b)). L(vm\ni ) is defined as follows:\nL(vm\ni ) = µ ∗ DKL\n\u0010\nPF†\nθ\n\u0002\ny | p′\u0003\n∥PFθ\n\u0002\ny | p′\u0003\u0011\n+\nφ ∗ 1\nP\nPX\nj=1\n−log PF†\nθ\nh\nySt\ni | prefj ⊕ p(xi)\ni\n,\n(10)\nwhere φ and µ are hyperparameters used to balance reli-\nability and specificity. F†\nθ ≜ Fθ\n\u0000\naL\ni + = δa\ni , mL\ni + = δm\ni\n\u0001\nrepresents the optimizable parameters δa\ni and δm\ni are added\nto the TC hidden states of MHSA and FFN at the L-th layer\nof the model Fθ, respectively. prefj ⊕ p(xi) and p′ are, as\nin (Meng et al. 2022a,b), prefixes used to enhance the gen-\neralization of the target knowledge and the prompt template\nused for calculating the KL divergence: ‘{S} is a’. After cal-\nculating the values of all the target knowledge that need to\nbe changed, they can be stacked into a matrix V1.\nTo edit multiple layers of the model, we need to spread\nthe residual R to all critical layers. MEMIT spreads updates\nevenly over the range of critical layersR as Rl = V1−W0K1\nL−l+1 .\nIn contrast, PMET adopts a square root spread to convey\nmore precise information to critical layers:\nRl = V1 − W0K1√\nL − l + 1 . (11)\nNow that we have C0 and Rl, the next step is to obtain\nkeys K1. Keys are related to specific weights to be edited\nand represent the hidden states before entering those specific\nweights. Similar to (Meng et al. 2022a,b), the keys kl\ni at the\nl-th layer are defined as follows:\nkl\ni = 1\nP\nPX\nj=1\nprev(W,prefj ⊕ S), (12)\nwhere prev(W,prefj ⊕ S) represents the hidden state of the\ninput prefj ⊕ S before flowing through the weight W. If\none wants to edit Wl\nOFFN in (2), then prev(Wl\nOFFN , x) =\nσ\n\u0000\nWl\nIγ\n\u0000\nhl−1\nj (x)\n\u0001\u0001\n.\nWith this, PMET follows the same algorithm steps as\nMEMIT to update FFN weights.\nExperiments\nBaselines and Datasets\nOur experiments are conducted on GPT-J (6B) and GPT-\nNeoX (20B). Our baseline methods include the improved\nConstrained Fine-Tuning (FT+W) (Zhu et al. 2020; Meng\net al. 2022b), the learning-based method MEND (Mitchell\net al. 2022a), and the optimization-based methods ROME\n(Meng et al. 2022a) and MEMIT (Meng et al. 2022b).\nFor the datasets, we performed counterfactual update ex-\nperiments on two datasets: Zero-Shot Relation Extraction\n(zsRE) (Levy et al. 2017) and C OUNTER FACT (Meng et al.\n2022a). More details about datasets can be found in Ap-\npendix C.\nEditing Experiments\nThe score is the harmonic mean of efficacy, generalization,\nand specificity, representing the balance between reliabil-\nity (i.e., efficacy and generalization) and specificity of the\nediting method(Meng et al. 2022a). Note that in our exper-\niments, we updates counterfactual information, so we eval-\nuated specificity based on factual information, while when\ntesting for efficacy and generalization, we used counterfac-\ntual information as the standard. As a result, the unedited\nLLMs performed poorly in terms of efficacy and generaliza-\ntion but exhibited good performance in terms of specificity.\nImplementation details are presented in Appendix D.\nEditing Knowledge in Counterfact As mentioned in\n(Meng et al. 2022a), we also conducted 17 counter-\nfactual experiments by sampling 17 integers ni =\nexp\n\u0000\nln (10000)∗ i\n16\n\u0001\nfrom a log-scale curve for editing. The\nperformance of PMET and other existing methods on GPT-J\n(6B) in these 17 edits is shown in Figure 3. With the excep-\ntion of being slightly inferior to MEMIT in terms of speci-\nficity, PMET outperforms all baselines in all other metrics.\nTable 1 shows the results of all methods on 10K counter-\nfactual edits. The results show that PMET outperforms ex-\nisting methods in score, efficacy, fluency, and consistency,\nbut is slightly inferior to MEMIT in specificity, and like\nMEMIT, it is far behind the meta-learning based method\nMEND. In the trade-off between editing reliability and\nspecificity, both PMET and MEMIT tend to prioritize reli-\nability, while MEND leans towards specificity. While sacri-\nficing some specificity for improved reliability is acceptable\nuntil better methods are available, we hope to find a compro-\nmise in the future.\nThen, we applied PMET to conduct 10K edits on GPT-\nNeoX (20B) on the COUNTERFACT dataset, and the results\nare shown in the lower part of Table 1. Similarly, PMET out-\nperforms MEMIT in terms of reliability and consistency, but\nlags behind in specificity. These might be because PMET\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18568\nEditor Score Efficacy Generalization Specificity Fluency Consistency\nGPT-J (6B) 22.4 15.2 (0.7) 17.7 (0.6) 83.5 (0.5) 622.4 (0.3) 29.4 (0.2)\nFT-W 67.6 99.4 (0.1) 77.0 (0.7) 46.9 (0.6) 293.9 (2.4) 15.9 (0.3)\nMEND 23.1 15.7 (0.7) 18.5 (0.7) 83.0 (0.5) 618.4 (0.3) 31.1 (0.2)\nROME 50.3 50.2 (1.0) 50.4 (0.8) 50.2 (0.6) 589.6 (0.5) 3.3 (0.0)\nMEMIT 85.8 98.9 (0.2) 88.6 (0.5) 73.7 (0.5) 619.9 (0.3) 40.1 (0.2)\nPMET 86.2 99. 5 (0.1) 92.8 (0.4) 71.4 (0.5) 620.0 (0.3) 40.6 (0.2)\nGPT-NeoX (20B) 23.7 16.8 (1.9) 18.3 (1.7) 81.6 (1.3) 620.4 (0.6) 29.3 (0.5)\nMEMIT 82.0 97.2 (0.8) 82.2 (1.6) 70.8 (1.4) 606.4 (1.0) 36.9 (0.6)\nPMET 84.3 98. 4 (0.2) 89.4 (0.5) 70.3 (0.5) 598.1 (0.6) 38.9 (0.2)\nTable 1: 10,000 counterfact edits on GPT-J (6B) and GPT-NeoX (20B). Within parentheses is the 95% confidence interval.\n100 101 102 103 104\n0\n20\n40\n60\n80\n100\nScore ↑\n100 101 102 103 104\n0\n50\n100\nEfficacy ↑\n100 101 102 103 104\n0\n50\n100\nGeneralization↑\n100 101 102 103 104\n40\n60\n80\n Specificity↑\n100 101 102 103 104\n0\n10\n20\n30\n40\nConsistency↑\n100 101 102 103 104\n450\n500\n550\n600\nFluency↑\nROMEMENDOriginal GPT-J (6B) MEMITPMET\nFigure 3: The editing performance of PMET and baselines\nvaries with the number of edits (X-axis).\nemploys square root propagation (11), resulting in greater\nchanges to the model and hence more damage to specificity\n. We further investigate this in the following ablation exper-\niments. Nevertheless, these results demonstrate that PMET\nachieves the most significant updates to target knowledge\ncompared to existing methods.\nEditing 10K Knowledge in ZsRE The results of editing\n10K knowledge on the zsRE dataset are presented in Table\n2. The results demonstrate that PMET outperforms existing\nmethods in all three metrics: efficacy, generalization, and\nspecificity. It is worth noting that the original GPT-J (6B)\nmodel has a specificity score of only 27.0, and therefore, the\nspecificity of the edited models is also lower than this value.\nEditor Efficacy Generalization Specificity\nGPT-J 26.4 (±0.6) 25.8 (±0.5) 27.0 (±0.5)\nFT-W 69.6 (±0.6) 64.8 (±0.6) 24.1 (±0.5)\nMEND 19.4 (±0.5) 18.6 (±0.5) 22.4 (±0.5)\nROME 21.0 (±0.7) 19.6 (±0.7) 0.9 (±0.1)\nMEMIT 96.7 (±0.3) 89.7 (±0.5) 26.6 (±0.5)\nPMET 96.9(±0.3) 90.6 (±0.2) 26.7 (±0.2)\nTable 2: 10,000 zsRE Edits on GPT-J (6B).\nAblation Study\nWe conduct three sets of ablation experiments and demon-\nstrate that: 1) PMET simultaneously optimizing the TC hid-\nden states of MHSA and FFN can result in enhanced re-\nliability; 2) The updating of MHSA weights contributes\nmarginally to the improved generalization of editing while\nalso inflicting greater damage to specificity; and 3) square\nroot spreads in PMET enhances reliability but leads to larger\nchanges in the model, ultimately affecting specificity. All the\nablation experiments were conducted onCOUNTERFACT us-\ning GPT-J (6B), with parameters consistent with the previ-\nous experiments in COUNTERFACT .\nWe first conduct experiments where PMET only opti-\nmizes TC hidden states of FFN (i.e., δa\ni is removed) for\n1K, 5623, and 10K counterfactual edits. The experimental\nresults are shown in Table 3 under “w/o δa\ni ”. This shows\nthat simultaneously optimizing TC hidden states of FFN and\nMHSA can result in better reliability compared to only opti-\nmizing TC hidden states of FFN.\nNext, we update the weights of both MHSA and FFN\nusing the optimized TC hidden states. This means we up-\ndated Wl\nOMHSA and Wl\nOFFN simultaneously in (2), and addi-\ntionally computed the keys for (12) as prev(Wl\nOMHSA , x) =\nMHSAl \u0000\nhl−1\n1 (x) , hl−1\n2 (x) , ..., hl−1\nj (x)\n\u0001\n. The results are\nshown in Table 3 under “w/ Wl\nOMHSA ”. The results indicate\nthat additionally updating MHSA weights can slightly im-\nprove editing generalization, but at the same time, it wors-\nens the specificity. This might be due to the fact that MHSA\nweights store certain general knowledge extraction patterns\nalong with a small amount of factual knowledge. While up-\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18569\nEdits Editor Score Efficacy Generalization Specificity Fluency Consistency\nGPT-J 22.4 15.2 17.7 83.5 622.4 29.4\n1K\nPMET 91.1 99.8 96.1 80.1 622.2 41.7\nw/o δa\ni 90.8 (↓0.3) 99.6 (↓0.2) 96.6 (↑0.5) 79.1 (↓1.0) 622.4 (↑0.2) 42.2 (↑0.5)\nw/ Wl\nOMHSA 90.8 (↓0.3) 99.8 (→) 96.8 (↑0.7) 78.9 (↓1.2) 622.0 (↓0.2) 42.1 (↑0.4)\nEven spread 88.9 (↓2.2) 99.6 (↓0.2) 86.7 (↓9.9) 82.2 (↑ 3.1) 622.3 (↓0.1) 39.1 (↓3.1)\n5623\nPMET 88.0 99.7 94.5 74.2 621.7 41.3\nw/o δa\ni 87.0 (↓1.0) 99.3 (↓0.4) 95.0 (↑0.5) 72.0 (↓2.2) 622.3 (↑0.6) 41.6 (↑0.3)\nw/ Wl\nOMHSA 86.7 (↓1.3) 99.6 (↓0.1) 96.0 (↑1.5) 70.8 (↓3.4) 621.3 (↓0.4) 41.6 (↑0.3)\nEven spread 85.8 (↓2.2) 98.2 (↓1.5) 82.2 (↓12.3) 79.4 (↑5.2) 621.8 (↑0.1) 38.1 (↓3.2)\n10K\nPMET 86.2 99.5 92.8 71.4 620.0 40.6\nw/o δa\ni 85.0 (↓1.2) 98.9 (↓0.6) 89.0 (↓3.8) 71.6 (↑0.2) 621.2 (↑1.2) 40.0 (↓0.6)\nw/ Wl\nOMHSA 84.9 (↓1.3) 99.5 (→) 93.5 (↑0.7) 68.6 (↓2.8) 619.0 (↓1.0) 40.5 (↓0.1)\nEven spread 83.3 (↓2.9) 96.7 (↓2.8) 78.4(↓ 14.4) 77.3 (↑5.9) 621.8 (↑1.8) 37.4 (↓3.2)\nTable 3: The results of the ablation experiments. w/oδa\ni represents only optimizing the TC hidden state δm\ni of FFN. w/ Wl\nOMHSA\nrepresents simultaneously updating the weights of both MHSA and FFN. Even spread represents evenly spreading the residual\nR to the critical layers R.\ndating MHSA weights strengthens the extraction patterns of\nthe knowledge similar to edited-knowledge, it may also im-\npair the patterns of extracting other unrelated knowledge,\nmaking it more likely to harm specificity.\nFinally, we evenly spread the residual R to the critical\nlayers R, and the results are shown in Table 3 under “Even\nspread”. The results indicate that even spreading leads to\nbetter model retention (i.e., specificity and fluency), but effi-\ncacy, generalization, and consistency are much worse com-\npared to square root spreading. This suggests that using even\nspreading in PMET may cause significant loss of update in-\nformation, reducing the update reliability while preserving\nmore model’s original knowledge. While using square root\nspreading mitigates the loss of update information, improves\nreliability, but leads to larger changes in the model, causing\nmore side effects to the specificity and fluency.\nWe further analyze the relationship between the editing\nperformance and the norms of the incremental weight ∆ in\nAppendix A. In summary, PMET strikes a good balance be-\ntween reliability and specificity which becomes more pro-\nnounced as the number of edited knowledge increases.\nConclusion\nWe reveal that MHSA works as a knowledge extractor\nand encodes certain general knowledge extraction patterns.\nBased on this finding, we propose PMET, which simulta-\nneously optimizes the TC hidden states of both MHSA and\nFFN while only uses the optimized TC hidden states of FFN\nto perform precise updates of FFN weights. Our experiments\non zsRE and COUNTERFACT demonstrate the state-of-the-\nart performance of PMET. Furthermore, our ablation ex-\nperiments show that our enhancements are effective, PMET\nstrikes a good balance between different metrics, and MHSA\nstores a small amount of factual knowledge. Our findings\ncontribute additional insights for a better comprehension of\nthe roles played by MHSA and FFN, and our approach takes\na step forward in terms of model editing techniques.\nLimitations\nUnlike knowledge graphs that explicitly store information\nin symbolic form (Liang et al. 2023b,a), LLMs implicitly\nstore substantial knowledge in parameterized form. The par-\ntial opacity of LLMs’ internal mechanisms poses challenges\nfor direct weight modification in model editing. While ap-\nproaches like PMET and MEMIT have shown promising\nresults in some evaluations, their effectiveness does not\nnecessarily indicate true internalization of edited knowl-\nedge by LLMs. Consequently, models edited by PMET and\nMEMIT cannot reason using the edited knowledge (e.g.,\nafter editing the knowledge “The Prime Minister of the\nUK is {Theresa},” to “{Rishi Sunak}” the edited model\nmight generate statements like “The Prime Minister of Eng-\nland is {British}, not {Indian}”). Additionally, although this\npaper defines the problem of knowledge editing centered\naround subjects, benchmark and dataset construction have\nnot strictly adhered to this definition but instead have been\nadapted to existing evaluation methods. In the future, we aim\nto devise more sophisticated editing methods and evaluation\nmetrics (e.g., such as MQuAKE by Zhong et al. (2023) and\nRIPPLEEDITS by Cohen et al. (2023)) to advance model\nediting.\nEthical Statement\nThe original intention of our research into model editing\ntechniques is to rectify errors and outdated knowledge in\nLLMs, enabling them to better serve our needs. However,\nthese techniques also have the potential for misuse, allowing\nLLMs to generate false, toxic, and harmful content. There-\nfore, we emphasize the importance of not placing excessive\ntrust in the generated content until LLMs are well-regulated.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18570\nAcknowledgments\nThis work was partly supported by the Hunan Provincial\nNatural Science Foundation Projects (No.2022JJ30668 and\nNo. 2022JJ30046).\nReferences\nBlack, S.; Biderman, S.; Hallahan, E.; Anthony, Q.; Gao, L.;\nGolding, L.; He, H.; Leahy, C.; McDonell, K.; Phang, J.;\nPieler, M.; Prashanth, U. S.; Purohit, S.; Reynolds, L.; Tow,\nJ.; Wang, B.; and Weinbach, S. 2022. GPT-NeoX-20B: An\nOpen-Source Autoregressive Language Model. In Proceed-\nings of BigScience Episode #5 – Workshop on Challenges &\nPerspectives in Creating Large Language Models, 95–136.\nvirtual+Dublin: Association for Computational Linguistics.\nCao, B.; Lin, H.; Han, X.; Sun, L.; Yan, L.; Liao, M.; Xue,\nT.; and Xu, J. 2021. Knowledgeable or Educated Guess? Re-\nvisiting Language Models as Knowledge Bases. InProceed-\nings of the 59th Annual Meeting of the Association for Com-\nputational Linguistics and the 11th International Joint Con-\nference on Natural Language Processing (Volume 1: Long\nPapers), 1860–1874. Online: Association for Computational\nLinguistics.\nCohen, R.; Biran, E.; Yoran, O.; Globerson, A.; and Geva,\nM. 2023. Evaluating the Ripple Effects of Knowledge Edit-\ning in Language Models. arXiv preprint arXiv:2307.12976.\nDe Cao, N.; Aziz, W.; and Titov, I. 2021. Editing Fac-\ntual Knowledge in Language Models. In Proceedings of\nthe 2021 Conference on Empirical Methods in Natural Lan-\nguage Processing, 6491–6506. Online and Punta Cana, Do-\nminican Republic: Association for Computational Linguis-\ntics.\nGeva, M.; Bastings, J.; Filippova, K.; and Globerson, A.\n2023. Dissecting Recall of Factual Associations in Auto-\nRegressive Language Models. arXiv:2304.14767.\nGeva, M.; Caciularu, A.; Wang, K.; and Goldberg, Y . 2022.\nTransformer Feed-Forward Layers Build Predictions by Pro-\nmoting Concepts in the V ocabulary Space. In Proceedings\nof the 2022 Conference on Empirical Methods in Natural\nLanguage Processing, 30–45. Abu Dhabi, United Arab Emi-\nrates: Association for Computational Linguistics.\nGeva, M.; Schuster, R.; Berant, J.; and Levy, O. 2021. Trans-\nformer Feed-Forward Layers Are Key-Value Memories. In\nProceedings of the 2021 Conference on Empirical Methods\nin Natural Language Processing, 5484–5495. Online and\nPunta Cana, Dominican Republic: Association for Compu-\ntational Linguistics.\nHao, Y .; Dong, L.; Wei, F.; and Xu, K. 2021. Self-\nAttention Attribution: Interpreting Information Interactions\nInside Transformer. Proceedings of the AAAI Conference on\nArtificial Intelligence, 35(14): 12963–12971.\nHassid, M.; Peng, H.; Rotem, D.; Kasai, J.; Montero, I.;\nSmith, N. A.; and Schwartz, R. 2022. How much does at-\ntention actually attend? Questioning the Importance of At-\ntention in Pretrained Transformers. arXiv:2211.03495.\nHeinzerling, B.; and Inui, K. 2021. Language Models as\nKnowledge Bases: On Entity Representations, Storage Ca-\npacity, and Paraphrased Queries. In Proceedings of the 16th\nConference of the European Chapter of the Association for\nComputational Linguistics: Main Volume, 1772–1791. On-\nline: Association for Computational Linguistics.\nHernandez, E.; Li, B. Z.; and Andreas, J. 2023. Inspecting\nand Editing Knowledge Representations in Language Mod-\nels. arXiv:2304.00740.\nJi, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y .; Ishii, E.;\nBang, Y . J.; Madotto, A.; and Fung, P. 2023. Survey of Hal-\nlucination in Natural Language Generation. ACM Comput-\ning Surveys, 55(12): 1–38.\nKobayashi, G.; Kuribayashi, T.; Yokoi, S.; and Inui, K. 2023.\nFeed-Forward Blocks Control Contextualization in Masked\nLanguage Models. arXiv:2302.00456.\nKovaleva, O.; Romanov, A.; Rogers, A.; and Rumshisky,\nA. 2019. Revealing the Dark Secrets of BERT. In\nProceedings of the 2019 Conference on Empirical Meth-\nods in Natural Language Processing and the 9th Interna-\ntional Joint Conference on Natural Language Processing\n(EMNLP-IJCNLP), 4365–4374. Hong Kong, China: Asso-\nciation for Computational Linguistics.\nLevy, O.; Seo, M.; Choi, E.; and Zettlemoyer, L. 2017. Zero-\nShot Relation Extraction via Reading Comprehension. In\nProceedings of the 21st Conference on Computational Nat-\nural Language Learning (CoNLL 2017), 333–342. Vancou-\nver, Canada: Association for Computational Linguistics.\nLi, X.; Li, S.; Song, S.; Yang, J.; Ma, J.; and Yu, J.\n2023. PMET: Precise Model Editing in a Transformer.\narXiv:2308.08742.\nLiang, K.; Liu, Y .; Zhou, S.; Tu, W.; Wen, Y .; Yang, X.;\nDong, X.; and Liu, X. 2023a. Knowledge Graph Contrastive\nLearning Based on Relation-Symmetrical Structure. IEEE\nTransactions on Knowledge and Data Engineering, 1–12.\nLiang, K.; Meng, L.; Liu, M.; Liu, Y .; Tu, W.; Wang, S.;\nZhou, S.; and Liu, X. 2023b. Learn from relational corre-\nlations and periodic events for temporal knowledge graph\nreasoning. In Proceedings of the 46th International ACM\nSIGIR Conference on Research and Development in Infor-\nmation Retrieval, 1559–1568.\nLiang, R.; Li, T.; Li, L.; Wang, J.; and Zhang, Q. 2020.\nKnowledge Consistency between Neural Networks and Be-\nyond. arXiv:1908.01581.\nMeng, K.; Bau, D.; Andonian, A.; and Belinkov, Y . 2022a.\nLocating and Editing Factual Associations in GPT. In\nKoyejo, S.; Mohamed, S.; Agarwal, A.; Belgrave, D.; Cho,\nK.; and Oh, A., eds., Advances in Neural Information Pro-\ncessing Systems, volume 35, 17359–17372. Curran Asso-\nciates, Inc.\nMeng, K.; Sharma, A. S.; Andonian, A.; Belinkov, Y .; and\nBau, D. 2022b. Mass-Editing Memory in a Transformer.\narXiv:2210.07229.\nMitchell, E.; Lin, C.; Bosselut, A.; Finn, C.; and Manning,\nC. D. 2022a. Fast Model Editing at Scale. In International\nConference on Learning Representations.\nMitchell, E.; Lin, C.; Bosselut, A.; Manning, C. D.; and\nFinn, C. 2022b. Memory-Based Model Editing at Scale.\narXiv:2206.06520.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18571\nMurphy, A. H. 1996. The Finley affair: A signal event in\nthe history of forecast verification. Weather and forecasting,\n11(1): 3–20.\nPetroni, F.; Rockt¨aschel, T.; Riedel, S.; Lewis, P.; Bakhtin,\nA.; Wu, Y .; and Miller, A. 2019. Language Models as\nKnowledge Bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Process-\ning and the 9th International Joint Conference on Natural\nLanguage Processing (EMNLP-IJCNLP), 2463–2473. Hong\nKong, China: Association for Computational Linguistics.\nSinitsin, A.; Plokhotnyuk, V .; Pyrkin, D.; Popov, S.;\nand Babenko, A. 2020. Editable Neural Networks.\narXiv:2004.00345.\nWang, B.; and Komatsuzaki, A. 2021. GPT-J-6B: A 6\nBillion Parameter Autoregressive Language Model. https:\n//github.com/kingoflolz/mesh-transformer-jax. Accessed:\n2023-12-21.\nWang, K.; Variengien, A.; Conmy, A.; Shlegeris, B.;\nand Steinhardt, J. 2022. Interpretability in the wild: a\ncircuit for indirect object identification in gpt-2 small.\narXiv:2211.00593.\nYao, Y .; Wang, P.; Tian, B.; Cheng, S.; Li, Z.; Deng,\nS.; Chen, H.; and Zhang, N. 2023. Editing Large Lan-\nguage Models: Problems, Methods, and Opportunities.\narXiv:2305.13172.\nZhao, W. X.; Zhou, K.; Li, J.; Tang, T.; Wang, X.; Hou, Y .;\nMin, Y .; Zhang, B.; Zhang, J.; Dong, Z.; Du, Y .; Yang, C.;\nChen, Y .; Chen, Z.; Jiang, J.; Ren, R.; Li, Y .; Tang, X.; Liu,\nZ.; Liu, P.; Nie, J.-Y .; and Wen, J.-R. 2023. A Survey of\nLarge Language Models. arXiv:2303.18223.\nZheng, C.; Li, L.; Dong, Q.; Fan, Y .; Wu, Z.; Xu, J.; and\nChang, B. 2023. Can We Edit Factual Knowledge by In-\nContext Learning? arXiv:2305.12740.\nZhu, C.; Rawat, A. S.; Zaheer, M.; Bhojanapalli, S.; Li, D.;\nYu, F.; and Kumar, S. 2020. Modifying Memories in Trans-\nformer Models. arXiv:2012.00363.\nThe Thirty-Eighth AAAI Conference on Artiﬁcial Intelligence (AAAI-24)\n18572",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6313532590866089
    },
    {
      "name": "Computer science",
      "score": 0.4891414940357208
    },
    {
      "name": "Engineering",
      "score": 0.2553269863128662
    },
    {
      "name": "Electrical engineering",
      "score": 0.24296769499778748
    },
    {
      "name": "Voltage",
      "score": 0.08883199095726013
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I170215575",
      "name": "National University of Defense Technology",
      "country": "CN"
    }
  ],
  "cited_by": 19
}