{
  "title": "Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems",
  "url": "https://openalex.org/W4385573708",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2902549737",
      "name": "Denis Emelin",
      "affiliations": [
        "University of Edinburgh"
      ]
    },
    {
      "id": "https://openalex.org/A2468808117",
      "name": "Daniele Bonadiman",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2578358788",
      "name": "Sawsan Alqahtani",
      "affiliations": [
        "Princess Nourah bint Abdulrahman University"
      ]
    },
    {
      "id": "https://openalex.org/A1965939310",
      "name": "Yi Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2131603063",
      "name": "Saab Mansour",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3175604467",
    "https://openalex.org/W3134891661",
    "https://openalex.org/W2972119829",
    "https://openalex.org/W2964006684",
    "https://openalex.org/W4287684041",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4287795696",
    "https://openalex.org/W2964303773",
    "https://openalex.org/W4389009440",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W3099453223",
    "https://openalex.org/W4287366208",
    "https://openalex.org/W3164652135",
    "https://openalex.org/W3200895474",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W3045703328",
    "https://openalex.org/W3034999214",
    "https://openalex.org/W3171434230",
    "https://openalex.org/W3197780238",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W3100353583",
    "https://openalex.org/W2908510526"
  ],
  "abstract": "Pre-trained language models (PLM) have advanced the state-of-the-art across NLP applications, but lack domain-specific knowledge that does not naturally occur in pre-training data. Previous studies augmented PLMs with symbolic knowledge for different downstream NLP tasks. However, knowledge bases (KBs) utilized in these studies are usually large-scale and static, in contrast to small, domain-specific, and modifiable knowledge bases that are prominent in real-world task-oriented dialogue (TOD) systems. In this paper, we showcase the advantages of injecting domain-specific knowledge prior to fine-tuning on TOD tasks. To this end, we utilize light-weight adapters that can be easily integrated with PLMs and serve as a repository for facts learned from different KBs. To measure the efficacy of proposed knowledge injection methods, we introduce Knowledge Probing using Response Selection (KPRS) – a probe designed specifically for TOD models. Experiments on KPRS and the response generation task show improvements of knowledge injection with adapters over strong baselines.",
  "full_text": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 11962–11974\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nInjecting Domain Knowledge in Language Models\nfor Task-Oriented Dialogue Systems\n∗Denis Emelin1, Daniele Bonadiman2, ∗Sawsan Alqahtani3,4, Yi Zhang2, and Saab Mansour2\n1University of Edinburgh , denis.emelin@gmail.com\n2AWS AI Labs , {dbonadim,yizhngn,saabm}@amazon.com\n3Princess Nourah Bint Abdulrahman , saalqhtani@pnu.edu.sa\n4National Center of AI , sawalqahtani@nic.gov.sa\nAbstract\nPre-trained language models (PLM) have ad-\nvanced the state-of-the-art across NLP applica-\ntions, but lack domain-specific knowledge that\ndoes not naturally occur in pre-training data.\nPrevious studies augmented PLMs with sym-\nbolic knowledge for different downstream NLP\ntasks. However, knowledge bases (KBs) uti-\nlized in these studies are usually large-scale and\nstatic, in contrast to small, domain-specific, and\nmodifiable knowledge bases that are prominent\nin real-world task-oriented dialogue (TOD) sys-\ntems. In this paper, we showcase the advan-\ntages of injecting domain-specific knowledge\nprior to fine-tuning on TOD tasks. To this end,\nwe utilize light-weight adapters that can be eas-\nily integrated with PLMs and serve as a repos-\nitory for facts learned from different KBs. To\nmeasure the efficacy of proposed knowledge\ninjection methods, we introduce Knowledge\nProbing using Response Selection (KPRS) – a\nprobe designed specifically for TOD models.\nExperiments1 on KPRS and the response gen-\neration task show improvements of knowledge\ninjection with adapters over strong baselines.\n1 Introduction\nPre-trained language models (PLMs), such as\nBERT (Devlin et al., 2018), BART (Lewis et al.,\n2020), GPT (Brown et al., 2020), and XLNet (Yang\net al., 2019), have advanced the state-of-the-art of\nvarious natural language processing (NLP) tech-\nnologies and demonstrated an exceptional ability\nto store and utilize linguistic, factual, and com-\nmonsense knowledge. Consequently, PLMs form\nthe backbone of many recent NLP applications\nand have been successfully employed as modu-\nlar components in the context of task-oriented dia-\nlogue (TOD), responsible for sub-tasks including\n∗ Work performed while at AWS AI Labs\n1https://github.com/amazon-research/\ndomain-knowledge-injection\nFigure 1: A high-level representation of the KB-adapter\narchitecture (decoder only, for clarity). Adapter states\nare fused with the hidden states of the PLM to produce\na knowledge-informed predictive distribution. Dashed\nelements are used only if multiple adapters are active.\ndialogue state tracking and response generation\n(Hosseini-Asl et al., 2020; Lee et al., 2021).\nSince they are exposed to large quantities of\ngeneral data during training, PLMs store a wide\nvariety of diverse and general knowledge in their\nparameters (Petroni et al., 2019) such as capitals of\nnations, biographical details of famous individuals,\nand other facts of varying granularity. Commer-\ncially deployed TOD systems, however, typically\nrequire access to more restricted, domain-specific\ncategories of knowledge in order to produce in-\nformative and factually accurate responses to user\nqueries.2 Such information may include addresses\nof particular local attractions, detailed restaurant\nmenus, train routes, or ticket prices, and is unlikely\nto be found in the PLM’s training data. Due to its\nspecialized nature, this knowledge is often stored in\nexternal knowledge bases (KBs) that are accessed\nat run-time by TOD systems via external queries.\n2The term domain here refers to a specific application use-\ncase (e.g. expedia.com (travel) and opentable.com\n(restaurant) represent different domains).\n11962\nThis process introduces additional complexity\ninto the dialogue model design and requires imple-\nmenting KB queries and code wrappers as part of\nsystem setup, causing a substantial overhead espe-\ncially for non-experts. Querying external KBs can\nalso be disadvantageous when the KB is small, or\nis not changing in real time (as is the case with\ncatalogs, restaurants’ menus, etc). We identify the\ndecoupling of domain-specific knowledge from the\ndialogue model as a shortcoming to be remedied\nand instead propose to inject this knowledge di-\nrectly into the model’s parameters. This eliminates\nthe need for querying external KBs, streamlining\nthe creation and deployment of TOD systems.\nInjecting domain-specific information into TOD\nsystems that can guide and inform model behav-\nior and may be subsequently updated and modi-\nfied by the user is not a trivial task. Ideally, this\nshould be accomplished in a manner that is effi-\ncient, architecture-agnostic, and compatible with\noff-the-shelf PLMs. In order to satisfy these re-\nquirements, we adopt light-weight adapter net-\nworks as repositories of domain-specific knowl-\nedge (KB-adapters for short). Such adapters can\nbe trained to memorize KB facts 3 and integrated\ninto pretrained PLMs through the fusion of hidden\nrepresentations, as illustrated in Figure 1. Our work\nis in line with past studies that demonstrated the\nutility of adapters as stores of factual and linguis-\ntic knowledge outside of TOD (Wang et al., 2020).\nImportantly, injecting knowledge into TOD models\nthrough adapters is computationally less demand-\ning than injecting domain-specific facts by fine-\ntuning entire dialogue models on synthetic data, as\nexplored in (Madotto et al., 2020), which facilitates\nefficient updating of the injected knowledge.\nTo quantify the success of the knowledge injec-\ntion procedure, we develop theKnowledge Probing\nusing Response Selection (KPRS) task and bench-\nmark (see §3). KPRS leverages contrastive dia-\nlogue response pairs to probe the extent of memo-\nrization of domain-specific facts by the evaluated\ndialogue model, whereby one response is consis-\ntent with the corresponding KB, while the other\nis not. To our knowledge, both KPRS and the use\nof adapters for domain-specific knowledge injec-\ntion in TOD represent novel contributions of our\nwork. We conduct experiments that evaluate PLMs\nequipped with domain-specific KB-adapters on the\nKPRS benchmark as well as the more conventional\n3We use the term fact to refer to individual KB entries.\nresponse generation (RG) task, comparing them\nagainst strong baselines.\nOur contributions can be summarized as follows:\n• We define and implement adapter-based meth-\nods for injecting highly specific and retriev-\nable domain knowledge into TOD models\n• We design and develop the KPRS probing task\nthat can be used to evaluate the effectiveness\nof knowledge injection for TOD systems\n• We show that PLMs with KB-adapters are\nusually preferable to knowledge-unaware and\nsequentially-finetuned PLMs for TOD\n2 KB-Adapters for Domain-Specific\nKnowledge Injection\nWe conceptualize KB adapters as repositories of\ndomain-specific information that guide the PLMs’\npredictions to be consistent with KB contents. The\nproposed knowledge injection process is divided\ninto two stages: (1) Memorization: adapters are\ntrained to memorize domain-specific KB facts; (2)\nUtilization: PLMs are trained to leverage adapters\nwhen reasoning about entities and their attributes.\nDuring the memorization stage, adapters are con-\nnected to the frozen PLM and tasked with recon-\nstructing corrupted KB facts, thereby memorizing\nassociations between entity and attribute mentions.\nDuring the utilization stage, the PLM (now un-\nfrozen) is given access to frozen adapters and learns\nto leverage their memorized knowledge to make\nmore accurate predictions on downstream tasks\nsuch as RG. As a result, PLMs can generalize to\nunseen inputs by virtue of their domain-general pre-\ntraining while receiving domain-specific guidance\nin their predictions by the knowledge encoded in\nadapter representations.\nWhen training KB-adapters, we allocate a single\nadapter for each individual domain KB (e.g. ho-\ntel or restaurant). This results in shorter training\ntimes per adapter and (if needed) facilitates effi-\ncient re-training of adapters to reflect changes in\nthe associated KBs. 4 This allows for a straight-\nforward extension of TOD systems equipped with\nKB-adapters to new domains, as this only requires\ntraining a single, new domain-specific adapter that\ncan be used in concert with existing ones. Never-\ntheless, we also consider a setting where we train a\n4E.g. if the user updates the prices of certain items on a\nrestaurant’s menu.\n11963\nFigure 2: Example MultiWOZ 2.2 KB entry.\nsingle, mixed-domain adapter on the concatenation\nof all KBs in our experiments (see §5.5).\n2.1 System Overview\nUnlike the vast amounts of data used to pre-\ntrain PLMs, information stored in KBs is usu-\nally structured and does not resemble natural lan-\nguage expressions. Figure 2 shows a single KB\nentry (or fact) from the MultiWOZ 2.2 dataset\n(Budzianowski et al., 2018; Ye et al., 2021). Since\nKB-adapters need to be compatible with PLMs and\ntheir internal representations, we therefore convert\nKB entries prior to the memorization stage from\ntheir initial format into declarative statements of\nvarying complexity (§2.2). Each statement men-\ntions exactly one entity (e.g. a restaurant’s name)\nand one or more entity attributes (e.g. the types of\ncuisine served by a restaurant). Each statement is\nsubsequently corrupted by masking out a single at-\ntribute.5 By denoising the input sequence, adapters\nlearn to correlate entities with their attributes, ef-\nfectively memorizing entire KBs with high accu-\nracy (§2.3). The obtained KB-adapters are utilized\nto guide PLMs’ predictions during fine-tuning on\ndownstream TOD tasks (§2.4).\nIn our experiments, BART (Lewis et al., 2019)\nis chosen as the PLM that forms the backbone of\nthe adapter-augmented TOD model, due to its com-\npetitive performance on generative tasks.6 While\nthe proposed knowledge injection approach is ag-\nnostic to the choice of particular PLM, we leave\nsuch validation for future work.\nWe employ bottleneck adapters (Houlsby et al.,\n5The entity mention is never masked out, as multiple enti-\nties can have the same attribute resulting in ambiguous model\ninputs, e.g. multiple restaurants can serve Indian food.\n6We utilize the BART-Large provided as part of the\nTransformers library (Wolf et al., 2019).\natomic\nfacts\nPizza Hut City Centre is located in the cen-\ntre area of the city.\nPizza Hut City Centre serves food in the\ncheap price range.\nThe postcode of Pizza Hut City Centre is\ncb21ab.\n. . .\ncomposite\nfacts\nPizza Hut City Centre is a restaurant that\nserves Italian food in the cheap price range.\nIt is located at [51.20103, 0.126023], in the\ncentre area of the city, in the cb21ab post-\ncode. Its phone number is 01223323737.\nTable 1: Examples of the natural language formats used\nto represent KB facts in our study. Entity mentions are\nunderlined, whereas entity attributes are italicized.\n2019) due to their established effectiveness and\ninsert them after the final layer of the encoder and\ndecoder.\nThe PLM’s hidden state given to the adapter as\ninput is combined with the adapter’s output using\na weighted fusion function which is a linear trans-\nformation of the PLM’s hidden state followed by a\nsoftmax activation that produces the fusion weights.\nThis allows the final model to dynamically adjust\nthe extent to which adapter knowledge is used at\neach prediction step. In this work, we ran two sets\nof experiments by applying this gating function to\neither the logits obtained from both the PLM and\nthe adapters, or to their pre-logit hidden states.\nWe train a single encoder and a single decoder\nadapter per domain (hyper-parameter settings are\nreported in Appendix C).7\n2.2 From KB Facts to Declarative Statements\nPrevious studies that investigated knowledge injec-\ntion methods often use relational tuples to repre-\nsent individual facts contained within a KB, e.g.\nwhere an entity is connected to one of its at-\ntributes via the relevant relation: [Pizza Hut\nCity Centre, food, Italian]. While\nthis knowledge representation format has been\nfound to be effective in the past, our preliminary\nstudies indicated that the mismatch between the\nnatural language input format expected by a PLM\nand the structured tuple causes slight performance\ndegradation. Hence, we choose to represent indi-\nvidual KB entries as natural language statements\n7We also investigated several other fusion functions, in-\ncluding unweighted state averaging, state concatenation fol-\nlowed by a projection as used in (Wang et al., 2020), atten-\ntion, GRU cell, and a combination of softmax distributions\nproduced separately by the PLM and the adapter. However,\nneither of these performed better than the proposed approach.\n11964\nFigure 3: On the left, a schematic representation of\nthe memorization stage, where the adapter is trained\nto memorize KB contents by reconstructing corrupted\nstatements derived from KB facts. Note that the PLM\nparameters are frozen at this stage. On the right, a rep-\nresentation of the utilization stage, where the adapter-\naugmented PLM is fine-tuned on a downstream TOD\ntask and learns how to utilize adapter knowledge. Note\nthat the adapter parameters are frozen at this stage.\nthat are fully consistent with the data seen by the\nPLM during pretraining.\nThere are several intuitive ways in which a KB\nentries can be translated into natural language state-\nments. Referring again to Figure 2, we consider (1)\natomic statements, where each statement mentions\nthe entity and one of its attributes, connected by the\nattribute’s relation, and (2) composite statements\nwhere each statement communicates the entirety\nof the entry, covering all provided entity attributes\nand relations. Table 1 illustrates both formats based\non the MultiWOZ KB entry in Figure 2. All state-\nments are derived by filling-in pre-defined, human-\nauthored templates with the appropriate entity and\nattribute values.8 Designing the templates intro-\nduces minimal overhead, as they reuse attribute\ndesignations where possible and do not introduce\nany information beyond the contents of KB entries.\nThe exhaustive list of templates used in our experi-\nments is provided in Tables 9 and 10. During the\nmemorization stage, KB-adapters are trained on a\nmixture of all atomic and composite facts, so as to\nfamiliarize the TOD model with different represen-\ntations of the same information.\n2.3 Memorization Stage\nFollowing the construction of natural language rep-\nresentations of KB facts, the memorization stage\ninvolves training adapters to memorize and recall\n8We note that we did not optimize the templates’ design\nas part of our investigation. Our goal in creating the templates\nwas to render structured KB content into natural language\nwithout introducing any superfluous information, so as to\nverify the efficacy of our adapter-based knowledge injection\nmethod without additional confounding factors.\nFigure 4: Samples from the KPRS benchmark. Each\nsample consists of (1) a dialogue context that includes\nthe available history and the active user turn and (2) two\ncandidate responses to be scored by the model – a refer-\nence response that is consistent with both the dialogue\ncontext and the KB, and a perturbed response that is not.\nReference values are set in green and perturbed values\nare set in red. Note that \"Tenpin\" is not in the centre\narea and \"Alexander Bed and Breakfast\" does not have\nfree WiFi according to their respective KB entries.\nKB information. As shown on the left in Figure 3,\nthe adapter-augmented PLM learns to reconstruct\nmasked declarative statements that are derived from\nKB contents, whereby the weights of the PLM\nitself are kept frozen – only adapter parameters\nare being updated. By filling-in masked tokens,\nadapters learn correlations between entities (e.g.\nhotel names) and their attributes (e.g. phone num-\nbers). Adapter training resembles masked language\nmodeling and is easy to implement and scale.\n2.4 Utilization Stage\nAfter the memorization stage, PLMs are trained to\nleverage the domain-specific knowledge encoded in\nadapter representations with the goal of producing\nmore accurate predictions on a downstream task,\nsuch as RG, as illustrated on the right in Figure 3.\nThroughout this fine-tuning process, adapter param-\neters are kept frozen so as to preserve the domain-\nspecific knowledge injected during the memoriza-\ntion stage. PLM parameters, on the other hand,\nare unfrozen to allow the model to learn to exploit\nadapter representations.\n11965\n3 Knowledge-Probing using Response\nSelection (KPRS) Benchmark\nIn this study, we investigate the ability of language\nmodels to verify and retrieve domain-specific facts\nwithin the TOD setting. To this end, we propose the\n\"Knowledge-Probing using Response Selection\"\n(KPRS) task and the associated benchmark. KPRS\nallows us to examine whether domain-specific\nknowledge, such as entities and their attributes,\nthat is stored within the parameters of the evaluated\nmodel can be successfully accessed and guide the\nmodel’s predictions. Being knowledgeable about\ndomain-specific entities in this manner can benefit\ndialogue models when reasoning about and reply-\ning to user queries. We show this to be the case for\nthe response generation task in §5.3.\nKPRS is a contrastive evaluation benchmark that\nmeasures whether the probed model has memo-\nrized and can accurately retrieve domain-specific\nknowledge contained within a specified KB. It is\nderived from MultiWOZ 2.2 dialogues (Zang et al.,\n2020) (development and test portions only) and\ncovers four domains: restaurant, hotel, attraction,\nand train. Given a dialogue context, the task pre-\nsented to the evaluated model is to score responses\nthat are either compatible or incompatible with the\ninformation contained in the KB.\nImportantly, KPRS should not be regarded as a\nstand-alone evaluation task, but rather as a probing\nmechanism that can offer informative insights into\na model’s ability to access domain-specific facts\nstored within its parameters, similar to other knowl-\nedge probes, e.g. (Petroni et al., 2019). Specifically,\na fact-aware model should be able to distinguish\nbetween an appropriate (\"reference\") dialogue\nresponse that is compatible with the knowledge\nbase information from an inappropriate (\"dis-\ntractor\") response that contradicts the domain-\nspecific knowledge. By design, the two responses\nare minimally different – identical except for at-\ntribute values associated with entities described in\nthe KB, such as restaurant names or departure times\nof trains. Hence, to identify the correct dialogue re-\nsponse, a model must be able to distinguish values\nthat are compatible with domain-specific informa-\ntion from those that are not.\n3.1 Benchmark Design\nIn order to derive KPRS from MultiWOZ 2.2 de-\nvelopment and test set dialogues, we (1) extract\ndialogue contexts that precede a system response\nthat contains a mention of an entity from the KB or\nits attributes, and (2) perturb the corresponding sys-\ntem response to make it incompatible with the KB\nby modifying said entity and attribute mentions.\nDifferent perturbation strategies are used for dif-\nferent types of attribute slots. For phone numbers, a\nsingle digit is randomly changed. For integers (e.g.\ndenoting the price of a train ticket), we randomly\nincrement or decrement the numbers by a small\namount. For other slot types, distractor values are\nchosen so that they differ from the reference value\nwhile producing inadmissible responses. Distrac-\ntors are chosen adversarially, i.e., candidates are\nsampled from the KB until the perturbed response\nbecomes incompatible with the domain-knowledge\nand the dialogue context up to the response, while\nalso achieving a lower sentence-level perplexity\nthan the reference response according to a filter-\nLM (BART-Large). The latter is to ensure the\nwell-formedness and plausibility of the perturbed\nresponses. To guarantee that the perturbed response\nis indeed unsuitable, we make sure that the selected\ndistractor does not share attriutes that have been\nmentioned in the dialogue context with the replaced\nslot value.9\nFigure 4 shows examples included in the KPRS\nbenchmark. Each KPRS sample contains the di-\nalogue context that includes reference dialogue\nstates, and two response options – reference re-\nsponse and distractor response . Overall, the\nKPRS benchmark dataset includes 3,055 samples\n(1,711 single-domain, 1,324 multi-domain). Sam-\nples had been derived from 831 unique dialogues /\n1,997 unique dialogue contexts. On average, 3.65\nsamples were obtained from each individual dia-\nlogue / 1.52 samples from each individual dialogue\ncontext.\n4 Experimental Setup\n4.1 Knowledge Base Resource\nThroughout our experiments, we use MultiWOZ\n2.2 (Zang et al., 2020) which contains several rel-\natively small-scale domain-specific KBs that are\naligned with task-oriented dialogues. 10 After fil-\n9E.g. if the response originally mentioned the name of a\nrestaurant that serves Italian food and the dialogue context\nup to the response only mentions Italian cuisine as a desired\nrestaurant property, the distractor is explicitly chosen, using\nstring-matching heuristics, to be a restaurant that serves some\nother type of food, so as not to unintentionally yield a valid\nresponse.\n10In practical settings, businesses maintain similar knowl-\nedge bases in-house which could be utilized in TOD servicees.\n11966\nrestaurant hotel attraction train\n1,540 594 1,106 39,592\nTable 2: Number of facts in each KB.\ntering out KBs with missing information, we are\nleft with four domains: restaurant, hotel, attrac-\ntion, and train. Table 2 shows the number of facts\navailable per domain. Note the substantial gap in\nthe number of facts where trains is approximately\n25X to 66X larger than the other domains.\n4.2 Intrinsic Evaluation\nTo examine whether they can accurately retrieve the\ninjected KB facts, we task knowledge-augmented\nPLMs with reconstructing masked facts, using in-\nputs of the same format as described in §2.2. Since\nthis task measures success as a model’s ability to\nmemorize and recall learned KB information rather\nthan generalize it to unseen inputs, we evaluate our\nmodels on the same set of data as was used for\nknowledge injection as part of the memorization\nstage. Memorization accuracy is employed as the\nevaluation metric, representing the number of facts\nthat have been correctly reconstructed. We refer to\nthis task as fact memorization task.\n4.3 Downstream Evaluation\nAdditionally, we evaluate our models on the KPRS\nprobe (§3) as well as the response generation (RG)\ntask. While KPRS directly estimates models’ pref-\nerence for dialogue continuations that are either\nconsistent or inconsistent with KB information, RG\nexamines model’s ability to integrate the injected\nKB knowledge into the generated response as part\nof the TOD pipeline.\nFor KPRS, we fine-tune BART-large on the\ntraining data for each domain, using correct re-\nsponses as targets, and evaluate subsequent model\nperformance on the KPRS benchmark. An aug-\nmented PLM that can accurately access the injected\ndomain-specific facts is expected to assign a higher\nlikelihood to the reference response, compared to\nthe permuted distractor. Response selection accu-\nracy is used as the evaluation metric, defined as\n(c/N), where N is the total number of contrastive\nsentence pairs and c is the number of pairs in which\nthe reference response (i.e. the one consistent with\nthe KB) is assigned lower perplexity by the model.\nFor RG, given a dialogue context, models must\ngenerate a response that is consistent with KB facts\nwithout performing external KB queries. To test\nrestaurant hotel attraction train\n98.1 98.2 97.6 93.2\nTable 3: Fact memorization accuracy for KB-adapters.\nthe model’s ability for fact retrieval, we use un-\nweighted mean of two informative metrics: inform\nrate (n/N) and success rate ( m/N) (Zang et al.,\n2020), where N is the total number of turns in the\ntest set, n is the number of turns in which the enti-\nties generated by the model are all consistent with\nthe KB, and m is the number of turns in which the\nmodel generation provides at least as much of the\nuser-requested information as the gold response.11\n4.4 Baselines\nWe compare the performance of the knowledge-\ninjected model with two baselines: (1) BART-large\nwithout any knowledge augmentation; (2) BART-\nlarge that has been sequentially fine-tuned on each\nKB (Seq-BART). We fine-tune all models on the\ndownstream task prior to the downstream evalua-\ntion.\n5 Results & Analysis\nWe examine the models’ ability to memorize and\nretrieve facts learned from the knowledge base in\n§5.1 and the impact of knowledge injection on\ndownstream tasks in §5.2 and §5.3. Models were\nevaluated in the single-domain setting where only\none single adapter corresponding to the specified\ndomain was active at evaluation time with test sam-\nples belonging exclusively to the adapter domain\n(a multi-domain setting is discussed in §5.5)\n5.1 Fact Memorization\nAs discussed in §4.2, we evaluate whether the\nknowledge-augmented model is able to success-\nfully denoise masked facts seen during training,\nthus testing its memorization capabilities. Table\n3 shows the results of the fact memorization task\nfor BART equipped with KB-adapters. The memo-\nrization accuracy is generally very high across all\ndomains and appears to correlate with KB size.\n11BLEU (Papineni et al., 2002), as typically used for text\ngeneration, is not sufficient as an evaluation metric for our\npurpose. Previous work evaluated generated responses that\ncontain slot value placeholders instead of concrete informa-\ntion such as entity attributes, as in the case in our study. In\naddition, any evaluation of response factuality must consider\nall permissible entities given the dialogue context, rather than\nonly one out of many, as is implicitly done by BLEU.\n11967\nModel rest. hotel attr. train all\nBART 70.8 72.5 71.3 78.9 76.5\nSeq-BART 71.5 72.1 72.7 74.4 75.6\nada-logits 81.5 83.1 81.2 94.3 78.2\nada-hidden 81.3 82.0 80.6 94.0 78.4\nTable 4: Response selection accuracy on KPRS. ada-\nlogits and ada-hidden refer to experiments utilizing KB-\nadapters with different fusion mechanisms (either at the\nlevel of logits or pre-logits hidden states).\n5.2 Knowledge-Probing using Response\nSelection (KPRS)\nTable 4 reports the performance of the knowledge-\naugmented PLM compared to baselines introduced\nin §4.4. We found that injecting domain-specific\nknowledge into the PLM significantly improves\nKPRS accuracy – by 9-15% – compared to BART.\nThe largest improvement can be observed in the\ntrain domain, which is at odds with the fact mem-\norization results (§5.1), where our model under-\nperformed on that domain. As such, while perfect\nmemorization of a of all facts contained within a\nlarge KBs remains a challenge in the current train-\ning setup, the domain knowledge embedded within\nthe adapter network can nevertheless be effectively\nexploited by the PLM.\n5.3 Response Generation (RG)\nPresumably, having access to the domain knowl-\nedge stored in KB-adapters should enable a PLM\nto generate responses that are more consistent with\nthe respective KBs. Table 5 reports the results for\nour RG experiments, providing empirical support\nfor this hypothesis. Interestingly, a large discrep-\nancy can be observed for the hotel domain between\nthe two examined representation fusion techniques\n(ada-logit that combines PLM and adapter repre-\nsentations at the logit level vs. ada-hidden that\ncombines their pre-logits hidden states). We hy-\npothesise that this is, at least in part, due to thehotel\nKB containing a small number of facts, which may\nhave caused instability during training. Accord-\ningly, although knowledge injection can clearly\nbenefit generation of factual system responses in\nboth the single-domain setting, the extent of the\nimprovements is contingent on the target domain\nand its properties, as is the best-performing repre-\nsentation combination function.12\n12It would be valuable to investigate the general impact of\nKBs’ size on the PLMs’ performance. However, this falls\noutside the scope of this paper, as such study would require a\ngreater diversity in the sizes of available KBs.\nModel rest. hotel attr. train all\nBART 54.7 44.3 50.3 38.2 54.2\nada-logit 46.0 12.6 69.7 55.0 61.4\nada-hidden 53.3 55.9 68.6 48.6 62.3\nTable 5: RG performance calculated as the average of\ninform rate and success rate metrics. The all column\nreports results for the multi-domain setting.\nModel rest. hotel attr. train all\nBART 12.59 11.53 15 17.71 13.41\nada-logit 12.69 6.5 15.09 19.33 15.98\nada-hidden 10.39 12.64 15.94 17.56 15.33\nTable 6: Response generation BLEU score performance.\nTable 6 provides estimates of RG quality accord-\ning to BLEU. Overall, we see minor to substantial\nimprovements with respect to the BLEU metric\nover the baseline lacking KB-adapters. This can\nbe taken as further evidence in support of the ef-\nfectiveness of the proposed knowledge injection\nmethodology. However, it should be noted that the\nextent of the observed improvements varies across\ndomains and representation combination functions.\n5.4 Randomly-initialized Adapters\nWe investigate how equipping PLMs with our pro-\nposed KB-adapters compares to equipping them\nwith randomly-initialized adapters during the fine-\ntuning stage (a setting to which we refer as rand-\nBART). This effectively isolates the impact of\nknowledge injection on the KPRS and RG perfor-\nmance, by factoring out the increased model ca-\npacity due to the additional parameters introduced\nby the adapters. Table 7 shows the experimen-\ntal results for both tasks. We find that injecting\ndomain-specific knowledge into the PLM does in-\ndeed significantly improve KPRS performance – by\n6-15% – compared with rand-BART, thus further\nvalidating our approach.\n5.5 Integration of Multiple Knowledge Bases\nThe modular nature of of the proposed knowledge-\ninjection method allows us to equip PLMs with\nmultiple adapters, with each adapter encoding in-\nformation from a different domain. This enables\nthe augmented PLM to access facts from differ-\nent domains simultaneously, without running the\nrisk of catastrophic forgetting, whereby informa-\ntion from one domain overwrites previously ac-\nquired domain-specific knowledge, e.g. as a result\nof sequential fine-tuning. Aligned with our mo-\ntivation to allow users to easily add and modify\n11968\nModel rest. hotel attr. train\nKPRS\nrand-BART 70.3 76.6 74.4 79.6\nada-logits 81.5 83.1 81.2 94.3\nada-hidden 81.3 82.0 80.6 94.0\nRG\nrand-BART 0 47.0 66.1 28.2\nada-logit 46.0 12.6 69.7 55.0\nada-hidden 53.3 55.9 68.6 48.6\nTable 7: Response selection accuracy on KPRS and the\naverage of inform and success rate metrics for RG. For\nRG in the the restaurant domain, rand-BART failed to\nconverge given our hyper-parameter settings.\nKBs in practical settings, we investigate whether\nour proposed system can effectively integrate in-\nformation from multiple adapters. We utilize the\nsame representation combination functions as de-\nscribed in §2.1, generalizing them to an unbound\nnumber of adapters by computing normalized fu-\nsion weights for each adapter and the PLM itself.\nIn this multi-domain setting, multiple adapters are\nactive simultaneously, while test samples are drawn\nfrom all four studied domains.\nTables 4 and 5 report multi-domain results for\nKPRS and RG in the multi column. For both tasks,\nwe observe clear improvements compared to base-\nline models when providing the model with ac-\ncess to all domain-specific adapters simultaneously.\nHowever, we note that the gap between the adapter-\naugmented PLM and the best-performing baseline\nis much smaller compared to single-domain experi-\nments where the model only has access to a single,\nrelevant adapter (1.9% vs. 12.25% on average for\nKPRS and 8.1% vs. 11.6% on average for RG).\nOne reason for the limited improvements ob-\nserved in the multi-domain setting could be the\nPLM’s inability to correctly identify adapters corre-\nsponding to the dialogues’ domains and to promote\ntheir representations. The more pronounced gains\nobserved in the single-domain setting – where the\nmodel does not have to chose between multiple\nadapters – appears to support this interpretation.\nTo verify our hypothesis, we preclude the need\nfor adapter selection by instead training a single\nadapter on the concatenation of facts from all four\ndomains, which preserves the multi-domain setting.\nEvaluating the performance of the resultant model\non KPRS, we observe improvements over the mul-\ntiple adapters setting, with ada-logis obtaining an\naccuracy of 83.0% andada-hidden reaching 85.9%,\nthus improving over the best-performing baseline\nby a substantial 9.4%. This, however, comes at\nthe expense of increased training time during the\nmemorization stage and a significant reduction in\nflexibility for the addition of new KBs (which will\nrequire costly re-training the single, multi-domain\nadapter rather than simply introducing a new single-\ndomain adapter).\nIt may be possible to improve the performance\nof PLMs equipped with multiple single-domain\nadapters by implementing more expressive com-\nbination representation functions or by adjusting\nthe training regime. We regard as a promising re-\nsearch direction that could more effectively extend\nthe flexibility of adapter-based knowledge injection\nto more complex dialogue settings.\n6 Related Work\n6.1 Knowledge Injection\nOur work contributes to the growing body of re-\nsearch that explores strategies for introducing exter-\nnal knowledge into the internal reasoning processes\nof PLMs, with the aim of aligning their predic-\ntions with respective knowledge sources (Colon-\nHernandez et al., 2021). Previous work in this\narea incorporated linguistic (Lauscher et al., 2019;\nWang et al., 2020), factual (Wang et al., 2020;\nAgarwal et al., 2020), and commonsense (Lauscher\net al., 2020) knowledge into pretrained models,\nwith studies differing in the exact format of the\ninjected knowledge and potential modifications to\nthe PLMs’ architecture. Nevertheless, injection of\nhighly specific, fine-grained, tabular information\ncommonly associated with TOD (as exemplified\nby MultiWOZ 2.2 KBs) has so far received limited\nattention, both within dialogue literature and be-\nyond. The use of natural language statements as the\nprimary mechanism for injecting external informa-\ntion into PLMs has been previously considered in\nworks such as (Lu et al., 2021), who trained a gen-\nerative model to transform knowledge triplets into\ndeclarative statements. We rely on template-based\ngeneration, instead, to account for the relatively\nsmall size of our KBs, the highly structured nature\nof KB entries, and the lack of natural language\nsequences that can be trivially aligned with KB\ncontents.\n6.2 Knowledge-Grounded Dialogue\nOf particular relevance to our work is the study by\n(Madotto et al., 2020) who fine-tune all parameters\nof a PLM on synthetic dialogues constructed so as\n11969\nto communicate all information contained within\na TOD KB. The limitations of their approach, as\nnoted by its authors, are that the synthetic dialogues\nare noisy and any subsequent updates to the in-\njected KB information require finetuning the entire\nmodel anew which is computationally demanding.\nWe address both issues by relying on grammati-\ncally sound templates during knowledge injection\nand by leveraging light-weight adapters that can be\nupdated for a small fraction of cost incurred by up-\ndating the full PLM. The Adapter-Bot introduced in\n(Lin et al., 2021) is likewise related to our models\nin that it employs adapters in the context of TOD.\nHowever, rather than training adapters to memorize\nKB content that can be exploited by the dialogue\nmodel without additional supervision, the authors\nrely on knowledge-aligned dialogues to introduce\ndomain-specific information into their model which\nmay not always be available. More recently, (Fan\net al., 2021) proposed equipping transformer mod-\nels with specialized modules that fetch embedded\ninformation from external resources, integrating\nit into the model’s reasoning process. While the\nauthors apply their model to dialogue generation,\ntheir work differs substantially from ours, as they\ndo not consider the task-oriented setting or struc-\ntured KBs (instead using training set utterances and\nWikipedia excerpts). However, combining knowl-\nedge memorization and differential information re-\ntrieval is a promising direction for future research.\nMoreover, external knowledge has found applica-\ntion in dialogue literature outside of directly guid-\ning response generation. For instance, (Lertvit-\ntayakumjorn et al., 2021) annotated dialogue data\nwith constraint violations based on valid links be-\ntween entities as specified in the corresponding\nKBs. Similar to KPRS, detection of constraint\nviolations can be regarded as a probing task that\nprovides insights about the ability of a dialogue\nmodel to reason about KB entities.\n7 Limitations\nOne of the main limitations of the presented ap-\nproach is its reliance on manually constructed\nfact templates. We experimented with fine-tuning\nKG-adapters directly on < ent1, rel, ent2 > KB\ntriples, but found that the use of templates improves\nthe ability of models to apply the memorized knowl-\nedge in downstream applications. In light of this,\npossible future extensions of our work may include\ncreation of domain-agnostic strategies for knowl-\nedge injection that do not necessitate manual design\nof templates for each new domain.\nAnother limitation comes from the fact that the\nproposed approach is suitable only for static and\npseudo-dynamic KBs , i.e. that can change periodi-\ncally, such as a seasonal menu or a database of cars\nmanufactured by a company. However, it is not\nsuited for real-time databases (e.g. databases that\nstore the availability of rooms in a hotel) since for\nevery KB change the corresponding adapter needs\nto be retrained in order to be updated.\nAdditionally, while injecting knowledge into the\nlanguage model has been shown to be effective for\nmaking it available during fine-tuning on down-\nstream tasks, the knowledge stored in the adapters’\nparameters might not be accurate enough for cer-\ntain real world applications due to the imperfect\nfact memorization we observed in our experiments.\nFinally, the introduced KPRS task only evalu-\nates the extent to which a model can access factual\ninformation stored in its parameters. It does not\nnot assess the model’s ability to understand and\nuse this knowledge for complex reasoning tasks,\ne.g. counting the number of cars in a specific price\nrange, or listing the items on a menu that do not\ncontain a certain ingredient. This could be an ex-\nciting direction for future research.\n8 Discussion and Conclusion\nIn this study, we proposed a method for tightly in-\ntegrating external knowledge with the internal rep-\nresentations of PLMs by storing domain-specific\ninformation within light-weight adapter networks\nthat guide model predictions. Such adapters can\nmemorize KB contents with high accuracy, which\ndecreases slightly for larger KBs. An important\ncontribution of our work is the KPRS probe de-\nsigned to measure the ability of TOD models to rea-\nson about KB entities and their attributes. As part\nof our experiments, we showed that KB-adapters\nclearly benefit the identification and generation of\nTOD responses that are consistent with dialogue\nhistory and relevant KB entries, and showcased\nthe advantages of using adapters for knowledge\ninjection as opposed to sequential fine-tuning.\nOur investigation demonstrates that dialogue\nmodels can access domain-specific knowledge\nwithout having to query external KBs. This is an\nimportant finding as it can pave the way towards\nreducing the query engineering overhead in chatbot\ndesign, thus lowering the entry barrier for develop-\ning and deploying real-world TOD systems.\n11970\nReferences\nOshin Agarwal, Heming Ge, Siamak Shakeri, and\nRami Al-Rfou. 2020. Knowledge graph based syn-\nthetic corpus generation for knowledge-enhanced\nlanguage model pre-training. arXiv preprint\narXiv:2010.12688.\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. arXiv preprint arXiv:2005.14165.\nPaweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang\nTseng, Inigo Casanueva, Stefan Ultes, Osman Ra-\nmadan, and Milica Gaši ´c. 2018. Multiwoz–a\nlarge-scale multi-domain wizard-of-oz dataset for\ntask-oriented dialogue modelling. arXiv preprint\narXiv:1810.00278.\nPedro Colon-Hernandez, Catherine Havasi, Jason\nAlonso, Matthew Huggins, and Cynthia Breazeal.\n2021. Combining pre-trained language mod-\nels and structured knowledge. arXiv preprint\narXiv:2101.12294.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nAngela Fan, Claire Gardent, Chloé Braud, and Antoine\nBordes. 2021. Augmenting transformers with knn-\nbased composite memory for dialog. Transactions of\nthe Association for Computational Linguistics, 9:82–\n99.\nEhsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu,\nSemih Yavuz, and Richard Socher. 2020. A simple\nlanguage model for task-oriented dialogue. arXiv\npreprint arXiv:2005.00796.\nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,\nBruna Morrone, Quentin De Laroussilhe, Andrea\nGesmundo, Mona Attariyan, and Sylvain Gelly. 2019.\nParameter-efficient transfer learning for nlp. In In-\nternational Conference on Machine Learning, pages\n2790–2799. PMLR.\nAnne Lauscher, Olga Majewska, Leonardo FR Ribeiro,\nIryna Gurevych, Nikolai Rozanov, and Goran\nGlavaš. 2020. Common sense or world knowl-\nedge? investigating adapter-based knowledge in-\njection into pretrained transformers. arXiv preprint\narXiv:2005.11787.\nAnne Lauscher, Ivan Vuli´c, Edoardo Maria Ponti, Anna\nKorhonen, and Goran Glavaš. 2019. Informing unsu-\npervised pretraining with external linguistic knowl-\nedge.\nChia-Hsuan Lee, Hao Cheng, and Mari Ostendorf.\n2021. Dialogue state tracking with a language model\nusing schema-driven prompting. arXiv preprint\narXiv:2109.07506.\nPiyawat Lertvittayakumjorn, Daniele Bonadiman, and\nSaab Mansour. 2021. Knowledge-driven slot con-\nstraints for goal-oriented dialogue systems. In Pro-\nceedings of the 2021 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, pages\n3407–3419.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVes Stoyanov, and Luke Zettlemoyer. 2019. Bart: De-\nnoising sequence-to-sequence pre-training for natural\nlanguage generation, translation, and comprehension.\narXiv preprint arXiv:1910.13461.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2020.\nBART: Denoising sequence-to-sequence pre-training\nfor natural language generation, translation, and com-\nprehension. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 7871–7880, Online. Association for Computa-\ntional Linguistics.\nZhaojiang Lin, Andrea Madotto, Yejin Bang, and Pas-\ncale Fung. 2021. The adapter-bot: All-in-one con-\ntrollable conversational model. In Proceedings of\nthe AAAI Conference on Artificial Intelligence, vol-\nume 35, pages 16081–16083.\nIlya Loshchilov and Frank Hutter. 2017. Decou-\npled weight decay regularization. arXiv preprint\narXiv:1711.05101.\nYinquan Lu, Haonan Lu, Guirong Fu, and Qun\nLiu. 2021. Kelm: Knowledge enhanced pre-\ntrained language representations with message pass-\ning on hierarchical relational graphs. arXiv preprint\narXiv:2109.04223.\nAndrea Madotto, Samuel Cahyawijaya, Genta Indra\nWinata, Yan Xu, Zihan Liu, Zhaojiang Lin, and Pas-\ncale Fung. 2020. Learning knowledge bases with\nparameters for task-oriented dialogue systems. arXiv\npreprint arXiv:2009.13656.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. Bleu: a method for automatic evalu-\nation of machine translation. In Proceedings of the\n40th annual meeting of the Association for Computa-\ntional Linguistics, pages 311–318.\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, An-\nton Bakhtin, Yuxiang Wu, Alexander H Miller, and\nSebastian Riedel. 2019. Language models as knowl-\nedge bases? arXiv preprint arXiv:1909.01066.\nRuize Wang, Duyu Tang, Nan Duan, Zhongyu Wei,\nXuanjing Huang, Guihong Cao, Daxin Jiang, Ming\nZhou, et al. 2020. K-adapter: Infusing knowledge\ninto pre-trained models with adapters. arXiv preprint\narXiv:2002.01808.\n11971\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\net al. 2019. Huggingface’s transformers: State-of-\nthe-art natural language processing. arXiv preprint\narXiv:1910.03771.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. Advances in neural informa-\ntion processing systems, 32.\nFanghua Ye, Jarana Manotumruksa, and Emine Yilmaz.\n2021. Multiwoz 2.4: A multi-domain task-oriented\ndialogue dataset with essential annotation corrections\nto improve state tracking evaluation. arXiv preprint\narXiv:2104.00773.\nXiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara,\nRaghav Gupta, Jianguo Zhang, and Jindong Chen.\n2020. Multiwoz 2.2: A dialogue dataset with addi-\ntional annotation corrections and state tracking base-\nlines. arXiv preprint arXiv:2007.12720.\n11972\nA Atomic vs. Compositional Fact\nFormats\nWhile developing the memorization stage of the\nknowledge injection process, we compared the rela-\ntive utility of representing KB facts as either atomic\nor compositional statements, as measured by the\nmemorization accuracy attained by the adapter-\naugmented PLM. The results of this pilot exper-\niment are summarized in Table 8, which paints a\nmixed picture. While atomic statements result in\nstronger memorization for the restaurant, hotel,\nand attraction domains, compositional statements\nare substantially more effective in the trains do-\nmain. We therefore decided to combine both for-\nmats for our main set of experiments, as the resul-\ntant mixture shows reasonable performance across\nall domains. Furthermore, exposing the model to\ndifferent surface forms of the same underlying in-\nformation is expected to enable better generaliza-\ntion for downstream tasks.\nModel rest hotel attract train\natomic 98.2 99.3 96.7 88.7\ncomposite 95.8 97.6 93.7 97.0\nboth 98.1 98.2 97.6 93.2\nTable 8: Memorization accuracy when training adapters\non different formats of declarative statements. both\ndenotes the combination of atomic and compositional\nstatements. Scores set in bold are the highest in their\nrespective column.\nB Ethical Considerations\nInjection of external knowledge into dialogue mod-\nels may have both ethical and legal implication, if\nsaid knowledge contains personal identifiable in-\nformation (PII), such as social security numbers of\naddresses of private individuals. Such information\nwould be memorized by the adapter-augmented\nmodel and potentially exposed during response\ngeneration, if there are no additional safeguards\nin place to prevent this scenario. For this reason,\nit is crucial to curate the memorized KBs by re-\nmoving any and all instances of PII prior to the\nmemorization stage.\nC Hyper-parameters\nAll models were trained on V100 GPUs, using the\nPyTorch implementation of the BART-Large model\ndistributed as part of the HuggingFace Transform-\ners library (Wolf et al., 2019). The training loop em-\nployed the AdamW (Loshchilov and Hutter, 2017)\noptimizer. By conducting a grid search, we empiri-\ncally determined that a learning rate (LR) of 3e−5\nworked best for fine-tuning RG models and LR of\n1e−6 yielded best results for KPRS. For knowledge\ninjection, LR of 3e−5 was found to be effective.\nIn all cases, LRs were kept constant across all do-\nmains. For all domains and experiments, we re-use\nthe same bottleneck adapter configuration, by set-\nting the size of the hidden layer to 769. All models\nwere trained until convergence by terminating train-\ning after 10 epochs during which no improvement\nhad been observed on the development set.\nD Fact Templates\nThis section provides a complete, exhaustive list of\nall templates used in the generation of declarative\nstatements derived from the MultiWOZ 2.2 KB\nfacts.\n11973\nDomain Fact Type Templates\nrestaurant\naddress The restaurant {} is located at {}.\narea The restaurant {} is located in the {} area of the city.’\nfood The restaurant {} serves {} food.\nphone The phone number of the restaurant {} is {}.\npostcode The postcode of the restaurant {} is {}.\npricerange The restaurant {} is in the {} price range.\ntype {} is a {}.\nhotel\naddress The hotel {} is located at {}.\narea The hotel {} is located in the {} area of the city.\ninternet The hotel {} does{}have free internet.\nparking The hotel {} does{}have free parking.\nphone The phone number of the hotel {} is {}.\npricerange The hotel {} is in the {} price range.\nstars The hotel {} is rated as {} stars.\ntype The hotel {} is a {}.\nattraction\naddress The attraction {} is located at {}.\narea The attraction {} is located in the {} area of the city.\nentrance fee The entrance fee for the attraction {} is {}.\nphone The phone number of the attraction {} is {}.\npostcode The postcode of the attraction {} is {}.\npricerange The attraction {} is in the {} price range.\ntype The attraction {} is {}.\ntrain\narriveBy The {} train arrives at its destination by {}.\nday The {} train operates every {}.\ndeparture The {} train departs from {}.\ndestination The destination of the {} train is {}.\nduration The duration of the journey with the {} train is {}.\nleaveAt The {} train leaves at {}.\nprice The ticket price for the {} train is {}.\nTable 9: An exhaustive list of human-authored templates used to generate atomic statements for use in the\nmemorization stage. Note that each domain is allocated exactly one template per entity attribute. Also note that the\nmask in does{}have allows for negation in cases where the attribute is negative (e.g. if a hotel does not have free\nWiFi).\nDomain Templates\nrestaurant {} is a {} that serves {} food in the {} price range. It is located at\n{}, in the {} area of the city, in the {} postcode. Its phone number is {}.\nhotel The hotel {} is a {} in the {} price range. It is rated {} stars. It is located at {}, in the {} area of the city, in the\n{} postcode. Its phone number is {}. It does{}have free parking and it does{}have free internet.\nattraction The attraction {} is {} in the {} price range. The entrance fee is\n{}. It is located at {}, in the {} area of the city, in the {} postcode. Its phone number is {}.\ntrain The {} train departs from {} every {}. It leaves at {}. Its destination is {} where it arrives at\n{}. The duration of the journey is {}. The ticket price for this train is {}.\nTable 10: An exhaustive list of human-authored templates used to generatecomposite statements for use in the\nmemorization stage.\n11974",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8177894353866577
    },
    {
      "name": "Domain knowledge",
      "score": 0.7043003439903259
    },
    {
      "name": "Task (project management)",
      "score": 0.6725436449050903
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5585734248161316
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5274617671966553
    },
    {
      "name": "Natural language processing",
      "score": 0.4949745535850525
    },
    {
      "name": "Language model",
      "score": 0.42965489625930786
    },
    {
      "name": "Knowledge-based systems",
      "score": 0.4124416410923004
    },
    {
      "name": "Machine learning",
      "score": 0.36785733699798584
    },
    {
      "name": "Engineering",
      "score": 0.07894867658615112
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}