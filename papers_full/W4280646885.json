{
  "title": "Tweets Topic Classification and Sentiment Analysis Based on Transformer-Based Language Models",
  "url": "https://openalex.org/W4280646885",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2152378888",
      "name": "Ranju Mandal",
      "affiliations": [
        "Griffith University"
      ]
    },
    {
      "id": "https://openalex.org/A2095704844",
      "name": "Jin-Yan Chen",
      "affiliations": [
        "Griffith University"
      ]
    },
    {
      "id": "https://openalex.org/A2184250878",
      "name": "Susanne Becken",
      "affiliations": [
        "Griffith University"
      ]
    },
    {
      "id": "https://openalex.org/A1906233575",
      "name": "Bela Stantic",
      "affiliations": [
        "Griffith University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3198167326",
    "https://openalex.org/W2910636646",
    "https://openalex.org/W2790694086",
    "https://openalex.org/W2942903528",
    "https://openalex.org/W2743481586",
    "https://openalex.org/W2294587711",
    "https://openalex.org/W3047782976",
    "https://openalex.org/W3210605734",
    "https://openalex.org/W2099813784",
    "https://openalex.org/W2951398196",
    "https://openalex.org/W2053968437",
    "https://openalex.org/W2774008574",
    "https://openalex.org/W2137349054",
    "https://openalex.org/W2097089247",
    "https://openalex.org/W1993108184",
    "https://openalex.org/W2232290562",
    "https://openalex.org/W2962739339",
    "https://openalex.org/W3151835558"
  ],
  "abstract": "People provide information on their thoughts, perceptions, and activities through a wide range of channels, including social media. The wide acceptance of social media results in vast volume of valuable data, in variety of format as well as veracity. Analysis of such ‘big data’ allows organizations and analysts to make better and faster decisions. However, this data had to be quantified and information has to be extracted, which can be very challenging because of possible data ambiguity and complexity. To address information extraction, many analytic techniques, such as text mining, machine learning, predictive analytics, and diverse natural language processing, have been proposed in the literature. Recent advances in Natural Language Understanding-based techniques more specifically transformer-based architectures can solve sequence-to-sequence modeling tasks while handling long-range dependencies efficiently. In this work, we applied transformer-based sequence modeling on short texts’ topic classification and sentiment analysis from user-posted tweets. Applicability of models is investigated on posts from the Great Barrier Reef tweet dataset and obtained findings are encouraging providing insight that can be valuable for researchers working on classification of large datasets as well as large number of target classes.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8333926796913147
    },
    {
      "name": "Sentiment analysis",
      "score": 0.6646102666854858
    },
    {
      "name": "Transformer",
      "score": 0.5917146801948547
    },
    {
      "name": "Ambiguity",
      "score": 0.5772219300270081
    },
    {
      "name": "Data science",
      "score": 0.5771993398666382
    },
    {
      "name": "Information extraction",
      "score": 0.5290417075157166
    },
    {
      "name": "Social media",
      "score": 0.5173968076705933
    },
    {
      "name": "Natural language",
      "score": 0.49880385398864746
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4332340955734253
    },
    {
      "name": "Language model",
      "score": 0.43057355284690857
    },
    {
      "name": "Big data",
      "score": 0.4299026131629944
    },
    {
      "name": "Data mining",
      "score": 0.4199329614639282
    },
    {
      "name": "Machine learning",
      "score": 0.4117041230201721
    },
    {
      "name": "Information retrieval",
      "score": 0.36643344163894653
    },
    {
      "name": "Natural language processing",
      "score": 0.33681827783584595
    },
    {
      "name": "World Wide Web",
      "score": 0.22256812453269958
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}