{
  "title": "Data extraction from polymer literature using large language models",
  "url": "https://openalex.org/W4405590246",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2188313226",
      "name": "Sonakshi Gupta",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3011941017",
      "name": "Akhlak Mahmood",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2134401640",
      "name": "Pranav Shetty",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5108947361",
      "name": "Aishat Adeboye",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2443284501",
      "name": "Rampi Ramprasad",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2188313226",
      "name": "Sonakshi Gupta",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3011941017",
      "name": "Akhlak Mahmood",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2134401640",
      "name": "Pranav Shetty",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5108947361",
      "name": "Aishat Adeboye",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2443284501",
      "name": "Rampi Ramprasad",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3095028680",
    "https://openalex.org/W3196212666",
    "https://openalex.org/W3127365350",
    "https://openalex.org/W4297831469",
    "https://openalex.org/W3100445615",
    "https://openalex.org/W2980932864",
    "https://openalex.org/W4384914963",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W4362640271",
    "https://openalex.org/W3046375318",
    "https://openalex.org/W4224442790",
    "https://openalex.org/W3115677442",
    "https://openalex.org/W3212619479",
    "https://openalex.org/W4388593316",
    "https://openalex.org/W4391846075",
    "https://openalex.org/W4295857769",
    "https://openalex.org/W4392402185",
    "https://openalex.org/W2963809228",
    "https://openalex.org/W4391836235",
    "https://openalex.org/W4385027818",
    "https://openalex.org/W4392002118",
    "https://openalex.org/W3112850967",
    "https://openalex.org/W4384200891",
    "https://openalex.org/W4404781996",
    "https://openalex.org/W4387573006",
    "https://openalex.org/W1994282576",
    "https://openalex.org/W2996001033",
    "https://openalex.org/W3178873356",
    "https://openalex.org/W4221047533",
    "https://openalex.org/W4392921865",
    "https://openalex.org/W4385571746",
    "https://openalex.org/W4293061803"
  ],
  "abstract": "Abstract Automated data extraction from materials science literature at scale using artificial intelligence and natural language processing techniques is critical to advance materials discovery. However, this process for large spans of text continues to be a challenge due to the specific nature and styles of scientific manuscripts. In this study, we present a framework to automatically extract polymer-property data from full-text journal articles using commercially available (GPT-3.5) and open-source (LlaMa 2) large language models (LLM), in tandem with the named entity recognition (NER)-based MaterialsBERT model. Leveraging a corpus of ~ 2.4 million full text articles, our method successfully identified and processed around 681,000 polymer-related articles, resulting in the extraction of over one million records corresponding to 24 properties of over 106,000 unique polymers. We additionally conducted an extensive evaluation of the performance and associated costs of the LLMs used for data extraction, compared to the NER model. We suggest methodologies to optimize costs, provide insights on effective inference via in-context few-shots learning, and illuminate gaps and opportunities for future studies utilizing LLMs for natural language processing in polymer science. The extracted polymer-property data has been made publicly available for the wider scientific community via the Polymer Scholar website.",
  "full_text": "communicationsmaterials Article\nhttps://doi.org/10.1038/s43246-024-00708-9\nData extraction from polymer literature\nusing large language models\nCheck for updates\nSonakshi Gupta1,4, Akhlak Mahmood 2,4, Pranav Shetty1, Aishat Adeboye3 & Rampi Ramprasad 2\nAutomated data extraction from materials science literature at scale using artiﬁcial intelligence and\nnatural language processing techniques is critical to advance materials discovery. However, this\nprocess for large spans of text continues to be a challenge due to the speciﬁc nature and styles of\nscientiﬁc manuscripts. In this study, we present a framework to automatically extract polymer-\nproperty data from full-text journal articles using commercially available (GPT-3.5) and open-source\n(LlaMa 2) large language models (LLM), in tandem with the named entity recognition (NER)-based\nMaterialsBERT model. Leveraging a corpus of ~ 2.4 million full text articles, our method successfully\nidentiﬁed and processed around 681,000 polymer-related articles, resulting in the extraction of over\none million records corresponding to 24 properties of over 106,000 unique polymers. We additionally\nconducted an extensive evaluation of the performance and associated costs of the LLMs used for data\nextraction, compared to the NER model. We suggest methodologies to optimize costs, provide\ninsights on effective inference via in-context few-shots learning, and illuminate gaps and opportunities\nfor future studies utilizing LLMs for natural language processing in polymer science. The extracted\npolymer-property data has been made publicly available for the wider scientiﬁc community via the\nPolymer Scholar website.\nThe ﬁeld of materials informatics1,2 suffers from lack of data readiness and\ndata accessibility. Although materialsdata can be systematically generated\nthrough computational and physical experiments, a substantial amount of\nhistorical data is trapped in publishedliterature. An ever-growing volume of\ndata is continually released in scientiﬁc journal articles, but this data fre-\nquently exists in unstructured natural language text formats, posing chal-\nlenges for immediate utilization by modern informatics that rely on the\navailability of structured datasets. Natural language processing (NLP)\ntechniques implemented in materials science seek to automatically extract\nmaterials insights, materials properties, and synthesis data from a corpus of\ntext documents, and propose hypotheses and designs for new materials\n3– 5.\nAfter acquiring the corpus, a series of complex NLP operations are per-\nformed which include turning texts into smaller units called tokens,\nrecognizing key entities (such as materials, characterization methods, or\nproperties) using named entity recognition (NER) methods, creating rule-\nbased algorithms to identify relationships between the entities through\ndependency parsing, andﬁnally, extracting information and organizing it\ninto a structured format\n6.\nWith the advent of modern machine learning (ML) and artiﬁcial\nintelligence techniques, deep learning models including recurrent neural\nnetworks and long short-term memory architectures have become valuable\nfor NER tasks7,8. In recent years, the transformer-based BERT architecture,\nwith its ability to capture contextual and semantic relationships within\nscientiﬁct e x t s9, has especially demonstrated superior performance com-\npared to traditional neural network models10. We have previously developed\nand published MaterialsBERT 11, a NER model derived from\nPubMedBERT12. This model demonstrated superior performance on pub-\nlicly available datasets in comparison to other BERT models, including\nChemBERT13 and MatBERT14, particularly for materials science-speciﬁc\ndata extraction tasks. By employing aMaterialsBERT-based pipeline, we\nsuccessfully extracted over 300,000 polymer-property records from\napproximately 130,000 abstracts, the largest such undertaking at that time,\nwith the data made publicly available\n15. This data extraction approach\ndemonstrated the effectiveness of theMaterialsBERT model in processing a\nsubstantial volume of abstracts to obtain polymer-property information.\nThe potential for large-scale data extraction using MaterialsBERT from the\nfull texts of journal articles presentsa further new opportunity for materials\ndata acquisition.\nWhile NER models excel in identifying named entities within texts,\ndiscerning entity relationships across extended passages encompassing\n1School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, USA.2School of Materials Science and Engineering, Georgia\nInstitute of Technology, Atlanta, GA, USA.3School of Chemical and Biomolecular Engineering, Georgia Institute of Technology, Atlanta, GA, USA.4These authors\ncontributed equally: Sonakshi Gupta, Akhlak Mahmood. e-mail: rampi.ramprasad@mse.gatech.edu\nCommunications Materials|           (2024) 5:269 1\n1234567890():,;\n1234567890():,;\nmultiple sentences solely through recognized named entities continues to be\na challenge16. This limitation is particularly pronounced in technical and\nscientiﬁc documents, where critical information is often expressed in a non-\nstandard and complex manner. In the domain of polymer science, NER-\nbased extraction methods encounter additional speciﬁcc h a l l e n g e ss t e m -\nming from the expansive chemical design space of the materials and the\nutilization of non-standard nomenclature, including commonly used\nnames, acronyms, synonyms, and historical terms\n17.\nRecently, large language models (LLMs) such as Generative Pretrained\nTransformer (GPT), Large Language Model Meta AI (LlaMa), Pathways\nLanguage Model, etc., have gained signiﬁcant attention in theﬁeld of natural\nlanguage processing\n18,19. These models have shown remarkable perfor-\nmance in handling various NLP tasks, showcasing their robustness and\nversatility\n20, especially in high-performance text classiﬁc a t i o n ,N E R ,a n d\nextractive question answering with limited datasets21.Ak e yf a c t o rc o n -\ntributing to the success of the LLMs is the vast amount of‘knowledge’these\nmodels gain during semi-supervised pre-training (e.g., using masked lan-\nguage modeling to predict the next token given a set of preceding tokens for\ncontext)\n22. In the pre-training phase, LLMs acquire a foundational com-\nprehension of language semantics andcontextual understanding through\nexposure to training datasets, whichtypically comprise texts from general\nscience and scientiﬁc literature23. Subsequently, the pre-trained LLMs, also\nreferred to as base models, undergo supervisedﬁne-tuning to produce\ndesired text outputs in response to speciﬁc prompts or instructions.\nExamples include OpenAI Codex and Code LlaMa, both of which areﬁne-\ntuned to generate code snippets based on a given natural language input24.\nSimilarly, ChatGPT and LlaMa Chat models are language modelsﬁne-\ntuned to respond to user prompts or instructions conversationally while\nmaintaining a history of previous interactions for added context for the\nconversation. A human-like understanding of the language semantics and\nsubsequent instruction tuning thus enable the LLMs to perform in-domain\nt a s k ss u c ha si n f o r m a t i o nextraction about a speciﬁc material class with no\n(zero-shot) to only a few task-speciﬁc examples (few-shots). Such ability\noffers excellent performance and eliminates the efforts needed to create a\nlabeled dataset of signiﬁcant volume and train orﬁne-tune a new model\n25.\nDespite the potential for many use cases including data extraction, the\nimproved capabilities of the LLMs depend on access to signiﬁcant com-\nputational resources. Using LLMs for inference incurs signiﬁcant monetary\ncosts, due to high demands of energy consumption, hardware or cloud\ncomputing time, and in terms of the environment, due to the carbon\nfootprint of powering a number of modern tensor processing units26,27.\nTherefore, a data extraction pipeline aiming to efﬁciently utilize LLMs\nshould extract the maximum amount of high-quality information and at the\nsame time reduce the unnecessary prompting of the LLMs during the\nprocessing of millions of full-text scientiﬁc articles.\nLimited prior works exist on the application of LLMs for data extrac-\ntion in materials science. Dagdelen et al.ﬁne-tuned GPT-3.5 and LlaMa 2\nmodels to extract useful records of linking dopants and host metal-organic\nframeworks28. Zheng et al. developed a workﬂow utilizing ChatGPT as a\ncollaborator for human chemists, extracting 26,257 distinct synthesis\nparameters of approximately 800 metal-organic frameworks from 228\narticles29. Polak and Morgan proposed a similar workﬂow for metallic\nglasses and high entropy alloys, employing follow-up questions to GPT-4 to\nensure correctness and address the issues of hallucinations with LLMs30.\nSimilarly, Yang et al. used a repeated questioning strategy with GPT-4 for\nbandgap values, demonstrating reduced error rates and a more extensive\ndataset than human-curated databases31. GPT-based approach offered\nhigh-performance text classiﬁcation, NER, and ex tractive question\nanswering with limited datasets, andcould reduce researcher workload by\nproducing initial labelling sets and verifying human-annotations.\nIn this contribution, we present an approach to employing LLM- and\nNER-based pipelines, speciﬁcally designed to automate the extraction of\nproperty data of polymers from the full-text contents of journal articles. Our\ndata extraction workﬂow, depicted in Fig.1, processes a corpus of 2.4 million\nmaterials science journal articles published in the last two decades, from\nwhich, we identify and concentrate on 681,000 polymer-related articles.\nSubsequently, the paragraphs of the articles are processed through a dual-\nstage ﬁltering scheme consisting of a‘heuristic ﬁlter’ and a‘NER ﬁlter’ to\nidentify the most relevant paragraphs that contain extractable property data.\nThe materials and properties are identiﬁed, relationships are established,\nand the information is extracted in a structured format using Materi-\nalsBERT and GPT-3.5 models independently. Our pipelines extracted more\nthan one million values of 24 selected properties from the full texts of the\npolymer-related articles. We have madethe extracted data publicly available\nat polymerscholar.org(henceforth referred to as Polymer Scholar) where\nresearchers can explore the distribution and relationships within the\nproperties of polymers\n15. To identify the most efﬁcient model, with a special\nfocus on optimizing quality and costs, we evaluate three models– Materi-\nFig. 1 | Overall workﬂow to extract polymer property data. aPolymer-speciﬁc\ndocuments are selected from a corpus of 2.4 million materials science journal arti-\ncles. Multiple stages ofﬁltering select the most relevant documents and paragraphs\nof the documents before performing data extraction by MaterialsBERT and GPT-\n3.5. Extracted data areﬁnally deposited to a relational database of the Polymer\nScholar web interface.b Property-speciﬁc paragraphs are selected by a heuristicﬁlter\nbased on string matching and dictionary lookup.c The NERﬁlter identiﬁes para-\ngraphs with extractable named entities. The LlaMa-2 large language model was also\nevaluated, but was not used in theﬁnal data extraction pipeline due to comparatively\nlow performance and long inference time, as described later in the text.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 2\nalsBERT, GPT-3.5, and LlaMa 2, across four critical performance categories:\nquantity, quality, time, and cost of data extraction. Our study undertakes a\nthorough examination of the capabilities of the LLMs, juxtaposing their\nperformance against MaterialsBERT. We also present results offering\ninsights into optimizing the performance and costs associated with using\nLLMs for data extraction via in-context few-shots learning and analyzing\nthe general trends, characteristics, anddistributions of the extracted full text\ndata. We conclude by addressing the remaining challenges and looking\nahead at the future potential of utilizing LLMs for informatics tasks speciﬁc\nto polymer science.\nResults and discussion\nOverview of the data extraction pipelines\nWe assembled a corpus comprising morethan 2.4 million materials science\njournal articles published over the last two decades. The articles were initially\nindexed through the Crossref database,followed by authorized downloads\nfrom 11 publishers, including Elsevier, Wiley, Springer Nature, American\nChemical Society, and the Royal Society of Chemistry. Further details\nregarding the articles can be found in the Methods section and in ref.32.\nSpeciﬁcally focusing on polymer-related content, we identiﬁed 681,000\ndocuments by searching for the term‘poly’ in the title and abstract of the\narticles. Extracting information from these polymer-related documents\ninvolved treating individual paragraphs as text units, resulting in a total of\n23.3 million paragraphs. To extract data from the selected paragraphs, we\ntargeted 24 properties of polymers based on their signiﬁcance and down-\nstream usage. Commonly reported thermal and optical properties were\nselected for their efﬁcacy in training multi-task ML models, using highly\ncorrelated properties as substitutes for less prevalent ones. Additionally,\nproperties that are beneﬁcial for various polymer application areas were\nincluded. For instance, the bandgap and refractive index are vital for\ndielectric aging and breakdown, gas permeability properties are crucial for\nﬁltering and distillation applications, and mechanical properties are sig-\nniﬁcant for thermosets and recyclable polymers. A list of the polymer\np r o p e r t i e ss e l e c t e df o re x t r a c t i o nc a nb ef o u n di nT a b l e1.\nAt w o - s t e pﬁltering system was used to avoid unnecessary prompting\nof LLMs by ignoring texts that do not have extractable and complete data.\nFirst, as illustrated in Fig.1b, each paragraph was passed through property-\nspeciﬁc heuristicﬁlters to detect paragraphs that mention a target polymer\nproperty or its co-referents manually curated via literature review.\nApproximately 2.6 million paragraphs (~11%) successfully passed the\nproperty-speciﬁc heuristicﬁlters, indicating relevance to the selected 24\nproperties of polymers. Subsequently, an additional NERﬁlter was applied\nto identify paragraphs containingall necessary named entities such as\nmaterial name, property name, and property value (Fig.1c) to conﬁrm the\nexistence of a complete extractable record. This reﬁnedﬁltering stage yielded\nabout 716,000 paragraphs (~3%) containing texts relevant to the selected 24\nproperties. Regardless of theﬁnal data extraction model, the NERﬁlter is\nutilized to verify the presence of‘material’, ‘property’, ‘value’,a n d‘unit’\nentities in the given paragraph because the absence of any of these entities\nwould preclude the extraction of a complete data point by the models. This\nﬁlter thus assists LLMs in accurately identifying relationships without which\nthey may generate placeholder values such as‘\nnot mentioned’, ‘n/a’,o r‘-’,o r\neven hallucinate false data if an entity is not present in the text.\nThe texts of theﬁltered paragraphs are then passed to either Materi-\nalsBERT for NER-based data extraction, or to the OpenAI API for GPT-3.5-\nbased data extraction. During the extraction process, the relationship\nextraction module ofMaterialsBERT processes the identiﬁed entities to\ndetermine and establish correct relationships using heuristic rules. GPT-3.5,\non the other hand, automatically identiﬁes relationships between the entities\nby itself. Finally, the extracted data undergo post-processing, validation, and\ndeposition into a relational database and the data stored in the database is\nmade publicly accessible for visualization via a user-friendly web interface of\nPolymer Scholar. In total, the pipelines extracted over one million polymer-\nproperty records from the full texts. Data extracted by GPT-3.5 (Materi-\nalsBERT) from the full text is approximately 21 times (12 times) than what\nwas collected purely from the abstracts in our previous work for the selected\n24 properties. Additional details about the different stages of the pipelines\nare discussed in the Methods section, with speciﬁc details on data extraction\nusing MaterialsBERT provided in ref.11.\nData extraction using large language models\nPolymer-related property data from a journal article can be extracted by\nleveraging the ability of LLMs to understand the specialized semantics of\nmaterials entities discussed in the text. However, obtaining the desired\noutput from an LLM poses a challenging task and is presently a subject of\nactive research\n33,34. Even with the same prompt or instruction and text\ngeneration parameters, the LLMs can produce varying responses35.T h e\neffectiveness of simple natural language prompts in eliciting desired results\nfrom LLMs is not always straightforward, due to the models’interpretation\nmethods often being non-intuitive36. Hence, it is crucial to employ techni-\nques and parameters that can minimize the variability in the generated\nresponses.\nTable 1 | List of the selected 24 property names and the\ncorresponding number of property values extracted using the\nGPT-3.5 and MaterialsBERT pipelines\nProperty GPT-3.5 MaterialsBERT MaterialsBERT\nFull text Full text Abstract\nGlass transition\ntemperature\n125,585 75,722 6155\nMelting temperature 76,577 41,766 1615\nThermal\ndecomposition\ntemperature\n70,285 19,817 1479\nLower critical\nsolution temperature\n20,115 11,658 712\nCrystallization\ntemperature\n12,863 4045 605\nThermal conductivity 5574 10,300 1429\nUpper critical\nsolution temperature\n1486 581 50\nBandgap 63,361 30,732 2245\nIon exchange\ncapacity\n3118 4656 1034\nRefractive index 18,982 9785 576\nTensile strength 63,014 38,773 4382\nYoung’s modulus 40,148 32,207 1904\nElongation at break 30,754 15,072 1499\nCompressive\nstrength\n12,343 6879 814\nFlexural strength 7201 3543 313\nHardness 5271 1984 244\nWater contact angle 84,601 63,685 3932\nWater uptake 15,991 6019 330\nLimiting\noxygen index\n7893 6606 1146\nCO\n2 permeability 2943 2561 685\nSwelling degree 1880 1995 71\nMethanol\npermeability\n1228 852 174\nO\n2 permeability 735 503 99\nH2 permeability 501 1072 46\nTotal 672,449 390,813 31,539\nThe number of data records extracted from the abstracts alone using MaterialsBERT are taken from\nref. 11 for comparison against the full text data extraction.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 3\nOne of the intriguing capabilitiesof LLMs, referred to as in-context\nfew-shot learning, is their ability to learn from examples (often termed as\n‘shots’) prepended to the prompt\n25. The response generation can be sufﬁ-\nciently inﬂuenced by the shots and the prompt given to the model as inputs.\nFor few-shot learning, we used a pool of examples containing manually\ncurated 595 glass transition temperature (Tg) values and 356 bandgap\nvalues from 630 abstracts. Given the necessity for the LLM’s response to be\npresented in a structured format for seamless programmatic extraction of\nmaterial names and property values, we experimented with different\nprompts. Weﬁnally selected one that directs the model to identify entities of\ninterest, reading:“Extract all<property>values in JSONL format with\n‘material’, ‘property’, ‘value’, ‘condition’ columns.” The placeholder\n<property> is replaced with the desired polymer property names we\nchose to extract. A sample shot, shown in Fig.2a, displays glass transition\ntemperature data manually curated from the abstract of ref.37 and the\ncorresponding prompt. The formatted response in the example adheres to\nthe JSONL structure, serving as a demonstration to the model that its\ngenerated response should precisely follow the same format. The shot is\nfollowed by the actual prompt containing the input text from which data\nneeds to be extracted. Fig.2b provides an illustrative example of such a\nprompt, comprising a paragraph taken from the full text of ref.38,a l o n g\nwith speciﬁc instructions given to the LLM for data extraction. The resulting\nresponse from GPT-3.5 is shown in Fig.2c, revealing three data points of\nglass transition temperature values extracted by the LLM.\nOur similarity-based shot selection method, illustrated in Fig.2e,\nprovides a way to determine the most suitable example from the pool of\nexamples for inclusion as a shot along with the LLM prompt. Weﬁrst\nperformedk-means clustering (withk = 10) on the word embeddings of the\nexamples. The embeddings of the examples and input text were determined\nusing the MaterialsBERT text encoder. Subsequently, we selected the\nexample corresponding to the centroid of the cluster closest to the input text\nwhich is sent to the LLM for data extraction. This method, as opposed to\nrandom selection, allows us to choose an example that closely resembles the\ntext from which data needs to be extracted.\nTo assess the monetary costs associated with text generation using\nGPT-3.5, we counted the number of OpenAI tokens in the input prompts\nand shots while extracting property data from the 630 manually curated\nabstracts. The tokenization process employed by the LLMs depends on the\nlinguistic characteristics and contextual nuances of the words, numbers,\npunctuations, and symbols present in a given text. Our initial evaluations\nnevertheless reveal a direct correlation between the number of tokens and\nthe word count within the selected abstracts, as depicted in Fig.2f, which\nprovides an approximate but simpler way to understand the effects of the\ntext lengths on computational expenses associated with using GPT-3.5.\nCosts during text generation directly increase with the number of words\nbeing processed. Furthermore, the introduction of multiple shots as an\nadditional component in the input requires the LLM to consider extended\ntextual inputs during response generation. A linear increase in both token\nFig. 2 | Data extraction using large language models. aExample of a shot generated\nfrom the text of a manually curated dataset containing glass transition temperature\nand bandgap values.b Prompt used to extract data using LLM.c Response generated\nby GPT-3.5 andd Tg data extracted from the response text.e Schematic illustration\nof clusters formed by word embeddings of the texts of 630 manually curated abstracts\nand choice of the shot most similar to the text from which data is to be extracted.\nf Correlation between token count and number of words in 630 abstracts related to\npolymers. The positivey-intercept is attributable to the average expected number of\npunctuation marks and symbols typically found in the texts.g Barchart depicting an\nincrease in the number of tokens and the ultimate cost for OpenAI API usage for\nmultiple shots.h Effects of multiple shots on the accuracy of the extracted Tg and\nbandgap data from the manually curated 630 abstracts.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 4\nutilization and corresponding API usage can be observed in Fig.2gw i t ha n\nincreasing number of shots used to extract data from the 630 abstracts.\nDespite the expectation that the model’s performance would improve\nwith an increased number of shots, we consistently observed optimal results\nwhen providing only a single shot to GPT-3.5 while prompting for\nextraction of Tg and bandgap values (see Fig.2h). A plausible explanation\nf o rt h i sp h e n o m e n o nc o u l db et h a tt he model learns the structure of the\nanticipated output immediately from a single shot and experiences dis-\norientation when additional shots areadded to the prompt. Based on these\nobservations, we proceeded to use one shot while prompting the LLM to\nextract data from a given text.\nPerformance benchmarking for a labeled subset of the\nfull corpus\nWe employ NER- and LLM-based extraction methods to comparatively\nassess the validity and reliability of different data extraction pipelines. The\nprimary objective of this assessment is to identify the most effective\nextraction methods while emphasizing the optimization of computational\nand monetary costs. Consequently, the evaluation involves a subset of\n1000 articles from the larger pool of the 681,000 polymer-related papers.\nIn this subset, we have manually curated data from the abstracts of 630\narticles, which reported one or more Tg and bandgap values in their\nabstracts and were selected randomly. The rest of the 370 articles were\nrandomly chosen from the polymer papers. Bar charts containing the\ndistribution of the selected articles compared to the full corpus are shown\nin Fig. S1.\nThe assessment pipeline, depicted in Fig.3a, involves parsing the full\ntexts of the selected papers into paragraphs, resulting in a total of 37,434\nparagraphs. As discussed in the previous section, twoﬁltering stages are\nemployed to select the most relevant paragraphs for a target property and\nparagraphs containing extractable data. In theﬁrst stage, the property-\nspeciﬁc heuristicﬁlter is applied, resulting in a reduction of the paragraph\ncount to 12,817. Subsequently, the second stage utilizes the MaterialsBERT-\nbased NERﬁlter, further narrowing the selection to 6179 paragraphs. The\nﬁnal data extraction process involves three models: MaterialsBERT, incor-\nporating NER and rule-based entity recognition and relationship extraction;\nthe open-source 70 B LlaMa-2 model developed by Meta AI; and the\ncommercially available GPT-3.5 model hosted by OpenAI. To determine\nthe optimal shot for each prompt in theLLM-based data extraction process,\nwe compared our strategy based on similarity to a random selection of shots\nfrom the curated data pool. We termed these approaches as“Similar” and\n“Random” shot selection methods, respectively.\nIn terms of quantity, (Fig.3c, d) GPT-3.5 demonstrates signiﬁcant\nsuperiority over the other models. It extracted the largest amount of data,\ncomprising 4706 material-property value pairs using Random-shot and\n4589 pairs using Similar-shot selection from the selected 6179 paragraphs.\nFig. 3 | Performance evaluation of NER and LLM pipelines. aOverview of the\npipelines used to measure the performance of MaterialsBERT, LlaMa-2, and GPT-\n3.5 for data extraction from 1000 polymer documents.b Representation ofF1 score\nmeasurement using manually curated data.c, d Total number of materials and\nproperty data extracted using the pipelines,e time spent running the pipelines,\nf, g calculated F1 scores for Tg and bandgap respectively andh incurred cost due to\nAPI usage by the pipelines.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 5\nThe NER-based MaterialsBERT pipeline extracted 3631 material-property\npairs, slightly outperforming LLaMa, which extracted 3441 data pairs.\nTo assess extracted data quality, we checked if the extracted material\nname, property name, and property value (including unit) match the\nmanually curated records (Fig.3b) to calculate theF1 scores. OurF1 score\ncomputation methodology necessitates that the extracted data be com-\npletely present within the provided text. Thus, to ensure precise data\nextraction, it is imperative to identify all entities, speciﬁcally ‘material’,\n‘property’, ‘value’,a n d‘unit’within the speciﬁed paragraph. Furthermore, to\nverify the correct relationships amongthese entities, they must correspond\naccurately with their respective entities in the curated dataset to account for\nhallucination by the LLMs. TheF\n1 score calculation method not only veriﬁes\nthe accuracy of the completely extracted data but also conﬁrms their origin\nfrom the appropriate source paragraph, because any semantically accurate\nbut fabricated data points produced byLLMs would be absent in the curated\nground truth data extracted from the provided text. Additional details about\nthe calculation of the F\n1 score are discussed in the Supplementary\nDiscussion.\nWe found that the performance of the models is contingent on the\nproperty being extracted. Both LLMs exhibit superior performance relative\nto the NER-based MaterialsBERT pipeline in extracting data for bandgap,\nwhile accuracy declines when extracting data for Tg (Fig.3f, g). GPT-3.5\nachieved the highestF\n1 score of 0.67 for Tg, with the Similar-shot selection\nmethod slightly outperforming theRandom selection method. Materi-\nalsBERT and LlaMa obtainedF1 scores of 0.63 and 0.64, respectively. LlaMa\n2 outperformed the comparatively lowerF1 score of 0.66 achieved using\nMaterialsBERT, particularly during the extraction of bandgap, where it\nachieved an accuracy of 0.77. GPT-3.5 once again secured the highestF1\nscores of 0.87 and 0.85 for the Random and Similar-shot selection methods,\nrespectively. We previously demonstrated the superior performance of\nMaterialsBERT compared to other existing NER models11.T h eh i g h e rF1\nscores compared to the MaterialsBERT obtained in this work thus under-\nscores the advantage of the LLMsover the existing NER models.\nConcerning computational efﬁciency and monetary costs, Materi-\nalsBERT emerges as the most advantageous choice (Fig.3e). Operated in-\nhouse, MaterialsBERT processed the6179 paragraphs in under half hour\nwithout incurring anyﬁnancial costs. LlaMa-2, also hosted locally, imposed\nno direct monetary costs but demonstrated the longest inference time,\nattributable to its substantial model size of 70 billion parameters running on\nfour Nvidia Quadro GP 100 GPU cards. In contrast, the commercial LLM,\nGPT-3.5, required API calls to OpenAI’s servers for inference, introducing a\ndirect ﬁnancial cost of$4.48 (for ~2.9 million tokens) for each of the shot\nselection methods (Fig.3h).\nThis thorough evaluation allowed us to identify the best models for\ndata extraction from the full corpus. Given GPT-3.5’s superior performance\nin both quantity and quality and MaterialsBERT’s optimal cost efﬁciency,\nwe chose to incorporate GPT-3.5 with Similar-shot selection and Materi-\nalsBERT in ourﬁnal pipeline to extract data for all the selected properties\nfrom the entire corpus of polymer articles.\nData extraction from full texts\nHaving selected the best-performing models, we extracted data for the\n24 selected properties from the full texts of 681, 000 polymer-related journal\narticles using the NER-based MaterialsBERT and the LLM-based GPT-3.5\npipelines. Given that neither pipeline can achieve perfect accuracy, and\nmanually curating data sets for all 24 properties requires a signiﬁcant effort,\nwe conducted additional validation of the extracted data in a post-\nprocessing step. After programmatically obtaining the data from the\nMaterialsBERT pipeline and JSONL responses generated by GPT-3.5, we\nveriﬁed if the property name matched one of the selected 24 property names\nor their known variations. We standardized the extracted values and units\nwithin the extraction pipelines, such as converting kPa or GPa to MPa, K to\n°C, etc. Subsequently, in the post-processing stage, we checked if the unit of\nthe extracted data matched the unit corresponding to the selected property.\nAdditionally, we assessed if the extracted value for each property fell within a\nspeciﬁed minimum and maximum range, that was manually assigned based\non literature review. We ignored any extracted data that does not satisfy\nthese post-processing validation criteria. In addition to the polymers, the\npipelines also extracted property data for other classes of materials. To\nidentify the polymers, we checked if theextracted material is a valid polymer\nname by cross-referencing it with a comprehensive, albeit non-exhaustive,\nlist of polymer names manually collected from the literature.\nFrom the GPT-3.5 pipeline, we extracted 672,449 polymer-property\nrecords, and from the MaterialsBERT pipeline, we obtained 390,813 records\nfor the 24 selected properties that passed the validation stage (see Table1). In\nassessing the number of data points extracted for the selected properties, the\nGPT-3.5 pipeline demonstrated superior performance compared to the\nMaterialsBERT pipeline. Speciﬁcally, with the full text, the LLM extracted\ndata volume was 72% greater than the data extracted by the NER pipeline,\nand 21 times the data extracted from abstracts (using the NER pipeline) in\nref. 11. Among the extracted data, thermal and mechanical properties were\nmore commonly found in the literature, while data on gas permeability was\ncomparatively sparse.\nFigure 4a, b illustrates the distribution of extracted Tg and bandgap\ndata, respectively. For comparativepurposes, we have also presented the\ndistributions of Tg and bandgap data extracted from abstracts using\nMaterialsBERT which show a signiﬁcantly higher amount of data extracted\nfrom the full texts. Though not obvious in the distribution of extracted data\nfrom abstracts, a bimodal distributionof Tg values and an elongated tail can\nbe observed for all pipelines, demonstrating the presence of extreme\nproperty values. A comparative analysis of full-text extraction using\nMaterialsBERT reveals 75,722 valid Tg records, which is about 12 times the\ndata extracted from abstracts earlier. This corresponds to 20,511 unique\nmaterials. Further, it provides 30,732 valid bandgap records, indicating 13\ntimes the abstract extracted data and corresponds to 10,627 unique mate-\nrials. In contrast, the GPT-3.5 pipeline provides a higher volume of valid\nrecords, amassing 125,585 Tg records,a 65% increase over MaterialsBERT\nand 20 times the data extracted from abstracts. This pertains to 69,740\nunique materials. Similarly, GPT-3.5 yielded 106% more bandgap data than\nMaterialsBERT (63,361 records), which is 28 times the data obtained from\nabstracts, for a total of 31,337 unique materials.\nUpon comparing the valid data points of Tg and bandgap that passed\nthe post-processing criteria, we observed that each pipeline retrieved data\nfrom the source paragraphs where the other pipeline encountered difﬁ-\nculties (Fig.4c). This supports the previously reportedF\n1 scores, demon-\nstrating that GPT-3.5 is capable of understanding more intricate\nrelationships and extracting more data. Notably, there is a signiﬁcant\nnumber of paragraphs where MaterialsBERT fails (F\n1 =0 . 6 6 ) ,i nc o n t r a s tt o\nthe success of GPT-3.5 (F1 = 0.85). Speciﬁcally, GPT-3.5 extracted data from\nan additional 47,966 paragraphs, from which MaterialsBERT failed to\nextract any valid data. Conversely, MaterialsBERT successfully extracted\ndata from 7311 paragraphs where the GPT-3.5 pipeline did not retrieve any\nvalid data.\nThe combined data extraction efforts of both pipelines resulted in a\ntotal of 113,099 unique materials for Tg and bandgap. Notably, only 11,042\nmaterial names exactly matched between the pipelines, as illustrated in\nFig. 4d, and parity plots showing overlap between the pipelines in Fig. S2.\nGPT-3.5 demonstrated its proﬁciency by extracting an additional 88,128\nmaterial names that were not captured by MaterialsBERT. This signiﬁcant\nincrease in the identiﬁcation of new material names can be attributed to\nGPT-3.5’s inclination towards detailed extraction of composition and types\nwhile extracting material names (see Table S3). It is important to mention\nthat variations in naming and co-referents of polymers were considered\ncorrect during the calculation of theF\n1 score. Consequently, although there\nis a low overlap of the names exactly extracted by the methods as depicted in\nFig. 4d, a highF1 score is still maintained. For comparison, similar Venn\ndiagrams for Tg and bandgap data extracted from the 630 abstracts are\nshown in Fig. S1. Upon further investigation, we found that MaterialsBERT\nin some cases faced challenges in correctly associating property and material\nnames in texts ﬁlled with numerous numbers and values. This was\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 6\nparticularly prevalent in cases involving polymer blends or composites,\nwhere MaterialsBERT often extracted redundant values for each polymer.\nAs a result, the total amount of data extracted by the MaterialsBERT pipeline\nis often erroneously inﬂated for many ordinary polymers, as shown in\nFig. 4e. GPT-3.5 exhibited signiﬁcantly enhanced efﬁciency in accounting\nfor composite and blend compositions in the sentences. Examples eluci-\ndating the F-1 score calulcation method and anomalies of MaterialsBERT\nare discussed in the Supplementary Discussion.\nWe plotted the pairwise distributions where values of two properties\nwere available for the same material name and were extracted from the same\nsource article. Fig.4f depicts the relationship between bandgap and Tg data\nextracted by the pipelines. GPT-3.5 demonstrated the ability to capture\nmore data including numerous extreme property values, while Materi-\nalsBERT successfully captured values towards the center of the distribution.\nAdditionally, both methods illustratethe scarcity of materials exhibiting\nhigh bandgaps and simultaneously high Tg values. Six data points with high\nbandgap or Tg values, as determined by the pipelines, are identiﬁed and\nnumbered in Fig.4f. The pipelines correctly extracted points 1, 2, and 3. In\nthe case of point 1, GPT-3.5 managed to extract more detailed information,\nidentifying both‘non-oriented PMMA layer’ and ‘oriented PMMA layer’\ninstead of merely labeling it as‘PMMA’. Neither GPT-3.5 nor Materi-\nalsBERT were successful in extracting any bandgap data for points 2 and 3,\nrespectively. With regard to point 4, GPT-3.5 incorrectly identiﬁed the\nthermal decomposition temperature as the Tg value. Meanwhile, Materi-\nalsBERT was unable to extract the high bandgap value. Points 5 and 6 were\nidentiﬁed as a composite and blend, respectively. However, MaterialsBERT\nonly managed to extract the polymer names, failing to recognize the pre-\nsence and modiﬁcations by other materials. Despite the observation that\nGPT-3.5 typically extracts the compositions of polymer composites and\nblends, it did not identify the presence of other materials in this instance and\nonly extracted the polymer names due to the complexity of the sentences in\nthe source text. Out of the total 12 values for the designated property pairs,\n10 were accurately extracted. Supplementary Information, including\nreferences and actual values of the marked points, can be found in Tables\nS2 and S3.\nCorrelations between extracted properties\nKnowledge of the relationships betweendistinct material properties can be\ngained by examining the pairwise distributions among other property pairs.\nRepresentative pairwise plots indicate diverse trends, with Fig.4gh i g h -\nlighting a discernible positive correlation between crystallization tempera-\nture and Tg. The extracted data highlights an inverse correlation between\nwater contact angle and water uptake (Fig.4h), conﬁrming that hydrophilic\nmaterials with smaller contact angles tend to absorb greater amounts of\nwater. Additionally, the bandgap determines the energy above which a\nmaterial remains transparent. As the light wavelength decreases towards the\nbandgap, there is a corresponding increase in the refractive index. When the\nlight wavelength is held constant, materials with a larger bandgap generally\nexhibit a smaller refractive index. The inverse trend depicted in Fig.4i\nillustrates this relationship between the optical properties of the materials\nextracted. Another fundamental observation for polymers is the inherent\ntrade-off between mechanical properties. Fig.4j elucidates the negative\nFig. 4 | Comparison of GPT and MaterialsBERT extracted data. a, b Distribution\nof extracted Tg and bandgap data from the abstracts using MaterialsBERT and full\ntexts of polymer articles using both GPT-3.5 and MaterialsBERT pipelines.\nc, d Overlap between the source paragraphs and extracted material names in GPT-\n3.5 and MaterialsBERT extracted Tg and bandgap data.e Barchart showing the total\nnumber of data extracted from the full texts for the top 10 polymers using the two\npipelines. f Pairwise plot of bandgap and Tg values for the materials extracted from\nthe same source articles, marked points are discussed in the text.g– k Representative\npairwise plots showing relationships between selected pairs of properties. The\ndashed lines are guides for the eye.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 7\ntrade-off between tensile strength and elongation at break, emphasizing the\ncapacity of GPT-3.5 to capture additional values. The phenomenon of water\nabsorption induces polymer chain swelling, thereby instigating plasticizing\neffects that can alter the mechanical properties of the material. Although the\nspeciﬁc nature of the relation depends on the material in question, Fig.4k\nsuggests a pervasive negative trend wherein water uptake causes a reduction\nin the tensile properties of materials. Overall, the extracted data largely\nfollow expected trends and agree with domain knowledge as demonstrated\nby the pairwise distributions.\nThe datasets we extracted from literature containing the 24 properties\nare integral for training downstream ML models. In a previous study, we\nemployed similar datasets to optimize the material system and develop\nrobust predictive models to optimize power conversion efﬁciency of poly-\nmer solar cells and demonstrated a signiﬁcant reduction in new polymer\ndiscovery time\n39. In another study, we assembled a comparable dataset to\npredict the retrosynthesis pathways for a target polymer40.\nOutlook\nLLMs, such as GPT-3.5 with likely over 200 billion parameters, show a\nmarked advantage in data extraction quality and ease due to their pre-\ntraining on extensive text corpora, even withoutﬁne-tuning on domain-\nspeciﬁcd a t a s e t s .T h ee fﬁcacy of pre-training is highlighted by GPT-3.5’s\nproﬁciency in recognizing material and chemical entities. The LlaMa-2\nmodel, with 70 billion parameters, demonstrates comparatively limited\ncapability in recognizing chemical entities and establishing correct entity\nrelationships, hinting at consideration for potential improvement through\nﬁne-tuning on labeled datasets. The challenges speciﬁc to polymer literature\nfor NER-based models are marked by the absence of a standardized naming\nconvention for polymers and the requirement for manual efforts to identify\nentity relationships.\nDespite the promising performance of GPT-3.5, various limitations\nstill exist for the extraction of datafrom polymer literature and their\napplications in polymer informatics. We discuss some speciﬁc issues and\nour goals for improvement below.\n Manual conversion is necessary to transform the extracted material\nnames into machine-readable formats such as Simpliﬁed Molecular\nInput Line Entry System (SMILES) strings to make the datasets\ninformatics-ready. Despite the incorporation of LLMs into the data\nextraction pipeline, the parsing of chemical structures fromﬁgures\nremains a signiﬁcant challenge, particularly in polymer-related studies.\nThis is due largely to the fact that polymer structures are often\nexclusively presented inﬁgures, which obstructs the direct extraction\nand conversion of polymer chemistry into machine-readable SMILES\nstrings from the text. In the future, integration of large-scale computer\nvision models with LLMs to efﬁciently identify and extract polymer\nmolecules depicted inﬁgures will enable immediate use of the extracted\ndata for training ML models without the need for additional manual\nprocessing.\n The intricate nature of scientiﬁc texts, particularly in introducing\nmaterial names across different sections and using abbreviations,\nmakes establishing correct relationships between entities mentioned in\ndifferent paragraphs or even sentences a difﬁcult task. Our current\npipelines extract data that is described completely in a speciﬁcp a r a -\ngraph by looking for all the required named entities (i.e.,‘material’,\n‘property’, ‘value’ and ‘unit’) to establish correct relationships. How-\never, the properties of polymers often rely on further information, such\nas molecular weights, temperature, synthesis and processing condi-\ntions, and morphology. This additional data also needs to be extracted\nfrom multiple paragraphs, while ensuring the preservation of valid\nrelationships. Using a speciﬁce x a m p l eo fF i g .2d, where one of the\nextracted materials is simply labeled as a\n‘copolymer,’ it becomes\nchallenging to fully extract the actual name or chemistry of the material\nwithout inputting the full text of the article into the LLM or correctly\nidentifying theﬁrst occurrence of the term using other means. How-\never, feeding the entirety of text contents into larger context lengths of\nthe latest LLMs, even if possible, is fundamentally inefﬁcient and a\nsquandering of computational resources. In addition, the outputs\nderived from conversational LLMs often exhibit inconsistency,\nnecessitating manual effort for conversion into structured formats.\nFormulation of a robust chemical entity relationship extraction strat-\negy that leverages both NER and LLM, could markedly augment the\nquality and application of the extracted data.\n Extraction of materials data present in tabular formats can further\nenhance the utility of comprehensive data extraction tasks. Another\nsigniﬁcant source of data often originates from the supplementary\ninformation published alongside articles. These documents are typi-\ncally available in portable document format (PDF), which poses a\nchallenge for parsing due to the lack of standardization in document\ncreation\n41. While values with heightened scientiﬁcs i g n iﬁcance are\nusually mentioned in the main text, the presence of a substantial\namount of extractable and relevant data in tabular format and sup-\nporting documents has the potential to greatly improve the perfor-\nmance of downstream data-hungry ML models. However, tables are\nfrequently arbitrarily structured, necessitating meticulousﬁltering,\nclassiﬁcation, and pre-processing for correct relationship\nestablishment\n42,43.\n Extracting property data from literature represents a speciﬁca p p l i c a -\ntion of NLP in polymer research. Accurate predictions of step-by-step\ntasks and procedures, such as synthesis recipes, characterization data,\nmeasurement conditions, etc., couldguide the development of superior\npolymers through inversedesign and suggest speciﬁc conditions that\nresearchers could maintain to produce a target material. Synthesis\nrecipes, for example, present a unique challenge due to the need to\nextract a diverse set of information, including monomers, catalysts,\ntemperature, reaction conditions, and more. Additionally, the chemical\nreactions must be predicted algorithmically, maintaining proper order\nof the procedure. Despite these challenges, the capacity of LLMs to\ncomprehend complex procedures offers a promising avenue for\nsystematically extracting such information.\nNevertheless, it is evident that the introduction of LLMs such as GPT-\n3.5 is a signiﬁcant leap forward in theﬁeld of data extraction, particularly in\ncomplex domains like polymer literature. Future work may involveﬁne-\ntuning the model to concurrently handle searching,ﬁltering, NER and data\nextraction tasks. As advancements in smaller open-source models persist,\nwe anticipate the potential tosubstitute our entire workﬂow with a single,\nﬁne-tuned, open-source LLM. Such a system could democratize the process\nof extracting accurate data from literature. However, this transition would\nrequire comprehensive analysis and validation by the materials science\ncommunity. Our focus will not only be on reﬁning data extraction work-\nﬂows but also on ensuring the availability of the extracted data for inspection\nthrough resources such as Polymer Scholar.\nConclusion\nIn conclusion, this study presents a framework for automated extraction of\npolymer property data from full-text scientiﬁc literature, utilizing a com-\nbination of NER-based MaterialsBERT and GPT-3.5 LLMs. The approach\nhas demonstrated a signiﬁcant improvement in data extraction capabilities,\nyielding 21 times more data than previously extracted from just the abstracts\nof journal articles. A comparative analysis of the performance and costs\nassociated with both extraction models was also conducted. The GPT-3.5\nand MaterialsBERT models achievedF\n1 scores of 0.67 and 0.63 respectively\nfor Tg, and 0.85 and 0.66 respectively for bandgap. While traditional NER\nmodels offer speed, the LLMs, although more costly, provide ease of use and\nrequire less manual effort, making them an attractive alternative. GPT-3.5\nalso shows a marked improvement in recognizing materials entities and\ncorrect entity relationships, particularly in the context of polymer compo-\nsites and blends. However, both models encountered difﬁculties in\nextracting correct values from texts containing complex discussions about\nmaterials. The potential of LLMs lie in their ability to produce not just\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 8\nstructured outputs such as property data extraction, but also assistance with\nproperty predictions, material design and synthesis recipe\nrecommendations.\nMethods\nThe literature corpus\nOur literature corpus consists of ~2.4 million documents downloaded from\npublishers including Elsevier, Wiley,Springer Nature, American Chemical\nSociety, and Royal Society of Chemistry which covers articles published up\nto the year 2021. Only HTML and XML versions of the documents were\nprocessed in this work as formats such as PDF are difﬁcult to parse\n44.\nLiterature published before the year 2000 is often found in PDF format while\nXML and HTML versions are available from most publishers after 2000.\nT h ed e t a i l so ft h ew o r kﬂow is discussed in ref.32.\nFull-text extraction\nPlain text paragraphs embedded inside thep, span, or similar tags of the\nHTML and XML documents were extracted using the LXML Python\npackage. Both the abstracts and the full texts available in the body of the\ndocuments were collected in the process. Subscripts and superscripts in\nthe text were encoded by the underscore and the caret symbols, respec-\ntively. No additional pre-processing was performed since the LLMs are\ngenerally able to ‘understand’ chemical entities, units, and literature\nreferences.\nProperty-speciﬁch e u r i s t i cﬁlter\nThe paragraphs extracted from full texts of the journal articles underwent a\ntwo-stageﬁltering process before being sent to the data-extraction pipeline.\nThe heuristicﬁlter assessed the text for the occurrence of the property name\nor any of its known variations, employing string-matching and dictionary\nlookup techniques. The property namevariations were carefully curated\nthrough an extensive literature search.\nNER ﬁlter\nNER-basedﬁltering was used to identify the paragraphs that contain data\nsuitable for extraction. First, the named entities present in the paragraph are\npredicted using MaterialsBERT. Theﬁlter then selects the paragraphs that\nhave (1) at least one of the material-related named entities, (i.e.,“POLY-\nMER”, “MONOMER”, “POLYMER_FAMILY”, “ORGANIC”, “INOR-\nGANIC”)( 2 )t h e “PROPERTY_NAME” entity and (3) the\n“PROPERTY_VALUE” entity present in the text. If the text does not\nmeet all three conditions, the paragraph fails theﬁlter. This allows theﬁlter\nto select paragraphs with data for allpossible materials and properties\nknown by MaterialsBERT and are suitable for extraction.\nLlaMa model\nAn instruct-tuned 70B LlaMa-2-chat model was used in this work to extract\ndata from texts. The architecture of the LlaMa model was obtained from the\nHuggingFace hub using the transformers Python package. The corre-\nsponding LlaMa 2 weights were requested and obtained from the ofﬁcial\nwebsite of Meta AI. A 4-bit GPTQ quantized (group size 32, with act order)\nversion of the model was run on four 235W 16GB Nvidia Quadro GP100\nGPUs hosted in our in-house computing servers. For text generation\nparameters, the temperature was setto 0.001, top_p to 0.95, min_p to 0,\nfrequency_penalty to 1.1, and top_k to 1. The maximum output length was\nautomatically computed each time before inference, so the total number of\ntokens for the prompt and the generated output remains less than the\ncontext length of the model, i.e., 4096. The use of a conversational model did\nnot involve incorporating history from prior interactions during text gen-\neration. Consequently, the model treated each prompt as a distinct text\ngeneration request.\nGPT model\nThe GPT-3.5-turbo-0613 model hosted by OpenAI was used to extract data\nfrom text. The OpenAI Python package was used to access the OpenAI API.\nThe temperature parameter was set to 0.001 for text generation by the\nmodel, with all other parameters remaining at their default values. Similar to\nthe LlaMa 2 model, a history of previous interactions was not maintained\nbetween the API requests. The manually curated Tg and bandgap data were\nused as a shot to the LLM regardless of the property to be extracted. The\nextraction process from the full texts of the 716,000 paragraphs took\napproximately a month (respecting the guidelines for fair usage of the API\nserver), incurring approximately 1200 US dollars. The API usage costs were\ncalculated assuming 0.0015 and 0.0020 US dollars per one thousand prompt\ntokens and completion tokens respectively.\nData availability\nThe journal articles used to extract material property data were downloaded\nthrough licensing arrangements thatthe Georgia Institute of Technology\nhas with Elsevier, Wiley, Royal Society of Chemistry, American Chemical\nSociety, Springer Nature, Taylor & Francis, and the American Institute of\nPhysics. The pre-trained language model MaterialsBERT is available in the\nHuggingFace hub athttps://huggingface.co/pranav-s/MaterialsBERT.T h e\nmaterial property data extracted in this work can be freely explored through\nhttps://polymerscholar.org.\nCode availability\nT h ec o d eu s e di nt h i sw o r kc a nb ef o u n da thttps://github.com/Ramprasad-\nGroup/PromptDataExtraction.\nReceived: 25 April 2024; Accepted: 30 November 2024;\nReferences\n1. Doan Tran, H. et al. Machine-learning predictions of polymer\nproperties with Polymer Genome.J. Appl. Phys.128, 171104 (2020).\n2. Wu, C. et al. Dielectric polymers tolerant to electricﬁeld and\ntemperature extremes: integration of phenomenology, informatics,\nand experimental validation.ACS Appl. Mater. Interfaces13,\n53416– 53424 (2021).\n3. Kononova, O. et al. Opportunities and challenges of text mining in\nmaterials research.iScience 24, 102155 (2021).\n4. Foppiano, L. et al. Automatic extraction of materials and properties\nfrom superconductors scientiﬁc literature.Sci. Technol. Adv. Mater.:\nMethods 3, 2153633 (2023).\n5. Cheung, J. J. et al. PolyIE: a dataset of information extraction from\npolymer material scientiﬁc literaturehttp://arxiv.org/abs/2311.07715\n(2023).\n6. Batra, R., Song, L. & Ramprasad, R. Emerging materials intelligence\necosystems propelled by machine learning.Nat. Rev. Mater.6,\n655– 678 (2021).\n7. Oka, H., Yoshizawa, A., Shindo, H., Matsumoto, Y. & Ishii, M. Machine\nextraction of polymer data from tables using XML versions of scientiﬁc\narticles. Sci. Technol. Adv. Mater.: Methods1,1 2– 23 (2021).\n8. Kononova, O. et al. Text-mined dataset of inorganic materials\nsynthesis recipes.Sci. Data6, 203 (2019).\n9. Choi, J. et al. Deep learning of electrochemical CO2 conversion\nliterature reveals research trends and directions.J. Mater. Chem. A11,\n17628– 17643 (2023).\n10. Beltagy, I., Lo, K. & Cohan, A. SciBERT: a pretrained language model\nfor scientiﬁc texthttp://arxiv.org/abs/1903.10676 (2019).\n11. Shetty, P. et al. A general-purpose material property data extraction\npipeline from large polymer corpora using natural language\nprocessing. npj Comput Mater.9,1 – 12 (2023).\n12. Gu, Y. et al. Domain-speciﬁc language model pretraining for\nbiomedical natural language processing.ACM Trans. Comput.\nHealthc. 3,1 – 23 (2022).\n13. Chithrananda, S., Grand, G. & Ramsundar, B. ChemBERTa: large-\nscale self-supervised pretraining for molecular property prediction\nhttp://arxiv.org/abs/2010.09885 (2020).\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 9\n14. Trewartha, A. et al. Quantifying the advantage of domain-speciﬁc pre-\ntraining on named entity recognition tasks in materials science.\nPatterns 3, 100488 (2022).\n15. Mahmood, A., Sonakshi, G. & Shetty, P. Polymer scholarhttps://\npolymerscholar.org (2024).\n16. Olivetti, E. A. et al. Data-driven materials research enabled by natural\nlanguage processing and information extraction.Appl. Phys. Rev.7,\n041317 (2020).\n17. Shetty, P. & Ramprasad, R. Machine-guided polymer knowledge\nextraction using natural language processing: the example of named\nentity normalization.J. Chem. Inf. Model.61, 5377– 5385 (2021).\n18. Touvron, H. et al. Llama 2: open foundation andﬁne-tuned chat\nmodels http://arxiv.org/abs/2307.09288 (2023).\n19. Chowdhery, A. et al. PaLM: scaling language modeling with pathways\nhttp://arxiv.org/abs/2204.02311 (2022).\n20. Lappin, S. Assessing the strengths and weaknesses of large language\nmodels. J. Log. Lang. Inf.https://doi.org/10.1007/s10849-023-\n09409-x (2023).\n21. Choi, J. & Lee, B. Accelerating materials language processing with\nlarge language models.Commun. Mater.5,1 – 11 (2024).\n22. Wang, H., Li, J., Wu, H., Hovy, E. & Sun, Y. Pre-trained language\nmodels and their applications.Engineering 25,5 1– 65 (2023).\n23. Liu, Y., Cao, J., Liu, C., Ding, K. & Jin, L. Datasets for large language\nmodels: a comprehensive surveyhttps://arxiv.org/abs/2402.18041v1\n(2024).\n24. Rozière, B. et al. Code Llama: open foundation models for code\nhttps://arxiv.org/abs/2308.12950v2 (2023).\n25. Brown, T. B. et al. Language models are few-shot learnershttp://arxiv.\norg/abs/2005.14165 (2020).\n26. Strubell, E., Ganesh, A. & McCallum, A. Energy and policy\nconsiderations for deep learning in NLPhttp://arxiv.org/abs/1906.\n02243 (2019).\n27. Luccioni, A. S., Viguier, S. & Ligozat, A.-L. Estimating the carbon\nfootprint of BLOOM, a 176B parameter language modelhttp://arxiv.\norg/abs/2211.02001 (2022).\n28. Dagdelen, J. et al. Structured information extraction from scientiﬁc\ntext with large language models.Nat. Commun.15, 1418 (2024).\n29. Zheng, Z., Zhang, O., Borgs, C., Chayes, J. T. & Yaghi, O. M. ChatGPT\nchemistry assistant for text mining and the prediction of MOF\nsynthesis. J. Am. Chem. Soc.145, 18048– 18062 (2023).\n30. Polak, M. P. & Morgan, D. Extracting accurate materials data from\nresearch papers with conversational language models and prompt\nengineering. Nat. Commun.15, 1569 (2024).\n31. Yang, S. J. et al. Accurate prediction of experimental band gaps from\nlarge language model-based data extractionhttp://arxiv.org/abs/\n2311.13778 (2023).\n32. Shetty, P. & Ramprasad, R. Automated knowledge extraction from\npolymer literature using natural language processing.iScience 24\n,\n101922 (2021).\n33. Meyer, J. G. et al. ChatGPT and large language models in academia:\nopportunities and challenges.BioData Min.16, 20 (2023).\n34. Li, Y., Ramprasad, R. & Zhang, C. A simple but effective approach to\nimprove structured language model output for information extraction\nhttp://arxiv.org/abs/2402.13364 (2024).\n35. Dengel, A. et al. Qualitative research methods for large language\nmodels: conducting semi-structured interviews with ChatGPT and\nBARD on computer science education.Informatics 10,7 8\n(2023).\n36. Zhou, Y. et al. Large language models are human-level prompt\nengineers http://arxiv.org/abs/2211.01910 (2023).\n37. Kim, S. I., Pyo, S. M., Kim, K. & Ree, M. Investigation of glass transition\nbehaviours in aromatic poly(amic acid) precursors with various chain\nrigidities by oscillating differential scanning calorimetry.Polymer 39,\n6489– 6500 (1998).\n38. Khanlari, T., Bayat, Y. & Bayat, M. Synthesis, thermal stability and\nkinetic decomposition of triblock copolymer polypropylene\nglycol– poly glycidyl nitrate– polypropylene glycol (PPG– PGN– PPG).\nPolym. Bull.77, 5859– 5878 (2020).\n39. Shetty, P., Adeboye, A., Gupta, S., Zhang, C. & Ramprasad, R.\nAccelerating materials discovery for polymer solar cells: data-driven\ninsights enabled by natural language processing.Chem. Mater.36,\n7676– 7689 (2024).\n40. Chen, L., Kern, J., Lightstone, J. P. & Ramprasad, R. Data-assisted\npolymer retrosynthesis planning.Appl. Phys. Rev.8, 031405\n(2021).\n41. Zhu, M. & Cole, J. M. PDFDataExtractor: a tool for reading scientiﬁc\ntext and interpreting metadata from the typeset literature in the\nportable document format.J. Chem. Inf. Model.62, 1633– 1643\n(2022).\n42. Hira, K., Zaki, M., Sheth, D. & Anoop Krishnan, N. M. Reconstructing\nthe materials tetrahedron: challenges in materials information\nextraction. Digital Discov.3, 1021– 1037 (2024).\n43. Gupta, T. et al. DiSCoMaT: distantly supervised composition\nextraction from tables in materials science articles. InProceedings of\nthe 61st Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers)(eds. Rogers, A., Boyd-Graber, J.\n& Okazaki, N.) 13465– 13483 (Association for Computational\nLinguistics, Toronto, Canada,https://aclanthology.org/2023.acl-\nlong.753 2023).\n44. Smith, A., Bhat, V., Ai, Q. & Risko, C. Challenges in information-mining\nthe materials literature: a case study and perspective.Chem. Mater.\n34, 4821– 4827 (2022).\nAcknowledgements\nThis work was supported by the Ofﬁce of Naval Research through grants\nN00014-19-1-2103 and N00014-20-1-2175. Pranav Shetty was partially\nfunded by a fellowship by JPMorgan Chase & Co. that helped to support this\nresearch. Any views or opinions expressed herein are solely those of the\nauthors listed, and may differ from the views and opinions expressed by\nJPMorgan Chase & Co. or its afﬁliates.\nAuthor contributions\nConceptualization: R.R. Data curation: A.A., P.S., and S.G. MaterialsBERT\npipeline: P.S. LLM pipelines: A.M., P.S. Database design: A.M., S.G. Polymer\nScholar: A.M., P.S. Visualization: A.M. Original draft: A.M., S.G. Review &\nediting: S.G., A.M., P.S., and R.R.\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s43246-024-00708-9.\nCorrespondenceand requests for materials should be addressed to\nRampi Ramprasad.\nPeer review informationCommunications materialsthanks Byungju Lee,\nZhiling Zheng and the other, anonymous, reviewer(s) for their contribution to\nthe peer review of this work. Primary Handling Editors: Milica Todorović and\nAldo Isidori. A peer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional afﬁliations.\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 10\nOpen AccessThis article is licensed under a Creative Commons\nAttribution-NonCommercial-NoDerivatives 4.0 International License,\nwhich permits any non-commercial use, sharing, distribution and\nreproduction in any medium or format, as long as you give appropriate\ncredit to the original author(s) and the source, provide a link to the Creative\nCommons licence, and indicate if you modiﬁed the licensed material. You\ndo not have permission under this licence to share adapted material\nderived from this article or parts of it. The images or other third party\nmaterial in this article are included in the article’s Creative Commons\nlicence, unless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted use,\nyou will need to obtain permission directly from the copyright holder. To\nview a copy of this licence, visithttp://creativecommons.org/licenses/by-\nnc-nd/4.0/\n.\n© The Author(s) 2024\nhttps://doi.org/10.1038/s43246-024-00708-9 Article\nCommunications Materials|           (2024) 5:269 11",
  "topic": "Extraction (chemistry)",
  "concepts": [
    {
      "name": "Extraction (chemistry)",
      "score": 0.6024602055549622
    },
    {
      "name": "Data extraction",
      "score": 0.502307653427124
    },
    {
      "name": "Computer science",
      "score": 0.4930224120616913
    },
    {
      "name": "Natural language processing",
      "score": 0.3930944502353668
    },
    {
      "name": "Chromatography",
      "score": 0.21640846133232117
    },
    {
      "name": "Chemistry",
      "score": 0.20862305164337158
    },
    {
      "name": "MEDLINE",
      "score": 0.12667733430862427
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}