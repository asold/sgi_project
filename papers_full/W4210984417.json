{
  "title": "A Survey on the Need and Use of AI in Game Agents",
  "url": "https://openalex.org/W4210984417",
  "year": 2010,
  "authors": [
    {
      "id": "https://openalex.org/A2116314274",
      "name": "Sule Yildirim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4211331205",
      "name": "Sindre Berg",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1697695594",
    "https://openalex.org/W1574206192",
    "https://openalex.org/W1527144090",
    "https://openalex.org/W2326387853",
    "https://openalex.org/W115079321",
    "https://openalex.org/W167175497",
    "https://openalex.org/W170257274",
    "https://openalex.org/W2122410182",
    "https://openalex.org/W2096178388",
    "https://openalex.org/W2568311684"
  ],
  "abstract": "In this chapter, we investigated whether it is possible to view NPCs in games as game agents. We used the qualities of reactivity, being temporally continuous, autonomy and being goal-oriented for evaluating a representative set of popular commercial games on how much agent-like they are. Our evaluations show that some games have NPCs that achieve more agent-like behavior than others. Also, we give a survey on the use of various AI methodologies in commercial games and in game research. We indicate that the need for AI in games is centered around maximizing goal achievement by choosing the most optimal actions given the available information. NPCs can challenge human players and add to the quality of experience if they can become better at achieving optimal behavior. Furthermore, we postulate that further investigation is required before conclusions can be made about whether the given methodologies (especially those that are not commonly used in commercial games at the moment) are really applicable in commercial games. Regarding this point, the use of learning in games is relatively low in commercial arena as can be observed from Table 2 even though learning is an important aspect in achieving artificial intelligence. Another relevant point is that the non player characters are required to make",
  "full_text": "A Survey on the Need and Use of AI in Game Agents 225\nA Survey on the Need and Use of AI in Game Agents\nSule Yildirim and Sindre Berg Stene\nX \n \nA Survey on the Need and Use \n of AI in Game Agents  \n \nSule Yildirim and Sindre Berg Stene \nHedmark University College \nNorway \n \n1. Introduction \n \nThis chapter firstly seeks an answer to the question of whether Non Player Characters \n(NPCs) in Computer Games can also be viewed as game a gents where reactivity, autonomy, \nbeing temporally continuous and having goal-oriented behavior are taken as the features of \nbeing a game agent. Within this scope, we will try to assess whether naming NPCs as agents \npoint to a desire that one day they will fulfill th e requirements of being an agent or whether \nNPCs actually already fulfill these requirements. S econdly, the chapter looks into the AI \nneeds of video games. We present the AI methodologies that are either being used or under \nresearch for use in Game AI. The same methodologies are als o likely to contribute to the \nincreasing levels of autonomy and goal-directed beh avior of NPCs and help them become \nmore agent-like.  \n \n2. Background \n \nIn game development and game AI research, terms such as game agents and NPCs are often \nused interchangeably. However, considering the many years of agent research, are NPCs \nreally game agents? In order to answer this question, w e look at different definitions of \nbeing an agent from agent research and point out the features that would possibly separate \nan ordinary NPC from a game agent. Autonomy and goal-direct ed behavior are features \nthat lie at the heart of being an agent and for that reason we look into t he details of what it \nmeans to be autonomous and goal-oriented for an agent. \nIn agent research and applications, having its own agenda and being able to select its own \nactions are essential parts of being autonomous (Franklin & Graesser 1997). For that reason, \nthe more the NPCs are able to carry out own agenda the more agent-like they are. If  an NPC \nresponds to certain conditions with predefined acti ons scripted in a certain programming \nlanguage, it would have much less autonomy compared t o an agent which can plan its \nfuture actions. Furthermore, the actions that NPCs execute c ause changes in the \nenvironment. NPCs can then select further actions b ased on the consequences of an applied \naction, or they can ignore the consequences of their actions. An NPC wh ich can consider the \nconsequences of its actions can plan. \n14\nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications226\n \nOn the other hand, we look into the purpose of game AI and present the capabilities \n(reasoning, decision making, learning, prediction, goal-oriented behavio r) that are expected \nfrom NPCs endowed with game AI. We also present a list of AI methodologies (e.g. path \nfinding, Finite State Machines) which are in use or are proposed for use to achieve those \ncapabilities. We summarize different kinds of game ge nres, the AI status and challenges of \nthese games in order to be able to be more specific about t he behaviors (e.g. create an army, \nform alliances, and so on) which would be expected from NPCs. \nAnother relevant definition is the definition of “i ntelligence”. Intelligence is the ability to \nacquire and apply knowledge. The way in which the NPCs acquire knowledge a nd reason \nupon it will provide agents with different levels of intelligence. \nThen, section 3 investigates the aspects of being a  game agent. Section 4 gives the purpose \nand methods of game AI and the capabilities that NPC s become equipped with through \ngame AI. It also explains what is meant by game AI for different game genres. Section 5 \ngives an evaluation of games for their agent characteristics. Section 6 gives the conclusions.  \n \n3. Agent Perspective: Being an NPC vs. Being a Game Agent \n \nA definition of agents is as follows: \n \nAn autonomous agent is a system situated within and part of an environment that senses \nthat environment and acts on it, over time, in pursuit  of its own agenda and so as to reflect \nwhat it senses in the future (Franklin & Graesser, 1997).  \n \nAnother definition of agent is given as follows: \n \nAgents can be defined to be autonomous, problem solving computation al entities capable of \nsolving effective operations in dynamic and open environments (Luck et al., 2003). \n \nOn the other hand, an agent is stated to be autonomous if its behavior is determined by its \nown experience (with ability to learn and adapt) (Russell & Norvig, 2003). \nIn robotics, autonomy means independence of control . This characterization implies that \nautonomy is a property of the relation between the designer and the autonomous robot. \nSelf-sufficiency, situatedness, learning or develop ment, and evolution increase an agent’s \ndegree of autonomy (Pfeifer & Scheier, 1999). \nA list of properties is listed at the end of page 5 in (F ranklin & Graesser, 1997). The authors \nstate that the first four properties should exist in a program to name it  as an agent and these \nfour properties are as follows: \n \nReactive: Most of the NPCs in existing games have reactive resp onses, e.g. First Person \nShooter NPCs. \nAutonomous: Are there any NPCs that have their own agenda and that exercise contro l over \nits actions in any of the existing games? Such an N PC would not need to be told what to do \nbut would be able to decide which action(s) to take under what conditions.  \nGoal-oriented: Does not simply act in response to the environment. Are there any agents  in \nexisting games which can pursue its goals? \n \nTemporally continuous: This feature seems to be true in all agents. \n \nIn this chapter, we use these four properties to assess whether an NPC can be named as an \nagent. In existing games, most NPCs are reactive and  temporally continuous. However, are \nthey also autonomous and goal-oriented? Which AI methods can be employed to help \nachieve these properties? \nOn the other hand, we classify NPCs as software agents (Franklin & Graesser, 1997). This \nclassification allows us further to classify NPCs a ccording to their control mechanisms. In \nthis way, game agents can be algorithmic, rule based, pl anning based, or otherwise \nprimarily oriented around fuzzy logic, neural networks,  machine learning, etc. This kind of \nclassification is also important since it forms a natural bridge between the agent terminology \nsuch as being reactive, goal-oriented, autonomous, temporally continuous and  the AI \nmethodologies that can be employed to achieve them.  \nThe type of control mechanism to employ depends on the kind of intelligence that is \nrequired to build into an NPC and the game genre that an NPC belongs to. For that reason,  \none of the coming sections will also give an overview of different game types (genres). Next \nwe will look at what is meant by goal-based agents. \n \n3.1 Goal-based Agents \n“A game is a form of art in which participants, term ed players, make decisions in order to \nmanage resources through game tokens in the pursuit of a goal.” \n \nGreg Costikyan - Game designer and science fiction writer \nA goal-based agent not only considers the consequences of its actions (See Fig. 1: What it \nwill be like if I do action A) but also considers h ow much those actions are in line with its \ngoals (See Fig. 1: What action I should do now given certain goals). As an example, F.E.A .R \n(Yue & de-Byl, 2006; Hubbard, 2005) is a game with goal-oriented behavior.  \nIn (Yue & de-Byl, 2006), an example is presented for goal-directed behavior which is given \nin Fig. 2. In the figure, blue boxes represent keys  and the current and goal values of a key. A \nkey is a state that an agent wants to get into. For example, the topmost bo x holds a key \nwhich is “EnemyIsDead”. This key has a current value of “ False” and a goal value of “True” \nas the AI-controlled agent wants to have its enemy dead. In order to achieve that goal value, \nthe enemy can choose to apply the action “fire weapon”. The white boxes indicate the \npreconditions and effects of the action that they are b ound to. The precondition of the “fire \nweapon” action requires that the key “HealthRecovered” has a value of “True” before the \naction can be applied. The effect of the action is t o have the key “EnemyIsDead” have a \nvalue of “True” after the action is applied. It can be seen in Fig. 2 that the current value of \nthe key “HealthRecovered” is “False”. In order to have a value of “True” for the key \n“HealthRecovered”, the action “take cover” is select ed for application before the “fire \nweapon” action. The “take cover” action does not have any preconditions and for that \nreason, the goal state is achieved by the application of the “take cover” action first and the \n“fire weapon” action second.  \n \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 227\n \nOn the other hand, we look into the purpose of game AI and present the capabilities \n(reasoning, decision making, learning, prediction, goal-oriented behavio r) that are expected \nfrom NPCs endowed with game AI. We also present a list of AI methodologies (e.g. path \nfinding, Finite State Machines) which are in use or are proposed for use to achieve those \ncapabilities. We summarize different kinds of game ge nres, the AI status and challenges of \nthese games in order to be able to be more specific about t he behaviors (e.g. create an army, \nform alliances, and so on) which would be expected from NPCs. \nAnother relevant definition is the definition of “in telligence”. Intelligence is the ability to \nacquire and apply knowledge. The way in which the NPCs acquire knowledge a nd reason \nupon it will provide agents with different levels of intelligence. \nThen, section 3 investigates the aspects of being a  game agent. Section 4 gives the purpose \nand methods of game AI and the capabilities that NPC s become equipped with through \ngame AI. It also explains what is meant by game AI for different game genres. Section 5 \ngives an evaluation of games for their agent characteristics. Section 6 gives the conclusions.  \n \n3. Agent Perspective: Being an NPC vs. Being a Game Agent \n \nA definition of agents is as follows: \n \nAn autonomous agent is a system situated within and part of an environment that senses \nthat environment and acts on it, over time, in pursuit  of its own agenda and so as to reflect \nwhat it senses in the future (Franklin & Graesser, 1997).  \n \nAnother definition of agent is given as follows: \n \nAgents can be defined to be autonomous, problem solving computation al entities capable of \nsolving effective operations in dynamic and open environments (Luck et al., 2003). \n \nOn the other hand, an agent is stated to be autonomous if its behavior is determined by its \nown experience (with ability to learn and adapt) (Russell & Norvig, 2003). \nIn robotics, autonomy means independence of control . This characterization implies that \nautonomy is a property of the relation between the designer and the autonomous robot. \nSelf-sufficiency, situatedness, learning or develop ment, and evolution increase an agent’s \ndegree of autonomy (Pfeifer & Scheier, 1999). \nA list of properties is listed at the end of page 5 in (F ranklin & Graesser, 1997). The authors \nstate that the first four properties should exist in a program to name it  as an agent and these \nfour properties are as follows: \n \nReactive: Most of the NPCs in existing games have reactive resp onses, e.g. First Person \nShooter NPCs. \nAutonomous: Are there any NPCs that have their own agenda and that exercise contro l over \nits actions in any of the existing games? Such an N PC would not need to be told what to do \nbut would be able to decide which action(s) to take under what conditions.  \nGoal-oriented: Does not simply act in response to the environment. Are there any agents  in \nexisting games which can pursue its goals? \n \nTemporally continuous: This feature seems to be true in all agents. \n \nIn this chapter, we use these four properties to assess whether an NPC can be named as an \nagent. In existing games, most NPCs are reactive and  temporally continuous. However, are \nthey also autonomous and goal-oriented? Which AI methods can be employed to help \nachieve these properties? \nOn the other hand, we classify NPCs as software agents (Franklin & Graesser, 1997). This \nclassification allows us further to classify NPCs a ccording to their control mechanisms. In \nthis way, game agents can be algorithmic, rule based, pl anning based, or otherwise \nprimarily oriented around fuzzy logic, neural networks,  machine learning, etc. This kind of \nclassification is also important since it forms a natural bridge between the agent terminology \nsuch as being reactive, goal-oriented, autonomous, temporally continuous an d the AI \nmethodologies that can be employed to achieve them.  \nThe type of control mechanism to employ depends on the kind of intelligence that is \nrequired to build into an NPC and the game genre that an NPC belongs to. For that reason,  \none of the coming sections will also give an overview of  different game types (genres). Next \nwe will look at what is meant by goal-based agents. \n \n3.1 Goal-based Agents \n“A game is a form of art in which participants, term ed players, make decisions in order to \nmanage resources through game tokens in the pursuit of a goal.” \n \nGreg Costikyan - Game designer and science fiction writer \nA goal-based agent not only considers the consequences of its actions (See Fig. 1: What it \nwill be like if I do action A) but also considers h ow much those actions are in line with its \ngoals (See Fig. 1: What action I should do now given certain goals). As an example, F.E .A.R \n(Yue & de-Byl, 2006; Hubbard, 2005) is a game with goal-oriented behavior.  \nIn (Yue & de-Byl, 2006), an example is presented for goal-directed behavior which is given \nin Fig. 2. In the figure, blue boxes represent keys  and the current and goal values of a key. A \nkey is a state that an agent wants to get into. For example, the topmost bo x holds a key \nwhich is “EnemyIsDead”. This key has a current value of “False” and a goal value of “True” \nas the AI-controlled agent wants to have its enemy dead. In order to achieve that go al value, \nthe enemy can choose to apply the action “fire weapon”. The white boxes indicate the \npreconditions and effects of the action that they are b ound to. The precondition of the “fire \nweapon” action requires that the key “HealthRecovered” has a value of “True” before the \naction can be applied. The effect of the action is t o have the key “EnemyIsDead” have a \nvalue of “True” after the action is applied. It can be seen in Fig. 2 that the current value of \nthe key “HealthRecovered” is “False”. In order to have a value of “True” for the key \n“HealthRecovered”, the action “take cover” is select ed for application before the “fire \nweapon” action. The “take cover” action does not have any preconditions and for that \nreason, the goal state is achieved by the application of the “take cover” action first and the \n“fire weapon” action second.  \n \nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications228\n \n \nFig. 1. Goal-based Agents (adapted from (Russell & Norvig, 2003)). \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 2. Taken from (Yue & de-Byl, 2006) - F.E.A.R. © Monolith Productions 2005. \nkey              curr value   goal value \nEnemyIsDead   False               True \nfire \nweapon \n                          Key                        value \nEffect                EnemyIsDead        True \nPrecondition   HealthRecovered  True \nkey               curr value   goal value \nEnemyIsDead        True                   True \nHealthRecovered  False         \n              True \nkey               curr value    goal value \nEnemyIsDead         True                    True \nHealthRecovered   True                       True \n                          Key                            value \nEffect                HealthRecovered     True \nPrecondition   none                           none \ntake \ncover \n \nOn the other hand, planning is a more complicated goal-direct ed behavior and more on \nplanning will be given in Section 4. The benefits of a goal-oriented planning behavior are \nstated as follows in (Yue & de-Byl, 2006). \n There are no hard-coded plans \n Code maintenance is minimized \n Bugs are minimized  when planning \n Code is reusable \n \nThe drawbacks of a goal-oriented planning behavior are as stated as follows in (Yue & de-\nByl, 2006): \n \n Real-time planning requires processing time \n More complex plans require more time \n \nDifferent aspects of goal-directed behavior and planning such as representation of world, \narchitectures and applications can be found in (Orkin, 2005), (Orkin,  2004), (Narayek, 2002), \n(IGDA, 2005) and (Namee & Cunningham, 2001). \n \n4. Game AI in General \n \nOne of the aims of Game AI is to increase the difficulty of the g ame to challenge the human \nplayers. The game AI should lead to a fulfilling gam e experience. On the other hand, games \ntake place in dynamic complex worlds in which compl ex decisions must be made, often \nbased on partial knowledge (Fairclough et al., 2001). \nIt is usual to state that Non Player Characters are AI-controlled charact ers that can only \ninteract with PCs (Player Characters) through scripted events or artificial i ntelligence (AI). \nHowever, what is it that is called Artificial Intel ligence in an NPC? For example, World of \nWarcraft is one of the most popular games and its NPCs are stated to b e AI controlled \n(Blizzard, 2005). Even though it is so popular, it actually has very little  AI composed of \nreactive agents and a great deal of scripted events. For example, a player is tasked wi th \nescorting an NPC so that he can walk around and look for his lost bac kpack or something \nsimilar (where you meet monsters and assassins on t he way, also scripted NPCs, and \neverything woven into a storyline about this man's misfortune). On the other hand, even \nthough it is \"low AI\", this is something which adds to the game experience in terms of AI.  \nWhat kind of intelligent behaviors are expected fro m NPCs? In general, an NPC is expected \nto maximize goal achievement by choosing the most o ptimal actions given the available \ninformation. An exception to the rule could be when more human-like actions may be a \nbetter choice than the most optimal action, for the sake of realism. \nThe most commonly used AI methodologies to achieve game AI can be stated as follows \n(McGee, 2005): \n \n Decision trees: can be realized by If-Then statements.. \n Finite state machines \n Command hierarchies \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 229\n \n \nFig. 1. Goal-based Agents (adapted from (Russell & Norvig, 2003)). \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nFig. 2. Taken from (Yue & de-Byl, 2006) - F.E.A.R. © Monolith Productions 2005. \nkey              curr value   goal value \nEnemyIsDead   False               True \nfire \nweapon \n                          Key                        value \nEffect                EnemyIsDead        True \nPrecondition   HealthRecovered  True \nkey               curr value   goal value \nEnemyIsDead        True                   True \nHealthRecovered  False         \n              True \nkey               curr value    goal value \nEnemyIsDead         True                    True \nHealthRecovered   True                       True \n                          Key                            value \nEffect                HealthRecovered     True \nPrecondition   none                           none \ntake \ncover \n \nOn the other hand, planning is a more complicated goal-direct ed behavior and more on \nplanning will be given in Section 4. The benefits of a goal-oriented planning behavior are \nstated as follows in (Yue & de-Byl, 2006). \n There are no hard-coded plans \n Code maintenance is minimized \n Bugs are minimized  when planning \n Code is reusable \n \nThe drawbacks of a goal-oriented planning behavior are as stated as follows in  (Yue & de-\nByl, 2006): \n \n Real-time planning requires processing time \n More complex plans require more time \n \nDifferent aspects of goal-directed behavior and planning such as representation of world, \narchitectures and applications can be found in (Orkin, 2005), (Orkin,  2004), (Narayek, 2002), \n(IGDA, 2005) and (Namee & Cunningham, 2001). \n \n4. Game AI in General \n \nOne of the aims of Game AI is to increase the difficulty of the g ame to challenge the human \nplayers. The game AI should lead to a fulfilling gam e experience. On the other hand, games \ntake place in dynamic complex worlds in which compl ex decisions must be made, often \nbased on partial knowledge (Fairclough et al., 2001). \nIt is usual to state that Non Player Characters are AI-controlled charact ers that can only \ninteract with PCs (Player Characters) through scripted events or artificial i ntelligence (AI). \nHowever, what is it that is called Artificial Intel ligence in an NPC? For example, World of \nWarcraft is one of the most popular games and its NPCs are stated to b e AI controlled \n(Blizzard, 2005). Even though it is so popular, it actually has very littl e AI composed of \nreactive agents and a great deal of scripted events. For example, a player is tasked w ith \nescorting an NPC so that he can walk around and look for his lost bac kpack or something \nsimilar (where you meet monsters and assassins on t he way, also scripted NPCs, and \neverything woven into a storyline about this man's misfortune). On the other hand, even \nthough it is \"low AI\", this is something which adds to the game experience in terms of AI.  \nWhat kind of intelligent behaviors are expected from  NPCs? In general, an NPC is expected \nto maximize goal achievement by choosing the most o ptimal actions given the available \ninformation. An exception to the rule could be when more human-like actions may be a \nbetter choice than the most optimal action, for the sake of realism. \nThe most commonly used AI methodologies to achieve game AI can be stated as follows \n(McGee, 2005): \n \n Decision trees: can be realized by If-Then statements.. \n Finite state machines \n Command hierarchies \nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications230\n \n Manager task assignment \n Path finding (A*) \n Terrain analysis \n Influence mapping \n Formations \n Flocking \n Emergent behaviour \n \nInfluence mapping is a technique for terrain analysis to identify boundaries of control or \notherwise interesting points/areas/features of a map.  \nOther possibilities are: \n Artificial Neural Networks \n Genetic Algorithms \n Fuzzy logic \n \nScripting is the most common means of control in Game AI. Path finding is another common \nuse for AI, widely seen in RTS (Real Time Strategy) games. Emergent AI has been explored \nin Black & White. \nIn addition to the methodologies stated above, cheating is also considered a valid technique \nin game AI. The position of an unforeseen object can  simply be looked up in the game’s \nscene graph (Fairclough et al., 2001). This kind of cheating can cause a feeling of unfairness \non the player character’s behalf and too much of it might not be appropriate for that reason.  \nAs human beings, what is important for us when selecting  an action in a certain situation is \nto behave in a way that we believe is the right way  in the particular situation. For that \nreason, we have certain action formats which tell us what to do or how to act  under various \ncircumstances. Such behavior can be implemented using rules , and Finite State Machines \nmodel this by combining sets of such rules into \"st ates\" where each state also contains rules \nfor which conditions would cause an agent to change state.  \nFSMs are very rigid and behave poorly when confronted by sit uations not dreamed of by \nthe game designer (Fairclough et al., 2001). The be havior of the NPC is governed by a set of \nrules, each rule having a condition and some action (s) to execute when this condition is \nsatisfied by the state of the world (Fairclough et al., 2001). Therefore, as a player interacts \nwith an NPC he gets to know the behavior of the NPC  and can predict what it will do next \nand can develop a plan to despatch the NPC (Fairclough et al., 2001). Non-deterministic \nFSMs are also employed to increase the unpredictabi lity of NPCs so that the “fun” side of a \ngame increases (Brownlee). \nOn the other hand, we as humans learn from our mistakes. In (Scott, 2002), it is stated that in \ngeneral, game AI lacks the learning and reasoning cap abilities of humans and that game AI \ncould address the fields of machine learning, decision making based on arbitrary data input, \nreasoning etc. However, in several games, game AI encompasses some amount o f learning \nand reasoning capabilities (e.g. learning capability of creatures in Black and White). An NPC \nwhich executes FSMs to mimic human behavior can lear n from its mistakes and build up its \nown experience to be able to act smarter in time. Equipped with an FSM, an NPC should be \nable to find out which of its actions has been beneficial, which o f them have not been \nbeneficial and what other action types it could emp loy under given circumstances. Learning \n \nactions which is not in its repertoire and learning them on its own would be a real challenge \nfor an NPC especially when it would obviously lack the observational and mimicking by \nimitation or natural language understanding capacities of a human player. The research in \nAI towards this direction can also find its application for developing NPCs.  \n \nIn (Evans, 2001), learning is stated to cover the following characteristics, specifically for the \ngame Black and White: \n \n Learning that (e.g. learning that there is a town nearby with plenty of food) \n \n Learning how (e.g. learning how to throw things, improving your skill over time) \n \n Learning how sensitive to be to different desires (e.g. learning how l ow your \nenergy must be before you should start to feel hungry)  \n \n Learning which types of object you should be nice to, which types of obj ect you \nshould eat, etc. (e.g. learning to only be nice to big creatures who know spells). \n \n Learning which methods to apply in which situations (e.g. if you want to attack \nsomebody, should you use magic or a more straightforward approach?) \n \nLearning can be initiated in a number of very different ways (Evans, 2001): \n \n From player feedback, stroking or slapping the creature (NPC).  \n \n From being given a command: when the creature is told to attack a town, the \ncreature learns that that sort of town should be attacked.  \n \n From the creature observing others: observing the player, other creatures, or \nvillagers.  \n \n From the creature reflecting on his experience: after performing an action to satisfy \na motive, seeing how well that motive was satisfied , and adjusting the weights \nrepresenting how sensible it is to use that action in that sort of situation. \n \nReasoning is about finding out why something has happened while showing an awareness \nof goals and assessing the relative importance of different goals (Hawes, 2000). If the game \nAI reasons better, the NPCs would become more agent-like.  \n(Wintermute, 2007) presents the use of SOAR architecture to meet the deman ds on the AI in \nRTS games. A discussion of the CogAff architecture as the basis for an agent that can display \ngoal-oriented behavior is given in (Hawes, 2000).  \nPlanning in real-time is an alternative to the more common techniques of mode ling \ncharacter behavior with scripts or finite state machines (FSMs). Rather than trav ersing a \npredefined graph of state transitions, a planning Non Player Character (NPC) searches for a \nsequence of actions to satisfy some goal. Considera tions for developing an agent \narchitecture for real-time planning in games is given in (Orkin, 2005). \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 231\n \n Manager task assignment \n Path finding (A*) \n Terrain analysis \n Influence mapping \n Formations \n Flocking \n Emergent behaviour \n \nInfluence mapping is a technique for terrain analysis to identify boundaries of control or \notherwise interesting points/areas/features of a map.  \nOther possibilities are: \n Artificial Neural Networks \n Genetic Algorithms \n Fuzzy logic \n \nScripting is the most common means of control in Game AI. Path finding is another common \nuse for AI, widely seen in RTS (Real Time Strategy) games. Emergent AI has been explored \nin Black & White. \nIn addition to the methodologies stated above, cheating is also considered a valid technique \nin game AI. The position of an unforeseen object can  simply be looked up in the game’s \nscene graph (Fairclough et al., 2001). This kind of cheating can cause a feeling of unfairness \non the player character’s behalf and too much of it might not be appropriate for that reason.  \nAs human beings, what is important for us when selecting  an action in a certain situation is \nto behave in a way that we believe is the right way  in the particular situation. For that \nreason, we have certain action formats which tell us what to do or how to act  under various \ncircumstances. Such behavior can be implemented using rules , and Finite State Machines \nmodel this by combining sets of such rules into \"st ates\" where each state also contains rules \nfor which conditions would cause an agent to change state.  \nFSMs are very rigid and behave poorly when confronted by sit uations not dreamed of by \nthe game designer (Fairclough et al., 2001). The be havior of the NPC is governed by a set of \nrules, each rule having a condition and some action (s) to execute when this condition is \nsatisfied by the state of the world (Fairclough et al., 2001). Therefore, as a player interacts \nwith an NPC he gets to know the behavior of the NPC  and can predict what it will do next \nand can develop a plan to despatch the NPC (Fairclough et al., 2001). Non-deterministic \nFSMs are also employed to increase the unpredictabi lity of NPCs so that the “fun” side of a \ngame increases (Brownlee). \nOn the other hand, we as humans learn from our mistakes. In (Scott, 2002), it is stated that in \ngeneral, game AI lacks the learning and reasoning cap abilities of humans and that game AI \ncould address the fields of machine learning, decision making based on arbitrary data input, \nreasoning etc. However, in several games, game AI encompasses some amount o f learning \nand reasoning capabilities (e.g. learning capability of creatures in Black and White). An NPC \nwhich executes FSMs to mimic human behavior can lear n from its mistakes and build up its \nown experience to be able to act smarter in time. Equipped with an FSM, an NPC should be \nable to find out which of its actions has been beneficial, which o f them have not been \nbeneficial and what other action types it could emp loy under given circumstances. Learning \n \nactions which is not in its repertoire and learning them on its own would be a real challenge \nfor an NPC especially when it would obviously lack the observational and mimicking by \nimitation or natural language understanding capacities of a human player. The research in \nAI towards this direction can also find its application for developing NPCs.  \n \nIn (Evans, 2001), learning is stated to cover the following characteristics, specifically for the \ngame Black and White: \n \n Learning that (e.g. learning that there is a town nearby with plenty of food) \n \n Learning how (e.g. learning how to throw things, improving your skill over time) \n \n Learning how sensitive to be to different desires (e.g. learning how low your \nenergy must be before you should start to feel hungry)  \n \n Learning which types of object you should be nice to, which types of obj ect you \nshould eat, etc. (e.g. learning to only be nice to big creatures who know spells). \n \n Learning which methods to apply in which situations (e.g. if you want to attack \nsomebody, should you use magic or a more straightforward approach?) \n \nLearning can be initiated in a number of very different ways (Evans, 2001): \n \n From player feedback, stroking or slapping the creature (NPC).  \n \n From being given a command: when the creature is told to attack a town, the \ncreature learns that that sort of town should be attacked.  \n \n From the creature observing others: observing the player, other creatures, or \nvillagers.  \n \n From the creature reflecting on his experience: after performing an action to satisfy \na motive, seeing how well that motive was satisfied , and adjusting the weights \nrepresenting how sensible it is to use that action in that sort of situation. \n \nReasoning is about finding out why something has happened while showing an awareness \nof goals and assessing the relative importance of different goals (Hawes, 2000). If the game \nAI reasons better, the NPCs would become more agent-like.  \n(Wintermute, 2007) presents the use of SOAR architecture to meet the deman ds on the AI in \nRTS games. A discussion of the CogAff architecture as the basis for an agent that can display \ngoal-oriented behavior is given in (Hawes, 2000).  \nPlanning in real-time is an alternative to the more common techniques of mod eling \ncharacter behavior with scripts or finite state machines (FSMs). Rather than tr aversing a \npredefined graph of state transitions, a planning Non Player Character (NPC) searches for a \nsequence of actions to satisfy some goal. Considera tions for developing an agent \narchitecture for real-time planning in games is given in (Orkin, 2005). \nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications232\n \nOne project regarding saving the NPCs from being predictable and even a llowing them to \nmake predictions about the human player is the TCD Game AI project (Fairclough et al., \n2001). On the other hand, Case-Based Plan Recognition is proposed as a prediction \nmechanism for NPCs to predict a player’s actions (Kerkez & Cox, 2001). \n \n4.1 Game AI Specific to Different Genres: NPC Behaviors, AI Methodologies in Use, \nExpected AI Challenges \nGames can be grouped under different types: according t o their nature: Real Time Strategy \n(RTS), First Person Shooter (FPS), Role Playing Gam e (RPG), God Games etc. This section \nwill present a mixture of the need for AI, the meth ods of AI and the behaviors that can be \nobtained by AI for different kind of games.  \n \nRole Playing Games \nIn RPG games, a team is built up to reach a common goal. Some fine ex amples of RPG's are \nSecret of Mana, the games in the Final Fantasy serie s and other many varieties. The \nintelligence required from a team or from individua l characters (collaborating or \ncooperating) depends on how complex behavior is required to reach the common goal, what \nkind of resources the team or individuals in the team hav e and whether the team members \nhave primitive or advanced collaboration strategies . There is a need for more realistic and \nengaging NPCs in these games (Fairclough et al., 2001).  \n \nFirst Person Shooter Games \nFirst-person shooter games (FPS games), emphasize sho oting and combat from the \nperspective of the character controlled by the player. FPS-type games usually implement the \nlayered structure of the artificial intelligence sy stem. Layers at the lower levels handle the \nmost elementary tasks, such as determining the optimal path to the target or playing \nappropriate sequences of character animation. The higher levels are responsi ble for tactical \nreasoning and selecting the behavior which an AI agent should assume in acc ordance with \nits present strategy. The examples for tasks of higher layers are whether the agent should \npatrol the area, enter combat or run through the map searching for an op ponent (Grzyb, \n2005). \nSome fine examples of FPS games would be Half-Life 1, Half-Life 2 , Counter-Strike, Doom \nIII and Quake IV. \nThe NPCs in the original Half-Life 1 released in 1998 had A I behaviors which were not \npresent in previous games. For example, AI comrades and enemies had di fferent reactions \nfor getting shot, spotting grenades and even a realistic awareness of the actions of the \nhuman player. As a result of displaying this intelli gent behavior, Half-Life 1 quickly \nasserted itself as having the best AI of any game at  the time. After Half-Life 1, more and \nmore games started to focus on the AI aspect of game design instead of just graphics. Today, \ncombat AI can be seen ducking around corners or behind b oxes and tossing the player's \ngrenades back. In many cases, AI controlled NPCs are eve n standing in for real players in \nmultiplayer games. Even though combat AI can dodge incoming fire and shoot like a skilled \nplayer, there are four major things that human combatants offer over A I: knowledge of their \nenvironment, efficient use of teamwork, the ability to \"hunt\", and survi val instincts \n(Schreiner). However, some progress has since been made to address each of these issues.  \n \nReal Time Strategy Games \nStrategy games require that the human player displays  skillful and planned behavior in \norder to play efficiently and hence achieve victory. Real-time strategy ga mes are strategy \ngames which are played in a real-time environment. In the RTS game environment, the \nhuman and computer controlled players compete for re sources. The most common setting \nfor RTS games is the war-game setting, where in addi tion to resource management the \nplayer engages in war. The resource management in R TS games encompasses obtaining \nresources and utilizing those resources to gain an a dvantage. Resources are valuable \nminerals, energy, or other materials. Building an a rmy and attacking strategic objectives, \nsuch as locations with access to resources, are asp ects which make an RTS game a “war \ngame”.  \nFine examples of RTS games would be Starcraft 1 and 2, Warcraft 1-3, Sup reme \nCommander, the different games in the Command and C onquer series, and many other \nvarieties of games as well. \nAt the low levels of AI, path planning is important whereas at  higher levels, there are \nmodules responsible for economy, development or, ve ry importantly, a module to analyse \nthe game map (Grzyb, 2005).  \nIn Warcraft 3, users are called upon to create an a rmy to defeat one or more computer-\ncontrolled villages with armies of their own. Compu ter controlled villages form alliances, \nscout surrounding areas and devise appropriate batt le plans to do their best to be the last \nvillage standing (Wexler, 2002). \n \nGod Games \nThe focus of a god game tends to be control over the lives of people, anywhere from \nmicromanaging a family to overseeing the rise of a civilization as in Spore (Maxis, 2008). \nAlso, Black and White is a god game developed by Lio nhead Studios and it was \nimplemented through a variety of AI algorithms and techniques in 2002. W hat sets “Black \nand White” apart from any other game before it is i ts advanced use of AI. There are two \ntypes of intelligent agents in “Black and White”. The first type is the community of villagers. \nThe villagers have their knowledge, desires and bel iefs represented in large tables and \nsituation calculus. The other intelligent agent is the creature. AI in the creature allows the \ncreature to learn how to satisfy its master and know  how to correctly act based upon its \nbeliefs and perceptions (Funge, 1999). Symbolic attribute-value pairs are used to represent a \ncreature’s belief about any individual object. This  type of representation is used with rule-\nbased AI to give creatures basic intelligence about objects (W exler, 2002). Decision trees are \nused to represent agents’ beliefs about general type of objects (Wexler, 2002). Neural \nnetworks are used to represent desires (Wexler, 2002). The creatures also learn facts about its \nsurroundings, how to do certain tasks, how sensitive to be to its desires, how to behave to or \naround certain objects, and which methods to apply in certain situat ions. The user can help \nthe creature to learn or it can learn to please its user by differentiating the tasks that pl ease \nthe user versus the tasks that do not.  \nMore advanced AI in terms of a partial-planner with  which a creature can satisfy its desires \nand goals is foreseen to be included in “Black and White”. This way a user can create a list \nof goals that it wishes for the creature to complete (Bandi et al., 1999). \n \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 233\n \nOne project regarding saving the NPCs from being predictable and even a llowing them to \nmake predictions about the human player is the TCD Game AI project (Fairclough et al., \n2001). On the other hand, Case-Based Plan Recognition is proposed as a prediction \nmechanism for NPCs to predict a player’s actions (Kerkez & Cox, 2001). \n \n4.1 Game AI Specific to Different Genres: NPC Behaviors, AI Methodologies in Use, \nExpected AI Challenges \nGames can be grouped under different types: according t o their nature: Real Time Strategy \n(RTS), First Person Shooter (FPS), Role Playing Gam e (RPG), God Games etc. This section \nwill present a mixture of the need for AI, the meth ods of AI and the behaviors that can be \nobtained by AI for different kind of games.  \n \nRole Playing Games \nIn RPG games, a team is built up to reach a common goal. Some fine ex amples of RPG's are \nSecret of Mana, the games in the Final Fantasy serie s and other many varieties. The \nintelligence required from a team or from individua l characters (collaborating or \ncooperating) depends on how complex behavior is required to reach the common goal, what \nkind of resources the team or individuals in the team hav e and whether the team members \nhave primitive or advanced collaboration strategies . There is a need for more realistic and \nengaging NPCs in these games (Fairclough et al., 2001).  \n \nFirst Person Shooter Games \nFirst-person shooter games (FPS games), emphasize sho oting and combat from the \nperspective of the character controlled by the player. FPS-type games usually implement the \nlayered structure of the artificial intelligence sy stem. Layers at the lower levels handle the \nmost elementary tasks, such as determining the optimal path to the target or playing \nappropriate sequences of character animation. The higher levels are responsi ble for tactical \nreasoning and selecting the behavior which an AI agent should assume in acc ordance with \nits present strategy. The examples for tasks of higher layers are whether the agent should \npatrol the area, enter combat or run through the map searching for an op ponent (Grzyb, \n2005). \nSome fine examples of FPS games would be Half-Life 1, Half-Life 2 , Counter-Strike, Doom \nIII and Quake IV. \nThe NPCs in the original Half-Life 1 released in 1998 had A I behaviors which were not \npresent in previous games. For example, AI comrades and enemies had di fferent reactions \nfor getting shot, spotting grenades and even a realistic awareness of the actions of the \nhuman player. As a result of displaying this intelli gent behavior, Half-Life 1 quickly \nasserted itself as having the best AI of any game at  the time. After Half-Life 1, more and \nmore games started to focus on the AI aspect of game design instead of just graphics. Today, \ncombat AI can be seen ducking around corners or behind b oxes and tossing the player's \ngrenades back. In many cases, AI controlled NPCs are eve n standing in for real players in \nmultiplayer games. Even though combat AI can dodge incoming fire and shoot like a skilled \nplayer, there are four major things that human combatants offer over A I: knowledge of their \nenvironment, efficient use of teamwork, the ability to \"hunt\", and surviv al instincts \n(Schreiner). However, some progress has since been made to address each of these issues.  \n \nReal Time Strategy Games \nStrategy games require that the human player displays  skillful and planned behavior in \norder to play efficiently and hence achieve victory. Real-time strategy g ames are strategy \ngames which are played in a real-time environment. In the RTS game environment, the \nhuman and computer controlled players compete for re sources. The most common setting \nfor RTS games is the war-game setting, where in addi tion to resource management the \nplayer engages in war. The resource management in R TS games encompasses obtaining \nresources and utilizing those resources to gain an a dvantage. Resources are valuable \nminerals, energy, or other materials. Building an a rmy and attacking strategic objectives, \nsuch as locations with access to resources, are asp ects which make an RTS game a “war \ngame”.  \nFine examples of RTS games would be Starcraft 1 and 2, Warcraft 1-3, Sup reme \nCommander, the different games in the Command and C onquer series, and many other \nvarieties of games as well. \nAt the low levels of AI, path planning is important whereas at  higher levels, there are \nmodules responsible for economy, development or, ve ry importantly, a module to analyse \nthe game map (Grzyb, 2005).  \nIn Warcraft 3, users are called upon to create an a rmy to defeat one or more computer-\ncontrolled villages with armies of their own. Compu ter controlled villages form alliances, \nscout surrounding areas and devise appropriate batt le plans to do their best to be the last \nvillage standing (Wexler, 2002). \n \nGod Games \nThe focus of a god game tends to be control over the lives of people, anywhere from \nmicromanaging a family to overseeing the rise of a civilization as in Spore (Maxis, 2008). \nAlso, Black and White is a god game developed by Lio nhead Studios and it was \nimplemented through a variety of AI algorithms and techniques in 2002. What sets “Black \nand White” apart from any other game before it is i ts advanced use of AI. There are two \ntypes of intelligent agents in “Black and White”. The first type is the community of villagers. \nThe villagers have their knowledge, desires and bel iefs represented in large tables and \nsituation calculus. The other intelligent agent is the creature. AI in the creature allows the \ncreature to learn how to satisfy its master and know  how to correctly act based upon its \nbeliefs and perceptions (Funge, 1999). Symbolic attribute-value pairs are used to represent a \ncreature’s belief about any individual object. This  type of representation is used with rule-\nbased AI to give creatures basic intelligence about objects ( Wexler, 2002). Decision trees are \nused to represent agents’ beliefs about general type of objects (Wexler, 2002). Neural \nnetworks are used to represent desires (Wexler, 2002). The creatures also learn facts about its \nsurroundings, how to do certain tasks, how sensitive to be to its desires, how to behave to or \naround certain objects, and which methods to apply in certain situat ions. The user can help \nthe creature to learn or it can learn to please its user by differentiating the tasks that pl ease \nthe user versus the tasks that do not.  \nMore advanced AI in terms of a partial-planner with  which a creature can satisfy its desires \nand goals is foreseen to be included in “Black and White”. This way a user can create a list \nof goals that it wishes for the creature to complete (Bandi et al., 1999). \n \nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications234\n \nAction-Adventure Games \nAction-adventure games focus on exploration and usually involve item gat hering, simple \npuzzle solving, and combat, e.g. Tomb Raider (Core Design, 1996). In act ion games, having \nthe player as a member of a squad or a team provides an opportunity for the further use of  \nmore complex AI. \nAlso there is need for more realistic and engaging NPCs in Adventure Games (Fairclough  et \nal., 2001).  \nThe other types of games are sport games, racing ga mes and puzzles. There are also games \nwhich do not fit squarely in any category. \n \n5. Evaluation of Games for Their Agent Characteristics \n \nIn Table 1 and Table 2, we use the agent definition given  in (Franklin & Graesser, 1997) to \nevaluate the agent characteristics of individual NPC s in a diverse selection of popular \ngames. \nIn reactive agents, a program is just a set of perce pt → action rules, commonly termed a \nproduction-rule system. In each step of the control cycle a rule is selected whose left hand \nside matches the agent’s current percept, and the action on that rule’s right hand side is then \neffected. The first column of Table 1 shows our evaluation of the reactive capabilities of the \nselected games. The value for reactivity can be High, Low or None in t he table, indicating \nthe ability of acting out useful reactive responses  in rapidly changing situations. For \nexample, an NPC is unexpectedly attacked on the way to a distant destination, and \ntemporarily stops in order to respond to the attack. \nAn agent is a temporally continuous software process that senses the environment and acts \non it over time, in pursuit of its own agenda and so as to effect what it senses in the future. \nThe corresponding column in Table 1 lists the extent to  which an agent’s behavior is \ninfluenced over time by what it senses in the environment.  \nIn goal-oriented agents, an agent applies actions in pursuit of a goal. A goal-oriented agent  \nis different from an agent where the agent does not necessarily try to achieve a goal, but it  \napplies an action just because it is right to do that action in a given situation (Table 1).  \n \nAutonomy characteristic of an agent is split furthe r into following aspects:  Self-sufficiency, \nComplexity of decision making, Variety of action re pertoire, Learning and Situatedness \n(Table 2). These are the aspects of autonomy that we deemed to be relevan t for game AI \nagents. \n \nSelf-sufficiency is a property of autonomy in agents. It has three aspects: \n1. Supervision by higher level agents where there is a hierarchy of agents and each \nlevel of the hierarchy can have various amounts of complexity.  \n \n2. Visible inter-agent communication. \n \n3. Being capable of supporting an agent’s own life without help, food, shelter etc. This \naspect does not apply in game environments. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 1. Evaluation of different games for their age nt aspects related to reactivity, being \ntemporally continuous and goal-oriented. \n \nVisible inter-agent communication is an aspect that influenc es an agent’s autonomy level. \nMore agent interaction might mean higher autonomy, e.g. one NPC informs another that \nthere is a danger. \nThe complexity of an agent’s decision-making mechan ism influences the quality of \ndecisions. For example, an agent that uses non-deterministic finite-state machines is better at \nconsidering alternative actions for a given situation compared to an agent that uses a \ndeterministic finite state machine. An NPC with a co ntroller of the former type is more \nlikely to survive compared to the latter.  \nHaving a variety of action repertoire will increase an agent’s levels of autonomy, by \nenabling it to choose between more actions. \nBeing able to learn would mean an agent is likely to become informed about what to do in \nsituations it is not currently able to take an actio n or take the most suitable action. From the \ngames referred to in Table 2, learning is a feature only present in Black & White 2. \nBeing situated and hence being informed about the environment al state is a property that \nexists in all the selected games of Table 2 and is a property of being autonomous for agents.  \n \n \n \n \n \n \n \nReactivity \n \nTemporally \ncontinuous \n \nGoal-oriented \n \nWorld of Warcraft \n \nLow \n \nLow \n \nYes \n \nHalf Life 2 (Single player \nmode) \n \nHigh \n \nLow \n \nYes \n \nSupreme Commander \n \nLow \n \nHigh \n \nYes \n \nWarcraft 3 \n \nLow \n \nHigh \n \nYes \n \nBlack & White 2 \n \nLow \n \nHigh \n \nYes \n \nTomb Raider: Anniversary \n \nLow \n \nLow \n \nYes \n \nUnreal Tournament 2004 \n(bots) \n \nHigh \n \nHigh \n \nYes \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 235\n \nAction-Adventure Games \nAction-adventure games focus on exploration and usually involve item gat hering, simple \npuzzle solving, and combat, e.g. Tomb Raider (Core Design, 1996). In act ion games, having \nthe player as a member of a squad or a team provides an opportunity for the further use of  \nmore complex AI. \nAlso there is need for more realistic and engaging NPCs in Adventure Games (Fairclough  et \nal., 2001).  \nThe other types of games are sport games, racing ga mes and puzzles. There are also games \nwhich do not fit squarely in any category. \n \n5. Evaluation of Games for Their Agent Characteristics \n \nIn Table 1 and Table 2, we use the agent definition given  in (Franklin & Graesser, 1997) to \nevaluate the agent characteristics of individual NPC s in a diverse selection of popular \ngames. \nIn reactive agents, a program is just a set of perce pt → action rules, commonly termed a \nproduction-rule system. In each step of the control cycle a rule is selected whose left hand \nside matches the agent’s current percept, and the action on that rule’s right hand side is then \neffected. The first column of Table 1 shows our evaluation of the reactive capabilities of the \nselected games. The value for reactivity can be High, Low or None in t he table, indicating \nthe ability of acting out useful reactive responses  in rapidly changing situations. For \nexample, an NPC is unexpectedly attacked on the way to a distant destination, and \ntemporarily stops in order to respond to the attack. \nAn agent is a temporally continuous software process that senses the environment and acts \non it over time, in pursuit of its own agenda and so as to effect what it senses in the future. \nThe corresponding column in Table 1 lists the extent to  which an agent’s behavior is \ninfluenced over time by what it senses in the environment.  \nIn goal-oriented agents, an agent applies actions in pursuit of a goal. A goal-oriented agent  \nis different from an agent where the agent does not necessarily try to achieve a goal, but it  \napplies an action just because it is right to do that action in a given situation (Table 1).  \n \nAutonomy characteristic of an agent is split furthe r into following aspects:  Self-sufficiency, \nComplexity of decision making, Variety of action re pertoire, Learning and Situatedness \n(Table 2). These are the aspects of autonomy that we deemed to be relevan t for game AI \nagents. \n \nSelf-sufficiency is a property of autonomy in agents. It has three aspects: \n1. Supervision by higher level agents where there is a hierarchy of agents and each \nlevel of the hierarchy can have various amounts of complexity.  \n \n2. Visible inter-agent communication. \n \n3. Being capable of supporting an agent’s own life without help, food, shelter etc. This \naspect does not apply in game environments. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 1. Evaluation of different games for their age nt aspects related to reactivity, being \ntemporally continuous and goal-oriented. \n \nVisible inter-agent communication is an aspect that influenc es an agent’s autonomy level. \nMore agent interaction might mean higher autonomy, e.g. one NPC informs another that \nthere is a danger. \nThe complexity of an agent’s decision-making mechan ism influences the quality of \ndecisions. For example, an agent that uses non-deterministic finite-state machines is better at \nconsidering alternative actions for a given situation compared to an agent that uses a  \ndeterministic finite state machine. An NPC with a co ntroller of the former type is more \nlikely to survive compared to the latter.  \nHaving a variety of action repertoire will increase an agent’s levels of autonomy, by \nenabling it to choose between more actions. \nBeing able to learn would mean an agent is likely to become informed about what to do in \nsituations it is not currently able to take an actio n or take the most suitable action. From the \ngames referred to in Table 2, learning is a feature only present in Black & White 2. \nBeing situated and hence being informed about the environm ental state is a property that \nexists in all the selected games of Table 2 and is a property of being autonomous for agents.  \n \n \n \n \n \n \n \nReactivity \n \nTemporally \ncontinuous \n \nGoal-oriented \n \nWorld of Warcraft \n \nLow \n \nLow \n \nYes \n \nHalf Life 2 (Single player \nmode) \n \nHigh \n \nLow \n \nYes \n \nSupreme Commander \n \nLow \n \nHigh \n \nYes \n \nWarcraft 3 \n \nLow \n \nHigh \n \nYes \n \nBlack & White 2 \n \nLow \n \nHigh \n \nYes \n \nTomb Raider: Anniversary \n \nLow \n \nLow \n \nYes \n \nUnreal Tournament 2004 \n(bots) \n \nHigh \n \nHigh \n \nYes www.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications236\n \nTable 2. Evaluation of different games for their agent aspects related to autonomy \n \n6. Conclusion \n \nIn this chapter, we investigated whether it is poss ible to view NPCs in games as game \nagents. We used the qualities of reactivity, being temporally continuous, autonomy and \nbeing goal-oriented for evaluating a representative set of popular commercial games on how \nmuch agent-like they are. Our evaluations show that some games have NPCs that achieve \nmore agent-like behavior than others. \nAlso, we give a survey on the use of various AI met hodologies in commercial games and in \ngame research. We indicate that the need for AI in g ames is centered around maximizing \ngoal achievement by choosing the most optimal actions given the available information. \nNPCs can challenge human players and add to the quality of experience if they can become \nbetter at achieving optimal behavior. \nFurthermore, we postulate that further investigatio n is required before conclusions can be \nmade about whether the given methodologies (especially those that are not commonly used  \nin commercial games at the moment) are really applic able in commercial games. Regarding \nthis point, the use of learning in games is relatively low in commer cial arena as can be \nobserved from Table 2 even though learning is an important aspect in achieving artificial \nintelligence. Another relevant point is that the non p layer characters are required to make \n \n \n \nSupervision \nby higher \nlevel agents \n \nVisible \ninter-\nagent \ncommu-\nnication \n \nComplexity \nof decision \nmaking \n \nVariety of \naction \nrepertoire \n \n \nLearning \n \n \nSituatedness \n \nWorld of \nWarcraft \n \nNone \n \nLow \n \nLow \n \nLow \n \nNo \n \nYes \nHalf Life 2 \n(Single \nplayer mode) \n \nNone \n \nHigh \n \nLow \n \nHigh \n \nNo \n \nYes \n \nSupreme \nCommander \n \nHigh \n \nLow \n \nLow \n \nHigh \n \nNo \n \nYes \n \nWarcraft 3 \n \nHigh \n \nLow \n \nLow \n \nHigh \n \nNo \n \nYes \n \nBlack & \nWhite 2 \n \nLow  \n \nLow \n \nHigh \n \nHigh \n \nYes \n \nYes \nTomb \nRaider: \nAnniversary \nNone  \nHigh \n \nLow \n \nLow \n \nNo \n \nYes \nUnreal \nTournament  \n2004 (bots) \n \nNone \n \nHigh \n \nHigh \n \nHigh \n \nNo \n \nYes \n \nreal-time decisions and that it does not seem practical to  add time consuming and \ncomplicated intelligence control mechanisms in them. \n \n7. References \n \nBandi, S., Cavazza, M. et al. (1999). Situated AI in Video Games, University of Branford \nBlizzard (2005). World of Warcraft, Blizzard. www.worldofwarcraft.com \nBrownlee, J. Finite State Machines (FSM), Artificial Intelligence Depot \nhttp://ai-depot.com/FiniteStateMachines/FSM.html. \nCore Design (1996). Tomb Raider, http://www.tombraider.com/, Eidos Interactive \nEvans, R. (2001). The Future of AI in Games: A Personal View, Game Developer Magazine. \nFairclough, C.; Fagan, M. et al.( 2001). Research Directions for AI in Computer Games, \nProceedings of the Twelfth Irish Conference on Artif icial Intelligence and Cognitive \nScience, pp. 333 – 344. \nFranklin, S. & Graesser, A (1996). Is it an Agent, or just a Program?: A Taxonomy for \nAutonomous Agents, Proceedings of the Workshop Intelligent Agents III, Agent \nTheories, Architectures, and Languages , pp. 21–35, ISBN:3-540-I-0  Springer Verlag, \nLondon. \nFunge, J. (1999). AI for Computer Games and Animation: A Cognitive Modeling Approach , AK \nPeters Ltd, ISBN: 1-56881-103.9, Natick, MA  \nGrzyb, J. (2005). Artificial Intelligence in Games, The Software Developer's Journal \nHawes, N. (2000). Real-Time Goal-Oriented Behavior for Computer Game Agents. \nProceedings of the 1st International Conference on Intelligen t Games and Simulation , \nLondon, November, 2000 \nHubbard, V. (2005) F.E.A.R First Encounter Assault Recon, Monolith Productions, Vivendi \nUniversal \nIGDA (2005). The AIISC Report \nKerkez, B. & Cox M. T. (2001). Incremental Case-Based Plan Recognition Using State Indices, \nProceedings of the 4th International Conference on C ase-Based Reasoning: Case-Based \nReasoning Research and Development, pp. 291–305, ISBN: 978-3-540-42358-4, Springer-\nVerlag, Berlin \n Luck, M. & McBurney, P. et al. (2003). Agent Technology: Enabling Next Generat ion \nComputing A Roadmap for Agent Based Computing, AgentLink 2. \nMaxis  (2008). Spore, Electronic Arts. http://www.spore.com/ \nMcGee, K. (2005). Advanced Game Programming: AI    Session 2: Genres, Roles, Techniques, \nhttp://www.ida.liu.se/~kevmc/courses/2005-ht02/tsbk10-session-2.pdf \nNamee, B. M. &  Cunningham, P. (2001). Proposal for an Agent Architecture for Proactive \nPersistent Non Player Characters, Proceedings of the 12th I rish Conference on \nArtificial Intelligence and Cognitive Science: 221 – 232 \nNarayek, A. (2002). Intelligent Agents for Computer Games. Computers and Games, \nProceedings of Second International Conference, CG 2000, pp. 414-422, Springer \nOrkin, J. (2004). Symbolic Representation of Game World State: Toward Real-Time Planning \nin Games, Proceedings of the Workshop Challenges in Game AI, AAAI \nOrkin, J. (2005). Agent Architecture Considerations for Real-Time Planning in Games, \nProceedings of  AIIDE \nPfeifer, R. &  Scheier ,C. (1999). Understanding Intelligence, MIT Press. \nwww.intechopen.com\nA Survey on the Need and Use of AI in Game Agents 237\n \nTable 2. Evaluation of different games for their agent aspects related to autonomy \n \n6. Conclusion \n \nIn this chapter, we investigated whether it is poss ible to view NPCs in games as game \nagents. We used the qualities of reactivity, being temporally continuous, autonomy and \nbeing goal-oriented for evaluating a representative set of popular commercial games on how \nmuch agent-like they are. Our evaluations show that some games have NPCs that achieve \nmore agent-like behavior than others. \nAlso, we give a survey on the use of various AI met hodologies in commercial games and in \ngame research. We indicate that the need for AI in g ames is centered around maximizing \ngoal achievement by choosing the most optimal actions given the available information. \nNPCs can challenge human players and add to the quality of experience if they can become \nbetter at achieving optimal behavior. \nFurthermore, we postulate that further investigatio n is required before conclusions can be \nmade about whether the given methodologies (especially those that are not commonly used  \nin commercial games at the moment) are really applic able in commercial games. Regarding \nthis point, the use of learning in games is relatively low in commer cial arena as can be \nobserved from Table 2 even though learning is an important aspect in achieving artificial \nintelligence. Another relevant point is that the non player characters are required to make \n \n \n \nSupervision \nby higher \nlevel agents \n \nVisible \ninter-\nagent \ncommu-\nnication \n \nComplexity \nof decision \nmaking \n \nVariety of \naction \nrepertoire \n \n \nLearning \n \n \nSituatedness \n \nWorld of \nWarcraft \n \nNone \n \nLow \n \nLow \n \nLow \n \nNo \n \nYes \nHalf Life 2 \n(Single \nplayer mode) \n \nNone \n \nHigh \n \nLow \n \nHigh \n \nNo \n \nYes \n \nSupreme \nCommander \n \nHigh \n \nLow \n \nLow \n \nHigh \n \nNo \n \nYes \n \nWarcraft 3 \n \nHigh \n \nLow \n \nLow \n \nHigh \n \nNo \n \nYes \n \nBlack & \nWhite 2 \n \nLow  \n \nLow \n \nHigh \n \nHigh \n \nYes \n \nYes \nTomb \nRaider: \nAnniversary \nNone  \nHigh \n \nLow \n \nLow \n \nNo \n \nYes \nUnreal \nTournament  \n2004 (bots) \n \nNone \n \nHigh \n \nHigh \n \nHigh \n \nNo \n \nYes \n \nreal-time decisions and that it does not seem practical to  add time consuming and \ncomplicated intelligence control mechanisms in them. \n \n7. References \n \nBandi, S., Cavazza, M. et al. (1999). Situated AI in Video Games, University of Branford \nBlizzard (2005). World of Warcraft, Blizzard. www.worldofwarcraft.com \nBrownlee, J. Finite State Machines (FSM), Artificial Intelligence Depot \nhttp://ai-depot.com/FiniteStateMachines/FSM.html. \nCore Design (1996). Tomb Raider, http://www.tombraider.com/, Eidos Interactive \nEvans, R. (2001). The Future of AI in Games: A Personal View, Game Developer Magazine. \nFairclough, C.; Fagan, M. et al.( 2001). Research Directions for AI in Computer Games, \nProceedings of the Twelfth Irish Conference on Artif icial Intelligence and Cognitive \nScience, pp. 333 – 344. \nFranklin, S. & Graesser, A (1996). Is it an Agent, or just a Program?: A Taxonomy for \nAutonomous Agents, Proceedings of the Workshop Intelligent Agents III, Agent \nTheories, Architectures, and Languages , pp. 21–35, ISBN:3-540-I-0  Springer Verlag, \nLondon. \nFunge, J. (1999). AI for Computer Games and Animation: A Cognitive Modeling Approach , AK \nPeters Ltd, ISBN: 1-56881-103.9, Natick, MA  \nGrzyb, J. (2005). Artificial Intelligence in Games, The Software Developer's Journal \nHawes, N. (2000). Real-Time Goal-Oriented Behavior for Computer Game Agents. \nProceedings of the 1st International Conference on Intelligen t Games and Simulation , \nLondon, November, 2000 \nHubbard, V. (2005) F.E.A.R First Encounter Assault Recon, Monolith Productions, Vivendi \nUniversal \nIGDA (2005). The AIISC Report \nKerkez, B. & Cox M. T. (2001). Incremental Case-Based Plan Recognition Using State Indices, \nProceedings of the 4th International Conference on C ase-Based Reasoning: Case-Based \nReasoning Research and Development, pp. 291–305, ISBN: 978-3-540-42358-4, Springer-\nVerlag, Berlin \n Luck, M. & McBurney, P. et al. (2003). Agent Technology: Enabling Next Generat ion \nComputing A Roadmap for Agent Based Computing, AgentLink 2. \nMaxis  (2008). Spore, Electronic Arts. http://www.spore.com/ \nMcGee, K. (2005). Advanced Game Programming: AI    Session 2: Genres, Roles, Techniques, \nhttp://www.ida.liu.se/~kevmc/courses/2005-ht02/tsbk10-session-2.pdf \nNamee, B. M. &  Cunningham, P. (2001). Proposal for an Agent Architecture for Proactive \nPersistent Non Player Characters, Proceedings of the 12th I rish Conference on \nArtificial Intelligence and Cognitive Science: 221 – 232 \nNarayek, A. (2002). Intelligent Agents for Computer Games. Computers and Games, \nProceedings of Second International Conference, CG 2000, pp. 414-422, Springer \nOrkin, J. (2004). Symbolic Representation of Game World State: Toward Real-Time Planning \nin Games, Proceedings of the Workshop Challenges in Game AI, AAAI \nOrkin, J. (2005). Agent Architecture Considerations for Real-Time Planning in Games, \nProceedings of  AIIDE \nPfeifer, R. &  Scheier ,C. (1999). Understanding Intelligence, MIT Press. \nwww.intechopen.com\nModeling, Simulation and Optimization – Focus on Applications238\n \nRussell, S. &  Norvig, P. (2003). Artificial Intelligence: A Modern Approach, Prentice Hall \nSchreiner, Artificial Intelligence in Game Design, http://ai-depot.com/GameAI/ \nDesign.html \nScott, B. (2002). The Illusion of Intelligence, In: AI Game Programming Wisdom , Rabin, Steve \n(Eds),  19–20, Charles River Media \nWexler, J. (2002). Artificial Intelligence in Games : A look at the smarts behind Lionhead \nStudio's \"Black and White\" and where it can go and will go in the future, University \nof Rochester. \nWintermute, S., Xu, J., & Laird, J.E. (2007). SORTS: A Human-Level Approach to Real-Time \nStrategy AI, Proceedings of the Third Artificial Intelligence and Inte ractive Digital \nEntertainment Conference (AIIDE-07), Stanford, California.  \nYue, B. & de-Byl, P. (2006). The state of the art in game AI standardisation, Proceedings of \nACM International Conference \n \nAcknowledgement \nThis chapter is a revised version of a paper by the authors published in the Proceedings o f \nAgent Directed Simulation (ADS'08) within the Conference SpringSim’08, pp. 124-131, ISBN: \n1-56555-319-5, Ottawa, Canada, April 2008, The Society for Computer Simulation \nInternational, San Diego. \nWe would like to thank Arild Jacobsen from Gjøvik U niversity College for sharing his ideas \nabout different parts of this chapter with us and his valuable help with th e proof-reading of \nthe chapter. \nwww.intechopen.com\nModeling Simulation and Optimization - Focus on App lications\nEdited by Shkelzen Cakaj\nISBN 978-953-307-055-1\nHard cover, 312 pages\nPublisher InTech\nPublished online 01, March, 2010\nPublished in print edition March, 2010\nInTech Europe\nUniversity Campus STeP Ri \nSlavka Krautzeka 83/A \n51000 Rijeka, Croatia \nPhone: +385 (51) 770 447 \nFax: +385 (51) 686 166\nwww.intechopen.com\nInTech China\nUnit 405, Office Block, Hotel Equatorial Shanghai \nNo.65, Yan An Road (West), Shanghai, 200040, China \nPhone: +86-21-62489820 \nFax: +86-21-62489821\nThe book presents a collection of chapters dealing with a wide selection of topics concerning differen t\napplications of modeling. It includes modeling, sim ulation and optimization applications in the areas of medical\ncare systems, genetics, business, ethics and lingui stics, applying very sophisticated methods. Algorit hms, 3-D\nmodeling, virtual reality, multi objective optimiza tion, finite element methods, multi agent model sim ulation,\nsystem dynamics simulation, hierarchical Petri Net model and two level formalism modeling are tools an d\nmethods employed in these papers.\nHow to reference\nIn order to correctly reference this scholarly work , feel free to copy and paste the following:\nSule Yildirim and Sindre Berg Stene (2010). A Surve y on the Need and Use of AI in Game Agents, Modelin g\nSimulation and Optimization - Focus on Applications , Shkelzen Cakaj (Ed.), ISBN: 978-953-307-055-1, In Tech,\nAvailable from: http://www.intechopen.com/books/mod eling-simulation-and-optimization-focus-on-\napplications/a-survey-on-the-need-and-use-of-ai-in- game-agents\n\n© 2010 The Author(s). Licensee IntechOpen. This chapter is distributed\nunder the terms of the \nCreative Commons Attribution-NonCommercial-\nShareAlike-3.0 License\n, which permits use, distribution and reproduction for\nnon-commercial purposes, provided the original is properly cited and\nderivative works building on this content are distributed under the same\nlicense.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.4088561236858368
    },
    {
      "name": "Psychology",
      "score": 0.34495896100997925
    }
  ],
  "institutions": []
}