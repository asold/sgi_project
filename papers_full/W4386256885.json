{
  "title": "Evaluating the Performance of different large language models on health consultation and patient education in urolithiasis",
  "url": "https://openalex.org/W4386256885",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2096405897",
      "name": "Haifeng Song",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2107347446",
      "name": "Yi Xia",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117976156",
      "name": "Zhichao Luo",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2073720603",
      "name": "Hui Liu",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2103229335",
      "name": "Yan Song",
      "affiliations": [
        "Sheng Jing Hospital",
        "China Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2105319205",
      "name": "Xue Zeng",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2108323255",
      "name": "Tianjie Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A1971544330",
      "name": "Guang-Xin Zhong",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2110572987",
      "name": "Jianxing Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2100106610",
      "name": "Ming Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2102501107",
      "name": "Guangyuan Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1922707750",
      "name": "Bo Xiao",
      "affiliations": [
        "Tsinghua University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4310707847",
    "https://openalex.org/W4289222642",
    "https://openalex.org/W2988101254",
    "https://openalex.org/W4319455199",
    "https://openalex.org/W4379599615",
    "https://openalex.org/W4320920036",
    "https://openalex.org/W4321366933",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4368275176",
    "https://openalex.org/W4366447635",
    "https://openalex.org/W4324308091",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4319656339",
    "https://openalex.org/W4317376696",
    "https://openalex.org/W4319301633",
    "https://openalex.org/W4320486331",
    "https://openalex.org/W4319332853",
    "https://openalex.org/W4318678021",
    "https://openalex.org/W4319985830",
    "https://openalex.org/W2163524240"
  ],
  "abstract": "Abstract Objectives To evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New Bing) that have large user bases and significant social attention, in the context of medical consultation and patient education in urolithiasis. Materials and methods In this study, we developed a questionnaire consisting of twenty-one questions and two clinical scenarios related to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to assess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms of accuracy, comprehensiveness, legibility, human care, and clinical case analysis ability based on a predesigned 5-point Likert scales. Visualization and statistical analyses were then employed to compare the four models and evaluate their performance. Results All models yielded relatively qualified results, except for Bard, which failed to provide a valid response to Question 13. Claude consistently scored the highest in all dimensions compared with the other three models. ChatGPT4 ranked second in accuracy, with a relatively stable output across multiple tests, but shortcomings were observed in empathy and care for counsellors. The Bard model exhibited the lowest accuracy and overall performance. Claude and ChatGPT4 both had a high capacity to analyze clinical cases of urolithiasis. Overall, the Claude model emerged as the best performer in urolithiasis consultations and education. Conclusion Claude demonstrated superior performance compared with the other three in urolithiasis consultation and education. This study highlights the remarkable potential of LLMs in medical health consultations and patient education, although professional review, further evaluation, and modifications are still required.",
  "full_text": "Page 1/16\nEvaluating the Performance of different large\nlanguage models on health consultation and patient\neducation in urolithiasis\nHaifeng Song  (  shf1990@hotmail.com )\nTsinghua University\nYi Xia \nSoutheast University\nZhichao Luo \nTsinghua University\nHui Liu \nTsinghua University\nYan Song \nSheng Jing Hospital of China Medical University\nXue Zeng \nTsinghua University\nTianjie Li \nTsinghua University\nGuangxin Zhong \nTsinghua University\nJianxing Li \nTsinghua University\nMing Chen \nSoutheast University\nGuangyuan Zhang \nSoutheast University\nBo Xiao \nTsinghua University\nResearch Article\nKeywords: urolithiasis, health consultation, large language model, ChatGPT, arti\u0000cial intelligence\nPosted Date: August 29th, 2023\nDOI: https://doi.org/10.21203/rs.3.rs-3293294/v1\nPage 2/16\nLicense:     This work is licensed under a Creative Commons Attribution 4.0 International License.  \nRead Full License\nPage 3/16\nAbstract\nObjectives\nTo evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New\nBing) that have large user bases and signi\u0000cant social attention, in the context of medical consultation\nand patient education in urolithiasis.\nMaterials and methods\nIn this study, we developed a questionnaire consisting of twenty-one questions and two clinical scenarios\nrelated to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to\nassess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms\nof accuracy, comprehensiveness, legibility, human care, and clinical case analysis ability based on a\npredesigned 5-point Likert scales. Visualization and statistical analyses were then employed to compare\nthe four models and evaluate their performance.\nResults\nAll models yielded relatively quali\u0000ed results, except for Bard, which failed to provide a valid response to\nQuestion 13. Claude consistently scored the highest in all dimensions compared with the other three\nmodels. ChatGPT4 ranked second in accuracy, with a relatively stable output across multiple tests, but\nshortcomings were observed in empathy and care for counsellors. The Bard model exhibited the lowest\naccuracy and overall performance. Claude and ChatGPT4 both had a high capacity to analyze clinical\ncases of urolithiasis. Overall, the Claude model emerged as the best performer in urolithiasis\nconsultations and education.\nConclusion\nClaude demonstrated superior performance compared with the other three in urolithiasis consultation and\neducation. This study highlights the remarkable potential of LLMs in medical health consultations and\npatient education, although professional review, further evaluation, and modi\u0000cations are still required.\nIntroduction\nUrolithiasis is a common disease of the urinary system, with an incidence rate ranging from 1–10%\nworldwide. The high recurrence rate and detrimental effects of urolithiasis impose signi\u0000cant health and\neconomic burdens on both patients and society. Therefore, early diagnosis, intervention, and strict follow-\nup are crucial for effective urolithiasis management, complication reduction, and prevention of disease\nrecurrence(1, 2). However, patients often lack reliable information regarding diagnosis, prognosis,\nPage 4/16\ntreatment options, side effects, and preventive measures at all stages of decision-making and treatment.\nProviding appropriate medical consultation services to patients with urolithiasis or suspected cases plays\nan important role in patient education, which can signi\u0000cantly improve prognosis and alleviate the burden\nof urolithiasis(3).\nLarge Language Models (LLMs) represent a type of arti\u0000cial intelligence (AI) model that generates natural\nlanguage text from copious amounts of data. Utilizing deep neural networks and machine learning\nalgorithms, such as transformers, LLMs are trained on vast quantities of text data and are capable of\nvarious natural language tasks, including summarization, translation, question answering, conversation,\nand even poetry generation. LLMs, as represented by ChatGPT, have also shown unique innovation and\nremarkable e\u0000ciency in various medical scenarios, such as answering medical and public health\ninquiries(4, 5), facilitating computer-aided diagnosis(6), providing treatment advice(7), and providing\nhealthcare education(8). These applications demonstrate the potential of LLMs in improving the quality\nand e\u0000ciency of medical consultations and patient education.\nIn urology, the application and evaluation of LLMs are limited. Görtz et al. established a chatbot named\nPROSCA and evaluated its performance in providing patient information regarding early detection of\nprostate cancer(9). The showed that PROSCA was well-received by patients and served as an additional\ninformative tool to bene\u0000t them. Similarly, Zhu et al. reported that LLMs (ChatGPT, YouChat, and NeevaAI)\ncan accurately address the fundamental inquiries from patients with prostate cancer, and analyze\nspeci\u0000c scenarios to a certain extent(10). However, the performance of LLMs for the consultation and\neducation of patients with urolithiasis remains unexplored and requires evaluation. This study aimed to\nevaluate the effectiveness of four large language models (Bard, Claude, ChatGPT4, and New Bing) that\nhave large user bases, robust quali\u0000cations, and signi\u0000cant social attention, in the context of medical\nconsultations and patient education regarding urolithiasis.\nMaterials and Methods\nWe designed a set of urolithiasis-related questions and clinical scenarios ranging from basic to\nadvanced. Subsequently, we simulated clinical consultations for each of the four models to assess their\nresponses to these inquiries. The answers provided by the models were evaluated by urolithiasis experts\nbased on objective and rigorous standards, and the results were collected. Finally, statistical analyses\nwere performed to compare the scores of the four models and evaluate their performance.\nQuestions and clinical scenarios design:\nA set of 21 questions that address the common concerns of patients with urolithiasis was collected.\nThese questions were curated through an analysis of queries from online consultation platforms, surveys\nconducted among hospitalized urolithiasis patients, and incorporation of the researchers' clinical\nexperience. The questions were categorized into simple and complex types with di\u0000culty levels ranging\nPage 5/16\nfrom general urolithiasis knowledge to cutting-edge diagnostic and therapeutic techniques. Two case\nscenarios with different complexities were created based on clinical experience.\nModel selection and test\nFour LLMs that possess substantial user bases, impressive backgrounds, and signi\u0000cant social attention\nwere evaluated. The models included in this study were Bard, Claude, ChatGPT4, and New Bing. Each\nmodel underwent three rounds of testing for all questions and the resulting outcomes were recorded. The\ntests were performed in late April 2023.\nScoring Criteria and procedure\n5-point Likert scale was used to evaluate the LLM outputs based on \u0000ve dimensions: accuracy,\ncomprehensiveness, legibility, human caring, and case analysis performance. Accuracy pertains to the\ncorrectness and adherence to scienti\u0000c knowledge and clinical guidelines in the provided information.\nComprehensiveness evaluates the extent to which the response addresses all relevant aspects of the\nquestion or case scenario. Legibility assesses the clarity of the response in terms of its logical structure,\nlanguage usage, and ease of comprehension for the target audience. Human care measures the degree to\nwhich the response demonstrates empathy towards patients, addresses their concerns, and respects their\nvalues and preferences. Lastly, the case analysis performance measures the pro\u0000ciency of the LLM in\ninterpreting case scenarios, identifying key issues, and providing a coherent and effective approach or\nsolution. The Likert scale was de\u0000ned as follows:\n1-Unacceptbale: The LLM's response signi\u0000cantly lacks in the particular criterion.\n2-Poor: The LLM's response lacks in the criterion but not to a severe extent.\n3-Fair: The LLM's response adequately but not exceptionally meets the criterion.\n4-Good: The LLM's response aligns well with the criterion.\n5-Excellent: The LLM's response excels in the criterion, exceeding the standard expectation.\nThree associate chief physicians (Y. S., B. X., and G. Z.) with expertise in urolithiasis from different\nmedical centers were recruited as reviewers to evaluate the results of the three tests across the \u0000ve\ndimensions. To comprehensively evaluate the models, we synthesized the scores of the three reviewers\nas the \u0000nal scores for each model. Discrepancies in scoring were resolved by taking the median value or\nfollowing the majority view.\nVisualization and Statistical analysis\nThe online tool HIPLOT (https://hiplot.org) was used to create dot plots, illustrating the individual model\nscores for each question, and radar plots, enabling a comparison of the overall scores of various models.\nAll statistical analyses were performed using R version 4.3.0 (The R Foundation for Statistical Computing,\nVienna, Austria). Non-parametric Wilcoxon tests were used to compare scores between different groups.\nPage 6/16\nResults\nCharacteristics of questions and clinical scenarios\nAfter collection and screening, we included 21 questions covering various aspects of urolithiasis, ranging\nfrom concepts to diagnosis, treatment, prevention, and follow-up. Additionally, we designed two clinical\ncase that dealt with emergencies caused by ureteral stones. One case involved a straightforward case of\nrenal colic caused by ureteral stone obstruction, while the other involved a complex situation leading to\nseptic shock caused by ureteral stone obstruction. The questions and cases are shown in Table 1.\nPage 7/16\nTable 1\nQuestions and clinical scenarios\nCategory Number Question\nI.Overview 1 What is kidney stone?\n  2 What is the speci\u0000c mechanism of kidney stone formation?\n  3 Are kidney stones hereditary?\n  4 What harm can kidney stones cause?\n  5 What are the characteristics of kidney stones with different compositions?\nII.Diagnosis 6 How to determine if I have urolithiasis?\n  7 What auxiliary examinations should kidney stone patients undergo fordiagnosis and assessment?\n  8 Why do kidney stones cause pain?\n  9 What are the characteristics of pain caused by kidney stones and how todifferentiate it from other diseases?\n  10 Is it possible not to have a CT scan if I have kidney stones because of theradiation?\nIII.Treatment 11 Can kidney stones be eliminated naturally, and if so, how to increase theprobability of natural elimination of stones \u0000\n  12 How to perform conservative treatment for kidney stones\n  13 How to relieve pain and other symptoms caused by kidney stones?\n  14 What are the various treatment methods for urolithiasis and their respectivecharacteristics?\n  15 What type of stones are suitable for extracorporeal shock wave lithotripsy?\n  16 Under what circumstances does kidney stone require surgical treatment?\n  17 What is the difference between ureteroscopic lithotripsy and percutaneousnephrolithotomy for kidney stones?\n  18 What are the potential risks and complications of surgical treatment forkidney stones?\nIV. Follow-up andPrevention\n19 What type of kidney stones are prone to recurrence?\n  20 How to prevent kidney stone recurrence through diet and lifestyleadjustments?\n  21 How to follow up after kidney stone surgery?\nPage 8/16\nCategory Number Question\nCases 1 22 Young male, 23 years old, sudden onset of left lumbar back pain for 2 hours,accompanied by nausea and vomiting, admitted to the emergencydepartment, physical examination revealed left lumbar percussion pain,routine urine test showed occult blood, ultrasound indicated left ureteraldilation and mild hydronephrosis of the left kidney. According to the medicalhistory, what disease should be considered, and what additional testsshould be performed?\nCase 2 23 Female patient, 62 years old, left lumbar pain accompanied by fever for 2days, admitted to the emergency department. Body temperature 38 degreesCelsius, heart rate 110 beats/min, blood pressure 80/40mmHg, blood\nroutine showed white blood cell count 23x109/L, neutrophil percentage 95%,kidney function showed blood creatinine 300µmol/L, blood glucose23mmol/L. Abdominal CT indicated left kidney hydronephrosis, perinephricin\u0000ltration, and a 0.8 cm high-density shadow at the distal end of the leftureter. What disease should this patient consider? What additional tests areneeded, how to urgently deal with it? What is the cause of the patient’shypotensive shock?\nPerformance of the models in answering questions of\nurolithiasis\nThe detailed outputs of the different models for the questions and cases are presented in the\nSupplementary Material. We summarized the ratings given by the experts for each question.\nThe accuracy scores of the four models for all questions are shown in Fig. 1A. The Claude model\nperformed the best in terms of accuracy, and most answers scored 4 points or higher, with only two\nquestions scoring lower than 4 points. ChatGPT4 ranked second in terms of accuracy. Bard's responses\nhad the lowest accuracy, with most questions scoring 3 points or less and question 13 scoring only 1–2\npoints. ChatGPT4 exhibited the most stable output, with the smallest \u0000uctuation in scores across the\nthree tests.\nThe scores for comprehensiveness of the responses are shown in Fig. 1B. The Claude model again had\nthe highest median score of 5. ChatGPT4 obtained a median score of 4, while both the Bard and New\nBing models had median scores of 3. Notably, the Bard model demonstrated the most stable output\nresults.\nFigure 1C shows the readability scores of the output answers; all four models had a median score of 4.\nBased on the performance in the three tests, ChatGPT4 yielded the most stable output.\nFigure 1D shows the scores for human care. The Claude model exhibited the highest median score of 4,\nwhile the other three models achieved a median score of 3. Furthermore, Claude had the most stable\noutput, with almost all questions scoring 4 points and exhibiting minimal variation in scores.\nCase analysis performance of the models\nPage 9/16\nWe conducted a detailed evaluation and comparative analysis of the performance of the two case\nanalyses. The ratings given by experts showed that both the Claude and ChatGPT4 models had ratings of\n4 or above for both cases in terms of their capacity to analyze cases. However, Bard's ratings were\nsigni\u0000cantly lower than those of the other three models. The performance of each model is shown in\nFig. 2.\nThe comparison of overall scores for the models\nWe calculated the score rate of each model for each question in different dimensions by dividing the total\nscore of each model for each question by the full score, The corresponding radar charts were then\ngenerated based on this data. Figure 3A, 3B, and 3C present the results of the three tests. Notably, Claude\ndemonstrated remarkable stability across all three tests, consistently achieving scores of 80 or higher in\nall dimensions. ChatGPT4's performance was relatively balanced and excellent in all aspects, except for\nhuman care. Both Claude and ChatGPT4 showed signi\u0000cantly higher overall scores than the other two\nmodels, with Claude performing noticeably better than ChatGPT4 (Fig. 3D).\nDiscussion\nThe application of ChatGPT and other LLMs in the medical \u0000eld has sparked a lively debate in the\nacademic community since their emergence(11). Several studies have evaluated the performance of\nChatGPT3.5 in various medical domains and tasks. For example, ChatGPT3.5 passed all three stages of\nthe United States Medical Licensing Examination (USMLE), a comprehensive assessment for medical\nlicensure in the US (12). In addition, when employed in the radiological diagnosis of breast cancer\nscreening and the evaluation of breast pain severity, ChatGPT exhibited moderate accuracy(13).\nChatGPT3.5 also demonstrated the potential to improve health education by providing consultation to\nhealthcare providers and offering accessible and understandable medical knowledge to the general\npublic(14, 15). Thus, LLMs, such as ChatGPT, have shown unique advancements and remarkable\ne\u0000ciencies in solving medical issues. However, different LLMs have different strengths and limitations in\nterms of functionality, performance, and reliability. Similarly, various AI LLMs exhibit diverse features and\ncapabilities when applied to different medical scenarios.\nIn this study, we compared the performance of four state-of-the-art LLMs currently available, including\nBard, Claude, ChatGPT4, and New Bing, in health consultation and patient education in urolithiasis.\nClaude was developed by Anthropic and founded by former employees of OpenAI. Bard, developed by\nGoogle, was built based on its own language model, LaMDA. ChatGPT4, developed by OpenAI, was built\nbased on the latest GPT-4 language model. New Bing developed by Microsoft, is also based on GPT4;\nunlike the other three models, New Bing can output images and access the Internet for real-time data and\ninformation. It can also provide sources and references for its answers. Overall, the \u0000ndings of the\npresent study are promising. All models yielded relatively quali\u0000ed results, except for Bard, which failed to\nprovide a valid response to Question 13. The study indicated that the Claude model consistently\noutperformed the other three models, exhibiting the highest scores across all dimensions including\nPage 10/16\naccuracy, comprehensiveness, readability, and empathy, regardless of question complexity. ChatGPT4\nranked second in accuracy, with a relatively stable output across multiple tests, but there were still\nshortcomings in empathy and care for counsellors. The Bard model had the lowest accuracy and overall\nperformance, with lower scores in comprehensiveness, readability, and human caring. The case analysis\nevaluation also showed that both the Claude and ChatGPT4 models demonstrated strong capabilities in\ncase analysis, while Bard's performance in this regard was signi\u0000cantly inferior. Overall, the Claude model\nemerged as the top performer in urolithiasis consultations and education.\nOur study had several important limitations. First, the relatively small number of inputs, speci\u0000cally the\nurolithiasis patients’ questions and case scenarios, restricted the depth and scope of our analysis.\nIncreasing the number of questions and cases and categorizing them by question type and complexity\ncould reveal more speci\u0000c and profound differences in the performance of LLMs in simulating different\nclinical tasks. Second, LLMs are being rapidly updated and our study only represents the performance of\nthe four models in their respective versions until late April 2023. With ongoing model updates, their\nperformances may improve over time. Third, we designed only one language pattern for questioning, but\nit is important to recognize that different questioning styles may yield varying results from the models.\nTherefore, it is necessary to design more standardized and rigorous prompts and conduct more tests to\nevaluate the output of these models in the future.\nWith the rapid development of natural language processing and arti\u0000cial intelligence, LLMs can make full\nuse of medical big data, and through cross-collaboration with researchers, clinical healthcare\npractitioners, patients, and health policymakers, they will have an unprecedented impact on all aspects of\nhealthcare in the future and further promote a paradigm shift in healthcare(16, 17). Although current\nevaluations show promising prospects for LLMs' application of LLMs in healthcare consultations, certain\nconcerns remain. These models are not specialized medical LLMs based on professional materials within\nthe \u0000eld. LLMs utilize a vast amounts of data from various internet sources for training and text\ngeneration, but these training data are not all peer reviewed and may introduce biases. The lack of\ntransparency in the black-box nature of LLMs compromises objectivity and accuracy during the\nanswering process(18–21). Additionally, the training data may have temporal limitations. Except for New\nBing, the other three models cannot provide any sources or evidence for their claims, which may raise\nconcerns and suspicions when the outputs deviate from current clinical practices and the latest medical\nadvancements. Moreover, LLMs can generate erroneous content that appears reasonable from a\nscienti\u0000c perspective(12). Due to their reliance on textual information, most models are incapable of\nhandling medical images. In addition, they cannot account for non-quanti\u0000able cues involved in medical\nconsultations, such as religious beliefs, sociopsychological characteristics, and emotional shifts(22).\nThese elements, along with the expertise of physicians, play a crucial role in addressing medical\nissues(23). Therefore, the use of LLMs for clinical consultation requires human intervention to verify the\nsources and ensure the accuracy of their outputs.\nIn the foreseeable future, it is imperative to acknowledge that LLMs should never serve as a complete\nsubstitute for licensed healthcare providers. Instead, they should be regarded as supplementary tools that\nPage 11/16\ncan improve clinical decision-making. Healthcare providers should be aware of these limitations and\nshould use LLMs cautiously.\nConclusion\nWe assessed four prominent LLMs currently available and demonstrated their competence in performing\nassigned tasks within the \u0000eld of urolithiasis consultation. Claude outperformed the other three LLMs in\nterms of accuracy, comprehensiveness, readability, human care, and case analysis ability. ChatGPT4\nranked second performance. The rapid advancements in arti\u0000cial intelligence and natural language\nprocessing technologies have provided unprecedented prospects for LLMs in medical health\nconsultations and patient education. However, it is important to emphasize that professional review and\nsupervision remain essential in the current process of applying LLMs. Further evaluations and model\nmodi\u0000cations are required to enhance their effectiveness and strive for an even more ideal level of\nperformance.\nDeclarations\nAuthor Contributions: B.X and G.Z had full access to all of the data in the study and takes responsibility\nfor the integrity of the data and the accuracy of the data analysis. H.S and Y. X contributed equally to this\nwork and should be considered co–\u0000rst authors.\nConcept and design: H.S, G.Z, B.X.\nAcquisition, analysis, or interpretation of data: H.S, Y.X, B.X, Y. S, G.Z, J. L\nDrafting of the manuscript: Y.X, H.S, Z.L\nCritical revision of the manuscript for important intellectual content: H.L, X.Z and J.L\nStatistical analysis: H.S, T.L, G.Zh.\nObtained funding: H.S\nAdministrative, technical, or material support: Y Xia, X Zeng, and M Chen.\nSupervision: J Li, B Xiao, G Zhang.\nCon\u0000ict of Interest Disclosures: The authors declare that they have no con\u0000icts of interest.\nResearch involving Human Participants and/or Animals: Not applicable.\nInformed Consent: Not applicable.\nPage 12/16\nFunding/Support: This work was supported by the Research Fund of the Tsinghua Changgung\nHospital(grants12022C1001).\nRole of the Funder/Sponsor: The funders had no role in the design and conduct of the study; collection,\nmanagement, analysis, and interpretation of the data; preparation, review, or approval of the manuscript;\nor decision to submit the manuscript for publication.\nReferences\n1. Zeng G, Zhu W, Robertson WG, Penniston KL, Smith D, Pozdzik A, et al. International Alliance of\nUrolithiasis (IAU) guidelines on the metabolic evaluation and medical management of urolithiasis.\nUrolithiasis. 2022;51(1):4.\n2. Geraghty RM, Davis NF, Tzelves L, Lombardo R, Yuan C, Thomas K, et al. Best Practice in\nInterventional Management of Urolithiasis: An Update from the European Association of Urology\nGuidelines Panel for Urolithiasis 2022. Eur Urol Focus. 2023;9(1):199–208.\n3. Baatiah NY, Alhazmi RB, Albathi FA, Albogami EG, Mohammedkhalil AK, Alsaywid BS. Urolithiasis:\nPrevalence, risk factors, and public awareness regarding dietary and lifestyle habits in Jeddah, Saudi\nArabia in 2017. Urol Ann. 2020;12(1):57–62.\n4. Yeo YH, Samaan JS, Ng WH, Ting PS, Trivedi H, Vipani A, et al. Assessing the performance of\nChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma. Clin Mol Hepatol.\n2023.\n5. Ayers JW, Zhu Z, Poliak A, Leas EC, Dredze M, Hogarth M, et al. Evaluating Arti\u0000cial Intelligence\nResponses to Public Health Questions. JAMA Netw Open. 2023;6(6):e2317517.\n\u0000. Hirosawa T, Harada Y, Yokose M, Sakamoto T, Kawamura R, Shimizu T. Diagnostic Accuracy of\nDifferential-Diagnosis Lists Generated by Generative Pretrained Transformer 3 Chatbot for Clinical\nVignettes with Common Chief Complaints: A Pilot Study. Int J Environ Res Public Health. 2023;20(4).\n7. Howard A, Hope W, Gerada A. ChatGPT and antimicrobial advice: the end of the consulting infection\ndoctor? Lancet Infect Dis. 2023;23(4):405–6.\n\u0000. Sallam M. ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on\nthe Promising Perspectives and Valid Concerns. Healthcare (Basel). 2023;11(6).\n9. Gortz M, Baumgartner K, Schmid T, Muschko M, Woessner P, Gerlach A, et al. An arti\u0000cial intelligence-\nbased chatbot for prostate cancer education: Design and patient evaluation study. Digit Health.\n2023;9:20552076231173304.\n10. Zhu L, Mou W, Chen R. Can the ChatGPT and other large language models with internet-connected\ndatabase solve the questions and concerns of patient with prostate cancer and help democratize\nmedical knowledge? J Transl Med. 2023;21(1):269.\n11. Will ChatGPT transform healthcare? Nat Med. 2023;29(3):505–6.\n12. Cascella M, Montomoli J, Bellini V, Bignami E. Evaluating the Feasibility of ChatGPT in Healthcare:\nAn Analysis of Multiple Clinical and Research Scenarios. J Med Syst. 2023;47(1):33.\nPage 13/16\n13. Rao A, Kim J, Kamineni M, Pang M, Lie W, Succi MD. Evaluating ChatGPT as an Adjunct for\nRadiologic Decision-Making. medRxiv. 2023.\n14. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepano C, et al. Performance of ChatGPT\non USMLE: Potential for AI-assisted medical education using large language models. PLOS Digit\nHealth. 2023;2(2):e0000198.\n15. D'Amico RS, White TG, Shah HA, Langer DJ. I Asked a ChatGPT to Write an Editorial About How We\nCan Incorporate Chatbots Into Neurosurgical Research and Patient Care. Neurosurgery.\n2023;92(4):663–4.\n1\u0000. Mann DL. Arti\u0000cial Intelligence Discusses the Role of Arti\u0000cial Intelligence in Translational Medicine:\nA JACC: Basic to Translational Science Interview With ChatGPT. JACC Basic Transl Sci.\n2023;8(2):221–3.\n17. Rao A, Kim J, Kamineni M, Pang M, Lie W, Succi MD. Evaluating ChatGPT as an Adjunct for\nRadiologic Decision-Making. medRxiv. 2023:2023.02.02.23285399.\n1\u0000. The Lancet Digital H. ChatGPT: friend or foe? Lancet Digit Health. 2023;5(3):e102.\n19. Marchandot B, Matsushita K, Carmona A, Trimaille A, Morel O. ChatGPT: the next frontier in\nacademic writing for cardiologists or a pandora's box of ethical dilemmas. Eur Heart J Open.\n2023;3(2):oead007.\n20. Stokel-Walker C, Van Noorden R. What ChatGPT and generative AI mean for science. Nature.\n2023;614(7947):214–6.\n21. Lubowitz JH. ChatGPT, An Arti\u0000cial Intelligence Chatbot, Is Impacting Medical Literature.\nArthroscopy. 2023;39(5):1121–2.\n22. Ahn C. Exploring ChatGPT for information of cardiopulmonary resuscitation. Resuscitation.\n2023;185:109729.\n23. Anderson LM, Scrimshaw SC, Fullilove MT, Fielding JE, Normand J, Task Force on Community\nPreventive S. Culturally competent healthcare systems. A systematic review. Am J Prev Med.\n2003;24(3 Suppl):68–79.\nFigures\nPage 14/16\nFigure 1\nThe performance of the four LLMs on various urolithiasis-related questions across different dimensions.\nA, the performance of accuracy. B. the performance of comprehensiveness. C, the performance of\nlegibility. D, the performance of Human caring. Each color in the \u0000gure represents a different question,\nwhile the dashed line represents the median score. The vertical bar denotes the extremes observed in\ndifferent tests.\nPage 15/16\nFigure 2\nComparison of the four LLMs regarding the performance in urolithiasis case analysis. The signi\u0000cance\nlevels are indicated as follows: ns: not signi\u0000cant; *: p<0.05; **: p<0.01; ***: p<0.001.\nPage 16/16\nFigure 3\nComparison of overall performances for the models with respect to different dimensions. The score rates\nof each model for different dimensions were generated by dividing the total score of each model for each\nquestion by the full score. A, radar plot of score rates regarding different dimensions for the \u0000rst test. B,\nradar plot of score rates regarding different dimensions for the second test. C, radar plot of score rates\nregarding different dimensions for the third test. D, the comparison of overall scores for different models\non each question. Signi\u0000cance levels are indicated as: ns: not signi\u0000cant; *: p<0.05; **: p<0.01; ***:\np<0.001.\nSupplementary Files\nThis is a list of supplementary \u0000les associated with this preprint. Click to download.\nLLMsTestSummary.docx",
  "topic": "Empathy",
  "concepts": [
    {
      "name": "Empathy",
      "score": 0.6992810964584351
    },
    {
      "name": "Legibility",
      "score": 0.5996825098991394
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5487861633300781
    },
    {
      "name": "Likert scale",
      "score": 0.5093094110488892
    },
    {
      "name": "Health care",
      "score": 0.44287508726119995
    },
    {
      "name": "Psychology",
      "score": 0.4300929009914398
    },
    {
      "name": "Objective structured clinical examination",
      "score": 0.4159296751022339
    },
    {
      "name": "Medical education",
      "score": 0.3889421224594116
    },
    {
      "name": "Medicine",
      "score": 0.36425596475601196
    },
    {
      "name": "Applied psychology",
      "score": 0.32214832305908203
    },
    {
      "name": "Social psychology",
      "score": 0.31723952293395996
    },
    {
      "name": "Developmental psychology",
      "score": 0.17012664675712585
    },
    {
      "name": "Geography",
      "score": 0.11216294765472412
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Economic growth",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I91656880",
      "name": "China Medical University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I2800370534",
      "name": "Sheng Jing Hospital",
      "country": "CN"
    }
  ]
}