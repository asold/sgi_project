{
  "title": "Evaluating German Transformer Language Models with Syntactic Agreement\\n Tests",
  "url": "https://openalex.org/W3041594829",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5055612224",
      "name": "Karolina Zaczynska",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5027823774",
      "name": "Nils Feldhus",
      "affiliations": [
        "German Research Centre for Artificial Intelligence"
      ]
    },
    {
      "id": "https://openalex.org/A5078968418",
      "name": "Robert Schwarzenberg",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5070048651",
      "name": "Aleksandra Gabryszak",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5075001284",
      "name": "Sebastian Möller",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2963751529",
    "https://openalex.org/W2970853769",
    "https://openalex.org/W2951286828",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3006881356",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W2549835527",
    "https://openalex.org/W2971380169",
    "https://openalex.org/W2910243263",
    "https://openalex.org/W3001393026",
    "https://openalex.org/W2888922637"
  ],
  "abstract": "Pre-trained transformer language models (TLMs) have recently refashioned\\nnatural language processing (NLP): Most state-of-the-art NLP models now operate\\non top of TLMs to benefit from contextualization and knowledge induction. To\\nexplain their success, the scientific community conducted numerous analyses.\\nBesides other methods, syntactic agreement tests were utilized to analyse TLMs.\\nMost of the studies were conducted for the English language, however. In this\\nwork, we analyse German TLMs. To this end, we design numerous agreement tasks,\\nsome of which consider peculiarities of the German language. Our experimental\\nresults show that state-of-the-art German TLMs generally perform well on\\nagreement tasks, but we also identify and discuss syntactic structures that\\npush them to their limits.\\n",
  "full_text": "arXiv:2007.03765v1  [cs.CL]  7 Jul 2020\nEvaluating German T ransformer Language Models\nwith Syntactic Agreement T ests\nKarolina Zaczynska*, Nils Feldhus*, Robert Schwarzenberg,\nAleksandra Gabryszak, Sebastian M ¨oller\nGerman Research Center for Artiﬁcial Intelligence (DFKI)\n{firstname.lastname}@dfki.de\nAbstract\nPre-trained transformer language models\n(TLMs) have recently refashioned natural\nlanguage processing (NLP): Most state-\nof-the-art NLP models now operate on\ntop of TLMs to beneﬁt from contextual-\nization and knowledge induction. T o ex-\nplain their success, the scientiﬁc commu-\nnity conducted numerous analyses. Be-\nsides other methods, syntactic agreement\ntests were utilized to analyse TLMs. Most\nof the studies were conducted for the En-\nglish language, however. In this work, we\nanalyse German TLMs. T o this end, we\ndesign numerous agreement tasks, some\nof which consider peculiarities of the\nGerman language. Our experimental re-\nsults show that state-of-the-art German\nTLMs generally perform well on agree-\nment tasks, but we also identify and dis-\ncuss syntactic structures that push them to\ntheir limits.\n1 Introduction\nPre-trained language models, in particular those\nwhich are based on the transformer architecture\n(\nV aswani et al. , 2017), have immensely improved\nthe performance of various downstream models\n(see, e.g. Zhang et al. (2020, 2019); Raffel et al.\n(2019)). T o explain their success, numerous in-\ntrospective experiments have targeted different as-\npects of TLMs. It was shown, for instance, that\nthey encode syntactic, semantic and world knowl-\nedge (\nPetroni et al. , 2019) and present downstream\nCopyright c⃝ 2020 for this paper by its authors. Use permit-\nted under Creative Commons License Attribution 4.0 Interna -\ntional (CC BY 4.0)\n* Shared ﬁrst authorship.\nmodels with a highly contextualized representa-\ntion of the input tokens (\nT enney et al. , 2019). For a\ncomprehensive overview of the many studies con-\nducted about arguably the most prominent of lan-\nguage models, B ERT (\nDevlin et al. , 2019), we re-\nfer the interested reader to the excellent overview\npaper by\nRogers et al. (2020).\nWith the exception of experiments targeting a\nmultilingual B ERT model ( Rogers et al. , 2020),\nmost of the studies were conducted only for En-\nglish, however. Other languages are underrepre-\nsented. In this work, we narrow the gap for Ger-\nman by analysing the abilities and limits of Ger-\nman TLMs. T o the best of our knowledge, we are\nthe ﬁrst to conduct such an analysis for the Ger-\nman language.\nWhen compared with English, there are con-\nsiderable syntactic differences in the German lan-\nguage that we consider in this work. For exam-\nple, the inﬂection system of the German language\nis more complex, the range of morpho-syntactic\nrules needed to form grammatical sentences is\nlarger, and the allowed word order is more di-\nverse. As a consequence, the German language\nmodels face speciﬁc challenges. The syntactic\nagreement tests presented in this work include sev-\neral of them.\nOur main contributions are threefold:\n1. Utilizing context-free grammars (CFG), we\ncompile a German data set of controlled\nsyntactic correctness tests of various com-\nplexities. The motivation and construction\nof the data set is closely following the one\ndescribed in\nMarvin and Linzen (2018),\nwhere syntactic tests were conducted for\nEnglish. In particular, we devise several\nkinds of subject-verb agreement as well as\nreﬂexive anaphora agreement tasks, taking\ninto account peculiarities of the German\nlanguage. A simple subject-verb agreement\ntask is given in Example\n1.1.\nExample 1.1. Decide which of the follow-\ning sentences is grammatical:\n(a) Der Autor lacht. (The author laughs.)\n(b) * Der Autor lachen. (The author\nlaugh.)\n2. W e use the data set to evaluate two\ntransformer-based language models that\nwere pre-trained on German corpora. Dur-\ning the evaluation, contrary to prior work,\nwe utilize the cross entropy loss to score\nthe syntactic correctness of input sentences.\nThis addresses a problem with the sub-word\ntokenization of some TLMs that was previ-\nously solved by discarding thousands of data\npoints.\n3. W e conduct a qualitative and quantitative\nanalysis of the experimental results, esti-\nmating the abilities and limits of the TLMs\ntested.\n2 Methods\nOur work combines and translates the targeted syn-\ntactic evaluation of language models by\nMarvin\nand Linzen (2018) and the assessment of B ERT ’s\nsyntactic abilities by Goldberg (2019) from En-\nglish into German. Our methods consist of agree-\nment test generation and model evaluation.\nW e created the following agreement test, follow-\ning\nMarvin and Linzen (2018): T wo sentences, a\ngrammatical one and an ungrammatical one, are\nforwarded through a model. The sentences dif-\nfer minimally from each other at only one locus\nof (un)grammaticality , i.e. one word. The model\noutput is monitored and if the output suggests that\nthe model prefers the grammatical one over the un-\ngrammatical one, that instance is counted as a cor-\nrect classiﬁcation; otherwise, it is counted as an\nincorrect classiﬁcation.\nGoldberg (2019) used agreement tests to evalu-\nate B ERT models. T o account for their bidirection-\nality , he masked the locus of (un)grammaticality\nand queried the candidate probabilities for the\nmask. In Example\n1.1, Der Mann [MASK]. is\nforwarded through a B ERT model and the candi-\ndate probabilities at the position of the mask are\ndetermined. If lacht receives a higher probabil-\nity than lachen, the task is solved correctly by\nthe language model. The author runs into prob-\nlems, however, when the candidates are tokenized\ninto multiple sub-word tokens, say lachen →\n[lach, ##en]. In this case, the author simply\nignores the data point.\nInstead of discarding such sequences, we take\ninspiration from\nMarvin and Linzen (2018) and\nscore whole sentences (without masks). However,\nwe still discard cases in which the two candidates\nhave a different amount of sub-words after tok-\nenization, as we see the comparability impaired if\nthe resulting sequences of tokens are of different\nlengths.\nW e compute the sentence score with the cross-\nentropy loss of the forward pass, using the input\nsequence as the target:\n1\nT\nT∑\ni=1\n\n− f(S)i,Si + log(\nT∑\nj=1\nexp(f(S)j,Sj ))\n\n\nwhere S is a sequence of T positive integer token\nids and f : ZN → RN× V a language model map-\nping N token IDs onto N token probabilities over\na vocabulary of size V . W e compute Eq.\n2 with\nthe grammatical candidate in place and a second\ntime with the ungrammatical candidate in place.\nPlease note that during the training of a bidirec-\ntional language model, the points of interests need\nto be masked to prevent information leakage (\nDe-\nvlin et al. , 2019). In our case, information leakage\nis not a problem because we compare two whole\nsequences.\n3 Syntactic Agreement T ests\nThis section describes the syntactic agreement\ntests we generated to evaluate German TLMs on.\nOur tests are inspired by the research of\nMarvin\nand Linzen (2018) and Goldberg (2019). In partic-\nular, we translate many of their tests on subject-\nverb agreement (SV A) and reﬂexive anaphora\n(RA) agreement from English to German (Sec-\ntion 3.2). In addition, we design tests for syntactic\nphenomena which are typical of the German lan-\nguage (Section\n3.3).\nThe generated tasks cover a range of difﬁcul-\nties. In German, the subject and the inﬂected verb\nagree with regard to person and grammatical num-\nber. In the simplest case, the sentences contain\nonly a subject and a verb. In the more challeng-\ning cases we added different types of distraction,\ni.e. either additional non-subjective (pro)nouns as\ncandidates for subjects or other additional lexical\nmaterial making the sentences more complex.\nFor our experiments, we consider instances\nwhere the grammatical number of non-subjective\n(pro)nouns matches the one of the subject as well\nas examples where their grammatical number is\ndifferent. Furthermore, we distinguish between lo-\ncal and non-local feature agreement, which means,\nwe take into account whether the distractors oc-\ncur between subject and its corresponding verb or\nnot. The described test scenario allows us to com-\npare the models’ performance with regard to the\nfeatures of the distractor as well as its distance to\nthe relevant verb. Therefore, the designed tests ex-\npand the experimental setup of\nMarvin and Linzen\n(2018) by going beyond the attractors, i.e. inter-\nmissions deﬁned as intervening nouns with the\nopposite number from the subject (\nLinzen et al. ,\n2016).\n3.1 Dataset\nW e created a dataset of 13,002 sentences using\nhand-crafted Context Free Grammars (CFGs) as\nillustrated in Example\n3.1.\nExample 3.1. Context Free Grammar for creating\nsentences S from a vocabulary V to test agreement\nin a simple sentence:\nS − > NP V ’.’\nNP − > ART N\nART − > ’Die’\nN − > ’Autoren’ |’Richterinnen’\nV − > ’lachen’ |’reden’\nOutput: Die Autoren lachen. / Die Autoren reden.\n/ Die Richterinnen lachen. / Die Richterinnen re-\nden.\nAs shown in the example, the CFG creates sen-\ntences as output with varying lexical items but\nwith a relatively low variance. However, it allows\nus to tightly control the generated sentences with\nrespect to the desired tests, in terms of distractor\nfeatures as well as syntactic structure and correct-\nness of the sentences.\nOur data set covers 14 test cases of different\nchallenge levels (Sections\n3.2– 3.3). The number\nof sentences ranges from 64 to 2160 with an aver-\nage of 928,71 sentences per test case. A sentence\nis build on average of 6.88 tokens. The vocabulary\nconsists of 88 lexems and 171 word forms. For our\ncorpus, we chose common words to build the sen-\ntences, so that the TLM was not confronted with\npotentially unknown words.\n3.2 Established Agreement T ests\nIn the following, we introduce the agreement tests\nthat we translated from the work of\nMarvin and\nLinzen (2018).\nW e describe three groups of tests ordered by the\nincreasing challenge level: (1) local agreement, no\ndistractors, (2) local agreement, plus distractors,\nand (3) non-local agreement, plus distractors. Af-\nterwards, we introduce tests designed to target Ger-\nman phenomena speciﬁcally .\nLocal agreement, no distractors W e ﬁrst in-\nclude cases with local agreement and without a dis-\ntractor. Sentences consisting of only one subject\nand verb are what we refer to as simple sentence\nin the following, showcased in Example\n3.2.\nExample 3.2. Simple sentence with only one sub-\nject and one verb (the locus of (un)grammaticality\nis italic, the incorrect variant is preceded by *):\n(a) Das Kind trinkt.\n(b) * Das Kind trinken.\nLocal agreement, plus distractors Complex\nsentences with a local agreement in a sentential\ncomplement or in an object relative clause consti-\ntute the next level of difﬁculty . Those sentences\ncontain two subjects: one in the main clause, and\nanother one in the subordinate clause. In Exam-\nple\n3.3, the latter functions as a sentential comple-\nment, in Example 3.4, as an object relative clause.\nFor both types of the subordinate clause, the verb\nfollows the subject directly . The subject of a main\nclause is the distractor in those cases while the\nagreement between the subject and the verb of the\nsubordinate clause is our point of interest.\nExample 3.3. SVA in a sentential complement :\n(a) Die V ertreter sagten, dass das Kind trinkt.\n(b) * Die V ertreter sagten, dass das Kind trinken.\nExample 3.4. SVA in an object relative clause\n(a) Der Autor, den die V ertreter kennen, lacht.\n(b) * Der Autor, den die V ertreter kennt, lacht.\nNon-local agreement, plus distractors W e also\ntested TLMs on a set of constructions with non-\nlocal agreement, induced by potentially distracting\nwords and phrases between the head of the subject\nand its corresponding verb. With these tasks, we\nare testing the language model’s ability to attend\nto the subject in sentences across long contexts.\nOur ﬁrst test case is a SVA across a preprosi-\ntional phrase (PP). W e created sentences with the\nsubject modiﬁed by a directly following PP , which\nincludes a potentially attracting noun, as in Exam-\nple\n3.5.\nExample 3.5. SVA across a PP\n(a) Der Autor neben den Landstrichen lacht.\n(b) * Der Autor neben den Landstrichen lachen.\nFurthermore, we test SVAs across subject rela-\ntive clauses which include one potentially distract-\ning object and verb in between subject and corre-\nsponding verb, as in Example\n3.6.\nExample 3.6. SVA across a subject relative clause\n(a) Der Autor, der die Architekten liebt, lacht.\n(b) * Der Autor, der die Architekten liebt,\nlachen.\nThe same challenge exists for SVAs across ob-\nject relative clauses which also contain potentially\ndistracting chunks and separate the subject and its\ncorresponding verb, as in Example\n3.7.\nExample 3.7. SVA across an object relative\nclause\n(a) Der Autor, den die V ertreter kennen, lacht.\n(b) * Der Autor, den die V ertreter kennen,\nlachen.\nAdditionally , we designed various sentences for\ntesting SVAs across coordinated verbal phrases\n(VP), where the subject must agree in person and\nnumber with the ﬁnite verb included in each VP . In\nour test, the point of interest is the second verb of\nthe coordination. This kind of structure challenges\nthe model to recognize that the complete subject-\nverb structure does not end after the ﬁrst verb, but\nrather it also includes the second verb. W e test the\nSV A in verbal coordinations of different lengths\nand various number of distractors.\nFirst, we test the model on sentences consisting\nof a short and simple VP coordination with no dis-\ntractors, as illustrated by Example\n3.8.\nExample 3.8. SVA in short VP coordinations (i.e.\nwith no distractors)\n(a) Der Autor schwimmt und lacht.\n(b) * Der Autor schwimmt und lachen.\nT o increase the difﬁculty level, we inserted noun\nphrases having a different number as the subject\ninto the coordinated VP . W e distinguish between\nverbal coordinations with a single noun distractor\n(Example\n3.9) and two noun distractors (Exam-\nple 3.10).\nExample 3.9. SVA in medium VP coordinations\n(i.e. with a single noun distractor)\n(a) Der Autor redet mit Menschen und lacht.\n(b) * Der Autor redet mit Menschen und lachen.\nExample 3.10. SVA in long VP coordinations (i.e.\nwith two noun distractors)\n(a) Der Autor redet mit Menschen und verfolgt\ndie Fernsehprogramme.\n(b) Der Autor redet mit Menschen und verfolgen\ndie Fernsehprogramme.\n3.3 Novel Agreement T ests\nIn addition to the tests above that we based on pre-\nvious work, we also designed tasks which target\nconstructs that are more speciﬁc to the German\nlanguage.\nFirst, we test the agreement between verb and\nits corresponding subject containing an extended\nmodiﬁer, i.e. an adjective modifying a subject and\nextended by further subordinate nominal or prepo-\nsitional phrase. The extended modiﬁer is posi-\ntioned between the determinator and the noun of\nthe subject. In comparison to English, the Ger-\nman language is much more ﬂexible with regard\nto the number and the types of allowed extensions.\nT o test the impact of nouns used within extended\nmodiﬁers of a subject we include sentences with\nsimple modiﬁers as well as with extended modi-\nﬁers (Example\n3.11 and 3.12).\nExample 3.11. SVA with a simple modiﬁer\n(a) Die wartenden Autoren lachen.\n(b) * Die wartenden Autoren lacht.\nExample 3.12. SVA with an extended modiﬁer\n(a) Die die Pﬂanze liebenden Autoren lachen.\n(b) * Die die Pﬂanze liebenden Autoren lacht.\nAnother agreement test relates to the more di-\nverse word order in German in comparison to En-\nglish. Example 3.13 illustrates the shift of the di-\nrect object diese Romane from its standard posi-\ntion in the middle-ﬁeld (after the ﬁnite verb) to the\npre-ﬁeld, and the shift of the subject der Autor to\nthe middle-ﬁeld from its standard position in the\npre-ﬁeld (before the ﬁnite verb). This movement\nwould be not possible in English. The German\nlanguage often allows the shift, since it marks the\ncase of noun phrases by the inﬂectional sufﬁx of\ntheir determiner (e.g. der Autor in nominative case\nvs. den Autor in accusative case) and sometimes\nalso by the sufﬁx of the noun itself (e.g. des Au-\ntors in genitive). That property supports to distin-\ndistil GBERT G BERT large # sents\nSU B JEC T-V ER B AG R EEM EN T\nSimple Sentence 0.9710 0.9420 69\nIn a sentential complement 0.9565 0.9894 2160\nShort VP coordination 0.7125 0.7542 240\nMedium VP coordination 0.4813 0.6188 480\nLong VP coordination 0.5167 0.5938 480\nAcross a PP 0.7968 0.9005 2160\nAcross a subject relative clause 0.6924 0.9896 1440\nAcross an object relative clause 0.7386 0.9206 945\nIn an object relative clause 0.9568 0.9600 1575\nWith a modiﬁer 0.9458 0.9959 240\nWith an extended modiﬁer 0.8917 0.9583 480\nPre-ﬁeld 0.73 0.7987 348\nREFLEX IV E A NA PH O R A\nPerson & number agreement 0.4876 0.8716 1737\nCase agreement 0.8534 0.9691 648\nT able 1: Performances (accuracy) of two TLMs on German synta ctic agreement tests. Underlined are the ﬁve tasks\nthe models performed worst on. Bold-faced are the best score s per task.\nguish subjects (always nominative case) from ob-\njects or adjuncts independent from their position in\na sentence. With this test case, we can evaluate if\nthe model recognizes the subject in sentences cor-\nrectly , even though the subject-verb-object order is\ndisregarded. W e exclude test sentences where the\nsubject and the object have the same inﬂectional\nsufﬁxes in nominative and accusative, i.e. an un-\nambiguous distinction between subject and object\nis not possible solely based on the inﬂection.\nExample 3.13. Pre-ﬁeld\n(a) Diese Romane empfahl der Autor.\n(b) * Diese Romane empfahlen der Autor.\nMoreover, we created sentences with reﬂexive\nverbs, i.e. sentential phrases where the reﬂexive\nanaphora (RA) in the accusative case follows the\nverb and agrees with the subject in the grammati-\ncal number and person. The ﬁrst sentence in Ex-\namples\n3.14 and 3.15 illustrates the agreement be-\ntween RA mich (accusative case) and the subject\nich in person (ﬁrst) and number (singular). W e use\ntwo different tests: (a) for the recognition of a cor-\nrect person (Example\n3.14), also used by Marvin\nand Linzen (2018), and (b) for the recognition of\na correct case (accusative instead of incorrect da-\ntive, Example\n3.15). The correct number is always\ngiven.\nExample 3.14. Subject RA agreement (person-\nagreement)\n(a) Ich bedanke mich.\n(b) * Ich bedanke sich.\nExample 3.15. RA in accusative (case-\nagreement)\n(a) Ich bedanke mich.\n(b) * Ich bedanke mir.\n4 Experiments\nIn this section, we introduce the models we eval-\nuate and in particular highlight their similarities\nand differences. W e probe transformer-based\nBERT models because they are currently the ba-\nsis for many state-of-the-art downstream models\nand very prominent in the community . The model\nselection was driven and conﬁned by availability .\nW e made use of\nW olf et al. (2019)’s transformers\npackage.1\nThe ﬁrst model which we refer to as GBERT large\nis a community model provided by the Bavarian\nState Library .\n2 It was trained on multiple Ger-\nman corpora including a recent Wikipedia dump,\nEU Bookshop corpus, the Open Subtitles corpus,\na CommonCrawl corpus, a ParaCrawl corpus and\nthe News Crawl corpus, with 16 GB of training\nmaterial in total. The second model which we re-\nfer to as distil GBERT was trained on half of the data\n1 https : //github.com/huggingface/\ntransformers (Accessed: 2020-03-05)\n2 https : //huggingface.co/dbmdz/bert-\nbase-german-cased (Accessed: 2020-03-05)\nused to pretrain B ERT using distillation with the\nsupervision of GBERT large 3 .\nThe data set, the CFGs with the list of lexical\nitems and the code for the experiments are publicly\navailable.\n4\n5 Results & Discussion\nThe coarse-grained results of our experiments are\nlisted in T able 1. W e note that both models per-\nform well across the majority of tasks. This is\nin line with previous work that demonstrated that\nBERT models are capable of solving syntactic\nagreement tasks. As shown by\nGoldberg (2019)\nfor English, for instance, our most successful Ger-\nman B ERT model, GBERT large , also scores above\n80% or 90% in most of the tasks, whereas the\nLSTM-LMs probed by\nMarvin and Linzen (2018)\nachieve scores not above 74%. W e observe that\nGBERT large outperforms distil GBERT in thirteen out\nof fourteen tasks. For example, in the case of\nSVA across an object relative clause , GBERT large\nachieved a score of 92.06%, whereas distil GBERT ’s\nscore is lower by around 18 percentage points.\nBased on these observations, we assume the higher\namount of German training data, that GBERT large\nwas trained on, is the distinguishing factor.\nThere is a big overlap between the most chal-\nlenging stress tests. Four out of ﬁve tests align\nwhen sorted in ascending order (worst perfor-\nmance ﬁrst, underscored in T able\n1). T o analyse\nthe stress tests further, in T able 2, we subdivide\ncases between singular and plural subjects and dis-\ntractors.\nW e expected high accuracies for the cases with\nlocal agreement. Our results show that all those\ncases, which are Simple Sentence , SVA in a senten-\ntial complement , SVA in an object relative clause\nand SVA with a simple modiﬁer , have a score\nabove 94 percent for both models.\nRegarding the German-speciﬁc syntactic con-\nstructs, we observe that both models perform well.\nThe movement of the subject from pre-ﬁeld to\nmiddle-ﬁeld does not seem to cause any bigger\nproblems, both distil GBERT and GBERT large have\nan accuracy between 0.73 and 0.8.\nAs can be seen in T ables\n1 and 2, VP coordi-\nnation probing cases were a big challenge for both\nmodels. For example, distil GBERT only achieves an\n3 https : //github.com/huggingface/\ntransformers/blob/master/examples/\ndistillation/README.md\n(Accessed: 2020-05-21)\n4 https://github.com/DFKI-NLP/gevalm/\noverall accuracy of 0.4813 on SVA in a medium VP\ncoordination and 0.5167 on SVA in a long VP co-\nordination, while GBERT large achieves 0.6188 and\n0.5938, respectively . In these aspects, our results\ndeviate considerably from the ﬁndings of\nGold-\nberg (2019) who reported that the English B ERT\nmodels performed well on long VP tasks, too. The\nrespective syntactic constructs may thus be partic-\nularly challenging for the B ERT models in the Ger-\nman language. Interestingly , according to T able\n2,\nGBERT large performs with an accuracy of 1.0 for\nlong VPs with a singular subject. W e note that the\nmost challenging sentences for both models in all\nof the VP coordination cases were the ones with a\nplural subject.\nIn contrast to the aforementioned VP coordina-\ntions, SVA across an object relative clause for both\nmodels and SVA across a subject relative clause\nfor distil GBERT show a better accuracy for sen-\ntences when the subject is plural. W e assume that\nfor some cases the grammatical number of the sub-\nject is a more inﬂuential aspect for the result than\nthe number of the distractor. W e didn’t expect this\ngiven that we used the same lexemes within one\ncase to ensure comparability between the results.\nW e expected that sentences in which the gram-\nmatical number of the distractor deviates from the\nnumber of the relevant verb (singular-plural and\nplural-singular) have a lower accuracy . This, how-\never, applies only to a few cases, like SVA across\nan object relative clause and Pre-ﬁeld . Thus, the\nTLMs appear to be mostly robust against those dis-\ntractors.\nInferring sound causes for why some syntactic\nconstructs push the models to their limit would\nrequire a thorough statistical analysis of the data\nand probably even an introspective analysis of the\nmodel. W e leave it to future work to conduct such\nan analysis.\n6 Related W ork\nThere is a huge body of related literature on the\nsyntactic evaluation of language models. For more\nbackground, we refer the interested reader to the\nworks cited in the inﬂuential contribution by\nMar-\nvin and Linzen (2018) and Goldberg (2019).\nGulordava et al. (2018) assessed subject-verb\nagreement with an emphasis on syntactic over se-\nmantic preference.\nMcCoy et al. (2019) created a\ndata set with entailment tests. Bacon and Regier\n(2019) extended Goldberg (2019) to 26 languages,\ndistil GBERT G BERT large # sents\nSU B JEC T-V ER B AG R EEM EN T\nSimple sentence -sg 0.9744 0.8974 39\n-pl 0.9667 1.0 30\nIn a sentential complement\n-sgsg 1.0 0.9593 540\n-plpl 0.8926 1.0 270\n-sgpl 0.9407 1.0 1080\n-plsg 0.9963 0.9963 270\nShort VP coordination -sg 0.8917 0.9667 120\n-pl 0.5333 0.5417 120\nMedium VP coordination\n-sgsg 0.7667 0.95 120\n-plpl 0.2333 0.3167 120\n-sgpl 0.775 0.9667 120\n-plsg 0.15 0.2417 120\nLong VP coordination\n-sgsg 0.5917 1.0 120\n-plpl 0.2 0.2167 120\n-sgpl 0.4917 1.0 120\n-plsg 0.7833 0.1583 120\nAcross a prepositional phrase\n-sgsg 0.7593 0.8667 540\n-plpl 0.7759 0.9426 540\n-sgpl 0.7907 0.8333 540\n-plsg 0.8611 0.9593 540\nAcross a subject relative clause\n-sgsg 0.4222 0.9944 360\n-plpl 1.0 0.975 360\n-sgpl 0.3638 0.9889 360\n-plsg 0.9833 1.0 360\nAcross an object relative clause\n-sgsg 0.4148 0.963 270\n-plpl 0.9667 0.9481 270\n-sgpl 0.4889 0.7481 135\n-plsg 0.9593 0.937 270\nIn an object relative clause\n-sgsg 0.9911 1.0 450\n-plpl 0.9511 0.9422 450\n-sgpl 0.88 0.9822 225\n-plsg 0.9667 0.9267 450\nWith a simple modiﬁer -sg 0.975 1.0 120\n-pl 0.9167 0.9917 120\nWith an extended modiﬁer\n-sgsg 0.9417 0.9667 120\n-plpl 0.8 0.9583 120\n-sgpl 0.9083 0.9667 120\n-plsg 0.9167 0.9417 120\nPre-ﬁeld\n-sgsg 0.7167 0.975 120\n-sgpl 0.574 0.6759 120\n-plsg 0.8833 0.7333 108\nREFLEX IV E A NA PH O R A\nPerson & number agreement\n-simple 0.3611 0.6389 72\n-longer 0.3492 0.7841 315\n-SentCompl 0.5267 0.9045 1350\nCase agreement\n-simple 0.9444 1.0 18\n-longer 0.7222 0.7889 90\n-SentCompl 0.8722 0.9981 540\nT able 2: Fine-grained results of our experiments. Double-c ase speciﬁcations, e.g. ”-plsg”, are to be read as the\ntested agreement being in plural form, while the distractor is in singular form.\nexcluding German, and found out that with a\nhigher number of distractors and long-range de-\npendencies, B ERT achieves lower accuracies for\nthe syntactic agreement tests.\nAs mentioned above, we also recommend the\noverview paper by\nRogers et al. (2020) on stud-\nies of B ERT models speciﬁcally . Apart from the\nexperiments cited in this work that evaluate multi-\nlingual models, such as MBERT , we are not aware\nof any study dedicated to the agreement analysis\nof German B ERT models.\nR ¨ onnqvist et al. (2019), nevertheless, tested\nmultilingual B ERT models on their ability of hier-\narchical understanding of German sentences and\nwith a cloze test for which an arbitrary (grammat-\nically correct) word was masked and needed to be\nﬁlled in again.\n7 Conclusion\nW e conducted a broad analysis of German B ERT\nmodels, targeting their syntactic abilities. W e\ntranslated agreement tests from English to German\nand also designed tasks that reﬂect syntactic phe-\nnomena that are typical for the German language.\nThe data set we generated and the accompanying\ngrammars are publicly available.\nFurthermore, we utilized the cross-entropy loss\nto score whole natural sentences and this way mit-\nigated a problem with sub-word tokenization. Our\nsource code is open source, too.\nOur experimental results show that the German\nmodels perform very well on most of the agree-\nment tasks. However, we also identiﬁed syntactic\nstress tests that models in other languages appear\nto solve much better. W e plan to replace the syn-\nthetic sentences with real language samples in the\nfuture, to better reﬂect the diversity of the German\nlanguage in our experiments.\nAcknowledgements\nW e would like to thank Leonhard Hennig for\nhis valuable feedback. This work has been sup-\nported by the German Federal Ministry of Educa-\ntion and Research as part of the project BBDC\nII\n(N O. 01IS18025A).\nReferences\nGeoff Bacon and T erry Regier. 2019. Does BER T\nagree? Evaluating knowledge of structure\ndependence through agreement relations.\narXiv:1908.09892 [cs] . ArXiv: 1908.09892.\nJacob Devlin, Ming-W ei Chang, Kenton Lee, and\nKristina T outanova. 2019. Bert: Pre-training of\ndeep bidirectional transformers for language\nunderstanding. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage T echnologies, V olume 1 (Long and Short\nP apers), pages 4171–4186.\nY oav Goldberg. 2019. Assessing bert’s syntactic\nabilities. arXiv preprint arXiv:1901.05287 .\nKristina Gulordava, Piotr Bojanowski, Edouard Grave,\nT al Linzen, and Marco Baroni. 2018. Colorless\nGreen Recurrent Networks Dream Hierarchically.\nIn Proceedings of the 2018 Conference of the North\nAmerican Chapter of the Association for\nComputational Linguistics: Human Language\nT echnologies, V olume 1 (Long P apers) , pages\n1195–1205, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nT al Linzen, Emmanuel Dupoux, and Y oav Goldberg.\n2016. Assessing the ability of LSTMs to learn\nsyntax-sensitive dependencies. T ransactions of the\nAssociation for Computational Linguistics ,\n4:521–535.\nRebecca Marvin and T al Linzen. 2018. T argeted\nsyntactic evaluation of language models. In\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing , pages\n1192–1202, Brussels, Belgium. Association for\nComputational Linguistics.\nT om McCoy, Ellie Pavlick, and T al Linzen. 2019.\nRight for the Wrong Reasons: Diagnosing\nSyntactic Heuristics in Natural Language Inference.\nIn Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics , pages\n3428–3448, Florence, Italy. Association for\nComputational Linguistics.\nFabio Petroni, Tim Rocktschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Y uxiang Wu, and\nAlexander Miller. 2019. Language Models as\nKnowledge Bases? In Proceedings of the 2019\nConference on Empirical Methods in Natural\nLanguage Processing and the 9th International\nJoint Conference on Natural Language Processing\n(EMNLP-IJCNLP), pages 2463–2473, Hong Kong,\nChina. Association for Computational Linguistics.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Y anqi Zhou,\nW ei Li, and Peter J Liu. 2019. Exploring the limits\nof transfer learning with a uniﬁed text-to-text\ntransformer. arXiv preprint arXiv:1910.10683 .\nAnna Rogers, Olga Kovaleva, and Anna Rumshisky.\n2020. A primer in bertology: What we know about\nhow bert works. arXiv preprint arXiv:2002.12327 .\nSamuel R ¨ onnqvist, Jenna Kanerva, T apio Salakoski,\nand Filip Ginter. 2019. Is multilingual BER T ﬂuent\nin language generation? In Proceedings of the First\nNLPL W orkshop on Deep Learning for Natural\nLanguage Processing , pages 29–36, Turku, Finland.\nLink ¨ oping University Electronic Press.\nIan T enney, Patrick Xia, Berlin Chen, Alex W ang,\nAdam Poliak, R. Thomas McCoy, Najoung Kim,\nBenjamin V an Durme, Samuel R. Bowman,\nDipanjan Das, and Ellie Pavlick. 2019. What do\nyou learn from context? Probing for sentence\nstructure in contextualized word representations.\narXiv:1905.06316 [cs] . ArXiv: 1905.06316.\nAshish V aswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information\nprocessing systems , pages 5998–6008.\nThomas W olf, Lysandre Debut, V ictor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi,\nPierric Cistac, Tim Rault, R’emi Louf, Morgan\nFuntowicz, and Jamie Brew . 2019. Huggingface’s\ntransformers: State-of-the-art natural language\nprocessing. ArXiv, abs/1910.03771.\nZhuosheng Zhang, Y uwei Wu, Hai Zhao, Zuchao Li,\nShuailiang Zhang, Xi Zhou, and Xiang Zhou. 2019.\nSemantics-aware bert for language understanding.\narXiv preprint arXiv:1909.02209 .\nZhuosheng Zhang, Junjie Y ang, and Hai Zhao. 2020.\nRetrospective reader for machine reading\ncomprehension. arXiv preprint arXiv:2001.09694 .",
  "topic": "German",
  "concepts": [
    {
      "name": "German",
      "score": 0.6914942860603333
    },
    {
      "name": "Agreement",
      "score": 0.5554310083389282
    },
    {
      "name": "Transformer",
      "score": 0.5098801851272583
    },
    {
      "name": "Linguistics",
      "score": 0.46641528606414795
    },
    {
      "name": "Natural language processing",
      "score": 0.38598835468292236
    },
    {
      "name": "Computer science",
      "score": 0.3736668825149536
    },
    {
      "name": "Philosophy",
      "score": 0.14202702045440674
    },
    {
      "name": "Engineering",
      "score": 0.12103128433227539
    },
    {
      "name": "Electrical engineering",
      "score": 0.07263365387916565
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I33256026",
      "name": "German Research Centre for Artificial Intelligence",
      "country": "DE"
    }
  ]
}