{
  "title": "Comparative analysis of the performance of the large language models DeepSeek-V3, DeepSeek-R1, open AI-O3 mini and open AI-O3 mini high in urology",
  "url": "https://openalex.org/W4412088642",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2350471589",
      "name": "Yan Zijun",
      "affiliations": [
        "Kunming Medical University",
        "Panzhihua Central Hospital",
        "Yunnan University"
      ]
    },
    {
      "id": null,
      "name": "Fan, Ke-qin",
      "affiliations": [
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1901339710",
      "name": "Zhang Qi",
      "affiliations": [
        "Hong Kong Baptist University"
      ]
    },
    {
      "id": "https://openalex.org/A2510987659",
      "name": "Wu Xinyan",
      "affiliations": [
        "Yunnan University",
        "Sichuan Agricultural University",
        "Panzhihua Central Hospital",
        "Kunming Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A1848179187",
      "name": "Chen Yu-quan",
      "affiliations": [
        "Monash University"
      ]
    },
    {
      "id": "https://openalex.org/A2222143088",
      "name": "Wu Xinyu",
      "affiliations": [
        "Panzhihua Central Hospital",
        "Sichuan Agricultural University",
        "Yunnan University",
        "Kunming Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2118211902",
      "name": "Yu Ting",
      "affiliations": [
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2159496772",
      "name": "Su Ning",
      "affiliations": [
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2107631927",
      "name": "Zou Yan",
      "affiliations": [
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2319679831",
      "name": "Chi Hao",
      "affiliations": [
        "Southwest Medical University",
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": null,
      "name": "Xia, Liangjing",
      "affiliations": [
        "Hong Kong Baptist University",
        "Panzhihua Central Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2034939100",
      "name": "Cao Qiang",
      "affiliations": [
        "Kunming University of Science and Technology",
        "Panzhihua Central Hospital",
        "Kunming Medical University",
        "Yunnan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4401388711",
    "https://openalex.org/W4318038352",
    "https://openalex.org/W4399867972",
    "https://openalex.org/W4399828635",
    "https://openalex.org/W4317359099",
    "https://openalex.org/W3185181555",
    "https://openalex.org/W3117241550",
    "https://openalex.org/W4396923492",
    "https://openalex.org/W4401728194",
    "https://openalex.org/W3198788525",
    "https://openalex.org/W4401788618",
    "https://openalex.org/W4381492604",
    "https://openalex.org/W4401377892",
    "https://openalex.org/W4327624155",
    "https://openalex.org/W4388347957",
    "https://openalex.org/W4383710066",
    "https://openalex.org/W4383302386",
    "https://openalex.org/W4401083855",
    "https://openalex.org/W4390704701",
    "https://openalex.org/W4381309893",
    "https://openalex.org/W4401798900",
    "https://openalex.org/W6601289607",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4404795474",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4403982217",
    "https://openalex.org/W4405234363",
    "https://openalex.org/W4321366933",
    "https://openalex.org/W4391004116",
    "https://openalex.org/W4408391653",
    "https://openalex.org/W3040260923",
    "https://openalex.org/W4404134492",
    "https://openalex.org/W4400879250",
    "https://openalex.org/W4402313440",
    "https://openalex.org/W4398194877",
    "https://openalex.org/W4238494775",
    "https://openalex.org/W2067659486",
    "https://openalex.org/W3089715081",
    "https://openalex.org/W3113314539",
    "https://openalex.org/W3173550964",
    "https://openalex.org/W4360830375",
    "https://openalex.org/W4376277336",
    "https://openalex.org/W4220685687",
    "https://openalex.org/W3093312636",
    "https://openalex.org/W2907010595"
  ],
  "abstract": "Abstract Objectives We sought to compare how DeepSeek‑V3, DeepSeek‑R1, OpenAI o3‑mini, and OpenAI o3‑mini high handle urological questions, especially in areas such as benign prostatic enlargement, urinary stones, infections, and guideline updates. The intent was to identify how these text‑creation platforms might aid clinical practice without overlooking potential gaps in accuracy. Methods A set of 34 routinely asked questions plus 25 queries based on newly revised guidelines was assembled. Six board‑certified urologists independently scored each system’s replies using a five‑point scale. Questions scoring below a set threshold were reintroduced to the same system, accompanied by critiques, to gauge self‑correction. Statistical analyses focused on total scores, percentage of excellent ratings, and improvements after iterative prompting. Results Across all 59 queries (34 general plus 25 guideline-based), OpenAI o3-mini high recorded the highest median total score (22 [20–24]), significantly outperforming DeepSeek-R1, DeepSeek-V3 and OpenAI o3-mini (all pair-wise p &lt; 0.01). DeepSeek-R1’s accuracy approached that of o3-mini high in patient-counseling items, where their excellent-answer rates were 49% and 57%, respectively. DeepSeek‑V3 achieved solid baseline correctness but made fewer successful corrections on subsequent attempts. Although OpenAI o3‑mini initially produced more concise responses, it showed a surprisingly strong capacity to revise earlier errors. Conclusion OpenAI o3‑mini high, followed by DeepSeek‑R1, provided the most reliable answers for modern urological concerns, whereas DeepSeek‑V3 exhibited limited adaptability during re‑evaluation. Despite often briefer replies, OpenAI o3‑mini outdid DeepSeek‑V3 in self‑correction. These findings indicate that, when reviewed by a clinician, o3-mini high can serve as a rapid second-opinion tool for outpatient counselling and protocol updates, whereas DeepSeek-R1 may provide a cost-effective alternative in resource-limited settings.",
  "full_text": "RESEARCH\nWorld Journal of Urology          (2025) 43:416 \nhttps://doi.org/10.1007/s00345-025-05757-4\npelvic organs [1–7]. With developments such as endoscopic \nfiber-optic technology and advanced imaging protocols, the \nonce-rudimentary landscape of kidney stone removal, blad-\nder tumor resection, or prostatic surgery has transformed \ninto a high-tech environment. Yet, these technological leaps \nbring fresh complexities. For instance, the introduction \nof robotic-assisted laparoscopic prostatectomy improved \nIntroduction\nUrology, as a distinct branch of medical practice, covers \na surprisingly wide domain of concerns related to the uri -\nnary tract and the male reproductive system. In day-to-day \npractice, a urologist deals not only with kidneys, ureters, \nand bladders but also with prostates, testicles, and assorted \nZijun Yan, Ke-qin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, and \nXinyu Wu contribute equally to this work.\nExtended author information available on the last page of the article\nAbstract\nObjectives We sought to compare how DeepSeek-V3, DeepSeek-R1, OpenAI o3-mini, and OpenAI o3-mini high handle \nurological questions, especially in areas such as benign prostatic enlargement, urinary stones, infections, and guideline \nupdates. The intent was to identify how these text-creation platforms might aid clinical practice without overlooking poten-\ntial gaps in accuracy.\nMethods A set of 34 routinely asked questions plus 25 queries based on newly revised guidelines was assembled. Six \nboard-certified urologists independently scored each system’s replies using a five-point scale. Questions scoring below a \nset threshold were reintroduced to the same system, accompanied by critiques, to gauge self-correction. Statistical analyses \nfocused on total scores, percentage of excellent ratings, and improvements after iterative prompting.\nResults Across all 59 queries (34 general plus 25 guideline-based), OpenAI o3-mini high recorded the highest median total \nscore (22 [20–24]), significantly outperforming DeepSeek-R1, DeepSeek-V3 and OpenAI o3-mini (all pair-wise p < 0.01). \nDeepSeek-R1’s accuracy approached that of o3-mini high in patient-counseling items, where their excellent-answer rates \nwere 49% and 57%, respectively. DeepSeek-V3 achieved solid baseline correctness but made fewer successful corrections \non subsequent attempts. Although OpenAI o3-mini initially produced more concise responses, it showed a surprisingly \nstrong capacity to revise earlier errors.\nConclusion OpenAI o3-mini high, followed by DeepSeek-R1, provided the most reliable answers for modern urological \nconcerns, whereas DeepSeek-V3 exhibited limited adaptability during re-evaluation. Despite often briefer replies, OpenAI \no3-mini outdid DeepSeek-V3 in self-correction. These findings indicate that, when reviewed by a clinician, o3-mini high can \nserve as a rapid second-opinion tool for outpatient counselling and protocol updates, whereas DeepSeek-R1 may provide a \ncost-effective alternative in resource-limited settings.\nKeywords Urology · Large language models · Clinical guidelines · Performance evaluation · Self-correction capacity\nReceived: 2 February 2025 / Accepted: 10 June 2025\n© The Author(s) 2025\nComparative analysis of the performance of the large language \nmodels DeepSeek-V3, DeepSeek-R1, open AI-O3 mini and open AI-O3 \nmini high in urology\nZijun Yan1,5 · Ke-qin Fan1 · Qi Zhang2 · Xinyan Wu3 · Yuquan Chen4 · Xinyu Wu1,5 · Ting Yu1 · Ning Su1 · Yan Zou1 · \nHao Chi1,6 · Liangjing Xia1,2 · Qiang Cao1,5,7\n1 3\n\nWorld Journal of Urology          (2025) 43:416 \nsurgical precision but added a steeper learning curve, not to \nmention cost considerations for institutions [ 8–14]. Train-\ning, mentorship, and standardization of care are vital for \nensuring good clinical results in procedures like transure -\nthral prostate resection or radical cystectomy. At the same \ntime, urology remains intimately concerned with patients’ \nquality of life, addressing sexual function, incontinence, \nchronic pelvic pain, and psychosocial factors that are not \nalways easy to quantify.\nIn recent years, there has been a global wave of interest \nin large language model that generate written content with \nremarkable fluency. Urologists, who routinely sift through \nmassive amounts of clinical data and evolving scientific lit-\nerature, have taken notice of these emerging text-process -\ning platforms [ 15–21]. To date, however, no head-to-head \nstudy has simultaneously benchmarked proprietary and \nopen-source LLMs against expert opinion on both everyday \nand guideline-driven urological decision points, leaving a \nclear gap in evidence for their comparative clinical utility. \nAmong them, DeepSeek-V3 and DeepSeek-R1 have gar -\nnered considerable attention within academic communities \nfor their ability to produce elaborate, context-aware narra -\ntives, sometimes matching or exceeding what a human peer \nwould generate when asked about key issues like prostate \ncancer screening or surgical guidelines for kidney stones. \nDeepSeek-V3, known for its enormous parameter count, \nhas stirred curiosity because of its emphasis on mixture-\nof-experts structure, allegedly allowing for more nuanced, \nspecialized replies in logic-heavy or coding-related con -\ntexts—though some experts question whether it tends to \nlack deeper reasoning in certain nuanced clinical scenarios \n[22]. DeepSeek-R1, which shares a similar foundation, \nintroduces a reinforcement-based approach intended to \nrefine the clarity and correctness of its results, potentially \nmaking it more transparent in the way it formulates answers \nto tricky queries such as deciding when to offer radical cys-\ntectomy [23]. Alongside these DeepSeek systems, the Open \nAI-O3 mini versions have also gained a foothold world -\nwide, especially among clinicians seeking a more nimble \ntext generator with robust question-answering capabilities \nin science, math, and stepwise reasoning. DeepSeek models \nrely on a Mixture-of-Experts architecture that routes each \nquestion to specialised sub-networks, trading raw speed for \ngreater topical depth, whereas the OpenAI o-series employs \na dense-transformer backbone tuned heavily on reasoning \nand safety alignment to deliver concise, broadly reliable \nanswers. Readers unfamiliar with these platforms can freely \nexperiment with demo endpoints provided at https://plat-\nform.deepseek.com and  h t t p s : / / p l a t f o r m . o p e n a i . c o m     . The \nO3 mini high boasts a higher reasoning level, offering, in \nprinciple, more precise solutions for complicated quandaries \none might face in advanced oncologic guidelines or intricate \nreconstructive surgery decisions [ 24, 25]. According to \ninternational medical discourse, these text-producing tools \nhold the promise of accelerating data assimilation, sum -\nmarizing newly released guidelines, and educating trainees \nwho lack the time to comb through every detail in volu -\nminous clinical trial reports [ 26–31]. However, consistent \nreliability has not been proven in every domain, and some \npractitioners worry that partial inaccuracies—especially \naround antibiotic stewardship or novel hormone therapy \nintervals—could inadvertently influence clinical judgment. \nFor instance, early deployments of chat-based triage sys -\ntems recommended fluoroquinolones for uncomplicated \ncystitis despite 2019 FDA safety warnings, and a dermatol-\nogy-focused LLM mislabelled histologically proven early \nmelanomas as benign naevi, underscoring the tangible risks \nof unquestioned AI output [ 32–34].Artificial-intelligence \ndeployment in health care therefore raises a distinct set of \nethical obligations that reach beyond traditional notions \nof clinical accuracy. First, training-data bias can silently \npropagate health-care inequities if a model is fine-tuned on \ndatasets that under-represent certain age groups, ethnici -\nties, or resource-limited settings. Second, privacy and data-\nprotection statutes such as the European Union’s GDPR \nand China’s Personal Information Protection Law mandate \nexplicit safeguards when patient notes or imaging data are \nuploaded for model refinement. Third, explainability is no \nlonger an academic luxury: without transparent rationales \nclinicians cannot satisfy the duty of informed consent, nor \ncan they contest unsafe recommendations in medico-legal \ndisputes. Finally, most regulatory frameworks—including \nthe U.S. FDA’s proposed AI/ML-Enabled Device guid -\nance—now emphasise “human-in-the-loop” accountability, \nrequiring that automated suggestions be auditable and over-\nruled by a licensed practitioner. Any evaluation of large lan-\nguage models for urology must therefore consider not only \nnumerical performance but also these intertwined issues of \nbias mitigation, privacy preservation, traceability, and pro -\nfessional responsibility [ 35–41]. The worldwide situation \nthus stands at a crossroads: many teaching hospitals and \nresearch centers are experimenting with DeepSeek or Open \nAI-O3 platforms for academic writing support, patient edu-\ncation materials, and quick reference queries, but the debate \nregarding authenticity, interpretative errors, and liability for \nmisguided care remains lively.\nThis article attempts to compare these text-creation sys -\ntems—DeepSeek-V3, DeepSeek-R1, OpenAI o3-mini, and \nOpenAI o3-mini high—through a structured set of ques -\ntions drawn from everyday urological practice and from \nnewly revised guidelines. By enlisting expert evaluation \nof each system’s responses and exploring how well they \nself-correct after pointed feedback, we hope to illuminate \n1 3\n  416  Page 2 of 10\nWorld Journal of Urology          (2025) 43:416 \nboth the benefits and drawbacks these systems might pres -\nent in clinical environments.\nMethods\nStudy design\nA set of frequently encountered clinical questions pertain -\ning to urological conditions was assembled by reviewing \nreputable online medical resources and standard clinical \nguidelines. The assembled questions encompassed common \nurological complaints, diagnostic approaches, therapeutic \nstrategies, preventive measures, and emerging trends in \nurology. To capture current practice scenarios, the question \nset was refined by experienced urologists who prioritized \nqueries deemed most representative of everyday clinical \ndecision-making and patient education in urology. In total, \n34 questions were identified as reflective of routine urologi-\ncal practice, addressing conditions such as benign prostatic \nhyperplasia, urinary tract infections, nephrolithiasis, onco -\nlogical concerns (e.g., prostate cancer), and postoperative \nmanagement. These questions were organized into thematic \ngroups to facilitate focused assessment: pathology and \nmechanisms, diagnosis, treatment, prevention, and patient \ncounseling, as shown in Appendix Table 1. An additional \nset of 25 questions was derived from recent updates to uro -\nlogical practice guidelines—particularly those released in \nthe past 18 months by major associations—to evaluate how \naccurately each model handles the latest evidence-based \nrecommendations [ 42–50]. Each question was presented \nindividually to the four models—DeepSeek-V3, DeepSeek-\nR1, OpenAI o3-mini, and OpenAI o3-mini high—to solicit \nresponses under identical conditions, as shown in Appendix \nTable 2.\nExpert evaluation and scoring\nSix board-certified urology experts (median practice 14 \nyears, range 11–22), recruited through the national society’s \npeer-review roster to minimise institutional bias, indepen -\ndently appraised each model’s responses. Six board-certi -\nfied urology experts—actively practising clinicians with \nno financial relationship to the companies developing the \nevaluated models and excluded if they had co-authored AI-\nrelated commercial work—independently appraised each \nmodel’s responses.The evaluation was blinded such that the \nexperts were unaware of which model produced the text. \nTo ensure a clear differentiation from previously published \nrating methods, a customized five-point scoring scale was \nadopted:\n(1) 1 point—factually incorrect or highly misleading \ncontent.\n(2) Points—partially accurate but containing serious omis -\nsions or errors.\n(3) Points—generally accurate but lacking important \ndetails or clinical nuance.\n(4) Points—accurate, appropriately detailed, and clinically \nrelevant.\n(5) Points—comprehensive, precise, and demonstrating \nsuperior clinical applicability.\nEach expert awarded a separate score (ranging from 1 to \n5) for every question response from the four models, yield -\ning a total score out of 30 (5 points × 6 experts) per query. \nWhen two reviewers’ ratings for a given response differed \nby more than two points, the full panel convened a brief \nblinded tele-conference and reached consensus by major -\nity vote, ensuring a uniform final score without altering \nindividual rater statistics used for Fleiss’ κ. For interpretive \nconsistency, overall performance was grouped into three \ncategories: scores under 10 were labeled “Inadequate,” \nscores of 10 to 20 were “Acceptable,” and scores above 20 \nwere “Excellent.”\nPrompting for self-correction\nTo investigate the capacity of each model to refine answers \nthrough iterative feedback, responses scoring below 10 \n(“Inadequate”) were presented again to the same model \nalongside a brief critique indicating the primary weak -\nnesses or inaccuracies. The prompt encouraged the model \nto “review and correct any errors, then provide the most up-\nto-date, accurate response possible.” This new response was \ngathered in plain text form and re-evaluated by the same \nsix experts in a separate round, conducted two weeks later. \nExperts were intentionally blinded to whether the response \nunder review was an original or revised answer. The dif -\nference in scores before and after self-correction was then \nanalyzed to quantify the model’s capacity for meaningful \nimprovement.\nStatistical analysis\nAll raw scores from the six experts were collected and tested \nfor interrater reliability. Fleiss’ kappa was used to gauge \nthe level of agreement among the six evaluators regard -\ning each model’s responses. Mean ± SD (or median [IQR]) \nwere computed for each item; cross-model differences were \ntested with Kruskal–Wallis analysis followed by Bonfer -\nroni-adjusted Dunn pairwise tests, while before-versus-\nafter self-correction scores were analysed with Wilcoxon \nsigned-rank tests. Post hoc analyses, including pairwise \n1 3\nPage 3 of 10   416 \nWorld Journal of Urology          (2025) 43:416 \nvs. DeepSeek-V3). Character-count differences were \nconcordant.\nFor the 25 guideline-based prompts (Table 2) DeepSeek-\nR1 wrote the longest answers (302 words [285–335]), Deep-\nSeek-V3 was second (288 words [265–316]) and o3-mini \nthe briefest (250 words [210–276], p < 0.05 vs. DeepSeek-\nR1). A post-hoc Spearman analysis revealed only a weak, \nnon-significant association between response length and \naccuracy (ρ = 0.18, p = 0.12), suggesting that verbosity alone \ndid not determine correctness.\nAccuracy on the 34 general-practice questions\nMedian total scores (TS) by thematic domain are presented \nin Table 3. o3-mini high led overall (22.0 [20.0–24.0]), sig-\nnificantly outperforming every comparator (p < 0.05). Deep-\nSeek-R1 placed second and essentially tied o3-mini high for \npatient-counselling items (23.0 vs. 24.0, p = 0.062). o3-mini \nrecorded the lowest general-question median (17.5), largely \nbecause its terse phrasing omitted qualifying details.\nAccuracy on the 25 guideline-based questions\nTable 4 details the guideline cohort. o3-mini high achieved \nthe highest median TS—23.0 (21.0–25.0), range 17–30—\nand delivered an “Excellent” answer (> 20/30) for 60% of \nprompts. DeepSeek-R1 ranked second with a median 20.0 \n(19.0–23.0), range 15–29, performing particularly well \non active-surveillance and imaging-interval questions but \nmissing fine points on antibiotic prophylaxis. DeepSeek-V3 \ncomparisons, were carried out when overall comparisons \nsuggested significant differences. Changes in scoring before \nand after self-correction were examined using paired tests, \nwith statistical significance set at p < 0.05.\nResults\nLengths of model responses\nTable 1 compares median word- and character-counts for \nthe 34 routine prompts. DeepSeek-V3 and DeepSeek-R1 \nproduced the longest replies (≈ 290 words). o3-mini high \nwas ~ 8% shorter and o3-mini ~ 14% shorter (both p < 0.05 \nTable 1 Length of responses for 34 general urology questions\nModel Word count, M(P25–P75) Character count, \nM(P25–P75)\nDeepSeekV3 292.00 (271.00–329.00) 2108.00 \n(1822.00–2414.00)\nDeepSeekR1 288.00 (252.50–320.00) 2004.50 \n(1746.75–2136.00)\nOpenAI o3mini 252.50 (218.75–278.50)* 1598.00 (1443.75–\n1708.25)*\nOpenAI o3mini \nhigh\n269.00 (221.00–293.00)^ 1786.00 (1625.50–\n1985.50)^\n*P < 0.05 vs. DeepSeek-V3, ^ P < 0.05 vs. DeepSeek-R1\nTable 2 Length of responses for 25 guideline-based questions\nModel Word count, M(P25–P75) Character count, \nM(P25–P75)\nDeepSeekV3 287.50 (265.00–316.00) 2035.50 \n(1774.00–2254.00)\nDeepSeekR1 302.00 (285.00–335.00) 2136.00 \n(1986.50–2342.00)\nOpenAI o3mini 250.00 (210.00–275.50)* 1527.00 (1356.00–\n1693.50)*\nOpenAI o3mini \nhigh\n274.50 (232.00–291.50) 1672.00 \n(1534.75–1853.00)\n* P < 0.05 vs. DeepSeek-R1\nTable 4 Total scores (TS) for 25 guideline-based questions\nModel Median (P25–P75) Range\nDeepSeekV3 19.50 (17.00–21.00) 13–26\nDeepSeekR1 20.00 (19.00–23.00) 15–29\nOpenAI o3mini 16.50 (14.00–18.50) 10–23\nOpenAI o3mini high 23.00 (21.00–25.00)* 17–30\n*P < 0.05 vs. all other models\nCategory DeepSeekV3, \nM(P25–P75)\nDeepSeekR1, \nM(P25–P75)\nOpenAI o3mini, \nM(P25–P75)\nOpenAI o3mini \nhigh, M(P25–P75)\nP \nvalue\nPathology and \nmechanisms\n19.00 (17.00–21.00) 22.50 \n(20.00–23.00)\n16.00 \n(14.00–18.50)\n23.50 \n(21.00–25.00)*\n0.006\nDiagnosis 19.00 (16.50–20.50) 21.00 \n(19.00–22.50)\n17.00 \n(14.75–19.00)\n22.00 (20.00–24.00) 0.012\nTreatment 20.00 (18.00–21.00) 21.50 \n(19.00–23.00)\n18.50 \n(15.00–20.00)\n24.00 \n(22.00–25.00)*\n0.004\nPrevention 19.50 (17.00–21.00) 20.00 \n(18.00–22.00)\n17.50 \n(15.00–20.00)\n22.00 (20.00–24.00) 0.028\nPatient \ncounseling\n20.00 (18.00–22.00) 23.00 \n(20.75–24.00)\n19.50 \n(17.00–21.50)\n24.00 (22.00–25.00) 0.06\nAll general \nquestions\n19.50 (17.00–22.00) 20.50 \n(18.75–23.00)\n17.50 \n(15.00–20.00)\n22.00 \n(20.00–24.00)*\n0.003\nTable 3 Total scores (TS) for 34 \ngeneral questions by thematic \ncategory\n*P < 0.05 vs. all other models\n \n1 3\n  416  Page 4 of 10\nWorld Journal of Urology          (2025) 43:416 \nimprovements were also seen for o3-mini and DeepSeek-\nR1, whereas DeepSeek-V3’s gains were modest and non-\nsignificant. Average point increases across all inadequate \nanswers were: o3-mini high + 6.2, o3-mini + 5.2, DeepSeek-\nR1 + 4.7, DeepSeek-V3 + 2.1.\nInter-rater reliability\nExpert agreement was moderate for general prompts \n(κ = 0.54, 95% CI 0.47–0.60) and strong for guideline \nprompts (κ = 0.68, 95% CI 0.61–0.75). Most disagreements \noccurred at the 19–21-point border between “Acceptable” \nand “Excellent.”\nshowed similar central tendency (19.5 [17.0–21.0]) yet \nwas less consistent, occasionally providing conflicting dos-\ning schedules. o3-mini trailed (16.5 [14.0–18.5]) because \nits brevity sacrificed guideline granularity; nevertheless, \nthe model was never dangerously wrong, and 29% of its \nanswers still reached the “Excellent” threshold.\nGlobal accuracy distribution\nAggregating all 59 prompts, Table 5 shows that o3-mini \nhigh produced “Excellent” answers in 59% of cases and \nfell below “Acceptable” (< 10/30) only six times. Figure 1 \nvisually confirms this gradient, highlighting the markedly \nhigher share of ‘Excellent’ responses achieved by o3-mini \nhigh compared with the other three models. DeepSeek-R1 \nachieved 48% excellent, DeepSeek-V3 42%, and o3-mini \n31%.\nSelf-correction ability\nAmong responses initially rated “Inadequate,” re-prompt -\ning yielded the consolidated outcomes in Table 6. Median \nscores for o3-mini high nearly doubled for both general \n(p = 0.014) and guideline ( p = 0.013) prompts. Significant \nTable 5  Accuracy rating distribution for all 59 questions (34 gen -\neral + 25 guideline-based)\nModel Poor < 10, n \n(%)\nAcceptable \n10–20, n (%)\nExcel-\nlent > 20, n \n(%)\nDeepSeek-V3 19 (32.2%) 15 (25.4%) 25 (42.4%)\nDeepSeek-R1 11 (18.6%) 20 (33.9%) 28 (47.5%)\nOpenAI o3-mini 23 (39.0%) 18 (30.5%) 18 (30.5%)\nOpenAI o3-mini high 6 (10.2%) 18 (30.5%) 35 (59.3%)\nModel General questions initial TS M \n(P25–P75) → Post TS\np-Value Guideline questions initial TS \nM (P25–P75) → Post TS\np-Value\nDeepSeek-V3 7.00 (5.75–8.25) → 9.00 \n(7.50–10.00)\n0.096 6.00 (5.00–7.00) → 8.00 \n(6.50–9.00)\n0.072\nDeepSeek-R1 7.00 (6.00–8.00) → 12.50 \n(10.00–14.00)\n0.022 8.00 (7.00–9.00) → 12.00 \n(11.00–13.00)\n0.028\nOpenAI o3-mini 6.50 (5.00–9.00) → 12.00 \n(10.00–13.00)\n0.019 5.00 (3.00–7.00) → 11.00 \n(9.00–13.00)\n0.015\nOpenAI o3-mini \nhigh\n8.00 (7.00–9.00) → 14.00 \n(12.00–15.00)\n0.014 8.00 (7.00–8.00) → 15.00 \n(13.50–16.00)\n0.013\nTable 6 Self-correction outcomes \nfor all “inadequate” responses \n(< 10 points)\n \nFig. 1 Proportion of “Excel-\nlent” (> 20/30) answers across 59 \nquestions\n \n1 3\nPage 5 of 10   416 \nWorld Journal of Urology          (2025) 43:416 \nwhereas smaller but well-aligned systems still improved cli-\nnician efficiency. Such concordance suggests that our urol -\nogy-focused observations reflect a broader pattern rather \nthan a specialty-specific anomaly. Automated answers alone \ncannot replace expert oversight, especially given the het -\nerogeneity of patient presentations in real-world settings. \nBeyond accuracy, the ethical landscape includes safeguard-\ning patient confidentiality, clarifying liability for AI-derived \nadvice, and ensuring transparency when generative text \nis incorporated into clinical notes. All four models occa -\nsionally produced confident but spurious statements—an \ninstance of hallucination that, if unrecognised, could propa-\ngate unsafe recommendations such as outdated antibiotic \nregimens; mandatory human verification therefore remains \nindispensable. The subtle differences in diagnostic pathways \nand recommended treatments require the measured discern-\nment of a trained practitioner, informed by guidelines that \nevolve rapidly. The higher performance of certain systems \nin advanced oncologic settings can be a promising supple -\nment in multidisciplinary teamwork, ensuring that key \nupdates—such as new hormone therapy dosing intervals or \naltered imaging schedules—are not overlooked. However, \neven the models that excelled in accuracy and detail may \nexhibit inconsistencies when dealing with layered questions \ninvolving psychosocial factors. Consistent validation by \nurology professionals remains essential to prevent inaccura-\ncies that might compromise patient outcomes. Ultimately, \nthese observations highlight how technological innovations \nin language modeling, although promising, should be inte -\ngrated thoughtfully, with vigilant clinical governance safe -\nguarding the quality of care at every step.\nDeepSeek-V3 and DeepSeek-R1 both utilize a Mixture \nof Experts (MoE) configuration, boasting large parameter \ncounts that facilitate complex text generation. Notably, \nDeepSeek-R1’s emphasis on iterative reinforcement learn -\ning and group relative policy optimization contributes to \nan enhanced reasoning capacity and more transparent solu -\ntion derivation in many tasks. This improved reasoning is \nevident when interpreting advanced urological guidelines, \nalthough it can sometimes lead to verbose explanations \nrequiring further pruning for clarity. By contrast, the Ope -\nnAI o3-mini series, including the higher-intensity variant, \noptimizes for science, technology, engineering, and math -\nematics reasoning while maintaining cost-efficiency and \nspeed—a design choice that manifests in concise but high-\nquality responses. The self-correction capacities observed \nin OpenAI o3-mini high illustrate the benefits of advanced \nfeedback integration layers, which can substantially boost \nperformance after a prompt identifying weaknesses or inac-\ncuracies. Large language models operating with numerous \nparameters may have the potential to outperform smaller \nsystems, yet these findings highlight that scale alone does \nOverall ranking\nConsidering first-pass accuracy (Tables 3 and 4) and feed -\nback responsiveness (Table 6), the final hierarchy was: \no3-mini high > DeepSeek-R1 > o3-mini > DeepSeek-V3. \nEven the lowest performer (o3-mini) maintained a median \n17.5/30, so none of the four systems generated uniformly \nunsafe advice.\nDiscussion\nTraditionally, the assessment of automated text-generation \ntools in urology has centered on their capacity to provide \naccurate, clinically relevant, and trustworthy information. \nBecause all six reviewers were academically affiliated, their \npreferences for formal medical prose may have favoured \ncertain stylistic features; future work should include \ncommunity-based urologists to mitigate this potential rat -\ning bias. In this comparative evaluation of DeepSeek-V3, \nDeepSeek-R1, OpenAI o3-mini, and OpenAI o3-mini high, \nthe observed performance differences offer crucial insights \ninto how these models might be harnessed in daily clini -\ncal scenarios. Clarity and precision in handling common \nurological conditions—such as benign prostatic hyperpla -\nsia, urinary tract infections, nephrolithiasis, and prostate \ncancer—are paramount. Notably, OpenAI o3-mini high \ndisplayed a particularly impressive level of thoroughness \nand depth in responses, achieving higher overall scores in \nvarious thematic categories. Such robust performance sug -\ngests potential benefits for complex decision-making, for \nexample, in evaluating evolving treatments for metastatic \nprostate cancer or selecting best-practice methods for anti -\nbiotic prophylaxis. DeepSeek-R1 demonstrated commend -\nable accuracy, sometimes approaching the proficiency of \nOpenAI o3-mini high, especially in domains like patient \ncounseling. Its capacity to illuminate finer points in post -\noperative care and emerging interventions illustrates an \naptitude for guiding nuanced discussion with patients. \nDeepSeek-V3, while solid in foundational knowledge, \noccasionally faltered when confronted with the need for \ndetailed clarification of contemporary guidelines, and its \nself-correction feature appeared more limited. Conversely, \nOpenAI o3-mini stood out through concise communica -\ntion that may be valuable in streamlining patient education, \nthough it sometimes lacked the comprehensive breadth \ndesired by specialists. These findings underscore the need \nfor critical evaluation of generative tools that purport to \nenhance clinical practice.Comparable cross-disciplinary \nevaluations echo our results; in cardiology and dermatology \nbenchmarks, higher-parameter OpenAI variants likewise \nsurpassed Open-source MoE models in guideline fidelity, \n1 3\n  416  Page 6 of 10\nWorld Journal of Urology          (2025) 43:416 \nsupervision to ensure completeness in topics that require \ndetailed elaboration. The scoring patterns observed in the \nstudy reflect not only raw content correctness but also an \nalignment with current recommendations from prominent \nurological associations. According to these findings, model \nselection may be guided by clinical priorities; for example, \ncenters requiring extensive coverage of emerging onco -\nlogic guidelines might choose a higher-intensity reasoning \nmodel, whereas clinics focusing on rapid dissemination of \nconservative management tips might consider a concise \ngenerator. It remains prudent to maintain a skeptical stance \nwhen delegating educational tasks to generative systems, as \neven the strongest model can miss subtle changes in prac -\ntice guidelines. Ensuring a human-in-the-loop approach is \ncrucial for bridging knowledge gaps and mitigating poten -\ntial harm. When it comes to patient counseling, a gentle but \nknowledgeable tone is required to handle sensitive topics \nsuch as psychosocial support in chronic prostatitis. Auto -\nmated outputs should therefore be considered initial drafts, \nallowing the clinician to refine vocabulary, personalize care \ninstructions, and address emotional factors that statistical \nalgorithms cannot fully comprehend. Leveraging these mod-\nels, if done responsibly, can improve workflow efficiency \nand aid in handling routine questions that otherwise con -\nsume precious consultation time. Yet, caution is advisable \nbecause oversight lapses may diminish the trust patients \nplace in medical advice, especially if contradictions arise in \nsubsequent consultations. The strength of this study is the \nintegration of data comparing four well-known large lan -\nguage models, revealing clear differences in accuracy, self-\ncorrection, and adherence to guidelines. However, there are \nstill limitations to this study. The sample size of this study \nis limited and inevitably relies on subjective expert scoring. \nFuture research will require more multi-institutional stud -\nies and iterative improvements to ensure safe and effective \napplication in urology practice.\nConclusion\nThis comparative evaluation of DeepSeek-V3, DeepSeek-\nR1, OpenAI o3-mini, and OpenAI o3-mini high underscores \nboth the promise and limitations of large language models \nin urological practice. By presenting 34 clinically oriented \nquestions and an additional 25 guideline-based queries, and \nthen employing blinded expert review, the study reveals that \nOpenAI o3-mini high achieves the highest overall scores in \naccuracy, detail, and alignment with recently updated guide-\nlines. DeepSeek-R1 follows closely, particularly excelling \nin patient counseling domains, while DeepSeek-V3 demon-\nstrates a solid baseline understanding but shows less flex -\nibility in post-response self-corrections. OpenAI o3-mini, \nnot guarantee superior clinical guidance. Cost and acces -\nsibility also merit attention: o3-mini high currently carries \nan operational cost roughly three-times that of DeepSeek-\nR1, which could restrict its adoption in smaller clinics or \nlow-resource regions. Data curation, reward structures, and \ndomain-specific fine-tuning appear to be equally important, \nif not more so, in determining real-world utility. Further -\nmore, some architectures, while excelling in raw capacity, \nmay require additional refinement to manage domain-spe -\ncific jargon, especially in a field as specialized as urology. \nThe interplay between parameter efficiency and real-time \nadaptability remains intriguing—OpenAI o3-mini, though \nsmaller, often displayed notable plasticity during iterative \ncorrections, suggesting that carefully architected feedback \nloops can partially compensate for fewer parameters. The \nconclusion drawn from these results is that each system’s \ndesign priorities, such as maximizing interpretability or \nachieving a balance between speed and detail, shape its \nbehavior in ways that are particularly salient in medical \ncontexts. Continuous monitoring, versioning, and updates \nappear vital, given how guideline modifications can rapidly \nshift the landscape of best practices. Equally important is \nan understanding that domain knowledge, once accurately \nintegrated, must be continuously tested against emerging \nevidence. From a systems-engineering standpoint, these \nmodels show that synergy among massive pre-training, \nstrategic fine-tuning, and carefully structured reward signals \ncan produce remarkable performance, but domain-based \nscrutiny is imperative to confirm reliability in patient-facing \nsolutions.\nA viewpoint from daily urology clinical practice empha-\nsizes the pragmatic implications of these findings. Although \nthoroughness in addressing BPH symptomatology, diagnos-\ntic algorithms for UTIs, and cutting-edge management of \nprostate malignancies is important, the actual translation of \nmodel responses into better patient care necessitates con -\ntextual awareness and expert judgment. OpenAI o3-mini \nhigh, for instance, appears proficient at synthesizing \nguideline-based information on advanced oncologic treat -\nments, such as novel hormonal therapies, offering clinicians \nrapid reinforcement of complex protocols. DeepSeek-R1’s \nrobust baseline performance in patient counseling scenar -\nios—particularly post-prostatectomy erectile dysfunction \nand fertility preservation—suggests a valuable utility for \ncommunicating nuanced information, as long as clinicians \nreview the generated responses for accuracy. DeepSeek-V3 \ndisplays promise in certain logic-intensive queries, yet it \noccasionally fails to refine initial inaccuracies upon iterative \nprompting, which implies a risk of propagating misinforma-\ntion if left unchecked. Meanwhile, OpenAI o3-mini demon-\nstrates that an efficient, succinct style can be helpful when \nhandling standard counseling points, yet it also demands \n1 3\nPage 7 of 10   416 \nWorld Journal of Urology          (2025) 43:416 \nDeclarations\nConflict of interest The authors declare no competing interests.\nEthics approval and consent to participate  This study was reviewed \nby the Kunming University of Science and Technology Ethics Com -\nmittee, which determined that this study could be conducted without \napproval.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit  h t t p  : / /  c r e a  t i  v e c  o m m o  n s .  o \nr g  / l i c e n s e s / b y / 4 . 0 /.\nReferences\n1. Rosenblad AK, Hashim BM, Lindblad P et al (2024) Recurrences \nafter nephron-sparing treatments of renal cell carcinoma: a com -\npeting risk analysis. World J Urol 42(1):474\n2. Corona G, Cucinotta D, Di Lorenzo G et al (2023) The Italian \nsociety of andrology and sexual medicine (SIAMS), along with \nten other Italian scientific societies, guidelines on the diagnosis \nand management of erectile dysfunction. J Endocrinol Investig \n46(6):1241–1274\n3. Nicolazzini M, Palumbo C, Porté F et al (2024) Preoperative pro-\nteinuria correlates with renal function after partial nephrectomy \nfor renal cell carcinoma. World J Urol 42(1):381\n4. Mazza M, Margoni S, Mandracchia G et al (2024) This pain \ndrives me crazy: psychiatric symptoms in women with interstitial \ncystitis/bladder pain syndrome. World J Psychiatry 14(6):954\n5. Tamadonfar K O, Di Venanzio G, Pinkner JS et al (2023) Struc -\nture–function correlates of fibrinogen binding by acinetobacter \nadhesins critical in catheter-associated urinary tract infections. \nProc Natl Acad Sci 120(4):e2212694120\n6. Wertli MM, Zumbrunn B, Weber P et al (2021) High regional \nvariation in prostate surgery for benign prostatic hyperplasia in \nSwitzerland. PLoS ONE 16(7):e0254143\n7. Fitzpatrick K (2021) The imperial makings of medical work: \nPeter Johnstone Freyer and the practice of genitourinary medicine \nin Britain and the raj, c. 1875–1921. J Soc Hist 55(2):426–452\n8. Tomida R, Fukawa T, Kusuhara Y et al (2024) Robot-assisted par-\ntial nephrectomy in younger versus older adults with renal cell \ncarcinoma: a propensity score-matched analysis. World J Urol \n42(1):326\n9. Li JK, Tang T, Zong H et al (2024) Intelligent medicine in focus: \nthe 5 stages of evolution in robot-assisted surgery for prostate \ncancer in the past 20 years and future implications. Military Med \nRes 11(1):58\n10. Makary J, van Diepen DC, Arianayagam R et al (2022) The \nevolution of image guidance in robotic-assisted laparoscopic \nprostatectomy (RALP): a glimpse into the future. J Robot Surg \n16(4):765–774\nalthough generating more concise responses, proves sur -\nprisingly adept at iterative improvement when prompted \nto address inaccuracies, surpassing DeepSeek-V3 in this \ndomain. These results indicate that a model’s capacity for \ncomprehensive and guideline-driven responses is not solely \ndictated by response length or parameter count; rather, \nthoughtful design elements—such as feedback integration \nlayers and domain-specific fine-tuning—can be decisive. \nAlthough such tools hold considerable promise for enhanc-\ning clinical workflows and patient education, expert over -\nsight remains essential to correct nuanced errors and ensure \nalignment with rapidly evolving best practices. Future \nresearch should emphasize ongoing refinement, broader \nvalidation across diverse clinical settings, and cautious \nimplementation to safeguard the standard of urological care.\nSupplementary Information  The online version contains \nsupplementary material available at  h t t p  s : /  / d o i  . o  r g /  1 0 . 1  0 0 7  / s 0  0 3 4 5 - 0 \n2 5 - 0 5 7 5 7 - 4.\nAcknowledgements We appreciate the efforts of the editors and \nreviewers in evaluating this paper.\nAuthor contributions Conceptualization: Zijun Yan, Ke-qin Fan, Qi \nZhang, Xinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, Ning Su, Yan \nZou, Hao Chi, Liangjing Xia, Qiang CaoMethodology: Zijun Yan, Ke-\nqin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, \nNing Su, Yan Zou, Hao Chi, Liangjing Xia, Qiang CaoValidation: Zi-\njun Yan, Ke-qin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, Xinyu Wu, \nTing Yu, Ning Su, Yan Zou, Hao Chi, Liangjing Xia, Qiang CaoFormal \nanalysis: Zijun Yan, Ke-qin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, \nXinyu Wu, Ting Yu, Ning Su, Yan Zou, Hao Chi, Liangjing Xia, Qiang \nCaoInvestigation: Zijun Yan, Ke-qin Fan, Qi Zhang, Xinyan Wu, \nYuquan Chen, Xinyu Wu, Ting Yu, Ning Su, Yan Zou, Hao Chi, Li -\nangjing Xia, Qiang CaoResources: Zijun Yan, Ke-qin Fan, Qi Zhang, \nXinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, Ning Su, Yan Zou, \nHao Chi, Liangjing Xia, Qiang CaoData Curation: Zijun Yan, Ke-qin \nFan, Qi Zhang, Xinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, Ning \nSu, Yan Zou, Hao Chi, Liangjing Xia, Qiang CaoWriting - Original \nDraft: Zijun Yan, Ke-qin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, \nXinyu Wu, Ting Yu, Ning Su, Yan Zou, Hao Chi, Liangjing Xia, Qiang \nCaoWriting - Review & Editing: Zijun Yan, Ke-qin Fan, Qi Zhang, \nXinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, Ning Su, Yan Zou, \nHao Chi, Liangjing Xia, Qiang CaoProject administration: Zijun Yan, \nKe-qin Fan, Qi Zhang, Xinyan Wu, Yuquan Chen, Xinyu Wu, Ting Yu, \nNing Su, Yan Zou, Hao Chi, Liangjing Xia, Qiang Cao.\nFunding Open access funding provided by Hong Kong Baptist Uni -\nversity Library. This work was supported by National Natural Science \nFoundation of China (No.42267063), The 2024 Healthcare Quality \n(Evidence-Based) Management Research Project of the National In -\nstitute of Hospital Administration, National Health Commission of \nthe People’s Republic of China (YLZLXZ24G039), Sichuan Provin -\ncial Administration of Traditional Chinese Medicine Research Project \n(2023MS057; 2023MS207),Yunnan Provincial Department of Science \nand Technology Joint Project of Local Universities (202001BA070001-\n041), Key project of popular science research of Chinese Pharmaceuti-\ncal Association (CMEI2024KPYJ(JZYY)00427).\nData availability  Data is provided within the manuscript or supple -\nmentary information files.\n1 3\n  416  Page 8 of 10\nWorld Journal of Urology          (2025) 43:416 \nof an ophthalmology large language model. J Med Internet Res \n26:e60063\n31. Zong H, Wu R, Cha J et al (2024) Large language models in \nworldwide medical exams: platform development and compre -\nhensive analysis. J Med Internet Res 26:e66114\n32. Howard A, Hope W, Gerada A (2023) ChatGPT and antimicrobial \nadvice: the end of the consulting infection doctor? Lancet Infect \nDis 23(4):405–406\n33. Shifai N, van Doorn R, Malvehy J et al (2024) Can ChatGPT \nvision diagnose melanoma? An exploratory diagnostic accuracy \nstudy. J Am Acad Dermatol 90(5):1057–1059\n34. Ngoc Nguyen O, Amin D, Bennett J et al (2025) GP or chatgpt? \nAbility of large language models(LLMs) to support general prac-\ntitioners when prescribing antibiotics. J Antimicrob Chemother \n80(5):1324–1330\n35. Dornbier R, Pahouja G, Branch J et al (2020) The new American \nurological association benign prostatic hyperplasia clinical guide-\nlines: 2019 update. Curr Urol Rep 21:1–10\n36. Cross JL, Choma MA, Onofrey JA (2024) Bias in medical AI: \nimplications for clinical decision-making. PLOS Digit Health \n3(11):e0000651\n37. Pahud de Mortanges A, Luo H, Shu SZ et al (2024) Orchestrating \nexplainable artificial intelligence for multimodal and longitudinal \ndata in medical imaging. NPJ Digit Med 7(1):195\n38. Aboy M, Minssen T, Vayena E (2024) Navigating the EU AI act: \nimplications for regulated digital medical products. Npj Digit \nMed 7(1):237\n39. U.S. Food and Drug Administration (2025) Artificial intelli -\ngence-enabled device software functions: lifecycle management \nand marketing submission recommendations: draft guidance for \nindustry and FDA staff [S/OL]. FDA, Silver Spring. Accessed 27 \nApril 2025.  h t t p  s : /  / w w w  . f  d a .  g o v /  m e d  i a /  1 8 4 8 5 6 / d o w n l o a d\n40. Jiang J, Zheng Z (2024) Medical information protection in inter -\nnet hospital apps in china: scale development and content analy -\nsis. JMIR mHealth uHealth 12(1):e55061\n41. World Health Organization (2021) Ethics and governance of arti-\nficial intelligence for health [M/OL]. WHO, Geneva. Accessed 27 \nApril 2025.  h t t p s :   /  / w w  w . w  h  o  . i  n  t / p u  b l  i c a  t i o   n  s /  i / i   t e m / 9 7 8 9 2 4 0 0 2 9 \n2 0 0\n42. Assel M, Sjoberg D, Elders A et al (2019) Guidelines for \nreporting of statistics for clinical research in urology. J Urol \n201(3):595–604\n43. Bryk DJ, Zhao LC (2016) Guideline of guidelines: a review of \nurological trauma guidelines. BJU Int 117(2):226–234\n44. Tzelves L, Türk C, Skolarikos A (2021) European association of \nurology urolithiasis guidelines: where are we going? Eur Urol \nFocus 7(1):34–38\n45. Jiang P, Xie L, Arada R et al (2021) Qualitative review of clinical \nguidelines for medical and surgical management of urolithiasis: \nconsensus and controversy 2020. J Urol 205(4):999–1008\n46. Salonia A, Bettocchi C, Boeri L et al (2021) European association \nof urology guidelines on sexual and reproductive health—2021 \nupdate: male sexual dysfunction. Eur Urol 80(3):333–357\n47. Rouprêt M, Seisen T, Birtle AJ et al (2023) European association \nof urology guidelines on upper urinary tract urothelial carcinoma: \n2023 update. Eur Urol 84(1):49–64\n48. Patrikidou A, Cazzaniga W, Berney D et al (2023) European asso-\nciation of urology guidelines on testicular cancer: 2023 update. \nEur Urol 84(3):289–301\n49. Ljungberg B, Albiges L, Abu-Ghanem Y et al (2022) European \nassociation of urology guidelines on renal cell carcinoma: the \n2022 update. Eur Urol 82(4):399–410\n50. Morey AF, Broghammer JA, Hollowell CMP et al (2021) \nUrotrauma guideline 2020: AUA guideline. J Urol 205(1):30–35\n11. Abbasi N, Hussain HK (2024) Integration of artificial intelligence \nand smart technology: AI-driven robotics in surgery: precision \nand efficiency. J Artif Intell Gen Sci (JAIGS) 5(1):381–390\n12. Haney CM, Kowalewski KF, Westhoff N et al (2023) Robot-\nassisted versus conventional laparoscopic radical prostatectomy: \na systematic review and meta-analysis of randomised controlled \ntrials. Eur Urol Focus 9(6):930–937\n13. Castellani D, Perpepaj L, Fuligni D et al (2024) Advancements \nin artificial intelligence for robotic-assisted radical prostatectomy \nin men suffering from prostate cancer: results from a scoping \nreview. Chin Clin Oncol 13(4):54–54\n14. Fan S, Hao H, Chen S et al (2023) Robot-assisted laparoscopic \nradical prostatectomy using the KangDuo surgical robot system \nvs the Da Vinci Si robotic system. J Endourol 37(5):568–574\n15. Eppler M, Ganjavi C, Ramacciotti LS et al (2024) Awareness and \nuse of ChatGPT and large language models: a prospective cross-\nsectional global survey in urology. Eur Urol 85(2):146–153\n16. Davis R, Eppler M, Ayo-Ajibola O et al (2023) Evaluating the \neffectiveness of artificial intelligence–powered large language \nmodels application in disseminating appropriate and readable \nhealth information in urology. J Urol 210(4):688–694\n17. Eppler MB, Ganjavi C, Knudsen JE et al (2023) Bridging the gap \nbetween urological research and patient understanding: the role \nof large Language models in automated generation of layperson’s \nsummaries. Urol Pract 10(5):436–443\n18. Pompili D, Richa Y , Collins P et al (2024) Using artificial intel-\nligence to generate medical literature for urology patients: a com-\nparison of three different large language models. World J Urol \n42(1):455\n19. Kollitsch L, Eredics K, Marszalek M et al (2024) How does arti -\nficial intelligence master urological board examinations? A com-\nparative analysis of different large language models’ accuracy \nand reliability in the 2022 in-service assessment of the European \nboard of urology. World J Urol 42(1):20\n20. Reis LO (2023) ChatGPT for medical applications and urological \nscience. Int Braz J Urol 49(5):652–656\n21. Alasker A, Alsalamah S, Alshathri N et al (2024) Performance \nof large language models (LLMs) in providing prostate cancer \ninformation. BMC Urol 24(1):177\n22. Liu A, Feng B, Xue B et al (2024) Deepseek-v3 technical report. \narXiv preprint arXiv:2412.19437\n23. Guo D, Yang D, Zhang H et al (2025) Deepseek-r1: incentivizing \nreasoning capability in Llms via reinforcement learning. ArXiv \nPreprint arXiv:2501.12948\n24. Pfister R, Jud H (2025) Understanding and benchmarking arti -\nficial intelligence: openAI’s o3 is not AGI. arXiv preprint \narXiv:2501.07458\n25. Garrison E (2024) Memory makes computation universal, \nremember? arXiv preprint arXiv:2412.17794\n26. Kung TH, Cheatham M, Medenilla A et al (2023) Performance of \nChatGPT on USMLE: potential for AI-assisted medical education \nusing large language models. PLoS Digit Health 2(2):e0000198\n27. Brügge E, Ricchizzi S, Arenbeck M et al (2024) Large language \nmodels improve clinical decision making of medical students \nthrough patient simulation and structured feedback: a random -\nized controlled trial. BMC Med Educ 24(1):1391\n28. Gilson A, Safranek CW, Huang T et al (2023) How does Chat -\nGPT perform on the united States medical licensing examina -\ntion (USMLE)? The implications of large language models for \nmedical education and knowledge assessment. JMIR Med Educ \n9(1):e45312\n29. Thirunavukarasu AJ, Ting DSJ, Elangovan K et al (2023) Large \nlanguage models in medicine. Nat Med 29(8):1930–1940\n30. Chen X, Zhao Z, Zhang W et al (2024) EyeGPT for patient \ninquiries and medical education: development and validation \n1 3\nPage 9 of 10   416 \nWorld Journal of Urology          (2025) 43:416 \nPublisher’s note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations.\nAuthors and Affiliations\nZijun Yan1,5 · Ke-qin Fan1 · Qi Zhang2 · Xinyan Wu3 · Yuquan Chen4 · Xinyu Wu1,5 · Ting Yu1 · Ning Su1 · Yan Zou1 · \nHao Chi1,6 · Liangjing Xia1,2 · Qiang Cao1,5,7\n \r Hao Chi\nchihao7511@gmail.com\n \r Liangjing Xia\n1332949857@qq.com\n \r Qiang Cao\n20060008@kust.edu.cn\n1 Department of Pharmacy, Panzhihua Central Hospital, \nPanzhihua 617067, Sichuan, China\n2 College of Chinese Medicine, Hong Kong Baptist University, \nHKG, Kowloon Tong, Hong Kong\n3 College of Veterinary Medicine, Sichuan Agricultural \nUniversity, Chengdu 610000, China\n4 School of Public Health and Preventive Medicine, Faculty of \nMedicine, Nursing & Health Sciences, Monash University, \nLevel 1, 553 St Kilda Road, Melbourne, VIC 3004, Australia\n5 School of Pharmaceutical Sciences, Yunnan Key Laboratory \nof Pharmacology for Natural Products, Kunming Medical \nUniversity, Kunming 650500, Yunnan, China\n6 School of Clinical Medicine, Southwest Medical University, \nLuzhou 402103, China\n7 Department of Earth Sciences, Kunming University of \nScience and Technology, Kunming 650093, China\n1 3\n  416  Page 10 of 10",
  "topic": "Guideline",
  "concepts": [
    {
      "name": "Guideline",
      "score": 0.6076418161392212
    },
    {
      "name": "Medicine",
      "score": 0.5795902609825134
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.48849189281463623
    },
    {
      "name": "Correctness",
      "score": 0.4167783558368683
    },
    {
      "name": "Artificial intelligence",
      "score": 0.388962060213089
    },
    {
      "name": "Medical physics",
      "score": 0.33418741822242737
    },
    {
      "name": "Computer science",
      "score": 0.2660260796546936
    },
    {
      "name": "Algorithm",
      "score": 0.17840614914894104
    },
    {
      "name": "Pathology",
      "score": 0.1289653480052948
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I26080491",
      "name": "Kunming Medical University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210139405",
      "name": "Panzhihua Central Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I141568987",
      "name": "Hong Kong Baptist University",
      "country": "HK"
    },
    {
      "id": "https://openalex.org/I37574244",
      "name": "Sichuan Agricultural University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I56590836",
      "name": "Monash University",
      "country": "AU"
    },
    {
      "id": "https://openalex.org/I3017480383",
      "name": "Southwest Medical University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I10660446",
      "name": "Kunming University of Science and Technology",
      "country": "CN"
    }
  ]
}