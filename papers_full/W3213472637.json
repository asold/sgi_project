{
  "title": "Generative Pre-Trained Transformer for Design Concept Generation: An Exploration",
  "url": "https://openalex.org/W3213472637",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2095866250",
      "name": "Q. Zhu",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    },
    {
      "id": "https://openalex.org/A2098911996",
      "name": "J. Luo",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    },
    {
      "id": "https://openalex.org/A2095866250",
      "name": "Q. Zhu",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    },
    {
      "id": "https://openalex.org/A2098911996",
      "name": "J. Luo",
      "affiliations": [
        "Singapore University of Technology and Design"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6745087761",
    "https://openalex.org/W2961923021",
    "https://openalex.org/W2108924389",
    "https://openalex.org/W1815076433",
    "https://openalex.org/W3130890978",
    "https://openalex.org/W2014656672",
    "https://openalex.org/W6898505805",
    "https://openalex.org/W4239464499",
    "https://openalex.org/W2911893601",
    "https://openalex.org/W2100495367",
    "https://openalex.org/W1997079748",
    "https://openalex.org/W6796608850",
    "https://openalex.org/W6690846393",
    "https://openalex.org/W2988774027",
    "https://openalex.org/W2802313088",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W1946582949",
    "https://openalex.org/W6703448945",
    "https://openalex.org/W2966501066",
    "https://openalex.org/W6730740904",
    "https://openalex.org/W3011193154",
    "https://openalex.org/W6903575470",
    "https://openalex.org/W2412652493",
    "https://openalex.org/W2084333023",
    "https://openalex.org/W2916055891",
    "https://openalex.org/W2009851935",
    "https://openalex.org/W6778688570",
    "https://openalex.org/W6697296848",
    "https://openalex.org/W6673473585",
    "https://openalex.org/W6651815560",
    "https://openalex.org/W2962953307",
    "https://openalex.org/W6779141521",
    "https://openalex.org/W2091855346",
    "https://openalex.org/W1989056512",
    "https://openalex.org/W6691343179",
    "https://openalex.org/W2604799547",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3129603164",
    "https://openalex.org/W6696466220",
    "https://openalex.org/W6778867108",
    "https://openalex.org/W6770739798",
    "https://openalex.org/W2963668753",
    "https://openalex.org/W6791551222",
    "https://openalex.org/W3110623878",
    "https://openalex.org/W2026161499",
    "https://openalex.org/W6779539983",
    "https://openalex.org/W6635110145",
    "https://openalex.org/W2979567694",
    "https://openalex.org/W1489185854",
    "https://openalex.org/W2991001143",
    "https://openalex.org/W2006456734",
    "https://openalex.org/W2765664503",
    "https://openalex.org/W3034378854",
    "https://openalex.org/W3034785375",
    "https://openalex.org/W3105168176",
    "https://openalex.org/W3134661641",
    "https://openalex.org/W2787623698",
    "https://openalex.org/W3114913914",
    "https://openalex.org/W3168249318",
    "https://openalex.org/W3098903812",
    "https://openalex.org/W3041149780",
    "https://openalex.org/W2245231109",
    "https://openalex.org/W2297520409",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2560735687",
    "https://openalex.org/W3120769605",
    "https://openalex.org/W2053754901",
    "https://openalex.org/W3102854726",
    "https://openalex.org/W2091905911",
    "https://openalex.org/W2248571566",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3030772833",
    "https://openalex.org/W3034420245",
    "https://openalex.org/W3169554260",
    "https://openalex.org/W2291311632",
    "https://openalex.org/W2336706136",
    "https://openalex.org/W3206790237",
    "https://openalex.org/W3058517477",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2800068420"
  ],
  "abstract": "Abstract Novel concepts are essential for design innovation and can be generated with the aid of data stimuli and computers. However, current generative design algorithms focus on diagrammatic or spatial concepts that are either too abstract to understand or too detailed for early phase design exploration. This paper explores the uses of generative pre-trained transformers (GPT) for natural language design concept generation. Our experiments involve the use of GPT-2 and GPT-3 for different creative reasonings in design tasks. Both show reasonably good performance for verbal design concept generation.",
  "full_text": " \n \nARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN 1825 \nINTERNATIONAL DESIGN CONFERENCE – DESIGN 2022 \nhttps://doi.org/10.1017/pds.2022.185 \nGenerative Pre-Trained Transformer for Design Concept \nGeneration: An Exploration\nQ. Zhu  and J. Luo \nSingapore University of Technology and Design, Singapore \n qihao_zhu@mymail.sutd.edu.sg \n \nAbstract \nNovel concepts are essential for design innovation and can be generated with the aid of data stimuli and \ncomputers. However, current generative design algorithms focus on diagrammatic or spatial concepts that are \neither too abstract to understand or too detailed for early phase design exploration. This paper explores the \nuses of generative pre -trained transformers (GPT) for natural language design c oncept generation. Our \nexperiments involve the use of GPT-2 and GPT-3 for different creative reasonings in design tasks. Both show \nreasonably good performance for verbal design concept generation. \nKeywords: early design phase, idea generation, generative design, natural language generation, \ngenerative pre-trained transformer \n1. Introduction \nDesign innovation is heavily dependent on high-quality and novel concepts. Concept design activities \nare divided into two stages: divergence and convergence ( Tschimmel, 2012). Designers must generate \na wide range of concepts during the divergence stage before any assessmen t and selection for \nconvergence to be made. Therefore, much research has been conducted to develop methodologies and \ntools to aid designers to create design concepts, often with the aid of data and computers (Chakrabarti \net al., 2011; Han et al., 2018; Han et al., 2020). \nMeanwhile, little progress has been made regarding \" computer ideation\", i.e., computers directly and \nautomatically generating ideas, in contrast  to computer-aided ideation , i.e., computers aiding or \nstimulating human designers to generate ideas . In this study, we introduce a new technique from the \nfield of artificial intelligence  (AI)--the generative pre -trained transformer (GPT) --for automated \ngeneration of verbal design concepts. GPTs are language models pre-trained on vast quantities of textual \ndata and can perform a wide range of language-related tasks (Radford et al., 2019; Brown et al., 2020). \nOur work experiments the applicability of different GPT models for both problem-driven reasoning and \nanalogy-driven reasoning for design, with customized datasets. \n2. Literature Review \nRecent research  on design concept generation  can be categorized based on three dimensions: the role \nof method or tool, the form of concept representation, and the targeted design process  stage. \nA concept generation method or tool can play one of the three roles: as a guide,  as a stimulator , or \nas a generator. A method is considered as guide if it is instructively involved in the generation of \ndesign concept s, providing design rules or guidelines to the activities of the designers. For instance, \nBonnardel and Didier (2020) proposed two variants of brainstorming, encouraging designers to focus \non the evocation of both the design ideas and the constraints related to the design problem. A \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \n1826  ARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN \nstimulator provides inspiration al stimuli  to provoke designers to conceive new concepts. \nGoldschmidt and Smolkov (2006)  discussed how visual stimuli affect problem solving  design \nperformance.  Jin and Dong (2020)  extracted 10 design heuristics as stimul i from RedDot award -\nwining design concepts to help digital designer s overcome design fixation . He et al. (2019) tested the \nuse of word clouds as stimulators to inspire ideation.  Meanwhile, some methods can be a guide and \na simulator at the same time. Luo et al. (2019) introduced a computer-aided ideation  tool InnoGPS to \nguide the provision of design stimuli from the patent database by their knowledge distance to the \ndesign problem  or interest . Fargnoli et al . (2006) introduced the morphological matrix to guide \ndesigners to navigate and combine alternative solutions to each of multiple functions of a product to \ngenerate a variety of designs . \nA concept generator represents a fully automated computational agent that create s new concepts for \nthe interest of designers. One example is function -based design synthesis ( Chakrabarti et al., 2011). \nSangelkar and McAdams (2017) introduced graph grammar to generate the function structures of the \ndesign concepts with potential for computational design synthesis. Kang and Tucker (2015) proposed \na concept generation method based on function -form synthe sis. Other generators perform topology \noptimization and generative visual design ( Vlah et al., 2020). Oh et al. (2019)  and Nie et al. (2021)  \nintegrate topology optimization and generative adversarial network (GAN) to generate concepts for \nboth aesthetic and engineering performance. Ren et al. (2013), Burnap et al. (2016), and Dogan et al. \n(2019) use generative models to create new concepts of vehicle form design.  \nDuring design activities, concepts can be represented in the forms of abstract  diagram, verbal  text, \nor spatial visualization . Guiding or stimul ation-based methods  can direct designers to  generate \nconcepts in  either of the three  forms, e.g.,  simple sketches ( Shah et al., 2001 ; Goldschmidt and \nSmolkov, 2006), mind-mapping graph  (Shih et al ., 2009 ; Yagita et al., 2011 ), functional diagram \n(Stone et al., 2000 ), or textual description  (He et al., 2019 ; Sarica et al ., 2021 ). Some guides or \nstimulators may also lead to multiple forms of concept representation as designers may record their \nperception of ideas in different ways ( Bonnardel and Didier, 2020; Ilevbare, et al., 2013; Yilmaz et al., \n2016). On the other hand, for automated tools, the type of concept s to be generated is pre-determined \nwhen designing the system, e.g., the graph  grammar-based tool s represent new concepts in abstract \ngraphs (Campbell, 2009 ; Sangelkar and McAdams, 2017 ), while the topology optimization tools \ngenerate spatially visualized concepts in the form of 2D images ( Oh et al., 2019) or 3D models ( Nie \net al., 2021). \nThe forms of generated concepts need to fit with  design process  stages. Pahl et al. (2007) specified \nfour stages in design processes , including planning and task clarification, conceptual design, \nembodiment design, and detail design. For designers, visual stimulators like mood boards ( Ahmed \nand Boelskifte, 2006 ) and spatial  concept generator s (Oh et al., 2019 ; Nie et al., 2021 ) are mainly \nuseful for embodiment and detail design stages and may cause design fixation if applied in earlier \nstages (Viswanathan et al., 2016). Diagrammatic  concepts are represented in a more abstract way that \neither visualize s the mind map of a design concept ( Shih et al ., 2009; Yagita et al ., 2011) or the \nrelationship between components of function or structure ( Stone et al., 2000; Campbell, 2009 ). They \nare more suitable for the planning and task clarification as well as conceptual design stages. \nMeanwhile, text is also a common modality of recording concepts for early design stages. In typical \nbrainstorming sessions, designers exchange preliminary design ideas verbally and frequently. Chiu \nand Shu (2007)  investigated how semantic stimuli presented as words affect concept generation . \nSarica et al. (2021) retrieved the terms from a pre-trained technology semantic network as stimuli to \ngenerate new concepts in the form of text . Goucher-Lambert & Cagan (2019)  and Camburn et al . \n(2020) collected design ideas written in short text from crowdsourcing  campaigns. To date, however, \nthere exist  no automated tool that is built to generate verbal design concepts. \nTo summarize, we present a taxonomy of  concept generation methods or tools in Figure 1  by their \nroles, concept representation forms and suitable design stages . In this research, we focus on verbal \ngenerator using the latest natural language generation (NLG)  technology. Particularly, we \nexperiment the generative pre -trained transformer s from OpenAI to learn design knowledge and \nreasoning from task-oriented datasets and then generate high fidelity design concept description s in \nnatural language.  \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \nARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN 1827 \n \nFigure 1. Taxonomy of concept generation methods or tools  \n3. Natural Language Generation (NLG) \nNatural language generation (NLG) is a computer program that generate s natural language as output \n(Gatt and Krahmer, 2018 ). Recent NLG techniques include machine trans lation (e.g., Kenny, 2019), \ntext summarization (e.g., Ozsoy et al., 2011), paraphrasing (e.g., Li et al., 2018), and so on.  \n3.1. Transformer for NLG \nTransformer, first introduced by Vaswani et al (2017), is the state-of-the-art neural network architecture \nfor natural language processing (NLP) and is becoming the dominant for NLG ( Topal et al ., 2021). \nComparing to recurrent neural network (RNN) and long short-term memory (LSTM), which were the \nmost popular neural network architectures until recently, transformer overcomes the vanishing gradient \nproblem (Pascanu et al ., 2013 ) and enables parallel training. With the training data and model \narchitecture become larger in size, it can capture longer sequence features and therefore result in much \nmore comprehensive language understanding and generation (Brown et al., 2020).  \nAlthough transformer is a rather new technique in NLP and NLG, some applications have already been \nseen in different fields. Amin-Nejad et al. (2020) use transformer models to generate structured patient \ninformation to augment medical dataset . Fang (2021) use GPT to generate ideas for content creators . \nHowever, according to a recent review conducted by Regenwetter et al.  (2021), the application of \ntransformers is still a wide-open space for engineering design tasks. Our work fills this gap. \n3.2. Generative Pre-trained Transformer (GPT) \nGenerative pre-trained transformer (GPT)  stands for a series of pre -trained language models (PLM) \ndeveloped by OpenAI (Radford et al., 2019; Brown et al., 2020), which has been the most popular type \nof transformers in NLG tasks. PLMs are language models that have been trained with a large dataset of \ntextual information and can be applied to deal with specific language-related tasks (Arslan, et al. 2021). \nFor example, BERT was trained with Wiki and books data that contains over 3.3 billion tokens (Kenton \n& Toutanova, 2019 ), and is popular in natural language understanding tasks, e.g., text classification. \nHowever, BERT as a masked language model can only learn contextual representation of words but not \norganize and generate language ( Duan, et al., 2020 ), which makes it unsuitable for design concept \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \n1828  ARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN \ngeneration task. On the other hand, GPTs are autoregressive language models that are trained to predict \nthe next token based on all tokens before it. \nGPT-2 uses the two -step training strategy of pre -training and fine -tuning, following Hinton and \nSalakhutdinov (2006). The workflow is shown in Figure 2(a). During the pre-training step, the model is \ntrained on a text dataset collected from millions of webpages (Radford et al, 2019). For downstream NLP \ntasks, the pre-trained model needs to be fine-tuned given a customized and task-oriented dataset. The fine-\ntuned model is trained through repeated gradient updates using a large dataset of corpus of the example \ntask. This process updates the weights of the pre-trained model and stores them for the use of the target \ntask. However, the large dataset suitable for the target NLP task may be unavailable or difficult to collect. \nGPT-3 is the largest language model so far. It is trained on a mixture of datasets containing 400 billion \ntokens and has a maximum of 175 billion parameters. Comparing to its precursor, GPT-3 is capable of \nfew-show learning (Brown et al., 2020), in which the model learns from multiple examples of the NLP \nor NLG task called prompts. In this process, no gradient updates are performed ( Brown et al., 2020). \nThe training process of GPT-3 is shown in Figure 2 (b). \n \nFigure 2. Training and re-training process of GPT-2 (a) and GPT-3 (b) \n4. Research Method \nIn this paper, we experiment the application s of different GPT models in different design concept \ngeneration tasks. By customizing the fine-tunning dataset or examples for few-shot learning, GPT can \nlearn and generate concepts based on different reasonings in design. Figure 3 depicts the general \nframework of our experiments. First, knowledge for the task is the key component of our framework. It \nis provided through the dataset used for fine-tuning GPT-2 model, or in the examples of design concepts \nfor few-shot learning of GPT-3. Secondly, we take in varied input as for conditional learning. The input \nshould be customized and consistent with the specific reasoning we want the model to learn, and output \nwill be the generated design concept description. For instance, for analogy reasoning, the input will be \nthe source and target domains for analogy mapping. Finally, the transformer in the framework can be \neither a fine-tuned GPT-2 or the pre-trained GPT-3 for few-shot learning. \n \nFigure 3. Experimental framework \nTable 1 summarizes the settings for two experiments, in which we explore the capability of GPT for \ngenerating concepts by problem -driven reasoning and analogy-driven reasoning. The data we use for \nknowledge acquirement in both experiments is from the repository of RedDot award-wining designs. \nThe first experiment includes three phrases for implementation: preparing the data for the NLG task, \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \nARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN 1829 \nfine-tuning the model with the provided dataset, and testing the performance. The fine-tuning phrase is \nnot included for the second experiment because we will be employing GPT-3 few-shot learning. \nTable 1. Experiment settings \nExperiment Knowledge for the task Input Transformer \nProblem-driven \nreasoning \nRedDot award-winning design Problem statement, \nconcept category \nFine-tuned \nGPT-2 \nAnalogy-driven \nreasoning \nExamples of design-by-analogy concepts \nfrom RedDot award-winning design \nTarget and source domains GPT-3 few-shot \nlearning \n5. Experiments \n5.1. Problem-Driven Reasoning \nGiven GPT-2's capability to generate text based on understanding the context v ia training and fine -\ntuning, we experiment its application to generating text of solution ideas for a given problem. Problem-\nsolving in design could be supported by different methods such as analogy and first principle. In this \nexperiment we do not constrain GPT-2's problem-solving approach. The dataset for model fine-tuning \nis collected from RedDot's official website (https://www.red-dot.org/), including 14,502 product designs \nfrom 2011 to 2020 and 1,486 design concepts from 2016 to 2020. Data preparation includes picking out \nthe text description of each design and add ing its category name before the description. An example  \ndescription of a problem-driven design in the RedDot dataset is shown below:  \n“One of the biggest and most common concerns of using public toilets is avoiding \ndermatosis and bacterial infection that comes from sharing a toilet with others. Clean \nSeat has a toilet lid that automatically opens when the first sensor (located at the front \nof the toilet lid) detects a user approaching. A second sensor then detects the person \nleaving after using the toilet, prompting the toilet lid to close and lock itself. When the \nlid is locked, the system kickstarts the self-cleaning function of the toilet.\" \nAs shown i n the example, the problem is stated in the first sentence, followed by the solution idea \ndescription. This structure is common in the descriptions of problem-driven design and ideal for GPT \nto generate solution idea text as the output in response to a problem text as the input. However, not all \naward-winning designs are problem -driven and often t he description does not begin with a problem \ndescription. Our hypothesis is that the model can learn from those problem-driven design descriptions \n(as the example above) in the total dataset to execute problem-solving tasks, while also learning from \ndesign descriptions of other structures during training. A pre-trained GPT-2 of 355M parameters is fine-\ntuned for 14,000 steps with batch size of 1. Figure 4 reports loss over the fine-tuning steps. \n \nFigure 4. Loss with training steps when fine-tuning with RedDot data  \nIn the generation phrase, t he problem statement and the design domain category are both set as input. \nThe problem statement can be a single sentence written by the designer, and the category input can \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \n1830  ARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN \nbe selected from the categories listed on RedDot official website. Table 2 reports two solutions \ngenerated for each of the two design problems  in two experiments (parameters: temperature = 0.85, \ntop-k = 40, and top -p = 1) . The first  problem statement is from in the example above and the other  \nis from an IF award-winning design  (https://ifworlddesignguide.com/entry/324944 -ema), in order to test \nthe model's capability to generate solution ideas to known versus unknown problems to the model. \nTable 2. Problem-driven reasoning experiment: inputs and generated concepts \nInputs Generated Concepts \nCategory: Personal \nHygiene \nProblem Statement: One \nof the biggest and most \ncommon concerns of using \npublic toilets is avoiding \ndermatosis and bacterial \ninfection that comes from \nsharing a toilet with others. \nThe concept of this redesign of the traditional single -roof toilet presents a new \nidea. Instead of storing the toilet and washing it under the seat, it keeps the air in \nand a circular filter on the surface of the toilet seat, thereby preventing dermatosis \nfrom spreading. The built-in water tank is placed at the front of the seat so that it \ndoes not interfere with the efficiency of the cleaning process. \nClean Seat has a toilet lid that automatically opens when the first one is defecated \nand closes automatically afterwards. In combination with a toilet lid with anti -\nperspiratory properties, the lid can be fitted over the first defecation und prevent \nthe spread of the bacteria. The design of the toi let lid is very simple and in \nharmony with the shape of the body. It has a built -in air -flow control that is \noperated via a single touch of the keypad. \nCategory: Life Science \nProblem Statement: \nCurrent electrocardiograph \ntesting involves a large \nnumber of wires, making \nthe process time-\nconsuming for doctors and \nstressful for children. \nAs a solution, the Electric Micro-Inspection Tool Show'em! is a wearable micro-\ntest device that alleviates the r epetitive testing procedure by simultaneously \nvisualising the heart function of an implanted externa-nation. The externa-nation \nis a tiny, flexible device made of medical -grade silicone that can be readily \nattached to the patient’s clothing. When an electr ic current is applied to the \ndevice, the externa-nation collects data, which are then translated into a formable \nelectronic document. The user is only required to turn the small switch to trigger \nthe testing procedure.  \nThe Light Guide is a remote controlled electrocardiograph that makes the process \nof testing electronic health records easier for both doctors and children. With a \nLight Guide, children can fully concentrate on examining themselves and their \nmedical condition, which makes the testing of ele ctronic health records more \nstress-free. The controller is small and remote -controlled so that it can be easily \ntaken along to be tested at home. The information stored in the Light Guide is \nsaved with the child's medical records and is reviewed at a later time. This allows \ndoctors and families to have their medical records reviewed at a glance.  \n \nFor the known problem with a known solution, GPT-2 can generate many new solution ideas based on \nthe massive knowledge it has acquired from the training. For the unknown problem, it is also capable of \ncomprehending the problem and generating solution ideas. However, as the text lengthens, it is likely to \nstart talking about other features of the design that are unrelated to the given problem. This is not \nsurprising as the design descriptions in the fine-tuning dataset often provide comprehensive elaboration \nof multiple aspects and the model learnt this well. \n5.2. Analogy-Driven Reasoning \nDesign-by-analogy is the projection of existing reference in a source domai n to address a comparable \nchallenge in the target domain (Gentner, 1983; Luo et al., 2021). It is usually considered as a problem-\nsolving approach. However, when a problem is not specified, analogy reasoning can also lead to open-\nended design concept generation. This experiment is to test the analogy-driven reasoning of the model \nfor concept generation, particularly for the context when a designer aims to draw analogy from a given \nsource domain to generating design concepts in a given target domain but has not established clear \nanalogy mapping across domains to generate specific new concepts. \nAs there are insufficient design -by-analogy examples to fine -tune a GPT -2, this experiment  employs \nfive analogy-driven reasoning examples selected from RedDot dataset as prompts for GPT-3's few-shot \nlearning. Table 3 shows the source and target domains in each of the five examples for learning. Before \neach example is inputted , a structured sentence specifying the source and target domains (e.g., \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \nARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN 1831 \n“Applying accordion to computer mouse”) is inserted so that the GPT -3 may learn to develop ideas \nbased on the input domains. When generating new concepts, we simply need to update the tokens that \nspecify the source and target domains in the input sentence. \nTable 3. Analogy-driven reasoning examples used as prompts for GPT-3 \nSource Domain Target Domain Link of the example \nAccordion Computer Mouse https://www.red-dot.org/project/ambi-48504 \nCells Building https://www.red-dot.org/project/build-fender-27044 \nStanding desk Automobile https://www.red-dot.org/project/sole-26525  \nFolding chair Wheelchair https://www.red-dot.org/project/fold-light-wheelchair-26521/  \nCircuit board Desk https://www.red-dot.org/project/cabletread-46563  \n \nTable 4 reports two drone design concepts generated by GPT -3, by drawing analogy from the given \nsource domains of lantern and origami in two experiments (parameters: temperature = 0.85, top-p = 1, \npresence_penalty=0.5, frequency_penalty=0 .5). The model successfully understands both source \ndomains and applies the lighting feature of the lantern and the folding mechanism of origami to drone \ndesign. Without being trained with a large amount of analogical design cases, the generated concepts do \nadhere to analog ical reasoning and learn to build a clear analogical mapping between the source and \ntarget domains , even when the two given source domains are culture-related and distant from the \ntechnical domain of drone . This is because the G PT-3 is pre -trained on a massive text dataset that \nincludes nearly all possible kinds of scenarios and knowledges  and a few examples as prompts are \nenough for the specific 'memory' to be evoked. \nFurthermore, consistent to the pervious experiment, we also tested for the model's performance with the \ninput of the same prompt sentences as in the given examples. It turns out GPT-3 is more likely to repeat \nthe ideas given in the examples given low frequency penalty and presence penalty parameters , but it \nbegins to generate novel texts as these parameters are set to  higher values. This reveals another \ndifference between the mechanisms of GPT-2 and GPT-3 models when being applied to design concept \ngeneration tasks, which will need further investigation. \nTable 4. Analogy-driven reasoning experiment: inputs and generated concepts \nInput Output \nSource  Target  Generated Concepts \nLantern  Drone  Focused on the design of portable drone landing pads, Skylight is conceived as a \nportable lantern that allows operators to track flying drones for charging or repair. \nDeveloped into different designs that can fit with any situation, Skylight has two main \nforms: docking stations that are focused on portability and public space; and lamp-like \nstructures for open areas. \nD-LIGHT is a decorative drone that is fitted with a lantern inspired by the Chinese \n‘paper lantern’. The drone’s movements control the position and movement of the \nlantern, which is mounted at its centre. The functional design of D-LIGHT focuses on \nresponsive mechanisms for flying and controlling the lantern. This also enables it to be \noperated wherever necessary. \nOrigami Drone Aerobowl is inspired by the art of origami. The drone folds like an aerial paper aircraft \nand is able to fold itself up after landing. It can be launched without any human \nintervention, for example into lakes or rivers to help with rescue operations; it then \nfolds its propellers into lightweight aircraft mode before floating along on the surface \nof the water like a boat. \nFor centuries, paper folding has evolved into various different forms of art. Inspired \nby this, PaperDrone  is an origami -inspired drone that is designed to have its chassis \nstructure be deformable. The main goal of the design is to minimize the folding part \nwhile maintaining its strength and rigidity, mainly focusing on the legs for this feature. \nThere are three feathered blades attached to each leg that can rotate in both directions \nat certain angles. The foldable body allows it to be very compact when folded, thus \nmaking easy storage possible. \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \n1832  ARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN \n6. Discussion and Future Works \nThis article has examined the uses of generative pre-trained transformers to generate design concepts. \nIt is demonstrated that by customizing the training data or examples, GPT can perform conceptual design \ntasks with a reasonable level of competence. This work opens the p ath to verbal concept generation \nusing NLG, which may possibly be integrated with other approaches for a broader variety of applications \nand a higher level of automation. For example, the  analogy-driven reasoning experiment necessitates \nsource domain data for concept generation and comparison. This may be supplemented with knowledge \ngraphs that provide domain knowledges with a given knowledge distance. In the current paper, we only \nprovided case studies of using GPT for problem-driven and analogy-driven concept generation, but there \nare more opportunities to be explored . For example, the concept generation can also be driven by \ntechnology domain, i.e., generating concepts that addressing novel needs of a given technology.  \nFurthermore, given suitable datasets, the generation of design concepts based on varied design heuristics \nwill be possible, such as TRIZ (Ilevbare, et al., 2013) or the 77 design heuristics (Yilmaz et al., 2016). \nDesigners have challenges to generate novel ideas in practice due to a lack of comprehensive knowledge \nfrom various fields and the difficulty of properly applying design thinking. GPT's concept generation \napproach can be useful since it can acquire both knowledge and log ic from a wide range of data and \ngenerate intelligible concepts for specific design tasks. Designers who use the tool may discover \nvaluable ideas that are beyond their knowledge base and encourage them to think out of the box. In this \nsense, we expect the method will be an extension of human ideation. Moreover, human-AI collaboration \nin design concept generation does not necessarily stop at applying what the algorithm may offer. \nDesigners can also draw further inspiration from the given concept and combine inspiration from other \nsources to make it more suitable, add more details and optimize it for their own project scenario. \nHowever, it should be highlighted that the computer-generated concepts we showcased above  were \nselected from a pool of low -quality results that may not be viable or context relevant. Thus, efficient \nconcept evaluation algorithm is required to filter the automatically generated design concepts. However, \ncommon NLG evaluation metrics such as BLEU (Papineni, et al., 2002) and WMD (Kusner, et al., 2015) \nare designed for assessing the model's capability of generating high-quality language and require ground \ntruth samples to measure the similarity or distance between texts. In design concept generation tasks, in \naddition to language quality , we aim to gauge the usefulness and novelty of any individual concept \nwhere ground truth benchmark is seldomly available. This makes existing NLG metrics unsuitable for \nconcept generation tasks and thus new quantitative evaluation approaches will be needed. Furthermore, \nextensive experiments to compare different models as well as human assessment should be employed \nto validate the performances of both the generator and evaluator. \nReferences \nAhmed, S. and Boelskifte, P. (2006), \"Investigations of Product Design Engineering Students Intentions and a \nUsers Perception of Product Character\", Proceedings of Nordesign, Reykjavik, Iceland, pp. 372-381, 2006. \nAmin-Nejad, A., Ive, J., & Velupillai, S. ( 2020), \" Exploring transformer text generation for medical dataset \naugmentation\". In Proceedings of the 12th Language Resources and Evaluation Conference (pp. 4699-4708). \nArslan, Y., Allix, K., Veiber, L., Lothritz, C., Bissyandé, T. F., Klein, J., & Goujon, A. (2021). \"A comparison of \npre-trained language models for multi-class text classification in the financial domain \". In Comp. Proc. Web \nConf. 2021 (260-268). https://doi.org/10.1145/3442442.3451375 \nBonnardel, N., & Didier, J. (2020), \"Brainstorming variants to favor creative design\". Applied Ergo., 83, 102987. \nhttps://doi.org/10.1016/j.apergo.2019.102987 \nBrown, T. B. , Mann, B., Ryder, N., Subbiah, M., Kaplan, J., et al . ( 2020), \"Language models are few -shot \nlearners\". Advances in Neural Information Processing Systems 33 (NeurIPS 2020). \nBurnap, A., Liu, Y., Pan, Y., Lee, H., Gonzalez, R., et al, P.Y. (2016), \"Estimating and exploring the product form \ndesign space using deep generative models\", in  IDETC-CIE, ASME , V02AT03A013. \nhttps://doi.org/10.1115/DETC2016-60091 \nCamburn, B., He, Y., Raviselvam, S., Luo, J. and Wood, K. ( 2020), \"Machine learning -based design concept \nevaluation\", Journal of Mechanical Design, 142(3), 031113. https://doi.org/10.1115/1.4045126 \nCampbell, M., (2009) “A Graph Grammar Methodology for Generative Systems” [Online] . Available: \nhttp://repositories.lib.utexas.edu/handle/2152/6258. [Accessed: 10 -11 -2021]. \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \nARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN 1833 \nChakrabarti, A., Shea, K., Stone, R., Cagan, J., Campbell, M., et al. (2011), \"Computer-based design synthesis \nresearch: an overview\", J. Comput. Inf. Sci. Eng., 11(2). https://doi.org/10.1115/1.3593409 \nChiu, I. and Shu, L. (2007) \"Understanding the use of language stimuli in concept generation\", in IDETC-CIE, \n161-172. https://doi.org/10.1115/DETC2007-35772 \nDogan, K.M., Suzuki, H., Gunpinar, E. and Kim, M.-S. (2019), \"A generative sampling system for profile designs \nwith shape constraints and user evaluation \", Computer-Aided Design , 111, 93-112. \nhttps://doi.org/10.1016/j.cad.2019.02.002 \nDuan, J., Zhao, H., Zhou, Q., Qiu, M., & Liu, M. (2020, November). \"A Study of Pre -trained Language Models \nin Natural Language Processing\". In 2020 IEEE International Conference on Smart Cloud (SmartCloud) (pp. \n116-121). https://doi.org/10.1109/SmartCloud49737.2020.00030 \nFang, J. (2021), An Application of Customized GPT -2 Text Generator for Modern Content Creators , [Master \nThesis], UCLA. \nFargnoli, M., Rovida, E. and Troisi, R. (2006), \"The morphological matrix: Tool for the development of innovative \ndesign solutions\", in 4th ICAD, 1-7. https://doi.org/10.1109/FIE.1998.736828 \nGatt, A. and Krahmer, E. ( 2018), \" Survey of the state of the art in natural language generation: Core tasks, \napplications and evaluation \", Journal of  Artificial Intelligence Research , 61, 65-170. \nhttps://doi.org/10.1613/jair.5477 \nGentner, D. (1983), \"Structure-mapping: A theoretical framework for analogy\", Cognitive science, 7(2), 155-170. \nhttps://doi.org/10.1016/S0364-0213(83)80009-3 \nGoldschmidt, G. and Smolkov, M. (2006), \"Variances in the impact of visual stimuli on design problem solving \nperformance\", Design studies, 27(5), 549-569. https://doi.org/10.1016/j.destud.2006.01.002 \nGoucher-Lambert, K. and Cagan, J. ( 2019) ' Crowdsourcing inspiration: Using crowd generated inspirational \nstimuli to support designer ideation', Design studies, 61, 1-29. https://doi.org/10.1016/j.destud.2019.01.001 \nHan, J., Forbes, H., Shi, F., Hao, J. and Schaefer, D. ( 2020), \" A data -driven approach for creative concept \ngeneration and evaluation \", in Proceedings of the Design Society: DESIGN Conference , 167-176. \nhttps://doi.org/10.1017/dsd.2020.5 \nHan, J., Shi, F., Chen, L. and Childs, P.R. ( 2018), \" The Combinator –a computer -based tool for creative idea \ngeneration based on a simulation approach\", Design Science, 4. https://doi.org/10.1017/dsj.2018.7 \nHe, Y., Camburn, B., Liu, H., Luo, J., Yang, M., et al. (2019), \"Mining and representing the concept space of \nexisting ideas for directed ideation\", J. Mech. Des., 141(12). https://doi.org/10.1115/1.4044399 \nHinton, G.E. and Salakhutdinov, R.R. ( 2006), \" Reducing the dimensionality of data with neural \nnetworks\", Science, 313(5786), 504-507. https://doi.org/10.1126/science.1127647 \nHuang, Q., Gan, Z., Celikyilmaz, A., Wu, D., Wang, J. and He, X. (2019), \"Hierarchically structured reinforcement \nlearning for topically coherent visual story generation \", in Proceedings of the AAAI Conference on Artificial \nIntelligence, 8465-8472. https://doi.org/10.1609/aaai.v33i01.33018465 \nIlevbare, I.M., Probert, D. and Phaal, R. (2013), “A review of TRIZ, and its benefits and  challenges in practice”, \nTechnovation, Vol. 33 No. 2-3, pp. 30-37. https://doi.org/10.1016/j.technovation.2012.11.003 \nJin, X. and Dong, H. (2020), \"New design heuristics in the digital era \", in Proceedings of the Design Society: \nDESIGN Conference, 607-616. https://doi.org/10.1017/dsd.2020.321 \nKang, S.W. and Tucker, C.S. ( 2015), \"Automated concept generation based on function -form synthesis\", \nin  IDETC-CIE, ASME, V02AT03A008. https://doi.org/10.1115/DETC2015-47687 \nKenny, D. ( 2019), 'Machine translation' , In: Baker, M., & Saldanha, G. (Eds.),  Routledge Encyclopedia of \nTranslation Studies Routledge (3rd ed.), pp. 305-310. https://doi.org/10.4324/9781315678627 \nKenton, J. D. M. W. C., & Toutanova, L. K. (2019). \"BERT: Pre-training of Deep Bidirectional Transformers for \nLanguage Understanding\". In Proc. of NAACL-HLT (pp. 4171-4186). \nKusner, M., Sun, Y., Kolkin, N., & Weinberger, K. (2015, June). \"From word embeddings to document distances\". \nIn Int’l Conference on Machine Learning (pp. 957-966). PMLR. \nLi, Z., Jiang, X., Shang, L. and Li, H. ( 2018), \" Paraphrase Generation with Deep Reinforcement Learning \", \nin Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 3865-3878. \nLuo, J., Sarica, S. and Wood, K.L. (2019), \"Computer-aided design ideation using InnoGPS\", in  IDETC-CIE, \nASME, V02AT03A011. https://doi.org/10.1115/DETC2019-97587 \nLuo, J., Sarica, S. and Wood, K.L. ( 2021), \" Guiding data -driven design ideation by knowledge \ndistance\", Knowledge-Based Systems, 218, 106873. https://doi.org/10.1016/j.knosys.2021.106873 \nNie, Z., Lin, T., Jiang, H. and Kara, L.B. ( 2021), \" Topologygan: Topology optimization using generative \nadversarial networks based on physical fields over the initial domain \", J. Mech. Des ., 143(3), 031715. \nhttps://doi.org/10.1115/1.4049533 \nOh, S., Jung, Y., Kim, S., Lee, I. and Kang, N. ( 2019), \" Deep generative design: Integration of topology \noptimization and generative models\", J. Mech. Des., 141(11). https://doi.org/10.1115/1.4044229 \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press\n \n1834  ARTIFICIAL INTELLIGENCE AND DATA-DRIVEN DESIGN \nOzsoy, M.G., Alpaslan, F.N. and Cicekli, I. (2011), \"Text summarization using latent semantic analysis\", Journal \nof Information Science, 37(4), 405-417. https://doi.org/10.1177%2F0165551511408848 \nPahl, Beitz, W., Feldhusen, J., & Grote, K.-H. (2007), \"Engineering Design A Systematic Approach\" , Springer \nLondon. https://doi.org/10.1007/978-1-84628-319-2 \nPapineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002, July). \"Bleu: a method for automatic evaluation of machine \ntranslation\". In Proceedings of the 40th annual meeting of the Association for Computational Linguistics (pp. \n311-318). \nPascanu, R., Mikolov, T. and Bengio, Y. (2013), \"On the difficulty of training recurrent neural networks\", \nin International conference on machine learning, PMLR, 1310-1318. \nRadford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019), \"Language models are unsupervised \nmultitask learners\". OpenAI blog, 1(8), 9. \nRegenwetter, L., Nobari, A.H. and Ahmed, F. (2021), \"Deep Generative Models in Engineering Design: A \nReview\", arXiv preprint arXiv:2110.10863. \nRen, Y., Burnap, A. and Papalambros, P. (2013), \"Quantification of perceptual design attributes using a crowd\", \nin DS 75-6: Proceedings of the 19th International Conference on Engineering Design (ICED13) , Design for \nHarmonies, Vol. 6: Design Information and Knowledge, Seoul, Korea, 19-22.08. 2013. \nSangelkar, S. and McAdams, D.A. (2017), \"Automated Graph Grammar Generation for Engineering Design With \nFrequent Pattern Mining\", in  International Design Engineering Technical Conferences and Computers and \nInformation in Engineering Conference, ASME, V02AT03A006. https://doi.org/10.1115/DETC2017-67520 \nSarica, S., Song, B., Luo, J. and Wood, K.L. (2021), \"Idea generation with technology semantic network \", AI \nEDAM, 1-19. https://doi.org/10.1017/S0890060421000020 \nShah, J.J., Vargas‐Hernandez, N., Summers, J.D. and Kulkarni, S. (2001), \"Collaborative Sketching (C‐Sketch)—\nAn idea generation technique for engineering design \", The Journal of Creative Behavior , 35(3), 168-198. \nhttps://doi.org/10.1002/j.2162-6057.2001.tb01045.x \nShih, P.C., Nguyen, D.H., Hirano, S.H., Redmiles, D.F. and Hayes, G.R. (2009), \"GroupMind: supporting idea \ngeneration through a collaborative mind -mapping tool \", in Proceedings of the ACM  2009 international \nconference on Supporting group work, 139-148. https://doi.org/10.1145/1531674.1531696 \nStone, R.B., Wood, K.L. and Crawford, R.H. (2000), \"A heuristic method for identifying modules for product \narchitectures\", Design studies, 21(1), 5-31. https://doi.org/10.1016/S0142-694X(99)00003-4 \nTopal, M. O., Bas, A., & van Heerden, I. (2021), \"Exploring transformers in natural language generation: GPT, \nBERT, and XLNET\". International Conference on Interdisciplinary Applications of AI (ICIDAAI) \nTschimmel, K. ( 2012), \"Design Thinking as an effective Toolkit for Innovation\", in  ISPIM Conference \nProceedings, The International Society for Professional Innovation Management (ISPIM), 1. \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., et al. (2017), \"Attention is all you need\", in Advances \nin neural information processing systems, 5998-6008. \nViswanathan, V., Tomko, M. and Linsey, J. (2016), \"A study on the effects of example familiarity and modality \non design fixation\", AI EDAM, 30(2), 171-184. https://doi.org/10.1017/S0890060416000056 \nVlah, D., Žavbi, R. and Vukašinović, N. (2020), \"Evaluation of topology optimization and generative design tools \nas support for conceptual design \", in Proceedings of the Design Society: DESIGN Conference , 451-460. \nhttps://doi.org/10.1017/dsd.2020.165 \nYagita, H., Tose, A., Nakajima, M., Kim, S.K. and Maeno, T. (2011), \"A validation regarding effectiveness of \nscenario graph\", in IDETC-CIE, 385-394. https://doi.org/10.1115/DETC2011-48047 \nYilmaz, S., Daly, S.R., Seifert, C.M. and Gonzalez, R. ( 2016), \"Evidence-based design heuristics for idea \ngeneration\", Design studies, 46, 95-124. https://doi.org/10.1016/j.destud.2016.05.001 \nhttps://doi.org/10.1017/pds.2022.185 Published online by Cambridge University Press",
  "topic": "Generative grammar",
  "concepts": [
    {
      "name": "Generative grammar",
      "score": 0.858820378780365
    },
    {
      "name": "Generative Design",
      "score": 0.7716512680053711
    },
    {
      "name": "Transformer",
      "score": 0.746968686580658
    },
    {
      "name": "Computer science",
      "score": 0.635188639163971
    },
    {
      "name": "Diagrammatic reasoning",
      "score": 0.6216041445732117
    },
    {
      "name": "Focus (optics)",
      "score": 0.4945974051952362
    },
    {
      "name": "Human–computer interaction",
      "score": 0.402884840965271
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3768177330493927
    },
    {
      "name": "Engineering",
      "score": 0.2501685619354248
    },
    {
      "name": "Programming language",
      "score": 0.12770187854766846
    },
    {
      "name": "Electrical engineering",
      "score": 0.09413251280784607
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    },
    {
      "name": "Metric (unit)",
      "score": 0.0
    },
    {
      "name": "Operations management",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I152815399",
      "name": "Singapore University of Technology and Design",
      "country": "SG"
    }
  ]
}