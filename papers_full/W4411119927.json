{
    "title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
    "url": "https://openalex.org/W4411119927",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2530138888",
            "name": "Ruiyao Xu",
            "affiliations": [
                "Northwestern University"
            ]
        },
        {
            "id": "https://openalex.org/A2533475035",
            "name": "Kaize Ding",
            "affiliations": [
                "Northwestern University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2788633781",
        "https://openalex.org/W3040892440"
    ],
    "abstract": null,
    "full_text": "Findings of the Association for Computational Linguistics:\nNAACL 2025, pages 6007–6027\nApril 29 - May 4, 2025 ©2025 Association for Computational Linguistics\nLarge Language Models for Anomaly and Out-of-Distribution Detection:\nA Survey\nRuiyao Xu♠ and Kaize Ding♠\n♠Department of Statistics and Data Science, Northwestern University\nruiyaoxu2028@u.northwestern.edu, kaize.ding@northwestern.edu\nAbstract\nDetecting anomalies or out-of-distribution\n(OOD) samples is critical for maintaining the\nreliability and trustworthiness of machine learn-\ning systems. Recently, Large Language Mod-\nels (LLMs) have demonstrated their effective-\nness not only in natural language processing\nbut also in broader applications due to their\nadvanced comprehension and generative capa-\nbilities. The integration of LLMs into anomaly\nand OOD detection marks a significant shift\nfrom the traditional paradigm in the field. This\nsurvey focuses on the problem of anomaly and\nOOD detection under the context of LLMs. We\npropose a new taxonomy to categorize exist-\ning approaches into two classes based on the\nrole played by LLMs. Following our proposed\ntaxonomy, we further discuss the related work\nunder each of the categories and finally discuss\npotential challenges and directions for future\nresearch in this field. We also provide an up-to-\ndate reading list 1 of relevant papers.\n1 Introduction\nMost machine learning models operate under the\nclosed-set assumption (Krizhevsky et al., 2012),\nwhere the test data is assumed to be drawn i.i.d.\nfrom the same distribution as the training data.\nHowever, in real-world applications, this assump-\ntion often cannot hold, as test examples can come\nfrom distributions not represented in the training\ndata. These instances, known as anomalies or out-\nof-distribution (OOD) samples, can severely de-\ngrade the performance and reliability of existing\nmodels (Yang et al., 2024a). To build robust AI sys-\ntems, methods including probabilistic approaches\n(Lee et al., 2018; Leys et al., 2018) and recent deep\nlearning techniques (Pang et al., 2021; Yang et al.,\n2024a) have been explored to detect these unknown\ninstances across various domains, such as fraud de-\n1https://github.com/rux001/\nAwesome-LLM-Anomaly-OOD-Detection\n…\nData\n…\nDetectorsTimeSeriesTextsVideosImages\nBERTLLAMACLIPGPT-4V\nAnomalyDetection\nOODDetection\nID\n OOD\nNormalAbnormal\nFigure 1: A simple illustration of leveraging LLMs for\nvision anomaly and OOD detection.\ntection in finance and fault detection in industrial\nsystems (Hilal et al., 2022; Liu et al., 2024b).\nLarge Language Models, such as GPT-4\n(Achiam et al., 2023) and LLaMA (Touvron et al.,\n2023), have demonstrated remarkable capabilities\nin language comprehension and generation. To\nfurther harness the potential of LLMs beyond text\ndata, there is also a growing interest in extending\nthem to multi-modal tasks such as vision-language\nunderstanding and generation (Wang et al., 2024),\nevolving them into Multimodal LLMs (MLLMs)\n(Yin et al., 2023). Given the zero- and few-shot\nreasoning capabilities of LLMs and MLLMs, re-\nsearchers try to apply these models to anomaly and\nout-of-distribution (OOD) detection, as illustrated\nin Figure 1, yielding promising detection results.\nRemarkably, the emergence of LLMs has fun-\ndamentally changed the learning paradigm in this\nfield. In the meantime, while leveraging LLMs\nto solve the problem of anomaly and OOD detec-\ntion has drawn much attention, this field remains\nunderexplored, highlighting the need for a compre-\nhensive survey to analyze the emerging challenges\nand systematically review the rapidly expanding\nworks. Recently, Salehi et al. (2021) and Yang et al.\n(2024a) present unified frameworks for OOD detec-\ntion but do not delve into the utilization of LLMs.\nWhile Su et al. (2024) review some small-sized\n6007\nlanguage models for forecasting and anomaly de-\ntection, they neither cover the usage of LLMs with\nemergent abilities nor discuss OOD detection. A\nrecent survey by Miyai et al. (2024a) summarizes\nworks on anomaly and OOD detection in vision us-\ning vision-language models but neglects other data\nmodalities. Therefore, we aim to conduct a sys-\ntematic survey that covers both anomaly and OOD\ndetection across various data domains, concentrat-\ning on how LLMs are used in existing works.\nIn this survey, we propose a novel taxonomy\nthat focuses on how LLMs can profoundly impact\nanomaly and OOD detection in two fundamental\nways, as illustrated in Figure 2:❶ LLMs for Detec-\ntion (§3): We provide a detailed review of existing\nmethods that leverage LLMs as detectors for identi-\nfying anomalies and OOD instances; and ❷LLMs\nfor Generation ( §4): We also review methods\nthat utilize LLMs’ emergent abilities, advanced\nsemantic understanding, and vast knowledge to\ngenerate augmented data and explanations. At the\nend (§5 and §6), we also summarize widely used\ndatasets and outline future research directions, in\norder to provide a better understanding of anomaly\nand OOD detection in the era of LLMs and shed\nlight on the following research.\n2 Preliminaries\nLarge Language Models. Large language mod-\nels (LLMs) generally refer to Transformer-based\npre-trained language models with hundreds of bil-\nlions of parameters or more. Early LLMs like\nBERT (Devlin et al., 2018) and RoBERTa (Liu\net al., 2019) utilize an encoder-only architecture,\nexcelling in text representation learning (Bengio\net al., 2013). Recently, the focus has shifted toward\nmodels aimed at natural language generation, of-\nten using the “next token prediction” objective as\ntheir core task. Examples include T5 (Raffel et al.,\n2020) and BART (Lewis et al., 2019), which em-\nploy an encoder-decoder structure, as well as GPT-\n3 (Brown et al., 2020), PaLM (Chowdhery et al.,\n2023), and LLaMA (Touvron et al., 2023), which\nare based on decoder-only architectures. Advance-\nments in these architectures and training methods\nhave led to superior reasoning and emergent abili-\nties, such as in-context learning(Brown et al., 2020)\nand chain-of-thought reasoning (Wei et al., 2022).\nMultimodal Large Language Models. The re-\nmarkable abilities of Large Language Models\n(LLMs) have inspired efforts to integrate language\nwith other modalities, with a particular focus on\ncombining language and vision. Notable examples\nof Multimodal Large Language Models (MLLMs)\ninclude CLIP (Radford et al., 2021), BLIP2 (Li\net al., 2023a), and Flamingo (Alayrac et al., 2022),\nwhich were pre-trained on large-scale cross-modal\ndatasets comprising images and text. Models like\nGPT-4(V) (OpenAI, 2023) and Gemini (Team et al.,\n2023) showcase the emergent abilities of Multi-\nmodal LLMs, significantly improving the perfor-\nmance of vision-related tasks.\n2.1 Problem Definition\nWith LLMs advancing in zero-shot and few-shot\nlearning, the general pipeline of anomaly and out-\nof-distribution (OOD) detection methods shifts to\nadapt pre-trained LLMs for detection without ex-\ntensive training. This shift challenges traditional\ndefinitions of anomaly and OOD detection, as the\nconventional train-test paradigm may not always\napply. Following previous studies (Miyai et al.,\n2024a; Yang et al., 2024a), we propose to redefine\nanomaly and OOD detection under the context of\nLLMs and highlight the differences between the\ntwo problems as follows:\nDefinition 1 LLM-based Anomaly Detection:\nGiven a test dataset Dtest = {x1, ··· , xn}, where\neach sample xi is drawn from distribution Pin or\nPout. The objective of LLM-based Anomaly Detec-\ntion is to use a pre-trained LLM as the backbone\nand develop a detection model fLLM (·) to predict\nwhether each sample x′ ∈Dtest belongs to Pout,\nwhere Pout has covariate shift with Pin\nDefinition 2 LLM-based OOD Detection:Given\na test dataset Dtest = {x1, ··· , xn}, where each\nsample xi is drawn from distribution Pin or Pout,\nand a known ID class set C= {c1, ··· , ck}. The\nobjective of LLM-based OOD Detection is to use a\npre-trained LLM as backbone and develop detec-\ntion model fLLM(·) to predict whether each sample\nx′ ∈Dtest belongs to Pout, where Pout has semantic\nshift with Pin. If not, x′ will be classified into one\nof the classes in C.\nDiscussions. The distinction between anomaly de-\ntection and OOD detection in the context of LLMs\nhighlights the unique challenges posed by covari-\nate and semantic shifts. Anomaly detection aims to\nidentify subtle deviations within the data that may\nnot involve a complete change in the underlying\nclass or concept, such as detecting defects or irreg-\nularities in industrial processes. In contrast, OOD\n6008\nLLMs for Anomaly and OOD Detection\nLLMs forDetection\nPrompting\nw/o Tuning SIGLLM (Alnegheimish et al., 2024), LLMAD (Liu et al., 2024c), LogPrompt(Liu et al., 2024d), LA V AD (Zanella et al., 2024), LLM-Monitor (Elhafsi et al., 2023),GPT-4V-AD (Zhang et al., 2023), (Cao et al., 2023)\nw/ Tuning Tabular (Li et al., 2024a), Myriad (Li et al., 2023b), AnomalyGPT (Zhang et al., 2023)\nContrasting\nw/o Tuning\n(Fort et al., 2021), ZOC (Esmaeilpour et al., 2022), NegLabel (Jiang et al., 2024),CLIPScope (Fu et al., 2024), WinCLIP (Jeong et al., 2023),AnoCLIP (Deng et al., 2023), CLIP-AD (Chen et al., 2023b), MCM (Ming et al., 2022),(Miyai et al., 2023), SETAR (Li et al., 2024d)\nw/ Tuning\nLoCoOp (Miyai et al., 2024c) AnomalyCLIP (Zhou et al., 2024), InCTRL(Zhu and Pang, 2024), MVFA (Huang et al., 2024a), ID-like (Bai et al., 2024),NegPrompt (Li et al., 2024b), CLIPN (Wang et al., 2023),LSN (Nie et al., 2024), MCM-PEFT (Ming and Li, 2024)\nLLMs forGeneration\nAugmentation\nText Embedding LogGPT (Qi et al., 2023), LogFit (Almodovar et al., 2024),(Liu et al., 2024a), (Zhang et al., 2024a)\nPseudo Label EOE (Cao et al., 2024), PCC (Huang et al., 2024b),TOE (Park et al., 2023), CoNAL (Xu et al., 2023)\nTextual Description TagFog (Chen et al., 2024), ALFA (Zhu et al., 2024), (Dai et al., 2023)\nExplanation Holmes-V AD (Zhang et al., 2024b), AnomalyRuler (Yang et al., 2024c),V AD-LLaMA (Lv and Sun, 2024), AESOP (Sinha et al., 2024)\nFigure 2: Taxonomy of methods utilizing LLMs for anomaly and OOD detection tasks.\ndetection focuses on identifying instances that do\nnot belong to any of the known ID classes at the\nobject level, such as recognizing a dog when the\nonly provided ID class is cat. This differentiation\nunderscores the need for tailored approaches for\neach detection task.\n3 LLMs for Detection\nThe primary objective of this section is to explore\nexisting works that utilize LLMs’ inherent knowl-\nedge to detect anomalies or OOD samples. Un-\nder this line of research, approaches can be cat-\negorized into two classes as illustrated in Figure\n3: ❶ Prompting-based Detection methods, which\ninvolve directly prompting LLMs to generate lan-\nguage responses that include detection results; ❷\nContrasting-based Detection methods, which fo-\ncus on multimodal scenarios, using MLLMs pre-\ntrained with a contrastive objective as detectors.\n3.1 Prompting-based Detection\nThe general pipeline for prompting-based detection\nmethods consists of two primary stages: (i) con-\nstructing a structured prompt template with instruc-\ntion prompt Pand input dataX; and (ii) feeding the\ntemplate-based prompt ˆX into LLMs to generate a\nlanguage response. The function Parse(·) is then\napplied to extract the detection results. Depending\non the scenario, the LLM can either be frozen or\nfine-tuned, denoted as f♡\nLLM or f♣\nLLM , respectively.\nThis process can be summarized as follows:\nPrompt Construction: ˆX = Template(X, P),\nDetection: ˜Y = Parse\n(\nf♡/♣\nLLM ( ˆX)\n)\nNote that the prompting-based approach primarily\naddresses the anomaly detection task. OOD detec-\ntion research has not yet widely adopted prompting\nto directly identify OOD samples.\n3.1.1 Detection without LLM Tuning\nSince some approaches do not require additional\ntuning, they mainly focus on employing various\nprompt engineering techniques (Sahoo et al., 2024)\nto guide LLMs to produce better detection results.\nTo design suitable prompts for anomaly detection,\nresearchers have employed a combination of vari-\nous prompt techniques, such as role-play prompt-\ning (Wu et al., 2023), in-context learning (Brown\net al., 2020), and chain-of-thought (CoT) reasoning\n(Wei et al., 2022), to create effective prompt tem-\nplates. Studies such as SIGLLM (Alnegheimish\net al., 2024), LLMAD (Liu et al., 2024c), and\nLogPrompt (Liu et al., 2024d) focus on time se-\nries and log data. SIGLLM (Alnegheimish et al.,\n2024) investigates two distinct pipelines for using\nLLMs in time series anomaly detection: one di-\nrectly prompts an LLM with specific role-play in-\nstructions to identify anomalous elements in given\ndata, and the other uses the LLM’s forecasting abil-\nity to detect anomalies by comparing original and\nforecasted signals, where discrepancies indicate\n6009\nanomalies. LLMAD (Liu et al., 2024c) incorpo-\nrates in-context learning examples retrieved from\na constructed database and CoT prompts that in-\nject domain knowledge of time series. LogPrompt\n(Liu et al., 2024d) explores three prompting strate-\ngies for log data: self-prompt, CoT prompt, and\nin-context prompt, demonstrating that the prompt\nwith CoT techniques outperforms other prompting\nstrategies. The tailored CoT prompt for log data\nincludes a specific task instruction, i.e. “classify\nthe given log entries into normal and abnormal\ncategories”, and step-by-step rules for considering\ngiven data as anomalies.\nUnlike time series and log data which can be\ndirectly converted into raw text data, other data\nmodalities, such as videos and images, require ad-\nditional processing to be transformed into a format\nthat LLMs can understand. For instance, LA V AD\n(Zanella et al., 2024) first exploits a captioning\nmodel to generate a textual description for each\nvideo frame and further uses an LLM to summa-\nrize captions within a temporal window. This sum-\nmary is then used to prompt the LLM to provide\nan anomaly score for each frame. LLM-Monitor\n(Elhafsi et al., 2023) uses an object detector to iden-\ntify objects in video clips and then designs specific\nprompt templates incorporating CoT and in-context\nexamples to query LLMs for anomaly detection.\nWith the integration of multimodal understand-\ning into LLMs, these models are now capable of\ncomprehending various modalities beyond text, en-\nabling more direct applications for anomaly detec-\ntion across a wide range of data types. Cao et al.\n(2023) conduct comprehensive experiments and\nanalyses using GPT-4V(ision) for anomaly detec-\ntion across various modality datasets and tasks. To\nenhance GPT-4V’s performance, they also incor-\nporate different types of additional cues such as\nclass information, human expertise, and reference\nimages as prompts. Similarly, GPT-4V-AD (Zhang\net al., 2023) employs GPT-4V as the backbone, de-\nsigning a general prompt description for all image\ncategories and injecting specific image category\ninformation, resulting in a specific output format\nfor each region with respective anomaly scores.\n3.1.2 Detection with LLM Tuning\nDirectly prompting frozen LLMs for anomaly or\nOOD detection results across various data types\noften yields suboptimal performance due to the in-\nherent modality gap between text and other data\nmodalities. As a result, additional training and fine-\nData\nKnowledgePromptTemplate\nTaskDescriptionDomain\u0000KnowledgeCoTInstructionsInputData\n /LLM\nAnomalyDetected!Result\nc\nImageBirdDogCat…Car\nAPhotoofa{Label}TextPromptTextEncoder\nImageEncoder\nContrastingOOD/Anomaly!Result\n Adapter\n/\n(a)\n(b)\nFigure 3: The illustration of two approaches in (§3): (a)\nPrompting-based Detection and (b) Contrasting-based\nDetection.\ntuning on LLMs for downstream detection tasks\nhas become a prevalent research trend. Unfortu-\nnately, fine-tuning entire LLMs is often computa-\ntionally expensive and poses significant challenges.\nTherefore, parameter-efficient fine-tuning (PEFT)\nhas been extensively employed instead. For exam-\nple, Tabular (Li et al., 2024a) designs a prompt\ntemplate to query the LLM to output anomalies\nbased on given converted tabular data. To better\nadapt the LLM for anomaly detection at the batch\nlevel, they apply Low-Rank Adaptation (LoRA),\nusing a synthetic dataset with ground truth labels\nin a supervised manner.\nTo enhance LLMs for localization understand-\ning and adapting to industrial tasks, AnomalyGPT\n(Zhang et al., 2023) first derives localization fea-\ntures from a frozen image encoder and image de-\ncoder and these features are then fed to a tun-\nable prompt learner. Without fine-tuning the en-\ntire LLM, they fine-tune the prompt learner with\nLoRA to significantly reduce computational costs.\nMyriad (Li et al., 2023b) employs Mini-GPT-4 as\nthe backbone and integrates a trainable encoder,\nreferred to as Vision Expert Tokenizer, to embed\nthe vision expert’s segmentation output into tokens\nthat the LLM can understand. With expert-driven\nvisual-language extraction, Myriad can generate\naccurate anomaly detection descriptions.\n3.2 Contrasting-based Detection\nIn this section, we focus on MLLMs, such as\nCLIP, which are pre-trained with an image-text con-\ntrastive objective and learn by pulling the paired\nimages and texts close and pushing others far away\n6010\nin the embedding space. The zero-shot classifica-\ntion ability of these models further builds the foun-\ndation for contrasting-based anomaly and OOD\ndetection methods: (i) given an image xi and a text\nprompt f with a target class set C, CLIP extracts\nimage features h ∈RD using an image encoder\nfimg, and text features ej ∈RD using a text en-\ncoder ftext with a prompt template for each class\ncj ∈C, and (ii) the similarity between h and each\nej is usually used as an important component in\nthe score function fscore for deciding whether xi is\nan anomaly or OOD sample. This process can be\nsummarized as follows:\nFeature Extraction: h = fimg(xi),\nand e j = ftext(prompt(cj)),\nDetection: ˜Y = fscore (cos(h, ej))\nWe further categorize contrasting-based detection\nmethods into two classes depending on whether\nthere exists additional training and fine-tuning.\n3.2.1 Detection without LLM Tuning\nAnomaly and OOD detection problems can indeed\nbe understood as classification problems. There-\nfore, pretrained MLLMs like CLIP, with strong\nzero-shot classification ability, can serve as de-\ntectors themselves. By using only ID or normal\nprompts, CLIP can be leveraged for both OOD\nand anomaly detection tasks. Despite the promise,\nexisting CLIP-like models perform zero-shot clas-\nsification in a closed-world setting. That is, it will\nmatch an input into a fixed set of categories, even if\nit is irrelevant (Ming et al., 2022). To address this,\none approach involves designing effective post-hoc\nscore functions that rely solely on ID or normal\nclass labels. Alternatively, some researchers incor-\nporate anomaly or OOD class information into the\ntext prompts, allowing the model to match OOD or\nabnormal images to paired prompts.\n• Without Anomaly/OOD Prompts. For anomaly\ndetection, WinCLIP (Jeong et al., 2023) initially\ninvestigates a one-class design by using only the\nnormal prompt “normal [o]” where [o] repre-\nsents object-level label, i.e “bottle”, and defining\nan anomaly score as the similarity between vec-\ntors derived from the image encoder and normal\nprompts. However, this one-class design yields\npoorer results compared to a simple binary zero-\nshot framework, CLIP-AC (Jeong et al., 2023),\nwhich adapts CLIP with two class prompts: “nor-\nmal [o]” vs. “anomalous [o]”. These results high-\nlight that the one-class design is less effective\nfor anomaly detection, and as a result, anomaly\ndetection research generally does not follow this\nline with only normal prompts.\nFor OOD detection, to address the challenges of\nusing only in-distribution (ID) class information\nwhile avoiding the matching of OOD inputs to\nirrelevant ID classes, one notable approach is the\nMaximum Concept Matching (MCM) framework\nproposed by (Ming et al., 2022). This method is\nnot limited to CLIP and can be generally appli-\ncable to other pre-trained models that promote\nmulti-modal feature alignment. They view the\ntextual embeddings of ID classes as a collection\nof concept prototypes and define the maximum\nconcept matching (MCM) score based on the co-\nsine similarity between the image feature and the\ntextual feature. Following the idea of MCM, sev-\neral subsequent works focus on improving OOD\ndetection results by either adding a local MCM\nscore or modifying weights in the original MCM\nframework, such as (Miyai et al., 2023) and (Li\net al., 2024d).\n• With Anomaly/OOD Prompts. Fort et al. (2021)\nfirst investigate using CLIP for OOD detection\nand demonstrate encouraging performance. How-\never, in their setup, they include the candidate\nlabels related to the actual OOD classes and\nutilize this knowledge as a very weak form of\noutlier exposure, which contradicts the open-\nworld assumption. Therefore, after this work,\nresearchers aim to leverage pseudo-OOD labels\nin the text prompt instead of using actual OOD\nlabels. The earliest work under this idea is ZOC\n(Esmaeilpour et al., 2022) which trains a text\ndescription generator on top of CLIP’s image en-\ncoder to dynamically generate candidate unseen\nlabels for each test image. The similarity of the\ntest image with seen and generated unseen labels\nis used as the OOD score. Instead of training an\nadditional text decoder, NegLabel (Jiang et al.,\n2024) and CLIPScope (Fu et al., 2024) rely on\nauxiliary datasets to gather potential OOD la-\nbels. CLIPScope gathers nouns from open-world\nsources as potential OOD labels and uses them in\ndesigned prompts to ensure maximal coverage of\npotential OOD samples. NegLabel employs the\nNegMining algorithm to select high-quality neg-\native labels with sufficient semantic differences\nfrom ID labels. Recent work utilizes the emer-\ngent abilities of LLMs to generate reliable OOD\nlabels, such as (Cao et al., 2024), (Huang et al.,\n6011\n2024b), (Park et al., 2023), and (Xu et al., 2023).\nFor contrasting-based anomaly detection, fol-\nlowing the simple binary zero-shot framework,\nCLIP-AC (Jeong et al., 2023), which adapts CLIP\nwith two class prompts: “normal [o]” vs. “anoma-\nlous [o]”, many subsequent research emerge.\nWhile using the default prompt has demonstrated\npromising performance, similar to the prompt\nengineering discussion around GPT-3 (Brown\net al., 2020), researchers have observed that per-\nformance can be significantly improved by cus-\ntomizing the prompt text. Models like WinCLIP\n(Jeong et al., 2023) and AnoCLIP (Deng et al.,\n2023) use a Prompt Ensemble technique to gen-\nerate all combinations of pre-defined lists of state\nwords per label and text templates. After gen-\nerating all combinations of states and templates,\nthey compute the average of text embeddings\nper label to represent the normal and anomalous\nclasses. In practice, more descriptions in prompts\ndo not always yield better performance. There-\nfore, CLIP-AD (Chen et al., 2023b) proposes\nRepresentative Vector Selection (RVS), from a\ndistributional perspective for the design of the\ntext prompt, broadening research opportunities\nbeyond merely crafting adjectives.\n3.2.2 Detection with LLM Tuning\nFollowing the similar detection pipeline of meth-\nods without LLM tuning, researchers propose to\nemploy prompt tuning or adapter tuning techniques\nto eliminate the need for manually crafting prompts\nand enhance the understanding of local features of\nimages. Additionally, by incorporating a few ID or\nnormal images during training or inference phases,\nsome methods transition into few-shot scenarios.\n• LLM Adapter-Tuning. Adapter-tuning methods\ninvolve integrating additional components or lay-\ners into the model architecture to facilitate better\nalignment or localization (Hu et al., 2023). This\napproach is significantly useful for anomaly de-\ntection task, because CLIP was originally de-\nsigned for classifying the semantics of objects\nin the scene, which does not align well with the\nsensory anomaly detection task where both nor-\nmal and abnormal samples are often from the\nsame class of object. To reconcile this, InCTRL\n(Zhu and Pang, 2024) includes a tunable adapter\nlayer to further adapt the image representations\nfor anomaly detection. To better adapt to medical\nimage anomaly detection, MVFA (Huang et al.,\n2024a) proposes a multi-level visual feature adap-\ntation architecture to align CLIP’s features with\nthe requirements of anomaly detection in med-\nical contexts. This is achieved by integrating\nmultiple residual adapters into the pre-trained vi-\nsual encoder, guided by multi-level, pixel-wise\nvisual-language feature alignment loss functions.\n• LLM Prompt-Tuning. Manually crafting suitable\nprompts always requires extensive human effort.\nTherefore, researchers employ the idea of prompt\ntuning, such as CoOp (Zhou et al., 2022), to learn\na soft or differentiable context vector to replace\nthe fixed text prompt. For OOD detection, most\napproaches rely on using auxiliary prompts to\nrepresent potential OOD textual information, and\none crucial problem is to identify hard OOD data\nthat is similar to ID samples. To solve this, Bai\net al. (2024) first constructs outliers highly corre-\nlated with ID data and introduces a novel prompt\nlearning framework for learning specific prompts\nfor the most challenging OOD samples, which\nbehave like ID classes. Additionally, LSN (Nie\net al., 2024), NegPrompt (Li et al., 2024b), and\nCLIPN (Wang et al., 2023) all work on learn-\ning extra negative prompts to fully leverage the\ncapabilities of CLIP for OOD detection. Un-\nlike the other two approaches, CLIPN requires\ntraining an additional “no” text encoder using\na large external dataset to get negative prompts\nfor all classes. This auxiliary training is compu-\ntationally expensive, limiting its application to\ngeneralized tasks. Also, LSN demonstrates that\nnaive “no” logic prompts cannot fully leverage\nnegative features. Therefore, both LSN and Neg-\nPrompt focus on training on more detailed neg-\native prompts, while LSN also aims to develop\nclass-specific positive and negative prompts, en-\nabling more accurate detection.\nInstead of focusing on leveraging OOD informa-\ntion into the text encoder, some methods aim to\nperform prompt tuning to optimize word embed-\ndings for ID labels and then use the MCM score\nas the detection criterion. MCM-PEFT (Ming\nand Li, 2024) demonstrates that simply apply-\ning prompt tuning for CLIP on few-shot ID\ndatasets can significantly improve detection ac-\ncuracy. However, a primary limitation of this\napproach is its exclusive reliance on the features\nof ID classes, leading to incorrect detection when\ninput images share a high visual similarity with\nthe class in the prompt. To address this, LoCoOp\n6012\n(Miyai et al., 2024c) treats such ID-irrelevant\nnuisances as OOD and learns to push them away\nfrom the ID class text embeddings, preventing the\nmodel from producing high ID confidence scores\nfor the OOD features. Additionally, Lafon et al.\n(2024) enhances detection capabilities by learn-\ning a diverse set of prompts utilizing both global\nand local visual representations. For anomaly\ndetection which emphasizes more on learning\nlocal features, AnomalyCLIP (Zhou et al., 2024)\naims to learn object-agnostic text prompts that\ncapture generic normality and abnormality in im-\nages, allowing the model to focus on abnormal\nregions rather than object semantics.\n4 LLMs for Generation\nIn this section, we review methods that leverage\nLLMs as generative tools for enhancing anomaly\nand OOD detection. LLMs use their extensive\npre-trained knowledge to generate augmented data,\nsuch as embeddings, pseudo labels, and textual de-\nscriptions, improving detection performance (Li\net al., 2024c; Ding et al., 2024). Furthermore, due\nto their ability to understand and generate human-\nlike text, LLMs have been explored for provid-\ning insightful explanations and analyses of detec-\ntion results, aiding in interpretation, planning, and\ndecision-making. These methods are classified into\ntwo main approaches: ❶ Augmentation-centric\nGeneration and ❷ Explanation-centric Generation.\n4.1 Augmentation-centric Generation\nLLMs serve as effective tools for data augmenta-\ntion in anomaly and OOD detection tasks by gen-\nerating textual embeddings, pseudo labels, and de-\nscriptive text. The extensive pre-training of LLMs\non large datasets and the autoregressive training ob-\njective endow them with superior generative capa-\nbilities. These capabilities allow LLMs to produce\nhigh-quality embeddings, create synthetic labels,\nand provide additional descriptive information, ul-\ntimately boosting the performance and robustness\nof detection models.\n4.1.1 Text Embedding-based Augmentation\nLLMs are highly effective feature extractors, pro-\nducing meaningful embeddings that can be used\nin detection tasks. This augmentation enables de-\ntection models to capture more subtle patterns and\ndistinctions, leading to more accurate and robust\ndetection performance. For instance, Hadadi et al.\n(2024) and Qi et al. (2023) fine-tune pre-trained\nGPT models on log data and use the extracted se-\nmantic embeddings as key components for future\nanomaly detection.\nFor OOD detection in text data, a common ap-\nproach involves using encoder-only LLMs to gen-\nerate sentence representations that are used to com-\npute OOD confidence scores (Liu et al., 2024a).\nThese models are typically fine-tuned on ID data,\nand OOD detectors are applied to the generated\nrepresentations. Recently, there has been a shift\ntoward leveraging larger language models with de-\ncoder architectures, which provide enhanced capa-\nbilities in refining textual representations. Liu et al.\n(2024a) explore the use of decoder-only LLMs,\nsuch as LLaMa, incorporating fine-tuning tech-\nniques like LoRA to reduce the additional param-\neters. Their findings demonstrate that fine-tuned\nLLMs, combined with customized OOD scoring\nfunctions, significantly improve OOD detection\nperformance. A key advantage of decoder-based\nLLMs is their autoregressive ability, which al-\nlows for more effective handling of sequential data.\nBuilding on this, Zhang et al. (2024a) propose us-\ning the likelihood ratio between a pre-trained and\nfine-tuned LLM as a criterion for OOD detection,\nleveraging the deep contextual understanding em-\nbedded within LLMs for text data.\n4.1.2 Pseudo Label-based Augmentation\nThe emergent capabilities of LLMs provide a\npromising approach for generating high-quality\nsynthetic datasets, including pseudo labels for\nOOD samples. A significant challenge in OOD\ndetection is the lack of labeled OOD data, which\ncan limit model performance. Traditionally, obtain-\ning OOD labels requires extensive human effort,\nbut LLMs can mitigate this by generating pseudo-\nOOD labels through carefully designed prompts.\nFor example, EOE (Cao et al., 2024) and PCC\n(Huang et al., 2024b) prompt LLMs to generate\nvisually similar OOD class labels, which are then\nused to define a new scoring function. This ap-\nproach significantly outperforms methods relying\nsolely on known ID labels. TOE (Park et al.,\n2023) further evaluates the generation of pseudo-\nOOD labels at three verbosity levels—word-level,\ndescription-level, and caption-level—using BERT,\nGPT-3, and BLIP-2, respectively. Results indicate\nthat caption-level pseudo-OOD labels generated\nby BLIP-2, which incorporates both semantic and\nvisual understanding, perform the best. In text\ndata, CoNAL (Xu et al., 2023) prompts LLMs to\n6013\nPrompt\nSuggest\u0000categories\u0000that\u0000are\u0000not\u0000directly\u0000related\u0000or\u0000belong\u0000to\u0000the\u0000same\u0000primary\u0000group\u0000as\u0000[dog].\nLLM\n(b)\nLabelPrompt\nCanyoudescribefeaturesforanomalousobject?\n(c)Description\nData Embedding\nLLM\n (a)\nData\n LLM\nA\u0000large\u0000explosion\u0000in\u0000a\u0000desert\u0000fieldwhich\u0000is\u0000abnormalbecause\u0000it\u0000is\u0000andestructive\u0000event. (d)\nFigure 4: The illustration of four approaches in ( §4):\n(a) Text Embedding-based Augmentation; (b) Pseudo\nLabel-based Augmentation; (c) Textual Description-\nbased Augmentation; and (d) Explanation-centric Gen-\neration.\nextend closed-set labels with novel examples and\ngenerates a comprehensive set of probable OOD\nsamples. By applying contrastive confidence loss\nduring training, the model achieves high accuracy\non the ID training set while maintaining lower con-\nfidence on the generated OOD examples.\n4.1.3 Textual Description-based Augmentation\nIn addition to generating pseudo labels, LLMs are\nalso used to generate textual descriptions of both\nknown ID classes and potential OOD samples. For\nexample, TagFog (Chen et al., 2024) employs a\nJigsaw strategy to generate fake OOD samples and\nprompts ChatGPT to create detailed descriptions\nfor each ID class, guiding the training of the image\nencoder in CLIP for OOD detection. In anomaly de-\ntection tasks, it is essential for LLMs to recognize\nthe close correlation between normal images and\ntheir respective prompts, while identifying a more\ndistant association with abnormal prompts. This\nrequires detailed and nuanced descriptions of nor-\nmal and anomalous stages of objects. ALFA (Zhu\net al., 2024) formulates prompts for LLMs to de-\nscribe both normal and abnormal features for each\nclass, and these descriptions are then used to im-\nprove the detection of abnormal objects. To avoid\nLLM hallucination, Dai et al. (2023) introduce a\nconsistency-based uncertainty calibration method,\nwhere LLMs describe visual features for distin-\nguishing categories in images, and the confidence\nscore of each generation is estimated accordingly.\n4.2 Explanation-centric Generation\nBeyond augmentation, LLMs’ powerful reason-\ning and natural language generation abilities al-\nlow them to provide insightful explanations for\nanomaly and OOD detection outcomes. These\nexplanations are especially important in safety-\ncritical domains, such as autonomous driving,\nwhere transparency and interpretability are crucial.\nFor example, Holmes-V AD (Zhang et al., 2024b)\ntrains a lightweight temporal sampler to select\nframes with high anomaly scores and uses an\nLLM to generate detailed explanations, providing\nclear insights into the detected anomalies. V AD-\nLLaMA (Lv and Sun, 2024) generates instruction-\ntuning data to train the projection layer of Video-\nLLaMA, enabling more comprehensive explana-\ntions of anomalies. AnomalyRuler (Yang et al.,\n2024c) employs a rule-based reasoning strategy\nwith few-normal-shot prompting, providing inter-\npretable, rule-driven explanations that can quickly\nadapt to various video anomaly detection scenarios.\nAdditionally, LLMs are being used in au-\ntonomous agents to guide decision-making after\nanomaly or OOD detection. For instance, AESOP\n(Sinha et al., 2024) leverages the autoregressive\ncapabilities of an LLM to provide zero-shot as-\nsessments on whether interventions are required\nin robotic systems after an anomaly is detected.\nBy utilizing LLMs’ generative reasoning, these\nsystems can plan and respond to anomalies in an\nefficient and informed manner.\n5 Evaluation Datasets\nIn this section, we introduce commonly used\ndatasets across multiple modalities in Table 1, in-\ncluding images, videos, text, and time series, that\nserve as benchmarks for anomaly and OOD de-\ntection We also introduce widely used evaluation\nmetrics in Appendix E.\nImages. Industrial anomaly detection is com-\nmonly evaluated using MVTec-AD (Bergmann\net al., 2019) and VisA (Zou et al., 2022), which\nprovide benchmarks for defect detection and local-\nization. In the medical domain, datasets such as\nChest X-ray (Kermany et al.) and Head CT (Fe-\nlipe, 2018) are used for detecting abnormalities in\nclinical imaging. Logical anomaly detection is as-\nsessed with MVTec LOCO (Bergmann et al., 2022).\nFor OOD detection, which focuses on semantic\nshifts, large-scale datasets such as ImageNet (Deng\net al., 2009), iNaturalist (Van Horn et al., 2018),\n6014\nTask Type Datasets\nImages\nAnomaly MVTec-AD (Bergmann et al., 2019)\nAnomaly VisA (Zou et al., 2022)\nAnomaly Chest X-ray (Kermany et al.)\nAnomaly Head CT (Felipe, 2018)\nAnomaly LOCO (Bergmann et al., 2022)\nOOD ImageNet (Deng et al., 2009)\nOOD iNaturalist (Van Horn et al., 2018)\nOOD Places (Zhou et al., 2017)\nOOD SUN (Xiao et al., 2010)\nOOD Texture (Cimpoi et al., 2014)\nVideos\nAnomaly UCF-Crime (Sultani et al., 2018)\nAnomaly XD-Violence (Wu et al.)\nAnomaly V AD-Intruct50k (Zhang et al., 2024b)\nTexts\nAnomaly NLP-AD (Li et al., 2024e)\nAnomaly AD-NLP (Bejan et al., 2023)\nOOD 20NG (Lang, 1995)\nOOD SST-2 (Socher et al., 2013)\nOOD CLINC150 (Repository, 2020)\nTimes Series\nAnomaly ODDS (Rayana, 2016)\nAnomaly Yahoo (Paparrizos et al., 2022)\nAnomaly ECG (Paparrizos et al., 2022)\nAnomaly SVDB (Paparrizos et al., 2022)\nAnomaly IOPS (Paparrizos et al., 2022)\nTable 1: A summary of datasets for Anomaly and Out-\nof-Distribution (OOD) Detection by Modality.\nPlaces (Zhou et al., 2017), and SUN (Xiao et al.,\n2010) are widely used.\nVideos. UCF-Crime (Sultani et al., 2018) and XD-\nViolence (Wu et al.) are widely used for detecting\nanomalous activities in surveillance footage. The\nV AD-Instruct50k dataset (Zhang et al., 2024b) in-\ntroduces a large-scale multimodal benchmark for\nvideo anomaly detection.\nTexts. Textual anomaly and OOD detection have\ngained attention with the rise of LLMs. NLP-\nAD (Li et al., 2024e) and AD-NLP (Bejan et al.,\n2023) provide benchmarks for detecting anoma-\nlous patterns in textual data. Recent work, AD-\nLLM (Yang et al., 2024b), evaluates LLM per-\nformance on text anomaly detection, demonstrat-\ning their superior effectiveness in this task. Tex-\ntual OOD detection is commonly assessed us-\ning CLINC150 (Repository, 2020), which parti-\ntions intent categories into ID and OOD classes.\nAdditional benchmarks, such as 20 Newsgroups\n(20NG) (Lang, 1995) and SST-2 (Socher et al.,\n2013), are used for OOD detection in topic classifi-\ncation and sentiment analysis.\nTime Series. The ODDS dataset (Rayana, 2016)\nserves as a standard benchmark for time series\nanomaly deteciton, while Yahoo, ECG, SVDB, and\nIOPS datasets (Paparrizos et al., 2022) focus on\ndetecting anomalies in financial transactions, phys-\niological signals, and system performance.\n6 Challenges and Future Directions\nIn this section, we briefly summarize challenges\nand future directions within the anomaly and OOD\ndetection research field in the era of LLMs.\nExplainability and Trustworthiness. In addition\nto accurately detecting anomalies or OOD samples,\nthere is an increasing trend to utilize LLMs to pro-\nvide reasonable explanations and serve as agents to\nplan future actions. Future research should focus\non developing methods to enhance the explainabil-\nity of LLMs for anomaly or OOD detection, in-\ncreasing the trustworthiness of LLM-based systems\nand facilitating their adoption in critical domains\nsuch as healthcare and finance (Holzinger et al.,\n2019; Guidotti et al., 2019).\nUnsolvable Problem Detection. Miyai et al.\n(2024b) propose Unsolvable Problem Detection\n(UPD), which evaluates the LLMs’ ability to rec-\nognize and abstain from answering unexpected or\nunsolvable input questions, aiding in preventing\nincorrect or misleading outputs in critical appli-\ncations where the consequences of errors can be\nsignificant. Future work should focus on incorpo-\nrating the concepts of OOD detection techniques\nfor solving the UPD problems.\nHandling Multimodal Data. The emergence of\nMLLMs capable of processing and understanding\nmultiple data modalities offers significant potential\nin the field of anomaly and OOD detection (Alayrac\net al., 2022; Li et al., 2023a). Future research\nshould explore methods to better adapt LLMs to\ncomprehend and integrate various multimodal data,\nthereby enhancing their ability to detect anomalies\nand OOD instances across diverse datasets.\n7 Conclusion\nIn this survey, we examine the use of Large Lan-\nguage Models (LLMs) and multimodal LLMs\n(MLLMs) in anomaly and out-of-distribution\n(OOD) detection. We introduce a novel taxonomy\ncategorizing methods into two approaches based\non the role of LLMs in the architectures: detec-\ntion, and generation. This taxonomy clarifies how\nLLMs can augment data, detect anomalies or OOD,\nand build explainable systems. We also summa-\nrize commonly used datasets and discuss future\nresearch directions, aiming to highlight advance-\nments and challenges in the field of anomaly or\nOOD detection and encourage further progress.\n6015\nLimitations\nWhile this survey provides a comprehensive\noverview of the utilization of Large Language Mod-\nels (LLMs) for anomaly and out-of-distribution\n(OOD) detection, several limitations should be ac-\nknowledged:\n• Scope of Coverage: Although we endeavored\nto include the latest research, the rapid pace of\nadvancements in the field means that some recent\ndevelopments may not be covered.\n• Depth of Analysis : Given the broad range of\ntopics discussed, certain methods may not be\nexplored in the depth they deserve.\n• Evaluations and Benchmarks : Due to space\nconstraints, we did not include a detailed sum-\nmary of common evaluation metrics and bench-\nmark datasets used in this area.\nBy acknowledging these limitations, we aim to pro-\nvide a balanced perspective and encourage further\nresearch to address these gaps and build on the\nfoundations laid by this survey.\nReferences\nDavide Abati, Angelo Porrello, Simone Calderara, and\nRita Cucchiara. 2019. Latent space autoregression\nfor novelty detection. In CVPR.\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\nDiogo Almeida, Janko Altenschmidt, Sam Altman,\nShyamal Anadkat, et al. 2023. Gpt-4 technical report.\narXiv preprint arXiv:2303.08774.\nJean-Baptiste Alayrac, Jeff Donahue, Pauline Luc,\nAntoine Miech, Iain Barr, Yana Hasson, Karel\nLenc, Arthur Mensch, Katherine Millican, Malcolm\nReynolds, et al. 2022. Flamingo: a visual language\nmodel for few-shot learning. NeurIPS.\nCrispin Almodovar, Fariza Sabrina, Sarvnaz Karimi,\nand Salahuddin Azad. 2024. Logfit: Log anomaly\ndetection using fine-tuned language models. IEEE\nTransactions on Network and Service Management.\nSarah Alnegheimish, Linh Nguyen, Laure Berti-Equille,\nand Kalyan Veeramachaneni. 2024. Large language\nmodels can be zero-shot anomaly detectors for time\nseries? arXiv preprint arXiv:2405.14755.\nYichen Bai, Zongbo Han, Bing Cao, Xiaoheng Jiang,\nQinghua Hu, and Changqing Zhang. 2024. Id-like\nprompt learning for few-shot out-of-distribution de-\ntection. In CVPR.\nMatei Bejan, Andrei Manolache, and Marius Popescu.\n2023. AD-NLP: A benchmark for anomaly detection\nin natural language processing. In Proceedings of the\n2023 Conference on Empirical Methods in Natural\nLanguage Processing, pages 10766–10778, Singa-\npore. Association for Computational Linguistics.\nJessa Bekker and Jesse Davis. 2020. Learning from\npositive and unlabeled data: A survey. Machine\nLearning.\nYoshua Bengio, Aaron Courville, and Pascal Vincent.\n2013. Representation learning: A review and new\nperspectives. IEEE transactions on pattern analysis\nand machine intelligence.\nPaul Bergmann, Kilian Batzner, Michael Fauser, David\nSattlegger, and Carsten Steger. 2022. Beyond dents\nand scratches: Logical constraints in unsupervised\nanomaly detection and localization. IJCV.\nPaul Bergmann, Michael Fauser, David Sattlegger, and\nCarsten Steger. 2019. Mvtec ad — a comprehensive\nreal-world dataset for unsupervised anomaly detec-\ntion. In CVPR.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. NeurIPS.\nChentao Cao, Zhun Zhong, Zhanke Zhou, Yang Liu,\nTongliang Liu, and Bo Han. 2024. Envisioning out-\nlier exposure by large language models for out-of-\ndistribution detection. In ICML.\nYunkang Cao, Xiaohao Xu, Chen Sun, Xiaonan Huang,\nand Weiming Shen. 2023. Towards generic anomaly\ndetection and understanding: Large-scale visual-\nlinguistic model (gpt-4v) takes the lead. arXiv\npreprint arXiv:2311.02782.\nJiankang Chen, Tong Zhang, Wei-Shi Zheng, and Ruix-\nuan Wang. 2024. Tagfog: Textual anchor guid-\nance and fake outlier generation for visual out-of-\ndistribution detection. In AAAI.\nXuhai Chen, Yue Han, and Jiangning Zhang. 2023a.\nApril-gan: A zero-/few-shot anomaly classification\nand segmentation method for cvpr 2023 vand work-\nshop challenge tracks 1&2: 1st place on zero-shot\nad and 4th place on few-shot ad. arXiv preprint\narXiv:2305.17382.\nXuhai Chen, Jiangning Zhang, Guanzhong Tian,\nHaoyang He, Wuhao Zhang, Yabiao Wang, Chengjie\nWang, Yunsheng Wu, and Yong Liu. 2023b. Clip-\nad: A language-guided staged dual-path model\nfor zero-shot anomaly detection. arXiv preprint\narXiv:2311.00453.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Sebas-\ntian Gehrmann, et al. 2023. Palm: Scaling language\nmodeling with pathways. JMLR.\n6016\nMircea Cimpoi, Subhransu Maji, Iasonas Kokkinos,\nSammy Mohamed, and Andrea Vedaldi. 2014. De-\nscribing textures in the wild. In CVPR.\nYi Dai, Hao Lang, Kaisheng Zeng, Fei Huang, and\nYongbin Li. 2023. Exploring large language models\nfor multi-modal out-of-distribution detection. arXiv\npreprint arXiv:2310.08027.\nSimon Damm, Mike Laszkiewicz, Johannes Lederer,\nand Asja Fischer. 2024. Anomalydino: Boosting\npatch-based few-shot anomaly detection with dinov2.\narXiv preprint arXiv:2405.14529.\nGaudenz Danuser and Markus Stricker. 1998. Para-\nmetric model fitting: From inlier characterization to\noutlier detection. TPAMI.\nLucas Deecke, Robert Vandermeulen, Lukas Ruff,\nStephan Mandt, and Marius Kloft. 2018. Image\nanomaly detection with generative adversarial net-\nworks. In ECML&KDD.\nThomas Defard, Aleksandr Setkov, Angelique Loesch,\nand Romaric Audigier. 2021. Padim: a patch distribu-\ntion modeling framework for anomaly detection and\nlocalization. In International Conference on Pattern\nRecognition, pages 475–489. Springer.\nHanqiu Deng, Zhaoxiang Zhang, Jinan Bao, and Xingyu\nLi. 2023. Anovl: Adapting vision-language models\nfor unified zero-shot anomaly localization. arXiv\npreprint arXiv:2308.15939.\nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai\nLi, and Li Fei-Fei. 2009. Imagenet: A large-scale\nhierarchical image database. In CVPR.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nBosheng Ding, Chengwei Qin, Ruochen Zhao, Tianze\nLuo, Xinze Li, Guizhen Chen, Wenhan Xia, Junjie\nHu, Anh Tuan Luu, and Shafiq Joty. 2024. Data aug-\nmentation using LLMs: Data perspectives, learning\nparadigms and challenges. In Findings of the Asso-\nciation for Computational Linguistics: ACL 2024 ,\npages 1679–1705, Bangkok, Thailand. Association\nfor Computational Linguistics.\nAmine Elhafsi, Rohan Sinha, Christopher Agia, Edward\nSchmerling, Issa AD Nesnas, and Marco Pavone.\n2023. Semantic anomaly detection with large lan-\nguage models. Autonomous Robots.\nSepideh Esmaeilpour, Bing Liu, Eric Robertson, and Lei\nShu. 2022. Zero-shot out-of-distribution detection\nbased on the pre-trained model clip. In AAAI.\nKitamura Felipe. 2018. Head ct - hemorrhage.\nhttps://www.kaggle.com/datasets/\nfelipekitamura/headct-hemorrhage.\nStanislav Fort, Jie Ren, and Balaji Lakshminarayanan.\n2021. Exploring the limits of out-of-distribution de-\ntection. In NeurIPS.\nHao Fu, Naman Patel, Prashanth Krishnamurthy, and\nFarshad Khorrami. 2024. Clipscope: Enhancing\nzero-shot ood detection with bayesian scoring. arXiv\npreprint arXiv:2405.14737.\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,\nBing Xu, David Warde-Farley, Sherjil Ozair, Aaron\nCourville, and Yoshua Bengio. 2014. Generative\nadversarial nets. In NeurIPS.\nZhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen,\nHao Li, Ming Tang, and Jinqiao Wang. 2024a. Filo:\nZero-shot anomaly detection by fine-grained descrip-\ntion and high-quality localization. arXiv preprint\narXiv:2404.13671.\nZhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen,\nMing Tang, and Jinqiao Wang. 2024b. Anomalygpt:\nDetecting industrial anomalies using large vision-\nlanguage models. In AAAI.\nRiccardo Guidotti, Anna Monreale, Salvatore Ruggieri,\nFranco Turini, Fosca Giannotti, and Dino Pedreschi.\n2019. A survey of methods for explaining black box\nmodels. ACM computing surveys (CSUR).\nFatemeh Hadadi, Qinghua Xu, Domenico Bianculli,\nand Lionel Briand. 2024. Anomaly detection on\nunstable logs with gpt models. arXiv preprint\narXiv:2406.07467.\nDan Hendrycks, Steven Basart, Mantas Mazeika, Andy\nZou, Joe Kwon, Mohammadreza Mostajabi, Jacob\nSteinhardt, and Dawn Song. 2019. Scaling out-of-\ndistribution detection for real-world settings. arXiv\npreprint arXiv:1911.11132.\nDan Hendrycks and Kevin Gimpel. 2017. A baseline\nfor detecting misclassified and out-of-distribution ex-\namples in neural networks. In ICLR.\nWaleed Hilal, S. Andrew Gadsden, and John Yawney.\n2022. Financial fraud: A review of anomaly detec-\ntion techniques and recent advances. Expert Systems\nwith Applications.\nAndreas Holzinger, Georg Langs, Daniel Denk, Kurt\nZatloukal, and Henning M ¨uller. 2019. Causabil-\nity and explainability of artificial intelligence in\nmedicine. Wiley Interdisciplinary Reviews: Data\nMining and Knowledge Discovery.\nWeiming Hu, Jun Gao, Bing Li, Ou Wu, Junping Du,\nand Stephen Maybank. 2018. Anomaly detection\nusing local kernel density estimation and context-\nbased regression. TKDE.\nZhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-\nPeng Lim, Lidong Bing, Xing Xu, Soujanya Po-\nria, and Roy Ka-Wei Lee. 2023. Llm-adapters:\nAn adapter family for parameter-efficient fine-\ntuning of large language models. arXiv preprint\narXiv:2304.01933.\n6017\nChaoqin Huang, Aofan Jiang, Jinghao Feng, Ya Zhang,\nXinchao Wang, and Yanfeng Wang. 2024a. Adapting\nvisual-language models for generalizable anomaly\ndetection in medical images. In CVPR.\nK Huang, G Song, Hanwen Su, and Jiyan Wang. 2024b.\nOut-of-distribution detection using peer-class gen-\nerated by large language model. arXiv preprint\narXiv:2403.13324.\nKristen Jaskie and Andreas Spanias. 2019. Positive and\nunlabeled learning algorithms and applications: A\nsurvey. In International Conference on Information,\nIntelligence, Systems and Applications.\nJongheon Jeong, Yang Zou, Taewan Kim, Dongqing\nZhang, Avinash Ravichandran, and Onkar Dabeer.\n2023. Winclip: Zero-/few-shot anomaly classifica-\ntion and segmentation. In CVPR.\nXue Jiang, Feng Liu, Zhen Fang, Hong Chen, Tongliang\nLiu, Feng Zheng, and Bo Han. 2024. Negative label\nguided ood detection with pretrained vision-language\nmodels. arXiv preprint arXiv:2403.20078.\nDaniel S Kermany, Michael Goldbaum, Wenjia Cai, Car-\nolina CS Valentim, Huiying Liang, Sally L Baxter,\nAlex McKeown, Ge Yang, Xiaokang Wu, Fangbing\nYan, et al. Identifying medical diagnoses and treat-\nable diseases by image-based deep learning. Cell.\nDiederik P Kingma and Prafulla Dhariwal. 2018. Glow:\nGenerative flow with invertible 1x1 convolutions.\nNeurIPS.\nDiederik P Kingma and Max Welling. 2013. Auto-\nencoding variational bayes. arXiv preprint\narXiv:1312.6114.\nIvan Kobyzev, Simon Prince, and Marcus Brubaker.\n2020. Normalizing flows: An introduction and re-\nview of current methods. TPAMI.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. NeurIPS.\nMark A Kramer. 1991. Nonlinear principal compo-\nnent analysis using autoassociative neural networks.\nAIChE journal.\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hin-\nton. 2012. Imagenet classification with deep con-\nvolutional neural networks. Communications of the\nACM.\nMarc Lafon, Elias Ramzi, Cl´ement Rambour, Nicolas\nAudebert, and Nicolas Thome. 2024. Gallop: Learn-\ning global and local prompts for vision-language\nmodels. arXiv preprint arXiv:2407.01400.\nKen Lang. 1995. Newsweeder: Learning to filter net-\nnews. In Machine Learning Proceedings 1995. Mor-\ngan Kaufmann, San Francisco (CA).\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin.\n2018. A simple unified framework for detecting out-\nof-distribution samples and adversarial attacks. In\nNeurIPS.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVeselin Stoyanov, and Luke Zettlemoyer. 2019. Bart:\nDenoising sequence-to-sequence pre-training for nat-\nural language generation, translation, and compre-\nhension. arXiv preprint arXiv:1910.13461.\nChristophe Leys, Olivier Klein, Yves Dominicy, and\nChristophe Ley. 2018. Detecting multivariate out-\nliers: Use a robust variant of the mahalanobis dis-\ntance. Journal of Experimental Social Psychology.\nAodong Li, Yunhan Zhao, Chen Qiu, Marius Kloft,\nPadhraic Smyth, Maja Rudolph, and Stephan Mandt.\n2024a. Anomaly detection of tabular data using llms.\narXiv preprint arXiv:2406.16308.\nJunnan Li, Dongxu Li, Silvio Savarese, and Li Fei-\nFei. 2023a. Blip-2: Bootstrapping language-image\npre-training with frozen image encoders and large\nlanguage models. arXiv preprint arXiv:2301.12597.\nTianqi Li, Guansong Pang, Xiao Bai, Wenjun Miao, and\nJin Zheng. 2024b. Learning transferable negative\nprompts for out-of-distribution detection. In CVPR.\nYichuan Li, Kaize Ding, Jianling Wang, and Kyumin\nLee. 2024c. Empowering large language models for\ntextual data augmentation. In Findings of the As-\nsociation for Computational Linguistics: ACL 2024,\npages 12734–12751, Bangkok, Thailand. Association\nfor Computational Linguistics.\nYixia Li, Boya Xiong, Guanhua Chen, and Yun Chen.\n2024d. Setar: Out-of-distribution detection with\nselective low-rank approximation. arXiv preprint\narXiv:2406.12629.\nYuangang Li, Jiaqi Li, Zhuo Xiao, Tiankai Yang,\nYi Nian, Xiyang Hu, and Yue Zhao. 2024e. Nlp-\nadbench: Nlp anomaly detection benchmark. arXiv\npreprint arXiv:2412.04784.\nYuanze Li, Haolin Wang, Shihao Yuan, Ming Liu,\nDebin Zhao, Yiwen Guo, Chen Xu, Guangming\nShi, and Wangmeng Zuo. 2023b. Myriad: Large\nmultimodal model by applying vision experts for\nindustrial anomaly detection. arXiv preprint\narXiv:2310.19070.\nShiyu Liang, Yixuan Li, and R. Srikant. 2018. Enhanc-\ning the reliability of out-of-distribution image detec-\ntion in neural networks. In International Conference\non Learning Representations.\nBo Liu, Li-Ming Zhan, Zexin Lu, Yujie Feng, Lei Xue,\nand Xiao-Ming Wu. 2024a. How good are LLMs\nat out-of-distribution detection? In Proceedings of\nthe 2024 Joint International Conference on Compu-\ntational Linguistics, Language Resources and Eval-\nuation (LREC-COLING 2024) , pages 8211–8222,\nTorino, Italia. ELRA and ICCL.\n6018\nJiaqi Liu, Guoyang Xie, Jinbao Wang, Shangnian Li,\nChengjie Wang, Feng Zheng, and Yaochu Jin. 2024b.\nDeep industrial image anomaly detection: A survey.\nMachine Intelligence Research.\nJun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma,\nSi Qin, Chetan Bansal, Qingwei Lin, Saravan Ra-\njmohan, and Dongmei Zhang. 2024c. Large lan-\nguage models can deliver accurate and interpretable\ntime series anomaly detection. arXiv preprint\narXiv:2405.15370.\nWeitang Liu, Xiaoyun Wang, John Owens, and Yixuan\nLi. 2020. Energy-based out-of-distribution detection.\nNeurIPS.\nYilun Liu, Shimin Tao, Weibin Meng, Feiyu Yao, Xi-\naofeng Zhao, and Hao Yang. 2024d. Logprompt:\nPrompt engineering towards zero-shot and inter-\npretable log analysis. In ICSE.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nPhilipp Liznerski, Lukas Ruff, Robert A Vandermeulen,\nBilly Joe Franks, Klaus-Robert M¨uller, and Marius\nKloft. 2022. Exposing outlier exposure: What can\nbe learned from few, one, and zero outlier images.\narXiv preprint arXiv:2205.11474.\nHui Lv and Qianru Sun. 2024. Video anomaly detection\nand explanation via large language models. arXiv\npreprint arXiv:2401.05702.\nYifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun,\nWei Li, and Yixuan Li. 2022. Delving into out-of-\ndistribution detection with vision-language represen-\ntations. In NeurIPS.\nYifei Ming and Yixuan Li. 2024. How does fine-\ntuning impact out-of-distribution detection for vision-\nlanguage models? IJCV.\nAtsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei\nMing, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty,\nYixuan Li, Hai Li, et al. 2024a. Generalized\nout-of-distribution detection and beyond in vision\nlanguage model era: A survey. arXiv preprint\narXiv:2407.21794.\nAtsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei\nMing, Qing Yu, Go Irie, Yixuan Li, Hai Li, Ziwei\nLiu, and Kiyoharu Aizawa. 2024b. Unsolvable prob-\nlem detection: Evaluating trustworthiness of vision\nlanguage models. arXiv preprint arXiv:2403.20331.\nAtsuyuki Miyai, Qing Yu, Go Irie, and Kiyoharu\nAizawa. 2023. Zero-shot in-distribution detection\nin multi-object settings using vision-language foun-\ndation models. arXiv preprint arXiv:2304.04521.\nAtsuyuki Miyai, Qing Yu, Go Irie, and Kiyoharu\nAizawa. 2024c. Locoop: Few-shot out-of-\ndistribution detection via prompt learning. NeurIPS.\nJun Nie, Yonggang Zhang, Zhen Fang, Tongliang Liu,\nBo Han, and Xinmei Tian. 2024. Out-of-distribution\ndetection with negative prompts. In ICLR.\nOpenAI. 2023. Gpt-4 technical report. arXiv preprint\narXiv:2303.08774.\nGuansong Pang, Chunhua Shen, Longbing Cao, and\nAnton Van Den Hengel. 2021. Deep learning for\nanomaly detection: A review. ACM computing sur-\nveys (CSUR).\nJohn Paparrizos, Yuhao Kang, Paul Boniol, Ruey S.\nTsay, Themis Palpanas, and Michael J. Franklin.\n2022. Tsb-uad: an end-to-end benchmark suite\nfor univariate time-series anomaly detection. Proc.\nVLDB Endow.\nSangha Park, Jisoo Mok, Dahuin Jung, Saehyung Lee,\nand Sungroh Yoon. 2023. On the powerfulness of\ntextual outlier exposure for visual ood detection. In\nNeurIPS.\nTaesung Park, Ming-Yu Liu, Ting-Chun Wang, and\nJun-Yan Zhu. 2019. Semantic image synthesis with\nspatially-adaptive normalization. In CVPR.\nEmanuel Parzen. 1962. On estimation of a probability\ndensity function and mode. The annals of mathemat-\nical statistics.\nStanislav Pidhorskyi, Ranya Almohsen, Donald A Ad-\njeroh, and Gianfranco Doretto. 2018. Generative\nprobabilistic novelty detection with adversarial au-\ntoencoders. In NeurIPS.\nJiaxing Qi, Shaohan Huang, Zhongzhi Luan, Shu Yang,\nCarol Fung, Hailong Yang, Depei Qian, Jing Shang,\nZhiwen Xiao, and Zhihui Wu. 2023. Loggpt: Ex-\nploring chatgpt for log-based anomaly detection. In\nHPCC/DSS/SmartCity/DependSys.\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya\nRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-\ntry, Amanda Askell, Pamela Mishkin, Jack Clark,\net al. 2021. Learning transferable visual models from\nnatural language supervision. In ICML.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. JMLR.\nShebuti Rayana. 2016. Odds library.\nUCI Machine Learning Repository. 2020. CLINC150.\nKarsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard\nSch¨olkopf, Thomas Brox, and Peter Gehler. 2022.\nTowards total recall in industrial anomaly detection.\nIn CVPR.\nLukas Ruff, Robert Vandermeulen, Nico Goernitz, Lu-\ncas Deecke, Shoaib Ahmed Siddiqui, Alexander\nBinder, Emmanuel M¨uller, and Marius Kloft. 2018.\nDeep one-class classification. In ICML.\n6019\nMohammad Sabokrou, Mohammad Khalooei, Mah-\nmood Fathy, and Ehsan Adeli. 2018. Adversarially\nlearned one-class classifier for novelty detection. In\nCVPR.\nPranab Sahoo, Ayush Kumar Singh, Sriparna Saha,\nVinija Jain, Samrat Mondal, and Aman Chadha.\n2024. A systematic survey of prompt engineering in\nlarge language models: Techniques and applications.\narXiv preprint arXiv:2402.07927.\nMohammadreza Salehi, Hossein Mirzaei, Dan\nHendrycks, Yixuan Li, Mohammad Hossein\nRohban, and Mohammad Sabokrou. 2021. A\nunified survey on anomaly, novelty, open-set, and\nout-of-distribution detection: Solutions and future\nchallenges. arXiv preprint arXiv:2110.14051.\nRohan Sinha, Amine Elhafsi, Christopher Agia,\nMatthew Foutter, Edward Schmerling, and Marco\nPavone. 2024. Real-time anomaly detection and re-\nactive planning with large language models. arXiv\npreprint arXiv:2407.08735.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, Andrew Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Proceedings of the 2013 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1631–1642, Seattle, Washington, USA. Association\nfor Computational Linguistics.\nJing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong\nXiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu,\nand Junhong Lin. 2024. Large language models for\nforecasting and anomaly detection: A systematic lit-\nerature review. arXiv preprint arXiv:2402.10350.\nWaqas Sultani, Chen Chen, and Mubarak Shah. 2018.\nReal-world anomaly detection in surveillance videos.\nIn CVPR.\nYiyou Sun, Chuan Guo, and Yixuan Li. 2021. Re-\nact: Out-of-distribution detection with rectified acti-\nvations. In NeurIPS.\nYiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li.\n2022. Out-of-distribution detection with deep nearest\nneighbors. In ICML.\nJihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jin-\nwoo Shin. 2020. Csi: Novelty detection via con-\ntrastive learning on distributionally shifted instances.\nIn NeurIPS.\nDavid Martinus Johannes Tax. 2002. One-class classifi-\ncation: Concept learning in the absence of counter-\nexamples.\nGemini Team, Rohan Anil, Sebastian Borgeaud,\nYonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,\nRadu Soricut, Johan Schalkwyk, Andrew M Dai,\nAnja Hauth, et al. 2023. Gemini: a family of\nhighly capable multimodal models. arXiv preprint\narXiv:2312.11805.\nJing Tian, Michael H Azarian, and Michael Pecht. 2014.\nAnomaly detection using self-organizing maps-based\nk-nearest neighbor algorithm. In PHM Society Euro-\npean Conference.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Thomas Lacroix,\nBaptiste Rozi`ere, Naman Goyal, Eric Hambro, Fer-\nhan Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nMelissa Turcotte, Juston Moore, Nick Heard, and Aaron\nMcPhall. 2016. Poisson factorization for peer-based\nanomaly detection. In IEEE Conference on Intelli-\ngence and Security Informatics (ISI).\nGrant Van Horn, Oisin Mac Aodha, Yang Song, Yin\nCui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro\nPerona, and Serge Belongie. 2018. The inaturalist\nspecies classification and detection dataset. In CVPR.\nAaron Van Oord, Nal Kalchbrenner, and Koray\nKavukcuoglu. 2016. Pixel recurrent neural networks.\nIn ICML.\nHualiang Wang, Yi Li, Huifeng Yao, and Xiaomeng Li.\n2023. Clipn for zero-shot ood detection: Teaching\nclip to say no. In ICCV.\nWenhai Wang, Zhe Chen, Xiaokang Chen, Jiannan\nWu, Xizhou Zhu, Gang Zeng, Ping Luo, Tong Lu,\nJie Zhou, Yu Qiao, et al. 2024. Visionllm: Large\nlanguage model is also an open-ended decoder for\nvision-centric tasks. In NeurIPS.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\net al. 2022. Chain-of-thought prompting elicits rea-\nsoning in large language models. In NeurIPS.\nNing Wu, Ming Gong, Linjun Shou, Shining Liang,\nand Daxin Jiang. 2023. Large language models are\ndiverse role-players for summarization evaluation. In\nNLPCC.\nPeng Wu, Jing Liu, Yujia Shi, Yujia Sun, Fangtao Shao,\nZhaoyang Wu, and Zhiwei Yang. Not only look, but\nalso listen: Learning multimodal violence detection\nunder weak supervision. In ECCV.\nJianxiong Xiao, James Hays, Krista A Ehinger, Aude\nOliva, and Antonio Torralba. 2010. Sun database:\nLarge-scale scene recognition from abbey to zoo. In\nCVPR.\nAlbert Xu, Xiang Ren, and Robin Jia. 2023. Con-\ntrastive novelty-augmented learning: Anticipating\noutliers with large language models. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 11778–11801, Toronto, Canada. Association\nfor Computational Linguistics.\nJingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei\nLiu. 2024a. Generalized out-of-distribution detec-\ntion: A survey. IJCV.\n6020\nTiankai Yang, Yi Nian, Shawn Li, Ruiyao Xu, Yuangang\nLi, Jiaqi Li, Zhuo Xiao, Xiyang Hu, Ryan Rossi,\nKaize Ding, et al. 2024b. Ad-llm: Benchmarking\nlarge language models for anomaly detection. arXiv\npreprint arXiv:2412.11142.\nYuchen Yang, Kwonjoon Lee, Behzad Dariush, Yinzhi\nCao, and Shao-Yuan Lo. 2024c. Follow the rules:\nReasoning for video anomaly detection with large\nlanguage models. arXiv preprint arXiv:2407.10299.\nShukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing\nSun, Tong Xu, and Enhong Chen. 2023. A survey on\nmultimodal large language models. arXiv preprint\narXiv:2306.13549.\nLuca Zanella, Willi Menapace, Massimiliano Mancini,\nYiming Wang, and Elisa Ricci. 2024. Harness-\ning large language models for training-free video\nanomaly detection. In CVPR.\nAndi Zhang, Tim Z Xiao, Weiyang Liu, Robert Bamler,\nand Damon Wischik. 2024a. Your finetuned large lan-\nguage model is already a powerful out-of-distribution\ndetector. arXiv preprint arXiv:2404.08679.\nBangzuo Zhang and Wanli Zuo. 2008. Learning from\npositive and unlabeled examples: A survey. In Inter-\nnational Symposiums on Information Processing.\nHuaxin Zhang, Xiaohao Xu, Xiang Wang, Jialong Zuo,\nChuchu Han, Xiaonan Huang, Changxin Gao, Yue-\nhuan Wang, and Nong Sang. 2024b. Holmes-vad:\nTowards unbiased and explainable video anomaly\ndetection via multi-modal llm. arXiv preprint\narXiv:2406.12235.\nJiangning Zhang, Xuhai Chen, Zhucun Xue, Yabiao\nWang, Chengjie Wang, and Yong Liu. 2023. Ex-\nploring grounding potential of vqa-oriented gpt-4v\nfor zero-shot anomaly detection. arXiv preprint\narXiv:2311.02612.\nBolei Zhou, Agata Lapedriza, Aditya Khosla, Aude\nOliva, and Antonio Torralba. 2017. Places: A 10 mil-\nlion image database for scene recognition. TPAMI.\nKaiyang Zhou, Jingkang Yang, Chen Change Loy, and\nZiwei Liu. 2022. Learning to prompt for vision-\nlanguage models. IJCV.\nQihang Zhou, Guansong Pang, Yu Tian, Shibo He, and\nJiming Chen. 2024. AnomalyCLIP: Object-agnostic\nprompt learning for zero-shot anomaly detection. In\nICLR.\nYibo Zhou. 2022. Rethinking reconstruction\nautoencoder-based out-of-distribution detection. In\nCVPR.\nJiaqi Zhu, Shaofeng Cai, Fang Deng, and Junran Wu.\n2024. Do llms understand visual anomalies? uncov-\nering llm capabilities in zero-shot anomaly detection.\nIn ACM Multimedia 2024.\nJiawen Zhu and Guansong Pang. 2024. Toward general-\nist anomaly detection via in-context residual learning\nwith few-shot sample prompts. In CVPR.\nEv Zisselman and Aviv Tamar. 2020. Deep residual\nflow for out of distribution detection. In CVPR.\nBo Zong, Qi Song, Martin Renqiang Min, Wei Cheng,\nCristian Lumezanu, Daeki Cho, and Haifeng Chen.\n2018. Deep autoencoding gaussian mixture model\nfor unsupervised anomaly detection. In ICLR.\nYang Zou, Jongheon Jeong, Latha Pemula, Dongqing\nZhang, and Onkar Dabeer. 2022. Spot-the-difference\nself-supervised pre-training for anomaly detection\nand segmentation. In ECCV.\n6021\nA LLM-based Anomaly and OOD\nDetection: Strengths and Challenges\nA.1 Strengths\nZero-shot/Few-shot: Traditional anomaly and\nOOD detection methods require extensive training\non well-defined normal and in-distribution datasets,\nwhich can be both time-consuming and compu-\ntationally expensive. In contrast, LLMs can per-\nform zero-shot or few-shot reasoning or learning,\nproducing detection results without needing large-\nscale training (Kojima et al., 2022). This allows re-\nsearchers to bypass the complex process of data col-\nlection and model training, enabling faster anomaly\nand OOD detection.\nExplainability and Interpretability: LLMs pos-\nsess strong reasoning abilities that can contribute\nto building explainable systems for anomaly and\nOOD detection. Traditional methods often rely\non scores that offer little insight into the detection\nprocess. In contrast, LLMs can provide detailed, in-\nterpretable explanations for their detection results,\noffering valuable insights for future actions. Fur-\nthermore, LLMs can be integrated as agents within\na system, assisting in planning the next steps when\nan anomaly or OOD event is detected.\nA.2 Challenges\nComputational Efficiency and Token Limits: A\nmajor concern when leveraging LLMs for anomaly\nand OOD detection is computational inefficiency.\nApplying LLMs in these tasks often requires com-\nplex reasoning which can lead to significant com-\nputational overhead. Additionally, many LLMs\nhave input token limits, making it impossible to\nfeed large amounts of data directly into the model.\nTo address this, researchers must carefully design\narchitectures that allow LLMs to process the data\neffectively. For instance, techniques like Retrieval-\nAugmented Generation have been used to retrieve\nthe most relevant data to avoid token limit issues\n(Liu et al., 2024c). Moreover, methods such as\nmodel pruning and knowledge distillation should\nbe considered to reduce computational costs while\nmaintaining high accuracy.\nDomain Knowledge: While LLMs are trained on\nvast and diverse datasets, they may lack specific\ndomain expertise needed for certain anomaly and\nOOD detection tasks. To enhance performance in\nthese specialized domains, incorporating domain\nknowledge into the LLMs is crucial. One strategy is\ninjecting domain knowledge into prompts to guide\nthe LLM’s understanding. Another approach in-\nvolves using adapters or fine-tuning to better tailor\nthe LLMs to domain-specific problems, ensuring\nthey perform well in specialized tasks.\nHallucination and Trustworthiness: LLMs can\nsometimes produce inaccurate or fabricated infor-\nmation, a phenomenon known as hallucination. In\nthe context of anomaly and OOD detection, hallu-\ncinations pose a significant risk, potentially leading\nto incorrect or misleading results. To mitigate this,\nresearchers need to work on reducing hallucina-\ntion rates and improving the trustworthiness of the\nmodel. Manual checks may still be necessary in\ncritical applications, as LLMs should be seen as\nassistants rather than sole decision-makers.\nB Anomaly Detection Research Roadmap\nAnomaly detection has evolved significantly from\ntraditional statistical methods to deep learning ap-\nproaches and more recently to Large Language\nModel (LLM)-based methods. These advance-\nments have expanded the range of applications\nacross diverse data modalities and downstream\ntasks. Following Yang et al. (2024a), tradi-\ntional methodologies can be grouped into density-\nbased, reconstruction-based, distance-based, and\nclassification-based methods. Below is an overview\nof these traditional approaches, followed by a dis-\ncussion of the advantages and challenges of LLM-\nbased anomaly detection.\nB.1 Traditional Methods\nDensity-based Methods. Density-based methods\nmodel the distribution of normal data and detect\nanomalies by evaluating how well a sample fits this\nmodeled distribution. The underlying assumption\nis that normal data is more likely to have a higher\nlikelihood under the distribution, while anomalous\ndata will have a lower likelihood.\nParametric density estimation assumes a prede-\nfined form for the distribution, such as a multivari-\nate Gaussian or Poisson distribution (Danuser and\nStricker, 1998; Leys et al., 2018; Turcotte et al.,\n2016). These methods perform well when the data\ndistribution adheres to the parametric assumption\nbut can struggle with more complex cases. Non-\nparametric density estimation methods, such as his-\ntograms and kernel density estimation (KDE), offer\nmore flexibility by not assuming a fixed paramet-\nric form, making them suitable for handling more\ncomplex distributions (Parzen, 1962; Hu et al.,\n6022\n2018). Modern deep learning techniques enhance\ndensity estimation by learning high-quality feature\nrepresentations. Methods such as autoencoders\n(AE), variational autoencoders (V AE), and flow-\nbased models are commonly used (Kramer, 1991;\nKingma and Welling, 2013; Goodfellow et al.,\n2014).\nReconstruction-based Methods. Reconstruc-\ntion-based methods operate on the assumption that\nmodels trained on normal data will reconstruct\nthose samples accurately, while anomalous data\nwill result in higher reconstruction errors. This dis-\ncrepancy in reconstruction performance is used to\nidentify anomalies. Common approaches include\nsparse reconstruction, where normal samples are\nrepresented by a small set of basis functions, while\nanomalies are not. Autoencoders and variational\nautoencoders are often employed to capture these\ndifferences in reconstruction errors (Kramer, 1991;\nKingma and Welling, 2013).\nRecent advancements have sought to reduce the\ncomputational costs associated with reconstruction-\nbased methods, for example by focusing on recon-\nstructing hidden features or masking parts of the\ninput (Pidhorskyi et al., 2018). These improve-\nments enhance both the accuracy and efficiency of\nanomaly detection, without requiring pixel-level\nreconstruction.\nDistance-based Methods. Distance-based meth-\nods detect anomalies by measuring the distance\nbetween test samples and reference points, such\nas class prototypes or centroids. Anomalies are\nexpected to be further from these reference points\nthan normal samples (Tian et al., 2014).\nClassification-based Methods. Classification-\nbased methods treat anomaly detection as a super-\nvised learning problem. In one-class classification\n(OCC) (Tax, 2002), the goal is to learn a decision\nboundary that encompasses the normal data, with\nany data points outside this boundary being classi-\nfied as anomalies.\nDeepSVDD (Ruff et al., 2018) is a notable\ndeep learning method for OCC, where a deep net-\nwork learns a compact representation of the nor-\nmal class. Semi-supervised approaches, such as\npositive-unlabeled (PU) learning (Zhang and Zuo,\n2008; Bekker and Davis, 2020; Jaskie and Spanias,\n2019), are also used when only a subset of the\nnormal data is labeled, with the rest being unla-\nbeled. Self-supervised learning methods have been\nproposed as well, using pretext tasks such as con-\ntrastive learning or future frame prediction to iden-\ntify anomalies (Tack et al., 2020).\nB.2 LLM-based Anomaly Detection\nThe advent of Large Language Models (LLMs) like\nGPT, as well as multimodal LLMs, has introduced\nnew possibilities for anomaly detection. LLMs\noffer zero-shot and few-shot learning capabilities,\nallowing anomalies to be detected with minimal or\nno task-specific training. This is particularly valu-\nable in scenarios where labeled data is scarce or\nunavailable. LLM-based approaches benefit from\ntheir pre-trained knowledge and can adapt to vari-\nous data modalities, including images, and videos.\nBy using natural language processing capabilities,\nLLMs can provide explainability in anomaly de-\ntection, offering reasoning as to why a particular\ninstance is flagged as anomalous.\nHowever, LLM-based methods come with cer-\ntain challenges, including high computational costs\nand limitations related to token size. These mod-\nels are computationally intensive to run and may\nstruggle with long input sequences, which necessi-\ntates techniques such as retrieval-augmented gen-\neration (RAG) or model pruning to manage these\nconstraints.\nB.3 Comparison: Traditional vs. LLM-based\nAnomaly Detection\nWhen comparing traditional and LLM-based\nanomaly detection methods, several key differences\nemerge:\n• Assumptions: Traditional methods often rely on\npredefined assumptions about the data distribu-\ntion, such as the parametric forms used in density-\nbased methods. In contrast, LLM-based ap-\nproaches are better equipped to generalize across\na variety of tasks.\n• Data Requirements: Traditional methods, par-\nticularly those based on deep learning, usually\nrequire large labeled datasets for training. LLM-\nbased methods excel in zero-shot or few-shot\nsettings, enabling them to detect anomalies with\nminimal task-specific data.\n• Explainability: Traditional methods lack the\nability to explain their decisions in natural lan-\nguage. LLM-based approaches can not only de-\ntect anomalies but also provide natural language\nexplanations, which improves transparency and\ntrustworthiness for further steps.\n• Computational Efficiency: Traditional methods\nare generally more computationally efficient\n6023\ncompared to LLM-based methods, especially\nwhen fine-tuning models. However, LLM-based\napproaches offer greater flexibility and can han-\ndle a wider range of tasks, though at the cost\nof higher computational resources. Moreover,\nLLMs do not require extensive data preparation\nand training from scratch, which can offset the\ncomputational overhead in certain scenarios.\n• Generalization: LLM-based methods are highly\nadaptable, capable of processing different types\nof data, such as text and images. In contrast, tra-\nditional methods often need custom architectures\ntailored to the specific data modality.\nIn conclusion, while traditional anomaly detec-\ntion methods remain effective and computation-\nally efficient, LLM-based methods provide greater\nflexibility, generalization, and explainability. This\nmakes LLM-based approaches increasingly valu-\nable in modern, complex anomaly detection tasks.\nC Out-of-Distribution Detection Research\nRoadmap\nCompared to Anomaly Detection (AD), Out-of-\ndistribution (OOD) detection emerged in 2017 and\nhas since received increasing attention. OOD de-\ntection is critical for ensuring the reliability and\nsafety of machine learning models by identifying\nsamples that fall outside the distribution of the\ntraining data. Following Yang et al. (2024a), tradi-\ntional OOD detection methods can be categorized\ninto classification-based, density-based, distance-\nbased, and reconstruction-based methods. These\napproaches vary in how they define and detect\nOOD samples, with each showing strengths de-\npending on data characteristics and the task at hand.\nC.1 Traditional Methods\nClassification-based Methods. Classification-\nbased OOD detection methods rely on the outputs\nof neural networks , typically using the softmax\nprobabilities of a classifier to determine whether a\nsample is in-distribution (ID) or OOD. The most\ncommon baseline is the Maximum Softmax Prob-\nability (MSP) method, which flags samples with\nlower softmax scores as OOD (Hendrycks and Gim-\npel, 2017). This has led to more advanced tech-\nniques that either post-process the classification\noutputs or modify the training process to improve\nOOD detection performance (Liu et al., 2020).\nGiven its alignment with classification tasks, this\napproach remains one of the most prominent meth-\nods for OOD detection.\nDensity-based Methods. Density-based methods\nexplicitly model the distribution of in-distribution\n(ID) data using probabilistic models, assuming that\nOOD samples will lie in low-density regions (Zong\net al., 2018; Abati et al., 2019; Pidhorskyi et al.,\n2018; Deecke et al., 2018; Sabokrou et al., 2018).\nTechniques such as class-conditional Gaussian\nmodels allow for probabilistic modeling of ID\nclasses, while flow-based models are also used for\ndensity estimation (Kobyzev et al., 2020; Zissel-\nman and Tamar, 2020; Kingma and Dhariwal, 2018;\nVan Oord et al., 2016). However, density-based\nmethods sometimes assign higher likelihoods to\nOOD samples, leading to challenges in reliabil-\nity. Methods such as likelihood ratio-based ap-\nproaches and ensembles have been proposed to ad-\ndress these issues, though these approaches tend to\nbe computationally expensive and often fall behind\nclassification-based methods in performance.\nDistance-based Methods. Distance-based meth-\nods operate under the assumption that OOD sam-\nples are farther from the centroids or prototypes\nof in-distribution classes in feature space. A pop-\nular parametric approach is to use Mahalanobis\ndistance to compute the distance between test sam-\nples and class centroids (Lee et al., 2018), whereas\nnon-parametric methods are increasingly favored\nfor their flexibility and simplicity (Sun et al., 2022).\nThese methods use various distance metrics—such\nas Euclidean distance and geodesic distance—to\ndetect OOD samples.\nReconstruction-based Methods. Reconstruc-\ntion-based methods leverage encoder-decoder mod-\nels to reconstruct input samples and detect OOD\nsamples by measuring reconstruction error. The\npremise is that models trained on ID data will ex-\nhibit lower reconstruction errors for ID samples\nand higher errors for OOD samples. (Zhou, 2022).\nC.2 LLM-based OOD Detection\nLarge Language Models (LLMs) and Multi-\nModal LLMs (MLLMs) have transformed Out-of-\nDistribution (OOD) detection by leveraging pre-\ntrained models like CLIP to perform downstream\ndetection tasks. These models are capable of detect-\ning OOD samples in zero-shot or few-shot settings,\nmeaning they can generalize to unseen data with lit-\ntle to no additional training. This represents a shift\nfrom traditional OOD detection methods, which\ntypically rely on training classifiers using the entire\n6024\nin-distribution (ID) dataset.\nIncorporating the internal knowledge of pre-\ntrained MLLMs, the field is progressing towards\neven greater computational efficiency, where min-\nimal or no training data is needed. This ability to\noperate with limited data while maintaining per-\nformance makes LLM-based OOD detection espe-\ncially appealing for real-world applications.\nC.3 Comparison of Traditional vs.\nLLM-based OOD Detection\nThe shift from traditional OOD detection methods\nto LLM-based approaches marks a fundamental\nchange in how OOD detection is defined and exe-\ncuted. Traditional methods, such as classification-\nbased approaches like Maximum Softmax Prob-\nability (MSP) or distance-based techniques like\nMahalanobis distance, rely heavily on task-specific\ntraining and typically require large amounts of in-\ndistribution (ID) data. These methods often define\nOOD detection in the context of post-processing\nor retraining models on ID data to differentiate\nbetween in- and out-of-distribution samples.\nIn contrast, LLM-based methods redefine OOD\ndetection by leveraging pre-trained models, allow-\ning them to detect OOD samples without extensive\ntask-specific training. This results in a significant\nshift in the OOD detection paradigm, moving to-\nwards zero-shot and few-shot learning, where mod-\nels can generalize to new tasks with minimal or no\nadditional training. Key differences include:\n• Performance: LLM-based methods often outper-\nform traditional methods in zero-shot and few-\nshot scenarios, where limited labeled data is avail-\nable. Traditional methods struggle without sub-\nstantial in-distribution data and retraining.\n• Flexibility: LLM-based approaches are highly\nadaptable to new tasks and datasets due to their\nreliance on vast pre-trained knowledge, while\ntraditional methods require significant retraining\nfor new domains or data types.\n• Efficiency: Traditional OOD methods rely on ex-\nplicitly training models with in-distribution data,\nwhile LLM-based methods redefine the problem\nby leveraging pre-existing knowledge in zero-\nshot or few-shot settings, minimizing the need\nfor retraining or task-specific data preparation.\nIn conclusion, the transition from traditional\nOOD detection methods to LLM-based approaches\nrepresents a shift from task-specific training and\nrigid models to more flexible, generalizable sys-\nMethod MVTec AD VisA\nAUC↑ AUC↑\nZero-shot\nCoOp(Zhou et al., 2022)† 88.8 62.8\nCLIP-AC(Radford et al., 2021)† 71.5 65.0\nV AND(Chen et al., 2023a)† 86.1 78.0\nAnomalyCLIP(Zhou et al., 2024)† 91.5 82.1\nCLIP-AD(Liznerski et al., 2022)† 90.9 79.2\nFiLo(Gu et al., 2024a)† 91.2 83.9\nOne-shot\nSPADE(Park et al., 2019) 81.0 79.5\nPaDiM(Defard et al., 2021) 76.6 62.8\nPatchCore(Roth et al., 2022) 83.4 79.9\nWinCLIP(Jeong et al., 2023)† 93.1 83.8\nAnomalyGPT(Gu et al., 2024b)† 94.1 87.4\nAnomalyDINO-S(Damm et al., 2024)† 96.6 87.4\nTable 2: Anomaly detection results for MVTec AD and\nVisA (image-level). Bold indicates the best performance.\nThe methods marked with †are using MLLMs as back-\nbones. The results are are sourced from (Zhou et al.,\n2024; Gu et al., 2024b)\ntems that can handle a wider variety of tasks with\nminimal additional training. As research contin-\nues, a hybrid approach combining the efficiency\nof traditional methods with the flexibility LLM-\nbased models may offer the most robust solution\nfor diverse OOD detection challenges.\nD Quantitative Analysis and Comparison\nWhile our primary goal is to conduct a systematic\nliterature review of existing methods for anomaly\nand out-of-distribution (OOD) detection tasks, we\nacknowledge that including quantitative analysis\nand comparisons is valuable for understanding the\npractical implications of these methods.\nD.1 Anomaly Detection\nTable 2 presents the quantitative results for image-\nlevel anomaly detection on two widely used bench-\nmarks, MVTec AD (Bergmann et al., 2019) and\nVisA (Zou et al., 2022). The results are sourced\nfrom the original papers. We ensured that the ex-\nperiments across different methods used the same\ndataset and learning settings for a fair comparison.\nD.2 OOD Detection\nTable 3 provides an overview of out-of-distribution\n(OOD) detection results using ImageNet-1K as the\nin-distribution (ID) dataset. The methods are evalu-\nated across multiple OOD datasets, including Tex-\nture, iNaturalist, Places, and SUN (Van Horn et al.,\n2018; Zhou et al., 2017; Xiao et al., 2010; Cim-\npoi et al., 2014), with performance measured using\n6025\nMethod Texture iNaturalist Places SUN Avg\nAUC↑ FPR95↓ AUC↑ FPR95↓ AUC↑ FPR95↓ AUC↑ FPR95↓ AUC↑ FPR95↓\nTraditional posthoc methods\nMSP(Hendrycks et al., 2019)† 74.84 73.66 77.74 74.57 72.18 79.12 73.97 76.95 74.98 76.22\nMaxLogit(Hendrycks et al., 2019)† 88.63 48.72 88.03 60.88 87.45 55.54 91.16 44.83 88.82 52.49\nEnergy(Liu et al., 2020)† 88.22 50.39 87.18 64.98 87.33 57.40 91.17 46.42 88.48 54.80\nReAct(Sun et al., 2021)† 88.13 49.88 86.87 65.57 87.42 56.85 91.04 46.17 88.37 54.62\nODIN(Liang et al., 2018)† 87.85 51.67 94.65 30.22 85.54 55.06 87.17 54.04 88.80 47.75\nWithout Tuning methods\nMCM(Ming et al., 2022)† 86.11 57.77 94.61 30.91 89.77 44.69 92.57 34.59 90.76 42.74\nNegLabel(Jiang et al., 2024) 90.22 43.5 99.49 1.91 91.64 35.59 95.49 20.53 94.21 25.40\nEOE(Cao et al., 2024) 57.53 85.64 97.52 12.29 95.73 20.40 92.95 30.16 92.96 30.09\nWith Tuning methods\nCoOp(Zhou et al., 2022) 89.47 45.00 93.77 29.81 90.58 40.11 93.29 40.83 91.78 51.68\nLoCoOp(Miyai et al., 2024c)† 90.19 42.28 96.86 16.05 91.98 32.87 95.07 23.44 93.52 28.66\nCLIPN(Wang et al., 2023)† 90.93 40.83 95.27 23.94 92.28 33.45 93.92 26.17 93.10 31.10\nNegPrompt(Nie et al., 2024)91.60 35.21 98.73 6.32 93.34 27.60 95.55 22.89 94.81 23.01\nTable 3: Comprehensive OOD detection results for ImageNet-1K as ID dataset. The black bold indicates the best\nperformance. The results marked with †are sourced from (Wang et al., 2023) and (Miyai et al., 2024c). Others are\nsourced from their original papers (Wang et al., 2023; Jiang et al., 2024; Cao et al., 2024; Nie et al., 2024)\nAUC (Area Under the ROC Curve) and FPR95\n(False Positive Rate at 95% True Positive Rate).\nE Evaluation Metrics\nThe primary goal of both anomaly detection and\nout-of-distribution (OOD) detection is to differen-\ntiate between normal/in-distribution (ID) samples\nand abnormal/out-of-distribution (OOD) samples,\nframing the problem as a binary classification task.\nSeveral common metrics are used to evaluate the\nperformance of detectors:\nAUROC (Area Under the Receiver Operating\nCharacteristic curve): This metric evaluates a de-\ntector’s overall ability to distinguish between ID or\nnormal and OOD or anomalous samples. The ROC\ncurve plots the true positive rate (TPR) against the\nfalse positive rate (FPR), where:\nTPR = TP\nTP + FN , FPR = FP\nFP + TN\nHere, TP (true positives), TN (true negatives), FP\n(false positives), and FN (false negatives) corre-\nspond to the detector’s correct and incorrect classi-\nfications.\nAUPR (Area Under the Precision-Recall curve):\nThe AUPR metric is particularly useful for cases\nwhere there is class imbalance, as AUROC can\nbe biased in such situations. The Precision-Recall\ncurve plots precision against recall, where:\nPrecision = TP\nTP + FP , Recall = TP\nTP + FN\nFPR@N (False Positive Rate at TPR = N%):\nThis metric evaluates the probability of misclassify-\ning an OOD or anomalous sample as ID or normal\nwhen the true positive rate (TPR) is set at a speci-\nfied value, commonly 90% or 95%. This is crucial\nfor real-world deployments where achieving high\naccuracy on ID samples is important, while also\nminimizing false positives for OOD or anomaly\ndetection.\nF1 Score: The F1 score is a harmonic mean of\nprecision and recall, providing a balanced evalua-\ntion of a model’s performance across both metrics.\nIt is particularly useful in scenarios where there\nis an imbalance between the positive and negative\nclasses, as it gives a single metric that reflects both\nfalse positives and false negatives.\nThe F1 score is calculated as:\nF1 = 2×Precision ×Recall\nPrecision + Recall\nwhere:\nPrecision = TP\nTP + FP , Recall = TP\nTP + FN\nPrecision measures the proportion of true positive\npredictions out of all positive predictions made by\nthe model, while recall measures the proportion of\nactual positives correctly identified by the model.\nThere are two main variations of the F1 score:\n• Macro F1 Score : This version computes the\nF1 score independently for each class (ID and\nOOD, or normal and anomalous) and then takes\nthe average across classes. It treats all classes\nequally, making it particularly useful when the\nclass distribution is imbalanced.\n• Micro F1 Score : This version aggregates the\ncontributions of all classes to calculate the F1\n6026\nscore, considering the total number of true posi-\ntives, false positives, and false negatives across\nall classes. It is more sensitive to the performance\non the larger class.\nA high F1 score indicates that the model main-\ntains a good balance between precision (minimiz-\ning false positives) and recall (minimizing false\nnegatives), which is critical in practical OOD de-\ntection and anomaly detection tasks.\nF General Guidelines\nWe provide general guidelines for selecting ap-\npropriate approaches for anomaly or out-of-\ndistribution (OOD) detection, considering key fac-\ntors such as data modality, efficiency, explanation,\nand optimization.\nData Modality: The choice of approach is\nstrongly influenced by the type of data being an-\nalyzed. For textual data, prompting-based meth-\nods may not always offer meaningful interpreta-\ntions of anomalies or OOD detection, particularly\nwhen trying to understand patterns in semantic\nspaces. In these cases, generating embeddings\nfrom LLMs and applying specialized post-hoc de-\ntection techniques can lead to better results. Fine-\ntuning LLMs to produce more relevant embed-\ndings may further enhance detection accuracy. In\nthe case of numerical data, such as time series or\ntabular data, prompting-based methods have been\nexplored, though they often require carefully de-\nsigned prompts or fine-tuning to capture the un-\nderlying structure of the data. For vision data, in-\ncluding images and videos, the development of\nmultimodal LLMs offers greater flexibility. Both\nprompting-based and contrasting-based methods\ncan be highly effective, as they are capable of han-\ndling the diverse characteristics of multimodal data.\nEfficiency: Efficiency is a crucial considera-\ntion when choosing between prompting-based and\ncontrasting-based methods. Prompting-based meth-\nods can be inefficient for high-precision numerical\ntasks, as the conversion of numerical values into\ntext results in excessively long input sequences.\nThis inefficiency can become a bottleneck for tasks\ninvolving long-term predictions or large datasets,\nwhere the computational overhead of generating\nlong outputs becomes significant. In contrast,\ncontrasting-based methods are more efficient for\ndetection tasks for image. By utilizing contrastive\nobjectives to distinguish between positive and nega-\ntive samples, these methods excel at zero-shot clas-\nsification and are computationally more efficient,\nespecially for handling multimodal anomaly and\nOOD detection. Researchers can also explore the\nuse of contrasting-based approaches to numerical\ndata modalities with their visual representations.\nExplanation: In fields where transparency and\ninterpretability are critical, explanation plays a piv-\notal role in model selection. LLMs offer a unique\nadvantage by not only detecting anomalies but also\ngenerating human-like explanations. This capabil-\nity is especially valuable in domains where action-\nable insights and interpretable results are essential\nfor decision-making. Research should focus on en-\nhancing the ability of LLMs to explain their outputs\nin a way that aligns with domain-specific require-\nments for clarity and transparency.\nOptimization: The optimization strategy is\nhighly dependent on the specific data modality and\nthe nature of the detection task. For prompting-\nbased methods, parameter-efficient tuning tech-\nniques—such as Low-Rank Adaptation are essen-\ntial for improving model performance without in-\ncurring high computational costs. These techniques\nenable models to adapt to new tasks efficiently\nwhile maintaining their generalization capabilities.\nThis allows the broad generalization capabilities of\nLLMs to be leveraged while optimizing for specific\ndomain-related tasks, leading to improved accuracy\nand reduced computational overhead.\n6027"
}