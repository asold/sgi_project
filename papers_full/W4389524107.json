{
  "title": "Large Language Models are Complex Table Parsers",
  "url": "https://openalex.org/W4389524107",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2155163913",
      "name": "Bo-Wen Zhao",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A5111097611",
      "name": "Changkai Ji",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2137538350",
      "name": "Yuejie Zhang",
      "affiliations": [
        "Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2095727308",
      "name": "Wen He",
      "affiliations": [
        "Children's Hospital of Fudan University",
        "Shanghai Children's Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2630712365",
      "name": "Yingwen Wang",
      "affiliations": [
        "Shanghai Children's Medical Center",
        "Children's Hospital of Fudan University"
      ]
    },
    {
      "id": "https://openalex.org/A2042208499",
      "name": "Qing Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1997788646",
      "name": "Rui Feng",
      "affiliations": [
        "Children's Hospital of Fudan University",
        "Shanghai Children's Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2043530960",
      "name": "Xiao-bo Zhang",
      "affiliations": [
        "Shanghai Children's Medical Center",
        "Children's Hospital of Fudan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4289494028",
    "https://openalex.org/W2891991579",
    "https://openalex.org/W3035231859",
    "https://openalex.org/W4366342667",
    "https://openalex.org/W4377009978",
    "https://openalex.org/W4389520249",
    "https://openalex.org/W2119717200",
    "https://openalex.org/W2020608795",
    "https://openalex.org/W4386566488",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W3174481949",
    "https://openalex.org/W4389519321",
    "https://openalex.org/W4301674784",
    "https://openalex.org/W3166417463",
    "https://openalex.org/W4319793302",
    "https://openalex.org/W2963899988",
    "https://openalex.org/W2032655922",
    "https://openalex.org/W4362679254",
    "https://openalex.org/W4323570543",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3035140194",
    "https://openalex.org/W3197798882",
    "https://openalex.org/W4297778680",
    "https://openalex.org/W4221163895",
    "https://openalex.org/W4322717386",
    "https://openalex.org/W4306291596",
    "https://openalex.org/W4319452276",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4376653844",
    "https://openalex.org/W4210451781",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2751448157",
    "https://openalex.org/W4304194220",
    "https://openalex.org/W3101082165",
    "https://openalex.org/W4312600202",
    "https://openalex.org/W4364383757",
    "https://openalex.org/W4281557260"
  ],
  "abstract": "With the Generative Pre-trained Transformer 3.5 (GPT-3.5) exhibiting remarkable reasoning and comprehension abilities in Natural Language Processing (NLP), most Question Answering (QA) research has primarily centered around general QA tasks based on GPT, neglecting the specific challenges posed by Complex Table QA. In this paper, we propose to incorporate GPT-3.5 to address such challenges, in which complex tables are reconstructed into tuples and specific prompt designs are employed for dialogues. Specifically, we encode each cell’s hierarchical structure, position information, and content as a tuple. By enhancing the prompt template with an explanatory description of the meaning of each tuple and the logical reasoning process of the task, we effectively improve the hierarchical structure awareness capability of GPT-3.5 to better parse the complex tables. Extensive experiments and results on Complex Table QA datasets, i.e., the open-domain dataset HiTAB and the aviation domain dataset AIT-QA show that our approach significantly outperforms previous work on both datasets, leading to state-of-the-art (SOTA) performance.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 14786–14802\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nLarge Language Models are Complex Table Parsers\nBowen Zhao1, Changkai Ji2, Yuejie Zhang1, Wen He3, Yingwen Wang3,\nQing Wang3, Rui Feng123*, Xiaobo Zhang3*\n1 School of Computer Science, Shanghai Key Laboratory of Intelligent Information\nProcessing, Fudan University, Shanghai 200433, 2 Academy for Engineering and Technology,\nFudan University, Shanghai, 3 Children’s Hospital of Fudan University,\nNational Children’s Medical Center, Shanghai, China\n{bwzhao22,22210860023}@m.fudan.edu.cn, {fengrui,yjzhang,hewen}@fudan.edu.cn,\n{yingwenwong,zhangxiaobo0307,wq141269}@163.com\nAbstract\nWith the Generative Pre-trained Transformer\n3.5 (GPT-3.5) exhibiting remarkable reasoning\nand comprehension abilities in Natural Lan-\nguage Processing (NLP), most Question An-\nswering (QA) research has primarily centered\naround general QA tasks based on GPT, ne-\nglecting the specific challenges posed by Com-\nplex Table QA. In this paper, we propose to in-\ncorporate GPT-3.5 to address such challenges,\nin which complex tables are reconstructed into\ntuples and specific prompt designs are em-\nployed for dialogues. Specifically, we encode\neach cell’s hierarchical structure, position in-\nformation, and content as a tuple. By enhanc-\ning the prompt template with an explanatory\ndescription of the meaning of each tuple and\nthe logical reasoning process of the task, we\neffectively improve the hierarchical structure\nawareness capability of GPT-3.5 to better parse\nthe complex tables. Extensive experiments and\nresults on Complex Table QA datasets, i.e.,\nthe open-domain dataset HiTAB and the avi-\nation domain dataset AIT-QA show that our\napproach significantly outperforms previous\nwork on both datasets, leading to state-of-the-\nart (SOTA) performance.\n1 Introduction\nComplex tables, characterized by multi-level struc-\nture headers and numerous merged cells, are a\nprevalent data format that includes diverse data\ntypes and intricate associations among cells (Lim\nand Ng, 1999; Chen and Cafarella, 2014; Jin et al.,\n2022). In this context, the Complex Table QA task\nemerges as an important and challenging problem\nwithin the field of NLP.\nIn traditional Table QA tasks, the majority of re-\nsearch efforts focused on simple flat tables (i.e.,\ntables with single-level column headers and no\nmerged cells). Earlier, a substantial number of\n*Corresponding author\nFigure 1: The overall architecture of complex table pars-\ning. It achieves through table structure reconstruction\nand prompt template designing based on GPT-3.5. Texts\nin the pink background are prompts, where the bold text\ncan be replaced; texts in the yellow background mean\nthe format of the tables in the original dataset; and texts\nin the orange background represent the tables after refac-\ntoring. GPT-3.5 indicates the model text-davinci-003.\nOOL indicates that the number of tokens we requested\nexceeds the length limit of GPT-3.5. Code represents a\npiece of Python code we insert to assist multi-turn QA.\nstudies focused on improving the conversion of\nquestions into logical forms (e.g., SQLs and code)\nthat could be directly executed on tables to retrieve\nanswers (Jin et al., 2022; Dong et al., 2022). To\nthis end, a wide range of strategies has been in-\ntroduced, such as reinforcement learning, memory\nenhancement, type awareness, relationship aware-\nness, etc. (Pasupat and Liang, 2015; Zhong et al.,\n2017; Liang et al., 2018; Yu et al., 2018; Yin et al.,\n2020). In recent years, there has been a notable\nprogress of Large Language Models (LLMs), such\nas BERT (Devlin et al., 2019), GPT (Radford et al.,\n14786\n2018), GPT-2 (Radford et al., 2019), RoBERTa\n(Liu et al., 2019), GPT-3 (Brown et al., 2020), and\nT5 (Raffel et al., 2020) in the field of NLP. This\nenable the Table QA tasks to generate answers di-\nrectly without the need for intermediate logical\nforms, which leverage the rich language representa-\ntions and knowledge acquired through large-scale\ntext pre-training (Herzig et al., 2020; Chen et al.,\n2020; Eisenschlos et al., 2021; Yang et al., 2022;\nChen, 2023).\nWhile significant attainment has been made in\nthe studies above-mentioned, their primary empha-\nsis has been on the development of simple flat ta-\nbles, overlooking the ubiquitous complex tables.\nAlthough (Katsis et al., 2021; Cheng et al., 2022)\nendeavored to construct QA datasets, specifically\ntailored for complex tables, and evaluated the per-\nformance of the SOTA Table QA models, the out-\ncomes have not met expectations.\nMost recently, with the advent of ChatGPT1, an\nadvanced NLP model derived from GPT-3, has\nshowcased remarkable capabilities in generation\n(Maddigan and Susnjak, 2023; Dong et al., 2023;\nLiu et al., 2023a), contextual understanding (Bang\net al., 2023; Gao et al., 2023b; Amin et al., 2023),\nand reasoning (Liu et al., 2023b; Gao et al., 2023a),\nhas profoundly impacted on the field of NLP. A\nmultitude of research actively explores and lever-\nages the comprehension and generation abilities of\nChatGPT for QA tasks (Tan et al., 2023; Zuccon\nand Koopman, 2023; Wang et al., 2023; Singhal\net al., 2023). However, we have not come across\nany relevant work that harnesses the competencies\nof GPT-3.5 for Complex Table QA task as yet.\nIn this paper we first attempt to incorporate GPT-\n3.5 to achieve complex table parsing, in which com-\nplex tables are reconstructed into tuples and spe-\ncific prompt designs are employed for dialogues.\nAs illustrated in Figure 1, we reconstruct the table\nstored in JSON format into tuples, incorporating\nthe hierarchical information, position information,\nand the value of each cell into different elements\nof the tuple. Subsequently, we fill in and calculate\nthe length using the designed single-turn dialogue\nprompt templates. If the token count does not ex-\nceed the limit of GPT-3.5, we adopt a single-turn\ndialogue scheme for QA task. Otherwise, we uti-\nlize multi-turn dialogue scheme, in which we break\ndown the question into sub-questions based on the\nlogic of the single-turn prompt and introduce a\n1https://openai.com/blog/chatgpt\ncode snippet to facilitate the answering process.\nThrough careful study and meticulous experimen-\ntal analysis, we conclude that GPT-3.5 can be a\ngreat parser for complex tables.\nTo sum up, the contributions of this paper are:\n• We present a novel approach that leverages\nGPT-3.5 as a parser to address Complex Table\nQA tasks, which enhances the ability of the\nmodel to perceive the hierarchical structure\nof complex tables by restructuring the data\nformat and devising prompt templates.\n• We resolve the constraint on the input token\nlimitation for GPT-3.5 by crafting single-turn\nand multi-turn dialogue prompts tailored to\ncomplex tables of different lengths, as well as\nincorporating code snippets for assistance in\nmulti-turn dialogue.\n• Extensive experiments are conducted on both\npubic benchmark datasets (i.e., HiTAB and\nAIT-QA), and the results show that our\nmethod outperforms the SOTA methods.\n2 Related Works\n2.1 Complex Table Question Answering\nComplex table QA tasks refer to information re-\ntrieval and answer generation on complex tables\ncontaining multi-level headers and a large num-\nber of merged cells. In previous work, most re-\nsearch has focused on the simple flat table dataset,\nsuch as SQA (Pasupat and Liang, 2015), Spider\n(Yu et al., 2019), Hybridq (Chen et al., 2020), Fe-\nTaQA (Nan et al., 2021), etc. Recently, (Katsis\net al., 2021) introduced the domain-specific Ta-\nble QA dataset AIT-QA, which consists of 515\nQA pairs authored by human annotators on 116\ntables, and experimented with the most popular\nTable QA models, such as TaPAS (Herzig et al.,\n2020), TaBERT (Yin et al., 2020), and RCI (Glass\net al., 2021), but the results were not satisfactory.\n(Cheng et al., 2022) also proposed a new dataset\nHiTab, which contains 10,672 QA pairs based on\n3,597 complex tables from open-domain, and ex-\namined with Table QA models, but the results fell\nshort of expectations. Furthermore, they proposed\na hierarchy-aware-based method, which improved\nthe performance on complex tables with the models\ntrained on simple flat tables. However, the perfor-\nmance of these models on simple flat tables still\noutperformed the hierarchy-aware-based method.\n14787\nFigure 2: The illustration of table reconstruction. First, we rewrite the rows and column headers of the input\nJSON-formatted table into a tree structure, where, except for the root node, all nodes have a unique precursor node.\nMoreover, we encode the \"Hierarchical-Index\" of row and column headers according to the hierarchy sequence\nnumber of the tree. For example, \"Col 1\" indicates that 2018, 2017, 2016, the three headers are all located at the\nfirst layer of column header, and the encoding is 1. In addition, we encode the row and column position information\nof the header, for example, the \"Column Position Index\" of 2018 is 0, the \"Column Position Index\" of 2017 is 1,\netc. Finally, we encode each cell in the table based on \"Hierarchical-Index\", \"Row Position Index\", and \"Column\nPosition Index\". In the refactored table, the \"Non-header\" represents the cell other than the \"Column Header\" and\n\"Row Header\", and the \"Title\" represents the table title.\nDifferent from them, we propose to reconstruct the\ntable format and design suitable prompt templates\nto fully unleash the comprehension and reasoning\npower of GPT-3.5, which exhibits outstanding per-\nformance on both complex table datasets.\n2.2 Prompt Engineering\nPrompt Engineering refers to making better use\nof the knowledge from the pre-training model by\nadding additional texts to the input. In the era of\nLLM, (Wei et al., 2023) proposed a new method\ncalled chain-of-thought (CoT), a series of inter-\nmediate reasoning steps to unleash the power of\nLLMs to perform complex reasoning. Soon, (Ko-\njima et al., 2023) proved LLMs to be an effec-\ntive zero-shot reasoners by incorporating \"Let’s\nthink step by step\" before each answer. (Zhang\net al., 2022) also proposed Auto-CoT (automatic\nchain-of-thought), which could generate prompts\nautomatically. However, the power of LLMs as\ngood reasoners has not been applied to implement\ncomplex table parsing. In this paper, we specifi-\ncally focus on designing the appropriate prompts\nto make full use of the remarkable understanding\nand reasoning capabilities of GPT-3.5 to realize the\nstructure-awareness of complex tables.\n3 Method\nIn this section, we reconstruct the table from JSON-\nformatted to tuples (Section 3.1). To better leverage\nthe reasoning and generation capabilities of GPT-\n3.5, we introduce the single-turn prompts designed\nfor tables that do not exceed the API input limit on\ntokens (Section 3.2) and the multi-turn prompts for\ntables that exceed the limit. Moreover, we add a\npiece of code to assist question answering in multi-\nturn QA (Section 3.3). Here, we use Python for\ncoding and calling API.\n3.1 Table Reconstruction\nAs shown in Figure 2, we reconstruct the table from\nJSON-formatted to tuples. For the row and column\nheaders, we encode each cell as a five-tuple. The\nfirst element in the tuple serves as the label to in-\ndicate that it represents the row or column header\n(T stands for column header and L stands for row\nheader). The second element denotes the hierar-\nchical index of the cell, while the third element\nrepresents the ordinal number of the cell’s start-\ning row or column. The fourth element signifies\nthe cell’s ending row or column number, and the\nfifth element encapsulates the cell’s value. For non-\nheader cells, we utilize a quadruple to depict each\n14788\n(a) An example of Single-Turn Dialogue.\n (b) An example of Multi-Turn Dialogue.\nFigure 3: Examples of Single-Turn and Multi-Turn Dialogue.\ncell. The first element in the tuple designates the\nlabel, indicating that it pertains to a non-header cell.\nThe second element represents the row number of\nthe cell, while the third element signifies the col-\numn number of the cell. Lastly, the fourth element\nencapsulates the value of the cell. For example, (L,\n0, 0, 3, \"Compensation cost:\") means that the tuple\nis a row header with hierarchical-index 0, starting\nat row position index 0, ending at row position\nindex 3, and the value is \"Compensation cost:\".\nWe successfully integrate the category informa-\ntion, position information, and value of each cell\nin the complex table, as well as the hierarchical\ninformation of the row and column headers into the\ntuple by table reconstruction. Thus, not only the\ninformation of the whole table is clearly expressed,\nbut also the problem of token numbers beyond the\nlimit caused by the information redundancy of the\noriginal format can be solved.\n3.2 Single-Turn Prompt\nIn this section, we adopt a single-turn dialogue\nscheme for complex tables that do not exceed the\nlimit of the API input token. As shown in Figure\n3(a), we reformulate the prompt of a single-turn\ndialogue into Regulations and Input Context.\n• Regulations aim to dictate and guide the be-\nhavior of GPT-3.5 to make it more capable\nof reasoning on complex tables. In Figure\n3(a), we make the role assumption of GPT-\n3.5, and the reconstructed table is described in\ndetail and illustrated with examples. Also, we\nprovide a detailed description of CoT for the\nentire Complex Table QA task to drive GPT-\n3.5 starting at the top level header, to find the\nrelevant sub-headers layer by layer and locate\nthe non-header cells by the location informa-\ntion in header tuples. It is worth noting that in\nthe part of \"Output Control\", we require the\nmodel to output the selected \"Column header\",\n14789\n\"Row header\", \"Cell\", \"Operation\" and \"An-\nswer\" in return. In this way, we can better\nevaluate the reasoning and understanding abil-\nities of the model (See Appendix A.1 for more\ndetails of single-turn prompt).\n• Input Context contains a large number of\nfill slots, which can be filled at: \"title: []\",\n\"column header: []\", \"row header: []\", \"Q:\n\"\"\" according to different QA pairs, where\n\"title\" represents the title of the table, \"col-\numn header\"and \"row header\"refers to the\ncolumn headers and row headers of the table\nrespectively, and \"Q\" denotes the question.\nGive the input in Figure 3(a) as an example,\n\"title: [tab-102]\" is generated by filling \"title:\n[]\" with \"tab-102\".\n3.3 Multi-Turn Prompt and Code Assistant\nIn multi-turn dialogue, as shown in Figure 3(b),\nsimilar to the single-turn dialogue, we partition the\nprompt into two components: Regulations and In-\nput Context. However, we divide the dialogue into\nthree turns with four modules. More specifically,\nwe not only split the Chain-of-thought in the Regu-\nlations part of the single-round dialogue and assign\nit to the three turns of the multi-turn dialogue, but\nalso move the Output Controlpart to the last turn\nof the dialogue. It is worth noting that we add a\npiece of code in the third module to assist the cell\nselection.\n• In the first module(i.e., the first prompt turn),\nwe extract the keywords from the question.\n• In the second module (i.e., the second\nprompt turn), we pick the relevant tuples in\nthe row and column header tuples and record\nthem based on the keywords we select in the\nfirst prompt turn.\n• In the third module (i.e., the code assistant\nmodule), we incorporate a code snippet to fa-\ncilitate the dialogue. Specifically, we pass\nthe row and column header tuples selected in\nthe second round of dialogue into the third\nmodule, extract the row and column position\ninformation in these tuples through the code,\nand retrieve the non-header tuples of the ta-\nble based on this position information. All\nthe tuples matching the location information\nare returned and passed to the last module.\nThis optimization expedites the experiment by\nFigure 4: Schematic comparison of the answers gen-\nerated by GPT-3.5 with the original answers. GPT-3.5\nrepresents the answers generated by text-davinci-003.\nOri represents the standard answer in the dataset. Texts\nin the green background represent the question. Texts\nin the blue background represent the answer.\nDatasetTablenumber\nQA Pair Average numberof tokens Domain\nTrain Dev Test Total\nHiTAB3,597 7,417 1,671 1,584 10,672 2,521 Open domain\nAIT-QA116 - - - 515 115 Domain specific\nTable 1: Dataset statistics. Average number of tokens\nrepresents the average number of tokens after tokenizing\nthe table in the original format when calling API.\nmitigating the relatively slow API calls, and\nsignificantly enhances the results by reducing\nthe accumulation of errors resulting from the\nmulti-turn dialogue.\n• In the fourth module (i.e., the third prompt\nturn), we prompt GPT-3.5 for all relevant row\nheaders, column headers, and non-header tu-\nples, ask questions, and require the model to\nanswer them in our prescribed format.\n4 Experiment\n4.1 Datasets\nWe evaluate our approach on Complex Table QA\ntask with HiTab (Cheng et al., 2022) and AIT-QA\n(Katsis et al., 2021). As shown in Table 1, we\nprovide the statistical results of the datasets and\ncalculate the average length of the tokenized table.\nMoreover, it can be seen in Table 3 that the AIT-QA\ndataset is divided into four subsets. According to\nwhether the question is related to Key Performance\nIndicators (KPIs), the dataset is divided into \"KPI-\ndriven\" and \"Table-driven\". Similarly, AIT-QA is\nalso divided into \"Row header hierarchy\" and \"No\nrow header hierarchy\", according to whether the\nanswer relies on the row header hierarchy.\nIt is worth noting that the data in HiTAB comes\nfrom statistical reports across 28 different fields\nand Wikipedia, offering rich table information with\n14790\ncomplex structures. In contrast, the data in AIT-\nQA are all selected from airline companies, and the\ninformation and hierarchical structures contained in\nthe tables are relatively simple compared to HiTAB.\n4.2 Baselines\nSince we have not found any further work related\nto HiTAB and AIT-QA, we compare our work\nwith the evaluation results in their original paper,\nincluding 1) supervision-based method: MAPO\n(Liang et al., 2018), TaPas (Herzig et al., 2020),\nMML (Dempster et al., 1977) and REINFORCE\n(Williams, 1992); and 2) zero-shot-based methods:\nTaBERT (Yin et al., 2020), TaPas (Herzig et al.,\n2020) and RCI (Glass et al., 2021).\n4.3 Evaluation\nBecause of the presence of a substantial number\nof non-numerical type answers in the datasets, di-\nrect alignment or similarity evaluation cannot effec-\ntively assess our method. As illustrated in Figure 4,\nit is evident that the answers generated by GPT-3.5\nhave essentially the same meaning as the original\nanswer. However, there exists a notable difference\nin their representation. The model-generated an-\nswers tend to provide more intricate details, while\nthe original answers exhibit a more concise nature.\nTherefore, we use Accuracy as our evaluation met-\nric following (Cheng et al., 2022), which indicates\nthe percentage of QA pairs with correct answers,\nto align whether the generated answers are equiva-\nlent to the original answers in the case of a specific\nquestion and context (i.e., table content).\n4.4 Model\nWe conduct experiments mainly with the text-\ndavinci-003 from OpenAI, which is improved on\nGPT-3 and can understand as well as generate nat-\nural language or code. Text-davinci-003 supports\n4,097 input tokens at most, which means that the\ncombined count of the input tokens and the gener-\nated tokens can not exceed 4,097.\n4.5 Results\n4.5.1 Main Results\nThe results on HiTAB are shown in Table 2. Specif-\nically, the absolute accuracy improvement of 5.5 on\nthe Dev set and 9.3 on the Test set. Specifically, the\nabsolute accuracy improvement of 5.5 on the Dev\nset and 9.3 on the Test set can be observed if com-\npared to the previous best weak supervision method\nMAPO with the hierarchy-aware logical form on\nMethod Dev Test\nWeak Supervision MAPOw. original logical form31.9 29.2\n(Cheng et al., 2022) TaPasw/o. logical form 39.7 38.9\nMMLw. h.a. logical form 38.9 36.7\nREINFORCEw. h.a. logical form42.7 38.4\nMAPOw. h.a. logical form 43.5 40.7\nPartial Supervision TaPasw/o. logical form 41.2 40.1\n(Cheng et al., 2022) MMLw. h.a. logical form 45.4 45.1\nREINFORCEw. h.a. logical form44.0 39.7\nMAPOw. h.a. logical form 44.8 44.3\nZero-shot Ours w. GPT-3.5 49.0 50.0\nTable 2: Accuracy on dev/test of HiTAB. h.a. stands for\nhierarchy-aware.\nData subset Models Ours\nTaBERT TaPaS RCI Single-turn Multi-turn All\nKPI-driven 41.37 48.26 60.00 76.92 66.67 74.48\nTable-driven 31.08 50.0 48.64 76.67 80.0071.84\nRow header hierarchy 21.92 47.26 45.8961.72 61.11 61.64\nNo row header hierarchy 38.75 50.39 54.2082.23 78.95 81.84\nOverall 33.98 49.32 51.84 76.73 70.27 76.26\nTable 3: Accuracy on AIT-QA. We compare with other\nbaselines: TaBERT, TaPaS, RCI (Katsis et al., 2021).\nHiTAB. Among the partial supervision methods on\nHiTAB, our approach still outperforms previous\nworks by a large margin. Table 3 reports the results\non AIT-QA. In the context of zero-shot learning,\nthe accuracy of our method outperforms TaBERT,\nTaPas, and RCI by 42.28, 26.94, and 24.42 on the\noverall dataset, respectively. Combining the results\non these two datasets, it can be demonstrated that\nGPT-3.5 can achieve the parsing of complex tables\ngiven appropriate data format and prompt.\n4.5.2 Results on HiTAB\nAs shown in Table 2, our method outperforms all\nprevious methods by over 3.5 in accuracy across the\nboard. At the same time, it can be seen from Table\n4 that, the results of the single-turn dialogue are\nsignificantly higher than the overall results. These\nindicate that our approach of leveraging the Large\nLanguage Model as a parser for complex tables\nis effective. In multi-turn dialogue, our method\nachieves 43.5 and 47.0 accuracy on the Dev and\nTest sets, respectively. Notice that, our work is built\nupon the framework of zero-shot learning, differing\nfrom the supervised methods utilized in previous\nstudies. Even if our results may not consistently\nsurpass those of these previous works, we assert\nour method is still comparable to the SOTA as\nreported in the original paper (Cheng et al., 2022)\nAlthough the training set is also applicable, we\nfind it performs slightly worse partially due to the\n14791\nTrain Dev Test Overall\nSingle-turn 52.0 51.1 51.1 51.7\nMulti-turn 40.8 43.5 47.0 42.1\nOverall 48.9 49.0 50.0 49.3\nTable 4: Accuracy of different dialogue schemes on\ntrain/dev/test/overall of HiTAB.\ndataset bias.\n4.5.3 Results on AIT-QA\nWe divide the AIT-QA dataset into four subsets\naccording to the method in the original paper (Kat-\nsis et al., 2021), and analyze them separately, as\nshown in Table 3. Overall, compared to other mod-\nels trained on tabular data, our method soundly\noutperforms all previous works. The overall accu-\nracy of single-turn dialogue reaches 76.73, and of\nmulti-turn dialogue, it reaches 70.27, which is a sig-\nnificant leap compared to the 51.84 accuracy of the\nthe previous best method RCI (Glass et al., 2021).\nFurthermore, our method achieves the best results\non two subsets \"KPI-driven\" and \"Table-driven\",\nrespectively, as well as on two subsets determined\nby whether or not the answer relies on the row\nheader hierarchy. It is noteworthy that, on the AIT-\nQA dataset, GPT-3.5 still exhibits a trend where\nthe accuracy of single-turn dialogue is generally\nhigher than that of multi-turn dialogue. We con-\nsider that this is due to the inability of multi-turn\ndialogue to preserve historical information, result-\ning in information loss and the accumulation of\nerrors throughout multiple interactions.\nIn addition, an absolute improvement over pre-\nvious work is achieved on all subsets of AIT-QA.\nThe results on subsets \"Row header hierarchy\" and\n\"No row header hierarchy\" show that the accuracy\nof answers that do not rely on the row header hier-\narchy is significantly higher than those that do rely\non it. We attribute this to a bias in the attention of\nGPT-3.5 to row and column headers.\n4.6 Ablation Study\nAs shown in Table 5, we conduct ablation exper-\niments on the HiTAB and AIT-QA datasets. The\nresults indicate that by restructuring the tables and\nintegrating the restructured structural information\nwith the CoT design prompts for the Complex Ta-\nble QA task, the ability of GPT-3.5 to parse com-\nplex tables is significantly enhanced. Simultane-\nously, there is a notable reduction in the instances\nwhere the model responds with \"I don’t know.\"\nAccuracy Idn\nHiTAB\nTable w. spt & w/o. ref 20.3 9.9\nTable w. mpt & w. ref 49.3 0.6\nAIT-QA\nTable w. spt & w/o. ref 64.7 14.2\nTable w. mpt & w. ref 76.3 0.2\nTable 5: Ablation sresults on HiTAB and AIT-QA.spt\nrepresents a simple prompt. mpt represents the prompt\nthat combines the information of the reconstructed table\nwith the CoT design of Complex Table QA. ref repre-\nsents a JSON-formatted table. Idn stands for \"I don’t\nknow\". We ask the model to answer \"I don’t know\" if it\ncould not infer the answer based on the existing context\nin the prompt. Please refer to Appendix A.1, A.2 and\nA.3 for more details.\nThis demonstrates that our method can effectively\nimprove the perception ability of the model regard-\ning complex table structures, and consequently en-\nhance its capacity to analyze complex tables.\n5 Analysis\nThe results show that our method proposed for com-\nplex table parsing based on GPT-3.5 effectively out-\nperforms the optimal methods on the existing two\ncomplex table datasets. However, compared to the\nsignificant performance with single-turn dialogue,\nthe accuracy with multi-turn dialogue, especially\non the HiTAB dataset, performs slightly worse. We\nfurther analyze the results in this section.\n5.1 Effects of the Input Token Limit\nDue to the inherent length of complex tables, as\nseen in Table 1, filling them into prompt templates\nincreases the likelihood of exceeding the input to-\nken limit of GPT-3.5, which has the following im-\nplications for our task.\n5.1.1 Context Truncation\nThe excessive length of the input text leads to con-\ntext truncation, resulting in the omission of critical\ninformation. As shown in Table 5, the accuracy\non the HiTAB dataset is quite low without table\nreconstruction, which is attributed to the fact that\nafter filling the prompt template slot with the table\ninformation, a large number of prompts exceed the\ninput token limit, and the direct truncation of the\ncontext leads to the missing of valuable informa-\ntion. As a solution, we employ a combination of\nsingle-turn and multi-turn dialogues to accomplish\ncomplex table QA.\n14792\nFigure 5: An example of hallucination of GPT-3.5.\n5.1.2 Trade-off between Depth and Breadth\nWhen opting for single-turn dialogue for Complex\nTable QA, we input all information at once. The\nmodel is exposed to a wide and comprehensive\nrange of information sources, but due to the ab-\nsence of interactive prompts, its ability to focus\non key information in the questions and tables is\nlimited. In contrast, when employing multi-turn\ndialogue, through continuous interactive prompt-\ning, we consistently guide the model to identify\nkey information from each dialogue turn. We then\nutilize this information to further prompt the model\nin subsequent turns. Multi-turn dialogue enables\nthe model to be more focused on key information,\nbut there is a possibility that it may overlook the\nglobal context.\nAdditionally, given that GPT-3.5 cannot auto-\nmatically retain historical conversations, errors ac-\ncumulate as dialogue turns increase, rendering the\nanswers increasingly prone to inaccuracy.\n5.1.3 Prompt Design Limitation\n(Pan et al., 2023) pointed out that providing both ex-\namples and descriptions in prompt can effectively\nimprove the performance of ChatGPT. However,\ndue to the length of the complex table, we cannot\nprovide an example with complete dialogue and\ndescription in the prompt concurrently.\n5.2 Effect of Hallucination\nHallucination refers to the generation of content\nthat may seem plausible but is not grounded in the\nsource information or is outright incorrect. As seen\nin the Figure 5, when we pose the question, \"were\nwomen still living in a private dwelling on census\nday 2011more likelyto be unmarried or were those\nliving in an nh at the time of the cchs interview?\",\nGPT-3.5 responded with \"Women\" and further pro-\nvided a detailed explanation stating \"(57.5% vs\n72.4%)\". Evidently, if we make our selection based\non the analysis provided in the answer, the appro-\npriate response would be \"women living in an n\",\nwhich refers to a \"nursing home\".\n5.3 Effect of Hierarchical Row Header\nIn conjunction with Table 3, it can be observed\nthat the performance of not only our method but\nalso others on the subset \"Row header hierarchy\"\nbegins to decline when the answer relies on the row\nheader hierarchy compared with the subset \"No\nrow header hierarchy\".\nDuring the analysis of experimental results on\nthe HiTAB dataset, we also encountered the same\nissue: the model exhibits different levels of atten-\ntion to row headers and column headers in tables.\nUnder the same data format and prompt conditions,\nGPT-3.5 typically tends to focus more on column\nheaders. We consider that this behavior might be\nattributed to the inherent ability of GPT-3.5 to in-\nterpret tables in markdown format, which typically\nonly has column headers or places emphasis on\nthem. Consequently, when attempting to under-\nstand tables in a new format, GPT-3.5 may transfer\nits prior knowledge, thereby affecting its parsing\nof the new tables.\n5.4 Error Analysis\nWe randomly sample 50 instances, each from the\nerroneous results of single-turn dialogue and multi-\nturn dialogue, and analyze them in terms of the\naccuracy in the row and column header localiza-\ntion and cell selection. The results indicate that\nthe errors are primarily attributed to the model ei-\nther locating incorrect row and column headers or\nlocating too few row and column headers.\nIn the analysis of single-turn dialogue and multi-\nturn dialogue, it can be found that errors are mainly\ncaused by incorrect localization of row and col-\numn headers. When the model locates non-header\ntuples based on incorrect or incomplete row and\ncolumn header tuples, it tends to make erroneous\nselections. Furthermore, when the model selects a\nbroad range of row and column headers, the num-\nber of non-header tuples that are selected based on\nthem increases. The excess information can also\nlead to incorrect selections (another main reason\nfor the erroneous answers of the model). This sug-\ngests that the comprehension capability of GPT-3.5\nmight decline when the input content is lengthy\nand complex. In addition, the model sometimes\nchooses the wrong cells even under the guidance of\ncorrect row and column headers, such as generat-\ning fictitious answers on their own, indicating that\nGPT-3.5 is sometimes prone to hallucinations.\n14793\n6 Conclusion\nInspired by the powerful reasoning and genera-\ntion capabilities of LLMs, we propose to lever-\nage GPT-3.5 as a parser for complex tables with\ntable reformat and prompt design. Extensive ex-\nperiments show that our method achieves the best\nperformance on HiTAB and AIT-QA. However,\nlimited by the input length and inability to store\nhistorical information of GPT-3.5, how to utilize\nmulti-turn dialogue to obtain more valuable context\nfor Complex Table QA remains to be explored.\nLimitations\nWhen utilizing GPT-3.5, a generative model, for\nthe Complex Table QA task, comparing its gener-\nated outputs to the original answers is an important\nissue.\n• GPT-3.5 typically generates answers in its\nown words. When paraphrasing the informa-\ntion from the context or that it has learned\nduring training, it may provide details that\ndo not align in granularity with the original\nanswer.\n• GPT-3.5 is unstable. When posing the same\nquestion within the same context, it does not\nalways provide consistent responses.\n• GPT-3.5 is prone to hallucinations. It is ca-\npable of generating answers that bear no rel-\nevance to the original text or the original an-\nswer.\nGiven these issues, it is important to define an\nevaluation metric that takes into account the com-\nplexity and variability of the responses generated\nby GPT-3.5.\nAcknowledgements\nWe deeply indebted to the anonymous reviewers\nfrom EMNLP for their constructive feedback. We\nare also express our gratitude to our tutors and\npeers for their invaluable insights and unflagging\nsupport throughout the course of this research. This\nwork is also supported by National Natural Science\nFoundation of China (No.62172101); and by the\nScience and Technology Commission of Shanghai\nMunicipality (No.22511106000); and Regional so-\ncial experimentation with the \"Clinical Decision\nSupport System for Paediatric Outpatient Clinics\"\n(PROJECT NO: 21002411800); and Auxiliary Di-\nagnosis and Rare Disease Screening System for\nChildren’s Pneumonia (No.yg2022-7).\nReferences\nMostafa M. Amin, Erik Cambria, and Björn W. Schuller.\n2023. Will affective computing emerge from foun-\ndation models and general ai? a first evaluation on\nchatgpt.\nYejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wen-\nliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei\nJi, Tiezheng Yu, Willy Chung, Quyet V . Do, Yan\nXu, and Pascale Fung. 2023. A multitask, multilin-\ngual, multimodal evaluation of chatgpt on reasoning,\nhallucination, and interactivity.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot\nlearners. Advances in neural information processing\nsystems, 33:1877–1901.\nWenhu Chen. 2023. Large language models are few(1)-\nshot table reasoners.\nWenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong,\nHong Wang, and William Wang. 2020. Hybridqa: A\ndataset of multi-hop question answering over tabular\nand textual data. arXiv preprint arXiv:2004.07347.\nZhe Chen and Michael Cafarella. 2014. Integrating\nspreadsheet data via accurate and low-effort extrac-\ntion. In Proceedings of the 20th ACM SIGKDD in-\nternational conference on Knowledge discovery and\ndata mining, pages 1126–1135.\nZhoujun Cheng, Haoyu Dong, Zhiruo Wang, Ran Jia,\nJiaqi Guo, Yan Gao, Shi Han, Jian-Guang Lou, and\nDongmei Zhang. 2022. Hitab: A hierarchical table\ndataset for question answering and natural language\ngeneration.\nArthur P Dempster, Nan M Laird, and Donald B Rubin.\n1977. Maximum likelihood from incomplete data\nvia the em algorithm. Journal of the royal statistical\nsociety: series B (methodological), 39(1):1–22.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning.\nHaoyu Dong, Zhoujun Cheng, Xinyi He, Mengyu Zhou,\nAnda Zhou, Fan Zhou, Ao Liu, Shi Han, and Dong-\nmei Zhang. 2022. Table pretraining: A survey\non model architectures, pretraining objectives, and\ndownstream tasks. arXiv preprint arXiv:2201.09745.\nYihong Dong, Xue Jiang, Zhi Jin, and Ge Li. 2023.\nSelf-collaboration code generation via chatgpt.\n14794\nJulian Martin Eisenschlos, Maharshi Gor, Thomas\nMüller, and William W Cohen. 2021. Mate: multi-\nview attention for table transformer efficiency. arXiv\npreprint arXiv:2109.04312.\nJinglong Gao, Xiao Ding, Bing Qin, and Ting Liu.\n2023a. Is chatgpt a good causal reasoner? a compre-\nhensive evaluation.\nYuan Gao, Ruili Wang, and Feng Hou. 2023b. How to\ndesign translation prompts for chatgpt: An empirical\nstudy.\nMichael Glass, Mustafa Canim, Alfio Gliozzo, Sa-\nneem Chemmengath, Vishwajeet Kumar, Rishav\nChakravarti, Avi Sil, Feifei Pan, Samarth Bharad-\nwaj, and Nicolas Rodolfo Fauceglia. 2021. Cap-\nturing row and column semantics in transformer\nbased question answering over tables. arXiv preprint\narXiv:2104.08303.\nJonathan Herzig, Paweł Krzysztof Nowak, Thomas\nMüller, Francesco Piccinno, and Julian Martin Eisen-\nschlos. 2020. Tapas: Weakly supervised table parsing\nvia pre-training. arXiv preprint arXiv:2004.02349.\nNengzheng Jin, Joanna Siebert, Dongfang Li, and Qing-\ncai Chen. 2022. A survey on table question answer-\ning: Recent advances.\nYannis Katsis, Saneem Chemmengath, Vishwajeet Ku-\nmar, Samarth Bharadwaj, Mustafa Canim, Michael\nGlass, Alfio Gliozzo, Feifei Pan, Jaydeep Sen,\nKarthik Sankaranarayanan, et al. 2021. Ait-qa: ques-\ntion answering dataset over complex tables in the\nairline industry. arXiv preprint arXiv:2106.12944.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2023. Large lan-\nguage models are zero-shot reasoners.\nChen Liang, Mohammad Norouzi, Jonathan Berant,\nQuoc V Le, and Ni Lao. 2018. Memory augmented\npolicy optimization for program synthesis and se-\nmantic parsing. Advances in Neural Information\nProcessing Systems, 31.\nSeung-Jin Lim and Yiu-Kai Ng. 1999. An automated\napproach for retrieving hierarchical data from html\ntables. In Proceedings of the eighth international\nconference on Information and knowledge manage-\nment, pages 466–474.\nChao Liu, Xuanlin Bao, Hongyu Zhang, Neng Zhang,\nHaibo Hu, Xiaohong Zhang, and Meng Yan. 2023a.\nImproving chatgpt prompt for code generation.\nHanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji\nZhou, and Yue Zhang. 2023b. Evaluating the logical\nreasoning ability of chatgpt and gpt-4.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nPaula Maddigan and Teo Susnjak. 2023. Chat2vis: Gen-\nerating data visualisations via natural language us-\ning chatgpt, codex and gpt-3 large language models.\nIEEE Access.\nLinyong Nan, Chiachun Hsieh, Ziming Mao, Xi Victoria\nLin, Neha Verma, Rui Zhang, Wojciech Kry´sci´nski,\nNick Schoelkopf, Riley Kong, Xiangru Tang, Murori\nMutuma, Ben Rosand, Isabel Trindade, Renusree\nBandaru, Jacob Cunningham, Caiming Xiong, and\nDragomir Radev. 2021. Fetaqa: Free-form table ques-\ntion answering.\nWenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che,\nand Libo Qin. 2023. A preliminary evaluation of\nchatgpt for zero-shot dialogue understanding. arXiv\npreprint arXiv:2304.04256.\nPanupong Pasupat and Percy Liang. 2015. Composi-\ntional semantic parsing on semi-structured tables.\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\nSutskever, et al. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, 1(8):9.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. The Journal of Machine Learning Research,\n21(1):5485–5551.\nKaran Singhal, Tao Tu, Juraj Gottweis, Rory Sayres,\nEllery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl,\nHeather Cole-Lewis, Darlene Neal, Mike Schaeker-\nmann, Amy Wang, Mohamed Amin, Sami Lachgar,\nPhilip Mansfield, Sushant Prakash, Bradley Green,\nEwa Dominowska, Blaise Aguera y Arcas, Nenad\nTomasev, Yun Liu, Renee Wong, Christopher Sem-\nturs, S. Sara Mahdavi, Joelle Barral, Dale Webster,\nGreg S. Corrado, Yossi Matias, Shekoofeh Azizi,\nAlan Karthikesalingam, and Vivek Natarajan. 2023.\nTowards expert-level medical question answering\nwith large language models.\nYiming Tan, Dehai Min, Yu Li, Wenbo Li, Nan Hu,\nYongrui Chen, and Guilin Qi. 2023. Evaluation of\nchatgpt as a question answering system for answering\ncomplex questions.\nZezhong Wang, Fangkai Yang, Pu Zhao, Lu Wang,\nJue Zhang, Mohit Garg, Qingwei Lin, and Dong-\nmei Zhang. 2023. Empower large language model to\nperform better on industrial domain-specific question\nanswering.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\nDenny Zhou. 2023. Chain-of-thought prompting elic-\nits reasoning in large language models.\n14795\nRonald J Williams. 1992. Simple statistical gradient-\nfollowing algorithms for connectionist reinforcement\nlearning. Reinforcement learning, pages 5–32.\nJingfeng Yang, Aditya Gupta, Shyam Upadhyay,\nLuheng He, Rahul Goel, and Shachi Paul. 2022.\nTableformer: Robust transformer modeling for table-\ntext encoding. arXiv preprint arXiv:2203.00274.\nPengcheng Yin, Graham Neubig, Wen-tau Yih, and Se-\nbastian Riedel. 2020. Tabert: Pretraining for joint\nunderstanding of textual and tabular data. arXiv\npreprint arXiv:2005.08314.\nTao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and Dragomir\nRadev. 2018. Typesql: Knowledge-based type-\naware neural text-to-sql generation. arXiv preprint\narXiv:1804.09769.\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li, Qingn-\ning Yao, Shanelle Roman, Zilin Zhang, and Dragomir\nRadev. 2019. Spider: A large-scale human-labeled\ndataset for complex and cross-domain semantic pars-\ning and text-to-sql task.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2022. Automatic chain of thought prompting\nin large language models.\nVictor Zhong, Caiming Xiong, and Richard Socher.\n2017. Seq2sql: Generating structured queries from\nnatural language using reinforcement learning. arXiv\npreprint arXiv:1709.00103.\nGuido Zuccon and Bevan Koopman. 2023. Dr chatgpt,\ntell me what i want to hear: How prompt knowledge\nimpacts health answer correctness.\nA Appendix\nA.1 Single-Turn Prompt\nThe Regulation and Input Context parts of the\nsingle-turn dialogue prompt are detailed in Tables\n6 and 7, respectively.\nA.2 Multi-Turn Prompt\nAs shown in 8, 9 and 10, we describe the prompt\nof the first, second and third prompt turn in detail.\nA.3 Simple Prompt\nTable 11 shows the full text of a specific prompt\ndesigned for the original table format.\n14796\nRegulations\n# Role play\nSuppose you are an expert in statistical analysis.\nYou will be given a table described in a special format.\nYour task is to answer the questions based on the content of the table.\n# Table Description\nThe table is described as follows:\n1. The title means the title of the table.\n2. A tuple (T, T1, T2, T3, T4) represents a column header, where T indicates it’s a column header,\nT1 denotes its level, T2 and T3 indicate the start and end column of the header, and T4 specifies the\ncontent.\n3. A tuple (L, L1, L2, L3, L4) represents a row header, where L indicates it’s a row header, L1\ndenotes its level, L2 and L3 indicate the start and end row of the header, and L4 specifies the\ncontent.\n4. We represent non-header tuples as (C, C1, C2, C3), where C denotes a non-header tuple, C1\ndenotes the row, C2 denotes the column, and C3 denotes the content. C1 corresponds to the row\nheader tuple’s L2 and L3 that are related to it, while C2 corresponds to the column header tuple’s\nT2 and T3 that are related to it.\n5. The tuple of a column header contains T1, representing the level of the header, with 0 being the\nhighest level and larger T1 indicating lower levels. If the T2 and T3 of tuple A are between T2\nand T3 of tuple B (can be equal), then there is a parent-child relationship between A and B, A is a\nsub-header of B, B is a parent-header of A, and A’s T1 must be smaller than B’s T1. The lowest\nlevel header’s tuple has T2=T3. Similarly for row headers. The specific tuples are in Table Content.\n# Examples\nFor examples:\nThe tuple (T, 1, 0, 0, g) denotes a column header with level 1, spanning from column 0 to column 0,\nwith the content \"g\".\nThe tuple (L, 0, 6, 6, karlsruher sc) denotes a row header with level 0, spanning from row 6 to row\n6, with the content \"karlsruher sc\".\nThe tuple (C, 7, 0, 416) represents a non-header cell at row 7, column 0, with a value of 416.\nMake sure you read and understand these instructions carefully.\n# Chain-of-thought\nLet’s think step by step as follows and give full play to your expertise as a statistical analyst:\n1. Clearly understand the question and the information needed to answer the question to determine\nthe necessary information to extract.\n2. Have a comprehensive understanding of the data in the table, including the meaning, data types,\nand formats of each column and row tuples (Note: There are usually summative tuples in the table,\nsuch as all, combine, total, sum, average, mean, etc. These tuples help you skip a lot of operations).\n3. Based on the question, select the row and column header tuples that are most relevant to the\nquestion and then locate the non-header tuples based on the row and column header tuples you\nselected before.\n4. Perform statistical, calculation, sorting, grouping, or other operations on the tuples you selected\nbefore to extract useful information based on the question’s requirements.\n# Output Control\nYou MUST answer each question in the format below line by line (Note: Keep your answer\nconcise):\n1. Column header: The column header tuples most relevant to the answer.\n2. Row header: The row header tuples most relevant to the answer.\n3. Cell: The non-header tuples most relevant to the answer.\n4. Operation: the operation you performed on the tuples you selected.\n5. Answer: your answer (A number, noun, phrase, or set of data).\nAnd if the answer is not contained within the context, say \"I don’t know\".\nTable 6: Full text of the \"Regulations\" part of the single-turn dialogue prompt. The text in \"[]\" can be replaced\naccording to the specific information in the QA process.\n14797\nInput Context\n# Table Title\nTitle: [TABLE_TITLE_HERE]\n# Column Header\nColumn header: [TABLE_COLUMN_HEADER_HERE]\n# Row Header\nRow header: [TABLE_ROW_HEADER_HERE]\n# Non-Header\nNon-header: [TABLE_NON_HEADER_HERE]\n# Question\nQ: [QUSTION_HERE]\nA:\nTable 7: Full text of the \"Input Context\" part of the single-turn dialogue prompt. The text in \"[]\" can be replaced\naccording to the specific information in the QA process.\n14798\nRegulations\n# Role play\nSuppose you are an expert in statistical analysis.\nYou will be given a table described in a special format.\nYour task is to answer the questions based on the content of the table.\n# Table Description\nThe table is described as follows:\n1. The title means the title of the table.\n2. A tuple (T, T1, T2, T3, T4) represents a column header, where T indicates it’s a column header,\nT1 denotes its level, T2 and T3 indicate the start and end column of the header, andT4 specifies the\ncontent.\n3. A tuple (L, L1, L2, L3, L4) represents a row header, where L indicates it’s a row header, L1\ndenotes its level, L2 and L3 indicate the start and end row of the header, and L4 specifies the\ncontent.\n4. We represent non-header tuples as (C, C1, C2, C3), where C denotes a non-header tuple, C1\ndenotes the row, C2 denotes the column, and C3 denotes the content. C1 corresponds to the row\nheader tuple’s L2 and L3 that are related to it, while C2 corresponds to the column header tuple’s\nT2 and T3 that are related to it.\n5. The tuple of a column header contains T1, representing the level of the header, with 0 being the\nhighest level and larger T1 indicating lower levels. If the T2 and T3 of tuple A are between T2\nand T3 of tuple B (can be equal), then there is a parent-child relationship between A and B, A is a\nsub-header of B, B is a parent-header of A, and A’s T1 must be smaller than B’s T1. The lowest\nlevel header’s tuple has T2=T3. Similarly for row headers. The specific tuples are in Table Content.\n# Examples\nFor examples:\nThe tuple (T, 1, 0, 0, g) denotes a column header with level 1, spanning from column 0 to column 0,\nwith the content \"g\".\nThe tuple (L, 0, 6, 6, karlsruher sc) denotes a row header with level 0, spanning from row 6 to row\n6, with the content \"karlsruher sc\".\nThe tuple (C, 7, 0, 416) represents a non-header cell at row 7, column 0, with a value of 416.\nMake sure you read and understand these instructions carefully.\nInput Context #1\n# Abstract Keywords\nExtract the key words in the question.\nQ: [QUESTION_HERE]\nA:\nTable 8: Full text of the first prompt turn of the multi-turn dialogue. The text in \"[]\" can be replaced according to the\nspecific information in the QA process.\n14799\nRegulations and Historical Dialogue\n# Role play\nSuppose you are an expert in statistical analysis.\nYou will be given a table described in a special format.\nYour task is to answer the questions based on the content of the table.\n# Table Description\nThe table is described as follows:\n1. The title means the title of the table.\n2. A tuple (T, T1, T2, T3, T4) represents a column header, where T indicates it’s a column header,\nT1 denotes its level, T2 and T3 indicate the start and end column of the header, andT4 specifies the\ncontent.\n3. A tuple (L, L1, L2, L3, L4) represents a row header, where L indicates it’s a row header, L1\ndenotes its level, L2 and L3 indicate the start and end row of the header, and L4 specifies the\ncontent.\n4. We represent non-header tuples as (C, C1, C2, C3), where C denotes a non-header tuple, C1\ndenotes the row, C2 denotes the column, and C3 denotes the content. C1 corresponds to the row\nheader tuple’s L2 and L3 that are related to it, while C2 corresponds to the column header tuple’s\nT2 and T3 that are related to it.\n5. The tuple of a column header contains T1, representing the level of the header, with 0 being the\nhighest level and larger T1 indicating lower levels. If the T2 and T3 of tuple A are between T2\nand T3 of tuple B (can be equal), then there is a parent-child relationship between A and B, A is a\nsub-header of B, B is a parent-header of A, and A’s T1 must be smaller than B’s T1. The lowest\nlevel header’s tuple has T2=T3. Similarly for row headers. The specific tuples are in Table Content.\n# Examples\nFor examples:\nThe tuple (T, 1, 0, 0, g) denotes a column header with level 1, spanning from column 0 to column 0,\nwith the content \"g\".\nThe tuple (L, 0, 6, 6, karlsruher sc) denotes a row header with level 0, spanning from row 6 to row\n6, with the content \"karlsruher sc\".\nThe tuple (C, 7, 0, 416) represents a non-header cell at row 7, column 0, with a value of 416.\nMake sure you read and understand these instructions carefully.\n# Output of Turn 1\nExtract the key words in the question.\nQ: [QUESTION_HERE]\nA: [ANSWER_OF_TURN_1]\nInput Context #2\n# Select Headers\nHere are table title and the tuples of the table’s rows and headers, please try to locate the lowest\nlevel of headers that match the question and keywords you extracted:\n\"Title\": [TABLE_TITLE_HERE]\n\"Column header\": [TABLE_COLUMN_HEADER_HERE]\n\"Row header\": [TABLE_ROW_HEADER_HERE]\n# Output Control\nYou MUST output your selection in the following format:\n1. Column header:\n2. Row header:\nTable 9: Full text of the second prompt turn of the multi-turn dialogue. The text in \"[]\" can be replaced according to\nthe specific information in the QA process.\n14800\nRegulations and Historical Dialogue\n# Role play\nSuppose you are an expert in statistical analysis.\nYou will be given a table described in a special format.\nYour task is to answer the questions based on the content of the table.\n# Table Description\nThe table is described as follows:\n1. The title means the title of the table.\n2. A tuple (T, T1, T2, T3, T4) represents a column header, where T indicates it’s a column header,\nT1 denotes its level, T2 and T3 indicate the start and end column of the header, andT4 specifies the\ncontent.\n3. A tuple (L, L1, L2, L3, L4) represents a row header, where L indicates it’s a row header, L1\ndenotes its level, L2 and L3 indicate the start and end row of the header, and L4 specifies the\ncontent.\n4. We represent non-header tuples as (C, C1, C2, C3), where C denotes a non-header tuple, C1\ndenotes the row, C2 denotes the column, and C3 denotes the content. C1 corresponds to the row\nheader tuple’s L2 and L3 that are related to it, while C2 corresponds to the column header tuple’s\nT2 and T3 that are related to it.\n5. The tuple of a column header contains T1, representing the level of the header, with 0 being the\nhighest level and larger T1 indicating lower levels. If the T2 and T3 of tuple A are between T2\nand T3 of tuple B (can be equal), then there is a parent-child relationship between A and B, A is a\nsub-header of B, B is a parent-header of A, and A’s T1 must be smaller than B’s T1. The lowest\nlevel header’s tuple has T2=T3. Similarly for row headers. The specific tuples are in Table Content.\n# Examples\nFor examples:\nThe tuple (T, 1, 0, 0, g) denotes a column header with level 1, spanning from column 0 to column 0,\nwith the content \"g\".\nThe tuple (L, 0, 6, 6, karlsruher sc) denotes a row header with level 0, spanning from row 6 to row\n6, with the content \"karlsruher sc\".\nThe tuple (C, 7, 0, 416) represents a non-header cell at row 7, column 0, with a value of 416.\nMake sure you read and understand these instructions carefully.\n# Output of Turn 2 and Code\nHere are all the tuples relevant to the question:\n[ANSWER_OF_TURN_2]\nNon-header: [OUTPUT_OF_CODE]\nInput Context #2\n# All Headers\n\"Column header\": [TABLE_COLUMN_HEADER_HERE]\n\"Row header\": [TABLE_ROW_HEADER_HERE]\n# Output Control\nYou MUST answer each question in the format below line by line (Note: Keep your answer\nconcise):\n1. Column header: The column header tuples most relevant to the answer.\n2. Row header: The row header tuples most relevant to the answer.\n3. Cell: The non-header tuples most relevant to the answer.\n4. Operation: the operation you performed on the tuples you selected.\n5. Answer: your answer (A number, noun, phrase, or set of data).\nAnd if the answer is not contained within the context, say \"I don’t know\".\nNotes:\n1. In the row and column header tuples, the third and fourth elements represent the row and column\nposition information.\n2. You must output non-header tuples that are valid in the above tuples.\nTable 10: Full text of the third prompt turn of the multi-turn dialogue. The text in \"[]\" can be replaced according to\nthe specific information in the QA process.\n14801\nRegulations\nThe text provided describes a table in json format, answer the question as truthfully as possible\nusing the provided text and don’t omit the decimal point, and if the answer is not contained within\nthe text below, say \"I don’t know\".\n# Content [ORIGINAL_TABLE]\nQ: [QUESTION_HERE]\nA:\nTable 11: Full text of the simple prompt. The text in \"[]\" can be replaced according to the specific information in the\nQA process.\n14802",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8565033674240112
    },
    {
      "name": "Parsing",
      "score": 0.7429533004760742
    },
    {
      "name": "Natural language processing",
      "score": 0.6694365739822388
    },
    {
      "name": "Tuple",
      "score": 0.6110044121742249
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5937215089797974
    },
    {
      "name": "Table (database)",
      "score": 0.5116317868232727
    },
    {
      "name": "Question answering",
      "score": 0.4741101861000061
    },
    {
      "name": "ENCODE",
      "score": 0.448316365480423
    },
    {
      "name": "Structuring",
      "score": 0.4145236015319824
    },
    {
      "name": "Transformer",
      "score": 0.4139779806137085
    },
    {
      "name": "Information retrieval",
      "score": 0.3484552502632141
    },
    {
      "name": "Data mining",
      "score": 0.24668094515800476
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Discrete mathematics",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Finance",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I24943067",
      "name": "Fudan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210159329",
      "name": "Children's Hospital of Fudan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210092101",
      "name": "Shanghai Children's Medical Center",
      "country": "CN"
    }
  ],
  "cited_by": 11
}