{
    "title": "Feedback-Based Self-Learning in Large-Scale Conversational AI Agents",
    "url": "https://openalex.org/W3038119500",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2985333450",
            "name": "Pragaash Ponnusamy",
            "affiliations": [
                "Amazon (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A1967149857",
            "name": "Alireza Roshan Ghias",
            "affiliations": [
                "Amazon (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A2900894694",
            "name": "Chenlei Guo",
            "affiliations": [
                "Amazon (United States)"
            ]
        },
        {
            "id": "https://openalex.org/A116639046",
            "name": "Ruhi Sarikaya",
            "affiliations": [
                "Amazon (United States)"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1811905496",
        "https://openalex.org/W6753443365",
        "https://openalex.org/W7020061393",
        "https://openalex.org/W4238097273",
        "https://openalex.org/W2584094115",
        "https://openalex.org/W2046932483",
        "https://openalex.org/W6602761724",
        "https://openalex.org/W2572102653",
        "https://openalex.org/W2606974598",
        "https://openalex.org/W6679436768",
        "https://openalex.org/W2125288949",
        "https://openalex.org/W4306716473",
        "https://openalex.org/W2130942839",
        "https://openalex.org/W3147409906",
        "https://openalex.org/W2752779325"
    ],
    "abstract": "Today, most of the large-scale conversational AI agents such as Alexa, Siri, or Google Assistant are built using manually annotated data to train the different components of the system including Automatic Speech Recognition (ASR), Natural Language Understanding (NLU) and Entity Resolution (ER). Typically, the accuracy of the machine learning models in these components are improved by manually transcribing and annotating data. As the scope of these systems increase to cover more scenarios and domains, manual annotation to improve the accuracy of these components becomes prohibitively costly and time consuming. In this paper, we propose a system that leverages customer/system interaction feedback signals to automate learning without any manual annotation. Users of these systems tend to modify a previous query in hopes of fixing an error in the previous turn to get the right results. These reformulations, which are often preceded by defective experiences caused by either errors in ASR, NLU, ER or the application. In some cases, users may not properly formulate their requests (e.g. providing partial title of a song), but gleaning across a wider pool of users and sessions reveals the underlying recurrent patterns. Our proposed self-learning system automatically detects the errors, generate reformulations and deploys fixes to the runtime system to correct different types of errors occurring in different components of the system. In particular, we propose leveraging an absorbing Markov Chain model as a collaborative filtering mechanism in a novel attempt to mine these patterns. We show that our approach is highly scalable, and able to learn reformulations that reduce Alexa-user errors by pooling anonymized data across millions of customers. The proposed self-learning system achieves a win-loss ratio of 11.8 and effectively reduces the defect rate by more than 30% on utterance level reformulations in our production A/B tests. To the best of our knowledge, this is the first self-learning large-scale conversational AI system in production.",
    "full_text": "The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference (IAAI-20)\nFeedback-Based Self-Learning in Large-Scale Conversational AI Agents\nPragaash Ponnusamy, Alireza Roshan Ghias, Chenlei Guo, Ruhi Sarikaya\nAmazon Alexa\n{ponnup, ghiasali, guochenl, rsarikay}@amazon.com\nAbstract\nToday, most of the large-scale conversational AI agents such\nas Alexa, Siri, or Google Assistant are built using manually\nannotated data to train the different components of the sys-\ntem including Automatic Speech Recognition (ASR), Nat-\nural Language Understanding (NLU) and Entity Resolution\n(ER). Typically, the accuracy of the machine learning mod-\nels in these components are improved by manually transcrib-\ning and annotating data. As the scope of these systems in-\ncrease to cover more scenarios and domains, manual annota-\ntion to improve the accuracy of these components becomes\nprohibitively costly and time consuming. In this paper, we\npropose a system that leverages customer/system interaction\nfeedback signals to automate learning without any manual\nannotation. Users of these systems tend to modify a previ-\nous query in hopes of ﬁxing an error in the previous turn to\nget the right results. These reformulations, which are often\npreceded by defective experiences caused by either errors in\nASR, NLU, ER or the application. In some cases, users may\nnot properly formulate their requests (e.g. providing partial\ntitle of a song), but gleaning across a wider pool of users and\nsessions reveals the underlying recurrent patterns. Our pro-\nposed self-learning system automatically detects the errors,\ngenerate reformulations and deploys ﬁxes to the runtime sys-\ntem to correct different types of errors occurring in different\ncomponents of the system. In particular, we propose lever-\naging an absorbing Markov Chain model as a collaborative\nﬁltering mechanism in a novel attempt to mine these patterns.\nWe show that our approach is highly scalable, and able to\nlearn reformulations that reduce Alexa-user errors by pooling\nanonymized data across millions of customers. The proposed\nself-learning system achieves a win-loss ratio of 11.8 and ef-\nfectively reduces the defect rate by more than 30% on utter-\nance level reformulations in our production A/B tests. To the\nbest of our knowledge, this is the ﬁrst self-learning large-scale\nconversational AI system in production.\nIntroduction\nLarge-scale conversational AI agents (Sarikaya 2017) such\nas Alexa, Siri, and Google Assistant are getting more and\nmore prevalent, opening up in new domains and taking up\nCopyright c⃝ 2020, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nnew tasks to help users across the globe. One key consid-\neration in designing such systems is how they can be im-\nproved over time at that scale. Users interacting with these\nagents experience frictions due to various reasons: 1) Auto-\nmatic Speech Recognition (ASR) errors, such as”play maj\nand dragons” (should be”play imagine dragons”), 2) Nat-\nural Language Understanding (NLU) errors, such as”don’t\nplay this song again skip”(Alexa would understand if it is\nformulated as ”thumbs down this song”), and even user er-\nrors, such as ”play bazzi angel” (it should’ve been ”play\nbeautiful by bazzi”). It goes without saying that ﬁxing these\nfrictions help users to have a more seamless experience, and\nengage more with the AI agents.\nOne common method to address frictions is to gather\nthese use cases and ﬁx them manually using rules and Finite\nState Transducers (FST) as they’re often the case in speech\nrecognition systems (Mohri, Pereira, and Riley 2002). This\nof course is a laborious technique which is: 1) not scalable\nat Alexa scale, and 2) prone to error, and 3) getting stale and\neven defective over time. Another approach could be to iden-\ntify these frictions, ask annotators to come up with the cor-\nrect form of query, and then update ASR and NLU models\nto solve these problems. This is also: 1) not an scalable so-\nlution, since it needs a lot of annotations, and 2) it is expen-\nsive and time consuming to update those models. Instead,\nwe have taken a ”query rewriting” approach to solve cus-\ntomer frictions, meaning that when necessary, we reformu-\nlate a customer’s query such that it conveys the same mean-\ning/intent, and is actionable (i.e. interpretable) by Alexa’s\nexisting NLU systems.\nIn motivating our approach, consider the example utter-\nance, ”play maj and dragons”. Now, without reformulation,\nAlexa would inevitably come up with the response,”Sorry, I\ncouldn’t ﬁnd maj and dragons”. Some customers give up at\nthis point, while others may try enunciating better for Alexa\nto understand them:”play imagine dragons”. Also note that\nthere might be other customers who give up, and change the\nnext query to another intent, for example:”play pop music”.\nHere, frictions evidently cause dissatisfaction with differ-\nent customers reacting differently to them. However, quite\nclearly there are good rephrases by some customers among\nall these interactions, which beckons the question – how can\n13180\nFigure 1: A high-level overview of the deployed architecture with our reformulation engine in context of the overall system in\n(a) and the ofﬂine sub-system that updates its online counterpart on a daily cadence.\nwe identify and extract them to solve customer frictions?\nWe propose using a Markov-based collaborative ﬁltering\napproach to identify rewrites that lead to successful cus-\ntomer interactions. We go on to discuss the theory and im-\nplementation of the idea, as well as show that this method is\nhighly scalable and effective in signiﬁcantly reducing cus-\ntomer frictions. We also discuss how this approach was de-\nployed into customer-facing production and what are some\nof the challenges and beneﬁts of such approach.\nRelated Work\nCollaborative ﬁltering has been used extensively in recom-\nmender systems. In a more general sense, collaborative ﬁl-\ntering can be viewed as a method of mining patterns from\nvarious agents (most commonly, people), in order to help\nthem help each other out (Terveen and Hill 2001). Markov\nchains have been used previously in collaborative ﬁltering\napplications to recommend course enrollment (Khorasani,\nZhenge, and Champaign 2016), personalized recommender\nsystems (Sahoo, Singh, and Mukhopadhyay 2012), and web\nrecommendation (Fouss et al. 2005).\nStudies have shown that Markov processes can be used\nto explain the user web query behavior (Jansen, Booth, and\nSpink 2005), and Markov chains have since been used suc-\ncessfully for web query reformulation via absorbing random\nwalk (Wang, Huang, and Wu 2015), and modeling query\nutility (Xiaofei Zhu 2012). We here present a new method\nfor query reformulation using Markov chain that is both\nhighly scalable and interpretable due to intuitive deﬁnitions\nof transition probabilities. Also, to the best of the authors’\nknowledge, this is the ﬁrst work where Markov chain is used\nfor query reformulation in voice-based virtual assistants.\nOne important difference between the web query refor-\nmulation and Alexa’s use case is that we need to seamlessly\nreplace the user’s utterance in order to remove friction. Ask-\ning users for conﬁrmation every time we plan to reformulate\nis on itself an added friction, which we try to avoid as much\nas possible. Another difference is how success and failure\nare deﬁned for an interaction between user and a voice-based\nvirtual assistant system. We use implicit and explicit user\nfeedback when interacting with Alexa to establish theab-\nsorbing states of success and failure.\nSystem Overview\nThe Alexa conversational AI system follows a rather well-\nestablished architectural pattern of cloud-based digital voice\nassistants (Gao, Galley, and Li 2018) i.e. comprising of an\nautomatic speech recognition (ASR) system, a natural lan-\nguage understanding (NLU) system with a built-in dialog\nmanager, and a text-to-speech (TTS) system, as visualized in\nFig. 1. Conventionally, as a user interacts with their Alexa-\nenabled device, their voice is ﬁrst recognized by ASR and\ndecoded into plain text, which we refer to as an utterance.\nThe utterance is then interpreted by the NLU component to\nsurface the aforementioned user’s intent by also accounting\nfor the state of user’s active dialog session. Thereafter, the\nintent and the corresponding action to execute is passed on\nto the TTS to generate the appropriate response as speech\nback to the user via their Alexa-enabled device, thus closing\nthe interaction loop. Also note that the metadata associated\nwith each of the above systems are anonymized and logged\nasynchronously to an external database.\nIn deploying our self-learning system, we ﬁrst intercept\nthe utterance being passed onto the NLU system and rewrite\nit with our reformulation engine. We then subsequently pass\nthe rewrite in lieu of the original utterance back to NLU for\ninterpretation, and thus restoring the original data ﬂow. This\nis shown as the post-deployment data ﬂow path in Fig. 1.\nOur reformulation engine is essentially implements rather\nlightweight service-oriented architecture that encapsulates\n13181\nthe access to a high-performance, low-latency database,\nwhich is queried with the original utterance to yield its cor-\nresponding rewrite candidate. This along with the fact that\nthe system is fundamentally stateless across users translates\nto a rather scalable customer-facing system with marginal\nimpact to the user perceived latency of their Alexa-enabled\ndevice.\nIn order to discover new rewrite candidates and maintain\nthe viability of existing rewrites, our Markov-based model\ningests the anonymized Alexa log data on a daily basis\nto learn from users’ reformulations and subsequently up-\ndates the aforementioned online database. We discuss the\nnature of the dataset and how our model achieves this in\nlater sections of this paper. This ingestion to update pro-\ncess takes place ofﬂine in entirety with the rewrites in the\ndatabase updated via a low-maintenance feature-toggling\n(i.e. feature-ﬂag) mechanism. Additionally, we also have an\nofﬂine blacklisting mechanism which evaluates the rewrites\nfrom our Markov model by independently comparing their\nfriction rate against that of the original utterance, and subse-\nquently ﬁltering them from being uploaded to the database\nshould they perform worse against their no-rewrite counter-\npart using aZ-test with a rather conservativep-value of0.01.\nThis allows us to maintain a high precision system at run-\ntime. It is worth mentioning that friction detection is done\nusing a pre-trained ML model based on user’s utterance and\nAlexa’s response. The details of that model is out of scope\nof this paper.\nDataset\nAs our objective is to learn the patterns from user interac-\ntions with Alexa, we pre-process 3 months of anonymized\nAlexa log data across millions of customers, which consti-\ntutes a highly randomized collection of time-series utterance\ndata, to build our dataset,D comprising of a set of sessions,\nS i.e.:\nD = {S\n0,S1,... } (1)\nHere, in deﬁning the concept of a session, we ﬁrst deﬁne\nthe construction function f, parameterized by a customer,\nc, a device,d, and an initial timestamp,τ0, to yield a ﬁnite\nordered set of successive utterances,u (and its associated\nmetadata) such that the time delay between any two con-\nsecutive utterances is at mostδτ. We also note that inter-\njecting utterances, J, i.e. those leading to StopIntent,\nCancelIntent, etc., that occur before the end of the\naforementioned set are removed. Then, a session,Sk is de-\nﬁned as follows:\nSk = f(c,d,τ 0)=\n(\nu(k)\n0 ,u(k)\n1 ,...,u (k)\nTk\n)\n(2)\nsuch that the following properties hold true:\n• τ(k)\n0 = τ0, and\n• τ(k)\nj >τ (k)\ni , ∀ 0 ≤ i<j ≤ Tk, and\n•\n⏐⏐⏐τ(k)\ni+1 −τ(k)\ni\n⏐⏐⏐≤ δτ, and\n• ui ̸∈ J, ∀ i<T k.\nIntuitively speaking, a session is effectively a time-\ndelimited snapshot of a user’s conversation history with their\nAlexa-enabled device. We illustrate this in Fig. 2 (a), (b),\nand (c) where each session is represented as a linear directed\nchain of successive utterances e.g.u\n2 → u3 → u4. In this\npaper, we choose the value ofδτ =4 5seconds as a result\nfrom a separate internal analysis.\nAbsorbing Markov Chain\nIn this section, we show how encoding user interaction his-\ntory as paths in an absorbing Markov Chain model can be\nused to mine patterns for reformulating utterances. In par-\nticular, we discuss in detail the concept of the interpretation\nspace, H, which functions as the vertex set of the model’s\ntransient states. We then elaborate on the construction of the\nabsorbing states,R, the canonical solution to the model, and\nthe practical implementation of the model. As the Markov\nChain model is inherently a probabilistic graphical model,\nwe can represent it as graph,G =( V,E ), where the vertex\nset, V and the edge set,E are given as follows:\nV = H ∪RE = {(x,y) | x ∈ H ∧y ∈ V} (3)\nWe note that from here on out, we use the terms, Graph\nand Markov model interchangeably.\nInterpretation Space\nWhile our deﬁnition of a session above naturally extends to-\nwards having each ordered linear sequence of utterances as\na path in our Markov model, this encoding in the utterance\nspace, U i.e. the space of all utterancesu, imposes a limita-\ntion on the model by creating heavily sparse connections.\nThis is primarily due to the high degree of semantic and\nstructural variance in U, which would ultimately result in\na lower capacity for generalization.\nTo resolve this, we leverage the domain and intent clas-\nsiﬁer as well as the named entity recognition (NER) results\nfrom Alexa’s NLU systems to surface structured representa-\ntions of utterances, and thus encapsulate a latent distribution\nover U. Consequently, each utterance in a session is pro-\njected into this interpretation space,H which comprises the\nset of all interpretationsh, to deﬁne a latent session:\nS\n′\nk =\n(\nh(k)\n0 ,h(k)\n1 ,...,h (k)\nTk\n)\n(4)\nTo exemplify this, consider the utterance,”play despica-\nble me” (i.e. u4 in Fig. 2), which would be mapped into the\nH-space as:\nMusic|PlayMusicIntent|AlbumName:despicable me\nwhich is compactly represented ash2 in Fig. 2. As theH-\nspace condenses the semantics ofU, this mapping between\nU and H is inherently a many-to-one relationship. However,\ngiven the stochasticity of Alexa’s NLU, the original projec-\ntion itself is not entirely bijective and thus results in a many-\nto-one relationship in both the forward and inverse mapping,\ni.e. U → H and H → U, akin to a bipartite mapping.\nThis in turn, yields the conditional probability distributions,\n13182\nFigure 2: A visual representation of the Markov model constructed in the interpretation space,H, over three separate sessions,\n(a), (b), and (c), of users attempting to play the album”Despicable Me”, and how solving for the path with the highest likelihood\nof success, (+), given by the darkened edged in (d), can allow for the defective utterances to be reformulated into a more\nsuccessful query, as summarized in (e). Note that here, for demonstration purposes, we only show 3 interactions. However,\nin practice, we had a higher threshold for the minimum number of customers and interactions to have better estimates for the\nprobabilities.\nP(H|U) and P(U|H), such that for a particularu ∈ U and\nh ∈ H, they are deﬁned as follows:\nP (h|u)= c(u,h)\n∑\nh′∈H\nc(u,h′) P (u|h)= c(u,h)∑\nu′∈U\nc(u′,h)\n(5)\nwhere c(u,h) is the co-occurrence count of the pair(u,h)\nin the dataset,D i.e. the total number of times bothu and h\nare mapped onto each other.\nTransient States\nGiven our transformed dataset, D′ of latent sessions S′,\nwe take each such session and the interpretations within it\nto represent paths and transient states respectively in our\nMarkov model, such that each successive pair of interpre-\ntations would represent an edge in the Graph. In deﬁning the\ntransition probability distribution, we ﬁrst deﬁneZ\ni, the to-\ntal occurrence of an interpretationhi in the aforementioned\ndataset as follows:\nZi =\n∑\nv∈V\nc(hi,v) (6)\nwhere c(hi,v)is the co-occurrence count of the pair(hi,v)\ni.e. the total number of timesv is adjacent tohi, aggregated\nacross all sessions (i.e. over 3 months and millions of cus-\ntomers)i nD′:\nc(hi,v)=\n∑\nk\nTk−1∑\nt=0\n1\n(\nh(k)\nt = hi ∧h(k)\nt+1 = v\n)\n(7)\nThen, the corresponding probability that a transition state\nhi ∈ H transitions tohj ∈ H in the Graph is given by:\nP (hj|hi)= c(hi,hj)\nZi\n(8)\nTaking this in context of Fig. 2, consider the transition\nprobability P (h1|h0). From the sessions (a), (b), and (c), we\ncan note that the transition stateh0 is adjacent to the states,\n{h0,h1,h3,(−)}with each of them having a co-occurrence\nof 1 with h0. Here, (−) refers to the failure absorbing state\n(deﬁned in the following sub-section). As such, the probabil-\nity P (h1|h0)= 1\n4 =0 .25 as shown in (d).\nAbsorbing States\nIn formulating the deﬁnition of the absorbing states of the\nMarkov model, we look towards encoding the notion of in-\nterpreted defects as perceived by the user. As we have brieﬂy\nintroduced earlier, this concept of defect surfaces in two key\nforms i.e. viaexplicit and implicit feedback.\nHere, explicit feedback refers to the type of corrective\nor reinforcing feedback received from direct user engage-\nment. This primarily includes events where users opt to in-\nterrupt Alexa by means of an interjecting utterance (as de-\nﬁned above in Dataset). This is illustrated in the example\nbelow:\n13183\nUser: ”play a lever”\nAlexa: ”Here’s Lever by The Mavis’s, starting now. ”\nUser: ”stop”\nIn contrast, implicit feedback is typically observed when\nusers abandon a session following Alexa’s failure to handle\na request either due to an internal exception or simply unable\nto ﬁnd a match for the entities resolved. Case in point:\nUser: ”play maj and dragons”\nAlexa: ”Sorry, I can’t ﬁnd the artist maj and dragons. ”\nGiven this, we deﬁne two absorbing states:failure (r−),\nand success (r+), where success is deﬁned as the absence\nof failure. These states are artiﬁcially injected to the end of\nall sessions, based on the implicit and explicit feedback we\ninfer from Alexa’s response, and user’s last utterance.\nTo clarify this, let’s walk through the examples above as-\nsuming that they are the last utterances of their correspond-\ning sessions. In the ﬁrst example, we would drop the”stop”\nturn, and add afailure state. In the second example, we sim-\nply add the failure state to the end of the session. Finally,\nin the absence of an explicit or implicit feedback, we add a\nsuccess state to the end of the session. Given this, we can\nthen deﬁne the probability that a given transient state,h\ni is\nabsorbed in much the same way as in Eq. 8, e.g.:\nP\n(\nr+|hi\n)\n= c(hi,r+)\nZi\n(9)\nNote that in Fig. 2, we refer to thefailure (r−), and suc-\ncess (r+) states as(−) and (+) respectively.\nMarkov Model\nWith the distributions over both the transition and absorbing\nstates deﬁned above, recall that the interpretation space,H\nis the set of all transient states in the Graph. Then, we can\nsummarize the Markov model in its canonical form via the\ntransition matrix,A as follows:\nA =\n[\nQR\n0I\n2\n]\n(10)\nwhere:\n• Q ∈ R|H|×|H| s.t. qi,j = P (hj|hi),\n• R =[ r+,r−] ∈ R|H|×2 s.t. ri =[ P (r+|hi),P (r−|hi)],\n• 0 is the2×|H| zero-matrix, and\n• I2 is the2×2 identity matrix.\nNow, we generalize the previous notation of probabilities\nas P(n) i.e. the probability at depth-n of the Graph, withP\nimplicitly referring to P(1). Then, let hs and ht be given\nsource and target transient states in the Graph respectively.\nWe further deﬁne the probability ofsuccess of h\nt given hs\nsuch thatht is reached by hs in at mostk steps as follows:\nΦk (ht)= P(1) (\nr+|ht\n)\n·\nk∑\nn=0\nP(n) (ht|hs) (11)\nAs such, in the context of reducing defects, we considerht to\nbe a possible reformulation candidate forhs if it isreachable\nby hs, such that conditioned onhs, ht has a higher chance\nof success than hs on its own, i.e.:\nP(1) (\nr+|ht\n)\n·\n∞∑\nn=0\nP(n) (ht|hs) >P (1) (\nr+|hs\n)\nΦ∞(ht) > Φ1(hs)\n(12)\nHere, reachability of any two states implies that there\nexists a path between them in the Graph or mathemati-\ncally speaking, there exists a non-zero value ofn for which\nP\n(n) (ht|hs) > 0. Now, consider the probability ofsuccess\nof ht given hs such that ht is reached by hs in exactly n\nsteps. We would then have the following:\nP(1) (\nr+|ht\n)\n·P(n) (ht|hs)= P(1) (\nr+|ht\n)\n·q(n)\ns,t (13)\nwhere q(n)\ns,t refers to the (s,t)-entry of the matrix Qn (Q\nmultiplied by itself n times), which in turn refers to the\nprobability of reaching ht from hs in exactly n steps i.e.\nP(n) (ht|hs). Expanding this to any number of steps i.e.\nreachable would thus allow us to reformulate the left set of\nterms in the inequality of Eq. 12 using matrix notations:\nΦ∞(ht)= P(1) (\nr+|ht\n)\n·\n∞∑\nn=0\nP(n) (ht|hs)\n= P(1) (\nr+|ht\n)\n·\n∞∑\nn=0\nq(n)\ns,t\n= P(1) (\nr+|ht\n)\n·\n( ∞∑\nn=0\nQn\n)\ns,t\n(14)\nGeneralizing this across allh ∈ H, deﬁne the matrixP\nsuch that its(s,t)-th entry,ps,t =Φ ∞(ht). Then, we have:\nP =\n( ∞∑\nn=0\nQn\n)\nR+\ndg (15)\nwhere R+\ndg is the diagonal matrix whose diagonal is the vec-\ntor r+.N o w ,a sQ is a square matrix of probabilities, we\nhave ∥Q∥ < 1 and that Q is convergent. Then the summa-\ntion above leads to a geometric series of matrices, which as\ngiven by Deﬁnition 11.3 in (Grinstead and Snell 1997), cor-\nresponds to the fundamental matrix of the Markov model,\ndenoted byN:\nN =\n∞∑\nn=0\nQn =\n(\nI|H| −Q\n)−1\n(16)\nwith I|H| referring to the identity matrix with the dimen-\nsions, |H|×| H|. Given this, letp(s) be thes-th row vector\nof the matrix P corresponding to hs. As such, every non-\nzero entry t in p(s) translates to the probabilityΦ∞(ht) of\nsome reachable ht. This vector is thus given by:\np(s) =\n(\nNR+\ndg\n)\ns\n= N⊤\ns ◦r+ (17)\n13184\nwhere ◦ refers to the Hadamard (element-wise) product. We\nthen frame our objective as identifying theht which maxi-\nmizes the aforementioned probability for the givenhs:\nh∗\nt = arg max\nht\nΦ∞(ht)= arg max\nt\np(s)\nt (18)\nIntuitively speaking, in the event thath∗\nt ̸= hs, the model\nshows that there exists areachable target interpretation that\nwhen reformulated from hs, has a better chance at asuc-\ncessful experience than not doing so. In reference to Fig. 2,\nwe can see that reformulatingh0 to h∗\nt = h2 increases the\nlikelihood of success as:\nP(1) (\nr+|h2\n)\n·\n∞∑\nn=0\nP(n) (h2|h0)= 2\n3 >P (1) (\nr+|h0\n)\n=0\n(19)\nSuppose that h∗\nt = hs. In which case, the source inter-\npretation is alreadysuccessful on its own and hence requires\nno reformulation. As such, the model is effectively able to\nautomatically partition the vertex space,H into sets ofsuc-\ncessful (H\n+) and unsuccessful (H−) interpretations. In ex-\ntending this reformulation back to the utterance space,U,\nwe leverage the distributionsP(U|H) and P(H|U) deﬁned\nin Eq. 5 and re-deﬁne our objective as follows for a given\nsource utteranceu\ns ∈ U:\nu∗\nt = arg max\nut\n∑\nhs\n∑\nht\nP(1) (ut|ht)·Φ∞(ht)·P(1) (hs|us)\n(20)\nThe intuition described above can similarly be applied here\nwhere u∗\nt is the moresuccessful reformulation of us. Note\nthat the self-partitioning feature of the model directly ex-\ntends to the utterance space,U, allowing it to surgically tar-\nget only utterances that are likely to be defective and sur-\nface their corresponding rewrite candidates. This is the car-\ndinal aspect of the model that drives theself-learning nature\nof the proposed system without requiring any human in the\nloop.\nImplementation\nWith |H|∼ 106, constructing the matrixQ, let alone invert-\ning it, poses a key challenge towards scaling out the model,\nparticularly in its batched form. As such, we formulate an\napproximation in computing the vectorp\n(s) for all source\ninterpretations, hs by means of a distributed approach.\nWe note that from our dataset,D′, that in the event that\na given source utterance,us is defective, users would only\nattempt at reformulating their query a few times before ei-\nther arriving at a satisfactory experience or abandoning their\nsession entirely. This translates to most (∼ 97.3%) source\ninterpretations, h\ns in the Markov model having short path\nlengths (i.e. typically ≤ 5) prior to them being absorbed by\nan absorbing state. Consequently, this along with the fact\nthat these reformulations are recurrent across users, most\nhigh-conﬁdence reformulations often only involve visiting\na much smaller set of target interpretations,h\nt, i.e.\n|H|∑\nt=0\n1\n(\np(s)\nt > 0\n)\n≪| H| (21)\nThis leads us to deduce that the matrixQ is highly sparse\nand the corresponding Graph contains many clustered (i.e.\ncommunity) structures. We then leverage these facts to ﬁrst\ncollect the paths for every source interpretation,hs in a se-\nries of map-reduce tasks, by means of a distributed breadth-\nﬁrst search traversal up to a ﬁxed depth of 5 using Apache\nSpark (Zaharia et al. 2016). Thereafter, each task receives\nthe paths corresponding to a singleh\ns and in turn uses them\nto construct an approximate transition matrix,¯A(s).A st h e\ndimensionality of the matrix ¯A(s) is much lower than that\nof A, we can easily compute the approximate fundamental\nmatrix, ¯N and the approximate vector¯p(s) within the same\ntask. As a result, we have a distributed solution for paral-\nlelizing the computation of¯p(s) for everyh ∈ H.\nThe breadth-ﬁrst search traversal, which involves a series\nof sort-merge joins, does indeed introduce an algorithmic\noverhead ofO(d·|E|+|E|log|E|), wheredand E refer to\nthe depth of the traversal and the set of all edges in the Graph\nrespectively. We do also note that as this is a distributed join,\nthe incurred network cost due to data shufﬂes are omitted\nhere for simplicity. That being said, these overheads are off-\nset by the advantage of being able to scale out the model.\nFor purposes of optimization, each successive join is only\nperformed on the set of paths which are non-cyclic and have\nyet to be absorbed while paths with vanishing probabilities\nare pruned off.\nExperiments\nBaseline: Pointer-Generator Sequence-to-Sequence\nModel\nSequence-to-sequence (seq2seq) architectures have been the\nfoundation for many neural machine translation and se-\nquence learning tasks (Sutskever, Vinyals, and Le 2014). As\nsuch, by formulating the task of query rewriting as an ex-\ntension of sequence learning, we used a Long Short-Term\nMemory-based (LSTM) model as an alternative method\nto produce rewrites. In short, we ﬁrst mined 3 months of\nrephrase data using a rephrase detection ML model such that\nthe ﬁrst utterance was defective, and the rephrase was suc-\ncessful. We then used this data to train the pointer-generator\nmodel, such that given the ﬁrst utterance, it produces the\nsecond utterance. The model is based on well-established\nencoder-decoder architecture with attention and copy mech-\nanisms (See, Liu, and Manning 2017). After the model is\ntrained, we then used it to rewrite the same utterances that\nthe Graph rewrites.\nOfﬂine Analysis\nIn order to evaluate the quality of the rewrites we obtained,\nwe annotated 5,679 unique utterance-rewrite pairs generated\nvia the Graph, and estimated the accuracy and win-loss ra-\ntio to be 93.4% and 12.0, respectively. The notion of win-\nloss ratio here is deﬁned as the ratio of rewrites that result\n13185\nTable 1: Some example rewrites from the Graph.\nNo. Original utterance Rewrite Label\n1 play maj and dragons play imagine dragons\nGood\n2 play shadow by lady gaga play shallow by lady gaga\n3 play rumer play rumor by lee brice\n4 play sirius x. m. chill play channel ﬁfty three on sirius x. m.\n5 play a. b. c. play the alphabet song\n6 don‘t ever play that song again thumbs down this song\n7 turn the volume to half volume ﬁve\n8 play island ninety point ﬁve play island ninety eight point ﬁve\n9 play swaggy playlist shufﬂe my songs Bad10 play carter ﬁve by lil wayne play carter four by lil wayne\nin better customer experience and the rewrites that deterio-\nrate customer experience. We further leveraged the pointer-\ngenerator model to generate rewrites for these utterances as\na baseline.\nApplying the pointer-generator model on this dataset re-\nsulted in accuracy of 55.2%, i.e. signiﬁcantly lower than the\naccuracy of Graph. This is expected, since the Graph\n1. Aggregates all three months of data (and not limited to\nmerely rephrases),\n2. Takes into account the frequency of transitions whereas\nthe pointer-generator model only has unique rephrase\npairs for training, and\n3. Utilizes the interpretation space to further compact and\naggregate the utterances.\nHowever, the pointer-generator model has the beneﬁt of\nhigher recall (since it can rewrite any utterance ), and it\nlearns the patterns, e.g. SongName → play SongName.\nAnother important difference between the Graph and the\npointer-generator method is that the Graph is capable of\nidentifying when an utterance issuccessful via its interpre-\ntation i.e. whenh\n∗\nt = hs and thus maximize its precision.\nThis is a signal tonot rewrite the utterance, since statisti-\ncally speaking, rewriting could only potentially worsen its\nlikelihood of success. However, the pointer-generator model\nlacks this capability, and it may rewrite an otherwise suc-\ncessful utterance, which thereafter would cause a friction.\nTable 1 shows some examples of good and bad rewrites\nfrom the Graph. It is clear from the examples that the\nrewrites are capable of ﬁxing ASR (no. 1-3), NLU (no. 4-\n7) and even user errors (no. 8). On the other hand, there\nare cases that the rewrites fail (no. 9-10). One of the recur-\nring cases of failure is when an utterance is rewritten to a\ngeneric utterance, like ”play”, or ”shufﬂe my songs”. This\nusually happens due to the original utterance not being suc-\ncessful, and the users trying many different paths that even-\ntually loses information, and is aggregated in a generic ut-\nterance (due to Eq. 20). Another common case of failure is\nwhen the rewrite changes the intention of the original utter-\nance by changing the song name or artist name. This hap-\npens because of various reasons. For example, the data that\nwe use for building the Graph may contain a period of time\nwhere the original utterance was not usually successful, so\nthe users changed their mind by asking to play another sim-\nilar song (like no. 10). The ﬁrst type of error is easy to cor-\nrect, by either applying rules or building a learning-based\nranker after the Graph generation. The second type, how-\never, is tricky to detect, since a lot of times, the change in\nthe interpretation helps. We relied on an online blacklisting\nmechanism to remove these rewrites in the production sys-\ntem.\nApplication Deployment\nOfﬂine Rewrite Mining\nSince there are thousands of new utterances per day, and\nthere are constant changes to the upstream and downstream\nsystems in Alexa on a daily basis, it is important to update\nour rewrites on a regular basis to remove stale and ineffective\nrewrites. We run daily jobs to mine the most recent rewrites\nin an ofﬂine fashion. This allows us to ﬁnd the most recent\nrewrites and serve them to users. It is noteworthy that in case\nof conﬂicts between the rewrites, we pick the most recent\nrewrite, since it has the latest data. We have online alarms\nand metrics to monitor daily jobs, since sometimes changes\nto the upstream and downstream Alexa components can im-\npact our rewrite mining algorithm. In case of large changes\nin our metrics, we do a dive deep into the data to ﬁnd the\nroot cause.\nOnline Service\nSince the Graph is static during the period it is used, and\nthere are many repetitive utterances per day, we opted to\nmine the rewrites as key-value pairs, where the original ut-\nterance is the key, and the rewrite is the value. For exam-\nple, we store ”play babe shark” → ”play baby shark” as\none entry. We then serve these pairs in a high-performance\ndatabase to meet the low latency requirement. This allows us\nto decouple the ofﬂine mining process and the online serving\nprocess for high availability and low latency requirements.\nOnline Performance\nFollowing the ofﬂine analysis and trafﬁc simulations, we\nlaunched the Graph rewrites in production in an A/B testing\nsetup. We monitored the performance of our rewrites against\n13186\nno-rewrites for over 2 weeks, and we observed more than\n30% average reduction in defect rate (p-value < 0.001),\nhelping millions of users. Here, the notion of defect is based\non a ML model which scores user dissatisfaction at ev-\nery turn. In a separate 9 week randomized control trial,\nwe also noted as defect decreased, a new dialog interac-\ntion was created for every 2 corrections made by the sys-\ntem (p-value < 0.01), which in turn translates to greater\nuser engagement. We further measured the win-loss ratio 3\nmonths after the system’s release by calculating the number\nof unique rewrites where rewriting is signiﬁcantly better -\nwin - or worse - loss - compared to no-rewrite option (we\nused Z-test to test the signiﬁcance, and setp-value threshold\nof 0.01). The post-launch win-loss ratio closely matched our\nofﬂine estimate (11.8online vs.12.0ofﬂine).\nWe have been running this application for over 9 months\nin production, and it has been serving millions of users since,\nimproving their experience on a daily basis without getting\nin their way. We know this for a fact since we have been\nmonitoring customer satisfaction metrics on a weekly ba-\nsis. We monitor the total number of rewrites, and the aver-\nage friction rate for the rewrites, along with average friction\nfor no-rewrites, where for the latter two, the aforementioned\n30% margin still prevails. On top of tracking online met-\nrics, we continue doing ofﬂine evaluations on a weekly ba-\nsis, where we sample our trafﬁc, and send it for annotation.\nCombining the online and ofﬂine metrics in a longitudinal\nfashion allows us to closely follow the changes in the cus-\ntomer experience, which is the ultimate metric for our sys-\ntem.\nConclusion\nAs conversational agents become more popular and grow\ninto new scopes, it is critical for these systems to have self-\nlearning mechanisms to ﬁx the recurring issues continuously\nwith minimal human intervention. In this paper, we pre-\nsented a self-learning system that is able to efﬁciently tar-\nget and rectify both systemic and customer errors at runtime\nby means of query reformulation. In particular, we proposed\na highly-scalable collaborative-ﬁltering mechanism based\non an absorbing Markov chain to surfacesuccessful utter-\nance reformulations in conversational AI agents. Our system\nachieves a high precision performance thanks to aggregating\nlarge amounts of cross-user data in an ofﬂine fashion, with-\nout adversely impacting users’ perceived latency by serv-\ning the rewrites in a look-up manner online. We have tested\nand deployed our system into production across millions of\nusers, reducing customer frictions by more than 30% and\nachieving a win-loss ratio of 11.8. Our solution has been\ncustomer-facing for over 9 months now, and it has helped\nmillions of users to have a more seamless experience with\nAlexa.\nAcknowledgements\nWe would very much like to thank Steven Wasik and his\nteam for their analysis into customer engagement and Jin\nHock Ong and his team, particularly Karen Stabile and Vin-\ncent Ly for their continued engineering support in maintain-\ning and monitoring the system as a whole. We also extend\nour appreciation to Benjamin Yao, and Jacky Yi for their\non-going effort in improving the blacklisting system, thus\nensuring the overall precision of the system.\nReferences\nFouss, F.; Faulkner, S.; Kolp, M.; Pirotte, A.; and Saerens,\nM. 2005. Web recommendation system based on a markov-\nchain model.Proceedings of the Seventh International Con-\nference on Enterprise Information Systems56–63.\nGao, J.; Galley, M.; and Li, L. 2018. Neural approaches to\nconversational AI.CoRR abs/1809.08267.\nGrinstead, C. M., and Snell, J. L. 1997. Introduction to\nProbability. American Mathematical Society.\nJansen, B. J.; Booth, D. L.; and Spink, A. 2005. Patterns\nof query reformulation during web searching.Journal of the\nAmerican Society for Information Science and T echnology\n60(7):1358–1371.\nKhorasani, E. S.; Zhenge, Z.; and Champaign, J. 2016. A\nmarkov chain collaborative ﬁltering model for course enroll-\nment recommendations. IEEE International Conference on\nBig Data.\nMohri, M.; Pereira, F.; and Riley, M. 2002. Weighted ﬁnite-\nstate transducers in speech recognition.Computer Speech &\nLanguage 16(1):69–88.\nSahoo, N.; Singh, P . V .; and Mukhopadhyay, T. 2012. A\nhidden markov model for collaborative ﬁltering.MIS Quar-\nterly.\nSarikaya, R. 2017. The technology behind personal digital\nassistants: An overview of the system architecture and key\ncomponents. IEEE Signal Processing Magazine34(1):67–\n81.\nSee, A.; Liu, P . J.; and Manning, C. D. 2017. Get to the\npoint: Summarization with pointer-generator networks.Pro-\nceedings of the 55th Annual Meeting of the Association for\nComputational Linguistics 1:1073–1083.\nSutskever, I.; Vinyals, O.; and Le, Q. V . 2014. Se-\nquence to sequence learning with neural networks. CoRR\nabs/1409.3215.\nTerveen, L., and Hill, W. 2001. Beyond recommender sys-\ntems: Helping people help each other.The New Millennium,\nJack Carroll.\nWang, J.; Huang, J. Z.; and Wu, D. 2015. Recommending\nhigh utility queries via query-reformulating graph.Mathe-\nmatical Problems in Engineering.\nXiaofei Zhu, Jiangfeng Guo, X. C. Y . L. 2012. More than\nrelevance: High utility query recommendation by mining\nusers’ search behaviors. CIKM’12, October 29–November\n2, Maui, HI, USA.\nZaharia, M.; Xin, R. S.; Wendell, P .; Das, T.; Armbrust, M.;\nDave, A.; Meng, X.; Rosen, J.; V enkataraman, S.; Franklin,\nM. J.; Ghodsi, A.; Gonzalez, J.; Shenker, S.; and Stoica, I.\n2016. Apache spark: A uniﬁed engine for big data process-\ning. Commun. ACM59(11):56–65.\n13187"
}