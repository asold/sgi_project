{
  "title": "The TALP–UPC Spanish–English WMT Biomedical Task: Bilingual Embeddings and Char-based Neural Language Model Rescoring in a Phrase-based System",
  "url": "https://openalex.org/W2515770991",
  "year": 2016,
  "authors": [
    {
      "id": "https://openalex.org/A5074210163",
      "name": "Marta R. Costa‐jussà",
      "affiliations": [
        "Universitat Politècnica de Catalunya",
        "National Student Clearinghouse Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A5029540488",
      "name": "Cristina España-Bonet",
      "affiliations": [
        "Universitat Politècnica de Catalunya",
        "National Student Clearinghouse Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A5055155740",
      "name": "Pranava Madhyastha",
      "affiliations": [
        "Universitat Politècnica de Catalunya",
        "National Student Clearinghouse Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A5032308508",
      "name": "Carlos Escolano",
      "affiliations": [
        "Universitat Politècnica de Catalunya",
        "National Student Clearinghouse Research Center"
      ]
    },
    {
      "id": "https://openalex.org/A5004224082",
      "name": "José A. R. Fonollosa",
      "affiliations": [
        "Universitat Politècnica de Catalunya",
        "National Student Clearinghouse Research Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2144945507",
    "https://openalex.org/W2098507980",
    "https://openalex.org/W2250660307",
    "https://openalex.org/W66137051",
    "https://openalex.org/W932413789",
    "https://openalex.org/W4241645538",
    "https://openalex.org/W2153653739",
    "https://openalex.org/W1938755728",
    "https://openalex.org/W1899794420",
    "https://openalex.org/W2398269847",
    "https://openalex.org/W1631260214",
    "https://openalex.org/W2951559648",
    "https://openalex.org/W2293547632",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2950577311",
    "https://openalex.org/W2951336364",
    "https://openalex.org/W1828724394",
    "https://openalex.org/W2952037945",
    "https://openalex.org/W2595715041",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2156985047",
    "https://openalex.org/W1860935423",
    "https://openalex.org/W2126725946",
    "https://openalex.org/W853920710",
    "https://openalex.org/W1614298861",
    "https://openalex.org/W2146574666",
    "https://openalex.org/W2251033195",
    "https://openalex.org/W2124140601",
    "https://openalex.org/W2252212383",
    "https://openalex.org/W2124807415"
  ],
  "abstract": "This paper describes the TALP–UPC system in the Spanish–English WMT 2016 biomedical shared task. Our system is a standard phrase-based system enhanced with vocabulary expansion using bilingual word embeddings and a characterbased neural language model with rescoring. The former focuses on resolving outof- vocabulary words, while the latter enhances the fluency of the system. The two modules progressively improve the final translation as measured by a combination of several lexical metrics.",
  "full_text": "Proceedings of the First Conference on Machine Translation, V olume 2: Shared Task Papers, pages 463–468,\nBerlin, Germany, August 11-12, 2016.c⃝2016 Association for Computational Linguistics\nThe TALP–UPC Spanish–English WMT Biomedical Task:\nBilingual Embeddings and Char-based Neural Language Model Rescoring\nin a Phrase-based System\nMarta R. Costa-juss`a, Cristina Espa˜na-Bonet, Pranava Madhyastha,\nCarlos Escolano, Jos´e A. R. Fonollosa\nTALP Research Center\nUniversitat Polit`ecnica de Catalunya, Barcelona\n{marta.ruiz,jose.fonollosa}@upc.edu, {cristinae,pranava}@cs.upc.edu,\ncarlos.escolano@est.fib.upc.edu\nAbstract\nThis paper describes the TALP–UPC sys-\ntem in the Spanish–English WMT 2016\nbiomedical shared task. Our system is\na standard phrase-based system enhanced\nwith vocabulary expansion using bilin-\ngual word embeddings and a character-\nbased neural language model with rescor-\ning. The former focuses on resolving out-\nof-vocabulary words, while the latter en-\nhances the ﬂuency of the system. The two\nmodules progressively improve the ﬁnal\ntranslation as measured by a combination\nof several lexical metrics.\n1 Introduction\nMachine Translation (MT) has been evolving in\nrecent years achieving successful translations as\nshown by international evaluations such as WMT1\nand increasing use of MT in commercial applica-\ntions. However, speciﬁc domains like legal, bio-\nmedical, etc., still lag behind the state-of-the-art\nMT systems. This can mostly be attributed to the\nlack of available corpora. The new biomedical\ntask from WMT 2016 especially helps in improv-\ning our understanding in this direction.\nIn this paper, we describe our participation in\nthe WMT 2016 biomedical task. We participated\nwith a phrase-based SMT system enhanced with\nbilingual word embeddings and a character-based\nneural language model. Section 2 presents some\nrelated work to our approach. Next, Section 3 in-\ntroduces the theoretical aspects of the system com-\nponents and Section 4 the experiments. Finally,\nwe justify our choice for the ﬁnal submission and\ndraw the conclusions in Section 5.\n1http://www.statmt.org/wmt16\n2 Related Work\nIn this paper, we are interested in research in the\narea that target OOVs and approaches to re-rank\nn-best lists of translations.\nOur work closely follows Vulic and Moens\n(2015) and Zhao et al. (2015) in spirit, where word\nvectors are used to induce bilingual lexicons of\nwords or phrases. We go a step further and build\nlexicons from bilingual word embeddings to be\nlater used within an SMT system.\nThere is also a rich body of recent literature that\nfocuses on obtaining bilingual word embeddings\nusing aligned corpora (Bhattarai, 2012; Gouws et\nal., 2015; Ko ˇcisk`y et al., 2014). We approach the\nproblem differently and obtain embeddings sepa-\nrately on monolingual corpora and then use super-\nvision in the form of a small sparse bilingual dic-\ntionary. This is similar to Mikolov et al. (2013b),\nwho obtain monolingual embeddings for both the\nlanguages separately and then learn transforma-\ntion for projecting the embeddings of words onto\nembeddings of the word translation pairs using a\nbig bilingual dictionary.\nOn the other hand, there have been several\nlanguage models used for rescoring in SMT.\nFor example, neural feed-forward language mod-\nels (Schwenk et al., 2006) have been used to\nrescore both n-gram-based and phrase-based sys-\ntems. Mikolov (2012) re-ranks n-best lists with\nrecurrent neural networks. Vaswani et al. (2013)\ncombine feed-forward language models, with rec-\ntiﬁed linear units and noise-contrastive estimation.\nLuong et al. (2015) propose to use deeper neu-\nral models which improve re-ranking. In this pa-\nper, we are using Kim et al. (2016) a character-\nbased language model to re-rank the output of the\nphrase-based system.\n463\n3 The Translation System\nThe TALP-UPC translation system is built on\nthree different components. We describe their the-\noretical basis in the following subsections.\n3.1 Phrase-based SMT\nThe standard phrase-based machine translation\nsystem (Koehn et al., 2003) focuses on ﬁnding\nthe most probable target sentence given the source\nsentence. The phrase-based system has evolved\nfrom the noisy-channel to the log-linear model\nwhich combines a set of feature functions in the\ndecoder, including the translation and language\nmodel, the reordering model and the lexical mod-\nels. Although the phrase-based system is a com-\nmoditized technology used at the academic and\ncommercial level, there are still many challenges\nto solve, such as OOVs.\n3.2 Vocabulary Expansion using Bilingual\nWord-Embeddings\nWe look at this task as a bilinear prediction task as\nproposed by (Madhyastha et al., 2014). The pro-\nposed model makes use of word embeddings of\nboth languages with no additional features. The\nbasic function is formulated —the probability of\na target word given a source word— as log-linear\nmodel and takes the following form:\nPr(t|s; W) = exp{φ˜s(s)⊤Wφ˜t(t)}∑\nt′ exp{φ˜s(s)⊤Wφ˜t(t′)} (1)\nWhere φ(.) denotes the n-dimensional distributed\nrepresentation of the words, and we assume we\nhave both source (φ˜s) embeddings and target (φ˜t)\nembeddings.\nEssentially, our problem reduces to: a) ﬁrst get-\nting the corresponding word embeddings of the\nvocabularies on both the languages on a signiﬁ-\ncantly large monolingual corpus and b) estimating\nW given a relatively small dictionary. To learnW\nwe use the source word to target word dictionaries\nas training supervision.\nWe learn W by minimizing the negative\nlog-likelihood of the dictionary using a nu-\nclear norm regularized objective as: L(W) =\n−∑\ns,t log(Pr(t|s; W)) +λ∥W∥∗. λis the con-\nstant that controls the capacity of W. To ﬁnd the\noptimum, we follow the previous work and use an\noptimization scheme based on Forward-Backward\nSplitting (FOBOS) (Singer and Duchi, 2009).\nTable 1: Size of the parallel (top) and monolin-\ngual (bottom) corpora used to train the translation\nsystems\nCorpus Segments Words V ocab\nBiomedical 1 · 106 20 · 106 0.3 · 106\nQuest 13 · 106 340 · 106 0.5 · 106\nBio-mono/en 0.1 · 106 2 · 106 0.1 · 106\nBio-mono/es 0.01 · 106 0.1 · 106 0.01 · 106\nWikipedia/en 92 · 106 1900 · 106 2.0 · 106\nWikipedia/es 20 · 106 465 · 106 0.8 · 106\n3.3 Character-based Neural Language Model\nLanguage models based on Recurrent Neural Net-\nworks are currently one of the best performing ap-\nproaches in terms of perplexity (Mikolov et al.,\n2010). They are also a good re-ranking option\nin tasks such as speech recognition and machine\ntranslation. However, the standard lookup-based\nword embeddings are limited to a ﬁnite-size vo-\ncabulary for both computational and sparsity rea-\nsons. Moreover, the orthographic representation\nof the words is completely ignored. The standard\nlearning process is blind to the presence of stems,\npreﬁxes, sufﬁxes and any other kind of afﬁxes in\nwords.\nAs a solution to those drawbacks, new alterna-\ntive character-based word embeddings have been\nrecently proposed for tasks as language model-\ning (Kim et al., 2016; Ling et al., 2015), parsing\n(Ballesteros et al., 2015) or part-of-speech tagging\n(Ling et al., 2015; Santos and Zadrozny, 2014).\nFor our system we selected the best character-\nbased embedding architecture proposed by Kim et\nal. (Kim et al., 2016). The computation of the rep-\nresentation of each word starts with a character-\nbased embedding layer that associates each word\n(sequence of characters) with a sequence of vec-\ntors. This sequence of vectors is then processed\nwith a set of 1D convolution ﬁlters of different\nlengths (from 1 to 7 characters) followed with a\nmax pooling layer and two additional highway\nlayers. The output of the second highway layer\nprovide us with the ﬁnal vector representation of\neach source word that replaces the standard source\nword embedding in the recurrent neural network\nused for language modeling (Kim et al., 2016).\n464\n4 Experimental Framework\n4.1 Data\nOur main corpus is the compilation of the corpora\nassigned for the shared task, which was built us-\ning scientiﬁc publications gathered from the Sci-\nelo database. We focus on the Spanish–English\nlanguage pair, for which the size of the corpora is\nsummarised in Table 1. We further increase the\nvocabulary of the system by using standard paral-\nlel corpora for the Spanish–English language pair\n(i.e., UN corpora, Europarl corpora, News corpus,\netc.2). This corpus appears as Quest in Table 1.\nFor the monolingual corpus we use an English and\nSpanish Wikipedia dump3.\nThe corpora has been pre-processed with a stan-\ndard pipeline for both Spanish and English: to-\nkenizing and keeping parallel sentences between\n1 and 80 words. Additionally, for Spanish we\nused Freeling (Padr´o and Stanilovsky, 2012) to to-\nkenize pronouns from verbs (i.e. comenz´andose to\ncomenzando + se), we also split prepositions and\narticles, i.e. del to de + el and al to a + el. This\nwas done for similarity to English.\nWe divided the provided parallel corpus into\ntraining, development and test sets. Sentences\nfrom development and test set were taken ran-\ndomly, proportionally to the amount of Medline\nand Scielo (biomedical and health) sources and\nonly from unique parallel sentences.\nSince the domain of the test set is the same as\nthe domain of training corpus, the number of OOV\nwords is small. Table 2 shows the total number and\npercentage of unknown words in our in-house de-\nvelopment and test sets with respect to translation\ntables (see the following section). For compari-\nson, we also include the ﬁgures for the two test\nsets made available for the ﬁnal evaluation.\n4.2 System Description\nAs introduced in the previous section, three differ-\nent modules build our system: the SMT engine,\nthe module to resolve OOVs and the module for\nre-reranking.\nSMT Engine. Three different state-of-the-art\nphrase-based SMT translation systems are trained\n2In particular, we use the parallel data given\nfor the Quality Estimation task at WMT13, http:\n//statmt.org/˜buck/wmt13qe/wmt13qe_t13_\nt2_MT_corpus.tgz\n3Dumps downloaded from https://dumps.\nwikimedia.org in January 2015.\non the parallel corpora detailed in Table 1. For the\npurely in-domain system, we use only the biomed-\nical data made available for the task (STT systems,\nsmall translation table). For more general systems,\nwe also use the Quest data; we name these systems\nBTT (big translation table).\nFor the in-domain system, a 5-gram language\nmodel is estimated on the target side of the cor-\npus using interpolated Kneser-Ney discounting\nwith SRILM (Stolcke, 2002) ( SLM, small lan-\nguage model). For the extended systems, we use\nall the monolingual corpora available and the tar-\nget side of the large parallel corpus ( BLM, big\nlanguage model). Word alignment is done with\nGIZA++ (Och and Ney, 2003) and both phrase ex-\ntraction and decoding are done with the Moses\npackage (Koehn et al., 2007). The optimisa-\ntion of the weights of the model is trained with\nMERT (Och, 2003) against the BLEU (Papineni\net al., 2002) evaluation metric on devBio.\nOOVs resolution. This module ﬁrst obtains\nbilingual embeddings from the monolingual ones\nas explained in Section 3.2. For estimating mono-\nlingual word vector models, we use the CBOW al-\ngorithm as implemented in the Word2Vec pack-\nage (Mikolov et al., 2013a) using a 5-token win-\ndow. We obtain 300 dimension vectors for English\nand Spanish from the monolingual and the source\nside of the parallel corpora in Table 1. The bilin-\ngual counterpart has been estimated using 34,806\nwords from the Apertium bilingual dictionary4 as\nseed lexicon divided for training and validation.\nEach bilingual pair has an associated probability\ngiven by Eq. 1. We keep the top-10 pairs for each\nout-of-vocabulary word in the test (development)\nset and include these new translation options at\ndecoding time. Since we are only dealing with\nOOVs, the new options do not interact with the\nother phrase pairs in the translation table, but there\nis interaction with the language model.\nRe-ranking. The 1000-best list of translations\ngiven by the SMT engine is re-ranked using the\ncharacted-based language model described in Sec-\ntion 3.3. It has 1D convolutional ﬁlters of width\n[1,2,3,4,5,6,7] and size [50, 100, 150, 200, 200,\n200, 200] for a total of 1,100 ﬁlters with a tanh ac-\ntivation, 2 highway layers with a ReLU activation,\nand 2 LSTM with 650 hidden units. The network\n4http://repositori.upf.edu/handle/\n10230/17110\n465\nTable 2: Figures –tokens and OOVs– on the development and test sets used in the experiments\nEnglish Spanish\nSeg. Tokens OOV STT OOVBTT Tokens OOV STT OOVBTT\ndevBio 1000 18967 16 (0.08%) 2 (0.01%) 19931 14 (0.07%) 6 (0.03%)\ntestBio 1000 26105 31 (0.11%) 19 (0.07%) 27651 25 (0.09%) 9 (0.03%)\nBiological 4344 115709 434 (0.37%) 333 (0.29%) 126008 415 (0.33%) 254 (0.20%)\nHealth 5111 125624 133 (0.10%) 98 (0.08%) 146368 160 (0.11%) 40 (0.03%)\nhas been trained on the monolingual part of the in-\ndomain data (Biomedical corpus in Table 1).\n4.3 Results\nWe evaluate the performance of each module\nwhen added to the three standard SMT sys-\ntems built with different amount of training data\n(STTSLM, STTBLM, BTTBLM). In the follow-\ning, we denote the module for OOV resolution\nwith oov and the module for re-reraking with\nreranked. For the total.reranked system, we re-\nranked then-best lists for the thirteen systems with\nour neural language model. We conduct the eval-\nuation automatically with a set of lexical metrics\ncalculated with the Asiya toolkit 5 (Gim´enez and\nM`arquez, 2010). Table 3 reports the results for\nthe English-to-Spanish translation systems and Ta-\nble 4 for the Spanish-to-English ones.\nThe ﬁrst thing to notice is that the best trans-\nlation is obtained when only in-domain data\nare used to build the translation model. This\nis true in both directions. When going from\nSpanish into English, we obtain 0.45 BLEU\npoints of improvement when adding the oov mod-\nule to the in-domain system (STTSLM.oov) and\nan additional 0.15 with the re-ranking module\n(STTSLM.oov.reranked). Even if the number of\nOOV is only a 0.09% in this test set, the improve-\nment with this module is consistent through all\nmetrics. The main reason is that making available\nnew translation options at decoding time allows\nthe language model to modify the sentence as a\nwhole, and the neighbouring words can be modi-\nﬁed accordingly.\nIn the English-to-Spanish direction, the trends\nare less homogeneous through the set of met-\nrics. For BLEU and METEOR (with the stem-\nming variant, MTRst), the best system is still\nSTTSLM.oov. However, with NIST and TER, the\nbest system is STTBLM. In this case, enlarging\nthe language model has a similar effect as injecting\n5http://nlp.cs.upc.edu/asiya\nnew vocabulary through OOV translations. This\nis because only a 31% of the OOV belong to the\nbiomedical domain, suggesting that in this case\nand for an in-domain test set, it is important to gain\nﬂuency on the general domain phrases. The effect\nof the re-ranking module is more evident in this di-\nrection: the more data one uses, the more distinct\nthe ﬁnal n-best list is and the more improvement\none can obtain. For the in-domain system the re-\nranking is not promoting a better translation, but\nfor the general system the improvement is signiﬁ-\ncant.\n5 Conclusions\nWe have built thirteen translation systems per di-\nrection. The ones chosen for the ﬁnal submis-\nsion follow two criteria: i) they have a top per-\nformance according to BLEU and METEOR (the\nofﬁcial metrics) and, ii) they allow us a coher-\nent comparison among languages and methodolo-\ngies. With this criteria, our primary submission\nboth for the health and biological test sets is the\nstrictly in-domain system with the OOV module\n(STTSLM.oov). For comparison, we also submit-\nted our baseline as a second run: the same system\nwithout the OOV module ( STTSLM). Finally, we\nsubmitted as third run a system with re-ranking of\na 1000-best list. Due to time constraints, we could\nnot submit the system that re-ranks all the n-best\nlists for the thirteen systems, total.reranked, but\nwe used instead the two most promising options\nper direction.\nAccording to the preliminary results of the\nshared task, the OOV module consistently im-\nproves the translations with respect to our base-\nline specially in the health subdomain as measured\nby BLEU. The effect is similar to the results in\nour in-house test set. On the other hand, the re-\nranking module is also always better than the in-\ndomain phrase-based baseline and, in this case, the\nperformance on the competition test set is signif-\nicantly better than the one in our test set, espe-\n466\nTable 3: Automatic evaluation of the in-house test set for the En2Es systems\nWER PER TER BLEU NIST GTM-2 MTRst MTRpa RG-S* ULC\nBTTBLM.oov 48.45 29.82 44.27 43.84 8.81 36.30 61.58 62.87 49.85 66.03\nBTTBLM.oov.reranked 47.58 29.74 43.56 44.43 8.90 36.97 62.01 63.25 50.43 67.16\nBTTBLM 47.74 30.39 43.72 43.61 8.86 36.51 61.50 62.76 49.98 66.19\nBTTBLM.reranked 47.64 29.91 43.52 44.24 8.89 36.90 61.88 63.14 50.29 66.95\nSTTBLM.oov 48.00 29.60 43.73 44.32 8.87 36.65 62.13 63.32 50.12 66.88\nSTTBLM.oov.reranked 47.22 29.85 43.11 44.57 8.96 37.21 62.22 63.42 50.44 67.57\nSTTBLM 47.01 29.93 42.81 44.51 8.98 37.36 62.28 63.47 50.49 67.75\nSTTBLM.reranked 47.10 29.91 42.96 44.65 8.97 37.40 62.31 63.46 50.68 67.78\nSTTSLM.oov 47.84 29.28 43.61 44.99 8.88 37.36 62.33 63.44 50.51 67.60\nSTTSLM.oov.reranked 47.41 29.82 43.25 44.52 8.94 37.29 62.25 63.36 50.68 67.54\nSTTSLM 47.29 29.84 43.16 44.64 8.96 37.58 62.27 63.42 50.56 67.71\nSTTSLM.reranked 47.40 29.93 43.24 44.39 8.94 37.36 62.21 63.30 50.56 67.44\ntotal.reranked 47.06 29.82 43.03 44.75 8.98 37.56 62.33 63.53 50.66 67.88\nTable 4: Automatic evaluation of the in-house test set for the Es2En systems\nWER PER TER BLEU NIST GTM-2 MTRst MTRpa RG-S* ULC\nBTTBLM.oov 50.95 29.98 46.79 40.94 8.59 35.02 35.03 37.28 49.13 65.30\nBTTBLM.oov.reranked 50.41 29.75 46.23 41.58 8.65 35.52 35.25 37.48 49.50 66.24\nBTTBLM 50.21 29.33 45.98 41.97 8.68 35.88 35.44 37.65 50.01 66.97\nBTTBLM.reranked 50.41 29.63 46.28 41.62 8.65 35.51 35.27 37.53 49.50 66.29\nSTTBLM.oov 50.75 29.95 46.68 40.82 8.61 34.83 35.05 37.12 49.15 65.27\nSTTBLM.oov.reranked 50.19 29.22 46.04 42.10 8.71 35.72 35.57 37.65 49.95 67.04\nSTTBLM 50.91 29.74 46.74 41.16 8.62 34.97 35.33 37.40 49.39 65.67\nSTTBLM.reranked 50.27 29.08 46.01 42.19 8.72 35.79 35.62 37.66 50.08 67.20\nSTTSLM.oov 49.79 29.45 45.62 42.16 8.75 35.94 35.57 37.60 50.13 67.31\nSTTSLM.oov.reranked 50.15 29.08 45.99 42.30 8.71 35.88 35.65 37.66 50.10 67.30\nSTTSLM 50.62 29.53 46.46 41.71 8.65 35.47 35.46 37.48 49.71 66.34\nSTTSLM.reranked 50.25 29.12 46.04 42.13 8.70 35.76 35.59 37.62 49.97 67.09\ntotal.reranked 50.06 29.42 45.93 42.06 8.71 35.80 35.47 37.65 49.93 67.00\ncially for English-to-Spanish. Run 3, the system\nthat includes re-ranking with a char-based neural\nlanguage model, is 2 points of BLEU over the av-\nerage value among participants in the biological\nsubdomain and 1 point of BLEU on the health sub-\ndomain.\nAcknowledgements\nThis work is supported by the 7th Framework Pro-\ngram of the European Commission through the In-\nternational Outgoing Fellowship Marie Curie Ac-\ntion (IMTraP-2011-29951) and also by the Span-\nish Ministerio de Econom´ıa y Competitividad and\nEuropean Regional Development Fund, contract\nTEC2015-69266-P (MINECO/FEDER, UE).\nReferences\nMiguel Ballesteros, Chris Dyer, and Noah A. Smith.\n2015. Improved transition-based parsing by model-\ning characters instead of words with lstms. In Pro-\nceedings of the 2015 Conference on Empirical Meth-\nods in Natural Language Processing , pages 349–\n359, Lisbon, Portugal, September.\nAlexandre Klementiev Ivan Titov Binod Bhattarai.\n2012. Inducing Crosslingual Distributed Represen-\ntations of Words. In Proceedings of COLING 2012,\npages 1459–1474, Mumbai, India, December.\nJes´us Gim ´enez and Llu ´ıs M`arquez. 2010. Asiya: an\nOpen Toolkit for Automatic Machine Translation\n(Meta-)Evaluation. The Prague Bulletin of Mathe-\nmatical Linguistics, 94:77–86.\nStephan Gouws, Yoshua Bengio, and Greg Corrado.\n2015. BilBOW A: Fast Bilingual Distributed Rep-\nresentations without Word Alignments. In Proceed-\nings of the 32nd International Conference on Ma-\nchine Learning, ICML 2015, Lille, France, 6-11 July\n2015, pages 748–756, July.\nYoon Kim, Yacine Jernite, David Sontag, and Alexan-\nder M. Rush. 2016. Character-aware neural lan-\nguage models. In Proceedings of the 30th AAAI\nConference on Artiﬁcial Intelligence (AAAI’16).\n467\nTom´aˇs Koˇcisk`y, Karl Moritz Hermann, and Phil Blun-\nsom. 2014. Learning bilingual word representa-\ntions by marginalizing alignments. arXiv preprint\narXiv:1405.0947.\nPhilipp Koehn, Franz Joseph Och, and Daniel Marcu.\n2003. Statistical Phrase-Based Translation. In Proc.\nof the 41th Annual Meeting of the Association for\nComputational Linguistics.\nPhilipp Koehn, Hieu Hoang, Alexandra Birch Mayne,\nChristopher Callison-Burch, Marcello Federico,\nNicola Bertoldi, Brooke Cowan, Wade Shen, Chris-\ntine Moran, Richard Zens, Chris Dyer, Ondrej Bo-\njar, Alexandra Constantin, and Evan Herbst. 2007.\nMoses: Open source toolkit for statistical machine\ntranslation. In Annual Meeting of the Association\nfor Computation Linguistics (ACL), Demonstration\nSession, pages 177–180, June.\nWang Ling, Chris Dyer, Alan W Black, Isabel Tran-\ncoso, Ramon Fermandez, Silvio Amir, Luis Marujo,\nand Tiago Luis. 2015. Finding function in form:\nCompositional character models for open vocabu-\nlary word representation. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1520–1530, Lisbon, Portu-\ngal, September.\nThang Luong, Michael Kayser, and Christopher D.\nManning. 2015. Deep neural language models for\nmachine translation. In Proceedings of the Nine-\nteenth Conference on Computational Natural Lan-\nguage Learning , pages 305–309, Beijing, China,\nJuly.\nSwaroop Pranava Madhyastha, Xavier Carreras, and\nAriadna Quattoni. 2014. Learning task-speciﬁc\nbilexical embeddings. In Proceedings of COLING\n2014, the 25th International Conference on Compu-\ntational Linguistics: Technical Papers , pages 161–\n171.\nTomas Mikolov, Martin Karaﬁ ´at, Luk ´as Burget, Jan\nCernock´y, and Sanjeev Khudanpur. 2010. Recur-\nrent neural network based language model. In IN-\nTERSPEECH 2010, 11th Annual Conference of the\nInternational Speech Communication Association,\nMakuhari, Chiba, Japan, September 26-30, 2010 ,\npages 1045–1048.\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey\nDean. 2013a. Efﬁcient Estimation of Word Repre-\nsentations in Vector Space. In Proceedings of Work-\nshop at ICLR. http://code.google.com/p/word2vec.\nTomas Mikolov, Quoc V . Le, and Ilya Sutskever.\n2013b. Exploiting Similarities among Languages\nfor Machine Translation. abs/1309.4168.\nTomas Mikolov. 2012. Statistical Language Models\nbased on Neural Networks. Ph.D. thesis, Brno Uni-\nversity of Technology.\nFranz Josef Och and Hermann Ney. 2003. A sys-\ntematic comparison of various statistical alignment\nmodels. Computational Linguistics, 29(1):19–51.\nFranz Josef Och. 2003. Minimum Error Rate Train-\ning in Statistical Machine Translation. In Proceed-\nings of the Association for Computational Linguis-\ntics, pages 160–167, Sapporo, Japan, July 6-7.\nLlu´ıs Padr´o and Evgeny Stanilovsky. 2012. Freeling\n3.0: Towards wider multilinguality. In International\nConference on language Resources and Evaluation.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2002. BLEU: A Method for Automatic\nEvaluation of Machine Translation. In Proceed-\nings of the Association of Computational Linguis-\ntics, pages 311–318.\nCicero D. Santos and Bianca Zadrozny. 2014.\nLearning character-level representations for part-of-\nspeech tagging. In Proceedings of the 31st Interna-\ntional Conference on Machine Learning (ICML-14),\npages 1818–1826.\nHolger Schwenk, Marta R. Costa-Juss`a, and Jos´e A. R.\nFonollosa. 2006. Continuous space language mod-\nels for the IWSLT 2006 task. In 2006 International\nWorkshop on Spoken Language Translation, IWSLT\n2006, Keihanna Science City, Kyoto, Japan, Novem-\nber 27-28, 2006, pages 166–173.\nYoram Singer and John C Duchi. 2009. Efﬁcient\nlearning using forward-backward splitting. In Ad-\nvances in Neural Information Processing Systems ,\npages 495–503.\nAndreas Stolcke. 2002. SRILM - An Extensible Lan-\nguage Modeling Toolkit. In Proceedings of the Sev-\nenth International Conference of Spoken Language\nProcessing (ICSLP2002), pages 901–904, Denver,\nColorado, USA.\nAshish Vaswani, Yinggong Zhao, Victoria Fossum,\nand David Chiang. 2013. Decoding with large-\nscale neural language models improves translation.\nIn Proceedings of the 2013 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1387–1392, Seattle, Washington, USA, October.\nIvan Vulic and Marie-Francine Moens. 2015.\nBilingual Word Embeddings from Non-Parallel\nDocument-Aligned Data Applied to Bilingual Lex-\nicon Induction. In Proceedings of the 53rd Annual\nMeeting of the Association for Computational Lin-\nguistics and the 7th International Joint Conference\non Natural Language Processing of the Asian Fed-\neration of Natural Language Processing, ACL 2015,\npages 719–725, July.\nKai Zhao, Hany Hassan, and Michael Auli. 2015.\nLearning Translation Models from Monolingual\nContinuous Representations. In The 2015 Con-\nference of the North American Chapter of the As-\nsociation for Computational Linguistics: Human\nLanguage Technologies, NAACL HLT 2015 , pages\n1527–1536, June.\n468",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8112030029296875
    },
    {
      "name": "Phrase",
      "score": 0.7934389114379883
    },
    {
      "name": "Task (project management)",
      "score": 0.6732808351516724
    },
    {
      "name": "Language model",
      "score": 0.6311395168304443
    },
    {
      "name": "Fluency",
      "score": 0.5817739963531494
    },
    {
      "name": "Machine translation",
      "score": 0.5724226236343384
    },
    {
      "name": "Vocabulary",
      "score": 0.5693188905715942
    },
    {
      "name": "Natural language processing",
      "score": 0.5552849769592285
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5432842969894409
    },
    {
      "name": "Word (group theory)",
      "score": 0.4452718198299408
    },
    {
      "name": "Speech recognition",
      "score": 0.43473899364471436
    },
    {
      "name": "Linguistics",
      "score": 0.1796453595161438
    },
    {
      "name": "Engineering",
      "score": 0.056738078594207764
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ]
}