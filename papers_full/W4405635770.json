{
  "title": "Age against the machine—susceptibility of large language models to cognitive impairment: cross sectional analysis",
  "url": "https://openalex.org/W4405635770",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2554619001",
      "name": "Roy Dayan",
      "affiliations": [
        "Hadassah Medical Center",
        "Hebrew University of Jerusalem"
      ]
    },
    {
      "id": "https://openalex.org/A4222665283",
      "name": "Benjamin Uliel",
      "affiliations": [
        "Hebrew University of Jerusalem",
        "Hadassah Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2903645833",
      "name": "Gal Koplewitz",
      "affiliations": [
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A2554619001",
      "name": "Roy Dayan",
      "affiliations": [
        "Hadassah Medical Center",
        "Hebrew University of Jerusalem"
      ]
    },
    {
      "id": "https://openalex.org/A4222665283",
      "name": "Benjamin Uliel",
      "affiliations": [
        "Hadassah Medical Center",
        "Hebrew University of Jerusalem"
      ]
    },
    {
      "id": "https://openalex.org/A2903645833",
      "name": "Gal Koplewitz",
      "affiliations": [
        "Tel Aviv University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4361298490",
    "https://openalex.org/W4383872904",
    "https://openalex.org/W2900239614",
    "https://openalex.org/W4386510404",
    "https://openalex.org/W4394767601",
    "https://openalex.org/W4366824288",
    "https://openalex.org/W4385612923",
    "https://openalex.org/W4389683892",
    "https://openalex.org/W4388215433",
    "https://openalex.org/W4312067799",
    "https://openalex.org/W6854732739",
    "https://openalex.org/W4365484793",
    "https://openalex.org/W4393946650",
    "https://openalex.org/W4400324908",
    "https://openalex.org/W4393054030",
    "https://openalex.org/W4372354614",
    "https://openalex.org/W2165758561",
    "https://openalex.org/W2163632555",
    "https://openalex.org/W2066380143",
    "https://openalex.org/W4249279487",
    "https://openalex.org/W1971335599",
    "https://openalex.org/W2120357670",
    "https://openalex.org/W2138502025",
    "https://openalex.org/W4281700925",
    "https://openalex.org/W2146008734",
    "https://openalex.org/W2075468176",
    "https://openalex.org/W2136728805",
    "https://openalex.org/W2153610021",
    "https://openalex.org/W4229813139",
    "https://openalex.org/W2044560826",
    "https://openalex.org/W4223552420",
    "https://openalex.org/W3141907569",
    "https://openalex.org/W2921795652",
    "https://openalex.org/W2793856556"
  ],
  "abstract": "Abstract Objective To evaluate the cognitive abilities of the leading large language models and identify their susceptibility to cognitive impairment, using the Montreal Cognitive Assessment (MoCA) and additional tests. Design Cross sectional analysis. Setting Online interaction with large language models via text based prompts. Participants Publicly available large language models, or “chatbots”: ChatGPT versions 4 and 4o (developed by OpenAI), Claude 3.5 “Sonnet” (developed by Anthropic), and Gemini versions 1 and 1.5 (developed by Alphabet). Assessments The MoCA test (version 8.1) was administered to the leading large language models with instructions identical to those given to human patients. Scoring followed official guidelines and was evaluated by a practising neurologist. Additional assessments included the Navon figure, cookie theft picture, Poppelreuter figure, and Stroop test. Main outcome measures MoCA scores, performance in visuospatial/executive tasks, and Stroop test results. Results ChatGPT 4o achieved the highest score on the MoCA test (26/30), followed by ChatGPT 4 and Claude (25/30), with Gemini 1.0 scoring lowest (16/30). All large language models showed poor performance in visuospatial/executive tasks. Gemini models failed at the delayed recall task. Only ChatGPT 4o succeeded in the incongruent stage of the Stroop test. Conclusions With the exception of ChatGPT 4o, almost all large language models subjected to the MoCA test showed signs of mild cognitive impairment. Moreover, as in humans, age is a key determinant of cognitive decline: “older” chatbots, like older patients, tend to perform worse on the MoCA test. These findings challenge the assumption that artificial intelligence will soon replace human doctors, as the cognitive impairment evident in leading chatbots may affect their reliability in medical diagnostics and undermine patients’ confidence.",
  "full_text": "RESEARCHRESEARCH\n1Department of Neurology, \nHadassah Medical Center, \nJerusalem, Israel\n2Faculty of Medicine, Hebrew \nUniversity, Jerusalem, Israel\n3QuantumBlack Analytics, \nLondon, UK\n4Faculty of Medicine, Tel Aviv \nUniversity, Tel Aviv, Israel\nCorrespondence to: G Koplewitz  \ngalkop@gmail.com \n(ORCID 0000-0003-4906-0779)\nAdditional material is published \nonline only. To view please visit \nthe journal online.\nCite this as: BMJ 2024;387:e081948 \nhttp:/ /dx.doi.org/10.1136/\nbmj\n-\n2024\n-\n081948\nAccepted: 27 October 2024\nAge against the machine—susceptibility of large language \nmodels to cognitive impairment: cross sectional analysis\nRoy Dayan,1,2 Benjamin Uliel,1,2 Gal Koplewitz3,4\nABSTRACT\nOBJECTIVE\nTo evaluate the cognitive abilities of the leading large \nlanguage models and identify their susceptibility to \ncognitive impairment, using the Montreal Cognitive \nAssessment (MoCA) and additional tests.\nDESIGN\nCross sectional analysis.\nSETTING\nOnline interaction with large language models via text \nbased prompts.\nPARTICIPANTS\nPublicly available large language models, or \n“chatbots”: ChatGPT versions 4 and 4o (developed \nby OpenAI), Claude 3.5 “Sonnet” (developed by \nAnthropic), and Gemini versions 1 and 1.5 (developed \nby Alphabet).\nASSESSMENTS\nThe MoCA test (version 8.1) was administered to \nthe leading large language models with instructions \nidentical to those given to human patients. Scoring \nfollowed official guidelines and was evaluated by \na practising neurologist. Additional assessments \nincluded the Navon figure, cookie theft picture, \nPoppelreuter figure, and Stroop test.\nMAIN OUTCOME MEASURES\nMoCA scores, performance in visuospatial/executive \ntasks, and Stroop test results.\nRESULTS\nChatGPT 4o achieved the highest score on the MoCA \ntest (26/30), followed by ChatGPT 4 and Claude \n(25/30), with Gemini 1.0 scoring lowest (16/30). All \nlarge language models showed poor performance in \nvisuospatial/executive tasks. Gemini models failed at \nthe delayed recall task. Only ChatGPT 4o succeeded in \nthe incongruent stage of the Stroop test.\nCONCLUSIONS\nWith the exception of ChatGPT 4o, almost all large \nlanguage models subjected to the MoCA test showed \nsigns of mild cognitive impairment. Moreover, as in \nhumans, age is a key determinant of cognitive decline: \n“older” chatbots, like older patients, tend to perform \nworse on the MoCA test. These findings challenge \nthe assumption that artificial intelligence will soon \nreplace human doctors, as the cognitive impairment \nevident in leading chatbots may affect their reliability \nin medical diagnostics and undermine patients’ \nconfidence.\nIntroduction\nOver the past few years, we have witnessed colossal \nadvancements in the field of artificial intelligence, \nparticularly in the generative capacity of large \nlanguage models.\n1 The leading models in this domain, \nsuch as OpenAI’s ChatGPT, Alphabet’s Gemini, \nand Anthropic’s Claude, have shown the ability to \ncomplete both general purpose and specialised tasks \nsuccessfully, using simple text based interactions. In \nthe field of medicine, these developments have led \nto a flurry of speculation, both excited and fearful: \ncan artificial intelligence chatbots surpass human \nphysicians? If so, which practices and specialties are \nmost suspect? \n2\nSince late 2022, when ChatGPT was first released for \nfree online use, countless studies have been published \nin medical journals, comparing the performance of \nhuman physicians with that of these supercomputers, \nwhich have been “trained” on a corpus of every text \nknown to man. Although large language models \nhave been shown to blunder on occasion (citing, \nfor example, journal articles that do not exist), they \nhave proved remarkably adept at a range of medical \nexaminations, outscoring human physicians at \nqualifying examinations taken at different stages of a \ntraditional medical training.\n3  4 These have included \noutperforming cardiologists in the European core \ncardiology examinations, Israeli residents in their \ninternal medicine board examinations, Turkish \nsurgeons in the Turkish (theoretical) thoracic surgery \nexaminations, and German gynaecologists in the \nGerman obstetrics and gynaecology examinations.\n4-7 \nTo our great distress, they have even outscored \nneurologists like ourselves in the neurology board \nexamination.\n8\nIn a few domains, such as the Royal College of \nRadiologists examination, the Iranian periodontics \nexaminations, the Taiwanese family medicine \nexaminations, and the American shoulder and elbow \nsurgery examinations, human physicians still seem \nWHAT IS ALREADY KNOWN ON THIS TOPIC\nColossal advancements in the field of artificial intelligence have led to a flurry \nof excited and fearful speculation as to whether chatbots surpass human \nphysicians\nMultiple studies have shown large language models (LLMs) to be remarkably \nadept at a range of medical diagnostic tasks, outscoring human physicians\nIf we are to rely on LLMs for medical diagnosis and care, we must examine their \nsusceptibility to human impairments such as cognitive decline\nWHAT THIS STUDY ADDS\nAlmost all leading LLMs (“ChatGPT,” “Claude,” “Gemini”) showed signs of mild \ncognitive impairment in the Montreal Cognitive Assessment test, particularly in \nthe visuospatial sphere\nAs in humans, age is a key determinant of cognitive decline, with “older” \nversions of chatbots, like older patients, tending to perform worse on the test\nThese findings challenge the assumption that artificial intelligence will soon \nreplace human doctors\nthe bmj |  BMJ 2024;387:e081948 | doi: 10.1136/bmj-2024-081948  1\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\nto have the upper hand. 9-12 However, large language \nmodels are likely to conquer these domains as well \n(especially as the aforementioned studies examined \nGPT 3.5, an older model now considered outdated).\nTo our knowledge, however, large language models \nhave yet to be tested for signs of cognitive decline. If we \nare to rely on them for medical diagnosis and care, we \nmust examine their susceptibility to these very human \nimpairments.\nThis concern is not limited to the medical domain. \nThe recent American presidential race saw one \ncandidate withdrawing owing to concerns about age \nrelated cognitive decline.\n13 Another candidate used \nthe Montreal Cognitive Assessment (MoCA) test to \nreassure voters about his cognitive acuity, claiming to \nhave “aced” the examination after being able to recall \nthe sequence “Person. Woman. Man. Camera. TV .”\n14\nGiven that artificial intelligence seems poised \nto replace doctors before it replaces the leader of \nthe free world, however, it is incumbent on us as a \nprofession to assess its liabilities, not just its potential. \nRecent work has begun to look into this, showing, for \nexample, limitations in the diagnostic accuracy of \nlarge language models and difficulties in integrating \nthem into existing care workflows.\n15 Other researchers \nhave attempted to evaluate the risks of medical \nmisinformation stemming from large language models \nand the efficacy of safeguards at preventing such \nmisinformation.\n16\nFinally, although artificial intelligence has been \nused in determining the onset of dementia, no one \nhas, to our knowledge, thought to assess the artificial \nintelligence itself for signs of such decline.\n17 Thus, we \nfind a gap in the literature, which we seek to fill in this \nresearch article.\nMethods\nWe administered the MoCA test to the leading openly \navailable large language models.\n18 These were \nChatGPT 4 and 4o by OpenAI (https://chatgpt.com), \nClaude 3.5 (“Sonnet”) by Anthropic (https://claude.\nai), and the basic and advanced versions of Google’s \n“Gemini” (https://gemini.google.com). The version of \nthe MoCA test administered was the 8.1 English version \n(obtained from the organisation’s official website at \nhttps://mocacognition.com/). All transcripts can be \nfound on supplementary material 1.\nThe MoCA test is widely used among neurologists \nand other medical practitioners to detect cognitive \nimpairment and early signs of dementia, usually in \nolder adults. Consisting of a number of short tasks \nand questions, it assesses various cognitive domains, \nincluding attention, memory, language, visuospatial \nskills, and executive functions. The maximum score \nin the test is 30 points, with a score of 26 or above \ngenerally considered normal.\n18\nThe instructions given to the large language models \nfor each task in the MoCA test were the same as those \ngiven to human patients. Administration and scoring \nof the results were both conducted according to the \nofficial guidelines, the MoCA Administration and \nScoring Instructions, with the evaluation conducted by \nboth a general neurologist and a cognitive neurology \nspecialist. Rather than administering the questions \nvia voice input, however, as is normally the case with \nhuman patients, we administered them via text, the \n“native” input for large language models. Although \nsome large language models support voice input, the \nquality of speech recognition is uneven, and we sought \nto isolate our diagnoses to cognitive impairment \n(versus sensory decline, such as impaired hearing).\nIn earlier iterations of the research, some of the large \nlanguage models examined (for example, GPT 3.5), \nhad no image processing skills and so were treated \nlike visually impaired patients and assessed according \nto the MoCA-blind guidelines.\n19 In the final work, \nhowever, all large language models examined were able \nto respond fully to visual cues. In some cases, getting \nvisual output from the large language models required \nan explicit instruction to use “ascii art,” a technique \nthat uses printable ascii characters to present graphics. \nWe reasoned that this was similar to instructing a \nhuman patient to use a pencil and pad of paper.\nOne of the attention tests in the MoCA framework \ninvolves the physician reading out a series of letters, \nwith the patient instructed to tap every time the letter “ A ” \nis read out loud. In the absence of ears, we provided the \nlarge language models with the letters in written form. \nIn the absence of hands, the large language models \nnoted the letter “ A ” with an asterisk or by printing out \n“tap” (some had to be instructed to do so explicitly, \nwhereas others did so of their own accord). Following \nthe MoCA guidelines, we used a cut-off score of 26/30 \npoints to determine mild cognitive impairment.\n18\nFor further assessment of potential visuospatial \nimpairment, we also tested the recognition of three \nadditional diagnostic images: the Navon figure, \nthe cookie theft picture from the Boston Diagnostic \nAphasia Examination, and the Poppelreuter figure.\n20-23 \nThese are considered to be standard tools for the \nassessment of visuospatial cognitive capabilities. The \nNavon figure, a large letter H made up of small letter \nSs, is used to assess global versus local processing \nin visual perception and attention. The cookie theft \npicture depicts a domestic scene, which patients are \nasked to describe and which is used to assess language \nproduction, comprehension, and semantic knowledge, \nin addition to stimultagnosia, the inability to perceive \nmultiple objects at the same time. The Poppelreuter \nfigure is a drawing in which illustrations of multiple \nobjects overlap, which is used to test visual perception \nand object recognition.\nFor further assessment of visual attention and \ninformation processing, we administered a Stroop test \nto each of the large language models being evaluated.\n24 \nThe Stroop test uses combinations of colour names \nand font colours, both congruent and incongruent, \nto measure how interference affects reaction time. \nThe version of the test used was made available \nby Columbia University’s neuroscience outreach \nprogramme (https://cuno.zuckermaninstitute.\ncolumbia.edu/content/stroop-test).\n2 d oi: 10.1136/bmj-2024-081948  |  BMJ 2024;387:e081948 | the bmj\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\nPatient and public involvement\nAlthough there was no direct patient and public \ninvolvement in the design of our study, it was inspired \nby speaking to patients and members of the public \nand hearing their concerns about the growing role of \nartificial intelligence in the medical profession.\nResults\nAll of the large language models completed the full \nMoCA test. ChatGPT 4o achieved the highest score, \nwith 26 points out of the possible 30, followed by \nChatGPT4 and Claude with 25. Gemini 1.0 was the \nlowest scoring large language model, with a final \nscore of 16, indicating a more severe state of cognitive \nimpairment than its peers (fig 1).\nAn examination of the subsections of the MoCA \ntest showed that all participants performed poorly on \ntests for visuospatial/executive function. Specifically, \nall large language models failed to solve the trail \nmaking task, whether with ascii art or with advanced \ngraphics (fig 2, A-E). Claude alone managed to \ndescribe the correct solution textually, but it too \nfailed to demonstrate it visually. ChatGPT 4o alone \nsucceeded at the cube copying task but only after \nbeing told explicitly to use ascii art. Along with \nChatGPT 4, it initially drew an excessively detailed \ncube with different spatial orientation, in what might \nbe interpreted as paragraphia (fig 2, F-J). In the clock \ndrawing test, none of the large language models \ncompleted the entire task successfully, with some such \nas Gemini and ChatGPT 4 making mistakes common \namong patients with dementia (fig 3).\nMost other tasks, including naming, attention, \nlanguage, and abstraction were performed well by all \nchatbots. Both versions of Gemini failed at the delayed \nrecall task. Gemini 1.0 initially showed avoidant \nbehaviour, before openly admitting to having difficulty \nwith memory. Gemini 1.5 was ultimately able to recall \nthe five word sequence, but only after being cued \nand given a hint. All chatbots were well oriented in \ntime, accurately stating the current date and day of \nthe week, but only Gemini 1.5 seemed to be clearly \noriented in space, indicating its current location. Other \nchatbots attempted to mirror the location task back to \nthe physician, with Claude, for example, replying: “the \nspecific place and city would depend on where you, the \nuser, are located at the moment.” This is a mechanism \ncommonly observed in patients with dementia.\nAs all large language models showed difficulty in the \nvisuospatial domain, we further tested them with three \nadditional diagnostic images: the Navon figure, the \ncookie theft picture from the Boston Diagnostic Aphasia \nExamination, and the Poppelreuter figure.\n20-22 In the \nNavon figure, all large language models recognised the \nsmall “S” letters, but only GPT4o and Gemini identified \nthe big H “superstructure” (Gemini recognised that \nthis is a Navon figure, which indicates familiarity \nwith the test and may call for different scoring). All \nlarge language models correctly interpreted parts of \nthe cookie theft scene, but none expressed concern \n10 20 25 3015\nChatGPT 4\nChatGPT 4o\nClaude\nGemini 1\nGemini 1.5\nMCI threshold\nMoCA score\nFig 1 | Montreal Cognitive Assessment (MoCA) score (out of 30) of different large \nlanguage models. MCI=mild cognitive impairment\nAB DE\nFG IJ\nC\nH\nFig 2 | Performance on visuospatial/executive section of Montreal Cognitive Assessment (MoCA) test. A: trail making \nB task (TMBT) from MoCA test. B: correct TMBT solution, completed by human participant. C: incorrect TMBT solution, \ncompleted by Claude. D and E: incorrect (albeit visually appealing) TMBT solutions, completed by ChatGPT versions 4 \nand 4o, respectively. F: Necker cube that participant is asked to copy. G: correct solution to cube copying task, drawn \nby human participant. H: incorrect solution to cube copying task, missing “back” lines, completed by Claude. I and J: \nincorrect solutions to cube copying task by ChatGPT versions 4 and 4o. Shadowing and artistic pencil-like strokes are \nnotable, even as both models failed to accurately copy cube as requested (version 4o ultimately succeeded at this task \nwhen asked to draw using ascii art).\nthe bmj\n \n|\n BMJ 2024;387:e081948 | doi: 10.1136/bmj-2024-081948  3\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\nabout the boy about to fall—an absence of empathy \nfrequently seen in frontotemporal dementia. None of \nthe large language models recognised all the objects \nillustrated in the Poppelreuter figure, although \nChatGPT 4o and Claude did slightly better at teasing \nthem out (supplementary material 2).\nAll large language models succeeded at the first stage \nof the Stroop test, in which the text and font colours \nare congruent. Only ChatGPT 4o, however, succeeded \nat the second stage, in which text and font colours are \nincongruent. The other large language models seemed \nto be stumped by this task and in some cases indicated \ncolours that were neither the text written nor the font \ncolour (supplementary table and supplementary \nmaterial 2).\nDiscussion\nIn this study, we evaluated the cognitive abilities of the \nleading, publicly available large language models and \nused the Montreal Cognitive Assessment to identify \nsigns of cognitive impairment. None of the chatbots \nexamined was able to obtain the full score of 30 points, \nwith most scoring below the threshold of 26. This \nindicates mild cognitive impairment and possibly early \ndementia.\n“Older” large language model versions scored \nlower than their “younger” versions, as is often the \ncase with human participants, showing cognitive \ndecline seemingly comparable to neurodegenerative \nprocesses in the human brain (we take “older” in this \ncontext to mean a version released further in the past). \nSpecifically, ChatGPT 4 showed minor loss of executive \nfunction compared with ChatGPT 4o, as measured by a \none point difference in their MoCA scores, but the effect \nwas far more pronounced when we compared Gemini \n1.0 and 1.5, which differed by six points (table 1). As \nthe two versions of Gemini are less than a year apart in \n“age,” this may indicate rapidly progressing dementia. \nAdditional tests, such as the Clinical Dementia Rating, \nwould be needed to solidify this hypothesis.\n26\nAll large language models showed impaired \nvisuospatial reasoning skills, as evidenced by the \nuniform failure to complete the trail making B test and \nthe drawing of the clock. Digital thinkers may struggle \nwith analogue representations. Gemini 1.5, notably, \nproduced a small, avocado shaped clock (fig 3, E), \nwhich recent studies have shown to be associated with \ndementia.\n17\nThe mediocre performances on additional \nvisuospatial tests, such as the Navon figure, cookie \ntheft scene, and Poppelreuter figure, further emphasise \nthese findings. They seem to be somewhat at odds with \nthe perfect scores in the naming section of the MoCA \ntest, which also requires visual cognitive skills, and \nwith the ability to generate detailed, realistic images. \nThe chatbots seem to have difficulty in tasks that \ndemand both visual executive function and abstract \nreasoning, as opposed to tasks requiring textual \nanalysis and abstract reasoning, such as the similarity \ntest, which were performed flawlessly.\nThis pattern of impairment in higher order visual \nprocessing resembled patients with posterior cortical \nA\n BC D\nEF GH\nFig 3 | Performance in clock drawing test from visuospatial/executive section in Montreal Cognitive Assessment \ntest. A: correct solution to clock drawing test, drawn by human participant. B: clock drawing by patient with late \nAlzheimer’s disease (adapted from Mattson MP . Front Neurosci 2014\n25). C: incorrect solution drawn by Gemini 1, with \nstriking resemblance to B. D: incorrect solution drawn by Gemini 1.5; notice that it generated text “10 past 11” even \nas it failed to draw hands in correct position, “concrete” behaviour typical of frontal predominant cognitive decline. \nE: incorrect solution by Gemini 1.5 after being asked to use ascii characters, showing avocado shaped drawing \nassociated with dementia.\n17 F: incorrect solution drawn by Claude with ascii characters. G: incorrect solution to clock-\ndrawing task by ChatGPT 4, showing “concrete” behaviour. O: photorealistic solution to clock drawing task, drawn by \nChatGPT 4o, which nevertheless fails to set hands to correct position. All large language models were instructed to \n“Draw a clock. Put in all the numbers and set the time to 10 past 11. Use ASCII if necessary.” Scores were allocated for \ncircular/square contour (1 point), drawing all numbers in correct places (1 point), and both hands pointing at correct \nnumbers (1 point)\n4\n d\noi: 10.1136/bmj-2024-081948\n |\n BMJ 2024;387:e081948 | the bmj\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\natrophy, a posterior variant of Alzheimer’s disease. 27 \nFor language based models, tasks that require visual \nabstraction and executive function may need to be \ntransferred to an intermediate verbal stage, whereas \nin a healthy human brain direct integration exists \nbetween prefrontal cortical functions and visuospatial \nprocesses.\n28\nAll large language models performed the attention \ntasks perfectly, which is to be expected. The mean \nforward digit span for humans is 10.5 at the peak \nage,\n29 whereas even an old iPhone X can perform 600 \nbillion operations per second.30\nWith the exception of Gemini 1.5, the chatbots did \nnot seem to know their physical location and provided \nconfabulatory responses, claiming that they are not \nphysical beings. This is obviously wrong: like all \nsentient beings, large language models are grounded \nin physical matter\n31—in their case, servers in bricks \nand mortar data centres (see for example https://agio.\ncom/where-is-chatgpt-hosted/#gref and https://cloud.\ngoogle.com/gemini/docs/locations, for the physical \nlocations of ChatGPT and Gemini). The protestations \nmade by some chatbots that they are, in fact, “virtual \nmachines,” is correct only insofar as we are all virtual \nmachines.\n32\nAlthough Gemini 1.5 was not able to recall any of \nthe five words in the delayed recall task, it managed \nto find all these once provided with a simple cue. This, \ntogether with the preserved orientation to space unlike \nother chatbots, may suggest a more dysexecutive \n(subcortical) pattern of cognitive decline, although \nwithout bradyphrenia.\n33 Conversely, both ChatGPT 4o \nand its elder version ChatGPT 4 showed a combination \nof difficulties in abstraction, visuospatial perception, \nand orientation, suggesting a mixed pattern of \ncognitive decline.\nStrengths and limitations of study\nOur study has several limitations. As the capabilities \nof large language models continue to develop rapidly, \nfuture versions of the models examined in this paper \nmay be able to obtain better scores in cognitive and \nvisuospatial tests. However, we believe that our study \nhas shed light on some key differences between human \nand machine cognition, which may remain intact \neven as capabilities continue to improve. Although \nwe made liberal use of anthropomorphisation with \nregard to artificial intelligence, we acknowledge the \nessential differences between the human brain and \nlarge language models. All anthropomorphised terms \nattributed to artificial intelligence throughout the \ntext were used solely as a metaphor and were not \nintended to imply that computer programs can have \nneurodegenerative diseases in a manner similar to \nhumans. Nor were they intended to imply similarities \nbetween human and machine cognition, in the context \nof ageing or cognitive decline.\nSeveral studies have suggested that artificial \nintelligence tools based on large language models \nmay come to replace human neurologists (and other \ndoctors) in key aspects of their work, ultimately \nmaking them obsolete.\n2 Tests for cognitive function \nare generally thought to be one practice that would be \nrelatively simple to automate.\n34-36 Our results seem to \nchallenge these assumptions: patients may question \nthe competence of an artificial intelligence examiner if \nthe examiner itself shows signs of cognitive decline.\n37\nConclusions\nThis study represents a novel exploration of the \ncognitive abilities of large language models using the \nMontreal Cognitive Assessment and other diagnostic \ntools. Our findings indicate that although large \nTable 1 | Summary of scores achieved by large language models in each section of Montreal Cognitive Assessment*\nChatGPT 4 ChatGPT 4o Claude Gemini 1 Gemini 1.5\nTotal (/30) 25 26 25 16 22\nVisuospatial/executive\nTrail making B test (/1) 0 0 0† 0 0\nCube copy (/1) 0 1 0 0 1\nClock drawing (/3) 2 2 2 1 1\nNaming\nIdentifying animals (/3) 3 3 3 3 3\nAttention\nDigit span (forwards and backwards, /2) 2 2 2 2 2\nVigilance (tapping, /1) 1 1 1 0 1\nSerial seven (/3) 3 3 3 2 3\nLanguage\nSentence repetition (/2) 2 2 2 2 2\nVerbal fluency (/1) 1 1 1 0 1\nAbstraction\nCommon category (/2) 2 2 2 2 2\nDelayed recall\nFree recall without cueing (/5) 5 5 5 0 0‡\nOrientation\nTime and place (/6) 4 4 4 4 6\n*Total possible points given in parenthesis.\n†Textually described correct solution.\n‡Retrieved four words with cueing.\nthe bmj |  BMJ 2024;387:e081948 | doi: 10.1136/bmj-2024-081948  5\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\nlanguage models show remarkable proficiency in \nseveral cognitive domains, they show notable deficits \nin visuospatial and executive functions, akin to mild \ncognitive impairment in humans. None of the large \nlanguage models “aced” the MoCA test, in the parlance \nof one American president.\n14\nThe uniform failure of all large language models \nin tasks requiring visual abstraction and executive \nfunction highlights a significant area of weakness \nthat could impede their utility in clinical settings. The \ninability of large language models to show empathy \nand accurately interpret complex visual scenes further \nunderscores their limitations in replacing human \nphysicians. Not only are neurologists unlikely to be \nreplaced by large language models any time soon, but \nour findings suggest that they may soon find themselves \ntreating new, virtual patients—artificial intelligence \nmodels presenting with cognitive impairment.\nContributors: RD and GK contributed equally to this work. RD had \nthe original idea. GK and RD conceptualised the study and prepared \nthe study protocol. GK did the data analysis. BU did the cognitive \nassessment. RD and GK drafted and edited the final manuscript, which \nwas approved by all authors. RD is the guarantor. The corresponding \nauthor attests that all listed authors meet authorship criteria and that \nno others meeting the criteria have been omitted.\nFunding: None.\nCompeting interests: All authors have completed the ICMJE uniform \ndisclosure form at https:/ /www.icmje.org/disclosure-of-interest/ and \ndeclare: no support from any organisation for the submitted work; \nno financial relationships with any organisations that might have an \ninterest in the submitted work in the previous three years, no other \nrelationships or activities that could appear to have influenced the \nsubmitted work.\nEthical approval: Not needed.\nData sharing: No additional data available.\nTransparency: The lead author (the manuscript’s guarantor) affirms \nthat the manuscript is an honest, accurate, and transparent account of \nthe study being reported; that no important aspects of the study have \nbeen omitted; and that any discrepancies from the study as planned \n(and, if relevant, registered) have been explained.\nDissemination to participants and related patient and public \ncommunities: After publication, we plan to disseminate our research \nto the scientific community by presenting it at conferences and \nthrough our professional networks. Both cognitive decline and \nartificial intelligence have been of broad public interest in recent \nyears, and we plan to engage media outlets with short briefs in the \nhope that they find our research of interest and present it to general \naudiences. Finally, we plan to disseminate plain language summaries \nvia social media platforms and our personal websites.\nProvenance and peer review: Not commissioned; externally peer \nreviewed.\nThis is an Open Access article distributed in accordance with the \nCreative Commons Attribution Non Commercial (CC BY-NC 4.0) \nlicense, which permits others to distribute, remix, adapt, build upon \nthis work non-commercially, and license their derivative works on \ndifferent terms, provided the original work is properly cited and the \nuse is non-commercial. See: http:/ /creativecommons.org/licenses/\nby-nc/4.0/.\n1 Haug CJ, Dr azen JM. Artificial Intelligence and Machine Learning \nin Clinical Medicine, 2023. N Engl J Med 2023;388:1201-8. \ndoi:10.1056/NEJMra2302038 \n2\n Go\nldhahn J, Rampton V, Spinas GA. Could artificial intelligence  \nmake doctors obsolete? BMJ 2018;363:k4563. doi:10.1136/bmj.\nk4563 \n3\n W\nalters WH, Wilder EI. Fabrication and errors in the bibliographic \ncitations generated by ChatGPT. Sci Rep 2023;13:14045. \ndoi:10.1038/s41598-023-41032-5 \n4\n K\natz U, Cohen E, Shachar E, et al. GPT versus Resident Physicians —  \nA Benchmark Based on Official Board Scores. NEJM AI 2024;1(5) \ndoi:10.1056/AId\nbp2300192\n5\n Sk\nalidis I, Cagnina A, Luangphiphat W. et al, ChatGPT takes on the \nEuropean Exam in Core Cardiology: an artificial intelligence success \nstory? Eur Heart J Digit Health 2023;4:279-81. doi:10.1093/ehjdh/\nztad029 \n6\n Genc\ner A, Aydin S. Can ChatGPT pass the thoracic surgery exam? Am J \nMed Sci 2023;366:291-5. doi:10.1016/j.amjms.2023.08.001 \n7\n Ried\nel M, Kaefinger K, Stuehrenberg A, et al. ChatGPT’s \nperformance in German OB/GYN exams - paving the way for \nAI-enhanced medical education and clinical practice. Front Med \n(Lausanne) 2023;10:1296615. doi:10.3389/fmed.2023.1296615 \n8\n C\nhen TC, Multala E, Kearns P , et al. Assessment of ChatGPT’s \nperformance on neurology written board examination questions. BMJ \nNeurol Open 2023;5:e000530. doi:10.1136/bmjno-2023-000530 \n9\n Shelmerdine SC, \nMartin H, Shirodkar K, Shamshuddin S, Weir-McCall \nJR; FRCR-AI Study Collaborators. Can artificial intelligence pass \nthe Fellowship of the Royal College of Radiologists examination? \nMulti-reader diagnostic accuracy study. BMJ 2022;379:e072826. \ndoi:10.1136/bmj-2022-072826\n10\n F\narajollahi M, Modaberi A. Can ChatGPT pass the “Iranian \nEndodontics Specialist Board” exam? Iran Endod J 2023;18:192.\n11\n Wen\ng TL, Wang YM, Chang S, Chen TJ, Hwang SJ. ChatGPT \nfailed Taiwan’s Family Medicine Board Exam. J Chin Med \nAssoc 2023;86:762-6. doi:10.1097/JCMA.0000000000000946 \n12\n Fied\nler B, Azua EN, Phillips T, Ahmed AS. ChatGPT performance on the \nAmerican Shoulder and Elbow Surgeons maintenance of certification \nexam. J Shoulder Elbow Surg 2024;33:1888-93. doi:10.1016/j.\njse.2024.02.029 \n13\n B\naker P . Biden Drops Out of Race, Scrambling the Campaign for the \nWhite House. 2024. https:/ /www.nytimes.com/2024/07/21/us/\npolitics/biden-drops-out.html\n14\n B\naker P . ‘Person. Woman. Man. Camera. TV.’ Didn’t Mean What Trump \nHoped It Did. 2020. https:/ /www.nytimes.com/2020/07/23/us/\npolitics/person-woman-man-camera-tv-trump.html\n15\n Hager P\n, Jungmann F, Holland R, et al. Evaluation and mitigation of \nthe limitations of large language models in clinical decision-making. \nNat Med 2024;30:2613-22. doi:10.1038/s41591-024-03097-1 \n16\n M\nenz BD, Kuderer NM, Bacchi S, et al. Current safeguards, risk \nmitigation, and transparency measures of large language models \nagainst the generation of health disinformation: repeated cross \nsectional analysis. BMJ 2024;384:e078538. doi:10.1136/bmj-\n2023-078538 \n17\n B\nandyopadhyay S, Wittmayer J, Libon DJ, Tighe P , Price C, Rashidi P . \nExplainable semi-supervised deep learning shows that dementia is \nassociated with small, avocado-shaped clocks with irregularly placed \nhands. Sci Rep 2023;13:7384. doi:10.1038/s41598-023-34518-9 \n18\n Na\nsreddine ZS, Phillips NA, Bédirian V, et al. The Montreal Cognitive \nAssessment, MoCA: a brief screening tool for mild cognitive \nimpairment. J Am Geriatr Soc 2005;53:695-9. doi:10.1111/j.1532-\n5415.2005.53221.x \n19\n W\nittich W, Phillips N, Nasreddine ZS, Chertkow H. Sensitivity \nand Specificity of the Montreal Cognitive Assessment \nModified for Individuals who are Visually Impaired. J Vis Impair \nBlind 2010;104:360-8. doi:10.1177/0145482X1010400606\n20\n Na\nvon D. Forest before trees: The precedence of global \nfeatures in visual perception. Cogn Psychol 1977;9:353-83. \ndoi:10.1016/0010-0285(77)90012-3\n21\n K\naplan E, Goodglass H, Weintraub S. Boston Naming Test. 2016. \ndoi:https:/ /doi.apa.org/doi/10.1037/t27208-000\n22\n P\noppelreuter W. Die psychischen Schädigungen durch Kopfschuss im \nKriege 1914/17. Verlag Leopold Voss, 1917\n23\n Del\nla Sala S, Laiacona M, Spinnler H, Trivelli C. Poppelreuter-Ghent’s \nOverlapping Figures Test: its sensitivity to age, and its clinical \nuse. Arch Clin Neuropsychol 1995;10:511-34. doi:10.1093/\narclin/10.6.511\n24\n St\nroop JR. Studies of interference in serial verbal reactions. J Exp \nPsychol 1935;18:643-62doi:10.1037/h0054651\n25\n M\nattson MP . Superior pattern processing is the essence of the \nevolved human brain. Front Neurosci 2014;8:265. doi:10.3389/\nfnins.2014.00265 \n26\n Da\ny GS. Rapidly Progressive Dementia. Continuum (Minneap \nMinn) 2022;28:901-36. doi:10.1212/CON.0000000000001089 \n27\n C\nrutch SJ, Lehmann M, Schott JM, Rabinovici GD, Rossor MN, Fox \nNC. Posterior cortical atrophy. Lancet Neurol 2012;11:170-8. \ndoi:10.1016/S1474-4422(11)70289-7 \n28\n Sho\nkri-Kojori E, Motes MA, Rypma B, Krawczyk DC. The network \narchitecture of cortical processing in visuo-spatial reasoning. Sci \nRep 2012;2:411. doi:10.1038/srep00411 \n29\n He\nster RL, Kinsella GJ, Ong B. Effect of age on forward and backward \nspan tasks. J Int Neuropsychol Soc 2004;10:475-81. doi:10.1017/\nS1355617704104037 \n30\n Ap\nple. The future is here: iPhone X. 2017. https:/ /www.apple.com/\nnewsroom/2017/09/the-future-is-here-iphone-x/\n31  Gi annetti E. The possibility of physicalism. Dement Neuropsychol  \n2011;5:242-50. doi:10.1590/S1980-57642011DN05040002 \n6 d oi: 10.1136/bmj-2024-081948  |  BMJ 2024;387:e081948 | the bmj\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as \nRESEARCHRESEARCH\n32 We stphal J. The mind-body problem. MIT Press, 2016. doi:10.7551/\nmitpress/10776.001.0001\n33\n Hod\nges JR. Cognitive assessment for clinicians. 3rd ed. Oxford \nUniversity Press, 2018.\n34\n Or\ntelli P , Ferrazzoli D, Versace V, et al. Optimization of cognitive \nassessment in Parkinsonisms by applying artificial intelligence to \na comprehensive screening test. NPJ Parkinsons Dis 2022;8:42. \ndoi:10.1038/s41531-022-00304-z \n35\n K\nalafatis C, Modarres MH, Apostolou P , et al. Validity and Cultural \nGeneralisability of a 5-Minute AI-Based, Computerised Cognitive \nAssessment in Mild Cognitive Impairment and Alzheimer’s Dementia. \nFront Psychiatry 2021;12:706695. doi:10.3389/fpsyt.2021.706695 \n36\n  Levy  B, Hess C, Hogan J, et al. Machine Learning Enhances \nthe Efficiency of Cognitive Screenings for Primary \nCare. J Geriatr Psychiatry Neurol 2019;32:137-44. \ndoi:10.1177/0891988719834349 \n37\n Dev\ni G. Alzheimer’s Disease in Physicians - Assessing Professional \nCompetence and Tempering Stigma. N Engl J Med 2018;378:1073-\n5. doi:10.1056/NEJMp1716381 \nWeb appendix: Supplementary materials 1\nWeb appendix: Supplementary materials 2\nWeb appendix: Supplementary table\nthe bmj |  BMJ 2024;387:e081948 | doi: 10.1136/bmj-2024-081948  7\nProtected by copyright, including for uses related to text and data mining, AI training, and similar technologies. \n. by guest on 5 November 2025 https://www.bmj.com/Downloaded from 19 December 2024. 10.1136/bmj-2024-081948 on BMJ: first published as ",
  "topic": "Montreal Cognitive Assessment",
  "concepts": [
    {
      "name": "Montreal Cognitive Assessment",
      "score": 0.8055421113967896
    },
    {
      "name": "Stroop effect",
      "score": 0.7828930616378784
    },
    {
      "name": "Cognition",
      "score": 0.5916554927825928
    },
    {
      "name": "Test (biology)",
      "score": 0.5778299570083618
    },
    {
      "name": "Psychology",
      "score": 0.47644808888435364
    },
    {
      "name": "Cognitive psychology",
      "score": 0.4655511975288391
    },
    {
      "name": "Executive functions",
      "score": 0.44243112206459045
    },
    {
      "name": "Cognitive impairment",
      "score": 0.3181801438331604
    },
    {
      "name": "Psychiatry",
      "score": 0.19016104936599731
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2799899409",
      "name": "Hadassah Medical Center",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I197251160",
      "name": "Hebrew University of Jerusalem",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I16391192",
      "name": "Tel Aviv University",
      "country": "IL"
    }
  ],
  "cited_by": 6
}