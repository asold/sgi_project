{
  "title": "VT-MCNet: High-Accuracy Automatic Modulation Classification Model Based on Vision Transformer",
  "url": "https://openalex.org/W4389065273",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A4209672104",
      "name": "Thien-Thanh Dao",
      "affiliations": [
        "Pusan National University"
      ]
    },
    {
      "id": "https://openalex.org/A4314394856",
      "name": "Dae-Il Noh",
      "affiliations": [
        "Pusan National University"
      ]
    },
    {
      "id": "https://openalex.org/A2921636182",
      "name": "Quoc Viet Pham",
      "affiliations": [
        "Trinity College Dublin"
      ]
    },
    {
      "id": "https://openalex.org/A2169562741",
      "name": "Mikio HASEGAWA",
      "affiliations": [
        "Tokyo University of Science"
      ]
    },
    {
      "id": "https://openalex.org/A1985090606",
      "name": "Hiroo SEKIYA",
      "affiliations": [
        "Chiba University"
      ]
    },
    {
      "id": "https://openalex.org/A2104266938",
      "name": "Won-Joo Hwang",
      "affiliations": [
        "Pusan National University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2773170971",
    "https://openalex.org/W2741230443",
    "https://openalex.org/W4292737595",
    "https://openalex.org/W3101503122",
    "https://openalex.org/W3000943722",
    "https://openalex.org/W4220783431",
    "https://openalex.org/W4360930839",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4312262250",
    "https://openalex.org/W4293195393",
    "https://openalex.org/W2005227457",
    "https://openalex.org/W3113059984",
    "https://openalex.org/W3032977069"
  ],
  "abstract": "Cognitive radio networks’ evolution hinges significantly on the use of automatic modulation classification (AMC). However, existing research reveals limitations in attaining high AMC accuracy due to ineffective feature extraction from signals. To counter this, we propose a vision-centric approach employing diverse kernel sizes to augment signal extraction. In addition, we refine the transformer architecture by incorporating a dual-branch multi-layer perceptron network, enabling diverse pattern learning and enhancing the model’s running speed. Specifically, our architecture allows the system to focus on relevant portions of the input sequence, thus, it improves classification accuracy for both high and low signal-to-noise regimes. By utilizing the widely recognized DeepSig dataset, our pioneering deep model, termed as VT-MCNet, outshines prior leading-edge deep networks in terms of classification accuracy and computational costs. Notably, VT-MCNet reaches an exceptional cumulative classification rate of up to 99.24%, while the state-of-the-art method, even with higher computational complexity, can only achieve 99.06%.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7948394417762756
    },
    {
      "name": "Feature extraction",
      "score": 0.6707308292388916
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6249008774757385
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.5217369794845581
    },
    {
      "name": "Deep learning",
      "score": 0.4995083808898926
    },
    {
      "name": "Artificial neural network",
      "score": 0.48736244440078735
    },
    {
      "name": "Perceptron",
      "score": 0.4847257137298584
    },
    {
      "name": "Computational complexity theory",
      "score": 0.46978798508644104
    },
    {
      "name": "Transformer",
      "score": 0.43193280696868896
    },
    {
      "name": "Machine learning",
      "score": 0.3631094694137573
    },
    {
      "name": "Algorithm",
      "score": 0.1314760148525238
    },
    {
      "name": "Engineering",
      "score": 0.08961442112922668
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}