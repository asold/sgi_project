{
    "title": "Surgical Gesture Recognition in Laparoscopic Tasks Based on the Transformer Network and Self-Supervised Learning",
    "url": "https://openalex.org/W4311014067",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A3097104827",
            "name": "Athanasios Gazis",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        },
        {
            "id": "https://openalex.org/A4202013647",
            "name": "Pantelis Karaiskos",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        },
        {
            "id": "https://openalex.org/A1965561473",
            "name": "Constantinos Loukas",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        },
        {
            "id": "https://openalex.org/A3097104827",
            "name": "Athanasios Gazis",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        },
        {
            "id": "https://openalex.org/A4202013647",
            "name": "Pantelis Karaiskos",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        },
        {
            "id": "https://openalex.org/A1965561473",
            "name": "Constantinos Loukas",
            "affiliations": [
                "National and Kapodistrian University of Athens"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3110385255",
        "https://openalex.org/W3100964249",
        "https://openalex.org/W3121789984",
        "https://openalex.org/W593558681",
        "https://openalex.org/W2029294400",
        "https://openalex.org/W2568518337",
        "https://openalex.org/W2413983136",
        "https://openalex.org/W2491875666",
        "https://openalex.org/W2550143307",
        "https://openalex.org/W2962836302",
        "https://openalex.org/W2980110287",
        "https://openalex.org/W3090581617",
        "https://openalex.org/W3196875695",
        "https://openalex.org/W2415633882",
        "https://openalex.org/W3176125528",
        "https://openalex.org/W3211048356",
        "https://openalex.org/W3096298754",
        "https://openalex.org/W4285175079",
        "https://openalex.org/W2161299247",
        "https://openalex.org/W3013053228",
        "https://openalex.org/W2963524571",
        "https://openalex.org/W3023371261",
        "https://openalex.org/W6739901393",
        "https://openalex.org/W3094480255",
        "https://openalex.org/W3203204495",
        "https://openalex.org/W2565597243",
        "https://openalex.org/W2943800384",
        "https://openalex.org/W6781351468",
        "https://openalex.org/W3091935435",
        "https://openalex.org/W4366496950",
        "https://openalex.org/W4385245566"
    ],
    "abstract": "In this study, we propose a deep learning framework and a self-supervision scheme for video-based surgical gesture recognition. The proposed framework is modular. First, a 3D convolutional network extracts feature vectors from video clips for encoding spatial and short-term temporal features. Second, the feature vectors are fed into a transformer network for capturing long-term temporal dependencies. Two main models are proposed, based on the backbone framework: C3DTrans (supervised) and SSC3DTrans (self-supervised). The dataset consisted of 80 videos from two basic laparoscopic tasks: peg transfer (PT) and knot tying (KT). To examine the potential of self-supervision, the models were trained on 60% and 100% of the annotated dataset. In addition, the best-performing model was evaluated on the JIGSAWS robotic surgery dataset. The best model (C3DTrans) achieves an accuracy of 88.0%, a 95.2% clip level, and 97.5% and 97.9% (gesture level), for PT and KT, respectively. The SSC3DTrans performed similar to C3DTrans when training on 60% of the annotated dataset (about 84% and 93% clip-level accuracies for PT and KT, respectively). The performance of C3DTrans on JIGSAWS was close to 76% accuracy, which was similar to or higher than prior techniques based on a single video stream, no additional video training, and online processing.",
    "full_text": null
}