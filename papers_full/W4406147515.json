{
  "title": "Can Large Language Models Aid Caregivers of Pediatric Cancer Patients in Information Seeking? A Cross‐Sectional Investigation",
  "url": "https://openalex.org/W4406147515",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A1971732328",
      "name": "Emre Sezgin",
      "affiliations": [
        "Nationwide Children's Hospital",
        "The Ohio State University"
      ]
    },
    {
      "id": "https://openalex.org/A5114241084",
      "name": "Daniel I. Jackson",
      "affiliations": [
        "Nationwide Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1249972642",
      "name": "A. Baki Kocaballi",
      "affiliations": [
        "Macquarie University"
      ]
    },
    {
      "id": "https://openalex.org/A2920982216",
      "name": "Mindy Bibart",
      "affiliations": [
        "Nationwide Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A1495588249",
      "name": "Sue Zupanec",
      "affiliations": [
        "Hospital for Sick Children"
      ]
    },
    {
      "id": "https://openalex.org/A1496442504",
      "name": "Wendy Landier",
      "affiliations": [
        "University of Alabama at Birmingham"
      ]
    },
    {
      "id": "https://openalex.org/A4362146900",
      "name": "Anthony Audino",
      "affiliations": [
        "Nationwide Children's Hospital",
        "The Ohio State University"
      ]
    },
    {
      "id": "https://openalex.org/A2737994826",
      "name": "Mark Ranalli",
      "affiliations": [
        "Nationwide Children's Hospital",
        "The Ohio State University"
      ]
    },
    {
      "id": "https://openalex.org/A2075067881",
      "name": "Micah Skeens",
      "affiliations": [
        "Nationwide Children's Hospital",
        "The Ohio State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2888203087",
    "https://openalex.org/W4385851471",
    "https://openalex.org/W4399907504",
    "https://openalex.org/W4229366284",
    "https://openalex.org/W4381952115",
    "https://openalex.org/W2940960150",
    "https://openalex.org/W4281395694",
    "https://openalex.org/W4393327656",
    "https://openalex.org/W4393529891",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W4394967854",
    "https://openalex.org/W4391784553",
    "https://openalex.org/W4402245094",
    "https://openalex.org/W1966976587",
    "https://openalex.org/W4393386964",
    "https://openalex.org/W4384389802",
    "https://openalex.org/W4399774223",
    "https://openalex.org/W4403680361",
    "https://openalex.org/W4391591650",
    "https://openalex.org/W4386304195",
    "https://openalex.org/W4383749364",
    "https://openalex.org/W4386423073",
    "https://openalex.org/W4392564188",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W3175938648",
    "https://openalex.org/W4385246972",
    "https://openalex.org/W4393125844",
    "https://openalex.org/W4400066098",
    "https://openalex.org/W4320710158",
    "https://openalex.org/W4221164017",
    "https://openalex.org/W4380871737",
    "https://openalex.org/W4389518954",
    "https://openalex.org/W4294214983",
    "https://openalex.org/W4391554501",
    "https://openalex.org/W4383295164",
    "https://openalex.org/W3111740296",
    "https://openalex.org/W4396900090",
    "https://openalex.org/W4396775758",
    "https://openalex.org/W4396775553",
    "https://openalex.org/W4400682759",
    "https://openalex.org/W4394807113",
    "https://openalex.org/W4387768520",
    "https://openalex.org/W2125487958",
    "https://openalex.org/W4394892516",
    "https://openalex.org/W4390647678",
    "https://openalex.org/W4403689553",
    "https://openalex.org/W4391591279",
    "https://openalex.org/W4404782785",
    "https://openalex.org/W4394723029",
    "https://openalex.org/W4391097696",
    "https://openalex.org/W4386022860",
    "https://openalex.org/W4386554968",
    "https://openalex.org/W4392851477",
    "https://openalex.org/W4404782774",
    "https://openalex.org/W4391610230",
    "https://openalex.org/W4389217447",
    "https://openalex.org/W4390499608",
    "https://openalex.org/W3190594412",
    "https://openalex.org/W3092758542",
    "https://openalex.org/W4389938179",
    "https://openalex.org/W2892173253",
    "https://openalex.org/W4382992448",
    "https://openalex.org/W4402389378",
    "https://openalex.org/W4399246606",
    "https://openalex.org/W4399999717",
    "https://openalex.org/W4399597451",
    "https://openalex.org/W4400657362",
    "https://openalex.org/W4403577524",
    "https://openalex.org/W4395044331"
  ],
  "abstract": "ABSTRACT Purpose Caregivers in pediatric oncology need accurate and understandable information about their child's condition, treatment, and side effects. This study assesses the performance of publicly accessible large language model (LLM)‐supported tools in providing valuable and reliable information to caregivers of children with cancer. Methods In this cross‐sectional study, we evaluated the performance of the four LLM‐supported tools—ChatGPT (GPT‐4), Google Bard (Gemini Pro), Microsoft Bing Chat, and Google SGE—against a set of frequently asked questions (FAQs) derived from the Children's Oncology Group Family Handbook and expert input (In total, 26 FAQs and 104 generated responses). Five pediatric oncology experts assessed the generated LLM responses using measures including accuracy, clarity, inclusivity, completeness, clinical utility, and overall rating. Additionally, the content quality was evaluated including readability, AI disclosure, source credibility, resource matching, and content originality. We used descriptive analysis and statistical tests including Shapiro–Wilk, Levene's, Kruskal–Wallis H ‐tests, and Dunn's post hoc tests for pairwise comparisons. Results ChatGPT shows high overall performance when evaluated by the experts. Bard also performed well, especially in accuracy and clarity of the responses, whereas Bing Chat and Google SGE had lower overall scores. Regarding the disclosure of responses being generated by AI, it was observed less frequently in ChatGPT responses, which may have affected the clarity of responses, whereas Bard maintained a balance between AI disclosure and response clarity. Google SGE generated the most readable responses whereas ChatGPT answered with the most complexity. LLM tools varied significantly ( p &lt; 0.001) across all expert evaluations except inclusivity. Through our thematic analysis of expert free‐text comments, emotional tone and empathy emerged as a unique theme with mixed feedback on expectations from AI to be empathetic. Conclusion LLM‐supported tools can enhance caregivers' knowledge of pediatric oncology. Each model has unique strengths and areas for improvement, indicating the need for careful selection based on specific clinical contexts. Further research is required to explore their application in other medical specialties and patient demographics, assessing broader applicability and long‐term impacts.",
  "full_text": null,
  "topic": "CLARITY",
  "concepts": [
    {
      "name": "CLARITY",
      "score": 0.9072827100753784
    },
    {
      "name": "Readability",
      "score": 0.8527369499206543
    },
    {
      "name": "Credibility",
      "score": 0.6175268292427063
    },
    {
      "name": "Medicine",
      "score": 0.4874880313873291
    },
    {
      "name": "Cross-sectional study",
      "score": 0.4221823811531067
    },
    {
      "name": "Medical education",
      "score": 0.40372687578201294
    },
    {
      "name": "Psychology",
      "score": 0.3244161605834961
    },
    {
      "name": "Computer science",
      "score": 0.3121373653411865
    },
    {
      "name": "Pathology",
      "score": 0.11880958080291748
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}