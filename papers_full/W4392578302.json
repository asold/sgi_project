{
  "title": "The Transformative Potential of Large Language Models in Mining Electronic Health Records Data",
  "url": "https://openalex.org/W4392578302",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2137299157",
      "name": "Amadeo Wals-Zurita",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2953453661",
      "name": "Héctor Miras del Río",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5041030328",
      "name": "Nerea Ugarte Ruiz de Aguirre",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5111142556",
      "name": "Cristina Nebrera Navarro",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5106266879",
      "name": "María Rubio Jiménez",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2518681324",
      "name": "David Muñoz Carmona",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2546802706",
      "name": "Carlos Míguez Sánchez",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2137299157",
      "name": "Amadeo Wals-Zurita",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2953453661",
      "name": "Héctor Miras del Río",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5041030328",
      "name": "Nerea Ugarte Ruiz de Aguirre",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5111142556",
      "name": "Cristina Nebrera Navarro",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A5106266879",
      "name": "María Rubio Jiménez",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2518681324",
      "name": "David Muñoz Carmona",
      "affiliations": [
        "Hospital Universitario Virgen Macarena"
      ]
    },
    {
      "id": "https://openalex.org/A2546802706",
      "name": "Carlos Míguez Sánchez",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2345195116",
    "https://openalex.org/W2967056613",
    "https://openalex.org/W3134687420",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4362721801",
    "https://openalex.org/W4386865118",
    "https://openalex.org/W4386932783",
    "https://openalex.org/W3092731154",
    "https://openalex.org/W3083410900",
    "https://openalex.org/W4297014655",
    "https://openalex.org/W4400408791",
    "https://openalex.org/W4380995257",
    "https://openalex.org/W4387301351",
    "https://openalex.org/W4396653542",
    "https://openalex.org/W4395050972",
    "https://openalex.org/W4387928375",
    "https://openalex.org/W1995945562",
    "https://openalex.org/W4393466856",
    "https://openalex.org/W4399161615",
    "https://openalex.org/W4386836900",
    "https://openalex.org/W4323542771",
    "https://openalex.org/W4308292299"
  ],
  "abstract": "Abstract Objectives To explore the potential of Large Language Models (LLMs) to extract and structure information from free-text clinical reports, with a specific focus on identifying and classifying patient comorbidities in the electronic health records of oncology. We specifically evaluate the gpt-3.5-turbo-1106 and gpt-4-1106-preview models in comparison with the capabilities of specialized human evaluators. Methods We implemented a script using the OpenAI API to extract structured information in JSON format from comorbidities reported in 250 personal history reports. These reports were manually reviewed in batches of 50 by five specialists in radiation oncology. We compared the results using metrics such as Sensitivity, Specificity, Precision, Accuracy, F-value, Kappa index, and the McNemar test, in addition to examining the common causes of errors in both humans and GPT models. Results The GPT-3.5 model exhibited slightly lower performance compared to physicians across all metrics, though the differences were not statistically significant. GPT-4 demonstrated clear superiority in several key metrics. Notably, it achieved a sensitivity of 96.8%, compared to 88.2% for GPT-3.5 and 88.8% for physicians. However, physicians marginally outperformed GPT-4 in precision (97.7% vs. 96.8%). GPT-4 showed greater consistency, replicating exact results in 76% of the reports after 10 analyses, in contrast to 59% for GPT-3.5. Physicians were more likely to miss explicit comorbidities, while the GPT models more frequently inferred non-explicit comorbidities, sometimes correctly, though this also resulted in more false positives. Conclusion The studied LLMs, with carefully designed prompts, demonstrate competence comparable to that of medical specialists in interpreting clinical reports, even in complex and confusingly written texts. Considering also their superior efficiency in terms of time and costs, these models represent a preferable option over human analysis for data mining and structuring information in large collections of clinical reports.",
  "full_text": "Title: The Transformative Potential of Large Language \nModels in Mining Electronic Health Records Data. \n \nAuthors: \nAmadeo Wals Zurita1, Héctor Miras del Rio2, Nerea Ugarte Ruiz de Aguirre1, Cristina \nNebrera Navarro1, María Rubio Jiménez1, David Muñoz Carmona1, Carlos Míguez \nSánchez1. \n1: Servicio de Oncología Radioterápica. Hospital Universitario Virgen Macarena. \nSevilla. España. \n2: Servicio de Radiofísica Hospitalaria. Hospital Universitario Virgen Macarena. \nSevilla. España. \n \nAbstract \nObjectives: To explore the potential of Large Language Models (LLMs) to extract and structure \ninformation from free-text clinical reports, with a specific focus on identifyin g and classifying patient \ncomorbidities in the electronic health records of oncology. We specifically evaluate the gpt -3.5-turbo-\n1106 and gpt -4-1106-preview models in comparison with the capabilities of specialized human \nevaluators. \nMethods: We implemented a script using the OpenAI API to extract structured information in JSON \nformat from comorbidities reported in 250 personal history reports. These reports were manually \nreviewed in batches of 50 by five specialists in radiation oncology. We compared the re sults using \nmetrics such as Sensitivity, Specificity, Precision, Accuracy, F-value, Kappa index, and the McNemar \ntest, in addition to examining the common causes of errors in both humans and GPT models. \nResults: The GPT-3.5 model exhibited slightly lower p erformance compared to physicians across all \nmetrics, though the differences were not statistically significant. GPT-4 demonstrated clear superiority \nin several key metrics. Notably, it achieved a sensitivity of 96.8%, compared to 88.2% for GPT-3.5 and \n88.8% for physicians. However, physicians marginally outperformed GPT -4 in precision (97.7% vs. \n96.8%). GPT-4 showed greater consistency, replicating exact results in 76% of the reports after 10 \nanalyses, in contrast to 59% for GPT -3.5. Physicians were more l ikely to miss explicit comorbidities,  \nwhile the GPT models more frequently inferred non-explicit comorbidities, sometimes correctly, though \nthis also resulted in more false positives. \nConclusion: The studied LLMs, with carefully designed prompts, demonstrate competence \ncomparable to that of medical specialists in interpreting clinical reports, even in complex and confusingly \nwritten texts. Considering also their superior efficiency in terms of ti me and costs, these models \nrepresent a preferable option over human analysis for data mining and structuring information in large \ncollections of clinical reports. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nIntroduction \nClinical Natural Language Processing (cNLP), a subfield dedicated to the analys is of \nclinical texts within artificial intelligence, has experienced a significant development \nover the last decades. Recent advancements in computing power and algorithms have \nenabled its expanded application in oncological research. \nIn the field of oncol ogy, cNLP has been discussed as a valuable tool for improving \ncancer treatment outcomes. This includes its integration into electronic medical \nrecords, as highlighted in the studies by Yim W. et al [1] and Savova GK et al [2]. \nThese studies emphasize the potential of cNLP to harness unstructured data from \nroutine clinical practice and to catalyze evidence -based research.  Commercial \nsystems like Watson for Oncology® (WFO), introduced by IBM in 2015, have also \nemerged, employing cNLP techniques to provide on cological treatment \nrecommendations. However, their reliability has been questioned due to insufficient \nagreement rates compared with specialist physicians observed in some scenarios [3]. \nTransformer models, a deep learning architecture introduced in the paper \"Attention is \nAll You Need\" by Vaswani et al. in 2017  [4], have revolutionized the field of Natural \nLanguage Processing (NLP), establishing themselves as the founda tion upon which \nmodern Large Language Models (LLMs) have been developed. LLMs, such as \nOpenAI's Generative Pre -trained Transformers (GPT), are models trained on vast \namounts of text to learn complex linguistic patterns. This enables them to generate \ntext, understand context, perform translations, and carry out other tasks with \nunprecedented accuracy and fluency. Thanks to this capability, users can interact with \nthese models, instructing them to tackle various problems without the need for \nadditional training. \nThe GPT-3 model, released in 2020, and its successor, GPT-4 [5], introduced in 2023, \nrepresent significant advancements in the ability to understand and generate coherent \ntext. GPT-4, in particular, offers notable improvements in accuracy and in reducing the \ngeneration of false information. Additionally, it is capable of processing both images \nand text. \nSince the public release of GPT models, there has been a steady in crease in studies \nexamining their application in analyzing and interpreting clinical texts. In an editorial \npublished in March 2023 in the International Journal of Radiation Oncology, Biology, \nPhysics (IJRBP) [6], concerns about the reliability of GPT models in radiation oncology \nwere raised. The authors discussed both the potential benefits and concerns regarding \nthe reliability of this tool, including its ability to summarize lengthy texts, respond to \nclinical inquiries, a nd provide educational materials. Furthermore, the importance of \ncarefully evaluating the credibility of references generated by ChatGPT was \nunderscored, along with the suggestion of developing tool versions tailored to different \nmedical specialties. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nWithin the field of radiodiagnostic imaging, Matthias A. Fink et al [7] conducted a study \ninvestigating the capacity of Large Language Models (LLMs) in extracting data from \ncomputed tomography (CT) reports concerning lung cancer . Employing two LLMs, \nnamely ChatGPT and GPT-4, they analyzed CT reports and produced labels indicating \ndisease progression. The findings showcased outstanding performance in disease \nprogression classification, outperforming alternative natural language processing \nmodels. \nFocusing on the significance of appropriate in structions (prompts), researchers such \nas Hyeon Seok Choi et al [8] highlighted that the gpt -3.5-turbo model exhibited an \naccuracy rate of 87.7% in extracting information from pathology and ultrasound reports \nof breast cancer patients. This achievement represents a notable advancement over \ntraditional natural language processing models . The authors emphasized the crucial \nrole of well-designed prompts in maximizing the capabilities of LLMs, as these prompts \nsignificantly influence model output and performance. In an estimated comparison, the \nLLM methods demonstrated superior efficiency in terms of time and costs compared \nto the manual method. \n \nConstructing an Oncological Information System at HUVM \nIn 2018, the Department of Radiation Oncology at HUVM initiated the implementation \nof the Mosaiq system, transitioning towards a paperless workflow and centralizing all \nradiation therapy treatment data within the application. As detailed by Bertolet et al [9], \nthis data was automatically exported to JSON files via Word documents and VBA code. \nSubsequently, a MongoDB database was developed to efficiently store and access \nthis data, integrating additional information from other systems such as DICOM \ntreatment plans, administrative data sourced from the Andalusian Public Health \nService (SSPA), and patient histories from its electronic health record (EHR) system, \nDIRAYA. As the culminat ion of this process, we developed SIOW (Web Oncological \nInformation System), a web application for managing, consulting, and visualizing this  \nintegrated information. Figure 1 depicts a diagram illustrating the flow and organization \nof the described data. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n \nFigure 1: Representative diagram of the Web Oncological Information System (SIOW). It illustrates the \nintegration of data from MOSAIQ and TPS into the MongoDB database, and its subsequent \nmanagement through SIOW, including the collection of administrative data from the Users Data Base \n(BDU) and clinical data from the EHR system DIRAYA. \nMotivated by the capabilities of LLM s, we aimed to investigate their potential \napplication in extracting and structuring information from clinical reports . Our \noverarching objective is to integrate LLM -based tools into our information system, \nenhancing the richness of our real-world datasets. Specifically, in this study, we assess \nthe capability of the GPT 3.5 and 4 models as tools for data mining applied to the \nidentification and classification of  comorbidities and relevant lifestyle risk factors in \noncological texts. We compare their performance against that of specialized human \nevaluators to gauge their efficacy and suitability for clinical use. \n \nMethods \nOpenAI API \nThe application programming interface  (API) of OpenAI [10] allows interaction with \ntheir advanced LLMs, facilitating various language processing tasks such as \ngenerating automatic textual responses, conducting sentiment analysis, and \nsummarizing texts. In our study, we leverage the chat.completions.create function of \nthe API to extract structured information from unstructured clinical reports. \nOpenAI offers a comprehensive library of natural language processing models. Each \nmodel features unique characteristics in terms of size, language comprehension \nability, speed, and cost. In our study, we have employed two models from the library: \nMain\ncollection\nRT\nPatients Clinical\nStatus\nTreatment\nsessions\nRT plans\nComorbidities\nJSON\nFiles\nMOSAIQ\n❏ Forms\n❏ WordDocs+VBA\n❏ Schedule reports\nTPS\n❏ RTPLAN\n❏ RTSTRUCT\n❏ RTDOSE\nSIOW\nBDU\nDIRAYA\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n- gpt-4-1106-preview: Positioned among the most sophisticated within the GPT-\n4 series, this model is engineered to deliver highly accurate outcomes for \ncomplex natural language processing tas ks. Its exceptional ability to \ncomprehend text makes it well -suited for interpreting medical jargon and the \nlinguistic variability present in clinical reports. \n- gpt-3.5-turbo-1106: Representing a more cost-effective and faster option from \nthe previous generation (GPT-3.5), this model, while not as advanced as GPT-\n4, remains effective for many NLP tasks. It is particularly valuable for \napplications that demand quicker responses and reduced token consumption. \nA noteworthy feature of these models is their capability to structure responses in JSON \nformat. By setting the response_format to {\"type\": \"json_object\"} in the API requests, \nwe engage JSON mode, which directs the model to organize its responses into a \nstructured JSON object. JSON mode allows us to receive responses already formatted \nfor direct integration into databases and applications, eliminating the need for \nadditional processing steps to organize the model's output. This streamlines the \nintegration process and enhances the efficiency of utilizing  the model's outputs in \ndownstream applications. \nFor this study, we utilized clinical reports in Spanish, exclusively interacting with \nOpenAI's LLMs in this language. Although LLMs typically exhibit superior performance \nin English, owing to the predominanc e of this language in training data, recent \ncomparisons indicate notable effectiveness in other languages, including Spanish. The \nGPT-4 technical report  [5] highlights th is multilingual capability, demonstrating that \nperformance in Spanish closely approaches that of English, with a minimal difference \nof only 1.5 percentage points in the MMLU evaluation [11]. \n \nPrompt generation \nTo interact with the LLM models, we first create a prompt that will guide the model \nthrough the specific task. The context provided to the model establishes a scenario in \nwhich it is asked to assume the role of a specialist in radiation oncology.  This setting \nserves as a reference framework, enabling the model to adopt the appropriate \nperspective and apply its natural language understanding capabil ities in a manner \nconsistent with the medical domain.  \nOur request is a direct instruction to the model, directing it to process the text of the \nprovided clinical report and return the relevant information in a structured format. \nSpecifically, the model is instructed to utilize the clinical report provided at the end of \nthe prompt to complete a predefined dictionary in JSON format. This dictionary \ncontains keys related to comorbidities and lifestyle risk factors. The model is tasked \nwith updating the values  of these keys with \"YES\" or \"NO\" as appropriate. For \nindividuals who are ex-smokers, the model should use \"EX\" instead. Additionally, the \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nmodel must identify and add any other relevant comorbidities not classifiable under \nthe provided categories, assigning them to the \"Other\" key. \nThis is the prompt generated for the task: \n• Context: \"Act as a specialist in radiation oncology.\" \n• Request: \"Use the clinical report provided at the end of this prompt to return in \nJSON format the dictionary [...] with the values ' YES' or 'NO'. For the 'Smoker' \nfield: 'YES' if they smoke, 'NO' if they have never smoked, 'EX' if they are an \nex-smoker. For the 'Other' field, return a list of comorbidities found that cannot \nbe classified in any of the categories of the keys of the prov ided dictionary, or \nempty if there are no other comorbidities. Return only the dictionary with the \nupdated values, DO NOT ADD OR MODIFY KEYS. Clinical report: [text of the \nclinical report]\" \nThe dictionary mentioned in the request is structured with keys labeling the specific \ncomorbidities and lifestyle risk factors we seek to identify. These comorbidities, along \nwith their potential values, are outlined in Table 1. \nTable 1: List of the labels, possible values, and description of the comorbidities and lifestyle risk factors \nconsidered in this study.  \nLabel Values Description \nDiabetes YES/NO Elevated blood glucose levels \nHBP YES/NO High Blood Pressure \nSmoker YES/NO/EX Smoking habit. \nDyslipidemia  YES/NO Lipid metabolism disorder \nLiver Disease YES/NO Liver Disease \nCOPD YES/NO Chronic Obstructive Pulmonary Disease \nDepression YES/NO Mood disorder \nKidney Disease YES/NO Kidney Disease \nFentanyl YES/NO Use of WHO step 3 analgesics. (Opioids) \nHeart Disease YES/NO Heart Disease \nHyperthyroidism YES/NO Thyroid disease with increased thyroxine \nHypothyroidism YES/NO Thyroid disease with decreased thyroxine \nDependent YES/NO Patient in need of continuous care \nOther Text list Other past comorbidities detected not listed above. \n \nDuring a postprocessing phase, we divided the category labeled as \"smoker\" into two \ndistinct categories: \" smoker\" (representing current smokers) and \" ex-smoker\". This \ndivision was implemented to ease the subsequent analysis of the results. \nIt's important to highlight that the prompt does not provide context or additional \ninstructions regarding how the specified comorbidities of interest should be \ninterpreted. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nThe development of this prompt was achieved through an iterative process applied to \na group of 50 reports that were specifically reserved for this purpose. The methodology \nincluded the following steps: \n1. Prompt Definition: Establishing the parameters and structure of the prompt to \nguide the model's responses. \n2. Information Extraction:  The developed prompt was applied to 50 reports \nusing the GPT-4-1106-preview model. \n3. Verification of Structure: It was ensured that the model's responses adhered \nto the requested st ructure, with previous steps being repeated in case of \ndeviations. \n4. Accuracy Evaluation: A specialist physician (AW) verified the accuracy of the \nmodel's responses. This process was repeated until the accuracy met or \nexceeded that of a manual analysis performed by the same physician. \n \nPython Script \nThe Python script developed utilizes the OpenAI API to automatically structure textual \nclinical information. The process begins with reading patient clinical reports stored in \nan Excel file, followed by generating  individual prompts for each patient using the \nget_query_prompts function. These prompts are then passed to the extract_info_gpt \nfunction, which invokes the OpenAI API and receives the structured information \ndirectly in a JSON format. The script also calculates the estimated cost and execution \ntime and saves the results and query details in an Excel file for further analysis. All the \ncode developed for this work is openly available in a GitHub the repository [12]. \n \nClinical Report Acquisition Procedure \nThe clinical reports for our study were provided by the hospital's Innovation & Data \nAnalysis department. These reports were delivered in an Excel spreadsheet format, \norganized into two essential columns: one containing the clinical h istory number of \neach patient and another with the text of the medical personal history report. The \ndepartment responsible for data collection undertook a process of anonymization and \nrandomization of the reports to ensure an unbiased selection. \n \nSample Selection Criteria \nFor estimating the sample size, we relied on the proportion of comorbidities (80%) \nobtained from a prio r analysis of a dataset of 5257 personal history reports from \npatients treated in our service between May 2018 and October 2022. Detection was \nperformed using keywords and their variants (diabetes, hypertension, dyslipidemia, \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \netc.) through Boolean operators and with search and reference functions in Microsoft® \nExcel® for Microsoft 365 MSO (version 2312). \nThe comorbidities selected for the study were chosen based on prior knowledge of \nprevalences in the general population and those presented by our patients according \nto the aforementioned analysis. We also considered those that could most significantly \nimpact the clinical outcome of oncological treatments. \nWith these considerations, we conducted a preliminary calculation that established the \nneed to include 250 clinical reports (see below in the statistical analysis section). \nBased on this calculation, we selected the first 250 patients from the provided list who \nhad a non -empty personal history report. Before proceeding with the analysis, we \nvalidated that our script was capable of correctly interpreting an empty report as \nequivalent to the absence of comorbidities, thereby avoiding biases in the study \nresults. \n \nEthical Considerations and Data Protection \nThe text processed by the selected LLMs  is strictly confined to personal history \nreports. These reports were stripped of any information that could lead to patient \nidentification, ensuring confidentiality and anonymity. The model’s interpretation of the \ntexts focuses solely on identifying and structuring data relevant to the study, without \ncompromising individual privacy. \nThe study's design and methodology have been communicated to and reviewed by \nthe hospital's ethics committee. The research received the necessary approval, \nconfirming that it adheres to the ethical standards required for patient data research. \nThis retrospective study adheres to the guidelines outlined in the seventeenth \nadditional provision, specifically Health Data Processing, Section d) of the Organic \nLaw 3/2018, dated December 5, on Personal Data Protection and Guarantee of Digital \nRights. This law governs the use of pseudo -anonymized personal data for health \nresearch purposes. The study was granted an exemption from requiring informed \nconsent due to its exclusive use of non-identifiable data.  \nOn January 18, 2024, the Ethics Committ ee of the University Hospitals Virgen \nMacarena and Virgen del Rocío issued a favorable opinion for our study, under the \nreference EC_IA_V1 (Version 1-Dec-2023). \n \nManual Extraction \nThe 250 patient clinical reports were divided into five groups, each consist ing of 50 \nreports. These groups were randomly assigned to five physicians, including three \nspecialists in radiation oncology and two residents in the same field. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nTo ensure uniform and accurate data collection, the physicians were provided with a \nspecially designed Excel template for this task. The template features a table where \nthe first column contains the full texts of the clinical reports. The subsequent columns \nof the table are labeled with the comorbidities of interest . The cells corresponding to \neach comorbidity only allow the selection of predefined values, as stipulated in Table \n1. This restriction ensures consistent annotation and reduces the possibility of errors \nor variations in the entries. \n \nAutomatic Extraction \nThe 250 clinical reports in the sample were automatically analyzed using our script \nwith the gpt-3.5-turbo-1106 and gpt-4-1106-preview models. To maintain a consistent \nstructure in the study, these reports were organized into the same five groups of 50 \nreports that were assigned to the physicians. The results were recorded in an Excel \ndocument, mirroring the structure of the template used in the manual extraction. This \nuniformity in documentation facilitates a direct comparison of results between manual \nand automatic extraction methods. \n \nEstablishing the Ground Truth \nTo assess the comparative accuracy and effectiveness of the LLMs used in this study \nagainst the evaluations performed by physicians, it is crucial to establish a reference \ndataset containing the  ground truth. To construct this reference dataset, we first \ncompared the results obtained from the physicians and the gpt-4-1106-preview model \nacross all 250 reports, identifying and recording any discrepancies between the two \nsources. The detected differences were then subjected to further review by an expert \nphysician (AW). For each report where discrepancies in the results were found, \nphysician AW assessed both responses (from the physician and the AI) and \ndetermined which one was correct. \n \nAssessing Reproducibility in Results \nThe non-deterministic nature of LLMs, such as GPT-3.5 and GPT-4, means they can \ngenerate different responses to identical requests [5]. This phenomenon, coupled with \nthe potential for periodic retraining of the models, significantly impacts the \nreproducibility of results. Therefore, it is crucial to consider the need for rigorous quality \ncontrol for algorithms that employ LLMs, especially to assess  the impact of any \nchanges in the models. \nA well -defined and explicit prompt can increase the reproducibility of responses. \nHowever, variability remains a possibility, particularly in situations where the \ninformation is ambiguous, or the prompt is not clear or specific enough. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nTo measure the consistency of our automatic extraction method, we repeated the \nanalysis of the 250 clinical reports 10 times over 10 consecutive days. This approach \nallows us to observe the stability of the model responses to the same input. \n \nStatistical Analysis \nTo ensure the statistical validity of the study, a significance level of 5% (alpha error) \nand a power of 80% (beta error of 20%) were established. Additionally, a 5% error \nmargin was applied for 95% confidence intervals. With these considerations in mind, \nit was determined that the sample size (n) should include 245 patient records. To adjust \nthe sample to a practical number, it was rounded up, resulting in a final sample size of \n250. \nFigure 2: Flowchart of the study design. \nFor a comprehensive analysis, we consolidated the results from the 250 reports into \na single category named “Physicians,” representing the aggregated findings of the five \ndoctors involved in the study. Subsequently, we compared this category and the results \nfrom the GPT-3.5 and GPT-4 models with the reference dataset, considered as the \nground truth. In this process, a confusion matrix was created for each report and \ncomorbidity, from which several key statistical estimators were derived. \nTo assess the agreement, we employed the Kappa index. The McNemar's test was \nused to determine if there were significant differences in the proportions of \ndiscordance between the classifications. We chose the F -score as a measure of \nbalance between precisi on and sensitivity, which is crucial in a classification model. \nThe calculated metrics are presented in the Table 2. \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nTable 2: Metrics used in the study with their descriptions. \nMetric Description \nTP True Positives \nTN True Negatives \nFP False Positives \nFN False Negatives \nSensitivity TP/(TP+FN) \nSpecificity TN/(FP+TN) \nPrecision TP/(TP+FP) \nPrevalence (TP+FN)/(TP+TN+FP+FN) \nAccuracy (TP+TN)/(TP+TN+FP+FN) \nKappa (Pobs-Pesp)/(1-Pesp) \nF-score (2*Precision*Sensibility)/(Precision+Sensibility) \nMcNemar Exact-P-value from McNemar test (binomial distribution) \n \nFor some of these metrics, we calculated their confidence interval using the \nbootstrapping method. This approach starts from the frequencies of True Positives \n(TP), True Negatives (TN), False Positives (FP), and False Negatives (FN) to generate \n1,000 resamples. With these resamples, we recalculated the metrics to obtain a \ndistribution that allows us to calculate the 95% confidence interval. \nAdditionally, a detailed analysis was conducted on the groups of 50 reports assigned \nto each physician. This analysis focused on measuring the variability in evaluations \namong different physicians. For each patient and comorbidity, Cohen's kappa index \nwas calculated in comparison with the ground truth for the results of each physician. \nThe reproducibility of the GPT -3.5 and GPT-4 models was assessed by quantifying \nthe number of different responses for each patient and comorbidity across the 10 \nrepeated analyses conducted on successive days. \n \nAnalysis of Discrepant Results \nA detailed analysis of discrepancies between the evaluators' results and the \nestablished Ground Truth was conducted by the same physician who defined the \nreference dataset. This analysis covered each report with discrepancies in the \nidentification of comorbidities, identifying the probable causes of each deviation. \nDiscrepancies were classified according to the nature of the detected errors: \n• Differences in criteria: Variations in the interpretation of the relevance of \nreported pathologies. \n• Incorrect interpretation: Misunderstandings caused by confusing wording. \n• Incorrect inference: Erroneous deductions when the comorbidity is not \nexplicitly mentioned. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n• Ambiguous text: Textual ambiguity that allows for multiple interpretations. \n• Error/Hallucination: Unjustified errors, attributed to human distractions or AI \nhallucinations. \n• Error in Ground Truth:  Corrections made upon review that validate the \nevaluator's interpretation. \n• Explicit omission: Overlooking direct mentions of comorbidities. \n• Omission by context: Failure to notice comorbidities deducible from the \ncontext or medication. \n• Unrecognized acronyms: Inability to interpret specific medical acronyms. \n \nResults \nCost and time analysis by model \nTable 3 details the cost and total time invested in analyzing the 250 reports using the \nGPT-3.5 and GPT-4 models. It is noted that GPT-4, being a larger and more complex \nLLM compared to GPT-3.5, incurs longer processing times and a cost approximately \n10 times higher. Extrapolating these data to the entire set of 7,500 patients currently \nregistered in our database, processing with GPT-4 would require about 24 hours and \nwould cost approximately 76 dollars. On the other hand, using GPT-3.5 would reduce \nthe processing time to about 9 hours, with a significantly lower cost of around 7 dollars. \nTable 3: Execution times and costs in dollars for the analysis of the 250 reports with each of the \nmodels used. \nModel Time (min) Cost ($) \ngpt-3.5-turbo-1106 18.63 0.23 \ngpt-4-1106-preview 47.65 2.53 \n \nPrevalences \nThe analysis of our Ground Truth sample reveals a wide range of prevalences in \ncomorbidities and lifestyle risk factors among oncological patients. These are detailed \nin Table 4, where both the number of cases and the prevalence for each comorbidity \nare reported. The most common conditions include high blood pressure and \ndyslipidemia, present in almost half and a third of the cases, respectively. On the other \nhand, conditions like hyperthyroidism and liver disease show relatively low prevalence. \nCategories related to smoking are also highly frequent, accounting for almost 50% of \nthe cases. Interestingly, the proportion of ex-smokers significantly exceeds that of \ncurrent smokers. \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nTable 4: Number of reports, out of the total 250 in the sample, that indicate each comorbidity and the \ncorresponding prevalence. \nCondition #Cases Prevalence \nDiabetes 64 25.6% \nHBP 116 46.4% \nSmoker 37 14.8% \nDyslipidemia 77 30.8% \nHypothyroidism 21 8.4% \nCOPD 17 6.8% \nDepression 25 10.0% \nKidney disease 39 15.6% \nFentanyl 19 7.6% \nHeart disease 43 17.2% \nHyperthyroidism 1 0.4% \nLiver disease 13 5.2% \nDependent 12 4.8% \nEx-smoker 85 34.0% \nEvaluation metrics \nTable 5 display the values of true positives, false positives, true negatives, and false \nnegatives, detailed by comorbidity, derived from the comparison with the Ground Truth \ndataset. \nTable 5: Tables displaying the results for true positives (TP), true negatives (TN), false positives (FP), \nand false negatives (FN) for each comorbidity, obtained by each of the evaluators (Physicians, GPT-\n3.5, and GPT-4). \n Physicians GPT-3.5 GPT-4 \n TP TN FP FN TP TN FP FN TP TN FP FN \nDiabetes 63 185 1 1 54 186 0 10 63 186 0 1 \nHBP 110 133 1 6 113 132 2 3 114 133 1 2 \nSmoker 37 209 4 0 36 212 1 1 36 213 0 1 \nDyslipidemia 67 173 0 10 67 172 1 10 74 173 0 3 \nHypothyroidism 19 229 0 2 19 229 0 2 20 227 2 1 \nCOPD 16 233 0 1 15 233 0 2 16 231 2 1 \nDepression 25 224 1 0 21 220 5 4 22 223 2 3 \nKidney disease 15 211 0 24 21 211 0 18 38 208 3 1 \nFentanyl 18 231 0 1 18 230 1 1 19 230 1 0 \nHeart disease 38 207 0 5 30 205 2 13 40 205 2 3 \nHyperthyroidism 0 249 0 1 0 249 0 1 1 249 0 0 \nLiver disease 9 236 1 4 12 234 3 1 13 234 3 0 \nDependent 12 234 4 0 11 238 0 1 10 238 0 2 \nEx-smoker 76 165 0 9 85 161 4 0 85 163 2 0 \nTotal 505 2919 12 64 502 2912 19 67 551 2913 18 18 \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n \nFigure 3 illustrates the performance of the physicians, GPT-3.5, and GPT-4 classifiers, \nbroken down by comorbidity, across various metrics. The “Total” category, which \nconsolidates the results for all studied comorbidities, enables direct comparison \nbetween the three evaluators on each assessed metric: \n• Sensitivity: The GPT-4 model (96.8%) demonstrates superiority over GPT-\n3.5 (88.2%) and the physicians (88.8%) in most categories, showing notable \neffectiveness in detecting comorbidities. Although GPT-3.5 presents slightly \nlower results than the physici ans, the difference is not statistically \nsignificant. \n• Specificity: All evaluators achieve high specificity values, which is expected \ngiven the low prevalences of the studied comorbidities and the relative ease \nof identifying the absence of a comorbidity in texts. The physicians (99.6%) \nexcel in this metric, often achieving perfection, while both models (99.4%) \nscore slightly lower due to a higher rate of false positives. \n• Precision: The physicians get the highest score  (97.7% vs 96.4% and \n96.8%) assessing the proportion of correct positive identifications, possibly \nalso influenced due to  the models generating a higher number of false \npositives. \n• F-Score: Representing the harmonic mean between precision and \nsensitivity, the F-Score is particularly relevant in asymmetric samples like in \nour study. The GPT -4 model achieves the highest score (96.8%) on this \nindicator, surpassing both GPT-3.5 (92.1%) and the physicians (93.0%). \n• Accuracy (Agreement): In the proportion of correct identifications, GPT -4 \nshows superior performance (99.0%), while GPT -3.5 (97.5%) and the \nphysicians (97.8%) achieve similar results. \n• Cohen's Kappa Index:  This index, measuring agreement adjusted for \nchance, reveals that GPT -4 reaches the highest scores (0.962), \ndemonstrating greater consistency compared to the ground truth. The GPT-\n3.5 score of 0.907, while marginally lower, does not significantly differ f rom \nthe physicians' score of 0.917. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n \nFigure 3: Statistical metrics comparison between three evaluators (Physicians, GPT-3.5, and GPT-4) \nfor individual comorbidities and overall totals. Asymmetric error bars indicate the 95% confidence \ninterval. \nBased on the results obtained, we can conclude that the GPT-4 model is notably better \nat identifying present comorbidities (fewer false negatives), while physicians are \nslightly more accurate in their diagnoses (fewer false positives). The GPT -3.5 model \ngenerally performs slightly below the physicians, though the differences found are not \nstatistically significant. \nThe application of McNemar's test to the “Total” category, comparing Physicians with \nGPT-3.5 and Physicians with GPT -4, yielded p-values of 0.79 and 10-6, respectively. \nThis confirms that the performance differences between the physicians and the GPT-\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \n3.5 model are not statistically significant, while the differences between the physicians \nand GPT-4 are significant. \n \nVariability among physicians’ performance \nTable 6 displays the Cohen’s Kappa index values obtained in the detection of various \ncomorbidities for each of the five physician evaluators. It is important to note that each \nphysician analyzed a different group of 50 reports. \nTable 6: Concordance values for each comorbidity, calculated using Cohen's Kappa index for each \nmedical evaluator. The “Total” categories summarize the aggregated concordance across all \ncomorbidities and medical evaluators. \n #M1 \nsenior \n#M2 \nresident \n#M3 \nsenior \n#M4 \nsenior \n#M5 \nresident \nTOTAL \n#HUM \nDiabetes 1.00 0.95 1.00 1.00 0.95 0.98 \nHBP 1.00 0.96 0.83 0.96 0.96 0.94 \nSmoker 1.00 1.00 0.88 0.86 0.93 0.94 \nDyslipidema 0.91 1.00 0.75 0.77 1.00 0.90 \nHypothyrodism 0.66 1.00 0.90 1.00 1.00 0.95 \nCOPD 1.00 1.00 1.00 0.66 1.00 0.97 \nDepression 0.93 1.00 1.00 1.00 1.00 0.98 \nKidney disease 0.52 0.70 0.45 0.56 0.26 0.51 \nFentanyl 1.00 1.00 0.85 1.00 1.00 0.97 \nHeart disease 0.95 1.00 0.91 0.79 1.00 0.93 \nHyperthyroidism - - - - 0.00 0.00 \nLiver disease - 1.00 0.63 0.65 1.00 0.77 \nDependent 0.66 0.66 0.91 0.88 - 0.85 \nEx-smoker 0.95 1.00 0.87 0.76 1.00 0.92 \nTotal 0.95 1.00 0.87 0.76 1.00 0.92 \n \nOverall, there was considerable similarity in the physicians' responses, except when \nthe comorbidity to be detected was a broader concept, as in the case of “kidney \ndisease” (kappa 0.51) or “liver disease” (kappa 0.77). It's important to note that no \nfurther instructions or explanations were provided beyond finding the comorbidity in \nthe presented text. Therefore, some physicians considered that renal lithiasis was not \na relevant \" kidney disease” and reserved this category for conditions describing an \nalteration in renal function (such as chronic renal failure, for example). \nInterestingly, the senior physicians scored lower than the medical residents in the \noverall calculation for the Kappa index. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nReproducibility of models’ responses \nIn our reproducibility study, each report was analyzed 10 times by the GPT -3.5 and \nGPT-4 models. For each comorbidity, we counted the number of different responses \ngenerated in these repeated analyses, as well as the total number of variations for \neach report. \nFigure 4 presents a histogram illustrating the number of reports that generated at least \nthe specified number of different responses. This histogram reveals that, in all \ninstances, the GPT -4 model exhibited fewer differences in responses compared to \nGPT-3.5, suggesting greater consistency and reliability in its results. \nFurthermore, it was found that 73.6% of the reports analyzed with GPT-4 reproduced \nthe same result across all comorbidities during the 10 analyses, compared to 59.2% \nfor GPT-3.5. This notable difference in re producibility underscores the superiority of \nGPT-4 in maintaining consistency in its responses across multiple executions. \n \nFigure 4: For each model, the number of reports is shown in which at least the number of differences \nindicated on the x-axis were obtained in the 10 analyses. \nVariability in responses often stems from ambiguous text, where LLMs may assign \nvalues inconsistently. For example, a report describing a patient as an \"active smoker \n(1 month since quitting, 1 pack/day since age 14 -16)\" resulted in GPT-3.5 identifying \nthe patient as a smoker in six out of ten analyses, while GPT -4 made only one error \nacross ten analyses. However, in the same report, regarding the comorbidity of COPD, \nGPT-4 shows a split: in five instances it identifies it as present and in five as absent. \nThe physician reviewing the results and establishing the ground truth determined the \nabsence of COPD, as it is not explicitly mentioned in the report. Nonetheless, the \nmention of “mild pulmonary emphysema areas” and the pa tient's prolonged smoking \nhistory could lead GPT-4 to infer the presence of COPD. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nDiscrepancy Analysis \nFigures 5 and 6 display the distribution of discrepant results categorized by the causes \ndetermined through a detailed manual analysis of the reports. \n \nFigure 5: Number of false positive results attributed to each of the considered causes. \n \nFigure 6: Number of false negative results attributed to each of the considered causes. \nA notable discrepancy arose in the \"kidney disease\" category due to differ ences in \ncriteria. Some physicians and GPT-3.5 did not deemed certain renal pathologies, such \nas renal lithiasis, as relevant comorbidities in the context of oncology treatment, unlike \nGPT-4, which aligned its results more closely with the ground truth. \nIn analyzing cases interpreted as hallucinations, it was found that this phenomenon \noccurred exclusively in 1 response from GPT-4 and in 6 from GPT-3.5, particularly in \n0\n1\n2\n3\n4\n5\n6\n7\n8\nDifferences in\ncriteria\nIncorrect\ninterpretation\nIncorrect\ninference\nAmbiguous\ntext\nError /\nHallucination\nError in GT\n# FP\nPhysicians gpt-3.5-turbo-1106 gpt-4-1106-preview\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nDifferences in\ncriteria\nExplicit\nomission\nOmission by\ncontext\nAmbiguous\ntext\nUnrecognized\nacronyms\nError in GT\n# FN\nPhysicians gpt-3.5-turbo-1106 gpt-4-1106-preview\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nthe smoker and ex -smoker categories, possibly due to the use of the label “toxic \nhabits,” even when referring to other habits like alcoholism. \nThe models, especially GPT-4, tend to infer comorbidities from the context or reported \nmedication more frequently than physicians, who exhibit a more conservative \napproach. This tendency leads to more false positives by the models, particularly when \nthe medication does not imply the presence of comorbidity. \nGPT-3.5 exhibited difficulties in interpreting common medical acronyms such as “DM” \nfor diabetes or “AF” for atrial fibrillation, whereas GPT -4 demonstrated a superior \nability to recognize and correctly interpret most of these acronyms. \nInterestingly, GPT-4 displayed some false positives when encountering comorbidity \nlabels followed by “:” without additional information, a misinterpretation not common in \nhumans but observed in AI, particularly in GPT-4 more than in GPT-3.5. \nHuman evaluators showed a greater tendency to overlook comorbidities explicitly \nreported, likely due to distraction or fatigue. \nOnly three errors were identified in the determination of the ground truth, underscoring \nthe reliability of the review process. \nFinally, we identified a category of discre pancies exclusive to the models, related to \nstructural or formatting errors. This includes situations where the models' responses \ndo not follow the guidelines specified in the prompt, resulting in outputs that do not \nmeet the expected JSON format or that i ncorrectly alter and/or introduce comorbidity \nlabels. Given that these incidents were limited, affecting less than 10 cases, it was \ndecided to manually correct these formatting errors for inclusion in the subsequent \nanalysis. \n \nDiscussion \nIt is important to highlight that\tthe categorization of observers as \"Physicians,\" \"GPT-\n3.5,\" and \"GPT-4\" in our results presentation actually reflects the synergy between the \nspecific models (gpt-3.5-turbo-1106 and gpt-4-1106-preview) and the prompt designed \nfor our study. The efficacy of the GPT models in generating responses is inherently \ntied to the quality and structure of the prompts provided, suggesting that results could \nvary significantly with  a redefinition of the prompt . Similarly, the performance o f \nphysicians in this study reflects not only their clinical competence but also the influence \nof the instructions they receive. Providing them with more detailed and specific \nguidelines might improve their responses. Thus, while our results offer valuable \ninsights into the ability of GPT models within our study context, they also indicate the \npotential for optimization through prompt refinement. \nThe superior sensitivity of GPT -4 is particularly noteworthy, indicating its advanced \ncapability to accurately id entify reported comorbidities, even when the information is \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nnot directly evident in the text. However, both GPT-3.5 and GPT-4 models generate a \ncomparable number of false positives, significantly higher than those recorded by \nphysicians. Physicians' false positives typically stem from specific circumstances, \nsuch as ambiguity in clinical reports , variations in interpretation among professionals  \nand, occasionally, inadvertent errors in the template filling process.  \nIn contrast, false positives from the GPT models seem to  arise from a less \nconservative approach in determining comorbidity presence based on inferred \ncontext. These cases are also more likely to generate less reproducible responses \ndue to the nondeterministic nature of LLMs. \nIt's worth noting tha t in these cases, the criterion adopted by physicians to establish \nthe Ground Truth favored the more conservative approach, considering only an \nunreported comorbidity when the medication or context necessarily implied such a \ncomorbidity. Whether this criterion is preferable to that shown by the GPT models can \nonly be determined through an analysis of the complete medical history confirming or \nrefuting the presence of the comorbidity. \nSuch discrepancies, stemming from variations in criteria interpretation, can be \nmitigated by employing prompts with clearer instructions on the interpretation of \ndifferent comorbidities. This emphasizes the importance of refining prompts to \nenhance the consistency and accuracy of LLM -generated responses in clini cal \ncontexts. \nDespite the remarkable capacity of current LLMs as potential tools for data mining in \nclinical reports, questions arise regarding the practical utility of this real-world data for \nuse in research and the generation of real -world evidence [13]. This is primarily due \nto the variability, subjectivity, and lack of structure in these reports, which can \ncompromise the quality and reliability of the extracted data, thereby affecting their \napplicability in clinical research contexts. \nTherefore, while LLMs represent a promising innovation to overcome the limitations of \nunstructured data, implementing more structured clinical recording practices could \nprovide a more sustainable and reliable solution for generating real -world clinical \nevidence. This duality underscores the need for a balanced approach that integrates \nthe advantages of advanced AI technology with good clinical data management \npractices. \nConclusions \nThis study has established that the OpenAI LLMs examined exhibit comparable, if not \nsuperior, competence to medical specialists in interpreting and extracting relevant \ninformation from clinical reports. Remarkably, the gpt-4-1106-preview model has \nshown significant superiority compared to both gpt-3.5-turbo-1106 and me dical \nevaluators across the metrics analyzed. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nWhen considering cost and processing time benefits in comparison to human \nintervention, the examined models present a notable advantage in both cost and time \nefficiency. This efficiency is evidenced not only by faster data processing but also by \nreduced associated operational expenses, providing an economically feasible solution \nfor large-scale clinical data analysis. \nAdditionally, the accessibility of these models via an API and their capability to deliver \nresults in a structured format (JSON) broaden their applicability in data mining. This \nfacilitates the processing of voluminous collections of clinical reports and enables their \ndirect integration with databases and other applications, thereby empowering research \nand healthcare management. \nIn conclusion, this study highlights the transformative potential of LLMs in the \nhealthcare sector, redefining methodologies for the extraction and analysis of clinical \ndata. Nonetheless, continuous evaluation of these models is essential to enhance their \naccuracy and applicability, while also emphasizing the importance of advancing \ntowards more structured clinical records. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nAuthors and collaborators \n• Study Idea and Design: Amadeo Wals Zurita and Héctor Miras del Rio \n• Data Collection: Carlos Míguez Sánchez, David Muñoz Carmona, María Rubio \nJiménez, Nerea Ugarte Ruiz de Aguirre, Cristina Nebrera Navarro. \n• Data Analysis: Héctor Miras del Rio and Amadeo Wals Zurita \n• Results Interpretation: Héctor Miras del Rio and Amadeo Wals Zurita \n• Manuscript Writing: Héctor Miras del Rio and Amadeo Wals Zurita \n• Critical Review and Editing: all authors \n• Final Approval: all authors \n• Data Anonymization and Randomization: Alberto Moreno Conde. Innovation & \nData Analysis Unit, Virgen Macarena University Hospital. \n \nConﬂict of Interest \nThe authors of this scientific work declare that there are no conflicts of interest that \ncould influence the results or conclusions of the conducted research. Furthermore, we \nemphasize that this study has not r eceived any external funding. Our research was \nconducted independently, with the primary purpose of contributing to the advancement \nof knowledge in the corresponding area. \n \nAbbreviations \ncNLP: clinical natural language processing \nEHR: electronic health record \nLLM: large language model \nJSON: JavaScript Object Notation \nAPI: application programming interface \nGPT: generative pre-trained transformers \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint \nReferences \n \n[1] W. Yim, M. Yetisgen, W. P. Harris, and S. W. Kwan, “Natural Language \nProcessing in Oncology: A Review,” JAMA Oncology, vol. 2, no. 6, pp. 797–804, \nJun. 2016, doi: 10.1001/jamaoncol.2016.0213. \n[2] G. K. Savova et al., “Use of Natural Language Processing to Extract Clinical \nCancer Phenotypes from Electronic Medical Records,” Cancer Research, vol. \n79, no. 21, pp. 5463–5470, Nov. 2019, doi: 10.1158/0008-5472.CAN-19-0579. \n[3] Z. Jie, Z. Zhiying, and L. Li, “A meta-analysis of Watson for Oncology in clinical \napplication,” Sci Rep, vol. 11, no. 1, Art. no. 1, Mar. 2021, doi: 10.1038/s41598-\n021-84973-5. \n[4] A. Vaswani et al., “Attention is All you Need,” in Advances in Neural Information \nProcessing Systems, Curran Associates, Inc., 2017. Accessed: Feb. 22, 2024. \n[Online]. Available: \nhttps://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1\nc4a845aa-Abstract.html \n[5] OpenAI et al., “GPT-4 Technical Report.” arXiv, Dec. 18, 2023. doi: \n10.48550/arXiv.2303.08774. \n[6] B. Ebrahimi, A. Howard, D. J. Carlson, and H. Al-Hallaq, “ChatGPT: Can a \nNatural Language Processing Tool Be Trusted for Radiation Oncology Use?,” \nInternational Journal of Radiation Oncology, Biology, Physics, vol. 116, no. 5, \npp. 977–983, Aug. 2023, doi: 10.1016/j.ijrobp.2023.03.075. \n[7] M. A. Fink et al., “Potential of ChatGPT and GPT-4 for Data Mining of Free-Text \nCT Reports on Lung Cancer,” Radiology, vol. 308, no. 3, p. e231362, Sep. \n2023, doi: 10.1148/radiol.231362. \n[8] H. S. Choi, J. Y. Song, K. H. Shin, J. H. Chang, and B.-S. Jang, “Developing \nprompts from large language model for extracting clinical information from \npathology and ultrasound reports in breast cancer,” Radiat Oncol J, vol. 41, no. \n3, pp. 209–216, Sep. 2023, doi: 10.3857/roj.2023.00633. \n[9] A. Bertolet, A. Wals, H. Miras, and J. Macías, “Organic generation of real-world \nreal-time data for clinical evidence in radiation oncology,” International Journal \nof Medical Informatics, vol. 144, p. 104301, Dec. 2020, doi: \n10.1016/j.ijmedinf.2020.104301. \n[10] “OpenAI Platform.” Accessed: Feb. 22, 2024. [Online]. Available: \nhttps://platform.openai.com \n[11] D. Hendrycks et al., “Measuring Massive Multitask Language Understanding.” \narXiv, Jan. 12, 2021. doi: 10.48550/arXiv.2009.03300. \n[12] RFMacarena, “RFMacarena/openaiAPIscript_forsharing.” Mar. 06, 2024. \nAccessed: Mar. 12, 2024. [Online]. Available: \nhttps://github.com/RFMacarena/openaiAPIscript_forsharing \n[13] R. Knevel and K. P. Liao, “From real-world electronic health record data to real-\nworld results using artificial intelligence,” Annals of the Rheumatic Diseases, \nvol. 82, no. 3, pp. 306–311, Mar. 2023, doi: 10.1136/ard-2022-222626. \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \nperpetuity. \n is the author/funder, who has granted medRxiv a license to display the preprint in(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted March 15, 2024. ; https://doi.org/10.1101/2024.03.07.24303588doi: medRxiv preprint ",
  "topic": "Transformative learning",
  "concepts": [
    {
      "name": "Transformative learning",
      "score": 0.8642600178718567
    },
    {
      "name": "Health records",
      "score": 0.5974594950675964
    },
    {
      "name": "Data science",
      "score": 0.4752197861671448
    },
    {
      "name": "Electronic health record",
      "score": 0.41120484471321106
    },
    {
      "name": "Business",
      "score": 0.38021427392959595
    },
    {
      "name": "Computer science",
      "score": 0.37198150157928467
    },
    {
      "name": "Political science",
      "score": 0.2412344515323639
    },
    {
      "name": "Psychology",
      "score": 0.23512330651283264
    },
    {
      "name": "Health care",
      "score": 0.17978298664093018
    },
    {
      "name": "Pedagogy",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210090436",
      "name": "Hospital Universitario Virgen Macarena",
      "country": "ES"
    }
  ],
  "cited_by": 2
}