{
  "title": "Can Large Language Models Revolutionalize Open Government Data Portals? A Case of Using ChatGPT in statistics.gov.scot",
  "url": "https://openalex.org/W4388267439",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2626480520",
      "name": "Marios Mamalis",
      "affiliations": [
        "University of Macedonia"
      ]
    },
    {
      "id": "https://openalex.org/A158436118",
      "name": "Evangelos Kalampokis",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2016295031",
      "name": "Areti Karamanou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4313607802",
      "name": "Petros Brimos",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2200655569",
      "name": "Konstantinos Tarabanis",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4353015365",
    "https://openalex.org/W3030163527",
    "https://openalex.org/W4383605161",
    "https://openalex.org/W2965260787",
    "https://openalex.org/W2523971795",
    "https://openalex.org/W2556419726",
    "https://openalex.org/W2901486005",
    "https://openalex.org/W4313451803",
    "https://openalex.org/W4386153961",
    "https://openalex.org/W4376865009",
    "https://openalex.org/W2134578292",
    "https://openalex.org/W3021533447",
    "https://openalex.org/W4319049323",
    "https://openalex.org/W4376653873",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4366735603",
    "https://openalex.org/W4377121531",
    "https://openalex.org/W3182737888",
    "https://openalex.org/W4386081135",
    "https://openalex.org/W4385570013",
    "https://openalex.org/W2924690340",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4322832290",
    "https://openalex.org/W4330337479",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W4389520455",
    "https://openalex.org/W3085139254",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4361866125",
    "https://openalex.org/W3126093591",
    "https://openalex.org/W4226069413",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W3173343821",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3030030185",
    "https://openalex.org/W4310510826"
  ],
  "abstract": "Large language models possess tremendous natural language understanding and generation abilities. However, they often lack the ability to discern between fact and fiction, leading to factually incorrect responses. Open Government Data are repositories of, often times linked, information that is freely available to everyone. By combining these two technologies in a proof of concept designed application utilizing the GPT3.5 OpenAI model and the Scottish open statistics portal, we show that not only is it possible to augment the large language model's factuality of responses, but also propose a novel way to effectively access and retrieve statistical information from the data portal just through natural language querying. We anticipate that this paper will trigger a discussion regarding the transformation of Open Government Portals through large language models.",
  "full_text": "Can Large Language Models Revolutionalize Open Government\nData Portals? A Case of Using ChatGPT in statistics.gov.scot\nMamalis, Marios∗\nbad22019@uom.edu.gr\nKalampokis, Evangelos∗\nekal@uom.edu.gr\nKaramanou, Areti∗\nakarm@uom.edu.gr\nBrimos, Petros∗\nbad21024@uom.edu.gr\nTarabanis, Konstantinos∗\nkat@uom.edu.gr\nAbstract\nLarge language models possess tremendous natural language understanding and generation\nabilities. However, they often lack the ability to discern between fact and fiction, leading to\nfactually incorrect responses. Open Government Data are repositories of, often times linked,\ninformation that is freely available to everyone. By combining these two technologies in a proof of\nconcept designed application utilizing the GPT3.5 OpenAI model and the Scottish open statistics\nportal, we show that not only is it possible to augment the large language model’s factuality of\nresponses, but also propose a novel way to effectively access and retrieve statistical information\nfrom the data portal just through natural language querying. We anticipate that this paper\nwill trigger a discussion regarding the transformation of Open Government Portals through large\nlanguage models.\nKeywords: large language model, open government data, linked data, natural language processing, chat-\ngpt\n1 Introduction\nThe emergence of large language models (LLM) has led to the development of novel approaches that aim to\nuncover information located within natural language data. Based on the ever evolving capacities of the models\nparticularly regarding the tasks of natural language understanding and generation, applications have been\ncreated that harness this ability, in a variety of fields like medicine [26, 14], education [13] and finance [34].\nHowever, the high performance of the LLMs in natural language generation tasks comes with the disadvantage\nof frequent alterations of factual knowledge [1].\nOpen Government Data (OGD), offer a way for information to be easily accessible to everyone. In particular,\nOGD published as linked data offer the added benefits of semantically structured information, allowing for\ncomplex queries and retrieval of factually correct and frequently updated information. By combining the natural\nlanguage understanding and generation capacities of LLM with the widely available information contained\nwithin OGD through techniques such as Retrieval Augmented Generation, a system could overcome the LLM’s\ninability to retain factual information while at the same time offer an easier way to access and retrieve OGD.\nThe objective of this paper is to explore the potential and challenges of transforming OGD portals through\nLLM. Towards this end, we focus on a single case and we implement a proof of concept application that\nis sufficiently capable in formulating answers enhanced by knowledge retrieved through linked OGD. The\napplication employs ChatGPT API in order to enable interacting with the Scottish open statistics portal\nthrough natural language questions.\nThe rest of this paper is structured as follows. Section 2 provides backround knowledge regarding (Linked)\nOGD and LLM. In section 3 our research approach is described, while section 3 presents the proof of concept\napplication of the ChatGPT enhanced OGD portal along with an initial evaluation’s results. Discussion and\nconclusions, including future work, are presented in section 5.\n∗University of Macedonia, Department of Business Administration, Egnatia 156, 54636, Thessaloniki, Greece\n1\n2 Background\n2.1 Linked Open Statistical data\nOpen Government Data (OGD) are published by the public sector in order to be freely accessible by the public.\nThey are a political priority the last decade in many countries in order to enhance evidence-based policy making\nand stimulate economic growth. OGD are published in the official data portals of governments (e.g., the official\nportal for European data1). A large part of OGD are statistical consisting of highly structured numeric data [11]\nand commonly regard aggregated demographical, social, and business indicators across countries. Statistical\ndata are multidimensional, meaning that a measure is described based on multiple of dimensions.\nIn order to unleash the full potential of OGD, a large number of official OGD portals are publishing OGD as\nlinked data. Linked data has been introduced as a proper technological paradigm for opening up data because\nit facilitates the integration of data and facilitate performing data analytics on top of integrated but previously\nisolated statistical data coming from various sources across the Web [10, 20]. Linked data are based on the\nSemantic Web philosophy and technologies and are mainly about publishing structured data using the W3C\nResource Description Framework (RDF) standard. The QB vocabulary [6] is a W3C standard that uses the\nlinked data principles to publish statistical data on the Web. It models statistical data as data cubes, which\ncomprise a set of dimensions that define what the observations of the dataset apply to (e.g., reference area,\ntime), measures (qb:MeasureProperty) that represent the phenomenon which is being observed, and attributes\n(qb:AttributeProperty) that are used to represent structural metadata such as the unit of measurement.\nThis work uses Linked OGD from the Scottish open statistics portal 2. The portal currently hosts more\nthan 250 linked datasets covering various societal and business aspects of Scotland classified into 18 themes.\nDatasets are provided at different levels of spatial granularity in Scotland starting from the level of postcodes\nto the level of council areas. Users can navigate through the data portal to view and retrieve data as tables,\nmaps, and charts or download them in various formats (e.g., html, json, csv), or, alternatively, retrieve them\nas linked data by submitting flexible queries to the SPARQL endpoint 3 released by the portal.\n2.2 Large language models\nLarge language models or LLMs for short and henceforth, are artificial intelligence models used for natural\nlanguage tasks, trained on massive datasets. Ever since the invention of the revolutionary transformer archi-\ntecture [7, 28], and the attention mechanism [32], LLMs have advanced at a tremendous speed. The creation\nof models with the ability to capture contextual information regardless of orientation has been a game changer\nin terms of model performance, allowing for the creation of systems reliant on their capacities. LLMs can\nperform various tasks, from simple text classification [8] and named entity recognition [18] to summarization\n[16] and translation [38]. However, the largest potential of LLMs stems from their ability to understand [5]\nand generate human-like texts, enabling countless applications.\nLLMs with such capacities are becoming more and more available to the public. Amongst these models\nare the GPT [37] LLM family (GPT-1 [23], GPT-2 [24], GPT-3 and GPT-3.5 [35], GPT-4 [19]) released by\nOpenAI, the Llama LLM family (Llama [30] and Llama2 [31]) released by Meta, Google’s BARD that is based\non LaMDA [29] and many more. Such massively pre-trained models, nowadays widely available, either through\nAPIs or locally hosted solutions, offer new ways to manipulate natural language textual information.\n2.2.1 Instruction learning\nThe massive potential of LLMs, mentioned previously, stems from the generative models’ ability to adapt to a\nwide range of natural language tasks that they did not initially train on through instruction and example based\nlearning that often rivals fine tuning approaches [3]. Specifically, it is shown that in-context instruction learning\ncan not only boost the zero-shot task generalization performance of pretrained but also of instruction-fine-tuned\nmodels [36].\nThrough instruction and example based learning, conversational LLMs are taught how to perform new,\nunseen tasks as humans would. By understanding the new natural language task presented in a descriptive\nmanner, the LLM is usually able to accomplice it with high performance. Examples of such human-oriented\ninstruction [17] applications include but are not limited to summarization [2], text classification [27] and\nnamed entity recognition [33]; tasks that were previously performed by dedicated models specifically trained\nor fine-tuned for such purposes.\n1https://data.europa.eu/en\n2https://statistics.gov.scot/\n3https://statistics.gov.scot/sparql\n2\n2.2.2 Retrieval Augmented Generation\nEven though LLMs hold considerable amounts of world knowledge, thanks to their initial training [22], they\nstill lack the ability to be factually correct in all their responses, which often results in ”hallucinations” [40]:\nfactually incorrect responses presented by the LLM as correct ones.\nIn generative LLMs, the technique of Retrieval Augmented Generation (RAG) is used to supply external\ncontext into the model’s input [15] with the goal of augmenting its output quality in terms of factuality. More\nspecifically, the original input is used to retrieve context based on a criterion, usually embedding similarity,\nfrom a pool of available factually correct and externally provided texts. After the relevant text or texts are\nretrieved, they are added to the initial query as context and the augmented prompt is supplied to the generator.\nContext is shown to have advantageous effects on the generated outputs’ factuality [21] if it is carefully chosen.\nIn the opposite scenario, where the context is not fitting, it may lead to worse performance [25], so the selection\nof the context is of critical importance.\n3 Research Approach\nOur case study revolved around the creation of an application where a generative LLM would quasi-autonomously\ninteract with the SPARQL endpoint of the Scottish statistical data portal to provide a way for end users to\nquery statistical information with natural language instead of SPARQL queries. The designed application\ntakes advantage of instruction and example based learning to have the LLM create queries and structure text\nwhere needed.\nThe Scottish statistical government portal contains 293 datasets as of the 25/Sep/2023, with their contents\nvarying in topic and detail, covering different aspects of Scotland. The portal also offers a SPARQL API\nendpoint that allows querying of information in the SPARQL query language. The accessible datasets vary in\nmeasures and dimensions, making their querying a non easily automated task that requires time and effort.\nHowever the portal offers a robust way to retrieve information that is both up to date and accurate.\nOur study utilizes the gpt-3.5-turbo-0613 and gpt-3.5-turbo-16k-0613 large language models, offered through\nthe OpenAI API, as conversational agents. The LLMs support different maximum input token sizes, with the\nlarger model being used when the context is expected to exceed the limit of the smallest model. The models\nare selected for their extensive ability to adapt to different tasks through instruction learning [39], making\nthem ideal for this application.\nThe OpenAI embedding API is also used to encode text into a latent space representation in order to\nenable functionalities such as vector store retrieval, used in retrieval augmented generation. The embedding\nmodel is the text-embedding-ada-002. By using both OpenAI embeddings and OpenAI LLMs we ensure that\nthe application will rely on similar mechanisms of language understanding and generation.\nFor the evaluation of the designed application, the SPARQL datasets used for testing are selected specifically\nfor their properties. More precisely, each of them adhere to the constraint of having dimensions with codelists\ncontaining relatively few members as to be able to be passed to the LLM for filtering without surpassing the\ntoken limit. Regarding the test questions that are asked of the application to process, they are formulated\nin a way that the answer will be a single value and thus all dataset dimensions will be used in creating the\nanswering SPARQL query. The single value returned must also not be a product of aggregation operations or\na result of calculations between different datasets. This is done intentionally as the application implemented,\nlacks autonomy in favor of reproducibility.\nThe datasets used for testing are three: ¡http://statistics.gov.scot/data/hmo-licences¿, described as the\nnumber of houses in multiple occupation (HMO) licences in force at 31 of March, ¡http://statistics.gov.scot/data/vacant-\nderelict-land¿, that is the area of derelict and urban vacant land in hectares, and ¡http://statistics.gov.scot/data/exports¿,\nwhere information is contained about Scottish international exports and Scottish exports to the rest of the\nUK broken down by industry sector. The questions asked are specific to each dataset. The questions are\nformulated as follows:\n• How many HMO licences were in force in Dundee City in 2014?\n• How much vacant urban land was there in East Ayrshire in 2007?\n• What was the count of international exports in 2002 in Scotland for education?\n, for the three datasets, respectively.\n4 ChatGPT enhanced Open Government Data Portal\n4.1 Architecture\nThe designed application consists of seven components. Firstly, the prompt creator component is responsible for\nall operations involving the creation, modification, or augmentation of the prompts that would later be supplied\n3\nto the large language model (LLM). Such prompts include instructions passed to the LLM, data retrieved, or a\ncombination of the two. The embedding generator component handles the encoding of text into the embedding\nspace for the purpose of calculation of the semantic similarity between texts. In our case, the input questions\nof the users as well as text describing the available datasets are being encoded into the embedding space.\nMoreover, the embedding generator used is the text-embedding-ada-002 model, accessed through the OpenAI\nAPI. The vector database, handles the storage of the created embeddings in vector format, in cases where\npersistence is needed. In particular, the implementation of retrieval systems reliant on previously accessed\ndata, not available in real-time, utilizes this component. In our case, the embeddings of the descriptions of\nthe available datasets are stored in the vector database. The vector database employed in our study is a\nChromaDB vector store. The retriever component is used in cases where similarity between embeddings needs\nto be calculated. In our case it is used in tandem with the vector database and the embedding generator to\nretrieve texts that are the most similar to each other. The similarity metric used is the cosine distance of the\ntwo vectors, shown below.\nCosineDistance(θ) = 1 − A · B\n∥A∥2 ∥B∥2\n, where A and B two vectors in the embedding space, and θ the angle between them.\nThe SPARQL endpoint, part of the Scottish open statistics portal, offers linked statistical data used in this\nstudy. It accepts queries made in the SPARQL query language, and returns data in a tabular format. Lastly,\nthe generative LLM performs a multitude of actions, including executing natural language based structuring\nthrough instructions, SPARQL query creation, and replying to the user. We employ the gpt-3.5-turbo-0613\nand gpt-3.5-turbo-16k-0613 large language models for these purposes, used through the OpenAI API. The\ninternal components and external components used in the application mentioned above are presented with\ntheir interactions in figure 1.\nFigure 1: Components of the designed application and their interactions\nThe connections between the components can be summarized as follows: The user provides the initial\nnatural language question as input, and the LLM is responsible for fetching the needed information from the\nSPARQL endpoint by creating a series of SPARQL queries, until finally replying to the user in a factually\ncorrect response. In order for this to be practically possible, the supportive components are employed. The\nretrieval of information can either be based on a combination of a vector database with a retriever, or an LLM\nand the SPARQL endpoint. The former combination is used when the data is too large to fit in the context\nwindow of the LLM (e.g., dataset information). However having such a system with practically no limit in the\namount of candidate information, comes at the cost of relying in the less effective way of embedding similarity\ncompared to natural language understanding. In the second case, the LLM performs tasks like query creation,\nexecution, and interpretation of fetched results. The SPARQL endpoint is used throughout the process to\nsupply information that is not available inside the user query, but is still necessary for the creation of the final\nSPARQL query (e.g., available dimensions and measures for a given dataset).\nSince all necessary information cannot be collected all at once, the application performs iterations where\ninformation is retrieved and then filtered. These cycles lead to a gradual ”distillation” of information resulting\nin all necessary data being present without redundancy. The collected and filtered information is then passed\nto the generative LLM with instructions to make a SPARQL query that answers the original question, utilizing\nthe filtered information. After the successful retrieval of the results of the SPARQL endpoint, the LLM is\ncalled once again, in the context of the original conversation with the user, to present the results in a human\n4\nunderstandable way.\n4.2 Design and development\nIn order to create a conversational LLM application that will be able to be used as the connecting link between\nuser and data, we follow the architecture shown in figure 2. Essentially, in the implemented solution, the\nexisting SPARQL endpoint and the generative LLM work synergetically, as described in the section above.\nThe architecture implemented, showcases applications both of embedding similarity based and LLM struc-\nturing based information retrieval that will be utilized by the SPARQL endpoint. Before the user’s input,\nall relevant dataset information was manually collected and encoded through the OpenAI embedding API.\nThe embeddings were calculated for the concatenation of the datasets’ names and descriptions. The resulting\nembeddings were stored in a ChromaDB vector store along with their metadata. In this case the metadata set\nwere information about the datasets’ URIs, titles and descriptions.\nFigure 2: Implementation of the proposed application\nThe application is structured in a way that no intermediate inputs from the user are required during\nthe entire process. The initial user’s input is encoded through the OpenAI embedding API, and is used to\nperformed a cosine distance based search against the vector database in order to retrieve the relevant dataset’s\nURI. This is then used in a SPARQL query in order to get all of the dataset’s measures and dimensions.\nThe generative LLM is subsequently employed to filter out the unnecessary properties in relation to the user’s\nquestion, through instructions that also specify the way in which the returned information will be structured.\nFor each dimension that is deemed necessary for the creation of the final SPARQL query, the respective codelist\nis retrieved through SPARQL queries and the LLM, given the appropriate instructions, narrows the selection\nof possible values for each dimension.\nThe information retrieved in every step of the process (e.g. dataset, measures and dimensions, codelists) is\niteratively added to a provided initial prompt. The initial prompt is formulated as instructions for the creation\n5\nof the final SPARQL query, by means of replacing values in a given SPARQL template. The replacement process\nis enhanced by providing as context the retrieved information. The result will be the final prompt, passed\nto the conversational LLM in order to create the SPARQL query that will return the statistical information\nrequested by the user. After the query to the SPARQL endpoint and the retrieval of its response, the LLM\nwill be tasked to structure the information received in a human understandable way and present it to the user\nin continuation of the inital conversation. The gpt-3.5-turbo-0613 model is used in all cases except for the\ncreation of the final SPARQL query, where the gpt-3.5-turbo-16k-0613 model is employed.\n4.3 Evaluation\nThe questions asked, proved to be indicative of the designed application’s function. Each of the answers re-\nturned by the application where manually checked and verified to be factually correct. The results of the\nquestions are presented below:\nQ1: How many HMO licences were in force in Dundee City in 2014?\nA1: In 2014, there were a total of 1,577 HMO licences in force in Dundee City.\nQ2: How much vacant urban land was there in East Ayrshire in 2007?\nA2: In 2007, there were 37 units of vacant urban land in East Ayrshire.\nQ3: What was the count of international exports in 2002 in Scotland for education?\nA3: In 2002, Scotland had a remarkable count of 170 international exports in the field of education. This\nsignifies the significant global recognition and demand for Scottish educational expertise and resources.\nAs it can be seen, the resulting LLM outputs are not only verifiably factually correct, but also conveyed\nto the user in a straightforward manner that enhances understanding.\nRegarding the specifics of the RAG process, we noticed that all retrievals performed both through the\nvector store regarding the dataset URIs as well as through the SPARQL endpoint, whose results were later\nfiltered by the generative LLM, were not only successful, but managed to provide the necessary context to the\nmodel for creation of the final SPARQL query. This further proved that both approaches were applicable to\nour case, and while each had its distinct advantages and disadvantages, their capabilities proved sufficient for\nthe task at hand.\n5 Discussion and Conclusions\nIn this study we design an application that functions as the connective link between user and open government\ndata portals. The proposed application accepts queries in natural language regarding the contents of the data\nportals and through a series of retrievals, leads to the offering of a factually correct answer, also written in\nnatural language, to the user that requests it. The applications for such ana application are massive, since a\ngeneralized application of this kind would eliminate barriers that currently practically restrict access to users\nwith no technical knowledge from accessing available information. In essence this could be considered as a\nconcept working towards the goal of democratization of information, all the while maintaining a high standard\nin terms of accessed data quality.\nOur specific implementation of the proposed model led to the creation of a proof of concept application\nthat performs adequately when presented with unseen data. The implemented application relies on numerous\niterations of information retrievals through a variety of retrieval systems such as SPARQL APIs and vector\nstores, followed by LLM-based structuring and filtering of the information retrieved with the final goal of\ncreating a prompt that will be accepted by the Scottish statistical data portal, and more specifically by the\nSPARQL API exposed. The returned data, enables the creation of answers written in natural language, that\nproved to be factually correct and at the same time presented in an understandable and intuitive way, allowing\nfor a direct communication between users and the statistical portal.\nIt is important to note in our implemented proof of concept application we relied on the GPT-3.5 con-\nversational LLM and the text-embedding-ada-002 embedding model, that are both developed and offered by\nOpenAI. Even though the model’s natural language understanding and generating capacities are considered\nto be state-of-the-art, it is necessary to mention that the need for open source models in applications that\ninvolve and rely on governmental statistical information, like the one presented in this case, is essential. This\ndue to the fact that open source, locally hosted models, promote privacy, transparency and trustworthiness;\nall necessary qualities in governmental applications.\nAnother important aspect that our implementation revealed through its limitations is the need for a robust\nframework concerning linked open statistical data. In previous years there have been effort to bring forth\nthe problems that arise from the insufficient interoperability present in currently created ontologies [9], and\neven though efforts have been made to tackle existing shortcomings [12], the landscape still seems immature,\nespecially if we are to consider the possibility for large scale applications that rely on such systems.\n6\nFinally, as part of considered future work in extension of the current effort, we focus on the generalization of\nthe implemented proof of concept application. More specifically, future efforts are to include a comprehensive\nlarge scale evaluation of the LLM in the same task, thus providing quantitative measures for the assessment of\nthe application, something whose importance has been highlighted recently [4]. Regarding the generalization\nof the application itself, it is expected that newer models will be more flexible in terms of the data that the will\nbe able to operate upon, something of critical importance if we are to build a fully autonomous application for\nthe retrieval of information from linked open statistical data portals.\nReferences\n[1] Razvan Azamfirei, Sapna R Kudchadkar, and James Fackler. Large language models and the perils of\ntheir hallucinations. Critical Care, 27(1):1–2, 2023.\n[2] Adithya Bhaskar, Alexander R Fabbri, and Greg Durrett. Zero-shot opinion summarization with gpt-3.\narXiv preprint arXiv:2211.15914, 2022.\n[3] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language\nmodels are few-shot learners, 2020.\n[4] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,\nCunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie.\nA survey on evaluation of large language models, 2023.\n[5] Xuanting Chen, Junjie Ye, Can Zu, Nuo Xu, Rui Zheng, Minlong Peng, Jie Zhou, Tao Gui, Qi Zhang, and\nXuanjing Huang. How robust is gpt-3.5 to predecessors? a comprehensive study on language understanding\ntasks. arXiv preprint arXiv:2303.00293, 2023.\n[6] R Cyganiak and D Reynolds. The RDF data cube vocabulary: W3C recommendation. W3C Tech. Rep.,\n2014.\n[7] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n[8] Santiago Gonz´ alez-Carvajal and Eduardo C Garrido-Merch´ an. Comparing bert against traditional machine\nlearning text classification. arXiv preprint arXiv:2005.13012, 2020.\n[9] Evangelos Kalampokis, Areti Karamanou, and Konstantinos Tarabanis. Interoperability conflicts in linked\nopen statistical data. Information, 10(8), 2019.\n[10] Evangelos Kalampokis, Efthimios Tambouris, and Konstantinos Tarabanis. Linked Open Cube Analytics\nSystems: Potential and Challenges. IEEE Intelligent Systems, 31(5):89–92, 2016.\n[11] Evangelos Kalampokis, Efthimios Tambouris, and Konstantinos Tarabanis. ICT tools for creating, ex-\npanding and exploiting statistical linked Open Data. Statistical Journal of the IAOS, 33:503–514, 2017.\n2.\n[12] Evangelos Kalampokis, Dimitris Zeginis, and Konstantinos Tarabanis. On modeling linked open statistical\ndata. Journal of Web Semantics, 55:56–68, 2019.\n[13] Tiffany H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepa˜ no,\nMaria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, et al. Performance of chatgpt\non usmle: Potential for ai-assisted medical education using large language models. PLoS digital health,\n2(2):e0000198, 2023.\n[14] Alexandros Laios, Georgios Theophilou, Diederick De Jong, and Evangelos Kalampokis. The future of ai in\novarian cancer research: The large language models perspective. Cancer Control, 30:10732748231197915,\n2023. PMID: 37624621.\n[15] Huayang Li, Yixuan Su, Deng Cai, Yan Wang, and Lemao Liu. A survey on retrieval-augmented text\ngeneration. arXiv preprint arXiv:2202.01110, 2022.\n[16] Yang Liu. Fine-tune bert for extractive summarization, 2019.\n[17] Renze Lou, Kai Zhang, and Wenpeng Yin. Is prompt all you need? no. a comprehensive and broader\nview of instruction learning, 2023.\n[18] Rahul Mehta and Vasudeva Varma. Llm-rm at semeval-2023 task 2: Multilingual complex ner using\nxlm-roberta, 2023.\n7\n[19] OpenAI. Gpt-4 technical report, 2023.\n[20] Juan Manuel Perez Martinez, Rafael Berlanga, Maria Jose Aramburu, and Torben Bach Pedersen. In-\ntegrating Data Warehouses with Web Data: A Survey. IEEE Transactions on Knowledge and Data\nEngineering, 20(7):940–955, 2008.\n[21] Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rockt¨ aschel, Yuxiang Wu, Alexander H. Miller,\nand Sebastian Riedel. How context affects language models’ factual predictions, 2020.\n[22] Fabio Petroni, Tim Rockt¨ aschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and\nSebastian Riedel. Language models as knowledge bases? arXiv preprint arXiv:1909.01066, 2019.\n[23] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understand-\ning by generative pre-training. 2018.\n[24] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\nmodels are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n[25] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H. Chi, Nathanael Sch¨ arli,\nand Denny Zhou. Large language models can be easily distracted by irrelevant context. In Andreas\nKrause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett,\neditors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings\nof Machine Learning Research, pages 31210–31227. PMLR, 23–29 Jul 2023.\n[26] Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales,\nAjay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge.\narXiv preprint arXiv:2212.13138, 2022.\n[27] Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, and Guoyin Wang. Text\nclassification via large language models, 2023.\n[28] Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. Efficient transformers: A survey.(2020).\narXiv preprint cs.LG/2009.06732, 2020.\n[29] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin\nGhafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen,\nYuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching\nChang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-\nHellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben\nZevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina,\nErin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya\nKuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui,\nMarian Croak, Ed Chi, and Quoc Le. Lamda: Language models for dialog applications, 2022.\n[30] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth´ ee\nLacroix, Baptiste Rozi` ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin,\nEdouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models, 2023.\n[31] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh\nKoura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao,\nXavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy\nReizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Sub-\nramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned\nchat models, 2023.\n[32] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  Lukasz\nKaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems,\n30, 2017.\n[33] Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin\nWang. Gpt-ner: Named entity recognition via large language models, 2023.\n[34] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan\nKambadur, David Rosenberg, and Gideon Mann. Bloomberggpt: A large language model for finance.\narXiv preprint arXiv:2303.17564, 2023.\n8\n[35] Junjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai Shao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao\nGong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui, Qi Zhang, and Xuanjing Huang. A comprehensive\ncapability analysis of gpt-3 and gpt-3.5 series models, 2023.\n[36] Seonghyeon Ye, Hyeonbin Hwang, Sohee Yang, Hyeongu Yun, Yireun Kim, and Minjoon Seo. In-context\ninstruction learning, 2023.\n[37] Gokul Yenduri, Ramalingam M, Chemmalar Selvi G, Supriya Y, Gautam Srivastava, Praveen Ku-\nmar Reddy Maddikunta, Deepti Raj G, Rutvij H Jhaveri, Prabadevi B, Weizheng Wang, Athanasios V.\nVasilakos, and Thippa Reddy Gadekallu. Generative pre-trained transformer: A comprehensive review on\nenabling technologies, potential applications, emerging challenges, and future directions, 2023.\n[38] Zhebin Zhang, Sai Wu, Dawei Jiang, and Gang Chen. Bert-jam: Maximizing the utilization of bert for\nneural machine translation. Neurocomputing, 460:84–94, 2021.\n[39] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. Expel: Llm\nagents are experiential learners, 2023.\n[40] Chunting Zhou, Graham Neubig, Jiatao Gu, Mona Diab, Paco Guzman, Luke Zettlemoyer, and Marjan\nGhazvininejad. Detecting hallucinated content in conditional neural sequence generation. arXiv preprint\narXiv:2011.02593, 2020.\n9",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7708332538604736
    },
    {
      "name": "Government (linguistics)",
      "score": 0.7203986048698425
    },
    {
      "name": "Open data",
      "score": 0.6626996994018555
    },
    {
      "name": "Open government",
      "score": 0.6456509232521057
    },
    {
      "name": "Natural language",
      "score": 0.5484541058540344
    },
    {
      "name": "Language model",
      "score": 0.5081593990325928
    },
    {
      "name": "Open source",
      "score": 0.47847720980644226
    },
    {
      "name": "Data science",
      "score": 0.44899433851242065
    },
    {
      "name": "World Wide Web",
      "score": 0.4098399877548218
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3639248013496399
    },
    {
      "name": "Programming language",
      "score": 0.14433565735816956
    },
    {
      "name": "Linguistics",
      "score": 0.13122138381004333
    },
    {
      "name": "Software",
      "score": 0.09541106224060059
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I192756129",
      "name": "University of Macedonia",
      "country": "GR"
    }
  ]
}