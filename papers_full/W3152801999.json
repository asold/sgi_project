{
  "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering",
  "url": "https://openalex.org/W3152801999",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4202208022",
      "name": "Yasunaga, Michihiro",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2361153460",
      "name": "Ren, Hongyu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4227134328",
      "name": "Bosselut, Antoine",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3166964279",
      "name": "Liang, Percy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2750049651",
      "name": "Leskovec Jure",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2963380480",
    "https://openalex.org/W2911489562",
    "https://openalex.org/W3151929433",
    "https://openalex.org/W1815076433",
    "https://openalex.org/W3174660442",
    "https://openalex.org/W2890961898",
    "https://openalex.org/W2994695355",
    "https://openalex.org/W2971155257",
    "https://openalex.org/W3006500814",
    "https://openalex.org/W2890431379",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W3162922479",
    "https://openalex.org/W2767891136",
    "https://openalex.org/W2890894339",
    "https://openalex.org/W2950339735",
    "https://openalex.org/W2511149293",
    "https://openalex.org/W2964144561",
    "https://openalex.org/W2892280852",
    "https://openalex.org/W2094728533",
    "https://openalex.org/W2892094955",
    "https://openalex.org/W2987669390",
    "https://openalex.org/W2983995706",
    "https://openalex.org/W2971869958",
    "https://openalex.org/W3094459920",
    "https://openalex.org/W2604314403",
    "https://openalex.org/W3036267641",
    "https://openalex.org/W2964207259",
    "https://openalex.org/W1852412531",
    "https://openalex.org/W2998374885",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3004630545",
    "https://openalex.org/W2572289264",
    "https://openalex.org/W2926937441",
    "https://openalex.org/W1836465849",
    "https://openalex.org/W2963339397",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W3097986428",
    "https://openalex.org/W3082274269",
    "https://openalex.org/W3094258447",
    "https://openalex.org/W2951561177",
    "https://openalex.org/W2972260442",
    "https://openalex.org/W2963895422",
    "https://openalex.org/W2963829073",
    "https://openalex.org/W3099655892",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2963858333",
    "https://openalex.org/W2968908603",
    "https://openalex.org/W2911966030",
    "https://openalex.org/W3104150569",
    "https://openalex.org/W2985925969",
    "https://openalex.org/W3015440086",
    "https://openalex.org/W2994689640",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2889787757",
    "https://openalex.org/W2963995027",
    "https://openalex.org/W2250635077",
    "https://openalex.org/W2159583324",
    "https://openalex.org/W3034995113",
    "https://openalex.org/W2252136820",
    "https://openalex.org/W3023160663",
    "https://openalex.org/W2950576363",
    "https://openalex.org/W2963907629"
  ],
  "abstract": "The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. In this work, we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph neural networks. We evaluate our model on QA benchmarks in the commonsense (CommonsenseQA, OpenBookQA) and biomedical (MedQA-USMLE) domains. QA-GNN outperforms existing LM and LM+KG models, and exhibits capabilities to perform interpretable and structured reasoning, e.g., correctly handling negation in questions.",
  "full_text": "QA-GNN: Reasoning with Language Models and Knowledge Graphs\nfor Question Answering\nMichihiro Yasunaga, Hongyu Ren, Antoine Bosselut\nPercy Liang, Jure Leskovec\nStanford University\n{myasu,hyren,antoineb,pliang,jure}@cs.stanford.edu\nAbstract\nThe problem of answering questions using\nknowledge from pre-trained language models\n(LMs) and knowledge graphs (KGs) presents\ntwo challenges: given a QA context (question\nand answer choice), methods need to (i)\nidentify relevant knowledge from large KGs,\nand (ii) perform joint reasoning over the QA\ncontext and KG. In this work, we propose a\nnew model, QA-GNN, which addresses the\nabove challenges through two key innovations:\n(i) relevance scoring, where we use LMs to\nestimate the importance of KG nodes relative to\nthe given QA context, and (ii) joint reasoning,\nwhere we connect the QA context and KG to\nform a joint graph, and mutually update their\nrepresentations through graph neural networks.\nWe evaluate our model on QA benchmarks in\nthe commonsense (CommonsenseQA, Open-\nBookQA) and biomedical (MedQA-USMLE)\ndomains. QA-GNN outperforms existing LM\nand LM+KG models, and exhibits capabilities\nto perform interpretable and structured reason-\ning, e.g., correctly handling negation in ques-\ntions. Our code and data are available athttps:\n//github.com/michiyasunaga/qagnn.\n1 Introduction\nQuestion answering systems must be able to access\nrelevant knowledge and reason over it. Typically,\nknowledge can be implicitly encoded in large\nlanguage models (LMs) pre-trained on unstructured\ntext (Petroni et al., 2019; Bosselut et al., 2019), or ex-\nplicitly represented in structured knowledge graphs\n(KGs), such as Freebase (Bollacker et al., 2008)\nand ConceptNet (Speer et al., 2017), where entities\nare represented as nodes and relations between\nthem as edges. Recently, pre-trained LMs have\ndemonstrated remarkable success in many question\nanswering tasks (Liu et al., 2019; Raffel et al.,\n2020). However, while LMs have a broad coverage\nof knowledge, they do not empirically perform well\non structured reasoning ( e.g., handling negation)\n(Kassner and Schütze, 2020). On the other hand,\nKGs are more suited for structured reasoning (Ren\net al., 2020; Ren and Leskovec, 2020) and enable\nIf it is not used for hair, a round brush is an example of what? \nA. hair brush    B. bathroom    C. art supplies*   \nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nhairbrush\nRelatedTo\nAtLocation\nUsedFor UsedFor\nChoiceEntity\nAnswer\nQuestionEntity\nQA context\nKnowledge graph\nartsupply\nQA context Node\nhair\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes74.11\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final) 76.54\nRelevance scoring (§3.2)Dev Acc. \nNothing 75.15\nw/ contextual embedding76.31\nw/ relevance score (final) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3)Dev Acc. \nNode type, relation, score-aware (final) 76.54\n- type-aware 75.11\n- relation-aware 75.23\n- score-aware 75.15\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final) 76.54\nL = 6 76.21\nL = 7 75.96\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes 74.81\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final system) 76.54\nContextualization (§3.2) Dev Acc. \nNo contextualization 75.56\nw/ contextual embedding 76.31\nw/ relevance score (final system) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3) Dev Acc. \nNode type, relation, score-aware (final system) 76.54\n- type-aware 75.41\n- relation-aware 75.61\n- score-aware 75.56\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final system) 76.54\nL = 6 76.21\nL = 7 75.96\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes74.81\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final) 76.54\nRelevance scoring (§3.2)Dev Acc. \nNothing 75.56\nw/ contextual embedding76.31\nw/ relevance score (final) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3)Dev Acc. \nNode type, relation, score-aware (final) 76.54\n- type-aware 75.41\n- relation-aware 75.61\n- score-aware 75.56\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final) 76.54\nL = 6 76.21\nL = 7 75.96\nIf it is not used for hair, a round brush is an example of what? \nA. hair brush    B. bathroom    C. art supplies*   \nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nhairbrush\nRelatedTo\nAtLocation\nUsedFor UsedFor\nChoiceEntity\nAnswer\nQuestionEntity\nQA context\nKnowledge graph\nartsupply\nQA context Node\nhair\nFigure 1: Given the QA context (question and answer\nchoice; purple box), we aim to derive the answer by\nperforming joint reasoning over the language and the\nknowledge graph (green box).\nexplainable predictionse.g., by providing reasoning\npaths (Lin et al., 2019), but may lack coverage and\nbe noisy (Bordes et al., 2013; Guu et al., 2015).\nHow to reason effectively with both sources of\nknowledge remains an important open problem.\nCombining LMs and KGs for reasoning (hence-\nforth, LM+KG) presents two challenges: given\na QA context (e.g., question and answer choices;\nFigure 1 purple box), methods need to (i) identify\ninformative knowledge from a large KG (green\nbox); and (ii) capture the nuance of the QA context\nand the structure of the KGs to perform joint\nreasoning over these two sources of information.\nPrevious works (Bao et al., 2016; Sun et al., 2018;\nLin et al., 2019) retrieve a subgraph from the KG\nby taking topic entities (KG entities mentioned in\nthe given QA context) and their few-hop neighbors.\nHowever, this introduces many entity nodes that\nare semantically irrelevant to the QA context,\nespecially when the number of topic entities or hops\nincreases. Additionally, existing LM+KG methods\nfor reasoning (Lin et al., 2019; Wang et al., 2019a;\nFeng et al., 2020; Lv et al., 2020) treat the QA\ncontext and KG as two separate modalities. They\narXiv:2104.06378v5  [cs.CL]  13 Dec 2022\nIf it is not used for hair, a round brush is an \nexample of what? \nA. hair brush    B. bathroom    C. art supplies*   \nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nhairbrush\nRelatedTo\nAtLocation\nUsedFor UsedFor\nChoiceEntity\nAnswer\nQuestionEntity\nLanguage Context\nKnowledge Graph\nartsupply\nContextNode\nhair\nMLP\nContextualGNN\nPlausibility Score\nTextEncodere.g. LM\nKGRetrieval\nLanguage Context\n[q; a] \nPooling(§3)\nZ Z\nIf it is not used for hair, a round brush is an example of what? \nA. hair brush    B. bathroom    C. art supplies*   \nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nhairbrush\nRelatedTo\nAtLocation\nUsedFor UsedFor\nChoiceEntity\nAnswer\nQuestionEntity\nLanguage Context\nKnowledge Graph\nartsupply\nContextNode\nhair\nMLP\nQA-GNN\nProbability score\nLM Encoding\nKGRetrieval\nQA context\n[q; a] \nPooling\nZ Z\nReasoning (§3.3)\nRelevance Scoring (§3.2)\nJoint Graph (§3.1)\nIf it is not used for hair, a round brush\nA. hair brush    B. bathroom    C. art supplies\nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nRelatedTo\nAtLocation\nUsedFor\nQuestionEntity\nLanguage Context\nKnowledge Graph\nContextNode\nhair\nFigure 2: Overview of our approach. Given a QA context ( z), we connect it with the retrieved KG to form a joint\ngraph (working graph; §3.1), compute the relevance of each KG node conditioned onz(§3.2; node shading indicates\nthe relevance score), and perform reasoning on the working graph (§3.3).\nindividually apply LMs to the QA context and graph\nneural networks (GNNs) to the KG, and do not\nmutually update or unify their representations. This\nseparation might limit their capability to perform\nstructured reasoning, e.g., handling negation.\nHere we propose QA-GNN, an end-to-end\nLM+KG model for question answering that\naddresses the above two challenges. We ﬁrst encode\nthe QA context using an LM, and retrieve a KG\nsubgraph following prior works (Feng et al., 2020).\nOur QA-GNN has two key insights: (i)Relevance\nscoring: Since the KG subgraph consists of all\nfew-hop neighbors of the topic entities, some entity\nnodes are more relevant than others with respect to\nthe given QA context. We hence propose KG node\nrelevance scoring: we score each entity on the KG\nsubgraph by concatenating the entity with the QA\ncontext and calculating the likelihood using a pre-\ntrained LM. This presents a general framework to\nweight information on the KG; (ii)Joint reasoning:\nWe design a joint graph representation of the QA\ncontext and KG, where we explicitly view the QA\ncontext as an additional node (QA context node) and\nconnect it to the topic entities in the KG subgraph\nas shown in Figure 1. This joint graph, which we\nterm the working graph, uniﬁes the two modalities\ninto one graph. We then augment the feature of\neach node with the relevance score, and design a\nnew attention-based GNN module for reasoning.\nOur joint reasoning algorithm on the working graph\nsimultaneously updates the representation of both\nthe KG entities and the QA context node, bridging\nthe gap between the two sources of information.\nWe evaluate QA-GNN on three question answer-\ning datasets that require reasoning with knowledge:\nCommonsenseQA (Talmor et al., 2019) andOpen-\nBookQA (Mihaylov et al., 2018) in the common-\nsense domain (using the ConceptNet KG), and\nMedQA-USMLE (Jin et al., 2021) in the biomedical\ndomain (using the UMLS and DrugBank KGs). QA-\nGNN outperforms strong ﬁne-tuned LM baselines\nas well as the existing best LM+KG model (with the\nsame LM) by 4.7% and 2.3% respectively. In par-\nticular, QA-GNN exhibits improved performance\non some forms of structured reasoning ( e.g., cor-\nrectly handling negation and entity substitution in\nquestions): it achieves 4.6% improvement over ﬁne-\ntuned LMs on questions with negation, while exist-\ning LM+KG models are +0.6% over ﬁne-tuned LMs.\nWe also show that one can extract reasoning pro-\ncesses from QA-GNN in the form of general KG sub-\ngraphs, not just paths (Lin et al., 2019), suggesting\na general method for explaining model predictions.\n2 Problem statement\nWe aim to answer natural language questions using\nknowledge from a pre-trained LM and a structured\nKG. We use the term language model broadly to be\nany composition of two functions, fhead(fenc(x)),\nwhere fenc, the encoder, maps a textual inputx to a\ncontextualized vector representationhLM, and fhead\nuses this representation to perform a desired task\n(which we discuss in §3.2). In this work, we speciﬁ-\ncally use masked language models (e.g., RoBERTa)\nas fenc, and let hLM denote the output representa-\ntion of a[CLS] token that is prepended to the input\nsequence x, unless otherwise noted. We deﬁne the\nknowledge graph as a multi-relational graph G=\n(V,E). Here Vis the set of entity nodes in the KG;\nE⊆V×R×V is the set of edges that connect nodes\nin V, where Rrepresents a set of relation types.\nGiven a question qand an answer choice a∈C,\nwe follow prior work (Lin et al., 2019) to link the en-\ntities mentioned in the question and answer choice\nto the given KGG. We denote Vq⊆Vand Va⊆V\nas the set of KG entities mentioned in the question\n(question entities; blue entities in Figure1) and an-\nswer choice (answer choice entities; red entities in\nFigure1), respectively, and useVq,a:=Vq∪Vato de-\nnote all the entities that appear in either the question\nor answer choice, which we calltopic entities. We\nthen extract a subgraph fromGfor a question-choice\npair, Gq,a\nsub = ( Vq,a\nsub ,Eq,a\nsub ),1 which comprises all\nnodes on thek-hop paths between nodes inVq,a.\n1We remove the superscriptq,a if there is no ambiguity.\nQA Context\nRetrieved KG\ntravel\ndoor\nsecurity\ngo\nrun\nhuman\nlock\nplace\nholiday\nclose\nsafe\nmoney\nrobber\nbank\nbankholiday\nriverbank\nA revolving door is convenient for two direction travel, \nbut also serves as a security measure at what?\nA. bank*      B. library          C. department store \nD. mall          E. new york \nKG node scored\nLanguage \nModel Relevance ( entity | QA context )\ntravel\ndoor\nsecurity\ngo\nrun\nhuman\nlock\nplace\nholiday\nclose\nsafe\nmoney\nrobber\nbank\nbankholiday\nriverbank\n entity \nSome entities are more relevant than others given the context.Entity relevance estimated. Darker color indicates higher score.\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes 74.11\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final system) 76.54\nContextualization (§3.2) Dev Acc. \nNo contextualization 75.15\nw/ contextual embedding 76.31\nw/ relevance score (final system) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3) Dev Acc. \nNode type, relation, score-aware (final system) 76.54\n- type-aware 75.11\n- relation-aware 75.23\n- score-aware 75.15\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final system) 76.54\nL = 6 76.21\nL = 7 75.96\nInference (§3.4) Dev Acc. \nFinal states of Z and KG (final system) 76.54\n- Z 74.91\n- KG 75.15\nFigure 3: Relevance scoring of the retrieved KG: we use a pre-trained LM to calculate the relevance of each KG\nentity node conditioned on the QA context (§3.2).\n3 Approach: QA-GNN\nAs shown in Figure 2, given a question and an\nanswer choice a, we concatenate them to get theQA\ncontext [q; a]. To reason over a given QA context\nusing knowledge from both the LM and the KG,\nQA-GNN works as follows. First, we use the LM\nto obtain a representation for the QA context, and\nretrieve the subgraph Gsub from the KG. Then we\nintroduce a QA context node zthat represents the\nQA context, and connectzto the topic entitiesVq,a\nso that we have a joint graph over the two sources\nof knowledge, which we term the working graph,\nGW (§3.1). To adaptively capture the relationship\nbetween the QA context node and each of the other\nnodes inGW, we calculate a relevance score for each\npair using the LM, and use this score as an additional\nfeature for each node (§3.2). We then propose\nan attention-based GNN module that performs\nmessage passing on the GW for multiple rounds\n(§3.3). We make the ﬁnal prediction using the LM\nrepresentation, QA context node representation and\na pooled working graph representation (§3.4).\nWe also discuss the computational complexity of\nour model (§3.5), and why our model uses a GNN\nfor question answering tasks (§3.6).\n3.1 Joint graph representation\nTo design a joint reasoning space for the two sources\nof knowledge, we explicitly connect them in a\ncommon graph structure. We introduce a new QA\ncontext node z which represents the QA context,\nand connect zto each topic entity inVq,a on the KG\nsubgraph Gsub using two new relation typesrz,q and\nrz,a. These relation types capture the relationship\nbetween the QA context and the relevant entities\nin the KG, depending on whether the entity is found\nin the question portion or the answer portion of\nthe QA context. Since this joint graph intuitively\nprovides a reasoning space (working memory) over\nthe QA context and KG, we term itworking graph\nGW = (VW,EW), where VW = Vsub ∪{z}and EW =\nEsub ∪{(z,rz,q,v)|v∈Vq}∪{(z,rz,a,v)|v∈Va}.\nEach node inGW is associated with one of the four\ntypes: T={Z,Q,A,O}, each indicating the context\nnode z, nodes inVq, nodes inVa, and other nodes, re-\nspectively (corresponding to the node color,purple,\nblue, red, gray in Figure1 and 2). We denote the\ntext of the context nodez(QA context) and KG node\nv∈Vsub (entity name) astext(z) and text(v).\nWe initialize the node embedding of z by the\nLM representation of the QA context ( zLM =\nfenc(text(z))), and each node onGsub by its entity\nembedding (§4.2). In the subsequent sections, we\nwill reason over the working graph to score a given\n(question, answer choice) pair.\n3.2 KG node relevance scoring\nMany nodes on the KG subgraph Gsub (i.e., those\nheuristically retrieved from the KG) can be irrel-\nevant under the current QA context. As an example\nshown in Figure 3, the retrieved KG subgraphGsub\nwith few-hop neighbors of the Vq,a may include\nnodes that are uninformative for the reasoning\nprocess, e.g., nodes “holiday” and “river bank” are\noff-topic; “human” and “place” are generic. These\nirrelevant nodes may result in overﬁtting or intro-\nduce unnecessary difﬁculty in reasoning, an issue\nespecially when Vq,a is large. For instance, we em-\npirically ﬁnd that using theConceptNet KG (Speer\net al., 2017), we will retrieve a KG with|Vsub|>400\nnodes on average if we consider 3-hop neighbors.\nIn response, we propose node relevance scoring,\nwhere we use the pre-trained language model to\nscore the relevance of each KG node v ∈Vsub\nconditioned on the QA context. For each nodev, we\nconcatenate the entitytext(v) with the QA context\ntext(z) and compute therelevance score:\nρv=fhead(fenc([text(z); text(v)])), (1)\nwhere fhead ◦fenc denotes the probability oftext(v)\ncomputed by the LM. This relevance score ρv\ncaptures the importance of each KG node relative to\nthe given QA context, which is used for reasoning\nor pruning the working graphGW.\n3.3 GNN architecture\nTo perform reasoning on the working graphGW, our\nGNN module builds on the graph attention frame-\nwork (GAT) (Veliˇckovi´c et al., 2018), which induces\nnode representations via iterative message passing\nbetween neighbors on the graph. Speciﬁcally, in\na L-layer QA-GNN, for each layer, we update the\nrepresentation h(ℓ)\nt ∈RD of each nodet∈VW by\nh(ℓ+1)\nt =fn\n( ∑\ns∈Nt∪{t}\nαstmst\n)\n+h(ℓ)\nt , (2)\nwhere Nt represents the neighborhood of node t,\nmst∈RD denotes the message from each neighbor\nnode sto t, and αstis an attention weight that scales\neach message mst from s to t. The sum of the\nmessages is then passed through a 2-layer MLP,\nfn: RD →RD, with batch normalization (Ioffe\nand Szegedy, 2015). For each nodet∈VW, we set\nh(0)\nt using a linear transformationfh that maps its\ninitial node embedding (described in §3.1) toRD.\nCrucially, as our GNN message passing operates\non the working graph, it will jointly leverage and\nupdate the representation of the QA context and KG.\nWe further propose an expressive message (mst)\nand attention (αst) computation below.\nNode type & relation-aware message. As GW\nis a multi-relational graph, the message passed from\na source node to the target node should capture\ntheir relationship, i.e., relation type of the edge and\nsource/target node types. To this end, we ﬁrst obtain\nthe type embedding ut of each node t, as well as\nthe relation embeddingrstfrom node sto node tby\nut=fu(ut), rst=fr(est,us,ut), (3)\nwhere us,ut∈{0,1}|T |are one-hot vectors indicat-\ning the node types of sand t, est ∈{0,1}|R| is a\none-hot vector indicating the relation type of edge\n(s,t), fu: R|T |→RD/2 is a linear transformation,\nand fr: R|R|+2|T |→RD is a 2-layer MLP. We then\ncompute the message fromsto tas\nmst=fm(h(ℓ)\ns ,us,rst), (4)\nwhere fm: R2.5D→RD is a linear transformation.\nNode type, relation, and score-aware attention.\nAttention captures the strength of association be-\ntween two nodes, which is ideally informed by their\nnode types, relations and node relevance scores.\nWe ﬁrst embed the relevance score of each nodetby\nρt=fρ(ρt), (5)\nwhere fρ: R →RD/2 is an MLP. To compute the\nattention weight αst from node s to node t, we\nobtain the query and key vectorsq, kby\nqs=fq(h(ℓ)\ns ,us,ρs), (6)\nkt=fk(h(ℓ)\nt ,ut,ρt,rst), (7)\nwhere fq: R2D→RD and fk: R3D→RD are linear\ntransformations. The attention weight is then\nαst= exp(γst)∑\nt′∈Ns∪{s}exp(γst′ ), γst= q⊤\ns kt√\nD\n. (8)\n3.4 Inference & Learning\nGiven a question q and an answer choice a, we\nuse the information from both the QA context\nand the KG to calculate the probability of it being\nthe answer p(a|q) ∝exp(MLP(zLM, zGNN, g)),\nwhere zGNN = h(L)\nz and gdenotes the pooling of\n{h(L)\nv |v∈Vsub}. In the training data, each question\nhas a set of answer choices with one correct choice.\nWe optimize the model (both the LM and GNN com-\nponents end-to-end) using the cross entropy loss.\n3.5 Computation complexity\nWe analyze the time and space complexity of our\nmodel and compare with prior works, KagNet (Lin\net al., 2019) and MHGRN (Feng et al., 2020) in Ta-\nble 1. As we handle edges of different relation types\nusing different edge embeddings instead of design-\ning an independent graph networks for each relation\nas in RGCN (Schlichtkrull et al., 2018) or MHGRN,\nthe time complexity of our method is constant with\nrespect to the number of relations and linear with re-\nspect to the number of nodes. We achieve the same\nspace complexity as MHGRN (Feng et al., 2020).\n3.6 Why GNN for question answering?\nWe provide more discussion on why we use a GNN\nfor solving question answering and reasoning tasks.\nRecent work shows that GNNs are effective for\nmodeling various graph algorithms (Xu et al., 2020).\nExamples of graph algorithms include knowledge\ngraph reasoning, such as execution of logical queries\non a KG (Gentner, 1983; Ren and Leskovec, 2020):\nV?.∃V : Located(Europe,V)\n∧¬Held(World Cup,V)∧President(V,V?)\nModel Time Space\nGis a dense graph\nL-hop KagNet O(|R|L|V|L+1L)O(|R|L|V|L+1L)\nL-hop MHGRN O(|R|2|V|2L) O(|R||V|L)\nL-layer QA-GNN O(|V|2L) O(|R||V|L)\nGis a sparse graph with maximum node degree∆≪|V|\nL-hop KagNet O(|R|L|V|L∆L)O(|R|L|V|L∆L)\nL-hop MHGRN O(|R|2|V|L∆) O(|R||V|L)\nL-layer QA-GNN O(|V|L∆) O(|R||V|L)\nTable 1: Computation complexity of different L-hop\nreasoning models on a dense / sparse graph G= (V,E)\nwith the relation setR.\n(“Who are the presents of European countries\nthat have not held the World Cup?”)\nViewing such logical queries as input “questions”,\nwe conducted a pilot study where we apply QA-\nGNN to learn the task of executing logical queries on\na KG—including complex queries that contain nega-\ntion or multi-hop relations about entities. In this task,\nwe ﬁnd that QA-GNN signiﬁcantly outperforms a\nbaseline model that only uses an LM but not a GNN:\nMethods Hit@3 on FB15k\nLM-only 15\nQA-GNN (Ours) 40\nTable 2: Performace in learning to answer complex\nlogical queries on a KG.\nThe result conﬁrms that GNNs are indeed useful for\nmodeling complex query answering. This provides\nan intuition that QA-GNN can be useful for answer-\ning complex natural language questions too, which\ncould be viewed as executing soft queries—natural\nlanguage instead of logical—using a KG.\nFrom this “KG query execution” intuition, we\nmay also draw an interpretation that the KG and\nGNN can provide ascaffold for the model to reason\nabout entities mentioned in the question. We further\nanalyze this idea in §4.6.3.\n4 Experiments\n4.1 Datasets\nWe evaluate QA-GNN on three question answer-\ning datasets: CommonsenseQA (Talmor et al.,\n2019), OpenBookQA (Mihaylov et al., 2018), and\nMedQA-USMLE (Jin et al., 2021).\nCommonsenseQA is a 5-way multiple choice QA\ntask that requires reasoning with commonsense\nknowledge, containing 12,102 questions. The test\nset of CommonsenseQA is not publicly available,\nand model predictions can only be evaluated once\nevery two weeks via the ofﬁcial leaderboard. Hence,\nwe perform main experiments on the in-house (IH)\ndata splits used in Lin et al. (2019), and also report\nthe score of our ﬁnal system on the ofﬁcial test set.\nOpenBookQA is a 4-way multiple choice QA\ntask that requires reasoning with elementary science\nknowledge, containing 5,957 questions. We use the\nofﬁcial data splits from Mihaylov and Frank (2018).\nMedQA-USMLE is a 4-way multiple choice QA\ntask that requires biomedical and clinical knowl-\nedge. The questions are originally from practice\ntests for the United States Medical License Exams\n(USMLE). The dataset contains 12,723 questions.\nWe use the original data splits from Jin et al. (2021).\n4.2 Knowledge graphs\nFor CommonsenseQA and OpenBookQA, we use\nConceptNet (Speer et al., 2017), a general-domain\nknowledge graph, as our structured knowledge\nsource G. It has 799,273 nodes and 2,487,810\nedges in total. Node embeddings are initialized\nusing the entity embeddings prepared by Feng\net al. (2020), which applies pre-trained LMs to all\ntriples in ConceptNet and then obtains a pooled\nrepresentation for each entity.\nFor MedQA-USMLE, we use a self-constructed\nknowledge graph that integrates the Disease\nDatabase portion of the Uniﬁed Medical Language\nSystem (UMLS; Bodenreider, 2004) and DrugBank\n(Wishart et al., 2018). The knowledge graph\ncontains 9,958 nodes and 44,561 edges. Node\nembeddings are initialized using the pooled\nrepresentations of the entity name from SapBERT\n(Liu et al., 2020a).\nGiven each QA context (question and answer\nchoice), we retrieve the subgraph Gsub from Gfol-\nlowing the pre-processing step described in Feng\net al. (2020), with hop sizek=2. We then pruneGsub\nto keep the top 200 nodes according to the node rel-\nevance score computed in §3.2. Henceforth, in this\nsection (§4) we use the term “KG” to refer toGsub.\n4.3 Implementation & training details\nWe set the dimension ( D = 200) and number of\nlayers (L= 5) of our GNN module, with dropout\nrate 0.2 applied to each layer (Srivastava et al.,\n2014). We train the model with the RAdam (Liu\net al., 2020b) optimizer using two GPUs (GeForce\nRTX 2080 Ti), which takes∼20 hours. We set the\nbatch size from {32, 64, 128, 256}, learning rate for\nthe LM module from {5e-6, 1e-5, 2e-5, 3e-5, 5e-5},\nand learning rate for the GNN module from {2e-4,\n5e-4, 1e-3, 2e-3}. The above hyperparameters are\ntuned on the development set.\nMethods IHdev-Acc. (%) IHtest-Acc.(%)\nRoBERTa-large (w/o KG) 73.07 (±0.45) 68.69 (±0.56)\n+ RGCN(Schlichtkrull et al., 2018)72.69 (±0.19) 68.41 (±0.66)\n+ GconAttn(Wang et al., 2019a)72.61(±0.39) 68.59 (±0.96)\n+ KagNet(Lin et al., 2019)73.47 (±0.22) 69.01 (±0.76)\n+ RN(Santoro et al., 2017)74.57 (±0.91) 69.08 (±0.21)\n+ MHGRN(Feng et al., 2020)74.45 (±0.10) 71.11 (±0.81)\n+ QA-GNN (Ours) 76.54(±0.21) 73.41(±0.92)\nTable 3: Performance comparison on Commonsense\nQA in-house split (controlled experiments). As the\nofﬁcial test is hidden, here we report the in-house Dev\n(IHdev) and Test (IHtest) accuracy, following the data\nsplit of Lin et al. (2019).\n4.4 Baselines\nFine-tuned LM. To study the role of KGs, we\ncompare with a vanilla ﬁne-tuned LM, which does\nnot use the KG. We use RoBERTa-large (Liu et al.,\n2019) for CommonsenseQA, and RoBERTa-large\nand AristoRoBERTa2 (Clark et al., 2019) forOpen-\nBookQA. ForMedQA-USMLE, we use a state-of-the-\nart biomedical LM, SapBERT (Liu et al., 2020a).\nExisting LM+KG models. We compare with\nexisting LM+KG methods, which share the same\nhigh-level framework as ours but use different mod-\nules to reason on the KG in place of QA-GNN (“yel-\nlow box” in Figure2): (1) Relation Network (RN)\n(Santoro et al., 2017), (2) RGCN (Schlichtkrull\net al., 2018), (3) GconAttn (Wang et al., 2019a), (4)\nKagNet (Lin et al., 2019), and (5) MHGRN (Feng\net al., 2020). (1),(2),(3) are relation-aware GNNs\nfor KGs, and (4),(5) further model paths in KGs.\nMHGRN is the existing top performance model\nunder this LM+KG framework. For fair comparison,\nwe use the same LM in all the baselines and our\nmodel. The key differences between QA-GNN and\nthese are that they do not perform relevance scoring\nor joint updates with the QA context (§3).\n4.5 Main results\nTable 3 and Table 5 show the results on Common-\nsenseQA and OpenBookQA, respectively. On\nboth datasets, we observe consistent improvements\nover ﬁne-tuned LMs and existing LM+KG models,\ne.g., on CommonsenseQA, +4.7% over RoBERTa,\nand +2.3% over the prior best LM+KG system,\nMHGRN. The boost over MHGRN suggests that\nQA-GNN makes a better use of KGs to perform\njoint reasoning than existing LM+KG methods.\nWe also achieve competitive results to other\nsystems on the ofﬁcial leaderboards (Table 4 and 6).\n2OpenBookQA provides an extra corpus of scientiﬁc facts\nin a textual form. AristoRoBERTa uses the facts corresponding\nto each question, prepared by Clark et al. (2019), as an\nadditional input to the QA context.\nMethods Test\nRoBERTa (Liu et al., 2019) 72.1\nRoBERTa+FreeLB (Zhu et al., 2020) (ensemble) 73.1\nRoBERTa+HyKAS (Ma et al., 2019) 73.2\nRoBERTa+KE (ensemble) 73.3\nRoBERTa+KEDGN (ensemble) 74.4\nXLNet+GraphReason (Lv et al., 2020) 75.3\nRoBERTa+MHGRN (Feng et al., 2020) 75.4\nAlbert+PG (Wang et al., 2020b) 75.6\nAlbert (Lan et al., 2020) (ensemble) 76.5\nUniﬁedQA* (Khashabi et al., 2020) 79.1\nRoBERTa + QA-GNN (Ours) 76.1\nTable 4: Test accuracy onCommonsenseQA’s ofﬁcial\nleaderboard. The top system, UniﬁedQA (11B\nparameters) is 30x larger than our model.\nMethods RoBERTa-large AristoRoBERTa\nFine-tuned LMs (w/o KG) 64.80 (±2.37) 78.40 (±1.64)\n+ RGCN 62.45 ( ±1.57) 74.60 (±2.53)\n+ GconAtten 64.75 ( ±1.48) 71.80 (±1.21)\n+ RN 65.20 ( ±1.18) 75.35 (±1.39)\n+ MHGRN 66.85 ( ±1.19) 80.6\n+ QA-GNN (Ours) 67.80(±2.75) 82.77(±1.56)\nTable 5: Test accuracy comparison on OpenBook\nQA (controlled experiments). Methods with Aris-\ntoRoBERTa use the textual evidence by Clark et al.\n(2019) as an additional input to the QA context.\nMethods Test\nCareful Selection (Banerjee et al., 2019) 72.0\nAristoRoBERTa 77.8\nKF + SIR (Banerjee and Baral, 2020) 80.0\nAristoRoBERTa + PG (Wang et al., 2020b) 80.2\nAristoRoBERTa + MHGRN (Feng et al., 2020) 80.6\nAlbert + KB 81.0\nT5* (Raffel et al., 2020) 83.2\nUniﬁedQA* (Khashabi et al., 2020) 87.2\nAristoRoBERTa + QA-GNN (Ours) 82.8\nTable 6: Test accuracy onOpenBookQA leaderboard.\nAll listed methods use the provided science facts as\nan additional input to the language context. The top 2\nsystems, UniﬁedQA (11B params) and T5 (3B params)\nare 30x and 8x larger than our model.\nNotably, the top two systems, T5 (Raffel et al., 2020)\nand UniﬁedQA (Khashabi et al., 2020), are trained\nwith more data and use 8x to 30x more parameters\nthan our model (ours has ∼360M parameters).\nExcluding these and ensemble systems, our model\nis comparable in size and amount of data to other\nsystems, and achieves the top performance on the\ntwo datasets.\nTable 7 shows the result on MedQA-USMLE.\nQA-GNN outperforms state-of-the-art ﬁne-tuned\nLMs (e.g., SapBERT). This result suggests that our\nmethod is an effective augmentation of LMs and\nKGs across different domains (i.e., the biomedical\ndomain besides the commonsense domain).\nMethods Test\nBERT-base(Devlin et al., 2019)34.3\nBioBERT-base(Lee et al., 2020)34.1\nRoBERTa-large(Liu et al., 2019)35.0\nBioBERT-large(Lee et al., 2020)36.7\nSapBERT(Liu et al., 2020a) 37.2\nSapBERT + QA-GNN (Ours) 38.0\nTable 7: Test accuracy onMedQA-USMLE.\nIf it is not used for hair, a round brush is an example of what? \nA. hair brush    B. bathroom    C. art supplies*   \nD. shower          E. hair salon\npainting\nAtLocation\nroundbrush\nhairbrush\nRelatedTo\nAtLocation\nUsedFor UsedFor\nChoiceEntity\nAnswer\nQuestionEntity\nQA context\nKnowledge graph\nartsupply\nQA context Node\nhair\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes74.11\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final) 76.54\nRelevance scoring (§3.2)Dev Acc. \nNothing 75.15\nw/ contextual embedding76.31\nw/ relevance score (final) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3)Dev Acc. \nNode type, relation, score-aware (final) 76.54\n- type-aware 75.11\n- relation-aware 75.23\n- score-aware 75.15\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final) 76.54\nL = 6 76.21\nL = 7 75.96\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes 74.81\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final system) 76.54\nContextualization (§3.2) Dev Acc. \nNo contextualization 75.56\nw/ contextual embedding 76.31\nw/ relevance score (final system) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3) Dev Acc. \nNode type, relation, score-aware (final system) 76.54\n- type-aware 75.41\n- relation-aware 75.61\n- score-aware 75.56\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final system) 76.54\nL = 6 76.21\nL = 7 75.96\nGraph Connection (§3.1) Dev Acc. \nNo edge between Z and KG nodes74.81\nConnect Z to all KG nodes 76.38\nConnect Z to QA entity nodes (final) 76.54\nRelevance scoring (§3.2)Dev Acc. \nNothing 75.56\nw/ contextual embedding76.31\nw/ relevance score (final) 76.54\nw/ both 76.52\nGNN Attention & Message (§3.3)Dev Acc. \nNode type, relation, score-aware (final) 76.54\n- type-aware 75.41\n- relation-aware 75.61\n- score-aware 75.56\nGNN Layers (§3.3)Dev Acc. \nL = 3 75.53\nL = 4 76.34\nL = 5  (final) 76.54\nL = 6 76.21\nL = 7 75.96\nTable 8: Ablation study of our model components,\nusing the CommonsenseQA IHdev set.\n4.6 Analysis\n4.6.1 Ablation studies\nTable 8 summarizes the ablation study conducted\non each of our model components (§3.1, §3.2, §3.3),\nusing the CommonsenseQA IHdev set.\nGraph connection (top left table): The ﬁrst key\ncomponent of QA-GNN is the joint graph that con-\nnects the znode (QA context) to QA entity nodes\nVq,a in the KG (§3.1). Without these edges, the\nQA context and KG cannot mutually update their\nrepresentations, hurting the performance: 76.5%\n→74.8%, which is close to the previous LM+KG\nsystem, MHGRN. If we connectedzto all the nodes\nin the KG (not just QA entities), the performance\nis comparable or drops slightly (-0.16%).\nKG node relevance scoring (top right table): We\nﬁnd the relevance scoring of KG nodes (§3.2)\nprovides a boost: 75.56% →76.54%. As a\nvariant of the relevance scoring in Eq. 1, we\nalso experimented with obtaining a contextual\nembedding wv for each nodev∈Vsub and adding to\nthe node features: wv= fenc([text(z); text(v)]).\nHowever, we ﬁnd that it does not perform as well\n(76.31%), and using both the relevance score and\ncontextual embedding performs on par with using\nthe score alone, suggesting that the score has a\nsufﬁcient information in our tasks; hence, our ﬁnal\nsystem simply uses the relevance score.\nGNN architecture (bottom tables): We ablate the\ninformation of node type, relation, and relevance\nscore from the attention and message computation\nin the GNN (§3.3). The results suggest that all\nthese features improve the model performance. For\nthe number of GNN layers, we ﬁnd L= 5 works\nWhere would you find a basement that can be accessed with an elevator?     \nA. closet   B. church   C. office building*\nZ\n. . \n. . \n. . \nAtLocation\nAtLocation\nRelatedTo\nPartOf\nPartOf\nIsA-1\nRelatedTo\nCrabs live in what sort of environment?   \nA. saltwater*  B. galapagos   C. fish market\nelevator\nbasement\nbuilding\nhouse\ncargo\nofficebuilding\nchurch\nZ\nZ\ncrab salt_water\nsea\nsalt\nocean\nsolution\nfreshwater\nshellcrustacean\nkingcrab\nZ\nAtLocation\nRelatedTo\nHas\nIsA\nTypeOf\n-1 AtLocation\nAtLocation\nAtLocation\n-1\nTypeOf\nAntonym\n(a)  Attention visualization direction: BFS from Q\n(b)  Attention visualization direction: Q → O and A → O\nFigure 4: Interpreting QA-GNN’s reasoning process\nby analyzing the node-to-node attention weights\ninduced by the GNN. Darker and thicker edges indicate\nhigher attention weights.\nthe best on the dev set. Our intuition is that 5\nlayers allow various message passing or reasoning\npatterns between the QA context (z) and KG, such\nas “z→3 hops on KG nodes→z”.\n4.6.2 Model interpretability\nWe aim to interpret QA-GNN’s reasoning process\nby analyzing the node-to-node attention weights\ninduced by the GNN. Figure 4 shows two examples.\nIn (a), we perform Best First Search (BFS) on the\nworking graph to trace high attention weights from\nthe QA context node (Z; purple) toQuestion entity\nnodes (blue) to Other (gray) or Answer choice\nentity nodes (orange), which reveals that the QA\ncontext zattends to “elevator” and “basement” in\nthe KG, “elevator” and “basement” both attend\nstrongly to “building”, and “building” attends to\n“ofﬁce building”, which is our ﬁnal answer. In (b),\nwe use BFS to trace attention weights from two\ndirections: Z →Q →O and Z →A →O, which\nreveals concepts (“sea” and “ocean”) in the KG that\nare not necessarily mentioned in the QA context but\nbridge the reasoning between the question entity\n(“crab”) and answer choice entity (“salt water”).\nWhile prior KG reasoning models (Lin et al., 2019;\nFeng et al., 2020) enumerate individual paths in\nthe KG for model interpretation, QA-GNN is not\nspeciﬁc to paths, and helps to ﬁnd more general\nreasoning structures ( e.g., a KG subgraph with\nmultiple anchor nodes as in example (a)).\nIf it is not used for hair, a round brush is an example of what?  \nA. hair brush  B. art supplies*\nIf it is used for hair, a round brush is an example \nof what?    A. hair brush  B. art supplies\nGNN Final Layer\nartsupplyroundbrush\nhairbrush\nNegation Flipped \nZ\npaintingpainting\nartsupply\nGNN 1st Layer GNN Final Layer\nhair\nroundbrush\nhairbrush\nartsupplyroundbrush\nhairbrush\nZ Z\npainting\nOur GNN Prediction\nA. hair brush (#2) \nB. art supplies (#1) \nRoBERTa Prediction\nA. hair brush (#1) \nB. art supplies (#2) \nOur GNN Prediction\nA. hair brush (#1) \nB. art supplies (#2) \nRoBERTa Prediction\nA. hair brush (#1) \nB. art supplies (#2) \nOriginal Question\nIf it is not used for art, a round brush is an \nexample of what?    A. hair brush   B. art supplies\nGNN Final Layer\nartsupply\nart\nroundbrush\nhairbrush\nEntity Changed (hair → art)  \nZ\npainting\nOur GNN Prediction\nA. hair brush (#1) \nB. art supplies (#2) \nRoBERTa Prediction\nA. hair brush (#1) \nB. art supplies (#2) \nhair hair\nIf it is not used for hair, a round brush is an example of what?  \nA. hair brush  B. art supply*\nIf it is used for hair, a round brush is an example \nof what?    A. hair brush  B. art supply\nGNN Final Layer\nartsupplyroundbrush\nhairbrush\n(a) Negation Flipped \npaintingpainting\nartsupply\nGNN 1st Layer GNN Final Layer\nhair\nroundbrush\nhairbrush\nartsupplyroundbrush\nhairbrush\npainting\nModel Prediction\nA. hair brush    (0.38) \nB. art supply  (0.64) \nOriginal Question\nIf it is not used for art, a round brush is an \nexample of what?    A. hair brush   B. art supply\nGNN Final Layer\nartsupply\nart\nroundbrush\nhairbrush\n(b) Entity Changed (hair → art)  \npainting\nhair hair\nModel Prediction\nA. hair brush   (0.81) \nB. art supply     (0.19) \nModel Prediction\nA. hair brush   (0.72) \nB. art supply     (0.28) \nExample  (Original taken from CommonsenseQA Dev) RoBERTa Prediction Our Prediction\n[Original]  If it is not used for hair, a round brush is an example of what?   \n                                            A. hair brush   B. art supply A. hair brush (✗) B. art supply (✓)\n[Negation flip]  If it is used for hair, a round brush is an example of what?  A. hair brush (✓ just no change?) A. hair brush (✓)\n[Entity change]  If it is not used for  art  a round brush is an example of what?   A. hair brush (✓ just no change?) A. hair brush (✓)\n[Original]  If you have to read a book that is very dry you may become what?  \n                                            A. interested   B. bored B. bored (✓) B. bored (✓)\n[Negation ver 1]  If you have to read a book that is very dry you may not become what? B. bored (✗) A. interested (✓)\n[Negation ver 2]  If you have to read a book that is not dry you may become what? B. bored (✗) A. interested (✓)\n[Double negation]  If you have to read a book that is not dry you may not become what? B. bored (✓ just no change?) A. interested (✗)\nExample  (Original taken from CommonsenseQA Dev) RoBERTa Prediction Our Prediction\n[Original]  If it is not used for hair, a round brush is an example of what?   \n                                            A. hair brush   B. art supply A. hair brush (✗) B. art supply (✓)\n[Negation flip]  If it is used for hair, a round brush is an example of what?  A. hair brush (✓ just no change?) A. hair brush (✓)\n[Entity change]  If it is not used for  art  a round brush is an example of what?   A. hair brush (✓ just no change?) A. hair brush (✓)\n[Original]  If you have to read a book that is very dry you may become what?  \n                                            A. interested   B. bored B. bored (✓) B. bored (✓)\n[Negation ver 1]  If you have to read a book that is very dry you may not become what? B. bored (✗) A. interested (✓)\n[Negation ver 2]  If you have to read a book that is not dry you may become what? B. bored (✗) A. interested (✓)\n[Double negation]  If you have to read a book that is not dry you may not become what? B. bored (✓ just no change?) A. interested (✗)\nZ ZZZ\nFigure 5: Analysis of QA-GNN’s behavior for structured reasoning. Given an original question (left), we modify\nits negation (middle) or topic entity (right): we ﬁnd that QA-GNN adapts attention weights and ﬁnal predictions\naccordingly, suggesting its capability to handle structured reasoning.\nIf it is not used for hair, a round brush is an example of what?  \nA. hair brush  B. art supplies*\nIf it is used for hair, a round brush is an example \nof what?    A. hair brush  B. art supplies\n  \nartsupplyroundbrush\nhairbrush\nZ\npaintingpainting\nartsupply\n    \nhair\nroundbrush\nhairbrush\nartsupplyroundbrush\nhairbrush\nZ Z\npainting\nA. hair brush (#2) \nB. art supplies (#1) \nA. hair brush (#1) \nB. art supplies (#2) \nA. hair brush (#1) \nB. art supplies (#2) \nA. hair brush (#1) \nB. art supplies (#2) \nIf it is not used for art, a round brush is an \nexample of what?    A. hair brush   B. art supplies\n  \nartsupply\nart\nroundbrush\nhairbrush\n→\nZ\npainting\nA. hair brush (#1) \nB. art supplies (#2) \nA. hair brush (#1) \nB. art supplies (#2) \nhair hair\nIf it is not used for hair, a round brush is an example of what?  \nA. hair brush  B. art supply*\nIf it is used for hair, a round brush is an example \nof what?    A. hair brush  B. art supply\n  \nartsupplyroundbrush\nhairbrush\nZ\npaintingpainting\nartsupply\n    \nhair\nroundbrush\nhairbrush\nartsupplyroundbrush\nhairbrush\nZ Z\npainting\nA. hair brush    (0.38) \nB. art supply  (0.64) \nIf it is not used for art, a round brush is an \nexample of what?    A. hair brush   B. art supply\n  \nartsupply\nart\nroundbrush\nhairbrush\n→\nZ\npainting\nhair hair A. hair brush   (0.81) \nB. art supply     (0.19) \nA. hair brush   (0.72) \nB. art supply     (0.28) \nExample  (Original taken from CommonsenseQA Dev) RoBERTa Prediction Our Prediction\n[Original]  If it is not used for hair, a round brush is an example of what?   \n                                            A. hair brush   B. art supply A. hair brush (✗) B. art supply (✓)\n[Negation flip]  If it is used for hair, a round brush is an example of what?  A. hair brush (✓ just no change?) A. hair brush (✓)\n[Entity change]  If it is not used for  art  a round brush is an example of what?   A. hair brush (✓ just no change?) A. hair brush (✓)\n[Original]  If you have to read a book that is very dry you may become what?  \n                                            A. interested   B. bored B. bored (✓) B. bored (✓)\n[Negation ver 1]  If you have to read a book that is very dry you may not become what? B. bored (✗) A. interested (✓)\n[Negation ver 2]  If you have to read a book that is not dry you may become what? B. bored (✗) A. interested (✓)\n[Double negation]  If you have to read a book that is not dry you may not become what? B. bored (✓ just no change?) A. interested (✗)\nExample  (Original taken from CommonsenseQA Dev) RoBERTa Prediction Our Prediction\n[Original]  If it is not used for hair, a round brush is an example of what?   \n                                            A. hair brush   B. art supply A. hair brush (✗) B. art supply (✓)\n[Negation flip]  If it is used for hair, a round brush is an example of what?  A. hair brush (✓ just no change?) A. hair brush (✓)\n[Entity change]  If it is not used for  art  a round brush is an example of what?   A. hair brush (✓ just no change?) A. hair brush (✓)\n[Original]  If you have to read a book that is very dry you may become what?  \n                                            A. interested   B. bored B. bored (✓) B. bored (✓)\n[Negation ver 1]  If you have to read a book that is very dry you may not become what? B. bored (✗) A. interested (✓)\n[Negation ver 2]  If you have to read a book that is not dry you may become what? B. bored (✗) A. interested (✓)\n[Double negation]  If you have to read a book that is not dry you may not become what? B. bored (✓ just no change?) A. interested (✗)\nTable 9: Case study of structured reasoning , comparing predictions by RoBERTa and our model (RoBERTa +\nQA-GNN). Our model correctly handles changes in negation and topic entities.\nMethods IHtest-Acc. IHtest-Acc.\n(Overall)(Question w/negation)\nRoBERTa-large (w/o KG) 68.7 54.2\n+ KagNet 69.0 (+0.3) 54.2 (+0.0)\n+ MHGRN 71.1 (+2.4) 54.8 (+0.6)\n+ QA-GNN (Ours) 73.4 (+4.7) 58.8 (+4.6)\n+ QA-GNN (no edgebetween Z and KG)71.5 (+2.8) 55.1 (+0.9)\nTable 10: Performance on questions with negation\nin CommonsenseQA. () shows the difference with\nRoBERTa. Existing LM+KG methods (KagNet, MH-\nGRN) provide limited improvements over RoBERTa\n(+0.6%); QA-GNN exhibits a bigger boost (+4.6%),\nsuggesting its strength in structured reasoning.\n4.6.3 Structured reasoning\nStructured reasoning, e.g., precise handling of\nnegation or entity substitution (e.g., “hair”→“art”\nin Figure 5b) in question, is crucial for making\nrobust predictions. Here we analyze QA-GNN’s\nability to perform structured reasoning and compare\nwith baselines (ﬁne-tuned LMs and existing\nLM+KG models).\nQuantitative analysis. Table 10 compares\nmodel performance on questions containing\nnegation words (e.g., no, not, nothing, unlikely),\ntaken from the CommonsenseQA IHtest set. We\nﬁnd that previous LM+KG models (KagNet,\nMHGRN) provide limited improvements over\nRoBERTa on questions with negation (+0.6%);\nwhereas QA-GNN exhibits a bigger boost (+4.6%),\nsuggesting its strength in structured reasoning.\nWe hypothesize that QA-GNN’s joint updates of\nthe representations of the QA context and KG\n(during GNN message passing) allows the model to\nintegrate semantic nuances expressed in language.\nTo further study this hypothesis, we remove the\nconnections between z and KG nodes from our\nQA-GNN (Table 10 bottom): now the performance\non negation becomes close to the prior work,\nMHGRN, suggesting that the joint message passing\nhelps for performing structured reasoning.\nQualitative analysis. Figure 5 shows a case\nstudy to analyze our model’s behavior for structured\nreasoning. The question on the left contains\nnegation “not used for hair”, and the correct answer\nis “B. art supply”. We observe that in the 1st layer of\nQA-GNN, the attention fromzto question entities\n(“hair”, “round brush”) is diffuse. After multiples\nrounds of message passing on the working graph,\nzattends strongly to “round brush” in the ﬁnal layer\nof the GNN, but weakly to the negated entity “hair”.\nThe model correctly predicts the answer “B. art sup-\nply”. Next, given the original question on the left,\nwe (a) drop the negation or (b) modify the topic en-\ntity (“hair”→“art”). In (a),znow attends strongly\nto “hair”, which is not negated anymore. The model\npredicts the correct answer “A. hair brush”. In (b),\nwe observe that QA-GNN recognizes the same\nstructure as the original question (with only the\nentity swapped): zattends weakly to the negated\nentity (“art”) like before, and the model correctly\npredicts “A. hair brush” over “B. art supply”.\nMethods IHtest-Acc. IHtest-Acc.\n(Question w/≤10 entities)(Question w/>10 entities)\nRoBERTa-large (w/o KG) 68.4 70.0\n+ MHGRN 71.5 70.1\n+ QA-GNN (w/o noderelevance score) 72.8 (+1.3) 71.5 (+1.4)\n+ QA-GNN (w/ noderelevance score;ﬁnal system) 73.4 (+1.9) 73.5 (+3.4)\nTable 11: Performance on questions with fewer/more\nentities in CommonsenseQA. () shows the difference\nwith MHGRN (LM+KG baseline). KG node relevance\nscoring (§3.2) boosts the performance on questions\ncontaining more entities (i.e. larger retrieved KG).\nTable 9 shows additional examples, where we\ncompare QA-GNN’s predictions with the LM\nbaseline (RoBERTa). We observe that RoBERTa\ntends to make the same prediction despite the\nmodiﬁcations we make to the original questions\n(e.g., drop/insert negation, change an entity); on\nthe other hand, QA-GNN adapts predictions to the\nmodiﬁcations correctly (except for double negation\nin the table bottom, which is a future work).\n4.6.4 Effect of KG node relevance scoring\nWe ﬁnd that KG node relevance scoring (§3.2)\nis helpful when the retrieved KG ( Gsub) is large.\nTable 11 shows model performance on questions\ncontaining fewer (≤10) or more (>10) entities in\nthe CommonsenseQA IHtest set (on average, the\nformer and latter result in 90 and 160 nodes inGsub,\nrespectively). Existing LM+KG models such as\nMHGRN achieve limited performance on questions\nwith more entities due to the size and noisiness of\nretrieved KGs: 70.1% accuracy vs 71.5% accuracy\non questions with fewer entities. KG node relevance\nscoring mitigates this bottleneck, reducing the\naccuracy discrepancy: 73.5% and 73.4% accuracy\non questions with more/fewer entities, respectively.\n5 Related work and discussion\nKnowledge-aware methods for NLP. Various\nworks have studied methods to augment natural lan-\nguage processing (NLP) systems with knowledge.\nExisting works (Pan et al., 2019; Ye et al., 2019;\nPetroni et al., 2019; Bosselut et al., 2019) study pre-\ntrained LMs’ potential as latent knowledge bases.\nTo provide more explicit and interpretable knowl-\nedge, several works integrate structured knowledge\n(KGs) into LMs (Mihaylov and Frank, 2018; Lin\net al., 2019; Wang et al., 2019a; Yang et al., 2019;\nWang et al., 2020b; Bosselut et al., 2021).\nQuestion answering with LM+KG. In particu-\nlar, a line of works propose LM+KG methods for\nquestion answering. Most closely related to ours\nare works by Lin et al. (2019); Feng et al. (2020); Lv\net al. (2020). Our novelties are (1) the joint graph of\nQA context and KG, on which wemutually update\nthe representations of the LM and KG; and (2)\nlanguage-conditioned KG node relevance scoring.\nOther works on scoring or pruning KG nodes/paths\nrely on graph-based metrics such as PageRank, cen-\ntrality, and off-the-shelf KG embeddings (Paul and\nFrank, 2019; Fadnis et al., 2019; Bauer et al., 2018;\nLin et al., 2019), without reﬂecting the QA context.\nOther QA tasks. Several works study other\nforms of question answering tasks, e.g., passage-\nbased QA, where systems identify answers using\ngiven or retrieved documents (Rajpurkar et al.,\n2016; Joshi et al., 2017; Yang et al., 2018), and\nKBQA, where systems perform semantic parsing\nof a given question and execute the parsed queries\non knowledge bases (Berant et al., 2013; Yih et al.,\n2016; Yu et al., 2018). Different from these tasks,\nwe approach question answering using knowledge\navailable in LMs and KGs.\nKnowledge representations. Several works\nstudy joint representations of external textual\nknowledge (e.g., Wikipedia articles) and structured\nknowledge ( e.g., KGs) (Riedel et al., 2013;\nToutanova et al., 2015; Xiong et al., 2019; Sun et al.,\n2019; Wang et al., 2019b). The primary distinction\nof our joint graph representation is that we construct\na graph connecting each question and KG rather\nthan textual and structural knowledge, approaching\na complementary problem to the above works.\nGraph neural networks (GNNs). GNNs have\nbeen shown to be effective for modeling graph-\nbased data. Several works use GNNs to model the\nstructure of text (Yasunaga et al., 2017; Zhang et al.,\n2018; Yasunaga and Liang, 2020) or KGs (Wang\net al., 2020a). In contrast to these works, QA-GNN\njointly models the language and KG. Graph At-\ntention Networks (GATs) (Veliˇckovi´c et al., 2018)\nperform attention-based message passing to induce\ngraph representations. We build on this framework,\nand further condition the GNN on the language\ninput by introducing a QA context node (§3.1), KG\nnode relevance scoring (§3.2), and joint update of\nthe KG and language representations (§3.3).\n6 Conclusion\nWe presented QA-GNN, an end-to-end question\nanswering model that leverages LMs and KGs.\nOur key innovations include (i)Relevance scoring,\nwhere we compute the relevance of KG nodes\nconditioned on the given QA context, and (ii)Joint\nreasoning over the QA context and KGs, where\nwe connect the two sources of information via the\nworking graph, and jointly update their representa-\ntions through GNN message passing. Through both\nquantitative and qualitative analyses, we showed\nQA-GNN’s improvements over existing LM and\nLM+KG models on question answering tasks,\nas well as its capability to perform interpretable\nand structured reasoning, e.g., correctly handling\nnegation in questions.\nAcknowledgment\nWe thank Rok Sosic, Weihua Hu, Jing Huang,\nMichele Catasta, members of the Stanford SNAP,\nP-Lambda and NLP groups and Project MOWGLI\nteam, as well as our anonymous reviewers for valu-\nable feedback. We gratefully acknowledge the\nsupport of DARPA under Nos. N660011924033\n(MCS); Funai Foundation Fellowship; ARO under\nNos. W911NF-16-1-0342 (MURI), W911NF-16-1-\n0171 (DURIP); NSF under Nos. OAC-1835598\n(CINES), OAC-1934578 (HDR), CCF-1918940\n(Expeditions), IIS-2030477 (RAPID); Stanford\nData Science Initiative, Wu Tsai Neuro-sciences\nInstitute, Chan Zuckerberg Biohub, Amazon, JP-\nMorgan Chase, Docomo, Hitachi, JD.com, KDDI,\nNVIDIA, Dell, Toshiba, and United Health Group.\nHongyu Ren is supported by Masason Foundation\nFellowship and the Apple PhD Fellowship. Jure\nLeskovec is a Chan Zuckerberg Biohub investigator.\nReproducibility\nCode and data are available at\nhttps://github.com/michiyasunaga/qagnn.\nExperiments are available at\nhttps://worksheets.\ncodalab.org/worksheets/\n0xf215deb05edf44a2ac353c711f52a25f.\nReferences\nPratyay Banerjee and Chitta Baral. 2020. Knowl-\nedge fusion and semantic knowledge ranking for\nopen domain question answering. arXiv preprint\narXiv:2004.03101.\nPratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra,\nand Chitta Baral. 2019. Careful selection of knowl-\nedge to solve open book question answering. In\nAssociation for Computational Linguistics (ACL).\nJunwei Bao, Nan Duan, Zhao Yan, Ming Zhou, and\nTiejun Zhao. 2016. Constraint-based question an-\nswering with knowledge graph. InInternational Con-\nference on Computational Linguistics (COLING).\nLisa Bauer, Yicheng Wang, and Mohit Bansal. 2018.\nCommonsense for generative multi-hop question\nanswering tasks. In Empirical Methods in Natural\nLanguage Processing (EMNLP).\nJonathan Berant, Andrew Chou, Roy Frostig, and Percy\nLiang. 2013. Semantic parsing on freebase from\nquestion-answer pairs. In Empirical Methods in\nNatural Language Processing (EMNLP).\nOlivier Bodenreider. 2004. The uniﬁed medical\nlanguage system (UMLS): Integrating biomedical\nterminology. Nucleic acids research.\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim\nSturge, and Jamie Taylor. 2008. Freebase: a col-\nlaboratively created graph database for structuring\nhuman knowledge. In SIGMOD.\nAntoine Bordes, Nicolas Usunier, Alberto Garcia-\nDuran, Jason Weston, and Oksana Yakhnenko.\n2013. Translating embeddings for modeling multi-\nrelational data. In Advances in Neural Information\nProcessing Systems (NeurIPS).\nAntoine Bosselut, Ronan Le Bras, and Yejin Choi.\n2021. Dynamic neuro-symbolic knowledge graph\nconstruction for zero-shot commonsense question\nanswering. In Proceedings of the AAAI Conference\non Artiﬁcial Intelligence.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap,\nChaitanya Malaviya, Asli Çelikyilmaz, and Yejin\nChoi. 2019. Comet: Commonsense transformers\nfor automatic knowledge graph construction. In\nAssociation for Computational Linguistics (ACL).\nPeter Clark, Oren Etzioni, Daniel Khashabi, Tushar\nKhot, Bhavana Dalvi Mishra, Kyle Richardson,\nAshish Sabharwal, Carissa Schoenick, Oyvind\nTafjord, Niket Tandon, et al. 2019. From’f’to’a’on\nthe ny regents science exams: An overview of the\naristo project. arXiv preprint arXiv:1909.01958.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In North American Chapter of the Association\nfor Computational Linguistics (NAACL).\nKshitij Fadnis, Kartik Talamadupula, Pavan Kapani-\npathi, Haque Ishfaq, Salim Roukos, and Achille\nFokoue. 2019. Heuristics for interpretable knowl-\nedge graph contextualization. arXiv preprint\narXiv:1911.02085.\nYanlin Feng, Xinyue Chen, Bill Yuchen Lin, Peifeng\nWang, Jun Yan, and Xiang Ren. 2020. Scalable\nmulti-hop relational reasoning for knowledge-aware\nquestion answering. In Empirical Methods in\nNatural Language Processing (EMNLP).\nDedre Gentner. 1983. Structure-mapping: A theoretical\nframework for analogy.Cognitive science.\nKelvin Guu, John Miller, and Percy Liang. 2015.\nTraversing knowledge graphs in vector space. Em-\npirical Methods in Natural Language Processing\n(EMNLP).\nSergey Ioffe and Christian Szegedy. 2015. Batch\nnormalization: Accelerating deep network training\nby reducing internal covariate shift. In International\nconference on machine learning (ICML).\nDi Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,\nHanyi Fang, and Peter Szolovits. 2021. What disease\ndoes this patient have? a large-scale open domain\nquestion answering dataset from medical exams.\nApplied Sciences.\nMandar Joshi, Eunsol Choi, Daniel S Weld, and Luke\nZettlemoyer. 2017. Triviaqa: A large scale distantly\nsupervised challenge dataset for reading comprehen-\nsion. In Association for Computational Linguistics\n(ACL).\nNora Kassner and Hinrich Schütze. 2020. Negated and\nmisprimed probes for pretrained language models:\nBirds can talk, but cannot ﬂy. In Association for\nComputational Linguistics (ACL).\nDaniel Khashabi, Tushar Khot, Ashish Sabharwal,\nOyvind Tafjord, Peter Clark, and Hannaneh\nHajishirzi. 2020. Uniﬁedqa: Crossing format bound-\naries with a single qa system. InFindings of EMNLP.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. Albert: A lite bert for self-supervised learn-\ning of language representations. In International\nConference on Learning Representations (ICLR).\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon\nKim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang.\n2020. Biobert: a pre-trained biomedical language\nrepresentation model for biomedical text mining.\nBioinformatics.\nBill Yuchen Lin, Xinyue Chen, Jamin Chen, and\nXiang Ren. 2019. Kagnet: Knowledge-aware graph\nnetworks for commonsense reasoning. In Empirical\nMethods in Natural Language Processing (EMNLP).\nFangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco\nBasaldella, and Nigel Collier. 2020a. Self-alignment\npretraining for biomedical entity representations.\narXiv preprint arXiv:2010.11784.\nLiyuan Liu, Haoming Jiang, Pengcheng He, Weizhu\nChen, Xiaodong Liu, Jianfeng Gao, and Jiawei Han.\n2020b. On the variance of the adaptive learning\nrate and beyond. In International Conference on\nLearning Representations (ICLR).\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du,\nMandar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining\napproach. arXiv preprint arXiv:1907.11692.\nShangwen Lv, Daya Guo, Jingjing Xu, Duyu Tang, Nan\nDuan, Ming Gong, Linjun Shou, Daxin Jiang, Gui-\nhong Cao, and Songlin Hu. 2020. Graph-based rea-\nsoning over heterogeneous external knowledge for\ncommonsense question answering. In Proceedings\nof the AAAI Conference on Artiﬁcial Intelligence.\nKaixin Ma, Jonathan Francis, Quanyang Lu, Eric\nNyberg, and Alessandro Oltramari. 2019. To-\nwards generalizable neuro-symbolic systems for\ncommonsense question answering. arXiv preprint\narXiv:1910.14087.\nTodor Mihaylov, Peter Clark, Tushar Khot, and Ashish\nSabharwal. 2018. Can a suit of armor conduct\nelectricity? a new dataset for open book question an-\nswering. In Empirical Methods in Natural Language\nProcessing (EMNLP).\nTodor Mihaylov and Anette Frank. 2018. Knowledge-\nable reader: Enhancing cloze-style reading compre-\nhension with external commonsense knowledge. In\nAssociation for Computational Linguistics (ACL).\nXiaoman Pan, Kai Sun, Dian Yu, Jianshu Chen, Heng\nJi, Claire Cardie, and Dong Yu. 2019. Improving\nquestion answering with external knowledge. arXiv\npreprint arXiv:1902.00993.\nDebjit Paul and Anette Frank. 2019. Ranking and se-\nlecting multi-hop knowledge paths to better predict\nhuman needs. In North American Chapter of the\nAssociation for Computational Linguistics (NAACL).\nFabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton\nBakhtin, Yuxiang Wu, Alexander H Miller, and\nSebastian Riedel. 2019. Language models as\nknowledge bases? In Empirical Methods in Natural\nLanguage Processing (EMNLP).\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the\nlimits of transfer learning with a uniﬁed text-to-text\ntransformer. Journal of Machine Learning Research\n(JMLR).\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev,\nand Percy Liang. 2016. Squad: 100,000+ questions\nfor machine comprehension of text. In Empirical\nMethods in Natural Language Processing (EMNLP).\nHongyu Ren, Weihua Hu, and Jure Leskovec. 2020.\nQuery2box: Reasoning over knowledge graphs in\nvector space using box embeddings. InInternational\nConference on Learning Representations (ICLR).\nHongyu Ren and Jure Leskovec. 2020. Beta embed-\ndings for multi-hop logical reasoning in knowledge\ngraphs. In Advances in Neural Information Process-\ning Systems (NeurIPS).\nSebastian Riedel, Limin Yao, Andrew McCallum, and\nBenjamin M Marlin. 2013. Relation extraction\nwith matrix factorization and universal schemas.\nIn North American Chapter of the Association for\nComputational Linguistics (NAACL).\nAdam Santoro, David Raposo, David G Barrett, Ma-\nteusz Malinowski, Razvan Pascanu, Peter Battaglia,\nand Timothy Lillicrap. 2017. A simple neural net-\nwork module for relational reasoning. InAdvances in\nNeural Information Processing Systems (NeurIPS).\nMichael Schlichtkrull, Thomas N Kipf, Peter Bloem,\nRianne Van Den Berg, Ivan Titov, and Max Welling.\n2018. Modeling relational data with graph con-\nvolutional networks. In European Semantic Web\nConference.\nRobyn Speer, Joshua Chin, and Catherine Havasi. 2017.\nConceptnet 5.5: An open multilingual graph of\ngeneral knowledge. In Proceedings of the AAAI\nConference on Artiﬁcial Intelligence.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,\nIlya Sutskever, and Ruslan Salakhutdinov. 2014.\nDropout: A simple way to prevent neural networks\nfrom overﬁtting. Journal of Machine Learning\nResearch (JMLR), 15(1):1929–1958.\nHaitian Sun, Tania Bedrax-Weiss, and William W\nCohen. 2019. Pullnet: Open domain question\nanswering with iterative retrieval on knowledge\nbases and text. In Empirical Methods in Natural\nLanguage Processing (EMNLP).\nHaitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn\nMazaitis, Ruslan Salakhutdinov, and William W\nCohen. 2018. Open domain question answering\nusing early fusion of knowledge bases and text. In\nEmpirical Methods in Natural Language Processing\n(EMNLP).\nAlon Talmor, Jonathan Herzig, Nicholas Lourie,\nand Jonathan Berant. 2019. Commonsenseqa: A\nquestion answering challenge targeting common-\nsense knowledge. In North American Chapter of the\nAssociation for Computational Linguistics (NAACL).\nKristina Toutanova, Danqi Chen, Patrick Pantel, Hoi-\nfung Poon, Pallavi Choudhury, and Michael Gamon.\n2015. Representing text for joint embedding of\ntext and knowledge bases. In Empirical Methods in\nNatural Language Processing (EMNLP).\nPetar Veliˇckovi´c, Guillem Cucurull, Arantxa Casanova,\nAdriana Romero, Pietro Liò, and Yoshua Bengio.\n2018. Graph attention networks. In International\nConference on Learning Representations (ICLR).\nHongwei Wang, Hongyu Ren, and Jure Leskovec.\n2020a. Entity context and relational paths for\nknowledge graph completion. arXiv preprint\narXiv:2002.06757.\nPeifeng Wang, Nanyun Peng, Pedro Szekely, and Xiang\nRen. 2020b. Connecting the dots: A knowledgeable\npath generator for commonsense question answering.\narXiv preprint arXiv:2005.00691.\nXiaoyan Wang, Pavan Kapanipathi, Ryan Musa, Mo Yu,\nKartik Talamadupula, Ibrahim Abdelaziz, Maria\nChang, Achille Fokoue, Bassem Makni, Nicholas\nMattei, et al. 2019a. Improving natural language\ninference using external knowledge in the science\nquestions domain. In Proceedings of the AAAI\nConference on Artiﬁcial Intelligence.\nXiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan\nLiu, Juanzi Li, and Jian Tang. 2019b. Kepler: A\nuniﬁed model for knowledge embedding and pre-\ntrained language representation. Transactions of the\nAssociation for Computational Linguistics (TACL).\nDavid S Wishart, Yannick D Feunang, An C Guo,\nElvis J Lo, Ana Marcu, Jason R Grant, Tanvir Sajed,\nDaniel Johnson, Carin Li, Zinat Sayeeda, et al.\n2018. Drugbank 5.0: a major update to the drugbank\ndatabase for 2018. Nucleic acids research.\nWenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo,\nand William Yang Wang. 2019. Improving question\nanswering over incomplete kbs with knowledge-\naware reader. In Association for Computational\nLinguistics (ACL).\nKeyulu Xu, Jingling Li, Mozhi Zhang, Simon S Du,\nKen-ichi Kawarabayashi, and Stefanie Jegelka. 2020.\nWhat can neural networks reason about? In Inter-\nnational Conference on Learning Representations\n(ICLR).\nAn Yang, Quan Wang, Jing Liu, Kai Liu, Yajuan\nLyu, Hua Wu, Qiaoqiao She, and Sujian Li. 2019.\nEnhancing pre-trained language representations with\nrich knowledge for machine reading comprehension.\nIn Association for Computational Linguistics (ACL).\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\nWilliam W Cohen, Ruslan Salakhutdinov, and\nChristopher D Manning. 2018. Hotpotqa: A dataset\nfor diverse, explainable multi-hop question answer-\ning. In Empirical Methods in Natural Language\nProcessing (EMNLP).\nMichihiro Yasunaga and Percy Liang. 2020. Graph-\nbased, self-supervised program repair from diag-\nnostic feedback. In International Conference on\nMachine Learning (ICML).\nMichihiro Yasunaga, Rui Zhang, Kshitijh Meelu,\nAyush Pareek, Krishnan Srinivasan, and Dragomir\nRadev. 2017. Graph-based neural multi-document\nsummarization. In Conference on Computational\nNatural Language Learning (CoNLL).\nZhi-Xiu Ye, Qian Chen, Wen Wang, and Zhen-Hua\nLing. 2019. Align, mask and select: A simple\nmethod for incorporating commonsense knowledge\ninto language representation models. arXiv preprint\narXiv:1908.06725.\nWen-tau Yih, Matthew Richardson, Christopher Meek,\nMing-Wei Chang, and Jina Suh. 2016. The value of\nsemantic parse labeling for knowledge base question\nanswering. In Association for Computational\nLinguistics (ACL).\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,\nDongxu Wang, Zifan Li, James Ma, Irene Li,\nQingning Yao, Shanelle Roman, et al. 2018. Spider:\nA large-scale human-labeled dataset for complex\nand cross-domain semantic parsing and text-to-sql\ntask. In Empirical Methods in Natural Language\nProcessing (EMNLP).\nYuhao Zhang, Peng Qi, and Christopher D Manning.\n2018. Graph convolution over pruned dependency\ntrees improves relation extraction. In Empirical\nMethods in Natural Language Processing (EMNLP).\nChen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Thomas\nGoldstein, and Jingjing Liu. 2020. Freelb: Enhanced\nadversarial training for language understanding. In\nInternational Conference on Learning Representa-\ntions (ICLR).",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7750075459480286
    },
    {
      "name": "Question answering",
      "score": 0.7263625264167786
    },
    {
      "name": "Knowledge graph",
      "score": 0.6140947937965393
    },
    {
      "name": "Natural language processing",
      "score": 0.6049234867095947
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5908665657043457
    },
    {
      "name": "Relevance (law)",
      "score": 0.5692468881607056
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5532349348068237
    },
    {
      "name": "Commonsense reasoning",
      "score": 0.4941590130329132
    },
    {
      "name": "Negation",
      "score": 0.48780038952827454
    },
    {
      "name": "Graph",
      "score": 0.4685804545879364
    },
    {
      "name": "Language model",
      "score": 0.4479418098926544
    },
    {
      "name": "Information retrieval",
      "score": 0.35961294174194336
    },
    {
      "name": "Programming language",
      "score": 0.17870000004768372
    },
    {
      "name": "Theoretical computer science",
      "score": 0.15129873156547546
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I97018004",
      "name": "Stanford University",
      "country": "US"
    }
  ]
}