{
  "title": "Exploring the role of AI algorithmic agents: The impact of algorithmic decision autonomy on consumer purchase decisions",
  "url": "https://openalex.org/W4306947088",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2539381162",
      "name": "Yuejiao Fan",
      "affiliations": [
        "Huaqiao University"
      ]
    },
    {
      "id": "https://openalex.org/A2104426756",
      "name": "Xianggang Liu",
      "affiliations": [
        "Huaqiao University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1967352038",
    "https://openalex.org/W4281625651",
    "https://openalex.org/W3082622239",
    "https://openalex.org/W1668078885",
    "https://openalex.org/W2777677018",
    "https://openalex.org/W2997468044",
    "https://openalex.org/W2067762251",
    "https://openalex.org/W4292808503",
    "https://openalex.org/W4248125493",
    "https://openalex.org/W1654467375",
    "https://openalex.org/W2507975203",
    "https://openalex.org/W3118271039",
    "https://openalex.org/W2942966180",
    "https://openalex.org/W1511558225",
    "https://openalex.org/W2466381818",
    "https://openalex.org/W2127662631",
    "https://openalex.org/W2981686111",
    "https://openalex.org/W2790629405",
    "https://openalex.org/W4220744240",
    "https://openalex.org/W3133180979",
    "https://openalex.org/W2488888703",
    "https://openalex.org/W2753975405",
    "https://openalex.org/W2122517769",
    "https://openalex.org/W2974452734",
    "https://openalex.org/W3125633690",
    "https://openalex.org/W3113581731",
    "https://openalex.org/W3211055152",
    "https://openalex.org/W2994789796",
    "https://openalex.org/W2511102856",
    "https://openalex.org/W4214853148",
    "https://openalex.org/W2336052666",
    "https://openalex.org/W2750126764",
    "https://openalex.org/W1799410249",
    "https://openalex.org/W3201598001",
    "https://openalex.org/W2493140117",
    "https://openalex.org/W2581159468",
    "https://openalex.org/W2598702997",
    "https://openalex.org/W4200057456",
    "https://openalex.org/W2042012636",
    "https://openalex.org/W3092788160",
    "https://openalex.org/W2786141192",
    "https://openalex.org/W3008828973",
    "https://openalex.org/W3094793347",
    "https://openalex.org/W2987375214",
    "https://openalex.org/W2899856450",
    "https://openalex.org/W1968008316",
    "https://openalex.org/W2921105016",
    "https://openalex.org/W1977055214",
    "https://openalex.org/W2175169347",
    "https://openalex.org/W1984883844",
    "https://openalex.org/W3118439741",
    "https://openalex.org/W3203055883",
    "https://openalex.org/W3158412788",
    "https://openalex.org/W4232279720",
    "https://openalex.org/W2800068874",
    "https://openalex.org/W2942858056",
    "https://openalex.org/W3175883460",
    "https://openalex.org/W4200546216",
    "https://openalex.org/W3161540876",
    "https://openalex.org/W4211094900",
    "https://openalex.org/W2789983349",
    "https://openalex.org/W2123989818",
    "https://openalex.org/W2004967085",
    "https://openalex.org/W1993854102",
    "https://openalex.org/W2900101166",
    "https://openalex.org/W4293062722",
    "https://openalex.org/W2950834660",
    "https://openalex.org/W2093505263",
    "https://openalex.org/W3081261125",
    "https://openalex.org/W2142781584",
    "https://openalex.org/W2128291680",
    "https://openalex.org/W2042605568",
    "https://openalex.org/W2603703217",
    "https://openalex.org/W2135250378",
    "https://openalex.org/W4283465375",
    "https://openalex.org/W3137457055",
    "https://openalex.org/W3138864873",
    "https://openalex.org/W4283391136",
    "https://openalex.org/W4283788756",
    "https://openalex.org/W3199477727",
    "https://openalex.org/W4224438971",
    "https://openalex.org/W2101642767",
    "https://openalex.org/W3128351871",
    "https://openalex.org/W3107592527",
    "https://openalex.org/W2563045059",
    "https://openalex.org/W2558287871",
    "https://openalex.org/W3216399797",
    "https://openalex.org/W2912633426",
    "https://openalex.org/W2792794664",
    "https://openalex.org/W4200294983",
    "https://openalex.org/W2913854599",
    "https://openalex.org/W3162137248",
    "https://openalex.org/W4220795885",
    "https://openalex.org/W2134049139"
  ],
  "abstract": "Although related studies have examined the impact of different images of artificial intelligence products on consumer evaluation, exploring the impact on consumer purchase decisions from the perspective of algorithmic decision autonomy remains under-explored. Based on the self-determination theory, this research discusses the influence of the agent decision-making role played by different AI algorithmic decision autonomy on consumer purchase decisions. The results of the 3 studies indicate that algorithmic decision autonomy has an inverted U-shaped effect on consumer’s purchase decisions, consumer’s self-efficacy mediates the relationship between algorithmic decision autonomy and purchase decisions, and consumer’s power distance moderates the relationship between algorithmic decision autonomy, self-efficacy, and purchase decisions. The research results can provide references for marketers, retailers, algorithm designers, and other parties to formulate algorithm marketing strategies, make AI algorithm decisions better serve consumers, and achieve value co-creation with consumers.",
  "full_text": "Frontiers in Psychology 01 frontiersin.org\nExploring the role of AI \nalgorithmic agents: The impact \nof algorithmic decision \nautonomy on consumer \npurchase decisions\nYuejiao Fan  and Xianggang Liu *\nBusiness School, Huaqiao University, Quanzhou, China\nAlthough related studies have examined the impact of different images of \nartificial intelligence products on consumer evaluation, exploring the impact \non consumer purchase decisions from the perspective of algorithmic decision \nautonomy remains under-explored. Based on the self-determination theory, \nthis research discusses the influence of the agent decision-making role \nplayed by different AI algorithmic decision autonomy on consumer purchase \ndecisions. The results of the 3 studies indicate that algorithmic decision \nautonomy has an inverted U-shaped effect on consumer’s purchase decisions, \nconsumer’s self-efficacy mediates the relationship between algorithmic \ndecision autonomy and purchase decisions, and consumer’s power distance \nmoderates the relationship between algorithmic decision autonomy, self-\nefficacy, and purchase decisions. The research results can provide references \nfor marketers, retailers, algorithm designers, and other parties to formulate \nalgorithm marketing strategies, make AI algorithm decisions better serve \nconsumers, and achieve value co-creation with consumers.\nKEYWORDS\nAI algorithmic marketing, algorithm agent role, algorithmic decision autonomy,  \nself-efficacy, power distance, purchase decisions\nIntroduction\nIn the era of the digital economy, data have become a strategic factor of production \ninvolved in the whole process of value creation, distribution, circulation, and consumption, \nwhile algorithms have become a strategic tool for collecting and processing data, resulting in \nAI algorithms decision-making based on data elements (Logg et al., 2019; Hoffman et al., \n2022). Compared with human decision-making, algorithmic decision-making has the \nadvantages of being fast, pervasive, and low consumption (Bonnefon et al., 2016). With these \ncharacteristics, algorithms have been becoming the basis of decision-making in “algorithmic \nlife” and have started to intervene and even dominate more and more  \nhuman social affairs, becoming agents in people’s daily lives (Bo and Benbasat, 2007; Danaher \net al., 2017). For example, many of the content services that people access on the Internet, such \nas news, music, video, advertising, social network dynamics, and the goods they buy, are \nTYPE Original Research\nPUBLISHED 20 October 2022\nDOI 10.3389/fpsyg.2022.1009173\nOPEN ACCESS\nEDITED BY\nCatherine Prentice,  \nGriffith University,  \nAustralia\nREVIEWED BY\nBingjia Shao,  \nChongqing University,  \nChina\nDon Donghee Shin,  \nZayed University,  \nUnited Arab Emirates\n*CORRESPONDENCE\nXianggang Liu  \n20013120017@stu.hqu.edu.cn\nSPECIALTY SECTION\nThis article was submitted to  \nPersonality and Social Psychology,  \na section of the journal  \nFrontiers in Psychology\nRECEIVED 13 August 2022\nACCEPTED 26 September 2022\nPUBLISHED 20 October 2022\nCITATION\nFan Y and Liu X (2022) Exploring the role of \nAI algorithmic agents: The impact of \nalgorithmic decision autonomy on \nconsumer purchase decisions.\nFront. Psychol. 13:1009173.\ndoi: 10.3389/fpsyg.2022.1009173\nCOPYRIGHT\n© 2022 Fan and Liu. This is an open-access \narticle distributed under the terms of the \nCreative Commons Attribution License  \n(CC BY). The use, distribution or \nreproduction in other forums is permitted, \nprovided the original author(s) and the \ncopyright owner(s) are credited and that \nthe original publication in this journal is \ncited, in accordance with accepted \nacademic practice. No use, distribution or \nreproduction is permitted which does not \ncomply with these terms.\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 02 frontiersin.org\ncurrently personalized by recommendation engines based on \nconsumer preferences, not by human decisions (sohu.com)1 (Gal, \n2018). Most Internet technology companies are already using \nalgorithmic decision-making in consumer, education, finance, \nhealthcare, transportation, justice, urban governance, and other \nfields and scenarios (Mestel et al., 2018; Dubey et al., 2021). For \ncompanies using algorithms for decision-making, algorithms are not \nonly marketing or sales tools, but also an important driving force to \nstimulate insight, innovation, and user participation. Therefore, with \nthe popularity of algorithms in consumer-oriented decision-making, \nit is of great significance to understand how consumers react to \nalgorithmic decisions (Hoffman et al., 2022; Y alcin et al., 2022).\nA review of the relevant literature reveals that most of the \nexisting studies on algorithms have focused on technical \nimprovements in human-computer interaction or investigated the \ninfluence of algorithm-related features on people’s motivation to \naccept (Logg et al., 2019), or compared algorithmic decisions with \nhuman decisions to derive the reasons and factors influencing \npreferences (Dietvorst et al., 2015; Dietvorst and Bharti, 2020; Y alcin \net al., 2022), while studies exploring the interactive processes and \npsychological mechanisms of consumer-algorithmic decision-\nmaking are relatively limited, and the impact of algorithmic decision \nautonomy on consumer purchase decisions and its mechanisms of \naction from the perspective of algorithmic decision autonomy has \nnot been studied yet (Paschen et al., 2019). Existing research reviews \non the impact of algorithmic decision-making are mixed and have \nyet to reach a consistent conclusion. On the one hand, scholars \nargue that sophisticated algorithms allow online marketers to offer \njust the right product or service that not only alleviates consumers’ \nsearch costs but also alleviates the trade-off of difficult choices and \nincreases the utility they derive from their choices. On the other \nhand, scholars have argued that algorithmic decision-making can \nundermine consumers’ sense of autonomy and may be harmful to \nconsumers’ well-being ( André et  al., 2018 ), and even cause \nalgorithmic pollution ( Marjanovic et  al., 2021 ). This kind of \ndecision-making based solely on interest-based algorithmic \nrecommendations limits users’ access to diverse information and \nties them to the “echo chamber” built by AI algorithms. So, while \nalgorithms can often make more accurate decisions than humans, \npeople still prefer human decisions. Therefore, we aim to address \nthese research questions:\n 1. What role do AI algorithmic agents play in social \ninteractions with consumers?\n 2. Is there an optimum for the influence of algorithmic \ndecision autonomy on consumer decisions?\n 3. What are the cognitive processes and conditions for the \nimpact of algorithmic decision autonomy on consumer  \ndecisions?\n1 The rise of algorithmic decision making: Some ethical issues and strategies \nin the age of artificial intelligence|AI watch (2017). www.sohu.com. Available \nat: https://www.sohu.com/a/143165651_455313 (Accessed June 19, 2022).\nTo answer these research questions, based on self-\ndetermination theory, we construct a model framework (as in \nFigure 1) to describe the causal mechanism between algorithmic \ndecision autonomy and consumer purchase decisions, and classify \nalgorithmic decision autonomy into three levels (high vs. middle \nvs. low) based on the relationship between algorithms, human, \nand society, which correspond to the corresponding agent roles: \ndictatorial substitute/co-assistant/pure performer. Three studies \nare conducted to explore the effects of algorithmic decision \nautonomy on consumer purchase decisions; the mediating effect \nof consumer self-efficacy in algorithmic decision autonomy and \npurchase decisions; and the moderating role of the heterogeneous \ncharacteristics of consumer power distance (high vs. low).\nTheoretical background and \nhypothesis development\nSelf-determination theory\nSelf-determination theory is a motivational theory of human \nbehavior that investigates the extent to which individuals are self-\ndetermined, as reflected in the three major psychological needs \nmotivating consumer autonomy, competence, and relatedness \n(Brown and Ryan, 2003). Autonomy represents the ability of an \nindividual to make choices and determine a course of action based \non his or her own volition, without external coercion (e.g., \ninitiating, regulating, and maintaining his or her behavior; Lau \nand Ki, 2021 ). The need for competence reflects the desire to \ninteract effectively with the environment, and when this need is \nmet, people have a sense of control and accomplishment (Puntoni \net al., 2021); Relatedness needs refer to people’s need for mutual \nrespect and connection with others, and when this need is met, \npeople will feel social support from others and enhance their sense \nof social existence (Deci and Ryan, 2000).\nAccording to SDT, the degree of algorithmic decision \nautonomy affects these three major intrinsic motivations of \nconsumers. Firstly, when the degree of algorithmic decision \nautonomy is high, it can deprive consumers of autonomy (Puntoni \net  al., 2021 ), because consumers feel that they experience \nsystematic discrimination or oppression, are socially excluded, \nand are limited in the expression of their own autonomous needs \n(Kachanoff et  al., 2020 ), thus influencing their purchasing \ndecisions. Secondly, users do not simply receive algorithmic \noutput but will process the concept of algorithmic information \nthey receive, and they will rely more on their intuition than \nalgorithmic decisions in the decision-making judgment process \n(Shin, 2022), this is a demonstration of their competence. Thirdly, \nin terms of relatedness, humans perceive themselves as distinct \nfrom other groups, but the control of the environment by \nalgorithmic decisions, especially those with high autonomy,  \nmay blur the boundary between “human” and “tool” and bring \nabout the annihilation of human uniqueness, threaten  \nhuman identity or uniqueness and lose their sense of control \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 03 frontiersin.org\n(Faraji-Rad et al., 2017; Longoni et al., 2019), which is detrimental \nto consumers’ purchasing decisions (Kim et al., 2015; Lau and Ki, \n2021). In addition, it has also been shown that self-determination \nallows people to feel that they have control over their choices and \nlives, which ultimately increases their feelings of psychological \nwellbeing (e.g., feeling capable, self-governed, well-supported, and \nsatisfied with their state; Brown and Ryan, 2003) Therefore, SDT \nexplains well the influence mechanism of algorithmic decision \nautonomy on consumer purchase decisions (Beer, 2017).\nAlgorithmic decision autonomy\nThe degree of algorithmic decision autonomy reflects the \nextent to which AI decision systems based on big data and \nmachine learning and deep learning algorithms operate in an \nindependent and goal-directed way without users’ interference \n(Baber, 1996; Rijsdijk et al., 2007 ; Rijsdijk and Hultink, 2009), \ntakes over tasks on its own and can exhibit proactive and self-\ninitiated behavior (Benlian et al., 2020; Lucia-Palacios and Pérez-\nLópez, 2021). While human autonomy refers to individuals’ ability \nto carry out a decision that fits their needs or desires free from \ncoercion or manipulation ( Dogruel et  al., 2022 ), which is \nassociated with self-determination theory. Humans have been \nrational and ethical decision-makers for thousands of years, but \nemerging algorithmic technologies are now replacing human \nautonomy by making decisions for humans (Chiodo, 2022), which \ncan threaten the autonomy of human decision-making (Burton \net al., 2020; Dogruel et al., 2022). At the same time, algorithmic \ndecision-making may challenge the control of human decisions, \nwhere potential biases, discrimination, censorship, or the \nemergence of echo chambers may occur ( Dogruel et al., 2022 ; \nShin et  al., 2022c ). Autonomous algorithms may also collect \ninformation from the environment about the consumer’s behavior, \nand share this information with third-party service providers \nwithout the consumer’s permission (Shin et al., 2022d), raising a \nrange of issues such as transparency, fairness, accountability, and \nexplainability (Shin, 2021 ; Shin et  al., 2022c ). Therefore, AI \nalgorithm decision-making involves the decision-making \nmechanism of human and machine interaction, which is reflected \nin the relationship between human, algorithm and society. The \nmost basic and core is the autonomy relationship between human \nand algorithm in decision-making, which is reflected in the \nproportional relationship between them, or in other words, the \nrelationship between the two is a trade-off (Hongjun, 2022).\nThere is no unified knowledge about algorithmic decision \nautonomy and the role it represents, but we can draw insights \nfrom a series of studies by many scholars or institutional subjects. \nAccording to the order of development and degree of intelligence \nof AI, Huang et  al. distinguished four types of intelligence: \nmechanical, analytical, intuitive, and empathic (Huang and Rust, \n2018). After that he  merged both analytic and intuitive AI, \nforming mainly three types of AI, which are mechanical, thinking, \nand feeling AI ( Huang and Rust, 2021a), and was widely cited \n(Huang and Rust, 2021b ; Pantano and Scarpi, 2022 ; Schepers \net al., 2022). Some studies classify AI into three categories: narrow \nAI, general AI, and super AI (Kaplan and Haenlein, 2019; Benbya \net al., 2020; Ameen et al., 2022). Based on the different roles of \nalgorithmic decision agents, OECD (2017) also proposed four \ntypes of roles for AI algorithms: Monitoring algorithms, Parallel \nalgorithms, Signaling algorithms, and Self-learning algorithms. \nBut parallel algorithms and signaling algorithms are decisions that \nare ultimately made by humans and can be grouped into the same \ncategory. Therefore, from the perspective of the human-algorithm \ndecision relationship, the above division of AI types actually \ncorresponds to three different degrees of autonomy of AI \nalgorithms: high, middle, and low (Leung et al., 2018; Dogruel \net al., 2022), and play different roles in the social value network \n(Čaić et al., 2018). When the algorithm has absolute dominance \nin decision-making, the “autonomy” of the algorithm will be at the \nhighest level and the algorithm becomes an independent decision-\nmaker; when the human has dominant autonomy in decision-\nmaking, the “autonomy” will be close to the middle level and the \nalgorithm is an auxiliary decision-maker in the human-algorithm \nrelationship; and when the “autonomy” of the algorithm is at a \nlower level, the algorithm becomes a mechanical executor in the \nhuman-algorithm relationship (Leung et al., 2018). According to \nSDT, these three different levels of autonomy and the \nFIGURE 1\nTheoretical framework.\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 04 frontiersin.org\ncorresponding roles of decision-making agents have different \neffects on consumer’s psychological and behavioral activities. \nResearch shows that, at low levels of autonomy, one AI product is \nunable to act by itself and start listening without the user’s \ninteraction, and that, as autonomy increases, the benefits can \noutweigh the risks until to the point that increasing autonomy \nleads to a loss of control (Lucia-Palacios and Pérez-López, 2021). \nHuang et al. also argue that substitution effects in decision-making \nare more likely to occur at high levels of AI ( Huang and \nRust, 2018).\nAlgorithmic decision autonomy and \npurchase decisions\nConsumer purchase decisions are influenced by multiple \nfactors, and the decision process is often intertwined with risk \nperception, emotions, cognition, etc. Therefore, from a customer \njourney perspective, decision quality and decision satisfaction are \ntwo important measures of decision outcomes (Bo and Benbasat, \n2007). Bechara et al. (1998)believe that decision-making is not \nonly a cognitive process but also a process of cognitive processing \nafter inputting a large amount of information such as feedback \nrelated to emotion or motivation. Kuo et al. (2009)have shown \nthat information representation can cause emotional changes, \nwhich can change cognitive strategies, which in turn can affect \ndecision-making behavior. Therefore, our studies focus on the \nimpact of individual consumer level factors and psychological \ncognitive processes on their decision quality and satisfaction in \nthe context of AI marketing.\nWhen the algorithm becomes an independent decision-maker \nin the relationship between people and algorithms, that is, the \nalgorithm has a high degree of decision-making autonomy and \nhuman autonomy is relatively small. According to SDT, algorithms \nintervene too much in the human operational process, which \ncreates the negative potential hazard of algorithmic \noverdependence, which will reduce human satisfaction with the \noperational process and deepen systematic bias against AI \nalgorithms (Banker and Khetani, 2019). Because individuals feel \nthat their behavior is controlled by AI algorithms, their \nautonomous needs cannot be satisfied, which leads to a decrease \nin internal motivation, and the independent decision-making of \nthe algorithm makes consumers perceive that their freedom of \ndecision-making and autonomy is violated, which leads to \nresistance (André et al., 2018). The most typical example is that \ninformation delivery platforms are using recommendation \nalgorithm technology to subvert people’s reading in this era, \nmastering the voice power of news information distribution, \npeople’s reading selection decisions are determined by algorithms. \nEven worse, companies are using AI algorithms to manipulate \npublic opinion. In addition, according to the “uncanny valley” \ntheory ( Stein and Ohler, 2017 ), the autonomous decisions by \nalgorithms can be  disconcerting, and people’s reactions can \nchange from empathy to aversive and fear, which may inhibit \nconsumers’ perceptions of how willingness to adopt algorithms \naffects their decision quality and decision satisfaction (van Doorn \net  al., 2017), creating algorithmic decision loss aversion ( Kim \net al., 2019). Therefore, the following hypotheses are framed:\nH1a: When algorithmic decision autonomy is high, it will \nhave a negative impact on consumers’ purchase decisions.\nWhen humans have relatively dominant autonomy in \ndecision-making, the autonomy of algorithmic decision-making \nis close to the middle level, and the algorithm plays an auxiliary \nrole in the human-algorithm relationship. In this context, \nalgorithmic decision-making can well improve the efficiency of \ndecision-making, provide an important reference for consumer \ndecision-making with more accurate services ( Prahalad and \nRamaswamy, 2004; Lalicic and Weismayer, 2021 ; Yin and Qiu, \n2021), and will not undermine consumers’ decision autonomy. \nAccording to self-determination theory, when the content of \nalgorithmic decisions based on users’ needs and preferences \nsatisfies their unique preferences. Users not only feel pleasure \nand satisfaction, and their loyalty will be improved to a certain \nextent, but also enhance their perception of reaching consensus \non their decision-making and recommender system, generating \nstronger confidence in their choices, and thus satisfaction with \nthe algorithmic decisions ( Xiao and Benbasat, 2018 ). \nMeanwhile, personalized recommendations make it easier for \nusers to access information of interest and better products and \nservices, choices become easier, practical, and effective, and \ndecision quality is improved, so users develop positively \nperceived usefulness and perceived personalization ( André \net  al., 2018 ; Palos-Sanchez et  al., 2019 ), increasing their \ncognitive and affective trust, and thus a significantly higher \nwillingness to adopt algorithmic decisions ( Palmeira and \nSpassova, 2015; Starke and Lünich, 2020), which contributes to \nenhance individuals’ internal motivation for the decision task \nand improve the sense of social presence. Accordingly, \nwe hypothesize the following:\nH1b: When the algorithm decision-making autonomy is at the \nintermediate level, this is the most comfortable agency \nrelationship, which has the highest impact on consumers’ \npurchase decisions.\nWhen the algorithm has no autonomy in decision-making, \nand the autonomy of the algorithm is at the lowest level, the \nalgorithm becomes a “pure executor” in the human-algorithm \nrelationship. Although the degree of self-determination reaches \nthe highest, everything needs to be decided by consumers, just \na pure executor will affect the user experience, affect the \nefficiency of decision-making, and do not provide the necessary \ndecision-making reference, which is tantamount to increasing \nthe difficulty of decision-making and will cause consumers to \ndecision boredom, which is contrary to the trend of digital \nadvancement (Yunwen, 2021). In addition, when the algorithm \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 05 frontiersin.org\nbecomes a pure executor, there may be great problems in the \npractice of algorithm decision-making, because the past data \nmay be outdated, and people’s preference characteristics may \nchange over time. However, the algorithm decision-making that \nblindly implements “poor historical data” will strengthen the \npast shortcomings and accumulate the adverse effects of bias \ndisadvantages ( Marjanovic et  al., 2021 ), reflecting the \nnon-intelligence of algorithmic decisions that do not change \niteratively with the environment. Based on SDT, when AI \nalgorithms have low decision autonomy, they are characterized \nas mechanical, rigid, and inflexible, and will only do \nstandardized and repetitive tasks according to a set procedure \n(Longoni et  al., 2019 ). Algorithmic decision-making suffers \nfrom a lack of flexibility and does not satisfy consumers’ \nmotivation for unique needs. Consumers will tend to find it \ndifficult to interact with AI algorithmic systems or products. \nBased on the points discussed above, we  propose the \nfollowing hypothesis:\nH1c: When the algorithmic decision autonomy is at a low level \nit has a negative impact on the consumer’s purchase decision.\nH1: Combining these three levels, algorithmic decision \nautonomy has an inverted U-shaped effect on consumers’ \npurchase decisions.\nMediating role of self-efficacy\nSelf-efficacy is defined as the degree of one’s feelings about \nhis/her ability to accomplish goals ( Bandura, 1977 ). In the \ncontext of algorithms, extensive research has shown that user’s \nself-efficacy is significantly associated with algorithmic decisions. \nShin et  al. studied the positive effect of perceived fairness, \nexplainability, accountability, and transparency on users’ self-\nefficacy of personalized algorithms ( Shin et al., 2022a ,b). Hu \net al. confirmed that the sensing, thought and action autonomy \nof artificial intelligence has a positive impact on the competence \nand warmth perception of individuals ( Hu et al., 2021 ). It has \nalso been shown that better learning of algorithmic skills in a \nlearning environment can improve algorithmic thinking and \nachieve higher levels of self-efficacy ( Fanchamps et al., 2021 ). \nBased on SDT, individuals generally want to achieve control over \nthe external environment, while algorithmic decision-making is \nconducive to the realization of this goal to a certain extent. \nBecause in an environment where the purchase task makes a \ndecision, it is actually a depletion of the consumer’s cognitive \nresources, while the algorithm as a decision tool contributes to \nthe consumer’s motivation to mobilize, cognitive resources, and \nability to take actions to successfully complete the task in the \ndecision process (Orth and Wirtz, 2014; Wang and Jiang, 2022). \nGiven this, H2 is proposed:\nH2: Algorithmic decision autonomy has a positive effect on \nconsumer self-efficacy.\nSelf-efficacy plays a key role in how humans perform \nbecause it directly influences factors such as motivations and \ngoals, affective tendencies, perceptions of opportunities, and \noutcome expectations in social environments. Research \nsuggests that consumer self-efficacy may affect their decision-\nmaking, the greater the consumer’s self-efficacy for decision-\nmaking tasks, the more efficient the decision-making process \nstrategies are expected to be ( Hale et al., 2021 ). When self-\nefficacy is considered in terms of people’s online behavior, the \nhigher the online self-efficacy, the more confident people are in \nusing the algorithm ( Araujo et al., 2020 ). Further, the greater \nthe individual’s belief in their online self-efficacy, the higher the \nindividual’s positive attitude toward the use of algorithmic \ndecision-making ( Mahmud et  al., 2022 ). Self-efficacy can \nincrease the adoption of both sustainable behaviors, such as \nfintech usage intentions ( Lee, 2021 ), recycling intentions \n(White et al., 2019 ), and health behaviors ( Han et al., 2016 ). \nLastly, self-efficacy can benefit one’s psychological well-being. \nFor example, feelings of self-efficacy associated with self-made \ncreations were found to produce positive feelings as well as a \ngreater willingness to pay for the product ( Cannon and Rucker, \n2022). Consequently, the following hypotheses are framed:\nH3: Self-efficacy has a positive effect on consumer \npurchase decisions.\nH4: Self-efficacy mediates the inverted-U relationship between \nalgorithmic decision autonomy and purchase decisions.\nModerating of power distance\nPower distance reflects the individual’s cultural values about \nsociety, and refers to people’s acceptance and expectation of the \nuneven distribution of power (Hofstede, 1980; Oyserman, 2006). \nResearch has shown that consumers with different power distance \nperceptions have different preferences for decision-making, which \ncan influence people’s attitudes and behaviors. Consumers with \nlow power distance perceive equality everywhere in their lives, \nand they are committed to respecting the equality that exists in \nsocial communication processes (Gao et al., 2016), they tend to \ncooperate with others. Algorithmic decision-making brings them \nconvenience in decision-making, do not have algorithmic decision \naversion even when there is a high level of algorithmic decision \nautonomy. Because they are affectionate and forgiving (Han et al., \n2017), they are more likely to accept even if the algorithm is \nbiased. In contrast, people with high power distance have a greater \nsense of status (Kim and Zhang, 2014) and self-confidence, and \npay attention to their emotional self-evaluation of being socially \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 06 frontiersin.org\naccepted (Soll and Mannes, 2011). Therefore, when the degree of \nalgorithm decision-making autonomy is high, it will make them \nlose the evaluation degree of self-determination and reduce their \nsense of self-efficacy.\nAt the same time, people with high power distance will \nhave reduced motivation to connect with others while \nmaintaining social distance with others. According to the self-\ndetermination theory, high power distance people prefer to \nself-judge and self-determine and self-make decisions than \nlow power people and thus feel bad about algorithmic \ndecision-making especially when algorithms become \nindependent players. Typically, as executives with a high sense \nof power distance, they have long resisted the use of AI \ndecision-making for higher-level decision-making. They \nalways prefer intuitive decision-making based on field \nexperience rather than AI-assisted decision-making ( Banker \nand Khetani, 2019 ; Thurai and McKendrick, 2022 ). Research \nshows that people who strongly identify with a specific social \ncategory will resist the results of identity-related consumption \nalgorithm autonomous decision-making, because they have a \nhigher degree of attribution identification for their internal \nmotivation decision-making ( Leung et al., 2018 ). Those with \na high sense of power follow the dynamic orientation of  \npower when making decisions for themselves, placing more \nvalue and importance on themselves and being more self-\nfocused ( Rucker et  al., 2011 ). Thus, we  hypothesize \nthe following:\nH5: Power distance plays a negative moderating role in the \neffect of algorithmic decision autonomy on purchase decisions.\nH6: Power distance plays a negative moderating role in the \neffect of algorithmic decision autonomy on self-efficacy.\nOverview of studies\nThree different study scenarios were manipulated to test the \nhypothesis. In study 1, taking the news information distribution \nplatform as the background, a one-way between-group design \n(algorithm decision autonomy: high vs. middle vs. low) was used \nto test the inverted U effect of algorithm decision autonomy on \nconsumers’ purchasing decisions, including H1a/b/c. In study 2, \nagainst the background of the decision to purchase a home AI \nservice robot, a one-way between-group design was used to test \nH1 again and to test the mediating effect of self-efficacy, including \nH2/3/4. Study 3 used a 3 (algorithmic decision autonomy: high vs. \nmiddle vs. low) × 2 (power distance: high vs. low) between-group \nexperimental design based on an AI shopping guide service \nprogram of an e-commerce platform, the aim is to test again the \neffect of the inverted U-shape and the moderating effect of power \ndistance, i.e., H5/6.\nStudy1: Main effect\nPre-study 1\nStimuli and design\nThe pre-experiment mainly tests the experimental situation, \nexperimental method, and the validity of the scale. A total of 70 \nparticipants were recruited through the “credamo” online platform \n(The platform is equivalent to the Amazon “MTurk” portal and is \nused for online recruitment of willing research study participants). \nAll subjects were randomly divided into three groups (News \ninformation distribution platform as the background (Shin et al., \n2022d), algorithmic decision autonomy high vs. middle vs. low) \nof text material experimental scenarios. Subsequently, algorithmic \ndecision autonomy was measured as manipulation tests, and a \ngeneral judgment question on the role of the algorithmic agent \n“Based on the decision scenario, do you think its role belongs to a \npure performer/co-assistant/dictatorial” ( Lucia-Palacios and \nPérez-López, 2021), and included attention questions is built to \ntest whether subjects answer carefully. Finally, demographic \ninformation and familiarity were completed.\nResults\nThe four items of autonomy had high reliability (α = 0.928), \nthe number of subjects in the three groups was 23:24:23, and the \nresults of the manipulation test showed that there was a significant \ndifference in the subjects’ autonomy of algorithmic decision-\nmaking between the three groups (F (2, 67) = 9.133, p < 0.001). The \ncross-table analysis of the manipulation judgment questions of the \nexperimental group and the algorithm agent role shows that \nparticipants with high autonomy in algorithmic decision-making \npreferred the role of “dictatorial substitute” (78.3%, M = 4.359, \nSD = 1.857); participants with moderate autonomy in algorithmic \ndecision-making think the algorithm tends to play the role of \n“co-assistant” (87.5%, M = 4.271, SD = 0.992); participants with \nlow autonomy think that the algorithm tends to be  a “pure \nexecutor” (82.6%, M = 2.826, SD = 1.328), Pearson chi-square test \nand Monte Carlo two-tailed test were significant. Post hoc multiple \ncomparison analysis Dunnett’s t-test (two-tailed) showed \nsignificant differences between the two groups (pmax = 0.002 < 0.05), \nindicating that the experimental manipulation test was successful \nand that the experimental context and information will be used in \nstudy 1.\nStudy 1\nDesign and procedures\nIn addition to adding two dimensions of consumer purchase \ndecision quality and decision satisfaction measurement (Amason, \n1996; Ameen et al., 2021 ), the procedures and contents of the \nformal experiment were the same as those of the pre-study. The \nmeasurement scales were all seven-point Likert scales. The formal \nexperiment calculates the sample size in advance. Based on the \ncalculation method and relevant research in Cohen (1977) , \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 07 frontiersin.org\nG*power is used to set the statistical power in advance (A priori) \nto determine the sample size. The F-test, a one-way ANOV A \nstatistical test was selected from the test set, and the effect size was \nset to a middle effect size of 0.25 (effect size f = 0.25), the α level of \nthe two-tailed test was controlled at 0.05, and the expected efficacy \nvalue of 0.8 (power = 0.80), and then the number of groups 3 was \nentered to calculate the sample size should reach 159 or more. \nTherefore, the study recruited 160 consumers through the \ncredamo, and participants were randomly assigned to 3 groups. \nThe sample distribution of each group of the algorithmic decision \nautonomy was Nhigh = 53, Nmiddle = 54, Nlow = 53; the proportion of \nwomen was 67.5%, the age group was concentrated between 18 \nand 50  years old (about 95%), and the education level was \nconcentrated in undergraduate and high school and college level; \nin addition, most of the respondents (56.25%) were managers, \nstudents, clerks, and 77.5% had a monthly income of more than \n3,000 RMB.\nResults\nANOV A analysis results show that there are significant \ndifferences in the subjects’ decision-making autonomy of the three \ngroups of algorithms (F (2, 157) = 49.946, p < 0.001; Mhigh = 5.160, \nMmiddle = 4.579, Mlow = 2.816), the homogeneity of variance was \nequal. The Dunnett’s t-test of multiple comparative analyses \nshowed that there were significant differences between the two \ngroups (p = 0 < 0.05). The results with purchase decisions as the \ndependent variable show that the effect of algorithmic decision \nautonomy on purchase decisions is significant (F (2, 157) = 19.210, \np < 0.001), and the evaluative impact of consumer purchase \ndecisions is the largest when the algorithmic decision autonomy \nis at a middle level, followed by the other two \n(Mmiddle = 5.625 > Mhigh = 4.580 > Mlow = 4.250), verifying the H1b.\nNext, we verify the inverted U-shaped relationship presented \nby the influence of algorithmic decision autonomy on consumer \npurchase decisions. First, the regression estimation of the curve \nwas fitted by SPSS 26, and the results showed that the quadratic \nand primary terms standardized regression coefficients of \nβ2 = −1.213 ( t = −2.757, p = 0.007) and β1 = 1.427 ( t = 3.243, \np = 0.001) were significant, while the cubic curve fitting was not \nsignificant, proving that the non-“S” curve and the inverted \nU-curve relationship regression equation can be  obtained: \ny = −0.122 (x2) + 1.187x + 2.311. Second, the independent variable \nwas squared and included in hierarchical regression, and Model \n3  in Table  1 shows that the square of decision autonomy \n(β2 = −0.142, p < 0.01) is significantly and negatively related to the \npurchase decision. However, Haans et al. argue that significant \ncoefficients alone are not sufficient to establish a quadratic \nrelationship (Haans et al., 2016). Therefore, using their research \nmethods on inverted U-shaped curves for reference, we use Stata \nto carry out the standardized “ U” test (the fitted Figure 2 is as \nfollows). The algorithmic decision autonomy ranges from −1.993 \nto 1.759, when at −1.993, the slope is 1.133, which is positive; at \n1.759, the slope is −0.633, which is negative. After calculation, the \nturning point is 0.414, which is within the range of the algorithmic \ndecision autonomy. Therefore, the hypotheses of H1a, H1b, H1c, \nand the inverted U-shape of H1 are fully verified.\nDiscussion\nStudy 1 shows the supporting evidence of the inverted \nU-shaped hypothesis of H1a, H1b, H1c, and H1, that is, different \nroles of algorithm agents have significantly different effects on \nconsumers’ purchase decisions. Compared with higher and lower \nalgorithmic decision-making autonomy, when the algorithmic \ndecision-making is a collaborative assistant (the autonomy is at a \nmiddle level), the impact of consumers’ purchase decisions is the \nhighest, followed by the other two, and the two slopes are positive \nfirst and then negative, thus showing an inverted U-shaped \nrelationship between the impact of algorithmic decision autonomy \non the consumer purchase decision.\nStudy 2: Mediating effect of self-efficacy\nPre-study 2\nStimuli and design\nWe conducted pre-study 2 against the background of the \ndecision to purchase a home AI service robot. Using a one-way \nbetween-groups experimental design to describe the materials of \nthree different algorithm decision-making autonomy of home AI \nrobot. A total of 80 participants were recruited through an online \nexperimental platform, and they were randomly divided into three \ngroups (home AI robot algorithm decision-making autonomy is \nhigh vs. middle vs. low, and the proportion of the three groups of \nsubjects is 27:27:26). After the manipulation, as in study 1, the \neffectiveness of the manipulation of the was measured by four \nalgorithmic decision autonomy questions and the overall \nmanipulation judgment question “ According to the decision-\nmaking scene, do you think its role belongs to a pure performer \npure performer/co-assistant/dictatorial substitute?” is asked to \ngive an overall judgment on the role of the algorithm agent by \nparticipants (Lucia-Palacios and Pérez-López, 2021). In addition, \nan attention item was set to test whether the subjects answered \ncarefully. After the experiment, the participants were given a \ncertain reward.\nResults\nANOV A analysis showed that there was a significant \ndifference between the subjects’ autonomy of algorithmic \ndecision-making for the three groups ( F (2, 77) = 65.754, \np < 0.001), and the cross-tabulation analysis of manipulation \njudgment questions between the experimental groups and the \noverall algorithmic agent role showed that participants with high \nautonomy of algorithmic decision-making preferred the algorithm \nto the role of “dictatorial substitute” role (85.2%); participants with \nmoderate algorithmic decision autonomy preferred the role of \n“co-assistant” (96.3%); participants with low algorithmic decision \nautonomy preferred the role of “pure executor” (88.5%). The \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 08 frontiersin.org\nPearson chi-square test and Monte Carlo two-tailed test were both \nsignificant. Post hoc  multiple comparison analysis Dunnett’s \ntwo-tailed t-test showed significant differences between the two \ngroups ( p = 0 < 0.05), indicating that the experimental \nmanipulation test was successful and that the experimental \ncontext and information will be used in study 2.\nStudy 2\nStudy design and procedures\nStudy 2 used a one-way between-group experimental design \n(algorithmic decision autonomy high vs. middle vs. low). Two \ndimensions of consumer purchase decisions, decision quality and \ndecision satisfaction (Amason, 1996; Ameen et  al., 2021), and \nself-efficacy (Köhler et al., 2011), were added. All were measured on \na seven-point Likert scale. The procedures and content of the rest of \nthe formal experiment were identical to the Pre-study. As in Study 1, \nthe sample size was measured before the formal experiment, and the \ncalculated sample size should reach more than 159. Therefore, 170 \nparticipants were recruited through the Credamo platform for this \nstudy, and participants were randomly assigned to 3 groups. The \nsample distribution of each group was Nhigh = 57, Nmiddle = 57, Nlow = 56 \n(female, 65.3%); the proportion of the age group was concentrated \nbetween 18 and 50 years old about 90%, and the education level was \nconcentrated in the undergraduate level (71.2%); and the \noccupational distribution, the majority of the respondents were \nstudents, managers, clerical and administrative personnel, etc., and \nthe occupational distribution was relatively even; more than half \n(69.4%) of the subjects’ monthly income exceeding RMB 3,000, so \nthe valid sample composition is reasonable.\nResults\nFirst, direct effects were tested. The results of ANOV A analysis \nwith purchase decisions as the dependent variable showed that the \neffect of algorithmic decision autonomy on purchase decisions \nwas significant (F (2, 167) = 21.072, p < 0.001). Meanwhile, when \nalgorithmic decision autonomy was at a middle level, the impact \nof consumer purchase decision evaluation was largest, followed by \nthe other two ( Mmiddle = 5.511 > Mhigh = 5.206 > Mlow = 4.246), the \nmean equality robustness test was significant, and the Dunnett’s t \ntwo-tailed test showed significant differences between the two \ngroups (p = 0 < 0.05), which confirmed the H1b again.\nNext, the inverted U-shaped effect of algorithmic decision \nautonomy on consumer purchase decisions is verified. First, the \nregression estimation fit of the curves was performed, and the \nresults showed that the quadratic and primary terms standardized \nTABLE 1 Regression results.\nVariables Purchase decisions (Study 1) Purchase decisions (Study 2) Self-efficacy (Study 2)\nModel 1 Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8 Model 9 Model 10\nControl variables\nGender 0.144 0.028 0.024 0.243 0.071 0.076 0.162 −0.03 −0.129 −0.129\nAge 0.175 0.138 0.104 0.067 0.142 0.172 0.164* −0.035 0.008 0.012\nEducation −0.140 −0.102 −0.203 −0.284 −0.27 −0.242 −0.054 −0.295* −0.286* −0.283*\nOccupation −0.051 −0.043 −0.044 −0.022 −0.029 −0.033 −0.018 −0.017 −0.021 −0.022\nIncome 0.095 0.055 0.106 0.060 0.034 0.032 −0.013 0.083 0.068 0.068\nFamiliarity 0.003 0.009 0.086 0.123 0.088 0.121 −0.029 0.242** 0.221** 0.226**\nIndependent variables\nADA 0.177** 1.327** 0.398*** 1.2*** 0.978*** 0.23*** 0.333\nADA2 −0.142** −0.099** −0.09*** −0.013\nMediator\nSelf-efficacy 0.668***\nR2 0.03 0.072 0.125 0.045 0.325 0.368 0.603 0.085 0.222 0.223\nR2 change 0.03 0.043 0.053 0.045 0.280 0.043 0.236 0.085 0.137 0.001\nF-value 0.778 1.689 2.691** 1.278 11.13*** 11.701*** 27.056*** 2.513* 6.602*** 5.776***\n*p < 0.05; **p < 0.01; ***p < 0.001; “ ADA ” is algorithmic decision autonomy.\nFIGURE 2\nInverted U-shaped curve fitting (Study 1).\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 09 frontiersin.org\nregression coefficients of β2 = −0.969 (t = −2.891, p = 0.004) and \nβ1 = 1.481 (t = 4.419, p = 0.000) were significant, while the cubic \ncurve fitting was not significant, proving that the non-“S” curve \n(the fitted Figure  3), the regression equation for the inverted \nU-curve relationship can be  initially verified: \ny = −0.087(X2) + 1.096X + 2.131. The independent variable was \nsquared and included in the hierarchical regression, and Models \n4–7 in Table 1 show that the square of decision autonomy (Model \n6, β2 = −0.099, p < 0.01) was significantly negatively correlated with \npurchase decisions, and the square of algorithmic decision \nautonomy remained significantly negatively correlated with \npurchase decision after adding the self-efficacy (Model 7, \nβ2 = −0.090, p < 0.001). After standardization, algorithmic decision \nautonomy ranges from −1.992 to 1.704, when at −1.992, the slope \nis 5.341, which is positive; and at 1.704 is −1.822, which is \nnegative. After calculation, the turning point is 0.764, which is \nwithin the range of algorithmic decision autonomy. Therefore, \nH1a, H1b, H1c, and H1 are again supported.\nMediating effects\nFinally, to test the mediating effect of algorithmic decision \nautonomy on purchase decisions. The results of the \nhierarchical regression with self-efficacy as the dependent \nvariable in Table  1  (Model 9–10) show that there is a \nsignificant positive effect of algorithmic decision autonomy on \nself-efficacy (Model 9, β = 0.230, p < 0.001). None of the \ncoefficients are significant after adding the quadratic of \nalgorithmic decision-making (Model 10), which shows that \nthere is no inverted U-shaped relationship, there is only a \nlinear positive effect, and hypothesis H2 is supported. \nMeanwhile, self-efficacy has a significant positive effect on \nconsumer purchase decisions (Model 7, β = 0.668, p < 0.001), \nand H3 is supported.\nTo further obtain a more accurate mediating effect of self-\nefficacy, we refer to the research method recommended by Lin \nand Feng (2022)  on curve effect in management and use the \nBootstrap curve mediating test to obtain confidence intervals \n(Lin and Feng, 2022 ). Using the MEDCURVE in SPSS with \nsampling set at 5,000 times and covariates are added, the \nresults show that the total effect of the model is significant, \nthe 95% confidence interval for the bias corrected bootstrap \nconfidence interval for instantaneous indirect effect is \n[0.0879, 0.2436], which does not contain 0, and the value of \nthe instantaneous indirect effect is 0.1535, indicating that the \nmediating effect is significant. In addition, the results of the \nBootstrap mediating effect test show that ( Table 2) the total \neffect of the model is significant, the effect value is 0.398, and \nthe 95% confidence interval is [0.3019, 0.4937], excluding 0; \nThe direct effect of algorithmic decision autonomy on \nconsumer purchase decisions is significant, the effect value is \n0.2421, and the 95% confidence interval is [0.1587, 0.3256], \nexcluding 0; the mediating effect value of algorithmic decision \nautonomy on purchase decision through self-efficacy is \n0.1557, Bootstrap  95% confidence interval is [0.0793,  \n0.2427], does not contain 0, and the mediating effect \npercentage is 39.140%, which is an incomplete mediation. In \nsummary, it is indicated that self-efficacy plays a partially \nmediating role in the process of the influence of algorithmic \ndecision autonomy on purchase decisions, which corroborates  \nthe H4.\nDiscussion\nStudy 2 shows that algorithmic decision autonomy has a \npositive effect on consumers’ self-efficacy, self-efficacy has a \npositive effect on consumers’ purchase decisions, and self-efficacy \npartially mediates the inverted-U relationship between algorithmic \ndecision autonomy and purchase decisions. In fact, this can also \nbe reflected in the results of the hierarchical regression, because \nModels 6–7 in Table 1 show that the square of algorithmic decision \nautonomy is significantly negatively correlated with purchase \ndecisions, but the correlation coefficient decreases. However, \nconsumers with different power distance perceptions have \ninherently different preferences for decision-making, which is a \nprerequisite to influencing self-efficacy. Therefore, in the next \nstudy, we  will explore the moderating effect of consumer \npower distance.\nFIGURE 3\nInverted U-shaped curve fitting (study 2).\nTABLE 2 Mediating effects of self-efficacy (N = 170).\nEffects \ntype\nSpecific \npaths\nEffect \nvalue\nStandard \nerror\n95% confidence \nintervals\nLower \nCI\nUpper \nCI\nTotal effect / 0.3978 0.0486 0.3019 0.4937\nDirect \neffect\nADA-PDa 0.2421 0.0423 0.1587 0.3256\nIndirect \neffect\nADA-SE-\nPDb\n0.1557 0.0415 0.0793 0.2427\naAlgorithmic decision autonomy—purchase decisions.\nbAlgorithmic decision autonomy—self-efficacy—purchase decisions.\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 10 frontiersin.org\nStudy 3: Moderating effect of power \ndistance\nPre-study 3\nStudy design and procedures\nThis experiment used a 3 (algorithmic decision autonomy: \nhigh vs. middle vs. low) × 2 (power distance: high vs. low) \nbetween-group experimental design. 130 participants were \nrecruited for the pre-experiment, and the participants’ sense of \npower distance was first manipulated experimentally. Using role \nimagination to realize the manipulation of power distance (Rucker \net al., 2014). According to the process control design of the data \ncollection platform, participants are randomly entered into a \nscenario where participants are told to imagine themselves as the \nmanager or employee of a company while reading a description of \na role (Rucker et al., 2012), corresponding to high and low power \ndistances, respectively. Referring to the eight measures proposed \nby Anderson for the manipulation test (including four reverse \nmeasures; Anderson et  al., 2012 ). Then participants were \nrandomly assigned to three different algorithmic decision \nautonomy scenarios by the platform. The testing procedure of the \nexperiments is similar to studies 1 and 2, but to improve the \ngeneralizability and external validity of this study, the stimulus \nmaterials are based on an AI shopping guide service program of \nan e-commerce platform.\nResults\nANOV A analysis results show that there is a significant \ndifference in the subjects’ decision-making autonomy of the three \ngroups of algorithms (F (2, 127) = 174.624, p < 0.001). The cross-\ntable analysis between the experimental group of algorithm \ndecision-making autonomy and the overall algorithm agent role \nshows that participants with high autonomy in algorithmic \ndecision-making preferred the role of “dictatorial substitute” \n(72.1%); participants with middle autonomy preferred the role of \n“co-assistant” (97.7%); participants with low autonomy preferred \nthe role of “pure executor” (84.1%). The Pearson chi-square test \nand Monte Carlo two-tailed test are significant, and the post hoc \nmultiple comparison analysis Dunnett’s t-test (two tailed) test \nshowed that there was a significant difference between the two \ngroups (p = 0 < 0.05). The results of power distance manipulation \nshowed that the high-power distance group was significantly \nhigher than the low power distance group ( Mhigh = 6.018, \nMlow = 2.528, F (1, 128) = 397.643, p = 0). It shows that the \nexperiments were successful in manipulating algorithmic decision \nautonomy and power distance, and the experimental context and \ninformation will be used in the formal experiment.\nStudy 3\nStimuli and design\nThe purpose of Study 3 was to examine whether the effect of \nalgorithmic decision autonomy on consumer self-efficacy varies \ndepending on individual power distance and to explore \nthe   moderating effect of consumer power distance. The \nformal experiment was fully consistent with the pretest, and the \nscales were consistent with Study 1 and 2 (see the \nSupplementary material), Cronbach’s α was above 0.9. A total of \n180 participants participated in the experiment, and participants \nwere randomly assigned to six groups. The sample distribution \nof each group was Nhigh ADA = 59, Nmiddle ADA = 61, Nlow ADA = 60; Nhigh \nPD = 89, Nlow PD = 91 (ADA: algorithmic decision autonomy; PD: \npower distance). The proportion of females is 63.3%; the age \ngroup is concentrated in the 18–30 years old, accounting for \nabout 92.8%; and the education level is concentrated in the \nundergraduate stage, accounting for 78.3%; The occupation \ndistribution is relatively uniform, and the basic information \ncomposition of effective samples is reasonable.\nResults\nFirst, is the direct effect test. The results of ANOV A analysis \nwith purchase decisions as the dependent variable show that \nthe effect of algorithmic decision autonomy on purchase \ndecisions is significant ( F (2, 177) =104.252, p < 0.001), while \nthe impact of consumer purchase decision evaluation is largest \nwhen algorithmic decision autonomy is at a middle level, \nfollowed by the other two ( Mmiddle = 5.592 > Mhigh =  \n5.057 > Mlow = 2.983). The mean value equality robust test is \nsignificant, and the variance homogeneity is significant. The \nDunnett’s two tailed t-test of post hoc multiple comparative \nanalysis shows that there are significant differences between the \ntwo groups ( p < 0.05). The fitting results of curve regression \nestimation show that the standardized regression coefficients \nof quadratic and primary terms are β2 = −1.322(t = −3.640, \np = 0.000), β1 = 1.851 (t = 5.097, p = 0.000) are significant (the \nfitted Figure 4 ), and the inverted U-shaped curve regression \nequation can be obtained: y = −0.134 (x2) + 1.538x + 0.941. The \nindependent variables are squared and included in the \nhierarchical regression, and Model 3 in Table 2 shows that the \nFIGURE 4\nInverted U-shaped curve fitting (Study 3).\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 11 frontiersin.org\nquadratic and primary terms of the algorithm decision-making \nautonomy are significantly correlated with the purchase \ndecisions (Model3, β2 = −0.151, β1 = 1.668, p < 0.001), and H1 \nis verified.\nModerating effects\nAs can be  seen from Table  3, when the moderating and \nmediating variables and their interaction terms are added in turn, \nthe coefficients of the quadratic terms are not significant (model \n4–8), so the moderating variables do not have a significant \nmoderating effect on the inverted U-shaped relationship. The \nresults of the hierarchical regression with self-efficacy as the \ndependent variable (models 9–14) show, that the coefficients of \nthe quadratic terms and their interaction terms are also not \nsignificant when the moderating variables and their interaction \nterms were added in turn. So, the moderating variables do not \nhave a significant moderating effect on the inverted U-shaped \nrelationship. However, a linear moderating relationship can \nbe found in models 10–13, because the primary term coefficient \nand interaction are significant (model 13), so there is a linear \nmoderating effect.\nModerated mediation analysis\nThrough the PROCESS provided by Hayes, Model 8 of \nBootstrap was selected to further do the mediated model test \nwith moderation, setting the sample size at 5,000 and the \nconfidence interval at 95%, and the regression model results \nwere obtained as shown in Table 4, where it can be found that \nthe moderating effect (interaction term) was significantly \nnegative when self-efficacy was the dependent variable \n(β = −0.098, p < 0.01); while the moderating effect (interaction \nterm) was significantly negative ( β = −0.060, p < 0.01) when \npurchase decisions were the outcome variable. Further results \nshow ( Table  5) that the mediating index with moderation \nwas-0.0582, and the bootstrap  95% CI interval is [ −0.0987, \n−0.0171], which did not contain 0, so the mediating effect with \nmoderation was significant. When algorithmic decision \nautonomy was low, the mediation effect of self-efficacy was \n0.1732, the bootstrap 95% CI interval did not contain 0, and the \nmediation was significant; when algorithmic decision autonomy \nwas high, the mediation effect of self-efficacy is −0.0555, \nbootstrap 95% CI interval contained 0, and the mediation was \nnot significant; while the contrasts between the effects were \nall significant.\nTo visualize the moderating effect of power distance, the \nmoderating effects of power distance on self-efficacy and purchase \ndecisions are plotted in Figures 5, 6. Consumers with low power \ndistance perceive that algorithmic decision autonomy can bring \nthem ease of decision-making, and do not experience algorithmic \ndecision aversion even when the level of algorithmic decision \nautonomy is high. Whereas, people with high power distance have \nmore status (Kim and Zhang, 2014) and self-confidence and focus \non their emotional self-evaluation of being accepted by society so \nthat when the level of algorithmic decision autonomy is high \ncompared to those with a low power distance sense will instead \ncause them to lose their level of self-determination evaluation, \nreduce their self-efficacy, and negatively affect the purchase \ndecisions. Also, it can be seen from the figure that algorithmic \ndecision-making varies more with different degrees of autonomy \nfor consumers with low power distance perception. Consumers \nwith low power distance had higher self-efficacy and purchase \ndecision influence than those with high power distance at the \nsame level of autonomy.\nDiscussion\nThe results of Study 3 support H5 and H6 that power distance \nmoderates the effect of algorithmic decision autonomy on \nconsumers’ self-efficacy and purchase decisions, but not on the \ninverted U-shaped relationship. Because people with high power \ndistance have higher self-efficacy: autonomy, competence, and \nrelationship. When algorithmic decision autonomy is high, \nartificial intelligence substitutes for making decisions, and the role \nof algorithmic agents as “dictatorial substitutes” will instead \nthreaten the self-efficacy of the high-power distance, cannot \nreflect their superiority, and the evaluation of the purchase \ndecisions will be correspondingly low.\nGeneral discussion\nThe ability to predict consumer behavior and decisions is a \nmust for business success (Struhl, 2017), therefore, more and more \ncompanies are using algorithms to make business decisions that \ndirectly affect potential and existing customers (Y alcin et al., 2022), \nusing algorithms to collect and process information about data \ngenerated by consumers during shopping activities to make \nautomated decisions about data analytics (Helbing et al., 2018), \ndriving a shift from descriptive to predictive models for algorithmic \ndata analysis. However, various problems arising from the use of \nautonomous algorithm decision-making also make people face the \nrisks and challenges it brings, and even cause humans to lose \ncontrol of it (Günther et al., 2017). Peter F . Drucker also warned \nthat “unless we control the new power extended by knowledge, it \nis difficult for humans to continue to survive. ” Therefore, our \nresearch provides support for understanding consumers’ responses \nto algorithmic decision-making and also provides insights and \nmanagement recommendations to address this phenomenon.\nConclusion\nThrough three studies, we verify the consumer’s response \nto different algorithmic decision autonomy. Study 1 confirmed \nthe inverted U-shaped effect of algorithmic decision autonomy \non consumer purchase decisions, that is, lower levels of \nalgorithmic decision autonomy have a negative influence on \nconsumer purchase decisions; when algorithmic decision \nautonomy is at a middle level, which is the most comfortable \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 12 frontiersin.org\nTABLE 3 Regression results.\nVariables Purchase decisions (Study 3) Self-efficacy (Study 3)\nModel 1 Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8 Model 9 Model 10 Model 11 Model 12 Model 13 Model 14\nControl variables\nGender 0.001 0.048 0.096 0.086 0.086 0.08 0.069 0.084 −0.132 −0.12 −0.065 −0.03 0.022 0.019\nAge −0.032 −0.156 −0.145 −0.157 −0.157 −0.172 −0.097 −0.085 −0.246 −0.277 −0.264 −0.219 −0.122 −0.131\nEducation 0 0.022 −0.028 −0.028 −0.028 −0.006 −0.002 0.021 0.02 0.026 −0.032 −0.033 −0.02 −0.007\nOccupation 0.022 0.006 0.017 0.018 0.018 0.017 −0.02 −0.009 0.048 0.044 0.057 0.054 0.065* 0.064*\nIncome −0.142 −0.02 0.047 0.043 0.043 0.043 0.03 0.011 −0.051 −0.021 0.056 0.071 0.024 0.023\nFamiliarity 0.275* 0.167 0.221* 0.218* 0.218* 0.225* 0.012 0.027 0.339* 0.312* 0.374** 0.384** 0.365** 0.369**\nIndependent variables\nADA 0.452*** 1.668*** 1.633*** 1.632*** 2.142** 0.777 0.25 0.113 1.501*** 1.634*** 2.057*** 2.368**\nADA2 −0.151*** −0.147*** −0.147*** −0.209* −0.078 −0.023 −0.172*** −0.187*** −0.19*** −0.228**\nModerator\nPD 0.039 0.038 0.23 0.01 0.12 −0.146* 0.265* 0.382\nADA × PD 0 −0.124 −0.023 0.096 −0.1** −0.176\nADA2 × PD 0.015 0.01 −0.003 0.009\nMediator\nSE 0.577*** 0.889***\nSE × PD −0.069**\nR2 0.031 0.314 0.371 0.373 0.373 0.375 0.664 0.681 0.052 0.068 0.135 0.165 0.218 0.219\nR2 change 0.031 0.283 0.056 0.002 0 0.002 0.288 0.018 0.052 0.016 0.066 0.03 0.053 0.001\nF-value 0.927 11.266*** 12.591*** 11.239*** 10.056*** 9.181*** 27.49*** 27.312*** 1.597 1.803*** 3.322*** 3.727*** 4.717*** 4.283***\n*p < 0.05; **p < 0.01; ***p < 0.001; ADA is algorithmic decision autonomy; PD is power distance; SE is self-efficacy.\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 13 frontiersin.org\nagent relationship, it reaches the largest influence on consumer \npurchase decisions; and when algorithmic decision autonomy \nis high, it will have a negative influence on consumer purchase \ndecisions. Study 2 explored the mediating mechanism of \nalgorithmic decision autonomy on consumers’ purchase \ndecisions, that is, algorithmic decision autonomy has a positive \neffect on consumer self-efficacy, which in turn has a positive \neffect on consumer purchase decisions, ultimately, self-efficacy \npartially mediates the inverted U relationship between \nalgorithmic decision autonomy and purchase decisions. Study \n3 showed that the effect of algorithmic decision autonomy on \nconsumer purchase decisions varies depending on the \nconsumer’s sense of power distance. For consumers with a low \npower distance, the effect of algorithmic decision autonomy on \nconsumer purchase decisions was more significant than for \nconsumers with a high-power distance.\nTheoretical implications\nThe theoretical implications of this research are: Firstly, \nwe provide a clear and detailed definition and classification of AI \nalgorithmic decision autonomy and conduct the first empirical \nstudy to investigate the inverted U-shaped impact of algorithmic \ndecision autonomy on consumer purchase decisions. The findings \nfurther illustrate the differences in the impact of different degrees \nof algorithmic decision autonomy on consumer purchase \ndecisions. Previous studies have argued for either algorithmic \nappreciation (Banker and Khetani, 2019 ; Logg et  al., 2019) or \nalgorithmic aversion (Dietvorst et al., 2015; Zhang et al., 2022) of \nalgorithmic decision-making, but the impact of algorithmic \ndecision autonomy on consumer purchase decisions has not been \nfully explored. We investigated the inverted U-shaped influence of \nalgorithmic decision autonomy on consumer purchase decisions. \nIn other words, there is an optimal state of influence of algorithmic \ndecision autonomy on consumer purchase decisions: as the degree \nof algorithmic decision autonomy gradually increases from low to \nhigh, the quality of consumer purchase decisions and decision \nsatisfaction show a trend of first increasing and then decreasing. \nAlgorithmic decision-making belongs to the role of middle-level \ncollaborative decision-maker, which is better than low-level pure \nexecutors and high-level autonomous dictatorial substitute.\nSecondly, the research enriches the potential mechanism of the \nrelationship between algorithmic decision autonomy and consumer \nFIGURE 5\nThe moderating effect of power distance on self-efficacy.\nFIGURE 6\nThe oderating effect of power distance on purchasing decisions.\nTABLE 4 Bootstrap regression results.\nVariables Self-efficacy Purchase decisions\nCoeff SE t Coeff SE t\nControl variables\nGender −0.046 0.245 −0.187 0.061 0.146 0.417\nAge −0.147 0.171 −0.861 −0.089 0.103 −0.869\nEducation 0.043 0.262 0.163 −0.005 0.157 −0.032\nOccupation 0.051 0.032 1.623 −0.023 0.019 −1.223\nIncome −0.062 0.124 −0.499 0.014 0.074 0.192\nFamiliarity 0.2965* 0.131 2.260 −0.011 0.080 −0.140\nIndependent variables\nADA 0.099 0.064 1.535 0.389*** 0.039 10.038\nModerator\nPD −0.118* 0.059 −1.980 −0.132*** 0.036 3.678\nInt_1 −0.098** 0.031 −3.176 −0.060** 0.019 3.173\nMediator\nM_SE 0.596*** 0.046 12.984\nR 0.373 0.812\nR2 0.139 0.660\nF 3.049** 32.786***\n*p < 0.05; **p < 0.01; ***p < 0.001; ADA is algorithmic decision autonomy; PD is power \ndistance; M_SE is self-efficacy; “Int_1” is ADA × PD.\nTABLE 5 Moderated mediating effects.\nPaths Effects \nindicators\nEffect \nINDEX\nBoot \nSE\nBoot \nLLCI\nBoot \nULCI\nIndirect \neffect \n(X-M-Y)\nPower distance −0.0582 0.0206 −0.0983 −0.0171\n−1.9645 \n(M − SD)\n0.1732 0.0532 0.067 0.2729\n(M = 0) 0.0588 0.0402 −0.0213 0.1362\n1.9645(M + SD) −0.0555 0.0605 −0.1766 0.0598\nPairwise \ncontrast\neff2–eff1 −0.1144 0.0405 −0.1931 −0.0336\neff3–eff1 −0.2287 0.0809 −0.3861 −0.0673\neff3–eff2 −0.1144 0.0405 −0.1931 −0.0336\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 14 frontiersin.org\npurchase decisions and contributes to the exploration of the impact \nmechanism of algorithmic decisions on consumer behavior. Previous \nstudies usually take psychological resistance, identity threat, privacy \nconcerns, trust, or consumer’s empathy for algorithms as mediating \nmechanisms. Based on the self-determination theory, our research, \nfrom the perspective of consumers, has clearly defined consumers’ \nautonomy in algorithm decision-making and explored the mediating \nmechanism of self-efficacy based on previous work on consumers’ \ndifferent perceptions of humans and algorithms.\nThirdly, we  investigate an important factor that influences \nconsumer responses to the autonomy of different algorithmic \ndecisions: the power distance. Previous studies have mostly \nexplored the moderating role of algorithmic anthropomorphic \nfeatures, communication style, or subjective and objective task \ncharacteristics when deploying algorithms from the perspective of \nAI itself. In this paper, we  explain the boundary effects of \nalgorithmic decision autonomy on purchase decisions by \nintroducing power distance perception as a moderating variable \nand providing insight into other possible moderation.\nFinally, this research also enriches the literature related to AI \nalgorithmic marketing. Although algorithmic decision-making is \nprevalent in the marketing environment, current research on \nusers’ psychological and behavioral responses in AI marketing is \nmostly qualitative, such as interview research and conceptual \nmodel construction, and lacks analytical support of empirical data \nand in-depth exploration of mechanisms. However, understanding \nthe psychological mechanisms and behavioral attitudes of \nconsumers toward AI services and purchase decisions, as well as \nhow to design AI for consumers to quickly accept this shift in \nservice format, are issues that should be  of urgent concern to \nscholars in the current marketing field.\nPractical implications\nThe findings of this research have rich managerial \nimplications. First, our research shows the inverted U-shaped \neffect of algorithmic decision autonomy on consumer purchase \ndecisions. Therefore, for companies, there should be a “degree” of \nautonomy in using algorithmic decision-making, and “overdoing \nit” should be avoided. While adapting to the digital management \ntrend, companies should adopt the appropriate role of algorithmic \nagents to serve the consumer’s decision, and not let the algorithmic \ndecision make the human perceive the loss of autonomy. The \nphilosopher Kant said that “human autonomy leads to free \nbehavior, and the absence of autonomy means the partial \ndisintegration of freedom and the complete disintegration of \nmorality. ” Therefore, companies should explore personalized \nalgorithm design to highlight human control over algorithmic \ndecision-making, and giving consumers a sense of self-control and \nautonomy in the purchase decision process may be a better choice.\nSecond, research shows that consumer self-efficacy plays a \nmediating role between algorithmic decision-making autonomy \nand purchase decisions, so companies should focus on enhancing \nusers’ self-efficacy. For example, by enhancing the sense of \nparticipation and co-creation in the user’s algorithmic decision-\nmaking process, consumers can perceive their existence as unique \nindividuals who have not lost their absolute dominant decision-\nmaking power in the algorithmic decision-making process. \nDuring the purchase decision task, set up techniques and \ncorresponding guidance procedures to stimulate customers’ self-\nefficacy and make them believe that they can cope with various \nchallenges in the purchase decision process.\nThird, due to the negative moderating effect of power distance, \nretailers should form a portrait of different power distance \nconsumers by using big data analysis to adopt different degrees of \nautonomy in algorithmic decision-making. For consumers with \nhigh power distance, a lower degree of algorithmic decision \nautonomy should be adopted because people with high power \ndistance follow the dynamic orientation of power in making \ndecisions for themselves, value their value and importance, and \nfocus more on themselves, so a low degree of algorithmic \nautonomy will increase consumers’ sense of self-judgment and \nself-determination and satisfy their sense of self-efficacy; while for \nconsumers with low power distance, they should be  guided \nthrough oriented steps for proper guidance, enough to stimulate \ncustomers’ self-efficacy and improve decision evaluation.\nFinally, retail enterprises can establish an algorithm application \nimpact assessment system and build a perfect user feedback \nmechanism. For typical scenarios, enterprises should assess the \nimpact of algorithms on consumers’ interests and individuals’ basic \nrights before the algorithms are formally launched, take \ncorresponding preventive measures for the relevant risks found in \nthe assessment; and establish an algorithm transparency system to \ndisclose information related to the adoption of algorithms to \nrelevant departments and the public, including the purpose of \nadoption, application scenarios, and technical implementation of \nalgorithms, etc. For those algorithm decisions that may have a \nsignificant impact on individuals and society, companies should \nexplain the basic principles of the algorithms. Giving individuals the \nright to redress for algorithmic damages through algorithmic \napplication rules, and allowing individuals to dispute algorithmic \ndecisions and conduct manual reviews, etc. (Burton et al., 2020).\nLimitations and future research\nFirstly, this research only considers the division of algorithmic \nautonomy and does not distinguish between algorithmic decision \ntask types, whereas research has shown that people are more \nreluctant to use algorithms in more subjective tasks, and decision \ntasks are governed by personal tastes (Y eomans et al., 2019), so \nfuture research could consider the triadic interaction of task type, \nalgorithmic decision autonomy, and consumers’ individual \ncharacteristics to explore the behavioral outcomes of consumer \ndecisions under the role of more contexts.\nSecondly, this research does not conduct follow-up research \non the results of consumer algorithm decision-making behavior, \nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 15 frontiersin.org\nresearch has shown that algorithms can have a significant impact \non consumers’ brand attitudes, and thus future research could \nexplore the chain-mediating mechanisms of consumers’ self-\nefficacy and purchase decision evaluation on consumers’ brand \nattitudes in terms of algorithmic decision autonomy (Srinivasan \nand Sarial-Abi, 2021).\nFinally, research by Martin and Waldman suggests that as \ndecision importance increases, individuals’ perceptions of the \nlegitimacy of using an algorithm to make a decision decrease \n(Martin and Waldman, 2022). Therefore, future research could \nexamine the role of decision importance and how to improve \nconsumers’ decision experiences.\nData availability statement\nThe original contributions presented in the study are included \nin the article/ Supplementary material, further inquiries can \nbe directed to the corresponding author.\nAuthor contributions\nFY supervised the study and performed a thorough review \nand revision of the manuscript. LX designed the study, analyzed \nthe data, and wrote the manuscript. All authors contributed \nequally to this manuscript, reviewed, and approved this \nmanuscript for publication.\nFunding\nThis work was supported by grants from the National Social \nScience Foundation of China (no: 18BJY167).\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbe construed as a potential conflict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the \nauthors and do not necessarily represent those of their affiliated \norganizations, or those of the publisher, the editors and the \nreviewers. Any product that may be evaluated in this article, or \nclaim that may be made by its manufacturer, is not guaranteed or \nendorsed by the publisher.\nSupplementary material\nThe Supplementary material for this article can be  found \nonline at: https://www.frontiersin.org/articles/10.3389/fpsyg.2022. \n1009173/full#supplementary-material\nReferences\nAmason, A. C. (1996). Distinguishing the effects of functional and dysfunctional \nconflict on strategic decision making: resolving a paradox for top management \nteams. Acad. Manag. J. 39, 123–148. doi: 10.2307/256633\nAmeen, N., Sharma, G. D., Tarba, S., Rao, A., and Chopra, R. (2022). Toward \nadvancing theory on creativity in marketing and artificial intelligence. Psychol. \nMark. 39, 1802–1825. doi: 10.1002/mar.21699\nAmeen, N., Tarhini, A., Reppel, A., and Anand, A. (2021). Customer experiences \nin the age of artificial intelligence. Comput. Hum. Behav. 114, 106548–106516. doi: \n10.1016/j.chb.2020.106548\nAnderson, C., John, O. P ., and Keltner, D. (2012). The personal sense of power. J. \nPers. 80, 313–344. doi: 10.1111/j.1467-6494.2011.00734.x\nAndré, Q., Carmon, Z., Wertenbroch, K., Crum, A., Frank, D., Goldstein, W ., et al. \n(2018). Consumer choice and autonomy in the age of artificial intelligence and big \ndata. Cus. Needs Solut. 5, 28–37. doi: 10.1007/s40547-017-0085-8\nAraujo, T., Helberger, N., Kruikemeier, S., and de Vreese, C. H. (2020). In AI \nwe trust? Perceptions about automated decision-making by artificial intelligence. AI \nSoc. 35, 611–623. doi: 10.1007/s00146-019-00931-w\nBaber, C. (1996). “Humans, servants and agents: human factors of intelligent \ndomestic products, ” in IEE Colloquium on Artificial Intelligence in Consumer and \nDomestic Products (IEE). Vol 4, 1–3.\nBandura, A. (1977). Self-efficacy: toward a unifying theory of behavioral change. \nPsychol. Rev. 84, 191–215. doi: 10.1037/0033-295X.84.2.191\nBanker, S., and Khetani, S. (2019). Algorithm overdependence: how the use of \nalgorithmic recommendation systems can increase risks to consumer well-being. J. \nPublic Policy Mark. 38, 500–515. doi: 10.1177/0743915619858057\nBechara, A., Damasio, H., Tranel, D., and Anderson, S. W . (1998). Dissociation of \nworking memory from decision making within the human prefrontal cortex. J. \nNeurosci. 18, 428–437. doi: 10.1523/jneurosci.18-01-00428.1998\nBeer, D. (2017). The social power of algorithms. Info. Commun. Soc. 20, 1–13. doi: \n10.1080/1369118X.2016.1216147\nBenbya, H., Davenport, T. H., and Pachidi, S. (2020). Artificial intelligence in \norganizations: current state and future opportunities. SSRN Electron. J. 19, 1–15. doi: \n10.2139/ssrn.3741983\nBenlian, A., Klumpe, J., and Hinz, O. (2020). Mitigating the intrusive effects of \nsmart home assistants by using anthropomorphic design features: a multimethod \ninvestigation. Inf. Syst. J. 30, 1010–1042. doi: 10.1111/isj.12243\nBo, X., and Benbasat, I. (2007). E-commerce product recommendation  \nagents: use, characteristics, and impact. MIS Q.  31, 137–209. doi: 10.2307/ \n25148784\nBonnefon, J. F ., Shariff, A., and Rahwan, I. (2016). The social dilemma of \nautonomous vehicles. Science 352, 1573–1576. doi: 10.1126/science.aaf2654\nBrown, K. W ., and Ryan, R. M. (2003). The benefits of being present: mindfulness \nand its role in psychological well-being. J. Pers. Soc. Psychol.  84, 822–848. doi: \n10.1037/0022-3514.84.4.822\nBurton, J. W ., Stein, M. K., and Jensen, T. B. (2020). A systematic review of \nalgorithm aversion in augmented decision making. J. Behav. Decis. Mak.  33, \n220–239. doi: 10.1002/bdm.2155\nČaić, M., Odekerken-Schröder, G., and Mahr, D. (2018). Service robots: value \nco-creation and co-destruction in elderly care networks. J. Serv. Manage.  29, \n178–205. doi: 10.1108/JOSM-07-2017-0179\nCannon, C., and Rucker, D. D. (2022). Motives underlying human agency: how \nself-efficacy versus self-enhancement affect consumer behavior. Curr. Opin. Psychol. \n46:101335. doi: 10.1016/j.copsyc.2022.101335\nChiodo, S. (2022). Human autonomy, technological automation (and reverse). AI \nSoc. 37, 39–48. doi: 10.1007/s00146-021-01149-5\nCohen, J. (1977). “F Tests on Means in the Analysis of Variance and Covariance, ” \nin Statistical Power Analysis for the Behavioral Sciences (Elsevier), 273–406.\nDanaher, J., Hogan, M. J., Noone, C., Kennedy, R., Behan, A., De Paor, A., et al. \n(2017). Algorithmic governance: Developing a research agenda through the power \nof collective intelligence. Big Data Soc. 4, 1–21. doi: 10.1177/2053951717726554\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 16 frontiersin.org\nDeci, E. L., and Ryan, R. M. (2000). The “What” and “Why” of goal pursuits: \nhuman needs and the self-determination of behavior. Psychol. Inq. 11, 227–268. doi: \n10.1207/S15327965PLI1104_01\nDietvorst, B. J., and Bharti, S. (2020). People reject algorithms in uncertain \ndecision domains because they have diminishing sensitivity to forecasting error. \nPsychol. Sci. 31, 1302–1314. doi: 10.1177/0956797620948841\nDietvorst, B. J., Simmons, J. P ., and Massey, C. (2015). Algorithm aversion: people \nerroneously avoid algorithms after seeing them err. J. Exp. Psychol. Gen.  144, \n114–126. doi: 10.1037/xge0000033\nDogruel, L., Facciorusso, D., and Stark, B. (2022). ‘I’m still the master of the \nmachine. ’ Internet users’ awareness of algorithmic decision-making and their \nperception of its effect on their autonomy. Inf. Commun. Soc. 25, 1311–1332. doi: \n10.1080/1369118X.2020.1863999\nDubey, R. K., Babu, A. S., Jha, R. R., and Varma, U. (2021). Algorithmic trading \nefficiency and its impact on market-quality. Asia-Pac. Financ. Mark 29, 381–409. \ndoi: 10.1007/s10690-021-09353-5\nFanchamps, N. L. J. A., Slangen, L., Hennissen, P ., and Specht, M. (2021). The \ninfluence of SRA programming on algorithmic thinking and self-efficacy using Lego \nrobotics in two types of instruction. Int. J. Technol. Des. Educ. 31, 203–222. doi: \n10.1007/s10798-019-09559-9\nFaraji-Rad, A., Melumad, S., and Johar, G. V . (2017). Consumer desire for control \nas a barrier to new product adoption. J. Consum. Psychol. 27, 347–354. doi: 10.1016/j.\njcps.2016.08.002\nGal, M. (2018). Algorithmic challenges to autonomous choice. Michigan Technol. \nLaw Rev. 25, 59–103. doi: 10.36645/mtlr.25.1.algorithmic\nGao, H., Winterich, K. P ., and Zhang, Y . (2016). All that glitters is not gold: how \nothers’ status influences the effect of power distance belief on status consumption. \nJ. Consum. Res. 43, 265–281. doi: 10.1093/jcr/ucw015\nGünther, W . A., Rezazade Mehrizi, M. H., Huysman, M., and Feldberg, F . (2017). \nDebating big data: a literature review on realizing value from big data. J. Strateg. Inf. \nSyst. 26, 191–209. doi: 10.1016/j.jsis.2017.07.003\nHaans, R. F . J., Pieters, C., and He, Z. L. (2016). Thinking about U: theorizing and \ntesting U-and inverted U-shaped relationships in strategy research. Strateg. Manag. \nJ. 37, 1177–1195. doi: 10.1002/smj.2399\nHale, D., Thakur, R., Riggs, J., and Altobello, S. (2021). Consumers’ decision-\nmaking self-efficacy for service purchases: construct conceptualization and scale. J. \nServ. Mark. 36, 637–657. doi: 10.1108/JSM-12-2020-0505\nHan, D., Duhachek, A., and Agrawal, N. (2016). Coping and construal level \nmatching drives health message effectiveness via response efficacy or self-efficacy \nenhancement. J. Consum. Res. 43, 429–447. doi: 10.1093/jcr/ucw036\nHan, D., Lalwani, A. K., and Duhachek, A. (2017). Power distance belief, \npower, and charitable giving. J. Consum. Res.  44, ucw084–ucw195. doi: 10.1093/\njcr/ucw084\nHelbing, D., Frey, B. S., Gigerenzer, G., Hafen, E., Hagner, M., Hofstetter, Y ., et al. \n(2018). Will democracy survive big data and artificial intelligence? Towar. Digit. \nEnlight. Essays. Dark. Light Sides Digit. Revolut. 7, 73–89. doi: 10.1007/978-3-319- \n90869-4_7\nHoffman, D. L., Moreau, C. P ., Stremersch, S., and Wedel, M. (2022). The rise of \nnew Technologies in Marketing: a framework and outlook. J. Mark. 86, 1–6. doi: \n10.1177/00222429211061636\nHofstede, G. (1980). Motivation, leadership, and organization: do American \ntheories apply abroad? Organ. Dyn.  9, 42–63. doi: 10.1016/0090-2616(80)90013-3\nHongjun, X. (2022). Algorithmic responsibility: theoretical justification, \npanoramic portrait and governance paradigm. J. Manage. World. 38, 200–226. doi: \n10.19744/j.cnki.11-1235/f.2022.0053\nHu, Q., Lu, Y ., Pan, Z., Gong, Y ., and Y ang, Z. (2021). Can AI artifacts influence \nhuman cognition? The effects of artificial autonomy in intelligent personal assistants. \nInt. J. Inf. Manag. 56:102250. doi: 10.1016/j.ijinfomgt.2020.102250\nHuang, M. H., and Rust, R. T. (2018). Artificial intelligence in service. J. Serv. Res. \n21, 155–172. doi: 10.1177/1094670517752459\nHuang, M. H., and Rust, R. T. (2021a). Engaged to a robot? The role of AI in \nservice. J. Serv. Res. 24, 30–41. doi: 10.1177/1094670520902266\nHuang, M. H., and Rust, R. T. (2021b). A strategic framework for artificial intelligence \nin marketing. J. Acad. Mark. Sci. 49, 30–50. doi: 10.1007/s11747-020-00749-9\nKachanoff, F . J., Wohl, M. J. A., Koestner, R., and Taylor, D. M. (2020). Them, us, \nand I: how group contexts influence basic psychological needs. Curr. Dir. Psychol. \nSci. 29, 47–54. doi: 10.1177/0963721419884318\nKaplan, A., and Haenlein, M. (2019). Siri, Siri, in my hand: Who’s the fairest in \nthe land? On the interpretations, illustrations, and implications of artificial \nintelligence. Bus. Horiz. 62, 15–25. doi: 10.1016/j.bushor.2018.08.004\nKim, K., Schmierbach, M. G., Bellur, S. (. S.)., Chung, M.-Y ., Fraustino, J. D., \nDardis, F ., et al. (2015). Is it a sense of autonomy, control, or attachment? Exploring \nthe effects of in-game customization on game enjoyment. Comput. Hum. Behav. 48, \n695–705. doi: 10.1016/j.chb.2015.02.011\nKim, S. Y ., Schmitt, B. H., and Thalmann, N. M. (2019). Eliza in the uncanny \nvalley: anthropomorphizing consumer robots increases their perceived warmth but \ndecreases liking. Mark. Lett. 30, 1–12. doi: 10.1007/s11002-019-09485-9\nKim, Y ., and Zhang, Y . (2014). The impact of power-distance belief on consumers’ \npreference for status brands. J. Glob. Mark.  27, 13–29. doi: 10.1080/08911762. \n2013.844290\nKöhler, C. F ., Rohm, A. J., de Ruyter, K., and Wetzels, M. (2011). Return on \ninteractivity: the impact of online agents on newcomer adjustment. J. Mark. 75, \n93–108. doi: 10.1509/jmkg.75.2.93\nKuo, F . Y ., Hsu, C. W ., and Day, R. F . (2009). An exploratory study of cognitive \neffort involved in decision under framing-an application of the eye-tracking \ntechnology. Decis. Support. Syst. 48, 81–91. doi: 10.1016/j.dss.2009.06.011\nLalicic, L., and Weismayer, C. (2021). Consumers’ reasons and perceived value \nco-creation of using artificial intelligence-enabled travel service agents. J. Bus. Res. \n129, 891–901. doi: 10.1016/j.jbusres.2020.11.005\nLau, O., and Ki, C.-W . (2021). Can consumers’ gamified, personalized, and \nengaging experiences with VR fashion apps increase in-app purchase intention by \nfulfilling needs? Fash. Text. 8:36. doi: 10.1186/s40691-021-00270-9\nLee, Y .-K. (2021). Impacts of digital technostress and digital technology self-\nefficacy on Fintech usage intention of Chinese gen Z consumers. Sustainability \n13:5077. doi: 10.3390/su13095077\nLeung, E., Paolacci, G., and Puntoni, S. (2018). Man versus machine: resisting \nautomation in identity-based consumer behavior. J. Mark. Res. 55, 818–831. doi: \n10.1177/0022243718818423\nLin, W ., and Feng, B. (2022). Curvilinear effect and statistical test method in the \nmanagement research. Nankai. Bus. Rev. 25, 155–166.\nLogg, J. M., Minson, J. A., and Moore, D. A. (2019). Algorithm appreciation: \npeople prefer algorithmic to human judgment. Organ. Behav. Hum. Decis. Process. \n151, 90–103. doi: 10.1016/j.obhdp.2018.12.005\nLongoni, C., Bonezzi, A., and Morewedge, C. K. (2019). Resistance to medical \nartificial intelligence. J. Consum. Res. 46, 629–650. doi: 10.1093/jcr/ucz013\nLucia-Palacios, L., and Pérez-López, R. (2021). Effects of home voice assistants’ \nautonomy on instrusiveness and usefulness: direct, indirect, and moderating effects \nof interactivity. J. Interact. Mark. 56, 41–54. doi: 10.1016/j.intmar.2021.03.005\nMahmud, H., Islam, A. K. M. N., Ahmed, S. I., and Smolander, K. (2022). What \ninfluences algorithmic decision-making? A systematic literature review on \nalgorithm aversion. Technol. Forecast. Soc. Change  175:121390. doi: 10.1016/j.\ntechfore.2021.121390\nMarjanovic, O., Cecez-Kecmanovic, D., and Vidgen, R. (2021). Algorithmic \npollution: making the invisible visible. J. Inf. Technol.  36, 391–408. doi: \n10.1177/02683962211010356\nMartin, K., and Waldman, A. (2022). Are algorithmic decisions legitimate? The \neffect of process and outcomes on perceptions of legitimacy of AI decisions. J. Bus. \nEthics. doi: 10.1007/s10551-021-05032-7\nMestel, R., Murg, M., and Theissen, E. (2018). Algorithmic trading and liquidity: \nlong term evidence from Austria. Financ. Res. Lett. 26, 198–203. doi: 10.1016/j.\nfrl.2018.01.004\nOECD (2017). Algorithms and Collusion: Competition Policy in the Digital Age. \nAvailable at: https://www.oecd.org/daf/competition/Algorithms-and-colllusion-\ncompetition-policy-in-the-digital-age.pdf (Accessed October 8, 2022).\nOrth, U. R., and Wirtz, J. (2014). Consumer processing of interior service \nenvironments: the interplay among visual complexity, processing fluency, and \nattractiveness. J. Serv. Res. 17, 296–309. doi: 10.1177/1094670514529606\nOyserman, D. (2006). High power, low power, and equality: culture beyond \nindividualism and collectivism. J. Consum. Psychol.  16, 352–356. doi: 10.1207/\ns15327663jcp1604_6\nPalmeira, M., and Spassova, G. (2015). Consumer reactions to professionals who \nuse decision aids. Eur. J. Mark. 49, 302–326. doi: 10.1108/EJM-07-2013-0390\nPalos-Sanchez, P ., Saura, J. R., and Martin-Velicia, F . (2019). A study of the effects \nof programmatic advertising on users’ concerns about privacy overtime. J. Bus. Res. \n96, 61–72. doi: 10.1016/j.jbusres.2018.10.059\nPantano, E., and Scarpi, D. (2022). I, robot, you, consumer: measuring artificial \nintelligence types and their effect on consumers emotions in service. J. Serv. \nRes.:109467052211035. doi: 10.1177/10946705221103538\nPaschen, J., Kietzmann, J., and Kietzmann, T. C. (2019). Artificial intelligence (AI) \nand its implications for market knowledge in B2B marketing. J. Bus. Ind. Mark. 34, \n1410–1419. doi: 10.1108/JBIM-10-2018-0295\nPrahalad, C. K., and Ramaswamy, V . (2004). Co-creation experiences: the next \npractice in value creation. J. Interact. Mark. 18, 5–14. doi: 10.1002/dir.20015\nFan and Liu 10.3389/fpsyg.2022.1009173\nFrontiers in Psychology 17 frontiersin.org\nPuntoni, S., Reczek, R. W ., Giesler, M., and Botti, S. (2021). Consumers and \nartificial intelligence: an experiential perspective. J. Mark.  85, 131–151. doi: \n10.1177/0022242920953847\nRijsdijk, S. A., and Hultink, E. J. (2009). How Today’s consumers perceive \ntomorrow’s smart products. J. Prod. Innov. Manag. 26, 24–42. doi: 10.1111/J.1540- \n5885.2009.00332.X\nRijsdijk, S. A., Hultink, E. J., and Diamantopoulos, A. (2007). Product intelligence: \nits conceptualization, measurement and impact on consumer satisfaction. J. Acad. \nMark. Sci. 35, 340–356. doi: 10.1007/s11747-007-0040-6\nRucker, D. D., Dubois, D., and Galinsky, A. D. (2011). Generous paupers and \nstingy princes: power drives consumer spending on self versus others. J. Consum. \nRes. 37, 1015–1029. doi: 10.1086/657162\nRucker, D. D., Galinsky, A. D., and Dubois, D. (2012). Power and consumer \nbehavior: how power shapes who and what consumers value. J. Consum. Psychol. 22, \n352–368. doi: 10.1016/j.jcps.2011.06.001\nRucker, D. D., Hu, M., and Galinsky, A. D. (2014). The experience versus the \nexpectations of power: a recipe for altering the effects of power on behavior. J. \nConsum. Res. 41, 381–396. doi: 10.1086/676598\nSchepers, J., Belanche, D., Casaló, L. V ., and Flavián, C. (2022). How smart should \na service robot be? J. Serv. Res.:109467052211077. doi: 10.1177/10946705221107704\nShin, D. (2021). The perception of humanness in conversational journalism: an \nalgorithmic information-processing perspective. New Media Soc.:146144482199380. \ndoi: 10.1177/1461444821993801\nShin, D. (2022). How do people judge the credibility of algorithmic sources? AI \nSoc. 37, 81–96. doi: 10.1007/s00146-021-01158-4\nShin, D., Kee, K. F ., and Shin, E. Y . (2022a). Algorithm awareness: why user \nawareness is critical for personal privacy in the adoption of algorithmic platforms? \nInt. J. Inf. Manag. 65:102494. doi: 10.1016/j.ijinfomgt.2022.102494\nShin, D., Lim, J. S., Ahmad, N., and Ibahrine, M. (2022b). Understanding user \nsensemaking in fairness and transparency in algorithms: algorithmic sensemaking \nin over-the-top platform. AI Soc. doi: 10.1007/s00146-022-01525-9\nShin, D., Rasul, A., and Fotiadis, A. (2022c). Why am I seeing this? Deconstructing \nalgorithm literacy through the lens of users. Internet Res. 32, 1214–1234. doi: \n10.1108/INTR-02-2021-0087\nShin, D., Zaid, B., Biocca, F ., and Rasul, A. (2022d). In platforms we  trust? \nUnlocking the black-box of news algorithms through interpretable AI. J. Broadcast. \nElectron. Media 66, 235–256. doi: 10.1080/08838151.2022.2057984\nSoll, J. B., and Mannes, A. E. (2011). Judgmental aggregation strategies depend on \nwhether the self is involved. Int. J. Forecast.  27, 81–102. doi: 10.1016/j.\nijforecast.2010.05.003\nSrinivasan, R., and Sarial-Abi, G. (2021). When algorithms fail: consumers’ \nresponses to brand harm crises caused by algorithm errors. J. Mark. 85, 74–91. doi: \n10.1177/0022242921997082\nStarke, C.,  and Lünich, M. (2020). Artificial intelligence for political decision-\nmaking in the European Union: effects on citizens’ perceptions of input, \nthroughput, and output legitimacy. Data Policy  2, 1–16. doi: 10.1017/dap.  \n2020.19\nStein, J. P ., and Ohler, P . (2017). Venturing into the uncanny valley of mind—\nthe influence of mind attribution on the acceptance of human-like characters in \na virtual reality setting. Cognition 160, 43–50. doi: 10.1016/j.cognition.2016.  \n12.010\nStruhl, S. (2017). Artificial intelligence marketing and predicting consumer \nchoice: An overview of tools and techniques. Kogan page; 1st edition (3 April \n2017), 270.\nThurai, A., and McKendrick, J. (2022). Overcoming the C-Suite’s distrust of AI. \nHarv bus rev. Available at: https://hbr.org/2022/03/overcoming-the-c-suitesdistrust-\nof-ai (Accessed June 19, 2022).\nvan Doorn, J., Mende, M., Noble, S. M., Hulland, J., Ostrom, A. L., Grewal, D., \net al. (2017). Domo arigato Mr. Roboto: emergence of automated social presence in \norganizational frontlines and customers’ service experiences. J. Serv. Res. 20, 43–58. \ndoi: 10.1177/1094670516679272\nWang, Y ., and Jiang, J. (2022). The effect of environmental disorderliness on \nvariety seeking behavior and its mechanism. Acta Psychol. Sin.  54, 78–90. doi: \n10.3724/SP .J.1041.2022.00078\nWhite, K., Habib, R., and Hardisty, D. J. (2019). How to SHIFT consumer \nbehaviors to be more sustainable: a literature review and guiding framework. J. \nMark. 83, 22–49. doi: 10.1177/0022242919825649\nXiao, B., and Benbasat, I. (2018). An empirical examination of the influence \nof biased personalized product recommendations on consumers’ decision \nmaking outcomes. Decis. Support. Syst.  110, 46–57. doi: 10.1016/j.dss.2018.  \n03.005\nY alcin, G., Lim, S., Puntoni, S., and van Osselaer, S. M. J. (2022). Thumbs up or \ndown: consumer reactions to decisions by algorithms versus humans. J. Mark. Res. \n59, 696–717. doi: 10.1177/00222437211070016\nY eomans, M., Shah, A., Mullainathan, S., and Kleinberg, J. (2019). Making \nsense of recommendations. J. Behav. Decis. Mak.  32, 403–414. doi: 10.1002/\nbdm.2118\nYin, J., and Qiu, X. (2021). Ai technology and online purchase intention: structural \nequation model based on perceived value. Sustainability (Switzerland)  13, \n5671–5687. doi: 10.3390/su13105671\nYunwen, L. (2021). Intelligent customer service is not “intelligent” but a \n“roadblock. ” finance.people.com.cn. Available at: http://finance.people.com.cn/\nn1/2021/0928/c1004-32239417.html (Accessed June 19, 2022).\nZhang, Y ., Xu, L., Yu, F ., Ding, X., Wu, J., and Zhao, L. (2022). A three-dimensional \nmotivation model of algorithm aversion. Adv. Psychol. Sci. 30, 1093–1105. doi: \n10.3724/sp.j.1042.2022.01093",
  "topic": "Autonomy",
  "concepts": [
    {
      "name": "Autonomy",
      "score": 0.8078696727752686
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.5949254631996155
    },
    {
      "name": "Marketing",
      "score": 0.5085395574569702
    },
    {
      "name": "Computer science",
      "score": 0.49530377984046936
    },
    {
      "name": "Consumer behaviour",
      "score": 0.4587540626525879
    },
    {
      "name": "Decision theory",
      "score": 0.44566407799720764
    },
    {
      "name": "Value (mathematics)",
      "score": 0.42836907505989075
    },
    {
      "name": "Psychology",
      "score": 0.36461496353149414
    },
    {
      "name": "Business",
      "score": 0.3071298599243164
    },
    {
      "name": "Artificial intelligence",
      "score": 0.23376035690307617
    },
    {
      "name": "Microeconomics",
      "score": 0.16816401481628418
    },
    {
      "name": "Economics",
      "score": 0.167339026927948
    },
    {
      "name": "Machine learning",
      "score": 0.12838920950889587
    },
    {
      "name": "Political science",
      "score": 0.07839378714561462
    },
    {
      "name": "Law",
      "score": 0.0
    }
  ]
}