{
  "title": "Large Language Models Are Poor Medical Coders â€” Benchmarking of Medical Code Querying",
  "url": "https://openalex.org/W4394943312",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2036204426",
      "name": "ali soroush",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1498187152",
      "name": "Benjamin S Glicksberg",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A855924086",
      "name": "Eyal Zimlichman",
      "affiliations": [
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    },
    {
      "id": "https://openalex.org/A2572125234",
      "name": "Yiftach Barash",
      "affiliations": [
        "Sheba Medical Center",
        "Tel Aviv University"
      ]
    },
    {
      "id": "https://openalex.org/A1968102139",
      "name": "Robert Freeman",
      "affiliations": [
        "Mount Sinai Health System"
      ]
    },
    {
      "id": "https://openalex.org/A2127182135",
      "name": "Alexander W. Charney",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A2170298636",
      "name": "GIRISH N. NADKARNI",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai"
      ]
    },
    {
      "id": "https://openalex.org/A1945837108",
      "name": "Eyal Klang",
      "affiliations": [
        "Icahn School of Medicine at Mount Sinai",
        "Tel Aviv University",
        "Sheba Medical Center"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2414800060",
    "https://openalex.org/W4307138871",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W2159583324",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W2889272240",
    "https://openalex.org/W2133459682",
    "https://openalex.org/W2803274241",
    "https://openalex.org/W4389519585",
    "https://openalex.org/W4385573636",
    "https://openalex.org/W4385571689",
    "https://openalex.org/W3212438831"
  ],
  "abstract": "BackgroundLarge language models (LLMs) have attracted significant interest for automated clinical coding. However, early data show that LLMs are highly error-prone when mapping medical codes. We sought to quantify and benchmark LLM medical code querying errors across several available LLMs.MethodsWe evaluated GPT-3.5, GPT-4, Gemini Pro, and Llama2-70b Chat performance and error patterns when querying medical billing codes. We extracted 12 months of unique International Classification of Diseases, 9th edition, Clinical Modification (ICD-9-CM), International Classification of Diseases, 10th edition, Clinical Modification (ICD-10-CM), and Current Procedural Terminology (CPT) codes from the Mount Sinai Health System electronic health record (EHR). Each LLM was provided with a code description and prompted to generate a billing code. Exact match accuracy and other performance metrics were calculated. Nonexact matches were analyzed using descriptive metrics and standardized measures of text and code similarity, including METEOR score, BERTScore, and cui2vec cosine similarity. We created and applied a CodeSTS manual similarity grading system to 200 randomly selected codes weighted by EHR code frequency. Using CodeSTS scores, we identified correct \"equivalent\" or \"generalized\" generated codes.ResultsA total of 7697 ICD-9-CM, 15,950 ICD-10-CM, and 3673 CPT codes were extracted. GPT-4 had the highest exact match rate (ICD-9-CM: 45.9%; ICD-10-CM: 33.9%; CPT: 49.8%). Among incorrectly matched codes, GPT-4 generated the most equivalent codes (ICD-9-CM: 7.0%; ICD-10-CM: 10.9%), and GPT-3.5 generated the most generalized but correct codes (ICD-9-CM: 29.9%; ICD-10-CM: 18.5%). Extracted code frequency, shorter codes, and shorter code descriptions were associated (P<0.05) with higher exact match rates in nearly all analyses.ConclusionsAll tested LLMs performed poorly on medical code querying, often generating codes conveying imprecise or fabricated information. LLMs are not appropriate for use on medical coding tasks without additional research. (Funded by the AGA Research Foundation and National Institutes of Health.)",
  "full_text": null,
  "topic": "Benchmarking",
  "concepts": [
    {
      "name": "Benchmarking",
      "score": 0.7075161933898926
    },
    {
      "name": "Computer science",
      "score": 0.6830378174781799
    },
    {
      "name": "Code (set theory)",
      "score": 0.5868995189666748
    },
    {
      "name": "Diagnosis code",
      "score": 0.4523318111896515
    },
    {
      "name": "Natural language processing",
      "score": 0.4137815535068512
    },
    {
      "name": "Programming language",
      "score": 0.37689679861068726
    },
    {
      "name": "Medicine",
      "score": 0.27168983221054077
    },
    {
      "name": "Business",
      "score": 0.09124496579170227
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.06615528464317322
    },
    {
      "name": "Marketing",
      "score": 0.0
    },
    {
      "name": "Population",
      "score": 0.0
    },
    {
      "name": "Environmental health",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98704320",
      "name": "Icahn School of Medicine at Mount Sinai",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I2799810450",
      "name": "Sheba Medical Center",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I16391192",
      "name": "Tel Aviv University",
      "country": "IL"
    },
    {
      "id": "https://openalex.org/I1320796813",
      "name": "Mount Sinai Health System",
      "country": "US"
    }
  ]
}