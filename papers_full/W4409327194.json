{
  "title": "Bearing fault diagnosis based on efficient cross space multiscale CNN transformer parallelism",
  "url": "https://openalex.org/W4409327194",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5102961064",
      "name": "Qi Chen",
      "affiliations": [
        "Huaqiao University"
      ]
    },
    {
      "id": "https://openalex.org/A5100401289",
      "name": "Feng Zhang",
      "affiliations": [
        "Huaqiao University"
      ]
    },
    {
      "id": "https://openalex.org/A5100715442",
      "name": "Yin Wang",
      "affiliations": [
        "Huaqiao University"
      ]
    },
    {
      "id": "https://openalex.org/A5100337761",
      "name": "Qing Yu",
      "affiliations": [
        "Huaqiao University"
      ]
    },
    {
      "id": "https://openalex.org/A5044182340",
      "name": "Genfeng Lang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5066577620",
      "name": "Lixiong Zeng",
      "affiliations": [
        "Huaqiao University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2896994063",
    "https://openalex.org/W4281398915",
    "https://openalex.org/W2884136488",
    "https://openalex.org/W2953885557",
    "https://openalex.org/W2523553285",
    "https://openalex.org/W4389194516",
    "https://openalex.org/W2404692435",
    "https://openalex.org/W1597576211",
    "https://openalex.org/W1989006121",
    "https://openalex.org/W2039951318",
    "https://openalex.org/W2097715699",
    "https://openalex.org/W2088202114",
    "https://openalex.org/W1964940342",
    "https://openalex.org/W2261059368",
    "https://openalex.org/W3033236487",
    "https://openalex.org/W2896784509",
    "https://openalex.org/W4385638651",
    "https://openalex.org/W4385577941",
    "https://openalex.org/W4392349400",
    "https://openalex.org/W3145770415",
    "https://openalex.org/W4398236356",
    "https://openalex.org/W4403332604",
    "https://openalex.org/W4400198006",
    "https://openalex.org/W4322724151",
    "https://openalex.org/W3142292878",
    "https://openalex.org/W4392882950",
    "https://openalex.org/W4210282624",
    "https://openalex.org/W4210440620",
    "https://openalex.org/W4379740536",
    "https://openalex.org/W4391795643",
    "https://openalex.org/W3034552520",
    "https://openalex.org/W4327831947",
    "https://openalex.org/W3134164546",
    "https://openalex.org/W4284882312",
    "https://openalex.org/W2911003490",
    "https://openalex.org/W4234718219",
    "https://openalex.org/W2067530554",
    "https://openalex.org/W2531409750",
    "https://openalex.org/W3111341023",
    "https://openalex.org/W4243804860",
    "https://openalex.org/W2982083293",
    "https://openalex.org/W3146366485",
    "https://openalex.org/W4372347372",
    "https://openalex.org/W4399090816",
    "https://openalex.org/W3081792418",
    "https://openalex.org/W2584994008",
    "https://openalex.org/W2551393996",
    "https://openalex.org/W4379647709"
  ],
  "abstract": null,
  "full_text": "Bearing fault diagnosis based on \nefficient cross space multiscale \nCNN transformer parallelism\nQi Chen1, Feng Zhang1, Yin Wang1, Qing Yu1, Genfeng Lang2 & Lixiong Zeng1\nFault diagnosis of wind turbine bearings is crucial for ensuring operational safety and reliability. \nHowever, traditional serial-structured deep learning models often fail to simultaneously extract spatio- \ntemporal features from fault signals in noisy environments, leading to critical information loss. To \naddress this limitation, this paper proposes a Wind Turbine Bearing Fault Diagnosis Model Based on \nEfficient Cross Space Multiscale CNN Transformer Parallelism (ECMCTP). The model first transforms \none-dimensional vibration signals into two-dimensional time-frequency images using Continuous \nWavelet Transform (CWT). Subsequently, parallel branches are employed to extract spatio-temporal \nfeatures: the Convolutional Neural Network (CNN) branch integrates a multiscale feature extraction \nmodule, a Reversed Residual Structure (RRS), and an Efficient Multiscale Attention (EMA) mechanism \nto enhance local and global feature extraction capabilities; the Transformer branch combines \nBidirectional Gated Recurrent Units (BiGRU) and Transformer to capture both local temporal dynamics \nand long-term dependencies. Finally, the features from both branches are concatenated along the \nchannel dimension and classified using a softmax classifier. Experimental results on two publicly \navailable bearing datasets demonstrate that the proposed model achieves 100% accuracy under \nnoise-free conditions and maintains superior noise robustness under low signal-to-noise ratio (SNR) \nconditions, showcasing excellent robustness and generalization capabilities.\nAlong with the progress of science and technology and global economic development, energy and environmental \npollution problems are becoming more and more prominent, and wind energy has attracted much attention \nbecause of its low cost and renewability1–3. According to the data of the Global Wind Energy Council, by 2024, \nthe new installed capacity of global onshore wind power will exceed 100GW for the first time; in the next five \nyears, the total amount of global wind power newly connected to the grid will reach 680GW4. This signifies that \nwind power has entered a period of rapid development. However, wind turbines are usually installed in remote \nareas, where the bearings, as the critical rotating parts of the wind turbines, are highly prone to failures due to \nlong work in harsh environments, which can lead to unexpected shutdowns and major dangerous accidents 5. \nTherefore, timely and accurate fault diagnosis of fan bearings is crucial to ensure fan systems’ long-term safe and \nstable operation6,7.\nTraditional intelligent fault diagnosis algorithms for bearings usually involve two steps: fault feature extraction \nand classification8. Feature extraction is often based on time-domain, frequency-domain, and time-frequency-\ndomain method9. Time-domain methods extract features by calculating and analyzing statistical attributes such \nas the mean and variance of vibration signals10. Frequency-domain methods use Fourier transforms and spectral \nanalysis to convert signals from the time domain to the frequency domain, revealing frequency components \nand energy distributions 11. Time-frequency domain methods, like Short-Time Fourier Transform (STFT) 12, \nWavelet Transform (WT)13, and Hilbert-Huang transform (HHT)14, combine both time and frequency domain \ntechniques, making them more suitable for non-stationary signals. After feature extraction, these features are \ntypically fed into machine learning algorithms for fault classification. Commonly used methods include Support \nVector Machines (SVM)15, Random Forest (RF)16, and Bayesian Classifiers (BC)17.\nHowever, traditional intelligent fault diagnosis methods mainly rely on expert experience and are time-\nconsuming, which is difficult to meet the requirements of large-scale data training 18. At present, data-driven \nbearing fault diagnosis methods are gradually becoming popular. These methods collect condition monitoring \ndata during bearing operation and use artificial intelligence technology to assist in analysis and diagnosis. As \ntypical condition monitoring data, vibration signals contain a wealth of fault information and are highly sensitive \nto the occurrence and evolution of faults, so they are widely used in fault diagnosis 19. For example, Harrou et \nal.20 proposed an improved multivariate statistical method based on a combination of independent component \n1College of Mechanical Engineering and Automation, Huaqiao University, Xiamen 361021, China. 2Niell Company, \nXiamen 361021, China. email: zhangfeng@hqu.edu.cn\nOPEN\nScientific Reports |        (2025) 15:12344 1| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports\n\nanalysis (ICA) and Kantorovich distance (KD), which significantly improves the accuracy and sensitivity of fault \ndetection and performs well under noisy conditions. Kini et al.21 also proposed a sensor fault detection method \nbased on dynamic independent component analysis (DICA) combined with a double exponential weighted \nmoving average (DEWMA) chart, which can better capture the dynamic characteristics of wind turbine data.\nAlthough statistical methods based on vibration signal analysis have made significant progress in fault \ndetection, their dependence on signal pre-processing and feature engineering still limits their ability to generalise \nto complex operating conditions. With the rapid development of deep learning technology, researchers have \nbegun to explore image-based fault diagnosis methods. Some researchers are exploiting the advantages of \nconvolutional neural networks (CNNs) in image feature extraction and pattern recognition for fault diagnosis. \nFor example, Dong et al. 22 proposed a fault diagnosis method based on empirical wavelet transform and an \nimproved self-attention augmented convolutional neural network, achieving 100% classification accuracy \nthrough multi-frequency feature extraction and attention mechanisms. Song et al. 23 introduced a vast \nconvolutional kernel-based convolutional neural network (WKCNN) fault diagnosis model, which enhanced \nfeature extraction efficiency by expanding input data and employing a wide convolutional kernel, showing \nexcellent accuracy, noise immunity, and real-time performance. Other researchers have proposed the global \ncontext modelling capability based on the Vision Transformer (ViT), which captures long-range dependencies \nin time-frequency images through a self-attention mechanism, significantly improving the representation of \nsubtle features of defects24,25. For example, Y adav et al.26proposed a hybrid architecture of CNN and Transformer \nfor concrete crack monitoring, designing a dual-path feature interaction mechanism of windowed self-attention \n(W-MSA) and convolutional channel attention (CAM), which achieved good generalisation performance \ndespite noise interference.\nFault signals of bearings are typically temporal data, and relying solely on CNNs for feature extraction \nfails to capture temporal features, potentially degrading accuracy with complex fault signals 27. Consequently, \nresearchers have suggested combining recurrent neural networks (RNNs) and their variants with CNNs to \nmitigate these limitations. For instance, Huang et al. 28 introduced a fault diagnosis method using CNN and \nLSTM, enhancing prediction accuracy and noise immunity via sliding window processing. Nguyen Da et al. 29 \nproposed a CNN-BGRU hybrid deep learning algorithm based on cloud AIoT for industrial diesel generator \nfault diagnosis, achieving fault diagnosis by extracting deep features from historical signals.\nThe above method adopts a serial structure. If the model extracts spatial features sequentially, the problem \nof partial feature loss will occur, leading to a decrease in the recognition accuracy of the model 30. Therefore, \nsome scholars have proposed to use a parallel structure to alleviate the problem of feature loss. For example, \nY adav et al. 31 proposed the dual-stream transformer model (DSTNet) based on spatial attention, which \nimplements multi-granularity feature extraction through parallel semantic paths and pixel paths. Guo et al. 32 \nproposed a parallel deep neural network that combines a convolutional block attention module and an abnormal \ntransformer model to thoroughly analyse the time-domain and time-frequency-domain features of drilling \npump signals, significantly improving the accuracy and reliability of fault diagnosis. In addition, these methods \nmainly focus on local feature extraction of fault signals and cannot effectively discriminate and select essential \nfeatures. Therefore, some scholars have introduced the attention mechanism into the fault diagnosis model, \nthrough which the model can selectively focus on important features to improve the overall feature extraction \nperformance of the model33–35. For example, Wang et al.36 proposed a multi-task convolutional neural network \n(MTA-CNN) approach based on feature-level attention, which achieves significant performance improvement \nin multiple datasets by introducing a feature-level attention mechanism and exhibits strong robustness in noisy \nenvironments. Xu et al.37 proposed a multiscale denoising residual convolutional neural network (AM-DRCN) \nbased on attention to the fault diagnosis of rotating machinery. The method combines multiscale denoising, \nfeature enhancement, and joint attention modules to extract and integrate features effectively.\nIn summary, existing deep learning methods have good feature extraction and classification capabilities in \nrolling bearing fault diagnosis, but there are still three major challenges: First, traditional deep learning methods \nlack an effective attention mechanism during feature extraction and cannot adaptively select and highlight key \ninformation in the data. Second, the operating environment of rolling bearings is often accompanied by noise, \nand the diagnostic performance of traditional deep learning methods in noisy environments can be significantly \ndegraded. Third, when a serial structure is used for feature extraction, the model usually extracts features \nsequentially, which may lead to the loss of some important key information. To solve the above problems, this \npaper proposes a “Wind Turbine Bearing Fault Diagnosis model based on Efficient Cross Space Multiscale CNN \nTransformer Parallelism (ECMCTP)” . The model first converts a one-dimensional time series signal into a two-\ndimensional time-frequency image using CWT, and then the ECMCTP model performs feature extraction by \ntwo parallel branches of CNN and Transformer to achieve joint extraction and feature fusion of spatiotemporal \nfeatures in the same framework. Specifically, the CNN branch uses a multi-scale feature extraction module \ncomposed of separable convolutions with different kernel sizes, combined with an inverse residual structure \nto alleviate the gradient vanishing problem. In addition, this paper introduces the EMA (Exponential Moving \nAverage) attention mechanism to improve the model’s ability to capture features across spatial pixels. The \nTransformer branch, on the other hand, can model time series signals on a global scale by combining BiGRU \nwith the Transformer model, which significantly improves the ability to capture long-range dependencies and \nenhances the model’s ability to detect time series features under complex conditions. Experimental results show \nthat the proposed model achieves excellent error detection rates in noise-resistant experiments on two public \ndatasets, and has good robustness and generalisation. The main contributions of this study are shown below:\n (1) The ECMCTP model designs a parallel architecture for the CNN transformer to achieve parallel extraction \nand fusion of spatio-temporal features, which has good robustness and generalisation ability under noisy \nconditions.\nScientific Reports |        (2025) 15:12344 2| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\n (2) A lightweight multi-scale feature extraction module is constructed using a Depthwise Separable Convolu-\ntion (DSC) with different kernel sizes, which enhances the multi-scale feature extraction capabilities. This \nis combined with a reverse residual structure to effectively alleviate the problem of gradient disappearance.\n (3) The EMA is introduced to improve the model’s ability to capture cross-spatial pixel-level features and en -\nhance the extraction of important features.\n (4) The BiGRU-Transformer time series modelling method is proposed in the Transformer branch, which \ncombines the advantages of the two to improve the model’s ability to capture local features and model global \ndependencies.\nMethods\nEfficient cross-space multiscale branch\nContinuous wavelet transform (CWT)\nContinuous Wavelet Transform (CWT) can transform one-dimensional time-series signals into two-dimensional \ntime-frequency images, providing both time-domain and frequency-frequency information and effectively \ncapturing the transient features in the signals 38,39. CWT can analyze the low-frequency and high-frequency \nfeature changes in the signal at multiple scales by changing the scale parameter of the wavelet function, revealing \nthe details and overall trend of the signal changes. Therefore, using CWT to generate images can enrich the \nfeature representation, which plays a vital role in the feature extraction of non-smooth signals.\nThe mother wavelet function is the primary function of the CWT, which is used to convert the continuous \nwavelet transform into a time-domain map containing both time and frequency information. It must satisfy the \ncondition of Eq. (1).\n \n∫ ∞\n−∞\nΨ(τ)dτ =0  (1)\nWhen the wavelet function has a specific mathematical form, such as when it consists of a complex exponential \nfunction and a Gaussian envelope function, it is referred to as a Complex Morlet Wavelet (CMW). Due to its \nsensitivity to oscillating signals, ability to separate amplitude and phase information, and ability to provide rich \ntime-frequency details, it is particularly suitable for fault diagnosis. The definition of using the CMW as the \nmother wavelet function is given below:\n ψM (t)=( πfB)−(1/2)e2πifCte−(t2/fB) (2)\nWhere e2πifCt denotes complex exponential function, 2πfctdenotes angular frequency, fc denotes center \nfrequency; e−(t2/fB) denotes Gaussian envelope function, fB denotes bandwidth parameter.\nDepthwise separable convolution (DSC)\nConvolutional Neural Network (CNN) is a deep learning model specially designed for processing data with \na lattice-like topological structure 40. CNN consists of several layers, usually including input, convolutional, \npooling, and fully connected layers. Its main structure is shown in Fig. 1.\nDepthwise Separable Convolution (DSC) significantly reduces the amount of computation and the number \nof parameters by dividing the operation process of standard convolution into depth convolution and point-by-\npoint convolution while fully considering features in both spatial and depth dimensions 41. Specifically, depth \nseparable convolution first applies a set of 2D filters in the width and height directions of the feature map for \ndepth convolution computation to generate the intermediate feature map. Then, the intermediate feature map is \nconvolved with a 1 × 1 point-by-point convolution filter to output the final feature map. This method effectively \nreduces the computational complexity and preserves the spatial and depth information of the image. Literature42 \ncompared DSC with standard convolution and demonstrated that DSC can significantly reduce the number of \nparameters and significantly improve the computational efficiency compared to standard convolution. Let VDW\nand VPW  denote the total number of operations in the two parts, which the following Equation can calculate:\n VDW = G × H × J × J × Iin (3)\n VPW = G × H × Iin × R (4)\nFig. 1. Schematic diagram of CNN structure.\n \nScientific Reports |        (2025) 15:12344 3| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nThe total number of operations of the depth separable convolution can be obtained from Eqs. (3),  (4), which is \ncalculated as shown in Eq. (5):\n VDWS = G × H × Iin × R + G × H × J × J × Iin (5)\nIn this paper, the multiscale feature extraction module extracts multiscale features by depth-separable convolution \nwith three different scales of convolution kernels, and the dimensions of the convolution kernels used are 3 × 3, \n6 × 6 and 9 × 9. Its structure is shown in Fig. 2, and the fusion of the convolution kernel feature extraction results \nis achieved by a splicing mechanism, as shown in Eq. (6):\n SG×H×(Iin×n) = concat(S1,S 2, ...., Sn) (6)\nReversed residual structure (RRS)\nThe main idea of ResNet is to efficiently train deeper networks by introducing residual blocks and jump \nconnections for better gradient transfer. MobileNetV2 borrows this idea from ResNet and proposes a reverse \nresidual structure based on it43. As shown in Fig. 3, the reverse structure and linear bottleneck layer are introduced. \nMobileNetV3 further builds on MobileNetV2 by adding the SE module and the h-swish activation function 43. \nThe SE module, as a lightweight module, enhances the representation of essential features by adaptively adjusting \nthe channel weights without significantly increasing the computational effort. H-swish activation function with \nfewer parameters than Swish, it can dramatically reduce computation and delay while retaining and conveying \nthe information in the input features, thus improving the representation of the model.\nThe RRS in MobileNetV3 mainly consists of two PC layers and one DW layer, whose structure is shown \nin Fig.  3. Firstly, PW1 extends the number of input feature map channels by a 1*1 convolution kernel, which \nincreases the complexity of the features and provides a higher dimensional input for the DW layer. Then, the \nDW layer uses 3*3 deep convolution to perform convolution operations in each channel to extract each channel \nfeature effectively. Finally, PW2 compresses the extended high-dimensional features using a 1*1 convolution \nkernel to reduce the number of feature map channels and ensure that the number of input and output channels \nremains consistent. In this case, in the bottleneck layer, the SE module is introduced to enhance the essential \nfeatures and suppress the unimportant ones.\nEfficient multiscale attention mechanism (EMA)\nThe channel attention mechanism has been demonstrated to enhance the representation ability and performance \nof the model by focusing the model’s attention on important features44. Literature45 proposed that The Efficient \nFig. 3. Schematic diagram of RRS structure.\n \nFig. 2. Schematic diagram of the multi-scale feature extraction module.\n \nScientific Reports |        (2025) 15:12344 4| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nMultiscale Attention Mechanism (EMA) establishes long and short-term dependencies by designing parallel \nmultiscale modules. It allows the model to fuse parallel channel feature maps in a cross-space learning manner \nand simultaneously reshapes some channel dimensions into batch dimensions. This approach avoids channel \ndimensionality reduction, retains more feature information, and thus improves the completeness and accuracy \nof feature representation. Therefore, in order to increase the recognition ability of CNN channels for important \nimage features and improve the accuracy of fault classification, this paper introduces the EMA mechanism. It \nimproves it in its parallel branch in order to enhance the recognition ability for fault features of different scales, \nand its structure is shown in Fig. 4.\nGiven a set of input feature maps X with input feature map dimensions X ∈ RC×H×W, which are now \nclassified into K groups, each group can be obtained with the following feature dimensions:\n X =[ X0,X 1,...,X K−1] ,X i ∈ R\nC\nK ×H×W  (7)\nThe different weight relationships in the input feature map are captured in EMA by designing three parallel \nbranches. The first two parallel branches are performed by 1D global average pooling in horizontal and vertical \nspatial dimensions for extracting global information and generating coding vectors. The 1D global average \npooling in the horizontal and vertical directions are represented by Eq. (8) and Eq. (9), respectively:\n \nuH\nc = 1\nW\nW−1∑\ni=0\nxc(i) (8)\n \nuW\nc = 1\nH\nH−1∑\nj=0\nxc(j) (9)\nIn this study, a multiscale feature extraction module is integrated into the Efficient Multiscale Attention (EMA) \nmechanism within a parallel branch. This module comprises three convolution operations with 1 × 1, 3 × 3, and \n5 × 5 convolution kernels to capture deeper features and enhance spatial feature interactions. The EMA module \nis designed by constructing channel and spatial dependencies through a method of information aggregation \nacross space. Long-term dependencies are captured by employing 2D global average pooling to globally encode \nthe results of 1 × 1 convolutional branching, as illustrated in Eq. (10).\n \nuc = 1\nH × W\nH−1∑\ni=0\nW−1∑\nj=0\nxc(i, j) (10)\nEMA ensures the integrity of spatial feature information within each sub-feature group by maintaining the \nchannel dimension and using group feature remodelling technology to assign some channels to the batch \ndimension, thereby capturing multi-scale features more comprehensively. At the same time, the design of the \nEMA attention mechanism effectively avoids the highly complex computations of the fully connected layer and \nself-attention in SE. It adopts cross-branch feature fusion to effectively enhance the synergy between channels \nand spaces, thereby achieving efficient pixel-level spatial feature detection capability with low computational \noverhead.\nFig. 4. Schematic diagram of improved EMA structure.\n \nScientific Reports |        (2025) 15:12344 5| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nTransformer branch\nBidirectional gated recurrent unit (BIGRU)\nTraditional GRUs can only capture temporal features in a single direction while failing to capture long-range \ndependencies when processing long sequence data adequately. To overcome this limitation, Bidirectional Gated \nRecurrent Unit (BIGRU) is proposed46. The structure of BIGRU is shown in Fig. 5.\nTransformer\nThe Transformer is a deep learning model based on the self-attention mechanism, initially proposed by Vaswani \net al. in 2017 33, and has since been widely applied in natural language processing tasks. Unlike traditional \nrecurrent neural networks (RNNs) and convolutional neural networks (CNNs), the Transformer entirely \ndispenses with recursive and convolutional operations, instead leveraging the attention mechanism to capture \nglobal dependencies within input sequences.\nThe core architecture of the Transformer consists of an encoder and a decoder, each composed of multiple \nlayers of self-attention and feedforward neural networks. By processing sequence data in parallel, the Transformer \ndemonstrates exceptional performance in training efficiency and modeling long-range dependencies, \nestablishing itself as the foundational framework for many modern natural language processing models. Its \nstructure is illustrated in Fig. 6.\nMultimodal parallel feature fusion mechanism\nIn the field of mechanical fault diagnosis, the effective extraction of spatio-temporal information from vibration \nsignals is paramount. To address this need, we propose a novel multimodal parallel feature fusion mechanism. \nThe architecture is designed to extract spatial and temporal features in a parallel manner through a double-\nbranch processing, followed by channel-wise dimension fusion. This approach is intended to enhance the \ndiscriminative ability for subsequent fault classification tasks.\nThe model is composed of two distinct branches: the CNN branch and the Transformer branch. Following \nthe extraction of features FCNN −Flattened  and FT ransformer-F lattened from these two branches, they are \nflattened to yield FCNN −Flattened  and FT ransformer-F lattened. Subsequently, these features are concatenated \nalong the channel axis by the concat mechanism, resulting in the generation of the fused composite feature E, as \nillustrated in Eq. (11):\nFig. 6. Schematic diagram of transformer structure.\n \nFig. 5. Schematic diagram of BIGRU structure.\n \nScientific Reports |        (2025) 15:12344 6| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\n Fconcat = Concat (FCNN −Flattened ,F Transformer -Flattened ) (11)\nFollowing the completion of the feature fusion process, the resulting fused features are then subjected to \nclassification using a fully connected layer, as illustrated in Eq. (12):\n y = Softmax (W · Fconcat + b) (12)\nwhere W is the weight matrix of the fully connected layer, b is the bias, y is the classification result, Softmax  is \nthe activation function, and E is used to output the probability distribution of each class.\nThis fusion strategy enables the optimisation of the complementary advantages inherent in both the CNN \nand Transformer branches. The CNN branch is utilised for the extraction of multi-scale spatial features, while \nthe Transformer branch is employed for the modelling of global temporal features. Consequently, the model \nis endowed with the ability to process non-stationary vibration signals, thereby circumventing the issue of \ninformation loss that is typically associated with the extraction process in conventional serial structures.\nECMCTP fault diagnosis model\nThe main structure of the model\nThis paper proposes “Wind Turbine Bearing Fault Diagnosis Model Based on Efficient Cross Space Multiscale \nCNN Transformer Parallelism” to implement fault diagnosis of wind turbine bearings. Efficient Cross space \nMultiscale CNN Transformer Parallelism (ECMCTP) is used to implement fault diagnosis of wind turbine \nbearings by designing a parallel structure of CNN and Transformer and simultaneously extracting spatial and \ntemporal features of the original vibration signals. The fault diagnosis of bearings shows excellent performance \nand robustness. The model framework consists of two parallel branches: the CNN branch includes a multi-\nscale feature extraction module consisting of depth-separable convolution, inverse residual connection, and \nan improved EMA mechanism; and the Transformer branch includes BIGRU and Transformer. Its workflow is \nshown in Fig. 7.\nThe use of two-dimensional image inputs can fully exploit the advantages of convolutional neural networks \nfor image data processing. Therefore, in this study, the input one-dimensional time-series vibration signal is \ntransformed into a two-dimensional image by continuous wavelet transform (CWT) to ensure that the details \nand overall information of the signal are fully captured. The use of CWT provides information about the signal \nin the time-frequency domain simultaneously, captures the local features of the signal, more consistently reflects \nthe true characteristics of the signal, and reduces the impact of noise on model training.\nThe generated 2D image is then fed into the CNN branch. Firstly, multiscale features are extracted by the \nmultiscale feature extraction module. This module consists of three depth-separable convolutions (DSCs) with \ndifferent convolutional kernel sizes (3 × 3, 6 × 6, and 9 × 9), which can effectively capture the feature information \nof different scales and enhance the feature diversity while significantly reducing the amount of computation and \nthe number of parameters. The features are then processed by the reverse residual structure (RRS), which serves \nto alleviate the gradient vanishing problem in the deep network. This, in turn, enhances the computational \nefficiency and stability of the model. Finally, an improved Efficient Multiscale Attention (EMA) mechanism \nis introduced to enhance the model’s ability to globally capture the important features of the image through a \ncross-space learning mechanism. This further improves the robustness and classification accuracy of the model.\nThe Transformer branch is comprised of BIGRU and Transformer. Initially, the original one-dimensional \ntemporal vibration signal is input to the BIGRU layer, which captures the bidirectional dependencies in the \nsequence data to ensure the completeness and dynamic characteristics of the temporal features. The preliminary \nfeatures output from the BIGRU are then input to the Transformer enc order, which globally models the temporal \nFig. 7. Flowchart of ECMCTP fault diagnosis model.\n \nScientific Reports |        (2025) 15:12344 7| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nsignals through the multi-head self-attention mechanism, efficiently captures the long-distance dependencies, \nand combines with a feed-forward neural network to further extract deeper features. This combination \nsignificantly improves the feature representation of the model for complex temporal patterns.\nFinally, in order to make full use of the complementary nature of spatial and temporal features, the features \nextracted from the two parallel branches are spliced in the channel dimension to form fused features. The fused \nfeatures are dimensionally reduced and nonlinearly mapped through the fully connected layer, and finally the \nprobability distributions of fault categories are output by the Softmax layer. To enhance the robustness of the \nmodel in noisy environments, a Dropout layer is introduced after the key modules (EMA and Transformer) for \nboth branches. This is set to a dropout rate of 0.3 in order to suppress the risk of overfitting by randomly masking \nsome neuronal connections.\nModel structure parameters\nThe specific parameter contents of the wind turbine fault diagnosis model with ECMCTP proposed in this paper \nare shown in Table 1.\nThe CWT of this paper employs the complex Morlet wavelet, designated as ‘cmor’ , with a centre frequency \nfactor of 1.5, a width factor of 0.5, and a scale range of (1, 256). The Transformer model incorporates eight \nattention heads, with each attention head having a dimensionality of 128, to ensure the model can effectively \nprocess the varied information present in the input data. Conversely, the feed-forward neural network employs \nthe ReLU activation function and sets the hidden layer dimension to 256, thereby enhancing the model’s \nnonlinear modelling capability and expressive power. The dropout rate is set to 0.2.\nExperimental setup introduction\nData set description and processing\nIn this paper, two datasets, the Case Western Reserve University (CWRU) bearing dataset and the Southeast \nUniversity (SU) gearbox dataset, are used to validate the proposed fault diagnosis algorithm. Dataset 1 (CWRU \nbearing dataset) is widely used for bearing fault diagnosis; dataset 2 Southeast University (SU) gearbox dataset is \nchosen because of its proximity to the working environment of wind turbine gears.\nDataset 1 uses the bearing dataset provided by Case Western Reserve University (CWRU), which is widely \nused in the field of bearing fault diagnosis. This dataset contains a variety of operating conditions and fault \ntypes and is a well-established dataset. Dataset 1 was acquired from the test rig shown in Fig.  8, which includes \na motor, torque transducer, and dynamometer with 6203-2RS JEM SKF deep groove ball bearings. Single-\npoint faults with diameters of 0.007, 0.014, and 0.021 inches were set on the inner ring, outer ring surface, and \nrolling element of the bearing by EDM technology. In this paper, the fault data of the drive end with a sampling \nfrequency of 12 kHz and a motor speed of 1772r/min is selected, which contains four health states: inner ring \nfault, outer ring fault, rolling element fault, and normal state.\nThis article divides dataset 1 into ten categories, A0 ~ A9, where each class is 1200 samples, each sample \ncontains 1024 data points, and is sampled by overlapping sliding windows with an overlapping window length \nof 256, and is divided into training set, testing set, and validation set according to the ratio of 0.8:0.1:0.1. The \nLayer name Type Number of filters Padding Output size Activation function\nInput layer1 Input layer – – (None, 112, 112, 3) –\nStandard Conv2D 32 Same (None, 112, 112,32) ReLU\nConvolution MaxPooling2D – (None, 14, 14, 32) –\nDepthwise SeparableConv2D1 32 Same (None, 14, 14, 32) ELU\nSeparable SeparableConv2D2 32 Same (None, 14, 14, 32) ELU\nConvolution SeparableConv2D3 32 Same (None, 14, 14, 32) ELU\nConcatenate Concat – – (None, 14, 14, 96) –\nReversed residual structure\nBatch normalization – – (None, 14, 14, 32) –\nDepthwiseConv2D – Same (None, 14, 14, 32) –\nEMA EMA attention – – (None, 14, 14, 8) –\nDropout Dropout – – (None, 14, 14, 8) –\nCNN flatten Flatten – – (None, 1568) –\nInput layeer2 Input layer 32 – (None, 1024, 1) –\nBIGRU\nBIGRU1 32 – (None, 1024, 64) Tanh\nMaxPooling1D – – (None, 128, 64) –\nBIGRU2 16 – (None, 128, 32) Tanh\nTransformer Transformer encoder – – (None, 128, 32) –\nDropout Dropout – – (None, 128, 32) –\nGru flatten Flatten – – (None, 2048) –\nConcatenate Concatenate input layer 1 and layer 2 – – (None, 3616) –\nOutput layer Dense – – (None, 10) Softmax\nTable 1. Schematic diagram of the model structure.\n \nScientific Reports |        (2025) 15:12344 8| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nspecific fault types and the corresponding labels are shown in Table  2. The schematic diagram of the time-\ndomain signals of the samples of the data set is shown in Fig.  9. The Schematic diagram of overlapping sliding \nwindows is shown in Fig. 10. Although cross-validation can theoretically provide unbiased estimation results47,48, \nthe parallel architecture used in this paper needs to process multimodal data (raw vibration signals and time-\nfrequency images) simultaneously. To ensure strict alignment between data modalities and avoid leakage of \ntemporal information, a fixed ratio division strategy is used. In addition, the results of subsequent experiments \nare calculated by averaging the results of ten experiments.\nFig. 9. Time-domain plot of vibration signals for dataset 1.\n \nLabel Type Fault diameter /mm Number of training/validation/testing samples\nA0 Normal 0.000 960/120/120\nA1 Inner ring fault 0.178 960/120/120\nA2 Outer ring fault 0.178 960/120/120\nA3 Ball fault 0.178 960/120/120\nA4 Inner ring fault 0.356 960/120/120\nA5 Outer ring fault 0.356 960/120/120\nA6 Ball fault 0.356 960/120/120\nA7 Inner ring fault 0.533 960/120/120\nA8 Outer ring fault 0.533 960/120/120\nA9 Ball fault 0.533 960/120/120\nTable 2. CWRU dataset.\n \nFig. 8. CWRU bearing test stand.\n \nScientific Reports |        (2025) 15:12344 9| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nDataset 2 was collected by the gearbox test bed of Southeast University, which is shown in Fig. 11. The dataset \ncollects eight channels of data, and the collected conditions are 1800 r/min-2 V . It contains a total of five fault \ntypes: inner ring fault, outer ring fault, rolling body fault, compound fault, and health condition.\nIn this paper, four fault conditions are selected, respectively B0 ~ B3, 1200 samples of each type, each sample \ncontains 1024 data points, and overlapping sliding window sampling is adopted with the overlapping window \nlength of 256. The training set, testing set, and validation set are divided according to the ratio of 0.8:0.1:0.1. \nThe specific fault types and the corresponding labels are shown in Table 3. The schematic diagram of the time-\ndomain signals of the samples of the data set is shown in Fig. 12.\nThe two data sets were transformed into two-dimensional images with time-frequency characteristics by \napplying continuous wavelet transform (CWT) to the original vibration time series signal, so that they could be \nused for subsequent image processing and analysis.\nStatistical analysis of data sets\nThe statistical analysis of the two data sets was performed using the mean, variance and peak values, and the \nresults are shown in Table 4. As demonstrated in Table 4, there are significant differences between the CWRU \nand SU data sets in terms of fault diagnosis. The mean and variance of the health status signals in the CWRU \ndata set are higher than those in the SU data set, indicating that the signal stability of the CWRU data set is \nhigher. In terms of inner ring faults, the mean and variance of the CWRU data set are larger, indicating that its \nfault characteristics are more prominent. The outer ring faults also show higher mean values and variances in the \nCWRU data set, while the outer ring fault signal in the SU data set shows higher peaks, which may indicate that \nthe extreme values of the fault signal in the SU data set are more significant. The mean values and variances of \nthe rolling element faults in both data sets are low, but the SU data set has slightly higher peaks, which means that \nunder certain circumstances, the signal of the rolling element fault in the SU data set is more prominent. These \ndifferences may be due to differences in data collection conditions, equipment characteristics, or fault modes.\nThe CWRU dataset demonstrates a higher prevalence of signal fluctuations, particularly in the context of \nfault type identification, a factor that facilitates the extraction of more discriminative features. Conversely, \nthe SU dataset exhibits a reduced incidence of signal fluctuations, thereby complicating the process of feature \nextraction. The employment of more sophisticated signal processing methodologies or feature engineering \ntechniques may become imperative in order to effectively differentiate between disparate fault states. These \nstatistical observations provide substantial support for the subsequent classification and diagnosis of faults, \nLabel Type Number of training/testing samples\nB0 Normal 960/120\nB1 Inner ring fault 960/120\nB2 Outer ring fault 960/120\nB3 Ball fault 960/120\nTable 3. Southeast university dataset.\n \nFig. 11. Gearbox experiment platform of Southeast University.\n \nFig. 10. Schematic diagram of overlapping sliding windows.\n \nScientific Reports |        (2025) 15:12344 10| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nwhilst simultaneously highlighting the potential ramifications of diverse datasets on the efficacy of diagnostic \nmodels.\nECMCTP model parameter settings\nIn this paper, the model employs cross-entropy to calculate the loss, utilising the Adam optimiser. The initial \nlearning rate is set to 0.001, the batch size to 64, and the number of training rounds to 30.\nAs the wind turbine data collected under actual working conditions are difficult to apply to fault diagnosis \ndirectly, and the wind turbine working process will be accompanied by the friction of the parts and other noise, \nso this paper adds noise artificially according to Eq. ( 13) in datasets 1 and 2 to simulate the actual working \nconditions of the wind turbine.\n \nSNRdb = log10( Psignal\nPnoise\n) (13)\nWhere Psignal and Pnoise are the power of the signal and noise, respectively.\nExperiment results and analysis\nAnalysis of fault diagnosis experimental results\nThe ECMCTP model mentioned in this paper was used to perform fault diagnosis experiments on the CWRU \nand SU datasets, and the experimental settings are shown in the previous section. The results of the experiment \nwere obtained by averaging the results of ten experiments. As shown in Fig.  13a is a schematic of the training \nresults for dataset 1, and (b) is a schematic of the training results for dataset 2. From Fig. 13, it can be seen that \nDataset Type Mean Variance Peak value\nCWRU\nNormal 0.0126 0.0053 0.3113\nInner ring fault 0.0207 0.1329 2.5126\nOuter ring fault 0.0141 0.2659 3.6113\nBall fault 0.0129 0.0202 1.5149\nSU\nNormal -0.0006 0.0083 1.2545\nInner ring fault 0.0025 0.0282 2.5082\nOuter ring fault 0.0010 0.0818 4.3079\nBall fault 0.0003 0.0371 3.3279\nTable 4. Statistical analysis of data set results.\n \nFig. 12. Time-domain plot of vibration signals for dataset 2.\n \nScientific Reports |        (2025) 15:12344 11| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nduring the training process of both datasets, the model validation set loss decreases rapidly after the first round \nconverges to 0 and remains stable after the 5th epoch. The test set accuracy of both datasets increases quickly \nafter the first epoch, reaches 100% after the 5th epoch, and remains smooth. No overfitting phenomenon occurs \nin the training process of both datasets.\nTo visually compare and analyze the fault diagnosis results of the two datasets, a confusion matrix is used to \ndisplay the results of the two (as shown in Fig. 14). Where the horizontal axis represents the predicted categories \nof the model and the vertical axis represents the true categories. The diagonal elements represent the number \nof samples in which the true category is consistent with the predicted category, and the off-diagonal elements \nrepresent the number of samples in which the true category is inconsistent with the expected category. As can \nbe seen from Fig. 14, the proposed model achieves better classification results on both datasets, with 100% fault \ndiagnosis accuracy for the ten-category task in (a) and the four-category task in (b). The model classification is \nevaluated using Precision, Recall, and F1-score evaluation metrics, and the results are all 1.\nIn order to visualize the model training results and evaluate its classification ability, this study used the \nt-distributed stochastic neighbor embedding (t-SNE) technique to visualize and analyze the model classification \nresults. Figure 15 shows the t-SNE visualization results for two datasets, where (a) and (c) are the input data \nand classification results visualized for dataset 1, and (b) and (d) are the input data and classification results \nvisualized for dataset 2. From (a) and (b), it can be seen that the different categories of the original data are mixed \nand distributed in the high-dimensional space with some overlap. After feature extraction and classification \nby the model, (c) and (d) show that the different categories form obvious independent clusters in the low-\ndimensional space, indicating that the model has strong feature classification ability and can effectively separate \ndifferent categories of fault data. This shows that the model proposed in this paper performs well in the fault \nclassification task with good classification effect and robustness.\nIn summary, the ECMCTP model proposed in this paper has good classification results in both datasets, \nwith high classification accuracy, fast-fitting speed, and smooth training process, and has some potential for \napplication in the field of wind turbine fault diagnosis.\nFig. 14. Schematic diagram of the confusion matrix. (a) represents the confusion matrix for the CWRU \ndataset, and (b) represents the confusion matrix for the SU dataset.\n \nFig. 13. Schematic of the ECMCTP training and testing process. (a) represents the results for the CWRU \ndataset, and (b) represents the results for the SU dataset.\n \nScientific Reports |        (2025) 15:12344 12| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nAnalysis of ablation experiment results\nIn this paper, we conduct ablation experiments using CWRU dataset to verify the impact of each module on \nthe performance of the fault diagnosis model by gradually removing each module in the parallel branch in \norder to select the best model. The experimental setup is consistent with the experiment above, and each type \nof experiment is repeated ten times, and the average value is taken. The ablation experiments are arranged in \nTable 5, and the results are shown in Table 6.\nThe experimental results show that the fault diagnosis model ECMCTP outperforms the comparison models \nin five metrics, including accuracy and loss, and has optimal fault classification performance. Comparing \nExperiments 1, 2, and 5, the EMA and Transformer modules significantly improve the extraction of important \nfeatures in the parallel branch and enhance the overall classification performance. The Transformer module \nbetter captures the long-time dependencies in the time-series data, while the EMA strengthens the CNN branch’s \nability to focus on and extract key image features.\nFig. 15. Schematic of T-SNE downscaling visualization results. (a) and (b) represent the results for the CWRU \ndataset, and (c) and (d) represent the results for the SU dataset.\n \nScientific Reports |        (2025) 15:12344 13| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nThe comparative results of Experiments 1 to 4 show that the DSC and RRS significantly improve the model’s \nmultiscale feature extraction capability. Deeply separable convolution increases the expressive ability of the \nmodel through convolution operations at different scales, effectively identifies and classifies fault features, and \nsignificantly improves computational efficiency. The use of residual connection improves the overall stability of \nthe model and avoids the problem of gradient explosion. Comparison results from experiments 6 to 8 show that \nthe parallel application of CNN and Transformer significantly improves the accuracy of fault diagnosis, fully \nconsidering the temporal and spatial characteristics of the original vibration data. The findings of this study \nindicate that the utilisation of BIGRU alone is constrained in its capacity to extract temporal features within \nthe Transformer branch, as evidenced by a comparison between Experiments 1 and 6. Specifically, Experiment \n6 demonstrates that when the Transformer branch extracts temporal features independently using BIGRU, the \naccuracy attained is a mere 94.44%.This decline in performance can be attributed to the limitations of BIGRU in \nmodelling long-distance dependencies. Conversely, the self-attention mechanism of the Transformer has been \nshown to effectively model global dependencies. The combination of these two mechanisms not only captures \nlocal features in the time series signal, but also effectively models global dependencies, thereby significantly \nimproving the overall performance of the model and leveraging the complementary advantages of both in \nfeature extraction.\nAfter a series of ablation experiments, this study demonstrates the key role of each module in enhancing \nthe performance of the fault diagnosis model. The model performs well in different experiments and effectively \nimproves the accuracy and robustness of fault classification, which verifies the superiority and innovation of the \nproposed method.\nAnalysis of calculation efficiency and parameter complexity\nTo verify the computational efficiency advantages of the proposed ECMCTP model, this study uses an Intel(R) \nCore (TM) i5-14600KF @ 3.50 GHz processor, 16 GB of memory, and an NVIDIA GeForce RTX 2070 graphics \ncard (8 GB of memory) for experimentation. During the experiment, 30 rounds of training were performed \nusing the SU dataset, and the specific experimental settings are as described above.\nFrom the results in Table  7, the ECMCTP model shows an excellent balance between computational \nefficiency and parameter complexity. Although RESNET-50 and ECMCT are similar in terms of accuracy, the \nECMCTP model has only 0.26  M parameters, which reduces the computational time by 42.86% per round. \nThis difference highlights the inefficiency of deep residual networks in scenarios with limited computational \nresources. In this paper, the ECMCTP model has achieved an ideal balance between accuracy and computational \nefficiency by introducing a parallel architecture and lightweight design. Compared to the traditional serial CNN-\nLSTM structure, the ECMCTP model has 43% fewer parameters, a 32-second reduction in computation time \nper round, and an accuracy improvement of about 10%. Compared to the CNN-GRU model, the ECMCTP \nmodel has a slightly higher number of parameters, but still shows a significant improvement in computation \ntime and accuracy. Although the ECMCTP model takes longer to compute than the CNN model, the accuracy \nof the CNN model remains stable at 95%, which may be due to the fact that the CNN model is limited in the \nextraction of deep features.\nExperimental model Acc Loss Precision Recall F1-score\nExperiment 1 1 0.0008 1 1 1\nExperiment 2 0.9906 0.0296 0.9914 0.9906 0.9906\nExperiment 3 0.9858 0.0428 0.9864 0.9858 0.9858\nExperiment 4 0.9670 0.0822 0.9722 0.9670 0.9664\nExperiment 5 0.9828 0.0608 0.9849 0.9828 0.9827\nExperiment 6 0.9422 0.2455 0.9520 0.9456 0.9444\nExperiment 7 0.9062 0.4210 0.9276 0.9062 0.9086\nExperiment 8 0.9162 0.3968 0.9252 0.9161 0.9154\nTable 6. Results of ablation experiments.\n \nExperimental setup CNN branch Transformer branch\nExperiment 1 CNN + DSC + RRS + EMA BIGRU + Transformer\nExperiment 2 CNN + DSC + RRS BIGRU + Transformer\nExperiment 3 CNN + DSC BIGRU + Transformer\nExperiment 4 CNN BIGRU + Transformer\nExperiment 5 CNN + DSC + RRS + EMA BIGRU\nExperiment 6 CNN BIGRU\nExperiment 7 CNN /\nExperiment 8 / BIGRU\nTable 5. Ablation experimental program design.\n \nScientific Reports |        (2025) 15:12344 14| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nIn conclusion, the ECMCTP model has obvious advantages in balancing computational efficiency, parameter \ncomplexity and classification accuracy through parallel architecture and lightweight design. However, the model \nstill has certain limitations. Due to computational resource limitations, this study did not consider training \nscenarios with large datasets, and it has not been verified by deployment on actual low-power industrial devices.\nAnalysis of the results of the noise addition experiment\nIn order to verify the performance of the proposed ECMCTP model under different noise conditions, seven \nSNR noise conditions were set up for the experiment (–6 dB, − 4 dB, − 2 dB, 0 dB, 2 dB, 4 dB, and 6 dB). To \nmore accurately simulate the noise environment of the fan bearing in actual work, corresponding Gaussian \nwhite noise was manually added according to Eq.  ( 13). To facilitate a comprehensive comparative analysis, \nfive deep learning models were selected for this study: Cross-Attention Multi-Scale Vision Transformer \n(CrossVIT)49, Wide Convolutional Neural Network (WDCNN) 50, Fully Convolutional Networks (FCN) 51, \nMultiscale Convolutional Neural Network-Long Short Term Memory (MCCNN-LSTM) 18, and Bidirectional \nGated Recurrent Unit (BIGRU)46. The training, testing, and validation protocols for each model are delineated \nin the preceding section. The experimental outcomes for the CWRU dataset are presented in Fig.  16. The data \nin the figure is expressed in the format of mean and error range, which represents the 95% confidence interval \ncalculated based on 10 experiments.\nAs illustrated in Fig. 16, at an SNR of 6 dB, all models demonstrated commendable performance, exhibiting \na classification accuracy that exceeded 90%. Notably, the ECMCTP and CrossVIT models attained 100% \naccuracy, underscoring their resilience to noise interference.However, as the SNR progressively diminished, \nthe performance of each model underwent a substantial decline, with the ECMCTP model exhibiting notable \nresilience to noise degradation. In contrast, although CrossVIT introduced a cross-attention mechanism, its \nperformance at SNR=-6dB was slightly inferior to that of ECMCTP , which may be limited by the single-branch \nstructure.This result demonstrates that the parallel dual-branch design of the ECMCTP model exhibits superior \nadaptability and generalization ability in complex noise environments. The performance of the WDCNN and \nBIGRU models exhibited a substantial decline under low SNR conditions, with classification accuracies of \nFig. 16. Comparison of test set accuracy for each algorithm in the noise addition experiment on the CWRU \ndataset.\n \nModel name Training time per epoch /S Parametric quantity /M Accuracy /%\nECMCTP 24 0.260 100.00\nRESNET-50 42 24.64 97.50\nCNN 16 0.235 95.00\nCNN-LSTM 56 0.374 90.48\nCNN-GRU 44 0.328 93.00\nTable 7. Results of computational efficiency and parameter complexity.\n \nScientific Reports |        (2025) 15:12344 15| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\n68.59% and 56.08% at SNR=-6dB, respectively. However, even under such conditions, ECMCTP demonstrated \na classification accuracy of 95.86%, representing an enhancement of 18.61% over the FCN model and 35.17% \ncompared to the MCCNN-LSTM model. This outcome substantiates ECMCTP’s superior noise resistance.\nFurthermore, to verify the generalizability and robustness of the ECMCTP model under diverse noise \nconditions, the same method was employed to conduct an experimental verification on the SU dataset. The \nresults are shown in Fig.  17. The experimental results demonstrate that the classification accuracy of the \nECMCTP model under various noise conditions consistently exceeds that of the other comparison models. \nFurthermore, there is no significant performance degradation, which further substantiates the model’s efficacy \nin fault diagnosis and its robustness in noisy environments.\nIn order to better demonstrate the role of each module of the proposed model under noisy conditions, we \nchoose to perform t-SNE dimensionality reduction on the original input signal, the standard convolutional layer \nof the CNN branch, the first layer of the BIGRU branch, the CNN flatten layer, the BIGRU flatten layer, and the \noutput layer under the condition of SNR = -6dB, and the results are shown in Fig. 18.\nFigure 18 clearly shows the role of each module in feature extraction. Figure  18a shows the input data in \nwhich various types of features overlap without order. Figure 18b,c show the features after preliminary extraction \nby CNN and BIGRU. The boundaries of various types of features are gradually clearer, and data points with the \nsame category are initially clustered together, showing the effect of preliminary extraction of shallow features. \nHowever, it is still difficult to perform accurate classification. As shown in Fig. 18d,e, after the multiscale feature \nextraction module and Transformer processing, the boundaries of each feature category are clearer, and the \nfeature clustering is more obvious, which shows that the introduction of the attention mechanism enhances \nthe extraction ability of the two branches for important features. Finally, Fig.  18f shows the results after the \nparallel branch feature fusion and the categories achieve clear classification, and the distance between categories \nincreases, indicating that the model has good robustness under noise conditions.\nConclusion\nTo address the problem of insufficient feature extraction capability and loss of key features in noisy environments \nin traditional serial deep learning fault diagnosis models, this paper proposes “Wind Turbine Bearing Fault \nDiagnosis Model Based on Efficient Cross Space Multiscale CN Transformer Parallelism” . This model (ECMCTP) \nuses two parallel branches, CNN and Transformer, to simultaneously extract spatial and temporal features from \nthe fault signal to achieve multimodal feature fusion and analysis of bearing fault vibration signals. This avoids \nthe loss of key features and significantly improves the fault diagnosis capability and robustness of the model in \nnoisy environments.\nThe ECMCTP model architecture is composed of a CNN branch and a transformer branch in parallel, \nwhere the CNN branch uses deep separable convolution with different kernel sizes to form a multi-scale feature \nextraction module, which significantly reduces the number of parameters while effectively extracting multi-scale \nspatial features. Combined with the inverse residual structure, it effectively alleviates the problem of gradient \ndisappearance caused by the deepening of the network layer. At the same time, a modified EMA attention \nmechanism is finally introduced to enhance the cross-space feature extraction ability of the CNN branch, \neffectively strengthen the synergy between channels, and achieve the pixel-level spatial feature detection ability \nFig. 17. Comparison of test set accuracy for each algorithm in the noise addition experiment on the SU \ndataset.\n \nScientific Reports |        (2025) 15:12344 16| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nwith low computational overhead. The Transformer branch combines BIRGU and Transformer to globally \nmodel time-series signals, effectively capture long-range dependencies, and significantly improve the model’s \nability to capture time-series features under complex conditions. Multimodal fusion of spatio - temporal features \nis achieved by extracting features in parallel in the two branches, effectively improving the fault diagnosis \nperformance of the model.\nExperiments were conducted to verify the model on the CWRU and SU datasets. The results show that the \nECMCTP model proposed in this paper achieves 100% fault diagnosis accuracy without manually added noise \non both datasets, demonstrating good robustness and generalisability. In the noise addition experiment on the \nCWRU dataset, the model achieved a classification accuracy of 99% in the low noise range from SNR = 6dB to \n0dB, and a classification accuracy of more than 95% in the high noise range from SNR = 0dB to -6dB, which is \nbetter than the comparison algorithm. At the same time, the noise experiment on the SU dataset further proves \nthe good generalisation ability of the ECMCTP model. The ablation experiment verifies the effectiveness and \nimportance of each parallel branch module, and proves the rationality and superiority of the model design.\nIn this study, the publicly available CWRU and SU datasets were used for experimentation. However, since \nthe acquired wind turbine field data set is difficult to apply directly to fault diagnosis in this study, artificial noise \nis currently added for simulation. Although this method can produce some simulation data, there are still some \ndifferences between this method and the actual wind turbine bearing data. Future research will be conducted to \nfurther verify the method using actual field data sets. In addition, it is useful to study the performance changes \nof the model under small sample conditions52. As a follow-up to this study, we will investigate the robustness and \ngeneralisation of the model under small sample conditions using transfer learning.\nData availability\nThe bearing datasets from the Case Western Reserve University and the gearbox dataset from the Southeast \nUniversity used in this study are both publicly available. They can be accessed at the following URL:  h t t p s :   /  / g i t h \nu  b . c o  m / e 6 2 5   0 5 / F a  u  l t _ d  i o g n o  s  i s _ d a  t a  s e t . g i t.\nReceived: 26 July 2024; Accepted: 25 March 2025\nFig. 18. Schematic representation of the visualization results of each layer (a) original input signal, (b) \nstandard convolutional layer of CNN branch, (c) BIGRU first layer, (d) CNN flatten layer, (e) BIGRU flatten \nlayer and (f) output layer.\n \nScientific Reports |        (2025) 15:12344 17| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\nReferences\n 1. Liu W .Intelligent fault diagnosis of wind turbines using multi-dimensional kernel domain spectrum technique. Measurement 133, \n303–309. https://doi.org/10.1016/j.measurement.2018.10.027 (2019).\n 2. Zhang, Y ., Liu, W ., Wang, X. & Gu H.A novel wind turbine fault diagnosis method based on compressed sensing and DTL-CNN. \nRenew. Energy  194, 249–258. https://doi.org/10.1016/j.renene.2022.05.085 (2022).\n 3. Artigao, E., Martín-Martínez, S., Honrubia-Escribano, A. & Gómez-Lázaro E.Wind turbine reliability: A comprehensive review \ntowards effective condition monitoring development. Appl. Energy  228, 1569–1583. https://doi.org/10.1016/j.apenergy.2018.07.037 \n(2018).\n 4. GWEC-2023_interactive.pdf.\n 5. Kong, Z., Tang, B., Deng, L., Liu, W . & Han, Y . Condition monitoring of wind turbines based on spatio-temporal fusion of SCADA \ndata by convolutional neural networks and gated recurrent units. Renew. Energy 146, 760–768.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / j . r e n e n e . 2 \n0 1 9 . 0 7 . 0 3 3     (2020).\n 6. Tautz-Weinert, J. & Watson, S. J.Using SCADA data for wind turbine condition monitoring – a review. IET Renew. Power Gener. \n11, 382–394. https://doi.org/10.1049/iet-rpg.2016.0248 (2017).\n 7. Wang, T. & Yin, L. A. Hybrid 3DSE-CNN-2DLSTM model for compound fault detection of wind turbines. Expert Syst. Appl. 242, \n122776. https://doi.org/10.1016/j.eswa.2023.122776 (2024).\n 8. Janssens, O. et al. Neural network based fault detection for rotating machinery. J. Sound Vib. 377, 331–345.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 \n6 / j . j s v . 2 0 1 6 . 0 5 . 0 2 7     (2016).\n 9. Gao, Z., Cecati, C. & Ding, S. X. A. Survey of fault diagnosis and fault-tolerant techniques—Part I: fault diagnosis with model-\nbased and signal-based approaches. IEEE Trans. Ind. Electron. 62, 3757–3767. https://doi.org/10.1109/TIE.2015.2417501 (2015).\n 10. Zhen, L., Zhengjia, H., Y anyang, Z. & Xuefeng C.Bearing condition monitoring based on shock pulse method and improved \nredundant lifting scheme. Math. Comput. Simul. 79, 318–338. https://doi.org/10.1016/j.matcom.2007.12.004 (2008).\n 11. Li, D. Z., Wang, W . & Ismail, F . A. Enhanced bispectrum technique with auxiliary frequency injection for induction motor health \ncondition monitoring. IEEE Trans. Instrum. Meas. 64, 2679–2687. https://doi.org/10.1109/TIM.2015.2419031 (2015).\n 12. Durak, L. & Arikan O.Short-time fourier transform: two fundamental properties and an optimal implementation. IEEE Trans. \nSignal. Process. 51, 1231–1242. https://doi.org/10.1109/TSP .2003.810293 (2003).\n 13. Zhang, D. W . Transform. In Fundamentals of Image Data Mining (Cham: Springer International Publishing: 35–44). \n 14. Huang, N. E., Wu, Z. A. & review on Hilbert-Huang transform: method and its applications to geophysical studies. Rev. Geophys. \n46 https://doi.org/10.1029/2007RG000228 (2008).\n 15. Noble, W . S.What is a support vector machine? Nat. Biotechnol. 24, 1565–1567. https://doi.org/10.1038/nbt1206-1565 (2006).\n 16. Belgiu, M. & Drăguţ L.Random forest in remote sensing: A review of applications and future directions. ISPRS J. Photogramm. \nRemote Sens. 114, 24–31. https://doi.org/10.1016/j.isprsjprs.2016.01.011 (2016).\n 17. Friedman, N., Geiger, D. & Goldszmidt M.Bayesian network classifiers.\n 18. Chen, X., Zhang, B. & Gao D.Bearing fault diagnosis base on multi-scale CNN and LSTM model. J. Intell. Manuf. 32, 971–987. \nhttps://doi.org/10.1007/s10845-020-01600-2 (2021).\n 19. Lei, J., Liu, C. & Jiang D.Fault diagnosis of wind turbine based on long short-term memory networks. Renew. Energy 133, 422–432. \nhttps://doi.org/10.1016/j.renene.2018.10.031 (2019).\n 20. Harrou, F ., Kini, K. R., Madakyaru, M. & Sun, Y . Uncovering sensor faults in wind turbines: an improved multivariate statistical \napproach for condition monitoring using SCADA data. Sustain. Energy Grids Netw. 35, 101126.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / j . s e g a n . 2 0 \n2 3 . 1 0 1 1 2 6     (2023).\n 21. Kini, K. R., Harrou, F ., Madakyaru, M. & Sun, Y . E. Wind turbine performance: statistical detection of sensor faults based on \nimproved dynamic independent component analysis. Energies 16, 5793. https://doi.org/10.3390/en16155793 (2023).\n 22. Dong, Z., Zhao, D. & Cui L.An intelligent bearing fault diagnosis framework: one-dimensional improved self-attention-enhanced \nCNN and empirical wavelet transform. Nonlinear Dyn. 112, 6439–6459. https://doi.org/10.1007/s11071-024-09389-y (2024).\n 23. Song, X., Cong, Y ., Song, Y ., Chen, Y . & Liang P .A bearing fault diagnosis model based on CNN with wide convolution kernels. J. \nAmbient Intell. Hum. Comput. 13, 4041–4056. https://doi.org/10.1007/s12652-021-03177-x (2022).\n 24. Y adav, D. P ., Sharma, B., Chauhan, S., Amin, F . & Abbasi, R. Enhancing road crack localization for sustainable road safety using \nHCTNet. Sustainability 16, 4409. https://doi.org/10.3390/su16114409 (2024).\n 25. Mahmoud, M. S., Salem, A., Huynh, V . K. & Robbersmyr, K. G. A. Few–shot open-circuit fault diagnosis of F-Type inverters \nusing CGAN-based vision transformer. IEEE J. Emerg. Sel. Top. Power Electron. 1–1. https://doi.org/10.1109/JESTPE.2024.3478378 \n(2024).\n 26. Y adav, D. P ., Sharma, B., Chauhan, S. & Dhaou, I. B. Bridging convolutional neural networks and transformers for efficient crack \ndetection in concrete building structures. Sensors 24, 4257. https://doi.org/10.3390/s24134257 (2024).\n 27. Cao, L., Zhang, H., Meng, Z. & Wang X.A parallel GRU with dual-stage attention mechanism model integrating uncertainty \nquantification for probabilistic RUL prediction of wind turbine bearings. Reliab. Eng. Syst. Saf. 235, 109197.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 \n6 / j . r e s s . 2 0 2 3 . 1 0 9 1 9 7     (2023).\n 28. Huang, T., Zhang, Q., Tang, X., Zhao, S. & Lu X.A novel fault diagnosis method based on CNN and LSTM and its application in \nfault diagnosis for complex systems. Artif. Intell. Rev. 55, 1289–1315. https://doi.org/10.1007/s10462-021-09993-z (2022).\n 29. Nguyen Da, T., Thanh, N., Cho, M. Y . & P ., & Novel cloud-AIoT fault diagnosis for industrial diesel generators based hybrid deep \nlearning CNN-BGRU algorithm. Internet Things  26 https://doi.org/10.1016/j.iot.2024.101164 (2024).\n 30. Huo, Z., Y ang, X., Zhang, T., Wang, Y . & Zheng, Y . CNN-GRU fault diagnosis method for rolling bearing. In 2021 CAA Symposium \non Fault Detection, Supervision, and Safety for Technical Processes (SAFEPROCESS) 1–6. Chengdu, China, IEEE.\n 31. Prasad Y adav, D., Chauhan, S., Kada, B. & Kumar A.Spatial attention-based dual stream transformer for concrete defect \nidentification. Measurement 218, 113137. https://doi.org/10.1016/j.measurement.2023.113137 (2023).\n 32. Guo, J., Y ang, Y ., Li, H., Dai, L. & Huang B.A parallel deep neural network for intelligent fault diagnosis of drilling pumps. Eng. \nAppl. Artif. Intell. 133, 108071. https://doi.org/10.1016/j.engappai.2024.108071 (2024).\n 33. Vaswani, A. et al. I.Attention is all you need.\n 34. Wang, Q. et al. Efficient channel attention for deep convolutional neural networks. In 2020 IEEE/CVF Conference on Computer \nVision and Pattern Recognition (CVPR) 11531–11539. Seattle, W A, USA, IEEE.\n 35. Li, Z. B., Feng, X. Y ., Wang, L. & Xie, Y . C.DC–DC  circuit fault diagnosis based on GWO optimization of 1DCNN-GRU network \nhyperparameters. Energy Rep. 9, 536–548. https://doi.org/10.1016/j.egyr.2023.03.069 (2023).\n 36. Wang, H., Liu, Z., Peng, D., Y ang, M. & Qin, Y . F . L. Attention-guided multitask CNN for fault diagnosis and working conditions \nidentification of rolling bearing. IEEE Trans. Neural Netw. Learn. Syst. 33, 4757–4769. https://doi.org/10.1109/TNNLS.2021.3060494 \n(2022).\n 37. Xu, Y . et al. Z.Attention-based multiscale denoising residual convolutional neural networks for fault diagnosis of rotating \nmachinery. Reliab. Eng. Syst. Saf. 226, 108714. https://doi.org/10.1016/j.ress.2022.108714 (2022).\n 38. Gao, D., Zhu, Y ., Wang, X., Y an, K. & Hong, J. A. Fault diagnosis method of rolling bearing based on complex Morlet CWT and \nCNN. In 2018 Prognostics and System Health Management Conference (PHM-Chongqing) 1101–1105. Chongqing, IEEE.\n 39. Rioul, O. & Duhamel P .Fast algorithms for discrete and continuous wavelet transforms. IEEE Trans. Inf. Theory   38, 569–586. \nhttps://doi.org/10.1109/18.119724 (1992).\n 40. Gu, J. et al. T.Recent Advances in Convolutional Neural Networks. arXiv.\nScientific Reports |        (2025) 15:12344 18| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/\n 41. Chollet, F . X. & Recognition, P . Deep learning with depthwise separable convolutions. In IEEE Conference on Computer Vision and \n(CVPR) 1800–1807. Honolulu, HI, (IEEE, 2017).\n 42. Srivastava, H., Sarawadekar, K. A. & Depthwise separable convolution architecture for CNN accelerator. In 2020 IEEE Applied \nSignal Processing Conference (ASPCON) 1–5. Kolkata, India, IEEE.\n 43. Howard, A. et al. & Le, Q.Searching for MobileNetV3. In  2019 IEEE/CVF International Conference on Computer Vision (ICCV) \n1314–1324. Seoul, Korea (South), IEEE.\n 44. Niu, Z., Zhong, G. & Yu H.A review on the attention mechanism of deep learning. Neurocomputing 452, 48–62.  h t t p s : / / d o i . o r g / 1 0 \n. 1 0 1 6 / j . n e u c o m . 2 0 2 1 . 0 3 . 0 9 1     (2021).\n 45. Ouyang, D. et al. Multi-scale attention module with cross-spatial learning. In ICASSP 2023–2023 IEEE International Conference on \nAcoustics, Speech and Signal Processing (ICASSP) 1–5. Rhodes Island, Greece, IEEE.\n 46. Cho, K. et al. Y .Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv.\n 47. Dave, V . et al. Learning-enhanced small-sample bearing fault analysis using Q-transform and HOG image features in a GRU-XAI \nframework. Machines 12, 373. https://doi.org/10.3390/machines12060373 (2024).\n 48. Falessi, D., Huang, J., Narayana, L., Thai, J. F . & Turhan B.On the need of preserving order of data when validating within-project \ndefect classifiers. Empir. Softw. Eng. 25, 4805–4830. https://doi.org/10.1007/s10664-020-09868-x (2020).\n 49. Chen, C. F ., Fan, Q. & Panda, R. C. V . T. Cross-attention multi-scale vision transformer for image classification. arXiv.\n 50. Zhang, W ., Peng, G., Li, C., Chen, Y . & Zhang, Z. A. New deep learning model for fault diagnosis with good anti-noise and domain \nadaptation ability on raw vibration signals. Sensors 17, 425. https://doi.org/10.3390/s17020425 (2017).\n 51. Wang, Z., Y an, W . & Oates T.Time series classification from scratch with deep neural networks: A strong baseline. In 2017 \nInternational Joint Conference on Neural Networks (IJCNN) 1578–1585 Anchorage, AK, USA, IEEE .\n 52. Song, S., Zhang, S., Dong, W ., Li, G. & Pan C.Multi-source information fusion meta-learning network with convolutional block \nattention module for bearing fault diagnosis under limited dataset. Struct. Health Monitor. 23, 818–835.   h t t p s : / / d o i . o r g / 1 0 . 1 1 7 7 / 1 \n4 7 5 9 2 1 7 2 3 1 1 7 6 0 4 5     (2024).\nAcknowledgements\nThis research was funded by the Xiamen Natural Science Foundation of China under Grant 3502Z20227198.\nAuthor contributions\nMethodology, Q.C., F .Z., Y .W .; software, Q.C., Q.Y .; validation Q.C., Y .W ., G.L; data curation Q.C., L.Z., G.L.; \nwriting—original draft preparation, Q.C.; writing—review and editing, Q.C., F .Z., and Q.Y .; funding acquisition, \nF .Z.; All authors have read and agreed to the published version of the manuscript.\nDeclarations\nCompeting interests\nThe authors declare no competing interests.\nAdditional information\nSupplementary Information The online version contains supplementary material available at  h t t p s : / / d o i . o r g / 1 \n0 . 1 0 3 8 / s 4 1 5 9 8 - 0 2 5 - 9 5 8 9 5 - x     .  \nCorrespondence and requests for materials should be addressed to F .Z.\nReprints and permissions information is available at www.nature.com/reprints.\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and \ninstitutional affiliations.\nOpen Access  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives \n4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in \nany medium or format, as long as you give appropriate credit to the original author(s) and the source, provide \na link to the Creative Commons licence, and indicate if you modified the licensed material. Y ou do not have \npermission under this licence to share adapted material derived from this article or parts of it. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence \nand your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to \nobtain permission directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o \nn s . o r g / l i c e n s e s / b y - n c - n d / 4 . 0 /     .  \n© The Author(s) 2025 \nScientific Reports |        (2025) 15:12344 19| https://doi.org/10.1038/s41598-025-95895-x\nwww.nature.com/scientificreports/",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.731591522693634
    },
    {
      "name": "Parallelism (grammar)",
      "score": 0.5501160025596619
    },
    {
      "name": "Transformer",
      "score": 0.48017969727516174
    },
    {
      "name": "Fault (geology)",
      "score": 0.4555659294128418
    },
    {
      "name": "Bearing (navigation)",
      "score": 0.4447503387928009
    },
    {
      "name": "Parallel computing",
      "score": 0.41179099678993225
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3625847101211548
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3623705208301544
    },
    {
      "name": "Electrical engineering",
      "score": 0.08148446679115295
    },
    {
      "name": "Geology",
      "score": 0.07573002576828003
    },
    {
      "name": "Seismology",
      "score": 0.05948016047477722
    },
    {
      "name": "Engineering",
      "score": 0.05507385730743408
    },
    {
      "name": "Voltage",
      "score": 0.05414876341819763
    }
  ],
  "cited_by": 10
}