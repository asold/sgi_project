{
  "title": "Large language models streamline automated machine learning for clinical studies",
  "url": "https://openalex.org/W4392016947",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2623000210",
      "name": "Soroosh Tayebi Arasteh",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097930329",
      "name": "Tianyu Han",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A3129062026",
      "name": "Mahshad Lotfinia",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A2171454352",
      "name": "Christiane Kuhl",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "University Hospital Carl Gustav Carus",
        "National Center for Tumor Diseases",
        "University Hospital Heidelberg",
        "Heidelberg University"
      ]
    },
    {
      "id": "https://openalex.org/A2029259259",
      "name": "Daniel Truhn",
      "affiliations": [
        "RWTH Aachen University"
      ]
    },
    {
      "id": "https://openalex.org/A11407780",
      "name": "Sven Nebelung",
      "affiliations": [
        "RWTH Aachen University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4205164650",
    "https://openalex.org/W4361298490",
    "https://openalex.org/W3196012986",
    "https://openalex.org/W2905483812",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4366818660",
    "https://openalex.org/W3006913750",
    "https://openalex.org/W3161546262",
    "https://openalex.org/W4295036551",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4375861579",
    "https://openalex.org/W4385158697",
    "https://openalex.org/W4384661486",
    "https://openalex.org/W1988790447",
    "https://openalex.org/W1678356000",
    "https://openalex.org/W4324135090",
    "https://openalex.org/W2911964244",
    "https://openalex.org/W2087347434",
    "https://openalex.org/W3174446981",
    "https://openalex.org/W3163032543",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4321606060",
    "https://openalex.org/W4220704354",
    "https://openalex.org/W4283760976",
    "https://openalex.org/W2129833620",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4385543838",
    "https://openalex.org/W6852476831",
    "https://openalex.org/W4313312731",
    "https://openalex.org/W4377861964",
    "https://openalex.org/W4385242971",
    "https://openalex.org/W4324308091",
    "https://openalex.org/W4368367885",
    "https://openalex.org/W4367186868",
    "https://openalex.org/W4365143687",
    "https://openalex.org/W4382181231",
    "https://openalex.org/W3112631310",
    "https://openalex.org/W2981731882",
    "https://openalex.org/W2918368791",
    "https://openalex.org/W2605471079",
    "https://openalex.org/W4285798540",
    "https://openalex.org/W4223430324",
    "https://openalex.org/W4308019809",
    "https://openalex.org/W2987229635",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W2102201073",
    "https://openalex.org/W2087600499",
    "https://openalex.org/W3183729494",
    "https://openalex.org/W2617595617",
    "https://openalex.org/W6967650839",
    "https://openalex.org/W4392016947",
    "https://openalex.org/W4321351832"
  ],
  "abstract": "Abstract A knowledge gap persists between machine learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to ChatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study’s training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Following the re-implementation and optimization of the published models, the head-to-head comparison of the ChatGPT ADA-crafted ML models and their respective manually crafted counterparts revealed no significant differences in traditional performance metrics ( p ≥ 0.072). Strikingly, the ChatGPT ADA-crafted ML models often outperformed their counterparts. In conclusion, ChatGPT ADA offers a promising avenue to democratize ML in medicine by simplifying complex data analyses, yet should enhance, not replace, specialized training and resources, to promote broader applications in medical research and practice.",
  "full_text": "Article https://doi.org/10.1038/s41467-024-45879-8\nLarge language models streamline\nautomated machine learning for clinical\nstudies\nSoroosh Tayebi Arasteh1 ,T i a n y uH a n1 ,M a h s h a dL o tﬁnia 1,2,\nChristiane Kuhl1, Jakob Nikolas Kather3,4,D a n i e lT r u h n1,5 &\nSven Nebelung 1,5\nA knowledge gap persists between machine learning (ML) developers (e.g.,\ndata scientists) and practitioners (e.g., clinicians), hampering the full utiliza-\ntion of ML for clinical data analysis. We investigated the potential of the\nChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this\ngap and perform ML analyses efﬁciently. Real-world clinical datasets and study\ndetails from large trials across variousmedical specialties were presented to\nChatGPT ADA without speciﬁc guidance. ChatGPT ADA autonomously devel-\noped state-of-the-art ML models based on the original study’s training data to\npredict clinical outcomes such as cancer development, cancer progression,\ndisease complications, or biomarkers such as pathogenic gene sequences.\nFollowing the re-implementation and optimization of the published models,\nthe head-to-head comparison of theChatGPT ADA-crafted ML models and\ntheir respective manually craftedcounterparts revealed no signiﬁcant differ-\nences in traditional performance metrics (p ≥ 0.072). Strikingly, the ChatGPT\nADA-crafted ML models often outperformed their counterparts. In conclusion,\nChatGPT ADA offers a promising avenue to democratize ML in medicine by\nsimplifying complex data analyses, yetshould enhance, not replace, specia-\nlized training and resources, to promote broader applications in medical\nresearch and practice.\nMachine learning (ML) drives advancements in artiﬁcial intelligence\nand is about to transform medical research and practice, especially in\ndiagnosis and outcome prediction\n1,2. Recently, the adoption of ML for\nanalyzing clinical data has expanded rapidly. Today, ML models have\nan established and evolving role in various areas of public health and\nmedicine, spanning image analysis, public health, clinical-trial perfor-\nmance, and operational organization\n2. ML models are used in variable\ncontexts such as augmenting medical knowledge, assisting clinicians,\nor taking on administrative tasks\n3. Several developments, such as\nincreases in (i) available data generated during clinical care, (ii) avail-\nable computational processing capacities, and (iii) research activities,\nfavor the more widespread future utilization of ML models in\nmedicine\n4. However, the complexity of developing, implementing, and\nvalidating those models renders them inaccessible to most clinicians\nand medical researchers\n5. It also limits their utilization to those people\nor groups that combine expertise in medicine and data science.\nAutomated machine learning (AutoML) is an established dis-\ncipline that aims to make ML accessible to non-technical experts. In\nReceived: 10 October 2023\nAccepted: 6 February 2024\nCheck for updates\n1Department of Diagnostic and Interventional Radiology, University Hospital RWTH Aachen, Aachen, Germany.2Institute of Heat and Mass Transfer, RWTH\nAachen University, Aachen, Germany.3Else Kroener Fresenius Center for Digital Health, Medical Faculty Carl Gustav Carus, Technical University Dresden,\nDresden, Germany.4Medical Oncology, National Center for Tumor Diseases (NCT), University Hospital Heidelberg, Heidelberg, Germany.5These authors\njointly supervised this work: Daniel Truhn, Sven Nebelung.e-mail: soroosh.arasteh@rwth-aachen.de; than@ukaachen.de\nNature Communications|         (2024) 15:1603 1\n1234567890():,;\n1234567890():,;\nmedicine, the principle feasibility and use of AutoML platforms, such\nas the Classiﬁcation Learner of MATLAB (MathWorks Inc.), Vertex AI\n(Google LLC), and Azure (Microsoft Corporation), have been\ndemonstrated\n6– 11, enabling non-technical experts to create ML models.\nThese software solutions automate algorithm training andﬁne-tuning\nby providing dedicated interfaces to build and run a particular ML\nmodel. The user needs to direct the software to the desired output. So\nfar, however, models using natural language commands and their\nconversion to Python code have not been implemented.\nPowerful large language models (LLMs)\n12, such as ChatGPT’s latest\nversion, GPT-413 (Generative Pre-Trained Transformer-4, OpenAI, CA,\nUS), expand the repertoire of AutoML platforms by offering a well-\naccessible option to the user\n14,15. While conversing with humans in plain\nlanguage, LLMs can reason and perform logical deduction. Recently,\nthe ChatGPT Advanced Data Analysis (ADA), formerly known as\nChatGPT Code Interpreter, has been made available as an extension\nand beta feature that may be used to analyze data and math problems,\ncreate charts, and write, execute, and re ﬁne computer code\n16.\nInstructing ChatGPT ADA can be straightforward, such as“Analyze this\npatient data and build a machine-learning model predicting 12-month\nmortality rates”. Given this prompt, ChatGPT ADA will execute the task\nand provide feedback on the procedure. However, its validity and\nreliability in advanced data processing and analysis for large clinical\ntrials have not yet been evaluated.\nOur objective was to study the validity and reliability of ChatGPT\nADA in autonomously developing and implementing ML methods. We\nincluded real-world datasets from four large clinical trials of various\nmedical specialties that applied ML models for advanced data analysis\n(Fig. 1). We hypothesized that (i) ChatGPT ADA may be used intuitively\nand does not require prior training, resources, and guidance in ML\ntheory and practice to implement advanced ML methods efﬁciently\nand accurately and that (ii) the results of these implementations match\nthose of specialized data scientists. We provide evidence that\nadvanced LLMs like ChatGPT ADA simplify complex ML methods,\nincreasing their accessibility in medicine and beyond.\nResults\nAcross four large clinical-trial datasets, ChatGPT ADA autonomously\nformulated and executed advanced ML techniques for disease screen-\ning and prediction. Its performance matched the hand-crafted and\ncustomized ML methods re-implemented based on the original studies.\nFigure 2 illustrates an exemplary interaction with ChatGPT ADA, high-\nlighting the prompts and responses for autonomous prediction.\nAfter brieﬂy summarizing each clinical trial and associated data-\nset, we compare the ML methods head-to-head for each trial. We\ninclude ML methods developed and executed by ChatGPT ADA against\nthe performance metrics of the originally published ML methods (as\nreported in the original studies) and the validatory ML methods (as re-\nimplemented by a seasoned data scientist, S.T.A. withﬁve years of\nexperience in ML). Because individual patient predictions were una-\nvailable in the original studies, the best-performing ML methods of the\noriginal studies were re-implemented. We conclude our analysis by\nFig. 1 | Study design.Real-world datasets and study details from four large clinical\ntrials were collected and input into the ChatGPT Advanced Data Analysis (ADA)\ntool. The tool autonomously selected the appropriate machine-learning models for\nthe analysis following prompting. The models were expert-checked and compre-\nhensively evaluated. The ChatGPT ADA-based predictions were compared to the\noriginal studies (benchmark publication) and the validatory predictions following\nthe re-implementation of the models. Figure 1 was provided by a freelancer service\n(ﬁverr.com). Copyright rests with the authors. Theﬁgure constitutes original\nmaterial and has not been published before.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 2\npresenting the explainability metrics determined by ChatGPT ADA and\nconﬁrmed by our re-implementation.\nMetastatic disease [endocrinologic oncology]—predicting\nmetastatic disease in pheochromocytoma and paraganglioma\nPamporaki et al. utilized cross-sectional cohort data from the US,\nGermany, Poland, and the Netherlands, and employed ML methods to\npredict metastatic disease in patients diagnosed with pheochromo-\ncytoma or paraganglioma using blood test results\n17. These tumors are\nreferred to as the‘great masquerader’ because of their unspeciﬁc\nclinical presentation secondary to largely variable catecholamine\nexcess, which poses diagnostic challenges\n17. The original study’s\ntraining and test set cohorts comprised 493 and 295 patients (Table1).\nUsing predictions by 12 clinical experts as their reference, the authors\nimplemented multiple supervised ML models, i.e., the decision tree\nclassiﬁer, support vector machine, Naïve Bayes, and AdaBoost18\nensemble tree classiﬁer. In the original study, the latter model per-\nformed best and signiﬁcantly outperformed the clinical care specia-\nlists, with an area under the receiver operating characteristic curve\n(AUROC) of 0.942 versus 0.815 (best-performing clinical expert,\np < 0.001). Using the same (training and test) dataset distribution as\nthe original study but withholding speciﬁcg u i d a n c eo nd a t ap r e -\nprocessing or ML methodology, weprompted ChatGPT ADA to predict\nmetastatic disease in the test set while. ChatGPT ADA selected a Gra-\ndient Boosting Machine (GBM)\n19 model for its prediction and achieved\na slightly improved performance relative to its best-performing pub-\nlished counterpart in terms of AUROC values (0.949 vs. 0.942), accu-\nracy (0.922 vs. 0.907), and F1-scores (0.806 vs. 0.755) (Table2). The\nentire conversation with ChatGPT ADA regarding prompts and\nresponses is detailed in Supplementary Note 1.\nAfter re-implementing and optimizing the best-performing ML\nmodel from the original study, i.e., the AdaBoost\n18 ensemble tree\nclassiﬁer, as our validatory ML model, we performed a head-to-head\ncomparison. The performance metrics were similar (validatory re-\nimplementation: AUROC = 0.951 ± 0.014 [95% CI: 0.920, 0.977];\nChatGPT ADA: AUROC = 0.949 ± 0.015 [95% CI: 0.917, 0.974]) and not\nsigniﬁcantly different (p =0 . 4 6 4 )( T a b l e3 and Fig.3).\nEsophageal cancer [gastrointestinal oncology]—predicting car-\ncinoma of the distal esophagus and oesophagogastric junction\nGao et al. used sponge cytology testing and epidemiologic data to\nscreen for esophageal squamous cell carcinoma and adenocarcinoma\nof the oesophagogastric junction\n20. The authors obtained multicohort\ndata from 14,597 participants in China (Table1)t od e s i g ns i xM L\nmodels, i.e., logistic regression, adaptive boosting, Light Gradient\nBoosting Machine (LightGBM)21, extreme gradient boosting, Random\nForest (RF)22, and support vector machine23, to predict high-grade\nintraepithelial neoplasia and carcinoma based on 105 cytologic and 15\nepidemiologic features. The best-performing model was the\nLightGBM, which achieved an AUROC value of 0.960 in the test set. In\ncontrast, ChatGPT ADA selected the GBM and outperformed the ori-\nginal model at an AUROC value of 0.979 (Table2). Supplementary\nNote 2 details the entire conversation with ChatGPT ADA for this\ndataset.\nThe head-to-head analysis of the ChatGPT ADA-selected ML\nmodel and our validatory re-implemented ML model indicated\nlargely similar AUROC values of 0.979 ± 0.004 [95% CI: 0.970,\n0.986] and 0.978 ± 0.005 [95% CI: 0.967, 0.986], respectively,\nwhich were not signi ﬁcantly different ( p =0 . 4 9 6 ) ( T a b l e3\nand Fig.3).\nFig. 2 | Screenshots of an example interaction with ChatGPT ADA to analyze\nthe endocrinologic oncology dataset.ChatGPT ADA autonomously selects and\napplies the appropriate ML model for the provided dataset, generating predictions\nfor the test data. The model also displays deeper insights in response to follow-up\nqueries about the reasoning and parameters guiding its choices. Note: The“Show\nwork” option visible in the images allows users to view the intermediary Python\ncode offered by the tool.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 3\nHereditary hearing loss [otolaryngology]—predicting patho-\ngenic genetic variants\nLuo et al. aimed to identify patients with hereditary hearing loss based\non particular gene sequences, i.e., the sequence variants at 144 sites in\nthree genes\n24. Using data from 1778 patients and controls (Table1), the\nauthors implemented six supervised ML models, i.e., the decision tree,\nrandom forest, k-nearest neighbor, adaptive boosting, multilayer\nperceptron models, and the support vector machine\n23.T h el a t t e rM L\nmethod performed best (AUROC value of 0.751) and outperformed\nthree clinical experts. The ChatGPT ADA-selected predictive model,\ni.e., the RF classiﬁer, outperformed the original model regarding\nAUROC values (0.773) yet demonstrated inferior performance\nregarding accuracy (0.767 vs. 0.812) and F1-score (0.845 vs. 0.861)\n(Table 2). Supplementary Note 3 details the entire conversation with\nChatGPT ADA for this dataset.\nThe head-to-head analysis of the ChatGPT ADA-selected ML\nmodel and our validatory re-implemented ML model indicated largely\nsimilar AUROC values of 0.773 ± 0.024 [95% CI: 0.726, 0.817] and\n0.762 ± 0.026 [95% CI: 0.714, 0.812], respectively, which were not sig-\nniﬁcantly different (p =0 . 6 2 4 )( T a b l e3 and Fig.3).\nCardiac amyloidosis [cardiology]—predicting the\ncardiomyopathies\nHuda et al. attempted to identify patients at risk of cardiac amyloidosis,\na now treatable condition predisposing to heart failure, using various\ncohorts and established medical diagnoses retrieved from health\nrecords\n25. Using data from 2142 patients and controls (Table1), the\nauthors designed three ML models, i.e., logistic regression, extreme\ngradient boosting, and RF classiﬁer. They found the latter ML model to\nperform best (AUROC value of 0.930 [internal validation set]). Because\nthe external validation dataset was not publicly available, we used the\noriginal study’s internal validation set to prompt ChatGPT ADA as\nabove. The ChatGPT ADA-selected predictive model, i.e., the RF clas-\nsiﬁer, outperformed the original model regarding the AUROC (0.954)\nand the other performance metrics (Table2). Supplementary Note 4\ndetails the entire conversation with ChatGPT ADA for this dataset.\nTable 1 | Characteristics of the clinical trials whose datasets were included\nMetastatic disease17 [endocrinologic\noncology]\nEsophageal cancer20\n[gastrointestinal\noncology]\nHereditary hearing\nloss24 [otolaryngology]\nCardiac Amyloidosis25\n[cardiology] (*)\nTraining set Test set Training set Test set Training set Test set Training set Test set\nPatient number\nTotal [n] (with disease/without dis-\nease [%])\n493\n(34/66)\n295\n(19/81)\n7899\n(3/97)\n6698\n(2/98)\n1209\n(76/24)\n569\n(77/23)\n1712\n(50/50)\n430\n(50/50)\nPatient sex\nFemale/male [%] 49/51 57/43 0/100 0/100 49/51 39/61 N/A N/A\nPatient age [years]\nMedian\nMean ± standard deviation\nRange (minimum, maximum)\n42\n42 ± 18\n(4, 83)\n48\n47 ± 16\n(11, 82)\n56\n56 ± 9\n(39, 82)\n55\n56 ± 9\n(24, 86)\nN/A\n18 ± 15\n(N/A, N/A)\nN/A\n34 ± 12\n(N/A, N/A)\nN/A N/A\nLocation of clinical trial US, Netherlands Germany, Poland,\nNetherlands\nChina China China China US US\n(*) indicates that the original data split and, consequently, the external validation dataset was unavailable per the original study. In line with the published methodology, we randomly allocated 80% of\npatients and controls to the training set (n = 1712) and 20% to the test set (n =4 3 0 ) .N/A not available.\nTable 2 | Benchmark publication— ML models and their published performance metrics as a function of clinical-trial dataset\nAUROC Accuracy F1-score Sensitivity Speci ﬁcity\nMetastatic disease [endocrinologic oncology]17\nBest-performing ML model (original study): AdaBoost18 ensemble tree 0.942 0.907 0.755 0.833 0.922\nChatGPT ADA: GBM 0.949 0.922 0.806 0.841 0.941\nBest-performing clinical expert 0.815 0.830 N/A 0.800 0.850\nMean of clinical experts [n = 12] 0.710 0.722 N/A 0.664 0.755\nEsophageal cancer [gastrointestinal oncology]\n20\nBest-performing ML models (original study): LightGBM 0.960 N/A N/A 0.945 0.919\nChatGPT ADA: GBM 0.979 0.985 0.538 0.457 0.995\nHereditary hearing loss [otolaryngology]\n24\nBest-performing ML model (original study): Support vector machine 0.751 0.812 0.861 0.925 N/A\nChatGPT ADA: RF 0.773 0.767 0.845 0.834 0.541\nMean of clinical experts [n = 3] N/A N/A N/A 0.789 0.470\nCardiac amyloidosis [cardiology]\n25\nBest-performing ML model (original study): RF 0.930 0.870 0.875 0.870 0.870\nChatGPT ADA: RF 0.954 0.892 0.894 0.903 0.884\nIndicated are the performance metrics of the best-performing ML models as published in the original studies, of the ChatGPT ADA-based ML models, and,if available, of individual or numerous\nclinical experts.\nAdaBoostadaptive boosting,AUROCarea under the receiver operating characteristic curve,ChatGPT ADAChatGPT advanced data analysis,GBMgradient boosting machine, LightGBM light gradient\nboosting machine,N/A not available,RF random forest.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 4\nTable 3 | Benchmark validatory re-implementation— ML models and their performance metrics as a function of clinical-trial dataset\nAUROC Accuracy F1-score Sensitivity Speci ﬁcity\nMetastatic disease [endocrinologic oncology]17\nValidatory model (AdaBoost ensemble tree) 0.951 ± 0. 014 [0.920, 0.977] 0.911 ± 0.016 [ 0.878, 0.942] 0.783 ± 0.041 [0.698 , 0.862] 0.821 ± 0.050 [0.720, 0.915] 0.932 ± 0.016 [0.900, 0.962]\nChatGPT ADA (GBM) 0.949 ± 0.015 [0.917, 0.974] 0.922 ± 0.016 [0.892, 0.953] 0.806 ± 0.039 [0.727, 0.876] 0.841 ± 0.050 [0.742, 0.933] 0.941 ± 0.015 [0.90 9, 0.969]\np-value 0.464 0.665 0.659 0.619 0.646\nEsophageal cancer [gastrointestinal oncology]20\nValidatory model (LightGBM) 0.978 ± 0.005 [0.967, 0.986] 0.986 ± 0.001 [0.983, 0.989] 0.576 ± 0.041 [0.492, 0.652] 0.497 ± 0.045 [0.411, 0.585] 0.996 ± 0.001 [0.994, 0.997]\nChatGPT ADA (GBM) 0.979 ± 0.004 [0.970, 0.986] 0.985 ± 0.001 [0.982, 0.988] 0.538 ± 0.043 [0.452, 0.620] 0.457 ± 0.044 [0.370, 0.541] 0.995 ± 0.001 [0.99 4, 0.997]\np-value 0.496 0.271 0.267 0.238 0.404\nHereditary hearing loss [otolaryngology]24\nValidatory model (support vector machine) 0.762 ± 0.026 [0.714, 0.812] 0.783 ± 0.018 [0.747, 0.817] 0.860 ± 0.012 [0.836, 0.884] 0.869 ± 0.016 [0.836, 0.899] 0.503 ± 0.043 [0.419, 0.584]\nChatGPT ADA (RF) 0.773 ± 0.024 [0.726, 0.817] 0.767 ± 0.018 [0.733, 0.800] 0.845 ± 0.013 [0.820, 0.869] 0.834 ± 0.018 [0.795, 0.867] 0.541 ± 0.044 [0.453 ,0 . 6 2 8 ]\np-value 0.624 0.249 0.198 0.072 0.741\nCardiac amyloidosis [Cardiology]25\nValidatory model (RF) 0.952 ± 0.010 [0.931, 0.969] 0.890 ± 0.015 [0.858, 0.919] 0.892 ± 0.016 [0.860, 0.920] 0.893 ± 0.020 [0.853, 0.932] 0.888 ± 0.021 [ 0.847, 0.928]\nChatGPT ADA (RF) 0.954 ± 0.010 [0.934, 0.972] 0.892 ± 0.015 [0.863, 0.921] 0.894 ± 0.016 [0.862, 0.922] 0.903 ± 0.020 [0.860, 0.938] 0.884 ± 0.023 [0.841 ,0 . 9 2 6 ]\np-value 0.539 0.525 0.539 0.647 0.460\nIndicated are the performance metrics of the re-implemented and optimized ML models (as reported to perform best in the original studies) and of the ChatGPT ADA-based ML models. A seasoned data scientist re-implemented the ML models for validation\npurposes, thereby making per-patient predictions and head-to-head comparisons using bootstrapping available.Performance metrics are presented as mean ± standard deviation [95% Conﬁdence Intervals]. Bootstrapping54 with replacements and 1000 redraws\non the test sets (number of independent samples: endocrinologic oncology dataset,n = 295; Gastrointestinal Oncology dataset,n = 6698, Otolaryngology dataset,n = 569; Cardiology dataset,n = 430) was applied to determine means and measures of statistical\nspread in terms of standard deviations and 95% conﬁdence intervals and if the metrics were signiﬁcantly different. We adjusted for multiple comparisons based on the false discovery rate, setting the family-wise alpha threshold at 0.05. Source data are provided as\naS o u r c eD a t aﬁle.\nAdaBoost adaptive boosting,AUROC area under the receiver operating characteristic curve,ChatGPT ADAChatGPT advanced data analysis,GBM gradient boosting machine,LightGBM light gradient boosting machine,RF random forest.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 5\nThe head-to-head analysis of the ChatGPT ADA-selected ML\nmodel and our validatory re-implemented ML model indicated largely\nsimilar AUROC values of 0.954 ± 0.010 [95% CI: 0.934, 0.972] and\n0.952 ± 0.010 [95% CI: 0.931, 0.969], respectively, which were not\nsigniﬁcantly different (p =0 . 5 3 9 )( T a b l e3 and Fig.3).\nExplainability analysis\nThe interpretation of model predictions, especially in situations\ndemanding transparency and trust, relies on our capacity to grasp the\nimportance of individual features. To study the ability of ChatGPT to\nprovide metrics of explainability, we utilized the SHapley Additive\nexPlanations (SHAP)\n26 analysis that helps quantify each feature’sc o n -\ntributions to a model’s predictions. We instructed ChatGPT ADA to\nperform the SHAP analysis autonomously without providing speciﬁc\nguidance. Figure4 details the top 10 most inﬂuential features (ranked\nby their overall impact as determined by the mean absolute SHAP\nvalues) contributing to the best-performing ML model of each clinical\ntrial. SHAP values measure a feature’si nﬂuence on a model’so u t p u t .\nHigh absolute SHAP values signify substantial impact, and positive\nSHAP values elevate the model’s prediction above the baseline.\nDiscussion\nThe availability of LLMs for advanced data processing27,28,s p e c iﬁcally\nthose with the capacity to write, execute, and reﬁne code like ChatGPT\nADA, marks a pivotal shift in the convergence of data science and\nclinical research and practice. Our investigation of four large clinical\ntrials underscores the potential of these tools to simplify complex ML\nmethods and increase their accessibility in medicine and beyond. If\nimplemented with due diligence, these tools enhance, not replace,\nspecialized training and resources, democratizing access to advanced\ndata processing and, potentially, revolutionizing data-driven medicine.\nWhile ML and “Big Data ” are touted as revolutionizing\nhealthcare\n29, clinicians regularly deal with too many patients in too\nlittle time30. Yet, they make hundreds of decisions each day that are\nprimarily based on eminence and not on published data or studies31.\nConsequently, a valid and reliable tool that automates data processing\nmay decentralize the monopoly of evidence held by specialized insti-\ntutions. While clinicians remain at the center of patient care, ML\nmethods can assist their expertise, e.g., by identifying at-risk patients\nfor speciﬁc conditions based on electronic health records or by ana-\nlyzing complex datasets such as genomic sequences. Intentionally, we\nFig. 3 | Benchmark validatory re-implementation—receiver operating char-\nacteristic (ROC) curves of ML models as a function of the clinical-trial dataset.\nThe ROC curves of the ChatGPT ADA-based ML model (blue, solid curve) and the\nvalidatory ML model as re-implemented by a seasoned data scientist (red, dotted\ncurve) are shown. The True Positive Rate (sensitivity) is plotted versus the False\nPositive Rate (1-speciﬁcity). The diagonal gray line represents the line of no dis-\ncrimination. Source data are provided as a Source Dataﬁle. Bootstrapping\n54 with\nreplacements and 1000 redraws on the test sets (number of independent samples:\nEndocrinologic Oncology dataset,n = 295; Gastrointestinal Oncology dataset,\nn = 6698, Otolaryngology dataset,n = 569; Cardiology dataset,n = 430) was applied\nto determine means and measures of statistical spread, i.e., standard deviations and\n95% conﬁdence intervals (CI). AUROC area under the receiver operating char-\nacteristic curve, ChatGPT advanced data analysis.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 6\ndesigned our study to include variable data types such as clinical data,\ndemographic data, cytologic data, genetic sequencing data, Interna-\ntional Classiﬁcation of Disease codes, and laboratory values from\nclinical trials spanning endocrinology, gastrointestinal oncology,\ngenetics, and cardiology. Beyond empowering clinicians to use the\nclinical data to their patients’advantage, utilizing LLMs for advanced\ndata analysis provides a less costly and more efﬁcient alternative to\nhand-crafted ML models\n32.\nIn assessing accuracy, validity, and reliability, our study utilized\ndatasets from original studies to gauge the robustness of predictions\non previously unseen data. External validation is paramount in evalu-\nating the model and its broader applicability. However, it is worth\nnoting that external validation was absent in the Cardiac Amyloidosis\ndataset. Across various datasets, models chosen by ChatGPT ADA\nconsistently demonstrated performance on par with, or exceeding, the\nhand-crafted ML methods used in the original studies. When com-\nparing performance metrics, i.e., AUROC, accuracy, F1-score, sensi-\ntivity, and speciﬁcity, no signiﬁcant differences were found between\nthe optimized models re-implemented by our data scientist and those\nautonomously chosen by ChatGPT ADA. This observation demon-\nstrates ChatGPT ADA’s ability to select, train, and reﬁne suitable and\nperformant ML models autonomously.\nWe also assessed the risk of overﬁtting, which occurs when a\nmodel excels on training data but may not generalize well to unseen\ndata. When evaluating the model’s execution across training and vali-\ndation datasets for each clinical trial, we observed that ChatGPT ADA\nhad implemented strategies to increase model robustness and gen-\neralizability, like regularization, model selection based on validation,\nand choosing simpler models. However, even though these strategies\nmay be helpful, users should still regularly check performance metrics\nfor signs of overﬁtting.\nPer the design of our prompting strategy, we did not ask ChatGPT\nADA for speciﬁc explanations of why it selected a particular ML model.\nHowever, the tool displayed a surprisingly deep understanding of the\nclinical trial and appropriate analysis methods. For most clinical-trial\ndatasets, ChatGPT ADA employed a median imputation strategy. In\ncontrast, it used a zero-imputation strategy for the Hereditary Hearing\nLoss dataset. When asked to explain, ChatGPT ADA indicated that its\nFig. 4 | Model explainability through the top 10 predictive features for the\nChatGPT ADA-selected machine-learning models.An explainability analysis was\nperformed for each clinical trial including (a) Metastatic Disease [Endocrinologic\nOncology],b Oesophageal Cancer [Gastrointestinal Oncology],c Hereditary\nHearing Loss [Otolaryngology], andd Cardiac Amyloidosis [Cardiology], and\nChatGPT ADA-selected machine-learning model. Indicated are SHapley Additive\nexPlanations (SHAP) values of each predictive feature that measure the feature’s\ninﬂuence on model predictions. High absolute SHAP values signify substantial\ninﬂuence. The features are ranked from top to bottom based on the mean absolute\nSHAP values (color-coded on the right). Inc, speciﬁc gene locations are indicated.\nPlease refer to the Methods for more details on abbreviations. Box plots indicate\nthe ranges (x-axes) of each feature (y-axes). Crosses indicate (arithmetic) means,\nboxes the ranges (ﬁrst [Q1] to third [Q3] quartile), with the central line representing\nthe (arithmetic) median (second quartile [Q2]). Whiskers extend to 1.5 times the\ninterquartile range above Q3 and below Q1. Any data point outside this range is\nconsidered an outlier (dots). Mind the different scales for the color codes and\nSHAP values. Source data are provided as a Source Dataﬁle. ChatGPT ADA per-\nformed the SHAP analysis on the training sets (number of independent samples:\nEndocrinologic Oncology dataset,n = 493, Gastrointestinal Oncology dataset,\nn = 7899, Otolaryngology dataset,n = 1209, and Cardiology dataset,n = 1712).\nPlasma MN plasma concentrations of metanephrine, plasma NMN plasma con-\ncentrations of normetanephrine, SDHB succinate dehydrogenase complex iron-\nsulfur subunit B, Plasma MTY plasma concentrations of methoxytyramine, AGC\natypical glandular cells, DNA deoxyribonucleic acid, Chron. chronic, Cong. con-\ngenital, Dias. diastolic, Sys. systolic. Note: The feature“Hyp. heart w/ HF & Stg 1– 4\nUnsp. CKD” refers to“Hypertensive heart with heart failure coexisting with\nunspeciﬁed stage 1– 4 chronic kidney disease”,w h i l e“Prev. hist. PGGLs” refers to\n“Previous history of Pheochromocytomas and Paragangliomas”.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 7\nchoice was informed by the dataset’s inherent characteristics and\nsemantics: “The data represents the presence (1) or absence (0) of\ncertain genetic variants in patients. Given this binary representation,\nmedian imputation (which would yield either 0 or 1) might introduce\nbias. In genetic studies, undetected or missing variants are often\ninterpreted as absent, making zero-imputation align with this under-\nstanding”. This statement is supported by pertinent literature\nstudies\n33. Contrarily, our seasoned data scientist, with a limited com-\nmand of genetics, used median imputation, underscoring the value of\ndomain-speciﬁc knowledge when setting up domain-speciﬁcM L\nmethods.\nWe did notﬁnd signs of“hallucinations”, i.e., factually erroneous\nresponses\n27,34. Critically, we performed the statistical analysis step-by-\nstep to ascertain the accuracy, reliability, and consistency of the\nmodel’s outputs. Speciﬁc safeguarding measures, such as the provi-\nsion of intermediary Python code throughout the different phases of\nbuilding and executing the ML model, have been implemented by the\nmanufacturer and improve comprehensibility and transparency. If\ncoupled with more general safeguarding measures, e.g., increasing\nuser awareness of hallucinations, enhancing the LLM’s inherent\nrobustness\n35, and implementing regular auditions and quality checks,\nthe tool’s validity and reliability can be ascertained36.W ea s s e s s e dt h e\nconsistency in ChatGPT ADA’s behavior and analysis choices for each\nclinical-trial dataset by prompting the tool multiple times in different\nchat sessions. It consistently selected the same ML model and para-\nmeter settings when provided with identical datasets, instructions, and\nprompts. The only variation occurred when computational resources\nwere limited. In those instances, the tool communicated its primary\nmodel choice but temporarily opted for an alternative.\nRegarding ease of use, ChatGPT ADA substantially reduces the\ncomplexity of developing and implementing ML methods by taking\ntabular data, suggesting how to deal with it, building the model, and\noutputting the results in the desired format. Not least due to its ability\nto communicate with the user, the tool offers a natural and effective\nway to work with ML models. At the same time, the automatization\nsimpliﬁes the associated workﬂow. However, as with any innovation,\nutilizing LLMs in clinical research and practice has multifaceted\nimplications, from data privacy to data security to model interpret-\nability, reliability, and associated ethical concerns\n37– 41. Upholding\npatient data privacy seems particularly challenging as— on the one\nhand— users may be enticed to disclose conﬁdential (or proprietary)\ninformation, let alone sensitive personal data such as race and ethni-\ncity, to use the model most efﬁciently. On the other hand, OpenAI\ncontinuously trains the model using earlier user interactions, including\nprompts, which are retained as part of the ever-enlarging training data\nand cannot be deleted. Consequently, it is the user’sr e s p o n s i b i l i t yt o\nweigh the tool’sa d v a n t a g e sa n db e n eﬁts against its disadvantages\nand risks.\nChatGPT ADA, as a tool, democratizes access to advanced ML\nmethods, enabling clinicians and researchers of all backgrounds to\nharness its capabilities. Besides being a potential cornerstone for their\nbroader utilization in clinical research and practice\n42,t h ei m p r o v e d\naccessibility holds the potential of (i) accelerating medical research, (ii)\nconﬁrming or contradicting earlier research, and (iii) improving\npatient care. However, when using the tool more widely, several\npotential challenges and limitations must be acknowledged. First, the\ntool’s commercial and proprietary distribution is concerning because\n(i) its‘black-box’nature limits transparency and may reduce trust in its\noutputs\n43, (ii) commercial bias may be in opposition to the idealized\nconcept of unbiased scientiﬁc or clinical deliberation, and (iii) algo-\nrithmic bias secondary to the model’s potentially skewed foundational\ndata may perpetuate unbalanced outcomes, for example, by not\nrepresenting those patients adequately that had been under-\nrepresented in the foundational data\n44. In the absence of benchmark\npublications for comparison, users must be more vigilant in\nascertaining accuracy and reliability, for example, by seeking external\nvalidation whenever possible.\nRegarding transparency and trust, we conducted a SHapley\nAdditive exPlanations (SHAP) analysis45 to better understand how\nChatGPT ADA works on and with the respective datasets. The tool\nsuccessfully identiﬁed and plausibly quantiﬁed the importance of\nnumerous variables across the trials. For instance, its predictions\ncentered on sex, age, and laboratory values (Metastatic Disease\n[Endocrinologic Oncology] dataset), speci ﬁc cytologic features\nsuch as the presence of atypical glandular cell and nuclear width\nfeatures (Esophageal Cancer [Gastrointestinal Oncology] dataset),\nspeciﬁc gene variants such as c.235delC and p.V37I that are asso-\nciated with hearing loss\n46,47 (Hereditary Hearing Loss [Otolaryngol-\nogy] dataset), and the previous history of (diagnosed)\ncardiomyopathy (Cardiac Amyloidosis [Cardiology] Dataset). The\nin-built ability to autonomously extract key features contributing to\nthe model’s predictions increases transparency, improves under-\nstanding, and furthers trust in ChatGPT ADA\n48.\nOur study has limitations: First, clinical ML projects require a\nreliable and sound database following consistent data pre-processing.\nWhile we assessed ChatGPT ADA’s performance in the presence of\nwell-curated clinical-trial datasets, real-world clinical data are often-\ntimes less curated and characterized by data quality issues such as\nmissing and irregular values\n49,50. Successfully applying ML methods to\nmore complex real-world clinical data regularly necessitates more\nadvanced and nuanced pre-processing and statistical methods. Here,\nChatGPT ADA’s effectiveness remains to be assessed. Second, given\ntheir publication in 2021, we cannot exclude the possibility of two\noriginal studies\n24,25 being part of the training that was concluded in\n2021. Given the large sizes of the included datasets consisting of\nhundreds to thousands of patients, previous publications on the same\ndataset (or a speciﬁc subset), e.g., ref.51, may have been included as\npart of the model’s training data. Third, even though ChatGPT ADA and\nthe original studies implemented the same model, we found different\nperformance metrics, e.g., for the Cardiac Amyloidosis dataset where\nrandom forest classiﬁers were implemented. Possible sources of\nvariability are the speciﬁc approaches used for data pre-processing,\ndataset splitting, model conﬁgurations, and hyperparameter selection.\nDespite our best efforts to standardize each model’s implementation\nand execution, inter-model comparability is inherently limited. Fourth,\nbecause the LLM’s response is closely related to how it is prompted\n52,i t\nis unclear whether the performance metrics are subject to change if\nthe model is prompted differently. Consequently, our work represents\na mere starting point for exploring the potential of LLMs in clinical\nresearch and practice. Future research must validate ourﬁndings\nacross different medical domains.\nIn conclusion, advanced LLMs like ChatGPT ADA are a potentially\ntransformative step forward in data-driven medicine, making intricate\nML methods more accessible. By way of example, our study demon-\nstrates that such tools may streamline advanced data analyses for\nresearchers, both experienced and inexperienced in ML, and hold the\npotential to reduce the burden of data pre-processing and model\noptimization substantially. Given the tools’ novelty, limitations, and\nchallenges, they should be applied as enhancements to specialized\ntraining, resources, and guidance, not substitutes. Nonetheless, in this\ndawning era of data-driven medicine, these tools may bridge the\nchasm between complex ML methods and their practical application in\nmedical research and practice.\nMethods\nEthics statement\nThe methods were performed in accordance with relevant guidelines\nand regulations and approved by the ethical committee of the Medical\nFaculty of RWTH Aachen University for this retrospective study\n(Reference No. EK 028/19).\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 8\nPatient cohorts\nThe patient datasets were retrieved from public repositories as indi-\ncated in the original studies on metastatic disease prediction17, eso-\nphageal cancer screening20, hereditary hearing loss24,a n dc a r d i a c\namyloidosis25.\nIn the included Endocrinologic Oncology study17, cross-sectional\ndata from Germany, Poland, the US, and the Netherlands was used to\nassess the ability of the dopamine metabolite methoxytyramine to\nidentify metastatic disease in patients with pheochromocytoma or\nparaganglioma. To this end, ten features were available.\nThe included Esophageal Cancer study\n20 from China was centered\non endoscopic screening and included multiple data sources from\nquestionnaires to endoscopy data, i.e., cytologic and\nepidemiologic data.\nThe included Hereditary Hearing Loss study\n24 contained genetic\nsequencing data to diagnose this condition in a Chinese cohort. Indi-\nviduals were categorized based on hearing loss severity and variations\nin three genes (GJB2, SLC26A4, MT-RNR1).\nThe included Cardiac Amyloidosis study\n25 utilized electronic\nhealth records to identify patients with cardiac amyloidosis from a\ndataset spanning 2008-2019, sourced from IQVIA, Inc., focusing on\nheart failure and amyloidosis. While the original study used external\ndatasets for validation, these were inaccessible. Therefore, our analysis\nadhered to the original study’s internal validation strategy: 80% as the\ntraining set and 20% for testing, resulting in 1712 individuals for\ntraining and 430 for testing. For further information on the individual\ndatasets, the reader is referred to Table1 or the original studies.\nExperimental design\nWe extracted the original training and test datasets from each\nclinical trial. All datasets were available in tabular format, albeit in\nvarious ﬁle formats such as comma-separated values or Excel\n(Microsoft Corporation). No modi ﬁcations to the data format,\nspeciﬁc data pre-processing or engineering, or selecting a particular\nML method were necessary to prompt ChatGPT ADA. GPT-4\n13,t h e\ncurrent state-of-the-art version of ChatGPT, was accessed online\n(https://chat.openai.com/) following the activation of the Advanced\nData Analysis feature. Initially, we operated the August 3 (2023)\nversion, while, during the project, we transitioned to the September\n25 version. A new chat session was started for each trial to exclude\nmemory retention bias.\nIn theﬁrst phase, ChatGPT ADA was sequentially prompted by (i)\nproviding a brief description of the study’s background, objectives,\nand dataset availability, (ii) asking for developing, reﬁning, and\nexecuting the optimal ML model based on the individual study’s fra-\nmework and design, and (iii) producing patient-speciﬁc predictions\n(classiﬁcation probabilities) without revealing the ground truth. The\nsame training and test datasets as in the original studies were used. We\ndeliberately refrained from offering speciﬁc ML-related guidance when\nChatGPT sought advice on improving prediction accuracy. Instead,\nChatGPT ADA was tasked with (i) autonomously choosing the most\nsuitable and precise ML model for the given dataset and (ii) generating\npredictions for the test data. Figure2 provides an exemplary interac-\ntion with the model.\nUsing the provided ground-truth test set labels, we calculated the\nperformance metrics for ChatGPT ADA’s results using Python (v3.9)\nusing open-source libraries such as NumPy, SciPy, scikit-learn, and\npandas.\nThe performance metrics were compared against those published\nin the original studies (“benchmark publication”). In some clinical\ntrials, the clinical care specialists’performance was also reported, and\nthese metrics were included for comparison. Notably, inputting and\nanalyzing each dataset through ChatGPT ADA took less thanﬁve\nminutes. Detailed transcripts of the interactions with ChatGPT ADA for\nevery dataset are presented in Supplementary Notes 1– 4.\nData pre-processing and ML model development\nIn the second phase, a seasoned data scientist re-implemented and\noptimized the best-performing ML model of the original studies\nusing Python (v3.9) using open-source libraries such as NumPy,\nSciPy, scikit-learn, and pandas and the same training datasets as\noutlined above (“benchmark validatory re-implementation”). This\nre-implementation and optimization was necessary because indivi-\ndual patient predictions were unavailable in the original studies,\nprecluding head-to-head model comparisons and detailed statis-\ntical analyses. More speci ﬁcally, the data scientist optimized\nthe data pre-processing and the ML model in close adherence to the\noriginal studies, yet complemented by his expertise and experience\nwhile aiming for peak accuracy.\nThe following provides trial-speciﬁc details on the data pre-\nprocessing and the conceptualization of the speciﬁcM Lm o d e l s .\nMetastatic disease [endocrinologic oncology].R e - i m p l e m e n t e d\n(validatory) ML model: The training set contained 30 missing values,\nwhile the test set contained 15 missing values. Median values from the\ntraining set were used to impute the missing values in both datasets.\nTen distinct feature vectors were constructed from the dataset vari-\nables. The feature vectors were partially categorical and partially\nnumerical. The categorical features were: (1) previous history of\npheochromocytoma or paraganglioma (yes/no), (2) adrenal/extra-\nadrenal location of primary tumor (adrenal/extra-adrenal), (3) pre-\nsence of Succinate Dehydrogenase Complex Iron-Sulfur Subunit B\n(SDHB) (yes/no/not tested), (4) tumor category of primary tumor\n(solitary, bilateral, multifocal), and 5) sex (female/male). The numerical\nfeatures were: (1) age at diagnosis ofﬁrst tumor [years], (2) spherical\nvolume of primary tumor [cm\n3], (3) plasma concentration of meta-\nnephrine (MN) [pg/ml], (4) plasma concentration of normetanephrine\n(NMN) [pg/ml], and (5) plasma concentration of methoxytyramine\n(MTY) [pg/ml]. Categorical data were translated into numerical integer\nvalues, e.g., female (0) and male (1) for sex. An Adaptive Boosting\n(AdaBoost)\n18 ensemble tree classiﬁer was employed and optimized\nusing a 10-fold cross-validation grid search. This optimization led to\nselecting parameters like a maximum depth of 2 for individual decision\ntrees, a count of 200 trees, and a learning rate of 0.01. Stagewise\nadditive modeling was chosen, utilizing a multiclass exponential loss\nfunction.\nChatGPT ADA-crafted ML model: A check for missing data mir-\nrored the ﬁndings above, leading the model to resort to a median\nimputation strategy. Numerical data were standardized using standard\nscaling, while categorical data were converted to integer values. The\nselected classiﬁcation technique was a Gradient Boosting Machine\n(GBM)\n19 with parameters set as follows: maximum tree depth: 3,\nnumber of trees: 100, minimum samples per leaf: 1, minimum samples\nfor split: 2, and learning rate: 0.1. The logarithmic loss function was the\nchosen evaluation metric, with the quality of splits being evaluated\nusing the Friedman mean squared error\n53. No validation dataset was\nincorporated, and the model was not subjected to any speciﬁcr e g -\nularization techniques.\nEsophageal cancer [gastrointestinal oncology]. Re-implemented\n(validatory) ML model: The training dataset included 147 feature vec-\ntors, whereas the test dataset included 169. A comprehensive list of the\nfeature vectors can be found in the literature:\n20. Excess feature vectors\nin the test set were excluded to maintain consistency, aligning it with\nthe training dataset. Consequently, neither the training nor the test\ndatasets contained missing values. Categorical data were mapped to\nnumerical integer values. Imbalanced dataset distributions were\naddressed by conferring inverse frequency weights upon the data. In\nline with the original study, the DS selected the Light Gradient\nBoosting Machine (LightGBM)\n21 with the gradient boosting decision\ntree algorithm. The conﬁguration for the classiﬁer was as follows: an\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 9\nunspeciﬁed maximum tree depth, 300 trees, a cap of 31 leaves per tree,\nand a 0.1 learning rate. The logarithmic loss function served as the\nevaluation metric. The model integrated both L\n1 and L2 regularization\ntechniques.\nChatGPT ADA-crafted ML model: The pre-processing mirrored the\napproach above, identifying a class imbalance. The selected classiﬁer\nwas the GBM with parameters including a maximum tree depth of 3,\n100 trees, minimum samples per leaf of 1, minimum samples for a split\nof 2, and a learning rate of 0.1. The model’s performance was assessed\nusing the logarithmic loss function, with the quality of tree splits\nevaluated using the Friedman mean squared error. No validation\ndataset was incorporated, and the model was not subjected to any\nspeciﬁc regularization techniques.\nHereditary hearing loss [otolaryngology]. Re-implemented (valida-\ntory) ML model: The training and test sets included 144 feature vec-\ntors, i.e., sequence variants at 144 sites in three genes\n24.T h ev a l u e so f\nthe training set were numerical, i.e., 0 (individual has no copies of the\naltered allele [98.2% of the values]), 1 (individual has one copy of the\naltered allele [1.6%]), and 2 (individual has two copies of the altered\nallele [0.2%]), while only one value was missing. The values of the test\nset were numerical, too, with a similar distribution: 0 (98.3%), 1 (1.5%),\nand 2 (0.2%), while no values were missing. Missing data points were\naddressed by imputing the median of the training data. All feature\nvectors were then subject to MinMax scaling. A Support Vector\nMachine\n23 was the best-performing classiﬁer per the original study,\nconﬁgured with the Radial Basis Function kernel, gamma set to 1, and\nenabled shrinking. Model optimization leveraged a 5-fold stratiﬁed\ncross-validation using grid search. The regularization cost parameter\nwas deﬁned at 100.\nChatGPT ADA-crafted ML model: The pre-processing was closely\naligned with the methodology above, with one notable exception:\nMissing data was addressed by zero-imputation. The classiﬁer chosen\nwas the Random Forest (RF)\n22, with the following framework para-\nmeters: no explicitly deﬁned maximum depth for individual trees, tree\ncount of 100, minimum samples per leaf of 1, and minimum samples\nper split of 2. At each split, the features considered were the square\nroot of the total features available. 5-fold cross-validation was\nemployed without the use of a grid search. Regularization was\nachieved by averaging predictions across multiple trees. Boot-\nstrapping was chosen to create diverse datasets for training each\ndecision tree in the forest.\nCardiac amyloidosis [cardiology]. Re-implemented (validatory) ML\nmodel: The dataset comprised 1874 numerical (0 or 1, indicating the\npresence or absence) feature vectors\n25. There was no value missing in\nthe dataset. The feature vectors underwent standard scaling for nor-\nmalization. The classiﬁer chosen was the RF, with the following para-\nmeters: maximum depth for individual trees of 20, total tree number of\n200, minimum samples per leaf of 2, and minimum samples per split of\n5. For each tree split, the square root of the total features determined\nthe number of features considered. A 5-fold cross-validation was\ncombined with a grid search for optimization. Regularization was\neffectuated by averaging the predictions over multiple trees. The\nmodel did not utilize bootstrapping.\nChatGPT ADA-crafted ML model: As there was no missing value in\nthe dataset and the values were binary, the data underwent no scaling\nor standardization. The selected classiﬁer was the RF. Parameters for\nthe model were as follows: an unspeciﬁed maximum depth for indivi-\ndual trees, a tree count of 1000, minimum samples per leaf of 1, and\nminimum samples per split of 2. For each tree split, the features con-\nsidered were the square root of the total feature count. The model was\nvalidated using 5-fold cross-validation without grid search. Regular-\nization was achieved by averaging predictions across several trees, and\nthe model utilized bootstrapping\n22,54.\nBecause ChatGPT ADA provides all intermediary Python code\nduring data pre-processing and ML model development and execu-\ntion, we meticulously analyzed the code for accuracy, consistency, and\nvalidity.\nExplainability analysis\nWe used SHapley Additive exPlanations (SHAP)26 to analyze feature\ncontributions to the model’s predictions. ChatGPT ADA was tasked\nwith autonomously performing a SHAP analysis to be narrowed down\nto the top 10 features. To ensure accuracy, the seasoned data scientist\n(S.T.A. withﬁve years of experience) reviewed the Python code pro-\nvided by ChatGPT ADA and re-implemented the procedure in Python\nusing SHAP library\n26 with TreeExplainer55 to conﬁrm the model’s\noutputs.\nReproducibility analysis\nWe evaluated the consistency of the tool’s responses using separate\nchat sessions (to avoid memory retention bias), yet the same datasets,\ninstructions, and prompts on three consecutive days. The model\nconsistently reported the same responses and qualitative and quanti-\ntative ﬁndings.\nStatistical analysis and performance evaluation\nThe quantitative performance evaluation was performed using Python\n(v3.9) and its open-source libraries, such as NumPy and SciPy. Unless\nnoted otherwise, performance metrics are presented as mean, stan-\ndard deviation, and 95% conﬁdence interval (CI) values.\nUsing the published ground-truth labels from the original studies\nas reference (“benchmark publication”), we calculated a range of\nperformance metrics based on ChatGPT ADA’s predictions of the test\nset labels: AUROC, accuracy, F1-score, sensitivity, and speciﬁcity. These\nperformance metrics are presented alongside those reported in the\noriginal studies, if available (Table2).\nOnce the per-patient predictions were available following the re-\nimplementation and optimization of the select ML models (“bench-\nmark validatory re-implementation”), we calculated the performance\nmetrics outlined above using the ground-truth labels for the re-\nimplemented (validatory) ML models and their ChatGPT ADA-based\ncounterparts. We adopted bootstrapping\n54 with replacements and\n1000 redraws on the test sets to ascertain the statistical spread (in\nterms of means, standard deviations, and 95% conﬁdence intervals),\nand to determine if the metrics were signiﬁcantly different. We\nadjusted for multiple comparisons based on the false discovery rate,\nsetting the family-wise alpha threshold at 0.05. Notably, the com-\nparative evaluation of the performance metrics was conducted in a\npaired manner. Bootstrapping was applied to both models. The\nthreshold for calculating the F1-score, sensitivity, and speciﬁcity was\nchosen based on Youden’sc r i t e r i o n\n56.\nReporting summary\nFurther information on research design is available in the Nature\nPortfolio Reporting Summary linked to this article.\nData availability\nThe datasets utilized in this study were extracted from public reposi-\ntories. The raw data for predicting metastatic disease in pheochro-\nmocytoma or paraganglioma\n17 is available onZenodo: https://doi.org/\n10.5281/zenodo.7749613. Esophageal cancer screening-trial data20 is\navailable on GitHub: https://github.com/Gaooooye/Esophageal-\ncAncer-Screening-Trial. The hereditary hearing loss trial data24 is\navailable on Mendeley: https://data.mendeley.com/datasets/\n6mh8mpnbgv/1. The data on cardiac amyloidosis (“derivation data-\nset”) is available per the original study25 at https://www.nature.com/\narticles/s41467-021-22876-9. Source data of Figures are provided in\nthis paper. Source data are provided in this paper.\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 10\nCode availability\nChatGPT Advanced Data Analysis (previously known as“Code Inter-\npreter”) was utilized for analyses and may be accessed viahttps://chat.\nopenai.com for ChatGPT Plus users. Source codes for training, evalu-\nating, and optimizing the ML models, as well as for data pre-proces-\nsing, statistical analysis, and visualizations, are publicly available at\nhttps://github.com/tayebiarasteh/LLMmed. The code was developed\nin Python v3.9.18 using open-source libraries including shap (v0.44.0),\nNumPy (v1.26.2), SciPy (v1.11.4), lightgbm (v4.1.0), mne (v1.6.0), pandas\n(v2.1.1), and scikit-learn (v1.3.0). All source codes are permanently\narchived onZenodo and are accessible via ref.57.\nMaterials availability\nThe hardware used in our experiments included an Intel CPU with\neight cores and 16 GB RAM. No GPU was utilized.\nReferences\n1. Rajpurkar, P., Chen, E., Banerjee, O. & Topol, E. J. AI in health and\nmedicine.Nat. Med.28,3 1– 38 (2022).\n2 . H a u g ,C .J .&D r a z e n ,J .M .A r t iﬁcial intelligence and machine\nlearning in clinical medicine, 2023.N. Engl. J. Med.388,\n1201– 1208 (2023).\n3 . A u n g ,Y .Y .M . ,W o n g ,D .C .S .&T i n g ,D .S .W .T h ep r o m i s eo f\nartiﬁcial intelligence: a review of the opportunities and challenges\nof artiﬁcial intelligence in healthcare.B r .M e d .B u l l .139,4 – 15 (2021).\n4. Wang, F., Casalino, L. P. & Khullar, D. Deep learning in medicine-\npromise.Prog. Chall. JAMA Intern. Med.179,2 9 3– 294 (2019).\n5. Lee, P., Bubeck, S. & Petro, J. Beneﬁts, limits, and risks of GPT-4 as\nan AI Chatbot for medicine.N. Engl. J. Med.388,1 2 3 3– 1239 (2023).\n6. Callender, T. & Van Der Schaar, M. Automated machine learning as\na partner in predictive modelling.Lancet Digit. Health5,\ne254– e256 (2023).\n7. Waring, J., Lindvall, C. & Umeton, R. Automated machine learning:\nreview of the state-of-the-art and opportunities for healthcare.Artif.\nIntell. Med.104,1 0 1 8 2 2( 2 0 2 0 ) .\n8. Ito, Y. et al. A method for utilizing automated machine learning for\nhistopathological classiﬁcation of testis based on Johnsen scores.\nSci. Rep.11, 9962 (2021).\n9. Opara, E., Wimmer, H. & Rebman, C. M. Auto-ML cyber security data\nanalysis Using Google, Azure and IBM Cloud Platforms. in2022\nInternational Conference on Electrical, Computer and Energy\nTechnologies (ICECET)1– 10 (IEEE, 2022).https://doi.org/10.1109/\nICECET55527.2022.9872782.\n10. Zhang, S., Gong, C., Wu, L., Liu, X. & Zhou, M. AutoML-GPT: auto-\nmatic machine learning with GPT. Preprint athttp://arxiv.org/abs/\n2305.02499(2023).\n11. Kung, T. H. et al. Performance of ChatGPT on USMLE: potential for\nAI-assisted medical education using large language models.PLoS\nDigit. Health2, e0000198 (2023).\n12. Thirunavukarasu, A. J. et al. Large language models in medicine.\nNat. Med.29,1 9 3 0– 1940 (2023).\n13. OpenAI. GPT-4 Technical Report.P r e p r i n ta thttp://arxiv.org/abs/\n2303.08774(2023).\n14. Vert, J.-P. How will generative AI disrupt data science in drug dis-\ncovery? Nat. Biotechnol.41,7 5 0– 751 (2023).\n15. Nori, H., King, N., McKinney, S. M., Carignan, D. & Horvitz, E. Cap-\nabilities of GPT-4 on medical challenge problems. Preprint athttp://\narxiv.org/abs/2303.13375(2023).\n1 6 . W a n g ,L . ,G e ,X . ,L i u ,L .&H u ,G .C o d ei n t e r p r e t e rf o rb i o i n f o r m a t i c s :\na r ew et h e r ey e t ?Ann. Biomed. Eng.https://doi.org/10.1007/\ns10439-023-03324-9(2023).\n17. Pamporaki, C. et al. Prediction of metastatic pheochromocytoma\nand paraganglioma: a machine learning modelling study using data\nfrom a cross-sectional cohort.Lancet Digit. Health\nS2589750023000948https://doi.org/10.1016/S2589-7500(23)\n00094-8 (2023).\n1 8 . F r e u n d ,Y .&S c h a p i r e ,R .E .Ad e c ision-theoretic generalization of\non-line learning and an application to boosting.J. Comput.Syst. Sci.\n55, 119– 139 (1997).\n19. Friedman, J. H. Greedy function approximation: a gradient boosting\nmachine.Ann. Statist. 29, 1189– 1232 (2001).\n20. Gao, Y. et al. Machine learning-based automated sponge cytology\nfor screening of oesophageal squamous cell carcinoma and ade-\nnocarcinoma of the oesophagogastric junction: a nationwide,\nmulticohort, prospective study.Lancet Gastroenterol. Hepatol.8,\n432– 445 (2023).\n21. Ke, G. et al. LightGBM: A highly efﬁcient gradient boosting decision\ntree. inAdvances in Neural Information Processing Systems 30.\n3149– 3157 (NIPS, 2017).\n22. Breiman, L. Random Forests.Mach. Learn.45,5 – 32 (2001).\n23. Boser, B. E., Guyon, I. M. & Vapnik, V. N. A training algorithm for\noptimal margin classiﬁers. inProceedings of the Fifth Annual\nWorkshop on Computational Learning theory144– 152. https://doi.\norg/10.1145/130385.130401(ACM, 1992).\n24. Luo, X. et al. Machine learning-based genetic diagnosis models for\nhereditary hearing loss by the GJB2, SLC26A4 and MT-RNR1 var-\niants. eBioMedicine69, 103322 (2021).\n25. Huda, A. et al. A machine learning model for identifying patients at\nrisk for wild-type transthyretin amyloid cardiomyopathy.Nat.\nCommun. 12, 2725 (2021).\n26. Lundberg, S. & Lee, S.-I. A Uniﬁed Approach to Interpreting Model\nPredictions. inProceedings of the 31st International Conference on\nNeural Information Processing Systems.4768– 4777.https://doi.org/\n10.5555/3295222.3295230(NIPS, 2017).\n27. Singhal, K. et al. Large language models encode clinical knowl-\nedge. Nature 620,1 7 2– 180 (2023).\n28. Arora, A. & Arora, A. The promise of large language models in health\ncare. Lancet 401, 641 (2023).\n2 9 . K a r a t a s ,M . ,E r i s k i n ,L . ,D e v e c i ,M . ,P a m u c a r ,D .&G a r g ,H .B i gd a t a\nfor healthcare industry 4.0: applications, challenges and future\nperspectives.Expert Syst. Appl.200, 116912 (2022).\n30. Porter, J., Boyd, C., Skandari, M.R. & Laiteerapong, N. Revisiting the\ntime needed to provide adult primary care.J. Gen. Intern. Med.38,\n147– 155 (2023).\n3 1 . D a r s t ,J .R . ,N e w b u r g e r ,J .W . ,R e s c h ,S . ,R a t h o d ,R .H .&L o c k ,J .E .\nDeciding without data: deciding without data.Congenit. Heart Dis.\n5, 339– 342 (2010).\n32. Gilson, A. et al. How does ChatGPT perform on the United States\nMedical Licensing Examination? The implications of large language\nmodels for medical education and knowledge assessment.JMIR\nMed. Educ.9, e45312 (2023).\n33. Azcorra, M. et al. Unique functional responses differentially map\nonto genetic subtypes of dopamine neurons.Nat. Neurosci.26,\n1762– 1774 (2023).\n34. Alkaissi, H. & McFarlane, S. I. Artiﬁcial hallucinations in\nChatGPT: implications in scientiﬁcw r i t i n g .Cureus 15,e 3 5 1 7 9\n(2023).\n35. Lightman, H. et al. Let’s verify step by step. Preprint athttp://arxiv.\norg/abs/2305.20050(2023).\n36. Chua, M. et al. Tackling prediction uncertainty in machine learning\nfor healthcare.Nat. Biomed. Eng.7,7 1 1– 718 (2022).\n37. Parray, A. A. et al. ChatGPT and global public health: applications,\nchallenges, ethical considerations and mitigation strategies.Glob.\nTransit.5,5 0– 54 (2023).\n38. Wang, C. et al. Ethical considerations of using ChatGPT in health\ncare. J. Med Internet Res25, e48009 (2023).\n39. Will ChatGPT transform healthcare?Nat. Med. 29,5 0 5– 506 https://\ndoi.org/10.1038/s41591-023-02289-5(2023).\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 11\n40. Dave, T., Athaluri, S. A. & Singh, S. ChatGPT in medicine: an over-\nview of its applications, advantages, limitations, future prospects,\nand ethical considerations.Front. Artif. Intell.6, 1169595 (2023).\n41. Li, H. et al. Ethics of large language models in medicine and medical\nresearch.Lancet Digit. Health5,e 3 3 3– e335 (2023).\n42. Moor, M. et al. Foundation models for generalist medical artiﬁcial\nintelligence.Nature 616,2 5 9– 265 (2023).\n43. Chakraborty, C., Bhattacharya, M. & Lee, S.-S. Need an AI-enabled,\nnext-generation, advanced ChatGPT or large language models\n(LLMs) for error-free and accurate medical information.Ann.\nBiomed. Eng. https://doi.org/10.1007/s10439-023-03297-9(2023).\n4 4 . S t r a w ,I .&C a l l i s o n - B u r c h ,C .A r t iﬁcial intelligence in mental health\nand the biases of language based models.PLoS ONE15,\ne0240376 (2020).\n45. Barredo Arrieta, A. et al. Explainable artiﬁcial intelligence (XAI):\nconcepts, taxonomies, opportunities and challenges toward\nresponsible AI.Inf. Fusion58,8 2– 115 (2020).\n46. Xia, H. et al. GJB2 c.235delC variant associated with autosomal\nrecessive nonsyndromic hearing loss and auditory neuropathy\nspectrum disorder.Genet. Mol. Biol.42,4 8– 51 (2019).\n47. Shen, N. et al. Association between the p.V37I variant of GJB2 and\nhearing loss: a pedigree and meta-analysis.Oncotarget8,\n46681– 46690 (2017).\n48. Zini, J. E. & Awad, M. On the explainability of natural language\nprocessing deep models.ACM Comput. Surv.55,1 – 31 (2023).\n49. Varoquaux, G. & Cheplygina, V. Machine learning for medical ima-\nging: methodological failures and recommendations for the future.\nnpj Digit. Med.5, 48 (2022).\n50. Pfob, A., Lu, S.-C. & Sidey-Gibbons, C. Machine learning in medi-\ncine: a practical introduction to techniques for data pre-processing,\nhyperparameter tuning, and model comparison.BMC Med. Res.\nMethodol.22, 282 (2022).\n51. Buitenwerf, E. et al. Efﬁcacy ofα-blockers on hemodynamic control\nduring pheochromocytoma resection: a randomized controlled\ntrial. J. Clin. Endocrinol. Metab.105,2 3 8 1– 2391 (2020).\n52. White, J. et al. A prompt pattern catalog to enhance prompt engi-\nneering with ChatGPT. Preprint athttp://arxiv.org/abs/2302.\n11382 (2023).\n53. Friedman, J. H. Multivariate adaptive regression splines.Ann. Sta-\ntist. 19,1 – 67 (1991).\n54. Konietschke, F. & Pauly, M. Bootstrapping and permuting paired\nt-test type statistics.Stat. Comput.24,2 8 3– 296 (2014).\n55. Mitchell, R., Frank, E. & Holmes, G. GPUTreeShap: massively parallel\nexact calculation of SHAP scores for tree ensembles. Preprint at\nhttp://arxiv.org/abs/2010.13972(2022).\n56. Unal, I. Deﬁning an optimal cut-point value in ROC analysis: an\nalternative approach.Comput. Math. Methods Med.2017,\n3762651 (2017).\n57. Tayebi Arasteh, S. et al. Large language models streamline auto-\nmated machine learning for clinical studies, LLMmed,Zenodo\nhttps://doi.org/10.5281/zenodo.10376161(2023).\nAcknowledgements\nS.T.A. is funded and partially supported by the Radiological Cooperative\nNetwork (RACOON) under the German Federal Ministry of Education and\nResearch (BMBF) grant number 01KX2021. S.N. and D.T. were supported\nby grants from the Deutsche Forschungsgemeinschaft (DFG) (NE 2136/\n3-1, TR 1700/7-1). D.T. is supported by the German Federal Ministry of\nEducation (TRANSFORM LIVER, 031L0312A; SWAG, 01KD2215B) and the\nEuropean Union’s Horizon Europe and Innovation program (ODELIA\n[Open Consortium for Decentralized Medical Artiﬁcial Intelligence],\n101057091).\nAuthor contributions\nS.T.A., D.T., and S.N. designed the study and performed the formal\nanalysis. The manuscript was written by S.T.A. and corrected by D.T. and\nS.N. The experiments were performed by S.T.A. The statistical analysis\nwas performed by S.T.A. and M.L. The illustrations were designed by\nS.T.A., M.L., D.T., and S.N. The literature research was conducted by\nS.T.A., D.T., and S.N. J.N.K., C.K., D.T., and S.N. provided clinical exper-\ntise. S.T.A., T.H., M.L., J.N.K., and D.T. provided technical expertise. All\nauthors read the manuscript and agreed to the submission of this paper.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL.\nCompeting interests\nJ.N.K. declares consulting services for Owkin, France; DoMore Diag-\nnostics, Norway, and Panakeia, UK. Furthermore, J.N.K. holds shares in\nStratifAI GmbH and has received honoraria for lectures by Bayer, Eisai,\nMSD, BMS, Roche, Pﬁzer, and Fresenius. D.T. holds shares in StraifAI\nGmbH, Germany, and received honoraria for lectures by Bayer. The\nother authors declare no competing interests.\nAdditional information\nSupplementary informationThe online version contains\nsupplementary material available at\nhttps://doi.org/10.1038/s41467-024-45879-8.\nCorrespondenceand requests for materials should be addressed to\nSoroosh Tayebi Arasteh or Tianyu Han.\nPeer review informationNature Communicationsthanks Fares Antaki,\nPearse Keane, and the other, anonymous, reviewer(s) for their con-\ntribution to the peer review of this work. A peer reviewﬁle is available.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nPublisher’s noteSpringer Nature remains neutral with regard to jur-\nisdictional claims in published maps and institutional afﬁliations.\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indicate if\nchanges were made. The images or other third party material in this\narticle are included in the article’s Creative Commons licence, unless\nindicated otherwise in a credit line to the material. If material is not\nincluded in the article’s Creative Commons licence and your intended\nuse is not permitted by statutory regulation or exceeds the permitted\nuse, you will need to obtain permission directly from the copyright\nholder. To view a copy of this licence, visithttp://creativecommons.org/\nlicenses/by/4.0/.\n© The Author(s) 2024\nArticle https://doi.org/10.1038/s41467-024-45879-8\nNature Communications|         (2024) 15:1603 12",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.738864541053772
    },
    {
      "name": "Bridge (graph theory)",
      "score": 0.6153226494789124
    },
    {
      "name": "Machine learning",
      "score": 0.5995838046073914
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4881513714790344
    },
    {
      "name": "Clinical trial",
      "score": 0.4431207776069641
    },
    {
      "name": "Clinical Practice",
      "score": 0.4413381516933441
    },
    {
      "name": "Data science",
      "score": 0.3654814660549164
    },
    {
      "name": "Medicine",
      "score": 0.199167400598526
    },
    {
      "name": "Pathology",
      "score": 0.10788768529891968
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Family medicine",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I887968799",
      "name": "RWTH Aachen University",
      "country": "DE"
    },
    {
      "id": "https://openalex.org/I4210162051",
      "name": "University Hospital Carl Gustav Carus",
      "country": "DE"
    }
  ],
  "cited_by": 75
}