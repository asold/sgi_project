{
  "title": "Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?",
  "url": "https://openalex.org/W4387800303",
  "year": 2023,
  "authors": [
    {
      "id": null,
      "name": "Ilić, David",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Gignac, Gilles E.",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2130158090",
    "https://openalex.org/W2968893733",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W2019133471",
    "https://openalex.org/W2103587878",
    "https://openalex.org/W2133097426",
    "https://openalex.org/W2797635503",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2088477804",
    "https://openalex.org/W2761866650",
    "https://openalex.org/W2001562585",
    "https://openalex.org/W3162344419",
    "https://openalex.org/W4394653315",
    "https://openalex.org/W1815596065",
    "https://openalex.org/W1599016936",
    "https://openalex.org/W4381587373",
    "https://openalex.org/W4253201919",
    "https://openalex.org/W4235148340",
    "https://openalex.org/W654454365",
    "https://openalex.org/W1993760488",
    "https://openalex.org/W2963846996",
    "https://openalex.org/W2799449427",
    "https://openalex.org/W2794325560",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W2062974915",
    "https://openalex.org/W3001279689",
    "https://openalex.org/W4307123345",
    "https://openalex.org/W2946609015",
    "https://openalex.org/W2604673438",
    "https://openalex.org/W2063207796",
    "https://openalex.org/W131533222",
    "https://openalex.org/W2100811537",
    "https://openalex.org/W3121904249",
    "https://openalex.org/W3033661511",
    "https://openalex.org/W2490356861",
    "https://openalex.org/W1844666675",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W4288366910",
    "https://openalex.org/W2952828155",
    "https://openalex.org/W4220656815",
    "https://openalex.org/W2165862071",
    "https://openalex.org/W2963176674",
    "https://openalex.org/W2094102654",
    "https://openalex.org/W2007356270",
    "https://openalex.org/W2086985992",
    "https://openalex.org/W2888081983"
  ],
  "abstract": "Large language models (LLMs) are advanced artificial intelligence (AI) systems that can perform a variety of tasks commonly found in human intelligence tests, such as defining words, performing calculations, and engaging in verbal reasoning. There are also substantial individual differences in LLM capacities. Given the consistent observation of a positive manifold and general intelligence factor in human samples, along with group-level factors (e.g., crystallized intelligence), we hypothesized that LLM test scores may also exhibit positive intercorrelations, which could potentially give rise to an artificial general ability (AGA) factor and one or more group-level factors. Based on a sample of 591 LLMs and scores from 12 tests aligned with fluid reasoning (Gf), domain-specific knowledge (Gkn), reading/writing (Grw), and quantitative knowledge (Gq), we found strong empirical evidence for a positive manifold and a general factor of ability. Additionally, we identified a combined Gkn/Grw group-level factor. Finally, the number of LLM parameters correlated positively with both general factor of ability and Gkn/Grw factor scores, although the effects showed diminishing returns. We interpreted our results to suggest that LLMs, like human cognitive abilities, may share a common underlying efficiency in processing information and solving problems, though whether LLMs manifest primarily achievement/expertise rather than intelligence remains to be determined. Finally, while models with greater numbers of parameters exhibit greater general cognitive-like abilities, akin to the connection between greater neuronal density and human general intelligence, other characteristics must also be involved.",
  "full_text": "Evidence of interrelated cognitive-like capabilities in large language \nmodels: Indications of artificial general intelligence or achievement?\nDavid Ili ´c\na\n, Gilles E. Gignac\nb , *\na\nIndependent Researcher, Belgrade, Serbia\nb\nSchool of Psychological Science, University of Western Australia, Australia\nARTICLE INFO\nKeywords:\nArtificial intelligence\nArtificial general intelligence\nNumber of parameters\nABSTRACT\nLarge language models (LLMs) are advanced artificial intelligence (AI) systems that can perform a variety of tasks \ncommonly found in human intelligence tests, such as defining words, performing calculations, and engaging in \nverbal reasoning. There are also substantial individual differences in LLM capacities. Given the consistent \nobservation of a positive manifold and general intelligence factor in human samples, along with group-level \nfactors (e.g., crystallised intelligence), we hypothesized that LLM test scores may also exhibit positive inter- \ncorrelations, which could potentially give rise to an artificial general ability (AGA) factor and one or more \ngroup-level factors. Based on a sample of 591 LLMs and scores from 12 tests aligned with fluid reasoning ( Gf ), \ndomain-specific knowledge ( Gkn ), reading/writing ( Grw ), and quantitative knowledge ( Gq ), we found strong \nempirical evidence for a positive manifold and a general factor of ability. Additionally, we identified a combined \nGkn / Grw group-level factor. Finally, the number of LLM parameters correlated positively with both general \nfactor of ability and Gkn / Grw factor scores, although the effects showed diminishing returns. We interpreted our \nresults to suggest that LLMs, like human cognitive abilities, may share a common underlying efficiency in \nprocessing information and solving problems, though whether LLMs manifest primarily achievement/expertise \nrather than intelligence remains to be determined. Finally, while models with greater numbers of parameters \nexhibit greater general cognitive-like abilities, akin to the connection between greater neuronal density and \nhuman general intelligence, other characteristics must also be involved.\n1. Introduction\nGignac and Szodorai (2024, p. 4) defined artificial intelligence (AI) \nas “ an artificial system ’ s maximal capacity to complete a novel stan -\ndardized task with veridical scoring using computational algorithms ” . \nCurrently, much attention has focussed on the development and testing \nof large language models (LLMs), sophisticated AI systems that leverage \nextensive datasets and advanced neural network architectures ( Zhao \net al., 2023 ). LLMs, such as GPT, Claude, LLaMA, and Gemini, are \ncapable of performing a wide range of tasks, including defining words, \nretrieving factual information, summarization, performing calculations, \nverbal reasoning, and creative writing.\nA large number of modern LLMs have been developed since the \nintroduction of transformer technology ( Zhao et al., 2023 ). Like \nhumans, LLMs exhibit substantial individual differences in capacities, as \nevidenced by their varied performance across a diversity of tasks ( Owen, \n2024 ). Some LLMs excel in specific domains due to specialized training \ndata or enhanced architectural features, while others perform more \nrobustly across a broader spectrum of tasks ( Dong et al., 2023 ; Lin et al., \n2023 ). This variability in performance suggests that, similar to human \nintelligence, there might be one or more underlying dimensions that \nrepresent LLM performance. Understanding these individual differences \nmay prove useful for advancing our knowledge of AI capabilities and \ndesigning more effective and versatile AI systems. Additionally, scien -\ntific discoveries into the nature of AI system capabilities and behaviour \ncould provide valuable insights into human intelligence ( Gignac & \nSzodorai, 2024 ; Neubauer, 2021 ). Consequently, the primary purpose of \nthis study was to examine whether LLM performance exhibits positive \ncorrelations across a range of human-like cognitive abilities. Addition -\nally, we sought to investigate the potential emergence of one or more \nLLM ability dimensions, including a general ability factor.\n* Corresponding author at: School of Psychological Science, University of Western Australia, 35 Stirling Highway, Crawley, Western Australia 6009, Australia.\nE-mail address: gilles.gignac@uwa.edu.au (G.E. Gignac). \nContents lists available at ScienceDirect\nIntelligence\njournal homep age: www.el sevier.com/loc ate/inte ll\nhttps://doi.org/10.1016/j.intell.2024.101858\nReceived 18 June 2024; Received in revised form 9 August 2024; Accepted 21 August 2024  \nIntelligence 106 (2024) 101858 \nAvailable online 29 August 2024 \n0160-2896/© 2024 The Authors. Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ). \n1.1. General intelligence: human and artificial\nHumans who tend to have higher verbal skills also tend to have \nhigher spatial skills, better memories, and faster processing speed \n( Jensen, 1998 ). Expressed in statistical terms, the average correlation \nbetween a wide array of cognitive ability test performances tends to be \napproximately 0.45 to 0.50 ( Detterman & Daniel, 1989 ; Walker et al., \n2023 ). In general terms, the observation of consistent, positive corre -\nlations between cognitive ability test scores is known as the positive \nmanifold ( Jensen, 1998 ). When cognitive ability inter-correlations are \nsubmitted to data reduction procedures such as factor analysis, the \nlargest factor tends to be a general factor that accounts for 40 to 50% of \nthe variance in test performance ( Deary et al., 2009 ). Known as psy -\nchometric g ( Jensen & Weng, 1994 ), the phenomenon has been observed \nacross many human cultures ( Warne & Burningham, 2019 ), as well as \nseveral species, including orangutans ( Damerius et al., 2019 ), dogs \n( Arden & Adams, 2016 ), and deer ( Pastrana et al., 2022 ).\nRecently, Gignac and Szodorai (2024) proposed that a general factor \nof ability could potentially be identified in AI systems, including LLMs, if \ntheir performance across various tasks is positively inter-correlated. It \nshould be clarified that many computer scientists, as well the general \npublic, commonly refer to artificial general intelligence (AGI) as a level \nof intelligence, specifically human-level intelligence ( Amazon Web \nServices, 2024 ; Demasi et al., 2010 ; McLean et al., 2023 ; Obaid, 2023 ; \nRayhan et al., 2023 ). However, because general intelligence in humans \nis observed across all levels of ability ( Breit et al., 2022 ; Detterman & \nDaniel, 1989 ), Gignac and Szodorai (2024) proposed that AGI should be \nconsidered a reflection of the phenomenon of the positive manifold, \nrather than simply a quantitative level of cognitive ability. From this \nperspective, one may hypothesize that AGI is observed across all levels \nof AI system performance. Furthermore, by conceptualising and \nmodeling AGI in a manner consistent with general intelligence in \nhumans, it is possible to quantify levels of AGI across AI systems, as well \nas investigate predictors and outcomes of AGI.\nBefore proceeding, we note that Gignac and Szodorai (2024) con -\ntended that current LLMs may exhibit what they term as ‘artificial \nachievement ’ (AA) rather than true AI, as these models may not fulfill all \nthe criteria for genuine intelligence. Acknowledging that this debate is \nongoing, we opted to use the broader term ‘artificial general ability ’ \n(AGA) instead of the more specific term ‘artificial general intelligence ’ \n(AGI) throughout this paper. We address this issue further in our dis -\ncussion section.\n1.2. Group-level factors of intelligence\nBeyond the general factor of human intelligence, a reliable amount of \nthe variance in cognitive ability tests scores is accounted for by a variety \nof smaller, group-level of factors, also known as stratum II dimensions \n(the general factor is known as a stratum III dimension; Carroll, 2003 ). \nAccording to the most recent Cattell-Horn-Carroll (CHC) model of in -\ntelligence, there are approximately 16 stratum II dimensions of cogni -\ntive ability ( Schneider & McGrew, 2018 ). Of the 16 strata II dimensions, \nperhaps seven are relatively more dominant and commonly investi -\ngated: fluid reasoning ( Gf ), comprehension-knowledge ( Gc ), short-term \nmemory ( Gsm ), visual processing ( Gv ), quantitative knowledge ( Gq ), \ncognitive processing speed ( Gs ), and reading and writing ( Grw ). We \nbriefly review each of these seven dimensions and propose that several \ncommonly used LLM system benchmark tests may align with some of \nthese categories.\nFluid reasoning ( Gf ) is the ability to use various reasoning methods \n(e.g., inductive, deductive, analogical, etc.) to solve unfamiliar or novel \nproblems ( Kyllonen & Kell, 2017 ). Tests of Gf can be developed based on \nspatial, verbal, and numerical content. Raven ’ s progressive matrices is a \nwell-established spatial/figural test of fluid reasoning ( Raven, 2000 ). As \nLLMs are based exclusively upon textual data, they may not be expected \nto solve spatial reasoning tasks. However, some are considered capable \nof solving certain types of verbal reasoning problems ( Orrù et al., 2023 ).\nComprehension-knowledge ( Gc ) is the ability to understand and \ncommunicate culturally significant knowledge ( Schneider & McGrew, \n2018 ). A well-established measure of Gc is Vocabulary from the \nWechsler scales ( Wechsler, 2008a ), as well as Similarities which mea -\nsures the capacity to identify relationships between concepts. Though \ntypically conceived as verbal tests, spatial tests of Gc are conceivable. \nFor example, a geography test where participants are asked to identify \nnations based on their shapes may be considered a test of spatial \ncomprehension-knowledge (e.g., Hagge, 2023 ). A less investigated \nstratum II dimension that is conceptually highly similar to Gc is domain- \nspecific knowledge ( Gkn ), which represents specialized knowledge and \nskills in particular areas, such as knowledge of a specific academic \nsubject (e.g., European history) or technical expertise (e.g., computer \nprogramming). Many LLM benchmark tests are would likely be classified \nas measures of Gkn , as we detail further below.\nVisual processing intelligence ( Gv ) represents the cognitive ability to \nperceive, analyze, synthesize, manipulate, and think with visual pat -\nterns, including the capacity to understand spatial relationships. An \nexample Gv test is mental rotation ( Vandenberg & Kuse, 1978 ). As with \nspatial Gf tasks, LLMs may not be expected to solve Gv problems, as they \nare based purely on spatial content.\nQuantitative knowledge ( Gq ) represents “ declarative and procedural \nknowledge related to mathematics ” ( Schneider & McGrew, 2018 , p. \n123), which includes knowledge of symbols (e.g., ≤ , ∞ , ∕= , etc.), oper -\nations (e.g., addition, multiplication, etc.) and computational proced -\nures (e.g., long division). An example Gq test is the arithmetic subtest \nfrom the Multidimensional Aptitude Test II ( Jackson, 2003 ). Though \nmany LLMs are known to struggle with calculations ( Urrutia & Araya, \n2024 ), some can still perform reasonably well in tasks that require the \nrecognition and manipulation of mathematical symbols and operations \n( Xu et al., 2024 ).\nShort-term memory ( Gsm ) is the capacity to perceive and tempo -\nrarily hold a restricted amount of information from one ’ s present cir -\ncumstances in active conscious awareness (i.e., events that transpired \nwithin the last roughly one minute). A commonly used test of short-term \nmemory is digit span, where the participant is asked to immediately \nrecall a sequence of randomly presented numbers in the correct order \n( Bowden et al., 2013 ). To date, there are no consistently used tests of \nmemory span for LLMs, though LLM context windows could possibly \nserve as a rough proxy for short-term memory capacity ( Gignac & Szo -\ndorai, 2024 ; Kuratov et al., 2024 ).\nProcessing speed ( Gs ) represents the capacity to execute relatively \nsimple or well-practiced basic cognitive operations swiftly and \nsmoothly, particularly when a high level of focused mental resources \nand concentration is necessitated. In humans, a well-established method \nto measuring processing speed is inspection time, which is a psycho -\nphysical procedure that determines the minimum exposure duration \nrequired for a person to reliably make a simple discrimination between \ntwo visual stimuli ( Jensen, 2006 ; Nettelbeck & Lally, 1976 ). To date, \nprocessing speed has not been considered a dimension on which LLMs \nare compared, though, theoretically, it could be potentially measured (e. \ng., time taken by an LLM to parse and analyze large volumes of text \ndata).\nSimilar to the psychometric tests used to measure the intelligence of \nhumans, the capacities of LLMs are measured with benchmark tests, also \nknown as datasets ( Welty et al., 2019 ). At least conceptually, many \nbenchmark tests can be classified with one or more CHC stratum II di -\nmensions. For instance, Hellaswag ( Zellers et al., 2019 ), an LLM \nbenchmark test that involves questions related to commonsense \nreasoning, requiring the prediction of the most likely scenario continu -\nation, may be regarded as a measure of Gf . Additionally, Winogrande \n( Sakaguchi et al., 2021 ) focuses mainly on reading comprehension test \nitems and can be categorized as a measure of Grw . Finally, the \nHumanEval test is comprised of programming challenges and may be \nconsidered to be a measure of Gkn .\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n2 \nOver the years, numerous tests for LLMs have been developed, and \nmany LLMs have been evaluated using benchmark tests, including the \nthree tests noted above. Furthermore, the test results from thousands of \nLLMs are publicly available on the Hugging Face repository ( Hugging \nFace, 2024 ). This accessibility allows for the investigation of whether \nLLM test performances are positively inter-correlated, potentially \nyielding a positive manifold. Such a positive manifold could indicate the \npresence of an artificial general ability factor, as well as one or more \ngroup-level factors similar to the stratum II abilities recognized within \nthe CHC model of intelligence.\nThe empirical verification of a general ability factor (AGI or AGA) \nmay be considered important, as it would provide evidence that current \nLLMs may possess general capabilities that extend beyond narrow task \nspecialization ( Lin et al., 2023 ). Additionally, the identification of a \nreliable general ability factor would justify the calculation and inter -\npretation of global AI (or AA) performance scores psychometrically, \nwhich would facilitate overall performance comparisons between LLMs. \nFinally, by drawing parallels between the structures of human and \nartificial intelligence, novel insights into the nature of human intelli -\ngence may be eventually achieved ( Gignac & Szodorai, 2024 ; Neubauer, \n2021).\n1.3. Number of parameters and artificial general ability\nLLMs are fundamentally based on neural networks ( Goldberg, 2016 ). \nA neural network is a computational model inspired by the way bio -\nlogical neural networks in the human brain process information ( Jeon & \nKim, 2023 ). It consists of layers of interconnected nodes (or neurons), \nwhere each connection has an associated weight. These weights are \nadjusted during the training process to minimize prediction errors and \nimprove the model ’ s performance. In the context of LLMs, the number of \nparameters refers to the total count of learnable weights and biases in \nthe model, with each weight and bias representing a parameter that can \nbe tuned to optimize the model ’ s predictions ( Zhao et al., 2023 ). For \ninstance, RoBERTa-large is based on 355 million parameters, GPT-2-x1 \non 1.56 billion parameters, and Mistral 7B on 7.3 billion parameters \n( Kazi & Elmahdy, 2023 ).\nIn theory, the number of parameters that underpin LLMs may be \nexpected to positively predict the performance of LLMs. This is because a \ngreater number of parameters allows the model to capture more com -\nplex patterns and nuances in the data, leading to a higher capacity for \nlearning intricate relationships ( Hu et al., 2021 ). Moreover, the greater \ncapacity should allow the model to generalize better from training data \nand produce more accurate outputs across diverse tasks, potentially \nboosting overall performance. As a parallel, in biological organisms, \nincluding humans, there is evidence that greater neuronal density and \nconnectivity in specific brain regions are associated with higher cogni -\ntive abilities (e.g., Dicke & Roth, 2016 ; Goriounova et al., 2018 ).\nTo date, a small number of studies have examined the association \nbetween model parameter size and LLM performance, though within \nonly one model. For example, Anil et al. (2023) examined the perfor -\nmance of Palm 2 on 27 benchmark tests, while varying the number of \nmodel parameters experimentally, i.e., 3.86B, 7.05B, 9.50B and 16.1B \nparameters. The found that performance increased with larger numbers \nof parameters, though not linearly across all tests. From a differential \npsychology perspective, it would be useful to estimate the association \nbetween number of parameters and performance in a large and diverse \nsample of LLMs. Based on the above, we predicted a positive correlation \nbetween the number of LLM parameters and LLM test performance.\n1.4. Summary and purpose\nMany LLMs have been tested on tasks similar to those found in \npsychometric intelligence test batteries, and there is evidence that there \nare substantial individual differences in LLM capabilities. Furthermore, \nmany LLM benchmark tests can be theoretically classified under specific \nstratum II dimensions within the CHC model of intelligence ( Schneider \n& McGrew, 2018 ). Consequently, we investigated potential correlations \nbetween LLM system performance across diverse benchmark tests, \nexpecting a positive manifold. We also hypothesized the existence of an \nartificial general factor of ability and explored the possibility of group- \nlevel factors aligning with stratum II dimensions recognized by the \nCHC model. Finally, in the event that artificial ability factors were \nobserved, we hypothesized that there would be a positive association \nbetween number of LLM parameters and LLM test performance (e.g., \ngeneral ability factor scores).\n2. Method\n2.1. Sample\nThe data for this study were obtained on March 8th, 2024, from the \nHugging Face website, a well-known repository for LLM benchmarks. \nThe initial sample consisted of 3862 models. However, many of the \nmodels were arguably not sufficiently distinct to be considered unique \ncases from an individual differences investigation perspective. Defining \nwhat constitutes a distinct model in this context is inherently complex, \nwith no universally accepted criteria. We suggest that models may be \ndescribed on a uniqueness continuum across several categories, from \nmost unique (entirely new architectures and trained on data from \nscratch), moderately unique (large-scale pre-trained models, merged \nmodels with significant training adjustments, and specialized models \nwith unique fine-tuning), less unique (fine-tuned models and merged \nmodels with minimal adjustments), and least unique (parameter- \nadjusted models and replicas or clones). While this continuum provides \na general framework, it is important to note that the boundaries between \ncategories can be fluid, and factors such as innovative training tech -\nniques or specialized applications can influence a model ’ s perceived \nuniqueness. In our investigation, we employed three strategies to curate \na sample to help reduce the impact of less distinct models on our \nanalyses.\nFirst, we employed Density-Based Spatial Clustering of Applications \nwith Noise (DBSCAN; Ester et al., 1996 ) to remove essentially redundant \nmodels. Specifically, we used an epsilon (eps) value of 0.33 and a \nminimum samples parameter of 2. We arrived at these values through \nexperimentation by collecting groups of models that were slight varia -\ntions of one another and observing how they responded to changes in the \nDBSCAN parameters. This process reduced our sample size from 3862 to \n2680 models. Next, three months after the initial data were downloaded \nfrom the repository, we found that 264 models were no longer on the \nsite, suggesting the models were either deprecated or removed by their \ncreators for various reasons. Finally, two models in our database \npossessed essentially the same name, differing only in capitalization: \n‘Vmware/open-llama-7b-v2-open-instruct ’ versus ‘VMware/open- \nllama-7b-v2-open-instruct. ’ We used the most recently uploaded data \nfor our investigation (i.e., Vmware/open-llama-7b-v2-open-instruct), \nresulting in a final sample size of 2415 models. Well known LLMs \nincluded those associated with Mistral, LLaMA, GPT, and Claude, as well \nmodels from less well-known sources such as ConvexAI, Lorinma, and \nCalderaAI, for example. We used model ‘submitted time ’ as an approx -\nimate indicator of model age, which yielded a median of 147 days (IQR: \n99 days).\nFor the second subsample of LLMs, we subjectively evaluated the \ndegree of uniqueness among the 2415 models obtained in the first \napproach based on their names and the number of associated parame -\nters. Information such as model architecture, fine-tuning methods, \nversion numbers, merging or combination indicators, and specialized \napplications was considered, for example. Based on such an evaluation, \nwe excluded an additional 816 models from 2415, which yielded a \nsubsample size of n = 1599.\nFor the third and final approach, we quantified the similarity be -\ntween model names among the 2415 models obtained in the first \nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n3 \napproach using a Levenshtein distance metric, which measures the \nnumber of single-character edits required to transform one name into \nanother ( Beernaerts et al., 2019 ; Levenshtein, 1966 ). Through initial \ntrials, we determined that a stringent similarity threshold of 20 was \nnecessary to ensure meaningful differentiation between models. Thus, \nany two models with a name similarity within this distance and have the \nsame number of parameters were considered too similar. The dedupli -\ncation process was implemented in Python, resulting in a final sub -\nsample size of 591 usable models. Because the results derived from all \nthree samples were highly similar, we report only the results derived \nfrom the subsample of 591 models in the main manuscript (the results \nassociated with the n = 1599 and n = 2415 subsamples are reported in \nthe supplementary document).\n2.2. Measures\nA total of 12 tests were selected to represent, at least theoretically, \nfour different group-level factors of ability: fluid reasoning ( Gf ); quan -\ntitative knowledge ( Gq ); reading/writing ( Grw ) and domain-specific \nknowledge ( Gkn ). Several tests were selected from the Massive Multi -\ntask Language Understanding (MMLU) test battery ( Hendrycks et al., \n2020 ). All items associated with the MMLU subtests can be viewed at htt \nps://huggingface.co/datasets/cais/mmlu .\nGf was measured by three tests. First, Hellaswag is a 10,042-item test \ndesigned to evaluate an LLM ’ s abilities in natural language under -\nstanding and commonsense reasoning ( Zellers et al., 2019 ). Test items \nconsist of various contexts that require the identification of the most \nplausible continuation out of four provided options. For example, “ A \nwoman is outside with a bucket and a dog. The dog is running around \ntrying to avoid a bath. She … a) rinses the bucket off with soap and blow \ndry the dog ’ s head; b) uses a hose to keep it from getting soapy; c) gets \nthe dog wet, then runs away again (correct); d) gets into a bathtub with \nthe dog.\nThe two remaining Gf tests were considered measures of quantitative \nreasoning, a stratum I dimension of Gf ( Schneider & McGrew, 2018 ). \nThe Grade School Math 8 K (GSM8K) aims to test an LLM ’ s ability to \nperform multi-step arithmetic operations and mathematical reasoning \npresented in a natural language context ( Cobbe et al., 2021 ). Out of the \n8500 items, we selected 1319 that best reflect quantitative reasoning. An \nexample question is: “ The ratio of boys to girls in a family is 5:7. The \ntotal number of children in the family is 180. If the boys are given $3900 \nto share, how much money does each boy receive? ” (Answer: 52). The \nresponse format is open-ended.\nThe items for the third Gf test, specifically the Elementary Mathe -\nmatics subtest within the MMLU benchmark battery ( Hendrycks et al., \n2020 ), were selected for their ability to represent quantitative \nreasoning. For instance, one of the items is as follows: “ The rate at which \na purification process can remove contaminants from a tank of water is \nproportional to the amount of contaminant remaining. If 20% of the \ncontaminant can be removed during the first minute of the process and \n98% must be removed to make the water safe, approximately how long \nwill the decontamination process take? (Response alternatives: a) 2 min, \nb) 5 min, c) 18 min [correct], and d) 20 min.\nGkn was measured by a combination of three composites scores, \nwhich were based on items derived from the (MMLU) test battery \n( Hendrycks et al., 2020 ). All items associated with the MMLU subtests \ncan be viewed at https://huggingface.co/datasets/cais/mmlu . Com -\nposite score one was based on the International Law, Business Ethics, \nPhilosophy test items. Composite score two was based on the Medical \nGenetics, Clinical Knowledge, Human Aging, and Human Sexuality test \nitems. Finally, composite score three was based on the Global Facts, \nComputer Security, Marketing, and Miscellaneous test items.\nGq was also measured by several tests within the MMLU test battery. \nOne composite was based on the High School Statistics, Abstract \nAlgebra, and Econometrics subtests (measuring Mathematical Knowl -\nedge; KM). A second composite was based on selected items from the \nElementary Mathematics subtest (measuring Mathematical Accom -\nplishment; A3). Finally, the third composite based on a combination of \nselected Elementary Mathematics items and High School Mathematics \nsubtest items (measuring Mathematical Accomplishment; A3).\nGrw was measured by three tests, two of which were from the MMLU: \nthe High School European History test and the High School US History \ntest ( Hendrycks et al., 2020 ). For both tests, the items require carefully \nreading and comprehending intricate written passages, which often \ninvolve nuanced language, contextual references, and philosophical \nperspectives from different historical eras. Each question is multiple- \nchoice in nature with four response alternatives. The third test, \nWinogrande, was classified as a measure of Grw , as Winogrande prob -\nlems require comprehending written sentences/passages and resolving \nambiguity through contextual understanding ( Sakaguchi et al., 2021 ). \nSpecifically, for each test item, models must choose between two options \nto complete a sentence, based on understanding subtle linguistic and \ncontextual cues. For example: ‘John moved the couch from the garage to \nthe backyard to create space. The _____ is small. ’ Choices: a) garage \n(correct); b) backyard.\nAll tests were scored such that they represented percentage of \nquestions answered correctly. For a list of the tests, their theorised CHC \nTable 1 \nSelected LLM Benchmark Tests and the Corresponding CHC Model \nCategorisations.\nStratum \nII \nAbility\nStratum I Ability Tests Model \nIndicator \nName\nItems α\nGf\nQuantitative \nReasoning\nElementary \nMathematics RQ 51 0.74\nGf\nQuantitative \nReasoning GSM8K GSM8K 1319 0.99\nGf\nGeneral \nSequential \nReasoning Hellaswag Hellaswag 10,042 0.99\nGkn\nLaw & Ethics \nKnowledge\nInternational \nLaw, Business \nEthics, \nPhilosophy Ethics 532 0.97\nGkn\nHealth Science \nKnowledge\nMedical \nGenetics, \nClinical \nKnowledge, \nHuman Aging, \nHuman \nSexuality Health 719 0.97\nGkn\nMiscellaneous \nKnowledge\nGlobal Facts, \nMiscellaneous, \nComputer \nSecurity, \nMarketing Misc. 1217 0.87\nGrw\nReading \nComprehension\nHS European \nHistory Euro. Hist 44 0.96\nGrw\nReading \nComprehension HS US History US Hist. 48 0.97\nGrw\nReading \nComprehension Winogrande Winogrande 1267 0.99\nGq\nMathematical \nKnowledge\nHigh School \nStatistics, \nAbstract \nAlgebra, \nEconometrics KM 53 0.93\nGq\nMathematical \nAccomplishment\nElementary \nMathematics A3.E 41 0.87\nGq\nMathematical \nAccomplishment\nElementary \nMathematics, \nHigh School \nMathematics A3.HS 29 0.72\nNote . Gf = fluid reasoning; Gkn = domain-specific knowledge; Grw = reading/ \nwriting; Gq = quantitative knowledge; α = internal consistency reliability.\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n4 \nmodel classifications, number of items, and test score reliabilities, see \nTable 1 .\n1\n2.3. Data analysis\nAll statistical analyses were performed using R (Version 4.2.2) and \nRStudio (Version 2022.09.1). To evaluate the relationships between key \nobserved variables, Pearson correlation coefficients were calculated. We \nused the ggplot2 package ( Wickham, 2016 ) to create a scatter matrix, \nwhich provided visual insights into the nature and strength of these \nassociations. LOESS regression lines, computed with R ’ s tricubic \nweighted function ( Cleveland & Devlin, 1988 ), were included in the \nscatter matrix for a flexible fit, emphasizing data points based on \nproximity. The default setting window size of 0.75 was specified, \nimplying that 75% of the data points in the neighbourhood of each point \nwere used for local regression. Finally, 95% confidence intervals were \nincluded to show estimation uncertainty.\nLatent variable modeling was performed using the lavaan package \n( Rosseel, 2012 ). Model fit was assessed using RMSEA and SRMR (with \nvalues ≤ 0.08 indicating acceptable fit), as well as CFI and TLI (with \nvalues ≥ 0.950 indicating acceptable fit). Given that the data were \ncontinuously scored, maximum likelihood estimation was utilized. \nStandardized effect 95% confidence intervals were generated through \nbootstrapping (5000 resamples) using a combination of the manymome \n( Cheung & Cheung, 2023 ) and semhelpinghands packages ( Cheung & \nCheung, 2023 ).\nWe evaluated a theoretical model comprising a second-order general \nfactor and four first-order factors ( Gf , Gkn , Grw , Gq ), aligning with the \ncategorizations and tests outlined in Table 1 . To ensure proper identi -\nfication and scaling, the variance of the general factor was fixed at 1, and \none loading for each of the first-order factors was also constrained to 1. \nThe data, scripts, and results are available on the OSF: https://osf. \nio/792ug/\n3. Results\n3.1. Descriptive statistics and inter-subtest pearson correlations\nAs can be seen in Table 2 , LLM mean performance (percentage of \nquestions answered correctly) across the 12 tests ranged from 18.09 to \n74.27, with a mean of 48.62, suggesting the tests were, on average, \nmoderately difficult. Furthermore, there were substantial individual \ndifferences in performance, as the mean test performance standard de -\nviation was 20.02 (range: 10.99 to 31.48). The test performance distri -\nbutions tended to be negative, though only substantially so for the \nHellaswag test (skewness = \u0000 1.04). See Tables S1.1 and S1.2 in the \nsupplementary document for the descriptives based on the other two \nsubsamples.\nThe inter-correlations between the 12 test performance scores were \nall positive with a mean correlation of 0.73 (range: 0.35 to 0.99; see \nTable 2 ; see Fig. S1.1 for scatter matrix), supporting the hypothesis of a \npositive manifold. The Gkn inter-correlations were exceptionally large, \nranging between 0.98 and 0.99.\n3.2. Confirmatory factor analysis\nThe Kaiser-Meyer-Olkin (KMO) index analysis yielded a value of \n0.93, suggesting the correlation matrix was appropriate for data \nreduction ( Kaiser & Rice, 1974 ). Our hypothesized higher-order \nconfirmatory factor analytic model did not produce an interpretable \nsolution, as evidenced by statistically significant negative residual var -\niances for two of the first-order factors. Consequently, we explored the \nstructure of the data by conducting unrestricted factor analyses. First, \nwe conducted a parallel analysis to determine the number of dimensions \nto extract. The parallel analysis suggested the extraction of one dimen -\nsion (see Table S2.1). However, a maximum likelihood estimation factor \nanalysis with the extraction of one factor failed to yield good model \nclose-fit (e.g., TLI = 0.814).\n2\nA subsequent unrestricted factor analysis \nwith the extraction of two factors remained unacceptably well-fitting (e. \ng., TLI = 0.870). Furthermore, the Hellaswag test was associated with a \nloading of 1.07 on the first factor, suggesting the factor solution was not \nstable. Moreover, the correlation between the two factors was quite \nlarge at 0.78, suggesting the presence of a substantial general factor.\nBased on the above unrestricted factor analytic findings, we tested a \nsupplementary restricted factor analytic bifactor model with a first- \norder general factor defined by all 12 tests. Additionally, we specified \na nested, first-order Gkn / Grw factor. Due to the very high correlations \nbetween the Winogrande and Hellaswag tests ( r = 0.95) and the Euro -\npean History and US History tests ( r = 0.97), we also specified corre -\nlations between these respective test residuals. When we tested the \nmodel, the modification indices suggested the addition of one more \ncorrelated residual, i.e., between the A3.E and A3.HS tests. The bifactor \nmodel with the three correlated residuals yielded acceptable model \nclose-fit, χ\n2\n(44) = 250.42, p < .001, CFI = 0.984, TLI = 0.977, RMSEA =\n0.089, SRMR = 0.025.\n3\nAll of the loadings were positive and statistically \nsignificant ( p < .001; see Fig. 1 ). The mean general factor loading was \nlarge at 0.81 (range: 64 to 0.96; see Table S3.1 for all loadings and 95% \nCIs). The indicator with the largest general factor loading was associated \nwith the KM mathematics composite ( λ = 0.96). The percentage of \nvariance accounted for by the general factor was estimated at 65.6%.\n4\nFurthermore, the general factor omega hierarchical was 0.94. Thus, \nthere was evidence for a very strong general factor and, thus, highly \nreliable LLM general ability composite scores. Though the nested Gkn / \nGrw nested factor was notably weaker than the general factor, it was \nnonetheless defined by consistently positive and statistically significant \nfactor loadings (mean λ = 0.50).\n3.3. Associations with number of parameters\nNext, we investigated the associations between the two LLM ability \ndimensions, artificial general ability (AGA) and Gkn / Grw , and the \nnumber of LLM parameters. Number of parameters data were available \nfor 579 models. The LLMs had an average number of parameters equal to \n14.86 billion. However, a histogram revealed two outliers with values of \n238.09 and 180.00 billion parameters. These outliers were excluded \nfrom the correlation analyses. After removing the outliers ( n = 577), the \nnumber of parameters had a mean of 14.19 billion ( SD = 18.87; Median \n= 7.24 billion). The distribution remained skewed (skewness = 2.53). \nTherefore, we estimated the associations using both Pearson and \nSpearman correlations. Additionally, the 95% confidence intervals for \nthe correlations were calculated using 5000 bootstrapped resamples.\nThe Pearson correlation between number of parameters and general \n1\nWe conducted item-total correlation analyses, prior to the testing of hy -\npotheses. For some tests, we omitted items, as they failed to yield positive item- \ntotal correlations (see supplementary file 2). Reliabilities were estimated using \nitem-level analyses for all tests, except for the Gkn composite scores, which \nwere derived from three subtests each. For these composite scores, the three \nrespective subtests were used as inputs in the reliability analysis.\n2\nThe parallel analysis procedure fails to identify the correct number of fac -\ntors to extract in ≈ 2 5% of cases ( Crawford et al., 2010 ).\n3\nDespite the RMSEA being above 0.080, we considered the model to be \nacceptably well-fitting because the SRMR was quite low at 0.02 5. This decision \nis supported by simulation research indicating that RMSEA (but not SRMR) can \nbe overly sensitive to unmodeled correlated residuals ( Montoya & Edwards, \n2021 ).\n4\nWe calculated the percentage of variance accounted for by summing the \nsquared g loadings and dividing that sum by the total number of indicators in \nthe model (7.87 / 12 = 6 5.6).\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n5 \nability factor scores was r = 0.54, 95% CI: [0.48, 0.59]. The corre -\nsponding Spearman correlation was r = 0.62, 95% CI: [0.60, 0.67]. A \nnonlinear model (cubic spline) fit the relationship between parameter \ncount and general ability scores significantly better than a linear model, \nF (2, 573) = 27.93, p < .001, Δ η\n2 \n= 0.063. Next, we examined the nature \nof the association in a scatter plot with a LOESS regression line of fit. As \nthere were only 10 LLMs with more than 80 billion parameters, we \nrestricted the scatter plot analysis to values less than 80 billion param -\neters. As can be seen in Fig. 2 (left side), the analysis revealed a positive \nassociation, characterized by distinct phases. Initially, there was a sharp \nincrease in AGA factor scores as the number of parameters increased \nfrom 100 million to approximately 10 billion parameters. This was fol -\nlowed by a phase of stabilization between 10 and 20 billion parameters. \nBeyond 30 billion parameters, the AGA factor scores continued to \nimprove gradually and steadily up to 80 billion parameters. Overall, the \ntrend suggests that increasing the number of parameters generally en -\nhances general large language model capacity, with the most significant \ngains observed at lower parameter counts and a more gradual \nimprovement at higher counts.\nThe Pearson correlation between Gkn/Grw and number of parame -\nters was r = 0.11, 95% [CI: 0.05, 0.18]. The corresponding Spearman \ncorrelation was r = 0.42, 95% CI: [0.34, 0.49]. A nonlinear model (cubic \nspline) fit the relationship between parameter count and Gkn / Grw scores \nsignificantly better than a linear model, F (2, 573) = 87.13, p < .001, Δ η\n2 \n= 0.230. As can be seen in Fig. 2 (right side), somewhat similar to the \ngeneral ability factor, the analysis revealed a positive association, \ncharacterized by distinct phases. Initially, there was a sharp increase in \nGkn / Grw factor scores as the number of parameters increased from 0 to \napproximately 10 to 15 billion. This was followed by a phase of fluc -\ntuation and slight decline between 10 and 45 billion parameters, indi -\ncating variability and a non-linear relationship. Beyond 45 billion \nparameters, there was essentially no association between the two vari -\nables. Overall, the trend suggests that increasing the number of pa -\nrameters enhances Gkn / Grw ability, though only up to 15 to 20 billion \nparameters. See Table S2.4 for a summary of the key results across all \nthree subsamples.\n4. Discussion\nWe found evidence for a LLM test performance positive manifold, as \nwell as an artificial general ability (AGA) factor. Beyond the general \nfactor, instead of four separate group-level factors, we found evidence \nfor only one combined Grw / Gkn group-level factor. A mathematics test \ncomposite yielded the largest AGA loading. Finally, number of model \nparameters was found to associate positively with both AGA and the \nGrw / Gkn group-level factor. We discuss each of these key results next.\n4.1. Positive manifold and AGA\nThe strength of the LLM positive manifold was remarkable, with a \nTable 2 \nBenchmark LLM test performance descriptive statistics and Pearson inter-correlations.\nTest II 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. M SD Mdn skew kurtosis\n1. Hellaswag Gf 1.0 72.18 21.01 81.96 \u0000 1.04 \u0000 0.27\n2. RQ Gf 0.45 1.0 32.83 10.99 31.37 0.37 0.10\n3. GSM8K Gf 0.58 0.62 1.0 18.09 21.41 8.61 1.05 \u0000 0.21\n4. KM Gq 0.61 0.73 0.80 1.0 43.35 20.13 37.74 0.52 \u0000 0.82\n5. A3.E Gq 0.37 0.35 0.62 0.63 1.0 31.45 17.24 29.27 0.44 \u0000 0.85\n6. A3.HS Gq 0.54 0.56 0.67 0.73 0.65 1.0 33.19 15.69 33.33 0.70 0.42\n7. European History Grw 0.79 0.62 0.68 0.80 0.51 0.64 1.0 60.70 29.11 70.45 \u0000 0.28 \u0000 1.61\n8. US History Grw 0.82 0.60 0.67 0.78 0.50 0.64 0.97 1.0 65.34 31.48 79.17 \u0000 0.32 \u0000 1.64\n9. Winogrande Grw 0.95 0.56 0.69 0.73 0.47 0.60 0.86 0.89 1.0 74.27 13.82 79.09 \u0000 0.49 \u0000 1.10\n10. Ethics Gkn 0.85 0.65 0.73 0.84 0.55 0.70 0.94 0.95 0.91 1.0 51.07 19.93 57.03 \u0000 0.20 \u0000 1.47\n11. Health Gkn 0.83 0.68 0.75 0.86 0.59 0.71 0.94 0.95 0.90 0.98 1.0 50.05 19.59 53.98 \u0000 0.11 \u0000 1.50\n12. Miscellaneous Gkn 0.86 0.63 0.71 0.81 0.55 0.69 0.95 0.96 0.91 0.99 0.98 50.94 19.80 58.60 \u0000 0.32 \u0000 1.54\nNote. N = 591; II = theorised stratum II dimension; Gf = fluid reasoning; Gq = Quantitative Knowledge; Grw = reading/writing; Gkn = domain specific knowledge; all \ncorrelations statistically significant, p < .001.\nFig. 1. Latent Variable model with completely standardized coefficients. \nNote. N = 591; AGA = artificial general ability; Gkn = domain-specific knowledge; Grw = reading/writing; all coefficient statistically significant, p < .001; see Table 1\nfor model indicator descriptions; see Table S2 for 95% CIs.\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n6 \nmean inter-test correlation of 0.73, significantly higher than that typi -\ncally observed in humans, i.e., r = 0.45 to 0.50 ( Detterman & Daniel, \n1989 ; Walker et al., 2023 ). Correspondingly, the general factor of arti -\nficial ability accounted for 66% of the variance, whereas general factors \nof intelligence in human samples typically account for 40 to 50% of the \nvariance ( Deary et al., 2009 ). Finally, the LLM general factor yielded a \ncoefficient of omega hierarchical of 0.94, a value higher than typically \nobserved for the general factor of human intelligence (mid to high .80s; \nDombrowski et al., 2019 ; Gignac, 2014a ; Gignac & Watkins, 2013 ).\nThere are several possible reasons why the LLM general factor was \nfound to be stronger than the general factor of intelligence for humans. \nFirst, the LLM test data were mostly associated with exceptional test \nscore reliability. The median internal consistency reliability across the \n12 LLM composite test scores was 0.97, whereas, as a point of com -\nparison, the WAIS-IV technical manual ( Wechsler, 2008b ) reported \nmean subtest reliabilities of 0.88, which is probably closer to 0.75 to \n0.80 in practice (see Oosterwijk et al., 2019 ). In contrast to LLMs, human \nperformance is influenced by a myriad of factors including emotional \nand physical states, which vary widely among individuals. LLMs, how -\never, do not experience such variability, likely leading to more reliable \ntest performance.\nRelatedly, while LLMs are trained on a vast and diverse corpus of \ntext, the processing of this data by LLMs is uniform. Each piece of text, \nregardless of its origin or content, is converted into a standardized \nformat and fed into the model through the same training algorithms and \nprocedures ( Zhao et al., 2023 ). This uniformity in processing ensures \nthat the model processes the data in a consistent manner, which is in \ncontrast to the moderate fluctuations that characterize human neuro -\nphysiology, thoughts, and behaviours over time (i.e., test-retest reli -\nability far less than 1; Dai et al., 2019 ; Gnambs, 2014 ; Noble et al., \n2019 ).\nFinally, the median number of items per LLM test we included in the \ntest battery was very large at 300. This is important, as the number of \nitems in a psychometric measure is positively associated with test score \nreliability ( Nunnally & Bernstein, 1994 ). Correspondingly, the internal \nconsistencies for the LLM tests were typically very high (median 0.97), \nallowing for maximum possible correlations between LLM test scores (i. \ne., not attenuated by measurement error). By comparison, humans \ncannot be expected to complete very large numbers of test items without \nexperiencing fatigue, loss of concentration, or other transient factors \nthat can negatively impact the consistency of performance and, to some \nextent, the magnitude of an observed score positive manifold. We note \nthat when restricted to the six LLM tests composed of 52 or fewer items, \nthe mean LLM inter-test correlation was 0.63, which is smaller than the \n0.73 value associated with all 12 LLM tests, but still larger than the 0.45 \nto 0.50 typically observed in humans ( Detterman & Daniel, 1989 ; \nWalker et al., 2023 ). Thus, the greater breadth of coverage in some of the \nLLM tests composed of 100 s of items is arguably not the full explanation \nfor why the LLMs yielded a stronger positive manifold than that typically \nobserved in humans.\nAdmittedly, the range of LLM tests included in our analysis may be \nconsidered narrower compared to comprehensive measures of human \nintelligence. For example, none of the 12 tests assessed spatial abilities, a \nkey dimension of cognitive ability in comprehensive batteries of human \nintelligence ( Johnson & Bouchard Jr, 2005 ). Therefore, it is plausible \nthat the percentage of variance accounted for by the LLM general factor \nwas somewhat inflated due to the greater homogeneity in the selected \nLLM benchmark tests. Consequently, we refrained from labelling the \nLLM general factor identified in our investigation as ‘artificial general \nintelligence, ’ as true AGI is expected to be demonstrated across verbal \nand spatial ability tests ( Gignac & Szodorai, 2024 ; Jensen, 1998 ). We \nnonetheless note that the mean inter-subtest correlation between the \nverbal subtests associated with the Wechsler scales is between 0.55 and \n0.60 ( Wechsler, 1981 ; Wechsler, 2008b ), which is still lower than the \n0.73 mean inter-subtest correlation observed in our investigation. In \nsimple terms, our results imply that better LLM performance on one task \nis substantially associated with better performance on another, much \nlike the patterns observed in human cognitive abilities ( Jensen, 1998 ). \nThus, even considering the homogeneity of the LLM tests, the substantial \nshared variance across moderately distinct LLM tasks suggests the \npresence of general LLM capability.\n4.2. Group-level factors\nWe identified only one group-level factor, not four as hypothesized. \nThis group factor was a combination of Gkn and Grw tests. Tests \ndesigned to measure Grw and Gkn share substantial content overlap. \nSpecifically, reading and writing skills often involve the application of \nFig. 2. Scatter plots depicting the association between number of parameters (billions) and artificial general ability factor scores (left side),and number of parameters \nand Grw/Gkn factor scores (right side). \nNote. N = 577; lines of best fit are LOESS regression lines (tricubic weighting; span = 0.75); the jitter applied to the scatter plots was set to a width and height of 0.3 \nunits along the respective axes; all correlations were significant, p < .001.\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n7 \ngeneral knowledge, as comprehension and production of text rely \nheavily on background information and vocabulary. Schneider and \nMcGrew (2018) contended that it is beneficial to conceptualize a higher- \norder acquired-knowledge/expertise dimension that unites Gc , Grw , \nGkn , and Gq variance. Although we did not find evidence that Gq tests \nare indicators of any factor beyond AGA, the fact that the Grw and Gkn \ntests formed a nested group-level factor independent of AGA is at least \npartially consistent with Schneider and McGrew (2018) theoretical \nproposition of an overarching acquired knowledge/expertise dimension.\nWe note that the empirical distinction between Grw and Gkn is far \nfrom clear in humans. Based on a sample of 6701 school children who \ncompleted a battery of verbal intelligence tests ( Gc , Grw , and Gkn ), \nSchipolowski et al. (2014) reported a latent variable correlation of 0.91 \nbetween Grw and Gkn . Additionally, based on Bryan and Mayer (2020)\nmeta-analysis on the associations between CHC group-level factors, only \none study included a Grw factor and none the Gkn dimension.\n5\nThe \ncorrelation between Grw and Gc was reported at r = 0.85. Though cor -\nrelations of 0.85 to 0.91 may not be entirely consistent with the notion of \nisomorphic constructs, it should be acknowledged that correlations of \nsuch a magnitude are so large that the apparent discriminant validity \nmay have arisen due to method artifacts (e.g., question type) rather than \nsubstantive (construct) variance. All things considered, the observation \nof a combined Grw / Gkn dimension in our LLM data may be considered \nlargely consistent with the human intelligence empirical literature, i.e., \nGrw and Gkn are highly inter-related.\nWe also failed to observe a Gf factor independent of the general \nfactor. While some have argued that Gf is essentially isomorphic with g \nin humans (e.g., Gustafsson, 2001 ), we are more cautious about making \nsuch an interpretation with our data. Our selected measures of Gf were, \nat best, acceptable rather than good or excellent. In particular, two of \nour Gf tests focused on mathematical reasoning, and none involved \nfigural matrices which are typically well-regarded for measuring fluid \nreasoning ( Gignac, 2015 ). Consequently, further research with better \nmeasures of Gf is required to evaluate the possibility of a distinct Gf \ngroup-level factor in LLM data.\n4.3. Strongest indicator of AGA\nMuch research has found that Gf dimensions are the strongest in -\ndicators of g in humans (e.g., Gignac, 2014b ; Hertzog & Schaie, 1988 ; \nKvist & Gustafsson, 2008 ). However, in our study, a mathematics \ncomposite that included algebra and statistics questions yielded the \nlargest AGA loading. As previously noted, among the LLM benchmark \ntests available for this investigation, none were consistent with the well- \nregarded figural matrices tests of fluid reasoning. Consequently, it is \ndifficult to compare our results with the broader human intelligence \nliterature, in this context. Nonetheless, it is noteworthy that several \ninvestigations have found arithmetic to be the strongest indicator of g in \nhuman samples. For example, Gignac (2015) consistently found math -\nematics/arithmetic subtests to be the strongest indicators of g across \nbifactor analyses of three comprehensive batteries of human intelli -\ngence. Additionally, based on a bifactor analysis of the WAIS-IV \nnormative sample, Gignac and Weiss (2015) found that the Arithmetic \nsubtest yielded the most substantial loading onto g . While arithmetic \nmay or may not be the best indicator of g , the literature on humans \nsuggests that arithmetic is a strong indicator of g , which aligns with the \nresults observed in our investigation with LLMs.\nBased on latent variable models, several stratum II cognitive ability \ndimensions have been found to be unique predictors of human arith -\nmetic ability, suggesting a relatively complex cognitive process ( Floyd \net al., 2003 ; Fung & Swanson, 2017 ). It is noteworthy that LLMs are \nknown to exhibit challenges with completing arithmetic problems \n( Panas et al., 2024 ). Possible explanations for this phenomenon include \ntheir training on diverse, noisy data which does not emphasize preci -\nsion, their tendency to propagate errors in multi-step reasoning, and \ndifficulties with symbolic manipulation ( Imani et al., 2023 ; Qian et al., \n2022 ; Yuan et al., 2023 ). Thus, LLMs capable of greater precision, error \ncorrection in multi-step problem solving, and enhanced symbolic \nmanipulation would be expected to perform better at arithmetic, as well \nas a wide range of other tasks, thereby exhibiting higher levels general \nability. In other words, LLMs that excel in solving arithmetic/mathe -\nmatics problems, which would be expected to require more sophisti -\ncated training, model architecture, and computational algorithms, may \nalso be superior at a variety of other verbal tasks, explaining the sub -\nstantial AGA loading we observed for arithmetic.\n4.4. Association with number of parameters\nWe found number of parameters to be a substantial, positive pre -\ndictor of AGA, as hypothesized. Thus, our results align with the small \namount of empirical research on individual LLMs that have indicated \nthat increasing number of parameters improves LLM performance ( Anil \net al., 2023 ). We extend the literature by estimating the association \nbased on a large sample of LLMs and a moderately diverse battery of \nbenchmark tests. Thus, our results help support the notion that the more \ncomplex patterns captured by larger models not only facilitates better \nperformance on specific tasks ( Hu et al., 2021 ), but on LLM capacity in a \ngeneral sense. Our finding is also consistent with research with biolog -\nical organisms that has found greater cognitive abilities to be predicted \nby greater neuronal density and connectivity ( Dicke & Roth, 2016 ; \nGoriounova et al., 2018 ).\nWhile the number of model parameters accounted for approximately \n25% of the variance in AGA, the relationship was clearly curvilinear. \nAGA factor scores generally increased with parameter count, showing \nthe most significant gains at lower ranges (100 M to 10B), followed by \nsomewhat weaker improvements, and essentially no association for \nGkn / Grw , at higher parameter counts. These results are supported by \nHoffmann et al. (2022) , who demonstrated that for compute-optimal \ntraining, both the model size and the number of training tokens \nshould be scaled equally. That is, increasing model parameters without \nalso increasing the number of training tokens proportionally should not \nbe expected to improve LLM performance uniformly. Such a perspective \nis somewhat analogous to neuronal density and cognitive abilities in \nbiological organisms. While the cerebral cortex of humans and other \nprimates has a higher neuronal density compared to other mammals, it is \nalso the intricate patterns of connectivity and the hierarchical organi -\nzation of these densely packed neurons that enable advanced cognitive \nfunctions like language, reasoning, and problem-solving ( Herculano- \nHouzel, 2009 ; Roth & Dicke, 2005 ).\n4.5. Limitations\nFirst, the breadth of the tests in our 12-test battery may be regarded \nas limited. In particular, our 12-test battery did not include assessments \nfrom several important CHC stratum II dimensions, such as Gv (visual \nprocessing), Gsm (short-term memory), and Gs (processing speed). Un -\nfortunately, none of the tests within the Hugging Face database fall into \nthese stratum II categories. This limitation reflects the nature of the tests \ntypically used to evaluate LLMs, which are fundamentally verbal in \nnature. Consequently, it is unreasonable to expect LLMs to be successful \nat solving visual-spatial problems. Moreover, short-term memory and \nprocessing speed have not yet been considered as dimensions for \nbenchmarking LLMs, despite their significant roles in human intelli -\ngence ( Conway et al., 2013 ; Jensen, 2006 ). It is hoped that future \nbenchmarks will address this gap by incorporating tests that evaluate \nmemory span and processing speed.\nAdditionally, as noted above, none of the included tests can be \njustifiably regarded as relatively pure indicators of Gf . While good \n5\nFor reasons that are unclear, the Bryan and Mayer meta-analysis did not \ninclude Schipolowski et al. ’ s (2014) results.\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n8 \nquality Gf tests often involve visual items (e.g., figural matrices), there \nare high-quality verbal approaches to the measurement of Gf ( Beauducel \net al., 2001 ). For example, analogical reasoning (e.g., “ Lawyer is to \nClient as Doctor is to _____ ” ), inductive reasoning (e.g., determining the \nnext letter in a sequence like “ A, C, E, G, ____ ” ), and logical reasoning (e. \ng., “ All mammals are animals. All dogs are mammals. Therefore, all dogs \nare ____ ” ). All things considered, despite the lack of breadth in our test \nbattery, our results may be considered at least tentatively suggestive of a \ngeneral factor of artificial ability, which will ideally be re-tested in \nfuture when the breadth of tests included in large scale databases is \nexpanded.\nCritics might argue that not all models in our analysis were suffi -\nciently distinct to be considered separate cases, potentially inflating the \ncorrelations between model test performances. To address this concern, \nwe employed three approaches to exclude insufficiently distinct cases. In \nour most conservative subsample, we omitted 85% of the models (3271 \nout of 3862), retaining only 591 for analysis. Beyond architecture \n(neural network layers, connections, and main components), model size, \nand even training data, there are many characteristics associated with a \nlanguage model that can be expected to impact performance, including \ntraining duration, input representation (static versus dynamic), hyper -\nparameters (batch sizes), objective (e.g., Masked Language Model; Next \nSentence Prediction), data augmentation (artificially increase the size of \nthe training dataset), tokenization (e.g., WordPiece; byte-level BPE), and \noptimization algorithms (e.g., Adam or Stochastic Gradient Descent). \nThus, we believe our most conservative sample essentially represents \nwhat can be considered in practice the relatively unique models avail -\nable in the first half of 2024.\nAs another limitation, we examined only one predictor of LLM per -\nformance. As noted, in addition to the number of model parameters, \nnumerous other factors are expected to impact LLM performance, \nincluding the quantity and quality of training data, model architecture, \ntokenization, hyperparameters, and fine-tuning ( Hoffmann et al., 2022 ). \nWe did not have access to such information for a sufficiently large \nnumber of models to examine these factors statistically. Consequently, \nfuture research should consider examining these potential predictors as \nmore comprehensive databases of LLM performance become available.\nFinally, we acknowledge the possibility that LLMs may not exhibit \ntrue intelligence. After IBM ’ s Watson defeated two American Jeopardy! \nchampions in 2011, Detterman (2011) argued that this achievement did \nnot necessarily indicate true intelligence, as that version of Watson was \nspecifically designed to answer Jeopardy! questions and would likely \nperform poorly on reasoning tasks. Consequently, Detterman (2011)\nproposed that a more meaningful test of a computer ’ s intelligence would \ninvolve a unique battery of IQ tests, developed by human intelligence \nexperts. This challenge would have two levels: the first allowing data \nand algorithms to be supplied post hoc, similar to Watson ’ s Jeopardy! \npreparation, and the second requiring only pre-programmed algorithms, \nforcing the computer to self-organize information as humans do. Only AI \nsystems that answer questions on the second test would be considered to \nmanifest true intelligence.\nAlthough the tests utilized in the current investigation were not \ncrafted by experts in human intelligence, there is awareness in the field \nthat LLMs should not be specifically trained upon the benchmark tests \nemployed to evaluate their performance ( Lyu et al., 2021 ). Conse -\nquently, it may be posited that modern LLMs have, to some extent, met \nthe criteria of Detterman (2011) second challenge. However, it is widely \nacknowledged that even more modern AI systems often struggle to \nconsistently generalize their learned capabilities effectively ( Vafa et al., \n2024 ). Moreover, LLMs are prone to making certain types of errors that \nmight be effortlessly avoided by humans, even those with relatively \nlower cognitive abilities ( Tyen et al., 2023 ).\nConsidering the importance of generalizability in defining intelli -\ngence, some researchers have argued that evidence for true intelligence \nin AI systems remains limited ( van der Maas et al., 2021 ). More recently, \nGignac and Szodorai (2024) contended that, given the nature of LLM \ndevelopment and training, and the essential need for novelty in intelli -\ngence testing, there may be more evidence supporting artificial \nachievement/expertise than artificial intelligence. Finally, beyond the \nconsiderations of generalizability and training, some argue that true \nintelligence includes self-awareness and the capacity for autonomous \nimprovement through self-evaluation (e.g., Bostrom, 2014 ; Mitchell, \n2019 ; Sternberg, 2011 ). Correspondingly, a distinction is often made \nbetween weak AI, designed for specific tasks without true understanding \nor consciousness, and strong AI, which can understand, learn, and \nexhibit consciousness similar to human intelligence (Neubauer, 2021). \nAwareness and self-improvement are characteristics that were not \nassessed in our study of LLMs.\nThus, while our findings suggest the presence of a general factor of \nability in LLMs, it is unclear whether this factor represents true artificial \ngeneral intelligence or merely artificial general achievement. Regardless \nof the validity of Gignac and Szodorai (2024) conclusions, it is note -\nworthy that current LLMs exhibit a positive manifold - a phenomenon \nwhere performance on one task positively correlates with performance \non others. This characteristic mirrors a fundamental property observed \nin human cognitive abilities ( Jensen, 1998 ).\n5. Conclusion\nIndividual differences in LLM capacities, similar to human cognitive \nabilities, result in a strong positive manifold. Consequently, models that \nperform well on one task also tend to perform well on others, suggesting \nthe possibility of underlying general processes. Number of model pa -\nrameters was found to be an appreciable, positive predictor of general \nand Gkn / Grw LLM performance. However, in the absence of other \ncomplementary model characteristics (e.g., number of tokens), the \nnumber of model parameters is likely to manifest an effect of dimin -\nishing returns. Our findings help describe the structure of artificial \nsystem capabilities and underscore the potential for further optimizing \nLLM performance through a balanced approach to model design. Addi -\ntional work investigating LLM performance with differential psychology \napproaches may facilitate further advancements in both artificial and \nhuman intelligence research.\nCRediT authorship contribution statement\nDavid Ili ´c: Writing – review & editing, Software, Methodology, \nInvestigation, Formal analysis, Data curation, Conceptualization. Gilles \nE. Gignac: Writing – original draft, Methodology, Investigation, Formal \nanalysis, Conceptualization.\nDeclaration of generative AI and AI-assisted technologies in the \nwriting process\nDuring the preparation of this work the authors used ChatGPT, \nClaude, and Perplexity to help with the generation of R scripts, as well as \nto suggest superior and more concise writing. After using these tools/ \nservices, the authors reviewed and edited the content as needed and take \nfull responsibility for the content of the publication.\nDeclaration of competing interest\nThe authors declare that they have no conflict of interest.\nData availability\nData and scripts available on the OSF link\nAppendix A. Supplementary data\nSupplementary data to this article can be found online at https://doi. \norg/10.1016/j.intell.2024.101858 .\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n9 \nReferences\nAmazon Web Services. (2024). What is AGI?. Retrieved May 26\nth\n, 2024 from https://aw \ns.amazon.com/what-is/artificial-general-intelligence/ .\nAnil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., … Wu, Y. (2023). \nPalm 2 technical report. arXiv . preprint arXiv:2305.10403 .\nArden, R., & Adams, M. J. (2016). A general intelligence factor in dogs. Intelligence, 55 , \n79 – 85 .\nBeauducel, A., Brocke, B., & Liepmann, D. (2001). Perspectives on fluid and crystallized \nintelligence: Facets for verbal, numerical, and figural intelligence. Personality and \nIndividual Differences, 30 (6), 977 – 994 .\nBeernaerts, J., Debever, E., Lenoir, M., De Baets, B., & Van de Weghe, N. (2019). \nA method based on the Levenshtein distance metric for the comparison of multiple \nmovement patterns described by matrix sequences of different length. Expert Systems \nwith Applications, 115 , 373 – 385 .\nBostrom, N. (2014). Superintelligence: Paths, dangers, strategies . Oxford University Press . \nBowden, S. C., Petrauskas, V. M., Bardenhagen, F. J., Meade, C. E., & Simpson, L. C. \n(2013). Exploring the dimensionality of digit span. Assessment, 20 (2), 188 – 198 .\nBreit, M., Brunner, M., Molenaar, D., & Preckel, F. (2022). Differentiation hypotheses of \nintelligence: A systematic review of the empirical evidence and an agenda for future \nresearch. Psychological Bulletin, 148 (7 – 8), 518 – 554 .\nBryan, V. M., & Mayer, J. D. (2020). A meta-analysis of the correlations among broad \nintelligences: Understanding their relations. Intelligence, 81 , Article 101469 .\nCarroll, J. B. (2003). The higher-stratum structure of cognitive abilities: Current evidence \nsupports g and about ten broad factors. In H. Nyborg (Ed.), The scientific study of \ngeneral intelligence: Tribute to Arthur R. Jensen (pp. 5 – 21). Pergamon . \nCheung, S. F., & Cheung, S. H. (2023). Manymome: An R package for computing the \nindirect effects, conditional effects, and conditional indirect effects, standardized or \nunstandardized, and their bootstrap confidence intervals, in many (though not all) \nmodels. Behavior Research Methods , 1 – 21 .\nCleveland, W. S., & Devlin, S. J. (1988). Locally weighted regression: An approach to \nregression analysis by local fitting. Journal of the American Statistical Association, 83 \n(403), 596 – 610 .\nCobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., \nTworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training \nverifiers to solve math word problems. arXiv . preprint arXiv:2110.14168 .\nConway, A. R. A., MacNamara, B. N., & Engel de Abreu, P. M. J. (2013). Working \nmemory and intelligence: An overview. In T. P. Alloway, & R. G. Alloway (Eds.), \nWorking memory: The connected intelligence (pp. 13 – 35). Psychology Press . \nCrawford, A. V., Green, S. B., Levy, R., Lo, W. J., Scott, L., Svetina, D., & Thompson, M. S. \n(2010). Evaluation of parallel analysis methods for determining the number of \nfactors. Educational and Psychological Measurement, 70 (6), 885 – 901 .\nDai, M., Li, Y., Gan, S., & Du, F. (2019). The reliability of estimating visual working \nmemory capacity. Scientific Reports, 9 (1), 1155 .\nDamerius, L. A., Burkart, J. M., van Noordwijk, M. A., Haun, D. B., Kosonen, Z. K., \nGaldikas, B. M., … van Schaik, C. P. (2019). General cognitive abilities in orangutans \n( Pongo abelii and Pongo pygmaeus ). Intelligence, 74 , 3 – 11 .\nDeary, I. J., Johnson, W., & Houlihan, L. M. (2009). Genetic foundations of human \nintelligence. Human Genetics, 126 , 215 – 232 .\nDemasi, P., Szwarcfiter, J. L., & Cruz, A. J. (2010, June). A theoretical framework to \nformalize AGI-hard problems. In 3d conference on artificial general intelligence (AGI- \n2010) (pp. 64 – 65). Atlantis Press . \nDetterman, D. K. (2011). A challenge to Watson. Intelligence, 39 (2 – 3), 77 – 78 .\nDetterman, D. K., & Daniel, M. H. (1989). Correlations of mental tests with each other \nand with cognitive variables are highest for low IQ groups. Intelligence, 13 (4), \n349 – 359 .\nDicke, U., & Roth, G. (2016). Neuronal factors determining high intelligence. \nPhilosophical Transactions of the Royal Society, B: Biological Sciences, 371 (1685), \n20150180 .\nDombrowski, S. C., McGill, R. J., Canivez, G. L., & Peterson, C. H. (2019). Investigating \nthe theoretical structure of the differential ability scales — Second edition through \nhierarchical exploratory factor analysis. Journal of Psychoeducational Assessment, 37 \n(1), 91 – 104 .\nDong, G., Yuan, H., Lu, K., Li, C., Xue, M., Liu, D., Wang, W., Yuan, Z., Zhou, C., & \nZhou, J. (2023). How abilities in large language models are affected by supervised \nfine-tuning data composition. arXiv . preprint arXiv:2310.05492 .\nEster, M., Kriegel, H.-P., Sander, J., & Xu, X. (1996). A density-based algorithm for \ndiscovering clusters in large spatial databases with noise. In Proceedings of the 2nd \nInternational Conference on Knowledge Discovery and Data Mining (KDD-96) (pp. \n226 – 231). AAAI Press . \nFloyd, R. G., Evans, J. J., & McGrew, K. S. (2003). Relations between measures of Cattell- \nhorn-Carroll (CHC) cognitive abilities and mathematics achievement across the \nschool-age years. Psychology in the Schools, 40 (2), 155 – 171 .\nFung, W., & Swanson, H. L. (2017). Working memory components that predict word \nproblem solving: Is it merely a function of reading, calculation, and fluid \nintelligence? Memory & Cognition, 45 , 804 – 823 .\nGignac, G. E. (2014a). Dynamic mutualism versus g factor theory: An empirical test. \nIntelligence, 42 , 89 – 97 .\nGignac, G. E. (2014b). Fluid intelligence shares closer to 60% of its variance with \nworking memory capacity and is a better indicator of general intelligence. \nIntelligence, 47 , 122 – 133 .\nGignac, G. E. (2015). Raven ’ s is not a pure measure of general intelligence: Implications \nfor g factor theory and the brief measurement of g . Intelligence, 52 , 71 – 79 .\nGignac, G. E., & Szodorai, E. T. (2024). Defining intelligence: Bridging the gap between \nhuman and artificial perspectives. Intelligence, 104 , Article 101832 .\nGignac, G. E., & Watkins, M. W. (2013). Bifactor modeling and the estimation of model- \nbased reliability in the WAIS-IV. Multivariate Behavioral Research, 48 (5), 639 – 662 .\nGignac, G. E., & Weiss, L. G. (2015). Digit span is (mostly) related linearly to general \nintelligence: Every extra bit of span counts. Psychological Assessment, 27 (4), 1312 .\nGnambs, T. (2014). A meta-analysis of dependability coefficients (test – retest reliabilities) \nfor measures of the big five. Journal of Research in Personality, 52 , 20 – 28 .\nGoldberg, Y. (2016). A primer on neural network models for natural language \nprocessing. Journal of Artificial Intelligence Research, 57 , 345 – 420 .\nGoriounova, N. A., Heyer, D. B., Wilbers, R., Verhoog, M. B., Giugliano, M., Verbist, C., \n… Mansvelder, H. D. (2018). Large and fast human pyramidal neurons associate \nwith intelligence. elife, 7 , Article e41714 .\nGustafsson, J.-E. (2001). On the hierarchical structure of ability and personality. In \nJ. M. Collis, & S. Messick (Eds.), Intelligence and personality: Bridging the gap in theory \nand measurement (pp. 25 – 42). Mahwah, NJ: Erlbaum . \nHagge, P. D. (2023). Find it on a map: Country location identification in a university \ngeography classroom, 2016 – 2022. Journal of Geography, 122 (5), 105 – 114 .\nHendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. \n(2020). Measuring massive multitask language understanding. arXiv . preprint arXiv: \n2009.03300 .\nHerculano-Houzel, S. (2009). The human brain in numbers: A linearly scaled-up primate \nbrain. Frontiers in Human Neuroscience, 3 , 31 .\nHertzog, C., & Schaie, K. W. (1988). Stability and change in adult intelligence: II. \nSimultaneous analysis of longitudinal means and covariance structures. Psychology \nand Aging, 3 (2), 122 .\nHoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., … \nSifre, L. (2022). Training compute-optimal large language models. ArXiv . htt \nps://arxiv.org/abs/2203.15556 .\nHu, X., Chu, L., Pei, J., Liu, W., & Bian, J. (2021). Model complexity of deep learning: A \nsurvey. Knowledge and Information Systems, 63 , 2585 – 2619 .\nHugging Face. (2024). Hugging Face Hub documentation. https://huggingface.co/doc \ns/hub/index .\nImani, S., Du, L., & Shrivastava, H. (2023). Mathprompter: Mathematical reasoning using \nlarge language models. arXiv . preprint arXiv:2303.05398 .\nJackson, D. N. (2003). Multidimensional aptitude battery II (MAB-II) [Measurement \nInstrument] . SIGMA Assessment Systems, Inc . \nJensen, A. R. (1998). The g factor: The science of mental ability . Praeger . \nJensen, A. R. (2006). Clocking the mind: Mental chronometry and individual differences . \nElsevier . \nJensen, A. R., & Weng, L. J. (1994). What is a good g? Intelligence, 18 (3), 231 – 258 .\nJeon, I., & Kim, T. (2023). Distinctive properties of biological neural networks and recent \nadvances in bottom-up approaches toward a better biologically plausible neural \nnetwork. Frontiers in Computational Neuroscience, 17 .\nJohnson, W., & Bouchard, T. J., Jr. (2005). The structure of human intelligence: It is \nverbal, perceptual, and image rotation (VPR), not fluid and crystallized. Intelligence, \n33 (4), 393 – 416 .\nKaiser, H. F., & Rice, J. (1974). Little jiffy, mark IV. Educational and Psychological \nMeasurement, 34 (1), 111 – 117 .\nKazi, S., & Elmahdy, A. (2023, October 17). Top large language models (LLMs): GPT-4, \nLLaMA 2, mistral 7B, ChatGPT, and more [blog post] . Vectara. https://vectara.com/ \nblog/top-large-language-models-llms-gpt-4-llama-gato-bloom-and-when-to-choo \nse-one-over-the-other/ . \nKuratov, Y., Bulatov, A., Anokhin, P., Sorokin, D., Sorokin, A., & Burtsev, M. (2024). In \nsearch of needles in a 10M haystack: Recurrent memory finds what LLMs miss. arXiv . \npreprint arXiv:2402.10790 .\nKvist, A. V., & Gustafsson, J. E. (2008). The relation between fluid intelligence and the \ngeneral factor as a function of cultural background: A test of Cattell ’ s investment \ntheory. Intelligence, 36 (5), 422 – 436 .\nKyllonen, P., & Kell, H. (2017). What is fluid intelligence? Can it be improved? In \nM. Ros ´en, K. Yang Hansen, & U. Wolff (Eds.), Cognitive abilities and educational \noutcomes: A festschrift in honour of Jan-Eric Gustafsson (pp. 15 – 37). Springer \nInternational Publishing/Springer Nature . \nLevenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions, and \nreversals. Soviet Physics Doklady, 10 (8), 707 – 710 .\nLin, Y., Tan, L., Lin, H., Zheng, Z., Pi, R., Zhang, J., … Zhang, T. (2023). Speciality vs \ngenerality: An empirical study on catastrophic forgetting in fine-tuning foundation \nmodels. arXiv . preprint arXiv:2309.06256 .\nLyu, Y., Li, H., Sayagh, M., Jiang, Z. M., & Hassan, A. E. (2021). An empirical study of the \nimpact of data splitting decisions on the performance of AIOps solutions. ACM \nTransactions on Software Engineering and Methodology (TOSEM), 30 (4), 1 – 38 .\nvan der Maas, H. L., Snoek, L., & Stevenson, C. E. (2021). How much intelligence is there \nin artificial intelligence? A 2020 update. Intelligence, 87 , Article 101548 .\nMcLean, S., Read, G. J., Thompson, J., Baber, C., Stanton, N. A., & Salmon, P. M. (2023). \nThe risks associated with artificial general intelligence: A systematic review. Journal \nof Experimental & Theoretical Artificial Intelligence, 35 (5), 649 – 663 .\nMitchell, M. (2019). Artificial intelligence: A guide for thinking humans (1st ed.). Farrar, \nStraus and Giroux . \nMontoya, A. K., & Edwards, M. C. (2021). The poor fit of model fit for selecting number \nof factors in exploratory factor analysis for scale evaluation. Educational and \nPsychological Measurement, 81 (3), 413 – 440 .\nNettelbeck, T., & Lally, M. (1976). Inspection time and measured intelligence. British \nJournal of Psychology, 67 (1), 17 – 22 .\nNeubauer, A. C. (2021). The future of intelligence research in the coming age of artificial \nintelligence – With a special consideration of the philosophical movements of trans- \nand posthumanism. Intelligence, 87 , 101563 .\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n10 \nNoble, S., Scheinost, D., & Constable, R. T. (2019). A decade of test-retest reliability of \nfunctional connectivity: A systematic review and meta-analysis. Neuroimage, 203 , \nArticle 116157 .\nNunnally, J. C., & Bernstein, I. H. (1994). Psychometric theory (3rd ed.). McGraw-Hill . \nObaid, O. I. (2023). From machine learning to artificial general intelligence: A roadmap \nand implications. Mesopotamian Journal of Big Data, 2023 , 81 – 91 .\nOosterwijk, P. R., van der Ark, L. A., & Sijtsma, K. (2019). Using confidence intervals for \nassessing reliability of real tests. Assessment, 26 (7), 1207 – 1216 .\nOrrù, G., Piarulli, A., Conversano, C., & Gemignani, A. (2023). Human-like problem- \nsolving abilities in large language models using ChatGPT. Frontiers in Artificial \nIntelligence, 6 , 1199350 .\nOwen, D. (2024). How predictable is language model benchmark performance? arXiv . \npreprint arXiv:2401.04757. Retrieved from https://arxiv.org/abs/2401.04757 .\nPanas, D., Seth, S., & Belle, V. (2024). Can large language models put 2 and 2 together? \nProbing for entailed arithmetical relationships. arXiv . preprint arXiv:2404.19432 .\nPastrana, C. I., Gonzalez, F. J. N., Inostroza, M. G. P., Arbulu, A. A., Bermejo, J. V. D., & \nAguilera, M. J. R. (2022). Study of variability of cognitive performance in captive \nfallow deer ( Dama dama ) through g and c factors. Journal of Veterinary Behavior, 47 , \n70 – 85 .\nQian, J., Wang, H., Li, Z., Li, S., & Yan, X. (2022). Limitations of language models in \narithmetic and symbolic induction. arXiv . preprint arXiv:2208.05051 .\nRaven, J. (2000). The Raven ’ s progressive matrices: Change and stability over culture \nand time. Cognitive Psychology, 41 (1), 1 – 48 .\nRayhan, A., Rayhan, R., & Rayhan, S. (2023). Artificial general intelligence: Roadmap to \nachieving human-level capabilities .\nRosseel, Y. (2012). Lavaan: An R package for structural equation modeling. Journal of \nStatistical Software, 48 (2), 1 – 36. https://doi.org/10.18637/jss.v048.i02\nRoth, G., & Dicke, U. (2005). Evolution of the brain and intelligence. Trends in Cognitive \nSciences, 9 (5), 250 – 257 .\nSakaguchi, K., Le Bras, R., Bhagavatula, C., & Choi, Y. (2021). Winogrande: An \nadversarial Winograd Schema challenge at scale. Communications of the ACM, 64 (9), \n99 – 106. Retrieved from https://arxiv.org/abs/1907.10641 .\nSchipolowski, S., Wilhelm, O., & Schroeders, U. (2014). On the nature of crystallized \nintelligence: The relationship between verbal ability and factual knowledge. \nIntelligence, 46 , 156 – 168 .\nSchneider, W. J., & McGrew, K. S. (2018). The Cattell – Horn – Carroll theory of cognitive \nabilities. In D. P. Flanagan, & E. M. McDonough (Eds.), Contemporary intellectual \nassessment: Theories, tests, and issues (4th ed., pp. 73 – 163). The Guilford Press . \nSternberg, R. J. (2011). Intelligence and giftedness. In R. J. Sternberg, L. Jarvin, & \nE. L. Grigorenko (Eds.), Explorations in giftedness (pp. 54 – 81). Cambridge University \nPress . \nTyen, G., Mansoor, H., Chen, P., Mak, T., & C ˘arbune, V. (2023). LLMs cannot find \nreasoning errors, but can correct them! arXiv . preprint arXiv:2311.08516 .\nUrrutia, F., & Araya, R. (2024). Who ’ s the best detective? Large language models vs. \ntraditional machine learning in detecting incoherent fourth grade math answers. \nJournal of Educational Computing Research, 61 (8), 187 – 218 .\nVafa, K., Rambachan, A., & Mullainathan, S. (2024). Do large language models perform \nthe way people expect? Measuring the human generalization function. arXiv . \npreprint arXiv:2406.01382 .\nVandenberg, S. G., & Kuse, A. R. (1978). Mental rotations, a group test of three- \ndimensional spatial visualization. Perceptual and Motor Skills, 47 (2), 599 – 604 .\nWalker, D. L., Palermo, R., Callis, Z., & Gignac, G. E. (2023). The association between \nintelligence and face processing abilities: A conceptual and meta-analytic review. \nIntelligence, 96 , Article 101718 .\nWarne, R. T., & Burningham, C. (2019). Spearman ’ s g found in 31 non-Western nations: \nStrong evidence that g is a universal phenomenon. Psychological Bulletin, 145 (3), \n237 – 272 .\nWechsler, D. (1981). Wechsler Adult Intelligence Scale-Revised . Psychological Corporation . \nWechsler, D. (2008a). Wechsler Adult Intelligence Scale (4th ed.). Pearson . \nWechsler, D. (2008b). WAIS-IV: Wechsler adult intelligence scale — Fourth edition: Technical \nand interpretive manual . Pearson . \nWelty, C., Paritosh, P., & Aroyo, L. (2019). Metrology for AI: From benchmarks to \ninstruments. arXiv . preprint arXiv:1911.01875 .\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis . New York: Springer- \nVerlag . \nXu, Y., Liu, X., Liu, X., Hou, Z., Li, Y., Zhang, X., … Dong, Y. (2024). ChatGLM-Math: \nImproving math problem-solving in large language models with a self-critique \npipeline. arXiv . preprint arXiv:2404.02893 .\nYuan, Z., Yuan, H., Tan, C., Wang, W., & Huang, S. (2023). How well do large language \nmodels perform in arithmetic tasks? arXiv . preprint arXiv:2304.02015 .\nZellers, R., Holtzman, A., Bisk, Y., Farhadi, A., & Choi, Y. (2019). Hellaswag: Can a \nmachine really finish your sentence? arXiv . preprint arXiv:1905.07830 .\nZhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., … Wen, J. (2023). A survey of \nlarge language models. ArXiv . https://arxiv.org/abs/2303.18223 .\nD. Ili ´c and G.E. Gignac                                                                                                                                                                                                                        Intelligence 106 (2024) 101858 \n11 ",
  "topic": "Psychology",
  "concepts": [
    {
      "name": "Psychology",
      "score": 0.6552907824516296
    },
    {
      "name": "Cognition",
      "score": 0.5996925830841064
    },
    {
      "name": "Human intelligence",
      "score": 0.5567935705184937
    },
    {
      "name": "Factor (programming language)",
      "score": 0.5379332900047302
    },
    {
      "name": "Fluid and crystallized intelligence",
      "score": 0.5277206301689148
    },
    {
      "name": "Emotional intelligence",
      "score": 0.5274824500083923
    },
    {
      "name": "Test (biology)",
      "score": 0.5133644938468933
    },
    {
      "name": "Cognitive psychology",
      "score": 0.5109421610832214
    },
    {
      "name": "Reading (process)",
      "score": 0.49072444438934326
    },
    {
      "name": "Social psychology",
      "score": 0.4589501619338989
    },
    {
      "name": "Developmental psychology",
      "score": 0.4420573115348816
    },
    {
      "name": "Sample (material)",
      "score": 0.44185927510261536
    },
    {
      "name": "Verbal reasoning",
      "score": 0.4309224486351013
    },
    {
      "name": "Expression (computer science)",
      "score": 0.4128096103668213
    },
    {
      "name": "Fluid intelligence",
      "score": 0.24410581588745117
    },
    {
      "name": "Linguistics",
      "score": 0.14662855863571167
    },
    {
      "name": "Computer science",
      "score": 0.14496171474456787
    },
    {
      "name": "Working memory",
      "score": 0.13990283012390137
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Neuroscience",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Chromatography",
      "score": 0.0
    }
  ],
  "institutions": []
}