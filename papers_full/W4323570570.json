{
  "title": "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting",
  "url": "https://openalex.org/W4323570570",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2352542969",
      "name": "Dang, Hai",
      "affiliations": [
        "University of Bayreuth"
      ]
    },
    {
      "id": "https://openalex.org/A4297682192",
      "name": "Goller, Sven",
      "affiliations": [
        "University of Bayreuth"
      ]
    },
    {
      "id": "https://openalex.org/A4289609730",
      "name": "Lehmann, Florian",
      "affiliations": [
        "University of Bayreuth"
      ]
    },
    {
      "id": "https://openalex.org/A3187725872",
      "name": "Buschek, Daniel",
      "affiliations": [
        "University of Bayreuth"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2996952890",
    "https://openalex.org/W1951724000",
    "https://openalex.org/W4289597535",
    "https://openalex.org/W3123978464",
    "https://openalex.org/W2947160092",
    "https://openalex.org/W4225012671",
    "https://openalex.org/W1550321890",
    "https://openalex.org/W2051780479",
    "https://openalex.org/W4285164582",
    "https://openalex.org/W3206079177",
    "https://openalex.org/W2148723390",
    "https://openalex.org/W2113893685",
    "https://openalex.org/W2402790201",
    "https://openalex.org/W3154903254",
    "https://openalex.org/W2164483209",
    "https://openalex.org/W3044438666",
    "https://openalex.org/W2373570000",
    "https://openalex.org/W2774486220",
    "https://openalex.org/W4220747294",
    "https://openalex.org/W4226125322",
    "https://openalex.org/W1982451263",
    "https://openalex.org/W4287249924",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2401452835",
    "https://openalex.org/W4224035735",
    "https://openalex.org/W2236262502",
    "https://openalex.org/W4293138840",
    "https://openalex.org/W3153427360",
    "https://openalex.org/W4213451626",
    "https://openalex.org/W4301393026",
    "https://openalex.org/W1930404901",
    "https://openalex.org/W2054689358",
    "https://openalex.org/W3203321135",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W3162821954",
    "https://openalex.org/W2329223578",
    "https://openalex.org/W4300126213",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W4300807552",
    "https://openalex.org/W3176456866",
    "https://openalex.org/W4225080353",
    "https://openalex.org/W2964074081",
    "https://openalex.org/W4225165463",
    "https://openalex.org/W4297801719",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3155340931",
    "https://openalex.org/W2582743722",
    "https://openalex.org/W3165482393",
    "https://openalex.org/W2606712314",
    "https://openalex.org/W4308900200"
  ],
  "abstract": "We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. \"Once upon a time, I saw a fox...\"), and (2) non-diegetic prompts (external, e.g. \"Write about the adventures of the fox.\"). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.",
  "full_text": "Choice Over Control: How Users Write with Large Language\nModels using Diegetic and Non-Diegetic Prompting\nHai Dang\nhai.dang@uni-bayreuth.de\nUniversity of Bayreuth\nBayreuth, Bavaria, Germany\nSven Goller\nsven.goller@uni-bayreuth.de\nUniversity of Bayreuth\nBayreuth, Bavaria, Germany\nFlorian Lehmann\nflorian.lehmann@uni-bayreuth.de\nUniversity of Bayreuth\nBayreuth, Bavaria, Germany\nDaniel Buschek\ndaniel.buschek@uni-bayreuth.de\nUniversity of Bayreuth\nBayreuth, Bavaria, Germany\nS\ni\nn\ng\nl\ne\n \nS\nu\ng\ng\ne\ns\nt\ni\no\nn\ns\nM\nu\nl\nt\ni\np\nl\ne\n \nS\nu\ng\ng\ne\ns\nt\ni\no\nn\ns\nO\nn\nl\ny\n \nd\ni\ne\ng\ne\nt\ni\nc\n \np\nr\no\nm\np\nt\ns\nU\ns\ne\nr\ns\n \ni\nn\nf\nl\nu\ne\nn\nc\ne\n \ns\nu\ng\ng\ne\ns\nt\ni\no\nn\ns\n \nw\ni\nt\nh\n \nt\nh\ne\ni\nr\n \nt\ne\nx\nt\n \nw\nr\ni\nt\nt\ne\nn\n \ns\no\n \nf\na\nr\n \n.\n.\n.\n.\n.\n.\n \na\nn\nd\n \nc\na\nn\n \no\np\nt\ni\no\nn\na\nl\nl\ny\n \nw\nr\ni\nt\ne\n \ne\nx\np\nl\ni\nc\ni\nt\n \ni\nn\ns\nt\nr\nu\nc\nt\ni\no\nn\ns\n \nt\no\n \nt\nh\ne\n \nA\nI\nA\nl\ns\no\n \nw\ni\nt\nh\n \nn\no\nn\n-\nd\ni\ne\ng\ne\nt\ni\nc\n \np\nr\no\nm\np\nt\ns\nFigure 1: Overview of our four UI variants, showing the user‚Äôs written text (black font, i.e. a diegetic prompt), the suggestions\n(text highlighted in green, and options in the list), and a popup text box that allows users to input an instruction as a zero-shot\nprompt to the system (i.e. a non-diegetic prompt).\nABSTRACT\nWe propose a conceptual perspective on prompts for Large Lan-\nguage Models (LLMs) that distinguishes between (1) diegetic prompts\n(part of the narrative, e.g. ‚ÄúOnce upon a time, I saw a fox ... ‚Äù ), and\n(2) non-diegetic prompts (external, e.g. ‚ÄúWrite about the adventures\nof the fox. ‚Äù). With this lens, we study how 129 crowd workers on\nProlific write short texts with different user interfaces (1 vs 3 sug-\ngestions, with/out non-diegetic prompts; implemented with GPT-3):\nWhen the interface offered multiple suggestions and provided an\noption for non-diegetic prompting, participants preferred choosing\nfrom multiple suggestions over controlling them via non-diegetic\nprompts. When participants provided non-diegetic prompts it was\nto ask for inspiration, topics or facts. Single suggestions in particu-\nlar were guided both with diegetic and non-diegetic information.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\n¬© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9421-5/23/04. . . $15.00\nhttps://doi.org/10.1145/3544548.3580969\nThis work informs human-AI interaction with generative models\nby revealing that (1) writing non-diegetic prompts requires effort,\n(2) people combine diegetic and non-diegetic prompting, and (3)\nthey use their draft (i.e. diegetic information) and suggestion timing\nto strategically guide LLMs.\nCCS CONCEPTS\n‚Ä¢ Human-centered computing ‚ÜíEmpirical studies in HCI ;\nText input; ‚Ä¢ Computing methodologies ‚ÜíNatural language\ngeneration.\nKEYWORDS\nLarge language models, Co-creative systems, Human-AI collabora-\ntion, User-centric natural language generation\nACM Reference Format:\nHai Dang, Sven Goller, Florian Lehmann, and Daniel Buschek. 2023. Choice\nOver Control: How Users Write with Large Language Models using Diegetic\nand Non-Diegetic Prompting. In CHI ‚Äô23: ACM Conference on Human Factors\nin Computing Systems, April 23‚ÄìApril 28, 2023, Hamburg, Germany. ACM,\nNew York, NY, USA, 17 pages. https://doi.org/10.1145/3544548.3580969\narXiv:2303.03199v1  [cs.HC]  6 Mar 2023\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\n1 INTRODUCTION\nWhen writing collaboratively, people coordinate and inspire each\nother through what they write in the draft itself and through com-\nmunication beyond it. In this paper, we examine related mechanisms\nfor human-AI co-writing.\nInput text provided to a Large Language Model (LLM) as a basis\nfor generating text is referred to as a ‚Äúprompt‚Äù. Providing a few\nexamples of inputs and outputs in such a text prompt can help\nthe model solve a task [5, 50]. This is called few-shot learning. For\nexample, an LLM can be prompted to translate from English to\nFrench with a few examples of English sentences and correspond-\ning translations, followed by the English sentence to be translated.\nBy completing this text the LLM then (ideally) translates that sen-\ntence. This affords user control: Users can define tasks and del-\negate them to an LLM ad-hoc. Going further, zero-shot learning\nprompts the LLM with an instruction without examples (e.g. Trans-\nlate ‚ÄôThe weather is nice‚Äô to French ). This is a harder task but from\na Human-Computer Interaction (HCI) point of view it frees users\nfrom thinking of specific examples when instructing the AI system.\nWe introduce the terms diegetic prompting and non-diegetic\nprompting1 to frame a new perspective on how users influence\nan LLM in their writing process. A diegetic prompt is part of the\nusers‚Äô narrative. For example, when the user writes about a vacation\nin South East Asia, the story as written so far forms the diegetic\nprompt. In contrast, a non-diegetic prompt is an explicit instruction\nto the LLM (e.g. ‚Äúsuggest activities to do in Singapore‚Äù). Crucially,\nthis instruction is not a part of the resulting document (e.g. travel\nblog); it only serves to guide the LLM‚Äôs text generation.\nTechnically, there may not be a difference between diegetic and\nnon-diegetic prompts for the LLM ‚Äì both types are received by\nthe model as text input strings. However, from an HCI perspective,\nthis distinction allows us to identify patterns in the perception and\ninteraction of users writing with LLMs. With this new distinction, in\nthis paper we address the research question:How do users write with\nLarge Language Models using diegetic and non-diegetic prompting?\nConcretely, we propose and compare four UI variants (Figure 1)\nthat allow people to write with these types of prompts, plus a\nbaseline UI without suggestions. We conducted a remote study\nwith 129 crowd workers on Prolific, each writing five stories. We\ninvestigate the influence of two independent variables on users‚Äô\nwriting behavior, namely Instruction with two levels (ùëñùëõùëú , ùëñùë¶ùëíùë† )\nand Number of suggestions with three levels (baseline: ùë†0; ùë†1, ùë†3).\nUsers overall prefer choosing from multiple suggestions over\ncontrolling them via non-diegetic prompts. They use non-diegetic\nprompts to ask the LLM for inspiration, topics or facts. Non-diegetic\nprompts increase effort, for learning how to formulate them and\nswitching between diegetic and non-diegetic writing. Users also\nprefer the UI with multiple suggestions over seeing single ones, yet\nallowing them to provide non-diegetic prompts reduces the gap in\nacceptance rates by boosting it for the UI with single suggestions.\nMoreover, single suggestions are triggered later in sentences, and\nless frequently at transition words and to start sentences. Together\nwith people‚Äôs comments, this indicates that writers consider diegetic\ninformation to guide LLMs. We discuss implications for LLMs and\ninteraction design.\n1https://www.merriam-webster.com/dictionary/diegetic, last accessed March 7, 2023\nWe contribute a new conceptual lens on prompting that distin-\nguishes diegetic and non-diegetic ways in which users can influence\nLLMs, and a new UI design to combine text continuation sugges-\ntions with zero-shot prompt input.\n2 RELATED WORK\nWe relate our work to prompting in Natural Language Processing\n(NLP) and writing interfaces in Human-Computer Interaction (HCI).\nMoreover, we present our proposed concept of diegetic and non-\ndiegetic prompting by locating it in existing user interfaces for\nwriting and prompting.\n2.1 Prompting in Large Language Models\nLanguage models are trained to predict the next word given the pre-\nvious words in the text. One primary advantage of Deep Learning-\nbased LLMs is that they can solve several natural language process-\ning tasks without being specifically trained on those. This can be\ndone via text prompts written in natural language [5]. Zhao et al.\n[50] show that providing a few examples of inputs and outputs can\nhelp to steer the model. However, optimizing prompts is not trivial\nand requires extensive experience [28].\n2.1.1 Prompt Engineering. Related work in prompt engineering has\nproposed several methods to improve prompts: For example, para-\nphrasing prompts can lead to better model outputs [20, 23, 27, 49].\nAnother approach involves constructing prompt templates to in-\ncrease the accuracy for probing knowlege [33], for translation tasks\n[5], or for text classification tasks [39]. However, optimized prompts\nconstructed in the process of prompt engineering are usually not\nmeant to be consumed by humans; rather, they are designed for\nLLMs to most effectively perform a task [ 28]. In contrast, in our\nstudy, we explore how non-expert users write and use (zero-shot)\nprompts when writing with an LLM.\n2.1.2 Prompting Interfaces. Several interactive systems have been\nproposed to enable users to work more effectively with prompts:\nFor example, AI Chains by Wu et al. [47] allows users to combine\nmultiple prompt primitives and their outputs to form a chain of\nprompts that can solve complex language processing tasks. In an-\nother study, they introduce an interface for visually programming\nthese chains [ 46]. Similarily, PromptMaker [22] allows users to\nprototype new AI functionalities using language prompts. Stro-\nbelt et al. [42] developed a prompt programming environment to\nallow users to experiment with prompt variations and visualize\nprompt performance. Story Centaur by Swanson et al. [43] supports\nusers in creating few-shot examples for creative writing. Using our\nterminology, these projects focused on non-diegetic prompts as a\nmain output of interaction. In contrast, we integrate non-diegetic\nprompts into a text editor, with a focus on writing. Concretely, we\ncombine a UI for phrase suggestions with a UI for zero-shot prompt\ninputs to an LLM, and analyze how users make use of these during\ntheir writing.\n2.2 Writing Interfaces for LLMs\nHere we give a brief overview of key design factors for user inter-\nfaces that involve LLMs and text generation.\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\n2.2.1 Scope of Suggestions. Earlier work mainly focused on single\nword suggestions [11, 12, 18, 34]. This scope favours performance\nmetrics, such as reducing key-strokes, while longer phrase sugges-\ntions [6, 26, 37] are perceived more as new ideas for writing [ 1].\nWe focus on such phrase suggestions in this paper.\n2.2.2 Display of Suggestions. Single text suggestions can be shown\ninline [4, 8, 17, 48], whereas multiple suggestions are shown as pop-\nup lists of about three to six entries [6, 26]. Beyond that, Singh et al.\n[41] evaluated how writers use suggestions displayed as images and\nsound. Moreover, Bhat et al. [4] used a a pop-up text box to show\nsuggestions for insertions in the middle of sentences. We follow\nthese design choices (Figure 1) and show single suggestions inline\nand multiple ones in a pop-up list. We add a pop-up text field for\nentering non-diegetic prompts.\n2.2.3 Implicit vs. Explicit Trigger. In writing interfaces, suggestions\ncan be triggered explicitly or implicitly. Related work showed sug-\ngestions automatically after short inactivity [ 4, 6] or gated by a\nutility function [24]. Alternatively, recent work has also explored\ndesigns in which users explicitly request suggestions with a hotkey\n[7, 17, 26, 41, 48]. We also use this design with an explicit request\nkey to better understand how and when users request suggestions.\n2.3 Diegetic and Non-Diegetic Prompting in\nExisting Writing Interfaces\nHere we apply the proposed lens to analyse how existing systems\nuse diegetic and non-diegetic information in their writing inter-\nfaces. Traditionally, systems mainly use diegetic information, that is,\nthey predict text based (only) on the preceding text [11, 12, 18, 34].\nSome also added other information (e.g. hand posture, body move-\nment [15, 16]). These show early examples of non-diegetic input to\nthe language model. In this work, we focus on textual diegetic and\nnon-diegetic information.\nFrom a technical perspective, for recent systems that use LLMs to\ngenerate text suggestions, there might be no difference between the\nuser‚Äôs text draft (i.e. diegetic text) and other text inputs to the lan-\nguage model (e.g. instructions to the model, i.e. non-diegetic text).\nTherefore, systems in which the UI did not afford text prompts ex-\nplicitly made the implicit choice of only using diegetic information\nas their input to the LLM [6, 7, 26, 41].\nIn contrast, writing interfaces that indeed allow users to explic-\nitly enter prompts often use a mix of diegetic and non-diegetic\ninformation. Gero et al. [14] propose ‚Äúsparks‚Äù, i.e. sentences gen-\nerated from LLMs to inspire new ideas for scientific writing. The\nuser-provided prompts to generate these sparks are not part of\nthe final outcome text, thus they are non-diegetic. Similarly, other\nsystems (e.g. Wordcraft [48], LaMPost [17]) allowed users to select\na part of the written text and modify it via predefined functionality\n(internally these functionalities also use prompting: e.g. a button for\n‚Äúrewrite selection‚Äù + text entry field for prompt). The selected text\nin this example is diegetic information while the prompt template\nand user-provided prompts are non-diegetic information. Related,\nwe include the entire user written text draft as diegetic information\nand allow users to provide non-diegetic custom text prompts to\nfurther guide the LLM.\n3 INTERACTION CONCEPT\nHere we describe our UI and interaction concept (also see Figure 1\nand Figure 8): It closely integrates diegetic and non-diegetic prompt-\ning in the same UI; users can use both types without having to take\nthe hands off the keyboard.\n3.1 Inline (Single) Suggestions (Figure 1 top\nrow)\nWhen a user requests a new suggestion ( TAB ) a preview of the\nsuggestion appears after the current caret position in the text ed-\nitor. Users can press TAB repeatedly to get new suggestions. The\nsuggestion preview is visually highlighted in green to indicate that\nit is not part of the text yet. We decided for this design instead of\ne.g. a greyed out suggestion text (as e.g. used in Google‚Äôs Smart\nCompose [8]) because pilot tests showed that grey text can be diffi-\ncult to read for some people and makes readability more dependant\non screen brightness settings, which we cannot control in an online\nstudy. If the suggestion is accepted (ENTER ) the preview style (green\nbackground) is removed and the suggested text becomes part of\nthe text document. Alternatively, the user can cancel the current\nsuggestion preview by pressing ESC or by continuing to type with-\nout confirming the suggestion. When the suggestion is cancelled\nin one of these ways, the previewed suggestion is removed from\nthe text editor.\n3.2 Multiple Suggestions (Figure 1 bottom row)\nOur system follows current practices for multiple suggestions (see\nSection 2.2) and shows each phrase suggestion as a separate item\nin a list of three. Again, users can press TAB to get suggestions (and\nrepeatedly to get new ones). Users can use the ‚ÜëUP/ ‚ÜìDOWN keys to\nnavigate this list and confirm a suggestion with ENTER . Selection\nvia mouse is also possible.\n3.3 Pop-up Textbox for Non-Diegetic Prompts\n(Figure 1 right column)\nIn the study, we described non-diegetic prompts as ‚Äúinstructions\nto the AI‚Äù. Users can request suggestions with TAB as before. Ad-\nditionally, they can enter an instruction by typing in a popup box\nthat appears above the caret position. Thus, users have the option\nto input an instruction but are not forced to do so to request sug-\ngestions. Input focus is automatically switched from the text editor\nto the pop-up textbox when requesting suggestions so users can\ntype instructions directly after pressing TAB . Users can submit the\ninstruction with TAB or Enter . They can then press Enter again to\naccept the selected suggestion. Alternatively, they can revise their\ninstruction to update the suggestions.\n4 PROTOTYPE IMPLEMENTATION\nHere we provide details about the web prototype used in the study.\nFor screenshots, see Figure 1 and Appendix A.\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\n4.1 Web System\nThe prototype was implemented with ReactJS 2 and CKEditor53.\nEach suggestion request from the client was passed to and parsed\nby a backend server which used FastApi4 as a lightweight webserver.\nThe server forwarded these requests to OpenAI‚Äôs text-davinci-edit-\n001 model along with the entire written text as well as an instruction\nfor the suggestion model (see Section 3). We chose this model and\nAPI because it is reportedly trained specifically to take in a given\ntext as well as a (separate) instruction relating to the text.\n4.2 Language Model Prompts\nWe used two default prompt prefixes to retrieve sentence comple-\ntions from GPT-3 (text-davinci-edit-001): (1) Complete the sentence.\n(2) Complete the sentence and <user_instruction>. The system auto-\nmatically used (1) when there was no option for the participants\nto provide explicit instructions to the AI, or when users did not\nprovide an instruction. When they did write instructions, these\nwere appended to (2). For instance, if the user wrote the instruction:\n‚Äôsuggest colors‚Äô, the resulting full instruction sent to the model was:\n‚ÄôComplete the sentence and suggest colors‚Äô. During the pre-study\nwe experimented with other default instructions such as: ‚ÄôContinue‚Äô\nor ‚ÄôContinue the text‚Äô, as well as more complex ones, but found\nthem to be less suitable (e.g. produced longer text or less consistent).\nWe applied a post processing step to trim the model‚Äôs output and\ndisplay only the generated continuation.\n4.3 Information Box\nFor the user study, we implemented an information box (Figure 8\nin Appendix A) which explains the different features of the current\ntext editor setup. Concretely, it showed an image that demonstrates\nthe usage of the UI as well as an explanation of the available action\nkeys.\n5 METHOD\nWe used the following methods, in line with related studies on\nhuman-AI writing (e.g. cf. [6, 26]).\n5.1 Questionnaires\nTo assess participants‚Äô backgrounds, an initial questionnaire asked\nabout demographics and experience with writing features and lan-\nguage models. Participants also filled in one questionnaire after\neach UI variant (see Figure 3) to give subjective feedback per UI. To\nextend on this with overall feedback, a final questionnaire asked\nfor (optional) open comments on changes to the system and experi-\nences with suggestions and instructions.\n5.2 Interaction Logging\nTo analyze interaction behaviour in detail, we logged interaction\nevents, i.e. key and mouse events, during the writing tasks (see Ap-\npendix A). Each event included atimestamp, task id, and the current\ntext in the editor. Depending on the event it included information\n2https://reactjs.org/, last accessed March 7, 2023\n3https://ckeditor.com, last accessed March 7, 2023\n4https://fastapi.tiangolo.com, last accessed March 7, 2023\nsuch as the suggestion trigger position in the text or the instruction\nto the AI.\n5.3 Coding of Open Questions\nWe analysed the open comments from the final questionnaire in an\napproach adopting coding steps from Grounded Theory [10, 29],\nin order to identify and report on the emerging aspects: First, two\nresearchers inductively proposed codes for the data of 20 people.\nThey then compared and clustered these codes to develop a common\ncodebook. Then, they coded the first 20 plus 32 more participants\nand checked each other‚Äôs codings, with slight adjustments to the\ncodebook. Finally, one researcher coded the remaining data and\nanother one checked this coding. Throughout the process, disagree-\nments were resolved via discussion.\n5.4 Evaluation of User Written Text\nWe used LanguageTool5, a multilingual grammar and spell-checker,\nto count the number of grammar and spelling mistakes. To evaluate\nthe degree to which participants engaged with the selected writing\nprompts during the user study (cf. Section 6), three researchers\nindependently reviewed the stories and provided comments on\ntheir connection to the prompts. Finally, one researcher reviewed\nall comments to ensure consistency.\n6 USER STUDY\n6.1 Study Design\nOur study uses a within-subject design with two independent vari-\nables: The Number of (parallel) suggestions with two levels: one\nand three suggestions (ùë†1, ùë†3); and the opportunity forInstruction\nwith two levels ( ùëñùëõùëú , ùëñùë¶ùëíùë† ). This results in four UI variants with\nsuggestions. In addition, we included a baseline UI without any sug-\ngestions (ùë†0). The order of these five UIs was fully counterbalanced.\nAs dependent variables we included interaction measures as well\nas questionnaire data.\n6.2 Participants\nWe conducted a pre-study with 6 participants with direct disussions\nfor rich feedback, followed by our main study with 129 participants\n(M=71, F=57, NB=1). We recruited on Prolific6 and screened partici-\npants for written and spoken fluency in English, as well as access\nto a computer with a keyboard. Participants reported ages ranged\nfrom 18 to 70 with a median age of 32. Following the platform\nrecommendations, participants were compensated with 8 ¬£/h.\n6.3 Procedure\nThe study started with a description page, including information\nabout the collected data and GDPR, in line with our institute‚Äôs\nregulations. After giving their consent, participants were directed to\na page with an overview of the procedure and involved UI variants.\nFollowing this, people were guided through the five writing tasks\nin a counterbalanced order, and then to the final questionnaire. The\nstudy had an estimated duration of 45 minutes (actual mean was\n45 minutes and 41 seconds).\n5https://languagetool.org, last accessed March 7, 2023\n6https://www.prolific.co/, last accessed March 7, 2023\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\n6.3.1 Topic Selection. For each task, participants first selected\na writing topic. Repeated selections were allowed, as in related\nwork [26], yet we asked them to choose at least two different topics\noverall. The topic order was also randomized and shown one at a\ntime to encourage variety in the topic choices overall.\nGero et al. [13] suggested three tasks for writing support tools,\nincluding story writing and argumentative essay writing. We thus\nselected five topics for creative writing7 and five topics for argu-\nmentative writing from the same source8 as Lee et al. [26].\n6.3.2 Writing Task. Participants were told to write about the pre-\nviously selected topic for five minutes and finish their text with\na clear ending. The description encouraged to try out all features\nbut also to write their own text. A timer was shown below the text\neditor. It was mentioned that the timer was not a hard cut-off, but\nserved as a reminder of when to finish the task. We set a minimum\ntime of 15 seconds before participants could submit their story but\npeople stayed close to the five minutes anyway (see Section 7.2).\nPeople filled in a questionnaire after each task (Section 5.1).\n7 RESULTS\nHere we present our study results. For statistical testing we use\nR [35], concretely, (generalised) linear mixed-effects models (LMMs\nwith the packages lme4 [2], lmerTest [25]). The models account for\nparticipants‚Äô individual differences, as well as for the type of their\nchosen topics (creative story writing, argumentative writing), via\nrandom intercepts. As fixed effects, the models have Instruction\nand Number. Moreover, we use the R package multgee [44] to anal-\nyse the Likert results (i.e. ordinal data) with Generalized Estimating\nEquations (GEEs). We report significance at p < 0.05.\nWe define asuggestion session as continuous interaction with sug-\ngestions, from requesting them until cancellation or acceptance (e.g.\na session might involve three subsequent ‚Äútab‚Äù presses to browse\nsuggestions). Participants triggered 3097 suggestion sessions. The\nmean in tasks with suggestions enabled was 6.47 (SD 4.00), compa-\nrable to related work [26].\n7.1 Suggestion Acceptance\nWe define the acceptance rate as the number of accepted suggestions\ndivided by the number of triggered suggestion sessions. We found\nconsiderable differences between the UIs (Means: ùë†1=0.55, ùë†3=0.74,\nùëñùëõùëú =0.59, ùëñùë¶ùëíùë† =0.69). The grand mean acceptance rate was 0.64 (SD\n0.29). The mean for suggestion requests with a written instruction\nwas in line with this (0.64, SD: 0.33). We fitted a generalised LMM\non the acceptances as binomial data (i.e. for each shown suggestion\nwe logged if it was accepted or not), summarized in Table 1 (row 1).\nFigure 2 (top left) shows the descriptive data. In summary, showing\none suggestion (instead of three) significantly decreased the chance\nof acceptance, yet enabling users to write instructions significantly\nreduced this gap by increasing their acceptance (Mean rate of 0.45\nfor ùë†1 without instructions vs 0.65 with them).\n7https://www.reddit.com/r/WritingPrompts, last accessed March 7, 2023\n8https://www.nytimes.com/2021/02/01/learning/300-questions-and-images-to-\ninspire-argument-writing.html, last accessed March 7, 2023\n7.2 Task Completion Time\nWe measured task time from starting the task to submitting it\n(Means: ùë†0=281, ùë†1=305, ùë†3=306, ùëñùëõùëú =303, ùëñùë¶ùëíùë† =309). As a fixed writ-\ning time was given, we do not expect large differences here. Indeed,\nan LMM fitted on this data for the suggestion UIs did not reveal\nsignificant effects (Table 1, row 2). Another such model compared\nthe suggestion UIs against the baseline (Table 1, row 3): Here we\nfound that writing with three suggestions took significantly longer\nthan without suggestions. This is in line with the descriptive picture\nin Figure 2 (top center): Participants followed the task description\nof writing for five minutes, and writing with the suggestion UIs\ntook slightly longer.\n7.3 Text Length\nIn total, submitted texts contained 87,640 words, including text\nfrom accepted suggestions. The grand mean number of words per\ntext was 134 words (SD 54). We fitted a generalised (Poisson) LMM\non the word count data to compare the four tasks with suggestions\n(Table 1, row 4), and another such model to compare the suggestion\nUIs against the baseline without suggestions (Table 1, row 5). The\nresults match the descriptive pattern visible in Figure 2 (top right):\nIn summary, texts are significantly shorter when writing with sin-\ngle suggestions or with a UI allowing for instructions. However,\nwriting with multiple suggestions leads to significantly longer texts.\nThese differences are rather small, about 6-10 words (Means:ùë†0=136,\nùë†1=130, ùë†3=140, ùëñùëõùëú =138, ùëñùë¶ùëíùë† =131).\n7.4 Moments of Suggestion Requests\nWe analysed at which moments participants requested suggestions.\n7.4.1 After Sentence vs Mid-sentence. We analysed how often sug-\ngestions started a sentence (e.g. ‚ÄúHello, world! [tab]‚Äù) vs in the\nmiddle (e.g. ‚ÄúHello world, how[tab]‚Äù). We fitted a generalised LMM\non the requests as binomial data (i.e. for each request we logged if\nit was at the beginning of a new sentence or not), summarized in\nTable 1 (row 6). Figure 2 (bottom left) shows the descriptive data. In\nsummary, showing one suggestion (instead of three) significantly\ndecreased the chance of requesting suggestions at the beginning of\na new sentence (Means: ùë†1=21.70 %, ùë†3=31.02 %).\n7.4.2 Number of Words in Sentence. For the suggestion requests\nin the middle of sentences we further analysed after how many\nwords in that sentence they were requested. We fitted an LMM\non the mean numbers of words in sentences with suggestion re-\nquests per text, summarized in Table 1 (row 7). Figure 2 (bottom\ncenter) shows the descriptive data. In summary, showing one sug-\ngestion (instead of three) significantly increased the number of\nwords in a sentence after which suggestions were requested ‚Äì by\nabout 1.5 words (Means: ùë†1=10.93, ùë†3=9.48; i.e. a relative increase of\n15.3 %), while Instruction seemed to make no difference (Means:\nùëñùëõùëú =10.18, ùëñùë¶ùëíùë† =10.34). Note that 1-2 words later in a sentence is\nconsiderable because it may lead to very different constraints that\nusers give to the system for possible continuations (e.g. ‚ÄúThe... ‚Äù vs\n‚ÄúThe man said... ‚Äô)‚Äô.\n7.4.3 Words at the Suggestion Requests. We further analysed the\ntype of words after which suggestions were requested. Concretely,\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\nOnly diegetic Also non-d.\n0\n20\n40\n60\n80Suggestion acceptance rate (%)\n3 (list)\n1 (inline)\nOnly diegetic Also non-d.\n0\n100\n200\n300Task time (seconds)\nNo sugg.\n3 (list)\n1 (inline)\nOnly diegetic Also non-d.\n0\n25\n50\n75\n100\n125\n150Text length (number of words)\nNo sugg.\n3 (list)\n1 (inline)\nOnly diegetic Also non-d.\nPrompting options\n0\n10\n20\n30\n40\nRequested sugg. after sentence\n(% of all requests)3 (list)\n1 (inline)\nOnly diegetic Also non-d.\nPrompting options\n0\n2\n4\n6\n8\n10\n12\nNumber of words in sentence\n at which sugg. are requested\n3 (list)\n1 (inline)\nOnly diegetic Also non-d.\nPrompting options\n0\n5\n10\n15\n20\nRequested sugg. after transition word \n(% of all mid-sentence requests)\n3 (list)\n1 (inline)\nFigure 2: Overview of the interaction metrics in our study. In summary, we observe: (1) Giving users the option to write\ninstructions (i.e. non-diegetic prompts) increases the acceptance rate of suggestions for single suggestions, but not beyond that\nof multiple suggestions (top left). (2) Writing time did not vary much and texts were slightly shorter with single suggestions\nand instructions (top center/right). (3) Single suggestions were requested less often at the start of sentences (bottom left), about\n1.5 words later in a sentence (bottom center), and less often after transition words (bottom right). See text for details.\nwe categorised these ‚Äútrigger words‚Äù into transition words and\nother words, using online lists of English transition words 9. For\nexample, transition words mark causes (e.g. ‚Äúbecause‚Äù, ‚Äúsince‚Äù),\nopposites (e.g. ‚Äúwhile‚Äù, ‚Äúdespite‚Äù), effects (e.g. ‚Äútherefore‚Äù, ‚Äúthen‚Äù),\nand other aspects. We provide the full list we used in the project\nrepository. We fitted a generalised LMM on the requests as binomial\ndata (i.e. for each request we logged if it was after a transition word\nor not), summarized in Table 1 (row 8). Figure 2 (bottom right)\nshows the descriptive data. In summary, showing one suggestion\n(instead of three) significantly decreased the chance of requesting\nsuggestions after a transition word (Means: ùë†1=11.80 %, ùë†3=14.03 %),\nwhile Instruction seemed to make no (sig.) difference (Means:\nùëñùëõùëú =12.03 %, ùëñùë¶ùëíùë† =13.32 %).\n7.5 Perception of the Tasks and UIs\nWe used Likert items to assess participants‚Äô perception after each\nwriting task (Figure 3). Descriptively, suggestions received favourable\nratings by the majority and had almost no perceived grammatical\nor factual errors. However, no UI was clearly ‚Äúbest‚Äù for everyone:\nAcross questions and UI variants, there is a spread of opinions,\nincluding for the perceived usefulness of being able to write instruc-\ntions (i.e. non-diegetic prompting). This spread fits to the different\npros and cons and preferences that participants commented on (see\nSection 8). Here, we report on the results from our GEE analysis.\nSince we have 16 questions, we summarize this analysis according\nto the emerging bigger picture.\n7.5.1 Perceived Differences for Number of Suggestions (ùë†1 vs ùë†3).\nShowing a single suggestion was rated worse than having a list of\nthree suggestions. This was significant for several questions. The\n9e.g.: https://www.grammarly.com/blog/transition-words-phrases/,\nhttps://writingcenter.unc.edu/tips-and-tools/transitions/, last accessed March 7, 2023\nGEE model estimates that the odds of giving a higher rating with\na single suggestion were ‚Äúùë•‚Äù times the odds of that with the list\nof three suggestions, with ùë• as follows: Single suggestions were\nrated as significantly more distracting (ùë•=1.95, p<0.005), less helpful\n(ùë•=0.60, p=0.02), leading to more manual editing (ùë•=1.91, p<0.005),\nfeeling less in control (ùë•=0.67, p=0.03), and providing less diverse\nsuggestions (ùë•=0.67, p=0.04).\n7.5.2 Perceived Differences for Instruction (ùëñùëõùëú vs ùëñùë¶ùëíùë† ). We found\na tradeoff in the perception of instructions: On the negative side,\nthe UIs that allowed users to enter instructions to the AI received\nratings of manually editing suggestions significantly more (ùë•=1.54,\np=0.02) and being significantly more distracting (ùë•=2.03, p<0.0005).\nOn the positive side, giving instructions was rated significantly\nbetter on being able to influence the suggested text (ùë•=1.92, p<0.001).\nDescriptively, it was also rated better on feeling in control of the\nsuggested text (see ùëÑ10 in Figure 3), although this was not signifi-\ncant (ùë•=1.42, p=0.058).\n7.5.3 Interactions of Number and Instruction. As mentioned in\nthe previous two parts, both single suggestions and the ability to\ngive instructions were perceived as significantly more distracting.\nHowever, there was also a significant negative interaction effect of\nInstruction and Number on distraction. The increase in distrac-\ntion between ùë†1 compared to ùë†3 was lower for ùëñùë¶ùëíùë† than ùëñùëõùëú (which\nalso matches the picture forùëÑ2 in Figure 3). This seems to be in line\nwith the earlier finding for acceptance rates (Section 7.1): Possibly,\nfinding more useful single suggestions with instructions reduced\nthe otherwise perceived distraction of single suggestions and/or\ninstructions. That said, note that for all suggestion UIs, the majority\ndid not find them distracting. We return to the aspect of distraction\nin more detail when analysing the open feedback (Section 8).\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\nSection Aspect Sig. pos. predictors Sig. neg. predictors Sig. interaction Takeaway in words\n1 7.1 Suggestion\nacceptance\nùë†1 (ùõΩ=-1.26, SE=0.11,\nCI95%=[-1.48, -1.03],\np<.0001)\nNumber *\nInstruction\n(ùõΩ=0.72, SE=0.17,\nCI95%=[0.39,\n1.05], p<.0001)\nShowing one suggestion (instead of three) decreases chance of\nacceptance; more so without instructions than with them.\n2 7.2 Task time,\ncomparing sugg.\nUIs\nNo sig. differences in task completion times were found between the\nfour UIs with suggestions.\n3 7.2 Task time,\ncomparing sugg.\nUIs against baseline\n(no suggestions)\nùë†3 (ùõΩ=24.59, SE=9.5,\nCI95%=[5.96, 43.22],\np<.01)\nWriting with three suggestions took longer than without\nsuggestions.\n4 7.3 Text length,\ncomparing sugg.\nUIs\nùë†1 (ùõΩ=-0.08, SE=0.01,\nCI95%=[-0.10, -0.06],\np<.0001); ùëñùë¶ùëíùë† (ùõΩ=-0.06,\nSE=0.01, CI95%=[-0.09,\n-0.04], p<.0001)\nTexts are slightly shorter when writing with single suggestions or\nwith a UI allowing for instructions...\n5 7.3 Text length,\ncomparing sugg.\nUIs against baseline\n(no suggestions)\nùë†3 (ùõΩ=0.05, SE=0.01,\nCI95%=[0.03, 0.07],\np<.0001)\nùë†1 (ùõΩ=-0.03, SE=0.01,\nCI95%=[-0.05, -0.01],\np<.005); ùëñùë¶ùëíùë† (ùõΩ=-0.05,\nSE=0.01, CI95%=[-0.07,\n-0.03], p<.0001)\n..., also compared to the baseline. However, writing with multiple\nsuggestions leads to slightly longer texts.\n6 7.4.1 Requesting\nsuggestions after\nsentence vs\nmid-sentence\nùë†1 (ùõΩ=-0.83, SE=0.13,\nCI95%=[-1.08, -0.57],\np<.0001); ùëñùë¶ùëíùë† (ùõΩ=-0.32,\nSE=0.14, CI95%=[-0.59,\n-0.05], p=0.018)\nShowing one suggestion (instead of three) decreased the chance of\nrequesting suggestions at the beginning of a new sentence.\n7 7.4.2 Number of words\nin sentence at\nsuggestion request\nùë†1 (ùõΩ=1.55, SE=0.78,\nCI95%=[0.01, 3.08],\np=0.049)\nShowing one suggestion (instead of three) increased the number of\nwords in a sentence after which suggestions were requested.\n8 7.4.3 Type of words at\nsuggestion request\nùë†1 (ùõΩ=-0.37, SE=0.14,\nCI95%=[-0.65, -0.09],\np=0.010)\nShowing one suggestion (instead of three) decreased the chance of\nrequesting suggestions after a transition word.\nTable 1: Overview of the (generalised) LMM results and takeaways of the significant results. Empty cells indicate no significant\nresults. See Sections 7.1 - 7.4 for details and Figure 2 for a descriptive overview of the data.\nFinally, we also asked two questions that focused on the instruc-\ntions directly (ùëÑ15 and ùëÑ16) and thus could only be asked for those\nUIs with instructions (i.e. there‚Äôs only a non-diegetic row in Figure 3\nfor ùëÑ15 and ùëÑ16). For these two questions, we found no significant\ndifferences between ùë†1 and ùë†3.\n7.6 Instruction Usage and Content\nIn total, participants used the non-diegetic prompting option to\nsend 397 instructions to the system, with an average of 3.08 in-\nstructions per person (SD: 3.40). The mean instruction length was\n14.20 characters (SD: 9.01) and 2.52 words (SD: 1.74). On average,\nparticipants had a ratio of 0.19 (SD: 0.17) of entering an instruction\ntext when requesting suggestions, for those tasks that offered to do\nso. That is, about every fifth suggestion request used instructions.\nWe identified three main instruction ‚Äústyles‚Äù: The most common\none (171 usages) was to use single keywords (or comma-separated\nlists of keywords). We also found animperative style with 59 occur-\nrences (e.g. starting the prompt text with ‚Äúsuggest‚Äù, ‚Äúgive‚Äù, ‚Äúfind‚Äù,\n‚Äúdescribe‚Äù). In 12 cases, participants formulated aquestion (e.g. start-\ning with a w-word like ‚Äúwhat‚Äù, ‚Äúwho‚Äù and so on, and/or ending\nwith a ‚Äú?‚Äù). Other cases included instructions consisting of multiple\nwords to describe something (e.g. ‚Äúsomewhere in Italy‚Äù). Qualita-\ntively, we found a range of approaches (Table 2).\n7.7 Evaluation of Text Quality\nThe mean number of spelling and grammar mistakes per word was\n0.0025, which is comparable to values reported in previous research\n[26]. Approximately 3.5% of all texts (23 out of 645) did not align\nwith the selected topics. Of these, the majority (13 out of 23) were\nwritten for the category of ‚Äúshapeshifter‚Äù, which may have been\nmisunderstood as a metaphor for a specific set of desired traits in a\npartner. Despite this potential misunderstanding, the majority of\nparticipants demonstrated attentiveness to the task and provided\nthoughtful reflections on the topic.\n8 OPEN FEEDBACK\nWe analyzed the final feedback as described in Section 5. We struc-\nture this report by the emerging aspects.\n8.1 Comments on Suggestions\nThe majority preferred multiple suggestions (75 people stated this\npreference vs 23 for single suggestions). Main reasons were higher\nchances of finding fitting suggestions (coded 36 times) and more\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\n255075100 0 25 50 75 100\nOnly\ndiegetic\nAlso\nnon-d.\nQ1: The sugg. provided new ideas for my writing\n255075100 0 25 50 75 100\nQ2: ...were distracting\n255075100 0 25 50 75 100\nQ3: ...were helpful\n255075100 0 25 50 75 100\nQ4: ...aligned with what I wanted to write\n255075100 0 25 50 75 100\nOnly\ndiegetic\nAlso\nnon-d.\nQ5: ...helped me to put my ideas into words\n255075100 0 25 50 75 100\nQ6: ...helped me to enter the text correctly\n255075100 0 25 50 75 100\nQ7: I frequently accepted the sugg.\n255075100 0 25 50 75 100\nQ8: I frequently edited sugg. after accepting them\n255075100 0 25 50 75 100\nOnly\ndiegetic\nAlso\nnon-d.\nQ9: I could influence the sugg. text\n255075100 0 25 50 75 100\nQ10: I felt in control of the sugg. text\n255075100 0 25 50 75 100\nQ11: The sugg. made sense\n255075100 0 25 50 75 100\nQ12: ...contained many grammatical errors\n255075100 0 25 50 75 100\nOnly\ndiegetic\nAlso\nnon-d.\nQ13: ...contained many factual errors\n255075100 0 25 50 75 100\nQ14: ...were diverse\n255075100 0 25 50 75 100\nQ15: I had problems thinking of\nsuitable sugg. instructions\n255075100 0 25 50 75 100\nQ16: Being able to write instructions\nto the sugg. system was useful\nStrongly disagree Disagree Neither agree nor disagree Agree Strongly agree 3 (list) 1 (inline)\nFigure 3: Overview of the Likert results. These questions were asked after each writing task. Note that Q15 and Q16 relate to\nthe instructions (i.e. non-diegetic prompts) and thus were only asked for the corresponding tasks.\nApproach Examples\nproviding a topic ‚Äúschool‚Äù, ‚Äúbook‚Äù, ‚Äúretirement‚Äù, ‚Äúzoo‚Äù, ‚Äúevent‚Äù\nproviding adjectives ‚Äúgood‚Äù, ‚Äúhorrendous‚Äù, ‚Äúbad‚Äù, ‚Äúlong, too much, insane‚Äù,\n‚Äúfriendly‚Äù, ‚Äúfunny‚Äù, ‚Äúscared‚Äù\nrequest for inspiration ‚Äúgive me a horror story‚Äù, ‚Äúsuggest a place‚Äù, ‚Äúsuggest\nthe next step‚Äù, ‚Äúthings we do in the morning‚Äù,\n‚Äúsuggest an activity for a middle aged man‚Äù\nmake idea more concrete ‚Äúsuggest something disgusting‚Äù, ‚Äúwhat is wrong with\ndad‚Äù, ‚Äúsuggest a cocktail‚Äù, ‚Äúsuggest a type of pistol‚Äù\nrequest for variation ‚Äúanother phrase‚Äù, ‚Äúanother action outside‚Äù, ‚Äúsuggest a\ndifferent approach‚Äù, ‚Äúanything‚Äù\nrequest for writing help ‚Äúother words for stereotypical‚Äù, ‚Äúfind a synonym for\nvalued‚Äù, ‚Äúsuggest a word for young people‚Äù, ‚Äúanother\nword for talent‚Äù\nask for opinion/advice ‚Äúare books good‚Äù, ‚Äúwhat do i do next‚Äù\nretrieve facts ‚Äúclosest galaxy‚Äù, ‚Äúside effect of anti ageing‚Äù, ‚Äúa place\non the Danube‚Äù\nTable 2: An overview of the different approaches for writ-\ning non-diegetic prompts during the user study. Partici-\npants used single keywords to suggest topics and adjectives.\nMultiple-word prompts were often written in the impera-\ntive style, phrased as questions or phrased as incomplete\nsentences without a verb.\ninspiration (coded 8 times). As ùëÉ38 wrote: ‚ÄúI found the multiple\nsuggestions much more user friendly and also much more inspiring\ndue to the multiple options. ‚Äù\nThose preferring single suggestions found them more intuitive\n(coded 7 times), faster to work with (coded 3 times) or less distract-\ning (coded 3 times): ‚ÄúI strongly preferred inline due to how intuitive\nthey were to use. ‚Äù (ùëÉ113) Or: ‚ÄúI like seeing how the sentences actu-\nally looks in its actual place, and the inline suggestions allowed this. ‚Äù\n(ùëÉ109). Others liked not having to decide (coded 2 times) but noted\nthat this might lead to choosing a less than optimal suggestion.\nFourteen participants reflected on benefits for both, such as: ‚ÄúOn\nthe one hand, the inline suggestions felt less cluttered and I could just\npress tab again if the first suggestion wasn‚Äôt suitable. On the other\nhand, displaying multiple suggestions at once could lead me to a better\nsuggestion when I might just have settled for the first one. ‚Äù (ùëÉ13)\nParticipants commented on why and how to use suggestions,\nmentioning inspiration (coded 39 times), overcoming writer‚Äôs block\n(coded 3 times), or finishing sentences (coded 7 times). For example:\n‚ÄúI used the suggestions if they aligned with what I was writing or if I\nfelt a little stuck with what to say next. ‚Äù (ùëÉ117) Or: ‚ÄúI tended to start\nwith a vague idea of my own and see what ideas it had. ‚Äù (ùëÉ14).\nEighteen participants explicitly commented on suggestion qual-\nity: Eight were negative (ùëÉ91: ‚Äú[...] had to edit most of it. ‚Äù ). Nine felt\nsuggestions were hit or miss ( ùëÉ130: ‚ÄúSometimes [the suggestions]\nhelped, sometimes it didn‚Äôt. ‚Äù ). Two left positive comments (ùëÉ27: ‚ÄúI\nwas sceptical about whether the AI would align with my ideas or\nsuggest phrasing that I would actually use but most often it did so\nand I was pleasantly surprised by the results. ‚Äù ). ùëÉ109 further noted\nthat ‚Äú[instructions] helped the AI write more detailed and inter-\nesting sentences‚Äù when the direction of the sentence was known\nbeforehand. Using ‚Äúone or two words in the instructions to get\nbetter sentences‚Äù that participant continued that ‚Äú[s]ometimes [it]\nworked, but quite often I just ended up writing my own sentences,\nor changing the suggested sentences substantially. ‚Äù (see Figure 5).\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\nIt was a normal Thursday morning when Matt Damon was kidnapped. It was like he just disappeared off the face of the earth. This caused a huge worldwide search. People from all over went to extreme lengths to try and find the beautiful actor and no one was willing to give up until he was safe. An old couple who were a huge fan of Matt, spent hours walking around places they'd never been to before in hopes they'd find him. Carrying around weapons just in case, they were putting their lives on the line for him. After a few hours when it was getting dark, they saw a sighting - they weren't sure what it was, it didn't look human. As they got closer, they realised it was Matt Damon in the flesh but he wasn't.. him. It looked like he had just morphed into a completely different person. Different features, different voice - the couple weren't sure whether to believe it was actually him. At the end of the day they decided they should bring it to the police, they were their only hope in finding out what happened, or to potentially get the old Matt back. To be continued.. Accepted text suggestions\n‚ÄúI liked it better without [the instructions], just let the AI do its thing. That seems more human, that‚Äôs how I share story telling with my grand children, we just take turns.‚Äù (P34)\nFigure 4: Text sample of ùëÉ34 who took turns with the AI to write about the kidnapping of Matt Damon. The suggestions were\ntaken verbatim and mostly requested at the start or in the middle of a sentence.\nAccepted text suggestions\nfunny\nUser provided non-diegetic prompt\n‚ÄúI think the suggestions helped the AI write more detailed and interesting sentences. I usually had an idea of where I wanted the sentence to go, and I used a word or two in the instructions to get better sentences. Sometimes this worked, but quite often I just ended up writing my own sentences, or changing the suggested sentences substantially. (P109)\nDating is a funny thing. It can be like a rest[au]rant, where you pay tons of money and you expect a great meal but you might get the worst meal in the world. Nowadays, this has been complicated by the rise of social media, and apps, such as Facebook and Tinder. Personally, I'm still a fan of the \"old school\" way of dating. It is more of a fun way of dating, and it is a great way to meet new people. It also is a little more exciting, and I think rewarding whether or not t[he] date is successful.On one date, I remember a going to the train station with the girl I was dating and we ate a nice meal together and had a great time. going to the zoo. It was great.\nrestaurant\nFun way\ntrain\nFigure 5: Text sample of ùëÉ109 who provided non-diegetic prompts to guide the LLM. For the last instruction (‚Äútrain‚Äù), ùëÉ109\ndecided to then modify the topic to ‚Äúzoo‚Äù.\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\n8.2 Comments on Instructions\nOpinions diverged on instructions: 21 participants explicitly stated\nthey preferred the UIs allowing for instructions, while 24 preferred\nthose without them. 22 participants reflected on both pros and cons.\nThe main reasons for using instructions were getting more suitable\nsuggestions (coded 12 times) (e.g. ùëÉ27: ‚ÄúI found the instructions more\nhelpful as I could guide the AI when needed. ‚Äù ), inspiration for words\n(coded 29 times) (e.g. ùëÉ65: ‚Äú[...] it gave me inspiration when i was\nstuck for words. ‚Äù) and delegating tasks like coming up with places,\nnames or synonyms. (coded 5 times). One person used the AI ‚Äú[...]\nto get suggestions for and against the point I was trying to make. ‚Äù\n(ùëÉ85).\nIn contrast, some found it hard to write instructions (see Sec-\ntion 8.4 for details). Six participants described a trial-and-error\napproach to find out how to best write instructions.\nIt was also reported that coming up with instructions can disrupt\nthe writing flow (coded 3 times) and thus reduces efficiency, or is\nnot worth the effort. For example: ‚ÄúIt made no difference, as i never\nfelt the need to give it specific instructions. I felt it did a pretty good\njob of knowing what sort of suggestions I wanted. ‚Äù (ùëÉ38).\nSome said writing with instructions felt less natural (coded 3\ntimes): ‚ÄúI mostly enjoyed writing without the instructions. I felt more\nlike I was ‚Äôone‚Äô with the AI and it felt like it was more of a team member\nwith me than a piece of software. I think because it removed that\nfeeling of using a computer to help me write I felt like the suggested\nwriting was an extension of myself. ‚Äù (ùëÉ132). And ùëÉ34 wrote: ‚ÄúI liked\nit better without [the instructions], just let the AI do its thing. That\nseems more human, that‚Äôs how I share story telling with my grand\nchildren, we just take turns. ‚Äù (see Figure 4).\n8.3 Control and Influence\nEleven participants commented on control and influencing sugges-\ntions. For example: ‚ÄúI prefer[r]red multiple because - literally - there\nwere multiple to choose from and that gave me a better feeling of\ncontrol over the story. ‚Äù (ùëÉ59). Another commented: ‚ÄúI like the sugges-\ntion systems especially when I was able to provide guidance. ‚Äù (ùëÉ82).\nOverall, multiple suggestions and instructions were mentioned here\nas contributing to feeling in control, matching the Likert results on\ncontrol and influence (ùëÑ9 and ùëÑ10 in Figure 3).\nMoreover, participants commented on strategies around what\nwe now call diegetic prompting in this paper. For example, some\npreferred influencing the suggestion with the diegetic approach: ‚ÄúI\ndidn‚Äôt have much success providing instructions, was having trouble\nthinking of suggestions quickly and instead focused on directing the\ntopic towards a place were viable suggestions would be made without\ninteractive input. ‚Äù (ùëÉ99). Similarly, ùëÉ111 said: ‚ÄúOften it was just as\ndifficult to think of the instruction as it would be to actually write\nsomething. It seemed just as easy to start writing what I wanted in\norder to push the AI in the direction I wanted it to go. ‚Äù\nIn contrast, some disliked diegetic prompting: ‚ÄúWithout instruc-\ntions was highly annoying, had to shape your lead-in sentences to\nget it to say something relevant. The instructions were intuitive and\nusually got it right. ‚Äù (ùëÉ78, also see Figure 6).\nFinally, others noticed influences on their own writing processes\nrelated to diegetic prompting: ‚Äú[W]hen I was on my own I just ram-\nbled on but while working with the AI I was mentally setting up what\nI wrote to be able to ask for a suggestion at a point where the ideas\ncould go in different directions, depending on what was suggested. ‚Äù\n(ùëÉ99, also see Figure 7). And similarly, ùëÉ9 wrote: ‚Äú[I] noticed that the\nmore time I spent the more my tendency was to find a way to write\nthat would facilitate the suggestion to be meaningful and at the same\ntime interesting to add to give more in-depth to my story. ‚Äù\n8.4 Learnability\nSeveral participants (33) touched on challenges of learnability and\nwriting instructions: ‚ÄúI found coming up with suggestions [to the AI]\ndifficult, really. Having to type the start of a sentence and then type\nwhat I wanted in a smaller box felt quite clunky and not worth the\neffort for what was generated. It felt much more fluid when the AI\nrecognized what I wanted and completed the writing without needing\nsuggestions. ‚Äù(ùëÉ29). ùëÉ6 said: ‚ÄùI almost felt stressed trying to think of\nsome instructions to give to the AI; it felt really hard to me. I‚Äôm glad\nthat the option was there, but I guess I wasn‚Äôt taking full advantage\nof it. ‚Äù Fittingly, 25 participants said they did not use instructions\nmuch because, for example, ‚Äú[...] I wasn‚Äôt very good of thinking of\nthem. ‚Äù (ùëÉ2). Some of the previous comments (Section 8.3) fit this\naspect as well.\n8.5 Distraction\nNine participants explicitly reflected on distraction. For example\nùëÉ20 wrote: ‚ÄúI actually found the suggestions fairly distracting and not\nhelpful. I tended to already know what I wanted to say so the chances\nof the suggestions aligning with my thoughts were fairly slim. ‚Äù ùëÉ43\nperceived instructions in particular as distracting:‚ÄúI feel like writing\nwithout instructions help me focus more and [I] am less distracted\nwhich allows my sentences to flow and be more natural. Instructions\nare good if [I] am stuck and need help. ‚Äù .\n8.6 Perception of the AI and Expectations\nThe comments indicate two fundamental views on the role of the AI:\nSome expected the system to serve efficiency. For example: ‚ÄúI think\nthere is a lot of value in this system, but inputting instructions make\nit quite long winded and onerous, negating any benefits there may\nbe. I preferred the multi suggestions without instruction. ‚Äù (ùëÉ26). Also\nsee the first quote on ‚Äúalignment‚Äù above (Section 8.5). In contrast,\nothers saw the system as serving inspiration (also see Section 8.2\nand Section 7.6). They asked the AI for content suggestions or were\ncurious to see in which direction the AI would take the story. This\nincluded feeling inspired by suggestions even without accepting\nthem: ‚ÄúI was reading the suggestions either to use them or to just get\nideas of what I was writing about‚Äù (ùëÉ67).\n9 DISCUSSION\n9.1 Choice vs. Control\nOur findings contribute to the literature on prompt-based inter-\naction with generative systems for writing: Participants overall\npreferred choosing from multiple text suggestions presented to\nthem, over actively writing instructions, in short creative and argu-\nmentative writing tasks. This is evident from highest acceptance\nrates with the multiple suggestions UI (Section 7.1), which were not\nimproved through instructions, and from the qualitative feedback,\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\nI think the most important things in school are not the subjects, but the skills and the knowledge you gain from them. School subjects: - Maths - English - Science - History - Geography - D&T - Art - Music. Sure, maths will help you in its most basic form but to get the most out of it, you need to learn how to learn. I don't remember what a surd is and I'm doing just fine. In school we should be learning real skills to tackle real life, like finances and taxes. How to book appointments, how to use a computer, how to get a job. I did great in school yet my life skills are lacking.\nAccepted text suggestionsSchool subjects\nreal world skills\nSeriously! Had they not seen The Martian? Not even Saving Private Ryan. No. They were kind enough to leave a note though. \"Gone 2 planet \"Xenon\", took Matt, see ya later\". We didn't know where that was but we were damn well going to find it out. The world had been headed towards another Cold War but upon hearing this news the governments of every superpower put aside their differences and work together. These stakes were too high. We launched all our best spaceship starship vehicles and took to exploring the galaxy.\nsuggest an alien planet name\nUser provided non-diegetic prompt\n‚ÄúWithout instructions was highly annoying, had to shape your lead-in sentences to get it to say something relevant. The instructions were intuitive and usually got it right.‚Äù‚Äù (P78)\nFigure 6: Text sample of ùëÉ78 who used non-diegetic prompting to retrieve a list of ‚Äúschool subjects‚Äù. The accepted suggestion\nis highlighted in blue. Part of the accepted suggestions was later on deleted.\nThe day started the same as any other day. However, it ended unlike any other day. People were waking up spending time with their families, eating breakfast, sending kids off to school when suddenly everything was interrupted by a worldwide amber alert, one that humanity would soon not forget. \"Matt Damon has been abducted by aliens\" the alert read. \"He was last seen playing golf with Ben Affleck before disappearing straight up into the sky via some sort of tractor beam\" Humanity as a whole quickly got over the fact that aliens existed and rapidly went into protection mode for one of societies greatest treasures, Matt Damon.  What can  we do? People asked themselves. Governments assembled the best and brightest to come up with a plan to save Matt Damon. \nAccepted text suggestions\n‚ÄúI didn't have much success providing instructions, was having trouble thinking of suggestions quickly and instead focused on directing the topic towards a place were viable suggestions would be made without interactive input.‚Äù (P99)\n‚Äú[W]hen I was on my own I just rambled on but while working with the AI I was mentally setting up what I wrote to be able to ask for a suggestion at a point where the ideas could go in different directions, depending on what was suggested.‚Äù (P99)\nFigure 7: Text sample of ùëÉ99 who found it difficult to provide non-diegetic prompts and instead focused on guiding the sug-\ngestion through diegetic content, e.g. requesting suggestions after ‚Äú...sending kids off to school when‚Äù (line 3). By setting the\nsentence up in this way before requesting a suggestion this participant guided the LLM to suggestions that ‚Äúgo in different\ndirections‚Äù (cf. comment in the second yellow box).\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\nwhere a clear majority favored multiple suggestions, while opinions\nwere divided on instructions (Section 8).\nHowever, giving users more control options in the UI by adding\nnon-diegetic prompting partially mitigated the drawback of a lack\nof suggestion choice: Instructions increased acceptance rates for\nsingle suggestions ‚Äì although these still did not reach the rate for\nmultiple suggestions (Section 7.1). This indicates that the control\noffered by instructions was useful to guide single suggestions but\nnot better than having a choice of three suggestions to begin with.\nWe discuss possible reasons: First, participants mightsatisfice [40],\nthat is, accept a ‚Äúgood enough‚Äù suggestion rather than trying to ‚Äúop-\ntimize‚Äù it via instructions. Suggestions might also already be good\nenough so that there is no need for instructions, as supported by\nsome comments (Section 8.2). Second, a known usability principle\nis recognition over recall [31]: Users might find it easier to recognize\na presented suggestion as suitable (or not), compared to coming up\nwith an instruction and typing it in. Third, convenience might lead\nparticipants in the study to accept suggestions without instructions\nto get through the tasks quickly. However, participants accepted\nsuggestions at a rate comparable with related work (with multiple\nsuggestions and explicit request via tab key: 74 % here vs 72 % in\n[26]). For suggestions based on user instructions, our rate (64 %)\nis higher than in a related study design where users could enter\nrequests in a sidebar (17.6 % in [48]): This suggests that potential\ninfluences of the study setup do not necessarily work against in-\nstructions, or are less dominant than the effects of the UI design (e.g.\nsidebar vs integration at text cursor). Moreover, times and texts, in\ncombination with the comments, further support the conclusion\nthat participants took the tasks seriously (see Section 7.7).\nAt the same time, instructions were indeed (situationally) useful:\nParticipants commented on their benefits (Section 8.2), used them\nin every fifth suggestion request, and experimented with different\nstyles (Section 7.6). Together, these findings motivate the HCI com-\nmunity to further explore the integration of choice and control via\nprompting. For example, future work could build on our concep-\ntual lens to envision further UI designs that combine diegetic and\nnon-diegetic prompting, and use our data as a benchmark in their\nevaluation.\n9.2 Guiding Suggestions with Diegetic Prompts\nOur results add to the literature on writing with AI by revealing\nthat people specify more diegetic information to offset the lack\nof suggestion choice in UIs that display only a single suggestion.\nThis is based on the first large-scale analysis of where in the text\nusers request suggestions: Users wrote about 1.5 more words in\nthe sentence before requesting single suggestions, compared to\nmultiple ones. Moreover, single suggestions were requested less\nfrequently to start a new sentece and to continue after a transition\nword. Possibly, receiving a single suggestion is less useful here,\ngiven that new sentences and transition words signal ‚Äúopenness‚Äù\nfor potential changes to the direction of the narrative.\nCurrently, there is one other (small-scale) analysis of trigger mo-\nments (N=4 in [7]). Thus, we encourage the community to analyze\ntrigger moments whenever studying UIs with explicit suggestion\ntriggers.\nFittingly, we indeed recently see high interest in interaction\ndesigns where users explicitly request suggestions (e.g. [7, 26, 41]).\nOur study explores this design space further by looking at how\nit interacts with the number of suggestions: Here, we contribute\nevidence that people consider when to request suggestions, and\nin particular for single suggestions they request them at points\nin their text that are expected to give clearer guidance to the text\ncontinuation system. Future work could examine whether this holds\nin other writing contexts and to what extent users actively think\nabout when to request suggestions while writing. Based on people‚Äôs\ncomments, at least some strategically thought about what we term\ndiegetic prompting (see Section 8.3).\nAs a related aspect, prior work focused on how people react\nto suggestions (e.g. evaluation fatigue [4], integrative leaps [41]).\nComplementary, the above results indicate that there is also aproac-\ntive direction: Writers think about suggestions before seeing them.\nFuture work could investigate this in more detail, in particular for\nUIs in which users explicitly request suggestions.\n9.3 Challenges of Integrating Non-Diegetic\nPrompts\nWe extract two concrete challenges of interacting via non-diegetic\nprompts to guide future research and design.\n9.3.1 Non-Diegetic Prompts Interrupt the Writing Process. Writing\ninvolves multiple cognitive processes, such as coming up with a\nthought, turning it into words, and entering it [21]. Recently, Bhat\net al. [4] studied (without non-diegetic prompts) how this is im-\npacted by text suggestions. For example, writers need to evaluate\ndisplayed suggestions. Here, our study adds insights into the rela-\ntive impact of diegetic vs non-diegetic prompts: Crucially, switching\nfrom diegetic writing to non-diegetic instructing forces writers to\nshift from thinking about their narrative or argument to thinking\nabout instructions to the system. This is reflected in people‚Äôs com-\nments (Section 8.2, 8.3, 8.4) and the Likert results on distraction and\nproblems with thinking of instructions (ùëÑ2 and ùëÑ15 in Figure 3). In\ncontrast, diegetic prompts do not require such shifts, although they\nstill require engagement with displayed suggestions [4, 6].\n9.3.2 Non-Diegetic Prompts can be Hard to Write. Even after mak-\ning that shift, then writing effective non-diegetic prompts is difficult,\nadding to related findings in the literature [48]: Many participants\nstruggled with this and recognised that they did so in self-reflection\n(Section 8.2, 8.3, 8.4). More positively, the non-diegetic prompts\ncollected in our study show how users experimented with different\nstyles. These might evolve further with longer use. At the moment,\nnone of these styles go beyond what would also be a meaningful\ncomment to a human co-author.\n9.4 Perceived Role of the AI\nHere we discuss how users perceived the AI and support this discus-\nsion by reflecting on three writing processes as in the framework\nfor analyzing writer-suggestion interactions by Bhat et al. [4]: (1)\nproposing new topics or ideas, (2) translating abstract thoughts or\nkeywords into sentences, (3) transcribing (i.e. entering) words.\n9.4.1 Two Perspectives on the Main Role: Proposer vs Transcriber.\nSome people clearly saw the system as something that serves input\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\nefficiency (i.e. transcriber), whereas others saw it as providing inspi-\nration (i.e. proposer). The former are more critical about the system\nsince it would only be good if it is fast and predicts exactly what\nthey want. Based on the qualititative feedback we think that the\nchosen topic as well as participants‚Äô familiarity with the topic might\nhave an influence on their writing mindset. For argumentative writ-\ning and, more generally, when people already had an opinion about\na topic, they felt that the AI was distracting if it proposed something\nother than what participants had in mind. Future work may have\na closer look at the influence of topic genre and prior knowledge\nabout a topic on the perception of the role of the AI. Study designs\nshould take this difference into account when choosing writing\ntopics to calibrate metrics for performance or exploration.\n9.4.2 Non-diegetic Prompts Reflect Users‚Äô Perception of the AI. We\ncan further discuss how the content of non-diegetic prompts reflects\nvarying perceptions of the role of the AI: Considering the writing\nprocesses [4], non-diegetic prompts from our dataset show that\nusers requested the AI to propose inspirational ideas. Sometimes\nusers also only provided partial phrases or keywords, or asked for\nword choices, which puts the AI into the role of translating these\nabstract ideas into full sentences. At other times, they perceived\nthe AI as a transcriber for input efficiency (Section 8).\nOther non-diegetic prompts indicate influences on the perceived\nrole beyond these writing processes: For example, people asked\nthe AI for an opinon or advice, or to lookup information. Thus,\nnon-diegetic prompts may shift perception of the AI‚Äôs role towards\na writing collaborator.\n9.5 Limitiations and Reflections on\nMethodology\nPeople wrote for five minutes with each UI. Hence, they spent\nten minutes in total with each individual UI feature across the\nwriting tasks (single and multiple suggestions, with and without\ninstructions). This is comparable to related work (e.g. 11 min [26],\n4 min [6], 10-12 min [48]). Future studies should investigate long-\nterm use, in particular to observe how non-diegetic prompts evolve\nas writers gain experience with a system.\nWe prototyped our system with GPT-3 via an API. We did not\nhave access to the model directly and we do not claim to have\nidentified the ‚Äúbest‚Äù settings for our specific usage of the model.\nWe noticed two limitations: Sometimes, suggestions were repetive\n(e.g. similar ones in one list) or repeated the instruction text (which\nseems unhelpful). Nevertheless, suggestions were rated highly over-\nall (Section 7.5).\nPotential changes to the model over time are beyond our control.\nThis limits exact replicability for studies like this. We see a trend\nof limited direct access to state-of-the-art LLMs for parts of the\nacademic community, which is not easy to resolve. On the positive\nside, our work shows that it is possible to construct and study in\ndetail interactive applications built on existing models.\nWe chose an online setup in line with recent related work (e.g. [6,\n26]) to collect logging data from interactions of many people. How-\never, we could not observe people directly or ask questions at in-\nteresting moments in the interaction, except for in our pre-study,\nwhich we used to refine our design. A small-N study with direct\nobservation and think-aloud could complement our work, for exam-\nple, to understand decision-making around triggering suggestions\nand writing non-diegetic prompts in more detail. Nevertheless, we\nreceived rich qualitative feedback as well (Section 8).\nIt is possible that the instruction styles (Section 7.6) are biased\nby the provided examples (Figure 8 in Appendix A). Our pre-study\nshowed that such examples are needed to help people get started\nwith this new feature. Nevertheless, people experimented beyond\nthese examples (e.g. questions, writing help, advice, etc.; see Ta-\nble 2).\nWith the pop-up box, we tested one way of integrating instruc-\ntions. This UI element is motivated as a simple way of integrating\ninstructions with the established design of a suggestion list (or\ninline suggestion). A similar pop-up is used in recent related work\n(not for instructions but for suggestions in the middle of sentences;\ncf. [4]). Other designs should be explored in the future.\nFinally, we emphasize the importance of open writing tasks in\nHCI research. Historically, transcription tasks have dominated text\nentry research (cf. [45]). With the rising interest in human-AI co-\ncreation, research on writing tools needs new tasks. These might\nnot necessarily focus on measuring input speed but rather cover a\nrange of topics, text types, and other aspects. Pragmatically, writing\ntasks from writer communities and custom tasks have been used in\nrecent studies (e.g. [6, 26, 41, 48]), including ours. As a community,\nwe should systematically evaluate and curate such writing tasks if\nthey are to become a lasting key methodological component.\n9.6 Beyond Writing: Diegetic and Non-diegetic\nInteraction in Generative Systems\nWe have studied diegetic and non-diegetic prompts to draft text (i.e.\ntext to text ). Here we reflect on this new perspective by discussing\nconcrete examples of how other interactive generative systems use\ndiegetic and non-diegetic prompting.\n‚Ä¢Visual to Text Chung et al. [9] proposed a new story ideation\ntool that uses visual sketching to guide a LLM. Here the\nsketch is translated to a text prompt. This interaction is non-\ndiegetic.\n‚Ä¢Text to Visual Recent text to image models allow users to\ngenerate images from text descriptions [30, 32, 36]. These\nare non-diegetic prompts, because they are not part of the\nvisuals.\n‚Ä¢Visual to Visual Bau et al. [3] show an example of ‚Äúpainting\nshapes‚Äù to guide image models: Users draw simple shapes\nsuch as a triangle to symbolize a mountain. The image model\nthen translates these shapes into a high-fidelity rendering.\nSince the abstract shape is usually not part of the outcome\nwe consider this interaction non-diegetic. On the other hand,\nHa and Eck [19] enable users to start painting a part of an\nimage (i.e. providing diegetic information) and let the system\ncontinue or finish the painting.\nDifferentiating these two perspectives therefore allows researchers\nto analyse users‚Äô intention and behavior when interacting or de-\nsigning systems with generative AI. As shown in the following\ndiscussion we can use this understanding to derive implications on\nthe design of interactions for generative models.\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\n9.7 Implications for LLMs and User Interfaces\nIn recent work by Schick et al . [38], their LLM ‚ÄúPEER‚Äù is explic-\nitly trained to follow non-diegetic prompts related to text revision.\nEffectively, our study contributes the HCI counterpart ‚Äì an investi-\ngation of a UI and interaction design to integrate an LLM in such a\nrole into the writing process. Our results guide future work at this\nintersection of HCI and NLP in two concrete ways:\nFirst, based on our collected non-diegetic prompts these LLMs\nshould be trained to understand a broader range of inputs. For\ninstance, PEER is trained on the imperative-style but we found the\nkeyword-style to be more common. Alternatively, users need to be\nguided towards the supported style via the UI.\nSecond, while LLMs are rapidly improving, even the best model\ncannot eliminate cognitive costs and interaction costs of switching\nbetween diegetic and non-diegetic writing. This motivates further\nstudies on interaction designs that require such switches and po-\ntential pathways to making them easier and more efficient.\n10 CONCLUSION\nOur new understanding highlights that people use two types of\nprompting to guide LLMs for text generation. While related work\nhas presented systems that focused on non-diegetic prompts, our\nfindings reveal that users additionally think about and shape their\ntext to guide LLMs through diegetic information. With our UI design\nthat allows for both types, using GPT-3, participants preferred\nchoosing from multiple suggestions over writing instructions. We\nconclude by highlighting three key takeaways based on our results:\nFirst, writing instructions to the AI requires effort, including\nswitching between diegetic and non-diegetic writing. Second, peo-\nple combine diegetic and non-diegetic prompting, as single sug-\ngestions benefitted from both. Third, writers use their draft (i.e.\ndiegetic information) and suggestion timing to strategically guide\nLLMs, based on our analysis of when people request suggestions,\nas well as their self-reflection in comments.\nWe encourage future work to further analyze these prompt types\nto develop better writing tools and generalize to other domains (e.g.\ninteraction with generative models for images). To facilitate this,\nwe release our prototype and material on the study and analysis\nhere:\nhttps://osf.io/qwakj\nACKNOWLEDGMENTS\nWe thank Lukas Mecke for feedback on the manuscript. This project\nis funded by the Bavarian State Ministry of Science and the Arts\nand coordinated by the Bavarian Research Institute for Digital\nTransformation (bidt).\nREFERENCES\n[1] Kenneth C. Arnold, Krysta Chauncey, and Krzysztof Z. Gajos. 2018. Sentiment\nBias in Predictive Text Recommendations Results in Biased Writing. InProceedings\nof the 44th Graphics Interface Conference (Toronto, Canada) (GI ‚Äô18) . Canadian\nHuman-Computer Communications Society, Waterloo, CAN, 42‚Äì49. https:\n//doi.org/10.20380/GI2018.07\n[2] Douglas Bates, Martin M√§chler, Ben Bolker, and Steve Walker. 2015. Fitting\nLinear Mixed-Effects Models Using lme4. Journal of Statistical Software 67, 1\n(2015), 1‚Äì48. https://doi.org/10.18637/jss.v067.i01\n[3] David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenen-\nbaum, William T. Freeman, and Antonio Torralba. 2018. GAN Dissection:\nVisualizing and Understanding Generative Adversarial Networks . Technical\nReport arXiv:1811.10597. arXiv. https://doi.org/10.48550/arXiv.1811.10597\narXiv:1811.10597 [cs] type: article.\n[4] Advait Bhat, Saaket Agashe, Niharika Mohile, Parth Oberoi, Ravi Jangir, and\nAnirudha Joshi. 2022. Studying writer-suggestion interaction: A qualitative study\nto understand writer interaction with aligned/misaligned next-phrase suggestion.\nhttps://doi.org/10.48550/ARXIV.2208.00636\n[5] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Pra-\nfulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\nSandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon\nChild, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse,\nMark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,\nChristopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario\nAmodei. 2020. Language Models are Few-Shot Learners. InAdvances in Neural In-\nformation Processing Systems , H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan,\nand H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877‚Äì1901. https://proceedings.\nneurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[6] Daniel Buschek, Martin Z√ºrn, and Malin Eiband. 2021. The Impact of Multiple\nParallel Phrase Suggestions on Email Input and Composition Behaviour of Native\nand Non-Native English Writers. In Proceedings of the 2021 CHI Conference on\nHuman Factors in Computing Systems (Yokohama, Japan) (CHI ‚Äô21) . Association\nfor Computing Machinery, New York, NY, USA, Article 732, 13 pages. https:\n//doi.org/10.1145/3411764.3445372\n[7] Alex Calderwood, Vivian Qiu, Katy Ilonka Gero, and Lydia B. Chilton. 2020.\nHow Novelists Use Generative Language Models: An Exploratory User Study.. In\nHAI-GEN+ user2agent@ IUI .\n[8] Mia Xu Chen, Benjamin N. Lee, Gagan Bansal, Yuan Cao, Shuyuan Zhang, Justin\nLu, Jackie Tsay, Yinan Wang, Andrew M. Dai, Zhifeng Chen, Timothy Sohn,\nand Yonghui Wu. 2019. Gmail Smart Compose: Real-Time Assisted Writing.\nIn Proceedings of the 25th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining (Anchorage, AK, USA) (KDD ‚Äô19) . Association for\nComputing Machinery, New York, NY, USA, 2287‚Äì2295. https://doi.org/10.1145/\n3292500.3330723\n[9] John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan\nAdar, and Minsuk Chang. 2022. TaleBrush: Sketching Stories with Generative\nPretrained Language Models. In Proceedings of the 2022 CHI Conference on Human\nFactors in Computing Systems (CHI ‚Äô22) . Association for Computing Machinery,\nNew York, NY, USA. https://doi.org/10.1145/3491102.3501819 event-place: New\nOrleans, LA, USA.\n[10] Juliet M Corbin. 1990. Basics of qualitative research: Grounded theory procedures\nand techniques . Sage.\n[11] Mark Dunlop and John Levine. 2012. Multidimensional Pareto Optimization of\nTouchscreen Keyboards for Speed, Familiarity and Improved Spell Checking. In\nProceedings of the SIGCHI Conference on Human Factors in Computing Systems\n(Austin, Texas, USA)(CHI ‚Äô12) . Association for Computing Machinery, New York,\nNY, USA, 2669‚Äì2678. https://doi.org/10.1145/2207676.2208659\n[12] Andrew Fowler, Kurt Partridge, Ciprian Chelba, Xiaojun Bi, Tom Ouyang, and\nShumin Zhai. 2015. Effects of Language Modeling and Its Personalization on\nTouchscreen Typing Performance. InProceedings of the 33rd Annual ACM Con-\nference on Human Factors in Computing Systems (Seoul, Republic of Korea)\n(CHI ‚Äô15) . Association for Computing Machinery, New York, NY, USA, 649‚Äì658.\nhttps://doi.org/10.1145/2702123.2702503\n[13] Katy Gero, Alex Calderwood, Charlotte Li, and Lydia Chilton. 2022. A Design\nSpace for Writing Support Tools Using a Cognitive Process Model of Writing. In\nProceedings of the First Workshop on Intelligent and Interactive Writing Assistants\n(In2Writing 2022) . Association for Computational Linguistics, Dublin, Ireland,\n11‚Äì24. https://aclanthology.org/2022.in2writing-1.2\n[14] Katy Ilonka Gero, Vivian Liu, and Lydia Chilton. 2022. Sparks: Inspiration for\nScience Writing Using Language Models. In Designing Interactive Systems Confer-\nence (Virtual Event, Australia) (DIS ‚Äô22) . Association for Computing Machinery,\nNew York, NY, USA, 1002‚Äì1019. https://doi.org/10.1145/3532106.3533533\n[15] Mayank Goel, Leah Findlater, and Jacob Wobbrock. 2012. WalkType: Using\nAccelerometer Data to Accomodate Situational Impairments in Mobile Touch\nScreen Text Entry. In Proceedings of the SIGCHI Conference on Human Factors in\nComputing Systems (Austin, Texas, USA)(CHI ‚Äô12) . Association for Computing\nMachinery, New York, NY, USA, 2687‚Äì2696. https://doi.org/10.1145/2207676.\n2208662\n[16] Mayank Goel, Alex Jansen, Travis Mandel, Shwetak N. Patel, and Jacob O. Wob-\nbrock. 2013. ContextType: Using Hand Posture Information to Improve Mobile\nTouch Screen Text Entry. InProceedings of the SIGCHI Conference on Human Fac-\ntors in Computing Systems (Paris, France) (CHI ‚Äô13) . Association for Computing\nMachinery, New York, NY, USA, 2795‚Äì2798. https://doi.org/10.1145/2470654.\n2481386\n[17] Steven Goodman, Erin Buehler, Patrick Clary, Andy Coenen, Aaron Michael\nDonsbach, Tiffanie Horne, Michal Lahav, Bob MacDonald, Rain Breaw Michaels,\nAjit Narayanan, Mahima Pushkarna, Joel Christopher Riley, Alex Santana, Lei\nShi, Rachel Sweeney, Phil Weaver, Ann Yuan, and Meredith Ringel Morris. 2022.\nLaMPost: Evaluation of an AI-assisted Writing Email Editor Prototype for Adults\nwith Dyslexia. https://arxiv.org/abs/2207.02308\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\n[18] Mitchell Gordon, Tom Ouyang, and Shumin Zhai. 2016. WatchWriter: Tap and\nGesture Typing on a Smartwatch Miniature Keyboard with Statistical Decoding.\nIn Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems\n(San Jose, California, USA) (CHI ‚Äô16). Association for Computing Machinery, New\nYork, NY, USA, 3817‚Äì3821. https://doi.org/10.1145/2858036.2858242\n[19] David Ha and Douglas Eck. 2017. A Neural Representation of Sketch Drawings.\nhttp://arxiv.org/abs/1704.03477 arXiv:1704.03477 [cs, stat].\n[20] Adi Haviv, Jonathan Berant, and Amir Globerson. 2021. BERTese: Learning to\nSpeak to BERT. In Proceedings of the 16th Conference of the European Chapter\nof the Association for Computational Linguistics: Main Volume . Association for\nComputational Linguistics, Online, 3618‚Äì3623. https://doi.org/10.18653/v1/2021.\neacl-main.316\n[21] John R. Hayes. 2012. Modeling and Remodeling Writing. Written Communication\n29, 3 (July 2012), 369‚Äì388. https://doi.org/10.1177/0741088312451260\n[22] Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach,\nMichael Terry, and Carrie J. Cai. 2022. PromptMaker: Prompt-based Prototyping\nwith Large Language Models. In CHI Conference on Human Factors in Computing\nSystems Extended Abstracts . 1‚Äì8.\n[23] Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How Can\nWe Know What Language Models Know? Transactions of the Association for\nComputational Linguistics 8 (Dec. 2020), 423‚Äì438. https://doi.org/10.1162/tacl_\na_00324\n[24] Anjuli Kannan, Karol Kurach, Sujith Ravi, Tobias Kaufmann, Andrew Tomkins,\nBalint Miklos, Greg Corrado, Laszlo Lukacs, Marina Ganea, Peter Young, and\nVivek Ramavajjala. 2016. Smart Reply: Automated Response Suggestion for\nEmail. In Proceedings of the 22nd ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining (San Francisco, California, USA) (KDD\n‚Äô16). Association for Computing Machinery, New York, NY, USA, 955‚Äì964.\nhttps://doi.org/10.1145/2939672.2939801\n[25] Alexandra Kuznetsova, Per B. Brockhoff, and Rune H. B. Christensen. 2017.\nlmerTest Package: Tests in Linear Mixed Effects Models. Journal of Statistical\nSoftware 82, 13 (2017), 1‚Äì26. https://doi.org/10.18637/jss.v082.i13\n[26] Mina Lee, Percy Liang, and Qian Yang. 2022. CoAuthor: Designing a Human-AI\nCollaborative Writing Dataset for Exploring Language Model Capabilities. In\nProceedings of the 2022 CHI Conference on Human Factors in Computing Systems\n(New Orleans, LA, USA) (CHI ‚Äô22) . Association for Computing Machinery, New\nYork, NY, USA, Article 388, 19 pages. https://doi.org/10.1145/3491102.3502030\n[27] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and\nWeizhu Chen. 2021. What Makes Good In-Context Examples for GPT-$3$?\nhttp://arxiv.org/abs/2101.06804 arXiv:2101.06804 [cs].\n[28] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and\nGraham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic Survey of\nPrompting Methods in Natural Language Processing. arXiv:2107.13586 [cs] (July\n2021). http://arxiv.org/abs/2107.13586 arXiv: 2107.13586.\n[29] Michael J. Muller and Sandra Kogan. 2012. Grounded Theory Method in Human-\nComputer Interaction and Computer-Supported Cooperative Work. In The Hu-\nman‚ÄìComputer Interaction Handbook (3 ed.). CRC Press. Num Pages: 21.\n[30] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,\nBob McGrew, Ilya Sutskever, and Mark Chen. 2021. GLIDE: Towards Photoreal-\nistic Image Generation and Editing with Text-Guided Diffusion Models. (2021).\nhttps://doi.org/10.48550/ARXIV.2112.10741 Publisher: arXiv Version Number: 3.\n[31] Jakob Nielsen. 1994. Enhancing the Explanatory Power of Usability Heuristics.\nIn Proceedings of the SIGCHI Conference on Human Factors in Computing Systems\n(Boston, Massachusetts, USA) (CHI ‚Äô94) . Association for Computing Machinery,\nNew York, NY, USA, 152‚Äì158. https://doi.org/10.1145/191666.191729\n[32] Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski.\n2021. StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery. (2021). https:\n//doi.org/10.48550/ARXIV.2103.17249 Publisher: arXiv Version Number: 1.\n[33] Fabio Petroni, Tim Rockt√§schel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,\nAlexander H. Miller, and Sebastian Riedel. 2019. Language Models as Knowledge\nBases? http://arxiv.org/abs/1909.01066 arXiv:1909.01066 [cs].\n[34] Philip Quinn and Shumin Zhai. 2016. A Cost-Benefit Study of Text Entry Sugges-\ntion Interaction. In Proceedings of the 2016 CHI Conference on Human Factors in\nComputing Systems (San Jose, California, USA) (CHI ‚Äô16) . Association for Com-\nputing Machinery, New York, NY, USA, 83‚Äì88. https://doi.org/10.1145/2858036.\n2858305\n[35] R Core Team. 2020. R: A Language and Environment for Statistical Computing . R\nFoundation for Statistical Computing, Vienna, Austria. https://www.R-project.\norg\n[36] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.\n2022. Hierarchical Text-Conditional Image Generation with CLIP Latents. (2022).\nhttps://doi.org/10.48550/ARXIV.2204.06125 Publisher: arXiv Version Number: 1.\n[37] Melissa Roemmele and Andrew S. Gordon. 2015. Creative Help: A Story Writing\nAssistant. In Interactive Storytelling (Lecture Notes in Computer Science) , Henrik\nSchoenau-Fog, Luis Emilio Bruni, Sandy Louchart, and Sarune Baceviciute (Eds.).\nSpringer International Publishing, Cham, 81‚Äì92. https://doi.org/10.1007/978-3-\n319-27036-4_8\n[38] Timo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis,\nGautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and\nSebastian Riedel. 2022. PEER: A Collaborative Language Model. https:\n//doi.org/10.48550/ARXIV.2208.11663\n[39] Timo Schick and Hinrich Sch√ºtze. 2021. Exploiting Cloze Questions for Few Shot\nText Classification and Natural Language Inference. http://arxiv.org/abs/2001.\n07676 arXiv:2001.07676 [cs].\n[40] Herbert Alexander Simon. 1996. The sciences of the artificial (3. ed. ed.). MIT\nPress, Cambridge, Mass.\n[41] Nikhil Singh, Guillermo Bernal, Daria Savchenko, and Elena L. Glassman. 2022.\nWhere to Hide a Stolen Elephant: Leaps in Creative Writing with Multimodal\nMachine Intelligence. ACM Trans. Comput.-Hum. Interact. (jan 2022). https:\n//doi.org/10.1145/3511599 Just Accepted.\n[42] Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna Beyer,\nHanspeter Pfister, and Alexander M. Rush. 2022. Interactive and Visual Prompt\nEngineering for Ad-hoc Task Adaptation with Large Language Models. http:\n//arxiv.org/abs/2208.07852 arXiv:2208.07852 [cs].\n[43] Ben Swanson, Kory Mathewson, Ben Pietrzak, Sherol Chen, and Monica Di-\nnalescu. 2021. Story Centaur: Large Language Model Few Shot Learning as\na Creative Writing Tool. In Proceedings of the 16th Conference of the Euro-\npean Chapter of the Association for Computational Linguistics: System Demon-\nstrations. Association for Computational Linguistics, Online, 244‚Äì256. https:\n//doi.org/10.18653/v1/2021.eacl-demos.29\n[44] Anestis Touloumis. 2015. R Package multgee: A Generalized Estimating Equations\nSolver for Multinomial Responses. Journal of Statistical Software 64, 8 (2015),\n1‚Äì14. http://www.jstatsoft.org/v64/i08/\n[45] Keith Vertanen and Per Ola Kristensson. 2014. Complementing Text Entry\nEvaluations with a Composition Task. ACM Trans. Comput.-Hum. Interact. 21, 2,\nArticle 8 (feb 2014), 33 pages. https://doi.org/10.1145/2555691\n[46] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina,\nMichael Terry, and Carrie J. Cai. 2022. PromptChainer: Chaining Large Language\nModel Prompts through Visual Programming. http://arxiv.org/abs/2203.06566\nNumber: arXiv:2203.06566 arXiv:2203.06566 [cs].\n[47] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Transparent\nand Controllable Human-AI Interaction by Chaining Large Language Model\nPrompts. InProceedings of the 2022 CHI Conference on Human Factors in Computing\nSystems (New Orleans, LA, USA)(CHI ‚Äô22). Association for Computing Machinery,\nNew York, NY, USA, Article 385, 22 pages. https://doi.org/10.1145/3491102.\n3517582\n[48] Ann Yuan, Andy Coenen, Emily Reif, and Daphne Ippolito. 2022. Wordcraft: Story\nWriting With Large Language Models. In 27th International Conference on Intelli-\ngent User Interfaces (Helsinki, Finland) (IUI ‚Äô22) . Association for Computing Ma-\nchinery, New York, NY, USA, 841‚Äì852. https://doi.org/10.1145/3490099.3511105\n[49] Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021. BARTScore: Evaluating Gen-\nerated Text as Text Generation. http://arxiv.org/abs/2106.11520 arXiv:2106.11520\n[cs].\n[50] Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021.\nCalibrate Before Use: Improving Few-Shot Performance of Language Models.\nhttp://arxiv.org/abs/2102.09690 arXiv:2102.09690 [cs].\nA APPENDIX\nIn this appendix, we provide a table of logged events and additional\nscreenshots.\nCHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany Dang et al.\nNo. Interaction Event Description\n1 EVENT_CONFIRM_INSTRUCTION User has confirmed instruction (Enter Key)\n2 EVENT_CANCEL_INSTRUCTION User has cancelled the instruction (ESC key or clicking outside the instruction box)\n3 EVENT_OPEN_INSTRUCTION_BOX User has triggered new suggestions in the ‚Äúwith instructions‚Äù writing setting (Tab Key)\n4 EVENT_SELECT_NEXT_SUGGESTION User has selected next suggestion (Down Arrow Key)\n5 EVENT_SELECT_PREV_SUGGESTION User has selected previous suggestions (Up Arrow Key)\n6 EVENT_REQUEST_SUGGESTIONS User has requested new suggestions (Tab Key)\n7 EVENT_SUGGESTIONS_RESPONSE System returned suggestions\n8 EVENT_CONFIRM_SUGGESTION User has selected and confirmed one suggestion (Enter Key or Mouse Selection)\n9 EVENT_CANCEL_SUGGESTION User has cancelled the suggestions (ESC key or clicking outside the suggestion box)\n10 EVENT_TASK_STATUS Can be either ‚Äútask started‚Äù or ‚Äútask finished‚Äù\n11 EVENT_KEYDOWN User has pressed a key, e.g ‚ÄúA‚Äù or ‚ÄúTAB‚Äù\nTable 3: An overview of the interaction events logged in the user study.\nFigure 8: Screenshot of the writing interface. (Left Side) The info box describes the available functionalities in the current\nsetting, (Top Middle) the selected topic, (Bottom Middle) the text editor with the current written text and an inline suggestion.\nHow Users Write with LLMs using Diegetic and Non-Diegetic Prompting CHI ‚Äô23, April 23‚ÄìApril 28, 2023, Hamburg, Germany\nFigure 9: The topic selection panel. Users can browse through the topics and indicate that they are ready to write about the\ndepicted topic.",
  "topic": "Narrative",
  "concepts": [
    {
      "name": "Narrative",
      "score": 0.709297239780426
    },
    {
      "name": "Conflation",
      "score": 0.5785186290740967
    },
    {
      "name": "Computer science",
      "score": 0.5591732263565063
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.53367018699646
    },
    {
      "name": "Generative grammar",
      "score": 0.49862098693847656
    },
    {
      "name": "Linguistics",
      "score": 0.3498096764087677
    },
    {
      "name": "Artificial intelligence",
      "score": 0.31722214818000793
    },
    {
      "name": "Art",
      "score": 0.30167877674102783
    },
    {
      "name": "Literature",
      "score": 0.16586819291114807
    },
    {
      "name": "Philosophy",
      "score": 0.11715233325958252
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I54009628",
      "name": "University of Bayreuth",
      "country": "DE"
    }
  ]
}