{
  "title": "Delving into Participants’ Profiles and Use of Social Tools in MOOCs",
  "url": "https://openalex.org/W2144709494",
  "year": 2014,
  "authors": [
    {
      "id": "https://openalex.org/A2746546663",
      "name": "Carlos Alario-Hoyos",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2376919554",
      "name": "Mar Pérez-Sanagustin",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A1995220988",
      "name": "CARLOS DELGADO KLOOS",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2567794409",
      "name": "Hugo A. Parada G",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2015978287",
      "name": "Mario Munoz Organero",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2746546663",
      "name": "Carlos Alario-Hoyos",
      "affiliations": [
        "Universidad Carlos III de Madrid"
      ]
    },
    {
      "id": "https://openalex.org/A2376919554",
      "name": "Mar Pérez-Sanagustin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1995220988",
      "name": "CARLOS DELGADO KLOOS",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2567794409",
      "name": "Hugo A. Parada G",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2015978287",
      "name": "Mario Munoz Organero",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W40105975",
    "https://openalex.org/W6631894117",
    "https://openalex.org/W6678064627",
    "https://openalex.org/W1989940942",
    "https://openalex.org/W2009156591",
    "https://openalex.org/W2001386703",
    "https://openalex.org/W1559246682",
    "https://openalex.org/W2145912399",
    "https://openalex.org/W2823260",
    "https://openalex.org/W2076582092",
    "https://openalex.org/W6720364629",
    "https://openalex.org/W6600743424",
    "https://openalex.org/W17354724",
    "https://openalex.org/W2120820700",
    "https://openalex.org/W1533506932",
    "https://openalex.org/W2471699996"
  ],
  "abstract": "This paper presents an in-depth empirical analysis of a nine-week MOOC. This analysis provides novel results regarding participants' profiles and use of built-in and external social tools. The results served to detect seven participants' patterns and conclude that the forum was the social tool preferred to contribute to the MOOC.",
  "full_text": "Delving into Participants’ Proﬁles\nand Use of Social Tools in MOOCs\nCarlos Alario-Hoyos, Mar P/C19erez-Sanagust/C19ın,\nCarlos Delgado-Kloos, Hugo A. Parada G., and\nMario Mu~noz-Organero\nAbstract— This paper presents an in-depth empirical analysis of a nine-week\nMOOC. This analysis provides novel results regarding participants’ proﬁles and\nuse of built-in and external social tools. The results served to detect seven\nparticipants’ patterns and conclude that the forum was the social tool preferred to\ncontribute to the MOOC.\nIndex Terms— Collaborative learning, distance learning, computer and informa-\ntion science education\nÇ\n1I NTRODUCTION\nMASSIVE open online courses (MOOCs) have caused a disruption in\neducation systems in just a few months [1], [2]. Following the suc-\ncess of Coursera or edX in the United States, many initiatives at\nnational levels were created across Europe, such as Mir/C19ıadaX in\nSpain, FutureLearn in UK, iversity in Germany, or OpenUpEd,\nwhich is an umbrella initiative of European MOOCs. On the one\nhand, MOOCs offer teachers the opportunity to reach a large num-\nber of students interested in the subjects taught [3]. On the other\nhand, MOOCs enable students accessing free education provided\nby elite universities [4]. Furthermore, MOOCs are the meeting\npoint for communities of people that share common interests [5].\nThe large number of people that register in MOOCs entails a\ngreat heterogeneity [5]. This heterogeneity does not only refer to\nparticipants’ literacy, background or origin, but also to their perfor-\nmance throughout the MOOC; it is possible to ﬁnd participants\nthat complete the course with proﬁciency and also contribute\nactively to the generation of a community [6], and participants\nwho have no real interest in the course but log in a couple of times\njust because it is free [7]. Between them, there are many others that\nare interested in the course but give up because they cannot keep\npace and do not ﬁnd the adequate support and advice [8].\nThe most engaged participants are expected to act as mentors,\nassisting their peers and enriching the MOOC with additional con-\ntents and discussion [9]. Mentors complement teachers, who can-\nnot give personalized support to the large number of people\nenrolled in MOOCs [10]. Social tools, such as forums or social net-\nworks, are typically employed to connect MOOC participants.\nThese social tools can be included in the platform that centralizes\nthe course (built-in social tools) or can be provided by third-parties\n(external social tools) [11]. In any of these cases, an appropriate\nselection of social tools is a key aspect to effectively build connec-\ntions among MOOC participants, facilitate mentors to support\ntheir peers and foster the creation of the MOOC community [12].\nThis paper delves into participants’ proﬁles and use of social\ntools in MOOCs with the aim to help MOOC teachers detect differ-\nent types of participants and make informed choices when select-\ning social tools. Speciﬁcally, this paper presents two contributions:\na list of proﬁles that characterize participants according to their\nperformance throughout the MOOC, and an analysis of the level of\nactivity in built-in and external social tools around the MOOC.\nBoth contributions are particularized for a nine-week MOOC called\nDigital Education of the Future (DEF), deployed in the platform\nMir/C19ıadaX. The decision to separate the analyses of participants’\nproﬁles and use of social tools is determined by the fact that data\nfrom the former were obtained from the mandatory part of the\nMOOC (watching videos and carrying out assignments), while\ndata from the latter were obtained from the complementary sup-\nport of the MOOC, which was not required to pass the course.\nThese two perspectives provide an in-depth analysis of the course\nconsidering both, the participants’ characteristics in and around\nthe MOOC and their ﬁnal outcomes. This paper uses partial data\nincluded in the conference paper [11], which covered the ﬁrst six\nweeks of DEF, and extends the study to the entire course. This\nwork seeks to provide an insight into the range of people that coex-\nist in MOOCs and their activity in social tools based on empirical\ndata. The results add an overall understanding of MOOC partici-\npants and can be used by teachers for designing upcoming courses.\nThe remainder of this paper proceeds with Section 2 laying the\ngroundwork with a review of the literature related to participants’\nproﬁles and use of social tools in MOOCs. Section 3 brieﬂy\ndescribes the MOOC DEF. Section 4 proposes a novel characteriza-\ntion of participants recognizing seven different patterns, according\nto their performance, and analyzes the level of activity in ﬁve\nbuilt-in and external social tools using the data collected from DEF.\nSection 5 discusses the most relevant ﬁndings to support teachers\nin making informed choices when designing MOOCs. Section 6\ndraws the conclusions and set some open questions that emerge\nfrom this work.\n2R ELATED WORKS\nAlthough MOOCs are a recent research ﬁeld, there is already some\nliterature exploring the diversity of people that coexists in these\ncourses, and the use of social tools as a means for mass communi-\ncation and collaboration. In addition, research in online learning\nand in other collaborative settings (especially regarding the analy-\nsis of social tools) provides results and ideas that sustain and\ninspire the contributions of this work.\n2.1 Participants’ Proﬁles in MOOCs\nMost of the research on participants’ proﬁles has been done in\nxMOOCs, which are MOOCs that replicate the traditional educa-\ntional model of knowledge transfer from teachers to students.\nHowever, there are also studies deﬁning some participants’ activ-\nity patterns in cMOOCs (connectivist MOOCs) [13], which are\nMOOCs that rely on user-generated content and in which connec-\ntions among participants are key for the course to advance.\nRegarding xMOOCs, some researchers have classiﬁed partici-\npants into different proﬁles according to their behavior during the\ncourse. For example, Hill [6] deﬁnes ﬁve proﬁles:no-shows, those\nwho register in a course but never log in;observers, those who log\nin but do not take assessment tasks;drop-ins, those who participate\nin some activities but do not attempt to complete the entire course;\npassive, those seeing the course as content to consume; andactive,\nthose participating in all the activities and enriching the course.\nSimilarly, authors in [14] distinguish ﬁve groups of people depend-\ning on their level of participation in the MOOC forum:inactive,\nthose that do not visit the forum at all;passive, those that just con-\nsume information;reacting, those that add further aspects to exist-\ning questions; acting, those that post questions and lead\ndiscussions; and supervising/supporting, those that besides leading\ndiscussions summarize gained insights.\nRegarding cMOOCs, the most relevant work is the one by\nMilligan et al. [15], who explored patterns of learners’ engagement\nafter 17 weeks of a cMOOC. This study classiﬁes people into three\n/C15 The authors are with the Department of Telematic Engineering, Universidad Carlos\nIII de Madrid, Avda. de la Universidad, 30, Legan/C19es, Spain.\nE-mail: {calario, mmpsanag, cdk, hparada, munozm}@it.uc3m.es.\nManuscript received 9 Dec. 2013; revised 17 Feb. 2014; accepted 9 Mar. 2014. Date of\npublication 12 Mar. 2014; date of current version 12 Sept. 2014.\nFor information on obtaining reprints of this article, please send e-mail to: reprints@ieee.\norg, and reference the Digital Object Identiﬁer below.\nDigital Object Identiﬁer no. 10.1109/TLT.2014.2311807\n260 IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014\n1939-1382 /C2232014 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\npatterns: active, those that followed the course and also enriched it\nthrough active blogs and Twitter accounts; lurkers, those that\nfollowed the course but did not engage with peers; andpassive,\nthose that were frustrated or dissatisﬁed with the course but still\npersisted until week 17. Both the existing xMOOC and cMOOC\nclassiﬁcations of participants match some of the participants’ 4C\nlearning behaviors identiﬁed in [16]: consume, connect, create and\ncontribute.\nThere is also research in online learning that provides some\nunderstanding about how to classify MOOC participants based on\nperformance. For instance, Fischer [17] proposes a framework to\nsupport the exploration of human-centered social computing\nfocused on cultures of participation, distinguishing amongunaware\nconsumers, consumers, contributors, collaborators, and meta-designers.\nMost people start asunaware consumers who, when aware of the\npossibilities offered by the supporting technology, become aware\nconsumers. A fraction of the aware consumers contribute (contribu-\ntors), organize the content acting also as curators (collaborators) and,\nin a small percentage, feel responsible for the content shared and\nextend the environment (meta-designers). Fischer’s classiﬁcation can\nbe adapted to the MOOC context, since MOOCs are a particular\ntype of participatory learning community.\nThese studies provide a base of empirical data for arranging\nMOOC participants according to different classiﬁcation methods.\nHowever, more empirical research is needed in order to understand\nthe relationship between participants’ performance throughout a\nMOOC and ﬁnal scores, deﬁning simple and precise patterns for\ncategorizing participants, as it is done in Section 4.1 of this paper.\n2.2 Social Tools in MOOCs\nIn the last few months, discussions about the importance of using\nsocial tools in MOOCs appeared in both traditional peer-review\npublications and non-academic dissemination sources (e.g., blogs).\nAlthough most authors agree that social tools are the basis for sup-\nporting connections among MOOC participants and creating a\n“sense of community” [5], [18], [19], few studies provide empirical\ndata about real use of social tools in MOOCs at the time. Hill gath-\ners in a recent post most of these studies [20].\nFor example, authors in [21] report that only 3% of the people\nenrolled in edX’s ﬁrst MOOC participated in the discussion forum.\nThis work also identiﬁes that, of the total number of people that\nearned a completion certiﬁcate, 52% of them were active contribu-\ntors in the forum. Duke University also reports that about 7% of\npeople registered in its ﬁrst MOOC contributed in the forum [22],\nparticipants being satisﬁed with its overall use. Similar conclusions\nwere reached in [23], whose authors analyzed the activity in the\ndiscussion forums of 23 Coursera MOOCs. This study also reports\nthat the number of people posting in the forums was never higher\nthan 10% of registered participants, being under 5% in most cases.\nFinally, the University of Edinburgh reports a bit better numbers\nwith an average of 15% of participants engaged in discussion\nforums in its ﬁrst six MOOCs [24].\nThere are also a few studies that focus on the analysis of Face-\nbook, Googleþ or Twitter, which, although external to MOOC plat-\nforms, are sometimes useful in MOOCs as an alternative to\ndiscussion forums, and as a form of widespread publicity. As an\nexample the report by Duke University [22] points out that over 80\nstudents joined a Facebook study group during its ﬁrst MOOC.\nAlso, the course “E-Learning and Digital Culture” delivered at the\nUniversity of Edinburgh had a large amount of social media activ-\nity in Facebook, Googleþ and Twitter [24]. With respect to the lat-\nter social tool, authors in [25] analyzed the use of Twitter in the\nMOOC “OpenCourse” during two consecutive editions. They\nfound that only 39% of the total tweets were related to the course\ntopics, with 31% tweets about the course organization and 8%\nabout MOOCs, tools and platforms in general. Interestingly, 17%\nof tweets had no visible connection to the course topics and 4%\nwere just for self-marketing.\nAlthough these works provide some empirical results about the\nlevel of activity of MOOC participants in one or two social tools,\nthese results typically refer to built-in social tools. However, in this\nwork, we compare in Section 4.2 several built-in and external social\ntools for providing a more general picture of the discussions\nemerging around a MOOC and the kind of information shared\namong participants.\n3D IGITAL EDUCATION OF THE FUTURE\nDigital Education of the Future was a MOOC on educational tech-\nnologies deployed in Mir/C19ıadaX by ﬁve Professors from the Univer-\nsidad Carlos III de Madrid (Spain) between 5th February and 25th\nApril 2013. This MOOC lasted nine weeks with a short break at\nEaster. The nine weeks were divided into three modules of three\nweeks each, covering three broad subjects by means of video lec-\ntures: a) human computer interaction; b) mobile learning; and\nc) MOOCs as a disruption in education. There was also a short pre-\nsentation module to introduce participants in the course topics, the\nassessment system and the social tools around DEF.\nTeachers applied a continuous assessment in DEF during the\nwhole course. Participants needed 50 points out of 100 to pass and\nthere were 13 different summative assessment activities (see Table 1\nfor details about the weights of the activities and the timeframes to\ncomplete them). These activities were either multiple choice tests\nor peer review (P2P) activities, which were the two kinds of assign-\nments supported by the platform Mir/C19ıadaX at the time. P2P has\nbeen successfully applied for years in many ﬁelds including\nresearch, and is a recurrent way to assess tasks that cannot be auto-\nmatically corrected in MOOCs [4]. Mir/C19ıadaX implemented P2P\nactivities as follows: a) participants got the ﬁrst half of the score if\nthey submitted the task and reviewed all their peers’ work (the sys-\ntem typically assigned them 3-5 documents to review); b) partici-\npants got the second half of the score from the grade given by their\npeers. Teachers provided a detailed rubric to facilitate the review\nof P2P activities.\nRegarding social tools, teachers selected ﬁve, two Mir/C19ıadaX\nbuilt-in and three external. Built-in social tools were Q&A and a\nforum. External social tools were Facebook, Twitter and Mentor-\nMob (see [11] for details about the intended purpose of each social\ntool in DEF).\nThe registration process in DEF remained open throughout the\ncourse. In total, 5,595 participants were registered after the nine\nTABLE 1\nDistribution of Summative Assessment Activities in DEF\nIEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014 261\nweeks. The origin, literacy, background, status and motivation of\nthe participants were very varied (see [11] for further information).\nThe course was taught in Spanish and around 60% of people came\nfrom Spain, but there were also large communities of people from\nmost Latin American countries.\nTable 2 summarizes participants’ ﬁnal scores. A total of 456 peo-\nple (8.15% of the 5,595 registered participants) passed the course,\nwhile 5,140 (91.85%) failed it. The maximum score achieved was\n94.7 points out of 100, with the mean 9.37 and the standard devia-\ntion 20.22. The low mean value is the result of most participants\ngetting zero points (70.49%), which is quite common in MOOCs,\nsince a high percentage of registered people do not really intend to\ntake them [6]. If we exclude participants with zero points, then the\nmean value increases to 31.75 (SD 25.97).\n4R ESULTS AND ANALYSIS\nThis section analyzes the data extracted at the end of DEF. These\ndata are arranged according to participants’ performance, in order\nto detect different proﬁles, and the actual use of social tools.\n4.1 Participants’ Proﬁles\nIn order to simplify and be precise when classifying participants\nwe only take into account participants’ performance in the\nsequence of activities proposed by teachers, which in most\nMOOCs involves watching videos and solving a exercises (tests\nand P2P activities in DEF). Thu s, the participants’ proﬁles\ndeﬁned here do not take into account the contributions submit-\nted to the social tools, which are addressed in the next section.\nThis classiﬁcation builds on the patterns deﬁned in [6] and [15],\nbut considering that the registration process in DEF remained\nopen throughout the course.\nThree broad categories are deﬁned for MOOC participants:\nlurkers (those that register in the course but watch a few\nresources at most); participants that do not complete the course\n(those that just take a part of the course); andparticipants that\ncomplete the course (those that take the course from the begin-\nning to the end). Within these three broad categories seven pat-\nterns are established particularized for DEF. These patterns are\nsummarized in Table 3:\n/C15 No shows. These are a type of lurkers that enrol in the\ncourse but do not perform any activity (neither watch vid-\neos nor solve exercises). No shows formed a large group of\n1,486 people (26.56%) in DEF, for whom there were no\nrecords beyond clicking on the register button.\n/C15 Observers. These are another type of lurkers that register in\nthe course, typically watch a few videos, but do not\nattempt any evaluation activity. There were 2,352 observers\n(42.04%) in DEF that watched at least one of the videos,\ndespite not trying any summative assessment activity.\n/C15 Drop-ins. These are a type of participants that do not com-\nplete the course. They start the MOOC but never ﬁnish it\n[6]. 739 (13.21%) drop-ins were identiﬁed in DEF, checking\nthat they completed the ﬁrst summative assessment activ-\nity (A1), but did not attempt the end-course questionnaire\n(A13).\n/C15 Latecomers. These are another type of participants that do\nnot complete the course. However, unlike drop-ins,\nlatecomers join after the course starts. 301 latecomers\n(5.38%) were identiﬁed in DEF, checking that they com-\npleted the end-course test (A13), but missed the ﬁrst sum-\nmative assessment activity (A1).\n/C15 Drop-in latecomers. These are the third kind of participants\nthat do not complete the MOOC. They join late and leave\nbefore the end of the course. 292 participants (5.22%) were\nclassiﬁed as drop-in latecomers in DEF, checking that they\nmissed the ﬁrst summative assessment activity (A1), per-\nformed at least one of the intermediate activities (A2–A12),\nbut left before the end-course test (A13).\n/C15 Non-engaged. These are a kind of participants that complete\nthe course from the beginning to the end, but without par-\nticipating in activities that require an important workload.\nWe identiﬁed 88 non-engaged participants (1.57%) in DEF,\nas those that performed the ﬁrst and last multiple choice\ntests (A1 and A13) and some other intermediate summa-\ntive questionnaires (A2-A3, A5-A7, A9-A11), but did not\nparticipate in any of the three peer review activities (A4,\nA8, and A12).\n/C15 Engaged. These are also participants that follow the course\nfrom the beginning to the end, but in this case performing\nall kinds of activities. 337 engaged participants (6.02%)\nwere identiﬁed in DEF, as those that completed both sum-\nmative questionnaires and peer review activities. How-\never, not all of them carried out the 13 summative\nassessment activities (only 104 people tried them all).\nTABLE 2\nDistribution of Participants’ Final Scores in DEF\nTABLE 3\nClassiﬁcation of the Participants Registered in DEF, Indicating How Many of Them Passed or Failed the Course\n262 IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014\nThe larger number of observers with respect to no shows in\nDEF contradicts Hill’s analysis [6] (he detected a higher propor-\ntion of no shows in Coursera MOOCs). That can be explained by\nt w or e a s o n s .F i r s t ,t h er e g i s t r ation process remained open as the\ncourse was being delivered, cau s i n gt h a tm a n yp e o p l ed e c i d e d\nto watch a few videos just after enrolling (observers). Second,\nthe lack of availability of a stable version of the platform\nMir/C19ıadaX caused that the registration process could be open\nonly ﬁfteen days before the starting date, limiting the number of\npeople that registered and did not click on any of the course\nmaterials (no shows). The lack of sufﬁcient time to announce the\ncourse motivated that teachers decided to keep the registration\nin the course open for latecomers and that most of the score\ncould be achieved in the second half of the course (65% of the\ntotal score could be obtained in weeks 6-9). Interestingly, we\ndetected that 26.1% of those passing the course were latecomers\n(119 out of 456) as reported in Table 3, an important pattern that\nshould be taken into account during the instructional design of\nthe MOOC so as to support this proﬁle.\nTable 3 details the percentage of participants of each proﬁle that\npassed the course. Obviously, all the lurkers failed with zero\npoints. Nevertheless, we found a few drop-ins (and drop-in late-\ncomers) that also got zero points in the few summative assessment\nactivities they tried to resolve. Interestingly, the assessment system\nenabled that some of the people that did not complete the entire\ncourse reached 50 points out of 100. This is especially signiﬁcant in\nlatecomers, with 39.5% of them passing the course. Anecdotally, a\nnegligible number of drop-ins (1.6%) and drop-in latecomers\n(0.7%) could also pass the course after completing most of the sum-\nmative assessment activities, but leaving before the end-course\ntest. We also noticed the penalty of not being involved in peer\nreview activities, since only 31.8% of the non-engaged participants\nwere able to pass DEF, even though they followed it from the\nbeginning to the end. Finally, most engaged participants (87.5%)\nwere able to pass following the continuous assessment system\ndesigned by the teaching staff (those engaged participants that\nfailed the course typically skipped several intermediate summative\nassessment activities).\nThe decision to let participants join the MOOC once started\nhas the positive effect of latecomers counterbalancing the num-\nber of drop-ins. This can be seen in Table 4, which represents the\nnumber of participants in DEF that worked in each of the sum-\nmative assessment activities. After the initial excitement of the\nstart of the course (A1, A2), there was an important drop in the\nnumber of people that tried to solve A3; but this drop progres-\nsively decreased in the coming weeks thanks to latecomers. It is\nnoteworthy that the number of people trying to solve the multi-\nple choice tests even grew in some weeks, such as between A5\nand A6, or between A10 and A11. Peer review activities, which\ndemanded a higher effort to participants were less attractive and\ntypically had a lower number of people working on them. Inter-\nestingly, the peer review activity in the second module received\nmore people than the one in the ﬁrst module. One possible\nexplanation for this fact, as d etected by the teaching staff\ninspecting the social tools, was the initial confusion of many par-\nticipants with the two-step procedure of submitting their work\nand later reviewing their peers’ tasks.\n4.2 Social Tools\nParticipants in DEF contributed to the course using the ﬁve social\ntools selected by the teachers. Table 5 summarizes the number of\npeople that posted messages in each social tool, the total number of\ncontributions received per tool, and the number of posts submitted\nby the most active user in each social tool. It is interesting to point\nout that the most active user was different for each of the ﬁve social\ntools. Therefore, having several social alternatives enabled MOOC\nparticipants choosing the one (or ones) they felt more comfortable\nwith or were more used to.\nQ&A had a moderate impact in DEF with 604 posts from\n339 different participants. This social tool was mainly employed\nto submit queries about the log istical and methodological\naspects of the MOOC, such as certiﬁcation, assessment system,\nor peer review assignments; and it was also the entry point for\ncomplaints about the platform, e specially service outages. In\ntotal, 332 different questions were created through Q&A (four\nof them by the teachers). Teachers tried to answer them all, but\nTABLE 4\nNumber of Participants Taking Each of the 13 Summative\nAssessment Activities in DEF\nTABLE 5\nParticipants’ Contributions in DEF\nPosts from the teaching staff are excluded from these data.\nIEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014 263\nquite a few were also answered by DEF participants, who\ncould also vote the most relevantones. Unlike the other social\ntools, the contributions in Q&A began to arrive from the ﬁrst\nday participants registered on the course, that is, a couple of\nweeks before the course actually started.\nThe forum was the tool with the highest impact in DEF. In total\n2,819 contributions from 800 different participants arranged in 684\ndifferent threads were submitted to the forum, which was primar-\nily used for deep discussions about the topics presented in the\nvideo lectures. Several participants used the forum very actively,\nwith 50 users posting 10 or more messages in this social tool.\nFacebook was the external tool with a higher impact, receiving\n664 posts from 341 different participants. Facebook was also used\nfor long discussions, usually started by the teaching staff. Fig. 1\nshows the number of contributions received in Facebook per day.\nIt can be clearly seen the initial excitement and progressive drop,\nas well as intermediate peaks which were generally produced in\nresponse to teachers’ posts in the Facebook wall.\nTwitter had a moderate impact with659 tweets including the\ncourse hashtags from 173 different people. That makes Twitter the\nsocial tool with a higher number of posts per user. These posts\nmainly contained opinions about open questions posed by the\nteachers, additional resources shared by the MOOC participants,\nand remarkable quotations extracted from the video lectures.\nMentorMob had a very low impact as a social tool to share con-\ntents related to the MOOC, and people preferred other means for\nsharing, such as the forum, Facebook or Twitter. Teachers created\nfour MentorMob lists and included some initial resources, but only\n45 contributions from 34 participants were received, which means\nnot only the lowest number of contributions and participants from\nthe ﬁve social tools, but also the lowest number of contributions\nper participant. The impact of MentorMob was so low that the last\nresource was linked two weeks before the end of the course.\nFinally, and regarding the relationship between participants’\nperformance and use of social tools, it is noteworthy that from\nthose who passed the MOOC, 65.4% (298 out of 456) contributed in\nany of the ﬁve social tools. This number is slightly higher than the\none reported in [21]. In addition, from those who did not pass the\nMOOC, only 14.3% (733 out of 5,139) contributed in any of the\navailable social tools.\n5D ISCUSSION\nThe classiﬁcation of participants based on performance was estab-\nlished from the records provided by Mir/C19ıadaX just after the end of\nthe course. These records indicated whether a participant had taken\nan activity or not, and the score obtained (in the case of assessment\nactivities). Nevertheless, Mir/C19ıadaX only kept data from the people\nregistered in the course at that moment. There might be other people\nthat, apart from leaving the course earlier than expected, explicitly\nderegistered from DEF. These people, for whom there are no records,\nwould be classiﬁed as lurkers (either no shows or observers), drop-\nins or drop-in latecomers. From the messages posted in built-in social\ntools (Q&A and forum), we detected119 people that contributed at\nsome point during the course but later deregistered. All these people\nwould be discarded as lurkers according to Hill’s patterns [6] since\nthey actively participated in the social tools; and thus these 119 extra\nparticipants would necessarily bedrop-ins or drop-in latecomers.\nFrom the percentages of each pattern calculated in Table 3, we could\nestimate another equivalent 441extra lurkers, and conclude that\napproximately 560 additional people enrolled in the course but\nderegistered before its end, which represents an additional 10% in\nthe total number of participants. This additional 10% may be reason-\nable but probably too optimistic because lurkers tend to forget the\ncourse after their ﬁrst access, which also includes deregistering.\nThe classiﬁcation of participants presented in this paper is\naligned with the one in [11], but taking into account that in the\nlatter there are only four patterns versus the seven deﬁned here.\nA st h ea n a l y s i sh e r ec o v e r sal o n g e rp e r i o do ft i m ei nc o m p a r i -\nson to [11], the number of lurkers increases and the people that\nfollowed DEF from start to ﬁnish decreases, as expected. Further,\nthis paper builds the classiﬁcation of participants looking into\nthe performance of each individual in each summative\nevaluation activity, while [11] establishes the classiﬁcation based\non the total number of participants that completed each assign-\nment. As such, the classiﬁcation in [11] would be less accurate\ndue to not taking into account that there might be people that\ncould have missed some activity but carried out the subsequent\no n e s .F u r t h e r m o r e ,t h ec l a s s i ﬁ c a tion of participants is not a novel\ncontribution since it builds on outcomes from previous research\nworks [6], [15] in which ﬁve of these patterns were already\nd e t e c t e d :n os h o w s ,o b s e r v e r s ,d r o p - i n s ,n o t - e n g a g e d ,e n g a g e d .\nHowever, the particular features of the course enabled the detec-\ntion of two additional patterns that do not appear in these previ-\nous works: latecomers and drop-in latecomers.\nWith respect to social tools, their potential to connect the dif-\nferent participants in DEF was apparent. From the 5595 partici-\npants, at least 1031 (18.4%) of them contributed through any of\nthe ﬁve social tools available. This numbers are higher than those\nfound in [21], [22], [23], [24] and can be due to the higher number\nof social tools offered in this MOOC and to DEF teachers actively\nparticipating in tools like Facebook or Twitter fostering debate.\nThe aforementioned percentage of contributors in DEF excludes\nthe 119 extra users that also posted in the social tools but explic-\nitly deregistered the course, and possibly some of the hundred\nusernames on Facebook, Twitter and MentorMob that could not\nbe mapped to the corresponding usernames in Mir/C19ıadaX. Creat-\ning a community of over one thousand participants connected\nthrough the social networks around a MOOC, no matter their\nproﬁles and interests, maximizes the possibility of ﬁnding people\nwith whom to collaborate and share [5].\nFrom the ﬁve social tools, participants in DEF preferred built-in\ntools and especially the forum to discuss and contribute. This con-\nclusion based on empirical data (Table 5) is consistent with partic-\nipants’ perception of their degree of involvement in social tools, as\nstudied through volunteer surveys ﬁlled out by DEF participants\nduring the ﬁrst weeks of the MOOC (see [11] for details). The pref-\nerence for built-in social tools in DEF is aligned with the ﬁndings\nin [18], in which participants employed more the built-in forum\nthan Facebook for privacy reasons. The fact that DEF participants\nfound in a centralized platform both the learning materials and the\nsocial tools can also motivate their preference for built-in tools as a\nway to contribute to the course.\nOf course, this preference for built-in tools was not true for\neveryone. And it must also be added that the ﬁve social tools avail-\nable in DEF were employed for different purposes. Although a\nFig. 1. Participants’ contributions in Facebook throughout the course. This ﬁgure is\naligned with those presented in [11] regarding Facebook and Twitter impact in the\nﬁrst six weeks of DEF.\n264 IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014\ndeeper analysis of the actual content in the messages is required,\nfrom ﬁrst analysis we can see that the forum or Facebook were\nmore suitable for longer discussions about the course topics, unlike\nQ&A or Twitter. In addition, while teachers selected a speciﬁc tool\nto easily share and arrange related resources (MentorMob), partici-\npants decided to employ the forum, Facebook or Twitter to share\nthese additional resources in a more unstructured way. This leads\nto an interesting result: it is a good idea to offer several social tools\nin MOOCs, as also suggested by [18], in order to get different out-\ncomes and levels of participation.\nHowever, offering multiple social tools in a MOOC has one\nmajor drawback: the information overload for learners and teach-\ners, who must visit several sites to ﬁnd the most signiﬁcant contri-\nbutions. In fact, we received complaints of information diluted in\ndifferent spaces. Moreover, teachers had problems to detect emer-\ngent issues, and noted the repetition of the same discussions in sev-\neral places. In order to overcome this shortcoming it is convenient\nto develop intra-tool ﬁltering mechanisms based on the quality of\nthe contributions, and encourage participants to follow best practi-\nces when using social tools, such as reading before writing or not\nopening unnecessary threads. Uniﬁed interfaces that allow posting\nin several social tools at the same time can also alleviate this draw-\nback [26] although they are still not present in most MOOC plat-\nforms, as it was the case in Mir/C19ıadaX.\nThe most positive aspect of including social tools in MOOCs is\nthe appearance of mentors (or facilitators) giving support to their\npeers [5]. In DEF, these mentors were participants that voluntarily\nﬁlled the gap of teacher-students interactions particularly within\nthe forum. Among the more than a thousand people that contrib-\nuted through the various social tools available in DEF, mentors\nwould be found among the ones that posted more messages in one\nor several of these tools. The fact that there are voluntary mentors\nin MOOCs may help creating a stronger community around the\nMOOC and fostering the discussions in the different open threads.\nOn the opposite side there can be people with negative inten-\ntions that want to take advantage of the open nature of MOOCs for\ntheir own beneﬁt. In the case of DEF, we found several participants\nposting comments off-topic and even spam. We also had people\nthat voluntarily or involuntarily published some answers to assess-\nment activities in the social tools. All in all, it is necessary to\ninclude rewards for mentors and enable the community of partici-\npants to self-regulate the MOOC throwing out those people that\ntry to undermine the learning process.\n6C ONCLUSIONS AND FUTURE WORK\nMOOCs are characterized by a large number of people enrolled in\nthem. However, the performance of all these people throughout the\nMOOC is very heterogeneous, and only a few manage to follow the\ncourse from beginning to end. This paper classiﬁes the participants\nin MOOCs according to seven different patterns depending on the\nassignments they take. The example of DEF is used to detect that\nobservers are the largest group when MOOCs start their advertising\ncampaign with little time in advance. Also, DEF shows the value of\nleaving a door open for latecomers, offering alternatives that\nencourage them not to give up. Properly identifying participants’\nproﬁles in MOOCs based on performance can help developing per-\nsonalized recommending systems or more effective engagement\nmechanisms that can help reducing the existing high dropout rates.\nThis paper also analyzes the impact of built-in and external\nsocial tools in MOOCs, with the forum revealing as the main\nsource of contributions in the case of DEF. Nevertheless, other\nsocial tools such as Facebook, Twitter and Q&A also had a moder-\nate impact in the promotion of discussions and in the sharing of\nresources related to the MOOC. An important conclusion that\nstems from this analysis is the need for a tradeoff between offer-\ning participants a wide range of social tools (so they can use the\nones they feel more comfortable with) and the extra burden in\norder to process the large amount of information generated in the\ndifferent social tools. Teachers should be aware of this conclusion\nwhen designing the MOOC, and also reﬂect about whether they\nwill be able to promote the conversation (or at least follow it) if\nopting for multiple social tools, since most social tools need regu-\nlar interventions to foster debateonce past the initial excitement.\nThe ﬁndings of this paper also serve to open new lines of\nresearch regarding participants’ proﬁles and use of social tools\nin MOOCs. One of these research lines concerns the role of vol-\nuntary mentors. Questions such as, who these people? what is\ntheir motivation? or whether they are really prepared to replace\nteachers or not, remain open. Besides, it would also be interest-\ning to ﬁnd out if it is possible to have these mentors in the next\neditions of the MOOC, as a wayto generate a growing commu-\nnity of people that survives beyond the course. Another line of\nresearch refers to encouraging everyone, not only mentors, to\nfurther contribute in social tools with strategies like gamiﬁcation\napproaches, which were not included in Mir/C19ıadaX at the time of\nrunning DEF. Further, there is a need for mechanisms that help\nself-regulating the community, and ﬁght against those who seek\nto undermine the learning process within the social tools.\nRelated to this, it is necessary to ﬁnd ways to ﬁlter the huge\namount of information generated in the different social tools,\nseparating and promoting the valuable contributions, no matter\nin which social tool they were posted. Finally, and in order to\ngeneralize the results obtained in this study, similar analysis\nshould be made using MOOCs on different areas of knowledge,\ndeployed in different platforms, and that include a varied num-\nber of social tools for participants to choose from.\nACKNOWLEDGMENTS\nThis work was funded by the Spanish Ministry of Economy\nand Competitiveness Project TIN2011-28308-C03-01, the Regional\nGovernment of Madrid project S2009/TIC-1650, and the postdoc-\ntoral fellowship Alliance 4 Universities.\nREFERENCES\n[1] P. Hyman, “In the year of disruptive education,” Comm. ACM, vol. 55,\nno. 12, pp. 20–22, 2012.\n[2] M. Sharples, P. McAndrew, M. Weller, R. Ferguson, E. FitzGerald, T. Hirst,\nand M. Gaved, “Innovating pedagogy 2013, exploring new forms of teach-\ning, learning and assessment, to guide educators and policy makers,” Tech.\nReport, The Open Univ., 2013..\n[3] S. Kolowich, (2013), The professors who make the MOOCs. The\nChronicle Higher Edu [Online]. Available: http://chronicle.com/article/\nThe-Professors-Behind-the-MOOC/137905\n[4] J. Daniel, (2012), Making sense of moocs: musings in a maze of myth, para-\ndox and possibility. J. Interactive Media Edu [Online]. Available: http://\njime.open.ac.uk/2012/18\n[5] A. McAuley, B. Stewart, G. Siemens, and D. Cormier (2010), The\nM O O Cm o d e lf o rd i g i t a lp r a c t i c e .T e c h .R e p o r t ,U n i v .o fP r i n c e\nEdward Island, [Online]. Available: h ttp://elearnspace.org/Articles/\nMOOC_ Final.pdf.\n[6] P. Hill, (2013) Emerging student patterns in moocs: A (revised) graphical\nview., [Online]. Available: http://mfeldstein.com/emerging-student-\npatterns-in-moocs-a-revised-graphical-view.\n[7] D. Clow, “MOOCs and the funnel of participation,” inProc. 3rd Int. Conf.\nLearning Analytics Knowl., 2013, pp. 185–189.\n[8] D. Yang, T. Sinha, D. Adamson, and C. P. Rose, (2013). Turn on, tune in,\ndrop out: anticipating student dropouts in massive open online courses.\n[Online]. Available: http://lytics.stanford.edu/datadriveneducation/\npapers/yangetal.pdf.\n[9] J. Mackness, S. F. J. Mak, and R. Williams, “The ideals and reality of partici-\npating in a MOOC,” inProc. 7th Int. Conf. Netw. Learning, 2010, pp. 266–274.\n[10] S. Downes, (2010), The role of the educator Hufﬁngton Post Educa-\ntion [Online] Available: http://hufﬁngtonpost .com/stephen-downes/\nthe-role-of-the-educa tor_b_790937.html\n[11] C. Alario-Hoyos, M. P/C19erez-Sanagust/C19ın, C. Delgado-Kloos, H. A. Parada G.,\nM. Mu ~noz-Organero, and A. Rodriguez-de-las-Heras, “Analysing the\nImpact of Built-in and External Social Tools in a MOOC on Educational\nTechnologies,” in Proc. 8th Eur. Conf. Technol. Enhanced Learning, 2013,\npp. 5–18.\nIEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014 265\n[12] H. Khalil and M. Ebner, “How satisﬁed are you with your MOOC? - A\nresearch study on interaction in huge online courses,” inProc. World Conf.\nEdu. Multimedia, Hypermedia and Telecommun., 2013, pp. 830–839.\n[13] G. Siemens, “Connectivism: A learning theory for the digital age,”Int. J.\nInstructional Technol. Distance Learning, vol. 2, no. 1, pp. 3–10, 2005.\n[14] F. Gr €unewald, E. Mazandarani, C. Meinel, R. Teusner, M. Totschnig, and C.\nWillems, “openHPI-a Case-Study on the emergence of two learning\ncommunities,” inProc. IEEE Global Eng. Edu. Conf., 2013, pp. 13–15.\n[15] C. Milligan, A. Littlejohn, and A. Margaryan, (2013), Patterns of engage-\nment in connectivist MOOCs MERLOT J. Online Learning Teaching, vol. 9,\nno. 2, [Online]. Available: http://jolt.merlot.org/vol9no2/milligan_0613.\nhtm\n[16] A. Littlejohn, C. Milligan, and A. Margaryan, “Collective learning in the\nworkplace: Important knowledge sharing behaviours,”Int. J. Advanced Cor-\nporate Learning, vol. 4, no. 4, pp. 26–31, 2011.\n[17] G. Fischer, “Understanding, fostering, and supporting cultures of partic-\nipation,” Magazine Interactions, vol. 18, no. 3, pp. 42–53, 2011.\n[18] R. Kop, H. Fournier, and S. F. J. Mak, “A pedagogy of abundance or a peda-\ngogy to support human beings? participant support on massive open\nonline courses,”Int. Rev. Res. Open Distance Learning, vol. 12, no. 7, pp. 74–\n93, 2011.\n[19] R. McGuire, (2013), Building a sense of community in MOOCs\n[Online]. Available: http://campustechnology.com/Articles/2013/09/\n03/Building-a-Sense-of-C ommunity-in-MOOCs.aspx\n[20] P. Hill, (2013), MOOC discussion forum: barrier to engangement? [Online].\nAvailable: http://mfeldstein.com/mooc-discussion-forums-barriers-\nengagement/\n[21] L. Breslow, D. E. Pritchard, J. DeBoer, G. S. Stump, A. D. Ho, and D. T. Sea-\nton, “Studying learning in the worldwide classroom: Research into edX’s\nﬁrst MOOC,”Res. Practice Assessment, vol. 8, pp. 13–25, 2013.\n[22] Y. Belanger and J. Thornton, (2013), Biolelectricity: A quantitative\napproach: Duke University’s ﬁrst MOOC, [Online]. Available: http://\ndukespace.lib.duke.edu/dspace/bitstream/handle/10161/6216/Duke_-\nBioelectricity_ MOOC_Fall2012.pdf\n[23] J. Manning and M. Sanders, (2013), How widely used are MOOC forums?\nA ﬁrst look, [Online]. Available: https://www.stanford.edu/dept/vpol/\ncgi-bin/wordpress/how-widely-used-are-mooc-forums-a-ﬁrst-look\n[24] MOOCs@Edinburgh Group (2013) “MOOCs @ Edinburgh 2013—Report\n#1,” Tech. Rep.[Online]. Available: http://hdl.handle.net/1842/6683.\n[25] T. van Treeck and M. Ebner, “How useful is twitter for learning in massive\ncommunities? An analysis of two MOOCs,” inTwitter & Society, K. Weller,\nA. Bruns, J. Burgess, M. Mahrt, and C. Puschmann, eds., Bern, Switzerland:\nPeter Lang, pp. 411–424, 2013.\n[26] N. Sclater, “Web 2.0, personal learning environments, and the future of\nlearning management systems,” Educause Res. Bulletin, vol. 2008, no. 13,\npp. 1–13, 2008.\n266 IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 7, NO. 3, JULY-SEPTEMBER 2014",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6842920184135437
    },
    {
      "name": "Empirical research",
      "score": 0.5489448308944702
    },
    {
      "name": "Data science",
      "score": 0.45037662982940674
    },
    {
      "name": "World Wide Web",
      "score": 0.42985352873802185
    },
    {
      "name": "Social media",
      "score": 0.42195022106170654
    },
    {
      "name": "Multimedia",
      "score": 0.3937651515007019
    },
    {
      "name": "Statistics",
      "score": 0.07372033596038818
    },
    {
      "name": "Mathematics",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I50357001",
      "name": "Universidad Carlos III de Madrid",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I162148367",
      "name": "Pontificia Universidad Católica de Chile",
      "country": "CL"
    },
    {
      "id": "https://openalex.org/I4210160189",
      "name": "Institut Polytechnique de Bordeaux",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210119061",
      "name": "Institut de Recherche en Informatique de Toulouse",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I4210152422",
      "name": "Université Toulouse - Jean Jaurès",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I134560555",
      "name": "Université Toulouse III - Paul Sabatier",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I3131550300",
      "name": "Université Toulouse-I-Capitole",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I88060688",
      "name": "Universidad Politécnica de Madrid",
      "country": "ES"
    }
  ],
  "cited_by": 111
}