{
  "title": "Retrieval-Augmented Controllable Review Generation",
  "url": "https://openalex.org/W3115828495",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2102148289",
      "name": "Ji-Hyeok Kim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2463447918",
      "name": "Seungtaek Choi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2771764204",
      "name": "Reinald Kim Amplayo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2162241770",
      "name": "Seung-won Hwang",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2962905474",
    "https://openalex.org/W2025605741",
    "https://openalex.org/W2889518897",
    "https://openalex.org/W2890419630",
    "https://openalex.org/W2573463306",
    "https://openalex.org/W1570031249",
    "https://openalex.org/W2798542795",
    "https://openalex.org/W2164079290",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2097726431",
    "https://openalex.org/W2950397305",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2963667126",
    "https://openalex.org/W2962965405",
    "https://openalex.org/W2885421725",
    "https://openalex.org/W2786744843",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W4230563027",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W1832693441",
    "https://openalex.org/W2251648804",
    "https://openalex.org/W2786983967",
    "https://openalex.org/W2798277467",
    "https://openalex.org/W2156718681",
    "https://openalex.org/W2119717200",
    "https://openalex.org/W2176263492",
    "https://openalex.org/W2341865734",
    "https://openalex.org/W2940154139",
    "https://openalex.org/W2964121744",
    "https://openalex.org/W2788330850",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2962950136",
    "https://openalex.org/W2890271771",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2606974598",
    "https://openalex.org/W2133564696",
    "https://openalex.org/W2740167620",
    "https://openalex.org/W2128507180",
    "https://openalex.org/W2963592583",
    "https://openalex.org/W2550132532",
    "https://openalex.org/W3098427234",
    "https://openalex.org/W2970909388",
    "https://openalex.org/W2493916176",
    "https://openalex.org/W2964238590",
    "https://openalex.org/W2739046565",
    "https://openalex.org/W2964329882",
    "https://openalex.org/W319996907",
    "https://openalex.org/W2902639680",
    "https://openalex.org/W2950670227",
    "https://openalex.org/W2125417976",
    "https://openalex.org/W2798463315"
  ],
  "abstract": "In this paper, we study review generation given a set of attribute identifiers which are user ID, product ID and rating. This is a difficult subtask of natural language generation since models are limited to the given identifiers, without any specific descriptive information regarding the inputs, when generating the text. The capacity of these models is thus confined and dependent to how well the models can capture vector representations of attributes. We thus propose to additionally leverage references, which are selected from a large pool of texts labeled with one of the attributes, as textual information that enriches inductive biases of given attributes. With these references, we can now pose the problem as an instance of text-to-text generation, which makes the task easier since texts that are syntactically, semantically similar with the output text are provided as input. Using this framework, we address issues such as selecting references from a large candidate set without textual context and improving the model complexity for generation. Our experiments show that our models improve over previous approaches on both automatic and human evaluation metrics.",
  "full_text": "Proceedings of the 28th International Conference on Computational Linguistics, pages 2284‚Äì2295\nBarcelona, Spain (Online), December 8-13, 2020\n2284\nRetrieval-Augmented Controllable Review Generation\nJihyeok Kim\nYonsei University\nzizi1532@yonsei.ac.kr\nSeungtaek Choi\nYonsei University\nhist0613@yonsei.ac.kr\nReinald Kim Amplayo\nUniversity of Edinburgh\nreinald.kim@ed.ac.uk\nSeung-won Hwang‚àó\nYonsei University\nseungwonh@yonsei.ac.kr\nAbstract\nIn this paper, we study review generation given a set of attribute identiÔ¨Åers which are user ID,\nproduct ID and rating. This is a difÔ¨Åcult subtask of natural language generation since models\nare limited to the given identiÔ¨Åers, without any speciÔ¨Åc descriptive information regarding the\ninputs, when generating the text. The capacity of these models is thus conÔ¨Åned and dependent\nto how well the models can capture vector representations of attributes. We thus propose to\nadditionally leverage references, which are selected from a large pool of texts labeled with one\nof the attributes, as textual information that enriches inductive biases of given attributes. With\nthese references, we can now pose the problem as an instance of text-to-text generation, which\nmakes the task easier since texts that are syntactically, semantically similar to the output text are\nprovided as inputs. Using this framework, we address issues such as selecting references from a\nlarge candidate set without textual context and improving the model complexity for generation.\nOur experiments show that our models improve over previous approaches on both automatic and\nhuman evaluation metrics.\n1 Introduction\nThe ultimate goal of opinion mining and sentiment analysis (Pang and Lee, 2008) is to automatically\ndigest opinions of users towards a certain product to accommodate decision making. While some of\nthese opinions are explicitly articulated in product reviews that users write, most of them are unknown\nsince users have not bought most of the products. Alternative solutions such as aspect-based sentiment\nanalysis (Mukherjee and Liu, 2012; Pontiki et al., 2016) and recommendation systems (Resnick and\nVarian, 1997; Bobadilla et al., 2013) exist, however these only offer superÔ¨Åcial outputs that are not as\nexpressive as textual reviews. Thus, the task of automatically generating reviews given their attributes\nsuch as user and product, or review generation (Dong et al., 2017), is necessary to achieve this goal.\nMost of the previous approaches (Dong et al., 2017; Sharma et al., 2018) have framed review gener-\nation as A2T (Attribute-to-Text problem), where the given input is a non-linguistic data ( i.e., attribute\nidentiÔ¨Åers for user, product, and rating) and the output is the review text. In this problem setup, the key\nchallenge is to learn rich representations of the attributes, which are then used to produce the text us-\ning either template-based surface realization methods (Kukich, 1983; McKeown, 1992) or neural-based\ndecoders (Mei et al., 2016; Wiseman et al., 2017), as shown in the red box in Figure 1. However, it is\ndifÔ¨Åcult to learn these representations merely from the given attribute identiÔ¨Åers since they do not convey\nany semantics regarding the attributes.\nOur key contribution isAT2T(Attribute-matched-Text-to-Text), of augmenting inductive biases of at-\ntributes with their matching reference reviews, as illustrated as the blue box in Figure 1. For example, as\nshown in Figure 1, multiple references together contain inductive biases such as frequently reviewed as-\npects of the product (e.g., talking about plot and character aspects) or habitual user phrases (e.g., ‚Äúlooking\nforward to the next book‚Äù). These references greatly help text generation since not only do they reinforce\n‚àóCorresponding author\nThis work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://\ncreativecommons.org/licenses/by/4.0/.\n2285\nAttributes\nùêó=References\nReferenceRetrievalùêó‚àó‚äÜùêó\nTextGeneration\nOutput\tText\n‚ãØ\n‚ãØ (ref\t#2)\tI\tenjoyedprevious\tbook.‚Ä¶but\tdisappointed\tat\tthis\tone,\t‚Ä¶too\tboring.(ref\t#3)\tit\twas\ta\tgreat\tread.\tNice\tplotand\tcharming\tcharacters.\tI\tam\tlooking\tforward\tto\tthe\tnext!\nI\treallyenjoyedthis\tbook\t!\tI\tloved\tthe\tcharactersand\tthe\tplot.\tI\tam\tlooking\tforward\tto\tthe\tnext\tbook\tin\tthe\tseries!\nSelected\tReferences(ref\t#1)\tcharacters\twereannoying\tand\tplot\twas\tboring.\nOutput\tText\nUserProduct\n#p3\nRating\n5ID#u1\n #u5\n#u1\n#u1\n#u1\n#p3\n#p8\n#p4\n#p3\n5\n5\n2\n3\nFigure 1: High-level diagram of frameworks of previous models (in red box) and our proposed model (in\nblue box), where we additionally make use of references to generate the output text.\nthe representations learned from the attributes, they also allow the use of techniques used in sequence-\nto-sequence learning such as attention (Bahdanau et al., 2015) and copy (See et al., 2017) mechanisms.\nIn related problem domains of generating abstractive summaries or dialogue utterances, such bias is in-\ntroduced by a T2T (Text-to-Text) approach, of generating an extractive summary Ô¨Årst (Gehrmann et al.,\n2018) or retrieving informative prior turns (Cai et al., 2018), then generating Ô¨Ånal outputs using these\nas references. Central to the framework is reference retrieval, since relevant references provide valuable\ncontext, but, in contrast, noisy references rather hinder generation.\nFor reference retrieval in T2T, lexical features, e.g., TF-IDF, have been used, assigning relevance\nbased on the degree of word overlap between two texts. In AT2T, however, lexical features are not\ndirectly applicable or effective. First, unlike T2T where input and output are both texts, our input is a\nlist of identiÔ¨Åers, i.e., (user ID, product ID, rating). As a result, we cannot expedite the process of Ô¨Ånding\nmatching references, as in T2T solutions using lexical features for fast retrieval,e.g., using inverted index.\nSecond, lexical similarity cannot fully capture rating, as sentiment lexicons appear in a small portion of\ntext (Li et al., 2018). For example, Ô¨Çipping a single lexicon (from ‚Äògood‚Äô to ‚Äòbad‚Äô) from lexically identical\nsentences can completely invert the rating. One alternative solution, complementing lexical similarity,\nis to assign additional credits to references labeled with the input rating. However, references ‚Äì labeled\nwith a different rating, but having useful rating-related context ‚Äì are forced to be penalized. For example,\nin Figure 1, no additional credits are assigned to ref#2 labeled with the nearly opposite rating, although\nit contains useful context for the given rating, e.g., ‚Äúenjoyed‚Äù. We later empirically show that neither\nlexical similarity nor rating accuracy of references guarantee rating semantics of generated reviews.\nTo address these limitations, we propose two approaches: pseudo-supervised and reinforcement\nlearning framework, denoted as SL and RL respectively. First, we expedite matching in SL using iden-\ntiÔ¨Åers. For efÔ¨Åcient retrieval without lexical features, we propose a parametric coarse-Ô¨Åltering approach\nusing attribute identiÔ¨Åers, having constant time complexity for each instance in a candidate pool. Sec-\nond, to generate reviews which are compatible with input rating, we retrieve references which maximize\nthe rating accuracy of generated reviews - rather than references labeled with the input rating. RL en-\nables such retrieval: a retrieval model is trained to maximize rewards including rating accuracy as well\nas lexical similarity of generated reviews.\nTo validate the effectiveness of AT2T, we perform experiments on a dataset consisting of product\nreviews from Amazon Books, aligned with their corresponding attributes: user, product and rating (Dong\net al., 2017). Our experiments using automatic evaluations show that utilizing relevant references hugely\nhelps generation in terms of content similarity, and rating accuracy. Moreover, our human evaluations\nshow that our model generates more informative and grammatical texts compared to previous models.\n2286\n2 Related Work\nData-to-Text Generation Our task is generally related to a suite of tasks on data-to-text (D2T) gen-\neration, where database tables (Wiseman et al., 2017), RDF graphs (Belz et al., 2011), and knowledge\nbase relations (Perez-Beltrachini et al., 2016) are explored as inputs. A variety of neural-based models\nhave been used on these tasks, including vanilla sequence-to-sequence models (Mei et al., 2016), ex-\ntended by explicitly incorporating context selection and planning (Puduppully et al., 2019a), by employ-\ning graph-based neural networks (Marcheggiani and Perez-Beltrachini, 2018), and by modeling entities\n(Puduppully et al., 2019b). While review generation is essentially a subtask of D2T, it is relatively under-\nstudied than other D2T tasks. Previous models include an encoder-decoder model with attention (Dong\net al., 2017), improved by including an objective function for rating accuracy (Sharma et al., 2018; Li and\nTuzhilin, 2019), by introducing a hierarchical decoder (Zang and Wan, 2017), by decomposing the de-\ncoding stage as coarse-to-Ô¨Åne manner (Li et al., 2019), and by using additional inputs such as user-given\nsummary (Ni and McAuley, 2018) or product description (Li and Tuzhilin, 2019). In this paper, we make\nperformance improvements by proposing a concept of leveraging references, and extensions proposed in\nthe aforementioned literature are orthogonal and thus applicable to improve our models further.\nAugmenting context using references While data-hungry neural models for some task may afford\nsufÔ¨Åcient training resources, some other tasks such as sentence-level classiÔ¨Åcation (Kim, 2014) and\nsummarization (Rush et al., 2015) suffer from limited context, given a single sentence as context. Review\ngeneration can be viewed as an extreme case of limited context, totally lacking textual context and thus\ndepending solely on a small set of attribute identiÔ¨Åers as input.\nFor text classiÔ¨Åcation tasks, solutions have been to increase the context, by adding inherent and in-\nduced metadata such as topics (Zhao and Mao, 2017) and translations (Amplayo et al., 2018). Meanwhile\nreferences have been used as additional source to augment context in text-to-text generation tasks such\nas summarization (Cao et al., 2018; Peng et al., 2019), machine translation (Gu et al., 2018), or dialogue\nsystem (Song et al., 2018; Pandey et al., 2018; Weston et al., 2018; Zhu et al., 2019). References can be\nseen as a new and effective additional context that introduces inductive biases of attributes that can only\nbe found in texts. However, retrieval task is much harder in our task than in previous tasks, as we have\ninputs of attribute identiÔ¨Åers having little information for retrieval.\n3 AT2T\nPretrainedGEN\n‚ãØ\n‚ãØ\n0.13\n0.87\n0.72\n0.28\nùë•#‚àó\nùë•%‚àó\nùêÄ=(u,p,r)\nùõº/0 0.92ùë•#1It\twas\tgreat\tread.Nice\tplot\tand\tcharming\tcharacters.I\tam\tlooking\tforward\ttothe\tnext\t!\nBiLSTM+ attention\n0.78 charming\tcharactersand\tinteresting\tplot\tùë•21\nBiLSTM+ attention\n0.75 This\tis\tmy\tfavorite\t!ùë•31\nBiLSTM+attention\nSelf-Attention\nCoarse-Grained\tREFLECT Fine-GrainedREFLECT\nùõº/4\nùõº/5\nùõº/6\nInput\tAttributes\nI\treally\tenjoyed\tthis\tbook!\tI\tloved\tthe\tcharacters\tand\tthe\tplot.\tI\tamlooking\tforward\tto\tthe\tnext\tbook\tin\tthe\tseries!Output\tText\tùêò‚Ä≤\nInput\tCandidate\tReferences\nComparingand\t\nComparingand\t\nùõº ùõº1\nFigure 2: The full architecture of R EFLECT when integrated to a generation model, which consists of\nthree components: Coarse-Grained R EFLECT , Fine-Grained R EFLECT , and the pretrained G EN model.\nWe use different encoders for Œ±and Œ±+ with the same identiÔ¨Åers A.\n2287\nThis work studies review generation task, where we are given review-speciÔ¨Åc attributes such as user,\nproduct, and rating, i.e., A = {u,p,r }as input and the corresponding review Y = {yi}L\ni=1 as output.\nWe reformulate the problem by introducing references. In review domain, references are reviews from\nthe training dataset that are either written by user uor written for product p. That is, references can be\nreviews from another user but from the same product, i.e., (u‚Ä≤,p) where u‚Ä≤ Ã∏= u, and vice versa 1. This\nintroduces an additional input to our text generation model: a set of N references X = {xj}N\nj=1, where\nxj = {wi}Lj\ni=1 is the jth reference with Lj tokens. Through this reformulation (AT2T), we can now pose\nthe task as text-to-text generation, where we generate an output given X and A as inputs.\nThe new problem setting introduces a major challenge since there can be a large number of references.\nAs most of the references are irrelevant, efÔ¨Åciently and effectively selecting the optimal K references\nX‚àó= {x‚àó\n1,...,x ‚àó\nK}‚äÜ X is one of the essential sub-tasks to AT2T. To this end, in AT2T, models consist\nof (1) reference selection modules (REFLECT ) where we select relevant referencesX‚àóto given attributes\nA and (2) a generation module (GEN) of utilizing references as inductive biases of the attributes.\nWhile, in T2T tasks, lexical features have been used for retrieval, those cannot be directly applied\nfor AT2T, having inputs of identiÔ¨Åers without text contents. To overcome such difÔ¨Åculty, we propose\ntwo approaches on retrieval stage with different learning schemes which are pseudo-supervised learning\n(SL) and reinforcement learning (RL). We Ô¨Årst introduce a SL method to construct trainable R EFLECT\nwithout text contents as inputs. Then, we propose to train REFLECT using RL where we enable the model\nto effectively preserve rating semantics. We show an overview of our approach in Figure 2.\n4 SL-R EFLECT\nGiven the attributes A and reference candidates X, R EFLECT selects the most relevant K references\nX‚àó = {x‚àó\n1,...,x ‚àó\nK}from X. In T2T tasks having texts as inputs, text-based, non-parametric matching\nhas been used for retrieval, e.g., TF-IDF. However, given only identiÔ¨Åers, we cannot use such matching.\nIn this section, we explore a pseudo-supervised learning approach to train parametric retrieval models.\nRelevance Pseudo-Supervision In contrast to T2T tasks, references should contain relevant contexts\nto the input rating, to guide G EN to generate a rating-consistent review. Although references largely\ncomprising of words presented in target review are useful for providing overall contents, lexical similarity\ndoes not guarantee semantic relevance especially for rating, e.g., two identical sentences with one word\ndifference such as ‚Äúgood‚Äù or ‚Äúbad‚Äù have signiÔ¨Åcant rating differences.\nTo consider rating information, we propose to generate a pseudo-labelzxj for each reference candidate\nxj. We use rating accuracy and lexical similarity which are linearly combined by Œª:\nzxj = (1‚àíŒª) ‚àóLEXSIM(xj,Y) +Œª‚àóI(r= rj), (1)\nwhere LEXSIM denotes lexical similarity between each reference candidatexj and a ground-truth review\nY, I(r = rj) is an indicator variable for rating accuracy (1 for the same rating, 0 otherwise), and Œªis\na balancing factor between lexical similarity and rating accuracy. We adopt average of uni-/bi-/quad-\ngram BLEUs (Papineni et al., 2002) as L EXSIM which was effective in our experiments. We train\nSL-REFLECT models using binary cross entropy as objective and zxj as supervision. Note that, the gold\nreview Y is only needed to provide supervision during training, and is not required for inference.\nCoarse-Grained REFLECT To maximize computational efÔ¨Åciency, previous approaches in T2T\ncoarsely retrieve the small number of promising references, X+ = {x+\n1 ,...,x +\nM}‚äÜ X, using efÔ¨Åcient\nmatching such as TF-IDF or inverted index, then rerank using more effective but expensive matching to\nselect best Kreferences, X‚àó‚äÜX+ where K <M ‚â™N.\nInstead of text-based matching which is not available in our task, we propose to use attribute-\nbased parametric matching, which has O(N) time complexity and is fully parallelizable. More for-\nmally, we match input attributes A with attributes of candidates AX = {Ax1 ,..., AxN }, where\n1Though sharing the same rating can also be a criteria for reference candidates, we empirically found this would increase\nthe candidate size too much, while we can apply rating bias by including rating accuracy in relevance supervision instead.\n2288\nAxj = {uxj ,pxj ,rxj }. We encode attribute features using embedding matrices followed by a fully\nconnect layer, and calculate relevance score using inner product between them. We denote concatenation\nof the attribute vectors for the input identiÔ¨Åers, u/p/r, by a ‚ààR3√ódc where dc is the number of fea-\ntures in vectors. For simplicity, we use different superscripts for a to indicate that different embedding\nmatrices are used with the same identiÔ¨Åers, and use different subscripts to indicate different identiÔ¨Åers.\nŒ±xj = tanh(Hxaxj ) ‚ààRdc (2)\nŒ±= tanh(Ha) ‚ààRdc (3)\ns(xj) =œÉ(Œ±‚ä§\nxj Œ±) ‚àà(0,1), (4)\nwhere axj and a are attribute vectors for Axj and A respectively, Hx and H are learnable matrices, and\nœÉdenotes sigmoid function. For axj and a, we share the same embedding matrices for efÔ¨Åcient training.\nFine-Grained REFLECT Now that we narrowed down toM ‚â™Nreference candidates, we can afford\nto use expensive textual input features. Fine-Grained R EFLECT accepts the references X+ as input and\noutputs a score for each candidate that is used to select the Ô¨Ånal Kreferences.\nTo get document-level encoding d+\nj for each candidate x+\nj , we use a bidirectional LSTM (Hochreiter\nand Schmidhuber, 1997) with attention pooling (Bahdanau et al., 2015) using A as attention query.\nŒ±+ = tanh(Ma+) ‚ààRdc (5)\nh+\nj = BiLSTM({w+\njk}\nL+\nj\nk=1) ‚ààRL+\nj √ódf (6)\nd+\nj = softmaxk(v‚ä§\natanh(Ha[h+\njk; Œ±+])h+\nj ‚ààRdf , (7)\nwhere a+ is obtained from another embedding matrix using A as identiÔ¨Åers, M and Ha are learnable\nmatrices and va ‚ààRdf is a learable vector. Note that, we use different parameters forŒ±in Equation 3 and\nŒ±+ in Equation 5 since different features are required for Coarse-Grained R EFLECT and Fine-Grained\nREFLECT : features for attribute-attribute matching and features for attribute-text matching respectively.\nWe also add a self-attention layer (Vaswani et al., 2017) to further contextualize reference{d+\nj }M\nj=1.\n[q; k; v]j = [Wq; Wk; Wv]d+\nj ‚ààRdf (8)\nÀúd+\nj = fFF\n(\nsoftmax\n(\nq‚ä§k‚àödf\n)\nv\n)\n‚ààRM√ódf , (9)\nwhere fFF is a residual feed-forward layer. Cross-reference contextualization further clariÔ¨Åes the mean-\ning of each reference by considering latent dependency over references (Liu and Lapata, 2019).\nThen, we estimate relevance score using inner product betweenÀúd+\nj and Œ±+, i.e., s(x+\nj ) =œÉ(Àúd+‚ä§\nj Œ±+).\n5 RL-R EFLECT\nSL has the advantage of efÔ¨Åcient selection of references by lexical and rating similarity, but this cannot\nguarantee generated documents would preserve such similarity. In addition, ‚Äúselection‚Äù of reference can\nbe generalized into ‚Äúcomposing‚Äù multiple documents. We Ô¨Årst concretely describe the motivation for\nintroducing RL-REFLECT using the example presented in Figure 1.\nPseudo-labels evaluate the lexical and rating similarity of the entire reference document, and encour-\nage to select ref#3 in Figure 1. However, in a hypothetical scenario without ref#3, ref#1 and ref#2 can\nbe ‚Äúcomposed‚Äù, with the former contributing to aspects to be discussed ( e.g., ‚Äúcharacter‚Äù and ‚Äúplot‚Äù)\nand the latter to rating (e.g., ‚Äúenjoyed‚Äù), while pseudo-labels may underestimate the importance of both.\nEspecially with respect to the goal of attaining rating semantics, pseudo-labels discourage R EFLECT\nto retrieve ref#2, with nearly opposite rating to the ground truth, though other aspects can guide the\ngeneration strongly.\nInstead, to compute the aggregated effect of partial contributions, we employ Reinforcement Learning\n(RL): We Ô¨Årst sample a set of references, generate a review using the references, and then estimate partial\n2289\nrelevance of those by how those are reÔ¨Çected in the generation. As illustrated with the above example,\nRL is better than SL, especially in scenarios where multiple references collaboratively contribute to the\ngeneration, while SL is comparable if some document is dominant in all aspects.\nSpeciÔ¨Åcally, training retrieval models using RL involves (1) sampling a set of references X‚àófrom a\ncandidate pool; (2) generating a reviewY‚Ä≤using GEN with X‚àó; (3) calculating a reward forX‚àóbased on\nY and Y‚Ä≤; and (4) adapting the sampling towards the direction to maximize the reward. We set reward\nfunction by replacing xj with Y‚Ä≤in the previously deÔ¨Åned formula on relevance score (Equation 1). To\nobtain rating accuracy of Y‚Ä≤, we Ô¨Årst train a standard sentiment classiÔ¨Åer comprising of a bidirectional\nLSTM layer followed by an attention pooling layer, and then predict rating ofY‚Ä≤using the classiÔ¨Åer. For\nefÔ¨Åcient RL training, we use Ô¨Åltered references by Coarse-Grained R EFLECT , i.e., X+, as candidates.\nA challenging part is adapting the sampling X‚àó(the 4th step described above) during training, since\nsampling is a discrete operation which breaks continuity of a function and thus violates differentiability\nassumption in standard backpropagation algorithm. Likelihood-ratio trick, proposed in (Williams, 1992),\nenables the backpropagation of gradients regardless of discrete sampling.\n‚àáJ =EœÑ[‚àálog p(X+)zY‚Ä≤] (10)\n‚âà1\nB\nB‚àë\nb=1\n‚àálog p(X+\nb )zb\nY‚Ä≤ (11)\nwhere p(X+) is probability distribution of selecting{x+\nj }M\nj=1 which is obtained by normalizing relevance\nscores, i.e., p(x+\nj ) =s(x+\nj )/‚àëM\nm=1 s(x+\nm), and Bis the number of sampling trials for approximation.\nStabilizing Training of RL Despite the above-mentioned strength of adapting to a heuristic scoring\nfunction for generation, RL training is notoriously unstable and converges slowly (Ranzato et al., 2015).\nOur key contribution is to make RL training practical. Note, we keep the weights of pretrained GEN Ô¨Åxed\nto keep RL training cost low. First, we use BLEU-1 as a proxy of look-ahead exploration. Compared\nto random exploration for all references increasing variance too much, we prioritize exploration to those\nwith high lexical similarity ( e.g., BLEU-1 no less than 0.2). We empirically found this prioritization\nreduces the variance without compromising the reference quality much. Second, as greedily maximizing\nfor Rinduces high variance, we maximizeR‚àíÀúRinstead of R, where ÀúRis a sub-optimal reward obtained\nby a baseline, speciÔ¨Åcally, p(X+) (Dong et al., 2018). Introducing a baseline performance is known to\ndecrease the variance (Weaver and Tao, 2001), and our experience was consistent.\n6 G EN\nGEN follows an encoder-decoder framework equipped with copying mechanism. First, we encode each\nreference x‚àó\nj with L‚àó\nj words using a bidirectional LSTM with attention pooling.\nh‚àó\nj = BiLSTM(x‚àó\nj) ‚ààRL‚àó\nj √óde\ng (12)\nd‚àó\ntj = softmaxk(v‚ä§\ngw tanh(Hgw [h‚àó\njk; agw ; ot])h‚àó\nj, (13)\nwhere vgw ,h‚àó\njk,d‚àó\ntj ‚ààRde\ng and ot ‚ààRdh\ng is a hidden state of decoder at t-th generation.\nAs in Fine-Grained REFLECT (Equation 8, 9), we further contextualize reference encodings,d‚àó\ntj, using\na self-attention layer, yielding Àúd‚àó\ntj. Then, we aggregate Àúd‚àó\ntj using another attention layer.\noref\nt = softmax(v‚ä§\ngxtanh(Hgx[Àúd‚àó\ntj; agx; ot])Àúd‚àó\nt, (14)\nwhere vgx,oref\nt ‚ààRde\ng and Àúd‚àó\nt ‚ààRK√óde\ng . Similar to encoding references, we attend over embedding\nvectors of input attributes, aemb ‚ààR3√óda\ng , yielding oemb\nt ‚ààRda\ng .\nFor decoder, we use a two-layer LSTM, and to obtain initial hidden state of LSTM, we use a multi-\nlayer perceptron following (Dong et al., 2017) taking attribute vectors as input.\nh0 = tanh(Waemb) ‚ààRdh\ng (15)\n2290\nFor each generation step, decoder uses both reference vectors oref\nt and attribute vectors oemb\nt .\not = 2-layer-LSTM(ot‚àí1,yt) ‚ààRdh\ng (16)\nst = tanh(Wo[oref\nt ; oemb\nt ; ht]) ‚ààRdh\ng (17)\ngt = softmax(Hsst), (18)\nwhere yt is generated word at step t.\nAs habitual words/phrases of users/products can be reused for generation, we allow G EN to copy\nwords from references.\nzt = œÉ(Wz[yt; ht; oemb\nt ; oref\nt ]) ‚àà(0,1) (19)\npt = zt √ógt + (1‚àízt) √óattt, (20)\nwhere att t is attention score distribution for words in references at Equation 13. For inference, we\ngreedily generate words by argmax-ing pt.\nTraining GEN We pretrain GEN using top-KBLEU-1 score references as inputs and cross-entropy on\ngold reviews as the loss function. When we trained G EN using retrieved references by R EFLECT , per-\nformance dropped signiÔ¨Åcantly. We suspect this is because even a small amount of irrelevant references\nmisguide training of GEN.\n7 Experiments\nWe used the same dataset used in (Dong et al., 2017) (Amazon Book reviews) to evaluate models. Each\ninstance in the dataset consists of a review and aligned attributes (user ID, product ID, and a rating\nranging from 1 to 5). Statistics of the number of references for each attribute are as follows: (1) mini-\nmum number of references is 6, 2, 13K for user, product, rating respectively, (2) maximum number of\nreferences is 1265, 351, 405K, and (3) average number of references is 33.34, 8.17, 131K.\n7.1 Training Details\nFor efÔ¨Åcient hyperparameter search on the vector dimension, we used 64 for attribute vectors (i.e.,dc,da\ng)\nfollowing (Dong et al., 2017), and for others we choose the best value among 128, 256, and 512 using\nvalidation set, where df,de\ng,dh\ng were 256, 128, and 512 respectively. Word embedding matrices for Fine-\nGrained REFLECT and GEN were pre-trained using fastText (Bojanowski et al., 2017). For the number\nof references, we set M and Kto be 50 and 10 respectively.\nFor training of G EN, we used the same setting with (Dong et al., 2017) including batch size, opti-\nmizer, learning rate scheduling, initialization of parameters, dropout ratio, and gradient clipping. We\nexcluded references having BLEU-1 score to ground-truth review less than 0.2. If all reference can-\ndidates are excluded, we set oref\nt as zero vector. For training of SL-R EFLECT , we set batch size to be\n50,000 and 150 for Coarse- and Fine-Grained R EFLECT respectively, and use Adam (Kingma and Ba,\n2015) optimizer with learning rate 0.001 for both models. For training of RL-R EFLECT , we set both\nthe number of samples B and batch size to be 50, and Œªto be 0.04. We searched the optimal Œªamong\n[0.0,0.02,0.04,0.06,0.08,0.1]. We used Adam optimizer with learning rate 0.0001. Our experiments\nwere conducted on a GTX-2080Ti GPU.\n7.2 Evaluation Results\nModels As baselines, we report performance of Attr2Seq (Dong et al., 2017) and Cyclegen (Sharma\net al., 2018) which use embedding vectors to encode given attributes. For our models, we report per-\nformance of G EN using retrieved references by Coarse- and Fine-Grained R EFLECT trained using SL\nand RL, denoted by GEN-C-F (SL) and GEN-C-F (RL) respectively2. In addition, we also report perfor-\nmances of RETRIEVE -C-F by evaluating the top-1 retrieved reference.\n2In our preliminary evaluation on G EN-C-F (SL‚ÜíRL) where we Ô¨Årst pretrained R EFLECT using SL and Ô¨Åne-tuned using\nRL and G EN-C-F (SL+RL) where we train R EFLECT by jointly optimizing both SL supervision and RL rewards, the models\nperformed poorly, so we do not consider such combination.\n2291\nModel Lexical Sim Phrase Sim Rating\nBLEU-1 BLEU-4 Accuracy\nBaseline\nAttr2Seq 30.48 5.03 -\nAttr2Seq‚Ä† 28.57 4.74 76.89\nCyclegen 30.63 5.46 -\nOurs RETRIEVE -C-F 30.28 4.85 80.33\nGEN-C-F (SL) 31.82 5.65 78.93\nGEN-C-F (RL) 32.03 5.58 84.48\nTable 1: BLEU and rating accuracy results on test dataset. We report performances of Attr2Seq model\nreported in the original paper, and of our best-effort implementation for unreported measures (denoted\nby Attr2Seq‚Ä†). Bold denotes the best result, and underlined denotes results outperforming all baselines.\nModel Output\nInput Attributes\nUser : hooked, men, family, love, stories , Mackenzie, Hart , series, Lilianna\nProduct : characters , looking, next, story , believable, fast, author, mystery, moving\nRating : 1\nGold Hart is a good author but I found this series short on content and characters lacking.\nLength and depth of story left you wanting more.\nAttr2Seq ‚Ä† I am not sure what to say about this book. I am not sure what I was expecting but I\nwas disappointed.\nRETRIEVE -C-F A chicks club with a difference, good fast moving story with believable\ncharacters . I will read more of this author and looking forward to the next book to this series.\nGEN -C-F (SL) The author has a great story line and the characters are great.\nI will read more of her books. I will read more of her work.\nGEN -C-F (RL) The beginning of the book was great, but the last ‚Äúnum‚Äù% of the book was boring\nand the characters were boring. I didn‚Äôt like the story and the characters .\nTable 2: Example generated outputs from four different systems. Bold-faced tokens are words that are\nalso found in the attribute-speciÔ¨Åc-frequent words. Words colored blue and red contain consistent and\ninconsistent rating information to the given rating respectively.\nMetrics We validate models based on two criteria and corresponding metrics as follows: (1) Con-\ntent similarity between generated reviews and ground-truth reviews can be measured by widely adapted\nmetric, BLEU (Papineni et al., 2002). (2) We measure rating accuracy via classiÔ¨Åcation accuracy of\ngenerated reviews using pretrained rating classiÔ¨Åer3.\nAutomatic Evaluation This section compares our model with existing baselines based on content\nsimilarity and rating accuracy. Results are presented in Table 1.\nRETRIEVE -C-F show worse performance compared to generation approaches including baselines, ex-\ncept for rating accuracy. This is because aspects or opinions to be discussed can be Ô¨Çexible depending\non input attributes, but retrieval approaches are limited to predicting existing reviews. On the other hand,\nGEN-C-F (RL) and Gen-C-F (SL) utilizing existing reviews as references signiÔ¨Åcantly outperform all\nbaselines. This validates our hypothesis that inductive biases improve generation performance, and our\nREFLECT models can retrieve helpful references.\nHuman Evaluation We also conducted human evaluations using Amazon Mechanical Turk system\nto evaluate 150 randomly sampled texts. We compared a retrieval model, R ETRIEVE -C-F, and three\ngeneration models including Attr2Seq‚Ä†, GEN-C-F (SL), and GEN-C-F (RL).\nFor each attribute pair, participants were asked to blindly compare outputs of the four models and\nannotate the best and worst. SpeciÔ¨Åcally, three participants were shown each paired four outputs as well\nas corresponding ground-truth text and were asked to decide which is the best and the worst according to\nthree criteria such as Informativeness (Does the review convey all information found in the gold standard\nreview?), Correctness (Is the information in the review factually accurate based on the information in the\n3We use a BiLSTM with an attention layer for the rating classiÔ¨Åer, which is trained using Amazon review dataset and\noptimized using cross entropy as objective function\n2292\ngold standard review?), and Compactness (Is the review written in a complete yet concise manner?).\nModel Best-Worst\nBaseline Attr2Seq‚Ä† -8.89%\nOurs\nRETRIEVE -C-F -2.22%\nGEN-C-F (SL) -0.67%\nGEN-C-F (RL) 11.78%\nTable 3: Human evaluation result.\nWe can then observe whether any model is\nsigniÔ¨Åcantly better in terms of Best-Worst Scal-\ning (Louviere and Woodworth, 1991) where the\npercentage of times it was selected as best sub-\ntracted by the percentage of times it was selected\nas worst. In Table 3, we can observe that G EN-\nC-F (RL) signiÔ¨Åcantly outperforms Attr2Seq‚Ä†as\nwell as RETRIEVE -C-F) at p< 0.05 using t-test.\nQualitative Example Table 2 shows examples of generated reviews from different models with given\nattributes for the given attributes. We also present frequently used words of the user and the product\nwhich are gathered by ranking words using TF-IDF.\nAs can be seen in the examples, Attr2Seq ‚Ä† tends to generate generic reviews, where the generated\nwords do not coincide with the attribute-speciÔ¨Åc-frequent words. R ETRIEVE -C-F is able to generate\nattribute-speciÔ¨Åc-frequent words such as characters and story, however it also outputs inconsistent infor-\nmation where rating semantic does not match to the given rating. Utilizing references as inputs, GEN-C-F\n(SL) and -F (RL) are also able to generate attribute-speciÔ¨Åc terms. For rating accuracy, while G EN-C-F\n(SL) generates words that are inconsistent with the given rating, such asgreat, GEN-C-F (RL), optimized\nto increase rating accuracy of generated reviews, is able to preserve rating accuracy.\nAnalysis on Rating Consistency We analyze contribution of rating accuracy for relevance of refer-\nences in Equation 1 on overall quality and rating consistency of generated reviews, where BLEU-1/4 and\nrating accuracy are adopted as evaluation metrics. We show results on Table 4.\nModel BLEU-1 BLEU-4 RA\nAttr2Seq‚Ä† 28.57 4.74 76.89\nGEN-C-F (SL) 31.82 5.65 78.93\n- RA 31.43 5.60 75.49\nGEN-C-F (RL) 32.03 5.58 84.48\n- RA 31.95 5.53 74.75\nTable 4: Ablation on relevance estimation. ‚ÄúRA‚Äù\ndenotes rating accuracy and ‚Äú-RA‚Äù indicates Œª = 0\nin Equation 1. We bold the best performance on\neach metric. Values colored red are performances\nweaker than that of Attr2Seq‚Ä†.\nIntroducing rating accuracy for relevance, in\naddition to lexical similarity, increased rating ac-\ncuracy of generated reviews, and even BLEU-\n1 and BLEU-4. Without rating accuracy, i.e.,\nŒª = 0 in Equation 1, both G EN-C-F (SL) and\nGEN-C-F (RL) produced lower rating accuracy\nof generated reviews than that of Attr2Seq ‚Ä†.\nThis shows that lexical similarity may fail to\ncapture rating semantics. Meanwhile, G EN-C-F\n(RL) signiÔ¨Åcantly outperformed G EN-C-F (SL)\non rating accuracy with little sacriÔ¨Åce of BLEU-\n4, which indicates that relevance of references\nregarding rating semantics should be determined\nbased on generated reviews rather than on references.\n8 Conclusion\nIn this work, we study the problem of review generation guided by reference documents. Attribute-\nspeciÔ¨Åc reference reviews provide useful inductive biases of given attributes, and such biases can be\nexplicitly delivered to generated reviews using copying mechanism. Inspired by promising results, as\nfuture work, we will investigate alternative means of guidance, such as keywords or topic distribution of\nattributes.\nAcknowledgements\nThis work was supported by AI Graduate School Program (2020-0-01361) and by the MSIT (Ministry\nof Science and ICT), Korea, under the ITRC (Information Technology Resarch Center) support program\n(IITP-2020-2016-0-00464) supervised by the IITP (Institute for Information Communications Technol-\nogy Planning Evaluation).\n2293\nReferences\nReinald Kim Amplayo, Kyungjae Lee, Jinyoung Yeo, and Seung-won Hwang. 2018. Translations as additional\ncontexts for sentence classiÔ¨Åcation. In IJCAI, pages 3955‚Äì3961.\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to\nalign and translate. In ICLR.\nAnja Belz, Mike White, Dominic Espinosa, Eric Kow, Deirdre Hogan, and Amanda Stent. 2011. The Ô¨Årst surface\nrealisation shared task: Overview and evaluation results. In ENLG, pages 217‚Äì226.\nJes¬¥us Bobadilla, Fernando Ortega, Antonio Hernando, and Abraham Guti ¬¥errez. 2013. Recommender systems\nsurvey. Knowledge-based systems, 46:109‚Äì132.\nPiotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with\nsubword information. Transactions of the Association for Computational Linguistics, 5:135‚Äì146.\nDeng Cai, Yan Wang, Victoria Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, and Shuming Shi. 2018. Skeleton-to-\nresponse: Dialogue generation guided by retrieval memory. arXiv preprint arXiv:1809.05296.\nZiqiang Cao, Wenjie Li, Sujian Li, and Furu Wei. 2018. Retrieve, rerank and rewrite: Soft template based neural\nsummarization. In ACL, pages 152‚Äì161.\nLi Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, and Ke Xu. 2017. Learning to generate product\nreviews from attributes. In EACL, pages 623‚Äì632.\nYue Dong, Yikang Shen, Eric Crawford, Herke van Hoof, and Jackie Chi Kit Cheung. 2018. Banditsum: Extrac-\ntive summarization as a contextual bandit. In EMNLP, pages 3739‚Äì3748.\nSebastian Gehrmann, Yuntian Deng, and Alexander M Rush. 2018. Bottom-up abstractive summarization. arXiv\npreprint arXiv:1808.10792.\nJiatao Gu, Yong Wang, Kyunghyun Cho, and Victor OK Li. 2018. Search engine guided neural machine transla-\ntion. In Thirty-Second AAAI Conference on ArtiÔ¨Åcial Intelligence.\nSepp Hochreiter and J ¬®urgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735‚Äì\n1780.\nYoon Kim. 2014. Convolutional neural networks for sentence classiÔ¨Åcation. In EMNLP, pages 1746‚Äì1751.\nDiederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In ICLR.\nKaren Kukich. 1983. Design of a knowledge-based report generator. In ACL, pages 145‚Äì150.\nPan Li and Alexander Tuzhilin. 2019. Towards controllable and personalized review generation. In Proceed-\nings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP) , pages 3237‚Äì3245, Hong Kong, China,\nNovember. Association for Computational Linguistics.\nJuncen Li, Robin Jia, He He, and Percy Liang. 2018. Delete, retrieve, generate: a simple approach to sentiment\nand style transfer. In NAACL-HLT, pages 1865‚Äì1874.\nJunyi Li, Wayne Xin Zhao, Ji-Rong Wen, and Yang Song. 2019. Generating long and informative reviews with\naspect-aware coarse-to-Ô¨Åne decoding. In Proceedings of the 57th Annual Meeting of the Association for Com-\nputational Linguistics, pages 1969‚Äì1979, Florence, Italy, July. Association for Computational Linguistics.\nYang Liu and Mirella Lapata. 2019. Hierarchical transformers for multi-document summarization. In ACL, pages\n5070‚Äì5081.\nJordan J Louviere and George G Woodworth. 1991. Best-worst scaling: A model for the largest difference\njudgments. University of Alberta: Working Paper.\nDiego Marcheggiani and Laura Perez-Beltrachini. 2018. Deep graph convolutional encoders for structured data to\ntext generation. In INLG, pages 1‚Äì9.\nKathleen R. McKeown. 1992. Text generation - using discourse strategies and focus constraints to generate\nnatural language text. Studies in natural language processing. Cambridge University Press.\n2294\nHongyuan Mei, Mohit Bansal, and Matthew R. Walter. 2016. What to talk about and how? selective generation\nusing lstms with coarse-to-Ô¨Åne alignment. In NAACL-HLT, pages 720‚Äì730.\nArjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In Proceedings\nof the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\n339‚Äì348, Jeju Island, Korea, July. Association for Computational Linguistics.\nJianmo Ni and Julian McAuley. 2018. Personalized review generation by expanding phrases and attending on\naspect-aware representations. In Proceedings of the 56th Annual Meeting of the Association for Computational\nLinguistics (Volume 2: Short Papers) , pages 706‚Äì711, Melbourne, Australia, July. Association for Computa-\ntional Linguistics.\nGaurav Pandey, Danish Contractor, Vineet Kumar, and Sachindra Joshi. 2018. Exemplar encoder-decoder for neu-\nral conversation generation. In Proceedings of the 56th Annual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 1329‚Äì1338.\nBo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1‚Äì135,\nJanuary.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation\nof machine translation. In ACL, pages 311‚Äì318.\nHao Peng, Ankur P. Parikh, Manaal Faruqui, Bhuwan Dhingra, and Dipanjan Das. 2019. Text generation with\nexemplar-based adaptive decoding. In NAACL-HLT, pages 2555‚Äì2565.\nLaura Perez-Beltrachini, Rania Sayed, and Claire Gardent. 2016. Building RDF content for data-to-text genera-\ntion. In COLING, pages 1493‚Äì1502.\nMaria Pontiki, Dimitris Galanis, Haris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar, Mohammad AL-\nSmadi, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing Qin, Orph¬¥ee De Clercq, V¬¥eronique Hoste, Marianna Apidi-\nanaki, Xavier Tannier, Natalia Loukachevitch, Evgeniy Kotelnikov, Nuria Bel, Salud Mar¬¥ƒ±a Jim¬¥enez-Zafra, and\nG¬®uls ¬∏en EryiÀògit. 2016. SemEval-2016 task 5: Aspect based sentiment analysis. In Proceedings of the 10th\nInternational Workshop on Semantic Evaluation (SemEval-2016) , pages 19‚Äì30, San Diego, California, June.\nAssociation for Computational Linguistics.\nRatish Puduppully, Li Dong, and Mirella Lapata. 2019a. Data-to-text generation with content selection and\nplanning. In AAAI, pages 6908‚Äì6915.\nRatish Puduppully, Li Dong, and Mirella Lapata. 2019b. Data-to-text generation with entity modeling. In ACL,\npages 2023‚Äì2035.\nMarc‚ÄôAurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2015. Sequence level training with\nrecurrent neural networks. arXiv preprint arXiv:1511.06732.\nPaul Resnick and Hal R Varian. 1997. Recommender systems. Communications of the ACM, 40(3):56‚Äì58.\nAlexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sentence\nsummarization. In EMNLP, pages 379‚Äì389.\nAbigail See, Peter J Liu, and Christopher D Manning. 2017. Get to the point: Summarization with pointer-\ngenerator networks. arXiv preprint arXiv:1704.04368.\nVasu Sharma, Harsh Sharma, Ankita Bishnu, and Labhesh Patel. 2018. Cyclegen: Cyclic consistency based\nproduct review generator from attributes. In INLG, pages 426‚Äì430.\nYiping Song, Cheng-Te Li, Jian-Yun Nie, Ming Zhang, Dongyan Zhao, and Rui Yan. 2018. An ensemble of\nretrieval-based and generation-based human-computer conversation systems. In Proceedings of the 27th Inter-\nnational Joint Conference on ArtiÔ¨Åcial Intelligence, pages 4382‚Äì4388.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and\nIllia Polosukhin. 2017. Attention is all you need. In NIPS, pages 5998‚Äì6008.\nLex Weaver and Nigel Tao. 2001. The optimal reward baseline for gradient-based reinforcement learning. In\nProceedings of the Seventeenth conference on Uncertainty in artiÔ¨Åcial intelligence , pages 538‚Äì545. Morgan\nKaufmann Publishers Inc.\n2295\nJason Weston, Emily Dinan, and Alexander H. Miller. 2018. Retrieve and reÔ¨Åne: Improved sequence generation\nmodels for dialogue. In Proceedings of the 2nd International Workshop on Search-Oriented Conversational AI,\nSCAI@EMNLP 2018, Brussels, Belgium, October 31, 2018, pages 87‚Äì92.\nRonald J. Williams. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learn-\ning. Machine Learning, 8:229‚Äì256.\nSam Wiseman, Stuart M. Shieber, and Alexander M. Rush. 2017. Challenges in data-to-document generation. In\nEMNLP, pages 2253‚Äì2263.\nHongyu Zang and Xiaojun Wan. 2017. Towards automatic generation of product reviews from aspect-sentiment\nscores. In INLG, pages 168‚Äì177.\nRui Zhao and Kezhi Mao. 2017. Topic-aware deep compositional models for sentence classiÔ¨Åcation. IEEE/ACM\nTrans. Audio, Speech & Language Processing, 25(2):248‚Äì260.\nQingfu Zhu, Lei Cui, Weinan Zhang, Furu Wei, and Ting Liu. 2019. Retrieval-enhanced adversarial training for\nneural response generation. In ACL, pages 3763‚Äì3773.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6774381399154663
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98677209",
      "name": "University of Edinburgh",
      "country": "GB"
    },
    {
      "id": "https://openalex.org/I193775966",
      "name": "Yonsei University",
      "country": "KR"
    }
  ]
}