{
  "title": "Generating Reasonable Legal Text through the Combination of Language Modeling and Question Answering",
  "url": "https://openalex.org/W3034827881",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A5059364615",
      "name": "Weijing Huang",
      "affiliations": [
        "Ping An (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5068672896",
      "name": "Xianfeng Liao",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5101504251",
      "name": "Zhiqiang Xie",
      "affiliations": [
        "University of Science and Technology of China"
      ]
    },
    {
      "id": "https://openalex.org/A5039717115",
      "name": "Qian Jiang",
      "affiliations": [
        "Ping An (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5047199971",
      "name": "Bojin Zhuang",
      "affiliations": [
        "Ping An (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5100702012",
      "name": "Shaojun Wang",
      "affiliations": [
        "Ping An (China)"
      ]
    },
    {
      "id": "https://openalex.org/A5016038454",
      "name": "Jing Xiao",
      "affiliations": [
        "Ping An (China)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2734914506",
    "https://openalex.org/W2970609357",
    "https://openalex.org/W2252136820",
    "https://openalex.org/W2989867050",
    "https://openalex.org/W6863994431",
    "https://openalex.org/W2970384151",
    "https://openalex.org/W2896391192",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2898875342",
    "https://openalex.org/W2945259830",
    "https://openalex.org/W2999854190",
    "https://openalex.org/W2856961199",
    "https://openalex.org/W2950444459",
    "https://openalex.org/W2951048068",
    "https://openalex.org/W2409591106",
    "https://openalex.org/W2427527485",
    "https://openalex.org/W2945844671",
    "https://openalex.org/W2788187279",
    "https://openalex.org/W2995346997",
    "https://openalex.org/W2890026792",
    "https://openalex.org/W2990192458",
    "https://openalex.org/W2963475460",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2970102799",
    "https://openalex.org/W2963448850",
    "https://openalex.org/W2998557616",
    "https://openalex.org/W2998733856",
    "https://openalex.org/W2951008357",
    "https://openalex.org/W3103181983",
    "https://openalex.org/W2962940365",
    "https://openalex.org/W2020073413",
    "https://openalex.org/W179875071",
    "https://openalex.org/W580074167",
    "https://openalex.org/W2983258080",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3014521650",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2129790556",
    "https://openalex.org/W2964059756"
  ],
  "abstract": "Due to the improvement of Language Modeling, the emerging NLP assistant tools aiming for text generation greatly reduce the human workload on writing documents. However, the generation of legal text faces greater challenges than ordinary texts because of its high requirement for keeping logic reasonable, which can not be guaranteed by Language Modeling right now. To generate reasonable legal documents, we propose a novel method CoLMQA, which (1) combines Language Modeling and Question Answering, (2) generates text with slots by Language Modeling, and (3) fills the slots by our proposed Question Answering method named Transformer-based Key-Value Memory Networks. In CoLMQA, the slots represent the text part that needs to be highly constrained by logic, such as the name of the law and the number of the law article. And the Question Answering fills the slots in context with the help of Legal Knowledge Base to keep logic reasonable. The experiment verifies the quality of legal documents generated by CoLMQA, surpassing the documents generated by pure Language Modeling.",
  "full_text": "Generating Reasonable\nLegal Text through the Combination of Language\nModeling and Question Answering\nWeijing Huang1 , Xianfeng Liao2∗ , Zhiqiang Xie2∗ , Jiang Qian1 , Bojin Zhuang1 ,\nShaojun Wang1 and Jing Xiao3\n1Ping An Technology\n2University of Science and Technology of China\n3Ping An Insurance (Group) Company of China\nhuangwaleking@gmail.com, sa1314hx@mail.ustc.edu.cn, earl.xiezhiqiang@foxmail.com,\n{qianjiang456, zhuangbojin232, wangshaojun851, xiaojing661 }@pingan.com.cn\nAbstract\nDue to the improvement of Language Modeling,\nthe emerging NLP assistant tools aiming for text\ngeneration can greatly reduce the human work-\nload on writing documents. However, the genera-\ntion of legal text faces greater challenges than or-\ndinary texts because of its high requirement for\nkeeping logic reasonable, which can not be guar-\nanteed by Language Modeling right now. To gener-\nate reasonable legal documents, we propose a novel\nmethod CoLMQA, which (1) combines Language\nModeling and Question Answering, (2) generates\ntexts with slots by Language Modeling, and (3)\nﬁlls the slots by our proposed Question Answer-\ning method named Transformer-based Key-Value\nMemory Networks. In CoLMQA, the slots repre-\nsent the part of the text that needs to be highly con-\nstrained by logic, such as the name of the law and\nthe number of the law article. And the Question\nAnswering ﬁlls the slots in context with the help\nof Legal Knowledge Base to keep logic reasonable.\nThe experiment veriﬁes the quality of legal docu-\nments generated by CoLMQA, surpassing the doc-\numents generated by pure Language Modeling.\n1 Introduction\nThe improvement of Language Modeling [Mikolov et al.,\n2010; Vaswani et al. , 2017; Radford et al. , 2018; Devlin et\nal., 2019 ] has greatly changed the landscape of NLP, and be-\ngin to shed lights on automatic text generation, which can\nreduce the human workload on writing documents. The suc-\ncessful examples are the smart reply [Kannan et al. , 2016 ]\nand the smart compose in Gmail, helping people to type the\nﬁxed daily utterances in e-mail editor.\nThe similar efforts have being made in the legal do-\nmain [Alschner and Skougarevskiy, 2017 ] to automati-\ncally generate the ofﬁcial legal documents, even since\n1990s [Branting, 1998]. However, the generating of legal text\nfaces greater challenges than ordinary texts due to its own\n∗Contribution\nduring internship at Ping An Technology.\ncharacteristics. There are at least two requirements for the\ngeneration of legal documents: (1) the syntax should be cor-\nrect, and (2) the logic should be reasonable. The syntax cor-\nrectness problem has been mainly relieved by the current pre-\ntrained-then-ﬁne-tuned language models such as GPT [Rad-\nford et al., 2018 ]. But the current language models still\nlack the ability to keep logical rationality [Mao et al., 2019;\nGuan et al., 2020 ]. For example, the text may be gener-\nated by a language model such as ”Someone misappropriated\n100,000 yuan of public funds. In accordance with Article 100\nof the Criminal Law of the People’s Republic of China 1, the\njudgment is as follows ...”, which is syntax-correct. But the\nlanguage model here does not know what Article 100 is, even\nit has been trained on a lot of judicial documents. In fact,\nArticle 100 in the Criminal Law of the People’s Republic of\nChina is about the crime reporting system, which logically\nconﬂicts with the fact of the misappropriation of public funds.\nIn another hand, the template-based generation seems a\npossible solution, but it needs large manual efforts for cre-\nating templates [Branting, 1998 ], and cannot be generalized\nto a more complex scenario. Meanwhile, a method for gen-\nerating variational templates is proposed [Ye et al., 2020 ]\nfor further generating text from tables, but can not be easily\nextended to the legal domain. However, the template-based\nmethod meets another challenge that requires the knowledge\nof implementing the templates to avoid logic conﬂicts.\nTo solve this problem, we introduce the Knowledge Base\nenhanced Question Answering technique to the existing lan-\nguage modeling in order to generate the logical part. In our\npilot study, when generating the ”Article 100”, the language\nmodel was very uncertain whether it was correct. In general,\nwhere the language model is uncertain, you can ask the sys-\ntem: what applicable law article should be applied to a certain\nperson who misappropriates 100,000 yuan of public funds?\nThe Question Answering component can look up the knowl-\nedge base and historical precedents, knowing that it is Article\n185 and Article 272 in the Criminal Law of the People’s Re-\npublic of China, which is further discussed in Subsection 4.3\nand Figure 3. We use the slots to represent the logical part\n1The English\nversion of the Criminal Law of the People’s Re-\npublic of China can be found on an ofﬁcial webpage https://www.\nfmprc.gov.cn/ce/cgvienna/eng/dbtyw/jdwt/crimelaw/t209043.htm.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3687\nneed to\nbe addressed in a QA system. And the slots can be\ngenerated as special tokens in a text sequence by a trained\nlanguage model.\nTo implement this idea, we propose a novel method\nCoLMQA, which (1) combines Language Modeling and\nQuestion Answering, (2) generates texts with slots by Lan-\nguage Modeling, and (3) ﬁlls the slots by our proposed Ques-\ntion Answering method named Transformer-based Key-Value\nMemory Networks.\nTo sum up, our contribution is mainly in four aspects. (1)\nWe convert the problem of keeping logic in the legal text\ngeneration into two sub-tasks of generating texts with slots\nand ﬁlling slots with the logical coherent values. (2) With\nthe guiding of this divide-and-conquer idea, we propose a\nmethod CoLMQA, which beneﬁts from the Language Model-\ning and Question Answering simultaneously. (3) We propose\na Transformer-based Key-Value Memory Networks, which\ncan encode a long query. (4) The experiment veriﬁes that\nCoLMQA can generate ﬂuent sentences with slots, and can\nﬁll in the correct values to keep the overall logical coherent.\n2 Related Works\nOn methodology, there are two orthogonal lines of research\nrelated to our work: language modeling and question answer-\ning. And the related works also include the NLP techniques\napplied to legal documents.\nLanguage modeling. The language models are used to pre-\ndict the words when given context, describing the statistical\npattern in a sequence, such as the n-gram in traditional statis-\ntical linguistics [Bellegarda, 2004]. With the development of\ndeep learning, neural language models like LSTM [Hochre-\niter and Schmidhuber, 1997 ] and RNNLM [Mikolov et\nal., 2010 ] enhance the prediction power. Furthermore, the\nTransformer-based neural language models [Vaswani et al. ,\n2017; Radford et al. , 2018; Devlin et al. , 2019 ] have greatly\nchanged the landscape of NLP.\nBoth traditional statistical language models and neural lan-\nguage models are trained on text corpora to memorize pat-\nterns. Although Petroni [2019] and Bouraoui [2020] point out\nthat the masked language model BERT [Devlin et al. , 2019 ]\ncan learn certain types of factual knowledge from large text\ncorpora, BERT cannot be used on the text generation task di-\nrectly. On the other hand, the autoregressive language model\nGPT [Radford et al., 2018], GPT-2 [Radford et al., 2019] can\ngenerate syntax-ﬂuent text, and see successful applications.\nBut GPT(-2) faces the problem of unabeling to generate\nfactual aware text [Logan et al., 2019; Mao et al., 2019; Guan\net al., 2020 ]. To generate reasonable stories, Mao [2019] and\nGuan [2020] both independently conducts the GPT-2’s multi-\ntask ﬁne-tuning on external common sense datasets (e.g.,\nConceptNet) to promote GPT-2’s awareness of facts. Unlike\ngenerating reasonable stories, our task places additional em-\nphasis on the preciseness of law article numbers to keep logic\nin the legal texts. Just like cardinal numbers in natural lan-\nguage need to be processed additionaly [Andor et al. , 2019 ],\nso are ordinal numbers in legal documents.\nQuestion answering. Question Answering is a big family\nof NLP tasks, including QA on Knowledge Base [Berant et\nal., 2013], machine reading comprehension [Rajpurkar et al.,\n2016], cloze-style QA [Das et al., 2017 ], etc. In a nutshell, it\nprovides answers to natural language questions. Our task of\nﬁlling correct values in generated legal text slots is equivalent\nto the cloze-style question answering.\nAdopting an external memory module, the memory net-\nworks [Weston et al., 2015; Sukhbaatar et al., 2015; Bor-\ndes et al., 2015 ] perform well on QA for mainly two rea-\nsons: (1) the addressing and reading on external memo-\nries help the multi-hop reasoning; (2) the memory mod-\nule can visit an external knowledge base and scale up to\ncomplex reasoning. Key-value memory networks [Miller\net al. , 2016 ] extends MemNNs by separating keys and val-\nues in memory module, making it suitable for reading the\n(key, value) style external knowledge [Das et al., 2017;\nXu et al., 2019 ]. The aforementioned memory networks ex-\nploit bag of words or RNN to encode queries, keys, and val-\nues but cannot encode very long texts well in our slots ﬁlling\nscenario. The closest work to ours is Generative Transformer\nMemory Network [Dinan et al., 2019 ], which employs Trans-\nformer as encoder and decoder in multi-turn dialogue. In our\nwork, the answer should be selected rather than generated to\nensure preciseness.\nLegal documents. It’s a big human workload to process\nmassive legal texts. So employing NLP methods in le-\ngal domain has attracted a lot of attention recently, for in-\nstance, charge prediction [Luo et al. , 2017; Hu et al. , 2018;\nChen et al., 2019 ], question answering [Zhong et al., 2020 ],\nand applicable law articles prediction [Zhong et al. , 2018 ].\nAnd the generation of legal texts also draws interests in the\nNLP community. Alschner [2017] proposed a modiﬁed RNN\nand applied on bilateral investment treaties. Ye [2018] pro-\nvided a seq2seq method to generate court views (written ex-\nplanation from judges) from criminal facts.\nThe legal documents can be roughly categorized as fol-\nlows: legislative, executive, judicial documents, and con-\ntracts [Gostoji´c and Markovi ´c, 2019 ]. The aforementioned\nmethods mainly focus on only one type of documents. How-\never, the contents of the law articles are in the legislative doc-\numents, while the numbers of the law articles are mentioned\nin the judicial documents. Therefore, combining them helps\nto generate reasonable legal documents.\n3 Problem Deﬁnition\nWe consider the problem of generating a reasonable legal\ndocument d when given a prompt π and a legal knowledge\nbase K. More speciﬁcally, we narrow down the type of le-\ngal document d to judicial document, so the prompt π is a\ntext sequence for describing the meta information of the judi-\ncial document, such as the criminal fact. A legal knowledge\nbase is formalized as K = {(ki, v i)}|K|\ni=1, where ki is the i-\nth law article and vi is the corresponding content. Then the\ntask of generating reasonable legal text is to ﬁnd out the best\ndocument d under the constraint between π and K, shown as\nEquation (1).\nd = arg max\nd′\np(d′|π, K). (1)\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3688\nIt’s\ninfeasible to get the global optimal solution in Equation\n(1) because of the huge search space O(|V|N ), where |V| is\nthe vocabulary size and N is the upper bound of document\nlength. To get approximation solutions, we decompose the\noriginal problem with the chain rule as follows: p(d′|π, K) =∏n\ni=1 p(si|π, K, s 1:i−1), where d′ = s1:n and si is the i-th\nsentence in document d′. We conduct the greedy search on\nthe decomposed parts to get the ﬁnal document, which means\nsearching a feasible solution for sentence si when given the\nprevious ones s1:i−1 at each step i. With the approximation,\nthe original problem is converted to the following one.\ns∗\ni = arg max\nsi\np(si|π, K, s 1:i−1) (2)\nAlthough the original optimization problem is relaxed, the\nnew one is still challenging because the sentence si relates to\nthe prompt π, previous sentences s1:i−1 and a legal knowl-\nedge base K simultaneously. We will show how to tackle the\nproblem proposed in Equation (2) through the combination of\nLanguage Modeling and Question Answering in Section 4.\n4 Method\nIn this section we discuss the main components of our pro-\nposed method CoLMQA.\n4.1 The Overall Architecture of CoLMQA\nBefore diving into the details of CoLMQA, recall the ”Keep\nCalm and Carry On” meme, which’s a typical phrase often\nbeing imitated, by keeping the slots but replacing values with\nothers, such as ”Keep Calm and Never Give Up”. Our method\nCoLMQA follows a similar style: generate texts with slots\nand ﬁll them on. In this example, ”Carry On” and ”Never\nGive Up” are two different values of the slots in the meme.\nMore speciﬁcally, we divide the challenging task deﬁned\nin Section 3 into two sub-tasks: (a) text generation with slots\nand (b) automatic ﬁlling slots based on the text context and\nknowledge base. Therefore, the optimization target in Equa-\ntion (2) can be further decomposed as Equation (3), where\ns(−)\ni is the sentence by keeping slots with placeholder, and\nv(+)\ni are the values of slots in sentence s(−)\ni need to be ﬁlled\nin. Then the optimization of Equation (2) is divided into two\nsub-tasks of optimization.\np(si|π, K, s 1:i−1) =p(s(−)\ni |π, K, s 1:i−1)\n· p(v(+)\ni |π, K, s 1:i−1, s (−)\ni )\n(3)\nIllustrated in Figure 1, CoLMQA contains three parts: the\ncontroller, the language modeling, and the question answer-\ning. The controller runs the text generation with the follow-\ning rules, and get the two sub-tasks in Equation (3) optimized\nseparately.\nRule 1 (LM). If there’s no slot in existing text, call LM to\ngenerate next sentence.\nRule 2 (QA). If there are slots in existing text, call QA to ﬁll\nslots.\nRule 3 (End). If there’s an END symbol in existing text, ﬁnish\nthe generation.\n/DZ\n7H[W\n&RQWUROOHU\n/DQJXDJH\u0003\n0RGHOLQJ\nZLWK\u0003VORWV\n6ORWV\u0010\nEDVHG\n4XHVWLRQ\u0003\n$QVZHULQJ\n.QRZOHGJH\u0003\n%DVH\n(1) generate next sentence\nwith slots\n(2) ﬁll slots\n(1)\n(0)\n(2)\n(2)\n(2)\nFigure 1:\nOverall Architecture of CoLMQA.\n4.2 Generating Texts with Slots by Language\nModeling\nAs shown in Figure 2, there are two phases in using a lan-\nguage model to generate texts with slots. The ﬁrst phase is\nﬁne-tuning. In this phase, after replacing the corresponding\nvalues in the original text with slots, we put the legal docu-\nments into a pre-trained model for ﬁne-tuning, where differ-\nent slots occupy different positions in the vocabulary.\nFine-tuning on Legal Document\n[CLS] s1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \ns1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \nsn\n<latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> \nsn\n<latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> <latexit sha1_base64=\"ll+2wH/s1CmU5RZnetXgyJVF8EM=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxmoQbXm1t0FyDrxClKDAq1B9as/TFgWc4VMUmN6nptikFONgkk+q/Qzw1PKJnTEe5YqGnMT5ItTZ+TCKkMSJdqWQrJQf0/kNDZmGoe2M6Y4NqveXPzP62UY3QS5UGmGXLHloiiTBBMy/5sMheYM5dQSyrSwtxI2ppoytOlUbAje6svrpN2oe27du7+qNRtFHGU4g3O4BA+uoQl30AIfGIzgGV7hzZHOi/PufCxbS04xcwp/4Hz+AFu2jcg=</latexit> \n/DQJXDJH\u00030RGHO\n\u000b3UH\u0010WUDLQHG\u0003*37\f\n…\ns1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \ns1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \ns2\n<latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> \ns2\n<latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> <latexit sha1_base64=\"Z9hJLS1IRlXq+CbxmCXGB1ZW9FY=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsJ+3SzSbsboQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MBVcG9f9dkobm1vbO+Xdyt7+weFR9fikrZNMMfRZIhLVDalGwSX6hhuB3VQhjUOBnXByO/c7T6g0T+SjmaYYxHQkecQZNVZ60IPGoFpz6+4CZJ14BalBgdag+tUfJiyLURomqNY9z01NkFNlOBM4q/QzjSllEzrCnqWSxqiDfHHqjFxYZUiiRNmShizU3xM5jbWexqHtjKkZ61VvLv7n9TIT3QQ5l2lmULLloigTxCRk/jcZcoXMiKkllClubyVsTBVlxqZTsSF4qy+vk3aj7rl17/6q1mwUcZThDM7hEjy4hibcQQt8YDCCZ3iFN0c4L86787FsLTnFzCn8gfP5AwDGjYw=</latexit> \nsn+1\n<latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> \nsn+1\n<latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> <latexit sha1_base64=\"HAVhmZzCtzQTFqrrpvZ+n3aZMp0=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIcyKoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCppkdJvb219Y3Nru7RT3t3bPzisHB23bJIZLpo8UYnphMwKJbVookQlOqkRLA6VaIfju5nffhLGykQ/4iQVQcyGWkaSM3RS2/ZzfelP+5UqrdE5yCrxC1KFAo1+5as3SHgWC41cMWu7Pk0xyJlByZWYlnuZFSnjYzYUXUc1i4UN8vm5U3LulAGJEuNKI5mrvydyFls7iUPXGTMc2WVvJv7ndTOMboNc6jRDofliUZQpggmZ/U4G0giOauII40a6WwkfMcM4uoTKLgR/+eVV0rqq+bTmP1xX67SIowSncAYX4MMN1OEeGtAEDmN4hld481LvxXv3Phata14xcwJ/4H3+APk7j0I=</latexit> \n…\nsi 2 Vword [ Vslots\n<latexit sha1_base64=\"eHFCY0+BoyuikdN2tA5P+CMnK4Y=\">AAACCHicbVC7TsMwFHXKq5RXgJEBiwqJqUoQEoyVWBiLRB9SE0WO47RWHTuyHVAVZWThV1gYQIiVT2Djb3DaDNBypCsdn3OvfO8JU0aVdpxvq7ayura+Ud9sbG3v7O7Z+wc9JTKJSRcLJuQgRIowyklXU83IIJUEJSEj/XByXfr9eyIVFfxOT1PiJ2jEaUwx0kYK7GMVUOhRDntB/iBkVEAPZ2n5UkxoVQR202k5M8Bl4lakCSp0AvvLiwTOEsI1Zkipoeuk2s+R1BQzUjS8TJEU4QkakaGhHCVE+fnskAKeGiWCsZCmuIYz9fdEjhKlpkloOhOkx2rRK8X/vGGm4ys/pzzNNOF4/lGcMagFLFOBEZUEazY1BGFJza4Qj5FEWJvsGiYEd/HkZdI7b7lOy729aLadKo46OAIn4Ay44BK0wQ3ogC7A4BE8g1fwZj1ZL9a79TFvrVnVzCH4A+vzB6HNmaw=</latexit> <latexit sha1_base64=\"eHFCY0+BoyuikdN2tA5P+CMnK4Y=\">AAACCHicbVC7TsMwFHXKq5RXgJEBiwqJqUoQEoyVWBiLRB9SE0WO47RWHTuyHVAVZWThV1gYQIiVT2Djb3DaDNBypCsdn3OvfO8JU0aVdpxvq7ayura+Ud9sbG3v7O7Z+wc9JTKJSRcLJuQgRIowyklXU83IIJUEJSEj/XByXfr9eyIVFfxOT1PiJ2jEaUwx0kYK7GMVUOhRDntB/iBkVEAPZ2n5UkxoVQR202k5M8Bl4lakCSp0AvvLiwTOEsI1Zkipoeuk2s+R1BQzUjS8TJEU4QkakaGhHCVE+fnskAKeGiWCsZCmuIYz9fdEjhKlpkloOhOkx2rRK8X/vGGm4ys/pzzNNOF4/lGcMagFLFOBEZUEazY1BGFJza4Qj5FEWJvsGiYEd/HkZdI7b7lOy729aLadKo46OAIn4Ay44BK0wQ3ogC7A4BE8g1fwZj1ZL9a79TFvrVnVzCH4A+vzB6HNmaw=</latexit> <latexit sha1_base64=\"eHFCY0+BoyuikdN2tA5P+CMnK4Y=\">AAACCHicbVC7TsMwFHXKq5RXgJEBiwqJqUoQEoyVWBiLRB9SE0WO47RWHTuyHVAVZWThV1gYQIiVT2Djb3DaDNBypCsdn3OvfO8JU0aVdpxvq7ayura+Ud9sbG3v7O7Z+wc9JTKJSRcLJuQgRIowyklXU83IIJUEJSEj/XByXfr9eyIVFfxOT1PiJ2jEaUwx0kYK7GMVUOhRDntB/iBkVEAPZ2n5UkxoVQR202k5M8Bl4lakCSp0AvvLiwTOEsI1Zkipoeuk2s+R1BQzUjS8TJEU4QkakaGhHCVE+fnskAKeGiWCsZCmuIYz9fdEjhKlpkloOhOkx2rRK8X/vGGm4ys/pzzNNOF4/lGcMagFLFOBEZUEazY1BGFJza4Qj5FEWJvsGiYEd/HkZdI7b7lOy729aLadKo46OAIn4Ay44BK0wQ3ogC7A4BE8g1fwZj1ZL9a79TFvrVnVzCH4A+vzB6HNmaw=</latexit> <latexit sha1_base64=\"eHFCY0+BoyuikdN2tA5P+CMnK4Y=\">AAACCHicbVC7TsMwFHXKq5RXgJEBiwqJqUoQEoyVWBiLRB9SE0WO47RWHTuyHVAVZWThV1gYQIiVT2Djb3DaDNBypCsdn3OvfO8JU0aVdpxvq7ayura+Ud9sbG3v7O7Z+wc9JTKJSRcLJuQgRIowyklXU83IIJUEJSEj/XByXfr9eyIVFfxOT1PiJ2jEaUwx0kYK7GMVUOhRDntB/iBkVEAPZ2n5UkxoVQR202k5M8Bl4lakCSp0AvvLiwTOEsI1Zkipoeuk2s+R1BQzUjS8TJEU4QkakaGhHCVE+fnskAKeGiWCsZCmuIYz9fdEjhKlpkloOhOkx2rRK8X/vGGm4ys/pzzNNOF4/lGcMagFLFOBEZUEazY1BGFJza4Qj5FEWJvsGiYEd/HkZdI7b7lOy729aLadKo46OAIn4Ay44BK0wQ3ogC7A4BE8g1fwZj1ZL9a79TFvrVnVzCH4A+vzB6HNmaw=</latexit> \n/DQJXDJH\u00030RGHO\n\u000b)LQH\u0010WXQHG\u0003*37\f\n[CLS] s1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \ns1\n<latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> <latexit sha1_base64=\"aUpErPFh11jWZfKf3vIWVK9aJ2o=\">AAAB6nicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKoMeCF48VTVtoQ9lsN+3SzSbsToQS+hO8eFDEq7/Im//GbZuDtj4YeLw3w8y8MJXCoOt+O6WNza3tnfJuZW//4PCoenzSNkmmGfdZIhPdDanhUijuo0DJu6nmNA4l74ST27nfeeLaiEQ94jTlQUxHSkSCUbTSgxl4g2rNrbsLkHXiFaQGBVqD6ld/mLAs5gqZpMb0PDfFIKcaBZN8VulnhqeUTeiI9yxVNOYmyBenzsiFVYYkSrQthWSh/p7IaWzMNA5tZ0xxbFa9ufif18swuglyodIMuWLLRVEmCSZk/jcZCs0ZyqkllGlhbyVsTDVlaNOp2BC81ZfXSbtR99y6d39VazaKOMpwBudwCR5cQxPuoAU+MBjBM7zCmyOdF+fd+Vi2lpxi5hT+wPn8Af8zjYs=</latexit> \nst\n<latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> \nst\n<latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> <latexit sha1_base64=\"JNO1MU6DgxYFnAJKYxmErYplJ2M=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LBbBU0mKUI8FLx4rmLbQhrLZbtqlm03YnQgl9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YSqFQdf9dkpb2zu7e+X9ysHh0fFJ9fSsY5JMM+6zRCa6F1LDpVDcR4GS91LNaRxK3g2ndwu/+8S1EYl6xFnKg5iOlYgEo2gl3wxznA+rNbfuLkE2iVeQGhRoD6tfg1HCspgrZJIa0/fcFIOcahRM8nllkBmeUjalY963VNGYmyBfHjsnV1YZkSjRthSSpfp7IqexMbM4tJ0xxYlZ9xbif14/w+g2yIVKM+SKrRZFmSSYkMXnZCQ0ZyhnllCmhb2VsAnVlKHNp2JD8NZf3iSdRt1z697DTa3VKOIowwVcwjV40IQW3EMbfGAg4Ble4c1Rzovz7nysWktOMXMOf+B8/gAprI7a</latexit> \n…\nst+1\n<latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> \nst+1\n<latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> <latexit sha1_base64=\"sLe+8SKrdJ5hno1el57sG81cDzw=\">AAAB7nicbVDLSgNBEOz1GeMr6tHLYBAEIeyIoMeAF48RzAOSJcxOZpMhs7PLTK8QlnyEFw+KePV7vPk3TpI9aGJBQ1HVTXdXmCpp0fe/vbX1jc2t7dJOeXdv/+CwcnTcsklmuGjyRCWmEzIrlNSiiRKV6KRGsDhUoh2O72Z++0kYKxP9iJNUBDEbahlJztBJbdvP8ZJO+5WqX/PnIKuEFqQKBRr9yldvkPAsFhq5YtZ2qZ9ikDODkisxLfcyK1LGx2wouo5qFgsb5PNzp+TcKQMSJcaVRjJXf0/kLLZ2EoeuM2Y4ssveTPzP62YY3Qa51GmGQvPFoihTBBMy+50MpBEc1cQRxo10txI+YoZxdAmVXQh0+eVV0rqqUb9GH66rdVrEUYJTOIMLoHADdbiHBjSBwxie4RXevNR78d69j0XrmlfMnMAfeJ8/AsGPSQ==</latexit> \n…\nQH[W\u0003VHQWHQFH\nSUHYLRXV\u0003VHQWHQFHV\nGeneration\nFigure 2:\nGeneration of texts with slots.\nThe second phase is to use the ﬁne-tuned language model\nto generate texts with slots. We choose GPT as the language\nmodel in our work. So Vwords is the original vocabulary used\nby the pre-trained GPT, and Vslots includes the additional\nplaceholders in the ﬁne-tuned GPT.\n4.3 Filling Slots by Transformer-based Key-value\nMemory Networks\nBrieﬂy, our proposed method is in a family of Key-Value\nMemory Networks [Miller et al., 2016; Das et al., 2017;\nXu et al., 2019 ], but enhanced by Transformer encoder. As\nXu [2019] pointed out, the standard Key-Value Memory Net-\nworks contain the following components: key hashing, key\naddressing, value reading, query updating, and answer pre-\ndiction, which also applies in our proposed method. And in\nthe above components, the standard KV-MemNNs exploit the\nbag of words to encode queries, keys, values, and candidate\nanswers. This straightforward approach is not appropriate to\nencode very long queries key-value pairs stored in the Legal\nKnowledge Base, as shown in a running example in Figure 4.\nEncoders. Transformer has shown its ability to capture the\nlong-range dependencies in natural language in GPT [Rad-\nford et al., 2018 ] and BERT [Devlin et al., 2019 ]. So rather\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3689\nKey Hashing (Information Retrive)\n4XHVWLRQ\n4XHVWLRQ\u0003\n(QFRGHU\n\u000b7UDQVIRUPHU\f\n.H\\\u0003\n(QFRGHU\n\u000b7UDQVIRUPHU\f\n9DOXH\u0003\n(QFRGHU\n\u000b7UDQVIRUPHU\f\n5HODWHG\n.H\\V\n5HODWHG\n9DOXHV\n$QVZHUV\u0003\n(QFRGHU\n\u000b7UDQVIRUPHU\f\n$OO\u0003\nSRVVLEOH\u0003\n$QVZHUV\n$WWHQWLRQ\u0003\n/D\\HU\nq k v\n&RQFDW\u0003\t\u0003\n/D\\HU1RUPT hops\nGRW\u0003\nSURGXFW\nc\nTransformer-based\nKey-Value Memory Networks\nq\no\nscores a for each candidate\nKey Addressing \n& Value Reading\nQuery Updating\nAnswer Prediction\nFigure 3:\nThe illustration of the Transformer-based key-value mem-\nory networks, a KB enhanced QA method for ﬁlling slots.\nthan encoding the input as a bag of words, we use Trans-\nformer. We append a special token, i.e., [CLS], at the tail\nof a sentence s, then input it into an encoder with n layer of\nTransformer encoder blocks. And then we use [CLS]’s corre-\nsponding output embedding enc[CLS] to represent the sentence\ns, and denote T ransformer (s) =enc[CLS] in s.\nSince the Transformer encoder are pre-trained on all\nqueries, keys, values, and candidate answers with an au-\ntoregressive task of predicting next words, the encoding of\n[CLS] can not be directly used in the Question Answering\ntask. So we apply a linear projection WLHS ∈ RH×H on\nT ransformer (s), where H is the hidden size of Trans-\nformer encoder.\nEquation (4) deﬁnes the Question Encoder in Figure 3,\ngiven the original query q as the input, to get the represen-\ntation q(0) as the output. And all encoders in Figure 3 use a\nsame Transformer.\nq(0) = WLHS · Transformer(q) (4)\nKey hashing. This component searches on the whole Le-\ngal Knowledge Base and gets query-related key-value pairs\nby conventional IR methods, e.g., TF-IDF or SQL selec-\ntion on speciﬁc ﬁelds. Because the IR method doesn’t go\ndeeper into the sentence-level semantics of the query, and\nkey-value pairs, we need to store them in memory and do\nre-organization by the remaining components.\nKey addressing and value reading. Key addressing re-\nﬂects the relatedness between keys and query, as shown in\nEquation (5) and Equation (6). Similar to the scaled dot-\nproduct attention in Transformer, we rescaled the relatedness\nscore p(t) with a factor of 1/\n√\nH when doing\nnormalization.\nThe superscript t indicates the t-th hop (iteration) in multi-\nhop reasoning, and no more than the number T of total hops.\np(t)\ni = (q(t))⊤(WLHS · Transformer(ki)) (5)\nQuery: . . . In a company, someone misappropriated 100,000 yuan of\npublic funds, according to Article [ARTICLE NUMBER] of the [LAW] ...\nAnswer: [ARTICLE NUMBER] = 272,\n[LAW] = Criminal Law of the People’s Republic of China\nRelated Keys & Values in Legal Knowledge Base\nKey(1): Criminal\nLaw of the\nPeople’s Republic\nof China,\nArticle 185\nValue(1): Personnel of banks or other monetary\ninstitutions who take advantage of their ofﬁce to\nmisappropriate funds of their respective institutions\nor customers are to be sentenced and punished in\naccordance with the stipulations of Article\n272 of this law. . .\nKey (2): Value (1) Value (2): Key (1)\nKey(3): Criminal\nLaw of the\nPeople’s Republic\nof China,\nArticle 272\nValue(3): When personnel of companies,\nenterprises, and other units, who take advantage\nof their ofﬁces to misappropriate their units’\nfunds for their own use or for lending to others,\nand the amounts involved are relatively large\nand have not been returned for a period of over\nthree months; . . .\nKey (4): Value (3) Value (4): Key (3)\netc.\nCandidate Answers:\nCriminal Law of the People’s Republic of China, Article 185;\nCriminal Law of the People’s Republic of China, Article 272;\netc.\nFigure 4:\nA running example of ﬁlling slots with KB enhanced QA.\nThe slots of [ARTICLE NUMBER], [LA\nW], and their context are\ntreated as the query. The values of slots are the answer. In this\nexample, the fact of misappropriating in a company leads to Article\n272 as the answer instead of Article 185, because the latter is about\nthe misappropriating in banks or other monetary institutions.\n˜p(t)\ni = exp (p(t)\ni /\n√\nH)\n∑\nj exp (p(t\n)\nj /\n√\nH)\n, for all i (6)\nV\nalue reading is given by Equation (7), summing the\nweighted encodings of values.\no(t) =\n∑\ni\n˜p(t)\ni · WLHS · Transformer(vi) (7)\nEssentially, key addressing and value reading implements\nan attention layer to select which values are used to answer\nthe query q(t).\nQuery updating. In the case of multi-hop reasoning, the\nquery needs to be updated after each hop of reading on KB,\nbecause the newly read-in values should also be treated as a\npart of the query. In the running example in Figure 4, the\nquery is to ask which law and article number applies to the\nfact of misappropriating in a company. After one hop, the\nfourth value in Figure 4 could answer the question. But in\na more complex situation, such as the misappropriating in a\nbank, one hop is not enough because Article 185 also refers\nto Article 272.\nWe concatenate the query representation q(t) and the repre-\nsentation of related values o(t), then map to the H dimension\nspace by the matrix M(t) ∈ RH×2H to be a new query q(t+1).\nq(t+1) = LayerNorm(M(t) · (q(t) ⊕ o(t))) (8)\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3690\nAnswer pr\nediction. Rather than picking up all keys in Le-\ngal Knowledge Base K as candidate answers like TextK-\nBQA [Das et al., 2017 ], we only conduct the similarity com-\nputation between q(T ) and the retrieved candidates by Equa-\ntions (9) and (10).\na(T )\ni = (q(T ))⊤ · WRHS · Transformer(ci), for i-th candidate\n(9)\nˆy(T ) = softmax(a(T )) (10)\nConsidering the article number and law in K plays three\nroles in the network, such as the keys, the values, and the\nanswers, we use a different matrix WRHS to do the necessary\ndecoupling in Equation (9). Finally, the loss of cross-entropy\nbetween the prediction score ˆy(T ) and the ground truth y is\ntaken for training the Transformer-based key-value memory\nnetworks.\nLoss(ˆy(T ), y ) =−\n∑\ni\nyi log ˆy(T )\ni (11)\n5 Empirical Study\nIn this section, we demonstrate the effectiveness of our pro-\nposed method CoLMQA in the following aspects. (1) We\nevaluate the quality of the generated texts with slots to show\nthe language model is capable of predicting the number of\nslots and the composition of slots and words, which is critical\nto our divide-and-conquer strategy. (2) Comparing to other\nQA methods, we test the accuracy of ﬁlling slots by our pro-\nposed Transformer-based key-value memory networks.\n5.1 Legal Document Dataset and Legal Knowledge\nBase\nLegal Document Dataset. All the experiments are con-\nducted on the judicial documents from China Judgements\nOnline2, which are widely used in NLP works in legal do-\nmain [Luo et al., 2017; Ye et al., 2018 ]. We crawled\n11,327,945 judicial documents from China Judgements On-\nline in 2015. The legal documents cover diverse branches of\nlaw. For instance, we tokenized the document titles with a\nChinese Tokenizer jieba 3, and do the quick overview of the\nwordcount, then ﬁnd out that the word ”dispute” appearing\nin 4,774,968 (42.1%) document titles, the word ”limited com-\npany” 30.5%, the word ”criminal” 17.2%, and the word ”di-\nvorce” 8.5%, etc.\nWe randomly select 20,000 documents from the dataset,\nsplitting to the training data, validation data, and testing data,\nwith the portion 80%, 10%, and 10%. By regular expres-\nsions, the fact descriptions, and court views are extracted.\nWe mainly consider the generation of court views, which is\nthe explanation for the charge. And court views contain the\napplicable law article to make the charge interpretable.\nLegal Knowledge Base. We collect the required legislative\ndocuments according to the law articles mentioned in the le-\ngal document dataset, e.g., the Criminal Law of the People’s\nRepublic of China. On the basis of the collected legislative\n2http://wenshu.court.gov\n.cn/\n3https://github.com/fxsjy/jieba\nwithout\nslots\nwith\nType A slots\nwith\nType B slots\nwith\nall slots\nRNN 0.131 0.198\n0.186 0.292\nGPT 0.238 0.441\n0.425 0.573\nGPT\n(pre-trained) 0.421 0.642\n0.573 0.682\nTable\n1: The F score of predicting law article slots (Type B slots) of\ndifferent language models, on test dataset.\nwithout\nslots\nwith\ntype A\nslots\nwith\ntype B slots\nwith\nall slots\nRNN 67.9 59.6 62.8 53.1\nGPT 12.8 10.3 11.9 8.2\nGPT\n(pre-trained) 11.3 8.8 10.5 7.8\nTable\n2: The perplexity on test dataset.\ndocuments, the regular expression and a ﬁnite-state machine\nare used to extract the (key, value) pairs, where the key rep-\nresents law article and value represents the detailed content.\nIn the end, the Legal Knowledge Base is built upon the 149\nlaws, civil codes, and interpretations, which appeared in the\naforementioned Legal Document Dataset.\n5.2 LM with Slots\nSlots Based on the level of uncertainty, we modeled 7 slots:\n[NAME], [DATE], [MONEY], [ADDRESS], [NUMBER],\n[LAW], [ARTICLE\nNUMBER]. W\ne use the regular expres-\nsion to replace the values in court views part in legal docu-\nments with the above slot placeholders. The ﬁrst ﬁve slots re-\nduce the uncertainty of language modeling. The last two slots\ncorrespond to two parts of a law article, which are the law’s\nname and the number pointing to the law article. They have\nspeciﬁc values in our built Legal Knowledge Base. These val-\nues can be obtained by reasoning based on the text content.\nTherefore, they are within the consideration of slot ﬁlling in\nour question-answering model. And we denote the ﬁrst ﬁve\nslots as the Type A slots and the last two slots as the Type\nB slots. The Type A slots used here is to demonstrate that\nlanguage models can beneﬁt from reducing the uncertainties\nwhen generating text, especially when they don’t have to pre-\ndict the exact number of [MONEY] or the value of [DATE].\nLanguage models with(out) slots. Language Models are\ncategorized into different groups depending on whether\ntrained with slots or without slots as shown in Table 1. We use\ntwo versions of GPT 4, pre-trained, and without pre-trained.\nThe former is pre-trained on a news dataset 5 which contains\n2.5 million news articles for one epoch on a 4× NVIDIA\nTesla V100 machine, and with the stride being 768. The se-\nquence length of the Transformer block used in both GPT ver-\nsions is 1024. The text generation sub-task is given a prompt\n(the facts part in a judicial document), then to generate a sen-\ntence by using the Beam search.\n4https://github.com/huggingf\nace/transformers\n5It’s news2016zh dataset in https://github.com/brightmart/nlp\nchinese corpus.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3691\nResult. In the\nﬁrst sub-task, after removing some highly un-\ncertain content and replacing it with slots, the language model\ncan generate more deterministic text and make the sentence\nmore ﬂuent as shown in Table 1 and Table 2.\nGiven a prompt, we use a language model to generate the\ncourt view that contains slots and then count the generated\nType B slots in it. The F score in Table 1 is computed be-\ntween two Type B slot sequences by matching one by one. As\na toy example, a ground truth in a court view containing slots\nlike ”in accordance with Article b and Article b of a”, where\na=[LAW], b=[ARTICLE\nNUMBER], and\nthe slot sequences\nin a generated text is like ”in accordance with Article b of a,\nArticle b of a, and Article b of a”. Then the precision of pre-\ndicting Type B slots ([LAW] and [ARTICLE\nNUMBER]) is\n1/6\nbecause the ﬁrst one slots are matched one by one, while\nthe recall of predicting Type B slots is 2/3 when considering\nthe total length of subsequences ”b*a” in the ground truth\nis matched by the generated sequence. The F score in this\ntoy example is 0.27. In this way, the F score is used to mea-\nsure how good the text sequence with slots is matched to the\nground truth. When computing the F score of the slots pre-\ndiction by using the model without slots, we do a manual\nconversion to replace the values with slots in the result.\nIn Table 1, we compare different language models and dif-\nferent settings and ﬁnd out that the pre-trained GPT can effec-\ntively generate a sentence with correct slots. In Table 2, the\nperplexity on the test dataset demonstrates that the generated\nsentence of the court view is ﬂuent when considering slots.\n5.3 Filling Slots by Transformer-based Key-Value\nMemory Networks\nConstruction of query-answer pairs. To derive the query-\nanswer training pairs from the Legal Document Dataset in\nSubsection 5.1, we consider different situations as follows.\nThe ﬁrst one is that a court view part in the legal judi-\ncial document only contains one applicable law article in the\nform of ”According to Article 263 of the Criminal Law of\n...”. In this case, the query in a query-answer pair is the text\nspan from the beginning to the position of current law ar-\nticle, while the value is the ground truth, e.g., Article 263\nof the Criminal Law. The second one is that a court view\ncontains more than one applicable law article with the same\nlaw, such as ”According to Article 263 and Article 269 of the\nCriminal Law”. In this one, we make multi tiny-modiﬁed\ncopies, Query1: ”According to [ARTICLE\nNUMBER] of\nthe\n[LAW]”, Query2: ”According to Article 263 and [ARTI-\nCLE NUMBER] of\nthe Criminal Law”. The third one is the\nmixing case, that different laws and different law articles are\ncited in a court view, which can be processed like the second\none. On average, there are 4.1 query-answer pairs produced\nper court view. And the average length of a query is 2783. For\nthe query which is longer than the sequence length of Trans-\nformer Encoder in TKVMemNN, we keep the tail part of the\nquery sequence, which is reasonable as the fact description\nappears more often in the tail part.\nTraining of our method. We use the ﬁrst four layers of\nTransformers in our pre-trained GPT as the encoder for\nqueries, keys, values, and answers in the experiment, then\ncarry out the two-phases ﬁne-tuning. The ﬁrst-phase ﬁne-\ntuning is conducted on the task of predicting the next words in\nthe sequences of queries, keys, and values. The second-phase\nﬁne-tuning is training the proposed model TKVMemNN on\nour constructed query-answer pairs and the Legal Knowledge\nBase. To conduct the multi-hop reasoning, we set the number\nof hops T as 3.\nBaselines. We use Whoosh (a Python IR open-source\ntoolkit), Memory Networks, and their variants with or with-\nout the document title as baselines. As the title are important\nfor providing additional information, such as the type of doc-\numents, they are useful for ﬁlling slots.\nBecause the computation of the dot product between the\nquery and the encodings of all the candidates in the Legal\nKnowledge Base is very expensive, we limit the number of\ncandidates in IR scope to improve the efﬁciency.\nMemNN Whoosh Whoosh\n+title TKVMemNN TKVMemNN\n+title\n0.23 0.13\n0.17 0.39 0.41\nTable\n3: The accuracy of ﬁlling slots.\nResult. In the second sub-task, the multi-hop reasoning on\nthe knowledge base makes the generated text more logical as\nillustrated in Table 3.\n6 Conclusion and Future Works\nIn order to solve the problem of conﬂicting logics appeared in\nthe text generated by a language model, we propose a novel\nmethod CoLMQA which beneﬁts from Language Modeling\nand Question Answering simultaneously. In the Language\nModeling component, the sentences with slots are generated\nand provided a well-written skeleton of sentences. And in\nthe Question Answering component, the slots are ﬁlled with\naccurate values with the help of Knowledge Base. In our ex-\nperiment, we veriﬁed that our method can ﬁll slots with logi-\ncal coherent values. In the future, we’ll expand CoLMQA to\nother scenarios of text generation which also require keeping\nlogic, but using different kinds of slots.\nAcknowledgments\nWe thank Xi Chen, Ni Li, Yan Cui, Mingkuo Ji, Jun Chen,\nYuren Wu, and Hanzhang Yang for helpful discussions.\nReferences\n[Alschner and Skougarevskiy, 2017 ] Wolfgang Alschner\nand Dmitriy Skougarevskiy. Towards an automated\nproduction of legal texts using recurrent neural networks.\nIn ICAIL, pages 229–232. ACM, 2017.\n[Andor et al., 2019] Daniel Andor, Luheng He, Kenton Lee,\nand Emily Pitler. Giving BERT a calculator: Finding op-\nerations and arguments with reading comprehension. In\nEMNLP, 2019.\n[Bellegarda, 2004] Jerome R Bellegarda. Statistical lan-\nguage model adaptation: review and perspectives. Speech\ncommunication, 42(1):93–108, 2004.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3692\n[Berant et al.\n, 2013] Jonathan Berant, Andrew Chou, Roy\nFrostig, and Percy Liang. Semantic parsing on Freebase\nfrom question-answer pairs. In EMNLP, 2013.\n[Bordes et al., 2015 ] Antoine Bordes, Nicolas Usunier,\nSumit Chopra, and Jason Weston. Large-scale simple\nquestion answering with memory networks. arXiv\npreprint arXiv:1506.02075, 2015.\n[Bouraoui et al., 2020] Zied Bouraoui, Jose Camacho-\nCollados, and Steven Schockaert. Inducing relational\nknowledge from bert. AAAI, 2020.\n[Branting, 1998] L Karl Branting. Techniques for automated\ndrafting of judicial documents. IJLIT, 6(2):214–229, 1998.\n[Chen et al., 2019 ] Huajie Chen, Deng Cai, Wei Dai, Zehui\nDai, and Yadong Ding. Charge-based prison term predic-\ntion with deep gating network. EMNLP, 2019.\n[Das et al., 2017] Rajarshi Das, Manzil Zaheer, Siva Reddy,\nand Andrew McCallum. Question answering on knowl-\nedge bases and text using universal schema and memory\nnetworks. In ACL, 2017.\n[Devlin et al., 2019 ] Jacob Devlin, Ming-Wei Chang, Ken-\nton Lee, and Kristina Toutanova. BERT: Pre-training of\ndeep bidirectional transformers for language understand-\ning. In ACL, 2019.\n[Dinan et al., 2019] Emily Dinan, Stephen Roller, Kurt\nShuster, Angela Fan, Michael Auli, and Jason Weston.\nWizard of wikipedia: Knowledge-powered conversational\nagents. In ICLR, 2019.\n[Gostoji´c and Markovi ´c, 2019] Stevan Gostoji ´c and Marko\nMarkovi´c. Legal document management: An integrated\napproach. In Sinteza 2019, pages 374–380, 2019.\n[Guan et al., 2020 ] Jian Guan, Fei Huang, Zhihao Zhao, Xi-\naoyan Zhu, and Minglie Huang. A knowledge-enhanced\npretraining model for commonsense story generation.\nTACL, 2020.\n[Hochreiter and Schmidhuber, 1997 ] Sepp Hochreiter and\nJ¨urgen Schmidhuber. Long short-term memory. Neural\ncomputation, 9(8):1735–1780, 1997.\n[Hu et al., 2018] Zikun Hu, Xiang Li, Cunchao Tu, Zhiyuan\nLiu, and Maosong Sun. Few-shot charge prediction with\ndiscriminative legal attributes. In COLING, 2018.\n[Kannan et al., 2016] Anjuli Kannan, Karol Kurach, Sujith\nRavi, Tobias Kaufmann, Andrew Tomkins, Balint Mik-\nlos, Greg Corrado, Laszlo Lukacs, Marina Ganea, Peter\nYoung, et al. Smart reply: Automated response suggestion\nfor email. In KDD, pages 955–964, 2016.\n[Logan et al., 2019] Robert Logan, Nelson F. Liu,\nMatthew E. Peters, Matt Gardner, and Sameer Singh.\nBarack’s wife hillary: Using knowledge graphs for\nfact-aware language modeling. In ACL, 2019.\n[Luo et al., 2017] Bingfeng Luo, Yansong Feng, Jianbo Xu,\nXiang Zhang, and Dongyan Zhao. Learning to predict\ncharges for criminal cases with legal basis. arXiv preprint\narXiv:1707.09168, 2017.\n[Mao et al., 2019] Huanru Henry Mao, Bodhisattwa Prasad\nMajumder, Julian McAuley, and Garrison W Cottrell. Im-\nproving neural story generation by targeted common sense\ngrounding. EMNLP, 2019.\n[Mikolov et al., 2010 ] Tom´aˇs Mikolov, Martin Karaﬁ ´at,\nLuk´aˇs Burget, Jan ˇCernock`y, and Sanjeev Khudanpur. Re-\ncurrent neural network based language model. In INTER-\nSPEECH, 2010.\n[Miller et al., 2016 ] Alexander Miller, Adam Fisch, Jesse\nDodge, Amir-Hossein Karimi, Antoine Bordes, and Jason\nWeston. Key-value memory networks for directly reading\ndocuments. In EMNLP, 2016.\n[Petroni et al., 2019] Fabio Petroni, Tim Rockt ¨aschel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H\nMiller, and Sebastian Riedel. Language models as\nknowledge bases? EMNLP, 2019.\n[Radford et al., 2018] Alec Radford, Karthik Narasimhan,\nTim Salimans, and Ilya Sutskever. Improving language\nunderstanding by generative pre-training. 2018.\n[Radford et al., 2019] Alec Radford, Jeffrey Wu, Rewon\nChild, David Luan, Dario Amodei, and Ilya Sutskever.\nLanguage models are unsupervised multitask learners.\nOpenAI Blog, 1(8), 2019.\n[Rajpurkar et al., 2016 ] Pranav Rajpurkar, Jian Zhang, Kon-\nstantin Lopyrev, and Percy Liang. SQuAD: 100,000+\nquestions for machine comprehension of text. In EMNLP,\n2016.\n[Sukhbaatar et al., 2015] Sainbayar Sukhbaatar, Arthur\nSzlam, Jason Weston, and Rob Fergus. End-to-end\nmemory networks. In NIPS, pages 2440–2448, 2015.\n[Vaswaniet al., 2017] Ashish Vaswani, Noam Shazeer, Niki\nParmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nŁukasz Kaiser, and Illia Polosukhin. Attention is all you\nneed. In NIPS, pages 5998–6008, 2017.\n[Weston et al., 2015] Jason Weston, Sumit Chopra, and An-\ntoine Bordes. Memory networks. ICLR, 2015.\n[Xu et al., 2019 ] Kun Xu, Yuxuan Lai, Yansong Feng, and\nZhiguo Wang. Enhancing key-value memory neural net-\nworks for knowledge based question answering. In ACL,\npages 2937–2947, 2019.\n[Ye et al., 2018 ] Hai Ye, Xin Jiang, Zhunchen Luo, and\nWenhan Chao. Interpretable charge predictions for crimi-\nnal cases: Learning to generate court views from fact de-\nscriptions. In NAACL, pages 1854–1864, 2018.\n[Ye et al., 2020 ] Rong Ye, Wenxian Shi, Hao Zhou, and Lei\nLi. Variational template machine for data-to-text genera-\ntion. In ICLR, 2020.\n[Zhong et al., 2018] Haoxi Zhong, Zhipeng Guo, Cunchao\nTu, Chaojun Xiao, Zhiyuan Liu, and Maosong Sun. Legal\njudgment prediction via topological learning. In EMNLP,\npages 3540–3549, 2018.\n[Zhong et al., 2020] Haoxi Zhong, Chaojun Xiao, Cunchao\nTu, Tianyang Zhang, Zhiyuan Liu, and Maosong Sun. Jec-\nqa: A legal-domain question answering dataset. AAAI,\n2020.\nProceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence (IJCAI-20)\n3693",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8174172639846802
    },
    {
      "name": "Question answering",
      "score": 0.6894416213035583
    },
    {
      "name": "Language model",
      "score": 0.627593994140625
    },
    {
      "name": "Transformer",
      "score": 0.5449373722076416
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5079708695411682
    },
    {
      "name": "Natural language processing",
      "score": 0.4704517424106598
    },
    {
      "name": "Key (lock)",
      "score": 0.4323952794075012
    },
    {
      "name": "Context (archaeology)",
      "score": 0.42885300517082214
    },
    {
      "name": "Engineering",
      "score": 0.0782952606678009
    },
    {
      "name": "Electrical engineering",
      "score": 0.06948146224021912
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4401726822",
      "name": "Ping An (China)",
      "country": null
    },
    {
      "id": "https://openalex.org/I126520041",
      "name": "University of Science and Technology of China",
      "country": "CN"
    }
  ],
  "cited_by": 10
}