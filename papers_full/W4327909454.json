{
    "title": "A foundation model for clinician-centered drug repurposing",
    "url": "https://openalex.org/W4327909454",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2097021629",
            "name": "Kexin Huang",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2625205325",
            "name": "Payal Chandak",
            "affiliations": [
                "Harvard–MIT Division of Health Sciences and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2158800269",
            "name": "Qianwen Wang",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A3186072721",
            "name": "Shreyas Havaldar",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2502250637",
            "name": "Akhil Vaid",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1878631932",
            "name": "Jure Leskovec",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2419298921",
            "name": "Girish Nadkarni",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1498187152",
            "name": "Benjamin S Glicksberg",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A257767137",
            "name": "Nils Gehlenborg",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2811250751",
            "name": "Marinka Zitnik",
            "affiliations": [
                "Broad Institute",
                "Harvard University Press",
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2097021629",
            "name": "Kexin Huang",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2625205325",
            "name": "Payal Chandak",
            "affiliations": [
                "Harvard–MIT Division of Health Sciences and Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2158800269",
            "name": "Qianwen Wang",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A3186072721",
            "name": "Shreyas Havaldar",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A2502250637",
            "name": "Akhil Vaid",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1878631932",
            "name": "Jure Leskovec",
            "affiliations": [
                "Stanford University"
            ]
        },
        {
            "id": "https://openalex.org/A2419298921",
            "name": "Girish Nadkarni",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A1498187152",
            "name": "Benjamin S Glicksberg",
            "affiliations": [
                "Icahn School of Medicine at Mount Sinai"
            ]
        },
        {
            "id": "https://openalex.org/A257767137",
            "name": "Nils Gehlenborg",
            "affiliations": [
                "Harvard University"
            ]
        },
        {
            "id": "https://openalex.org/A2811250751",
            "name": "Marinka Zitnik",
            "affiliations": [
                "Harvard University Press",
                "Broad Institute",
                "Harvard University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3095385778",
        "https://openalex.org/W4256014735",
        "https://openalex.org/W2896002881",
        "https://openalex.org/W4281297752",
        "https://openalex.org/W3118556611",
        "https://openalex.org/W2145321215",
        "https://openalex.org/W3017154096",
        "https://openalex.org/W4318983406",
        "https://openalex.org/W2056782561",
        "https://openalex.org/W2950411297",
        "https://openalex.org/W3100887812",
        "https://openalex.org/W2083045667",
        "https://openalex.org/W2062533676",
        "https://openalex.org/W3158868742",
        "https://openalex.org/W1990223774",
        "https://openalex.org/W2786016794",
        "https://openalex.org/W2263739890",
        "https://openalex.org/W2922229918",
        "https://openalex.org/W4381839562",
        "https://openalex.org/W3095380161",
        "https://openalex.org/W4304757966",
        "https://openalex.org/W2604314403",
        "https://openalex.org/W3012871709",
        "https://openalex.org/W2911286998",
        "https://openalex.org/W2911489562",
        "https://openalex.org/W3026047280",
        "https://openalex.org/W831206998",
        "https://openalex.org/W2952984539",
        "https://openalex.org/W3016970897",
        "https://openalex.org/W4327813569",
        "https://openalex.org/W4385567641",
        "https://openalex.org/W2318802957",
        "https://openalex.org/W2646300788",
        "https://openalex.org/W4365515961",
        "https://openalex.org/W3011881482",
        "https://openalex.org/W2990435446",
        "https://openalex.org/W4214710464",
        "https://openalex.org/W3092119378",
        "https://openalex.org/W2945719875",
        "https://openalex.org/W2104450197",
        "https://openalex.org/W2767891136",
        "https://openalex.org/W3215148291",
        "https://openalex.org/W4390571932",
        "https://openalex.org/W2918341242",
        "https://openalex.org/W1608814077",
        "https://openalex.org/W2184957013",
        "https://openalex.org/W2088263677",
        "https://openalex.org/W3103934428"
    ],
    "abstract": "Drug repurposing – identifying new therapeutic uses for approved drugs – is often serendipitous and opportunistic, expanding the use of drugs for new diseases. The clinical utility of drug repurposing AI models remains limited because the models focus narrowly on diseases for which some drugs already exist. Here, we introduce T x GNN, a graph foundation model for zero-shot drug repurposing, identifying therapeutic candidates even for diseases with limited treatment options or no existing drugs. Trained on a medical knowledge graph, T x GNN utilizes a graph neural network and metric-learning module to rank drugs as potential indications and contraindications across 17,080 diseases. When benchmarked against eight methods, T x GNN improves prediction accuracy for indications by 49.2% and contraindications by 35.1% under stringent zero-shot evaluation. To facilitate model interpretation, T x GNN’s Explainer module offers transparent insights into multi-hop medical knowledge paths that form T x GNN’s predictive rationales. Human evaluation of T x GNN’s Explainer showed that T x GNN’s predictions and explanations perform encouragingly on multiple axes of performance beyond accuracy. Many of T x GNN’s novel predictions align with off-label prescriptions clinicians make in a large healthcare system. T x GNN’s drug repurposing predictions are accurate, consistent with off-label drug use, and can be investigated by human experts through multi-hop interpretable rationales.",
    "full_text": "Zero-shot prediction of therapeutic use with geometric\ndeep learning and clinician centered design\nKexin Huang1,†,∗, Payal Chandak2,∗, Qianwen Wang1, Shreyas Havaldar3, Akhil Vaid3,4, Jure Leskovec5,\nGirish Nadkarni4, Benjamin S. Glicksberg3,4, Nils Gehlenborg1, and Marinka Zitnik1,6,7,‡\n1Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115\n2Harvard-MIT Program in Health Sciences and Technology, Cambridge, MA 02139\n3Hasso Plattner Institute for Digital Health, Icahn School of Medicine at Mount Sinai, NY 10029\n4Charles Bronfman Institute for Personalized Medicine, Icahn School of Medicine at Mount Sinai, NY 10029\n5Department of Computer Science, Stanford University, Stanford, CA 94305\n6Broad Institute of MIT and Harvard, Cambridge, MA 02142\n7Harvard Data Science Initiative, Cambridge, MA 02138\n†Present address: Department of Computer Science, Stanford University\n⋆ Equal contribution\n‡Corresponding author: marinka@hms.harvard.edu\nOf the several thousand diseases that affect humans, only about 500 have treatments ap-\nproved by the U.S. Food and Drug Administration. Even for those with approved treatments,\ndiscovering new drugs can offer alternative options that cause fewer side effects and replace\ndrugs that are ineffective for certain patient groups. However, identifying new therapeutic\nopportunities for diseases with limited treatment options remains a challenge, as existing al-\ngorithms often perform poorly. Here, we leverage recent advances in geometric deep learning\nand human-centered AI to introduce T XGNN, a model for identifying therapeutic oppor-\ntunities for diseases with limited treatment options and minimal molecular understanding.\nTXGNN is a graph neural network pre-trained on a comprehensive knowledge graph of\n17,080 clinically-recognized diseases and 7,957 therapeutic candidates. The model can pro-\ncess various therapeutic tasks, such as indication and contraindication prediction, in a uniﬁed\nformulation. Once trained, we show that T XGNN can perform zero-shot inference on new\ndiseases without additional parameters or ﬁne-tuning on ground truth labels. Evaluation\nof TXGNN shows signiﬁcant improvements over existing methods, with up to 49.2% higher\naccuracy in indication tasks and 35.1% higher accuracy in contraindication tasks. T XGNN\ncan also predict therapeutic use for new drugs developed since June 2021. To facilitate in-\nterpretation and analysis of the model’s predictions by clinicians, we develop a human-AI\nexplorer for T XGNN and evaluate its usability with medical experts. Finally, we demon-\nstrate that T XGNN’s novel predictions are consistent with off-label prescription decisions\nmade by clinicians in a large healthcare system. These label-efﬁcient and clinician-centered\nlearning systems pave the way for improvements for many therapeutic tasks.\n1\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nIntroduction\nA limited number of clinically-recognized diseases currently have approved treatments, under-\nscoring the pressing need to develop therapies to address the healthcare demands of billions glob-\nally. Diseases often arise due to disrupting normal gene behavior and the molecular products\nthey produce. Effective drugs can intervene against these diseases by restoring intended molecu-\nlar behaviors. However, restoring the biological functions of disrupted genes through therapeutic\ninterventions remains challenging for many diseases. Furthermore, most diseases are driven by\nalterations in more than one gene, wherein each gene can manifest with very different patterns of\nmutations across patients with the same disease. A powerful way to interpret these genetic events\nis to organize them into interactomes — networks of genes that participate in disease-associated\nprocesses and functions 1–3. Machine learning has been used to analyze high-throughput molec-\nular interactomes and electronic medical record data to unravel genetic architecture perturbed in\ndisease3, 4 and help design therapies to target them5. To provide therapeutic predictions, geometric\ndeep learning models optimized on protein interactomes6 can extract disease signatures and match\nthem to therapeutic candidates based on the proximity of their mechanisms to the disease-perturbed\nnetworks6–8.\nWhile successfully identifying therapeutic candidates for complex diseases9, 10, this approach\nconsiders diseases that already have extensive molecular signatures and existing treatment options.\nDespite the promising performance of this approach, its use in practice is hindered by the assump-\ntion that there are already known and similar drugs for a given disease of interest 11. However,\ndiseases with few or no therapies and limited molecular understanding have incomplete underly-\ning interactomes, leading to poorly predictive disease signatures and drastic drops in the ability of\ndeep learning models to identify therapeutic candidates 7, 11. The critical challenge is that models\nneed to make zero-shot predictions — identifying therapies for diseases that have not been en-\ncountered during training; a model needs to extend therapeutic predictions to new diseases without\nseeing any prior therapeutic information for them. This learning capability is essential because\nseveral thousand diseases affect humans, of which only about 500 have any U.S. Food and Drug\nAdministration-approved treatment (NIH’s National Center for Advancing Translational Sciences).\nOut of 17,080 clinically recognized diseases examined in our study, only 1,363 diseases have di-\nrectly indicated drugs, out of which 435 diseases have only one indicated medication, 182 have\ntwo indicated medications, and 128 have three indicated medications. Even for diseases with treat-\nments, ﬁnding new drugs is clinically impactful because it can give alternative treatment options\n2\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nwith less severe side effects and replacements for drugs that are ineffective in subsets of patients.\nHere, we introduce T XGNN, a geometric deep learning approach for therapeutic use pre-\ndiction, focusing on neglected diseases with a limited understanding of molecular mechanisms\nand treatment options. T XGNN is trained on a therapeutics-centered graph overlaid with disease-\nperturbed networks targeted by existing treatments. This knowledge graph collects and organizes\ndecades of biological research centering around 17,080 diseases, including complex and rare dis-\neases. T XGNN uses a graph neural network model to embed therapeutic candidates and dis-\neases into a latent representation space and is optimized to reﬂect the geometry of T XGNN’s\ntherapeutics-centered graph. To overcome the limitation of supervised deep learning in predicting\ntherapeutic use for neglected diseases, TXGNN uses a metric learning module that operates on the\nlatent representation space and can transfer T XGNN’s model from diseases encountered during\ntraining to unseen diseases.\nWe evaluate TXGNN for predicting indication and contraindication therapeutic use on sys-\ntematic, disease-area, and disease-centric hold-out datasets across 1,363 diseases. First, T XGNN\nshows consistently strong performance for neglected diseases in all settings. Across six settings,\nTXGNN gains up to 49.2% (average gain = 33.9%) in accuracy on predicting indications and up to\n35.1% (average gain = 26.8%) in accuracy on predicting contraindications compared to a state-of-\nthe-art graph neural network. Second, we evaluated T XGNN for diseases not encountered during\nmachine learning model training. T XGNN correctly identiﬁes therapies that recently (since June\n2021) received U.S. Food and Drug Administration approval, ranking belzutifan among the top\n4% of all therapeutic candidates for the treatment of a subset of von Hippel-Lindau cancers and\nfaricimab in the top 2% of all therapeutic candidates for neovascular age-related macular degen-\neration and diabetic macular edema. Third, novel predictions made by T XGNN predictions were\nevaluated against a large EHR phenotyping dataset (across 1,272,085,403 patients, 480 diseases,\nand 1,290 drugs), showing a 107% enrichment of likelihood of usage in real-world adoption com-\npared to non-prioritized predictions. Finally, T XGNN provides explanations for its predictions as\nreasoning paths that can guide human inquiry. We develop TXGNN Explorer, an interpretable and\ninteractive human-AI explorer that visually presents these reasoning paths to support and evalu-\nate its usability in a user study with a panel of 12 clinicians. T XGNN Explorer is available at\nhttp://txgnn.org.\n3\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nResults\nOverview of T XGNN’s therapeutics-centered dataset bridging molecular and phenotypic\nscales. Reasoning about therapeutic action requires knowing what genes are perturbed by dis-\nease and how those genes can be targeted by therapy to restore the function of disrupted genes. To\nbring this information together, we consider a therapeutics-centered graph uniﬁed across 20 data\nresources (Figure 1a)12 (Methods 1.1). Therapeutics-centered graph covers ten types of biological\nentities, including 27,671 protein-coding genes, 7,957 drugs, 17,080 clinically-recognized dis-\neases, 14,035 anatomy concepts, 28,642 biological processes, 4,176 cellular components, 11,169\nmolecular functions, 818 exposures, 15,311 disease phenotypes, and 2,516 pathways. It also in-\ncludes 29 types of relations among these entities, forming a connection map essential for under-\nstanding the mechanism of disease treatments. Further, the graph encodes physical protein-protein\ninteractions, information on combinatorial drug action, membership of genes in molecular path-\nways, and gene phenotypes for a total of 8,100,498 edges (Methods 1).\nThe dataset comprises 9,388 indications representing approved therapies covering 1,363 dis-\neases and 1,801 drugs. Further, it contains 30,675 contraindications split across 1,195 diseases,\nrepresenting conditions when a particular medication must not be taken because of the harm it\nwould cause the patient. On a median, a disease node is connected to 5 proteins, 14 phenotypes,\n3 other diseases, and 2 exposures in the graph (Supplementary Figure 1). These connections to\ndiverse entities enable machine learning models to fully determine the essential features of thera-\npeutic action. However, 15,717 diseases (92% of diseases) currently have no indicated therapies,\nand 15,885 diseases (93% of diseases) have no known contraindications, highlighting the need for\nstrategies to support research for diseases with no available therapies.\nMachine learning has proved helpful in identifying therapeutic opportunities for diseases for\nwhich some therapies already exist3–7, 9, 10. The approach is to retrieve additional candidate thera-\npies that are similar to existing ones across levels of biology13. However, this approach has limited\napplicability for diseases with incomplete biological mechanisms (Figure 1b) because a direct re-\nlationship between the disease and its candidate therapies does not exist 7, 11. Network proximity\nbetween diseases and candidate therapies is predictive of efﬁcacy9. The challenge, however, is that\ndiseases are on average multiple hops (avg=2.70 hops) away from their standard therapies in the\nknowledge graph — for example, herpes simplex virus (HSV) keratitis is found ﬁve hops away\nfrom idoxuridine in the T XGNN’s knowledge graph, and in another example, the shortest path\nlength between pityriasis simplex capitis and selenium sulﬁde is ﬁve; similarly Klebsiella pneu-\n4\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nmonia and clavulanic acid are ﬁve hops away from each other in the knowledge graph. While drugs\nindicated for diseases are signiﬁcantly closer to each other in the graph than their random coun-\nterparts (the average shortest path length between each disease and random set of drug molecules\nis 3.35), this observation indicates that models must consider several hops of indirect relationships\nfor accurate prediction.\nGeometric biological priors in T XGNN for therapeutic use prediction. TXGNN operates\non the principle that effective drugs target disease-perturbed networks in the protein interactome.\nTXGNN is a knowledge-grounded graph neural network (GNN) that maps therapeutic candidates\nand diseases (disease concepts) into the latent representation space, optimized to capture the ge-\nometry of TXGNN’s knowledge graph (Methods2.2). The latent representation model serves as a\nfoundation model for therapeutic prediction tasks — given a therapeutic candidate and a disease,\nTXGNN transforms points in the latent space representing the candidate and disease into predic-\ntions about their relationship (Figure 1c). We consider two therapeutic tasks: indication prediction\n(i.e., a disease that makes a particular treatment advisable) and contraindication prediction (i.e., a\ndisease that serves as a reason to avoid a certain medication due to the harmful adverse events that\nit would cause the patient).\nWhen only limited molecular information exists for a disease of interest, we can leverage\nmolecular mechanisms of other diseases in the knowledge graph to improve performance for the\npoorly annotated disease. In TXGNN, we obtain a disease signature vector for each disease based\non the set of neighboring proteins, exposures, and other biomedical entities. A normalized dot\nproduct between two disease signatures accounts for the amount of molecular entities shared be-\ntween diseases, serving as a disease similarity metric. These signatures can portray the disease\nsimilarity landscape, including many rare diseases (Figure 1d). Most disease pairs have low simi-\nlarity scores since they do not share mechanisms (e.g., T-substance anomaly and frontometaphyseal\ndysplasia have a score of 0.084). In contrast, the similarity is signiﬁcant if two diseases score rela-\ntively high (>0.2). For example, Wells syndrome and pemphigus erythematosus have a similarity\nof 0.433. Both are skin diseases caused by autoimmune disorders. However, there are differences\nin phenotypes where Wells syndrome exhibits redness and swelling, and the pemphigus exhibits\nblisters. There are also a few disease pairs with extremely high similarity scores. For example,\nPick’s disease and Alzheimer’s have a similarity of 0.909 since they share many of the same causes,\nbut Pick’s disease affects a speciﬁc part of the brain that controls emotions, behavior, personality,\nand language and thus have slightly different symptoms (e.g., no delusions, earlier onset). Thus,\n5\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nwe can retrieve a set of similar diseases for each disease, quantiﬁed by the number of overlapping\nentities.\nLeveraging the knowledge of retrieved diseases requires fusing it into the graph neural net-\nwork model. To that end, given a target disease, T XGNN generates embedding for each retrieved\ndisease. Then, it adaptively aggregates the embeddings in the metric learning module, weigh-\ning each retrieved disease by the target disease similarity. The aggregated output embedding is\na compact summary of knowledge borrowed from similar diseases fused with the target disease\nembedding. With the uniﬁed modeling, large-scale GNN training enables T XGNN to process\ndifferent downstream therapeutic tasks using shared drug and disease embeddings (Methods 2.3).\nFrom a graph machine learning perspective, T XGNN can be considered a domain prior-\nguided graph rewiring technique (Supplementary Figure 2) 14. Since T XGNN aggregates similar\ndisease nodes to the target disease node in the latent space, it is equivalent to generating new edges\nbetween the target disease and similar diseases (i.e., rewiring a set of disease nodes to the target\ndisease node). These new edges allow relevant disease module information captured in the embed-\ndings of similar diseases to ﬂow into the target disease embedding, which enables zero-shot predic-\ntions. This graph rewiring is guided by a domain prior because we select similar diseases using the\nlocal hypothesis in network medicine, as discussed in the intuition above. Without these rewired\nedges, the target disease embedding is not meaningful since there are few connected molecular\nnodes and zero treatment nodes to learn the embedding from. Technically, the low degree of these\ndisease nodes presents a network bottleneck, leading to difﬁculty in learning the embedding for\nthe disease node and its neighboring nodes (i.e., over-squashing) 14, 15. By rewiring disease nodes,\nwe enlarge the bottleneck and thus circumvent the over-squashing issue and improve the learning\nof a meaningful representation.\nBenchmarking T XGNN for zero-shot prediction of therapeutic use. We evaluate T XGNN\nfor indication and contraindication prediction. The model is evaluated for zero-shot performance,\nmeaning that it is asked to predict therapeutic use for diseases in the hold-out (test) set that are not\nseen during model training (i.e., zero of each disease’s indications or contraindications are avail-\nable to the model during training), which is the intended use of T XGNN for neglected diseases,\nsuch as Stargardt disease16 and hyperoxaluria17 that have no existing therapies. We use three strate-\ngies to construct hold-out datasets (Methods 3): systematic hold-outs\n(diseases in the hold-out set\nare selected at random), disease area hold-outs (for each disease area, all diseases in the area are\nput in a hold-out set), and disease-centric hold-outs (for each disease, a separate hold-out set is\n6\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nconstructed).\nZero-shot performance on therapeutic use prediction on systematic hold-outs . We ﬁrst con-\nsider systematic hold-out evaluation, where we exclude all known therapies for testing diseases\nfrom the dataset and ask the model to make predictions for these therapies. Biologically, the\nmodel is probed to predict diseases with no existing treatments, meaning no information about\ndrug similarities is available. Each random selection spans 103 never-before-seen diseases with\n495 indications and 1,729 contraindications.\nWe compare T XGNN to a state-of-the-art GNN 18 previously validated for therapeutic use\nprediction6–8, 19–21. The GNN performs poorly on realistic yet challenging systematic data splits.\nTXGNN outperforms GNN by 0.180 on average in AUPRC when identifying new indications,\nwhich is a 33.92% performance gain in predicting new indications for previously approved drug\nmolecules (Figure 2a). When identifying contraindications, T XGNN improves over the baseline\nby 0.133 in AUPRC, which is a 26.79% relative gain in identifying medical treatments that would\ncause harm to the patient (Figure 2b). Notably, in the systematic split where we test the model’s\ngeneralizability to diseases with no treatments, T XGNN achieves an AUPRC of 0.874 (49.2%\nincrease over GNN) when identifying indications and an AUPRC of 0.773 (35.1% increase over\nGNN) for contraindications.\nZero-shot performance on therapeutic use prediction for 5 disease areas\n. Biologically related\ndiseases may have similar treatments1. For example, the same chemotherapy can be indicated for\ntwo types of cancers. Thus, if the model encounters the therapy for one cancer type during training,\nit can easily predict the same treatment for related cancer when the model is deployed 11. This\nphenomenon is known as shortcut learning22, 23 and underlies many of deep learning’s failures24, 25:\nshortcuts are decision rules learned by the model that perform well on standard benchmarks but\nfail to transfer to challenging testing conditions 26, such as real-world scenarios when the model\nis asked to assist in the development of therapies for a new group of diseases (such as rare or\nneglected diseases) or diseases with no existing treatments.\nTo evaluate TXGNN in challenging testing conditions, we curate a stringent evaluation split\nwhere we evaluate model performance on a group of biologically related diseases referred to as a\ndisease area. Given a set of diseases in a disease area, all their indications and contraindications\nare removed from the training dataset. Further, a large fraction (95%) of the connections from\nbiomedical entities to these diseases are excluded from the training dataset. This removal sim-\nulates the diseases’ limited molecular characterization while having no existing treatments. We\n7\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nconsider ﬁve disease areas (Table 2): the cell proliferation hold-out has 213 diseases with a total\nof 1,022 indications and 1,079 contraindications; the mental health hold-out has 60 diseases with\n355 indications and 1,567 contraindications; the cardiovascular disease hold-out has 113 diseases\nwith 453 indications and 4,242 contraindications; the anemia hold-out has 19 diseases with 88\nindications and 752 contraindications; and lastly, the adrenal gland hold-out has 7 diseases with 41\nindications and 374 contraindications.\nWhile T XGNN consistently outperforms baselines on hold-out splits organized by disease\nareas, it performs exceptionally well on cell proliferation, anemia, and mental health-centric splits,\nwhere it achieves an absolute improvement of 0.270, 0.211, 0.162 on the AUPRC, which represents\nrelative gains of 46.54%, 44.60%, 34.23% over the GNN baseline, respectively (Figure2a-b). This\nﬁnding demonstrates that TXGNN is broadly generalizable and produces accurate predictions even\nin the most challenging setting when the same disease or related diseases from the same area are not\nin the training set of the machine learning model. Notably, on cell proliferation diseases, TXGNN\nachieves an AUPRC of 0.851, showing an accurate prediction model for oncology diseases even\nthough it has not seen any oncology disease during training.\nZero-shot performance for each of 1,363 diseases with indications and 1,195 diseases with\ncontraindications. Another type of hold-out evaluation we consider are disease-centric tests. To\nevaluate the therapeutic prediction accuracy for each disease, we consider known indications and\ncontraindications in the test set as hits and the rest of the drugs as negative samples and calcu-\nlate performance metrics. T XGNN successfully predicts therapeutic use with high precision for\ndiseases not seen by the model during training. For example, T XGNN ﬂags nine indications (be-\ntamethasone, triamcinolone, prednisone, hydrocortisone, prednisolone, methylprednisolone, dex-\namethasone, cortisone acetate, hydrocortisone acetate) for adrenal insufﬁciency without seeing\nthe disease in training with an AUPRC of 0.938. In the case of another disease, plasmablas-\ntic lymphoma has six indications. T XGNN assigns all six (carmustine, bleomycin, vincristine,\nprednisone, doxorubicin, dexamethasone) in the top 100 list with an AUPRC of 0.746. By con-\ntrast, anaplastic oligoastrocytoma has two contraindications, sirolimus, temsirolimus, and TXGNN\nidentiﬁes these contraindicated drugs correctly with an AUPRC of 0.833. Further, leiomyoma has\n24 contraindications, including diethylstilbestrol and chlorotrianisene, and T XGNN annotates 22\nof them in the top-100 list, achieving an AUPRC of 0.779. We have provided the disease and its\nperformance metrics in Supplementary Tables 1 and 2.\nPrioritizing indicated and contraindicated therapies with high sensitivity. Therapeutic use\n8\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nprediction models can prioritize therapeutic candidates to maximize the experimental and clinical\ninvestigation yield by focusing only on top-ranked candidates. We generate a list of the top-100\npredicted drugs for each disease and calculate the fraction of correct hits in the list (Recall@100).\nIn addition to comparing with the GNN, we include a non-guided screening baseline, randomly\nselecting 100 drugs as predicted indications/contraindications for a disease. This strategy is sim-\nilar to high-throughput screening without using machine learning for prioritization. The multi-\nrelational GNN baseline has a similar prioritization performance as non-guided screening. In\ncontrast, T XGNN performs consistently better across all evaluations. On predicting indications,\nTXGNN achieves, on average, 10.44 fold enrichment (from 5.94 - 13.11 folds) compared to non-\nguided screening (Figure 2c). Traditional GNN does not retrieve any hits for adrenal gland and\nanemia disease group splits and very few for mental health splits. On the other three splits (i.e.,\nno information about any disease and its treatment for the entire disease group is available to the\nmodel during training), TXGNN achieved 6.54 average fold enrichment over GNN. T XGNN can\nrecall more than 70% of hits in the top 100 predictions for systematic disease splits, adrenal gland\nsplits, and cell proliferation splits. In addition, it retrieves more than 45% hits for anemia and\nmental health splits, providing a generalist model for therapeutic use prediction.\nOn predicting contraindications, T XGNN achieves a 6.893 average folds enrichment over\nnon-guided screening and a 4.33 fold enrichment over GNN (Figure 2d). In addition, T XGNN\nachieves Recall@100=0.865 and Recall@100=0.689 for adrenal gland and cell proliferation dis-\neases, meaning it can retrieve most drugs that have harmful effects on adrenal gland and cell\nproliferation patients. For example, in the adrenal gland split, T XGNN prioritizes all 71 con-\ntraindications in the top 100 ranked list for familial glucocorticoid deﬁciency. Similarly, in the cell\nproliferation split, TXGNN correctly identiﬁes sirolimus and temsirolimus as the top-2 contraindi-\ncations for glioblastoma, and it predicts contraindicated indomethacin for colorectal cancer.\nIn 47 out of 189 cell proliferation diseases, T XGNN prioritizes all known treatments in\nthe top-10 ranked list out of more than 7,000 drug candidates. Without seeing any treatment for\nthe rare uterus tumor of adenosarcoma, T XGNN retrieves doxorubicin, dactinomycin, and vin-\ncristine as the 1st, 4th, and 5th most promising indications. This shows TXGNN’s ability even for\nmany rare diseases. On the mental health disease split, T XGNN achieves the best performance\nfor narcolepsy, a chronic sleep disorder characterized by overwhelming daytime drowsiness and\nsudden sleep attacks. T XGNN ranked six treatments among the top 10 predicted indications,\nmethylphenidate, modaﬁnil, dextroamphetamine, armodaﬁnil, pitolisant, and solriamfetol. Sepa-\n9\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nrately, out of 53 diseases in the cardiovascular disease group split, T XGNN predicts all known\nindications for eight diseases in the top 50 list. Notably, for a rare heart disease tetralogy of fallot,\ncaused by a combination of four heart defects, TXGNN assigns its ﬁrst-line therapy alprostadil as\nthe top-1 drug. On the anemia disease group split, TXGNN retrieves all treatments for 2 out of 12\nanemia diseases in the top-10 list. For instance, for beta thalassemia, a blood disorder that reduces\nthe production of hemoglobin, T XGNN predicts deferasirox, deferiprone, and luspatercept as the\ntop-3 ranked indications.\nUtility of geometric deep learning for therapeutic use prediction. We conduct a systematic\nstudy by modifying individual components of T XGNN to test their utility on the systematic dis-\nease split (Figure 2e). First, we remove the entire metric learning procedure, and it degrades to\nregular GNN (‘No-Metric’ ). We ﬁnd TXGNN has a 0.2884 AUPRC increase over the ablation for\nindication and 0.2008 AUPRC increase for contraindication. Then, we keep the metric learning\nprocedure but remove pretraining (‘No-Pretrain’). The ablation has 0.030 decrease in AUPRC and\nretrieves 7.5% fewer hits in the top 100 predictions for indication. We observe similar behaviors\nfor predicting contraindicated use, where ‘No-Pretrain’ leads to a 0.044 decrease in AUPRC and\nrecalls 7.7% fewer hits, showing that the biomedical knowledge-grounded pretraining strategy is\nvaluable and leads to positive knowledge transfer. To test the utility of degree-based aggrega-\ntion, we use a simple alternative by taking the average between the auxiliary and original disease\nembeddings (’Avg-Agg’). We ﬁnd TXGNN has relatively similar performances in indication pre-\ndiction but improves contraindication prediction by 0.022 in AUPRC and retrieves 1.8% more hits,\nshowing the usefulness of this component. Lastly, we experiment with two alternative strategies\nto calculate the disease signature, one is only using protein nodes to calculate disease similarity\n(‘Protein-Sig’), and another is a diffusion-based random walk signature (‘Walk-Sig’). We ﬁnd\nTXGNN retrieves 8.4%/5.4% more hits than ‘Protein-Sig’ and 9.6%/6.4% more hits than ‘Walk-\nSig’ in indication/contraindication prediction, respectively, suggesting the importance of signature\nselection to characterize the similarity among diseases.\nWe ﬁnd that each component is indispensable in the success of T XGNN. The deep metric\nlearning module is the key factor that drives T XGNN performance, corroborating our hypothesis\non disease similarity. To further understand the performance gain of the metric learning module\nfrom a machine learning standpoint, we explore the example of tonsillitis (Figure 4a). Diseases\nsimilar to tonsillitis (epiglottitis, peritonsillar abscess, nasopharyngitis, pharyngitis, vulvitis) are\ninitially distant in the embedding space. Thus, by fusing distant disease embeddings, TXGNN es-\n10\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \ntablishes a long-range skip connection to the disease module of these similar diseases and provides\ncomplementary information missing from the local neighborhood around the target disease. This\nis especially beneﬁcial in predicting therapeutic use for conditions with few or no treatments and\nlimited molecular understanding (Figure 1b). T XGNN uses disease signatures as a learnable dis-\nease look-up catalog to identify the appropriate distant disease information that can be transferred\nto the underpowered target disease.\nEvaluation of TXGNN predictions against recently developed therapies. To demonstrate that\nTXGNN is not driven by conﬁrmatory bias, we consider ten recently introduced therapies that\nwere approved after T XGNN’s dataset and model development were completed. None of these\ntherapies have direct relationships between their drug-disease nodes in the T XGNN dataset. We\nthen asked T XGNN to make predictions for them (Table 1). We observe that T XGNN consis-\ntently prioritizes newly introduced drugs highly. On average, the drugs are found in the ﬁrst third\n(30.19%) of the full-length prediction list. For example, T XGNN ranked Merck’s belzutifan, an\norphan drug that treats von Hippel-Lindau disease, among the top 4.11% therapeutic candidates.\nIt ranked faricimab, a biologic developed for macular degeneration, among the top 2.25% chem-\nicals. However, T XGNN ranked maribavir, an inhibitor of the cytomegalovirus (CMV) pUL97\nkinase used to treat CMV infections in patients post-transplantation, in the 66.37% of prediction\nlist — unsurprising, given that maribavir exerts its antiviral efﬁcacy via an alternative protein tar-\nget in CMV as compared to traditional CMV antivirals and that TXGNN dataset does not contain\ninformation about host-pathogen interactions.\nProducing AI-based reasoning paths and visual explanations for predictions. Even though\nTXGNN can produce accurate predictions of therapeutic use, these predictions require critical\nexamination and evaluation by clinicians. In addition to being accurate, predictive rationales ex-\ntracted by T XGNN from the dataset must be concise and interpretable. T XGNN uses a self-\nexplaining approach (GraphMask 27, Methods 2.6) to generate a sparse and sufﬁcient subgraph\nrelevant for therapeutic use prediction as the explanations. The approach produces an importance\nscore ranging from 0 to 1 for every edge in the dataset, where 1 means that the edge is crucial for\nthe prediction and 0 means that this edge is irrelevant to the prediction.\nThe self-explaining T XGNN model can extract high-quality sparse explanations around a\ndrug-disease query in the dataset. We trained ﬁve models with different data splits using the\nsystematic split. To measure the quality of model explanations, faithfulness is a theoretically-\ngrounded metric28, 29 that measures the performance gap between predictions using a sparse ex-\n11\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nplainable subgraph and the original predictions using the complete subgraph of a query drug-\ndisease pair. A small gap suggests that the explainer accurately selects edges crucial for T XGNN\nto make a prediction, i.e., the explanation is faithful to the rationale used by T XGNN predictor.\nThe self-explaining T XGNN model achieved high faithfulness, where, on average, the AUPRC\nhas only lost 0.98%. At the same time, the model extracts sparse and relevant information. For\nexample, setting a 0.5 threshold on self-explaining edge importance scores, 86.1% of all edges in\nsubgraphs are dropped. The user can also adjust the threshold to further ﬁlter to more important ex-\nplanations. The evaluation results show that the extracted explanations ﬁlter out non-informative\nconnections and contain a sparse set of meaningful relations that are necessary to make faithful\ndrug-disease predictions (Figure 3a, Methods 2.6). Next, we asked an important and insufﬁciently\nstudied question of how to represent best and visualize T XGNN-extracted explanatory rationales\nto support clinicians’ reasoning about therapeutic use. In developing human-AI TXGNN Explorer,\nwe took a user-centric approach by comparing three visual explanations for displaying GNN ex-\nplanations, i.e., neighbor nodes around the query disease, subgraphs, and paths (Figure 3a, Sup-\nplementary Figure 4). Our studies showed that path explanations improve user performance and\nsatisfaction compared to neighbor and subgraph explanations30.\nVisual explanations have the potential to guide clinical inquiry into predictions.Improving the\ninteraction between humans and machines is essential for successful collaboration between medi-\ncal experts and AI31, 32. This is crucial to prevent common pitfalls, such as over-reliance on model\npredictions without independent expert evaluation, displaying limited trust in model predictions\neven when they provide valuable information, and avoiding opaque judgments. Moreover, even\nwhen medical experts have an appropriate level of conﬁdence in TXGNN’s predictions, they may\nbe unable to determine whether predictions are reliable. To evaluate and understand how clinicians\nuse model predictions and explanations, we conduct a user study (Supplementary Figure 5) with 12\nclinicians and summarize results in Figure 3c. We ﬁnd that providing visual explanations can im-\nprove clinicians’ performance in evaluating model predictions (i.e., whether a predicted drug can\nbe used to treat a disease). Compared with the no explanation baseline, TXGNN Explorer enables\nclinicians to more accurately assess a predicted drug-disease relation (t(11) = 2 .76,p < 0.05).\nSince we showed study participants both correct and incorrect predictions, higher accuracy indi-\ncates not only that participants tend to trust model predictions but also that they can better distin-\nguish between correct and incorrect predictions while using T XGNN Explorer. We also observed\nhigher self-reported satisfaction levels when using T XGNN Explorer compared to the baseline.\n12\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nParticipants reported higher usability for path-based explanations than neighboring node-based\nor subgraph-based model explanations, as measured by User Trust, Model Helpfulness, Under-\nstandability, and Willingness to Use. Using TXGNN Explorer, 91.6 (11/12) participants (strongly)\nagreed that TXGNN’s predictions and explanations are valuable. On the contrary, without explana-\ntion, 75.0% (8/12) participants (strongly) disagreed with using TXGNN’s predictions. Participants\nalso report a higher level of conﬁdence in correct model predictions (t(11) = 3.64,p< 0.01) when\nusing TXGNN Explorer over a baseline that does not use a human-AI explorer. Some participants\nstated that the path-based explanations provide helpful information for planning the downstream\nevaluation, such as examining biological mechanisms and possible adverse effects of predicted\ntherapeutic candidates. T XGNN Explorer provides experimental evidence of effective human-AI\ncollaboration for therapeutic use prediction.\nEvaluation of most promising predictions in a large electronic health record system. The\nabove evaluations show that TXGNN can retrieve promising therapeutic candidates by recovering\nthe known indications. T XGNN’s performance suggests that its novel predictions (i.e., therapies\nthat are not yet FDA-approved for a disease but are ranked high in T XGNN) could potentially\nhave clinical value. Since these predictions are not approved treatment indications, there is no gold\nstandard information to validate against. Motivated by prevalent off-label drug prescriptions in\nclinical practice, we use the enrichment of disease-drug pair co-occurrence in an extensive health\nsystem’s electronic health records (EHR) as a proxy measure of a potential indication. In particular,\nwe used data from the Mount Sinai Health System to curate a cohort of 1,272,085 patients with\n480 diseases and 1,290 drugs. The cohort included all patients over 18 years of age with at least\none drug and at least one diagnosis in the system until 2022. Diseases were included if at least\none patient had a diagnosis in the dataset; drugs were included if at least ten patients were listed\nwith the drug and an order date (Table 5 and Methods 3.7). The enrichment of disease-drug co-\noccurrence can be quantiﬁed by the ratio between the odds of using a particular drug given the\ndisease and the odds of using that drug given other diseases. We obtain 619,200 log-odds ratios\n(Log-OR) for every disease and drug pair matched to the EHR system. We benchmark the Log-\nOR against the FDA-approved drug-disease pairs and found that approved pairs have a much larger\nlog-odds ratio than the other pairs (Supplementary Figure 1), conﬁrming that the log-odds ratio can\nserve as a feasible measure for evaluating the potential indication.\nFor every disease, we rank drug candidates based on TXGNN predictions, and we retrieve the\ntop-1, top-5, top-5%, and bottom-50% novel candidates and calculate their respective average Log-\n13\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nOR (Figure 4d). The top-1 novel TXGNN prediction has, on average, a 107% higher Log-OR than\nthe bottom-50% predictions, suggesting that T XGNN top candidate has much higher enrichment\nin the EHR system and improved likelihood of being an appropriate indication. In addition, we\nsee that the Log-OR increases as we loosen the fraction of retrieved candidates, suggesting that\nTXGNN prediction score is meaningful in capturing the likelihood of indication. In addition,\nwhile the overall average Log-OR is 1.09, we ﬁnd that the top-1 therapeutic candidate by TXGNN\nhas a Log-OR=2.26, which is close to the average Log-OR for FDA-approved indications, Log-\nOR=2.92. This observation suggests the potential utility of TXGNN’s most promising predictions.\nFurther, we show two examples of predicted novel indications for anaplastic astrocytoma, a rare\nmalignant brain tumor, and Wilson’s disease, a rare genetic disorder that causes excessive copper\nto accumulate in the organs (Figure 4e). The T XGNN’s predicted likelihood is close to 0 for\nmost candidate therapies, and only a few are likely to be indications. With an 80% predicted\nprobability, lomustine is T XGNN’s top-1 therapeutic candidate for anaplastic astrocytoma. This\nprediction is substantiated by the EHR records, where lomustine has a high off-label prescription\nrate for anaplastic astrocytoma with a Log-OR=10.64, further supported by evidence suggesting\nlomustine’s efﬁcacy towards anaplastic astrocytoma33. Similarly, TXGNN ranks deferasirox as the\nmost promising therapy for Wilson’s disease, a common cause of liver cirrhosis in children (Log-\nOR=5.26), suggesting that deferasirox’s might have a similar efﬁcacy as deferoxamine in removing\nhepatic iron34. These analyses demonstrate that T XGNN ’s novel predictions are consistent with\nclinical decisions on off-label prescription.\nDiscussion\nThousands of diseases affect humans, and most of them lack effective treatments. Furthermore,\nmultiple treatments may exist for some conditions, each with unique advantages and disadvan-\ntages. The optimal treatment for a patient will depend on various factors, including the patient’s\nmedical history and the speciﬁc condition being treated. Research is ongoing to develop thera-\npies for various diseases. This entails identifying indications as conditions for which a candidate\ntherapy might be appropriate. Additionally, research efforts include determining contraindications,\nwhich are conditions or circumstances under which therapy should not be used because of potential\nadverse interactions with other medications or medical conditions or due to safety concerns.\nTXGNN has zero-shot predicting ability of therapeutic use for diseases without existing\ntreatments and limited molecular understanding. This opens up new avenues for machine learn-\n14\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \ning to identify therapeutic opportunities for diseases that are challenging to model using existing\nstrategies as well as neglected and rare diseases35 in urgent need of therapeutic innovation36, 37.\nTXGNN achieves this goal by capturing and representing similar diseases, extracting rel-\nevant knowledge, and fusing it into the disease of limited knowledge. This is achieved through\na network medicine principle that governs disease-treatment mechanisms 6 and involves ﬁnding\ndiseases with a higher frequency of shared pathways, phenotypes, and pathologies in the latent\nrepresentation space than expected. The set of retrieved similar diseases suggests that T XGNN is\nleveraging information from diverse disease partners. This principle of efﬁcient retrieval of sim-\nilar diseases from the latent space that drives T XGNN can be adapted to other problems, such\nas disease-target identiﬁcation and phenotype modeling. These latent connections are captured\nby T XGNN, allowing for generalization to diseases with few treatment options. Unlike existing\napproaches, TXGNN can tackle indication and contraindication therapeutic use prediction in a uni-\nﬁed formulation across 17,080 clinically-recognized diseases. It can perform zero-shot inference\nfor new diseases without requiring additional ﬁne-tuning for diseases using labeled data points.\nOur results show that T XGNN can signiﬁcantly improve therapeutic use prediction across\na wide range of diseases, even under a real-world constraint of having zero known therapies for\na given disease and extrapolating to a new disease area unseen during training. Additionally,\nTXGNN’s predicted therapies strongly correlate with information in real-world electronic health\nrecords and can be used to test a large number of therapeutic hypotheses in parallel by identifying\ndisease cohorts that either have or have not been prescribed a particular medication (indication\nvs. contraindication) using patient populations followed for several years. Finally, a clinician-\ncentered T XGNN Explorer linked T XGNN with a self-explaining model to present T XGNN’s\npredictions to an audience of clinicians and explore disease-treatment mechanisms leveraged by\nthe model. The usability study of the clinician-centered design shows that researchers using the\ninteractive TXGNN Explorer can reproduce machine learning models and more easily identify and\ndebug failure points of models, highlighting the importance of clinician-centered design in shifting\nmachine learning from development to biomedical implementation38.\n15\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nData availability. The TXGNN’s project website is at https://zitniklab.hms.harvard.edu/projects/\nTxGNN. Therapeutics-centered knowledge graph is available at Harvard Dataverse under a per-\nsistent identiﬁer https://doi.org/10.7910/DVN/IXA7BM. We have deposited the knowledge graph\nand all relevant intermediate ﬁles in this repository. All clinical and electronic medical record\ndata were deidentiﬁed, and the Institutional Review Board at Mount Sinai, New York City, U.S.,\napproved the study.\nCode availability. Python implementation of the methodology developed and used in the study\nis available via the project website athttps://zitniklab.hms.harvard.edu/projects/TxGNN. The code\nto reproduce results, documentation, and usage examples are at https://github.com/mims-harvard/\nTxGNN. To facilitate the usage of the algorithm, we developed a TXGNN Explorer, a web-based\napp available at http://txgnn.org to access TXGNN’s predictions.\nAcknowledgements. K.H., P.C., and M.Z. gratefully acknowledge the support by NSF under\nNo. IIS-2030459, US Air Force under No. FA8702-15-D-0001, and awards from Harvard Data\nScience Initiative, Amazon Research, Bayer Early Excellence in Science, AstraZeneca Research,\nand Roche Alliance with Distinguished Scientists. P.C. was supported, in part, by the Harvard\nSummer Institute in Biomedical Informatics. Any opinions, ﬁndings, conclusions or recommen-\ndations expressed in this material are those of the authors and do not necessarily reﬂect the views\nof the funders.\nAuthors contribution. P.C. retrieved, processed, and analyzed the therapeutics-centered knowl-\nedge graph. K.H. and P.C. developed and implemented new machine learning methods, bench-\nmarked machine learning models, and analyzed model behavior, all together with M.Z. Q.W. and\nN.G. implemented the clinician-centered visual explorer of model predictions and performed a\nuser study to evaluate its usability. S.H., A.V ., G.N. and B.S.G. performed a validation study ex-\namining new predictions of therapeutic use through the electronic health record system. K.H.,\nP.C, Q.W., S.H., A.V ., J.L., G.N, B.S.G., N.G., and M.Z. contributed new analytic tools and wrote\nthe manuscript. All authors discussed the results and contributed to the ﬁnal manuscript. M.Z.\ndesigned the study.\nCompeting interests. The authors declare no competing interests.\n16\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n?\nTreatment candidate, to predictExisting treatmentsMolecular underpinnings\n?\nGNN(    ,    ) = 85%GNN(    ,    ) = 21%\nVS\nScenario A•Many known treatments•Rich molecular underpinnings•Easy to predict\nScenario B•No existing treatments•Poorly characterized mechanisms•Challenging to predict\na 17,080Diseases\n15,311Phenotypes\n7,957Drugs14,035Anatomies\n2,516Pathways\n4,176CellularComponents\n11,169MolecularFunctions27,671Genes/Proteins\n818Exposures28,642BiologicalProcesses\nDisease-Pheno(+)\nContra-indication\nDisease-Pheno(-)Disease-ProteinDrug-PhenotypeDrug-Protein\nExpo-BioprocessExpo-CellCompExpo-DiseaseExpo-MolFuncExpo-Protein\nIndicationMolFunc-ProteinOff-label UsePathway-ProteinPheno-Protein\nb\ns 1\n<latexit sha1_base64=\"kuZvZMv2hHMKAH5SO6g9p5Lz3gI=\">AAAB73icbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIigoEL2Vv2YMPe3mV3zoRc+A02FtoYW/+Onf/GBa5Q8CW7eXlvJjPzgkQKg6777RTW1jc2t4rbpZ3dvf2D8uHRg4lTzXiLxTLWnYAaLoXiLRQoeSfRnEaB5O1gfDPz209cGxGre5wk3I/oUIlQMIpWalVN36v2yxW35s5BVomXkwrkaPbLX71BzNKIK2SSGtP13AT9jGoUTPJpqZcanlA2pkPetVTRiBs/my87JWdWGZAw1vYpJHP1d0dGI2MmUWArI4ojs+zNxP+8borhlZ8JlaTIFVsMClNJMCazy8lAaM5QTiyhTAu7K2EjqilDm0/JhuAtn7xKHus176Jmv/pdvdK4zhMpwgmcwjl4cAkNuIUmtICBgGd4hTdHOS/Ou/OxKC04ec8x/IHz+QN+Go6W</latexit>\ns 2\n<latexit sha1_base64=\"1hLcWYAuqYpUjHVIWsVcCpaBrQU=\">AAAB73icbVA9T8MwEL2Ur1K+CowsFi0SU5WEAcYKFsYiEVrURpXjOq1V24lsB6mK+htYGGBBrPwdNv4NbpsBWp5k6+m9O93di1LOtHHdb6e0tr6xuVXeruzs7u0fVA+PHnSSKUIDkvBEdSKsKWeSBoYZTjupolhEnLaj8c3Mbz9RpVki780kpaHAQ8liRrCxUlDXfb/er9bchjsHWiVeQWpQoNWvfvUGCckElYZwrHXXc1MT5lgZRjidVnqZpikmYzykXUslFlSH+XzZKTqzygDFibJPGjRXf3fkWGg9EZGtFNiM9LI3E//zupmJr8KcyTQzVJLFoDjjyCRodjkaMEWJ4RNLMFHM7orICCtMjM2nYkPwlk9eJY9+w7to2M+/82vN6yKRMpzAKZyDB5fQhFtoQQAEGDzDK7w50nlx3p2PRWnJKXqO4Q+czx9/oo6X</latexit>\ns3\n<latexit sha1_base64=\"N1gMSA9KGEUJdkNjXHgwPYKl0hQ=\">AAAB73icbVA9TwJBEJ3DL8Qv1NJmI5hYkTsotCTaWGLiiQYI2VvmYMPe3mV3z4Rc+A02FtoYW/+Onf/GBa5Q8CW7eXlvJjPzgkRwbVz32ymsrW9sbhW3Szu7e/sH5cOjex2niqHPYhGrh4BqFFyib7gR+JAopFEgsB2Mr2d++wmV5rG8M5MEexEdSh5yRo2V/KruN6r9csWtuXOQVeLlpAI5Wv3yV3cQszRCaZigWnc8NzG9jCrDmcBpqZtqTCgb0yF2LJU0Qt3L5stOyZlVBiSMlX3SkLn6uyOjkdaTKLCVETUjvezNxP+8TmrCy17GZZIalGwxKEwFMTGZXU4GXCEzYmIJZYrbXQkbUUWZsfmUbAje8smr5LFe8xo1+9Vv65XmVZ5IEU7gFM7Bgwtowg20wAcGHJ7hFd4c6bw4787HorTg5D3H8AfO5w+BKo6Y</latexit>\ns 1\n<latexit sha1_base64=\"kuZvZMv2hHMKAH5SO6g9p5Lz3gI=\">AAAB73icbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIigoEL2Vv2YMPe3mV3zoRc+A02FtoYW/+Onf/GBa5Q8CW7eXlvJjPzgkQKg6777RTW1jc2t4rbpZ3dvf2D8uHRg4lTzXiLxTLWnYAaLoXiLRQoeSfRnEaB5O1gfDPz209cGxGre5wk3I/oUIlQMIpWalVN36v2yxW35s5BVomXkwrkaPbLX71BzNKIK2SSGtP13AT9jGoUTPJpqZcanlA2pkPetVTRiBs/my87JWdWGZAw1vYpJHP1d0dGI2MmUWArI4ojs+zNxP+8borhlZ8JlaTIFVsMClNJMCazy8lAaM5QTiyhTAu7K2EjqilDm0/JhuAtn7xKHus176Jmv/pdvdK4zhMpwgmcwjl4cAkNuIUmtICBgGd4hTdHOS/Ou/OxKC04ec8x/IHz+QN+Go6W</latexit>\ns 2\n<latexit sha1_base64=\"1hLcWYAuqYpUjHVIWsVcCpaBrQU=\">AAAB73icbVA9T8MwEL2Ur1K+CowsFi0SU5WEAcYKFsYiEVrURpXjOq1V24lsB6mK+htYGGBBrPwdNv4NbpsBWp5k6+m9O93di1LOtHHdb6e0tr6xuVXeruzs7u0fVA+PHnSSKUIDkvBEdSKsKWeSBoYZTjupolhEnLaj8c3Mbz9RpVki780kpaHAQ8liRrCxUlDXfb/er9bchjsHWiVeQWpQoNWvfvUGCckElYZwrHXXc1MT5lgZRjidVnqZpikmYzykXUslFlSH+XzZKTqzygDFibJPGjRXf3fkWGg9EZGtFNiM9LI3E//zupmJr8KcyTQzVJLFoDjjyCRodjkaMEWJ4RNLMFHM7orICCtMjM2nYkPwlk9eJY9+w7to2M+/82vN6yKRMpzAKZyDB5fQhFtoQQAEGDzDK7w50nlx3p2PRWnJKXqO4Q+czx9/oo6X</latexit>\ns3\n<latexit sha1_base64=\"N1gMSA9KGEUJdkNjXHgwPYKl0hQ=\">AAAB73icbVA9TwJBEJ3DL8Qv1NJmI5hYkTsotCTaWGLiiQYI2VvmYMPe3mV3z4Rc+A02FtoYW/+Onf/GBa5Q8CW7eXlvJjPzgkRwbVz32ymsrW9sbhW3Szu7e/sH5cOjex2niqHPYhGrh4BqFFyib7gR+JAopFEgsB2Mr2d++wmV5rG8M5MEexEdSh5yRo2V/KruN6r9csWtuXOQVeLlpAI5Wv3yV3cQszRCaZigWnc8NzG9jCrDmcBpqZtqTCgb0yF2LJU0Qt3L5stOyZlVBiSMlX3SkLn6uyOjkdaTKLCVETUjvezNxP+8TmrCy17GZZIalGwxKEwFMTGZXU4GXCEzYmIJZYrbXQkbUUWZsfmUbAje8smr5LFe8xo1+9Vv65XmVZ5IEU7gFM7Bgwtowg20wAcGHJ7hFd4c6bw4787HorTg5D3H8AfO5w+BKo6Y</latexit>\n·\n<latexit sha1_base64=\"5vfVq7qHq5Dbitfz/DS+53zdn4Q=\">AAAB8XicbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIigoEL2dvbgw17e5fdORNC+BE2FtoYW/+Nnf/GBa5Q8CW7eXlvJjPzglQKg6777RTW1jc2t4rbpZ3dvf2D8uHRg0kyzXiLJTLRnYAaLoXiLRQoeSfVnMaB5O1gdDPz209cG5Goexyn3I/pQIlIMIpWald7LEyw2i9X3Jo7B1klXk4qkKPZL3/1woRlMVfIJDWm67kp+hOqUTDJp6VeZnhK2YgOeNdSRWNu/Ml83Sk5s0pIokTbp5DM1d8dExobM44DWxlTHJplbyb+53UzjK78iVBphlyxxaAokwQTMrudhEJzhnJsCWVa2F0JG1JNGdqESjYEb/nkVfJYr3kXNfvV7+qVxnWeSBFO4BTOwYNLaMAtNKEFDEbwDK/w5qTOi/PufCxKC07ecwx/4Hz+AFeDj60=</latexit>\n·\n<latexit sha1_base64=\"5vfVq7qHq5Dbitfz/DS+53zdn4Q=\">AAAB8XicbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIigoEL2dvbgw17e5fdORNC+BE2FtoYW/+Nnf/GBa5Q8CW7eXlvJjPzglQKg6777RTW1jc2t4rbpZ3dvf2D8uHRg0kyzXiLJTLRnYAaLoXiLRQoeSfVnMaB5O1gdDPz209cG5Goexyn3I/pQIlIMIpWald7LEyw2i9X3Jo7B1klXk4qkKPZL3/1woRlMVfIJDWm67kp+hOqUTDJp6VeZnhK2YgOeNdSRWNu/Ml83Sk5s0pIokTbp5DM1d8dExobM44DWxlTHJplbyb+53UzjK78iVBphlyxxaAokwQTMrudhEJzhnJsCWVa2F0JG1JNGdqESjYEb/nkVfJYr3kXNfvV7+qVxnWeSBFO4BTOwYNLaMAtNKEFDEbwDK/w5qTOi/PufCxKC07ecwx/4Hz+AFeDj60=</latexit>\n·\n<latexit sha1_base64=\"5vfVq7qHq5Dbitfz/DS+53zdn4Q=\">AAAB8XicbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIigoEL2dvbgw17e5fdORNC+BE2FtoYW/+Nnf/GBa5Q8CW7eXlvJjPzglQKg6777RTW1jc2t4rbpZ3dvf2D8uHRg0kyzXiLJTLRnYAaLoXiLRQoeSfVnMaB5O1gdDPz209cG5Goexyn3I/pQIlIMIpWald7LEyw2i9X3Jo7B1klXk4qkKPZL3/1woRlMVfIJDWm67kp+hOqUTDJp6VeZnhK2YgOeNdSRWNu/Ml83Sk5s0pIokTbp5DM1d8dExobM44DWxlTHJplbyb+53UzjK78iVBphlyxxaAokwQTMrudhEJzhnJsCWVa2F0JG1JNGdqESjYEb/nkVfJYr3kXNfvV7+qVxnWeSBFO4BTOwYNLaMAtNKEFDEbwDK/w5qTOi/PufCxKC07ecwx/4Hz+AFeDj60=</latexit>\n\u0000\n<latexit sha1_base64=\"3DAmGVo0Emg2E6FaXiLXvBux9hY=\">AAAB8nicbVC7TgJBFL3rE/GFWtpMBBMrsouFlkQbS0xEMLAhs8MsTJjHOjNrQjb8hI2FNsbWr7HzbxxgCwVPMpOTc+7NvfdECWfG+v63t7K6tr6xWdgqbu/s7u2XDg7vjUo1oU2iuNLtCBvKmaRNyyyn7URTLCJOW9Hoeuq3nqg2TMk7O05oKPBAspgRbJ3UrnRVwlNT6ZXKftWfAS2TICdlyNHolb66fUVSQaUlHBvTCfzEhhnWlhFOJ8VuamiCyQgPaMdRiQU1YTbbd4JOndJHsdLuSYtm6u+ODAtjxiJylQLboVn0puJ/Xie18WWYMZmklkoyHxSnHFmFpsejPtOUWD52BBPN3K6IDLHGxLqIii6EYPHkZfJQqwbnVffVbmvl+lWeSAGO4QTOIIALqMMNNKAJBDg8wyu8eY/ei/fufcxLV7y85wj+wPv8AVDGkEA=</latexit>\np\n<latexit sha1_base64=\"3ktjs+a0RaGgCj90QoTQtsjbEs4=\">AAAB7XicbVA9TwJBEJ3DL8Qv1NJmI5hYkTsstCTaWGIUxcCF7C17sGFv77I7Z0Iu/AQbC22Mrf/Hzn/jAlco+JLdvLw3k5l5QSKFQdf9dgorq2vrG8XN0tb2zu5eef/g3sSpZrzFYhnrdkANl0LxFgqUvJ1oTqNA8odgdDX1H564NiJWdzhOuB/RgRKhYBStdFtNqr1yxa25M5Bl4uWkAjmavfJXtx+zNOIKmaTGdDw3QT+jGgWTfFLqpoYnlI3ogHcsVTTixs9mq07IiVX6JIy1fQrJTP3dkdHImHEU2MqI4tAselPxP6+TYnjhZ0IlKXLF5oPCVBKMyfRu0heaM5RjSyjTwu5K2JBqytCmU7IheIsnL5PHes07q9mvflOvNC7zRIpwBMdwCh6cQwOuoQktYDCAZ3iFN0c6L8678zEvLTh5zyH8gfP5A1GOje8=</latexit>\n......\n...\np i\n<latexit sha1_base64=\"Ix9ONgJ/FHM13aXs1OkKgGooBgU=\">AAAB+HicbVDNTgIxGPwW/xD/UI9eGsHEE9nFgx6JXjxiIoKBlXRLFxq63abtasiG9/DiQS/Gq4/izbexC3tQcJI2k5nvS6cTSM60cd1vp7Cyura+UdwsbW3v7O6V9w/udJwoQlsk5rHqBFhTzgRtGWY47UhFcRRw2g7GV5nffqRKs1jcmomkfoSHgoWMYGOlh2ovwmYUhKmc9lm1X664NXcGtEy8nFQgR7Nf/uoNYpJEVBjCsdZdz5XGT7EyjHA6LfUSTSUmYzykXUsFjqj201nqKTqxygCFsbJHGDRTf2+kONJ6EgV2MgupF71M/M/rJia88FMmZGKoIPOHwoQjE6OsAjRgihLDJ5ZgopjNisgIK0yMLapkS/AWv7xM7us176xmr/pNvdK4zBspwhEcwyl4cA4NuIYmtICAgmd4hTfnyXlx3p2P+WjByXcO4Q+czx/+f5Lr</latexit>\npj\n<latexit sha1_base64=\"oWrk2LosHZ1crXWsQ/oPq29rGLU=\">AAAB+HicbVC9TsMwGPxc/kr5KzCyWLRITFVSBhgrWBiLRGlRGyrHdVqD40S2A6qivgcLAyyIlUdh421w2gzQcpKt0933yefzY8G1cZxvVFhaXlldK66XNja3tnfKu3s3OkoUZS0aiUh1fKKZ4JK1DDeCdWLFSOgL1vYfLjK//ciU5pG8NuOYeSEZSh5wSoyV7qq9kJiRH6TxpH9f7ZcrTs2ZAi8SNycVyNHsl796g4gmIZOGCqJ113Vi46VEGU4Fm5R6iWYxoQ9kyLqWShIy7aXT1BN8ZJUBDiJljzR4qv7eSEmo9Tj07WQWUs97mfif101McOalXMaJYZLOHgoSgU2EswrwgCtGjRhbQqjiNiumI6IINbaoki3Bnf/yIrmt19yTmr3qV/VK4zxvpAgHcAjH4MIpNOASmtACCgqe4RXe0BN6Qe/oYzZaQPnOPvwB+vwBABaS7A==</latexit>\nh sim\ni\n<latexit sha1_base64=\"5LTi5NggWACyaSomYVF+YDmR7LI=\">AAACB3icbVC7TsMwFHXKq5RXgLGLRYvEVCVlgLGChbFIlBa1IXJcp7VqO5HtIFVRBxZ+hYUBFsTKL7DxNzhpBmg5kq3jc+6V7z1BzKjSjvNtlVZW19Y3ypuVre2d3T17/+BWRYnEpIMjFslegBRhVJCOppqRXiwJ4gEj3WBymfndByIVjcSNnsbE42gkaEgx0kby7Wp9wJEeB2E6nvn0Pn9InirKZ3XfrjkNJwdcJm5BaqBA27e/BsMIJ5wIjRlSqu86sfZSJDXFjMwqg0SRGOEJGpG+oQJxorw0X2IGj40yhGEkzREa5urvjhRxpaY8MJXZkGrRy8T/vH6iw3MvpSJONBF4/lGYMKgjmCUCh1QSrNnUEIQlNbNCPEYSYW1yq5gQ3MWVl8lds+GeNszVvG7WWhdFImVQBUfgBLjgDLTAFWiDDsDgETyDV/BmPVkv1rv1MS8tWUXPIfgD6/MHIkyZGg==</latexit>\nh i\n<latexit sha1_base64=\"WRqfx0V0kt3gwSy+bqBZDkWdAb8=\">AAAB+HicbVDNTgIxGPwW/xD/UI9eGsHEE9nFgx6JXjxiIoKBlXRLFxq67abtasiG9/DiQS/Gq4/izbexC3tQcJI2k5nvS6cTxJxp47rfTmFldW19o7hZ2tre2d0r7x/caZkoQltEcqk6AdaUM0FbhhlOO7GiOAo4bQfjq8xvP1KlmRS3ZhJTP8JDwUJGsLHSQ7UXYTMKwnQ07bNqv1xxa+4MaJl4OalAjma//NUbSJJEVBjCsdZdz42Nn2JlGOF0WuolmsaYjPGQdi0VOKLaT2epp+jEKgMUSmWPMGim/t5IcaT1JArsZBZSL3qZ+J/XTUx44adMxImhgswfChOOjERZBWjAFCWGTyzBRDGbFZERVpgYW1TJluAtfnmZ3Ndr3lnNXvWbeqVxmTdShCM4hlPw4BwacA1NaAEBBc/wCm/Ok/PivDsf89GCk+8cwh84nz/yJ5Lj</latexit>\nˆh i\n<latexit sha1_base64=\"Rv4TAwGdEqUtBBXYRbETNw8HqQI=\">AAACAHicbVC7TsMwFHV4lvIKj40lokViqpIywFjBwlgkSouaqHJcp7HqOJF9g1SiiF9hYYAFsfIZbPwNTpsBWo5k6+ice+Xj4yecKbDtb2NpeWV1bb2yUd3c2t7ZNff271ScSkI7JOax7PlYUc4E7QADTnuJpDjyOe3646vC7z5QqVgsbmGSUC/CI8ECRjBoaWAe1t0QQ+ZGGEI/yMJ8wPL6wKzZDXsKa5E4JamhEu2B+eUOY5JGVADhWKm+YyfgZVgCI5zmVTdVNMFkjEe0r6nAEVVeNk2fWydaGVpBLPURYE3V3xsZjpSaRL6eLFKqea8Q//P6KQQXXsZEkgIVZPZQkHILYquowhoySQnwiSaYSKazWiTEEhPQhVV1Cc78lxfJfbPhnDX01bxp1lqXZSMVdISO0Sly0DlqoWvURh1E0CN6Rq/ozXgyXox342M2umSUOwfoD4zPH1wKleE=</latexit>\nh j\n<latexit sha1_base64=\"/LjVlnx9xyCyZRnuIlH7XpNH4I8=\">AAAB+HicbVC9TsMwGPxc/kr5KzCyWLRITFVSBhgrWBiLRGlRGyrHdVqD40S2A6qivgcLAyyIlUdh421w2gzQcpKt0933yefzY8G1cZxvVFhaXlldK66XNja3tnfKu3s3OkoUZS0aiUh1fKKZ4JK1DDeCdWLFSOgL1vYfLjK//ciU5pG8NuOYeSEZSh5wSoyV7qq9kJiRH6SjSf++2i9XnJozBV4kbk4qkKPZL3/1BhFNQiYNFUTrruvExkuJMpwKNin1Es1iQh/IkHUtlSRk2kunqSf4yCoDHETKHmnwVP29kZJQ63Ho28kspJ73MvE/r5uY4MxLuYwTwySdPRQkApsIZxXgAVeMGjG2hFDFbVZMR0QRamxRJVuCO//lRXJbr7knNXvVr+qVxnneSBEO4BCOwYVTaMAlNKEFFBQ8wyu8oSf0gt7Rx2y0gPKdffgD9PkD86+S5A==</latexit>\nSignature Computation\nSimilar DiseasesRetrieve EmbeddingsDegree GatingPrediction\nDisease-disease RecombinationSimilarity ProfilingTraining Strategy\n...Pre-training\nFine-tuning\nKnowledge Graph Message Passing\nexp( \u0000 )\n<latexit sha1_base64=\"T4X2lRSD74XUOn/rCwTz4M3pzqc=\">AAACA3icbVC7TsMwFHXKq5RXgIGBxaJFKkuVlAHGChbGIlFa1ESV4zitVduJbAdRRV34FRYGWBArP8HG3+C0GaBwJVtH59yje+8JEkaVdpwvq7S0vLK6Vl6vbGxube/Yu3u3Kk4lJh0cs1j2AqQIo4J0NNWM9BJJEA8Y6Qbjy1zv3hOpaCxu9CQhPkdDQSOKkTbUwD6oeRzpkeQZeUimdY8Za4hOagO76jScWcG/wC1AFRTVHtifXhjjlBOhMUNK9V0n0X6GpKaYkWnFSxVJEB6jIekbKBAnys9mB0zhsWFCGMXSPKHhjP3pyBBXasID05lvqxa1nPxP66c6OvczKpJUE4Hng6KUQR3DPA0YUkmwZhMDEJbU7ArxCEmEtcmsYkJwF0/+C+6aDfe0Yb7mdbPauigSKYNDcATqwAVnoAWuQBt0AAZT8ARewKv1aD1bb9b7vLVkFZ598Kusj2/ybpaw</latexit>\nQueryDisease\nQueryDrug\nDisease\nPhenotype\nProtein\nDrug\nMolecular Function\nPathway\nExposure\nBiologicalProcess\nAnatomy\nCellular Component\nQueryDisease\nQueryDrug\nRelation\nMessage\nEmbedding\ne\nc\nd\nAnatomy-AnatomyBioprocess-BioprocessCellComp-CellCompDisease-DiseaseDrug-DrugExpo-ExpoMolFunc-MolFuncPathway-PathwayPhenotype-PhenotypeProtein-Protein\nAnatomy-Protein(+)Anatomy-Protein(-)Bioprocess-ProteinCellComp-Protein\n●\n●\n●\n● ●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n● ●\n●\n●\n●\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00AUPRC\n●● ●●GNN RxGNN\n+46.5%\n+4.9%\n+49.2%\nAnnotated Treatments?Scenario AScenario BPrior Biological Knowledge?YesYesNoYesNoNoSystematicStandardCellProliferation\nDisease Signature Similarity Score\nTxGNN\n17\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nFigure 1: T XGNN is a geometric deep learning approach for discovering therapeutics across challenging diseases with no\nknown treatments and limited molecular understanding. a. A large-scale therapeutics-driven knowledge graph integrates 17\nprimary data sources to depict a comprehensive landscape of biological mechanisms for therapeutics discovery. b. Commonly\npredicted diseases have many known treatments and rich molecular understandings and are thus easy to predict. However, diseases of\nactive research and with the most therapeutic potentials are often the ones that have no existing treatments and poorly characterized\nmechanisms. The machine learning model is most useful in the latter case, but prevailing models fail. c. Detailed illustration of\nthe TXGNN method. It follows three key steps. (1) T XGNN projects biological concepts into meaningful representations through\nknowledge graph neural network message passing on the KG (Methods 2.2). (2) It then designs a similarity disease search component\nto enrich molecularly uncharacterized diseases (Methods 2.4) and it has three modules (2.1) It computes a signature vector for each\ndisease that captures the disease similarity. (2.2) Based on the signature vector distance, it proﬁles a set of similar diseases and\nretrieves their latent embeddings. (2.3) It then aggregates the different similar diseases into a powerful auxiliary embedding. (2.4)\nA gating mechanism is designed to control the effect between the original disease embedding and the auxiliary disease embedding\nsince many well-characterized diseases have sufﬁcient embeddings and do not need subsidies. (3) A decoder then maps the query\ndrug and disease representation to predict the outcome (Methods 2.3). A pretext learning stage is devised to allow T XGNN to learn\nan initialized embedding that captures complex biological knowledge (Methods 2.5). d. The insight of T XGNN is that biology is a\nconnected system where diseases are partially similar and can share multiple mechanisms. By identifying and fusing similar diseases\nto poorly characterized diseases, T XGNN can make an accurate prediction on these challenging diseases. T XGNN develops a\ndisease signature that accurately depicts the disease relation landscape. e. State-of-the-art methods (GNN) break when inferring\ntreatments for diseases in the wild, while T XGNN signiﬁcantly improves over GNN and achieves accurate prediction for diseases\nwith no treatments annotation and limited biological knowledge prior. The reported metric is AUPRC on indication prediction,\naverage across ﬁve random runs.\n18\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \na b\nc\nd\nIndications Contra-indications\nIndications\nContra-indications\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\u0000 \u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\nSystematic Adrenal Gland Anemia Cardi o v ascular Cell Proli f e r ation Mental Health\nNon−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.00\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\nRecall@100\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\n\u0000\n\u0000 \u0000\n\u0000 \u0000\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000 \u0000 \u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000 \u0000\n\u0000\n\u0000\n\u0000\nSystematic Adrenal Gland Anemia Cardi o v ascular Cell Proli f e r ation Mental Health\nNon−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN Non−Guided GNN RxGNN\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.08\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.22\n0.24\n0.26\n0.28\n0.30\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\n0.90\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60\n0.65\nRecall@100\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\nCardi o v ascular Cell Proli f e r ation Mental Health\nSystematic Adrenal Gland Anemia\nGNN RxGNN GNN RxGNN GNN RxGNN\nGNN RxGNN GNN RxGNN GNN RxGNN\n0.46\n0.48\n0.50\n0.52\n0.54\n0.56\n0.58\n0.60\n0.62\n0.64\n0.66\n0.68\n0.70\n0.48\n0.50\n0.52\n0.54\n0.56\n0.58\n0.60\n0.62\n0.64\n0.53\n0.53\n0.54\n0.54\n0.55\n0.55\n0.55\n0.56\n0.56\n0.57\n0.57\n0.58\n0.58\n0.59\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.50\n0.51\n0.52\n0.53\n0.54\n0.55\n0.56\n0.57\n0.58\n0.59\n0.60\nA UPRC\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000 \u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\n\u0000\u0000\n\u0000\nCardi o v ascular Cell Proli f e r ation Mental Health\nSystematic Adrenal Gland Anemia\nGNN RxGNN GNN RxGNN GNN RxGNN\nGNN RxGNN GNN RxGNN GNN RxGNN\n0.53\n0.54\n0.55\n0.56\n0.57\n0.58\n0.59\n0.60\n0.61\n0.62\n0.51\n0.52\n0.53\n0.54\n0.55\n0.56\n0.57\n0.58\n0.59\n0.60\n0.52\n0.52\n0.52\n0.52\n0.53\n0.53\n0.53\n0.53\n0.53\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.55\n0.56\n0.57\n0.58\n0.59\n0.60\n0.61\n0.62\nA UPRC\na b\nc\nd\ne f\n+49.2% +10.0% +44.6%\n+34.2%+46.5%+18.9%\n+35.1% -1.98%+15.1%\n+16.4%+83.4%+12.6%\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\n\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX6.38\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX12.81\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX8.64\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX2.97\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX10.25\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX9.51\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX8.67\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX2.70\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX3.07\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX1.91\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX2.82\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nX3.96\u0000 =\n<latexit sha1_base64=\"DOOzDxmL+ZO/shZZ6Fuje4ADDc0=\">AAAB83icbVA9TwJBEJ3DL8Qv1NLmIphYkTsstDEhamGJiSgELmRv2YMNu3uX3TkTQvgVNhbaGFv/jJ3/xgWuUPAlu3l5byYz88JEcIOe9+3kVlbX1jfym4Wt7Z3dveL+wYOJU01Zg8Yi1s2QGCa4Yg3kKFgz0YzIULDHcHg99R+fmDY8Vvc4SlggSV/xiFOCVmqVOzdMILksd4slr+LN4C4TPyMlyFDvFr86vZimkimkghjT9r0EgzHRyKlgk0InNSwhdEj6rG2pIpKZYDxbeOKeWKXnRrG2T6E7U393jIk0ZiRDWykJDsyiNxX/89opRhfBmKskRabofFCUChdjd3q92+OaURQjSwjV3O7q0gHRhKLNqGBD8BdPXiatasU/q9ivelct1a6yRPJwBMdwCj6cQw1uoQ4NoCDhGV7hzdHOi/PufMxLc07Wcwh/4Hz+AGT3kD4=</latexit>\nTxGNN TxGNN TxGNN\nTxGNN TxGNN TxGNN TxGNN TxGNN TxGNN\nTxGNNTxGNNTxGNN\nTxGNN TxGNN TxGNNTxGNNTxGNNTxGNN\nTxGNN TxGNN TxGNN TxGNN TxGNN TxGNN\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●●\n●\n●\n●\n●\n●\n●\n● ●\n●\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\nRxGNN No−Metric No−Pretrain Avg−Agg Protein−Sig Walk−Sig\nAblations\nAUPRC\n●●\n●●\n●●\n●●\n●●\n●●\nRxGNN\nNo−Metric\nNo−Pretrain\nAvg−Agg\nProtein−Sig\nWalk−Sig\nContra-indications\nTxGNN\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n● ●\n●\n●● ●\n●\n●\n● ●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n●\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nRxGNN No−Metric No−Pretrain Avg−Agg Protein−Sig Walk−Sig\nAblations\nAUPRC\n●●\n●●\n●●\n●●\n●●\n●●\nRxGNN\nNo−Metric\nNo−Pretrain\nAvg−Agg\nProtein−Sig\nWalk−Sig\nIndications\nTxGNN\nFigure 2: T XGNN predicts therapeutics indications and contraindications across disease areas with high precision. a. Per-\nformance of T XGNN and baseline GNN on indication prediction measured as the area under the precision-recall curve (AUPRC).\nA higher AUPRC is better. The result is reported with ﬁve random data splits. The mean is highlighted with the standard error as\nthe error bar. Each panel is a type of disease split. b. Performance of T XGNN and GNN on contraindication prediction measured\nas AUPRC. c. Indication prioritization performance of T XGNN, GNN and Non-Guided as measured in Recall@100. Higher Re-\ncall@100 is better, with 1 retrieving every hit and 0 none retrieved.d. Contraindication prioritization performance of TXGNN, GNN\nand Non-Guided as measured in Recall@100. e. Performance of variants of TXGNN where we remove/modify each component of\nTXGNN to test its contribution to the model performance on indication prediction measured as AUPRC. f. Performance of variants\nof TXGNN on contra-indication prediction measured as AUPRC.\n19\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nQ2: This AI helps me assess the predicted drug\nours\nbaseline\nAccuracy\nQ1: I understand why AI makes this prediction Q3: I trust the drug predicted by this AI\nQ4: I am willing to use this AI \n9\n6\n6\n5\n3\n2\n2\n2\n1\n3\n2\n3\n5\n4\n1\n3\n2\n5\n2\n7\n7\n9\n7\nours\nbaseline\nours\nbaseline\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\n0.792\n0.542\n58.308\n18.358\n0\n10\n20\n30\n40\n50\n60\n70\n80\nTime(s)\n3.542\n2.375\n1.0\n2.0\n3.0\n4.0\n5.0\nConfidence\nbaseline\nours\nbaseline\nours\nbaseline\nours\nPath Explaination\nEscitalopram\nDesvenlafaxine\nFluoxetine\nMirtazapine\nClozapine\nClomipramine\nMethotrimeprazine\n11\n2\n5\n13\n2\n13\ndisease\ngene/protein\nmolecular_function\ndrug\n1\n1\n1\n2\n1\n2\ndisease\ngene/protein\ndrug\nunipolar depres...\nHTR7\nClozapine\nassociated\ntargets\ng\nHTR2C\ng\nassociated\ntargets\ng\ng\nClomipramine\nassociated\ntargets\n1\ndisease\ngene/protein\npathway\ndrug\n20\n17\n20\n20\n15\n14\n11\ndisease\ngene/protein\nanatomy\ndrug\n3\nUsers can hide (  ), unhide (   ), collapse (   ), or expand (   ) \na group of explanation paths based on the metapath \nThe Meta-Matrix provides \nan overview of all predicted \ndrugs in terms of meta paths\nDrug Embedding\nControl Panel\ngene/protein\ngene/protein\ngene/protein\n4\nstrongly disagree\ndisagree\nneutral\nagree\nstrongly agree\n5\nMore details about\na drug on query\na\nc\nb\nW rr\nsigmoid\nzi,j,r\ni\nj\n> 0.5\n≤ 0.5\nKeep\nMask\nGraph XAI\nNeighbor \nNodes Subgraphs Paths\nours\nbaseline\n1\nSelect disease\n2\nSelect drugs\n2\nSelect drugs \nthrough lasso\nFigure 3: We generate, visualize, and evaluate explanations for T XGNN Predictions. a. We produce a sparse set biological\nrelations to explain a drug-disease prediction by masking less informative relations in the neighborhood of the biological knowledge\ngraph. b. DrugExplorer supports domain scientists in interpreting and interacting with model predictions and explanations. The ‘Path\nExplanation’ panel displays those biological relations that have been identiﬁed as critical for TXGNN’s predictions about therapeutic\nuse.c. We compare DrugExplorer with a no-explanation baseline in terms of user answer accuracy, exploration time, user conﬁdence,\nand user agreement on 4 usability questions. Error bars indicate the 95% conﬁdence intervals. Agree scores are placed to the right,\ndisagree to the left.\n20\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \na\ned\n+107%\nUS FDA-approved indications\nDeferasiroxTxGNN: 0.79LogOR: 5.26\nWilson’s Disease\nLomustineTxGNN: 0.80LogOR: 10.64\nAnaplastic Astrocytoma\nEpiglottitisVulvitis\nTonsillitis\nPeritonsillarAbscessNasopharyngitis\nPharyngitis\nb\nPatient ID: Drug ID: Disease ID: \nMatching drug and disease in TxGNNdata with EHR data in Mount Sinai Health System \n1,290 drugs with ≥10 patients \n480 diseaseswith ≥1 patients \n1,272,085 patients with at least 1 drug & at least 1 disease \nTxGNNdata\nCalculating log-odds ratioper drug-disease pair Evaluating TxGNNnovel indication predictionFeasibility benchmark with FDA approved drug-disease pair\nApproved drug-disease pairs\nLog-odds ratio\nDensity\nAll drug-disease pairs\nYesNoYesNo\nCurating cohort for systematic estimation of drug disease occurrence\n....\nPatient ID: Drug ID: Disease ID: \nPatient ID: Drug ID: Disease ID: \n. 0.73\nPredictionLog-odds\n0.450.21\n0.01…\n3.51\n2.141.21\n0.15…\nc\nDiseasePhenotypeProteinDrug\nMolecular FunctionPathway\nExposureBiologicalProcess\nAnatomy\nCellular Component\nFigure 4: Understanding and evaluating the novel predictions made by T XGNN. a. The 5 most related diseases for Tonsillitis\nand their positions in the disease embedding space. We ﬁnd the target disease is distant from the related diseases in the embedding\nmanifold, suggesting TXGNN leverages a domain prior-guided selective aggregation scheme to enrich the target disease embedding.\nWe use UMAP to generate the embedding landscape. b. TXGNN learn meaningful embeddings that capture biological hierarchy. c.\nIllustrated steps to evaluate TXGNN in large-scale EHR system at Mount Sinai. d. Evaluation of novel predictions made by TXGNN\nin Mount Sinai EHR system. The y-axis is the Log-OR of the disease-drug pairs, measuring the enrichment of the pair co-occurence,\na proxy of indication. For every disease, we rank the T XGNN prediction and retrieve the top 1, top 5, top 5%, and bottom 50% of\nnovel drug candidates and calculate the respective average Log-OR. The red horizontal line is the average Log-OR of FDA-approved\nindications. e. Examples of TXGNN predicted score against Log-OR for Anaplastic Astrocytoma and Wilson’s disease. Each point\nrepresents a therapeutic candidate. The top 1 most probable candidate by TXGNN is highlighted with its TXGNN score and LogOR.\n21\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nOnline Methods\nThe Methods are structured as follows: 1) description of therapeutics-centered knowledge graph\n(Section 1), 2) description of machine learning approach (Section 2), and 3) outline of the experi-\nmental setup, benchmarking and evaluation (Section 3).\n1 Therapeutics-centered knowledge graph\nThe knowledge graph is heterogeneous, with 10 types of nodes and 29 types of undirected edges.\nIt contains 123,527 nodes and 8,063,026 edges. Tables 3 and 4 show a breakdown of nodes by\nnode type and edges by edge type, respectively. The knowledge graph and all auxiliary data ﬁles\nare available via Harvard Dataverse at https://doi.org/10.7910/DVN/IXA7BM.\n1.1 Primary data resources\nThe knowledge graph is compiled based on 17 primary knowledge bases that cover 10 types of\nbiomedical entities and provide broad coverage of human disease, already-available drugs, and\nnovel drugs in development. We brieﬂy overview biological information retrieved from the knowl-\nedge bases, with details provided in Chandak et al.12: Bgee. Bgee39 contains gene expression\npatterns across multiple animal species. Processing involved keeping only gold-quality calls and\nensuring the anatomical entities were coded using the UBERON ontology. To extract only highly\nexpressed genes in the anatomical entity, we ﬁltered the data to keep data with an expression rank\nof less than 25,000. The processed data contains 1,786,311 anatomy-protein associations where\ngene expression was present or absent. Comparative Toxicogenomics Database. The Compar-\native Toxicogenomics Database (CTD)40 focuses on environmental exposures’ impact on human\nhealth. The processed data contains 180,976 associations between exposures and proteins, dis-\neases, other exposures, biological processes, molecular functions, and cellular components. Dis-\nGeNET. DisGeNET41 is a resource about the relationships between genes and human disease that\nexperts have curated. The raw data contains 84,038 associations of genes with diseases and pheno-\ntypes. DrugBank. DrugBank42 is a resource that contains pharmaceutical knowledge. Processing\ninvolved using the beautiful soup package to extract synergistic drug interactions. The processed\ndata contains 2,682,157 associations. We also retrieved information about drug targets, enzymes,\ncarriers, and transporters. The processed data contains 26,118 drug-protein interactions. Drug\nCentral. Drug Central43 curates information about approved drug indications and contraindica-\ntions. The processed data contains 26,698 indication edges, 8,642 contraindication edges, and\n22\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n1,917 off-label use edges. Entrez Gene. Entrez Gene44 is a resource maintained by the NCBI that\ncontains vast amounts of gene-speciﬁc information. Processing involved using the GOATOOLS\npackage45 to extract relations between genes and Gene Ontology terms. The processed data in-\ncludes 297,917 associations of genes with biological processes, molecular functions, and cellular\ncomponents. Gene Ontology. The Gene Ontology46 network describes molecular functions, cel-\nlular components, and biological processes. Processing involved using the GOATOOLS package45\nto extract information for gene ontology terms and relations between go terms. The processed\ndata contains 71,305 hierarchical associations between biological processes, molecular functions,\nand cellular components. Human Phenotype Ontology. The Human Phenotype Ontology47 pro-\nvides information on phenotypic abnormalities found in diseases. Processing involved parsing\nthe ontology ﬁle to extract phenotype terms in the ontology, parent-child relationships, and cross-\nreferences to other ontologies. The processed data contains disease-phenotype, protein-phenotype,\nand phenotype-phenotype edges. We also obtained expertly curated annotations. The processed\ndata includes 218,128 curated associations between diseases and phenotypes. Mondo Disease\nOntology. Since the Mondo Disease Ontology48 harmonizes diseases from a wide range of ontolo-\ngies, including OMIM, SNOMED CT, ICD, and MedDRA, it was our preferred ontology for deﬁn-\ning diseases. The processed data contains 64,388 disease-disease edges. Orphanet. Orphanet49 is\na database that gathers knowledge about rare diseases. The Orphanet portal has curated information\nabout deﬁnitions, prevalence, management and treatment, epidemiology, and clinical description\nfor 9348 rare diseases. Physical protein-protein interactions. Protein-protein interactions are\ncomposed of experimentally-veriﬁed interactions between proteins. The interactions we consider\nare diverse, including signaling, regulatory, metabolic-pathway, kinase-substrate, and protein com-\nplex interactions, which are unweighted and undirected. We use the human PPI network compiled\nby Menche et al.1 as the starting resource. This resource integrates several protein-protein inter-\naction databases, including TRANSFAC for regulatory interactions50, MINT and IntAct for yeast\nto hybrid binary interactions 51, 52, and CORUM for protein complex interactions 53. Additionally,\nwe retrieve protein-protein interaction information from BioGRID54 and STRING55 databases. We\nalso consider the human reference interactome (HuRI) generated by Lucket al.56, where we use the\nHI-union, a combination of HuRI and several related efforts to systematically screen for protein-\nprotein interactions. The processed data contains 642,150 edges. Reactome. Reactome57 is an\nopen-source, curated database for pathways. The processed data contains 5,070 pathway-pathway\nand 85,292 protein-pathway edges. Side Effect Resource. The Side Effect Resource (SIDER) 58\n23\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \ncontains data about adverse drug reactions. We retrieved side-effect data and SIDER’s drug to\nAnatomical Therapeutic Chemical (ATC) classiﬁcation mapping. Processing involved extracting\nall side effects where the MedDRA term was coded at the ”PT” or preferred term level and then\nmapping drugs from STITCH ID to ATC ID. The processed data 202,736 contains drug-phenotype\nassociations. UBERON. UBERON59 is an ontology containing human anatomy information. Pro-\ncessing involved extracting information about anatomy nodes and the relationships between them.\nThe processed data includes 28,064 hierarchical relationships between anatomy nodes.\n1.2 Building therapeutics-centered knowledge graph\nWe selected ontologies for each node type, harmonized primary data resources into a standardized\nformat and resolved overlap across ontologies, and speciﬁed display names for relation/edge types\nto aid in the visualization of the knowledge graph by DrugExplorer and user studies.\nData standardization and ontologies. To harmonize primary data resources, we mapped them\nto common ontologies12. The node types ‘drug’, ‘disease’, ‘anatomy’, and ‘pathway’ are encoded\nas terms in DrugBank, Mondo, UBERON, and Reactome. Genes and proteins are treated as a\nsingle node type, ‘gene/protein’, and identiﬁed by Entrez Gene IDs. The node types ‘biological\nprocess’, ‘molecular function’, and ‘cellular component’ are deﬁned using Gene Ontology terms.\nDisease phenotypes extracted from HPO and drug side effects extracted from SIDER are collapsed\ninto a single node type, ‘effect/phenotype’, encoded using HPO IDs. Finally, ‘exposure’ nodes\nare deﬁned using the ExposureStressorID ﬁeld, which contains MeSH identiﬁers provided by the\nComparative Toxicogenomics Database. Here, ‘gene/protein’ nodes are also referred to as protein\nnodes, and ‘effect/phenotype’ nodes are referred to as phenotype nodes interchangeably.\nThere was considerable overlap between phenotype and disease nodes across primary data\nresources. Overlapping nodes are effect/phenotype nodes in the Human Phenotype Ontology with\nthe same ID number as disease nodes in Mondo Disease Ontology. They can be mapped from the\nHuman Phenotype Ontology to Mondo using cross-references found in the Mondo. To resolve the\noverlap between phenotype nodes (Human Phenotype Ontology) and disease nodes (Mondo Dis-\nease Ontology), these overlapping phenotype nodes were converted to disease nodes by aligning\nedges across datasets as outlined in Chandak et al.12.\nDeﬁning display relation names. To support the visualization of TXGNN’s predictions, we added\na ‘display\nrelation’ ﬁeld, a descriptive version of the ‘relation’ ﬁeld. When visualizing explana-\ntory meta paths, the user sees two node types and a connecting relation name. For example, a\n24\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nuser would see a ‘drug’ connected to another ‘drug’ by the ‘drugdrug’ relation. Since the relation\nname becomes repetitive here, we introduced more meaningful descriptions through this display\nrelation ﬁeld. Some notable examples include converting ‘drug drug’ to ‘synergistic interaction’,\n‘anatomy protein present’ to ‘expression present’, and ‘disease phenotype negative’ to ‘pheno-\ntype absent’. The display relation ﬁeld does not map to the relation ﬁeld one-one. For example,\ndrug-protein relations in the knowledge graph can be displayed as ‘target’, ‘enzyme’, ‘transporter’,\nor ‘carrier’ depending on their speciﬁcation in DrugBank. In the reverse, disease-disease and\nanatomy-anatomy relations have the display name ‘is a’ to indicate hierarchical relations.\nHarmonizing graph structure and topology of therapeutics-centered knowledge graph. We\nmerged the harmonized datasets into a heterogeneous knowledge graph and extracted its largest\nconnected component using the approach outlined in Chandak et al.12. Since the knowledge graph\nis designed for therapeutic use prediction, we wanted to ensure that disease nodes in the graph were\nmeaningful representations of diseases by collapsing disease nodes with nearly identical names\ninto a single disease node. To this end, we adopted an approach previously validated 12 to group\ndisease nodes with nearly identical names. First, disease groups were identiﬁed using automated\nstring matching across disease names. This was achieved by selecting a starting disease via the\nending-matching criteria and using the starting disease to ﬁnd matches.\nMatches included any diseases with the same initial phrase as the main disease name after\ndeleting the ending word and any disease that contained all the words in the main disease name with\nno additional words, regardless of word order. Second, the intermediate disease groupings were\ntightened using ClinicalBERT60 embedding similarities between disease names. The similarity be-\ntween disease names was deﬁned as the cosine distance between their ClinicalBERT embeddings.\nFinally, after applying an empirically chosen cutoff of similarity ≥0.98, we manually approved\nthe suggested disease matches and assigned names to the new groups. After grouping, 22,205\ndiseases in the Mondo Disease Ontology were collapsed into 17,080 grouped diseases.\n2 Geometric deep learning approach\nNotation. We are given a heterogeneous knowledge graph (KG)G= (V,E,TR) with nodes in the\nvertex set vi ∈V, edges ei,j = (vi,r,vj) in the edge set E, where r ∈TR indicates the relation\ntype, vi is called the head/source node and vj is called the tail/target node. Each node also belongs\nto a node type set TV. Each node also has an initial embedding, which we denote as h(0)\ni .\n25\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nProblem deﬁnition. Given a disease iand drug j, we want to predict the likelihood of the drug\nbeing (1) indicated for the disease or (2) contraindicated for the disease. The goal is to inject\nfactual knowledge from the KG into AI application to imitate important skills possessed by human\nexperts, i.e., reasoning and understanding when forming hypotheses and making predictions about\ndisease treatments.\n2.1 Overview of T XGNN approach\nTXGNN is a deep learning approach for mechanistic predictions in drug discovery based on molec-\nular networks perturbed in disease and targeted by therapeutics. T XGNN is composed of four\nmodules: (1) a heterogeneous graph neural network-based encoder to obtain biologically mean-\ningful network representation for each biomedical entity; (2) a disease similarity-based metric\nlearning decoder to leverage auxiliary information to enrich the representation of diseases that lack\nmolecular characterization; (3) an all-relation stochastic pre-training followed by a drug-disease\ncentric full-graph ﬁne-tuning strategy; (4) a graph explainability module to retain a sparse set of\nedges that are crucial for prediction as a post-training step. Next, we expand each module in detail.\n2.2 Heterogeneous graph neural network encoder\nGiven a knowledge graph, we aim to learn a numerical vector (i.e., network embedding) for each\nnode such that it captures biomedical knowledge encapsulated in the neighboring relational struc-\ntures. This is achieved by transforming initial node embeddings through several layers of local\ngraph-based non-linear function transformations to generate embeddings18, 61. These functions are\noptimized iteratively, given a loss function to gradually minimize the error of making poor ther-\napeutic use predictions. Upon convergence, optimized functions generate an optimal set of node\nembeddings.\nStep 1: Initialization. We denote the input node embeddingXi for each nodei, which is initialized\nusing Xavier uniform initialization62. For every layer lof message-passing, there are the following\nthree stages:\nStep 2: Propagating relation-speciﬁc neural messages. For every relation type, ﬁrst calculates\na transformation of node embedding from the previous layer h(l−1), where the ﬁrst layer h(0) =\nX. This is achieved via applying a relation-speciﬁc weight matrix W(l)\nr,M on the previous layer\n26\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nembedding:\nm(l)\nr,i = W(l)\nr,Mh(l−1)\ni (1)\nStep 3: Aggregating local network neighborhoods. For each node vi, we aggregate on the\nincoming messages {m(l)\nr,j|j ∈Nr(i)}from neighboring nodes of each relation rdenoted as Nr(i)\nby taking the average of these messages:\n˜m(l)r,i = 1\n|Nr(i)|\n∑\nj∈Nr(i)\nm(l)\nr,j (2)\nStep 4: Updating network embeddings. We then combine the node embedding from the last\nlayer and the aggregated messages from all relations to obtain the new node embedding:\nh(l)\ni = h(l−1)\ni +\n∑\nr∈TR\n˜m(l)r,i (3)\nAfter Llayers of propagation, we arrive at our encoded node embeddings hi for each node i.\n2.3 Predicting drug-disease relationships\nGiven the disease embedding and the drug embedding, we can predict the interaction between\na disease-drug pair. As we have three relation types to predict for each disease-drug pair, we\nuse a trainable weight vector wr for each relation type. We then use DistMult 63 to calculate the\ninteraction likelihood for that relation. Formally, for disease i, drug j, and relation r, we calculate\nthe predicted likelihood p:\npi,j,r = 1\n1 + exp(−sum(hi ·wr ·hj)). (4)\n2.4 Similarity Disease Search to Enrich Molecularly Uncharacterized Disease Embedding\nDiseases receive various degrees of research, given their prevalence, complexity, and so on. For\nexample, we know very little about the molecular underpinnings of many rare diseases 64, 65. Nev-\nertheless, these diseases usually present the most promising therapeutic opportunities 66. Due to\nthe lack of understanding of these diseases, machine learning predictions have become more im-\nportant than ever. However, the limited research on these diseases is reﬂected by the scarcity of\n27\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nrelevant nodes and edges around these diseases in our biological knowledge graph. Because of\nthis sparsity, the graph embedding tends to be lower quality. For example, if a disease has zero\nconnections in the KG (i.e., no existing knowledge), then the disease embedding will be the ran-\ndom initialization. Empirically, we see that prevailing GNN approaches have drastically lower\npredictive performance on our disease-centric splits to simulate this realistic property of diseases\ncompared to random splits (Figure 1g).\nWe hypothesize that the obtained network embedding for these diseases is not meaningful\ndue to this limited prior in the KG. Thus, a model must subsidize and augment the network em-\nbedding for these molecularly uncharacterized diseases. Our key insight is that human physiology\nis a connected system where diseases are similar across dimensions (e.g., lung cancer is similar to\nbrain cancer in the dimension of cancer diseases, while lung cancer is similar to asthma in the di-\nmension of lung diseases). Therefore, if we could borrow useful information from a set of similar\ndiseases that are relatively well-characterized in the KG through the model, we could augment the\nembedding of the candidate disease and improve the prediction.\nTo do that, we propose a three-step procedure: (1) a disease signature vector that captures\nthe intricate disease similarities; (2) an aggregation mechanism that integrates the different similar\ndiseases into a robust auxiliary embedding that can subsidize original disease embedding; (3) a\ngating mechanism to control the effect between the original disease embedding and the auxiliary\ndisease embedding since many well-characterized diseases have sufﬁcient embeddings and do not\nneed subsidies. We discuss each of the three steps in detail below.\nNetwork-based Disease Signature Proﬁling. The overall goal for this module is to obtain a\nsignature vectorpi for every diseasei. There are numerous ways to calculate the similarity between\ntwo diseases. As disease representations generated by the graph neural network alone are not\nsufﬁcient to characterize the candidate disease, they ideally should not be directly used to calculate\nsimilarity. Instead, we resort to graph theoretical techniques that are rooted in the ﬁeld of network\nscience5. We consider the following three types of signature functions:\n• Protein signatures (PS): The mechanism of actions for small molecule drugs is to act upon pro-\ntein targets in the disease pathway67. Thus, the ideal disease signature should preserve similarity\nin the protein target space. If two diseases have similar proteins in their corresponding disease\npathways, they are more likely to have a similar treatment mechanism1, 68. This key observation\nmotivates the protein signature 69. We have a bit vector for each disease where each bit corre-\n28\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nsponds to a speciﬁc protein. A bit is ﬂipped to one if the bit corresponds to a protein in the\ndisease pathway. Formally, for disease i, the protein signature is deﬁned as:\npPS\ni = [ p1 ··· p|VP|], (5)\nwhere\npj =\n\n\n\n1 if j ∈NP\ni\n0 otherwise,\n(6)\nand NP\ni is the set of proteins that lie in the 1-hop neighborhood of diseaseiand |VP|the number\nof total available proteins. To calculate similarity between two diseases i,j, we use dot product:\nsimPS(i,j) =pPS\ni ·pPS\nj = |NP\ni ∩NP\nj |. (7)\nThe similarity directly measures the number of intersecting proteins in the disease pathway of\ni,j. If the similarity is high, we know these two diseases have a larger number of intersecting\ndiseases, which increases the probability of similar treatment mechanisms.\n• All-node-types signatures (AT): Human knowledge about disease pathways are vastly incom-\nplete. Thus, some diseases may not have complete protein pathways in the knowledge graph,\nwhich leads to biased protein signatures. Additional biological knowledge about diseases could\npotentially beneﬁt. In the knowledge graph, other node types connect to diseases, including\neffect/phenotype, exposure, and disease. Since the local neighborhood can deﬁne some charac-\nteristics of diseases, we can extend the principle of protein signature, such that if two diseases\nshare the same nodes in these additional node types, they have similar biological underpinnings.\nWe call these all-node-types signatures. Formally, for disease i, the protein signature is deﬁned\nas:\npAT\ni = [ p1 ··· p|VP ep1 ···ep|VEP|ex1 ···ex|VEX|ep1 ···ep|VEP|d1 ···d|VD|], (8)\nwhere\npj =\n\n\n\n1 if j ∈NP\ni\n0 otherwise\n,epj =\n\n\n\n1 if j ∈NEP\ni\n0 otherwise\n,exj =\n\n\n\n1 if j ∈NEX\ni\n0 otherwise\ndj =\n\n\n\n1 if j ∈ND\ni\n0 otherwise\n(9)\n29\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nand NEP\ni ,NEX\ni ,ND\ni is the set of effect/phenotype, exposure, diseases nodes lie in the 1-hop\nneighborhood of disease iand |VEP|,|VEX|,|VD|the number of total available effect/phenotype,\nexposure, diseases respectively. We also adopt the dot product as the similarity measure, which\nmeans the similarity is the sum of all shared nodes across the four node types:\nsimAT(i,j) =pAT\ni ·pAT\nj = |NP\ni ∩NP\nj |+ |NEP\ni ∩NEP\nj |+ |NEX\ni ∩NEX\nj |+ |ND\ni ∩ND\nj |. (10)\n• Diffusion signatures (DS): The above two signatures rely on the ﬁrst-hop neighbor of the dis-\neases, while higher-hop neighbors may contain useful molecular characterization. Diffusion\nsignature simulates many random walks, where each random walk is a path of length hstarting\nfrom the disease i: w = vi\nei,1\n−−→v1 ··· vh−1\neh−1,h\n−−−→vh70. The set of visited nodes in the k-th ran-\ndom walk from disease node iis denoted as Wk\ni . ∩kWk\ni represents the total set of visited nodes\nacross all walks, and we can calculate the normalized visitation probability for visited nodejas:\nfj =\n∑\nk\n∑1 Wk\ni =j\n∑\nk|Wk\ni | (11)\nThese nodes correspond to a multi-hop snapshot of molecular interactions centering around the\ndiseases, and the visitation probability corresponds to the inﬂuence level. Given this probability\nscore, we can obtain the diffusion signature for disease node i:\npDS\ni = [f1 ··· f|VP|]. (12)\nFor diffusion signature, we still use the dot product:\nsimDS(i,j) =pDS\ni ·pDS\nj =\n|VP|∑\nu\n(∑\nk\n∑1 Wk\ni =u\n)\n·\n(∑\nk\n∑1 Wk\nj =u\n)\n(∑\nk|Wk\ni |)2\n∼\n|VP|∑\nu\n(∑\nk\n∑\n1 Wk\ni =u\n)\n·\n(∑\nk\n∑\n1 Wk\nj =u\n)\n.\n(13)\nNote the denominator (∑\nk|Wk\ni |)2 = (|k|∗h)2 is a constant. Intuitively, the similarity between\ndiseases iand jis higher when two diseases visit more shared nodes at a higher frequency.\nGiven the selected signature for diseases and calculated similarities among the diseases, for\n30\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \na query disease, we can then obtain kmost similar diseases for a query disease i:\nDsim,i = argmaxk\nj∈VDsim(i,j) (14)\nDisease-disease metric learning. Given the set of similar diseases, we aim to obtain an embedding\nthat fuses different similarity dimensions into a single embedding sufﬁcient to enhance the query\ndisease that might be sparsely annotated. We use a weighted scheme, where the similarity score\nweights each disease as follows:\nhsim\ni =\n∑\nj∈Dsim\nsim(i,j)\n∑\nk∈Dsim sim(i,k) ∗hj. (15)\nEmbedding gating. The ﬁnal step is to update the original disease embeddinghi with the disease-\ndisease metric learning embedding hsim\ni through a gating mechanism. The gating mechanism\nconsists of a scalar c∈[0,1] that balances between these two types of embeddings. Note that this\nrequires special treatment because for a disease well-characterized in the knowledge graph, we do\nnot need the disease-disease metric learning embedding, and it potentially can even bias the ﬁnal\nembedding. The disease-disease metric learning embedding is most useful for uncharacterized\ndiseases since the original disease embedding is insufﬁcient to characterize molecular mechanisms.\nNote that the learnable attention mechanism to select whether or not to attend original/augmented\nembedding does not work well because the training examples are usually the most characterized,\nwhich makes the attention weight assign high importance to the original embeddings and leaves the\nsubsidy embedding unused. Instead, we propose a heuristic algorithm that assigns weight based\non the node degree for the drug-disease relation type that is under calculation: |Nr\ni |. The higher\nthe degree, the more well-characterized the disease is, and the less weight should be assigned to\nthe disease-disease metric learning embedding and vice-versa. Also, this scalar should have a very\nhigh value when the node degree is minimal (0 or 1) and decreases quickly when the node degree\nincreases. To approximate this effect, we use an inﬂated exponential distribution density function\nwith λ= 0.7:\nci = 0.7 ∗exp(−0.7 ∗|Nr\ni |) + 0.2 (16)\nWe observe the result is not sensitive to λ(Supplementary Figure 6). Finally, we use parameter\n31\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nsearch and ﬁnd optimal λ= 0.7. Then, we can ﬁnally obtain an augmented disease embedding:\nˆhi = ci ∗hsim\ni + (1−ci) ∗hi (17)\nWe then use this augmented disease embedding to feed into the DistMult decoder 63 described in\nSection 2.3.\n2.5 Training T XGNN deep graph models\nObjective function. The training objective is to accurately predict whether or not a relation holds\ngiven two entities in the knowledge graph. This can be formulated as a binary classiﬁcation task\nfor each relation. The positive samples consist of all pairs(i,j) with diverse relation types r∈TR.\nWe denote this as D+ and the label yi,r,j = 1. Similarly, for each pair, we generate negative\ncounterparts through sampling described in Section 3, denoted as D−. For each pair i,j and its\nrelation type r, the model predicts the likelihood pi,j,r and the training loss is calculated via binary\ncross entropy loss:\nL=\n∑\n(i,r,j)∈D+∪D−\nyi,r,j ∗log (pi,r,j) + (1−yi,r,j) ∗log (1−pi,r,j) (18)\nPrevious work has focused on knowledge graph completion, leading them to optimize over the\nentire set of relations in the knowledge graph 71. However, since we are only interested in drug-\ndisease relations, training on all relation types could move the model capacity toward capturing\nknowledge we are not interested in. Conversely, since complicated biological mechanisms drive\ndrug-disease relations, the vast array of biomedical relations in the knowledge graph presents a\nunique information source that holistically describes biological systems. Thus, the challenge is to\nultimately do well on a small set of relations while also transferring knowledge positively from the\nlarger relation set.\nTo solve this challenge, TXGNN uses a pre-training strategy. During pre-training, T XGNN\nis trained to predict relations across the entire set of relation types in the KG using stochastic mini-\nbatching. This process allows TXGNN to distill biomedical knowledge into enriched node embed-\ndings. Next, during ﬁne-tuning, T XGNN zooms in and trains only on the drug-disease relations\nto obtain more granular drug-disease-speciﬁc embeddings that optimize for the best therapeutic\noutcomes.\n32\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nPre-training. TXGNN is ﬁrst pre-trained on millions of biomedical entity pairs across the entire\nset of relations. As there are millions of edges, full-graph training is computationally infeasible.\nThus, we use stochastic mini-batching to train only on a set of pairs in each training step. Each\nepoch goes through all pairs of data in the training knowledge graph. During pre-training, degree-\nadjusted disease augmentation is turned off since it is unavailable for other node types. All relations\nare treated equally. The weights of the trained encoder model are then used to initialize the encoder\nmodel weights during ﬁne-tuning. Note that the weight in the decoder DistMult wr is reinitialized\nbefore ﬁne-tuning to discourage the effect of negative transfer.\nFine-tuning. After pre-training, we have an initialization that captures general biological knowl-\nedge. Next, we focus on optimizing drug-disease relation prediction. To do that, we only use\nthe samples of all drug-disease pairs (i,j) with relation types r ∈{indication, contraindication,\nrev\nindication, rev contraindication}. The rest of the relations are discarded in the training objec-\ntive but are included in the knowledge graph for messaging the passing of drug and disease nodes.\nDuring ﬁne-tuning, the degree-adjusted inter-disease embedding is turned on.\nThe complete T XGNN model is pre-trained and ﬁne-tuned in an end-to-end manner. The\nbest-performing model on the validation set is then used for performance evaluation on the test set\nand downstream machine-learning analyses.\n2.6 Explaining model predictions\nDistilling model predictions into mechanisms of molecular networks perturbed in disease\nand targeted by therapeutics. A machine learning model can provide accurate disease treatment\npredictions. However, for domain scientists’ adoption, prediction alone is not sufﬁcient. Thus, a\nmodel is expected to generate why it outputs this prediction in a form familiar to domain experts’\ndecision-making. In the case of treatment prediction, an ideal form of explanation is to simulate\nhow drug developers approach drug-disease relation — that is, to understand how a drug perturbs\nthe local biological system such that it creates a therapeutic effect on the disease pathway. As\nTXGNN leverages the large-scale biological knowledge graph, we can probe into the local neigh-\nborhood around a query drug-disease node and pinpoint the exact mechanism contributing to the\nprediction. However, as a biological network is complex, making meaningful explanations requires\na model to prune most uninformative edges and extract a sparse version of the local neighborhood.\nThis can be formulated as a graph explainability problem where we try to identify a sparse set\nof edges where the model can make a faithful prediction using these edges 28. To achieve it, we\n33\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \ndevelop a post-training graph explainability module, adapted from GraphMask approach 27, that\ncan drop spurious edges from the dataset and retain a sparse set of edges that contribute most to-\nwards the prediction. Next, we describe the mathematical formulation of GraphMask as used by\nTXGNN.\nLocal explanation subgraphs through pruning superﬂuous biomedical relations. Given a\ntrained disease treatment prediction model, for each target node j and one of the neighbor source\nnode iwith edge ei,j at layer l, we have intermediate messages m(l)\nr,i, m(l)\nr,j given a relation r. Given\nthese two embeddings, we concatenate them and feed them into a relation-wise single-layer neural\nnetwork parameterized byW(l)\ng,r to predict the likelihood of masking the message from source node\niwhen we compute the target node jembedding, followed by a gate consisting of a sigmoid layer\nto squeeze the likelihood into 0 to 1 and an indicator function to decide whether or not to drop the\nedge:\nz(l)\ni,j,r = 1[R>0.5]\n(\nsigmoid\n(\nW(l)\ng,r\n(\nm(l)\nr,i∥m(l)\nr,i\n)))\n, (19)\nsuch that z(l)\ni,j,r ∈0,1. In practice, we add a location bias of 3 to the sigmoid function at initial-\nization. This ensures that for initialized inputs, the biased sigmoid outputs are close to 1, meaning\nthat the gates are open at initialization, and the model can adaptively close the gates to mask edges\nin the subgraph. This step is crucial as random initialization starts by dropping random edges. The\ngap between the original and updated predictions is big, so the model minimizes the gap instead of\nbalancing the two objectives. Next, instead of simply removing the message when the gate outputs\n0, the message is replaced with a learnable baseline vectorb(l)\nr for each relation rand layer l. Thus,\nthe updated message from source node ito target node jbecomes:\nˆm(l)\ni,r = z(l)\ni,j,r ·m(l)\ni,r + (1−z(l)\ni,j,r) ·b(l)\nr (20)\nThen, we can proceed with the standard message aggregation and update steps to compute\nthe updated node embedding (Section 2.2), feed to inter-disease augmentation (Section 2.4), and\ngenerate the updated predictions ˆpbetween a drug and a disease (Section 2.3). The GraphMask\ngate weights are optimized with two objectives. The ﬁrst objective is faithfulness, where the up-\ndated predictions after masking are encouraged to be the same as the original prediction outcome.\nThe second objective is to promote the model to mask as much as possible. These two objectives\npresent a trade-off since larger amounts of masking would lead to a more signiﬁcant gap between\n34\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nupdated/original predictions. This can be formulated as constrained optimization using Lagrange\nrelaxation, where we strive to maximize the Lagrange multiplierλfor constraint while minimizing\nthe main objective. Formally, we use the loss function below:\nmax\nλ\nmin\nWg\nL∑\nk=1\n∑\n(i,j,r)∈D+∪D−\n1[R̸=0]z(k)\ni,j,r + λ\n(\n∥ˆpi,j,r −pi,j,r∥2\n2 −β\n)\n, (21)\nwhere βis the margin between the updated and original prediction. After training, we can remove\nedges (i,j,r ) that have z(k)\ni,j,r = 0 and use the retained edges as the explanations. We can also\nuse the value calculated before the indicator function to measure the level of contributions to the\nprediction and can be used as adjustments of more granular differences.\nNecessary adaptations of GraphMask approach for biomedical knowledge graphs. We mod-\nify GraphMask27 in the following manner to generate meaningful local explanation subgraphs of\nthe knowledge graph. (1) Instead of a complex gate that outputs scores close to 0/1, we adopt a\nsmooth sigmoid gate where predictions are uniform across 0 to 1. This is important because we\nﬁnd hard concrete map edges to 1 as long as they affect the model prediction. However, this still\nkeeps many edges that preclude us from making acceptable medical explanations. The sigmoid\ngate instead allows us to distinguish the intensity of contributions and provides a ﬂexible frame-\nwork. By setting a threshold, we remove large amounts of positive edges and only retain ones\ncrucial for the model prediction. (2) Second, while GraphMask has a single learnable weight for\nevery edge in the dataset, we adopt a separate weight for each relation. Since embeddings across\nrelations are different, the model assigns uniformly high scores for all edges of a given relation type\ndespite edges varying in relevance. Using relation-speciﬁc weights allows the model to capture the\nimportance scores of individual edges.\n3 Experimental setup and implementation details\nNext, we outline the experimental setup, including information on performance evaluation and\ndataset splits. We also provide details on the practical implementation of T XGNN deep graph\nmodels.\n3.1 Creating dataset splits for rigorous performance evaluation\nOur dataset presents well-studied information and includes the vast majority of existing treatments.\nAs a result, it is easy to predict treatments for diseases with various pre-existing treatments. How-\n35\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \never, for zero-shot prediction of therapeutic use, we need to make good predictions on conditions\nwith few or no current treatments available. The classical random split of edges of the knowledge\ngraph into training and testing sets would not simulate this application. In the random split, for\ndiseases with many known indications, the model would view some of these drug-disease edges\nin training and thus easily predict therapeutic use based on drug similarity. However, this would\nprevent the model from assimilating meaningful biological knowledge. Therefore, we consider the\nfollowing dataset splits into training and test sets:\n• Disease area splits: Many diseases of therapeutic interest have no existing treatments and lack\nsigniﬁcant biological knowledge. To evaluate whether T XGNN would be robust to predicting\ndrug-disease relationships for such diseases, we develop data splits that simulate well-studied\ndiseases as molecularly uncharacterized diseases. We cannot directly test on molecularly un-\ncharacterized diseases, such as rare diseases, because the treatments are too few to build a con-\nﬁdent machine learning model. We select ﬁve disease groups: cell proliferation, mental health,\ncardiovascular diseases, anemia, and adrenal gland diseases, and then extract groups for these\ndiseases from the Disease Ontology hierarchy such that group includes the disease and all its\nchildren. Since these well-studied diseases have many drug-disease relationships, we can easily\nevaluate the model’s performance during the simulation.\nFor each disease, we create a separate data split as follows. First, all the drug-disease edges\nconnected to the diseases in the group are moved to the test set. As a result, T XGNN has no\ninformation about existing indications and contraindications use edges for the chosen disease\ngroup during training. This simulates the lack of existing treatments encountered with molec-\nularly uncharacterized diseases. Next, we remove a signiﬁcant fraction (5% of the knowledge\ngraph size) of the local 1-hop subgraph neighborhood for the disease group. Again, this simulates\nthe limited biological understanding of molecularly uncharacterized diseases. Dataset statistics\nof each disease area split is provided in Table 2.\n• Systematic dataset splits: The deployed machine learning model should excel at predicting\ndiseases without known treatments. Predicting new treatments for diseases that already have\ntreatments is easier than predicting diseases without treatments. This is because information\nabout existing treatments can directly illuminate the molecular mechanism, and drug similarity\ncan help infer new treatments. Thus, to robustly test our model, we design this split to systemat-\nically study prediction on novel unseen diseases. To do that, we ﬁrst randomly split the entire set\n36\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nof diseases. Then, we take all drug-disease relations associated with the testing set of diseases to\nthe test set such that there are no known treatments during training and the testing set consists of\nnovel diseases. The testing set has around 100 different diseases in each randomly seeded run.\n• Disease-centric dataset splits: We adopt a disease-centric evaluation to simulate realistic usage\nof drug candidate prioritization. First, for each disease in the test set, we pair it with all other\ndrugs in the KG, except the drug-disease relations in the training set. Then, we make predictions\nfor all pairs and rank based on the likelihood of interaction. We then retrieve the topKdrugs and\ncompute the recall (i.e., how much drug and disease in the testing set are in the top K). Finally,\nwe build a baseline of random screening where we randomly sample top K drugs from the drug\nset and compute the recall.\n3.2 Modeling molecular and clinical relationships\nIn graphs, each edge typically has a direction and points from the source to the target node. How-\never, in our biological knowledge graph, edges are bidirectional. For example, a drug Aindicated\nfor disease Bis represented in TXGNN by a tuple (A,indication,B). Similarly, disease Bcan be\ntreated by drug A, corresponding to a tuple (B,rev\nindication,A). For homogeneous relation type\n(e.g., protein-protein interactions) where the head and tail node belongs to the same node types,\nthere is no additional reverse relation type as the reverse edges are collapsed into the original re-\nlation type. Thus, we add these reverse relation types to the knowledge graph, following standard\npractice. For the sake of notation, when the reverse relation has a different relation type from the\noriginal type r, we denote the reverse relation type as rc.\n3.3 Negative sampling for training T XGNN models\nAs we only have positive data, negative data are constructed via sampling. The sampling from\nthe unobserved simulates the realistic constraint where most possible drugs do not interact with\nthe disease. For each relation type, we ﬁx the source nodes and permute the target nodes through\neither random sampling from the set of nodes associated with this relation type’s target nodes\nor a weighted sampling based on the degree of the target nodes. As we conduct reverse rela-\ntion type construction, the source node type would also be shufﬂed and included in the negative\nsamples when we do sampling for the reverse relation type. This concept of negative sampling\nbased on shufﬂing target nodes is crucial. For example, suppose we want to study drugs A that\ncan treat disease B, then we narrow down to the relation (B,rev\nindication,A) instead of the\n37\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n(A,indication,B).\n3.4 Hyperparameter tuning\nWe conduct hyperparameter tuning using Hyperband on validation set micro AUROC using com-\nplex disease split following two stages. The ﬁrst is to optimize the parameters for pre-training\nand ﬁx ﬁne-tuning parameters, where we conduct a sweep of grid search with a learning rate of\n{1e−4,5e−4,1e−3}, batch size of {1024,2048}, and epoch size of {1,2,3}. Next, we ﬁx\nthe pre-training parameters and do a grid search for ﬁne-tuning parameters with the hidden size of\n{64,128,256,512}, input size of {64,128,256,512}, output size of {64,128,256,512}, number\nof inter-disease prototypes of {3,5,10,20,50}and learning rate of {1e−4,5e−4,1e−3}. We\nobtain a ﬁnal set of hyperparameters with a pre-training learning rate of1e−3, batch size of 1024,\nepoch size of 2, the ﬁne-tuning learning rate of 5e−4, hidden size of 512, input size of 512, output\nsize of 512, number of prototypes 3.\n3.5 Implementation details\nThe TXGNN is implemented using DGL 72 and PyTorch73 Python deep learning frameworks. We\nuse Pandas74, Numpy75 for data processing and computing; scikit-learn 76 for evaluation metrics;\nseaborn77, matplotlib78, UMAP79 for visualization; Weights and Bias (https://www.wandb.ai) for\ntraining monitoring and hyperparameter tuning. We train the model with one NVIDIA Tesla V100\nGPU in a server. TXGNN Explorer is implemented in JavaScript using React.js80, D3.js81, and Ant\nDesign82. The graph data is managed using Neo4j database 83. T XGNN Explorer communicates\nwith TXGNN through a Python web server built with Flask84.\n3.6 Usability study of T XGNN with medical experts\nWe designed and developed T XGNN Explorer following a user-centric design study process 30,\nwhich compared three visual presentations of GNN explanations from users’ perspectives and mo-\ntivated the implementation of path-based explanations based on user feedback. We evaluated the\nusability of T XGNN Explorer by comparing it with a non-explanation baseline that shows drug\npredictions and corresponding conﬁdence scores. Twelve medical experts (7 males, 5 females,\navg. age=34.25) were recruited for the usability study through personal contacts, Slack channels,\nand email lists in collaborating institutions. We conducted the evaluation on Zoom due to COVID-\n19-related restrictions. Each participant logged in to the user study system (Supplementary Figure\nS5) using their computers and shared their screens with the interviewer. The order of predictions\n38\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nand the order of two conditions (TXGNN Explorer or baseline) were randomized and counterbal-\nanced across participants. For each drug assessment task, the participants were asked to 1) decide\nwhether this drug prediction is correct (i.e., the drug can potentially be used to treat the disease)\nand 2) give a conﬁdence score for their decision using a 5-point Likert scale (1=not conﬁdent at\nall, 5=completely conﬁdent). The study system automatically recorded the completion time for\nassessing each prediction. After assessing all predictions, participants provided subjective ratings\nfor the two conditions in terms of Trust, Helpfulness, Understandability, and Willingness to use\nvia a 5-point Likert scale (1=strongly disagree, 5=strongly agree).\n3.7 Evaluations within a large healthcare system\nWe leveraged patient data from the Mount Sinai Health System’s electronic health records (EHR)\nin New York City, U.S., to assess patterns from predictions in clinical practice. All clinical data\nwere deidentiﬁed, and the Mount Sinai Institutional Review Board approved the study. The cohort\nconsisted of over 10 million patients and was ﬁltered for patients over 18 years of age with at least\none drug and at least one diagnosis on record, leaving 1,272,085 patients. This cohort was 40.1\npercent male, and the average age was 48.6 years (SD: 18.6 years). Table 5 shows the dataset’s\nracial breakdown.\nAll disease and medication data were captured using the Observational Medical Outcomes\nPartnership (OMOP)85, 86 standard data model. We produce predictions for the 1,363 diseases with\nindications by training the full knowledge graph with only 5% of randomly selected drug-disease\npairs as a validation set for early stopping. This experiment does not evaluate zero-shot perfor-\nmance for all 17,080 diseases since the model has more conﬁdence in conditions with known\nindications. Disease names in the TXGNN prediction dataset were matched to SNOMED or ICD-\n10 codes and ﬁnally mapped to OMOP concepts in the Mount Sinai data system. We included\nonly diseases with at least one patient diagnosis in the dataset, leaving 480 conditions. Medica-\ntion names in the T XGNN prediction were matched to DrugBank ID, which was then mapped to\nRxNorm IDs and OMOP concepts. We included only medications with at least one patient order\nin the dataset, leaving 1,290 medications. Next, we included drug-disease pairs for which at least\none patient was listed with both the drug and the disease, leaving 1,236 drugs and 470 diseases.\nFor each drug-disease pair, we created a contingency table. Using the SciPy 87 library’s Fisher\nexact function, we computed 2-sided odds ratios and p-values for each pair. Finally, we used the\nstatsmodels88 Python library’s multi-test function to apply a two-sided Bonferonni correction on\n39\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nthe previously generated p-values. Finally, we noted statistically signiﬁcant drug-disease pairs as\nthose with p <0.005.\n40\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nDrug\nname Active ingredient Disease Appro\nval FDA Number Orphan TXG\nNN Percentile\nV\nabysmo Faricimab Macular degeneration 01/28/2022\nBLA761235 No 0.938 2.25%\nW\nelireg Belzutifan von Hippel-Lindau disease 08/13/2021\nNDA215383 Yes 0.720 4.11%\nMounjaro\nTirzepatide Type 2 diabetes mellitus 05/13/2022\nNDA215866 No 0.286 12.50%\nZtalmy\nGanaxolone CDKL5 disorder 03/18/2022\nNDA215904 Yes 0.335 18.73%\nLeqvio\nInclisiran sodium Familial hypercholesterolemia 12/22/2021\nNDA214012 No 0.301 19.32%\nT\nezspire Tezepelumab-ekko Asthma 12/17/2021\nBLA761224 No 0.233 32.41%\nVtama\nTapinarof Psoriasis 05/23/2022\nNDA215272 No 0.261 32.70%\nAdbry\nTralokinumab Atopic dermatitis 12/27/2021\nBLA761180 No 0.040 50.37%\nV\nonjo Pacritinib citrate Myeloﬁbrosis 02/28/2022\nNDA208712 Yes 0.011 63.14%\nLi\nvtencity Maribavir Cytomegalovirus infection 11/23/2021\nNDA215596 Yes 0.033 66.37%\nTable 1: Evaluation of novel TxGNN predictions against recently developed therapies. Out of 7,957 therapeutic candidates, TxGNN\nranked recent FDA-approved drugs high.\nDisease\narea Number\nof diseases Number of indications Number of Contraindications\nAdrenal\ngland 7\n41 374\nAnemia 19\n88 752\nCardiovascular diseases 113\n453 4,242\nDiseases of cell proliferation 213\n1022 1079\nMental health diseases 60\n355 1,567\nTable 2: Statistics on disease-area-based dataset splits used to evaluate the zero-shot prediction of therapeutic use. Given all\ndiseases in a given disease area, all indications and contraindications were removed from the dataset used to train machine learning\nmodels. Additionally, a large fraction (95%) of the connections between biomedical entities to these diseases were removed from\nthe therapeutics-centered knowledge graph. Disease-area splits were curated to evaluate model performance on diseases with limited\nmolecular understanding and no existing treatments.\nNode Type Count Percent (%)\nBiological process 28,642 22.1\nProtein 27,671 21.4\nDisease 17,080 13.2\nPhenotype 15,311 11.8\nAnatomy 14,035 10.8\nMolecular function 11,169 8.6\nDrug 7,957 6.2\nCellular component 4,176 3.2\nPathway 2,516 1.9\nExposure 818 0.6\nTotal number of nodes 129,375 100.0\nTable 3: Statistics on nodes in the therapeutics-centered knowledge graph.\n41\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nRelation Count Percent (%)\nAnatomy – Protein (present) 3,036,406 37.5\nDrug – Drug 2,672,628 33.0\nProtein – Protein 642,150 7.9\nDisease – Phenotype (positive) 300,634 3.7\nBiological process – Protein 289,610 3.6\nCellular component – Protein 166,804 2.1\nDisease – Protein 160,822 2.0\nMolecular function – Protein 139,060 1.7\nDrug – Phenotype 129,568 1.6\nBiological process – Biological process 105,772 1.3\nPathway – Protein 85,292 1.1\nDisease – Disease 64,388 0.8\nDrug – Disease (contraindication) 61,350 0.8\nDrug – Protein 51,306 0.6\nAnatomy – Protein (absent) 39,774 0.5\nPhenotype – Phenotype 37,472 0.5\nAnatomy – Anatomy 28,064 0.3\nMolecular function – Molecular function 27,148 0.3\nDrug – Disease (indication) 18,776 0.2\nCellular component – Cellular component 9,690 0.1\nPhenotype – Protein 6,660 0.1\nDrug – Disease (off-label use) 5,136 0.1\nPathway – Pathway 5,070 0.1\nExposure – Disease 4,608 0.1\nExposure – Exposure 4,140 0.1\nExposure – Biological process 3,250 <0.1\nExposure – Protein 2,424 <0.1\nDisease – Phenotype (negative) 2,386 <0.1\nExposure – Molecular function 90 <0.1\nExposure – Cellular component 20 <0.1\nTotal number of edges 8,100,498 100.0\nTable 4: Statistics on edges in the therapeutics-centered knowledge graph.\n42\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nRacial group Count Percent (%)\nAsian 60,041 4.7\nBlack 162,102 12.7\nWhite 534,305 42.0\nUnknown 241,998 19.0\nOther 273,639 21.5\nTotal number of patients 1,272,085 100.0\nTable 5: Demographics of the electronic health record dataset at Mount Sinai Health System in New York City used to validate\nTXGNN’s hypotheses on therapeutic use prediction.\n43\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \nReferences\n1. Menche, J. et al. Uncovering disease-disease relationships through the incomplete interac-\ntome. Science 347 (2015).\n2. Zitnik, M., Feldman, M. W., Leskovec, J. et al. Evolution of resilience in protein interactomes\nacross the tree of life. Proceedings of the National Academy of Sciences 116, 4426–4433\n(2019).\n3. Ruiz, C., Zitnik, M. & Leskovec, J. Identiﬁcation of disease treatment mechanisms through\nthe multiscale interactome. Nature Communications 12, 1–15 (2021).\n4. Goh, K.-I. et al. The human disease network.Proceedings of the National Academy of Sciences\n104, 8685–8690 (2007).\n5. Barab ´asi, A.-L., Gulbahce, N. & Loscalzo, J. Network medicine: a network-based approach\nto human disease. Nature Reviews Genetics 12, 56–68 (2011).\n6. Li, M. M., Huang, K. & Zitnik, M. Graph representation learning in biomedicine and health-\ncare. Nature Biomedical Engineering 1–17 (2022).\n7. Gysi, D. M. et al. Network medicine framework for identifying drug-repurposing opportuni-\nties for covid-19. Proceedings of the National Academy of Sciences 118 (2021).\n8. Zitnik, M., Agrawal, M. & Leskovec, J. Modeling polypharmacy side effects with graph\nconvolutional networks. Bioinformatics 34, i457–i466 (2018).\n9. Guney, E., Menche, J., Vidal, M. & Bar ´abasi, A.-L. Network-based in silico drug efﬁcacy\nscreening. Nature Communications 7, 1–13 (2016).\n10. Cheng, F., Kov ´acs, I. A. & Barab ´asi, A.-L. Network-based prediction of drug combinations.\nNature Communications 10, 1–11 (2019).\n11. Guney, E. Reproducible drug repurposing: When similarity does not sufﬁce. In Paciﬁc Sym-\nposium on Biocomputing 2017, 132–143 (World Scientiﬁc, 2017).\n12. Chandak, P., Huang, K. & Zitnik, M. Building a knowledge graph to enable precision\nmedicine. Scientiﬁc Data 10, 67 (2023).\n13. Duran-Frigola, M. et al. Extending the small-molecule similarity principle to all levels of\nbiology with the chemical checker. Nature Biotechnology 38, 1087–1096 (2020).\n14. Topping, J., Di Giovanni, F., Chamberlain, B. P., Dong, X. & Bronstein, M. M. Understanding\nover-squashing and bottlenecks on graphs via curvature. ICLR (2022).\n15. Arnaiz-Rodr ´ıguez, A., Begga, A., Escolano, F. & Oliver, N. Diffwire: Inductive graph rewiring\nvia the lov\\’asz bound. LoG (2022).\n16. Tanna, P., Strauss, R. W., Fujinami, K. & Michaelides, M. Stargardt disease: clinical features,\nmolecular genetics, animal models and therapeutic options. British Journal of Ophthalmology\n101, 25–30 (2017).\n17. Cochat, P. & Rumsby, G. Primary hyperoxaluria. New England Journal of Medicine 369,\n649–658 (2013).\n44\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n18. Schlichtkrull, M. et al. Modeling relational data with graph convolutional networks. InESWC,\n593–607 (Springer, 2018).\n19. Ding, Y ., Jiang, X. & Kim, Y . Relational graph convolutional networks for predicting blood–\nbrain barrier penetration of drug molecules. Bioinformatics 38, 2826–2831 (2022).\n20. Wang, W., Yang, X., Wu, C. & Yang, C. Cginet: graph convolutional network-based model\nfor identifying chemical-gene interaction in an integrated multi-relational graph. BMC bioin-\nformatics 21, 1–17 (2020).\n21. Shu, J., Li, Y ., Wang, S., Xi, B. & Ma, J. Disease gene prediction with privileged information\nand heteroscedastic dropout. Bioinformatics 37, i410–i417 (2021).\n22. Bickel, S., Br ¨uckner, M. & Scheffer, T. Discriminative learning under covariate shift.Journal\nof Machine Learning Research 10 (2009).\n23. Sch ¨olkopf, B. et al. On causal and anticausal learning. ICML 1255–1262 (2012).\n24. Niven, T. & Kao, H.-Y . Probing neural network comprehension of natural language argu-\nments. Proc. 57th Annual Meeting of the Association of Computational Linguistics4658–4664\n(2019).\n25. Zech, J. R. et al. Variable generalization performance of a deep learning model to detect\npneumonia in chest radiographs: a cross-sectional study.PLoS medicine 15, e1002683 (2018).\n26. Geirhos, R. et al. Shortcut learning in deep neural networks. Nature Machine Intelligence 2,\n665–673 (2020).\n27. Schlichtkrull, M. S., De Cao, N. & Titov, I. Interpreting graph neural networks for NLP with\ndifferentiable edge masking. International Conference on Learning Representations (2021).\n28. Agarwal, C., Queen, O., Lakkaraju, H. & Zitnik, M. Evaluating explainability for graph neural\nnetworks. Scientiﬁc Data 10 (2023).\n29. Agarwal, C., Zitnik, M. & Lakkaraju, H. Probing GNN explainers: A rigorous theoretical\nand empirical analysis of gnn explanation methods. In International Conference on Artiﬁcial\nIntelligence and Statistics, 8969–8996 (2022).\n30. Wang, Q., Huang, K., Chandak, P., Zitnik, M. & Gehlenborg, N. Extending the nested model\nfor user-centric xai: A design study on gnn-based drug repurposing. IEEE Transactions on\nVisualization and Computer Graphics 29, 1266–1276 (2023).\n31. Gaube, S. et al. Do as AI say: susceptibility in deployment of clinical decision-aids. NPJ\ndigital medicine 4, 31 (2021).\n32. Tschandl, P. et al. Human–computer collaboration for skin cancer recognition. Nature\nMedicine 26, 1229–1234 (2020).\n33. Chamberlain, M. C. Salvage therapy with lomustine for temozolomide refractory recurrent\nanaplastic astrocytoma: a retrospective study. Journal of Neuro-Oncology 122, 329–338\n(2015).\n34. Seetharaman, J. & Sarma, M. S. Chelation therapy in liver diseases of childhood: Current\nstatus and response. World Journal of Hepatology13, 1552 (2021).\n45\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n35. Alsentzer, E. et al. Deep learning for diagnosing patients with rare genetic diseases. medRxiv\n2022–12 (2022).\n36. O’Connell, D. Neglected diseases. Nature 449, 157–157 (2007).\n37. Tambuyzer, E. et al. Therapies for rare diseases: therapeutic modalities, progress and chal-\nlenges ahead. Nature Reviews Drug Discovery 19, 93–111 (2020).\n38. Zhang, A., Xing, L., Zou, J. & Wu, J. C. Shifting machine learning for healthcare from\ndevelopment to deployment and from models to data. Nature Biomedical Engineering 1–16\n(2022).\n39. Bastian, F. B. et al. The Bgee suite: integrated curated expression atlas and comparative\ntranscriptomics in animals. Nucleic Acids Research 49, D831–D847 (2021).\n40. Davis, A. P. et al. Comparative Toxicogenomics Database (CTD): update 2021.Nucleic Acids\nResearch 49, D1138–D1143 (2021).\n41. Pi ˜nero, J. et al. The DisGeNET knowledge platform for disease genomics: 2019 update.\nNucleic Acids Research gkz1021 (2019).\n42. Wishart, D. S. et al. DrugBank 5.0: a major update to the DrugBank database for 2018.\nNucleic Acids Research 46, D1074–D1082 (2018).\n43. Avram, S. et al. DrugCentral 2021 supports drug discovery and repositioning. Nucleic Acids\nResearch 49, D1160–D1169 (2021).\n44. Maglott, D., Ostell, J., Pruitt, K. D. & Tatusova, T. Entrez Gene: gene-centered information\nat NCBI. Nucleic Acids Research 39, D52–D57 (2011).\n45. Klopfenstein, D. V .et al. GOATOOLS: A Python library for Gene Ontology analyses. Scien-\ntiﬁc Reports 8, 10872 (2018).\n46. The Gene Ontology Consortium et al. The Gene Ontology resource: enriching a GOld mine.\nNucleic Acids Research 49, D325–D334 (2021).\n47. K ¨ohler, S. et al. The Human Phenotype Ontology in 2017. Nucleic Acids Research 45, D865–\nD876 (2017).\n48. Shefchek, K. A. et al. The Monarch Initiative in 2019: an integrative data and analytic platform\nconnecting phenotypes to genotypes across species. Nucleic Acids Research 48, D704–D715\n(2020).\n49. Weinreich, S., Mangon, R., Sikkens, J., Teeuw, M. E. e. & Cornel, M. [orphanet: a european\ndatabase for rare diseases]. Nederlands tijdschrift voor geneeskunde 152, 518—519 (2008).\n50. Matys, V . et al. TRANSFAC ® : transcriptional regulation, from patterns to proﬁles. Nucleic\nAcids Research 31, 374–378 (2003).\n51. Ceol, A. et al. MINT, the molecular interaction database: 2009 update.Nucleic Acids Research\n38, D532–D539 (2010).\n52. Aranda, B. et al. The IntAct molecular interaction database in 2010. Nucleic Acids Research\n38, D525–D531 (2010).\n46\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n53. Giurgiu, M. et al. Corum: the comprehensive resource of mammalian protein com-\nplexes—2019. Nucleic acids research 47, D559–D563 (2019).\n54. Oughtred, R. et al. The BioGRID database: A comprehensive biomedical resource of curated\nprotein, genetic, and chemical interactions. Protein Science 30, 187–200 (2021).\n55. Szklarczyk, D. et al. The string database in 2021: customizable protein–protein networks, and\nfunctional characterization of user-uploaded gene/measurement sets. Nucleic Acids Research\n49, D605–D612 (2021).\n56. Luck, K. et al. A reference map of the human binary protein interactome.Nature 580, 402–408\n(2020).\n57. Jassal, B. et al. The reactome pathway knowledgebase. Nucleic Acids Research gkz1031\n(2019).\n58. Kuhn, M., Letunic, I., Jensen, L. J. & Bork, P. The SIDER database of drugs and side effects.\nNucleic Acids Research 44, D1075–D1079 (2016).\n59. Mungall, C. J., Torniai, C., Gkoutos, G. V ., Lewis, S. E. & Haendel, M. A. Uberon, an\nintegrative multi-species anatomy ontology. Genome Biology 13, R5 (2012).\n60. Alsentzer, E. et al. Publicly Available Clinical BERT Embeddings 7.\n61. Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O. & Dahl, G. E. Neural message passing\nfor quantum chemistry. In ICML, 1263–1272 (PMLR, 2017).\n62. Glorot, X. & Bengio, Y . Understanding the difﬁculty of training deep feedforward neural\nnetworks. In AISTATS, 249–256 (2010).\n63. Yang, B., Yih, W.-t., He, X., Gao, J. & Deng, L. Embedding entities and relations for learning\nand inference in knowledge bases. ICLR (2015).\n64. Griggs, R. C. et al. Clinical research for rare disease: opportunities, challenges, and solutions.\nMolecular Genetics and Metabolism 96, 20–26 (2009).\n65. Boycott, K. M., Vanstone, M. R., Bulman, D. E. & MacKenzie, A. E. Rare-disease genetics in\nthe era of next-generation sequencing: discovery to translation. Nature Reviews Genetics 14,\n681–691 (2013).\n66. Thomas, S. & Caplan, A. The orphan drug act revisited. Jama 321, 833–834 (2019).\n67. Yıldırım, M. A., Goh, K.-I., Cusick, M. E., Barab´asi, A.-L. & Vidal, M. Drug—target network.\nNature Biotechnology 25, 1119–1126 (2007).\n68. Agrawal, M., Zitnik, M. & Leskovec, J. Large-scale analysis of disease pathways in the human\ninteractome. In Proceedings of the Paciﬁc Symposium on Biocomputing, 111–122 (2018).\n69. Kov ´acs, I. A. et al. Network-based prediction of protein interactions. Nature Communications\n10, 1–8 (2019).\n70. Raj, A., Kuceyeski, A. & Weiner, M. A network diffusion model of disease progression in\ndementia. Neuron 73, 1204–1215 (2012).\n71. Lin, Y ., Liu, Z., Sun, M., Liu, Y . & Zhu, X. Learning entity and relation embeddings for\nknowledge graph completion. In AAAI (2015).\n47\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint \n72. Wang, M. et al. Deep graph library: Towards efﬁcient and scalable deep learning on graphs.\n(2019).\n73. Paszke, A. et al. Pytorch: An imperative style, high-performance deep learning library.\nNeurIPS 32, 8026–8037 (2019).\n74. McKinney, W. et al. pandas: a foundational python library for data analysis and statistics.\nPython for High Performance and Scientiﬁc Computing 14, 1–9 (2011).\n75. Harris, C. R. et al. Array programming with numpy. Nature 585, 357–362 (2020).\n76. Pedregosa, F. et al. Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch 12, 2825–2830 (2011).\n77. Waskom, M. L. Seaborn: statistical data visualization. Journal of Open Source Software 6,\n3021 (2021).\n78. Hunter, J. D. Matplotlib: A 2d graphics environment. Computing in science & engineering 9,\n90–95 (2007).\n79. McInnes, L., Healy, J., Saul, N. & Grossberger, L. Umap: Uniform manifold approximation\nand projection. The Journal of Open Source Software 3, 861 (2018).\n80. Inc, F. React.js. https://github.com/facebook/react.\n81. Bostock, M., Ogievetsky, V . & Heer, J. D 3 data-driven documents. IEEE Transactions on\nVisualization and Computer Graphics 17, 2301–2309 (2011).\n82. Team, A. D. Ant design. https://github.com/ant-design/ant-design/.\n83. Neo4j, I. Neo4j graph data platform. https://neo4j.com. Accessed: 2020-10-01.\n84. Grinberg, M. Flask web development: developing web applications with python (” O’Reilly\nMedia, Inc.”, 2018).\n85. Stang, P. E. et al. Advancing the science for active surveillance: rationale and design for\nthe Observational Medical Outcomes Partnership. Annals of Internal Medicine 153, 600–606\n(2010).\n86. Klann, J. G., Joss, M. A., Embree, K. & Murphy, S. N. Data model harmonization for the All\nOf Us Research Program: Transforming i2b2 data into the OMOP common data model. PloS\nONE 14, e0212463 (2019).\n87. Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientiﬁc computing in Python.\nNature Methods 17, 261–272 (2020).\n88. Seabold, S. & Perktold, J. Statsmodels: Econometric and statistical modeling with python. In\nProceedings of the 9th Python in Science Conference, vol. 57 (2010).\n48\n . CC-BY 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted March 20, 2023. ; https://doi.org/10.1101/2023.03.19.23287458doi: medRxiv preprint "
}