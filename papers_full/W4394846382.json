{
  "title": "Assessing Usability of Large Language Models in Education",
  "url": "https://openalex.org/W4394846382",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5094018540",
      "name": "Leo Huovinen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1726210583",
    "https://openalex.org/W3197976508",
    "https://openalex.org/W4366548330",
    "https://openalex.org/W1939570644",
    "https://openalex.org/W4241043733",
    "https://openalex.org/W2011258666",
    "https://openalex.org/W2916904544",
    "https://openalex.org/W4400049129",
    "https://openalex.org/W4210614090",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2139050370",
    "https://openalex.org/W4396229200",
    "https://openalex.org/W4391559941",
    "https://openalex.org/W4389157038",
    "https://openalex.org/W1980741066",
    "https://openalex.org/W3084138802",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2892021205",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W2013565625",
    "https://openalex.org/W1596953637",
    "https://openalex.org/W997324903",
    "https://openalex.org/W4307001389",
    "https://openalex.org/W2973508446",
    "https://openalex.org/W4366327299",
    "https://openalex.org/W2131965512",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W4385569970",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W2125633073",
    "https://openalex.org/W2983991260",
    "https://openalex.org/W3111683616",
    "https://openalex.org/W4214935824",
    "https://openalex.org/W1731704170",
    "https://openalex.org/W2130517825",
    "https://openalex.org/W2032010382",
    "https://openalex.org/W1567460621",
    "https://openalex.org/W4322760121",
    "https://openalex.org/W3106362911",
    "https://openalex.org/W3005570470",
    "https://openalex.org/W3035509916",
    "https://openalex.org/W4320858112",
    "https://openalex.org/W3028484854",
    "https://openalex.org/W3173346761",
    "https://openalex.org/W1990580455",
    "https://openalex.org/W2918497321",
    "https://openalex.org/W3199377785",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W4322775461",
    "https://openalex.org/W4321499561",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W2033862310",
    "https://openalex.org/W1997430717",
    "https://openalex.org/W3187911027",
    "https://openalex.org/W2031213082"
  ],
  "abstract": "The aim of the final year project was to investigate the potential of utilizing Large Language Models (LLMs) in automating and enhancing the process of curriculum development.The project was carried out through the development and implementation of the LLM-based web application, followed by usability testing using the cognitive walkthrough approach and user feedback sessions. Test users were presented with the tool and tasked with evaluating its effectiveness, clarity, and overall usability in the context of curriculum planning. Feedback from users highlighted the importance of clear guidance, integration of tasks into a centralized tool, and the need for human input in verifying and refining generated content, to ensure accurate and meaningful goals in curriculum design. These findings will guide the further development and refinement of the application.",
  "full_text": " \n Leo Huovinen \nAssessing Usability of Large \nLanguage Models in Education  \nMetropolia University of Applied Sciences \nBachelor of Engineering \nInformation and Communication Technology \nBachelor’s Thesis \n23rd February 2024\n \nAbstract \nAuthor: Leo Huovinen \nTitle: Assessing Usability of Large Language Models in \nEducation \nNumber of Pages: 27 pages \nDate: 23rd February 2024 \nDegree: Bachelor of Engineering \nDegree Programme: Information and Communication Technology \nProfessional Major: Information and Communication Technology \nSupervisors: Mika Hämäläinen, Project Manager \n Janne Salonen, Head of School \nThe aim of the final year project was to investigate the potential of utilizing Large \nLanguage Models (LLMs) in automating and enhancing the process of curriculum \ndevelopment. The study sought to investigate how these models could streamline the \nlaborious tasks involved in curriculum planning. \nThe project was carried out through the development and implementation of the LLM-\nbased web application, followed by usability testing using the cognitive walkthrough \napproach and user feedback sessions. Test users were presented with the tool and \ntasked with evaluating its effectiveness, clarity, and overall usability in the context of \ncurriculum planning. The study aimed to understand user interactions with the tool \nand identify areas for improvement to enhance its usability. \nThe results of this study show that while the LLM-based tool has the potential to \nstreamline certain aspects of curriculum planning, there are key areas that require \nattention. Feedback from users highlighted the importance of clear guidance, \nintegration of tasks into a centralized tool, and the need for human input in verifying \nand refining generated content, to ensure accurate and meaningful goals in \ncurriculum design. These findings will guide the further development and refinement \nof the application. \n \n \nKeywords: LLM, NLP, AI, Usability, Education, Curriculums \n___________________________________________________________ \n \nThe originality of this thesis has been checked using Turnitin Originality Check \nservice.\n \n \nTiivistelmä \nTekijä:  Leo Huovinen \nOtsikko: Suurten kielimallien hyödynnettävyyden arviointi \nopetuksessa \nSivumäärä: 27 sivua \nAika: 23.2.2024 \nTutkinto: Insinööri (AMK) \nTutkinto-ohjelma: Tieto- ja viestintätekniikan tutkinto-ohjelma  \nAmmatillinen pääaine:  Tieto- ja viestintätekniikan tutkinto-ohjelma  \nOhjaajat: Mika Hämäläinen, Projektipäälikkö \n Janne Salonen, Osaamisaluejohtaja \nTämän opinnäytetyön tavoitteena oli tutkia suurten kielimallien (Large Language \nModels, LLM) potentiaalia opetussuunnitelmien kehittämistyön automatisoinnissa ja \ntehostamisessa. Tutkimus pyrki selvittämään, miten nämä mallit voisivat \nvirtaviivaistaa työläitä tehtäviä, jotka liittyvät opetussuunnitelman suunnitteluun.  \nOpinnäytetyö toteutettiin kehittämällä ja toteuttamalla LLM-pohjainen webapplikaatio, \njonka käytettävyyttä testattiin kognitiivisen kävelyn lähestymistavan ja \nkäyttäjäpalautteen kautta. Testikäyttäjille esiteltiin työkalu ja heidät pyydettiin \narvioimaan sen tehokkuutta, selkeyttä ja yleistä käytettävyyttä opetussuunnitelmien \nsuunnittelukontekstissa. Tutkimuksen tavoitteena oli ymmärtää käyttäjien \nvuorovaikutusta työkalun kanssa ja tunnistaa käytettävyyteen liittyviä kehityskohteita. \nTutkimuksen tulokset osoittavat, että vaikka LLM-pohjaisella työkalulla on \npotentiaalia vähentää työläitä tehtäviä opetussuunnitelman suunnittelussa, on vielä \nolemassa huomiota vaativia osa-alueita. Käyttäjäpalautteiden perusteella korostui \nselkeän ohjeistuksen, tehtävien integroimisen keskitettyyn työkaluun sekä ihmisen \npanoksen tarve tuotetun sisällön tarkistamisessa ja hienosäätämisessä. Nämä \nhavainnot ohjaavat työkalun jatkokehitystä ja hienosäätöä. \n \nAvainsanat: LLM, NLP, AI, tekoäly, käytettävyys, opetus, \nopintosuunnitelmat \n \n \nContents \nList of Abbreviations \n1 Introduction 1 \n2 Text processing using NLP 2 \n2.1 Personalized approaches with NLP 2 \n2.2 Modern large language models 3 \n3 Addressing the needs of curriculum development 5 \n4 LLM curriculum tool and usability tests 9 \n4.1 A user-friendly application 9 \n4.2 Cognitive walkthrough 15 \n4.3 User tests 19 \n5 Discussion and conclusions 26 \n \n \n \n \n \n \n \n \n \n \n \nList of Abbreviations \n \nLLM: Large Language Models \nNLP:   Natural Language Processing \nUN:          the United Nations \nSDG: United Nation’s Sustainable Development Goals \nGPT:          Generative Pre-trained Transformer\n1 \n \n \n \n \n1 Introduction \nLarge Language Models (LLMs) hold immense potential for a variety of writing \nand planning tasks. Pre -trained on large text corpora, they can achieve  \nremarkable performance on natural language tasks (Chen & Yih, 2020). \nHowever, the widespread use of LLMs has largely been limited to manually typing \nprompts into tools like ChatGPT, with limitations on scalability and reliability of \noutput (Zamfirescu-Pereita et al., 2023). \n \nBase models, such as BERT, can be fine -tuned with task-specific datasets  to \nrecognize, summarize, translate, and generate natural language text. (Devlin et \nal., 2018). However, the current prerequisite of a technical background \nsignificantly limits this kind of integration of LLMs into non -technical users’ \npersonal workflow (Kinnula et al., 2021). \n \nThis barrier to usability highlights the current gap between the effectiveness of AI \ntools and the growing pains in the usability of AI tools within the everyday \nworkflow (Amershi et al., 2019). \n \nIn response to this challenge, this study focuses on the development of a user -\nfriendly interface in the context of improving curriculum planning at Metropolia \nUniversity of Applied Sciences. The objective is to incorporate an LLM-based tool \nas a part of the natural workflow of curriculum planning. \n \nIts usability is reviewed using the cognitive walkthrough approach and a series of \nuser tests (Polson et al., 1992). The results of these user tests will be discussed \nto assess the user experience and gather feedback for further refinement of this \nLLM-based tool as a natural part of the education workflow. \n \n \n \n2 \n \n \n \n \n \n \n2 Text processing using NLP \n \nMachine learning algorithms can be trained to process large volumes of data, \nrecognize patterns and categori ze information, replacing the need for human \ninvolvement in such repetitive tasks (Amershi et al., 2019). \n \nOne form of machine learning is Natural Language Processing (NLP). NLP-based \nsolutions have gained significant traction in the field of education, as working with \ncurriculums and study materials involves processing large amounts of text only \nunderstandable by domain experts. Data analysis, based on NLP methods, can \nprovide a more accurate understanding and analysis, and therefore further \nprocessing, of such a large amount of data and information. (Chowdhury, 2023.)  \n2.1 Personalized approaches with NLP                                                                                                                                \nAs the field of NLP continues to evolve, there is also a growing emphasis on \npersonalization and adaptation techniques, aiming to process natural language \nin a more flexible and user-specific manner (Lucie, 20 20).  This shift towards \npersonalized NLP is seen as a means to address the limitations of traditional NLP \ntools and to provide more accessible and more effective tools for a diverse range \nof users. (Flek, 2020.)  \nThe workplace environment is increasingly inundated with information, leading to \nentire fields of science observing information overload and its impact on \nemployees (Parasuraman, 2011). This information overload stems from various \nsources, including excess ive information supply, multitasking, and inadequate \nworkplace information infrastructure (Kirsch, 2000). Such literature underscores \n3 \n \n \n \n \nthe need for interface designs and optimi zed tools that effectively manage \ncognitive load and information overload. \nMany domain -specific tasks that involve simple categorization or data \nprocessing, for instance, could be significantly sped up through AI integration. In \nthe context of education, this flexibility would allow study planners and curriculum \ncoordinators to f ocus on higher -order tasks, such as determining the learning \nobjectives and outcomes, rather than on the repetitive task of writing similar \ncontent.  \nThe design and usability of web interfaces play a significant role in managing \ncognitive load. Insufficient contrast and task difficulty can increase cognitive load, \naffecting website usability (Sonderegger & Sauer, 2010). User tests for web \ninterfaces have found selective filtering of information to be an effective way of \nmitigating information overload (Savolainen, 2007). \nTherefore, optimizing web interface design based on the userbase’s professional \nand personal background, and their specific cognitive load is crucial to mitigate  \ncognitive strain and enhance user experience. Literature suggests that adaptive \ninterfaces based on the needs of users can help reduce cognitive strain. (López-\nJaquero et al., 2005.) \n2.2 Modern large language models \nLarge language models (LLMs), like the recent GPT-4 (Achiam et al., 2023), \nLlama 2 (Touvron, et al. 2023) and Falcon (Almazrouei et al., 2023) have been in \nthe spotlight  in the last few years, due to their remarkable capabilities in \ncomprehending and producing natural language content of different types . The \nmodels can understand  natural language inputs and produc e coherent, even \nintelligent, text. (Brown et al., 2020.) \n \n4 \n \n \n \n \nLLMs are pre -trained on vast text corpora, often comprising billions of tokens, \nenabling them to capture a broad and diverse range of linguistic patterns and \nknowledge. This extensive pre -training on large -scale datasets allows LLMs to \nacquire a deep under standing of language, making them capable of attaining \nremarkable performance in different natural language tasks. (Wang et al., 2018). \n \nWhen pretrained on different tasks, LLM models have demonstrated remarkable \nproficiency across several NLP tasks, such as machine translation (Kocmi & \nFedermann, 2023), question answering (Chen & Yih, 2020) and text \nsummarization (Zhang et al., 2023). \n \nLLM-based tools, based on PaLM (Chowdhery et al., 2022) can be customized \nto match the needs of curriculum writers. For one instance, these models could \nbe fine-tuned on a vast array of educational content (See Latif et al., 2022.) \n \nCurrent research has demonstrated the remarkable results of LLMs in various \nNLP tasks with few -shot (or even one -shot) learning, which involves inference \nbased on a few (or just one) demonstration examples (Hegselmann, 2023) . In \nrecent years, f ew-shot learning has attracted substantial attention (Mosbach, \n2023.)  \n \nIt involves training models to make accurate predictions with only a few labelled \nexamples. This approach is particularly useful in scenarios where labelled data \nis scarce or when adapting to new tasks, such as in prototyping. (Winata, 2021) \n \nHowever, this prompt designing can be a laborious process. (Zamfirescu-Pereita \net al., 2023) One solution to this is providing prompt templates for users to utilize, \nand to automatically fill in these prompts with contextual data from the user’s \ninterface environment (Cao et al., 2023). One such solution will be looked at with \nthe tool presented in this final year project, in the context of curriculum planning. \n \n5 \n \n \n \n \n3 Addressing the needs of curriculum development \nCurriculum development is a multifaceted process. The stages of curriculum \ndevelopment include curriculum goal analysis, syllabus design, creating study \nmaterials, teaching students, and evaluating study outcomes. (Richards, 2001.) \n \nCurriculum developers are responsible for identifying and incorporating these \nnecessary goals and competencies into the curriculum to equip students for the \nchallenges of the contemporary world. (Schwab, 1973.) \n \nMany curriculum coordinators also act as teachers. The involvement of teachers \nin the curriculum development design process is crucial, as they possess first -\nhand knowledge of classroom dynamics and the practicality of materials.  \n(Renfors, 2021.) \n \nThis demanding task of curriculum development requires a team of curriculum \nplanners, or curriculum coordinators. They must know the competencies \nexpected of students upon graduation , and the curriculum’s role in helping the \nstudents attain these objectives . They are tasked with defining the expected \nabilities that students should possess upon transitioning to the workforce. They \nmust guide the graduates in navigating the workforce and the surrounding world. \n(Alsagoff & Low, 2007.) \n \nThe development of a curriculum involves a series of complex iterative steps. \nDesigning a curriculum requires careful consideration of various factors to ensure \nits effectiveness and relevance. The development of a more holistic, sustainable, \nand adaptable approach to curriculum design is an ongoing challenge. (Vreuls et \nal. 2022.) \n \nYet at the same time, curriculums must be updated at an ever-faster rate, with \nhigher degree of automation, as the skills required by graduates are likely to \nchange at a faster pace compared to previous years (Walker, 2012) . The needs \n6 \n \n \n \n \nof graduating students should be considered to ensure that the curriculum aligns \nwith the competencies and skills required by employers (Pereira et al., 2020). \n \nIt must also match the current dynamic changes within the culture. The \nmultifaceted nature of curriculum development is evident in the diverse \nperspectives and approaches to curriculum design, as well as the ongoing efforts \nto match the changes in culture and society (Green & Whitsed, 2013). This is \ncrucial in the learning environment at every stage, as the gap on the skills and \nknowledge between curriculum and work life is perceptible by both students and \nemployers (Aryanti & Adhariani, 2020). \n \nDespite all these shared challenges, it is typical to encounter slightly varied \nterminologies and lexicons when a university (or any educational institution ) \ndescribes its curriculum. This is because each university and university of applied \nsciences follows its own practices and processes in developing its curriculum and \ndesigning curriculum descriptions. (Khan et al., 2019.) \n \nKhan et al. (2019) further highlight the importance of standards and standardized \nterminology in ensuring the quality and viability of curriculums. Standards for \noutcomes and goals are ill-defined and challenging to compare. The units of the \ncurriculum may be programs or courses. They may comprise different kinds of \nunits or modules and be delivered through completely different platforms, lessons \nor classes. \n \nControlling the use of a specific framework or specific vocabulary is nearly \nunmanageable, and there is no formal way that dictates which terms or goals are \nto be used. There is a need for increased alignment and a shared vision in \neducation programs in sustainability, highlighting the need of a cohesive template \nto integrate shared sustainability principles into a higher education curriculum  \n(Fraser & Bosanquet, 2006).  \n \n7 \n \n \n \n \nThe UN sustainability goals offer one approach to standardi zed goals within \nhigher education curriculum development (Fishman & Krajcik, 2003). The United \nNations Sustainable Development Goals (SDGs) are a set of 17 global targets \naimed at addressing social, economic, and environmental challenges to achieve \na better and more sustainable future by 2030 (UN, 2015). Figure 1 shows the 17 \ndifferent categories that make up the UN sustainability objectives. \n \n \nFigure 1. The 17 UN Sustainable Development Goals (UN, 2015) \nIntegration of sustainable development principles into higher education \ncurriculum is essential for preparing students to address environmental and \nsocietal challenges.  By aligning the curriculum with the UN SDGs, higher \neducation institutions can have a crucial function in creating future leaders who \ncan address environmental and societal issues (Franco et al., 2019). Research \nhas also pointed out how both LLMs and smaller NLP models are able to identify \nUN SDGs within school curriculums, making them a great standard (Kharlashkin \net al., 2024). \n \nThe realisation of such progressive objectives included in official curriculum texts \nis far from guaranteed, even with human writers, much less machine ones. As \nMetropolia UAS  is dedicated to including sustainability in all of its degree \n\n8 \n \n \n \n \nprograms by 2030, there is a lot of internal motivation for finding solutions to \nanalysing sustainability within curriculums (Metropolia, 2021). At EU -level, \ndifferent degrees also have certain standardi zed expectations for what must be \nincluded within each curriculum (EU, 2018).  \n \nDespite these guidelines, the lack of structure around the curriculum design \nprocess continues to be a problem. The notion of a curriculum is broad and \ndynamic, reflecting the complexity of its design process, underscoring the \nsignificance of curriculum coordinators in driving educational reforms. Curriculum \ncoordinators play a crucial role in educational institutions, particularly in the \nintegration of new innovations and trends into the curriculum policies.  \n \nThese traditional methods of curriculum design can be laborious and time -\nconsuming, involving numerous different tasks, including needs analysis, goal \nsetting, syllabus design, materials development and material adaptation.  \nEducators have historically been responsible for developing and revising learning \nmaterials as curriculums develop a process that can be repetitive and inefficient.  \n(Voogt et al., 2019) \n \nCould curriculum design and analysis be automated using machine learning? At \nleast it can be sped up using many of the already existing data analysis and NLP \ntools, reducing the workload involved in the design process (Hamam & Loucif, \n2009; Teixeira, 2020.)   \n \nLLMs’ remarkable ability to understand and generate text -based conten t \nstreamlines various NLP tasks (Brown et al., 2020). As earlier, NLP methods can \nbe used to conduct content analysis of curriculum materials, identifying the \ngeneral structure, recommendations, and expected learning outcomes . LLMs \ncould potentially offer degree program coordinators an even more powerful \nmeans to identify and interpret the goals embedded within curriculum texts . \n(Teixeira, 2020.) \n \n9 \n \n \n \n \nBut these complex dynamics within teams of curriculum coordinators underscore \nthe challenges and intricacies involved in reali zing any form of automated \napproach to curriculum writing. To identify the goals within a university curriculum \ntext corpus, it is essential to consider interdisciplinary approaches, and alignment \nwith broader educational objectives. These tools must reduce cognitive workload \nand assist the curriculum planners, not add further complexity to the workflow. \n(Voogt et al., 2019.) \n \n4 LLM curriculum tool and usability tests \n4.1 A user-friendly application \nWhile ChatGPT has found popular use, most NLP  engines require knowledge \nand expertise in machine learning, natural language processing, and \nprogramming, their uptake is relatively low among laypeople (Kinnula et al., \n2021). \n \nMachine learning skills, while common among computer scientists and data \nanalysts, are not typically found among educators. This mismatch between the \nrequired skills and those possessed by educators creates a significant gap, \npreventing the full integratio n of LLMs into educational settings . (Lindner et al., \n2019.) \n \nAs different NLP tools become more and more widely used in education, their \nusability becomes a critical question. The technical performance of NLP tools has \ntraditionally been evaluated numerically using objective and constraint functions \nand various benchmarking platforms (Wang et al., 2018) . But usability of NLP \ntools is a question that has been approached less. \n \nThe implementation of AI should aim to ensure equitable access to these \ntechnologies. The lack of research into usability and accessibility that a wider AI \n10 \n \n \n \n \nintegration demand is a valid concern, especially as AI is increasingly integrated \ninto an increasing number of work tasks. For both employers and industry, \nguaranteeing ease of adaptation is critical. (Zheng et al., 2015.) \n                                                                                                                                                                                                               \nBy leveraging LLM -based tools, curriculum writers could generate, modify, and \ncustomize content more efficiently, thereby reducing redundancy and increasing \nproductivity. (cf. Teixeira, 2020.) \n \nTherefore, the design and implementation of user -friendly interfaces, as well as \nthe evaluation of usability, will continue to be central to the development of these \ntools. (Kocielnik et al., 2019.) \n \nAs part of a larger remodelling of Metropolia University of Applied Sciences \ncurriculum structure, the organization wanted to harness the potential of LLMs in \ncurriculum design. For this a more user-friendly interface was wanted. \n \nThe aim of this final year project was to create an easy -to-use interface that \ncombines backend LLM prompt templates and regular expressions to \nstandardize the generated text into a data table of numbers and descriptions, with \na front-end that is easy to use and reduces cognitive workload.  \n \nThe application is divided into a frontend and a backend. The React backend is \nan academic data exploration webpage, designed to provide analysis and \ninsights into the curriculum of the chosen domain. The color choices and visual \naesthetics of the frontend were designed to resemble the Metropolia UAS brand, \nin order to make it feel less intimidating (cf. Sonderegger & Sauer, 2010). \nThe application is presented in in Figures 2 – 4. \n \nAs seen in Figure 2, t he landing page of the application allows users to select a \nspecific year and language (Finnish or English) to explore and analyse the \ncourses across the last 20 years. Users can view detailed information from each \ncourse, including course name, credits, course content and objectives. Results \n11 \n \n \n \n \nof the AI analysis, whether newly queried or earlier cached results, are visible \ndirectly within the application. \n \n \nFigure 2. The landing page of the application \n \nOrientation-wise, the top toolbar includes a dropdown menu for the years, buttons \nfor language selection, and a download option for exporting data. A sidebar, as \nseen in Figure 3, contains courses of the current year, and the main page \ncontains the curriculum to be analysed. \n \n\n12 \n \n \n \n \nFigure 3. The curriculum analysis page of the application \nAs seen in Figure 4, users can further visualize the results of the LLM analysis, \nby using charts. Additionally, the application features loading animations and \nsmooth scroll animations for a comprehensive user experience. \n \nFigure 4. Results display on the curriculum analysis page of the application \n \n\n13 \n \n \n \n \n \nThe steps of using the application are represented by the following numbers: \n1. Upper bar / tooltip. Always visible. The user chooses the tool language \nusing buttons and the year of the curriculum through a dropdown menu. \n2. Sidebar. Always visible. Holds all the degrees from a chosen year that the \nuser can choose from. The user chooses their respective course \ncurriculum domain and degrees they want to process , from a scrollable \nsidebar. \n3. A toolbar for the goal buttons. The tool can be switched to analyze the \ncurriculums using either UN SDG goals, the Finnish university of applied \nsciences goals (ARENE goals) or job market goals. \n4. A button to launch the AI tool, at the center of the page. It queries all the \ncourses of the current degree program to the Vertex backend, saving the \nresults into a cache and into the server’s MongoDB database. \n5. A button to launch the AI tool for each individual course. Given the \nunpredictable nature of LLM’s, errors and missing output may occur. Here \nthe user can resend the query with different stochastic parameters. \n6. Two buttons to upload and export the results.  Initially grayed out, once a \ncourse has been selected, the user can upload the goals to the organization’s \nbackend or export the analyzed goals into an Excel spreadsheet. \n \nBehind the interface, there is an extensive backend. Using a Flask backend \n(Pallets, 2023) the users can analyse the curriculum directly within the application \nfor associated goals, such as UN SDGs, ARENE goals (Arene, 2022) and Finnish \njob market goals. \n \nThe backend utilizes a large language model for text generation to analyse the \ncurriculum descriptions provided by the users. It generates a response in the form \nof a JSON file containing the top 5 most relevant UN SDGs based on a relevancy \n14 \n \n \n \n \nscore assigned to each goal. Additionally, the backend can provide a description \nof how the curriculum aligns with specific UN SDGs by matching quotes from the \ncurriculum to relevant keywords. \n \nThe backend is structured to handle requests in both Finnish and English, \nallowing users to interact with the system based on their language preference. \nThis is due to PaLM 2’s multilingual capabilities. (Anil, 2023) The generated \noutput is cached in a MongoDB database, providing a structured way to organize \nand access the analysed information for future reference, before uploading it to \nthe organization’s backend. The curriculum data itself is the latest curriculum data \nfrom the organization’s Peppi database. \n \nFor the LLM part of the backend, Google Vertex AI platform’s multilingual PaLM \n2 model was chosen. Google Vertex AI is an integrated platform for developing, \ndeploying, and maintaining machine learning models. This  environment is \ndesigned to streamline the ML workflow. (Google, 2024) Several alternatives to \nGoogle Vertex AI , and its provided models exist in the market, each with their \nstrengths and weaknesses. Microsoft's Azure Machine Learning is one such \ncommercial alternative (Microsoft, 2024), open-source models such as Llama are \nanother (Touvron, et al. 2023). \n \nPaLM 2 is an improved language model over its predecessor, PaLM, with \nenhanced multilingual and reasoning capabilities. It is more compute -efficient, \nexhibits better quality on downstream tasks across different model sizes, and \noffers faster and more effic ient inference. It delivers groundbreaking results , \noutperforming traditional state-of-the-art models on a number of multi -step \nreasoning language tasks. (Anil, 2023.) \n \nPrompt templates used in the tool are structured using a one-shot strategy.  Using \nFlask, the prompt is automatically formulated to ask the model to score the top 5 \nmost relevant UN SDGs based on a relevancy score within a given curriculum \ndescription. Thi s automatic prompt generation guides the model to generate \n15 \n \n \n \n \nresponses to automatically include appropriate course information from the \nbrowsed curriculum, requiring no prompt engineering on the user’s end. (cf. Cao \net al., 2023.) \n \nThe prompt also instructs the model to return the information in a specific JSON \nformat. Regex (regular expression) processing is used to extract UN SDG goal \nnumbers from the JSON string the model generates. This allows the tool to \norganize and present the information in a structured manner, utili zing data \nvisualization libraries such as Chart.js. (Chart.js, 2023.) \n \nUsability-wise, the app features a number of interactive elements.  There are \ndropdown menus for selecting the year, language change buttons, and task -\nspecific buttons for analysing different types of goals associated with the courses. \nUsers can also download an Excel chart based on the selected course and \ncurriculum. In the near future, thi s tool can also send and receive data directly \nbetween the organization’s internal backend services, namely the Peppi service \n(Peppi-Konsortio, 2023) and Metropolia’s Teams group. \n \nWith so many interactive elements and a complicated motivation for the tool, how \ncan one be sure it  is usable comfortably? Cognitive walkthrough analysis was \nused along with user tests to assess the accessibility and usability of these \ninteractive elements.  \n \n4.2 Cognitive walkthrough \nCognitive walkthrough is a theory-based evaluation of user interfaces, providing \na systematic way to assess the steps involved in using the webpage or program \nwithout the need for test users. The cognitive walkthrough method is a valuable \napproach for evaluating the usability of software and online tools, particularly in \nterms of identifying and predicting usability problems. It provides a structured \napproach to understanding user interactions, identifying usability issues, and \n16 \n \n \n \n \nultimately enhancing the user experience in a way that minimizes cognitive load.  \n(Polson et al., 1992.) \n \nIn the context of software and online tools designed to manage cognitive load \nnewer variations on the cognitive walkthrough method have been instrumental in \nassessing the usability and user experience (Mahatody et al., 2010) . The \nCognitive Walkthrough for the Web (CWW) is one such variant, specifically \ntailored for assessing the effectiveness of websites in aiding users with navigation \nand information retrieval (Blackmon et al., 2002). \n \nBy simulating and assessing users' internal cognitive models for specific tasks or \nsituations, the cognitive walkthrough method can help in identifying potential error \nsituations, information overload issues and overly complex interfaces. \nFurthermore, it c an aid in iteratively designing and refining software and online \ntools to align with new users. (Kirsch, 2000.) \nCognitive workload refers to the mental exertion or focus dedicated to completing \na task. Reducing cognitive workload is crucial for enhancing performance and \ndecision-making. We have brought up earlier literature about how personali zed \nNLP solutions could help reduce this information workload. (Flek, 2020)   The \ngoal is to help coordinators seek guidance from LLMs in formulating and refining \nprogram goals, with minimal cognitive strain.                                    \nThe cognitive walkthrough was carried out using a local demo. In actual use, the \napplication will be deployed onto a server, with the React frontend, along with the \nFlask (Pallets, 2023) and MongoDB (MongoDB Inc, 2023) cache existing as \nservices accessible on the organization’s server for the users. \n \nThe cognitive walkthrough was performed with an imagined curriculum planner \nwho wanted to analyse the 2024 curriculums for a bachelor’s degree in nursing \nat Metropolia UAS. While the imagined user does not have any background in \n17 \n \n \n \n \nLLM, their familiarity with writing study programs, along with the goals being \nassessed, would guide their attitude and approach.  \n \nThe steps of the cognitive walkthrough roughly correlate to each of the six \ninteractive elements mentioned earlier: \n \n1. The user will open the tool and know what the tool is for. \n2. The user will be able to navigate to a degree program draft they are \nworking on, or an older degree program they want to analyse.  \n3. The user will be able to identify the goals they want to analyse within the \ndegree program. \n4. The user will be able to run the LLM backend through all the courses within \nthe degree program. \n5. The user will be able to identify outliers generated by the LLM, mistakes \nor missing output, and run the LLM again with different parameters. \n6. The user will be able to upload the results to the organization backend and \nexport the results to an Excel spreadsheet. \n \nFor each of the above steps, a usability question was raised, to make sure the \nhypothetical user is able to complete each step. In Table 1, the usability problems \nthat might arise during the hypothetical user’s simulated walkthrough are raised, \nalongside potential improvements for these problems.  \n \n \n \n \n \n \n \n \n \n \n18 \n \n \n \n \nTable 1. Cognitive walkthrough, its expected results and added improvements.  \nTest question Expected \nresult \nImprovements added \nduring cognitive \nwalkthrough \n1. On the front page, will the \nuser identify what the \napplication has been \ndesigned for? \n   \nYes - No changes.  \n2. Can the user identify which \ncurriculum the current in-\nprogress draft is, and which \nversion is from an earlier \nyear? \n   \nYes \n- Courses categorized \ninto drafts and \npublished ones. \n3. Will the user correctly \nidentify the given goals to \nanalyse? \n   \nNo \n- Additional color-coding \nand better button \nlabels. \n4. Will the user be able to \nsuccessfully call the LLM \nand understand what the \nresults are? \n   \nYes \n- Additional color-coding \nand better button \nlabels. \n5. Will the user navigate to \noutlier/missing AI results, \nand run the LLM again with \ndifferent parameters? \n   \nYes - No changes.  \n6. After AI has returned all the \ngoals, will the user navigate \nto the upload and export \nbuttons? \n   \nNo \n- Upload button moved \nto the tooltip for better \nvisibility. \n \n \n19 \n \n \n \n \nChanges were made to the application according to the results of the cognitive \nwalkthrough (cf. Mahatody et al., 2010).  \n \n4.3 User tests \nAs Metropolia University of Applied Sciences is going through a remodelling of \nits curriculum structure, user tests at this stage are crucial, as it was important to \nmake sure the tool responds to specific needs of the staff. As discussed earlier, \nreducing cognitive load for a task as complex as curriculum development, \nespecially during such moments of large structural change, is critical. \nStructured test cases, combined with unstructured questions, were seen as the \nmost effective way to gather data about the usability of this tool. This allowed \nexploring the curriculum planners' personal experiences, thoughts, attitudes, and \nperceptions. \nThe user tests were conducted in February 2024. The selected interviewees were \ncurriculum coordinators representing various disciplines at Metropolia University \nof Applied Sciences. The tests were conducted within the office spaces at \nMetropolia UAS’s Myllypuro Campus, using a laptop platform the test users were \nasked to navigate the demo on. \nTest subjects ranged from new curriculum planners to more experienced ones. \nThey were chosen from various study fields, as the development goals of each \nare quite different. Given the variety of educational domains from which the user \nsubjects were from - healthcare studies, architecture studies, therapeutic studies \n- it can be assumed the test subjects cover a range of possible users well. Within \nusability research, it has been found that five test subjects can identify 80% of \nusability problems, with extra participants unlikely to reveal new data. (Virzi, \n1992.) \n \n20 \n \n \n \n \nTest users were tasked to find and summari ze sustainability accomplishments \nwithin the curriculums. They had a rough idea that this tool was going to be used \nto analyse sustainability and work life goals within curriculums and they knew \nwhat format the output would be in, but before the test they h ad never seen this \napplication, nor did they know anything about the backend , nor what kind of AI \nwas working in the backend . They also each held a lot of industry -specific \nknowledge about writing study programs and the goals analysed by the tool.  \n \nThe tests were structured around the same task steps as the cognitive \nwalkthrough, accompanied with free conversation and questions. The questions \nwere chosen to roughly approximate a normal use case for a curriculum planner \nwho has never seen this tool before. Each test user was asked to use the tool to \nnavigate through a curriculum analysis task of their own domain of expertise. \nThey were asked to analyse the 2024 curriculums according to the UN goals, \ninternal goals and workplace goals and send them to t he internal service, using \nthe mock-up upload button. \n \n21 \n \n \n \n \nTable 2. User test questions , and the collected results from all the test cases.  \n      \n \nTest question \nUser \nresponses      \n(n = 5) \nSuggestions for \nimprovement \n1. On the front page, can the \nuser identify what the \napplication has been \ndesigned for? \n   \nYes - 2 \nNo - 3  \n- Describe the use \ncases for the \napplication on the front \npage. \n2. Can the user identify which \ncurriculum the current in-\nprogress draft is, and which \nversion is from an earlier \nyear? \n   \nYes - 2 \nNo - 3  \n- Action guide on the \nfront page. \n- More visible visual \n“year” and “draft” \nsignifiers. \n3. Will the user correctly \nidentify the given goals to \nanalyse? \n   \nYes - 5 \nNo - 0 \n- Users themselves \nsuggested further \ndomain-specific goals \nto be added. \n4. Will the user be able to \nsuccessfully call the LLM \nand understand what the \nresults are? \n   \nYes - 4 \nNo - 1 \n- Describe what the \nprompt is based on, in \nmore detail. \n5. Will the user navigate to \noutlier/missing AI results, \nand run the LLM again with \ndifferent parameters? \n   \nYes - 5 \nNo - 0 \n- No suggestions.  \n6. After AI has returned all the \ngoals, will the user navigate \nto the upload and export \nbuttons? \n   \nYes - 2 \nNo - 3  \n- Action guide on the \nfront page. \n- An additional pop-up, \nwhen the AI is done. \n22 \n \n \n \n \nDyring step 1, several test users said that the front page of the application did not \norient them towards the task enough . They suggested it is a problem that could \nbe eased by additional information and guidance within the tool itself: \n \nThere is no clarification here, I wouldn't know what this is. It wouldn't hurt \nto have an action guide. \n \nIf it's not an everyday tool, then you wouldn't have to remember every time \nwhere to click. Then it is a joy to use and does not burden my work so \nmuch. \n \nComputer tools are not my favorite thing to do. I  would like a guaranteed \nclarification of what I need to do with  just a glance, and then when I do \nthat, the next glance provides clarity on what to do next. \n \nSome users also did not find or notice the year button, and when asked about it, \nthey said it could be larger, or pointed out to the user within a step-by-step action \nguide. \n \nFor steps 3. and 4, they emphasi zed the importance of already having \nbackground working with the goals: \n \nFirst, I notice from the button labels that this is going to tell me something \nabout all these goals. That background information , of me working with \nthese before is important, otherwise I might not have understood what \nthese are used for. \n \nFor steps 5 and 6, several test users urged caution with these generative text \ndescriptions of program goals, as the generated descriptions for the goals are \noften very vague and general. For example, “Student master the methods of \nteamwork.” Test users fe lt many of these generated goal descriptions as \n“awkward”. \n23 \n \n \n \n \n \nMany emphasized how important a manual human verification is, as part of this \nanalysis work. As Vertex AI is a closed platform, the decisions made by the AI \nare not transparent or explainable. Verifying the goals found within the \ncurriculums requires domain expertise. \n \nWithin our healthcare domain, for example, there is a world organization \nand EU -level requirements that sets minimum standards for education. \nThere are specific training hours and certain areas of expertise that the \nstudents must meet. Then we have European-level skills. \n \nI hope we can spend the most time on industry -specific goals, as no one \nelse can do that. I'd like the easiest available tool for these general \noverhead tasks, to avoid having to do this kind of general work. We can \nthen focus on our own expertise. \n \n \nOne test user believed that AI is not able to detect all the “weak signals” within \nthe curriculum descriptions. A domain expert is able to recognize teaching related \nproblems and opportunities in, especially ones related to learning important work \nskills. \n \nOn the other hand, one user suggested that curriculum planners  themselves \nmight not have enough information about the UN SDGs and their specific \nrequirement. They expressed doubt whether they are able to assess the validity \nof these goals with a quick glance. They expressed trust in the assessment of the \nAI about these goals. \nThe users were also asked about their general perception of AI, and how they \nfeel about the potential automation of the curriculum design process. This \n24 \n \n \n \n \nhuman-AI connection element is something that cannot be understood through \ncognitive walkthrough. \n \nDuring previous years, curriculum planners have used Microsoft Excel, where \nentering manual comments and analysis from the data was very laborious. The \ntest users were asked about their experiences with filling out the curriculums \nbefore, and what feelings this evoked.  \n \nFor some, creating curriculum plans every year was laborious, as it required a lot \nof writing across different platforms and there are many study program goals that \nneed to be met. Most were motivated to try out a new tool. \n \nIt is frustrating to fill all kinds of online sticky notes with these goals, and \nthen not have the time or coordination to apply these goals anywhere \nwithin the actual teaching. \n \nSeveral test subjects emphasized cognitive workload, that comes from having to \nuse many different platforms and tools. \n \nThere is a huge amount of information in different databases and tools in \nthis house, but it is always difficult to find. Because I use them so rarely, \nand there are so many of them, it always takes a long time to find what I \nneed. \nMost had used LLMs before in the form of conversational AI but felt that the \nguidance they had received at their work organization had been at a very \ngeneral and abstract level and did not prepare them to utilize AI or LLMs \neffectively at work. \n \nAll the test users had used AI before, most notably ChatGPT. Many had tried \nChatGPT to identify curriculum themes before. While these experiences with AI \nwere positive, two common complaints rose. The goal analysis produced by \n25 \n \n \n \n \nChatGPT was in an unexpected format and difficult to standardi ze. It does not \nprovide numbers in a comparable or aggregable format. Second ly, there was a \nneed to write the prompt over and over, to get the desired result: \n \nI have used AI (ChatGPT) in our teaching domain before to brainstorm \nabout sustainable development goals. I tried to ask the AI to integrate the \nprinciples of sustainable development into this course, but what came out \nwas difficult to use.  I had to ask over and over to get the result I need.\"  \n \nIf this had been the tool we used last fall, we would now have all the \nnecessary goals ready in there already. \n \nMany program directors wanted the tool to be used for data exploration as well, \nas part of their teacher guidance tasks: \n \nThe tool could divide degree programs thematically and by domain. \nShared courses across fields could be filtered out. \n \nIt should be possible to compare degree programs in the same domain \nwith each other, thereby enhancing internal communication within the \norganization. Then we would have a better idea how we’re doing \ncompared to others. \n \nSeveral were curious whether the tool could include a small text editor, to reduce \nthe dependency on separate tools for writing and analysis. The tool could \npotentially be improved by integrating it with text editing, to include a feedback \nloop where the user could use the NLP to quickly iterate the  development. Such \nweb interface solutions already exist for NLP -based annotation tools  (See \nFrasnelli, 2021.) \n \n \n \n26 \n \n \n \n \n \n5 Discussion and conclusions \nThis final year project focused on the development of a user-friendly interface for \nan LLM -based curriculum tool. Its usability was reviewed using the cognitive \nwalkthrough approach and a series of user tests. Several key themes emerged \nfrom this user feedback, shedding light on potential areas for improvement and \nenhancement of the tool. \n \nOne of the main areas of concern highlighted by the test users was the lack of \nclarity and guidance, when presented with the application without any \nbackground information. Test users expressed the need for additional information \nand instructions to orient  them towards the task at hand. This highlights the \ndifference between what was expected to happen in the cognitive walkthrough , \nand what really happened. \n \nThere was a clear frustration with having to use multiple platforms for a number \nof tasks. The cognitive workload and inefficiencies associated with having to jump \nback and forth between a large number of disparate tools and platforms can be \nmitigated by m aking these tools and interfaces as  easy as possible  to use, but \nthis will not solve the underlying problem. This feedback underscores the \nimportance of potential benefits of a centralized and integrated tool for curriculum \ndesign. \n \nThe generative text descriptions of program goals generated by the tool were \nalso a point of contention among the test users. \n \nHow trustworthy are the predictions of these models ? Many found the \ndescriptions to be vague and general, emphasizing the need for human input and \ndomain expertise in verifying and refining the generated goals. The explanations \n27 \n \n \n \n \ngiven by LLMs to users are summaries of a potentially complicated decision \nprocess. This falls outside the scope of this study, and more research is needed. \n \nThese decisions are subject to their own biases and approximations, no matter \nhow much data is used in training. (Hämäläinen, 2024) Biases are impossible to \nbe known with large commercial models such as Vertex’s PaLM. (Roberts et al., \n2020). \n \nAdditionally, it should be noted that the responses provided to the user are \nsimplifications of a complicated decision -making procedure. There could be \nvarious decision-making approaches, both erroneous and accurate, that lead to \nthe same explanation on the user’s end. (Kocielnik et al., 2019). \n \nMoreover, the test users expressed varying opinions on the role of AI in \ncurriculum design. This feedback underscores the importance of combining AI \ncapabilities with human expertise to ensure accurate and meaningful results.  \n \nWhile some believed in the potential of AI to streamline the process and automate \ncertain tasks, others expressed scepticism about the ability of AI to detect subtle \nnuances and signals within curriculum descriptions. \n \nThe education goals the AI gives to curriculum planners are simplified summaries \nof unknown sources of training data. It is essential to carefully test and proofread \nall use situations beforehand, to ensure the output’s quality and effectiveness. \nHowever, the positive feedback highlights how much even partial automation of \ntasks can reduce cognitive workload with the most repetitive tasks. \n \nLike with the tool, other studies too have emphasized the importance of tailoring \nthe design of LLM -based tools, to consider specific populations and individual \nneeds to enhance usability and user satisfaction. (Borsci et al., 2021) As \nlanguage technology continues to play a significant role in people's lives, access \nto nuanced LLM tools becomes an issue of equality and equity.  \n28 \n \n \n \n \n \nWhile conversational, LLM -based online services have certainly grown more \npopular (Zhou et al., 2023), and NLP libraries and pipelines are increasingly \naccessible to even hobbyist programmers (Madnani & Loukina, 2020), these \ntools are out of reach for peop le who end up doing the most repetitive writing \ntasks. (Kinnula et al., 2021) This highlights the importance of addressing \naccessibility considerations in the development and deployment of NLP \ntechnology. (Sallam, 2023) \n \nTo adapt to new technologies, LLM or not, user tests, user feedback, training and \nresources will be needed. Proper preparation for work changes, to pre-emptively \nprevent cognitive strain through proper guidance and planning, will improve \nfaculty members' commitment , and faculty adaptation of new technologies. (cf. \nGetchell et al., 2022) \n \n \n29 \n \nReferences \nAchiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., ... & \nMcGrew, B. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774. \nAlmazrouei, E., Alobeidli, H., Alshamsi, A., Cappelli, A., Cojocaru, R., Debbah, \nM., ... & Penedo, G. (2023). The falcon series of open language models. arXiv \npreprint arXiv:2311.16867. \nAlsagoff, L. and Low, E. (2007). Challenges in curriculum development. Relc \nJournal, 38(2), 229-246. \nAmershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., … \n& Horvitz, E. (2019). Guidelines for human-ai interaction. Proceedings of the \n2019 CHI Conference on Human Factors in Computing Systems.  \nAnil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., ... & Wu, Y. \n(2023). Palm 2 technical report. arXiv preprint arXiv:2305.10403. \nArene, (2022). Recommendation on the shared competences of universities of \napplied sciences and their application. Available at: https://www.arene.fi/wp-\ncontent/uploads/Raportit/2022/Kompetenssit/RECOMMENDATION%20ON%20\nTHE%20SHARED%20COMPETENCES%20OF%20UNIVERSITIES%20OF%2\n0APPLIED%20SCIENCES%20AND%20THEIR%20APPLICATION.pdf?_t=164\n2539550 (accessed February 23rd, 2024). \nAryanti, C. and Adhariani, D. (2020). Students’ perceptions and expectation gap \non the skills and knowledge of accounting graduates. The Journal of Asian \nFinance, Economics and Business, 7(9), 649-657.  \n30 \n \nBlackmon, M. H., Polson, P. G., Kitajima, M., & Lewis, C. (2002). Cognitive \nwalkthrough for the web. Proceedings of the SIGCHI Conference on Human \nFactors in Computing Systems.   \nBorsci, S., Malizia, A., Schmettow, M., Velde, F. v. d., Tariverdiyeva, G., Balaji, \nD., … & Chamberlain, A. (2021). The chatbot usability scale: the design and \npilot of a usability scale for interaction with ai-based conversational agents. \nPersonal and Ubiquitous Computing, 26(1), 95-119.   \nBrown, T. B., Mann, B. F., Ryder, N. C., Subbiah, M., Kaplan, J., Dhariwal, P., \n… & Amodei, D. (2020). Language models are few-shot learners. arXiv preprint   \narXiv:2005.14165. \nCao, J., Li, M., Wen, M., & Cheung, S. C. (2023). A study on prompt design, \nadvantages and limitations of chatgpt for deep learning program repair. arXiv \npreprint arXiv:2304.08191. \nChart.js, (2023). Chart.js. Available at https://www.chartjs.org/docs/latest/ \n(accessed February 23rd, 2024). \nChen, D. and Yih, W. (2020). Open-domain question answering. Proceedings of \nthe 58th Annual Meeting of the Association for Computational Linguistics: \nTutorial Abstracts.  \nChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., … & \nFiedel, N. (2022). Palm: scaling language modeling with pathways.  \nChowdhury, G. (2003). Natural language processing. Annual Review of \nInformation Science and Technology, 37(1), 51-89. \n31 \n \nChowdhury, G. (2003). Natural language processing. Annual Review of \nInformation Science and Technology, 37(1), 51-89.  \nDevlin, J., Chang, M., Lee, K., & Toutanova, K. (2018). Bert: pre-training of \ndeep bidirectional transformers for language understanding.  \nEU (2018). The European Qualifications Framework. Available at \nhttps://europa.eu/europass/en/europass-digital-tools/european-qualifications-\nframework (accessed February 23rd, 2024). \nFishman, B. J. and Krajcik, J. (2003). What does it mean to create sustainable \nscience curriculum innovations? a commentary. Science Education, 87(4), 564-\n573.   \nFlek, L. (2020). Returning the N to NLP: towards contextually personalized \nclassification models. Proceedings of the 58th Annual Meeting of the \nAssociation for Computational Linguistics.  \nFranco, Isabel & Saito, Osamu & Vaughter, Philip & Whereat, J. & Kanie, N. & \nTakemoto, K.. (2019). Higher education for sustainable development: actioning \nthe global goals in policy, curriculum and practice. Sustainability Science. 14. \n10.1007/s11625-018-0628-4.  \nFraser, S. and Bosanquet, A. (2006). The curriculum? that’s just a unit outline, \nisn’t it?. Studies in Higher Education, 31(3), 269-284. \nFrasnelli, V., Bocchi, L., & Aprosio, A. P. (2021). Erase and rewind: manual \ncorrection of nlp output through a web interface. Proceedings of the 59th Annual \nMeeting of the Association for Computational Linguistics and the 11th \nInternational Joint Confer.  \n32 \n \nGoogle (2024) Vertex AI documentation. Available at \nhttps://cloud.google.com/vertex-ai/docs (accessed February 23rd, 2024). \nGetchell, K., Carradini, S., Cardon, P. W., Fleischmann, C., Ma, H., Aritz, J., … \n& Stapp, J. (2022). Artificial intelligence in business communication: the \nchanging landscape of research and teaching. Business and Professional \nCommunication Quarterly, 85(1), 7-33.  \nGreen, W., & Whitsed, C. (2013). Reflections on an alternative approach to \ncontinuing professional learning for internationalization of the curriculum across \ndisciplines. Journal of Studies in International Education, 17(2), 148-164. \nHämäläinen, M. (2024). Eettisesti kestävä tekoäly. Vastuullinen hankeviestintä. \nMetropolia Ammattikorkeakoulu. 978-952-328-422-7.  \nHamam, H. & Loucif, S., \"Web-Based Engine for Program Curriculum \nDesigners,\" in IEEE Transactions on Education, vol. 52, no. 4, pp. 563-572, \nNov. 2009. \nHegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., & Sontag, D. \n(2023, April). Tabllm: Few-shot classification of tabular data with large language \nmodels. In International Conference on Artificial Intelligence and Statistics (pp. \n5549-5581). PMLR. \nKhan, R., Spruijt, A., Mahboob, U., & Merriënboer, J. (2019). Determining \n‘curriculum viability’ through standards and inhibitors of curriculum quality: a \nscoping review. BMC Medical Education, 19(1).  \nKharlashkin, L., Macias, M., Huovinen, L., Hämäläinen, M., (2024). Predicting \nSustainable Development Goals Using Course Descriptions - from LLMs to \nConventional Foundation Models. arXiv preprint arXiv:2402.16420. \n33 \n \nKinnula, M., Iivari, N., Sharma, S., Eden, G., Turunen, M., Achuthan, K., … & \nTulaskar, R. (2021). Researchers’ toolbox for the future: understanding and \ndesigning accessible and inclusive artificial intelligence (aiai). Academic \nMindtrek 2021.  \nKirsh, D. (2000). A few thoughts on cognitive overload. Intellectica. Revue De \nl'Association Pour La Recherche Cognitive, 30(1), 19-51.  \nKocielnik, R., Amershi, S., & Bennett, P. (2019). Will you accept an imperfect \nai?. Proceedings of the 2019 CHI Conference on Human Factors in Computing \nSystems.  \nKocmi, T., & Federmann, C. (2023). Large language models are state-of-the-art \nevaluators of translation quality. arXiv preprint arXiv:2302.14520.  \nLatif, E., & Zhai, X. (2024). Fine-tuning chatgpt for automatic scoring. \nComputers and Education: Artificial Intelligence, 100210. \nLindner, A., Romeike, R., Jasute, E., & Pozdniakov, S. (2019). Teachers’ \nperspectives on artificial intelligence. In 12th International conference on \ninformatics in schools. “Situation, evaluation and perspectives”, ISSEP. \nLópez-Jaquero, V., Montero, F., Molina, J. P., González, P., & Fernández-\nCaballero, A. (2005). A seamless development process of adaptive user \ninterfaces explicitly based on usability properties. Engineering Human \nComputer Interaction and Interactive Systems, 289-291.  \nLucie F. 2020. Returning the N to NLP: Towards Contextually Personalized \nClassification Models. In Proceedings of the 58th Annual Meeting of the \nAssociation for Computational Linguistics, 7828–7838, Online. Association for \nComputational Linguistics. \n34 \n \nMadnani, N. and Loukina, A. (2020). User-centered & Robust NLP OSS: \nlessons learned from developing & maintaining rsmtool. Proceedings of Second \nWorkshop for NLP Open Source Software (NLP-OSS).  \nMahatody, Thomas & Sagar, Mouldi & Kolski, Christophe. (2010). State of the \nArt on the Cognitive Walkthrough Method, Its Variants and Evolutions. Int. J. \nHum. Comput. Interaction. 26. 741-785. 10.1080/10447311003781409.   \nMetropolia (2021) Strategy 2021 - 2030: A bold reformer of expertise and an \nactive builder of sustainable future. Available at \nhttps://www.metropolia.fi/en/about-us/strategy-2030/sustainable-development-\nand-growth (accessed February 23rd, 2024). \nMicrosoft (2024) Azure documentation. Available at \nhttps://learn.microsoft.com/en-us/azure/?product=popular (accessed February \n23rd, 2024). \nMilne‐Ives, M., Cock, C. d., Lim, E., Shehadeh, M. H., Pennington, N. d., Mole, \nG., … & Meinert, E. (2020). The effectiveness of artificial intelligence \nconversational agents in health care: systematic review. Journal of Medical \nInternet Research, 22(10), e20346.  \nMongoDB Inc (2023). MongoDB documentation. Available at \nhttps://www.mongodb.com/docs/ (accessed February 23rd, 2024). \nMosbach, Marius & Pimentel, Tiago & Ravfogel, Shauli & Klakow, Dietrich & \nElazar, Yanai. (2023). Few-shot Fine-tuning vs. In-context Learning: A Fair \nComparison and Evaluation. 12284-12314. 10.18653/v1/2023.findings-acl.779. \nPallets (2023). Flask documentation. Available at \nhttps://flask.palletsprojects.com/en/3.0.x/ (accessed February 23rd, 2024). \n35 \n \nParasuraman, R. (2011). Neuroergonomics. Current Directions in Psychological \nScience, 20(3), 181-186. \nPeppi-Konsortio (2023), Peppi. Available at https://www.peppi-konsortio.fi/ \n(accessed February 23rd, 2024). \nPereira, E., Vilas-Boas, M., & Rebelo, C. (2020). University curricula and \nemployability: the stakeholders’ views for a future agenda. Industry and Higher \nEducation, 34(5), 321-329. \nRenfors, S.-M. (2021). Internationalization of the Curriculum in Finnish Higher \nEducation: Understanding Lecturers’ Experiences. Journal of Studies in \nInternational Education, 25(1), 66-82. \nRoberts, A., Raffel, C., & Shazeer, N. (2020). How much knowledge can you \npack into the parameters of a language model?. Proceedings of the 2020 \nConference on Empirical Methods in Natural Language Processing (EMNLP).  \nSallam, M. (2023). The utility of chatgpt as an example of large language \nmodels in healthcare education, research and practice: systematic review on \nthe future perspectives and potential limitations.  \nSavolainen, R. (2007). Filtering and withdrawing: strategies for coping with \ninformation overload in everyday contexts. Journal of Information Science, \n33(5), 611-621.  \nSchwab, J. J. (1973). The practical 3: Translation into curriculum. The school \nreview, 81(4), 501-522. \n36 \n \nSonderegger, A. and Sauer, J. (2010). The influence of design aesthetics in \nusability testing: effects on user performance and perceived usability. Applied \nErgonomics, 41(3), 403-410.  \nTeixeira, André & Guerra, Aida & Knorn, Steffi & Staffas, Kjell & Varagnolo, \nDamiano. (2020). Computer-aided curriculum analysis and design: existing \nchallenges and open research directions. 1-9.  \nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M. A., Lacroix, T., ... \n& Lample, G. (2023). Llama: Open and efficient foundation language models. \narXiv preprint arXiv:2302.13971. \nUN (2015) - Sustainable Development Goals. Available at \nhttps://sdgs.un.org/goals (accessed February 23rd, 2024). \nVirzi, R. A. (1992). Refining the Test Phase of Usability Evaluation: How Many \nSubjects Is Enough? Human Factors, 34(4), 457-468.  \nVoogt, J., Pieters, J. M., & Roblin, N. P. (2019). Collaborative curriculum design \nin teacher teams: foundations. Collaborative Curriculum Design for Sustainable \nInnovation and Teacher Learning, 5-18. \nVreuls, J., Koeslag-Kreunen, M., Klink, M. v. d., Nieuwenhuis, L., & Boshuizen, \nH. P. A. (2022). Responsive curriculum development for professional education: \ndifferent teams, different tales. The Curriculum Journal, 33(4), 636-659.  \nWalker, M. (2012). Universities and a human development ethics: a capabilities \napproach to curriculum. European Journal of Education, 47(3), 448-461.  \n37 \n \nWang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R. (2018). \nGLUE: A multi-task benchmark and analysis platform for natural language \nunderstanding. arXiv preprint arXiv:1804.07461. \nWinata, G. I., Madotto, A., Lin, Z., Liu, R., Yosinski, J., & Fung, P. (2021). \nLanguage models are few-shot multilingual learners. Proceedings of the 1st \nWorkshop on Multilingual Representation Learning. \nZamfirescu-Pereira, J. D., Wong, R. Y., Hartmann, B., & Yang, Q. (2023). Why \nJohnny can’t prompt: how non-AI experts try (and fail) to design LLM prompts. \nIn Proceedings of the 2023 CHI Conference on Human Factors in Computing \nSystems (pp. 1-21). \nZheng, K., Vydiswaran, V. G. V., Liu, Y., Wang, Y., Stubbs, A., Uzuner, Ö., … & \nXu, H. (2015). Ease of adoption of clinical natural language processing \nsoftware: an evaluation of five systems. Journal of Biomedical Informatics, 58, \nS189-S196. \nZhang, T., Ladhak, F., Durmus, E., Liang, P., McKeown, K., & Hashimoto, T. B. \n(2023). Benchmarking large language models for news summarization. arXiv \npreprint arXiv:2301.13848. \nZhou, J., Ke, P., Qiu, X., Huang, M., & Zhang, J. (2023). ChatGPT: potential, \nprospects, and limitations. Frontiers of Information Technology & Electronic \nEngineering, 1-6. \n ",
  "topic": "Usability",
  "concepts": [
    {
      "name": "Usability",
      "score": 0.8641619682312012
    },
    {
      "name": "Computer science",
      "score": 0.6964161992073059
    },
    {
      "name": "CLARITY",
      "score": 0.6296384930610657
    },
    {
      "name": "Usability engineering",
      "score": 0.5970991253852844
    },
    {
      "name": "Pluralistic walkthrough",
      "score": 0.541395366191864
    },
    {
      "name": "Curriculum",
      "score": 0.528119683265686
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5263972282409668
    },
    {
      "name": "Process (computing)",
      "score": 0.5100144147872925
    },
    {
      "name": "Cognitive walkthrough",
      "score": 0.49970245361328125
    },
    {
      "name": "Human–computer interaction",
      "score": 0.43967804312705994
    },
    {
      "name": "Web usability",
      "score": 0.43205660581588745
    },
    {
      "name": "Usability goals",
      "score": 0.4303451180458069
    },
    {
      "name": "Plan (archaeology)",
      "score": 0.41513293981552124
    },
    {
      "name": "Process management",
      "score": 0.38623565435409546
    },
    {
      "name": "Software engineering",
      "score": 0.34333959221839905
    },
    {
      "name": "Engineering",
      "score": 0.1725665032863617
    },
    {
      "name": "Psychology",
      "score": 0.157430499792099
    },
    {
      "name": "Pedagogy",
      "score": 0.09917911887168884
    },
    {
      "name": "Programming language",
      "score": 0.09367826581001282
    },
    {
      "name": "History",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Archaeology",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I121486552",
      "name": "Helsinki Metropolia University of Applied Sciences",
      "country": "FI"
    }
  ],
  "cited_by": 9
}