{
    "title": "Pilot Study on Using Large Language Models for Educational Resource Development in Japanese Radiological Technologist Exams",
    "url": "https://openalex.org/W4406552440",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2117911562",
            "name": "Tatsuya Kondo",
            "affiliations": [
                "Niigata University"
            ]
        },
        {
            "id": "https://openalex.org/A2103853136",
            "name": "Masashi Okamoto",
            "affiliations": [
                "Niigata University"
            ]
        },
        {
            "id": "https://openalex.org/A2154874751",
            "name": "Yohan Kondo",
            "affiliations": [
                "Niigata University"
            ]
        },
        {
            "id": "https://openalex.org/A2117911562",
            "name": "Tatsuya Kondo",
            "affiliations": [
                "Niigata University"
            ]
        },
        {
            "id": "https://openalex.org/A2103853136",
            "name": "Masashi Okamoto",
            "affiliations": [
                "Niigata University"
            ]
        },
        {
            "id": "https://openalex.org/A2154874751",
            "name": "Yohan Kondo",
            "affiliations": [
                "Niigata University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2220688940",
        "https://openalex.org/W1745376035",
        "https://openalex.org/W4253897753",
        "https://openalex.org/W4385266429",
        "https://openalex.org/W2148623326",
        "https://openalex.org/W4391225179",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4376866715",
        "https://openalex.org/W4390426502",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4376640725",
        "https://openalex.org/W4387326101",
        "https://openalex.org/W4380685958",
        "https://openalex.org/W4318913281",
        "https://openalex.org/W3204083252",
        "https://openalex.org/W4318931874",
        "https://openalex.org/W2913707177",
        "https://openalex.org/W4387818199"
    ],
    "abstract": "Abstract In this study, we explored the potential application of large language models (LLMs) to the development of educational resources for medical licensure exams in non-English-speaking contexts, focusing on the Japanese Radiological Technologist National Exam. We categorized multiple-choice questions into image-based, calculation, and textual types. We generated explanatory texts using Copilot, an LLM integrated with Microsoft Bing, and assessed their quality on a 0–4-point scale. LLMs achieved high performance for textual questions, which demonstrated their strong capability to process specialized content. However, we identified challenges in generating accurate formulas and performing calculations for calculation questions, as well as in interpreting complex medical images in image-based questions. To address these issues, we suggest using LLMs with programming functionalities for calculations and using keyword-based prompts for medical image interpretation. The findings highlight the active role of educators in managing LLM-supported learning environments, particularly by validating outputs and providing supplementary guidance to ensure accuracy. Furthermore, the rapid evolution of LLM technology necessitates continuous adaptation of utilization strategies to align with their advancing capabilities. In this study, we underscored the potential of LLMs to enhance educational practices in non-English-speaking regions, while addressing critical challenges to improve their reliability and utility.",
    "full_text": "Vol.:(0123456789)\nMedical Science Educator (2025) 35:919–927 \nhttps://doi.org/10.1007/s40670-024-02251-1\nORIGINAL RESEARCH\nPilot Study on Using Large Language Models for Educational Resource \nDevelopment in Japanese Radiological Technologist Exams\nTatsuya Kondo1  · Masashi Okamoto1  · Yohan Kondo1 \nAccepted: 29 November 2024 / Published online: 18 January 2025 \n© The Author(s) 2024\nAbstract\nIn this study, we explored the potential application of large language models (LLMs) to the development of educational \nresources for medical licensure exams in non-English-speaking contexts, focusing on the Japanese Radiological Technologist \nNational Exam. We categorized multiple-choice questions into image-based, calculation, and textual types. We generated \nexplanatory texts using Copilot, an LLM integrated with Microsoft Bing, and assessed their quality on a 0–4-point scale. \nLLMs achieved high performance for textual questions, which demonstrated their strong capability to process specialized \ncontent. However, we identified challenges in generating accurate formulas and performing calculations for calculation ques-\ntions, as well as in interpreting complex medical images in image-based questions. To address these issues, we suggest using \nLLMs with programming functionalities for calculations and using keyword-based prompts for medical image interpreta-\ntion. The findings highlight the active role of educators in managing LLM-supported learning environments, particularly \nby validating outputs and providing supplementary guidance to ensure accuracy. Furthermore, the rapid evolution of LLM \ntechnology necessitates continuous adaptation of utilization strategies to align with their advancing capabilities. In this study, \nwe underscored the potential of LLMs to enhance educational practices in non-English-speaking regions, while addressing \ncritical challenges to improve their reliability and utility.\nKeywords Large Language Models · Radiological Technologist Training · Education Technology · Artificial Intelligence in \nEducation · Learning Enhancement\nIntroduction\nIn medical education, the use of multiple-choice questions \n(MCQs) is an essential tool for learning and evaluation; how-\never, it is challenging to use them effectively [1 –4]. MCQs \nare widely used in healthcare professional licensure exams \nacross many countries, including Japan, and have proven to \nbe valuable in assessing levels of achievement and knowl-\nedge. However, the constant need for new questions and \nthe error-prone nature of MCQ creation present significant \nobstacles [3]. Approaches such as ontology-based automated \ngeneration exist; however, they often lead to monotonous \nquestions, which highlights the need for more dynamic solu-\ntions [1, 5]. Additionally, research that focuses on question \ncreation and solving skills is prevalent, but there is a notable \ngap in exploring the development of explanatory materials \nfor MCQs. These materials include explanatory texts that \nclarify the questions and answer choices, in addition to dia-\ngrams, graphs, and supplementary content.\nLarge language models (LLMs) are a promising tech-\nnological application in medical education [4 , 6–8]. LLMs \nare advanced artificial intelligence systems designed to pro-\ncess and generate human-like text based on vast amounts \nof training data. These models can perform tasks such as \nlanguage translation, sentiment analysis, image captioning, \ntext summarization, question-answering systems, content \nmoderation, text paraphrasing, text completion and predic-\ntion, programming code generation, and debugging, and \nare a versatile tool for diverse interactive applications [8 ]. \nLLM development has introduced multimodal capabili-\nties that allow these models to process data formats other \nthan text, such as images. This advancement has led to the \napplication of LLMs to medical imaging research [9]. LLMs \nhave demonstrated the capacity to pass medical exams in \n * Tatsuya Kondo \n kondo@clg.niigata-u.ac.jp\n1 Department of Radiological Technology, Graduate \nSchool of Health Sciences, Niigata University, 2-746 \nAsahimachi-dori, Chuo-ku, Niigata 951-8518, Japan\n920 Medical Science Educator (2025) 35:919–927\nEnglish [10–12] and have achieved success in various Japa-\nnese medical licensing exams, including physician, dental, \npharmaceutical, and nursing exams, in addition to special-\nized radiology exams [13– 16]. Applying LLMs to medi-\ncal education offers various benefits, such as personalized \nlearning experiences, key point summaries, generation of \npractice questions, access to a vast amount of information, \nreference to resources, assistance in reviewing MCQs, and \nmultilingual medical education. For educators and instruc-\ntors, LLMs are expected to provide approaches to enhance \nstudent engagement [4, 6]. In previous studies on LLMs in \nmedical education, researchers have explored their utility \nas training tools for healthcare professionals [ 17, 18], the \ngeneration of clinical vignettes [19], and medical writing \nassistance [20].\nSeveral concerns have been raised about the application \nof LLMs to medical education, as noted in various stud-\nies [4, 6–8]. These include the risk of promoting academic \ndishonesty, over-reliance on artificial intelligence (AI), the \npotential dilution of critical thinking skills, and the accu-\nracy and reliability of content generated by LLMs [6]. In the \ncontext of MCQs, the accuracy of LLMs remains a concern \n[4, 21]. It is crucial to perform thorough evaluations and \ntests for erroneous responses or “hallucinations” (i.e., gen-\neration of incorrect or fabricated information not found in \nthe training data). Educators must emphasize that LLMs and \nrelated applications cannot replace comprehensive lectures \nor textbooks and may provide inaccurate information based \non inadequate user prompts [6]. Addressing these concerns \nis vital for applying LLMs to medical education.\nIn this study, we aim to create and evaluate educational \nresources using LLMs for medical MCQs in Japan, that is, \na non-English-speaking region. Focusing on radiological \ntechnologist exams as a case study, we envision scenarios \nin which educators at radiology technologist training schools \nuse LLMs to develop explanatory materials for medical \nqualification exams. Four key reasons support this scenario: \n(1) using LLMs can mitigate concerns about their accuracy \nwhen used by educators, (2) it uncovers potential concerns \nwhen students independently use LLMs for learning, (3) tar-\ngeting MCQs for limited-participant medical qualifications \nin non-English-speaking regions has broad applications, and \n(4) radiological technology actively applies AI, with the pos-\nsibility to examine medical imaging questions. This sector \nrelies heavily on medical imaging and anticipates the appli-\ncation of multimodal functionalities [22]. In this study, we \nassess the quality of explanatory texts generated by LLMs \nfor past national exam questions and explore considerations \nand methodologies for using LLMs in learning support.\nMethods\nIn this study, we used LLMs to generate explanatory texts \nfor MCQs, focusing on their quality evaluation. Table 1 pro-\nvides a concise overview of the study, detailing the duration \nof LLM use, the specific LLM service used, the nature of \nthe MCQs examined, their classification method, and the \napproach to assessing the explanatory texts.\nTargeted National Exam Questions\nIn this study, we modified and used a subset of 100 MCQs \nfrom the 2022 Radiological Technologist National Exam in \nJapan. This exam is conducted annually and is divided into \ntwo sessions (morning and afternoon) on the same day. In \nthe February 2022 exam, 100 MCQs were administered in \neach session and candidates were required to complete both \nsessions. The subjects covered in the morning and afternoon \nsessions were identical. The exam questions are publicly \nTable 1  Summary of the search \nstrategy\na LLMs, large language models; bMCQs, multiple-choice questions\nItems Specification\nDuration using  LLMsa February 28, 2024, to March 21, 2024\nLLMsa service used Microsoft Bing Copilot\nMCQsb examined Morning session of the Radiological Technologist National Exam conducted \nin Japan, February 2022\nNumber of  MCQsb 100\nExcluded  MCQsb None\nModified  MCQsb 3\nCategory of  MCQsb Image-based, calculation, textual\nMethod for evaluating \nexplanatory texts\nFour criteria:\n(1) Generation of a bug-free explanatory text in a single input/output cycle;\n(2) Correct explanatory text of the correct answer choice;\n(3) Correct explanatory texts of incorrect answer choices;\n(4) Accurate explanatory text of specialized terminology used in the question\n921Medical Science Educator (2025) 35:919–927 \navailable on the official website of the Japanese Ministry of \nHealth, Labour and Welfare [23]. For this study, we focused \non 100 MCQs from the morning session and categorized \nthem into three types: image-based, calculation, and text-\nbased questions.\nCorrection of the Question Statement\nFor questions in the examination where a correct option was \nnot initially present, we adjusted some choices to include \na valid, correct answer. This modification was essential to \nensure that these questions were appropriate and usable for \nour study.\nClassification of Exam Questions\nWe categorized the exam questions on the basis of the ques-\ntioning format rather than the subject matter or topic area. \nImage-based questions were defined as those using medi-\ncal images, photographs, circuit diagrams, or dimension \ndrawings. Calculation questions were defined as those \nthat did not fall into the image-based category and had \nall choices in numerical form. Textual questions, distinct \nfrom image-based and calculation questions, were defined \nas purely text-based questions that assessed fundamental \nknowledge or thought processes. The distribution of ques-\ntions was as follows: 19 image-based, nine calculation, and \n72 textual questions.\nMethod Used to Create Explanatory Texts\nWe generated explanatory texts using Copilot integrated \ninto Microsoft Bing, which is a type of LLM that applies \nnatural language processing. Copilot generates text based on \nprovided prompts and has the capability to perform internet \nsearches, using web-based information in its responses. It \nalso supports image input, thereby allowing the use of both \nimages and text. All prompts input into Copilot were written \nin Japanese. Table 2 provides a specific example of a prompt \ntranslated from Japanese to English. For image-based \nTable 2  Example of a prompt translated from Japanese to English, with adjustments made within [] to suit each question\nExample of a typed prompt\n[A001]-Question Text:\n[Which of the following pairs of element symbols and names is correct?\n1. Cu—Chromium\n2. Ge—Gallium\n3. Ce—Selenium\n4. Lu—Lutetium\n5. Ta—Thallium]\nPlease create detailed explanatory text for this question to assist radiological technologist students in their studies. Export the answer for use in \nlearning. The format for the response should be as follows:\n[A001]-Question Text:\nAnswer Number:\nExplanatory Text:\nResponse to the example prompt\nA001-Question Text: Which of the following pairs of element symbols and names is correct?\n1. Cu—Chromium\n2. Ge—Gallium\n3. Ce—Selenium\n4. Lu—Lutetium\n5. Ta—Thallium\nExplanatory Text: This question asks you to choose the correct combination of element symbol and element name. The correct combination \namong the choices is 4. Lu—Lutetium\n1. Cu is the element symbol for Copper and Cr is the element symbol for Chromium. 2. Ge is the element symbol for Germanium, and Ga is the \nelement symbol for Gallium. 3. Ce is the element symbol for cerium and Se is the element symbol for selenium. 4. Lu is the element symbol \nfor lutetium, which is the correct answer. 5. Ta is the element symbol for tantalum and Tl is the element symbol for thallium\nTherefore, the correct answer is 4. Lu—Lutetium. These questions are designed to check your knowledge of the elements and to measure your \nunderstanding of the basic science required of a radiologist. Accurate memorization of the symbols and names of the elements is important in \nthe professional fields of radiological technologists, such as radiation physics and radiobiology\n922 Medical Science Educator (2025) 35:919–927\nquestions, we used image data obtained in PDF format. We \nset the PDF display to 200% magnification and captured \nscreenshots of the images, which we then input into Copilot. \nWe exported and saved the explanatory texts generated by \nCopilot from these images in PDF format. It should be noted \nthat we did not retain information from referenced websites \nwhen exporting these texts in PDF format.\nMethod for Evaluating Explanatory Texts\nThe evaluation of the explanatory texts involved both quan-\ntitative and qualitative methods. We conducted a quality \nevaluation of the explanatory texts by assessing key aspects, \nsuch as the tool’s usability and stability, the provision of \nthe rationale for correct and incorrect answers in MCQs, \nand the level of specialized knowledge in the medical field. \nThe quantitative assessment involved a cumulative scoring \nsystem and a tally of the number of questions containing \nerrors. Additionally, two instructors conducted qualitative \nevaluations in which they reviewed the explanatory texts for \ntheir educational adequacy and accuracy.\nQuantitative Evaluation of Explanatory Texts\nWe conducted a quantitative evaluation of the explanatory \ntexts generated by LLMs to assess their quality using four \nspecific criteria: (1) whether the explanatory text was gen-\nerated in a single interaction without technical errors, (2) \nproviding a correct explanatory text for the correct answer \nchoice, (3) offering correct explanatory texts for incorrect \nanswer choices, and (4) accurately explaining specialized \nterminology used in the question. Two qualified radiological \ntechnologist instructors scored each explanatory text inde -\npendently and assigned 1 point for meeting each criterion, \nwhich resulted in a total score ranging from 0 to 4 points \nper question.\nCriterion 1 assessed the technical integrity of the explana-\ntory text generation process, ensuring that outputs were free \nfrom issues, such as repeated phrases, incomplete responses, \nor errors during generation. This criterion focused on the \ncoherence and completeness of the process rather than \ncontent accuracy. Criterion 2 evaluated the correctness of \nexplanatory texts for the correct answer choice, ensuring \nlogical alignment with the question and, for calculation \nquestions, adherence to correct formulas and computations. \nCriterion 3 examined the accuracy of explanatory texts for \nincorrect answer choices, verifying clear and valid reason-\ning for their incorrectness. For calculation questions, this \nincluded ensuring accurate computations that guided the \ncorrect choice. Criterion 4 focused on the accurate use and \nexplanatory text of specialized terminology, which reflected \ndomain-specific knowledge.\nWe calculated the average scores for each question cat -\negory (textual, calculation, and image-based), along with \ntheir 95% confidence intervals (CIs) using the t-distribution. \nAdditionally, we analyzed the generated texts for recurring \nerrors and recorded the number of questions with inaccura-\ncies to identify areas for improvement.\nQualitative Evaluation of Explanatory Texts\nTwo radiological technologist instructors with national qual-\nifications evaluated the generated explanatory texts qualita-\ntively. This qualitative analysis was agreed on through joint \nconsultation and focused on identifying errors and inaccu-\nracies across different categories. It also involved examin -\ning the characteristics of texts that received lower scores in \nthe quantitative evaluation to understand specific issues or \nrecurring patterns in the texts generated by the LLMs. Mul-\ntiple responses were obtained using the same prompts when \nnecessary to examine the characteristics of the explanatory \ntexts.\nResults\nQuantitative Evaluation\nTable  3 displays the number of questions per category, \nthe scores for the explanatory texts, and the 95% CIs. We \nassessed the quality of the explanatory texts in each category \non a 0–4-point scale, where the higher the score, the higher \nthe quality. The average scores indicated that textual ques-\ntions had the best evaluation, at 3.2 points, whereas image-\nbased questions had the lowest, at 1.7 points.\nFigure 1 compares the number of questions within each \ncategory that resulted in explanatory texts that did not con-\ntain errors with the number of questions that resulted in \nexplanatory texts that did contain errors. Every category \nhad instances of errors in explanatory texts. The propor -\ntion of texts with errors was 52.6% for image-based ques-\ntions, 22.2% for calculation questions, and 11.1% for textual \nquestions.\nTable 3  Quantitative evaluation of explanatory text quality: average \nscores of explanatory texts evaluated for each category and their 95% \nCIs using the t-distribution\na CI, confidence interval\nCategory Number of ques-\ntions\nScores\nAverage 95%  CIa\nImage-based 19 1.7 [1.02, 2.35]\nCalculation 9 3.0 [1.98, 4.02]\nTextual 72 3.2 [2.98, 3.44]\n923Medical Science Educator (2025) 35:919–927 \nQualitative Evaluation\nImage‑Based Questions\nTechnical challenges arose in generating explanatory texts \nfrom image-based questions. Issues included failure to ini-\ntiate or complete text generation after image inputs. The \nsystem struggled with accurate image recognition and its \nability to create corresponding texts.\nThe system’s explanatory texts for image-based ques-\ntions exhibited both valuable interpretations and significant \ninaccuracies. Some instances demonstrated the system’s \nability to provide meaningful explanatory texts, even when \nits image recognition capabilities were limited, as illustrated \nin Table 4. However, other cases highlighted critical errors, \nsuch as the example in Table  5, where the generated text \nincluded inaccurate interpretations of visual content. The \nfindings indicate significant challenges in the system’s abil-\nity to interpret and explain visual data.\nCalculation Questions\nThere were instances of inaccuracies in the output formulas \nand errors in calculations. An example of explanatory text \nfor a calculation question containing errors is presented in \nTable 6, originally composed in Japanese and then translated \ninto English.\nTen responses were collected using the same prompt to \nevaluate the reproducibility of formulas generated by LLMs \nfor the calculation question in Table  6. The formulas var -\nied in their combinations of distances involving the focus, \nobject, and receiver, with some responses correctly pairing \nthese distances. The numerical substitution processes fell \ninto two distinct patterns: “0.3 × 1000/200 = 1.5 mm = 150\n0 µm” and “0.3 × 20/100 = 0.06 mm = 60 µm.”\nTextual Questions\nFrequently, there were no explanatory texts for specialized \nterminology in the question text or for incorrect answer \nchoices. We also observed instances of inadequately elabo-\nrated explanatory texts. Table 7 shows an example of inap-\npropriate explanatory text. The study’s explanatory text \nFig. 1  Comparison of the number of questions within each category \nthat resulted in explanatory texts that did not contain errors with the \nnumber of questions that resulted in explanatory texts that did contain \nerrors\nTable 4  Example of valuable explanatory text and a qualitative evaluation for an image-based question. The explanatory text was translated from \nJapanese to English\nResponse\nA021-Question Text: A separate abdominal magnetic resonance (MR) image No. 43 is shown. Which of the following reduces the artifact indi-\ncated by the arrow? 1. Extension of TE 2. Extension of TR 3. Combination with a respiratory synchronization method 4. Addition of CHESS \npulse 5. Addition of spatial saturation pulses outside the slice\nAnswer Number: 5\nExplanatory Text: This question asks about the method used to reduce the artifact indicated by the arrow in the abdominal MR image. The cor-\nrect answer is “5. Addition of spatial saturation pulses outside the slice.” This technique, used to improve MR image quality, saturates specific \nextraneous slice areas to decrease artifacts. It enhances the quality of the captured image, allowing for more accurate diagnoses. Specifi-\ncally, spatial saturation pulses outside the slice saturate (i.e., nullify the signal of) the regions outside the imaging plane, thereby eliminating \nunwanted signals from those areas. This can reduce artifacts that appear in the images. The technique is beneficial when imaging organs in \nmotion, such as the abdomen, and suppresses artifacts caused by physiological signals, such as breathing and heartbeats. Therefore, the correct \nanswer to this question is “5. Addition of spatial saturation pulses outside the slice,” which can reduce artifacts in abdominal MR images. This \nknowledge is crucial for deepening the expertise of radiological technologists and providing higher-quality images. The above is a detailed \nexplanatory text of the question. We hope it will benefit the students of radiological technologist training schools\nQualitative Evaluation\nThe image in an MR scan targeted the liver, showing the heart and liver on the same slice in a fat-suppressed  T1-weighted axial image. The \narrow on the image indicated an artifact, which was identified as either a ghost artifact or motion artifact occurring around the aorta. The \nexplanatory text did not explicitly mention the type of artifact in the image. However, from the content associated with answer number 5, \nit inferred the type of artifact that could be suppressed and explained under what circumstances suppression would be effective. Therefore, \nalthough we concluded that the image was not recognized, we deemed valid explanatory text to have been presented\n924 Medical Science Educator (2025) 35:919–927\nTable 5  Example of explanatory text and a qualitative evaluation for \nan image-based question containing errors. The explanatory text was \ntranslated from Japanese to English. The alphabetic characters A–E \nin the example correspond to the first five syllables of the Japanese \nkatakana alphabet\nResponse\nA015-Question Text: An MRCP image is provided separately. Which of the following is the main pancreatic duct?\n1. A 2. B 3. C 4. D 5. E\nAnswer Number: 4\nExplanatory Text: In this MRCP image, several structures are labeled. The main pancreatic duct, indicated by answer number 4, is the widest \nand centrally located duct compared with other structures in the image. Understanding the position and shape of the main pancreatic duct is \ncrucial for radiological technologists because it plays a vital role in diagnosing liver and gallbladder diseases. Accurate identification of this \nand other biliary structures is essential because abnormalities can lead to symptoms such as jaundice, cirrhosis, or cholelithiasis. Remembering \nthe main pancreatic duct as “D” can aid future patient diagnoses and treatment plans. Use this knowledge to enhance your skills as a radiologi-\ncal technologist and prepare for the national exam. Good luck!\nDetails of the attached images\nThe question presented an MRCP image targeting the pancreatic-hepatobiliary system. In the image, five arrows were depicted, each pointing \ntoward an organ and labeled with symbols for differentiation. The arrows corresponded to the following organs: common hepatic duct, gall-\nbladder, common bile duct, main pancreatic duct, and renal pelvis. The symbols used for arrow identification mirrored the first five characters \nof the Japanese katakana alphabet, similar to the choice options. The image can be downloaded from the official website of the Japanese \nMinistry of Health, Labour and Welfare [23]\nQualitative Evaluation\nThe correct organ-arrow combination pertained to the main pancreatic duct, which is the primary route for transporting pancreatic juice to the \nduodenum. However, the explanatory text incorrectly stated that the main pancreatic duct was the primary pathway for bile flow from the liver \nto the duodenum. Additionally, despite the common bile duct being the thickest structure in the image, the text erroneously described the main \npancreatic duct as the thickest structure. This led us to conclude that the attached image was not accurately recognized in the explanatory text\nTable 6  Example of explanatory text and a qualitative evaluation for a calculation question containing errors. The explanatory text was trans-\nlated from Japanese to English\nResponse\nA093- Question Text: In an angiographic examination, an X-ray tube with a focal spot size of 0.3 mm was used, and radiography was performed \nwith a distance of 100 cm between the focal spot and the image receptor. When the vessel to be contrasted is 20 cm from the image receptor at \nthe focal spot, which of the following is closest to the size [μm] of this vessel’s geometric irregularity (penumbra)?\n1. 15\n2. 25\n3. 35\n4. 50\n5. 75\nAnswer Number: 5\nExplanatory Text: This question concerns the calculation of geometric insensitivity (penumbra) in radiography. Geometric insensitivity is deter-\nmined by the size and position of the X-ray source (focal spot), the object’s position, and the image receptor’s position (X-ray film or digital \nsensor). The size of the penumbra can be calculated using the following formula:\nsize of the penumbra = focal spot×(distance from the receiver to the object )\ndistance from the focus to the receiver .\nIn this question, the focal dimension is 0.3 mm, the object’s distance from the receiver is 20 cm, and the distance from the focal point to the \nreceiver is 100 cm. Substituting these values into the above formula, we obtain\nsize of the penumbra = 0.3×20\n100 = 0.06 mm = 60 /u1D707m\nTherefore, the closest to 60 µm among the choices is 75 µm, and the answer number is 5. Thus, in radiography, various parameters must be \nadjusted to obtain optimal image quality, considering the focal plane dimensions and the position of the object. This question illustrates one \nexample. As a radiologist, you must understand and apply these principles appropriately in a clinical setting\nQualitative Evaluation\nAn error was identified in the formula. The correct formula is\nsize of the penumbra = focal spot size×(distance from the receiver to the object )\ndistance from the object to the receiver .\nDespite using an incorrect formula, the numerical calculation was performed accurately, yielding the result of 60 µm. The closest correct answer \nwas option 4 (50), but the system incorrectly identified the predefined answer, option 5 (75), as correct\n925Medical Science Educator (2025) 35:919–927 \nmainly focused on explaining artifacts but did not suffi-\nciently cover the topic of accuracy management in medical \nimage monitors. Considering the question’s emphasis on \nthis area, the explanatory text was evaluated as unsuitable \nbecause it did not align with the question’s primary intent.\nDiscussion\nIn this study, we evaluated the quality of explanatory texts \ngenerated by LLMs for MCQs from past questions from the \nJapanese Radiological Technologist National Exam, that is, \na non-English-speaking context. The results showed that the \nexplanatory texts for many textual questions were of ade-\nquate quality, but those for image-based, calculation, and \nsome textual questions were inadequate. This highlights a \nneed for novel approaches when applying LLMs to image-\nbased and calculation questions. Additionally, we identified \nissues with accuracy in some textual questions, which indi-\ncates areas for further improvement in LLM applications in \nmedical education.\nThe explanatory texts for image-based questions high-\nlighted several challenges specific to interpreting medical \nimages. For image-based questions, as shown in Table 3, the \naverage score was 1.7 out of a maximum of 4 points. Addi-\ntionally, as illustrated in Fig.  1, 52.6% of the explanatory \ntexts contained errors. Key difficulties included recognizing \nvisual cues, such as arrows and labels pointing to specific \nfeatures, and accurately interpreting text or numbers embed-\nded within images. Unlike general images used for training, \nmedical images often include specialized elements, such \nas diagnostic annotations and geometric indicators, which \nrequire a nuanced understanding. These limitations make \nLLMs less reliable for image-based questions in their cur -\nrent form.\nWhen creating explanatory texts for image-based ques-\ntions, a promising strategy involves using keywords from \nthe question text rather than inputting images directly. \nImages used in national exams are often too complex for \nLLMs to interpret accurately because of their specialized \nmedical content. However, these exams frequently test fun-\ndamental concepts in medical technology, which can often \nbe addressed through text-based prompts. By focusing on \nkeywords that highlight key features or concepts, LLMs \ncan generate explanatory texts that help students to deduce \nanswers by consulting the corresponding images. For exam-\nple, questions related to basic anatomical structures, image \nartifacts, or disease concepts are particularly suited to this \napproach. As shown in Table  4, accurate explanatory texts \naligned with question content can guide effective learn-\ning. Furthermore, combining keyword-based prompts with \ninternet image searches allows students to supplement their \nunderstanding, making LLMs a useful adjunct in image-\nfocused education.\nThe explanatory texts for calculation questions high-\nlighted significant challenges in LLMs’ ability to handle \nnumerical accuracy. Issues included incorrect formulas \nand erroneous arithmetic processes. For example, in the \nquestion detailed in Table  6, repeated prompts resulted in \nvaried formulas, incorrectly combining distances between \nthe receptor, object, and focus. The correct formula, which \nrequired implicit reasoning about the focal point and object \ndistances, was often misrepresented. This variability reflects \nthe inherent characteristics of LLMs, where responses can \ndiffer based on subtle variations in prompts. Moreover, the \nstudy reaffirmed the well-documented difficulty of LLMs \nwith basic arithmetic. These findings suggest that integrating \nTable 7  Example of inappropriate explanatory text and a qualitative evaluation for a textual question translated from Japanese to English\nResponse\nA046-Question Text: In the accuracy management of medical image monitors, which of the following is a visual test item? 1. Artifacts, 2. Lumi-\nnance Ratio, 3. Contrast Response, 4. Maximum Brightness, 5. Chromaticity\nAnswer Number: 1\nExplanatory text: This question focuses on the visual test items in the medical image monitor’s accuracy management. The correct choice is \nidentified as “Artifacts”. Artifacts refer to unnecessary information or noise not originally present in images, which can arise during image \nacquisition, processing, or display. Assessing the extent of the artifacts’ influence on images is crucial for accurately managing medical image \nmonitors because artifacts potentially affect diagnoses. Therefore, checking for artifacts in visual test items is essential for maintaining image \nquality and supporting accurate diagnostics. Remembering that artifacts are the correct answer to this question will aid radiological technolo-\ngists in making future diagnostic and treatment decisions. This knowledge is vital for enabling radiological technologists to deepen their exper-\ntise and provide higher-quality imaging. This detailed explanatory text can benefit students in radiological technologist training schools\nQualitative Evaluation\nThe explanatory text primarily focused on artifacts and did not sufficiently cover the topic of quality control for medical imaging monitors. The \nexpected information pertained to the quality control of monitors. For example, quality control involves two methods: quantitative testing \nusing measuring instruments and visual inspection. Quantitative testing measures parameters, such as the luminance ratio, contrast response, \nmaximum brightness, and chromaticity. Additionally, a brief explanatory text of each of these testing items is expected to clarify their purpose \nand relevance\n926 Medical Science Educator (2025) 35:919–927\nLLMs with programming capabilities, such as Python, may \nenhance their utility for calculation-based tasks. However, \na reliance on paid models, such as OpenAI’s ChatGPT-4, \nraises concerns about equitable access in educational \nsettings.\nThe explanatory texts for textual questions, which com-\nprised nearly 90% without errors and achieved high average \nscores, demonstrated sufficient quality. These findings are \npresented in Table 3 and Fig. 1. This outcome indicates that \nthe explanatory texts for textual questions were of a nota-\nbly high standard. This aligns with LLMs’ proficiency in \ntext-based information processing and handling specialized \nterms, which is a trend consistent with prior research [8, 11]. \nThese reports suggest that LLMs can adeptly manage basic \nspecialized terminology.\nIn this study, we demonstrated a specific method for \napplying LLMs to medical education. In previous studies, \nresearchers reported on the capabilities of LLMs in the med-\nical field [10–16], their usefulness as training tools [17, 18], \nand concerns regarding their use in medical education [4 , \n6–8]. By contrast, we introduced a new application scenario \nin which educators in radiological technologist training pro-\ngrams use LLMs to develop explanatory materials for medi-\ncal licensure exams. By focusing on MCQs for radiological \ntechnologists in Japan, we addressed challenges associated \nwith a specific and limited examinee population and limited \nonline resources, compounded by the linguistic and contex-\ntual constraints of conducting research in Japanese. Despite \nthese challenges, the results demonstrated that LLMs can \ngenerate high-quality explanatory texts for specialized con-\ntent in non-English educational contexts.\nThe results of this study indicate that educators at training \ninstitutions can use current LLMs to generate explanatory \ntexts for textual questions in multiple-choice exams. Using \nLLMs, educators can mitigate the impact of hallucinations \noften associated with LLM outputs, enabling the creation of \nhigh-quality explanatory texts for MCQ with greater ease. \nThe expected benefits of LLM integration include the ability \nto address new questions more efficiently, provide person-\nalized learning experiences for individual students, move \nbeyond ontology-based repetitive question patterns, and cre-\nate multilingual explanatory texts. Furthermore, it became \nevident that handling medical images requires carefully \ndesigned prompts, whereas addressing calculation questions \nnecessitates selecting LLMs capable of using programming \nlanguages.\nIn learning environments where students use LLMs, edu-\ncators must actively engage with and manage the learning \nframework. As shown in Fig. 1, prompts composed solely of \nsimple question–answer pairs led to errors across explana-\ntory texts in all categories. Table 7 further illustrates exam-\nples of insufficient explanatory texts, highlighting a key \nchallenge in applying LLMs to educational settings [4 , 6]. \nRecognizing inaccuracies in LLM outputs is particularly \nchallenging for beginners in specialized fields. Therefore, \neducators’ active involvement is essential when students \nrely on LLMs for learning. Strategies such as encourag-\ning the use of diverse learning resources to reduce depend-\nence on LLMs, facilitating discussions among students or \nbetween students and instructors, and leveraging interactive \nfeatures of LLMs, such as chat-based functionalities, could \nfurther enhance learning. These strategies offer promising \napproaches to effectively address the challenges associated \nwith LLMs in educational contexts.\nThe limitations of this study include the small number of \nquestions analyzed, restricting the scope to radiological tech-\nnologists, inadequate exploration of prompts and explana-\ntory text evaluation methods, and limited examination of \nother LLMs. The reliance on a free LLM raises concerns \nabout long-term availability, rapid performance changes, \nand capability disparities compared with paid models. \nAdditionally, we based the evaluation methods on indepen-\ndently established criteria without conducting a pilot study \nto test their validity and reliability. The limited number of \nevaluators, absence of student verification, and reliance on \nJapanese-language prompts may further restrict the general-\nizability of the findings. As shown in Table  6, variations in \nresponses to the same prompt indicate that a replication of \nthis study might yield slightly different results.\nConclusion\nIn this study, we demonstrated the potential application of \nLLMs to medical education in non-English-speaking con -\ntexts, particularly MCQs outside the field of medicine. Nota-\nbly, we highlighted the high-quality generation of explana-\ntory texts for textual questions, thereby indicating LLMs’ \ncapability to process specialized content effectively.\nFuture challenges include addressing issues with calcu-\nlation questions and medical images, developing learning \nenvironments that incorporate LLMs, and refining evalu-\nation standards. For calculation questions, selecting LLMs \ncapable of handling programming functionalities is a prom-\nising approach. For interpreting medical images, alterna-\ntive strategies, such as keyword-based prompt design, are \nnecessary. Additionally, enhancing the reliability and valid-\nity of evaluation criteria requires further refinement. The \nactive involvement of educators in students’ learning envi-\nronments, complementing LLM-generated outputs, will also \nbe essential for improving the accuracy and effectiveness of \neducation.\nLLMs are undergoing rapid technological advancements, \nleading to significant changes in their performance and \naccessibility over short periods. It is crucial to adapt to these \nrapid developments and align LLM utilization strategies \n927Medical Science Educator (2025) 35:919–927 \nwith their evolving capabilities. By doing so, LLMs can \nfurther unlock their potential to meet diverse educational \nneeds across medical fields in non-English-speaking regions.\nAcknowledgements We thank Edanz (https:// jp. edanz. com/ ac) for \nediting a draft of this manuscript.\nData Availability The questions from the national certification exam for \nJapanese radiological technologists used for the analysis were obtained \nfrom the website of the Ministry of Health, Labour and Welfare of \nJapan. The responses are available from the corresponding author upon \nreasonable request.\nDeclarations \nCompeting Interests The authors declare no competing interests.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Alsubait T, Parsia B, Sattler U. Ontology-based multiple choice \nquestion generation. KI - Künstliche Intelligenz. 2015;30:183–8.\n 2. Converse L, Barrett K, Rich E, Reschovsky J. Methods of observ-\ning variations in physicians’ decisions: the opportunities of clini-\ncal vignettes. J Gen Intern Med. 2015;30(Suppl 3):S586–94.\n 3. Tarrant M, Knierim A, Hayes SK, Ware J. The frequency of item \nwriting flaws in multiple-choice questions used in high stakes \nnursing assessments. Nurse Educ Today. 2006;26:662–71.\n 4. Safranek CW, Sidamon-Eristoff AE, Gilson A, Chartash D. The \nrole of large language models in medical education: applications \nand implications. JMIR Med Educ. 2023;9:e50945.\n 5. Gierl MJ, Lai H, Turner SR. Using automatic item generation to \ncreate multiple-choice test items. Med Educ. 2012;46:757–65.\n 6. Benitez TM, Xu Y, Boudreau JD, et al. Harnessing the potential of \nlarge language models in medical education: promise and pitfalls. \nJ Am Med Inform Assoc. 2024;31:776–83.\n 7. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan \nTF, Ting DSW. Large language models in medicine. Nat Med. \n2023;29:1930–40.\n 8. Abd-alrazaq A, AlSaad R, Alhuwail D, et al. Large language mod-\nels in medical education: opportunities, challenges, and future \ndirections. JMIR Med Educ. 2023;9:e48291.\n 9. Tian D, Jiang S, Zhang L, Lu X, Xu Y. The role of large language \nmodels in medical image processing: a narrative review. Quant \nImaging Med Surg. 2024;14:1108–21.\n 10. Kung TH, Cheatham M, Medenilla A, et al. Performance of \nChatGPT on USMLE: potential for AI-assisted medical edu-\ncation using large language models. PLOS Digit Health. \n2023;2:e0000198.\n 11. Gilson A, Safranek C, Huang T et al. How does ChatGPT perform \non the medical licensing exams? The implications of large lan-\nguage models for medical education and knowledge assessment. \nmedRxiv. 2022. https:// doi. org/ 10. 1101/ 2022. 12. 23. 22283 901: \n2022. 12. 23. 22283 901.\n 12. Bhayana R, Krishna S, Bleakney RR. Performance of ChatGPT \non a radiology board-style examination: insights into current \nstrengths and limitations. Radiology. 2023;307:e230582.\n 13. Toyama Y, Harigai A, Abe M, et al. Performance evaluation of \nChatGPT, GPT-4, and Bard on the official board examination of \nthe Japan Radiology Society. Jpn J Radiol. 2024;42:201–7.\n 14. Takagi S, Watari T, Erabi A, Sakaguchi K. Performance of GPT-\n3.5 and GPT-4 on the Japanese Medical Licensing Examination: \ncomparison study. JMIR Med Educ. 2023;9:e48002.\n 15. Kaneda Y, Takahashi R, Kaneda U, et al. Assessing the perfor -\nmance of GPT-3.5 and GPT-4 on the 2023 Japanese Nursing \nExamination. Cureus. 2023;15:e42924.\n 16. Ohta K, Ohta S. The Performance of GPT-3.5, GPT-4, and Bard \non the Japanese National Dentist Examination: a comparison \nstudy. Cureus. 2023;15:e50369.\n 17. Shorey S, Ang ENK, Ng ED, et al. Evaluation of a theory-based \nvirtual counseling application in nursing education. Comput \nInform Nurs. 2023;41:385–93.\n 18. Piotrkowicz A, Wang KW, Hallam J, Dimitrova V. Data-driven \nexploration of engagement with workplace-based assess-\nment in the clinical skills domain. Int J Artif Intell Educ. \n2021;31:1022–52.\n 19. Benoit JRA. ChatGPT for clinical vignette generation, revision, \nand evaluation. medRxiv. 2023. https:// doi. org/ 10. 1101/ 2023. 02. \n04. 23285 478: 2023. 02. 04. 23285 478.\n 20. Biswas S. ChatGPT and the future of medical writing. Radiology. \n2023;307:e223312.\n 21. Leo J, Kurdi G, Matentzoglu N, et al. Ontology-based gen-\neration of medical, multi-term MCQs. Int J Artif Intell Educ. \n2019;29:145–88.\n 22. Bera K, O’Connor G, Jiang S, Tirumani SH, Ramaiya N. Analysis \nof ChatGPT publications in radiology: literature so far. Curr Probl \nDiagn Radiol. 2024;53:215–25.\n 23. Ministry of Health, Labour and Welfare. Radiological Technolo-\ngist National Exam. https:// www. mhlw. go. jp/ seisa kunit suite/ \nbunya/ kenkou_ iryou/ iryou/ topics/ tp220 421- 06. html. Accessed \n28 February 2024.\nPublisher's Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations."
}