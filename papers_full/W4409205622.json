{
  "title": "Enhancing patient-centered information on implant dentistry through prompt engineering: a comparison of four large language models",
  "url": "https://openalex.org/W4409205622",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A3107103543",
      "name": "John Rong Hao Tay",
      "affiliations": [
        "National Dental Centre of Singapore",
        "Duke-NUS Medical School"
      ]
    },
    {
      "id": "https://openalex.org/A2397800423",
      "name": "Dian Yi Chow",
      "affiliations": [
        "National Dental Centre of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A3032357654",
      "name": "Yi Rong Ivan Lim",
      "affiliations": [
        "National Dental Centre of Singapore"
      ]
    },
    {
      "id": "https://openalex.org/A2117512395",
      "name": "Ethan Ng",
      "affiliations": [
        "National Dental Centre of Singapore",
        "Queen Mary University of London"
      ]
    },
    {
      "id": "https://openalex.org/A3107103543",
      "name": "John Rong Hao Tay",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2397800423",
      "name": "Dian Yi Chow",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3032357654",
      "name": "Yi Rong Ivan Lim",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117512395",
      "name": "Ethan Ng",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2886317930",
    "https://openalex.org/W4391684198",
    "https://openalex.org/W4306790191",
    "https://openalex.org/W3105630500",
    "https://openalex.org/W2109936334",
    "https://openalex.org/W4299961741",
    "https://openalex.org/W1966315031",
    "https://openalex.org/W2303670909",
    "https://openalex.org/W2955532962",
    "https://openalex.org/W2287280874",
    "https://openalex.org/W2619796501",
    "https://openalex.org/W3040772985",
    "https://openalex.org/W4310477240",
    "https://openalex.org/W4385227045",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4361000349",
    "https://openalex.org/W4391069573",
    "https://openalex.org/W4391027805",
    "https://openalex.org/W4391233140",
    "https://openalex.org/W4400838583",
    "https://openalex.org/W2029286390",
    "https://openalex.org/W4392524291",
    "https://openalex.org/W4393529891",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4391971084",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W4401365770",
    "https://openalex.org/W3021393259",
    "https://openalex.org/W4281764141",
    "https://openalex.org/W4379377320",
    "https://openalex.org/W4386110374",
    "https://openalex.org/W4401566492",
    "https://openalex.org/W4396639153",
    "https://openalex.org/W4403151997",
    "https://openalex.org/W4392303991",
    "https://openalex.org/W4399994575",
    "https://openalex.org/W4403924970",
    "https://openalex.org/W4366823098",
    "https://openalex.org/W4386812642",
    "https://openalex.org/W4367669592",
    "https://openalex.org/W4387747149",
    "https://openalex.org/W4386593417",
    "https://openalex.org/W4396814432",
    "https://openalex.org/W4406057752",
    "https://openalex.org/W4403870076",
    "https://openalex.org/W4403182105",
    "https://openalex.org/W2796095619",
    "https://openalex.org/W4403601954",
    "https://openalex.org/W6853465110",
    "https://openalex.org/W4405832618",
    "https://openalex.org/W4404584922",
    "https://openalex.org/W4394585870",
    "https://openalex.org/W6880136674",
    "https://openalex.org/W2565329226",
    "https://openalex.org/W4237907507",
    "https://openalex.org/W4379093623",
    "https://openalex.org/W3165835753",
    "https://openalex.org/W4405534231",
    "https://openalex.org/W4402564190",
    "https://openalex.org/W3107652152",
    "https://openalex.org/W4393340230",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4388525110"
  ],
  "abstract": "Background Patients frequently seek dental information online, and generative pre-trained transformers (GPTs) may be a valuable resource. However, the quality of responses based on varying prompt designs has not been evaluated. As dental implant treatment is widely performed, this study aimed to investigate the influence of prompt design on GPT performance in answering commonly asked questions related to dental implants. Materials and methods Thirty commonly asked questions about implant dentistry – covering patient selection, associated risks, peri-implant disease symptoms, treatment for missing teeth, prevention, and prognosis – were posed to four different GPT models with different prompt designs. Responses were recorded and independently appraised by two periodontists across six quality domains. Results All models performed well, with responses classified as good quality. The contextualized model performed worse on treatment-related questions (21.5 ± 3.4, p &amp;lt; 0.05), but outperformed the input-output, zero-shot chain of thought, and instruction-tuned models in citing appropriate sources in its responses (4.1 ± 1.0, p &amp;lt; 0.001). However, responses had less clarity and relevance compared to the other models. Conclusion GPTs can provide accurate, complete, and useful information for questions related to dental implants. While prompt designs can enhance response quality, further refinement is necessary to optimize its performance.",
  "full_text": "EDITED BY\nRui Amaral Mendes,\nUniversity of Porto, Portugal\nREVIEWED BY\nNicola Alberto Valente,\nUniversity of Cagliari, Italy\nNoha Taymour,\nImam Abdulrahman Bin Faisal University,\nSaudi Arabia\nFrancesco Puleio,\nUniversity of Messina, Italy\n*\nCORRESPONDENCE\nJohn Rong Hao Tay\njohn.tay.r.h@singhealth.com.sg\nRECEIVED 01 February 2025\nACCEPTED 21 March 2025\nPUBLISHED 07 April 2025\nCITATION\nTay JRH, Chow DY, Lim YRI and Ng E (2025)\nEnhancing patient-centered information on\nimplant dentistry through prompt engineering:\na comparison of four large language models.\nFront. Oral Health 6:1566221.\ndoi: 10.3389/froh.2025.1566221\nCOPYRIGHT\n© 2025 Tay, Chow, Lim and Ng. This is an\nopen-access article distributed under the\nterms of theCreative Commons Attribution\nLicense (CC BY). The use, distribution or\nreproduction in other forums is permitted,\nprovided the original author(s) and the\ncopyright owner(s) are credited and that the\noriginal publication in this journal is cited, in\naccordance with accepted academic practice.\nNo use, distribution or reproduction is\npermitted which does not comply with\nthese terms.\nEnhancing patient-centered\ninformation on implant dentistry\nthrough prompt engineering:\na comparison of four large\nlanguage models\nJohn Rong Hao Tay\n1,2*\n , Dian Yi Chow\n1\n, Yi Rong Ivan Lim\n3\nand\nEthan Ng\n1,4\n1Department of Restorative Dentistry, National Dental Centre Singapore, Singapore, Singapore,2Health\nServices and Systems Research Programme, Duke-NUS Medical School, Singapore, Singapore,3Private\nPractice, Royce Dental Group, Singapore, Singapore,4Centre for Oral Clinical Research, Barts and the\nLondon School of Medicine and Dentistry, Queen Mary University of London, London, United Kingdom\nBackground: Patients frequently seek dental information online, and generative\npre-trained transformers (GPTs) may be a valuable resource. However, the\nquality of responses based on varying prompt designs has not been evaluated.\nAs dental implant treatment is widely performed, this study aimed to\ninvestigate the inﬂuence of prompt design on GPT performance in answering\ncommonly asked questions related to dental implants.\nMaterials and methods: Thirty commonly asked questions about implant\ndentistry – covering patient selection, associated risks, peri-implant disease\nsymptoms, treatment for missing teeth, prevention, and prognosis – were\nposed to four different GPT models with different prompt designs. Responses\nwere recorded and independently appraised by two periodontists across six\nquality domains.\nResults: All models performed well, with responses classiﬁed as good quality.\nThe contextualized model performed worse on treatment-related questions\n(21.5 ± 3.4,p < 0.05), but outperformed the input-output, zero-shot chain of\nthought, and instruction-tuned models in citing appropriate sources in its\nresponses (4.1 ± 1.0, p < 0.001). However, responses had less clarity and\nrelevance compared to the other models.\nConclusion: GPTs can provide accurate, complete, and useful information for\nquestions related to dental implants. While prompt designs can enhance\nresponse quality, further reﬁnement is necessary to optimize its performance.\nKEYWORDS\nlarge language models, GPT, artiﬁcial intelligence, dental implants, peri-implantitis,\nprompt engineering, dental\n1 Introduction\nDental implants usage has increased dramatically over the last two decades (1). In the\nUnited States, the proportion of individuals with at least one dental implant rose from\n0.7% in 1999–2000 to 5.7% in 2015–2016, with an annual increase of 14% (1). The\nlargest absolute increase occurred among those aged 65–74 at 12.4%, and projections\nsuggest that dental implant prevalence in the United States could reach as high as 23%\nby 2026 (1). However, despite advances in surgical technique and prosthetic capabilities,\nTYPE Original Research\nPUBLISHED 07 April 2025\nDOI 10.3389/froh.2025.1566221\nFrontiers inOral Health 01 frontiersin.org\ncumulative factors in susceptible individuals can lead to peri-\nimplant disease ( 2). Peri-implant disease is prevalent, with\nperi-implantitis affecting approximately 19.5% of patients and\n12.5% of implants, though estimates vary based on clinical case\ndeﬁnitions ( 3). Some studies have reported even higher\nprevalence rates, with peri-implantitis affecting up to 56.6% of\npatients and 27.9% of implants (4–6). It has also been found that\npatients often have unrealistic high expectations of dental\nimplant therapy (7–9), and have a low awareness of maintenance\nstrategies and dental implant-related complications (10, 11). This\nmay be partly attributed to patients relying on non-credible\ninformation sources (12).\nLarge language models (LLMs) may potentially be used as an\neducational tool for patients. LLMs represent a signi ﬁcant\nadvancement in artiﬁcial intelligence (AI), particularly in the area\nof natural language processing. Built on deep neural networks,\nLLMs can generate human-like text, due to its training on vast\namounts of massive text databases. Many modern LLMs, such as\nOpenAI’s ChatGPT, Google’s Gemini, and Meta’sL l a m a ,p o s s e s s\n“few-shot” and “zero-shot” learning capabilities, enabling them to\ngenerate human-like text with minimal or even no ﬁne-tuning\n(13, 14). This is achieved through self-supervised learning, where\nmodels learn patterns in language to predict text based on its\nsurrounding context. In healthcare, LLMs have gained considerable\nattention due to its potential in assisting in diagnosis, treatment\nplanning, and providing medical advice (15–17). Large language\nmodels have demonstrated a performance level approximate to a\npassing grade in dental exams (18, 19), with some models being\ncapable of outperforming dental residents (20). This may have\nutility in clinical care by assisting dental providers in giving advice\nto patients. Self-diagnosis rates are highly prevalent, with over one-\nthird of individuals utilizing the internet for health information\n(21). Given this trend, it is likely that patients will use internet\nchatbots to answer dental-related queries (22, 23).\nA l t h o u g ht h e r eh a v eb e e ns i g n iﬁcant advances in LLMs, their\nperformance can still be improved (14, 24). Prompt engineering is\nan e wﬁeld which aims to generate more accurate and consistent\nresponses by creating prompts to guide the model ’s reasoning\nprocess. It is a way of designing instructions to guide a language\nmodel’s reasoning, giving more accurate responses. For example,\nprompting methods such as encouraging the model to break down\ncomplex problems into intermediate reasoning steps, to “think\nstep-by-step” (chain of thought prompting), or generating multiple\nresponses to the same prompt and selecting the most consistent\nanswer (self-consistency prompting), can enhance LLM\nperformance. However, its effectiveness can still vary widely\ndepending on the prompt design (24, 25). This underscores the\nneed for tailoring prompting strategies to achieve optimal\noutcomes. To the authors’ best knowledge, no studies within the\nﬁeld of Dentistry have compared different prompting strategies in\nassessing the performance of a Generative Pre-trained Transformer\n(GPT). A GPT is a type of LLM designed to produce content by\ncomprehending text within a conversation. This capability may be\nleveraged to provide dental education for patients. As dental\nimplant therapy is a commonly performed procedure in clinical\npractice, the aim of this study was to investigate the inﬂuence of\nprompt design on GPT performance, using frequently asked\nquestions about dental implants as a test example.\n2 Materials and methods\nOne of the state-of-the-art LLMs is the GPT-4o model (14). The\nprogramming environment utilized Python 3.10, using the Anaconda\n3 distribution, an open-source platform. Interaction with the GPT\nmodel was managed via the OpenAI Application Programming\nInterface (API), enabling controlled input delivery and output\nretrieval from the GPT model. Four methods of prompt engineering\nwere used: input-output prompting, zero-shot-chain of thought\nTABLE 1 List of questions posed to GPT models.\nQuestion\nNumber\nSection 1: Patient selection\n1 Who is an ideal candidate for dental implants?\n2 Who should not receive dental implants?\n3 Can I still have dental implants if I am a smoker?\n4 Does having high cholesterol or hypertension affect my eligibility\nto have implants done?\n5 If I am on anti-resorptive medication for osteoporosis, does this\nmean I cannot have dental implants done?\n6 Am I suitable for dental implants if I am a diabetic?\n7 Can I still have dental implants if I have previously received head\nand neck radiation?\nSection 2: Associated risks\n8 What are the risks of dental implant surgery?\n9 What is peri-implant disease?\n10 Who is at risk of peri-implant disease?\n11 Can dental implants fail?\nSection 3: Symptoms\n12 What are the possible complications of dental implant therapy and\nhow do I spot them?\n13 What are the symptoms of peri-implant mucositis?\n14 What are the symptoms of peri-implantitis?\nSection 4: Treatment\n15 Can you describe the process of dental implant surgery?\n16 What additional procedures may be needed for less straightforward\ndental implant cases?\n17 When would bone grafting procedures in conjunction with dental\nimplant therapy be recommended?\n18 What are all the stages of dental implant treatment and how long\ndoes it take to complete a standard case?\n19 Please specify the average treatment time in more complex cases\nwhere a staged approach with bone grafting is required?\n20 How soon can my implant be restored with a crown?\n21 Do I qualify for immediate implants?\n22 What are the alternatives to dental implants?\n23 What is the treatment for peri-implant diseases?\n24 When should my implant be removed?\nSection 5: Prevention\n25 Can peri-implant disease be prevented?\n26 How are dental implants professionally maintained?\n27 How should I care for my implant?\nSection 6: Prognosis\n28 How long do dental implants last for?\n29 What is considered successful dental implant therapy?\n30 What is the success rate following tr eatment of peri-implant diseases?\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 02 frontiersin.org\nprompting, zero-shot chain of thought prompting with instruction-\ntuning, and a contextualized model augmented with a dental\nknowledge base. Input-output prompting is a method of prompt\nengineering that deﬁnes the input and output that the GPT is to\ngenerate (25). Zero-shot-chain of thought prompting encourages the\nmodel to think “step-by-step” in its reasoning process ( 26).\nInstruction-tuning instructs the model to follow speciﬁci n s t r u c t i o n s ,\nand in addition temperature control was set to 0 to achieve the least\nstochastic (i.e., random) responses (27). A contextualized model in this\ninstance involves processing domain-speci ﬁc clinical practice\nguidelines into a knowledge base. The guidelines identiﬁed for this\nstudy comprised of the latest S3-level clinical practice guidelines for\nthe treatment of Stage I-III periodontitis (28); Stage IV periodontitis\n(29); and peri-implant diseases (30). These documents were uploaded\ninto the OpenAI API and made accessible for retrieval. A Retrieval-\nAugmented Generation approach was implemented to dynamically\nextract relevant content from the knowledge base during interactions.\nThis ensured that responses were based on the S3-level\nrecommendations, rather than relying solely on the model’sp r e -\ntrained knowledge. The GPT model was asked to assume the\nrole of a general dentist, and explicit instructions were given to each\nof the models. Full details of the prompts are detailed in\nSupplementary Table S1.\nThree dental specialist fellows (J.R.H.T., E.N., Y.R.I.L.) and\none resident (D.Y.C.) in periodontology collaborated closely\nand compiled a list of 30 questions related to dental implant\ntherapy. The number of questions was selected in line with the\nexploratory nature of this study, aimed at identifying core issues\nin implant dentistry (31, 32). This was initially derived from the\nfrequently asked questions section of reputable online sources\nof dental-related information, namely the European Federation of\nPeriodontology, American Academy of Periodontology, British\nSociety of Periodontology and Implant Dentistry, Singapore\nHealth Services, Academy of Australian and New Zealand\nProsthodontists, and Australian and New Zealand Academy of\nPeriodontists (33–38). The initial set of questions were then\nreﬁned by all members of the study team based on their shared\nexperience in encountering commonly encountered patient\nenquiries on dental implants, and categorized into question\ndomains related to patient selection, associated risks, peri-\nimplant disease symptoms, dental implant treatment for missing\nteeth, prevention, and prognosis (Table 1).\nThe responses for each of the 30 questions were extracted into a\nstandardized form across all four models. To account for run-to-\nrun variation, each query was presented three times to each\nmodel. The identities of the models were masked from the raters\n(E.N. and Y.R.I.L), who assessed each model over four different\ndays with a 72-h wash-out period between evaluations to\nminimize bias and carryover effects. The Quality Analysis of\nMedical AI (QAMAI) tool, a validated tool developed to evaluate\nFIGURE 1\nAverage scores of LLM models to dental implant-related questions. A maximum of 30 points can be scored for each question.\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 03 frontiersin.org\nthe quality of health information provided by AI within the\ncontext of dentistry and otorhinolaryngology, was utilized (39).\nThe raters each had a minimum of eight years in the practice\nof periodontology, and independently assessed each response.\nResponses were evaluated against six quality criteria, namely:\naccuracy, clarity, relevance, completeness, provision of sources of\nreferences, and usefulness, using a scale from 1 to 5: 1 (“strongly\ndisagree”), 2 ( “disagree”), 3 ( “neutral”), 4 ( “agree”), and 5\n(“strongly agree”).\n2.1 Statistical analysis\nAverage scores and standard deviations were calculated for\neach of the four models, with further subgroup analysis\naccording to the question and quality domains. To assess for\nsigniﬁcant differences in scores between models, the Kruskal –\nWallis rank sum test was used for overall and domain-speciﬁc\nscores. If signiﬁcant differences were detected in speciﬁc question\nor quality domains, Dunn’s post hoc multiple comparison test\nwas conducted. Proportions of response categories (i.e., strongly\nagree, agree, neutral, disagree, strongly disagree) were compared\nusing a two-tailed Pearson’s chi-squared test. Scores from each\nmodel were categorized into“pass” and “fail” responses. Ratings\nof ’strongly disagree’, “disagree”, and “neutral” were classiﬁed\nas a “fail”, while ratings of “agree” and ’strongly agree’ were\nclassiﬁed as a“pass”. Proportions of pass and fail responses were\ncalculated for each model across question domains and quality\ndomains. Fisher’s exact test was conducted to identify signiﬁcant\nassociations between response status and model type. Post hoc\npairwise tests were conducted between model pairs for domains\nwith signiﬁcant results. Sensitivity analysis was conducted by\nrecalculating total scores by taking the lower score from the two\nraters. A p-value of <0.05 was considered statistically signiﬁcant,\nwith adjustments for Bonferroni correction where needed.\nStatistical analysis was done using R (version 4.3.2, R Core Team,\nVienna, Austria).\nAs synthetic data was utilized, ethical approval was not\nrequired under the local Human Biomedical Research Act\nregulations (40). The study was conducted in accordance with\nthe 2024 revision of the Declaration of Helsinki.\n3 Results\nUsing a two-way consistency model, the intraclass correlation\ncoefﬁcient between the two raters indicated good agreement at\n0.73 (95% CI: 0.69–0.76). The average scores for all models were\nrelatively high, with most responses across question domains\nrated as 4 (“agree”)o r5( “strongly agree”), indicating all models\nwere of very good quality overall according to the QAMAI tool\n(Figure 1 ). Run-to-run variations were minimal, showing no\ndifference in scores. The Kruskal–Wallis rank sum test showed\nno signi ﬁcant differences in average scores across the four\nmodels (p = 0.933) (Figure 1). Pearson’s Chi-squared test did not\nreveal a statistically signiﬁcant difference (p = 0.10) in response\nTABLE 2 Distribution of response scores by question domains across models.\nDomain Number of questions Input-output model, n (%) Chain of thought model, n (%)\nStrongly disagree Disagree Neutral Agree Strongly agree Strongly disagree Disagree Neutral Agree Strongly agree\nPatient selection 7 2 (2.4) 0 (0.0) 15 (17.9) 29 (34.5) 38 (45.2) 2 (2.4) 2 (2.4) 16 (19.1) 34 (40.5) 30 (35.7)\nAssociated risks 4 3 (6.3) 1 (2.1) 5 (10.4) 22 (45.8) 17 (35.4) 0 (0.0) 0 (0.0) 4 (8.3) 23 (47.9) 21 (43.8)\nSymptoms 3 0 (0.0) 0 (0.0) 5 (13.9) 9 (25.0) 22 (61.1) 0 (0.0) 0 (0.0) 6 (16.7) 1 (2.8) 29 (80.6)\nTreatment 10 0 (0.0) 1 (0.8) 13 (10.8) 44 (36.7) 62 (51.7) 5 (4.2) 4 (3.3) 13 (10.8) 43 (35.8) 55 (45.8)\nPrevention 3 2 (5.6) 0 (0.0) 1 (2.8) 20 (55.6) 13 (36.1) 0 (0.0) 0 (0.0) 2 (5.6) 21 (58.3) 13 (36.1)\nPrognosis 3 6 (16.7) 0 (0.0) 6 (16.7) 15 (41.7) 9 (25.0) 2 (5.6) 2 (5.6) 3 (8.3) 16 (44.4) 13 (36.1)\nDomain Number of questions Instruction-tuning model, n (%) Contextualized model,n (%)\nStrongly disagree Disagree Neutral Agree Strongly agree Strongly disagree Disagree Neutral Agree Strongly agree\nPatient selection 7 1 (1.2) 5 (6.0) 13 (15.5) 43 (51.2) 21 (25.0) 0 (0.0) 3 (3.6) 12 (14.3) 30 (35.7) 39 (46.4)\nAssociated risks 4 0 (0.0) 0 (0.0) 6 (12.5) 28 (58.3) 14 (29.2) 3 (6.3) 5 (10.4) 1 (2.1) 13 (27.1) 26 (54.2)\nSymptoms 3 0 (0.0) 0 (0.0) 7 (19.4) 14 (38.9) 15 (41.7) 0 (0.0) 0 (0.0) 0 (0.0) 14 (38.9) 22 (61.1)\nTreatment 10 2 (1.7) 4 (3.3) 7 (5.8) 40 (33.3) 67 (55.8) 3 (2.5) 12 (10.0) 35 (29.2) 52 (43.3) 18 (15.0)\nPrevention 3 0 (0.0) 0 (0.0) 4 (11.1) 17 (47.2) 15 (41.7) 0 (0.0) 0 (0.0) 1 (2.8) 19 (52.8) 16 (44.4)\nPrognosis 3 6 (16.7) 0 (0.0) 0 (0.0) 19 (52.8) 11 (30.6) 1 (2.8) 0 (0.0) 4 (11.1) 17 (47.2) 14 (38.9)\nEach question within a question domain is evaluated across six quality criteria by the two raters. For instance, with four questions in a domain, the total number of assessments would equal 48.\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 04 frontiersin.org\nto distributions (i.e., strongly agree, agree, neutral, disagree,\nstrongly disagree) across models. Separate Chi-squared tests\nfor each response category indicated a signiﬁcant difference in\nthe “disagree” category across models, and although pairwise\ncomparisons showed that the contextualized model received\nsigniﬁcantly more “disagree” responses compared to input-output\nmodel ( p = 0.016), this result was not signi ﬁcant at the\nBonferroni-adjusted level (adjustedα = 0.01).\nWhen categorized according to question domain, the\ncontextualized model had a lower average score of 21.5 ± 3.4 in\nthe Treatment domain, with almost 12% of quality criteria\nrated as either 1 (’strongly disagree’)o r2( “disagree”)( Table 2).\nA statistically signiﬁcant difference in scores within the Treatment\ndomain was conﬁrmed by the Kruskal–Wallis test, and Dunn’s\npost hoc test, indicated that the contextualized model had\nstatistically signiﬁcantly lower total scores in the Treatment\ndomain compared to input-output model (26.4 ± 1.3,p = 0.0036)\nand chain of thought with instruction-tuning model (25.0 ± 2.3,\np = 0.0051) after Bonferroni correction (Figure 2). In the Prognosis\ndomain, the input-output model performed the worst with an\naverage score of 21.5 ± 2.6, with nearly 35% of quality criteria rated\nwith a score of 1–3( “strongly disagree”, “disagree”, “neutral”).\nHowever, this difference was not statistically signiﬁcant (Figure 2,\nSupplementary Table S2).\nComparing across quality domains, the input-output, zero-shot\nchain of thought, and instruction-tuned models performed poorly\nin citing appropriate sources in its responses, with around a quarter\nof responses being scored with a 1 ( “strongly disagree”)o r2\n(“disagree”)( Table 3). In contrast, the contextualized model scored\nbetter in source citation, with 78% of questions being rated with a 4\n(“agree”)o r5( “strongly agree”). The Kruskal–Wallis test conﬁrmed\na statistically signiﬁcant difference, with the contextualized model\nscoring signiﬁcantly higher than all other models in source citation\nand referencing (4.1 ± 1.0,p <0 . 0 0 1 )(Figure 3).\nAlthough the contextualized model had more ratings of 1–3\n(’strongly disagree’, “disagree”, “neutral”)i nt h ec l a r i t y ,r e l e v a n c e ,\nand usefulness domains compared to the other models,post hoc\ntesting revealed it scored signiﬁcantly lower in clarity (3.9 ± 0.6)\ncompared to the input-output (4.8 ± 0.3), chain of\nthought (4.7 ± 0.4), and instruction-tuned models (4.7 ± 0.4)\n(Supplementary Table S2).\nWhen responses were dichotomized into pass and fail\ncategories, the contextualized model had signiﬁcantly lower pass\nrates in the Treatment domain [58.3% (95% CI: 49.4 –66.8%)]\ncompared to the other models. The contextualized model\ndisplayed signiﬁcantly higher pass rates to the other models\nwhen citing relevant sources [78.3% (95% CI: 66.4 –86.9%)].\nHowever, it showed lower pass rates in clarity and relevance to\nthe other models (Figure 4, Supplementary Table S3).\nSensitivity analysis was conducted using the lower of the two\nscores between raters to re-calculate the total scores for each\nmodel. The overall distribution of responses was similar across\nmodels, with no signiﬁcant difference noted between categories.\nOverall scores did not differ signiﬁcantly across models, but the\ncontextualized model had a signiﬁcantly lower mean score in the\nTreatment domain (19.8 ± 3.4) compared to the input-output\nFIGURE 2\nAverage scores of LLM models according to question domain.\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 05 frontiersin.org\nmodel (24.9 ± 1.7, p = 0.007) and the chain of thought with\ninstruction-tuning model (25.2 ± 2.2,p = 0.004). There were no\nsigniﬁcant differences in any of the quality domains between the\nfour models.\n4 Discussion\nThis is theﬁrst study to the authors’ best knowledge, that shows\nthat prompt engineering can be used to generate responses to\nfrequently asked questions in implant dentistry, covering areas\nrelated to identifying ideal candidates for implant therapy,\ntherapeutic aspects, recognizing symptoms of peri-implant disease,\nand implant maintenance. Unlike previous LLM research in\ndentistry which focused on standardized exam questions (19, 20,\n41–44), this study explored realistic scenarios where individuals\nmay use chatbots to seek guidance on dental implant therapy.\nDeveloping LLMs in healthcare has relied onﬁne-tuning, also\nknown as model adaptation, where the LLM is retrained on\nspecialized datasets to improving its performance. However, this\ncan be computationally intensive as it requires optimizing\nnumerous parameters, which requires signiﬁcant cost and time\n(24). Prompt engineering offers an accessible and cost-effective\nmeans to customize responses. This study shows that using\nprompt engineering can achieve mixed performances in\nanswering frequently asked questions by patients, and results\nmay vary depending on the type of questions queried. Compared\nto other models, the contextualized model performed less\neffectively for questions in the Treatment domain. This was a\nsurprising outcome given the knowledge base it was augmented\nwith were S3 Level Clinical Practice Guidelines developed under\nthe European Federation of Periodontology, which is intended to\nsupport decision-making in patient treatment based on the best\navailable evidence. The discrepancy may be due to the highly\npatient-speciﬁc focus on some questions in this study, while the\nS3 guidelines were written for clinicians to guide their treatment\ndecisions and advice to patients. This study also found that there\nwere trade-offs in quality domains depending on the model. The\ncontextualized model had the best scores in when providing\nreliable sources to support its answers, as it relied on the recently\ndeveloped S3 guidelines. In contrast, the relatively high fail rates\nof the other models were attributed to frequent issues such as\nmisquoting references or citing them out of context. However,\nthe contextualized model performed worse in the clarity and\nrelevance of its responses. This may be because its attempt to\nincorporate relevant sources led to overly complex and\nconvoluted answers, reducing overall comprehensibility to non-\nclinicians. The contextualized model may have struggled to\nprovide nuanced responses that matched patient concerns. By\nprioritizing incorporating reliable references, this may have come\nat the cost of clarity and direct relevance to the questions asked,\nas compared to the other models.\nThe ﬁndings of this study are in agreement with others which\nfound that GPT models may struggle in providing personalized and\nclear advice to patients (45), and may produce signiﬁcant errors in\nhighly specialized aspects of clinical care (46, 47). Well-engineered\nTABLE 3 Distribution of response scores across quality domains for each model by both raters.\nDomain Input-output model, n (%) Chain of thought model, n (%)\nStrongly disagree Disagree Neutral Agree Strongly agree Strongly disagree Disagree Neutral Agree Strongly AGREE\nAccuracy 0 (0.0) 0 (0.0) 4 (6.7) 23 (38.3) 33 (55.0) 0 (0.0) 1 (1.7) 5 (8.3) 22 (36.7) 32 (53.3)\nClarity 0 (0.0) 0 (0.0) 0 (0.0) 14 (23.3) 46 (76.7) 0 (0.0) 0 (0.0) 1 (1.7) 15 (25.0) 44 (73.3)\nCompleteness 0 (0.0) 0 (0.0) 8 (13.3) 35 (58.3) 17 (28.3) 0 (0.0) 0 (0.0) 6 (10.0) 32 (53.3) 22 (36.7)\nRelevance 0 (0.0) 0 (0.0) 0 (0.0) 25 (41.7) 35 (58.3) 0 (0.0) 0 (0.0) 3 (5.0) 28 (46.7) 29 (48.3)\nSources 13 (21.7) 2 (3.3) 30 (50.0) 12 (20.0) 3 (5.0) 9 (15.0) 7 (11.7) 25 (41.7) 12 (20.0) 7 (11.7)\nUsefulness 0 (0.0) 0 (0.0) 3 (5.0) 30 (50.0) 27 (45.0) 0 (0.0) 0 (0) 4 (6.7) 29 (48.3) 27 (45.0)\nDomain Instruction-tuning model, n (%) Contextualized model,n (%)\nStrongly disagree Disagree Neutral Agree Strongly agree Strongly disagree Disagree Neutral Agree Strongly agree\nAccuracy 0 (0.0) 1 (1.7) 2 (3.3) 29 (48.3) 28 (46.7) 0 (0.0) 0 (0.0) 6 (10.0) 22 (36.7) 32 (53.3)\nClarity 0 (0.0) 0 (0.0) 1 (1.7) 17 (28.3) 42 (70.0) 1 (1.7) 1 (1.7) 10 (16.7) 38 (63.3) 10 (16.7)\nCompleteness 0 (0.0) 1 (1.7) 3 (5.0) 42 (70.0) 14 (23.3) 1 (1.7) 6 (10.0) 9 (15.0) 22 (36.7) 22 (36.7)\nRelevance 0 (0.0) 0 (0.0) 2 (3.3) 26 (43.3) 32 (53.3) 2 (3.3) 5 (8.3) 11 (18.3) 18 (30.0) 24 (40.0)\nSources 9 (15.0) 6 (10.0) 27 (45.0) 14 (23.3) 3 (5.0) 2 (3.3) 3 (5.0) 8 (13.3) 21 (35.0) 26 (43.3)\nUsefulness 0 (0.0) 1 (1.7) 2 (3.3) 33 (55.0) 24 (40.0) 1 (1.7) 5 (8.3) 9 (15.0) 24 (40.0) 21 (35.0)\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 06 frontiersin.org\nprompts can produce more comprehensive and accurate responses\n(25, 48, 49). Despite these challenges, this study supports existing\nevidence that LLMs are valuable tools for dental education,\nparticularly in dental implantology ( 50–52). However, their\nreliability and usefulness may vary between models (e.g., Google\nGemini vs. GPT-3.5/GPT-4), and may exhibit bias when\ndiscussing different implant brands (50, 51).\nThe language-based structure of LLMs may also mean that\nwhen a topic is under-resourced, it may compensate by drawing\non semantically similar concepts from related but distinct areas,\nresulting in potential inaccuracies. This is known as\nrepresentational heuristic bias, and is a type of cognitive bias,\nwhere LLMs generalize information from related concepts\n(53, 54). LLMs are also prone to other cognitive biases such as\nfalse consensus bias, where responses are generated on what the\nmodel assumes is the most popular opinion, and frequency bias,\nwhere responses are skewed towards more common diagnoses\nand treatments (55). These biases may be mitigated in implant\ndentistry due to abundant and speci ﬁc training data available.\nHowever, these ﬁndings suggest that generating responses to\ncommonly asked questions by patients in dentistry requires\nthorough evaluation given the varied levels of resource\nrepresentation across different specialties. Furthermore, the data\non which the LLM was trained on may not fully represent\ndiverse populations. For example, all questions were posed in\nEnglish, limiting the applicability of these results to non-English\nspeaker, or those with lower health literacy. Patients with lower\nliteracy levels may struggle to understand technical explanations,\npotentially limiting its accessibility.\nThis study is not without its limitations. Only four types of\nprompt engineering were tested. Other types of prompt strategies\nthat could be useful in LLM applications in dentistry include\nreﬂection of thoughts prompting, which involves guiding the LLM\nto break down the task into sequential steps and backtracking prior\nsteps for further reﬂection (25). Another type is known as tree of\nthoughts prompting, which aims to explore multiple reasoning\npaths (56). These were not utilized in this current study as these\ntechniques may be more suited for more complex tasks that\nrequire extensive reasoning. Another important limitation is the\nconstantly evolving nature of dental implant literature. Certain\npromising procedures may not yet be supported by well-conducted\nrandomized controlled trials nor addressed in consensus\nstatements. Additionally, the study utilized 30 questions as part of\nits exploratory nature. However, future studies should consider\nincorporating a broader set of questions, including those aligned\nwith the Implant Dentistry Core Outcome Set and Measurement\n(ID-COSM) domains, to ensure comprehensive assessment (51).\nAdditionally, even though the raters assessed each model three\ntimes with a wash-out period, there is still potential for bias as the\nsame raters rated it. Another limitation is that only the GPT-4-o\nmodel was used. Comparisons with other LLMs, such as\nGoogle Gemini, Claude, and DeepSeek, would provide a more\ncomprehensive analysis of prompt engineering performance. For\nexample, Google Gemini has been noted for its safety features in\nFIGURE 3\nAverage scores of LLM models according to QAMAI quality domain.\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 07 frontiersin.org\nrecommending professional dental care, and its ability to incorporate\ngraphical elements in responses, which may contribute to a better\nend-user experience (51, 52). Considerations for further research\ninclude using prompt engineering to conﬁne responses within a\nspeciﬁc timeframe to prevent GPTs from referencing outdated\ninformation (i.e., historical bias), or to only include high-quality\nacademic publications as a reference source. Another promising\napproach is training LLMs on specialized biomedical corpora to\nenhance its understanding of current and domain-speciﬁc practices\nto improve its accuracy (24). For example, PerioGPT, aﬁne-tuned\nversion of GPT-4o tailored for periodontal queries, demonstrated\nsigniﬁcantly improved performance compared to general-purpose\nmodels. This suggests that AI-driven implant dentistry education\ncould beneﬁt from similar ﬁne-tuning approaches to enhance\naccuracy and domain relevance (57). This is crucial as general-\npurpose GPT models are only trained on publicly available data\nand may not have access to latest research (58). Further work is\nrequired to evaluate these models with patient volunteers in real-\nworld settings before considering its adoption as part of routine\nclinical care ( 59). Clinical decisions often involve assessing\npotential patient beneﬁt, understanding the level of being informed\nof the patient, clinical expertise, and interpreting limited evidence\n(60, 61). These require nuanced clinical judgement, which GPTs\nmay not fully replicate.\nFurthermore, research is needed to assess the GPT ’s\neffectiveness across different literacy levels and language barriers,\nFIGURE 4\nProportion of“Pass”and“Fail”responses by quality domain and model. IO, input-output; COT, chain of thought; IT, instruction-tuning; Context, contextualized.\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 08 frontiersin.org\nas health literacy is a stronger predictor of health outcomes than\nage, income, or education (62). Ethical AI development is crucial\nin preventing the reinforcement of existing healthcare disparities,\nensuring transparency, accountability, and equity, particularly for\nunderrepresented populations ( 63, 64). Comprehensive data\ndocumentation and systematic identiﬁcation of algorithmic biases\nare necessary to improve transparency in LLM models and\nensure appropriate representation of diverse populations ( 65).\nEthical evaluations should be systematically integrated into model\ndevelopment to mitigate risks, ensure fairness and inclusivity by\nincorporating stakeholder involvement, and training models on\ndiverse, representative data, including vulnerable groups (65, 66).\nIn this context, GPTs for patient dental education should be\ndesigned to be accessible and consider varying levels of health\nliteracy and language pro ﬁciency amongst participants. The\nperformance of LLMs in voice interactions, which could be\nbeneﬁcial for individuals with disabilities, such as those with\nvisual impairments or motor limitations that affect typing may\nalso be evaluated.\nClinically, GPTs can enhance ef ﬁciency by reducing\nadministrative workload, such as answering patient queries and\nminimizing the burden on clinicians and administrators making\nfollow-up calls. It can be integrated into clinical workﬂows before\na consultation, or at subsequent visits for further patient\nclariﬁcation. Importantly, GPTs have the potential to reduce the\npower differential between clinician and patient by providing\naccessible, high-quality information, thereby strengthening shared\ndecision-making and bridging information gaps ( 67, 68).\nHowever, human oversight remains essential to ensure accuracy,\nprevent errors and maintain patient trust.\n5 Conclusion\nPrompt engineering is a promising approach in enhancing\nresponses to frequently asked questions in implant dentistry. State-\nof-the-art GPTs can potentially be used to inform patients about\ndental implants, reducing the knowledge gap between dentists and\npatients, and empowering the latter to make more informed\ndecisions. This is valuable because implant dentistry, while offering\nsigniﬁcant beneﬁts in the rehabilitation of edentulous patients,\nis a procedure that can carry signiﬁcant post-surgical risks and\nlong-term complications such as peri-implantitis.\nProviding reliable information for patients is important as\nGPTs may draw from open internet sources. Integrating\ncontextual knowledge to a GPT using an API that integrates\nhigh-quality dental information offers a potential solution.\nHowever, further work is required to improve the clarity and\nrelevance of answers when a contextualized model is used.\nQuality of responses varies across different prompt designs.\nWhile GPT-based information is not a substitute for clinical\nadvice, these models show potential as supportive tools in\npatient education.\nData availability statement\nThe raw data supporting the conclusions of this article will be\nmade available by the authors, without undue reservation.\nAuthor contributions\nJT: Conceptualization, Data curation, Formal analysis,\nInvestigation, Methodology, Software, Visualization, Writing –\noriginal draft, Writing – review & editing. DC: Data curation,\nFormal analysis, Investigation, Methodology, Visualization,\nWriting – original draft, Writing – review & editing. YL:\nConceptualization, Data curation, Formal analysis, Investigation,\nMethodology, Visualization, Writing – original draft, Writing –\nreview & editing. EN: Conceptualization, Data curation, Formal\nanalysis, Investigation, Methodology, Visualization, Writing –\noriginal draft, Writing– review & editing.\nFunding\nThe author(s) declare that noﬁnancial support was received for\nthe research and/or publication of this article.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nGenerative AI statement\nThe author(s) declare that no Generative AI was used in the\ncreation of this manuscript.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their afﬁliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed\nor endorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.3389/froh.2025.\n1566221/full#supplementary-material\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 09 frontiersin.org\nReferences\n1. Elani HW, Starr JR, Da Silva JD, Gallucci GO. Trends in dental implant use in the\nU.S., 1999–2016, and projections to 2026.J Dent Res. (2018) 97(13):1424–30. doi: 10.\n1177/0022034518792567\n2. Ng E, Tay JRH, Mattheos N, Bostanci N, Belibasakis GN, Seneviratne CJ. A\nmapping review of the pathogenesis of peri-implantitis: the bio ﬁlm-mediated\ninﬂammation and bone dysregulation (BIND) hypothesis. Cells. (2024) 13(4).\ndoi: 10.3390/cells13040315\n3. Diaz P, Gonzalo E, Villagra LJG, Miegimolle B, Suarez MJ. What is the prevalence\nof peri-implantitis? A systematic review and meta-analysis.BMC Oral Health. (2022)\n22(1):449. doi: 10.1186/s12903-022-02493-8\n4. Romandini M, Lima C, Pedrinaci I, Araoz A, Soldini MC, Sanz M. Prevalence and\nrisk/protective indicators of peri-implant diseases: a university-representative cross-\nsectional study. Clin Oral Implants Res. (2021) 32(1):112–22. doi: 10.1111/clr.13684\n5. Atieh MA, Alsabeeha NH, Faggion CM Jr, Duncan WJ. The frequency of peri-\nimplant diseases: a systematic review and meta-analysis. J Periodontol . (2013)\n84(11):1586–98. doi: 10.1902/jop.2012.120592\n6. Derks J, Tomasi C. Peri-implant health and disease. A systematic review of\ncurrent epidemiology. J Clin Periodontol. (2015) 42(Suppl 16):S158 –71. doi: 10.\n1111/jcpe.12334\n7. Yao J, Li M, Tang H, Wang PL, Zhao YX, McGrath C, et al. What do patients\nexpect from treatment with dental implants? Perceptions, expectations and\nmisconceptions: a multicenter study. Clin Oral Implants Res. (2017) 28(3):261–71.\ndoi: 10.1111/clr.12793\n8. Vipattanaporn P, Mattheos N, Pisarnturakit P, Pimkhaokham A, Subbalekha K.\nPost-treatment patient-reported outcome measures in a group of Thai dental\nimplant patients.Clin Oral Implants Res. (2019) 30(9):928–39. doi: 10.1111/clr.13500\n9. Abrahamsson KH, Wennström JL, Berglundh T, Abrahamsson I. Altered\nexpectations on dental implant therapy; views of patients referred for treatment of\nperi-implantitis. Clin Oral Implants Res. (2017) 28(4):437–42. doi: 10.1111/clr.12817\n10. Insua A, Monje A, Wang HL, Inglehart M. Patient-centered perspectives and\nunderstanding of peri-implantitis. J Periodontol. (2017) 88(11):1153 –62. doi: 10.\n1902/jop.2017.160796\n11. Brunello G, Gervasi M, Ricci S, Tomasi C, Bressan E. Patients’ perceptions of\nimplant therapy and maintenance: a questionnaire-based survey.Clin Oral Implants\nRes. (2020) 31(10):917–27. doi: 10.1111/clr.13634\n12. Huang Y, Levin L. Barriers related to dental implant treatment acceptance by\npatients. Int J Oral Maxillofac Implants. (2022) 37(6):1210–6. doi: 10.11607/jomi.9643\n13. Yang R, Tan TF, Lu W, Thirunavukarasu AJ, Ting DSW, Liu N. Large language\nmodels in health care: development, applications, and challenges.Health Care Sci.\n(2023) 2(4):255–63. doi: 10.1002/hcs2.61\n14. Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW.\nLarge language models in medicine.Nat Med. (2023) 29(8):1930–40. doi: 10.1038/\ns41591-023-02448-8\n15. Eriksen AV, Möller S, Ryg J.\nUse of GPT-4 to Diagnose complex Clinical Cases.\nWaltham, MA: Massachusetts Medical Society (2023). p. AIp2300031.\n16. Haupt CE, Marks M. AI-generated medical advice-GPT and beyond. Jama.\n(2023) 329(16):1349–50. doi: 10.1001/jama.2023.5321\n17. Li J, Dada A, Puladi B, Kleesiek J, Egger J. ChatGPT in healthcare: a taxonomy\nand systematic review. Comput Methods Programs Biomed. (2024):108013. doi: 10.\n1016/j.cmpb.2024.108013\n18. Chau RCW, Thu KM, Yu OY, Hsung RT, Lo ECM, Lam WYH. Performance of\ngenerative artiﬁcial intelligence in dental licensing examinations.Int Dent J. (2024)\n74(3):616–21. doi: 10.1016/j.identj.2023.12.007\n19. Revilla-León M, Barmak BA, Sailer I, Kois JC, Att W. Performance of an artiﬁcial\nintelligence-based chatbot (ChatGPT) answering the European certiﬁcation in implant\ndentistry exam.Int J Prosthodont. (2024) 37(2):221–4. doi: 10.11607/ijp.8852\n20. Sabri H, Saleh MHA, Hazrati P, Merchant K, Misch J, Kumar PS, et al. Performance\nof three artiﬁcial intelligence (AI)-based large language models in standardized testing;\nimplications for AI-assisted dental education.J Periodontal Res. (2024). doi: 10.1111/jre.\n13323\n21. Kuehn BM. More than one-third of US individuals use the internet to self-\ndiagnose. JAMA. (2013) 309(8):756–7. doi: 10.1001/jama.2013.629\n22. Lambert R, Choo ZY, Gradwohl K, Schroedl L, Ruiz De Luzuriaga A. Assessing\nthe application of large language models in generating dermatologic patient education\nmaterials according to Reading level: qualitative study. JMIR Dermatol. (2024) 7:\ne55898. doi: 10.2196/55898\n23. Yalamanchili A, Sengupta B, Song J, Lim S, Thomas TO, Mittal BB, et al.\nQuality of large language model responses to radiation oncology patient care\nquestions. JAMA Netw Open. (2024) 7(4):e244630. doi: 10.1001/jamanetworkopen.\n2024.4630\n24. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, et al. Large language\nmodels encode clinical knowledge. Nature. (2023) 620(7972):172–80. doi: 10.1038/\ns41586-023-06291-2\n25. Wang L, Chen X, Deng X, Wen H, You M, Liu W, et al. Prompt engineering in\nconsistency and reliability with the evidence-based guideline for LLMs.NPJ Digit Med.\n(2024) 7(1):41. doi: 10.1038/s41746-024-01029-4\n26. Wei J, Wang X, Schuurmans D, Bosma M, Xia F, Chi E, et al. Chain-of-thought\nprompting elicits reasoning in large language models.Adv Neural Inf Process Syst.\n(2022) 35:24824–37.\n27. Kee XLJ, Sng GGR, Lim DYZ, Tung JYM, Abdullah HR, Chowdury AR. Use of a\nlarge language model with instruction-tuning for reliable clinical frailty scoring.JA m\nGeriatr Soc. (2024). doi: 10.1111/jgs.19114\n28. Sanz M, Herrera D, Kebschull M, Chapple I, Jepsen S, Berglundh T, et al.\nTreatment of stage I–III periodontitis—the EFP S3 level clinical practice guideline.J\nClin Periodontol. (2020) 47:4–60. doi: 10.1111/jcpe.13290\n29. Herrera D, Sanz M, Kebschull M, Jepsen S, Sculean A, Berglundh T, et al.\nTreatment of stage IV periodontitis: the EFP S3 level clinical practice guideline.J\nClin Periodontol. (2022) 49:4–71. doi: 10.1111/jcpe.13639\n30. Herrera D, Berglundh T, Schwarz F, Chapple I, Jepsen S, Sculean A, et al.\nPrevention and treatment of peri ‐implant diseases —the EFP S3 level clinical\npractice guideline. J Clin Periodontol. (2023) 50(Suppl 26):4–76. doi: 10.1111/jcpe.\n13823\n31. Lim ZW, Pushpanathan K, Yew SME, Lai Y, Sun CH, Lam JSH, et al.\nBenchmarking large language models’ performances for myopia care: a comparative\nanalysis of ChatGPT-3.5, ChatGPT-4.0, and google bard. EBioMedicine. (2023)\n95:104770. doi: 10.1016/j.ebiom.2023.104770\n32. Zhang Q, Wu Z, Song J, Luo S, Chai Z. Comprehensiveness of large language\nmodels in patient queries on gingival and endodontic health. Int Dent J. (2025)\n75(1):151–7. doi: 10.1016/j.identj.2024.06.022\n33. European Federation of Periodontology. FAQs 2024. Available online at: https://\nwww.efp.org/faqs/(Accessed August 30, 2024).\n34. American Academy of Periodontology. Dental Implant Procedures 2024.\nAvailable online at: https://www.perio.org/for-patients/periodontal-treatments-and-\nprocedures/dental-implant-procedures/ (Accessed August 30, 2024).\n35. British Society of Periodontology and Implant Dentistry. Patient FAQs - Dental\nImplants 2024. Available online at: https://www.bsperio.org.uk/patients/patient-faqs-\ndental-implants (Accessed August 30, 2024).\n36. Singapore Health Services. Peri-Implant Mucositis and Peri-Implantitis (Gum\nDisease around Dental Implants) 2024. Available online at: https://www.singhealth.\ncom.sg/patient-care/conditions-treatments/Peri-Implant-Mucositis-and-Peri-\nImplantitis (Accessed August 30, 2024).\n37. Academy of Australian and New Zealand Prosthodontists. Dental Implants\n2024. Available online at: https://www.aanzp.com.au/patient-resources/common-\ndental-procedures/implants (Accessed August 30, 2024).\n38. Australian and New Zealand Academy of Periodontists. Dental Implants 2024.\nAvailable online at: https://www.perioinfo.org/dental-implants/dental-implants-\nexplained/ (Accessed August 30, 2024).\n39. Vaira LA, Lechien JR, Abbate V, Allevi F, Audino G, Beltramini GA,\net al. Validation of the quality analysis of medical artiﬁcial intelligence (QAMAI)\ntool: a new tool to assess the quality of health information provided by AI\nplatforms. Eur Arch Otorhinolaryngol. (2024) 281(11):6123–31. doi: 10.1007/s00405-\n024-08710-0\n40. Ministry of Health. Regulation of human biomedical research 2024. Available\nonline at: https://www.moh.gov.sg/others/health-regulation/regulation-of-human-\nbiomedical-research (Accessed November 04, 2024).\n41. Kim W, Kim BC, Yeom HG. Performance of large language models on the\nKorean dental licensing examination: a comparative study. Int Dent J . (2024).\ndoi: 10.1016/j.identj.2024.09.002\n42. Yamaguchi S, Morishita M, Fukuda H, Muraoka K, Nakamura T, Yoshioka I,\net al. Evaluating the ef ﬁcacy of leading large language models in the Japanese\nnational dental hygienist examination: a comparative analysis of ChatGPT, bard,\nand Bing chat.J Dent Sci. (2024) 19(4):2262–7. doi: 10.1016/j.jds.2024.02.019\n43. Quah B, Yong CW, Lai CWM, Islam I. Performance of large language models in\noral and maxillofacial surgery examinations. Int J Oral Maxillofac Surg . (2024)\n53(10):881–6. doi: 10.1016/j.ijom.2024.06.003\n44. Tussie C, Starosta A. Comparing the dental knowledge of large language models.\nBr Dent J. (2024). doi: 10.1038/s41415-024-8015-2\n45. Xie Y, Seth I, Hunter-Smith DJ, Rozen WM, Ross R, Lee M. Aesthetic surgery\nadvice and counseling from artiﬁcial intelligence: a rhinoplasty consultation with\nChatGPT. Aesthetic Plast Surg . (2023) 47(5):1985 –93. doi: 10.1007/s00266-023-\n03338-7\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 10 frontiersin.org\n46. Lim DYZ, Sng GGR, Tung JYM, Tan DMY, Tan C-K. ChatGPT for advice on\ncommon GI endoscopic procedures: the promise and the peril. iGIE. (2023)\n2(4):547–53.e26. doi: 10.1016/j.igie.2023.09.003\n47. Rasmussen MLR, Larsen AC, Subhi Y, Potapenko I. Artiﬁcial intelligence-based\nChatGPT chatbot responses for patient and parent questions on vernal\nkeratoconjunctivitis. Graefes Arch Clin Exp Ophthalmol . (2023) 261(10):3041 –3.\ndoi: 10.1007/s00417-023-06078-1\n48. Gordon EB, Towbin AJ, Wingrove P, Shaﬁque U, Haas B, Kitts AB, et al.\nEnhancing patient communication with chat-GPT in radiology: evaluating the\nefﬁcacy and readability of answers to common imaging-related questions.J Am Coll\nRadiol. (2024) 21(2):353–9. doi: 10.1016/j.jacr.2023.09.011\n49. Nielsen JPS, von Buchwald C, Grønhøj C. Validity of the large language model\nChatGPT (GPT4) as a patient information source in otolaryngology by a variety of\ndoctors in a tertiary otorhinolaryngology department. Acta Otolaryngol. (2023)\n143(9):779–82. doi: 10.1080/00016489.2023.2254809\n50. Çoban E, Altay B. ChatGPT may help inform patients in dental\nimplantology. Int J Oral Maxillofac Implants. (2024) 39(5):203–8. doi: 10.11607/\njomi.10777\n51. Taymour N, Fouda SM, Abdelrahaman HH, Hassan MG. Performance of the\nChatGPT-3.5, ChatGPT-4, and google gemini large language models in responding\nto dental implantology inquiries. J Prosthet Dent. (2025). doi: 10.1016/j.prosdent.\n2024.12.016\n52. Aziz AAA, Abdelrahman HH, Hassan MG. The use of ChatGPT and google\ngemini in responding to orthognathic surgery-related questions: a comparative\nstudy. J World Fed Orthod. (2025) 14(1):20–6. doi: 10.1016/j.ejwf.2024.09.004\n53. Ryu J, Kim J, Kim J. A study on the representativeness heuristics problem in\nlarge language models. IEEE Access. (2024) 12:147958–66. doi: 10.1109/ACCESS.\n2024.3474677\n54. Kliegr T, BahníkŠ, Fürnkranz J. A review of possible effects of cognitive biases\non interpretation of rule-based machine learning models. Artif Intell . (2021)\n295:103458. doi: 10.1016/j.artint.2021.103458\n55. Schmidgall S, Harris C, Essien I, Olshvang D, Rahman T, Kim JW, et al.\nEvaluation and mitigation of cognitive biases in medical language models.NPJ Digit\nMed. (2024) 7(1):295. doi: 10.1038/s41746-024-01283-6\n56. Yao S, Yu D, Zhao J, Shafran I, Grifﬁths T, Cao Y, et al. Tree of thoughts:\ndeliberate problem solving with large language models.Adv Neural Inf Process Syst.\n(2024) 36.\n57. Fanelli F, Saleh M, Santamaria P, Zhurakivska K, Nibali L, Troiano G.\nDevelopment and comparative evaluation of a reinstructed GPT-4o model\nspecialized in periodontology.J Clin Periodontol. (2024). doi: 10.1111/jcpe.14101\n58. Puleio F, Lo Giudice G, Bellocchio AM, Boschetti CE, Lo Giudice R. Clinical,\nresearch, and educational applications of ChatGPT in dentistry: a narrative review.\nAppl Sci. (2024) 14(23). doi: 10.3390/app142310802\n59. Tripathi S, Sukumaran R, Dheer S, Cook T. Promptwise: prompt engineering\nparadigm for enhanced patient-large language model interactions towards medical\neducation. (2024). doi: 10.2139/ssrn.4785683\n60. Stilwell C, Mattheos N, Al-Nawas B, Ochsner A, Chen S. The ITI Deﬁnition and\nImplementation of Evidence-Based Implant Dentistry. Basel: International Team for\nImplantology (2023). doi: 10.3290/iti.ﬁ.45724\n61. Nalliah RP. Clinical decision making—choosing between intuition, experience\nand scientiﬁc evidence.\nBr Dent J. (2016) 221(12):752–4. doi: 10.1038/sj.bdj.2016.942\n62. Health literacy: report of the Council on Scientiﬁc Affairs.Ad hoccommittee on\nhealth literacy for the council on scientiﬁc affairs, American medical association.\nJAMA. (1999) 281(6):552–7. doi: 10.1001/jama.281.6.552\n63. Tay JRH, Ng E, Chow DY, Sim CPC. The use of artiﬁcial intelligence to aid in\noral hygiene education: a scoping review.J Dent. (2023) 135:104564. doi: 10.1016/j.\njdent.2023.104564\n64. Mörch CM, Atsu S, Cai W, Li X, Madathil SA, Liu X, et al. Artiﬁcial intelligence\nand ethics in dentistry: a scoping review.J Dent Res. (2021) 100(13):1452–60. doi: 10.\n1177/00220345211013808\n65. Alderman JE, Palmer J, Laws E, McCradden MD, Ordish J, Ghassemi M, et al.\nTackling algorithmic bias and promoting transparency in health datasets: the\nSTANDING together consensus recommendations.Lancet Digit Health. (2025) 7(1):\ne64–88. doi: 10.1016/S2589-7500(24)00224-3\n66. Ning Y, Teixayavong S, Shang Y, Savulescu J, Nagaraj V, Miao D, et al.\nGenerative artiﬁcial intelligence and ethical considerations in health care: a scoping\nreview and ethics checklist.Lancet Dig Health. (2024) 6(11):e848–56. doi: 10.1016/\nS2589-7500(24)00143-2\n67. Benecke M, Kasper J, Heesen C, Schäfﬂer N, Reissmann DR. Patient autonomy\nin dentistry: demonstrating the role for shared decision making.BMC Med Inform\nDecis Mak. (2020) 20(1):318. doi: 10.1186/s12911-020-01317-5\n68. Oueslati R, Woudstra AJ, Alkirawan R, Reis R, van Zaalen Y, Slager MT, et al. What\nvalue structure underlies shared decision making? A qualitative synthesis of models of shared\ndecision making.Patient Educ Couns. (2024) 124:108284. doi: 10.1016/j.pec.2024.108284\nTay et al. 10.3389/froh.2025.1566221\nFrontiers inOral Health 11 frontiersin.org",
  "topic": "Dentistry",
  "concepts": [
    {
      "name": "Dentistry",
      "score": 0.5942868590354919
    },
    {
      "name": "Implant",
      "score": 0.5326423645019531
    },
    {
      "name": "Orthodontics",
      "score": 0.4184891879558563
    },
    {
      "name": "Medicine",
      "score": 0.35672587156295776
    },
    {
      "name": "Surgery",
      "score": 0.06834900379180908
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210126319",
      "name": "Duke-NUS Medical School",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I4210144008",
      "name": "National Dental Centre of Singapore",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I166337079",
      "name": "Queen Mary University of London",
      "country": "GB"
    }
  ],
  "cited_by": 1
}