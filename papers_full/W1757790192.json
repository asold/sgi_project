{
  "title": "Predicate Logic as a Modelling Language: The IDP System",
  "url": "https://openalex.org/W1757790192",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4295915470",
      "name": "De Cat, Broes",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2567133856",
      "name": "Bogaerts, Bart",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4287401337",
      "name": "Bruynooghe, Maurice",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4290566348",
      "name": "Janssens, Gerda",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2565060662",
      "name": "Denecker, Marc",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1489867543",
    "https://openalex.org/W1929859906",
    "https://openalex.org/W1578088218",
    "https://openalex.org/W101771189",
    "https://openalex.org/W2071784417",
    "https://openalex.org/W2011958646",
    "https://openalex.org/W2054623824",
    "https://openalex.org/W1766332311",
    "https://openalex.org/W2159875930",
    "https://openalex.org/W2952337064",
    "https://openalex.org/W1983909040",
    "https://openalex.org/W2060440626",
    "https://openalex.org/W2953166487",
    "https://openalex.org/W2171683607",
    "https://openalex.org/W2522980543",
    "https://openalex.org/W2220468947",
    "https://openalex.org/W1925387111",
    "https://openalex.org/W1885448744",
    "https://openalex.org/W1750419207",
    "https://openalex.org/W1559870885",
    "https://openalex.org/W2076698873",
    "https://openalex.org/W19153916",
    "https://openalex.org/W2070598037",
    "https://openalex.org/W2180387438",
    "https://openalex.org/W148570748",
    "https://openalex.org/W1557561422",
    "https://openalex.org/W1672891595",
    "https://openalex.org/W1968513265",
    "https://openalex.org/W1573918631",
    "https://openalex.org/W3105494749",
    "https://openalex.org/W1810250263",
    "https://openalex.org/W1976055110",
    "https://openalex.org/W2139922246"
  ],
  "abstract": "With the technology of the time, Kowalski's seminal 1974 paper {\\em Predicate Logic as a Programming Language} was a breakthrough for the use of logic in computer science. It introduced two fundamental ideas: on the declarative side, the use of the Horn clause logic fragment of classical logic, which was soon extended with negation as failure, on the procedural side the procedural interpretation which made it possible to write algorithms in the formalism. Since then, strong progress was made both on the declarative understanding of the logic programming formalism and in automated reasoning technologies, particularly in SAT solving, Constraint Programming and Answer Set Programming. This has paved the way for the development of an extension of logic programming that embodies a more pure view of logic as a modelling language and its role for problem solving. In this paper, we present the \\idp language and system. The language is essentially classical logic extended with one of logic programmings most important contributions to knowledge representation: the representation of complex definitions as rule sets under well-founded semantics. The system is a knowledge base system: a system in which complex declarative information is stored in a knowledge base which can be used to solve different computational problems by applying multiple forms of inference. In this view, theories are declarative modellings, bags of information, descriptions of possible states of affairs. They are neither procedures nor descriptions of computational problems. As such, the \\idp language and system preserve the fundamental idea of a declarative reading of logic programs, while they break with the fundamental idea of the procedural interpretation of logic programs.",
  "full_text": "arXiv:1401.6312v3  [cs.LO]  13 Mar 2018\n1 Predicate Logic as a Mod-\nelling Language:\nThe IDP System\nA UTHORS: Broes De Cat, Bart Bogaerts, Maurice Bruynooghe, G erda Janssens, Marc\nDenecker\nDepartment of Computer Science, KU Leuven\nWith the technology of the time, Kowalski’s seminal 1974 pap er Predicate Logic as\na Programming Language was a breakthrough for the use of logic in computer science.\nIt introduced two fundamental ideas: on the declarative sid e, the use of the Horn clause\nlogic fragment of classical logic, which was soon extended w ith negation as failure, on the\nprocedural side the procedural interpretation which made i t possible to write algorithms in the\nformalism.\nSince then, strong progress was made both on the declarative understanding of the logic\nprogramming formalism and in automated reasoning technolo gies, particularly in SA T solv-\ning, Constraint Programming and Answer Set Programming. Th is has paved the way for the\ndevelopment of an extension of logic programming that embod ies a more pure view of logic\nas a modelling language and its role for problem solving.\nIn this chapter, we present the IDP language and system. The l anguage is essentially\nclassical logic extended with one of logic programmings mos t important contributions to\nknowledge representation: the representation of complex d eﬁnitions as rule sets under well-\nfounded semantics. The system is a knowledge base system: a s ystem in which complex\ndeclarative information is stored in a knowledge base which can be used to solve different\ncomputational problems by applying multiple forms of infer ence. In this view , theories are\ndeclarative modellings, bags of information, i.e., descri ptions of possible states of affairs.\nThey are neither procedures nor descriptions of computatio nal problems. As such, the IDP\nlanguage and system preserve the fundamental idea of a decla rative reading of logic programs,\nwhile they break with the fundamental idea of the procedural interpretation of logic programs.\n1.1 Introduction\nSince the early days of artiﬁcial intelligence, it is believ ed that logic could bring important\nbeneﬁts in solving computational problems and tasks compar ed to standard programming\n1\n2 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nlanguages. Kowalski’s seminal paper Predicate Logic as a Programming Language [Kowalski\n1974] was a major step in this direction and laid the foundati ons for the ﬁeld of logic\nprogramming. It introduced two fundamental ideas: on the de clarative level, the use of\nthe Horn clause logic fragment of classical logic; on the pro cedural level, a procedural\ninterpretation of this logic which made it possible to write algorithms in the formalism.\nWith the technology of the time, Kowalski’s paper was a break through for the use of logic\nin computer science.\nSince then, logic programming has fanned out in many directi ons, but in most extensions\nand variants, the original key ideas are still present in str onger or weaker form: the use of a\nrule-based formalism, and the presence of a procedural inte rpretation. Or at least, if programs\nare not procedures, they are representations of computatio nal problems, as in Datalog and in\nAnswer Set programming.\nIn this chapter, we present the IDP system (and language) tha t, although it builds on the\naccomplishments of logic programming and contains languag e constructs based on logic\nprogramming, embodies a more pure view of logic as a modellin g language. In this view ,\na logic theory is not a program, it cannot be executed or run; i t does not describe an\nalgorithm. A theory, in principle, is not even a speciﬁcatio n of a problem. A theory is a\nbag of information, a description of possible states of affa irs of the domain of discourse, a\nrepresentation of knowledge, or in other words a modelling o f the domain of discourse. As\nsuch, this view breaks the link that Kowalski had laid betwee n logic and programming. On the\nother hand, the IDP language contains a language construct, namely inductive deﬁnition, that\ndirectly descends from logic programming, and the IDP syste m is designed to use declarative\ninformation to solve problems and uses many technologies th at were developed in logic\nprogramming. As such, the IDP language and system preserve s ome of the contributions\nof logic programming but break with some of the fundamental i deas of logic programming.\nT o explain the IDP language, we need to go back to the early day s of logic programming\nwhen negation as failure was introduced. On the one hand, con clusions obtained with the\nnegation as failure inference rule were often natural and as desired. This is illustrated by the\nprogram and query in T able 1.1. On the other hand, these answe rs were logically unsound if\nrules were interpreted as material implications 1. This problem disturbed the logic program-\nming community for more than a decade and led to the developme nt of stable and well-\nfounded semantics [Gelfond and Lifschitz 1988, V an Gelder e t al. 1991]. However, a formal\nsemantics still does not explain the intuition that humans a ttach to such programs. For that,\nwe need to study the informal semantics of the logic. So far, t wo informal semantics have\nbeen proposed that can explain the intuitive meaning of logi c programs. One is the view of\nlogic programs under stable semantics [Gelfond and Lifschi tz 1988] as a non-monotonic logic\nclosely related to default logic and autoepistemic reasoni ng developed by Gelfond and Lifs-\n1 This is, the logical implication ϕ ⇒ψ that is interpreted as ¬ϕ ∨ψ .\n1.1 Introduction 3\nHuman(John). John is a Human\nHuman(Jane). Jane is a Human\nMale(John). John is a Male\nFemale(x) : −Human(x),notMale(x). Females are Humans that are not Male\n? −Female(Jane). is Jane Female?\nyes\nT able 1.1 Prolog answers “yes” to the query ?- Female(Jane).\nchitz [Gelfond and Lifschitz 1991]. The second is the view of logic programs as deﬁnitions\nof concepts. This view was implicit already in Clark’s work [ Clark 1978] on completion se-\nmantics and in the work by V an Gelder, Ross and Schlipf [V an Ge lder 1993, V an Gelder et al.\n1991] on the well-founded semantics. It was elaborated late r in a series of papers [Denecker\n1998, Denecker and V ennekens 2014, Denecker et al. 2001].\nThe informal concept of deﬁnition (as found in scientiﬁc tex ts) has several interesting as-\npects. First, it is a rule-based linguistic concept of infor mal language: deﬁnitions, certainly\ninductive ones, are commonly phrased as conditionals or set s of these. Second, deﬁnitions are\nsecond nature to us. Much human knowledge is of deﬁnitional n ature; this includes inductive\nand recursive deﬁnitions 2. Many familiar recursive logic programs are obviously repr esenta-\ntions of inductive deﬁnitions (e.g., the member, append and transitive closure programs).\nThird, deﬁnitions are of mathematical precision: they are t he building blocks of formal math-\nematical theories. Fourth, it is a well-known consequence o f the compactness theorem that\ndeﬁnitions, in particular inductive ones, cannot, in gener al, be correctly expressed in classical\nﬁrst-order logic. Fifth, recently [Denecker and V ennekens 2014], it was shown that rule sets\nunder two-valued well-founded semantics correctly formal ize all main sorts of informal deﬁ-\nnitions that we ﬁnd in scientiﬁc text in the sense that the int erpretation of the deﬁned symbols\nin the well-founded model of a rule set always coincides with the set deﬁned by the informal\ndeﬁnition represented by the rule set. All these are solid ar guments that the concept of deﬁni-\ntion is a good candidate for the informal semantics of logic p rogramming. Furthermore, they\nsuggest to deﬁne a rule-based logic construct under the well -founded semantics for expressing\ndeﬁnitions. Importantly, given that this form of informati on cannot be expressed in classical\nlogic, it makes sense to add such a construct to classical log ic. This idea was carried out for\nthe ﬁrst time in [Denecker 2000] leading to the logic FO(ID) w hich forms the basis of the\n2 In this text, we use the names recursive deﬁnition and inductive deﬁnition interchangeably .\n4 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nIDP language. Given that logic programs were originally see n as a fragment of classical logic,\nthe deﬁnition of this logic was certainly a remarkable turn o f events.\nA deﬁnition is a piece of information. It lays a strict, preci se, deterministic logical relation-\nship between the deﬁned concept and the concepts in terms of w hich it is deﬁned. E.g., the\ndeﬁnition of transitive closure of a graph speciﬁes a logica l relationship between the transitive\nclosure relation and the graph. A deﬁnition, like all other l anguage constructs in IDP theories,\nis not a procedure, it cannot be run, it does not specify a prob lem. It is a kind of declarative\ninformation.\nThe following question now naturally arises: if IDP theorie s are not programs, how can\nthey be used to solve computational problems? The IDP system , which supports the IDP\nlanguage, is conceived as a knowledge base system (KBS) [Denecker and V ennekens 2008].\nThe scientiﬁc working hypothesis underlying the knowledge base paradigm is that many\ncomputational problems can be solved by applying some form o f inference to a speciﬁcation\nof information of the problem domain. A KBS essentially cons ists of two parts. On the\none hand, a formal declarative knowledge representation language and, on the other hand,\na number of powerful and generic inference methods to solve a broad class of tasks using a\nknowledge base.\nThe paradigm is inspired by several observations. First, imperative programming languages\nallow the direct encoding of specialised algorithms, but kn owledge about the problem domain\nis hidden deep within those algorithms. This facilitates hi gh-performance solutions, but makes\ndebugging and maintenance very difﬁcult. Second, a program is typically written to perform\none task and perform it well, but cannot handle many related tasks bas ed on the same knowl-\nedge. Third, knowledge representation languages excel at representing knowledge in a natural,\nhuman-understandable format. Programming language desig ners are starting to realize this\nand provide constructs to express generic knowledge, such a s the LINQ [Pialorsi and Russo\n2007] data queries in C# and annotation-driven conﬁguratio n [Deinum et al. 2014]. Lastly, the\nabove-mentioned progress in automated reasoning techniqu es facilitates the shift of the con-\ntrol burden from programmer to inference engine ever more. T he knowledge base paradigm\nis an answer to these observations: application knowledge i s modelled in a high-level Knowl-\nedge Representation (KR) language and state-of-the-art in ference methods are applied to rea-\nson on the modelled knowledge. It has also been demonstrated that, while the KBS approach\ncannot yet compete with highly tuned algorithms, the effort to reach an acceptable solution\n(w .r.t. computing time or solution optimality) can be much s maller than that to develop an\nalgorithmic solution [Bruynooghe et al. 2015, Gebser et al. 2012a]. Furthermore, the declara-\ntive approach results in software that is less error-prone a nd more maintainable.\nThe IDP system is a state-of-the art KBS. The system is alread y in existence for several\nyears, but only recently evolved into a KBS. Up until 2012, ID P was a model expansion sys-\n1.1 Introduction 5\ntem (the IDP2 system) 3 capable of representing knowledge in a rich extension of ﬁrs t-order\nlogic (FO) and performing model expansion by applying its gr ounder G ID L and its solver\nMIN I SA T(ID). Recently, we have extended it into the IDP knowledge base framework for\ngeneral knowledge representation and reasoning (referred to as IDP3); the earlier technology\nis reused for its model expansion inference. The IDP system g oes beyond the KBS paradigm:\nfor a KBS to be truly applicable in practical software engine ering domains, it needs to provide\nan imperative programming interface, see [De Pooter et al. 2 011]. Such an interface, in which\nlogical components are ﬁrst-class citizens, allows users t o handle input and output (e.g., to\na physical database), to modify logical objects in a procedu ral way and to combine multi-\nple inference methods to solve more involved tasks. In this c hapter, we use KBS to refer to\na three-tier architecture consisting of language, inferen ce methods, and procedural integra-\ntion. The IDP system provides such a procedural integration through the scripting language\nLua [Ierusalimschy et al. 1996]. The system’s name IDP , Imperative-Declarative Program-\nming, also refers to this paradigm.\nIn the work revolving around IDP, we can distinguish between the knowledge represen-\ntation language and the state-of-the-art inference engine s. One can naturally model diverse\napplication domains in the IDP language; this contrasts wit h many approaches that encode\nknowledge such that a speciﬁc inference task becomes efﬁcie nt. Furthermore, reuse of knowl-\nedge is central. The IDP language is modular and provides ﬁne -grained management of logic\ncomponents, e.g., it supports namespaces. The implementation of the inference engines pro-\nvided by IDP aims at the reuse of similar functionality (see S ection 1.6). This has two impor-\ntant advantages: (i) improvement of one inference engine (e .g., due to progress in one ﬁeld of\nresearch) immediately has a beneﬁcial effect on other engin es; (ii) once “generic” functional-\nity is available, it becomes easy to add new inference engine s. T o lower the bar for modellers,\nwe aim at reducing the importance of clever modelling on the p erformance of the inference\nengines. Several techniques, such as grounding with bounds [Wittocx et al. 2010], function\ndetection [De Cat and Bruynooghe 2013], automated translat ion to the most suitable solving\nparadigm [De Cat et al. 2013] and automated symmetry breakin g [Devriendt et al. 2012] have\nbeen devised to reduce the need for an expert modeller.\nThe rest of the chapter is structured as follows. In Section 1 .2, we present the syntax and\nsemantics of FO(ID,A G G,PF,T), the logic underlying the system. In Section 1.3 we pr esent\na high-level overview of the IDP system. In Section 1.4, we pr esent the IDP language, a\nuser-friendly syntax for FO(ID,A G G,PF,T) language components and procedural control.\nW e present advanced language features and inference method s in Section 1.5. In Section 1.6,\nwe focus on the inner working of some components of the IDP sys tem. More speciﬁcally,\nwe describe the workﬂow of the optimization inference and ho w users can control the various\n3 Given a logical theory and a structure interpreting the doma in of discourse, model expansion searches for a model\nof the theory that extends the structure.\n6 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nparts of the optimization engine. Applications, tools and p erformance are discussed in Section\n1.7, followed by related work and a conclusion. In the rest of the chapter, we use IDP to refer\nto the current (2018), knowledge base version of the system.\nThis chapter is a tribute to David S. W arren. The XSB Prolog sy stem [Chen and W arren\n1996] by David S. W arren and his students was the ﬁrst to suppo rt the well-founded semantics\nand was a milestone in closing the gap between the procedural semantics of the SLDNF\nproof procedure [Lloyd 1987] and the intuitive declarative semantics of logic programs as\nformalized by the well-founded semantics. In fact, XSB is us ed internally in the IDP system.\nIn a personal communication, David once told the authors of t his chapter that when he learned\nabout FO(ID) and the IDP system, he was less than thrilled; sp eciﬁcally, he found it “a crazy\nidea”. It is with great satisfaction and gratitude that we ha ve noticed that he changed his mind\nas can be seen in his LinkedIn editorial that is devoted to the IDP language [W arren 2014]. It\nis therefore a great pleasure to contribute this chapter in a book that was initiated to honour\nhis 65th birthday.\n1.2 FO(ID,A GG ,PF,T), the Formal Base Language\nIn this section, we introduce the logic that is the basis of th e IDP language. This logic, FO(ID,\nAG G,PF,T), is an extension of ﬁrst-order logic (FO) with induct ive deﬁnitions, aggregates,\npartial functions and types.\n1.2.1 First-Order Logic\nA vocabulary Σ consists of a set of predicate and function symbols, each wit h an associated\narity, the number of arguments they take. W e sometimes use P/n ( f /n) to denote the predicate\nsymbol P (function symbol f ) with arity n.\nA term is a variable or an n-ary function symbol applied to n terms. An atom is an n-ary\npredicate symbol applied to n terms. An atom is a formula; if ϕ and ϕ ′are formulas and x is a\nvariable, then ¬ϕ , ϕ ∧ϕ ′, ϕ ∨ϕ ′, ∀x : ϕ and ∃x : ϕ are also formulas. The expressions ϕ ⇒ϕ ′,\nϕ ⇐ϕ ′and ϕ ⇔ϕ ′are (as usual) shorthands for ¬ϕ ∨ϕ ′, ϕ ∨¬ϕ ′and (¬ϕ ∨ϕ ′) ∧(ϕ ∨¬ϕ ′)\nrespectively. A literal (often denoted l) is an atom a or its negation ¬a. A sentence is a formula\nwithout free (unquantiﬁed) variables. A theory T over a vocabulary Σ consists of a set of\nsentences with symbols in Σ . A term t containing occurrences of a term t ′is denoted as t [t ′];\nthe replacement of t ′in t by t ′′is denoted as t [t ′/t ′′] (similarly for formulas).\nA two-valued structure (in the literature, sometimes also referred to as an interpretation) I\nover a vocabulary Σ consists of a domain D and an interpretation for all symbols in Σ ; we use\nsI to refer to the interpretation of a symbol s in I. A two-valued interpretation PI of a predicate\nsymbol P/n is a subset of Dn ; a two-valued interpretation f I for a function symbol f /n is a\nmapping Dn →D. The latter mapping can also be represented by a subset of Dn+1 in which\nthere is a functional dependency from the ﬁrst n arguments to the last one. Given a domain D,\n1.2 FO(ID,A G G,PF,T), the Formal Base Language 7\na domain atom is a tuple (P,d) where P is an n-ary predicate symbol and d ∈Dn is an n-tuple\nof domain elements. Sometimes, we abuse notation and write a domain atom as P(d).\nWhile the domain of standard FO is unordered, it is often conv enient to assume that there\nis a total order of the set of all domain elements and that a voc abulary includes, by default, the\nbinary comparison predicates =/2, ̸=/2, </2, >/2, ≥/2 and ≤/2; their interpretation is ﬁxed in\naccordance with the total order.\nBy evaluating a term or formula in a structure I, we obtain its value. The value of a term\nis a domain element, the value of a formula is a truth value, ei ther true, denoted t, or false,\ndenoted f, hence an element of the set {t,f}. The value of a term t , denoted as t I , is d if t\nis of the form f (t ) and f I (tI ) =d. The value P(t)I of an atom P(t ) in I is t if tI ∈PI and\nf otherwise. W e deﬁne (ϕ ∧ϕ ′)I = t if ϕ I = ϕ ′I = t, ϕ ∨ϕ ′I = t if either ϕ I = t or ϕ ′I = t,\n¬ϕ I = t if ϕ I = f; (∀x : ϕ )I = t if (ϕ [x/d])I = t for all d ∈D, (∃x : ϕ )I = t if (ϕ [x/d])I = t for\nat least one d ∈D. In the two quantiﬁed forms, the replacement of x by d in ϕ means that x is\ninterpreted as d when deriving the value of ϕ in I. W e say a two-valued structure I is a model\nof a formula ϕ or I satisﬁes ϕ , denoted as I |= ϕ , if ϕ I = t. Given two tuples t = (t1 ,... ,tn ) and\nt ′= (t ′\n1 ,... ,t ′\nn ) of terms of equal length n, t = t ′denotes the conjunction t1 = t ′\n1 ∧···∧ tn = t ′\nn .\nFor vocabularies Σ and Σ ’ with Σ ′⊇Σ and a structure I over Σ ′, I|Σ denotes the restriction of\nI to the symbols in Σ .\nUnless the context speciﬁes it differently, ϕ denotes a formula, t a term, D a domain, I a\ntwo-valued structure, I a partial structure (introduced below), d a domain element, x and y\nvariables, and ∼any comparison predicate.\nSometimes, it is convenient to use true and false as atoms in a formula. Therefore, we\ninclude them as nullary predicates in every vocabulary. In e very structure I, true is interpreted\nas {()}, i.e., as the set containing only the empty tuple, hence trueI = t, and false is interpreted\nas the empty set /0, i.e., falseI = f.\nPartial Structures A typical problem solving setting is that of model expansion [Mitchell and T ernovska\n2005] where one has partial knowledge about a structure and w here the goal is to expand this\npartial information into a structure that is a model of the gi ven theory. Hence we also use\npartial structures. A partial structure over a vocabulary Σ consists of a domain D , and a partial\ninterpretation I of the symbols in Σ . With sI , we refer to the interpretation of a symbol s in a\npartial structure I .\nWhereas the two-valued interpretation of a predicate P/n was deﬁned as a subset of Dn, it\ncan as well be deﬁned as a mapping from Dn to the set {t,f}. The latter form is better suited\nfor generalization. The partial interpretation of a predic ate P/n is deﬁned as a mapping from\nDn to the set {t,f,u}, with u standing for “unknown”. This mapping partitions Dn in the set\nof true tuples, denoted PI\nct (here ct stands for certainly true ), the set of false tuples, denoted\nPI\nc f (c f stands for certainly false ), and the set of unknown tuples, denoted PI\nu . Note that two\nof these sets fully determine the partial interpretation of P.\n8 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nWhereas the two-valued interpretation of a term is a single d omain element, this is no\nlonger the case for a partial interpretation. The partial in terpretation of a function f /n is as\na mapping from Dn+1 to {t,f,u}. As for predicates, we can distinguish true tuples f I\nct , false\ntuples f I\nc f , and unknown tuples f I\nu . While a functional dependency holds in the set f I\nct , this is\nnot the case for the latter two sets. However, (d,d) ∈f I\nct iff (d,d′) ∈f I\nc f for all d′∈D \\{d}.\nIf I is a partial structure, U a set of domain atoms, and v a truth value, we use I [U : v] to\nrefer to the partial structure that equals I except that for each domain atom P(d) ∈U , it holds\nthat P(d)I [U :v] = PI [U :v] = v.\nThe partial structure I that corresponds to a two-valued v I is such that, for predicate\nsymbols P/n, PI\nct = PI , PI\nc f = Dn \\PI\nct and, PI\nu = /0 and, for function symbols f /n, f I\nct =\n{(d,d) |f I (d) =d}, f I\nc f = Dn+1 \\f I\nct and f I\nu = /0.\nThe truth order <t on truth values is induced by f <t u <t t. The precision order <p on\ntruth values is induced by u <p t and u <p f. This order is extended to a precision order\nover partial structure. A partial structure I is less precise than a partial structure I ′(notation\nI ≤p I ′) if, for all symbols s ∈Σ , sI\nct ⊆sI ′\nct and sI\nc f ⊆sI ′\nc f . Maximally precise partial structures\nare two-valued.\nIn the remainder of the chapter, partial interpretation or s tructure is intended when inter-\npretation or structure is used.\n1.2.2 Partial Functions\nIn standard logic, function symbols denote total functions . In practice, partial functions are\nunavoidable, e.g., a function that maps persons to their spo use is naturally undeﬁned for\nsingles as well as for objects that are not a person, and the ar ithmetic operation division is\nundeﬁned when the denominator is zero. So, our logic support s partial functions; however,\ndeﬁning a semantics for partial functions gives rise to unde ﬁned terms (also called non-\ndenoting); this is a subject of controversy [Frisch and Stuc key 2009, Wittocx 2010].\nThe simplest solution is to restrict the syntax of formulas. One could, e.g., only allow terms\nof the form f (t ) in contexts where it is certain that f (t ) is deﬁned. This option is often taken\nin mathematics, where terms like, e.g., 1 /0 are considered meaningless, but quantiﬁcations\nof the form ∀x : x ̸= 0 ⇒1/x ̸= 42 are allowed as it is clear that the division 1 /x will\nbe deﬁned for all relevant x. This idea has been implemented for example in the Rodin\ntoolset for Event-B [Abrial et al. 2010], where for every occ urrence of a partial function, it\nshould be provable that the function will only by applied to v alues in its domain. However,\nthis approach is too restrictive for a KBS. For example, in pl anning problems, the function\nDo/1 in a term Do(t ) that refers to the action performed at time t is typically a partial\none. It can be pretty hard to come up with the right Condition/1 predicate such that one\ncan write ∀t : Condition(t ) ⇒...Do(t ).... It is entirely impossible, when the partial function\nis a constant for which it is a priori unclear whether it is deﬁ ned, such as Unicorn. So we\nallow terms in contexts where they can be undeﬁned. This brin gs us to the question what an\n1.2 FO(ID,A G G,PF,T), the Formal Base Language 9\nambiguous form such as White(Unicorn) means. Does it mean “if the unicorn exists then\nit is white”, i.e., ∀x : Unicorn = x ⇒White(x) or “the unicorn exists and is white”, i.e.,\n∃x : Unicorn = x ∧White(x) (which equals (∃x : Unicorn = x) ∧White(Unicorn)). For the\nuser, having to write the longer unambiguous form is rather i nconvenient (especially in case\nof nested partial functions).\nThe current approach, which is the result of some years of exp erimenting, is based on\nthe relational semantics proposed in [Frisch and Stuckey 2009]. It turns out to be ﬂexi ble,\nintuitive and to allow for elegant modelling. The ambiguous form A( f (t )) is given the second\nof the above two meanings, namely ∃x : f (t ) =x ∧A[x] or equivalently ∃x : f (t ) =x ∧A[ f (t )].\nWhen the user is in doubt or prefers the other form, he should a void the ambiguous form and\nexplicitly write one of the explicit forms.\nIn a two-valued structure I, the value of a partial function f /n is a mapping f I : S →D\nwhere S is some subset of Dn . In a partial structure I , f /n is undeﬁned for d if and only if\n(d,d) ∈f I\nc f for all d ∈D. W e say that the image f (d ) is undeﬁned when f is undeﬁned for d.\nThe interpretation of a term with a direct subterm that is und eﬁned is also undeﬁned; that of an\natom with a direct subterm that is undeﬁned is false. This corresponds to the above described\nsemantics.\n1.2.3 Arithmetic\nStandard FO can easily be extended with arithmetic. Indeed, numbers can be added to\nthe domain and various (partial) functions can be included i n the vocabulary to perform\narithmetic.\nSo far, the IDP system only supports arithmetic over integer s. This is our motivation\nto include the integers in every domain of FO(ID,A G G,PF,T) and the arithmetic partial\nfunctions +/2, -/2, -/1, */2 (multiplication), //2 (divisi on) %/2 (modulo) and abs/1 in every\nvocabulary4. T o refer to these integers, every vocabulary also includes the constant symbol\nn for every integer n. Furthermore, in every structure, the interpretation of th ese integer\nconstants is ﬁxed to the corresponding integer in the domain .\n1.2.4 Aggregates\nAggregates are an important language construct to boost the expressiveness of ﬁrst-order\nlogic. FO(ID,A G G,PF,T) includes the aggregate functions cardinality, sum, product, mini-\nmum and maximum. The basic underlying concept is the set expression {(x) |ϕ }or {(x,t ) |ϕ }\nwhere x is a tuple of new variables and t is a term t [x,y] with variables in x and in the free vari-\nables y of the expression. Given a two-valued structure I, such a set expression denotes the set\nof tuples {(x)I |ϕ I = t}or {(x,t )I |(∃z : z = t ∧ϕ )I = t}, where the existential quantiﬁcation\n4 The current implementation of the ID P language, described i n Section 1.4, has only limited support for integer\ndivision.\n10 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nranges over the domain of t . The inclusion of ∃z : z = t in the set prescription disambiguates\nthe set in case of partial functions in ϕ .\nCardinality expressions are written in FO(ID,A G G,PF,T) as # {x : ϕ }and this term denotes\nthe number of tuples in the set. For the other four, the aggreg ate expressions take the form\nsum{(x,t ) : ϕ }, prod{(x,t ) : ϕ }, min{(x,t ) : ϕ }, and max{(x,t ) : ϕ }respectively. These\nexpressions denote the value of the aggregate function on th e multiset obtained by extracting\nthe last element t I of each tuple. For instance sum{((x1 ,x2 ),x2 ) : P(x1,x2 )}sums the values\nof the second element of all tuples in P. If there are multiple occurrences of the same “second\nelement” in tuples of P, then they are counted according to their multiplicity.\nAll aggregate functions are partial functions; they are und eﬁned for inﬁnite sets. Moreover,\nall aggregate functions except # are only deﬁned for sets con taining a tuple (... ,d) with d an\ninteger. The aggregates min and max are also undeﬁned for the empty set; in contrast, sum and\nprod map the empty set to 0 and 1 respectively.\nThe aggregates supported by FO(ID,A G G,PF,T) also include the class of formulas ∃∼nx :\nϕ with n a natural number and ∼one of the comparison operators. While such formulas are\nequivalent with # {x : ϕ }∼n, they are more concise and a convenient extension of existen sial\nquantiﬁcation. They allow one to express “there exists exac tly n” ( = n), “at most n” ( ≤n),\n“less than n” ( < n), “more than n” ( > n), “at least n” ( ≥n), and “there does not exist exactly n”\n(̸= n) values for x such that ϕ holds. Note that ∃≥1 x : ϕ is equivalent with ∃x : ϕ , and ∃=0 x : ϕ\nwith ¬(∃x : ϕ ).\n1.2.5 Deﬁnitions\nThe logic FO(ID,A G G,PF,T) contains a deﬁnition construct to express different kinds\nof (possibly inductive) deﬁnitions. This construct is one o f the most original aspects of\nFO(ID,A G G,PF,T) and we explain it in more detail. For additional detai ls we refer to\n[Denecker and T ernovska 2008].\nDeﬁnitions are important building blocks of any scientiﬁc t heory. However, there is no\ngeneral way to express inductive/recursive deﬁnitions in F O. Though the notion of deﬁni-\ntion is informal, deﬁnitions have some extraordinary prope rties. Certainly those used in for-\nmal mathematical text strike us for the precision of their me aning. The formal semantics of\nFO(ID,A G G,PF,T) deﬁnitions carefully formalizes this meaning. Seve ral types of informal\ndeﬁnitions can be distinguished. Below , the three most comm on ones are illustrated: Exam-\nple 1.2.1 is a non-recursive one, Example 1.2.2 is a monotone one, while Example 1.2.3 is\nby induction over a well-founded order, namely over the subf ormula order. Deﬁnitions over\na well-founded order frequently contain non-monotone rule s. For instance the rule deﬁning\nI |= ¬α has a non-monotone condition I ̸|= α .\nExample 1.2.1. Let a,b and c be integers; a is between b and c iff b ≤a and a ≤c.\n1.2 FO(ID,A G G,PF,T), the Formal Base Language 11\nExample 1.2.2. Let (N,E ) be a graph with nodes N and edges E . The transitive closure T of\n(N,E ) is deﬁned inductively as follows.\n•If (a,b) ∈E , then (a,b) ∈T ,\n•If for some c ∈N, it holds that (a,c) ∈T and (c,b) ∈T , then also (a,b) ∈T .\nExample 1.2.3. Let I be a two-valued structure of a propositional vocabulary. Th e satisfaction\nrelation |= is deﬁned by induction over the structure of formulas:\n•I |= P if P ∈I.\n•I |= α ∧β if I |= α and I |= β .\n•I |= α ∨β if I |= α or I |= β (or both).\n•I |= ¬α if I ̸|= α .\nIn FO(ID,A G G,PF,T), a formal deﬁnition ∆ is a set of rules of the form ∀x : P(t) ←ϕ or\n∀x : f (t ) =t ′←ϕ , with the free variables of ϕ and the variables in t and t ′amongst the x. W e\nrefer to P(t ) and f (t ) =t ′as the head of the rule and to ϕ as the body. In the ﬁrst form, P is the\ndeﬁned symbol; in the second, f is. The deﬁned symbols of ∆ are all symbols that are deﬁned\nby at least one of its rules; all other symbols occurring in ∆ are called parameters or open\nsymbols of ∆ . Intuitively, for each two-valued structure of the paramet ers, ∆ determines the\ninterpretation of the deﬁned symbols in a unique way. For ins tance, the deﬁnition of transitive\nclosure can be formalized as follows\n{\n∀a,b : T (a,b)←E (a,b).\n∀a,b : T (a,b)←∃c : T (a,c) ∧T (c,b).\n}\nThe different sorts of deﬁnitions have different semantic p roperties. It is commonly as-\nsumed that the deﬁned set is the least set that satisﬁes the rules of the deﬁnition, i.e., the least\nset such that the head is true whenever the body is true. Howev er, this is only true for mono-\ntone deﬁnitions. It does not hold for non-monotone deﬁnitio ns as the following example, from\n[Denecker and V ennekens 2014], illustrates.\n{\nE ven(0).\n∀x : E ven(x + 1)←¬E ven(x).\n}\nIntuitively, this deﬁnes the inﬁnite set {E ven(0),E ven(2),E ven(4)...}of even numbers.\nHowever, also the inﬁnite set {E ven(0),E ven(2),E ven(3),E ven(5), ...}satisﬁes the rules\nas for every rule instance with a true body, the head is also tr ue. Both solutions are minimal;\nhowever, none is “least”.\nStill, there is an explanation that applies to all kind of deﬁ nitions [Buchholz et al. 1981]: the\nset deﬁned by an inductive deﬁnition is the result of a constr uction process. The construction\nstarts with the empty set, and proceeds by iteratively apply ing non-satisﬁed rules, till the set is\nsaturated. In the case of monotone deﬁnitions, rules can be a pplied in any order; but in the case\n12 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nof deﬁnitions over a well-founded order, rule application m ust follow the well-founded order.\nThis condition is necessary for the non-monotone rules. If t hey would be applied too early,\nlater rule applications may invalidate their condition. E. g., in the initial step of the construction\nof |=, when the relation is still empty, we could derive I |= ¬ϕ for each ϕ , but the condition\nI ̸|= ϕ will in many cases later become invalidated. The role of the i nduction order is exactly to\nprevent such an untimely rule application. E.g., to prevent deriving E ven(3) before E ven(2)\nhas been derived.\nThe problem we face in formalizing this idea for the semantic s of FO(ID,A G G,PF,T)\ndeﬁnitions, is that the syntax of FO(ID,A G G,PF,T) does not specify an explicit induction\norder for non-monotone FO(ID,A G G,PF,T) deﬁnitions. Thus, the question is whether one\ncan somehow “guess” the induction order. Indeed, if we look b ack at the deﬁnition of\nExample 1.2.3, we see that the order is implicit in the struct ure of the rules: formulas in\nthe head of rules are always larger in the induction order tha n those in the body. This holds\ntrue in general. It should be possible then to design a mathem atical procedure that somehow\nis capable to exploit this implicit structure.\nIn [Denecker and V ennekens 2014], this idea was elaborated. The induction process of\nan FO(ID,A G G,PF,T) deﬁnition is formalized as a sequence of three-value d structures of\nincreasing precision. Such a structure records what elemen ts have been derived to be in the\nset, what elements have been derived to be out of the set, and w hich have not been derived\nyet. Using the current three-valued structure, one can then establish whether it is safe to apply\na rule or not. All induction sequences can be proven to conver ge. In case the deﬁnition has\nthe form of a logic program and the underlying structure is a H erbrand interpretation, the\nresulting process can be proven to converge to the well-know n well-founded model of the\nprogram [V an Gelder et al. 1991]. As such, the semantics of FO (ID,A G G,PF,T) deﬁnitions\nis a generalization of the well-founded semantics, to arbit rary bodies, arbitrary structures and\nwith parameters. This (extended) well-founded semantics p rovides a uniform formalization\nfor the two most common forms of induction (monotone and over a well-founded order) and\neven for the less common form of iterated induction [Buchhol z et al. 1981]. Compared to\nother logics of iterated inductive deﬁnitions, e.g., the wo rk in [Buchholz et al. 1981], the\ncontribution is that the order does not have to be expressed; a substantial advantage as this can\nbe very tedious.\nThe satisfaction relation of FO is thus extended to handle de ﬁnitions by means of the\nwell-founded semantics [V an Gelder 1993], since it formali zes the informal semantics of rule\nsets as inductive deﬁnitions [Denecker 1998, Denecker and V ennekens 2014, Denecker et al.\n2001]. W e now formally describe how this is done. First, cons ider deﬁnitions ∆ that de-\nﬁne only predicate symbols. W e use the parametrised well-fo unded semantics. This se-\nmantics has been implicitly present in the literature for a l ong time, by assigning a mean-\ning to an intensional database. W e follow the formalisation by Denecker and V enne kens\n[Denecker and V ennekens 2007]. W e say that a two-valued stru cture I satisﬁes ∆ (I |= ∆ )\n1.2 FO(ID,A G G,PF,T), the Formal Base Language 13\nif I is the parametrised well-founded model of ∆ , that means that I is the well-founded model\nof ∆ when the open symbols/parameters are interpreted as in I.\nChecking the latter is done by computing the well-founded mo del of ∆ . This can be\ncomputed as the limit of a well-founded induction [Denecker and V ennekens 2007], deﬁned\nbelow .\nDeﬁnition 1.2.4 (Reﬁnement) . W e call a partial structure I ′a reﬁnement of partial structure\nI if one of the following holds:\n•for every deﬁned predicate P and every tuple of domain elements\nd,\nP(d)I ′\n= max\n≤t\n{ϕ [x/d]I |∀x : P(x) ←ϕ is a rule in ∆ }.\n•I ′= I [U : f], where U is a set of domain atoms unknown in I such that for every P(d) ∈U\nand every rule ∀x : P(x) ←ϕ in ∆ , it holds that ϕ [x/d]I ′\n= f (such a set U is called an\nunfounded set of ∆ in I [V an Gelder et al. 1991]).\nA reﬁnement is strict if I ′̸= I .\nThe ﬁrst reﬁnement evaluates all rule bodies of all deﬁned do main atoms and assigns the\nlargest truth value (e.g., if one rule derives an atom to be tr ue, and the second rule does not\nyet derive information about that atom ( u), the atom obtains the value t) to each deﬁned atom.\nThe second reﬁnement identiﬁes an unfounded set: a set of dom ain atoms such that the bodies\nof rules deﬁning them can only become true if at least one of th ese atoms is true in the ﬁrst\nplace (due to cyclic dependencies). Such atoms can never be d erived constructively using the\ndeﬁnition, hence they must be false.\nDeﬁnition 1.2.5 (W ell-founded induction). Let I be a partial structure that interprets only the\nopen symbols of ∆ . A well-founded induction of ∆ in I is a sequence (Ii )i≤n , with n ∈N, of\npartial structures such that the following hold: 5\n•I0 = I ;\n•for each i < n, Ii+1 is a reﬁnement of Ii .\nA well-founded induction is terminal if its limit ( In ) has no strict reﬁnements.\nDenecker and V ennekens [Denecker and V ennekens 2007] showe d that all terminal well-\nfounded inductions in I have the same limit, namely the well-founded model of ∆ in context\nI .\nT o extend this satisfaction check to deﬁnitions deﬁning fun ctions, one treats a function\nf /n as if it is deﬁning an n + 1-ary relation. For what concerns the use of partial functio ns in\nthe head of a rule, note that ∀\ny : p(t ) ←ϕ is equivalent with ∀xy : p(x) ←x = t ∧ϕ . Partial\nfunctions in bodies have the same meaning as in formulas.\n5 In the inﬁnite case, a similar sequence can be constructed. F or details, see [Denecker and V ennekens 2007].\n14 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nIn FO(ID,A G G,PF,T), a deﬁnition is seen in a pure declarative way, as a pro position\nstating a special logical relationship between deﬁned pred icates and parameter symbols. In\ncase a theory contains multiple deﬁnitions of the same predi cate, the theory states multiple\nindependent such propositions. For instance, a theory that contains\n{\n∀x : H uman(x)←Man(x) ∨Woman(x).\n}\n{\n∀x : H uman(x)←Child (x) ∨Adult (x).\n}\nstates that Human is the union of men and women and also that hu man is the union of children\nand adults. This implies for example that the union of men and women, and of children and\nadults is identical. Note that this declarative view implie s that the deﬁnition\n{\np ←q.\nq ←p.\n}\nhas a different meaning than the pair of deﬁnitions\n{\np ←q.\n}\n{\nq ←p.\n}\nIndeed, in the former, p and q are false in the only well-founded model. In the latter, the\nstructure in which p and q are true is also a model since we now have two deﬁnitions, each\nwith a parameter.\nT o reason with deﬁnitions, the IDP solver makes also use of th eir completion. The\ncompletion of ∆ for a symbol P, deﬁned in ∆ by the rules ∀xi : P(ti ) ←ϕ i with i ∈[1,n],\nis the set consisting of the sentence ∀xi : ϕ i ⇒P(t i ) for each i ∈[1,n] and the sentence\n∀x : P(x) ⇒⋁\ni∈[1,n](x = t i ∧ϕ i ); the completion for deﬁned function symbols is deﬁned\nsimilarly. This set is denoted as com pP,∆ , the union of all these sets for ∆ as com p∆ . It\nis well known (see, e.g., [V an Gelder et al. 1991]) that if I |= ∆ then I |= comp∆ but not\nalways vice-versa (e.g., the inductive deﬁnition expressi ng transitive closure is stronger than\nits completion).\n1.2.6 Types\nWhile ﬁrst-order logic is untyped, the real world is typed. F or example, in a course scheduling\nproblem, we can distinguish persons, which can be further di vided in teachers and students,\ncourses, rooms, time slots, etc. The advantages are well kno wn in the ﬁeld of programming\nlanguages. For example, the introduction of the book of Pier ce [Pierce 2002] lists, among\nothers, early detection of errors and a minimum of documenta tion. These advantages also hold\nfor a knowledge representation language. Moreover, the use of types leads to more detailed\nand more accurate modelling of the different types of object s in the domain of discourse.\n1.3 ¡toc-entry¿ 15\nFO(ID,A G G,PF,T) is a simple order sorted logic . This means that a vocabulary contains\na set of types on which a subtype relation is deﬁned. The corre sponding type hierarchy is a\nset of trees. T wo types are disjoint if they have no common supertype (a type is a supertype of\nitself). Every vocabulary includes the type int of the integers and its subtype nat of the natural\nnumbers. All predicate and function symbols of a vocabulary are typed by means of a type\nsignature which associates a type with each argument positi on, and, in the case of functions,\nwith the result. All variable occurrences in a theory are typ ed; all occurrences of a variable\nwithin the same scope have the same type; the type of a variabl e is given when it is introduced\nin a formula or set expression, for example, ∀x[T ] : ϕ [x] and # {x[T ] y[T ′] : ϕ [x,y]}< 3.\nIn a structure, a domain DT is associated with each type T ; for a subtype T1 of T2 , DT1 is a\nsubset of DT2 ; if T1 and T2 are disjoint types, DT1 and DT2 must be disjoint. Structures are well-\ntyped. This means that for a predicate symbol P of type (T1 ,... ,Tn ), its value PI belongs to the\nCartesian product DT1 ×···× DTn , and for a function symbol f from (T1 ,...,Tn ) to T , its value\nf I is a partial function from DT1 ×···× DTn to DT . For the evaluation of quantiﬁed formulas\n∀x[T ] : ϕ and ∃x[T ] : ϕ , enumeration of the values of x is over the domain DT . Similarly, in\na set expression {(x [T ],t )|ϕ }of an aggregate, each xi is assigned domain elements from DTi .\nNote that a term t of type T1 that occurs in an argument of an atom or function where a term\nof type T2 is expected can have the meaning of an undeﬁned term (Section 1.2.2). Indeed,\nthe atom evaluates to false or the function is undeﬁned when t evaluates to a domain element\noutside DT2 . While this cannot happen when T2 is a supertype of T1, it always is the case\nwhen T1 and T2 are disjoint; it depends on the evaluation when there is a thi rd type that is a\nsupertype of both. When the types are disjoint, it is appropr iate to raise a type error as this is\nlikely a design error in the logical theory.\n1.3 IDP as a Knowledge Base System\nW e start the section with a description of the architecture a nd a discussion of design decisions.\nW e ﬁnish with sketching an application where the same knowle dge is used for different tasks.\n1.3.1 Architecture and Design Decisions\nHere, we introduce and motivate the basic design decisions u nderlying the IDP system, the\ndecisions that determine the look and feel of IDP as a KBS. IDP is an implementation of a\nKBS. Besides the two main parts, the declarative language and the inferences methods , there\nis also a part that provides procedural integration . An overview is shown in Figure 1.1.\nThe ﬁrst design decision, the one most visible to users, is ab out the language of the KBS.\nThe language should be (i) rich enough so that users can express all their needs; (ii) natural\nenough so that theories stay close to the original (natural l anguage) problem statement and are\neasy to read and to debug; and (iii) modular enough to allow for reuse and future extensions.\nIt is sometimes argued that the expressiveness of a language should be limited, to avoid that\nthe language becomes undecidable or intractable. W e disagr ee. First, note that decidability and\n16 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\n•V ocabulary\n•Structure\n•Theory\n•Procedure\n•T erm\n•Namespace\n•Query\n•Model expansion\n•Model checking and\nsatisﬁability checking\n•Optimization\n•Propagation\n•Deduction\n•Query inference\n•Symmetry detection\nLua code embedded in procedure components for calling\ninference methods\nProcedural interface: Lua\nInference MethodsLanguage Components\nFigure 1.1 High-level representation of a KBS system\ntractability depend on the task at hand. While deduction in ﬁ rst order logic is undecidable,\nother forms of inference, such as model expansion and queryi ng in the context of a ﬁnite\ndomain, are decidable. Second, while a more expressive lang uage might allow users to express\ntasks high in the polynomial hierarchy, that does not imply t hat simple tasks become harder\nto solve. Rather to the contrary, stating the problem in a ric her language sometimes allow the\nKBS to exploit structural information that would be hidden i n a more lower-level problem\nstatement.\nT o address the requirement of a rich and a natural language, w e have opted for FO(ID,\nAG G,PF,T), FO extended with deﬁnitions, aggregates, partial f unctions and types. W e choose\nfor ﬁrst-order logic because conjunction, disjunction, un iversal and existential quantiﬁcation\nhave very natural meanings. Extensions are needed because F O has various weaknesses.\nInductive deﬁnitions overcome the weakness that FO cannot e xpress inductively deﬁned\nconcepts. Also non-inductive deﬁnitions are very useful. I n mathematical texts, it is common\npractice to use “if ” when deﬁning concepts; this “if ” here is (in natural language) a deﬁnitional\nimplication. Aggregates allow users to concisely express information r equiring lengthy and\ncomplex FO formulas. T ypes are omnipresent in the context of natural language, where\nquantiﬁcation typically refers to a speciﬁc set of objects ( e.g., everyone is mortal). For\nintegration with a procedural language, IDP currently offe rs an interface to the languages\nLua and C++.\n1.3 ¡toc-entry¿ 17\nThe third language requirement, modularity, is important b oth at the language and at the\nsystem level. An advantage of ﬁrst-order logic as basis of ou r language is that language\nextensions can be added without much interference at the syn tactical and semantical level.\nFor example to introduce aggregates to FO, it sufﬁces to exte nd the satisfaction of atoms\nin which an aggregate occurs in order to obtain a semantics fo r a language extended with\naggregates.\nOn the system level, we have also attempted to organize infer ence engines in a modular\nway so that components can be reused in multiple engines. For example, the model expan-\nsion inference is currently implemented as ground-and-sol ve; the solver can be used sepa-\nrately from the grounder, and the grounding phase is compose d of several smaller, reusable\nparts (for example, evaluation of input-*-deﬁnitions [Jan sen et al. 2013]). Also various ap-\nproaches to preprocess simple theories in order to improve t heir computational efﬁciently are\nintegrated in the system. Examples are symmetry detection [ Devriendt et al. 2016b] and sym-\nmetry breaking [Devriendt et al. 2012] methods and the use of deduction to detect functional\ndependencies [De Cat and Bruynooghe 2013]. Such preprocess ing techniques also improve\nthe user-friendliness and robustness of the KBS as a whole. I ndeed, they let a user focus\non the declarative modelling, and partly relieve the user fr om the task of ﬁne-tuning it on a\nspeciﬁc solver.\n1.3.2 Multiple Inference Methods Within One Application Do main\nGiven any knowledge base, there are often multiple applicat ions that require different kinds\nof inference. By way of example, we explore the setting of a un iversity course management\nsystem. Its input is a database with information on students , professors, classrooms, etc. One\ntask of the system is to help students choose their courses sa tisfying certain restrictions. Such\nan application is usually interactive; students make choic es and, in between, the system checks\nthe knowledge base. It removes choices when they become inva lid, adds required prerequisites\nwhen a course is selected, etc; this is an example of propagation inference. When the student\nhas made all choices he deems important, the system could use the same knowledge base to\ncomplete the student’s choices to obtain a complete schedul e. This type of inference is called\nmodel generation or model expansion : one starts with partial information (certain selections\nhave been made) and wants to extend it into a complete solutio n, namely a model of the course\nselection theory. Another task where model expansion is nee ded in the same application area\nis to generate a schedule where every course is assigned a loc ation and a starting time such\nthat 1) no person has to be at two places at the same time, 2) no r oom is double-booked and 3)\navailability of professors is taken into account. However, due to the large number of optional\ncourses, such a solution (in which no student has overlappin g courses) will probably not exist.\nIn this case, we might want to ﬁnd a solution in which the numbe r of conﬂicts is minimal; this\nrequires minimization inference. Now , one might want to mail students with schedul es with\noverlaps to give them the opportunity to change their select ion. Hence, the solution of the\n18 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nminimization inference should be queried to ﬁnd the overlapping courses for every student.\nIn the course of a semester, professors might have to cancel a lecture due to other urgent\nobligations. In that case, we want to ﬁnd a revision of the current schedule, taking the changed\nrestrictions into account and minimizing the number of chan ges with respect to the current\nschedule. In case such revisions are done manually, the model checking inference can be used\nto ensure that no new conﬂicts are introduced. If some conﬂic t does occur, an explanation\nshould be provided. Finally, if a valid schedule is found, a visualization inference can be used\nto create an easy-to-understand, visual representation of the schedule, personalized by the\nviewer’s status (student, professor, administrative pers onnel, etc.). Part of such an application,\nusing the IDP system as a back end, is shown at http://krr.bit bucket.org/courses .\n1.4 The IDP Language\nThe IDP language is the input language of the IDP system. A pro gram in the IDP language\nconsists of declarative and imperative components. The dec larative components are vocab-\nulary, structure, theory and term components. T ogether, they provide a concrete computer-\nreadable syntax for FO(ID,A G G,PF,T). The imperative components allow one to perform\ncomputational tasks. They consists of procedures. Each procedure embeds a piece of impera-\ntive Lua [Ierusalimschy et al. 1996] code; besides performi ng standard imperative operations,\nprocedures can apply inference methods upon FO(ID,A G G,PF,T) theories encoded in the\ndeclarative components.\nV ocabulary, structure and theory components are described in Section 1.4.1; procedure\ncomponents in Section 1.4.2 and term components in Section 1 .4.3. In this section we do not\nstrive for completeness but focus on what is needed to get sta rted using the IDP system and\non providing answers to the difﬁculties a starting user migh t have.\nBefore describing the different kinds of components, we ﬁrs t discuss a few general no-\ntational conventions. Names are everywhere, they are used f or types, predicates, functions\n(including constants), and variables as well as for domain e lements in structures. T o distin-\nguish them from numbers, they start with a Latin letter (uppe r or lower case) and consist of a\nsequence of Latin letters and digits; also a few special char acters such as “\n” are allowed. For\ndomain elements, one can deviate from this convention by usi ng a string notation. For details,\nwe refer to the manual [Bogaerts et al. 2012]. Comments that ﬁ t on a single line start with\n“ // ”. One can start longer comments with “ /∗” and end them with “ ∗/”.\n1.4.1 The Logic\n1.4.1.1 V ocabulary\nThe vocabulary of an FO(ID,A G G,PF,T) theory is represented as a vocabulary component.\nW e start with an example.\nv o c a b u l a r y c o u r s e s {\nt y p e c o u r s e\n1.4 ¡toc-entry¿ 19\nt y p e p e r s o n\nt y p e s t u d e n t i s a p e r s o n\nt y p e i n s t r u c t o r i s a p e r s o n\nt y p e a g e i s a n a t\nt a k e s ( s t u d e n t , c o u r s e )\nh a s A g e ( p e r s o n ) : a g e\nV a c a t i o n\nB o s s : p e r s o n\n}\nA vocabulary declaration takes the form “ vocabulary ⟨vocname ⟩{⟨typed symbol list ⟩}”. It\nspeciﬁes the name of the vocabulary, here courses and its symbols. The symbol list comprises\ntype symbols, and typed predicate and function symbols. Eac h symbol is to be declared on a\nnew line. T ypes are declared using the keyword “ type”. A type may be declared as a subtype\nusing the keyword “ isa ” followed by a comma-separated list of supertypes. For exam ple “ type\nA isa B, C” declares A as a direct subtype of B and C. The declared isa graph needs to be\nacyclic. The integers, type int , and its subtype, the natural numbers, type nat, are part of every\nvocabulary and need not be declared. The same holds for predi cates and functions that are part\nof every FO(ID,A G G,PF,T) theory such as comparison predicates and arithmetic functions.\nPredicates and functions are introduced by declaring their signature. In the example, takes is\na relation over student and course and hasAge is a function from person to the subtype age, a\nsubtype of nat. The symbol V acation is a propositional symbol, and Boss a constant symbol.\nPartial functions are introduced by the keyword partial , for example partial hasAge(person)\n: age would declare hasAge as a partial function. The IDP system cannot yet cope well wit h\ninﬁnite types, so int and nat can better be avoided in signatures of predicates and functi ons.\n1.4.1.2 Structure\nA structure component describes a partial structure for a vo cabulary, in particular the domains\nof the user declared types. W e start again with an example.\ns t r u c t u r e d a t a 1 : c o u r s e s {\nc o u r s e = { L o g i c ; Math }\ns t u d e n t = { J o h n ; Bob ; A l i c e }\ni n s t r u c t o r = {Marc ; G e r d a ; M a u r i c e }\np e r s o n = { J o h n ; Bob ; A l i c e ; Marc ; G e r d a ; M a u r i c e }\na g e = {1 . . 6 5 }\nt a k e s <c t > = { J o h n , L o g i c }\nt a k e s <c f > = {Bob , Math }\nh a s A g e <c t >= { J o h n −>25; Bob −> 3 0 ; A l i c e −>19}\nV a c a t i o n = t r u e\nB o s s = A l i c e\n}\n20 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nA structure has a name, here data1, and speciﬁes the vocabulary that it (partially) interpret s,\nhere courses . It speciﬁes an assignment of values for symbols using a list of “symbol=value”\nequations. Boolean values are denoted true or false , as illustrated by the equation V acation=\ntrue in the example. Other base values are numbers, strings, or us er-deﬁned domain values\nlike Bob, Math . Set values are denoted as “ {⟨semicolon separated list ⟩}”. The list may\nconsist of individual entities or of tuples of individual en tities. Tuples are denoted as comma\nseparated lists of domain values, potentially between pare ntheses ”( . . . )”. The shorthand\n“n..m” enumerates the integer interval [n,m], as illustrated for age. The same holds for\ncharacters, e.g., student = {a .. d } is a shorthand for student = {a;b ; c ; d }.\nA structure speciﬁes, implicitly or explicitly, the value o f each type of the vocabulary 6. A\nvalue of a type is a set of domain elements. User-deﬁned domai n elements are identiﬁed by\nsymbolic identiﬁers (e.g., Bob, Math) but these identiﬁers are not symbols of the vocabulary\nand cannot be used in the theory. One can use integers as names for the domain elements of\ntypes, even if this type is not a subtype of int . For example student = {1..50} introduces 50\nstudents. Note, these domain elements are not integers, the domain element 49 of type student\nis different from domain element 49 of type integer.\nA (total) value for a predicate symbol is a set of domain eleme nts or tuples of it. Alterna-\ntively, a structure may specify a partial value for a predica te symbol P, as an assignment of\na list of certainly true, certainly false and unknown tuples to respectively P<ct>, P<cf>, and\nP<u>. Only two out of three need to be speciﬁed. This is illustrate d by takes .\nThe value or partial value for functions is speciﬁed in an ana logous way, with the difference\nthat the user is allowed (but not obliged) to specify a tuple “ (a1,. . . ,an,b)” of a function in the\nform “ a1 ,.., an −> b”. For partial interpretations of functions, we refer to the discussion on\npartial structures in Section 1.2.1. For example, hasAge<cf> = {Marc −> 1; Marc −> 2} can\nbe used to express that the age of Marc is neither 1 nor 2.\nIn IDP one cannot currently use a constant as a bound in a domai n enumeration, as in\nstudent = {1.. nbstudents }, where nbstudents is a constant symbol whose value is speciﬁed\nelsewhere. Another limitation that was already mentioned e arlier, is that domain values such\nas Bob and Alice (identiﬁers introduced at the right side of “symbol=value” equations), are not\npart of the vocabulary and cannot appear in theories.\nRecall that there exist also many interpreted symbols (e.g. , numerical operators and aggre-\ngates) whose values are ﬁxed and are implicit parts of all str uctures.\n1.4.1.3 Theory\nA theory component over some vocabulary is declared as “ theory ⟨theory name ⟩: ⟨vocname⟩{\n. . . }”. For the syntax of formulas and deﬁnitions, that of the form al base language is followed\n6 Autocompletion may derive missing type domains; e.g., in th e absence of a domain for age, autocompletion\nwill derive {19, 25, 30 } for it, in absence of a domain for person, it will derive the un ion of the student and\ninstructor domains.\n1.4 ¡toc-entry¿ 21\nas closely as possible. Formulas and rules are terminated wi th a “ . ” and rules are grouped\nin deﬁnitions which are put between “ deﬁne {” and “ }”. The following table provides a\ntranslation in a more keyboard friendly notation 7.\nFO(ID,A G G,PF,T) IDP language FO(ID,A G G,PF,T) IDP language\n∧ & ≥ >=\n∨ | = =\n⇒ => ̸= ∼=\n⇐ <= ← <−\n⇔ <=> #{x : ϕ } #{x1 ... xn : ϕ }\n¬ ∼ sum{(x,t ) : ϕ } sum{x1 ... xn : ϕ : t }\n∀ ! prod{(x,t ) : ϕ } prod{x1 ... xn : ϕ : t }\n∃ ? max{(x,t ) : ϕ } max{x1 ... xn : ϕ : t }\n≤ =< min{(x,t ) : ϕ } min{x1 ... xn : ϕ : t }\nBy way of example, we show a vocabulary, a structure and a theo ry for a small graph\nproblem that formalizes a connected graph over a set of nodes .\nv o c a b u l a r y V{\nt y p e Node\nF o r b i d d e n ( N o d e , Node )\nE d g e ( N o d e , Node )\nR e a c h a b l e ( N o d e )\nR o o t : Node\n}\ns t r u c t u r e S : V {\nNode = {A . . D }\nF o r b i d d e n = {A , A ; A , B ; A , C ; B , A ; B , B ; B , C ; C , C ; C , D ; D , D }\nR o o t = A\n}\nt h e o r y T : V {\n/ / i n d u c t i v e d e f i n i t i o n o f R e a c h a b l e\nd e f i n e {\nR e a c h a b l e ( R o o t ) .\n! x [ Node ] : R e a c h a b l e ( x ) <−\n? y [ Node ] : R e a c h a b l e ( y ) & E d g e ( y , x ) .\n}\n/ / T h e g r a p h i s f u l l y c o n n e c t e d\n! x [ Node ] : R e a c h a b l e ( x ) .\n7 The IDE at http://dtai.cs.kuleuven.be/krr/idp-ide/ visu alizes the symbols in the syntax of F O (ID , A G G,PF,T).\n22 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\n/ / No f o r b i d d e n e d g e s\n! x [ Node ] y [ Node ] : E d g e ( x , y ) = > ∼F o r b i d d e n ( x , y ) .\n}\nThe theory contains a deﬁnition 8 of the Reachable predicate and two formulas that constrain the\nsolution. All variables are typed with type Node; however, these types can be omitted since\ntype inference will derive them from the signatures of the symbols in which t he variables\noccur.9 Observe that this theory deﬁnes Reachable as the transitive closure of parameter Edge.\nThis deﬁnition is syntactically similar to a Prolog program , but unlike a Prolog program, it is\nhere the deﬁned predicate that is known (it is the set of all no des) and the parameter predicate\nthat is unknown. It illustrates the declarative understand ing of a deﬁnition that expresses a\nparticular logical relationship between the parameters an d the deﬁned symbols, and not a way\nto compute the deﬁned symbols in terms of the parameters.\n1.4.2 Procedure\nA procedure component is a chunk of Lua code [Ierusalimschy e t al. 1996] encapsulated in\nthe form of an IDP component (a keyword procedure, a name, a list of parameters and the\nchunk of code between “ {” and “ }”). When the IDP system is run, it calls the procedure main(\n). T ypically, one will use the IDP system to do some reasoning o n an FO(ID,A G G,PF,T)\ntheory. Here is a simple example:\np r o c e d u r e m a i n ( ) {\ns t d o p t i o n s . n b m o d e l s = 0\np r i n t m o d e l s ( m o d e l e x p a n d ( T , S ) )\n}\nThe ﬁrst line, stdoptions . nbmodels = 0 , conﬁgures the IDP system to compute all models\n(with a positive number n, inference is stopped after n models have been found; default value\nis 1). The second line calls IDP’s modelexpand procedure wit h as input arguments the theory\nT and the structure S and prints these models ( printmodels ). The modelexpand procedure calls\nupon the solver of the IDP system to search for models of T that expand the input structure\nS and returns an array of models. T o print a single model, one ca n select a model and print it,\ne.g. print(modelexpand(T , S) [3]) to print the third model. With the theory and structure as giv en\nin the small graph theory of the previous section, the above p rocedure prints 24 models, the\nﬁrst one being:\ns t r u c t u r e : V {\n8 The deﬁne keyword is optional; it emphasizes that the brackets {and }are delimiters of a deﬁnition.\n9 If within the same scope a variable appears in argument posit ions with different types, the inferred type is their least\nsupertype if it exists, otherwise a type error is raised, as e xplained in Section 1.2.6. If no type can be inferred, e.g., a s\nin !x : x=x , also then an error is raised.\n1.4 ¡toc-entry¿ 23\nNode = { ”A ” ; ”B ” ; ”C ” ; ”D” }\nE d g e = { ”A ” , ” D ” ; ”B ” , ” D ” ; ”C ” , ” A ” ; ”C ” , ” B ” ; ”D ” , ” A ” ; ”D ” , ” B ” ; ”D\n” , ” C” }\nF o r b i d d e n = { ”A ” , ” A ” ; ”A ” , ” B ” ; ”A ” , ” C ” ; ”B ” , ” A ” ; ”B ” , ” B ” ; ”B ” , ” C\n” ; ”C ” , ” C ” ; ”C ” , ” D ” ; ”D ” , ” D” }\nR e a c h a b l e = { ”A ” ; ”B ” ; ”C ” ; ”D” }\nR o o t = ”A”\n}\nNote that the model is written in the syntactic format of a str ucture component. The procedures\nmodelexpand and printmodels are only two out of many predeﬁned procedures in IDP. Many\nprocedures provide other forms of inference that can perfor m computational tasks using\nthe knowledge represented by an FO(ID,A G G,PF,T) theory. Other procedures serve to\nmanipulate and create new logical components, such as vocab ularies, structures and theories.\nW e refer to the online IDP W eb-IDE (http://dtai.cs.kuleuve n.be/krr/idp-ide/ ) and the IDP\nmanual (https://dtai.cs.kuleuven.be/krr/ﬁles/bib/man uals/idp3-manual.pdf ) for examples and\ndetails. The main design philosophy is that all components i n an IDP program are ﬁrst class\ncitizens. They can be used to perform various reasoning task s but can also be manipulated by\nLua code to construct different ones. So, it is possible to se t up a complete workﬂow .\nThis methodology in which ﬁne-grained declarative computa tion steps are mixed in pro-\ncedures is an exciting novel way of integrating declarative and procedural knowledge. This\nis illustrated by Bruynooghe et al. [Bruynooghe et al. 2015] . This is an application in stem-\nmatology, the study of the family relationships between dif ferent manuscripts (hand made\ncopies) of a text. It sketches a set of procedures that descri be the workﬂow to analyse a num-\nber of texts. For each text, a data set is read and analyzed and transformed into structures and\nvocabularies. These are then combined with the problem voca bulary and theory and, for each\nso called feature in the input data of a text, it is checked whe ther a model exists. Finally, for\neach data set, a summary report about all its features is repo rted.\n1.4.3 Term\nOne of the available forms of inference in IDP is to solve mini mization problems. This\ninference method takes as input a theory, a partial structur e, and a cost term, and outputs\none or more models of the theory expanding the partial struct ure such that the value of the\ncost term in these structures is minimal (among the set of all models more precise than the\npartial structure). The cost term is to be speciﬁed as a separ ate term component over the same\nvocabulary as the theory. T o illustrate, we return to our gra ph problem and introduce a term\nto count the number of edges in the solution.\nt e r m t : V {\n#{x y : E d g e ( x , y ) }\n}\n24 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\np r o c e d u r e m a i n ( ) {\ns t d o p t i o n s . n b m o d e l s = 0\nm o d e l s , o p t i m a l , c o s t = m i n i m i z e ( T , S , t )\np r i n t m o d e l s ( m o d e l s )\np r i n t ( o p t i m a l )\np r i n t ( c o s t )\n}\nThe main procedure now calls the minimization inference with the the ory T, the structure S and\nthe optimization term t as input. With T and S as above, the procedure returns three models,\nhowever, it also returns two other values: whether optimali ty has been proven and the value\nof the term in the optimal solution. The assignment models, optimal , cost =... assigns them to\ndifferent variables. The ﬁrst value is an array of models, wh ich can be printed with printmodels\n, the other two are simple values; they can be printed with the standard print command. In\nthis example, optimality is reached with a cost of 3.\n1.5 Advanced Features\n1.5.1 Constructed Types\nIn Prolog and ASP , functions and constants have a ﬁxed interp retation, their Herbrand inter-\npretation. Equivalently, we can think of them as logics with built-in unique names and domain\nclosure axioms (UNA and DCA), i.e., axioms stating that all those val ues are different and that\nthe domain consists of nothing more than those values, respe ctively. In FO(ID,A G G,PF,T),\nthe axioms are not present and interpretation of functions a nd constants is open as in standard\nFO. Both approaches have their merits, making it useful to in tegrate the advantages of both.\nIn ASP , there is work to incorporate open functions [Barthol omew and Lee 2012, Lifschitz\n2012]. In FO(ID,A G G,PF,T), one way to impose UNA and DCA is to explicitly specify a\nHerbrand interpretation. This method is illustrated below for the type of days of the week,\nusing the following declarations in the vocabulary:\nT y p e Day\nmonday : Day\nt u e s d a y : Day\n. . .\nand in the structure\nDay = { ’ ’ monday ’ ’ ; ’ ’ t u e s d a y ’ ’ ; . . . }\nmonday = ’ ’ monday ’ ’\nt u e s d a y = ’ ’ t u e s d a y ’ ’\n. . .\n1.5 Advanced Features 25\nThere is a way to avoid this cumbersome approach. The followi ng constructed type declaration\nin the vocabulary expresses the same information but in a com pact way:\nt y p e Day c o n s t r u c t e d from {monday , t u e s d a y , w e d n e s d a y , t h u r s d a y ,\nf r i d a y }\nThis statement declares several things at once: it declares the type Day and seven constants\nof this type, it speciﬁes the values for this type and for all i ts constants in every structure of\nthe vocabulary. Each constant is interpreted by itself. Her e, constants and domain elements\ncoincide.\nAlso non-constant constructor symbols are supported this w ay. For example, having types\nrow and column, one can introduce the constructed type of positions on a che ssboard by\ndeclaring “ type position constructed from pos(row,col ) ”, and use it in the deﬁnition of a unary\npredicate queen(position ) representing the positions where a queen stands. In theory, this\napproach also works for recursive constructors and types su ch as list of integers: type list\nconstructed from {nil ; cons[ int , list ] }. However, this creates an inﬁnite type and the current\nIDP solver cannot cope with such types.\n1.5.2 Structuring Components\nAll components, vocabularies, theories, structures, term s, and procedures, as we have shown\nso far, are part of the implicit global namespace idpglobal . This namespace also contains\nall Lua procedures that are available to the user of the syste m. When working on large\nprojects, different people may work on different parts, eac h introducing its own components.\nT o integrate such different parts, the IDP system provides namespaces. A namespace with\nname MySpace is declared by\nn a m e s p a c e MyS pace {\n/ / c o n t e n t o f t h e n a m e s p a c e\n}\nA namespace can contain other namespaces, and any sort of IDP component including\nvocabularies, theories, structures, terms, and procedure s. Each component has a full name that\nis determined by the hierarchy of namespaces it belongs to. T his allows users to disambiguate\ncomponents with the same name but belonging to different nam espaces. W e refer to the\nmanual for details.\nAnother useful structuring method is to compose a vocabular y from existing ones. For\ninstance, in the following example W is composed of the symbols of V and one function\ncoloring /1:1 from vocabulary U:10\nv o c a b u l a r y W {\n10 Here, the notation coloring /1:1 means that coloring has arity one ( /1 ) and is a function, i.e., has one output\nargument ( :1 ).\n26 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\ne x t e r n v o c a b u l a r y V\ne x t e r n U : : c o l o r i n g / 1 : 1\n}\nSuch an extension construct is not available for structures and theories but it could be\nsimulated for them by making use of certain Lua procedures. F or this we refer to the list\nof Lua procedures described in the manual.\nW orth mentioning is that there is a factlist component to initialize a two valued structure\nwith Prolog or ASP facts. Also, it is possible to call upon Lua procedures to initialize a\nstructure.\n1.5.3 An Output V ocabulary\nIn many problems we are interested only in the values of some s ubset of symbols. In\ncase multiple solutions are searched, we are interested onl y in models having different\ninterpretations of the output symbols. This is achieved by d eclaring an output vocabulary,\nsay V out, and adding it as an extra parameter to the modelexpand call:\np r o c e d u r e m a i n ( ) {\np r i n t ( m o d e l e x p a n d ( T , S , V o u t ) [ 1 ] )\n}\n1.5.4 Inference Methods\nSo far we have mentioned model expansion inference, invoked as modelexpand(T,S) (or\nmodelexpand(T,S,V out) if there is an output vocabulary) and optimization inference, invoked\nas minimize(T,S, t ) (or minimize(T,S, t , V out) ). The system supports several other inference\nmethods. W e discuss the most important ones. For a complete l ist, we refer to the manual.\nQuery inference takes as input a query component that declares a set expression of the\nform {x |ϕ }and a two-valued structure I and returns the set {x |ϕ }I . In the IDP language,\nthis inference is invoked as query(Q,S), where Q is a query and S a structure. Continuing our\ngraph example,\nq u e r y Q : V {\n{x : ( ? y : E d g e ( x , y ) ) }\n}\np r o c e d u r e m a i n ( ) {\nm o d e l s = m o d e l e x p a n d ( T , S )\np r i n t ( q u e r y ( Q , m o d e l s [ 1 ] ) )\n}\nwill print the set of all nodes that participate as the ﬁrst no de of an edge in the ﬁrst model\ncomputed by the model expansion. Note that query( ...) does not return a structure but a set.\n1.5 Advanced Features 27\nModel checking and satisﬁability checking are special cases of model expansion. In\nthe former, the input structure is two-valued; the result of this inference is true respectively\nfalse if the input structure is a model of the theory. The latter als o outputs a Boolean value,\ntrue if the (possibly three-valued) output structure can be expanded to a model. In the IDP\nlanguage, both of these inference methods are called using sat(T , S) , where T is a theory and\nS a structure. 11\nPropagation inference takes a theory and a structure and returns a more pr ecise structure\nthat preserves all solutions. The system supports differen t versions of propagation with\ndifferent costs. The most precise and most expensive versio n returns the partial structure in\nwhich atoms are unknown iff they do not have the same truth val ue in all models. This most\nexpensive propagation is called using optimalpropagate(T , S) . Cheaper, approximate forms of\npropagation are called using propagate(T , S) and groundpropagate(T , S).\nDeduction takes as input an FO(ID,A G G,PF,T) theory T and an FO theory TF O and\nreturns true if T |= TF O , that is if the ﬁrst theory logically entails the second one. It is\nimplemented in a sound but incomplete way by translating T into a (weaker) FO theory and\ncalling the theorem prover SP ASS [W eidenbach et al. 2009]. I t is used internally in the IDP\nsystem to detect and exploit functional dependencies in pre dicates [De Cat and Bruynooghe\n2013]. It is called using entails(T1 , T2) .\nSymmetry detection takes as input a theory T and a partial structure I and returns\nsymmetries over T and I . A symmetry is a function, say f , mapping structures to structures,\nsuch that, for any two-valued expansion J of I that is a model of T , f (J) is also a model\n[Devriendt et al. 2012]. Symmetry detection also returns cl auses to break these symmetries\nand to eliminate symmetric models. Symmetry detection is no t available as a Lua procedure\nbut can be exploited in the model expansion workﬂow using the option symmetrybreaking (see\nSection 1.6).\n∆ -model expansion takes as input a deﬁnition ∆ and a structure Iin , interpreting all\nparameters of ∆ , and returns the unique model I that expands Iin . This task is an instance\nof model expansion, but is solved in IDP using different tech nology. The close relationship\nbetween deﬁnitions and logic programs under the well-found ed semantics is exploited to\ntranslate ∆ and Iin into a tabled Prolog program, after which XSB is used to compu te I .\nT aking an extra formula ϕ as input, with free variables x, the same approach is used to solve\nthe query ϕ with respect to ∆ and Iin in a goal-oriented way [Jansen et al. 2013]. There is\nno dedicated Lua procedure for calling ∆ -model expansion. However, as described in Section\n1.6, it is automatically detected that ∆ -model expansion can be performed in normal model\nexpansion calls.\nUnsat-core extraction takes as input a theory T and a structure I such that T has\nno models expanding I . It returns a (minimal) theory Tout entailed by T (obtained by\n11 Note that satisﬁability checking reduces to model checking in case S is two-valued.\n28 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\ninstantiating some variables) such that Tout still has no models expanding I . Currently there is\nonly support for printing the output theory, not for actuall y obtaining it; this procedures also\nprints from which line every sentence in Tout was instantiated. This inference is particularly\nuseful when debugging logical speciﬁcation and can be calle d using printunsatcore(T , S) .\nFinally, there is support for the linear time calculus (L TC) deﬁned by Bogaerts et\nal. [Bogaerts et al. 2014a]. One can build an L TCvocabularycomponent as a vocabulary extend-\ning a default L TC vocabulary and can use special inference me thods to initialize the state and\nto perform progression inference, i.e., to infer the succes sor states step by step [Bogaerts et al.\n2014a].\n1.6 Under the Hood\nIn this section we focus on the inner working of some componen ts of the IDP system. First,\nwe discuss the workﬂow of the optimization inference and how users can control the various\nparts of the optimization engine. Afterwards we discuss tec hniques (under development) that\nhelp IDP scale to larger, possibly inﬁnite, domains.\nOptimization is the task of given a theory T , a structure I , and a term t , all over the same\nvocabulary V , ﬁnding models of T that expand (are more precise than) I . This inference cap-\ntures Herbrand model generation and (bounded) model expans ion, both of which were pro-\nposed as logic-based methods for constraint solving, respe ctively in [East and Truszczy ´ nski\n2006] and [Mitchell and T ernovska 2005]. In its most general form, we deﬁne optimization\nfor typed FO(ID,A G G,PF) as follows. The inference OPT ⟨V,T ,I ,t ,Vout ⟩takes as input a\ntheory T , structure I and term t , all over vocabulary V , and a vocabulary Vout ⊆V . Both T\nand I are well-typed and I interprets all types. The inference returns Vout -structures J such\nthat at least one model of T expanding both I and J exists and that expansion is minimal with\nrespect to t . The optimization inference is a generalization of the mode l expansion inference\nthat takes the same arguments without the optimization term t and that returns Vout -structures\nJ such that at least one model of T expanding both I and J exists. The workﬂow of these two\ninference methods coincides; for optimization, more searc h is needed to ﬁnd optimal models.\nOne approach to optimization, used in IDP, is through ground-and-solve: ground the input\ntheory and term over the input structure and afterwards appl y a search algorithm that, e.g.,\nuses branch-and-bound to ﬁnd optimal models.\nIn the rest of the section, we present how the optimization al gorithm in IDP solves\nan OPT ⟨V,T ,I ,t ,Vout ⟩task. The workﬂow consists of an FO(ID,A G G,PF,T) grounding\nalgorithm, a search algorithm for the full ground fragment o f FO(ID,A G G,PF,T) and various\nanalysis methods and transformations, that result in a smal ler grounding and/or improved\nsearch performance.\nThe workﬂow of the optimization inference consists of three parts. First, theory and\nstructure are preprocessed to optimize performance. Secon dly, the theory is grounded into\n1.6 Under the Hood 29\nECNF , the language supported by M IN I SA T(ID). Last, the solver M IN I SA T(ID) is called to\nperform the actual inference on the ground theory.\n1.6.1 Preprocessing\nSeveral preprocessing steps are performed before the groun ding phase. W e brieﬂy discuss\nthem below .\n1.6.1.1 Checking structure consistency\nFirst, we specify the structure I that is parsed from a structure component, in particular, ho w\nthe type autocompletion works. The following deﬁnitions fo rmalize this. The value of all other\nsymbols is clear.\nW e say that a type t of a vocabulary V is explicitly deﬁned in structure I if I contains an\nequation t = S. W e deﬁne the value of an explicitly deﬁned type in I as stated in its explicit\ndeﬁnition. For a type t that is not explicitly deﬁned, the interpretation of t in I consists of all\nelements of its subtypes and domain elements that occur in th e interpretation of symbols σ at\nan argument position of type t . Formally:\nt I =\n\n ⋃\n{s|s is a subtype of t }\nsI\n\n⋃\n\n ⋃\n{σ ∈V |the i’th type of σ is t }\n{di |\nd ∈σ I }\n\n.\nA number of constraints are imposed on structures:\n•For any subtype s of t , the interpretation of s must be a subset of the interpretation of t :\n∀x : s(x) ⇒t (x)\n•If f is a partial or total function that is totally deﬁned, there i s at most one image for each\nvalue of the input:\n∀\nx,y,z : f (x) =y ∧f (x) =z ⇒y = z\n•If f is a totally deﬁned total function, the structure must conta in an image for each input\nargument:\n∀x : ∃y : f (x) =y.\n•A partially deﬁned predicate cannot be both certainly true a nd certainly false for the same\ntuple:\n∀x : ¬P⟨ct⟩(x) ∨¬P⟨c f ⟩(x)\n•For any partially deﬁned function f ,\n30 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nthere is at most one certainly true image for every input:\n∀x,y,z : f ⟨ct⟩(x,y) ∧f ⟨ct⟩(x,z) ⇒y = z\nif f is a total function, at least one output is possible (not cert ainly false) for each\ninput:\n∀x : ∃y : ¬f ⟨c f ⟩(x,y)\nWhen any of these constraints are violated in the autocomple ted structure I , an appropriate\nerror message is given.\n1.6.1.2 Exploiting input ∗-deﬁnitions\n[Jansen et al. 2013].\nAssume that after preprocessing, we obtained a theory T and a structure I1 = I . The next\nstep is to eliminate some deﬁnitions of T and extend I1 . The deﬁnitions that can be eliminated\nare the so called input∗-deﬁnitions of T [Jansen et al. 2013].\nW e deﬁne inductively that a deﬁnition ∆ of T is an input ∗-deﬁnition of T in structure I if\nall parameters of ∆ have a 2-valued interpretation in I or are deﬁned in input ∗-deﬁnitions of\nT in I .\nAll input ∗-deﬁnitions of T can be evaluated in advance. Essentially this is done by iter ated\n∆ -model expansion steps: at each iteration an input ∗-deﬁnition ∆ is selected that has all\nits parameters interpreted in the current structure; we com pute12 its model in I1 and add\nthe interpretation of the deﬁned symbols to I1 . The advantage of this is that as explained\nbelow , top-down grounding techniques, as used in IDP, tend t o be rather inefﬁcient in case\nof complex (inductive) deﬁnitions [Wittocx 2010]. By evalu ating these deﬁnitions, we avoid\ngrounding them and we make the input structure more precise.\nNotice that this may result in inconsistency if the same pred icate is deﬁned in multiple\ninput∗-deﬁnitions that do not agree on its value. Otherwise, the re sult is a theory T2 and a\nreﬁned structure I2 .\nT o exploit the above procedure for a maximal effect, it is ext ended with a preprocessing\nstep to split each deﬁnition ∆ of T in subdeﬁnitions ∆ 1 ,...,∆ n . The advantage is that some of\nthese components may turn out to be input ∗-deﬁnitions whereas ∆ is not. In this case we can\nevaluate part of ∆ .\nThe split of a deﬁnition is computed from its dependency rela tion. Formally, the depen-\ndency relation ≤of a deﬁnition ∆ is the least transitive relation containing all pairs P ≤Q\nsuch that deﬁned symbol P occurs in a rule deﬁning Q. W e say that P ∼Q if P ≤Q ≤P.\nThis is an equivalence relation. The split of ∆ is the partition ∆ 1 ,... ,∆ n of ∆ such that each ∆ i\n12 This is done by translating it to a logic program and using X S B .\n1.6 Under the Hood 31\ndeﬁnes an equivalence class of ∼. The idea is that each ∆ i deﬁnes a group of predicates that\ndepend on each other.\n1.6.1.3 Delaying output ∗-deﬁnitions\n[Bogaerts et al. 2014b, Jansen et al. 2013] Consider a total d eﬁnition ∆ ∈T2 such that the\ndeﬁned symbols of ∆ occur only in ∆ and are not interpreted in I2 . Any structure that satisﬁes\nT2 \\{∆ }and does not interpret symbols deﬁned in ∆ , can be extended to a model of T2 by\nevaluating ∆ . Consequently, there is no need to consider such a ∆ during search; we prefer to\ndelay evaluation of ∆ as long as possible, to a postprocessing step.\nSuch a ∆ is one example of an output ∗-deﬁnition [Bogaerts et al. 2014b, Jansen et al.\n2013]. In general, we deﬁne inductively that a deﬁnition ∆ of T is an output∗-deﬁnition of\nT in structure I if all deﬁned symbols of ∆ only occur in ∆ and in the bodies of rules of\noutput∗-deﬁnitions.\nThese output ∗-deﬁnitions do not have to be considered during search and ca n be evaluated\nafterwards in a post-processing step. Theory T3 is the theory obtained from T2 by removing\nall output ∗-deﬁnitions; this phase does not modify the structure, henc e I3 = I2 .\n1.6.1.4 Reducing quantiﬁcation depth using functional dep endencies\n[De Cat and Bruynooghe 2013]. The size of the grounding is in g eneral exponential in the\nnesting depth of quantiﬁers (as it involves the Cartesian pr oduct of the involved domain\nsizes). One way to reduce the quantiﬁcation depth, is to dete ct that symbols can be split into a\nnumber of symbols with a smaller arity. Assume, for example, that a predicate timeOf(session\n, time ) speciﬁes at which time a certain session takes place in a sche duling application. If\none could detect that the second argument functionally depends on the ﬁrst argument (the\nﬁrst uniquely determines the value of the second), then it co uld be replaced by a new\nfunction timeFunc(session ) : time instead. With appropriate transformations, a subformula ? t\n: timeOf(s1 , t ) & timeOf(s2, t ) can then be reduced to timeFunc(s1)=timeFunc(s2) , eliminating\nthe quantiﬁcation over t . Detection of functional dependencies is done using the ded uction\ninference: we check whether an FO formula that expresses the dependency is entailed by the\noriginal theory. For timeOf, the functional dependency holds if the theory entails the s entence\n∀s : ∃=1t : timeOf (s,t ).\nThis preprocessing phase takes as input the theory T3 and structure I3 and returns T4 and\nI4 , in which entailed functional dependencies have been made e xplicit and quantiﬁcations\nhave been dropped where possible.\nHowever, as the user expects models in the original vocabula ry, additional output ∗-\ndeﬁnitions are added to T4, that deﬁne the original symbol in terms of the newly introdu ced\nones. In our example, this would be the deﬁnition\nd e f i n e {\n! s t : t i m e O f ( s , t ) <− t = t i m e F u n c ( s ) .\n32 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\n}\n1.6.1.5 Exploiting symmetries\n[Devriendt et al. 2012, 2016b]. It is well-known that if a pro blem exhibits symmetries, they\ncan cause a search algorithm to solve the same (sub)problem o ver and over again. For example\nthe “pigeonhole” problem “do n pigeons ﬁt in n −1 holes?” is known to be hard for SA T -\nsolvers. Symmetries can be detected and broken on the propos itional level [Aloul et al. 2006,\nDevriendt et al. 2016b], but for large problems, even the tas k of detecting symmetries becomes\ninfeasible. Detecting symmetries on the ﬁrst-order theory [Devriendt et al. 2016a] is often an\neasier problem, as much more structure of the problem is expl icitly available. For example for\nan FO speciﬁcation of the pigeonhole problem, it is almost tr ivial to detect that all pigeons\nare interchangeable. The symmetry detection inference in I DP detects a simple, frequently\noccurring form of symmetries: locally interchangeable dom ain elements (see [Devriendt et al.\n2016a]). T wo domain elements are considered interchangeab le if they are of the same type\nand occur only symmetrically in interpreted predicates. De tected symmetries are handled by\nadding sentences to T4 that statically break those symmetries, resulting in the th eory T5 .\n1.6.2 Ground-And-Solve\n1.6.2.1 Ground\n[De Cat et al. 2013]. The grounding algorithm visits the resu lting theory ( T5) in a depth-\nﬁrst, top-down fashion, basically replacing all variables by all their matching instantiations,\naccording to the interpretation of their types in a partial s tructure I5 . For example, a formula\n∀x[t ] : ψ (x) is replaced by ⋀\nd∈t I5 ψ (d).\nHowever, such an instantiation might be unnecessary large. Indeed, if the value of a term\nor formula is known in the current structure I5 for a given instantiation of its free variables, it\nshould not have been grounded in the ﬁrst place. The solution is to reuse query inference. For\nexample, consider a formula ∀x[T ] : ϕ and an instantiation d for the free variables y of this\nformula. In that case, x need only be instantiated with tuples d\n′\nfor which ϕ [y/d,x/d\n′\n] is not\ncertainly true in I5 . Finding such tuples can be done using the query inference on a derived\nstructure over a vocabulary in which <ct> and <cf> tables have an explicit representation.\nFor all instantiations of x not in the result of that query, we are certain that the subfor mula\nis true anyway. In fact, an incomplete (cheaper) query infer ence can be applied, as any over-\napproximation will result in additional grounding, still m aintaining correctness. The result is\na ground FO(ID,A G G,PF,T) theory. Several optimizations for this step exist, a s discussed in\n[Jansen et al. 2014]; below we discuss some of them.\n1.6 Under the Hood 33\n1.6.2.2 Simpliﬁcation\nT o ensure models are generated that expand the input structu re, not only the ground theory,\nbut also the structure I5 is passed to the search algorithm. Since we use a top-down gro unding\nalgorithm, we can optimize over this: whenever a domain atom or term is generated by\ninstantiating variables, instead of using the atom or term i tself, its interpretation is ﬁlled in\nin the grounding. For example, if a formula ∀x[t ] : P(x) ∨Q(x) is grounded in a structure with\ninterpretations\nT = { 1 ; 2 ; 3 }\nP<c t > = {1}\nQ<c f > = {3}\na simpliﬁed grounding is\n(t ∨Q(1)) ∧(P(2) ∨Q(2)) ∧(P(3) ∨f).\nThis sentence can be simpliﬁed even more, by propagating der ived truth values upwards,\nresulting in\nt ∧(P(2) ∨Q(2)) ∧P(3)\nand ﬁnally\n(P(2) ∨Q(2)) ∧P(3).\nThese simpliﬁcation techniques can have as effect that larg e parts of the theory do not need\nto be grounded. For example, consider a sentence ∀x[t ] : P(x)∨ϕ (x), where ϕ might be a large\nformula. For all instantiations d of x for which P(d) holds, the formula P(d)∨ϕ (d) simpliﬁes\nto t. Hence ϕ (d) does not need to be grounded for such d.\n1.6.2.3 Approximation and lifted unit propagation\n[Wittocx et al. 2010, 2013].\nThe above grounding algorithm exploits information in the i nput structure I using the\nquery inference. Essentially, it grounds only the instance s ϕ [d] of formulas that are un-\nknown in I . As a consequence, more precise input structures I yield smaller groundings\nand increased search performance. This observation gave ri se to the algorithms presented\nin [Wittocx et al. 2010], where instead of using structure I5 directly, we ﬁrst compute a more\nprecise structure I6 that approximates all models of T5 that expand I5 . Ideally, we would like\nto compute the most precise structure that is less precise than all models of T5 that expand I5 .\nOf course, ﬁnding this ideal structure is a task that is even h arder than the original problem.\nInstead of searching for this ideal structure, IDP’s approa ch is to execute a lifted (approxi-\nmative) version of the unit propagation that would occur aft er grounding. The result is stored\nas a symbolic representation of a structure. Namely, with ea ch symbol P, we associate two\n34 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nsymbolic set expressions Sct and Sc f with intended meaning that in structure I6 , Pct , respec-\ntively Pc f , is interpreted as SI5\nct , respectively SI5\nc f . Consider, for example, the following theory\n∀x : P(x) ⇒Q(x).\n∀x : ¬Q(x) ⇒R(x).\nSymbolic unit propagation then results in, e.g., a symbolic representation of I6 that interprets\nQct as {x |Pct (x) ∨Rc f (x)}(the latter interpreted in I5 !), Rct as {x |Qc f (x)}. During the\ngrounding phase, all queries for variable instantiations a nd the interpretation of atoms and\nterms are evaluated relative to this symbolic interpretati on, resulting in fewer instantiations\nand more precise interpretations. E.g., if P is interpreted in I5 , and Q and R are completely\nunknown in I5 , then the second sentence will only be instantiated for x’s such that that P(x) is\nnot true in I5 .\nA symbolic representation of complete lifted unit presenta tion often consists of complex\nformulas, which are infeasible to query. However, any appro ximation of those formulas\nis sufﬁcient, as long as the resulting structure is at least a s precise as I5 . Consequently,\nthe formulas are simpliﬁed to balance the estimated cost of q uerying against the expected\nreduction in number of answers.\n1.6.2.4 Search\nOptimization in IDP relies on the search algorithm M IN I SA T(ID) [De Cat et al. 2013]\nfor ground FO(ID,A G G,PF,T) theories. It takes the ground theory as input togethe r with\nstructure I5 . The algorithm combines techniques from SA T , Constraint Pr ogramming (CP) and\nAnswer Set Programming (ASP) through a DPLL(T) architectur e [Ganzinger et al. 2004]. At\nthe core lies the SA T -solver M IN I SA T [E ´ en and S ¨ orensson 2003], a complete, Boolean search\nalgorithm for propositional clauses. This core is compleme nted by a range of “propagator”\nmodules that take care of propagation for all other types of c onstraints in the theory, such\nas aggregates, deﬁnitions and atoms containing functions. Each module is responsible for\nexplaining its propagations in terms of the current assignm ent. For a deﬁnition ∆ , for example,\nthe module checks whether the current assignment satisﬁes ∆ ’s completion, whether the\ncurrent assignment contains unfounded sets, and when a comp lete assignment is found,\nwhether the structure is the well-founded model of ∆ . Optimization is taken care of by a\nmodule that ensures the search space is visited in a branch-a nd-bound fashion. Whenever a\nmodel M is found, with value v the interpretation of c in M, a constraint c < v is added to the\nground theory (which raises a conﬂict, leading to backtrack ing and additional search).\nOn the importance of CP integration [De Cat et al. 2013, 2014] In contrast to previous ver-\nsions, the current version of M IN I SA T(ID) supports ground FO(ID,A G G,PF,T) with func-\ntion symbols . Function symbols are handled using techniques from constr aint programming\n1.6 Under the Hood 35\n[Feydy and Stuckey 2009]. T o illustrate the importance of ha ving uninterpreted function sym-\nbols, consider the following birthday riddle.\nExample 1.6.1. “T o determine my age, it sufﬁces to know that my age in 2013 is h alfway\nbetween two consecutive primes, that my age’s prime factors do not sum to a prime number,\nand that I was born in a prime year. ”. In the IDP language, it ca n be modeled as:\nv o c a b u l a r y V {\nt y p e Nb i s a n a t\nAge : Nb / / u n i n t e r p r e t e d c o n s t a n t : my a g e\nP r i m e ( N b ) / / p r e d i c a t e c o n t a i n i n g a l l p r i m e n u m b e r s\nY e a r O f B i r t h : Nb / / u n i n t e r p r e t e d c o n s t a n t : my y e a r o f b i r t h\n}\nt h e o r y T : V {\n/ / D e f i n i t i o n o f p r i m e n u m b e r s\nd e f i n e {\n! x [ Nb ] : P r i m e ( x ) <−\nx>1 &\n! y [ Nb ] : 1 < y < x = > ( x % y ∼= 0 ) .\n}\n/ / R e l a t i o n b e t w e e n a g e ( i n 2 0 1 3 ) a n d y e a r o f b i r t h\nAge = 2 0 1 3 − Y e a r O f B i r t h .\n/ / M y a g e i n 2 0 1 3 i s h a l f w a y b e t w e e n t w o c o n s e c u t i v e p r i m e s\n? x 1 x 2 :\n/ / x 1 a n d x 2 a r e p r i m e\nP r i m e ( x 1 ) & P r i m e ( x 2 ) &\n/ / t h e y a r e c o n s e c u t i v e\n∼( ? y : P r i m e ( y ) & x 1 < y < x 2 ) & x 1 < x 2 &\n/ / my a g e i s h a l f w a y b e t w e e n t h e m\nAge = ( x 2 + x 1 ) / 2 .\n/ / I w a s b o r n i n a p r i m e y e a r\nP r i m e ( Y e a r O f B i r t h ) .\n/ / my a g e ’ s p r i m e f a c t o r s d o n o t sum t o a p r i m e n u m b e r\n∼P r i m e ( s u m {x : P r i m e ( x ) & 1 < x = < Age & Age % x = 0 : x }) .\n}\ns t r u c t u r e S : V {\nNb = { 0 . . 2 0 1 3 }\n}\n36 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nIDP is unable to ground this theory without using uninterpre ted function symbols (this is\ncontrolled through the option cpsupport, discussed below) due to memory exhaustion. With\nuninterpreted constants, IDP takes half a second to ﬁnd a sol ution. In fact, IDP proves that\n48 different solutions exist; however only one is an age belo w 100, namely Age = 26.\n1.6.3 Post-Processing\nAs a ﬁnal, post-processing step, structures returned by the search step are translated back\nto structures over V . Next, they are merged with I , output ∗-deﬁnitions are evaluated over\nthem and ﬁnally, they are projected to Vout , resulting in structures Iout that are solutions to the\noriginal OPT ⟨V,T ,I ,t ,Vout ⟩problem.\nAn output ∗-deﬁnition is only evaluated if evaluating it will have an ef fect on the eventual\nVout -structure. If symmetry-breaking was applied, additional solutions can be generated by\napplying the symmetries to the solutions found.\n1.6.4 Controlling the optimization workﬂow\nV arious components of the optimization workﬂow can be contr olled using options. W e provide\na brief overview .\nstdoptions.assumeconsistentinput default:false\nIf this option is true, the systems assumes that the input pro vided by the user is consistent\nand the consistency checks are skipped. Use at your own risk.\nstdoptions.xsb default:true\nIf this option is true, input ∗-deﬁnitions are evaluated using the XSB Prolog system. Oth-\nerwise, they are evaluated using standard ground-and-solv e techniques. W e recommend\nto use XSB for efﬁciency reasons.\nstdoptions.postprocessdefs default:true\nThis option controls whether output ∗-deﬁnitions are delayed until after search. In\ngeneral, we recommend to turn this option on. However, since detection of output ∗-\ndeﬁnitions is implemented through a bootstrapping approac h, enabling might cause a\nsmall delay of up to a second. Hence, if your goal is to solve a l arge number of very\nsmall problems, we recommend to turn this off.\nstdoptions.splitdefs default:true\nThis option controls whether deﬁnitions are split into mini mal strata. As with the\nprevious, we recommend to turn it on in most cases, unless whe n solving very small\nproblems.\nstdoptions.symmetrybreaking default:“none”\nThis option controls whether symmetries are broken and if th ey are broken, using which\nmethod. Currently, IDP only provides support for breaking s ymmetries statically, hence\n1.6 Under the Hood 37\nthis option can be set either to ‘‘ none ’’ or to ‘‘ static ’’ . Future versions of IDP might also\noffer the choice ‘‘ dynamic’’ . Whether symmetry breaking is beneﬁcial strongly depends\non the problem at hand.\nstdoptions.reducedgrounding default:true\nThis option controls whether the grounding is simpliﬁed usi ng information from the\nstructure. W e recommend to enable this option in most use cas es.\nstdoptions.groundwithbounds default:true\nThis option controls whether the grounding size is reduced u sing the approximation\ntechniques described above. W e recommend enabling this opt ion in most use cases.\nstdoptions.liftedunitpropagation default:true\nThis option controls whether the symbolic representation o f the input structure ( I6 ) is\nevaluated in advance, resulting in a concrete representati on of the input structure. W e\nrecommend enabling this option in most use cases.\nstdoptions.cpsupport default:true\nThis option controls whether function symbols are allowed i n the grounding. If turned\noff, the ground theory will be entirely propositional, if tu rned on, functions symbols\ncan appear in the ground theory; they are then handled by cons traint programming\ntechniques. W e recommend enabling this option in most use ca ses, except for hard\ncombinatorial problems with a very small grounding.\nstdoptions.cpgroundatoms default:false\nThis option controls whether function symbols are allowed t o occur nested in the\ngrounding. This is an advanced feature, with as advantage a s maller grounding, but as\ndisadvantage possible loss of propagation. Whether enabli ng this option is beneﬁcial\nstrongly depends on the problem at hand.\nstdoptions.functiondetection default:false\nThis option controls whether predicate symbols are automat ically replaced by function\nsymbols. Whether enabling this option is beneﬁcial depends strongly on the problem at\nhand. For theories crafted by experts (and manually optimis ed), this options is probably\nnot beneﬁcial. The more naive the theory is, the more potenti al beneﬁt this option has. If\nthis option is enabled, we recommend to also enable the cpsup port option.\nstdoptions.nbmodels default:1\nThis option speciﬁes the number of models that need to be retu rned by the optimization\n(or model expansion) inference.\nstdoptions.verbosity default:0 (for all suboptions)\nSuboptions of this option control the verbosity of various c omponents in the workﬂow .\n38 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nThis is used mainly for debugging purposes, e.g., to know whi ch part of the solver is\ncausing certain delays.\n1.6.5 Scalability and Inﬁnity\nThe reader might have noticed that structures and grounding s can be very large or even inﬁnite\n(for example, when a predicate or a quantiﬁed variable is typ ed over int ). Model expansion\n(and thus, optimization) over inﬁnite structures takes inﬁ nite time in general. In IDP, several\ntechniques are applied to address this issue; they often wor k well in practice.\nA ﬁrst such technique has been explained in Subsection 1.6.2 . By intelligent reasoning\nover the entire theory, we can sometimes derive better varia ble bounds. Suppose for example\nthat a theory contains formulas ∀x[int] : P(x) ⇒Q(x) and ∀y[int] : P(y) ⇒R(y), where Q\nonly ranges over a ﬁnite type, say T , but P and R range over int. The ﬁrst of these sentences\nguarantees that P will only hold for values such that Q holds, hence P can only hold for values\nin the ﬁnite type T . Thus we know that the second sentence should only be instant iated for y’s\nin T , i.e., by deriving an improved bound for y, the grounding of the second sentence suddenly\nbecomes ﬁnite. The ﬁrst sentence can be handled similarly. W e only ground this sentence for\ny’s in T and maintain a symbolic interpretation expressing that P is certainly false outside of\nT .\nSecond, the usage of a top-down, depth-ﬁrst grounding algor ithm has the advantage that\ninterpretations can be evaluated lazily: (i) instantiations of quantiﬁcations can be generated\none at a time, and (ii) the interpretation of atoms and terms n eeds only to be retrieved for\natoms and terms that effectively occur in the grounding. The same advantage applies for\nsymbols that are interpreted by (complex) procedures: the p rocedures are only executed for\nrelevant occurrences of that symbol.\nThird, the search algorithm maintains bounds on the interpr etation of function terms, taking\nconstraints in the grounding into account. Consider a const ant c : int, which in itself would\nresult in an inﬁnite search space. However, combined with, e .g., a constraint 0 ≤c ≤10 in the\ngrounding, the solver reduces c : int to c : [0,10], a ﬁnite search space.\nA fourth technique currently under development to increase scalability is Lazy Grounding\n[De Cat et al. 2015]. Lazy Grounding is based on the observati on that the entire grounding\noften is not necessary to ﬁnd solutions to a model expansion o r optimisation problem. Instead,\nthe technique interleaves grounding with search as follows . Initially, it (roughly) splits the\ninput theory into two parts: one part is grounded and the unde rlying solver performs its\nstandard search algorithm on it. The other part of the theory is delayed: the system makes\nassumptions about it that guarantee that models found by the solver can be extended to\nmodels of the entire theory. Whenever these assumptions bec ome violated, i.e., when they\nare inconsistent with the solver’s current assignment, the splitting of the theory is revised.\nConsider for example ∀x[int] : P(x) ⇒ϕ with ϕ a possibly large formula; it has an inﬁnite\ngrounding. A smart lazy grounder could delay the grounding o f that sentence with the\n1.7 In Practice 39\nassumption that P is false for all integers. During search, only when an atom P(d) becomes\ntrue, is the sentence grounded for x = d and only that ground sentence is added to the\nsearch, the remainder still delayed on the assumption that P is false. Whenever the search\nalgorithm ﬁnds a structure that satisﬁes the grounding and d oes not violate any assumptions,\nthat structure can be straightforwardly extended to a model of the whole theory.\n1.7 In Practice\nBoth IDP and its search algorithm M IN I SA T(ID) are open-source systems, freely available\nfrom dtai.cs.kuleuven.be/krr/software . Next to acceptin g input in the IDP language, both\nsystems provide C++ interfaces. The search algorithm M IN I SA T(ID) supports input in\nClausal Normal Form (CNF), Quantiﬁed Boolean Form (QBF , CNF ’s higher-order relative)\n[Egly et al. 2000], ground ASP (in the LParse-Smodels interm ediate format [Syrj¨ anen 1998])\nand FlatZinc [Nethercote et al. 2007].\nIDP can be be tried online in our web-IDE at https://dtai.cs. kuleuven.be/krr/idp-ide/ . Sev-\neral modelling examples are available in the web-IDE as well as at https://dtai.cs.kuleuven.be/software/idp/exampl es .\nThe web-IDE also provides support for the visualisations of structures, as explained, e.g., in\nhttps://dtai.cs.kuleuven.be/krr/idp-ide/?chapter=in tro/9-IDPD3 .\nThe main usage of IDP3 is currently its model expansion infer ence, which as discussed\nearlier, is closely related to generating answer sets of log ic programs and to solving constraint\nsatisfaction problems. As such, it shares applications wit h those domains, general examples\nof which are scheduling, planning, veriﬁcation and conﬁgur ation problems. More concretely,\nsome applications have been modelled in [Bruynooghe et al. 2 015], demonstrating its appli-\ncability as both an approach to replace procedural programm ing in some cases and as an\napproach to rapid prototyping due to the short development t ime. It has been used to analyze\nsecurity issues in several contexts, with an emphasis on for mal approaches that allow intuitive\nmodelling of the involved knowledge [Decroix et al. 2013, He yman 2013]. The model expan-\nsion engine, and various other types of inference, have been used for interactive conﬁguration\n[V an Hertum et al. 2016, 2017].\nThe performance of IDP has been demonstrated for example in t he ASP competition\nseries, in 2009 [Denecker et al. 2009] (IDP 2 ), 2011 [Calimeri et al. 2014] (IDP 2 ) and\n2013 [Alviano et al. 2013] (IDP3) and in [Bruynooghe et al. 20 15], where it is compared\nto various existing approaches to speciﬁc problems. The per formance of the search algo-\nrithm M IN I SA T(ID) has been demonstrated in [Amadini et al. 2013a,b], w here it turned\nout to be the single-best solver in their MiniZinc portfolio , and in the latest Minizinc chal-\nlenges [MinizincChallenge2012]. In [Bruynooghe et al. 201 5], it is demonstrated that a KR\nsystem like IDP can be practically used as a front-end for low er-level solvers (e.g., SA T -\nsolvers), instead of manually encoding problems in SA T or us ing custom scripting. Experi-\nmental results showed that IDP is able to relieve this burden with minimal performance loss\nand greatly reduced development effort.\n40 Chapter 1 Predicate Logic as a Modelling Language:The IDP System\nIDP3 is used as a didactic tool in various logic-oriented cou rses at various universities.\n1.8 Related Work\nWithin several domains, research is targeting expressive s peciﬁcation languages and (to a\nlesser extent) multiple inference techniques within one la nguage. While we do not aim at an\nextensive survey of related languages (e.g., [Marriott et a l. 2008] has a section with such a\nsurvey), we do compare with a couple of them.\nThe B language [Abrial 1996], a successor of Z, is a formal spe ciﬁcation language devel-\noped speciﬁcally for the generation of procedural code. It i s based on ﬁrst-order logic and\nset theory, and supports quantiﬁcation over sets. Event-B i s a variant for the speciﬁcation\nof event-based applications. The language Zinc, developed by Marriott et al. [Marriott et al.\n2008], is a successor of OPL and intended as a speciﬁcation la nguage for constraint pro-\ngramming applications (mainly CSP and COP solving). It is ba sed on ﬁrst-order logic, type\ntheory and constraint programming languages. Within ASP, a number of related languages,\noriginating from logic programs, are being developed, such as Gringo [Gebser et al. 2009]\nand DL V [Leone et al. 2006]. They support deﬁnitional knowle dge and default reasoning. Im-\nplementations exist for inference techniques like stable m odel generation (related to model\nexpansion), visualisation, optimization and debugging. A comparison of ASP and FO(ID)\ncan be found in [Denecker et al. 2012]. The language of the All oy [Jackson 2002] system\nis basically ﬁrst-order logic extended with relational alg ebra operators, but with an object-\noriented syntax, making it more natural to express knowledg e from application domains cen-\ntered around agents and their roles, e.g., security analysi s.\nThe following are alternative approaches to model expansio n (or to closely related infer-\nence tasks). The solver-independent CP language Zinc [Marr iott et al. 2008] is grounded to\nthe language MiniZinc [Nethercote et al. 2007], supported b y a range of search algorithms us-\ning various paradigms, as can be seen on www .minizinc.org/c hallenge2012/results2012.html .\nIn the context of constraint ASP (CASP), several systems gro und to ASP extended with\nconstraint atoms, such as Clingcon [Ostrowski and Schaub 20 12] and EZ(CSP) [Balduccini\n2011]. For search, Clingcon combines the ASP solver Clasp [G ebser et al. 2012b] with the\nCSP solver Gecode [Gecode T eam 2013], while EZ(CSP) combine s an off-the-shelf ASP\nsolver with an off-the-shelf CLP-Prolog system. The protot ype CASP solver Inca [Drescher and W alsh\n2012] searches for answer sets of a ground CASP program by app lying Lazy Clause Gen-\neration (LCG) for arithmetic and all-different constraint s. As opposed to extending the\nsearch algorithm, a different approach is to transform a CAS P program to a pure ASP pro-\ngram [Drescher and W alsh 2011], afterwards applying any off -the-shelf ASP solver. CASP\nlanguages generally only allow a restricted set of expressi ons to occur in constraint atoms\nand impose conditions on where constraint atoms can occur. F or example, none of the lan-\nguages allows general atoms P(\nc) with P being an uninterpreted predicate symbol. One\nexception is AC (C ), a language aimed at integrating ASP and Constraint Logic Pr ogram-\n1.9 Conclusion 41\nming [Mellarkod et al. 2008]. As shown in [Lierler 2012], the language captures the lan-\nguages of both Clingcon and EZ(CSP); however, only subsets o f the language are imple-\nmented [Gelfond et al. 2008].\n1.9 Conclusion\nKowalski’s 1974 paper [Kowalski 1974] laid the foundations for the ﬁeld of Logic Program-\nming, by giving the Horn-clause subset of predicate logic a p rocedural interpretation to use it\nfor programming. More recently, progress in automated reas oning in ﬁelds such as SA T and\nCP made the exploration possible of more pure forms of declar ative programming, gradually\nmoving from declarative programming to declarative modell ing, in which the user only has to\ncare about the problem speciﬁcation.\nIn this chapter, we took this development one step further an d presented the knowledge\nbase system IDP, in which knowledge is separated from comput ation. The knowledge rep-\nresentation language is both natural and extensible, clean ly integrating ﬁrst-order logic with\ndeﬁnitions, aggregates, etc. It provides a range of inferen ce engines and functionalities for\ntasks encountered often in practice.\nIDP is an extensible framework for declarative modelling, i n which both language exten-\nsions and inference engines can be added with relative ease. It focuses on moving the burden\nof performance on modelling from the user to the system, demo nstrated by the workﬂow of\noptimization inference, which is achieved by combining ins ights from ﬁelds such as SA T ,\nconstraint programming, logic programming and answer set p rogramming.\n\nBibliography\nJ.-R. Abrial. 1996. The B-book: Assigning Programs to Meanings . Cambridge University Press, New\nY ork, NY , USA. ISBN 0-521-49619-5.\nJ.-R. Abrial, M. J. Butler, S. Hallerstede, T . S. Hoang, F . Me hta, and L. V oisin. 2010. Rodin: An open\ntoolset for modelling and reasoning in Event-B. STTT, 12(6): 447–466.\nF . A. Aloul, K. A. Sakallah, and I. L. Markov . 2006. Efﬁcient s ymmetry breaking for Boolean satisﬁabil-\nity . IEEE Transactions on Computers , 55(5): 549–558. ISSN 0018-9340. DOI: 10.1109/TC.2006.75 .\nM. Alviano, F . Calimeri, G. Charwat, M. Dao-Tran, C. Dodaro, G. Ianni, T . Krennwallner, M. Kro-\nnegger, J. Oetsch, A. Pfandler, J. P ¨ uhrer, C. Redl, F . Ricca , P . Schneider, M. Schwengerer, L. K.\nSpendier, J. P . W allner, and G. Xiao. 2013. The fourth Answer Set Programming competition: Pre-\nliminary report. In P . Cabalar and T . C. Son, eds., Logic Programming and Nonmonotonic Reasoning,\n12th International Conference, LPNMR 2013, Corunna, Spain , September 15-19, 2013. Proceed-\nings, volume 8148 of LNCS, pp. 42–53. Springer. ISBN 978-3-642-40563-1, 978-3-642- 40564-8.\nhttp://dx.doi.org/10.1007/978-3-642-40564-8\n5.\nR. Amadini, M. Gabbrielli, and J. Mauro. 2013a. Features for building CSP portfolio solvers. CoRR,\nabs/1308.0227.\nR. Amadini, M. Gabbrielli, and J. Mauro. 2013b. An empirical evaluation of portfolios ap-\nproaches for solving CSPs. In C. P . Gomes and M. Sellmann, eds ., CP AIOR, volume 7874\nof Lecture Notes in Computer Science , pp. 316–324. Springer. ISBN 978-3-642-38170-6.\nhttp://dx.doi.org/10.1007/978-3-642-38171-3 21. DOI: 10.1007/978-3-642-38171-3 21.\nM. Balduccini. 2011. Industrial-size scheduling with ASP+ CP. In J. P . Delgrande and W . Faber, eds.,\nLPNMR, volume 6645 of Lecture Notes in Computer Science , pp. 284–296. Springer. ISBN 978-\n3-642-20894-2. http://dx.doi.org/10.1007/978-3-642-2 0895-9 33. DOI: 10.1007/978-3-642-20895-\n9 33.\nM. Bartholomew and J. Lee. 2012. Stable models of formulas wi th in-\ntensional functions. In Brewka et al. [2012]. ISBN 978-1-57 735-560-1.\nhttp://www .aaai.org/ocs/index.php/KR/KR12/paper/view/4559.\nB. Bogaerts, B. De Cat, S. De Pooter, and M. Denecker, 2012. Th e I D P framework reference manual.\nhttps://dtai.cs.kuleuven.be/krr/ﬁles/bib/manuals/id p3-manual.pdf.\nB. Bogaerts, J. Jansen, M. Bruynooghe, B. De Cat, J. V enneken s, and M. Denecker. 7 2014a. Simulating\ndynamic systems using linear time calculus theories. TPLP, 14(4–5): 477–492. ISSN 1475-3081.\nhttp://journals.cambridge.org/article S1471068414000155 . DOI: 10.1017/S1471068414000155.\nB. Bogaerts, J. Jansen, B. De Cat, G. Janssens, M. Bruynooghe , and M. Denecker. 2014b. Meta-\nlevel representations in the IDP knowledge base system: T ow ards bootstrapping inference engine\ndevelopment. In D. Mitchell and M. Denecker, eds., W orkshop on Logic and Search, 2014 , pp. 1–14.\nhttps://lirias.kuleuven.be/handle/123456789/459071 .\n43\n44 BIBLIOGRAPHY\nG. Brewka, T . Eiter, and S. A. McIlraith, eds. 2012. Principles of Knowledge Representation and\nReasoning: Proceedings of the Thirteenth International Co nference, KR 2012, Rome, Italy, June 10-\n14, 2012 . AAAI Press. ISBN 978-1-57735-560-1.\nM. Bruynooghe, H. Blockeel, B. Bogaerts, B. De Cat, S. De Poot er, J. Jansen, A. Labarre, J. Ramon,\nM. Denecker, and S. V erwer. November 2015. Predicate logic a s a modeling language: mod-\neling and solving some machine learning and data mining prob lems with IDP3. TPLP, 15(6):\n783–817. ISSN 1475-3081. http://journals.cambridge.org /article S147106841400009X . DOI:\n10.1017/S147106841400009X.\nW . Buchholz, S. Feferman, W . Pohlers, and W . Sieg. 1981. Iterated Inductive Deﬁnitions and Subsys-\ntems of Analysis: Recent Proof-Theoretical Studies , volume 897 of Lecture Notes in Mathematics .\nSpringer.\nF . Calimeri, G. Ianni, and F . Ricca. 2014. The third open answ er set programming com-\npetition. TPLP, 14(1): 117–135. http://dx.doi.org/10.1017/S147106841 2000105 . DOI:\n10.1017/S1471068412000105.\nW . Chen and D. S. W arren. 1996. T abled evaluation with delayi ng for general logic programs. J. ACM ,\n43(1): 20–74.\nK. L. Clark. 1978. Negation as failure. In Logic and Data Bases , pp. 293–322. Plenum Press. ISBN\n0-306-40060-X.\nB. De Cat and M. Bruynooghe. 2013. Detection and exploitatio n of functional dependencies for model\ngeneration. TPLP, 13(4–5): 471–485.\nB. De Cat, B. Bogaerts, J. Devriendt, and M. Denecker. 2013. M odel expansion in the presence of\nfunction symbols using constraint programming. In 2013 IEEE 25th International Conference on\nT ools with Artiﬁcial Intelligence, Herndon, VA, USA, Novem ber 4-6, 2013 , pp. 1068–1075. IEEE\nComputer Society . ISBN 978-1-4799-2971-9. http://dx.doi .org/10.1109/ICT AI.2013.159. DOI:\n10.1109/ICT AI.2013.159.\nB. De Cat, B. Bogaerts, and M. Denecker, Sept. 2014. MiniSA T( ID) for satisﬁability checking and\nconstraint solving. ALP Newsletter. https://lirias.kule uven.be/handle/123456789/463884 .\nB. De Cat, M. Denecker, M. Bruynooghe, and P . J. Stuckey . 2015 . Lazy model expansion: Interleaving\ngrounding with search. J. Artif. Intell. Res. (JAIR) , 52: 235–286. http://dx.doi.org/10.1613/jair.4591.\nDOI: 10.1613/jair.4591.\nS. De Pooter, J. Wittocx, and M. Denecker. 2011. A prototype o f a knowledge-based programming\nenvironment. CoRR, abs/1108.5667.\nK. Decroix, J. Lapon, B. De Decker, and V . Naessens. 2013. A fo rmal approach for inspecting privacy\nand trust in advanced electronic services. In J. J ¨ urjens, B . Livshits, and R. Scandariato, eds., ESSoS,\nvolume 7781 of LNCS, pp. 155–170. Springer. ISBN 978-3-642-36562-1.\nM. Deinum, J. Long, G. Mak, and D. Rubio. 2014. Spring Annotation Driven Core T asks , pp. 135–216.\nApress, Berkeley , CA. ISBN 978-1-4302-5909-1. https://do i.org/10.1007/978-1-4302-5909-1 3.\nDOI: 10.1007/978-1-4302-5909-1 3.\nM. Denecker. 1998. The well-founded semantics is the princi ple of inductive deﬁnition. In J. Dix,\nL. F . del Cerro, and U. Furbach, eds., JELIA, volume 1489 of LNCS, pp. 1–16. Springer. ISBN\n3-540-65141-1.\nBIBLIOGRAPHY 45\nM. Denecker. 2000. Extending classical logic with inductiv e deﬁnitions. In J. W . Lloyd, V . Dahl,\nU. Furbach, M. Kerber, K.-K. Lau, C. Palamidessi, L. M. Perei ra, Y . Sagiv , and P . J. Stuckey , eds.,\nCL, volume 1861 of LNCS, pp. 703–717. Springer. ISBN 3-540-67797-6.\nM. Denecker and E. T ernovska. Apr. 2008. A logic of nonmonoto ne inductive deﬁnitions. ACM Trans.\nComput. Log. , 9(2): 14:1–14:52. ISSN 1529-3785. http://dx.doi.org/10 .1145/1342991.1342998 .\nM. Denecker and J. V ennekens. 2007. W ell-founded semantics and the algebraic theory of non-\nmonotone inductive deﬁnitions. In C. Baral, G. Brewka, and J . S. Schlipf, eds., LPNMR, vol-\nume 4483 of Lecture Notes in Computer Science , pp. 84–96. Springer. ISBN 978-3-540-72199-4.\nhttp://dx.doi.org/10.1007/978-3-540-72200-7 9. DOI: 10.1007/978-3-540-72200-7 9.\nM. Denecker and J. V ennekens. 2008. Building a knowledge bas e system for an integra-\ntion of logic programming and classical logic. In M. Garc´ ıa de la Banda and E. Pon-\ntelli, eds., ICLP, volume 5366 of LNCS, pp. 71–76. Springer. ISBN 978-3-540-89981-5.\nhttp://dx.doi.org/10.1007/978-3-540-89982-2 12.\nM. Denecker and J. V ennekens. 2014. The well-founded semant ics is the principle of inductive deﬁni-\ntion, revisited. In C. Baral, G. De Giacomo, and T . Eiter, eds ., Principles of Knowledge Representa-\ntion and Reasoning: Proceedings of the F ourteenth Internat ional Conference , pp. 1–10. AAAI Press.\nISBN 978-1-57735-657-8. http://www .aaai.org/ocs/index .php/KR/KR14/paper/view/7957.\nM. Denecker, M. Bruynooghe, and V . Marek. 2001. Logic progra mming revisited: Logic programs as\ninductive deﬁnitions. ACM Trans. Comput. Log. , 2(4): 623–654.\nM. Denecker, J. V ennekens, S. Bond, M. Gebser, and M. Truszcz y ´ nski. 2009. The second answer set\nprogramming competition. In Erdem et al. [2009], pp. 637–65 4. ISBN 978-3-642-04237-9.\nM. Denecker, Y . Lierler, M. Truszczy ´ nski, and J. V ennekens . 2012. A Tarskian informal semantics for\nanswer set programming. In Dovier and Costa [2012], pp. 277– 289. ISBN 978-3-939897-43-9.\nJ. Devriendt, B. Bogaerts, B. De Cat, M. Denecker, and C. Mear s. 2012. Symmetry propagation:\nImproved dynamic symmetry breaking in SA T. In IEEE 24th International Conference on T ools\nwith Artiﬁcial Intelligence, ICTAI 2012, Athens, Greece, N ovember 7-9, 2012 , pp. 49–56. IEEE\nComputer Society . ISBN 978-1-4799-0227-9. http://dx.doi .org/10.1109/ICT AI.2012.16. DOI:\n10.1109/ICT AI.2012.16.\nJ. Devriendt, B. Bogaerts, M. Bruynooghe, and M. Denecker. 0 09 2016a. On local domain\nsymmetry for model expansion. Theory and Practice of Logic Programming , 16(5-6): 636–652.\nhttps://www .cambridge.org/core/article/on-local-domain-symmetry-for-model-expansion/96E8AB07EB4C02D502 B68687B23AC21C .\nDOI: 10.1017/S1471068416000508.\nJ. Devriendt, B. Bogaerts, M. Bruynooghe, and M. Denecker. 2 016b. Improved static symmetry\nbreaking for SA T. In N. Creignou and D. L. Berre, eds., Theory and Applications of Satisﬁability\nT esting - SAT 2016 - 19th International Conference, Bordeau x, France, July 5-8, 2016, Proceedings ,\nvolume 9710 of Lecture Notes in Computer Science , pp. 104–122. Springer. ISBN 978-3-319-40969-\n6. http://dx.doi.org/10.1007/978-3-319-40970-2 8. DOI: 10.1007/978-3-319-40970-2 8.\nA. Dovier and V . S. Costa, eds. 2012. T echnical Communications of the 28th International Confer ence\non Logic Programming, ICLP 2012, September 4-8, 2012, Budap est, Hungary. Proceedings , vol-\nume 17 of LIPIcs. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik. ISBN 978-3-939897-43-9.\nC. Drescher and T . W alsh. 2011. Translation-based constrai nt answer set solving.\nIn T . W alsh, ed., IJCAI, pp. 2596–2601. IJCAI/AAAI. ISBN 978-1-57735-516-8.\n46 BIBLIOGRAPHY\nhttp://ijcai.org/papers11/Papers/IJCAI11-432.pdf.\nC. Drescher and T . W alsh. 2012. Answer set solving with lazy n ogood generation. In Dovier and Costa\n[2012], pp. 188–200. ISBN 978-3-939897-43-9.\nD. East and M. Truszczy ´ nski. 2006. Predicate-calculus-ba sed logics for modeling and solving search\nproblems. ACM Trans. Comput. Log. , 7(1): 38–83.\nN. E´ en and N. S ¨ orensson. 2003. An extensible SA T-solver. I n E. Giunchiglia and A. T acchella, eds.,\nSAT, volume 2919 of LNCS, pp. 502–518. Springer. ISBN 3-540-20851-8.\nU. Egly , T . Eiter, H. T ompits, and S. W oltran. 2000. Solving a dvanced reasoning tasks using quantiﬁed\nBoolean formulas. In Proceedings of the Seventeenth National Conference on Arti ﬁcial Intelligence\nand T welfth Conference on Innovative Applications of Artiﬁ cial Intelligence , pp. 417–422. AAAI\nPress. ISBN 0-262-51112-6.\nE. Erdem, F . Lin, and T . Schaub, eds. 2009. Logic Programming and Nonmonotonic Reasoning, 10th\nInternational Conference, LPNMR 2009, P otsdam, Germany, S eptember 14-18, 2009. Proceedings ,\nvolume 5753 of LNCS. Springer. ISBN 978-3-642-04237-9.\nT . Feydy and P . J. Stuckey . 2009. Lazy clause generation reen gineered. In Gent [2009], pp. 352–366.\nISBN 978-3-642-04243-0. http://dx.doi.org/10.1007/978 -3-642-04244-7 29. DOI: 10.1007/978-3-\n642-04244-7 29.\nA. M. Frisch and P . J. Stuckey . 2009. The proper treatment of u ndeﬁnedness\nin constraint languages. In Gent [2009], pp. 367–382. ISBN 9 78-3-642-04243-0.\nhttp://dx.doi.org/10.1007/978-3-642-04244-7 30. DOI: 10.1007/978-3-642-04244-7 30.\nH. Ganzinger, G. Hagen, R. Nieuwenhuis, A. Oliveras, and C. T inelli. 2004. DPLL( T): fast decision\nprocedures. In R. Alur and D. Peled, eds., Computer Aided V eriﬁcation, 16th International Con-\nference, CA V 2004, Boston, MA, USA, July 13-17, 2004, Procee dings, volume 3114 of LNCS, pp.\n175–188. Springer. ISBN 3-540-22342-8. http://dx.doi.or g/10.1007/978-3-540-27813- 9 14. DOI:\n10.1007/978-3-540-27813-9 14.\nM. Gebser, R. Kaminski, M. Ostrowski, T . Schaub, and S. Thiel e. 2009. On the input language of ASP\ngrounder Gringo. In Erdem et al. [2009], pp. 502–508. ISBN 97 8-3-642-04237-9.\nM. Gebser, R. Kaminski, B. Kaufmann, and T . Schaub. 2012a. Answer Set Solving in Practice .\nSynthesis Lectures on Artiﬁcial Intelligence and Machine L earning. Morgan & Claypool Publishers.\ndx.doi.org/10.2200/S00457ED1V01Y201211AIM019 .\nM. Gebser, B. Kaufmann, and T . Schaub. 2012b. Conﬂict-drive n answer set solving: From theory to\npractice. Artif. Intell. , 187: 52–89.\nGecode T eam, 2013. Gecode: Generic constraint development environment. A vailable from\nhttp://www.gecode.org.\nM. Gelfond and V . Lifschitz. 1988. The stable model semantic s for logic programming. In R. A.\nKowalski and K. A. Bowen, eds., ICLP/SLP, pp. 1070–1080. MIT Press. ISBN 0-262-61056-6.\nhttp://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.6050 .\nM. Gelfond and V . Lifschitz. 1991. Classical negation in log ic programs and disjunctive databases. New\nGeneration Computing , 9(3/4): 365–386.\nM. Gelfond, V . S. Mellarkod, and Y . Zhang. 2008. Systems inte grating answer set programming and\nconstraint programming. In M. Denecker, ed., Second W orkshop on Logic and Search, 2008 , pp.\nBIBLIOGRAPHY 47\n145–152. ACCO.\nI. P . Gent, ed. 2009. Principles and Practice of Constraint Programming - CP 2009 , 15th\nInternational Conference, CP 2009, Lisbon, P ortugal, Sept ember 20-24, 2009, Proceedings ,\nvolume 5732 of Lecture Notes in Computer Science . Springer. ISBN 978-3-642-04243-0.\nhttp://dx.doi.org/10.1007/978-3-642-04244-7 . DOI: 10. 1007/978-3-642-04244-7.\nT . Heyman. Mar 2013. A Formal Analysis Technique for Secure Software Architectu res. PhD thesis,\nDepartment of Computer Science, KU Leuven. https://lirias .kuleuven.be/handle/123456789/389365 .\nR. Ierusalimschy , L. Henrique de Figueiredo, and W . Celes. 1 996. Lua – an extensi-\nble extension language. Software: Practice and Experience , 26(6): 635–652. ISSN 1097-\n024X. http://dx.doi.org/10.1002/(SICI)1097-024X(1996 06)26:6⟨635::AID-SPE26 ⟩3.0.CO;2-P.\nDOI: 10.1002/(SICI)1097-024X(199606)26:6¡635::AID-SP E26¿3.0.CO;2-P .\nD. Jackson. 2002. Alloy: A lightweight object modelling not ation. ACM Transactions on Software\nEngineering and Methodology (TOSEM’02) , 11(2): 256–290.\nJ. Jansen, A. Jorissen, and G. Janssens. 2013. Compiling inp ut∗FO(·) inductive deﬁnitions into tabled\nProlog rules for IDP3. TPLP, 13(4–5): 691–704. DOI: 10.1017/S1471068413000434.\nJ. Jansen, I. Dasseville, J. Devriendt, and G. Janssens. 201 4. Experimental evaluation of a state-\nof-the-art grounder. In O. Chitil, A. King, and O. Danvy , eds ., Proceedings of the 16th In-\nternational Symposium on Principles and Practice of Declar ative Programming, Kent, Canter-\nbury, United Kingdom, September 8-10, 2014 , pp. 249–258. ACM. ISBN 978-1-4503-2947-7.\nhttp://doi.acm.org/10.1145/2643135.2643149 . DOI: 10.1 145/2643135.2643149.\nR. A. Kowalski. 1974. Predicate logic as programming langua ge. In IFIP Congress , pp. 569–574.\nN. Leone, G. Pfeifer, W . Faber, T . Eiter, G. Gottlob, S. Perri , and F . Scarcello. 2006. The DL V system\nfor knowledge representation and reasoning. ACM Trans. Comput. Log. , 7(3): 499–562.\nY . Lierler. 2012. On the relation of constraint answer set pr ogramming languages and algorithms. In\nJ. Hoffmann and B. Selman, eds., AAAI. AAAI Press.\nV . Lifschitz. 2012. Logic programs with intensional functi ons. In Brewka et al. [2012]. ISBN 978-1-\n57735-560-1.\nJ. W . Lloyd. 1987. F oundations of Logic Programming, 2nd Edition . Springer. ISBN 3-540-18199-7.\nK. Marriott, N. Nethercote, R. Rafeh, P . J. Stuckey , M. Garci a de la Banda, and M. W allace. 2008. The\ndesign of the Zinc modelling language. Constraints, 13(3): 229–267.\nV . S. Mellarkod, M. Gelfond, and Y . Zhang. 2008. Integrating answer set programming and constraint\nlogic programming. Annals of Mathematics and Artiﬁcial Intelligence , 53(1-4): 251–287. ISSN\n1012-2443. DOI: http://dx.doi.org/10.1007/s10472-009- 9116-y .\nMinizincChallenge2012. Minizinc challenge 2012. http:// www .minizinc.org/challenge2012/results2012.html.\nD. G. Mitchell and E. T ernovska. 2005. A framework for repres enting and solving NP search problems.\nIn M. M. V eloso and S. Kambhampati, eds., AAAI, pp. 430–435. AAAI Press / The MIT Press. ISBN\n1-57735-236-X. http://www .aaai.org/Library/AAAI/2005 /aaai05-068.php.\nN. Nethercote, P . J. Stuckey , R. Becket, S. Brand, G. J. Duck, and G. T ack. 2007. Minizinc: T owards\na standard CP modelling language. In C. Bessiere, ed., CP’07 , volume 4741 of LNCS, pp. 529–543.\nSpringer.\nM. Ostrowski and T . Schaub. 2012. ASP modulo CSP: The clingco n system. TPLP, 12(4–5): 485–503.\n48 BIBLIOGRAPHY\nP . Pialorsi and M. Russo. 2007. Introducing Microsoft R⃝ Linq, ﬁrst. Microsoft Press, Redmond, W A,\nUSA. ISBN 9780735623910.\nB. C. Pierce. 2002. T ypes and Programming Languages . MIT Press, Cambridge, MA, USA. ISBN\n0-262-16209-1.\nT . Syrj¨ anen. 1998. Implementation of local grounding for l ogic programs with stable model semantics.\nT echnical Report B18, Helsinki University of T echnology , F inland.\nA. V an Gelder. 1993. The alternating ﬁxpoint of logic progra ms with negation. J. Comput. Syst. Sci. ,\n47(1): 185–221.\nA. V an Gelder, K. A. Ross, and J. S. Schlipf. 1991. The well-fo unded semantics for gen-\neral logic programs. J. ACM , 38(3): 620–650. http://dx.doi.org/10.1145/116825.116 838 . DOI:\n10.1145/116825.116838.\nP . V an Hertum, I. Dasseville, G. Janssens, and M. Denecker. 2 016. The KB paradigm and its application\nto interactive conﬁguration. In M. Gavanelli and J. H. Reppy , eds., Practical Aspects of Declarative\nLanguages - 18th International Symposium, P ADL 2016, St. P e tersburg, FL, USA, January 18-\n19, 2016. Proceedings , volume 9585 of Lecture Notes in Computer Science , pp. 13–29. Springer.\nISBN 978-3-319-28227-5. http://dx.doi.org/10.1007/978 -3-319-28228-2 2. DOI: 10.1007/978-3-\n319-28228-2 2.\nP . V an Hertum, I. Dasseville, G. Janssens, and M. Denecker. 2 017. The KB paradigm and its application\nto interactive conﬁguration. TPLP, 17(1): 91–117. http://dx.doi.org/10.1017/S1471068416 000156 .\nDOI: 10.1017/S1471068416000156.\nD. W arren, 2014. One semantics for logic programming.\nhttps://www .linkedin.com/pulse/one-semantics-logic-programming-david-warren .\nC. W eidenbach, D. Dimova, A. Fietzke, R. Kumar, M. Suda, and P . Wischnewski. 2009. SP ASS version\n3.5. In R. A. Schmidt, ed., CADE, volume 5663 of LNCS, pp. 140–145. Springer. ISBN 978-3-642-\n02958-5. http://dx.doi.org/10.1007/978-3-642-02959-2 10.\nJ. Wittocx. May 2010. Finite Domain and Symbolic Inference Methods for Extension s of First-Order\nLogic. PhD thesis, Department of Computer Science, K.U.Leuven, L euven, Belgium.\nJ. Wittocx, M. Mari¨ en, and M. Denecker. 2010. Grounding FO a nd FO(ID) with bounds. J. Artif. Intell.\nRes. (JAIR) , 38: 223–269.\nJ. Wittocx, M. Denecker, and M. Bruynooghe. Aug. 2013. Const raint propagation for ﬁrst-order\nlogic and inductive deﬁnitions. ACM Trans. Comput. Logic , 14(3): 17:1–17:45. ISSN 1529-3785.\nhttp://doi.acm.org/10.1145/2499937.2499938 .",
  "topic": "Horn clause",
  "concepts": [
    {
      "name": "Horn clause",
      "score": 0.74737149477005
    },
    {
      "name": "Logic programming",
      "score": 0.734355092048645
    },
    {
      "name": "Computer science",
      "score": 0.6594916582107544
    },
    {
      "name": "Predicate logic",
      "score": 0.6402783393859863
    },
    {
      "name": "Programming language",
      "score": 0.6336570978164673
    },
    {
      "name": "Prolog",
      "score": 0.6019075512886047
    },
    {
      "name": "Datalog",
      "score": 0.4495408535003662
    },
    {
      "name": "Declarative programming",
      "score": 0.4449472427368164
    },
    {
      "name": "Fifth-generation programming language",
      "score": 0.43818148970603943
    },
    {
      "name": "Predicate variable",
      "score": 0.4184216558933258
    },
    {
      "name": "Description logic",
      "score": 0.4015979766845703
    },
    {
      "name": "Multimodal logic",
      "score": 0.3123317360877991
    },
    {
      "name": "Inductive programming",
      "score": 0.2849001884460449
    },
    {
      "name": "Programming paradigm",
      "score": 0.25973671674728394
    },
    {
      "name": "Zeroth-order logic",
      "score": 0.13901308178901672
    }
  ],
  "institutions": []
}