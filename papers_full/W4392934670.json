{
    "title": "Evaluating the Application of Large Language Models to Generate Feedback in Programming Education",
    "url": "https://openalex.org/W4392934670",
    "year": 2024,
    "authors": [
        {
            "id": "https://openalex.org/A2148850519",
            "name": "Sven Jacobs",
            "affiliations": [
                "University of Siegen"
            ]
        },
        {
            "id": "https://openalex.org/A1996050151",
            "name": "Steffen Jaschke",
            "affiliations": [
                "University of Siegen"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4313288661",
        "https://openalex.org/W4390315357",
        "https://openalex.org/W4390985631",
        "https://openalex.org/W2894540915",
        "https://openalex.org/W4213421742",
        "https://openalex.org/W4380353816",
        "https://openalex.org/W4390621504",
        "https://openalex.org/W4392617381",
        "https://openalex.org/W4389762775",
        "https://openalex.org/W4391584331",
        "https://openalex.org/W4390490752",
        "https://openalex.org/W4388850769",
        "https://openalex.org/W6854096434",
        "https://openalex.org/W4396833177",
        "https://openalex.org/W4386719008",
        "https://openalex.org/W6731261423"
    ],
    "abstract": "This study investigates the application of large language models, specifically GPT-4, to enhance programming education. The research outlines the design of a web application that uses GPT-4 to provide feedback on programming tasks, without giving away the solution. A web application for working on programming tasks was developed for the study and evaluated with 51 students over the course of one semester. The results show that most of the feedback generated by GPT-4 effectively addressed code errors. However, challenges with incorrect suggestions and hallucinated issues indicate the need for further improvements.",
    "full_text": "Evaluating the Application of Large Language\nModels to Generate Feedback in Programming\nEducation\n1st Sven Jacobs\nComputer Science Education\nUniversity of Siegen\nSiegen, Germany\nsven.jacobs@uni-siegen.de\n2nd Steffen Jaschke\nComputer Science Education\nUniversity of Siegen\nSiegen, Germany\nsteffen.jaschke@uni-siegen.de\n©2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in\nany current or future media, including reprinting/republishing this material for advertising or promotional purposes,\ncreating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component\nof this work in other works.\nAbstract—This study investigates the application of large\nlanguage models, specifically GPT-4, to enhance programming\neducation. The research outlines the design of a web application\nthat uses GPT-4 to provide feedback on programming tasks,\nwithout giving away the solution. A web application for working\non programming tasks was developed for the study and evaluated\nwith 51 students over the course of one semester. The results\nshow that most of the feedback generated by GPT-4 effectively\naddressed code errors. However, challenges with incorrect sug-\ngestions and hallucinated issues indicate the need for further\nimprovements.\nI. I NTRODUCTION\nIn courses with numerous exercises, such as programming\ncourses, providing feedback can be time-consuming for teach-\ners. Simultaneously, it can be disadvantageous for learners\nif they have to wait too long for feedback before they can\ncontinue working on the assignment. To address this issue,\nmany automated solutions have been developed in recent years\n[1]. The development of large language models (LLMs) like\nGPT-4 [2] has opened up a wide range of new possibilities\nin this area [3] [4]. GPT-4’s ability to solve introductory\nprogramming tasks is already around 95% [5]. It can even\nsolve and explain more difficult tasks effectively [6], and\nits performance can be further improved with prompting\nstrategies [7]. Google Deepmind’s AlphaCode 2 demonstrates\nthat the combination of fine-tuning and prompting strategies\ncan already reach the 85th percentile on average on the code\ncontest platform Codeforces [8].\nWhile applications like ChatGPT or GitHub Copilot, which\nuse LLMs, can help with programming, their primary purpose\nis to increase productivity rather than to aid learning. To\nbe effective for skill development, such tools would require\nspecific prompts to ensure that the correct solution is not\nprovided immediately, allowing learners to engage in the\nproblem-solving process. Therefore, we integrated GPT-4 into\na new programming practice environment in an introductory\ncomputer science course to provide students with timely\nfeedback. The research question for this work is: To what\nextent is the large language model GPT-4 able to provide\nfeedback for programming education?\nII. R ELATED WORK\nIn the context of programming exercises, a variety of tools\nare used that already support different types of feedback [9]\n[10]. The use of LLMs has opened up new possibilities for\nthe automated creation of teaching materials and the analysis\nof student work, such as the generation of feedback [3].\nHellas et al. [11] compared Codex and GPT-3.5 in gen-\nerating LLM responses to student help requests. They found\nthat in 55% of student help requests, GPT-3.5 identified and\nmentioned all actual issues (Codex: 13%). Notably, 99% of the\nresponses included code, despite the model being prompted\nnot to do so. In an attempt to generate feedback as students\nwould do, Kiesler et al. used ChatGPT (March 2023: GPT-\n3) to examine its responses to incorrect student solutions.\nIn their research 79% of ChatGPT responses contained code\nand 62% contained misleading information [12]. Aziaz et al.’s\nresearch on feedback generation for programming exercises\nobtained 52% fully correct and complete feedback with GPT-\n4 Turbo [13], surpassing their previous research with GPT-3.5,\nwhich obtained 31% [14]. The feedback they generated almost\nalways contained code. Since it is difficult to avoid code in\nthe generated feedback, Lifton et al. use a second LLM for\n”code removal”, which rewrites the generated answer [15].\nIt appears that the models, including GPT-3.5 and GPT-3.5\nTurbo, are biased towards providing a complete solution or\ncode, and they do not consistently follow instructions telling\nthem not to do so [15] [16].\nIt is difficult to compare existing research as the exact model\nused is not always specified and there are several different\nmodels from OpenAI for GPT-3, GPT-3.5, GPT-4 and GPT-4\nTurbo. For example, the GPT-4 Turbo is currently available\nin two different models, ”gpt-4-0125-preview” and ”gpt-4-\n1106-preview”. Furthermore, the parameters used, such as\ntemperature, which controls the randomness of the response\nand can therefore have a large effect, are not always reported.\narXiv:2403.09744v1  [cs.CL]  13 Mar 2024\nFig. 1. Tutor Kai user interface\nThe input for the LLM (prompt) used also makes a dif-\nference [16] [17]. Sometimes only a simple question and\nthe student’s code [12] or additionally the task description\n[14] [13] [11] are used for the prompt. Compiler errors [18]\nand examples of good output (few-shot prompting) [19] can\nadditionally be added for context. Phung et al. show that it can\nalso be helpful to add the result of test cases to the prompt.\nThey also show how GPT-3.5 can be used to simulate a student\nresponse to feedback generated by GPT-4. If the generated\nstudent response does not pass the task-specific unit tests, this\ninformation can be used again to improve the feedback [20].\nFor the feedback generation in this work, the model GPT-\n4-0314 (temperature = 0) with a complex prompt is used\nto prevent code in the answers. The generated feedback was\nevaluated not only by experts, but also directly by the students.\nIII. E VALUATION\nTo evaluate the extent to which LLMs are able to provide\nfeedback for programming education, we have developed a\nweb application called Tutor Kai (Fig. 1). In Tutor Kai,\ncomputer science students can complete weekly tasks for the\nintroductory course ”Object-Oriented and Functional Program-\nming” and receive automated feedback generated by an LLM.\nStudents must also rate the feedback they receive on a scale\nof 1 to 7.\nA. Evaluation Setup\nWithin Tutor Kai, students select the current week and one\nof the associated programming tasks. They are then presented\nwith the task and a code editor that may already contain code.\nWithin the code editor (Fig. 1: top right), the student solves the\ntask and can execute their solution. The solution is compiled\nand unit tests are run to verify its correctness. The student\nreceives both error messages from the compiler and the results\nof the unit tests as text (Fig. 1: bottom right).\nHowever, the problem with semantic bugs in particular\nis that while it is communicated that there is a bug, no\ninformation is provided about what it is related to. This is\nwhere the strength of LLMs for reasoning, coding, and human\nlike text generation comes into play. Students can therefore\nrequest feedback after they have executed the program code.\nFor this purpose, the prompt (Fig 2) is sent to the GPT-4 API\nof OpenAI containing the task, the programming language,\nthe program code, the compiler output and the result of the\nunit tests as context. We used the first version of GPT-4,\nwhich is currently available under the name ”gpt-4-0314”.\nThe temperature parameter was changed to zero to decrease\nrandomness. The LLM feedback generated in this way must\nbe rated by the student (Fig. 1: bottom left).\nB. Method\nWhen evaluating generated feedback, the question arises as\nto whether it should be viewed atomically or in its chronolog-\nical sequence in the context of further code submissions per\nstudent. The advantage of the second method would be that it\nis immediately apparent whether the feedback has helped when\nthe student has received more points in a subsequent code\nsubmission. However, it cannot be ruled out that students have\nconsulted other external sources to obtain information or have\nused a different development environment in combination. The\nsecond option would therefore only be practical if it could be\nensured that only the evaluation setup presented here was used.\nSuch an investigation in a controlled environment is planned\nfor the future.\nBased on the methodology of Hellas et al. [11], we therefore\nanalyzed the feedback atomically using the following cate-\ngories:\n1) Identification and mention of at least one actual issue\n2) Identification and mention of all issues\n3) Wrong suggestions for improvement\n4) Hallucinated issues\n5) Unnecessary suggestions for improvement\n6) Includes code\nIdentification and mention of at least one actual issue is present\nif at least one problem, bug or error that prevents a correct\nsolution is mentioned in the feedback. Likewise, we flagged\nwhen all of them were mentioned. Wrong suggestions for\nimprovements are present if the feedback gives a wrong hint\nor suggests a direction that leads to a wrong solution. Hal-\nlucinated issues are issues where non-existent problems, bugs\nor errors were mentioned in the code submission. Only code\nsnippets that are longer than one line have been marked as\ncode. Individual variables and expressions were not marked, as\nthese are necessary for understanding the feedback. Although\nthese could also be avoided, this would make the feedback\nlonger and more difficult to understand.\nTo learn more about the students’ perspective on how they\nperceived the feedback, we collected additional data. After\nthey received feedback and before they could submit new code,\nthey were forced to rate the feedback on a scale of one to\nseven. Tutor Kai was once offered to students by email for\nvoluntary use.\nIV. R ESULTS\nIn this section, we present the overall aggregated data over\nthe course of the semester and take a closer look at the\nfeedback that was generated for three specific tasks.\nA. Aggregated Data\nAn analysis of the aggregated data from all students across\nthe 26 tasks reveals that Tutor Kai was extensively utilized\nby the participants (Table I). Of the 51 students who tried the\ntool, 25 students used it at least ten times. Twelve students\nused it more than 100 times. Overall, the students gave the\nfeedback an average rating of 5.54 on a scale of 1 to 7. There\nwere four students with more than 100 ratings who almost\nalways gave the highest rating for feedback. In interviews\nit became clear that the forced rating of feedback interfered\nwith task completion and disrupted the flow. Therefore, the\nhighest rating was given immediately in order to continue.\nAfter removing these four students from the data set, the\naverage feedback rating drops to 5.05. Another strategy used\nby the students to avoid the feedback rating was to reload the\npage. For this reason, the number of feedback ratings given\nby students is lower than the number of feedback.\nB. Individual task evaluation\nThe feedback generated on the students’ solutions to three\ntasks (Table II) was evaluated using the methodology de-\nscribed. Overall, 87% of the feedback identified and mentioned\nat least one actual issue. In 62% of the feedback, all of them\nwere identified and mentioned (Table III).\nHallucinated issues occurred several times in the Capital-\nValue task for the following reason. The unit tests associated\nwith the task have expected values that are accurate to the\ntwelfth decimal digit. Due to rounding, correct solutions were\nrecognized as incorrect by the unit tests. GPT-4 receives two\npieces of divergent information in the prompt template (Fig.\n2). On the one hand, the unit tests indicate that the code is\nincorrect and on the other hand, the correct solution as code.\nThis leads to GPT-4 hallucinating and describing errors in the\ncorrect solution that do not exist [21].\nUnnecessary suggestions for improvement usually occurred\nwhen the student’s solution was already correct. Using the\nprompt described (Fig. 2), the model still wants to give\nfeedback. It usually refers to the lack of comments in the\nCategory Result\nNumber of students 51\nNumber of tasks 26\nNumber of code submissions 3159\nNumber of generated feedback 1684\nNumber of student rated feedback 1243\nAverage feedback rating 5.54\nAverage feedback rating (adjusted) 5.05\nTABLE I\nAGGREGATED DATA OF ALL TASKS AND STUDENTS\nTask Description\nCapital-Value Create a recursive function named ‘capitalValue()‘ to\ncalculate the value of a principal amount of 1000 Euros\nafter ‘n‘ years at a constant interest rate.\nMaximum-\nValue\nImplement the ‘max()‘ method in the ‘Starter‘ class\nwithin the provided code skeleton (Starter.java), which\nreturns the larger of two natural numbers ‘a‘ and ‘b‘,\nor the common value if both are equal.\nSum Create a recursive function named ‘summe‘ that takes\ntwo integers ‘m‘ and ‘n‘ as arguments and returns the\nsum of all integers between ‘m‘ and ‘n‘ (inclusive),\nwith the result being 0 if ‘m‘ is greater than ‘n‘.\nTABLE II\nTASK OVERVIEW (TRANSLATED FROM GERMAN )\nSystem-Message\nYou are a professional and friendly computer\nscience teacher for an introductory computer\nscience course in the first semester.\nThe students hand in their solutions to pro-\ngramming tasks to you and you give them\nbrief, reasoned feedback. You explain neces-\nsary concepts in simple language.\nYour most important goal is to tell the stu-\ndents only enough so that they have to un-\nderstand the problem themselves and can\ntherefore solve it.\nYou do not give out the revised code and\nnever suggest program code. You never for-\nmulate code.\nUser-Message\nTask to be solved by the student: {task}\nThe programming language is: {language}\nSolution of the student: {code}\nOutput of the compiler: {output}\nNotes\n• The variables between the curly brackets are\nautomatically replaced by the corresponding\ninformation.\n• As the students’ solution may consist of\nmultiple files, these are separated by: Begin\n{Filename} {code} End {Filename}.\n• The results of the unit tests can be found as\na coherent string in the variable {output} if\nthe solution compiles successfully.\nFig. 2. Prompt (translated from german)\nTask\nCategory Capital-Value Maximum-Value Sum All 3 Tasks\nProgramming Language Python Java Python\nNumber of code submissions 175 62 26 263\nNumber of generated feedback 97 25 15 137\nAverage Feedback Rating 6.3 5.4 4.8 6.0\nIdentification and mention of at least one actual issue 73 (75%) 25 (100%) 15 (100%) 113 (87%)\nIdentification and mention of all actual issues 49 (51%) 23 (92%) 13 (87%) 85 (62%)\nWrong suggestions for improvement 14 (14%) 1 (4%) 1 (7%) 16 (12%)\nHallucinated issues 8 (8%) 0 (0%) 0 (0%) 8 (6%)\nUnnecessary suggestion for improvement 8 (8%) 7 (28%) 4 (27%) 19 (14%)\nIncludes code 4 (4%) 0 (0%) 0 (0%) 4 (3%)\nTABLE III\nFEEDBACK EVALUATION\nsolution or suggests alternative ways that could lead to a\nsimpler solution. A positive correlation between these values\nand the average feedback rating of the students is not evident.\nV. D ISCUSSION\nDespite multiple prompts, the issue of code appearing in the\nfeedback could not be completely avoided. This exemplifies\nthat the behavior of LLMs can neither be fully controlled nor\npredicted. While the inclusion of code in the feedback may\nbe unproblematic in this case, it could potentially become a\nmore significant issue if LLMs were to be used for grading\nassignments.\nCompared to the results of Hellas et al. [11] and Aziaz et al.\n[13], the feedback from Tutor Kai appears to perform better\nin terms of fully correct and complete feedback at first glance.\nHowever, it is unclear whether this is due to the different\nassignments, the more extensive prompt including the results\nof the unit tests in Tutor Kai, or the specific LLM used.\nTo attempt to reproduce and compare the results of similar\nresearch projects, the exact model and parameters used would\nneed to be known. Even then, it is possible that the providing\ncompany may restrict access to the models.\nA problem to be discussed is the deployment and subse-\nquent evaluation of such applications in educational settings.\nSince the completion of assignments often takes place asyn-\nchronously, it cannot be guaranteed that only the evaluated\ntool was used. To address this, the tools would need to be\nable to compete with applications like Visual Studio Code in\nterms of developer experience. During the evaluation of Tutor\nKai, the willingness of students to rate the feedback from 1-7\nwas problematic, even though it only required a single click\nin the user interface. It remains an open question how this can\nbe improved in the future without negatively impacting the\nstudents’ workflow too much.\nVI. C ONCLUSION\nThe evaluation of Tutor Kai demonstrates that the feedback\ngenerated by GPT-4 already identifies and mentions most of\nthe issues in the code. Simultaneously, the problem of code\nappearing in the feedback, which related studies [15] [11] have\nencountered in the past, has been almost entirely resolved.\nOverall, the students have rated the feedback relatively posi-\ntively, with an average of 5.05 on a scale from 1 to 7. One\nissue that was identified is that when students are required to\nevaluate all feedback, they may seek ways to circumvent this\nprocess, potentially distorting the data.\nFurthermore, it has been shown that faulty unit tests in com-\nbination with a correct student solution can lead to hallucinated\nissues. In such cases, errors are addressed that are not present\nin the student’s solution. To avoid this, care must be taken to\nensure that GPT-4 does not receive contradictory information.\nVII. O UTLOOK\nIn the future, the data already collected will also be eval-\nuated with regard to the different types of feedback [22] [9].\nA framework for automating this process will be developed\nand evaluated. Based on this, faster iterations of models and\nprompts would then be possible.\nIt is expected that future models such as GPT-5 or Llama3,\nwhich may be released as early as 2024, will be even more\ncapable of formulating and explaining code and providing\nfeedback. The maximum number of tokens that can be pro-\ncessed by the LLM is also likely to increase. Google’s Gemini\n1.5 increases this by a factor of eight compared to GPT-\n4 Turbo, to over one million. This increases the potential\nfor prompting strategies and the use of Retrieval Augmented\nGeneration (RAG) to fill the context window with relevant\ninformation about the situational and individual circumstances\nof students or the content of a lecture. It is therefore already\npossible to use complete lecture notes or textbooks as input\nfor the LLM when generating feedback. How the increasingly\nlarge context windows of LLMs can be filled in a didactically\nmeaningful way in educational contexts needs to be researched\nmore intensively in the future.\nREFERENCES\n[1] J. Jeuring, H. Keuning, S. Marwan, D. Bouvier, C. Izu, N. Kiesler,\nT. Lehtinen, D. Lohr, A. Peterson, and S. Sarsa, “Towards Giving Timely\nFormative Feedback and Hints to Novice Programmers,” in Proceedings\nof the 2022 Working Group Reports on Innovation and Technology in\nComputer Science Education, ser. ITiCSE-WGR ’22. New York, USA:\nACM, 2022, pp. 95–115, doi: 10.1145/3571785.3574124.\n[2] OpenAI, “GPT-4 Technical Report,” 2023, doi:\n10.48550/ARXIV .2303.08774.\n[3] J. Prather, P. Denny, J. Leinonen, B. A. Becker, I. Albluwi, M. Craig,\nH. Keuning, N. Kiesler, T. Kohn, A. Luxton-Reilly, S. MacNeil, A. Pe-\ntersen, R. Pettit, B. N. Reeves, and J. Savelka, “The Robots Are Here:\nNavigating the Generative AI Revolution in Computing Education,” in\nProceedings of the 2023 Working Group Reports on Innovation and\nTechnology in Computer Science Education. New York, USA: ACM,\n2023, pp. 108–159, doi: 10.1145/3623762.3633499.\n[4] P. Denny, J. Prather, B. A. Becker, J. Finnie-Ansley, A. Hellas,\nJ. Leinonen, A. Luxton-Reilly, B. N. Reeves, E. A. Santos, and S. Sarsa,\n“Computing Education in the Era of Generative AI,” Communications\nof the ACM, no. 67, pp. 55–67, 2023, doi: 10.1145/3624720.\n[5] N. Kiesler and D. Schiffner, “Large Language Models in Introductory\nProgramming Education: ChatGPT’s Performance and Implications for\nAssessments,” 2023, doi: 10.48550/arXiv.2308.08572.\n[6] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-\nmar, P. Lee, Y . T. Lee, Y . Li, S. Lundberg, H. Nori, H. Palangi, M. T.\nRibeiro, and Y . Zhang, “Sparks of Artificial General Intelligence: Early\nexperiments with GPT-4,” 2023, doi: 10.48550/arXiv.2303.12712.\n[7] H. Nori, Y . T. Lee, S. Zhang, D. Carignan, R. Edgar, N. Fusi, N. King,\nJ. Larson, Y . Li, W. Liu, R. Luo, S. M. McKinney, R. O. Ness,\nH. Poon, T. Qin, N. Usuyama, C. White, and E. Horvitz, “Can Generalist\nFoundation Models Outcompete Special-Purpose Tuning? Case Study in\nMedicine,” 2023, doi: 10.48550/arXiv.2311.16452.\n[8] AlphaCode, “AlphaCode 2 Technical Report,” 2023.\n[9] H. Keuning, J. Jeuring, and B. Heeren, “A Systematic Literature Review\nof Automated Feedback Generation for Programming Exercises,” ACM\nTransactions on Computing Education, vol. 19, pp. 1–43, 2019, doi:\n10.1145/3231711.\n[10] J. C. Paiva, J. P. Leal, and ´A. Figueira, “Automated Assessment in\nComputer Science Education: A State-of-the-Art Review,” ACM Trans-\nactions on Computing Education, vol. 22, no. 3, pp. 1–40, 2022, doi:\n10.1145/3513140.\n[11] A. Hellas, J. Leinonen, S. Sarsa, C. Koutcheme, L. Kujanp ¨a¨a, and\nJ. Sorva, “Exploring the Responses of Large Language Models to\nBeginner Programmers’ Help Requests,” in Proceedings of the 2023\nACM Conference on International Computing Education Research -\nVolume 1, ser. ICER ’23, vol. 1. New York, USA: ACM, 2023, pp.\n93–105, doi: 10.1145/3568813.3600139.\n[12] N. Kiesler, D. Lohr, and H. Keuning, “Exploring the Potential of Large\nLanguage Models to Generate Formative Programming Feedback,” in\n2023 IEEE Frontiers in Education Conference (FIE). College Station,\nUSA: IEEE, 2023, pp. 1–5, doi: 10.1109/FIE58773.2023.10343457.\n[13] I. Azaiz, N. Kiesler, and S. Strickroth, “Feedback-Generation\nfor Programming Exercises With GPT-4,” 2024, doi:\n10.48550/arXiv.2403.04449.\n[14] I. Azaiz, O. Deckarm, and S. Strickroth, “AI-Enhanced Auto-Correction\nof Programming Exercises: How Effective is GPT-3.5?” International\nJournal of Engineering Pedagogy (iJEP), vol. 13, no. 8, pp. 67–83,\n2023, doi: 10.3991/ijep.v13i8.45621.\n[15] M. Liffiton, B. Sheese, J. Savelka, and P. Denny, “CodeHelp: Us-\ning Large Language Models with Guardrails for Scalable Support\nin Programming Classes,” in Proceedings of the 23rd Koli Calling\nInternational Conference on Computing Education Research. Koli,\nFinland: ACM, 2023, doi: 10.1145/3631802.3631830.\n[16] L. Roest, H. Keuning, and J. Jeuring, “Next-Step Hint Genera-\ntion for Introductory Programming Using Large Language Mod-\nels,” in Proceedings of the 26th Australasian Computing Education\nConference. Sydney, Australia: ACM, 2023, pp. 144–153, doi:\n10.1145/3636243.3636259.\n[17] E. A. Santos, P. Prasad, and B. A. Becker, “Always Provide Context:\nThe Effects of Code Context on Programming Error Message Enhance-\nment,” in Proceedings of the ACM Conference on Global Computing\nEducation Vol 1. Hyderabad, India: ACM, 2023, pp. 147–153, doi:\n10.1145/3576882.3617909.\n[18] M. Pankiewicz and R. S. Baker, “Large Language Models (GPT) for\nautomating feedback on programming assignments,” in Proceedings of\nthe 31st International Conference on Computers in Education, 2023,\ndoi: 10.48550/arXiv.2307.00150.\n[19] M. Kazemitabaar, R. Ye, X. Wang, A. Z. Henley, P. Denny, M. Craig,\nand T. Grossman, “CodeAid: Evaluating a Classroom Deployment of an\nLLM-based Programming Assistant that Balances Student and Educator\nNeeds,” 2024, arXiv: 2401.11314.\n[20] T. Phung, V .-A. P ˘adurean, J. Cambronero, S. Gulwani, T. Kohn, R. Ma-\njumdar, A. Singla, and G. Soares, “Generative AI for Programming\nEducation: Benchmarking ChatGPT, GPT-4, and Human Tutors,” in\nProceedings of the 2023 ACM Conference on International Computing\nEducation Research. Chicago, USA: ACM, 2023, pp. 41–42, doi:\n10.1145/3568812.3603476.\n[21] S. Jacobs and S. Jaschke, “Large Language Models in der Berufsaus-\nbildung von IT-Fachkr ¨aften,” in INFOS 2023 - Informatikunterricht\nzwischen Aktualit¨at und Zeitlosigkeit. W ¨urzburg, Germany: Gesellschaft\nf¨ur Informatik, 2023, doi: 10.18420/INFOS2023-017.\n[22] S. Narciss, “Feedback Strategies for Interactive Learning Tasks,” in\nHandbook of Research on Educational Communications and Technology,\nM. Spector, D. Merill, J. Van Merrienboer, and M. Driscoll, Eds. New\nYork, USA: Lawrence Erlbaum Associates, 2008, pp. 125–144."
}