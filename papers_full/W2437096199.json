{
    "title": "Training neural network language models on very large corpora",
    "url": "https://openalex.org/W2437096199",
    "year": 2005,
    "authors": [
        {
            "id": "https://openalex.org/A2020611530",
            "name": "Holger Schwenk",
            "affiliations": [
                "Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur",
                "Centre National de la Recherche Scientifique"
            ]
        },
        {
            "id": "https://openalex.org/A4210055697",
            "name": "Jean-Luc Gauvain",
            "affiliations": [
                "Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur",
                "Centre National de la Recherche Scientifique"
            ]
        },
        {
            "id": "https://openalex.org/A2020611530",
            "name": "Holger Schwenk",
            "affiliations": [
                "Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur"
            ]
        },
        {
            "id": "https://openalex.org/A4210055697",
            "name": "Jean-Luc Gauvain",
            "affiliations": [
                "Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3042385255",
        "https://openalex.org/W1989705153",
        "https://openalex.org/W2056590938",
        "https://openalex.org/W1577724162",
        "https://openalex.org/W2156909104",
        "https://openalex.org/W2134237567",
        "https://openalex.org/W1996903695",
        "https://openalex.org/W1631260214",
        "https://openalex.org/W2998704965",
        "https://openalex.org/W4256364787",
        "https://openalex.org/W2154391726",
        "https://openalex.org/W108809533",
        "https://openalex.org/W2148321140",
        "https://openalex.org/W2140679639",
        "https://openalex.org/W2158195707",
        "https://openalex.org/W2148603752",
        "https://openalex.org/W2171645483",
        "https://openalex.org/W4285719527",
        "https://openalex.org/W2121227244",
        "https://openalex.org/W2070534370",
        "https://openalex.org/W2399351785",
        "https://openalex.org/W180685247"
    ],
    "abstract": "During the last years there has been growing interest in using neural networks for language modeling. In contrast to the well known back-off n-gram language models, the neural network approach attempts to overcome the data sparseness problem by performing the estimation in a continuous space. This type of language model was mostly used for tasks for which only a very limited amount of in-domain training data is available.In this paper we present new algorithms to train a neural network language model on very large text corpora. This makes possible the use of the approach in domains where several hundreds of millions words of texts are available. The neural network language model is evaluated in a state-of-the-art real-time continuous speech recognizer for French Broadcast News. Word error reductions of 0.5% absolute are reported using only a very limited amount of additional processing time.",
    "full_text": null
}