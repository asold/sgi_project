{
    "title": "Combining Variational Autoencoders and Transformer Language Models for Improved Password Generation",
    "url": "https://openalex.org/W4292158727",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2978460324",
            "name": "David Biesner",
            "affiliations": [
                "University of Bonn"
            ]
        },
        {
            "id": "https://openalex.org/A2579560983",
            "name": "Kostadin Cvejoski",
            "affiliations": [
                "University of Bonn"
            ]
        },
        {
            "id": "https://openalex.org/A2072919878",
            "name": "Rafet Sifa",
            "affiliations": [
                "Fraunhofer Institute for Intelligent Analysis and Information Systems"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3150971122",
        "https://openalex.org/W3199023617",
        "https://openalex.org/W1487941708",
        "https://openalex.org/W2751688886",
        "https://openalex.org/W2064675550",
        "https://openalex.org/W6767593240",
        "https://openalex.org/W2463456957",
        "https://openalex.org/W2982664727",
        "https://openalex.org/W2105594594",
        "https://openalex.org/W4304807927",
        "https://openalex.org/W3207878002",
        "https://openalex.org/W6745535286",
        "https://openalex.org/W2135359429",
        "https://openalex.org/W4394014474"
    ],
    "abstract": "Password generation techniques have recently been explored by leveraging deep-learning natural language processing (NLP) algorithms. Previous work has raised the state of the art for password guessing algorithms significantly, by approaching the problem using either variational autoencoders with CNN-based encoder and decoder architectures or transformer-based architectures (namely GPT2) for text generation. In this work we aim to combine both paradigms, introducing a novel architecture that leverages the expressive power of transformers with the natural sampling approach to text generation of variational autoencoders. We show how our architecture generates state-of-the-art results in password matching performance across multiple benchmark datasets.",
    "full_text": null
}