{
  "title": "AI in Investment Analysis: LLMs for Equity Stock Ratings",
  "url": "https://openalex.org/W4404350209",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5030885959",
      "name": "Kassiani Papasotiriou",
      "affiliations": [
        "Morgan Stanley (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5043221382",
      "name": "Srijan Sood",
      "affiliations": [
        "Morgan Stanley (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5064210543",
      "name": "Shayleen Reynolds",
      "affiliations": [
        "Morgan Stanley (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A5035482777",
      "name": "Tucker Balch",
      "affiliations": [
        "Emory University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2143747826",
    "https://openalex.org/W3122553568",
    "https://openalex.org/W3123783456",
    "https://openalex.org/W3121551929",
    "https://openalex.org/W4391286169",
    "https://openalex.org/W4303415434",
    "https://openalex.org/W3125916087",
    "https://openalex.org/W6811233882",
    "https://openalex.org/W4364320763",
    "https://openalex.org/W3133689835",
    "https://openalex.org/W4392366650",
    "https://openalex.org/W4398160938",
    "https://openalex.org/W4252360640",
    "https://openalex.org/W4388994251",
    "https://openalex.org/W4324268178",
    "https://openalex.org/W2914304175"
  ],
  "abstract": "Investment Analysis is a cornerstone of the Financial Services industry. The rapid integration of advanced machine learning techniques, particularly Large Language Models (LLMs), offers opportunities to enhance the equity rating process. This paper explores the application of LLMs to generate multi-horizon stock ratings by ingesting diverse datasets. Traditional stock rating methods rely heavily on the expertise of financial analysts, and face several challenges such as data overload, inconsistencies in filings, and delayed reactions to market events. Our study addresses these issues by leveraging LLMs to improve the accuracy and consistency of stock ratings. Additionally, we assess the efficacy of using different data modalities with LLMs for the financial domain. We utilize varied datasets comprising fundamental financial, market, and news data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent information leakage). Our results show that our benchmark method outperforms traditional stock rating methods when assessed by forward returns, specially when incorporating financial fundamentals. While integrating news data improves short-term performance, substituting detailed news summaries with sentiment scores reduces token use without loss of performance. In many cases, omitting news data entirely enhances performance by reducing bias. Our research shows that LLMs can be leveraged to effectively utilize large amounts of multimodal financial data, as showcased by their effectiveness at the stock rating prediction task. Our work provides a reproducible and efficient framework for generating accurate stock ratings, serving as a cost-effective alternative to traditional methods. Future work will extend to longer timeframes, incorporate diverse data, and utilize newer models for enhanced insights.",
  "full_text": "AI in Investment Analysis: LLMs for Equity Stock Ratings\nKassiani Papasotiriou\nkassiani.papasotiriou@jpmorgan.com\nJ.P. Morgan AI Research\nNew York, USA\nSrijan Sood\nsrijan.sood@jpmorgan.com\nJ.P. Morgan AI Research\nNew York, USA\nShayleen Reynolds\nshayleen.reynolds@jpmorgan.com\nJ.P. Morgan AI Research\nNew York, USA\nTucker Balch\ntucker.balch@emory.edu\nEmory University\nAtlanta, USA\nABSTRACT\nInvestment Analysis is a cornerstone of the Financial Services indus-\ntry. The rapid integration of advanced machine learning techniques,\nparticularly Large Language Models (LLMs), offers opportunities\nto enhance the equity stock rating process. This paper explores\nthe application of LLMs to predict stock performance and generate\nstock ratings by ingesting diverse datasets. Traditional stock rating\nmethods rely heavily on the expertise of financial analysts, and face\nseveral challenges such as data overload, inconsistencies in filings,\nand delayed reactions to market events. Our study addresses these\nissues by leveraging LLMs to improve the accuracy and consistency\nof stock ratings. Additionally, we assess the efficacy of using differ-\nent data modalities with LLMs for the financial domain.\nWe utilize varied datasets comprising fundamental financial,\nmarket, and news data from January 2022 to June 2024, along with\nGPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent\ninformation leakage). Our results show that our benchmark method\noutperforms traditional stock rating methods when assessed by\nforward returns. Specifically, incorporating financial fundamentals\nenhances ratings accuracy. While integrating news data improves\nshort-term performance, substituting detailed news summaries with\nsentiment scores reduces token use without loss of performance.\nIn many cases, omitting news data entirely enhances performance\nby reducing bias.\nOur research shows that LLMs can be leveraged to effectively\nutilize large amounts of multimodal financial data, as showcased\nby their effectiveness at the stock rating prediction task. Our work\nprovides a reproducible framework for generating consistent and\naccurate stock ratings, offering a cost-effective and efficient alterna-\ntive to traditional methods. Future work will extend the analysis to\nlonger time horizons, incorporating more diverse data, and utilizing\nnewer models to enhance detailed investment analysis and reports.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA\nÂ© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-1081-0/24/11. . . $15.00\nhttps://doi.org/10.1145/3677052.3698694\nACM Reference Format:\nKassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, and Tucker Balch.\n2024. AI in Investment Analysis: LLMs for Equity Stock Ratings . In\n5th ACM International Conference on AI in Finance (ICAIF â€™24), November\n14â€“17, 2024, Brooklyn, NY, USA. ACM, New York, NY, USA, 9 pages. https:\n//doi.org/10.1145/3677052.3698694\nDISCLAIMER\nThis paper was prepared for informational purposes by the Arti-\nficial Intelligence Research group of JPMorgan Chase & Co. and\nits affiliates (â€œJP Morganâ€) and is not a product of the Research\nDepartment of JP Morgan. JP Morgan makes no representation and\nwarranty whatsoever and disclaims all liability, for the complete-\nness, accuracy or reliability of the information contained herein.\nThis document is not intended as investment research or investment\nadvice, or a recommendation, offer or solicitation for the purchase\nor sale of any security, financial instrument, financial product or\nservice, or to be used in any way for evaluating the merits of par-\nticipating in any transaction, and shall not constitute a solicitation\nunder any jurisdiction or to any person, if such solicitation under\nsuch jurisdiction or to such person would be unlawful.\n1 INTRODUCTION\nInvestment Analysis is a foundational segment of the financial\nservices industry, and is crucial for the functioning of financial\nmarkets, providing essential insights that drive investment deci-\nsions, market trends, and economic policies. Financial analysts play\na key role in this process by evaluating financial data, preparing\nreports, and publishing stock ratings among other financial anlysis\ntasks. Their expertise helps in valuing assets, assessing investment\nopportunities, and formulating business decisions. By interpreting\ncomplex financial information, their analyses help mitigate risks\nand identify opportunities for investors [11].\nA crucial task of a financial analyst is to publish stock ratings,\nwhich evaluate a companyâ€™s future performance based on forward\nprojections of a companyâ€™s fundamentals, including earnings, rev-\nenue growth, and cash flow, as well as broader market conditions\nand economic trends. They consist of analystsâ€™ expert recommen-\ndations on how to position companies over the next quarter to a\nyear and thus play a pivotal role in shaping market perceptions\n[26]. These ratings are among many variables used to evaluate\ncompanies in the investment analysis domain.\nIn recent years, these methods have been complemented by\nadvanced machine learning techniques, such as Deep Learning\narXiv:2411.00856v1  [cs.LG]  30 Oct 2024\nICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, and Tucker Balch\nmethods and Large Language Models (LLMs) [16, 34]. LLMs, with\ntheir zero-shot and few-shot learning capabilities, can perform a\nwide range of tasks without costly fine-tuning. They offer advanced\nreasoning capabilities and can efficiently handle large volumes of\ndiverse unstructured data, making them useful in financial analysis.\nSpecifically, LLMs can answer questions, summarize information,\nwrite content, and handle multiple tasks simultaneously, augment-\ning the workflow of financial analysts. They significantly enhance\nthe process of generating stock ratings by analyzing financial re-\nports, assessing the sentiment of news articles, evaluating market\ncommentaries, and more.\nPredicting stock ratings is a challenging task due to the complex-\nity and dynamic nature of financial markets, but there are several\nopportunities where LLMs can help: 1) Analysts must process and\nanalyze vast volumes of complex data, and LLMs can assist by effi-\nciently ingesting large datasets. 2) LLMs can generate predictions\non demand. 3) LLMs can incorporate information from multiple\ndata sources and modalities which can help reduce bias [20, 26].\nThis study employs an instruction-based general purpose LLM\nfor predicting stock ratings, an under-explored area in research.\nWe utilize various data types such as fundamental financial data\n(tabular/semi-structured), market data (timeseries), and news data\n(unstructured), from January 2022 to June 2024. We specifically use\nGPT-4-32k (v0613), trained on data up until September 2021 [23]\nto avoid information leakage. It is important to note that future\ndata leakage is not often accounted for in studies that utilize AI in\nthe financial services domain, which can lead to overly optimistic\nperformance results.\nOur method explores best practices for enabling LLMs to utilize\nvarious modalities of financial data, and demonstrates its effec-\ntiveness at stock rating predictions. Since we do not fine-tune the\nmodel, the process remains cost-effective. When evaluated based\non forward returns, our method outperforms financial analysts in\nour experiments. This highlights the potential of utilizing LLMs in\nthe financial analysis pipeline.\nOur key contributions are as follows:\n(1) We demonstrate the novel use of an LLM for predicting stock\nratings, addressing a significantly under-researched area.\n(2) We evaluate the performance of LLMs in this task to de-\ntermine which data sources enhance or impede predictive\ncapabilities over various time horizons.\n(3) We build a reproducible framework to quickly and consis-\ntently generate ratings evaluated by forward-returns.\n(4) We address both the prediction of stock ratings and subse-\nquent stock price movements, providing a comprehensive\nview of utilizing LLMs in the financial forecasting process.\n2 BACKGROUND AND RELATED WORK\nIn this section, we first focus on the powerful capabilities of general\npurpose LLMs in finance and how AI has been increasingly inte-\ngrated in the domain. We speak specifically to tasks within the area\nof investing, discussing the importance of AI in financial analysis\nin conducting these tasks. Finally, we discuss the ratings produced\nby financial analysts, their impact on the market and the various\nways AI has been integrated to enhance the process.\n2.1 LLMS in Finance\nZero-shot and few-shot LLM techniques are widely applied in the\ndomain of finance. For example, [9, 37] demonstrate using LLMs for\nidentifying sentiment and summarization of financial news, respec-\ntively, using instruction based prompting techniques. [28] evaluates\ncomplex question answering (QA) techniques on semi-structured\nfinancial documents. [17] assesses LLM performance (ranging from\ngeneral purpose LLMs to fine-tuned) on QA and summarization\nfor financial documents, text classification, generation, stock move-\nment prediction and more, demonstrating many applications for\nLLMs in finance.\nThe commonalities among research utilizing LLMs for prediction\ninclude using diverse datasets, employing LLMs at multiple stages\nand enhancing interpretability. The integration of the capabilities\nhighlighted above and advancements in LLMs significantly enhance\nfinancial tasks such as stock movement prediction, risk mitigation\nand quantitative trading. [ 21] uses GPT to predict stock market\nreturns from news headline sentiment scores and finds a positive\ncorrelation, outperforming older GPTs and BERT in forecasting\nreturns, as evaluated by the Sharpe Ratio. [10], [30], and [18] uti-\nlize several sources of data such as financial news, fundamentals,\nstock prices, market data and macroeconomic factors to aid in stock\nprediction. [10] applies Chain-of-Thought (CoT) prompting and In-\nContext Learning with GPT-4 to generate signals and subsequently\nranking strategies that show positive percentage returns on selected\nstocks. [7] leverages LLMs to analyze and predict financial risks\nby combining data from earnings calls, market-related time series\ndata, and contextual news data. For quantitative trading, a popular\navenue of research utilizes memory modules and knowledge bases\nto aid in a modelâ€™s self-adaptability. [19, 35] built LLM-based au-\ntonomous trading agents that utilize layered memory. [31] built a\nself-improving LLM using an agent that refines its responses with\na knowledge base and then tests responses in real-world scenarios\nto update the knowledge base with new insights.\n2.2 Analyst Stock Ratings\nAn analyst stock rating forecasts a stocks performance. In the most\ncommon scenario, analysts publish ratings upon the release of\nquarterly filings, earnings calls, or significant events, updating their\nguidance for the next quarter, and for rest of the year. These ratings\nfall into five categories, though terminology may vary:\nâ€¢Strong Buy /Buy: Indicates that the stock is expected to\nsignificantly outperform the market or its sector.\nâ€¢Moderate Buy: Suggests that the stock is expected to per-\nform better than the market average or its sector. Also re-\nferred to as Outperform or Overweight.\nâ€¢Hold: Indicates that the stock is expected to perform in line\nwith the market or its sector.\nâ€¢Moderate Sell: Suggests that the stock is expected to per-\nform worse than the market average or its sector. Also re-\nferred to as Underperform or Underweight.\nâ€¢Strong Sell/Sell: Indicates that the stock is expected to un-\nderperform its benchmark significantly.\nDifferent institutions utilize custom rating scales, which can vary\nbetween organizations. For example, some analysts use a one-to-five\nrating system based on risk-adjusted performance, others employ\nAI in Investment Analysis: LLMs for Equity Stock Ratings ICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA\na buy, hold, sell system, while certain firms use proprietary aggre-\ngated scores that combine ratings from multiple research providers.\nThese rating scales are useful because they provide investors with\ntailored insights and help them make informed decisions based on\ndifferent analytical perspectives.\nAnalysts utilize past and current qualitative and quantitative\ninformation about a companyâ€™s performance, [ 33, 36] and based\non these evaluations and their experience, they recommend stock\nratings that are used by investors to make decisions regarding an\nasset [11, 20]. Common data includes: 1) Fundamental and technical\nanalysis: Assesses intrinsic value and trading trends using metrics\nlike earnings-per-share, shares outstanding, return on assets, price,\nvolume, and more. 2) Company and sector news: Considers manage-\nment changes, product launches, mergers, and regulatory develop-\nments. 3) Market and sector performance: Evaluates overall market\ntrends, sector performance, and price movements [11, 15, 36].\n2.3 Importance of Stock Ratings\nAs mentioned in section 2.1, while research on company perfor-\nmance prediction shows promising results, it often overlooks stock\nratings, a key indicator of future stock performance. Investors use\nstock ratings for many tasks such as portfolio building, risk assess-\nment, asset allocation and other investment strategies[ 5, 13, 27].\nStudies on how ratings impact the market reveal that investors\nclosely monitor these ratings to make informed decisions, leading\nto market movements based on ratings. For example, [26] analyzes\n20 years of S&P500 trading data, developing a classifier that predicts\n1% price changes up to 10 days ahead with 83.62% accuracy, 85%\nprecision for buy signals, and 100% recall for sell signals. Feature\nranking highlights analyst stock ratings as top contributors. [14]\nevaluates the impact of analystsâ€™ recommendations in G7 countries,\nfinding significant stock price reactions to recommendation revi-\nsions in all countries except Italy, with the US showing the largest\nprice reactions and post-revision price drifts. [4] evaluates the im-\npact of analyst stock changes, finding that influential recommenda-\ntions are linked to increased stock volatility and significant changes\nin consensus earnings forecasts. [36] examines the profitability of\nanalystsâ€™ recommendations in the Polish market using data from\n2004-2013. It builds market-neutral portfolios and tests their perfor-\nmance against CAPM, Fama-French, and Carhart models. The key\nfinding is that strategies based on analystsâ€™ recommendations yield\nstatistically significant positive abnormal returns, demonstrating\ntheir profitability.\n3 METHODOLOGY\nWe leverage LLMs to analyze financial data and generate stock\nratings, taking advantage of their ability to process large volumes\nof information, recognize complex patterns, and adapt to new data.\nLLMs can efficiently handle diverse data sources and provide de-\ntailed insights that traditional methods might miss. Our goal is to\nprovide the LLM with the same information an analyst would con-\nsider, such as financial fundamentals, stock price movements, news\nsummaries, sentiment, and other relevant data. This helps us assess\nthe feasibility of using LLMs for investment analysis and identify\nthe techniques and information that improve their performance.\n3.1 Prompt Structure\nWe utilize GPT-4-32k (v0613), hosted on Azure, which features\na context window of 32,000 tokens and is trained on data up to\nSeptember 2021 [23]. We specifically selected this model to prevent\ninformation leakage, as the data we use is from after the modelâ€™s\ntraining cut-off date.\nWe use the system prompt to instruct the LLM to adopt the\npersona of a financial analyst. By defining this role, we provide\nthe LLM with a clear framework for its function. Additionally, we\ncontextualize the financial terms utilized in the experiments by\ndefining the scale of stock ratings and their definitions (Section 2.2),\nincorporating synonyms to account for variations in terminology.\nWe also provide detailed descriptions of financial fundamentals,\nwhich are outlined in 4.1.\nTo design the user prompt, we follow the success of Chain-of-\nThought and few-shot prompt approaches [6, 32], and encourage\nthe LLM to engage in reasoning before making its final prediction\nand provide it with an example of what the output should look like.\nAdditionally, we provide company-specific input data in a struc-\ntured format, with textual information first followed by numerical\ndata in tables, following findings from [29]. We also perform basic\nCoVE (chain of verification) to detect if itâ€™s is predicting things for\nthe correct dates.\n3.2 Problem Formulation\nLet ratingğ‘ (ğ‘¡, ğ‘)be a rating for a company ğ‘ released on date ğ‘¡,\npredicting the companyâ€™s performance at a future horizon of ğ‘\nmonths. The rating can take any of the following ordinal values:\nratingğ‘ (ğ‘¡, ğ‘)âˆˆ{âˆ’ 2, âˆ’1, 0, 1, 2}\nwhere -2 = Strong Sell, -1 = Moderate Sell, 0 = Hold, 1 = Moderate\nBuy, and 2 = Strong Buy.\nWe assess the accuracy of a rating by evaluating how the com-\npanyâ€™s stock performs. This approach is commonly used in tech-\nnical papers that utilize future returns. For example, to assess the\nvalue of analyst stock ratings [ 12] investigates the performance\nof stocks shortly after ratings are published, while [ 3] analyzes\nthe distribution of analyst stock ratings over time, using company\nreturns in quintiles to predict potential profitability. [4] evaluates\nchanges in analyst stock ratings by comparing company returns\nacross different rating levels.\nTo determine the accuracy of a rating ratingğ‘ (ğ‘¡, ğ‘), we evaluate\nthe performance of company ğ‘ using its forward returns (at period\nğ‘¡ +ğ‘), and compare it to other companies. This is done by computing\ncompany returns for the entire group (e.g. S&P500 constituents) at\na fixed time horizon, and then dividing these into quintiles. The\nquintile groups correspond to rating levels, e.g., companies with\nreturns in the lowest quintile significantly underperformed their\npeers, making their ground truth rating a Strong Sell.\nOur process is as follows. We first calculate forward company\nreturns as well as market and sector relative returns:\nGiven the price for company ğ‘ at time ğ‘¡, ğ‘ƒğ‘ (ğ‘¡), the company\nreturn ğ‘…ğ‘ (ğ‘¡, ğ‘)over the period ğ‘ is defined as:\nğ‘…ğ‘ (ğ‘¡, ğ‘)= ğ‘ƒğ‘ (ğ‘¡ +ğ‘)âˆ’ğ‘ƒğ‘ (ğ‘¡)\nğ‘ƒğ‘ (ğ‘¡)\nICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, and Tucker Balch\nThe sector-relative forward return ğ‘…ğ‘,ğ‘  (ğ‘¡, ğ‘)is defined as:\nğ‘…ğ‘,ğ‘  (ğ‘¡, ğ‘)= ğ‘…ğ‘ (ğ‘¡, ğ‘)âˆ’ğ‘…ğ‘  (ğ‘¡, ğ‘)\nwhere the sector return ğ‘…ğ‘  (ğ‘¡, ğ‘)over the same period ğ‘ is:\nğ‘…ğ‘  (ğ‘¡, ğ‘)= ğ‘ƒğ‘  (ğ‘¡ +ğ‘)âˆ’ğ‘ƒğ‘  (ğ‘¡)\nğ‘ƒğ‘  (ğ‘¡)\nFor a rating released on date ğ‘¡ with a horizon of ğ‘, we compute\nthe quantiles of returns across all companies ğ‘ at ğ‘¡ +ğ‘ and assign\neach company the quantile that their returns fall into. If the returns\nquantile matches the rating, then the rating is considered correct.\nLet ğ‘„ğ‘ (ğ‘¡, ğ‘)represent the quantile of the company returnsğ‘…ğ‘ (ğ‘¡, ğ‘),\nğ‘„ğ‘,ğ‘š (ğ‘¡, ğ‘)represent the quantile of the market-relative returns\nğ‘…ğ‘,ğ‘š (ğ‘¡, ğ‘), andğ‘„ğ‘,ğ‘  (ğ‘¡, ğ‘)represent the quantile of the sector-relative\nreturns ğ‘…ğ‘,ğ‘  (ğ‘¡, ğ‘).\nWe define the indicator function for the correctness of the rating\nratingğ‘ (ğ‘¡, ğ‘)with respect to the absolute performance quantile\nğ‘„ğ‘ (ğ‘¡, ğ‘)as follows:\nI(ratingğ‘ (ğ‘¡, ğ‘)= ğ‘„ğ‘ (ğ‘¡, ğ‘))=\n(\n1 if ratingğ‘ (ğ‘¡, ğ‘)= ğ‘„ğ‘ (ğ‘¡, ğ‘)\n0 otherwise\nSimilarly, for sector-relative returns:\nIsector (ratingğ‘ (ğ‘¡, ğ‘)= ğ‘„ğ‘,ğ‘  (ğ‘¡, ğ‘))=\n(\n1 if ratingğ‘ (ğ‘¡, ğ‘)= ğ‘„ğ‘,ğ‘  (ğ‘¡, ğ‘)\n0 otherwise\n4 EXPERIMENTS\nIn this section we provide an overview of the data we use as well\nas our experiment set up.\n4.1 Data\nOur analysis focuses on US equities, specifically the 500 constituents\nof the S&P 500 index, using data spanning from January 2022 to\nthe end of June 2024.\nAnalyst Stock Ratings: We gather analyst stock ratings for each\ncompany in the S&P500 [1]. Out of a total of 45,000 ratings from 126\nfirms, the majority of ratings (75.90%) were maintained, followed by\nreiterate (7.25%), downgrade (6.27%), upgrade (5.68%), and initiate\n(4.89%). The top five firms, which include Morgan Stanley, Barclays,\nWells Fargo, Citigroup, and RBC Capital, collectively account for\n31.61% of all ratings. Specifically, Morgan Stanley contributed 9.99%,\nBarclays 6.52%, Wells Fargo 5.91%, Citigroup 4.67%, and RBC Capital\n4.52% of the total ratings. This dataset comprises the firm issuing\nthe rating, the date of the rating, and the rating itself. However, we\ndo not have data for the target date or the target price. Note that\nfor a particular date and company, there may be multiple ratings\nissued by different firms.\nFinancial News Summaries: We collect news articles for stocks\nin the S&P500 [1] [25] [8]. We filter irrelevant content out by per-\nforming named entity recognition (NER), utilizing both company\nnames and possible company aliases to enhance this process (alias\nwere also scraped from [1]). After filtering down to relevant data,\nour dataset consists of the following: on average per month, there\nare 39.63 articles, 187K characters, and 40K tokens, with 74.70 URLs\nand 34.40 missing articles per ticker. We summarize the monthly\nnews for each company and sector using GPT-4-32k (v0613) to\nhighlight key events and trends. Our system prompt designates the\nuser as an expert news summarizer, tasked with condensing articles\ninto concise summaries that highlight key events and important\ninformation, while excluding irrelevant content. We utilize two user\nprompts, one to create summaries for both individual companies,\nand another to summarize news across an entire sector, identifying\ngeneral themes and trends.\nFinancial News Summaries Sentiment : We utilize GPT-4-32k\n(v0613) to identify the sentiment of the financial news summaries\non the company and sector level. The system prompt assigns the\nuser the role of an expert in news sentiment scoring, particularly\nfor financial markets, using a scale from -5 to 5 to indicate the\nsentimentâ€™s severity. We utilize two user prompts, one to score\nthe sentiment of news summaries for individual companies, and\nanother for scoring sentiment at the sector level. Each template\nprovides specific instructions and examples to ensure consistency\nand accuracy in summarization and sentiment scoring.\nHistorical Returns: For a similar time frame as the news sum-\nmary data, we collect daily stock prices for companies in the S&P500\nand compute technical indicators using the prices [1]. The metrics\ninclude current price, the 52-week price range, 90-day volatility,\nand performance metrics over 1-month, 3-month, and 12-month\nperiods. The performance metrics are divided into returns, market\nrelative returns, and sector relative returns.\nFigure 1: Financial Fundamentals Example: AAPL\nFinancial Fundamentals:\nWe aggregate quarterly company fundamentals from 10-Q and\n10-K filings from January 2022 to March 2024 using finagg API [22]\nto access the SEC API [24]. We use the past 4 quarterly fillings avail-\nable for each prediction date. These filings, submitted by companies\nto the U.S. Securities and Exchange Commission (SEC), provide\ndetailed information on their balance sheet, income statements,\nand cash flow statements. Metrics provided to LLM are listed in\nFigure 1.\n4.2 Experiment Setup\nWe utilize GPT-4-32k (v0613), hosted on Azure, which features\na context window of 32,000 tokens and is trained on data up to\nAI in Investment Analysis: LLMs for Equity Stock Ratings ICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA\nSeptember 2021 [23]. We specifically selected this model to prevent\ninformation leakage, as the data we use is from after the modelâ€™s\ntraining cut-off date.\nEach experiment involves asking the LLM to generate stock rat-\nings at the beginning of each month from January 2022 to June\n2024 for every company in the S&P500. Specifically, for each com-\npany, we let the LLM know that it needs to issue a rating at the\nstart of a given month. We provide it with additional data (which\nvaries between experiments as described below) and ask it to pre-\ndict whether the stock should be rated as Strong Sell, Moderate\nSell, Hold, Moderate Buy, or Strong Buy, for multiple future time\nhorizons: 1, 3, 6, 12, and 18 months. For example, we ask the LLM\nto predict the rating it would release in March 2022 for future dates\nsuch as April 2022, June 2022, September 2022, March 2023 and\nSeptember 2023.\nFor each method, this results in approximately 5 (horizons) * 30\n(start dates) * 500 (companies) ratings. Using multiple time horizons\nallows us to account for the uncertainty around the exact target\ndate of the analystâ€™s rating, enabling us to assess predictions at\nseveral points in the future. Additionally, varying time horizons\nhelps us evaluate the LLMâ€™s predictive performance across different\nperiods.\n4.2.1 Methods. We conduct experiments with five distinct meth-\nods: Vanilla, News, Sentiment, Fundamentals, and Fundamentals +\nSentiment. All of these methods utilize GPT-4-32k (v0613), but with\nvarying data provided to the model in its input context. We provide\nthe LLM with the task description (as highlighted in Section 3.1.\nFor each query, we include the name of the company, the date on\nwhich the ratings will be released, and the five forward-looking\ntime horizons for which it needs to generate ratings. Inspired by\nthe chain-of-thought prompting framework, we also ask the LLM\nto output the corresponding price targets, along with a short expla-\nnation. We check the LLMâ€™s response to verify that it is computing\nthe dates which each time horizon corresponds to correctly.\nVanilla: The input context includes a snapshot of the companyâ€™s\nhistorical data: returns, market-relative returns, and sector-relative\nreturns for the past 1-month, 3-month, and 12-month periods. Ad-\nditionally, we provide the current stock price (as of rating date), the\n52-week price range (min, max), and the 90-day volatility (std. dev.\nof daily returns). In total, the LLM receives 10 values describing\nhistorical returns (1 for volatility), plus 3 values relating to the\nstock price (current and 52-week min-max), for a total of just 13\nnumbers. We found that these simple data points greatly improve\nthe LLMâ€™s ability to generate accurate ratings. This setting serves\nas our baseline for the following experiments.\nNews: This experiment enhances the input prompt for theVanilla\nmethod by including news data. As it is not pragmatic to include en-\ntire news articles due to LLM context limits, we provide summaries\nof company news and sector news from the previous month. In\naddition to the outputs described above, the LLM is also tasked with\nassessing the sentiment of the news summaries provided (positive,\nnegative, neutral, or mixed), and to use this in its predictions. We\nfound improved performance when the LLM receives the news sum-\nmaries earlier in the context (before the technical indicators). Given\nthe success of in-context learning, we also provide the LLM with\nan example: the input data as described, along with the expected\ndates, an explanation of the ratings, and the corresponding rating\noutput to guide its predictions. We use the dates as a hallucination\ncheck, incorporating a Chain of Verification (CoVE) to ensure that\nthe predicted dates are correct, as they are a straightforward as-\npect to verify. If the LLM fails to get the dates right, it suggests\nthat correctly predicting the ratings would likely be even more\nchallenging.\nSentiment: This experiment is similar to Vanilla, save for one\nkey difference â€” the inclusion of pre-computed news sentiment\n(also computed using GPT-4-32k (v0613)). Unlike the News experi-\nment, which provides the LLM with descriptive news summaries,\nthis method supplies the LLM with two sentiment scores, one for\ncompany news sentiment, and one for sector news sentiment, from\nthe previous month. The summaries used in the sentiment scor-\ning process are the same as the ones provided to the LLM in the\nNews method. The sentiment scores range from -5 to 5, capturing\na a spectrum of sentiment from extremely negative to extremely\npositive.\nFundamentals: This method augments the Vanilla prompt with\nquarterly financial fundamental data. The model is supplied with\ncompany financial metrics and detailed descriptions of each metric.\nThe system instructions for the LLM are updated with definitions of\nthe fundamental features. The LLM is tasked with analyzing these\nnumbers in its process. The fundamentals, as show in Figure 1, are\nprovided to the LLM in an HTML format, as HTML seems outper-\nform other formats for LLM ingestion, as mentioned in Section 3.1.\nFundamentals + Sentiment : This experiment builds upon the\nFundamentals method by also including the sentiment scores used\nin the Sentiment method; the setup is similar, with two scores cap-\nturing company sentiment and sector sentiment from news from\nthe previous month. The model is prompted to use both the funda-\nmental data and sentiment scores to make its recommendations.\n4.3 Evaluation\nWe evaluate ratings based on forward returns over 1, 3, 6, 12, and 18-\nmonth periods, including evaluations for market-relative and sector-\nrelative returns. As described in Section 3.2, a rating is considered\ncorrect if the quantile for the true forward return aligns with the\nratingâ€™s rank. For example, letâ€™s take a rating for a given company\n(whether from an analyst or LLM), with a 6-month horizon. Suppose\nthe stock was rated as a Strong Buy for the 6-month horizon, and\nthe companyâ€™s 6-month forward return falls in the bottom quantile\n(based on 6-month forward returns from the same date for all\ncompanies). This constitutes a significantly incorrect rating, as the\ncompany was amongst the worst performers in the market, but was\nrated as a Strong Buy. The ground-truth rating in this case would\nhave been a Strong Sell. Conversely, if another method generated a\nrating of Hold for the same <company,date,horizon> combination,\nthe rating would still be incorrect, but less severely so.\nWe compute the Mean Absolute Error (MAE) using two types\nof returns â€” regular market-relative forward returns (these auto-\nmatically become market-relative due to our quantile ranking eval-\nuation), and sector-relative forward returns (where the subsectorâ€™s\nforward return is subtracted from the asset return). MAE is appro-\npriate for ordinal classification because it considers the magnitude\nof the error and accounts for how far a rating is from its true value.\nICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, and Tucker Balch\nRatings further away from the ground-truth are penalized more.\nAccuracy, a popular metric for classification tasks, treats all errors\nequally, regardless of their severity. Since we have a balanced dis-\ntribution of classes (due to quantization), MAE doesnâ€™t need to be\nadapted, however metrics such as macro-averaged MAE [2] can be\nutilized in those scenarios.\nWe compute a composite error to compare methods more eas-\nily; we average the marker-relative return based MAE over the three\nmost common time horizons in this domain â€“ 3, 6, and 12-month\nperiods â€“ as the 1-month rating is usually too soon to be useful. We\nexclude the 18-month predictions from this score because ratings\nare typically intended for up to one year, and analysts usually up-\ndate their ratings for longer-term horizons. Table 1 presents these\nvalues. We also present a monthly breakdown of performance of all\nmethods across 1, 3, 6, 12, and 18-month periods. Figure 3 displays\nthese results.\nPlease note Analyst represents the real-world ratings from fi-\nnancial analysts across various Wall Street firms, which we measure\nagainst the LLMâ€™s predictions.\n5 RESULTS\nOur findings from the month-wise breakdown of themarket-relative\nMAE and sector-relative MAE across all methods. Figure 3 visualizes\nhow the methods stack up to each other, including a snapshot\ncomparison using the composite error (also listed in Table 1). Note\nthat the figures are based on the market-relative MAE.\nStrong Sell Moderate Sell Hold Moderate Buy Strong Buy\nRating\n0\n5\n10\n15\n20\n25\n30\n35\n40Percentage (%)\n4\n1\n34\n18\n43\n3\n22\n26\n34\n14\n1\n16\n23\n37\n23\n2\n17\n24\n36\n22\n6\n23\n26\n33\n13\n4\n21\n26\n35\n14\nDistribution of Ratings across Methods\nMethod\nAnalyst\nVanilla\nNews\nSentiment\nFundamentals\nFundamentals + Sentiment\nFigure 2: Value Counts of Ratings Across All Months for All\nExperiments\nModel Return MAE Â± Std Sector Rel Return\nMAE Â± Std\nAnalyst 1.570 Â± 0.637 1.591 Â± 0.648\nVanilla 1.447 Â± 0.745 1.459 Â± 0.749\nNews 1.491 Â± 0.738 1.513 Â± 0.744\nSentiment 1.496 Â± 0.752 1.512 Â± 0.755\nFundamentals 1.421 Â± 0.732 1.439 Â± 0.739\nFundamentals +\nSentiment\n1.417 Â± 0.747 1.441 Â± 0.752\nTable 1: Evaluation Averaged Across 3, 6, and 12 Month Peri-\nods for Experiments\n5.1 Traditional Analyst vs. Vanilla LLM\nFigure 2 shows how analysts are heavily biased towards buy ratings,\nand only gave sell ratings less than 5% of the time. In Table 1, the\nVanilla method has a lower MAE of 1.447 compared to the Analyst\npredictions, which has a Return MAE of 1.570. This indicates that\nthe LLMs predictions, even with only basic financial data, are more\naccurate than those made by analysts. However, the standard de-\nviation of the Vanilla method is 0.745, higher than the Analystâ€™s\n0.637, suggesting that while the predictions are more consistent,\nthey are less accurate overall. Sector Return MAE and standard\ndeviation follow the same trend. Figure 3 shows that errors for the\nAnalyst predictions decrease as the look-ahead periods increase,\nwith slightly better performance in the 18-month period, while\nerrors for Vanilla experiment increase.\n5.2 News: Summary vs. Sentiment\nTable 1 shows that the News (Summary) experiment, which we\nprovide the previous monthâ€™s news summaries for the company\nand the sector, results with a Return MAE of 1.491 and a standard\ndeviation of 0.738. The News (Sentiment) experiment, which we pro-\nvide sentiment scores of the news summaries instead of summaries\n(scored on a scale of -5 to 5), results in a Return MAE of 1.496 and\na standard deviation of 0.752. Interestingly, neither outperformed\nthe Vanilla experiment. Additionally, we did not see improved per-\nformance when including summaries compared to only including\ntheir sentiment. The trends for Sector Relative Return MAE are\nconsistent with the Return MAE metrics. Figure 3 shows that the\nNews (Summary) experiment performs best in the 1-month period,\noutperforming all other experiments in both Return and Sector\nMAE. This suggests news summaries provide better short-term\npredictions, likely because we include summaries from the previ-\nous month, therefore offering a clearer picture of recent company\nperformance. The News (Sentiment) experiment performs similarly\nto the News (Summary) experiment, indicating that incorporating\nsentiment does not significantly improve performance compared\nto news summaries.\n5.3 Fundamentals vs. Fundamentals +\nSentiment\nTable 1 shows that the Fundamentals + Sentiment experiment has\nthe best performance in terms of Return MAE, with a value of 1.417,\nindicating the most accurate predictions. The Fundamentals experi-\nment has a Return MAE of 1.421 and a lower standard deviation of\n0.732, indicating more consistent predictions.\nFigure 3 shows that both the Fundamentals and Fundamentals\n+ Sentiment experiments consistently perform best across most\nmonths, particularly excelling in the 3, 6, and 12-month periods.\nThis stable performance across horizons reinforces the benefits\nof incorporating fundamental financial data. The Fundamentals +\nSentiment experiment outperforms in the 3 and 6-month periods,\ndemonstrating that combining fundamentals and sentiment scores\nis effective in the short term but may lead to conflicting signals\nover longer periods, as indicated by the higher MAE in the 18-\nmonth period. Both models outperform the Vanilla experiment and\nAnalyst predictions, highlighting the significant impact of financial\nfundamentals. Including company and sector sentiment, without\nAI in Investment Analysis: LLMs for Equity Stock Ratings ICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA\n1 3 6 12 18\nTime Horizon (Months)\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\nMean Absolute Error\n(MAE)\nRatings Prediction Error across Time Horizons\nMethod\nAnalyst\nVanilla\nNews\nSentiment\nFundamentals\nFundamentals + Sentiment\nMethod\n0.2\n0.4\n0.6\n0.8\n1.0\n1.2\n1.4\n1.6\n1.8MAE\n1.570\n1.447 1.491 1.496\n1.421 1.417\nAnalyst\nVanilla\nNews\nSentiment\nFundamentals\nFundamentals + Sentiment\nComposite Mean Error\n(Averaged across 3, 6, and 12 Months)\nFigure 3: Ratings Prediction Error (MAE) across different time horizons. a) Mean, Standard Deviation for each technique and\ntime horizon. b) Composite Mean Error (MAE averaged across 3,6,12-month time horizons).\nthe actual news summary data, improves prediction accuracy, likely\ndue to decreased complexity and noise from news data.\n5.4 Results Summary\nOverall, for all LLM experiments (Vanilla, News (Summary), News\n(Sentiment), Fundamentals and Fundamentals + Sentiment) , the er-\nrors increase as we make predictions further into the future, in-\ndicating that the LLMs are better at short-term predictions and\nstruggle with longer-term forecasts. News-based experiments (es-\npecially News (Summary)) perform best in the short term due to\nthe immediate impact of news. We find that the News (Sentiment)\nexperiment generally performs similarly to the News (Summary)\nexperiment, indicating that incorporating sentiment analysis does\nnot significantly improve performance compared to providing news\nsummaries. Fundamentals and Fundamentals + Sentiment experi-\nments also perform similarly, excelling in the medium term. Finally,\nAnalyst predictions show the best performance over longer periods.\n5.5 Efficacy of News\nTo understand the impact of news summaries on the results, we\ncompute the Spearman correlation and generate heatmaps for the\nnews summaries and news sentiment. In the News experiment, we\nask the LLM to provide a rating for the company news summary\nand the sector summary before predicting the stock ratings. For\nthe Sentiment experiment, we score each sector and news summary\nfor its sentiment and then provide these sentiment scores during\ninference instead of the news summaries. In both cases, we observe\nthat news summaries are correlated across months, especially with\nthe periods closer to the rating. Additionally, the heatmaps Figure 4\nreveal that LLM ratings are correlated with the predictions made\nfor the previous period. Moreover, Figure 2 show how utilizing\nnews-derived data biases the model to make more positive ratings.\nAdditionally, Figure 4 shows a strong positive correlation be-\ntween the LLMâ€™s ratings and the sentiment score derived from the\nnews summaries, indicating that more positive sentiment leads to\nmore favorable LLM ratings. This influence of news sentiment is re-\nflected in the distribution of ratings, where we observe an increase\nin positive ratings, contributing to less accurate ratings.\n5.6 Challenges and Limitations\nOne limitation of this study is our method of evaluating ratings,\nwhich is based on forward returns over fixed periods and the quan-\ntiles into which these returns fall. These returns could be sensitive\nto market conditions, which might experience abnormal shifts on\nspecific days, thereby affecting the evaluation. Additionally, there\nare other factors that determine if the ratings were correct or not,\nwhich might be more qualitative than quantitative, such as market\nsentiment, company-specific news, and broader economic indica-\ntors. Moreover, our approach to evaluating the analysts was tricky\nsince we did not have the exact target date for the ratings (hence an\nassessment with varied time horizons). Another challenge is that\nwe did not provide the model with many essential factors that ana-\nlysts consider, such as projections of future performance, earnings\ncall reports, investor sentiment, and other qualitative assessments.\nAdditionally, we did not test the modelâ€™s ability to process and un-\nderstand extremely large amounts of information, which analysts\noften review in their evaluations.\nICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA Kassiani Papasotiriou, Srijan Sood, Shayleen Reynolds, and Tucker Balch\n1 3 6 12 18\nTime Horizon (Months)\nCompany NewsSector News\nSentiment T ype\n0.44 0.48 0.42 0.38 0.29\n-0.033 0.017 0.051 0.069 0.083\nCorrelation between LLM Outputs: Sentiment and Rating\n0.4\n0.2\n0.0\n0.2\n0.4\nOne-shot sentiment from news summaries: [positive, negative, neutral/mixed]\n1 3 6 12 18\nTime Horizon (Months)\nCompany NewsSector News\nSentiment T ype\n0.39 0.47 0.44 0.35 0.18\n0.054 0.1 0.15 0.15 0.12\nCorrelation between LLM Outputs: Sentiment and Rating\n0.4\n0.2\n0.0\n0.2\n0.4\nPrecomputed sentiment score from news summaries: [-5 to 5]\nFigure 4: Correlation between LLMâ€™s sentiment prediction\nand ratings across time horizons for two methods: News (top)\nand Sentiment (bottom).\n6 CONCLUSION\nThis study explores the potential of LLMs to predict stock ratings, a\nnovel application within the finance sector. By integrating various\ntypes of information, including basic financial metrics, technical\nindicators, financial news summaries financial news sentiment, and\nfinancial fundamentals, we aim to evaluate the performance of\nLLMs in this task and understand which data sources enhance or\nhinder their predictive capabilities.\nKey Findings:\n(1) The benchmark Vanilla LLM model, which uses basic fi-\nnancial metrics, demonstrates stronger performance than\ntraditional analyst evaluations when assessed by forward\nreturns.\n(2) The Fundamental LLMs outperformed all experiments, high-\nlighting the significant impact of financial fundamentals\non prediction accuracy. Additionally, combining sentiment\nscores with this data, without the full news summaries, fur-\nther improved prediction accuracy.\n(3) Integrating news summaries and sentiment analysis provides\nsome short-term predictive benefits but does not significantly\nimprove long-term prediction accuracy when compared to\nthe Vanilla model.\n(4) The performance difference between adding news as text\nversus news sentiment to the LLM is very small when other\ndata is not included (i.e. Fundamentals), indicating that both\napproaches offer similar benefits.\n(5) LLMs perform better in short-term predictions, which en-\ncourages further exploration of their capabilities for shorter\nperiod company predictions.\n(6) News summaries are more beneficial for short-term predic-\ntions, while traditional analysts perform better over longer\nhorizons.\nOur findings highlight the significant potential of LLMs to pro-\nvide accurate and interpretable predictions for stock ratings. Future\nwork will focus on using longer windows for news summaries, sum-\nmarizing over extended periods to provide a more comprehensive\ncontext. Additionally, we will further explore the capability of LLMs\nin short-term predictions and develop strategies to enhance their\nlong-term forecasting abilities.\nREFERENCES\n[1] Ran Aroussi. 2023. yfinance: Yahoo! Finance market data downloader. https:\n//github.com/ranaroussi/yfinance. Accessed: 2024-10-08.\n[2] Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2009. Evaluation Mea-\nsures for Ordinal Regression. In 2009 Ninth International Conference on Intelligent\nSystems Design and Applications . 283â€“287. https://doi.org/10.1109/ISDA.2009.230\n[3] Brad M. Barber, Reuven Lehavy, Maureen McNichols, and Brett Trueman. 2006.\nBuys, holds, and sells: The distribution of investment banksâ€™ stock ratings and\nthe implications for the profitability of analystsâ€™ recommendations. Journal of\nAccounting and Economics 41, 1 (2006), 87â€“117. https://doi.org/10.1016/j.jacceco.\n2005.10.001\n[4] Brad M Barber, Reuven Lehavy, and Brett Trueman. 2010. Ratings changes,\nratings levels, and the predictive value of analystsâ€™ recommendations. Financial\nManagement 39, 2 (2010), 533â€“553.\n[5] Nerissa C Brown, Kelsey D Wei, and Russ Wermers. 2014. Analyst recommen-\ndations, mutual fund herding, and overreaction in stock prices. Management\nScience 60, 1 (2014), 1â€“20.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,\nRewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter,\nChris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin\nChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\nSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.\nIn Advances in Neural Information Processing Systems , H. Larochelle, M. Ran-\nzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates,\nInc., 1877â€“1901. https://proceedings.neurips.cc/paper_files/paper/2020/file/\n1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[7] Yupeng Cao, Zhi Chen, Qingyun Pei, Fabrizio Dimino, Lorenzo Ausiello, Prashant\nKumar, K.P. Subbalakshmi, and Papa Momar Ndiaye. 2024. RiskLabs: Predicting\nFinancial Risk Using Large Language Model Based on Multi-Sources Data. ArXiv\nabs/2404.07452 (2024). https://api.semanticscholar.org/CorpusID:269042664\n[8] Harrison Chase. 2022. LangChain. https://github.com/langchain-ai/langchain\n[9] Rian Dolphin, Joe Dursun, Jonathan Chow, Jarrett Blankenship, Katie Adams,\nand Quinton Pike. 2024. Extracting Structured Insights from Financial News: An\nAugmented LLM Driven Approach. arXiv preprint arXiv:2407.15788 (2024).\n[10] Georgios Fatouros, Konstantinos Metaxas, John Soldatos, and Dimosthenis Kyri-\nazis. 2024. Can Large Language Models Beat Wall Street? Unveiling the Potential\nof AI in Stock Selection. arXiv:2401.03737 [q-fin.CP] https://arxiv.org/abs/2401.\n03737\n[11] Frank A Fernandez. 2001. The role and responsibilities of securities analysts.\nSecurities Industry Association Research Reports 2, 1 (2001), 3â€“10.\n[12] Alireza Jafari and Saman Haratizadeh. 2022. GCNET: graph-based prediction of\nstock price movement using graph convolutional network. Engineering Applica-\ntions of Artificial Intelligence 116 (2022), 105452.\n[13] Narasimhan Jegadeesh, Joonghyuk Kim, Susan D. Krische, and Charles M. C. Lee.\n2004. Analyzing the Analysts: When Do Recommendations Add Value? The\nJournal of Finance 59, 3 (2004), 1083â€“1124. http://www.jstor.org/stable/3694731\n[14] Narasimhan Jegadeesh and Woojin Kim. 2006. Value of analyst recommendations:\nInternational evidence. Journal of Financial Markets 9, 3 (2006), 274â€“309.\n[15] Jesus R Jimenez-Andrade, Timothy J Fogarty, and Gregory A Jonas. 2021. Coun-\nselors, judges, or executioners: The role of financial analysts in capital marketsâ€™\nresponses to alleged FCPA violations. Journal of Forensic and Investigative Ac-\ncounting 13, 3 (2021).\n[16] Geeta Kolte, Varadraj Kini, H Nair, and KSS Babu. 2022. Stock market prediction\nusing deep learning. International Journal for Research in Applied Science &\nEngineering Technology (IJRASET) 10, 4 (2022).\nAI in Investment Analysis: LLMs for Equity Stock Ratings ICAIF â€™24, November 14â€“17, 2024, Brooklyn, NY, USA\n[17] Jean Lee, Nicholas Stevens, Soyeon Caren Han, and Minseok Song. 2024. A\nSurvey of Large Language Models in Finance (FinLLMs). ArXiv abs/2402.02315\n(2024). https://api.semanticscholar.org/CorpusID:267412025\n[18] Xiang Li, Zhenyu Li, Chen Shi, Yong Xu, Qing Du, Mingkui Tan, and Jun Huang.\n2024. AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented\nStock-Chain Framework. In Proceedings of the 2024 Joint International Conference\non Computational Linguistics, Language Resources and Evaluation (LREC-COLING\n2024), Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste, Alessandro Lenci,\nSakriani Sakti, and Nianwen Xue (Eds.). ELRA and ICCL, Torino, Italia, 773â€“783.\nhttps://aclanthology.org/2024.lrec-main.69\n[19] Yang Li, Yangyang Yu, Haohang Li, Zhi Chen, and Khaldoun Khashanah. 2023.\nTradingGPT: Multi-Agent System with Layered Memory and Distinct Characters\nfor Enhanced Financial Trading Performance. arXiv:2309.03736 [q-fin.PM]\nhttps://arxiv.org/abs/2309.03736\n[20] Roger K. Loh and RenÃƒÂ© M. Stulz. 2010. When Are Analyst Recommendation\nChanges Influential? The Review of Financial Studies 24, 2 (10 2010), 593â€“627.\nhttps://doi.org/10.1093/rfs/hhq094 arXiv:https://academic.oup.com/rfs/article-\npdf/24/2/593/24430427/hhq094.pdf\n[21] Alejandro Lopez-Lira and Yuehua Tang. 2023. Can ChatGPT Forecast\nStock Price Movements? Return Predictability and Large Language Models.\narXiv:2304.07619 [q-fin.ST] https://arxiv.org/abs/2304.07619\n[22] OGognf. 2023. finagg: A Financial Aggregation Library. https://github.com/\ntheOGognf/finagg.\n[23] OpenAI. 2023. GPT-4-32k (v0613). https://platform.openai.com.\n[24] U.S. Securities and Exchange Commission. [n. d.]. EDGAR Application Pro-\ngramming Interfaces. https://www.sec.gov/search-filings/edgar-application-\nprogramming-interfaces\n[25] SerpAPI. 2023. SerpAPI: Google Search API .\n[26] Jaideep Singh and Matloob Khushi. 2021. Feature Learning for Stock Price\nPrediction Shows a Significant Role of Analyst Rating. Applied System Innovation\n4, 1 (2021). https://doi.org/10.3390/asi4010017\n[27] Srijan Sood, Kassiani Papasotiriou, Marius Vaiciulis, and Tucker Balch. 2023.\nDeep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative\nStudy with Mean-Variance Optimization. FinPlan Workshop at ICAPS Conference\n2023, 2023 (2023), 21.\n[28] Pragya Srivastava, Manuj Malik, Vivek Gupta, Tanuja Ganu, and Dan Roth. 2024.\nEvaluating LLMsâ€™ Mathematical Reasoning in Financial Document Question\nAnswering. In Findings of the Association for Computational Linguistics ACL\n2024, Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for\nComputational Linguistics, Bangkok, Thailand and virtual meeting, 3853â€“3878.\nhttps://doi.org/10.18653/v1/2024.findings-acl.231\n[29] Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, and Dongmei Zhang. 2024.\nTable meets llm: Can large language models understand structured table data?\na benchmark and empirical study. In Proceedings of the 17th ACM International\nConference on Web Search and Data Mining . 645â€“654.\n[30] Hanshuang Tong, Jun Li, Ning Wu, Ming Gong, Dongmei Zhang, and Qi Zhang.\n2024. Ploutos: Towards interpretable stock movement prediction with financial\nlarge language model. arXiv:2403.00782 [q-fin.ST] https://arxiv.org/abs/2403.\n00782\n[31] Saizhuo Wang, Hang Yuan, Lionel M Ni, and Jian Guo. 2024. QuantAgent: Seeking\nHoly Grail in Trading by Self-Improving Large Language Model. arXiv preprint\narXiv:2402.03755 (2024).\n[32] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei\nXia, Ed H. Chi, Quoc V. Le, and Denny Zhou. 2024. Chain-of-thought prompting\nelicits reasoning in large language models. InProceedings of the 36th International\nConference on Neural Information Processing Systems (New Orleans, LA, USA)\n(NIPS â€™22) . Curran Associates Inc., Red Hook, NY, USA, Article 1800, 14 pages.\n[33] Kent L. Womack. 1996. Do Brokerage Analystsâ€™ Recommendations Have Invest-\nment Value? The Journal of Finance 51, 1 (1996), 137â€“167. http://www.jstor.org/\nstable/2329305\n[34] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian\nGehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. 2023.\nBloombergGPT: A Large Language Model for Finance. arXiv:2303.17564 [cs.LG]\nhttps://arxiv.org/abs/2303.17564\n[35] Yangyang Yu, Haohang Li, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang,\nRong Liu, Jordan W Suchow, and Khaldoun Khashanah. 2024. FinMem: A\nperformance-enhanced LLM trading agent with layered memory and character\ndesign. In Proceedings of the AAAI Symposium Series , Vol. 3. 595â€“597.\n[36] Adam Zaremba and PrzemysÅ‚aw Konieczka. 2015. The profitability of following\nanalyst recommendations on the Polish stock market.Financial Internet Quarterly\n11, 1 (2015), 22â€“31.\n[37] Boyu Zhang, Hongyang Yang, Tianyu Zhou, Muhammad Ali Babar, and Xiao-\nYang Liu. 2023. Enhancing Financial Sentiment Analysis via Retrieval Augmented\nLarge Language Models. InProceedings of the Fourth ACM International Conference\non AI in Finance (Brooklyn, NY, USA) (ICAIF â€™23). Association for Computing Ma-\nchinery, New York, NY, USA, 349â€“356. https://doi.org/10.1145/3604237.3626866",
  "topic": "Stock market",
  "concepts": [
    {
      "name": "Stock market",
      "score": 0.5300619006156921
    },
    {
      "name": "Computer science",
      "score": 0.4956322908401489
    },
    {
      "name": "Stock (firearms)",
      "score": 0.48139524459838867
    },
    {
      "name": "Equity (law)",
      "score": 0.48067912459373474
    },
    {
      "name": "Finance",
      "score": 0.4407579302787781
    },
    {
      "name": "Financial market",
      "score": 0.42241692543029785
    },
    {
      "name": "Business",
      "score": 0.2439168393611908
    },
    {
      "name": "Engineering",
      "score": 0.11729010939598083
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Horse",
      "score": 0.0
    },
    {
      "name": "Mechanical engineering",
      "score": 0.0
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ],
  "cited_by": 5
}