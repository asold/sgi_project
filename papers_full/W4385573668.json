{
  "title": "Towards Tracing Knowledge in Language Models Back to the Training Data",
  "url": "https://openalex.org/W4385573668",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A3101039822",
      "name": "Ekin Akyürek",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2174406895",
      "name": "Tolga. Bolükbaşi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2235892558",
      "name": "Frederick Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103172861",
      "name": "Binbin Xiong",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2888964716",
      "name": "Ian Tenney",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2558501541",
      "name": "Jacob Andreas",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2553037633",
      "name": "Kelvin Guu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3093517588",
    "https://openalex.org/W3118560954",
    "https://openalex.org/W2785611959",
    "https://openalex.org/W4288091035",
    "https://openalex.org/W2970476646",
    "https://openalex.org/W2949279173",
    "https://openalex.org/W3169483174",
    "https://openalex.org/W3101656801",
    "https://openalex.org/W3034671305",
    "https://openalex.org/W3034475796",
    "https://openalex.org/W2594633041",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4286897388",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W2597603852",
    "https://openalex.org/W3102659883",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3213681714",
    "https://openalex.org/W3093205559",
    "https://openalex.org/W2951534261",
    "https://openalex.org/W3037881973",
    "https://openalex.org/W2577240759",
    "https://openalex.org/W2909737760",
    "https://openalex.org/W3152884768",
    "https://openalex.org/W3131061281",
    "https://openalex.org/W4293569541",
    "https://openalex.org/W4221149101",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4283810737",
    "https://openalex.org/W2005545412",
    "https://openalex.org/W1989898472",
    "https://openalex.org/W2962833140",
    "https://openalex.org/W2962851944",
    "https://openalex.org/W2946417913"
  ],
  "abstract": "Language models (LMs) have been shown to memorize a great deal of factual knowledge contained in their training data. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we propose the problem of fact tracing: identifying which training examples taught an LM to generate a particular factual assertion. Prior work on training data attribution (TDA) may offer effective tools for identifying such examples, known as “proponents”. We present the first quantitative benchmark to evaluate this. We compare two popular families of TDA methods — gradient-based and embedding-based — and find that much headroom remains. For example, both methods have lower proponent-retrieval precision than an information retrieval baseline (BM25) that does not have access to the LM at all. We identify key challenges that may be necessary for further improvement such as overcoming the problem of gradient saturation, and also show how several nuanced implementation details of existing neural TDA methods can significantly improve overall fact tracing performance.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 2429–2446\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nTowards Tracing Factual Knowledge in Language Models Back to the\nTraining Data\nEkin Akyürek† Tolga Bolukbasi Frederick Liu Binbin Xiong\nIan Tenney Jacob Andreas † Kelvin Guu\nGoogle Research †MIT CSAIL\nAbstract\nLanguage models (LMs) have been shown to\nmemorize a great deal of factual knowledge\ncontained in their training data. But when an\nLM generates an assertion, it is often difficult\nto determine where it learned this information\nand whether it is true. In this paper, we pro-\npose the problem of fact tracing: identifying\nwhich training examples taught an LM to gen-\nerate a particular factual assertion. Prior work\non training data attribution (TDA) may offer\neffective tools for identifying such examples,\nknown as “proponents”. We present the first\nquantitative benchmark to evaluate this. We\ncompare two popular families of TDA methods\n— gradient-based and embedding-based — and\nfind that much headroom remains. For example,\nboth methods have lower proponent-retrieval\nprecision than an information retrieval baseline\n(BM25) that does not have access to the LM\nat all. We identify key challenges that may\nbe necessary for further improvement such as\novercoming the problem of gradient saturation,\nand also show how several nuanced implemen-\ntation details of existing neural TDA methods\ncan significantly improve overall fact tracing\nperformance. 1\n1 Introduction\nResearch has shown that language models (LMs)\nacquire significant amounts of world knowledge\nfrom the massive text corpora on which they are\ntrained (Petroni et al., 2019; Raffel et al., 2020).\nThis development has enabled exciting advances\n1Code for the experiments is released at\nhttps://github.com/ekinakyurek/influence,\nand the datasets can be downloaded from https:\n//huggingface.co/datasets/ekinakyurek/ftrace.\nCorrespondences to akyurek@mit.edu\nFigure 1: FTRACE benchmark for tracing a language\nmodel’s predictions back to training examples (“pro-\nponents”): We provide two fact attribution datasets:\none with real facts ( FTRACE-TRE X) and one with\nsynthetic facts (FTRACE-S YNTH ). We evaluate com-\nmonly studied attribution methods, including gradient-\nbased and embedding-based approaches for their ability\nto identify true proponents.\nin knowledge-intensive NLP tasks such as open-\ndomain question answering (Roberts et al., 2020)\nand knowledge base population (Petroni et al.,\n2019). LMs have also been shown to generate fac-\ntually incorrect statements (Lee et al., 2018; Tian\net al., 2019), which is problematic for many appli-\ncations where trustworthiness is important. Hence,\nthere is an urgent need to understand exactly how\nLMs acquire and store knowledge so that we may\nimprove their accuracy and coverage.\nTraining Data Attribution Ultimately, a lan-\nguage model’s “knowledge” must derive from its\ntraining data. But there has been little research\n2429\non attributing an LM’s factual assertions back to\nspecific training examples — a task we call fact\ntracing. Training data attribution methods (TDA)\nare the main literature concerned with linking pre-\ndictions back to specific training examples (known\nas “proponents”). Influence functions (Hampel,\n1974; Koh and Liang, 2017) and TracIn (Pruthi\net al., 2020) are among the first methods to do this\nfor neural networks, by estimating the marginal\neffect of a training example on the loss of a test-\ntime example. However, most work on TDA has\nfocused on classification and regression tasks that\ndo not necessarily involve fine-grained factual in-\nformation (Han et al., 2020; Hara et al., 2019).\nSeveral obstacles have limited research on fact\ntracing for large, pre-trained LMs. First, since pre-\ntraining corpora are very large, it has not been clear\nhow to obtain ground truth labels regarding which\npre-training example was truly responsible for an\nLM’s prediction. Second, TDA methods have tra-\nditionally been computationally prohibitive. In this\npaper, we present one of the first computationally\ntractable studies of fact tracing for LMs. To do so,\nwe construct:\n(1) Two specially designed evaluation datasets,\nFTRACE-TRE X and FTRACE-S YNTH ,\nwhich contain unambiguous ground-truth in-\nformation about the origin of specific facts.\n(2) A tractable procedure for evaluating fact-\ntracing methods on large-scale LMs.\nObtaining Ground Truth Proponents To es-\ntablish (1) ground truth data for fact tracing, we\npropose a new recipe, which we call “novel fact\ninjection”. First, suppose that we can identify a set\nof “facts” that the pre-trained LM does not know\n— we call these “novel facts”. We can convert each\nnovel fact into an LM training example, and then\nfine-tune the LM on these extra examples until it\nmemorizes the novel facts (i.e. “injecting” them\ninto the LM). With a few caveats, we now know\nthat the LM must have learned these facts from our\nnewly injected examples. We also know which ex-\namples are responsible for teaching each fact, since\nwe constructed each example from a particular fact.\nHence, we now have ground-truth “proponents” for\nevery novel fact, and can evaluate any TDA method\non its ability to identify these proponents – i.e. to\nretrieve the true proponents out of a large set of\ntraining examples.\nWe implement this recipe using the TREx dataset\n(Elsahar et al., 2018) as our source of novel facts.\nTREx is a large text corpus where each sentence\nhas been comprehensively annotated with the facts\nthat it expresses, in the form of relational knowl-\nedge tuples. To identify novel facts present in\nTREx, we filter for knowledge tuples that the pre-\ntrained LM did not already know, as tested using\nmasked LM prompting. The sentences in TREx\nexpressing these tuples are then “injected” via fine-\ntuning and labeled as proponents. We call this setup\nFTRACE-TRE X.\nThere are two caveats for the above setup. First,\nwe must be careful about how we define what an\nLM “knows”. For example, if an LM generates a\nparticular assertion with 10% probability, does this\ncount as “knowing” or not? Second, some facts\ncan be indirectly inferred from other facts. For\nexample, suppose we want to know how an LM\nlearned that Barack Obama was born in Hawaii. It\ncould learn this from a literal mention of the fact:\n“Obama was born in Hawaii”, or indirectly infer it\nfrom “Obama was born in Honolulu”. Our TREx\nsetup only identifies literal proponents (the former),\nbut not indirect proponents (the latter).\nTo address these two issues, we introduce an\nadditional, more controlled setup, FTRACE-\nSYNTH , featuring synthetically generated novel\nfacts that could not have possibly been known by\nthe pre-trained LM, and which also have no cor-\nrelation with any existing facts – making indirect\ninferences impossible.\nMitigating Computational Cost To mitigate (2)\nthe high computational cost of most TDA meth-\nods, we propose a simple reranking setup that is\ncommonly used in information retrieval (IR) exper-\niments. Rather than running a TDA method over all\ntraining examples, we run it only over a small sub-\nset of “candidate” examples that is guaranteed to\ninclude the ground truth proponents as well as some\n“distractor” examples that are not true proponents.\nIn this way, a TDA method always has the oppor-\ntunity to identify the true proponents while still\nfacing challenging distractors, which enables us to\ndifferentiate the performance of multiple methods.\nKey Results Having developed data and quanti-\ntative evaluation methods for fact tracing, we use\nthem to evaluate two popular families of TDA meth-\nods: gradient-based methods (such as Pruthi et al.,\n2020), and embedding-based methods (Rajani et al.,\n2430\n2020). As a reference point, we also compare these\nTDA methods against a simple baseline: BM25\n(Robertson et al., 1995; Lv and Zhai, 2011), a stan-\ndard IR technique that simply selects proponents by\nretrieving training examples that have high lexical\noverlap with the query.\nWe experiment with several design choices for\nneural TDA methods, such as layer selection, and\nwe improve them by introducing a novel way of\naccounting for the optimizer momentum(Shazeer\nand Stern, 2018). Beside the improvements and\nthe proposed setup that eliminated previously\nused approximations, all methods under-perform\nBM25 in FTRACE-TRE X dataset. We note that\nthis does not imply that BM25 is optimal for this\ntask, but rather that there are clearly ways in which\nTDA methods could do better. On our more con-\ntrolled FTRACE-S YNTH , we observe that the\nupper-bound on neural TDA methods significantly\nabove of the standard IR methods, especially when\nwe introduce lexical variation in the way facts are\nexpressed. We conclude that significant headroom\nremains for TDA methods to successfully address\nfact tracing in datasets.\n2 Retrieval Methods\nWe begin with a formal description of the different\nTDA methods we study in this paper: gradient-\nbased methods (Koh and Liang, 2017; Pruthi et al.,\n2020) and embedding-based methods (Rajani et al.,\n2020). To contextualize the performance of these\ntwo families of approaches, we also describe a\nwidely used information retrieval baseline, BM25,\nwhich uses surface lexical similarity and thus tells\nus how effectively we can perform fact tracing with-\nout even having to access a model.\n2.1 Gradient-based Attribution\nInfluence functions (Hampel, 1974; Koh and Liang,\n2017) provide one of the first and best-known at-\ntribution methods. Given a training example z =\n(x,y) and a test example zquery = (xquery,yquery),\ninfluence functions seek to estimate the change in\nthe loss on zquery given an ϵincrease in the weight\nof a particular training example zat training time.\nComputing the influence of a training examplezin-\nvolves first estimating the change in the optimal pa-\nrameters ˆθ, given that the examplezis up-weighted\nby ϵin the training objective, then calculating how\nmuch the loss onzquery changes w.r.t. the parameter\nchange. The resulting influence score for convex\nloss functions is shown to be:\nI(z,zquery) =\n−∇θL\n(\nzquery,ˆθ\n)⊤\nH−1\nˆθ ∇θL\n(\nz,ˆθ\n)\n(1)\nwhere ∇θL(z,θ) denotes the gradient of the loss\nfunction on example zevaluated at model parame-\nters θ, and Hˆθ denotes the Hessian of the training\nobjective evaluated at the final converged model\nparameters, ˆθ (see Koh and Liang (2017) for the\nderivation). In this form, influence functions can be\nroughly viewed as the weighted dot product of the\ngradients for zquery and z, where the weight is the\ninverse Hessian of the training objective at ˆθ. Due\nto the complexity of inverse Hessian calculation,\nthe naive computational complexity isO(np2 +p3)\n(nis dataset size, pis parameter size). Even after\nthe sampling approximations proposed in Koh and\nLiang (2017), the cost is still too high to directly\napply influence functions for fact tracing.2\nTherefore, we turn to a more recent TDA method\nthat has demonstrated both better tractability and\nstrong empirical results: TracIn (Pruthi et al.,\n2020), which seeks to estimate influence by asking\na credit-assignment question rather than a coun-\nterfactual perturbation question. During training,\nwhen we take a gradient step on training examplez\n(input, output) at time t, we ask how much the loss\nchanges on test example zquery. TracIn employs\na first-order Taylor approximation to answer this\nquestion, yielding the following estimate, which is\nsimply the dot product of gradients at a particular\nstep t:\nIt(z,zquery) =∇θL\n(\nzquery,θt\n)⊤∇θL(z,θt) (2)\nIf we have taken K gradient steps on the training\nexample, this yields the total influence:\nI(z,zquery) =\nK∑\nk=1\n∇θL\n(\nzquery,θt(k)\n)⊤∇θL\n(\nz,θt(k)\n)\n(3)\nwhere t(k) denotes the training step at which we\ntook the kth gradient step on training example z.\nThe sum over time steps is generally approxi-\nmated by using some fixed set of training check-\npoints, which need not coincide with the actual\n2Schioppa et al. (2022) propose more tractable approxima-\ntions for Hessian based influence, but the memory requirement\nof the proposed method is still infeasible without projecting\ngradients into lower dimensions. Please refer to (Basu et al.,\n2021) for additional shortcomings.\n2431\nsteps where z was visited. A known issue is that\ngradient similarity may be dominated by outlier\ntraining examples with large gradients. A simple\nfix proposed in previous work (Barshan et al., 2020;\nHan and Tsvetkov, 2021) is to unit-normalize the\ngradients, effectively replacing the dot product in\nEquation (2) with cosine similarity:\nI(z,zquery) =\nK∑\nk=1\n∇θL\n(\nzquery,θt(k)\n)⊤∇θL\n(\nz,θt(k)\n)\n∥∇θL\n(\nzquery,θt(k)\n)\n∥∥∇θL\n(\nz,θt(k)\n)\n∥\n(4)\nWe hereafter refer to Iin Equation (4) as TRAC IN.\n2.2 Embedding-based Attribution\nHidden representations of neural networks are\nknown to embed high-level features that are often\nuseful for similarity search. While not as theo-\nretically justified, prior work (Rajani et al., 2019)\nhas found that such representations can outperform\ngradient-based methods. Following prior work, we\nextract the intermediate layer outputs of a Trans-\nformer language model, and average over decoding\ntime-steps to obtain a single vector representation\nfor any example. In our experiments, we consider\nrepresentations at different layers of the Transform-\ners, as well as their concatenations. Similar to the\ncase of gradient-based methods, the association be-\ntween a training example and a model prediction is\ndefined by a cosine product:\nI(z,zquery) =\nLMinter.(z)⊤LMinter.(zquery)\n∥LMinter.(z)⊤∥∥LMinter.(zquery)∥ (5)\nwhere LMinter. denotes some hidden representation\ninternal to the model LM. We refer to Iin Equa-\ntion (5) as EMBED .\n2.3 Baseline: BM25\nIn the previous sections, we used attribution meth-\nods to define a model-specific similarity function\nbetween examples. But it is also possible to iden-\ntify facts in a model-agnostic way: In the classic IR\nliterature, word-overlap based methods have been\nshown to be both simple and effective.\nAmong these approaches, BM25 (Robertson\net al., 1995; Lv and Zhai, 2011), the best perform-\ning variant, has been consistently used as a baseline\nfor information retrieval benchmarks (Thakur et al.,\nFigure 2: Dataset Creation: From the original TREx\n(Elsahar et al., 2018) data, we construct masked sen-\ntences and annotate their facts by using provided fact\nannotations. We assume a fact is expressed when either\nthe object or subject is masked in the sentence. Given\na query from the LAMA dataset (Petroni et al., 2019),\nwe identify proponents by matching all TREx training\nexamples expressing the same fact. (The outputs of the\nmasked examples are omitted in the figure.)\n2021) . When using BM25, we consider an ex-\nample as a bag of words consist of the input and\nthe output words. The score is proportional to to-\nken overlap between the query and the candidate,\ninversely weighted with the frequency of such to-\nkens, and the importance of weights regulated by\nhyperparameters. Refer to Appendix A for details.\n3 Fact Tracing Datasets\nWe propose two datasets to measure fact tracing ap-\nproaches: FTRACE-TRE X, a natural language\ndataset with real facts derived from the TREx\ndataset, and FTRACE-S YNTH , a synthetic dataset\nwith novel facts using made-up entities and rela-\ntions. For each dataset, we define an attribution\nset containing all LM training examples that might\nbe considered proponents and a query setcontain-\ning test examples, each annotated with their ground\ntruth proponents from the attribution set. The ex-\namples in these sets are masked language modeling\nexamples, each a (masked input, output, facts) tu-\nple.\n3.1 FTRACE-TREx\nWe create an attibution set using TREx (Elsahar\net al., 2018) and query set using LAMA (Petroni\net al., 2019) datasets. TREx consists of DBPedia\n(Brümmer et al., 2016) abstracts, ai ∈A. Each\nabstract contains a set of sentences, sj = aij,\n2432\nFTRACE-TREX FTRACE-SYNTH\nStatistics Attribution Query Attribution Query\nLength 1,560,453 31,479 3,190,000 10,000\nUnique Facts 552,381 31,479 50,000 5,000\nAvg. #proponents – 83 – 62\nFacts per example 8.28 1 2 1\nUnique Predicates 488 41 37 37\nUnique Objects 49,166 2,266 5,000 5,000\nUnique Subjects 310,197 29,464 5,000 5,000\nTable 1: FTRACE-TRE X: We extract 1M masked ex-\namples from TREx (Elsahar et al., 2018), and match\nthem with 27k queries from LAMA (Petroni et al., 2019)\nto construct our fact tracing benchmark. FTRACE-\nSYNTH : To evaluate influence methods on completely\nnovel facts, we propose a synthetic benchmark con-\nsists of made-up entities and relations. Refer to Ap-\npendix C.4 and Appendix C.5 for examples.\nand each sentence is associated with a set of facts,\nF(sj). For each fact f ∈F(sj), TREx annotates\nthe exact positions where the subject and object\nrespectively appear in the sentence sj.\nWe wish to convert these sentences into train-\ning examples that can teach a language model\nabout the facts stated within them. To do so, we\nconstruct cloze-style language modeling examples\nas in masked language modeling (Devlin et al.,\n2019) or span corruption (Raffel et al., 2020). In\nparticular, for each fact f in a sentence s, we\nmask out either the subject or the object, and train\nthe model to predict it. The two resulting exam-\nples masksub(s,f) and maskobj(s,f) are marked\nas “proponents” of the fact, as shown in Figure 2.\nThe LAMA dataset is anchored to the same fact\ntuples used by TREx. For each fact tuple, LAMA\nprovides a template-generated sentence expressing\nthe fact. Similar to TREx, we convert this sentence\ninto a cloze-style example by either masking out\nthe subject or object. Hence, we now have two sets\nof examples (TREx and LAMA) that express the\nsame facts. We treat the TREx examples as our\nattribution set and the LAMA examples as our test\nset. Since we wish to trace influence from LAMA\nback to TREx, we sometimes refer to LAMA exam-\nples as “queries” and TREx examples as “retrieval\ncandidates.” For any LAMA example, we define\nthe ground-truth proponents as simply the TREx\nexamples that express the same fact.\nOne ambiguity remains regarding ground truth\nin TREx sentences that express multiple facts. Sup-\npose a TREx sentence expresses facts f1 and f2,\nand we generate cloze examples for both f1 and\nf2. The example masksub(s,f1) is clearly a pro-\nponent of f1, but it is perhaps also a proponent\nof f2, since the text supporting f2 is still present\nafter masking. Ultimately, we care about whether\nattribution methods can retrieve the right sentence\nfrom the attribution set, not a particular masking of\nthat sentence. In our evaluations (described next),\nwe evaluate a method’s ability to retrieve at thesen-\ntence level, with the score of a sentence defined as\nthe max score over all maskings of that sentence.\nIn total (Table 1), we match approximately 448k\nTREx sentences with 31k LAMA queries. On aver-\nage, each TREx example expresses three facts, and\neach LAMA example has 83 proponents (including\ndifferent maskings of the same sentence).\n3.2 FTRACE-Synth\nIn a dataset with real facts, two factors can nega-\ntively impact TDA methods for LMs compared to\nbaselines such as BM25: First, many of the facts\nin FTRACE-TRE X may already be known by a\npre-trained LM.3 In such cases, the LM will not\nlearn the fact from TREx, and TDA methods should\nnot be expected to identify examples in TREx as\nproponents. We refer to this as the “saturation”\nproblem, since the model’s performance already\nsaturated on the fact before fine-tuning, leaving no\nsignal for TDA methods to detect. Second, real\ncorpora like TREx and LAMA have lexical overlap\nbetween query and attribution examples (overlap-\nping surface forms; see Section 3.1) which can\nfavor counting-based methods like BM25.\nTo better evaluate TDA methods in isolation, we\ncreate a synthetic dataset, FTRACE-S YNTH , to\nevaluate TDA methods on facts that are guaranteed\nto be novel. First, we create random entities with\na total number comparable to TRE X. Then, we\nrandomly relate those entities with each other using\nthe same set of relations from the TREx dataset.\nEntities Our entity list consists of 5,000 synthetic\nentities each uniquely identified by a number. To\nreduce the lexical overlap between examples in the\ndataset, we use 4 surface forms per entity – 2 forms\nwith Arabic numerals, 2 forms with Roman numer-\nals. For example, the fourth entity appears with\nthe following surface forms: [\"4-entity\", \"entity-4\",\n\"IV-entity\", \"entity-IV\"].\n3Even if the answer is not ranked first among model out-\nputs, the correct prediction may be “close to the surface” on\nthese examples, and the contribution of fine-tuning may be\nsmall, even if the predictions flip.\n2433\nRelations The dataset includes a set of 37 rela-\ntions (Appendix B) borrowed directly from TREx.\nAdditionally, we paraphrase each relation to create\ndiversity and to reduce the lexical overlap between\nattribution and query examples.\nAttribution Set Each example in the attribution\ncorpus expresses two facts to parallel the multi-fact\nnature of TREx examples.\nInput: entity-MMCLXXIV is the official lan-\nguage of 1 , CMXCVII-entity is the writ-\ning place of 2\nOutput: 1:3082-entity, 2:entity-MMMCCC\nThe attribution corpus includes 50,000 individual\nfacts. By masking different entities as well as com-\nbining different facts, we can generate 3,190,000\nmasked examples for the attribution corpus.\nQuery Set Similar to LAMA, each example in\nthe query corpus queries a single fact expressed as\na masked example, for example:\nInput: entity-3300 was written in .\nOutput: entity-CMXCVII\nWe generate 5,000 such facts by assigning random\nrelations between different entities, with two sur-\nface forms for each, resulting in 10,000 examples.\nAs a result, each fact in this query set has 62 pro-\nponents in the attribution corpus, and every entity\nappears in 10 relations on average.\n4 Experimental Setup\nOur experiments aim to answer the questions of (1)\nwhether TDA methods can be used as effective fact\ntracing tools (compared to simple IR baselines),\n(2) which configurations make them most effective\n(exploring many variations), and (3) analyzing the\nweaknesses of TRAC IN, in particular its sensitivity\nto when the knowledge is learned (the aforemen-\ntioned “saturation” hypothesis).\n4.1 Reranking Evaluation\nIdeally, an attribution method would score a given\ntest query against every training example, and we\ncan sort all examples by their influence score. This\nwould enable evaluation with standard IR methods\nlike recall@10 and mean reciprocal rank (MRR)\n1\n|Q|\n∑\nq∈Q\n1\nrankq , where rankq is the rank of the\nfirst true proponent for the query, and Qdenotes\nthe candidate set. However, most attribution meth-\nods are computationally intractable for scoring all\ntraining sentences in large datasets. Although we\ncan reduce the complexity of some of these meth-\nods through the use of random projections (Pruthi\net al., 2020), such lossy approximations would ren-\nder our results less conclusive, as it would be un-\nclear whether an outcome is due to the intrinsic\nquality of a method or the quality of the projection.\nTherefore, to achieve computational tractabil-\nity while avoiding such confounds, we propose a\nsimple reranking setup: instead of scoring all ex-\namples, we can score a carefully selected subset\nthat still enables meaningful comparisons. We call\nthis the “candidate set”. It is the union of four sets:\n1. all true proponents for a query: P(zquery),\n2. the top-100 retrievals from BM25:\nBM25(zquery),\n3. 100 random examples that share the same tar-\nget y as the query: Dy = {(x,y) s.t. y =\nyquery}, and\n4. 100 randomly sampled examples: Drandom,\nwith random samples fixed across all evaluations.\nNote that MRR on this particular candidate set is\nan upper-bound on the MRR over the full attri-\nbution set. Because it includes all proponents but\nfewer distractors, rank is guaranteed to be closer to\n1 in the MRR definition. Also, including P(zquery)\nis necessary to ensure that the model has the op-\nportunity to retrieve all proponents. BM25(zquery)\nensures that we have “distractors” with high lexical\noverlap, and Dy is included because we observed\nthat TDA methods have a tendency to retrieve ex-\namples with the same output as the query.\nOur candidate set includes all top retrievals from\nBM25, so the results for BM25 are exact. When\ncombined with the fact that reranking MRRs al-\nways upper-bound full retrieval MRRs, our setup\nguarantees that any method that underperforms\nBM25 on reranking will also underperform for full\nretrieval.\nSlicing examples The gradient-based methods\nrequire careful treatment when considering models\nthat go through two separate stages: pre-training\nand fine-tuning. For example, if a model has al-\nready obtained zero loss on an example at the start\nof fine-tuning, then the gradient will be near-zero\nthroughout fine-tuning, and computing influence\nusing only fine-tuning checkpoints will yield an un-\ninformative influence score for any query. We refer\n2434\nto this problem as “saturation.” To mitiagate sat-\nuration, we evaluate TDA methods on a subset of\nqueries we labelFinetune-learned (FL), where the\nmodel failed before fine-tuning (the answer is not\nin top-3 beam-search predictions), but succeeded\nafterward (the answer is top-1 in beam-search). We\nreferred to this set as “novel facts” in Section 1.4\n4.2 Model\nWe use MT5-base, a commonly used encoder-\ndecoder language model (Xue et al., 2021) to evalu-\nate the aforementioned neural TDA methods. MT5\nwas pre-trained on the MC4 corpus, which includes\nall of Wikipedia, and therefore was exposed to the\nknowledge expressed in FTRACE-TRE X. The\npre-trained MT5 model achieves 24.3% top-3 accu-\nracy when predicting answers to the TRE X queries.\nFine-tuning MT5 on our FTRACE-TRE X train-\ning set increases accuracy to 47.42%, suggesting\nthat there are still many facts MT5 did not know\nafter pre-training. For FTRACE-S YNTH , the pre-\ntrained model gets 0 accuracy as expected, and the\nfine-tuned model obtains 81%5.\nTo evaluate TRAC IN, we approximate Equa-\ntion (3) by choosing three checkpoints that are uni-\nformly spaced out in terms of their training loss\n(specifically, inverse perplexity), to ensure that we\ncover significant parts of training while favoring re-\ngions with greater loss reduction. Note that we use\npre-training checkpoints when evaluating the pre-\ntrained model, and fine-tuning checkpoints when\nevaluating the fine-tuned model; see Appendix A\nfor details. We calculate the gradient w.r.t the aver-\nage negative likelihood of the true output token se-\nquence. To evaluate embedding-based fact tracing,\nwe use representations from the final checkpoint of\nthe model.\nFor both gradient and embedding-based meth-\nods, we present the best layer combination among\nthe different concatenations of layers studied in\n(Section 5.2).\n5 Results\n5.1 Top-level comparisons\nIn Table 2, we present a top-level comparison of\nthe three main methods discussed (gradient-based,\nembedding-based, and BM25). Hyperparameters\n4In Appendix C.2, we present additional results for\nPretrain-learned (PL)examples, which went from failing to\nsuccessful during pre-training rather than fine-tuning.\n5We accept an answer if any of the surface forms of the\ncorrect entity is the output.\nMethods MRR Recall@10\nRandom-Target 14.50 ±0.95 10.32±1.54\nBM25 77.55±1.50 60.89±2.31\nFinetuned Pretrained Finetuned Pretrained\nTRACIN 48.56±4.40 62.38±1.99 56.02±0.67 57.54±1.25\nEMBED 64.29±1.32 60.59±1.13 57.89±1.38 54.91±0.32\nTRACIN+ EMBED 58.52±3.83 67.66±0.22 61.72±0.08 61.59±1.35\nTable 2: Top Level Results: Best scores for each method\nand model on the Finetune-learned slice of FTRACE-\nTREx. We present average sentence-level retrieval re-\nsults over 3 random selections of 200 queries. We found\nthat BM25 performs best in MRR outperforming neural\nmethods. Table 6 shows detailed MRRs on predicate,\nsubject, and object level of candidate examples.\nfor all methods have been optimized. As we discuss\nin subsequent sections, TDA hyperparameters have\na significant effect on performance.\nWe optimized TRAC IN by rescaling gradients\nwith Adafactor accumulators (Shazeer and Stern,\n2018), applying unit-normalization to the gradients\n(see Table 3) and selecting the best layer configura-\ntion (Section 5.2). To sanity check that TDAs are\ndoing more than matching the query’s output la-\nbel, we compare to a RANDOM -TARGET baseline\nthat outputs a score of 1 for all training examples\nwith the same output label. This baseline is indeed\nsubstantially worse than either method.\nDespite extensive optimization for TRAC IN and\nEMBED , however, we found that BM25 with no\ntuning still outperforms neural TDAs in MRR and\nRecall@10. TRAC IN slightly outperforms EMBED\nfor pretrained model but significantly underforms\nEMBED for the finetuned model. When we ensem-\nble TRAC IN and EMBED (by summing their influ-\nence scores) there is an improvement on recall of\ncandidate examples, demonstrating that their suc-\ncess is somewhat orthogonal. We provide example\nretrievals from all three models in Appendix C.\nSurprisingly, pre-trained TRAC IN outperforms\nfine-tuned TRAC IN in this dataset, as we discuss\nmore in Section 5.3.\nWe do not seek to measure all benefits of attri-\nbution methods, but rather to assess one expected\nfunction (fact-tracing), as promised by their stated\ngoal (tracing a model’s prediction back to data).\nThe fact that even the best TDA method obtains\nMRR of 67.66 and Recall@10 of 61.59 showcases\nthe significant absolute headroom that remains for\nattribution methods . BM25 results are only a little\nbetter, and are provided mainly as a reference point.\nNext, we analyze what choices contributed to the\ncurrent status of TDA methods with a detailed ex-\n2435\nMRR Recall@10\nChange Finetuned Pretrained Finetuned Pretrained\nAdafactor− →no-Adafactor –3.83±4.81 –7.20±2.25 –11.29±2.05 –2.36±1.63\nunit-norm− →no-norm –3.36±4.89 –32.90±2.13 –10.82±2.24 –28.06±1.46\nmulti-ckpt− →single-ckpt +0.51±6.42 +0.60±2.23 –6.95±4.72 +5.44±1.61\nno [eos]− →[eos] +5.50 ±4.63 –24.77±3.82 +12.96±1.59 –19.93±3.49\nTable 3: Our experiment with various configurations for\nbest layer of the TRAC IN evaluted in Finetune-Learned\nset of FTRACE-TRE X: For each change from the best\nconfiguration (the first row), we report the best result by\noptimizing free hyper-parameters. The normalization\nand the usage of the accumulator smoothing was effec-\ntive in our top level TRAC IN results. We compare max-\nimum scored checkpoint scores to our original multi-\ncheckpoint results, we found that the best checkpoint\nperforms slightly better than multi-heckpoint results in\nMRR. The including the the end of sentence token in\nthe target side hurts pretrained MT5 model since it is\noriginally trained to predict multiple answer.\nploration of hyperparameters.\n5.2 Which Transformer layers provide the\nmost reliable attribution signal?\nSome layers of a language model may be special-\nized for operations that have no relation to factual\ninformation. For example, previous probing work\n(Tenney et al., 2019) shows the existence of layers\nthat focus on syntax rather than on knowledge. The\ncontribution of such layers to TRAC IN may intro-\nduce noise. In Figure 3, we conduct an experiment\nwhere we sweep over various subsets of layers.\nFor TRAC IN, the best-performing layer is the\nembedding layer of the model — this result, also\nobserved in Yeh et al. (2022), is surprising, as most\nprior work used only the last layer. In EMBED ,\nthe best performing layer is again the output of the\nembedding layer. These results suggest that much\nof the effectiveness of embedding-based methods\nderives from their models of lexical similarity. Con-\nversely, for TRAC IN, the embedding layer also in-\ncludes contextual information since the gradient\nsignal propagates back through the entire model.\nAdditional Model Variants Section 5.1 men-\ntioned several design choices for TRAC IN. We\nperformed a systematic evaluation of those choices.\nIn Table 3, given the set of configurable options in\nthe table, we set a given option to a particular value\nand then optimize remaining parameters.\nUnit-normalized gradients drastically outper-\nform the dot product. Next, we considered the\nrole of Adafactor during training. The TRAC IN\nequation arises from considering parameter up-\nMRR Precision @10 Recall@10\nRandom-Target 36.47±2.84 30.43±4.00 2.45±0.32\nBM25 87.69 ±1.71 52.02±2.65 4.20±0.21\nTRACIN 100.00±0.00 99.50±0.14 8.02±0.01\nEMBED 99.58±0.24 97.12±0.53 7.83±0.04\nTRACIN+ EMBED 100.00±0.00 98.07±0.18 7.91±0.01\nTable 4: Synthetic Dataset Results: Best scores for\nfine-tuned model on the Finetune-learned slice of\nFTRACE-S YNTH . On completely novel facts, the\nTracIn upperbound is higher than the other methods.\nSince we control the lexical overlap, BM25 underper-\nforms neural methods. We present average sentence-\nlevel retrieval results over 2 random selections of 200\nqueries. The upper-bound scores on neural methods are\nhigher in the synthetic data than BM25 as we reduce the\nlexical overlap. The TRAC IN upperbound performs best\nin all the metrics.\ndates at a specific step. The true parameter up-\ndates were not raw gradients, but gradients that had\nbeen rescaled by Adafactor accumulators. Using\nthese rescaled gradient for TRAC IN performs much\nbetter. Also, surprisingly, using the single best-\nperforming checkpoint is sometimes better than\nusing multiple checkpoints. We provide the indi-\nvidual checkpoint results in Table 5.\n5.3 FTRACE-S YNTH and Saturation\nAs mentioned earlier, TRAC IN monitors the change\nin a model’s performance on a test query over\nthe course of training — and therefore is likely\nto fail if a test query’s loss is already zero (satu-\nrated) at the start of the training period monitored\nby TRAC IN. In addition, because the pre-trained\nmodel sees very similar sentences and information\nin the pre-training corpora, the influence could be\ndistributed over multiple examples, such that the\nsignal from each candidate is weak. These con-\nfounding factors may apply to FTRACE-TRE X.\nTherefore, we also evaluate TDA methods on our\nsynthetic dataset, FTRACE-S YNTH , which con-\ntrols for all these issues. We fine-tune the same\nmodel on FTRACE-S YNTH and perform the same\nevaluation in Table 4. The results suggest that\nwhen the aforementioned factors are controlled,\nthe reranking upper-bound for gradient-based TDA\nmethods is better than BM25 and slightly better\nthan embedding-based TDA methods. This result\nverifies that TDA methods might have advantages\nover standard IR methods, despite falling short in a\nmore realistic, applied scenario.\n2436\nFigure 3: Mean reciprocal rank for TRAC IN with different layers and and EMBED from different intermediate layers:\nIn G.0, gradient of embedding layer is used. In G. and A., respectively, gradients and embeddings of all layers\nare used. A.E.0 and A.D.0 corresponds to embedding layer’s output in the encoder and decoder part of the model\nrespectively. Comma-separated labels denote ensembling by summing the scores of the corresponding layers. We\nreport results for 3 random seeds (error bars with standard deviation) of 200 queries where queries learned between\npretraining checkpoints. In neural methods, using only the embedding layer or its output performs the best, while\nunderperforming the baseline method BM25.\n6 Related work\nInformation Retrieval To define our fact tracing\ntask, we employ standard concepts from the infor-\nmation retrieval (IR) literature: a retrieval + rerank-\ning setup, and standard retrieval metrics. However,\nwhile IR focuses on retrieving any document that\nsatisfies a user’s query, our benchmark specifically\naims to identify examples that caused a particular\nmodel to make a particular prediction. This focus\non model-specific causality distinguishes us from\nprior IR work (Thakur et al., 2021; Nguyen et al.,\n2016). Our evaluation setup should be easier than\ngeneric IR benchmarks because we are only evalu-\nating on predictions we know the LM gets right.\nLanguage Models as RetrieversLanguage mod-\nels have been successfully used in numerous IR\napplications. Karpukhin et al. (2020) use language\nmodel embeddings to warm-start neural retrievers\nfor knowledge-intensive tasks. Guu et al. (2020)\nand Lewis et al. (2020) show that language model-\ning and information retrieval can be jointly learned\nin a manner that benefits both tasks. Our work\nuses TDA-based retrieval methods to help users\nunderstand the behavior of the LMs themselves.\nAttribution Methods Recent work has tried to\nexplain neural model behavior in many different\nways: (1) attributing a prediction back to specific\nfeatures in the input (Simonyan et al., 2014; Sun-\ndararajan et al., 2017; Han et al., 2020), (2) attribut-\ning to specific model parameters (Dai et al., 2022;\nMitchell et al., 2022), (3) probing for competence\nat linguistic sub-tasks (Tenney et al., 2019), and\nfinally (4) attributing back to training examples\n(Pruthi et al., 2020; Koh and Liang, 2017).\nHowever, work in the last category (Han et al.,\n2020; Guo et al., 2021) has been limited, mainly\nfocusing on classification and regression tasks that\ndo not involve questions about factuality or world\nknowledge. Consequently, these methods have pri-\nmarily been used as a data cleaning technique, leav-\ning the question of fact tracing unexplored (Han\net al., 2020; Hara et al., 2019).\n7 Conclusion\nWe introduced a new dataset and benchmark for\nfact tracing: the task of tracing language models’\nassertions back to the training examples that pro-\nvided evidence for those predictions. We evalu-\nated gradient-based and embedding-based TDA\nmethods and found that they perform worse than a\nstandard IR baseline (BM25) even in settings that\nfavor TDA methods. We investigated the effects of\nlayer selection, model checkpoints and fine-tuning.\nOur ablative analysis suggests that saturation is an\nimportant factor affecting the performance of cur-\nrent methods. Much is needed to improve these\nmethods before they can be reliably used for fact\ntracing. We hope that this benchmark will enable\nfuture research on fact tracing, by mitigating com-\nputational challenges and establishing a principled\nground truth.\n2437\nAcknowledgments\nWe would like to thank Zhuyun Dai, Keith Hall, Ji\nMa for their helpful discussions and feedbacks.\nLimitations and Impact Statement\nOur experiments focus on a single representative\nlanguage model, MT5-base; it is possible that our\nfindings about the effectiveness of attribution meth-\nods for fact tracing would differ substantially when\napplied to language models with very different ar-\nchitectures or trained on different datasets. Because\nof the candidate set construction scheme described\nin Section 4.1, these results only upper-bound the\nperformance of evaluated methods, and it is also\npossible that they are even less effective than re-\nported here. The ground truth labels in FTRACE-\nTRE X extracted from TREx where the fact anno-\ntations are semi-automatically annotated, can have\nlabeling errors.\nThe FTRACE dataset includes content from\nWikipedia, some of which has not been vetted for\nfactual accuracy. It is possible that by redistribut-\ning this content we will propagate misinformation.\nWe plan to mitigate this harm with a datasheet that\nexplicitly communicates FTRACE’s role as an eval-\nuation tool, and not as a reliable source of infor-\nmation. Apart from the dataset, we anticipate no\nethical issues associated with the techniques de-\nscribed in this publication.\nReferences\nElnaz Barshan, Marc-Etienne Brunet, and\nGintare Karolina Dziugaite. 2020. Relatif:\nIdentifying explanatory training samples via relative\ninfluence. In International Conference on Artificial\nIntelligence and Statistics, pages 1899–1909. PMLR.\nSamyadeep Basu, Phil Pope, and Soheil Feizi. 2021.\nInfluence functions in deep learning are fragile. In\nInternational Conference on Learning Representa-\ntions.\nMartin Brümmer, Milan Dojchinovski, and Sebastian\nHellmann. 2016. Dbpedia abstracts: A large-scale,\nopen, multilingual nlp training corpus. In Proceed-\nings of the Tenth International Conference on Lan-\nguage Resources and Evaluation (LREC’16), pages\n3339–3343.\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao\nChang, and Furu Wei. 2022. Knowledge neurons in\npretrained transformers. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 8493–\n8502, Dublin, Ireland. Association for Computational\nLinguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nHady Elsahar, Pavlos V ougiouklis, Arslen Remaci,\nChristophe Gravier, Jonathon Hare, Frederique Lafor-\nest, and Elena Simperl. 2018. T-rex: A large scale\nalignment of natural language with knowledge base\ntriples. In Proceedings of the Eleventh International\nConference on Language Resources and Evaluation\n(LREC 2018).\nHan Guo, Nazneen Rajani, Peter Hase, Mohit Bansal,\nand Caiming Xiong. 2021. FastIF: Scalable influ-\nence functions for efficient model interpretation and\ndebugging. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 10333–10350, Online and Punta Cana,\nDominican Republic. Association for Computational\nLinguistics.\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\nand Mingwei Chang. 2020. Retrieval augmented\nlanguage model pre-training. In Proceedings of the\n37th International Conference on Machine Learning,\nvolume 119 of Proceedings of Machine Learning\nResearch, pages 3929–3938. PMLR.\nFrank R Hampel. 1974. The influence curve and its\nrole in robust estimation. Journal of the american\nstatistical association, 69(346):383–393.\nXiaochuang Han and Yulia Tsvetkov. 2021. Influence\ntuning: Demoting spurious correlations via instance\nattribution and instance-driven updates.\nXiaochuang Han, Byron C. Wallace, and Yulia Tsvetkov.\n2020. Explaining black box predictions and unveil-\ning data artifacts through influence functions. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 5553–\n5563, Online. Association for Computational Lin-\nguistics.\nSatoshi Hara, Atsushi Nitanda, and Takanori Maehara.\n2019. Data cleansing for models trained with sgd.\nAdvances in Neural Information Processing Systems,\n32.\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\nLewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\nWen-tau Yih. 2020. Dense passage retrieval for open-\ndomain question answering. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 6769–6781,\nOnline. Association for Computational Linguistics.\n2438\nPang Wei Koh and Percy Liang. 2017. Understanding\nblack-box predictions via influence functions. In In-\nternational Conference on Machine Learning, pages\n1885–1894. PMLR.\nKatherine Lee, Orhan Firat, Ashish Agarwal, Clara Fan-\nnjiang, and David Sussillo. 2018. Hallucinations in\nneural machine translation. In Workshop on Inter-\npretability and Robustness for Audio, Speech, and\nLanguage at NeurIPS.\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\nPetroni, Vladimir Karpukhin, Naman Goyal, Hein-\nrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\ntäschel, et al. 2020. Retrieval-augmented generation\nfor knowledge-intensive nlp tasks. Advances in Neu-\nral Information Processing Systems, 33:9459–9474.\nYuanhua Lv and ChengXiang Zhai. 2011. Lower-\nbounding term frequency normalization. In Proceed-\nings of the 20th ACM international conference on\nInformation and knowledge management, pages 7–\n16.\nEric Mitchell, Charles Lin, Antoine Bosselut, Chelsea\nFinn, and Christopher D Manning. 2022. Fast model\nediting at scale. In International Conference on\nLearning Representations.\nTri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao,\nSaurabh Tiwary, Rangan Majumder, and Li Deng.\n2016. Ms marco: A human generated machine read-\ning comprehension dataset. In Proceedings of the\nWorkshop on Cognitive Computation.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language models as knowl-\nedge bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473, Hong Kong, China. Association\nfor Computational Linguistics.\nGarima Pruthi, Frederick Liu, Satyen Kale, and Mukund\nSundararajan. 2020. Estimating training data influ-\nence by tracing gradient descent. Advances in Neural\nInformation Processing Systems, 33.\nColin Raffel, Noam Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2020. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. Journal of Machine Learning Research,\n21(140):1–67.\nNazneen Fatema Rajani, Ben Krause, Wengpeng Yin,\nTong Niu, Richard Socher, and Caiming Xiong. 2020.\nExplaining and improving model behavior with k\nnearest neighbor representations. arXiv preprint\narXiv:2010.09030.\nNazneen Fatema Rajani, Bryan McCann, Caiming\nXiong, and Richard Socher. 2019. Explain your-\nself! leveraging language models for commonsense\nreasoning. In Proceedings of the 57th Annual Meet-\ning of the Association for Computational Linguistics,\npages 4932–4942, Florence, Italy. Association for\nComputational Linguistics.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow much knowledge can you pack into the pa-\nrameters of a language model? arXiv preprint\narXiv:2002.08910.\nStephen E Robertson, Steve Walker, Susan Jones,\nMicheline M Hancock-Beaulieu, Mike Gatford, et al.\n1995. Okapi at trec-3. Nist Special Publication Sp,\n109:109.\nAndrea Schioppa, Polina Zablotskaia, David Vilar, and\nArtem Sokolov. 2022. Scaling up influence functions.\nProceedings of the AAAI Conference on Artificial\nIntelligence, 36(8):8179–8186.\nNoam Shazeer and Mitchell Stern. 2018. Adafactor:\nAdaptive learning rates with sublinear memory cost.\nIn Proceedings of the 35th International Conference\non Machine Learning , volume 80 of Proceedings\nof Machine Learning Research , pages 4596–4604.\nPMLR.\nK Simonyan, A Vedaldi, and A Zisserman. 2014. Deep\ninside convolutional networks: visualising image\nclassification models and saliency maps. pages 1–\n8. Proceedings of the International Conference on\nLearning Representations (ICLR).\nMukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\nAxiomatic attribution for deep networks. In Pro-\nceedings of the 34th International Conference on\nMachine Learning, volume 70 of Proceedings of Ma-\nchine Learning Research, pages 3319–3328. PMLR.\nIan Tenney, Dipanjan Das, and Ellie Pavlick. 2019. Bert\nrediscovers the classical nlp pipeline. In Proceedings\nof the 57th Annual Meeting of the Association for\nComputational Linguistics, pages 4593–4601.\nNandan Thakur, Nils Reimers, Andreas Rücklé, Ab-\nhishek Srivastava, and Iryna Gurevych. 2021. BEIR:\nA heterogeneous benchmark for zero-shot evaluation\nof information retrieval models. In Thirty-fifth Con-\nference on Neural Information Processing Systems\nDatasets and Benchmarks Track (Round 2).\nRan Tian, Shashi Narayan, Thibault Sellam, and\nAnkur P Parikh. 2019. Sticking to the facts: Con-\nfident decoding for faithful data-to-text generation.\narXiv preprint arXiv:1910.08684.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A massively multilingual\npre-trained text-to-text transformer. In Proceedings\nof the 2021 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, pages 483–498, On-\nline. Association for Computational Linguistics.\n2439\nChih-Kuan Yeh, Ankur Taly, Mukund Sundararajan,\nFrederick Liu, and Pradeep Ravikumar. 2022. First\nis better than last for training data influence. arXiv\npreprint arXiv:2202.11844.\n2440\nAppendix\nIn this appendix, we will provide implementation details and additional results for the experiments.\nA Implementation Details\nBM25 We use the following BM25 formula:\nI(z,zquery) =\n∑\nt∈zquery\nlog\n(N + 1\nNt\n)\n×\n\n (k1 + 1)·f(z,t)\nk1 ·\n(\n(1 −b) +b·\n(\nL(z)\nLavg\n))\n+ f(z,t)\n+ 1\n\n\nwhere, f(z, t) is the overlap count, N is the number of training examples, L(z) is the length of the\nexample, and Lavg is the average example length. k1 and b are hyperparameters tha reweights the\nimportance of the other terms in the formula. Robertson et al. (1995) provides the intuition behind this\ndefinition of relatedness.\nWe use a publicly available BM25+(Lv and Zhai, 2011) implementation written in python and released\nunder https://pypi.org/project/rank-bm25/. We tokenize queries and retrieval examples by space\nand we remove masked tokens. We did not optimize any of the default hyper parameters.\nMT5 Model We use intermediate checkpoints of MT5 model 6 (12 layers transformer with 580M\nparameters). We convert these checkpoints to Pytorch by using HugginFace’s T5 converter. We use the\ntokenizer provided. In our datasetSection 3.1, we use extra_id_0 for the mask token compatible with\npretraining corpus of MT5..\nTRACIN We calculate gradients by using Pytorch without batching examples and by using average\nnegative likelihood over output sequence. We store each individual parameter’s gradient (blocks of\ntransformer) in a dictionary structure. Given a query and a retrieval example, we calculate scores\nEquation (4) for each parameter seperately that means we locally normalize each parameters’ gradient in\nEquation (4). Then, to calculate a layer’s or full model’s score, we score individual scores corresponding\nto parameters in that layer. This enable us to sweep over different combination of layers as in Figure 3\nwithout rerunning the model.\nPretrained MT5 model is trained until 80k gradient steps. We use checkpoints at 5100, 10200, 15300\nsteps. We fine-tune MT5 model on additional 60k gradient steps on TREx dataset. Then, we use\ncheckpoints at 5000, 10000, 30000 steps.\nWe paralelize over checkpoints when calculating Equation (4). For each query, we spend approximately\n15 minutes by using VOLTA V100 32 GB GPUs to get scores for all the retrieval examples in the ranking\nset (Section 4.1))\nEMBED Transformer model’s forward pass can be expressed as following pseudo code:\nenc0 = Embedding(x)\nenci = Encoderi(enci−1)i= 1..N\ndec0 = Embedding(y)\ndeci = Decoderi(y,encN)i= 1..N\nL= NLL(WprojdecN,yquery)\n(6)\nWe use enci and deci, and reduce (average) them over time-steps in input and outputs side respectively.\n6https://github.com/google-research/multilingual-t5\n2441\nB Synthetic Data Relation Templates\nBelow are the relation templates we use in the dataset. “0 and “1\" are the slots for the entities. Paraphrases\nare delimited by “|\" sign. Left paraphrase is the original surface for in the FTRACE-TRE X dataset, right\none is the additional paraphrase paraphrase.\n{0} was born in {1} | {0} ’s birth place is {1}\n{0} died in {1} | {0} passed away in {1}\n{0} is a subclass of {1} | {1} is superclass of {0}\nThe official language of {0} is {1} | {1} is the official language of {0}\n{0} plays in {1} position | {1} is the play position of {0}\n{0} was awarded the {1} | {1} given to {0}\n{0} was originally aired on {1} | {1} is the first streamer of {0}\n{0} was educated at the University of {1} | {0} studied in University of {1}\n{0} shares border with {1} | {0} and {1} are neighbours\n{0} is named after {1} | {1} was inspirational for the naming of {0}\nThe original language of {0} is {1} | {1} is the original language of {0}\n{0} plays with {1} | {0} plays along with {1}\n{0} is a member of {1} | {1} accepted {0} as a member\n{0} works in the field of {1} | {1} is the work field of {0}\n{1} participated in the {0} | {1} was a participant of {0}\n{0} is a {1} by profession | {0} ’s profession is {1}\n{0} consists of {1} | {0} includes {1}\n{0} is a member of the {1} political party | {0} ’s political party was {1}\n{0} maintains diplomatic relations with {1} | {0} ’s diplomacy with {1}\n{0} is produced by {1} | {1} produced {0}\n{0} is a citizen of {1} | {0} ’s home country is {1}\n{0} was written in {1} | {1} is the writing place of {0}\n{0} is located in {1} | {0} placed in {1}\n{0} is developed by {1} | {1} developed {0}\n{0} is the capital of {1} | the capital of {1} is {0}\n{0} works for {1} | {0} works at {1}\n{0} plays {1} music | {0} perform {1} music\n{0} has the position of {1} | {0} ’s position is {1}\n{0} is represented by music label {1} | music label {1} represents {0}\n{0} used to work in {1} | {1} is ex - workplace of {0}\n{0} is affiliated with the {1} religion | {0} believes in {1} religion\n{0} is owned by {1} | {1} owned {0} v\nThe native language of {0} is {1} | {1} is the native language of {0}\n{0} and {1} are twin cities | {0} is twin city of {1}\n{0} is a legal term in {1} | {0} is a legal definition in {1}\nThe headquarter of {0} is in {1} | {0} ’s headquarter in {1}\n{0} was founded in {1} | {0} was established in {1}\nC Additional Results and Samples\nC.1 Individual Checkpoints\nMRR Recall@10\nFT PT FT PT\nMulti 48.56 ±4.40 62.38±1.99 56.02±0.67 57.54±1.25\nCkpt1 49.07 ±4.67 54.77±1.26 49.07±4.67 54.77±1.26\nCkpt2 47.30 ±2.88 62.98±1.01 47.30±2.88 62.98±1.01\nCkpt3 48.69 ±5.19 60.29±3.34 48.69±5.19 60.29±3.34\nTable 5: TRAC IN results for individual checkpoints on Finetune-Learned set.\nC.2 MRR Results with Submetrics\nMRR on Finetune-Learned Subsets of FTRACE-TRExWe provide submetrics for ( Finetuned-\nlearned (FL)) set.\n2442\nTable 6: MRR Results with submetrics in fine-tuned learned set. (see Table 2)\nSentence (Table 2) Predicate Subject Object\nFT PT FT PT FT PT FT PT\nRandom-Target 14.50 ±0.95 14.50±0.95 14.71±0.89 14.71±0.89 98.14±0.72 98.14±0.72 63.56±2.53 63.56±2.53\nBM25 77.55 ±1.50 77.55±1.50 79.26±2.82 79.26±2.82 88.25±1.80 88.25±1.80 85.71±1.22 85.71±1.22\nTRACIN 48.56±4.40 62.38±1.99 49.16±4.76 63.98±0.98 99.53±0.43 86.49±1.22 88.74±1.59 74.99±3.61\nEMBED 64.29±1.32 60.59±1.13 66.25±1.82 63.00±1.73 94.09±0.77 81.79±1.33 80.45±0.99 74.03±2.27\nTRACIN + EMBED 58.52±3.83 67.66±0.22 59.24±3.88 69.49±0.92 97.92±0.50 82.03±1.61 71.94±2.44 79.15±1.55\nMRR on Pretrained-Learned Subsets of FTRACE-TRExWe present additional results for (Pretrain-\nlearned (PL)) examples where the model failed before the a checkpoint of pre-training, but changed\nduring pre-training. We found that the average number of proponents in the PL set is 2.5x that of the\nFL set (since we expect that frequently mentioned facts will be learned first). These results suggest that\nit’s difficult to control for when facts were learned without affecting the other statistics, and that direct\ncomparisons between model performance on the PL and FL datasets may not be informative.\nTable 7: MRR Results with submetrics in pretrained- learned set. (see Table 2)\nSentence (Table 2) Predicate Subject Object\nFT PT FT PT FT PT FT PT\nRandom-Target 15.83 ±1.42 15.83±1.42 15.62±1.29 15.62±1.29 98.36±0.79 98.36±0.79 61.88±1.99 61.88±1.99\nBM25 77.62 ±3.24 77.62±3.24 77.20±3.56 77.20±3.56 91.24±0.83 91.24±0.83 88.07±1.39 88.07±1.39\nTRACIN 64.18±2.62 54.45±1.96 63.94±1.80 56.01±1.95 99.17±0.72 89.82±2.21 88.07±2.00 81.44±1.71\nEMBED 51.21±2.43 50.42±2.43 51.02±2.55 50.30±2.64 96.52±1.75 84.21±3.03 79.18±1.05 79.00±0.82\nTRACIN + EMBED 65.91±2.88 55.40±1.98 66.04±2.60 57.09±2.24 97.95±0.25 86.21±2.16 84.09±2.00 82.01±1.78\nC.3 Precision-Recall plots for FTRACE-TREx\nWe present accompanying precision and recall results for Figure 3.\n2443\nC.4 Samples for FTRACE-TREx\nHere, we provide example top-3 retrievals from TDAs for the FTRACE-TRE X dataset. Long examples\nare truncated for display purposes. We provide label (whether the retrieved example includes the fact)\nnext to the output of the retrieved example.\nEmbed TracIn BM25\nQ: In late 2005, the 1\nbroadcast a full series of Star\nSpell, again presented by Ea-\nmonn Holmes but Mishal Hu-\nsain took over from Nina as\nword pronou...\nA: BBCTrue\nQ: In late 2005, the 1\nbroadcast a full series of Star\nSpell, again presented by Ea-\nmonn Holmes but Mishal Hu-\nsain took over from Nina as\nword pronou...\nA: BBCTrue\nQ: In late 2005, the 1\nbroadcast a full series of Star\nSpell, again presented by Ea-\nmonn Holmes but Mishal Hu-\nsain took over from Nina as\nword pronou...\nA: BBCTrue\nQ: The Vicar of Dibley is a\n1 television sitcom cre-\nated by Richard Curtis and writ-\nten for actress Dawn French by\nCurtis and Paul Mayhew-Archer,\nwit...\nA: BBCFalse\nQ: Tasneem Zehra Husain (also\nspelled as Tasneem Zehra Hus-\nsain), is a Pakistani 1\nand an Assistant Professor of\nPhysics at the Lahore University\nof...\nA: theoretical physicistFalse\nQ: In late 2005, the BBC\nbroadcast a full series of Star\nSpell, again presented by Ea-\nmonn Holmes but 1 took\nover from Nina as word pro-\nnouncer.\nA: Mishal HusainTrue\nQ: Honigberg also recorded\nHomage to Rostropovich\n(1927–2007), a CD of solo\ncello works written for the\nlegendary cellist; Frédéric\nChopin’s complete wor...\nA: pianoFalse\nQ: Abdul Aziz Bin Dato Haji\nHusain was born 18 July 1950\nin Kuching, Sarawak, 1.\nA: MalaysiaFalse\nQ: He now works for the BBC,\npresenting on the BBC News\nchannel and 1.\nA: BBC OneFalse\nTable 8: Mishal Husain works for 1. (A: BBC)\nC.5 Samples for FTRACE-Synth\nNow, we provide the retrieved examples for FTRACE-S YNTH version of our dataset.\n2444\nEmbed TracIn BM25\nQ: Clara Ellaline Hope\nLeighton (sometimes Clare\nVeronica Hope Leighton) (12\nApril 1898 - 4 November 1989)\nwas an 1/American artist,\nwriter and ill...\nA: EnglishFalse\nQ: He was educated in 1\nand at the Quaker Leighton Park\nSchool.\nA: LondonFalse\nQ: The 1 Kenneth\nLeighton (1929–1988) also\nwrote a Fantasia Contrappuntis-\ntica (\"Homage to Bach\", Op.24)\nfor piano, which won the first\nprize at the...\nA: composerTrue\nQ: Lillianne Brown Leighton\n(May 17, 1874 – March 19,\n1956), known professionally as\nLillian Leighton, was an 1\nsilent film actress.\nA: AmericanFalse\nQ: Kenneth 1 Bray (May\n26, 1895 – January 9, 1953)\nwas an Episcopal priest, teacher,\nsportsman and coach.\nA: AugustineFalse\nQ: The composer 1\n(1929–1988) also wrote a\nFantasia Contrappuntistica\n(\"Homage to Bach\", Op.24) for\npiano, which won the first prize\nat the Bolzano...\nA: Kenneth LeightonTrue\nQ: The composer Kenneth\nLeighton (1929–1988) also\nwrote a Fantasia Contrappuntis-\ntica (\"Homage to Bach\", Op.24)\nfor 1, which won the first\nprize at ...\nA: pianoTrue\nQ: Leighton Road Evangelical\nChurch is a nonconformist in-\ndependent evangelical church\nlocated on the Gainsborough\nestate, 1 in the English\ncounty o...\nA: IpswichFalse\nQ: The composer Kenneth\nLeighton (1929–1988) also\nwrote a Fantasia Contrappuntis-\ntica (\"Homage to Bach\", Op.24)\nfor 1, which won the first\nprize at ...\nA: pianoTrue\nTable 9: Query: Kenneth Leighton plays 1. (A: piano)\nEmbed TracIn BM25\nQ: 1 given to 3692-\nentity,entity-2686 was awarded\nthe 2\nA: 1:entity-1138, 2:entity-\nMMMMDCLIIITrue\nQ: 1 given to entity-\nMMDCLXXXVI, 2 used\nto work in CXVI-entity\nA: 1:entity-MMMMDCLIII,\n2:entity-1650True\nQ: 1 given to 3692-\nentity, 2 was awarded the\nentity-MMMMDCLIII\nA: 1:entity-1138, 2:entity-2686\nTrue\nQ: entity-1138 given to\n1,entity-2686 was\nawarded the 2\nA: 1:3692-entity, 2:entity-\nMMMMDCLIIITrue\nQ: entity-CCCII given to\n1,MMMDLVI-entity\ngiven to 2\nA: 1:entity-MMMMDCLIII,\n2:entity-MDCCCLXXXVII\nFalse\nQ: entity-CCCII given to\n1, 2 given to entity-\nMDCCCLXXXVII\nA: 1:entity-MMMMDCLIII,\n2:MMMDLVI-entityFalse\nQ: 1 given to 2686-\nentity, 2 plays in entity-\n2658 position\nA: 1:MMMMDCLIII-entity,\n2:MMMMCCLXIX-entityTrue\nQ: 1 shares border with\nentity-DCCXXVII,entity-302\ngiven to 2\nA: 1:entity-MMMMCMXCVIII,\n2:entity-MMMMDCLIIIFalse\nQ: entity-CCCII given to\n1,MMMDLVI-entity\ngiven to 2\nA: 1:entity-MMMMDCLIII,\n2:entity-MDCCCLXXXVII\nFalse\nTable 10: 1 given to entity-2686. (A: entity-MMMMDCLIII)\n2445\nEmbed TracIn BM25\nQ: entity-MMMDLXXVI’s\ndiplomacy with 1,entity-\n3193’s birth place is 2\nA: 1:MMCDLX-entity, 2:entity-\n5 True\nQ: 3132-entity maintains\ndiplomatic relations with\n1, 2 was awarded\nthe entity-3701\nA: 1:entity-3468, 2:entity-4097\nFalse\nQ: MMMDLXXVI-entity’s\nprofession is 1,entity-\nCCLXI’s diplomacy with\n2\nA: 1:MXXX-entity, 2: 506-\nentityFalse\nQ: MMMDLXXVI-entity’s\ndiplomacy with 1, 2\ngiven to 2897-entity\nA: 1:entity-MMCDLX,\n2:MCMLIII-entityTrue\nQ: The original language\nof MMCCLXXIX-entity is\n1,3552-entity shares\nborder with 2\nA: 1:MMCDLX-entity,\n2:MMMMDLXV-entityFalse\nQ: MMMDLXXVI-\nentity’s diplomacy with\n1,MCMLIII-entity given\nto 2\nA: 1:entity-MMCDLX, 2:\n2897-entityTrue\nQ: MMMDLXXVI-\nentity’s diplomacy with\n1,MCMLIII-entity given\nto 2\nA: 1:entity-MMCDLX, 2:\n2897-entityTrue\nQ: The official language\nof CMXCVII-entity is\n1, 2 died in\nMMCDLX-entity\nA: 1:3215-entity, 2: 710-entity\nFalse\nQ: MMMDLXXVI-entity’s\ndiplomacy with 1, 2\ngiven to 2897-entity\nA: 1:entity-MMCDLX,\n2:MCMLIII-entityTrue\nTable 11: MMMDLXXVI-entity’s diplomacy with 1. (A: MMCDLX-entity)\n2446",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8044719099998474
    },
    {
      "name": "Assertion",
      "score": 0.7634283304214478
    },
    {
      "name": "Tracing",
      "score": 0.6340284943580627
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5245973467826843
    },
    {
      "name": "Memorization",
      "score": 0.4974994957447052
    },
    {
      "name": "Benchmark (surveying)",
      "score": 0.4651642143726349
    },
    {
      "name": "Embedding",
      "score": 0.4321703314781189
    },
    {
      "name": "Machine learning",
      "score": 0.41876283288002014
    },
    {
      "name": "Training set",
      "score": 0.41477060317993164
    },
    {
      "name": "Natural language processing",
      "score": 0.34372586011886597
    },
    {
      "name": "Information retrieval",
      "score": 0.3326065242290497
    },
    {
      "name": "Programming language",
      "score": 0.08379960060119629
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Mathematics education",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1291425158",
      "name": "Google (United States)",
      "country": "US"
    }
  ]
}