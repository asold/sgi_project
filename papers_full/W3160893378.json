{
  "title": "Simplifying Paragraph-level Question Generation via Transformer Language Models",
  "url": "https://openalex.org/W3160893378",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4288898161",
      "name": "Lopez, Luis Enrico",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4288898162",
      "name": "Cruz, Diane Kathryn",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225988164",
      "name": "Cruz, Jan Christian Blaise",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4225988165",
      "name": "Cheng, Charibeth",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2610891036",
    "https://openalex.org/W2130942839",
    "https://openalex.org/W2606333299",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2962717047",
    "https://openalex.org/W2154652894",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2890166583",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2133459682",
    "https://openalex.org/W2757978590",
    "https://openalex.org/W2971274815",
    "https://openalex.org/W2962977247",
    "https://openalex.org/W2996287690",
    "https://openalex.org/W2729046720",
    "https://openalex.org/W2964121744"
  ],
  "abstract": "Question generation (QG) is a natural language generation task where a model is trained to ask questions corresponding to some input text. Most recent approaches frame QG as a sequence-to-sequence problem and rely on additional features and mechanisms to increase performance; however, these often increase model complexity, and can rely on auxiliary data unavailable in practical use. A single Transformer-based unidirectional language model leveraging transfer learning can be used to produce high quality questions while disposing of additional task-specific complexity. Our QG model, finetuned from GPT-2 Small, outperforms several paragraph-level QG baselines on the SQuAD dataset by 0.95 METEOR points. Human evaluators rated questions as easy to answer, relevant to their context paragraph, and corresponding well to natural human speech. Also introduced is a new set of baseline scores on the RACE dataset, which has not previously been used for QG tasks. Further experimentation with varying model capacities and datasets with non-identification type questions is recommended in order to further verify the robustness of pretrained Transformer-based LMs as question generators.",
  "full_text": "Simplifying Paragraph-level Question\nGeneration via Transformer Language Models\nLuis Enrico Lopez1*, Diane Kathryn Cruz 1*, Jan Christian Blaise Cruz 1*, and\nCharibeth Cheng1\nDe La Salle University Manila, Taft Ave., Malate, 1004 Manila, Philippines\n{luis lopez,diane cruz,jan christian cruz,charibeth.cheng}@dlsu.edu.ph\nAbstract. Question Generation (QG) is an important task in Natu-\nral Language Processing (NLP) that involves generating questions auto-\nmatically when given a context paragraph. While many techniques exist\nfor the task of QG, they employ complex model architectures, exten-\nsive features, and additional mechanisms to boost model performance.\nIn this work, we show that transformer-based ﬁnetuning techniques can\nbe used to create robust question generation systems using only a single\npretrained language model, without the use of additional mechanisms,\nanswer metadata, and extensive features. Our best model outperforms\nprevious more complex RNN-based Seq2Seq models, with an 8.62 and\na 14.27 increase in METEOR and ROUGE L scores, respectively. We\nshow that it also performs on par with Seq2Seq models that employ\nanswer-awareness and other special mechanisms, despite being only a\nsingle-model system. We analyze how various factors aﬀect the model’s\nperformance, such as input data formatting, the length of the context\nparagraphs, and the use of answer-awareness. Lastly, we also look into\nthe model’s failure modes and identify possible reasons why the model\nfails.\nKeywords: Question Generation · Delimiters · Transformer Neural Net-\nworks.\n1 Introduction\nQuestion Generation (QG) [14], while not as prominent as its sibling task\nQuestion Answering (QA), still remains a relevant task in NLP. The ability to\nask meaningful questions provides evidence towards comprehension within an\nArtiﬁcial Intelligence (AI) model [10]. This makes the task of QG important in\nthe bigger picture of AI.\nMany studies have produced robust models with good performance for QG\nin recent years. The most widely-used techniques are Deep Learning-based ap-\nproaches involving Sequence-to-Sequence (Seq2Seq) [16] models. These approaches\n*: Equal contribution. Order determined by drawing lots.\narXiv:2005.01107v4  [cs.CL]  13 Aug 2021\n2 E. Lopez et al.\nuse two LSTM-based [6] neural networks, one to encode the source context para-\ngraph, and the other to decode the embedded information and output a gener-\nated question [5].\nFurther works that improve on the standard Seq2Seq-based QG models use\neither extra mechanisms, extra features, or both. These include the usage of\nextra linguistic features [21] or the introduction of answer-awareness [20,4,2],\nwhich uses the answer to the desired question, or the position of the answer\nwithin the context paragraph as additional features. A combination of these\ntechniques provide the base for state-of-the-art QG in recent years.\nMore recently, other techniques have been proposed in order to perform QG.\nReinforcement Learning (RL) have produced consistent results for the task by\nusing policy gradients [19]. The use of Transformers [17] over standard RNNs\nhave also been adopted as these models provide the power of Attention in order\nto refer to speciﬁc points of context within the context paragraph, alleviating\nthe RNN’s memory bottleneck [2].\nWhile all of these techniques are robust, they all employ complex models,\nextra features, and additional mechanisms that make them harder to train and\nexpensive to reproduce. In this work, we show that transformer-based ﬁnetuning\ntechniques can be used to create robust question generation systems using only\na single pretrained language model, without the use of additional mechanisms,\nanswer metadata, and extensive features.\nWe show that our method, albeit simpler, produces results on par with the\nstate-of-the-art. We benchmark standard language model ﬁnetuning on a refor-\nmatting of the SQuAD [13] v.1.1 dataset and evaluate generation performance\nwith standard language generation metrics. In addition, we perform a variety of\nanalyses in order to isolate performance indicators within our model and identify\nits weaknesses and failure modes.\n2 Methodology\n2.1 Data Preparation\nWe train the question generation model on version 1.1 of the Stanford Question\nAnswering Dataset (SQuAD) [13]. SQuAD contains context paragraphs, each\nwith sets of questions and corresponding answer spans related to the contents\nof these paragraphs; in total, SQuAD contains more than 100,000 crowdsourced\nquestions. While originally intended for the task of question answering, previous\nworks on question generation [4,20] have repurposed SQuAD as a training and\ntest dataset, designating the questions as the target output rather than the\nanswer spans.\nAs GPT-2 was pretrained to perform language modeling, we ﬁnetune it in a\nway similar to how it was trained on language modeling. Thus, we format SQuAD\nsuch that it appears similar to input data for language modeling. The entire\ndataset is transformed into a continuous body of text. Each training example\nconsists of a context paragraph and its associated question(s) transformed into\nSimplifying Paragraph-level Question Generation 3\nSQuAD\nContext1\nQuestion1\nQuestion2\n...\nContext2\nQuestion3\nQuestion4\n...\n...\nAQPL\nOQPL\nContext1 \n[SEP] \nQuestion1 \n[SEP] \nQuestion2\nContext2 \n[SEP] \nQuestion3 \n[SEP] \nQuestion4\n...\nContext1 \nQuestion: \nQuestion1 \nQuestion: \nQuestion2\nContext2 \nQuestion: \nQuestion3 \nQuestion: \nQuestion4\n...\nContext1 \n1. \nQuestion1 \n2. \nQuestion2\nContext2 \n1. \nQuestion3 \n2. \nQuestion4\n...\nContext1 \n[SEP] \nQuestion1\nContext1 \n[SEP] \nQuestion2\nContext2 \n[SEP] \nQuestion3\nContext2 \n[SEP] \nQuestion4\n...\nContext1 \nQuestion: \nQuestion1\nContext1 \nQuestion: \nQuestion2\nContext2 \nQuestion: \nQuestion3\nContext2 \nQuestion: \nQuestion4\n...\nContext1 \n1. \nQuestion1\nContext1 \n1. \nQuestion2\nContext2 \n1. \nQuestion3\nContext2 \n1. \nQuestion4\n...\nARTIFICIAL\nNATURAL-QUESTION\nNATURAL-NUMBER\nARTIFICIAL\nNATURAL-QUESTION\nNATURAL-NUMBER\nFig. 1.Data preparation pipeline for SQuAD.\nSuper Bowl 50 was an American football game to determine the champion of the National\nFootball League (NFL) for the 2015 season. The American Football Conference (AFC)\nchampion Denver Broncos defeated the National Football Conference (NFC) champion\nCarolina Panthers 24–10 to earn their third Super Bowl title. The game was played on\nFebruary 7, 2016, at Levi’s Stadium in the San Francisco Bay Area at Santa Clara, Cali-\nfornia... [SEP] Which NFL team represented the AFC at Super Bowl 50?\nFig. 2.A sample training example for question generation training. The context, de-\nlimiter, and question are highlighted in red, green, and blue respectively. Uses the\nARTIFICIAL delimiter and the OQPL format. Text adapted from SQuAD. [13].\na single continuous sequence with a delimiter in between. Training examples are\nseparated by the newline character \\n. Figure 2 shows an example of a single\ntraining example in this form.\nThere can be multiple ways to perform this transformation from the dataset’s\noriginal representation (JSON for SQuAD) to a continuous language modeling-\nready text. We experiment with two factors in formatting this data: the de-\nlimiter used, and the representation method for multiple questions per context\nparagraph. Figure 1 illustrates the six data formats we use for model training.\nDelimiters During data preparation, a delimiter is placed between each input\ncontext paragraph and output question. During training, this delimiter allows\nthe model to properly distinguish between the context and question, while during\nprediction, it can be used as a marker at the end of some input text to invoke\nquestion generation behavior in the model. We experiment with three diﬀerent\ndelimiting schemes: 1) ARTIFICIAL, or a delimiter in the form of the token\n[SEP], 2) NATURAL-QUESTION, or a delimiter in the form of the word\nQuestion, and 3) NATURAL-NUMBER, or a delimiting scheme in the form\nof a numbered list, where each item is a question.\n4 E. Lopez et al.\nSuper Bowl 50 was an American football game to determine the champion of the National\nFootball League (NFL) for the 2015 season. The American Football Conference (AFC)\nchampion Denver Broncos defeated the National Football Conference (NFC) champion\nCarolina Panthers 24–10 to earn their third Super Bowl title. The game was played on\nFebruary 7, 2016, at Levi’s Stadium in the San Francisco Bay Area at Santa Clara, Cali-\nfornia. As this was the 50th Super Bowl, the league emphasized the ”golden anniversary”\nwith various gold-themed initiatives, as well as temporarily suspending the tradition of\nnaming each Super Bowl game with Roman numerals (under which the game would have\nbeen known as ”Super Bowl L”), so that the logo could prominently feature the Ara-\nbic numerals 50. [SEP] Which NFL team represented the AFC at Super Bowl 50? [SEP]\nWhere did Super Bowl 50 take place? [SEP] What color was used to emphasize the 50th\nanniversary of the Super Bowl?\nFig. 3.A sample training example for question generation training. The context, de-\nlimiter, and questions are highlighted in red, green, and blue respectively. Uses the\nARTIFICIAL delimiter and the AQPL format. Text adapted from SQuAD dataset\n[13].\nThe ARTIFICIAL delimiter was not present in the original model’s vocabu-\nlary, and its weights are learned from scratch during the ﬁnetuning phase, while\nthe NATURAL delimiting schemes rely on token weights already learning during\nthe pretraining phase, thus making it possible for the model’s pretrained knowl-\nedge to aﬀect performance through these delimiters. Similar keywords have been\nshown to be eﬀective in invoking certain pretrained model behaviors (e.g.TL;DR:\nfor summarization), even in a zero-shot setting [12].\nQuestions Per LineThere can be several possible questions associated with\na single paragraph. We experiment with two ways to ﬂatten this many-to-one\nrelationship in the formatted data:\nAll Questions Per Line (AQPL)A single training example consists of a context\nparagraph with all of its associated questions placed immediately after it, sepa-\nrated from one another with the selected delimiter. While this avoids duplication\nof context and thus results in faster training time, it may potentially result in\nthe model no longer being able to attend to earlier tokens as its context window\nmoves further away from the beginning of the input paragraph.\nThis is critical in the question generation task, as information pertaining to\na reference question may be found anywhere in the input paragraph. If that\ninformation is found at the beginning, outside of the model’s current context\nwindow, the model may have diﬃculty generating the corresponding question.\nOne Question Per Line (OQPL)Each context paragraph is duplicated for each\nof its associated questions, such that for a single training example, there is only\none context and one question. For many cases, this may alleviate the moving\ncontext window problem raised with AQPL, as the length of a single training\nexample is reduced to the length of an input paragraph plus the length of a\nsingle associated question. However, this format does result in a longer training\ntime due to the duplicated contexts increasing the size of the ﬁnal formatted\ndataset.\nSimplifying Paragraph-level Question Generation 5\n2.2 Model Setup and Finetuning\nFor our base pretrained model, we used HuggingFace’s implementation [18] of the\n124 million parameter GPT-2, the smallest of the four available GPT-2 model\nsizes. From this base model, we ﬁnetuned six question generation models, each\nusing one of the data format combinations enumerated in Section 2.1.\nWe trained each model for 3 epochs using causal language modeling loss.\nWe used the Adam optimizer [8] with an initial learning rate of 5 ×10−4 and a\nlinearly decreasing learning rate schedule with warm up for 10% of total training\nsteps.\nFor training, we used a single Tesla V100 16GB GPU. As the model would\nnot ﬁt into memory using GPT-2’s default maximum sequence length of 1024\nand a batch size of 32, we simulated this batch size by combining an actual batch\nsize of 2 with 16 gradient accumulation steps per minibatch.\nWe opted out of using the larger models because of time and hardware lim-\nitations; training the 345 million parameter GPT-2 with a single 16GB GPU\nwould force us to use an actual batch size of 1 in order to ﬁt the model into\nmemory, greatly increasing training time, while training either of the two larger\nmodel sizes would require us to use multiple GPUs.\n2.3 Model Generation\nWe set the model temperature to 0 .6. Higher temperature values result in more\nrandomness in generations, while lower values approach greedy behavior.\nWe use the top-p nucleus sampling method [7] with a value of p = 0.9. Top-p\nallows for more diverse generations than a purely greedy scheme, and minimizes\nthe occurrence of certain tokens or token spans repeating indeﬁnitely in the\ngenerated text.\nEach generation loop is terminated either when the model generates the\nnewline character \\n, or when the model reaches a generation length of 32 tokens.\nWe manually set this maximum length in order to terminate generation sessions\nthat are stuck in token span loops and do not reach the \\n end-of-text token on\ntheir own.\n2.4 Metrics and Evaluation\nSimilar to the work of [20], we perform automatic evaluation metrics such as\nBLEU 1, BLEU 2, BLEU 3, BLEU 4 [11], ROUGE L [9] and METEOR [1]. We\nused the evaluation package made by [15] to quantify the models’ performance.\n3 Results and Discussion\nThe best performing model is the One Question Per Line (OQPL) model with\nnumber delimiters, achieving the highest score for BLEU 2, BLEU 3, BLEU 4\nand METEOR. For BLEU 1 and ROUGE L, the One Question Per Line (OQPL)\nmodel with artiﬁcial delimiters performed the best.\n6 E. Lopez et al.\nFormat Delimiter BLEU1 BLEU2 BLEU3 BLEU4 METEOR ROUGEL\nAQPL\nArtiﬁcial 54.83 30.13 15.72 7.31 20.53 43.88\nNumber 54.98 30.31 15.79 7.57 20.69 43.83\nQuestion 55.03 30.46 16.20 7.74 20.71 44.039\nOQPL\nArtiﬁcial 55.60 31.03 16.56 7.89 21.03 44.41\nNumber 55.51 31.17 16.79 8.27 21.2 44.38\nQuestion 55.28 30.81 16.55 8.21 21.11 44.27\nTable 1. Model Finetuning Scores\nIt is interesting to note, however, that the best OQPL models are on av-\nerage only 0.6917 points better than their corresponding All Questions Per\nLine (AQPL) counterparts. We hypothesize that this is because not enough\nof SQuAD’s context paragraphs combined with their questions are long enough\nto cause the moving context window problem (refer to Section 2.1) to occur.\nThis means that the choice between data formatting (OQPL vs AQPL) only\nmatters marginally, given that the context length does not approach the maxi-\nmum sequence length of the model.\nFor further analysis, we also extract post-ﬁnetuning features from the gen-\nerated questions such as question length, paragraph context length, and longest\nsub-sequence (between the paragraph context and generated question) on the\nbest performing model.\nA summary of the ﬁnetuning results can be found on Table 1.\nFrom the initial results and generated questions, we observe the following\nbehaviors:\n– Some generated questions seem to be simply extracting phrases from the\nparagraph context, and returning them in question form.\n– From the 2067 sample generated questions, 19 of which do not end with a\n“?” token. Note that we do not refer to such samples as “full questions.”\nFrom these observations, we perform further analysis on our model and its\nperformance indicators.\n3.1 Evaluating Context-Copying\nFrom the initial results, we observe that a number of generated questions seem\nto be simply pulled from the given context, with phrase order reversed.\nIn order to quantify how frequent this behavior is present in the model,\nwe calculate the longest common subsequence (LCS) between the generated\nquestions and its corresponding context paragraph. From this analysis, we ﬁnd\nthat, on average, the model tends to take 6.25 tokens from the context paragraph\nit was given.\nWe observe that in cases where this happens, the generated questions tend\nto be identiﬁcation type questions (who/what/when/where), which comprise\n91.67% of the total generated samples.\nSimplifying Paragraph-level Question Generation 7\nWe hypothesize that the model learned this mode (context-copying) as its\nmost common generation style because of the frequency of identiﬁcation type\nquestions in the training dataset. As we suspected, SQuAD contains 88.26%\nidentiﬁcation type questions in the training set, which lends empirical evidence\nto our hypothesis. This frequency caused the model to learn context-copying\nmore than other generation styles during ﬁnetuning.\nIn the future, diversifying the style of question-answer pairs in the training\nset beyond identiﬁcation type questions will most likely diversity the generation\nstyles of the model.\n3.2 Failure Modes\nAfter testing, we observe that 19 samples from the generated question set were\nnon-questions, generated by the model in “failure mode.” From the 19 samples,\nwe list down two modes:\n1. The last 3 words of the generated question keeps on repeating.\n2. The generated question was cut prematurely.\nExample generations from the two failure modes can be found on Table 2.\nFig. 4.Sample attention visualization for generated outputs of failure mode 1. This\nexample shows the words and the attention values to those words when focusing on\nthe word “profession,” which is highlighted in red.\nFor failure case 1, where the generated question simply keeps repeating words,\nwe surmise that the attention mechanism is not working properly in pinpointing\nimportant context words, which leads to the model being confused in generating\nthe next token.\nWe look towards visualizing the attention mechanism’s behavior while gener-\nating for this failure mode. For the following analysis, we point to the attention\nvisualization in Figure 4.\nWhen observing the attention scores over the context paragraph for failure\ncase 1, we show that the attention mechanism is “confused.” Attention is sup-\nposed to point to speciﬁc positions in the inputs in order to provide context\ninformation better. However, in this case, we see that the attention scores are\n8 E. Lopez et al.\nCase Question Context\n1 What is a profession of the profession\nof the profession of the profession of the\nprofession of the profession of the profes-\nsion of the profession of the profession of\nthe profession\nTeaching may be carried out informally,\nwithin the family, which is called home-\nschooling, or in the wider community.\nFormal teaching may be carried out\nby paid professionals. Such profession-\nals enjoy a status in some societies on a\npar with physicians, lawyers, engineers,\nand accountants (Chartered or CPA).\n2 Which newspaper in the United States\ndeﬁned Southern California as includ-\ning the seven counties of Los Angeles,\nSan Bernardino, Orange, Riverside, San\nDiego, Ventura and Sant\nIn 1900, the Los Angeles Times de-\nﬁned southern California as including\n”the seven counties of Los Angeles,\nSan Bernardino, Orange, Riverside, San\nDiego, Ventura and Santa Barbara.”\nIn 1999, the Times added a newer\ncounty—Imperial—to that list.\nTable 2. Examples of failed generations from the best performing model’s failure\nmodes.\nevenly distributed over a number of random positions in the given context para-\ngraph when generating a token after the word “profession.” Instead of helping\nthe model output the best next token, attention ends up not helping at all. This\nbehavior can be seen in multiple attention heads.\nFor failure case 2, we surmise that the generation is cut simply because it\nreached the maximum generation length while copying text from the context, as\na consequence of the model’s context-copy mode (which it learned as its most\ncommon generation mechanism).\n3.3 Optimal Context Length\nIn order to understand the limits of the model’s robustness, we also look at\nvarying the length of the context paragraph, which we surmise is a performance\nindicator for the model.\nFor every context paragraph in the test set with at least 30 sentences, we\nperform the following:\n1. The context is fed to the model to generate outputs.\n2. The outputs are scored via BLEU, the results are logged.\n3. We then sentence-split the context paragraph using SpaCy, removing the\nlast sentence, and reconstructing the now-modiﬁed context paragraph.\n4. We repeat from step 1 until the modiﬁed context paragraph now only has\none sentence.\nWe remove entire sentences instead of reducing the number of words as this\ninterferes with how intact the information is in the context. The model should\nalso be able to produce a question, disregarding performance, even with just\none sentence as a context paragraph. We also only test context paragraphs with\nat most 30 sentences as, on average, this is the most that ﬁt in GPT-2’s 1024\nmaximum sequence length restriction for inputs.\nAn example of the sentence reduction scheme is shown on Table 3.3.\nSimplifying Paragraph-level Question Generation 9\nSentence\nNumber\nContext\n1 Proportionality is recognised one of the general principles of European Union\nlaw by the European Court of Justice since the 1950s.\n2 Proportionality is recognised one of the general principles of European Union\nlaw by the European Court of Justice since the 1950s. According to the general\nprinciple of proportionality the lawfulness of an action depends on whether it\nwas appropriate and necessary to achieve the objectives legitimately pursued.\n3 Proportionality is recognised one of the general principles of European Union\nlaw by the European Court of Justice since the 1950s. According to the general\nprinciple of proportionality the lawfulness of an action depends on whether it\nwas appropriate and necessary to achieve the objectives legitimately pursued.\nWhen there is a choice between several appropriate measures the least onerous\nmust be adopted, and any disadvantage caused must not be disproportionate to\nthe aims pursued.\n4 Proportionality is recognised one of the general principles of European Union\nlaw by the European Court of Justice since the 1950s.According to the general\nprinciple of proportionality the lawfulness of an action depends on whether it\nwas appropriate and necessary to achieve the objectives legitimately pursued.\nWhen there is a choice between several appropriate measures the least onerous\nmust be adopted, and any disadvantage caused must not be disproportionate to\nthe aims pursued.The principle of proportionality is also recognised in Article\n5 of the EC Treaty, stating that ”any action by the Community shall not go\nbeyond what is necessary to achieve the objectives of this Treaty.\nTable 3. Sample context paragraph after sentence reduction generation, all of the\ncontext in the ﬁgure above would be fed to the best performing model. The ﬁrst\nsentence, second sentence, third sentence, and fourth sentence highlighted in black,\nblue, green, and red respectively\nFrom this analysis, we show that the optimal number of sentences in the\ncontext is more or less 10. As the number of sentences increase from 1 to 10, we\nsee that the performance also increases. However, as we increase the number of\nsentences in the context all the way to 30, the performance is shown to degrade.\nA graph showing the BLEU scores in relation to the number of sentences in the\ncontext paragraph is shown in Figure 5.\nWe hypothesize that this is because the model needs to look at more informa-\ntion in order to identify relevant attention positions as the number of sentences\nincrease. From an interpretative perspective, the performance degradation when\nthe number of sentences increase makes sense because there will be more possible\nquestions to produce from a longer context paragraph than a shorter one.\nA short context paragraph will have a more apparent subject, which can be\ndirectly used by the model’s context-copy mechanism in order to generate good\nquestions. On the other hand, if the model encounters a long context paragraph\nwhere the subject is not apparent (or if the context paragraph has multiple\ntopics/subjects), the context-copy mechanism that the model usually employs\nwill have a hard time pinpointing exact attention positions from where it bases\nits generated questions from.\nFurther analyzing the results, we see that BLEU 1 unsurprisingly degrades\nthe slowest as it only looks at unigram correspondence, while BLEU 4 degrades\nthe fastest, reaching a score of 0 as early as the 17 sentence mark.\n10 E. Lopez et al.\nFig. 5.BLEU scores for each length\nFrom this analysis, we learn that a higher number of sentences in the context\nparagraph will give the model more information to generate a question from, too\nmany sentences will confuse the model and cause its performance to degrade.\n3.4 Answer-Awareness\nGiven that a number of well-performing previous studies on question generation\nuse answer-awareness, we also test if our single-transformer method will beneﬁt\nfrom this additional feature. Answer-awareness refers to the usage of the answer’s\nposition or the answer to the question itself, alongside the context paragraph,\nas input to the model for question generation.\nSuper Bowl 50 was an American football game to determine the champion of the National\nFootball League (NFL) for the 2015 season. The American Football Conference (AFC)\nchampion [ANSS] Denver Broncos [ANSE] defeated the National Football Conference (NFC)\nchampion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was\nplayed on February 7, 2016, at Levi’s Stadium in the San Francisco Bay Area at Santa\nClara, California. As this was the 50th Super Bowl, the league emphasized the ”golden\nanniversary” with various gold-themed initiatives, as well as temporarily suspending the\ntradition of naming each Super Bowl game with Roman numerals (under which the game\nwould have been known as ”Super Bowl L”), so that the logo could prominently feature\nthe Arabic numerals 50. [SEP] Which NFL team represented the AFC at Super Bowl 50?\nFig. 6.A sample training example for answer-aware question generation training. The\nmarked answer span is highlighted in red. Uses the ARTIFICIAL delimiter and the\nOQPL format. Text adapted from SQuAD dataset [13].\nIn order to test this, we employ a OQPL artiﬁcial-based formatting scheme,\nmarking the start position of the answer within the context with a special answer\nSimplifying Paragraph-level Question Generation 11\nstart ([ANSS]) token, and marking the end of the answer with a special answer-\nend ([ANSE]) token.\nA sample input context paragraph with answer-awareness tokens can be\nfound in Figure 6.\nWe then follow the same ﬁnetuning setup as the original OQPL artiﬁcial\nmodel, evaluating on BLEU and ROUGE L scores. A summary of the ﬁnetuning\nresults for the answer-aware model can be found on Table 4.\nModel BLEU 1 BLEU2 BLEU3 BLEU4 ROUGEL\nOQPL Standard 55.60 31.03 16.56 7.89 44.41\nOQPL Answer-Aware 36.07 18.83 10.95 6.40 39.80\nTable 4. Summary of Answer-Aware ﬁnetuning results.\nFrom these results, we can see that the answer-aware models perform signif-\nicantly worse in terms of BLEU score, and marginally worse than the standard\nOQPL artiﬁcial model in terms of ROUGE L.\nWe surmise that this is because the model has no inherent idea what to do\nwith the answer-awareness information, and unlike true answer-aware models like\nUniLM [2], no explicit mechanism that puts importance to the answer-awareness\nis present in the model. While it is possible for the model to inherently learn to\nattend to the answer information, this is not deterministic. An explicit, separate\nmechanism to incorporate answer-awareness in order to help the model learn\nthe feature’s signiﬁcance is still important to have. In the end, the model still\nperforms better without answer-awareness.\n4 Related Literature\nThe most prevalent technique for question generation studies is the usage of a\nsequence-to-sequence (Seq2Seq) model [4,3,20,2] in addition to a variety of other\nfeatures and mechanisms. Attention is also a widely used technique, used by\nworks that employ both standard RNN architectures and Transformer models\n[20,2].\nOther studies employ widely diﬀerent techniques such as using a policy gra-\ndient for reinforcement learning [19], various lingustic features [21], and answer\nawareness [21,19,20,3].\nWhile most of these works produce robust results, they are complex (Seq2Seq\nnaturally using two neural networks instead of one) and use a lot of extra tech-\nniques in order to boost performance. Our work, in comparison, simply uses a\nsingle model (one transformer) instead of two in a Seq2Seq setup. It also uses a\nsimple ﬁnetuning setup, and does not use any extensive modiﬁcations or tech-\nniques. However, it produces robust results that are on par with the state of the\nart in question generation.\n12 E. Lopez et al.\nModel Answer BLEU 4 METEOR ROUGEL\nDu et al. (2017) [4] - 12.28 16.62 39.75\nDu et al. (2018) [3] 15.16 19.12 -\nZhao et al. (2018) [20] (s2s+a) - 4.8 12.52 30.11\nZhao et al. (2018)[20] (s2s-a-at-mcp-gsa) 16.38 20.25 44.48\nDong et al. (2019) [2] 22.12 25.06 51.07\nGPT2 + attention (ours) - 8.26 21.2 44.38\nTable 5. Previous Works with Paragraph Level Input\nOur model outperforms prior RNN-based Seq2Seq works [4,3,20] in terms\nof METEOR and ROUGE L score. It is worth noting that, in addition to a\nmore complex model setup, [20] uses other techniques such as a maxout pointer\nmechanism and gated self attention mechanisms. Other previous work also use\nanswer awareness, using the positions of the answers in the paragraph, or the\nanswers themselves, as additional features for the model. Our transformer uses\nnone of these extra features, yet still achieves robust METEOR and ROUGE L\nscores that outperform these studies.\nOur model performs worse in terms of BLEU 4 and ROUGE L, and slightly\nworse in terms of METEOR when compared with the recent UniLM work of [2].\nIt is important to note that [2] is also the only other work that uses a Transformer\nfor their question generation model. Their incorporation of an answer-awareness\nmechanism, in addition to the multiple modes of ﬁnetuning on a Seq2Seq trans-\nformer produces the best results in recent literature.\nWhile our model performs worse than UniLM, we note that UniLM uses a\nSeq2Seq-based approach, necessitating the use of two separate Transformers: an\nencoder and a decoder. In contrast, our model relies only on a single Transformer-\ndecoder-based language model, eﬀectively halving model complexity. In addition,\nour model does not require any sort of answer tagging, making it suitable for\nsituations where this information is not available in the input context. Our model\nis smaller, less complex, and faster to operate, making it an ideal alternative for\na variety of use cases related to question generation.\n5 Conclusion\nPrevious attempts at paragraph-level question generation have relied on several\nadditional features and techniques in order to produce state-of-the-art results.\nIn this paper, we demonstrate that a simple single Transformer-based question\ngeneration model is able to outperform more complex Seq2Seq methods without\nthe need for additional features, techniques, and training steps. For future work,\nwe plan to evaluate performance on more diﬃcult datasets that pose “why” or\n“how” questions as opposed to SQuAD’s factoid-only questions. We also look\ntowards training with larger model sizes and evaluating the cost-beneﬁt of using\nlarger models as opposed to more eﬃcient ones.\nSimplifying Paragraph-level Question Generation 13\nReferences\n1. Denkowski, M., Lavie, A.: Meteor universal: Language speciﬁc translation evalu-\nation for any target language. In: Proceedings of the EACL 2014 Workshop on\nStatistical Machine Translation (2014)\n2. Dong, L., Yang, N., Wang, W., Wei, F., Liu, X., Wang, Y., Gao, J., Zhou, M., Hon,\nH.: Uniﬁed language model pre-training for natural language understanding and\ngeneration. CoRR abs/1905.03197 (2019), http://arxiv.org/abs/1905.03197\n3. Du, X., Cardie, C.: Harvesting paragraph-level question-answer pairs from\nWikipedia. In: Proceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1: Long Papers). pp.\n1907–1917. Association for Computational Linguistics, Melbourne, Australia\n(Jul 2018). https://doi.org/10.18653/v1/P18-1177, https://www.aclweb.org/\nanthology/P18-1177\n4. Du, X., Shao, J., Cardie, C.: Learning to ask: Neural question generation for\nreading comprehension. CoRR abs/1705.00106 (2017), http://arxiv.org/abs/\n1705.00106\n5. Duan, N., Tang, D., Chen, P., Zhou, M.: Question generation for question an-\nswering. In: Proceedings of the 2017 Conference on Empirical Methods in Nat-\nural Language Processing. pp. 866–874. Association for Computational Linguis-\ntics, Copenhagen, Denmark (Sep 2017). https://doi.org/10.18653/v1/D17-1090,\nhttps://www.aclweb.org/anthology/D17-1090\n6. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8),\n1735–1780 (Nov 1997). https://doi.org/10.1162/neco.1997.9.8.1735\n7. Holtzman, A., Buys, J., Forbes, M., Choi, Y.: The curious case of neural text de-\ngeneration. CoRR abs/1904.09751 (2019), http://arxiv.org/abs/1904.09751\n8. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Bengio,\nY., LeCun, Y. (eds.) 3rd International Conference on Learning Representations,\nICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings\n(2015), http://arxiv.org/abs/1412.6980\n9. Lin, C.Y.: ROUGE: A package for automatic evaluation of summaries. In: Text\nSummarization Branches Out. pp. 74–81. Association for Computational Linguis-\ntics, Barcelona, Spain (Jul 2004), https://www.aclweb.org/anthology/W04-1013\n10. Nappi, J.S.: The importance of questioning in developing critical thinking skills.\nDelta Kappa Gamma Bulletin 84(1), 30 (2017)\n11. Papineni, K., Roukos, S., Ward, T., Zhu, W.J.: Bleu: a method for automatic\nevaluation of machine translation. In: Proceedings of the 40th Annual Meet-\ning of the Association for Computational Linguistics. pp. 311–318. Associa-\ntion for Computational Linguistics, Philadelphia, Pennsylvania, USA (Jul 2002).\nhttps://doi.org/10.3115/1073083.1073135, https://www.aclweb.org/anthology/\nP02-1040\n12. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.: Language\nmodels are unsupervised multitask learners. OpenAI Blog (2019)\n13. Rajpurkar, P., Zhang, J., Lopyrev, K., Liang, P.: SQuAD: 100,000+ ques-\ntions for machine comprehension of text. In: Proceedings of the 2016 Con-\nference on Empirical Methods in Natural Language Processing. pp. 2383–\n2392. Association for Computational Linguistics, Austin, Texas (Nov 2016).\nhttps://doi.org/10.18653/v1/D16-1264\n14. Rus, V., Cai, Z., Graesser, A.: Question generation: Example of a multi-year eval-\nuation campaign. Proc WS on the QGSTEC (2008)\n14 E. Lopez et al.\n15. Sharma, S., El Asri, L., Schulz, H., Zumer, J.: Relevance of unsupervised met-\nrics in task-oriented dialogue for evaluating natural language generation. CoRR\nabs/1706.09799 (2017), http://arxiv.org/abs/1706.09799\n16. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural\nnetworks. In: Advances in neural information processing systems. pp. 3104–3112\n(2014)\n17. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,\n L., Polosukhin, I.: Attention is all you need. In: Advances in neural information\nprocessing systems. pp. 5998–6008 (2017)\n18. Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,\nRault, T., Louf, R., Funtowicz, M., Brew, J.: Huggingface’s transformers: State-\nof-the-art natural language processing. ArXiv abs/1910.03771 (2019)\n19. Yuan, X., Wang, T., Gulcehre, C., Sordoni, A., Bachman, P., Zhang, S., Subra-\nmanian, S., Trischler, A.: Machine comprehension by text-to-text neural question\ngeneration. In: Proceedings of the 2nd Workshop on Representation Learning for\nNLP. pp. 15–25. Association for Computational Linguistics, Vancouver, Canada\n(Aug 2017)\n20. Zhao, Y., Ni, X., Ding, Y., Ke, Q.: Paragraph-level neural question generation\nwith maxout pointer and gated self-attention networks. In: Proceedings of the 2018\nConference on Empirical Methods in Natural Language Processing. pp. 3901–3910.\nAssociation for Computational Linguistics, Brussels, Belgium (Oct-Nov 2018)\n21. Zhou, Q., Yang, N., Wei, F., Tan, C., Bao, H., Zhou, M.: Neural question generation\nfrom text: A preliminary study. CoRR abs/1704.01792 (2017), http://arxiv.\norg/abs/1704.01792",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8498783707618713
    },
    {
      "name": "Transformer",
      "score": 0.7693419456481934
    },
    {
      "name": "Paragraph",
      "score": 0.7405748963356018
    },
    {
      "name": "Language model",
      "score": 0.5893672108650208
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5706393122673035
    },
    {
      "name": "Natural language processing",
      "score": 0.45836102962493896
    },
    {
      "name": "Natural language understanding",
      "score": 0.4522181749343872
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.44666558504104614
    },
    {
      "name": "Natural language",
      "score": 0.44084441661834717
    },
    {
      "name": "Machine learning",
      "score": 0.37792330980300903
    },
    {
      "name": "Speech recognition",
      "score": 0.3311307430267334
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 4
}