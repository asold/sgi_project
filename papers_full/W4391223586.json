{
  "title": "A time series driven model for early sepsis prediction based on transformer module",
  "url": "https://openalex.org/W4391223586",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5100805903",
      "name": "Yan Tang",
      "affiliations": [
        "Maternal and Child Health Hospital of Sichuan Province"
      ]
    },
    {
      "id": "https://openalex.org/A5100635386",
      "name": "Yu Zhang",
      "affiliations": [
        "Sichuan University",
        "West China Hospital of Sichuan University"
      ]
    },
    {
      "id": "https://openalex.org/A5100730105",
      "name": "Jiaxi Li",
      "affiliations": [
        "Maternal and Child Health Hospital of Sichuan Province"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2280404143",
    "https://openalex.org/W2944988359",
    "https://openalex.org/W3153722911",
    "https://openalex.org/W2998853022",
    "https://openalex.org/W2095745816",
    "https://openalex.org/W2107978811",
    "https://openalex.org/W4293242440",
    "https://openalex.org/W4298141779",
    "https://openalex.org/W2372800617",
    "https://openalex.org/W4231930751",
    "https://openalex.org/W2969225972",
    "https://openalex.org/W2996705655",
    "https://openalex.org/W209248235",
    "https://openalex.org/W2891400669",
    "https://openalex.org/W2414319411",
    "https://openalex.org/W2085281262",
    "https://openalex.org/W2944851425",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3003257820",
    "https://openalex.org/W2962862931",
    "https://openalex.org/W4313242224",
    "https://openalex.org/W3020996329",
    "https://openalex.org/W3154953099",
    "https://openalex.org/W4309043919",
    "https://openalex.org/W4211250103",
    "https://openalex.org/W4291284671",
    "https://openalex.org/W2111772099",
    "https://openalex.org/W3036357187",
    "https://openalex.org/W3135864894",
    "https://openalex.org/W2116820788",
    "https://openalex.org/W4213159034",
    "https://openalex.org/W4378717948",
    "https://openalex.org/W2746492441",
    "https://openalex.org/W2947494740",
    "https://openalex.org/W2144621019",
    "https://openalex.org/W3103145119"
  ],
  "abstract": null,
  "full_text": "Tang et al. \nBMC Medical Research Methodology           (2024) 24:23  \nhttps://doi.org/10.1186/s12874-023-02138-6\nRESEARCH Open Access\n© The Author(s) 2024. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom-\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nBMC Medical Research\nMethodology\nA time series driven model for early sepsis \nprediction based on transformer module\nYan Tang1†, Yu Zhang2† and Jiaxi Li1* \nAbstract \nSepsis remains a critical concern in intensive care units due to its high mortality rate. Early identification and interven-\ntion are paramount to improving patient outcomes. In this study, we have proposed predictive models for early sepsis \nprediction based on time-series data, utilizing both CNN-Transformer and LSTM-Transformer architectures. By collect-\ning time-series data from patients at 4, 8, and 12 h prior to sepsis diagnosis and subjecting it to various network mod-\nels for analysis and comparison. In contrast to traditional recurrent neural networks, our model exhibited a substantial \nimprovement of approximately 20%. On average, our model demonstrated an accuracy of 0.964 (± 0.018), a precision \nof 0.956 (± 0.012), a recall of 0.967 (± 0.012), and an F1 score of 0.959 (± 0.014). Furthermore, by adjusting the time win-\ndow, it was observed that the Transformer-based model demonstrated exceptional predictive capabilities, particularly \nwithin the earlier time window (i.e., 12 h before onset), thus holding significant promise for early clinical diagnosis \nand intervention. Besides, we employed the SHAP algorithm to visualize the weight distribution of different features, \nenhancing the interpretability of our model and facilitating early clinical diagnosis and intervention.\nKeywords Sepsis, Transformer, Time-series, SHAP , Predicting, Sepsis\nIntroduction\nSepsis is defined as life-threatening organ dysfunction \ncaused by a dysregulated host response to infection [1]. \nFailure to promptly recognize and intervene with treat -\nment can result in multiple organ dysfunction or even \nfatality. Over the last few decades, due to the timely \nadministration of antibiotics, fluid resuscitation, and \nmulti-organ support therapies, the mortality rate asso -\nciated with sepsis has progressively diminished. Nev -\nertheless, the mortality rate still persists at a high level. \nThe Global Burden of Disease report for the year 2017 \nrevealed a global total of 48.9 million reported cases of \nsepsis, with a mortality rate of 22.5%, accounting for \nnearly 20% of the total global deaths [2–4]. The progres -\nsion speed of sepsis can vary due to individual differences \nand the type of infection, but typically, certain signs and \nsymptoms might emerge during the initial stages of its \nonset. Acknowledging the non-absolute nature of these \nindicators is paramount, given that diverse patients may \npresent varying signs. Moreover, the early symptoms of \nsepsis may sometimes overlap with symptoms of other \ndiseases. Therefore, early prediction of sepsis is crucial \nfor a comprehensive assessment and diagnosis of the \ncondition’s progression.\nAs sepsis patients advance through various disease \nstages, the precise early prediction of a patient’s potential \nprogression to sepsis during the initial phases of inflam -\nmation is critically significant for clinical practitioners. \nThis significance arises from its dual role in not only \nfacilitating the evaluation of disease severity but also in \nenhancing treatment strategies, mitigating unfavorable \n†Yan Tang and Yu Zhang contributed equally to this work.\n*Correspondence:\nJiaxi Li\n576213658@qq.com\n1 Department of Clinical Laboratory Medicine, Jinniu Maternity and Child \nHealth Hospital of Chengdu, Chengdu, China\n2 Information Center, West China Hospital, Sichuan University, Chengdu, \nChina\nPage 2 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \noutcomes, and ultimately prolonging patients’ lives. \nCurrently, various clinical scoring systems, such as the \nSequential Organ Failure Assessment (SOFA) score [5], \nthe Acute Physiology and Chronic Health Evaluation \n(APACHE-II) score [6], and the Predisposition, Insult/\nInfection, Response, and Organ Dysfunction (PIRO) \nscore [7], can assist clinical practitioners in evaluating \npatients’ overall risk and prognosis. Nonetheless, these \nscoring systems are designed for a broader range of criti -\ncally ill patients and are not specifically tailored to sepsis. \nTo prevent the progression of severely infected patients \ninto sepsis, pre-diagnosis and continuous monitoring of \nsepsis are of utmost importance, potentially leading to \nimproved patient survival rates.\nIn recent times, machine learning has played a piv -\notal role in medical research, facilitating the creation of \npredictive models customized to meet specific clinical \nrequirements and data attributes. In contrast to tradi -\ntional clinical scoring systems, machine learning models \npossess the ability to consistently learn from feedback, \nenabling a gradual enhancement of their performance \nover time—an achievement that traditional scoring sys -\ntems might struggle to emulate. The construction of \nexisting sepsis prediction models heavily relies on the \nutilization of machine learning models. For instance, \nCalvert et al. [8] introduced the InSight algorithm, which \nutilizes 9 parameters—8 routine vital signs and patient \nage—to predict sepsis which achieved an Area Under the \nReceiver Operating Characteristic curve (AUROC) of \n0.72. Yao et al. [9] found that the xgboost model outper -\nforms traditional logistic regression models and SOFA \nscores in both discrimination and calibration in early \nidentification of high-risk sepsis mortality patients, with \nAUCs of 0.835, 0.737, and 0.621 respectively. Beyond \nconventional machine learning algorithms, there have \nbeen endeavors within research to explore enhance -\nments utilizing deep learning algorithms. For a predic -\ntion 3 h prior to sepsis onset, Matthieu Scherpf et al. [10] \nexploited a recurrent neural network and achieved an \nAUROC of 0.81.\nNonetheless, most studies face limitations as they \ntend to narrow their focus on only a handful of criti -\ncal patient characteristics or depend on data from spe -\ncific timeframes or intervals, unintentionally neglecting \nthe dynamic evolution of potential clinical features and \ndisease conditions. The signs and symptoms observed \nbefore the onset of sepsis are critically important \nin the development of sepsis. Hence, we propose a \nTransformer-based time-series data prediction model \nthat collects clinical features of patients before illness \nonset, assesses the influence of various retrospective \ntimeframes, and enhances interpretability with the \nShap algorithm [11]. This approach aims to investigate \nclinical factors related to sepsis onset, offering clini -\ncians guidance for effective intervention measures \nwithin the early sepsis onset window.\nData collection and preprocessing\nData collection\nThe eICU Collaborative Research Database is a large, \nmulti-center intensive care unit (ICU) database \n(https:// eicu- crd. mit. edu/ about/ eicu/) established \nthrough a collaboration between the Massachusetts \nInstitute of Technology (MIT) and Philips Group [12]. \nThe database contains clinical data of over 200,000 \npatients from 208 hospitals in the United States, \nrecorded between 2014 and 2015. It includes demo -\ngraphic information, vital signs, laboratory test results, \ntreatments, diagnoses, and other data. The data qual -\nity is high, validated through multiple research studies. \nThis research does not involve any ethical concerns and \nconsent to participate.\nBased on the patient table and diagnosis table \nextracted from the eICU database, we conducted essen -\ntial patient inclusion and exclusion operations, select -\ning patients whose diagnosis includes the keyword \n\"sepsis,\" and ensuring their diagnostic status is \"valid\" \nupon discharge. We also ensured that patients were \n18 years of age or older. Furthermore, given that we are \nestablishing a time-series model, it was necessary to \ncollect data for patients over a specific period. There -\nfore, we opted for patients with a hospital stay exceed -\ning one day. We gathered clinical baseline information, \nall test data during their hospitalization, and vital sign \ndata (both regular and irregular), which served as the \nfoundation for the time-series model. The distinction \nbetween the control group and the sepsis group lies in \nthe absence of any \"sepsis\" incidents during the hospi -\ntalization of patients in the control group. Therefore, \nwe randomly selected 9,000 samples as the control \ngroup and excluded patients with missing data exceed -\ning 30% based on the results. In the end, the sepsis \ngroup included 9,092 individuals, while the control \ngroup consisted of 8,840 individuals (as illustrated in \nFig.  1). Additionally, we have collected 38,895 external \ntest cases from the MIMIC database following the same \nstandards (Non-sepsis: 34,345, Sepsis: 4550) to validate \nthe effectiveness of the model.\nUsing the Python Scikit-learn toolkit (scikit-learn: \nmachine learning in Python — scikit-learn 1.3.0 docu -\nmentation) [13], we split the entire training dataset into a \n70:30 ratio for the training and testing sets. Additionally, \nwe conducted multiple cross-validation tests using k-fold \n(k = 5) [14] to obtain the average performance results of \nthe model.\nPage 3 of 12\nTang et al. BMC Medical Research Methodology           (2024) 24:23 \n \nData preprocessing\nDue to our study is focused on predicting the occur -\nrence of sepsis in advance based on time-series data, \nwe use the diagnosis time of sepsis patients as a ref -\nerence point and collect patient time-series data in \nforward increments of 12  h, 8  h, and 4  h to establish \npredictive models. The eICU database records data in \nminutes relative to the time of admission, creating a \ntimeline of patient data. During the process of handling \ntime-series data, we need to establish the aligned time \nintervals. The start time is uniformly set as the times -\ntamp of the patient’s first recorded data, while the end \ntime is adjusted based on the different prediction time \nwindows. Within the specified time range, we have \nestablished a uniformly spaced time axis to ensure data \nalignment at identical time points.\nTo control the scale of input data, we implemented \nthe following procedures: setting the data sampling \npoints to be one hour apart to ensure data alignment \nat the same time points; collecting data from vari -\nous sources, and identifying the closest time point on \nthe time axis and aligned the data to that specific time \npoint based on the timestamps associated with each \ndata point; using a forward-fill approach to supple -\nment missing data that might occur during the align -\nment process when data for a particular time point was \nabsent to maintain data continuity and applying mean \nimputation to ensure data completeness for patients \nFig. 1 Data inclusion and exclusion process\nPage 4 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \nwith entirely missing features. The specific process is as \nfollows (Fig. 2 ):\nUtilizing the Python Scikit-learn toolkit (scikit-learn: \nmachine learning in Python — scikit-learn 1.3.0 docu -\nmentation) [13], we partitioned the preprocessed data \ninto training and testing sets, maintaining a 7:3 ratio. This \nensured that 70% of the data was allocated to the train -\ning set, with the remaining 30% dedicated to the testing \nset. To facilitate unbiased model selection and hyperpa -\nrameter optimization, we adopted a fivefold cross-val -\nidation approach [14]. It is crucial to note that the test \nset, employed for the final model evaluation, remained \nentirely independent and played no role in the model \nselection or parameter optimization processes.\nModel construction\nWith the widespread adoption of electronic medical \nrecord systems, healthcare institutions have accumulated \na vast amount of time-series data, which contains rich \nclinical information. Conventional predictive modeling \napproaches are confronted with the formidable task of \neffectively modeling extensive and intricate time-series \ndata. To harness these data more effectively, deep learn -\ning models have emerged, capable of automatically learn-\ning complex patterns and features within the data. Over \nthe past few years, RNN (Recurrent Neural Network) and \ntheir variants, such as LSTM (Long Short-Term Mem -\nory), as well as Transformer models, have been widely \napplied to clinical prediction tasks. By considering the \ntemporal dependencies between observed outcomes, \nthey effectively model time-series data.\nRNN: Recurrent Neural Networks are a type of neural \nnetwork model based on a cyclic structure [15], designed \nfor processing sequential data. Their core concept \ninvolves the transmission and retention of information \nacross time dimensions through recurrent connections. \nAn RNN consists of recurrent units, with each unit \nreceiving input from the current time step as well as the \nhidden state from the previous time step, and it outputs \nthe hidden state for the current time step. This architec -\nture enables RNNs to leverage context information and \ncapture temporal dependencies within sequences.\nLSTM: Long Short-Term Memory networks are an \nimproved variant of recurrent neural network architec -\nture designed to address the issues of gradient vanishing \nand exploding gradients in traditional RNNs [16]. LSTM \nintroduces gate mechanisms, including the input gate, \nforget gate, and output gate. The input gate determines \nhow much new information should be added to the hid -\nden state of the current time step, the forget gate controls \nhow much of the previous time step’s hidden state should \nbe forgotten, and the output gate regulates how much \ninformation should be output from the hidden state of \nthe current time step. Through these gate mechanisms, \nLSTM can effectively capture long-term dependencies \nwhile mitigating the problems associated with gradient \nvanishing and exploding gradients.\nWith the introduction of Transformer models [17], \ndeep learning has witnessed a significant breakthrough in \nthe field of time-series data modeling. Transformer mod-\nels, through their self-attention mechanism, can capture \nglobal dependencies, mitigating the issues of information \nloss and gradient vanishing encountered in traditional \nRNN models. Consequently, they exhibit advantages in \nhandling long-term dependencies and large-scale time-\nseries data.\nTraditional Transformer networks, when dealing \nwith two-dimensional input matrices, typically embed \nFig. 2 Data processing workflow\nPage 5 of 12\nTang et al. BMC Medical Research Methodology           (2024) 24:23 \n \neach element of the 2D matrix into a high-dimensional \nspace and then employed the Transformer’s self-atten -\ntion mechanism to capture dependencies between \nthese elements. In the conventional architecture of the \nTransformer network, the Encoder layer typically com -\nmences with an Embedding layer. This Embedding layer \nis responsible for transforming each time-series feature \ninto a vector representation, subsequently serving as the \ninput for the Transformer. In this experiment, we trans -\nform time-series data matrices based on the model’s \ninput feature quantity N and a maximum of 300 time \npoints, then replace the traditional Embedding layer with \neither an LSTM network or a CNN network to combine \nand extract features from the time-series data to enhance \nfeature diversity and richness. Within the Transformer’s \nEncoder module, the input data undergoes self-atten -\ntion mechanisms to extract both local and global fea -\ntures from the time-series data. Ultimately, classification \nresults are derived through the utilization of fully con -\nnected layers and a SoftMax layer. The detailed network \narchitecture is outlined below (Fig. 3):\nThe main contribution of this study lies in introducing \na novel time-series data modeling approach specifically \ndesigned for sepsis patients. This approach effectively \naccommodates time-series data of varying lengths and \nfrequencies. Our goal is to facilitate early and precise \nsepsis prediction, consequently extending the crucial \ntimeframe for early intervention and treatment of sepsis \npatients. Furthermore, this method upholds a robust pre-\ndictive performance.\nStatistics\nCategorical variables are presented as counts and per -\ncentages, and continuous variables are presented as mean \nand standard deviation (SD). Comparisons between \ngroups were performed by 2-tailed t-test for continuous \nvariables and chi-square test for categorical variables. All \nstatistical analyses were performed in the python package \nSciPy (SciPy) [18]. The statistical significance was consid -\nered as P < 0.5.\nSHAP‑Visualization\nIn 2017, Lundberg proposed the SHAP (Shapley additive \nexplanations) method. SHAP exhibits additivity consist -\nency in explaining the output results [19], consistent with \nthe general notion of regression. For each predicted sam -\nple, the model generates a predicted value, and the SHAP \nvalue is the assigned numerical value to each feature in \nthat sample. Assuming the i-th sample is denoted as x i, \nthe j-th feature of the i-th sample is denoted as x ij, the \nmodel’s predicted value for the i-th sample is yi, and the \nmean of all sample predictions is denoted as y base. Then, \nthe SHAP value of  xij follows the following equation:\nFig. 3 The architecture of CNN-Transformer and LSTM-Transformer\nPage 6 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \nHere, f\n(\nx i, j\n)\n represents the SHAP value of xij. This \nfeature ensures that the sum of the contribution values \nequals the final output, thereby eliminating the interpret-\nability differences caused by structural variations among \ndifferent models.\nThe main idea behind SHAP is derived from the Shap -\nley value in cooperative game theory. Shapley devel -\noped this method to address the problem of allocating \ncooperative benefits among multiple players. In a set \nI = {1,2,…,n} of n participants, if there exists a coop -\nerative benefit function v for any subset S of I that sat -\nisfies v(∅) = 0 and for any disjoint subsets S1 and S2 of I \nexist v(S1 ∪ S2) ≥ v(S1) + v (S2), then for each participant \ninvolved, the allocation of their contribution x = {x1,x2,…\n,xn} must satisfy the following conditions for cooperation \nto occur: xi = v(i)i = 1, 2,... ,n , xi ≥ v(i), i = 1,2,…,n. \nIn other words, each participant should receive no less \nthan their individual contribution in a non-cooperative \nscenario, and the sum of the allocations should equal the \ntotal benefit. For the benefit function v, the allocation \nϕ (v) = (ϕ 1 (v),ϕ 2 (v),... ,ϕ n(v)) has been proven to sat -\nisfy the following properties:\nHere, T is a subset of the set, |T| represents the number \nof elements in the subset, and n represents the total num-\nber of members. SHAP builds upon the Shapley value and \nmakes improvements suitable for Machine learning mod-\nels. It treats features as players and model outputs as the \ncooperative results. For the K-th data point, the model \noutput can be represented as vk(I), The contribution value \nof each feature at that data point, denoted as ϕ i(vk ) , is \nalso known as the SHAP value. Unlike linear models that \nuse the magnitude of parameters or coefficients to meas -\nure the contribution of a feature to the model, the SHAP \nalgorithm calculates the combined contributions of each \nfeature for every sample. In the end, we obtain the contri-\nbution of each feature in each sample. If a feature exhibits \nconsistent trends across most samples, it indicates that \nthe model recognizes the importance of that feature in \neither a positive or negative direction.\nResults\nPatient characteristics\nThe cohort included 17,932 ICU patients, of whom 9092 \npatients (50.70%) developed sepsis. The mortality rate of \nsepsis patients is significantly higher compared to regu -\nlar ICU patients, showing a notable difference (Sepsis: \n14.19% vs. Non-Sepsis: 7.86%). Furthermore, the BMI \n(1)yi = ybase + f(xi,1) + f(xi,2) +···+ f(xi,k )\n(2)\nϕ i(v) =\n∑\nT ∈ I\ni ∈ T\n(|T |− 1)!(n − |T |)!\nn! (v(T ) − v(T − {i}))\nindex of sepsis patients is also significantly lower than \nthat of regular ICU patients (Sepsis: 15.72  ± 5.29 vs. Non-\nSepsis: 20.67  ± 6.62), highlighting the substantial harm \nthat sepsis poses to patient prognosis. Regarding patient \nage, there was no statistical significance ( P > 0.05). The \nbasic demographic characteristics of the cohort are pre -\nsented in Table 1.\nModel performance\nWith a 12-h time window selected, Fig.  4 displays \nthe area under the receiver operating characteristic \n(AUROC) curves for these predictive models. Among \nthe three models, the LSTM-Transformer exhibited the \nhighest performance, reaching up to 0.99. Based on the \nLSTM-Transformer model, the specific model classifica -\ntion results are presented using a confusion matrix (as \nshown below). In this investigation, we introduce time \nwindows and employ Transformer self-attention mod -\nules to holistically scrutinize their impact on model per -\nformance. We scrutinize the clinical metrics obtained \nduring the patients’ inaugural hospitalization, and con -\ncomitantly integrate them with conventional recurrent \nneural networks to formulate our foundational model. \nThis culmination yields an AUROC value of 0.58, serving \nas a baseline for our research.\nIn addition, we employed various statistical metrics to \nevaluate and compare the results among different models \non the same test dataset, including accuracy, precision, \nTable 1 Base characteristics of the included patients\n*  Chi-square test\nVariables (mean ± SD) Non-Sepsis Sepsis P\nSex 0.011*\n Female 3980 (45.02%) 4286 (47.14%)\n Male 4860 (54.97%) 4806 (52.86%)\nAge(yrs) 65.32 ± 16.05 65.29 ± 16.06  > 0.05\nBMI 20.67 ± 6.62 15.72 ± 5.29  < 0.001\nDischarge status  < 0.001*\n Alive 8144 (92.13%) 7800 (85.79%)\n Expired 695 (7.86%) 1290 (14.19%)\nUnit type  < 0.001*\n Cardiac ICU 569 (6.44%) 802 (8.82%)\n CCU-CTIU 403 (4.56%) 506 (5.57%)\n CSICU 1226 (13.87%) 194 (2.13%)\n CTICU 461 (5.21%) 57 (0.63%)\n Med-Surg ICU 5233 (59.20%) 6044 (66.48%)\n MICU 292 (3.30%) 918 (10.10%)\n Neuro ICU 614 (6.95%) 208 (2.29%)\n SICU 42 (0.48%) 363 (3.99%)\nICU stay 3.27 (2.35) 5.76 (6.74)  < 0.001\nApachescore 64.27 (27.54) 73.87 (27.36)  < 0.001s\nPage 7 of 12\nTang et al. BMC Medical Research Methodology           (2024) 24:23 \n \nrecall, F1 score, and others. Additionally, based on 5-fold \ncross-validation, the average results of the improved \nTransformer-based model indicate a significant enhance-\nment in all performance metrics (Table 2).\nBy adjusting different time windows and collecting \ntime-series data from patients in the 4-h and 8-h peri -\nods before sepsis diagnosis, we compared the predic -\ntive performance of different network models. It can be \nobserved that our LSTM-Transformer model exhibited \nfavorable performance as early as the 12-h window, and \nas we extended the review window, the improvement \nin model performance was not particularly significant \n(Fig. 5A). Based on the prediction model, weight analysis \nis conducted using the SHAP algorithm, which generates \nvisual heatmaps. The Fig.  5B displays the activation fea -\nture ranking based on the LSTM-transformer model in \nthe 12-h window.\nConsidering the generalization of the model, we uti -\nlized data from MIMIC (Medical Information Mart \nfor Intensive Care) for external validation. The over -\nall accuracy has experienced a modest decrease, with \nan accuracy of approximately 80% and the AUC value \nstill hovers around 0.9 in the time window (advance 4 \nfours) + LSTM-Transformer model. The predicted results \nfor different time windows are as shown in Fig. 6.\nHospital system integration with predictive models\nIn our research, we are also exploring integration with \nhospital information systems by collecting real-time \npatient data for model testing, with the goal of provid -\ning meaningful assistance to clinical sepsis patients. \nTo achieve this, we have devised the following system \nintegration framework, illustrated in Fig.  7: gather -\ning patient’s fundamental information, laboratory test \nresults, and vital signs monitoring values since admis -\nsion, and consolidating this data in a centralized data \ncenter. Considering that patients generate time-series \ndata every minute, it is impractical to continually assess \ntheir sepsis risk. Therefore, we propose setting an inter -\nval, such as five or ten minutes, to collect patient data \nusing a 300 * N time window. This data is then processed \nthrough an Application Programming Interface (API) to \nFig. 4 The results of different models and the confusion matrix of LSTM-transformer\nTable 2 The outcomes of prediction models(mean ± std)\nModel Baseline Time window + RNN Time window + LSTM Time \nwindow + CNN + Transformer\nTime \nwindow + LSTM + Transformer\nAccuracy 0.637 (0.035) 0.653 (0.032) 0.835 (0.023) 0.951 (0.017) 0.964 (0.018)\nPrecision 0.711 (0.037) 0.715 (0.030) 0.875 (0.047) 0.955 (0.028) 0.956 (0.012)\nRecall 0.677 (0.044) 0.691 (0.041) 0.861 (0.011) 0.951 (0.012) 0.967 (0.012)\nF1-score 0.667 (0.045) 0.662 (0.039) 0.871 (0.054) 0.954 (0.023) 0.959 (0.014)\nPage 8 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \ninvoke deep learning models, providing predicted out -\ncomes for 4  h, 8  h, and 12  h back to the patient moni -\ntoring system. The final decision on whether to clinically \nintervene rests with the doctor, thus completing the \nentire closed-loop process. Currently, we have finalized \nthe framework design, however, the implementation of \nclinical applications entails tasks such as data integration, \nsystem integration, and obtaining ethical approvals. This \nprocess necessitates some additional time.\nDiscussion\nMachine learning is considered a promising approach for \nsepsis prediction in the ICU. The key to sepsis prevention \nis the early identification and treatment of the underlying \ncauses of the inflammatory response. Early diagnosis and \ntimely intervention in sepsis patients can significantly \nimprove outcomes. Therefore, there is an urgent need \nfor an accurate and efficient sepsis bedside early predic -\ntion tool. In this study, we constructed a model for early \nprediction of sepsis in ICU patients. By collecting time-\nseries data from patients in the 4-h, 8-h, and 12-h peri -\nods before sepsis diagnosis and inputting it into different \nnetwork models for comparative analysis, we found that \nthe time-series model based on the Transformer archi -\ntecture demonstrated outstanding predictive capabilities \nin an earlier time window (i.e., 12  h before onset). This \nfinding provides an opportunity for earlier clinical inter -\nvention, which has the potential to result in significant \nenhancements in disease management and patient care. \nAs the time window gradually shifts backward, tradi -\ntional recurrent neural network models also progres -\nsively exhibit performance improvements. This implies \nthat in the later stages of disease progression, traditional \nmodels gradually approach the advantages exhibited by \nTransformer-based models in the early stages. It high -\nlights the potential of Transformer-based time-series \nmodels for early prediction, offering a more forward-\nlooking tool for clinical practice. However, it’s impor -\ntant to note that the gradual improvement of traditional \nrecurrent neural networks in later-stage prediction may \nstem from their enhanced capability to capture long-term \ntemporal relationships. Therefore, by considering the \nstrengths of both models, it is possible to develop more \nprecise and individualized treatment plans for healthcare \nteams, potentially leading to greater impacts on patient \nhealth outcomes.\nA sufficiently large dataset is key to training machine \nlearning models for achieving good performance. The \ninclusion of new tests and technologies can enhance our \nprediction tasks, but their direct integration into exist -\ning machine learning models is often impractical. There -\nfore, transfer learning may be a promising and viable \nstrategy to maintain the effectiveness of machine learn -\ning models across multi-center deployments. Chen et al. \nimproved the performance of LightGBM and MLP mod -\nels in predicting sepsis occurrence within 1–5  h using \nTransformer, achieving favorable areas under the receiver \noperating characteristic curve (AUC) within the range \nof 0.96–0.98 [20]. In our study, the process of transfer \nlearning effectively enhanced the performance of RNN \nand LSTM models in predicting sepsis occurrence in the \ne-ICU dataset. When predicting sepsis occurrence 12  h \nin advance, compared to traditional RNN and LSTM \nmodels, the CNN-Transformer and LSTM-Transformer \nmodels demonstrated a clear advantage. Among these, \nthe LSTM-Transformer showed the best area under the \nFig. 5 A Results of different models at different time windows. B The activation feature ranking based on the LSTM-transformer model in the 12-h \nwindow\nPage 9 of 12\nTang et al. BMC Medical Research Methodology           (2024) 24:23 \n \ncurve (AUC) of 0.99, accuracy of 95.6%, and recall of \n0.967. Furthermore, transfer learning has been applied \nto similar domains or tasks in multiple medical fields, \nreducing the requirements for target dataset size while \nenhancing training speed and prediction performance \n[21, 22]. The results of this study clearly demonstrate \nthe potential benefits of Transformer models in clini -\ncal prediction and underscore the critical role of model \nselection within specific time windows. This exploratory \nresearch not only brings new perspectives to medical \nresearch but also provides valuable insights for the future \ndevelopment of healthcare practices. Sepsis often leads \nto organ dysfunction and damage, and acute respiratory \ndistress syndrome (ARDS) can exacerbate acute injuries. \nTherefore, ARDS is typically considered a fatal conse -\nquence of severe sepsis, accounting for approximately \n32% of all cases of sepsis [23]. ARDS usually manifests \nas a sudden exacerbation of non-cardiogenic pulmo -\nnary edema, severe hypoxemia, and requires mechani -\ncal ventilation to improve oxygenation [24]. For patients \nadmitted to the ICU due to respiratory system diseases, \nespecially COVID-19, respiratory parameters are closely \nrelated to ICU mortality. Plateau pressure, which is the \npressure inside the alveoli during breath-holding positive \npressure ventilation, has been analyzed for its impact on \nthe prognosis of ARDS patients [25]. Timely monitoring \nFig. 6 The external validation results on the MIMIC dataset (0: Non-sepsis, 1: Sepsis)\nPage 10 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \nof a patient’s respiratory condition plays a positive role in \nimproving their prognosis.\nEnhancing the interpretability of data-driven models \ncan help overcome the barriers to trust and acceptance \nof these machine learning models by practitioners in \nclinical settings. In this study, SHAP analysis served as an \ninterpretive tool, aiding healthcare professionals in iden -\ntifying key risk factors. In our study, the importance of \nvariables showed that heartbeat rate, BNP , AST, respira -\ntion, Sao2, and palates were the most important risk fac -\ntors that contribute to the predicted occurrence of sepsis. \nThe concept of heart rate analysis has been around for \ndecades, and with the continuous improvement in com -\nputing power, it has become increasingly important [26]. \nAtrial fibrillation (AF) is a common complication of sep -\nsis, and continuous heart rate variability monitoring con -\ntributes to the rapid diagnosis and early intervention of \nsevere sepsis, altering the course of sepsis-related condi -\ntions [27]. Additionally, heart rate is another important \nfactor in predicting the occurrence of sepsis-related \nacute brain injury [28]. Furthermore, elevated BNP levels \nhave practical applications in the early diagnosis, clini -\ncal treatment, and prognosis assessment of severe sepsis \npatients. BNP is one of the members of the natriuretic \npeptide family secreted by the heart. It promotes diure -\nsis and sodium excretion, effectively dilates blood vessels, \nand anti-natriuretic peptide is an important marker for \nassessing heart damage [29]. The excessive inflammatory \nstress response in sepsis generates more cardiac toxins, \nand infections by pathogenic microorganisms can also \nproduce more endotoxins, thereby inducing an increase \nin BNP levels in the body [30]. Sepsis can lead to multi-\norgan damage and even failure. During systemic infec -\ntion, the cytokine storm and endotoxin production in \nsepsis can damage liver cells, resulting in organ dys -\nfunction. Damaged liver cells release damage-associated \nmolecular patterns, triggering a more severe systemic \ninflammatory response, and in severe cases, it can lead \nto death [31]. Abnormal levels of serum aspartate ami -\nnotransferase (AST) are sensitive indicators of liver cell \ndamage [32]. Early testing of liver function parameters \nbefore the onset of sepsis can improve patient survival \nto some extent. Furthermore, sepsis is associated with \nan increased platelet reactivity [33]. There is evidence to \nsuggest that cytokines released during sepsis can directly \nactivate platelets [34]. Sepsis is also related to an increase \nin bone marrow platelet release, leading to thrombocy -\ntosis, which is mediated by elevated levels of platelet \ngrowth factors and cytokines such as interleukin-6 [35].\nLimitations\nThe limitations of this experiment include the fact that \nboth model training and validation were based on the \nsame publicly available dataset. When externally validat -\ning with the MIMIC dataset, there was a certain degree \nof decline observed in its predictive performance. In the \nFig. 7 The framework of hospital system integration with predictive models\nPage 11 of 12\nTang et al. BMC Medical Research Methodology           (2024) 24:23 \n \nfuture, we will consider incorporating data from addi -\ntional sources while integrating this model with hospital \ninformation systems to validate its effectiveness. Addi -\ntionally, in terms of model interpretability, we have only \nvalidated the overall associations between clinical indi -\ncators and sepsis occurrence within the predefined 12-h \nwindow. Visual analysis at specific time points and the \ninterpretation of individual patient clinical information \nhave not been implemented yet.\nAuthors’ contributions\nY.T, and Y.Zcontributed equally. J.L and YT conceptualized the study. Y.Z and Y.T \ncarried out the collection and analysis of the literature and data, and drafted \nthe manuscript. All authors reviewed and approved the final version of the \nmanuscript.\nFunding\nThis research was primarily supported by project 2022016 from the Sichuan \nHealth Informatics Association and Sichuan Province Maternal and Child \nHealth Medical Science and Technology Innovation Project(22FXYB01).\nAvailability of data and materials\nThe data used in this study were sourced from the publicly available eICU \ndatabase (https:// eicu- crd. mit. edu/ about/ eicu/). For access to the related \ncode, please contact the corresponding author.\nDeclarations\nEthics approval and consent to participate\nThe data for this study were obtained from the publicly available eICU data-\nbase and do not involve any ethical concerns and consent to participate.\nConsent for publication\nNA.\nCompeting interests\nThe authors declare no competing interests.\nReceived: 10 September 2023   Accepted: 27 December 2023\nReferences\n 1. Singer M, Deutschman CS, Seymour CW, et al. The third international \nconsensus definitions for sepsis and septic shock (Sepsis-3). JAMA. \n2016;315(8):801–10.\n 2. Seymour CW, Kennedy JN, Wang S, et al. Derivation, validation, and \npotential treatment implications of novel clinical phenotypes for sepsis. \nJAMA. 2019;321(20):2003–17. https:// doi. org/ 10. 1001/ jama. 2019. 5791.\n 3. Gavelli F, Castello LM, Avanzi GC. Management of sepsis and septic shock \nin the emergency department. Intern Emerg Med. 2021;16(6):1649–61. \nhttps:// doi. org/ 10. 1007/ s11739- 021- 02735-7.\n 4. Rudd KE, Johnson SC, Agesa KM, et al. Global, regional, and national sep-\nsis incidence and mortality, 1990–2017: analysis for the Global Burden of \nDisease Study. Lancet. 2020;395(10219):200–11. https:// doi. org/ 10. 1016/ \nS0140- 6736(19) 32989-7.\n 5. Minne L, Abu-Hanna A, de Jonge E. Evaluation of SOFA-based mod-\nels for predicting mortality in the ICU: a systematic review. Crit Care. \n2008;12(6):1–13.\n 6. Knaus WA, Draper EA, Wagner DP , et al. APACHE II: a severity of disease \nclassification system. Crit Care Med. 1985;13(10):818–29.\n 7. Dronamraju S, Agrawal S, Kumar S, et al. Comparison of PIRO, APACHE \nIV, and SOFA Scores in Predicting Outcome in Patients with Sepsis \nAdmitted to Intensive Care Unit: A Two-year Cross-sectional Study at \nRural Teaching Hospital. Indian J Crit Care Med. 2022;26(10):1099–105. \nhttps:// doi. org/ 10. 5005/ jp- journ als- 10071- 24323.\n 8. Calvert JS, Price DA, Chettipally UK, et al. A computational approach to \nearly sepsis detection. Comput Biol Med. 2016;74:69–73.\n 9. Medicine TLR. Opening the black box of machine learning. Lancet Respir \nMed. 2018;6(11):801. https:// doi. org/ 10. 1016/ S2213- 2600(18) 30425-9.\n 10. Scherpf M, Gräßer F, Malberg H, et al. Predicting sepsis with a recur -\nrent neural network using the MIMIC III database. Comput Biol Med. \n2019;113:103395.\n 11. Parsa AB, Movahedi A, Taghipour H, et al. Toward safer highways, \napplication of XGBoost and SHAP for real-time accident detection and \nfeature analysis. Accid Anal Prev. 2020;136:105405.\n 12. Pollard TJ, Johnson AEW, Raffa JD, et al. The eICU Collaborative \nResearch Database, a freely available multi-center database for critical \ncare research. Sci Data. 2018;5(1):1–13.\n 13. Kramer O, Kramer O. Scikit-learn[J]. Machine learning for evolution \nstrategies. 2016:45–53. https:// doi. org/ 10. 1007/ 978-3- 319- 33383-0\n 14. Fushiki T. Estimation of prediction error by using K-fold cross-validation. \nStat Comput. 2011;21:137–46.\n 15. Medsker LR, Jain LC. Recurrent neural networks. Des Appl. \n2001;5(64–67):2.\n 16. Yu Y, Si X, Hu C, et al. A review of recurrent neural networks: LSTM cells \nand network architectures. Neural Comput. 2019;31(7):1235–70.\n 17. Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. Adv \nNeural Inf Process Syst. 2017;30. https:// doi. org/ 10. 48550/ arXiv. 1706. \n03762.\n 18 Virtanen P , Gommers R, Oliphant TE, et al. SciPy 1.0: fundamen-\ntal algorithms for scientific computing in Python. Nat Methods. \n2020;17(3):261–72.\n 19. Lundberg S M, Lee SI. A unified approach to interpreting model predic-\ntions. Adv Neural Inf Process Syst. 2017;30. https:// doi. org/ 10. 48550/ \narXiv. 1705. 07874.\n 20. Chen Q, Li R, Lin C, et al. Transferability and interpretability of the sepsis \nprediction models in the intensive care unit. BMC Med Inform Decis \nMak. 2022;22(1):343. https:// doi. org/ 10. 1186/ s12911- 022- 02090-3. \nPublished 2022 Dec 29.\n 21. Morid MA, Borjali A, Del Fiol G. A scoping review of transfer learning \nresearch on medical image analysis using ImageNet. Comput Biol Med. \n2021;128:104115. https:// doi. org/ 10. 1016/j. compb iomed. 2020. 104115.\n 22. Tseng KK, Wang C, Huang YF, Chen GR, Yung KL, Ip WH. Cross-Domain \nTransfer Learning for PCG Diagnosis Algorithm. Biosensors (Basel). \n2021;11(4):127. https:// doi. org/ 10. 3390/ bios1 10401 27. Published 2021 \nApr 20.\n 23 Gong H, Chen Y, Chen M, et al. Advanced development and mecha-\nnism of sepsis-related acute respiratory distress syndrome. Front Med \n(Lausanne). 2022;9:1043859. https:// doi. org/ 10. 3389/ fmed. 2022. 10438 \n59. Published 2022 Nov 14.\n 24 Matthay MA, Zemans RL, Zimmerman GA, et al. Acute respiratory \ndistress syndrome. Nat Rev Dis Primers. 2019;5(1):18. https:// doi. org/ 10.  \n1038/ s41572- 019- 0069-0. Published 2019 Mar 14.\n 25. Supady A, Combes A, Barbaro RP , et al. Respiratory indications for \nECMO: focus on COVID-19. Intensive Care Med. 2022;48(10):1326–37. \nhttps:// doi. org/ 10. 1007/ s00134- 022- 06815-w.\n 26 Billman GE. Heart rate variability - a historical perspective. Front Physiol. \n2011;2:86. https:// doi. org/ 10. 3389/ fphys. 2011. 00086. Published 2011 \nNov 29.\n 27. Wee BYH, Lee JH, Mok YH, Chong SL. A narrative review of heart rate \nand variability in sepsis. Ann Transl Med. 2020;8(12):768. https:// doi.  \norg/ 10. 21037/ atm- 20- 148.\n 28. Zhang LN, Wang XT, Ai YH, et al. Epidemiological features and risk \nfactors of sepsis-associated encephalopathy in intensive care unit \npatients: 2008–2011. Chin Med J (Engl). 2012;125(5):828–31.\n 29. Liu J, Wang CJ, Ran JH, et al. The predictive value of brain natriuretic \npeptide or N-terminal pro-brain natriuretic peptide for weaning out -\ncome in mechanical ventilation patients: Evidence from SROC. J Renin \nAngiotensin Aldosterone Syst. 2021;22(1):1470320321999497. https://  \ndoi. org/ 10. 1177/ 14703 20321 999497.\n 30. Di Somma S, Magrini L, Ferri E. In-hospital brain natriuretic peptide and \nN-terminal prohormone brain natriuretic peptide variations are predic-\ntors of short-term and long-term outcome in acute decompensated \nheart failure. Crit Care. 2011;15(1):116. https:// doi. org/ 10. 1186/ cc9970.\nPage 12 of 12Tang et al. BMC Medical Research Methodology           (2024) 24:23 \n 31. Liang H, Song H, Zhang X, et al. Metformin attenuated sepsis-related \nliver injury by modulating gut microbiota. Emerg Microbes Infect. \n2022;11(1):815–28. https:// doi. org/ 10. 1080/ 22221 751. 2022. 20458 76.\n 32 Chinnappan R, Mir TA, Alsalameh S, et al. Aptasensors Are Conjectured as \nPromising ALT and AST Diagnostic Tools for the Early Diagnosis of Acute \nLiver Injury. Life (Basel). 2023;13(6):1273. https:// doi. org/ 10. 3390/ life1 \n30612 73. Published 2023 May 29.\n 33. Akinosoglou K, Theodoraki S, Xanthopoulou I, et al. Platelet reactivity in \nsepsis syndrome: results from the PRESS study. Eur J Clin Microbiol Infect \nDis. 2017;36(12):2503–12. https:// doi. org/ 10. 1007/ s10096- 017- 3093-6.\n 34. Houck KL, Yuan H, Tian Y, et al. Physical proximity and functional coopera-\ntion of glycoprotein 130 and glycoprotein VI in platelet membrane lipid \nrafts. J Thromb Haemost. 2019;17(9):1500–10. https:// doi. org/ 10. 1111/ jth. \n14525.\n 35. Kaser A, Brandacher G, Steurer W, et al. Interleukin-6 stimulates throm-\nbopoiesis through thrombopoietin: role in inflammatory thrombocytosis. \nBlood. 2001;98(9):2720–5. https:// doi. org/ 10. 1182/ blood. v98.9. 2720.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Interpretability",
  "concepts": [
    {
      "name": "Interpretability",
      "score": 0.752264142036438
    },
    {
      "name": "Sepsis",
      "score": 0.5349712371826172
    },
    {
      "name": "Transformer",
      "score": 0.5212243795394897
    },
    {
      "name": "Window of opportunity",
      "score": 0.5028018951416016
    },
    {
      "name": "Medicine",
      "score": 0.47219574451446533
    },
    {
      "name": "Computer science",
      "score": 0.45678433775901794
    },
    {
      "name": "Artificial intelligence",
      "score": 0.45306214690208435
    },
    {
      "name": "Intensive care",
      "score": 0.44462907314300537
    },
    {
      "name": "Machine learning",
      "score": 0.44044530391693115
    },
    {
      "name": "Time series",
      "score": 0.4148472249507904
    },
    {
      "name": "Data mining",
      "score": 0.3438209295272827
    },
    {
      "name": "Intensive care medicine",
      "score": 0.19718921184539795
    },
    {
      "name": "Internal medicine",
      "score": 0.16880905628204346
    },
    {
      "name": "Engineering",
      "score": 0.1303882896900177
    },
    {
      "name": "Real-time computing",
      "score": 0.11831989884376526
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210124723",
      "name": "Maternal and Child Health Hospital of Sichuan Province",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I24185976",
      "name": "Sichuan University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210089761",
      "name": "West China Hospital of Sichuan University",
      "country": "CN"
    }
  ],
  "cited_by": 26
}