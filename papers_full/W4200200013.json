{
    "title": "Transformer-Based Generative Model Accelerating the Development of Novel BRAF Inhibitors",
    "url": "https://openalex.org/W4200200013",
    "year": 2021,
    "authors": [
        {
            "id": "https://openalex.org/A1904849205",
            "name": "Yang Li-juan",
            "affiliations": [
                "Ji Hua Laboratory",
                "Institute of Modern Physics",
                "Chinese Academy of Sciences",
                "University of Chinese Academy of Sciences",
                null
            ]
        },
        {
            "id": "https://openalex.org/A1500781152",
            "name": "Yang Guanghui",
            "affiliations": [
                "Institute of Modern Physics",
                "Chinese Academy of Sciences",
                "Ji Hua Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A5094336523",
            "name": "Bing Zhitong",
            "affiliations": [
                "Institute of Modern Physics",
                "Chinese Academy of Sciences",
                "Ji Hua Laboratory"
            ]
        },
        {
            "id": "https://openalex.org/A2092245569",
            "name": "Tian Yuan",
            "affiliations": [
                "Chinese Academy of Sciences",
                "Lanzhou University",
                "Institute of Modern Physics"
            ]
        },
        {
            "id": "https://openalex.org/A2385930010",
            "name": "Niu Yu-zhen",
            "affiliations": [
                "Shandong University of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2070624805",
            "name": "Huang Liang",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A2037538644",
            "name": "Yang Lei",
            "affiliations": [
                "University of Chinese Academy of Sciences",
                "Institute of Modern Physics",
                "Chinese Academy of Sciences",
                "Ji Hua Laboratory",
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3005108264",
        "https://openalex.org/W3165548596",
        "https://openalex.org/W3019745511",
        "https://openalex.org/W3147202816",
        "https://openalex.org/W3152975457",
        "https://openalex.org/W2999044305",
        "https://openalex.org/W2529996553",
        "https://openalex.org/W2578240541",
        "https://openalex.org/W2773987374",
        "https://openalex.org/W2610148085",
        "https://openalex.org/W2971690404",
        "https://openalex.org/W2991736596",
        "https://openalex.org/W1979278760",
        "https://openalex.org/W2956961449",
        "https://openalex.org/W3042826782",
        "https://openalex.org/W3125566655",
        "https://openalex.org/W3119872582",
        "https://openalex.org/W3206921875",
        "https://openalex.org/W2060531713",
        "https://openalex.org/W2605908560",
        "https://openalex.org/W2558999090",
        "https://openalex.org/W2963084773",
        "https://openalex.org/W2809595040",
        "https://openalex.org/W2037788267",
        "https://openalex.org/W3200044094",
        "https://openalex.org/W3193570095",
        "https://openalex.org/W1971947883",
        "https://openalex.org/W3157426342",
        "https://openalex.org/W2054881399",
        "https://openalex.org/W3100751385",
        "https://openalex.org/W1899504021",
        "https://openalex.org/W3213530673",
        "https://openalex.org/W3098269892"
    ],
    "abstract": "The de novo drug design based on SMILES format is a typical sequence-processing problem. Previous methods based on recurrent neural network (RNN) exhibit limitation in capturing long-range dependency, resulting in a high invalid percentage in generated molecules. Recent studies have shown the potential of Transformer architecture to increase the capacity of handling sequence data. In this work, the encoder module in the Transformer is used to build a generative model. First, we train a Transformer-encoder-based generative model to learn the grammatical rules of known drug molecules and a predictive model to predict the activity of the molecules. Subsequently, transfer learning and reinforcement learning were used to fine-tune and optimize the generative model, respectively, to design new molecules with desirable activity. Compared with previous RNN-based methods, our method has improved the percentage of generating chemically valid molecules (from 95.6 to 98.2%), the structural diversity of the generated molecules, and the feasibility of molecular synthesis. The pipeline is validated by designing inhibitors against the human BRAF protein. Molecular docking and binding mode analysis showed that our method can generate small molecules with higher activity than those carrying ligands in the crystal structure and have similar interaction sites with these ligands, which can provide new ideas and suggestions for pharmaceutical chemists.",
    "full_text": null
}