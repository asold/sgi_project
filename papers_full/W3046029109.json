{
  "title": "Applying Transformers and Aspect-based Sentiment Analysis approaches on Sarcasm Detection",
  "url": "https://openalex.org/W3046029109",
  "year": 2020,
  "authors": [
    {
      "id": "https://openalex.org/A2965034032",
      "name": "Taha Shangipour ataei",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3044939388",
      "name": "Soroush Javdan",
      "affiliations": [
        "Iran University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2030491744",
      "name": "Behrouz Minaei Bidgoli",
      "affiliations": [
        "Iran University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2510141903",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2964126051",
    "https://openalex.org/W2263859238",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2251958472",
    "https://openalex.org/W2969743835",
    "https://openalex.org/W2970597249",
    "https://openalex.org/W2888643222",
    "https://openalex.org/W2607623312",
    "https://openalex.org/W2962772361",
    "https://openalex.org/W2512470422",
    "https://openalex.org/W2154359981",
    "https://openalex.org/W2964164368",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W4294367149",
    "https://openalex.org/W2232443784",
    "https://openalex.org/W2916076862",
    "https://openalex.org/W2963635943",
    "https://openalex.org/W2512532697",
    "https://openalex.org/W2998825278"
  ],
  "abstract": "Sarcasm is a type of figurative language broadly adopted in social media and daily conversations. The sarcasm can ultimately alter the meaning of the sentence, which makes the opinion analysis process error-prone. In this paper, we propose to employ bidirectional encoder representations transformers (BERT), and aspect-based sentiment analysis approaches in order to extract the relation between context dialogue sequence and response and determine whether or not the response is sarcastic. The best performing method of ours obtains an F1 score of 0.73 on the Twitter dataset and 0.734 over the Reddit dataset at the second workshop on figurative language processing Shared Task 2020.",
  "full_text": "Proceedings of the Second Workshop on Figurative Language Processing, pages 67–71\nJuly 9, 2020.c⃝2020 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17\n67\nApplying Transformers and Aspect-based Sentiment Analysis approaches\non Sarcasm Detection\nTaha Shangipour ataei, Soroush Javdan and Behrouz Minaei-Bidgoli\nComputer Engineering Department\nIran University of Science and Technology\nTehran, Iran\ntaha shangipour,soroush javdan@comp.iust.ac.ir\nb minaei@iust.ac.ir\nAbstract\nSarcasm is a type of ﬁgurative language\nbroadly adopted in social media and daily con-\nversations. The sarcasm can ultimately alter\nthe meaning of the sentence, which makes\nthe opinion analysis process error-prone. In\nthis paper, we propose to employ bidirec-\ntional encoder representations transformers\n(BERT), and aspect-based sentiment analysis\napproaches in order to extract the relation be-\ntween context dialogue sequence and response\nand determine whether or not the response is\nsarcastic. The best performing method of ours\nobtains an F1 score of 0.73 on the Twitter\ndataset and 0.734 over the Reddit dataset at the\nsecond workshop on ﬁgurative language pro-\ncessing Shared Task 2020.\n1 Introduction\nWe are living in the age of social media. Many\nconsider it as a revolution. Social media creates\na variety of new possibilities; for instance, today,\npeople can express their thought with just a tap\nof a ﬁnger. In the twitter platform, people are\ntwitting around 500 million tweets per day, and\nit is estimated that over 2.8 million comments are\nposted on the Reddit every single day. This vast\namount of data present an enormous opportunity\nfor businesses, and researchers alogn with a signiﬁ-\ncant number of challenges. Many companies and\nresearchers have been interested in these data to\ninvestigate the opinion, emotions, and other aspects\nof them.\nThe usage of informal language and noisy con-\ntent within social media presents many difﬁculties\ntoward the opinion and emotion analysis problems.\nOne of the main challenges in this criteria is the\nappearance of ﬁgurative language such as sarcasm.\nThe sarcasm can alter the meaning of the sentence\nultimately, and consequently, make the opinion\nanalysis process error-prone. For instance, criti-\ncism may use positive words to convey a negative\nmessage. In recent years there was a growing trend\nto address the Sarcasm Detection problem among\nNatural Language Processing (NLP) researchers.\nMany approaches tackle the Sarcasm Detection\nproblem by considering contextual information, in-\nstead of using utterance solely. For instance, Bam-\nman and Smith (2015) utilized author context along\nwith the environment and audience context, and\nMishra et al. (2016) used cognitive features, Ghosh\net al. (2018) made use of conversational context.\nThe Sarcasm Detection shared task 1 is aimed\nto detect sarcasm based on the conversation con-\ntext. Given the current utterance and conversation\nhistory, the models are expected to decide if the\nutterance is sarcastic or not. We test our models\non the dataset from both Twitter and Reddit. Both\nutterance and the conversation history have been\nused as input. We applied the transformer-based\nmodel and adopted aspect-based sentiment analysis\napproaches to address the problem.\nThe remnant of this paper is organized as fol-\nlows: Section 2 reviews related work. Section\n3 describes the datasets. Section 4 explains our\nmethodology. Section 5 shows the results of each\ndataset in detail. Lastly, section 6 provides conclu-\nsions and our plans for future research.\n2 Related works\nThere have been several attempts to solve the\nSarcasm Detection problem with rule-based ap-\nproaches. Bharti et al. (2015) presented two rule-\nbased classiﬁers for two different types of tweet\nstructure, the ﬁrst one used to detect sarcasm in\ntweets that have a contradiction between negative\nsentiment and positive situation. The second clas-\nsiﬁer applied to tweets that start with interjection\n1https://competitions.codalab.org/competitions/22247\n68\nwords. The former classiﬁer applied parsed-based\nlexicon generation to identify phrases that display\nsentiment, and indicate the sarcastic label when-\never a negative phrase occurs in a positive sentence.\nThe latest classiﬁer used interjections and inten-\nsiﬁers that occur together in order to predict sar-\ncasm. Maynard and Greenwood (2014) suggests\nthat hashtag sentiment is an essential symbol of\nsarcasm, and authors often used hashtags to empha-\nsize sarcasm. They propose the tweet is sarcastic\nwhenever the hashtags’ sentiments do not agree\nwith the rest of the tweet.\nBesides the requirement for in-depth knowledge\nof the domain and much manual work, rule-based\nmethods are usually not the best performers in\nterms of prediction quality. Because of the high\ncost of the rule-based methods, many researchers\nput there focus on machine learning approaches.\nDifferent types of models and features have been\nadopted to tackle this problem. Mukherjee and\nBala (2017) addressed the problem in both super-\nvised and unsupervised settings. They utilized\nNa¨ıve Bayes as a classiﬁer and C-means cluster-\ning, which is one of the most widely used fuzzy\nclustering algorithms. Joshi et al. (2016) adopted\na sequence labeling techniques (SVM-HMM and\nSEARN) and indicated that sequence labeling al-\ngorithms outperform the classiﬁcation algorithms\nin conversational data.\nWith the development of computational hard-\nware and deep learning in recent years, many deep\nlearning methods have been proposed to address\nthe sarcasm detection problem. Amir et al. (2016)\nproposed a Convolutional Neural Network-based\narchitecture that jointly learns and exploits embed-\ndings for the users’ content and utterances. Ghosh\nand Veale (2016) used the complication of the Con-\nvolutional Neural Network and Recurrent Neural\nNetwork. They used two layers of Convolutional\nNeural Network, followed by two layers of Long\nShort-Term Memory(LSTM). The output of LSTM\nlayers fed to a Fully Connected Neural Network in\norder to produce a higher-order feature set. Diao\net al. (2020) proposed a novel multi-dimension\nquestion answering network in order to detect sar-\ncasm. They utilized conversation context informa-\ntion. A deep memory network based on BiLSTM\nand attention mechanisms have been adopted to\nextract the factors of sarcasm.\n3 Dataset\nTwo corpora were used in Sarcasm Detection\nshared task, which both of them are balanced. The\nTwitter corpus consists of 5000 data samples for\nthe train and 1800 for the test set. On the other\nhand, Reddit corpus contains 4400 data samples\nfor the train and 1800 for the test set. Training\ndatasets have four columns:\n• ID: a unique identiﬁer for each data sample\n• Context: an ordered list of dialogues\n• Response: reply to the last post or tweet of\nContext dialogues\n• Label: indicate wheter the responce is sarcas-\ntic or not\nFigure 1 shows the distribution of dialogue turns\nin each dataset.\nFigure 1: distribution of dialogues turns.\nMoreover, we used a balanced dataset proposed\nat (Khodak et al., 2017) with 1 million data samples\nover Reddit comments as an additional dataset.\n4 Methodology\nIn this section we describe models and technquies\nthat we used to address sarcasm detection problem.\n4.1 Preprocessing\nHashtag segmentation: the hashtag is a type of\nmetadata used on social media starting with a num-\nber sign, #, which helps users ﬁnd messages with\nthe same topic. We apply word segmentation on\nhashtags, for example ’#BlackHistoryMonth’ is\nsegmented as ’Black History Month.’\nMisc.: We removed all of the @USER mentions\nand <URL> tags.\n69\n4.2 Word Embedding:\nGloVe (Pennington et al., 2014) is an unsuper-\nvised method for extracting word vector represen-\ntation for our raw data. We also employed Fast-\ntext(Mikolov et al., 2018) embedding because they\nare derived from character n-gram and thus are use-\nful for misspelled words and social media contents.\n4.3 Models:\nNBSVM: We used the NBSVM model intro-\nduced by Wang and Manning (2012), which is a\ncombination of Na ¨ıve Bayes and support vector\nmachine, and is known as an excellent baseline for\nmany NLP tasks. As input, we utilized the TF-IDF\nmatrix with character n-gram features with n-gram\nrange from 2 to 6. We applied this method over\nboth datasets. Also, we tried different input data\nfor the NBSVM model. The different combinations\nof ’response’ column, ’context’ column have been\nused as input.\nBERT: Bidirectional Encoder Representation\nfrom Transformer (BERT) (Devlin et al., 2018) was\nreleased by the Google research team and achieved\nstate of the art in many NLP tasks. BERT is pre-\ntrained on a huge corpus of data sources. As input,\nwe experiment with the ’response’ column solely,\n’context’ column solely, and the concatenation of\n’context’ and ’response’ column. We trained the\nmodel with three epochs, a batch size of 8, and\na learning rate of 2e-5. For maximum sequence\nlength, the 128 yield best result.\nBERT-SVM: We used logits from the ﬁnal layer\nof BERT as input for a support vector machine\nmodel with a linear kernel. We trained the model\nwith three epochs, a batch size of 8, and a learning\nrate of 2e-5. For maximum sequence length, the\n128 yield best result.\nBERT-LR: We used logits from the ﬁnal layer\nof BERT as input for a logistic regression model.\nWe trained the model with three epochs, a batch\nsize of 8, and a learning rate of 2e-5. For maximum\nsequence length, the 128 yield best result.\nXLNET: XLNet (Yang et al., 2019) is a gener-\nalized autoregressive pretraining method. Since\nit outperforms BERT on 20 different NLP tasks,\nwe train this method over the Reddit dataset. We\ntrained the model with three epochs, a batch size\nof 8, and a learning rate of 2e-5. For maximum\nsequence length, the 128 yield best result.\nBi-GRU-CNN+BiLSTM-CNN: CNN is suit-\nable for detecting patterns, and by changing kernel\nsizes, it also can detect different patterns regardless\nof their positions. RNN is a sequence of network\nblocks linked to each other, and each of them passes\na message to the next one, this feature enables the\nnetwork to demonstrate dynamic temporal behav-\nior for a time sequence. We employ a neural net-\nwork architecture built on top of a concatenation of\nglove embedding and the fastText embedding, both\nof them with 300 dimensions. Then, the network\nsplits into two parallel parts. The ﬁrst part com-\nbines a bidirectional gated recurrent unit (GRU)\nwith 128 hidden units and a convolutional layer\nwith a kernel size of 2 and 64 hidden units. The\nsecond part combines a BiLSTM with 128 hidden\nunits and a convolutional layer with a kernel size\nof 2 and 64 hidden units. Finally, we concatenate\nglobal max pooling and global average pooling of\nparallel parts and feed them to a dense layer and\nthen through a softmax layer for the classiﬁcation\npurpose.\nAfter reviewing some aspect-based sentiment\nanalysis methods, we found some similarities be-\ntween these models and sarcasm detection prob-\nlems, so we attempted to change aspect-based sen-\ntiment analysis and adapt it sufﬁciently to address\nthe Sarcasm Detection problem. For all the follow-\ning models, the number of training epochs has been\nset to 10.\nIAN: IAN (Ma et al., 2017) has two attention\nlayers that learn context and target interactively\nand make representation for both separately. We\nreplace the context of the ABSA with the last\ndialogue in the ’context’ column of the sarcasm\ndatasets and target with the ’response’ column. We\nutilized 300 hidden units for both LSTM and atten-\ntion parts. We run this method on both datasets.\nLCF-BERT: LCF-BERT (Zeng et al., 2019) is a\nmethod based on multi-head self-attention, it em-\nploys context features dynamic mask (CDM) and\ncontext features dynamic weighted (CDW) layers\nalong with a BERT-shared layer to extract long-\nterm internal dependencies of local context and\nglobal context in aspect-based sentiment classiﬁca-\ntion problem. We alter the model input so it can\nperform on the sarcastic dataset. As input, we used\n’response’ and the last dialogue in the ’context’ col-\numn. The BERT-base-uncased with a maximum\nsequence length of 80 has been used as a BERT-\n70\nshared layer.\nBERT-AEN: AEN-BERT (Song et al., 2019) is\nanother method proposed for the aspect-based sen-\ntiment classiﬁcation that we borrowed for this task.\nThis method introduces an attentional encoder net-\nwork as a solution for the RNN problem with long-\nterm pattern recognition. It also applies a BERT-\nbase-uncased pre-trained model with a maximum\nsequence length of 80. We also used hidden units\nof 300 for the attention part. We modify the model\ninput so it can work on the sarcastic dataset. As\ninput, we used ’response’ and the last dialogue in\nthe ’context’ column.\n5 Results\nOn twitter corpus, the performance of NBSVM\nas a simple model is quite impressive. As long\nas the data is from social media and might con-\ntain informal and misspelling content using charac-\nter n-gram TFIDT matrix can yield excellent per-\nformance. As features, we used different combi-\nnations of ’response’ column, ’context’ column.\nHowever, taking the ’response’ column as a fea-\nture solely produced the best result. We also test\nmodels with and without preprocessing steps. How-\never, adding the preprocessing step did not show\na signiﬁcate change in the results. As expected,\nBERT achieved the second-best position on the\nscoreboard. We used a different set of features, but\nagain using the ’response’ column solely scored\nthe best among others. Furthermore, LCF-BERT,\nwhich is an aspect-based sentiment classiﬁcation\nmethod, scored the best on the Twitter dataset be-\ncause aspect-based sentiment classiﬁcation meth-\nods consider input data as two different sections\nand try to learn them interactively. The complete\nresults with more details are shown in Table. 1.\nMethod Score\nBase-line\nNBSVM 0.691\nTransformers\nBERT-base-cased 0.726\nBi-GRU-CNN+BiLSTM-CNN 0.660\nAspect-based\nLCF-BERT 0.730\nIAN 0.648\nBERT-AEN 0.651\nTable 1: Models performance over Twitter dataset\nUnlike our experience on the Twitter dataset,\nNBSVM did not perform well on the Reddit dataset.\nIt appears that the Reddit dataset is more compli-\ncated and challenging than twitter. However, using\nan additional dataset, around 1 million data points,\nboosted the NBSVM result around 7 percent. For\nNBSVM, we used the same feature as it was used\nfor the twitter dataset. BERT performance was the\nbest on this dataset, regardless of additional data.\nFor BERT-SVM and BERT-LR, we only utilized\nthe ’response’ column as input. Moreover, for XL-\nNet, we used the ’response’ column with 100,000\nrandom data points from the additional dataset. Fur-\nthermore, for the aspect-based sentiment analysis\nmodels, we used the last dialogue ’context’ column\nand ’response’ column as our input. The complete\nresults with more details are shown in Table. 2.\nMethod Score\nBase-line\nNBSVM 0.675\nTransformers\nBERT-base-cased 0.734\nBERT-SVM 0.647\nBERT-LR 0.649\nBi-GRU-CNN+BiLSTM-CNN 0.660\nXLNet 0.698\nAspect-based\nIAN 0.502\nBERT-AEN 0.612\nTable 2: Models performance over Reddit dataset\n6 Conclusion\nOur proposed methods ranked 5 out of 37 groups\nfor the Reddit dataset and ranked 25 out of 36 for\nthe Twitter dataset. This result shows the strength\nof the BERT pre-trained model on sarcasm detec-\ntion and its combination with aspect-based sen-\ntiment analysis models, which take data as two\nseparate parts and learn them interactively. Also,\nadditional data can improve performance slightly\nbetter. It is noteworthy to mention that NBSVM\nperformance as a simple baseline with the TFIDF\nmatrix with character n-gram was quite impres-\nsive. For future work, a combination of contextual\nand character-based embedding could lead to better\nperformance. Moreover, since social media con-\ntent usually contains misspelling and informal data,\nmore complicated preprocessing techniques like\n71\nsocial media content normalization might be more\nhelpful than proposed techniques.\nReferences\nSilvio Amir, Byron C Wallace, Hao Lyu, and Paula Car-\nvalho M´ario J Silva. 2016. Modelling context with\nuser embeddings for sarcasm detection in social me-\ndia. arXiv preprint arXiv:1607.00976.\nDavid Bamman and Noah A Smith. 2015. Contextual-\nized sarcasm detection on twitter. In Ninth Interna-\ntional AAAI Conference on Web and Social Media.\nSantosh Kumar Bharti, Korra Sathya Babu, and San-\njay Kumar Jena. 2015. Parsing-based sarcasm senti-\nment recognition in twitter data. In 2015 IEEE/ACM\nInternational Conference on Advances in Social Net-\nworks Analysis and Mining (ASONAM), pages 1373–\n1380. IEEE.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. arXiv preprint arXiv:1810.04805.\nYufeng Diao, Hongfei Lin, Liang Yang, Xiaochao Fan,\nYonghe Chu, Kan Xu, and Di Wu. 2020. A multi-\ndimension question answering network for sarcasm\ndetection. IEEE Access.\nAniruddha Ghosh and Tony Veale. 2016. Fracking sar-\ncasm using neural network. In Proceedings of the\n7th workshop on computational approaches to sub-\njectivity, sentiment and social media analysis, pages\n161–169.\nDebanjan Ghosh, Alexander R Fabbri, and Smaranda\nMuresan. 2018. Sarcasm analysis using conversa-\ntion context. Computational Linguistics, 44(4):755–\n792.\nAditya Joshi, Vaibhav Tripathi, Pushpak Bhat-\ntacharyya, and Mark Carman. 2016. Harnessing se-\nquence labeling for sarcasm detection in dialogue\nfrom tv series ‘friends’. In Proceedings of The 20th\nSIGNLL Conference on Computational Natural Lan-\nguage Learning, pages 146–155.\nMikhail Khodak, Nikunj Saunshi, and Kiran V odrahalli.\n2017. A large self-annotated corpus for sarcasm.\narXiv preprint arXiv:1704.05579.\nDehong Ma, Sujian Li, Xiaodong Zhang, and Houfeng\nWang. 2017. Interactive attention networks for\naspect-level sentiment classiﬁcation. arXiv preprint\narXiv:1709.00893.\nDiana G Maynard and Mark A Greenwood. 2014. Who\ncares about sarcastic tweets? investigating the im-\npact of sarcasm on sentiment analysis. In LREC\n2014 Proceedings. ELRA.\nTomas Mikolov, Edouard Grave, Piotr Bojanowski,\nChristian Puhrsch, and Armand Joulin. 2018. Ad-\nvances in pre-training distributed word representa-\ntions. In Proceedings of the International Confer-\nence on Language Resources and Evaluation (LREC\n2018).\nAbhijit Mishra, Diptesh Kanojia, Seema Nagar, Kuntal\nDey, and Pushpak Bhattacharyya. 2016. Harnessing\ncognitive features for sarcasm detection. InProceed-\nings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers), pages 1095–1104, Berlin, Germany. Associa-\ntion for Computational Linguistics.\nShubhadeep Mukherjee and Pradip Kumar Bala. 2017.\nSarcasm detection in microblogs using na ¨ıve bayes\nand fuzzy clustering. Technology in Society, 48:19–\n27.\nJeffrey Pennington, Richard Socher, and Christopher D\nManning. 2014. Glove: Global vectors for word rep-\nresentation. In Proceedings of the 2014 conference\non empirical methods in natural language process-\ning (EMNLP), pages 1532–1543.\nYouwei Song, Jiahai Wang, Tao Jiang, Zhiyue Liu, and\nYanghui Rao. 2019. Attentional encoder network\nfor targeted sentiment classiﬁcation. arXiv preprint\narXiv:1902.09314.\nSida Wang and Christopher Manning. 2012. Baselines\nand bigrams: Simple, good sentiment and topic clas-\nsiﬁcation. In Proceedings of the 50th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 2: Short Papers), pages 90–94, Jeju Island,\nKorea. Association for Computational Linguistics.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-\nbonell, Russ R Salakhutdinov, and Quoc V Le. 2019.\nXlnet: Generalized autoregressive pretraining for\nlanguage understanding. In Advances in neural in-\nformation processing systems, pages 5754–5764.\nBiqing Zeng, Heng Yang, Ruyang Xu, Wu Zhou, and\nXuli Han. 2019. Lcf: A local context focus mecha-\nnism for aspect-based sentiment classiﬁcation. Ap-\nplied Sciences, 9(16):3389.",
  "topic": "Sarcasm",
  "concepts": [
    {
      "name": "Sarcasm",
      "score": 0.9974092245101929
    },
    {
      "name": "Literal and figurative language",
      "score": 0.8454759120941162
    },
    {
      "name": "Sentiment analysis",
      "score": 0.7234979867935181
    },
    {
      "name": "Computer science",
      "score": 0.7165544033050537
    },
    {
      "name": "Natural language processing",
      "score": 0.6847519278526306
    },
    {
      "name": "Sentence",
      "score": 0.6425023674964905
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6122926473617554
    },
    {
      "name": "Transformer",
      "score": 0.5469238758087158
    },
    {
      "name": "Social media",
      "score": 0.45220211148262024
    },
    {
      "name": "Task (project management)",
      "score": 0.41472476720809937
    },
    {
      "name": "Speech recognition",
      "score": 0.3311505913734436
    },
    {
      "name": "Linguistics",
      "score": 0.3240933418273926
    },
    {
      "name": "Irony",
      "score": 0.26459065079689026
    },
    {
      "name": "World Wide Web",
      "score": 0.08458632230758667
    },
    {
      "name": "Engineering",
      "score": 0.07404768466949463
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I67009956",
      "name": "Iran University of Science and Technology",
      "country": "IR"
    }
  ],
  "cited_by": 39
}