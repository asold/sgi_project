{
    "title": "Sensitivity, specificity and avoidable workload of using a large language models for title and abstract screening in systematic reviews and meta-analyses",
    "url": "https://openalex.org/W4389923369",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A2746523494",
            "name": "Viet-Thi Tran",
            "affiliations": [
                "Centre de Recherche Épidémiologie et Statistique",
                "Inserm",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Hôtel-Dieu de Paris",
                "Assistance Publique – Hôpitaux de Paris",
                "Université Paris Cité"
            ]
        },
        {
            "id": "https://openalex.org/A2555150227",
            "name": "Gerald Gartlehner",
            "affiliations": [
                "RTI International",
                "Universität für Weiterbildung Krems"
            ]
        },
        {
            "id": "https://openalex.org/A3025149611",
            "name": "Sally Yaacoub",
            "affiliations": [
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Centre de Recherche Épidémiologie et Statistique",
                "Inserm",
                "Université Paris Cité"
            ]
        },
        {
            "id": "https://openalex.org/A108308545",
            "name": "Isabelle Boutron",
            "affiliations": [
                "Université Paris Cité",
                "Inserm",
                "Hôtel-Dieu de Paris",
                "Centre de Recherche Épidémiologie et Statistique",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Assistance Publique – Hôpitaux de Paris"
            ]
        },
        {
            "id": "https://openalex.org/A1566631851",
            "name": "Lukas Schwingshackl",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A3138891914",
            "name": "Julia Stadelmaier",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A2058722308",
            "name": "Isolde Sommer",
            "affiliations": [
                "Universität für Weiterbildung Krems"
            ]
        },
        {
            "id": "https://openalex.org/A5093527268",
            "name": "Farzaneh Aboulayeh",
            "affiliations": [
                "Inserm",
                "Université Paris Cité",
                "Centre de Recherche Épidémiologie et Statistique",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement"
            ]
        },
        {
            "id": "https://openalex.org/A2933490060",
            "name": "Sivem Afach",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2667037783",
            "name": "Joerg Meerpohl",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A1985180350",
            "name": "Philippe Ravaud",
            "affiliations": [
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Hôtel-Dieu de Paris",
                "Assistance Publique – Hôpitaux de Paris",
                "Université Paris Cité",
                "Columbia University",
                "Inserm",
                "Centre de Recherche Épidémiologie et Statistique"
            ]
        },
        {
            "id": "https://openalex.org/A2746523494",
            "name": "Viet-Thi Tran",
            "affiliations": [
                "Sorbonne Paris Cité",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Inserm",
                "Centre de Recherche Épidémiologie et Statistique",
                "Hôtel-Dieu de Paris",
                "Assistance Publique – Hôpitaux de Paris"
            ]
        },
        {
            "id": "https://openalex.org/A2555150227",
            "name": "Gerald Gartlehner",
            "affiliations": [
                "RTI International",
                "Universität für Weiterbildung Krems"
            ]
        },
        {
            "id": "https://openalex.org/A3025149611",
            "name": "Sally Yaacoub",
            "affiliations": [
                "Centre de Recherche Épidémiologie et Statistique",
                "Inserm",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Sorbonne Paris Cité"
            ]
        },
        {
            "id": "https://openalex.org/A108308545",
            "name": "Isabelle Boutron",
            "affiliations": [
                "Inserm",
                "Sorbonne Paris Cité",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Hôtel-Dieu de Paris",
                "Centre de Recherche Épidémiologie et Statistique",
                "Assistance Publique – Hôpitaux de Paris"
            ]
        },
        {
            "id": "https://openalex.org/A1566631851",
            "name": "Lukas Schwingshackl",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A3138891914",
            "name": "Julia Stadelmaier",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A2058722308",
            "name": "Isolde Sommer",
            "affiliations": [
                "Universität für Weiterbildung Krems"
            ]
        },
        {
            "id": "https://openalex.org/A5093527268",
            "name": "Farzaneh Aboulayeh",
            "affiliations": [
                "Sorbonne Paris Cité",
                "Centre de Recherche Épidémiologie et Statistique",
                "Inserm",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement"
            ]
        },
        {
            "id": "https://openalex.org/A2933490060",
            "name": "Sivem Afach",
            "affiliations": [
                "Paris-Est Sup"
            ]
        },
        {
            "id": "https://openalex.org/A2667037783",
            "name": "Joerg Meerpohl",
            "affiliations": [
                "University of Freiburg"
            ]
        },
        {
            "id": "https://openalex.org/A1985180350",
            "name": "Philippe Ravaud",
            "affiliations": [
                "Centre de Recherche Épidémiologie et Statistique",
                "Columbia University",
                "Sorbonne Paris Cité",
                "Assistance Publique – Hôpitaux de Paris",
                "Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
                "Hôtel-Dieu de Paris",
                "Inserm"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2808826267",
        "https://openalex.org/W3203912530",
        "https://openalex.org/W2999536597",
        "https://openalex.org/W2955273711",
        "https://openalex.org/W3179388700",
        "https://openalex.org/W2122589015",
        "https://openalex.org/W2300445845",
        "https://openalex.org/W2560438049",
        "https://openalex.org/W2981527585",
        "https://openalex.org/W1779982606",
        "https://openalex.org/W3111278950",
        "https://openalex.org/W4319062614",
        "https://openalex.org/W4367310920",
        "https://openalex.org/W4318765555",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4312091769",
        "https://openalex.org/W4384389814",
        "https://openalex.org/W4367701145",
        "https://openalex.org/W4392791588",
        "https://openalex.org/W4310102500",
        "https://openalex.org/W4386823179",
        "https://openalex.org/W4323926629",
        "https://openalex.org/W4383998038",
        "https://openalex.org/W2102269881",
        "https://openalex.org/W2088323328",
        "https://openalex.org/W2126727011",
        "https://openalex.org/W2903961062",
        "https://openalex.org/W4315641584",
        "https://openalex.org/W3110318438",
        "https://openalex.org/W2562241822",
        "https://openalex.org/W2285413972",
        "https://openalex.org/W4384807943"
    ],
    "abstract": "Abstract Importance Systematic reviews are time-consuming and are still performed predominately manually by researchers despite the exponential growth of scientific literature. Objective To investigate the sensitivity, specificity and estimate the avoidable workload when using an AI-based large language model (LLM) (Generative Pre-trained Transformer [GPT] version 3.5-Turbo from OpenAI) to perform title and abstract screening in systematic reviews. Data Sources Unannotated bibliographic databases from five systematic reviews conducted by researchers from Cochrane Austria, Germany and France, all published after January 2022 and hence not in the training data set from GPT 3.5-Turbo. Design We developed a set of prompts for GPT models aimed at mimicking the process of title and abstract screening by human researchers. We compared recommendations from LLM to rule out citations based on title and abstract with decisions from authors, with a systematic reappraisal of all discrepancies between LLM and their original decisions. We used bivariate models for meta-analyses of diagnostic accuracy to estimate pooled estimates of sensitivity and specificity. We performed a simulation to assess the avoidable workload from limiting human screening on title and abstract to citations which were not “ruled out” by the LLM in a random sample of 100 systematic reviews published between 01/07/2022 and 31/12/2022. We extrapolated estimates of avoidable workload for health-related systematic reviews assessing therapeutic interventions in humans published per year. Results Performance of GPT models was tested across 22,666 citations. Pooled estimates of sensitivity and specificity were 97.1% (95%CI 89.6% to 99.2%) and 37.7%, (95%CI 18.4% to 61.9%), respectively. In 2022, we estimated the workload of title and abstract screening for systematic reviews to range from 211,013 to 422,025 person-hours. Limiting human screening to citations which were not “ruled out” by GPT models could reduce workload by 65% and save up from 106,268 to 276,053-person work hours (i.e.,66 to 172-person years of work), every year. Conclusions and Relevance AI systems based on large language models provide highly sensitive and moderately specific recommendations to rule out citations during title and abstract screening in systematic reviews. Their use to “triage” citations before human assessment could reduce the workload of evidence synthesis.",
    "full_text": "Sensitivity, specificity and avoidable workload of using a large language models for title \nand abstract screening in systematic reviews and meta-analyses \nViet-Thi Tran 1,2, Gerald Gartlehner 3,4, Sally Yaacoub 1, Isabelle Boutron 1,2, Lukas Schwingshackl 5, \nJulia Stadelmaier5, Isolde Sommer 3, Farzaneh Aboulayeh 1, Sivem Afach 6, Joerg Meerpohl 5, Philippe \nRavaud1,2,7 \n \n1 Université Paris Cité, CRESS, INSERM, INRAE, Paris, France. \n2 Centre d’Epidémiologie Clinique, Hôpital Hôtel-Dieu, AP-HP, Paris, France \n3 Department for Evidence-based Medicine and Evaluation, University for Continuing Education \nKrems, Krems, Austria \n4 Center for Public Health Methods, RTI International, Research Triangle Park, USA \n5 Institute for Evidence in Medicine, Medical Center - University of Freiburg, Faculty of Medicine, \nUniversity of Freiburg, Freiburg, Germany \n6Epidemiology in Dermatology and Evaluation of Therapeutics (EpiDermE) - EA 7379, University \nParis Est \n7 Department of Epidemiology, Columbia University Mailman School of Public Health, New York, \nNY, USA \n \n \nCorrespondence to: \nViet-Thi Tran - MD, PhD \nHôpital Hôtel Dieu, Centre d′ Épidémiologie Clinique, Paris, France \n1 place du Parvis Notre-Dame, Paris 75181, France \nTel: +33 1 42 34 89 87, fax: +33 1 42 34 87 90, email: thi.tran-viet@aphp.fr\n \n \n \nKeywords: Systematic reviews, generative artificial intelligence, methodology  \n \nWord count: 3604 \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract (348) \nImportance: Systematic reviews are time-consuming and are still performed predominately \nmanually by researchers despite the exponential growth of scientific literature. \nObjective: To investigate the sensitivity, specificity and estimate the avoidable workload \nwhen using an AI-based large language model (LLM) (Generative Pre-trained Transformer \n[GPT] version 3.5-Turbo from OpenAI) to perform title and abstract screening in systematic \nreviews. \nData Sources: Unannotated bibliographic databases from five systematic reviews conducted \nby researchers from Cochrane Austria, Germany and France, all published after January 2022 \nand hence not in the training data set from GPT 3.5-Turbo.  \nDesign: We developed a set of prompts for GPT models aimed at mimicking the process of \ntitle and abstract screening by human researchers. We compared recommendations from LLM \nto rule out citations based on title and abstract with decisions from authors, with a systematic \nreappraisal of all discrepancies between LLM and their original decisions. We used bivariate \nmodels for meta-analyses of diagnostic accuracy to estimate pooled estimates of sensitivity \nand specificity. We performed a simulation to assess the avoidable workload from limiting \nhuman screening on title and abstract to citations which were not “ruled out” by the LLM in a \nrandom sample of 100 systematic reviews published between 01/07/2022 and 31/12/2022. We \nextrapolated estimates of avoidable workload for health-related systematic reviews assessing \ntherapeutic interventions in humans published per year. \nResults: Performance of GPT models was tested across 22,666 citations. Pooled estimates of \nsensitivity and specificity were 97.1% (95%CI 89.6% to 99.2%) and 37.7%, (95%CI 18.4% to \n61.9%), respectively. In 2022, we estimated the workload of title and abstract screening for \nsystematic reviews to range from 211,013 to 422,025 person-hours. Limiting human \nscreening to citations which were not “ruled out” by GPT models could reduce workload by \n65% and save up from 106,268 to 276,053-person work hours (i.e.,66 to 172-person years of \nwork), every year. \nConclusions and Relevance : AI systems based on large language models provide highly \nsensitive and moderately specific recommendations to rule out citations during title and \nabstract screening in systematic reviews. Their use to “triage” citations before human \nassessment could reduce the workload of evidence synthesis.  \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n1. Introduction \nEvidence synthesis is defined as the “process of bringing together information and knowledge \nfrom many sources to inform decisions ” 1. According to prominent researchers, it is \nconsidered as one of the most valuable contributions research can offer decision-makers 1,2. \nYet, comprehensive evidence synthesis in the form of high quality systematic reviews, with or \nwithout meta-analysis, is limited by the fact that researchers still often manually  screen \nthousands of studies to determine whether they meet the eligibility criteria of reviews, despite \nthe exponential growth of scientific literature 3. Manual screening is time-consuming because \nonly a limited fraction (often less than 10%) of the screened studies is finally included. \nWorse, this screening process is conducted in duplicate because of the risk of error (with a 7 \nto 11% error rate during abstract screening) 4-6. A review estimated that conducting a single \nsystematic review required over a thousand hours of highly skilled manual labour, with hours \nincreasing or decreasing proportionally to the body of evidence to be screened 7. \nAmong methods to increase the efficiency of screening for evidence synthesis, automated \ntools using natural language processing and/or machine learning methods have been \ndeveloped. Most tools work by prioritizing relevant studies learning from the researchers’ \ndecision to include the study or not, via active “human-in-the-loop” learning 8-10. In a survey \nstudy, such tools provided on average 40% of time savings as compared to manual screening. \nYet, these tools have limitations. For example, their performance depends on the proportion \nof relevant publications (i.e., publications that will be included) and the complexity of the \ninclusion criteria used by the research team \n11,12. \nRecently, the development of general-purpose Artificial Intelligence (AI) systems based on \nlarge language models (LLMs) , such as ChatGPT (OpenAI), has changed the paradigm of \ntask automation. LLMs have shown excellent ability in answering health questions 13,14, \ndiagnosing conditions 15, and  performing at (or near) the passing threshold for the exams of \nthe United States Medical Licensing Exam (USMLE) 16, without any specialized training or \nreinforcement. LLMs can also accurately label unannotated data (accuracy 89% vs. 95% for \nhuman labelling) 17,18. Three studies have investigated the performance of LLMs to screen for \nsystematic reviews in different fields (informatics and literature) with sensitivities ranging \nfrom 60% to 90% and specificities ranging from 10 to 60% depending on the dataset \nexamined 19-21. Beyond their performance, LLMs also transform the accessibility of \nautomated tools for non-specialists thanks to the use of chatbot interfaces where users can \ninstruct the models in natural language.   \nIn this study, we aimed to appraise how a LLM-based system could perform title and abstract \nscreening in systematic reviews. We 1) developed a set of prompts for the Generative Pre-\ntrained Transformer (GPT) 3.5-Turbo model (OpenAI) aimed at mimicking the process of \ntitle and abstract screening by human researchers; 2) evaluated the performance of the \ndeveloped prompts in five high quality systematic reviews; and 3) performed a simulation \nstudy to estimate the avoidable workload when using LLMs to screen citations for inclusion \nin systematic reviews. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n2. Methods \nWe investigated the sensitivity, specificity and avoidable workload when using GPT 3.5-\nTurbo models for screening in systematic reviews. \n2.1. Data sources \nUnannotated bibliographic databases from five systematic reviews conducted by researchers \nfrom Cochrane Austria, Germany and France were used in this study: 1) a review on the \nefficacy of primary treatment of confirmed C OVID-19 in outpatient settings (Sommer et al., \n2022) \n22; 2) a review on the efficacy of outpatient treatment options for the omicron variant of \nSARS-CoV-2 (Sommer et al., 2023) 23; 3) a methodological review on the epidemiology and \nreporting characteristics of non-randomized studies of pharmacologic treatment \n(unpublished); 4) a review on the effects of dairy intake on intermediate disease markers in \nadults (Kiesswetter et al., 2023) 24; and 5) a Cochrane review on systemic pharmacological \ntreatments for chronic plaque psoriasis (Sbidian et al., 2023) 25. In all systematic reviews, \ndecisions to include a citation beyond title and abstract screening were performed by two \nreviewers in duplicate and independently. All systematic reviews were published after \nJanuary 2022 and hence were not in the training data set from GPT 3.5-Turbo. \nUnannotated bibliographic databases contained the deduplicated list of citations (i.e., studies \nidentified by their title and abstracts) retrieved from electronic search, the list of citations \nselected after examination of title and abstracts only, and the list of citations selected based on \ntheir full texts. In addition to the bibliographic databases, the registered the protocols were \nused for the inclusion and exclusion criteria of studies in the reviews (PROSPERO \nCRD42022323440, CRD42023406456, and CRD42022303198, OSF https://osf.io/ywr8s/, \nand https://doi.org/10.1002/14651858.CD011535). \n2.2. Prompt development \nOne investigator (VTT) developed five prompts for the GPT 3.5-Turbo model aimed at \nmimicking how humans apply the PICOS framework (Population, Intervention, Control, \nOutcomes and Study design) during title and abstract screening. Each prompt was focused on \none element of the PICOS framework and instructed the model to 1) extract relevant \ninformation from the title and abstract of citations retrieved from electronic searches and; 2) \nassess whether the extracted information corresponded to the criteria reported in the protocol \nof the systematic review (using the same words as those used in the protocol); and 3) give a \nrecommendation to “include” or “exclude” the citation \n26. For example: “Read the following \ntext and pay close attention to details. Proceed step by step. First, assess the control. Second, \nanswer with the words \"YES\" or \"NO\" by using the following algorithm: 1-If the control is a \nplacebo, or usual care, or a different dose or duration of the intervention, answer \"YES\". 2-If \nthe control is an active treatment, different from the intervention, answer \"NO\". 3-If unclear, \nanswer \"NO\".\" We used temperature hyperparameters of “0”, so as to have deterministic \noutputs. Final prompts for each review are detailed in Appendix 1. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nThe investigator (VTT) designed a program applying the series of prompt to each citation so \nas to sequentially assess the design, population, intervention, control and then outcomes. The \nprogram was instructed to stop whenever the title or abstract did not fit the inclusion and \nexclusion criteria of the review. Both prompts and the program were developed with 10 to \n20% of citations by comparing the output from the model to the decisions from the authors of \nsystematic reviews and optimizing the ability of the model to “rule out” citations. Final \nprompts were run on all citations through the application programming interface (API) of \nGPT. Final output for each review was a binary recommendation (Yes/No) to include or not \neach citation. \n2.3. Evaluation of the performance of GPT models to screen \ncitations for inclusion in systematic reviews \nFor each systematic review, we compared the recommendations from GPT models \n(considered as the index test) to rule-out citations based on title and abstract and the original \ndecisions from the authors of the systematic review, at title and abstract level, (considered as \nthe reference standard) by calculating the sensitivity and specificity with 95% confidence \nintervals. As the systematic reviews were not in the training data set from GPT 3.5-Turbo, we \ncan consider that decisions from GPT models and from authors were completely independent. \nAs human reviewers can make errors during title and abstract screening, their decisions can be \nconsidered as an imperfect reference standard. We therefore considered two reference \nstandards. Reference standard 1 was the original decisions from authors, after title and \nabstract screening. Reference standard 2 involved the reappraisal of all discrepancies between \nrecommendations from GPT models and original decisions from authors (i.e., “over \ninclusion”, “missed citation because of a screening error” or “correct original decision”) \n27,28. \nPooled estimates for sensitivity and specificity across all reviews were obtained using the \nbivariate model from Reitsma et al. for meta-analysis of diagnostic accuracy studies. This \nmodel preserves the two-dimensional nature of the underlying data (i.e., sensitivity and \nspecificity) as compared to models relying solely on the diagnostic odds ratio \n29. Results were \npresented by plotting estimates of the paired observed sensitivities and specificities, for each \nreview, and a summary receiver operating characteristic (SROC) curve obtained from the \nbivariate model aforementioned.  \nWe performed a sensitivity analysis where the performance of GPT models was tested only in \ncitations not used to fine-tune models (i.e., from 80 to 90% citations per review).  \n2.4. Avoidable workload when using of GPT models to \nscreen citations for inclusion in systematic reviews  \nTo assess the workload arising from title and abstract screening, one reviewer (FA) searched \nPubMed via MEDLINE for all systematic reviews (with or without meta-analyses) evaluating \nthe effectiveness of a pharmacological or biological therapeutic or preventive intervention in \nhumans published between July 1, 2022 and December 31, 2022 ( Appendix 2). The reviewer \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nexcluded studies focused solely on natural medicine, animal studies, diagnostic studies and \nprotocols. The search was performed on October 24, 2023. Among identified reviews, we \nrandomly selected 100 and assessed: 1) the number of citations obtained from the electronic \ndatabase searches, after deduplication; 2) the number of citations kept after title and abstract \nscreening; 3) the number of citations kept after full-text assessment; 4) the number of \nreviewers involved in the screening; and 5) whether an automated tool was used to accelerate \nscreening. \nWe estimated the time required to perform screening using the estimates reported in the \nCochrane Handbook, which considers that the results of a database search can be screened at \nthe rate of 60–120 per hour \n26. Workload was multiplied by the number of reviewers \nperforming screening independently. Whenever the number of reviewers was not reported, we \nmade the conservative hypothesis that only a single reviewer was involved. If the review \nreported the use of machine learning tool to accelerate screening, we considered 40% average \ntime savings 9. To obtain estimates over a one-year period, we hypothesized that 1) our \nsample of 100 reviews was representative of the identified reviews; and 2) the number of \nreviews published per year was twice the number of reviews identified over a 6-months \nperiod. For example, we considered that the number of citations to be screened over one year, \nwas twice average number of citations observed in the sample multiplied by the number of \nsystematic reviews and meta-analyses identified in the search. To obtain person-years \nestimates, we arbitrarily considered that a human reviewer was working 8 hours a day for 200 \ndays per year. \nTime required for the use of GPT models for title and abstract screening involved 1) human \nscreening for 20% of the number of citations retrieved from electronic searches and 2) a \nconservative and arbitrary quantity of 8 hours of work to adapt and fine-tune the prompt.  \nAvoidable workload was obtained by subtracting the time required for human screening and \nthe time required to use GPT models in two hypothetical scenarios: 1) in systematic reviews \nand meta-analyses where two reviewers performed screening on title and abstract, one \nreviewer was replaced by the use of a GPT model; and 2) human screening on title and \nabstract was limited to citations which were not “ruled out” by a GPT model.  \n3. Results \n3.1. Systematic reviews \nThe five systematic reviews used in this study identified a total number of 22,666 citations \nfrom electronic searches on the Epistemonikos COVID-19 LOVE platform (n=2), the iSearch \nCOVID-19 portfolio (n=1), MEDLINE (n=3), Cochrane Central Register of Controlled Trials \n(n=2), EMBASE (n=2), Web of Science (n=1), and LILACS (Latin American and Caribbean \nHealth Science Information database) (n=1). After screening of title and abstracts, 1,485 \n(6.5%) citations were included (ranging from 1.2% to 35%). After full-text screening, 432 \n(1.9%) citations were included (ranging from 0.1% to 4%) (Table 1). \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n3.2. Evaluation of the performance of GPT models to screen \ncitations for inclusion in systematic reviews \nConsidering the reference standard 1 (i.e. original decisions from authors), sensitivity of GPT \nmodels to rule out citations during title and abstract screening for systematic reviews ranged \nfrom 81.3% (95% CI 77.1 to 84.9) for the review on the efficacy of primary treatment of \nconfirmed COVID-19 in outpatient settings; to 99.2% (95% CI 99.0 to 99.4) for the review on \ndairy intake on intermediate disease markers in adults \n22,24. Specificity ranged from 9.1% \n(95%CI 6.4 to 12.7) for the review on dairy intake on intermediate disease markers in adults \nto 56.6% (95%CI 50.8 to 62.2) for the review on the efficacy of primary treatment of \nconfirmed COVID-19 in outpatient settings \n22,24 (Table 2).  \nConsidering the reference standard 2 (i.e., decisions from authors and reappraisal of all \ndiscrepancies), 97 citations (median 27 (IQR 2 to 27) per review) were excluded on title and \nabstract by human reviewers despite being eligible for full-text review (i.e., screening errors) \nand identified by GPT models. On the contrary, GPT models excluded 187 citations (median \n19 (IQR 6 to 64) per review) that were considered eligible by human reviewers and included \nafter full-text review ( Appendix 4). Using the reference standard 2, sensitivity ranged from \n87.5% (95%CI 83.9 to 90.5) to 99.6% (95%CI 99.5 to 99.8). Specificity ranged from 9.7% \n(95%CI 7.0 to 13.4) to 66.0% (95%CI 60.3 to 71.2) (Table 2). \nFigure 1 summarizes information, displaying the pooled estimates for sensitivity of 97.1% \n(95% CI 89.6 to 99.2) and for specificity of 37.7% (95% CI 18.4 to 61.9), using reference \nstandard 2. The figure also shows the coherence between sensitivity and specificity across the \ndifferent reviews, hinting that the performance estimated was not driven by outlier results. \nSimilar information is displayed in Appendix 3 for the reference standard 1. \nPerformance was unchanged in a sensitivity analysis where the performance of GPT models \nwas tested only in citations not used to fine-tune models (i.e., from 80 to 90% citations per \nreview) (Appendix 5). \n3.3. Avoidable workload when using GPT models to screen \ncitations for inclusion in systematic reviews \nIn total, we identified 2507 systematic reviews evaluating the effectiveness of therapeutic or \npreventive pharmacological interventions in humans, published between 01/07/2022 and \n31/12/2022. In a random sample of 100 studies (Appendix 3), the median number of citations \n1) identified from electronic search was 662 (interquartile range (IQR 202 to 1740), 2) \nincluded after title and abstract screening was 36 (IQR 23 to 74) (median proportion of \ncitations retrieved from electronic searches: 8%, IQR 3 to 21), and 3) included after full-text \nscreening was 13 (IQR 8 to 22) (median proportion: 2.5%, IQR 0.8 to 6.1). The cumulated \ntime to perform title and abstract screening for the 100 reviews was 4208 to 8417 person-\nhours (i.e., 2.6 to 5.3 person-years of work). By extrapolating these results to 2507*2 \nsystematic reviews evaluating the effectiveness of therapeutic or preventive pharmacological \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \ninterventions published in 2022, we estimate the workload of title and abstract screening to \n211,013 to 422,025 person-hours (i.e., 132 to 264 persons-year of work), every year.  \nUsing GPT models to replace one reviewer in reviews where title and abstract screening was \nperformed in double and independently would reduce workload from 11 to 21% of the \nworkload of title and abstract screening and would save a cumulated time of 24,136 to 88,385 \npersons hours (15 to 55 person-years of work) per year, as compared to human screening \nalone. At review level, average time saved by review ranged from 4 to 17 hours per review.  \nLimiting human screening to citations which were not “ruled out” by GPT models, \nindependently would reduce workload from 50 to 65% of the workload of title and abstract \nscreening and save a cumulated time of 106,268 to 276,053 persons hours (i.e.,66 to 172 \nperson-years of work) per year, as compared to human screening alone. At review level, \naverage time saved by review ranged from 5 to 55 hours per review. \n4. Discussion \nAI systems based on LLMs provide highly sensitive and low to moderate specific \nrecommendations to rule out citations during title and abstract screening in systematic reviews \nand meta-analyses, without specific training. Using these models as a “triage tool”, used \nbefore human screening, could reduce human workload up to 65% and save up to 275,000 \nperson-hours of work per year for systematic reviews evaluating the effectiveness of \ntherapeutic or prophylactic pharmacological interventions on humans and referenced in \nMedline.  \nThe use of LLM based AI systems to perform title and abstract screening in systematic \nreviews differ from existing automated tools which learn from the researchers’ decisions to \nprioritize citations by relevance \n9,30. First, the tool functions as a zero-shot classifier: decision \nto exclude a citation is provided without prior training, using solely a prompt based on the \nPICOS elements reported in the protocol of the review 31. As a result, the tool’s performance \nis not dependent on the proportion of citations that will be included by researchers, nor is it \nsubject to the lack of appropriate stopping criteria faced by prioritization tools 32. Second, \nGPT models use instructions in human language and can therefore be used widely without \nspecific training nor configuration. Third, they function independently from humans, without \nfatigue. Finally, newer generative AI are multimodal, accept larger inputs, including the \nupload of documents, potentially suggesting that an AI could bypass title and abstract \nscreening and use all data available to make a recommendation. \nIn this study, sensitivity of GPT models to rule out citations from title and abstract was high \n(>87%). However, specificity was more heterogeneous and varied from 10% to 50%. Two \nfactors may have played a role in this result. First, specificity seemed to be associated with the \ncomplexity of inclusion and exclusion criteria in our study. For example, in the review \nevaluating the effect of dairy intake on cardiometabolic health 24, decisions often required \nexpert knowledge beyond simply understanding the text (e.g., the protocol described eligible \ninterventions as “Non-bovine milk and dairy products (e.g. from sheep, goats, buffalos, \ncamels), milk/ protein isolates (e.g. whey or casein), capsules, fortified dairy products (e.g. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nfortified with Vitamin D, plant sterols/ stanols, prebiotics, probiotics or omega-3 fatty acids) \nand fermented milk products with additional microbiota strains added (beyond those \nnaturally occurring) will be excluded ). Second, performance also depended on human \nresearchers’ tendency and habits to “over include” at title and abstract screening. This was \nhighlighted by the reassessment of discrepancies between human and AI decisions which \ncould improve specificity up to 10%. Despite low specificity, GPT models are still useful to \nrule out citations and reduce human workload during the conduct of reviews. For example, in \nthe aforementioned review, pre-screening of citations by GPT models could rule out \n6148/6478 (95%) references, helping human reviewers focus on the 330 remaining citations.  \nDespite high sensitivity, GPT models excluded some citations that had been finally included \nin reviews after full texts. In particular, we chose to include “outcomes” in the prompt so as to \nbalance sensitivity and specificity, despite some researchers advising not to select on title and \nabstract based on this information, because some outcomes may not be reported in the abstract \nor because of selective outcome reporting bias. Furthermore, some exclusion of eligible \ncitations came from the unreliable ability of GPT models to provide expected answers to \nprompts (“YES” or “NO”) and because the program was designed to capture these answers. \nThis led to a reduction in sensitivity. This highlights that these models are not yet ready to \nreplace humans but may rather be used to complement human assessment (e.g., serving as a \nsecond or third reviewer). In all, we show that use of LLM based models can reduce the \nworkload of title and abstract screening by human researchers. For some reviews, a low loss \nin precision may be acceptable, in particular when considering the time gained, e.g., when \nconducting rapid reviews for urgent decision-making. Furthermore, use of GPT models might \nallow to broaden the scope of the searches (e.g., increasing time ranges, relaxing search terms, \nadding another electronic database in the search, or searching in clinical trial registries) \nthereby increasing overall comprehensiveness of study inclusion. In particular, the ability of \nAI-based systems to drastically reduce the human workload is of critical importance with the \nrise of network meta-analyses and living network meta-analyses 33, which typically involve \nlarger literature streams than traditional reviews; as well as rapid reviews, which require the \ntimely analysis of these literature streams 34. \nWe chose to use GPT 3.5-Turbo models to ensure that none of the systematic reviews were in \nthe training data set of the model and that no information about the reference standard results \nwere available to inform the index test. GPT-4 models have shown better performance in most \ntasks as compared to GPT 3.5-Turbo models and the performance estimates we show here are \nlikely to improve quickly in the next months or years.  \nAnother issue is the reproducibility and transparency of results from GPT models: for \nexample, researchers have shown important differences in models’ performance over a one-\nmonth interval 35. In this study, highest performance was observed with the first reviews \nassessed. While we cannot ascertain that time and modification of the models was responsible \nfor the change in performance, this affects the reproducibility of results in reviews. Potential \nsolutions may involve the development and use of “fixed” LLM systems for research tasks.  \nOur study has several limitations. First, estimates of sensitivity and performance used five \nreviews from researchers from Cochrane Austria, Germany and France, which involved \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nexperienced reviewers and larger searches. Results may therefore differ in other settings. \nSecond, estimation of the avoidable workload relied on multiple hypotheses which may have \nimpacted the final results. As we used conservative hypotheses and given the magnitude of \nthe avoidable workload of evidence synthesis, we believe that AI-based LLM should be \nconsidered as a “triage tool”, used before human screening, when performing systematic \nreviews. Third, it is known that performance of LLM is driven by the prompt used. In this \nstudy, we chose a standardized prompting style across all reviews, always following the same \nstructure, and incorporating the PICOS extracted from review protocols. While this approach \nfacilitates the use of our results in different contexts, it is possible that fine-tuned prompts \nmay improve the performance of GPT models in specific reviews.  \nAI systems based on LLMs provide highly sensitive and low to moderately specific \nrecommendations to include citations during title and abstract screening, in systematic \nreviews and meta-analyses. Using these models to rule out citations before human screening \ncould significantly reduce human work in evidence synthesis. \n5. Acknowledgments \nWe would like to thank Emilie Sbidian, Laurence Le Cleach and Kathrin Grummich for their \nhelp in obtaining the unannotated databases. \n6. Data sharing statement \nUnannotated data from reviews are available to academic research teams from contacting \noriginal authors of reviews. \n7. Contributorship statement \nGenerated the idea: VTT, Conceived and designed the experiments: VTT, GG, JM and PR. \nCollected data: GG, SY, IB, LS, JS, IS, FA, SA, JM. Analyzed data: VTT, GG, SY, LS, JS, \nIS, FA and SA; Wrote the first draft of the manuscript: VTT. Contributed to the writing of the \nmanuscript: all authors; ICMJE criteria for authorship read and met: all authors. Agree with \nmanuscript results and conclusions: all authors. VTT is the guarantor. He had full access to \nthe data in the study and take responsibility for the integrity of the data and the accuracy of \nthe data analysis. \n8. Funding \nThe authors received no specific funding for this work. \n9. Competing interests \nThe authors declare no competing interests and no financial associations that may be relevant \nor seen as relevant to the submitted manuscript. The authors have no association with \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \ncommercial entities that could be viewed as having an interest in the general area of the \nsubmitted manuscript. \nAll authors have completed the ICMJE uniform disclosure form and declare: no support from \nany organization for the submitted work, no financial relationships with any organizations that \nmight have an interest in the submitted work in the previous three years; and no other \nrelationships or activities that could appear to have influenced the submitted work. \n \n10. References \n1 . D on nelly CA, Bo yd I , Cam pb ell P, e t  al .  Four p r inc iple s to mak e ev idenc e synt hesi s mor e  \nuse ful f o r  po licy . Na t ur e. Jun 2018; 558(7 710):36 1-364 . doi :10 .1038 / d41 586 -018- 0541 4-4  \n2 . N a t io n al In stitu te for  Heal th and Ca re E xce llenc e. NICE  he al th tec hn olo gy ev al u ati on s :  the  \nm an ual . 2 022 .  \n3 . Bor n mann L , Haun sch ild R , Mu tz  R.  Gr owth ra te s o f mod ern scie nce: a l a ten t piec ewi se  \ng r ow th c urve  app roac h t o  model  pu bl icatio n  numb ers  f r om e stabli sh ed a nd new  li t e r a t u re  \nda taba s e s .  H u m a nitie s a nd S ocia l Sc ienc es Com mu ni catio ns . 202 1;8(224 )  \n4 . W a ng Z, Nayf eh T,  T etz l af f J, O ' Bleni s P,  M u r a d  MH . Err or  rat e s o f  hum a n re vie w er s  during  \na bstrac t scre e ning in  s y st ematic  r eview s. Pl oS one . 2 02 0;15(1) :e022 7742 .  \ndo i:10.137 1 / jou r na l .pone .02 27742  \n5 . W a ffe n s c hmid t S, Knel angen  M, S ieb e n W, Bühn S , Piepe r D. Sin gle scre e ning  versu s  \nc onve nt i onal doub le scr eeni ng  fo r study  s el ection i n s y stema tic  revie w s: a m etho dol ogic al sy ste mati c  \nrev iew. BMC me dic al res earch  me tho dol o gy . Jun 2 8 2019; 19(1 ):132. d o i:10.118 6 /s12874 - 0 19 -0782 -0  \n6 . O 'Hea r n K,  M a cDon ald C, T s am palie ro s A, e t al. Ev alu ating  the  rel ati on s h ip b et ween  cita tion  \nse t s i ze, te am  siz e and scr eening  meth o ds  u sed in sy ste matic revi ew s: a cro ss -se ctional  study . BMC  \nm edic al re search m e tho dol ogy . Jul 8 202 1;21(1) :14 2. doi:10 .1186/ s 1 2874 -021-01 335-5  \n7 . A l len IE , O l kin I. Estima t i ng time to c onduc t  a meta -ana ly si s  from n umber of ci t a t i on s \nretri ev ed. Jam a . A ug  18 199 9;282(7):63 4 -5. doi :10. 1001/jama .2 82.7 .634  \n8 . H ol z ing er A. I nte rac t i ve ma chine  le arni ng  for heal th inform atic s: w hen do we n eed th e  \nhu man-in -th e -loop?  Br a in In form . Jun 2 0 16;3(2) :119 - 1 31 . doi:1 0.1007 / s 4 0708-01 6-00 42-6  \n9 . O uzz a ni M, Hammady  H, F edor owi cz Z, Elma garmid A. R a yyan - a  w eb a nd mo b ile app f o r \nsys tema tic  r e view s . Syste ma tic r e view s . Dec  5 2 016;5(1 ):210.  doi :10.1 186 /s136 43-016-038 4 -4  \n1 0. N orman C R, Le efl a ng MMG,  Po rcher R, Névéo l  A. M e a surin g the imp ac t o f s c r e e ning  \na utoma tion o n meta -a n alys e s of dia gnostic t e s t acc uracy . Sy s t  Re v .  Oct  28  2019 ;8(1):243 .  \ndo i:10.118 6 / s13643 - 0 19 -1162-x  \n1 1. Kilic oglu H, Demne r-Fu shm an D , R indfl e s ch TC,  W i lczynski NL, H a yne s RB . Tow ard s  a u t o matic  \nrec ognition of sci enti fic ally  rigoro us  cl inica l re se arch evide nc e. Journ al of the  Americ an M edi ca l  \nI nf or m a t i cs A ssoci a t i on : JAM IA . Jan -Fe b  2009;16 ( 1 ): 25-31 . doi :10.1197 /jami a. M2 996 \n1 2. van de  Sch oo t  R,  de Bruin J, S ch ram R,  e t a l. A n op en sourc e  machi ne  lea r nin g f ra mework fo r \ne ffi cien t a nd tra n s pa re nt  sy stem atic  revi ew s . N at ure Mac hi ne I ntelli ge nce . 2021; 3: 125-133.  \n1 3. Sarraju A, B r u emme r D, Van I te rson E, Cho L, Rodrigu ez F, Laf fin L. App r op r ia t e ne ss o f  \nCa r d iova scul a r D is ea se Pre venti on Rec o mmendation s O bt ain ed F r o m a  Popu l ar  Online  Cha t - Ba se d  \nArti fici al In tell igenc e Mode l.  Ja ma . Mar 1 4 2 023;329 ( 1 0):842 -844. doi :10.10 01 / j ama.20 23.1044  \n1 4. A y er s  JW, Po liak  A, Dre dze M ,  e t  al . Co mparing Physic ian and Ar ti ficia l Int ellige nce Cha t b ot  \nRe spon se s to P ati ent Q u e stio ns Po s ted  to a Public  S ocial  M edia  F or um.  JAM A Inter n Me d . Jun  1  \n2 023;183(6) :5 89-596. d oi :10.100 1 / ja mai nternm ed.20 23.1838  \n1 5. Lev ine DM,  Tuwan i R, Kompa B, et al .  T he Dia gn ostic  a nd T riag e Ac curac y o f th e G PT-3  \nArti fici al In tell igenc e Mode l.  me dRx iv . 20 23;doi: h ttp s : / /doi. org/10 .1101 / 202 3.01 . 30. 2328506 7\n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n1 6. Kung TH, Ch ea t ha m M , Me denill a  A, et a l. Per fo rmance  of C h at G PT  on U S M L E: Pot enti al  f o r \nAI- a s sisted medic al educa t i on u sing  large lang uage model s . PL OS d igital heal th . F eb  \n2 023;2(2) :e00 00198. doi :10.13 71 / jo ur na l.pdig. 0000198  \n1 7. S. W, L iu Y, X u Y, Zh u C, Ze ng M. Want T o  Reduc e La beling  C o s t? G PT - 3  Can H elp.  arXiv. 2 021;  \n1 8. D i ng B, Q in  C , L iu L, Bing L, Joty S, L i B. Is  GPT-3 a Go od Da ta Anno t ator?  ar X iv . \n2 022;doi: ht tp s: //doi.o rg/10 .485 50/ a r Xi v.2212 .10450\n \n1 9. Syriani  E, Davi d I, Kumar G. A sse s s i ng th e Ability  of Ch at G P T to Scre e n Artic le s fo r  S yst e ma tic  \nRe view s. ar X iv . 20 23;d oi:ht tp s : // doi.o rg/ 10.4855 0/ a r Xi v.2307. 06464  \n2 0 .  G u o  E ,  G u p t a  M ,  D e n g  J,  P a r k  Y ,  P a g e t  M ,  N a u g l e r  C .  A u t o m a t e d  P a p e r  S c r e e n i n g  f o r  C l i n i c a l  \nRe view s  U sing L arge L angu age M ode l s  ar X i v . 202 3;doi: h ttp s:/ /doi. org/10 .48550 / a rXiv .2305.0 0844\n \n2 1. Khr a lsh a Q ,  P u t  S , Kapp e nberg  J,  Wa r rai tc h A, H adfi eld K .  C an la rge  la ngua ge mo del s re pla ce  \nhu mans in  the systema t i c r e view  proc e ss ? Eva luating GPT -4's e ff i cac y in s c re e ning and ex tr a cting  \nda ta from p eer -rev iewe d an d  grey  liter atu re i n mul tipl e  la nguag e s . ArXiv . \n2 023;doi: ht tp s: //arxiv .org/a b s /2310 .1 75 26\n \n2 2. Sommer I , D ob re scu  A , Le dinge r D ,  et  al. Outp atie nt Tre a tment  o f Con firmed  CO VI D -19 : A  \nL ivin g, Rapi d Revie w f or t he Am erica n Colleg e o f Phy sic ian s.  An nal s o f i nt ernal m e dici ne . Jan \n2 023;176(1) :9 2-104. d oi :10.7326 /m22-2 2 02 \n23 .  S o m m e r  I ,  Le d i n ge r  D , T h a ler  K , e t  a l .  O ut p a t ie n t  T r eat m ent  o f  Co n f ir m e d  C OVI D -1 9 : A  L i vi n g ,  \nRa pid Ev idenc e Revi ew for the Am eri ca n Colle g e of Phy s ic ian s ( Ver s i on 2) .  Ann als of i nter nal  \nm edic ine . S ep 19 2 023;doi:1 0 .7326/m23 - 162 6 \n2 4 .  K i e s s w e t t e r  E ,  S t a d e l m a i e r  J,  P e t r o p o u l o u  M ,  e t  a l .  E f f e c t s  o f  D a i r y  I n t a k e  o n  M a r k e r s  o f  \nCa r d iom eta bolic  He alth  in Ad ult s:  A S y s t ema tic R ev iew w it h  Ne twork  Me ta -An a l ysis. Adv  N u tr. May  \n2 023;14(3) :43 8-450. d oi :10.1016 /j.a dvnu t.2023 .03 .004 \n2 5. Sbidia n E,  Chai mani A ,  Guelimi  R, e t al . Sy stemic  ph a r m acolo gica l tre atmen t s for c h ronic  \npl aque p s o ria si s: a  netwo rk met a-a nal y s i s. T h e  Co c h r a ne d at ab as e  of  s ys t e mat ic  r e vi e ws . Jul  12  \n2 023;7(7) :Cd01 1535. d oi :10.1002 / 146 51 858.C D011 535.pub6  \n2 6. H ig gins J , Thoma s J, Chan dl er J,  e t  a l. Coc hr a n e H and bo ok  fo r  S yst e ma tic Re view s o f  \nI nt e rv en tion s v e r si on 6.4 . Coc hra ne Coll a borati on; 202 3.  \n2 7. Reit s ma  JB , Rut j e s  AW,  Khan  KS,  Coom a r a samy  A, Bo ssuyt PM . A r e view  o f solution s fo r \ndi agnos tic ac cur ac y studie s with an imp erf ec t  or mi ssing  r ef er enc e s tanda rd.  J Clin Epid e miol . A ug  \n2 009;62(8) :79 7-806. d oi :10.1016 /j.jc line pi .2009.02 .005  \n2 8. W hi t i ng P , Rutje s A W, Rei t sma JB , G la s  AS, Bo s suyt P M, K leijnen  J. So u r c e s of v ariati on and  \nbi as i n s tudie s of  diagno s tic a cc ur a cy:  a  sys tema tic  r ev iew. An n I n t e rn M ed .  Feb  3 2004 ;140(3 ):189 -\n2 02. doi:1 0.7326 /0003-4 819 -140-3 -200 4 02030-00 010 \n2 9. Reit s ma  JB,  G l a s  AS, Ru tje s  A W, Sc holt e n RJ, Bo ssuyt PM, Zw inde rman AH . Biv ar iate an al ysi s \nof s en sitivity a nd s p ec ifici t y  pr o d uce s in forma tive summary  me a s ur e s in  diag no s tic  r e view s .  J our na l  \no f  clin ical epid em iol ogy . O c t 2005;5 8 (10) :982-90. doi :10.10 16 / j .jcli nepi.200 5 .02.0 22 \n3 0. Lerner I , Cre quit P, Ravau d P,  At al I. A u tomatic  sc r e e ning usi ng word embe ddin gs achie ved  \nhi gh sen s i t i vity an d worklo a d r e duction f or upda ting  livi ng network  me ta -analy s e s. Jo urnal o f  c lini ca l  \nep i d em io l og y .  Apr  2019;108 :86 -94. doi :1 0.1016/j.jc linepi .2018 .12 .001  \n3 1. M o r en o -Garc ia C, Jay ne C, Elyan  E, A ce ves -M a r tin s M . A nov el ap plica t i on of mac hine  \nl earning a n d z e ro -sho t  c l as s i fic a tion method s for  a utom ate d ab strac t  sc re e ning in sys t e ma tic  \nrev iews . Dec i s i on A naly t i cs Jour nal . 202 3;6(10016 2)  \n3 2. Calla ghan  MW , Mül l er - Han se n F.  S t a t i s tic a l sto pping crit eria  f or au t om a ted  scre ening  in  \nsys tema tic  r e view s . Syste ma tic r e view s . Nov  28 202 0;9(1):273 . doi:10 .118 6/s136 43 -020-01521 - 4  \n3 3. Zarin W, Ve roni ki AA,  N inc ic  V , e t al. Ch arac t eri s tic s  and  k nowledg e s y nth e s is a pproac h f o r \n4 56 netwo r k  m eta -an al yse s : a  s c oping r e view .  BMC medic ine .  Ja n  5 201 7;15(1 ):3 .  \ndo i:10.118 6 / s12916 - 0 16 -0764-6  \n3 4. Cr e qu it P , Trinqua rt L , Yav chitz A, Rava u d P. Wa s ted r e s e a rch w hen sy stem atic r evi ews f ail t o  \np r o vi d e  a c om p l e te  a nd  u p- t o- d at e e v ide n c e  s y n t hes i s:  t h e ex a m p l e of  l un g  c ance r .  B MC me dic ine . \nJa n 20 201 6;14:8. doi :10.118 6 /s12916 - 0 16-0555-0  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n3 5. Chen L, Zaha r ia  M, Zou J.  How Is Chat GPT’ s Be h avio r  Cha ngi ng over T ime. arXiv . \n2 023;doi: ht tp s: //doi.o rg/10 .485 50/ a r Xi v.2307 .09009  \n \nT able 1. Characteri s tic s  of included r ev i ews  \nRev iew \nNu m b e r  o f  \ncitations identified \nfro m elec t ronic  \nsearches*  \nNu m b e r  o f  \ncitations inc lude d \nafter t i t le  and \nabs tract \nsc re e n i n g *  \nNu m b e r  o f  \ncitations inc lude d \na ft er full -text \nsc re e n i n g *  \nS ommer et al . (2022 )  673  235 (35 %) 26 (4% ) \nS ommer et al . (2023 )  407 7 120 ( 3 %) 8  (0.1%)  \nY aac oub et al .  (unp ubli shed )  633 4 722 (11 %) 20 0 (3.2% ) \nKi esswe t te r et a l . (2023 )  647 8 7 7 (1.2% ) 19  (0.2%)  \nS bidian  et al . (2 023 )  510 4 33 1 (6.4% ) 17 9 (3.6% ) \nTo t al  226 66 14 85 (6.5% )  43 2 (1.9% ) \n* Figure s may be s l ightly di ff ere nt fr om publi s h ed  ar tic le s  du e to t he  w ay dupli c ate cita tio n s  we re  \nha ndled   \n \nT able 2. S ens itiv it y and specific ity  of GP T m odels  to rule out c it a t ions d ur i ng title and a bs trac t \nscreeni ng. * Re fe rence sta nda rd 2 ac co unt s fo r th e imper f ect na tur e of r e f e re nce s ta nda r d  1 : all  \ndi s c re panci e s  b etwe en deci s i ons  f rom author s and f rom A I  wer e rea sse ssed  by the au tho rs o f  \nrev iews . ** O bt aine d by u sing  a biv aria te mode l  \n Referenc e st a ndard 1 Referenc e st a ndard 2*  \nRe view Se ns itivity \n[95%C I]  \nS p e c if ic i t y \n[9 5 % C I ]  \nSe ns itivity \n[95% CI]  \nSpec if i city  \n[95%CI] \nS ommer et al . (2022 )  81.3 \n[77.1 – 84.9 ]  \n56.6  \n[50. 8 – 62. 2 ] \n87.5 \n[83.9 –  90.5 ]  \n66. 0 \n[60. 3 – 71. 2 ]  \nS ommer et al . (2023 )  98.1 \n[97.6 – 98.5 ]  \n38.6  \n[30. 2 – 47. 8 ] \n99.1  \n[98.7 –  99.3 ]  \n38. 6 \n[30. 2 – 47. 8 ]  \nY aac oub et al .  \n(unp ubli she d)  \n92.0 \n[91.3 – 92.7 ]  \n52.2  \n[47. 8 – 56. 6 ] \n94.6  \n[94.0 –  95.1 ]  \n57. 7 \n[53. 5 – 62. 2 ]  \nKi esswe t te r e t  al .  \n(20 23)  \n99.2 \n[99.0 – 99.4 ]  \n9.1 \n[6.4  – 12 .7]  \n99.6 \n[99.5 –  99.8 ]  \n9.7  \n[7.0  – 13 .4 ] \nS bidian  et al . (2 023 )  91.6 \n[90.7 – 92.3 ]  \n24.8  \n[21.7 -28 .3 ]  \n92.5 \n[91.7 –  93.2 ]  \n31. 7 \n[28.3 -35 .4 ]  \nPo oled st atistic**  95.3 \n[86.2 – 98.5 ]  \n33.0  \n[16. 5 – 55. 1 ] \n97.1 \n[89.6 –  99.2 ]  \n37. 7 \n[18. 4 – 61. 9 ]  \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \nF igure 1: Biv ar i at e  s um ma r y es ti mates of s ensitivity  and s pec ificity  for the abilit y of  G PT  models  t o  \ns c r e e n  f o r  t i t l e  a n d  a b s t r a c t  i n  t h e  f i v e  s ys t e m a t i c  r e v i e w s .  We  u sed r e fe renc e s tan d ard 2  w hich  \na cc ount s  for  imper fec t  na ture  o f huma n de cisi on s by r eana ly si s  o f  a ll di scr epa nci es  by  t h e  au tho rs o f  \nrev iews .  \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint \n0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\nFalse Positive Rate\nSensitivity\nData\nPooled estimate\nSROC\nConfidence region\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.(which was not certified by peer review)preprint \nThe copyright holder for thisthis version posted December 17, 2023. ; https://doi.org/10.1101/2023.12.15.23300018doi: medRxiv preprint "
}