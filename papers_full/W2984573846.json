{
  "title": "Pedestrian Heading Estimation Based on Spatial Transformer Networks and Hierarchical LSTM",
  "url": "https://openalex.org/W2984573846",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A2097324074",
      "name": "Qu Wang",
      "affiliations": [
        "Beijing University of Posts and Telecommunications"
      ]
    },
    {
      "id": "https://openalex.org/A2130830421",
      "name": "Haiyong Luo",
      "affiliations": [
        "Institute of Computing Technology",
        "University of Chinese Academy of Sciences"
      ]
    },
    {
      "id": "https://openalex.org/A2904806545",
      "name": "Langlang Ye",
      "affiliations": [
        "University of Chinese Academy of Sciences",
        "Institute of Computing Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2265328786",
      "name": "Aidong Men",
      "affiliations": [
        "Beijing University of Posts and Telecommunications"
      ]
    },
    {
      "id": "https://openalex.org/A2023743285",
      "name": "Fang Zhao",
      "affiliations": [
        "Beijing University of Posts and Telecommunications"
      ]
    },
    {
      "id": "https://openalex.org/A2098668577",
      "name": "Yan Huang",
      "affiliations": [
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2402564827",
      "name": "Changhai Ou",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2097324074",
      "name": "Qu Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2130830421",
      "name": "Haiyong Luo",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2904806545",
      "name": "Langlang Ye",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2265328786",
      "name": "Aidong Men",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2023743285",
      "name": "Fang Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098668577",
      "name": "Yan Huang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2402564827",
      "name": "Changhai Ou",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2088136988",
    "https://openalex.org/W2011224697",
    "https://openalex.org/W2808833513",
    "https://openalex.org/W2161872204",
    "https://openalex.org/W6678255763",
    "https://openalex.org/W2911310752",
    "https://openalex.org/W2182353117",
    "https://openalex.org/W2909910397",
    "https://openalex.org/W2039833319",
    "https://openalex.org/W2075198545",
    "https://openalex.org/W6763204146",
    "https://openalex.org/W2883923125",
    "https://openalex.org/W2895262569",
    "https://openalex.org/W2309916540",
    "https://openalex.org/W2781125408",
    "https://openalex.org/W1991133427",
    "https://openalex.org/W2125691646",
    "https://openalex.org/W2560609797",
    "https://openalex.org/W2042821893",
    "https://openalex.org/W1947853012",
    "https://openalex.org/W2886988640",
    "https://openalex.org/W2918704254",
    "https://openalex.org/W1956618308",
    "https://openalex.org/W2184410429",
    "https://openalex.org/W2984124472",
    "https://openalex.org/W2056427752",
    "https://openalex.org/W2160146756",
    "https://openalex.org/W2186667588",
    "https://openalex.org/W2889987081",
    "https://openalex.org/W2962994355",
    "https://openalex.org/W6754547238",
    "https://openalex.org/W6747834056",
    "https://openalex.org/W2887149528",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2741392919",
    "https://openalex.org/W1998552594",
    "https://openalex.org/W2953071416",
    "https://openalex.org/W2920745458",
    "https://openalex.org/W2894555786",
    "https://openalex.org/W2805594094",
    "https://openalex.org/W2790384971",
    "https://openalex.org/W2744793037",
    "https://openalex.org/W2908979191",
    "https://openalex.org/W2955299013",
    "https://openalex.org/W2782546940",
    "https://openalex.org/W2792576649",
    "https://openalex.org/W2945555875",
    "https://openalex.org/W2912791673",
    "https://openalex.org/W2953673861",
    "https://openalex.org/W2788453142",
    "https://openalex.org/W2947739547",
    "https://openalex.org/W2735031100",
    "https://openalex.org/W2958608002",
    "https://openalex.org/W2903155668",
    "https://openalex.org/W2083256639",
    "https://openalex.org/W2897182409",
    "https://openalex.org/W2114182580",
    "https://openalex.org/W1995588456",
    "https://openalex.org/W2034271950",
    "https://openalex.org/W2103217435",
    "https://openalex.org/W2192417683",
    "https://openalex.org/W2889409040",
    "https://openalex.org/W2108512685",
    "https://openalex.org/W2811144474",
    "https://openalex.org/W2891047313",
    "https://openalex.org/W2963423603",
    "https://openalex.org/W2947698081",
    "https://openalex.org/W2122093596"
  ],
  "abstract": "Accurate heading estimation is the foundation of numerous applications, including augmented reality, pedestrian dead reckoning, and human-computer interactions. While magnetometer is a key source of heading information, the poor accuracy of consumer-grade hardware coupled with the pervasive magnetic disturbances makes accurate heading estimation a challenging issue. Heading error is one of the main error sources of pedestrian dead reckoning. To reduce the heading error and enhance robustness, we proposed a novel heading estimation method based on Spatial Transformer Networks (STNs) and Long Short-Term Memory (LSTM), termed DeepHeading, which uses sensors embedded in a smartphone without any historical training data or dedicated infrastructure. We automatically annotate heading data based on map matching, and augment heading data based on device attitude. We leverage the STNs to align the device coordinate system and the navigation coordinate system, allow an unconstrained use of smartphones. Based on the characteristics of pedestrian heading continuity, we designed a hierarchical LSTM-basedSeq2Seq model to estimate the walking heading of the pedestrian. We conducted well-designed experiments to evaluate the performance of deepheading and compared it with the state-of-the-art heading estimation algorithms. The experimental results on real-world demonstrated that deepheading outperformed the compared heading estimation algorithms and achieved promising estimation accuracy with a median heading error of 4.52°, mean heading error of 6.07° and heading error of 9.18° at the confidence of 80% when a pedestrian is walking in indoor environments with magnetic field disturbances. The proposed method is high-efficiency and easy to integrate with various mobile applications.",
  "full_text": "Received October 6, 2019, accepted October 28, 2019, date of publication October 31, 2019, date of current version November 18, 2019.\nDigital Object Identifier 10.1 109/ACCESS.2019.2950728\nPedestrian Heading Estimation Based on Spatial\nTransformer Networks and Hierarchical LSTM\nQU WANG\n 1, HAIYONG LUO\n 2, (Member, IEEE), LANGLANG YE2,\nAIDONG MEN1, (Member, IEEE), FANG ZHAO3,\nYAN HUANG4, AND CHANGHAI OU\n5\n1School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China\n2Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, University of Chinese Academy of Sciences,\nBeijing 100190, China\n3School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China\n4School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China\n5School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798\nCorresponding authors: Haiyong Luo (yhluo@ict.ac.cn) and Aidong Men (menad@bupt.edu.cn)\nThis work was supported in part by the National Key Research and Development Program under Grant 2016YFB0502000, in part by the\nNational Natural Science Foundation of China under Grant 61872046, Grant 61671264, and Grant 61671077, in part by the Action Plan\nProject of the Beijing University of Posts and Telecommunications supported by the Fundamental Research Funds for the Central\nUniversities under Grant 2019XD-A06, in part by the Special Project for Youth Research and Innovation, Beijing University of Posts and\nTelecommunications, supported by the Fundamental Research Funds for the Central Universities under Grant 2019PTB-011, in part by the\nKey Research and Development Project from Hebei Province under Grant 19210404D, in part by the Open Project of the Beijing Key\nLaboratory of Mobile Computing and Pervasive Device, in part by the Blue Fire Plan (Huizhou) Industry-University Joint Innovation\nProject of Ministry of Education under Grant CXZJHZ201729, and in part by the BUPT Excellent Ph.D. Students Foundation under Grant\nCX2018102.\nABSTRACT Accurate heading estimation is the foundation of numerous applications, including augmented\nreality, pedestrian dead reckoning, and human-computer interactions. While magnetometer is a key source\nof heading information, the poor accuracy of consumer-grade hardware coupled with the pervasive magnetic\ndisturbances makes accurate heading estimation a challenging issue. Heading error is one of the main error\nsources of pedestrian dead reckoning. To reduce the heading error and enhance robustness, we proposed\na novel heading estimation method based on Spatial Transformer Networks (STNs) and Long Short-Term\nMemory (LSTM), termed DeepHeading, which uses sensors embedded in a smartphone without any histori-\ncal training data or dedicated infrastructure. We automatically annotate heading data based on map matching,\nand augment heading data based on device attitude. We leverage the STNs to align the device coordinate\nsystem and the navigation coordinate system, allow an unconstrained use of smartphones. Based on the\ncharacteristics of pedestrian heading continuity, we designed a hierarchical LSTM-basedSeq2Seq model\nto estimate the walking heading of the pedestrian. We conducted well-designed experiments to evaluate\nthe performance of deepheading and compared it with the state-of-the-art heading estimation algorithms.\nThe experimental results on real-world demonstrated that deepheading outperformed the compared heading\nestimation algorithms and achieved promising estimation accuracy with a median heading error of 4.52 ◦,\nmean heading error of 6.07 ◦and heading error of 9.18 ◦at the conﬁdence of 80% when a pedestrian is\nwalking in indoor environments with magnetic ﬁeld disturbances. The proposed method is high-efﬁciency\nand easy to integrate with various mobile applications.\nINDEX TERMS Indoor positioning, heading estimation, pedestrian dead reckoning, deep learning.\nI. INTRODUCTION\nIn various spatiotemporal network demands, location-based\nservice (LBS) is one of the essential network service\napplications [1]. Accurate and pervasive indoor positioning\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Mohammad Anwar Hossain\n.\nhas been applied in a variety of domains such as asset and\npersonnel tracking, search and rescue, health monitoring,\nlocation-based social networks, and location-speciﬁc push\nnotiﬁcations [2]. To meet the explosive demand, various\nindoor positioning and indoor navigation approaches have\nrecently been developed, including RFID [3], UWB [4],\nBLE [5], Wi-Fi [6]–[8], magnetic [9], [10], visible light\nVOLUME 7, 2019 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see http://creativecommons.org/licenses/by/4.0/ 162309\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\n[11], [12] and visual methods [13]. Most existing tech-\nnologies depend on historical training data or dedicated\ninfrastructure, which is always not continuously available\nduring pedestrian walking. Moreover, the hardware cost of\nlargescale deployment is very expensive\nAmong various indoor positioning schemes, pedestrian\ndead reckoning (PDR) become mainstream technology\nbecause PDR does not rely on any dedicated infrastruc-\ntures [14]–[16]. Furthermore, PDR based on smartphone\nmainly beneﬁts from the proliferation of smartphones, which\nhave integrated inertial measurement unit (IMU) sensor\nsensors (gyroscope and accelerometer) and magnetometer.\nSmartphone is always carried almost everywhere we go, thus\nmaking that smartphone plays an indispensable role in our\ndaily lives. Moreover, unlike radio-frequency signal-based\nmethods, PDR has no coverage limitation, thus providing\nseamless positioning services connecting indoor and out-\ndoor environments. Given an initial location, PDR estimates\nthe relative position of a pedestrian in real-time by join-\ning the heading estimation and displacement of each step.\nAn ocean of studies about step detection and step counting\nhave been done, including context-based, peak detection, fre-\nquency domain features, auto-correlation, zero-crossing and\nneural networks [17]. Considerable studies about step length\nestimation have been developed to enhance the accuracy of\nstep length estimation, and they are summarized as dou-\nble integration of the acceleration, empirical relationships,\nlinear models, nonlinear models, biomechanical models,\ncontext-based and deep learning [18], [19].\nThe heading (walking direction of pedestrian at each\nstep) estimation of pedestrian is a dominant factor in PDR\nalgorithms [20]. For instance, 5 degrees heading estimation\nerror will result in 5.2 meters positioning error after traveling\n100 meters. Nowadays, to develop PDR systems with smart-\nphoneembedded low-cost sensors, accurate heading estima-\ntion over a long period is a crucial issue [21]. Unlike step\ncounting and step length estimation, heading estimation is\nmore challenging. Many heading estimation methods employ\nwearable devices worn in a speciﬁc position to estimate\nthe heading of pedestrian [22]. Foxlin [23] leveraged foot-\nmounted sensors estimate reliable heading of pedestrian by\nintroducing the zero velocity updates into extended Kalman\nFilter. Jirawimut et al.[24] used stereo-cameras ﬁxed on the\npedestrian’s chest to achieve the walking heading of pedes-\ntrian. However, carrying a dedicated device is unpractical\nand inconvenient for users in their daily lives. For the mass\nusers, using smartphone as a navigation carrier for heading\nestimation is more practical.\nMost smartphones-based heading estimation methods\nare based on gyroscopes, accelerometers, magnetometers.\nMagnetometers estimate the heading angle relative to the\nmagnetic north by sensing the earth magnetic ﬁeld. Attitude\nand Heading Reference Systems (AHRS) combines inertial\nsensors and magnetometer observations to estimate heading.\nMadgwick et al.[25] presented a real-time heading estimat-\ning algorithm for the x-IMU sensor board [26] based on\nthe gradient descent method, which is widely known as the\nmost accurate open source heading estimating algorithm. The\nMadgwick et al.[25] and Mahony et al.[27] only correctly\nestimated the heading of pedestrian under ideal conditions\n(i.e. no magnetic disturbances). However, the ferromagnetic\nmaterials in buildings severely affected magnetometer read-\nings, which resulted in heading errors [28]. Gyroscopes\nonly give a short-term accurate heading estimation, while\nmagnetometers give a long-term heading estimation.\nKang et al. [29] proposed a reliable heading estimation\nmethod based on the correlation between magnetometer\nand gyroscope using a selection and weighting algorithm.\nPoulose et al.[14] estimated heading by fusing the magne-\ntometer and gyroscope sensor values. To enhance heading\nestimation accuracy, Xu et al. [30] designed a heading cor-\nrection method based on zero angular velocity and lateral\nvelocity limitation to reduce the error of heading estimation.\nZhao et al. [15] improved gradient descent algorithm to\nreduce the heading drift. To obtain a better heading estima-\ntion, extended Kalman ﬁltering (EKF) [31]–[33] and com-\nplementary ﬁlters (CF) [34]–[36] are used to fuse inertial\nsensors and magnetometer readings, and reduce sensor noise.\nIn References [37], [38], smartphone-based heading estima-\ntion algorithms required users to hold a smartphone in a ﬁxed\nmode as long as possible. Most existing smartphone-based\nheading estimation methods assume that the misalignment\nangle between the device and pedestrian remains constant,\nand pedestrian’s heading is determined by removing the\nheading offset [22]. However, the misalignment angle varies\nwith body locomotion. The pedestrians may put their smart-\nphone in bag, make a phone call, or even swing in hand\nduring walking. To solve this problem, references [39]–[43]\nproposed smartphone mode or posture recognition-based\nPDR method that calculated pedestrian heading by selecting\nheading model with corresponding to smartphone mode.\nHowever, the limited mode classiﬁcation cannot reﬂect the\ndiversity of smartphone carrying modes. The unconstrained\nposture and position of a smartphone brings great challenges\nfor heading estimation.\nTo estimate the heading of pedestrian without the con-\nstraints of smartphone attitude, some researchers utilize the\nprincipal component analysis (PCA) of acceleration to deter-\nmine the offset between the misalignment angle between\nsmartphone and pedestrian. Wang et al. [40] combined\nPCA with global accelerations to estimate pedestrian head-\nings. Kunze et al. [44] utilized PCA over the horizontal\nacceleration components for estimating walking heading of\na pedestrian with a smartphone placed in pocket. However,\nthe performance of PCA-based approaches relies on the esti-\nmation of the horizontal acceleration plane that is prone to\nthe device coordinates change. To enhance the estimation\naccuracy of the horizontal acceleration plane, RMPCA [22]\nleveraged a rotation matrix that tracks the device coordi-\nnates accurately and continuously, and combined the rotation\nmatrix with PCA to estimate pedestrian heading. However,\nthe approach is speciﬁcally designed for the smartphone\n162310 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nplaced in a trouser pocket, and it may be not suitable for\nother positions. Moreover, the PCA-based heading estimation\nmethods have the problem of 180 ◦ambiguity [45] that is dif-\nﬁcult to solve. For estimating the heading of pedestrian with-\nout attitude constraints, uDirect [46] directly estimated the\nheading of pedestrian within a speciﬁc area of acceleration,\nwhere the forward acceleration (the ﬁrst principal component\nof principal component analysis) dominated the horizontal\nacceleration components. However, the speciﬁc area was\nalways corrupted by the lateral acceleration during walking.\nMore importantly, both PCA-based nor uDirect approaches\nutilize compass to convert the local heading into the global\none. Compass is prone to magnetic perturbations [47]. There-\nfore, neither PCA nor uDirect approach can obtain an\naccurate and robustness heading estimation in the indoor\nenvironment. In addition, studies [48]–[54] leveraged map\ninformation or map matching technology to reduce heading\nestimation error and improve heading estimation accuracy.\nHowever, map limits the practicability of PDR.\nDeep learning automatically learns features with high-\nlevel abstractions by using multiple nonlinear transforma-\ntions [55]. Deep learning has been deemed to be powerful for\nnatural language processing and speech-recognition, with-\nout additional processing. Neural Networks show excellent\npotential to exploit and analyze the collected data without\nhandcraft feature extraction. Motivated by the fact that speech\nrecognition based on deep learning outperforms other exist-\ning traditional speech recognition methods, studies [56]–[62]\nleveraged deep learning technologies to reckon trajectory\nof pedestrian. All of them achieve superior localization\naccuracy. However, they only provide position information,\nno heading information. This paper proposed a novel heading\nestimation method based on Spatial Transformer Networks\n(STNs) [63] and Long Short-Term Memory (LSTM), termed\nDeepHeading, to overcome the aforementioned shortcom-\nings. We automatically annotate the heading data based on\nmap matching, and augment the heading data based on device\nattitude. The STNs is used to align the coordinate system.\nIn addition, we design a hierarchical LSTM-basedSeq2Seq\nmodel to estimate the heading of the pedestrian according\nto the characteristics of pedestrian heading continuity. Deep-\nHeading estimates pedestrian’s heading with inertial sensors\nand magnetometer embedded in commercial smartphones.\nThe main contributions of paper are as follows:\n• We propose a method for automatic data labeling in\npedestrian heading estimation problem. The ground-\ntruth of pedestrian heading is hard to collect, which\nis rarely mentioned and mostly jumped over in most\nexisting related studies. We leverage a foot-mounted\nIMU module to collect the relative trajectory, then match\nthe trajectory with the real indoor path to obtain the\naccurately heading of pedestrian in each step.\n• We propose a heading data augmentation method based\non device attitude. To reduce the amount of training\ndata collection and solve the terminal attitude prob-\nlem, data augmentation method is used to expand the\nFIGURE 1. System architecture of deepheading.\ncollected data, thus promoting the ﬁt of the model to the\npedestrian’s heading and enhancing the robustness of the\nheading.\n• We propose a pedestrian heading estimation method\nbased on STNs and hierarchical LSTM. We leverage the\nSTNs to align the device coordinate system and the navi-\ngation coordinate system. Based on the characteristics of\npedestrian heading continuity, we design a hierarchical\nLSTM-based Seq2Seq model to estimate the walking\nheading of the pedestrian.\n• We conduct elaborate experiments to compare the head-\ning estimation accuracy of single-step heading model\nwith Seq2Seq heading model, and analyze the impact\nof data augmentation. The experimental results on real-\nworld data set show that the heading error is within 9.18 ◦\nat the conﬁdence of 80%.\nThe rest of the paper is organized as follows: we detail the\nsolution of the proposed deepheading in Section II. After that,\nwe evaluate deepheading in Section III. At last, we draw our\nconclusions and future work in Section IV .\nII. MATERIALS AND METHODS\nIn this section, overview of proposed method is depicted.\nThen, the essential modules are described, which include\nheading data annotation based on map matching, heading data\naugmentation method based on device attitude, and heading\nestimation method based on STNs and hierarchical LSTM.\nA. SYSTEM ARCHITECTURE\nFigure 1 illustrates the overall structure of Seq2Seq pedes-\ntrian heading estimation model based on Spatial Transformer\nNetworks (STNs) and hierarchical LSTM. In the ofﬂine phase\nwe utilized the inertial-sensors and magnetometer measure-\nments from smartphone as training data, and the correspond-\ning PDR trajectory from the foot-mounted IMU module and\nmap matching as labels to train a heading model. In the online\npredicting phase, we leveraged the trained heading estimation\nmodel and real-time sensor data to accurately estimate the\nheading of pedestrian in each step.\nVOLUME 7, 2019 162311\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nB. HEADING DATA ANNOTATION BASED\nON MAP MATCHING\nFor heading estimation, a key problem is how to obtain the\nground-truth of the pedestrian’s heading. The ground-truth is\nthe key to verify and tune the heading estimation algorithm.\nFor the heading estimation model based on deep learning,\nthe ground-truth of the user’s heading is the necessary data\nlabel for model training. At present, many papers avoid the\nquestion of getting the user’s heading ground-truth. Some\npapers directly use the known heading of the straight path\nas the ground-truth of the user’s heading. However, users do\nnot strictly follow a straight line most of the time. Moreover,\neven if user walks in a straight line, there will be a slight\nswing in heading during the walking process. Therefore, it is\nchallenging to accurately capture the heading of pedestrians\nat every step.\nThis section introduces a map matching-based heading\ndata annotation algorithm, which utilizes the user’s trajectory\ninformation and indoor map to obtain the true heading of\nthe user’s current trajectory, and further calculates the user’s\none-step heading and completes the data labeling. We use\nHidden Markov Model (HMM) to match the PDR trajectory\nto the key points of the map (called node). Pedestrian trajec-\ntory matching is modeled as a decoding problem. In other\nwords, given a model λ ={M,N,π, A,B}and observation\nsequence O, pedestrian trajectory matching aims to ﬁnd an\noptimal node sequence Q that best explains the observa-\ntion sequence O. In our model, λ, M and N represent the\nnumber of hidden states and observation states, respectively.\nπdenotes the initial state distribution. A and B represent the\nstate transition matrix and the emission matrix. We present\nour HMM as follows:\n• Hidden States: in our HMM, we deﬁne the key nodes\nof the map as hidden states. each state represents a\nnode. M = {S1,S2,··· ,Si,···}is the set of hidden\nstates, where Si =[kpi,0,kpi,1] represents the position\nof the ith state. Pedestrian only moves between adjacent\nnodes.\n• Observations: we use the walking distance and average\nheading during two consecutive turns as observations.\nNi ={Disi,Diri}is the set of observations. Disi and Diri\nare the walking distance and the mean of heading angle\nobservations during two consecutive turns.\n• Transition Probabilities: a transition between hidden\nstates is triggered by a turn event. Since the building\ntopology constrains the accessible areas of pedestrians,\nwe leverage the length information of indoor path to\nconstruct a transition matrix. Therefore, the transition\nprobability of each node in our HMM model is deﬁned\nas follow,\nAi,j = 1\n1 +Disi,j\n(1)\nTPi,j = Ai,j\n∑N\nj=1 Ai,j\n(2)\nwhere Disi is the walking distance observations during\ntwo consecutive turns. TP is transition probabilities\n• Emission Probabilities: the emission probability consists\nof the distance and heading information. Since walk-\ning distance and heading observations are independent,\nwe deﬁne the emission probability distribution EP as\nfollows,\nEPk\n=P(DisPDR,DirPDR|Sk−1,Sk )\n= 1\n√\n2πDisStdsk−1,sk\ne\n− 1\n2DisStd2sk−1,sk\n(DisPDR−Dissk−1,sk )2\n• 1√\n2πDirStdsk−1,sk\ne\n− 1\n2DirStd2sk−1,sk\n(DirPDR−Dirsk−1,sk )2\n(3)\nwhere\nDisi,j =\n\n\n\n\n\n√\n(kpi,0 −kpj,0)2 +(kpi,1 −kpj,1)2,\nif i ̸=j and sc i,j =1\n∞,\nif i = j or sc i,j =0\n(4)\nDiri,j =\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0,\nif i =j\ncos−1(−(kpj,1 −kpi,1)\ndisi,j\n)∗180,\nif i ̸=j and sc i,j =1 and kpj,1 −kpi,1 ≥0\n360 −cos−1(−(kpj,1 −kpi,1)\ndisi,j\n)∗180,\nif i ̸=j and sc i,j =1 and kpj,1 −kpi,1 <0\nNaN,\nif i ̸=j and sc i,j =0\n(5)\nwhere Sk is the kth hidden state. sc i,j represents\nconnectivity between state i and state j. sc i,j = 1\nrepresents reachable path, and sc i,j = 0 represents\nunreachable path. [kp i,0,kpi,1] represents the position of\nthe ith state. DirStdsk−1,sk and DisStdsk−1,sk represent the\nstandard deviation of the heading and distance obser-\nvations, respectively. DisPDR is the calculative walking\ndistance calculated by PDR, and Dissk−1,sk is the distance\nbetween sk−1 and sk . DirPDR is the average heading\nestimated by PDR, and Dirsk−1,sk is the angle between\nvector sk−1,sk and magnetic North.\n• Initial State Distribution: the initial state distribution is\nuniform when the ﬁrst turn event is detected.\n5i =1\nN (6)\nwhere N represents the number of observation states.\n• Pedestrian Trajectory Matching: after obtaining the tran-\nsition and emission probabilities, we solve the\nHMM-based map-matching problem utilizing the\n162312 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nFIGURE 2. Map matching based on HMM.\nFIGURE 3. Data annotation of pedestrian step heading.\nViterbi decoder [64]. To decrease the computational\noverhead of Viterbi decoding procedure, we leverage\nthe user’s heading and walking distance to remove the\ninvalid states. In addition, PDR usually works with other\npositioning algorithms that can be used to decrease the\ncomputational overhead of map matching and improve\nmatching accuracy.\np(st =x) =max\ni\np(st−1 =i) •p(st =x|st−1 =i)\n•p(DisPDR,DirPDR|st−1 =i,st =x) (7)\nAs shown in Figure 2, the upper left is the true walking\npath, the top right is the most likely path in the matching\nresult, and the bottom left and bottom right are the candidate\npaths for the second and third probability in the matching\nresults.\nAfter getting the most likely path, it is easy to get the\ntrue heading value of each atomic path (a straight from map\ninformation). As shown in Figure 3, we calculate the real\nheading of user one-step by combining the deviation between\nthe atomic path and trajectories from foot-mounted IMU\nmodel. The green line is atomic path, and the black line is\nthe walking trajectory from foot-mounted IMU module.\nhi =αk +βi, stepi ∈segk (8)\nwhere segk is kth atomic path, αk is the heading of the kth\natomic path. βi is the angle between the heading of the stepi\nin the kth atomic path and the heading of the corresponding\natomic path. hi is the ground-truth of walking heading in\nnavigation frame.\nC. HEADING DATA AUGMENTATION METHOD\nBASED ON DEVICE ATTITUDE\nThe key problem with deep learning in practice is the amount\nof data. The training process of the deep learning model is\na process of model parameter adjustment. The number of\nparameters in the deep learning model is often in the mil-\nlions or even hundreds of millions of magnitudes Therefore,\na massive amount of data is needed to learn these parameters.\nHowever, the process of collecting massive amounts of data\nis often a time-consuming and laborious task. It makes sense\nand is necessary to expand the amount of data by using data-\nexpanding techniques on the original data set. In addition,\nincreasing the data in the dataset effectively can prevent the\nnetwork from learning irrelevant characteristics and focus\nmore on the characteristics related to the goal thus signif-\nicantly enhancing the model performance and generaliza-\ntion capabilities. However, the data augmentation method for\ntime-series data (sensor data) has not been well investigated\nso far.\nWe expand the inertial sensor data by attitude conversion,\nso that the model extracts more useful features directly related\nto the user’s heading from the sensor data, thus eliminating\nthe inﬂuence of the device attitude. We ﬁrst randomly gen-\nerate a set of Euler angles (yaw angle α, roll angle β, pitch\nangle γ),\n(α,β,γ )=Random(3) (9)\nThe corresponding attitude conversion matrix is calculated\nfor the resulting Euler angle. (10)–(13), as shown at the\nbottom of the next page.\nWe convert the sensor data to generate new samples.\nD =\n\n\nx1 ··· xT\ny1 ··· yT\nz1 ··· zT\n\n (14)\nDnew =RD (15)\nwhere (x,y,z) represent three-axis sensor data, T is the number\nof sensor readings in the time interval of each step. D and\nDnew denote the original and generated three-axis sensor data-\nseries, respectively.\nIt is important to emphasize that the proposed heading data\naugmentation method is performed for the accelerometer,\nthe gyroscope and the magnetometer data, respectively.\nD. PEDESTRIAN HEADING ESTIMATION BASED\nON STNS AND HIERARCHICAL LSTM\n1) ADAPTIVE ALIGNING ALGORITHM BASED ON STNs\nThe alignment of device coordinate system and navigation\ncoordinate system is a key problem in heading estimation.\nThe traditional way is to maintain a real-time attitude esti-\nmation and convert the observations from device coordinate\nsystem to the navigation coordinate system. In response to\nthis problem, we present an adaptive alignment algorithm\nbased on Spatial Transformer Networks (STNs) [63]. STNs is\nproposed by Google DeepMind to solve the spatial invariance\nof computer vision models on input images. STNs mainly\ntransforms the input image or feature map, outputs the new\nimage or feature map, and in theory, the STNs can cor-\nrect the image or feature map as the ideal image or feature\nVOLUME 7, 2019 162313\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nFIGURE 4. Structure of spatial transformer networks [63].\nmap after the transformation of the image or feature map.\nAs shown in Figure 4, the input of STNs is a matrix or feature\nmap U, and the output is a corrected image or feature map\nV , which mainly consists of a localization network, a grid\ngenerator, and a sampler. The input feature map U is passed\nto a localization network which regresses the transformation\nparameters θ. The regular spatial grid G over V is transformed\nto the sampling grid Tθ(G), which is applied to U, produc-\ning the warped output feature map V . The combination of\nthe localization network and sampling mechanism deﬁnes a\nspatial transformer.\nFirst, the localization network is a customizable network\nwhose primary function is to calculate the transformation\nparameters θ through the input U. This parameter is used to\nmap the coordinates (x,y) in U to the coordinates (x ′,y′) in V .\nFor instance, zoom in on the input image k times, or rotate\nthe input by θdegrees.\n[x′\ny′\n]\n=\n[k 0\n0 k\n][x\ny\n]\n+\n[0\n0\n]\n(16)\n[x′\ny′\n]\n=\n[cosθ −sinθ\nsinθ cosθ\n][x\ny\n]\n+\n[0\n0\n]\n(17)\nThe prediction parameters are determined by the per-\nformed transformation. For the two two-dimensional afﬁne\ntransformations described above, the prediction is six param-\neters that represent the coordinate mapping relationship\nbetween the input and output.\nSecondly, after the transformation parameters are obtained\nby localization network, the corresponding coordinate points\ncan be found in the output map V by making matrix opera-\ntions for each point in the input feature map U according to\nthe parameter obtained by the localization network.\n[xs\ni\nys\ni\n]\n=2\n\n\nxt\ni\nyt\ni\n1\n\n=\n[θ11 θ12 θ13\nθ21 θ22 θ23\n]\n\nxt\ni\nyt\ni\n1\n\n (18)\nwhere (x t\ni , yt\ni ) is the target coordinates of the regular grid in\nthe output feature map, 2is the afﬁne transformation matrix,\nand (x s\ni , ys\ni ) is the source coordinates in the input feature map\nthat deﬁne the sample points.\nFinally, the grid generator generates samples. Each pixel\nin output map V is ﬁlled with the corresponding coordinates\nin input map U to obtain a pixel value. Because the calcu-\nlated coordinates can be decimal, the coordinates need to be\nprocessed, and the surrounding pixels need to be considered\nwhen ﬁlling, the ﬁlling formula is as follows.\nVi =\n∑\nn\n∑\nm\nUnm ∗k\n(\nxs\ni −m;∅x\n)\n∗k\n(\nys\ni −n;∅y\n)\n(19)\nwhere m and n will traverse all coordinate points in the\ninput map U. Unm refers to the pixel value of a point in the\ninput map U. k is the sampling core, indicating that different\nmethods are used to ﬁll. ∅x and ∅y are parameters.\n(\nxs\ni ,ys\ni\n)\nrepresents the corresponding point in the ith point in V to U.\nFilling is usually done by bilinear interpolation. After ﬁlling,\na converted image or feature map is obtained.\nVi =\n∑\nn\n∑\nm\nUnm ∗max\n(\n0,1 −\n⏐⏐xs\ni −m\n⏐\n⏐)\n∗max\n(\n0,1 −\n⏐⏐ys\ni −n\n⏐⏐)\n(20)\nSTNs is a plug-and-play module that can be inserted into\nan existing model, thus allowing the model to achieve the\nspatial transformation of an image or feature map without\nadditional supervision and without changing the original opti-\nmization process. STNs is mainly used in such tasks like\nimage classiﬁcation and image entity co-positioning.\nR (α)=\n\n\n1 0 0\n0 cos(α ) −sin(α)\n0 sin(α ) cos(α )\n\n (10)\nR (β)=\n\n\ncos(β) 0 sin(β )\n0 1 0\n−sin(β) 0 cos(β )\n\n (11)\nR (γ)=\n\n\ncos(γ) −sin(γ) 0\nsin(γ) cos(γ ) 0\n0 0 1\n\n (12)\nR =R (γ)\nR (β)R (α)=\n\n\ncos (β)cos(γ) sin (α)sin (β)cos (γ)−cos (α)sin(γ) cos (α)sin (β)cos (γ)+sin (α)sin(γ)\ncos (β)sin(γ) sin (α)sin (β)sin (γ)+cos (α)cos(γ) cos (α)sin (β)sin (γ)−sin (α)cos(γ)\n−sin(β) sin (α)cos(β) cos (α)cos(β)\n\n (13)\n162314 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nFIGURE 5. A daptive aligning module in the proposed heading estimation\nmodel.\nFor smartphone sensor data, a set of sensor data is similar\nto a set of three-dimensional point clouds. Therefore, we are\ninspired by the approach PointNet [65] and implement a sim-\npler approach that is similar to STNs. As shown in Figure 5,\nwe design a transformation network (T-Net) module that\npredicts an afﬁne transformation matrix based on input data,\ntransforms the input data with the predicted transformation\nmatrix and then passes it into the original model for adaptive\nalignment.\nBefore the Step LSTM layer, sensor data for a gait cycle\nis passed into a small LSTM network. This LSTM network\nintegrates sensor data in the gait cycle and eventually predicts\na conversion matrix by regression, which uses the conversion\nmatrix to convert the input sensor data. We use the converted\ndata as input to the Step LSTM layer. The conversion module\nis inserted between the input layer and the Step LSTM layer.\nBefore extracting the time-series features, the current sensor\ndata input is predicted and converted, so that the model has\nsome afﬁne invariant.\n2) SEQ2SEQ PEDESTRIAN HEADING ESTIMATION\nMODEL BASED ON HIERARCHICAL LSTM\nThere is a strong correlation between the heading of the\nadjacent steps within the same user track, and simply deﬁning\nthe sample by step will lose this continuous information, and\nthe noise of the single-step data causes large-scale heading\nﬂuctuations, seriously affecting the performance of the head-\ning estimation. Therefore, we propose a Seq2Seq pedestrian\nheading estimation model based on hierarchical LSTM to\naccurately estimate the heading of pedestrian travel, as shown\nin Figure 6.\nThe method takes a user trajectory as a sample. The sensor\ndata collected by the trajectory is the input sequence, and\nthe heading corresponding to each step of the trajectory is\nthe output sequence. Sensor data in a gait cycle is processed\nby the Step LSTM to extract the heading information of the\ncurrent step. The output of the Step LSTM at each step of\nthe throughout trajectory forms a sequence that acts as an\ninput to the Track LSTM layer. The time step in the Step\nLSTM layer is a set of sensor data, a multi-to-one LSTM\nstructure, while the time step in the Track LSTM layer is a\ngait cycle, a many-to-many LSTM structure. The Heading\nRegression layer calculates the output of each time step of\nthe Track LSTM layer. Finally, the Track LSTM layer output\nthe predicted heading of pedestrian for each step.\n3) LOSS FUNCTION DESIGNING FOR HEADING ESTIMATION\nFor general regression problems, Mean Squared Error (MSE)\nis usually used as a loss function to adjust the model weight\naccording to the MSE between the model prediction value\nand the ground-truth. For the heading estimation problem,\nMSE cannot reﬂect the true deviation between the predicted\nvalue and the ground-truth, due to the circular period problem\nof the heading as shown in Figure 7. For instance, when\nthe true heading is 5 ◦, the MSE of the predicted 355 ◦ is\n122500 while the MSE of the predicted 25 ◦is 400. The loss\nvalue of the former is much higher than the loss value of the\nlatter. However, the deviation between the former and the real\nheading is 10 ◦, and the deviation between the latter and the\nreal heading is 20 ◦. The inappropriate loss function directly\ncauses the error in the heading of model optimization, thus\npreventing the model from converging.\nMSE =1\nN\nN∑\ni=1\n(θi −ˆθi)\n2\n(21)\nwhere θ is the real heading obtained by combining map\ninformation and walking trajectory from foot-mounted IMU\nmodel, ˆθis the prediction of heading estimation algorithm.\nAs shown in Figure 8, we consider the problem of the head-\ning circumference and deﬁne new loss function for heading\nestimation, termed Heading Loss, which reﬂects the devia-\ntion between the predicted heading and the true heading by\ncalculating the European distance between the intersection of\nthe true and predicted headings on the unit circle according\nto equation (22).\nHeading Loss= 1\n2N\nN∑\ni=1\n((\nsin (θi)−sin\n(\nˆθi\n))2\n+\n(\ncos (θi)−cos\n(\nˆθi\n))2)\n(22)\nwhere θis the real heading, ˆθis the prediction heading.\nFigure 9 compares the loss value change of Heading Loss\nwith that of MSE. If the real heading of the pedestrian is 0 ◦\n(positive north). Heading Loss has a minimum value when\nthe model prediction is 0 ◦ or 360 ◦, and the value of the\nHeading Loss increases gradually as the predicted heading\ndeviates from 0◦or 360◦. Heading Loss reaches the maximum\nvalue when the model prediction is 180 ◦ (positive south),\nwhich is the opposite heading of the real heading. This result\nindicates that the Heading Loss is more reasonable than MSE\nfor heading estimation problem.\nVOLUME 7, 2019 162315\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nFIGURE 6. The architecture of the proposed Seq2Seq pedestrian heading estimation model based on hierarchical LSTM.\nFIGURE 7. The circular period problem of the heading.\nFIGURE 8. Diagram of heading loss.\nE. COMPLETE PROCEDURES OF PROPOSED HEADING\nESTIMATION METHOD\nAlgorithm 1 describes the complete procedures of the\nproposed heading estimation method. The proposed algo-\nrithm takes a set of training samples with precise heading\nlabel as input to train the network. The inertial sensors and\nFIGURE 9. Comparison of MSE and heading loss.\nmagnetometer readings are divided into segments by step\nevent. The step data is fed to heading model. The actual\nheading is used to train the regression layer on the top of the\nnetwork. Once the training is done, the heading model will be\nused to predict the heading of pedestrian at each step.\n162316 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nAlgorithm 1Pedestrian Heading Estimation Based on STNs\nand Hierarchical LSTM\n1: Input: sensors data with PDR trajectory, indoor map,\ntest data without PDR trajectory\n2 Output: heading estimation of pedestrian\n3 // Data annotation and augmentation\n4 Segment the inertial sensor data according to the step\nevent.\n5 For each trajectory do\n6 Perform HMM-based map matching\n7 Split atomic path according to the most likely path\n8 Calculate heading of each step according to the\ndeviation between the atomic path and trajectory\n9 Annotate heading with sensors data for each step\n10 End for\n11 Augment heading data according to device attitude\n12 // Model training\n13 Coordinate system aligning using STNs\n14 Build and train step LSTM model\n15 Build and train track LSTM (Seq2Seq) model\n16 // Testing\n17 Step detection and counting\n18 Coordinate system aligning using STNs\n19 Leverage trained model to predict heading of\npedestrian at each step\nF. FEVALUATION METRICS\nThe paper uses a one-step heading error to measure the\nperformance of the model. The one-step heading error is\ncalculated as follow.\nEh =1\nN\nN∑\ni=1\n((\nHi\ne −Hi\nt\n)\nmod 360\n)\n(23)\nwhere Hi\ne and Hi\nt denote the estimated heading and the real\nheading of the i-th step, respectively. Eh is heading error. N is\nthe number of step.\nIII. EXPERIMENTATION AND EVALUATION\nA. AEXPERIMENTAL SETUP\nTo evaluate the effectiveness and explore the limitations\nof DeepHeading, we implemented and evaluated Deep-\nHeading in indoor environments with magnetic ﬁeld dis-\nturbances. Obtaining ground-truth of pedestrian heading\nin indoor environments is not trivial and usually requires\ndedicated infrastructure such as an optical motion cap-\nture system (Vicon [66]) during experimental setup. Here,\nwe have designed a new methodology for obtaining ground-\ntruth of relative heading according map information and\nwalking trajectory. As shown in Figure 10, we obtained\ndata with precise heading labels using a foot-mounted\nIMU module (NGIMU [67] with a three-axis accelerome-\nter (range ±16 g), and gyroscope (range ±2000 deg/sec)\ncome from x-io technologies), which controls localiza-\ntion error in 0.3% of the entire travel distance and an\nFIGURE 10. The system of training data collection and performance\nevaluation.\nTABLE 1. Description of subjects.\nTABLE 2. Description of devices.\nAndroid smartphone, which equipped with inertial sensors\n(consist of a three-axis accelerometer (range ±8 g), and gyro-\nscope (range ±2000 deg/sec)) from InvenSense (ICM-20690)\nand a three-axis magnetometer (amk09911, range 2000 uT).\nThe precise PDR trajectory of pedestrian from foot-mounted\nIMU module was sent to smartphone through a Wi-Fi mod-\nule. We matched the trajectory with the real indoor path to\naccurately obtain the heading of pedestrians at every step and\nsynchronize the obtained heading with the MEMS observa-\ntions of the smartphone. We utilized the obtained heading\nas ground-truth to train heading model and evaluate the per-\nformance of model. The data collected from 7 test subjects\nand 6 devices were randomly divided into three parts: 70%\nof the data for heading model training and 30% of the data\nfor heading model validation (15%) and testing (15%). The\nsubjects and devices information were detailed in Table 1 and\nTable 2.\nB. COMPARISON OF MODEL WITH AND\nWITHOUT DATA AUGMENTATION\nTo verify the inﬂuence of the data augmentation method\non model performance, we trained two single-step heading\nmodels (one model with data augmentation, another model\nwithout data augmentation) and compared their performance\nusing the same data set. We ﬁrst directly used the original\nVOLUME 7, 2019 162317\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nTABLE 3. Comparison of model with and without data augmentation\n(statistics).\ntraining set to train a single-step heading estimation model.\nThen, we extended the original data set using the proposed\nheading data augmentation method based on device attitude,\nand used the expanded training set to train a heading model.\nThe results of the comparison are as shown in Table 3 and\nFigure 11. Under 80%, the error of the single-step heading\nmodel with data augmentation in ofﬁce and shopping mall\nare 11.91◦and 12.81◦, respectively. Compared to the single-\nstep heading model without data augmentation, the mean\nheading estimation error of the model with data augmentation\ndecreased from 9.94◦to 7.44◦in ofﬁce scenario and 10.31 ◦to\n8.26◦in shopping mall scenario. In other word, the mean error\nof the model with data augmentation in ofﬁce and shopping\nmall are reduced by 25.15% ((9.94 ◦–7.44◦)/ 9.94 ◦)∗100%\nand 19.88% ((10.31 ◦–8.26◦)/ 8.26 ◦)∗100%, respectively.\nThe experimental results demonstrated that data augmenta-\ntion help improves heading estimation accuracy. The most\nimportant thing was that the data augmentation greatly\nreduced the collection and storage overhead of training\ndata.\nC. COMPARISON OF SINGLE-STEP HEADING\nMODEL AND SEQ2SEQ HEADING MODEL\nConsidering the continuous characteristics of heading esti-\nmation, we designed a Seq2Seq model based on hierarchical\nLSTM using data from a walking trajectory as a sequence\nsample. To verify the impact of the Seq2Seq model architec-\nture on heading estimation performance, we used the same\naugmented data to test and compare performance between\nthe single-step model and the Seq2Seq model. As shown\nin Figure 12 and Table 4, we used the statistical values\nand cumulative distribution function (CDF) to demonstrate\nheading estimation performance comparison between the\nLSTM-based single-step heading model and the hierarchical\nLSTM-based Seq2Seq heading model. The heading estima-\ntion error of the Seq2Seq heading model was within 9.18 ◦\nat the conﬁdence of 80%. Compared with the single-step\nheading model, the mean heading estimation error of the\nSeq2Seq model decreased from 7.44 ◦ to 6.07 ◦. In other\nwords, the performance of the Seq2Seq heading estimation\nmodel was enhanced by 18.41%. The experimental results\ndemonstrated that the Seq2Seq heading estimation model\nfor the continuity of the hierarchical LSTM-based heading\nestimation problem dramatically improved the accuracy of\nthe heading estimation.\nFIGURE 11. Comparison of model with and without data\naugmentation (CDF).\nFIGURE 12. Comparison of the single-step LSTM model and the\nSeq2Seq model (CDF).\nD. COMPARISON WITH OTHER METHODS\nTo justify the superiority of our pedestrian heading estimation\nmethod, we compared the proposed pedestrian heading esti-\nmation method with the following state-of-the-art pedestrian\nheading estimation methods:\n• uDirect [46], directly estimates the heading of pedestrian\nwithin a speciﬁc area of acceleration, where the forward\nacceleration (the ﬁrst principal component of principal\n162318 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nTABLE 4. Comparison of the single-step model and the Seq2Seq model\n(statistics).\ncomponent analysis) dominated the horizontal accelera-\ntion components. However, the speciﬁc area was always\ncorrupted by the lateral acceleration during walking.\n• RMPCA [22], achieves accurate user heading estima-\ntion based on Rotation Matrix and Principal Component\nAnalysis, regardless of the smartphone orientation and\nplacement within the pocket.\n• Deng [43], detects the three motion states (random\nhand movements, carrying position transitions, and user\nturns,) timely and discriminate them accurately by\na position classiﬁer, estimates walking heading with\nrespect to motion state.\n• SmartPDR [38]: a PDR solution based on a smartphone\nkept on hands all the time, which includes an heading\nestimation method that logically selects how to blend\nprevious heading estimation, gyroscope measurements\nwith magnetic data based on the variation of magne-\ntometer as well as the correlation between magnetometer\nand gyroscope.\nWe studied the overall heading estimation accuracy of\nthe proposed method and compared methods with differ-\nent holding smartphone styles. To make a fair comparison,\nwe utilized the same training set to train the heading esti-\nmation models and utilized the same testing set to validate\nthe performance of models. Figure 13 shows the cumula-\ntive error distribution of the proposed method and compared\nheading estimation method. As seen in Figure 13 the 50th\npercentile heading estimation error of the proposed method\nis 4.52 degrees, while those of uDirect, RMPCA, Deng and\nsmartPDR are 10.96, 9.76, 6.84 and 5.75 degrees, respec-\ntively. the 75th percentile heading estimation error of the\nproposed method is 7.93 degrees, while those of uDirect,\nRMPCA, Deng and smartPDR are 19.03, 17.60, 11.17 and\n9.94 degrees, respectively. The 90th percentile heading esti-\nmation error of the proposed approach is 13.41 degrees,\nwhile those of uDirect, RMPCA, Deng and smartPDR are\n28.11, 25.01, 16.25 and 16.18 degrees, respectively. As seen\nin Figure 14, compared with uDirect, RMPCA, Deng and\nsmartPDR, the proposed method reduces the mean head-\ning estimation error by 53.98 percent (7.12 degrees), 48.69\npercent (5.76 degrees), 23.65 percent (1.88 degrees), and\n17.97 percent (1.33 degrees), respectively. For standard devi-\nation of heading estimation error, the proposed approach\nreduces it by 44.67 percent (4.57 degrees), 36.33 percent\n(3.23 degrees), 7.36 percent (0.45 degrees), and 17.49 percent\nFIGURE 13. Comparison of the proposed method and other methods\n(CDF).\nFIGURE 14. Comparison of the proposed method and other methods\n(Mean and standard deviation).\n(1.2 degrees), respectively. The proposed method achieved\nmore signiﬁcant heading estimation accuracy than those of\ncompared methods.\nE. TIME COMPLEXITY ANALYSIS\nThe top 2 most time-consuming procedures of the proposed\nheading estimation method are the training data collection\nand neural-network training. Fortunately, both two proce-\ndures are performed in the ofﬂine phase In other words,\nthe two procedures do not consume time during the online\nprediction phase. The time consumption of collecting training\ndata equals walking time. The heading model training is\nperformed on a personal computer equipped with an Intel\nCore i5-4460 CPU and 16 GB DDR4 RAM.\nTable 5 details the training and testing time of the proposed\nheading estimation method on the whole training dataset and\ntest data. The sample unit of the single-step heading model\nis the step, while the sample unit of the Seq2Seq heading\nmodel is the trajectory. The training set size is 25 trajectories\n(2790 steps), and the test set size is 7 trajectories (872 steps).\nCompared to the single-step heading model, the Seq2Seq\nmodel adds an LSTM layer, and increases the number of\nparameters, but the total training time only increases 16 min-\nutes. In the testing phase, the Seq2Seq heading model and the\nVOLUME 7, 2019 162319\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nTABLE 5. Time complexity analysis of heading estimation models in time complexity.\nsingle-step model have no obvious difference in time, and the\naverage prediction time per step is about 2.32 milliseconds,\nwith good real-time.\nIV. CONCLUSION\nWalking heading of pedestrian provides indispensable\ninformation for pedestrian dead reckoning, augmented\nreality/virtual reality, sports training, and human-computer\ninteractions. Notably, the heading is one of the most critical\nfactors in PDR-based indoor positioning. The accurate head-\ning estimation of pedestrians is a challenging research topic.\nThis paper proposed a novel heading estimation by exploiting\nthe inertial sensors built-in smartphones. We automatically\nannotated heading data based on map matching, and augment\nthe heading data based on device attitude. We leveraged the\nSTNs to align the device coordinate system and the nav-\nigation coordinate system. Based on the characteristics of\npedestrian heading continuity, we designed a hierarchical\nLSTM-based Seq2Seq model to estimate the heading of the\npedestrian. The proposed method achieved a median heading\nerror of 4.52 ◦, mean heading error of 6.07 ◦and heading error\nof 9.18◦at the conﬁdence of 80%.\nDeepheading requires a signiﬁcant amount data for train-\ning, validation and testing. In addition, highly precise labels\n(ground-truth of walking heading) are extremely important\nin model training. The acquisition of the ground-truth of\nthe walking direction is a very difﬁcult problem. This paper\nobtains the walking heading based on map match and user\nwalking trajectories from the foot-mounted inertial module.\nThis method provides a new way for obtaining the ground-\ntruth of walking heading. However, mismatch and non-\nnormal walking will cause signiﬁcant error of ground-truth.\nFortunately, the map matching-based heading data annotation\nalgorithm only used in the ofﬂine phase, the training data\ncollector is required to strictly walk along the pre-planned\ntrajectory, and the error of ground-truth be controlled within\nan acceptable range.\nREFERENCES\n[1] Z. Peng, S. Gao, B. Xiao, G. Wei, S. Guo, and Y . Yang, ‘‘Indoor ﬂoor\nplan construction through sensing data collected from smartphones,’’ IEEE\nInternet Things J., vol. 5, no. 6, pp. 4351–4364, Aug. 2018.\n[2] Y . Shu, C. Bo, G. Shen, C. Zhao, L. Li, and F. Zhao, ‘‘Magicol: Indoor\nlocalization using pervasive magnetic ﬁeld and opportunistic WiFi sens-\ning,’’IEEE J. Sel. Areas Commun., vol. 33, no. 7, pp. 1443–1457, Jul. 2015.\n[3] F. Seco and A. R. Jiménez, ‘‘Smartphone-based cooperative indoor local-\nization with RFID technology,’’ Sensors, vol. 18, no. 1, p. 266, 2018.\n[4] J. Sidorenko, V . Schatz, N. Scherer-Negenborn, M. Arens, and\nU. Hugentobler, ‘‘Decawave UWB clock drift correction and power\nself-calibration,’’Sensors, vol. 19, no. 13, p. 2942, Jul. 2019.\n[5] C. Xiao, D. Yang, Z. Chen, and G. Tan, ‘‘3-D BLE indoor localization\nbased on denoising autoencoder,’’ IEEE Access, vol. 5, pp. 12751–12760,\n2017.\n[6] R. Wang, Z. Li, H. Luo, F. Zhao, W. Shao, and Q. Wang, ‘‘A robust Wi-Fi\nﬁngerprint positioning algorithm using stacked denoising autoencoder and\nmulti-layer perceptron,’’ Remote Sens., vol. 11, no. 11, p. 1293, May 2019.\n[7] W. Shao, H. Luo, F. Zhao, Y . Ma, Z. Zhao, and A. Crivello, ‘‘Indoor\npositioning based on ﬁngerprint-image and deep learning,’’ IEEE Access,\nvol. 6, pp. 74699–74712, 2018.\n[8] S. Xu, R. Chen, Y . Yu, G. Guo, and L. Huang, ‘‘Locating smartphones\nindoors using built-in sensors and Wi-Fi ranging with an enhanced particle\nﬁlter,’’IEEE Access, vol. 7, pp. 95140–95153, 2019.\n[9] D. Liu, S. Guo, Y . Yang, Y . Shi, and M. Chen, ‘‘Geomagnetism-based\nindoor navigation by ofﬂoading strategy in NB-IoT,’’ IEEE Internet Things\nJ., vol. 6, no. 3, pp. 4074–4084, Jun. 2019.\n[10] B. Bhattarai, R. K. Yadav, H.-S. Gang, and J.-Y . Pyun, ‘‘Geomagnetic ﬁeld\nbased indoor landmark classiﬁcation using deep learning,’’ IEEE Access,\nvol. 7, pp. 33943–33956, 2019.\n[11] Q. Wang, H. Luo, A. Men, F. Zhao, and Y . Huang, ‘‘An infrastructure-free\nindoor localization algorithm for smartphones,’’ Sensors, vol. 18, no. 10,\np. 3317, Oct. 2018.\n[12] Q. Wang, ‘‘Light positioning: A high-accuracy visible light indoor posi-\ntioning system based on attitude identiﬁcation and propagation model,’’\nInt. J. Distrib. Sens. Netw., vol. 14, no. 2, pp. 1–14, Feb. 2018.\n[13] T. Liu, X. Zhang, Q. Li, and Z. Fang, ‘‘A visual-based approach for\nindoor radio map construction using smartphones,’’ Sensors, vol. 17, no. 8,\np. 1790, 2017.\n[14] A. Poulose, O. S. Eyobu, and D. S. Han, ‘‘An indoor position-estimation\nalgorithm using smartphone IMU sensor data,’’ IEEE Access, vol. 7,\npp. 11165–11177, 2019.\n[15] H. Zhao, L. Zhang, S. Qiu, Z. Wang, N. Yang, and J. Xu, ‘‘Pedestrian\ndead reckoning using pocket-worn smartphone,’’ IEEE Access, vol. 7,\npp. 91063–91073, 2019.\n[16] M. Zhang, Y . Wen, J. Chen, X. Yang, R. Gao, and H. Zhao, ‘‘Pedestrian\ndead-reckoning indoor localization based on OS-ELM,’’ IEEE Access,\nvol. 6, pp. 6116–6129, 2018.\n[17] X. Kang, B. Huang, and G. Qi, ‘‘A novel walking detection and step\ncounting algorithm using unconstrained smartphones,’’ Sensors, vol. 18,\nno. 1, p. 297, 2018.\n[18] Q. Wang, L. Ye, H. Luo, A. Men, F. Zhao, and C. Ou, ‘‘Pedestrian Walking\nDistance Estimation Based on Smartphone Mode Recognition,’’ Remote\nSens., vol. 11, no. 9, p. 1140, May 2019.\n[19] Q. Wang, L. Ye, H. Luo, A. Men, F. Zhao, and Y . Huang, ‘‘Pedestrian stride-\nlength estimation based on LSTM and denoising autoencoders,’’ Sensors,\nvol. 19, no. 4, p. 840, Feb. 2019.\n[20] A. Manos, I. Klein, and T. Hazan, ‘‘Gravity-based methods for heading\ncomputation in pedestrian dead reckoning,’’ Sensors, vol. 19, no. 5, p. 1170,\n2019.\n[21] M. Edel and E. Köppe, ‘‘An advanced method for pedestrian dead reckon-\ning using BLSTM-RNNs,’’ in Proc. Int. Conf. Indoor Positioning Indoor\nNavigat. (IPIN), Oct. 2015, pp. 1–6.\n[22] Z.-A. Deng, G. Wang, Y . Hu, and D. Wu, ‘‘Heading estimation for indoor\npedestrian navigation using a smartphone in the pocket,’’ Sensors, vol. 15,\nno. 9, pp. 21518–21536, 2015.\n[23] E. Foxlin, ‘‘Pedestrian tracking with shoe-mounted inertial sensors,’’ IEEE\nComput. Graph. Appl., vol. 25, no. 6, pp. 38–46, Nov. 2005.\n[24] R. Jirawimut, S. Prakoonwit, F. Cecelja, and W. Balachandran, ‘‘Visual\nodometer for pedestrian navigation,’’ IEEE Trans. Instrum. Meas., vol. 52,\nno. 4, pp. 1166–1173, Aug. 2003.\n[25] S. O. H. Madgwick, A. J. L. Harrison, and R. Vaidyanathan, ‘‘Estimation of\nIMU and MARG orientation using a gradient descent algorithm,’’ in Proc.\nIEEE Int. Conf. Rehabil. Robot., Jun. 2011, pp. 1–7.\n[26] X-IMU Sensor Board. Accessed: Apr. 15, 2019. [Online]. Available: http://\nx-io.co.uk/x-imu/\n[27] R. Mahony, T. Hamel, and J. M. Pﬂimlin, ‘‘Nonlinear complementary\nﬁlters on the special orthogonal group,’’ IEEE Trans. Autom. Control,\nvol. 53, no. 5, pp. 1203–1217, Jun. 2008.\n162320 VOLUME 7, 2019\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\n[28] B. Fan, Q. Li, and T. Liu, ‘‘How magnetic disturbance inﬂuences the\nattitude and heading in magnetic and inertial sensor-based orientation\nestimation,’’Sensors, vol. 18, no. 1, p. 76, 2018.\n[29] W. Kang, S. Nam, Y . Han, and S. Lee, ‘‘Improved heading estimation\nfor smartphone-based indoor positioning systems,’’ in Proc. IEEE 23rd\nInt. Symp. Pers., Indoor Mobile Radio Commun. (PIMRC), Apr. 2012,\npp. 2449–2453.\n[30] L. Xu, Z. Xiong, J. Liu, Z. Wang, and Y . Ding, ‘‘A novel pedestrian dead\nreckoning algorithm for multi-mode recognition based on smartphones,’’\nRemote Sens., vol. 11, p. 294, Jan. 2019.\n[31] J. L. Marins, X. Yun, E. R. Bachmann, R. B. McGhee, and M. J. Zyda,\n‘‘An extended Kalman ﬁlter for quaternion-based orientation estimation\nusing MARG sensors,’’ in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst.\nExpanding Societal Role Robot. Next Millennium, vol. 4, Oct. 2002,\npp. 2003–2011.\n[32] A. M. Sabatini, ‘‘Quaternion-based extended Kalman ﬁlter for determining\norientation by inertial and magnetic sensing,’’ IEEE Trans. Biomed. Eng.,\nvol. 53, no. 7, pp. 1346–1356, Jun. 2006.\n[33] D. Wu, L. Xia, and J. Geng, ‘‘Heading estimation for pedestrian dead\nreckoning based on robust adaptive Kalman ﬁltering,’’ Sensors, vol. 18,\nno. 6, p. 1970, Jun. 2018.\n[34] H. Fourati, N. Manamanni, L. Aﬁlal, and Y . Handrich, ‘‘Complementary\nobserver for body segments motion capturing by inertial and magnetic\nsensors,’’ IEEE/ASME Trans. Mechatronics, vol. 19, no. 1, pp. 149–157,\nNov. 2014.\n[35] T. S. Yoo, S. K. Hong, H. M. Yoon, and S. Park, ‘‘Gain-scheduled com-\nplementary ﬁlter design for a MEMS based attitude and heading reference\nsystem,’’Sensors, vol. 11, no. 4, pp. 3816–3830, 2011.\n[36] Q. Fan, H. Zhang, P. Pan, X. Zhuang, J. Jia, P. Zhang, Z. Zhao, G. Zhu, and\nY . Tang, ‘‘Improved pedestrian dead reckoning based on a robust adaptive\nKalman ﬁlter for indoor inertial location system,’’ Sensors, vol. 19, no. 2,\np. 294, Jan. 2019.\n[37] A. Bilke and J. Sieck, ‘‘Using the magnetic ﬁeld for indoor localisation on\na mobile phone,’’ in Progress in Location-Based Services(Lecture Notes\nin Geoinformation and Cartography). Berlin, Germany: Springer, 2013,\npp. 195–208.\n[38] W. Kang and Y . Han, ‘‘SmartPDR: Smartphone-based pedestrian dead\nreckoning for indoor localization,’’ IEEE Sensors J., vol. 15, no. 5,\npp. 2906–2916, May 2015.\n[39] R. Gao, ‘‘Sextant: Towards ubiquitous indoor localization service by\nphoto-taking of the environment,’’ IEEE Trans. Mobile Comput., vol. 15,\nno. 2, pp. 460–474, Mar. 2016.\n[40] B. Wang, X. Liu, B. Yu, R. Jia, and X. Gan, ‘‘Pedestrian dead reckoning\nbased on motion mode recognition using a smartphone,’’ Sensors, vol. 18,\nno. 6, p. 1811, Jun. 2018.\n[41] I. Klein, Y . Solaz, and G. Ohayon, ‘‘Pedestrian dead reckoning with\nsmartphone mode recognition,’’ IEEE Sensors J., vol. 18, no. 18,\npp. 7577–7584, Sep. 2018.\n[42] M. Elhoushi, J. Georgy, A. Noureldin, and M. J. Korenberg, ‘‘Motion mode\nrecognition for indoor pedestrian navigation using portable devices,’’ IEEE\nTrans. Instrum. Meas., vol. 65, no. 1, pp. 208–221, Jan. 2015.\n[43] Z. Deng, X. Liu, Z. Qu, C. Hou, and W. Si, ‘‘Robust heading estimation for\nindoor pedestrian navigation using unconstrained smartphones,’’ Wireless\nCommun. Mobile Comput., vol. 2018, pp. 1–11, Jul. 2018.\n[44] K. Kunze, P. Lukowicz, K. Partridge, and B. Begole, ‘‘Which way am\nI facing: Inferring horizontal device orientation from an accelerometer\nsignal,’’ in Proc. Int. Symp. Wearable Comput., Sep. 2009, pp. 149–150.\n[45] U. Steinhoff and B. Schiele, ‘‘Dead reckoning from the pocket—An exper-\nimental study,’’ in Proc. IEEE Int. Conf. Pervasive Comput. Commun.\n(PerCom), Mar. 2010, pp. 162–170.\n[46] S. A. Hoseinitabatabaei, A. Gluhak, R. Tafazolli, and W. Headley, ‘‘Design,\nrealization, and evaluation of uDirect—An approach for pervasive obser-\nvation of user facing direction on mobile phones,’’ IEEE Trans. Mobile\nComput., vol. 13, no. 9, pp. 1981–1994, Apr. 2014.\n[47] M. H. Afzal, V . Renaudin, and G. Lachapelle, ‘‘Use of earth’s magnetic\nﬁeld for mitigating gyroscope errors regardless of magnetic perturbation,’’\nSensors, vol. 11, no. 12, pp. 11390–11414, 2011.\n[48] F. Zampella, A. R. J. Ruiz, and F. S. Granja, ‘‘Indoor positioning using efﬁ-\ncient map matching, RSS measurements, and an improved motion model,’’\nIEEE Trans. Veh. Technol., vol. 64, no. 4, pp. 1304–1317, Apr. 2015.\n[49] H. Bao and W. C. Wong, ‘‘A novel map-based dead-reckoning algorithm\nfor indoor localization,’’ J. Sens. Actuator Netw., vol. 3, no. 1, pp. 44–63,\n2014.\n[50] Q. Tian, Z. Salcic, K. I.-K. Wang, and Y . Pan, ‘‘A hybrid indoor local-\nization and navigation system with map matching for pedestrians using\nsmartphones,’’Sensors, vol. 15, no. 12, pp. 30759–30783, Dec. 2015.\n[51] L. Pei, D. Liu, D. Zou, R. L. F. Choy, Y . Chen, and Z. He, ‘‘Optimal\nheading estimation based multidimensional particle ﬁlter for pedestrian\nindoor positioning,’’ IEEE Access, vol. 6, pp. 49705–49720, 2018.\n[52] F. Holzke, J.-P. Wolff, and C. Haubelt, ‘‘Improving pedestrian dead reckon-\ning using likely paths and backtracking for mobile devices,’’ in Proc. IEEE\nInt. Conf. Pervasive Comput. Commun. Workshops (PerCom Workshops),\nMar. 2019, pp. 273–278.\n[53] J. Qian, L. Pei, J. Ma, R. Ying, and P. Liu, ‘‘Vector graph assisted pedestrian\ndead reckoning using an unconstrained smartphone,’’ Sensors, vol. 15,\nno. 3, pp. 5032–5057, 2015.\n[54] L. Ma, Y . Fan, Y . Xu, and Y . Cui, ‘‘Pedestrian dead reckoning trajectory\nmatching method for radio map crowdsourcing building in WiFi indoor\npositioning system,’’ in Proc. IEEE Int. Conf. Commun. (ICC), May 2017,\npp. 1–6.\n[55] Y . LeCun, Y . Bengio, and G. Hinton, ‘‘Deep learning,’’ Nature, vol. 521,\nno. 7553, pp. 436–444, May 2015.\n[56] S. Cortes, A. Solin, and J. Kannala, ‘‘Deep learning based speed estimation\nfor constraining strapdown inertial navigation on smartphones,’’ in Proc.\nIEEE 28th Int. Workshop Mach. Learn. Signal Process. (MLSP), Sep. 2018,\npp. 1–6.\n[57] C. Chen, X. Lu, A. Markham, and N. Trigoni, ‘‘IONet: Learning to cure\nthe curse of drift in inertial odometry,’’ in Proc. Conf. Artif. Intell. (AAAI),\n2018, pp. 6468–6476.\n[58] C. Chen, P. Zhao, C. X. Lu, W. Wang, A. Markham, and\nN. Trigoni, ‘‘OxIOD: The dataset for deep inertial odometry,’’ Sep. 2018,\narXiv:1809.07491. [Online]. Available: https://arxiv.org/abs/1809.07491\n[59] H. Yan, Q. Shan, and Y . Furukawa, ‘‘RIDI: Robust IMU double integra-\ntion,’’ in Proc. Eur. Conf. Comput. Vis., in Lecture Notes in Computer\nScience, vol. 11217, 2018, pp. 641–656.\n[60] H. Yan, S. Herath, and Y . Furukawa, ‘‘RoNIN: Robust neural inertial navi-\ngation in the wild: Benchmark, evaluations, and new methods,’’ May 2019,\narXiv:1905.12853. [Online]. Available: https://arxiv.org/abs/1905.12853\n[61] C. Chen, Y . Miao, C. X. Lu, P. Blunsom, A. Markham, and N. Trigoni,\n‘‘Transferring physical motion between domains for neural inertial track-\ning,’’ in Proc. NIPS, Oct. 2018, pp. 1–4.\n[62] S. Cortés, A. Solin, E. Rahtu, and J. Kannala, ‘‘ADVIO: An authen-\ntic dataset for visual-inertial odometry,’’ in Proc. Eur. Conf. Comput.\nVis. (ECCV), in Lecture Notes in Computer Science, vol. 11214, 2018,\npp. 425–440.\n[63] R. Pelossof, I. Singh, J. L. Yang, M. T. Weirauch, T. R. Hughes, and\nC. S. Leslie, ‘‘Afﬁnity regression predicts the recognition code of\nnucleic acid–binding proteins,’’ Nature Biotechnol., vol. 33, no. 12,\npp. 1242–1249, Dec. 2015.\n[64] A. J. Viterbi, ‘‘Error bounds for convolutional codes and an asymptotically\noptimum decoding algorithm,’’ IEEE Trans. Inf. Theory, vol. 13, no. 2,\npp. 260–269, Apr. 1967.\n[65] R. Q. Charles, H. Su, M. Kaichun, and L. J. Guibas, ‘‘PointNet: Deep\nlearning on point sets for 3D classiﬁcation and segmentation,’’ in Proc.\nIEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jan. 2017, pp. 77–85.\n[66] Vicon. Accessed: Aug. 15, 2019. [Online]. Available: http://www.vicon.\ncom\n[67] NGIMU Sensor Board. Accessed: Apr. 15, 2019. [Online]. Available:\nhttp://x-io.co.uk/ngimu/\nQU WANG received the B.S. degree from\nthe School of Software Engineering, Beijing\nUniversity of Posts and Telecommunication,\nChina, in 2013, and the M.S. degree from the Uni-\nversity of Chinese Academy of Sciences, Beijing,\nChina, in 2016. He is currently pursuing the\nPh.D. degree with the School of Information and\nCommunication Engineering, Beijing University\nof Posts and Telecommunications. His current\nmain interests include location-based services,\npervasive computing, computer vision, and machine learning.\nVOLUME 7, 2019 162321\nQ. Wanget al.: Pedestrian Heading Estimation Based on STNs and Hierarchical LSTM\nHAIYONG LUO received the B.S. degree from\nthe Department of Electronics and Information\nEngineering, Huazhong University of Science and\nTechnology, Wuhan, China, in 1989, the M.S.\ndegree from the School of Information and Com-\nmunication Engineering, Beijing University of\nPosts and Telecommunication, China, in 2002, and\nthe Ph.D. degree in computer science from the\nUniversity of Chines Academy of Sciences, Bei-\njing, China, in 2008. He is currently an Associate\nProfessor with the Institute of Computer Technology Chinese Academy of\nScience, China. His main research interests include location-based services,\npervasive computing, mobile computing, and the Internet of Things.\nLANGLANG YE received the B.S. degree from\nthe School of Basic Medical Science, Zhejiang\nUniversity, in 2016. He is currently pursuing the\nM.S. degree in computer technology with the Uni-\nversity of Chinese Academy of Sciences. His main\nresearch interests include location-based services,\ndata mining, and deep learning.\nAIDONG MEN received the B.S., M.S., and\nPh.D. degrees from the Department of Radio Engi-\nneering, Beijing University of Posts and Telecom-\nmunications, Beijing, in 1994. From 1994 to 2000,\nhe was an Associate Professor with the Depart-\nment of Radio Engineering, Beijing University\nof Posts and Telecommunications. Since 2000,\nhe has been a Professor with Telecom Engineering\nCollege, Beijing University of Posts and Telecom-\nmunications. He has published over 100 articles in\njournals and international conference. His research interests include multi-\nmedia communication, digital TV , images and speech signal processing and\ntransmission, and so on. He is a Fellow of the Chinese Institute of Electronics\nand China Institute of Communications. He is also an Invited Fellow of the\nScience and Technology Committee of State Administration of Radio, Film,\nand Television.\nFANG ZHAO received the B.S. degree from the\nSchool of Computer Science and Technology,\nHuazhong University of Science and Technol-\nogy, Wuhan, China, in 1990, and the M.S. and\nPh.D. degrees in computer science and technology\nfrom the Beijing University of Posts and Telecom-\nmunications, Beijing, China, in 2004 and 2009,\nrespectively. She is currently a Professor with the\nSchool of Software Engineering, Beijing Univer-\nsity of Posts and Telecommunication. Her research\ninterests include mobile computing, location-based services, and computer\nnetworks.\nYAN HUANG received the B.S. degree from\nGuangxi Normal University, in 2013, and the M.S.\ndegree from the Institute of Software, Chinese\nAcademy of Sciences, Beijing, China, in 2017.\nShe is currently pursuing the Ph.D. degree with\nPeking University, China. Her current main inter-\nests include location-based services, optical-based\nlocation and communication, computer vision, and\nmachine learning.\nCHANGHAI OU was born in Tongren, Guizhou,\nChina, in 1989. He received the bachelor’s degree\nin computer science and technology from the\nSchool of Computer and Information Technol-\nogy, Beijing Jiaotong University, China, in 2013,\nand the Ph.D. degree in cyber security from\nthe Institute of Information Engineering, Chinese\nAcademy of Sciences (i.e., School of Cyber Secu-\nrity, University of Chinese Academy of Sciences),\nin July 2018. He is currently a Research Fellow\nwith the Hardware & Embedded Systems Laboratory (HESL), School of\nComputer Science and Engineering, Nanyang Technological University,\nSingapore. His current research interests include cryptographic hardware\nand embedded system security, side channel attacks, machine learning, and\nprivacy preserving.\n162322 VOLUME 7, 2019",
  "topic": "Heading (navigation)",
  "concepts": [
    {
      "name": "Heading (navigation)",
      "score": 0.8933215141296387
    },
    {
      "name": "Computer science",
      "score": 0.8028923273086548
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6731744408607483
    },
    {
      "name": "Computer vision",
      "score": 0.5852421522140503
    },
    {
      "name": "Dead reckoning",
      "score": 0.521891176700592
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.49756577610969543
    },
    {
      "name": "Pedestrian",
      "score": 0.46853819489479065
    },
    {
      "name": "Leverage (statistics)",
      "score": 0.46129071712493896
    },
    {
      "name": "Global Positioning System",
      "score": 0.1690060794353485
    },
    {
      "name": "Telecommunications",
      "score": 0.11579129099845886
    },
    {
      "name": "Engineering",
      "score": 0.08080524206161499
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Aerospace engineering",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Transport engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I139759216",
      "name": "Beijing University of Posts and Telecommunications",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210090176",
      "name": "Institute of Computing Technology",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I4210165038",
      "name": "University of Chinese Academy of Sciences",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I20231570",
      "name": "Peking University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    }
  ]
}