{
  "title": "Eggsplorer: a rapid plant–insect resistance determination tool using an automated whitefly egg quantification algorithm",
  "url": "https://openalex.org/W4377136734",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5083706899",
      "name": "Micha Gracianna Devi",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5085496502",
      "name": "Dan Jeric Arcega Rustia",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5053644050",
      "name": "Lize Braat",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5091983358",
      "name": "Kas Swinkels",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5113159729",
      "name": "Federico Fornaguera Espinosa",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5060426421",
      "name": "Bart M. van Marrewijk",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5057318634",
      "name": "J. Hemming",
      "affiliations": [
        "Wageningen University & Research"
      ]
    },
    {
      "id": "https://openalex.org/A5005810075",
      "name": "Lotte Caarls",
      "affiliations": [
        "Wageningen University & Research"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2807169760",
    "https://openalex.org/W2799323234",
    "https://openalex.org/W1995552536",
    "https://openalex.org/W2331952361",
    "https://openalex.org/W3036963153",
    "https://openalex.org/W3033617930",
    "https://openalex.org/W2082665344",
    "https://openalex.org/W2943957125",
    "https://openalex.org/W2113003545",
    "https://openalex.org/W2550606576",
    "https://openalex.org/W3047433976",
    "https://openalex.org/W4285107929",
    "https://openalex.org/W2009360690",
    "https://openalex.org/W2252871478",
    "https://openalex.org/W1602936558",
    "https://openalex.org/W2981211097",
    "https://openalex.org/W1983727995",
    "https://openalex.org/W2072244555",
    "https://openalex.org/W2612651926",
    "https://openalex.org/W2186569047",
    "https://openalex.org/W2144988920",
    "https://openalex.org/W2466017276",
    "https://openalex.org/W2070112895",
    "https://openalex.org/W2007657812",
    "https://openalex.org/W3109806460",
    "https://openalex.org/W3131929053",
    "https://openalex.org/W2102998355",
    "https://openalex.org/W3082115252",
    "https://openalex.org/W2804081731",
    "https://openalex.org/W2313127812",
    "https://openalex.org/W2203031418",
    "https://openalex.org/W2901349686",
    "https://openalex.org/W2017738410",
    "https://openalex.org/W2338154137",
    "https://openalex.org/W4210985634",
    "https://openalex.org/W3173326012"
  ],
  "abstract": null,
  "full_text": "Devi et al. Plant Methods           (2023) 19:49  \nhttps://doi.org/10.1186/s13007-023-01027-9\nMETHODOLOGY Open Access\n© The Author(s) 2023. Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which \npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the \noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or \nother third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory \nregulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this \nlicence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecom-\nmons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.\nPlant Methods\nEggsplorer: a rapid plant–insect resistance \ndetermination tool using an automated whitefly \negg quantification algorithm\nMicha Gracianna Devi1*, Dan Jeric Arcega Rustia2, Lize Braat1, Kas Swinkels1, Federico Fornaguera Espinosa1, \nBart M. van Marrewijk2, Jochen Hemming2 and Lotte Caarls1 \nAbstract \nBackground A well-known method for evaluating plant resistance to insects is by measuring insect reproduction \nor oviposition. Whiteflies are vectors of economically important viral diseases and are, therefore, widely studied. In \na common experiment, whiteflies are placed on plants using clip-on-cages, where they can lay hundreds of eggs \non susceptible plants in a few days. When quantifying whitefly eggs, most researchers perform manual eye meas-\nurements using a stereomicroscope. Compared to other insect eggs, whitefly eggs are many and very tiny, usually \n0.2 mm in length and 0.08 mm in width; therefore, this process takes a lot of time and effort with and without prior \nexpert knowledge. Plant insect resistance experiments require multiple replicates from different plant accessions; \ntherefore, an automated and rapid method for quantifying insect eggs can save time and human resources.\nResults In this work, a novel automated tool for fast quantification of whitefly eggs is presented to accelerate the \ndetermination of plant insect resistance and susceptibility. Leaf images with whitefly eggs were collected from a com-\nmercial microscope and a custom-built imaging system. A deep learning-based object detection model was trained \nusing the collected images. The model was incorporated into an automated whitefly egg quantification algorithm, \ndeployed in a web-based application called Eggsplorer. Upon evaluation on a testing dataset, the algorithm was able \nto achieve a counting accuracy as high as 0.94, r2 of 0.99, and a counting error of ± 3 eggs relative to the actual num-\nber of eggs counted by eye. The automatically collected counting results were used to determine the resistance and \nsusceptibility of several plant accessions and were found to yield significantly comparable results as when using the \nmanually collected counts for analysis.\nConclusion This is the first work that presents a comprehensive step-by-step method for fast determination of plant \ninsect resistance and susceptibility with the assistance of an automated quantification tool.\nKeywords Insect egg quantification, Rapid phenotyping, Whitefly, Deep learning, Plant insect resistance, Bioassay\nBackground\nWhiteflies are insects classified in the Aleyrodidae family \nand consist of more than 1500 species [21]. Their pres -\nence is sufficient to cause serious crop yield loss, e.g., \ndamage by Bemisia tabaci (Gennadius, 1889), a very \ninvasive whitefly species. It takes approximately 20 days \nduring warm weather conditions for a whitefly to develop \nfrom an egg to a crawler, through to pupae, and finally \nan adult. Female whiteflies originate from fertilized eggs, \n*Correspondence:\nMicha Gracianna Devi\nmicha.devi@wur.nl\n1 Plant Breeding, Wageningen University & Research, Po Box 384, 6700 \nAJ Wageningen, The Netherlands\n2 Greenhouse Horticulture and Flower Bulbs, Wageningen Plant \nResearch, Wageningen University & Research, 6708 PB Wageningen, The \nNetherlands\nPage 2 of 14Devi et al. Plant Methods           (2023) 19:49 \nwhile males originate from unfertilized eggs; the typi -\ncal sex ratio is 2:1, females to males [33]. Whiteflies are \nphloem feeders, which means they use their four inter -\nlocked stylets to enclose food and a salivary canal allow -\ning independent movements between plant mesophyll \ncells [27]. While feeding, they secrete saliva as a lubri -\ncant during the penetration of the stylets, which contain \nenzymes and metabolites, thereby providing protection \nagainst plant wound response [13]. Furthermore, white -\nflies indirectly cause damage to plants by acting as a vec -\ntor of viruses, including more than 100 plant viruses, \nsuch as those in the Begomovirus genus, which causes \ntomato yellow leaf curl virus, and viruses in the Crini -\nvirus genus, which causes tomato chlorosis virus [17]. \nWhiteflies are predominantly polyphagous, e.g., B. tabaci \nhas a wide host range such as tomato, cucumber, cotton, \nand sweet potato [30]. The two most dominant B. tabaci \nbiotypes are Middle East-Minor Asia 1 (MEAM1 or bio -\ntype B) and Mediterranean (MED or biotype Q) genetic \ngroups. These two biotypes have caused serious yield \nlosses in more than 60 countries [23] with annual losses \nof more than one billion dollars [15].\nResearch works on finding whitefly resistance, espe -\ncially involving wild Solanaceae accessions, have yielded \nQuantitative Trait Loci (QTL) for adult survival and \noviposition [2, 10, 20, 29, 34, 36]. The most common \nmethods employed to test whitefly host compatibility \nin greenhouse and laboratory settings are choice and \nno-choice assays [35]. Choice assays allow whiteflies to \nchoose between several plant genotypes to assess white -\nfly preference, while no-choice assays limit whiteflies \nto feed on a single plant to evaluate response. A choice \nassay can be prepared using a Y-tube olfactometer setup \nfor whole plants or leaves, which evaluates relative pref -\nerence based on volatile compounds as well as other \nphenotypic characteristics such as insect mortality and \noviposition [16]. On the other hand, a no-choice assay \ncan be performed by using clip-on cages on leaves [3].\nTwo of the most important observation parameters \nobtained from both choice and no-choice assays are \nadult insect survival and oviposition rate. Oftentimes, \nthe quantification of adult survival and oviposition are \nmanually done by looking through a stereomicroscope \n[38]. Counting adult survival in a clip-cage setting is \nquick but counting the number of eggs deposited by \nthe insects on each leaf is very laborious. Each whitefly \negg is approximately 0.2 mm in length and 0.08 mm in \nwidth while its color ranges from translucent green to \nbrown, depending on maturity. On a susceptible potato \nline, 5 female whiteflies, inside a 2  cm diameter clip-\ncage, can lay more than 100 eggs in 5  days [25]. In a \nnatural setting, whiteflies deposit eggs at the abaxial of \nthe leaves, thereby hiding each egg from predators and \nenvironmental factors such as precipitation and high-\nintensity ultraviolet light [26]. Moreover, some leaves \nhave thick veins, trichomes, and surface unevenness \nthat may conceal eggs and hinder observation. Further -\nmore, whitefly eggs are commonly found in leaf regions \nsurrounded by whitefly honeydew, which hinders \nobservation [37]. Whitefly honeydew provides optimal \nconditions for mold to grow and as protection for the \ndevelopment of whitefly eggs to instars [8 ]. Due to the \naforementioned factors, researchers would benefit from \na more reliable and systematic protocol for analyzing \nwhitefly assay samples.\nTo assure the reliability of performed assays, micro -\nscopic images are stored for further analysis. One of the \nways to analyze microscopic images is by digital image \nprocessing. Digital image processing is a computer -\nized method for automatically identifying and detect -\ning characteristics of objects in an image by performing \noperations such as color conversion, edge detection, \ncolor segmentation, and blob analysis. Digital image \nprocessing has been employed in microscopic image \nanalysis such as for mosquito egg counting [11, 19], \nand beetle egg counting [12]. In the works mentioned, \nit involves a user that specifies algorithm parameters to \noptimize the image analysis results; therefore, consid -\nering it as a semi-automated approach. Unlike digital \nimage processing-based algorithms, a deep learning-\nbased algorithm is more resistant to variations in image \nappearance and requires less input from a user. Deep \nlearning is a subset of artificial intelligence that aims \nto train a neural network model to learn feature hier -\narchies from a given dataset. Deep learning models are \ncapable of accurately detecting minute objects, such as \ninsect eggs, even without manually tuning algorithm \nparameters. Deep learning has been used in micro -\nscopic image analysis for counting nematodes [1 , 18], \nstomata [9 ], and protozoan parasites [39].\nThis work aims to develop a novel and more efficient \nprotocol for automated whitefly egg quantification to \naccelerate the determination of insect-resistant and \nsusceptible plant accessions. The specific objectives \nare: (1) the development of a fast and accurate white -\nfly egg quantification algorithm; (2) designing a web-\nbased platform to deploy the algorithm; (3) assessing \nthe advantages and disadvantages of using different \nimaging setups for collecting leaf image assays; and (4) \ndetermining plant–insect resistance and susceptibility \nbased on the automatically obtained egg counts. This \nwork proves the benefits of employing novel computer \ntechniques to achieve more objective research results \nin the field of plant–insect resistance.\nPage 3 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \nMaterials and method\nPlant materials and growth conditions\nWild (Solanum berthaultii (Hawkes, 1963)—BER481-\n3) and cultivated (S. tuberosum cv. RH89-039-16) pota -\ntoes were obtained from the Wageningen University and \nResearch (WUR) Plant Breeding collection, Wagenin -\ngen, The Netherlands. For collecting leaf images, in vitro \npropagated cuttings were grown for 2  weeks in MS20 \nmedium, and successively transferred to the greenhouse \nin ⌀14  cm pots with potted soil for 3  weeks before the \nwhitefly infection assays. Resistant wild tomato plants \n(S. habrochaites (Knapp & Spooner, 1999)—LA1777) \nand susceptible cultivated tomato plants (S. lycopersi -\ncum cv. Moneymaker) were also used in this study. Seeds \nwere obtained from WUR Plant Breeding Department, \nWageningen, The Netherlands. Seeds were sown on ger -\nmination media for 2  weeks before being transplanted \ninto ⌀14  cm pots with potting soil for 3  weeks before \nthe whitefly infestation assays were commenced. The \nplants were grown in peat soil in an insect-proof green -\nhouse at Unifarm with a 16 h light and 8 h dark photo -\nperiod, 21 °C/19 °C (day/night) and 70% relative humidity \nfrom September–October 2022 in Wageningen, The \nNetherlands.\nWhitefly assay\nWhitefly assays were conducted on 5-week-old plants; \n3 plants per genotype. Non-viruliferous whiteflies (B. \ntabaci group Mediterranean-Middle East-Asia Minor \nI), reared on S. lycopersicum cv. Forticia from the WUR \nPlant Breeding Department were used for screening. \nNo-choice assays were carried out in an insect green -\nhouse of WUR. The assay was done by attaching two clip-\non-cages ⌀2  cm containing five synchronized 1-day-old \nfemale B. tabaci whiteflies on the abaxial side of the sec -\nond and third fully expanded leaf of each plant. Five days \nlater, the leaves attached with clip-cages were harvested \nfor image acquisition, egg quantification (OR) and adult \nsurvival (AS) on the same day. Leaves can optionally be \nstored on wet filter paper and in 4 °C to maintain cell tur-\ngidity and prevent dehydration. AS and OR for tomato \nplants [20] were calculated according to the following \nequations, respectively:\nArcsine transformation was used to normalize AS, \nwhereas square root transformation was used for ovipo -\nsition rate. Statistical analyses via t-tests were performed \nusing Python 3.8.13, with the support of SciPy scientific \ncomputing library v1.9.3.\nLeaf image acquisition\nThe leaf image samples used in the whitefly assay were \nacquired using two different imaging setups: (1) using a \ncommercial microscope (VHX-7000) (Keyence, Japan), \nand 2) using AutoEnto device, as shown in Fig.  1. The \nVHX-7000 is a 4K digital microscope designed for surface \n(1)AS =\n(alive whiteﬂies\ntotal whiteﬂies\n)\nsurvival for5 days ,\n(2)\nOR = 2 × number of eggs\nalive whiteﬂies+ total whiteﬂieseggs female−1 for5 days.\nFig. 1 Workflow for rapid determination of plant resistance based on insect oviposition\nPage 4 of 14Devi et al. Plant Methods           (2023) 19:49 \nFig. 2 Automated egg quantification algorithm\nPage 5 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \nmicroscopy. It acquires high resolution leaf images by \nacquiring tiled images based on box vertices that were \nmanually selected using its accompanying controller. \nThe tiled images were automatically stitched together by \nits software. The VHX-7000 was electronically adjusted \nto set a 45–50 mm distance from the lens to the camera \nwhile the magnification was set to 30×. The automatic \nwhite balance and brightness were manually adjusted and \nkept uniform throughout the trials.\nMeanwhile, the AutoEnto device is an imaging system \ndeveloped by the Greenhouse Horticulture & Flower \nbulbs Business Unit of Wageningen Plant Research in \nBleiswijk, The Netherlands. It is designed to rapidly \nacquire images of tiny biological samples such as insects, \ninsect eggs, nematodes, and alike. It is equipped with an \nindustrial CMOS color camera (IDS Imaging Develop -\nment Systems GmbH, Germany), replaceable C-mount \nlenses, and a custom x–y table that can hold up to 9 \ndishes, for automated image acquisition and analysis. \nIn this work, it was configured with a 30× magnifica -\ntion C-mount lens (Kowa Company, Japan), acquiring \n4912 × 3684 pixels per image with a spatial resolution of \n350 pixel/mm. In this research, it was configured to take \n35 images with 4912 × 3684 pixels over a 5 × 7 grid that \nwere stitched together into a single image. The AutoEnto \ndevice was only used for image acquisition but not for \nimage analysis.\nAutomatic egg quantification algorithm\nThe acquired leaf images were analyzed using an auto -\nmatic egg quantification algorithm, as illustrated in \nFig.  2. The egg quantification algorithm was developed \nusing Python 3.8.3 programming language, with the sup -\nport of OpenCV image processing library [5], PyTorch \ndeep learning library [24] and MLFlow machine learning \ntracking library [6]. All computations were performed \nusing a desktop computer running under Ubuntu 22.04 \noperating system, with an Intel Xeon E5-1650 processor, \nNVIDIA GeForce GTX Titan X GPU, and 16 GB RAM. \nThis section discusses the methods and theoretical con -\nsiderations in developing the algorithm.\nDataset preparation and image pre‑processing\nA leaf image dataset was prepared using the image pre-\nprocessing step of the algorithm. First, the size of the leaf \nimage is reduced from L × W to L − SL × W − SW based on \na pre-defined tiling size, where L and W are the length \nand width of the leaf image while S L and S W are the sur -\nplus length pixels and surplus width pixels, respectively; \nthis was done by equally removing the pixels from all \nsides of the leaf image. Removal of the surplus pixels was \ndone to attain an equal tiling size. In this work, a tiling \nsize of 1400 × 1400 pixels was used on images obtained \nfrom both setups, with a padding of 100 pixels on all \nsides of the tiled leaf image. Tiling is a technique in deep \nlearning which cuts an image into several equal parts \nto achieve better object detection results [28]. On the \nother hand, the padding allows the merging of duplicate \negg detections after obtaining the detection results from \neach tiled leaf image later. The tiling process produces \nn 1600 × 1600 tiled leaf images that are used as individ -\nual inputs to the deep learning-based object detection \nmodel. Every egg on each tiled leaf image was annotated \nusing a rectangular box via Darwin v7 image annota -\ntion platform with the assistance of experts. The statisti -\ncal summary of the prepared image dataset is shown in \nTable 1.\nObject detection and image stitching\nThe automated egg quantification algorithm uses a \nYOLOv5m (Ultralytics, Los Angeles, CA, USA) deep \nlearning model for detecting the eggs from each tiled \nleaf image. YOLOv5m is an object detection model with \nthree components: backbone, neck, and head. It uses \nTable 1 Image dataset statistical information\nDevice Dataset Size (pixels) Total Training Validation Testing\nCommercial microscope \n(VHX-7000)\nComplete image Min.: 5258 × 6660\nAve.: 7556 × 8188\nMax.: 9287 × 10,399\n144 – – 30\nTiled image 1600 × 1600 765 35% of total 15% of total –\nWhitefly egg Min.: 27 × 29\nAve.: 45 × 51\nMax.: 69 × 70\n– – – –\nAutoEnto Complete image 24,560 × 25,788 22 – – 30\nTiled image 1600 × 1600 413 35% of total 15% of total\nWhitefly egg Min.: 22 × 26\nAve.: 40 × 44\nMax.: 78 × 88\n– – – –\nPage 6 of 14Devi et al. Plant Methods           (2023) 19:49 \ncross-stage partial networks as the backbone for feature \nextraction while the neck, made of path aggregation net -\nworks, combines the extracted features. The combined \nfeatures are used as input to a YOLO layer, which acts \nas the model’s head, for obtaining bounding box pre -\ndictions. In this work, the YOLOv5m was specifically \nchosen since it has a good balance of speed and perfor -\nmance compared to the other YOLOv5 variants. The \nYOLOv5m model’s input was set to the default 614 × 614 \npixels, thereby resizing each 1600 × 1600 tiled image to \n614 × 614 pixels for inference. The YOLOv5m model’s \noutput was defined to have a single image class, egg  class. \nAfter detecting the eggs from each tiled leaf image, the \nleaf image was stitched back together while retranslating \nthe bounding box coordinates according to the original \nleaf image size.\nDetection post‑processing\nThree detection post-processing methods were applied \nto reduce the algorithm errors: detection merging, object \nsize filtering, and confidence thresholding. In detection \nmerging, similar objects found in adjacent tiled images \nwere merged using Intersection-over-Union (IoU ). IoU \nis a measure of the overlap between two objects in an \nimage. IoU values closer to 1 indicate higher overlap and \n0 otherwise. IoU was computed using Eq. 3:\nwhere Bo is the bounding box coordinates of each \ndetected object, with o as the object index. B o includes \nfour coordinates: x1, y1, x2, and y2, where x1 and y1 belong \nto the object’s x and y vertex box coordinates, and x 2 and \ny2 belong to the vertex opposite to x 1 and y1. If the IoU of \ntwo or more egg detection boxes is greater than 0.5, the \nboxes are merged by retaining the lowest x 1 and y 1 and \nhighest x2 and y2 and counting the overlapping objects as \na single object.\nThe object size filtering threshold was manually deter -\nmined using the average size of each detected object based \non Table 1. If the length or width of a detected object is less \nthan 20 pixels, then the detected object was ignored. Such \ndetected objects are trichomes and leaf spots that resemble \nthe appearance of whitefly eggs. If the length or width of a \ndetected object is more than 90 pixels, then the detected \n(3)IoU = area(B1 ∩ B2 ∩ ... Bo)\narea(B1 ∪ B2 ∪ ... Bo) ,\nFig. 3 Automated egg quantification algorithm confidence threshold optimization results\nPage 7 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \nobject was also ignored since such objects may include \nnymphs or other unwanted objects.\nConfidence thresholding utilizes the confidence score \nof each detection, which ranges from 0 to 1.0, where val -\nues closer to 1.0 indicate higher confidence. To ignore \ndetected objects with low confidence scores, a pre-set \nclassification confidence threshold was defined and fine-\ntuned. Some of the detected objects with low confidence \nscores include trichomes and leaf spots.\nAlgorithm evaluation\nThe algorithm was evaluated using two methods: object-\nlevel testing and image level testing, with the test data -\nset defined in Table 1. In this context, object-level testing \nrefers to how the model performs when tested on each \nobject of all the leaf images. On the other hand, image-\nlevel testing refers to the overall algorithm performance \nwhen tested on individual leaf images. In object-level \ntesting, the algorithm performance was evaluated by \nautomatically matching each set of ground truth box \ncoordinates with each predicted box coordinates via IoU . \nIf the calculated IoU between two paired coordinates was \nhigher than 0.5, it was counted as a true positive (TP) \ndetection. All unmatched ground truth box coordinates \nwere considered as missed detections. Using the above \ndefinitions, the following metrics were calculated:\n(4)\nPrecision= TP\ntotal number of detected egg objects ,\n(5)Recall= TP\ntrue number of egg objects ,\nF1-score is a performance metric that balances preci -\nsion and recall; it ranges from 0 to 1, where values closer \nto 1 indicate better performance. Meanwhile, the miss \nrate measures how many detections were undetected by \nthe algorithm; it ranges from 0 to 1, where values closer \nto 1 indicate worse performance.\nIn image-level testing, counting accuracy, miss rate, \nand coefficient of determination (r 2) were measured. \nCounting accuracy was measured by obtaining the per -\ncent difference between the true counts (TC) and the \nautomatic counts (AC) per leaf image, as follows:\nMeanwhile, the miss rate is the ratio of missed detec -\ntions and the true number of egg objects in a leaf image, \ncomputed as follows:\nFinally, r2 measures the performance of the model rela -\ntive to the manual counts.\nResults and discussion\nModel training and algorithm optimization results\nIn order to optimize the process of training the YOLOv5 \nmodel, hyperparameter tuning using genetic algo -\nrithm was applied [14]. Hyperparameter tuning aims to \n(6)F1 score = 2 · precision·recall\nprecision+ recall.\n(7)Counting accuracy = TC − AC\nTC .\n(8)\nMiss rate = missed detections in a leaf image\ntrue number of egg objects in a leaf image .\nFig. 4 Predicted number of whitefly eggs vs. true number of whitefly eggs r2 scatter plots obtained using different imaging setups: a Commercial \nmicroscope; and b AutoEnto\nPage 8 of 14Devi et al. Plant Methods           (2023) 19:49 \nFig. 5 Sample automated egg quantification results using different imaging setups: a commercial microscope; and b AutoEnto device\nPage 9 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \nmaximize model performance by finding the best train -\ning parameters such as for learning rate, momentum, box \nloss gain, and more. In so doing, the default YOLOv5m \ntraining hyperparameters were changed including learn -\ning rate from 0.003 to 0.01, momentum from 0.8 to 0.93, \nand box loss gain from 0.03 to 0.06. Training was done \nfor 100 epochs and a batch size of 16, achieving a mean \naverage precision of 0.96. Threshold optimization was \ndone by fine-tuning the values of the confidence thresh -\nold from 0.3 to 0.7, with increments of 0.05. The results \nof threshold optimization for the two imaging setups are \nshown in Fig. 3.\nIn object level testing, the F 1-score of the model can \nreach as high as 0.935 on images obtained using the com-\nmercial microscope and 0.91 on images obtained using \nthe AutoEnto when using a confidence threshold of 0.6 \n(Fig. 3a). A slight difference in performance was expected \nsince the commercial microscope can acquire sharper \nimages than the AutoEnto. Nevertheless, both results \nshow that the model detected the whitefly eggs with high \naccuracy and confidence. In image level testing, it was \nfound that miss rates of the algorithm were 0.06 and 0.14 \nwhen processing the leaf images obtained by the com -\nmercial microscope and the AutoEnto, respectively, with \na confidence threshold of 0.6 (Fig.  3b). The miss rate was \nhigher using the AutoEnto since there were some parts \nof the leaf images that were blurred due to curling, while \nthe commercial microscope can resolve this problem \nthrough its depth correction feature. Finally, the count -\ning accuracies of the algorithm was about 0.94 when pro -\ncessing the commercial microscope leaf images and using \na confidence threshold of 0.6 but had a lower count -\ning accuracy of 0.88 when processing the AutoEnto leaf \nimages (Fig.  3c). Based on the tuning results, an optimal \nconfidence threshold of 0.6 was found and used through -\nout this research. It can be concluded that the trained \nmodel was reliable for both imaging setups, but improve -\nments can still be made to enhance algorithm perfor -\nmance on images acquired using the AutoEnto.\nAlgorithm testing\nThe true number of eggs and predicted number of eggs \nwere compared as shown in Fig.  4. It can be immediately \nseen that the predicted number of eggs from the com -\nmercial microscope images were remarkably close to the \ntrue number of eggs, with an error of ± 3 eggs relative to \nthe actual number of eggs counted by eye, even for high \nnumber of whitefly eggs (> 200 eggs). On the other hand, \nthe algorithm still performed well with minor issues \nwhen analyzing the AutoEnto leaf images, with an error \nof ± 10 eggs. As mentioned previously, this was mainly \ncaused by blurred spots which cause missed whitefly egg \ndetections. In summary, this shows that the algorithm is \nusable in both imaging setups and can accurately esti -\nmate the number of whitefly eggs in each leaf.\nFig. 6 Sample errors obtained by the automated egg quantification algorithm\nPage 10 of 14Devi et al. Plant Methods           (2023) 19:49 \nThe quality of detections was also visually evaluated, as \nshown in Fig. 5. It can be noticed that most whitefly eggs \ncan be easily detected by the algorithm, with high con -\nfidence scores of about 0.9 (Fig.  5a). The algorithm also \nperformed well on the AutoEnto leaf images even though \nthe lighting and white balance was slightly different from \nthe settings of the commercial microscope (Fig.  5b). This \nindicates that the algorithm is very adaptive to changes in \nimaging conditions.\nFig. 7 Plant–insect resistance and susceptibility analysis: a normalized adult survival rate; b normalized oviposition rate measured using the \nprocessed VHX7000 images; and c normalized oviposition rate measured using the processed AutoEnto images\nPage 11 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \nSome of the errors obtained by the algorithm are shown \nin Fig. 6. As seen from the upper right of Fig.  6b, a white-\nfly egg was not successfully detected since it was slightly \ncovered by a strand of trichome. Meanwhile, some plant \nmaterial was falsely detected as an egg in the middle of \nFig. 6b, while a trichome cuticle was also falsely detected \nTable 2 Whitefly assay result for female survival and oviposition\nSpecies Accession Clip cage 1 Clip cage 2\nAlive \nwhiteflies\nDead \nwhiteflies\nWhitefly eggs Alive \nwhiteflies\nDead \nwhiteflies\nWhitefly eggs\nVHX7000 AutoEnto VHX7000 AutoEnto\nS. habrochaites LA1777 0 5 0 0 0 5 0 0\nLA1777 1 4 34 37 0 5 14 0\nLA1777 0 5 38 38 1 4 0 0\nS. lycopersicum Moneymaker 5 0 128 171 5 0 102 77\nMoneymaker 3 0 119 91 5 0 195 149\nMoneymaker 4 0 220 59 5 0 220 227\nS. tuberosum RH89-039-16 3 1 134 113 5 0 210 194\nRH89-039-16 3 1 140 119 4 1 207 194\nRH89-039-16 5 0 157 108 4 0 58 43\nS. berthaultii BER481-3 0 5 52 33 0 5 0 0\nBER481-3 0 5 0 0 0 5 0 0\nBER481-3 0 5 0 0 2 2 0 0\nFig. 8 Sample leaf images taken from each accession: a S. lycopersicum cv. Moneymaker; b S. habrochaites LA1777; c S. tuberosum cv. RH89-039-16; \nand d S. berthaultii BER481-3, showing oviposition\nPage 12 of 14Devi et al. Plant Methods           (2023) 19:49 \nat the bottom of Fig.  6b. In the future, these errors can \nbe minimized by collecting more training images, most \nespecially of different egg colors and trichome densities, \nand possibly devising other post-processing strategies.\nDetermination of insect plant resistance and susceptibility\nThe plant–insect resistance analysis results are shown in \nFig. 7 and Table 2, while sample leaf images of each acces-\nsion are shown in Fig. 8. In this experiment, BER481-3 (S. \nberthaultii) and LA1777 (S. habrochaites) were selected \nas accessions that are highly resistant to B. tabaci and \nTrialeurodes vaporariorum [4, 22], BER481-3 is a newly \nreported S. berthaultii accession that is resistant to \nwhitefly. Meanwhile, the cultivated tomato Moneymaker \nand potato RH89-039-16 accessions are known suscepti -\nble genotypes, not only for insect resistance [7, 40]. Based \non statistical analysis, both Moneymaker (p < 0.001, n = 3) \nand RH89-039-16 (p < 0.05, n = 3) showed significantly \nhigher adult survival (Fig.  7a) and oviposition (p < 0.05, \nn = 3) (Fig.  7b) compared to the resistant accessions. \nGenerally, Moneymaker and RH89-039-16 had higher \noviposition on the abaxial surface of the leaf compared \nto the wild accessions, as can be observed in Fig.  8a, c, \nrespectively.\nImaging device evaluation\nOne of the goals of this research was to determine which \nimaging devices are suitable for quantifying whitefly eggs \non leaf samples. The results in Fig.  7c show that, despite \nthe number of false positives/negatives of eggs counted \ndue to the differences in leaf surface morphology (e.g., \ncolor and trichome composition), the statistical conclu -\nsions that can be drawn from both imaging devices were \nsimilar. The VHX7000 microscope is the most recent \nhigh-end version of electronic stereomicroscope from the \nVHX Keyence line. Up to date, researchers use this line \nof microscope to capture fast high-resolution z-stacked \nstitched images from plant cells to insects [31, 32]. In \nthis research, the acquisition of each leaf sample using \nthe VHX7000 takes about 2  min. On the other hand, \nAutoEnto costs approximately €5000 and it can take an \nimage of a leaf sample in a dish in about 2 min, but it can \nbe programmed to acquire 9 dishes at a time. Addition -\nally, the accompanying computer of the AutoEnto may be \nprogrammed to upload images and record whitefly egg \ncounts automatically. In this research, it was found that \nimage quality was a disadvantage of the AutoEnto, but it \ncan be used for faster image acquisition. Nevertheless, \nAutoEnto serves as a budget-friendlier customized device \nalternative but VHX7000 can acquire sharper images.\nWeb application deployment\nThe automated egg quantification algorithm was \ndeployed in a web application that we named Eggsplorer. \nEggsplorer was written using Python, JavaScript, and \nHTML programming languages, with the support of \nFlask micro web framework. A screenshot of the web \napplication is shown in Fig.  9. As shown, the user can \ndrag and drop images to the web application for upload -\ning. The user can also configure the classification confi -\ndence threshold if unwanted detections are to be ignored. \nOnce all leaf images are uploaded, each leaf image is \nprocessed on the server. The detection results are shown \nin the web application. Finally, the counting results can \nbe downloaded as a.xlsx file while the processed images \ncan be downloaded as a.zip file. Currently, the web \nFig. 9 Screenshot of the Eggsplorer web application\nPage 13 of 14\nDevi et al. Plant Methods           (2023) 19:49 \n \napplication can only be accessed in the WUR intranet but \nmay also be opened to interested researchers.\nConclusion\nA novel method for determining plant–insect resistance \nand susceptibility, with the assistance of an automated \negg quantification tool, is presented in this work. The \nresults show that the automated quantification tool could \ncount whitefly eggs obtained from two different imaging \nsetups. Algorithm testing results showed that the quan -\ntification tool can be used on images generated from \nvarious microscopes. Users of other microscopes can \nsimply upload their own images in the web application \nand quantify the whitefly eggs found in their leaf samples. \nAlternatively, a custom-built imaging setup, such as the \nAutoEnto, can also be used for faster image acquisition \nand sampling.\nThe procedures presented herein can be a reference to \nother researchers for determining plant–insect resistance \nand susceptibility in a quantitative and practical man -\nner. In the future, images from other leaves may also be \nobtained to train new models and make the web-based \napplication more versatile. This can be done by incorpo -\nrating images of other insect eggs such as mites, thrips, \nand other harmful insect pests, to build a universal plat -\nform for determining plant–insect resistance.\nAbbreviations\nAC  Automatic counts\nAS  Adult survival\nIoU  Intersection-over-Union\nOR  Oviposition rate\nTC  True counts\nTP  True positive\nAcknowledgements\nThe authors would like to express their gratitude to Fien Meijer-Dekens and \nIsolde Bertram, from Plant Breeding WUR, for maintaining the collection and \nproviding the tomato seeds and potato clones. The information on the resist-\nance of S. berthaultii (BER481-3) wild potato species was obtained within the \nHolland Innovative Potato project. The authors would also like to thank Ger-\nben Messelink and Hessel van der Heide, from the Entomology Group of the \nWUR Greenhouse Horticulture and Flower Bulbs Business Unit, for maintaining \nand operating the AutoEnto device. The authors would like to thank Richard \nVisser and Jack Vossen from the Plant Breeding Department, WUR for review-\ning this article before submission.\nAuthor contributions\nMGD: conceptualization, image collection, methodology proposed and \ndeveloping, supervision, writing original draft, writing—review and editing of \ndraft. DJAR: software engineer, conceptualization, writing original draft, valida-\ntion, writing—review and editing of draft. LB, KS, FFE: insect assay. BMVM, JH: \nAutoEnto developer. LC: supervision. All authors read and approved the final \nmanuscript.\nFunding\nThis work was funded by Horizon 2020 Framework Programme (Grant No. \n101000570) and the  WUR internal program KB34 Towards a Circular and \nClimate Neutral Society (2019–2022), project KB34-1-2A-6 Virtigation.\nAvailability of data and materials\nThe datasets used and analyzed during the current study are available from \nthe corresponding author on reasonable request.\nDeclarations\nEthics approval and consent to participate\nNo specific permits were required. All authors agreed to publish this \nmanuscript.\nConsent for publication\nConsent and approval for publication from all the authors were obtained.\nCompeting interests\nThe authors declare that they have no competing interests.\nReceived: 20 March 2023   Accepted: 9 May 2023\nReferences\n 1. Akintayo A, Tylka GL, Singh AK, Ganapathysubramanian B, Singh A, Sarkar \nS. A deep learning framework to discern and count microscopic nema-\ntode eggs. Sci Rep. 2018;8(1):9145.\n 2. Andrade MC, da Silva AA, Carvalho RDC, de Andrade Santiago J, de \nOliveira AMS, Francis DM, Maluf WR. Quantitative trait loci associated with \ntrichomes in the Solanum galapagense accession LA1401. Genet Resour \nCrop Evol. 2018;65(6):1671–85.\n 3. Bas N, Mollema C, Lindhout P . Resistance in Lycopersicon hirsutum f. \nglabratum to the greenhouse whitefly (Trialeurodes vaporariorum) \nincreases with plant age. Euphytica. 1992;64(3):189–95.\n 4. Boiteau G, Singh RP . Resistance to the greenhouse whitefly, Trialeurodes \nvaporariorum (Westwood) (Homoptera: Aleyrodidae), in a clone of \nthe wild potato Solanum berthaultii Hawkes. Ann Entomol Soc Am. \n1988;81(3):428–31.\n 5. Bradski G. The OpenCV library. Dr Bobb’s J Softw Tools Prof Program. \n2000;25(11):120–3.\n 6. Chen A, Chow A, Davidson A, Dcunha A, Ghodsi A, Hong S, Konwinski \nA, Mewald C, Murching S, Nykodym T, Ogilvie P , Parkhe M, Singh A, Xie \nF, Zaharia M, Zang R, Zheng J, Zumar C. Developments in MLflow: a \nsystem to accelerate the machine learning lifecycle. In: Proc. Fourth Int. \nworkshop on data management for end-to-end machine learning; 2020.\n 7. Clot CR, Polzer C, Prodhomme C, Schuit C, Engelen CJM, Hutten RCB, van \nEck HJ. The origin and widespread occurrence of Sli-based self-compati-\nbility in potato. Theor Appl Genet. 2020;133(9):2713–28.\n 8. Davidson EW, Segura BJ, Steele T, Hendrix DL. Microorganisms influ-\nence the composition of honeydew produced by the silverleaf white -\nfly, Bemisia argentifolii. J Insect Physiol. 1994;40(12):1069–76.\n 9. Fetter KC, Eberhardt S, Barclay RS, Wing S, Keller SR. StomataCounter: \na neural network for automatic stomata identification and counting. \nNew Phytol. 2019;223(3):1671–81.\n 10. Firdaus S, van Heusden AW, Hidayati N, Supena ED, Mumm R, de Vos \nRC, Visser RG, Vosman B. Identification and QTL mapping of whitefly \nresistance components in Solanum galapagense. Theor Appl Genet. \n2013;126(6):1487–501.\n 11. Gaburro J, Duchemin J-B, Paradkar PN, Nahavandi S, Bhatti A. Assess-\nment of ICount software, a precise and fast egg counting tool for the \nmosquito vector Aedes aegypti. Parasites Vectors. 2016;9(1):590.\n 12. Georgina J, Arun CH, Bai MR. Automatic detection and counting of \nCallosobruchus maculatus (Fab.) eggs on vigna radiata seeds, using \nImageJ. J Appl Biol Biotechnol. 2021;9(2):182–6.\n 13. Huang HJ, Ye ZX, Lu G, Zhang CX, Chen JP , Li JM. Identification of \nsalivary proteins in the whitefly Bemisia tabaci by transcriptomic and \nLC-MS/MS analyses. Insect Sci. 2021;28(5):1369–81.\n 14. Isa IS, Rosli MSA, Yusof UK, Maruzuki MIF, Sulaiman SN. Optimizing \nthe hyperparameter tuning of YOLOv5 for underwater detection. IEEE \nAccess. 2022;10:52818–31.\nPage 14 of 14Devi et al. Plant Methods           (2023) 19:49 \n•\n \nfast, convenient online submission\n •\n  \nthorough peer review by experienced researchers in your ﬁeld\n• \n \nrapid publication on acceptance\n• \n \nsupport for research data, including large and complex data types\n•\n  \ngold Open Access which fosters wider collaboration and increased citations \n \nmaximum visibility for your research: over 100M website views per year •\n  At BMC, research is always in progress.\nLearn more biomedcentral.com/submissions\nReady to submit y our researc hReady to submit y our researc h  ?  Choose BMC and benefit fr om: ?  Choose BMC and benefit fr om: \n 15. Jiang ZF, Xia F, Johnson KW, Brown CD, Bartom E, Tuteja JH, Stevens \nR, Grossman RL, Brumin M, White KP , Ghanim M. Comparison of the \ngenome sequences of “Candidatus Portiera aleyrodidarum” primary \nendosymbionts of the whitefly Bemisia tabaci B and Q biotypes. Appl \nEnviron Microbiol. 2013;79(5):1757–9.\n 16. John LC, Alvin MS, Shepard BM, Amnon L. Vertical Y-tube assay for \nevaluation of Arthropod response to plant materials. J Agric Urban \nEntomol. 2016;32(1):7–12.\n 17. Jones DR. Plant viruses transmitted by whiteflies. Eur J Plant Pathol. \n2003;109(3):195–219.\n 18. Kalwa U, Legner C, Wlezien E, Tylka G, Pandey S. New methods of \nremoving debris and high-throughput counting of cyst nematode \neggs extracted from field soil. PLoS ONE. 2019;14(10): e0223386.\n 19. Mains JW, Mercer DR, Dobson SL. Digital image analysis to estimate \nnumbers of Aedes eggs oviposited in containers. J Am Mosq Control \nAssoc. 2008;24(4):496–501.\n 20. Maliepaard C, Bas N, van Heusden S, Kos J, Pet G, Verkerk R, Vrieunk R, \nZabel P , Lindhout P . Mapping of QTLs for glandular trichome densities \nand Trialeurodes vaporariorum (greenhouse whitefly) resistance in an \nF2 from Lycopersicon esculentum × Lycopersicon hirsutum f. glabratum. \nHeredity. 1995;75(4):425–33.\n 21. Martin JH, Mound LA. An annotated check list of the world’s whiteflies \n(Insecta: Hemiptera: Aleyrodidae). Zootaxa. 2007;1492(1):1–84.\n 22. Momotaz A, Scott JW, Schuster DJ. Identification of quantitative trait loci \nconferring resistance to Bemisia tabaci in an F2 population of Solanum \nlycopersicum × Solanum habrochaites accession LA1777. J Am Soc Hortic \nSci. 2010;135(2):134–42.\n 23. Pan HP , Chu D, Liu BM, Xie W, Wang SL, Wu QJ, Xu BY, Zhang YJ. Relative \namount of symbionts in insect hosts changes with host-plant adaptation \nand insecticide resistance. Environ Entomol. 2013;42(1):74–8.\n 24. Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, Killeen T, Lin Z, \nGimelshein N, Antiga L, Desmaison A, Köpf A, Yang E, DeVito Z, Raison M, \nTejani A, Chilamkurthy S, Steiner B, Fang L, Bai J, Chintala S. PyTorch: an \nimperative style, high-performance deep learning library. In: Proc. 33rd \nInt. Conf. on neural information processing systems; 2019.\n 25. Rodríguez-Álvarez CI, López-Climent MF, Gómez-Cadenas A, Kaloshian \nI, Nombela G. Salicylic acid is required for Mi-1-mediated resistance of \ntomato to whitefly Bemisia tabaci, but not for basal defense to this insect \npest. Bull Entomol Res. 2015;105(5):574–82.\n 26. Rodríguez-López MJ, Garzo E, Bonani JP , Fernández-Muñoz R, Moriones E, \nFereres A. Acylsucrose-producing tomato plants forces Bemisia tabaci to \nshift its preferred settling and feeding site. PLoS ONE. 2012;7(3): e33064.\n 27. Rosell RC, Lichty JE, Brown JK. Ultrastructure of the mouthparts of adult \nsweetpotato whitefly, Bemisia tabaci Gennadius (Homoptera: Aleyrodi-\ndae). Int J Insect Morphol Embryol. 1995;24(3):297–306.\n 28. Rustia DJA, Chao J-J, Chiu L-Y, Wu Y-F, Chung J-Y, Hsu J-C, Lin T-T. \nAutomatic greenhouse insect pest detection and recognition based \non a cascaded deep learning classification method. J Appl Entomol. \n2021;145(3):206–22.\n 29. Santegoets J, Bovio M, van’t Westende W, Voorrips RE, Vosman B. A novel \nnon-trichome based whitefly resistance QTL in Solanum galapagense. \nEuphytica. 2021;217(3):1–11.\n 30. Simmons AM, Harrison HF, Ling KS. Forty-nine new host plant species for \nBemisia tabaci (Hemiptera: Aleyrodidae). Entomol Sci. 2008;11(4):385–90.\n 31. Song W, Li J, Li K, Chen J, Huang J. An automatic method for stomatal \npore detection and measurement in microscope images of plant leaf \nbased on a convolutional neural network model. Forests. 2020;11(9):954.\n 32. Ströbel B, Schmelzle S, Blüthgen N, Heethoff M. An automated device \nfor the digitization and 3D modelling of insects, combining extended-\ndepth-of-field and all-side multi-view imaging. Zookeys. 2018;759:1–27.\n 33. Tsai JH, Wang K. Development and reproduction of Bemisia argenti-\nfolii (Homoptera: Aleyrodidae) on five host plants. Environ Entomol. \n1996;25(4):810–6.\n 34. van den Oever-van den Elsen F, Lucatti AF, van Heusden S, Broekgaarden \nC, Mumm R, Dicke M, Vosman B. Quantitative resistance against Bemisia \ntabaci in Solanum pennellii: genetics and metabolomics. J Integr Plant \nBiol. 2016;58(4):397–412.\n 35. van Driesche RG, Reardon RC. Assessing host ranges of parasitoids and \npredators used for classical biological control: a guide to best practice. \nUnited States Department of Agriculture Forest Health Technology Enter-\nprise Team; 2004.\n 36. Vosman B, Kashaninia A, Van’t Westende W, Meijer-Dekens F, van \nEekelen H, Visser RGF, de Vos RCH, Voorrips RE. QTL mapping of insect \nresistance components of Solanum galapagense. Theor Appl Genet. \n2019;132(2):531–41.\n 37. Wei Y-A, Hendrix DL, Nieman R. Diglucomelezitose, a novel pen-\ntasaccharide in silverleaf whitefly honeydew. J Agric Food Chem. \n1997;45(9):3481–6.\n 38. Xiao N, Pan L-L, Zhang C-R, Shan H-W, Liu S-S. Differential tolerance \ncapacity to unfavourable low and high temperatures between two \ninvasive whiteflies. Sci Rep. 2016;6(1):24306.\n 39. Zhang C, Jiang H, Jiang H, Xi H, Chen B, Liu Y, Juhas M, Li J, Zhang Y. Deep \nlearning for microscopic examination of protozoan parasites. Comput \nStruct Biotechnol J. 2022;20:1036–43.\n 40. Zhang C, Yang Z, Tang D, Zhu Y, Wang P , Li D, Zhu G, Xiong X, Shang Y, Li \nC, Huang S. Genome design of hybrid potato. Cell. 2021;184(15):3873-\n3883.e3812.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in pub-\nlished maps and institutional affiliations.",
  "topic": "Whitefly",
  "concepts": [
    {
      "name": "Whitefly",
      "score": 0.9464722871780396
    },
    {
      "name": "Insect",
      "score": 0.6218145489692688
    },
    {
      "name": "Biology",
      "score": 0.6036046743392944
    },
    {
      "name": "Resistance (ecology)",
      "score": 0.4355662167072296
    },
    {
      "name": "Artificial intelligence",
      "score": 0.35213369131088257
    },
    {
      "name": "Computer science",
      "score": 0.25643080472946167
    },
    {
      "name": "Agronomy",
      "score": 0.2410416305065155
    },
    {
      "name": "Horticulture",
      "score": 0.2208540141582489
    },
    {
      "name": "Botany",
      "score": 0.2139522135257721
    }
  ]
}