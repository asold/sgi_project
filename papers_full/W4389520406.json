{
  "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration",
  "url": "https://openalex.org/W4389520406",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2143737267",
      "name": "Yiquan WU",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2489202427",
      "name": "Siying Zhou",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2098346062",
      "name": "Liu Yifei",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2112122693",
      "name": "Weiming Lu",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2103494509",
      "name": "Xiaozhong Liu",
      "affiliations": [
        "Worcester Polytechnic Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2117508990",
      "name": "Yating Zhang",
      "affiliations": [
        "Alibaba Group (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2103766668",
      "name": "Changlong Sun",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097805274",
      "name": "Fei Wu",
      "affiliations": [
        "Zhejiang University"
      ]
    },
    {
      "id": "https://openalex.org/A2584736634",
      "name": "Kun Kuang",
      "affiliations": [
        "Zhejiang University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3103181983",
    "https://openalex.org/W4246483584",
    "https://openalex.org/W2932110532",
    "https://openalex.org/W4321011670",
    "https://openalex.org/W4377865105",
    "https://openalex.org/W4285601006",
    "https://openalex.org/W4323323144",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4309211096",
    "https://openalex.org/W2765440119",
    "https://openalex.org/W2005949547",
    "https://openalex.org/W4380559178",
    "https://openalex.org/W2890026792",
    "https://openalex.org/W4281487830",
    "https://openalex.org/W3124848065",
    "https://openalex.org/W4320813768",
    "https://openalex.org/W3099950029",
    "https://openalex.org/W4287027006",
    "https://openalex.org/W2161882149",
    "https://openalex.org/W3099641295",
    "https://openalex.org/W1537528262",
    "https://openalex.org/W4224903957",
    "https://openalex.org/W2116920598",
    "https://openalex.org/W4318586794",
    "https://openalex.org/W4327810667",
    "https://openalex.org/W2395585048",
    "https://openalex.org/W2147800946",
    "https://openalex.org/W2143646152",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W3204112174",
    "https://openalex.org/W3176443840",
    "https://openalex.org/W2601470260",
    "https://openalex.org/W4385573332",
    "https://openalex.org/W3034892514",
    "https://openalex.org/W3209145439",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W4386076413",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W3203176827",
    "https://openalex.org/W3035668167",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W4304080724",
    "https://openalex.org/W3156831596",
    "https://openalex.org/W3156638011",
    "https://openalex.org/W1974448158",
    "https://openalex.org/W4285605895",
    "https://openalex.org/W4323717348",
    "https://openalex.org/W2120879767",
    "https://openalex.org/W4364384540",
    "https://openalex.org/W2962854673"
  ],
  "abstract": "Yiquan Wu, Siying Zhou, Yifei Liu, Weiming Lu, Xiaozhong Liu, Yating Zhang, Changlong Sun, Fei Wu, Kun Kuang. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 2023.",
  "full_text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 12060–12075\nDecember 6-10, 2023 ©2023 Association for Computational Linguistics\nPrecedent-Enhanced Legal Judgment Prediction with LLM and\nDomain-Model Collaboration\nYiquan Wu1, Siying Zhou1, Yifei Liu1, Weiming Lu1∗, Xiaozhong Liu2\nYating Zhang3, Changlong Sun13, Fei Wu1∗, Kun Kuang1∗\n1Zhejiang University, Hangzhou, China\n2Worcester Polytechnic Institute, USA\n3Alibaba Group, Hangzhou, China\n{wuyiquan, zhousiying, liuyifei, luwm, kunkuang}@zju.edu.cn, yatingz89@gmail.com\nxliu14@wpi.edu, changlong.scl@taobao.com, wufei@cs.zju.edu.cn\nAbstract\nLegal Judgment Prediction (LJP) has become\nan increasingly crucial task in Legal AI, i.e.,\npredicting the judgment of the case in terms of\ncase fact description. Precedents are the previ-\nous legal cases with similar facts, which are the\nbasis for the judgment of the subsequent case in\nnational legal systems. Thus, it is worthwhile\nto explore the utilization of precedents in the\nLJP. Recent advances in deep learning have en-\nabled a variety of techniques to be used to solve\nthe LJP task. These can be broken down into\ntwo categories: large language models (LLMs)\nand domain-specific models. LLMs are capable\nof interpreting and generating complex natural\nlanguage, while domain models are efficient\nin learning task-specific information. In this\npaper, we propose the precedent-enhanced LJP\nframework (PLJP) – a system that leverages the\nstrength of both LLM and domain models in the\ncontext of precedents. Specifically, the domain\nmodels are designed to provide candidate labels\nand find the proper precedents efficiently, and\nthe large models will make the final prediction\nwith an in-context precedents comprehension.\nExperiments on the real-world dataset demon-\nstrate the effectiveness of our PLJP. Moreover,\nour work shows a promising direction for LLM\nand domain-model collaboration that can be\ngeneralized to other vertical domains.\n1 Introduction\nLegal AI has been the subject of research for sev-\neral decades, with the aim of assisting individuals\nin various legal tasks, including legal QA (Mon-\nroy et al., 2009), court view generation (Wu et al.,\n2020), legal entity recognition (Cardellino et al.,\n2017), and so on. As one of the most important\nlegal tasks, legal judgment prediction (LJP) aims to\npredict the legal judgment of the case based on the\ncase fact description. The legal judgment typically\nincludes the law article, charge and prison term.\n*Corresponding Authors.\nCase Database\nJudgment\nCase \nComprehension\nJudge\nFact\nCase Investigation\nPrior\nKnowledg\ne\nDomain-Model\nLLM-enabled\nCase Comprehension\nPrecedents\nRetrieval\nJudgment\nHuman Judicial Process AI Judicial Process\nFigure 1: An illustration of the judicial process, our\nmotivation is to promote the collaboration between the\ndomain model and LLM (right part) for simulating the\njudicial process of the human judge (left).\nPrecedents, which refer to previous cases with\nsimilar fact descriptions, hold a crucial position\nwithin national legal systems (Guillaume, 2011).\nOn a more macro level, precedents are known as\nthe collective body of judge-made laws in a na-\ntion(Garner, 2001). They serve the purpose of en-\nsuring consistency in judicial decisions, providing\ngreater legal guidance to judges and facilitating le-\ngal progress and evolution to meet dynamic legal\ndemands. In the Common Law system, the prece-\ndents are the mandatory basis of the judgment of\nthe subsequent case (Rigoni, 2014). In the Civil\nLaw system, judge-made laws are perceived as sec-\nondary legal sources while written laws are the\nbasic legal sources(Larenz, 1992). In the contem-\nporary era, there is also a growing trend to treat the\nprecedents as a source of “soft” law (Fon and Parisi,\n2006), and judges are expected to take them into ac-\ncount when reaching a decision (Guillaume, 2011).\nThus, it is worthwhile to explore the utilization of\nprecedents in the legal judgment prediction.\nWith the development of deep learning, many\ntechnologies have been adopted in the LJP task,\nwhich can be split into two categories: large lan-\n12060\nguage models (LLMs) and domain-specific mod-\nels (Ge et al., 2023). Owing to extensive training,\nLLMs are good at understanding and generating\ncomplex natural language, as well as in-context\nlearning. On the other hand, domain-specific mod-\nels are designed to cater to specific tasks and offer\ncost-effective solutions. However, when it comes to\nincorporating precedents into the LJP task, both cat-\negories of models face certain limitations. LLMs,\nconstrained by their prompt length, struggle to\ngrasp the meaning of numerous abstract labels and\naccurately select the appropriate one. For domain\nmodels, though trained with label annotations, the\ndrawback is the limited ability to comprehend and\ndistinguish the similarities and differences between\nthe precedents and the given case.\nIn this paper, as Fig. 1 shows, we try to collab-\norate the LLMs with the domain-specific models\nand propose a novel precedent-enhanced legal judg-\nment prediction framework (PLJP). Specifically,\ndomain models contribute by providing candidate\nlabels and finding the proper precedents from the\ncase database effectively; the LLMs will decide\nthe final prediction through an in-context precedent\ncomprehension.\nFollowing the previous LJP works (Zhong et al.,\n2018; Yue et al., 2021; Dong and Niu, 2021), our\nexperiments are conducted on the publicly avail-\nable real-world legal dataset. To prevent any poten-\ntial data leakage during the training of the LLMs,\nwhere the model may have already encountered the\ntest cases, we create a new test set comprising cases\nthat occurred after 2022. This is necessary because\nthe LLMs we utilize have been trained on a corpus\ncollected only until September 2021. By doing\nso, we ensure a fair evaluation of the PLJP frame-\nwork. Remarkably, our proposed PLJP framework\nachieves state-of-the-art (SOTA) performance on\nboth the original test set and the additional test set.\nTo sum up, our main contributions are as fol-\nlows:\n• We address the important task of legal judg-\nment prediction (LJP) by taking precedents\ninto consideration.\n• We propose a novel precedent-enhanced legal\njudgment prediction (PLJP) framework that\nleverages the strength of both LLM and do-\nmain models.\n• We conduct extensive experiments on the real-\nworld dataset and create an additional test set\nto ensure the absence of data leakage during\nLLM training. The results obtained on both\nthe original and additional test sets validate\nthe effectiveness of the PLJP framework.\n• Our work shows a promising direction for\nLLM and domain-model collaboration that\ncan be generalized over vertical domains. We\nmake all the codes and data publicly available\nto motivate other scholars to investigate this\nnovel and interesting research direction1.\n2 Related Work\n2.1 Legal AI\nLegal Artificial Intelligence (Legal AI) aims to en-\nhance tasks within the legal domain through the uti-\nlization of artificial intelligence techniques (Zhong\net al., 2020; Katz et al., 2023). Collaborative ef-\nforts between researchers in both law and com-\nputer fields have been lasting to explore the poten-\ntial of Legal AI and its applications across vari-\nous legal tasks. These tasks encompass areas such\nas legal question answering (QA) (Monroy et al.,\n2009), legal entity recognition (Cardellino et al.,\n2017), court view generation (Wu et al., 2020),\nlegal summarization (Hachey and Grover, 2006;\nBhattacharya et al., 2019), legal language under-\nstanding(Chalkidis et al., 2022) and so on.\nIn this work, we focus on the task of legal judg-\nment prediction, which is one of the most common\ntasks in Legal AI.\n2.2 Legal Judgment Prediction\nLegal judgment prediction (LJP) aims to predict\njudgment results based on the fact descriptions au-\ntomatically (Lin et al., 2012; Chalkidis et al., 2019;\nYue et al., 2021; Xu et al., 2020; Niklaus et al.,\n2021; Malik et al., 2021; Feng et al., 2022; Lyu\net al., 2022; Gan et al., 2022). The LJP methods in\nearlier years required manually extracted features\n(Keown, 1980), which is simple but costly. Owing\nto the prosperity of machine learning (Wu et al.,\n2022; Shen et al., 2022; Li et al., 2022a,b; Zhang\net al., 2022; Li et al., 2023; Zhang et al., 2023),\nresearchers began to formalize the LJP problem\nwith machine learning methods. These data-driven\nmethods can learn the features with far less labor\n(e.g., only the final labels are required). Sulea et al.\n(2017) developed an ensemble system that aver-\nages the output of multiple SVM to improve the\n1https://github.com/wuyiquan/PLJP\n12061\nperformance of LJP. Luo et al. (2017) utilized an\nattention mechanism in the LJP. Zhong et al. (2018)\nconsidered the dependency of the sub-tasks in the\nLJP. Yue et al. (2021) investigated the problem by\nseparating the representation of fact description\ninto different embedding. Liu et al. (2022) used\ncontrastive learning in the LJP.\nHowever, these existing LJP methods tend to\noverlook the significance of precedents. In this\nstudy, we propose a precedent-enhanced LJP frame-\nwork (PLJP) that leverages the collaboration be-\ntween domain-specific models and large language\nmodels (LLMs) to address the LJP task.\n2.3 Precedent Retrieval\nThe precedent is the basis of judgment in the Com-\nmon Law system, and also an important refer-\nence for decision-making in the Civil Law system.\nTherefore, precedent retrieval is another valuable\ntask in Legal AI (Althammer et al., 2021). There\nare two main precedent retrieval models: expert\nknowledge-based models and natural language pro-\ncessing (NLP)-based models (Bench-Capon et al.,\n2012). Expert knowledge-based models use the\ndesigned sub-elements to represent the legal cases\n(Saravanan et al., 2009), while NLP-based models\nmainly convert the text into embeddings and then\ncalculate the similarity from the embedding level\n(Ma et al., 2021; Chalkidis et al., 2020).\nMost retrieval models required additional anno-\ntation so can not be directly applied to the LJP\ntask. In our paper, we use an unsupervised dense\nretrieval model (Izacard et al., 2022) to get the\nprecedents, which can be updated by other retrieval\nmodels if needed.\n2.4 Large Language Models\nLarge language models (LLMs), such as ChatGPT,\nhave attracted widespread attention from society\n(Zhao et al., 2023). With pre-training over large-\nscale corpora, LLMs show strong capabilities in\ninterpreting and generating complex natural lan-\nguage, as well as reasoning (e.g., in-context learn-\ning). The technical evolution of LLMs has been\nmaking an important impact on the fields of natural\nlanguage processing (Brown et al., 2020; Touvron\net al., 2023), computer vision (Shao et al., 2023;\nWu et al., 2023), and reinforcement learning (Du\net al., 2023). In the legal domain, LLMs can also\nbe used for many tasks such as legal document\nanalysis and legal document writing (Sun, 2023).\nHowever, in the prediction tasks, which can in-\nvolve dozens of abstract labels, the performance of\nLLMs is not as good as in generation tasks, due to\nthe limited prompt length. In this paper, we explore\nthe utilization of LLMs in the LJP task with the\ncollaboration of domain-specific models.\n3 Problem Formulation\nIn this work, we focus on the problem of legal\njudgment prediction. We first clarify the definition\nof the terms as follows.\n•Fact Descriptionrefers to a concise narrative\nof the case, which typically includes the timeline\nof events, the actions or conduct of each party, and\nany other essential details that are relevant to the\ncase. Here we define it as a token sequence f =\n{wf\nt }lf\nt=1, where lf is the length.\n•Judgment is the final decision made by a judge\nin a legal case based on the facts and the precedents.\nIt typically consists of the law article, the charge,\nand the prison term. We represent the judgment of a\ncase as j = (a, c, t), where a, c, t refer to the labels\nof article, charge and prison term, respectively.\n•Precedent is the previous case with a similar\nfact. The judgments of the precedents are important\nreferences for the current case. Here, a precedent is\ndefined as p = (fp, jp), where fp is its fact descrip-\ntion and jp is its judgment. For a given case, there\ncan be several precedents, which can be denoted\nas P = {p1, p2, ..., pn}, where n is the number of\nprecedents.\nThen the problem can be defined as:\nProblem 1(Legal Judgment Prediction). Given the\nfact description f, our task is to get and compre-\nhend the precedents P, then predict the judgment\nj = (a, c, t).\n4 Precedent-Enhanced LJP (PLJP)\nIn this section, we describe our precedent-enhanced\nlegal judgment prediction framework (PLJP), Fig.\n2 shows the overall framework.\n4.1 Case Database Construction\nBefore we use the precedents, we have to collect a\nlarge number of previous cases to construct a case\ndatabase. Since the fact descriptions are usually\nlong and elaborate, it is difficult for the models to\nget the proper precedents. To this end, we reor-\nganize the fact description of these previous cases\nwith the help of LLMs.\n12062\n…\nAt about 2 a.m. on \nOctober 9, 2017, \ndefendant A was on \nthe west side of the \nroad of the C City, \nfollowing B who \npassed by here alone \nand asking B for \n$200 in cash, and B \nwas forced to hand \nover one mobile \nphone to A. The \nprice certification\n…\nDuring the trial of \nthe case, defendant \nA refunded $200 of \nillegal gains.\nDefendant A deliberately \nfollowed and demanded money \nfrom B.\nDefendant A forced B to hand \nover a mobile phone.\nAfter Arrest, A returned $200 of \nillegal gains.\nArticle 263 36 monthsRobbery\nFact Description Domain Model \n(Predictive Model)\nDomain Model \n(Retrieval Model)\nCandidate Labels\nLLM\nCase Database\nReorganized Fact\nsub\nobj\nex\nPredicted Judgment\nsub: subjective motivation \nobj: objective behavior\nex: ex post facto circumstance\na: law article\nc: charge\nt: prison term\nPrecedents\nJudgmentFactCase \nID\n(a, c, t)(sub, obj, ex)1\n(a, c, t)(sub, obj, ex)2\n.........\na c t\nFigure 2: The overall framework of PLJP, where the sub, obj and ex refer to the subjective motivation, objective\nbehavior and ex post facto circumstance, respectively. The solid lines are the precedent retrieval process, while the\ndotted lines represent the process of the prediction.\n4.1.1 Fact Reorganization\nGiven a fact description of a case, we summarize\nit from three aspects: subjective motivation, objec-\ntive behavior, and ex post facto circumstances. The\nreorganization doesn’t require human annotation\nand is completed by the LLMs with the following\nprompts: “A fact description can be categorized\ninto subjective motivation, objective behavior, and\nex post facto circumstances. Subjective motiva-\ntion refers to the psychological attitude of the per-\npetrator towards their harmful actions and their\nconsequences, including intent, negligence, and\npurposes of the crime. Objective behavior per-\ntains to the necessary conditions for constituting a\ncrime in terms of observable activities, including\nharmful conduct, harmful results, and the causal\nrelationship between the conduct and the results.\nEx post facto circumstances are various factual sit-\nuations considered when determining the severity\nof penalties. Mitigating circumstances for lenient\npunishment include voluntary surrender and meri-\ntorious conduct, while aggravating circumstances\nfor harsher punishment include recidivism. Based\non the provided information, your task is to sum-\nmarize the following facts. ”\nThe reorganization reduces the length of facts\nand makes the precedents easy to get and compre-\nhend in the PLJP.\nAfter the reorganization, the fact description f\nis translated to a triplet (sub, obj, ex), which indi-\ncates the subjective motivation, objective behavior,\nand ex post facto circumstances, respectively. Fi-\nnally, a previous case in the case database is stored\nas a pair of reorganized facts and the judgment.\n4.2 Legal Judgment Prediction\nNext, we describe the collaboration of the LLM\nand domain models in legal judgment prediction.\n4.2.1 Domain Models\nThe domain models are trained on specific datasets,\naiming to solve certain tasks. Here, we use two\nkinds of domain models, including the predictive\nmodel and the retrieval model.\nPredictive model. The predictive model takes\nthe fact description as the input and outputs the\ncandidate labels of the three sub-tasks (e.g., law\narticle, charge, prison term). Since the fact descrip-\ntion f = {wf\nt }lf\nt=1 are sequences of words, we first\ntransform it into embedding sequence Hf ∈Rlf ×d\nwith an Encoder:\nHf = Encode(f), (1)\nwhere Hf = hf\n1 , hf\n2 , ..., hf\nlf\n, and d is the dimension\nof the embedding.\nWe take a max-pooling operation to obtain the\npooled hidden vector hf ∈Rd and then feed it into\na fully-connected network with softmax activation\n12063\nto obtain the label probability distributionP ∈Rm:\nhf = MaxPooling(Hf ),\nP = Softmax(Wp ·hf + bp),\n(2)\nwhere Wp ∈Rm×d and bp ∈Rm are learnable\nparameters. Note m varies in different sub-tasks.\nThen, each sub-task gets its candidate labels ac-\ncording to the probability distribution P, and the\nnumber of candidate labels is equal to the number\nof precedents n.\nRetrieval model. The retrieval model aims to get\nthe proper precedents of the given case based on\nits reorganized fact (sub, obj, ex).\nFormally, to get the similarity score of any two\ntexts D1 and D2, we will first encode each of them\nindependently using the same encoder:\nhD1 = Encoder(D1), hD2 = Encoder(D2),\n(3)\nwhere hD1 ∈Rd′\nand hD2 ∈Rd′\nare the embed-\nding of each, d′is the dimension. The similarity\nscore s(D1, D2) is then the cosine similarity of the\nhD1 and hD2 :\ns(D1, D2) = hD1 ·hD2\n∥hD1 ∥∥hD2 ∥. (4)\nHere we concatenate the sub, obj and ex into a\nwhole text to calculate the similarity score of the\ngiven case and the cases in the case database.\nFor each candidate label, we pick one case as\nthe precedent: the case that has the highest similar-\nity score and has the same label. For example, if\nthe label “Theft” is in the candidate labels in the\ncharge prediction, we will find the most similar pre-\nvious case with the same label as the corresponding\nprecedent. The one-to-one relationship between the\ncandidate label and precedent helps the LLM dis-\ntinguish the differences among the labels. In other\nwords, the precedent serves as a supplementary\nexplanation of the label.\nFinally, we get precedents P = {p1, p2, ..., pn}\nfor the given case.\n4.2.2 LLMs\nThe large language models are models with billions\nof parameters, which are trained on large-scale cor-\npora, and show strong capabilities in interpreting\nand generating complex natural language. LLMs\ncontribute to PLJP by fact reorganization and in-\ncontext precedent comprehension.\nFact Reorganization The fact reorganization\nis described in case database construction (Sec.\n4.1.1), which aims to summarize the fact descrip-\ntion from three aspects by the LLMs. Besides the\ndatabase contribution, as Fig. 2 shows, when a new\ntest case comes, the LLMs will reorganize the fact\ndescription with the same prompt.\nIn-Context Precedent Comprehension Since\nLLMs are capable of understanding complex nat-\nural language, we stack the given case with its\nprecedents and let the LLMs make the final pre-\ndiction by an in-context precedent comprehension.\nSpecifically, the prompt of law article prediction is\ndesigned as follows: “Based on the facts, we select\nthe candidate law articles by the domain models\nand select the following three precedents based\non the candidate law articles. Please comprehend\nthe difference among the precedents, then compare\nthem with the facts of this case, and choose the\nfinal label. ”\nConsider the topological dependencies among\nthe three sub-tasks (Zhong et al., 2018), in the pre-\ndiction of charge, we add the predicted law article\nin the prompt; in the prediction of prison term, we\nadd the predicted law article and charge.\n4.3 Training\nIn PLJP, considering the realizability, we train do-\nmain models on legal datasets and leave the LLMs\nunchanged. To train predictive models, the cross-\nentropy loss is employed. As for retrieval models,\ncontrastive loss is used like Izacard et al. (2022).\n5 Experiments\nType CAIL2018 CJO22\n# Law Article 164 164\n# Charge 42 42\n# Prison Term 10 10\n# Sample 82138 1698\nAvg. # words in Fact 288.6 461.7\nTable 1: Statistics of datasets.\n5.1 Datasets\nFollowing many influential LJP works (Zhong\net al., 2018; Xu et al., 2020; Yue et al., 2021; Dong\nand Niu, 2021), our experiment is conducted on\nthe widely used and publicly available CAIL2018\ndataset, which is a Chinese dataset in the con-\ntext of People’s Republic of China (PRC). This\ndataset consists of real-world cases, each of which\n12064\nMethod CJO22 CAIL2018\nAcc Ma-P Ma-R Ma-F Acc Ma-P Ma-R Ma-F\nCNN (LeCun et al., 1989) 76.14 35.48 38.55 35.39 80.50 40.10 38.33 38.49\nBERT (Devlin et al., 2019) 82.62 45.89 47.91 45.83 82.77 36.82 35.94 35.82\nRoberta (Liu et al., 2019) 80.32 42.36 44.22 41.80 83.08 48.09 44.25 44.87\nTopJudge (Zhong et al., 2018) 78.73 40.38 41.47 40.09 80.46 40.96 40.96 38.24\nR-Former (Dong and Niu, 2021) 87.69 53.03 49.35 50.23 87.82 56.13 56.57 55.81\nLADAN (Xu et al., 2020) 79.44 48.43 44.13 46.18 82.82 42.57 39.00 40.71\nNeurJudge (Yue et al., 2021) 71.38 52.86 53.52 52.62 76.91 55.95 52.92 53.56\nEPM(Feng et al., 2022) 84.19 47.21 43.79 44.39 85.80 49.08 45.76 47.32\nCTM(Liu et al., 2022) 79.44 47.83 42.25 43.43 84.72 46.46 44.83 45.10\nDav003 2.10 0.82 0.17 0.26 1.02 0.30 0.08 0.13\n3.5turbo 9.13 2.54 1.61 1.53 4.08 4.95 3.64 2.30\nPLJP(CNN) 87.67 55.21 55.59 54.37 86.05 58.08 56.46 54.92\nPLJP(BERT) 94.18 74.65 76.23 74.84 87.07 58.81 57.29 56.63\nTable 2: Results of law article prediction, the best is bolded and the second best is underlined.\nMethod CJO22 CAIL2018\nAcc Ma-P Ma-R Ma-F Acc Ma-P Ma-R Ma-F\nCNN (LeCun et al., 1989) 74.91 74.00 78.12 73.97 87.52 88.23 88.31 88.17\nBERT (Devlin et al., 2019) 80.50 80.34 81.09 78.36 89.10 90.10 89.48 89.63\nRoberta (Liu et al., 2019) 79.26 78.93 81.25 78.18 90.30 91.02 90.97 90.94\nTopJudge (Zhong et al., 2018) 76.67 74.00 77.40 74.62 87.31 88.68 87.84 88.20\nR-Former (Dong and Niu, 2021) 90.71 93.06 88.66 89.82 91.54 91.61 91.96 91.58\nLADAN (Xu et al., 2020) 79.64 48.43 44.13 46.18 88.09 90.12 88.82 89.47\nNeurJudge (Yue et al., 2021) 71.85 69.37 71.09 68.66 82.13 82.71 82.30 82.36\nEPM(Feng et al., 2022) 83.49 80.36 83.29 81.87 91.20 90.81 89.99 90.46\nCTM(Liu et al., 2022) 79.33 82.39 83.12 82.81 90.28 90.34 88.08 86.30\nDav003 44.65 52.43 32.93 35.29 25.85 35.37 25.09 22.08\n3.5turbo 58.37 56.03 40.68 42.62 49.65 42.29 34.05 31.85\nPLJP(CNN) 91.62 83.43 84.88 83.40 91.49 81.80 83.95 80.06\nPLJP(BERT) 94.18 90.25 88.67 89.05 94.99 92.12 91.10 91.33\nTable 3: Results of charge prediction, the best is bolded and the second best is underlined.\nincludes a fact description accompanied by a com-\nplete judgment encompassing three labels: law ar-\nticles, charges, and prison terms2.\nTo mitigate the potential data leakage during the\ntraining of LLMs, which were trained on corpora\ncollected until September 2021, we have compiled\na new dataset called CJO22. This dataset exclu-\nsively contains legal cases that occurred after 2022,\nsourced from the same origin as CAIL20183. How-\never, due to its limited size, the newly collected\nCJO22 dataset is inadequate for the training pur-\nposes of the domain models. Consequently, we\nutilize it solely as an additional test set. To facil-\nitate meaningful comparisons, we retain only the\nlabels that are common to both datasets, consider-\ning that the labels may not be entirely aligned.\nTab. 1 shows the statistics of the processed\ndatasets, and all the experiments are conducted\non the same datasets. For CAIL2018 dataset, we\nrandomly divide it into training set, validation set\nand test set according to the ratio of 8: 1: 1.\n2Prison terms are divided into non-overlapping intervals.\n3https://wenshu.court.gov.cn/\n15.32\n44.35\n56.63\n81.02 85.22\n91.33\n28.73 31.44\n35.43\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n1 2 3\nNumber of Precedents\nLaw Article Charge Prison Term\n35.62\n65.53\n74.8470.82\n85.66 89.05\n22.3 25.5\n31.98\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n1 2 3\nNumber of Precedents\nLaw Article Charge Prison Term\nMa-FMa-F CJO22 CAIL2018\nFigure 3: The Ma-F of PLJP with different number of\nprecedents.\nThe previous cases in the case database are sam-\npled from the training dataset, and we set the\namount to 4000.\n5.2 Baselines\nFor domain-specific LJP baselines, we implement\nthe following for comparison:\nCNN (LeCun et al., 1989) extracts text features\nthrough convolutional operations with different ker-\nnels for text classification; BERT(Devlin et al.,\n2019) is a pre-trained language model and can be\neasily fine-tuned on the downstream tasks; Top-\nJudge (Zhong et al., 2018) use multi-task learn-\n12065\nMethod CJO22 CAIL2018\nAcc Ma-P Ma-R Ma-F Acc Ma-P Ma-R Ma-F\nCNN (LeCun et al., 1989) 27.38 18.48 17.51 17.44 34.42 32.22 30.53 31.05\nBERT (Devlin et al., 2019) 36.80 29.83 27.50 27.03 40.00 37.53 33.66 33.58\nRoberta (Liu et al., 2019) 29.74 24.73 24.76 23.22 40.84 38.62 38.55 38.50\nTopJudge (Zhong et al., 2018) 27.14 19.76 17.69 17.94 35.54 33.55 31.08 32.00\nR-Former (Dong and Niu, 2021) 38.63 32.63 32.76 29.51 40.70 36.09 36.76 35.04\nLADAN (Xu et al., 2020) 33.69 26.40 22.94 24.55 38.03 33.66 30.08 31.77\nNeurJudge (Yue et al., 2021) 26.80 26.81 26.85 25.97 33.53 36.46 37.26 36.53\nEPM(Feng et al., 2022) 36.91 30.65 31.61 30.20 40.25 37.96 37.00 37.34\nCTM(Liu et al., 2022) 36.81 27.10 25.96 26.46 39.56 38.66 38.02 37.84\nDav003 0.47 5.56 0.21 0.41 0.68 10.38 0.49 0.94\n3.5turbo 1.40 1.16 1.07 1.11 1.02 2.71 1.13 1.15\nPLJP(CNN) 36.51 20.21 21.44 20.07 40.81 32.77 35.59 25.71\nPLJP(BERT) 43.52 33.37 35.67 31.98 48.72 42.64 36.80 35.43\nTable 4: Results of prison term prediction, the best is bolded and the second best is underlined.\nMethod\nCJO22 CAIL2018\nLaw Article Charge Prison Term Law Article Charge Prison Term\nAcc Ma-F Acc Ma-F Acc Ma-F Acc Ma-F Acc Ma-F Acc Ma-F\nw/o p 54.65 28.32 83.48 76.33 35.81 20.84 85.03 51.54 85.03 70.07 32.31 22.58\nw/o c 45.34 40.22 42.32 41.85 32.55 20.26 67.35 46.65 72.79 60.34 26.53 13.66\nw/o d 94.18 74.84 85.58 70.50 39.53 20.31 87.07 56.63 87.41 73.45 38.09 21.44\nw/o r 88.13 58.75 87.67 74.83 36.27 23.70 86.05 58.26 86.73 77.53 38.10 21.70\nw/ e 90.70 67.90 80.70 66.53 35.35 20.21 89.80 61.64 85.37 68.48 38.44 23.14\nPLJP 94.18 74.84 94.18 89.05 43.52 31.98 87.07 56.63 94.99 91.33 48.72 35.43\nTable 5: Results of ablation experiments, the best is bolded and the second best is underlined.\ning and capture the dependencies among the three\nsub-task in LJP; NeurJudge (Yue et al., 2021)\nsplits the fact description into different parts for\nmaking predictions; R-Former (Dong and Niu,\n2021) formalizes LJP as a node classification prob-\nlem over a global consistency graph and relational\nlearning is introduced; LADAN (Xu et al., 2020)\nuses graph distillation to extract discriminative fea-\ntures of the fact Retri-BERT (Chalkidis and Ke-\nmentchedjhieva, 2023) retrieves similar documents\nto augment the input document representation for\nmulti-label text classification; EPM (Feng et al.,\n2022) locates event-related information essential\nfor judgment while utilizing cross-task consistency\nconstraints among the subtasks; CTM (Liu et al.,\n2022) establishes a LJP framework with case triple\nmodeling from contrastive case relations.\nWe use the LLM baselines as follows4: Dav003\nmeans the text-davinci-003, 3.5turbo means the\ngpt-3.5-turbo. These LLMs are both from the GPT-\n3.5 family, released by OpenAI and can understand\nand generate complex natural language5.\nFor PLJP, we take the CNN and BERT as the pre-\ndictive models, and take the text-davinci-003 as the\nimplementation of the LLM, named as PLJP(CNN)\n4We give a fixed example in the prompt to help the LLMs\nunderstand the tasks.\n5https://platform.openai.com/docs/models\nand PLJP(BERT). The top-k accuracy of CNN and\nBERT is shown in the Appendix. Considering the\nlength limit of the prompt, we set the number of\nprecedents to 3.\nWe also do ablation experiments as follows:\nPLJP w/o prefers to the removal of precedents,\nand the prediction of labels is done solely based\non the candidate labels using the LLM; PLJP w/o\nc denotes we remove the candidate labels and pre-\ndict the label only with the fact description and\nprecedents; PLJP w/o dmeans we predict the\nthree labels independently instead of considering\nthe dependencies among the three subtasks; PLJP\nw/o rdenotes we find precedents based the raw fact\ninstead of from the reorganized fact; PLJP w/ e\nmeans we let the LLMs generate the explanation\nof the prediction as well.\nIn the ablation study, PLJP means PLJP(BERT).\n5.3 Experiment Settings\nHere we describe the implementation of PLJP in\nour experiments. Note all the LLMs and domain\nmodels are replaceable in the PLJP framework.\nIn the experiments, for the LLMs, we directly\nuse the APIs provided by OpenAI. For the domain\nmodels, we use the unsupervised dense retrieval\nmodel (Izacard et al., 2022) in precedent retrieval,\nwhich gets the precedents from the case database\n12066\nGiven Case\nOn June 23, 2021, defendant A leased a loader from D for the Z Project, agreeing to a monthly rent of $15,000. A signed a machinery leasing \ncontract and subsequently sold the loader the next day for $70,000. A paid a total of $32,000 in rent to D. The Price Service Center determined\nthat the deceived loader was worth $61,167.\nAround July 23, 2021, defendant A leased another loader from F for Project Z, agreeing to a monthly rent of $15,000. After towing the loader to \nE, A sold it to H on July 24 for $54,000. On July 26, 2021, A leased a Y loader from F for the same project, agreeing to a monthly rent of $15,000.\nOn the same day , A towed the vehicle to E and sold it to H for $40,000. Later, at F's request, A and F signed a loader lease contract. A paid a total\nof $28,000 in rent to F. The Price Service Center determined that the deceived loaders were worth $54,167 and $46,200, respectively.\nThe fraudulently obtained funds were used by A to settle debts, cover living expenses, and indulge in lavish spending. It was also confirmed that\ndefendant A surrendered to the public security authorities on August 3, 2021.\nCandidate labels from domain models: Contract Fraud, Fraud, Extortion\nPrecedents\nPrecedent for Extortion\nSub: Defendant A deliberately attacked victim.\nObj: Defendant A entered the home of victim\nB with a knife, beat him, and destroyed the\nproperty in B's home, causing mental and\nproperty damage.\nEx: None.\nPrecedent for Fraud\nSub: Defendant A deliberately defrauded the \nvictim for the purpose of illegal possession.\nObj: Defendant A defrauded the victim of $3,000 \non the grounds that he could apply for a driver's\nlicense and squandered the stolen money.\nEx: Defendant surrendered to the public security.\nPrecedent for Contract Fraud\nSub: Defendant A deliberately defrauded\nthe car in the name of another person.\nObj: In the process of signing the contract,\nthe defendant fraudulently used the name\nof another person to obtain 2 cars.\nEx: None.\nPredicted Judgment\nPLJP(BERT): Fraud\n✅BERT: Contract Fraud\n❌R-Former: Contract Fraud\n❌\nFigure 4: The charge prediction of a given case. The ::::green parts are useful information for prediction, while the red\nparts are content that can be confused by the domain models.\naccording to the reorganized facts. For other do-\nmain models such as TopJudge and NeurJudge, we\nuse the training settings from the original paper.\nFor the metrics, we employ Accuracy (Acc),\nMacro-Precision (Ma-P), Macro-Recall (Ma-R)\nand Macro-F1 (Ma-F).\n5.4 Experiment Results\nWe analyze the experimental results in this section.\nResult of judgment prediction: From Tab. 2,\nTab. 3 and Tab. 4, we have the following observa-\ntions: 1) The LLMs perform not well in the predic-\ntion tasks alone, especially when the label has no\nactual meaning (e.g., the index of the law article\nand prison term). 2) By applying our PLJP frame-\nwork with the collaboration of LLMs and domain\nmodels, the simple models (e.g., CNN, BERT) gain\nsignificant improvement. 3) The model perfor-\nmance on CJO22 is lower than that on CAIL2018,\nwhich shows the challenge of the newly constructed\ntest set. 4) PLJP(BERT) achieves the best perfor-\nmance in almost all the metric evaluation metrics in\nboth CAIL2018 and CJO22 test sets, which proves\nthe effectiveness of the PLJP. 5) Compared to the\nprediction of the law article and charge, the pre-\ndiction of prison term is still a more challenging\ntask. 6) The reported results of the LJP baselines\nare not as good as the original papers, this may\nbe because we keep all the low-frequency labels\ninstead of removing them as the original papers\ndid.\nResults of ablation experiment: From Tab. 5,\nwe can conclude that: 1) The performance gap\nof the PLJP w/o p and PLJP demonstrates the ef-\nfects of the precedents. 2) The results of PLJP\nw/o c prove the importance of the candidate labels.\n3) Considering the topological dependence of the\nthree sub-tasks benefits the model performance as\nPLJP w/o d shows. 4) When we use the raw fact\ninstead of the reorganized fact, the performance\ndrops (e.g., the Acc of prison term in CJO22 drops\nfrom 45.32% to 36.27%). 5) If we force the LLMs\nto generate the explanation of the prediction, the\nperformance also drops a bit. We put cases with\nexplanations in the Appendix.\nFrom Fig. 3, we can find that the performance\nof PLJP improves as the number of precedents in-\ncreases, which also proves the effectiveness of in-\njecting precedents into the LJP.\n5.5 Case Study\nFig. 4 shows an intuitive comparison among the\nthree methods in the process of charge prediction.\nBased on the fact description of the given case, the\ndomain models provide candidate charges with the\ncorresponding precedents. As the case shows, the\ndefendant made fraud by selling the cars that were\nrented from other people. However, since there\ncontains “contract” in the fact description, base-\nlines (e.g., R-Former and BERT) can be misled\nand predict the wrong charge of “Contract Fraud”.\nThrough an in-context precedent comprehension\nby the LLMs, PLJP(BERT) distinguishes the dif-\n12067\nferences among the precedents and the given case\n(e.g., the crime does not occur during the contract-\ning process, and the contract is only a means to\ncommit the crime), and give the right result of\n“Fraud”.\n6 Conclusion and Future Work\nIn this paper, we address the important task of le-\ngal judgment prediction (LJP) by taking precedents\ninto consideration. We propose a novel framework\ncalled precedent-enhanced legal judgment predic-\ntion (PLJP), which combines the strength of both\nLLMs and domain models to better utilize (e.g.,\nretrieve and comprehend) the precedents. Experi-\nments on the real-world dataset prove the effective-\nness of the PLJP.\nBased on the PLJP, in the future, we can ex-\nplore the following directions: 1) Develop methods\nto identify and mitigate any biases that could af-\nfect the predictions and ensure fair and equitable\noutcomes. 2) Validate the effectiveness of LLM\nand domain collaboration in other vertical domains\nsuch as medicine and education.\n6.1 Ethical Discussion\nWith the increasing adoption of Legal AI in the field\nof legal justice, there has been a growing awareness\nof the ethical implications involved. The potential\nfor even minor errors or biases in AI-powered sys-\ntems can lead to significant consequences.\nIn light of these concerns, we have to claim that\nour work is an algorithmic exploration and will not\nbe directly used in court so far. Our goal is to pro-\nvide suggestions to judges rather than making final\njudgments without human intervention. In practi-\ncal use, human judges should be the final safeguard\nto protect justice fairness. In the future, we plan to\nstudy how to identify and mitigate potential biases\nto ensure the fairness of the model.\n7 Limitations\nIn this section, we discuss the limitations of our\nworks as follow:\n•We only interact with the LLMs one round\nper time. The LLMs are capable of multi-round\ninteraction (e.g., Though of Chains), which may\nhelp the LLM to better understand the LJP task.\n•We validate the effectiveness of LLM and do-\nmain model collaboration in the legal domain. It’s\nworthwhile to explore such collaboration in other\nvertical domains such as medicine and education,\nas well as in other legal datasets (e.g., the datasets\nfrom the Common Law system).\nAcknowledgments\nThis work was supported in part by National\nKey Research and Development Program of\nChina (2022YFC3340900), National Natural Sci-\nence Foundation of China (62037001, 62376243,\nU20A20387), the StarryNight Science Fund\nof Zhejiang University Shanghai Institute for\nAdvanced Study (SN-ZJU-SIAS-0010), Young\nElite Scientists Sponsorship Program by CAST\n(2021QNRC001), Project by Shanghai AI Lab-\noratory (P22KS00111), Program of Zhejiang\nProvince Science and Technology (2022C01044),\nFundamental Research Funds for the Central\nUniversities (226-2023-00060), Key Research\nand Development Program of Zhejiang Province\n(2021C01013).\nFinally, we would like to thank the anonymous\nreviewers for their helpful feedback and sugges-\ntions.\nReferences\nSophia Althammer, Arian Askari, Suzan Verberne,\nand Allan Hanbury. 2021. Dossier@coliee 2021:\nLeveraging dense retrieval and summarization-\nbased re-ranking for case law retrieval. CoRR,\nabs/2108.03937.\nTrevor J. M. Bench-Capon, Michal Araszkiewicz,\nKevin D. Ashley, Katie Atkinson, Floris Bex, Filipe\nBorges, Danièle Bourcier, Paul Bourgine, Jack G.\nConrad, Enrico Francesconi, Thomas F. Gordon,\nGuido Governatori, Jochen L. Leidner, David D.\nLewis, Ronald Prescott Loui, L. Thorne McCarty,\nHenry Prakken, Frank Schilder, Erich Schweighofer,\nPaul Thompson, Alex Tyrrell, Bart Verheij, Dou-\nglas N. Walton, and Adam Z. Wyner. 2012. A history\nof AI and law in 50 papers: 25 years of the interna-\ntional conference on AI and law. Artif. Intell. Law,\n20(3):215–319.\nPaheli Bhattacharya, Kaustubh Hiware, Subham Raj-\ngaria, Nilay Pochhi, Kripabandhu Ghosh, and Sap-\ntarshi Ghosh. 2019. A comparative study of summa-\nrization algorithms applied to legal case judgments.\nIn Advances in Information Retrieval - 41st European\nConference on IR Research, ECIR 2019, Cologne,\nGermany, April 14-18, 2019, Proceedings, Part I ,\nvolume 11437 of Lecture Notes in Computer Science,\npages 413–428. Springer.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\n12068\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nCristian Cardellino, Milagro Teruel, Laura Alonso Ale-\nmany, and Serena Villata. 2017. Legal NERC with\nontologies, wikipedia and curriculum learning. In\nProceedings of the 15th Conference of the European\nChapter of the Association for Computational Lin-\nguistics, EACL 2017, Valencia, Spain, April 3-7,\n2017, Volume 2: Short Papers, pages 254–259. Asso-\nciation for Computational Linguistics.\nIlias Chalkidis, Ion Androutsopoulos, and Nikolaos\nAletras. 2019. Neural legal judgment prediction in\nenglish. In Proceedings of the 57th Conference of\nthe Association for Computational Linguistics, ACL\n2019, Florence, Italy, July 28- August 2, 2019, Vol-\nume 1: Long Papers, pages 4317–4323. Association\nfor Computational Linguistics.\nIlias Chalkidis, Manos Fergadiotis, Prodromos Malaka-\nsiotis, Nikolaos Aletras, and Ion Androutsopoulos.\n2020. LEGAL-BERT: the muppets straight out of\nlaw school. CoRR, abs/2010.02559.\nIlias Chalkidis, Abhik Jana, Dirk Hartung, Michael\nJ. Bommarito II, Ion Androutsopoulos, Daniel Mar-\ntin Katz, and Nikolaos Aletras. 2022. Lexglue: A\nbenchmark dataset for legal language understanding\nin english. In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), ACL 2022, Dublin, Ireland,\nMay 22-27, 2022, pages 4310–4330. Association for\nComputational Linguistics.\nIlias Chalkidis and Yova Kementchedjhieva. 2023.\nRetrieval-augmented multi-label text classification.\nCoRR, abs/2305.13058.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA,\nJune 2-7, 2019, Volume 1 (Long and Short Papers),\npages 4171–4186. Association for Computational\nLinguistics.\nQian Dong and Shuzi Niu. 2021. Legal judgment predic-\ntion via relational learning. In SIGIR ’21: The 44th\nInternational ACM SIGIR Conference on Research\nand Development in Information Retrieval, Virtual\nEvent, Canada, July 11-15, 2021 , pages 983–992.\nACM.\nYuqing Du, Olivia Watkins, Zihan Wang, Cédric Co-\nlas, Trevor Darrell, Pieter Abbeel, Abhishek Gupta,\nand Jacob Andreas. 2023. Guiding pretraining in\nreinforcement learning with large language models.\nCoRR, abs/2302.06692.\nYi Feng, Chuanyi Li, and Vincent Ng. 2022. Legal\njudgment prediction: A survey of the state of the art.\nIn Proceedings of the Thirty-First International Joint\nConference on Artificial Intelligence, IJCAI 2022,\nVienna, Austria, 23-29 July 2022, pages 5461–5469.\nijcai.org.\nVincy Fon and Francesco Parisi. 2006. Judicial prece-\ndents in civil law systems: A dynamic analysis. Inter-\nnational Review of Law and Economics, 26(4):519–\n535.\nLeilei Gan, Baokui Li, Kun Kuang, Yi Yang, and Fei Wu.\n2022. Exploiting contrastive learning and numerical\nevidence for improving confusing legal judgment\nprediction. CoRR, abs/2211.08238.\nBryan A. Garner. 2001. A dictionary of modern legal\nusage. Oxford University Press, New York.\nYingqiang Ge, Wenyue Hua, Jianchao Ji, Juntao Tan,\nShuyuan Xu, and Yongfeng Zhang. 2023. Ope-\nnagi: When LLM meets domain experts. CoRR,\nabs/2304.04370.\nGilbert Guillaume. 2011. The use of precedent by inter-\nnational judges and arbitrators. Journal of Interna-\ntional Dispute Settlement, 2(1):5–23.\nBen Hachey and Claire Grover. 2006. Extractive sum-\nmarisation of legal texts. Artif. Intell. Law, 14(4):305–\n345.\nGautier Izacard, Mathilde Caron, Lucas Hosseini, Se-\nbastian Riedel, Piotr Bojanowski, Armand Joulin,\nand Edouard Grave. 2022. Unsupervised dense in-\nformation retrieval with contrastive learning. Trans.\nMach. Learn. Res., 2022.\nDaniel Martin Katz, Dirk Hartung, Lauritz Gerlach,\nAbhik Jana, and Michael J Bommarito II. 2023. Nat-\nural language processing in the legal domain. arXiv\npreprint arXiv:2302.12039.\nR Keown. 1980. Mathematical models for legal predic-\ntion. Computer/lj, 2:829.\nKarl Larenz. 1992. Methodenlehre der Rechtswis-\nsenschaft. Springer, Berlin, Heidelberg.\nYann LeCun, Bernhard E. Boser, John S. Denker, Don-\nnie Henderson, Richard E. Howard, Wayne E. Hub-\nbard, and Lawrence D. Jackel. 1989. Backpropa-\ngation applied to handwritten zip code recognition.\nNeural Comput., 1(4):541–551.\nMengze Li, Han Wang, Wenqiao Zhang, Jiaxu Miao,\nZhou Zhao, Shengyu Zhang, Wei Ji, and Fei Wu.\n2023. WINNER: weakly-supervised hierarchical de-\ncomposition and alignment for spatio-temporal video\n12069\ngrounding. In IEEE/CVF Conference on Computer\nVision and Pattern Recognition, CVPR 2023, Vancou-\nver, BC, Canada, June 17-24, 2023 , pages 23090–\n23099. IEEE.\nMengze Li, Tianbao Wang, Haoyu Zhang, Shengyu\nZhang, Zhou Zhao, Jiaxu Miao, Wenqiao Zhang,\nWenming Tan, Jin Wang, Peng Wang, Shiliang Pu,\nand Fei Wu. 2022a. End-to-end modeling via in-\nformation tree for one-shot natural language spatial\nvideo grounding. In Proceedings of the 60th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), ACL 2022, Dublin,\nIreland, May 22-27, 2022, pages 8707–8717. Associ-\nation for Computational Linguistics.\nMengze Li, Tianbao Wang, Haoyu Zhang, Shengyu\nZhang, Zhou Zhao, Wenqiao Zhang, Jiaxu Miao,\nShiliang Pu, and Fei Wu. 2022b. HERO: hierarchical\nspatio-temporal reasoning with contrastive action cor-\nrespondence for end-to-end video object grounding.\nIn MM ’22: The 30th ACM International Conference\non Multimedia, Lisboa, Portugal, October 10 - 14,\n2022, pages 3801–3810. ACM.\nWan-Chen Lin, Tsung-Ting Kuo, Tung-Jia Chang,\nChueh-An Yen, Chao-Ju Chen, and Shou-de Lin.\n2012. Exploiting machine learning models for chi-\nnese legal documents labeling, case classification,\nand sentencing prediction. Int. J. Comput. Linguis-\ntics Chin. Lang. Process., 17(4).\nDugang Liu, Weihao Du, Lei Li, Weike Pan, and Zhong\nMing. 2022. Augmenting legal judgment prediction\nwith contrastive case relations. In Proceedings of\nthe 29th International Conference on Computational\nLinguistics, COLING 2022, Gyeongju, Republic of\nKorea, October 12-17, 2022, pages 2658–2667. Inter-\nnational Committee on Computational Linguistics.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized BERT pretraining\napproach. CoRR, abs/1907.11692.\nBingfeng Luo, Yansong Feng, Jianbo Xu, Xiang Zhang,\nand Dongyan Zhao. 2017. Learning to predict\ncharges for criminal cases with legal basis. In Pro-\nceedings of the 2017 Conference on Empirical Meth-\nods in Natural Language Processing, EMNLP 2017,\nCopenhagen, Denmark, September 9-11, 2017, pages\n2727–2736. Association for Computational Linguis-\ntics.\nYougang Lyu, Zihan Wang, Zhaochun Ren, Pengjie Ren,\nZhumin Chen, Xiaozhong Liu, Yujun Li, Hongsong\nLi, and Hongye Song. 2022. Improving legal judg-\nment prediction through reinforced criminal element\nextraction. Inf. Process. Manag., 59(1):102780.\nYixiao Ma, Yunqiu Shao, Bulou Liu, Yiqun Liu, Min\nZhang, and Shaoping Ma. 2021. Retrieving legal\ncases from a large-scale candidate corpus. Proceed-\nings of the Eighth International Competition on Legal\nInformation Extraction/Entailment, COLIEE2021.\nVijit Malik, Rishabh Sanjay, Shubham Kumar Nigam,\nKripabandhu Ghosh, Shouvik Kumar Guha, Arnab\nBhattacharya, and Ashutosh Modi. 2021. ILDC for\nCJPE: indian legal documents corpus for court judg-\nment prediction and explanation. In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing,\nACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual\nEvent, August 1-6, 2021, pages 4046–4062. Associa-\ntion for Computational Linguistics.\nAlfredo Monroy, Hiram Calvo, and Alexander F. Gel-\nbukh. 2009. NLP for shallow question answering\nof legal documents using graphs. In Computational\nLinguistics and Intelligent Text Processing, 10th In-\nternational Conference, CICLing 2009, Mexico City,\nMexico, March 1-7, 2009. Proceedings, volume 5449\nof Lecture Notes in Computer Science , pages 498–\n508. Springer.\nJoel Niklaus, Ilias Chalkidis, and Matthias Stürmer.\n2021. Swiss-judgment-prediction: A multilin-\ngual legal judgment prediction benchmark. CoRR,\nabs/2110.00806.\nAdam Rigoni. 2014. Common-law judicial reasoning\nand analogy. Legal Theory, 20(2):133–156.\nM. Saravanan, Balaraman Ravindran, and S. Raman.\n2009. Improving legal information retrieval using an\nontological framework. Artif. Intell. Law, 17(2):101–\n124.\nZhenwei Shao, Zhou Yu, Meng Wang, and Jun Yu. 2023.\nPrompting large language models with answer heuris-\ntics for knowledge-based visual question answering.\nCoRR, abs/2303.01903.\nKai Shen, Yichong Leng, Xu Tan, Siliang Tang, Yuan\nZhang, Wenjie Liu, and Edward Lin. 2022. Mask the\ncorrect tokens: An embarrassingly simple approach\nfor error correction. In Proceedings of the 2022 Con-\nference on Empirical Methods in Natural Language\nProcessing, EMNLP 2022, Abu Dhabi, United Arab\nEmirates, December 7-11, 2022, pages 10367–10380.\nAssociation for Computational Linguistics.\nOctavia-Maria Sulea, Marcos Zampieri, Shervin Mal-\nmasi, Mihaela Vela, Liviu P. Dinu, and Josef van Gen-\nabith. 2017. Exploring the use of text classification in\nthe legal domain. In Proceedings of the Second Work-\nshop on Automated Semantic Analysis of Information\nin Legal Texts co-located with the 16th International\nConference on Artificial Intelligence and Law (ICAIL\n2017), London, UK, June 16, 2017, volume 2143 of\nCEUR Workshop Proceedings. CEUR-WS.org.\nZhongxiang Sun. 2023. A short survey of view-\ning large language models in legal aspect. CoRR,\nabs/2303.09136.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\n12070\nAzhar, Aurélien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. CoRR,\nabs/2302.13971.\nChenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong\nWang, Zecheng Tang, and Nan Duan. 2023. Visual\nchatgpt: Talking, drawing and editing with visual\nfoundation models. CoRR, abs/2303.04671.\nLinjuan Wu, Shaojuan Wu, Xiaowang Zhang, Deyi\nXiong, Shizhan Chen, Zhiqiang Zhuang, and Zhiy-\nong Feng. 2022. Learning disentangled semantic\nrepresentations for zero-shot cross-lingual transfer\nin multilingual machine reading comprehension. In\nProceedings of the 60th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), ACL 2022, Dublin, Ireland, May 22-\n27, 2022, pages 991–1000. Association for Computa-\ntional Linguistics.\nYiquan Wu, Kun Kuang, Yating Zhang, Xiaozhong Liu,\nChanglong Sun, Jun Xiao, Yueting Zhuang, Luo Si,\nand Fei Wu. 2020. De-biased court’s view generation\nwith causality. In Proceedings of the 2020 Confer-\nence on Empirical Methods in Natural Language\nProcessing, EMNLP 2020, Online, November 16-20,\n2020, pages 763–780. Association for Computational\nLinguistics.\nNuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan\nWang, and Junzhou Zhao. 2020. Distinguish con-\nfusing law articles for legal judgment prediction. In\nProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics, ACL 2020,\nOnline, July 5-10, 2020, pages 3086–3095. Associa-\ntion for Computational Linguistics.\nLinan Yue, Qi Liu, Binbin Jin, Han Wu, Kai Zhang,\nYanqing An, Mingyue Cheng, Biao Yin, and Day-\nong Wu. 2021. Neurjudge: A circumstance-aware\nneural framework for legal judgment prediction. In\nSIGIR ’21: The 44th International ACM SIGIR Con-\nference on Research and Development in Information\nRetrieval, Virtual Event, Canada, July 11-15, 2021,\npages 973–982. ACM.\nWenqi Zhang, Yongliang Shen, Weiming Lu, and Yuet-\ning Zhuang. 2023. Data-copilot: Bridging billions of\ndata and humans with autonomous workflow. CoRR,\nabs/2306.07209.\nWenqi Zhang, Kai Zhao, Peng Li, Xiao Zhu, Yongliang\nShen, Yanna Ma, Yingfeng Chen, and Weiming Lu.\n2022. A closed-loop perception, decision-making\nand reasoning mechanism for human-like naviga-\ntion. In Proceedings of the Thirty-First International\nJoint Conference on Artificial Intelligence, IJCAI-22,\npages 4717–4724. International Joint Conferences on\nArtificial Intelligence Organization. Main Track.\nWayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\nXiaolei Wang, Yupeng Hou, Yingqian Min, Be-\nichen Zhang, Junjie Zhang, Zican Dong, Yifan Du,\nChen Yang, Yushuo Chen, Zhipeng Chen, Jinhao\nJiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang\nLiu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.\n2023. A survey of large language models. CoRR,\nabs/2303.18223.\nHaoxi Zhong, Zhipeng Guo, Cunchao Tu, Chaojun Xiao,\nZhiyuan Liu, and Maosong Sun. 2018. Legal judg-\nment prediction via topological learning. In Proceed-\nings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, Brussels, Belgium,\nOctober 31 - November 4, 2018, pages 3540–3549.\nAssociation for Computational Linguistics.\nHaoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang\nZhang, Zhiyuan Liu, and Maosong Sun. 2020. How\ndoes NLP benefit legal system: A summary of le-\ngal artificial intelligence. In Proceedings of the\n58th Annual Meeting of the Association for Com-\nputational Linguistics, ACL 2020, Online, July 5-10,\n2020, pages 5218–5230. Association for Computa-\ntional Linguistics.\nA Appendices\nA.1 Top-k Accuracy\n80.50 \n91.20 93.52 94.88 95.28 \n87.52 \n94.48 95.84 97.12 97.92 \n34.42 \n53.04 \n66.56 78.56 \n88.16 \n0.00\n10.00\n20.00\n30.00\n40.00\n50.00\n60.00\n70.00\n80.00\n90.00\n100.00\n1 2 3 4 5\nTop-k \nLaw Article Charge Prison Term\nAcc CAIL2018\nFigure 5: The top-k accuracy of CNN on CAIL dataset.\n76.14 \n84.39 87.51 89.22 90.28 \n74.91 \n85.10 88.16 90.28 91.87 \n27.38 \n44.88 \n61.25 71.97 \n81.39 \n0.00\n10.00\n20.00\n30.00\n40.00\n50.00\n60.00\n70.00\n80.00\n90.00\n100.00\n1 2 3 4 5Top-k\nLaw Article Charge Prison Term\nCJO22Acc\nFigure 6: The top-k accuracy of CNN on CJO22 dataset.\n12071\n82.77 93.04 95.20 96.00 96.64 \n89.10 95.12 96.32 97.36 97.76 \n40.00 65.20 \n80.32 89.28 94.96 \n0.00\n10.00\n20.00\n30.00\n40.00\n50.00\n60.00\n70.00\n80.00\n90.00\n100.00\n1 2 3 4 5Top-k\nLaw Article Charge Prison Term\nCAIL2018Acc\nFigure 7: The top-k accuracy of BERT on CAIL dataset.\n82.62 \n90.16 93.17 94.58 \n95.23 \n80.50 \n89.58 92.87 94.17 \n95.11 \n36.80 \n59.42 73.79 \n85.45 92.40 \n0.00\n10.00\n20.00\n30.00\n40.00\n50.00\n60.00\n70.00\n80.00\n90.00\n100.00\n1 2 3 4 5Top-k \nLaw Article Charge Prison Term\nCJO22Acc\nFigure 8: The top-k accuracy of BERT on CJO22\ndataset.\nA.2 More Show Cases\n12072\nGiven Case\nAt about 19:00 on September 12, 2021, when defendant A was driving a two-wheeled motorcycle along National Highway 106 from south to north to the road in\nfront of Hotel C, he hit pedestrian B who was crossing the road from east to west in front, causing B severe head injury, and later B died after ineffective \ntreatment. The D County Traffic Police Brigade determined that A was primarily responsible for the accident. After the case, defendant A immediately reported\nthe case and waited at the scene for the traffic police to come and deal with it. Later, defendant A reached a compensation agreement with the victim‘s relatives,\ncompensating the victim’s relatives for economic losses of $260,000 in one lump sum, and obtained the understanding of the victim's relatives.\nCandidate labels from domain models: Causing Traffic Casualties, Dangerous Driving, Involuntary Manslaughter\nPrecedents\nPrecedent for Causing Traffic Casualties\nSub: Defendant A drove a decked two-wheeled \nmotorcycle without a license after drinking\nalcohol, and failed to drive safely in accordance\nwith the operating specifications, resulting in the\ndeath of a pedestrian.\nObj: Defendant A drove a two-wheeled\nmotorcycle under the influence of alcohol, drove\neast to west along the X route of C City to the\nsection of Z Village in Y Town, C City,and injured \npedestrian B walking in the same direction and \ndied after ineffective rescue.\nEx: None.\nPrecedent for Dangerous Driving\nSub: Defendant A was driving a gray Chevrolet \nminibus under the influence of alcohol and collided.\nObj: Defendant A's blood alcohol content was\n151.4mg/100ml, and he was seized by the police on\nthe spot.\nEx: After the case, defendant A and B reached a\nmediation agreement on civil compensation.\nPrecedent for Involuntary Manslaughter\nSub: Defendant A drove a two-wheeled motorcycle \nalong National Highway 206 from north to south\nand hit pedestrian B.\nObj: Defendant A knocked B to the ground, and\nthen A sent B to the hospital. B died after\nineffective rescue, and after forensic physical\nexamination, B died of severe head injury.\nEx: Defendant A voluntarily surrendered to the C\nBranch of the D City Public Security Bureau, and\nhis punishment can be mitigated according to law.\nPredicted Judgment\nR-Former BERT PLJP(BERT)\nDangerous Driving\n❌ Dangerous Driving\n❌ Causing Traffic Casualties\n✅\nFigure 9: More case 1.\nGiven Case\nAround January 2021, without obtaining a forest harvesting permit, defendant A hired personnel to harvest the trees located in his own mountain farm next to \nthe \"Great Waterfall\" in B Village, C Town, D  County, and used the felled trees to build houses and sell them. Among them, the total profit from the sale of\nfelled trees was about $2,000. A total of 14.149 cubic meters of trees were identified as being harvested. On November 9, 2021, defendant A voluntarily\nsurrendered to the E Police Station of D County after being notified by the police handling the case.\nCandidate labels from domain models:Illegal Denudation, Illegal Lumbering, Illegal Occupation of Agricultural Land\nPrecedents\nPrecedent for Illegal Denudation\nSub: Defendant A cut down trees protected by the \nstate without the approval of the forestry \nauthorities.\nObj: Defendant A did not apply for a forest\nharvesting permit, and cut down trees in the\n\"Beofu Mountain\" of in B Villag e,C Town, with a\ntotal area of 4.5 acres of trees cut down and a total \nof 20.8702 cubic meters of standing wood \naccumulation.\nEx: Defendant A voluntarily surrenders after\ncommitting a crime and truthfully confesses his\ncrime, which is a voluntary surrender, and the\npunishment can be mitigated according to law.\nPrecedent for Illegal Lumbering\nSub: Defendant A intentionally committed the\ncrime for the purpose of illegal possession.\nObj: Defendant A falsely claimed that 328 poplar\ntrees located in the northeast of X Village, Y Town,\nZ County, owned by himself, sold the above-\nmentioned poplars to E, and then felled them at a \nprice of  $6,600, with a standing log accumulation \nof 15.7987 cubic meters and a total value of\n$12,068.\nEx: None.\nPrecedent for Illegal Occupation of Agricultural \nLand\nSub: Defendant A illegally reclaimed forest land\nwithout obtaining legal formalities.\nObj: Defendant A illegally reclaimed 10.05 acres\nof forest land in the Willow River Forest Farm\nApplication Area of the B Forestry Bureau.\nEx: Defendant A's confession and defense and\nevidence such as the on-site investigation records\nof the B Branch of the C Public Security Bureau\nconfirmed that it was recommended that the\npunishment be mitigated according to law.\nPredicted Judgment\nR-Former BERT PLJP\nIllegal Denudation\n✅ Illegal Lumbering\n❌ Illegal Denudation\n✅\nFigure 10: More case 2.\n12073\nGiven Case\nAt about 18:27 on December 1, 2021, defendant A drove a small ordinary bus from west to east along Wenhua Road, Qingshan District, Baotou City to a point 150 meters west of the \nintersection of Wenhua Road and Yingbin Road (the east side of the front of Qingshan Hotel) pedestrian crossing) and collided with the victim B who was riding an electric bicycle \nacross the road from north to south, resulting in the death of B on the spot. After the accident, defendant A dialed 120 emergency number and 122 alarm number to call the police, and\nwaited for the arrival of the traffic police at the scene. According to the forensic autopsy examination and identification of Baotou Public Security Traffic Judicial Appraisal Center, B\ndied of severe craniocerebral injury caused by a traffic accident. According to the determination of the road traffic accident by the Qingshan Brigade of the Baotou Traffic Management\nDetachment, the defendant A bears full responsibility for the accident, and B has no responsibility for the accident. It was also found that the small ordinary passenger car that caused the\naccident had purchased compulsory motor vehicle traffic accident liability insurance and motor vehicle third party liability insurance at Baotou City Center Sub-branch of Inner\nMongolia Branch of a certain property insurance company, and the accident occurred within the insurance period. . It was also found out that after the accident, defendant A had paid\n$40,000 for the funeral expenses of the family members of the victim. It was further found that defendant A voluntarily prepaid compensation of $10,000 to this court during the trial\nperiod.\nPredicted Judgment and Explanation\nLaw Article Charge Prison Term\nLaw article truth: 133 \nLaw article prediction: Article 133. Because of the facts of\nthe case enclosed by <>, defendant A drove a small\nordinary bus along Wenhua Road from west to east to 150\nmeters west of the intersection of Wenhua Road and\nYingbin Road, and met the victim B who was riding an\nelectric bicycle across the road from north to south. If two \npeople collided and violated traffic management  \nregulations, thereby causing injury or death to the victim, \nit constitutes the crime of causing a traffic accident \naccording to law, so the corresponding legal article in this \ncase should be Article 133.\nCharge truth: Causing traffic casualties\nCharge prediction: Causing traffic accident. Since the three\ntypes of cases all show that the defendant did not drive the \nvehicle in accordance with traffic safety regulations, thus \ncausing a traffic accident and directly causing the death of \nthe victim on the spot, the crime of causing a traffic \naccident can be selected in this case, which is in line with\nArticle 133 of the \"Criminal Law of the People's Republic\nof China\". Article 133 stipulates: \"Whoever drives a motor\nvehicle carelessly and the circumstances are serious shall be\nsentenced to fixed-term imprisonment of not more than\nthree years or criminal detention, and shall also be fined.\"\nPrison term truth:17 months\nPrison term prediction: One to two years in prison. Since \nthe driver in this case did not follow the traffic rules and \nlost his correct judgment, the victim died on the spot, and \nthe crime was serious, so a longer sentence should be \nimposed, so he chose a fixed-term imprisonment of one to\ntwo years. Precedents also support the adoption of a fixed-\nterm imprisonment of one to two years in this case. The \ncrimes of two of the three precedents are all lighter than this \ncase, and they are all sentenced to a correspondingly shorter \nsentence, which proves that a longer sentence should be \nadopted in this case to achieve the disciplinary effect.\nFigure 11: Case with explanations 1.\nGiven Case\nIn the early morning of March 11, 2022, defendant A drove a car carrying B, C, D and others in the county seat, and then defendant A left B, C, and D in the car he was driving to smoke \nthe drug ketamine on the back seat. At about 10:00 on March 18, 2022, defendant A was arrested at a milk tea shop in Rucheng County, and later truthfully confessed the above facts.\nPredicted Judgment and Explanation\nLaw Article Charge Prison Term\nLaw article truth: 354\nLaw article prediction: Article 354. Compared with  \nprecedents, the subjective motive of this case is to allow \nothers to take drugs, and the objective behavior is to takes \nthe drug ketamine. The behaviors involved are all \n\"allowing others to take drugs\", so the applicable legal \nprovisions For Article 354, the reason is that the law \ninvolves the penalties for drug detention. The difference\nfrom this case is that precedents involved drunk driving\n(Article 133) or mob fighting (Article 292), and the\nextraneous circumstances were not exactly the same, so\nthe applicable laws and regulations were different from\nthis case.\nCharge truth: Providing venues for drug users\nCharge prediction: Providing venues for drug users.\nComparing the three aspects of subjective motivation,\nobjective behavior, and incidental circumstances, it can be\nseen that defendant A's subjective motivation was \nintentional, and his objective behavior was to allow others \nto take drugs. The circumstances outside the incident are\ndifferent. In this case, defendant A can be given a lighter\npunishment according to law after being brought to justice.\nFrom this, it can be judged that the defendant in this case\nwas charged with allowing others to take drugs.\nPrison term truth: 7 months\nPrison term prediction: Six to nine months in prison. The\nobjective behavior of this case is clear. The vehicle driven\nby defendant A carried poisonous substances; in addition, \nthe subjective motive and extraneous circumstances of this \ncase are more in line with the original intention of a lighter \npunishment than precedents. After being arrested and\nbrought to justice, defendant A truthfully confessed his\ncrime. Therefore, the sentence in this case was chosen as\nfixed-term imprisonment of six to nine months.\nFigure 12: Case with explanations 2.\n12074\nGiven Case\nIn March 2019, when defendant A and victim B dated in the name of boyfriend and girlfriend, from March to September 2019, A demanded money from B on the grounds of helping B \nto transfer work and handling matters such as customs seizure , B delivered a total of $129,028  to A through WeCh at, Alipay transfer and cash payment, and most of the money was used \nby A for personal squandering. When B asked for repayment, A shirked on the grounds of being hospitalized and deactivating the account. In April 2019, defendant A lied to victim C \nthat he could help deal with C‘s husband Shi Moumou’s drunk driving, and demanded money from C in the name of dredging the relationship. C transfers a total of $9,000  to A through \nWeChat, which is used by A for personal consumption. When C asked for repayment, A forged the record of repayment to C‘s WeChat and blacklisted C’s WeChat. On March 5, 2020, A\nreturned $9,000 to the victim C. It was also found that because defendant A suffered from a serious illness, the Rencheng District People‘s Court of Jining City sentenced defendant A to\nsix months’ imprisonment, which has not yet been executed. It was further found that on March 15, 2022, defendant A paid victim B $120,000 in cash and issued a bill signed in\nacknowledgement of debt, which recorded “A voluntarily paid victim B $129,000 , and paid $120,000 in cash first, and owed $9,000 was paid off in four months, $2,000 was paid every\nmonth for the first three months, and the last $3000 was paid off before July 15, 2022.” Victim B issued a letter of understanding, expressing his respect for A's behavior. Forgive me and\nagree to a lighter punishment. Defendant A voluntarily pleaded guilty and accepted punishment, and had no objection to the facts, charges and sentencing recommendations of the public\nprosecution agency. The defender has no objection to the alleged criminal facts and charges, but believes that defendant A confessed the facts of the case before taking compulsory\nmeasures, which constitutes surrender and confession; A's fraudulent behavior occurred in the process of dating, and the subjective viciousness is relatively small and the harm is not\ngreat ; The amount of suspected fraud is not clear. According to the principle of lenient crime, the statutory penalty of \"huge amount\" should not be applied. It is recommended that the\ndefendant be exempted from criminal punishment under the circumstances of surrendering himself, actively compensating the victim and obtaining forgiveness.\nPredicted Judgment and Explanation\nLaw Article Charge Prison Term\nLaw article truth: 266\nLaw article prediction: Article 266, because the defendant\nin this case took the means of fraudulently using another\nperson's account number, fictitious facts and concealing\nthe truth to obtain other people's property in a large\namount, the provisions of the said article 266 apply. In the \ncontent of the precedents, in the first case, the defendant \nused the means of proposing fictitious facts to cheat money, \nin the second case, the defendant used the fraudulent use \nof other people's accounts credit card to demand money \nowed, and in the third case, the defendant used the means \nof fraudulent use of other people's accounts to cheat, so \nthis case and the three precedents all involve cheating \nproperty, and the acts in the three cases are mainly fraud,  \nso the provisions of article 266 are also applicable to this \ncase.\nCharge truth: Fraud\nCharge prediction: Fraud. Because both this case and the\nprecedents were established by the defendant with the\npurpose of unlawful possession, the act of taking possession\nof money by fictitious facts and concealing the truth are\nfraudulent. This case and the precedents both take the \napparently normal means, such as using credit cards to \nobtain property, both constitute fraud.\nPrison term truth: 36 months.\nPrison term prediction: Tw oto three years in prison. From \nthe above three categories of cases, it can be seen that the \nsubjective motive of the defendant as well as the objective \nbehavior is basically the same as this case, and the \nextraneous circumstances of the defendant in this case are \nalso more prominent than them. The defendant recognized\nthe amount of fraud, truthfully confessed to the crime,\ncooperated with the investigation and confessed the facts,\nwhich can be used as mitigating factors in the sentence, so\nthe sentence of the defendant in this case is chosen to be\ntwo to three years in prison, and the other two categories of\ncases also have the same sentence. However, fine\nadjustments should be made according to the actual\ncircumstances.\nFigure 13: Case with explanations 3.\n12075",
  "topic": "Zhàng",
  "concepts": [
    {
      "name": "Zhàng",
      "score": 0.7485340237617493
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5028414130210876
    },
    {
      "name": "Computer science",
      "score": 0.4954613447189331
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3995485007762909
    },
    {
      "name": "China",
      "score": 0.24503561854362488
    },
    {
      "name": "Law",
      "score": 0.23375725746154785
    },
    {
      "name": "Political science",
      "score": 0.19733071327209473
    },
    {
      "name": "Mathematics",
      "score": 0.16786321997642517
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I76130692",
      "name": "Zhejiang University",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I107077323",
      "name": "Worcester Polytechnic Institute",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I45928872",
      "name": "Alibaba Group (China)",
      "country": "CN"
    }
  ],
  "cited_by": 20
}