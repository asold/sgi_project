{
  "title": "Learning to Cluster Faces via Transformer",
  "url": "https://openalex.org/W3157111614",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5047734371",
      "name": "Jinxing Ye",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5033413473",
      "name": "Xiaojiang Peng",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5087131650",
      "name": "Baigui Sun",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5100647321",
      "name": "Kai Wang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5102803552",
      "name": "Xiuyu Sun",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5100348588",
      "name": "Hao Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5058267712",
      "name": "Hanqing Wu",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2150593711",
    "https://openalex.org/W1673310716",
    "https://openalex.org/W2117831564",
    "https://openalex.org/W2736633948",
    "https://openalex.org/W2965744772",
    "https://openalex.org/W2341251094",
    "https://openalex.org/W2963757395",
    "https://openalex.org/W2533545350",
    "https://openalex.org/W2964074409",
    "https://openalex.org/W2963839617",
    "https://openalex.org/W2022686119",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W3035669277",
    "https://openalex.org/W1854214752",
    "https://openalex.org/W2144767994",
    "https://openalex.org/W2194775991",
    "https://openalex.org/W1509966554",
    "https://openalex.org/W2089620427",
    "https://openalex.org/W2142838865",
    "https://openalex.org/W65834064",
    "https://openalex.org/W2121947440",
    "https://openalex.org/W2007444087",
    "https://openalex.org/W2889960480",
    "https://openalex.org/W2515770085",
    "https://openalex.org/W3099206234",
    "https://openalex.org/W2600975432",
    "https://openalex.org/W2165232124",
    "https://openalex.org/W2471768434",
    "https://openalex.org/W2120636855",
    "https://openalex.org/W3035028247",
    "https://openalex.org/W2799118171",
    "https://openalex.org/W1677182931",
    "https://openalex.org/W2072240081",
    "https://openalex.org/W2969985801",
    "https://openalex.org/W2888919236",
    "https://openalex.org/W2930556772",
    "https://openalex.org/W2155162820",
    "https://openalex.org/W2742503211"
  ],
  "abstract": "Face clustering is a useful tool for applications like automatic face annotation and retrieval. The main challenge is that it is difficult to cluster images from the same identity with different face poses, occlusions, and image quality. Traditional clustering methods usually ignore the relationship between individual images and their neighbors which may contain useful context information. In this paper, we repurpose the well-known Transformer and introduce a Face Transformer for supervised face clustering. In Face Transformer, we decompose the face clustering into two steps: relation encoding and linkage predicting. Specifically, given a face image, a \\textbf{relation encoder} module aggregates local context information from its neighbors and a \\textbf{linkage predictor} module judges whether a pair of images belong to the same cluster or not. In the local linkage graph view, Face Transformer can generate more robust node and edge representations compared to existing methods. Experiments on both MS-Celeb-1M and DeepFashion show that our method achieves state-of-the-art performance, e.g., 91.12\\% in pairwise F-score on MS-Celeb-1M.",
  "full_text": "Learning to Cluster Faces via Transformer\nJinxing Ye‚àó1, Xiaojiang Peng*2, Baigui Sun1, Kai Wang1,3, Xiuyu Sun1, Hao Li ‚Ä†1 , and Hanqing Wu1\n1Alibaba Group\n2Shenzhen Technology University, China\n3National University of Singapore, Singapore\nAbstract\nFace clustering is an useful tool for applications like au-\ntomatic face annotation and retrieval. The main challenge\nis that it is difÔ¨Åcult to cluster images from the same iden-\ntity with different face poses, occlusions, and image quality.\nTraditional clustering methods usually ignore the relation-\nship between individual images and their neighbors which\nmay contain useful context information. In this paper, we re-\npurpose the well-known Transformer and introduce a Face\nTransformer for supervised face clustering. In Face Trans-\nformer, we decompose the face clustering into two steps: re-\nlation encoding and linkage predicting. SpeciÔ¨Åcally, given\na face image, a relation encodermodule aggregates local\ncontext information from its neighbors and a linkage pre-\ndictor module judges whether a pair of images belong to the\nsame cluster or not. In the local linkage graph view, Face\nTransformer can generate more robust node and edge rep-\nresentations compared to existing methods. Experiments on\nboth MS-Celeb-1M and DeepFashion show that our method\nachieves state-of-the-art performance, e.g., 91.12% in pair-\nwise F-score on MS-Celeb-1M.\n1. Introduction\nIn recent years, face recognition has achieved remark-\nable progress in real-world applications due to the devel-\nopment of advanced metric learning methods [7] and deep\nneural models [14]. Large-scale well-labelled data is very\ncrucial for high-performance face recognition system, while\nto annotate these large-scale datasets is time-consuming and\nexpensive. Recent solutions resort to clustering methods\naiming to mine identity information from unlabeled data.\nTraditional clustering methods generally make differ-\nent assumptions on the input features. K-Means [19]\n*Equally-contributed Ô¨Årst authors\n‚Ä†Corresponding author (lihao.lh@alibaba-inc.com)\n(a) Transfer features with context to cluster challenging samples.\nhard negative pairs\nhard positive pairs\nhard negative pairs\nhard positive pairs\n(b) Adapt edge embedding via context to ease linkage prediction.\nFigure 1. Illustration for implementing context-based node aug-\nmentation and edge augmentation in face clustering. (a) Face\nfeature distribution in wild usually exists considerable challeng-\ning samples, which is hard to present direct clustering procedure.\nTransferring features with its local context is helpful to cluster\nthose challenging samples. Images from the same ID are rep-\nresented by the same letters. (b) Similarity between hard posi-\ntive pairs and hard negative pairs usually gathered closely, which\nmakes it difÔ¨Åcult to decide a threshold to distinguish whether a\nlink could be built. Adapting edge embedding via context eases\nlinkage prediction task.\nrequires the distribution of clusters to be convex, DB-\nSCAN (Density-Based Spatial Clustering of Applications\nwith Noise) [8] requires the density within the cluster to\nbe greater than a certain threshold, Spectral Clustering [24]\nrequires clusters are of the similar sizes. However, in\nreal-world applications, there still exist considerable im-\nages with extreme exposure, occlusion, pose variant, and\narXiv:2104.11502v1  [cs.CV]  23 Apr 2021\nlow resolution, whose distributions are often too complex\nto meet these distribution assumptions. We call those hard\nsamples as challenging samples. Clustering with these chal-\nlenging samples may lead to the following problems[4].\nFirst, challenging samples of the same person are inevitably\nfar from the high-quality ones, resulting in splitting the\nsame identity. Second, challenging images from differ-\nent identities may be close to each other due to the dom-\ninant imaging condition, resulting in a degradation in pu-\nrity. Third, the distance between an image and its neigh-\nbors differs from images to images, which leads to differ-\nent merging threshold for different instances. The pioneer\nwork Rank-Order [39] and recent supervised face clustering\nwork [27] attempt to re-measure distance between samples\nvia contextual information and annotations. However, they\nlargely ignore that noise may exists in local neighbor topol-\nogy, and directly consider all samples equally.\nIn this paper, considering contextual information is crit-\nical for clustering on a complex distribution, we re-purpose\nthe well-known Transformer [26] and propose a uniform\nface clustering framework, termed as Face Transformer\n(FaceT). As shown in Figure 1, the key motivation of FaceT\nis to leverage contextual information contained in the local\ntopology to reduce the adverse effects of challenging im-\nages thus to learn robust and compact cluster embeddings.\nTo this end, FaceT contains two crucial modules: (i) Re-\nlation Encoder (RE) and (ii) Linkage Predictor (LP). Rela-\ntion encoder is a transformer for a node to aggregate local\ncontext information from its neighbors. As illustrated in\nÔ¨Ågure 1(a), RE increases the inter-class distance and reduce\nthe intra-class distance between samples based on their con-\ntext. Linkage predictor is a transformer for a node to judge\nwhether a neighbor belongs to the same cluster or not. As il-\nlustrated in Ô¨Ågure 1(b), LP improves the similarity between\nchallenging samples and its positive samples and decreases\nthe similarity with its negative samples.\nCompared to these GCN-based supervised clustering\nmodels[27, 32, 31, 11] which need constructing adjacency\nmatrices, our method is simpler and effectively inherits\ncontextual information with the two transformer modules.\nWe conduct extensive experiments with varied recognition\nmodels and training datasets, and achieve consistent im-\nprovements over related state-of-the-art methods on several\nwidely-used benchmarks.\nOur contributions can be summarized as follows:\n‚Ä¢ A node enhancement structure termed Relation En-\ncoder(RE) is proposed, which extracts the contextual\ninformation of local topical structure to enhance node\nembedding.\n‚Ä¢ A Linkage Predictor(LP) that is composed of an edge\nenhancement structure and linkage classiÔ¨Åer is pro-\nposed, which regards the clustering task as a linkage\nprediction task and generalizes more precise predic-\ntions with enhanced edge embedding.\n‚Ä¢ A uniformed clustering framework, i.e. FaceT,\nachieves state-of-the-art performance with pairwise F-\nscore 91.18, Bcubed F-score 90.54, NMI 97.63 on MS-\nCeleb-1M dataset.\n2. Related Work\nWe Ô¨Årst brieÔ¨Çy review face clustering methods includ-\ning unsupervised and supervised ones, and then present\nsome related work on linkage prediction from social net-\nwork analysis.\n2.1. Face Clustering\nUnsupervised methods. With the development of deep\nlearning, recent works primarily adopt features extracted by\na deep convolutional neural network (DCNN) [7, 22]. For\nthe deep feature based clustering task, traditional algorithms\nlike K-Means, spectral clustering, and DBSCAN usually lie\non different data assumptions that are difÔ¨Åcult to satisfy.\nTherefore, later methods usually focus on additional con-\ntextual information to cluster faces. Rank-order[39] pro-\nposed a relation metric approach based on the local con-\ntext, ARO [20] proposed an approximate rank-order metric\nto reduce rank-order running cost, DDC [16] uses minimal\ncovering spheres of neighborhoods as the similarity metric,\nPHAC [17] exploits neighborhood similarity based on lin-\near SVMs that separates local positive instances and nega-\ntive instances. Additional deep neural networks(DNNs) are\nrecently used to boost clustering results, including unsuper-\nvised and supervised approaches. As typical unsupervised\nones, DEC [29] and SDLC [30] use encoder-decoder struc-\ntures to learn low-dimensional embeddings and cluster as-\nsignments. In general, there have been many schemes that\nadjust node representation based on context and have made\nsome progress. However, those methods depend on hand-\ncraft information communicating policy and usually treat\neach node equally, making it sensitive to outliers. There-\nfore, such methods usually have limited performance on\nface clustering tasks in wild.\nSupervised methods. As recent supervised ones, some\nmethods use contextual information to enhance the node\nembedding, so as to obtain a node representation that is\nmore friendly to clustering. VE-GCN [31] uses two stacked\nGCNs to estimate vertices‚Äô conÔ¨Ådence and build edges by\nthose high-conÔ¨Ådence vertices, DA-NET [11] uses stacked\nGCNs and LSTMs to decrease class intra-distance then\ngenerate better clustering results based on traditional algo-\nrithms. Other methods focus on the context-based distance\nmetric method and try to obtain a more powerful distance\nmeasurement scheme. LGCN [27] proposed a linkage-\nbased GCN to predict the linkage between a pivot node\nand its neighbors via enhanced edge embeddings. Finally,\nsome methods involve new clustering frameworks. After\nthe clustering results are constructed using traditional meth-\nods, additional post-processing models are used to obtain\nmore accurate clustering results. DS-GCN [32] is a typi-\ncal work of this method, it learns to cluster in a detection-\nsegmentation paradigm based on overlapped cluster propos-\nals. Our method differs from the previous GCN-based ap-\nproaches, FaceT doesn‚Äôt suffer from constructing adjacency\nmatrix and combines the advantages of the Ô¨Årst two meth-\nods, which is more direct and effective.\n2.2. Linkage Prediction\nAs a key problem in social network analysis, the objec-\ntive of link prediction is to identify pairs of nodes that will\neither form a link or not. PageRank [21] and SimRank [15]\nanalyze the whole graph via various information propaga-\ntion approaches, preferential attachment [3] and resource\nallocation [38] analyze linkage probability only from lo-\ncal topical graph structure. Further work like Weisfeiler-\nLehman Neural Machine [36] and LGNN [37] believe that\nit is sufÔ¨Åcient to compute link likelihood only from the local\nneighborhood of a node pair and solve this task via various\nneural networks, GKC [34] calculate the graph kernel sim-\nilarities between subgraphs and use an SVM to decide each\nlinkage. In general, there have been a lot of linkage predic-\ntion related work proposed and veriÔ¨Åed in the Ô¨Åeld of social\nnetworks, but there are relatively few works related to face\nrecognition and clustering.\n3. Methodology\nIn large-scale face clustering, supervised approaches\ndemonstrate their effectiveness with various mechanisms.\nSome supervised approaches[32] can handle complex pat-\nterns of clusters, but rely on manual components and\nlarge number of overlapping sub-graphs, which is time-\nconsuming. Other light-GCN-based methods [27, 31, 11]\ncan improve the speed of clustering, but are unable to con-\nsider both node and edge representations at the same time.\nTo address the problem, we propose a simple yet efÔ¨Åcient\nmodel: Face Transformer (FaceT). In FaceT, we divide the\nclustering task into two steps. First, we apply Relation En-\ncoder (RE) to fuse contextual information for a node with\noriginal features from its neighbors. Then, Linkage Pre-\ndictor (LP) is designed to determine whether paired nodes\nbelong to the same ID or not.\n3.1. Overview\nFaceT aims to generate accurate paired linkage predic-\ntions using two well-designed modules. Given a dataset D,\nwe extract deep features of images by a pretrained DCNN\nmodel. Let F = {fi}N\ni=1 as feature set where fi ‚ààRD,\nDdenotes the dimension of each image and N denotes the\nnumber of images. For each sample feature fq, we Ô¨Ånd its\nhop1 nearest neighbor nodes by comparing their features\nsimilarities in F, which are regarded as the candidate sam-\nples for Ô¨Ånal possible linkages. For query feature fq and\nthose hop1 neighbors, we utilize the same manner to search\nthe hop2 nearest neighbor nodes for fq and its candidate\nsamples, respectively, which is a scalable schema. Then we\nreplace query feature fq with enhanced feature gq generated\nby RE. For all hop1 candidates, we apply the same manner\nand generate enhanced candidate features. As the enhanced\nquery feature and its enhanced neighbors are generated,\nthe LP is designed to assign linkage probabilities between\nquery sample and its hop1 candidate samples. Finally, the\nobtained probability is used as the similarity score to deter-\nmine if the candidate is connected to this query pivot. Given\na threshold œÑ, we form the link between query sample and\na candidate sample whose pair linkage probability is larger\nthan œÑ. By repeating the above process while treating all\nsamples as query samples, we can get the linkage predic-\ntions on the entire test set. Finally, clustering procedure\nwith linkage predictions could be done with Union-Find al-\ngorithm [9]\nThe key challenge for the proposed method remains in\nhow to aggregate local context into node embeddings and\nedge embeddings. As shown in Figure 2, our framework\nconsists of two learnable modules, namely Relation En-\ncoder(RE) and Linkage Predictor(LP). The former mod-\nule aggregates local context information from its neighbors,\nand the latter module judges whether a pair of images be-\nlong to the same cluster or not.\n3.2. Transformer Preliminary\nAssume we have n query vectors each with dimension\ndq : Q ‚àà Rn‚àódq , we can deÔ¨Åne an attention function\nA(Q,K,V ) to calculate similarity between instance pairs.\nA(Q,K,V ; œâ) = œâ(QK‚ä§)V (1)\nThere K ‚àà Rnv‚àód1 , V ‚àà Rnv‚àódv are nv key-value\npairs, œâ is an activation function, the output œâ(QK‚ä§)V\nis a weighted sum of value vectors, where an instance\nvalue would get more weight when its key has larger dot\nproduct with the query vector. For multi-head attention\nM(¬∑,¬∑,¬∑; Œª), Ô¨Årst project Q,K,V onto hdifferent dM\nq , dM\nk ,\ndM\nv -dimensional vectors, then apply an attention function\nA(¬∑; œâj) to each of these h projections, Ô¨Ånally reduce di-\nmension with a linear transformation as follows:\nM(Q,K,V ; Œª,œâ) = cat(O1,...,O h)WO (2)\nwhere,\nOi = A(QWQ\ni ,KW K\ni ,VW V\nj ; œâi) (3)\nRelation Encoder\nCNN\n+\nLinkage Predictor\nclassifier\n(MLP)\n1    \n(positive)\n0    \n(negative)\n√ó\nSelf-attentionhop2\nneighbors\nSelf-attention\nhop1\nneighbors\nFigure 2. The overview of Face Transformer architecture. For each original face feature fq, we Ô¨Årst enhance it with its local context\n(constructed by hop2 nearest neighbors) resulting in enhanced feature gq. Then for each node fq, we use its hop1 neighbors as linkable\ncandidates, then calculate linkage likelihood with their respective enhanced features via Linkage Predictor. Finally, we use the linkage\nlikelihood to generate output clusters with the Union-Find algorithm. (In this toy example, hop1 is 2 and hop2 is 3.)\nThere cat(¬∑,¬∑) represents concatenation operation along\nthe feature dimension. Note that M(¬∑,¬∑,¬∑; Œª) has learnable\nparameters Œª = {WQ\ni ,WK\ni ,WV\ni }h\ni=1, where WQ\ni ,WK\ni ‚àà\nRdq‚àódM\nq , WV\ni ‚àà Rdv‚àódM\nv , WO ‚àà RhdM\nv ‚àód. Unless\notherwise speciÔ¨Åed, we use a scaled softmax œâi(¬∑) =\nsoftmax( ¬∑‚àö\nd).\n3.3. Relation Encoder\nRelation Encoder(RE) is used for enhancing node rep-\nresentations, which consists of de self-attention layers and\none normal attention layer. Its structure is illustrated in\nÔ¨Ågure 3(a). For each node embedding fq to be enhanced,\nÔ¨Årst we Ô¨Ånd its hop2 neighbors fq,1,fq,2,...,f q,hop2 from F\nwith normal retrieval methods. Then, we use self-attention\nlayers to enhance fq,j , where j ‚àà{1,2,...,hop 2}.\nApart from the attention functions mentioned in 3.2, we\napply dropout to each sub-layers output before it is added\nto the sub-layer input and normalized. We employ a resid-\nual connection around each of the two sub-layers, followed\nby layer normalization. In following method, dropout func-\ntion is represented as d(¬∑), layer normalization function is\nrepresented as NL(¬∑). First, we use self-attention layers to\nenhance original face features, which can be formulated as:\nfl\nq,k = NL(d(M(fl‚àí1\nq,k ,Kl‚àí1,V l‚àí1)) + fl‚àí1\nq,k ) (4)\nThere fl\nq,k denotes self-attention layer output from the\nl‚àíthlayer, l ‚àà{1,2,...,d e}, f0\nq,k = fq,k, K,V denotes\nall hop2 neighbors‚Äô key vectors and value vectors. Next, we\nwill use a common attention layer to construct the query‚Äôs\ncontext representation, denotes as Àúfq . Finally, we use an\nadd and norm operation to generate enhanced face feature\ngk, formulated as:\nÀúfq = (M(fq,Kde,V de)) (5)\n+\nFeed Forward\nùëëùëí √ó\nùëìùëû\nùëîùëû\nùëìùëû,1\nadd&norm\n·àöùëìùëû\nùëìùëû,2 ùëìùëû,3\n(a) Relation Encoder\nFeed Forward\nclassifier\nùëëùëí √ó\nùëîùëû,2ùëîùëû,1\nùëíùëû,2ùëíùëû,1\nùëîùëû\nùëùùëû,2ùëùùëû,1 (b) Linkage Predictor\nFigure 3. Details of Relation Encoder and Linkage Predictor.\ngq = N( Àúfq + fq) (6)\n3.4. Linkage Predictor\nLinkage Predictor(LP) is used for enhancing edge rep-\nresentations and predicting linkages, which consists of de\nself-attention layers and one MLP working as a linkage\nclassiÔ¨Åer. Its structure is illustrated in Ô¨Ågure 3(b). This\nmodule is applied to decide whether a neighbors‚Äô enhanced\nface feature gq,k could build a connection with the enhanced\nquery face feature gq. First, we Ô¨Ånd hop1 nearest neighbors\nof query feature fq from Fand replace them with related\nenhanced face features generated by RE. Secondly, self-\nattention layers are applied to enhanced neighbors‚Äô features,\nget gl\nk, formulated as:\ngl\nq,k = NL(d(M(gl‚àí1\nq,k ,K,V )) + gl‚àí1\nq,k ) (7)\nThere gl\nq,k denotes self-attention layer output from the\nl‚àíthlayer, l ‚àà{1,2,...,d e}, specially, g0\nq,k = gq,k, K,V\ndenotes all hop1 neighbors‚Äô key vectors and value vectors.\nThen, concatenate gq and gl\nq,k to generate edge embedding\neq,k, deÔ¨Åned as:\neq,k = cat(gk,ged\nq,k) (8)\nFinally, use a 2-layer MLP to predict probability pq,k of\nthe eq,k, which is formulated as:\npq,k = œâ(C(eq,k)) (9)\nThere C(¬∑) is a two-layer MLP using an edge embedding\neq,k as input, output probability pq,k of the input edge is\npositive. We use PReLU [13] as activation function in our\nmethod.\n3.5. Complexity Analysis\nFor both RE and LP, we need to construct a KNN graph;\nthis needs to be done only once. Hence, its complexity can\nbe regarded as O(nlogn) by Approximate Nearest Neigh-\nbor (ANN) search. Like the previous work LGCN, the pro-\nposed method is only processed on the local topical sub-\ngraph. Hence the runtime of the link prediction process\ngrows linearly with the number of data. Therefore, the\ntotal complexity of our pipeline is O(nlogn) considering\nANN cost, O(n) for ignoring ANN cost,nremarks instance\namount of D.\n4. Experiments\n4.1. Experimental Settings\nFace Clustering. MS-Celeb-1M [12] is a large-scale\nface recognition dataset consisting of 100K identities and\n5.8M images. As previous work DS-GCN and VE-GCN\ndid, we adopt the widely used annotations from ArcFace [7]\nthat contains 5.8M images from 86K classes. The cleaned\ndataset was randomly split into ten parts, with an almost\nequal number of identities. To make a fair comparison, we\nuse the same data released by DS-GCN and VE-GCN 1,\ndetails of those datasets are listed in Table 1, subset 0 is\nadopted for training face recognition model and clustering\nmodel, the others is used for testing. We use ArcFace[7] as\nthe face representations with dimension of 256.\nBesides, we tested our method with additional DCNN\nmodel to validate the scalability of our method. We use\nArcFace[7] as the face representations with dimension of\n1https://github.com/yl-1993/learn-to-cluster\nTable 1. Details of MS-Celeb-1M subsets.\nid 0 1 3 5 7 9\n#id 8.6K 8.6K 25.7K 42.9K 60.0K 77.2K\n#inst 576K 584K 1.74M 2.89M 4.05M 5.21M\n512. This model is trained on the union set of MS-Celeb-\n1M [12] and VGGFace2[5] dataset. For a fair compar-\nison, we use the data provided by LGCN[27] 2. Our\nFaceT is trained on CASIA dataset[33] and tested on IJB-B\ndataset[28]. IJB-B consists of three sets, which include 512,\n1,024, 1,845 identities, and 18,171, 36,575, 68,195 samples.\nWe follow its ofÔ¨Åcial protocol[28] for evaluation.\nFashion Clustering.We also evaluate the effectiveness\nof our method over the non-face dataset. We adopted the\nlarge subset of DeepFashion [18] , a long-tail clothes re-\ntrieval dataset. To make a fair comparison, we use the same\ndata released by DS-GCN and VE-GCN 1. Training fea-\ntures and testing features are mixed in the original split and\nrandomly sample 25, 752 images from 3, 997 categories\nfor training, and the other 26, 960 images with 3, 984 cat-\negories for testing. Because fashion clustering is regarded\nas an open set problem, there is no overlap between training\ncategories and testing categories.\nEvaluation Metrics.To evaluate the performance of the\nproposed clustering algorithm, we adopt three mainstream\nevaluation metrics: BCubed Fmeasure [1], pairwise Fmea-\nsure [2] and normalized mutual information(NMI).\nNMI is a widely used metric that measures the normal-\nized similarity two sets, given‚Ñ¶ the ground truth cluster set,\nC the prediction cluster set, H(‚Ñ¶) and H(C) are their en-\ntropies, I(‚Ñ¶,C) represents the mutual information. NMI is\ncalculated as follows.\nNMI(‚Ñ¶,C) = I(‚Ñ¶,C)‚àö\nH(‚Ñ¶)H(C)\n(10)\nWe did not evaluate traditional methods with the NMI\nmeasure metric on the MS1M benchmark. For the IJB-B\nbenchmark, F512,F1024,F1845 are Bcubed F-scores of dif-\nferent sets.\nImplementation Details.To train the FaceT, we set the\ndepth of encoders de as 2, both for RE and LP. Our feature\ndimension is 256, attention head dimension is 64, attention\nhead amount is 4, and the dropout ratio is 0.4. For IJB-\nB experiments, our feature dimension is 512, attention head\ndimension is 128, the other hyper parameter settings remain\nthe same.\nWe adopt a linear learning rate warm-up for the Ô¨Årst 500\nsteps for the training phase, then use cosine decay policy\nfor the rest training epochs. The batch size is 32; the weight\ndecay parameter is 0.0005. For MS-Celeb-1M and CASIA\n2https://github.com/Zhongdao/gcn clustering\ndataset, we adopt hop1 = 150 ,hop2 = 5 , training for 60\nepochs with a base learning rate 0.002; for DeepFashion\ndataset, we use hop1 = 8 ,hop2 = 6 , training for 1200\nepochs with a base learning rate 0.02.\n4.2. Method Comparison\nLike the previous works, we compare our method with\nseveral baseline methods, each with a brief description. For\nall those methods, we tune the hyper-parameters and report\nthe best results.\nK-Means [19] is a commonly used clustering algorithm.\nFor N ‚â•1.74M, we use mini-batch K-means [23], which\ncan reduce running time by running the original K-Means\nalgorithm with mini-batches.\nHAC [25] hierarchically merges close clusters based on var-\nious criteria in a bottom-up manner.\nDBSCAN [8] recognize clusters from the gallery based on\na designed density criterion, then leave the isolated point.\nMeanShift [6] updates candidates for centroids to be the\nmean of the points within a given region.\nAP [10] creates clusters by sending messages between pairs\nof samples until convergence.\nSpectral Clustering [24] performs a low-dimension em-\nbedding of the afÔ¨Ånity matrix between samples, followed\nby clustering of the components of the eigenvectors in the\nlow dimensional space.\nDDC [16] performs clustering based on measuring density\nafÔ¨Ånities between local neighborhoods in the feature space.\nARO [20] performs clustering with an approximate nearest\nneighbor search and a modiÔ¨Åed distance measure.\nCDP [35] performs clustering by exploiting a more robust\npairwise relationship via gathering different predictions.\nLGCN [27] is a supervised clustering method that adopts\nGCNs to exploit graph context for pairwise prediction, then\nperforms clustering based on the output pairwise prediction.\nDS-GCN [32] is a supervised clustering method that formu-\nlates clustering as a detection and segmentation pipeline.\nVE-GCN [31] proposes a method that employs a stacked\nGCN architecture to estimate the connectivity and obtain\nclusters by connecting each node to the most connective\nneighbors in the candidate set.\nFaceT is the proposed method that uses a hierarchical trans-\nformer architecture to enhance node embedding and edge\nembedding synchronously and build connections on en-\nhanced pairwise linkage predictions.\n4.3. Results\nFor all methods, we tune the corresponding hyper-\nparameters and report the best results. The results in Ta-\nble 2, Table 3, and Table 4 show: (1) As is conducted\nin [32, 31], traditional methods including K-Means, DB-\nSCAN, Spectral and ARO are limited in number of clus-\nters assumptions, distribution assumptions or large com-\n/uni0000000b/uni00000044/uni0000000c/uni00000003/uni00000025/uni00000058/uni0000004c/uni0000004f/uni00000047/uni00000003/uni00000055/uni00000044/uni0000005a/uni00000003/uni00000059/uni00000048/uni00000055/uni00000057/uni00000048/uni0000005b/uni00000003/uni00000048/uni00000050/uni00000045/uni00000048/uni00000047/uni00000047/uni0000004c/uni00000051/uni0000004a/uni00000011\n/uni00000046/uni00000048/uni00000051/uni00000057/uni00000048/uni00000055/uni00000003/uni00000053/uni0000004c/uni00000059/uni00000052/uni00000057\n/uni0000000b/uni00000045/uni0000000c/uni00000003/uni00000024/uni00000047/uni0000004d/uni00000058/uni00000056/uni00000057/uni00000003/uni00000059/uni00000048/uni00000055/uni00000057/uni00000048/uni0000005b/uni00000003/uni00000048/uni00000050/uni00000045/uni00000048/uni00000047/uni00000047/uni0000004c/uni00000051/uni0000004a/uni00000011\n/uni0000000b/uni00000046/uni0000000c/uni00000003/uni00000025/uni00000058/uni0000004c/uni0000004f/uni00000047/uni00000003/uni00000055/uni00000044/uni0000005a/uni00000003/uni00000048/uni00000047/uni0000004a/uni00000048/uni00000003/uni00000048/uni00000050/uni00000045/uni00000048/uni00000047/uni00000047/uni0000004c/uni00000051/uni0000004a/uni00000011\n/uni00000053/uni00000052/uni00000056/uni0000004c/uni00000057/uni0000004c/uni00000059/uni00000048\n/uni00000051/uni00000048/uni0000004a/uni00000044/uni00000057/uni0000004c/uni00000059/uni00000048\n/uni0000000b/uni00000047/uni0000000c/uni00000003/uni00000024/uni00000047/uni0000004d/uni00000058/uni00000056/uni00000057/uni00000003/uni00000048/uni00000047/uni0000004a/uni00000048/uni00000003/uni00000048/uni00000050/uni00000045/uni00000048/uni00000047/uni00000047/uni0000004c/uni00000051/uni0000004a/uni00000011\nFigure 4. Adjust node and edge embedding with our method. (a)\nOriginal features as node embeddings, where samples from the\nsame category are marked in the same color. (b) Enhanced node\nfeature embeddings generated by RE. (c) Raw edge embeddings\nby concatenating paired node features. (d) Enhanced edge feature\nembeddings generated by LP. Our method makes node of the same\nclass concentrate more tightly; meanwhile, the positive and nega-\ntive edge embedding interface is more explicit. This afÔ¨Ånity graph\nis built on a random center pivot‚Äôs local topical subgraph of MS1M\ndataset subset 1.\nputational budget, which make them hard to use in real-\nworld situations. (2) CDP is quite efÔ¨Åcient and achieves\nconsiderable F-scores on different datasets. (3) L-GCN and\nDS-GCN surpasses CDP consistently but they are an order\nof magnitude slower than CDP. (4) VE-GCN yields supe-\nrior performance, and has a high operating efÔ¨Åciency bene-\nÔ¨Åt from its high-conÔ¨Ådence sample screening strategy. (5)\nThe proposed FaceT outperforms previous methods consis-\ntently. Although the training set of FaceT only contains\n584K images 2, it scales well to 5.21M unlabeled data,\ndemonstrating its effectiveness in capturing contextual in-\nformation of nodes and edges and predicting linkages.\nFor results on IJB-B in Table 4, L-GCN[27] uses the\ndown-sampled CASIA training set, while sampling details\nis not provided, we randomly make three down-sampled\nsubsets for training and take the best result to report. There-\nfore, comparison on IJB-B benchmark is not fair enough\nto make a solid conclusion due to the unaligned down-\nsampling policy, and we should focus on datasets that can\nbe fairly compared, such as MS1M 2. What‚Äôs more, DA-\nNET[11] used completely different feature and training set,\ntherefore it is hard to make a fair comparison between DA-\nNET and the other methods.\n4.4. Ablation Study\nIn order to verify that key modules work as expected\nand study some key design choices, we conduct ablation\nstudy on MS-Celeb-1M subset 1. The ablation experiments\nis conducted from two aspects, the validity of the model\nstructure and the inÔ¨Çuence of model hyper-parameters.\nTable 2. Comparison on MS-Celeb-1M with different numbers of unlabeled images, subset id remarks different sizes. 1,3,5,7,9 respectively\nrepresent images count of 584K, 1.74M, 2.89M, 4.05M and 5.21M .\nMethod pairwise F-score( FP ) BCubed F-score(FB) NMI Time\nsubset id 1 3 5 7 9 1 3 5 7 9 1 3 5 7 9\nK-Means 79.21 73.04 69.83 67.9 66.47 81.23 75.2 72.34 70.57 69.42 - - - - - 11.5h\nHAC 70.63 54.4 11.08 1.4 0.37 70.46 69.53 68.62 67.69 66.96 - - - - - 12.7h\nDBSCAN 67.93 63.41 52.5 45.24 44.94 67.17 66.53 66.26 44.87 44.74 - - - - - 1.9m\nARO 13.6 8.78 7.3 6.86 6.35 17 12.42 10.96 10.5 10.01 - - - - - 27.5m\nCDP 75.02 70.75 69.51 68.62 68.06 78.70 75.82 74.58 73.62 72.92 94.69 94.62 94.63 94.62 94.61 2.3m\nL-GCN 78.68 75.83 74.29 73.70 72.99 84.37 81.61 80.11 79.33 78.60 96.12 95.78 95.63 95.57 95.49 63.8m\nDS-GCN 87.61 83.76 81.62 80.33 79.21 87.76 83.99 82.00 80.72 79.71 97.04 96.55 96.33 96.18 96.07 47.3m\nVE-GCN 87.93 84.04 82.1 80.45 79.30 86.09 82.84 81.24 80.09 79.25 96.41 96.03 95.85 95.71 95.62 11.5m\nFaceT 91.12 89.07 86.78 84.10 83.86 90.50 86.84 85.09 84.67 83.86 97.61 97.12 96.87 96.82 96.67 28.0m\nTable 3. Comparison on IJB-B.\nMethod F512 F1024 F1845\nK-means 61.2 60.3 60.0\nDBSCAN 75.3 72.5 69.5\nSpectral 51.7 50.8 51.6\nAP 49.4 48.4 47.7\nARO 76.3 75.8 75.5\nDDC 80.2 80.5 80.0\nLGCN 83.3 83.3 81.4\nFaceT 83.1 83.3 82.2\nTable 4. Comparison on DeepFashion.\nMethod FP FB NMI\nK-means 32.02 53.30 88.91\nHAC 22.54 48.77 90.44\nDBSCAN 25.07 53.23 90.75\nMeanShift 31.61 56.73 89.29\nSpectral 29.60 47.12 86.95\nARO 25.04 52.77 88.71\nCDP 28.28 57.83 90.93\nLGCN 30.7 60.13 90.67\nDS-GCN 33.25 56.83 89.36\nVE-GCN 38.47 60.06 90.50\nFaceT 34.82 61.29 91.28\nVisual Analysis. Regarding the impact of our method,\nwe give a visual analysis in Figure 4. We randomly selected\nthe center point of a batch and its neighbors of hop1, and\nvisualized the point embedding and edge embedding. As is\nshown in Figure 4, after adjustment by Face Transformer,\nthe sample variance of the same category as the center point\nbecomes smaller, and the boundary between positive and\nnegative samples on the edge embedding interface becomes\nclearer, which means those ambiguous samples are easier to\nbe separated after those two adjustments.\nRelation Encoder and Linkage Predictor. To better\nevaluate each sub structure‚Äôs role, we conduct end-to-end\nexperiments using each sub-module separately. Because\nour method is composed of RE and LP structures in series,\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013\n/uni00000013/uni00000011/uni00000019\n/uni00000013/uni00000011/uni0000001a\n/uni00000013/uni00000011/uni0000001b\n/uni00000013/uni00000011/uni0000001c\n/uni00000014/uni00000011/uni00000013\n/uni00000051/uni00000044/uni0000004c/uni00000059/uni00000048\n/uni00000052/uni00000051/uni0000004f/uni0000005c/uni00000003/uni00000035/uni00000028\n/uni00000052/uni00000051/uni0000004f/uni0000005c/uni00000003/uni0000002f/uni00000033\n/uni00000035/uni00000028/uni00000003/uni0000000e/uni00000003/uni0000002f/uni00000033\nFigure 5. ROC of Linkage prediction on MS-Celeb-1M.\nTable 5. Compatibility analysis on MS-Celeb-1M.\nMethod FP FB NMI\nnaive 70.63 70.46 92.67\nonly RE 86.17 87.29 96.72\nonly LP 82.08 80.72 94.72\nRE+LP 91.12 90.50 97.61\nusing these two sub-modules independently requires sepa-\nrate retraining. For validating the effectiveness of LP, we\ntrained a model with only one Relation Encoder structure,\nwhich is termed asonly RE. For validating the effectiveness\nof RE, we trained a model with only one Linkage Predictor\nstructure, which is termed as only LP. Training policy and\nhyper-parameters are the same as the original FaceT. An\nend-to-end clustering test is shown in Table 5.\nIn order to properly train only REmodel, we need to in-\ntroduce a new training objective function to complete end-\nto-end training. We Ô¨Årst normalize of node features with L2\nnormalize function N, then use the L2 distance as the dis-\ntance metric between the two nodes, Ô¨Ånally convert this dis-\ntance metric into a two-class probability distribution to use\nthe same training strategy as the MLP-based two-classiÔ¨Åer.\nThe speciÔ¨Åc method could be described as follows.\neq,k = 0.25 ‚àó||N(gk) ‚àíN(gq,k)||2\n2 (11)\npq,k = (1 ‚àíeq,k,eq,k) (12)\nIn the end-to-end test scenario, the complete FaceT ar-\nchitecture has obvious performance advantages. In the case\nof limited computing resources, using RE or LP alone can\nalso achieve a particular effect. Additionally, we utilize the\nROC curve to illustrate the discriminative power of our Ô¨Å-\nnal linkage prediction approach. There, we use the top 80\npredictions of each node on MS-Celeb-1M subset 1. As\nshown in Figure 5, under the same false-positive rate, the\nfull FaceT architecture‚Äôs true-positive rate is much higher\nthan the other candidates.\nTime Complexity Analysis. We measure the runtime of\ndifferent methods with ES-2640 v3 CPU and Tesla V100\n(16G). For MS1M, we measure the clock timings when N\n= 584K. (i.e. subset 1) Note that the clustering framework\nwe used is similar to LGCN, which is based on the clus-\ntering task completed by linkage prediction and clustering\npost-processing, and it is quite different from DS-GCN and\nVE-GCN in clustering framework. The existing clustering\nmethods have large differences in speciÔ¨Åc implementation\nand resource utilization, so it is not completely fair to di-\nrectly compare the running time. Because our CPU environ-\nment is consistent, we directly use the speed measurement\nresults of some methods in [31].\nHyper-parameters. To better understand our hyper-\nparameters, we set a group of parameters as our default set-\nting, then alter one parameter while the others are Ô¨Åxed. We\nmainly study the inÔ¨Çuence of encoder depth ( de), attention\nhead amount( nh), attention head dimension( dh), dropout\nratio(dr), training hop1( hop1) and training hop2( hop2).\nFor the default method, ( de, nh, dh, dropout, hop1, hop2)\nis set as (2, 4, 64, 0.4, 150, 5).\nTable 6. Hyper parameter analysis. We alter only one hyper pa-\nrameter to classify its robustness each time, FP , FB, NMI are\ndifferent measure metrics.\nvalue FP FB NMI\ndefault - 91.12 90.50 97.61\nde 1 91.08 90.46 97.56\n4 91.07 90.39 97.57\nnh 2 91.12 90.37 97.47\n8 91.34 90.6 97.63\ndh 32 90.96 90.18 97.18\n128 91.07 90.6 97.63\ndr 0.2 91.64 90.75 97.67\n0.6 89.96 89.96 97.47\nhop1 120 91.18 90.39 97.58\n180 91.51 90.54 97.63\nhop2 10 90.76 90.26 97.56\n20 89.03 89.23 97.29\nFrom the listed experimental results in Table 6, our\nmethod is not sensitive to the encoder depth de. From our\nexperimental results, reducing the numbers of self-attention\nlayers in RE and LP will have a certain impact on the end-\nto-end test results. We believe that the self-attention lay-\ners can make the neighborhood topology between nodes\nsmoother, thereby making the normal attention layer of RE\nand the MLP classiÔ¨Åer of LP generate more accurate re-\nsults. However, under the condition that other parameters\nare Ô¨Åxed, deepening the encoders will not bring substantial\nbeneÔ¨Åts. We believe that when de is set to 2, the model‚Äôs\nÔ¨Åtting ability is already sufÔ¨Åcient to learn the context distri-\nbution.\nFor the attention head related parameters, such asnh and\ndh, increasing the parameter scale can bring certain degree\nof performance improvement. It is a typical strategy of\nincreasing the amount of calculation in exchange for per-\nformance improvement. However, it is observed that this\nimprovement is not prominent, and trade-off should be de-\ncided on speciÔ¨Åc actual application scenarios.\nFor training hyper-parameter dr, we found that 0.4 used\nin the default settings may be too large. Broad regulariza-\ntion terms may limit the neural network model‚Äôs learning\nability, which may lead to under-Ô¨Åtting. From the listed ex-\nperimental results, reducing the dropout ratio can slightly\nimprove the performance on the test set.\nFor the heuristic parameters hop1 and hop2, the selected\nstrategy is closely related to the data set. For hop1 neigh-\nbors, we expect the positive and negative samples to be bal-\nanced as much as possible while trying to make the model\nthoroughly learn some knowledge of difÔ¨Åcult samples (i.e.,\npositive samples with low similarity and negative samples\nwith high similarity). During the training process, we found\nthat loss tends to converge to a lower solution when hop1 is\nset to a small value, but it is difÔ¨Åcult to thoroughly learn the\nknowledge of difÔ¨Åcult samples, which leads to worse per-\nformance on the test set. For the nearest neighbors of hop2,\nwe want them to come from the same category as the cen-\nter point as much as possible, so this value is often set to\na small value. Similar to the hop1 hyperparameter, during\nthe training process, we found that increasing this hyper-\nparameter leads to a smaller loss converge, but performs\nworse on the test set. We think this phenomenon is caused\nby overÔ¨Åtting. When the number of neighbor samples used\nfor training RE increases, a trivial solution may be learned\nfrom training samples that not from the same category of\ncenter pivot, limiting the performance of the model on the\ntest set.\n5. Conclusion and Future Work\nIn this work, we refer to the idea of Transformer applied\nin document classiÔ¨Åcation and model the clustering task as a\nlinkage prediction task. This paper proposes a novel method\nto enhance the node and the edge representation simultane-\nously and achieve the most advanced performance on the\nface clustering task. Experiments on clustering scenarios\nhave veriÔ¨Åed the effectiveness of the method. Besides, we\nnotice that using RE alone obtains robust node representa-\ntions that are measurable in Euclidean space. As iterative\nupdating policy of KNN may obtain more accurate results,\nthe speciÔ¨Åc algorithm framework is worthy of further explo-\nration. Finally, there is still room for further improvement\nin the current method of hyper-parameter exploration. We\nwill make further theoretical analysis and experimental ex-\nploration in the model structure design and hyper-parameter\nsettings.\nReferences\n[1] Enrique Amig ¬¥o, Julio Gonzalo, Javier Artiles, and Felisa\nVerdejo. A comparison of extrinsic clustering evaluation\nmetrics based on formal constraints. Information retrieval,\n12(4):461‚Äì486, 2009. 5\n[2] Arindam Banerjee, Chase Krumpelman, Joydeep Ghosh,\nSugato Basu, and Raymond J Mooney. Model-based over-\nlapping clustering. In Proceedings of the eleventh ACM\nSIGKDD international conference on Knowledge discovery\nin data mining, pages 532‚Äì537, 2005. 5\n[3] Albert-L ¬¥aszl¬¥o Barab¬¥asi and R¬¥eka Albert. Emergence of scal-\ning in random networks. science, 286(5439):509‚Äì512, 1999.\n3\n[4] Shai Ben-David and Nika Haghtalab. Clustering in the pres-\nence of background noise. In International Conference on\nMachine Learning, pages 280‚Äì288, 2014. 2\n[5] Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and An-\ndrew Zisserman. Vggface2: A dataset for recognising faces\nacross pose and age. In2018 13th IEEE international confer-\nence on automatic face and gesture recognition (FG 2018) ,\npages 67‚Äì74. IEEE, 2018. 5\n[6] Yizong Cheng. Mean shift, mode seeking, and clustering.\nIEEE transactions on pattern analysis and machine intelli-\ngence, 17(8):790‚Äì799, 1995. 6\n[7] Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos\nZafeiriou. Arcface: Additive angular margin loss for deep\nface recognition. In Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition , pages 4690‚Äì\n4699, 2019. 1, 2, 5\n[8] Martin Ester, Hans-Peter Kriegel, J ¬®org Sander, Xiaowei Xu,\net al. A density-based algorithm for discovering clusters in\nlarge spatial databases with noise. In Kdd, volume 96, pages\n226‚Äì231, 1996. 1, 6\n[9] Michael Fredman and Michael Saks. The cell probe com-\nplexity of dynamic data structures. In Proceedings of the\ntwenty-Ô¨Årst annual ACM symposium on Theory of comput-\ning, pages 345‚Äì354, 1989. 3\n[10] Frey, Brendan, J., Dueck, and Detbert. Clustering by passing\nmessages between data points. Science, 2007. 6\n[11] Senhui Guo, Jing Xu, Dapeng Chen, Chao Zhang, Xiaogang\nWang, and Rui Zhao. Density-aware feature embedding for\nface clustering. In Proceedings of the IEEE/CVF Conference\non Computer Vision and Pattern Recognition , pages 6698‚Äì\n6706, 2020. 2, 3, 6\n[12] Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and\nJianfeng Gao. Ms-celeb-1m: A dataset and benchmark for\nlarge-scale face recognition. In European conference on\ncomputer vision, pages 87‚Äì102. Springer, 2016. 5\n[13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDelving deep into rectiÔ¨Åers: Surpassing human-level perfor-\nmance on imagenet classiÔ¨Åcation. In Proceedings of the\nIEEE international conference on computer vision , pages\n1026‚Äì1034, 2015. 5\n[14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.\nDeep residual learning for image recognition. In Proceed-\nings of the IEEE conference on computer vision and pattern\nrecognition, pages 770‚Äì778, 2016. 1\n[15] Glen Jeh and Jennifer Widom. Simrank: a measure of\nstructural-context similarity. In Proceedings of the eighth\nACM SIGKDD international conference on Knowledge dis-\ncovery and data mining, pages 538‚Äì543, 2002. 3\n[16] Wei-An Lin, Jun-Cheng Chen, Carlos D Castillo, and Rama\nChellappa. Deep density clustering of unconstrained faces.\nIn Proceedings of the IEEE Conference on Computer Vision\nand Pattern Recognition, pages 8128‚Äì8137, 2018. 2, 6\n[17] Wei-An Lin, Jun-Cheng Chen, and Rama Chellappa. A\nproximity-aware hierarchical clustering of faces. In 2017\n12th IEEE International Conference on Automatic Face\n& Gesture Recognition (FG 2017) , pages 294‚Äì301. IEEE,\n2017. 2\n[18] Ziwei Liu, Ping Luo, Shi Qiu, Xiaogang Wang, and Xiaoou\nTang. Deepfashion: Powering robust clothes recognition\nand retrieval with rich annotations. In Proceedings of the\nIEEE conference on computer vision and pattern recogni-\ntion, pages 1096‚Äì1104, 2016. 5\n[19] Stuart Lloyd. Least squares quantization in pcm. IEEE trans-\nactions on information theory, 28(2):129‚Äì137, 1982. 1, 6\n[20] Charles Otto, Dayong Wang, and Anil K Jain. Clustering\nmillions of faces by identity. IEEE transactions on pattern\nanalysis and machine intelligence, 40(2):289‚Äì303, 2017. 2,\n6\n[21] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry\nWinograd. The pagerank citation ranking: Bringing order\nto the web. Technical report, Stanford InfoLab, 1999. 3\n[22] Florian Schroff, Dmitry Kalenichenko, and James Philbin.\nFacenet: A uniÔ¨Åed embedding for face recognition and clus-\ntering. In Proceedings of the IEEE conference on computer\nvision and pattern recognition, pages 815‚Äì823, 2015. 2\n[23] David Sculley. Web-scale k-means clustering. In Proceed-\nings of the 19th international conference on World wide web,\npages 1177‚Äì1178, 2010. 6\n[24] Jianbo Shi and Jitendra Malik. Normalized cuts and image\nsegmentation. IEEE Transactions on pattern analysis and\nmachine intelligence, 22(8):888‚Äì905, 2000. 1, 6\n[25] Sibson and R. Slink: An optimally efÔ¨Åcient algorithm for the\nsingle-link cluster method. Comput. J, 16(1):30‚Äì34, 1973. 6\n[26] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-\nreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia\nPolosukhin. Attention is all you need. In Advances in neural\ninformation processing systems, pages 5998‚Äì6008, 2017. 2\n[27] Zhongdao Wang, Liang Zheng, Yali Li, and Shengjin Wang.\nLinkage based face clustering via graph convolution net-\nwork. In Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition, pages 1117‚Äì1125, 2019. 2,\n3, 5, 6\n[28] Cameron Whitelam, Emma Taborsky, Austin Blanton, Bri-\nanna Maze, and Patrick Grother. Iarpa janus benchmark-b\nface dataset. In 2017 IEEE Conference on Computer Vision\nand Pattern Recognition Workshops (CVPRW), 2017. 5\n[29] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised\ndeep embedding for clustering analysis. In International\nconference on machine learning, pages 478‚Äì487, 2016. 2\n[30] Bo Yang, Xiao Fu, Nicholas D Sidiropoulos, and Mingyi\nHong. Towards k-means-friendly spaces: Simultaneous deep\nlearning and clustering. In international conference on ma-\nchine learning, pages 3861‚Äì3870. PMLR, 2017. 2\n[31] Lei Yang, Dapeng Chen, Xiaohang Zhan, Rui Zhao,\nChen Change Loy, and Dahua Lin. Learning to cluster faces\nvia conÔ¨Ådence and connectivity estimation. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition, pages 13369‚Äì13378, 2020. 2, 3, 6, 8\n[32] Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan,\nChen Change Loy, and Dahua Lin. Learning to cluster faces\non an afÔ¨Ånity graph. In Proceedings of the IEEE Conference\non Computer Vision and Pattern Recognition , pages 2298‚Äì\n2306, 2019. 2, 3, 6\n[33] Dong Yi, Zhen Lei, Shengcai Liao, and Stan Z. Li. Learning\nface representation from scratch. Computer ence, 2014. 5\n[34] Weiwei Yuan, Kangya He, Donghai Guan, Li Zhou, and\nChenliang Li. Graph kernel based link prediction for signed\nsocial networks. Information Fusion, 46:1‚Äì10, 2019. 3\n[35] Xiaohang Zhan, Ziwei Liu, Junjie Yan, Dahua Lin, and Chen\nChange Loy. Consensus-driven propagation in massive un-\nlabeled data for face recognition. In Proceedings of the Eu-\nropean Conference on Computer Vision (ECCV), pages 568‚Äì\n583, 2018. 6\n[36] Muhan Zhang and Yixin Chen. Weisfeiler-lehman neural\nmachine for link prediction. In Proceedings of the 23rd ACM\nSIGKDD International Conference on Knowledge Discovery\nand Data Mining, pages 575‚Äì583, 2017. 3\n[37] Muhan Zhang and Yixin Chen. Link prediction based on\ngraph neural networks. In Advances in Neural Information\nProcessing Systems, pages 5165‚Äì5175, 2018. 3\n[38] Tao Zhou, Linyuan L ¬®u, and Yi-Cheng Zhang. Predicting\nmissing links via local information. The European Physical\nJournal B, 71(4):623‚Äì630, 2009. 3\n[39] Chunhui Zhu, Fang Wen, and Jian Sun. A rank-order dis-\ntance based clustering algorithm for face tagging. In CVPR\n2011, pages 481‚Äì488. IEEE, 2011. 2",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6579686403274536
    },
    {
      "name": "Cluster analysis",
      "score": 0.649572491645813
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6028057336807251
    },
    {
      "name": "Pairwise comparison",
      "score": 0.5214052200317383
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.5003752708435059
    },
    {
      "name": "Encoder",
      "score": 0.4662443995475769
    },
    {
      "name": "Transformer",
      "score": 0.44215163588523865
    },
    {
      "name": "Face (sociological concept)",
      "score": 0.4176121652126312
    },
    {
      "name": "Computer vision",
      "score": 0.35712164640426636
    },
    {
      "name": "Data mining",
      "score": 0.3530464768409729
    },
    {
      "name": "Engineering",
      "score": 0.08313068747520447
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "institutions": []
}