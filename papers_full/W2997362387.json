{
    "title": "Joint Entity and Relation Extraction with a Hybrid Transformer and Reinforcement Learning Based Model",
    "url": "https://openalex.org/W2997362387",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2160921503",
            "name": "Ya Xiao",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2137573885",
            "name": "Chengxiang Tan",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2313958757",
            "name": "Zhijie Fan",
            "affiliations": [
                "The Third Institute of the Ministry of Public Security"
            ]
        },
        {
            "id": "https://openalex.org/A1978548049",
            "name": "Qian Xu",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2110050161",
            "name": "Wenye Zhu",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2160921503",
            "name": "Ya Xiao",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2137573885",
            "name": "Chengxiang Tan",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2313958757",
            "name": "Zhijie Fan",
            "affiliations": [
                "Ministry of Public Security of the People's Republic of China"
            ]
        },
        {
            "id": "https://openalex.org/A1978548049",
            "name": "Qian Xu",
            "affiliations": [
                "Tongji University"
            ]
        },
        {
            "id": "https://openalex.org/A2110050161",
            "name": "Wenye Zhu",
            "affiliations": [
                "Tongji University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2949568611",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2748160615",
        "https://openalex.org/W2776652360",
        "https://openalex.org/W281284504",
        "https://openalex.org/W2123143128",
        "https://openalex.org/W2132679783",
        "https://openalex.org/W2604610161",
        "https://openalex.org/W2134033474",
        "https://openalex.org/W2515462165",
        "https://openalex.org/W6605785179",
        "https://openalex.org/W2107598941",
        "https://openalex.org/W2229639163",
        "https://openalex.org/W2251091211",
        "https://openalex.org/W2020278455",
        "https://openalex.org/W6691431627",
        "https://openalex.org/W2804311790",
        "https://openalex.org/W2951450498",
        "https://openalex.org/W2155027007",
        "https://openalex.org/W2899996857",
        "https://openalex.org/W2513378248",
        "https://openalex.org/W2964273534",
        "https://openalex.org/W2119717200",
        "https://openalex.org/W6747920613",
        "https://openalex.org/W2903810220",
        "https://openalex.org/W2251135946",
        "https://openalex.org/W2626837907",
        "https://openalex.org/W2517194566",
        "https://openalex.org/W2963443341",
        "https://openalex.org/W2962913831",
        "https://openalex.org/W4230563027",
        "https://openalex.org/W2250539671",
        "https://openalex.org/W2808142148",
        "https://openalex.org/W2962939608",
        "https://openalex.org/W2964349647",
        "https://openalex.org/W2781712876",
        "https://openalex.org/W2964167098",
        "https://openalex.org/W143521272",
        "https://openalex.org/W2952402849",
        "https://openalex.org/W2951274974"
    ],
    "abstract": "Joint extraction of entities and relations is a task that extracts the entity mentions and semantic relations between entities from the unstructured texts with one single model. Existing entity and relation extraction datasets usually rely on distant supervision methods which cannot identify the corresponding relations between a relation and the sentence, thus suffers from noisy labeling problem. We propose a hybrid deep neural network model to jointly extract the entities and relations, and the model is also capable of filtering noisy data. The hybrid model contains a transformer-based encoding layer, an LSTM entity detection module and a reinforcement learning-based relation classification module. The output of the transformer encoder and the entity embedding generated from the entity detection module are combined as the input state of the reinforcement learning module to improve the relation classification and noisy data filtering. We conduct experiments on the public dataset produced by the distant supervision method to verify the effectiveness of our proposed model. Different experimental results show that our model gains better performance on entity and relation extraction than the compared methods and also has the ability to filter noisy sentences.",
    "full_text": "The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence (AAAI-20)\nJoint Entity and Relation Extraction with\na Hybrid Transformer and Reinforcement Learning Based Model\nYa Xiao,1 Chengxiang Tan,1∗ Zhijie Fan,2 Qian Xu,1 Wenye Zhu1\n1Tongji University, Shanghai, China\n2The Third Research Institute of the Ministry of Public Security, Shanghai, China\n{1710053, jerrytan, 1310512, 1310513}@tongji.edu.cn, aaronzfan@126.com\nAbstract\nJoint extraction of entities and relations is a task that extracts\nthe entity mentions and semantic relations between entities\nfrom the unstructured texts with one single model. Existing\nentity and relation extraction datasets usually rely on distant\nsupervision methods which cannot identify the correspond-\ning relations between a relation and the sentence, thus suffers\nfrom noisy labeling problem. We propose a hybrid deep neu-\nral network model to jointly extract the entities and relations,\nand the model is also capable of ﬁltering noisy data. The hy-\nbrid model contains a transformer-based encoding layer, an\nLSTM entity detection module and a reinforcement learning-\nbased relation classiﬁcation module. The output of the trans-\nformer encoder and the entity embedding generated from the\nentity detection module are combined as the input state of the\nreinforcement learning module to improve the relation classi-\nﬁcation and noisy data ﬁltering. We conduct experiments on\nthe public dataset produced by the distant supervision method\nto verify the effectiveness of our proposed model. Different\nexperimental results show that our model gains better perfor-\nmance on entity and relation extraction than the compared\nmethods and also has the ability to ﬁlter noisy sentences.\nIntroduction\nExtraction of entities and relations from the massive unstruc-\ntured texts has been a signiﬁcant task in information extrac-\ntion. The inputs are the unstructured texts, while the outputs\nare the triplets with pairs of entity mentions and the semantic\nrelations between them. The extraction methods are mainly\ndivided into two categories, the pipelined methods and joint\nextraction methods.\nPipelined methods treat the extraction as two sepa-\nrate subtasks: recognizing the entities ﬁrst (Nadeau and\nSekine 2007) and then extracting the relations between them\n(Hasegawa, Sekine, and Grishman 2004). This framework\nis ﬂexible and simple but has several problems. The errors\nfrom entity recognition may delivery to the relation extrac-\ntion part (Li and Ji 2014), and this separated framework also\nignore the interrelationships between two subtasks. On the\n∗Corresponding author.\nCopyright c⃝ 2020, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\ncontrary, the joint framework extracts the entities and rela-\ntions with one single model; it can take advantage of the\nrelationships between two subtasks, and thus achieves bet-\nter results. The joint framework falls into one of two cat-\negories, feature-based statistical methods (Li and Ji 2014;\nMiwa and Sasaki 2014; Ren et al. 2017) and neural network\nbased methods (Miwa and Bansal 2016; Zheng et al. 2017;\nWang et al. 2018). The statistical methods need to extract\nvarious features which are time consuming; some global fea-\ntures, such as the part-of-speech tags, are usually tagged by\nthe third-party toolkits, which may cause error propagation\nproblems. The neural network based methods usually realize\njoint learning by parameter sharing to interconnect two sub-\ntasks. Particularly, Zheng et al. (2017) proposed a novel tag-\nging schema to convert joint extraction into a tagging prob-\nlem. This end-to-end neural network model can directly out-\nput the triplets with entities and relations.\nHowever, to our best knowledge, none of the joint extrac-\ntion methods with neural networks considered the problem\nof noisy data. The distant supervision has become a stan-\ndard method for relation extraction and dataset generation.\nThis method assumes that the sentences containing an entity\npair must describe a relation of two entities. This assump-\ntion cannot identify the corresponding interrelationship be-\ntween a relation and the sentence, thus many noisy data will\nbe generated. The noisy data will cause error propagation\nproblem, so it is an important task to ﬁlter the wrong la-\nbelled data during the extraction of entities and relations.\nMany existing work use multi-instance learning to track la-\nbel ambiguity and ﬁlter noisy sentences (Wu et al. 2018;\nZeng et al. 2015; Lin et al. 2016). Ren et al. (2017) ﬁrstly\nproposed a feature-based joint method of relation and en-\ntity extraction and coped with the noisy data problem si-\nmultaneously. They mainly concentrated on the noisy as-\nsociations between relation mention and its candidate en-\ntity type. Feng et al. (2018) introduced the reinforcement\nlearning(RL) method to help with the relation classiﬁcation\nand instance selection, and proved the efﬁciency of using\nRL to select instances. Similar to the instance selection pro-\nposed by Feng et al., our joint extraction and noisy ﬁltration\ntasks also has the trial-and-error-search and delayed fea-\ntures, which exactly ﬁt the RL process.\n9314\nTo address the issues of joint extraction and noisy ﬁltra-\ntion, we propose a hybrid deep neural network model in\nthis paper. The joint extraction issue is addressed by shar-\ning the parameters and interactions between two subtasks.\nThe noisy data issue is handled by a reinforcement learn-\ning agent. Our proposed model allows joint extraction and\nnoisy sentence ﬁltration in one model by using transformer\nencoder, LSTM decoder and reinforcement learning. Our\nmodel introduces a new attenuation coefﬁcient based posi-\ntion embedding to enhance the word embedding, and ex-\ntracts the entities existing in a sentence with a transformer\nencoder and LSTM decoder. Then the embedding of ex-\ntracted entities and the hidden layer of transformer encoder\nare treated as the input state of reinforcement learning agent\nto help with relation extraction and noisy sentence ﬁltration.\nOur contributions are summarized as follows:\n• We propose a new model for joint entity and relation ex-\ntraction, which implement the entity extraction, relation\nclassiﬁcation and noisy data ﬁltration in one model with\nthe help of transformer encoder.\n• We formulate the relation classiﬁcation and noisy data ﬁl-\ntration as a reinforcement learning problem, which com-\nbines the sentence context information, entity information\nand ﬁltered noisy data all together.\nRelated Works\nThe pipelined methods for entity recognition and relation\nextraction treat these two tasks separately. Recognizing an\nnamed entity, such as name, location, organization or time, is\nalways treated as a sequence labeling problem which needs\nto recognize both the boundary and the category of the en-\ntity (Nadeau and Sekine 2007); the relation extraction is\nusually regarded as a classiﬁcation task and can be imple-\nmented by the neural network models such as Convolution\nNeural Network(CNN) (Liu et al. 2013) or Recurrent Neu-\nral Network(RNN) (Zhou et al. 2016; Wang et al. 2016).\nThe joint methods use one model to extract entities and re-\nlations simultaneously. The Long Short Term Memory net-\nwork(LSTM) can keep long term memory by training proper\ngating weights thus shows a powerful capacity on many nat-\nural language processing tasks. Ren et al. (2017) presented\na distant supervised framework for joint extraction of enti-\nties and relations. Miwa and Bansal (2016) also employed\nthe end-to-end method and used the dependency tree for re-\nlation classiﬁcation. Zheng et al. (2017) put forward a novel\ntagging schema to tag the entity related words and turn the\nextraction problem into a tagging problem, they also adopted\na bidirectional LSTM encoder and an LSTM decoder.\nThe limited amount of annotated corpus for entity and re-\nlation extraction is not enough, thus, the distant supervised\nmethods for relation extraction are proposed (Mintz et al.\n2009; Ren et al. 2017; Tang et al. 2017). The distant super-\nvision method maps the known entities in third party knowl-\nedge bases to the entities in unstructured texts to automati-\ncally generate tagged corpus. It assumes that sentences men-\ntioning one entity pair are all describing one of the relations\nof the entity pair, thus can not identify the mapping relation-\nship between a sentence and a relation, thus may produce\nnoisy data. To cope with the noisy labeling problem, Lin et\nal. (2016) proposed the sentence-level attention mechanism\nto select the instance. Lin et al. (2017) introduced the entity\ndescription information in knowledge base to enhance the\nlearning of entity embedding.\nWith the propose of the pre-trained model, such as GPT\n(Radford et al. 2018) and BERT (Devlin et al. 2019), re-\nsearchers have obtained great improvement by using the\npre-trained model in different natural language processing\ntasks. It has also been proved that the transformer used in\nGPT and BERT has better ability on extracting features than\nthe LSTM. Alt, H¨ubner, and Hennig (2019) have utilized a\ntransformer decoder in GPT for distantly supervised relation\nextraction and obtained state-of-the-art results.\nRecent works have also introduced reinforcement learn-\ning into information extraction or noise ﬁltering. Feng et al.\n(2017) used RL to jointly identify the entity mentions and\nrelation types, but they treated the two tasks separately and\nuse an LSTM as the feature extractor. Takanobu et al. (2019)\nalso used RL in the joint extraction task. They designed\na hierarchical paradigm with high-level relation detection\nand low-level entity extraction, but they do not consider the\nnoisy data problem. Feng et al. (2018) proposed a new model\nfor relation extraction which consists of an instance selector\nwith RL and a relation classiﬁer with CNN. Qin, Xu, and\nWang (2018) also proposed a deep RL framework for dis-\ntant supervision relation extraction. Previous methods have\nconcentrated on joint extraction or ﬁlter noisy data in rela-\ntion classiﬁcation, but not considered the noisy data ﬁltering\nin the joint extraction tasks.\nProposed Model\nWe propose a new hybrid framework for joint extraction of\nentities and relations, which is also able to deal with the\nnoisy data. Figure 1 illustrate the framework of the proposed\nmodel. The model mainly consists of three parts: the trans-\nformer encoding module, the LSTM decoding module for\nentity detection, and the reinforcement learning agent for re-\nlation classiﬁcation and noisy sentence ﬁltering. The trans-\nformer encoding module, which contains the word embed-\nding layer and transformer encoder, is shared by the entity\ndetection and relation classiﬁcation module. The embedding\nresult of entity detection also helps with the relation classi-\nﬁcation module, which extracts the relations and also ﬁlter\nthe noisy sentences. Finally, the reward from reinforcement\nlearning is used to optimize the parameters of other modules.\nEmbedding layer\nThe embedding layer converts the word with raw input to\nan embedding vector. Given a sentence withn words S =\n{x\n1,x2,...,x n}, each word xi is converted into a real val-\nued vector x′\ni. The word vectors are encoded by an embed-\nding matrix. The traditional embedding for the encoder input\nconsists of token embedding, mask embedding and position\nembedding, as shown in ﬁgure 1. The token embedding usu-\nally stands for the embedding of the basic unit of the input\nsentence, e.g., word for English and character for Chinese.\nMask embedding is used to identify whether the token is a\n9315\nFigure 1: The framework of the proposed hybrid model.\npadded one. The position embedding describes the location\nof each token in the input sentence.\nIn the joint extraction of entity and relation task, the dis-\ntance between each token and the source or target entity may\nhave an impact on the relation extraction task (Y uan et al.\n2019), and the traditional position embedding can not prop-\nerly demonstrate this relationship. To better illustrate the im-\npact of distance between tokens and entities, we introduce\nthe attenuation coefﬁcient based position weight, named as\nentity-wise position embedding in ﬁgure 1. Tokens which\nclose to the source and target entities often contain more\ninformation related to the relations. We deﬁne the position\nweight of each token asλ\ni, calculated as:\nλi = Wpe\n∑\nj\n(1− |dij|\nD ). (1)\nIn this paper, we only consider the situation that a sentence\ncontains only one triplet, i.e., one relation type and two enti-\nties. When j =1 , d\ni1 is the relative distance between token\nxi and the source entity, when j =2 , di2 is the distance\nabout the target entity.D is referred to the longest distance\nbetween token and entities.Wpe is a training parameter and\nupdates as the training process; this is mainly used to cope\nwith the situation when the test data can not see the rela-\ntive distance information. We useu\ni = λix′\ni to denote the\nweighted token embedding, and the input sentence is repre-\nsented asu\nS = {u1,u2,...,u n}after the embedding layer.\nTransformer encoder\nThe transformer encoder represents words as a linear se-\nquence with the word representations from the embedding\nlayer. The transformer encoder contains various transformer\nencoding layer, while each layer contains multi-head atten-\ntion, layer normalization, feed forward and layer normaliza-\ntion. The output of the layer normalization is regarded as\nthe output of the encoding layer. The attention layer maps a\nquery(Q), a set of key(K)-value(V) pairs to an output, the\noutput is computed as a weighted sum of the values. Query,\nkey and value are matrices which are calculated by multi-\nplying the input embeddinguby the trained weight matrices\nW, for example,Q = W\nQU. The attention weighted value\nis described as Equation (2), wheredk is the dimension of\nkeys and values.\nAttention(Q,K,V )= softmax(QKT\n√dk\n)V. (2)\nDifferent from the sequential bidirectional LSTM which can\nonly calculate the forward or backward hidden states and\nconcat them together, the transformer encoder can merge\nboth left and right contexts at the same time and the atten-\ntion of each word can be calculated simultaneously. Besides,\nsince the transformer encoder usually has much more layers,\nthe feature extraction ability is much stronger than BiLSTM.\nEntity detection\nWe treat the entity detection as a sequence labeling task\nwith an LSTM decoder. We use the entity tags proposed by\nTakanobu et al. (2019) as the tag scheme because they de-\nscribed not only the position of words in each entity but also\nthe source and target entities for a relation. The space of en-\ntity tags is denoted as:{S,T,O }×{ B,I }∪{ N}, whereS\nrepresents the source entity,T is the target entity,O is the\nentities that are not associated with the predicted relation\ntype. B and I indicate the word is the beginning or inside of\nan entity.N stands for the non-entity words.\n9316\nThe LSTM structure is used to obtain the entity tags. For\ntoken ut, the input of the LSTM decoder layer includes:\nht from the transformer encoding layer, former hidden state\nht−1 of the LSTM layer, and the former predicted entity tag\nvector et−1. The vector et is the predicted tag vector. The\ndetailed operations are as follows:\nit = σ(Wxiut +Whiht−1 +Wciet−1 +bi), (3)\nft = σ(Wxf ut +Whf ht−1 +Wcf et−1 +bf ), (4)\ngt = tanh(Wxcut +Whcht−1 +Wccet−1 +bc), (5)\nct = itgt +ftct−1, (6)\not = σ(Wxout +Whoht−1 +Wcoct−1 +bo), (7)\nht = ot tanh(ct), (8)\net = Wesht +bes. (9)\nA softmax layer is implemented to compute the entity tag\nprobabilities based onet, denoted as:\npi\nt = softmax(weet +be). (10)\nReinforcement Learning Based Relation\nClassiﬁcation\nA reinforcement learning agent is deployed for relation clas-\nsiﬁcation. By using the policy and reward mechanism, the\nmodel can also ﬁlter noisy sentences generated by distant\nsupervised learning. As shown in the upper-left corner of\nFigure 1, the reinforcement learning based relation classiﬁ-\ncation take the pooled hidden layer of the transformer en-\ncoder, the active entity embedding of the LSTM decoding\nlayer, the labelled noisy data and the data from the previous\ntime step as the input of each state. Then the agent follows\na policy function to take actions, including classifying the\nrelation types and determining whether the input sentence is\nnoisy or not. The reward will be received from the action re-\nsults and to optimize the policy function. We will introduce\nthe action, state, policy and reward in this module as follows.\nAction At each time step, the agent aims to extract the re-\nlation type of the input sentence and to determine whether\nthe sentence is noisy for the corresponding relation, i.e.,\nwhether the relation is actually described in the input sen-\ntence. The actiona\nt is selected from action setA = {R}×\n{0,1}, where {R} is a set of relation types, 0 means the\nsentence is not noisy and has higher weight when calculat-\ning the loss function;1 represents the sentence is noisy and\nshould have lower weight for the loss function. The relation\naction is used to calculate the rewards and noisy action will\naffect the loss and the state of the next step.\nState The state s\nt represents the information of the input\nsentence at current time stept. To take advantage of the rec-\nognized entities features, origin sentence features and the\nfeatures of the noisy sentences, the current state takes the\nentity embedding, hidden state of the encoding layer, and\nthe vector of noisy sentences into consideration. The repre-\nsentation ofs\nt is as follows:\nst = f(Ws[ve\nt ,vh\nt ,vr\nt ,st−1]), (11)\nwhere f(·) is a function implemented by a multilayer per-\nception. Ws is the matrix of weighted parameters.ve\nt rep-\nresents the active entity embedding, since some words are\nnon entity words and may be less useful in the relation ex-\ntraction step, we only use the average vector of the source\nand target entity embedding as the active embedding;v\nh\nt is\nthe pooled sentence embedding of the transformer encoding\nlayer, similar to the previous model (Devlin et al. 2019), we\nuse the hidden embedding of the ﬁrst token to represent the\nentire sentence; v\nr\nt indicates the average vector of the noisy\nsentences in the early states.\nPolicy The relation and noisy data classiﬁcation policy is\nimplemented by a softmax function, described as follows:\nat ∼ π(at|st)= softmax(Wt(δst)+ bt), (12)\nwhere theδ helps adjust the weight of different parts ofst.\nReward The action of our reinforcement learning agent\ncontains two parts, i.e., classiﬁcation of relation and noisy\nsentences. The noisy classiﬁcation is used to improve the\nperformance of relation classiﬁcation, therefore, the reward\nof the agent is denoted asr\nt, which represents the reward\nby the performance of the entity and relation classiﬁcation.\nInspired by Qin, Xu, and Wang(2018), the relation classi-\nﬁcation performance is measured by the difference of the\nF-score for the selected sentences, and the entity detection\nperformance is measured according to the predict precision\nof target entities, as shown in Equation (13).\nr\nt = Norm(Fi −Fi−1)+ Norm(\n∑\ni\nre), (13)\nwhere i represents different sets of sentences. For example,\nwe divide the input sentences into various sets, and calculate\nthe value of F-score between two neighbor sets, if the F-\nscore is improved, the reward is positive, meaning that the\nnoisy sentences are sort of correctly classiﬁed; if the F-score\nis decreased, which means the agent performs worse and the\nreward is negative. Norm function is used to convert the\nreward score to a rational numeric range. The F-score(F)i s\nthe harmonic mean of precision(P) and recall(R), we use the\nF1-score in this paper, calculated by:\nF = 2×P ×R\nP +R . (14)\nThe reward for entity detectionre equals l when the word is\ncorrected tagged and is a source or target entity;re equals\nm when the word is corrected tagged and is a non-related\nentity; re equals nwhen the word is corrected tagged and is\nnot an entity;re equals p when the word is wrong labelled;\nwhere l>m>n> 0 >p .\nModel Training\nFor the entity detection module, we deﬁne the objective\nfunction using cross-entropy as follows:\nJ(Φ) =− 1\nM\nM∑\ni=1\nN∑\nj=1\nlog(pj\ni |xj\ni ,Φ), (15)\nwhere M is the number of training set of training process,\nand N is the length of training sentence.\nTo optimize the policy function of reinforcement learning\nbased relation classiﬁcation, we aim to maximize the expect\n9317\ntotal reward, which can be decomposed into two parts, im-\nmediate reward and the discounted value of successor state.\nThe objective function is deﬁned as:\nJ(Θ) =R(st,at)\n= Es,a[\nT −1∑\nj=0\nγjrt+j +γT R(st+T ,at+T )|st,at], (16)\nwhere st and at are denoted as Equation (11) and (12) re-\nspectively. T is the number of time steps. The gradient of\nobjective function is calculated according to the policy gra-\ndient method (Sutton et al. 2000) and the reinforce algorithm\n(Williams 1992):\n∇\nΘJ(Θ) =Es,a[R(st,at)∇Θ logπΘ(st,at)]. (17)\nThe entire training process of the proposed hybrid model\nis described in Algorithm 1.\nAlgorithm 1 Training process for the proposed hybrid\nmodel\n1: INPUT: Training dataB : {B1,B2,...,B N }\n2: for epoch i=1 → E do\n3: for Bk ∈ B do\n4: Calculate hidden state ht according to the trans-\nformer encoding layer\n5: Calculate entity embeddinget according to the en-\ntity detection layer\n6: for each sentencex in Bk do\n7: Calculate statest by Equation (11)\n8: Sample actionat by Equation (12)\n9: Obtain rewardrt by Equation (13)\n10: end for\n11: Jointly optimize entity detection and relation ex-\ntraction module with Equation (15) and (17)\n12: end for\n13: end for\nExperiments\nExperimental Setting\nDataset We evaluate our proposed model on a widely used\ndataset which is developed by the distant supervised method\nand the test set is manually annotated (Hoffmann et al.\n2011). Similar to Takanobu et al. (2019), we also ﬁltered\nthe dataset by removing the sentences which have no rela-\ntion, i.e. theNone relation type, and relations in training set\nbut not in the test set. There are62,648 sentences, 74,312\ntriplets in the training set and370 sentences in the test set,\ndenoted as TestSet1. The size of the relation set is12. Be-\ncause TestSet1 is manually annotated with almost no noisy\ndata, to better evaluate our model on both joint extraction\nand noisy ﬁltration tasks, we also randomly selected5 per-\ncent of the training data as the additional test set, denoted as\nTestSet2, which contains3,763sentences. We use another5\npercent of the remaining training data as the validation set to\ntune the hyperparameters referring to the previous studies.\nParameter Settings Pre-training a transformer based\nmodel is computationally expensive, and our main goal is\nto show the effectiveness of combining pre-trained model\nand downstream models, so we use the pre-trained language\nmodel BERT (Devlin et al. 2019) as our pre-trained encoder.\nWe use the BERT-base version with12 encoder layers, 12\nheads attention, 768 hidden size and about110M parame-\nters. The number of LSTM units in the decoder layer is768.\nThe learning rate is5e−5 for the encoder and entity detec-\ntion module, and is set to0.003in the reinforcement learning\nmodule, and the batch size is16.\nBaselines We choose both the pipelined methods (FCM)\nand the joint learning methods as the baselines. For joint\nlearning methods, we also consider the feature-based model\n(CoType) and neural network based models. Besides, we\nalso do some ablation studies on different variants of our\nmethod to prove the effectiveness of different modules.\n• FCM(Gormley, Y u, and Dredze 2015): a pipelined and\nfeature-rich compositional embedding model which com-\nbines the handcrafted unlexicalized linguistic features and\nword embeddings for relation extraction.\n• CoType(Ren et al. 2017): a framework that jointly repre-\nsents the entity mentions, relation mentions, text features\nand type labels into two meaningful vector spaces which\ndenote entities and relations respectively.\n• SPTree(Miwa and Bansal 2016): an joint extraction\nmodel that represents the word sequence and distance fea-\ntures of the dependency tree with a BiLSTM-RNN struc-\nture.\n• Tagging(Zheng et al. 2017): a joint method to extract the\nentities and relations simultaneously with a novel tagging\nschema. In this model, each word is allocated with a tag\nincluding both the entity and relation information.\n• HRL(Takanobu et al. 2019): a hierarchical reinforcement\nlearning based model that decomposes the joint task into\na high-level relation detection and a low-level entity ex-\ntraction.\n• JRE\nL: a variant of our proposed model which replace\nthe transformer encoder with the traditional bidirectional\nLSTM. In this model we initialize the word vectors with\n300 dimensional Glove vectors (Pennington, Socher, and\nManning 2014), and the batch size is set to128.\n• JRE\nT: a variant of our proposed model with transformer\nencoder but no entity-wise position embedding and rein-\nforcement learning agent.\n• JRE\nT PE: a variant of our proposed model with trans-\nformer encoder and entity-wise position embedding but\nno reinforcement learning agent.\n• JRE TRL: our proposed joint entity and relation extrac-\ntion model with transformer encoder, entity-wise position\nembedding and reinforcement learning agent.\nExperimental Results\nTo evaluate the performance of our proposed model, we\nuse Precision(P), Recall(R) and F-score(F) as the evaluation\nmetrics in the joint entity and relation extraction.\n9318\nTable 1: Results on entity and relation detection respectively.\nCorpus Methods Entity Relation\nPRFPRF\nTestSet1\nFCM - - - 0.502 0.479 0.490\nCoType 0.659 0.620 0.639 0.558 0.558 0.558\nSPTree 0.514 0.442 0.470 0.650 0.614 0.631\nHRL 0.737 0.664 0.699 0.676 0.676 0.676\nJRE L 0.691 0.593 0.638 0.553 0.567 0.560\nJRE T 0.715 0.627 0.668 0.610 0.584 0.597\nJRE T PE 0.720 0.681 0.698 0.710 0.641 0.645\nJRE TRL 0.728 0.720 0.725 0.692 0.683 0.686\nTestSet2\nFCM - - - 0.445 0.362 0.399\nCoType 0.667 0.647 0.657 0.580 0.486 0.529\nSPTree 0.457 0.399 0.415 0.628 0.489 0.548\nHRL 0.696 0.654 0.674 0.626 0.588 0.606\nJRE L 0.644 0.556 0.597 0.542 0.445 0.489\nJRE T 0.652 0.587 0.618 0.578 0.572 0.575\nJRE T PE 0.698 0.628 0.661 0.593 0.606 0.598\nJRE TRL 0.720 0.695 0.708 0.615 0.630 0.623\nEntity and relation extraction results Table 1 compares\nour model with the baseline methods on both entity detec-\ntion and relation classiﬁcation with two test datasets. We\ncalculate the metrics for each label, and ﬁnd their average\nweighted by the number of true instances for each label. For\nentity detection, we only measure the prediction of entity\ntags and ignore the non-entity tags. Precision(P) measures\nthe percentage of correctly predicted entity tags; Recall(R)\nmeasures whether the actual entity tags are correctly pre-\ndicted. For relation classiﬁcation,P denotes the percentage\nof correctly predicted relation class,R denotes whether the\nactual relation types are correctly predicted.\nFCM is a pipelined method which suppose the entities are\nalready tagged, so we only compare the performance of re-\nlation extraction for FCM. It can be seen that our method\n(JRE\nTRL) outperforms other methods on both entity de-\ntection and relation classiﬁcation tasks atR and F metrics.\nAlthough HRL has a higher precision on entity detection,\nwe have got better recall and F-score. The surpass may be-\ncause that HRL optimizes the reinforcement learning agent\nbased on the performance of entity and relation classiﬁcation\non each word, which is very time consuming. All the joint\nmethods perform better than the pipelined method (FCM)\nproves the importance of considering the interactions be-\ntween two tasks. The neural models (SPTree, HRL) are more\nefﬁcient than the feature-based method (CoType) on relation\nextraction, this is because that the neural models can take\nadvantage of various kinds of features, including word em-\nbedding and location features. BothSPTree and JRE\nL uses\nan BiLSTM-RNN structure. But SPTree get worse results\ncompared to JRE L in entity detection task for the lack of\nthe LSTM decoder. ButSPTree performs better on relation\ndetection, because it utilizes not only the vector feature of\nwords, but also the linguistic features, such as the part-of-\nspeech tag, chunks and syntactic parsing tree.\nJRE\nT performs better than JRE L proves that trans-\nformer encoder has better ability on extracting the hidden\nTable 2: Results on the joint entity and relation detection.\nMethods P R F\nFCM 0.432 0.294 0.350\nCoType 0.486 0.386 0.430\nSPTree 0.522 0.541 0.531\nTagging 0.469 0.489 0.479\nHRL 0.538 0.538 0.538\nJRE TRL 0.542 0.542 0.542\nfeature than the BiLSTM.JRE T PE with entity-wise posi-\ntion embedding receives much higher relation classiﬁcation\nresults than JRE\nT demonstrates that the distance between\neach word and entities do affect the relation type. The bet-\nter performance on entity detection also indicates that the\nparameter in JRE\nT PE can properly learn the entity re-\nlated position information from the training data. The pro-\nposed modelJRE\nTRL improves little or even slightly lower\nthan JRE T PE on TestSet1, this is because theTestSet1 is\nmanually annotated and contains almost no noisy sentences,\nleading the reinforcement learning agent not fully works.\nJRE\nTRL improves a lot onTestSet2 than JRE T PE shows\nthat by ﬁltering the noisy sentences, the model can learn bet-\nter information related to the relation, thus can improve the\nperformance.\nJoint extraction results To thoroughly evaluate the pro-\nposed model, we further analyze the joint extraction perfor-\nmance, as shown in Table 2. A prediction is treated as cor-\nrect if both the entity and relation are correctly predicted.\nThe results are similar to those in Table 1, the joint meth-\nods perform better than the pipelined method, and neural\nmodels are more efﬁcient than the feature-based method.\nSPTree also performs good on the recall may because they\nuse many other resources, especially the dependency tree\nin the relation extraction. But this method may cause error\n9319\nTable 3: Some examples of noisy samples detected by our noisy data ﬁltering module.\nRelation /people/person/place lived\nAnd they would never understand why, forBill Elliott, there was no joy inDawsonville.\nRelation /location/location/contains\nThe museum, which opened in theNorth Beach neighborhood of San Francisco last fall, has\nmade plans to sponsor a spring tour of Mr. Morgan’s space scrap in a vintage Airstream trailer,\ncreating a kind of Electric Kool-Aid Acid Test for the astronomy set.\nWinter Park, the fourth-largest ski resort inColorado after Vail, Keystone and Snowmass , has\na Ski for Free program , in which volunteers help to operate the resort ’s racing events in return\nfor free skiing .\npropagation and not suitable for the language with inade-\nquate dependency tree resources. The only minor surpass of\nJRE\nTRL compared to HRL is because thatHRL takes fully\nconsideration of the word-level information and performs\nreinforcement learning on each word. However, we believe\nthat the pre-trained language models, such as BERT used in\nour model, have learned adequate word-level features from\nthe massive training data; it is less meaningful to spend too\nmuch time and computing resources on the word-level fea-\ntures in the downstream tasks.\nThe outperforms of our proposed model on different as-\npects of entity and relation extraction proves the efﬁciency\nof the hybrid transformer and reinforcement learning based\nmethod.\nNoisy data ﬁltering To measure the performance of data\nﬁltering in the reinforcement learning agent, we manually\nannotated 505 sentences, to decide whether the correspond-\ning relation is actually described in the sentences. We use\nthe ﬁltering results from the reinforcement learning agent to\ncompare with the annotated sentences. The 505 annotated\nsentences contain310truly noisy and195not noisy. We de-\nﬁne noisy as positive and not noisy as negative here. The\nprediction results after the reinforcement learning agent are\nas follows: true positive:180, false negative:130, false posi-\ntive: 75, true negative:120. The precision of noisy data ﬁlter-\ning is180/255 = 70.58%, and recall is180/310 = 58.06%,\nwhich demonstrate that our model can properly identify the\nnoisy sentences. In Table 3, we present some examples of\nnoisy sentences which are detected by our noisy data ﬁlter-\ning agent. These sentences are annotated as a speciﬁc re-\nlation type in the dataset, as listed in the relation row. How-\never, they do not actually describe that relation. For example,\nthere is not any valuable information reﬂect that the entity\nBill Elliotthas lived inDawsonville.\nPerformance of the reinforcement learning agent The\naim of the reinforcement learning agent is to optimize the\npolicy function and increase the total reward. To evaluate\nthe performance, we calculate the total reward by Equation\n(13) after each batch of the training process, for better vi-\nsualization, we split the reward values into1,200 parts and\ncalculate the mean of each part, as shown in Figure 2. It\ncan be seen that the reward begins from a small value, then\nincreases as the training iterations, and ﬁnally reach a rela-\ntively stable value. The result proves that the proposed re-\ninforcement learning method is useful on improving the re-\nFigure 2: Change of total rewards of the proposed model.\nwards of the joint extraction task.\nConclusion\nIn this study, we aim at the problem of jointly extracting\nthe entities and relations on noisy data and propose a hy-\nbrid transformer and reinforcement learning based model.\nWe use the attenuation coefﬁcient based position embed-\nding to weight the word vectors for better utilizing the dis-\ntance between words and entity mentions. A transformer en-\ncoder is deployed to take full advantage of the contextual\ninformation and an LSTM decoder layer is used to classify\nthe entity types. Finally, a reinforcement learning agent is\nimplemented for relation classiﬁcation and noisy sentence\nselection. The pooled hidden state from the encoder, ac-\ntive entity embedding from decoder, the removed noisy sen-\ntence embedding and the state of previous time step are all\ntaken as the state input of the reinforcement learning agent.\nThe model is optimized by maximizing the total rewards of\nentity detection and relation classiﬁcation. Experiments are\nlaunched at the following various aspects with a commonly\nused dataset: entity detection, relation classiﬁcation, joint\nextraction of entities and relations, noisy sentence ﬁltering,\nand change of reward values in the reinforcement learn-\ning process. Results show that our proposed hybrid model\nperforms better on relation and entity extraction compared\nto the baseline methods. Our model also has the ability to\nﬁler noisy sentences. As future works, we will enhance our\nmodel for coping with the overlapped and multiple relations.\n9320\nAcknowledgments\nThis work is supported in part by the National Key R\n& D Program of China under Grant 2017YFC0803700,\n2016YFB0801100 and 2017YFB0802300.\nReferences\nAlt, C.; H¨ubner, M.; and Hennig, L. 2019. Fine-tuning pre-\ntrained transformer language models to distantly supervised\nrelation extraction. InACL, 1388–1398.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. InNAACL-HLT, 4171–4186.\nFeng, Y .; Zhang, H.; Hao, W.; and Chen, G. 2017. Joint ex-\ntraction of entities and relations using reinforcement learn-\ning and deep learning.Computational intelligence and neu-\nroscience 2017.\nFeng, J.; Huang, M.; Zhao, L.; Y ang, Y .; and Zhu, X. 2018.\nReinforcement learning for relation classiﬁcation from noisy\ndata. In AAAI, 5779–5786.\nGormley, M. R.; Y u, M.; and Dredze, M. 2015. Improved re-\nlation extraction with feature-rich compositional embedding\nmodels. In EMNLP, 1774–1784.\nHasegawa, T.; Sekine, S.; and Grishman, R. 2004. Discov-\nering relations among named entities from large corpora. In\nACL.\nHoffmann, R.; Zhang, C.; Ling, X.; Zettlemoyer, L.; and\nWeld, D. S. 2011. Knowledge-based weak supervision for\ninformation extraction of overlapping relations. InNAACL-\nHLT, 541–550.\nJi, G.; Liu, K.; He, S.; and Zhao, J. 2017. Distant supervi-\nsion for relation extraction with sentence-level attention and\nentity descriptions. InAAAI, 3060–3066.\nLi, Q., and Ji, H. 2014. Incremental joint extraction of entity\nmentions and relations. InACL, volume 1, 402–412.\nLin, Y .; Shen, S.; Liu, Z.; Luan, H.; and Sun, M. 2016. Neu-\nral relation extraction with selective attention over instances.\nIn ACL, volume 1, 2124–2133.\nLiu, C.; Sun, W.; Chao, W.; and Che, W. 2013. Convolution\nneural network for relation extraction. InInternational Con-\nference on Advanced Data Mining and Applications, 231–\n242. Springer.\nMintz, M.; Bills, S.; Snow, R.; and Jurafsky, D. 2009. Dis-\ntant supervision for relation extraction without labeled data.\nIn Proceedings of the Joint Conference of the 47th Annual\nMeeting of the ACL and the 4th International Joint Confer-\nence on Natural Language Processing of the AFNLP: V ol-\nume 2-V olume 2, 1003–1011.\nMiwa, M., and Bansal, M. 2016. End-to-end relation extrac-\ntion using lstms on sequences and tree structures. InACL,\nvolume 1, 1105–1116.\nMiwa, M., and Sasaki, Y . 2014. Modeling joint entity and\nrelation extraction with table representation. In EMNLP,\n1858–1869.\nNadeau, D., and Sekine, S. 2007. A survey of named entity\nrecognition and classiﬁcation. Lingvisticae Investigationes\n30(1):3–26.\nPennington, J.; Socher, R.; and Manning, C. 2014. Glove:\nGlobal vectors for word representation. InEMNLP, 1532–\n1543.\nQin, P .; Xu, W.; and Wang, W. Y . 2018. Robust distant su-\npervision relation extraction via deep reinforcement learn-\ning. In ACL, 2137–2147.\nRadford, A.; Narasimhan, K.; Salimans, T.; and Sutskever,\nI. 2018. Improving language understanding by generative\npre-training.\nRen, X.; Wu, Z.; He, W.; Qu, M.; V oss, C. R.; Ji, H.; Ab-\ndelzaher, T. F.; and Han, J. 2017. Cotype: Joint extraction of\ntyped entities and relations with knowledge bases. InWWW,\n1015–1024.\nSutton, R. S.; McAllester, D. A.; Singh, S. P .; and Mansour,\nY . 2000. Policy gradient methods for reinforcement learning\nwith function approximation. In Advances in neural infor-\nmation processing systems, 1057–1063.\nTakanobu, R.; Zhang, T.; Liu, J.; and Huang, M. 2019. A hi-\nerarchical framework for relation extraction with reinforce-\nment learning. InAAAI, volume 33, 7072–7079.\nTang, S.; Zhang, J.; Zhang, N.; Wu, F.; Xiao, J.; and Zhuang,\nY . 2017. Encore: External neural constraints regularized\ndistant supervision for relation extraction. InSIGIR, 1113–\n1116. ACM.\nWang, L.; Cao, Z.; De Melo, G.; and Liu, Z. 2016. Re-\nlation classiﬁcation via multi-level attention cnns. InACL\n,\nvolume 1, 1298–1307.\nWang, S.; Zhang, Y .; Che, W.; and Liu, T. 2018. Joint extrac-\ntion of entities and relations based on a novel graph scheme.\nIn IJCAI, 4461–4467.\nWilliams, R. J. 1992. Simple statistical gradient-following\nalgorithms for connectionist reinforcement learning. Ma-\nchine learning8(3-4):229–256.\nWu, J.; Pan, S.; Zhu, X.; Zhang, C.; and Wu, X. 2018.\nMulti-instance learning with discriminative bag mapping.\nIEEE Transactions on Knowledge and Data Engineering\n30(6):1065–1080.\nY uan, C.; Huang, H.; Feng, C.; Liu, X.; and Wei, X. 2019.\nDistant supervision for relation extraction with linear attenu-\nation simulation and non-iid relevance embedding. InAAAI,\nvolume 33, 7418–7425.\nZeng, D.; Liu, K.; Chen, Y .; and Zhao, J. 2015. Distant su-\npervision for relation extraction via piecewise convolutional\nneural networks. InEMNLP, 1753–1762.\nZheng, S.; Wang, F.; Bao, H.; Hao, Y .; Zhou, P .; and Xu, B.\n2017. Joint extraction of entities and relations based on a\nnovel tagging scheme. InACL, volume 1, 1227–1236.\nZhou, P .; Shi, W.; Tian, J.; Qi, Z.; Li, B.; Hao, H.; and Xu, B.\n2016. Attention-based bidirectional long short-term mem-\nory networks for relation classiﬁcation. InACL, volume 2,\n207–212.\n9321"
}