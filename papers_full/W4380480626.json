{
  "title": "Pre-trained Multimodal Large Language Model Enhances Dermatological Diagnosis using SkinGPT-4",
  "url": "https://openalex.org/W4380480626",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3013334361",
      "name": "Juexiao Zhou",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2146830989",
      "name": "Xiaonan He",
      "affiliations": [
        "Beijing Anzhen Hospital",
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2117408619",
      "name": "Liyuan Sun",
      "affiliations": [
        "Beijing Anzhen Hospital",
        "Capital Medical University"
      ]
    },
    {
      "id": "https://openalex.org/A2184988452",
      "name": "Jiannan Xu",
      "affiliations": [
        "Capital Medical University",
        "Beijing Anzhen Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2109115853",
      "name": "xiuying chen",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3112786644",
      "name": "Yuetan Chu",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2210167350",
      "name": "Longxi Zhou",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2309994020",
      "name": "Xingyu Liao",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2031448644",
      "name": "Bin Zhang",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2103988188",
      "name": "Xin Gao",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3013334361",
      "name": "Juexiao Zhou",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2146830989",
      "name": "Xiaonan He",
      "affiliations": [
        "Capital Medical University",
        "Beijing Anzhen Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2117408619",
      "name": "Liyuan Sun",
      "affiliations": [
        "Beijing Anzhen Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2184988452",
      "name": "Jiannan Xu",
      "affiliations": [
        "Beijing Anzhen Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2109115853",
      "name": "xiuying chen",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3112786644",
      "name": "Yuetan Chu",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2210167350",
      "name": "Longxi Zhou",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2309994020",
      "name": "Xingyu Liao",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2031448644",
      "name": "Bin Zhang",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2103988188",
      "name": "Xin Gao",
      "affiliations": [
        "King Abdullah University of Science and Technology"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2051521434",
    "https://openalex.org/W2892342267",
    "https://openalex.org/W3025011581",
    "https://openalex.org/W2742893201",
    "https://openalex.org/W2072629969",
    "https://openalex.org/W2012945985",
    "https://openalex.org/W2784963878",
    "https://openalex.org/W4220786947",
    "https://openalex.org/W4284898303",
    "https://openalex.org/W4212936931",
    "https://openalex.org/W4207031999",
    "https://openalex.org/W4360763710",
    "https://openalex.org/W3025830737",
    "https://openalex.org/W4364295707",
    "https://openalex.org/W3014403957",
    "https://openalex.org/W4205499468",
    "https://openalex.org/W2581082771",
    "https://openalex.org/W2786147899",
    "https://openalex.org/W2806853752",
    "https://openalex.org/W2757940437",
    "https://openalex.org/W2917303411",
    "https://openalex.org/W2892053105",
    "https://openalex.org/W2947367580",
    "https://openalex.org/W2903060508",
    "https://openalex.org/W2993820249",
    "https://openalex.org/W4281783336",
    "https://openalex.org/W2945626616",
    "https://openalex.org/W2941548848",
    "https://openalex.org/W2963258365",
    "https://openalex.org/W2807032201",
    "https://openalex.org/W2765773998",
    "https://openalex.org/W2785200097",
    "https://openalex.org/W4322766760",
    "https://openalex.org/W1932469787",
    "https://openalex.org/W2607363228",
    "https://openalex.org/W2952971376",
    "https://openalex.org/W2519210008",
    "https://openalex.org/W4313451803",
    "https://openalex.org/W4361282369",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4323030608",
    "https://openalex.org/W4318829849",
    "https://openalex.org/W4321459182",
    "https://openalex.org/W4323348223",
    "https://openalex.org/W4365441234",
    "https://openalex.org/W4324387439",
    "https://openalex.org/W4323830259",
    "https://openalex.org/W4379259189",
    "https://openalex.org/W4321018175",
    "https://openalex.org/W6851467109",
    "https://openalex.org/W4317878668",
    "https://openalex.org/W4220791724",
    "https://openalex.org/W4321781611",
    "https://openalex.org/W4321444413",
    "https://openalex.org/W4366850747",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W4318718936",
    "https://openalex.org/W4386076522",
    "https://openalex.org/W2886641317",
    "https://openalex.org/W2109586012",
    "https://openalex.org/W3209532394",
    "https://openalex.org/W4375830716",
    "https://openalex.org/W4383815588",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4206961607"
  ],
  "abstract": "Abstract Large language models (LLMs) are seen to have tremendous potential in advancing medical diagnosis recently. However, it is important to note that most current LLMs are limited to text interaction alone. Meanwhile, the development of multimodal large language models for medical diagnosis is still in its early stages, particularly considering the prevalence of image-based data in the field of medical diagnosis, among which dermatological diagnosis is a very important task as skin and subcutaneous diseases rank high among the leading contributors to the global burden of nonfatal diseases. Inspired by current state-of-the-art multimodal large language models, we present SkinGPT-4, which is the world’s first interactive dermatology diagnostic system based on multimodal large language models. To implement SkinGPT-4, we have designed a new framework that aligned a pre-trained vision transformer with a large language model named Falcon-40B-Instruct, which is based on Falcon. To train SkinGPT-4, we have collected an extensive collection of skin disease images (comprising 52,929 publicly available and proprietary images) along with clinical concepts and doctors’ notes and designed a two-step training strategy. To demonstrate the robustness of SkinGPT-4, we have conducted quantitative evaluations on 150 real-life cases, which were independently reviewed by certified dermatologists. With SkinGPT-4, users could upload their own skin photos for diagnosis, and the system could autonomously evaluate the images, identifies the characteristics and categories of the skin conditions, performs in-depth analysis, and provides interactive treatment recommendations. Meanwhile, SkinGPT-4’s local deployment capability and commitment to user privacy also render it an appealing choice for patients. Though SkinGPT-4 is not a substitute for doctors, it could enhance users’ comprehension of their medical conditions, facilitate improve communication between patients and doctors, expedite the diagnostic process for dermatologists, facilitate triage, and potentially promote human-centred care and healthcare equity in underdeveloped areas. In summary, SkinGPT-4 represents a significant leap forward in the field of dermatology diagnosis in the era of large language models and a valuable exploration of multimodal large language models in medical diagnosis.",
  "full_text": "1\nSkinGPT -4: An Interactive Dermatology\nDiagnostic System with Visual Large Language\nModel\nJuexiao Zhou1,2,#, Xiaonan He3,#,∗, Liyuan Sun4,#, Jiannan Xu4, Xiuying Chen1,2, Yuetan Chu1,2, Longxi\nZhou1,2, Xingyu Liao1,2, Bin Zhang1,2, Xin Gao1,2,∗\nAbstract—Skin and subcutaneous diseases rank high among the leading contributors to the global burden of nonfatal diseases,\nimpacting a considerable portion of the population. Nonetheless, the field of dermatology diagnosis faces three significant hurdles.\nFirstly, there is a shortage of dermatologists accessible to diagnose patients, particularly in rural regions. Secondly, accurately\ninterpreting skin disease images poses a considerable challenge. Lastly, generating patient-friendly diagnostic reports is usually a\ntime-consuming and labor-intensive task for dermatologists. To tackle these challenges, we present SkinGPT -4, which is the world’s\nfirst interactive dermatology diagnostic system powered by an advanced visual large language model. SkinGPT -4 leverages a\nfine-tuned version of MiniGPT -4, trained on an extensive collection of skin disease images (comprising 52,929 publicly available and\nproprietary images) along with clinical concepts and doctors’ notes. We designed a two-step training process to allow SkinGPT -4 to\nexpress medical features in skin disease images with natural language and make accurate diagnoses of the types of skin diseases.\nWith SkinGPT -4, users could upload their own skin photos for diagnosis, and the system could autonomously evaluate the images,\nidentifies the characteristics and categories of the skin conditions, performs in-depth analysis, and provides interactive treatment\nrecommendations. Meanwhile, SkinGPT -4’s local deployment capability and commitment to user privacy also render it an appealing\nchoice for patients in search of a dependable and precise diagnosis of their skin ailments. To demonstrate the robustness of SkinGPT -4,\nwe conducted quantitative evaluations on 150 real-life cases, which were independently reviewed by certified dermatologists, and\nshowed that SkinGPT -4 could provide accurate diagnoses of skin diseases. Though SkinGPT -4 is not a substitute for doctors, it could\nenhance users’ comprehension of their medical conditions, facilitate improve communication between patients and doctors, expedite\nthe diagnostic process for dermatologists, and potentially promote human-centred care and healthcare equity in underdeveloped areas.\nIndex Terms—Dermatology, Deep learning, Large language model\n✦\n1 I NTRODUCTION\nSkin and subcutaneous diseases rank as the fourth major\ncause of nonfatal disease burden worldwide, affecting a\nconsiderable proportion of individuals, with a prevalence\nranging from 30% to 70% across all ages and regions [1].\nHowever, dermatologists are consistently in short supply,\nparticularly in rural areas, and consultation costs are on\nthe rise [2], [3], [4]. As a result, the responsibility of di-\nagnosis often falls on non-specialists such as primary care\n1Computer Science Program, Computer, Electrical and Mathematical Sciences\nand Engineering Division, King Abdullah University of Science and Technol-\nogy (KAUST), Thuwal 23955-6900, Kingdom of Saudi Arabia\n2Computational Bioscience Research Center, King Abdullah University of\nScience and Technology (KAUST), Thuwal 23955-6900, Kingdom of Saudi\nArabia\n3Emergency Critical Care Center, Beijing AnZhen Hospital, Affiliated to\nCapital Medical University, Beijing 100029, China\n4Department of Dermatology, Beijing AnZhen Hospital, Affiliated to Capital\nMedical University, Beijing 100029, China\n#These authors contributed equally.\n∗Corresponding author. e-mail: xin.gao@kaust.edu.sa\nphysicians, nurse practitioners, and physician assistants,\nwhich may have limited knowledge and training [5] and\nlow accuracy on diagnosis [6], [7]. The use of store-and-\nforward teledermatology has become dramatically popular\nin order to expand the range of services available to medical\nprofessionals [8], which involves transmitting digital images\nof the affected skin area (usually taken using a digital\ncamera or smartphone) [9] and other relevant medical in-\nformation from users to dermatologists. Then, the derma-\ntologist reviews the case remotely and advises on diagnosis,\nworkup, treatment, and follow-up recommendations [10],\n[11]. Nonetheless, the field of dermatology diagnosis faces\nthree significant hurdles [12]. Firstly, there is a shortage\nof dermatologists accessible to diagnose patients, partic-\nularly in rural regions. Secondly, accurately interpreting\nskin disease images poses a considerable challenge. Lastly,\ngenerating patient-friendly diagnostic reports is usually a\ntime-consuming and labor-intensive task for dermatologists\n[4], [13].\nAdvancements in technology have led to the develop-\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2\nment of various tools and techniques to aid dermatolo-\ngists in their diagnosis [13], [14], [15]. For example, the\ndevelopment of artificial intelligence tools to aid in the\ndiagnosis of skin disorders from images has been made\npossible by recent advancements in deep learning [16], [17],\nsuch as skin cancer classification [18], [19], [20], [21], [22],\n[23], [24], [25], [26], [27], dermatopathology [28], [29], [30],\npredicting novel risk factors or epidemiology [31], [32],\nidentifying onychomycosis [33], quantifying alopecia areata\n[34], classify skin lesions from mpox virus infection [35], and\nso on [4]. Among these, most studies have predominantly\nconcentrated on identifying skin lesions through dermo-\nscopic images [36], [37], [38]. However, dermatoscopy is\noften not readily available outside of dermatology clinics.\nSome studies have explored the use of clinical photographs\nof skin cancer [18], onychomycosis [33], and skin lesions on\neducational websites [39]. Nevertheless, those methods are\ntailored for particular diagnostic objectives as classification\ntasks and their approach still requires further analysis by\ndermatologists to issue reports and make clinical decisions.\nThose methods are unable to automatically generate de-\ntailed reports in natural language and allow interactive\ndialogues with patients. At present, there are no such di-\nagnostic systems available for users to self-diagnose skin\nconditions by submitting images that can automatically and\ninteractively analyze and generate easy-to-understand text\nreports.\nOver the past few months, the field of large language\nmodels (LLMs) has seen significant advancements [40], [41],\noffering remarkable language comprehension abilities and\nthe potential to perform complex linguistic tasks. One of\nthe most anticipated models is GPT-4 [42], which is a large-\nscale multimodal model that has demonstrated exceptional\ncapabilities, such as generating accurate and detailed im-\nage descriptions, providing explanations for atypical visual\noccurrences, constructing websites based on handwritten\ntextual descriptions, and even acting as family doctors [43].\nDespite these remarkable advancements, some features of\nGPT-4 are still not accessible to the public and are closed-\nsource. Users need to pay and use some features through\nAPI. As an accessible alternative, ChatGPT, which is also\ndeveloped by OpenAI, has demonstrated the potential to as-\nsist in disease diagnosis through conversation with patients\n[44], [45], [46], [46], [47], [48], [49]. By leveraging its ad-\nvanced natural language processing capabilities, ChatGPT\ncould interpret symptoms and medical history provided\nby patients and make suggestions for potential diagnoses\nor referrals to appropriate dermatological specialists [50].\nHowever, ChatGPT currently only allows text input and\ndoes not support direct image input for diagnosis, which\nlimits its availability for dermatological diagnosis.\nThe idea of providing skin images directly for auto-\nmatic dermatological diagnosis and generating text reports\nis exciting because it could greatly help solve the three\naforementioned challenges in the field of dermatology di-\nagnosis. However, there exists no method to accomplish\nthis at present. But in related areas, ChatCAD [51] is one\nof the most advanced approaches that designed various\nnetworks to take X-rays, CT scans, and MRIs images to\ngenerate diverse outputs, which are then transformed into\ntext descriptions. These descriptions are combined as in-\nputs to ChatGPT to generate a condensed report and of-\nfer interactive explanations and medical recommendations\nbased on the given image. However, their proposed vision-\ntext models were limited to certain tasks. Meanwhile, for\nChatCAD, users need to use ChatGPT’s API to upload text\ndescriptions, which could raise data privacy issues [41], [52],\n[53] as both medical images and text descriptions contain a\nlot of patients’ private information [54], [55], [56], [57]. To\naddress those issues, MiniGPT-4 [58] is the first open-source\nmethod that allows users to deploy locally to interface\nimages with state-of-the-art LLMs and interact using natural\nlanguage without the need to fine-tune both pre-trained\nlarge models but only a small alignment layer. MiniGPT-\n4 aims to combine the power of a large language model\nwith visual information obtained from a pre-trained vision\nencoder. To achieve this, the model uses Vicuna [59] as its\nlanguage decoder, which is built on top of LLaMA [60] and\nis capable of performing complex linguistic tasks. To process\nvisual information, the same visual encoder used in BLIP-2\n[61] is employed, which consists of a ViT [62] backbone com-\nbined with a pre-trained Q-Former. Both the language and\nvision models are open-source. To bridge the gap between\nthe visual encoder and the language model, MiniGPT-4\nutilizes a linear projection layer. However, MiniGPT-4 is\ntrained on the combined dataset of Conceptual Caption [63],\nSBU [64], and LAION [65], which are irrelevant to medical\nimages, especially dermatological images. Therefore, it is\nstill challenging to directly apply MiniGPT-4 to specific\ndomains such as formal dermatology diagnosis.\nHere, we propose SkinGPT-4, the world’s first derma-\ntology diagnostic system powered by an advanced vision-\nbased large language model (Figure 1). SkinGPT-4 leverages\na fine-tuned version of MiniGPT-4, trained on an extensive\ncollection of skin disease images (comprising 52,929 publicly\navailable and proprietary images) along with clinical con-\ncepts and doctors’ notes. We designed a two-step training\nprocess to develop SkinGPT-4 as shown in Figure 2. In\nthe initial step, SkinGPT-4 aligns visual and textual clinical\nconcepts, enabling it to recognize medical features within\nskin disease images and express those medical features\nwith natural language. In the subsequent step, SkinGPT-\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n3\nFig. 1. Illustration of SkinGPT -4. SkinGPT -4 incorporates a fine-tuned version of MiniGPT -4 on a vast collection (52,929) of both public and in-\nhouse skin disease images, accompanied by clinical concepts and doctors’ notes. With SkinGPT -4, users could upload their own skin photos for\ndiagnosis, and SkinGPT -4 could autonomously determine the characteristics and categories of skin conditions, perform analysis, provide treatment\nrecommendations, and allow interactive diagnosis. On the right is an example of interactive diagnosis.\n4 learns to accurately diagnoses the specific types of skin\ndiseases. This comprehensive training methodology ensures\nthe system’s proficiency in analyzing and classifying various\nskin conditions. With SkinGPT-4, users have the ability to\nupload their own skin photos for diagnosis. The system\nautonomously evaluates the images, identifies the charac-\nteristics and categories of the skin conditions, performs\nin-depth analysis, and provides interactive treatment rec-\nommendations (Figure 3). Moreover, SkinGPT-4’s localized\ndeployment capability and a strong commitment to user\nprivacy make it a trustworthy and precise diagnostic tool for\npatients seeking reliable assessments of their skin ailments.\nMeanwhile, we showed that SkinGPT-4 could empower\npatients to gain a clearer understanding of their symptoms,\ndiagnosis, and treatment plans, which could help patients\nengage in more effective and economical consultations with\ndermatologists. With SkinGPT-4, patients can have more\ninformed conversations with their doctors, leading to better\ntreatment outcomes and a higher level of satisfaction. To\ndemonstrate the robustness of SkinGPT-4, we conducted\nquantitative evaluations on 150 real-life cases, which were\nindependently reviewed by certified dermatologists (Figure\n4 and Supplementary information). The results showed\nthat SkinGPT-4 consistently provided accurate diagnoses of\nskin diseases. It is important to note that while SkinGPT-\n4 is not a substitute for medical professionals, it greatly\nenhances users’ understanding of their medical conditions,\nfacilitates improved communication between patients and\ndoctors, expedites the diagnostic process for dermatologists,\nand has the potential to advance human-centred care and\nhealthcare equity, particularly in underdeveloped regions\n[66]. In summary, SkinGPT-4 represents a significant leap\nforward in the field of dermatology diagnosis in the era of\nlarge language models.\n2 R ESULTS\n2.1 The Overall Design of SkinGPT-4\nSkinGPT-4 is an interactive system designed to provide a\nnatural language-based diagnosis of skin disease images\nas shown in Figure 1. The process commences when the\nuser uploads a skin image, which undergoes encoding by\nthe Vision Transformer (VIT) and Q-Transformer models\nto comprehend its contents. The VIT model partitions the\nimage into smaller patches and extracts vital features like\nedges, textures, and shapes. After that, the Q-Transformer\nmodel generates an embedding of the image based on the\nfeatures identified by the VIT model, which is done by using\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n4\nFig. 2. Illustration of our datasets for two-step training of SkinGPT -4. The notes below each image indicate clinical concepts and types of skin\ndiseases. In addition, we have detailed descriptions from the certified dermatologists for images in the step 2 dataset. To avoid causing discomfort,\nwe used a translucent grey box to obscure the displayed skin disease images.\na transformer-based architecture that allows the model to\nconsider the context of the image. The alignment layer\nfacilitates the synchronization of visual information and\nnatural language, and the Vicuna component generates the\ntext-based diagnosis. SkinGPT-4 is fine-tuned on MiniGPT-4\nusing large skin disease images along with clinical concepts\nand doctors’ notes to allow for interactive dermatological\ndiagnosis. The system could provide an interactive and\nuser-friendly way to help users self-diagnose skin diseases.\n2.2 Interactive, Informative and Understandable Der-\nmatology Diagnosis of SkinGPT-4\nSkinGPT-4 brings forth a multitude of advantages for\nboth patients and dermatologists. One notable benefit\nlies in its utilization of comprehensive and trustworthy\nmedical knowledge specifically tailored to skin diseases.\nThis empowers SkinGPT-4 to deliver interactive diag-\nnoses, explanations, and recommendations for skin diseases\n(Supplementary Video), which presents a challenge for\nMiniGPT-4. Unlike MiniGPT-4, which lacks training with\npertinent medical knowledge and domain-specific adapta-\ntion, SkinGPT-4 overcomes this limitation, enhancing its\nproficiency in the dermatological domain. To demonstrate\nthe advantage of SkinGPT-4 over MiniGPT-4, we presented\ntwo real-life examples of interactive diagnosis as shown in\nFigure 3. In Figure 3a, an image is presented of an elderly\nwith actinic keratosis on her face. In Figure 3b, an image is\nprovided of a patient with eczema fingertips.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n5\nFig. 3. Diagnosis generated by SkinGPT -4, SkinGPT -4 (step 1 only), SkinGPT -4 (step 2 only), MiniGPT -4 and Dermatologists.a. A case of actinic\nkeratosis. b. A case of eczema fingertips.\nFor the actinic keratosis case (Figure 3a), MiniGPT-4\nidentified features like small and red bumps, and incorrectly\ndiagnosed the skin disease as acne, while SkinGPT-4 iden-\ntified features like plaque, nodules, pustules, and scarring,\nand diagnosed the skin disease as actinic keratosis, which is\na common skin condition caused by prolonged exposure to\nthe sun’s ultraviolet (UV) rays [67]. During the interactive\ndialogue, SkinGPT-4 also suggested the cause of the skin\ndisease to be sun exposure, which was also verified as\ncorrect by the certified dermatologist. For the example of\neczema fingertips case (Figure 3b), MiniGPT-4 identified\nsome features like cracks and skin flakes, missed the type\nof the skin disease, and diagnosed the cause of the skin\ndisease to be dry weather and excessive hand washing. In\ncomparison, SkinGPT-4 identified either the features of the\nskin disease as dry itchy and flaky skin, and diagnosed the\ntype of the skin disease to be eczema fingertips, which was\nalso verified by certified dermatologists.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n6\nFig. 4. Clinical evaluation of SkinGPT -4 by certified offline and online dermatologists. a. Questionnaire-based assessment of SkinGPT -4 by offline\ndermatologists. b. Response time of SkinGPT -4 compared to consulting dermatologists online.\nIn summary, the absence of dermatological knowledge\nand domain-specific adaptation poses a significant chal-\nlenge for MiniGPT-4 in achieving accurate dermatological\ndiagnoses. Contrastingly, SkinGPT-4 successfully and ac-\ncurately identified the characteristics of the skin diseases\ndisplayed in the images. It not only suggested potential\ndisease types but also provided recommendations for poten-\ntial treatments. This further highlights that domain-specific\nadaption is crucial for SkinGPT-4 to work for the dermato-\nlogical diagnosis.\n2.3 SkinGPT-4 Masters Medical Features to Improve Di-\nagnosis with the Two-step Training\nTo further illustrate the capability of SkinGPT-4 in enhanc-\ning dermatological diagnosis through learning medical fea-\ntures in skin disease images, we conducted ablation studies,\nas depicted in Figure 3 by training SkinGPT-4 using either\nsolely the step 1 dataset or solely the step 2 dataset. As\nspecified in Method and illustrated in Figure 2, we designed\na two-step training process for SkinGPT-4. Initially, we\nutilized the step 1 dataset to familiarize SkinGPT-4 with\nthe medical features present in dermatological images and\nallow SkinGPT-4 to express medical features in skin disease\nimages with natural language. Subsequently, we employed\nthe step 2 dataset to train SkinGPT-4 to achieve a more\nprecise diagnosis of disease types.\nIn the instance of actinic keratosis (Figure 3a), which\nis a hard case, SkinGPT-4 trained solely on the step 1\ndataset demonstrated its proficiency in identifying pertinent\nmedical features such as plaque, crust, erythema, and umbil-\nicated. These precise and comprehensive morphological de-\nscriptions accurately captured the characteristics of the skin\ndisease depicted in the image. However, when SkinGPT-4\nwas exclusively trained on the step 1 dataset, it erroneously\ndiagnosed the skin condition as a viral infection, indicating\nthe importance of incorporating the step 2 dataset for more\naccurate disease identification. In contrast, when trained\nsolely on the step 2 dataset, SkinGPT-4 failed to capture the\naccurate morphological descriptions of the skin diseases and\ninstead incorrectly diagnosed it as the result of excessive\nsebum production. It highlights the necessity of incorpo-\nrating the step 1 dataset to effectively recognize and com-\nprehend the specific medical features essential for precise\ndermatological diagnoses. In comparison, SkinGPT-4 with\nour two-step training simultaneously identified the medical\nfeatures, such as plaque, nodules, pustules and scarring, and\ndiagnosed the skin disease as actinic keratosis. For simple\ncases such as the eczema fingertips shown in Figure 3b,\nSkinGPT-4 could also provide more detailed descriptions of\nthe skin disease image, encompass the medical features and\naccurately identify the type of skin disease. In conclusion,\nthe two-step training process we have implemented allows\nSkinGPT-4 to effectively comprehend and master medical\nfeatures in dermatological images, thereby significantly en-\nhancing the accuracy of diagnoses, which is particularly\ncrucial for hard cases where precise identification of medical\nfeatures is paramount to accurately determining the type of\ndisease.\n2.4 Clinical Evaluation of SkinGPT-4 by Certified Der-\nmatologists\nTo evaluate the reliability and robustness of SkinGPT-4, we\nconducted a comprehensive study involving a large number\nof real-life cases (150) and compared its diagnoses with\nthose of certified dermatologists. The results, presented in\nTable 2 and Supplementary information, demonstrated that\nSkinGPT-4 consistently provided accurate diagnoses that\nwere in agreement with those of the certified dermatologists\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n7\nas shown in Figure 4, as well as in all cases detailed in the\nSupplementary information.\nAmong the 150 cases, a significant percentage of\nSkinGPT-4’s diagnoses (78.76%) were evaluated as correct\nor relevant by certified dermatologists. This evaluation en-\ncompassed both strongly agree (73.13%) and agree (5.63%).\nAdditionally, SkinGPT-4’s responses regarding the causes\nof the disease and potential treatments were considered\ninformative (80.63%) and useful (83.13%) by the doctors.\nFurthermore, SkinGPT-4 proved to be a valuable tool for\ndoctors in the diagnosis process (85%) and for patients in\ngaining a better understanding of their diseases (81.25%).\nThe capability of SkinGPT-4 to support local deployment,\nensuring user privacy, garnered high agreement (91.88%),\nfurther enhancing the willingness to utilize SkinGPT-4\n(75%).\nOverall, the study demonstrated that SkinGPT-4 delivers\nreliable diagnoses, aids doctors in the diagnostic process, fa-\ncilitates patient understanding, and prioritizes user privacy,\nmaking it a valuable asset in the field of dermatology.\n2.5 SkinGPT-4 Acts as a 24/7 On-call Family Doctor\nIn comparison to online consultations with dermatologists,\nwhich often entail waiting minutes for a response, SkinGPT-\n4 offers several advantages. Firstly, it is available 24/7,\nensuring constant access to medical advice. Additionally,\nSkinGPT-4 provides faster response times, typically within\nseconds, as depicted in Figure 4b, which makes it a swift\nand convenient option for patients requiring immediate\ndiagnoses outside of regular office hours.\nMoreover, SkinGPT-4’s ability to offer preliminary di-\nagnoses empowers patients to make informed decisions\nabout seeking in-person medical attention. This feature can\nhelp reduce unnecessary visits to the doctor’s office, saving\npatients both time and money. The potential to improve\nhealthcare access is particularly significant in rural areas or\nregions experiencing a scarcity of dermatologists. In such\nareas, patients often face lengthy waiting times or must\ntravel considerable distances to see a dermatologist [68]. By\nleveraging SkinGPT-4, patients can swiftly and conveniently\nreceive preliminary diagnoses, potentially diminishing the\nneed for in-person visits and alleviating the strain on health-\ncare systems in these underserved regions.\n3 M ETHODS\n3.1 Dataset\nOur datasets include two public datasets and our private\nin-house dataset, where the first public dataset was used for\nthe step 1 training, and the second public dataset and our\nin-house dataset were used for the step 2 training.\nTABLE 1\nCharacteristics of Step 1 Dataset. It is possible for a single image to\nhave multiple medical concepts at the same time. The total number of\nsamples is 3886.\nClinical Concepts Number of Samples\nErythema 2139\nPlaque 1966\nPapule 1169\nBrown(Hyperpigmentation) 759\nScale 686\nCrust 497\nWhite(Hypopigmentation) 257\nYellow 245\nErosion 200\nNodule 189\nUlcer 154\nFriable 153\nPatch 149\nDome-shaped 146\nExudate 144\nScar 123\nPustule 103\nTelangiectasia 100\nBlack 90\nPurple 85\nAtrophy 69\nBulla 64\nUmbilicated 49\nVesicle 46\nWarty/Papillomatous 46\nExcoriation 46\nExophytic/Fungating 42\nXerosis 35\nInduration 33\nFissure 32\nSclerosis 27\nPedunculated 26\nLichenification 25\nComedo 24\nWheal 21\nFlat topped 18\nTranslucent 16\nMacule 13\nSalmon 10\nPurpura/Petechiae 10\nAcuminate 8\nCyst 6\nBlue 5\nAbscess 5\nPoikiloderma 5\nBurrow 5\nGray 5\nPigmented 5\nThe first public dataset named SKINCON [69] is the\nfirst medical dataset densely annotated by domain experts\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n8\nTABLE 2\nCharacteristics of Step 2 Dataset and Clinical Evaluation Dataset.\nMajor Classes of Skin Disease Number of Samples\nin Step 2 Dataset\nNumber of Samples\nin Clinical Evaluation Dataset\nAcne and Rosacea 840 10\nMalignant Lesions (Actinic Keratosis, Basal Cell Carcinoma, etc.) 8166 10\nDermatitis (Atopic Dermatitis, Eczema, Exanthems, Drug Eruptions, Contact Dermatitis, etc.) 5262 10\nBullous Disease 448 10\nBacterial Infections (Cellulitis, Impetigo, etc.) 228 10\nLight Diseases (vitiligo, sun damaged skin, etc.) 568 10\nConnective Tissue diseases (Lupus, etc.) 420 10\nBenign Tumors (Seborrheic Keratoses, etc.) 1916 10\nMelanoma Skin Cancer, Nevi, Moles 23373 10\nFungal Infections (Nail Fungus, Tinea Ringworm, Candidiasis, etc.) 2340 10\nPsoriasis and Lichen Planus 3460 10\nInfestations and Bites (Scabies, Lyme Disease, etc.) 431 10\nUrticaria Hives 212 10\nVascular Tumors 735 10\nHerpes 405 10\nOthers 239 /\nTotal 49043 150\nto provide annotations useful across multiple disease pro-\ncesses. SKINCON is a skin disease dataset densely anno-\ntated by dermatologists and it includes 3230 images from\nthe Fitzpatrick 17k skin disease dataset densely annotated\nwith 48 clinical concepts as shown in Table 1, 22 of which\nhave at least 50 images representing the concept, and 656\nskin disease images from the Diverse Dermatology Images\ndataset. The 48 clinical concepts proposed by SKINCON\ninclude Vesicle, Papule, Macule, Plaque, Abscess, Pustule,\nBulla, Patch, Nodule, Ulcer, Crust, Erosion, Excoriation, At-\nrophy, Exudate, Purpura/Petechiae, Fissure, Induration, Xe-\nrosis, Telangiectasia, Scale, Scar, Friable, Sclerosis, Peduncu-\nlated, Exophytic/Fungating, Warty/Papillomatous, Dome-\nshaped, Flat-topped, Brown (Hyperpigmentation), Translu-\ncent, White (Hypopigmentation), Purple, Yellow, Black, Ery-\nthema, Comedo, Lichenification, Blue, Umbilicated, Poik-\niloderma, Salmon, Wheal, Acuminate, Burrow, Gray, Pig-\nmented, and Cyst.\nThe second public dataset named the Dermnet contains\n18,856 images, which are further classified into 15 classes\nby our board-certified dermatologists, including Acne and\nRosacea, Malignant Lesions (Actinic Keratosis, Basal Cell\nCarcinoma, etc.), Dermatitis (Atopic Dermatitis, Eczema,\nExanthems, Drug Eruptions, Contact Dermatitis, etc.), Bul-\nlous Disease, Bacterial Infections (Cellulitis, Impetigo, etc.),\nLight Diseases (vitiligo, sun damaged skin, etc.), Connective\nTissue diseases (Lupus, etc.), Benign Tumors (Seborrheic\nKeratoses, etc.), Melanoma Skin Cancer (Nevi, Moles, etc.),\nFungal Infections (Nail Fungus, Tinea Ringworm, Candidi-\nasis, etc.), Psoriasis and Lichen Planus, Infestations and\nBites (Scabies, Lyme Disease, etc.), Urticaria Hives, Vascular\nTumors, Herpes, and others.\nOur private in-house dataset contains 30,187 pairs of skin\ndisease images and corresponding doctors’ descriptions.\nThe complete dataset for step 2 training comprises in total\nof 49,043 pairs of images and textual descriptions as shown\nin Table 2.\n3.2 The two-step training of SkinGPT-4\nSkinGPT-4 was trained using a vast of skin disease images\nalong with clinical concepts and doctors’ notes (Figure 1).\nIn the first step, we fine-tuned the pre-trained MiniGPT-4\nmodel using the step 1 training dataset. This dataset consists\nof paired skin disease images along with corresponding\ndescriptions of clinical concepts. By training SkinGPT-4 on\nthis dataset, we enabled the model to grasp the nuances of\nclinical concepts specific to skin diseases.\nIn the second step, we further refined the model by\nfine-tuning it using the step 2 dataset, which comprises\nadditional skin images and refined doctors’ notes. This\niterative training process facilitated the accurate diagnosis of\nvarious skin diseases, as SkinGPT-4 incorporated the refined\nmedical insights from the doctors’ notes.\nBy following this two-step fine-tuning approach,\nSkinGPT-4 attained an enhanced understanding of clinical\nconcepts related to skin diseases and acquired the profi-\nciency to generate accurate diagnoses.\n3.3 Model Training and Resources\nDuring the training of both steps, the max number of\nepochs was fixed to 20, the iteration of each epoch was\nset to 5000, the warmup step was set to 5000, batch size\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n9\nwas set to 2, the learning rate was set to 1e-4, and max\ntext length was set to 160. The entire fine-tuning process\nrequired approximately 9 hours to complete and utilized\ntwo NVIDIA V100 (32GB) GPUs. During inference, only one\nNVIDIA V100 (32GB) GPU was necessary. SkinGPT-4 was\ndeveloped using Python 3.7, PyTorch 1.9.1, and CUDA 11.4.\nFor a comprehensive list of dependencies, please refer to our\ncode availability documentation. The training and inference\nprocedures were conducted on a workstation equipped with\n252 GB RAM, 112 CPU cores, and two NVIDIA V100 GPUs,\nwhich provided the computational resources necessary for\nefficient model training and inference.\n3.4 Clinical Evaluation of SkinGPT-4\nTo assess the reliability and effectiveness of SkinGPT-4, we\nassembled a dataset comprising 150 real-life cases of various\nskin diseases as shown in Table 2. Interactive diagnosis ses-\nsions were conducted with SkinGPT-4, utilizing four specific\nprompts:\n1. Could you describe the skin disease in this image for\nme?\n2. Please provide a paragraph listing additional features\nyou observed in the image.\n3. Based on the previous information, please provide a\ndetailed explanation of the cause of this skin disease.\n4. What treatment and medication should be recom-\nmended for this case?\nTo conduct the clinical evaluation, certified dermatolo-\ngists were provided with the same set of four questions\nand were required to make diagnoses based on the given\nskin disease images. Meanwhile, the dermatologists also\nevaluated the reports generated by SkinGPT-4 and assigned\nscores (strongly agree, agree, neutral, disagree, and strongly\ndisagree) to each item in the evaluation form (Figure 4a),\nincluding the following questions:\n1. SkinGPT-4’s diagnosis is correct or relevant.\n2. SkinGPT-4’s description is informative.\n3. SkinGPT-4’s suggestions are useful.\n4. SkinGPT-4 can help doctors with diagnosis.\n5. SkinGPT-4 can help patients to understand their dis-\nease better.\n6. If SkinGPT-4 can be deployed locally, it protects pa-\ntients’ privacy.\n7. Willingness to use SkinGPT-4.\nIn particular, for questions 3 and 5, we further collected\nthe opinions of users of SkinGPT-4, who usually do not have\nstrong background knowledge in dermatology, to show that\nSkinGPT-4 is friendly to the general users. Those results\nallowed for a comprehensive evaluation of SkinGPT-4’s per-\nformance in relation to certified dermatologists and patients.\n4 C ONCLUSION AND DISCUSSION\nOur study showcases the promising potential of utilizing\nvisual inputs in LLMs to enhance dermatological diagnosis.\nWith the upcoming release of more advanced LLMs like\nGPT-4, the accuracy and quality of diagnoses could be fur-\nther improved. However, it is essential to address potential\nprivacy concerns associated with using LLMs like ChatGPT\nand GPT-4 as an API, as it requires users to upload their\nprivate data. In contrast, SkinGPT-4 offers a solution to\nthis privacy issue. By allowing users to deploy the model\nlocally, the concerns regarding data privacy are effectively\nresolved. Users have the autonomy to use SkinGPT-4 within\nthe confines of their own system, ensuring the security and\nconfidentiality of their personal information.\nDuring the course of a patient’s consultation with a\ndermatologist, the doctor often asks additional questions to\ngather crucial information that aids in arriving at a precise\ndiagnosis. In contrast, SkinGPT-4 relies on the information\nprovided by users to assist in the diagnostic process. Ad-\nditionally, doctors often engage in empathetic interactions\nwith patients, as the emotional connection could contribute\nto the diagnostic process. Due to these factors, it remains\nchallenging for SkinGPT-4 to fully replace dermatologists at\npresent. However, SkinGPT-4 still holds significant value as\na tool for both patients and dermatologists. It can greatly\nexpedite the diagnostic process and enhance the overall\nservice delivery. By leveraging its capabilities, SkinGPT-4\nempowers patients to obtain preliminary insights into their\nskin conditions and aids dermatologists in providing more\nefficient care. While it may not fully substitute for the ex-\npertise and empathetic nature of dermatologists, SkinGPT-4\nserves as a valuable complementary resource in the field of\ndermatological diagnosis.\nAs LLMs-based applications like SkinGPT-4 continue\nto evolve and improve with the acquisition of even more\nreliable medical training data, the potential for signifi-\ncant advancements in online medical services is enormous.\nSkinGPT-4 could play a critical role in improving access to\nhealthcare and enhancing the quality of medical services for\npatients worldwide. We will continue our research in this\nfield to further develop and refine this technology.\n5 A CKNOWLEDGEMENTS\nSpecial thanks: Thanks to Jun Chen, the author of\nMiniGPT-4 for the discussion of this work.\nFunding: Juexiao Zhou, Xiuying Chen, Yuetan Chu,\nLongxi Zhou, Xingyu Liao, Bin Zhang, and Xin Gao were\nsupported in part by grants from the Office of Research\nAdministration (ORA) at King Abdullah University of\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n10\nScience and Technology (KAUST) under award number\nFCC/1/1976-44-01, FCC/1/1976-45-01, REI/1/5202-01-01,\nREI/1/5234-01-01, REI/1/4940-01-01, RGC/3/4816-01-01,\nand REI/1/0018-01-01. Xiaonan He was supported by the\nfoundation of the National Natural Science Foundation of\nChina (No. 62272327).\nCompeting Interests: The authors have declared no\ncompeting interests.\nAuthor Contribution Statements:J.Z. and X.G. conceived\nof the presented idea. J.Z. designed the computational\nframework and analysed the data. J.Z, L.S., J.X., X.C., Y.C.,\nL.Z., X.L., B.Z. and X.H. conducted the clinical evaluation.\nX.G. supervised the findings of this work. J.Z., X.H., L.S.,\nJ.X. and X.G. took the lead in writing the manuscript and\nsupplementary information. All authors discussed the\nresults and contributed to the final manuscript.\nData availability: The data that support the findings\nof this study are divided into two groups: shared data\nand restricted data. Shared data include the SKINCON\ndataset and the Dermnet dataset. The SKINCON dataset\ncan be accessed at https://skincon-dataset.github.io/.\nThe Dermnet dataset can be accessed at https:\n//www.kaggle.com/datasets/shubhamgoel27/dermnet.\nThe restricted in-house skin disease images used in this\nstudy are not publicly available due to restrictions in the\ndata-sharing agreement.\nCode availability: To promote academic exchanges, un-\nder the framework of data and privacy security, the code\nproposed by SkinGPT-4 is publicly available at https:\n//github.com/JoshuaChou2018/SkinGPT-4. In the case of\nnon-commercial use, researchers can sign the license pro-\nvided in the above link and contact J.Z. or X.G. to access the\nlatest non-commercial trained model weights.\nREFERENCES\n[1] R. J. Hay, N. E. Johns, H. C. Williams, I. W. Bolliger, R. P . Dellavalle,\nD. J. Margolis, R. Marks, L. Naldi, M. A. Weinstock, S. K. Wulf\net al., “The global burden of skin disease in 2010: an analysis of the\nprevalence and impact of skin conditions,” Journal of Investigative\nDermatology, vol. 134, no. 6, pp. 1527–1534, 2014.\n[2] H. Feng, J. Berk-Krauss, P . W. Feng, and J. A. Stein, “Comparison\nof dermatologist density between urban and rural counties in the\nunited states,” JAMA dermatology, vol. 154, no. 11, pp. 1265–1271,\n2018.\n[3] J. Resneck Jr and A. B. Kimball, “The dermatology workforce\nshortage,” Journal of the American Academy of Dermatology, vol. 50,\nno. 1, pp. 50–54, 2004.\n[4] Y. Liu, A. Jain, C. Eng, D. H. Way, K. Lee, P . Bui, K. Kanada,\nG. de Oliveira Marinho, J. Gallegos, S. Gabriele et al., “A deep\nlearning system for differential diagnosis of skin diseases,” Nature\nmedicine, vol. 26, no. 6, pp. 900–908, 2020.\n[5] D. Seth, K. Cheldize, D. Brown, and E. E. Freeman, “Global burden\nof skin disease: inequities and innovations,” Current dermatology\nreports, vol. 6, pp. 204–210, 2017.\n[6] D. G. Federman, J. Concato, and R. S. Kirsner, “Comparison of\ndermatologic diagnoses by primary care practitioners and derma-\ntologists: a review of the literature,” Archives of family medicine,\nvol. 8, no. 2, p. 170, 1999.\n[7] G. Moreno, H. Tran, A. L. Chia, A. Lim, and S. Shumack, “Prospec-\ntive study to assess general practitioners’ dermatological diagnos-\ntic skills in a referral setting,” Australasian journal of dermatology,\nvol. 48, no. 2, pp. 77–82, 2007.\n[8] K. M. Yim, A. G. Florek, D. H. Oh, K. McKoy, and A. W. Arm-\nstrong, “Teledermatology in the united states: an update in a\ndynamic era,” Telemedicine and e-Health, vol. 24, no. 9, pp. 691–697,\n2018.\n[9] P . R. Kshirsagar, H. Manoharan, S. Shitharth, A. M. Alshareef,\nN. Albishry, and P . K. Balachandran, “Deep learning approaches\nfor prognosis of automated skin disease,” Life, vol. 12, no. 3, p.\n426, 2022.\n[10] F. Martora, A. Ruggiero, G. Fabbrocini, and A. Villani, “Patient\nsatisfaction with remote dermatology consultations during the\ncovid-19 pandemic. comment on ‘a qualitative assessment of\npatient satisfaction with remote dermatology consultations used\nduring the uk’s first wave of the covid-19 pandemic in a single,\nsecondary-care dermatology department’,” Clinical and Experimen-\ntal Dermatology, vol. 47, no. 11, pp. 2037–2038, 2022.\n[11] R. L ´opez-Liria, M. ´A. Valverde-Mart´ınez, A. L ´opez-Villegas, R. J.\nBautista-Mesa, F. A. Vega-Ram ´ırez, S. Peir ´o, and C. Leal-Costa,\n“Teledermatology versus face-to-face dermatology: An analysis of\ncost-effectiveness from eight studies from europe and the united\nstates,” International Journal of Environmental Research and Public\nHealth, vol. 19, no. 5, p. 2534, 2022.\n[12] N. Lakdawala, C. Gronbeck, and H. Feng, “Workforce charac-\nteristics of nonphysician clinicians in dermatology in the united\nstates,” Journal of the American Academy of Dermatology, vol. 87,\nno. 5, pp. 1108–1110, 2022.\n[13] I. K. Pious and R. Srinivasan, “A review on early diagnosis of\nskin cancer detection using deep learning techniques,” in 2022\nInternational Conference on Computer, Power and Communications\n(ICCPC). IEEE, 2022, pp. 247–253.\n[14] P . Puri, N. Comfere, L. A. Drage, H. Shamim, S. A. Bezalel, M. R.\nPittelkow, M. D. Davis, M. Wang, A. R. Mangold, M. M. Tollefson\net al., “Deep learning for dermatologists: Part ii. current applica-\ntions,” Journal of the American Academy of Dermatology, vol. 87, no. 6,\npp. 1352–1360, 2022.\n[15] S. Reshma and S. Reeja, “A review of computer assistance in der-\nmatology,” in 2023 International Conference on Intelligent and Inno-\nvative Technologies in Computing, Electrical and Electronics (IITCEE).\nIEEE, 2023, pp. 66–71.\n[16] S. S. Han, I. Park, S. E. Chang, W. Lim, M. S. Kim, G. H. Park, J. B.\nChae, C. H. Huh, and J.-I. Na, “Augmented intelligence derma-\ntology: deep neural networks empower medical professionals in\ndiagnosing skin cancer and predicting treatment options for 134\nskin disorders,” Journal of Investigative Dermatology, vol. 140, no. 9,\npp. 1753–1761, 2020.\n[17] D. Popescu, M. El-Khatib, H. El-Khatib, and L. Ichim, “New\ntrends in melanoma detection using neural networks: a systematic\nreview,” Sensors, vol. 22, no. 2, p. 496, 2022.\n[18] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau,\nand S. Thrun, “Dermatologist-level classification of skin cancer\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n11\nwith deep neural networks,” nature, vol. 542, no. 7639, pp. 115–\n118, 2017.\n[19] S. S. Han, M. S. Kim, W. Lim, G. H. Park, I. Park, and S. E. Chang,\n“Classification of the clinical images for benign and malignant\ncutaneous tumors using a deep learning algorithm,” Journal of\nInvestigative Dermatology, vol. 138, no. 7, pp. 1529–1538, 2018.\n[20] H. A. Haenssle, C. Fink, R. Schneiderbauer, F. Toberer, T. Buhl,\nA. Blum, A. Kalloo, A. B. H. Hassen, L. Thomas, A. Enket al., “Man\nagainst machine: diagnostic performance of a deep learning con-\nvolutional neural network for dermoscopic melanoma recognition\nin comparison to 58 dermatologists,” Annals of oncology, vol. 29,\nno. 8, pp. 1836–1842, 2018.\n[21] M. A. Marchetti, N. C. Codella, S. W. Dusza, D. A. Gutman,\nB. Helba, A. Kalloo, N. Mishra, C. Carrera, M. E. Celebi, J. L.\nDeFazio et al., “Results of the 2016 international skin imaging\ncollaboration international symposium on biomedical imaging\nchallenge: Comparison of the accuracy of computer algorithms to\ndermatologists for the diagnosis of melanoma from dermoscopic\nimages,” Journal of the American Academy of Dermatology, vol. 78,\nno. 2, pp. 270–277, 2018.\n[22] T. J. Brinker, A. Hekler, A. Hauschild, C. Berking, B. Schilling, A. H.\nEnk, S. Haferkamp, A. Karoglan, C. von Kalle, M. Weichenthal\net al., “Comparing artificial intelligence algorithms to 157 german\ndermatologists: the melanoma classification benchmark,”European\nJournal of Cancer, vol. 111, pp. 30–37, 2019.\n[23] J. Yap, W. Yolland, and P . Tschandl, “Multimodal skin lesion clas-\nsification using deep learning,” Experimental dermatology, vol. 27,\nno. 11, pp. 1261–1267, 2018.\n[24] s. L. P . Aggarwal, “Data augmentation in dermatology image\nrecognition using machine learning,” Skin Research and Technology,\nvol. 25, no. 6, pp. 815–820, 2019.\n[25] P . Tschandl, C. Rosendahl, B. N. Akay, G. Argenziano, A. Blum,\nR. P . Braun, H. Cabo, J.-Y. Gourhant, J. Kreusch, A. Lallas et al.,\n“Expert-level diagnosis of nonpigmented skin cancer by combined\nconvolutional neural networks,” JAMA dermatology, vol. 155, no. 1,\npp. 58–65, 2019.\n[26] S. S. Han, I. J. Moon, W. Lim, I. S. Suh, S. Y. Lee, J.-I. Na, S. H.\nKim, and S. E. Chang, “Keratinocytic skin cancer detection on\nthe face using region-based convolutional neural network,” JAMA\ndermatology, vol. 156, no. 1, pp. 29–37, 2020.\n[27] O. Jones, R. Matin, M. van der Schaar, K. P . Bhayankaram, C. Ran-\nmuthu, M. Islam, D. Behiyat, R. Boscott, N. Calanzani, J. Emery\net al., “Artificial intelligence and machine learning algorithms for\nearly detection of skin cancer in community and primary care\nsettings: a systematic review,” The Lancet Digital Health, vol. 4,\nno. 6, pp. e466–e476, 2022.\n[28] A. Hekler, J. S. Utikal, A. H. Enk, C. Berking, J. Klode, D. Schaden-\ndorf, P . Jansen, C. Franklin, T. Holland-Letz, D. Krahl et al. ,\n“Pathologist-level classification of histopathological melanoma\nimages with deep neural networks,” European Journal of Cancer,\nvol. 115, pp. 79–83, 2019.\n[29] Y. Jiang, J. Xiong, H. Li, X. Yang, W. Yu, M. Gao, X. Zhao, Y. Ma,\nW. Zhang, Y. Guan et al., “Recognizing basal cell carcinoma on\nsmartphone-captured digital histopathology images with a deep\nneural network,” British Journal of Dermatology, vol. 182, no. 3, pp.\n754–762, 2020.\n[30] A. Hekler, J. S. Utikal, A. H. Enk, W. Solass, M. Schmitt, J. Klode,\nD. Schadendorf, W. Sondermann, C. Franklin, F. Bestvater et al.,\n“Deep learning outperformed 11 pathologists in the classification\nof histopathological melanoma images,”European Journal of Cancer,\nvol. 118, pp. 91–96, 2019.\n[31] D. Roffman, G. Hart, M. Girardi, C. J. Ko, and J. Deng, “Predicting\nnon-melanoma skin cancer via a multi-parameterized artificial\nneural network,” Scientific reports, vol. 8, no. 1, p. 1701, 2018.\n[32] J. P . Lott, D. M. Boudreau, R. L. Barnhill, M. A. Weinstock,\nE. Knopp, M. W. Piepkorn, D. E. Elder, S. R. Knezevich, A. Baer,\nA. N. Tosteson et al., “Population-based analysis of histologically\nconfirmed melanocytic proliferations using natural language pro-\ncessing,” JAMA dermatology, vol. 154, no. 1, pp. 24–29, 2018.\n[33] S. S. Han, G. H. Park, W. Lim, M. S. Kim, J. I. Na, I. Park, and\nS. E. Chang, “Deep neural networks show an equivalent and often\nsuperior performance to dermatologists in onychomycosis diagno-\nsis: Automatic construction of onychomycosis datasets by region-\nbased convolutional deep neural network,” PloS one, vol. 13, no. 1,\np. e0191493, 2018.\n[34] E. Bernardis and L. Castelo-Soccio, “Quantifying alopecia areata\nvia texture analysis to automate the salt score computation,” in\nJournal of Investigative Dermatology Symposium Proceedings, vol. 19,\nno. 1. Elsevier, 2018, pp. S34–S40.\n[35] A. H. Thieme, Y. Zheng, G. Machiraju, C. Sadee, M. Mittermaier,\nM. Gertler, J. L. Salinas, K. Srinivasan, P . Gyawali, F. Carrillo-Perez\net al., “A deep-learning algorithm to classify skin lesions from\nmpox virus infection,” Nature Medicine, vol. 29, no. 3, pp. 738–747,\n2023.\n[36] A. A. Cruz-Roa, J. E. Arevalo Ovalle, A. Madabhushi, and\nF. A. Gonz ´alez Osorio, “A deep learning architecture for im-\nage representation, visual interpretability and automated basal-\ncell carcinoma cancer detection,” in Medical Image Computing\nand Computer-Assisted Intervention–MICCAI 2013: 16th International\nConference, Nagoya, Japan, September 22-26, 2013, Proceedings, Part II\n16. Springer, 2013, pp. 403–410.\n[37] Y. Yuan, M. Chao, and Y.-C. Lo, “Automatic skin lesion seg-\nmentation using deep fully convolutional networks with jaccard\ndistance,” IEEE transactions on medical imaging, vol. 36, no. 9, pp.\n1876–1886, 2017.\n[38] P . Tschandl, N. Codella, B. N. Akay, G. Argenziano, R. P . Braun,\nH. Cabo, D. Gutman, A. Halpern, B. Helba, R. Hofmann-Wellenhof\net al., “Comparison of the accuracy of human readers versus\nmachine-learning algorithms for pigmented skin lesion classifi-\ncation: an open, web-based, international, diagnostic study,” The\nlancet oncology, vol. 20, no. 7, pp. 938–947, 2019.\n[39] X. Sun, J. Yang, M. Sun, and K. Wang, “A benchmark for auto-\nmatic visual classification of clinical skin disease images,” in Com-\nputer Vision–ECCV 2016: 14th European Conference, Amsterdam, The\nNetherlands, October 11-14, 2016, Proceedings, Part VI 14. Springer,\n2016, pp. 206–222.\n[40] T. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. De Leon,\nC. Elepa ˜no, M. Madriaga, R. Aggabao, G. Diaz-Candido,\nJ. Maningo et al., “Performance of chatgpt on usmle: Potential for\nai-assisted medical education using large language models,” PLoS\ndigital health, vol. 2, no. 2, p. e0000198, 2023.\n[41] M. Sallam, N. Salim, M. Barakat, and A. Al-Tammemi, “Chat-\ngpt applications in medical, dental, pharmacy, and public health\neducation: A descriptive study highlighting the advantages and\nlimitations,” Narra J, vol. 3, no. 1, pp. e103–e103, 2023.\n[42] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,\nE. Kamar, P . Lee, Y. T. Lee, Y. Li, S. Lundberg et al., “Sparks of\nartificial general intelligence: Early experiments with gpt-4,” arXiv\npreprint arXiv:2303.12712, 2023.\n[43] P . Lee, S. Bubeck, and J. Petro, “Benefits, limits, and risks of gpt-4\nas an ai chatbot for medicine,” New England Journal of Medicine,\nvol. 388, no. 13, pp. 1233–1239, 2023.\n[44] M. Balas and E. B. Ing, “Conversational ai models for ophthalmic\ndiagnosis: Comparison of chatgpt and the isabel pro differential\ndiagnosis generator,” JFO Open Ophthalmology, vol. 1, p. 100005,\n2023.\n[45] M. Mijwil, M. Aljanabi, and A. H. Ali, “Chatgpt: Exploring the\nrole of cybersecurity in the protection of medical information,”\nMesopotamian journal of cybersecurity, vol. 2023, pp. 18–21, 2023.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint \n12\n[46] R. K. Sinha, A. D. Roy, N. Kumar, H. Mondal, and R. Sinha, “Ap-\nplicability of chatgpt in assisting to solve higher order problems\nin pathology,” Cureus, vol. 15, no. 2, 2023.\n[47] F. Ufuk, “The role and limitations of large language models such\nas chatgpt in clinical settings and medical journalism,” Radiology,\np. 230276, 2023.\n[48] M. Hu, S. Pan, Y. Li, and X. Yang, “Advancing medical imaging\nwith language models: A journey from n-grams to chatgpt,” arXiv\npreprint arXiv:2304.04920, 2023.\n[49] R. Vaishya, A. Misra, and A. Vaish, “Chatgpt: Is this version\ngood for healthcare and research?” Diabetes & Metabolic Syndrome:\nClinical Research & Reviews, vol. 17, no. 4, p. 102744, 2023.\n[50] E. J. Beltrami and J. M. Grant-Kels, “Consulting chatgpt: Ethical\ndilemmas in language model artificial intelligence,” Journal of the\nAmerican Academy of Dermatology, 2023.\n[51] S. Wang, Z. Zhao, X. Ouyang, Q. Wang, and D. Shen, “Chatcad:\nInteractive computer-aided diagnosis on medical image using\nlarge language models,” arXiv preprint arXiv:2302.07257, 2023.\n[52] H. Li, D. Guo, W. Fan, M. Xu, and Y. Song, “Multi-step jailbreaking\nprivacy attacks on chatgpt,” arXiv preprint arXiv:2304.05197, 2023.\n[53] B. Lund and D. Agbaji, “Information literacy, data literacy, privacy\nliteracy, and chatgpt: Technology literacies align with perspectives\non emerging technology adoption within communities,” Data Lit-\neracy, Privacy Literacy, and ChatGPT: Technology Literacies Align with\nPerspectives on Emerging Technology Adoption within Communities\n(January 14, 2023), 2023.\n[54] P . Rajpurkar, E. Chen, O. Banerjee, and E. J. Topol, “Ai in health\nand medicine,” Nature medicine, vol. 28, no. 1, pp. 31–38, 2022.\n[55] J. Zhou, S. Chen, Y. Wu, H. Li, B. Zhang, L. Zhou, Y. Hu, Z. Xiang,\nZ. Li, N. Chen et al., “Ppml-omics: a privacy-preserving federated\nmachine learning system protects patients’ privacy from omic\ndata,” bioRxiv, pp. 2022–03, 2022.\n[56] J. Zhou, L. Zhou, D. Wang, X. Xu, H. Li, Y. Chu, W. Han, and\nX. Gao, “Personalized and privacy-preserving federated hetero-\ngeneous medical image analysis with pppml-hmi,” medRxiv, pp.\n2023–02, 2023.\n[57] J. Zhou, H. Li, X. Liao, B. Zhang, W. He, Z. Li, L. Zhou, and X. Gao,\n“Audit to forget: A unified method to revoke patients’ private data\nin intelligent healthcare,” bioRxiv, pp. 2023–02, 2023.\n[58] D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4:\nEnhancing vision-language understanding with advanced large\nlanguage models,” arXiv preprint arXiv:2304.10592, 2023.\n[59] W.-L. Chiang, Z. Li, Z. Lin, Y. Sheng, Z. Wu, H. Zhang, L. Zheng,\nS. Zhuang, Y. Zhuang, J. E. Gonzalez, I. Stoica, , and E. P . Xing.,\n“Vicuna: An open-source chatbot impressing gpt-4 with 90%*\nchatgpt quality, march 2023.”\n[60] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\nT. Lacroix, B. Rozi`ere, N. Goyal, E. Hambro, F. Azharet al., “Llama:\nOpen and efficient foundation language models,” arXiv preprint\narXiv:2302.13971, 2023.\n[61] J. Li, D. Li, S. Savarese, and S. Hoi, “Blip-2: Bootstrapping\nlanguage-image pre-training with frozen image encoders and\nlarge language models,” arXiv preprint arXiv:2301.12597, 2023.\n[62] Y. Fang, W. Wang, B. Xie, Q. Sun, L. Wu, X. Wang, T. Huang,\nX. Wang, and Y. Cao, “Eva: Exploring the limits of masked visual\nrepresentation learning at scale,” arXiv preprint arXiv:2211.07636,\n2022.\n[63] P . Sharma, N. Ding, S. Goodman, , and R. Soricut, “Concep-\ntual captions: A cleaned, hypernymed, image alt-text dataset for\nautomatic image captioning,” In Proceedings of the 56th Annual\nMeeting of the Association for Computational Linguistics (Volume 1:\nLong Papers), pages 2556–2565, 2018.\n[64] V . Ordonez, G. Kulkarni, and T. Berg, “Im2text: Describing im-\nages using 1 million captioned photographs,” Advances in neural\ninformation processing systems, vol. 24, 2011.\n[65] C. Schuhmann, R. Vencu, R. Beaumont, R. Kaczmarczyk, C. Mullis,\nA. Katta, T. Coombes, J. Jitsev, and A. Komatsuzaki, “Laion-400m:\nOpen dataset of clip-filtered 400 million image-text pairs,” arXiv\npreprint arXiv:2111.02114, 2021.\n[66] C. Preiksaitis, C. A. Sinsky, and C. Rose, “Chatgpt is not the\nsolution to physicians’ documentation burden,” Nature Medicine,\npp. 1–2, 2023.\n[67] W. Fu and C. J. Cockerell, “The actinic (solar) keratosis: a 21st-\ncentury perspective,” Archives of dermatology , vol. 139, no. 1, pp.\n66–70, 2003.\n[68] G. R. Kanthraj, “The twenty factors that made teledermatology\nconsultation a matured application: A systematic review,” Clinical\nDermatology Review, vol. 7, no. 1, pp. 10–15, 2023.\n[69] R. Daneshjou, M. Yuksekgonul, Z. R. Cai, R. Novoa, and J. Y. Zou,\n“Skincon: A skin disease dataset densely annotated by domain\nexperts for fine-grained debugging and analysis,” Advances in\nNeural Information Processing Systems, vol. 35, pp. 18 157–18 167,\n2022.\n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted June 13, 2023. ; https://doi.org/10.1101/2023.06.10.23291127doi: medRxiv preprint ",
  "topic": "Upload",
  "concepts": [
    {
      "name": "Upload",
      "score": 0.6747536659240723
    },
    {
      "name": "Computer science",
      "score": 0.6160244345664978
    },
    {
      "name": "Software deployment",
      "score": 0.5490440130233765
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.5208011865615845
    },
    {
      "name": "Language model",
      "score": 0.4533091187477112
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3685901463031769
    },
    {
      "name": "World Wide Web",
      "score": 0.13336625695228577
    },
    {
      "name": "Software engineering",
      "score": 0.09224960207939148
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I71920554",
      "name": "King Abdullah University of Science and Technology",
      "country": "SA"
    },
    {
      "id": "https://openalex.org/I4210119028",
      "name": "Beijing Anzhen Hospital",
      "country": "CN"
    },
    {
      "id": "https://openalex.org/I183519381",
      "name": "Capital Medical University",
      "country": "CN"
    }
  ]
}