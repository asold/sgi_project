{
  "title": "Enhancing Biomedical Question Answering with Large Language Models",
  "url": "https://openalex.org/W4401696935",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2000647018",
      "name": "Hua Yang",
      "affiliations": [
        "Zhongyuan University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2159764639",
      "name": "Shi-Long Li",
      "affiliations": [
        "Zhongyuan University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1976354563",
      "name": "Teresa Gonçalves",
      "affiliations": [
        "University of Évora"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2740258984",
    "https://openalex.org/W2510976782",
    "https://openalex.org/W6746285233",
    "https://openalex.org/W1561536714",
    "https://openalex.org/W155523208",
    "https://openalex.org/W6753247694",
    "https://openalex.org/W2795319782",
    "https://openalex.org/W2001812656",
    "https://openalex.org/W173870552",
    "https://openalex.org/W2394935951",
    "https://openalex.org/W2539940768",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W2963963993",
    "https://openalex.org/W2404428026",
    "https://openalex.org/W4323349240",
    "https://openalex.org/W2886993012",
    "https://openalex.org/W2759699778",
    "https://openalex.org/W4252076394",
    "https://openalex.org/W2014415866",
    "https://openalex.org/W3099700870",
    "https://openalex.org/W2065240770",
    "https://openalex.org/W2152784831",
    "https://openalex.org/W3034212969",
    "https://openalex.org/W2536015822",
    "https://openalex.org/W4226208814",
    "https://openalex.org/W1981208470",
    "https://openalex.org/W3128581554",
    "https://openalex.org/W6633728942",
    "https://openalex.org/W2159065781",
    "https://openalex.org/W2087227067",
    "https://openalex.org/W1994863898",
    "https://openalex.org/W2149427297",
    "https://openalex.org/W4226391416",
    "https://openalex.org/W4385570359",
    "https://openalex.org/W2093390569",
    "https://openalex.org/W1973289172",
    "https://openalex.org/W3154755316",
    "https://openalex.org/W3206770993",
    "https://openalex.org/W3172119680",
    "https://openalex.org/W2136189984",
    "https://openalex.org/W6685160515",
    "https://openalex.org/W2132784310",
    "https://openalex.org/W6776225533",
    "https://openalex.org/W3180230246",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4389523765",
    "https://openalex.org/W6809646742",
    "https://openalex.org/W4402671832",
    "https://openalex.org/W4385573358",
    "https://openalex.org/W4389524586",
    "https://openalex.org/W2883547972",
    "https://openalex.org/W2951359136",
    "https://openalex.org/W1563486531",
    "https://openalex.org/W4221143046"
  ],
  "abstract": "In the field of Information Retrieval, biomedical question answering is a specialized task that focuses on answering questions related to medical and healthcare domains. The goal is to provide accurate and relevant answers to the posed queries related to medical conditions, treatments, procedures, medications, and other healthcare-related topics. Well-designed models should efficiently retrieve relevant passages. Early retrieval models can quickly retrieve passages but often with low precision. In contrast, recently developed Large Language Models can retrieve documents with high precision but at a slower pace. To tackle this issue, we propose a two-stage retrieval approach that initially utilizes BM25 for a preliminary search to identify potential candidate documents; subsequently, a Large Language Model is fine-tuned to evaluate the relevance of query–document pairs. Experimental results indicate that our approach achieves comparative performances on the BioASQ and the TREC-COVID datasets.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.847679853439331
    },
    {
      "name": "Question answering",
      "score": 0.8049702048301697
    },
    {
      "name": "Relevance (law)",
      "score": 0.7017776966094971
    },
    {
      "name": "Information retrieval",
      "score": 0.6971365213394165
    },
    {
      "name": "Pace",
      "score": 0.6192100048065186
    },
    {
      "name": "Language model",
      "score": 0.6135246753692627
    },
    {
      "name": "Field (mathematics)",
      "score": 0.561037003993988
    },
    {
      "name": "Task (project management)",
      "score": 0.5406297445297241
    },
    {
      "name": "Query expansion",
      "score": 0.44184964895248413
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3375719487667084
    },
    {
      "name": "Natural language processing",
      "score": 0.3230486214160919
    },
    {
      "name": "Pure mathematics",
      "score": 0.0
    },
    {
      "name": "Economics",
      "score": 0.0
    },
    {
      "name": "Geography",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Geodesy",
      "score": 0.0
    },
    {
      "name": "Management",
      "score": 0.0
    },
    {
      "name": "Political science",
      "score": 0.0
    }
  ]
}