{
    "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models",
    "url": "https://openalex.org/W4385572734",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A2123677600",
            "name": "Da Yin",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A2939328262",
            "name": "Hritik Bansal",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        },
        {
            "id": "https://openalex.org/A3134284595",
            "name": "Masoud Monajatipoor",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2915107679",
            "name": "Liunian Harold Li",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2208999240",
            "name": "Kai-Wei Chang",
            "affiliations": [
                "University of California, Los Angeles"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2998696444",
        "https://openalex.org/W3093517588",
        "https://openalex.org/W2050482109",
        "https://openalex.org/W3102659883",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W3156170450",
        "https://openalex.org/W3104163040",
        "https://openalex.org/W4221167694",
        "https://openalex.org/W2950339735",
        "https://openalex.org/W4294766263",
        "https://openalex.org/W3102999298",
        "https://openalex.org/W4205450747",
        "https://openalex.org/W2264742718",
        "https://openalex.org/W4285147794",
        "https://openalex.org/W3166986030",
        "https://openalex.org/W3198409578",
        "https://openalex.org/W4226155321",
        "https://openalex.org/W3116216579",
        "https://openalex.org/W3044438666",
        "https://openalex.org/W2970476646",
        "https://openalex.org/W3099771192",
        "https://openalex.org/W3087922520",
        "https://openalex.org/W3178522238",
        "https://openalex.org/W2963341956",
        "https://openalex.org/W4226095990",
        "https://openalex.org/W2979826702",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W3111372685",
        "https://openalex.org/W2912924812",
        "https://openalex.org/W3152665347",
        "https://openalex.org/W2963339397",
        "https://openalex.org/W3086339196",
        "https://openalex.org/W3175765954",
        "https://openalex.org/W3172943453",
        "https://openalex.org/W2962739339",
        "https://openalex.org/W3098267758",
        "https://openalex.org/W2914120296",
        "https://openalex.org/W3174234060",
        "https://openalex.org/W3202415077",
        "https://openalex.org/W2991223644",
        "https://openalex.org/W3100879603",
        "https://openalex.org/W3035032094",
        "https://openalex.org/W3169483174",
        "https://openalex.org/W3199207650",
        "https://openalex.org/W4285302800"
    ],
    "abstract": "Recent work has shown that Pre-trained Language Models (PLMs) store the relational knowledge learned from data and utilize it for performing downstream tasks. However, commonsense knowledge across different regions may vary. For instance, the color of bridal dress is white in American weddings whereas it is red in Chinese weddings. In this paper, we introduce a benchmark dataset, Geo-diverse Commonsense Multilingual Language Models Analysis (GeoMLAMA), for probing the diversity of the relational knowledge in multilingual PLMs. GeoMLAMA contains 3125 prompts in English, Chinese, Hindi, Persian, and Swahili, with a wide coverage of concepts shared by people from American, Chinese, Indian, Iranian and Kenyan cultures. We benchmark 11 standard multilingual PLMs on GeoMLAMA. Interestingly, we find that 1) larger multilingual PLMs variants do not necessarily store geo-diverse concepts better than its smaller variant; 2) multilingual PLMs are not intrinsically biased towards knowledge from the Western countries (the United States); 3) the native language of a country may not be the best language to probe its knowledge and 4) a language may better probe knowledge about a non-native country than its native country.",
    "full_text": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 2039–2055\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nGEOMLAMA : Geo-Diverse Commonsense Probing on Multilingual\nPre-Trained Language Models\nDa Yin Hritik Bansal Masoud Monajatipoor Liunian Harold Li Kai-Wei Chang\nComputer Science Department, University of California, Los Angeles\n{da.yin,hbansal,liunian.harold.li,kwchang}@cs.ucla.edu,\nmonajati@ucla.edu\nAbstract\nRecent work has shown that Pre-trained Lan-\nguage Models (PLMs) store the relational\nknowledge learned from data and utilize it for\nperforming downstream tasks. However, com-\nmonsense knowledge across different regions\nmay vary. For instance, the color of bridal\ndress is white in American weddings whereas\nit is red in Chinese weddings. In this paper,\nwe introduce a benchmark dataset, Geo-diverse\nCommonsense Multilingual Language Models\nAnalysis (GEOMLAMA ), for probing the di-\nversity of the relational knowledge in multi-\nlingual PLMs. GEOMLAMA contains 3,125\nprompts in English, Chinese, Hindi, Persian,\nand Swahili, with a wide coverage of concepts\nshared by people from American, Chinese, In-\ndian, Iranian and Kenyan cultures. We bench-\nmark 11 standard multilingual PLMs on GE-\nOMLAMA . Interestingly, we find that 1) larger\nmultilingual PLMs variants do not necessar-\nily store geo-diverse concepts better than its\nsmaller variant; 2) multilingual PLMs are not\nintrinsically biased towards knowledge from\nthe Western countries (the United States); 3) the\nnative language of a country may not be the best\nlanguage to probe its knowledge and 4) a lan-\nguage may better probe knowledge about a non-\nnative country than its native country. Code\nand data are released at https://github.\ncom/WadeYin9712/GeoMLAMA.\n1 Introduction\nPre-trained Language Models (PLMs) (Peters et al.,\n2018; Radford et al., 2019; Devlin et al., 2019;\nBrown et al., 2020) are increasingly used in various\nNatural Language Processing (NLP) applications.\nPre-trained on large-scale text corpora, they are\nshown to store relational knowledge (Petroni et al.,\n2019; Jiang et al., 2020b; Kassner et al., 2021), e.g.,\ncommonsense knowledge (Zhou et al., 2020; Lin\net al., 2020; Nguyen et al., 2021; Zhou et al., 2021).\nThey have been used to construct knowledge bases\nwhile requiring limited human effort for rule cre-\nIn traditional [X] weddings, the color of wedding dress is usually [MASK].\nपा र ं प \u0000र क  [X] शा िद यो ं  म \u0000  द ु \u0000 न  की  पो शा क  का  र ं ग  आम तौ र  पर  [MASK] हो ता  ह ै । \nKwenye harusi za kitamaduni nchini [X], rangi ya mavazi ya bibi harusi huwa [MASK].\n...\n[X] (Country name)[MASK]\n        American white\n         Chinese red\n          Indian red\n         Iranian white\n         Kenyan white\nColor of wedding dress\n[X] (Country name) [MASK]\n          अ म े \u0000र की स फ े द  (white)\n             ची नी ला ल  (red)\n           भा र ती य ला ल  (red)\n            फ़ा र सी स फ े द  (white)\n            क े \u0000ाी स फ े द  (white)\n...\nEN\nHI\nSW\nFigure 1: Examples of prompts and gold answers in\nGEOMLAMA . For each concept (e.g., color of wedding\ndress), there are multiple masked multilingual prompts\n(English, Hindi, Swahili, etc.) with specified country in-\nformation [X] querying geo-diverse knowledge about\nthe concept. We test multilingual PLMs by examining\nthe extent to which masked word predictions align with\nthe gold answers in [MASK] columns.\nation and validation (Bosselut et al., 2019; Zhou\net al., 2022).\nHowever, do PLMs store geo-diverse common-\nsense knowledge? Geo-diverse commonsense (Yin\net al., 2021) is a collection of commonsense lo-\ncally shared by people from certain regions but\nmay not apply in other regions due to cultural and\ngeographic differences. For instance, the color of\nbridal outfit in American wedding is white, while\nit is normally red in traditional Chinese and Indian\nweddings. PLMs which are unaware of geo-diverse\nknowledge may have disparity in performance on\ntest data associated with different regions. This\nmay lead to disadvantage of users in certain re-\ngions and further amplify bias in AI applications,\nsuch as constructing Western-centric knowledge\nbases eventually.\nIn this paper, we concentrate on evaluating mul-\ntilingual PLMs (Devlin et al., 2019; Conneau and\nLample, 2019; Conneau et al., 2020). Studying geo-\ndiversity naturally involves multilinguality. People\nin different regions may speak different languages,\n2039\nand it is natural to assume that geo-specific knowl-\nedge is better represented in its native language.\nMoreover, pre-trained on a collection of multilin-\ngual corpora, multilingual PLMs accumulate the\nknowledge from various languages. Therefore, we\nposit that knowledge in multilingual PLMs is more\ndiverse than that in models trained on a single lan-\nguage.\nCentered around multilingual PLMs, we follow\nthe original knowledge probing task LAnguage\nModel Analysis ( LAMA ) (Petroni et al., 2019)\nand introduce a new geo-diverse probing bench-\nmark GEOMLAMA . As shown in Figure 1, given\na masked geo-diverse prompt with a particular\ncountry name [X] , such as “ In traditional [X]\nweddings, the color of wedding dress is usually\n[MASK] .”, and a corresponding candidate answer\nlist, {“red”, “white”, “black”, “blue”, ...}, multilin-\ngual PLMs are required to predict the masked word\n[MASK] from the candidate list.\nThe characteristics of GEOMLAMA are sum-\nmarized as follows. 1) Diverse answers across\ncountries: Each prompt is designed based on geo-\ndiverse concept (e.g., color of traditional wedding\ndress in Figure 1) and gold answers for masked\nword are different across countries. 2) Broad cover-\nage of geo-diverse concepts: GEOMLAMA encom-\npasses comprehensive geo-diverse topics including\nhabits and personal choices, cultures and customs,\npolicies and regulations, and geography. 3) Cov-\nerage of multiple countries and languages : GE-\nOMLAMA involves knowledge about the United\nStates, China, India, Iran, and Kenya, and is con-\nstructed by the native languages of the five coun-\ntries, English, Chinese, Hindi, Persian, and Swahili.\nOverall, there are 3,125 prompts in our benchmark.\nWe perform in-depth probing analysis on 11 mul-\ntilingual PLMs, including mBERT (Devlin et al.,\n2019), XLM (Conneau and Lample, 2019), XLM-\nR (Conneau et al., 2020), mT5 (Xue et al., 2021),\nand XGLM (Lin et al., 2021b). In general, we ob-\nserve that multilingual PLMs significantly outper-\nform random guess, suggesting that multilingual\nPLMs are capable of storing geo-diverse common-\nsense to some extent. We then conduct fine-grained\ninvestigation across three dimensions.\nWe first study the correlation between model per-\nformance and model size. Contrary to our intuition,\nwe notice that the largest models do not necessarily\nhave the best performance on our benchmark. We\nfurther study the best language to probe the knowl-\nedge about a particular country. Surprisingly, we\nfind that the best language is not the native lan-\nguage of the given country (e.g., English is not\nthe best language to probe knowledge about the\nUS). We also explore the knowledge that can be\nmost accurately probed by a particular language.\nSimilarly, we find that the most accurately probed\nknowledge is not the one about indigenous country\nof the language (e.g., the country for which Chi-\nnese prompts provide the most accurate predictions\nis not always China). Lastly, we find evidence of\nreporting bias that might explain such observations.\n2 Related Works\nKnowledge Probing on PLMs. Petroni et al.\n(2019) first explore whether PLMs have capacity of\nstoring factual knowledge about entities. Based on\nthis observation, prior works involving knowledge\nprobing focus primarily on creating more effective\nprobing methods to elicit factual knowledge (Jiang\net al., 2020b,a; Shin et al., 2020; Zhong et al., 2021)\nor analyzing whether other types of knowledge are\nstored in PLMs (Talmor et al., 2020; Zhou et al.,\n2020; Kassner et al., 2021; Sung et al., 2021). In\nthe second line of works, there is a great variety\nof commonsense knowledge being explored, in-\ncluding social (Zhou et al., 2020), numerical (Lin\net al., 2020) and spatial (Zhang et al., 2020; Liu\net al., 2022) commonsense. GEOMLAMA focuses\non probing a new commonsense type, geo-diverse\ncommonsense, on multilingual PLMs.\nMultilingual Knowledge Probing and Multilin-\ngual Commonsense. MLAMA (Kassner et al.,\n2021) and Prix-LM (Zhou et al., 2022) simply fo-\ncus on capturing multilingual factual knowledge\nabout entities. XCOPA (Ponti et al., 2020) and X-\nCSR (Lin et al., 2021a) are two multilingual com-\nmonsense benchmarks, but both are built by transla-\ntion from English commonsense benchmarks, with-\nout any consideration of region-specific common-\nsense. Different from prior works, we value geo-\ndiversity and quantify the extent to which multilin-\ngual PLMs master such geo-diverse commonsense.\nGeo-Diverse Commonsense. Geo-diverse com-\nmonsense is strongly correlated with cultures and\ngeographic locations. There have emerged a few\nworks (Acharya et al., 2020; Yin et al., 2021;\nLiu et al., 2021; Shwartz, 2022) studying geo-\ndiverse commonsense. Specifically, by collecting\nresponses to questionnaire, Acharya et al. (2020)\n2040\nanalyze the cultural difference between US and\nIndia about scenarios including wedding and fu-\nneral. Yin et al. (2021); Liu et al. (2021) propose\ngeo-diverse multimodal benchmarks, GD-VCR and\nMaRVL. They find that due to lack of geo-diverse\nknowledge, large performance disparity appears\nwhen multimodal models are applied on tasks re-\nquiring knowledge about Western and non-Western\nregions. Shwartz (2022) propose culture-specific\ntime expression grounding task to acquire specific\ntemporal commonsense in different countries from\nmultilingual corpora and models.\nInclusion in NLP. Enhancing inclusivity of lan-\nguage processing technology and ensuring it works\nfor everyone is essential. Several studies have fo-\ncused on improving language inclusion (Joshi et al.,\n2020; Faisal et al., 2022), gender inclusion (Cao\nand Daumé III, 2021; Dev et al., 2021; Lauscher\net al., 2022), and race inclusion (Field et al., 2021).\nWe hope that GEOMLAMA can enable future de-\nvelopment in improving the diversity of knowledge\nembedded in pre-trained language models.\n3 GEOMLAMA Benchmark Construction\nTo build a geo-diverse commonsense probing\nbenchmark, we recruit annotators from five differ-\nent countries, the United States, China, India, Iran,\nand Kenya to participate in annotation. The anno-\ntation process is separated into four stages. 1) We\nfirst ask the annotators to list geo-diverse concepts.\n2) Based on the collected concepts, we then require\nannotators to design masked geo-diverse prompt\ntemplates in English. 3) After specifying prompts\nwith country names, we request annotators to pro-\nvide correct answers and form answer candidate\nlist for each prompt. 4) We translate the English\nprompts into other languages and paraphrase them.\nThe overview of the annotation pipeline is illus-\ntrated in Figure 2.\n3.1 Geo-Diverse Concept Collection\nGeo-diverse concepts are the foundation of design-\ning geo-diverse prompts. The criteria of selecting\ngeo-diverse concepts are shown as follows:\nUniversality and Diversity across Cultures. We\nrequire that the scenarios regarding the collected\nconcepts to be universal but diverse across the dif-\nferent cultures. “Color of wedding dress” qualifies\nour criteria as wedding dress is a universally un-\nderstood entity where its color is diverse across\ndifferent cultures.\nAvoiding Concepts involving Region-Specific\nTerms. We avoid probing models about region-\nspecific factual knowledge, e.g., festival names and\npresident names of the countries, as these concepts\nusually involve uncommonly used tokens in cer-\ntain languages and thus introduce another layer of\ncomplexity to make inference.\nFinally, we consider topics that cover habits and\npersonal choices, cultures and customs, policies\nand regulations, and geography for subsequent an-\nnotations. Details are shown in Appendix A.\n3.2 Geo-Diverse Prompt Template Design\nCentered on the collected geo-diverse concepts,\nannotators design English version of geo-diverse\nprompt templates that will be later paraphrased\nand translated into multilingual prompts. Given\none geo-diverse concept, e.g., “ color of wedding\ndress”, the corresponding prompt template would\nbe a masked sentence that inquires the missing\ncolor information, e.g., “The color of wedding dress\nis usually [MASK] .” Since we intend to probe\nknowledge about different countries using these\nprompts, we further insert phrases such as “In [X] ,\n”, “In traditional [X] wedding, ” to indicate the\ncountry knowledge to be probed. Here [X] is ei-\nther one of the country names (the United States,\nChina, India, Iran, and Kenya), or one of the cor-\nresponding modifiers ( American, Chinese, Indian,\nIranian, and Kenyan).\n3.3 Answer and Answer Candidate List\nAnnotation\nFor each masked geo-diverse prompt with a spec-\nified country name, we request the annotators to\nprovide correct answers for the masked words. For\ninstance, given a prompt about bridal outfit color\nin traditional Chinese weddings, “ In traditional\nChinese weddings, the color of wedding dress is\nusually [MASK]”, annotators are required to pro-\nvide the answer “red” for [MASK]. The answers\nare all provided by annotators who are familiar\nwith the culture in one of our studied countries.\nNote that besides prompts with only one answer,\nsome other prompts in GEOMLAMA , such as “The\nstaple food in Iran is [MASK]”, can have multiple\ncorrect answers (“rice” and “bread”) for a single\nprompt. To further validate the correctness of an-\nswers, we distributed a survey to collect responses\nfor knowledge about respondents’ own countries.\n2041\nIn traditional [X] weddings, the color of wedding dress is usually [MASK].\nपा र ं प \u0000र क  [X] शा िद यो ं  म \u0000  द ु \u0000 न  की  पो शा क  का  र ं ग  आम तौ र  पर  [MASK] हो ता  ह ै । \n...\nGeo-Diverse Concepts\nColor of wedding dress\nShower time\nStaple food\nDriver seat side\nUnit of measurement\n...\n...\n  In [X], the color of traditional wedding dress is usually [MASK].\nEN \nEN \nHI \n Katika harusi za jadi za [X], rangi ya mavazi ya bibi harusi kawaida ni [MASK]. SW \n[X] (Country name)[MASK]\n      American white\n       Chinese red\n        Indian red\n       Iranian white\n       Kenyan white\n       Kenyan white\nआम तौ र  पर  पा र ं प \u0000र क  [X] शा िद यो ं  म \u0000  द ु \u0000 न  की  पो शा क  का  र ं ग  [MASK] हो ता  ह ै । HI \n[X] (Country name)[MASK]\n      अ म े \u0000र की स फ े द \n         ची नी ला ल \n       भा र ती य ला ल \n       फ़ा र सी स फ े द \n        क े \u0000ाी स फ े द \nAnswer Candidate List\nred, white, yellow, blue,  \norange, green, violet, black\nAnswer Candidate List\nला ल , स फ े द , पी ला , नी ला ,  \nना र ं गी , ह रा , ब \u0000 ग नी , का ला \nThe driver seat of a car is in the [MASK] side in [X]. EN \n...\nStage 1: Concept Collection\nStage 2: Prompt Design\nStage 4: Translation and Paraphrase\nStage 3: Answer Annotation\n...\nParaphrase\nTranslate\nParaphrase\nTranslateTranslate\nFigure 2: Overall annotation pipeline. It is divided into four stages: Stage 1 is to collect geo-diverse concepts;\nStage 2 is to design English prompt templates; Stage 3 is to annotate answers for each country and construct answer\ncandidate list. Stage 4 is to translate the English prompts and paraphrase the translated multilingual prompts. Here\nwe showcase English and Hindi answer annotations for demonstration.\nWe collected 33 responses from the five countries,\nand retained the answers with majority support.\nIn this work, we focus on investigating whether\nPLMs are capable of predicting correct answers\namong all the possibilities of different countries.\nFor example, we wonder if PLMs can predict the\ndress color at Chinese wedding is “ red” over the\nother possibility, such as “white”. Therefore, we\npair each prompt with an additional answer candi-\ndate list composed by the probable choices and mul-\ntilingual PLMs are constrained to make predictions\nfrom the list. Specifically, each list contains the\nunion of all correct answers of five countries and ad-\nditional confounding candidates sharing the same\nword types with those correct answers. For the\nprompts about color of wedding dress, the union\nof correct answers is {“red”, “white”}. Other than\nthe two colors, as illustrated in Figure 2, we also\nappend confounders such as, “ yellow”, “ black”,\n“blue” to the list (the orange letters in grids titled\nwith “Answer Candidate List”). The final answer\ncandidate list for prompts about color of wedding\ndress will be {“ red”, “white”, “yellow”, “black”,\n“blue”, ...}. Note that the contents and lengths of\nanswer candidate lists for prompts about different\nconcepts vary greatly.\n3.4 Prompt Translation and Paraphrase\nWe then obtain multilingual geo-diverse prompts\nvia translating the annotated English prompts into\nfour other languages Chinese, Hindi, Persian, and\nSwahili. We leverage Google Translation API\nto translate English prompts and each translated\nprompt is manually checked and corrected by anno-\ntators familiar with both English and any of the four\nstudied languages. Besides, since it is shown that\nprobing results are sensitive to small perturbation to\nthe prompts (Jiang et al., 2020b), we further gener-\nate four paraphrases for each prompt to obtain more\nrobust probing results. Specifically, we paraphrase\nEnglish prompts via a round of backtranslation1 in\nwhich we first translate English prompts to German\nones and then translate them back to English. For\nprompts in other languages, their paraphrases are\ngenerated by backtranslation that translates texts to\nEnglish and translate them back to the original lan-\nguages. The paraphrases in a particular language\nare validated and modified by native speakers.\nIn total, we annotate 3125 prompts with answers\nand corresponding candidates in GEOMLAMA . All\nthe prompts are designed based on 16 geo-diverse\nconcepts listed in Appendix A, and there are 625\nprompts for each of the five languages. More de-\ntails are described in Appendix B.\n4 Probing Methods on G EOMLAMA\nPetroni et al. (2019) introduce the LAnaguage\nModel Analysis (LAMA) setup to probe knowl-\n1Based on Google Translation API.\n2042\nedge stored in the pre-trained language models\nusing masked templates. Without any additional\nfine-tuning, given a masked prompt, models are re-\nquired to recover masked tokens with entities with\nthe highest probability for the prompt context. Fol-\nlowing LAMA probe, on GEOMLAMA , we study\nwhether models are capable of seeking the most\nappropriate answers to from answer candidate list\naccording to given geo-diverse prompts.\nKassner et al. (2021) follow LAMA probe to\ninvestigate entity knowledge in multilingual BERT\nonly. In this work, we probe a diverse set of lan-\nguage models on geo-diverse commonsense knowl-\nedge by scoring answer candidates and calibrating\nthe score of each candidate.\n4.1 Scoring Answer Candidates\nWe score answer candidates based on log likelihood\nof generating answer candidates given prompts.\nDifferent model families have their individual infer-\nence methods to obtain the scores. In the following,\nwe introduce the probing methods for masked lan-\nguage models. Details of other probing methods\non autoregressive and encoder-decoder language\nmodels are shown in Appendix C.\nMasked Language Models (mBERT, XLM,\nXLM-R family). Given an answer candidate e\n(e.g., “chopsticks”) that is tokenized into subtokens\ne1, e2, ..., eL (e.g., “chop”, “stic”, “ks”) such that\nei ∈V where V is the vocabulary and t is the\nprompt (e.g., “ In China, people usually eat food\nwith [MASK1]...[MASKL].”), we assign a score\nle based on the log probability of recovering the an-\nswer candidate e in the masked prompt. Formally,\nle is defined as\n1\nL\nL∑\ni=1\nlog(p([MASKi] =ei|[MASK<i] =e<i, t)). (1)\nAccording to Eq. (1), we perform L for-\nward passes, each of which helps in obtain-\ning conditional probability of generating\none subtoken. To illustrate, ith forward\npass inference would be p([MASKi] =\nei|“In China, people usually eat food with e1 e2\n...ei−1 [MASKi]...[MASKL]”).\nHere we further normalize the sum of log like-\nlihood by the number of subtokens L to help in\nreducing the effect of length. The other model\nfamilies discussed in Appendix C also adopt the\nnormalization strategy.\n4.2 Calibrating Answer Candidates\nThe way to score answer candidates e ∈E (e.g.,\n“chopsticks” ∈{“chopsticks”, “hands”, “spoons”,\n“knives”}) given the prompt t for a country C (e.g.,\n“In China, people usually eat food with [MASK].”)\nis illustrated in §4.1. However, this scoring mecha-\nnism is likely to be biased towards statistical cor-\nrelations learned during pre-training (Zhao et al.,\n2021) whilst ignoring the country-specific informa-\ntion present in the prompt. For instance, the model\nmight choose “knives” over “chopsticks” because\n“knives” may occur more often than “chopsticks” in\npre-training corpora. Hence, we calibrate models\nwith the prior probability of answer predictions in\nthe absence of any country information. The final\nscore given to each answer in the answers candidate\nset is given by:\nse = le −l′\ne, (2)\nwhere l′\ne is obtained using the same approach as le\nbut the input prompt for calculating l′\ne is the one\nwithout country information (e.g., “People usually\neat food with [MASK].” without “In China,”).\n4.3 Evaluation Metric\nWe use the ratio of total number of model’s correct\npredictions to the total number of gold answers as\nmodel performance on GEOMLAMA . Specifically,\ngiven a prompt ti with gi gold answers, we count\nthe number of top- gi model predictions that also\nappear in the gold answer list as ci, based on the\nfinal score in Eq.2. For example, since there are\ntwo gold answers for the prompt “The staple food\nin Iran is [MASK]”, “rice” and “bread”, gi = 2.\nIn total, there are eight candidates in the answer\ncandidate list {“bread”, “noodles”, “rice”, “meat”,\n“maize”, ...} for this prompt. Assume one multi-\nlingual PLM assigns the highest gi scores to the\ncandidates “noodles” and “ rice”. Then ci = 1,\nsince only one of “noodles” and “rice” is the gold\nanswer of the prompt. We then sum up all ci and\ngi to calculate the ratio, ∑n\ni=1 ci/∑n\ni=1 gi, where\nn is the total number of prompts in GEOMLAMA .\n5 Analysis on Multilingual PLMs\nIn this section, we are interested in analyzing fol-\nlowing questions: 1) Are bigger multilingual PLMs\nmore geo-diverse than smaller ones? 2) In the ab-\nsence of any particular country information in the\nprompts, are multilingual PLMs biased towards\nthe knowledge towards certain countries? 3) Can\n2043\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\nmBERT\nXLM\nXLM/uni00ADR/uni00ADbase\nXLM/uni00ADR/uni00ADlarge\nrandom\n(a) mBERT, XLM, XLM-R family.\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\nmT5/uni00ADsmall\nmT5/uni00ADbase\nmT5/uni00ADlarge\nrandom (b) mT5 family.\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\nXGLM/uni00AD564M\nXGLM/uni00AD1.7B\nXGLM/uni00AD2.9B\nXGLM/uni00AD4.5B\nrandom (c) XGLM family.\nFigure 3: Multilingual PLMs’ performance on probing knowledge about the studied countries averaged over all\nlanguages. Complete results are shown in Appendix E.\nen zh hi fa sw0.2\n0.3\n0.4\n0.5\nmBERT\nXLM\nXLM/uni00ADR/uni00ADbase\nXLM/uni00ADR/uni00ADlarge\nrandom\n(a) mBERT, XLM, XLM-R family.\nen zh hi fa sw0.2\n0.3\n0.4\n0.5\nmT5/uni00ADsmall\nmT5/uni00ADbase\nmT5/uni00ADlarge\nrandom (b) mT5 family.\nen zh hi fa sw0.2\n0.3\n0.4\n0.5\nXGLM/uni00AD564M\nXGLM/uni00AD1.7B\nXGLM/uni00AD2.9B\nXGLM/uni00AD4.5B\nrandom (c) XGLM family.\nFigure 4: Multilingual PLMs’ performance averaged over countries when using multilingual prompts. “en”, “zh”,\n“hi”, “fa”, and “sw” denote English, Chinese, Hindi, Persian, and Swahili. Complete results are shown in Appendix E.\nnative language probe the knowledge about a par-\nticular country best? 4) Given a particular lan-\nguage, can the corresponding country’s knowledge\nbe most accurately probed by the language?\nTo this end, we experiment with 11 multilingual\nPLMs2 including mBERT (Devlin et al., 2019),\nXLM (Conneau and Lample, 2019), XLM-R fam-\nily3 (Conneau et al., 2020), mT5 family4 (Xue et al.,\n2021), and XGLM family5 (Lin et al., 2021b). We\nfreeze pre-trained model parameters provided by\nHuggingFace Transformers (Wolf et al., 2020) and\ndo not fine-tune the models during probing.\n5.1 Overview of Model Performance\nResults are shown in Figure 3 and 4. Figure 3\nfocuses on the comparison among performance of\nprobing the knowledge about a particular country\nwhile Figure 4 compares the performance of using\nprompts in different languages.\nIn Figure 3, we find that the performance of\nnearly all the multilingual PLMs lies in the range\n2We also experiment with GPT-3 as it is also pre-trained\non multilingual corpora. However, the results are not included\nin main paper because GPT-3 probing convention does not\nadopt cloze statements as the other 11 multilingual PLMs do.\nMore setup details and results can be found in Appendix D.\n3XLM-R-base, XLM-R-large.\n4mT5-small, mT5-base, mT5-large.\n5XGLM-564M, XGLM-1.7B, XGLM-2.9B, XGLM-4.5B.\nof 30% to 40% on probing each country’s knowl-\nedge. Further, these multilingual PLMs signifi-\ncantly outperform random guess 2-15%. It implies\nthat multilingual PLMs can store geo-diverse com-\nmonsense knowledge and some stored knowledge\ncan be accurately elicited even if we merely change\nthe country names in the prompt.\nAs illustrated in Figure 4, we observe that the\nperformance of using prompts in different lan-\nguages is generally from 30% to 40% and higher\nthan random guess 2-15% as well. Moreover, we\nfind that English and Hindi prompts are the most ef-\nfective ones to probe geo-diverse knowledge, while\nPersian and Swahili prompts cannot achieve com-\nparable results. In particular, from Figure 4c, using\nPersian prompts to probe XGLM-1.7B leads to\nworse performance than random guess.\n5.2 Effect of Model Size\nAccording to Petroni et al. (2019); Roberts et al.\n(2020), bigger models can generally store more\nknowledge and achieve better performance on\ndownstream NLP tasks such as open-domain\nQA (Joshi et al., 2017; Kwiatkowski et al., 2019).\nTo this end, we investigate whether larger mod-\nels indeed perform better than the smaller ones\non GEOM LAMA . For a fair comparison, we\nonly compare models in the same model families.\n2044\nThis avoids comparing models with different pre-\ntraining corpora and learning objectives.\nThe comparison results over the three model fam-\nilies are shown in Figure 3 and 4. We observe that\nthe larger models only perform marginally better\nthan their smaller counterparts on GEOMLAMA .\nFor the three model families, XLM-R, mT5, and\nXGLM, the performance gap between the largest\nand smallest models on all the prompts in GEOM-\nLAMA is merely 2.23%, 2.42%, and 1.46%, respec-\ntively. In specific cases (e.g., probing XGLM fam-\nily using Persian prompts), the largest model can\nbe even worse than its smallest variant. It demon-\nstrates that even if large models have nearly an\norder of magnitude more parameters than small\nmodels, large models cannot store geo-diverse com-\nmonsense significantly better than small models.\nThis highlights that GEOMLAMA is a challenging\ntask and being better on the standard multilingual\nNLP tasks does not guarantee good performance.\n5.3 Intrinsic Model Bias without Country\nInformation\nEach prompt in GEOMLAMA consists of the coun-\ntry information. However, it is still not clear as\nto what information is probed innately when we\nquery multilingual PLMs without any country in-\nformation. To study this phenomenon, we further\nprobe multilingual PLMs with the prompts where\nthe country token is removed. For example, instead\nof “In traditional Kenyan weddings, the color of\nwedding dress is usually [MASK]”, we implement\na new round of probing with the pruned prompt, “In\ntraditional weddings, the color of wedding dress is\nusually [MASK]”. The new prompts can elicit the\nknowledge that multilingual PLMs are intrinsically\ninclined towards predicting.\nAs shown in Figure 5, we find that for most\nmultilingual PLMs, the knowledge about India is\ncaptured frequently in the absence of any country\ninformation. Whereas, knowledge about the United\nStates is not well probed. It shows that at least, mul-\ntilingual PLMs are not originally biased towards\nknowledge about Western countries like US.\nWe do a quantitative case study to further explain\nthe phenomenon. We take a geo-diverse concept\n“staple food” as an example. Rice and bread are\nthe staple foods in China and the United States,\nrespectively. According to Table 2, in English,\nChinese and Swahili Wikipedia, we find that the\nco-occurrence of “staple food” and “rice” is com-\nModels US China India Iran Kenya\nmBERT fa sw en fa zh\nXLM fa en en zh zh\nXLM-R-base fa zh zh fa/sw en\nXLM-R-largefa zh en en zh\nmT5-small fa en en sw sw\nmT5-base fa en zh hi sw\nmT5-large fa sw sw fa hi\nXGLM-564Mfa en sw fa fa/hi\nXGLM-1.7B fa sw en fa fa\nXGLM-2.9B fa en en hi fa\nXGLM-4.5B fa zh en fa en\nBest Languages fa en en fa zh/fa\nTable 1: Best languages to probe each country’s knowl-\nedge. Each language in the last row “Best Languages”\nis the one appearing most in its located column.\nWords English Chinese Swahili\nrice, staple food 1040 33 7\nbread, staple food33 37 1\nTable 2: Word co-occurrence of “ rice”, “bread” and\n“staple food” in English, Chinese and Swahili Wikipedia,\nrespectively.\nparable or even way higher than “staple food” and\n“bread”. It demonstrates that the popularity of West-\nern knowledge across the world does not necessar-\nily mean higher frequency in knowledge sources\nlike Wikipedia. This may lead the models to pre-\ndicting non-Western knowledge more precisely.\n5.4 Best Languages to Probe Knowledge\nabout Countries\nIn GEOMLAMA , prompts in different languages\nare used to probe knowledge about different coun-\ntries. It is imperative to ask whether we elicit most\nknowledge about a country if we query the PLM\nwith its native language. From Table 1, contrary\nto our intuition, the native language is not the best\nlanguage to query its knowledge for most of the\ncountries. In particular, Iran is the only country\nfor which its native language Persian can help in\ndrawing out maximum knowledge about it. For\nthe United States and Kenya, the best probing lan-\nguage is Persian and for China and India, the best\nlanguage is English.\nWe speculate that our observations might be at-\ntributed to the reporting bias phenomenon (Grice,\n1975; Gordon and Van Durme, 2013). It is catego-\nrized by people rarely stating the obvious knowl-\nedge that is shared by everyone (commonsense)\nexplicitly in the text. For instance, the fact that\n2045\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\n0.6\nmBERT\nXLM\nXLM/uni00ADR/uni00ADbase\nXLM/uni00ADR/uni00ADlarge\n(a) mBERT, XLM, XLM-R family.\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\n0.6\nmT5/uni00ADsmall\nmT5/uni00ADbase\nmT5/uni00ADlarge (b) mT5 family.\nUS China India Iran Kenya0.2\n0.3\n0.4\n0.5\n0.6\nXGLM/uni00AD564M\nXGLM/uni00AD1.7B\nXGLM/uni00AD2.9B\nXGLM/uni00AD4.5B (c) XGLM family.\nFigure 5: Average performance of multilingual PLMs when fed with prompts without any specified country names.\nComplete results are shown in Appendix F.\nModels en zh hi fa sw\nmBERT India India US US China\nXLM India Kenya India US Kenya\nXLM-R-baseIndia China India US India\nXLM-R-largeIndia US US US Kenya\nmT5-small India Kenya Kenya US Kenya\nmT5-base India India Kenya US Kenya\nmT5-large India Kenya Kenya US India\nXGLM-564MChina US India/Kenya US India\nXGLM-1.7BIndia India India US India\nXGLM-2.9BIndia India US US India\nXGLM-4.5BIndia US/China/India India US India\nBest Countries India India India US India\nTable 3: Countries best probed with prompts in different\nlanguages. Each country in the last row “ Best Coun-\ntries” is the one appearing most in its located column.\nall the humans can murder is disproportionately\nover-reported than humans can breathe in the En-\nglish text. This unbalanced frequency would lead\nto bias towards acquiring uncommon event knowl-\nedge from PLMs, instead of commonsense knowl-\nedge (Shwartz and Choi, 2020). In our setting, we\nbelieve that reporting bias is a key ingredient in\nexplaining our observed trends. For instance, in-\ndigenous population is less likely to record obvious\nfacts about their culture in their native language\ntexts as compared to the facts from other cultures.\nFor example, when mentioning the driver seat side\nin India, compared with people living in other coun-\ntries, Indian people will not talk too much about\nthis because it is too trivial for them.\nWe seek a quantitative evidence in the context of\nstaple food as a concept again to support our claim.\nThroughout the English and Chinese Wikipedia cor-\npora, we count the co-occurrence of words “China”,\n“rice” and “staple food”, and “the United States”,\n“bread” and “staple food” in their respective lan-\nguages. The counting results are shown in Table 4.\nWe notice that when China is mentioned, English\nwords “rice” and “staple food” co-occur 25 times\nWords Freq. of Co-occur # Co-occur\nrice, staple food, China 3.6x 25bread, staple food, US 1x 7\n米饭(rice),主食(staple food),中国(China) 3.2x 3面包(bread),主食(staple food),美国(US) 3.2x 3\nTable 4: Word co-occurrence and frequency in En-\nglish and Chinese Wikipedia. English Wikipedia has\n72484142 sentences, 7.6 times more than those of Chi-\nnese Wikipedia, 9502859 sentences. ‘ nx’ denotes the\nfrequency rate is n times higher than the lowest one.\nwhereas it is mentioned merely 3 times in Chinese\nWikipedia. Furthermore, in the context of the US,\nEnglish words “bread” and “staple food” appear\n7 times simultaneously while Chinese words “面\n包(bread)” and “ 主食(staple food )” co-occur 3\ntimes. Although the number of co-occurrence is\nhigher in the English Wikipedia, the frequency rate\nof the Chinese word co-occurrence is 3.2 times\nhigher, since the Chinese Wikipedia corpus is 7.6\ntimes smaller than the English corpus. In sum-\nmary, it shows that commonsense knowledge about\na country is not mentioned more frequently in its\nnative language corpus but might have higher oc-\ncurrences in some other languages.\n5.5 Countries Best Probed with Prompts in\nDifferent Languages\nApart from the best languages to probe knowledge\nabout countries, conversely, we can also study the\ncountries best probed with prompts in different\nlanguages. Specifically, we focus on the following\nquestion: Given one studied language X, is the\ncountry best probed the same as the indigenous\ncountry of language X?\nWe present our results in Table 3. We observe\nthat except Hindi, the countries best probed are\ndistinct to the corresponding countries of language.\nFor example, Swahili prompts probe Indian knowl-\nedge best instead of Kenya, and Persian prompts\n2046\nprobe US knowledge best instead of Iran. It is also\ncounter-intuitive because it is natural for people\nto imagine that the best probed country should be\nthe one where a particular language is spoken most\ncommonly.\nWe can also ascribe the phenomenon observed\nfor Q2 to the reporting bias. To analyze this ob-\nservation, we compare the occurrence of knowl-\nedge about different countries in the same lan-\nguage corpus. We find that English words “bread”,\n“staple food ” and “ the United States ” co-occur\nmuch less frequently than “rice”, “staple food” and\n“China”. Besides, Chinese words “ 面包(bread)”,\n“主食(staple food)” and “美国(the United States)”\nco-occur 3 times, which is the same as co-\noccurrence of “ 米饭(rice)”, “主食(staple food)”\nand “中国(China)”. The comparison results in-\ndicate that given one language, local country’s\nknowledge may not appear the most, compared\nwith knowledge about other countries.\n6 Conclusions\nWe propose a knowledge probing benchmark, GE-\nOMLAMA , to evaluate the extent of multilingual\nPLMs to store geo-diverse commonsense. Results\nshow that multilingual PLMs can achieve signifi-\ncantly higher performance than random guess, sug-\ngesting that they are capable of storing geo-diverse\nknowledge. We also find that fed with prompts\nwithout any country cues, multilingual PLMs are\nnot intrinsically biased towards knowledge about\nthe United States. We further investigate the best\nlanguage to probe the knowledge about a particular\ncountry, and the country best probed with prompts\nin a certain language. Surprisingly, we notice that\nthe best language is not the country’s native lan-\nguage, and the best probed country is not the in-\ndigenous country of the language. We connect this\nto reporting bias issue in geo-diverse context: one\ncountry’s commonsense is seldom recorded in the\ntext by people living in that country as it is too\ntrivial and not worth mentioning for them.\nAcknowledgement\nWe thank annotators for tremendous efforts on an-\nnotation and evaluation. We also greatly appreci-\nate Tao Meng, Xiao Liu, Ashima Suvarna, Ming\nZhong, Kuan-Hao Huang, I-Hung Hsu and other\nmembers of UCLA-NLP group for their helpful\ncomments. This work was partially supported by\nNSF IIS-1927554, Sloan Research Fellow, Amazon\nAWS credits, Amazon Fellow, and a DARPA MCS\nprogram under Cooperative Agreement N66001-\n19-2-4032. The views and conclusions are those of\nthe authors and should not reflect the official policy\nor position of DARPA or the U.S. Government.\nLimitations\nGEOMLAMA is proposed for evaluating the degree\nof potential geographic bias in multilingual PLMs.\nHowever, due to the limited coverage of countries,\nlanguages and geo-diverse concepts, GEOMLAMA\nmay introduce unwanted bias. In GEOMLAMA ,\nwe only consider five countries and their native\nlanguages, which merely occupy a tiny portion of\nall the countries in the world and thousands of lan-\nguages. Also, in countries like India, there are mul-\ntiple commonly used languages, we limit our study\non Hindi and will extend to more languages to study\nthe phenomenon. Besides, we design prompts sim-\nply based on 16 general geo-diverse concepts. The\nextension on existing GEOMLAMA can help in\nobtaining more solid results and mitigating bias\nagainst uncovered countries and languages.\nIn this work, we mainly focus on evaluating mul-\ntilingual PLMs on GEOMLAMA without studying\nhow multilingual pre-training process affects the\nmodel performance on geo-diverse commonsense\nprobing. We intend to explore effect of the process\non model’s geo-diversity in future work. Specif-\nically, we aim to examine whether pre-training\non multilingual corpora really brings more geo-\ndiversity than pre-training on monolingual corpora\ndoes. Besides, we do not cover how to improve\nmodel performance on GEOMLAMA and other re-\nlated tasks. We expect to seek approaches to im-\nproving model’s geo-diversity while maintaining\nmultilingual PLMs’ performance on various multi-\nlingual benchmarks in future work as well.\nEthical Consideration\nAs we propose a new benchmark in this paper, we\nprovide details about compensation rate for anno-\ntators. We recruit five countries’ college students\nand annotators from Amazon MTurk. We provide\na fair compensation rate with $12 per hour and in\ntotal around $150 to the annotators on both prompt\ndesign, translation and evaluation. Note that part of\nannotations are done by the authors of this work.\n2047\nReferences\nA. Acharya, Kartik Talamadupula, and Mark A. Fin-\nlayson. 2020. An Atlas of Cultural Commonsense\nfor Machine Reasoning. ArXiv, abs/2009.05664.\nAntoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-\ntanya Malaviya, Asli Celikyilmaz, and Yejin Choi.\n2019. COMET: Commonsense Transformers for\nAutomatic Knowledge Graph Construction. In Pro-\nceedings of the 57th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 4762–\n4779, Florence, Italy. Association for Computational\nLinguistics.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language Models are Few-shot\nLearners. Advances in Neural Information Process-\ning Systems, 33:1877–1901.\nYang Trista Cao and Hal Daumé III. 2021. Toward\ngender-inclusive coreference resolution: An analysis\nof gender and bias throughout the machine learning\nlifecycle*. Computational Linguistics, 47(3):615–\n661.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzmán, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\nCross-lingual Representation Learning at Scale. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 8440–\n8451, Online. Association for Computational Lin-\nguistics.\nAlexis Conneau and Guillaume Lample. 2019. Cross-\nLingual Language Model Pretraining. Advances in\nNeural Information Processing Systems, 32.\nSunipa Dev, Masoud Monajatipoor, Anaelia Ovalle, Ar-\njun Subramonian, Jeff Phillips, and Kai-Wei Chang.\n2021. Harms of gender exclusivity and challenges in\nnon-binary representation in language technologies.\nIn Proceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n1968–1994, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\nDeep Bidirectional Transformers for Language Un-\nderstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171–4186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nFahim Faisal, Yinkai Wang, and Antonios Anastasopou-\nlos. 2022. Dataset Geography: Mapping Language\nData to Language Users. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 3381–\n3411, Dublin, Ireland. Association for Computational\nLinguistics.\nAnjalie Field, Su Lin Blodgett, Zeerak Waseem, and\nYulia Tsvetkov. 2021. A survey of race, racism, and\nanti-racism in NLP. In Proceedings of the 59th An-\nnual Meeting of the Association for Computational\nLinguistics and the 11th International Joint Confer-\nence on Natural Language Processing (Volume 1:\nLong Papers), pages 1905–1925, Online. Association\nfor Computational Linguistics.\nJonathan Gordon and Benjamin Van Durme. 2013. Re-\nporting Bias and Knowledge Acquisition. In Pro-\nceedings of the 2013 workshop on Automated knowl-\nedge base construction, pages 25–30.\nHerbert P Grice. 1975. Logic and Conversation. In\nSpeech Acts, pages 41–58. Brill.\nZhengbao Jiang, Antonios Anastasopoulos, Jun Araki,\nHaibo Ding, and Graham Neubig. 2020a. X-FACTR:\nMultilingual Factual Knowledge Retrieval from Pre-\ntrained Language Models. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5943–5959,\nOnline. Association for Computational Linguistics.\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\nNeubig. 2020b. How Can We Know What Language\nModels Know? Transactions of the Association for\nComputational Linguistics, 8:423–438.\nMandar Joshi, Eunsol Choi, Daniel Weld, and Luke\nZettlemoyer. 2017. TriviaQA: A Large Scale Dis-\ntantly Supervised Challenge Dataset for Reading\nComprehension. In Proceedings of the 55th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 1601–1611,\nVancouver, Canada. Association for Computational\nLinguistics.\nPratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika\nBali, and Monojit Choudhury. 2020. The state and\nfate of linguistic diversity and inclusion in the NLP\nworld. In Proceedings of the 58th Annual Meeting of\nthe Association for Computational Linguistics, pages\n6282–6293, Online. Association for Computational\nLinguistics.\nNora Kassner, Philipp Dufter, and Hinrich Schütze.\n2021. Multilingual LAMA: Investigating Knowl-\nedge in Multilingual Pretrained Language Models.\nIn Proceedings of the 16th Conference of the Euro-\npean Chapter of the Association for Computational\nLinguistics: Main Volume, pages 3250–3258, Online.\nAssociation for Computational Linguistics.\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\nton Lee, Kristina Toutanova, Llion Jones, Matthew\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natural\n2048\nQuestions: A Benchmark for Question Answering\nResearch. Transactions of the Association for Com-\nputational Linguistics, 7:452–466.\nAnne Lauscher, Archie Crowley, and Dirk Hovy. 2022.\nWelcome to the modern world of pronouns: Identity-\ninclusive natural language processing beyond gen-\nder. In Proceedings of the 29th International Con-\nference on Computational Linguistics, pages 1221–\n1232, Gyeongju, Republic of Korea. International\nCommittee on Computational Linguistics.\nBill Yuchen Lin, Seyeon Lee, Rahul Khanna, and Xiang\nRen. 2020. Birds have four legs?! NumerSense:\nProbing Numerical Commonsense Knowledge of Pre-\nTrained Language Models. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 6862–6868,\nOnline. Association for Computational Linguistics.\nBill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, and Xi-\nang Ren. 2021a. Common Sense Beyond English:\nEvaluating and Improving Multilingual Language\nModels for Commonsense Reasoning. In Proceed-\nings of the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 1274–1287, Online.\nAssociation for Computational Linguistics.\nXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu\nWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-\nman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021b.\nFew-shot Learning with Multilingual Language Mod-\nels. arXiv preprint arXiv:2112.10668.\nFangyu Liu, Emanuele Bugliarello, Edoardo Maria\nPonti, Siva Reddy, Nigel Collier, and Desmond El-\nliott. 2021. Visually Grounded Reasoning across\nLanguages and Cultures. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 10467–10485, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nXiao Liu, Da Yin, Yansong Feng, and Dongyan Zhao.\n2022. Things not Written in Text: Exploring Spatial\nCommonsense from Visual Signals. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 2365–2376, Dublin, Ireland. Association for\nComputational Linguistics.\nTuan-Phong Nguyen, Simon Razniewski, and Gerhard\nWeikum. 2021. Advanced semantics for common-\nsense knowledge extraction. In Proceedings of the\nWeb Conference 2021, pages 2636–2647.\nMatthew E. Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep Contextualized Word Rep-\nresentations. In Proceedings of the 2018 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long Papers), pages 2227–2237,\nNew Orleans, Louisiana. Association for Computa-\ntional Linguistics.\nFabio Petroni, Tim Rocktäschel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language Models as Knowl-\nedge Bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),\npages 2463–2473, Hong Kong, China. Association\nfor Computational Linguistics.\nEdoardo Maria Ponti, Goran Glavaš, Olga Majewska,\nQianchu Liu, Ivan Vuli´c, and Anna Korhonen. 2020.\nXCOPA: A Multilingual Dataset for Causal Com-\nmonsense Reasoning. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP), pages 2362–2376, On-\nline. Association for Computational Linguistics.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nModels are Unsupervised Multitask Learners. Ope-\nnAI blog, 1(8):9.\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\nHow Much Knowledge Can You Pack Into the Param-\neters of a Language Model? In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 5418–5426,\nOnline. Association for Computational Linguistics.\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV , Eric\nWallace, and Sameer Singh. 2020. AutoPrompt: Elic-\niting Knowledge from Language Models with Auto-\nmatically Generated Prompts. In Proceedings of the\n2020 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP), pages 4222–4235,\nOnline. Association for Computational Linguistics.\nVered Shwartz. 2022. Good Night at 4 pm?! Time\nExpressions in Different Cultures. In Findings of\nthe Association for Computational Linguistics: ACL\n2022, pages 2842–2853, Dublin, Ireland. Association\nfor Computational Linguistics.\nVered Shwartz and Yejin Choi. 2020. Do Neural\nLanguage Models Overcome Reporting Bias? In\nProceedings of the 28th International Conference\non Computational Linguistics , pages 6863–6870,\nBarcelona, Spain (Online). International Committee\non Computational Linguistics.\nMujeen Sung, Jinhyuk Lee, Sean Yi, Minji Jeon, Sung-\ndong Kim, and Jaewoo Kang. 2021. Can Language\nModels be Biomedical Knowledge Bases? In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing , pages 4723–\n4734, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nAlon Talmor, Yanai Elazar, Yoav Goldberg, and\nJonathan Berant. 2020. oLMpics-On What Language\nModel Pre-training Captures. Transactions of the As-\nsociation for Computational Linguistics, 8:743–758.\n2049\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\nJoe Davison, Sam Shleifer, Patrick von Platen, Clara\nMa, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le\nScao, Sylvain Gugger, Mariama Drame, Quentin\nLhoest, and Alexander M. Rush. 2020. Transform-\ners: State-of-the-Art Natural Language Processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nLinting Xue, Noah Constant, Adam Roberts, Mihir Kale,\nRami Al-Rfou, Aditya Siddhant, Aditya Barua, and\nColin Raffel. 2021. mT5: A Massively Multilingual\nPre-trained Text-to-Text Transformer. In Proceed-\nings of the 2021 Conference of the North American\nChapter of the Association for Computational Lin-\nguistics: Human Language Technologies, pages 483–\n498, Online. Association for Computational Linguis-\ntics.\nDa Yin, Liunian Harold Li, Ziniu Hu, Nanyun Peng,\nand Kai-Wei Chang. 2021. Broaden the Vision: Geo-\nDiverse Visual Commonsense Reasoning. In Pro-\nceedings of the 2021 Conference on Empirical Meth-\nods in Natural Language Processing , pages 2115–\n2129, Online and Punta Cana, Dominican Republic.\nAssociation for Computational Linguistics.\nXikun Zhang, Deepak Ramachandran, Ian Tenney,\nYanai Elazar, and Dan Roth. 2020. Do Language\nEmbeddings capture Scales? In Findings of the Asso-\nciation for Computational Linguistics: EMNLP 2020,\npages 4889–4896, Online. Association for Computa-\ntional Linguistics.\nZihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and\nSameer Singh. 2021. Calibrate Before Use: Im-\nproving Few-Shot Performance of Language Models.\nIn International Conference on Machine Learning,\npages 12697–12706. PMLR.\nZexuan Zhong, Dan Friedman, and Danqi Chen. 2021.\nFactual Probing Is [MASK]: Learning vs. Learning\nto Recall. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 5017–5033, Online. Association\nfor Computational Linguistics.\nPei Zhou, Rahul Khanna, Seyeon Lee, Bill Yuchen Lin,\nDaniel Ho, Jay Pujara, and Xiang Ren. 2021. RICA:\nEvaluating Robust Inference Capabilities Based on\nCommonsense Axioms. In Proceedings of the 2021\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 7560–7579, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nWenxuan Zhou, Fangyu Liu, Ivan Vuli ´c, Nigel Col-\nlier, and Muhao Chen. 2022. Prix-LM: Pretraining\nfor Multilingual Knowledge Base Construction. In\nProceedings of the 60th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 5412–5424, Dublin, Ireland. As-\nsociation for Computational Linguistics.\nXuhui Zhou, Yue Zhang, Leyang Cui, and Dandan\nHuang. 2020. Evaluating commonsense in pre-\ntrained language models. In Proceedings of the AAAI\nConference on Artificial Intelligence , volume 34,\npages 9733–9740.\n2050\nAppendix\nA Geo-Diverse Concept List\nThe general geo-diverse concepts are shown in\nTable 6. We summarize all the concepts into 16\ngeneral ones, covering rules, policies, geography,\ncustoms, personal choices and habits. Multiple\nprompts can be designed for each geo-diverse con-\ncept. For example, measurement units can involve\nunits measuring height, weight and temperature,\nand thus annotators can create multiple prompts\nabout various types of measurement units.\nB Statistics of G EOMLAMA\nTable 5 shows the statistics of GEOMLAMA . In\ntotal, there are 3125 prompts in GEOMLAMA , 625\nprompts about each country’s knowledge. We also\nmanifest the average numbers of gold answers and\ncorresponding answer candidates for prompts re-\ngarding each country. Overall, the number of gold\nanswers is 1.20 per prompt, with answer candi-\ndate list of average length 4.76. Here note that for\nprompts under the same topic (e.g., “In traditional\n[X] weddings, the color of wedding dress is usu-\nally [MASK].”), regardless of the exact country\nfilled in [X] , the answer candidate lists are the\nsame for all the five countries. Therefore, the aver-\nage length of answer candidates is identical to all\nthe studied countries.\nC Details of Evaluation Methods on\nAutoregressive and Encoder-Decoder\nLanguage Models\nAutoregressive Language Models (XGLM fam-\nily). For autoregressive language models such\nas XGLM, we first replace masked token in the\nprompt with answer candidate tokens (e.g., “ In\nChina, people usually eat food with [MASK].”-\n>“In China, people usually eat food with chop-\nsticks.”). The joint probability of generating all the\ntokens in the complete sentence is used for scor-\ning answer candidates. Given a prompt template\nt filled with an answer candidate e, t is tokenized\ninto K tokens (e.g., t1, t2, ..., tK). We assign score\nle to the answer candidate as:\nle = 1\nK\ni=K∑\ni=1\nlog(p(ti|t<i)). (3)\nHere, we perform K forward passes to the\nautoregressive language model to obtain log\nCountries#Prompts # Avg. Gold Answers # Avg. Answer Candidates\nUS\n625\n1.16\n4.76China 1.12India 1.32Iran 1.16Kenya 1.25\nOverall 3125 1.20 4.76\nTable 5: Detailed statistics of GEOMLAMA .\nprobability of generating the whole sentence\nwith the answer candidate e. In this case,\nthe ith forward pass inference would calculate\np(ti|“In China, ..., ti−2 ti−1”).\nEncoder-Decoder Language Models (mT5 fam-\nily). During pre-training of encoder-decoder lan-\nguage models mT5, a masked sequence is input\nto encoder, and decoder learns to recover the L\nmasked tokens in autoregressive fashion. There-\nfore, we input a masked prompt t into the mod-\nels (e.g., “In China, people usually eat food with\n[MASK]”) and calculate the score for answer can-\ndidate e as:\nle = 1\nL\ni=L∑\ni=1\nlog(p(ei|e<i, t)). (4)\nComputing Eq.4 requires L forward passes,\nsince the decoder needs to generate L to-\nkens. Here ith forward pass inference would be\np(ei|e1 e2...ei−1, “In China, people usually eat\nfood with [MASK]”). Note that mT5 can use one\nsingle [MASK] token to represent multiple consec-\nutive masked tokens. Thus, different from masked\nlanguage models, mT5 models are simply fed with\nthe prompt with only one [MASK] token instead\nof L [MASK] tokens.\nD Evaluating GPT-3 on G EOMLAMA\nApproach to probing GPT-3 is different from the\nmethods mentioned in §4. Instead of feeding declar-\native prompt sentences, we leverage Question An-\nswering (QA) API empowered by GPT-3 and input\nquestions to query the knowledge. For example,\ninstead of using “In traditional Chinese weddings,\nthe color of wedding dress is usually[MASK]”, we\nfirst convert it to question form like “ What is the\ncolor of wedding dress in an American wedding?”\nand query GPT-3 with the converted question. Dur-\ning evaluation stage, rather than scoring answers\nfrom given answer candidate list, GPT-3 can gen-\nerate open-ended answers and we evaluate GPT-3\npredictions using the same metric in §4.3. Con-\nsidering the huge time cost of manually inputting\n2051\nCategories Concepts\nrules, policies, geography\ntraffic rules\nmeasurement units\ndate formats\ncolor of stock price\nclimate\ncustoms, personal choices, habits\npayment\nshower time\nclothes drying\nbroom usage\nfood and drink\nfamily\npopular sports\ntransportation\nservant\nwedding\nfuneral\nTable 6: Geo-diverse concept list with categorization.\nquestions by annotators to GPT-3 API, we do not\nconvert paraphrased prompts to questions and per-\nform analysis on them. In other words, the number\nof tested questions is only 1/5 out of the total num-\nber of prompts in GEOMLAMA , which is 625.\nWe probe GPT-3 with the converted questions\nin five languages, each of which asks knowledge\nabout the five studied countries. Final results are\nshown in Table 7. One notable result is that using\nEnglish prompts can achieve nearly 60% perfor-\nmance, while using Swahili prompts cannot solve\nany questions correctly. Also for Hindi and Per-\nsian prompts, the results are still extremely low,\nranging from 0% to 25%. It exposes strong bias in\nterms of language usage. When looking at the per-\nformance of probing knowledge about respective\ncountries, the disparity is not large. The country\nthat can be best probed is the United States, while\nthe worst probed country only underperforms the\nUnited States 6.9%.\nE Detailed Results of Multilingual PLMs\non GEOMLAMA\nTable 8, 9, and 10 show the details of each multi-\nlingual PLM’s performance on GEOLAMA . The\nperformance of random guess depends on the ex-\npectation of correct predictions, which is equivalent\nto the ratio of total number of gold answers to the\ntotal number of answers in the answer candidate\nlists. Since the number of gold answers and an-\nswer candidates is different for knowledge about\ndifferent countries, the random guess performance\nis not the same across countries. However, prompts\nLanguages US China India Iran Kenya Average\nen 68.97 57.14 54.55 55.17 65.52 50.23\nzh 44.83 50.00 39.39 37.93 31.03 40.64\nfa 20.69 21.43 24.24 10.34 17.24 18.79\nhi 6.90 0.00 12.12 3.45 20.69 8.63\nsw 0.00 0.00 0.00 0.00 0.00 0.00\nAverage 28.28 25.71 26.06 21.38 26.90 25.67\nTable 7: GPT-3 performance (%) on GEOMLAMA .\nin each of the languages have the same number of\ngold answers and candidate answers, so random\nguess performance is identical across languages.\nF Detailed Results of Multilingual PLMs\nProbed with Prompts without Country\nTokens\nTable 11, 12, and 13 show the details of each\nmultilingual PLM’s performance when input with\nprompts lacking specified country information. It\ncan help in determining the intrinsic bias of each\nmultilingual PLM.\n2052\nLanguages Countries mBERT XLM XLM-R-base XLM-R-large\nen\nUS 31.03 26.21 30.34 33.10\nChina 30.00 39.29 34.29 37.14\nIndia 40.61 52.12 37.58 37.58\nIran 21.38 27.59 28.28 37.93\nKenya 30.63 34.38 30.63 32.50\nzh\nUS 35.17 28.28 30.34 46.21\nChina 30.71 28.57 46.43 40.00\nIndia 38.79 32.12 38.18 35.15\nIran 32.41 36.55 24.14 33.10\nKenya 41.25 35.00 27.50 39.38\nfa\nUS 48.97 57.93 48.28 53.79\nChina 27.86 20.71 28.57 32.14\nIndia 38.79 27.88 33.33 34.55\nIran 47.59 31.03 35.17 33.79\nKenya 38.75 31.87 27.50 34.38\nhi\nUS 42.07 40.00 33.10 42.07\nChina 29.29 22.86 18.57 13.57\nIndia 34.55 35.76 36.36 32.73\nIran 33.79 31.03 31.72 27.59\nKenya 28.75 33.75 36.25 33.75\nsw\nUS 27.59 24.83 23.45 29.66\nChina 34.29 22.86 32.14 29.29\nIndia 27.88 29.70 31.52 29.09\nIran 20.69 27.59 35.17 31.72\nKenya 26.88 31.87 27.50 31.87\nTable 8: Results (%) of mBERT, XLM, XLM-R-base, and XLM-R-large on GEOMLAMA .\nLanguages Countries mT5-small mT5-base mT5-large\nen\nUS 24.14 18.62 30.34\nChina 40.71 34.29 39.29\nIndia 41.21 34.55 49.09\nIran 19.31 19.31 26.21\nKenya 21.88 23.75 34.38\nzh\nUS 20.00 33.79 28.97\nChina 26.43 26.43 26.43\nIndia 23.64 46.06 33.33\nIran 33.10 26.90 31.03\nKenya 36.88 34.38 35.00\nfa\nUS 55.86 43.45 48.28\nChina 31.43 29.29 22.86\nIndia 36.36 34.55 30.30\nIran 28.28 30.34 33.79\nKenya 30.00 30.63 35.00\nhi\nUS 33.79 33.79 44.14\nChina 28.57 26.43 19.29\nIndia 33.33 33.33 35.15\nIran 33.79 33.10 32.41\nKenya 42.50 36.88 41.88\nsw\nUS 37.93 32.41 28.28\nChina 17.86 28.57 42.86\nIndia 30.91 30.30 41.21\nIran 36.55 26.21 23.45\nKenya 43.12 38.75 33.75\nTable 9: Results (%) of models in mT5 family on GEOMLAMA .\n2053\nLanguages Countries XGLM-564M XGLM-1.7B XGLM-2.9B XGLM-4.5B\nen\nUS 32.41 37.93 31.72 37.24\nChina 37.86 32.14 39.29 35.71\nIndia 30.91 40.00 43.03 42.42\nIran 23.45 28.28 20.00 31.03\nKenya 21.88 25.00 26.25 35.00\nzh\nUS 34.48 36.55 40.00 35.86\nChina 25.71 33.57 30.00 37.14\nIndia 27.27 32.73 36.36 31.52\nIran 18.62 22.07 25.52 13.79\nKenya 24.38 19.38 16.88 20.00\nfa\nUS 49.66 49.66 46.90 49.66\nChina 26.43 27.86 25.71 35.00\nIndia 32.73 31.52 28.48 32.73\nIran 37.24 35.86 31.72 36.55\nKenya 34.38 30.00 33.75 27.50\nhi\nUS 35.86 28.97 33.79 28.97\nChina 18.57 10.00 20.71 21.43\nIndia 33.33 29.70 29.09 33.94\nIran 34.48 22.76 32.41 23.45\nKenya 34.38 26.88 30.00 26.25\nsw\nUS 25.52 28.28 27.59 24.14\nChina 33.57 38.57 30.71 30.71\nIndia 34.55 34.55 37.58 33.33\nIran 31.72 22.07 21.38 33.10\nKenya 26.88 29.38 30.63 33.75\nTable 10: Results (%) of models in XGLM family on GEOMLAMA .\nLanguages Countries mBERT XLM XLM-R-base XLM-R-large\nen\nUS 31.03 26.21 30.34 33.10\nChina 30.00 39.29 34.29 37.14\nIndia 40.61 52.12 37.58 37.58\nIran 21.38 27.59 28.28 37.93\nKenya 30.63 34.38 30.63 32.50\nzh\nUS 35.17 28.28 30.34 46.21\nChina 30.71 28.57 46.43 40.00\nIndia 38.79 32.12 38.18 35.15\nIran 32.41 36.55 24.14 33.10\nKenya 41.25 35.00 27.50 39.38\nfa\nUS 48.97 57.93 48.28 53.79\nChina 27.86 20.71 28.57 32.14\nIndia 38.79 27.88 33.33 34.55\nIran 47.59 31.03 35.17 33.79\nKenya 38.75 31.87 27.50 34.38\nhi\nUS 42.07 40.00 33.10 42.07\nChina 29.29 22.86 18.57 13.57\nIndia 34.55 35.76 36.36 32.73\nIran 33.79 31.03 31.72 27.59\nKenya 28.75 33.75 36.25 33.75\nsw\nUS 27.59 24.83 23.45 29.66\nChina 34.29 22.86 32.14 29.29\nIndia 27.88 29.70 31.52 29.09\nIran 20.69 27.59 35.17 31.72\nKenya 26.88 31.87 27.50 31.87\nTable 11: Results (%) of mBERT, XLM, XLM-R-base, XLM-R-large probed with prompts without country tokens\non GEOMLAMA .\n2054\nLanguages Countries mT5-small mT5-base mT5-large\nen\nUS 38.62 49.66 40.69\nChina 45.00 47.14 42.86\nIndia 46.06 51.52 60.61\nIran 38.62 46.90 43.45\nKenya 43.12 44.38 57.50\nzh\nUS 24.14 24.83 30.34\nChina 32.86 30.71 33.57\nIndia 35.15 28.48 31.52\nIran 36.55 40.69 40.00\nKenya 39.38 43.12 36.88\nfa\nUS 46.21 41.38 47.59\nChina 39.29 33.57 41.43\nIndia 34.55 41.82 35.76\nIran 35.86 37.24 42.76\nKenya 37.50 41.88 42.50\nhi\nUS 31.72 25.52 29.66\nChina 39.29 38.57 32.86\nIndia 44.24 46.67 41.21\nIran 30.34 33.79 31.03\nKenya 40.00 40.00 41.25\nsw\nUS 22.76 28.28 25.52\nChina 23.57 35.71 42.86\nIndia 30.91 35.76 37.58\nIran 14.48 20.69 22.07\nKenya 16.88 23.75 26.25\nTable 12: Results (%) of models in mT5 family probed with prompts without country tokens on GEOMLAMA .\nLanguages Countries XGLM-564M XGLM-1.7B XGLM-2.9B XGLM-4.5B\nen\nUS 28.97 38.62 34.48 40.00\nChina 57.14 43.57 50.00 46.43\nIndia 51.52 47.88 53.94 46.67\nIran 35.86 35.17 34.48 36.55\nKenya 40.62 49.38 43.75 46.88\nzh\nUS 34.48 42.76 38.62 47.59\nChina 49.29 55.00 51.43 50.71\nIndia 44.24 52.73 54.55 46.67\nIran 54.48 52.41 46.21 63.45\nKenya 55.62 58.13 62.50 61.25\nfa\nUS 27.59 28.97 35.17 34.48\nChina 34.29 37.86 35.00 40.00\nIndia 38.18 34.55 40.00 36.97\nIran 17.93 22.07 24.83 24.14\nKenya 21.88 28.12 30.63 33.12\nhi\nUS 24.14 32.41 20.69 31.72\nChina 52.86 52.86 48.57 55.71\nIndia 39.39 41.21 40.61 40.61\nIran 37.93 39.31 28.28 42.07\nKenya 36.25 41.25 41.88 43.12\nsw\nUS 42.07 40.00 41.38 35.17\nChina 42.14 39.29 36.43 27.86\nIndia 40.00 42.42 50.30 46.06\nIran 33.10 24.83 37.24 31.72\nKenya 42.50 41.25 46.25 32.50\nTable 13: Results (%) of models in XGLM family probed with prompts without country tokens on GEOMLAMA .\n2055"
}