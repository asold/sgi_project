{
    "title": "ChatGPT, Large Language Models, and Generative AI as Future Augments of Surgical Cancer Care",
    "url": "https://openalex.org/W4365443207",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A3079525100",
            "name": "A.N. Kothari",
            "affiliations": [
                "Medical College of Wisconsin"
            ]
        },
        {
            "id": "https://openalex.org/A3079525100",
            "name": "A.N. Kothari",
            "affiliations": [
                "Medical College of Wisconsin"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4362716521",
        "https://openalex.org/W4313451803",
        "https://openalex.org/W4319662928",
        "https://openalex.org/W4319301505",
        "https://openalex.org/W3208986990",
        "https://openalex.org/W4313892628",
        "https://openalex.org/W4281264079"
    ],
    "abstract": null,
    "full_text": "Vol:.(1234567890)\nAnn Surg Oncol (2023) 30:3174–3176\nhttps://doi.org/10.1245/s10434-023-13442-2\nEDITORIAL – GLOBAL HEALTH SERVICES RESEARCH\nChatGPT, Large Language Models, and Generative AI as Future \nAugments of Surgical Cancer Care\nA. N. Kothari, MD, MS \nDepartment of Surgery, Medical College of Wisconsin, Milwaukee \nReleased in November of 2022 as a public and free \nresearch preview, ChatGPT rapidly brought OpenAI’s work \nwith autoregressive large language modeling based on Gen-\nerative Pretrained Transformers (GPT) into the mainstream.1 \nUsers from around the world were able to easily interact \nwith the ChatGPT model through a simple web interface \n(chat.openai.com). This model has now been used to gener-\nate scholarly content, take board exams, and write discharge \nsummaries.2,3 Less than 2 months from public launch, Chat-\nGPT had more than 100 million active users and OpenAI.\ncom became a top 50 most-visited websites in the world. 4 \nThe best explanation about why there was such rapid adop-\ntion and popularity might be directly from the source:\nAuthor Prompt: “Why did ChatGPT become so \npopular?”\nChatGPT Response: “As an AI language model, ChatGPT \nbecame popular because of its impressive ability to under -\nstand and generate human-like language. It was trained on a \nmassive amount of text data, using state-of-the-art machine \nlearning techniques, which enables it to provide accurate \nand relevant responses to a wide variety of questions and \ntopics…ChatGPT’s ability to understand and respond to \nnatural language queries makes it an attractive solution for \nbusinesses and individuals looking to automate customer \nsupport, personal assistants, and other applications. Fur -\nthermore, the availability of ChatGPT as an open-source \ntool makes it accessible to a wide range of developers, \nresearchers, and enthusiasts who can use and improve upon \nthe technology to create innovative applications. Overall, \nChatGPT’s popularity is a result of its advanced technol-\nogy, versatility, and accessibility, which make it a valuable \nresource for a wide range of users and applications.”5\nWhat immediately stands out when retrieving a response \nfrom OpenAI’s consumer interface is the quality of the lan-\nguage, complexity and apparent nuance of the response, and \nability to flexibly respond to a variety of input prompts. For \nthose without significant experience with large language \nmodels, generative artificial intelligence (AI), and/or con-\nversational AI, the first few moments interacting with the \nChatGPT model can feel like magic.\nGPT models are OpenAI’s solution for several natural \nlanguage processing tasks, including copywriting, parsing, \nclassification, and summarization. ChatGPT is a fine-tuned \nmodel using GPT-3.5; its training framework includes Rein-\nforcement Learning from Human Feedback (RLHF), which \nprovides some human supervision. 6 The model is trained \nusing >400 billion tokens of internet content (100 tokens \n= approximately 75 words) to predict what comes next in \nthe dataset: for example, completing a sentence. 7 The final \nproduct is a model that allows a user to provide a dialogue-\nbased instruction (input) and be provided a conversational \nresponse (output).\nThis type of AI-based chatbot, on its own, is not that new. \nThere are numerous examples of failed attempts, including \nMeta’s Galactica, which was released only 2 weeks before \nChatGPT and shut down in less than 72 hours after it was \nfound to frequently have incorrect, discriminatory, and \noffensive responses.8 However, where these others fell short \nis where ChatGPT has excelled by showcasing the capa -\nbilities of AI in understanding and responding to natural \nlanguage. While there remain key shortcomings with Chat-\nGPT, there is no arguing that OpenAI galvanized the pace \nof development and financial investment in conversational \nAI. Since the release of ChatGPT, Microsoft expanded its \npartnership with OpenAI through a multiyear, multibillion-\ndollar investment, Google released Bard, a conversational \n© Society of Surgical Oncology 2023\nFirst Received: 8 March 2023 \nAccepted: 20 March 2023 \nPublished online: 13 April 2023\nA. N. Kothari, MD, MS \ne-mail: akothari@mcw.edu\n3175\nChatGPT, Large Language Models, …         \nAI chatbot founded on their Language Model for Dialogue \nApplications (LaMDA), and Meta announced their own \nnew language model: LLaMA. The ability to access and \nfine-tune these models will provide a framework to create \nnew and innovative solutions for real world problems. This \nincludes considering ways to improve patient care through \nlanguage-driven processes, such as provider documenta-\ntion, patient education, written instructions, care coordina-\ntion, and supporting clinical decision support. Keeping up \nto date with this rapidly changing field is challenging, and \nseveral groups, including our own (www. anail ab. com/ gener \native- ai), now keep track of higher-quality applications with \ndomain-specific relevance.\nLarge language models are examples of generative AI—a \ndiscipline characterized by the use of foundation models \nto facilitate adaptation to a series of generative tasks that \ninclude the creation of text, images, music, and video. 9 \nDespite the excitement and enthusiasm surrounding genera-\ntive AI, effective use of these tools requires an understanding \nof their foundation models. To accomplish this, dedicated \ninterdisciplinary groups are being formed to advance the \nscience of foundation models through evaluating biases, \nidentifying limitations, providing transparency, and fore-\ncasting misuse before deployment at scale. 10 As generative \nAI moves to privacy-sensitive domains, including medicine \nand surgery, understanding data handling and processing is \nparamount. As with the adoption of any new technology, \nresponsible integration of generative AI into clinical care \nwill necessitate careful stewardship. Capitalizing on practi-\ncal training opportunities in informatics, collaborating with \ndevelopers, and establishing research priorities can equip \nsurgical oncologists with the tools to assess the safety and \nutility of these products.\nThis includes recognizing the potential harms that could \ncome with incorporation of generative AI models into surgi-\ncal practice. Because generated content is dependent on the \ndata used during model training, it will reproduce the biases, \nstereotypes, and toxicities present in the training data. This \ncould lead to the perpetuation of harmful discrimination, \nunjust representation, and inequitable practices when these \nmodels are implemented.11 Another area of concern is when \nhumans directly engage with generative AI models through \nweb-based interfaces, chatbots, or other types of conversa-\ntional agent systems. By anthropomorphizing AI systems, \nhuman users could be exploited to divulge private informa-\ntion or even be nudged into certain behaviors. A specific risk \nassociated with large language models, including ChatGPT, \nis the potential to create plausible sounding, but factually \nincorrect statements. This can result in dissemination of mis-\ninformation and incorrectly advising users with false infor -\nmation.12 Especially vulnerable are users who do not have \nthe necessary expertise to critically appraise the accuracy \nand context of generated material. Each of these concerns \nare even more important in settings where the stakes are high \nand there is no tolerance for misuse, such as surgery.\nStill, it is difficult not to get excited about the potential \nimpact of generative AI, especially when speculating on \nproducts that extend beyond text generation. Disciplines \nwith large amounts of underlying data that facilitate the \ndevelopment of foundation models and their fine-tuning for \nspecific use cases, such as oncology and surgery, are ripe \nfor disruption. This has already started. Absci, a drug crea-\ntion company, is using generative AI to design new antibod-\nies against common targets to rapidly accelerate the pace \nof pharmacologic development. 13 Subtle Medical is using \ngenerative AI to improve radiographic imaging (including \npreoperative images) by speeding acquisition and standard-\nizing quality.14 Other areas of growing interest in the appli-\ncation of generative AI include treatment selection, therapy \nsequencing, drug discovery, and operative planning, to name \na few.13 These examples emphasize how the first ways AI \nwill improve surgical oncologic practice will not be through \nreplacement, but instead through augmenting and teaming \nwith users.\nPrompting the ChatGPT model with a question and get-\nting back a fluent, cohesive, and (usually) accurate response \nmakes these often-promised applications of AI for precision \noncology appear much more achievable.\nAuthor Prompt: “How does ChatGPT think generative AI \nwill change surgical oncology?”\nChatGPT Response: “Generative AI has the potential to \nsignificantly improve the accuracy, efficiency, and precision \nof surgical oncology, leading to better patient outcomes and \na more personalized approach to cancer treatment.”5\nChatGPT is, of course, not magic. It is the product of \ncareful and iterative deployment that is supported by rigor -\nous research, pilot use cases, and frequent review of misuse. \nUnderstanding the model’s history and how generative AI \nis growing as a field is crucial for responsibly using these \ntechnologies in cancer care moving forward.\nDISCLOSURE ChatGPT was only used where directly quoted in \nthe body of the article and otherwise not used in the writing process \nfor this article.\nREFERENCES\n 1. Zimmerman A. A ghostwriter for the masses: ChatGPT and the \nfuture of writing. Ann Surg Oncol. 2023. https:// doi. org/ 10. 1245/ \ns10434- 023- 13436-0.\n 2. Kung TH, et al. Performance of ChatGPT on USMLE: potential \nfor AI-assisted medical education using large language models. \nPLOS Digit Health. 2023;2:e0000198.\n 3. Patel SB, Lam K. ChatGPT: the future of discharge summaries? \nLancet Digit Health. 2023;5:e107–8.\n3176 A. N. Kothari \n 4. Chow AR. How ChatGPT managed to grow faster than tiktok or \ninstagram. Time. 2023. https:// time. com/ 62536 15/ chatg pt- faste \nst- growi ng. Accessed Mar 7 2023.\n 5. ChatGPT. https:// chat. openai. com/ chat.\n 6. Ouyang L, et al. Training language models to follow instructions \nwith human feedback. arXiv [cs.CL]. 2022.\n 7. Brown TB, et al. Language models are few-shot learners. arXiv \n[cs.CL]. 2020.\n 8. Janssen A, Grützner L, Breitner MH. Why do chatbots fail? A \ncritical success factors analysis. In: International Conference on \nInformation Systems (ICIS) (researchgate.net, 2021).\n 9. Davenport TH, Mittal N. How generative AI is changing creative \nwork. Harvard Business Review. 2022. https:// hbr. org/ 2022/ 11/ \nhow- gener ative- ai- is- chang ing- creat ive- work. Accessed Mar 7 \n2023.\n 10. Bommasani R, et al. On the Opportunities and Risks of Founda-\ntion Models. arXiv [cs.LG]. 2021.\n 11. Weidinger L, et al. Ethical and social risks of harm from Lan-\nguage Models. arXiv [cs.CL] 2021.\n 12. Kenton Z, et al. Alignment of Language Agents. arXiv [cs.AI]. \n2021.\n 13. Shanehsazzadeh A, et al. Unlocking de novo antibody design \nwith generative artificial intelligence. bioRxiv. 2023. https:// doi.  \norg/ 10. 1101/ 2023. 01. 08. 523187.\n 14. Weyts K, et al. Artificial intelligence-based PET denoising could \nallow a two-fold reduction in [18F]FDG PET acquisition time in \ndigital PET/CT. Eur J Nucl Med Mol Imaging. 2022;49:3750–60.\nPublisher’s Note Springer Nature remains neutral with regard to \njurisdictional claims in published maps and institutional affiliations."
}