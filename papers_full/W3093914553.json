{
  "title": "Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classification",
  "url": "https://openalex.org/W3093914553",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5035082722",
      "name": "Linyi Yang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5085606158",
      "name": "Eoin M. Kenny",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5077802543",
      "name": "Tin Lok James Ng",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5101421088",
      "name": "Yi Yang",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5065595661",
      "name": "Barry Smyth",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5009000289",
      "name": "Ruihai Dong",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2965674570",
    "https://openalex.org/W2571789045",
    "https://openalex.org/W2470673105",
    "https://openalex.org/W2927690792",
    "https://openalex.org/W2265304962",
    "https://openalex.org/W2963207607",
    "https://openalex.org/W3085543735",
    "https://openalex.org/W3030406438",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2865687066",
    "https://openalex.org/W2966362896",
    "https://openalex.org/W2963029978",
    "https://openalex.org/W2901277930",
    "https://openalex.org/W2911971986",
    "https://openalex.org/W2964159526",
    "https://openalex.org/W2995446988",
    "https://openalex.org/W2963857521",
    "https://openalex.org/W3096942073",
    "https://openalex.org/W3122175177",
    "https://openalex.org/W2996507500",
    "https://openalex.org/W3017003177",
    "https://openalex.org/W2799194071",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W2994934025",
    "https://openalex.org/W3012629428",
    "https://openalex.org/W2970863760",
    "https://openalex.org/W3093419064",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W2964253222",
    "https://openalex.org/W2505493778",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W2003581433",
    "https://openalex.org/W1832693441",
    "https://openalex.org/W2964116600"
  ],
  "abstract": "Corporate mergers and acquisitions (M&amp;A) account for billions of dollars of investment globally every year, and offer an interesting and challenging domain for artificial intelligence. However, in these highly sensitive domains, it is crucial to not only have a highly robust and accurate model, but be able to generate useful explanations to garner a user's trust in the automated system. Regrettably, the recent research regarding eXplainable AI (XAI) in financial text classification has received little to no attention, and many current methods for generating textual-based explanations result in highly implausible explanations, which damage a user's trust in the system. To address these issues, this paper proposes a novel methodology for producing plausible counterfactual explanations, whilst exploring the regularization benefits of adversarial training on language models in the domain of FinTech. Exhaustive quantitative experiments demonstrate that not only does this approach improve the model accuracy when compared to the current state-of-the-art and human performance, but it also generates counterfactual explanations which are significantly more plausible based on human trials.",
  "full_text": "Generating Plausible Counterfactual Explanations for\nDeep Transformers in Financial Text Classiﬁcation\nLinyi Yang1, Eoin M. Kenny1, Tin Lok James Ng2, Yi Yang3, Barry Smyth1, and Ruihai Dong1\n1Insight Centre ,University College Dublin, Ireland\n1{first.last}@insight-centre.org\n2University of Wollongong, Australia\n2jamesng@uow.edu.au\n3The Hong Kong University of Science and Technology, Hong Kong, China\n3imyiyang@ust.hk\nAbstract\nCorporate mergers and acquisitions (M&A) account for billions of dollars of investment globally\nevery year, and offer an interesting and challenging domain for artiﬁcial intelligence. However,\nin these highly sensitive domains, it is crucial to not only have a highly robust and accurate\nmodel, but be able to generate useful explanations to garner a user’s trust in the automated sys-\ntem. Regrettably, the recent research regarding eXplainable AI (XAI) in ﬁnancial text classiﬁ-\ncation has received little to no attention, and many current methods for generating textual-based\nexplanations result in highly implausible explanations, which damage a user’s trust in the sys-\ntem. To address these issues, this paper proposes a novel methodology for producing plausible\ncounterfactual explanations, whilst exploring the regularization beneﬁts of adversarial training\non language models in the domain of FinTech. Exhaustive quantitative experiments demonstrate\nthat not only does this approach improve the model accuracy when compared to the current state-\nof-the-art and human performance, but it also generates counterfactual explanations which are\nsigniﬁcantly more plausible based on human trials.\n1 Introduction and Related Work\nIn recent years, large-scale, pre-trained transformer models have led to massive improvements on a wide\nrange of natural language processing (NLP) tasks (Devlin et al., 2018; Liu et al., 2019), including ﬁnan-\ncial technology applications (Duan et al., 2018; Yang et al., 2018; Xing et al., 2019; Yang et al., 2020).\nHowever, this impressive ability also coincides with an inherent lack of robustness and transparency,\nwhich undermines human trust in the prediction outcome. In the highly sensitive (and ﬁnancially lu-\ncrative) area of FinTech, explainable ﬁnancial text classiﬁcation remains an open, and highly alluring\nquestion. To tackle this problem, this paper advances a novel approach which ﬁrst applies robust trans-\nformer models (by leveraging adversarial training) on a real-world, up-to-date, self-collected mergers\nand acquisitions (M&A) dataset, and then generating plausible, post-hoc, counterfactual explanations.\nIn the remainder of this section, we describe relevant work to both of these areas before detailing our\ncontributions.\n1.1 Artiﬁcial Intelligence in Mergers and Acquisitions\nM&As have reshaped the global business landscape for generations, and are having an accelerating\nimpact on the world’s economy as new technologies such as the internet, big data, and artiﬁcial intel-\nligence disrupt many business sectors (Yan et al., 2016). To appreciate this, a recent economic study\nprovided strong evidence that M&A deal rumours could inﬂuence the share price volatility of rumor\ntarget ﬁrms (Ma and Zhang, 2016). In particular, they showed that, on average, M&A rumors have a\npositive short term impact and a negative long term impact on the cumulative abnormal returns of the\npotential acquirers and targets. In the existing AI literature, focus here is typically on predicting likely\nM&A targets (Yan et al., 2016), and forecasting the likely success of M&A (Danbolt et al., 2016) for\ndeveloping high-risk/high-reward investment strategies based on M&A speculation (Ji and Jetley, 2009).\narXiv:2010.12512v1  [cs.CL]  23 Oct 2020\nWhile the existing literature typically focuses on predicting likely M&A acquirers and targets, in this\nwork we address a distinct but related task: namely, whether a merger and acquisition rumor is likely\ngoing to prove to be correct.\n1.2 Visualization-based Explanations\nTo interpret a model’s prediction, prior efforts have focused on either incorporatingpre-hoc analysis into\nthe experimental design (Brunner et al., 2020), or developing post-hoc analysis algorithms to select or\nmodify particular instances of the dataset to explain the behavior of models (Keane and Smyth, 2020;\nKenny and Keane, 2019). Recent research (Grimsley et al., 2020) shows that transformer models can\nnot be perfectly explained from their intrinsic architecture, and a further work (Brunner et al., 2020)\nprovides strong evidence that self-attention distributions are not directly interpretable. For this reason,\nmodel-agnostic, post-hoc explanation methods have come to the fore among these works for explaining\ntext classiﬁcation models, as they are easy to understand and do not require access to the data or the\nmodel (Keane and Smyth, 2020).\nTowards post-hoc explanation in NLP tasks, (Murdoch et al., 2018) proposes a popular way named\ncontextual decomposition (CD) to quantify the importance of each individual word/phrase by computing\nthe change to the model prediction when solely removing a word/phrase. Its hierarchical extensions\n(Singh et al., 2019; Jin et al., 2020) continue to reﬁne the explanation algorithms that calculate and\nfurther visualize the individual phrase’s importance. However, despite these visualization-based methods\n(Murdoch et al., 2018; Singh et al., 2019; Jin et al., 2020) having achieved good results on a popular\ndataset of sentiment analysis (namely the Stanford Sentiment Treebank-2 [SST-2] dataset where human\ncreate the ground truth with their subjective judgement), how to generate explanations in more complex\nscenarios where human performance is worse than a model have not been well studied. As a result, the\nprior lines of visualization-based works cannot provide a clear boundary between positive and negative\ninstances to human, whereas counterfactuals could provide “human-like” logic to show a modiﬁcation to\nthe input that makes a difference to the output classiﬁcation (Byrne, 2019). Hence, post-hoc, example-\nbased explanation methods have received more and more attention in recent years (Keane and Smyth,\n2020).\n1.3 Counterfactual Text Explanations\nCounterfactual explanations are renown for their explanatory ability in AI systems (Wachter et al., 2017);\nspeciﬁcally, they offer the ability to explain models (such as transformers) without having to “open the\nblack-box” (Grath et al., 2018), by conveying causal information about what contributed to a given\nclassiﬁcation. To understand counterfactuals in the context of text classiﬁcation, consider a sentiment\nclassiﬁcation task were a black-box model may classify “John loved the ﬁlm” with a positive sentiment,\nand explain the prediction counterfactually by presenting “John hated the ﬁlm”. Glossed, this latter\ntext is the AI explaining the prediction by saying “f the word love was replaced with the word hate,\nI would have thought it was a negative sentiment”. This allows us to understand the main reasoning\nprocess behind the classiﬁer in question, thus explaining the prediction causally. To understand the issue\nof counterfactual plausibility, consider that the previous explanation may also generate a counterfactual\nwhich reads “John not the ﬁlm”. This text may “ﬂip” the classiﬁcation to the counterfactual class, but it\nis grammatically implausible, and (arguably) very difﬁcult to contextualize. The reason this is important\nis because humans avoid creating counterfactuals which are far from a “possible world” (Wachter et\nal., 2017), and by extension wildly implausible (Byrne, 2019; Kenny and Keane, 2020). In response to\nthis, our work attempts to guarantee more grammatically plausible explanations, and does not rely on\nattention weights, nor is it constrained to a speciﬁc text domain.\nContributions and Paper Outline\n• We present a novel dataset to the interesting and challenging problem of artiﬁcial intelligence in\nM&A prediction.\n• To the best of our knowledge, the present work is the ﬁrst general approach to generate grammati-\ncally plausible counterfactual explanations for unstructured text classiﬁcation.\n• The primary technical contribution in this work is to generate grammatically plausible counterfac-\ntuals by replacing the most important words with the antonyms (REP-SCD) based on pre-trained\nlanguage models. Furthermore, two additional variants (removing/inserting works at the most im-\nportant place, namely RM-SCD and INS-SCD) are proposed to guarantee counterfactual genera-\ntions, albeit ones which are less plausible.\nThe remainder of this paper is organized as follows. Section 2 details our novel dataset and the pre-\nprocessing steps involved. Section 3 describes our adversarial training approach, with the sensitivity-\nbased method for counterfactual explanation generation. Exhaustive experiments (both quantitative and\nhuman-based) show clear improvements in our method over current state-of-the-art, both in regards to\nclassiﬁcation accuracy, and explanation quality (see Sections 4 and 5). Finally, the implications of this\nwork on XAI and future research is discussed.\n2 The Novel Mergers and Acquisitions Dataset\nDescription Number\n#Processed deal news total (2007-2019) 4,098\n#Train (2007-2014) 3,120\n#Validation (2015 - 2016) 478\n#Test (2017 - Aug 2019) 500\n#Unique companies and institutions 1,406\nTable 1: The description of our dataset\nFor this study we adopted a large-scale, up-to-date M&A dataset collected from Zephyr, a comprehen-\nsive database of deal data from the “real world”. The dataset1 contains 14,539 news articles or tweets on\nM&A events between January 1st 2007, and August 12th 2019. Each instance corresponds to a speciﬁc\neditorial M&A article which describes a possible deal between an acquirer and a target company (also\nincluding a few IPO rumours). Additionally, each datapoint also includes the deal outcome (see below),\nand the deal announcement data, if relevant. In this work, the deal outcome corresponds to the target\nclass, and the raw dataset contains the following outcome types: complete – a deal between the acquirer\nand target companies concluded successfully; rumour – no deal materialized between the acquirer and\ntarget company; pending – a desired deal between the acquirer and target company has been conﬁrmed,\nand at the time of data collection was deemed to be in-progress, but not yet complete; cancelled – a past\npotential deal between the acquirer and target companies has been conﬁrmed, but it did not complete,\nand is no longer being pursued.\nIn order to prepare the raw dataset for use in this study, a number of pre-processing steps were carried\nout:\n1. In this work we chose to focus on a binary classiﬁcation task and, as such, removed instances with\noutcome types of cancelled and pending, leaving only those instances that correspond to completed\ndeals (the positive class) and rumours (the negative class).\n2. We eliminated instances where both acquiring and target companies were non-US, due to a tendency\ntowards low-quality data; in other words, all of the instances in our dataset include a US Listed\nCompany as either the acquirer or the target or both.\n3. Articles published within one day or after the deal announcement date were also removed, this\nis because our interest is in developing a prediction model that is capable of generating accurate\npredictions at least one day in advance of any deal outcome.\n1https://www.bvdinfo.com/en-gb/our-products/data/specialist/zephyr\n4. Finally, the remaining instances are randomly over-sampled to ensure an even split between positive\n(completed) and negative (rumours) instances for each year.\nThe result is a dataset of 4,098 instances (news articles and meta-data) which we split into training,\nvalidation, and testing sets on a year-by-year basis (see Table 1).\n3 Methodology\nThe pipeline of our method is shown in Fig. 1. First, as a prerequisite, a transformer variant is ﬁne-\ntuned on the M&A prediction task, alongside adversarial training (which as we shall see is shown to be\npromising in this domain). Second, important words in the test instances are identiﬁed using a sampled\ncontextual decomposition technique after the prediction. Third, a counterfactual explanation is generated\nby replacing these words withgrammatically plausible substitutes. As we shall see, although this method\ndoes not always guarantee a plausible counterfactual will be found, we propose two alternative methods\nwhich will, albeit with the possible trade-off of plausibility. These steps are detailed next.\n3.1 Step 1: Robust Transformer Classiﬁcation Models\nAs eluded to earlier, M&A prediction is a highly sensitive domain, and despite adversarial training\nshowing promise previously (Goodfellow et al., 2014; Tsipras et al., 2018), it has never been tested\nin this domain. Hence, to try ensure a robust model which can simultaneously generate intelligible\nexplanations, we explore its usage here compared to other popular approaches. Given a news article, we\nadopt the classical transformer architecture proposed by (Vaswani et al., 2017). The original multi-head\nself-attention is subsequently applied to the k-th document D(k), which is calculated as follows:\nMultiHead = Concat (head1,..., headh) WO (1)\nheadj = Attention (Q,K,V ) (2)\nQ= D(k)WQ\nj ,K = D(k)WK\nj ,V = D(k)WV\nj (3)\nwhere WQ\nj ,WK\nj ,WV\nj ∈Rd×d are weight metrics, and the attention is computed as:\nAttention (Q,K,V ) = softmax\n(QK⊤\n√\nd\n)\nV (4)\nfor input query, key and value matrices Q,K,V ∈Rn×d. The houtputs from the attention calculations\nare concatenated and transformed using an output weight matrix Wo ∈Rdh×d.\nAdditionally, the adversarial noise, treated as a form of regularization, is generated by the Fast Gra-\ndient Method (FGM) (Miyato et al., 2017) and Projected Gradient Descent (PGD) (Madry et al., 2018).\nThe idea of using adversarial perturbation is derived from the usage of adversarial attacks (Carlini and\nWagner, 2017) to evaluate the robustness of neural networks, while the recent advances of using the\nadversarial training in NLP models (Liu et al., 2020) inspires us to use it as a way of regularization. For\neach embedded word ein k-th news article D(k), the FGM computes its perturbation as follows:\nrfgm = ϵ·g/∥g∥2 where g= ∇eL(θ,(D(k),y)) (5)\nwhere rfgm is the perturbation of e, θ denotes the current values of the parameters of the classiﬁer,\nand Ldenotes the loss function (cross entropy) associated with the classiﬁer. The perturbation can be\neasily computed using back-propagation. The projected gradient descent, which can be considered as a\nmulti-step variant of the FGM, computes the perturbation of eiteratively:\net+1 = Πe+S\n(\net + αg\n(\nD(k)\nt\n)\n/\ng\n(\nD(k)\nt\n)\n2\n)\ng\n(\nD(k)\nt\n)\n= ∇eL\n(\nθ,(D(k)\nt ,y)\n) (6)\n… Stryker is buying US-based spinal \nimplant technology company K2M …\nOriginal\nSampled\n… First Mid-Illinois Bancshares is \nbuying SCB Bancorp in a USD \n70.40 million …\n… Archrock is buying out its master \nlimited partnership (MLP) …\n… The Texan company is buying\nCDM Resource Management …\n…\nTransformers\nCalculate the \nImportance \nWeights\nREP-SCD\nPositive Words\nDictionary\nNegative Words\nDictionary\nStryker is potentially buying \nUS-based spinal implant \ntechnology company K2M\nGenerating counterfactual explanation(s)\nStryker is considering US-\nbased spinal implant \ntechnology company K2M\nStryker is [UNK] US-based \nspinal implant technology \ncompany K2M\nCalculating the importance of the words (phrases)\nFine-tuned \nTransformer\nTransformers\nRM-SCD\nINS-SCD\nFigure 1: The pipeline of our methods, namely REP-SCD, RM-SCD, and INS-SCD. We show real examples of generating\ndiverse counterfactual instances that ﬂip the prediction result from completed to rumour. The original input has been changed\nby iteratively modifying words in order of their importance until the prediction matches the counterfactual class. The outputs\n(logits) of the predictions are represented in green, and orange points, respectively.\nwhere S =\n{\nr∈Rd : ∥r∥2 ≤ϵ\n}\nis the constraint space of the perturbation, Πe+S denotes the projec-\ntion of a vector onto the feasible set e+ S, and αis the step size. We use Adam optimizer with learning\nrate decay to train our model until convergence.\n3.2 Step 2: Context-Independent Word Importance\nTo calculate the context independent importance up to one word, we adopt the sensitivity of contextual\ndecomposition technique from (Madry et al., 2018) which removed part of inputs from the sequence text\nto evaluate a model’s sensitivity to them, thereby allowing for the identiﬁcation of important features.\nIn its hierarchical extensions – Sampling and Contextual Decomposition (SCD), (Jin et al., 2020) mask\nout the phrase p from the input while the max sequence length N is set to 40. However, the average\ninput length in our data is much larger than 40. We, therefore, propose a phrase-level removing method\nonly if the phrase starts with the negative pronouns or limitations. Otherwise, only a single word will be\nremoved. For example, in the sentence “the deal is not closing currently”, the attribution of “closing”\nshould be positive while the attribution of “not closing” should be negative. In this situation, we remove\nthe whole phrase “not closing” together to calculate the inﬂuence in terms of the logits change in the\noutput layer of the transformer and then assign the negative score to the word “closing”.\nGiven a phrase p starting with the negative limitations in the k-th document D(k), we sample the\ndocuments which contain the same phrase pto alleviate the inﬂuence by chance when there are multiple\nshreds of evidence saturating the prediction. For example, in the source “JPMorgan is closing in on\na deal, sources close to the situation are optimistic for deal completion”, if we only remove the word\n“closing”, the prediction would not be changed so much. In this sampling way, the proposed context-\nindependent importance of word and phrase is more robust to saturation. The formula for calculating the\nimportance can be written as:\nφ(p, ˆD(k)) = E ˆD(β)\n[\nl\n(ˆD(β); ˆD\n)\n−l\n(ˆD(β)\\p; ˆD\n)]\n(7)\nwhere D(β) denotes the resulting document after masking out a single token or a phrase starting with\nthe negative pronoun in the length ofNsurrounding the phrase p. we use l\n(ˆD(β)\\p; ˆD\n)\nto represent the\nmodel prediction logits after replacing the masked-out context. \\p indicates the operation of masking\nout the phrase pin a input ﬁle sampling from the testing set D.\nAs an aside, the resulting top 15 most inﬂuenced words are shown in Table 2. In total, there are\n123 positive words and 155 negative words in the dictionaries. We can see the average inﬂuence score\nof positive words (0.637) is higher than the negative words (0.385). It may reveal that positive words\nusually contain more powerful clues in predicting the M&A deal. That would be interesting to see which\nkind of words in the sources illustrate the deal is more likely to be completed in the future and which\nkind of words would be likely to kill the deal.\nAlgorithm 1 Plausible Counterfactual Instances Generation\nInput: Testing document example D(k)= {w1,w2,...,w n}, the corresponding ground truth label Y , pre-\ntrained Mask Language Model MLM, negative pronouns list NP, ﬁne-tuned transformer classiﬁer C.\nOutput: Positive Word Dictionaries POS, Negative Word Dictionaries NEG, Plausible counterfactual\nexample(s) D(k)\ncf = {D(k)\nREP−SCD,D(k)\nRM−SCD,...,D (k)\nINS−SCD}\n1: Initialization: D(k)\ncf ←D(k)\n2: for each word wi in in D(k) do\n3: if the prev word wi−1 is in NP then\n4: Creat the whole phrase npi by contextual decomposition\n5: Computer the importance score Pwi = −Pnp(i) via Eq.(7)\n6: else\n7: Computer the importance score Pwi via Eq.(7)\n8: end if\n9: end for\n10: Create dictionaries with words: WPOS; WNeg, alongside the word positions poswi sorted by the\ndescending order of their importance scores Pwi.\n11: for each word position posi in poswi do\n12: WPlausible ←MLM(D(k)\nmask wposi\n), W\n′\nPlausible ←MLM(D(k)\nmask wposi±1 )\n13: if Y(k) == POS then\n14: WCandidate, W\n′\nCandidate ←Intersection (WNEG and WPlausible), (WNEG and W\n′\nPlausible)\n15: else\n16: WCandidate, W\n′\nCandidate ←Intersection (WPOS and WPlausible), (WPOS and W\n′\nPlausible)\n17: end if\n18: D(k)\nrm ←D(k) wposi\n19: end for\n20: for each word wi,w\n′\ni in zip (WCandidate,W\n′\nCandidate) do\n21: D(k)\nins ←Insert w\n′\ni to D(k)\nmask wposi±1\n22: D(k)\nrep ←Replace wi with D(k)\nmask wposi\n23: if C(D(k)\nrm,D(k)\nins,D(k)\nrep) ̸= Y then\n24: Add D(k)\nrm,D(k)\nins,D(k)\nrep to the set D(k)\ncf\n25: end if\n26: end for\n27: return D(k)\ncf\n3.3 Step 3: Counterfactual Instance Generation\nAs shown in Algorithm 1, we summarize three different counterfactual generation methods, namely,\nthe primary technique which generates grammatically plausible counterfactuals (REP-SCD), and two\nfurther variants to guarantee counterfactual generation (RM-SCD and INS-SCD). We combine these\nthree methods to alleviate a major issue in counterfactual explanation, that is, there is no guarantee that\nfor a given example a counterfactual instance is found. Our main technique identiﬁes the most important\nword(s) in a test instance using SCD and replaces them with the intersection of grammatically plausible\nsubstitutes [using masked language model (MLM)] and words in the reverse emotional dictionary. The\nraw document contentD(k) itself is taken as input, and MLM outputsp(·|D(k)) for each masked position.\nAfter all masked positions are inﬁlled, we get the reconstructed document:\nˆD(k) = MLM(D(k)). (8)\nWe iterative repeat this operation at the most important word positions ranked by SCD until the recon-\nstructed document ultimately moves the model’s classiﬁcation towards the opposing class. Notably, there\nPositive Words Sensitivity Negative Words Sensitivity\nannounced 5.841 talks 4.674\nline 5.715 could 2.484\nannouncement 4.469 ﬂag 2.236\nagreement 3.378 diligence 1.363\nacquiring 3.342 considering 1.196\ncompletion 2.727 time 1.186\nagreed 2.429 may 1.085\nclosing 2.125 looking 0.983\nconsideration 1.994 this 0.972\nprevailed 1.639 when 0.914\nacquire 1.520 potentially 0.870\npaid 1.461 if 0.847\ndisclosed 1.403 intention 0.836\nselling 1.385 year 0.812\ncould 1.360 takeover 0.790\nTable 2: Top 15 most inﬂuenced words towards the M&A prediction. The inﬂuence score for each word is calculated and added\nup by Sampling and Contextual Decomposition (SCD) on the testing set.\nmay be more than one counterfactual explanation corresponding with the original text instance.\n4 Experiment 1: Financial Text Classiﬁcation with Robust Transformers\nIn this section we describe the results of a comprehensive evaluation of classiﬁcation accuracy, compar-\ning a variety of different classiﬁcation baselines (including a human baseline) to our adversarial trans-\nformer approach.\n4.1 Methods Used\nThe baselines used can be grouped into several distinct categories: human evaluations – traditional ma-\nchine learning approaches (SVM) – classical deep learning approaches (CNN (Kim, 2014), BiGRU (Bah-\ndanau et al., 2014) , and HAN (Yang et al., 2016)) – and various transformer approaches with/without\npruning strategies. These transformer-based models are generally considered to provide the current state-\nof-the-art in text classiﬁcation. We reproduce these baselines based on the Transformers.2\nAcquiring a human baseline As a baseline, we asked 26 participants which were experts in economics\nand ﬁnance to predict M&A events by completing 50 M&A evaluation questionnaires. The participants\nconsisted of Ph.D. students, and academics from the ﬁelds of economics/ﬁnance. All participants were\neither native English speakers or had a high degree of English competence. Each questionnaire provided\ninformation on ten M&A cases/instances, sampled randomly without replacement from the test set. In\naddition, the news articles available in the dataset that were published before the deal announcement\nwere also provided. The questionnaire asked the participant to predict the outcome of the deal (complete\nor rumour), and to state their conﬁdence in this prediction.\n4.2 Classiﬁcation Results\nIn line with best practice, model hyper-parameters are tuned using the validation set. In particular, the\nmaximum sequence length is set as 256, and the size of transformers are all set as large. All experiments\nare using the conventional Matthews Correlation Coefﬁcient (MCC), accuracy and F1 metrics. The\nclassiﬁcation results are summarized in Table 3 with Random Guess used to provide a lower-baseline\nbased on chance. While the human evaluators performed better than chance their ability to predict deal\noutcomes is limited when compared to the more sophisticated machine models that follow. These results\nare particularly compelling as the human evaluators had considerable domain expertize.\n2https://github.com/huggingface/pytorch-transformers\nEvaluation MCC Accuracy F1 Evaluation MCC Accuracy F1\nBaselines Transformers\nRandom Guess 0.013 0.510 0.462 ALBERT 0.768 0.882 0.879\nHuman Evaluation 0.307 0.640 0.672 +Ad. 0.780 0.890 0.888\nTraditional ML DistilBERT 0.750 0.874 0.877\nSVM(TF-IDF) 0.701 0.816 0.816 +Ad. 0.784 0.890 0.891\nClassical DL BERT-WWM 0.751 0.874 0.879\nCNN-Text 0.729 0.848 0.847 +Ad. 0.788 0.894 0.894\nBiGRU 0.734 0.836 0.849 RoBERTa 0.780 0.892 0.888\nHAN 0.742 0.848 0.853 +Ad. 0.788 0.894 0.895\nTable 3: Evaluations performed by human, machine learning, deep learning, and transformer-based models, alongside the\nablation study for adversarial training (indicate as +Ad.). The scores in bold and italics indicate the best performance across all\napproaches.\nEach of the machine learning approaches offer substantial improvements over the human evaluators\nand a clear separation can be seen between traditional machine learning (with MCC scores in low 0.7\nrange/F1 scores in the low 0.8 range), classical deep learners (with MCC scores in the range 0.73-0.74/F1\nscores in the range 0.84-0.85), and recent transformer-based models (MCC>0.75/F1>0.87).\nWe further evaluate the relative inﬂuence of the adversarial perturbation to test the robustness of the\nmodels. We ﬁnd that all variants of the transformer (Lan et al., 2019; Sanh et al., 2019) beneﬁt from the\nadversarial perturbation during the training process in terms of the prediction results in the practice. For\nexploring the reason why the optimal transformer classiﬁer can outperform the human test a lot – 39%,\nwe take the best performed model – RoBERTa (Liu et al., 2019) with adversarial training as our optimal\nclassiﬁer in the following experiments for generating the plausible counterfactual explanations.\n5 Experiment 2: Generating Plausible Counterfactual Explanations\nInterpretability is an increasingly important property for many deep learning techniques, including com-\nputer vision and natural language processing (Kenny and Keane, 2019), especially in critical tasks such as\nﬁnancial text classiﬁcation; high-value investment decisions demand a reasonable level of interpretabil-\nity if investors are to trust the predictions that come for a system such as the one described in this work.\nIn this section, we describe the qualitative analysis for each of our methods. Subsequently, we show the\nevaluation of user studies compared to the existing example-based explanation methods.\n5.1 Qualitative Analysis for the Resulting Counterfactual Instances\nIn qualitative analysis, we identiﬁed ﬁve typical patterns among the generated counterfactual instances\nas shown in Table 4 where we highlight the changing parts. Based on the 500 testing examples, we\nguarantee that there is at least one counterfactual instance corresponding with the original input. We\ngain insight into which aspects are causally relevant by comparing the original context to the revised\ncontext which can ﬂip the classiﬁer’s prediction.\n5.2 Human Evaluation for the Explanation\nWe implement interpretation experiments on the optimal ﬁne-tuned transformer classiﬁer. While an ex-\nplainable model trained with supervised learning is a common method to interpret the results of text\nclassiﬁcation (Wallace et al., 2019), the self-supervised learning explainable frameworks have been\nscarcely found. Meanwhile, the work in (Kaushik et al., 2020) consider similar types of edits to\ngenerate counterfactually-revised data, however, all of the instances are generated by human which\ngreatly limits the expansibility of the method. To comprehensively evaluate the performance of our\nmethod, we consider a state-of-the-art example-based explanation framework for comparison, namely\nHotFlip (Ebrahimi et al., 2017), which uses gradients to identify important words and then ﬂip it with\nthe adversarial word which can cause the maximum change in gradients.\nTypes of Algorithms Examples\nOri: Professional vacation services provider ILG is consider-\ning a merger with Diamond Resorts International...REP-SCD:\nReplacing with the certainty word Rev: Professional vacation services provider ILG is announc-\ning a merger with Diamond Resorts International...\nOri: Vivendi is in early discussions to sell a 10.0 per cent stake\nin Universal Music Group (UMG) to Tencent for roughly EUR\n3.00 billion... REP-SCD:\nChanging the deal value Rev: Vivendi is in early discussions to sell a 10.0 per cent stake\nin Universal Music Group (UMG) to Tencent for roughly EUR\n3.00 million\nOri: Stryker is buying US-based spinal implant technology\ncompany K2M Group Holdings for USD 1.40 billion in cashINS-SCD:\nRecasting fact as hopedfor Rev: Stryker is potentially buying US-based spinal implant\ntechnology company K2M Group Holdings for USD 1.40 bil-\nlion in cash\nOri: WPP has conﬁrmed the recent speculation that it has en-\ntered into exclusive negotiations with private equity ﬁrm Bain\nCapital... INS-SCD:\nInserting the negative word Rev: WPP has not conﬁrmed the recent speculation that it\nhas entered into exclusive negotiations with private equity ﬁrm\nBain Capital...\nOri: This suitor is the Namdar and Washington Prime consor-\ntium, the insiders noted, adding that there can be no certainty\na deal will complete... RM-SCD:\nRemoving the negative limitation(s) Rev: This suitor is the Namdar and Washington Prime consor-\ntium, the insiders noted, adding that there can be certainty a\ndeal will complete...\nTable 4: Most prominent categories of counterfactual explanations generated by our algorithms, namely RM-SCD, REP-SCD,\nand INS-SCD for M&A Predictions. Ori and Rev are short for original and revised instances, respectively.\nFor user evaluation, here we ask domain experts in ﬁnance to rate our explanations on two aspects,\n(1) how plausible (mainly in terms of grammar and comprehension) it is, and (2) how reasonable it is\n(i.e., does the explanation make sense). We compare our method to Hotﬂip - the current state-of-the-art\nframework for counterfactual explanation - at the time of writing. Each score is measured on a scale of\n1-5, where 5 is the best, and 1 is the worst. We randomly sample 100 examples from the testing set for\n5 participants to answer (20 examples per person). By combining the REP-SCD, RM-SCD, INS-SCD\ntogether, our method achieves signiﬁcantly higher ranking score compared to HotFlip, more speciﬁcally,\n2.35 score improvements (4.35/2.00) were made regarding plausibility while 0.85 score improvements\n(4.00/3.15) were made on reasonableness, showing a p-value less than 0.001 and 0.05, respectively.\nHence, there is compelling evidence that our method can generate counterfactual explanations which are\nmore plausible and reasonable.\n6 Conclusion and Future Work\nIn this work, we pursued a new research problem of M&A prediction. Our transformer-based clas-\nsiﬁer leveraged the regularization beneﬁts of adversarial training to enhance model robustness. More\nimportantly, we built upon previous techniques to quantify the importance of words and help guaran-\ntee the generation of plausible counterfactual explanations with a masked language model in ﬁnancial\ntext classiﬁcation. The results demonstrate superior accuracy and explanatory performance compared to\nstate-of-the-art techniques. An obvious extension would be to include canceled deals into the classiﬁer,\nor to predict novel M&A events based on market descriptions of companies (e.g., scale, ﬁnances, and\ntarget markets). Moreover, additional ﬁnancial events (e.g., misstatement detection and earnings call\nanalysis) is yet another related task to be considered for further research.\nAcknowledgment\nWe would like to thank Tianhao Fu, Yimeng Li, Yang Xu and Prof. Mark Keane for their helpful\nadvice and discussion during this work. Also, we would like to thank the anonymous reviewers for their\ninsightful comments and suggestions to help improve the paper. This research was supported by Science\nFoundation Ireland (SFI) under Grant Number SFI/12/RC/2289 2.\nReferences\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to\nalign and translate. arXiv preprint arXiv:1409.0473.\nGino Brunner, Yang Liu, Damian Pascual, Oliver Richter, Massimiliano Ciaramita, and Roger Wattenhofer. 2020.\nOn identiﬁability in transformers. In Proceedings of the International Conference on Learning Representations\n(ICLR).\nRuth MJ Byrne. 2019. Counterfactuals in explainable artiﬁcial intelligence (xai): evidence from human reasoning.\nIn Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19, pages\n6276–6282.\nNicholas Carlini and David Wagner. 2017. Towards evaluating the robustness of neural networks. In 2017 ieee\nsymposium on security and privacy (sp), pages 39–57. IEEE.\nJo Danbolt, Antonios Siganos, and Abongeh Tunyi. 2016. Abnormal returns from takeover prediction modelling:\nChallenges and suggested investment strategies. Journal of Business Finance & Accounting, 43(1-2):66–97.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirec-\ntional transformers for language understanding. arXiv preprint arXiv:1810.04805.\nJunwen Duan, Yue Zhang, Xiao Ding, Ching Yun Chang, and Ting Liu. 2018. Learning target-speciﬁc repre-\nsentations of ﬁnancial news documents for cumulative abnormal return prediction. In Proceedings of the 27th\nInternational Conference on Computational Linguistics (COLING-18), pages 2823–2833.\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. 2017. Hotﬂip: White-box adversarial examples for text\nclassiﬁcation. arXiv preprint arXiv:1712.06751.\nIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples.\narXiv preprint arXiv:1412.6572.\nRory Mc Grath, Luca Costabello, Chan Le Van, Paul Sweeney, Farbod Kamiab, Zhao Shen, and Freddy\nLecue. 2018. Interpretable credit application predictions with counterfactual explanations. arXiv preprint\narXiv:1811.05245.\nChristopher Grimsley, Elijah Mayﬁeld, and Julia RS Bursten. 2020. Why attention is not explanation: Surgical\nintervention and causal reasoning about neural models. In Proceedings of The 12th Language Resources and\nEvaluation Conference, pages 1780–1790.\nXinyu Ji and Gaurav Jetley. 2009. The shrinking merger arbitrage spread: Reasons and implications. Financial\nAnalysts Journal, 66, 03.\nXisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, and Xiang Ren. 2020. Towards hierarchical importance at-\ntribution: Explaining compositional semantics for neural sequence models. In Proceedings of the International\nConference on Learning Representations (ICLR).\nDivyansh Kaushik, Eduard Hovy, and Zachary C Lipton. 2020. Learning the difference that makes a difference\nwith counterfactually-augmented data. In Proceedings of the International Conference on Learning Represen-\ntations (ICLR).\nMark T Keane and Barry Smyth. 2020. Good counterfactuals and where to ﬁnd them: A case-based technique\nfor generating counterfactuals for explainable ai (xai). In International Conference on Case-Based Reasoning\n(ICCBR).\nEoin M Kenny and Mark T Keane. 2019. Twin-systems to explain artiﬁcial neural networks using case-based\nreasoning: comparative tests of feature-weighting methods in ann-cbr twins for xai. In Proceedings of the 28th\nInternational Joint Conference on Artiﬁcial Intelligence, pages 2708–2715. AAAI Press.\nEoin M Kenny and Mark T Keane. 2020. On generating plausible counterfactual and semi-factual explanations\nfor deep learning. arXiv preprint arXiv:2009.06399.\nYoon Kim. 2014. Convolutional neural networks for sentence classiﬁcation. In Proceedings of the 2014 Confer-\nence on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2019.\nAlbert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke\nZettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv\npreprint arXiv:1907.11692.\nXiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, and Jianfeng Gao. 2020.\nAdversarial training for large neural language models. arXiv preprint arXiv:2004.08994.\nMatthew Ma and Feng Zhang. 2016. Investor reaction to merger and acquisition rumors. SSRN 2813401.\nAleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. 2018. Towards\ndeep learning models resistant to adversarial attacks. In Proceedings of the International Conference on Learn-\ning Representations (ICLR).\nTakeru Miyato, Andrew M Dai, and Ian Goodfellow. 2017. Adversarial training methods for semi-supervised text\nclassiﬁcation. In Proceedings of the International Conference on Learning Representations (ICLR).\nW. James Murdoch, Peter J. Liu, and Bin Yu. 2018. Beyond word importance: Contextual decomposition to\nextract interactions from LSTMs. In Proceedings of the International Conference on Learning Representations\n(ICLR).\nVictor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. Distilbert, a distilled version of bert:\nsmaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108.\nChandan Singh, W. James Murdoch, and Bin Yu. 2019. Hierarchical interpretations for neural network predictions.\nIn Proceedings of the International Conference on Learning Representations (ICLR).\nDimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry. 2018. Robust-\nness may be at odds with accuracy. In International Conference on Learning Representations.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and\nIllia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems, pages\n5998–6008.\nSandra Wachter, Brent Mittelstadt, and Chris Russell. 2017. Counterfactual explanations without opening the\nblack box: Automated decisions and the gdpr. Harv. JL & Tech., 31:841.\nEric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt Gardner, and Sameer Singh. 2019. Allennlp\ninterpret: A framework for explaining predictions of nlp models. arXiv preprint arXiv:1909.09251.\nFrank Z Xing, Erik Cambria, and Yue Zhang. 2019. Sentiment-aware volatility forecasting. Knowledge-Based\nSystems, 176:68–76.\nJunchi Yan, Shuai Xiao, Changsheng Li, Bo Jin, Xiangfeng Wang, Bin Ke, Xiaokang Yang, and Hongyuan Zha.\n2016. Modeling contagious merger and acquisition via point processes with a proﬁle regression prior. In\nInternational Joint Conferences on Artiﬁcal Intelligence, IJCAI-16, pages 2690–2696.\nZichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, and Eduard Hovy. 2016. Hierarchical attention\nnetworks for document classiﬁcation. In Proceedings of the 2016 conference of the North American chapter of\nthe association for computational linguistics: human language technologies, NAACL-16, pages 1480–1489.\nLinyi Yang, Zheng Zhang, Su Xiong, Lirui Wei, James Ng, Lina Xu, and Ruihai Dong. 2018. Explainable text-\ndriven neural network for stock prediction. In 2018 5th IEEE International Conference on Cloud Computing\nand Intelligence Systems (CCIS), pages 441–445. IEEE.\nLinyi Yang, Tin Lok James Ng, Barry Smyth, and Ruihai Dong. 2020. Html: Hierarchical transformer-based\nmulti-task learning for volatility prediction. In Proceedings of The Web Conference 2020 , WWW ’20, page\n441–451.",
  "topic": "Counterfactual thinking",
  "concepts": [
    {
      "name": "Counterfactual thinking",
      "score": 0.9525167942047119
    },
    {
      "name": "Computer science",
      "score": 0.6248632669448853
    },
    {
      "name": "Adversarial system",
      "score": 0.6031600832939148
    },
    {
      "name": "Regularization (linguistics)",
      "score": 0.523981511592865
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4957917630672455
    },
    {
      "name": "Transformer",
      "score": 0.43502679467201233
    },
    {
      "name": "Comprehension",
      "score": 0.4283284544944763
    },
    {
      "name": "Machine learning",
      "score": 0.3537963628768921
    },
    {
      "name": "Data science",
      "score": 0.3260895013809204
    },
    {
      "name": "Psychology",
      "score": 0.19165176153182983
    },
    {
      "name": "Social psychology",
      "score": 0.07726764678955078
    },
    {
      "name": "Engineering",
      "score": 0.07236671447753906
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}