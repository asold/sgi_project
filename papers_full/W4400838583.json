{
  "title": "Performance of three artificial intelligence (AI)‐based large language models in standardized testing; implications for AI‐assisted dental education",
  "url": "https://openalex.org/W4400838583",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3210489917",
      "name": "Hamoun Sabri",
      "affiliations": [
        "University of Michigan–Ann Arbor",
        "Center for Clinical Research (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A2780623643",
      "name": "Muhammad H A Saleh",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A3134516411",
      "name": "Parham Hazrati",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": null,
      "name": "Keith Merchant",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2085626826",
      "name": "Jonathan Misch",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2171304315",
      "name": "Purnima S. Kumar",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2498964769",
      "name": "Hom-Lay Wang",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2804251468",
      "name": "Shayan Barootchi",
      "affiliations": [
        "Center for Clinical Research (United States)",
        "University of Michigan–Ann Arbor",
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A3210489917",
      "name": "Hamoun Sabri",
      "affiliations": [
        "Center for Clinical Research (United States)",
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2780623643",
      "name": "Muhammad H A Saleh",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A3134516411",
      "name": "Parham Hazrati",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": null,
      "name": "Keith Merchant",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2085626826",
      "name": "Jonathan Misch",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2171304315",
      "name": "Purnima S. Kumar",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2498964769",
      "name": "Hom-Lay Wang",
      "affiliations": [
        "University of Michigan–Ann Arbor"
      ]
    },
    {
      "id": "https://openalex.org/A2804251468",
      "name": "Shayan Barootchi",
      "affiliations": [
        "Center for Clinical Research (United States)",
        "University of Michigan–Ann Arbor",
        "Harvard University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2891432758",
    "https://openalex.org/W3200742808",
    "https://openalex.org/W4225565714",
    "https://openalex.org/W4384484700",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4367188881",
    "https://openalex.org/W4385380523",
    "https://openalex.org/W4380360936",
    "https://openalex.org/W4385620388",
    "https://openalex.org/W4385620111",
    "https://openalex.org/W4323035111",
    "https://openalex.org/W4383959108",
    "https://openalex.org/W4324130227",
    "https://openalex.org/W4386457251",
    "https://openalex.org/W4368360859",
    "https://openalex.org/W4383872904",
    "https://openalex.org/W4384824014",
    "https://openalex.org/W4394817701",
    "https://openalex.org/W4360620450",
    "https://openalex.org/W4380887490",
    "https://openalex.org/W4380291159",
    "https://openalex.org/W4380423243",
    "https://openalex.org/W4381469233",
    "https://openalex.org/W4380685958",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4386448461",
    "https://openalex.org/W4386460012",
    "https://openalex.org/W4390701140",
    "https://openalex.org/W4391466322",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4292779060"
  ],
  "abstract": "Abstract Introduction The emerging rise in novel computer technologies and automated data analytics has the potential to change the course of dental education. In line with our long‐term goal of harnessing the power of AI to augment didactic teaching, the objective of this study was to quantify and compare the accuracy of responses provided by ChatGPT (GPT‐4 and GPT‐3.5) and Google Gemini, the three primary large language models (LLMs), to human graduate students (control group) to the annual in‐service examination questions posed by the American Academy of Periodontology (AAP). Methods Under a comparative cross‐sectional study design, a corpus of 1312 questions from the annual in‐service examination of AAP administered between 2020 and 2023 were presented to the LLMs. Their responses were analyzed using chi‐square tests, and the performance was juxtaposed to the scores of periodontal residents from corresponding years, as the human control group. Additionally, two sub‐analyses were performed: one on the performance of the LLMs on each section of the exam; and in answering the most difficult questions. Results ChatGPT‐4 (total average: 79.57%) outperformed all human control groups as well as GPT‐3.5 and Google Gemini in all exam years ( p &lt; .001). This chatbot showed an accuracy range between 78.80% and 80.98% across the various exam years. Gemini consistently recorded superior performance with scores of 70.65% ( p = .01), 73.29% ( p = .02), 75.73% ( p &lt; .01), and 72.18% ( p = .0008) for the exams from 2020 to 2023 compared to ChatGPT‐3.5, which achieved 62.5%, 68.24%, 69.83%, and 59.27% respectively. Google Gemini (72.86%) surpassed the average scores achieved by first‐ (63.48% ± 31.67) and second‐year residents (66.25% ± 31.61) when all exam years combined. However, it could not surpass that of third‐year residents (69.06% ± 30.45). Conclusions Within the confines of this analysis, ChatGPT‐4 exhibited a robust capability in answering AAP in‐service exam questions in terms of accuracy and reliability while Gemini and ChatGPT‐3.5 showed a weaker performance. These findings underscore the potential of deploying LLMs as an educational tool in periodontics and oral implantology domains. However, the current limitations of these models such as inability to effectively process image‐based inquiries, the propensity for generating inconsistent responses to the same prompts, and achieving high (80% by GPT‐4) but not absolute accuracy rates should be considered. An objective comparison of their capability versus their capacity is required to further develop this field of study.",
  "full_text": null,
  "topic": "Dental education",
  "concepts": [
    {
      "name": "Dental education",
      "score": 0.5226766467094421
    },
    {
      "name": "Medical education",
      "score": 0.482596755027771
    },
    {
      "name": "Medicine",
      "score": 0.39071738719940186
    },
    {
      "name": "Psychology",
      "score": 0.3873107433319092
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3528136610984802
    },
    {
      "name": "Computer science",
      "score": 0.2700870931148529
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I27837315",
      "name": "University of Michigan",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I136199984",
      "name": "Harvard University",
      "country": "US"
    }
  ],
  "cited_by": 33
}