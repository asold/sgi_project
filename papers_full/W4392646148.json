{
  "title": "What Should a Robot Do? Comparing Human and Large Language Model Recommendations for Robot Deception",
  "url": "https://openalex.org/W4392646148",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2610700120",
      "name": "Kantwon Rogers",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4323588357",
      "name": "Reiden John Allen Webber",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A5094111586",
      "name": "Geronimo Gorostiaga Zubizarreta",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A4365354933",
      "name": "Arthur Melo Cruz",
      "affiliations": [
        "Pennsylvania State University"
      ]
    },
    {
      "id": "https://openalex.org/A2950611888",
      "name": "Shengkang Chen",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A326359912",
      "name": "Ronald C. Arkin",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2119815229",
      "name": "Jason Borenstein",
      "affiliations": [
        "Georgia Institute of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2096881164",
      "name": "Alan R. Wagner",
      "affiliations": [
        "Pennsylvania State University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4223649245",
    "https://openalex.org/W4283163904",
    "https://openalex.org/W4309674289",
    "https://openalex.org/W3210424426",
    "https://openalex.org/W4386041250",
    "https://openalex.org/W4210739840",
    "https://openalex.org/W2142121158",
    "https://openalex.org/W1969658910",
    "https://openalex.org/W2764192991",
    "https://openalex.org/W4380993732"
  ],
  "abstract": "This study compares human ethical judgments with Large Language Models (LLMs) on robotic deception in various scenarios. Surveying human participants and querying LLMs, we presented ethical dilemmas in high-risk and low-risk contexts. Findings reveal alignment between humans and LLMs in high-risk scenarios, prioritizing safety, but notable divergences in low-risk situations, reflecting challenges in AI development to accurately capture human social nuances and moral expectations.",
  "full_text": null,
  "topic": "Deception",
  "concepts": [
    {
      "name": "Deception",
      "score": 0.8528071045875549
    },
    {
      "name": "Humanâ€“robot interaction",
      "score": 0.5042058229446411
    },
    {
      "name": "Robot",
      "score": 0.5002453327178955
    },
    {
      "name": "Psychology",
      "score": 0.4651506841182709
    },
    {
      "name": "Computer science",
      "score": 0.37323620915412903
    },
    {
      "name": "Social psychology",
      "score": 0.37171441316604614
    },
    {
      "name": "Artificial intelligence",
      "score": 0.27209028601646423
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I130701444",
      "name": "Georgia Institute of Technology",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I130769515",
      "name": "Pennsylvania State University",
      "country": "US"
    }
  ]
}