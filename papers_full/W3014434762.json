{
    "title": "Conversational Question Reformulation via Sequence-to-Sequence Architectures and Pretrained Language Models",
    "url": "https://openalex.org/W3014434762",
    "year": 2022,
    "authors": [
        {
            "id": "https://openalex.org/A4202145230",
            "name": "Lin, Sheng-Chieh",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4221612662",
            "name": "Yang, Jheng-Hong",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4221795652",
            "name": "Nogueira, Rodrigo",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2232020161",
            "name": "Tsai, Ming-Feng",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4301488538",
            "name": "Wang, Chuan-Ju",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2672090663",
            "name": "Lin, Jimmy",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2590822507",
        "https://openalex.org/W2888302696",
        "https://openalex.org/W2962776342",
        "https://openalex.org/W2981852735",
        "https://openalex.org/W2896342318",
        "https://openalex.org/W2891176389",
        "https://openalex.org/W2890961898",
        "https://openalex.org/W2810840719",
        "https://openalex.org/W2970996870",
        "https://openalex.org/W3105690102",
        "https://openalex.org/W2786171444",
        "https://openalex.org/W2963963993",
        "https://openalex.org/W2788517680",
        "https://openalex.org/W2551396370",
        "https://openalex.org/W2962770891",
        "https://openalex.org/W2963403868",
        "https://openalex.org/W2964223283",
        "https://openalex.org/W2963323070",
        "https://openalex.org/W2971274815",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2949888546",
        "https://openalex.org/W2734823783"
    ],
    "abstract": "This paper presents an empirical study of conversational question reformulation (CQR) with sequence-to-sequence architectures and pretrained language models (PLMs). We leverage PLMs to address the strong token-to-token independence assumption made in the common objective, maximum likelihood estimation, for the CQR task. In CQR benchmarks of task-oriented dialogue systems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset as an in-domain task and validate the models using data from the TREC 2019 CAsT Track as an out-domain task. Examining a variety of architectures with different numbers of parameters, we demonstrate that the recent text-to-text transfer transformer (T5) achieves the best results both on CANARD and CAsT with fewer parameters, compared to similar transformer architectures.",
    "full_text": "Conversational Question Reformulation via Sequence-to-Sequence\nArchitectures and Pretrained Language Models\nSheng-Chieh Lin∗1, Jheng-Hong Yang∗1, Rodrigo Nogueira2,\nMing-Feng Tsai1, Chuan-Ju Wang1 and Jimmy Lin2\n1Research Center for Information Technology Innovation, Academia Sinica\n2David R. Cheriton School of Computer Science, University of Waterloo\nAbstract\nThis paper presents an empirical study of\nconversational question reformulation (CQR)\nwith sequence-to-sequence architectures and\npretrained language models (PLMs). We lever-\nage PLMs to address the strong token-to-token\nindependence assumption made in the com-\nmon objective, maximum likelihood estima-\ntion, for the CQR task. In CQR benchmarks\nof task-oriented dialogue systems, we evaluate\nﬁne-tuned PLMs on the recently-introduced\nCANARD dataset as an in-domain task and\nvalidate the models using data from the TREC\n2019 CAsT Track as an out-domain task. Ex-\namining a variety of architectures with dif-\nferent numbers of parameters, we demon-\nstrate that the recent text-to-text transfer trans-\nformer (T5) achieves the best results both on\nCANARD and CAsT with fewer parameters,\ncompared to similar transformer architectures.\n1 Introduction\nNatural-language dialogue capabilities play an es-\nsential role as an enabling technology in intelligent\npersonal assistants to understand and connect peo-\nple (Gao et al., 2018). Effective dialogue systems\nrequire many components, including natural lan-\nguage understanding, dialogue state tracking, and\nnatural language generation (Zhao and Eskenazi,\n2016). Of late, practitioners in industry (Ren et al.,\n2018) and researchers in academia (Elgohary et al.,\n2019) have made substantial progress in a variety\nof methods to improve end-to-end task-oriented\ndialogue systems.\nDue to the complex and nuanced nature of hu-\nman communication, conversations often contain\nutterances that include coreference, ellipsis, and\nother phenomena; thus, a good dialogue system\nshould be able to resolve these ambiguities to ac-\ncurately reconstruct the user’s original intent. We\n∗Contributed equally.\nWhat happe\nned 1983in What happe\nned to Vissi 1983inAnna\nVissiAnna to\nWhat happe\nned 1983in What happe\nned to Vissi 1983inAnna\nVissiAnna to\nRewritten questionOriginal question\n(a) Independence assumption of maximum likelihood estimation\n(b) Pretrained language model (dashed lines) to augment maximum likelihood estimation\nContext\nFigure 1: Conversational question reformulation.\npresent an example from Elgohary et al. (2019)\nin Figure 1 to illustrate the task of conversational\nquestion reformulation (CQR).\nHowever, as we can observe from Figure 1(a),\napplying maximum likelihood estimation (MLE)\npurely based on human-rewritten sentences intro-\nduces a strong independence assumption that does\nnot consider conversation dependencies or linguis-\ntic structure. Thanks to great progress made by\nlanguage models pretrained on large corpora using\nself-supervised learning objectives (Devlin et al.,\n2018; Radford et al., 2018; Dong et al., 2019;\nRaffel et al., 2019), there are now many mod-\nels equipped with knowledge of various language\nstructures extracted from human-generated texts.\nWe can leverage these models to relax the indepen-\ndence assumption in a pure MLE objective, shown\nin Figure 1(b).\nWe list the contributions of this work as follows:\n•We conduct, to our knowledge, the ﬁrst empiri-\ncal study leveraging pretrained language models\nto relax the independence assumption made in\nusing an MLE objective in a CQR task.\n•We achieve the state of the art in terms of BLEU\non two CQR benchmarks of task-oriented dia-\nlogue systems: (a) conversational open-domain\narXiv:2004.01909v1  [cs.CL]  4 Apr 2020\nquestion answering with CANARD and (b) con-\nversational search with TREC CAsT.\nIn summary, this work demonstrates a simple yet\neffective way to resolve coreference and ellipsis\nin a CQR task by leveraging pretrained language\nmodels. Furthermore, among representative mod-\nels, we ﬁnd that a well-tuned text-to-text transfer\ntransformer (T5) reaches performance that is on par\nwith humans on the in-domain CANARD dataset\nand achieves the best performance on the out-of-\ndomain CAsT dataset.\n2 Related Work\nConversational search(Radlinski and Craswell,\n2017) covers a broad range of techniques that facil-\nitate an IR task in a conversational context: nat-\nural language interactions, cumulative clariﬁca-\ntion (Aliannejadi et al., 2019), feedback collection,\nand information needs proﬁling during conversa-\ntions. CQR is an important component of conver-\nsational search systems. In order to resolve users’\ninformation needs to retrieve relevant answers, a\nCQR module that leverages pretrained models is a\npromising approach, compared to alternatives that\ntrack dialogue states based on “cheap” but noisy\nimplicit feedback from users (Ahmad et al., 2018,\n2019) or “expensive” but sparse judgments (Jeffrey\net al., 2019).\nOpen-domain question answering (QA) sys-\ntems return answers in response to user questions,\nboth in natural language, from a broad range of\ndomains (Sun et al., 2018). With great progress\ncoming from contributions by the NLP and IR com-\nmunities, high quality datasets for single-turn (Ra-\njpurkar et al., 2018; Koˇcisk´y et al., 2018; Dhingra\net al., 2017) and multi-turn (conversational) (Reddy\net al., 2019; Choi et al., 2018) open-domain QA\nare available today. These datasets have led to\nmany successful supervised techniques for various\ntasks (Chen et al., 2017; Seo et al., 2017; Huang\net al., 2019).\nRecently, to improve dialogue understanding, re-\nsearchers have proposed collecting annotations on\nresolving multi-turn dialogues in the context of\nquestion answering tasks (Ren et al., 2018; Elgo-\nhary et al., 2019). Building on this line of thought,\nour work addresses the problem of modeling ques-\ntion rewrites in multi-turn dialogues, especially in\nthe context of open-domain conversational QA.\n3 Conversational Question\nReformulation\n3.1 Problem Formulation\nWe ﬁrst formally deﬁne the conversational ques-\ntion reformulation (CQR) task, which is also called\nquestion de-contextualization (Elgohary et al.,\n2019) or conversational question (query) under-\nstanding in the context of task-oriented dialogue\nsystems (Ren et al., 2018). Consider a topic t\nfrom a set of topics T, given a topic-oriented ut-\nterance sequence (i.e., the conversation history):\nHt = {u1,··· ,ui,ui+1,···uN }of N utterances,\neach of which could be a question qi or an answer\nai at the i-th turn. The task is to reformulate the\nquestion qi into ¯qi that incorporates the context\nHt\n<i = {uj}i−1\nj=1. In other words, we wish to au-\ntomatically reformulate the input question qi by\ninfusing information that exists in the context Ht\nbut is missing from the question itself.\nFollowing the deﬁnitions of Ren et al. (2018)\nand Elgohary et al. (2019), we further reﬁne the\ntask scope of reformulating ¯qi. Given a question\nqi with its historical context Ht\n<i and a human-\nrewritten ground truth ¯qi, our objective is to induce\na function F({qi,Ht\n<i}) = ¯qi, where ¯qi is com-\nprised of tokens {yk}m\nk=1 of length mfrom the con-\ntext comprising the dialogue sequence {qi,Ht\n<i}\n(current and historical utterances), modeled as a se-\nquence of tokens {xk}n\nk=1 of length n. The tokens\nyk’s can either be drawn from the contextHt\n<i or\nthe current input qi. In the reconstruction of the\nground truth, human annotators are asked to main-\ntain the sentence structure of qi by copying phrases\nfrom the original utterances and performing as few\nedits as possible.\nFinally, given probability P conditioned on a\nparameterized function ˆF and the context (current\nand historical utterances), the overall objective of\nthe task is then deﬁned in terms of ﬁnding the pa-\nrameters θby maximum likelihood estimation:\nθ= arg max\nθ\nT∏\nt=1\nN∏\ni=1\nPti\n(\n¯qi| ˆF({qi,Ht\n<i},θ)\n)\n. (1)\n3.2 Sequence-to-Sequence Architectures and\nPretrained Language Models\nAs both the input qi and the output ¯qi are posed in\nnatural language, a reasonable choice for the para-\nmetric function is a sequence-to-sequence (S2S)\nmodel (Sutskever et al., 2014; Vaswani et al., 2017).\nWith this design, we can incorporate context-\ndependent sentence-level structures when gener-\nating output tokens, since the model can consider\nboth the previously-generated sequences as well as\nthe context.\nTo extract information from the conversation\nﬂow, a simple approach, proposed by Xiong et al.\n(2018) and Elgohary et al. (2019), is to concatenate\nthe historical utterances Ht\n<i with the current input\nqi as the context\n[\nHt\n<i ∥qi\n]\n, and then use a S2S\nmodel to infer the output sequence ˆqi based on it.\nTo optimize parameters in the S2S model, we can\nadopt a supervised learning approach to train the\nS2S model to generate the ˆqi tokens, given the ¯qi\ntokens as ground truth output.\nHowever, Eq (1) makes an important assumption:\nhere, we consider each conversation topic t and\neach i-th turn independently. Since a topic-oriented\nconversation is often coherent and smoothly spans\nseveral utterances, an approximation of the param-\neterized function ˆF(·,θ) purely based on Eq (1)\ncould be sub-optimal. To relax this assumption, we\nintroduce pretrained language models (Devlin et al.,\n2018; Radford et al., 2018; Raffel et al., 2019) to\nleverage language structures extracted from large\ncorpora. Speciﬁcally, we adopt these models and\nﬁne-tune their pretrained weights, as in previous\nwork (Radford et al., 2018; Raffel et al., 2019).\n4 Experiments\n4.1 Dataset\nTo evaluate the capability of various models in re-\nformulating conversational questions, we conduct\nexperiments on the CANARD dataset (Elgohary\net al., 2019), an existing large open-domain dataset\nfor CQR (containing over 30k training samples).\nEach sample in the CANARD dataset includes an\noriginal query from the QuAC dataset (Choi et al.,\n2018), its context (historical utterances and their\nanswers), and the corresponding rewritten question\nby human annotators.\nIn addition, we also evaluate model performance\non the dataset provided by the TREC 2019 Conver-\nsational Assistant Track (CAsT).1 CAsT organizers\nmanually rewrote each conversational query in the\nevaluation set according to its contextual informa-\ntion and previous utterances in the same session.\nStatistics of the CANARD and CAsT datasets are\npresented in Table 1.\n1https://github.com/daltonj/\ntreccastweb\nTable 1: Statistics of the datasets used in this work.\nCANARD CAsT\nTrain Dev Test\n31,538 3,418 5,571 479\n4.2 Setup\nTo train and evaluate our sequence-to-sequence\n(S2S) models, we construct model input largely fol-\nlowing Elgohary et al. (2019). Speciﬁcally, we con-\ncatenate each original question and its context by\nadding special separator tokens between them. Sep-\narator tokens are also added to contextual informa-\ntion to separate historical utterances. The human-\nrewritten questions serve as the ground truth target\nsequences. For encoder- or decoder-only models\n(e.g., GPT-2, BERT, and UniLM), each training in-\nput sequence (as described above) is concatenated\nwith its target sequence, and the models are trained\nto recover the target sequence using standard mask-\ning tricks.\nWe train each model on the CANARD training\nset and select the checkpoint with the best perfor-\nmance on development set. In addition to compar-\ning model performance on the CANARD test set,\nwe directly use the model trained on CANARD to\nperform CQR on the CAsT dataset. 2 Model per-\nformance is computed by the BLEU score between\nmodel output and the human-rewritten ground truth.\nTable 2 shows the settings of the neural models.\nAdditional model-speciﬁc training details are as\nfollows. (a) LSTM: Following the script provided\nby Elgohary et al. (2019), we train a bidirectional\nLSTM S2S model with attention; the word embed-\ndings are initialized with GloVE.3 (b) GPT-2(Rad-\nford et al., 2018), which can be characterized as a\npretrained decoder-only transformer: To focus on\nrewriting questions, we ﬁne-tune the model (GPT-2\nmedium) by masking the cross entropy loss at the\npositions of the contextual tokens. (c) BERT (De-\nvlin et al., 2018), which can be characterized as\na pretrained encoder-only transformer: Following\nthe S2S ﬁne-tuning procedure proposed in Dong\net al. (2019), we ﬁne-tune BERT-large (cased) by\nrandomly masking the tokens with 70% probability\nin targeted sequences.4 (d) UniLM (Dong et al.,\n2019), where the model architecture is the same\nas BERT large and pretrained using three types\n2Note that for CAsT, only historical questions are included\nas contextual information.\n3https://github.com/aagohary/canard\n4https://github.com/microsoft/unilm\nTable 2: Model settings.\n# parameters Learning rate Batch size\nLSTM 46M 0.15 16\nGPT-2-medium 345M 10−4 32\nBERT-large 340M 10−5 32\nUniLM-large 340M 10−5 32\nT5-base 220M 10−4 256\nof language-modeling tasks: The method for ﬁne-\ntuning is the same as BERT. (e) T5 (Raffel et al.,\n2019), an encoder–decoder transformer that maps\nnatural language understanding tasks to text-to-\ntext transformation tasks: We ﬁne-tune the T5-base\nmodel with the same settings used in Nogueira and\nLin (2019).5\nIn addition, we list human performance of CQR\n(denoted as Human), as measured by Elgohary\net al. (2019), and the baseline performance using\nquestions without any reformulation (denoted as\nRaw) for comparison.\n4.3 Results\nOur main results in terms of BLEU on CANARD\nand CAsT are shown in Table 3, using greedy\nsearch decoding for inference. In general, all neu-\nral S2S models perform better than the original\nquestions (Raw), except for LSTM on CAsT. This\nindicates that the PLMs (GPT2, BERT, UniLM,\nand T5) have obtained at least some generalization\ncapability on the CQR task.\nAmong all neural S2S models, T5 demonstrates\na better ability to learn CQR from human-rewritten\nquestions with fewer model parameters. Speciﬁ-\ncally, in the CANARD test set, T5 beats the other\nneural S2S models with 58.08 BLEU, which is\nclose to human performance, 59.92. Furthermore,\non CAsT, T5 achieves the highest BLEU score\n(75.07), four points better than the second-best\nmodel (71.21). These results demonstrate T5’s\nsuperior generalization ability.\nIn addition, we also perform S2S model infer-\nence using beam search and top- k random sam-\npling decoding.6 Figure 2 (left side) shows that\nbeam search with larger beam widths further im-\nproves BLEU scores in both datasets. T5 with a\nbeam width of 10 achieves a BLEU score that is on\npar with human performance on the CANARD test\nset and reaches 76.22 on CAsT. 7 Figure 2 (right\n5https://github.com/castorini/\ndocTTTTTquery\n6Note that beam search (top-krandom sampling) is equal\nto greedy search when the beam width (top-k) is set to 1\n7We did not perform GPT-2 inference with beam search\nTable 3: BLEU score comparison. For simplicity, we\ncompare neural S2S models using greedy search.\nCANARD CAsT\nDev Test\nHuman 59.92 -\nRaw 33.84 36.25 60.41\nLSTM 43.68 39.15 42.24\nGPT-2-medium 52.63 50.07 68.07\nBERT-large 55.34 54.34 69.53\nUniLM-large 57.39 55.92 71.21\nT5-base 59.13 58.08 75.07\n1 5 10\nChunk size (beam search)\n35\n40\n45\n50\n55\n60\n65BLEU\nHuman upper bound: 59.92\nCANARD (Test)\n1 5 10\nChunk size (random sampling)\n35\n40\n45\n50\n55\n60\n65BLEU\nHuman upper bound: 59.92\nCANARD (Test)\n1 5 10\nChunk size (beam search)\n40\n45\n50\n55\n60\n65\n70\n75\n80BLEU\nCAsT\n1 5 10\nChunk size (random sampling)\n40\n45\n50\n55\n60\n65\n70\n75\n80BLEU\nCAsT\nModel LSTM GPT2 BERT UniLM T5\nFigure 2: Decoding sensitivity analysis\nside) illustrates that random sampling with larger\ntop-kleads to poor BLEU scores.8 Under this de-\ncoding strategy, T5 still maintains better BLEU\nscores compared to the other S2S models.\n5 Conclusion\nIn this paper, we conduct experiments on conver-\nsational question reformulation (CQR) via neural\nsequence-to-sequence (S2S) models and demon-\nstrate that our ﬁne-tuned T5-base model achieves\nthe state of the art, in one case achieving perfor-\nmance on par with humans (at least measured by\nBLEU). In addition, experiments on the CAsT\ndataset show that our ﬁne-tuned T5-base model\ncan be directly used in a transfer setting and beats\nother neural S2S models by quite a large margin.\nsince the original implementation does not support beam\nsearch.\n8For random sampling, we perform model inference with\n10 repetitions and average over them.\n6 Acknowledgements\nThis research was supported in part by the Canada\nFirst Research Excellence Fund and the Natural Sci-\nences and Engineering Research Council (NSERC)\nof Canada. Additionally, we would like to thank\nGoogle for computational resources in the form of\nGoogle Cloud credits.\nReferences\nWasi Uddin Ahmad, Kai-Wei Chang, and Hongning\nWang. 2018. Multi-task learning for document rank-\ning and query suggestion. In Proc. ICLR.\nWasi Uddin Ahmad, Kai-Wei Chang, and Hongning\nWang. 2019. Context attentive document ranking\nand query suggestion. In Proc. SIGIR, page 385394.\nMohammad Aliannejadi, Hamed Zamani, Fabio\nCrestani, and W. Bruce Croft. 2019. Asking clarify-\ning questions in open-domain information-seeking\nconversations. In Proc. SIGIR, page 475484.\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine\nBordes. 2017. Reading Wikipedia to answer open-\ndomain questions. In Proc. ACL, pages 1870–1879.\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-\ntau Yih, Yejin Choi, Percy Liang, and Luke Zettle-\nmoyer. 2018. QuAC: Question answering in context.\narXiv:1808.07036.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2018. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. arXiv:1810.04805.\nBhuwan Dhingra, Kathryn Mazaitis, and William W.\nCohen. 2017. Quasar: Datasets for question answer-\ning by search and reading. arXiv:1707.03904.\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-\naodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\nand Hsiao-Wuen Hon. 2019. Uniﬁed language\nmodel pre-training for natural language understand-\ning and generation. In Proc. NIPS.\nAhmed Elgohary, Denis Peskov, and Jordan Boyd-\nGraber. 2019. Can you unpack that? Learning\nto rewrite questions-in-context. In Proc. EMNLP,\npages 5917–5923.\nJianfeng Gao, Michel Galley, and Lihong Li.\n2018. Neural approaches to conversational AI.\narXiv:1809.08267.\nHsin-Yuan Huang, Eunsol Choi, and Wen tau Yih.\n2019. FlowQA: Grasping ﬂow in history for con-\nversational machine comprehension. In Proc. ICLR.\nDalton Jeffrey, Chenyan Xiong, and Jamie Callan.\n2019. CAsT 2019: The conversational assistance\ntrack overview. In Proc. TREC.\nTom´aˇs Ko ˇcisk´y, Jonathan Schwarz, Phil Blunsom,\nChris Dyer, Karl Moritz Hermann, G´abor Melis, and\nEdward Grefenstette. 2018. The NarrativeQA read-\ning comprehension challenge. Trans.of ACL, 6:317–\n328.\nRodrigo Nogueira and Jimmy Lin. 2019. From\ndoc2query to docTTTTTquery.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2018. Language\nmodels are unsupervised multitask learners.\nFilip Radlinski and Nick Craswell. 2017. A theoret-\nical framework for conversational search. In Proc.\nCHIIR, page 117126.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. arXiv:1910.10683.\nPranav Rajpurkar, Robin Jia, and Percy Liang. 2018.\nKnow what you don’t know: Unanswerable ques-\ntions for SQuAD. In Proc. ACL, pages 784–789.\nSiva Reddy, Danqi Chen, and Christopher D. Manning.\n2019. CoQA: A conversational question answering\nchallenge. Trans. of ACL, 7:249–266.\nGary Ren, Xiaochuan Ni, Manish Malik, and Qifa Ke.\n2018. Conversational query understanding using se-\nquence to sequence modeling. In Proc. WWW, page\n17151724.\nMin Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and\nHannaneh Hajishirzi. 2017. Bidirectional attention\nﬂow for machine comprehension. In Proc. ICLR.\nHaitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn\nMazaitis, Ruslan Salakhutdinov, and William Co-\nhen. 2018. Open domain question answering using\nearly fusion of knowledge bases and text. In Proc.\nEMNLP, pages 4231–4242.\nIlya Sutskever, Oriol Vinyals, and Quoc V . Le. 2014.\nSequence to sequence learning with neural networks.\nIn Proc. NIPS, page 31043112.\nAshish Vaswani, Noam Shazeer, Niki Parmar,\nJakob Uszkoreit, Llion Jones, Aidan N. Gomez,\nŁukasz Kaiser, and Illia Polosukhin. 2017. At-\ntention is all you need. In Proc. NIPS, pages\n5998–6008.\nWayne Xiong, Lingfeng Wu, Jun Zhang, and Andreas\nStolcke. 2018. Session-level language modeling\nfor conversational speech. In Proc. EMNLP, pages\n2764–2768.\nTiancheng Zhao and Maxine Eskenazi. 2016. Towards\nend-to-end learning for dialog state tracking and\nmanagement using deep reinforcement learning. In\nProc. of SIGDIAL, pages 1–10."
}