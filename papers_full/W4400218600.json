{
  "title": "Large Language Models Can Enable Inductive Thematic Analysis of a Social Media Corpus in a Single Prompt: Human Validation Study",
  "url": "https://openalex.org/W4400218600",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2035500008",
      "name": "Michael S. Deiner",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4323837165",
      "name": "Vlad Honcharov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105271709",
      "name": "Jiawei Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2032801067",
      "name": "Tim K. Mackey",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A102620580",
      "name": "Travis C. Porco",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2149007370",
      "name": "Urmimala Sarkar",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W1984926150",
    "https://openalex.org/W4380682431",
    "https://openalex.org/W4210862213",
    "https://openalex.org/W2807878428",
    "https://openalex.org/W2913732268",
    "https://openalex.org/W4389341709",
    "https://openalex.org/W4389222161",
    "https://openalex.org/W3111394773",
    "https://openalex.org/W4323836089",
    "https://openalex.org/W4206606007",
    "https://openalex.org/W2785447792",
    "https://openalex.org/W3186243414",
    "https://openalex.org/W2770259901",
    "https://openalex.org/W4390593459",
    "https://openalex.org/W4391755461",
    "https://openalex.org/W4389990729",
    "https://openalex.org/W4391031145",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4281557260",
    "https://openalex.org/W4388777264",
    "https://openalex.org/W4386045865",
    "https://openalex.org/W4392748894",
    "https://openalex.org/W4382399573",
    "https://openalex.org/W4220676333",
    "https://openalex.org/W4389431401",
    "https://openalex.org/W4220795370",
    "https://openalex.org/W3186931810",
    "https://openalex.org/W4393231947",
    "https://openalex.org/W4367623968",
    "https://openalex.org/W2146029572",
    "https://openalex.org/W4391709247",
    "https://openalex.org/W2019432915"
  ],
  "abstract": "Background Manually analyzing public health–related content from social media provides valuable insights into the beliefs, attitudes, and behaviors of individuals, shedding light on trends and patterns that can inform public understanding, policy decisions, targeted interventions, and communication strategies. Unfortunately, the time and effort needed from well-trained human subject matter experts makes extensive manual social media listening unfeasible. Generative large language models (LLMs) can potentially summarize and interpret large amounts of text, but it is unclear to what extent LLMs can glean subtle health-related meanings in large sets of social media posts and reasonably report health-related themes. Objective We aimed to assess the feasibility of using LLMs for topic model selection or inductive thematic analysis of large contents of social media posts by attempting to answer the following question: Can LLMs conduct topic model selection and inductive thematic analysis as effectively as humans did in a prior manual study, or at least reasonably, as judged by subject matter experts? Methods We asked the same research question and used the same set of social media content for both the LLM selection of relevant topics and the LLM analysis of themes as was conducted manually in a published study about vaccine rhetoric. We used the results from that study as background for this LLM experiment by comparing the results from the prior manual human analyses with the analyses from 3 LLMs: GPT4-32K, Claude-instant-100K, and Claude-2-100K. We also assessed if multiple LLMs had equivalent ability and assessed the consistency of repeated analysis from each LLM. Results The LLMs generally gave high rankings to the topics chosen previously by humans as most relevant. We reject a null hypothesis (P&lt;.001, overall comparison) and conclude that these LLMs are more likely to include the human-rated top 5 content areas in their top rankings than would occur by chance. Regarding theme identification, LLMs identified several themes similar to those identified by humans, with very low hallucination rates. Variability occurred between LLMs and between test runs of an individual LLM. Despite not consistently matching the human-generated themes, subject matter experts found themes generated by the LLMs were still reasonable and relevant. Conclusions LLMs can effectively and efficiently process large social media–based health-related data sets. LLMs can extract themes from such data that human subject matter experts deem reasonable. However, we were unable to show that the LLMs we tested can replicate the depth of analysis from human subject matter experts by consistently extracting the same themes from the same data. There is vast potential, once better validated, for automated LLM-based real-time social listening for common and rare health conditions, informing public health understanding of the public’s interests and concerns and determining the public’s ideas to address them.",
  "full_text": null,
  "topic": "Social media",
  "concepts": [
    {
      "name": "Social media",
      "score": 0.6033557057380676
    },
    {
      "name": "Computer science",
      "score": 0.5804389119148254
    },
    {
      "name": "Thematic analysis",
      "score": 0.5534581542015076
    },
    {
      "name": "Thematic map",
      "score": 0.5251756906509399
    },
    {
      "name": "Natural language processing",
      "score": 0.5009808540344238
    },
    {
      "name": "Psychology",
      "score": 0.3681769371032715
    },
    {
      "name": "Linguistics",
      "score": 0.34648796916007996
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33946317434310913
    },
    {
      "name": "Sociology",
      "score": 0.2336399257183075
    },
    {
      "name": "World Wide Web",
      "score": 0.1425018012523651
    },
    {
      "name": "Geography",
      "score": 0.13048124313354492
    },
    {
      "name": "Qualitative research",
      "score": 0.12445670366287231
    },
    {
      "name": "Cartography",
      "score": 0.10192182660102844
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2802636490",
      "name": "San Francisco Foundation",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I180670191",
      "name": "University of California, San Francisco",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1295908608",
      "name": "San Francisco General Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210142920",
      "name": "Global Policy Institute",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I36258959",
      "name": "University of California, San Diego",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I160856358",
      "name": "University of San Diego",
      "country": "US"
    }
  ],
  "cited_by": 15
}