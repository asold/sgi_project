{
    "title": "Generative AI meets CAD: enhancing engineering design to manufacturing processes with large language models",
    "url": "https://openalex.org/W4411067687",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A5074247056",
            "name": "Amirmohammad Daareyni",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5021767632",
            "name": "Antti Martikkala",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5090115683",
            "name": "Hossein Mokhtarian",
            "affiliations": [
                null
            ]
        },
        {
            "id": "https://openalex.org/A5026610136",
            "name": "Iñigo Flores Ituarte",
            "affiliations": [
                null
            ]
        }
    ],
    "references": [
        "https://openalex.org/W3210165781",
        "https://openalex.org/W4327810158",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W4401671778",
        "https://openalex.org/W3177813494",
        "https://openalex.org/W3198685994",
        "https://openalex.org/W4405324062",
        "https://openalex.org/W3146958938",
        "https://openalex.org/W2077734604",
        "https://openalex.org/W4405319223",
        "https://openalex.org/W4408938915",
        "https://openalex.org/W4406725058",
        "https://openalex.org/W4403424906",
        "https://openalex.org/W4404310765",
        "https://openalex.org/W4407632324",
        "https://openalex.org/W6910601850"
    ],
    "abstract": "Abstract As a key technology in the field of Artificial Intelligence (AI), large language models (LLMs) have gained substantial attention due to their wide range of capabilities in understanding and generating human-like speech. These advancements extend opportunities beyond text generation offering solutions for more complex engineering tasks. Despite extensive exploration of LLM capabilities in multiple fields, there is a noticeable lack of comprehensive studies within the engineering sector. This study aims to address this gap by investigating the potential of LLMs in solving engineering design problems. This study presents a framework for LLM-assisted CAD that employs advanced artificial intelligence systems, specifically GPT-4o model, to provide users with the ability to generate and manipulate 3D models through text commands, visual inputs such as blueprints, images, voice, and any other type of general or professional information about the desired model. By integrating LLMs with CAD software and incorporating image recognition and voice detection capabilities, we aim to lower the barrier to entry for 3D modeling, making it more user-friendly and accessible to non-professionals. The proposed framework employs LLM to process user inputs (text, images, and/or voice) and generate the code corresponding the CAD model. A closed feedback loop ensures that the generated models are refined iteratively until they meet the user’s specifications. This research demonstrates the potential of generative AI-assisted design (GAD) in simplifying complex design processes and providing valuable insights into areas where LLM enhanced processes can assist design to manufacturing workflows.",
    "full_text": "The International Journal of Advanced Manufacturing Technology\nhttps://doi.org/10.1007/s00170-025-15830-2\nORIGINAL ARTICLE\nGenerative AI meets CAD: enhancing engineering design\nto manufacturing processes with large language models\nAmirmohammad Daareyni 1 · Antti Martikkala 1 · Hossein Mokhtarian 1 · Iñigo Flores Ituarte 1\nReceived: 22 April 2025 / Accepted: 26 May 2025\n© The Author(s) 2025\nAbstract\nAs a key technology in the ﬁeld of Artiﬁcial Intelligence (AI), large language models (LLMs) have gained substantial attention\ndue to their wide range of capabilities in understanding and generating human-like speech. These advancements extend\nopportunities beyond text generation offering solutions for more complex engineering tasks. Despite extensive exploration\nof LLM capabilities in multiple ﬁelds, there is a noticeable lack of comprehensive studies within the engineering sector. This\nstudy aims to address this gap by investigating the potential of LLMs in solving engineering design problems. This study\npresents a framework for LLM-assisted CAD that employs advanced artiﬁcial intelligence systems, speciﬁcally GPT-4o\nmodel, to provide users with the ability to generate and manipulate 3D models through text commands, visual inputs such as\nblueprints, images, voice, and any other type of general or professional information about the desired model. By integrating\nLLMs with CAD software and incorporating image recognition and voice detection capabilities, we aim to lower the barrier to\nentry for 3D modeling, making it more user-friendly and accessible to non-professionals. The proposed framework employs\nLLM to process user inputs (text, images, and/or voice) and generate the code corresponding the CAD model. A closed\nfeedback loop ensures that the generated models are reﬁned iteratively until they meet the user’s speciﬁcations. This research\ndemonstrates the potential of generative AI-assisted design (GAD) in simplifying complex design processes and providing\nvaluable insights into areas where LLM enhanced processes can assist design to manufacturing workﬂows.\nKeywords Computer-aided design · Design automation · Artiﬁcial intelligence · Large language models · Chat-GPT\n1 Introduction\nAI is reshaping nearly every sector of science, technology,\nand industry [ 1, 2]. Within this broad AI landscape, natural\nlanguage processing (NLP) has emerged as a pivotal ﬁeld\nfocused on enabling machines to understand, interpret, and\nAmirmohammad Daareyni, Antti Martikkala, Hossein Mokhtarian, and\nIñigo Flores Ituarte contributed equally to this work\nB Amirmohammad Daareyni\namirmohammad.daareyni@tuni.ﬁ\nAntti Martikkala\nantti.martikkala@tuni.ﬁ\nHossein Mokhtarian\nhossein.mokhtarian@tuni.ﬁ\nIñigo Flores Ituarte\ninigo.ﬂoresituarte@tuni.ﬁ\n1 Faculty of Engineering and Natural Sciences, Tampere\nUniversity, Korkeakoulunkatu 6, 33014 Tampere, Pirkanmaa,\nFinland\ngenerate human language [ 3]. A signiﬁcant development in\nthis progression is the rise of LLMs, exempliﬁed by models\nlike GPT-4 developed by OpenAI [ 4] and BERT developed\nby Google [ 5]. Powered by sophisticated transformer-based\narchitectures and massive datasets, these models perform\neffectively in conventional NLP applications while also\nextend their capabilities to a variety of domains [ 6]. Mod-\nern LLMs can retrieve information, generate textual and\ngraphical content, write and debug code in multiple program-\nming languages, and assist with complex computations and\ndata visualization [ 6]. They also facilitate document edit-\ning, proofreading, and translation across multiple languages,\nmaking them invaluable in ﬁelds like education, engineer-\ning, creative arts, personal development, and day-to-day life\n[6]. Leveraging vast amounts of textual data, these mod-\nels can interpret specialized instructions, identify underlying\npatterns, and generate structured outputs in line with user-\ndeﬁned objectives [ 7, 8].\nBeyond traditional language-focused tasks, LLMs are\nincreasingly being applied in engineering domains, where\n123\nThe International Journal of Advanced Manufacturing Technology\ntheir capacity to interpret structured queries and generate\ntechnical outputs can streamline complex workﬂows. Recent\nstudies have shown that integrating LLMs via accessible\nApplication Programming Interfaces (APIs), such as the\nChatGPT API, can facilitate the creation of domain-speciﬁc\ntools that lower technical barriers. For instance, Martikkala\net al. [ 9] developed a system that helps less-experienced\nusers program Arduino-based IoT sensors by integrating\nChatGPT with a custom interface. Combining LLMs with\nengineering templates and pin mappings, the tool enables a\nsemi-automated, human-in-the-loop workﬂow for accessible\nprototyping.\nComputer-aided design (CAD) has long been a cor-\nnerstone of product development, enhancing productivity\nthrough efﬁcient visualization, analysis, and documentation\nwhile reducing time and cost [ 10]. It improves design qual-\nity by minimizing errors and enabling thorough analysis and\nexploration of alternatives, while also standardizing doc-\numentation and enhancing communication [ 10]. Over the\nyears, engineers have continually sought to optimize and sim-\nplify CAD workﬂows through various innovations, ranging\nfrom parametric and direct modeling to generative design\n[11–13]. Despite these advancements, however, a signiﬁcant\ndegree of experience and proﬁciency remains essential for\nusers to effectively create viable designs in CAD software.\nRecent studies have explored the role of AI and machine\nlearning (ML) in optimizing design and manufacturing pro-\ncesses. For example, Careri et al. [ 14] combined ML and AI\nto determine the optimal process parameters for a powder bed\nfusion-laser beam on metal process, aiming to reduce defects\nand maintain the geometrical and dimensional integrity of\nthe thin features needed for efﬁcient heat transfer in a heat\nexchanger. Kiangala et al. [ 15] investigated a new method\nfor human and machine interaction in an Industry 5.0 context\nby designing a GPT-based industrial bot to enhance worker\nwell-being and production efﬁciency. The bot monitors pro-\nduction, tracks well-being parameters like pollution levels\nand overtime hours, and provides functions such as fault\ndetection, root cause analysis, and synthetic data generation.\nSimilarly, several commercial and non-commercial tools\nhave been developed to make the design process faster and\neasier by adding AI tools and technologies. For instance,\nZOO introduced a text-to-CAD open-source prompt inter-\nface, which can generate CAD models through textual\nprompts [ 16]. Unlike artistic text-to-3D solutions that rely\non point clouds, this model employs boundary representa-\ntion (B-Rep) to produce fully editable STEP ﬁles. As a result,\ndesigners can import these ﬁles into existing CAD software\nfor precise modiﬁcations, utilizing essential geometry and\ntopology data [ 16]. Deng et al. [ 17] explored how the inte-\ngration of LLMs in the design process can reduce the human\nworkload in design process. They used ChatGPT for required\nﬁle analysis, design computation, and 3D modeling. They\npropose a framework to connect design requirements, anal-\nysis, engineering computing, and model creation with LLM\nfor automated workﬂow. To show the framework capabilities,\nthey chose a one-stage reduction gear system. In a sepa-\nrate study, Li et al. [ 18] presented LLM4CAD, a framework\nenabling GPT-4 and GPT-4v to generate CAD models. They\nperformed a quantitative assessment to measure its effective-\nness in conceptual design, focusing on two core capabilities:\nproducing syntax error-free CAD models and creating shapes\nthat closely approximate ground truth geometry. To evaluate\nthese capabilities, they introduced two key metrics: pars-\ning rate, which measures how often the generated code can\nbe parsed successfully, and intersection over union, which\ncompares the overlap between the generated shape and the\nground truth shape relative to their total area. Jones et al. [ 19]\npropose AIDL (AI design language), a solver-aided domain-\nspeciﬁc language that enhances CAD modeling with LLMs\nby ofﬂoading precise geometric computations to a constraint\nsolver. This allows LLMs to focus on high-level reasoning,\nleveraging their strength in semantic understanding and natu-\nral language manipulation. AIDL supports implicit geometry\ndependencies, explicit constraints, and a hierarchical design\nstructure to improve modularity and editability. In few-shot\ntests, AIDL outperforms existing tools by generating designs\nthat better match input prompts and are easier to reﬁne, repre-\nsenting a notable step forward in LLM-driven CAD design. In\nanother study, Li et al. [ 20] introduce CAD-Llama, a frame-\nwork designed to adapt large language models for parametric\n3D CAD generation. By leveraging a structured code format\n(SPCC) and a hierarchical annotation pipeline, the authors\nalign LLMs with CAD-speciﬁc tasks through adaptive pre-\ntraining and instruction tuning. The approach demonstrates\nnotable improvements in accuracy and complexity over pre-\nvious methods.\nOther studies attempted to integrate LLMs with CAD tools\n[17, 18]. However, most of these studies have targeted narrow\napplication domains, lacked a dedicated user interface (UI)\nfor their frameworks, effective feedback loops to ensure the\nquality of the generated CAD, and ability to process dif-\nferent modalities. To address this gap, this study centers\non developing a streamlined API to interact with LLMs,\nand establishing feedback loops for CAD syntax quality\ncheck, reﬁne and visualize the design, and ﬁnal veriﬁca-\ntion whether the obtained design meets user’s query. The\nspeciﬁc objectives of this research include: (i) exploring\nmethods to translate multimodal voice, textual, and visual\ninputs (e.g., sketches, blueprints) into error free CAD models,\n(ii) developing a three layers closed-loop feedback mecha-\nnism wherein the system iteratively reﬁnes its outputs based\non user feedback or automated validations, and ﬁnally (iii)\nevaluating the accuracy and reliability of LLM-assisted CAD\nmodeling for meeting user-deﬁned speciﬁcations using the\ndesign to manufacturing of gears as a case study.\n123\nThe International Journal of Advanced Manufacturing Technology\nConcretely, the current paper proposes GAD, a Python-\nbased application built with Streamlit, providing an inter-\nactive environment that allows the users to submit design\nrequirements or queries. These inputs are then processed by\nthe OpenAI GPT API to generate CAD model scripts, which\nare displayed in real-time for quick iteration without the need\nfor extensive web development. Building on this technical\napproach, the present study examines how LLMs can sim-\nplify and enhance CAD workﬂows in mechanical and indus-\ntrial engineering. By identifying the strengths and limitations\nof this LLM-driven approach to CAD modeling, we aim to\nlay the groundwork for broader, more accessible design-to-\nmanufacturing workﬂows that leverage state-of-the-art AI\nsolutions. In addition to its technical advantages, the GAD\nframework can support evolving educational practices in\nmechanical engineering. As an open-source platform, GAD\noffers unrestricted access to AI-driven design tools, enabling\ncollaboration among students, educators, and researchers to\nenhance its capabilities. By presenting learners with a user-\nfriendly interface driven by AI-guided suggestions, real-time\nfeedback, and rapid prototyping capabilities, GAD facilitates\nengaging and interactive training experiences that integrate\ntheoretical knowledge with hands-on applications. Conse-\nquently, it helps prepare the next generation of manufacturing\nengineers by fostering both theoretical understanding and\npractical skills through an AI-enhanced, hands-on learning\nexperience.\n2 Methodology\nThe research methodology for this study investigates the\nintegration of large language models (LLMs) into CAD\nworkﬂows. The proposed framework aims to employ LLMs\nfor creating accurate and scalable CAD solutions addressing\ncurrent challenges in CAD design, particularly their inacces-\nsibility to non-experts and steep learning rate. An intuitive\nUI is developed to streamline interactions, enabling users to\nprovide design requirements and allow the users to review\ngenerated models and provide feedback for further reﬁne-\nments.\nThe system integrates an LLM with OpenSCAD and com-\nputer vision techniques to analyze visual inputs, facilitating\nthe generation of models with deﬁned dimensions and inter-\nrelated components. Figure 1 represents the overall workﬂow,\nstarting with uploading a user input query to the LLM. Three\nfeedback loops, including the syntax quality check loop,\nreﬁne and LLMs’ self-evaluation loop, and user feedback\nloop, ensure the quality of the generated models. Generated\nmodel then can be extracted in different formats. Following\nFig. 1 Workﬂow for generative\nAI-assisted CAD modeling\n(GAD)\n123\nThe International Journal of Advanced Manufacturing Technology\nis a detailed description of the system architecture along with\nprompt engineering details, the CAD generation process, and\ntesting and validation techniques.\n2.1 System architecture\nGAD is structured around three primary layers: the user\ninterface layer, the processing and LLM layer, and the render-\ning and export layer. This section focuses on explaining the\nutilized tools and approaches in every layer. Figure 1 demon-\nstrates the overall data ﬂow among GAD components.\n2.1.1 GAD user interface (UI)\nTo streamline interactions among the various tools integrated\ninto GAD, the entire application, including its UI, is built in\nPython. We use Streamlit open-source Python framework for\ndata scientists and AI/ML engineers as an interactive inter-\nface which runs locally but is accessible through a browser\n[21]. Figure 2 illustrates the GAD UI developed in this study.\nFigure 2a shows how the UI allows the user to submit textual,\naudio, and visual inputs to the system. A system log is also\ndisplayed to monitor current state of the system (see Fig. 2b).\nThe GAD UI also allows the user to test and utilize different\nLLM models (see Fig. 2c). Figure 2d shows how the user can\nactivate and control the feedback loops. The GAD system\nalso allows to include external resources for example CAD\nmodel libraries to enhance the accuracy of the outcome (see\nFig. 2e). The GAD process is connected to several outputs\nthat allow to display the CAD model after completion, gen-\nerate and save an.stl ﬁle, and generate G-code (see Fig. 2f).\nOnce the user inputs are provided, generating the CAD is\ntriggered in Fig. 1g. Additionally, Fig. 2h shows extra func-\ntionalities to connect the UI to a 3D printer and trigger the\nprinting process and manufacturing process.\n2.1.2 Processing and the LLM layer\nThe control logic within GAD collects all user’s inputs and\nconstructs a structured prompt for the LLM component. This\nprompt includes further description about the engine and\nits purpose, expected format for the outputs, and the type\nand format of inputs provided by the user. Then, this prompt\nwill be sent to GPT API, upon receiving the answer. GAD\nwill parse the response and extract the required information\nincluding additional information provided by LLM about the\ngenerated model, and the 3D model script. OpenSCAD, an\nopen-source script-based solid 3D CAD software [ 22], is\nused as the reference CAD tool for the generation of 3D\nmodel script. The generated script then will go through two\nlayers of validation. In the ﬁrst layer, system will run the\nSCAD ﬁle and ensures that the ﬁle runs without any syntax\nerror. Then, as LLMs, in this case GPT-4o, is still not capa-\nble of handling 3D models directly, an algorithm creates six\nprojection views of the generated 3D model. Generated pro-\njections then will be sent back to LLM along with all of user\nFig. 2 User interface of generative AI-assisted design (GAD)\n123\nThe International Journal of Advanced Manufacturing Technology\ninputs, and current CAD script asking the model for evalu-\nating itself and verifying that the provided outputs meet the\nuser request. This internal feedback system ensures that GAD\nsatisﬁed the request.\nPrompt engineering and well-structured prompts are the\nkey to interacting with LLMs (here GPT-4o). Prompts used\nin this study start with a brief introduction of the role\nthat LLM has followed by user inputs, expected task, and\nresponse format. To avoid having unnecessary outputs and\nto make handling the responses received from LLM easier,\nwe decided to use JSON format for the output. In this study,\nwe used two kinds of prompts: one for the ﬁrst request and\nthe other one for the internal feedback loop. Table 1 repre-\nsents two examples of prompts used in this study for creating\na model based on descriptions provided by the user using\nOpenSCAD external libraries, and another one for the inter-\nnal feedback loop for the same model.\nLLMs lack the ability to process audio directly; therefore,\na real-time Python-based speech recognition library [ 23]i s\nused to convert all audio inputs into text, which is subse-\nquently used in the GAD process. When the user uploading\nimages, Base64 encoding converts binary data (i.e., images,\nﬁles, or other raw data) into a text string. An extra function-\nality is present in GAD to support uploading images without\ndescription; in this case, the following prompt will be sent to\nLLM asking for descriptions.\n“Analyze the following image(s) encoded_image and sug-\ngest a descriptive name for a 3D SCAD model. Do not add\nmaterial, standard, or size-related descriptions if they are\nnot clearly given in my inputs. Replace any invalid charac-\nters with underscores (_).”\n2.1.3 Rendering and export layer\nAfter veriﬁcation and validation, OpenSCAD is used for ren-\ndering and extracting STL ﬁle. In the next step, Slic3r, an\nopen-source slicer engine [ 24], is used to generate the G-\ncode from 3D CAD ﬁles (STL or OBJ). Once this step is\ncomplete, an appropriate G-code ﬁle to print the 3D mod-\neled part will be extracted. In this paper, Three.js which is\nan interactive 3D visualization tool is used to display and\ninteract with STL ﬁles in UI.\nModel generation and rendering is composed of two main\ntasks, (i) generating the requested part based on user inputs\n(main loop) and (ii) internal feedback loop to ensure the\nsyntax quality of generated model along with several sub-\ntasks to make the LLM response more accurate and reliable.\nAfter user enters inputs in form of descriptions or images, the\nalgorithm forms the prompt to support the generating CAD\nscript in the main loop. This prompt will be uploaded to the\nLLM, and the code will be extracted from the response. The\nextracted code then will be run in OpenSCAD searching for\nsyntax error in the code. In case of any errors, the algorithm\nwill repeat the process for debugging. User can set the num-\nber of retries by changing maximum retries. If LLM cannot\ncreate any correct models, the algorithm will be closed with\nan error and user needs to try again with more detailed inputs.\nTable 1 Prompt structure for\nﬁrst quest and internal feedback\nloop\nFirst quest Internal loop\n“Y ou are a 3D SCAD model generator. Based\non the user’s description, feedback, and provided\nreference images or projections, regenerate a valid\nOpenSCAD (.scad) ﬁle. The SCAD code must\nalways be complete, valid, and formatted in Open-\nSCAD syntax.\nUse this description to guide the SCAD model\ngeneration: {description}. Generate a valid Open-\nSCAD (.scad) ﬁle. Analyze the following Open-\nSCAD libraries ﬁrst and use them in this model\ngeneration: {combined_libraries}. Do not include\nexplanations, questions, or any non-SCAD informa-\ntion. The SCAD code must always be complete and\nvalid. The provided SCAD code should not be inside\ntriple backticks.\nRespond in JSON format like this: {\n“description”: “ <text>”,\n“code”: “ <code>”}\nSpecial characters like newlines (\\n) must be\nescaped as \\\\n.”\n“Y ou created a 3D SCAD model based on the\nuser’s description and provided reference images or\nprojections. now you need to evaluate yourself. Here\nis the current SCAD ﬁle content: {current_scad}.\nAnalyze the following OpenSCAD libraries ﬁrst\nand use them in this model generation: {com-\nbined_libraries}.\nThis is the {view_name.lower()} projection of\nthe model generated by you. Use this description to\nreﬁne the SCAD model generation: {description}.\ncompare this projection with description and ref-\nerence images. Is the model that you made good\nenough?\nRespond in JSON format. If yes, set the\n‘response’ ﬁeld to ‘Yes’. If no, set the ‘response’\nﬁeld to ‘No’ and include a valid OpenSCAD (.scad)\ncode in the ‘code’ ﬁeld.\nExample response: {\n“response”: “Y es”}\nOR\n{“response”: “No”,\n“code”: “ <code>”}\nSpecial characters like newlines (\\n) must be\nescaped as \\\\n.”\n123\nThe International Journal of Advanced Manufacturing Technology\nAfter ensuring that the code runs smoothly and the CAD\nscript is error free, the provided code along with all user\ninputs and projections of the current CAD model will be\nsent back to LLM using the internal loop prompt provided\nin the previous section for internal evaluation (see Table 1).\nExpected answers in this part are “Y es” and “No,” answering\nthe question stated in the prompt “Is the model that you made\ngood enough?” If “Y es,” the algorithm will move forward\nand saves the requested formats while showing the STL ﬁle\nin the UI. In case of “No,” algorithm extracts the new code\nprovided by LLM, checks it for syntax error, and repeats\nthe internal loop with the new code. User can control the\nnumber of internal loops in the UI. If model is unable cre-\nate any good models, the algorithm will be closed with a\nwarning and user needs to decide whether to repeat the pro-\ncess or use the latest version. An additional layer to connect\nCAD design with CAM is added to the GAD functionalities\nfacilitating rapid prototyping. We integrated Printrun [ 25],\nan open-source software for controlling 3D printers used to\nprovide real-time interactions and monitoring. Once GAD\ngenerates the G-code, it can be sent to the 3D printer through\nthe UI, allowing users to quickly initiate and oversee the\nprinting process.\n2.2 Testing and validation\nTo evaluate the different capabilities of GAD, four different\n3D generation tasks were performed. The ﬁrst task exam-\nines the impact of GAD’s self-evaluation system (internal\nfeedback loop) on the quality of generated CAD model.\nThe second investigates the capability of the system to cre-\nate CAD models based on different types of inputs, in this\ncase visual inputs, and the quality of the generated model.\nThe third explores GAD’s performance in generating mod-\nels from highly detailed as well as poorly detailed user\ninputs. Finally, the fourth task evaluates GAD’s design-to-\nmanufacturing workﬂow using a one-stage reduction gear\nsystem as a case study. In this study, we utilize a Prusa\nMK4 desktop fused ﬁlament fabrication (FFF) 3D printer\nfor manufacturing; however, other 3D printers with different\nspeciﬁcations can also be used.\nTo further evaluate the capabilities of the GAD frame-\nwork and explore alternative processing cores, two mid-sized\nopen-access LLMs, Google Gemini 2.5 Pro Experimental\n[26] and OlympicCoder [ 27], were used in place of the orig-\ninal GAD core (e.g., GPT-4o). These models were accessed\nand executed via OpenRouter [ 28], a uniﬁed API platform\nthat enables interaction with multiple AI models (such as\nGPT-4, Claude, Mistral, and others) through a single inter-\nface. To analyze the performance of these alternative models,\nmultiple attempts were made to design a one-stage reduction\ngear system using the same prompt as in the fourth task. Suc-\ncess rate and execution time were recorded for each attempt.\n3 Results and discussion\nFigure 3 presents the results of validation tests performed\nusing GAD. These tests aim to evaluate various aspects of the\nsystem, including the internal loop, its response to different\ntypes of inputs, and its response to complete and incom-\nplete user request. Figure 3a illustrates the functionality of the\ninternal loop and its importance in the system. In this quest,\nfor the sake of simplicity and to emphasis that GAD can be\nused by professional and non-professional for engineering as\nwell as general purposes, GAD is asked to create a simple\nchair. The three design iterations show that GAD can assess\nan initial CAD model and reﬁne it to address shortcomings\nfrom the previous versions. However, it should be noted that\nthis does not guarantee its effectiveness for all use cases or\ngeometries.\nFigure 3b demonstrates how GAD responds to different\ninput types. In this case, a picture of a component without\ndescriptions and dimensions is uploaded to GAD. Although\nThe system successfully interpreted the general circular\ngeometry of the component, including the radial pattern\nof circular holes and the large central cutout, suggesting\nGAD’s capability to extract and replicate overarching geo-\nmetric features from visual cues, the output CAD model lacks\ndimensional accuracy and fails to reproduce the smooth,\nround contour of the outer edge. These inaccuracies highlight\na current limitation of GPT-4o: while it can infer general form\nand layout from an image, it struggles with precise scaling\nand complex edge features in the absence of explicit dimen-\nsional data. Figure 3 c and d illustrate how LLMs can be\nextremely relevant in engineering design workﬂows. In this\ncase, two different queries with different level of details are\nprompted into the GAD UI. The ﬁrst prompt (see Fig. 3c)\nprovides all details and parameters needed for the design of\na spur gear, while the second (refer to Fig. 3d) simply requests\nthe component without any engineering details. The results\nshow that in both cases GAD can create the requested item.\nThe outcome for the second query (Fig. 3d) supports that,\ngiven the assuming nature of large language models, these\nsystems can still generate useful results (here, CAD models)\neven with incomplete user input.\nFigure 4 showcases the process of designing and produc-\ning two spur gears with a 1:2 ratio, printed on a desktop 3D\nprinter using the G-code generated by GAD. This example\nunderlines GAD’s utility in rapid prototyping and educa-\ntional contexts, especially since users can directly link a 3D\nprinter to the system and proceed with the printing process\nthrough the UI. Initially, GAD generates the CAD model\nbased on user-deﬁned inputs speciﬁed in Fig. 4a. The result-\ning geometry (see Fig. 4b) is then sliced to be prepared for the\nmanufacturing process (see Fig. 4c). Note that, although this\nprocess does not address manufacturing-speciﬁc considera-\ntions, such as part orientation and support generation, gears\n123\nThe International Journal of Advanced Manufacturing Technology\nFig. 3 GAD testing and validation results. a Investigation of internal feedback loop on the quality of results, b results extracted from GAD in case\nof only visual inputs, c GAD response to a complete user input, and d a planetary gear box generated by GAD\nare oriented in a way that allows for straightforward produc-\ntion. Finally, Fig. 4d illustrates the printed gears, demonstrat-\ning the overall efﬁciency and accessibility of the process.\nAdditionally, Table 2 provides a comparative analysis of\nsix key geometric parameters for the gears shown in Fig. 4,\nincluding tip diameter, bore diameter, face width, whole\nFig. 4 Design to manufacturing process handled by GAD\n123\nThe International Journal of Advanced Manufacturing Technology\nTable 2 Design veriﬁcation measurements of GAD generated CAD\nand manufactured part\nParameter (Unit) Designed (CAD) 3D Printed\nGear Pinion Gear Pinion\nTip diameter (mm) 63.68 33.98 63.6 33.8\nBore diameter (mm) 10 10 9.7 9.7\nFace width (mm) 10 10 9.9 10.1\nWhole depth (mm) 4.34 4.34 4.4 4.4\nNumber of teeth (—) 30 15 30 15\nCenter distance (mm) 45 44.2\ndepth, number of teeth, and the center distance between\ngears. A direct comparison of the CAD-derived measure-\nments with the user-deﬁned speciﬁcations (Fig. 4a) conﬁrms\nGAD’s capability to produce CAD models that closely match\nuser requirements. Minor deviations observed in the ﬁnal\nprinted parts are attributed to the typical manufacturing tol-\nerances of the desktop 3D printers.\nTable3 presents the performance analysis of various mod-\nels, e.g., Gemini 2.5 Pro and OlympicCoder, when employed\nas the processing core in the GAD framework. In this section,\nthe success rate and execution time of these alternative mod-\nels are examined using the same prompt as in Task 4 (see\nFig. 4) across 10 attempts. Although the required SCAD code\nwas successfully generated by Google Gemini 2.5 Pro in 6\nout of 10 attempts and OlympicCoder successfully generated\nthe SCAD scripts in all 10 repetitions, the execution time\nwas signiﬁcantly large at this stage, which could negatively\nimpact the applicability of these alternative models as the\nprimary core for the GAD framework.\n4 Conclusion\nThis paper demonstrates the potential of LLM-driven design\nsystems. It is exempliﬁed by the GAD, capable of creat-\ning CAD models and G-code for 3D printing from diverse\nTable 3 Performance analysis\nof alternative models Model Attempt Description Success Execution\ntime (s)\nError\nGemini 2.5 Pro Experimental 1 Two spur gears TRUE 222.8 —–\n2 with 1:2 ratio TRUE 150.9 —–\n3 Bigger gear with\n30 teeth, module FALSE —– SCAD code\nnot generated\n4 is 2, width of the TRUE 208.4 —–\n5 gear is 10 mm\nbore diameter is FALSE —– SCAD code\nnot generated\n6 10 mm, and\npressure angle is FALSE —– SCAD code\nnot generated\n7 20. Set the TRUE 17.2 —–\n8 distance in a way\nthat they be TRUE 214 SCAD code\nnot extracted\n9 in contact TRUE 59 —–\n10 FALSE —– SCAD code\nnot generated\nOlympicCoder 1 Two spur gears\nwith 1:2 ratio. TRUE 144.8 Missing SCAD\ncode elements.\n2 Bigger gear with\n30 teeth, module TRUE 106.2 Missing SCAD\ncode elements.\n3 is 2, width of the TRUE 190.6 —–\n4 gear is 10mm, TRUE 112.4 —–\n5 bore diameter is TRUE 121.4 —–\n6 10 mm, and TRUE 164.6 —–\n7 pressure angle is TRUE 235.4 —–\n8 20. Set the\ndistance in a way TRUE 111.4 Missing SCAD\ncode elements.\n9 that they be\nin contact. TRUE 165 SCAD code\nnot extracted.\n10 TRUE 170.4 —–\n123\nThe International Journal of Advanced Manufacturing Technology\nmultimodal data inputs. By unifying AI-driven concept gen-\neration with practical manufacturing outputs, GAD enhances\nthe rapid prototyping process and shows signiﬁcant promise\nfor broader applications in both educational and professional\ndesign contexts. V alidating tests indicate that GAD can gen-\nerate CAD models from a variety of input types. Moreover,\nthanks to the LLM’s ability to make reasonable assump-\ntions, GAD continues to perform effectively even when\nprovided with incomplete or underspeciﬁed inputs. Through\nits iterative internal loop, GAD can generate, reﬁne, and\nadapt CAD models according to user requirements. GAD\ncan also make rapid prototyping easier and more accessible\nby integrating the design-to-manufacturing process, includ-\ning CAD modeling, slicing, and manufacturing, into one\nuser interface. A comparison between user-speciﬁed and\nﬁnal printed gear parameters shows that the observed devia-\ntions arise from the manufacturing process, highlighting the\nsystem’s reliability in following established design criteria.\nHowever, there are some limitations in the current status of\nthe existing LLMs. While GAD can interpret images and\nreplicate general shapes, the ﬁdelity of ﬁne details and pre-\ncise dimensional accuracy still pose challenges, especially\nwhen user input lacks sufﬁcient data, or when the com-\nponent has geometrical complexities. Additionally, in this\nstudy, we compared alternative free mid-sized LLMs, such\nas Google Gemini 2.5 Pro and OlympicCoder, to assess their\nperformance in generating SCAD code. While both mod-\nels showed high success rates, their large execution times\nmay limit their effectiveness as the primary core for the\nGAD framework. These ﬁndings underscore the trade-offs\nbetween model performance and processing efﬁciency when\nchoosing a core LLM for CAD-related applications. Future\nwork should therefore focus on improving GAD’s ability\nto extrapolate more accurate dimensional information, bet-\nter handle complex geometries, and reﬁne designs through\nadvanced error-detection and self-correction mechanisms.\nFurthermore, although commercial LLMs like GPT-4 sim-\nplify research and development efforts, they are costly for\nlarge-scale commercial deployment consequently, and future\nimprovements in execution speed are necessary to enhance\nthe practicality of alternative models for scalable applica-\ntions. Future explorations could seek more cost-effective\napproaches, whether by employing alternative LLMs or\nutilizing specialized, locally trained variants designed exclu-\nsively for CAD generation purposes. In conclusion, the\nﬁndings of this paper indicate that language model-driven\nCAD systems hold signiﬁcant potential for transforming\ndesign processes, offering user-friendly, rapidly iterative,\nand ﬂexible solutions that can accelerate innovation in\nengineering and beyond. This work lays the foundation\nfor future exploration of modular, multi-agent architectures\nand domain-speciﬁc model optimization tailored to the full\ndesign-to-manufacturing pipeline.\nAuthor Contributions\n Amirmohammad Daareyni: conceived the original idea, developed the\nﬁnal codes, developed the methodology, and wrote the original draft of\nthe manuscript.\n Antti Martikkala: developed the core codes and reviewed and edited\nthe manuscript.\n Hossein Mokhtarian: assisted in developing the methodology and\ncontributed to writing the original draft.\n Iñigo Flores Ituarte: contributed to the methods development and\ncritically reviewed the manuscript.\nFunding This work was supported by the project D2M (346874)\nResearch council of Finland - Academy Research Fellow.\nDeclarations\nConﬂict of interest The authors declare no competing interests.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing, adap-\ntation, distribution and reproduction in any medium or format, as\nlong as you give appropriate credit to the original author(s) and the\nsource, provide a link to the Creative Commons licence, and indi-\ncate if changes were made. The images or other third party material\nin this article are included in the article’s Creative Commons licence,\nunless indicated otherwise in a credit line to the material. If material\nis not included in the article’s Creative Commons licence and your\nintended use is not permitted by statutory regulation or exceeds the\npermitted use, you will need to obtain permission directly from the copy-\nright holder. To view a copy of this licence, visit http://creativecomm\nons.org/licenses/by/4.0/.\nReferences\n1. Xu Y , Liuand et al (2021) Artiﬁcial intelligence: a powerful\nparadigm for scientiﬁc research. Innovation. 2(4). https://doi.org/\n10.1016/j.xinn.2021.100179 . Accessed on 29 Jan 2025\n2. Russell SJ, Norvig P (2016) Artiﬁcial intelligence: a modern\napproach. Pearson, Upper Saddle River, New Jersey, USA. https://\naima.cs.berkeley.edu/\n3. Jurafsky D (2000) Speech and language processing. Prentice-Hall\n4. OpenAI et al. (2024) GPT-4 technical report. https://doi.org/10.\n48550/arXiv.2303.08774 . Accessed on 29 Jan 2025\n5. Devlin J, Chang M-W, Lee K, Toutanova K (2019) BERT:\npre-training of deep bidirectional transformers for language under-\nstanding. https://doi.org/10.48550/arXiv.1810.04805. Accessed\non 29 Jan 2025\n6. Kumar P (2024) Large language models (LLMs): survey, technical\nframeworks, and future challenges. Artif Intell Rev 57(10):260.\nhttps://doi.org/10.1007/s10462-024-10888-y . Accessed on 29 Jan\n2025\n7. Chen M, et al. (2021) Evaluating large language models trained on\ncode. https://doi.org/10.48550/arXiv.2107.03374. Accessed on 25\nJan 2025\n8. Wang Y , Wang W, Joty S, Hoi SC (2021) Codet5: identiﬁer-aware\nuniﬁed pre-trained encoder-decoder models for code understanding\nand generation. arXiv:2109.00859\n123\nThe International Journal of Advanced Manufacturing Technology\n9. Martikkala A, David J, Ituarte IF (2024) Chatgpt + arduino -\na powerful approach for unique use-case tailored sensors. IET\nConf Proc 2024:124–131. https://doi.org/10.1049/icp.2024.3496.\nhttps://digital-library.theiet.org/doi/pdf/10.1049/icp.2024.3496\n10. Sarcar MMM, Rao KM, Narayan KL (2008) Computer aided\ndesign and manufacturing. PHI Learning Pvt. Ltd., New Delhi,\nIndia. https://shorturl.at/Htf1B\n11. Jaisawal R, Agrawal V (2021) Generative design method (GDM) -\na state of art. IOP Conf Ser Mater Sci Eng 1104(1):012036. https://\ndoi.org/10.1088/1757-899X/1104/1/012036 . Accessed 2025-01-\n29\n12. Brière-Côté A, Rivest L, Maranzana R (2013) 3D CAD model\ncomparison: an evaluation of model difference identiﬁcation tech-\nnologies. Comput Aided Des Appl 10(2):173–195. https://doi.org/\n10.3722/cadaps.2013.173-195. https://www.tandfonline.com/doi/\npdf/10.3722/cadaps.2013.173-195 . Accessed 29 Jan 2025\n13. Daareyni A, Queguineur A, Mokhtarian H, Asadi R, Ituarte\nIF (2024) Multi-objective optimization-driven design: generative\ndesign approach for manufacturing of a train bogie. In: Wang Y -\nC, Chan SH, Wang, Z-H (eds) Flexible automation and intelligent\nmanufacturing: manufacturing innovation and preparedness for the\nchanging world order. Springer, Cham, pp 48–55. https://doi.org/\n10.1007/978-3-031-74485-3_6\n14. Careri F, Stella L, Khan RHU, Attallah MM (2025) Application of\nmachine learning in additive manufacturing of a novel Al alloy heat\nexchanger. Int J Adv Manuf Tech. https://doi.org/10.1007/s00170-\n025-15389-y . Accessed on 01 Apr 2025\n15. Kiangala KS, Wang Z (2025) A generative pre-trained trans-\nformer industrial bot to improve operators’ working experience in\na small Industry 5.0 factory. Int J Adv Manuf Tech 136(7):3525–\n3541. https://doi.org/10.1007/s00170-025-15033-9 . Accessed on\n02 Apr 2025\n16. Introducing Text-to-CAD (2023). https://zoo.dev/introducing-\ntext-to-cad Accessed on 29 Jan 2025\n17. Deng H, Khan S, Erkoyuncu JA (2024) An investigation on uti-\nlizing large language model for industrial computer-aided design\nautomation. Procedia CIRP 128:221–226. https://doi.org/10.1016/\nj.procir.2024.07.049. Accessed on 29 Oct 2024\n18. Li X, Sun Y , Sha Z (2024) LLM4CAD: multi-modal large language\nmodels for 3d computer-aided design generation. International\ndesign engineering technical conferences and computers and infor-\nmation in engineering conference, vol. V olume 6: 36th international\nconference on Design Theory and Methodology (DTM). pp 006–\n06015. https://doi.org/10.1115/DETC2024-143740\n19. Jones BT, Hähnlein F, Zhang Z, Ahmad M, Kim V , Schulz A\n(2025) A solver-aided hierarchical language for LLM-driven CAD\ndesign. https://doi.org/10.48550/arXiv.2502.09819. Accessed 15\nMay 2025\n20. Li J, Ma W, Li X, Lou Y , Zhou G, Zhou X (2025) CAD-Llama:\nleveraging large language models for computer-aided design para-\nmetric 3D model generation. https://doi.org/10.48550/arXiv.2505.\n04481. Accessed on 15 May 2025\n21. Streamlit (2021) A faster way to build and share data apps. https://\nstreamlit.io/. Accessed on 30 Jan 2025\n22. OpenSCAD. https://openscad.org. Accessed on 30 Jan 2025\n23. SpeechRecognition: Library for performing speech recognition,\nwith support for several engines and APIs, online and ofﬂine.\nhttps://github.com/Uberi/speech_recognition#readme . Accessed\n30 Jan 2025\n24. Slic3r - Open source 3D printing toolbox. https://slic3r.org/.\nAccessed on 30 Jan 2025\n25. kliment (2025) kliment/Printrun. original-date: 2011-05-\n10T07:41:19Z. https://github.com/kliment/Printrun. Accessed on\n12 Feb 2025\n26. Gemini 2.5 Pro (2025). https://deepmind.google/technologies/\ngemini/pro/. Accessed on 08 Apr 2025\n27. OlympicCoder 32B (free) - API, Providers, Stats. https://\nopenrouter.ai/open-r1/olympiccoder-32b:free . Accessed on 08\nApr 2025\n28. OpenRouter. https://openrouter.ai. Accessed on 08 Apr 2025\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional afﬁliations.\n123"
}