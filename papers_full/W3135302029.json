{
  "title": "The Transformer Network for the Traveling Salesman Problem",
  "url": "https://openalex.org/W3135302029",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A3083767140",
      "name": "Bresson, Xavier",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2098010065",
      "name": "Laurent Thomas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3021435853",
    "https://openalex.org/W2949555952",
    "https://openalex.org/W2148673189",
    "https://openalex.org/W2017708378",
    "https://openalex.org/W3114197418",
    "https://openalex.org/W1597286183",
    "https://openalex.org/W2795112307",
    "https://openalex.org/W2948433391",
    "https://openalex.org/W2964308564",
    "https://openalex.org/W626292722",
    "https://openalex.org/W1969186119",
    "https://openalex.org/W2952332632",
    "https://openalex.org/W2626778328",
    "https://openalex.org/W2119717200",
    "https://openalex.org/W2169337137",
    "https://openalex.org/W1546457065",
    "https://openalex.org/W2117226423",
    "https://openalex.org/W2060514920",
    "https://openalex.org/W2998057994",
    "https://openalex.org/W2257979135",
    "https://openalex.org/W2970731410",
    "https://openalex.org/W2951430899",
    "https://openalex.org/W2137095888",
    "https://openalex.org/W1757796397",
    "https://openalex.org/W2805798351",
    "https://openalex.org/W2024060531",
    "https://openalex.org/W2164948578",
    "https://openalex.org/W3115021520",
    "https://openalex.org/W2647779349",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W2106378689",
    "https://openalex.org/W2951846985",
    "https://openalex.org/W2507756961",
    "https://openalex.org/W2962979969",
    "https://openalex.org/W2787189213",
    "https://openalex.org/W1971483538"
  ],
  "abstract": "The Traveling Salesman Problem (TSP) is the most popular and most studied combinatorial problem, starting with von Neumann in 1951. It has driven the discovery of several optimization techniques such as cutting planes, branch-and-bound, local search, Lagrangian relaxation, and simulated annealing. The last five years have seen the emergence of promising techniques where (graph) neural networks have been capable to learn new combinatorial algorithms. The main question is whether deep learning can learn better heuristics from data, i.e. replacing human-engineered heuristics? This is appealing because developing algorithms to tackle efficiently NP-hard problems may require years of research, and many industry problems are combinatorial by nature. In this work, we propose to adapt the recent successful Transformer architecture originally developed for natural language processing to the combinatorial TSP. Training is done by reinforcement learning, hence without TSP training solutions, and decoding uses beam search. We report improved performances over recent learned heuristics with an optimal gap of 0.004% for TSP50 and 0.39% for TSP100.",
  "full_text": "The Transformer Network for the\nTraveling Salesman Problem\nXavier Bresson\nSchool of Computer Science and Engineering\nNTU, Singapore\nxbresson@ntu.edu.sg\nThomas Laurent\nDepartment of Mathematics\nLoyola Marymount University\ntlaurent@lmu.edu\nAbstract\nThe Traveling Salesman Problem (TSP) is the most popular and most studied\ncombinatorial problem, starting with von Neumann in 1951. It has driven the\ndiscovery of several optimization techniques such as cutting planes, branch-and-\nbound, local search, Lagrangian relaxation, and simulated annealing. The last\nﬁve years have seen the emergence of promising techniques where (graph) neural\nnetworks have been capable to learn new combinatorial algorithms. The main\nquestion is whether deep learning can learn better heuristics from data, i.e. replacing\nhuman-engineered heuristics? This is appealing because developing algorithms\nto tackle efﬁciently NP-hard problems may require years of research, and many\nindustry problems are combinatorial by nature. In this work, we propose to adapt\nthe recent successful Transformer architecture originally developed for natural\nlanguage processing to the combinatorial TSP. Training is done by reinforcement\nlearning, hence without TSP training solutions, and decoding uses beam search.\nWe report improved performances over recent learned heuristics with an optimal\ngap of 0.004% for TSP50 and 0.39% for TSP100.\n1 Traditional TSP Solvers\nThe TSP was ﬁrst formulated by William Hamilton in the 19th century. The problem states as follows;\ngiven a list of cities and the distances between each pair of cities, what is the shortest possible\npath that visits each city exactly once and returns to the origin city? TSP belongs to the class of\nrouting problems which are used every day in industry such as warehouse, transportation, supply\nchain, hardware design, manufacturing, etc. TSP is an NP-hard problem with an exhaustive search\nof complexity O(n!). TSP is also the most studied combinatorial problem. It has motivated the\ndevelopment of important optimization methods including Cutting Planes [10], Branch-and-Bound\n[4, 16], Local Search [8], Lagrangian Relaxation [12], Simulated Annealing [24].\nThere exist two traditional approaches to tackle combinatorial problems; exact algorithms and\napproximate/heuristic algorithms. Exact algorithms are guaranteed to ﬁnd optimal solutions, but\nthey become intractable when ngrows. Approximate algorithms trade optimality for computational\nefﬁciency. They are problem-speciﬁc, often designed by iteratively applying a simple man-crafted\nrule, known as heuristic. Their complexity is polynomial and their quality depends on an approximate\nratio that characterizes the worst/average-case error w.r.t the optimal solution.\nExact algorithms for TSP are given by exhaustive search, Dynamic or Integer Programming.\nA Dynamic Programming algorithm was proposed for TSP in [ 16] with O( n22n) complex-\nity, which becomes intractable for n > 40. A general purpose Integer Programming (IP)\nsolver with Cutting Planes (CP) and Branch-and-Bound (BB) called Gurobi was introduced in\n[15]. Finally, a highly specialized linear IP+CP+BB, namely Concorde, was designed in [ 2].\nConcorde is widely regarded as the fastest exact TSP solver, for large instances, currently in existence.\narXiv:2103.03012v1  [cs.LG]  4 Mar 2021\nSeveral approximate/heuristic algorithms have been introduced. Christoﬁdes algorithm [7] approxi-\nmates TSP with Minimum Spanning Trees. The algorithm has a polynomial-time complexity with\nO(n2 log n), and is guaranteed to ﬁnd a solution within a factor 3/2 of the optimal solution. Far-\nthest/nearest/greedy insertion algorithms [20] have complexity O(n2), and farthest insertion (the best\ninsertion in practice) has an approximation ratio of 2.43. Google OR-Tools [14] is a highly optimized\nprogram that solves TSP and a larger set of vehicle routing problems. This program applies different\nheuristics s.a. Simulated Annealing, Greedy Descent, Tabu Search, to navigate in the search space,\nand reﬁnes the solution by Local Search techniques. 2-Opt algorithm [27, 21] proposes an heuristic\nbased on a move that replaces two edges to reduce the tour length. The complexity is O(n2m(n)),\nwhere n2 is the number of node pairs and m(n) is the number of times all pairs must be tested to\nreach a local minimum (with worst-case being O(2n/2)). The approximation ratio is 4/√n. Extension\nto 3-Opt move (replacing 3 edges) and more have been proposed in [6]. Finally, LKH-3 algorithm\n[18] introduces the best heuristic for solving TSP. It is an extension of the original LKH [ 28] and\nLKH-2 [17] based on 2-Opt/3-Opt where edge candidates are estimated with a Minimum Spanning\nTree [17]. LKH-3 can tackle various TSP-type problems.\n2 Neural Network Solvers\nIn the last decade, Deep learning (DL) has signiﬁcantly improved Computer Vision, Natural Language\nProcessing and Speech Recognition by replacing hand-crafted visual/text/speech features by features\nlearned from data [26]. For combinatorial problems, the main question is whether DL can learn better\nheuristics from data than hand-crafted heuristics? This is attractive because developing algorithms\nto tackle efﬁciently NP-hard problems require years of research (TSP has been actively studied for\nseventy years). Besides, many industry problems are combinatorial. The last ﬁve years have seen the\nemergence of promising techniques where (graph) neural networks have been capable to learn new\ncombinatorial algorithms with supervised or reinforcement learning. We brieﬂy summarize this line\nof work below.\n•HopﬁeldNets [19]: First Neural Network designed to solve (small) TSPs.\n•PointerNets [39]: A pioneer work using modern DL to tackle TSP and combinatorial optimization\nproblems. This work combines recurrent networks to encode the cities and decode the sequence of\nnodes in the tour, with the attention mechanism. The network structure is similar to [3], which was\napplied to NLP with great success. The decoding is auto-regressive and the network parameters are\nlearned by supervised learning with approximate TSP solutions.\n•PointerNets+RL [5]: The authors improve [39] with Reinforcement Learning (RL) which eliminates\nthe requirement of generating TSP solutions as supervised training data. The tour length is used as\nreward. Two RL approaches are studied; a standard unbiased reinforce algorithm [40], and an active\nsearch algorithm that can explore more candidates.\n•Order-invariant PointerNets+RL [33]: The original network [39] is not invariant by permutations\nof the order of the input cities (which is important for NLP but not for TSP). This requires [39] to\nrandomly permute the input order to let the network learn this invariance. The work [33] solves this\nissue by making the encoder permutation-invariant.\n•S2V-DQN [9]: This model is a graph network that takes a graph and a partial tour as input, and\noutputs a state-valued function Q to estimate the next node in the tour. Training is done by RL\nand memory replay [31], which allows intermediate rewards that encourage farthest node insertion\nheuristic.\n•Quadratic Assignment Problem [34]: TSP can be formulated as a QAP, which is NP-hard and also\nhard to approximate. A graph network based on the powers of adjacency matrix of node distances\nis trained in supervised manner. The loss is the KL distance between the adjacency matrix of the\nground truth cycle and its network prediction. A feasible tour is computed with beam search.\n•Permutation-invariant Pooling Network [23]: This work solves a variant of TSP with multiple\nsalesmen. The network is trained by supervised learning and outputs a fractional solution, which is\ntransformed into a feasible integer solution by beam search. The approach is non-autoregressive, i.e.\nsingle pass.\n•Tranformer-encoder+2-Opt heuristic [11]: The authors use a standard transformer to encode the\ncities and they decode sequentially with a query composed of the last three cities in the partial\ntour. The network is trained with Actor-Critic RL, and the solution is reﬁned with a standard 2-Opt\nheuristic.\n•Tranformer-encoder+Attention-decoder [25]: This work also uses a standard transformer to encode\n2\nFigure 1: Proposed TSP Transformer architecture.\nthe cities and the decoding is sequential with a query composed of the ﬁrst city, the last city in the\npartial tour and a global representation of all cities. Training is carried out with reinforce and a\ndeterministic baseline.\n•GraphConvNet [22]: This work learns a deep graph network by supervision to predict the probabili-\nties of an edge to be in the TSP tour. A feasible tour is generated by beam search. The approach uses\na single pass.\n•2-Opt Learning [41]: The authors design a transformer-based network to learn to select nodes\nfor the 2-Opt heuristics (original 2-Opt may require O(2n/2) moves before stopping). Learning is\nperformed by RL and actor-critic.\n•GNNs with Monte Carlo Tree Search [42]: A recent work based on AlphaGo [35] which augments\na graph network with MCTS to improve the search exploration of tours by evaluating multiple next\nnode candidates in the tour. This improves the search exploration of auto-regressive methods, which\ncannot go back once the selection of the nodes is made.\n3 Proposed Architecture\nWe cast TSP as a “translation” problem where the source “language” is a set of 2D points and\nthe target “language” is a tour (sequence of indices) with minimal length, and adapt the original\nTransformers [37] to solve this problem. We train by reinforcement learning, with the same setting as\n[25]. The reward is the tour length and the baseline is simply updated if the train network improves\nthe baseline on a set of random TSPs. See Figure 1 for a description of the proposed architecture.\nEncoder. It is a standard Transformer encoder with multi-head attention and residual connection. The\nonly difference is the use of batch normalization, instead of layer normalization. The memory/speed\ncomplexity is O(n2). Formally, the encoder equations are (when considering a single head for an\n3\neasier description)\nHenc = Hℓ=Lenc\n∈R(n+1)×d, (1)\nwhere\nHℓ=0 = Concat(z,X) ∈R(n+1)×2,z ∈R2,X ∈Rn×2, (2)\nHℓ+1 = softmax(QℓKℓT\n√\nd\n)Vℓ ∈R(n+1)×d, (3)\nQℓ = HℓWℓ\nQ ∈R(n+1)×d,Wℓ\nQ ∈Rd×d, (4)\nKℓ = HℓWℓ\nK ∈R(n+1)×d,Wℓ\nK ∈Rd×d, (5)\nVℓ = HℓWℓ\nV ∈R(n+1)×d,Wℓ\nV ∈Rd×d, (6)\n(7)\nwhere zis a start token, initialized at random. See Figure 5 for an illustration of the encoder.\nFigure 2: Illustration of encoder.\nDecoder. The decoding is auto-regressive, one city at a time. Suppose we have decoded the ﬁrst t\ncities in the tour, and we want to predict the next city. The decoding process is composed of four\nsteps detailed below and illustrated on Figure 3.\nFigure 3: Illustration of the four decoding steps.\nDecoder – Part 1.The decoding starts with the encoding of the previously selected it city :\nhdec\nt = henc\nit + PEt ∈Rd, (8)\nhdec\nt=0 = hdec\nstart = z+ PEt=0 ∈Rd, (9)\n4\nwhere PEt ∈Rd is the traditional positional encoding in [37] to order the nodes in the tour:\nPEt,i =\n{\nsin(2πfit) if iis even,\ncos(2πfit) if iis odd, with fi = 10,000\nd\n⌊2i⌋\n2π . (10)\nDecoder – Part 2.This step prepares the query using self-attention over the partial tour. The self-\nattention layer is standard and uses multi-head attention, residual connection, and layer normalization.\nThe memory/speed complexity is O(t) at the decoding step t. The equations for this step are (when\nagain considering a single head for an easier description)\nˆhℓ+1\nt = softmax(qℓKℓT\n√\nd\n)Vℓ ∈Rd, ℓ= 0,...,L dec −1 (11)\nqℓ = ˆhℓ\nt ˆWℓ\nq ∈Rd, ˆWℓ\nq ∈Rd×d, (12)\nKℓ = ˆHℓ\n1,t ˆWℓ\nK ∈Rt×d, ˆWℓ\nK ∈Rd×d, (13)\nVℓ = ˆHℓ\n1,t ˆWℓ\nV ∈Rt×d, ˆWℓ\nV ∈Rd×d, (14)\nˆHℓ\n1,t = [ ˆhℓ\n1,.., ˆhℓ\nt], ˆhℓ\nt =\n{ hdec\nt if ℓ= 0\nhq,ℓ\nt if ℓ> 0 . (15)\nDecoder – Part 3.This stage queries the next possible city among the non-visited cities using a\nquery-attention layer. Multi-head attention, residual connection, and layer normalization are used.\nThe memory/speed complexity is O(n) at each recursive step.\nhq,ℓ+1\nt = softmax(qℓKℓT\n√\nd\n⊙Mt)Vℓ ∈Rd, ℓ= 0,...,L dec −1 (16)\nqℓ = ˆhℓ+1\nt ˜Wℓ\nq ∈Rd, ˜Wℓ\nq ∈Rd×d, (17)\nKℓ = Henc ˜Wℓ\nK ∈Rt×d, ˜Wℓ\nK ∈Rd×d, (18)\nVℓ = Henc ˜Wℓ\nV ∈Rt×d, ˜Wℓ\nV ∈Rd×d, (19)\n(20)\nwith Mt is the mask if the visited cities and ⊙is the Hadamard product.\nDecoder – Part 4.This is the ﬁnal step that performs a ﬁnal query using a single-head attention\nto get a distribution over the non-visited cities. Eventually, the next node it+1 is sampled from\nthe distribution using Bernoulli during training and greedy (index with maximum probability) at\ninference time to evaluate the baseline. The memory/speed complexity is O(n). The ﬁnal equation is\npdec\nt = softmax(C.tanh(qKT\n√\nd\n⊙Mt)) ∈Rn, (21)\nq = hq\nt ¯Wq ∈Rd, ¯Wq ∈Rd×d, (22)\nK = Henc ¯WK ∈Rn×d, ¯Wℓ\nK ∈Rd×d, (23)\n(24)\nwhere C = 10.\n4 Architecture Comparison\nComparing Transformers for NLP (translation) vs. TSP (combinatorial optimization), the order of\nthe input sequence is irrelevant for TSP but the order of the output sequence is coded with PEs for\nboth TSP and NLP. TSP-Encoder beneﬁts from Batch Normalization as we consider all cities during\nthe encoding stage. TSP-Decoder works better with Layer Normalization since one vector is decoded\nat a time (auto-regressive decoding as in NLP). The TSP Transformer is learned by Reinforcement\nLearning, hence no TSP solutions/approximations required. Both transformers for NLP and TSP\nhave quadratic complexity O(n2L).\nComparing with the closed neural network models of [25] and [11], we use the same transformer-\nencoder (with BN) but our decoding architecture is different. We construct the query using all\n5\ncities in the partial tour with a self-attention module. [25] use the ﬁrst and last cities with a global\nrepresentation of all cities as the query for the next city. [11] deﬁne the query with the last three cities\nin the partial tour. Besides, our decoding process starts differently. We add a token city z∈R2. This\ncity does not exist and aims at starting the decoding at the best possible location by querying all cities\nwith a self-attention module. [25] starts the decoding with the mean representation of the encoding\ncities and a random token of the ﬁrst and current cities. [ 11] starts the decoding with a random token\nof the last three cities.\n5 Decoding Technique\nGiven a set X ∈Rn×2 of 2-D cities, a tour is represented as an ordered sequence of city indices :\nseqn = {i1,i2,...,i n}and TSP can be cast as a sequence optimization problem:\nmax\nseqn={i1,...,in}\nPTSP(seqn|X) = PTSP(i1,...,i n|X). (25)\nFor auto-regressive decoding, i.e. selecting a city one at a time, PTSP can be factorized with the chain\nrule:\nPTSP(i1,...,i n|X) = P(i1|X) ·P(i2|i1,X) ·P(i3|i2,i1,X) ·... ·P(in|in−1,in−2,...,X ). (26)\nHence the decoding problem aims at ﬁnding the sequence i1,i2,...,i n that maximizes the objective:\nmax\ni1,...,in\nΠn\nt=1 P(it|it−1,it−2,...i1,X). (27)\nFinding exactly the optimal sequence by exhaustive search is intractable given the O(n!) complexity,\nand approximations are necessary. The simplest approximate search is the greedy search; at each\ntime step, the next city is selected with the highest probability:\nit = arg max\ni\nP(i|it−1,it−2,...i1,X) (28)\nThe complexity is linear O(n).\nBetter sampling techniques such as beam search or Monte Carlo Tree Search (MTCS) are known to\nimprove results over greedy search in NLP [36] and TSP [34, 23, 25, 22, 41, 42]. Their complexity\nis O(Bn), where Bis the number of beams or explored paths. Beam search [ 29] is a breadth-ﬁrst\nsearch (BFS) technique where the breath has a limited size B. the beam search decoding problem is\nas follows:\nmax\n{ib\n1,...,ibn}B\nb=1\nΠB\nb=1 P(ib\n1,...,i b\nn|X) s.t. {ib\n1,...,i b\nn}̸= {ib′\n1 ,...,i b′\nn }, ∀b̸= b′ (29)\nFor B = 1, the solution is given by greedy decoding. For B >1, the solution at tis determined by\nconsidering all possible extensions of Bbeams, and only keeping the Top-Bprobabilities :\n{ib\n1,...,i b\nt}B\nb=1 = Top-B\n{\nΠt\nk=1 P(ib\nk|ib\nk−1,ib\nk−2,...,i b\n1,X)\n}B.(n−t)\nb=1\n, (30)\nor equivalently (for better numerical stabilities) :\n{ib\n1,...,i b\nt}B\nb=1 = Top-B\n{ t∑\nk=1\nlog P(ib\nk|ib\nk−1,ib\nk−2,...,i b\n1,X)\n}B.(n−t)\nb=1\n. (31)\n6 Numerical Experiments\nWe compare the proposed architecture with existing methods in Table 1. Our test set is composed of\n10k TSP50 and TSP100. Concorde[1] run on Intel Xeon Gold 6132 CPU and the Transformers run on\nNvidia 2080Ti GPU. Our code is available on GitHub https://github.com/xbresson/TSP_Transformer.\nExperimental complexity for the inference time for a single TSP is presented on Figure 4.\n6\nTSP50 TSP100\nMethod Obj Gap T Time I Time Obj Gap T Time I Time\nMIP\nConcorde [2] 5.689 0.00% 2m* 0.05s 7.765 0.00% 3m* 0.22s\nGurobi [15] - 0.00%* 2m* - 7.765* 0.00%* 17m* -\nHeuristic\nNearest insertion 7.00* 22.94%* 0s* - 9.68* 24.73%* 0s* -\nFarthest insertion [20]6.01* 5.53%* 2s* - 8.35* 7.59%* 7s* -\nOR tools [14] 5.80* 1.83%* - - 7.99* 2.90%* - -\nLKH-3 [18] - 0.00%* 5m* - 7.765* 0.00%* 21m* -\nNeural Network\nGreedy Sampling\nVinyals et-al [39] 7.66* 34.48%* - - - - - -\nBello et-al [5] 5.95* 4.46%* - - 8.30* 6.90%* - -\nDai et-al [9] 5.99* 5.16%* - - 8.31* 7.03%* - -\nDeudon et-al [11] 5.81* 2.07%* - - 8.85* 13.97%* - -\nKool et-al [25] 5.80* 1.76%* 2s* - 8.12* 4.53%* 6s* -\nKool et-al [25] (our version)- - - - 8.092 4.21% - -\nJoshi et-al [22] 5.87 3.10% 55s - 8.41 8.38% 6m -\nOur model 5.707 0.31% 13.7s 0.07s 7.875 1.42% 4.6s 0.12s\nNeural Network\nAdvanced Sampling\nKool et-al [25] (B=1280)5.73* 0.52%* 24m* - 7.94* 2.26%* 1h* -\nKool et-al [25] (B=5000)5.72* 0.47%* 2h* - 7.93* 2.18%* 5.5h* -\nJoshi et-al [22] (B=1280)5.70 0.01% 18m - 7.87 1.39% 40m -\nXing et-al [42] (B=1200)- 0.20%* - 3.5s* - 1.04%* - 27.6s*\nWu et-al [41] (B=1000)5.74* 0.83%* 16m* - 8.01* 3.24%* 25m* -\nWu et-al [41] (B=3000)5.71* 0.34%* 45m* - 7.91* 1.85%* 1.5h* -\nWu et-al [41] (B=5000)5.70* 0.20%* 1.5h* - 7.87* 1.42%* 2h* -\nOur model (B=100) 5.692 0.04% 2.3m 0.09s 7.818 0.68% 4m 0.16s\nOur model (B=1000)5.690 0.01% 17.8m 0.15s 7.800 0.46% 35m 0.27s\nOur model (B=2500)5.689 4e-3% 44.8m 0.33s 7.795 0.39% 1.5h 0.62s\nTable 1: Comparison with existing methods. Results with * are reported from other papers. T Time\nmeans total time for 10k TSP (in parallel). I Time means inference time to run a single TSP (in\nserial).\nFigure 4: Experimental complexity.\n7 Discussion\nIn this work, we essentially focused on the architecture. We observe that the Transformer architecture\ncan be successful to solve the TSP Combinatorial Optimization problem, expanding the success\nof Transformer for NLP and CV . It also improves recent learned heuristics with an optimal gap of\n0.004% for TSP50 and 0.39% for TSP100.\nFurther developments can be considered with better sampling techniques such as group beam-search\n[38, 30] or MCTS [42] which are known to improve results. Besides, the use of heuristics like 2-Opt\nto get intermediate rewards has also shown improvements [ 41] (the tour length as global reward\nrequires to wait the end of the tour construction).\nHowever, traditional solvers like Concorde/LKH-3 still outperform learning solvers in terms of\nperformance and generalization, although neural network solvers offer faster inference time, O(n2L)\nvs. O(n2.5b(n)), where O(b(n)) is the number of branches to explore in BB.\nWhat’s next? The natural next step is to scale to larger TSP sizes forn> 100 but it is challenging as\nGPU memories are limited, and Transformer architectures and auto-regressive decoding are in O(n2).\n7\nFigure 5: Visualization of TSP100 instances.\nWe could consider “harder” TSP/routing problems where traditional solvers like Gurobi/LKH-3 can\nonly provide weaker solutions or would take very long to solve. We could also work on “harder”\ncombinatorial problems where traditional solvers s.a. Gurobi cannot be used.\nAnother attractive research direction is to leverage learning techniques to improve traditional solvers.\nFor example, traditional solvers leverage Branch-and-Bound technique [4, 16]. Selecting the variables\nto branch is critical for search efﬁciency, and relies on human-engineered heuristics s.a. Strong\nBranching [1] which is a high-quality but expensive branching rule. Recent works [ 13, 32] have\nshown that neural networks can be successfully used to imitate expert heuristics and speed-up the BB\ncomputational time. Future work may focus on going beyond imitation of human-based heuristics,\nand learning novel heuristics for faster Branch-and-Bound technique.\n8 Conclusion\nThe ﬁeld of Combinatorial Optimization is pushing the limit of deep learning. Traditional solvers still\nprovide better solutions than learning models. However, traditional solvers have been studied since\nthe 1950s and the interest of applying deep learning to combinatorial optimization has just started.\nThis topic of research will naturally expend in the coming years as combinatorial problems problems\ns.a. assignment, routing, planning, scheduling are used every day by companies. Novel software may\nalso be developed that combine continuous, discrete optimization and learning techniques.\n9 Acknowledgement\nXavier Bresson is supported by NRF Fellowship NRFF2017-10.\nReferences\n[1] Tobias Achterberg, Thorsten Koch, and Alexander Martin. 2005. Branching rules revisited.\nOperations Research Letters 33, 1 (2005), 42–54.\n[2] David L Applegate, Robert E Bixby, Vasek Chvatal, and William J Cook. 2006.The traveling\nsalesman problem: a computational study. Princeton university press.\n[3] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by\njointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).\n8\n[4] Richard Bellman. 1962. Dynamic programming treatment of the travelling salesman problem.\nJournal of the ACM (JACM)9, 1 (1962), 61–63.\n[5] Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. 2016. Neural\ncombinatorial optimization with reinforcement learning. arXiv preprint arXiv:1611.09940\n(2016).\n[6] Andrius Blazinskas and Alfonsas Misevicius. 2011. combining 2-opt, 3-opt and 4-opt with\nk-swap-kick perturbations for the traveling salesman problem. Kaunas University of Technology,\nDepartment of Multimedia Engineering, Studentu St (2011), 50–401.\n[7] Nicos Christoﬁdes. 1976. Worst-case analysis of a new heuristic for the travelling sales-\nman problem. Technical Report. Carnegie-Mellon Univ Pittsburgh Pa Management Sciences\nResearch Group.\n[8] Georges A Croes. 1958. A method for solving traveling-salesman problems. Operations\nresearch 6, 6 (1958), 791–812.\n[9] Hanjun Dai, Elias B Khalil, Yuyu Zhang, Bistra Dilkina, and Le Song. 2017. Learning\ncombinatorial optimization algorithms over graphs. arXiv preprint arXiv:1704.01665 (2017).\n[10] George Dantzig, Ray Fulkerson, and Selmer Johnson. 1954. Solution of a large-scale traveling-\nsalesman problem. Journal of the operations research society of America2, 4 (1954), 393–410.\n[11] Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yossiri Adulyasak, and Louis-Martin\nRousseau. 2018. Learning heuristics for the tsp by policy gradient. In International conference\non the integration of constraint programming, artiﬁcial intelligence, and operations research.\nSpringer, 170–181.\n[12] Marshall L Fisher. 1981. The Lagrangian relaxation method for solving integer programming\nproblems. Management science 27, 1 (1981), 1–18.\n[13] Maxime Gasse, Didier Chételat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. 2019. Exact\nCombinatorial Optimization with Graph Convolutional Neural Networks. InAdvances in Neural\nInformation Processing Systems, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer,\nFlorence d’Alché-Buc, Emily B. Fox, and Roman Garnett (Eds.). 15554–15566.\n[14] Google. 2015. OR-tools: Google’s Operations Research tools.\n[15] Z Gu, E Rothberg, and R Bixby. 2008. Gurobi.\n[16] Michael Held and Richard M Karp. 1962. A dynamic programming approach to sequencing\nproblems. Journal of the Society for Industrial and Applied mathematics10, 1 (1962), 196–210.\n[17] Keld Helsgaun. 2000. An effective implementation of the Lin–Kernighan traveling salesman\nheuristic. European Journal of Operational Research126, 1 (2000), 106–130.\n[18] Keld Helsgaun. 2017. An extension of the Lin-Kernighan-Helsgaun TSP solver for constrained\ntraveling salesman and vehicle routing problems. Roskilde: Roskilde University (2017).\n[19] John J Hopﬁeld and David W Tank. 1985. “Neural” computation of decisions in optimization\nproblems. Biological cybernetics 52, 3 (1985), 141–152.\n[20] David S Johnson. 1990. Local optimization and the traveling salesman problem. InInternational\ncolloquium on automata, languages, and programming. Springer, 446–461.\n[21] S Johnson David and A McGeoch Lyle. 1995. The Travelling Saleman Problem: A case study\nin Local Optimization. AT&T Labs, Florham Park, Department of Mathematics and Computer\nScience, Amherst College (1995).\n[22] Chaitanya K Joshi, Thomas Laurent, and Xavier Bresson. 2019. An efﬁcient graph convolutional\nnetwork technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227\n(2019).\n9\n[23] Yoav Kaempfer and Lior Wolf. 2018. Learning the multiple traveling salesmen problem with\npermutation invariant pooling networks. arXiv preprint arXiv:1803.09621 (2018).\n[24] Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. 1983. Optimization by simulated\nannealing. science 220, 4598 (1983), 671–680.\n[25] Wouter Kool, Herke Van Hoof, and Max Welling. 2018. Attention, learn to solve routing\nproblems! arXiv preprint arXiv:1803.08475 (2018).\n[26] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature 521, 7553\n(2015), 436–444.\n[27] Shen Lin. 1965. Computer solutions of the traveling salesman problem. Bell System Technical\nJournal 44, 10 (1965), 2245–2269.\n[28] Shen Lin and Brian W Kernighan. 1973. An effective heuristic algorithm for the traveling-\nsalesman problem. Operations research 21, 2 (1973), 498–516.\n[29] Bruce T Lowerre. 1976. The HARPY speech recognition system. Ph. D. Thesis (1976).\n[30] Clara Meister, Tim Vieira, and Ryan Cotterell. 2020. Best-ﬁrst beam search. Transactions of\nthe Association for Computational Linguistics 8 (2020), 795–809.\n[31] V olodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan\nWierstra, and Martin Riedmiller. 2013. Playing atari with deep reinforcement learning. arXiv\npreprint arXiv:1312.5602 (2013).\n[32] Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid von Glehn, Pawel Lichocki, Ivan Lobov,\nBrendan O’Donoghue, Nicolas Sonnerat, Christian Tjandraatmadja, Pengming Wang, Ravichan-\ndra Addanki, Tharindi Hapuarachchi, Thomas Keck, James Keeling, Pushmeet Kohli, Ira Ktena,\nYujia Li, Oriol Vinyals, and Yori Zwols. 2020. Solving Mixed Integer Programs Using Neural\nNetworks. CoRR abs/2012.13349 (2020).\n[33] Mohammadreza Nazari, Afshin Oroojlooy, Lawrence V Snyder, and Martin Takáˇc. 2018. Rein-\nforcement learning for solving the vehicle routing problem. arXiv preprint arXiv:1802.04240\n(2018).\n[34] Alex Nowak, Soledad Villar, Afonso S Bandeira, and Joan Bruna. 2017. A note on learning\nalgorithms for quadratic assignment with graph neural networks. stat 1050 (2017), 22.\n[35] David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driess-\nche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. 2016.\nMastering the game of Go with deep neural networks and tree search. nature 529, 7587 (2016),\n484–489.\n[36] Christoph Tillmann and Hermann Ney. 2003. Word reordering and a dynamic programming\nbeam search algorithm for statistical machine translation. Computational linguistics 29, 1\n(2003), 97–133.\n[37] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. arXiv preprint\narXiv:1706.03762 (2017).\n[38] Ashwin K Vijayakumar, Michael Cogswell, Ramprasath R Selvaraju, Qing Sun, Stefan Lee,\nDavid Crandall, and Dhruv Batra. 2016. Diverse beam search: Decoding diverse solutions from\nneural sequence models. arXiv preprint arXiv:1610.02424 (2016).\n[39] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. 2015. Pointer networks. arXiv preprint\narXiv:1506.03134 (2015).\n[40] Ronald J Williams. 1992. Simple statistical gradient-following algorithms for connectionist\nreinforcement learning. Machine learning 8, 3-4 (1992), 229–256.\n[41] Yaoxin Wu, Wen Song, Zhiguang Cao, Jie Zhang, and Andrew Lim. 2019. Learning improve-\nment heuristics for solving routing problems. arXiv preprint arXiv:1912.05784 (2019).\n[42] Zhihao Xing and Shikui Tu. 2020. A graph neural network assisted Monte Carlo tree search\napproach to traveling salesman problem. IEEE Access 8 (2020), 108418–108428.\n10",
  "concepts": [
    {
      "name": "Travelling salesman problem",
      "score": 0.8110121488571167
    },
    {
      "name": "Heuristics",
      "score": 0.7581722736358643
    },
    {
      "name": "Simulated annealing",
      "score": 0.667122483253479
    },
    {
      "name": "Combinatorial optimization",
      "score": 0.6194247007369995
    },
    {
      "name": "Computer science",
      "score": 0.6082941293716431
    },
    {
      "name": "Reinforcement learning",
      "score": 0.5475425124168396
    },
    {
      "name": "Lagrangian relaxation",
      "score": 0.5069675445556641
    },
    {
      "name": "Mathematical optimization",
      "score": 0.5012814998626709
    },
    {
      "name": "Transformer",
      "score": 0.499875545501709
    },
    {
      "name": "Artificial intelligence",
      "score": 0.44013458490371704
    },
    {
      "name": "Artificial neural network",
      "score": 0.4344840347766876
    },
    {
      "name": "2-opt",
      "score": 0.4193718433380127
    },
    {
      "name": "Graph",
      "score": 0.41651663184165955
    },
    {
      "name": "Theoretical computer science",
      "score": 0.39153772592544556
    },
    {
      "name": "Machine learning",
      "score": 0.24078401923179626
    },
    {
      "name": "Mathematics",
      "score": 0.23823747038841248
    },
    {
      "name": "Algorithm",
      "score": 0.213184654712677
    },
    {
      "name": "Engineering",
      "score": 0.1304614543914795
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ],
  "topic": "Travelling salesman problem",
  "institutions": [
    {
      "id": "https://openalex.org/I172675005",
      "name": "Nanyang Technological University",
      "country": "SG"
    },
    {
      "id": "https://openalex.org/I35566140",
      "name": "Loyola Marymount University",
      "country": "US"
    }
  ]
}