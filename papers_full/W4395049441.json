{
  "title": "Augmented non-hallucinating large language models as medical information curators",
  "url": "https://openalex.org/W4395049441",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2143148888",
      "name": "Stephen Gilbert",
      "affiliations": [
        "Fresenius (Germany)",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": [
        "Fresenius (Germany)",
        "TU Dresden"
      ]
    },
    {
      "id": "https://openalex.org/A2136710978",
      "name": "Aidan Hogan",
      "affiliations": [
        "University of Chile",
        "Millennium Institute for Integrative Biology"
      ]
    },
    {
      "id": "https://openalex.org/A2143148888",
      "name": "Stephen Gilbert",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2056217728",
      "name": "Jakob Nikolas Kather",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2136710978",
      "name": "Aidan Hogan",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2099813385",
    "https://openalex.org/W3120224639",
    "https://openalex.org/W4389992604",
    "https://openalex.org/W2969628488",
    "https://openalex.org/W3106811464",
    "https://openalex.org/W4324372992",
    "https://openalex.org/W3113300158",
    "https://openalex.org/W3010336026",
    "https://openalex.org/W2404369708",
    "https://openalex.org/W3080429061",
    "https://openalex.org/W4382246105",
    "https://openalex.org/W4379769651",
    "https://openalex.org/W4387500346",
    "https://openalex.org/W4226510082",
    "https://openalex.org/W4384890810",
    "https://openalex.org/W4387744047",
    "https://openalex.org/W4389792145",
    "https://openalex.org/W4388775426",
    "https://openalex.org/W4382678522",
    "https://openalex.org/W4386225382",
    "https://openalex.org/W4385848430",
    "https://openalex.org/W4376641278",
    "https://openalex.org/W4318983406",
    "https://openalex.org/W4297183943",
    "https://openalex.org/W4285020859",
    "https://openalex.org/W4385381606",
    "https://openalex.org/W4390919221",
    "https://openalex.org/W4367672504",
    "https://openalex.org/W4391221150",
    "https://openalex.org/W4387767115"
  ],
  "abstract": null,
  "full_text": "npj |digital medicine News & Views\nPublished in partnership with Seoul National University Bundang Hospital\nhttps://doi.org/10.1038/s41746-024-01081-0\nAugmented non-hallucinating large\nlanguage models as medical information\ncurators\nCheck for updates\nStephen Gilbert 1,4 , Jakob Nikolas Kather1,4 & Aidan Hogan 2,3\nReliably processing and interlinking medical information has been recognized as a critical foundation to the\ndigital transformation of medical workﬂows, and despite the development of medical ontologies, the optimi-\nzation of these has been a major bottleneck to digital medicine. The advent of large language models has\nbrought great excitement, and maybe a solution to the medicines’‘communication problem’is in sight, but how\ncan the known weaknesses of these models, such as hallucination and non-determinism, be tempered?\nRetrieval Augmented Generation, particularly through knowledge graphs, is an automated approach that can\ndeliver structured reasoning and a model of truth alongside LLMs, relevant to information structuring and\ntherefore also to decision support.\nThe ‘semantics problem in medicine’, otherwise known as medicine’s\n‘communication problem’refers to the difﬁcult task of reliably recording\nmedical information and making it interoperable between systems1,2.T h i s\nproblem is not an obscure issue affecting only researchers or a highly\ntechnical problem only of relevance to software system developers. It affects\nthe day to day linking of medical information, between medical IT systems\nby healthcare providers (HCPs) and creates challenges in the automation of\nmedical tasks for and by HCPs and applies to all medical roles and\nspecialisms\n3.T h e‘semantics problem’contributes to the burden of medical\ndocumentation, with tasks taking longer than they would with interoperable\nmedical information systems3,4. Previous approaches to address this chal-\nlenge have included the interrelated technologies of medical ontologies and\nmedical knowledge graphs (KGs). Medical ontologies capture the consensus\non a diverse range of concepts in the biomedical domain\n5.L e a d i n go n t o l -\nogies include SNOMED CT6,w h i c hd eﬁnes clinical terminology, and the\nhuman phenotype ontology (HPO 7), which describes phenotypic\nabnormalities, but the ambiguity and contextual richness of medical\ninformation poses challenges to their adoption\n2,8. Ambiguity results from\npractitioners and patients referring to concepts in diverse ways (e.g., a‘cold’\nversus ‘acute rhinitis’ or ‘acute viral respiratory infection’), and from\nsituations where terms have different meanings in different contexts, e.g.\n‘cold’ can relate to the clinical measurement of body temperature, or\nenvironmental conditions, or to a clinical syndrome‘acute rhinitis’or to a\nsub-component of various pathological conditions‘cold [sores]/[agglutinin\ndisease]’\n9. The contextual richness of information in human communica-\ntion results in clinical records being easily understandable and full of useful\nnuanced information for HCPs but being very challenging to interpret\nthrough computational means9. The expressive power of human commu-\nnication, with its contextual richness, also poses the same problem for\nKnowledge graphs (KGs), but these provide more delineated and curated\nrepositories of knowledge\n10. KGs create a network of real-world entities,\nrepresented as nodes, and the relationships that exist between them,\nrepresented as edges; for example, two nodes in a KG referring to“COVID-\n19”and“fever”m a yb el i n k e db ya ne d g el a b e l e d“has symptom”. Presenting\nknowledge in a structured form further allows KGs to be queried as graph\ndatabases\n10. Many KGs further express machine-readable semantics, in the\nform of ontologies, rules, etc., that allows for deductive reasoning to derive\nnew knowledge while preserving truth\n10. The medical ontologies discussed\nearlier can thus be considered medical KGs with well-deﬁned semantics11,\nand are already in use for a variety of applications in medicine, albeit as a\nsimpliﬁed and narrow representation of medical information\n11.T h ea r g u -\nment we develop is that, although medical ontologies and KGs are inﬂexible,\nand are even sometimes gross simpliﬁcations, that through the power of\ncombination, and where applied in use cases where a veriﬁable record of\n‘truth is needed’, they provide a means to bring the necessary control and\ntemperament to augment the moreﬂexible approaches of large language\nmodels (LLM)s. All models are wrong, some are useful and intelligent\ncombinations of imperfect models may be what the doctor has ordered for\nthe certain critical medical summarization tasks, to translate medical\ninformation between free, contextually rich human modes of commu-\nnication and certain rigid record structures that must limit context and\nmaximize factual simpliﬁcation and precision.\n1Else Kröner Fresenius Center for Digital Health, TUD Dresden University of Technology, Dresden, Germany.2Department of Computer Science, Universidad de\nChile, Santiago, Chile.3Millennium Institute for Foundational Research on Data, DCC, Universidad de Chile, Santiago, Chile.4These authors contributed equally:\nStephen Gilbert, Jakob Nikolas Kather. e-mail: stephen.gilbert@tu-dresden.de\nnpj Digital Medicine|           (2024) 7:100 1\n1234567890():,;\n1234567890():,;\nWhy does medicine’s ‘communication problem’ persist\nand how can it be solved?\nMedical information often resides in unstructured natural language that is\ndifﬁcult for information systems to process2,8, and despite advances in\ninformation structuring through deep learning12,t h e‘communication\nproblem’remains signiﬁcant.\nIt has been proposed that the technological advances brought by large\nlanguage models, which have been transformative in many areas of society\nsince 2022, will bring highly signiﬁcant advances, perhaps even solutions to\nsemantic “communication problems” in many ﬁelds, including\nmedicine13,14. LLMs are deep learning-based models trained on massive\ncorpora of text to provide probabilistic autocompletion of withheld\nwords\n15,16. Fine-tuned with human feedback via reinforcement learning\nfrom human feedback (RHLF) or other procedures, LLMs can generate\nresponses to prompts considered plausible to humans, powering con-\nversational agents17. They also demonstrate a remarkable ability to structure\nand categorize information13, including in medicine18–20. However, LLMs\nexhibit bias, hallucinations, and inaccuracies, which, when twinned with\nplausible responses presented with ostensible certainty, can mislead users,\ncasting doubts about their suitability for many tasks in clinical medicine\nincluding the interoperability and linking of medical knowledge\n21,22.T h i s\nraises the question: how can the strengths of LLMs be delivered for orga-\nnizing information in healthcare in a manner that tames their weaknesses?\nWe describe the potential of augmenting LLMs with other data technolo-\ngies, including KGs, to address digital medicine’s communication problem.\nSmoothing out the limitations of LLMs\nAlthough LLMs are a remarkable advance, they lack a model of truth, and\nhave limited ability to reliably check their own accuracy23. An intriguing\nfeature of LLMs and KGs is that they are complementary in many of their\nstrengths and weaknesses (Table1)\n24. This complementarity opens the\npossibility of combining the approaches, to create a‘dream team’approach\nto medical information processing and communications.\nThere are numerous conceptualapproaches to combine LLMs and\nKGs: using LLMs to enhance KGs, using KGs to enhance LLMs, and\ncombining LLMs and KGs in a holistic manner\n24.I nt h eﬁrst approach,\nLLMs can be used to construct, enrich and reﬁne KGs from text, leveraging\nLLMs’ability to extract and recognize structure (Fig.1a), e.g., as has been\napplied in the construction of dietary KGs25 and KGs for precision\nmedicine26.T h i si sa ni m p o r t a n ta p p l i c a t i o n ,a n di ti l l u s t r a t e sh o wm o d e r n\nKGs are generated ef ﬁciently through automated machine learning\napproaches, and not the output of laborious and non-scalable manual\napproaches. In the second category, which is a form of retrieval augmented\ngeneration (RAG), KGs can be used to augment LLMs by enriching\nprompts, verifying, or explaining responses (Fig.1b), e.g., as has been\napplied in medicine for delivering explainable outputs\n27. In a second form of\nRAG, LLMs and KGs can be used side-by-side or be hybridized to address\nparticular tasks (Fig.1c), e.g.: (i) for answering medical queries\n28;a n d ,( i i )\nSapBert28 which combines a language model trained over PubMed with\nknowledge from the Uniﬁed Medical Language System (UMLS) ontology.\nThough the area is in its infancy, these works illustrate directions in which\nresearch on combining LLMs and KGs for digital medicine will evolve in the\ncoming years. A related approach is known as vector embedding, which is\nalso a form of RAG but does not use KGs, and instead uses the unstructured\ninformation collected from medical websites (Fig.1b, c). We do not focus on\nthis approach as it does not use LLMs for chain of reasoning and therefore\nlacks much of the complementary to LMMs that KG approaches have\n(Table 1).\nSummary\nHow will combined LLM and KG approaches evolve? These approaches\ncould be the enabler of robust digital twins of individual patients (i.e.,\nrepresentations of up-to-date individual patient data in digital form, serving\nas a record of patient health and enablingpersonalized predictive analytics)\nwith LLMs used to rapidly create stable individual patient KGs as stable\nrobust data structures, which could be used to augment and verify data\nTable 1 | The combination of LLMs and knowledge graphs (KGs) has the potential for complementarity\nProperty Large language\nmodel (LLM) alone\nAdvantage (+) Dis-\nadvantage (-) Neu-\ntral (=)\nKnowledge graph\n(KG) alone\nAdvantage (+) Dis-\nadvantage (-) Neu-\ntral (=)\nLarge language model with Retrieval\nAugmented Generation (RAG)\nthrough Knowledge\nGraph (LLM+ KG)\nHallucination High – None + Complementarity\nOpaqueness High – Low + Complementarity\nStaleness High1 – Neutral = none\nBias High – Neutral = none\nCosts High – Neutral = none\nShort tailed Substantially1 – Low + Complementarity\nSanitized Highly2 – Low + Complementarity\nNon-deterministic Highly – Low + Complementarity\nIndecisiveness Highly – Low + Complementarity\nUsability High + Low – Complementarity\nContextual interpretation\nand reasoning\nLimited to moderate + None – Complementarity\nSuitability/approvability\nfor medical informa-\ntion tasks\nOnly for low-\nrisk tasks\n– Only tasks not\nrequiring contextual\nreasoning\n– Complementarity— potentially for\nmoderate risk tasks needing con-\ntextual reasoning\nComparison of the limiting properties of Large Language Models alone and Knowledge Graphs alone to the complementarity of fusing these approaches.\nThe terms describing the algorithmic approaches are deﬁned as follows:hallucination: invention of plausible facts;opaqueness: lack of explanation or provenance for responses;staleness: outdatedness of\ninformation; bias: under representation or lower accuracy of data on patient groups or condition types, or, repetition of known cultural often racist stereotypes fromdata; costs: energy costs and ethical\ncosts related to manual labeling tasks in training;short tailed: good performance in oft-discussed topics in the training data, but not good in deep technical knowledgeﬁelds (unlessﬁne-tuned); sanitized:\nsome general purpose models are constrained to avoid controversial responses that may include important topics in medicine;non-deterministic: responses can vary depending on time, phrasing of a\nprompt, language, etc.;Indecisiveness: inability to make decisive choices when faced with ambiguous or contradictory input; Usability: the ease of human interaction;contextual interpretation and\nreasoning: the ability to provide more than simple factual answers, along with contextual and reasoning insights;Suitability/approvability for medical information tasks: an assessment of the types of tasks\nfor which approaches are suited, and their approvability under current national and international medical devices frameworks; Some listed properties relate to currently described large language models but\nare only partially inherent (1) or are not inherent (2) to the underlying approach.\nhttps://doi.org/10.1038/s41746-024-01081-0 News & Views\nnpj Digital Medicine|           (2024) 7:100 2\nFig. 1 | The combination of large language models with KGs, including in\nretrieval augmented generation (RAG). aLLMs can be used to automate the\nconstruction, enrichment and reﬁnement of KGs from text queries, which can be\ngenerated from medical information systems;b RAG augments the performance of\nlarge language models (LLMs) through searching in either unstructured web-based\nknowledge bases (in vector embedding), or information retrieval from knowledge\ngraphs, and using the output to reﬁne LLM prompting;c in more sophisticated\napproaches to RAG, LLMs and KGs (or vector embedding) can be used side-by-side\nor be hybridized to address medical information reasoning tasks. Icons created by\nthe authors, I Putu Kharismayadi, Lucas Rathgeb and Nubaia Karim Barshafrom\nfrom the Noun Project (https://thenounproject.com/).\nhttps://doi.org/10.1038/s41746-024-01081-0 News & Views\nnpj Digital Medicine|           (2024) 7:100 3\ninterpreted by LLMs from newly conducted consultations. This approach\nwould have the potential to reduce the environmental impact of LLMs, as\nhistorical information from‘legacy’non-structured health records could be\ncodiﬁed once for a patient, creating a‘twin’, the information from which\nwould be retrievable at little computational cost, which would be updated\nthrough LLM approaches only when needed.\nEven combining LLMs and KGs may still result in important inac-\ncuracies when used to automate medical information tasks. The features of\nthese technologies to enhance the ability of the physician to process this\ninformation and to reach medical decisions will be critical. These could\ninclude the design of interfaces for quality control and for sign off, as have\nbeen designed in on-market LLM-based products (such as Microsoft’s\nNuance Dragon Experience) and differential labeling of the degree of\nreliability of interpreted information, toﬂag when information should be\nmanually veriﬁed.\nAlthough LLMs have been rapidly applied in on-market products for\nmedical information management (including information retrieval, struc-\nturing and interlinking, e.g., as shown by Microsoft’s early addition of GPT-\n4-based voice-to-SNOMED CT in Microsoft Nuance Dragon Experience),\nmany questions still remain about their accuracy and appropriateness for\nthis task\n21. One of the most interesting questions for their use in medicine is\nhow to optimize their strengths while curbing weaknesses. Here regulators\nand policy makers need to adopt a degree of healthy skepticism whilst also\nacknowledging the transformative potential of these technologies. Some\nhave challenged whether LLMs can ever have medical application due to\ntheir weaknesses, whilst others have described the very challenging pathway\nto regulatory approval of existing LLM tools for use in diagnostic or ther-\napeutic decision making\n22,29 (Table1,F i g .2), but many of the limitations of\nLLMs in isolation are at least partially resolved through their augmentation\nwith vector embedding or KGs. On the other side of the argument, some\nhave proposed that LLM approaches alone, perhaps based on medical\nspeciﬁc training sets, more data, and reﬁnement of their core approach, can\nattain the accuracy needed for truly automated clinical documentation, and\neven for medical decision making\n14, and that fallback to older approaches\nmay not be needed (Fig.2). We are of the view that RAG approaches,\nparticularly augmenting LLMs with KGs, and with interactive back-and-\nforward complementarity, show promise to better serve medicine, parti-\ncularly in tasks where accuracy and bias control are critical.\nIn what seems like an alternative view to that presented here, a\nmodel of three epochs of AI has been recently described: (i) AI 1.0\nSymbolic AI and probabilistic models (including KGs); (ii) AI 2.0 Deep\nlearning; and, (iii) AI 3.0 Foundation models\n30.T h e‘cross epoch model\nwe describe may seem naive— surely the newer concepts must replace\nthe earlier? The advancement of technology, practice, and governance\noften integrates earlier and later concepts and this is rational when\nthe earlier technologies have complementary strengths. It is certainly\ntrue that the limitations of insuf ﬁciently automated approaches to\ndeveloping KGs, which had a constant risk of human logic errors and\ndeveloper bias encoded in their rules\n30 must be replaced by hybrid\nautomated KG generation through LLMs and deep learning26. In the end,\nonly time will show if KGs themselves, and hybrid approaches for\naugmenting LLMs with KG, are technologies with sticking power.\nVector embedding approaches for RAG are currently the leading area of\nresearch in the augmentation of LLMs for general and medical\npurposes\n31. They do not yet provide the veriﬁable ‘model of truth’that is\ncalled for in many medical information recording tasks. Vector\nembedding approaches may continue to develop and, and ultimately\nreach a level of performance, accuracy and repeatability that removes the\nadvantage of KG-based RAG, as set out in Table1. It is our view that\nthere will be a range of RAG approaches, selected on the needs of speciﬁc\nclinical use cases (including regulatory considerations), that will harness\nthe power of LLMs, enabling them to ultimately solve medicine ’s\n‘communication problem’. Although challenges remain inﬁnding the\nright regulatory balance in oversight of these tools\n22, and in the control of\ntheir environmental impact, it looks certain that HCPs graduating now\nwill enjoy highly interoperable tools and access to clinical information\nsummarization that, only 5 years before, were unthinkable.\nReceived: 18 January 2024; Accepted: 14 March 2024;\nReferences\n1. Schulze-Kremer, S. & Smith, B. Ontologies for the life sciences in\nEncyclopedia of Genetics, Genomics, Proteomics and Bioinformatics,\nVol. 4 (John Wiley and Sons, New York and London, 2005).\n2. Hu, X. In Computational Systems Biology(eds. Kriete, A. & Eils, R.) Ch.\n3 (Academic Press, Burlington, 2006).\n3. Moy, A. J. et al. Measurement of clinical documentation burden\namong physicians and nurses using electronic health records: a\nscoping review.J. Am. Med. Inform. Assoc.28, 998–1008 (2021).\n4. Welzel, C. et al. Holistic human-serving digitization of health care\nneeds integrated automated system-level assessment tools.J. Med.\nInternet Res.25, e50158 (2023).\n5. Lehne, M., Sass, J., Essenwanger, A., Schepers, J. & Thun, S. Why\ndigital medicine depends on interoperability.npj Digit. Med.2,\n1–5 (2019).\n6. Donnelly, K. SNOMED-CT: The advanced terminology and coding\nsystem for eHealth.Stud. Health Technol. Inform.121,\n279–290 (2006).\n7. Köhler, S. et al. The human phenotype ontology in 2021.Nucleic Acids\nRes. 49, D1207–D1217 (2021).\n8. Kreuzthaler, M., Brochhausen, M., Zayas, C., Blobel, B. & Schulz, S.\nLinguistic and ontological challenges of multiple domains\ncontributing to transformed health ecosystems.Front. Med.10,\n1073313 (2023).\n9. Newman-Grif ﬁs, D. et al. Ambiguity in medical concept normalization:\nan analysis of types and coverage in electronic health record datasets.\nJ. Am. Med. Inform. Assoc.28, 516–532 (2020).\nFig. 2 | Divergent thinking on the use of LLMs in the curation, retrieval, and\ninteroperability of medical information.The central question that this viewpoint\naddresses is shown in the central circle (purple), and the divergent views currently\nexpressed on this theme are shown in the outer circles which are colored on a\ngrayscale from highly precautionary views, conservative about the applicability of\nLLMs (black), through less precautionary views, more open to the application of\nLLMs (dark gray, through light gray to white).\nhttps://doi.org/10.1038/s41746-024-01081-0 News & Views\nnpj Digital Medicine|           (2024) 7:100 4\n10. Hogan, A. et al. Knowledge graphs.ACM Comput. Surv.54,\n1–71 (2021).\n11. Chen, J. et al. Knowledge graphs for the life sciences: recent\ndevelopments, challenges and opportunities.arXiv 5,1 –5 (2023).\n12. Hahn, U. & Oleynik, M. Medical information extraction in the age of\ndeep learning.Yearb Med. Inform.29, 208–220 (2020).\n13. Min, B. et al. Recent advances in natural language processing via large\npre-trained language models: a survey.ACM Comput. Surv.56,\n1–40 (2024).\n14. Jiang, L. Y. et al. Health system-scale language models are all-\npurpose prediction engines.Nature 619, 357–362 (2023).\n15. Clusmann, J. et al. The future landscape of large language models in\nmedicine. Commun. Med.3,1 –8 (2023).\n16. Manning, C. D. Human language understanding & reasoning.\nDaedalus 151, 127–138 (2022).\n17. Liao, L., Yang, G. H. & Shah, C. Proactive conversational agents in the\npost-chatGPT world. inProceedings of the 46th International ACM\nSIGIR Conference on Research and Development in Information\nRetrieval 3452–3455 (Association for Computing Machinery,\nNY, 2023).\n18. Truhn, D., Reis-Filho, J. S. & Kather, J. N. Large language models\nshould be used as scientiﬁc reasoning engines, not knowledge\ndatabases. Nat. Med.29, 2983–2984 (2023).\n19. Truhn, D. et al. Extracting structured information from unstructured\nhistopathology reports using generative pre-trained transformer 4\n(GPT-4). J. Pathol.265, 310–319 (2023).\n20. Truhn, D. et al. A pilot study on the efﬁcacy of GPT-4 in providing\northopedic treatment recommendations from MRI reports.Sci. Rep.\n13, 20159 (2023).\n21. Giuffrè, M., You, K. & Shung, D. L. Evaluating chatGPT in medical\ncontexts: the imperative to guard against hallucinations and partial\naccuracies. Clin. Gastroenterol. Hepatol.S1542-3565,\n00835–2 (2023).\n22. Gilbert, S., Harvey, H., Melvin, T., Vollebregt, E. & Wicks, P. Large\nlanguage model AI chatbots require approval as medical devices.Nat.\nMed. 29, 2396–2398 (2023).\n23. Munn, L., Magee, L. & Arora, V. Truth machines: synthesizing veracity\nin AI language models.AI & Soc.https://doi.org/10.1007/s00146-\n023-01756-4 (2023).\n24. Pan, J. Z. et al. Large language models and knowledge graphs:\nopportunities and challenges.In Special Issue on Trends in Graph\nData and Knowledge. Transactions on Graph Data and Knowledge\n(TGDK). 1, 2:1-2:38, Schloss Dagstuhl– Leibniz-Zentrum für\nInformatik (2023)https://doi.org/10.4230/TGDK.1.1.2 (2023).\n25. Cenikj, G. et al. From language models to large-scale food and\nbiomedical knowledge graphs.Sci. Rep.13, 7815 (2023).\n26. Chandak, P., Huang, K. & Zitnik, M. Building a knowledge graph to\nenable precision medicine.Sci. Data.10, 67 (2023).\n27. Rajabi, E. & Etminani, K. Knowledge-graph-based explainable AI: a\nsystematic review.J. Inf. Sci.https://doi.org/10.1177/\n01655515221112844 (2022).\n28. Guo, Q., Cao, S. & Yi, Z. A medical question answering system using\nlarge language models and knowledge graphs.Int. J. Intelligent Syst.\n37, 8548–8564 (2022).\n29. Wornow, M. et al. The shaky foundations of large language models\nand foundation models for electronic health records.npj Digit. Med.6,\n1–10 (2023).\n30. Howell, M. D., Corrado, G. S. & DeSalvo, K. B. Three epochs of artiﬁcial\nintelligence in health care.JAMA 331, 242–244 (2024).\n31. Zakka, C. et al. Almanac— retrieval-augmented language models for\nclinical medicine.NEJM AI.https://doi.org/10.21203/rs.3.rs-\n2883198/v1 (2024).\nAcknowledgements\nS.G. received funding through a Bundesministerium für Bildung und\nForschung (BMBF) project (Personal Mastery of Health & Wellness Data,\nPATH) on consent in health data sharing,ﬁnanced through the European\nUnion NextGenerationEU program. A.H. received funding from ANID—\nMillennium Science Initiative Program— Code ICN17 002 and Fondecyt\nGrant 1221926.\nAuthor contributions\nS.G., J.N.K., and A. H. developed the concept of the manuscript. S.G. wrote\nthe ﬁrst draft of the manuscript. S.G., J.N.K., and A. H. contributed to the\nwriting, interpretation of the content, and editing of the manuscript, revising it\ncritically for important intellectual content, hadﬁnal approval of the\ncompleted version and take accountability for all aspects of the work in\nensuring that questions related to the accuracy or integrity of any part of the\nwork are appropriately investigated and resolved.\nCompeting interests\nS.G. declares a nonﬁnancial interest as an Advisory Group member of the\nEY-coordinated“Study on Regulatory Governance and Innovation in the\nﬁeld of Medical Devices” conducted on behalf of the DG SANTE of the\nEuropean Commission. S.G. declares the following competingﬁnancial\ninterests: he has or has had consulting relationships with Una Health GmbH,\nLindus Health Ltd., Flo Ltd, Thymia Ltd., FORUM Institut für Management\nGmbH, High-Tech Gründerfonds Management GmbH, and Ada Health\nGmbH and holds share options in Ada Health GmbH. S.G. is a News and\nViews Editor for npj Digital Medicine. S.G. played no role in the internal review\nor decision to publish this News and Views article. J.N.K. declares consulting\nservices for Owkin, France; DoMore Diagnostics, Norway and Panakeia, UK,\nhe holds shares in StratifAI GmbH and he has received honoraria for lectures\nor consulting fees by AstraZeneca, Bayer, Eisai, MSD, BMS, Roche, Pﬁzer\nand Fresenius. A.H. declares no competing interests.\nAdditional information\nCorrespondenceand requests for materials should be addressed to\nStephen Gilbert.\nReprints and permissions informationis available at\nhttp://www.nature.com/reprints\nOpen AccessThis article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long\nas you give appropriate credit to the original author(s) and the source,\nprovide a link to the Creative Commons licence, and indicate if changes\nwere made. The images or other third party material in this article are\nincluded in the article’s Creative Commons licence, unless indicated\notherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons licence and your intended use is not permitted\nby statutory regulation or exceeds the permitted use, you will need to\nobtain permission directly from the copyright holder. To view a copy of this\nlicence, visithttp://creativecommons.org/licenses/by/4.0/\n.\n© The Author(s) 2024\nhttps://doi.org/10.1038/s41746-024-01081-0 News & Views\nnpj Digital Medicine|           (2024) 7:100 5",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6891640424728394
    },
    {
      "name": "Hallucinating",
      "score": 0.671806812286377
    },
    {
      "name": "Bottleneck",
      "score": 0.6192304491996765
    },
    {
      "name": "Workflow",
      "score": 0.6138179302215576
    },
    {
      "name": "Unified Medical Language System",
      "score": 0.42035698890686035
    },
    {
      "name": "Augmented reality",
      "score": 0.419981986284256
    },
    {
      "name": "Data science",
      "score": 0.4113715887069702
    },
    {
      "name": "Artificial intelligence",
      "score": 0.4111618995666504
    },
    {
      "name": "Database",
      "score": 0.0
    },
    {
      "name": "Embedded system",
      "score": 0.0
    }
  ]
}