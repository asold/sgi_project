{
  "title": "Early fault diagnosis of transformer winding based on leakage magnetic field and DSAN learning method",
  "url": "https://openalex.org/W4315796640",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5091606045",
      "name": "Xiangli Deng",
      "affiliations": [
        "Shanghai University of Electric Power"
      ]
    },
    {
      "id": "https://openalex.org/A5100393420",
      "name": "Zhan Zhang",
      "affiliations": [
        "Shanghai University of Electric Power"
      ]
    },
    {
      "id": "https://openalex.org/A5100990402",
      "name": "Hongye Zhu",
      "affiliations": [
        "Shanghai University of Electric Power"
      ]
    },
    {
      "id": "https://openalex.org/A5102007924",
      "name": "Yan Kang",
      "affiliations": [
        "Shanghai University of Electric Power"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3155557926",
    "https://openalex.org/W3165008153",
    "https://openalex.org/W2019612157",
    "https://openalex.org/W4205571244",
    "https://openalex.org/W3167987031",
    "https://openalex.org/W2351546013",
    "https://openalex.org/W6607361319",
    "https://openalex.org/W2602876170",
    "https://openalex.org/W4230798895",
    "https://openalex.org/W3115507218",
    "https://openalex.org/W2112796928",
    "https://openalex.org/W2379930263",
    "https://openalex.org/W6683633756",
    "https://openalex.org/W2605431607",
    "https://openalex.org/W3132840356",
    "https://openalex.org/W2885208219",
    "https://openalex.org/W6962736251",
    "https://openalex.org/W3207875952",
    "https://openalex.org/W2948966631",
    "https://openalex.org/W3021632667",
    "https://openalex.org/W2159291411",
    "https://openalex.org/W2964288524",
    "https://openalex.org/W4249623890"
  ],
  "abstract": "Aiming at the problem of lack of training samples and low accuracy in transformer early winding fault diagnosis, this paper proposes a transformer early faults diagnosis method based on transfer learning and leakage magnetic field characteristic quantity. The method uses the leakage magnetic field waveform on the measuring point of the simulated transformer winding to draw the Lissajous figure to calculate the characteristic quantity. The characteristic quantity of the simulation model is used to train the convolutional neural network (CNN) faults classification model. The CNN fault classification model is transferred to the actual transformer fault detection through the improved deep subdomain adaptive network (DSAN), so as to realize the fault diagnosis of the actual transformer by the classification model trained by the simulation data. The test examples of the actual transformer early fault experimental platform and the leakage magnetic field measurement platform are established, and the feasibility of the transfer learning method based on the leakage magnetic field feature quantity proposed in this paper is verified.",
  "full_text": "Early fault diagnosis of\ntransformer winding based on\nleakage magneticﬁeld and DSAN\nlearning method\nXiangli Deng*, Zhan Zhang, Hongye Zhu and Kang Yan\nSchool of Electric Power Engineering, Shanghai University of Electric Power, Shanghai, China\nAiming at the problem of lack of training samples and low accuracy in\ntransformer early winding fault diagnosis, this paper proposes a transformer\nearly faults diagnosis method based on transfer learning and leakage magnetic\nﬁeld characteristic quantity. The method uses the leakage magnetic ﬁeld\nwaveform on the measuring point of the simulated transformer winding to\ndraw the Lissajous ﬁgure to calculate the characteristic quantity. The\ncharacteristic quantity of the simulation model is used to train the\nconvolutional neural network (CNN) faults classiﬁcation model. The CNN\nfault classi ﬁcation model is transferred to the actual transformer fault\ndetection through the improved deep subdomain adaptive network (DSAN),\nso as to realize the fault diagnosis of the actual transformer by the classiﬁcation\nmodel trained by the simulation data. The test examples of the actual\ntransformer early fault experimental platform and the leakage magneticﬁeld\nmeasurement platform are established, and the feasibility of the transfer\nlearning method based on the leakage magnetic ﬁeld feature quantity\nproposed in this paper is veriﬁed.\nKEYWORDS\ntransformer early fault, leakage magneticﬁeld, CNN-convolutional neural network,\ntransfer learning (TL), self-attention mechanism\n1 Introduction\nThe power transformer is one of the most important electrical equipment in the power\nnetwork. When the transformer is impacted by the external force or repeatedly impacted\nby the short-circuit fault current outside the region, it is easy to cause the deformation of\nthe transformer winding (Hang and Butler, 2002). The long-term operation of the\ntransformer under overload condition and insulation aging will cause the decrease of\nthe insulation performance of the transformer winding, which further leads to the inter-\nturn short-circuit faults (Liu et al., 2003). The transformer internal winding fault occurs\nabove and does not have huge impact, we call this fault for the transformer early fault.\nEarly faults of transformers are often difﬁcult to detect. The cumulative effect of long-term\noperation of transformers under potential early faults will eventually lead to serious\nOPEN ACCESS\nEDITED BY\nMohamed M. F. Darwish,\nAalto University, Finland\nREVIEWED BY\nMohamed H. A. Hassan,\nBenha University, Egypt\nManal M. Emara,\nKafrelsheikh University, Egypt\nXuguang Hu,\nNortheastern University, China\n*CORRESPONDENCE\nXiangli Deng,\nxiangli_deng@163.com\nSPECIALTY SECTION\nThis article was submitted to Smart\nGrids,\na section of the journal\nFrontiers in Energy Research\nRECEIVED 30 September 2022\nACCEPTED 27 October 2022\nPUBLISHED 12 January 2023\nCITATION\nDeng X, Zhang Z, Zhu H and Yan K\n(2023), Early fault diagnosis of\ntransformer winding based on leakage\nmagnetic ﬁeld and DSAN\nlearning method.\nFront. Energy Res.10:1058378.\ndoi: 10.3389/fenrg.2022.1058378\nCOPYRIGHT\n© 2023 Deng, Zhang, Zhu and Yan. This\nis an open-access article distributed\nunder the terms of theCreative\nCommons Attribution License (CC BY).\nThe use, distribution or reproduction in\nother forums is permitted, provided the\noriginal author(s) and the copyright\nowner(s) are credited and that the\noriginal publication in this journal is\ncited, in accordance with accepted\nacademic practice. No use, distribution\nor reproduction is permitted which does\nnot comply with these terms.\nFrontiers inEnergy Research frontiersin.org01\nTYPE Original Research\nPUBLISHED 12 January 2023\nDOI 10.3389/fenrg.2022.1058378\naccidents. Therefore, the accurate detection of transformer early\nfaults is of great signiﬁcance to ensure the stable operation of\npower system (Naseri et al., 2018).\nAt present, the detection methods for transformer faults are\nmainly divided into of ﬂine detection methods and online\nmonitoring methods. Off-line detection commonly used oil\nchromatography (Gao and He, 2010; Alshehawy, et al., 2021;\nEmara et al., 2021; Wu et al., 2021), frequency response method\n(Shamlou et al., 2021), the technology is relatively mature, but the\nmaintenance is limited by the operation cycle cannot be real-time\nmonitoring and timely detection of faults. The method of real-\ntime online monitoring is the main research direction at present.\nTransformer winding deformation fault can be diagnosed online\nby using leakage inductance parameters of transformer winding\n(Deng et al., 2014 ). The inter-turn short-circuit fault of\ntransformer can be identi ﬁed by constructing the ﬁtness\nfunction of resistance and leakage inductance parameters\n(Wang and Zeng, 2021). An article paper proposes an online\nfault detection method for transformers based on an IoT\nplatform (Elsis et al., 2022 ). All of the above studies have\nachieved some results. However, one parameter can only\ndetect a single fault and has the disadvantages of low\nparameter calculation accuracy and unclear fault relationship\n(Chen et al., 2019). Therefore, it is necessary toﬁnd a leakage\nmagnetic ﬁeld characteristic which can not only re ﬂect the\ninternal winding deformation of the transformer but also\nidentiﬁes the inter-turn short circuit and reﬂect more quickly\nas the early fault monitoring of the transformer. Using leakage\nmagnetic ﬁeld to monitor early faults of the transformer is a\nfeasible online monitoring scheme.\nThe leakage magneticﬁeld data of the transformer can directly\nreﬂect the operation state of the transformer (Wang and Han, 2021).\nWhen the transformer winding is deformed, the leakage magnetic\nﬁe l da r o u n dt h ew i n d i n gi sa s y m m e trically distributed in space.\nWhen inter-turn short circuit occurs in the transformer, the iron\ncore may be partially saturated, which increases the leakage magnetic\nﬁe l da r o u n dt h ew i n d i n g(Zhang, 2019). The winding deformation of\nthe transformer can be monitored based on the asymmetry of the\ndistribution of the leakage magneticﬁeld (Zhou and Wang, 2017;\nPan et al., 2020; Zhang et al., 2021) .A tt h es a m et i m e ,t h em u t a t i o no f\nthe leakage magneticﬁeld can be used to diagnose the inter-turn\nshort circuit faults (\nCabanas et al., 2007). However, when the leakage\nmagnetic ﬁeld data are used to segment the fault types of\ntransformers, there are probl ems such as small differences\nbetween different fault characteristics and difﬁcult to distinguish\nmanually.\nIn recent years, with the development of artiﬁcial intelligence\ntechnology, data-driven transformer fault classiﬁcation methods\nhave been widely employed because they can effectively identify\nsmall data differences. Machinelearning can effectively classify\ntransformer faults and identify early faults in transformers\n(Haghjoo et al., 2017; Li et al., 2022). Recent studies have shown\nthat the distribution of the magneticﬁeld leakage changes when the\ntransformer has an early fault. Online monitoring of the early fault of\nthe transformer can be realized by using the magneticﬁeld leakage\ndata and artiﬁcial intelligence methods. However, there are several\nproblems worthy to solve.\n(1) When using magnetic ﬁeld leakage data to diagnose\ntransformer faults, the change in transformer load has a\ngreater impact on fault classi ﬁcation, and the fault\nclassiﬁcation accuracy is low.\n(2) Is difﬁcult to obtain actual transformer fault data inﬁeld\napplications, and there is a lack of labeled training data.\nBased on the deﬁciencies in the existing literature, this study\nproposes the following innovations:\n(1) The Faraday magneto-optical effect was used to measure the\nleakage magnetic ﬁeld of the transformer, and current\ninformation was used to normalize the leakage magnetic\nﬁeld waveform to eliminate the inﬂuence of load changes on\nfault classiﬁcation. The leakage magneticﬁeld waveform was\nused to draw Lissajousﬁgures and extract the characteristic\nquantities for the early fault classiﬁcation of transformer\nwindings, which enhances the classiﬁcation accuracy.\n(2) Through the improved DSAN, the transfer learning can reduce\nthe difference between the actual transformer and the simulation\nmodel data, so as to realize the fault diagnosis of the actual\ntransformer using the neural network trained by the simulation\ndata, and solve the problem of insufﬁcient training data.\nIn this study, a fault diagnosis test was performed on the\nmeasured data of an actual transformer. The results reveal that\nthe proposed method can effectively transfer the transformer\nfault classiﬁcation model and has high classiﬁcation accuracy.\n2 Transformer fault classiﬁcation\nmethod based on deep subdomain\nadaptive network\nFor a new transformer we cannot obtain data on early\nwinding faults, but we can use simulation software to simulate\ndifferent fault types and obtain a large amount of fault data, but\nthere are deviations between the simulation data and the actual\ndata before. Weﬁrst use the simulation data to train a CNN fault\nclassiﬁcation model, and then use the DSAN transfer learning\nmethod to achieve early fault diagnosis of the actual transformer.\n2.1 Convolutional neural network\nclassiﬁcation model\nThe convolutional perceptual features of CNN can fully\nextract various features of the input image and have strong\nFrontiers inEnergy Research frontiersin.org02\nDeng et al. 10.3389/fenrg.2022.1058378\ntransferability. In this study, the classic LeNet-5 in CNN was used\nfor the feature extraction of images. The parameters for each\nlayer of the designed CNN are presented in Supplementary\nAppendix A1. The convolution layer in a CNN is composed\nof several convolution kernels. Different convolution kernels can\nextract different image features. Convolution operations can\nextract low-level to complex features from the input image\ndata. The mathematical expression of the convolution layer is\nexpressed in Eq. 1 (Lecun et al., 1998):\ng\nl(γ)/equals ACT⎡⎢⎢⎣∑\nG\ni/equals 1\n∑\nH\nj/equals 1\nWl\ni,j*γl\ni,j + El\ni,j\n⎤⎥⎥⎦ (1)\nIn the formula,l indicates the number of layers,ACT indicates\nthe activation function,G, Hdenotes the size of the current layer\nnode matrix,γ indicates the number of nodes in the node matrix,\nWl\ni,j corresponds to the weight matrix of the convolution kernel,\nγl\ni,j indicates the input value of the convolution layer, andEl\ni,j\ndenotes the bias of the current node.\nUsing a nonlinear Recti ﬁed Linear Activation Function\n(ReLU) activation function can solve the problem of low\nexpression ability of linear models (Wang et al., 2019). Using\nthe maximum pooling layer to scale and map the convolution\nimage can simplify the parameters and reduce the data\ndimensions. The mathematical expression is as followsEq. 2\n(Wang et al., 2019):\ngl+1(γ)/equals MP{gl(γ)} (2)\nMP indicates the maximum pooling function, gl(γ) represents\nconvolution computes the eigenvalues of the output. After the\nconvolution-pooling network, the transformer fault classiﬁcation\nstage is composed of a full connection layer, and the last fully\nconnected layer is used as the classiﬁer. The transformer winding\nis divided into different states using one-hot coding form to\ncalculate the classiﬁcation probability of one sample for each\nstate and take the state with the maximum probability as the\nclassiﬁcation result. Cross-entropy loss is used as the loss\nfunction of the classiﬁer, as expressed in the followingEq. 3\n(Jang et al., 2017):\nJ(θ(x\ni), yi)/equals− ∑\nC\nc/equals 1\n{yi |/equals c}log θ(xi) (3)\nIn the formula,J(·, ·) denotes the cross-entropy loss function,C /equals\n{1, 2, /,c } indicates the type of classiﬁcation, andθ(xi) represents\nthe probability that the network attaches the current type labelyi to\nthe samplexi. The empirical error of the CNN classiﬁcation model is\ngiven by theEq. 4(Jang et al., 2017):\nmin\nθ\n1\nn ∑\nn\ni/equals 1\nJ(θ(xi), yi) (4)\nIn the formula,n represents the total number of samples. In\nthe form represents a collection of parameters for each layer\nof CNN.\n2.2 Transfer learning\nBased on the theory of transfer learning (Ghifary et al.,\n2014), this study applies the knowledge learned in oneﬁeld to\nanother similar ﬁeld. More speciﬁcally, a machine learning\nalgorithm is utilized to transfer the transformer fault\nclassi ﬁcation model trained by the simulation model from\nthe fault diagnosis of the simulation transformer to the fault\ndiagnosis of the actual transformer. In ﬁeld applications,\nactual transformer fault data are often dif ﬁcult to obtain\nand the fault process causes irreversible damage to the\ntransformer. Actual transformers take the initiative to\nproduce fault data at a high cost. For an actual\ntransformer that needs to be diagnosed, there is almost no\navailable labeled data. Altho ugh a large amount of sample\ndata can be generated using the transformer simulation\nmodel, there are still some differences between the\nsimulation data and actual data. The classi ﬁcation model\ntrained using simulation data cannot be directly applied to\nthe fault diagnosis of an actual transformer.\nOwing to the lack of actual transformer data with labels, this\nstudy adopted the method of model transfer. We deﬁne the\ndataset generated by the transformer simulation model as the\nsource domain data, which is a labeled system\nD\nS /equals{ ( xS\n1, yS\n1), /, (xS\ns , yS\ns )}, the actual transformer data set as\ntarget domain data, and the target domain data as unlabeled\nsystem DT /equals{ ( xT\n1 ), /, (xT\nt )}. The simulation data and the actual\ndata are mapped from the original feature space to the new\nfeature space. In the new feature space, the data distribution of\nthe simulated data and the actual data are similar, so that the\nexisting labeled data samples of the simulated data can be better\nused in the new space for classiﬁcation testing of the actual\ntransformer data. We place the description of transfer learning\nschematic in Supplementary Appendix B1 . The probability\ndistributions p and q are obtained by sampling the\ntransformer simulation data D\nS and the actual transformer\ndata DT. The goal of using transfer learning in this study is to\ndesign a neural network to eliminate the difference between\nsimulated transformer data and real data by learning the\ntransferable characteristics of distribution p and q to\nminimize the target risk.\n2.3 Deep subdomain adaptive network\nbased on multi-core local maximum mean\ndifference\nT om i n i m i z et h ed i s t a n c eb e t w e e nt h es o u r c ed o m a i nd a t a\nDS and target domain dataDT, and align the edge distribution\nof the simulation and actual transformer data, a multiple\nkernel variant of the maxim um mean discrepancy (MK-\nMMD) is used to measure the distance between the source\ndomain data and the target domain data (Long and Wang,\nFrontiers inEnergy Research frontiersin.org03\nDeng et al. 10.3389/fenrg.2022.1058378\n2015). MK-MMD is an extension of MMD and is a non-\nparametric method used to measure the distribution\ndifferences between datasets in different domains. MMD\nuses a single kernel for transformation, and it is difﬁcult to\ndetermine an optimal kernel for different datasets. The\no p t i m a lk e r n e lo ft h eM K - M M Di so b t a i n e db yal i n e a r\ncombination of several kernels, which can be adapted to\ndifferent datasets. MK-MMD is de ﬁned to map the source\ndomain data distributed and the target domain data\ndistributed as to the reproducing kernel Hilbert space\n(RKHS) and calculate the mean distance as follows Eq. 5\n(Ghifary et al., 2014):\nM\n2\nk(p, q)≜\n/vextendouble/vextendouble\n/vextendouble/vextendoubleE\nxS ~ p[ϕ(xS)]− ExT ~ q[ϕ(xT)]\n/vextendouble/vextendouble\n/vextendouble/vextendouble\n2\nZ (5)\nIn the formula,∥·∥ 2\n- represents the two norms of RKHS,ExS~p[·],\nand ExT~q[·] represents the mathematical expectation of\ndistribution p and q, ϕ(·): x → - denotes the inﬁnite order\nnonlinear feature map of vectorx in -.\nAssuming that a characteristic kernel in RKHS isk, and the\nmean value of distribution p in kernel space - is an element\nμk(p), all the key statistical features in distributionp are coded\ninto μk(p), so that all the mapping functions satisfyingf ∈ -\nsatisfy the expectation Ex~pf(x)/equals 〈f(x), μk(p)〉-, so we can\nlearn throughμk(p) rather than distributionp, so as to eliminate\nthe incalculable density estimation in distribution p. The\nempirical estimation of the MK-MMD is given by the\nfollowing Eq. 6 (Long and Wang, 2015):\nM2\nK(DS, DT) ≜\n1\nn2\ns\n∑\nns\ni/equals 1\n∑\nns\nj/equals 1\nk(xS\ni , xS\nj)+ 1\nn2\nt\n∑\nnt\ni/equals 1\n∑\nnt\nj/equals 1\nk(xT\ni , xT\nj )\n− 2\nnsnt\n∑\nns\ni/equals 1\n∑\nnt\nj/equals 1\nk(xS\ni , xT\nj )\n(6)\nIn the above formula,ns,n t denote the sample size ofDS, DT.\nk(x, x′)/equals 〈ϕ(x), ϕ(x′)〉 is considered as the correlation between\nvectors x and x′, and the kernel functionk(x, x′) is a convex\ncombination ofk Gaussian kernels. The composition of kernel is\nas follows Eq. 7 (Long and Wang, 2015):\n⎧⎨\n⎩k /equals ∑\nK\ni/equals 1\nβiki: ∑\nK\ni/equals 1\nβi /equals 1, βiP0, ∀U\n⎫⎬\n⎭ (7)\nConstraints are imposed on coefﬁcient β to ensure that each\ncore k combination has unique characteristics. K denotes the\ntotal number of the kernel. Using kernel k with different\nbandwidths to obtain the mean value of the distribution at\ndifferent scales can give distributionp and q an optimal kernel.\nThe regularization based on MK-MMD can effectively align\nthe probability distribution of the sample; however, DSAN\nconsiders the ﬁne-grained information of the label of the\nsample and deﬁnes the label weight wi,c as shown in Eq. 8\n(Zhu et al., 2021):\nwi,c /equals yi,c\n∑\nyj.c∈{DS,DT}\nyj,c\n(8)\nyi,c denotes the probability that samplexi belongs to category\nc,a n dyj,c denote the category of the current sample label.\nThe source domain data uses the actual annotation to\ncalculate the wS\ni,c , the target domain samples data uses the\nCNN prediction probability calculate wT\nj,c . The regularization\nformula (8) of MK-LMMD use the activation vectors {zS\ni }ns\ni/equals 1\nand {zT\nj }nt\nj/equals 1 of the full connection layer as features to calculate\nthe distance, as follows Eq. 9 (Zhu et al., 2021):\nM2\nKL(DS, DT) ≜\n1\nC ∑\nC\nc/equals 1\n⎡⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢\n⎢⎢⎢⎢⎣\n∑\nns\ni/equals 1\n∑\nns\nj/equals 1\nwS\ni,cwS\nj,c\nk(zS\ni , zS\nj)+\n∑\nnt\ni/equals 1\n∑\nnt\nj/equals 1\nwT\ni,cwT\nj,c\nk(zT\ni , zT\nj )\n−2∑\nnt\ni/equals 1\n∑\nnt\nj/equals 1\nwS\ni,cwT\nj,c\nk(zS\ni , zT\nj )\n⎤⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥\n⎥⎥⎥⎥⎦\n(9)\nIn the expressionz\nS\ni , zT\nj represent the activation vectors of the\nsource domain and target domain samples.\nConvolutional layers in a CNN are transferable; therefore,\nt h e r ei sn on e e dt oa d dM K - L M M Dr e g u l a r i z e r st ot h e s e\nlayers. When migrating, we fr eeze the convolution and\npooling layers to maintain the effectiveness of collaborative\nadaptation. In a CNN, the dee p features transition from\ngeneral to speciﬁc features in the last layer of the network.\nThe transferability of the neural network decreases with an\nincrease in the difference b etween the source and target\ndomains, and the transferability of data between different\ndomains decreases through the full connection layer.\nTherefore, we only compute the distance difference\nbetween the source and target domains in the full\nconnection layer, and the trans fer learning loss function as\nfollows Eq. 10:\nmin\nθ\n1\nn ∑\nn\ni/equals 1\nJ(θ(xS\ni ),y S\ni )+ λ∑\nl2\nl/equals l1\nM2\nKL(Dl\ns, Dl\nt) (10)\nλ symbolizes a penalty factor,l1 and l2 denote the number of\nlayers based on MK-LMMD regularization, M2\nkL(Dl\ns, Dl\nt)\nrepresents the local maximum mean difference value of the\ncurrent layer.\n2.4 Improvement of deep subdomain\nadaptive network\nConsidering the different correlations between the\nsimulation data and the actual measurement data, to\nfurther improve the generalization ability of the DSAN, it\nis proposed to add the self-a ttention mechanism to the\nFrontiers inEnergy Research frontiersin.org04\nDeng et al. 10.3389/fenrg.2022.1058378\ntraditional DSAN ( Bo et al., 2021 ). Based on the regional\ncharacteristics, the full connection layer and sigmoid are used\nto estimate the importance of the sample and provide the\nweight value. The input sample is divided into several features,\nand the full connection layer data obtained by the convolution\nof each sample is input into a sigmoid function to obtain\ndifferent weights. The correlation between the simulation data\nand actual measurement data is too large to obtain higher\nweights, and vice versa . This allows the neural network to\nautomatically focus on samples with signiﬁcant weights. The\nsigmoid function is shown in the followingEq. 11 (Bo et al.,\n2021):\nτ\ni /equals SIG(xS\ni , cov(xS\ni )) (11)\ncov(xs\ni ) represents the parameter feature of the full connection\nlayer after the convolution layer. τi corresponds to the\nimportance weight parameter of i − th, SIG represents the\nsigmoid function. The improved DSAN loss function is given\nby Eq. 12:\nmin\nθ\n1\nn ∑\nn\ni/equals 1\nJ(θ(xS\ni ), τiyS\ni )+ λ∑\nl2\nl/equals l1\nM2\nKL(Dl\ns, Dl\nt) (12)\nThe DSAN model, based on the self-attention\nmechanism, is presented in Figure 1. From the perspective\nof the construction process of the transfer model, although\nf e a t u r ee x t r a c t i o ni sn o tnecessarily able to completely\neliminate the difference between the actual transformer\nsimulation model and the a ctual transformer data\ndistribution, according to the statistical principle, MK-\nL M M Dr e g u l a r i z a t i o nc a nr e d u c et h i sd i f f e r e n c ea sm u c h\nas possible and can obtain a better classi ﬁcation effect in\ntheory. Simultaneously, a DSAN with a self-attention\nmechanism can weight the sample data, which can further\nimprove the accuracy of classiﬁcation.\n3 Transformer fault diagnosis based\non magneticﬁeld leakage\ncharacteristic\n3.1 Load normalization of magneticﬂux\nleakage\nIn this study, leakage magneticﬁeld information is used to\ndiagnose transformer faults. Because the load change of the\ntransformer affects the current of the secondary winding and\nsubsequently affects the amplitude and phase angle of the leakage\nmagnetic ﬁeld waveform, it will adversely affect the accuracy of\nfault classiﬁcation. Previous papers have selected several different\nload conditions to analysis of leakageﬁelds for different load\nconditions. In this paper, we propose a method based on real-\ntime load normalization of the current on theﬁrst and second\nsides of the transformer.\nTo eliminate the inﬂuence of load changes on fault diagnosis,\nin this study, the amplitude and phase angle of the leakage\nmagnetic ﬁeld waveform are normalized using the currents at\nthe primary and secondary windings of the transformer. The\nmagnetic line of the leakageﬂux of the primary and secondary\nwindings is closed along the nonferromagnetic material and is\nFIGURE 1\nDSAN model based on self-attentive mechanism.\nFrontiers inEnergy Research frontiersin.org05\nDeng et al. 10.3389/fenrg.2022.1058378\nlinear with the primary and secondary side currents (Gu, 2010).\nThe resistive inductive load is the common load of a transformer.\nThe change in load simultaneously affects the waveform of the\nleakage magnetic ﬁeld amplitude and phase angle. The linear\nfunction between the leakage magneticﬁeld and the response of\nthe transformer primary and secondary side currents is asEq. 13\n(Gu, 2010):\n_BL /equals _p _I1 + _q_I2 (13)\n_BL Indicates leakage magneticﬁeld. _p, _q is constant coefﬁcient,\n_I1, _I2 is the primary and secondary side current. When the\ntransformer operates in any two different load states, theEq.\n14 shows:\n_B\n*\na /equals _p_Ia1\n* + _q_Ia2\n*\n_B\n*\nb /equals _p _Ib1\n* + _q_Ib2\n* (14)\n_B\n*\na, _B\n*\nb indicates the leakage magneticﬁeld under two different\nloads. _Ia1*, _Ia2*, _Ib1*, _Ib2* is the primary and secondary side current\nunder two different loads. When the transformer operates\nunder the rated load, as shown in theEq. 15:\n_B\n*\nf /equals _p _If1\n* + _q_If2\n* (15)\n_B\n*\nf Indicates leakage magneticﬁeld under the rated load._If1* , _If2*\nis the primary and secondary side current under the rated load.\nEq. 16 can be obtained fromEq. 14, 15:\n_B\n*\nf /equals [_If1\n* _If2\n* ][_Ia1* _Ia2*\n_Ib1* _Ib2* ]\n−1\n[\n_B\n*\na\n_B\n*\nb\n] (16)\nEq. 16shows that under any two load conditions, the leakage\nmagnetic ﬁeld intensity of any measuring point can be\nnormalized to the rated load condition, which avoids the\ninterference of loadﬂuctuation on the fault classiﬁcation.\n3.2 Extraction of Lissajousﬁgure feature\nquantity of magneticﬁeld leakage\nThe transformer used in this experiment was a toroidal core\ntransformer, which is widely used in electronic equipment with\nhigh technical requirements, and it primarily serves as a power\ntransformer. From the perspective of straightening the iron core,\nthe radial magnetic ﬁeld leakage is equivalent to the axial\ndirection of the core transformer, and the tangential direction\nis equivalent to the radial direction of the core transformer. This\nis called the radial direction and the tangential direction is called\nthe axial direction. In this study, the primary and secondary-side\nwindings of the A-phase Y/Y connection of the three-phase\ntransformer are used as an example for testing.\nWhen an early fault occurs in the transformer, it can be found\nby analyzing the waveform of the leakage magneticﬁeld that the\nchange in the leakage magnetic ﬁeld at the end and central\npositions of the transformer is the most evident, and there are\ndistinct differences in different fault types. To distinguish the\ndifferent fault types of the winding, it is proposed set a measuring\npoint at the two ends and central positions of the winding to\nmeasure the axial and radial leakage magnetic ﬁelds. The\nmeasurement point position of the transformer leakage\nmagnetic ﬁeld is illustrated inFigure 2.\nPrevious studies have only used the amplitude and phase\nangle of the leakageﬁeld at individual measurement points, but\nfor transformer faults it is the internal leakageﬁeld balance that\nchanges. The relationship of the leakage ﬁeld between the\nmeasurement points is also important information. We\npropose a method that uses the Lissajous image of the leakage\nﬁeld signal to better integrate the information between these\nmeasurement points. The transformer leakage magnetic ﬁeld\nwaveform is a harmonic signal and the Lissajous ﬁgure is\nwidely used in harmonic signal processing (Zhao et al., 2019).\nWhen the transformer fails, the symmetry of the magneticﬁeld\nleakage at both ends of the winding changes. The Lissajousﬁgure\ndrawn by the leakage magnetic ﬁeld waveform at measuring\npoints 1, 3 and 4, 6 can reﬂect the change in the symmetry of the\nwinding at the time. The leakage magneticﬁeld in the middle of\nthe fault winding changes; however, that of the non-fault winding\nremains unchanged. The Lissajousﬁgure drawn by the leakage\nmagnetic ﬁeld waveform at 2, 5 measuring points can reﬂect this\nmutation. To make the fault characteristics more intuitive, this\nwork deduces the length, swing angle, area, least square radius,\nand roundness of the long and short axes of the Lissajousﬁgure as\ncharacteristic parameters that reﬂect the change in the leakage\nmagnetic ﬁeld amplitude and phase angle. Considering the\nleakage magnetic ﬁeld waveform of 1, 3 measuring points as\nan example, the characteristic quantity of the leakage magnetic\nﬁeld is calculated. Assuming that the leakage magnetic ﬁeld\nwaveform of measuring points 1, 3 is as shown inEq. 17:\nFIGURE 2\nSchematic diagram of transformer measurement points.\nFrontiers inEnergy Research frontiersin.org06\nDeng et al. 10.3389/fenrg.2022.1058378\n{ B1 /equals M cos(ωt + ψ1)\nB3 /equals N cos(ωt + ψ3) (17)\nM, Nindicate the amplitude of the magneticﬁeld leakage, andξ /equals\nψ1 − ψ3 is deﬁned as the phase angle difference between points 1,\n3 measuring points. Solve the equation, we obtain the length of the\nlong- and short-axisa、b of the Lissajousﬁgure, as followsEq. 18:\na2orb2 /equals\n(M2 + N2)∓\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\n(M2 + N2)\n2\n− 4M2N2sin 2 ξ\n√\n2\n(18)\nAccording to the elliptic area formula, the area of the\nLissajous ﬁgure is calculated using S/equals πab.\nThe coordinates are rotated to calculate the swing angle of the\nLissajous ﬁgure as followsEq. 19:\nθQ /equals 1\n2 arctan 2MN cos ξ\nN2 − M2 ,N ≠ M (19)\nIt is evident from the above formulas that the long-short axis,\narea, and swing angle of the leakage magneticﬁeld Lissajous\nﬁgure are functions of the amplitude and phase difference of\nmeasuring points 1, 3, and the fault information of the leakage\nmagnetic ﬁeld represented by it is more abundant, which is\nconducive to improving the accuracy of classiﬁcation.\nAssuming that u、v is divided into m points of\nu\ni、vi(i /equals 1, 2, ... ,m ) following sampling, then the center\ncoordinate of the least square circle is ( u0 /equals 2\nm ∑\nm\ni\nui;\nv0 /equals 2\nm ∑\nm\ni\nvi). The radius of the least square circle of Lissajous\nﬁgure isr0 /equals 1\nm ∑m\ni/equals 1\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\n(u2\ni + v2\ni )\n√\n, and the distance between theﬁrst\npoint and the least square center is as followsEq. 20:\nri /equals\n/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext/radicaltpext\n(ui − u0)2 + (vi − v0)2\n√\n(20)\nThe circularity of the Lissajous graph ise /equals max(ri)− min(ri).\nThe change in the least square radius of the Lissajousﬁgure\nreﬂects the change in the amplitude of the leakage magneticﬁeld\nwaveform, and the change in the roundness reﬂects the change in\nthe phase difference of the leakage magneticﬁeld waveform. It\ncan also be used as a characteristic quantity of the magneticﬁeld\nleakage for transformer fault diagnosis.\n3.3 Transformer early fault diagnosis\nprocess\nFirst, the CNN classi ﬁcation model was constructed by\nofﬂine learning the fault leakage magneticﬁeld characteristics\nof the simulation transformer model. Second, the actual\ntransformer fault is diagnosed by online measurement and\nextraction of the magnetic ﬁeld leakage characteristics of the\nactual transformer. The early fault diagnosis process of the\ntransformer is as follows.\n3.3.1 Simulation model construction and actual\ntransformer experimental platform construction\n1) Measured actual transformer structure data and electrical\nparameters on the nameplate to establish a 1: 1 actual\ntransformer simulation model.\nFIGURE 3\nSystem operationﬂowchart.\nFIGURE 4\nTransformer leakage magneticﬁeld measurement.\nFrontiers inEnergy Research frontiersin.org07\nDeng et al. 10.3389/fenrg.2022.1058378\n2) Develop the actual transformer fault simulation and magnetic\nﬁeld leakage measurement platform.\n3.3.2 Data generation\n1) An actual transformer simulation model was used to simulate\nthe possible faults in the transformer under different load\nconditions. The current on the primary and secondary\nwindings of the transformer and the waveform data of the\nleakage magneticﬁeld at each measuring point were recorded.\nThe measured current data are normalized by the formula in\nSection 3.1, and the characteristic quantity of the magnetic\nﬁeld leakage is calculated. The gray image formed by the\ncharacteristic quantity of the magnetic ﬁeld leakage is\nconsidered as the sample datax\ns, and the labelys is added\naccording to the fault type to generate the training sampleDS.\nPart of the data was randomly divided into training dataset\nDtrain, and another part of the data was randomly divided into\nvalidation dataset Dvalid.\n2) Normal operation, inter-turn short circuit, and winding\ndeformation experiments of the actual transformer\nexperimental platform were performed, and the data were\nrecorded. The measured data from the actual transformer are\nused to constitute the test sample.D\nT.\n3.3.3 Network structure and acceleration\nalgorithm\nBecause the input image is small, to fully extract its feature\ninformation, the kernel funct ions of the convolution and\npooling layers in the CNN are both large. The momentum-\nupdating stochastic gradient descent (SGD) acceleration\nalgorithm was used to improve the network training speed.\nOfﬂine model training was terminated when the error was less\nthan the set value. The online detection model inherits the\nconvolution layer parameters completed by of ﬂine training,\nand its full connection layer parameters are randomly\ninitialized.\n3.3.4 Parameter update and stop\n1) The loss function of the ofﬂine CNN model is calculated\naccording to the actual label data and label output\npredicted by the classi ﬁer and stops after the error\nreaches the set value.\n2) The online model uses direct transfer learning. After\ncalculating the transfer loss and classiﬁcation loss by MK-\nLMMD regularization, the full connection layer parameters in\nthe CNN model were retrained until the set number of\ntraining was reached.\nFIGURE 5\nTransformer leakage magneticﬁeld measurement device and installation schematic.(A) Schematic diagram ofﬁber optic leakage magnetic\nﬁeld sensor.(B) Optical signal transmitter and receiver Instrument.(C) Leakage magneticﬁeld measurement sensor installation.(D) Field\nmeasurement device for leakage magneticﬁeld.\nFrontiers inEnergy Research frontiersin.org08\nDeng et al. 10.3389/fenrg.2022.1058378\nFIGURE 6\nMeasured waveform of transformer leakage magneticﬁeld. (A) Measured waveform of normal Operation leakage magneticﬁeld. (B) Simulation\nwaveform of normal operation leakage magneticﬁeld. (C) Measurement Waveform of Interturn Short Circuit leakage magneticﬁeld. (D) Simulation\nwaveform of interturn short circuit leakage magneticﬁeld. (E) The Measured waveform of winding deformation leakage magneticﬁeld. (F) Simulation\nwaveform of winding deformation leakage magneticﬁeld.\nFrontiers inEnergy Research frontiersin.org09\nDeng et al. 10.3389/fenrg.2022.1058378\n3) Online model parameter updating refers to online model\nupdating by re-labelling the monitored fault data following\nmanual veriﬁcation after each running period of online detection.\nThe overallﬂowchart of the transformer early fault diagnosis\nmodel based on CNN transfer learning is illustrated inFigure 3.\n4 Example analysis\n4.1 The establishment of simulation model\nand actual transformer experimental\nplatform\n4.1.1 Transformer simulation model\nThe ANSYS MAXWELL software used in this study\nsimulated an actual transformer. In the actual\nmeasurement, the sensor only measure the axial and radial\nleakage magnetic ﬁeld waveforms in the transformer section.\nTo reduce the generation time of the simulation data, only the\ntwo-dimensional (2D) section model of the ring core\ntransformer is established. T he solution area of the model\nwas set according to the actual box size, and the primary and\nsecondary windings were connected using a star connection.\nThe 2D model of the transformer was set up, as shown in\nSupplementary Appendix B2 ,a n dt h eg r i dv a l u ew a ss e t\naccording to the empirical value.\n4.1.2 The construction of the actual transformer\nearly fault experimental platform\nA wiring diagram of the actual experimental platform system is\nshown in theFigure 4.I nﬁnite powerE /equals 380V, with no internal\nresistance, passes through the high-voltage busvia the boost\ntransformer. The test transformer was a three-phase, three-\nwinding transformer. Primaryand secondary windings with a\nY-shaped connection were used for the experiment. Secondary\nwindings with angular connections were unloaded. The structural\nand electrical parameters of t he transformer are listed in\nSupplementary Appendix A2. The rated load parameter is\nZ\nL /equals 159.98 + j1.35Ω. The load adjustment ranges were\nZLmin /equals 107.89 + j0.858Ω, ZLmax /equals 212.08 + j2.02.Ω.\n4.1.3 Transformer leakage magneticﬁeld\nmeasurement platform\nWe developed aﬁber optic leakage magneticﬁeld sensor based on\na magneto-optical crystal to collect the actual transformer magnetic\nﬁeld leakage waveform according to the Faraday magneto-optical\neffect. A sensor probe was installed on the transformer winding. The\nlaser emitter emitted a light signal through the optical signal polarizer\nand Faraday rotator, and the other end detected the deﬂection angle of\nthe optical signal through the optical signal receiver and converted it to\nleakage magnetic ﬁeld intensity. A leakage magnetic ﬁeld\nmeasurement platform was built on an actual transformer\nexperimental platform, as displayed inFigure 5.\n4.2 Generation and processing of leakage\nmagnetic ﬁeld experimental data\n4.2.1 Training sample generation\nDuring the normal operation of the transformer, several\ngroups of normal operation state data of the transformer were\ngenerated according to the different load values, and several\ngroups of data were generated by changing the number of turns,\nthe position, and the load of the primary and secondary side\nwinding short circuits, respectively. The minimum number of\nshort-circuit turns is two, and the maximum is 40 turns. In the\nsimulation of the winding axial deformation fault, the axial\ndeformation degree of the upper or double ends of the\nprimary and secondary side windings were changed, the axial\nFIGURE 7\nLissajous ﬁgure before and after load normalization.(A) Before normalization.(B) After normalization.\nFrontiers inEnergy Research frontiersin.org10\nDeng et al. 10.3389/fenrg.2022.1058378\ncompression ratio ranged from 1% to 40%, and several groups of\ndata were generated by changing the load. In the fault simulation\nof the radial deformation of the winding, the proportion of the\nradial deformation of the primary- and secondary-side windings\nchanges from 3% to 25%. Different training data were generated\naccording to different radial deformation ratios, the position of\nthe radial deformation line cake, and the load. Each state type of\nthe simulation model generated 125 groups of sample data and a\ntotal of 1,125 groups of training sample data.\n4.2.2 Test sample generation\nThe test samples were generated by the actual transformer,\nand several groups of data for normal operation under\ndifferent loads were generated by the actual transformer. In\nthe inter-turn short-circuit test of the primary and secondary\nwindings, the minimum is 6 turns and the maximum is\n24 turns, and several groups of data were obtained under\ndifferent loads. Winding deformation test on transformer to\nchange the degree of axial and radial deformation of the\nprimary and secondary windings to form training samples.\nEach state type generated 20 groups of sample data with\n180 groups of test-data waveforms.\n4.2.3 Comparison between simulation model\nand actual transformer normal operation and\ninter-turn short circuit\nA sampling frequency of 1 kHz was used for all samples in\nthis study. Except for the actual measured waveforms, the data\nwere ﬁltered. A comparison of the measured and simulated\nwaveforms of the transformer leakageﬁeld is shown inFigure 6.\nIt can be observed fromFigure 6, the amplitude and phase\nangle of the leakage ﬁeld at our selected measurement points\nchange to different degrees when the transformer is in normal\ncondition and a fault occurs. We use the Lissajous curve\nproposed in Section 3.2 to extract the changes in the\ncharacteristic quantities at the time of the fault as input to the\nCNN and use artiﬁcial intelligence techniques to analyze the\ndifferences for transformer winding fault classi ﬁcation.\nMeanwhile, there is still a gap between the simulation\nwaveform and the actual waveform difference. DSAN realizes\ndomain adaptation by aligning its distribution difference and\nFIGURE 8\nEffect of different number of simulation sample data and load\nnormalized on detection accuracy.\nTABLE 1 Effect of different characteristic quantity on detection\naccuracy.\nNumber of features Rm/% F1/% Ac/%\n0 92.19 91.79 92.22\n1 93.24 88.12 90.00\n2 91.59 91.15 91.11\n3 92.60 92.59 92.78\n4 94.37 94.30 94.44\n5 96.84 96.59 96.67\n6 98.94 98.87 98.89\nTABLE 2 Effect of different regularizer layers on accuracy.\nAdd MK-MMD regularizer layers Rm/% F1/% Ac/%\nCNN only 89.78 84.93 85.56\nA layer of MK-LMMD regularizer 94.92 94.91 95.00\nTwo layer MK-LMMD regularizer 96.28 96.03 96.11\nThree layer MK-LMMD regularizer 98.94 98.87 98.89\nFIGURE 9\nTransfer learning training correct rate curve.\nFrontiers inEnergy Research frontiersin.org11\nDeng et al. 10.3389/fenrg.2022.1058378\nachieves the ability to diagnose actual transformer faults using\nsimulation data.\n4.2.4 Lissajousﬁgure comparison before and\nafter load normalization\nThe measured radial leakage magnetic ﬁelds at 1, 3 are\nplotted as Lissajous ﬁgures under the rated load, respectively,\nas shown in Figure 7A. It is evident that the Lissajousﬁgures\nchange with the change in load, which adversely affects the\nclassiﬁcation accuracy. Figure 7B illustrates the Lissajous\nﬁgures of measuring points 1, 3 after load normalization. It is\nevident that after load normalization, the change of Lissajous\nﬁgure caused by the change of transformer load is eliminated,\nand the characteristic quantity of leakage magneticﬁeld is not\naffected by the load.\n4.2.5 Lissajousﬁgure feature extraction and gray\nimage generation\nThe characteristic quantity of the Lissajousﬁgure formed by\nthe leakage magnetic ﬁeld was extracted, and the data were\ntransformed into gray image data of 6 × 6. The gray image\nformed by the characteristic quantity of the transformer winding\nis shown inSupplementary Appendix B3, B4.\n4.3 Example analysis\nThe transfer neural network prepared in this study is based\non Python 3.6 version and Pytorch version 1.2.0. CPU training\nwas then performed. The CPU of the computer was an AMD\nRyzen 7 4800 H, and the main frequency was 2.90 GHz. A batch\nFIGURE 10\nComparison of T-SNE scatter plots under different training models.(A) CNN T-SNE dimension.(B) A layer of MK-LMMD regularizer T-SNE\ndimension. (C) Tow layer of MK-LMMD regularizer T-SNE dimension.(D) Three layer of MK-LMMD regularizer T-SNE dimension.\nFrontiers inEnergy Research frontiersin.org12\nDeng et al. 10.3389/fenrg.2022.1058378\nof 10 sets of data, initial learning rate 0.4, training 100 Epohs,\nMK-LMMD regularizer penalty factor initial valueλ /equals 1. The\ntransformer states in this paper are divided into normal\noperation, winding deformation and inter-turn short circuit.\nThe inter-turn short circuit is subdivided into primary\nwinding inter-turn short circuit and secondary winding inter-\nturn short circuit. The winding deformation is subdivided into\nnine states, namely, the axial deformation at the upper end of\nprimary and secondary side winding, the axial deformation at the\ntwo ends of primary and secondary side winding, and the radial\ndeformation of primary and secondary side winding. The\noperation state of the transformer is coded as shown in\nSupplementary Appendix A3.\n4.3.1 Load normalization and simulation sample\nnumber experiments\nTo test the inﬂuence of load balances and the number of\nsimulation samples participating in training on transformer fault\ndiagnosis, we also generated gray images for training and testing\nthe data without load normalization. Simultaneously, to detect\nthe inﬂuence of the number of simulation samples on the\ndetection effect, different numbers of simulation samples were\nselected for ofﬂine training. To ensure that the data of the ofﬂine\ntraining test set were unchanged, a certain number of simulation\nsamples were randomly selected as the training set, and samples\nwithout and after load normalization were tested. The accuracy\nresults are presented inFigure 8.\nIt is evident from the above diagram that load\nnormalization has a signi ﬁcant impact on overall accuracy.\nLoad normalization can signiﬁcantly improve the transformer\ndetection accuracy. Compared with the unnormalized load\ndata, the highest accuracy increased by 28.33%.\nSimultaneously, the number of training sets also affects the\ndetection accuracy. Increasing the number of simulation\nsamples did not always impro ve the accuracy of the test.\nWhen the number of simulat ion samples is too large,\nt h em o d e lf o c u s e so nt h ed e t e c t i o no fs i m u l a t i o ns a m p l e s ,\nwhich reduces the accuracy of the actual transformer\nFIGURE 11\nDSAN error curve of self-attentive mechanism.\nTABLE 3 Identiﬁcation accuracy of different transfer methods in case\nof transformer faults.\nTransfer method Rm/% F1/% Ac/%\nDAN 91.34 91.06 91.11\nDeep-CORAL 95.62 95.55 95.56\nGAN 96.21 96.12 96.11\nDSAN 96.84 96.66 96.67\nModel in this paper 98.94 98.87 98.89\nFrontiers inEnergy Research frontiersin.org13\nDeng et al. 10.3389/fenrg.2022.1058378\nFIGURE 12\nComparison of diagnostic results of four different transfer models.(A) DAN transfer learning model diagnosis result graph.(B) CORAL transfer\nlearning model diagnosis result graph.(C) GAN transfer learning model diagnosis result graph.(D) DSAN transfer learning model diagnosis result\ngraph. (E) Diagram of the diagnostic results of the model in this paper.\nFrontiers inEnergy Research frontiersin.org14\nDeng et al. 10.3389/fenrg.2022.1058378\ndetection. When the number of simulation samples was 80 in\neach state, the accuracy was the highest, and the accuracy did\nnot increase again when the number of training samples\nincreased.\n4.3.2 Experiment on the quantity of\ncharacteristic quantities of magneticﬁeld\nleakages\nTo test the in ﬂuence of the leakage magnetic ﬁeld\ncharacteristics on the accuracy of the transformer fault\ndiagnosis, different quantities of characteristics were selected\nfor training and testing, and the accuracy of classiﬁcation was\ncompared. For the experimental group without feature\nparameters, we directly used the amplitude and phase angle\ndata of the six measuring points to load balance and convert\nthem into gray images for testing. Recall rate R\nm, stability\ncomprehensive index F 1, and accuracy Ac were used as\nevaluation indexes. Table 1 presents the results.\nIt can be observed fromTable 1that the method of using the\ncharacteristic quantity has a positive effect on enhancing the\naccuracy of transformer diagnosis. Compared with the method of\nusing only the amplitude and phase angle of the leakage magnetic\nﬁeld to diagnose faults, the accuracy of this method was\nimproved by 6.67%.\n4.3.3 MK-LMMD regularizer layer experiment\nThe data of the 80 simulation groups for each fault state\nwere used as training samples, and the measured waveform\nwas used as the test sample. To test the effect of adding\ndifferent numbers of MK-LMMD regularizers on the test\nresults, the training results of adding MK-LMMD\nregularizers in the last layer, last two layers, and three\nlayers of the full connection layer were tested and\ncompared with the results of the CNN classi ﬁcation\nmodel without transfer learni ng. The results are as follows.\nTable 2 presents that the accuracy curve of the classiﬁcation\nmodel with different number s of MK-LMMD regularizer\nlayers increases with the number of iterations, as shown in\nFigure 9.\nTable 2indicates that the difference between the simulation\ndata and the actual transformer data cannot be overcome when\nthe non-transfer CNN fault classiﬁcation model is directly used\nfor actual transformer detection, resulting in unsatisfactory\naccuracy of the actual transformer fault classi ﬁcation. As\nshown in Figure 9, the classiﬁcation model with three-layer\nMK-LMMD regularization has the highest accuracy and\nfastest convergence rate, which is 13.33% higher than that\nwith only CNN.\nThe transformer fault features extracted from the model with\nMK-LMMD regularizers of different layers were reduced to 2D\nvisualization by T-SNE, as shown inFigure 10.\nIn high-dimensional spatial data, the points with closer\ndistances remain close when they are projected to 2D by\nT-SNE dimension reduction. The farther the distance of\neach cluster, the greater the difference and the better the\nclassi ﬁcation effect. The results in Figure 10 reveal that the\ntransfer learning model u sing three-layer MK-LMMD\nregularization has a better discrimination for different fault\ntypes of the actual transformer, indicating that increasing the\nadaptability of the high-order feature layer can effectively\nimprove the transfer effect.\n4.3.4 Self-attention mechanism deep\nsubdomain adaptive network experiment\nTo verify the effect of the DSAN network with the self-\nattention mechanism, the datafrom 80 simulation groups for\neach fault state were used as training samples, and the\nmeasured waveform was used as the test sample. The error\niteration curve obtained using training is illustrated in\nFigure 11.\nFigure 11 shows that in the training process without\ngiving training samples self-attention weights, some\nsamples deviate too much from the test sample, resulting\nin large transfer error of M K-LMMD regularization,\nresulting in oscillation of e rror curve. The self-attention\nDSAN proposed in this paper can speed up the network\ntraining speed, reduce the error level, has good stability and\nreduce the training loss.\n4.4 Comparative experiments with other\ntransfer networks\nTo compare the proposed method with other transfer\nneural networks, the existi ng DAN transfer learning ( Long\nand Wang, 2015), CORAL transfer learning (Sun and Saenko,\n2016), GAN transfer learning (Hu et al., 2021), and traditional\nDSAN models are used for comparison (Zhu et al., 2021). In\nthe experiments, the data of 80 simulation groups for each\nfault state were used as the simulation samples. The test results\nfor the 20 groups of experimental samples in each group are\nlisted in Table 3. The classi ﬁcation of the test samples is\ndepicted in Figure 12 .I n Figure 12 ,t h eb l a c ks o l i dl i n e\nrepresents the true value of the fault type and the red circle\nrepresents the diagnostic value of the model for the fault.\nWhen the red circle coincides with the black line, it indicates\nthat the diagnosis is correct; otherwise, the diagnosis is\nincorrect.\nFigure 12 illustrates that the method used in this study has\nthe best classiﬁcation effect. In addition to the misjudgment of\nthe upper end winding deformation of the secondary side, the\nclassiﬁcation effect of the fault is superior. Compared with the\nother three transfer models, the MK-LMMD regularization and\nself-attention mechanism used in the proposed transfer model\neffectively reduced the distribution distance between the\nsimulated transformer data and the actual transformer data,\nFrontiers inEnergy Research frontiersin.org15\nDeng et al. 10.3389/fenrg.2022.1058378\nand realized the transfer from the simulated transformer to the\nactual transformer with high accuracy.\n5 Conclusion\nThis paper eliminates the effect of transformer load variations\non leakage ﬁeld measurements by negative normalization and\nimproves the utilization ra te of the leakage magnetic ﬁeld\ninformation. Meanwhile, transfer learning to reduce the\ndifference between the simulation model and the actual\ntransformer data and realizes the fault classi ﬁcation model\ntrained by the simulation data to early diagnosis of actual\ntransformer faults. The inﬂuence of load change in transformer\nleakage magneticﬁeld detection is eliminated, and the characteristic\nquantity of the leakage magneticﬁeld is extracted to diagnose\ntransformer faults, which improves the utilization rate of the\nleakage magneticﬁeld information. The accuracy of the method\nproposed in this paper reaches 98.89%, which is suitable for\ndetecting and diagnosing the internal faults of transformer\nwindings promptlyvia real-time acquisitionof transformer faults\nand provides a reference for re asonable periodic shutdown\nmaintenance of transformers. However, only one structure of\ntransformer transfer learning ability is studied in this paper, for\nother structures of transformer simulation and transfer learning\nbetween actual transformers and mutual transfer between the\ndifferent structure of transformers is our next research direction.\nData availability statement\nThe original contributions presented in\nthe study are included in the article/Supplementary Material,\nfurther inquiries can be directed to the corresponding author.\nAuthor contributions\nThe XD wrote the original draft. ZZ, KY, and HZ\nprovided the supervision, rev iew, and editing of the draft.\nAll authors contributed to t heatrical and approved the\nsubmitted version.\nFunding\nFunded by the National Nature Fund (51777119).\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial orﬁnancial relationships that could\nbe construed as a potential conﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their afﬁliated organizations,\nor those of the publisher, the editors and the reviewers. Any product\nthat may be evaluated in this article, or claim that may be made by its\nmanufacturer, is not guaranteedor endorsed by the publisher.\nSupplementary material\nThe Supplementary Material for this article can be found\nonline at:https://www.frontiersin.org/articles/10.3389/fenrg.2022.\n1058378/full#supplementary-material\nReferences\nA l s h e h a w y ,A .M . ,M a n s o u r ,D .E .A . ,G h a l i ,M . ,L e h t o n e n ,M . ,a n dD a r w i s h ,M .M .F .\n(2021). Photoluminescence spectroscopy measurements for effective condition\nassessment of transformer insulating oil.Processes9 (5), 732. doi:10.3390/pr9050732\nBo, Z., Xza, B., Zza, B., and Wu, Q. (2021). Deep multi-scale separable\nconvolutional network with triple attention mechanism: A novel multi-task\ndomain adaptation method for intelligent fault diagnosis. Expert Syst. Appl.\n2021, 115087. doi:10.1016/j.eswa.2021.115087\nCabanas, M. F., Melero, M. G., Pedrayes, F., Rojas, C. H., Orcajo, G. A., Cano,\nJ. M., et al. (2007). A new online method based on leakageﬂux analysis for the early\ndetection and location of insulating failures in power transformers: Application to\nremote condition monitoring.IEEE Trans. Power Deliv.22 (3), 1591–1602. doi:10.\n1109/TPWRD.2006.881620\nC h e n ,Y .M . ,L i a n g ,J . ,a n dZ h a n g ,J .W .( 2 0 1 9 ) .M e t h o do fo n l i n es t a t u sm o n i t o r i n gf o r\nwindings of three-winding transformer based on improved parameter identiﬁcation.\nHigh. Volt. Eng.45 (5), 1567–1575. doi:10.13336/j.1003-6520.hve.20190430029\nDeng, X. l., Xiong, X. F., and Gao, L. (2014). On line monitoring method of\ntransformer winding deformation based on parameter identiﬁcation CSEE.Proc.34\n(28), 4950–4958. doi:10.13334/j.0258-8013.pcsee.2014.28.023\nElsis, M., Minh, Q. T., Karar, M., Diaa-Eldin, A. M., Matti, L., and Darwish, M. M.\nF. (2022). Effective IoT-based deep learning platform for online fault diagnosis of\npower transformers against cyberattacks and data uncertainties.Meas. (. Mahwah.\nN. J). 2022, 110686. doi:10.1016/j.measurement.2021.110686\nEmara, M. M., Peppas, G. D., and Gonos, I. F. (2021). Two graphical shapes based\non DGA for power transformer fault types discrimination.IEEE Trans. Dielectr.\nElectr. Insul. 28 (3), 981–987. doi:10.1109/TDEI.2021.009415\nGao, J., and He, J. J. (2010). Application of quantum genetic ANNs in transformer\ndissolved gas-in-oil analysis. Proc. CSEE 30 (30), 121–127. doi:10.13334/j.0258-\n8013.pcsee.2010.30.020\nGhifary, M., Kleijn, W. B., and Zhang, M. (2014).“Domain adaptive neural\nnetworks for object recognition,” in Paciﬁc rim international conference on artiﬁcial\nintelligence (Cham: Springer), 898–904. doi:10.1007/978-3-319-13560-1_76\nGu, C. L. (2010).Electrical engineering. Wuhan: Huazhong University of Science\nand Technology.\nHaghjoo, F., Mostafaei, M., and Mohammadi, H. (2017). A new leakageﬂux-\nbased technique for turn-to-turn fault protection and faulty region identiﬁcation in\ntransformers. IEEE Trans. Power Deliv. 33, 671–679. doi:10.1109/TPWRD.2017.\n2688419\nHang, W., and Butler, K. L. (2002). Modeling transformers with internal incipient\nfaults. IEEE Trans. Power Deliv.17 (2), 500–509. doi:10.1109/61.997926\nFrontiers inEnergy Research frontiersin.org16\nDeng et al. 10.3389/fenrg.2022.1058378\nHu, X., Zhang, H., Ma, D., and Wang, R. (2021). A tnGAN-based leak detection\nmethod for pipeline network considering incomplete sensor data. IEEE Trans.\nInstrum. Meas. 70, 1–10. doi:10.1109/TIM.2020.3045843\nJang, E., Gu, S. S., and Poole, B. (2017). Categorical reparameterization with\ngumbel-softmax. Available at: http//:ArXiv.org/abs/1611.01144. doi:10.48550/\narXiv.1611.01144\nL e c u n ,Y . ,B o t t o u ,L . ,B e n g i o ,Y . ,a n dH a f fner, P. (1998). Gradient-based learning\napplied to document recognition.Proc. IEEE86 (11), 2278–2324. doi:10.1109/5.726791\nLi, H., Huang, Z. Y., and Tian, Y. (2022). Research on transformer fault diagnosis\nmethod based on deep neural network.Transformer 59 (04), 35–40. doi:10.19487/j.\ncnki.1001-8425.2022.04.014\nLiu, N., Liang, G. D., Wang, L. F., Gao, W. S., and Tan, K. X. (2003). Construction\nand analysis of fault tree for large-scalepower transformer.Electr. Power 36 (11),\n33–36. doi:10.13336/j.1003-6520.hve.2003.02.002\nLong, M., and Wang, J. (2015). “Learning transferable features with deep\nadaptation networks,” in International conference on machine learning. PMLR\n2015, 97–105. doi:10.1109/TPAMI.2018.2868685\nNaseri, F., Kazemi, Z., Areﬁ, M. M., and Farjah, E. (2018). Fast discrimination of\ntransformer magnetizing current from internal faults: An extended kalmanﬁlter-\nbased approach. IEEE Trans. Power Deliv.33 (1), 110–118. doi:10.1109/TPWRD.\n2017.2695568\nPan, C., Shi, W. X., and Meng, T. (2020). Study on electromagnetic characteristics\nof interturn short circuit of single-phase transformer.High. Volt. Eng. 46 (05),\n1839–1856. doi:10.13336/j.1003-6520.hve.20200515040\nShamlou, A., Feyzi, M. R., and Behjat, V. (2021). Winding deformation classiﬁcation in\na power transformer based on the time-frequency image of frequency response analysis\nusing Hilbert-Huang transform and evidence theory.Int. J. Electr. Power & Energy Syst.\n129 (5), 106854. doi:10.1016/j.ijepes.2021.106854\nSun, B., and Saenko, K. (2016).Deep CORAL: Correlation alignment for deep\ndomain adaptation. Berlin, Germany: Springer International Publishing.\nWang, G., Giannakis, G. B., and Chen, J. (2019). Learning ReLU networks on\nlinearly separable data: Algorithm, optimality, and generalization. IEEE Trans.\nSignal Process. 67 (9), 2357–2370. doi:10.1109/TSP.2019.2904921\nWang, K., and Zeng, J. L. (2021). Simulation study of leakageﬁeld of power\ntransformer under different operation modes based on ﬁeld-path coupling.\nJ. Harbin Inst. Technol.26 (04), 28–37. doi:10.15938/j.jhust.2021.04.005\nWang, X., and Han, T. (2021). Transformer fault diagnosis based on Bayesian\noptimized random forest.Electr. Meas. Instrum.58 (6), 167–173.\nWu, Z. H ., Zhou, M. B., Lin, Z. H., Chen, X. J., and Huang, Y. H. (2021).\nImproved genetic algorithm and XGBoost classiﬁer for power transformer fault\ndiagnosis. Front. Energy Res.2021, 9. doi:10.3389/fenrg.2021.745744\nZhang, B. Q., Xian, R., and Yu, Y. (2021). Analysis of physical characteristics of\npower transformer windings UnderInter-turn short circuit fault.High. Volt. Eng.47\n(06), 2177–2185. doi:10.13336/j.1003-6520.hve.20201178\nZhang, J. C. (2019).Analysis of transformer winding leakageﬁeld and short-circuit\nelectromotive force. Shenyang, China: Shenyang University of Technology.\nZhao, X., Yao, C., Zhou, Z., Li, C., Abu-Siada, A., Zhu, T., et al. (2019).\nExperimental evaluation of transformer internal fault detection based on V–I\ncharacteristics. IEEE Trans. Ind. Electron. 67, 4108–4119. doi:10.1109/TIE.2019.\n2917368\nZhou, Y. C., and Wang, X. (2017). The on-line monitoring method of transformer winding\ndeformation based on magneticﬁeld measurement.Electr. Meas. Instrum.54 (17), 58–63.\nZhu, Y. C., Zhuang, F. Z., Wang, J. D., Ke, G., Chen, J., Bian, J., et al. (2021). Deep\nsubdomain adaptation network for image classiﬁcation. IEEE Trans. Neural Netw.\nLearn. Syst. 32 (4), 1713–1722. doi:10.1109/TNNLS.2020.2988928\nFrontiers inEnergy Research frontiersin.org17\nDeng et al. 10.3389/fenrg.2022.1058378",
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.6239234805107117
    },
    {
      "name": "Electromagnetic coil",
      "score": 0.535921573638916
    },
    {
      "name": "Engineering",
      "score": 0.4957324266433716
    },
    {
      "name": "Waveform",
      "score": 0.4738253355026245
    },
    {
      "name": "Electronic engineering",
      "score": 0.4200797975063324
    },
    {
      "name": "Computer science",
      "score": 0.3882032334804535
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3295961022377014
    },
    {
      "name": "Electrical engineering",
      "score": 0.29886776208877563
    },
    {
      "name": "Voltage",
      "score": 0.19665920734405518
    }
  ]
}