{
  "title": "Creating Large Language Model Applications Utilizing LangChain: A Primer on Developing LLM Apps Fast",
  "url": "https://openalex.org/W4385287322",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5083142530",
      "name": "Oğuzhan Topsakal",
      "affiliations": [
        "Florida Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5023211480",
      "name": "Tahir Çetin Akıncı",
      "affiliations": [
        "University of California, Riverside"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2117539524",
    "https://openalex.org/W2163605009",
    "https://openalex.org/W2805093171",
    "https://openalex.org/W2981852735",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W2618530766",
    "https://openalex.org/W2896457183"
  ],
  "abstract": "This study focuses on the utilization of Large Language Models (LLMs) for the rapid development of applications, with a spotlight on LangChain, an open-source software library. LLMs have been rapidly adopted due to their capabilities in a range of tasks, including essay composition, code writing, explanation, and debugging, with OpenAI’s ChatGPT popularizing their usage among millions ofusers. The crux of the study centers around LangChain, designed to expedite the development of bespoke AI applications using LLMs. LangChain has been widely recognized in the AI community for its ability to seamlessly interact with various data sources and applications. The paper provides an examination of LangChain's core features, including its components and chains, acting as modular abstractions and customizable, use-case-specific pipelines, respectively. Through a series of practical examples, the study elucidates the potential of this framework in fostering the swift development of LLM-based applications.",
  "full_text": " \nAll Sciences Proceedings \nhttp://as-proceeding.com/ \n5th International Conference on Applied \nEngineering and Natural Sciences \n \nJuly 10-12, 2023 : Konya, Turkey \n \nhttps://www.icaens.com/ © 2023 Published by All Sciences Proceedings \n \n1050 \n \n \nCreating Large Language Model Applications Utilizing LangChain: A \nPrimer on Developing LLM Apps Fast \nOguzhan Topsakal1*, and Tahir Cetin Akinci 2  \n1Computer Science Department, Florida Polytechnic University, FL, USA  \n2WCGEC, University of California at Riverside, CA, USA \n*(otopsakal@floridapoly.edu) Email of the corresponding author \n \nAbstract – This study focuses on the utilization of Large Language Models (LLMs) for the rapid \ndevelopment of applications, with a spotlight on LangChain, an open-source software library. LLMs have \nbeen rapidly adopted due to their capabilities in a range of tasks, including essay composition, code \nwriting, explanation, and debugging, with OpenAI’s ChatGPT popularizing their usage among millions of \nusers. The crux of the study centers around LangChain, designed to expedite the development of bespoke \nAI applications using LLMs. LangChain has been widely recognized in the AI community for its ability \nto seamlessly interact with various data sources an d applications. The paper provides a n examination of \nLangChain's core features, including its components and chains, acting as modular abstractions and \ncustomizable, use-case-specific pipelines, respectively. Through a series of practical examples, the stu dy \nelucidates the potential of this framework in fostering the swift development of LLM-based applications.   \n \nKeywords – Large Language Models, LangChain, Concepts, Application, ChatGPT, NLP, GPT \n \nI. INTRODUCTION \nThe past decade has witnessed an unparalleled \nevolution in the realm of artificial intelligence (AI). \nThis period, characterized by the ascendancy of \ndeep learning through the utilization of neural \nnetworks, has resulted in significant enhancements \nin capabilities pertaining to image and speech \nrecognition. One salient milestone highlighting this \nprogress is the ImageNet Large Scale Visual \nRecognition Challenge, which effectively \ndemonstrated the prowess of AI capabilities in \nimage recognition. [1][2] \nAnother major milestone in the AI landscape is \nthe successful implem entation of reinforcement \nlearning, as exemplified by DeepMind's AlphaGo \nand AlphaZero.  [3] These innovations have \ndemonstrated extraordinary performance in \ncomplex games, such as Go and Chess, using self -\nplay algorithms, thereby signifying a leap forward \nin reinforcement learning techniques. In parallel, \nthe evolution of generative models has facilitated \nthe creation of convincingly realistic synthetic \nmultimedia content. \nDuring the same period, the field of natural \nlanguage processing (NLP) experienced \nremarkable transformations. The advent of \nadvanced models, exemplified by the likes of \nBERT (Bidirectional Encoder Representations \nfrom Transformers ) by Google [4] and GPT \n(Generative Pretrained Transformer ) by OpenAI  \n[5], and T5 (Text-to-Text Transfer Transformer) by \nGoogle [6] has fostered significant improvements \nin machine translation, sentiment analysis, and text \ngeneration, thus ushering in a new era for NLP.  \nBERT, GPT,  T5 and similar technologies all \nutilized transformers architecture and were trained \non huge amount of data and hence named as Large \nLanguage Models (LLMs).  [7] As LLMs were \ntrained using more and more data, and \nencompassed more parameters, their capabilit ies \nincreased. For example, GPT-1 (June 2018), GPT-\n2 (February 2019), and GPT-3 (June 2020) had 117 \n \n1051 \n \nmillion, 1.5 billion , and 175 billion  parameters, \nrespectively.  \nA large language model (LLM) is a subtype of \nartificial intelligence model that generates text with \nhuman-like proficiency.  [7] Characterized by a \nsizable number of parameters and trained on \nexpansive text corpora, these models are equipped \nto produce contextually pertinent and \ngrammatically coherent outputs. \nUtilizing machine learning techniques such as \ndeep learning, these models are trained to predict \nsubsequent words in a sentence based on prior \ncontext, thereby enabling the generation of \ncomprehensive sentences and paragraphs that bear \na resemblance to human-authored text. \nEven though the LLMs present limitations, such \nas occasionally producing erroneous or illogical \noutputs (also called hallucination), they achieved \nrapid success due to their performance in doing \nvarious tasks such as composing essays, writing, \nexplaining, and debugging code. The recent \nOpenAI’s LLM, ChatGPT, made the technology \nknown to most, acquiring millions of users in a \nshort am ount of time. The capabilities of GPTs \nhave become even more impressive with the \nrelease of GPT4. [8]. \nMany started to think  about how to leverage this \ntechnology to provide solutions for fields like \neducation, research, c ustomer service , content \ncreation, healthcare, entertainment, etc.  It became \npossible to develop AI applications much faster \nthan ever before b y interacting with  an LLM.  \nHowever, custom AI apps require more than just \ninteracting via a web interface. A recent open -\nsource software library called LangChain, started \nproviding solutions for the steps of developing a \ncustom AI app utilizing LLMs and gained much \nattention from th e AI community.  [9][10] In this \narticle, we describe the capabilities of LangChain \nand provide a primer on developing  large language \nmodel applications rapidly utilizing LangChain. \nII. MATERIALS AND METHOD \nLangChain is a framework for developing \napplications u tilizing large language models , and \nits goal is to enable developers to conveniently \nutilize other data sources and interact with other \napplications. To enable this, LangChain provides \ncomponents (modular abstractions) and chains \n(customizable use case-specific pipelines). We first \nprovide an overview of components and then \ndescribe several use cases.  \nA. Components \nNext, the main components of LangChain, such \nas Prompts, Memory, Chains, and Agents are \nexplained. \nA.A.1 Prompts  \nA \"prompt\" is the input to a LLM. They are \ngenerally generated dynamically when used in an \nLLM application and includes user’s input  \n(question), a set of few shot examples to help the \nlanguage model generate a better response , and \ninstructions for the LLM regarding how  to process \nthe input that comes from the user. LangChain \nprovides several classes to construct prompts \nutilizing several specialized Prompt Templates. A \nprompt template refers to a reproducible way to \ngenerate a prompt. It contains a text string (\"the \ntemplate\") that can take in a set of parameters from \nthe end user and generates a prompt. \nTable 1. Examples of prompts. The examples are adapted \nfrom the DeepLearning.AI course on LangChain. \nTask Prompt \nExtracting \ninformation  \nFor the following text, extract the \nfollowing information: \ngift: Was the item purchased as a gift for \nsomeone else? Answer True if yes, False \nif not or unknown. \ndelivery_days: How many days did it \ntake for the product to arrive? If this \ninformation is not found, output -1. \nprice_value: Extract any sentences about \nthe value or price. \ntext: {text} \nWriting a \nresponse \nWrite a follow-up response to the \nfollowing summary in the specified \nlanguage: \nSummary: {summary} \nLanguage: {language} \n \nA.A.2 Models \nLarge Language Models  (LLMs) are the main \ntype of models utilized in LangChain. They accept \na text string (prompt) and output a text string. \nThere are other types of models that are used in \nLangChain, namely, Chat Models  and Text \nEmbedding Models. Chat Models have more \nstructured API processing chat messages , and text \nembedding models take text and return its \ncorresponding embedding as a list of floats.  The \nembeddings are required when we want to work \n \n1052 \n \nwith our own documents , as discussed in the \nfollowing Question Answering from Docum ents \nsection. \nA.A.3 Chains \nThe most important key building block of \nLangChain is the chain. The chain usually \ncombines an LLM  together with a prompt, and \nwith this building block , you can also put a bunch \nof these building blocks together to carry out a \nsequence of operations on your text or on your \nother data. \nA simple chain takes one input prompt and \nproduces an output. Multiple chains can be run one \nafter another, where the output of the first chain  \nbecomes the input of the next chain. Multiple \nchains can be c oncatenated using the Simple \nSequential Chain class when there is one input and \none output, as illustrated in Fig 1.  \n \n \nFig. 1 Example of a Simple Sequential Chain \nLangChain provides another class named \nSequentialChain, when there can be multiple inputs \nbut one output, as illustrated in Fig 2. \n \nFig. 2 Example of a Sequential Chain that gets two inputs and \noutputs one result. \nA pretty common scenario  is to use several \nchains and to route an input to a chain depending \non what the input is. For example, if you have \nmultiple chains, each of which specialized for a \nparticular type of input, you could have a router \nchain which first decides which subchain to pass it \nto and then passes it to that chain.  An example of \nrouter chain is depicted in Fig 3. \n \n \nFig. 3 Example of a Router Chain that routes the input to a \nchain that can answer the input the best. \nEach chain can utilize a different or the same \nLLM and would be differentiated mostly based on \ntheir prompt. The prompts that go into an LLM as \ninput include a description of the role of the chain. \nThe input coming from the user is combined with \nthe description of the expected output to form the \nprompt so that the chain behaves as expected. \nTable 1 gives examples of these prompt \ndescriptions that a re used along with the user \ninputs to let LLM produce a result. \nTable 2. Examples of chain prompts. The examples are \nadapted from the DeepLearning.AI course on LangChain. \nName Description \nMath  \nYou are a very good mathematician. You are \ngreat at answering math questions. You are \nso good because you can break down hard \nproblems into their component parts, answer \nthe component parts, and then put them \ntogether to answer the broader question. \nHistory \nYou are a very good historian. You have an \nexcellent knowledge of and understanding of \npeople, events, and contexts from a range of \nhistorical periods. You can think, reflect, \ndebate, discuss, and evaluate the past. You \nhave respect for historical evidence and the \nability to make use of it to support your \nexplanations and judgments. \n \nA.A.4 Memory \nThe language model itself is stateless and does \nnot remember the conversation you've had so far. \nEach transaction (call) to the LLM’s API endpoint \nis independent. The illusion of memory in chatbot \nsystems is facilitat ed by supplementary code, \nwhich incorporates the context of preceding \ndialogues when interacting with the LLM . A \nmemory component is needed  that can store the \nprevious conversations and pass them to the LLM  \nwith the next prompt.  \nIn the LangChain framework, memory \nimplementation can take multiple forms. The \n\n \n1053 \n \n'buffer' type delineates memory bounds based on a \nset quantity of conversational exchanges, whereas \nthe 'token' type imposes limitations contingent on \nthe number of tokens. The 'summary memory' type \napplies an abstracted summary of tokens when a \ncertain threshold is exceeded. Beyond these \nmemory types, developers have the discretion to \narchive the entire conversation within a \nconventional database or a key -value store. This \ncan be beneficial for auditing purposes or to \nenhance system performance through reflective \nanalysis of past interactions. \nA.A.5 Question Answering from Documents \nOne of the most common  and complex \napplications that are being built using an LLM is a \nsystem that can answer questions o n top of or \nabout a document. Given a piece of text, extracted \nfrom a PDF file, a webpage, a csv file or another \ntype of document, apps can be developed to use an \nLLM to answer questions about the content of \nthose documents to help users gain a deeper \nunderstanding and get access to the information \nthat they need. Once LLMs can be utilized to \nprocess data that they were not originally trained \nfor, there are many use cases that can be achieved. \nThere are various steps involved in answering  \nquestions from own  documents, as depicted in Fig \n4.  \n \n \nFig. 4 Steps to answer questions from own documents. \n \nLangChain provides functionality to easily achieve \nthese steps to load, transform  (split), store , and \nquery your data . LangChain has the following \nclasses that help to perform these functionalities.  \n• Document Loaders:   Loads documents from \nmany different sources , including CSV, PDF, \nHTML, JSON, Excel, GitHub, Google Drive, \nOne Drive, XML, Wikipedia, and many more. \n• Document transformers: Splits documents into \nsmaller chunks so that they can be processed by \nLLMs. \n• Text embedding models: Take unstructured text \nand turn it into a list of floating-point numbers \nthat represent corresponding embeddings. \n• Vector stores : Helps to s tore and search over \nembedded data. \n• Retrievers: Helps to q uery your data  based on \nembedding similarities. \n \nEmbeddings generate quantitative representations \nfor textual units, encapsulating their semantic \nessence in a numerical format. When applied to \nsimilar textual content, these embeddin gs yield \nclosely aligned vectors. This enables an evaluation \nof textual similarity within the vector space, \nfacilitating an intuitive understanding of textual \ncoherence. This becomes particularly instrumental \nwhen selecting text pieces to feed into a langu age \nmodel for query resolution.  \nThese embeddings are stored in vector databases. \nWhen a user query comes in, it is converted into \nembeddings and then sent to the vector database to \nfind the most semantically close text based on the \nsimilarity scores computed by getting a dot product \nof the query embedding and the embeddings stored \nin the vector database.  The dot product can also be \nexpressed as the product of the magnitudes of the \nvectors and the cosine of the angle between them , \nas shown in the following equation, where a and b \nare the vectors being compared [12]: \na ⋅ b = ∣a∣ ∣b∣ cosα \n \nThere are several methods to pass the content of \nthe documents and process them via LLM. The \nmost used method is the stuff method which is \nsimple and works well if the text chunks that were \nreturned from the vector store similarly function fit \ninto the context size of the LLM. The Fig 5. depicts \nthe stuff method where retrieved similar documents \nare passed to LLM in a single prompt. \n \n \nFig. 5 Stuff method passes similar documents in a single \nprompt. \nThe other methods that can be used in processing \ndocuments when the retrieved documents do not fit \nin a single prompt are “map reduce,” “refine,” and \n“map rerank.” \nMap reduce takes all the chunks, passes them \nalong with the question to a language model, gets \nback a response, and then uses another language \nmodel call to summarize all of the individual \nresponses into a final answer. Map reduce  can \n\n \n1054 \n \noperate over any number of docum ents and can \nprocess individual questions in parallel. However, \nit requires more calls  and does treat all the \ndocuments as independent, which may not always \nbe the most desired thing.  Map reduce process is \ndepicted in Figure 6. \n \n \nFig. 6 Map reduce passes similar documents to multiple \nLLMs and then uses another LLM to finalize the output. \nRefine is used to loop over many documents \niteratively, building  upon the answer from the \nprevious document , which generally leads to \nlonger answers. However, many calls are required, \nand the calls cannot be done in parallel , causing \nslower execution. The refine methods is depicted in \nFig 7. \n \n \nFig. 7 Refine method iteratively builds the answer. \n \nMap rerank do es a single call to the language \nmodel for each document and ask s for a score. \nThen it selects the document with the highest \nscore. The map rerank method is shown in Fig. 8. \n \n \nFig. 8 Map rerank method gets an output score and then \nselects the output with the highest score. \nA.A.6 Agents \nWhen an app needs a flexible chain of calls to \nLLMs and other tools based on user input, agents \ncan be utilized. An agent determines which tool \nfrom a suite of tools needs to be used for the user \ninput. An agent can be either an action agent that \ndecides on the next action using the outputs of all \nprevious actions or a plan-and-execute agent  that \ndecide on the full sequence of actions upfront, then \nexecute them all without updating the plan. \n• Action Agent operates at a high level by \nreceiving user input, determining the \nappropriate tool and its input, executing the \ntool and recording its output (termed as an \n'observation'), and making decisions on \nsubsequent steps based on the history of tool \nusage, inputs, and observations. This cycl e \nrepeats until the agent can directly respond to \nthe user. These agents are encapsulated in agent \nexecutors that manage the sequence of actions \nand interactions with the tools. \n• Plan and Execute Agent operates at a high level \nby receiving user input, devis ing a \ncomprehensive sequence of steps, and \nimplementing these steps in a sequential \nmanner, where outputs from previous steps are \nutilized as inputs for subsequent ones. A \ncommon implementation involves using a \nlanguage model as the planner and an action \nagent as the executor. \n \nWithin the framework of agent -based systems, \nthe concepts of tools and toolkits play a significant \nrole. Tools, defined as interfaces that facilitate \nagent-world interactions, constitute specific actions \nthat an agent can perform, purposefully selected \nbased on the agent's functional objective. \nConversely, toolkits represent aggregated \ncollections of synergistic tools, assembled to cater \nto particular use cases. Toolkits are specifically \ndesigned to consolidate tools that f unction \neffectively in unison for distinct tasks, and they \nencompass convenience methods for easy loading. \nFor instance, an agent interfacing with a SQL \ndatabase would necessitate a tool for executing \nqueries and another for inspecting tables. \nB. Use Cases \nLangChain framework provides w alkthroughs of \ncommon end-to-end use cases on the topics such as \nautonomous agents , c hatbots, c ode understanding \nagents, e xtraction, q uestion answering over \ndocuments, s ummarization, and a nalyzing \nstructured data . Each of these categories provides \nseveral examples of how to utilize LangChain to \nimplement the LLM app using Langchain. For \nexample, the AutoGPT sample given under the \n‘autonomous agents’ category provides a notebook \nimplementing AutoGPT using LangChain that \n\n \n1055 \n \naims to autonomously achieve whatever goal is \ngiven. An increasing  number of examples of \nLangChain use cases are documented at the \nLangChain website. [12] \nIII. DISCUSSION \nThe rise of Large Language Models (LL Ms), \nspecifically OpenAI's ChatGPT, signifies a \ntransformative phase in AI development with \nbroad-ranging applications. LangChain, an open -\nsource library, stands out due to its proficiency in \nintegrating with diverse data sources and \napplications, making it an influential tool in the AI \ncommunity. \nLangChain's modular structure, with \ncustomizable pipelines for specific use cases, \nexpedites the development process for LLM \napplications. This paper contributes to the \ndiscourse on LLM application development, \naiming to spur further exploration of LangChain \nand similar tools.  To help facilitate the \ndevelopment of LLM applications utilizing \nLangChain, we provide a sample Jupyter Notebook \npage showcasing many of the concepts described \nhere at a GitHub page. [13] \nIV. CONCLUSION \nIn conclusion, the advent and rapid adoption of \nLarge Language Models, underscored by the rise of \nOpenAI’s ChatGPT, signify a new frontier in the \nAI landscape. These models have exhibited \nproficiency across a multitude of tasks, setting a \nprecedent for future advancements.  \nParticularly, LangChain, with its ability to \nstreamline the development process of LLM \napplications, has demonstrated significant potential \nin the AI ecosystem. It has pioneered a new \napproach that enables developers to interact with \nvarious data sources and applications effortlessly. \nThis flexibility and efficiency, characterized by \nLangChain's modular abstractions and \ncustomizable use -case-specific pipelines, make it \nan invaluable tool for the future of LLM \napplications. \nThis pa per provides insights into LangChain's \nstructure and usage in specific use -cases, \nelucidating its capacity to foster rapid \ndevelopment. It is hoped that the potential and \ncapabilities identified will spur more exploration \nand innovation in the field of LLM s and serve as a \nbasis for the development of more sophisticated \napplications, thus expanding the boundaries of \nwhat is possible with artificial intelligence. \nREFERENCES \n \n[1] OlgaRussakovsky, JiaDeng, HaoSu, JonathanKrause, \nSanjeevSatheesh, SeanMa, Zhiheng, Hu ang, \nAndrejKarpathy, AdityaKhosla, MichaelBernstein, et al. \nImagenet large scale visual recognition challenge. IJCV, \n2015. \n[2] Krizhevsky, Alex & Sutskever, Ilya & Hinton, \nGeoffrey. (2012). ImageNet Classification with Deep \nConvolutional Neural Networks. Neura l Information \nProcessing Systems. 25. 10.1145/3065386. \n[3] Sean D. Holcomb, William K. Porter, Shaun V. Ault, \nGuifen Mao, and Jin Wang. 2018. Overview on \nDeepMind and Its AlphaGo Zero AI. In Proceedings of \nthe 2018 International Conference on Big Data and \nEducation (ICBDE '18). Association for Computing \nMachinery, New York, NY, USA, 67 –71. \nhttps://doi.org/10.1145/3206157.3206174 \n[4] Jacob Devlin, Ming -Wei Chang, Kenton Lee, and \nKristina Toutanova. 2019. BERT: Pre -training of Deep \nBidirectional Transformers for Language \nUnderstanding. In Proceedings of the 2019 Conference \nof the North American Chapter of the Association for \nComputational Linguistics: Human Language \nTechnologies, Volume 1 (Long and Short Papers), \npages 4171–4186, Minneapolis, Minnesota. Associatio n \nfor Computational Linguistics. \n[5] Radford, A., Narasimhan, K., Salimans, T. & Sutskever, \nI. (2018). Improving language understanding by \ngenerative pre-training. \n[6] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine \nLee, Sharan Narang, Michael Matena, Yanqi Zh ou, Wei \nLi, & Peter J. Liu (2020). Exploring the Limits of \nTransfer Learning with a Unified Text -to-Text \nTransformer. Journal of Machine Learning Research, \n21(140), 1-67. \n[7] Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, \nY., ... & Wen, J. R. (2023). A survey of large language \nmodels. arXiv preprint arXiv:2303.18223 \n[8] Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., \nHorvitz, E., Kamar, E., ... & Zhang, Y. (2023). Sparks \nof artificial general intelligence: Early experiments with \ngpt-4. arXiv preprint arXiv:2303.12712. \n[9] Chase, H. LangChain LLM App Development \nFramework. https://langchain.com/  Accessed Jul 10 th, \n2023 \n[10] Chase, H. LangChain, Building applications with LLMs \nthrough composability , GitHub Repo, \nhttps://github.com/hwchase17/langchain Accessed Jul \n10th, 2023 \n[11] Vector Similarity Explained, The Pinecone Vector DB, \nhttps://www.pinecone.io/learn/vector-similarity/, \nAccessed July 10th, 2023. \n[12] LangChain Use Case Examples, \nhttps://docs.langchain.com/docs/category/use-cases , \nAccessed July 10th, 2023 \n \n1056 \n \n[13] GitHub page for sample Jupyter Notebook page \nshowcasing usage of LangChain framework, \nhttps://github.com/research-outcome/llm-langchain-\nexamples Accessed Jul 10th, 2023 \n \n \n ",
  "topic": "Bespoke",
  "concepts": [
    {
      "name": "Bespoke",
      "score": 0.9155151844024658
    },
    {
      "name": "Computer science",
      "score": 0.6808717846870422
    },
    {
      "name": "Modular design",
      "score": 0.6568437814712524
    },
    {
      "name": "Debugging",
      "score": 0.6542059779167175
    },
    {
      "name": "Software engineering",
      "score": 0.5953965187072754
    },
    {
      "name": "Swift",
      "score": 0.5077332258224487
    },
    {
      "name": "World Wide Web",
      "score": 0.49097397923469543
    },
    {
      "name": "Code (set theory)",
      "score": 0.45312029123306274
    },
    {
      "name": "Programming language",
      "score": 0.43119141459465027
    },
    {
      "name": "Modularity (biology)",
      "score": 0.41460371017456055
    },
    {
      "name": "Data science",
      "score": 0.38576576113700867
    },
    {
      "name": "Business",
      "score": 0.10739099979400635
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Advertising",
      "score": 0.0
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I32480017",
      "name": "Florida Polytechnic University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I103635307",
      "name": "University of California, Riverside",
      "country": "US"
    }
  ]
}