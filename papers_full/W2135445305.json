{
    "title": "USABILITY ASSESSMENT OF DRONE TECHNOLOGY AS SAFETY INSPECTION TOOLS",
    "url": "https://openalex.org/W2135445305",
    "year": 2012,
    "authors": [
        {
            "id": "https://openalex.org/A2132831413",
            "name": "Javier Irizarry",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2164322036",
            "name": "Masoud Gheisari",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2147601847",
            "name": "Bruce N. Walker",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2066723748",
        "https://openalex.org/W2099473180",
        "https://openalex.org/W1576413680",
        "https://openalex.org/W147759795",
        "https://openalex.org/W2122755080",
        "https://openalex.org/W126378795",
        "https://openalex.org/W2752491485",
        "https://openalex.org/W25665831",
        "https://openalex.org/W2148618154"
    ],
    "abstract": "SUMMARY: The construction industry lags behind many others in the rate of adoption of cutting edge technologies. In the area of safety management this is more so. Many advances in information technology could provide great benefits to this important aspect of construction operations. Innovative use of these tools could result in safer jobsites. This paper discusses initial application of drone technology in the construction industry. In this study, a small-scale aerial drone was used as a tool for exploring potential benefits to safety managers within the construction jobsite. This drone is an aerial quadricopter that can be piloted remotely using a smart phone, tablet device or a computer. Since the drone is equipped with video cameras, it can provide safety managers with fast access to images as well as real time videos from a range of locations around the jobsite. An expert analysis (heuristic evaluation) as well as a user participation analysis were performed on said quadricopter to determine the features of an ideal safety inspection drone. The heuristic evaluation uncovered some of the user interface problems of the drone interface considering the context of the safety inspection. The user participation evaluation was performed following a simulated task of counting the number of hardhats viewed through the display of a mobile device in the controlled environment of the lab. Considering the task and the controlled variables, this experimental approach revealed that using the drone together with a large-size interface (e.g. iPad) would be as accurate as having the safety manager with plain view of the jobsite. The results of these two evaluations together with previous experience of the authors in the area of safety inspection and drone technology led to recommendations for the required features of an Ideal Safety Inspection Drone. Autonomous navigation, vocal interaction, high-resolution cameras, and collaborative user-interface environment are some examples of those features. This innovative application of the aerial drone has the potential to improve construction practices and in this case facilitate jobsite safety inspections.",
    "full_text": " \nwww.itcon.org - Journal of Information Technology in Construction - ISSN 1874-4753 \nITcon Vol. 17 (2012), Irizarry, pg. 194 \nUSABILITY ASSESSMENT OF DRONE TECHNOLOGY AS SAFETY \nINSPECTION TOOLS \n \nPUBLISHED: September 2012 at http://www.itcon.org/2012/12 \nEDITOR: Amor R.  \nJavier Irizarry, Assistant Professor, \nGeorgia Institute of Technology; \nJavier.irizarry@coa.gatech.edu \nMasoud Gheisari, PhD Candidate, \nGeorgia Institute of Technology; \nmasoud@gatech.edu \nBruce N. Walker, Associate Professor, \nGeorgia Institute of Technology; \nbruce.walker@psych.gatech.edu \n \nSUMMARY: The construction industry lags behind many others in the rate of adoption of cutting edge technologies. \nIn the area of safety management this is mo re so. Many advances in information technology could provide great \nbenefits to this important aspect of construction operations. Innovative use of these tools could result in safer \njobsites. This paper discusses initial application of drone technology in t he construction industry. In this study, a \nsmall-scale aerial drone was used as a tool for exploring potential benefits to safety managers within the \nconstruction jobsite. This drone is an aerial quadricopter that can be piloted remotely using a smart phon e, tablet \ndevice or a computer. Since the drone is equipped with video cameras, it can provide safety managers with fast \naccess to images  as well as real time video s from a range of locations around the jobsite . An expert analysis \n(heuristic evaluation) as well as a user participation analysis were performed on said quadricopter to determine the \nfeatures of an ideal  safety inspection drone. The heuristic evaluation uncovered some of the user interface problems \nof the drone interface considering the context of the safety inspection. The user participation evaluation was \nperformed following a simulated task of counting the number of hardhats  viewed through the display of a mobile \ndevice in the controlled environment of the lab. Considering the task and the con trolled variables, this experimental \napproach revealed that using the drone together with a large -size interface (e.g. iPad) would be as accurate as \nhaving the safety manager with plain view of the jobsite. The results of these two evaluations together wit h previous \nexperience of the authors in the area of safety inspection and drone technology led to recommendations for the \nrequired features of an Ideal Safety Inspection Drone. Autonomous navigation, vocal interaction, high -resolution \ncameras, and collabor ative user -interface environment are some examples of those features. This innovative \napplication of the aerial drone has the potential to improve construction practices and in this case facilitate jobsite \nsafety inspections. \nKEYWORDS: drone, safety inspection, usability evaluation. \nREFERENCE: Javier Irizarry, Masoud Gheisari, Bruce N. Walker  (2012) Usability assessment of drone technology \nas safety inspection tools , Journal of Information Technology in Construction (ITcon), Vol. 1 7, pg. 194-212, \nhttp://www.itcon.org/2012/12 \nCOPYRIGHT: © 201 2 The authors. This is an open access article distributed under the terms of the Creative \nCommons Attribution 3.0 unported  (http://creativecommons.org/licenses/by/3.0/), which \npermits unrestricted use,  distribution, and reproduction in any medium, provided the \noriginal work is properly cited. \n\nITcon Vol. 17 (2012), Irizarry, pg. 195 \n1 INTRODUCTION \nIn 20 10, the construction industry contributed 3.4% of the United States total Gross Domestic Product (GDP) \n(Gilmore et al. 2011 ). One of the main concerns in such a financially important industry is related to safe ty issues. \nTechnological advances in areas such as personal protective equipment, safety conscious design, focused safety \ntraining, and others have improved worker safety. However, even with such improvements, construction continues to \nbe one of the most d angerous industries in the U.S. economy (Irizarry & Abraham 2005). According to preliminary \nresults of the most recent census data from the U.S. Bureau of Labor Statistics (BLS  2011), 4547 work -related \nfatalities were reported in 2010. Of these, 751 or 16.5% occurred on constructio n sites. The fatality rate (9.5  per \n100,000 full-time equivalent worker ) ranked fourth highest amo ng various industries (BLS  2011). Construction \nworkers are still prone to accidents that lead to material losses, temporary or perma nent disabilities, and to fatalities.  \nBoth researchers and practitioners have addressed accident prevention. There are many different procedures that \nshould be followed in order to reduce the number of accidents and move towards safe and zero -accident job sites. \nOne of the most important procedures is conducting periodical inspections of the whole construction jobsite. This \nmeans safety managers should conduct daily, weekly, and monthly inspections on the jobsite (consistent safety \nmanagement) to evaluate s ite conditions based on safety criteria. To achieve this goal, safety managers perform \nwalkthroughs of the jobsite and check the current safety situation of the workers, materials, and equipment, while \nhaving direct interaction with the workers. Providing safety managers with a communication tool that can enable \nthem to be present at any time in all different areas of the construction jobsite and to provide the workers with real \ntime feedback would be extremely beneficial. In this study, an aerial drone qua drotor helicopter (AR.Drone \nquadricopter) was used as an early prototype of a safety manager’s assistant drone. An ideal safety manager assistant \ndrone should be able to fly all around the construction jobsite and provide the safety managers with real time  \ninformation about what is happening on the jobsite. Also safety managers should be able to have direct interaction \nwith workers through the communication tools (video and voice transmitters) that would be provided on the ideal \ndrone. \nThe following section  will describe the task analysis of safety inspection as one of the responsibilities of safety \nmanagers. Then for facilitating safety managers’ performance of this task, the AR.Drone quadricopter was \nrecommended as a prototype of an ideal inspection tool. A usability evaluation of the quadricopter was performed \nusing (1) an expert analysis - Heuristic Evaluation (HE) and (2) a user participation analysis. These usability \nevaluations provide an understanding of what the level of applicability of this drone i n construction safety inspection \nis and how it can be improved. Finally, the features of an ideal inspection drone are discussed.  \n1.1 Safety Inspection \nThe Occupational Safety and Health Administration (OSHA) specifically requires that employers such as contr actors \nare responsible for providing workers a safe place at which to work (Koehn 1996). Safety managers have many \ndifferent responsibilities related to achieving this goal. The focus of the present research project is on safety \ninspections, which is one of the main responsibilities of a safety manager. \nToole (2002) suggested that all construction accidents result from eight root causes: lack of proper training; deficient \nenforcement of safety; safe equipment not provided; unsafe methods or sequencing; unsa fe site conditions; not using \nprovided safety equipment; poor attitude toward safety; and isolated, sudden deviation from prescribed behavior. \nOne of the keywords that have been used by Toole (2002) to define the factors needed to prevent root causes of \nconstruction accidents is “Observation”. The safety manager should observe employees, actual methods and \nsequencing, and actual site condition on a frequent basis (Toole 2002). Therefore, the safety managers’ task of \nobservation can be defined as frequently walking around the jobsite and getting real time data through direct \nobservation and interaction with workers. This data would be used as the input in the safety manager’s decision -\nmaking process.  \nBased on this definition, observation in the construction safety inspection process has three main characteristics: (1) \nbeing frequent; (2) direct observation; (3) direct interaction with workers. Below is the narrative sequence the user \nwill follow to complete the task of safety inspection. \nITcon Vol. 17 (2012), Irizarry, pg. 196 \nFrequent walking and observation: One of the main responsibilities of safety managers is their daily walking and \nobservation of the whole construction jobsite. They should walk around to check workers, material, and equipment \nbased on safety criteria. This frequent observation would usually occur on a daily basis  and when there is only one \nsafety manager who is responsible for a large construction jobsite, the observation can take more time and become s \ncomplex.  \nDirect observation: The essence of safety inspections is direct ob servation on a construction jobsite. Safety mangers \nshould be able to go in person to all different areas of the construction jobsite. This direct observation is a part of \ntheir daily inspection task. Direct observation would require the safety manager’s p resence in a short time to get real-\ntime data at any specific location. Those locations can range from the bottom of excavation trenches to the top of the \nroof structures. This may happen either when the usual construction activities are happening or when an accident has \nstopped work activity. Safety managers should be able to be present at those locations to observe and provide \nfeedback.  \nDirect interaction: Safety managers not only need to see what is happening in different areas of the construction \njobsite, but also they should be able to have interaction with the workers. According to Rasmussen et al. (1994), \neffective safety feedback mechanisms should be established to promote safe work practices that alert workers of \ndeviations from prescribed practices, entry into unsafe work zones, and failure of standard controls. Safety managers \nwould provide real time feedback (e.g. reminding a worker to wear his hardhat or alerting a welder about his unsafe \nlocation/situation) through a direct interaction. Safety managers should be able to observe a situation and then, after \nan internal decision -making process, provide appropriate feedback. However, it is difficult to find safety feedback \nmechanisms that are implemented in construction, and no technology or process  is currently being used in \nconstruction that can provide feedback in real -time (Shell Safety Committee, 1987). So any technology that can \nimprove safety management by facilitating the analysis and communication of safety issues would have potential \nbenefits (Hallowell et al. 2010). \nThis study proposes that a drone can be used to fly frequently over the construction jobsite and provide the safety \nmanagers with real time information about what is happening on the jobsite (frequent and direct observation). Al so, \nthrough the communication tools (video and voice transmitters) embedded in the drone, safety managers would be \nable to interact directly with workers (direct interaction). \n1.2 UAVs and the AR.Drone Quadricopter \nDrones are Unmanned Aerial Vehicles (UAVs) th at would operate under remote/autonomous control without any \npilot onboard. This operation relies mostly on human involvement. The very first application of this device was \nwithin military missions and now they have their permanent position in the military  arsenal (Nisser and Westin \n2006). Some peaceful applications of these devices are in border patrol; search, rescue and damage investigations \nduring/after disaster (e.g. hurricane, katrina or earthquake); locating forest fires or frost conditions in farmla nds; \nmonitor criminal activities; mining; advertising; scientific surveys and secure pipelines and offshore oil platforms \n(Nisser & Westin 2006, and Anand 2007) \nOne of the recent cases of using these devices for civilian applications is when a tsunami stru ck the Fukushima \nnuclear power plant in Japan on the 11 th of March 2011. During that disaster, due to very unsafe conditions at the \nplant, Tokyo Electric Power (TEPCO) used a US -made micro aerial vehicle called Honeywell T-Hawk™ to \nphotograph the nuclear plant from above. This flying robot had already been used by the US military to find roadside \nbombs in Iraq (Honig 2011).  \nThere are several companies developing a variety of commercial drones. These drones usually provide an aerial \nphotography and video pl atform for different applications in the industry or government. Table 1 lists some of the \npopular drones in the market and important information about them. \nITcon Vol. 17 (2012), Irizarry, pg. 197 \nTABLE 1 Some examples of commercial drones in the market \nDrone name Developed by Cost ($) Weight \n(gr) \nOperational \nDuration (Min.) \nCamera \nScout Aeryon Labs Inc. 30,000 to 50,000  1,300  25  \n \n1080p HD \nDraganflyer X8 Draganfly Innovation Inc. 25,000 to 30,000  1,700 20  1080p HD \nMD4-1000 Microdrone GmbH Starts from 50,000 1,800 88 720p HD \nAR.Drone Parrot 300 420 15  640x480 pixels \nVGA \nThe first three drones in the table (Scout by Aeryon Labs Inc. , Draganflyer X8 by Draganfly Innovation Inc. , and \nMD4-1000 by Microdrone GmbH ) are sophisticated commercial drones that have been recommend to be used for \ndifferent application s from aerial photography and video to real state inspection. These drones have applicable \nfeatures such as onboard GPS and HD cameras but the two important features which were used as the research \ngroup’s main filters for choosing an ap propriate drone platform were (1) the capability of streaming real -time video \nto an appropriate and not complicated user interface and (2) the low cost. For safety inspection purposes, the drone \nshould be capable of providing real-time video of the current situation at the construction jobsite. Only under such an \nenvironment a safety manager would be able to provide immediate feedback and interact with the workers in real -\ntime visually as well as via audio communication. Moreover using the current infrastru cture (the user’s own tablet or \nsmartphone) for controlling the drone and receiving its real -time feed would be less expensive and more applicable \nfor users. These three drones were not developed to be controlled by a mobile tablet computer or smartphone o r \nstream real-time video to an interface. Scout can be controlled using its own complicated command center interface \nbut is capable of streaming  the real-time feed to  tablets or smartphones . Draganflyer X8 is also controlled using its \nown command center interface, which does not provide real -time video on it,  but high-resolution video glasses that \ncan be connected to it to provide real -time streaming for the user. MD4-1000 also can be controlled using its own \ncontrol joystick and does not provide a real-time feed directly on the control interface.  \nThe limitations of n ot being able to provide a simple interface for both controlling and providing real -time feed \ntogether with the very high cost ($25,000 to $50,000) resulted in the selection of  the AR.Drone, developed by the \ncompany Parrot™, as a drone platform for this research (Figure 1). It is the first quadricopter that can be controlled \nby an iPhone/ iPodTouch/ iPad device through its onboard Wi -Fi system (AR.Drone website). It was initially \ndesigned for the Apple iOS platform but now it can also  be controlled with any Android device or even a computer \nand a joystick. Besides its affordable price, this consumer grade drone has some features that qualified it as a \nprototype of an ideal safety assistant drone.  A major feature that is very useful in this research is real time video \nstreaming. Dual cameras are embedded, one on the front and one underneath facing the ground, which help the \noperator to control the drone through the Wi -Fi connection. As an applied e xample, some engineers in New Zealand \nused this quadricopter to examine and film the front of the Roman Catholic Cathedral in Christchurch that was \ndamaged in the 22nd of February  2011 earthquake (Zibreg 2011). Krajnik et al. (2011) has declared that m any \nuniversities and research institutions have started using this device as an experimental platform in different \nresearches such as autonomous surveillance/navigation  (Faigl et al. 2010) , human -machine interaction  (Ng and \nSharlin 2011), and even as a sport a ssistant by providing athletes with external imagery of their actions (Higuchi et \nal. 2011). The relevant specifications of the AR.Drone are listed in Table 2.  \n \nFIG 1. AR.Drone Quadricopter (Parrot, 2011) \n\nITcon Vol. 17 (2012), Irizarry, pg. 198 \nTABLE 2: AR.Drone specifications (Adopted from Brandon 2010, Krajnik et al. 2011 and Parrot, 2011) \n \nDrone Control  (version 1.6.1) by Kammerer (2011) , AR.PowerFlight  (version 1.2) by Baeumle (2010) , Drone \nMaster (version 1.2) by Logic Consulting LLC (201 1), Drone Captain  (version 1.5) by New Wave Industries Inc. \n(2011), Flight Record ( version 1.6.2) by All About Jake LLC (2011)  and Free Flight (1. 9.1) by Parrot (2011)  are \namong the various applications developed for controlling the AR.Drone through iPhone /iPad devices. Of these \napplications, Free Flight was the first application created for the Parrot AR.Drone (AR.Drone website). Since this \napplication was not capable of video recording or taking still pictures,  and these features were required for \nperforming the evaluations,  another application called Flight Record, which did not have those limitations  about \nvideo recording and taking images, was used in this research.   \n1.3 Usability and User-Centered Systems \nSystems have traditionally been designed and devel oped through a t echnology-center perspective (Ends ley et al. \n2003). In such a perspective the designer s would accept the technology as is and would try to apply the very same \ntechnology in different domains without considering the very important element of the ultimate end-user (human). In \na technology-centered perspective, the end user and all its requirements would be considered improperly identical in \ndifferent domains. In this research, a user -centered approach was employed. Unlike the technology -centered \napproach, the very first issue that should be resolved in a user -center perspective is whether the technology is usable \nconsidering the real users’ experience and their own requirement s in a specific domain. This user -centered usability-\nbased step would  provide a grounded base for understanding the requirements for practical application of the \ntechnology in a domain. Having the drone technology might seem very useful for safety inspection practices but the \nvery first issue that should be resolved is whet her this technology would be usable for both safety managers and \nconstruction workers. A usable system should be easy to use and learn to work with while having the least number of \ndesign errors that makes it efficient enough to be ideally used.  \nAs Figure 2 illustrates and already discussed in section 1.1, within the current construction environment the safety \nmanagers usually have direct face -to-face and vocal interaction with construction workers. But using the drone \ntechnology would change this direct i nteraction between workers and safety managers by adding the two elements of \naerial drone and the user interface to the interaction process (Figure 3). The aerial drone part of the drone system \nwould usually fly as a safety assistant over the jobsite and w ould provide a real-time view of the jobsite on the safety \nmanager’s mobile handheld device (user interface). \nSpecifications Comment \nWeight: 420g (0.9lbs) A carbon -fiber frame and Styrofoam hulls for light weight and \nresiliency against impact \nDimension (With hull): 52.5x51.5cm (20.7 inches x 20.3 inches)  Dimension (Without hull): 45x29cm (17.7 inches x 11.4 inches) \nFront video camera:  640×480 pixel color image and 75°×60° \nfield of view \nCamera streams real-time feed directly to screen \nBottom video camera:  176×144 pixel color image and 45°×30° \nfield of view \nCamera is used for calculating speed and position  \nAn ultrasonic altimeter  \nOnboard lithium-ion batteries Batteries provide enough power for 15 minutes of flying time \nA microelectromechanical (MEMS) inertial guidance system This system includes (1) a th ree-axis accelerometer, (2) a two -\naxis gyroscope, and (3) a single -axis precision gyroscope for \nyaw. \nITcon Vol. 17 (2012), Irizarry, pg. 199 \n \nFIG 2.  Construction worker and safety manager direct interaction \n \nFIG 3.  Construction worker and safety manager indirect interaction through drone technology \n \nIn such new condition, workers would see the drones flying around the jobsite and they would have to interact with \nthem as they would interact with a safety manager. At the same time, the safety manager would get a real -time view \nof the jobsite and workers on the interface of the drone system. This interactive window of the jobsite would be a \nsafety manager’s center for interaction with workers and performing inspection tasks. Having the drone technology \nfor construction safety pract ices embeds two parts, the aerial drone and the user interface. The construction workers \nusually interact with the aerial drone part of the drone technology while the safety managers would mostly interact \nwith the user interface part.  The focus of this re search is on the safety inspection part and how a drone can play the \nrole of a safety inspection assistant. In such environment, where approximately all the safety manager’s interaction \nwith the drone technology would happen within the interactive physical  interface of the system, concentrating on the \nuser interface is justified. The user -centered approach together with the usability assessment scope of this research \nled to two different usability assessments and safety manager’s user experience measurement  while performing a \nsafety related task using the system. \n1.4 Overview of the Research \nAs illustrated in Figure 4, the first step of this research was performing a Heuristic Evaluation (HE) of the AR.Drone \ninterface that is considered as a prototype of a fully  functioning safety inspection aerial drone. This expert analysis \nevaluation did uncover issues and problems with the interface, as well as leading to  some recommendations to \nenhance it. Then a within -subjects experiment was designed to test the AR.Drone w ith real subjects while \nperforming a safety-manager-related-task under different conditions. In this experiment, the subjects would count the \nnumber of hardhats they could see in different images of the construction jobsite under three different conditions ; (1) \nplain view, (2) using iPad, and (3) using iPhone. Georgia Tech’s Institutional Review Board (IRB) evaluated and \napproved the study protocol. After performing the experiment, a repeated measures analysis of variance (ANOVA) \nwas performed to test the h ypotheses that: (1) the quadcopter would serve as a suitable inspection tool; and (2) the \naccuracy of the user in identifying safety -relevant features in a scene has a direct relationship with the size of the \n\nITcon Vol. 17 (2012), Irizarry, pg. 200 \nscreen that displays the scene image. After the  statistical analysis and results, the features of an ideal safety \ninspection drone are discussed. \n \nFIG 4.  Research Methodology \n2 STUDY 1: EXPERT HEURISTIC EVALUATION \nA Heuristic Evaluation (HE) was used as the first step in evaluating the AR.Drone syst em. HE is a very popular and \ninexpensive method of systematic inspection of a user interface for usability purposes. Having the drone technology \nwould not require the safety managers’ presence in most of the jobsite. In such a situation, all the focus of t he safety \nmanager would be on the interface of an IT tool to get all the required data from the jobsite and interact with the \nworkers. All the data and interactions should happen in the user interface used by the safety manager. Making this \ninterface as us able as possible and investigating its usability issues from a safety manager perspective is extremely \ncritical. HE, developed by Jackob Nielsen and Rolf Molich in 1990, is a “guideline or general principle or rule of \nthumb that can guide a design decision  or be used to critique a decision that has already been made” (Dix et al., \n2004). Nielsen, based on his experience, has indicated that for performing the HE, three to five evaluators are \nsufficient (Dix et al., 2004). Thus, three evaluators who are famili ar with HE methodology  and had previous \nunderstanding about safety inspection  and the AR.Drone, completed the HE independently. To aid the evaluators in \nunderstanding the problems with the current design and how the system can be improved, Nielsen’s ten he uristics \nwere provided (Table 3). \nTABLE 3: Nielsen’s Heuristics for Expert Evaluation (Adopted from Dix et al., 2004)  \n# Heuristic Description \n1 Visibility of system status  Keep users informed about system status \n Provide feedback about system status \n2 Match between system and the real world \n Speak user’s language \n Follow real-word conventions \n Make information appear in natural and logical order \n3 User control and freedom \n Clearly marked “emergency exit” should be provided for a \nuser who might choose a system function by mistake \n Supports undo and redo \n4 Consistency and standards \nFollow platform conventions and accepted standards by having \nconsistent meaning of words, situations or actions in different \ncontexts \n5 Error prevention \n Make it difficult to make mistakes \n A careful design that prevents a problem from occurring in \nthe first place is better than a good error message \n6 Recognition rather than recall  Make objects, actions and options visible \n Reduce memory load \n\nITcon Vol. 17 (2012), Irizarry, pg. 201 \n7 Flexibility and efficiency of use \n Allow users to tailor frequent actions \n Provide shortcuts (accelerators) for performing frequent \ntasks would speed up the interaction that the system can cater \nto both novice and experienced user \n8 Aesthetic and minimalist Dialogs should not contain information that is irrelevant or rarely \nneeded \n9 Help users recognize, diagnose and recover from \nerrors \nProvide good error messages;(1) should be expressed in plain \nlanguage (no codes), (2) precisely indicate the problem, and (3) \nconstructively suggest a solution \n10 Help and documentation \nProvide help and documentation; (1) should be easy to search, (2) \nfocus on the user’s task, (3) list concrete steps to be carried out, \nand (4) not to be lengthy \n \nNielsen has suggested that these 10 heuristics should cover most of t he common usability problems (Dix et al., \n2004). After assessing the system and identifying usability issues, the evaluators assessed the severity of each \nusability problem based on the following scale of 0-4 (Table 4). \nTABLE 4: Severity Rating (Adopted from Dix et al., 2004) \nScale Severity Rating Description \n0 Not a problem Not a usability problem at all \n1 Cosmetic problem only Need not to be fixed (unless extra time is available on project) \n2 Minor usability problem Low priority to be fixed \n3 Major usability problem High priority to be fixed \n4 Usability catastrophe Imperative to fix this before product can be released \n \nThe evaluators used the iPad for performing the HE since the display was large enough to facilitate the identification \nof usability deficiencies. For the purpose of the HE, the following defined order was used for flying the drone: \n1. Connecting the iPad to the AR.Drone wireless through Wi-Fi \n2. Starting the “Video Record” application \n3. Drone take off \n4. Turning the video camera on \n5. Going forward for about 3 feet (From point A to point B) \n6. Turning around \n7. Going up for about 1 feet \n8. Switching from front camera to bottom camera \n9. Taking a picture \n10. Going back from Point B to point A \n11. Push the “emergency” button in the application for a quick landing \n \n2.1 Resulting issues and recommendations from HE \nOnce the evaluators completed their separate assessments on the FlightRecord User Interface (Fig. 5), all of the \nproblems and issues were collated, and the mean severity calculated. Table 5 shows the said problems as well as their \nimportance and how addressing them can improve the AR.Drone’s effectiveness in facilitating safety inspection \nactivities. All of those issues were in the categories of minor usability problem ( severity rating #2) or major usability \nproblem (sev erity rating #3).  The recommendation s included in Table 5  are based on the safety context of this \nresearch and would be a good starting point for developing an ideal safety inspection assistant drone user interface.  \n \nITcon Vol. 17 (2012), Irizarry, pg. 202 \n \nFIG 5. FlightRecord User Interface (UI) on iPad while flying the drone \n \nTABLE 5: Resulting issues and recommendations based on the HE of the UI \n# Component Description Issue Violate \nHE # \nSeverity \nRating Recommendation \n1 \n \nFlightRecord application \nlogo \nNot an appropriate logo \nand name for a \nconstruction safety \ninspection application \n2 2 \nThe elements of \nconstruction safety should \nbe used in the design of the \nlogo/name. This makes the \napplication visually \nsignificant for the \nconstruction safety \nmanagers. \n2 \n \nSwitches between bottom \nand front cameras \nLooks like a metaphor for \nvideo recording and not a \nswitching bottom for \nbottom/front cameras \n4, 5, & 6 3 \nEmbedding the concepts of \n“switching” and “cameras” \nin its button design \n(reducing memory load & \npotential errors) \n3  \nDrone’s forward speed \n(“+” is moving forward \nand “–” is moving \nbackward) \nA constant directional \narrow which does not \nchange with drone’s \ndirection \n2 & 5 2 The arrow should show the \ndirection of the drone. \n4  \nBattery bar & battery \npercentage Provides redundant data 1& 5 2 Having only bar or \npercentage is adequate \n5 \n \nRecord/Pause the front \nvideo camera \nNot a good metaphor for \nvideo recording. Also \nwhen the button is off, \nthe word “off” is not \nreadable \n4, 5, & 6 3 \nEmbedding the concepts of \n“video recording” and \n“on/off” in its button design \n(reducing memory load & \npotential errors) \n6 \n \nUser emergency reset \nwould turn the drone’s \nmotors off \nThe button is red while \nthe drone is flying and \nwould change into green \nin case of emergency \n1, 2, & 4 3 \nThe red and green colors of \ndisplay should be switched \n(reducing memory load) \n\nITcon Vol. 17 (2012), Irizarry, pg. 203 \n7 \n \nStill Snapshot would take \npicture though front and \nrear cameras \nProvides a shutter sound \nwhile taking a picture but \nthere is no visual \nfeedback to verify it \n1 2 \nProvide visual feedback \n(e.g. changing the brightness \nof the interface right after \npushing this button). \n8 \n \nJoystick: makes the drone \npivot to the right/left or \nclimb/descend Having these two buttons \ntogether would cause \nconfusion (pivoting vs. \ndirectional movement) \n1, 2, & 4 3 \nControlling the drone with a \nsingle button would reduce \nthe learning curve and \nwould allow the user to have \nhis/her other hand almost \nfree. Right/left-handed \noption should also be \nprovided in this case \n9 \n \nDrone moves forward or \nbackward by pressing + \nholding this button and \ntilting the iPhone \n10 \n \nLanding & takeoff \nThe button is not a good \nmetaphor for \nlanding/takeoff \n1 & 5 3 \nModify this button in a way \nto make the user easily find \nout drone is landing or \ntaking off (e.g. color \nchange). \n11 \n \nDirectional Gyroscope \nComplicated and \nprovides redundant \ninformation \n1 & 2 2 \nDeleting this directional \ngyroscope and providing a \nsmall map with the current \nlocation of the drone in the \nconstruction jobsite while \nhaving geographical \ndirections on the map \n12 \n \nArtificial Horizon Provides redundant \ninformation 8 2 There is no need for this \ncomponent \n \n3 STUDY 2: EVALUATION THROUGH USER PARTICIPATION \nThe heuristic evaluation concentrated on evaluating the interface of the system, as the most important part of the \nsystem for the safety mana ger, through analysis by the evaluators who are expert s in both HE and safety inspection. \nBut the expert analysis cannot be a replacement for the actual usability test with real subjects performing a safety \nrelated task. An experimental approach was employ ed to test the drone technology application the construction \nsafety inspection practices. The experiment consisted of using the drone as a tool to inspect images from a typical \nworksite. The user’s task was to count the number of hardhats present in 10 different construction-related images that \nhad been projected on a flat non-reflective surface. Note that a hardhat is a personal protective equipment item used \nin many industries including construction , and determining whether workers are wearing their hardh at is an example \nof the many inspection tasks that safety managers must complete.  \n3.1 Study Design and Methods \nA within-subjects experiment al design was employed, in which each subject participated in three  different image-\nviewing conditions. In the Control condition the subject sat in front of a board , on which the jobsite images were \nprojected, and counted the number of hardhats in each picture (Figure 6).  \n\nITcon Vol. 17 (2012), Irizarry, pg. 204 \n \nFIG 6. Experiment setup for the Control condition \nIn the other two conditions, a drone was mounted in front of the board , with the drone’s front camera capturing the \nimages of the jobsite (see Figure 7). These conditions simulate  the way the drone would actually be used on  the \nconstruction site. In the iPad condition, the  participant viewed the projected images via the screen of  an iPad tablet \ndevice. In the iPhone condition,  the participant viewed the projected images via the screen of an iPhone smartphone. \nThe iPhone and iPad were selected as representative phone -size and tablet-size mobile handheld devices respectively \nthat might be used by safety managers on a daily basis to perform inspection -related practices. The new technologies \nthat are built on current common infrastructure (e.g. iPhone or iPad) would not only have lower cost but also would \nbe easier to work with due to users’ previous experience of using similar devices on a regular basis. Having the most \naccurate and flawless user interface might also contribute to usability shortcoming when there is a small screen size. \nThe safety manager w ould only need to have interaction with a user interface on a handheld device and all the real -\ntime critical information about the safety status of the jobsite would be displayed on the interface. In such condition, \nthe restricted screen space might lead t o not accurate decisions that in the safety inspection practices might lead to \ncatastrophes. The research team performed an experiment to not only measure the user experience while performing \na safety inspection task but also to compare between the two mos t common handheld interface sizes to check which \none would lead to more accurate response and satisfy user expectations. \n \n \n\nITcon Vol. 17 (2012), Irizarry, pg. 205 \n \n(a) Experiment setup for the iPhone and iPad conditions \n   \n(b) Drone mounted on top of a \ntripod \n(c) The subject looking through an \niPhone (treatment condition) \n(d) The subject looking through an \niPad    (treatment condition) \nFIG 7. Treatment Conditions \nFor each participant, a Microsoft PowerPoint file was prepared which consisted of three parts. Each part had 10 \nimages that were randomly chosen from a pool of 40 different pictures of construction jobsites. Participants \ncompleted the following steps in each part:  \n The participant would see 10 different pictures, one at a time, of workers in a construction jobsite. \n The participant then had 5 seconds to inspect each picture and count the number of hardhats they saw in \neach image. \n\nITcon Vol. 17 (2012), Irizarry, pg. 206 \n After the 5 seconds of viewing, the picture would fade away and the subjects had 10 seconds to write down \ntheir response in the data collection form pro vided to them . After the 10 second response period,  the next \npicture would appear on the display. \n After counting the number of hardhats in all 10 pictures under any specific condition, participants were \nasked to rate several subjective statements about the viewing condition using a 7-point Likert scale.  \n \nThe experiment lasted approximately twenty-five minutes per participant. A statistical analysis was performed on the \naccuracy of the correct number of hardhats under any condition. The experiment hypothesi s was that the accuracy of \nthe user in identifying the correct number of hardhats in the pictures would have a direct relationship with the size of \nthe screen used to view the jobsite image; the larger the screen size, the more accurate the user would be.  \n3.2 Participants  \nGiven that this was a  within-subjects study, ten adult participants  (5 male and 5 female) were recruited from the \nGeorgia Tech community.  All reported normal or corrected to normal vision. None of the subjects had used the \nAR.Drone previously and only one of them had heard about it before the experiment. In the case of the touch screen \ndevices, 8 subjects had already used iPhone, 5 had used iPad, 1 had used other devices and 2 had never used any \ntouch screen devices.  \n3.3 Results of user participation experiment  \nAccuracy Scores.  Figure 8 shows each participant’s  accuracy scores in the three different conditions of the \nexperiment. Accuracy was measured by dividing the reported number of pictures by the actual number of pictures in \neach condition. A Shapiro-Wilk test (appropriate for small sample size s) with an alpha level of p = .05 was used to \nassess the normality of accuracy scores under three different conditions. The accuracy scores were normally \ndistributed under plain view ( p = .112), iPad ( p = .088), and iPhone ( p = .500). Accuracy was then analyzed with a  \none-way repeated measures ANOVA with Greenhouse-Geisser correction  when necessary, and alpha level of p = \n.05. Planned comparisons were used to compare condition means. \nThere was an effect of viewing condition, F(1.245, 11.208) = 8.143,  p < 0.05, indicating that accuracy depended on \nhow the participant viewed the images. Accuracy was highest in the Control (plain view) condition (mean accuracy, \nM = 78%), which was numerically higher than the  accuracy in the iPad condition ( M = 57%), though this difference \ndid not reach conventional levels of statistical significance, p = .096. Accuracy in the iPhone condition was lowest \n(M = 43%); this was statistically different from the Control (plain view)  condition, p = .003, and from the iPad \ncondition, p = .021. \n \nITcon Vol. 17 (2012), Irizarry, pg. 207 \n \nFIG 8. Subjects’ accuracy scores  \nSubjective Rating Scores.  Using a Likert scale (1=Strongly Disagree to 7=Strongly Agree), participants were asked \nto rate 10 different subjective statements right after they completed the hardhat counting task under each condition. \nTable 5 shows the average rating score of each statement under each condition. \nTABLE 6. Average score for each subjective statement for each  viewing condition  (1=Strongly Disagre e to \n7=Strongly Agree) \nSubjective Statement \nAverage                          (n=10) \nPlain \nView iPad iPhone \n1. I can effectively complete this task using this system.  6.4 4.8 3.7 \n2. I am able to complete this task quickly using this system.  6.3 5.1 4.8 \n3. I am able to efficiently complete this task using this system.  6.2 4.4 3.7 \n4. I feel comfortable using this system.  6.3 4.5 3.7 \n5. The size of the picture was big enough to find out the number of hardhats.  6.7 5.1 3.1 \n6. The task was mentally demanding. 2.7 2.7 3 \n7. The task was physically demanding. 1.9 2.5 2.6 \n8. The pace of the task was hurried or rushed.  2.7 2.9 4.3 \n9. Overall, the image quality was good.  6.3 3.4 2.6 \n10. Overall, I am satisfied with the ease of completing this task.  6.4 4.6 3.5 \n \nParticipants indicated that they were most able to complete the task (Question #1) using the plain view (mean \nresponse out of 7, M = 6.4), followed by the iPad (4.8) and then the iPhone (3.7), which parallels the accuracy \nresults. The same pattern of results held for nearly all of the subjective responses (see Table 6). Overall, participants \nwere very positive about their effectiveness, efficiency and comfort of performing the task with the plain view, and \nwere also positive (albeit less positi ve than for plain view) while using the iPad. Using the iPhone to complete this \nSubject1\nSubject2\nSubject3\nSubject4\nSubject5\nSubject6\nSubject7\nSubject8\nSubject9\nSubject10\nAverage\nITcon Vol. 17 (2012), Irizarry, pg. 208 \nsafety inspection task was not rated positively (most average rating scores were lower than half of the scale). Note \nthat for Question #8 regarding pace of the task, lower valu es indicate a higher rating. Screen size appears to have \nbeen a major factor in satisfaction and perceived effectiveness. The iPad’s screen size was sufficient to be rated \npositively, whereas the iPhone screen was clearly too small for this task. Only plai n view could satisfy the \nparticipants (6.3) in terms of the image quality. \n4 IDEAL SAFETY INSPECTION ASSISTANT DRONE \nIn addition to real -time video streaming on the user interface, b ased on the  results from experiment and usability \nevaluation as well as the authors’ experience in the multidisciplinary area of safety inspection and drone technology,  \nthe following proposed features should be embedded in an ideal safety inspection assistant drone:  \n \n \n(b) Voice interaction between \nworkers and the drone \n \n(a) Autonomous navigation using predefined paths or locations \n(c) Safety manager interacts with \nworkers using the drone and \nthrough the iPad \nFIG 9. Ideal safety inspection assistant drone \nThe following are considered the basic three required features fo r a safety inspection drone which are based on the \nauthors’ experience and understanding of the integrated domain of safety inspection and drone technology:  \n Autonomous navigation: The safety managers should be able to manually control the device as well as  using \nthe autonomous navigation feature. Having predefined paths or locations that the drone can automatically \nuse, with or without minimum user interference, would be an ideal feature. Figure 7a shows drone’s station \non jobsite and its use of autonomous navigation to fly along predefined paths or over specific locations  \n Voice interaction:  The safety managers should be able to talk through this tool with the workers in the \njobsite (Figures 9a and 9b). Under critical circumstances, this feature will enable  the safety managers to \nmake required commands before physically arriving to, for example, the accident scene. \n Improving the battery life:  The battery life of the AR -Drone provides up to 13 minutes of continues flight.  \nThis should be increased to allow longer flight time. \n\nITcon Vol. 17 (2012), Irizarry, pg. 209 \nFrequent walking and observation which is one of the safety managers main responsibility would require a drone to \nbe capable of having long battery life to be able to fly around the jobsite for long periods every day. Also having \nautonomous navigation and predefined paths would be a very applicable option for frequ ent observation on the \njobsites by not adding another task of controlling or piloting a drone to the safety manager’s responsibilities.  Direct \ninteraction with the workers is als o a responsibility of the construction safety managers. Vocal interaction is a very \nimportant option for an ideal safety inspection assistant drone that is aligned with the direct interaction responsibility \nof the safety manager. \nThe following features are based on the result from experimental part of the research: \n Improving Cameras: The video feedback is provided by a VGA camera (640x480 pixels) in front with a 93° \nwide angle diagonal lens and a high -speed camera in bottom with a 64° diagonal lens. These c ameras \nshould be improved to provide the safety managers with better picture and video resolution . This statement \nis supported by the negative responses of the subjects about the image quality  while using iPad and iPhone \nin the experiment (3.4, 2.6, n=10).  In addition to real time applications, h igh-resolution pictures and videos \ncan be saved in the drone to be transferred to a computer for processing when the drone has landed. \nFurthermore the tool should be capable to take pictures and videos automatically  or in predefined intervals . \nAlso another disadvantage of the camera system is that both camera images cannot be obtained for the user \nsimultaneously. The user should just have one of the bottom and forward cameras or choose two -picture-in-\npicture mode (Krajnik et al. 2011). \n Having an iPad(tablet-size)-compatible-application: Based on the questionnaires, the users would prefer to \nuse the iPad compared to the iPhone . The larger interface did provide more accurate results in the \nexperiment that also was supported by the qualitative statements (Table 5). \n \nThe following features are based on the comments provided by the users on the open-ended part of the subjective \nusability questions: \n Multitasking: Being able to have other info/applications available while usi ng the drone. For example being \nable to email a picture, surf the web, view OSHA safety codes or call/Skype while using this application \nwould be beneficial. But having multiple windows and how it may affect the productivity of the safety \nmanagers should be studied. \n Optional audio/visual/vibrating emergency warnings : Having different types of warning systems for \nvarious features (e.g. landing, battery low) would be ideal. \n Collaborative User Interface Environment: Other people involved in project (e.g. proje ct manager or \nsuperintendent) should be able to use the drone or see the interface in their own device and even be able to \nprovide comments or assist the safety manager under critical circumstances.  \n Environmental applicability:  Frequent jobsite observatio n would lead to considering climate and weather \ncondition issues in developing an ideal safety inspection assistant drone. A construction project may start in \nany season and can last for a short or long time.  Safety managers should be able to perform the jobsite \ninspection under hot/cold, rainy/snowy, and cloudy/clear conditions. Table 6 provides some climate and \nweather indicators that affect the inspection task of safety managers. These issues and their usability \nimplications should be considered while designing the safety inspection assistant drone. \nTABLE 6. Environmental (weather) indicators that affect the safety inspection task  \nEnvironmental Indicators Usability Implications \nTemperature Perspiration when it is hot and wearing gloves in cold temperature should be \nconsidered \nPrecipitation/ Snowfall Waterproofing of drone and control device \nWind The stability of the drone \nCloud The brightness and reflectivity of the display \n \n \nITcon Vol. 17 (2012), Irizarry, pg. 210 \n5 CONCLUSION \nIn this study, a small -scale aerial drone was used as a tool for  exploring potential benefits to safety managers within \nthe construction jobsite safety inspection. Safety managers should perform walkthroughs of the jobsite and check the \ncurrent safety situation of workers, materials, and equipment, while having direct interaction with workers. The \nauthors believe that providing safety managers with a safety inspection assistant drone would be extremely beneficial \nand can enable them to achieve the goals of the safety inspection.  \nUsing the AR.Drone, as an experimental p latform for this research, usability evaluation was performed using (1) an \nexpert heuristic evaluation (HE) and (2) a user participation study. These two studies provided an understanding of \nthe applicability of this drone to construction safety inspection , and how it can be improved. The HE methodology \nuncovered some user interface (UI) issues about the AR.Drone application interface and some recommendations \nwere provided to overcome those deficiencies considering Nielsen’s heuristics and safety inspection  context. \nAfterwards, the simple task of counting the number of hardhats in images of a jobsite was performed in the \ncontrolled environment of the lab under three different conditions ( plain view, via iPad, and via iPhone). This \nexperiment was designed to simulate the actual use of the drone in the construction jobsite while performing a simple \ntask of a safety manager. The data revealed that accuracy score in the iPad condition is closer to plain view condition \nand on the other hand the iPhone elicits a st atistically significant reduction in accuracy score compared to the plain \nview condition. This means iPad has closer accuracy scores to plain view in comparison to the iPhone. The findings \nwere also supported by the results of the subjective survey done af ter each part of the experiment. Subjective \nquestions included in the survey revealed that on average the participants agreed that the size of the picture on an \niPad was big enough to determine the number of the hardhats ; the iPhone screen was not large en ough. Also \nparticipants felt that the pace of performing the task was hurried or rushed using the iPhone but they didn’t have the \nsame feeling under plain view or iPad conditions. Overall, participants were satisfied with the ease of completing the \ntask under plain view and iPad conditions but they were not satisfied with the ease of performing this task using \niPhone.  \nAfterwards, based on the literature review and the studies reported on here , some features were recommended for an \nideal safety inspection a ssistant drone. Autonomous navigation, voice interaction, environmental applicability, high -\nresolution cameras, multitasking application, and collaborative user interface environment are some of those \nfeatures. \nIn terms of the challenges of using drone in the construction industry, the main one is endangering the  safety of the \nworkers in the jobsite. Issues such as workers being distracted or even hit by drones should be studied (and obviously \navoided in any deployed system). Also there is a social challeng e of applying this technology in the construction \njobsite that should be considered as well. The workers are used to having a safety manager who would walk through \nthe construction jobsite to check the safety requirements. Having a safety assistant drone, which flies over the jobsite \nand sometimes allows safety managers to talk to workers remotely, might seem awkward or even under critical \ncircumstances might not work appropriately.  But considering all the challenges, this innovative application of the \naerial drone has the potential to improve construction practices and in this case facilitate jobsite safety inspections. \nThis research can be considered as an initial step of applying drone technology to the construction industry. For \nexample, providing photos  from upper angles can be used to cover blind spots that are currently a limitation in the \nphotogrammetry of the structure and the jobsite (Ito et al. 2011).  Providing real time videos, being able to fly to all \ndifferent parts of the jobsite, and voice int eraction are some features that would make the drone an appropriate \ntechnology to be used in other sectors of the construction industry.  \nITcon Vol. 17 (2012), Irizarry, pg. 211 \n6 REFERENCES \nAll About Jake LLC (2011) “Flight Record Webpage”, retrieved on October 23, 2011.  \nhttp://www.allaboutjake.com/flightrecord/ \nAnand, S. (2007) “Domestic Use of Unmanned Aircraft Systems: an Evaluation of Policy Constraints and the Role \nof Industry Consensus Standards” Washington Internships for Students of Engineering (WISE) \nBaeumle, M. (2010) “AR.PowerFlight Webpage” retrieved on October 23, 2011. http://powerflightapp.com/ \nBLS (2011) “National Census of Fatal Occupational Injuries in 2010 (Preliminary Results).” Bureau of Labor \nStatistics, U.S. Department of Labor, August 25, 2011 \nBrandon, A. (2010) “Control your own augmented reality aerial drone? There’s an app for that” 21:50 January 6, \n2010, retrieved on April 18, 2011. http://www.gizmag.com/parrot -ardrone-iphone-controlled-remote-\nhelicopter/13741/ \nGilmore, T. L., Morgan, E. T., and Osborne, S. B. (2011) “Annual Industry Accounts, Advance Statistics on GDP by \nIndustry for 2010” Bureau of Economic Analysis, U.S. Department of Commerce, May 2011  \nDix, A., Finlay, J., Abowd, G., and Beale, R. (2004). “Human -computer interaction”,  (3rd ed.), Prentice -Hall, Inc., \n2004 \nEndsley, M. R., Bolte, B., & Jones, D. G. (2003). Designing for Situation Awareness: An approach to human -\ncentered design: CRC Press; 1 edition \nFaigl, J., Krajnık, T., Vonasek, V., and Preucil, L. (2010) “Surveillance planning with localization uncertainty for \nmobile robots.” 3rd Israeli Conference on Robotics. \nHallowell M. R., Teizer J., and Blaney W. “Application of Sensing Technology to Safety Man agement.” ASCE \nConf. Proc. 373, 4 (2010), DOI:10.1061/41109(373)4  \nHiguchi, K., Shimada, T., and Rekimoto, J.  (2011) “Flying sports assistant: external visual imagery representation \nfor sports training. ” 2nd Augmented Human International Conference, New Y ork, NY, USA, ACM  \n7:1–7:4 \nHonig, Z. (2011) “T -Hawk UAV enters Fukushima danger zone, returns with video.” 6:48PM April 21, 2011, \nretrieved on April 22, 2011. http://www.engadget.com/2011/04/21/t -hawk-uav-enters-fukushima-\ndanger-zone-returns-with-video/ \nIrizarry, J. and Abraham, D. M. (2005) “Application of Virtual Reality Technology for the Improvement of \nSafety in the Steel Erection Process.” ASCE International Conference on Computing in Civil \nEngineering, Cancun, Mexico, July 2005 (in print).  \nIto, T., Tan iguchi, M., and Ichikawa, T. (2011) “ Regeneration of 3D Profile Line Using a Combination of Photo \nImages and Target Markers ” Improving Complex Systems Today  \nProceedings of the 18 th ISPE International Conference on Concurrent Engineering , 2011, Part 4,  293-\n300, DOI: 10.1007/978-0-85729-799-0_34 \nKammerer, T. (2011) “Drone Control Webpage .” retrieved on October 23, 2011. \nhttp://www.digitalsirup.com/apps/app_dronecontrol.html \nKoehn, E., and Surabhi, M. R. (1996) “Involving employees with construction safety and health practices. ” \nImplementation of Safety and Health on Construction Sites , L. M. Alves Dias and R. J. Coble, eds., \nProc., 1st Int. CIB Safety Conf., W99, Balkema, Rotterdam, The Netherlands, 385–392. \nKrajnik, T., Vonasek, V., Fiser, D., and Faigl, J. (2011) “AR -Drone as a Platform for Robotic Research and \nEducation.” Research and Education in Robotics: EUROBOT 2011, Heidelberg, Springer. To appear.  \nITcon Vol. 17 (2012), Irizarry, pg. 212 \nLogic Consulting LLC (2011)  “Drone-Master Webpage.” retrieved on October 23, 2011.  http://drone-apps.com/ios-\napps/drone-master/ \nNew Wave Industries Inc. (2011) “Drone Captain  Webpage.” retrieved on October 23, 2011. \nhttp://www.dronecaptain.com/ \nNg, W.S., and Sharlin, E. (2011) “Collocated interaction with ﬂying robots.” Technical Report 2011 -998-10, \nDepartment of Computer Science, University of Calgary, Calgary, Canada (2011)  \nNielsen, J., and Landauer, T. K. (1993) “A mathematical model of the finding of usability problems.” Proceedings of \nACM INTERCHI’93 Conference, pages 206-13, Amsterdam, The Netherland, 24-29 April 1993. \nNisser, T., and Westin, C. (2006) “Human Factors Challeng es in Unmanned Aerial Vehicles (UAVs): A Literature \nReview” TFHS 05:1, Lund University School of Aviation. \nParrot (2011)  “Parrot AR.Drone Webpage.” retrieved on October 23, 2011. http://ardrone.parrot.com/parrot-ar-\ndrone/usa/support \nRasmussen, J., Pejtersen, A. M., and Goodstein, L. P. (1994). Cognitive system engineering, Wiley, New York.  \nShell Safety Committee (1987) “Unsafe Act Auditing.” The Hague: Shell International Petroleum Maats chappij B.V. \nToole, T. M. (2002) “Construction Site Safety Roles.” ASCE Journal of Construction Engineering and Management, \nVol. 128, No. 3, June 1, 2002.  \nZibreg. C. (2011) “ Awesome use of an iPad and the Parrot AR  Drone.” 8:10 June 15, 2011,  retrieved on June 15, \n2011. http://9to5mac.com/2011/06/15/awesome-use-of-an-ipad-and-the-parrot-ar-drone/ "
}