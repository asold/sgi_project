{
  "title": "Sparks: Inspiration for Science Writing using Language Models",
  "url": "https://openalex.org/W4285281355",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4320566945",
      "name": "Katy Gero",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A1035853273",
      "name": "Vivian Liu",
      "affiliations": [
        "Columbia University"
      ]
    },
    {
      "id": "https://openalex.org/A3209897345",
      "name": "Lydia Chilton",
      "affiliations": [
        "Columbia University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3133702157",
    "https://openalex.org/W4288400169",
    "https://openalex.org/W2956068092",
    "https://openalex.org/W3180374035",
    "https://openalex.org/W3165482393",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2952988558",
    "https://openalex.org/W4307123345",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W4287900772",
    "https://openalex.org/W2938704169",
    "https://openalex.org/W3036315984",
    "https://openalex.org/W3206079177"
  ],
  "abstract": "Large-scale language models are rapidly improving, performing well on a variety of tasks with little to no customization. In this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. We present a system for generating “sparks”, sentences related to a scientific concept intended to inspire writers. We run a user study with 13 STEM graduate students and find three main use cases of sparks—inspiration, translation, and perspective—each of which correlates with a unique interaction pattern. We also find that while participants were more likely to select higher quality sparks, the overall quality of sparks seen by a given participant did not correlate with their satisfaction with the tool.",
  "full_text": "Proceedings of the First Workshop on Intelligent and Interactive Writing Assistants (In2Writing 2022), pages 83 - 84\nMay 26, 2022 ©2022 Association for Computational Linguistics\nSparks: Inspiration for Science Writing using Language Models\nKaty Ilonka Geroand Vivian Liu and Lydia B. Chilton\nColumbia University\nkaty@cs.columbia.edu, vl2463@columbia.edu,\nchilton@cs.columbia.edu\nAbstract\nLarge-scale language models are rapidly im-\nproving, performing well on a variety of tasks\nwith little to no customization. In this work we\ninvestigate how language models can support\nscience writing, a challenging writing task that\nis both open-ended and highly constrained. We\npresent a system for generating “sparks”, sen-\ntences related to a scientific concept intended\nto inspire writers. We run a user study with 13\nSTEM graduate students and find three main\nuse cases of sparks—inspiration, translation,\nand perspective—each of which correlates with\na unique interaction pattern. We also find that\nwhile participants were more likely to select\nhigher quality sparks, the overall quality of\nsparks seen by a given participant did not cor-\nrelate with their satisfaction with the tool.1\n1 Introduction\nNew developments in large-scale language models\nhave produced models that are capable of generat-\ning coherent, convincing text in a wide variety of\ndomains (Vaswani et al., 2017; Brown et al., 2020;\nAdiwardana et al., 2020). Their success has spurred\nimprovements on many tasks, from classification\nand summarization (Brown et al., 2020) to creative\nwriting support (Coenen et al ., 2021). These im-\nprovements demonstrate that language models have\nthe potential to support writers in real-world, high-\nimpact domains.\nDespite their successes, language models con-\ntinue to exhibit known problems, such as generic\noutputs (Holtzman et al., 2020), lack of diversity\nin their outputs (Ippolito et al ., 2019), and factu-\nally false or contradictory information (Lin et al.,\n2021). Additionally, there remain many unknowns\nabout how this technology will interface with peo-\nple in real-world writing tasks, such as how lan-\nguage models can best contribute to different writ-\n1This extended abstract summarizes work published in\nDesigning Interactive Systems (Gero et al., 2022).\ning forms (Calderwood et al., 2018) and how to mit-\nigate the bias that language models encode (Bender\net al., 2021).\nIn this work we study how language models can\nbe applied to a real-world, high-impact writing task:\nscience writing. This introduces challenges differ-\nent to those in traditional creative writing tasks\nwhich tend to deal with common objects and rela-\ntions. Science writing requires a system to demon-\nstrate proficiency within an area of expertise. We\npose the following research question: How can lan-\nguage model outputs support writers in a creative\nbut constrained writing task?\nAs a test-bed, we use a science writing form\ncalled “tweetorials” (Breu, 2020). Tweetorials\nare short, technical explanations of around 500\nwords written on Twitter for a general audience;\nthey have a low-barrier to entry and are gaining\npopularity as a science writing form (Soragni and\nMaitra, 2019). We present a system that aims to\ninspire writers when writing tweetorials on a topic\nof their expertise. This system provides what we\ncall “sparks”: sentences generated with a language\nmodel intended to spark ideas in the writer.\nWe report on a study in which we have 13 grad-\nuate students from five STEM disciplines write\ntweetorials with our system and report on how they\nthought about and made use of the sparks. We\nmake the following contributions:\n• a system that generates “sparks” related to\na scientific concept, including a custom de-\ncoding method for generating sparks from a\npre-trained language model;\n• an evaluation demonstrating that sparks are\nmore coherent and diverse than a baseline,\nand approach a human gold standard;\n• a user study with 13 graduate students show-\ning three main use cases of sparks and corre-\nsponding interaction patterns, as well as an\nanalysis on how spark quality relates to partic-\nipant satisfaction.\n83\nReferences\nDaniel Adiwardana, Minh-Thang Luong, David R. So,\nJamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,\nApoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,\nand Quoc V . Le. 2020. Towards a Human-like\nOpen-Domain Chatbot. arXiv:2001.09977 [cs, stat]\n(Feb. 2020). http://arxiv.org/abs/2001.\n09977 arXiv: 2001.09977.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-\nMajor, and Shmargaret Shmitchell. 2021. On\nthe Dangers of Stochastic Parrots: Can Lan-\nguage Models Be Too Big?. In Proceedings of\nthe 2021 ACM Conference on Fairness, Account-\nability, and Transparency. ACM, Virtual Event\nCanada, 610–623. https://doi.org/10.\n1145/3442188.3445922\nAnthony C. Breu. 2020. From Tweetstorm to\nTweetorials: Threaded Tweets as a Tool for\nMedical Education and Knowledge Dissemina-\ntion. Seminars in Nephrology40, 3 (May 2020),\n273–278. https://doi.org/10.1016/j.\nsemnephrol.2020.04.005\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen,\nEric Sigler, Mateusz Litwin, Scott Gray, Ben-\njamin Chess, Jack Clark, Christopher Berner,\nSam McCandlish, Alec Radford, Ilya Sutskever,\nand Dario Amodei. 2020. Language Models\nare Few-Shot Learners. arXiv:2005.14165 [cs]\n(July 2020). http://arxiv.org/abs/2005.\n14165 arXiv: 2005.14165.\nAlex Calderwood, Vivian Qiu, Katy Ilonka Gero, and\nLydia B Chilton. 2018. How Novelists Use Genera-\ntive Language Models: An Exploratory User Study.\nIn 23rd International Conference on Intelligent User\nInterfaces. ACM.\nAndy Coenen, Luke Davis, Daphne Ippolito,\nEmily Reif, and Ann Yuan. 2021. Wordcraft:\na Human-AI Collaborative Editor for Story\nWriting. arXiv:2107.07430 [cs] (July 2021).\nhttp://arxiv.org/abs/2107.07430\narXiv: 2107.07430.\nKaty Ilonka Gero, Vivian Liu, and Lydia B. Chilton.\n2022. Sparks: Inspiration for Science Writing using\nLanguage Models. In Designing Interactive Systems\nConference 2022. ACM, Virtual Event USA.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes,\nand Yejin Choi. 2020. The Curious Case of Neu-\nral Text Degeneration. arXiv:1904.09751 [cs]\n(Feb. 2020). http://arxiv.org/abs/1904.\n09751 arXiv: 1904.09751.\nDaphne Ippolito, Reno Kriz, Maria Kustikova, João\nSedoc, and Chris Callison-Burch. 2019. Compar-\nison of Diverse Decoding Methods from Condi-\ntional Language Models. arXiv:1906.06362 [cs]\n(June 2019). http://arxiv.org/abs/1906.\n06362 arXiv: 1906.06362.\nStephanie Lin, Jacob Hilton, and Owain Evans. 2021.\nTruthfulQA: Measuring How Models Mimic Hu-\nman Falsehoods. arXiv preprint arXiv:2109.07958\n(2021), 13. https://arxiv.org/abs/2109.\n07958\nAlice Soragni and Anirban Maitra. 2019. Of scien-\ntists and tweets. Nature Reviews Cancer 19, 9\n(Sept. 2019), 479–480. https://doi.org/10.\n1038/s41568-019-0170-4\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nKaiser, and Illia Polosukhin. 2017. Attention is All\nyou Need. In Advances in Neural Information Pro-\ncessing Systems, V ol. 30.\n84",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7666110992431641
    },
    {
      "name": "Personalization",
      "score": 0.7365699410438538
    },
    {
      "name": "Perspective (graphical)",
      "score": 0.6935461163520813
    },
    {
      "name": "Variety (cybernetics)",
      "score": 0.6439197063446045
    },
    {
      "name": "Task (project management)",
      "score": 0.6134403347969055
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.5770180225372314
    },
    {
      "name": "Machine translation",
      "score": 0.4400772452354431
    },
    {
      "name": "Scale (ratio)",
      "score": 0.4372987151145935
    },
    {
      "name": "Human–computer interaction",
      "score": 0.41319432854652405
    },
    {
      "name": "Natural language processing",
      "score": 0.4067782163619995
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3158060610294342
    },
    {
      "name": "World Wide Web",
      "score": 0.21859148144721985
    },
    {
      "name": "Engineering",
      "score": 0.0889328122138977
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}