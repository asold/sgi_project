{
  "title": "The Breakthrough of Large Language Models Release for Medical Applications: 1-Year Timeline and Perspectives",
  "url": "https://openalex.org/W4392782765",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4281147778",
      "name": "Cascella Marco",
      "affiliations": [
        "University of Salerno"
      ]
    },
    {
      "id": "https://openalex.org/A4366006249",
      "name": "Semeraro, Federico",
      "affiliations": [
        "Ospedale Maggiore Carlo Alberto Pizzardi"
      ]
    },
    {
      "id": null,
      "name": "Montomoli, Jonathan",
      "affiliations": [
        "Ospedale Infermi di Rimini"
      ]
    },
    {
      "id": "https://openalex.org/A2740996025",
      "name": "Bellini Valentina",
      "affiliations": [
        "University of Parma"
      ]
    },
    {
      "id": "https://openalex.org/A3037305380",
      "name": "Piazza, Ornella",
      "affiliations": [
        "University of Salerno"
      ]
    },
    {
      "id": "https://openalex.org/A2166918402",
      "name": "Bignami Elena",
      "affiliations": [
        "University of Parma"
      ]
    },
    {
      "id": "https://openalex.org/A4281147778",
      "name": "Cascella Marco",
      "affiliations": [
        "Pain and Rehabilitation Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A4366006249",
      "name": "Semeraro, Federico",
      "affiliations": [
        "Ospedale Maggiore Carlo Alberto Pizzardi"
      ]
    },
    {
      "id": null,
      "name": "Montomoli, Jonathan",
      "affiliations": [
        "Ospedale Infermi di Rimini"
      ]
    },
    {
      "id": "https://openalex.org/A2740996025",
      "name": "Bellini Valentina",
      "affiliations": [
        "University of Parma",
        "Pain and Rehabilitation Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A3037305380",
      "name": "Piazza, Ornella",
      "affiliations": [
        "Pain and Rehabilitation Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2166918402",
      "name": "Bignami Elena",
      "affiliations": [
        "University of Parma",
        "Pain and Rehabilitation Medicine"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1981276685",
    "https://openalex.org/W4220967417",
    "https://openalex.org/W4381587418",
    "https://openalex.org/W3169375224",
    "https://openalex.org/W6601899773",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W4361289889",
    "https://openalex.org/W4376640706",
    "https://openalex.org/W4389795202",
    "https://openalex.org/W4385988139",
    "https://openalex.org/W4387880927",
    "https://openalex.org/W4386704947",
    "https://openalex.org/W4384071683",
    "https://openalex.org/W4392044798",
    "https://openalex.org/W4389070894",
    "https://openalex.org/W4389518760",
    "https://openalex.org/W6756688054",
    "https://openalex.org/W4388725043",
    "https://openalex.org/W6636381977",
    "https://openalex.org/W4390041933",
    "https://openalex.org/W4221153690",
    "https://openalex.org/W4319350602",
    "https://openalex.org/W4327946446",
    "https://openalex.org/W4322761615",
    "https://openalex.org/W4386594700",
    "https://openalex.org/W4388911158",
    "https://openalex.org/W4387058885",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W4388420209",
    "https://openalex.org/W4386827842",
    "https://openalex.org/W3163960008",
    "https://openalex.org/W4388759569",
    "https://openalex.org/W2945976633",
    "https://openalex.org/W3187467055",
    "https://openalex.org/W4285787204",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W4287208373",
    "https://openalex.org/W4320003957",
    "https://openalex.org/W4226342560",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W4378189609"
  ],
  "abstract": null,
  "full_text": "REVIEW\nJournal of Medical Systems (2024) 48:22\nhttps://doi.org/10.1007/s10916-024-02045-3\nIntroduction\nNatural Language Processing (NLP) is a subfield of artifi -\ncial intelligence (AI) that focuses on the interaction between \ncomputers and human language. Notably, NLP models can \nenable machines to understand, interpret, and generate \nhuman-like text or speech. Large Language Models (LLMs) \nare advanced NLP models within the category of pre-trained \nlanguage models (PLMs), achieved through the scaling of \nmodel size, pretraining corpus, and computational resources \n[1]. Briefly, LLMs are developed through deep learning \nmethodologies, particularly employing transformer archi -\ntectures. They are neural network models implement -\ning self-attention mechanisms for enabling the model to \nconsider the entire context rather than being restricted to \n \r Valentina Bellini\nvalentina.bellini@unipr.it\n1 Anesthesia and Pain Medicine, Department of Medicine, \nSurgery and Dentistry “Scuola Medica Salernitana”, \nUniversity of Salerno, Via S. Allende, Baronissi 84081, Italy\n2 Department of Anesthesia, Intensive Care and Prehospital \nEmergency, Maggiore Hospital Carlo Alberto Pizzardi, \nBologna, Italy\n3 Department of Anesthesia and Intensive Care, Infermi \nHospital, AUSL Romagna, Viale Settembrini 2,  \nRimini 47923, Italy\n4 Anesthesiology, Critical Care and Pain Medicine Division, \nDepartment of Medicine and Surgery, University of Parma, \nViale Gramsci 14, Parma 43126, Italy\nAbstract\nWithin the domain of Natural Language Processing (NLP), Large Language Models (LLMs) represent sophisticated mod -\nels engineered to comprehend, generate, and manipulate text resembling human language on an extensive scale. They \nare transformer-based deep learning architectures, obtained through the scaling of model size, pretraining of corpora, and \ncomputational resources. The potential healthcare applications of these models primarily involve chatbots and interaction \nsystems for clinical documentation management, and medical literature summarization (Biomedical NLP). The challenge \nin this field lies in the research for applications in diagnostic and clinical decision support, as well as patient triage. There -\nfore, LLMs can be used for multiple tasks within patient care, research, and education. Throughout 2023, there has been \nan escalation in the release of LLMs, some of which are applicable in the healthcare domain. This remarkable output is \nlargely the effect of the customization of pre-trained models for applications like chatbots, virtual assistants, or any system \nrequiring human-like conversational engagement. As healthcare professionals, we recognize the imperative to stay at the \nforefront of knowledge. However, keeping abreast of the rapid evolution of this technology is practically unattainable, \nand, above all, understanding its potential applications and limitations remains a subject of ongoing debate. Consequently, \nthis article aims to provide a succinct overview of the recently released LLMs, emphasizing their potential use in the field \nof medicine. Perspectives for a more extensive range of safe and effective applications are also discussed. The upcoming \nevolutionary leap involves the transition from an AI-powered model primarily designed for answering medical questions to \na more versatile and practical tool for healthcare providers such as generalist biomedical AI systems for multimodal-based \ncalibrated decision-making processes. On the other hand, the development of more accurate virtual clinical partners could \nenhance patient engagement, offering personalized support, and improving chronic disease management.\nKeywords Large Language Models · Chatbot · Natural Language Processing · Artificial Intelligence · ChatGPT · \nClinical Decision Support · Generative AI\nReceived: 27 December 2023 / Accepted: 10 February 2024 / Published online: 17 February 2024\n© The Author(s) 2024\nThe Breakthrough of Large Language Models Release for Medical \nApplications: 1-Year Timeline and Perspectives\nMarco Cascella1 · Federico Semeraro2 · Jonathan Montomoli3 · Valentina Bellini4 · Ornella Piazza1 · Elena Bignami4\n1 3\nJournal of Medical Systems (2024) 48:22\nfixed-size windows, and multi-head attention to capturing \ncontextual relationships in input sequences. In this process, \nrecurrent and convolution layers are not required [2]. Other \ncrucial components of the transformer architecture include \nencoder and decoder structures to respectively process the \ninput sequence and generate the output sequence. Neverthe-\nless, the architecture of a transformer can vary depending on \nits specific task and design. Some transformers are designed \nonly with an encoder structure, while others may include \nboth encoder and decoder components. For example, in \ntasks like language translation, where input and output \nsequences are involved, both encoder and decoder modules \nare required. Conversely, for language modeling or text clas-\nsification, only an encoder may be used. Other key elements \nof a transformer architecture encompass feedforward neural \nnetworks for capturing complex, non-linear relationships in \nthe data, and positional encodings to provide information \nabout the positions of tokens in the sequence [3].\nOne of the key features of LLMs is their ability to learn \ncontextual information from large datasets, enabling them \nto grasp complex language structures and nuances. There -\nfore, LLM applications are effectively employed for text \nunderstanding, speech recognition, language generation \nand translation, chatbots and virtual assistance, sentimental \nanalysis, and other purposes.\nThe widespread integration of OpenAI’s LLM Chat-\nGPT (Chat Generative Pre-Trained Transformer) has stirred \nconsiderable excitement since its debut in November 2022 \n[4]. Following this release, a proliferation of new tools \nthroughout 2023, gave rise to a dynamic landscape of tech -\nnological progress. The architectures and training methods \nof these instruments differ, and their functionality is par -\ntially understandable in terms of model interpretability of \ninputs/features/outputs, transparency of model architecture, \nand training methods. In some cases, the weights, i.e., the \nparameters that the model learns during the training phase \nand uses for decisions (output), have been disclosed but this \nis not consistently achievable.\nSetting aside technical details, the user-friendly interface, \nand the availability of open licenses, particularly for basic \nframeworks, have been key factors in the quick proliferation \nof these systems. They hold promise for healthcare appli -\ncations, particularly in the development of chatbots, inter -\naction systems for clinical documentation management, \nand the summarization of medical literature (Biomedical \nNLP). The key challenge in this domain is the exploration \nof applications for diagnostic and clinical decision sup -\nport, along with patient triage. As healthcare profession -\nals, we acknowledge the urgent imperative to stay on the \ncutting edge of knowledge. Nevertheless, staying updated \nwith the evolution of this type of technology is practically \nimpossible, and above all, understanding the potential appli-\ncations remains a subject of debate.\nThis article aims to provide a concise overview of the \nLLM tools released in 2023, emphasizing their potential \napplications in the field of medicine. While the list may not \nbe exhaustive, the publication aims to offer insight into a \nphenomenon that is progressively transforming the land -\nscape of medicine, influencing research and clinical prac -\ntices, as well as healthcare processes.\nDevelopment of LLMs for Chatbots and Enhanced \nhuman-like Interaction\nThe innovative transformer architecture has paved the way \nfor the development of various LLMs, each distinguished \nby its unique characteristics [ 3]. Recent advancements in \nlanguage modeling have led to the emergence of three pre -\ndominant categories, classified based on the fundamental \nmodules employed in their construction. Firstly, there are \nencoder-only LLMs exemplified by BERT (Bidirectional \nEncoder Representations from Transformers) and its vari -\nous iterations. These models excel in capturing contextual \ninformation bidirectionally, fostering a comprehensive \nunderstanding of language semantics. Secondly, decoder-\nonly language models, as epitomized by the GPT family \nmembers, emphasize the generation of coherent and contex-\ntually relevant sequences. Leveraging unidirectional atten -\ntion blocks, these models have demonstrated proficiency in \ntasks requiring sequential understanding and generation. \nLastly, encoder-decoder language models, such as T5 (Text-\nto-Text Transfer Transformer) and BART (Bidirectional and \nAutoRegressive Transformers), represent a fusion of both \nbidirectional and unidirectional attention mechanisms. This \nhybrid approach allows for versatile applications, ranging \nfrom text summarization to language translation, where \nunderstanding context and generating coherent responses \nare both crucial. The application of diverse processes and \ndatasets allows for the provision of a spectrum of tools tai -\nlored to meet the evolving demands of natural language \nunderstanding and generation [5].\nBefore the rise of LLMs, traditional deep-learning mod -\nels grappled with numerous technical challenges, including \ninadequate sequence and semantic understanding, along \nwith computational complexity. This complexity neces -\nsitated a substantial number of parameters, as evident in \nconvolutional neural networks, to achieve satisfactory out -\ncomes. Additionally, issues such as vanishing gradients \n(e.g., in recurrent neural networks) posed challenges in \ncapturing long-term dependencies, while sequential com -\nputation impeded the efficiency of training and inference \nprocesses, particularly for extended sequences [3]. The true \ninnovation stemmed from optimizing pre-trained language \n1 3\n22 Page 2 of 11\nJournal of Medical Systems (2024) 48:22\nmodels to suit the specific demands of chat-oriented tasks, \nthereby achieving enhanced performance in applications that \ninvolve dialog-finetuned versions for conversational inter -\nactions. This complex process provides the use of different \napproaches. Chat-based fine-tuning, for instance, refers to \nthe modality of refining a pre-existing LLM through addi -\ntional training specifically tailored to conversational or chat-\nbased contexts. In this approach, the model is fine-tuned \nusing datasets that consist of dialogues or interactions, often \nin the form of message-response pairs. Therefore, the model \ncan learn the nuances of natural language interactions, \nincluding the flow of conversation, context handling, and \nthe generation of appropriate responses [6]. It can be able to \nunderstand user queries, maintain context across turns, and \nprovide contextually relevant and coherent replies. The pre-\ntrained model can be also provided with additional training \ndata specifically tailored to instructions or guidelines. This \nfine-tuning method helps generate outputs that align more \nclosely with desired instructions, improving its performance \nin tasks that require explicit guidance [ 3]. Furthermore, \nreinforcement learning from human feedback (RLHF) is a \nprocess that requires the involvement of humans in ranking \nthe output efficacy (human feedback) [ 7]. The RLHF pro -\ncess was fundamental to the success of ChatGPT. Remark-\nably, each of the fine-tuning or RLHF steps can be executed \neither independently or sequentially. This flexibility is par -\nticularly relevant considering that many LLM chat models \nundergo multiple stages of training, ultimately leading to \nimproved performance and effectiveness in various natural \nlanguage understanding and generation tasks. Finally, the \ndirect preference optimization (DPO) approach is aimed to \ndirectly optimize the model for user preferences or desired \noutcomes. It is proposed to be an alternative to RLHF. Con-\ncerning its functioning, DPO bypasses intermediary steps \nand directly targets the optimization of user-defined criteria. \nTherefore, the model can focus on more relevant and satis -\nfying results for users achieving personalized and contextu-\nally relevant outputs [8].\n2023 Timeline of LLMs\nPremise. The recent release of the models has resulted in the \ndisclosure of clinical applications mostly as preprints, with \ntechnical notes frequently inferred from companion blog \nposts. As a consequence, the findings may not undergo vali-\ndation or be regarded as definitive. Furthermore, the possi -\nble lack of precise details on the methodologies, limitations, \nand nuances of the models must be necessarily considered.\nThe timeline of the recently released LLMs is illustrated \nin Fig. 1.\nDecember 2022-January 2023\nAt the end of December 2022, a partnership between Stan -\nford CRFM and MosaicML released BioMedLM 2.7B (pre-\nviously indicated as PubMedGPT 2.7B). Since it was trained \nto interpret biomedical language, BioMedLM is a domain-\nspecific LLM for biomedicine. The model was developed \nby implementing the 825 GiB Pile open-source dataset \nFig. 1 Timeline of selected \nlarge language models launched \nbetween December 2022 and \nDecember 2023\n \n1 3\nPage 3 of 11 22\nJournal of Medical Systems (2024) 48:22\nOpenAI’s ChatGPT chatbot. They observed that Bing’s \nversion addressed some significant issues usually encoun -\ntered with ChatGPT, such as having knowledge of current \nevents through internet access and providing footnotes with \nlinks to sources for the information it retrieved [ 13]. In the \nmedical context, Copilot can be used for different aims. For \nexample, it enables the utilization of an Excel file to monitor \nthe advancement of clinical trials and generate natural lan -\nguage summaries of multimodal clinical information [14].\nMarch 2023\nMarch 2023 marked an extraordinary milestone in the LLMs \nera. OpenAI unveiled GPT-4, the latest addition to the unidi-\nrectional GPT family. This model became accessible to the \npublic through the paid chatbot service ChatGPT Plus and \nOpenAI’s API. The pre-training phase utilized a combina -\ntion of public and licensed datasets. The fine-tuning process \nemployed RLHF, reinforcement from artificial intelligence, \nand ensured policy compliance [ 15]. Although the data is \nunconfirmed, it appears that GPT-4 is built upon eight mod-\nels, each boasting 220B parameters. Overall, the model is \nover 10-fold larger than GPT-3 [ 16]. The single models \nare interconnected within the Mixture of Experts (MoE) \narchitecture. This structure represents a form of ensemble \nlearning that amalgamates various models, referred to as \n“experts,” to arrive at a decision. Within an MoE model, a \ngating network determines the weighting of each expert’s \noutput based on the input, allowing for specialization in \ndifferent segments of the input space. This architectural \napproach proves particularly advantageous for extensive \nand intricate datasets, effectively partitioning the problem \nspace into more manageable subspaces. The model imme -\ndiately demonstrated the capability to achieve high perfor -\nmance, showcasing an enhanced conversational experience \nand improved response accuracy, with fewer hallucination \nphenomena [17]. It can also manage multimodal data such \nas images. Therefore, despite not being specifically trained \nfor healthcare or medical purposes, its versatility enables a \nrange of applications in these fields. For example, the model \npassed a text-based radiology board–style examination [18] \nand the Korean National licensing examination for clini -\ncians [ 19]. It was also used for student training [ 20] and \npatient education [21]. On the contrary, it was less accurate \nthan trained healthcare personnel in laboratory tasks [22].\nPathways Language Model (PaLM) refers to a language \nmodel based on the pathway architecture. Med-PaLM (Med-\nPathways Language Model) is a large-sized AI-powered \nlanguage model (540B parameter LLM) designed to provide \nhighly accurate answers to medical questions developed by \nGoogle, in late 2022. Tailored and tested for the medical \n(16 million PubMed Abstracts and 5 million PubMed Cen-\ntral full-text articles) for language modeling which encom -\npasses 22 smaller, high-quality databases [9]. Trained on the \nMosaicML Cloud, a platform tailored for handling work -\nloads such as LLMs, the model utilized the Composer train-\ning library and PyTorch. Along with GPT, BioMedLM 2.7B \nis an autoregressive language model that generates outputs \none token at a time, conditioning each prediction on the \npreviously generated tokens. In other words, the model pre-\ndicts the next token in a sequence based on the preceding \ntokens, allowing it to capture dependencies and sequential \npatterns in the data. Concerning performances, this model \ncan effectively complete various biomedical NLP tasks. For \nexample, it reached a good accuracy on the open domain \nquestion answering (OpenQA) dataset examination MedQA \n[9]. Concerning applications, it is suitable to leverage NLP \napproaches for understanding and responding to medical-\nrelated questions (biomedical Q&A), for clinical notes, and \nespecially for biomedical text mining.\nFebruary 2023\nIn February 2023, Meta AI introduced LLaMA (Large Lan-\nguage Model Meta AI), a suite of fundamental language \nmodels spanning a parameter range from 7 billion (7B) to \n65 billion (65B). Since models within this range are tailored \nto cater to a broad array of linguistic intricacies, LLaMA \nproducts can provide a robust foundation for addressing \nmultiple NLP tasks. Moreover, these models underwent \ntraining on trillions of tokens, exclusively utilizing publicly \naccessible datasets. The weights are provided upon request \n[10]. In their article, Li et al. [ 11] illustrated that ChatDoc-\ntor, created using an extensive dataset comprising 100,000 \npatient-doctor dialogues extracted from a widely utilized \nonline medical consultation platform, was able to be pro -\nficient in comprehending patient inquiries and offering pre -\ncise advice. They used the 7B version of the LLaMA model. \nNevertheless, despite its limited number of parameters, it \ndemonstrated a performance comparable to the significantly \nlarger GPT-3 model (with 175B parameters).\nIn this month, Microsoft launched Bing Chat (now Copi-\nlot). The model underwent several updates and shows formi-\ndable features such as multimodal input (including images), \nand code generation. For its working, Copilot uses GPT-4 \nTurbo, and implements Code Interpreter, and DALL-E 3 for \ncoding and image creation, respectively. It can effectively \nwork with the Microsoft suites. For example, the model can \ngenerate a draft slideshow with information from another \ntype of file (e.g., word) and synchronize the text with ani -\nmations already present in a presentation [ 12]. Regarding \nperformance, ZDNET conducted tests on both Copilot and \n1 3\n22 Page 4 of 11\nJournal of Medical Systems (2024) 48:22\nplatforms and libraries such as Hugging Face and NVID -\nIA’s Faster Transformer. The model is licensed for com -\nmercial use. Kauf et al. [29] adopted MPT and other LLMs \nto investigate the dynamics of agent-patient interactions. \nIn addition to the base MPT-7B, other three models were \nreleased including MPT-7B-Instruct, MPT-7B-Chat , and \nMPT-7B-StoryWriter-65k+.\nJuly 2023\nIn July 2023, in partnership with Microsoft, Meta introduced \na series of models under the name LLaMa 2, boasting vary-\ning parameter sizes of 7 billion, 13 billion, and an impres -\nsive 70 billion. The architecture remains largely unchanged \nfrom the original model, albeit with a 40% increase in the \namount of data used to train the foundational models. The \nfine-tuned LLaMA, called LLaMa 2-Chat, was optimized for \ndialogue use cases [30]. The architecture closely resembles \nthe initial LLaMa, incorporating the addition of Grouped \nQuery Attention (GQA) [ 31]. The model was trained on a \ndata set encompassing 2 trillion tokens.\nSeptember 2023\nA few months later, in September, a French startup with \nvarious partnerships, launched Mistral 7B , as a European \nanswer to OpenAI. The 7B-parameter model appears to \noutperform LLaMa 2 13B in several benchmarks including \nreasoning, mathematics, and code generation [ 32]. These \nsuperior performances stem from the sliding window atten-\ntion (SWA) mechanism. This mechanism empowers the \nmodel’s attention system to focus on a sliding window or \nsubset of tokens at a time, rather than attending to the entire \nsequence of tokens. The result is more efficient processing \nand improved accuracy, even when utilizing a reduced num-\nber of parameters. Mistral-7B can be finetuned in a medical \nchatbot by implementing the NLP working platform Hug -\nging Face and a process of 4-bit quantization with param -\neter-efficient fine-tuning [ 33]. On December 2023 Mistral \nreleased Mixtral 8 × 7B. It is based on the Sparse Mixture \nof Experts (SMoE) model which is a type of neural network \narchitecture that combines the strengths of both global and \nlocal specialization in learning tasks. These architectures \noffer a flexible and adaptive framework for capturing intri -\ncate patterns in data while maintaining computational effi -\nciency [34].\nIn the same month, September 2023, Salesforce devel -\noped XGen-7B [35]. This family of LLMs, trained on the \nin-house JaxFormer library and public domain data such as \ndatabricks-dolly-15k, oasst1, and Baize, is better equipped \nto handle longer document inputs. This capability is \ndomain, it incorporates information from different medi -\ncal question-answering datasets, research, and consumer \nqueries [23]. Flan-PaLM is the instruction-tuned variant of \nPaLM. The newest iteration, Med-PaLM2, was introduced \nat Google Health’s annual event, in March 2023. It was \ndeveloped based on PaLM2, the language model underly -\ning the Google chatbot, Bard that adopted different models \nover time, beginning with LaMDA followed by PaLM2, and \nfinally Gemini Pro. For training researchers implemented \na collection of text datasets from the internet. This corpus \nincluded various sources, such as articles, books, websites, \nand other textual content. Concerning performance, the \nmodel demonstrated a level of expertise comparable to that \nof a human expert in answering the U.S. Medical Licensing \nExamination (USMLE)-style questions. Furthermore, as the \ndevelopers reported, they adopted an innovative ensemble \nrefinement encompassing chain-of-thought prompting and \nself-refine [24], as a prompting strategy to enhance model \nreasoning [ 25]. Expanding on the vision-language model \nPaLM-E, Google has developed (July 2023) a multimodal \niteration known as Med-PaLM M . This system can syn -\nthesize and convey information from images such as chest \nX-rays, medical images (e.g., dermatology), pathology, and \nother biomedical data for enabling the diagnostic pathway. \nMultiMedBench is a comprehensive biomedical benchmark \nthat encompasses various modalities such as medical imag-\ning, clinical text, and genomics. It comprises 14 diverse \ntasks designed for training and evaluation. As the authors \nstated, while a robust process of validation in real-world \nscenarios is needed, this could represent a fundamental step \ntoward the so-called generalist biomedical AI able to inter -\npret and manage multimodal data for decision-making pur -\nposes [26].\nA multidisciplinary team composed of physicians, hospi-\ntal administrators, lawyers, and AI researchers has released \nHippocratic AI . It was developed by implementing an \nRLHF process using healthcare professionals to train and \nvalidate the model [27].\nMay 2023\nIn May 2023, MosaicML launched MPT-7B [ 28]. The \nmodel is trained on a large amount of data and can handle \nstructured and unstructured data such as audio and video \ninputs. The modified transformer architecture incorporates \nperformance-optimized layer implementations and removes \ncontext length limits by substituting positional embeddings \nwith Attention to Linear Biases (ALiBi). These adjust -\nments enable the model to be trained with high through -\nput efficiency and stable convergence. Additionally, MPT \nmodels can be efficiently deployed using standard NLP \n1 3\nPage 5 of 11 22\nJournal of Medical Systems (2024) 48:22\nas chatbots, are already widely employed. Conversely, in \ndecision-making processes, we may still be far from their \nwidespread application (Fig. 2).\nThe healthcare applications of LLMs primarily involve \nchatbots and interaction systems, clinical documentation, \nmedical literature summarization, as well as diagnostic and \nclinical decision support. For chatbot use, a limitation arises \nfrom the length of the context. Current models struggle to \nhandle increasingly longer contexts while maintaining a \nhigh level of reliability and predictability. With the advent of \napplications like ChatGPT and the first version of Bing Chat \n(recently updated and renamed as Copilot, Microsoft), users \nhave noticed that the longer they use the model in a single \nconversation, the more inaccurate its responses become. The \ncause was the model’s inability to manage context length, \nleading to confusion and subsequently hallucinations. A \nseries of alternatives are emerging to overcome this limita -\ntion. One of these is Claude, developed by Anthropic, the AI \nstartup founded by former OpenAI alumni [ 38]. Moreover, \ndue to the inclusion of GPT-4 Turbo, Copilot can manage \nmore than 300 pages of documents in a single prompt. Dif -\nferent research teams from Google developed Gemini which \nis available in three different sizes including Gemini Ultra, \nGemini Pro, and Gemini Nano. Gemini was developed to \nbe multimodal. Therefore, the model can seamlessly pro -\ncess, understand, manipulate, and integrate various types \nof information, including text (also PDFs), images, audio, \nvideo, and computer code. Text and image outputs can be \nproduced [39]. The intriguing novelty is its ability to fact-\ncheck the responses generated by AI, to ensure they are not \nthe product of hallucination.\nConcerning medical literature analysis, documents fre -\nquently entail substantial dependencies, such as hyperlinks \nand references, allowing knowledge to extend across mul -\ntiple articles. To overcome this lack and establish knowl -\nedge links between documents, in 2022, researchers from \nStanford University developed LinkBERT. The training \nencompassed two domains: the general domain, utilizing \nWikipedia articles with hyperlinks, and the biomedical \ndomain, employing PubMed articles with citation links [40].\nThe incorporation of LLMs in medical education is an \nimportant field of research and development [ 41]. These \napproaches may offer alternative learning pathways and can \nbe used for designing interactive tools for medical educa -\ntion, enhancing the learning experience [42]. LLMs can also \nbe harnessed for generating case scenarios or quizzes, aiding \nmedical students in practicing and refining their diagnostic \nand treatment planning skills within a secure and controlled \nenvironment [43]. The integration of LLMs in gamification \nprocesses represents another captivating perspective [ 44]. \nThe enhancement of tools for interacting with the patient \n(virtual clinical partners) could lead to improving patient \nachieved through training with the standard dense attention \n(SDA) transformer for sequences up to a length of 8,000, \ncovering a maximum of 1.5 trillion tokens. In particular, \nthe SDA transformer process helps capture relationships \nbetween all tokens in the sequence, providing a more com -\nprehensive understanding of the context. This is particularly \nuseful when dealing with long documents or sequences.\nNovember – December 2023\nDuring this period, several updates to LLMs, especially for \nCopilot, have been released. In November 2023, research -\ners from the University of Florida and NVIDIA published a \npaper for explaining GatorTronGPT [36]. The model has a \nGPT-3 architecture and was trained on the Pile dataset and \nde-identified clinical text from the University of Florida. It \nappears to be suitable for creating and assessing healthcare \ntexts, such as clinical notes, medical reports, drug prescrip-\ntions, and other medical documents as well as to assess \ndrug-drug interaction, chemical-disease relation, and drug-\ntarget links [36].\nSelected models and features are shown in Table 1.\nLegend: ‡Number of parameters (the size can also \nbe measured in other quantities such as amount of RAM \nrequired for the model); °The license forbids the use of the \nmodel “To provide medical advice and medical results inter-\npretation”; ^Features not confirmed [13]; *Google released: \nBERT (2018), XLNet (2019), GLaM (2021), LaMDA \n(2022), PaLM (2022), and Minerva (2022); §Released as \nBing Chat. Abbreviations: ALiBi, Attention with Linear \nBiases; RLHF, reinforcement learning from human feed -\nback; EHRs: Electronic Health Records.\nIn addition to the models listed, many other models \nand software have been produced in the field of NLP. The \nmost interesting aspect concerns the interpretability of the \nmodels, focusing on highly controlled setup processes, and \ntraining dynamics. For this purpose, for instance, Eleuthe -\nrAI has developed Pythia, a suite encompassing 16 LLMs \nall trained on public data for analyzing LLMs across train -\ning and scaling [37].\nPerspectives for a Broader Range of safe and \nEffective Applications\nThe perspectives in this field encompass broadening the appli-\ncation scope of LLMs and overcoming crucial limitations \nthat hinder the widespread use of these models. Currently, \nthese tools are utilized by clinicians, patients, healthcare sys-\ntems, and researchers, but it should be noted that the level of \ndevelopment varies across different domains. For instance, \ntools aiding in writing and literature summarization, such \n1 3\n22 Page 6 of 11\nJournal of Medical Systems (2024) 48:22\nhealth disparities. In a recent study, for example, Birkun and \nGautan [48] showed that the advice provided by LLM chat-\nbots (Bing, Microsoft Corporation, USA, and Bard, Google \nLLC, USA) for assisting a non-breathing victim lacked cru-\ncial details of resuscitation techniques and, at times, pro -\nvided misleading and potentially harmful instructions. In \nanother study, carried out to assess the accuracy of Chat-\nGPT, Google Bard, and Microsoft Bing in distinguishing \nengagement, providing personalized support, and enhanc -\ning chronic disease management [45].\nThe key perspective revolves around addressing the \nlimitations of LLMs, which encompass challenges such \nas misinformation, privacy issues, biases in training data, \nand the risk of misuse [ 46, 47]. The phenomenon of hal -\nlucination can dangerously propagate medical misinforma -\ntion or introduce biases that have the potential to exacerbate \nModel Developer Architecture Size‡ Availability Features\nBioMedLM \n[9]\nStanford \nCRFM and \nMosaicML\nAutoregressive \nlanguage model. \nTrained with \nFlash Attention\n2.7B Licensed \nunder the \nterms of \nBigScience \nOpen RAIL-\nM license°\nTraining on the Pile 825 \nGiB dataset. It could not \nbe used for generating \ntext.\nLLaMA \n2-Chat [10, \n11, 30, 31]\nMeta AI with \nMicrosoft\nGrouped Query \nAttention \ntransformer\n7B-70B Publicly \naccessible \n(1.2 trillion \ntokens)\nDecoder-only Transformer.\nMassive process of \nfinetuning from human \npreferences (alignment \nprocedure)\nMistral-7B \n[32, 33]\nMistral Transformer \nleveraging \ngrouped-query \nattention, and \nsliding window \nattention\n7B Open source Trained on web-extracted \ntokens.\nReleased under the Apache \n2.0 license\nMixtral \n8 × 7B [34]\nMistral Sparse Mixture of \nExperts\n7B Will be \ndeployed \nwith an \nopen-source \ndeployment \nstack\nOpen weights (Apache 2.0 \nlicense).\nstrong performance in \ncode generation\nMPT-7B \n[28, 29]\nMosaicML Optimized for \nfast training and \ninference (via \nFlash Attention \nand Faster Trans-\nformer). AliBi\n7B Open source Open weights (Apache \n2.0 license). Works on \nstructured and unstruc-\ntured data\nXGen-7B \n[35]\nSalesforce Standard \ndense attention \ntransformer\n7B Apache 2.0 \nlicense\nUseful with long docu-\nments or sequences\nMed-PaLM2 \n[23–25]\nGoogle* RLHF, compute-\noptimal scaling, \nand few-shot \nlearning\n540B N/A Tailored and tested for the \nmedical domain.\nContinual learning and \niterative refinement\nMed-PaLM \nM\n [26]\nGoogle Flexible multi-\nmodal sequence-\nto-sequence \nencoding\n2B, 84B, \nand 562B\nN/A Multimodal generative \nmodel\nGPT-4 \n[15–22]\nOpenAI Mixture of \nExperts (MoE) \n(ensemble \nlearning)^\n8 × 220B^ Proprietary \nlicense\nEnhanced conversa-\ntional experience and \nresponse accuracy (less \nhallucinations)\nCopilot§ \n[12–14]\nMicrosoft Uses GPT-4 8 × 220B^ Proprietary \nlicense\nText queries for research, \nwriting, assistance, coding, \nand images.\nGator-\nTronGPT \n[36]\nUniversity of \nFlorida and \nNVIDIA\nGPT-based 5B-20B N/A Trained on clinical data. \nUseful for unlocking \npatient data from unstruc-\ntured EHRs.\nTable 1 Large Language Models \nlaunched between December \n2002 and December 2023\n \n1 3\nPage 7 of 11 22\nJournal of Medical Systems (2024) 48:22\nreferred to as ‘expand-guess-refine,’ providing a parameter \nand data-efficient solution [52].\nTaken together, these limitations must be carefully \naddressed, especially when the output involves complex and \nparamount tasks such as applications in diagnostic, patient \ntriage, and decision-making processes. For example, Benary \net al. [53] showed that different LLMs including ChatGPT \nand BioMedLM, are not currently suitable for routine use \nas tools to assist in personalized clinical decision-making \nin oncology.\nBecause of their considerable complexity, these models \nare often perceived as black-box models. Consequently, a \nrising concern revolves around the ethical responsibility \nof deploying such technology [ 54]. Interpretability aims to \nconvey explanations of the model’s functioning in a man -\nner comprehensible to humans. For this purpose, various \napproaches have been proposed, categorized as intrinsic \nmodels which are constructed with transparency and inter -\npretability considerations as primary design principles, and \npost-hoc models [55].\nAs the Med-Palm developers wisely noted, while the \nresults in the field of LLMs in medicine are promising, \nthe medical domain is intricate [ 24]. Consequently, further \nassessments are imperative, particularly in terms of safety, \nequity, and bias. Numerous limitations need to be addressed \nbefore LLMs can be considered viable for use in clinical \napplications [ 24]. Nevertheless, the correct path appears \nto be set. To tackle the hallucination phenomenon, for \nbetween a medical emergency and a non-emergency, the \nauthors concluded that the examined tools need additional \nimprovement to accurately identify different clinical situa -\ntions [49]. Continuous verification of the output’s appropri-\nateness is crucial. Significantly, in November 2022, Meta’s \nGalactica model was halted shortly after its release, just \na few days after, due to the generation of inaccurate data \n[50]. The overarching goal is to ensure NLP assurance. This \ncomprehensive process is incorporated at every stage of the \nNLP development lifecycle, aiming to validate, verify, and \nmake outcomes trustworthy and explainable to non-experts. \nAdditionally, it underscores ethical deployment, unbiased \nlearning, and fairness toward users [51].\nIn the training phase, the accuracy of the output relies \nheavily on the choice of the reference dataset [1, 3]. Models \nlike GPT-4 are generated using extensive data. Neverthe -\nless, data with privacy restrictions, such as those stored in \nan electronic health record system within a healthcare orga-\nnization or any medical information exclusive to the private \nnetwork, are excluded from the training process. Another \nsignificant concern pertains to the training and fine-tuning \nprocess. The integration of various techniques, such as \ninstruction-tuning and in-prompt strategies like few-shot \nand chain-of-thought prompting, has notably improved the \nperformance of LLMs. For instance, the authors have intro-\nduced an alignment strategy — an approach used to syn -\nchronize or align different components of a model or system \n— specifically tailored for medical question-answering, \nFig. 2 Current applications and perspectives of large language models in medicine. The battery symbol indicates the extent of current applications, \nranging from one line to multiple lines\n \n1 3\n22 Page 8 of 11\nJournal of Medical Systems (2024) 48:22\ntant intellectual content;3) approved the version to be published; and4) \nagree to be accountable for all aspects of the work in ensuring that \nquestions related to the accuracy or integrity of any part of the work \nare appropriately investigated and resolved.\nFunding None.\nOpen access funding provided by Università degli Studi di Parma \nwithin the CRUI-CARE Agreement.\nData Availability No datasets were generated or analysed during the \ncurrent study.\nDeclarations\nCompeting Interests The authors declare no competing interests.\nEthical Approval Not applicable.\nAvailability of Supporting data Not applicable.\nOpen Access   This article is licensed under a Creative Commons \nAttribution 4.0 International License, which permits use, sharing, \nadaptation, distribution and reproduction in any medium or format, \nas long as you give appropriate credit to the original author(s) and the \nsource, provide a link to the Creative Commons licence, and indicate \nif changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless \nindicated otherwise in a credit line to the material. If material is not \nincluded in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted \nuse, you will need to obtain permission directly from the copyright \nholder. To view a copy of this licence, visit http://creativecommons.\norg/licenses/by/4.0/.\nReferences\n1. Ouyang L, Wu J, Jiang X, Almeida, Wainwright C, Mishkin P, \nZhang C, Agarwal S, Slama K. Training language models to fol -\nlow instructions with human feedback. Advances in Neural Infor-\nmation Processing Systems. 2022; 35:730–744.\n2. Kalyan KS, Rajasekharan A, Sangeetha S. Ammu: a survey of \ntransformer-based biomedical pretrained language models. Jour -\nnal of biomedical informatics. 2022;126:103982.\n3. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez \nAN, Kaiser L, Polosukhin I. Attention Is All You Need. 2017. \narXiv:1706.03762.\n4. Open AI. ChatGPT release note. Available at: https://help.openai.\ncom/en/articles/6825453-chatgpt-release-notes#h_4799933861  \nLast Accessed: December 22, 2023.\n5. Tian S, Jin Q, Yeganova L, Lai P-T, Zhu Q, Chen X, Yang X, \nChen, Kim W, Comeau DC, Islamaj R, Kapoor A, Gao X, Lu Z. \nOpportunities and Challenges for ChatGPT and Large Language \nModels in Biomedicine and Health- arXiv:2306.10070. (2023).\n6. Radford A, Narasimhan K. Improving Language Understanding \nby Generative Pre-Training. 2018. https://api.semanticscholar.\norg/CorpusID:49313245.\n7. Cao Z, Wong K, Lin CT. Weak Human Preference Supervision \nfor Deep Reinforcement Learning. IEEE Trans Neural Netw \nLearn Syst. 2021;32(12):5369–5378. doi: https://doi.org/10.1109/\nTNNLS.2021.3084198.\nexample, Tran et al. [56] implemented a selective prediction \ntask. This involved utilizing the number of decodes match -\ning a given answer from self-consistency as a measure of \nuncertainty. The researchers applied this measure to with -\nhold the answer if the model lacked sufficient confidence. \nOther attempts were conducted to align LLMs to the medi -\ncal domain, working on prompting [ 57] and prompt tuning \n[58]. Moreover, efforts are currently underway to devise \nprocedures for evaluating bias and harms associated with \nfairness [ 59]. Finally, a multidisciplinary team composed \nof physicians, hospital administrators, lawyers, and AI \nresearchers is working on Hippocratic AI. It will be a safety-\nfocused LLM for healthcare developed by implementing an \nRLHF process using healthcare professionals to train and \nvalidate the model [60].\nConclusions\nIn the course of 2023, a significant influx of LLMs has \nbeen introduced by diverse developers, underscoring the \nexpansive potential of research in shaping models for the \nfuture of healthcare. A crucial aspect of this evolutionary \ntrajectory involves the transformation from an AI-powered \nmodel designed solely for answering medical questions to a \nmore extensive practical instrument for healthcare provid -\ners. However, realizing this transition mandates substantial \nadditional research efforts by administrators and end-users \nalike to guarantee the technology’s safety, reliability, effi -\ncacy, and privacy. The search for solutions to these obstacles \nmust run parallel to the rapid technological development \nthat will soon lead to the emergence of generalist biomedi -\ncal AI processes. These strides pave the way for construct -\ning a unified biomedical AI system proficient in interpreting \ncomplex, multimodal data to address a myriad of medical \nand healthcare challenges. In the meantime, Biomedical \nNLP techniques are primarily employed to aid in manual \ncuration, interpretation, and knowledge discovery within \nbiomedical literature.\nDeclarations Section\nSupplementary Information  The online version contains \nsupplementary material available at https://doi.org/10.1007/s10916-\n024-02045-3.\nAuthor Contributions MC, FS, OP:1) made substantial contributions \nto the conception of the work; acquisition, analysis, and interpretation \nof data; 2) drafted the work;3) approved the version to be published; \n4) agree to be accountable for all aspects of the work in ensuring that \nquestions related to the accuracy or integrity of any part of the work \nare appropriately investigated and resolved.JM, VB, EB:1) made sub-\nstantial contributions to the conception and design of the work; analy-\nsis and interpretation of data; 2) revised the work critically for impor -\n1 3\nPage 9 of 11 22\nJournal of Medical Systems (2024) 48:22\nrefinement with self-feedback. arXiv preprint arXiv:2303.17651 \n(2023).\n25. Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, Clark \nK, Pfohl S, Cole-Lewis H, Neal D, Schaekermann M, Wang A, \nAmin M, Lachgar S, Mansfield P, Prakash S, Green B, Domi -\nnowska E, Aguera y Arcas B, Tomasev N, Liu Y , Wong R, Sem-\nturs C, Mahdavi S. Towards Expert-Level Medical Question \nAnswering with Large Language Models. arXiv:2305.09617v1 \n(2023).\n26. Tu T, Azizi S, Driess D, Schaekermann M, Amin M, et al. Towards \nGeneralist Biomedical AI. arXiv:2307.14334v1 (2023).\n27. Hippocratic AI. Available at https://www.hippocraticai.com/. \nLast Accessed: December 24, 2023.\n28. Hugging Face. MPT-B. Available at: https://huggingface.co/\nmosaicml/mpt-7b. Last Accessed: December 24, 2023.\n29. Kauf C, Ivanova AA, Rambelli G, Chersoni E, She JS, Chowd -\nhury Z, Fedorenko E, Lenci A. Event Knowledge in Large Lan -\nguage Models: The Gap Between the Impossible and the Unlikely. \nCogn Sci. 2023;47(11):e13386. doi: https://doi.org/10.1111/\ncogs.13386.\n30. Touvron H, Martin L, et al. LLaMA-2: Open Foundation and \nFine-Tuned Chat Models. arXiv:2307.09288 (2023).\n31. Ainslie J, Lee-Thorp J, de Jong M, Zemlyanskiy Y , Lebron, \nSanghai S. 2023. GQA: Training Generalized Multi-Query Trans-\nformer Models from Multi-Head Checkpoints. In Proceedings of \nthe 2023 Conference on Empirical Methods in Natural Language \nProcessing, pages 4895–4901, Singapore. Association for Com -\nputational Linguistics.\n32. Jiang AQ, Sablayrolles A, Mensch A, Bamford C, Singh Chaplot \nD, de las Casas D, Bressand F, Lengyel G, Lample G, Saulnier L, \nLavaud LR, Lachaux MA, Stock P, Le Scao T, Lavril T, Wang T, \nLacroix T, El Sayed W. Mistral-7B arXiv:2310.06825.\n33. An END-to-END guide on how to finetune a LLM(Mistral-7B) \ninto a Medical Chat Doctor using Huggingface. Available at: \nhttps://medium.com/@SachinKhandewal/finetuning-mistral-\n7b-into-a-medical-chat-doctor-using-huggingface-qlora-peft-\n5ce15d45f581 Last Accessed: December 22, 2023.\n34. Mistral AI. Available at: https://mistral.ai/news/mixtral-of-\nexperts/ Last Accessed: December 24, 2023.\n35. Nijkamp E, Xie T, Hayashi H, Pang B, Xia C, Xing C, Vig J, \nYavuz S, Laban P, Krause B, Purushwalkam S, Niu T, Kryściński \nW, Murakhovs’ka L, Choubey PK, Fabbri A, Liu Y , Meng R, Tu \nL, Bhat M, Wu C-S, Savarese S, Zhou Y , Joty S, Xiong C. XGen-\n7B Technical Report. arXiv:2309.03450.\n36. Peng C, Yang X, Chen A, Smith KE, PourNejatian N, Costa AB, \nMartin C, Flores MG, Zhang Y , Magoc T, Lipori G, Mitchell \nDA, Ospina NS, Ahmed MM, Hogan WR, Shenkman EA, Guo \nY , Bian J, Wu Y . A study of generative large language model for \nmedical research and healthcare. NPJ Digit Med. 2023;6(1):210. \ndoi: https://doi.org/10.1038/s41746-023-00958-w.\n37. Cunningham H, Ewart A, Riggs L, Huben R, Sharkey R. Sparse \nAutoencoders Find Highly Interpretable Features in Language \nModels. arXiv:2309.08600 (2023).\n38. Anthropic. Available at: https://www.anthropic.com/ Last \nAccessed: December 22, 2023.\n39. Gemini Team, Google. Gemini: A Family of Highly Capable \nMultimodal Models. Available at: https://assets.bwbx.io/docu-\nments/users/iqjWHBFdfxIU/r7G7RrtT6rnM/v0 Last Accessed: \nJanuary 31, 2023.\n40. Yasunaga M, Leskovec J, Liang P. LinkBERT: Pretraining Lan -\nguage Models with Document Links. arXiv:2203.15827 (2022).\n41. Khan RA, Jawaid M, Khan AR, Sajjad M. ChatGPT - Reshap -\ning medical education and clinical management. Pak J Med \nSci. 2023;39(2):605–607. doi: https://doi.org/10.12669/\npjms.39.2.7653.\n8. Rafailov R, Sharma A, Mitchell E, Ermon S, Manning CD, Finn \nC. Direct Preference Optimization: Your Language Model is \nSecretly a Reward Model. arXiv:2305.18290 (2023).\n9. Gao L, Biderman S, Black S, Golding L, Hoppe T, Foster C, \nPhang J, He H, Thite A, Nabeshima N, Presser S, Leahy C. The \nPile: An 800GB Dataset of Diverse Text for Language Modeling. \narXiv:2101.00027 (2020).\n10. Meta AI Request Form. Available at: https://docs.google.com/\nforms/d/e/1FAIpQLSfqNECQnMkycAp2 jP4Z9TFX0cGR4u\nf7b_fBxjY_OjhJILlKGA/viewform Last Accessed: December \n22, 2023.\n11. Li Y , Li Z, Zhang K, Dan R, Jiang S, Zhang Y . ChatDoctor: A \nMedical Chat Model Fine-Tuned on a Large Language Model \nMeta-AI (LLaMA) Using Medical Domain Knowledge. Cureus. \n2023;15(6):e40895. doi: https://doi.org/10.7759/cureus.40895.\n12. Microsoft Bing Blog. Available at: https://blogs.bing.com/search/\nnovember-2023/our-vision-to-bring-microsoft-copilot-to-every -\none-and-more. Last Accessed: December 24, 2023.\n13. ZDNET Information. Available at: https://www.zdnet.com/\narticle/what-is-copilot-formerly-bing-chat-heres-everything-you-\nneed-to-know/. Last Accessed: December 24, 2023.\n14. Avanade Insight. Available at: https://www.avanade.com/en/\nblogs/avanade-insights/health-care/ai-copilot. Last Accessed: \nDecember 24, 2023.\n15. OpenAI. GPT-4 Technical Report. arXiv:2303.08774 (2023).\n16. The decoder. Available at: https://the-decoder.com/gpt-4-archi-\ntecture-datasets-costs-and-more-leaked/ Last Accessed: Decem -\nber 22, 2023\n17. Lee P, Bubeck S, Petro J. Benefits, Limits, and Risks of GPT-4 as \nan AI Chatbot for Medicine. N Engl J Med. 2023;388(13):1233–\n1239. doi: https://doi.org/10.1056/NEJMsr2214184.\n18. Bhayana R, Bleakney RR, Krishna S. GPT-4 in Radiol -\nogy: Improvements in Advanced Reasoning. Radiology. \n2023;307(5):e230987. doi: https://doi.org/10.1148/radiol.230987.\n19. Jang D, Yun TR, Lee CY , Kwon YK, Kim CE. GPT-4 can pass \nthe Korean National Licensing Examination for Korean Medicine \nDoctors. PLOS Digit Health. 2023;2(12):e0000416. doi: https://\ndoi.org/10.1371/journal.pdig.0000416.\n20. Guerra GA, Hofmann H, Sobhani S, Hofmann G, Gomez D, \nSoroudi D, Hopkins BS, Dallas J, Pangal DJ, Cheok S, Nguyen \nVN, Mack WJ, Zada G. GPT-4 Artificial Intelligence Model \nOutperforms ChatGPT, Medical Students, and Neurosurgery \nResidents on Neurosurgery Written Board-Like Questions. World \nNeurosurg. 2023;179:e160-e165. doi: https://doi.org/10.1016/j.\nwneu.2023.08.042.\n21. Scheschenja M, Viniol S, Bastian MB, Wessendorf J, König \nAM, Mahnken AH. Feasibility of GPT-3 and GPT-4 for in-Depth \nPatient Education Prior to Interventional Radiological Proce -\ndures: A Comparative Analysis. Cardiovasc Intervent Radiol. \n2023 Oct 23. doi: https://doi.org/10.1007/s00270-023-03563-2.\n22. Spies NC, Hubler Z, Roper SM, Omosule CL, Senter-Zapata \nM, Roemmich BL, Brown HM, Gimple R, Farnsworth CW. \nGPT-4 Underperforms Experts in Detecting IV Fluid Contami -\nnation. J Appl Lab Med. 2023;8(6):1092–1100. doi: https://doi.\norg/10.1093/jalm/jfad058.\n23. Singhal K, Azizi S, Tu T, Mahdavi SS, Wei J, Chung HW, Scales \nN, Tanwani A, Cole-Lewis H, Pfohl S, Payne P, Seneviratne M, \nGamble P, Kelly C, Babiker A, Schärli N, Chowdhery A, Man -\nsfield P, Demner-Fushman D, Agüera Y Arcas B, Webster D, \nCorrado GS, Matias Y , Chou K, Gottweis J, Tomasev N, Liu Y , \nRajkomar A, Barral J, Semturs C, Karthikesalingam A, Nata -\nrajan V . Large language models encode clinical knowledge. \nNature. 2023;620(7972):172–180. doi: https://doi.org/10.1038/\ns41586-023-06291-2.\n24. Madaan A, Tandon N, Gupta P, Hallinan S, Gao L, Wiegreffe S, \nAlon U, Dziri N, Prabhumoye S, Yang Y , et al. Self-refine: Iterative \n1 3\n22 Page 10 of 11\nJournal of Medical Systems (2024) 48:22\n51. Batarseh FA, Freeman L, Huang C-H. A survey on artificial \nintelligence assurance. J Big Data 2021;8,7. doi: https://doi.\norg/10.1186/s40537-021-00445-7.\n52. Manathunga S, Hettigoda I. Aligning Large Language Models for \nClinical Tasks. arXiv:2309.02884 (2023).\n53. Benary M, Wang XD, Schmidt M, Soll D, Hilfenhaus G, Nas -\nsir M, Sigler C, Knödler M, Keller U, Beule D, Keilholz U, \nLeser U, Rieke DT. Leveraging Large Language Models for \nDecision Support in Personalized Oncology. JAMA Netw \nOpen. 2023;6(11):e2343689. doi: https://doi.org/10.1001/\njamanetworkopen.2023.43689.\n54. Rudin C. Stop explaining black box machine learning models \nfor high stakes decisions and use interpretable models instead. \nNat Mach Intell. 2019;1:206–215. doi: https://doi.org/10.1038/\ns42256-019-0048-x.\n55. Madsen A, Reddy S, Chandar S. Post-hoc Interpretability for \nNeural NLP: A Survey. ACM Computing Surveys. 2022;55(8):1–\n42. doi: https://doi.org/10.1145/3546577.\n56. Tran D, Liu J, Dusenberry MW, Phan D, Collier M, Ren J, Han K, \nWang Z, Mariet Z, Hu H, Band N, Rudner TJG, Singhal K, Nado \nZ, van Amersfoort J, Kirsch A, Jenatton R, Thain N, Yuan H, \nBuchanan K, Murphy K, Sculley D, Gal Y . Plex: towards reliabil-\nity using pretrained large model extensions. Preprint at https://\ndoi.org/10.48550/arXiv.2207.07411 (2022).\n57. Brown T, et al. Language models are few-shot learners. Adv. \nNeural Inf. Process. Syst. 2020;33:1877–1901.\n58. Lester B, Al-Rfou R, Constant N. The power of scale for param -\neter-efficient prompt tuning. Preprint at: https://doi.org/10.48550/\narXiv.2104.08691 (2021).\n59. Liang P. et al. Holistic evaluation of language models. Preprint at: \nhttps://doi.org/10.48550/arXiv.2211.09110 (2022).\n60. Hippocratic AI. Available at https://www.hippocraticai.com/. \nLast Accessed: December 24, 2023\nPublisher’s Note Springer Nature remains neutral with regard to juris-\ndictional claims in published maps and institutional affiliations. \n42. Sallam M. ChatGPT Utility in Healthcare Education, Research, \nand Practice: Systematic Review on the Promising Perspectives \nand Valid Concerns. Healthcare (Basel). 2023;11(6):887. doi: \nhttps://doi.org/10.3390/healthcare11060887.\n43. Eysenbach G. The Role of ChatGPT, Generative Language Mod-\nels, and Artificial Intelligence in Medical Education: A Conver -\nsation With ChatGPT and a Call for Papers. JMIR Med Educ. \n2023;9:e46885. doi: https://doi.org/10.2196/46885.\n44. Cascella M, Cascella A, Monaco F, Shariff MN. Envisioning \ngamification in anesthesia, pain management, and critical care: \nbasic principles, integration of artificial intelligence, and simu -\nlation strategies. J Anesth Analg Crit Care. 2023;3(1):33. doi: \nhttps://doi.org/10.1186/s44158-023-00118-2.\n45. Haque A, Chowdhury N-U-R. The Future of Medicine: \nLarge Language Models Redefining Healthcare Dynamics. \nTechRxiv. November 22, 2023. doi: https://doi.org/10.36227/\ntechrxiv.24354451.v2.\n46. Gurrapu S, Kulkarni A, Huang L, Lourentzou I, Batarseh FA. \nRationalization for explainable NLP: a survey. Front Artif Intell. \n2023;6:1225093. doi: https://doi.org/10.3389/frai.2023.1225093.\n47. Cascella M, Montomoli J, Bellini V , Bignami E. Evaluating the \nFeasibility of ChatGPT in Healthcare: An Analysis of Multiple \nClinical and Research Scenarios. J Med Syst. 2023;47(1):33. doi: \nhttps://doi.org/10.1007/s10916-023-01925-4.\n48. Birkun AA, Gautam A. Large Language Model (LLM)-Pow -\nered Chatbots Fail to Generate Guideline-Consistent Content \non Resuscitation and May Provide Potentially Harmful Advice. \nPrehosp Disaster Med. 2023;38(6):757–763. doi: https://doi.\norg/10.1017/S1049023X23006568.\n49. Zúñiga Salazar G, Zúñiga D, Vindel CL, Yoong AM, Hincapie S, \nZúñiga AB, Zúñiga P, Salazar E, Zúñiga B. Efficacy of AI Chats \nto Determine an Emergency: A Comparison Between OpenAI’s \nChatGPT, Google Bard, and Microsoft Bing AI Chat. Cureus. \n2023;15(9):e45473. doi: https://doi.org/10.7759/cureus.45473.\n50. MIT Technology Review. Why Meta’s latest large language model \nsurvived only three days online. https://www.technologyreview.\ncom/2022/11/18/1063487/meta-large-language-model-ai-only-\nsurvived-three-days-gpt-3-science/ Last Accessed: December 22, \n2023.\n1 3\nPage 11 of 11 22",
  "topic": "Timeline",
  "concepts": [
    {
      "name": "Timeline",
      "score": 0.9338208436965942
    },
    {
      "name": "Health informatics",
      "score": 0.6987178325653076
    },
    {
      "name": "Computer science",
      "score": 0.5594329833984375
    },
    {
      "name": "Data science",
      "score": 0.3961640000343323
    },
    {
      "name": "Medicine",
      "score": 0.2471579909324646
    },
    {
      "name": "Nursing",
      "score": 0.1397194266319275
    },
    {
      "name": "History",
      "score": 0.13240256905555725
    },
    {
      "name": "Public health",
      "score": 0.11460673809051514
    },
    {
      "name": "Archaeology",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I131729948",
      "name": "University of Salerno",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I4210098325",
      "name": "Ospedale Maggiore Carlo Alberto Pizzardi",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I4210129405",
      "name": "Ospedale Infermi di Rimini",
      "country": "IT"
    },
    {
      "id": "https://openalex.org/I124601658",
      "name": "University of Parma",
      "country": "IT"
    }
  ],
  "cited_by": 143
}