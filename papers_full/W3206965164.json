{
  "title": "Private Language Model Adaptation for Speech Recognition",
  "url": "https://openalex.org/W3206965164",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5100462347",
      "name": "Zhe Liu",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5100343450",
      "name": "Ke Li",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5069821389",
      "name": "Shreyan Bakshi",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5047400593",
      "name": "Fuchun Peng",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3162639446",
    "https://openalex.org/W2028825255",
    "https://openalex.org/W1494108583",
    "https://openalex.org/W3100779497",
    "https://openalex.org/W3162072286",
    "https://openalex.org/W2026149468",
    "https://openalex.org/W2943845043",
    "https://openalex.org/W3162193499",
    "https://openalex.org/W179875071",
    "https://openalex.org/W2802422770",
    "https://openalex.org/W1795658042",
    "https://openalex.org/W2541884796",
    "https://openalex.org/W2594311007",
    "https://openalex.org/W2896422817",
    "https://openalex.org/W2027595342",
    "https://openalex.org/W3097714942",
    "https://openalex.org/W1828163288",
    "https://openalex.org/W2963240019",
    "https://openalex.org/W2962760690",
    "https://openalex.org/W2784621220",
    "https://openalex.org/W3101177651",
    "https://openalex.org/W2127141656",
    "https://openalex.org/W2034537249",
    "https://openalex.org/W2539241874",
    "https://openalex.org/W1873763122",
    "https://openalex.org/W2327501763",
    "https://openalex.org/W2535838896",
    "https://openalex.org/W3124442241",
    "https://openalex.org/W3025567392"
  ],
  "abstract": "Speech model adaptation is crucial to handle the discrepancy between server-side proxy training data and actual data received on local devices of users. With the use of federated learning (FL), we introduce an efficient approach on continuously adapting neural network language models (NNLMs) on private devices with applications on automatic speech recognition (ASR). To address the potential speech transcription errors in the on-device training corpus, we perform empirical studies on comparing various strategies of leveraging token-level confidence scores to improve the NNLM quality in the FL settings. Experiments show that compared with no model adaptation, the proposed method achieves relative 2.6% and 10.8% word error rate (WER) reductions on two speech evaluation datasets, respectively. We also provide analysis in evaluating privacy guarantees of our presented procedure.",
  "full_text": "Private Language Model Adaptation for Speech Recognition\nZhe Liu, Ke Li, Shreyan Bakshi, Fuchun Peng\nMeta AI, Menlo Park, CA, USA\n{zheliu, kli26, shreyanb, fuchunpeng}@fb.com\nAbstract\nSpeech model adaptation is crucial to handle the discrepancy\nbetween server-side proxy training data and actual data received\non local devices of users. With the use of federated learning\n(FL), we introduce an efﬁcient approach on continuously adapt-\ning neural network language models (NNLMs) on private de-\nvices with applications on automatic speech recognition (ASR).\nTo address the potential speech transcription errors in the on-\ndevice training corpus, we perform empirical studies on com-\nparing various strategies of leveraging token-level conﬁdence\nscores to improve the NNLM quality in the FL settings. Ex-\nperiments show that compared with no model adaptation, the\nproposed method achieves relative 2.6% and 10.8% word error\nrate (WER) reductions on two speech evaluation datasets, re-\nspectively. We also provide analysis in evaluating privacy guar-\nantees of our presented procedure.\nIndex Terms: federated learning, language modeling, speech\nrecognition, adaptation, conﬁdence scoring\n1. Introduction\nNeural network language models (NNLMs) play critical roles in\nautomatic speech recognition (ASR) systems [1, 2, 3, 4]. They\ntypically outperform traditional n-gram LMs with better capa-\nbility of modeling long-range dependency. For conventional\nASR models, NNLMs are widely used in the second pass viaN-\nbest or lattice rescoring [5, 6, 7]. For end-to-end ASR [8, 9, 10],\nalthough linguistic information is implicitly learned, NNLMs\ncan still further improve accuracy by fusion in ﬁrst-pass decod-\ning [11, 12] or second-pass rescoring.\nWith the latest advances in mobile technologies, hosting\nan ASR system entirely on-device has important implications\nfrom a reliability, latency, and particularly privacy perspective,\nand has become an active area of research and industrial ap-\nplications [13]. A common issue arising after deploying an\nASR model on user devices is the discrepancy between train-\ning data and actual data received on local devices. The seman-\ntic and acoustic characteristics of real users’ speech could be\nvery different from those of server-side proxy data, in which\ncase speech model adaptation is indispensable. The privacy-\npreserving constraint requires user data to stay on their local\ndevices. It is thus more challenging to perform model adapta-\ntion on user devices since there is no ground truth speech tran-\nscription from users.\nTo resolve this privacy concern, federated learning (FL)\n[14, 15, 16], a distributed learning technique, has been proposed\nand applied in many ﬁelds including recommendation [17], key-\nboard suggestion [18, 19], keyword spotting [20], health care\n[21], and more recently, ASR including hybrid acoustic models\nand end-to-end models [22, 23, 24]. FL can protect data pri-\nvacy by training a shared model in a decentralized manner on\nusers’ local devices, so that raw data never leaves physical de-\nvices. Speciﬁcally, FL distributes the training process among a\nlarge number of client devices, with each client learning from\nlive data and calculating model updates independently, then up-\nloading those updates to a central server for aggregation. The\nupdated model will later be delivered to each client device, after\nwhich this procedure is repeated until the training convergence\nof the model.\nIn this work, we focus on federated NNLM adaptation for\nspeech recognition application. Federated language modeling\nhas been well explored in mobile keyboard suggestion where\nsentences typed by users provide instant labeled data for su-\npervised learning [19]. However, for any on-device ASR with\nprivacy-preserving requirement, users’ text data can not be di-\nrectly accessed. Instead, we could use decoded hypotheses to\nperform model adaptation. The adaptation quality can be af-\nfected by any ASR transcription errors. Thus, more advanced\nmethods are called for to better leverage transcribed data to con-\nduct FL-based adaptation in an unsupervised manner.\nTo alleviate the transcription errors issue described above,\nwe leverage conﬁdence scores of transcripts, which estimate\nhow likely each token in any decoded hypothesis from ASR\nis correct [25, 26]. Lattice posteriors from conventional ASR\nsystems can be directly used as conﬁdence scores. Modeling\nbased approaches, for example, conﬁdence classiﬁers trained\nwith various decoding features [27], can provide more accurate\nconﬁdence measurements. In this paper, we propose to mitigate\nerrors in decoded hypotheses by modifying NNLM training ob-\njective using token-level conﬁdence scores from a conﬁdence\nclassiﬁer directly and improve adaptation quality.\nThe prior work on using ASR conﬁdence scores in LM task\nis limited. Authors in [28] use conﬁdence scores for selecting\ntext data for LM adaptation. Our paper presents and investi-\ngates this direction in a rigorous way, proposes the weighting\nmethod for adjusting the cross-entropy loss, and conducts solid\ncomparisons on the performance of these weighting approaches\nin the FL framework.\nWe mainly pursue three goals: (1) to present an effective\nprocedure on FL-based domain adaptation of NNLMs with its\napplications on ASR; (2) to empirically compare approaches of\nusing token-level conﬁdence scores to improve adaptation qual-\nity; and (3) to provide analysis in evaluating privacy guarantees\nof our proposed method using differential privacy (DP) tools\n[29, 30]. To the best of our knowledge, our paper is the ﬁrst\nwork that leverages FL to ﬁne-tune NNLMs for ASR systems\nand utilizes conﬁdence scores to address any potential qual-\nity degradation due to mis-transcribed text as training corpus.\nIn particular, the proposed conﬁdence-based approach can also\nbe applied to other tasks as well, for example, unsupervised\nspeaker adaptation.\nThe rest of the paper is organized as follows. In Sec-\ntion 2, we introduce the FL-based domain adaptation approach\nof NNLMs with its applications on speech recognition tasks.\nWe evaluate the proposed method in Section 3 and conclude in\nSection 4.\narXiv:2110.10026v3  [eess.AS]  15 Jun 2022\n2. Methods\n2.1. Federated Adaptation Framework\nFL distributes the model training process across a large number\nof client devices. Each device trains on private data and com-\nputes model updates independently. Those updates are then up-\nloaded to a central server for aggregation and the updated model\nis deployed to each client afterwards. We describe our approach\non FL-based NNLMs adaptation for ASR as follows.\nPre-training. We train an initial NNLM using a large gen-\neral corpus and if available, any “close-in-domain” proxy data\non the server side. The model then is delivered to each local\ndevice along with an ASR model;\nClient-side update. As soon as a user has input sufﬁcient\nvolume of utterances, local personal transcribed data is used to\nﬁne-tune all parameters of the current NNLM on the device.\nThen the client model update is sent back to the server if the\ndevice is selected to join the cohort;\nServer-side update. Once adequate client model updates are\nreceived by the server, global model update is conducted and an\nupdated server model is deployed to each local device.\nThe client-side and server-side updates above are repeated\nuntil model convergence. The procedure is outlined in Algo-\nrithm 1, with more details in subsections 2.2, 2.3, and 2.4.\nAlgorithm 1: FL-based NNLM adaptation for ASR.\nHyper-parameters K,ηl,ηg,β1,β2,ϵg;\nInitialize θ1 as a pre-trained NNLM (no adaptation);\nfor each round t= 1,2,... do\nDeliver θt to each client\nSample a subset It of clients\nfor each client i∈It in parallel do\nθt\ni,1 := θt\nLoad ASR transcripts on client ifor training\nfor each local epoch k= 1,2,...,K do\nCompute gradients gt\ni,k on batches\nθt\ni,k+1 ←SGD(θt\ni,k,gt\ni,k,ηl)\nend\nθt\ni := θt\ni,K+1\nSend ∆t\ni := θt −θt\ni to server\nend\nθt+1 ←FedAdam(θt,∆t\ni,wt\ni,t,η g,β1,β2,ϵg)\nend\n2.2. Client-side NNLM Adaptation\nUpon the initial deployment, on-device ASR model with the\npre-trained NNLM for second-pass rescoring runs on each local\nclient to transcribe user’s utterances. The decoded hypotheses\nare then stored on the local device and serve as in-domain data\nfor on-device NNLM adaptation. In this work, only the 1-best\nhypothesis of each utterance is stored and used for on-device\ntraining.\nSuppose at round t of FL training, each selected client\ndownloads the NNLM θt from server and performs secure local\ntraining on their own device, that is, ﬁne-tuning θt using pri-\nvate data. Mini-batch stochastic gradient descent (SGD) is used\nas the local optimizer. Speciﬁcally, in the kth training epoch,\ntranscripts data on client iis split into multiple batches. For the\nbth batch, let us denote θt\ni,k,b as the current client model and\ngt\ni,k,b as the computed gradients after back-propagation. Then\nthe client model is updated as\nθt\ni,k,b+1 = θt\ni,k,b −ηl ·gt\ni,k,b(θt\ni,k,b) (1)\nwhere ηl is a local learning rate. After K epochs of training,\nthe client uploads its model update (i.e. difference of model pa-\nrameters; see subsection 2.4) to the central server over a secure\nconnection.\nIn the next subsection, we describe how to compute gt\ni,k,b\nin speech LM task, and how to utilize token-level conﬁdence\nscores to address the potential quality degradation due to mis-\ntranscribed text as training data.\n2.3. NNLM Adaptation with Conﬁdence Scores\nCross entropy loss is usually used for NNLM training. The fol-\nlowing shows this function for thebth batch ofkth local training\nepoch on client i\nLt\ni,k,b(θ) = −1\nnb\nnb∑\nj=1\n1\nTj\nTj∑\ns=1\nlog(ˆpj,s,v∗\nj,s(θ)) (2)\nwhere nb denotes the batch size, Tj refers to the sequence\nlength, v∗\nj,s represents the sth word of the jth transcript, and\nˆpj,s,v∗\nj,s indicates the predicted probability of observing v∗\nj,s\nover the entire vocabulary.\nAdapting NNLMs using ASR transcribed data has the chal-\nlenge of dealing with potential transcription errors. In this work,\nwe leverage external conﬁdence classiﬁer models to mitigate\nthis issue. Speciﬁcally, we modify the NNLM training objec-\ntive using conﬁdence scores. Let ˆcj,s be the estimated conﬁ-\ndence score on the word of v∗\nj,s in the jth transcript, and\nˆcj := 1\nTj\nTj∑\ns=1\nˆcj,s (3)\nbe the estimated utterance-level conﬁdence score, which is the\naverage of token-level conﬁdence scores. We propose the fol-\nlowing three modiﬁed loss functions for NNLM training.\nHard thresholding. We adopt utterance-level conﬁdence\nscores for training data selection, which amounts to exclude the\nset of utterances\n{j ∈[nb] : ˆcj <c}\nfrom training, where cis some ﬁxed constant. Notice that this\nmethod is equivalent to include an indicator function as a mul-\ntiplier on each utterance in the loss function.\nUtterance-level weighting. The utterance-level conﬁdence\nscores are leveraged for loss weighting\nLt,utt-weight\ni,k,b (θ) = −1\nnb\nnb∑\nj=1\nˆcj\nTj\nTj∑\ns=1\nlog(ˆpj,s,v∗\nj,s(θ)) (4)\nToken-level weighting. We utilize token-level conﬁdence\nscores for weighting in the loss function\nLt,token-weight\ni,k,b (θ) = −1\nnb\nnb∑\nj=1\n1\nTj\nTj∑\ns=1\nˆcj,slog(ˆpj,s,v∗\nj,s(θ)) (5)\n2.4. Server-side NNLM Update\nSuppose that at roundt, the server has the modelθtand samples\na set Itof clients. Let θt\ni denotes the model of each clienti∈It\nafter local training, and ∆t\ni := θt −θt\ni be the model difference\non client iwhich is sent back to the server. Let\n∆t :=\n∑\ni∈Iwt\ni∆t\ni∑\ni∈Iwt\ni\n(6)\nbe the averaged model difference or “pseudo-gradient” which\nis used in general server optimizer updates. Here, wt\ni refers to\nthe weight being assigned to the model difference from client i\nin the aggregation, i.e. number of words in the training data for\nadapting the client NNLM in round t.\nWe use the FedAdam optimizer for updating the global\nmodel [31]. Speciﬁcally, let ηg be the learning rate and hyper-\nparameters β1, β2 ∈[0,1), then\nmt = β1mt−1 + (1 −β1)∆t (7)\nvt = β2vt−1 + (1 −β2)(∆t)2 (8)\nˆmt = mt/(1 −βt\n1) (9)\nˆvt = vt/(1 −βt\n2) (10)\nθt+1 = θt −ηg · ˆmt√ˆvt + ϵg\n(11)\nwhere m0 = 0,v0 = 0, and ϵg is a small positive number.\n2.5. Differential Privacy for NNLM Adaptation\nA differentially private mechanism enables the public release of\nmodel parameters with a strong privacy protection [29, 30].\nDeﬁnition 2.1 (DP) A randomized mechanism Mwith a do-\nmain Dand range Ssatisﬁes (ϵ,δ)-DP if for any two adjacent\ndatasets d,d′∈D and for any subset S ⊆S, it holds that\nP(M(d) ∈S) ≤eϵP(M(d′) ∈S) + δ. (12)\nHere dand d′are deﬁned to be adjacent if d′can be formed by\nadding or removing a single training example fromd. It is worth\nnoting that the deﬁnition of adjacent datasets in Deﬁnition 2.1\ndepends on the application. Most prior work on DP deals with\nexample level (or utterance level in our case). For our task,\na better deﬁnition is user-level adjacency for protecting whole\nuser histories in the training set [32], since a sensitive word may\nbe uttered several times by an individual user. Note that given\nsome target δ, a smaller ϵleads to stronger privacy protection,\nbut often, can degrade the model accuracy.\nTwo modiﬁcations to the FL-based NNLM adaptation are\nneeded to ensure an differentially private algorithm. First, clip\nthe gradient computed on any client per each round to bound\na user’s impact on model parameters. Second, add randomly\nsampled Gaussian noise to the clipped gradient.\nIn subsection 3.4, we perform privacy analysis of the pro-\nposed NNLM adaptation approach.\n3. Experiments\n3.1. Datasets\nIn our experiments, the ASR model is trained using in-house\nvideo dataset (14K hours), which is sampled from public so-\ncial media videos and de-identiﬁed before transcription; both\ntranscribers and researchers do not have access to any user-\nidentiﬁable information (UII).\nThe following two ASR applications are considered. The\nﬁrst is conversation speech and the second is short voice com-\nmand for smart devices. For both use cases, in-domain speech\nFigure 1: Histogram of number of utterances on each device in\nthe simulation.\ndatasets are collected using mobile devices through crowd-\nsourcing from a data supplier for ASR; the data is properly\nanonymized and no UII is contained in the datasets.\nTable 1 shows a summary of the two datasets which contain\nthe adaptation split for NNLMs adaptation, and the test\nsplit for model evaluation purpose. It is worth mentioning that\nthe word error rates (WERs) on the adaptation split using\nthe video ASR model with a pre-trained NNLM for second-\npass rescoring are 9.7% and 12.2% for conversation and voice\ncommand applications, respectively.\nTable 1: Summary of speech datasets for two applications.\nSplit Feature Conversation Voice Command\nadaptation # of utts 166K 63K\n# of words 1,738K 363K\ntest # of utts 13K 13K\n# of words 123K 73K\n3.2. Setups\nWe would like to simulate the real-world scenarios after deploy-\ning the ASR and pre-trained NNLM models to clients. V oice\ndata from the adaptation split is streamed to each device\nand decoded by the on-device speech models. Then the tran-\nscripts are used to ﬁne-tune the NNLMs for domain adaptation.\nFor the ASR model, we use connectionist temporal classi-\nﬁcation (CTC) [8] criterion to learn an acoustic model and it\nis further composed with a 5-gram LM in a standard weighted\nﬁnite-state transducers framework. Here, we adopt a 6-layer\nlatency-control bi-directional LSTM encoder with hidden di-\nmension 1,000. The NNLM is used for second-pass 5-best\nrescoring, where we utilize a LSTM based model with charac-\nter embeddings [33] dimension 100, and 2 layers of 512 hidden\nunits. For each hypothesis among the 5-best list, its NNLM\nscore is linearly interpolated with the score from the 5-gram\nLM. The interpolation weight is chosen to give the lowest WER.\nThe conﬁdence classiﬁer model is trained on video dataset us-\ning feed-forward networks and handcrafted input features from\ndecoding results; isotonic regression is used for calibrating the\nmodel.\nTo simulate the environment of FL-based approaches, for\neach utterance, we generate a random device label from a Zipf\ndistribution. Thus utterances with a common device label are\nconsidered being received by the same device. This results in\napproximately 8K devices for each application. Figure 1 shows\nthe histogram of number of training examples (i.e. utterances)\non each device in the simulation, where we can see the empirical\ndistribution is highly skewed.\nRegarding the hyper-parameters of FL training, we set the\nnumber of selected users per round |It|= 100 ; learning rate\nηg = 0 .001 in the global FedAdam optimizer and ηl = 1 .0\nfor the client SGD optimizer. Locally, we only train 1 epoch\nwith batch size 8 for any selected client per each FL round. We\nuse 10 epochs for FL training, where each epoch corresponds to\n100 rounds.\n3.3. Evaluation Results\nThe baseline model in our experiments is the one where we use\nthe on-server pre-trained NNLM for rescoring, without domain\nadaptation. We compare it with the ﬁne-tuned NNLM using in-\ndomain unsupervised text from the adaptation split (tran-\nscribed by the ASR model) in the FL frameworks. Note that\nsuch in-domain data never leaves physical devices and is thus\nnot accessible from servers due to privacy restrictions. Multiple\nmethods in handling potential transcription errors in the adap-\ntation data are measured, including using all transcripts, hard\nthresholding, utterance-level and token-level weighting. For\ncomparison purposes, we also include the result without NNLM\nrescoring.\nTable 2 and Table 3 show the perplexity (PPL) and WER\nresults on the conversation and voice command evaluation\ndatasets. Compared with the baseline model, FL-based domain\nadapted NNLMs (using all transcripts) obtain relative 2.1% and\n8.4% WER gains on the two use cases. In addition, models\nleveraging conﬁdence scoring always outperform the one using\nall transcripts as the training data, and obtain up to relative 0.5%\nand 2.4% WER reductions on the two applications, respectively.\nFor short voice command evaluation set, hard thresholding leads\nto the best result. For longer conversation utterances, token-\nlevel weighting performs the best.\nTable 2: Results on the Conversation evaluation set.\nConversation\nModel PPL WER\nNo NNLM - 8.07\nServer-pretrained NNLM (no adapt) 109.4 7.96\nFL-ﬁnetuned NNLM (all utts) 32.0 7.79 (-2.1%)\nFL-ﬁnetuned NNLM (hard thres. utts) 31.2 7.76 (-2.5%)\nFL-ﬁnetuned NNLM (utt weighted) 30.8 7.77 (-2.4%)\nFL-ﬁnetuned NNLM (token weighted)30.3 7.75 (-2.6%)\nTable 3: Results on the Voice Command evaluation set.\nVoice Command\nModel PPL WER\nNo NNLM - 10.10\nServer-pretrained NNLM (no adapt) 420.4 9.89\nFL-ﬁnetuned NNLM (all utts) 8.1 9.06 (-8.4%)\nFL-ﬁnetuned NNLM (hard thres. utts) 8.0 8.82 (-10.8%)\nFL-ﬁnetuned NNLM (utt weighted) 8.0 9.00 (-9.0%)\nFL-ﬁnetuned NNLM (token weighted) 8.0 8.93 (-9.7%)\nWe also evaluate the performance of NNLM adaptation\nwithout pre-training, that is, training from scratch using the in-\ndomain data in the FL settings. From the results in Table 4, we\ncan see that training from scratch has around relative 1% WER\ndegradation comparing to ﬁne-tuned models in the FL settings.\nThus it is beneﬁcial to start with some pre-trained NNLM be-\nfore on-device adaptation.\nTable 4: Results on the Conversation evaluation set without pre-\ntraining on NNLMs.\nConversation\nModel PPL WER\nFL-ﬁnetuned NNLM (all utts) 32.0 7.79\nFL-ﬁnetuned NNLM (token weighted) 30.3 7.75\nFL-trained-from-scratch NNLM (all utts) 35.8 7.85\nFL-trained-from-scratch NNLM (token weighted)34.5 7.82\n3.4. Privacy Analysis\nOur privacy analysis is performed in the framework of R´enyi DP\n[34], which is a natural relaxation of DP based on the R´enyi di-\nvergence. It is well-suited for expressing guarantees of privacy-\npreserving approaches and for composition of heterogeneous\nmechanisms.\nIn this analysis, the L2 norm clip is set to 0.5, and the noise\nmultiplier, which is the ratio of the standard deviation of Gaus-\nsian noise to the L2 sensitivity, is set to 0.2, 0.5, and 1.5 in our\nexperiments. We set the target δ as 1e-5 and the value of ϵis\ncalculated accordingly.\nTable 5 displays the privacy analysis results on FL-based\nadapted NNLMs using all or token-level weighted transcripts.\nIt is expected that the lower the value of ϵ, the larger the PPL\nand WER. It is worth noting that these resulting models still\nperform better than the server-trained NNLM without domain\nadaptation, although the margins of gains become smaller than\nthe one without strong privacy guarantees.\nTable 5: Privacy analysis on the Conversation evaluation set.\nConversation\nModel (ϵ,δ)-DP PPL WER\n(248.6, 1e-5) 46.1 7.88\nFL-ﬁnetuned NNLM (all utts) (14.2, 1e-5) 50.4 7.91\n(0.9, 1e-5) 56.7 7.92\n(248.6, 1e-5) 45.9 7.85\nFL-ﬁnetuned NNLM (token weighted)(14.2, 1e-5) 50.4 7.89\n(0.9, 1e-5) 56.3 7.93\n4. Conclusion\nIn this paper, we introduce a NNLM adaptation approach for\nASR in the FL settings. Particularly, we leverage conﬁdence\nscoring models to adjust the NNLM training objective accord-\ningly. Experiments show that compared with no adaptation,\nthe presented method obtains modest WER reductions on two\nspeech datasets. We also perform privacy analysis of the pro-\nposed approach using DP. Future work includes exploring the\npersonalization of NNLMs in a FL framework.\n5. References\n[1] T. Mikolov, M. Karaﬁ ´at, L. Burget, J. ˇCernock`y, and S. Khudan-\npur, “Recurrent neural network based language model,” in Proc.\nInterspeech, 2010.\n[2] X. Chen, X. Liu, M. J. Gales, and P. C. Woodland, “Improving\nthe training and evaluation efﬁciency of recurrent neural network\nlanguage models,” in Proc. ICASSP, 2015.\n[3] H. Xu, K. Li, Y . Wang, J. Wang, S. Kang, X. Chen, D. Povey, and\nS. Khudanpur, “Neural network language modeling with letter-\nbased features and importance sampling,” inProc. ICASSP, 2018.\n[4] K. Irie, A. Zeyer, R. Schl ¨uter, and H. Ney, “Language modeling\nwith deep transformers,” in Proc. Interspeech, 2019.\n[5] X. Liu, Y . Wang, X. Chen, M. J. Gales, and P. C. Woodland, “Ef-\nﬁcient lattice rescoring using recurrent neural network language\nmodels,” in Proc. ICASSP, 2014.\n[6] H. Xu, T. Chen, D. Gao, Y . Wang, K. Li, N. Goel, Y . Carmiel,\nD. Povey, and S. Khudanpur, “A pruned RNNLM lattice-rescoring\nalgorithm for automatic speech recognition,” in Proc. ICASSP,\n2018.\n[7] K. Li, D. Povey, and S. Khudanpur, “A parallelizable lat-\ntice rescoring strategy with neural language models,” in Proc.\nICASSP, 2021.\n[8] A. Graves, S. Fern ´andez, F. Gomez, and J. Schmidhuber, “Con-\nnectionist temporal classiﬁcation: labelling unsegmented se-\nquence data with recurrent neural networks,” in Proc. ICML ,\n2006.\n[9] A. Graves, “Sequence transduction with recurrent neural net-\nworks,”arXiv preprint arXiv:1211.3711, 2012.\n[10] W. Chan, N. Jaitly, Q. Le, and O. Vinyals, “Listen, attend\nand spell: A neural network for large vocabulary conversational\nspeech recognition,” in Proc. ICASSP, 2016.\n[11] A. Kannan, Y . Wu, P. Nguyen, T. N. Sainath, Z. Chen, and\nR. Prabhavalkar, “An analysis of incorporating an external lan-\nguage model into a sequence-to-sequence model,” in Proc.\nICASSP, 2018.\n[12] S. Kim, Y . Shangguan, J. Mahadeokar, A. Bruguier, C. Fuegen,\nM. L. Seltzer, and D. Le, “Improved neural language model fu-\nsion for streaming recurrent neural network transducer,” in Proc.\nICASSP, 2021.\n[13] Y . He, T. N. Sainath, R. Prabhavalkar, I. McGraw, R. Alvarez,\nD. Zhao, D. Rybach, A. Kannan, Y . Wu, R. Panget al., “Stream-\ning end-to-end speech recognition for mobile devices,” in Proc.\nICASSP, 2019.\n[14] J. Kone ˇcn`y, H. B. McMahan, D. Ramage, and P. Richt´arik, “Fed-\nerated optimization: Distributed machine learning for on-device\nintelligence,” arXiv preprint arXiv:1610.02527, 2016.\n[15] J. Kone ˇcn`y, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh,\nand D. Bacon, “Federated learning: Strategies for improving com-\nmunication efﬁciency,”NeurIPS Workshop on Private Multi-Party\nMachine Learning, 2016.\n[16] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Ar-\ncas, “Communication-efﬁcient learning of deep networks from\ndecentralized data,” in AISTATS, 2017.\n[17] F. Chen, M. Luo, Z. Dong, Z. Li, and X. He, “Federated meta-\nlearning with fast convergence and efﬁcient communication,”\narXiv preprint arXiv:1802.07876, 2018.\n[18] K. C. Arnold, K. Z. Gajos, and A. T. Kalai, “On suggesting\nphrases vs. predicting words for mobile text composition,” inPro-\nceedings of the 29th Annual Symposium on User Interface Soft-\nware and Technology, 2016.\n[19] S. Ji, S. Pan, G. Long, X. Li, J. Jiang, and Z. Huang, “Learning\nprivate neural language modeling with attentive aggregation,” in\nIJCNN. IEEE, 2019, pp. 1–8.\n[20] D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau,\n“Federated learning for keyword spotting,” in Proc. ICASSP ,\n2019.\n[21] J. Xu, B. S. Glicksberg, C. Su, P. Walker, J. Bian, and\nF. Wang, “Federated learning for healthcare informatics,”Journal\nof Healthcare Informatics Research, pp. 1–19, 2020.\n[22] D. Dimitriadis, K. Kumatani, R. Gmyr, Y . Gaur, and S. E. Es-\nkimez, “A federated approach in training acoustic models.” in\nProc. Interspeech, 2020.\n[23] D. Guliani, F. Beaufays, and G. Motta, “Training speech recogni-\ntion models with federated learning: A quality/cost framework,”\nin Proc. ICASSP, 2021.\n[24] X. Cui, S. Lu, and B. Kingsbury, “Federated acoustic modeling\nfor automatic speech recognition,” in Proc. ICASSP, 2021.\n[25] H. Jiang, “Conﬁdence measures for speech recognition: A sur-\nvey,”Speech communication, 2005.\n[26] P.-S. Huang, K. Kumar, C. Liu, Y . Gong, and L. Deng, “Predict-\ning speech recognition conﬁdence using deep learning with word\nidentity and score features,” in Proc. ICASSP, 2013.\n[27] K. Kalgaonkar, C. Liu, Y . Gong, and K. Yao, “Estimating conﬁ-\ndence scores on asr results using recurrent neural networks,” in\nProc. ICASSP, 2015.\n[28] S. Xie and L. Chen, “Evaluating unsupervised language model\nadaptation methods for speaking assessment,” in Proceedings of\nthe Eighth Workshop on Innovative Use of NLP for Building Edu-\ncational Applications, 2013, pp. 288–292.\n[29] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating\nnoise to sensitivity in private data analysis,” in Theory of Cryp-\ntography Conference. Springer, 2006, pp. 265–284.\n[30] C. Dwork and A. Roth, “The algorithmic foundations of differ-\nential privacy,”Foundations and Trends in Theoretical Computer\nScience, vol. 9, no. 3-4, pp. 211–407, 2014.\n[31] S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Kone ˇcn`y,\nS. Kumar, and H. B. McMahan, “Adaptive federated optimiza-\ntion,” in Proc. ICLR, 2021.\n[32] H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, “Learning\ndifferentially private recurrent language models,” in Proc. ICLR,\n2018.\n[33] Y . Kim, Y . Jernite, D. Sontag, and A. M. Rush, “Character-aware\nneural language models,” in Proc. AAAI, 2016.\n[34] I. Mironov, “R ´enyi differential privacy,” in 30th Computer Secu-\nrity Foundations Symposium (CSF). IEEE, 2017, pp. 263–275.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.850266695022583
    },
    {
      "name": "Security token",
      "score": 0.7778357267379761
    },
    {
      "name": "Adaptation (eye)",
      "score": 0.631309986114502
    },
    {
      "name": "Word error rate",
      "score": 0.606671154499054
    },
    {
      "name": "Proxy (statistics)",
      "score": 0.6027418375015259
    },
    {
      "name": "Speech recognition",
      "score": 0.5992222428321838
    },
    {
      "name": "Language model",
      "score": 0.54892498254776
    },
    {
      "name": "Artificial neural network",
      "score": 0.5041037797927856
    },
    {
      "name": "Acoustic model",
      "score": 0.4703633487224579
    },
    {
      "name": "Deep neural networks",
      "score": 0.42630526423454285
    },
    {
      "name": "Artificial intelligence",
      "score": 0.39443033933639526
    },
    {
      "name": "Natural language processing",
      "score": 0.36740171909332275
    },
    {
      "name": "Machine learning",
      "score": 0.3383234739303589
    },
    {
      "name": "Speech processing",
      "score": 0.31021422147750854
    },
    {
      "name": "Computer network",
      "score": 0.08263829350471497
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Optics",
      "score": 0.0
    }
  ]
}