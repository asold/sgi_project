{
  "title": "Learning the Physics of Particle Transport via Transformers",
  "url": "https://openalex.org/W3197468996",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2566031866",
      "name": "Óscar Pastor Serrano",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2154251624",
      "name": "Zoltan Perko",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2566031866",
      "name": "Óscar Pastor Serrano",
      "affiliations": [
        "Delft University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2154251624",
      "name": "Zoltan Perko",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3109361813",
    "https://openalex.org/W2904732647",
    "https://openalex.org/W6628554702",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2898515460",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2998280826",
    "https://openalex.org/W2580163862",
    "https://openalex.org/W2898757811",
    "https://openalex.org/W3037692190",
    "https://openalex.org/W3037123803",
    "https://openalex.org/W2885894200",
    "https://openalex.org/W3191312577",
    "https://openalex.org/W2963308874",
    "https://openalex.org/W2900148384",
    "https://openalex.org/W3005536866",
    "https://openalex.org/W3037946733",
    "https://openalex.org/W2982402070",
    "https://openalex.org/W1967121735",
    "https://openalex.org/W1986376168",
    "https://openalex.org/W6751702305",
    "https://openalex.org/W3116710803",
    "https://openalex.org/W3098023271",
    "https://openalex.org/W3105594088",
    "https://openalex.org/W2902472343",
    "https://openalex.org/W2948077267",
    "https://openalex.org/W2046285344",
    "https://openalex.org/W6763367864",
    "https://openalex.org/W1901129140",
    "https://openalex.org/W2298441161",
    "https://openalex.org/W2095705004",
    "https://openalex.org/W3128646645",
    "https://openalex.org/W3084272386",
    "https://openalex.org/W2604380817",
    "https://openalex.org/W3015732362",
    "https://openalex.org/W6749954789",
    "https://openalex.org/W3102799385",
    "https://openalex.org/W3021302456",
    "https://openalex.org/W2945785363",
    "https://openalex.org/W3081016275",
    "https://openalex.org/W2099471712",
    "https://openalex.org/W3037932933",
    "https://openalex.org/W3121293672",
    "https://openalex.org/W3137278571",
    "https://openalex.org/W2995435108",
    "https://openalex.org/W3127868510",
    "https://openalex.org/W2980372617",
    "https://openalex.org/W3170874841",
    "https://openalex.org/W2970389371",
    "https://openalex.org/W3084412168",
    "https://openalex.org/W3036406222",
    "https://openalex.org/W3094502228",
    "https://openalex.org/W3098903812",
    "https://openalex.org/W3159778524",
    "https://openalex.org/W2989226908",
    "https://openalex.org/W4320013936",
    "https://openalex.org/W2963403868",
    "https://openalex.org/W2899663614",
    "https://openalex.org/W4298395628",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2804608955",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4394666973",
    "https://openalex.org/W2889646458",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3170227631",
    "https://openalex.org/W3108923139",
    "https://openalex.org/W1481099429",
    "https://openalex.org/W4299802238"
  ],
  "abstract": "Particle physics simulations are the cornerstone of nuclear engineering applications. Among them radiotherapy (RT) is crucial for society, with 50% of cancer patients receiving radiation treatments. For the most precise targeting of tumors, next generation RT treatments aim for real-time correction during radiation delivery, necessitating particle transport algorithms that yield precise dose distributions in sub-second times even in highly heterogeneous patient geometries. This is infeasible with currently available, purely physics based simulations. In this study, we present a data-driven dose calculation algorithm predicting the dose deposited by mono-energetic proton beams for arbitrary energies and patient geometries. Our approach frames particle transport as sequence modeling, where convolutional layers extract important spatial features into tokens and the transformer self-attention mechanism routes information between such tokens in the sequence and a beam energy token. We train our network and evaluate prediction accuracy using computationally expensive but accurate Monte Carlo (MC) simulations, considered the gold standard in particle physics. Our proposed model is 33 times faster than current clinical analytic pencil beam algorithms, improving upon their accuracy in the most heterogeneous and challenging geometries. With a relative error of 0.34±0.2% and very high gamma pass rate of 99.59±0.7% (1%, 3 mm), it also greatly outperforms the only published similar data-driven proton dose algorithm, even at a finer grid resolution. Offering MC precision 4000 times faster, our model could overcome a major obstacle that has so far prohibited real-time adaptive proton treatments and significantly increase cancer treatment efficacy. Its potential to model physics interactions of other particles could also boost heavy ion treatment planning procedures limited by the speed of traditional methods.",
  "full_text": "Learning the Physics of Particle Transport via Transformers\nOscar Pastor-Serrano, Zolt´an Perk´o\nDelft University of Technology, Department of Radiation Science and Technology, Mekelweg 15 2629JB Delft, Netherlands\no.pastorserrano@tudelft.nl\nAbstract\nParticle physics simulations are the cornerstone of nuclear\nengineering applications. Among them radiotherapy (RT) is\ncrucial for society, with 50% of cancer patients receiving ra-\ndiation treatments. For the most precise targeting of tumors,\nnext generation RT treatments aim for real-time correction\nduring radiation delivery, necessitating particle transport al-\ngorithms that yield precise dose distributions in sub-second\ntimes even in highly heterogeneous patient geometries. This\nis infeasible with currently available, purely physics based\nsimulations. In this study, we present a data-driven dose cal-\nculation algorithm predicting the dose deposited by mono-\nenergetic proton beams for arbitrary energies and patient ge-\nometries. Our approach frames particle transport as sequence\nmodeling, where convolutional layers extract important spa-\ntial features into tokens and the transformer self-attention\nmechanism routes information between such tokens in the\nsequence and a beam energy token. We train our network\nand evaluate prediction accuracy using computationally ex-\npensive but accurate Monte Carlo (MC) simulations, con-\nsidered the gold standard in particle physics. Our proposed\nmodel is 33 times faster than current clinical analytic pen-\ncil beam algorithms, improving upon their accuracy in the\nmost heterogeneous and challenging geometries. With a rel-\native error of 0.34 ± 0.2% and very high gamma pass rate\nof 99.59 ± 0.7% (1%, 3 mm), it also greatly outperforms\nthe only published similar data-driven proton dose algorithm,\neven at a finer grid resolution. Offering MC precision 4000\ntimes faster, our model could overcome a major obstacle that\nhas so far prohibited real-time adaptive proton treatments and\nsignificantly increase cancer treatment efficacy. Its potential\nto model physics interactions of other particles could also\nboost heavy ion treatment planning procedures limited by the\nspeed of traditional methods. The code is publicly available\nat https://github.com/opaserr/dota.\nIntroduction\nDespite significant research efforts cancer remains a lead-\ning cause of death, responsible for more than 10 million\ndeaths in 2020 worldwide (Ferlay et al. 2020; Sung et al.\n2021). With more than 50% of the patients receiving ra-\ndiation treatments, radiotherapy (RT) is at the forefront of\ncurrent standard of care, playing a crucially important role\nCopyright © 2022, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.\nin improving societal health. Sophisticated computational\nmethods and particle transport simulations have been key\nto this success (Bernier, Hall, and Giaccia 2004), enabling\nhighly personalized treatments. Traditional physics based\nalgorithms improved all steps in the RT workflow (imag-\ning, segmentation, dose calculation, optimization), but so far\nthey proved too slow and inaccurate for real-time adaptive\ntreatments promising ultimate precision with fewest adverse\nside-effects. Deep learning is key to overcome these limita-\ntions and realize the full potential of real-time adaptation.\nOur study focuses on learning particle transport physics\n— fundamental to all steps of RT from Computed Tomogra-\nphy (CT) image reconstruction to simulating the actually de-\nlivered patient dose — to provide the necessary sub-second\nspeed and high accuracy required for real-time adaptation.\nWe frame the transport problem as sequence modelling, with\na particle beam going through varying geometries and mate-\nrials, using convolutional layers to learn relevant spatial fea-\ntures and the transformer self-attention mechanism to com-\nbine information from the feature tokens and a beam energy\ntoken. We train our algorithm to specifically learn proton\ntransport in lung cancer patients with highly heterogeneous\ngeometries to predict dose based on CT images alone, but\nthe model could in theory be easily adapted to other par-\nticles (photons, electrons, heavy ions) and quantities (e.g.,\nparticle flux or secondary particle emission prediction).\nContributions Our specific contributions are as follows:\n• We frame particle transport physics as a sequence mod-\nelling task and propose a novel algorithm using convo-\nlutional encoder and decoder layers together with trans-\nformer causal self-attention to predict dose distributions.\n• We train our algorithm using highly variable geometries\nfrom lung cancer patients and demonstrate that it out-\nperforms both current clinical pencil beam algorithms\n(PBA), being 33 times faster and more precise in the\nmost complex geometries, and ’gold standard’ Monte\nCarlo (MC) methods, offering MC accuracy 4000 times\nfaster. Our model is also more accurate than the only pub-\nlished data driven proton dose calculation algorithm us-\ning (Long Short-Term Memory) LSTM cells.\n• We highlight the direct societal impact of the presented\nalgorithm by showcasing how it could improve current\nradiotherapy practice and enable real-time adaptive treat-\nThe Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n12071\nments. While we train our model to learn proton physics\nto predict dose distributions, we also detail extensions to\nmake it a general particle transport simulator, accounting\nfor e.g., beam shape or energy spectrum changes.\nBackground\nHere we describe RT workflow and the critical role of par-\nticle transport and dose calculation methods, and frame our\nwork in terms of unsolved challenges and related literature.\nRadiotherapy workflow RT treatments usually follow a\n4-step procedure. First, high quality anatomical information\nis acquired — typically as CT images (Pereira, Traughber,\nand Muzic 2014) — on which target tumors and organs at\nrisk (OARs) to protect are delineated. Second, the irradia-\ntion modality is chosen, with most patients receiving pho-\nton treatments, but proton therapy spreading quickly due to\nprotons’ finite range and significantly better ability to focus\ndose on tumors (Lundkvist et al. 2005). Third, a treatment\nplan is obtained, containing the intensities, energies and an-\ngles of the thousands of pencil beams used for irradiation.\nThis is the most complex and computationally expensive\ntask, requiring solving large scale multi-criteria optimiza-\ntion problems and calculating the dose deposited by each in-\ndividual pencil beam before an acceptable, clinically ’best’\nplan is achieved (Hussein et al. 2018; Meyer et al. 2018).\nLast, for quality assurance purposes detailed dose calcula-\ntions are performed to test plan robustness against anatomi-\ncal changes or decide to adapt a plan for future irradiations.\nParticle transport & dose calculation Accurate particle\ntransport algorithms are crucial for all these steps. CT im-\nage reconstruction relies on simulating photon interactions\nwith tissues and detectors; plan optimization requires the\nspatial dose distribution (typically in more than 1 million\nvoxels) from each available proton or photon beamlet (in\nthe thousands); while for plan evaluation the dose must be\ncalculated for many different geometries. Ideally these cal-\nculations should be quick and precise, but current analyt-\nical pencil beam algorithms and stochastic MC dose cal-\nculation tools offer a trade-off. PBA yields results without\nthe computational burden of MC engines, but its accuracy\nis severely compromised in highly heterogeneous or com-\nplex geometries, making slow and clinically rarely afford-\nable MC approaches necessary. The problem is most acute\nfor next generation real-time adaptive treatments promis-\ning ultimate precision with fewest side effects by correcting\ntreatments during irradiation, e.g., to account for anatomical\nchanges due to breathing, coughs or intestinal movements.\nTo finally become reality, such adaptive treatments require\nalgorithms that deliver MC accuracy in sub-second speed.\nRelated work Deep learning has achieved significant im-\nprovements in all steps of the RT workflow (Meyer et al.\n2018), but only imaging, treatment planning and dose cal-\nculation are relevant to our work. U-net (Ronneberger, Fis-\ncher, and Brox 2015) and Generative Adversarial Networks\n(Goodfellow et al. 2014) (and their variants) have been\nwidely applied to improve image quality, e.g., to generate\nsynthetic CT images from Magnetic Resonance Images (of-\nfering better soft tissue contrast than CT without additional\npatient dose) or low dose Cone-Beam CT (CBCT) images\n(Edmund and Nyholm 2017; Zhang et al. 2021); to predict\nstopping power from CBCT (Harms et al. 2020); or cor-\nrect scatter artifacts in CBCT reconstruction (Lalonde et al.\n2020). These works represent image to image transforma-\ntion, producing more useful images for the RT workflow\nthan their easier/faster to obtain or lower patient dose input.\nIn treatment planning, deep learning methods aim to pre-\ndict an optimal 3D patient dose distribution based on his-\ntorical data. The most successful works use ResNet (Chen\net al. 2019; Fan et al. 2019), 2/3D U-net (Kearney et al.\n2018; Nguyen et al. 2019b; Kajikawa et al. 2019) or hi-\nerarchically densely connected U-net (HDU-net) (Nguyen\net al. 2019a; Barrag ´an-Montero et al. 2019) architectures,\nwith segmented structure masks as input. Some also utilize\nthe CT image (Kearney et al. 2018) and manually encoded\nbeam configuration information (Nguyen et al. 2019a; Bar-\nrag´an-Montero et al. 2019). These works basically mimic\n’optimal’ plans for new patients that should be achievable\nbased on past ones, only outputting final dose distributions,\nbut not the required beam intensities (i.e., fluence maps)\nneeded to deliver such plans, which must be obtained via\nadditional, costly optimization. Thus, they are mostly used\nfor Quality Assurance (QA) purposes to aid planning, not\nreplace it. Only few papers attempt to jointly predict dose\ndistribution and fluence maps (Lee et al. 2019; Wang et al.\n2020), and all have been applied to photon treatments.\nPractically all applications of deep learning to dose cal-\nculations learn how to improve cheaper and faster physics\nbased simulations. Most works try to predict low noise MC\nphoton dose distributions from high noise MC doses (Peng\net al. 2019a,b; Bai et al. 2021; Neph et al. 2021), or deter-\nministic particle transport based photon distributions from\nsimple analytical calculations (Xing et al. 2020b; Dong and\nXing 2020), using CNNs, U-net or HDU-net architectures\nwith 2/3D patches. A few papers manually encode some\nphysics information as additional input such as fluence maps\n(Fan et al. 2020; Xing et al. 2020a), total energy released per\nunit mass maps (Zhu, Liu, and Chen 2020) or beam informa-\ntion (Kontaxis et al. 2020; Tsekas et al. 2021). We are only\naware of 2 papers (Wu et al. 2021; Javaid et al. 2021) using\ndeep learning to predict accurate low noise MC proton dose\ndistributions, both using cheap physics models (noisy MC\nand PBA) as input. While all these works provide significant\nspeed-up compared to pure physics based algorithms, some\neven reaching sub-second speeds, they all require physics\nmodels to produce their input, do not generalize easily (e.g.,\nto different beam energies) and are trained with full plan\ndata, unsuitable for real-time adaptation needing the indi-\nvidual dose distribution from each beamlet alone.\nMost related to ours is the work from (Neishabouri et al.\n2021), using LSTM networks to sequentially calculate pro-\nton pencil beam dose distributions from relative stopping\npower slices. Although requiring a separate model per beam\nenergy, this LSTM-based dose engine offers excellent infer-\nence times and close to PBA accuracy when tested on exter-\nnal patient data. Our approach builds upon the methodology\n12072\nof (Neishabouri et al. 2021), but uses a different architec-\nture, works on finer resolution and — most crucially — also\nlearns the physics of energy dependence in particle transport\nvia a single model.\nTransformer The backbone of the presented model is\nthe Transformer, introduced by (Vaswani et al. 2017) for\nmachine translation tasks. The Transformer and similar\nattention-based frameworks have completely replaced recur-\nrent architectures like LSTM in natural language process-\ning applications since then (Devlin et al. 2019; Brown et al.\n2020). One reason behind their large-scale adoption and suc-\ncess is the ability to process long-term dependencies by di-\nrectly accessing information at any point in the past with-\nout needing internal memory, which is essential to introduce\nbeam energy dependence in our model.\nTransformer-based architectures have also achieved state-\nof-the-art performance in computer vision tasks like image\nclassification (Ramachandran et al. 2019; Dosovitskiy et al.\n2020). Inspired by (Cordonnier, Loukas, and Jaggi 2019),\n(Dosovitskiy et al. 2020) present the Vision Transformer\n(ViT), circumventing the quadratic cost of computing the\nattention weight matrix by dividing the input image into a\npatch sequence. Following the Transformer basis of ViT, our\nmodel also adopts a patch-based processing of the inputs.\nThe price Transformers pay for their generality in both\nlanguage and computer vision is the need for a self-\nsupervised pre-training stage with large amounts of text or\nimage data (Devlin et al. 2019; Brown et al. 2020; Doso-\nvitskiy et al. 2020). For image classification, several ap-\nproaches try to achieve state-of-the-art performance with-\nout costly pre-training (Touvron et al. 2020; D’Ascoli et al.\n2021). As in the concurrent work of (Hassani et al. 2021),\nour model can be directly trained on a relatively small\ndataset by using a convolutional encoder first extracting im-\nportant features from the patched input data.\nSelf-attention The proposed model leverages the self-\nattention (SA) mechanism (Vaswani et al. 2017) allowing\ndynamic routing of information between the L elements in\na sequence z ∈RL×D. SA is based on the interaction be-\ntween a series of queries Q ∈RL×Dh, keys K ∈RL×Dh,\nand values V ∈RL×Dh obtained through a learned linear\ntransformation of the input sequence\n[Q, K, V ] = zWQKV , (1)\nwith learned weights WQKV ∈RD×3Dh. Intuitively, every\nsequence element emits a query and a key vector with the\ninformation to gather from and to offer to the rest of the\nsequence, respectively. Each of theL elements in the output\nsequence is a weighted sum of the values, where the weights\n— referred to as attention matrixA ∈RL×L — are obtained\nby matching queries against key vectors via inner products\nA = softmax\n\u0010QKT\n√Dh\n\u0011\n, (2)\nSA(z) = AV . (3)\nMulti-head self-attention (MSA) runs Nh parallel SA op-\nerations to extract different features and inter-dependencies.\nSetting Dh = D, the outputs of the different operations,\ncalled heads, are concatenated and are linearly projected\nwith learned weights Wh ∈RNhDh×D as\nMSA(z) = concat\nh∈{Nh}\n[SAh(z)]Wh. (4)\nBy definition, MSA is invariant to the relative order of el-\nements in the sequence. To account for positional informa-\ntion, a fixed (Vaswani et al. 2017) or learned (Dosovitskiy\net al. 2020) positional embedding can be added or concate-\nnated to the input right before the first MSA operation. In\naddition, in MSA every element in the sequence can retrieve\ninformation at any past and future point. For some prediction\ntasks where the elements cannot or need not attend to future\ninformation, a binary mask is used to stop information flow\nfrom the future to the present. Such SA mechanism variant\nis referred to as causal SA and is particularly suited for mod-\neling proton interactions and energy deposition physics that\nmostly occur sequentially in the forward beam direction.\nMethods\nOur objective is sub-second prediction of the dose deposited\nby individual proton beamlets via a model that implicitly\ncaptures the physics of particle transport. The presented\ntransformer-based parametric model exploiting the forward\nsequential nature of proton transport physics is well-suited\nfor this. This section describes the model’s building blocks,\nthe dataset and the training and evaluation procedures.\nProposed model We introduce a parametric model that\ncomputes the output dose distribution y ∈RL×H×W given\nthe input geometry data x ∈ RL×H×W and particle en-\nergy ϵ ∈E ⊂R+, where L is the depth, H is the height\nand W is the width of the geometric 3D grid. The model\n— referred to as Dose Transformer Algorithm (DoTA) —\ncaptures the relationship between the inputs and the output\ndose distribution through a nonlinear mapping fθ(x, ϵ) :\nRL×H×W ×E → RL×H×W , performed by a series of\nartificial neural networks. Figure 1 shows the architecture\nof the model, which processes the 3D input geometry x\nas a sequence of L 2D images in the beam’s eye view\n{xi|xi ∈R1×H×W , ∀i = 1, ..., L}.\nConvolutional encoder First, a convolutional encoder ex-\ntracts important features such as geometry contrasts and\nedges from the input CT slices. The convolutional encoder\ncontains two blocks, each with a convolutional, a Group\nNormalization (GN) (Wu and He 2020) and a pooling layer,\nfollowed by a Rectified Linear Unit (ReLU) activation. Af-\nter the second block, a convolution with K filters results in\na sequence of elements of reduced embedding dimension\nD = H′×W′×K, where H′and W′are the reduced height\nand width of the images. The layers in the convolutional en-\ncoder share weights and are applied independently to every\nelement xi in the sequence. We refer to the output of the con-\nvolutional encoder as tokens {zi|zi ∈RD, ∀i = 1, ..., L}.\nTransformer encoder The interaction between tokens zi\nis modeled in the transformer encoder through causal MSA,\n12073\nFigure 1: Model architecture. We treat the input and output 3D volumes as a sequence of 2D slices. A convolutional encoder\nreduces the dimension of the input and extracts important geometrical features. The particle energy is added at the beginning\nof the resulting sequence. A transformer encoder with causal self-attention then routes information between the encoded input\nslices. Finally, a convolutional decoder transforms the low-dimensional sequence into an output sequence of 2D dose slices.\nwith each token routing information from all preceding to-\nkens. To account for the relative positional information of\nsequence elements we add a learnable embedding to each\ntoken. We include an extra energy token ze = Weϵ ∈RD\nat the beginning of the sequence, where We ∈RD×1 is a\nlearned linear projection of the beam energy ϵ. The trans-\nformer encoder alternates MSA and Multi-layer Perceptron\n(MLP) layers, with Layer Normalization (LN) applied be-\nfore every layer (Ba, Kiros, and Hinton 2016) and residual\nconnections after every layer. A stack of N transformer en-\ncoder blocks computes the operations\nz0 = [ze; z] + rp, (5)\nsn = zn−1 + MSA(LN(zn−1)), n = 1... N (6)\nzn = sn + MLP(LN(sn)), n = 1... N (7)\nwhere rp ∈R(L+1)×D is the learnable positional embed-\nding and MLP is a two layer feed-forward network with\nDropout (Srivastava et al. 2014) and Gaussian Error Linear\nUnit (GELU) activations (Hendrycks and Gimpel 2016).\nConvolutional decoder To produce output dose volumey\nwith the same dimension as the input, each token is trans-\nformed via a convolutional decoder with shared weights\ninto the output slices {yi|yi ∈R1×H×W , ∀i = 1 , ..., L}.\nInstead of normal convolutional layers, the decoder con-\ntains transposed convolutions that increase the dimension of\ntheir input. Similarly to the convolutional encoder, two final\ndimension-preserving convolutions transform the output of\nthe second block into the 2D dose slices.\nDataset The models are trained using a dataset with pairs\nof sliced CT images and dose distributions corresponding to\nmono-energetic proton beams with different energies. The\n3D CT scans from 4 lung cancer patients are highly het-\nerogeneous due to the air, bones and organs present in the\nthorax, and cover a volume of 512 ×512 ×100 mm3 with\na resolution of 1 ×1 ×3 mm. Since each proton beam has\napproximately 20 mm diameter and travels up to 250 mm\nthrough a small volume only, we crop and extract blocks\nx ∈ R256×48×16 maintaining the original CT resolution.\nMany different blocks can be obtained from the same pa-\ntient by rotating the CT scan along the Z direction in steps\nof 5◦and applying shifts in YZ plane with 5 mm steps.\nThe output ground-truth dose distributions are calculated\nusing the open source Monte Carlo particle transport soft-\nware MCsquare (Souris, Lee, and Sterpin 2016), taking CT\nslices and calculating output blocks y ∈R256×48×16 with\nthe same size and resolution as the input via random sam-\npling of proton trajectories. Dose distributions are estimated\nusing 3 million primary particles ensuring low MC noise lev-\nels of 0.6%. For each input CT block we generate 4 dose\ndistributions corresponding to 4 randomly sampled energies\nbetween 80 and 130 MeV , rounded to 1 decimal. We mask\nMC noise by zeroing out dose values below the noise level.\nThe entire training dataset consists of 63,048 pairs of\ninput-output blocks, 10% of which are used as a valida-\ntion set. We apply data augmentation during training and\nrandomly rotate the volumes 180◦in beam’s eye view (YZ\nplane), doubling the number of samples. A test set of 3,618\ninput-output pairs from an additional 5th patient is used to\nevaluate generalization to unseen geometries and energies.\nTraining details The best performing model consists of\none transformer encoder block with 16 heads and convolu-\ntional layers with a 3×3 kernel. Using size preserving zero-\npadding results in halving (or doubling, for the decoder) the\nH and W dimensions after each convolutional block. The\ntoken embedding dimension D = H/4 ×W/4 ×K is con-\nstant throughout the transformer encoder layers, with height\nH = 48, width W = 16, K = 10 kernels and D = 480 ob-\ntained from a model hyperparameter search. The models are\ntrained with Tensorflow (Abadi et al. 2015) using the LAMB\noptimizer (You et al. 2019) and mini-batches of 8 samples,\nlimited by the maximum internal memory of the Nvidia\n12074\nTesla T4® Graphics Processing Unit (GPU) used during our\nexperiments. We use the mean squared error (MSE) as loss\nfunction and a scheduled learning rate starting at 10−3 that\nis halved every 4 epochs.\nGamma analysis We compare the predicted and ground-\ntruth 3D dose distributions from the test set using gamma\nanalysis (Low et al. 1998). Intuitively, for a set reference\npoints and their corresponding reference dose values, this\nmethod searches for similar dose values within small spheres\naround each point. The similarity is quantified using a max-\nimum dose difference threshold (usually expressed as a per-\ncentage of the reference dose): e.g., dose values are accepted\nsimilar if within 1% of the reference dose. The radius of\nthe sphere is referred to as distance-to-agreement criterion.\nMathematically, gamma values are calculated for individual\npoints in the predicted dose grid as\nγ(p) = min\nˆp\n{Γ(p, ˆp)}, (8)\nΓδ,∆(p, ˆp) =\ns\n|p −ˆp|2\nδ2 + |D(p) −D(ˆp)|2\n∆2 , (9)\nwhere p are the coordinates of the points in the predicted\ndose grid and ˆp the coordinates of the points in the ground\ntruth dose grids. D(p) is the dose at any point p, δ is the\ndistance-to-agreement and ∆ the dose difference criterion.\nWe use the publicly available gamma evaluation functions\nfrom PyMedPhys1, with δ = 3 mm and ∆ = 1% . The 3\nmm distance-to-agreement criterion ensures a neighborhood\nsearch of at least one voxel, while the dose difference crite-\nrion of 1% disregards uncertainty due to MC noise. Gamma\nvalues are calculated for each voxel and a voxel centered at\np is considered to pass the gamma evaluation if γ(p) < 1.\nFor the entire grid, the gamma pass rate can be calculated as\nthe fraction of passed voxels over total number of voxels.\nError analysis The sample average relative error is used\nas an additional method to explicitly compare dose differ-\nences between two grids. Given the predicted output y and\nthe ground truth dose distribution ˆy, the average relative er-\nror ρ can be calculated as\nρ = ∥y −ˆy∥L1\nmaxj ˆyj\n×100, (10)\nwhere maxj ˆyj is the maximum dose value among all voxels\nin the ground-truth dose grid.\nExperiments\nWe compare the performance of the presented DoTA model\nto both state-of-the-art and clinically used methods. The ex-\nperiments first focus on evaluating the accuracy all models:\nthe gamma evaluation serves as a tool to assess dosimetric\ndifferences, while the relative error allows direct compar-\nison of the predicted output and ground truth grids. Last,\nwe report calculation times and evaluate DoTAs’ potential\nto displace other algorithms as a fast dose calculation tool.\n1see https://docs.pymedphys.com\nBaselines Our approach is compared to PBAs, the group\nof analytical dose calculation methods mostly used in the\nclinic. In particular, we calculate dose distributions for the\nentire test set using the PBA included in the open-source\ntreatment planning software matRad 2 (Wieser et al. 2017).\nThe DoTA model is also compared to the only published\ndata-driven approach based on LSTM cells (Neishabouri\net al. 2021). Since the LSTM models in (Neishabouri et al.\n2021) are trained for a single energy, we additionally train a\nmodel using 104.25 megaelectronvolt (MeV) proton beams.\nGamma evaluation The gamma pass rate is calculated for\nevery test sample using the MC dose distributions as refer-\nence with two settings. In the firstunmasked setting identical\nto (Neishabouri et al. 2021), voxels with exactly 0 gamma\nvalue are excluded from the pass rate calculation. These are\ntypically voxels not receiving any dose in both the predicted\nand ground-truth grids, having no clinical relevance. How-\never, the outputs of the model’s last linear layer are hardly\never exactly 0, taking very small values instead. Thus, in the\nsecond, stricter masked setting, we mask voxels in the pre-\ndicted dose grid that are below 0.01% of the maximum dose.\nTable 1 summarizes the results of the gamma evaluation\nfor both settings. We report mean, standard deviation, maxi-\nmum and minimum pass rates across the entire test set. Even\nwith energy dependence and a finer grid resolution, DoTA\noutperforms the LSTM model in all aspects: the average\npass rate is higher, the spread lower, and the minimum is\nalmost 2% higher. The performance of PBA and DoTA is\nvery similar: their average values are very close in both the\nmasked and unmasked setting, and their gamma pass rate\ndistributions (left plot of Figure 2) almost overlap. The min-\nimum pass rate is significantly higher for DoTA, indicating\nthat PBA struggles with the most heterogeneous and com-\nplicated samples. To verify this, we divide the dose beamlet\ninto 4 equal sections along depth and score the number of\nfailed voxels per section across the entire test set. The right\nplot in Figure 2 shows the proportion of voxels failing the\ngamma evaluation per section, out of the total number of\nfailed voxels. The higher proportion in the4th, last section of\nthe beam represents inaccuracies in the high dose, clinically\nmost relevant regions where the effects of heterogeneities\nare most evident.\nError evaluation To explicitly compare the performance\nof PBA and DoTA, we calculate the sample average relative\nerror ρ of the test set. Table 2 shows the mean, standard de-\nviation, maximum and minimum errors observed across all\ntest samples, and the left plot in Figure 3 displays the dis-\ntribution of ρ values for both models. Though PBA achieves\nlow errors in the most homogeneous samples, our approach\nis clearly superior with a lower mean ρ and a twice lower\nmaximum error. The depth profile in the right plot of Fig-\nure 3 shows the same trend as the gamma evaluation: DoTA\noutperforms PBA in the last high dose regions of the beam.\nTime evaluation Besides high prediction accuracy, fast\ninference times are critical for clinical dose calculation algo-\nrithms. Table?? reports run times of the LSTM, DoTA, PBA\n2Available at https://github.com/e0404/matRad.\n12075\nModel Mask Energy (MeV) Mean (%) Std (%) Min (%) Max (%)\nLSTM (Neishabouri et al. 2021)\n✗ 67.85 98.56 1.30 95.35 99.79\n✗ 104.25 97.74 1.48 92.57 99.74\n✗ 134.68 94.51 2.99 85.37 99.02\nDoTA (ours)\n✗ 104.25 99.55 0.71 93.45 100\n✗ [80, 130] 99.59 0.70 92.79 100\n✓ [80, 130] 99.12 1.45 87.32 100\nPBA (Wieser et al. 2017) ✗ [80, 130] 99.45 1.16 89.61 100\n✓ [80, 130] 99.16 1.73 83.35 100\nTable 1: Gamma analysis results (δ = 3 mm, ∆ = 1% ). For PBA and DoTA, gamma pass rates are calculated across the\nsame test set. Pass rates of the LSTM models are directly obtained from (Neishabouri et al. 2021). Mask indicates whether the\npredicted low dose values below 0.01% of the maximum dose are masked before gamma evaluation. Mean, standard deviation\n(Std), minimum (Min) and maximum (Max) values across the test set are shown for each model, mask and energy combination.\nFigure 2: (Left) Distribution of the gamma pass rates across\nthe test set for the PBA and DoTA. (Right) Distribution of\nthe failed voxels along the beam, where each bin shows the\nratio between the number of voxels in the test set that fail\nthe gamma evaluation within a section of the beam and the\ntotal number of failed voxels.\nModel Mean (%) Std (%) Min (%) Max (%)\nDoTA\n(ours) 0.3430 0.1999 0.0780 1.4250\nPBA 0.3863 0.3154 0.0683 2.7317\nTable 2: Average relative error between predicted and refer-\nence MC dose distributions. Reported values include mean,\nstandard deviation (Std), minimum (Min) and maximum\n(Max) values across the test set, for both the PBA and DoTA.\nand MC dose algorithms. Though dependent on hardware,\nthe data-driven approaches are clearly faster than clinically\nused PBA and MC baselines. While LSTM seems faster than\nDoTA, this is partially due to the LSTM model having 2.67\ntimes smaller input/output and being run on better hardware.\nOur proposed approach offers a 33 speed-up compared to\nPBAs and 4000 times speed-up with respect to MC meth-\nods.\nAdditional geometries Figure 4 displays the worst per-\nforming test sample in terms of gamma pass rate for the\nPBA and DoTA models. Both samples consist of a beam\nFigure 3: (Left) Distribution of the average relative errors\nacross the test set for the PBA and DoTA. (Right) Compar-\nison of the average relative error per beam section, where\neach bin shows the mean relative error across the test set for\nequally sized sections of the beam.\nModel Mean (ms) Std (ms)\nLSTMa 6.0 -\nDoTAb (1 per batch) 70.5 10.2\nDoTAb (8 per batch) 31.2 1.0\nPBAc 1,030.7 108.9\nMCc 128,948.5 31,708.8\na Nvidia® Quadro RTX 6000 64 Gb RAM\nb Debian10 4 vCPUs 15 Gb RAM - Nvidia® Tesla T4 16 Gb RAM\nc Ubuntu 20.04 intel® CoreTM i7-8550U 1.8 GHz 16Gb RAM\nTable 3: Mean inference time and standard deviation (Std)\nacross the test set for each model. Reported run times\nonly account for the dose calculation and disregard pre-\nprocessing steps. The values for the LSTM model are taken\ndirectly from (Neishabouri et al. 2021). The DoTA runtimes\ninclude the per-sample runtime obtained using the maximum\nGPU capacity corresponding to a batches of 8 sample.\ntraversing the lungs, where most of the energy is deposited\nin a highly heterogeneous region, with the PBA sample com-\npletely misplacing the high energy peak, while DoTA still\nyielding reasonable prediction.\n12076\n(a) PBA\n (b) DoTA\nFigure 4: Worst performing sample in the gamma evaluation across the test set, for (a) PBA and (b) DoTA. Each plot displays\nthe central slice of the 3D input CT grid, the MC ground truth dose distribution, the model prediction and the gamma values.\nConclusions\nAfter their recent success in natural language processing\nand computer vision tasks, transformer-based architectures\nprove to excel in problems that involve sequential image\nprocessing too. Framing particle transport as sequence mod-\neling of 2D geometry slices, we use their power to build a\nfast and accurate dose calculation algorithm that implicitly\nlearns proton transport physics and has the potential for pro-\nfound social impact by enabling next generation, real-time\nadaptive radiotherapy cancer treatments.\nOur evaluation shows that the presented DoTA model has\nthe right attributes to replace proton dose calculation al-\ngorithms currently used in clinical practice. Compared to\nPBAs, DoTA achieves 33x faster inference times while be-\ning better suited for heterogeneous patient geometries. The\nhigh gamma pass rate in unseen geometries from an exter-\nnal patient also demonstrate that the model predicts close to\nhigh accuracy MC dose distributions in sub-second times.\nSuch speed and accuracy increase could directly improve\ncurrent RT practice by allowing comprehensive plan robust-\nness analysis (now performed by checking only few poten-\ntial geometries), quick dosimetric quality assurance of daily\ntreatments (mostly done by analysing anatomy changes via\ncomparing pre-treatment CT/CBCT images to the planning\nCT instead of corresponding dose distributions variations)\nand precise evaluation of needing plan adaptation. Crucially,\nthe sub-second speed for individual pencil beam dose cal-\nculation and incorporation of energy dependence make our\nmodel well suited for real-time treatment adaptation.\nTo our knowledge DoTA is the first deep learning method\nto implicitly learn particle transport physics, predicting dose\nusing only CT and beam energy as input, as opposed to pre-\nvious works only learning corrections for ’cheap’ physics\nbased predictions or predicting dose under fixed conditions.\nThe flexibility to incorporate additional beam characteris-\ntics, e.g., changes in beam shape (provided as 0th image\nslice) or energy spectrum (as the ϵ 0th token), or to pre-\ndict additional quantities (e.g., particle flux) holds the poten-\ntial to be a fast, general particle transport algorithm. Since\nphotons (used in photon therapy and CT/CBCT imaging)\nand heavy ions (in carbon and helium therapy) share sim-\nilar, mostly forward scatter physics, training our algorithm\nfor different particles could open door to several further ap-\nplications: e.g., predicting physical or radiobiological dose\n(requiring DNA scale simulations) in heavy ion treatments\n(yielding higher speed-ups due to the longer computations);\nor real-time CBCT image reconstruction to provide input\nfor real-time adaptation. Attending to future information too\ncould even allow learning large angle scatter physics crucial\nfor electron therapy. Thus, the presented algorithm could\nsignificantly contribute to improving cancer treatments, hav-\ning profound societal impact even on the short term.\n12077\nAcknowledgments\nThe authors would like to thank Kevin Wielinga for his con-\ntributions to this project. This work is supported by KWF\nKanker Bestrijding [grant number 11711], and is part of\nthe KWF research project PAREL. Zolt´an Perk´o would like\nto thank the support of the NWO VENI grant ALLEGRO\n(016.Veni.198.055) during the time of this study. The credit\nauthorship contribution to this paper is as follows:\nOscar Pastor-Serrano : Conceptualization, Methodology,\nSoftware, Validation, Formal Analysis, Investigation, Data\nCuration, Writing – original draft, Visualization.\nZolt´an Perk ´o: Conceptualization, Methodology, Formal\nAnalysis, Resources, Writing – original draft, Writing – Re-\nview & editing, Supervision, Project Administration, Fund-\ning Acquisition.\nReferences\nAbadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro,\nC.; Corrado, G. S.; Davis, A.; Dean, J.; Devin, M.; Ghemawat, S.;\nGoodfellow, I.; Harp, A.; Irving, G.; Isard, M.; Jia, Y .; Jozefowicz,\nR.; Kaiser, L.; Kudlur, M.; Levenberg, J.; Man ´e, D.; Monga, R.;\nMoore, S.; Murray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner,\nB.; Sutskever, I.; Talwar, K.; Tucker, P.; Vanhoucke, V .; Vasudevan,\nV .; Vi´egas, F.; Vinyals, O.; Warden, P.; Wattenberg, M.; Wicke, M.;\nYu, Y .; and Zheng, X. 2015. TensorFlow: Large-Scale Machine\nLearning on Heterogeneous Systems. Software available from ten-\nsorflow.org.\nBa, J. L.; Kiros, J. R.; and Hinton, G. E. 2016. Layer Normaliza-\ntion. arXiv:1607.06450 [stat.ML].\nBai, T.; Wang, B.; Nguyen, D.; and Jiang, S. 2021. Deep dose\nplugin: towards real-time Monte Carlo dose calculation through a\ndeep learning-based denoising algorithm. Machine Learning: Sci-\nence and Technology, 2(2): 025033.\nBarrag´an-Montero, A. M.; Nguyen, D.; Lu, W.; Lin, M.-H.;\nNorouzi-Kandalan, R.; Geets, X.; Sterpin, E.; and Jiang, S. 2019.\nThree-dimensional dose prediction for lung IMRT patients with\ndeep neural networks: robust learning from heterogeneous beam\nconfigurations. Medical Physics, 46(8): 3679–3691.\nBernier, J.; Hall, E. J.; and Giaccia, A. 2004. Radiation oncology:\na century of achievements. Nature Reviews Cancer, 4(9): 737–747.\nBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhari-\nwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; Agar-\nwal, S.; Herbert-V oss, A.; Krueger, G.; Henighan, T.; Child, R.;\nRamesh, A.; Ziegler, D. M.; Wu, J.; Winter, C.; Hesse, C.; Chen,\nM.; Sigler, E.; Litwin, M.; Gray, S.; Chess, B.; Clark, J.; Berner, C.;\nMcCandlish, S.; Radford, A.; Sutskever, I.; and Amodei, D. 2020.\nLanguage models are few-shot learners. Advances in Neural Infor-\nmation Processing Systems, 2020-Decem.\nChen, X.; Men, K.; Li, Y .; Yi, J.; and Dai, J. 2019. A feasibility\nstudy on an automated method to generate patient-specific dose dis-\ntributions for radiotherapy using deep learning. Medical Physics,\n46(1): 56–64.\nCordonnier, J.-B.; Loukas, A.; and Jaggi, M. 2019. On the\nRelationship between Self-Attention and Convolutional Layers.\narXiv:1911.03584 [cs.LG].\nD’Ascoli, S.; Touvron, H.; Leavitt, M.; Morcos, A.; Biroli, G.; and\nSagun, L. 2021. ConViT: Improving Vision Transformers with Soft\nConvolutional Inductive Biases. arXiv:2103.10697 [cs.CV].\nDevlin, J.; Chang, M. W.; Lee, K.; and Toutanova, K. 2019. BERT:\nPre-training of deep bidirectional transformers for language un-\nderstanding. NAACL HLT 2019 - 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguis-\ntics: Human Language Technologies - Proceedings of the Confer-\nence, 1(Mlm): 4171–4186.\nDong, P.; and Xing, L. 2020. Deep DoseNet: a deep neural net-\nwork for accurate dosimetric transformation between different spa-\ntial resolutions and/or different dose calculation algorithms for pre-\ncision radiation therapy. Physics in Medicine & Biology, 65(3):\n035010.\nDosovitskiy, A.; Beyer, L.; Kolesnikov, A.; Weissenborn, D.; Zhai,\nX.; Unterthiner, T.; Dehghani, M.; Minderer, M.; Heigold, G.;\nGelly, S.; Uszkoreit, J.; and Houlsby, N. 2020. An Image is\nWorth 16x16 Words: Transformers for Image Recognition at Scale.\narXiv:2010.11929 [cs.CV].\nEdmund, J. M.; and Nyholm, T. 2017. A review of substitute CT\ngeneration for MRI-only radiation therapy. Radiation oncology\n(London, England), 12(1): 28.\nFan, J.; Wang, J.; Chen, Z.; Hu, C.; Zhang, Z.; and Hu, W. 2019.\nAutomatic treatment planning based on three-dimensional dose\ndistribution predicted from deep learning technique. Medical\nPhysics, 46(1): 370–381.\nFan, J.; Xing, L.; Dong, P.; Wang, J.; Hu, W.; and Yang, Y .\n2020. Data-driven dose calculation algorithm based on deep U-\nNet. Physics in Medicine & Biology, 65(24): 245035.\nFerlay, J.; Ervik, M.; Lam, F.; Colombet, M.; Mery, L.; Pi˜neros, M.;\nZnaor, A.; Soerjomataram, I.; and Bray, F. 2020. Global Cancer\nObservatory: Cancer Today. https://gco.iarc.fr/today. Accessed:\n2021-08-07.\nGoodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-\nFarley, D.; Ozair, S.; Courville, A.; and Bengio, Y . 2014. Genera-\ntive Adversarial Nets. In Ghahramani, Z.; Welling, M.; Cortes, C.;\nLawrence, N.; and Weinberger, K. Q., eds.,Advances in Neural In-\nformation Processing Systems, volume 27. Curran Associates, Inc.\nHarms, J.; Lei, Y .; Wang, T.; Mcdonald, M.; Ghavidel, B.; and\nStokes, W. 2020. Cone-beam CT-derived relative stopping power\nmap generation via deep learning for proton radiotherapy. Medical\nPhysics, 47(9): 4416–4427.\nHassani, A.; Walton, S.; Shah, N.; Abuduweili, A.; Li, J.; and Shi,\nH. 2021. Escaping the Big Data Paradigm with Compact Trans-\nformers. arXiv:2104.05704 [cs.CV].\nHendrycks, D.; and Gimpel, K. 2016. Gaussian Error Linear Units\n(GELUs). arXiv:1606.08415 [cs.LG].\nHussein, M.; Heijmen, B. J. M.; Verellen, D.; and Nisbet, A. 2018.\nAutomation in intensity modulated radiotherapy treatment plan-\nning—a review of recent innovations. The British Journal of Radi-\nology, 91(1092): 20180270.\nJavaid, U.; Souris, K.; Huang, S.; and Lee, J. A. 2021. Denoising\nproton therapy Monte Carlo dose distributions in multiple tumor\nsites: A comparative neural networks architecture study. Physica\nMedica, 89(August): 93–103.\nKajikawa, T.; Kadoya, N.; Ito, K.; Takayama, Y .; Chiba, T.; To-\nmori, S.; Nemoto, H.; Dobashi, S.; Takeda, K.; and Jingu, K. 2019.\nA convolutional neural network approach for IMRT dose distribu-\ntion prediction in prostate cancer patients. Journal of Radiation\nResearch, 60(5): 685–693.\nKearney, V .; Chan, J. W.; Haaf, S.; Descovich, M.; and Solberg,\nT. D. 2018. DoseNet: a volumetric dose prediction algorithm using\n3D fully-convolutional neural networks. Physics in Medicine &\nBiology, 63(23): 235022.\nKontaxis, C.; Bol, G. H.; Lagendijk, J. J. W.; and Raaymakers,\nB. W. 2020. DeepDose: Towards a fast dose calculation engine\nfor radiation therapy using deep learning. Physics in Medicine &\nBiology, 65(7): 075013.\n12078\nLalonde, A.; Winey, B.; Verburg, J.; Paganetti, H.; and Sharp, G. C.\n2020. Evaluation of CBCT scatter correction using deep convolu-\ntional neural networks for head and neck adaptive proton therapy.\nPhysics in Medicine & Biology Biology, 65(24): 245022.\nLee, H.; Kim, H.; Kwak, J.; Kim, Y . S.; Lee, S. W.; Cho, S.;\nand Cho, B. 2019. Fluence-map generation for prostate intensity-\nmodulated radiotherapy planning using a deep-neural-network.\nScientific Reports, 9(1): 15671.\nLow, D. A.; Harms, W. B.; Mutic, S.; and Purdy, J. A. 1998. A tech-\nnique for the quantitative evaluation of dose distributions. Medical\nPhysics, 25(5): 656–661.\nLundkvist, J.; Ekman, M.; Ericsson, S. R.; J ¨onsson, B.; and\nGlimelius, B. 2005. Proton therapy of cancer: Potential clinical\nadvantages and cost-effectiveness. Acta Oncologica, 44(8): 850–\n861.\nMeyer, P.; Noblet, V .; Mazzara, C.; and Lallement, A. 2018. Sur-\nvey on deep learning for radiotherapy. Computers in Biology and\nMedicine, 98(May): 126–146.\nNeishabouri, A.; Wahl, N.; Mairani, A.; K ¨othe, U.; and Bangert,\nM. 2021. Long short-term memory networks for proton dose cal-\nculation in highly heterogeneous tissues. Medical Physics, 48(4):\n1893–1908.\nNeph, R.; Lyu, Q.; Huang, Y .; Yang, Y . M.; and Sheng, K. 2021.\nDeepMC: a deep learning method for efficient Monte Carlo beam-\nlet dose calculation by predictive denoising in magnetic resonance-\nguided radiotherapy. Physics in Medicine & Biology, 66(3):\n035022.\nNguyen, D.; Jia, X.; Sher, D.; Lin, M.-H.; Iqbal, Z.; Liu, H.; and\nJiang, S. 2019a. 3D radiotherapy dose prediction on head and\nneck cancer patients with a hierarchically densely connected U-net\ndeep learning architecture. Physics in Medicine & Biology, 64(6):\n065020.\nNguyen, D.; Long, T.; Jia, X.; Lu, W.; Gu, X.; Iqbal, Z.; and\nJiang, S. 2019b. A feasibility study for predicting optimal radiation\ntherapy dose distributions of prostate cancer patients from patient\nanatomy using deep learning. Scientific Reports, 9(1): 1076.\nPeng, Z.; Shan, H.; Liu, T.; Pei, X.; Wang, G.; and Xu, X. G. 2019a.\nMCDNet – A Denoising Convolutional Neural Network to Accel-\nerate Monte Carlo Radiation Transport Simulations: A Proof of\nPrinciple With Patient Dose From X-Ray CT Imaging. IEEE Ac-\ncess, 7: 76680–76689.\nPeng, Z.; Shan, H.; Liu, T.; Pei, X.; Zhou, J.; Wang, G.; and Xu,\nX. G. 2019b. Deep learning for accelerating Monte Carlo radia-\ntion transport simulation in intensity-modulated radiation therapy.\narXiv:1910.07735 [physics.med-ph].\nPereira, G. C.; Traughber, M.; and Muzic, R. F. 2014. The Role of\nImaging in Radiation Therapy Planning: Past, Present, and Future.\nBioMed Research International, 2014(2): 1–9.\nRamachandran, P.; Bello, I.; Parmar, N.; Levskaya, A.; Vaswani,\nA.; and Shlens, J. 2019. Stand-alone self-attention in vision mod-\nels. Advances in Neural Information Processing Systems, 32.\nRonneberger, O.; Fischer, P.; and Brox, T. 2015. U-Net: Convo-\nlutional Networks for Biomedical Image Segmentation. In Navab,\nN.; Hornegger, J.; Wells, W. M.; and Frangi, A. F., eds., Medical\nImage Computing and Computer-Assisted Intervention – MICCAI\n2015, 234–241. Cham: Springer International Publishing. ISBN\n978-3-319-24574-4.\nSouris, K.; Lee, J. A.; and Sterpin, E. 2016. Fast multipurpose\nMonte Carlo simulation for proton therapy using multi- and many-\ncore CPU architectures. Medical Physics, 43(4): 1700–1712.\nSrivastava, N.; Hinton, G.; Krizhevsky, A.; and Salakhutdinov, R.\n2014. Dropout: A Simple Way to Prevent Neural Networks from\nOverfitting. Journal of Machine Learning Research, 15: 1929–\n1958.\nSung, H.; Ferlay, J.; Siegel, R. L.; Laversanne, M.; Soerjomataram,\nI.; Jemal, A.; and Bray, F. 2021. Global Cancer Statistics 2020:\nGLOBOCAN Estimates of Incidence and Mortality Worldwide for\n36 Cancers in 185 Countries.CA: A Cancer Journal for Clinicians,\n71(3): 209–249.\nTouvron, H.; Cord, M.; Douze, M.; Massa, F.; Sablayrolles, A.;\nand J´egou, H. 2020. Training data-efficient image transformers &\ndistillation through attention. arXiv:2012.12877 [cs.CV], 1–22.\nTsekas, G.; Bol, G. H.; Raaymakers, B. W.; and Kontaxis, C. 2021.\nDeepDose: a robust deep learning-based dose engine for abdominal\ntumours in a 1.5 T MRI radiotherapy system. Physics in Medicine\n& Biology, 66(6): 065017.\nVaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.;\nGomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. Attention is\nall you need. In Advances in Neural Information Processing Sys-\ntems, volume 2017-Decem, 5999–6009.\nWang, W.; Sheng, Y .; Wang, C.; Zhang, J.; Li, X.; Palta, M.; Cz-\nito, B.; Willett, C. G.; Wu, Q.; Ge, Y .; Yin, F.-F.; and Wu, Q. J.\n2020. Fluence Map Prediction Using Deep Learning Models –\nDirect Plan Generation for Pancreas Stereotactic Body Radiation\nTherapy. Frontiers in Artificial Intelligence, 3(September): 1–10.\nWieser, H. P.; Cisternas, E.; Wahl, N.; Ulrich, S.; Stadler, A.;\nMescher, H.; Muller, L. R.; Klinge, T.; Gabrys, H.; Burigo, L.;\nMairani, A.; Ecker, S.; Ackermann, B.; Ellerbrock, M.; Parodi,\nK.; Jakel, O.; and Bangert, M. 2017. Development of the open-\nsource dose calculation and optimization toolkit matRad. Medical\nPhysics, 44(6): 2556–2568.\nWu, C.; Nguyen, D.; Xing, Y .; Montero, A. B.; Schuemann, J.;\nShang, H.; Pu, Y .; and Jiang, S. 2021. Improving proton dose calcu-\nlation accuracy by using deep learning.Machine Learning: Science\nand Technology, 2(1): 015017.\nWu, Y .; and He, K. 2020. Group Normalization. International\nJournal of Computer Vision, 128(3): 742–755.\nXing, Y .; Nguyen, D.; Lu, W.; Yang, M.; and Jiang, S. 2020a. Tech-\nnical Note: A feasibility study on deep learning-based radiotherapy\ndose calculation. Medical Physics, 47(2): 753–758.\nXing, Y .; Zhang, Y .; Nguyen, D.; Lin, M.; Lu, W.; and Jiang, S.\n2020b. Boosting radiotherapy dose calculation accuracy with deep\nlearning. Journal of Applied Clinical Medical Physics, 21(8): 149–\n159.\nYou, Y .; Li, J.; Reddi, S.; Hseu, J.; Kumar, S.; Bhojanapalli, S.;\nSong, X.; Demmel, J.; Keutzer, K.; and Hsieh, C.-J. 2019. Large\nBatch Optimization for Deep Learning: Training BERT in 76 min-\nutes.\nZhang, Y .; Yue, N.; Su, M.-y.; Liu, B.; Ding, Y .; Zhou, Y .; Wang,\nH.; Kuang, Y .; and Nie, K. 2021. Improving CBCT quality to\nCT level using deep learning with generative adversarial network.\nMedical Physics, 48(June): 2816–2826.\nZhu, J.; Liu, X.; and Chen, L. 2020. A preliminary study of a pho-\nton dose calculation algorithm using a convolutional neural net-\nwork. Physics in Medicine & Biology, 65(20): 20NT02.\n12079",
  "topic": "Monte Carlo method",
  "concepts": [
    {
      "name": "Monte Carlo method",
      "score": 0.5525116324424744
    },
    {
      "name": "Physics",
      "score": 0.45541030168533325
    },
    {
      "name": "Particle therapy",
      "score": 0.44516465067863464
    },
    {
      "name": "Computer science",
      "score": 0.43946659564971924
    },
    {
      "name": "Algorithm",
      "score": 0.4334970712661743
    },
    {
      "name": "Proton therapy",
      "score": 0.4333900511264801
    },
    {
      "name": "Proton",
      "score": 0.41816246509552
    },
    {
      "name": "Computational physics",
      "score": 0.35760498046875
    },
    {
      "name": "Beam (structure)",
      "score": 0.2865447998046875
    },
    {
      "name": "Mathematics",
      "score": 0.22485727071762085
    },
    {
      "name": "Nuclear physics",
      "score": 0.18952444195747375
    },
    {
      "name": "Optics",
      "score": 0.1433793008327484
    },
    {
      "name": "Statistics",
      "score": 0.09831136465072632
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I98358874",
      "name": "Delft University of Technology",
      "country": "NL"
    }
  ]
}