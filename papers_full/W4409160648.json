{
  "title": "Large Language Models in Summarizing Radiology Report Impressions for Lung Cancer in Chinese: Evaluation Study",
  "url": "https://openalex.org/W4409160648",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2152563682",
      "name": "Danqing Hu",
      "affiliations": [
        "Nanjing University of Science and Technology",
        "Zhejiang Lab"
      ]
    },
    {
      "id": "https://openalex.org/A2163730931",
      "name": "Shanyuan Zhang",
      "affiliations": [
        "Peking University",
        "Peking University Cancer Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2036709854",
      "name": "Qing Liu",
      "affiliations": [
        "Peking University",
        "Peking University Cancer Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2132880602",
      "name": "Xiaofeng Zhu",
      "affiliations": [
        "Zhejiang Lab"
      ]
    },
    {
      "id": "https://openalex.org/A1973602695",
      "name": "Bing Liu",
      "affiliations": [
        "Peking University Cancer Hospital",
        "Peking University"
      ]
    },
    {
      "id": "https://openalex.org/A2152563682",
      "name": "Danqing Hu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2163730931",
      "name": "Shanyuan Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2036709854",
      "name": "Qing Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132880602",
      "name": "Xiaofeng Zhu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1973602695",
      "name": "Bing Liu",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2329360642",
    "https://openalex.org/W4392193048",
    "https://openalex.org/W2984982467",
    "https://openalex.org/W2515682654",
    "https://openalex.org/W2891022667",
    "https://openalex.org/W1484393529",
    "https://openalex.org/W4380551547",
    "https://openalex.org/W4205403018",
    "https://openalex.org/W4381587418",
    "https://openalex.org/W3109626385",
    "https://openalex.org/W4385737332",
    "https://openalex.org/W4327810158",
    "https://openalex.org/W4386120650",
    "https://openalex.org/W4390064615",
    "https://openalex.org/W4391292768",
    "https://openalex.org/W4378711639",
    "https://openalex.org/W4393203759",
    "https://openalex.org/W4393094733",
    "https://openalex.org/W4385292983",
    "https://openalex.org/W4382182493",
    "https://openalex.org/W4387225871",
    "https://openalex.org/W2938830017",
    "https://openalex.org/W3035451444",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W4311991106",
    "https://openalex.org/W4285294723",
    "https://openalex.org/W4389520259",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W2133512280"
  ],
  "abstract": "Background Large language models (LLMs), such as ChatGPT, have demonstrated impressive capabilities in various natural language processing tasks, particularly in text generation. However, their effectiveness in summarizing radiology report impressions remains uncertain. Objective This study aims to evaluate the capability of nine LLMs, that is, Tongyi Qianwen, ERNIE Bot, ChatGPT, Bard, Claude, Baichuan, ChatGLM, HuatuoGPT, and ChatGLM-Med, in summarizing Chinese radiology report impressions for lung cancer. Methods We collected 100 Chinese computed tomography (CT), positron emission tomography (PET)â€“CT, and ultrasound (US) reports each from Peking University Cancer Hospital and Institute. All these reports were from patients with suspected or confirmed lung cancer. Using these reports, we created zero-shot, one-shot, and three-shot prompts with or without complete example reports as inputs to generate impressions. We used both automatic quantitative evaluation metrics and five human evaluation metrics (completeness, correctness, conciseness, verisimilitude, and replaceability) to assess the generated impressions. Two thoracic surgeons (SZ and BL) and one radiologist (QL) compared the generated impressions with reference impressions, scoring them according to the five human evaluation metrics. Results In the automatic quantitative evaluation, ERNIE Bot, Tongyi Qianwen, and Claude demonstrated the best overall performance in generating impressions for CT, PET-CT, and US reports, respectively. In the human semantic evaluation, ERNIE Bot outperformed the other LLMs in terms of conciseness, verisimilitude, and replaceability on CT impression generation, while its completeness and correctness scores were comparable to those of other LLMs. Tongyi Qianwen excelled in PET-CT impression generation, with the highest scores for correctness, conciseness, verisimilitude, and replaceability. Claude achieved the best conciseness, verisimilitude, and replaceability scores on US impression generation, and its completeness and correctness scores are close to the best results obtained by other LLMs. The generated impressions were generally complete and correct but lacked conciseness and verisimilitude. Although one-shot and few-shot prompts improved conciseness and verisimilitude, clinicians noted a significant gap between the generated impressions and those written by radiologists. Conclusions Current LLMs can produce radiology impressions with high completeness and correctness but fall short in conciseness and verisimilitude, indicating they cannot yet fully replace impressions written by radiologists.",
  "full_text": null,
  "topic": "Verisimilitude",
  "concepts": [
    {
      "name": "Verisimilitude",
      "score": 0.8600375056266785
    },
    {
      "name": "Radiology",
      "score": 0.5403618216514587
    },
    {
      "name": "Correctness",
      "score": 0.45608091354370117
    },
    {
      "name": "Computer science",
      "score": 0.42243996262550354
    },
    {
      "name": "Medicine",
      "score": 0.3967442810535431
    },
    {
      "name": "Medical physics",
      "score": 0.3497077524662018
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3282318115234375
    },
    {
      "name": "Algorithm",
      "score": 0.11264413595199585
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ]
}