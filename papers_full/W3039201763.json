{
  "title": "Bidirectional Encoder Representations from Transformers (BERT): A sentiment analysis odyssey",
  "url": "https://openalex.org/W3039201763",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4288673712",
      "name": "Alaparthi, Shivaji",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4288673713",
      "name": "Mishra, Manit",
      "affiliations": [
        "International Management Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2599766447",
    "https://openalex.org/W2396526128",
    "https://openalex.org/W2487200295",
    "https://openalex.org/W1569827227",
    "https://openalex.org/W1576604406",
    "https://openalex.org/W2010812063",
    "https://openalex.org/W638679311",
    "https://openalex.org/W1518736070",
    "https://openalex.org/W2032793477",
    "https://openalex.org/W2097726431",
    "https://openalex.org/W1958077162",
    "https://openalex.org/W3123967386",
    "https://openalex.org/W2060437593",
    "https://openalex.org/W3125781831",
    "https://openalex.org/W2946382073",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W3124627942",
    "https://openalex.org/W2574134800",
    "https://openalex.org/W3123399111",
    "https://openalex.org/W2089961246",
    "https://openalex.org/W1689711448",
    "https://openalex.org/W2132314509",
    "https://openalex.org/W2493521008",
    "https://openalex.org/W2079735306",
    "https://openalex.org/W3123432896"
  ],
  "abstract": "The purpose of the study is to investigate the relative effectiveness of four different sentiment analysis techniques: (1) unsupervised lexicon-based model using Sent WordNet; (2) traditional supervised machine learning model using logistic regression; (3) supervised deep learning model using Long Short-Term Memory (LSTM); and, (4) advanced supervised deep learning models using Bidirectional Encoder Representations from Transformers (BERT). We use publicly available labeled corpora of 50,000 movie reviews originally posted on internet movie database (IMDB) for analysis using Sent WordNet lexicon, logistic regression, LSTM, and BERT. The first three models were run on CPU based system whereas BERT was run on GPU based system. The sentiment classification performance was evaluated based on accuracy, precision, recall, and F1 score. The study puts forth two key insights: (1) relative efficacy of four highly advanced and widely used sentiment analysis techniques; (2) undisputed superiority of pre-trained advanced supervised deep learning BERT model in sentiment analysis from text data. This study provides professionals in analytics industry and academicians working on text analysis key insight regarding comparative classification performance evaluation of key sentiment analysis techniques, including the recently developed BERT. This is the first research endeavor to compare the advanced pre-trained supervised deep learning model of BERT vis-à-vis other sentiment analysis models of LSTM, logistic regression, and Sent WordNet.",
  "full_text": "1 \n \nBidirectional Encoder Representations from Transformers (BERT):  \nA sentiment analysis odyssey  \nShivaji Alaparthi1 and Manit Mishra2 \n \nThe purpose of the study is to investigate the relative effectiveness of four different sentiment \nanalysis techniques: (1) unsupervised lexicon-based model using Sent WordNet; (2) traditional \nsupervised machine learning model using logistic regression; (3) supervised deep learning model \nusing Long Short-Term Memory (LSTM); and, (4) advanced supervised deep learning models \nusing Bidirectional Encoder Representations from Transformers  (BERT). We use p ublicly \navailable labeled corpora of 50,000 movie reviews originally posted on internet movie database \n(IMDB) for analysis using Sent WordNet lexicon, logistic regression, LSTM, and BERT. The first \nthree models were run on CPU based system whereas BERT was run on GPU based system. The \nsentiment classification performance was evaluated based on accuracy, precision, recall, and F1 \nscore. The study puts forth two key insights: (1) relative efficacy of four highly advanced and \nwidely used sentiment analysis techniques ; (2) undisputed superiority of pre -trained advanced \nsupervised deep learning BERT model in sentiment analysis from text data.  This study provides \nprofessionals in analyt ics industry and academicians working on text analysis key insight \nregarding comparative classification performance evaluation of key sentiment analysis techniques, \nincluding the recently developed BERT.  This is the first research endea vor to compare the \nadvanced pre-trained supervised deep learning model of BERT vis-à-vis other sentiment analysis \nmodels of LSTM, logistic regression, and Sent WordNet. \nKeywords – BERT, LSTM, Sentiment analysis, Logistic regression, Sent WordNet. \n(1) Data Scientist, CenturyLink, Bengaluru, India, E-mail id: alaparthishivaji@gmail.com \n(2) Associate Professor , International Management Institute Bhubaneswar , India, E-mail id:  \nmanit.mishra@imibh.edu.in \n2 \n \nIntroduction \nData is the new oil (Yi  et al., 2014), the most sought after raw material in 21 st century (Berners-\nLee and Shadbolt, 2011). It is a bottomless container of insight for organizations as every single \nday 2.5 quintillion bytes (2.5X10 18 bytes) of data gets added (Dobre and Xhafa, 2014) . Such an \ninflow is inevitable given the fact that only Walmart collects about 2.5 petabytes (2.5X10 15) of \ndata regarding customer transactions every hour (McAfee  et al., 2012). The data deluge is only \ngoing to be more pronounced in future with continuous emergence of new data sources (Bradlow  \net al., 2017). A significant portion of the data being generated is text data – structured, semi-\nstructured, and unstructured (Sivar ajah et al., 2017). Online consumer reviews are a formidable \nsource of such text data which have been utilized in extant research for the purpose of predicting \nconsumer ratings (Buschken and Allenby, 2016); forecasting stock market performance (Tirunillai \nand Tellis, 2012) ; extracting underlying dimensions of consumer satisfaction with quality \n(Tirunillai and Tellis, 2014) ; analysis and visualization of market structure (Lee and Bradlow, \n2011); generating market structure and competitive landscap e insights (Netzer et al., 2012); and \neven for assessing box office performance of movies (Chintagunta et al., 2010). Wedel and Kannan \n(2016, p. 107) underscore the significance of text data for future research in the area of marketing \nwhen they emphasize that “models for largescale unstructured data are still in their infancy, but \nresearch is starting to emerge.”  \n The opportunities notwithstanding, the challenges in deriving meaning out of text data are \nalso manifold. First, it is required to derive meaning from word or sentence in the context in which \nit has been used (Buschken and Allenby, 2016). For example, raging bull has a different meaning \nin the review of stock market as compared to a narrative about tourist attractions in Spain. Second, \nthe review itself may be fuzzy and/or incoherent thereby making it difficult to infer its meaning \n3 \n \n(Archak et al., 2011). For example, a movie review might read, “lackluster script saved by star \npower.” Such a dichotomous statement puts a question m ark on its valence. Third, unlike survey \ndata, text data is not readily available for data analysis. It requires substantial preprocessing before \nit can be subjected to statistical analysis (Tirunillai and Tellis, 2014). An exhaustive description of \nthe various steps involved in preprocessing of text prior to its statistical can be found in Bird  et \nal.’s (2009) Natural Language Tool Kit (NLTK) book. Given the enormity of text mining task, \nover a period of time multiple algorithms have been made available by  programming enthusiast, \ndata scientists, and even leading corporate houses such as Amazon. \n The intent of this paper is to offer a comparative analysis of the various algorithm options \navailable for an important application of text analytics - sentiment analysis. Sentiment analysis has \nbeen cited as one of the most popular applications of text analytics (Sarkar, 2019). Pang and Lee \n(2008, p. 10), in one of the early attempts to summarize research on consumer sentiments, have \ndefined sentiment analysis as a n “automatic analysis of evaluative text and tracking of the \npredictive judgments therein.”  A more elaborate definition has been given by Liu and Zhang \n(2012, p. 415 ) who define sentiment analysis as “the computational study of people’s opinions, \nappraisals, attitudes, and emotions toward entities, individuals, issues, events, topics, and their \nattributes.” Assessment of stakeholder sentiments has always been an important parameter for an \norganization’s sustenance and excellence. It is in complete alignment with the very foundational \nconcepts of marketing such as market orientation (Kohli and Jaworski, 1990). The significance of \nsentiment analysis has increased manifold since the availability of social media platforms to vent \nopinions (Liu and Zhang, 2012). However, keeping pace with the explosion in availability of text \nreflecting sentiments, multiple tools and techniques have inundated the analytics ecosystem. \nTherefore, in order to offer analytics enthusiasts a one-stop source on relative efficacy of some of \n4 \n \nthe prominent techniques of sentiment analysis, this study derives sentiments from a large corpus \nof publicly available movie reviews using four of the more widely used techniques: (1) \nunsupervised lexicon -based models  e.g., Sent WordNet ; (2) traditional supervised machine \nlearning models e.g., logistic regression ; (3) supervised deep learning models e.g., Long Short-\nTerm Memory (LSTM); and, (4) advanced supervised deep learning models e.g., Bidirectional \nEncoder Representations from Transformers (BERT). Based on sentiment analysis of this corpus \nof big data, we present output quality ratings of the  above-mentioned techniques of assessing \nsentiments from text.  To the best of our knowledge, no single comprehensive repository of \ninformation exists today which covers all the techniques mentioned above. Therefore, the paper \nwould serve as a source of reference for relative eff ectiveness of some of the most advanced \ntechniques of conducting sentiment analysis. \nSentiment analysis techniques: A review \nConsumer sentiments are a precursor to consumer intentions and decisions. The sentiments are \nhidden in the text uploaded onto various social media platforms by consumers in the form of \nreviews. This unstructured text data can be analyzed using sentiment analysis techniques to derive \na qualitative as well as quantitative interpretation of the underlying sentiments. While a qualitative \ninterpretation entails assessment on a positive to negative scale, a quantitative interpretation \nfacilitates calculation of sentiment polarity and subjectivity vis-à-vis objectivity proportions. The \nprimary target of analysis is the body of text comprising of all reviews called as corpora. The \ncorpora is made of a large number of individual text sentences or paragraphs called as documents. \nIt is the analysis of corpora made up of documents that leads to derivation of sentiments. Over a \nperiod of time there has been a gradual increase in the number and types of approaches for \nundertaking sentiment analysis. \n5 \n \nPreprocessing text data \nText data is largely unstructured (Sivarajah  et al. , 2017) and therefore, requires substantial \npreprocessing before sentiment analysis can be carried out (Tirunillai and Tellis, 2014). There are \na number of good sources to understan d preprocessing (e.g., Aggarwal and Zhai, 2012; Sarkar, \n2019) so we would only touch upon the major steps before moving on to the objective of this study \n– comparison of sentiment analysis techniques. The pre-processing of text data prior to conducting \nsentiment analysis involves following steps: \n1. Removing HTML tags from the text e.g. “<” \n2. Removing accented characters e.g. “ύ” \n3. Expanding the contracted words e.g. converting “haven’t” to “have not” \n4. Removing special characters e.g. “@” and “#” \n5. Separating text into sentences based on presence of punctuations and thereafter, removing \nthe punctuations e.g. “,” or “.” \n6. Lemmatization to arrive at the root word e.g. the root word for “succeeding” and \n“successful” would be “success” \n7. Replacing capital letters with lower-case letters e.g. “Positive” replaced by “positive”  \n8. Removing rare words that appear in less than 1% of the documents in any corpus \n9. Removing stop words that do not contribute to the meaning e.g. “the”     \n The reviews that form part of the cor pus are generated by individuals from different \ncultures having different ways of communicating in the same language and with no incentive to \nbe grammatically correct. Therefore, preprocessing of the text is essential to bring some degree of \nstandardization to the corpus and make it amenable to further analysis. \n \n6 \n \nUnsupervised lexicon-based model: Sent WordNet \nThese set of techniques are unsupervised and based on a lexicon or dictionary created and curated \nspecifically for sentiment analysis. The lexicons contain information on words; related positive or \nnegative sentiment; polarity as described by magnitude of positivity or negativity in the words ; \nparts of speech (POS) tag; subjectivit y classification in terms of strong, weak, or neutral etc.  \nSentiment analysis using this technique involves associating the words in the corpus with the \ncorresponding information provided in the lexicon along with contextual information in order to \nderive sentiment scores of documents constituting the corpora. Some of the popular lexicons in \nuse are TextBlob, AFINN, VADER, and Sent WordNet. \nSupervised machine learning model: Logistic regression \nThe traditional supervised machine learning predictive algorith m can also be  used to train the \nmodel into classifying sentiments. The sentiments undergo a classification into positive or negative \nbased on the review content.  This is followed by model validation. One of the more popular \ntechnique for undertaking such a binary classification is logistic regression (logit). The logit model \nis based on the theory of utility maximization incorporating a random factor (Nijkamp et al., 1992). \nSentiment analysis using logistic regression is based on bag of words model wherein each \ndocument in the corpora is considered to be a bag of unstructured words irrespective of its context, \norder, or grammar. This results i s a term-document matrix wherein each document is a row and \neach unique word is a distinct column. Thus, a corpus comprising of d documents (reviews)  and \nt unique terms (words) results in a ( d X t) matrix which is subjected to logistic regression. The \nlogit model calculates the odds of a document having a positive sentiment and based on its \ncomparison with a cut-off value, is classified as either a positive or a negative sentiment. The logit \n7 \n \nmodel uses a sigmoidal function and takes values between -∞ to +∞. It is a useful supervised \nmachine learning algorithm because it doesn’t have to assume linearity.  \nSupervised deep learning model: LSTM \nThe supervised deep learning models based on neural network architecture are being increasingly \nused to solve complicated problems and provide intelligent solutions (Metaxiotis and Psarras, \n2004). Its nonparametric nature, capability to train and build complex non-linear models, and its \nability to handle missing data makes it a sought after technique (Venugopal and Baets, 1994). The \nmost widely used neural network algorithm is the one based on feed forward mechanism and \nbackward propagation of error which facilitates analysis ov er input, output, and multiple hidden \nlayers (Shmueli et al., 2007). A variant of the deep neural network is the long short-term memory \n(LSTM) displaying a recurrent neural network (RNN) architecture which has applications in \nsentiment analysis of text dat a. In recent times, the standard LSTM architecture networks “have \nbecome the state-of-the-art models for a variety of machine learning problems” (Greff et al., 2016, \np. 2222). LSTM units generally comprise of a cell, an input gate, an output gate, and a forget gate. \nLSTMs are bidirectional networks that have been found to be more accurate in comparison to the \ntraditional multilayer perceptrons as well as standard RNNs (Graves and Schmidhuber, 2005). \nAdvanced supervised deep learning model:  BERT \nSentiment analysis from text data has undergone a colossal transformation with the arrival of pre-\ntrained transformer models such as Bidirectional Encoder Representations from Transformers \n(BERT). Developed by Devlin et al. (2018) of Google AI Language, BERT is “designed to pretrain \ndeep bidirectional representations from unlabeled text by jointly conditioning on both left and right \ncontext in all layers.” The state-of-the-art BERT is pre-trained on two unsupervised tasks – masked \nlanguage modeling and next sentence prediction , thus making it an effective technique for \n8 \n \nsentiment classification (Trivedi 2019, January 27). BERT is an advanced as well as more realistic \ntechnique since it accepts the fact that a document can simultaneously belong to multiple classes. \nBERT is known to have achieved exceptional results in eleven natural language understanding \n(NLU) tasks (Devlin  et al. , 2018). The credibility of BERT can be inferred from the fact that \nGoogle uses it in its search algorithm s (Nayak, 2019) and is currently applicable to over 70 \ndifferent languages (Roger, 2019).  \nAnalysis and interpretation \nData \nThe study uses publicly available movie review data from internet movie database (IMDB).  The \ndataset was first introduced and curated by Maas  et al.  (2011) in their study on vector -based \napproaches to sentiment classification.  This dataset consists of 50,000 movie reviews such that \neach movie accounts for 30 or lesser number of reviews. Each review has been labeled a priori as \nhaving either positive or negative sentiment.  There are an equal number of positive and negative \nsentiment reviews in the dataset. The reviews have a sentiment polarity score of either ≤4 or ≥7 on \na polarity index of 10. There are no neutral reviews  in the dataset. The dataset was downloaded \nfrom http://ai.stanford.edu/~amaas/data/sentiment/.  \nAnalysis \nFor the purpose of this study, the outputs for the techniques unsupervised lexicon based model \nusing Sent WordNet, unsupervised machine lear ning model using logistic regression, and \nsupervised deep learning model using LSTM, were derived based on a partitioning of 60% training \n(30,000 reviews) and 40% validation (20,000 reviews) data. However, for the advanced supervised \ndeep learning model using BERT, partitioning was done into 35% training (17,500 reviews), 15% \nvalidation (7,500 reviews), and 50% test (25,000 reviews) data. The structure of partitioning for \n9 \n \nBERT was altered due to two reasons: (1) pos sibility of overfitting since BERT is a pre -trained \nmodel; and, (2) requirement of greater computational power for a larger training data. The \nclassification performance of the models is assessed based on their accuracy, precision, recall, and \nF1 score obtained for sentiment classification of validation data or test data, in case of BERT.  \n The accuracy or hit-ratio of the model is the total number of documents correctly classified. \nIt provides the overall predictive accuracy of the model in classifying the reviews into positive and \nnegative sentiments. The precision of the model is determined from the ratio of correctly classified \ndocuments out of all the documents that have been predicted as having a positive sentiment. It \nsuggests success in classification within the predicted reviews belonging to important class – \nreviews having a positive sentiment. The recall or sensitivity is the true positive ratio. It indicates \nthe proportion of actual documents belonging to the important clas s that have been correctly \nclassified. Recall is a measure of the robustness of the model because it reflects the ability of the \nmodel to correctly predict the reviews having a positive sentiment. While recall gives the ability \nof the model to correctly pr edict the documents that actually belong to important class, precision \nportrays the model’s success rate out of all documents predicted to belong to the important class – \nin our case, the positive sentiment class. The F1 score of the model provides a balance between \nthe two and is an amalgamation of both these measures. A high F1 score indicates a model that not \nonly has high predictive ability of the important class but also has high success rate within the \npredictions of the important class. For all four measures of model robustness, a value closer to 1 \nis considered as better. The F1 score is obtained using the formula: \nF1 score = 2 * ((precision * recall)/(precision + recall)) \n  The classification performance of all the four techniques on the four output measures was \nderived based on their ability to classify the sentiments expressed in the reviews in validation data. \n10 \n \nThe sentiment analysis of the corpora based on Sent WordNet, logistic regression, and LSTM was \ncarried out on a central processing unit (CPU) based system whereas BERT was executed on a \ngraphics processing unit (GPU) based system. The run time using BERT for 5 epochs was 100 \nminutes. The derived classification performance outputs are given in Table 1. \nTable 1. Classification performance outputs \nClassification \ntechnique \nModel Accuracy Precision Recall F1 Score \nUnsupervised lexicon \nbased model \nSent WordNet 0.6308 0.6747 0.6308 0.6064 \nSupervised machine \nlearning model \nLogistic regression 0.8941 0.8975 0.8941 0.8941 \nSupervised deep \nlearning model \nLSTM 0.8675 0.8680 0.8675 0.8675 \nAdvanced supervised \ndeep learning model \nBERT 0.9231 0.9235 0.9231 0.9231 \n \nDiscussion and conclusion \nThe study examined the different sentiment analysis techniques on a publicly available labeled \ndataset of 50,000 IMDB movie reviews. Sentiment classification was carried out using \nunsupervised lexicon based model using Sent WordNet, supervised machine learning model using \nlogistic regression, supervised deep learning model using LSTM, and advanced supervised deep \nlearning model using pre -trained BERT. A comparative analysis of the four models reveal \nundisputed superiority of the pre-trained BERT model in sentiment classification. BERT is capable \nof achieving “deep bidirectional representations from unlabeled text by jointly conditioning on \nboth left and right context in all layers” (Devlin  et al. , 2018). This is unlike other language \nrepresentation models. That explains its unmatched superiority in sentiment classification in our \nstudy. Our findings also stand substantiated by BERT’s 80.5% score on general language \nunderstanding evaluation (GLUE) benchmark (Wang et al., 2018). Poor performance of LSTM in \n11 \n \ncomparison to logistic regression could be due to the fact that LSTM’s key strength lies in dealing \nwith vanishing gradient problems (Sundermeyer  et al., 2012). Therefore, it is more suitable for \ncases having a sequence of data points e.g., videos rather than single data points e.g., text or \nimages. The performance of unsupervised lexicon based model using the Sent WordNet lexicon is \ncomparatively inferior to other models probably due to its unsupervised predictive algorithm.  \n The study sheds new light on comparative classification performance evaluation of various \nsentiment analysis techniques on a labeled corpora. This is meant to aid analytics professionals \npursuing sentiment analysis. To the best of our knowledge, this is the first research endeavor to \ncompare the advanced pre -trained supervised deep learning model of BERT vis -à-vis other \nmodels. Even as the study broadens the horizon of work on sentiment analysis techniques, a few \nlimitations need to taken note of. First, BERT demands strong computational c apabilities. A \ngreater computational power could have allowed us to train the model on a larger data with more \nepochs leading to an even stronger performance by the model. Second, sentiment analysis using \nboth labeled as well unlabeled data could have thro wn interesting results. Having said that, we \nhave endeavored to provide a platform for future studies on sentiment analysis model comparison \nstudies. The insight generated study can be used by academicians and industry experts executing \nsentiment analysis for improved sentiment classification using a proven superior technique. \nReference \nAggarwal, C.C. and Zhai, C. (Eds.), (2012),  Mining Text Data . Springer Science & Business \nMedia, NY. \nArchak, N., Ghose, A. and Ipeirotis, P.G. (2011), “Deriving the pricing power of product features \nby mining consumer reviews”, Management Science, Vol. 57 No. 8, pp. 1485-1509. \n12 \n \nBerners-Lee, T., and Shadbolt, N. (2011), “There's gold to be mined from all our data”, available \nat: http://www.thetimes.co.uk/tto/opinion/columnists/article3272618.ece (accessed 21 November \n2019). \nBird, S., Loper, E. and Klein, E. (2009), Natural Language Toolkit, available at: \nhttp://www.nltk.org/book_1ed. \nBradlow, E.T., Gangwar, M., Kopalle, P. and Voleti, S. (2017), “The role of big data and predictive \nanalytics in retailing,” Journal of Retailing, Vol. 93 No. 1, pp.79-95. \nBüschken, J. and Allenby, G.M. (2016), “Sentence -based text analysis for customer \nreviews”, Marketing Science, Vol. 35 No. 6, pp. 953-975. \nChintagunta, P.K., Gopinath, S. and Venkataraman, S. (2010), “The effects of online user reviews \non movie box office performance: Accounting for sequential rollout and aggregation across local \nmarkets”, Marketing Science, Vol. 29 No. 5, pp. 944-957. \nDevlin, J., Chang, M.W., Lee, K. and To utanova, K. (2018), “BERT: Pre -training of deep \nbidirectional transformers for language understanding”, available \nat: https://arxiv.org/abs/1810.04805 (accessed 07 January 2020). \nDobre, C. and Xhafa, F. (2014), “Intelligent services for big data science”,  Future Generation \nComputer Systems, Vol. 37, pp.267-281. \nGraves, A. and Schmidhuber, J. (2005), “Framewise phoneme classification with bidirectional \nLSTM and other neural network architectures”, Neural Networks, Vol. 18 No. 5-6, pp. 602-610. \nGreff, K., Srivastava, R.K., Koutník, J., Steunebrink, B.R. and Schmidhuber, J. (2016), “LSTM: \nA search space odyssey”, IEEE Transactions on Neural Networks and Learning Systems, Vol. 28 \nNo. 10, pp.2222-2232. \n13 \n \nKohli, A.K. and Jaworski, B.J. (1990), “Market orientation: the construct, research propositions, \nand managerial implications”, Journal of Marketing, Vol. 54 No. 2, pp. 1-18. \nLee, T.Y. and Bradlow, E.T. (2011), “Automated marketing research using online customer \nreviews”, Journal of Marketing Research, Vol. 48 No. 5, pp. 881-894. \nLiu, B. and Zhang, L. (2012), “A survey of opinion mining and sentiment analysis”, in Aggarwal, \nC.C. and Zhai, C.X. (Eds.), Mining Text Data, Springer Science & Business Media, NY, pp. 415-\n463. \nMaas, A.L., Daly, R.E., Pham, P.T., Huang, D., Ng, A.Y. and Potts, C. (2011), “Learning word \nvectors for sentiment analysis”, in  Proceedings of the 49th annual meeting of the association for \ncomputational linguistics: Human language technologies -volume 1 , Association for \nComputational Linguistics, Portland, Oregon, pp. 142-150. \nMcAfee, A., Brynjolfsson, E., Davenport, T.H., Patil, D.J. and Barton, D. (2012), “Big data: the \nmanagement revolution”, Harvard Business Review, Vol. 90 No. 10, pp.60-68. \nMetaxiotis, K. and Psarras, J. (2004), “The contribution of neural networks and genetic algorithms \nto business decision support”, Management Decision, Vol. 42 No. 2, pp. 229-242. \nNayak, P. (2019), “Understanding searches better than ever before”, available at:  \nhttps://www.blog.google/products/search/search-language-understanding-bert/ (accessed 05 \nJanuary 2020). \nNetzer, O., Feldman, R., Goldenberg, J. and Fresko, M. (2012), “Mine your own business: Market-\nstructure surveillance through text mining”, Marketing Science, Vol. 31 No. 3, pp. 521-543. \nNijkamp, P., Reggiani, A. and Tritapepe, T. (1996), “Modelling inter -urban transport flows in \nItaly: A comparison between neural network analysis and logit analysis”, Transportation Research \nPart C: Emerging Technologies, Vol. 4 No. 6, pp. 323-338. \n14 \n \nPang, B. and Lee, L. (2008), “Opinion mining and sentiment analysis”, Foundations and Trends® \nin Information Retrieval, Vol. 2 No. 1–2, pp. 1-135. \nRoger, M. (2019), “Google’s BERT rolls out worldwide”, available at: \nhttps://www.searchenginejournal.com/google-bert-rolls-out-worldwide/339359/ (accessed 05 \nJanuary 2020). \nSarkar, D. (2019),  Text analytics with Python: a practitioner's guide to natural language \nprocessing, Apress, Bangalore. \nShmueli, G., Patel, N.R. and Bruce, P.C. (2007), Data mining for business intelligence: Concepts, \ntechniques, and applications in Microsoft Office Excel with XLMiner, John Wiley and Sons, New \nDelhi. \nSivarajah, U., Kamal, M.M., Irani, Z. and Weerakkody, V. (2017), “Critical analysis of Big Data \nchallenges and analytical methods”, Journal of Business Research, Vol. 70, pp.263-286. \nSundermeyer, M., Schlüter, R. and Ney, H. (2012), “LSTM neural networks for language \nmodeling”,  available at: https://www.isca-\nspeech.org/archive/archive_papers/interspeech_2012/i12_0194.pdf (accessed 07 January 2020). \nTirunillai, S. and Tellis, G.J. (2012), “Does chatter really matter? Dynamics of user -generated \ncontent and stock performance”, Marketing Science, Vol. 31 No. 2, pp. 198-215. \nTirunillai, S. and Tellis, G.J. (2014), “Mining marketing meaning from online chatter: Strategic \nbrand analysis of big data using latent dirichlet allocation”,  Journal of Marketing Research, Vol. \n51 No. 4, pp.463-479. \nTrivedi, K. (2019), “Multi -label text classification using BERT – The mighty transformer”, \navailable at: https://medium.com/huggingface/multi-label-text-classification-using-bert-the-\nmighty-transformer-69714fa3fb3d (accessed 05 January 2020). \n15 \n \nVenugopal, V. and Baets, W. (1994), “Neural networks and statistical techniques in marketing \nresearch”, Marketing Intelligence & Planning, Vol. 12 No. 7, pp. 30-38. \nWang, A., Singh, A., Michael, J., Hill, F., Levy, O. and Bowman, S.R. (2018), “GLUE: A multi -\ntask benchmark and analysis platform for natural language understanding”,  available at: \nhttps://arxiv.org/abs/1804.07461 (accessed 07 January 2020). \nWedel, M. and Kannan, P.K. (2016), “Marketing analytics for data -rich environments”, Journal \nof Marketing, Vol. 80 No. 6, pp. 97-121. \nYi, X., Liu, F., Liu, J. and Jin, H. (2014), “Building a network highway for big data: architecture \nand challenges”, IEEE Network, Vol. 28 No. 4, pp. 5-13. ",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8232545852661133
    },
    {
      "name": "Artificial intelligence",
      "score": 0.8087145090103149
    },
    {
      "name": "WordNet",
      "score": 0.7941845655441284
    },
    {
      "name": "Sentiment analysis",
      "score": 0.6535269021987915
    },
    {
      "name": "Lexicon",
      "score": 0.6041357517242432
    },
    {
      "name": "Deep learning",
      "score": 0.6010018587112427
    },
    {
      "name": "Natural language processing",
      "score": 0.5966838002204895
    },
    {
      "name": "Machine learning",
      "score": 0.571198582649231
    },
    {
      "name": "Encoder",
      "score": 0.5248669981956482
    },
    {
      "name": "Key (lock)",
      "score": 0.4678571820259094
    },
    {
      "name": "Supervised learning",
      "score": 0.4625622034072876
    },
    {
      "name": "Logistic regression",
      "score": 0.4369209408760071
    },
    {
      "name": "Artificial neural network",
      "score": 0.27491602301597595
    },
    {
      "name": "Computer security",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I158867519",
      "name": "International Management Institute",
      "country": "IN"
    }
  ],
  "cited_by": 53
}