{
    "title": "Evaluating Large Language Model-Generated Brain MRI Protocols: Performance of GPT4o, o3-mini, DeepSeek-R1 and Qwen2.5-72B",
    "url": "https://openalex.org/W4409286800",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2231255994",
            "name": "Su Hwan Kim",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2896924034",
            "name": "Severin Schramm",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A3168105521",
            "name": "Lena Schmitzer",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A5093873523",
            "name": "Kerem Serguen",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2908954584",
            "name": "Sebastian Ziegelmayer",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2131432264",
            "name": "Felix Busch",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A4367736728",
            "name": "Alexander Komenda",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2134728274",
            "name": "Marcus R. Makowski",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2432098160",
            "name": "Lisa C. Adams",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2767442332",
            "name": "Keno K. Bressem",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2097639162",
            "name": "Claus Zimmer",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2598981909",
            "name": "Jan Kirschke",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2055711268",
            "name": "Benedikt Wiestler",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A4225128329",
            "name": "Dennis Hedderich",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2107552077",
            "name": "Tom Finck",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2946150105",
            "name": "Jannis Bodden",
            "affiliations": [
                "Technical University of Munich"
            ]
        },
        {
            "id": "https://openalex.org/A2231255994",
            "name": "Su Hwan Kim",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2896924034",
            "name": "Severin Schramm",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3168105521",
            "name": "Lena Schmitzer",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A5093873523",
            "name": "Kerem Serguen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2908954584",
            "name": "Sebastian Ziegelmayer",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2131432264",
            "name": "Felix Busch",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4367736728",
            "name": "Alexander Komenda",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2134728274",
            "name": "Marcus R. Makowski",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2432098160",
            "name": "Lisa C. Adams",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2767442332",
            "name": "Keno K. Bressem",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2097639162",
            "name": "Claus Zimmer",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2598981909",
            "name": "Jan Kirschke",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2055711268",
            "name": "Benedikt Wiestler",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A4225128329",
            "name": "Dennis Hedderich",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2107552077",
            "name": "Tom Finck",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2946150105",
            "name": "Jannis Bodden",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W2422148244",
        "https://openalex.org/W1965830042",
        "https://openalex.org/W3118959542",
        "https://openalex.org/W2232597337",
        "https://openalex.org/W2164969488",
        "https://openalex.org/W2753917916",
        "https://openalex.org/W4311542223",
        "https://openalex.org/W2165839911",
        "https://openalex.org/W3176626957",
        "https://openalex.org/W2997405307",
        "https://openalex.org/W4401246245",
        "https://openalex.org/W4385230595",
        "https://openalex.org/W4404258623",
        "https://openalex.org/W4380422747",
        "https://openalex.org/W4383501206",
        "https://openalex.org/W4399118604",
        "https://openalex.org/W4387473486",
        "https://openalex.org/W4398781957",
        "https://openalex.org/W4367668513",
        "https://openalex.org/W4407393525",
        "https://openalex.org/W4407911733",
        "https://openalex.org/W4405079446",
        "https://openalex.org/W4387390366",
        "https://openalex.org/W4389984066",
        "https://openalex.org/W4404783788",
        "https://openalex.org/W4401660192",
        "https://openalex.org/W4403024753"
    ],
    "abstract": "Abstract Purpose To evaluate the potential of LLMs to generate sequence-level brain MRI protocols. Methods A dataset of 150 brain MRI cases was derived from imaging request forms obtained from the local institution. For each case, a reference MRI protocol was established by two board-certified neuroradiologists, with discrepancies resolved through consensus. GPT-4o, o3-mini, DeepSeek-R1 and Qwen-2.5-72B were employed to generate brain MRI protocols based on the case descriptions. For each model, protocol generation was conducted under two conditions: 1) with additional in-context learning involving local standard protocols and sequence explanations (enhanced) and 2) without additional external information (base). Additionally, two radiology residents independently defined MRI protocols for a subsample of 50 cases. The frequencies of redundant sequences, total missing sequences, and missing critical sequences are reported. The sum of redundant and missing sequences (accuracy index) was defined as a comprehensive metric to evaluate LLM protocoling performance. Accuracy indices were compared between groups using paired t-tests, with false discovery rate correction applied to control for multiple testing. Results The two neuroradiologists achieved substantial inter-rater agreement (Cohen’s κ = 0.74). The lowest accuracy index and therefore superior performance, was observed with o3-mini (base: 2.65; enhanced: 1.94), followed by GPT-4o (base: 3.11; enhanced: 2.23), DeepSeek-R1 (base: 3.42; enhanced: 2.37) and Qwen-2.5-72B (base: 5.95; enhanced: 2.75). o3-mini consistently outperformed the other models with a significant margin. All four models showed highly significant performance improvements under the enhanced condition ( adj. p &lt; 0.001 for all models), primarily driven by a substantial reduction of redundant MRI sequences. In the subsample, the highest-performing LLM (o3-mini [enhanced]) yielded an accuracy index comparable to residents (o3-mini [enhanced]: 1.92, resident 1: 1.80, resident 2: 1.44). Conclusion Our findings demonstrate promising potential of LLMs in automating brain MRI protocoling, especially when augmented through in-context learning. o3-mini exhibited superior performance, followed by GPT-4o.",
    "full_text": "Evaluating Large Language Model-\nGenerated Brain MRI Protocols: \nPerformance of GPT4o, o3-mini, \nDeepSeek-R1 and Qwen2.5-72B \n \nSu Hwan Kim 1, 2 , Severin Schramm 2, Lena Schmitzer 2, Kerem Serguen 2, Sebastian \nZiegelmayer 1, Felix Busch 1, Alexander Komenda 1, Marcus R. Makowski 1, Lisa C. Adams 1, \nKeno K. Bressem 1, 3, Claus Zimmer 2, Jan Kirschke 2, Benedikt Wiestler 4, Dennis Hedderich \n2, Tom Finck 2 *, Jannis Bodden 2 * \n \n1 Institute of Diagnostic and Interventional Radiology, TUM University Hospital, School of \nMedicine and Health, Technical University of Munich, Munich, Germany \n2 Institute of Diagnostic and Interventional Neuroradiology, TUM University Hospital, School \nof Medicine and Health, Technical University of Munich, Munich, Germany \n3 Department of Cardiovascular Radiology and Nuclear Medicine, German Heart Center \nMunich, School of Medicine and Health, Technical University of Munich, Munich, Germany \n4 AI for Image-Guided Diagnosis and Therapy, School of Medicine and Health, Technical \nUniversity of Munich, Munich, Germany \n \n* These authors contributed equally.  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\nAbstract \n \nPurpose \nTo evaluate the potential of LLMs to generate sequence-level brain MRI protocols. \n \nMethods \nA dataset of 150 brain MRI cases was derived from imaging request forms obtained from the \nlocal institution. For each case, a reference MRI protocol was established by two board-\ncertified neuroradiologists, with discrepancies resolved through consensus. GPT-4o, o3-mini, \nDeepSeek-R1 and Qwen-2.5-72B were employed to  generate brain MRI protocols based on \nthe case descriptions. For each model, prot ocol generation was conducted under two \nconditions: 1) with additional in-context l earning involving local standard protocols and \nsequence explanations (enhanced) and 2) without  additional external information (base). \nAdditionally, two radiology residents independently defined MRI protocols for a subsample of \n50 cases. The frequencies of redundant sequences, total missing sequences, and missing \ncritical sequences are reported. The sum of redundant and missing sequences (accuracy \nindex) was defined as a comprehensive metric to evaluate LLM protocoling performance. \nAccuracy indices were compared between groups using paired t-tests, with false discovery \nrate correction applied to control for multiple testing. \n \nResults\n \nThe two neuroradiologists achieved subs tantial inter-rater agreement (Cohen’s κ  = 0.74). \nThe lowest accuracy index and therefore super ior performance, was observed with o3-mini \n(base: 2.65; enhanced: 1.94), followed by GP T-4o (base: 3.11; enhanced: 2.23), DeepSeek-\nR1 (base: 3.42; enhanced: 2.37) and Qwen-2. 5-72B (base: 5.95; enhanced: 2.75). o3-mini \nconsistently outperformed the other models with a significant margin. All four models showed \nhighly significant performance im provements under the enhanced condition ( adj. p < 0.001 \nfor all models), primarily driven by a subst antial reduction of redundant MRI sequences. In \nthe subsample, the highest-performing LLM (o3-mini [enhanced]) yielded an accuracy index \ncomparable to residents (o3-mini [enhanced]: 1.92, resident 1: 1.80, resident 2: 1.44). \n \nConclusion \nOur findings demonstrate promising potential of LLMs in automating brain MRI protocoling, \nespecially when augmented through in-context learning. o3-mini exhibited superior \nperformance, followed by GPT-4o.  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nIntroduction \nMagnetic resonance imaging (MRI) of the brain is a complex diagnostic examination allowing \nfor the assessment of various neurological conditions. The process of determining the \nappropriate sequences for brain MRI scans bas ed on a review of the patient’s medical \nhistory and clinical question, commonly referred to as “protocoling”, is a crucial task requiring \nradiologists to carefully balance clinical necessity with efficiency. \nOn the one hand, imaging protocols should be sufficiently comprehensive to address the \nclinical indication. Omission of critical MR I sequences can necessitate repeat examinations \n(also known as callback examinations). In fact, protocol errors were reported to be the most \ncommon reason for such callbacks (28%), followed by inadequate anatomic coverage (21%) \n(1). On the other hand, protocols should be limi ted to essential sequences to minimize scan \ntime and healthcare costs. As the demand for MRI continues to increase (2), strategies to \nincrease patient access to MRI and to reduce wait times are a subject of ongoing interest (3–\n5). In addition, optimal MRI protocols can r educe unnecessary exposure to contrast agents \nwith potential adverse effects such as allergic reactions (6). \nInstitutions typically employ a set of stand ardized imaging protocols targeted at common \nclinical scenarios, such as “MR brain for brain metastasis” or “MR brain for multiple sclerosis” \n(7). Yet, they often prove insufficient in more complex cases, requiring individualized \nprotocol adjustments. Importantly, protocoling remains a time-consuming, non-interpretative \ntask intensifying radiologist workload, ex acerbating already increasing demands on their \ntime (8,9). In a study analysing the workflow in an academic neuroradiology reading room, \nprotocoling was found to take up 6.2% of the workday of radiologists, and was identified as a \nfrequent source of interruption from image interpretation (10). \nIn light of these challenges, previous studies have evaluated the potential of artificial \nintelligence (AI) tools to select or deter mine radiological imaging procedures (7,11–15). \nWong et al. trained a recurrent neural network to classify brain MRI cases into one out of \neight predefined brain MRI protocols (7). Several studies used large language models (LLMs) \nto predict the most suitable imaging modality, the anatomical region, and the need for \ncontrast application (12–15). Suzuki et al. analysed the performance of GPT-4 (Generative \nPre-Trained Transformer 4) in suggesting a single brain MRI sequence to be added to a \nstandard brain MRI protocol based on a disease name only, which limited the realism of the \nscenario (11). Therefore, this study aimed to evaluate the ability of LLMs to suggest granular, \nsequence-level brain MRI protocols based on realistic clinical cases. \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nMethods \nStudy Design \nEthical approval was waived by the institutional review board. \n \nCase Selection \nA set of 150 fictitious brain MRI cases in German was developed based on real patient \ncases from the local imaging database. For this purpose, the condensed medical history and \nclinical question indicated in the imaging request form as well as demographic information \nwas obtained. Subsequently, the original data was modified in each case by shifting the age \nrange by 5 – 10 years and substituting the location of the primary clinical or imaging finding \nin the medical history with a plausible alternat ive (e.g. “left frontal intracerebral hemorrhage” \ninstead of “right parietal intracerebral hemorr hage”). All references to locations were \nmanually removed, and specific dates were replaced with relative time descriptors (e.g. “2 \nyears ago”) to reach full anonymization. Cases were classified into five categories (vascular, \nneoplasia, inflammation, degenerative, miscellaneous ) based on the main clinical question. \nIn addition, cases were categorized as ‘typical’ if the reference protocol was identical to any \nof the local standard MRI protocols, and as ‘atypical’ if it was not.  \n \nBrain MRI Reference Protocols\n \nTwo board-certified neuroradiologists with  7 years of experience each (JB and TF) \nindependently defined a suitable brain MRI protocol for each of the 150 cases (Figure 1). \nMoreover, the two radiologists determined the critical MRI sequences per case, defined as \nthose without which a brain MRI examination would have to be repeated, due to their clinical \nrelevance.  Cases with inter-rater disagreement were adjudicated through consensus. The \nlevel of inter-rater agreement between the two board-certified neuroradiologists on a \nsequence level was determined using Cohens’ kappa. \n \nLLM Selection and Access\n \nTo include state-of-the-art models from both open-weight and closed-weight categories, the \nfollowing state-of-the-art LLMs were selected: GPT-4o (OpenAI, Inc., San Francisco, USA; \nclosed-weight), o3-mini (OpenAI, Inc., San Francisco, USA; closed-weight), Qwen2.5-72B \n(Alibaba Cloud, Singapore; open-weight), and DeepSeek-R1 (Hangzhou DeepSeek Artificial \nIntelligence Basic Technology Research Co., Ltd., Hangzhou, China; open-weight). \nGPT-4o and o3-mini were accessed via OpenAI’s official application programming interface \n(API) at https://platform.openai.com/docs/models\n. DeepSeek-R1 and Qwen2.5-72B were \naccessed via Fireworks AI, a generative AI inference platform with servers deployed in the \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nUnited States and Europe ( https://fireworks.ai/models). For all models, the structured output \nmode was applied to obtain responses adhering to a structured JSON (Javascript Object \nNotation) schema, enabling programmatic analysi s of LLM-generated protocols. For GPT-4o, \nDeepSeek-R1, and Qwen-2.5-72B, a temperature setting of 0 was selected to ensure \ndeterministic outputs, whereas the temperature parameter was not supported with o3-mini.  \nQueries with GPT-4o and o3-mini were performed on 6 Feb 2025 and 16 Feb 2025, \nrespectively. DeepSeek-R1 and Qwen2.5-72B queries were both executed on February 6, \n2025. Model details are provided in Table 1. \n \nLLM Prompting\n \nThe base prompt was iteratively refined using fi ve fictitious patient cases not included in the \ntest dataset. In response to initial observatio ns of misinterpretation of certain MRI sequence \nnames, brief descriptions of the less common sequences were added to the base prompt. \nThe final base prompt was defined as follows: \n  \n“You are a senior neuroradiologist tasked with defining a brain MRI protocol for a given \nclinical case. Consider the patient's demogr aphics, medical history, and clinical question. \nSynthesize this information to define an MRI protocol. For each sequence,  indicate 'yes' or \n'no'. Adhere to the data schema provided to y ou. Include only clinically relevant sequences, \navoid redundant or unnecessary sequences. Here  is a brief explanation of the more \nuncommon sequences. CISS (Constr uctive Interference in Steady State): A 3D gradient-\necho sequence with high spatial resolution. CE_1st_pass_Angio (Contrast-Enhanced First-\nPass Angiography): A dynamic imaging technique using gadolinium contrast to visualize \nblood vessels during the first pass of contrast through circulation. CSF_Drive: A specialized \nsequence for assessing CSF flow dynamics.  CSF_PCA (Phase Contrast Angiography): \nMeasures pulsatile CSF flow velocities and directions. T1_BB (Black Blood Imaging): \nSuppresses blood signal for vessel wall imaging. TRAK_4D (4D Time-Resolved MR \nAngiography with Keyhole): A 4D (time-resolved) MR angiography technique that captures \nthe dynamics of blood flow over time. \nTRANCE_4D (4D Time-Resolved Angiography using Non-Contrast Enhancement): A non-\ncontrast-enhanced 4D MRA technique, primarily used for imaging vascular structures based \non cardiac-triggered sequences. In the field 'reas oning', indicate your rationale for each \nsequence included.” \n \nFor each model, queries were executed  using ‘base’ queries (without additional context) \nand ‘enhanced’ queries employing in-context learning, a method guiding model behavior by \nembedding task-relevant information in the prompt (16). In the enhanced condition, models \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nwere provided with 20 standardized brain MR I protocols from the local institution \n(Supplement 1), along with an explanation of the clinical indications for each of the 27 \navailable MRI sequences (Supplement 2, created by SS and SHK), all included within the \nmodel’s context window. \n \nOne such explanation is provided in the following:  \n“TOF-MRA (Time-of-Flight Magnetic Resonanc e Angiography) is a non-contrast, static \ntechnique used to image the intracranial arteries. It confirms the patency and course of \nmajor vessels by demonstrating normal flow, and it excludes significant stenoses or \nocclusions when normal flow patterns are observed. TOF-MRA is a basic sequence for static \nvessel imaging and should be included in protocols that aim to assess cerebral arteries.” \n \nOur Python code for executing LLM queries is publicly available in our GitHub repository at \nhttps://github.com/shk03/llm_brain_mri_protocols\n. \n \nEvaluation of LLM Accuracy \nLLM performance in defining brain MRI protoc ols was evaluated by calculating the number \nof redundant sequences, total missing sequence s, and missing critical sequences, as \ncompared to the reference protocol. The sum of redundant and missing sequences was \ndefined as the ‘accuracy index’ serving as an overall metric for protocoling accuracy. \nFurthermore, the number of cases with unnecessary contrast application (protocols with at \nleast one post-contrast sequence) was calculated. \nFor the purpose of the analysis, ‘T2*’ and ‘SWI’ (susceptibility-weighted imaging) sequences \nwere considered equivalent. Similarly, ‘T1 Dixon’ and ‘T1 MPRAGE’ were treated as \ninterchangeable. \n \nResident-Generated Brain MRI Protocols\n \nIn a randomly selected subsample of 50 out of 150 brain MRI protocols, two radiology \nresidents further defined MRI protocols, se rving as a comparison for evaluating LLM-\ngenerated protocols. \nFor this subsample, two radiology residents with 18 and 16 months of dedicated \nneuroradiology experience (KS and LS) formulated brain MRI protocols. To simulate a \nrealistic scenario, residents were allowed to a ccess the local standard protocols if necessary. \n \nStatistical Analysis\n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nAll statistical analyses were conducted in Python (version 3.13.2) using ‘SciPy’ and \n‘statsmodels’ libraries. Two-sided paired t-tests were used to compare groups based on the \naccuracy index and the frequency of cases involving unnecessary contrast administration.  \nTo account for the increased risk of Type I errors due to multiple testing, the Benjamini–\nHochberg procedure was applied to control the false discovery rate (FDR) at 0.05. For each \ncomparison, the FDR-adjusted p-value is report ed. Statistical significance was set at p < \n0.05.\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nFigure 1: Study Design. Two board-certified neuroradiologists established the reference brain MRI protocols, with discrepancies resolved through \nGPT-4o, o3-mini, DeepSeek-R1 and Qwen-2.5-72B were employed to generate brain MRI protocols based on the case descriptions. For e\nprotocol generation was conducted under two conditions: 1) with additional in-context learning involving local standard protocols and sequence e\n(enhanced) and 2) without additional external information (base). Additionally, two radiology residents defined MRI protocols for a subsample of 50\n \ngh consensus. \nr each mod el, \ne explanations \n 50 cases. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nModel # Parameters Link API Access \ngpt-4o-2024-08-06 Unknown https://openai.com/index/hello-gpt-4o/ https://platform.openai.com/docs/models/gpt-4o#gpt-\n4o \no3-mini-2025-01-31 Unknown https://openai.com/index/openai-o3-mini/ https://platform.openai.com/docs/models/gpt-4o#o3-\nmini \nDeepSeek-R1 671B https://github.com/deepseek-ai/DeepSeek-\nR1 \nhttps://fireworks.ai/models/fireworks/deepseek-r1 \nQwen2.5-72B-Instruct 72B https://huggingface.co/Qwen/Qwen2.5-\n72B-Instruct \nhttps://fireworks.ai/models/fireworks/qwen2p5-72b-\ninstruct \nTable 1: Model details. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nResults \nDataset \nThe dataset comprised 150 cases with an equal gender distribution (50.0% female). The \nmedian patient age range was 56–60 years. 'Va scular' cases were most frequently observed \n(26.7%), followed closely by 'Neoplasia' case s (24.7%). Conversely, cases related to \ndegenerative conditions were relatively underrepresented (6.7%). A majority of cases \n(64.7%) was categorized as 'atypical', based on the divergence of the respective reference \nprotocol from any of the local standard brain MRI protocols (Table 2). The randomly selected \nsubsample had a similar composition, as shown in Table 3. \n \nReference Protocols\n \nThe two neuroradiologists achieved subst antial inter-rater agreement, reaching a \nconcordance of 96.0% across all MRI sequences (Cohen’s κ  = 0.74) and 97.3% for critical \nsequences (Cohen’s κ  = 0.75). The reference brain MRI protocols included an average of \n5.5 ± 1.50 sequences (range: 2–10), among which 3.22 ± 1.1 sequences (range: 1–6) were \nclassified as critical. The most frequently included sequence was FLAIR (100.0%; 150/150), \nfollowed by SWI (74.0%; 111/150) and DWI (72.7%; 109/150). In comparison, TOF-MRA \npost-contrast, CE fi rst-pass angiography, and dynamic pos t-contrast T1 sequences were \ninfrequently employed (0.7% each; 1/150). Contra st administration was required in 65.3% \n(98/150) of protocols. Cases categorized as  'inflammatory' exhibited the highest mean \nsequence count (6.2 ± 1.4), whereas 'degenerative' cases had the lowest (4.2 ± 0.4). Yet, \nequal sequence counts were found in typical (5.5 ± 1.4) and atypical (5.5 ± 1.5) cases.  \n \nLLM Protocoling Performance\n \nA sample brain MRI case including the LLM inputs and outputs is shown in Figure 2. The \nlowest accuracy index, indicating superior per formance, was observed with o3-mini (base: \n2.65; enhanced: 1.94), followed by GPT-4o (base: 3.11; enhanced: 2.23) and DeepSeek-R1 \n(base: 3.42; enhanced: 2.37). Qwen-2.5-72B demonstrated notably lower accuracy (base: \n5.95; enhanced: 2.75). o3-mini consistently outperformed other models with a significant \nmargin, surpassing GPT-4o (base: adj. p\n/i2 </i2 0.001, enhanced: adj. p/i2 =/i2 0.007), DeepSeek-\nR1 (base: adj. p /i2 </i2 0.001, enhanced: adj. p /i2 < 0.001), and Qwen-2.5-72B (base: adj. \np/i2 </i2 0.001, enhanced: adj. p/i2 < 0.001). \nGPT-4o surpassed Qwen-2.5-72B in both the base ( adj. p < 0.001) and enhanced ( adj. p < \n0.001) conditions, but showed no significant difference compared to DeepSeek-R1 (base: \nadj. p = 0.052; enhanced: adj.  p = 0.174). All four models showed highly significant \nimprovements in accuracy when augmented with additional domain knowledge (base vs \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nenhanced; adj. p < 0.001 for all models). Importantly, this improvement was primarily driven \nby a substantial reduction of unnecessary (r edundant) MRI sequences, whereas the rate of \nmissing critical sequences remained largely stable. For example, enhanced queries with o3-\nmini reduced redundant sequences from a mean of 1.75 (base) to 1.07 (enhanced), while \nthe frequency of missing sequences remained largely unchanged (base: 0.89; enhanced: \n0.87). In all scenarios, except for base queries using DeepSeek-R1, models recommended \nmore redundant than missing sequences, refl ecting a general tendency toward overly \ncomprehensive protocol recommendations.  \n \nIn Qwen-2.5-72B, the enhanced condition led to a major decrease of cases with \nunnecessary contrast administration (base: 95.3% [143/150], enhanced: 54.0% [81/150], adj. \np < 0.001), whereas the opposite trend was seen in DeepSeek-R1 (base: 23.3% [35/150], \nenhanced: 35.3% [53/150], adj. p = 0.012) (Figure 4).  \n \nProtocoling accuracy varied between case types. Across all four models, the greatest \nprotocoling accuracy was seen for ‘degenerativ e’ cases (accuracy index [base]: 2.48, \naccuracy index [enhanced]: 1.73). In contra st, inferior protocoling performance was \nobserved in ‘vascular’ cases (accuracy index [base]: 4.34, accuracy index [enhanced]: 2.47) \nand ‘miscellaneous’ cases (accuracy index [base]: 4.19, accuracy index [enhanced]: 2.80) \n(Figure 5). \n \nResident Protocoling Performance\n \nIn the subsample of 50 cases, the two radiol ogy residents achieved accuracy indices of 1.80 \n(0.98 redundant and 0.82 missing sequences per case) and 1.44 (0.58 redundant and 0.86 \nmissing sequences per case), respectively. The highest-performing LLM (o3-mini [enhanced]) \ndemonstrated comparable protocoling accuracy, reaching an index of 1.92 (1.16 redundant \nand 0.76 missing sequences per case) (Figure 6). \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nVariable Category Value # Sequences in Reference Protocol \nSex Female 50.0% (75/150)  \nMale 50.0% (75/150)  \nMedian age range - 56 – 60 - \nPathology Type Vascular  26.7% (40/150) 5.4 (± 1.9) \nNeoplasia 24.7% (37/150) 5.4 (± 1.1) \nMiscellaneous 23.3% (35/150) 5.5 (± 1.3) \nInflammation 18.7% (28/150) 6.2 (± 1.4) \nDegenerative 6.7% (10/150) 4.2 (± 0.4) \nProtocol type Typical 35.3% (53/150) 5.5 (± 1.4) \nAtypical 64.7% (97/150) 5.5 (± 1.5) \nTable 2: Dataset overview. 150 fictitious brain MRI cases were generated by significantly modifying \nreal patient cases from the local imaging database. The dataset included demographic information \n(age range and sex), the condensed medical history, and clinical question. Number of sequences in \nthe reference protocols are indicated as mean (± standard deviation). \n \n \nVariable Category Value \nSex Female 44.0% (22/50) \nMale 56.0% (28/50) \nAge range (median) - 56 – 60 \nPathology Type Vascular  28.0% (14/50) \nNeoplasia 24.0% (12/50) \nMiscellaneous 22.0% (11/50) \nInflammation 18.0% (9/50) \nDegenerative 8.0% (4/50) \nProtocol type Typical 32.0% (16/50) \nAtypical 68.0% (34/50) \nTable 3: Overview of the subsample dataset (n = 50). From the original 150 brain MRI cases, a \nrandom subsample of 50 cases was selected. Two radiology residents independently defined MRI \nprotocols for these cases, serving as a comparison for evaluating LLM-generated protocols. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \n \nFigure 2: Exemplary brain MRI case. In the enhanced condition, an explanation of MRI sequences as \nwell as local standard protocols were additionally provided to LLMs within the context window. For all \nmodels, the structured output mode was applied to obtain responses adhering to a structured JSON \n(JavaScript Object Notation) schema. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nFigure 3: Model performance in defining brain MRI protocols. ‘Enhanced’ indicates that the model received additional domain-specific knowledge -\nstandard protocols and explanations for the indications of MRI sequences. The accuracy index (sum of missing and redundant sequences) was us\nstatistically compare models with and without domain knowledge. *** Adj. p < 0.001.\n \n- local \n used to \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nFigure 4: Proportion of cases with LLM-generated protocols suggesting unnecessary contrast administration. ** Adj. p < 0.01. *** Adj. p < 0.001. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nFigure 5: Accuracy index by case type (n = 150). Accuracy index was defined as the sum of missing and redundant sequences in LLM- generate\nas compared to the consensus protocol of two board-certified neuroradiologists. Higher accuracy index indicates lower protocoli ng\n \nted protocols, \ng accuracy.\nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \n \nFigure 6: Performance of models and residents in defining brain MRI protocols (subsample, n = 50). ‘Enhanced’ indicates that the model received additional \ndomain-specific knowledge - local standard protocols and explanations for the indications of MRI sequences. Residents 1 and 2 had 18 and 16 months of \ndedicated neuroradiology experience at the time of the study.  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nDiscussion \nThis study evaluated the performance of four  state-of-the-art LLMs in creating granular, \nsequence-level brain MRI protocols with and without augmentation through in-context \nlearning. \n \nIn summary, LLMs showed promising performance in brain MRI protocoling. In-context \nlearning involving local standard protocols and explanations of MRI sequences consistently \nresulted in a substantial and highly significant improvement of protocoling accuracy. Notably, \nthe highest-performing LLM (o3-mini with enhanced queries) yielded accuracy levels \ncomparable to those of radiology residents with around 1.5 years of dedicated \nneuroradiology experience, demonstrating potential for automating this time-consuming \nprocess. Our study extends the findings of pr evious studies revealing the potential of LLMs \nin (semi-)automating imaging protocols (11–15). Although fictitious patient cases were used, \nthe generalizability of the findings is unlikely to be affected, as the data was derived from \nreal-world patient records through only minor modifications irrelevant to the MRI protocol. \n \nHowever, several obstacles remain to be addressed before (semi-)automation of MRI \nprotocoling is attainable. A technical infrastr ucture ensuring the preservation of patient data \nprivacy – either through deployment on local hardware or a secure cloud-based platform - is \nprerequisite for any clinical implementation of an LLM-based system (17). Open-weight \nmodels such as DeepSeek-R1 - which demonstrated reasonable performance in this study - \npresent a viable option for local deployment. Additionally, LLM-based systems should be \noptimized and tested for the prevention of any patient harm. Defining an imaging protocol \ninvolves the exclusion of potential contraindications for a particular imaging modality (e.g. \npresence of a pacemaker) or contrast administr ation (e.g. known allergy) (18). Avoiding any \nthreats arising from complete automation and overreliance on autonomous decision-making \nsystems (a psychological phenomenon also known as automation bias (19,20)) is critical. \nInsufficient clinical histories in imaging request forms are another frequent challenge faced \nby radiologists, requiring additional manual review  of the electronic medical records (EMR). \nRecent studies have explored the possibility to  utilize LLMs to assess the completeness of \nclinical histories (21) and augment request forms by mining the EMR for pertinent \ninformation (13). In the future, an agentic LLM system capable of orchestrating multiple tasks \nautonomously (22) could support an end-to-end auto-protocoling workflow, assessing \npotential contraindications, enriching clinical  histories with EMR-extracted data, and \neventually generating a tailored imaging protocol. \n \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nIn this study, LLMs were enhanced using in-cont ext learning, leading to improved protocol \naccuracy. The enrichment of LLM queries with external information sources has been an \narea of considerable scientific interest, holding promise for enhanced response accuracy \nwhile mitigating hallucinations (23). A widely adopted approach, retrieval-augmented \ngeneration (RAG), utilizes a pre-indexed external  database to dynamically retrieve relevant \ninformation during response generation (24). However, with the advent of LLMs featuring \nextensive context windows, vast amounts of information can now be processed directly \nthrough in-context learning approaches, eliminat ing the need for sophisticated retrieval \narchitectures – although at the cost of increased computational resources (25). As of this \nwriting, Gemini 2.0 Pro (Google LLC, Mountai n View, USA) features the largest context \nwindow, accommodating up to 2 million tokens, equivalent to approximately 3,000 pages of \ntext (26). Spanning 4,013 tokens only, the external documents used in this work were \nsufficiently compact to fit within the context window of all evaluated LLMs. The option to \neasily replace the external documents may allow for seamless adaptation to institution-\nspecific protocoling standards. \n \nIntriguingly, the MRI protocoling performanc e of GPT-4o – a non-reasoning LLM – was only \nslightly inferior to o3-mini, and comparable to DeepSeek-R1, both of which are considered \nstate-of-the-art reasoning LLMs (27,28). Reasoning models, designed to decompose \nproblems into smaller logical steps through techniques like chain-of-thought, are known to \nexcel at complex mathematical or logical reasoning tasks. Compared to non-reasoning LLMs, \nthey have been reported to better handle tasks outside their training data, albeit at the cost \nof increased processing time (29). In clinical settings, these structured reasoning capabilities \ncould contribute to improved transparency and explainability, allowing clinicians to better \nunderstand and validate the model’s output. Although direct comparisons were constrained \nby the undisclosed sizes of o3-mini and GPT- 4o, our results suggest that non-reasoning \nLLMs can perform competitively across various tasks, sometimes matching reasoning \nmodels. This underlines the importance of tailoring model selection to the specific task \nrequirements. \n \nLimitations\n \nThis study has several limitations. First, to en sure feasibility of the analysis, specific MRI \nprotocol parameters that influence exam as sessability, such as orientation and slice \nthickness, were not considered. Second, some MRI sequences (T1 MPRAGE and T1 Dixon, \nT2* and SWI) were treated as interchangeable, des pite their distinct technical properties and \nslightly different diagnostic utilities in ev aluating particular anatomical structures or \npathologies. Third, the accuracy index used to evaluate LLM protocoling performance \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nimplicitly gave equal weight to redundant and missing sequences, although omission of \nsequences could have greater clinical signif icance. Albeit imperfect, this approach allowed \nthe combined evaluation of clinical relevance and operational efficiency in a single metric. \nLastly, this is a single-center study and its findings require external validation across multiple \ninstitutions, particularly given the variability of available MRI sequences and protocoling \nstandards. \n \nIn conclusion, we demonstrate promising potential of LLMs in automating brain MRI \nprotocoling, especially when augmented with local protocoling standards. o3-mini exhibited \nsuperior performance, followed by GPT-4o. \n \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \nReferences  \n1.  Schemmel A, Lee M, Hanley T, et al. Radiology Workflow Disruptors: A Detailed \nAnalysis. Journal of the American College of Radiology. Elsevier B.V.; 2016;13:1210–\n1214. doi: 10.1016/j.jacr.2016.04.009. \n2.  Agarwal R, Bergey M, Sonnad S, Butowsky H, Bhargavan M, Bleshman MH. Inpatient \nCT and MRI utilization: Trends in the academic hospital setting. Journal of the \nAmerican College of Radiology. Elsevier; 2010;7:949–955. doi: \n10.1016/j.jacr.2010.08.015. \n3.  Bor DS, Sharpe RE, Bode EK, Hunt K, Gozansky WS. Increasing patient access to \nmri examinations in an integrated multispe cialty practice. Radiographics. Radiological \nSociety of North America Inc.; 2021;41:E1–E8. doi: 10.1148/rg.2021200082. \n4.  Holbrook A, Glenn H, Mahmood R, Cai Q, Kang J, Duszak R. Shorter Perceived \nOutpatient MRI Wait Times Associated with Higher Patient Satisfaction. Journal of the \nAmerican College of Radiology. Elsevier B.V.; 2016;13:505–509. doi: \n10.1016/j.jacr.2015.11.008. \n5.  Tokur S, Lederle K, Terris DD, et al. Process analysis to reduce MRI access time at a \nGerman University Hospital. International Journal for Quality in Health Care. \n2012;24:95–99. doi: 10.1093/intqhc/mzr077. \n6.  Ramalho M, Ramalho J. Gadolinium-Based Contrast Agents: Associated Adverse \nReactions. Magn Reson Imaging Clin N Am. W.B. Saunders; 2017. p. 755–764. doi: \n10.1016/j.mric.2017.06.006. \n7.  Wong KA, Hatef A, Ryu JL, Nguyen X V., Makary MS, Prevedello LM. An Artificial \nIntelligence Tool for Clinical Decision Support and Protocol Selection for Brain MRI. \nAmerican Journal of Neuroradiology. American Society of Neuroradiology; \n2023;44:11–16. doi: 10.3174/ajnr.A7736. \n8.  McDonald RJ, Schwartz KM, Eckel LJ, et al. The Effects of Changes in Utilization and \nTechnological Advancements ofCross-Sectional Imaging onRadiologist Workload. \nAcad Radiol. Elsevier Inc.; 2015;22:1191–1198. doi: 10.1016/j.acra.2015.05.007. \n9.  Kwee TC, Kwee RM. Workload of diagnostic radiologists in the foreseeable future \nbased on recent scientific advances: growth  expectations and role of artificial \nintelligence. Insights Imaging. Springer Science and Business Media LLC; 2021;12. \ndoi: 10.1186/s13244-021-01031-4. \n10.  Liles AL, Francis IR, Kalia V, Kim J, Davenport MS. Common causes of outpatient CT \nand MRI callback examinations: Opportunities for improvement. American Journal of \nRoentgenology. American Roentgen Ray Society; 2020;214:487–492. doi: \n10.2214/AJR.19.21839. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \n11.  Suzuki K, Abe K, Sakai S. Imaging protocol suggested by large language model \ndepends on language: preliminary experiments using GPT-4. 2024. doi: \n10.1101/2024.07.31.24311123. \n12.  Rau A, Rau S, Zöller D, et al. A Context-based Chatbot Surpasses Radiologists and \nGeneric ChatGPT in Following the ACR Appropriateness Guidelines. Radiology. \nRadiological Society of North America Inc.; 2023;308(1). doi: \n10.1148/RADIOL.230970. \n13.  Hallinan JTPD, Leow NW, Ong W, et al. MRI spine request form enhancement and \nauto protocoling using a secure institutional large language model. Spine Journal. \nElsevier Inc.; 2024; doi: 10.1016/j.spinee.2024.10.021. \n14.  Gertz RJ, Bunck AC, Lennartz S, et al. GPT-4 for Automated Determination of \nRadiologic Study and Protocol Based on Radiology Request Forms: A Feasibility \nStudy. Radiology. Radiological Society of North America Inc.; 2023;307(5). doi: \n10.1148/RADIOL.230877. \n15.  Nazario-Johnson L, Zaki HA, Tung GA. Use of Large Language Models to Predict \nNeuroimaging. Journal of the American College of Radiology. Elsevier B.V.; \n2023;20:1004–1009. doi: 10.1016/j.jacr.2023.06.008. \n16.  Iivanainen S, Lagus J, Viertolahti H, Sippola L, Koivunen J. Investigating large \nlanguage model (LLM) performance using in-cont ext learning (ICL) for interpretation \nof ESMO and NCCN guidelines for lung canc er. Journal of Clinical Oncology. \nAmerican Society of Clinical Oncology (ASCO); 2024;42:e13637–e13637. doi: \n10.1200/jco.2024.42.16_suppl.e13637. \n17.  Cai W. Feasibility and Prospect of Privacy-preserving Large Language Models in \nRadiology. Radiology. 2023;309(1):e232335. doi: 10.1148/RADIOL.232335. \n18.  Clement O, Romanini L, van der Molen AJ, et al. Contrast media safety: update on \nrecent ESUR-Contrast Media Safety Committee publications. Eur Radiol. Springer \nScience and Business Media Deutschland GmbH; 2024. doi: 10.1007/s00330-024-\n10725-4. \n19.  Dratsch T, Chen X, Mehrizi MR, et al. Automation Bias in Mammography: The Impact \nof Artificial Intelligence BI-RADS Suggesti ons on Reader Performance. Radiology. \nRadiological Society of North America Inc.; 2023;307(4). doi: \n10.1148/RADIOL.222176. \n20.  Kim SH, Schramm S, Riedel EO, et al. Automation bias in AI-assisted detection of \ncerebral aneurysms on time-of-flight MR angiography. Radiologia Medica. Springer-\nVerlag Italia s.r.l.; 2025; doi: 10.1007/s11547-025-01964-6. \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint \n21.  Larson DB, Koirala A, Cheuy LY, et al. Assessing Completeness of Clinical Histories \nAccompanying Imaging Orders Using Adapted Open-Source and Closed-Source \nLarge Language Models. Radiology. 2025;314:e241051. doi: 10.1148/radiol.241051. \n22.  Qiu J, Lam K, Li G, et al. LLM-based agentic systems in medicine and healthcare. Nat \nMach Intell. Nature Research; 2024. doi: 10.1038/s42256-024-00944-1. \n23.  Xu P, Ping W, Wu X, et al. RETRIEVAL MEETS LONG CONTEXT LARGE \nLANGUAGE MODELS. 12th International Conference on Learning Representations, \nICLR 2024. International Conference on Learning Representations, ICLR; 2024. doi: \n10.48550/arXiv.2310.03025. \n24.  Gao Y, Xiong Y, Gao X, et al. Retrieval-Augmented Generation for Large Language \nModels: A Survey. ArXiv. 2023; doi: 10.48550/arXiv.2312.10997. \n25.  Li Z, Li C, Zhang M, Mei Q, Bendersky M. Retrieval Augmented Generation or Long-\nContext LLMs? A Comprehensive Study and Hybrid Approach. Proceedings of the \n2024 Conference on Empirical Methods in Natural Language Processing: Industry \nTrack. Association for Computational Linguistics; 2024. p. 881–893. doi: \n10.18653/v1/2024.emnlp-industry.66. \n26.  Google DeepMind. Gemini 2.0 Pro. 2025. \nhttps://deepmind.google/technologies/gemini/pro/. Accessed March 16, 2025. \n27.  HuggingFace. deepseek-ai/DeepSeek-R1. 2025. https://huggingface.co/deepseek-\nai/DeepSeek-R1. Accessed March 16, 2025. \n28.  Yang A, Yang B, Hui B, et al. Qwen2 Technical Report. ArXiv. 2024; doi: \n10.48550/arXiv.2407.10671. \n29.  Temsah M-H, Jamal A, Alhasan K, Temsah AA, Malki KH. OpenAI o1-Preview vs. \nChatGPT in Healthcare: A New Frontier in Medical AI Reasoning. Cureus. \n2024;16:e70640. doi: 10.7759/cureus.70640. \n  \nAll rights reserved. No reuse allowed without permission. \n(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. \nThe copyright holder for this preprintthis version posted April 9, 2025. ; https://doi.org/10.1101/2025.04.08.25325433doi: medRxiv preprint "
}