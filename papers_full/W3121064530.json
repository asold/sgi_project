{
  "title": "Revisiting Mahalanobis Distance for Transformer-Based Out-of-Domain Detection",
  "url": "https://openalex.org/W3121064530",
  "year": 2021,
  "authors": [
    {
      "id": "https://openalex.org/A2803116312",
      "name": "Alexander Podolskiy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3120411212",
      "name": "Dmitry Lipin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2730432498",
      "name": "Andrey Bout",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2951265132",
      "name": "Ekaterina Artemova",
      "affiliations": [
        "National Research University Higher School of Economics",
        "Huawei Technologies (Sweden)"
      ]
    },
    {
      "id": "https://openalex.org/A2779311127",
      "name": "Irina Piontkovskaya",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2803116312",
      "name": "Alexander Podolskiy",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3120411212",
      "name": "Dmitry Lipin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2730432498",
      "name": "Andrey Bout",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2951265132",
      "name": "Ekaterina Artemova",
      "affiliations": [
        "National Research University Higher School of Economics"
      ]
    },
    {
      "id": "https://openalex.org/A2779311127",
      "name": "Irina Piontkovskaya",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W6684488266",
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2997140799",
    "https://openalex.org/W2959053776",
    "https://openalex.org/W6753056052",
    "https://openalex.org/W2531327146",
    "https://openalex.org/W2912237282",
    "https://openalex.org/W3015377432",
    "https://openalex.org/W6757615711",
    "https://openalex.org/W3035441651",
    "https://openalex.org/W2867167548",
    "https://openalex.org/W2767414122",
    "https://openalex.org/W6763425312",
    "https://openalex.org/W3035898727",
    "https://openalex.org/W2788907134",
    "https://openalex.org/W6630177651",
    "https://openalex.org/W6691431627",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W6762924995",
    "https://openalex.org/W2898856000",
    "https://openalex.org/W2970855255",
    "https://openalex.org/W2971525065",
    "https://openalex.org/W2951266961",
    "https://openalex.org/W2882319491",
    "https://openalex.org/W2250539671",
    "https://openalex.org/W2980282514",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2758425594",
    "https://openalex.org/W2963546708",
    "https://openalex.org/W2970946347",
    "https://openalex.org/W2957688595",
    "https://openalex.org/W3008896913",
    "https://openalex.org/W2164411961",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W1996118086",
    "https://openalex.org/W2896687685",
    "https://openalex.org/W2971002550",
    "https://openalex.org/W4287755806",
    "https://openalex.org/W3034408878",
    "https://openalex.org/W3014773921",
    "https://openalex.org/W2952409498",
    "https://openalex.org/W2978017171",
    "https://openalex.org/W1503398984",
    "https://openalex.org/W2947526163",
    "https://openalex.org/W3034630076",
    "https://openalex.org/W2970971581",
    "https://openalex.org/W2949137610",
    "https://openalex.org/W2904981516",
    "https://openalex.org/W2952053192",
    "https://openalex.org/W2986193249",
    "https://openalex.org/W2963215553",
    "https://openalex.org/W2951883849"
  ],
  "abstract": "Real-life applications, heavily relying on machine learning, such as dialog systems, demand for out-of-domain detection methods. Intent classification models should be equipped with a mechanism to distinguish seen intents from unseen ones so that the dialog agent is capable of rejecting the latter and avoiding undesired behavior. However, despite increasing attention paid to the task, the best practices for out-of-domain intent detection have not yet been fully established. This paper conducts a thorough comparison of out-of-domain intent detection methods. We prioritize the methods, not requiring access to out-of-domain data during training, gathering of which is extremely time- and labor-consuming due to lexical and stylistic variation of user utterances. We evaluate multiple contextual encoders and methods, proven to be efficient, on three common datasets for intent classification, expanded with out-of-domain utterances. Our main findings show that fine-tuning Transformer-based encoders on in-domain data leads to superior results. Mahalanobis distance, together with utterance representations, derived from Transformer-based encoders, outperform other methods by a wide margin(1-5% in terms of AUROC) and establish new state-of-the-art results for all datasets. The broader analysis shows that the reason for success lies in the fact that the fine-tuned Transformer is capable of constructing homogeneous representations of in-domain utterances, revealing geometrical disparity to out of domain utterances. In turn, the Mahalanobis distance captures this disparity easily.",
  "full_text": "Revisiting Mahalanobis Distance for\nTransformer-Based Out-of-Domain Detection\nAlexander Podolskiy1, Dmitry Lipin1, Andrey Bout1,\nEkaterina Artemova1, 2, Irina Piontkovskaya1\n1 Huawei Noah’s Ark Lab, Moscow, Russia\n2 HSE University, Moscow, Russia\nfpodolskiy.alexander, dmitry.lipin, bout.andrey, artemova.ekaterina, piontkovskaya.irinag@huawei.com\nAbstract\nReal-life applications, heavily relying on machine lear-\nning, such as dialog systems, demand out-of-domain\ndetection methods. Intent classiﬁcation models should\nbe equipped with a mechanism to distinguish seen in-\ntents from unseen ones so that the dialog agent is ca-\npable of rejecting the latter and avoiding undesired be-\nhavior. However, despite increasing attention paid to the\ntask, the best practices for out-of-domain intent detec-\ntion have not yet been fully established.\nThis paper conducts a thorough comparison of out-\nof-domain intent detection methods. We prioritize the\nmethods, not requiring access to out-of-domain data\nduring training, gathering of which is extremely time-\nand labor-consuming due to lexical and stylistic vari-\nation of user utterances. We evaluate multiple con-\ntextual encoders and methods, proven to be efﬁcient,\non three standard datasets for intent classiﬁcation, ex-\npanded with out-of-domain utterances. Our main ﬁnd-\nings show that ﬁne-tuning Transformer-based encoders\non in-domain data leads to superior results. Maha-\nlanobis distance, together with utterance representa-\ntions, derived from Transformer-based encoders, out-\nperforms other methods by a wide margin (1-5% in\nterms of AUROC) and establishes new state-of-the-art\nresults for all datasets.\nThe broader analysis shows that the reason for success\nlies in the fact that the ﬁne-tuned Transformer is ca-\npable of constructing homogeneous representations of\nin-domain utterances, revealing geometrical disparity to\nout of domain utterances. In turn, the Mahalanobis dis-\ntance captures this disparity easily.\nIntroduction\nThe usability of dialog systems depends crucially on the ca-\npability of dialog agents to recognize user intents. Recently\ndeep classiﬁers have been widely used to recognize user in-\ntents, leveraging efﬁcient pre-training, and large amounts\nof labeled data. However, the scope of annotated corpora\nis inherently limited, leading to unsatisfactory results when\npresented with unseen intents. Rather than trying to match\nuser utterances to a limited number of intent classes, dia-\nlog agents may be equipped with an auxiliary mechanism to\nCopyright c\r 2021, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\ndistinguish between seen and unseen intents, i.e., to identify\nout-of-domain (OOD) utterances. The OOD detection mech-\nanism must handle unseen intents to prevent the erroneous\nactions of dialog agents.\nMultiple recent papers emphasize the increasing impor-\ntance of OOD utterances detection caused by the spreading\nintegration of classiﬁcation models to real-life applications\nand dialog systems. Simultaneously, in the overwhelming\nmajority of papers, the task is approached in an unsupervised\nway, see (Gangal et al. 2020; Larson et al. 2019; Zheng,\nChen, and Huang 2020). To this end, the primary approach\nrelies on a decision rule, which is deﬁned to score each utter-\nance. The scores are further used to reject OOD utterances\nor to subject to further processing in-domain (ID) ones. An\nintuitive yet efﬁcient decision rule determines a threshold\nfor softmax output probabilities, measuring the classiﬁer’s\nconﬁdence. The less conﬁdent the classiﬁer is, the higher are\nthe chances to reject the utterance. Other decision rules rely\non distance-based approaches to check whether an utterance\nfalls out of ID space.\nWith Transformer-based contextual encoders becoming\ncore to almost, if not all, Natural Language Processing\n(NLP) methods, undoubtedly, their performance for intent\nclassiﬁcation is well-studied. However, the performance of\nTransformers in the OOD detection task so far has been lit-\ntle explored. Hendrycks et al. (2020) provide evidence that\nTransformers generalize well to unseen domains in senti-\nment classiﬁcation and sentence pair modeling tasks, sug-\ngesting that Transformers will perform better than previous\nmodels for the task of OOD utterance detection, too. This\npaper ﬁlls this gap in the evaluation of Transformers.\nThe key idea of this paper is to conduct a comprehensive\ncomparison of the performance of different contextual en-\ncoders in multiple settings. We adopt three dialog datasets\ndesigned for the task of OOD intent detection along with\nthe current best practices and state-of-the-art methods for\nthe task. Although Transformers primarily outperform other\ncontextual encoders by a wide margin, they serve as espe-\ncially useful embedders for the distance-based methods of\nOOD detection. When ﬁne-tuned on ID data, Transformers\nform dense clusters of ID utterances, which are easy to lo-\ncate with Mahalanobis distance.\nTo summarize, the key contributions of the paper are as\nfollows:\nTheThi rty-Fi fth AAA ICon ferenceon A rti fi ci al Intellig ence(AAAI-21)\n13675\n1. We evaluate multiple contextual encoders and best\npractices for OOD detection on three common datasets\nfor intent classiﬁcation, expanded with out-of-domain\nutterances;\n2. We show that not only ﬁne-tuning Transformers on ID\ndata consistently improves OOD detection, but also that\nwhen combined with Mahalanobis distance, it estab-\nlished new state-of-the-art results;\n3. We discover that the ﬁne-tuned Transformer is capable\nof constructing homogeneous representations of ID ut-\nterances, revealing geometrical disparity to OOD ones,\ncaptured easily in turn by the Mahalanobis distance.\nRelated Work\nMethods for OOD detection can be roughly grouped based\non whether they have access to OOD data and whether they\nutilize ID labels.\nClassiﬁcation methods require access to OOD data for\nsupervision. Larson et al. (2019) use two supervised set-\ntings: 1) binary classiﬁcation, so that all ID classes are clas-\nsiﬁed against OOD one, and 2) training an additional class\nfor OOD inputs. (Kamath, Jia, and Liang 2020) train an\nadditional model, a calibrator, which identiﬁes inputs on\nwhich the classiﬁer errs, and rejects those inputs, for which\nan error is likely. (Hendrycks, Mazeika, and Dietterich 2018)\nutilize OOD data for outlier detection by training models to\nincrease entropy on OOD examples.\nHowever, in real-life applications gathering and maintain-\ning OOD data is complicated by the lexical and stylistic vari-\nation of user utterances (Schuster et al. 2019). For this rea-\nson, methods without OOD supervision gain more attention.\nOutputs of the classiﬁer, trained with the supervision of\nID classes, can be exploited as a score for OOD inputs. Max-\nimum softmax probability (Hendrycks and Gimpel 2017) is\nrecognized as a strong baseline, when used with deep clas-\nsiﬁers, improved further by introducing temperature scaling\n(Liang, Li, and Srikant 2018). KL-divergence captures the\nchanges in prediction distributions learned for an ID class\nby the classiﬁer and detects the arbitrary guesses made for\nOOD inputs (Yilmaz and Toraman 2020).\nGenerative methods use a natural ability of language\nmodels and other generative models to estimate the likeli-\nhood of the inputs (Nalisnick et al. 2018; Ren et al. 2019).\n(Zheng, Chen, and Huang 2020) utilize ID inputs and unla-\nbeled data to generate pseudo-OOD utterances with a gen-\nerative adversarial network, improving OOD detection on a\ndialog dataset.\nDistance-based methods treat distance estimation as an\nOOD score: the further an input is from ID inputs, the higher\nare the chances that it is OOD (Mandelbaum and Weinshall\n2017; Gu, Akoglu, and Rinaldo 2019; Lee et al. 2018).\nOther research direction includeBayesian estimation for\nuncertanity derived from learned distributions over network\nweights (Malinin and Gales 2018; Blundell et al. 2015), pro-\ncessing of lexical features (Ghosal et al. 2018) and training\nprototypical networks to deﬁne class prototypes for each ID\nclass (Tan et al. 2019).\nBackground\nLet DID = f(x1;y1);:::; (xn;yn)gbe a dataset, where xi is an\ninput utterance and yi 2¡ is its class label. Than ¡ is the set\nof seen, in-domain classes, and the total number of classes\nis j¡j= N. Assume that ID utterances are drawn from the\ndistribution PID and that there exists an OOD distribution,\nPOOD, which differs fromPID. Finally, suppose that a scoring\nfunction maps an utterance x into a real number. The OOD\ndetector then accepts the ID utterances and rejects the OOD\nutterances according to the decision rule in Eq. 1.\nR(x) =\n\u001areject; if d(x) \u0015q\naccept; otherwise (1)\nwhere q is a threshold, d can be either independent from\ny, otherwise model joint d(x;y) or conditional d(xjy) de-\npendence. Ideally, we want d(x) < d(ˆx) for all x \u0018PIN ,\nˆx \u0018POOD.\nMethods\nWe adopt several methods that do not rely on access to OOD\ndata and are shown to be effective for OOD detection in vi-\nsion and natural language tasks. We exploit Maximum Soft-\nmax Probability (MSP) as a strong baseline (Hendrycks and\nGimpel 2017), Likelihood ratio (Gangal et al. 2020) as the\ncurrent state-of-the-art method for dialog data. We use Ma-\nhalanobis distance (De Maesschalck, Jouan-Rimbaud, and\nMassart 2000), an advanced distance-based method, com-\nputed in multiple ways. It is the most straightforward to\ncompute the Mahalanobis distance to the closest ID classes,\nassuming that the ID labels are provided. If not, marginal\nMahalanobis distance allows computing the distance to the\nID data centroid.\nMaximum Softmax Probability (MSP) requires a pre-\ntrained classiﬁer f with a softmax output layer (Hendrycks\nand Gimpel 2017). Let py(x) denote the probability, as-\nsigned by f , to the utterance x to belong to class y. The less\nclassiﬁer is conﬁdent with its prediction, the higher is the\nOOD score:\nd(x) =1 \u0000max\ny2¡\npy(x): (2)\nTo prevent the classiﬁer from becoming too conﬁdent in\nits prediction, (Liang, Li, and Srikant 2018) introduce soft-\nmax temperature scaling at the test time:py(x) =e\nzy\nt = å\ny2¡\ne\nzy\nt\n, where zy denotes the logit for label y while t denotes the\nsoftmax temperature.\nLikelihood Ratio (LLR) exploits two language models\n(Gangal et al. 2020). One of them, L(x), is trained on source\ndata and aims to capture ID utterances’ semantics. The sec-\nond language model, Lbg, addressed as a background model,\nis trained on corrupted with some noise source data and\naimed at learning the background statistics. The ﬁnal score\nis computed as follows in Eg. 3.\nd(x) =\u0000log L(x)\nLbg(x); (3)\nMahalanobis distance is a way to determine the close-\nness of an utterance to a set of utterances belonging to the\n13676\nclass c. Following (Lee et al. 2018), we deﬁne Mahalanobis\ndistance, serving as OOD score, as:\nd(x) =min\nc2¡\n(y(x)\u0000mc)T S\u00001(y(x)\u0000mc); (4)\nwhere y(x) is a vector representation of the utterance x, mc\nis the centroid for a class c and S is the co-variance matrix.\nThe estimations of mc and S are deﬁned by\nmc = 1\nNc\nå\nx2Dc\nin\ny(x);\nS = 1\nN å\nc2¡\nå\nx2Dc\nin\n(y(x)\u0000mc)(y(x)\u0000mc)T ;\nwhere Dc\nIN = fxj(x;y) 2Din; y = cg, N is the total number\nof utterances, and Nc is the number of utterances belonging\nto class c.\nDatasets\nTo the best of our knowledge, we are the ﬁrst to evaluate\nOOD detection with three NLU datasets, consisting of both\nID and OOD utterances.\nCLINC150 is an intent classiﬁcation dataset, modeling a\nreal-life situation. Some utterances fall out of domains, cov-\nered by train data (Larson et al. 2019). The total number of\nID classes in CLINC150 is equal to 150. The OOD utter-\nances relate to actions not supported by existing ID intents.\nROSTD extends the English part of multilingual dialog\ndataset with OOD utterances (Schuster et al. 2019; Gangal\net al. 2020). The hierarchical label structure of ROSTD al-\nlows us to experiment with both a larger number of classes\n(12) or “coarsened” classes (3). Following (Gangal et al.\n2020), we experiment with both variants and refer to them\nas ROSTD and ROSTD-COARSE. The OOD part consists\nmainly of subjective, under-speciﬁed, or over-emotional ut-\nterances that do not fall into ID classes.\nSNIPS has no explicit ID/OOD split. The total number\nof intents is 7. Following (Lin and Xu 2019) setup, we ran-\ndomly split all labels into ID and OOD parts. The ID part\ncovers about 75% of the whole dataset. We average the re-\nsults of all splits.\nTable 1 presents with dataset statistics.\nEmbeddings and Encoders\nWe evaluate three representation models, ranging from bag-\nof-words, static pre-trained word embeddings up to contex-\ntualized encoders.\nCLINC150 ROSTD SNIPS\nNumber train IND 15K 30K 13K\nNumber val IND 3K 4K 0.7K\nNumber val OOD 0.1K 1.5K –\nNumber test IND 4.5K 8.6K 0.7K\nNumber test OOD 1K 3K –\nTable 1: Dataset statistics\nBag-of-words. We use the bag-of-words model (Harris\n1954), which shows stable performance due to its low vari-\nance.\nStatic word embeddings. We use GloVe (Pennington,\nSocher, and Manning 2014) as inputs to a convolutional neu-\nral network (CNN) and long short-term memory (LSTM),\ntrained further with the supervision of ID data. The CNN\narchitecture follows one used in (Zheng, Chen, and Huang\n2020). We use GloVe vectors as inputs to language models\nneeded for LLR. LSTM is used as an underlying model of\nLLR, trained on ID data with language modeling objective.\nWe train the background model on the ID data with added\nuniform noise. We ﬁnd that 0.5 noise probability performs\nthe best.\nPre-trained Transformers. We utilize multiple BERT-\nbased models (Devlin et al. 2019), which are pre-trained\nTransformers, trained with a self-supervised masked lan-\nguage modeling objective. Additionally to BERT-base and\nBERT-large, we use RoBERTa-base and RoBERTa-large\nmodels (Liu et al. 2019). We use distilled versions of both\nBERT and RoBERTa, DistillBERT and DistillRoBERTa\n(Sanh et al. 2019).\nEach CNN, LSTM, and Transformer model is used as a\nclassiﬁer with the MSP method and as an embedder with\nMahalanobis distance. We follow the standard ﬁne-tuning\nprocedure to ﬁne-tune each model for three ID intent clas-\nsiﬁcation tasks. We tune hyper-parameters to maximize per-\nformance on the validation set for each of the ID intent clas-\nsiﬁcation tasks. We perform our experiments with PyTorch1,\nPyTorch Lightning and Hugging Face Transformers library\n(Wolf et al. 2019).\nEvaluation\nThe task of OOD detection is a binary classiﬁcation task,\nwhere OOD utterances should be distinguished from ID ut-\nterances. In the unsupervised setting, a scoring function is\nused to assign an OOD score.\nAUROC, the area under the Receiver Operating Charac-\nteristic, can be interpreted as the probability of randomly\nsampled ID utterance having a lower OOD score than ran-\ndomly sampled OOD one.\nAUPROOD, the area under Precision-Recall Curve, re-\nquires taking OOD as the positive class. It is more suitable\nfor highly imbalanced data in comparison to AUROC.\nFPR@X corresponds to False Positive Ratio with the de-\ncision threshold is set to q = supf˜q 2R jTPR( ˜q) \u0014Xg\nwhere TPR 2[0;1] is a True Positive Rate. This metric also\nrequires selecting one class as positive. Different approaches\nare used, e.g. Gangal, Arora, Einolghozati, and Gupta (2020)\ntreat the OOD class as positive one, while Zheng, Chen,\nand Huang (2020) choose ID class. We report both metrics:\nFPR@XID means that ID class is treated as positive, and\nFPR@XOOD means the same for OOD class.\nTwo metrics, AUROC and AUPR OOD are threshold-\nindependent. FPR@X requires picking a threshold.\n1PyTorch version 1.4.0, PyTorch Lightning version 0.7.5, Hug-\nging Face Transformers version 2.8.0\n13677\nDataset Model AUROC \" AUPROOD \" FPR@95OOD # FPR@95ID #\nCLINC150\nBoW MSP 91:5 \u00060:0 66:7 \u00060:2 31:7 \u00060:4 43:9 \u00060:9\nLSTM MSP 90:9 \u00060:6 67:8 \u00062:1 31:2 \u00062:0 50:7 \u00063:0\nCNN MSP 94:1 \u00060:6 80:8 \u00062:1 26:4 \u00064:0 24:4 \u00062:8\nCNN Maha 95:2 \u00060:2 76:2 \u00061:4 16:4 \u00061:1 27:8 \u00061:6\nLLR 91:4 \u00060:3 73:1 \u00061:0 37:0 \u00061:5 39:9 \u00061:5\nBERTbase Maha 97:3 \u00060:1 88:6 \u00061:0 10:9 \u00060:7 12:5 \u00061:1\nBERTbase SNGP1 96:9 \u00061:0 88:0 \u00061:0 – –\nRoBERTa MSP 97:1 \u00060:6 91:2 \u00061:3 11:6 \u00062:4 12:5 \u00062:2\nRoBERTa Maha 98:4\u00060:1 94 :5\u00060:5 6: 8\u00060:8 7: 3\u00061:1\nROSTD\nBoW MSP 94:2 \u00060:1 86:7 \u00060:1 30:5 \u00060:4 25:8 \u00060:2\nLSTM MSP 73:7 \u00068:3 60:6 \u000612:1 63:0 \u00066:0 57:4 \u000613:8\nCNN MSP 95:2 \u00061:2 88:2 \u00062:8 22:2 \u00066:3 32:5 \u00066:0\nCNN Maha 98:1 \u00060:2 93:3 \u00060:7 7:6 \u00061:5 7:8 \u00061:3\nLLR 97:7 \u00060:2 95:6 \u00060:3 12:3 \u00061:7 9:3 \u00061:0\nRoBERTa MSP 99:3 \u00060:2 98:2 \u00060:4 2:2 \u00060:8 1:8 \u00060:9\nRoBERTa Maha 99:8\u00060:1 99 :5\u00060:3 0: 5\u00060:4 1: 0\u00060:5\nROSTD-coarse\nBoW MSP 98:0 \u00060:1 96:0 \u00060:1 7:8 \u00060:7 6:6 \u00060:2\nLSTM MSP 86:3 \u00067:8 80:2 \u000610:6 52:7 \u000613:5 32:0 \u000615:3\nCNN MSP 97:0 \u00060:8 94:7 \u00061:3 19:8 \u00068:1 10:4 \u00062:7\nCNN Maha 99:0 \u00060:2 97:5 \u00060:4 4:5 \u00061:1 4:6 \u00060:8\nLLR 97:7 \u00060:2 95:5 \u00060:4 12:5 \u00061:4 9:1 \u00060:9\nRoBERTa MSP 99:2 \u00060:5 98:8 \u00060:5 0:6 \u00060:5 1:7 \u00060:9\nRoBERTa Maha 99:8\u00060:1 99:6 \u00060:1 0: 2\u00060:1 0: 7\u00060:4\nSNIPS 75\nBoW MSP 92:4 \u00062:0 76:9 \u00066:8 30:7 \u00064:3 41:6 \u00066:3\nLSTM MSP 81:7 \u000610:9 59:6 \u000615:3 49:9 \u000624:7 59:0 \u000615:3\nCNN MSP 93:7 \u00062:3 78:7 \u00069:1 24:4 \u00069:1 20:2 \u00068:8\nCNN Maha 87:1 \u00069:4 75:4 \u000612:6 49:3 \u000633:6 37:8 \u000618:7\nLLR 83:5 \u00065:2 61:3 \u000612:9 65:1 \u000616:0 58:1 \u00069:0\nRoBERTa MSP 95:3 \u00062:8 85:7 \u00065:6 25:5 \u000622:3 18:2 \u00069:1\nRoBERTa Maha 97:6\u00061:9 92 :9\u00065:4 12: 3\u000610:3 11:2 \u000610:5\nTable 2: Comparison of OOD detection performance. Each result is an average of 10 runs. \"– greater\nis better, #– lower is better\nOut-of-Domain Detection\nTransformers With Mahalanobis Distance are\nBetter at OOD Detection Than Other Models\nTable 2 presents with the results of experiments. On all\ndatasets, RoBERTa equipped with the Mahalanobis dis-\ntance outperforms baselines, and other methods, including\nRoBERTa with the MSP score. Advantages are even more\nevident for CLINC150, which is less lexically and syntacti-\ncally diverse and challenging.\nOn the CLINC150 dataset, Mahalanbois distance com-\nbined with Transformer-based embeddings outperforms re-\ncently proposed BERT SNGP (Spectral-normalized Neural\nGaussian) (Liu et al. 2020). In order to make a fair compar-\nison, we show the performance of the BERTbase Maha.\nLSTM with MSP performs at the baseline level and is\noutperformed with CNN with MSP, followed by the previ-\nously established state-of-the-art method, LLR (Gangal et al.\n2020). In turn, it does not cope well with CLINC150 and\n1Results are adopted from (Liu et al. 2020)\nSNIPS and is slightly outperformed by CNN with Maha-\nlanobis distance. LLR might be challenging to apply, as the\nbackground model can still learn semantics from the data,\neven though it is trained on the noisy inputs. There is a high\nvariance in the background model training due to the exten-\nsive vocabulary size.\nThe Mahalanobis distance and its variants depend pri-\nmarily on the embeddings learned by a model. All mod-\nels equipped with MSP were ﬁne-tuned using cross-entropy\nloss for intent classiﬁcation. The Table 2 conﬁrms that such\nﬁne-tuning does not always help the models generate infor-\nmative embeddings. CNN with the Mahalanobis distance\nshows moderate performance on the ROSTD dataset and\nits coarse version. However, performance severely drops on\nmore challenging datasets.\nSemantically Close ID and OOD Classes are Often\nConfused\nRoBERTa with the Mahalanobis distance score is affected\nby multiple factors, such as annotation issues and confusion\n13678\nRoBERTa CNN\nCLINC150 ROSTD SNIPS CLINC150 ROSTD SNIPS\nPairwise similarity\nbetween centroids 0 \u00060:08 \u00000:05 \u00060:13 \u00000:16 \u00060:12 0:35 \u00060:11 0:24 \u00060:09 0:15 \u00060:02\nCentroid length 19:75 \u00060:23 18:09 \u00060:36 18:57 \u00060:64 23:07 \u00061:38 19:12 \u00061:11 18:29 \u00061:08\nSimilarity between ID\ninstances and centroids 0:96 \u00060:11 0 :95 \u00060:08 0:98 \u00060:04 0 :92 \u00060:08 0:96 \u00060:44 0:99 \u00060:05\nTable 3: Descriptive statistics of embedding space. Both spaces are derived from ﬁne-tuned models with ID supervision. We\nshow statistics for only one of the SNIPS splits\nFigure 1: t-SNE visualization of CLINC150 ID classes. Em-\nbeddings are derived from ﬁne-tuned RoBERTa for ID clas-\nsiﬁcation. ID classes are easily separated\nbetween semantically related utterances.\nMislabeled instances cause top errors made for\nCLINC150, e.g. give me the weather forecast for to-\nday is labeled as OOD but is related to the intent weather.\nSimilarly, an OOD utterance how old is Jennifer Anniston?\nis incorrectly assigned with the intent how old are you?,\nused to question about the dialog agent’s personality.\nOther errors include confusion between semantically re-\nlated utterances. For example, CLINC150 contains intent\ntext that is related only to sending a text message. Utter-\nances related to similar actions, such asread my friend’s text\nmessage, are erroneously accepted.\nSimilar issues appear in SNIPS. The structure of ID-OOD\nsplits explains the high variance of metrics. If two semanti-\ncally related or often confused intents get into different sets,\nthe resulting measures drop signiﬁcantly. For example, it\nis challenging if the intent SearchScreenEvent is ID and\nSearchCreativeWorkis OOD. The rest of the ID intents do\nnot provide enough supervision to learn the former intent’s\nexact semantics to more clearly separate from the latter.\nOn the ROSTD dataset, we observe the same errors\ncaused by the semantic similarity between an OOD utter-\nance and ID intents. Another source of errors is the lexical\ndiscrepancy between ID utterances in the train and test sets.\nIs Bigger Model Better?\nWe utilize base, large, and distilled versions of BERT-based\nmodels. Fig. 2 compares the performance of models with\ndifferent sizes on two datasets, CLINC150 and ROSTD. On\na more diverse dataset, CLINC150, we see that larger mod-\n&/,1&\u0014\u0018\u0013 5267'\n\u0013\u0011\u001b\u0018\n\u0013\u0011\u001c\n\u0013\u0011\u001c\u0018\n\u0013\u0011\u001c\u001c\n\u0014\u0011\u0003%(57\u0003EDVH\u0003 \u0003063 \u0015\u0011\u0003%(57\u0003EDVH\u0003 \u00030DKD\n\u0016\u0011\u0003%(57\u0003ODUJH\u0003 \u0003063 \u0017\u0011\u0003%(57\u0003ODUJH\u0003 \u00030DKD\n\u0018\u0011\u0003'LVWLO%(57\u0003063 \u0019\u0011\u0003'LVWLO%(57\u00030DKD\n\u001a\u0011\u0003'LVWLO5R%(57 D\u0003063 \u001b\u0011\u0003'LVWLO5R%(57 D\u00030DKD\n\u001c\u0011\u00035R%(57 D\u0003EDVH\u0003 \u0003063 \u0014\u0013\u0011\u00035R%(57 D\u0003EDVH\u0003 \u00030DKD\n\u0014\u0014\u0011\u00035R%(57 D\u0003ODUJH\u0003 \u0003063 \u0014\u0015\u0011\u00035R%(57 D\u0003ODUJH\u0003 \u00030DKD\n$835\u0003RRG\u0003\n\u0014 \u0014\u0015 \u0015\u0016 \u0016\u0017 \u0017\u0018 \u0018\u0019 \u0019\u001a \u001a\u001b \u001b\u001c \u001c\u0014\u0013 \u0014\u0013\u0014\u0014 \u0014\u0014\u0014\u0015 \u0014\u0015\nFigure 2: Comparison of models of different sizes on\nROSTD and CLINC150. Maha stands for Mahalanobis dis-\ntance\nels outperform smaller versions. On the ROSTD dataset, this\ndifference is not so prominent but persists. By comparing\ndistilled versions with their respective teachers, we note that\nthe distillation does not affect the Mahalanobis distance, un-\nlike the MSP score. Hence, Mahalanobis distance is more\nrobust to distillation than MSP.\nDiverse Pre-Training Data Improves OOD\nDetection\nFig. 2 shows that RoBERTa has better OOD detection ca-\npabilities than BERT. The core difference between the two\nmodels is that RoBERTa was pre-trained on a larger and\nmore diverse dataset than BERT. Thus, we hypothesize that\npre-training on larger amounts of data improves model ro-\nbustness to OOD instances. Recent studies conﬁrm this ef-\nfect in computer vision (Hendrycks, Lee, and Mazeika 2019;\nOrhan 2019) and natural language processing (Hendrycks\net al. 2020).\nFeatures of Embeddings Space\nTransformer models, ﬁne-tuned on ID data, coupled with\nMahalanobis distance, show excellent performance for OOD\ndetection. A possible explanation could be the way the space\nof Transformer-based embeddings is settled. Further, we\ncompare geometrical features of two different embedding\nspaces, derived from RoBERTa model and CNN for com-\n13679\n(a) RoBERTa, no ﬁne-tuning\n (b) RoBERTa, ﬁne-tuned\n (c) CNN, trained\nFigure 3: These heatmaps represent each utterance from the CLINC150 test set as the vector of Mahalanobis distance terms,\ncomputed according to Eq. 5 and sorted in the decreasing order of explained variance. Each row stands for an utterance. The\nhorizontal solid line separates the OOD utterances (above the line) from the ID ones (below the line). The vertical solid line\nsplits each heatmap into two parts: to the left are components numbered lower than 150, to the right are components numbered\nabove 150. 150 is the number of classes in the CLINC150 dataset. Only ﬁne-tuned RoBERTa-based vectors clearly distinguish\nID and OOD utterances. The difference between ID and OOD is less evident in (c) and almost indistinguishable in (a). However,\nin (b), the values of the components, starting from the 150th one (in yellow), are lower than those of ID ones (in red).\nparison (see Table 3). The differences between the spaces\nare even sharper if the number of ID classes is high.\nID class centroids are mutually orthogonal. The pair-\nwise cosine similarity between centroids approaches zero\nas its mean value and standard deviation are close to zero.\nThis reveals that the centroids are mutually orthogonal, as\nall angles are close to p\n2 . This phenomenon is present for the\nspace of Transformer-based embeddings and does not hold\nfor CNN-based embeddings.\nID class centroids lay on a sphere. The length of\nTransformer-based centroids does not vary much, as the de-\nviation from the sphere is less than 2% of its radius. On the\nother hand, CNN embeddings deviate more signiﬁcantly.\nID classes form clusters around centroids. The devia-\ntion of ID instances from the centroids according to cosine\nsimilarity is small both for CNN and RoBERTa embeddings.\nID data is well clustered, and the classes are well separated\nfrom each other, as depicted in Fig. 1.\nID data can be approximated by low-dimensional sub-\nspace in the embedding space, because ID embeddings are\nclose to class centroids, and the number of classes is signiﬁ-\ncantly lower than the dimension of the embeddings (N\u001cd).\nFor further analysis, we consider several Mahalanobis dis-\ntance variants. Following Kamoi and Kobayashi (2020), we\nintroduce the equivalent Mahalanobis distance form, based\non Principal Component Analysis of the class-wise centered\nID data:\nd(y(x)) =min\nc\nd\nå\ni=1\ny2\ni (y(x)\u0000mc)\nli\n; (5)\nwhere yi(y(x)) is the i-th component of the PCA trans-\nform of y(x), li are explained variances of the correspond-\ning principal components, mc are class centroids.\nKamoi and Kobayashi (2020) introduced two modiﬁca-\ntions of Eq. 5, namely, marginal Mahalanobis distance,\nwhich ignores class information and uses instead a single\nmean vector for all ID classes, (see Eq. 6) and partial Ma-\nhalanobis distances: it is the version of the equations (5)\nand (6) with the summation starting from N-th component.\nEq. 7 corresponds to the partial marginal variant. Marginal\nMahalanobis distance aims at using more compact data rep-\nresentation in the form of a single ID centroid, helping to\nreduce the amount of data needed for OOD detection. Par-\ntial variant utilizes the most important terms only.\nd(y(x)) =\nd\nå\ni=1\ny2\ni (y(x)\u0000m)\nli\n(6)\nd(y(x);N) =\nd\nå\ni=N\ny2\ni (y(x)\u0000m)\nli\n; (7)\nwhere\nm = 1\nN å\nx2Din\ny(x);\nstands for the ID data centroid.\nMahalanobis distance can efﬁciently utilize low-\ndimensional nature of ID data. Following the properties\nof PCA (Murphy 2012), if the data is approximately N-\ndimensional, it is explained by the ﬁrst N principal compo-\nnents. That means that for ID data, all the terms in the Eq.\n6, 7 are little, while OOD data can be detected by important\nloadings of the terms y2\ni\nli\nwith i > N. To check this, we plot\nthe terms of the Eq. 7 for ID and OOD data, Fig. 3. Fig. 3\nshows that when decomposed with the Mahalanobis distance\nembeddings of ﬁne-tuned RoBERTa fall into two parts. The\nlast components of OOD embeddings have a higher vari-\nance when compared to the ﬁrst ones. This phenomena is\nobserved neither for ID embeddings nor for RoBERTa with-\nout ﬁne-tuning nor for the trained CNN.\nComparison of Other Distances\nWe compare Mahalanobis distance variants to explore this\nmatter: original, marginal Mahalanobis, and their partial ver-\nsions. Additionally, we exploit Euclidean distance to com-\nplete our evaluation.\n13680\n&/,1&\u0014\u0018\u0013 61,36B\u001a\u0018\u0003\u000bVSOLW\u0003\u0018\f\n\u0013\u0011\u001b\n\u0013\u0011\u001b\u0018\n\u0013\u0011\u001c\n\u0013\u0011\u001c\u0018\n\u0013\u0011\u001c\u001c\n\u0014\u0011\u0003(XFOLGHDQ \u0015\u0011\u00030DKD \u0016\u0011\u00030DUJLQDO\u00030DKD\n\u0017\u0011\u00033DUWLDO\u00030DKD \u0018\u0011\u00033DUWLDO\u00030DUJLQDO\u00030DKD\n$835\u0003RRG\u0003\n\u0014 \u0014\u0015 \u0015\u0016 \u0016\u0017 \u0017\u0018 \u0018\nFigure 4: Comparison of different distances. Mahalanobis\ndistance and its variants outperform Euclidean distance by a\nwide margin.\n10 25 50 100\n0.86\n0.88\n0.9\n0.92\n0.94\nMSP Maha Marginal Maha Partial Maha\nPartial Marginal Maha\nPercent of the training data\nAUPR ood \nFigure 5: OX: fraction of train data used, CLINC150, OY:\nperformance of OOD detection score. Mahalanobis distance\nand its variants need less data for OOD detection.\nAll Mahalanobis distance variants outperform Euclidean\ndistance by far; see Fig. 4. Euclidean distance does not\ntake the correlation between features into account. Although\nthere is little difference between Mahalanobis distance vari-\nants, partial and marginal variants are more stable when\nvarying training data size. Marginal Mahalanobis distance\nis less affected by the reduction of training data; see 5.\nConclusion\nOut-of-Domain (OOD) detection task is becoming core to\nmodern dialog systems. Successful detection and rejection\nof OOD utterances in real-life applications increase the dia-\nlog assistant’s credibility and improves user experience. This\npaper compared multiple techniques for unsupervised OOD\ndetection, applied to three commonly used NLU datasets, in\nparticular, CLINC150, ROSTD, and SNIPS. We exploited\ndifferent text representation models, ranging from the old-\nfashioned bag-of-word modes to the most recent pre-trained\nTransformers. We adopted best practices used in the vision\ndomain and previously established state-of-the-art methods\nwithin the scope of unsupervised methods, namely, Max-\nimum Softmax Probability, Likelihood Ratio, and Maha-\nlanobis distance, along with its modiﬁcations.\nWith the help of Transformer-based models, equipped\nwith Mahalanobis distance, we establish new state-of-the-art\nresults. To that end, we show that ﬁne-tuning with ID data’s\nsupervision plays a crucial role, allowing re-shaping, favor-\nable for the task, of the embedding space. These results are\nsupported in line with (Reimers and Gurevych 2019), con-\nﬁrming that ﬁne-tuning Transformers improves the perfor-\nmance of the downstream unsupervised tasks. What is more,\nthe proposed pipeline, i.e., ﬁne-tuning a Transformer and us-\ning Mahalanobis distance, is robust to distillation. Support-\ning smaller models is essential for edge devices, where dis-\ntilled models are usually deployed. Reduced in size, distilled\nversions of pre-trained Transformers models perform on par\nwith the full-size models. Mahalanobis distance remains sta-\nble, even when used with a distilled model.\nStill, there are some limitations to the Mahalanobis OOD\nscore. In the ﬁrst place, it depends on the geometrical fea-\ntures of the embedding space, which could be spoilt if, for\nexample, the embedder is used simultaneously as a classiﬁ-\ncation model and happens to overﬁt. Secondly, the greatest\nchallenge is caused by semantically similar utterances, of\nwhich one is ID, and the other is OOD. For example, this\ncan happen if the dialog assistant supports only one of two\nrelated actions. Future research directions should consider\nsuch cases and the trade-off between the accuracy of intents\nclassiﬁcation and OOD detection performance.\nAcknowledgments\nEkaterina Artemova is partially supported by the framework\nof the HSE University Basic Research Program.\nReferences\nBlundell, C.; Cornebise, J.; Kavukcuoglu, K.; and Wierstra,\nD. 2015. Weight Uncertainty in Neural Network. In Pro-\nceedings of the International Conference on Machine Learn-\ning, 1613–1622.\nDe Maesschalck, R.; Jouan-Rimbaud, D.; and Massart, D. L.\n2000. The Mahalanobis distance. Chemometrics and intel-\nligent laboratory systems 50(1): 1–18.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\nBERT: Pre-training of Deep Bidirectional Transformers for\nLanguage Understanding. In Proceedings of the Conference\nof North American Chapter of the Association for Compu-\ntational Linguistics: Human Language Technologies, 4171–\n4186.\nGangal, V .; Arora, A.; Einolghozati, A.; and Gupta, S. 2020.\nLikelihood Ratios and Generative Classiﬁers for Unsuper-\nvised Out-of-Domain Detection in Task Oriented Dialog.\nIn Proceedings of the AAAI Conference on Artiﬁcial Intel-\nligence, volume 34, 7764–7771.\nGhosal, T.; Sonam, R.; Saha, S.; Ekbal, A.; and Bhat-\ntacharyya, P. 2018. Investigating domain features for scope\ndetection and classiﬁcation of scientiﬁc articles. In Proceed-\nings of the Eleventh International Conference on Language\nResources and Evaluation, 7–12.\nGu, X.; Akoglu, L.; and Rinaldo, A. 2019. Statistical Anal-\nysis of Nearest Neighbor Methods for Anomaly Detection.\nIn Advances in Neural Information Processing Systems.\n13681\nHarris, Z. S. 1954. Distributional structure. Word 10: 146–\n162.\nHendrycks, D.; and Gimpel, K. 2017. A Baseline for Detect-\ning Misclassiﬁed and Out-of-Distribution Examples in Neu-\nral Networks. In Proceedings of International Conference\non Learning Representations.\nHendrycks, D.; Lee, K.; and Mazeika, M. 2019. Using Pre-\nTraining Can Improve Model Robustness and Uncertainty.\nIn Proceedings of the International Conference on Machine\nLearning, 2712–2721.\nHendrycks, D.; Liu, X.; Wallace, E.; Dziedzic, A.; Krishnan,\nR.; and Song, D. X. 2020. Pretrained Transformers Improve\nOut-of-Distribution Robustness. In Proceedings of the An-\nnual Meeting of the Association for Computational Linguis-\ntics, 2744–2751.\nHendrycks, D.; Mazeika, M.; and Dietterich, T. 2018. Deep\nAnomaly Detection with Outlier Exposure. In Proceedings\nof International Conference on Learning Representations.\nKamath, A.; Jia, R.; and Liang, P. 2020. Selective Ques-\ntion Answering under Domain Shift. In Proceedings of the\nAnnual Meeting of the Association for Computational Lin-\nguistics, 5684–5696.\nKamoi, R.; and Kobayashi, K. 2020. Why is the Maha-\nlanobis Distance Effective for Anomaly Detection? arXiv\npreprint arXiv:2003.00402 .\nLarson, S.; Mahendran, A.; Peper, J. J.; Clarke, C.; Lee, A.;\nHill, P.; Kummerfeld, J. K.; Leach, K.; Laurenzano, M. A.;\nTang, L.; et al. 2019. An Evaluation Dataset for Intent Clas-\nsiﬁcation and Out-of-Scope Prediction. In Proceedings of\nthe Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on\nNatural Language Processing, 1311–1316.\nLee, K.; Lee, K.; Lee, H.; and Shin, J. 2018. A Simple Uni-\nﬁed Framework for Detecting Out-of-Distribution Samples\nand Adversarial Attacks. In Advances in Neural Information\nProcessing Systems.\nLiang, S.; Li, Y .; and Srikant, R. 2018. Enhancing The Re-\nliability of Out-of-distribution Image Detection in Neural\nNetworks. In Proceedings of International Conference on\nLearning Representations.\nLin, T.-E.; and Xu, H. 2019. Deep Unknown Intent Detec-\ntion with Margin Loss. In Proceedings of the Annual Meet-\ning of the Association for Computational Linguistics, 5491–\n5496.\nLiu, J.; Lin, Z.; Padhy, S.; Tran, D.; Bedrax Weiss, T.; and\nLakshminarayanan, B. 2020. Simple and Principled Uncer-\ntainty Estimation with Deterministic Deep Learning via Dis-\ntance Awareness. In Advances in Neural Information Pro-\ncessing Systems, volume 33, 7498–7512.\nLiu, Y .; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;\nLevy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V .\n2019. Roberta: A Robustly Optimized BERT Pre-training\nApproach. arXiv preprint arXiv:1907.11692 .\nMalinin, A.; and Gales, M. 2018. Predictive Uncertainty\nEstimation via Prior Networks. In Advances in Neural In-\nformation Processing Systems, 7047–7058.\nMandelbaum, A.; and Weinshall, D. 2017. Distance-based\nConﬁdence Score for Neural Network Classiﬁers. arXiv\npreprint arXiv:1709.09844 .\nMurphy, K. P. 2012. Machine Learning: A Probabilistic Per-\nspective. The MIT Press .\nNalisnick, E.; Matsukawa, A.; Teh, Y . W.; Gorur, D.; and\nLakshminarayanan, B. 2018. Do Deep Generative Models\nKnow What They Don’t Know? In Proceedings of Interna-\ntional Conference on Learning Representations.\nOrhan, A. E. 2019. Robustness Properties of Facebook’s\nResNeXt WSL models. arXiv preprint arXiv:1907.07640 .\nPennington, J.; Socher, R.; and Manning, C. D. 2014. Glove:\nGlobal vectors for word representation. In Proceedings of\nthe Conference on Empirical Methods in Natural Language\nProcessing, 1532–1543.\nReimers, N.; and Gurevych, I. 2019. Sentence-BERT: Sen-\ntence Embeddings using Siamese BERT-Networks. In Pro-\nceedings of the Conference on Empirical Methods in Nat-\nural Language Processing and the 9th International Joint\nConference on Natural Language Processing, 3973–3983.\nRen, J.; Liu, P. J.; Fertig, E.; Snoek, J.; Poplin, R.; Depristo,\nM.; Dillon, J.; and Lakshminarayanan, B. 2019. Likelihood\nRatios for Out-of-Distribution Detection. In Advances in\nNeural Information Processing Systems, volume 32, 66–77.\nSanh, V .; Debut, L.; Chaumond, J.; and Wolf, T. 2019.\nDistilBERT, a Distilled Version of BERT: Smaller, Faster,\nCheaper and Lighter. arXiv preprint arXiv:1910.01108 .\nSchuster, S.; Gupta, S.; Shah, R.; and Lewis, M. 2019.\nCross-lingual Transfer Learning for Multilingual Task Ori-\nented Dialog. In Proceedings of the Conference of North\nAmerican Chapter of the Association for Computational\nLinguistics: Human Language Technologies, 3795–3805.\nTan, M.; Yu, Y .; Wang, H.; Wang, D.; Potdar, S.; Chang,\nS.; and Yu, M. 2019. Out-of-Domain Detection for Low-\nResource Text Classiﬁcation Tasks. In Proceedings of the\nConference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on\nNatural Language Processing, 3557–3563.\nWolf, T.; Debut, L.; Sanh, V .; Chaumond, J.; Delangue, C.;\nMoi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; et al.\n2019. HuggingFace’s Transformers: State-of-the-art Natural\nLanguage Processing. arXiv preprint arXiv:1910.03771 .\nYilmaz, E. H.; and Toraman, C. 2020. KLOOS: KL\nDivergence-based Out-of-Scope Intent Detection in Human-\nto-Machine Conversations. In Proceedings of the 43rd Inter-\nnational ACM SIGIR Conference on Research and Develop-\nment in Information Retrieval, 2105–2108.\nZheng, Y .; Chen, G.; and Huang, M. 2020. Out-of-domain\ndetection for natural language understanding in dialog sys-\ntems. In IEEE/ACM Transactions on Audio, Speech, and\nLanguage Processing, volume 28, 1198–1209. IEEE.\n13682",
  "topic": "Mahalanobis distance",
  "concepts": [
    {
      "name": "Mahalanobis distance",
      "score": 0.7857513427734375
    },
    {
      "name": "Computer science",
      "score": 0.7544831037521362
    },
    {
      "name": "Transformer",
      "score": 0.6762713193893433
    },
    {
      "name": "Encoder",
      "score": 0.6499078273773193
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5818096995353699
    },
    {
      "name": "Utterance",
      "score": 0.5131357312202454
    },
    {
      "name": "Natural language processing",
      "score": 0.4418077766895294
    },
    {
      "name": "Dialog box",
      "score": 0.4345913529396057
    },
    {
      "name": "Machine learning",
      "score": 0.4223650395870209
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.41786131262779236
    },
    {
      "name": "Margin (machine learning)",
      "score": 0.41526883840560913
    },
    {
      "name": "Speech recognition",
      "score": 0.3863331079483032
    },
    {
      "name": "Mathematics",
      "score": 0.11212858557701111
    },
    {
      "name": "Engineering",
      "score": 0.08699306845664978
    },
    {
      "name": "Voltage",
      "score": 0.07855382561683655
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    },
    {
      "name": "World Wide Web",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I118501908",
      "name": "National Research University Higher School of Economics",
      "country": "RU"
    }
  ],
  "cited_by": 50
}