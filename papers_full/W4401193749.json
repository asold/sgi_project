{
  "title": "AI Content Self-Detection for Transformer-based large Language Models",
  "url": "https://openalex.org/W4401193749",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2329668229",
      "name": "António Caiado",
      "affiliations": [
        "Southern Methodist University"
      ]
    },
    {
      "id": "https://openalex.org/A280853906",
      "name": "Michael Hahsler",
      "affiliations": [
        "Southern Methodist University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2122410182",
    "https://openalex.org/W4393262489",
    "https://openalex.org/W4380352297",
    "https://openalex.org/W4319773014",
    "https://openalex.org/W2969958763",
    "https://openalex.org/W4390175962",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W1959608418",
    "https://openalex.org/W4320013936",
    "https://openalex.org/W2973379954",
    "https://openalex.org/W4377121468",
    "https://openalex.org/W4319991848",
    "https://openalex.org/W4226399820",
    "https://openalex.org/W4367000196",
    "https://openalex.org/W4320014603",
    "https://openalex.org/W3101891351",
    "https://openalex.org/W4317553041",
    "https://openalex.org/W4315498228"
  ],
  "abstract": "<title>Abstract</title> The usage of generative artificial intelligence (AI)tools based on large language models, including ChatGPT, Bard, and Claude, for text generation, has many exciting applications with the potential for phenomenal productivity gains. One issue is authorship attribution when using AI tools. This is especially important in an academic setting where the inappropriate use regenerative AI tools may hinder student learning or stifle research by, creating a large amount of automatically generated derivative work. Existing plagiarism detection systems can trace the source of submitted text but are not yet equipped with methods to accurately detect AI-generated text. This paper introduces the dea of direct origin detection and evaluates whether generative AI systems can recognize their output and distinguish it from human-written texts. We argue why current transformer-based models may be able to self-detect their own generated text and perform a small empirical study using zero-shot learning to investigate if that is the case. Results reveal varying capabilities of AI systems to identify their generated text. Google’s Bard model exhibits the largest capability of self-detection with an accuracy of 94%, followed by OpenAI’s ChatGPT with 83%.On the other hand, Anthropic’s Claude model seems to be not able to self-detect.",
  "full_text": null,
  "topic": "Content (measure theory)",
  "concepts": [
    {
      "name": "Content (measure theory)",
      "score": 0.6140227317810059
    },
    {
      "name": "Transformer",
      "score": 0.5697560906410217
    },
    {
      "name": "Computer science",
      "score": 0.5179663896560669
    },
    {
      "name": "Natural language processing",
      "score": 0.4735153019428253
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3497973382472992
    },
    {
      "name": "Mathematics",
      "score": 0.15927425026893616
    },
    {
      "name": "Engineering",
      "score": 0.11578401923179626
    },
    {
      "name": "Electrical engineering",
      "score": 0.0944986343383789
    },
    {
      "name": "Voltage",
      "score": 0.06004342436790466
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}