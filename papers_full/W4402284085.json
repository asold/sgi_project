{
  "title": "Large language model evaluation for high‐performance computing software development",
  "url": "https://openalex.org/W4402284085",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2250274434",
      "name": "William F. Godoy",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2228957071",
      "name": "Pedro Valero-Lara",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2119740704",
      "name": "Keita Teranishi",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A778918145",
      "name": "Prasanna Balaprakash",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2165234532",
      "name": "Jeffrey S. Vetter",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W1663984431",
    "https://openalex.org/W4317602012",
    "https://openalex.org/W2902076893",
    "https://openalex.org/W4246734931",
    "https://openalex.org/W2120575449",
    "https://openalex.org/W2115733720",
    "https://openalex.org/W3034942609",
    "https://openalex.org/W3095319910",
    "https://openalex.org/W4289792856",
    "https://openalex.org/W4225108562",
    "https://openalex.org/W4285734663",
    "https://openalex.org/W3173383004",
    "https://openalex.org/W4312763760",
    "https://openalex.org/W4283705032",
    "https://openalex.org/W4211263275",
    "https://openalex.org/W4323037544",
    "https://openalex.org/W4324138978",
    "https://openalex.org/W4318817313",
    "https://openalex.org/W4398768423",
    "https://openalex.org/W4388581500",
    "https://openalex.org/W4386269029",
    "https://openalex.org/W4396790347",
    "https://openalex.org/W3081168214",
    "https://openalex.org/W4390188667",
    "https://openalex.org/W4382490953",
    "https://openalex.org/W3170790451",
    "https://openalex.org/W2078794610",
    "https://openalex.org/W2146292423",
    "https://openalex.org/W2245493112",
    "https://openalex.org/W1985462363",
    "https://openalex.org/W2030205755",
    "https://openalex.org/W2774096293",
    "https://openalex.org/W4385585370",
    "https://openalex.org/W4386907353",
    "https://openalex.org/W2105524676",
    "https://openalex.org/W2899753476",
    "https://openalex.org/W2990138404",
    "https://openalex.org/W4248294582",
    "https://openalex.org/W143162329",
    "https://openalex.org/W2612972698"
  ],
  "abstract": "Abstract We apply AI‐assisted large language model (LLM) capabilities of GPT‐3 targeting high‐performance computing (HPC) kernels for (i) code generation, and (ii) auto‐parallelization of serial code in C ++ , Fortran, Python and Julia. Our scope includes the following fundamental numerical kernels: AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG, and language/programming models: (1) C ++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). Kernel implementations are generated using GitHub Copilot capabilities powered by the GPT‐based OpenAI Codex available in Visual Studio Code given simple &lt;kernel&gt; + &lt;programming model&gt; + &lt;optional hints&gt; prompt variants. To quantify and compare the generated results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. For auto‐parallelization, we use ChatGPT interactively giving simple prompts as in a dialogue with another human including simple “prompt engineering” follow ups. Results suggest that correct outputs for C ++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general‐purpose Python can benefit from adding language keywords, while Julia prompts perform acceptably well for its Threads and CUDA.jl programming models. We expect to provide an initial quantifiable point of reference for code generation in each programming model using a state‐of‐the‐art LLM. Overall, understanding the convergence of LLMs, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human‐computer interactions.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8680398464202881
    },
    {
      "name": "CUDA",
      "score": 0.831038236618042
    },
    {
      "name": "Python (programming language)",
      "score": 0.8086671829223633
    },
    {
      "name": "Programming language",
      "score": 0.7483363151550293
    },
    {
      "name": "Fortran",
      "score": 0.687822699546814
    },
    {
      "name": "Parallel computing",
      "score": 0.6355021595954895
    },
    {
      "name": "Compiler",
      "score": 0.5121967196464539
    },
    {
      "name": "JavaScript",
      "score": 0.4226042330265045
    },
    {
      "name": "General-purpose computing on graphics processing units",
      "score": 0.41787824034690857
    },
    {
      "name": "Operating system",
      "score": 0.29200997948646545
    },
    {
      "name": "Graphics",
      "score": 0.183212548494339
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1289243028",
      "name": "Oak Ridge National Laboratory",
      "country": "US"
    }
  ],
  "cited_by": 3
}