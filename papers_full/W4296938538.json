{
  "title": "Program merge conflict resolution via neural transformers",
  "url": "https://openalex.org/W4296938538",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A4221624722",
      "name": "Svyatkovskiy, Alexey",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4296938559",
      "name": "Fakhoury, Sarah",
      "affiliations": [
        "Washington State University"
      ]
    },
    {
      "id": "https://openalex.org/A3179466705",
      "name": "Ghorbani, Negar",
      "affiliations": [
        "University of California, Irvine"
      ]
    },
    {
      "id": "https://openalex.org/A2746686891",
      "name": "Mytkowicz, Todd",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4287363414",
      "name": "Dinella, Elizabeth",
      "affiliations": [
        "California University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2746395805",
      "name": "Bird, Christian",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4281534349",
      "name": "Jang, Jinu",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4221583129",
      "name": "Sundaresan, Neel",
      "affiliations": [
        "Microsoft (United States)"
      ]
    },
    {
      "id": "https://openalex.org/A4286871212",
      "name": "Lahiri, Shuvendu",
      "affiliations": [
        "Microsoft (United States)"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963935794",
    "https://openalex.org/W2049134176",
    "https://openalex.org/W2007267771",
    "https://openalex.org/W1995969252",
    "https://openalex.org/W2971805582",
    "https://openalex.org/W2167626029",
    "https://openalex.org/W2761459579",
    "https://openalex.org/W3105247453",
    "https://openalex.org/W2548378638",
    "https://openalex.org/W2946767412",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2065489029",
    "https://openalex.org/W3098605233",
    "https://openalex.org/W6893968582",
    "https://openalex.org/W4393597794",
    "https://openalex.org/W2890081359",
    "https://openalex.org/W2144160189",
    "https://openalex.org/W3146893295",
    "https://openalex.org/W2139885493",
    "https://openalex.org/W2142403498",
    "https://openalex.org/W3011564318",
    "https://openalex.org/W2297048691",
    "https://openalex.org/W2137444776",
    "https://openalex.org/W2767854151",
    "https://openalex.org/W2121668868",
    "https://openalex.org/W2912237649",
    "https://openalex.org/W3210965569",
    "https://openalex.org/W3035252911",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2979977910",
    "https://openalex.org/W2898097209",
    "https://openalex.org/W3108032709",
    "https://openalex.org/W3000457305",
    "https://openalex.org/W3215914541",
    "https://openalex.org/W1986466161",
    "https://openalex.org/W2898225668",
    "https://openalex.org/W4255108598"
  ],
  "abstract": "Collaborative software development is an integral part of the modern software\\ndevelopment life cycle, essential to the success of large-scale software\\nprojects. When multiple developers make concurrent changes around the same\\nlines of code, a merge conflict may occur. Such conflicts stall pull requests\\nand continuous integration pipelines for hours to several days, seriously\\nhurting developer productivity. To address this problem, we introduce\\nMergeBERT, a novel neural program merge framework based on token-level\\nthree-way differencing and a transformer encoder model. By exploiting the\\nrestricted nature of merge conflict resolutions, we reformulate the task of\\ngenerating the resolution sequence as a classification task over a set of\\nprimitive merge patterns extracted from real-world merge commit data. Our model\\nachieves 63-68% accuracy for merge resolution synthesis, yielding nearly a 3x\\nperformance improvement over existing semi-structured, and 2x improvement over\\nneural program merge tools. Finally, we demonstrate that MergeBERT is\\nsufficiently flexible to work with source code files in Java, JavaScript,\\nTypeScript, and C# programming languages. To measure the practical use of\\nMergeBERT, we conduct a user study to evaluate MergeBERT suggestions with 25\\ndevelopers from large OSS projects on 122 real-world conflicts they\\nencountered. Results suggest that in practice, MergeBERT resolutions would be\\naccepted at a higher rate than estimated by automatic metrics for precision and\\naccuracy. Additionally, we use participant feedback to identify future avenues\\nfor improvement of MergeBERT.\\n",
  "full_text": "Program Merge Conflict Resolution via Neural Transformers\nAlexey Svyatkovskiy\nMicrosoft\nRedmond, W A, USA\nSarah Fakhoury\nWashington State University\nPullman, W A, USA\nNegar Ghorbani\nUC Irvine\nIrvine, CA, USA\nTodd Mytkowicz\nMicrosoft Research\nRedmond, W A, USA\nElizabeth Dinella\nUniversity of Pennsylvania\nPhiladelphia, PA, USA\nChristian Bird\nMicrosoft Research\nRedmond, W A, USA\nJinu Jang\nMicrosoft\nRedmond, W A, USA\nNeel Sundaresan\nMicrosoft\nRedmond, W A, USA\nShuvendu K. Lahiri\nMicrosoft Research\nRedmond, W A, USA\nABSTRACT\nCollaborative software development is an integral part of the modern\nsoftware development life cycle, essential to the success of large-\nscale software projects. When multiple developers make concurrent\nchanges around the same lines of code, a merge conflict may occur.\nSuch conflicts stall pull requests and continuous integration pipelines\nfor hours to several days, seriously hurting developer productivity.\nTo address this problem, we introduce MergeBERT, a novel neural\nprogram merge framework based on token-level three-way differenc-\ning and a transformer encoder model. By exploiting the restricted\nnature of merge conflict resolutions, we reformulate the task of gen-\nerating the resolution sequence as a classification task over a set of\nprimitive merge patterns extracted from real-world merge commit\ndata. Our model achieves 63â€“68% accuracy for merge resolution\nsynthesis, yielding nearly a 3Ã—performance improvement over ex-\nisting semi-structured, and 2 Ã—improvement over neural program\nmerge tools. Finally, we demonstrate that MergeBERT is sufficiently\nflexible to work with source code files in Java, JavaScript, Type-\nScript, and C# programming languages. To measure the practical\nuse of MergeBERT, we conduct a user study to evaluate Merge-\nBERT suggestions with 25 developers from large OSS projects on\n122 real-world conflicts they encountered. Results suggest that in\npractice, MergeBERT resolutions would be accepted at a higher\nrate than estimated by automatic metrics for precision and accuracy.\nAdditionally, we use participant feedback to identify future avenues\nfor improvement of MergeBERT.\nCCS CONCEPTS\nâ€¢ Software and its engineering â†’Software version control; Au-\ntomatic programming.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\nÂ© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9413-0/22/11. . . $15.00\nhttps://doi.org/10.1145/3540250.3549163\nKEYWORDS\nSoftware evolution, program merge, ml4code\nACM Reference Format:\nAlexey Svyatkovskiy, Sarah Fakhoury, Negar Ghorbani, Todd Mytkowicz,\nElizabeth Dinella, Christian Bird, Jinu Jang, Neel Sundaresan, and Shuvendu\nK. Lahiri. 2022. Program Merge Conflict Resolution via Neural Transform-\ners. In Proceedings of the 30th ACM Joint European Software Engineering\nConference and Symposium on the Foundations of Software Engineering\n(ESEC/FSE â€™22), November 14â€“18, 2022, Singapore, Singapore. ACM, New\nYork, NY , USA, 12 pages. https://doi.org/10.1145/3540250.\n3549163\n1 INTRODUCTION\nCollaborative software development relies on version control sys-\ntems such as git to manage and track changes across a codebase.\nIn most projects, developers work primarily in a branch of a soft-\nware repository, periodically synchronizing their code changes with\nthe main branch via merges and pull requests [21]. When multiple\ndevelopers make concurrent changes to the same line of code, a\nmerge conflict may occur. Merge commits occur frequently, almost\n12% of all commits are related to a merge [ 20], and up to 46% of\nthose commits result in conflicts. Resolving merge conflicts is a\ntime-consuming, complicated, and error-prone activity [ 6]. To re-\nsolve a conflict, developers must stop their workflow, understand\nconflicting changes, and identify a correct resolution. The ideal way\nto resolve a conflict is not always clear, and may require referring\nto project specification documentation or communicating with their\npeers about changes [6, 9, 13, 22, 33].\nModern version control systems such as git utilize the diff3\nalgorithm for performing unstructured line-based three-way merge\nof input files [ 42]. Thus, it is the de facto tool for merging and\nidentifying merge conflicts in software development. This algorithm\naligns the two-way diffs of two versions of the code, Aand B, with\nthe common base, O, into a sequence of diff â€œslotsâ€. At each slot, a\nchange from either Aor Bis selected. In cases where both Aand\nBcontain changes (relative to O) in the same slot (e.g., on the same\nline), there is a merge conflict. Standard merge algorithms cannot\nautomatically determine the correct way to merge these conflicting\nchanges. In these cases, developers must manually intervene in order\nto correctly resolve the conflicting code and complete the merge.\narXiv:2109.00084v4  [cs.SE]  29 Nov 2022\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\nOver the past decade, several approaches have been proposed\nto improve the detection and automatic resolution of merge con-\nflicts [4, 9, 10, 28, 30, 32, 45, 53]. Some approaches use the abstract\nsyntax trees (ASTs) or other representations of the source code to\nimprove conflict resolution [4, 49, 52]; others use a data-driven ap-\nproach which uses deep learning to predict the correct merge [15].\nResearchers have also developed tools to help developers visualize\nand navigate the merge conflict resolution process [41, 43, 44], and\nidentified key needs of the developer community for effective tool\nsupport [33]. The sheer body of research dedicated to this problem\nrepresents a significant amount of time and effort. Despite these\nadvancements, none of these approaches have been widely adopted\ninto practice, and the git textual-based detection algorithm remains\none of the most commonly used merging approaches [33].\nIn an effort to address this, we introduce MergeBERT: a neural\nprogram merge framework based on token-level three-way differ-\nencing and a multi-input variant of the bidirectional transformer\nencoder (BERT) model [14]. We formulate the task of generating a\nmerge conflict resolution sequence as a classification task over a set\nof primitive merge patterns extracted from real-world merge commit\ndata. MergeBERT encodes all inputs that a standard diff3 algo-\nrithm takes (two two-way diffs of input programs) as well as the edit\nsequence information, then aggregates them for learning. We train\nand then evaluate MergeBERT on 220,000 and 54,000 (respectively)\nreal world historical merge conflicts and their associated manual res-\nolutions from 100,000 GitHub repositories in JavaScript, TypeScript,\nJava and C#, and find that it performs quite well, with precision and\naccuracy always over 60% (over 70% if the top three suggestions\nare considered). Further, we compare MergeBERT to existing state\nof the art structured and semi-structured merge approaches (which\nare necessarily language-specific) and show that MergeBERT is\nable to provide resolution suggestions for more merge conflicts and\nthe suggestions are correct (i.e., match the historical user manual\nresolution) more often.\nTo better evaluate the resolutions generated by MergeBERT from\nusersâ€™ perspective in practice, we also conduct a user study with 25\ndevelopers from large OSS projects. We ask participants to evaluate\nif MergeBERT resolution suggestions are acceptable on a set of 122\nof their own real-world conflicts. Results show that MergeBERT\nmerge resolutions would be accepted in practice despite not always\nbeing syntactically identical to the historical user resolutions, and\nwe identify potential ways to improve MergeBERT and the merge\nconflict oracles used to evaluate neural program merge approaches.\nWe make the following contributions in this paper:\n(1) We introduce MergeBERT, a novel transformer-based pro-\ngram merge framework that leverages token-level three-way\ndifferencing and formulates the task of generating the resolu-\ntion sequence as a classification task.\n(2) We evaluate MergeBERT against structured and semi-structured\nprogram merge tools like JSFSTM ERGE and JDIME , as well\nas neural program merge models [15]. We demonstrate that\nMergeBERT outperforms the state-of-the-art, achieving 2â€“3Ã—\nhigher accuracy on merge resolution.\n(3) We present an empirical evaluation of the perceptions of\nMergeBERT resolutions with 25 developers from large OSS\nprojects, contributing the first user study in which developers\nuse and evaluate an automatic merge conflict resolution tool\non their own real-world conflicts.\nWe make available an online data package [ 19] containing the\ntest dataset of conflicts and user resolutions, as well as, the questions\nand responses gathered from our user study. We also provide an\nonline Appendix with supplementary details and figures [18] (also\nuploaded with this submission).\n2 MOTIV ATING EXAMPLE\nWe use a number of terms, concepts, and ideas throughout this\npaper. To provide an intuition around how our approach works and\nconcretely define terms and concepts, we begin with a motivating\nexample of a small, but realistic merge conflict.\nFig. 1 provides an example merge conflict in JavaScript which\nshows the result of merging two concurrent changes to the same\nJavaScript file. Fig. 1(a) on the left shows the standarddiff3 mark-\ners â€œ<<<<<<< A.jsâ€, â€œ||||||| O.jsâ€, â€œ=======â€ and\nâ€œ>>>>>>> B.jsâ€, which demarcate the conflicting regions intro-\nduced by programs A, base O, and Brespectively. Here, Orep-\nresents the lowest common ancestor of programs Aand Bin the\nversion control history. We denote the program text ofdiff3 con-\nflicting regions as ğ´, ğµ, ğ‘‚. The program text outside the conflict-\ning regions â€“ prefix and suffix â€“ is common to all three programs\nversions. Normally conflicts files have the same name in different\nbranches, but to avoid confusion, we name the original file in our\nexample O.js, and the two concurrently edited versions of this file\nA.js and B.js. A.js changes â€œvar xâ€ to â€œlet xâ€ and the 10\nto 11, while B.js changes the 10 to 11 and also adds an argument\nz.\nMergeBERT attempts to automatically resolve merge conflicts\nin two phases. First, MergeBERT represents each line-level merge\nconflict instance at the token level which localizes conflicting re-\ngions. Intuitively, MergeBERT converts the three line-structured\nsource texts into three sequences of tokens (including space and line\ndelimiters), applies the standard diff3 algorithm to these token\nsequences, and then reconstructs the merged document at line level.\nFig. 1(b) shows the result of applying this token-level merge on\nFig. 1(a). As a result of token-level merge, the whole â€œ let x =\nmax(y,â€ string is cleanly merged, becoming a part of the program\nprefix, and â€œ)â€ is prepended to the program suffix. Second, Merge-\nBERT invokes an underlying neural model to suggest a resolution\nvia classification for each token-level conflicting region and replaces\nthe conflict region with the suggestion from the model (Fig. 1(c)).\nObserve that the resolution does not consist of any single line\nfrom either ğ´or ğµsince both edits modify a common line in the base.\nHence, earlier neural approaches such as DeepMerge [15] that are\nrestricted to picking entire lines from the conflict region would not\nbe able to provide the resolution. On the other hand, structured\nmerge techniques (such as JSFSTM ERGE by [50]) cannot resolve\nthe conflict soundly as the conflict appears on a program statement,\nwhich leads to side effects (e.g. syntactically incorrect code).\nA token-level merge can interleave edits within lines (i.e., tokens\nin which one edit does not conflict with another are trivially merged).\nConsider Aâ€™s edit of thevar to let keyword. Such non-conflicting\nedits suffice to demonstrate the above. Token-leveldiff3 is a syn-\ntactic merge algorithm and therefore cannot guarantee semantic or\nProgram Merge Conflict Resolution via Neural Transformers ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\ny = 9z = 0<<<<<<< A.jslet x = max(y, 11)||||||| O.jsvar x = max(y, 10)=======var x = max(y, 12, z)>>>>>>> B.jsconsole.log(x)\nPrefix\nSuffix\n(a) Line-level conflict\ny = 9z = 0let x = max(y,<<<<<<< A.js11||||||| O.js10=======12, z>>>>>>> B.js)console.log(x) (b) Token-level conflict\ny = 9z = 0let x = max(y, 12, z)console.log(x) (c) Resolved merge\nFigure 1: Example merge conflict represented through standarddiff3 (left) and token-level diff3 (center), and the user resolution\n(right). The merge conflict resolution takes the token-level editğ‘.\neven syntactic correctness of the merged program. However, we ob-\nserved that in practice, syntactic correctness is preserved the majority\nof the time (over 97%).\nLikewise, consider the token-level conflict for the max functionâ€™s\narguments: an appropriate model trained on JavaScript should eas-\nily deduce that taking the edit from B(i.e., \"11, z\") captures the\nbehavior of Aâ€™s edit as well. The suggested resolution gives an intu-\nitive demonstration of how MergeBERT turns a complex line-level\nresolution into a simpler token-level classification problem.\n3 BACKGROUND: DATA-DRIVEN MERGE\nDinella et al. [15] introduced the data-driven program mergeprob-\nlem as a supervised machine learning problem. A program merge\nconsists of a 4-tuple of programs (A,B,O,M), where\n(1) The base program Ois the lowest common ancestor in the\nversion history for programs Aand B,\n(2) diff3 produces an unstructured line-level conflict when\napplied to (A,B,O), and\n(3) Mis the merged program with the developer resolution, in-\ncorporating changes made in Aand B.\nA merge may have multiple unstructured conflicts, we define amerge\ntuple (ğ´,ğµ,ğ‘‚,ğ‘€ ), where ğ´,ğµ,ğ‘‚ correspond to the conflicting regions\nin (A,B, and O), respectively, and ğ‘€ denotes the resolution region.\nGiven a set of merge tuples (ğ´ğ‘–,ğµğ‘–,ğ‘‚ğ‘–,ğ‘€ğ‘– ), i = 0...N, the goal of\na data-driven merge algorithm is to learn a function, merge, that\nmaximizes Pğ‘\nğ‘–=0 merge(ğ´ğ‘–,ğµğ‘–,ğ‘‚ğ‘– ) = ğ‘€ğ‘– . Throughout the text, we\nwill use notations (ğ‘,ğ‘,ğ‘œ,ğ‘š ) to refer to the token-level merge tuples.\nDinella et al. [15] also provide an algorithm for extracting the\nexact resolution regions for each merge tuple and define a dataset\nthat corresponds to non-trivial resolutions; resolutions where the\ndeveloper does not drop the changes from one side of the merge.\nFurther, they provide a sequence-to-sequence encoder-decoder based\narchitecture, where a bi-directional gated recurrent unit (GRU) is\nused for encoding the merge inputs comprising of (ğ´,ğµ,ğ‘‚ ) segments\nof a merge tuple, and a pointer mechanism is used to restrict the\noutput to only choose from line segments present in the input. Their\npaper suffers from two limitations. First, given the restriction on\ncopying only lines from inputs, their dataset did not consider merges\nwhere the resolution required token-level interleaving, such as the\nconflict in Figure 1. Second, their dataset consists of merge conflicts\nin a single language, namely JavaScript. Our approach addresses\nboth of these limitations.\n4 MERGE CONFLICT RESOLUTION AS A\nCLASSIFICATION TASK\nIn this work, we demonstrate how to exploit the restricted nature of\nmerge conflict resolutions â€“ compared to an arbitrary program repair â€“\nto leverage discriminative models to synthesize the merge resolution\nsequence. We have empirically observed that the application of\ndiff3 at token granularity enjoys two useful properties over its\nline-level counterpart: (i) it helps localize the merge conflicts to\nsmall program segments, effectively reducing the size of conflicting\nregions, and (ii) most resolutions of merge conflicts produced by\ntoken diff3 consist entirely of changes from ğ‘ or ğ‘ or ğ‘œ or a\nsequential composition of ğ‘followed by ğ‘or vice versa. Here, and\nthroughout the paper we will use lower case notations to refer to\nattributes of token-level differencing (e.g. ğ‘, ğ‘, and ğ‘œ are conflict\nregions produced by diff3 at token granularity). On the flip side,\na token-level merge can introduce many small conflicts. To balance\nthe trade-off, we start with the line-level conflicts as produced by\nthe standard diff3 and perform a token-level merge of only the\nsegments present in the line-level conflict. There are several potential\noutcomes for such a two-level merge at the line-level:\nâ€¢A conflict-free token-level merge: For example, the edit from\nğ´ about let is merged since ğµ does not edit that slot as\nshown in Fig. 1(b).\nâ€¢A single localized token-level merge conflict : For example,\nthe edit from both ğ´and ğµfor the arguments of max yields a\nsingle conflict as shown in Fig. 1(b).\nâ€¢Multiple token-level conflicts : Such a case (not illustrated\nabove) can result in several token-level conflicts.\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\nlet x = max(y, \n<<<<<<< branch A \n        11                    \n||||||| \n        10        \n======= branch O \n        11, z   \n>>>>>>> branch B\n)\nClassification\nEncoder\nAggregation\n  \nEmbedding \nToken\n= == = â†”== =\nx = max ( , 11)y\n=x max ( 10)y ,\n=x max y 10 ),(\n= = = == = â†” + + =\nx = max ( y , 11, z )\nResolution\nDecoding\nA \nEdit\nlet x = max(y, 11, z) \nO \nB \nEncoder\nEncoder\nEncoder\nPosition\n  \nEmbedding \nToken EditPosition\n  \nEmbedding \nToken EditPosition\n  \nEmbedding \nToken EditPosition\nFigure 2: An overview of the MergeBERT architecture. From left to right: given conflicting programs A, Band Otoken-level\ndifferencing is performed first, next, programs are tokenized and the corresponding sequences are aligned (ğ‘|ğ‘œ and ğ‘œ|ğ‘, ğ‘|ğ‘œ , and ğ‘œ|ğ‘).\nWe extract edit steps for each pair of token sequences (âˆ†ğ‘ğ‘œ and âˆ†ğ‘ğ‘œ ). Four aligned token sequences are fed to the multi-input encoder\nneural network, while edit sequences are consumed as edit type embeddings. Finally, encoded token sequences are aggregated into a\nhidden state which serves as input to classification layer.\nToken-level diff3 applied to a 4-tuple of programs(A,B,O,M),\nwould usually result in a set of localized merge tuplesâŸ¨ğ‘ğ‘—,ğ‘ğ‘—,ğ‘œğ‘—,ğ‘šğ‘— âŸ©.\nWe empirically observe that 74% of such resolutions ğ‘šğ‘— are com-\nprised of (ğ‘–) exactly the tokens in ğ‘ğ‘— or (ğ‘–ğ‘–) exactly the tokens in\nğ‘ğ‘— . Another 0.4% of the resolutions are ( ğ‘–ğ‘–ğ‘–) just the tokens in ğ‘œğ‘— .\nIn addition, 23% of the resolutions are the result of concatenating\n(ğ‘–ğ‘£) ğ‘ğ‘— and ğ‘ğ‘— or (ğ‘£) ğ‘ğ‘— and ğ‘ğ‘— . Finally, 1.8% comprise another four\nvariants, obtained by taking ğ‘–, ğ‘–ğ‘–, ğ‘–ğ‘£ and ğ‘£ above and removing the\ntokens that also occur in the base, ğ‘œğ‘— . In total, this provides nine\nprimitive merge resolution patterns (see online Appendix [18] for\nmore details about the primitive merge patterns).\nWe, therefore, treat the problem of constructing merge conflict\nresolutions ğ‘šğ‘— as a classification task to predict between these pos-\nsibilities. It is important to note that although we are predicting\nsimple resolution strategies at the token-level, they may translate to\ncomplex resolutions at the line-level. In addition, not all conflicts\nare resolved by breaking that conflict into tokens and applying these\npatternsâ€”some resolutions such as those introducing new tokens or\nreordering tokens are not expressible as a choice at the token-level.\n5 MERGEBERT: NEURAL PROGRAM\nMERGE FRAMEWORK\nMergeBERT is a textual program merge model based on the bidirec-\ntional transformer encoder (BERT) model [14]. We refer the reader\nto CodeBERT [17] for a discussion on applying transformers to code.\nA transformer, like a recurrent neural network, maps a sequence of\ntext into a high dimensional representation, which can later be de-\ncoded to solve downstream tasks. While not originally designed\nfor code, transformers have found many applications in software\nengineering [11, 26, 47]\nMergeBERT approaches merge conflict resolution as a sequence\nclassification task given conflicting regions extracted with token-\nlevel differencing and surrounding code as context. The key technical\ninnovation in MergeBERT lies in how it breaks program text into an\ninput representation amenable to learning with a transformer encoder\nand how it aggregates various input encodings for classification.\nIn the standard sequence learning setting there is a single input\nand single output sequence. In the merge conflict resolution task,\nthere are multiple conflicting input programs and one resolution.\nTo facilitate learning in this setting, we construct MergeBERT as\na multi-input encoder neural network, which first encodes token\nsequences of conflicting programs, then aggregates them into a\nsingle hidden summarization state.\nAn overview of the MergeBERT model architecture is shown in\nFig. 2. Given conflicting programs A, Band Owe first perform\ntokenization and then repeat the three-way differencing at token\ngranularity. If a conflict still exists in this token-level three-way\ndifferencing, we collect the token sequences corresponding to con-\nflicting regions ğ‘, ğ‘, and ğ‘œ, and compute pair-wise alignments of ğ‘\nand ğ‘ with respect to the base ğ‘œ. Finally, for each pair of aligned\ntoken sequences we extract an â€œedit sequenceâ€ that represents how\nto turn the second sequence into the first. The resulting aligned token\nsequences are fed to the multi-input encoder neural network, while\nthe corresponding edit sequences are consumed as type embeddings.\nFinally, the encoded token sequences are summarized into a hidden\nstate which serves as input to the classification layer.\nGiven a 4-tuple of programs (A,B,O,M) which contains token-\nlevel merge tuples (ğ‘ğ‘—,ğ‘ğ‘—,ğ‘œğ‘—,ğ‘šğ‘— ), j=0...N, MergeBERT models the\nfollowing conditional probability distribution:\nğ‘(ğ‘šğ‘— |ğ‘ğ‘—,ğ‘ğ‘—,ğ‘œğ‘— ), (1)\nand consequently, for entire programs:\nğ‘(M|A,B,O) =\nğ‘Y\nğ‘—=1\nğ‘(ğ‘šğ‘— |ğ‘ğ‘—,ğ‘ğ‘—,ğ‘œğ‘— ) (2)\nProgram Merge Conflict Resolution via Neural Transformers ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\n= = = = = = ÃŸÃ +\nx = max( y , 11,\nx = max( y , 10[PAD]\nz )\n+ =\n[PAD])\nFigure 3: An example edit sequence extracted between a pair\nof token sequences. Top row is ğ‘œ|ğ‘, bottom is ğ‘|ğ‘œ , and middle is\nâˆ†ğ‘ğ‘œ . Padding symbols [PAD] are introduced for alignment. In\nthis case, the target token sequence is obtained by swapping a\ntoken and inserting two tokens.\nIndependence of token-level conflicts is a simplifying assumption.\nHowever, we observe that in our data set only 5% of merge conflicts\nresult in more than 1 token-level conflict per line-level conflict.\n5.1 Context Encoding\nFor a merge tuple (ğ‘,ğ‘,ğ‘œ,ğ‘š ) MergeBERT calculates two pair-wise\nalignments between the sequences of tokens of conflicting regions\nğ‘ (respectively ğ‘) with respect to that of the original program ğ‘œ:\nğ‘|ğ‘œ , ğ‘œ|ğ‘, ğ‘|ğ‘œ , and ğ‘œ|ğ‘. For each pair of aligned token sequences we\ncompute an edit sequence. These edit sequences â€“ âˆ†ğ‘ğ‘œ and âˆ†ğ‘ğ‘œ â€“\nare comprised of the following editing actions (kinds of edits): =\nrepresents equivalent tokens, + represents insertions, - represents\ndeletions, â†” represents a replacement, and âˆ… is used as a padding\ntoken. Overall, this produces four token sequences and two edit se-\nquences: (ğ‘|ğ‘œ , ğ‘œ|ğ‘, and âˆ†ğ‘ğ‘œ ) and (ğ‘|ğ‘œ , ğ‘œ|ğ‘, and âˆ†ğ‘ğ‘œ ). Fig. 3 provides\nan example of an edit sequence. Each token sequence covers the\ncorresponding conflicting region and, potentially, surrounding code\ntokens. We make use of Byte-Pair Encoding (BPE) unsupervised to-\nkenization to avoid a blowup in the vocabulary size given the sparse\nnature of code identifiers [27]. To help the model learn to recognize\nediting steps we introduce an edit type embedding. We combine it\nwith the standard token and position embeddings utilized in BERT\nmodel architecture via addition.\n5.2 Merge Tuple Aggregation\nWe utilize transformer encoder model Eto independently encode\neach of the four token sequences of token-level conflicting regions\nğ‘|ğ‘œ , ğ‘œ|ğ‘, ğ‘|ğ‘œ , and ğ‘œ|ğ‘, passing corresponding edit sequences âˆ†ğ‘ğ‘œ\nand âˆ†ğ‘ğ‘œ as type embeddings. Finally, MergeBERT aggregates the\nresulting encodings into a single hidden summarization state â„:\n(3)â„=\nâˆ‘ï¸\nğ‘¥ âˆˆ(ğ‘ |ğ‘œ,ğ‘œ |ğ‘,ğ‘|ğ‘œ,ğ‘œ |ğ‘ )\nğœƒğ‘¥ Â·E(ğ‘¥,âˆ†ğ‘¥ )\nwhere E(ğ‘¥,âˆ†ğ‘¥ ) are the encoded tensors for each of the sequencesğ‘¥ âˆˆ\n(ğ‘|ğ‘œ,ğ‘œ|ğ‘,ğ‘|ğ‘œ,ğ‘œ|ğ‘), and ğœƒğ‘¥ are learnable weights. After aggregation a\nlinear classification layer with softmax is applied:\nğ‘(ğ‘šğ‘— |ğ‘ğ‘—,ğ‘ğ‘—,ğ‘œğ‘— ) = softmax(ğ‘Š Â·â„+ ğ‘) (4)\nThe resulting line-level resolution region is obtained by concate-\nnating the prefix, predicted token-level resolution ğ‘šğ‘— , and the suffix.\nFinally, in the case of a one-to-many correspondence between the\noriginal line-level and the token-level conflicts (see Appendix for\nmore details and a pseudocode), MergeBERT uses a standard beam-\nsearch to decode the most promising predictions.\n5.3 Implementation Details\nWe utilize a pretrained CodeBERT1 model with 6 encoder layers,\n12 attention heads, and a hidden state size of 768. The vocabulary is\nconstructed using byte-pair encoding [39] and the vocabulary size\nis 50000. We transfer the weights of the pretrained transformer en-\ncoder into the MergeBERT multi-input neural network, and attach\na randomly initialized linear layer with softmax. We then finetune\nthe resulting neural network in a supervised setting for the sequence\nclassification task. Input sequences for finetuning training cover con-\nflicting regions and surrounding code (i.e., fragments of prefix and\nsuffix of a conflicting region) up to a maximum length of 512 BPE\ntokens. The backbone of our implementation is HuggingFaceâ€™s 2\nRobertaModel and\nRobertaForSequenceClassification classes in PyTorch,\nwhich are modified to turn the model into a multi-input architecture\nshown in Fig. 2. We finetune MergeBERT with Adam stochastic\noptimizer with weight decay fix using a learning rate of 5e-5, 512\nbatch size and 8 backward passes per allreduce. The finetuning\ntraining was performed on 4 NVIDIA Tesla V100 GPUs with 16GB\nmemory for 6 hours.\nIn the inference phase, the model prediction for each line-level\nconflict consists of one or more token-level predictions. Given the\ntoken-level predictions and the contents of the merged file, Merge-\nBERT generates the code corresponding to the resolution region.\nThe contents of the merged file include the conflict in question and\nits surrounding regions. Afterward, MergeBERT checks the syntax\nof the generated code with a tree-sitter3 parser and outputs it as the\ncandidate merge conflict resolution only if it is syntactically correct.\n6 RESEARCH QUESTIONS\nWe pose the following research questions to evaluate the effective-\nness of utility of MergeBERT.\nRQ1: How effective is MergeBERT in producing merge conflict\nresolutions? We evaluate MergeBERTâ€™s performance of producting\nresolutions in terms of precision and accuracy of matching the actual\nuser resolution extracted from real-world merge resolutions. We\nalso provide a comparison MergeBERT to baseline approaches (at\nboth the line and token level) and state of the art merge resolution\napproaches.\nRQ2: How well does MergeBERT perform across different lan-\nguages? One of our primary goals is to be able to work on multiple\nlanguages with minimal effort. The core approach of MergeBERT\nis fundamentally language agnostic (though a parser and tokenizer\nis required for each additional language). We evaluate performance\nof MergeBERT across four languages and also compare the results\nof using four language-specific models (each trained on just one\nlanguage) to using one multi-lingual model trained on the data from\nall four languages.\n1https://huggingface.co/huggingface/CodeBERTa-\nsmall-v1\n2https://github.com/huggingface/transformers\n3https://tree-sitter.github.io/tree-sitter\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\nRQ3: How do different choices of context encoding impact per-\nformance of MergeBERT? We conduct an ablation study of the\nedit type embedding to understand and evaluate the impact of our\nnovel edit-aware encoding on model performance.\nRQ4: How do users perceive MergeBERT resolutions? We con-\nduct a user study involving a survey of real-world conflicts recently\nencountered by developers from large OSS projects. To understand\nhow developers would use MergeBERT in practice, we provide them\nwith an interface to explore MergeBERTâ€™s conflict resolution sugges-\ntions in relation to their original conflicting code ask them evaluate\nsuggestions and explain why they do or do not correctly resolve the\nmerge conflict.\n7 DATASET\nThe finetuning dataset is mined from over 100,000 open source soft-\nware repositories in multiple programming languages with merge\nconflicts. It contains commits from git histories with exactly two\nparents, which resulted in a merge conflict. We replay git merge\non the two parents to see if it generates any conflicts. Otherwise, we\nignore the merge from our dataset. We use the approach introduced\nby Dinella et al. [15] to extract resolution regionsâ€”however, we do\nnot restrict ourselves to conflicts with less than 30 lines only. Lastly,\nwe extract token-level conflicts and conflict resolution classifica-\ntion labels (introduced in Section 4) from line-level conflicts and\nresolutions. Tab. 1 provides a summary of the finetuning dataset.\nTable 1: Number of merge conflicts in the dataset.\nProgramming language Development set Test set\nC# 27874 6969\nJavaScript 66573 16644\nTypeScript 22422 5606\nJava 103065 25767\nThe finetuning dataset is split into development and test sets in\nthe proportion 80/20 at random at the file-level. The development set\nis further split into training and validation sets in 80/20 proportion\nat the merge conflict level.\n8 EV ALUATION\n8.1 Evaluation Metrics\nWe evaluate MergeBERTâ€™s performance of resolution synthesis in\nterms of precision and accuracy of string match (modulo whites-\npaces or indentation) to the user resolution extracted from real-world\nhistorical merge resolutions. This approach is rather restrictive as\na suggested resolution might differ from the actual user resolution\nby, for instance, only the order of statements, being semantically\nequivalent otherwise. As such, this evaluation approach gives a lower\nbound of performance.\nWe evaluate MergeBERT and compare it to baselines and existing\napproaches using two metrics, precision at top-k and accuracy at\ntop-k. Since MergeBERT is a neural approach, it may provide more\nthan one suggestion, which we rank according to the associated\nprediction probabilities. In addition, because we filter out resolution\nsuggestions that are not syntactically valid, it may provide no sug-\ngestions in rare cases. Accuracy at top-1 indicates the percentage of\ntotal conflicts for which MergeBERT produces the correct resolu-\ntion as its top suggestion. Precision at top-1 indicates how often (as\na percentage) the top suggestion is correct when the MergeBERT\nprovides any suggestions at all. As a concrete example, if a tool\nproduces a resolution suggestion for 50 out of 100 conflicts and\n40 of the suggestions matched the actual historical user resolution,\nthen the precision would be 80% (40/50), but the accuracy would\nbe 40% (40/100). Precision at top-k indicates how often the correct\nresolution is found in the top-k suggestions and Accuracy at top-k is\nanalogous. When â€œtop-kâ€ is omitted from the metric name (e.g. just\n\"Precision\") then k is 1.\n8.2 Baseline Models\n8.2.1 Language Model Baseline. Neural language models (LMs)\nhave shown great performance in natural language generation [36,\n38], and have been successfully applied to the domain of source\ncode [17, 24, 48]. We consider the generative pretrained transformer\nlanguage model for code (GPT-C) and appeal to the naturalness\nof software [ 1] to construct our baseline approach for the merge\nresolution synthesis task. We establish the following baseline: given\nan unstructured line-level conflict produced by diff3, we take the\ncommon source code prefix acting as user intent for program merge.\nWe attempt to generate an entire resolution region token-by-token\nusing beam search. As an ablation experiment, we repeat this for\nthe conflicts produced with the token-level differencing algorithm\n(Fig. 1 shows details about prefix and conflicting regions).\n8.2.2 DeepMerge: Neural Model for Interleavings.Next, we\nconsider DEEP MERGE [15]: a sequence-to-sequence model based on\nthe bidirectional GRU summarized in section 3. It learns to generate\na resolution region by choosing from line segments present in the\ninput (line interleavings) with a pointer mechanism. We retrain the\nDEEP MERGE model on our TypeScript dataset.\n8.2.3 JDIME. Looking for a stronger baseline, we considerJDIME ,\na Java-specific merge tool that automatically tunes the merging pro-\ncess by switching between structured and unstructured merge algo-\nrithms [2]. Structured merge is abstract syntax tree (AST) aware and\nleverages syntactic information to improve matching precision of\nconflicting nodes. We use the publicly available implementation [25],\nand run JDime in semi-structured mode.\n8.2.4 jsFSTMerge. Trindade Tavares et al. [50] implemented JS-\nFSTM ERGE by adapting an off-the-shelf grammar for JavaScript to\naddress shortcomings of FSTM ERGE [3] and modify its algorithm.\nJSFSTM ERGE allows for certain types of nodes to maintain their rel-\native order (e.g., statements) while others may be order independent\n(e.g., function declarations) even when sharing the same parent node.\nFor cases where JSFSTM ERGE produces a resolution not matching\nthe user resolution, we manually inspect the output for semantic\nequivalence (e.g., reordered import statements).\n8.3 Results\nRQ1: How effective is MergeBERT in producing merge conflict\nresolutions?\nProgram Merge Conflict Resolution via Neural Transformers ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\nTo evaluate MergeBERT We first compare it to other neural ap-\nproaches and to diff3. To be comprehensive, we evaluate at both\nthe token level and the line level. We then compare MergeBERT\nto existing state of the art structured and semi-structured merge\nlanguage-specific merge approaches.\nTable 2: Evaluation results for MergeBERT and various neural\nbaselines calculated for merge conflicts in TypeScript program-\nming language test set. The table shows top-1 precision and ac-\ncuracy metrics.\nApproach Granularity Precision Accuracy\nLM Line 3.6 3.1\nDeepMerge Line 55.0 35.1\ndiff3 Token 82.4 36.1\nLM Token 49.7 48.1\nDeepMerge Token 64.5 42.7\nMergeBERT Token 69.1 68.2\nAs seen in Tab. 2, language model baselinesâ€™ performance on\nmerge resolution synthesis is relatively low, suggesting that the natu-\nralness hypothesis is insufficient to capture the developer intent when\nmerging programs. This is perhaps not surprising given the notion\nof precision that does not tolerate even a single token mismatch.\nMergeBERT is based on two core components: token-leveldiff3\nand a multi-input neural transformer model. The token-level differ-\nencing algorithm alone gives a high top-1 precision of 82.4%, with\na relatively low accuracy of only 36.1% (i.e., it doesnâ€™t always\ngenerate a resolution suggestion, but when it does, it is very often\ncorrect). Combined with the neural transformer model, the accuracy\nis increased to a total of 68.2%. Note, as a deterministic algorithm\ntoken-level diff3 can only provide a single suggestion.\nDeepMerge precision of merge resolution synthesis is quite ad-\nmirable, showing 55.0% top-1 precision. However, it fails to generate\npredictions for merge conflicts which are not representable as a line\ninterleaving. This type of merge conflict comprises only roughly one\nthird of the test set, resulting in an accuracy of only 35.1% which is\nsignificantly lower than MergeBERT.\nAs an experiment, we also evaluate the DeepMerge model in\ncombination with the token-level diff3. This enables DeepMerge\nto overcome the limitation of providing only resolutions comprised\nof interleavings of lines from the conflict region by interleaving to-\nkens instead. As seen in Tab. 2 (DeepMerge with Token granularity)\noverall accuracy improves from 35.1% to 42.7%. However this still\nfalls short of MergeBERT with precision that is 5% less (64.5% vs.\n69.1%) and accuracy that is 25% less (42.7% vs 68.2%).\nWe also compared MergeBERT to state of the art structured and\nsemi-structured merge tools. Since both JDIME and JSFSTM ERGE\nare language-specific, to compare against MergeBERT, we use our\ndatasetâ€™s corresponding language-specific subset of conflicts (leading\nto slightly different results for MergeBERT on Java and JavaScript).\nAs can be seen from Tab. 3, JSFSTM ERGE only produces a reso-\nlution for 22.8% of conflicts and when a resolution is produced by\nJSFSTM ERGE , it is only correct 15.8% of the time, yielding a total\naccuracy of 3.6%. This is in line with the conclusions of the creators\nof JSFSTM ERGE that semi-structured merge approaches may not be\nTable 3: Comparison of MergeBERT to JD IME and JSFST-\nMERGE semi-structured merge tools. The table shows the per-\ncentage of conflicts in which the tool produces a resolution, the\ntop-1 precision of produced resolutions, and the overall top-1\naccuracy of merge resolution synthesis. JDIME evaluation is on\na Java data set and JSFSTM ERGE is on a JavaScript data set.\nApproach Language % conf. w/ res. Precision Accuracy\nJDIME Java 82.1 26.3 21.6\nMergeBERT Java 98.9 63.9 63.2\nJSFSTMERGE JavaScript 22.8 15.8 3.6\nMergeBERT JavaScript 98.1 66.9 65.6\nas advantageous for dynamic scripting languages [50]. Because JSF-\nSTM ERGE may produce reformatted code, we manually examined\ncases where a resolution was produced but did not match the user\nresolution (our oracle). If the produced resolution was semantically\nequivalent to the user resolution, we classified it as correct.\nTo compare the accuracy of JDIME to that of MergeBERT, we\nuse the Java Test data set introduced previously and complete the fol-\nlowing evaluation steps: JDIME does not merge all conflicts and gen-\nerates a resolution for 82.1% of conflicts. This is in line with related\nwork reporting that as much as 21% of files cannot be merged [2].\nTherefore, first, we identify the set of merge conflict scenarios where\ndiff3 reports a conflict and JDIME produces a non-conflicted\nmerge. When comparing the JDIME output to the actual historical\nuser-performed merge conflict resolution, we do not use a simple\nsyntactic match. As a result of its AST matching approach, code\ngenerated by JDIME is reformatted, and the original order of state-\nments and other constructs are not always preserved. In an effort to\naccurately and fairly identify semantically equivalent merges, we\nuse GumTree [ 16], an AST differencing tool, to identify and ig-\nnore semantically equivalent differences between JDIME output and\nthe user resolution, such as reordered method declarations. When\nJDIME produces a resolution, it generates a semantically equivalent\nmatch 26.3% of the time, with an accuracy of 21.6%.\nRQ2: How well does MergeBERT perform across different lan-\nguages? One goal of our approach is to be able to handle multiple\nlanguages with minimal effort. For MergeBERT to be able to provide\nmerge resolution suggestions for conflicts in a particular language,\nit needs three things. First, a tokenizer in that language, which al-\nlows us to split the source text into tokens for processing. Second,\na parser in that language, which allows us to filter out syntactically\nincorrect merge resolution suggestions. Third, a data set of merge\nconflicts and their user-resolutions to train MergeBERT. Fortunately,\ntokenizers and parsers for nearly any language are readily available\n(e.g., we use GitHubâ€™s tree-sitter for this) and repositories that use\na particular language can be easily identified (e.g. on GitHub) and\nmined for conflicts and resolutions.\nWe incorporated tokenizers and parsers into MergeBERT for\nJavaScript, TypeScript, Java, and C# and gathered merge conflict\ndata for these languages as described previously. Note that both\ncomments and strings in these languages are represented as single\ntokens and can be quite long. Therefore we further split these to-\nkens on whitespace. Tab. 4 shows the detailed evaluation results of\nMergeBERT broken down by language. The top section of results\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\nTable 4: Detailed evaluation results for (top) monolingual\nJavaScript, TypeScript, Java, and C# models, and (bottom) mul-\ntilingual MergeBERT model trained on all four programming\nlanguages. The table shows precision and accuracy of merge\nresolution synthesis.\nTest (Train) Languages Precision Accuracy\nTop-1 Top-3 Top-1 Top-3\nJavaScript (JS) 66.9 75.4 65.6 73.9\nTypeScript (TS) 69.1 76.6 68.2 75.6\nJava (Java) 63.9 76.1 63.2 75.2\nC# (C#) 68.7 76.4 67.3 74.8\nJavaScript (JS, TS, C#, Java) 66.6 75.2 65.3 73.8\nTypeScript (JS, TS, C#, Java) 68.5 76.8 67.6 75.8\nJava (JS, TS, C#, Java) 63.6 76.0 62.9 75.1\nC# (JS, TS, C#, Java) 66.3 76.2 65.1 74.8\nshows performance when MergeBERT is trained on data for that\nspecific language. The bottom section shows performance for each\nlanguage when MergeBERT is trained on a data set comprising data\nfor all languages (we term this the multilingual model). Note that\nfor the language specific models, performance is fairly consistent\nacross all four languages with Top-1 precision ranging from 63.9%\nto 69.1% and Top-1 Accuracy ranging from 63.2% to 68.2%. We\nalso find that over 97% of MergeBERT suggestions are syntactically\ncorrect across all programming languages.\nWe had no a priori expectations of the performance of the mul-\ntilingual model, as it is trained on more data, which could lead to\nimprovement, but it is not language specific, which could lead to\npoorer results. Overall, the multilingual variant of the model gen-\nerates results that are just slightly below the monolingual versions.\nThus performance on one language isnâ€™t improved by adding more\ndata in other languages. Thus, from a pragmatic perspective, if one\nchooses to simplify their use of MergeBERT by training just one\nmodel instead of one model per language, then the performance\ntakes only a negligible hit.\nRQ3: How do different choices of context encoding impact per-\nformance of MergeBERT?\nWe conduct an ablation study on the edit type embedding to\nunderstand the impact of edit-awareness of encoding on the model\nperformance. As shown in Tab. 5, use of the edit type embedding\nimproves MergeBERT from 63% to 68%.\nTable 5: Evaluation results for MergeBERT and the model vari-\nant without edit-type embedding for merge conflicts in Type-\nScript programming language test set. The table shows top-1\nprecision and accuracy metrics.\nApproach Precision Accuracy\nw/o edit type embeddings 65.2 63.1\nMergeBERT w/ edit type embeddings 69.1 68.2\nFigure 4: Methodology to identify candidate conflicts for the\nuser study.\nTable 6: Summary of projects in user study, total number of\nconflicts per project, number of conflicts evaluated in the study,\nand the survey participants.\nLanguage Project Conflicts Survey Participants\nConflicts\nJava\nAzure-Cosmosdb 341 6 P1\nAzure-SDK 997 14 P2-4\nApplicationInsights 313 10 P5-6\nTS MakeCode 106 12 P7-8\nVSCode 2256 48 P9-17\nC#\nAspNetCore 567 11 P18-19\nEFCore 397 7 P20-21\nRoslyn 1894 14 P22-25\nTotal 8 projects 6871 122 25\n9 USER EV ALUATION\n9.1 User Study Design\nTo better understand how MergeBERT performs in practice, we ask\ndevelopers about conflicts that MergeBERT is unable to correctly\nresolve. Since MergeBERTâ€™s resolution suggestions are evaluated\nagainst user resolutions using a verbatim string match (modulo\nwhitespace), asking study participants to confirm identical resolu-\ntions predicted by MergeBERT is not informative. Therefore, we\nextract conflicts where MergeBERT suggestions are not a direct\nmatch to the user resolution to determine what the limitations of the\nsuggestions are, and how they might be perceived in practice.\nTo build an oracle of merge conflicts and resolutions we identify\n8 open source projects hosted on GitHub. The selected projects are\nactive, with multiple contributors, and contain a large number of\nconflict scenarios in one of the languages supported by MergeBERT.\nTab. 6 contains a list of projects chosen. For each project, we follow\nthe same steps outlined in Section 7 to extract candidate conflicts\nand user resolutions to use in the survey.\nFig. 4 explains the methodology used to identify candidate merge\nconflicts. We identify the set of conflicts MergeBERT is unable to\ncorrectly merge (within the top-3 suggestions). From this set of\nconflicts, we identify candidate conflicts to use as part of the user\nstudy. We filter candidate files with the following criteria:\n(1) Conflicts should have been recently resolved i.e., at most\nwithin the past 12 months. Participants may not retain the\ncontext needed to evaluate suggestions for older conflicts.\nProgram Merge Conflict Resolution via Neural Transformers ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\n(2) Files must have at most 4 conflicts. Participants evaluate up to\n3 suggestions per conflict. More conflicts may be too complex\nto evaluate within the interview time slot.\n(3) Conflicts should be non-trivial. Trivial conflicts, such as those\nthat only involve formatting changes or renames, are manually\nexcluded. The determination of if a conflict was non-trivial\nwas manual and subjective, informed by our belief that more\nsubstantive conflicts would lead to more insights in the user\nstudy.\nFor each candidate conflict identified, we use the GitHub API to\nidentify authors for each of the conflicting branches and the resolved\nfile. Authors with at least 3 candidate merge conflicts are identified\nas potential survey participants. Our final pool of candidate partic-\nipants consists of 52 unique authors. We recruit participants via\nemail, using contact information on GitHub. Out of the 52 contacted\ndevelopers, 25 agreed to participate in the study. All participants\nwere professional software developers with at least 2-8 years of\nexperience working at large technology companies. We asked partic-\nipants to evaluate MergeBERT resolution suggestions for their own\nmerge conflicts. Tab. 6 contains the final number of participants and\nconflicts evaluated in our study. 122 conflicts were evaluated: 32 C#\nconflicts, 30 Java, and 60 Typescript.\n9.1.1 MergeBERT Interface. We designed an online interface\nwhere participants can view their own conflicts and explore Merge-\nBERTâ€™s resolution suggestions. Participants are asked to evaluate\ntheir own recently resolved merge conflicts, and the corresponding\ngenerated resolution suggestions by MergeBERT. The interface is\ncustomized based on the signed-in participant and displays a list of\ntheir recently encountered merge conflicts. Participants can click\nthrough different resolution suggestions to evaluate if they are ac-\nceptable ways to resolve the merge conflict. They can view their\noriginal resolution on the same page, and if needed, participants\ncan navigate to the conflicting commit on GitHub using a link if\nthey need additional context. They can also view a diff between the\nconflict file and any of the selected options (resolution suggestion or\nuser resolution). Participants use this interface to select one or more\nof the suggested resolutions, indicate if the suggested resolution is\nacceptable, and explain the reasons why or why not. Our online data\npackage [19] and appendix [18] contain the questions, images of the\ninterface, and participant responses.\n9.1.2 Protocol. The user study was conducted as 30 minute inter-\nviews remotely over Microsoft Teams using the interface we built.\nFirst, participants watched a video explaining MergeBERT and how\nto navigate conflicts and evaluate resolution suggestions using the\ninterface. Then, the participants evaluated a set of conflicts and sub-\nmitted their responses. One of the authors was on the teams call\nto help participants navigate the interface and ask any clarifying\nquestions based on their evaluation of the MergeBERT resolution\nsuggestions. Questions were iteratively developed based on two pi-\nlot interviews. Each interview was recorded for transcription and\nanalysis.\n9.2 User Study Results\nRQ4: How do users perceive MergeBERT resolutions?\nUsing the interface participants evaluate the conflict resolution\nsuggestions generated by MergeBERT and indicate if any of the\nsuggestions were acceptable, and explain why or why not. There\nwere no noticeable differences in the participantsâ€™ responses across\ndifferent languages or projects so we do not break down our results\nby those dimensions. Participantâ€™s evaluations of the merge sugges-\ntions generally fall into three categories: 1) the merge suggestion\nis correct and would be used to resolve the conflict 2) the merge is\nincorrect but the correct resolution would require an understanding\nof external context and 3) the merge is incorrect and no external\ncontext is needed.\n9.2.1 Acceptable Merge Suggestions. Surprisingly, of the 122\nconflicts included in the study, participants indicated that at least one\nof the 3 suggestions generated by MergeBERT was correct for 54%\n(66/122) of the examples. By design, the suggestions presented in\nthe study are not syntactically equivalent to the participantâ€™s original\nresolution, however, they still indicated that the suggestion was a\ncorrect merge. Using participant responses, we identify a few reasons\nwhy merge suggestions may be acceptable to a developer, even if it\nis not syntactically equivalent to their original resolution:\nSemantically Equivalent Resolution (54 of 122 conflicts)\nSemantically equivalent resolutions include scenarios where the\nstatements are re-ordered, equivalent changes made to naming or\ndocumentation, and unneeded import statements or commented out\ncode is preserved or removed.\nOne example in the study of conflicting changes that are both\nequally acceptable, and one is arbitrarily accepted by the resolving\nauthor is when authors of conflicting branches renamed the same\nvariable with a slight variation:\nSPAN_TARGET_ATTRIBUTE_NAME and\nSPAN_TARGET_APP_ID_ATTRIBUTE_NAME. In these cases, either\nversion selected by the merging algorithm might still be acceptable\nto the developer. MERGE BERT generated a suggestion to keep the\nvariable name SPAN_TARGET_ATTRIBUTE_NAME whereas the user\nresolution originally kept the other. Participant P5 marked this reso-\nlution as acceptable and semantically equivalent, explaining that in\nthis scenario they had â€˜no preference as to which one is betterâ€™.\nTakeaway 1: Evaluating the performance of MergeBERT using\nstrict syntactic approaches estimates a lower bound of perfor-\nmance. Survey results show almost 45% of MergeBERT sugges-\ntions are acceptable merges that are semantically equivalent to\nthe participantâ€™s original resolution. MergeBERTâ€™s performance\ncould be improved by considering semantic information, for exam-\nple, to identify how changes related to naming or documentation\nshould be merged.\nTangled Code Changes in Oracle (10/122)\nResolutions for 10 of the conflicts contained additional â€œtangledâ€\nchanges [23, 29] that were unrelated to the resolution. Examples\ninclude renaming a method and adding a variable in the conflict\nregion that is then used later outside the conflict region. In all 10\ninstances, MERGE BERT generates a suggestion that does not include\nthe additional tangled code, but is acceptable to the participant as\na resolution of the conflict. Participants indicated that if they had\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\naccess to the MERGE BERT suggestions, they would select the correct\nresolution and then manually add the additional code.\nTakeaway 2: When committing merged code, developers may\nintroduce changes unrelated to the conflict which are inadver-\ntently included in conflict resolution oracles. These changes can\nnegatively impact model performance estimated with automatic\nmetrics.\n9.2.2 Merge Requires External Context.MERGE BERT did not\ngenerate an acceptable suggestion for 46% (56/122) of examples\nshown to survey participants. Participants were asked to indicate\nwhether they resolved these examples using external context that\ncannot be inferred from the conflicting code regions and to explain\nwhat the external context was. Results indicate that 16% (20/122)\nof conflicts in the survey sample require external information not\nfound in either conflicting file, in order to be correctly resolved. One\nexample of external context is knowledge of linter rules enabled\nat a project level. Projects often require linter checks before code\ncan be committed to the repository, as a step towards improving\nthe quality and maintainability of the source code. One example\nis a merge conflict from Roslyn where the correct resolution was\nto remove a null check from the code. Participant P23 explained\nthe decision to remove the check: \"The previousResults parameter\nis non-nullable because C# nullability checking is now enabled at\nthe project level. The null check is unnecessary\" . In this scenario,\nwithout specific knowledge of linter checks, an automatic approach\nis unable to predict an accurate merge.\nAnother example of external context is updates to languages\nrules that have cascading effects on existing code. Participant P22\nfrom the Roslyn project explained one such conflict: \"Changes were\ndue to updates in â€™ usingâ€™ rules for the C# language\". Language\nupdates in C# version 8.0 introduced an alternative syntax for the\nusing statement and P22â€™s team had made to adopt this syntax.\nP22 therefore updated this code (involved in the conflict) during the\nmerge. Other examples of external context identified through the\nsurvey include: removal of global dependencies from non-conflicting\nfiles within a project, rolling back features that shouldnâ€™t be included\nin a release branch, and project-level decisions to remove â€™finalâ€™\nmodifiers for variables.\nTakeaway 3: The local view of a conflict is sufficient to merge a\nmajority of conflicts. Around 16% of the conflicts require external\ninformation to correctly resolve. One direction to improve Merge-\nBERT is to consider external context as an additional information\nsource for resolving conflicts.\n9.2.3 Unacceptable Merge Suggestions. Survey results show\nthat MERGE BERT suggestions were incorrect for 29% (36/122) of\nthe conflicts. Participants indicated that none of the 36 conflicts\nrequired external context to be resolved. We manually analyze the\nconflicts looking to identify patterns that may explain the incorrect\nmerges, for example, affected language construct [34] and type of\nconflict [40], but do not identify any consistent patterns. In summary,\nexisting automatic evaluation strategies estimate a lower bound of\napproach performance: MergeBERT suggestions are correct for 54%\nof conflicts included in our sample, despite not being syntactically\nequivalent to the user resolution. Further, suggestions from Merge-\nBERT helped two participants find bugs in their own recent merge\nconflict resolutions! This is in addition to those resolutions where\nMergeBERT does provide an exact match. This finding suggests\nthat automatic evaluation techniques that rely on a strict syntactic\ncomparison between the user resolution and merge suggestion might\nbe estimating a much lower bound of performance. This highlights\na discrepancy between how approaches are typically automatically\nevaluated, and how developers may evaluate an approach in practice.\nResearchers should consider conducting user studies to more accu-\nrately evaluate approaches when feasible. Tools like MergeBERT\ncan reduce effort and bug proneness involved in manually merging\nconflicts. Future studies should investigate these potential benefits.\n9.3 Related Work\nThere have been multiple attempts to improve merge algorithms\nby restricting them to a particular programming language or a spe-\ncific type of applications [ 32]. Typically, such attempts result in\nalgorithms that do not scale well or have low coverage. Syntactic\nmerge algorithms improve upon diff3 by verifying the syntac-\ntic correctness of the merged programs. Several syntactic program\nmerge techniques have been proposed [5, 52] which are based on\nparse trees or ASTs and graphs.\nApel et al. noted that structured and unstructured merge each has\nstrengths and weaknesses. They developed FSTM ERGE , a semi-\nstructured merge, that alternates between approaches [4]. Tavares et\nal. implemented JSFSTM ERGE by adapting an off-the-shelf gram-\nmar for JavaScript to address shortcomings of FSTM ERGE and also\nmodifying the FSTM ERGE algorithm itself [49]. Cavalcanti et al.\nperformed a large scale retrospective evaluation of semi-structure\nmerge on over 30,000 merges and found that it can still suffer from\nfalse negatives, cases where there is actually a semantic conflict\nbut the merge approach produces a (incorrect) resolution [10]. They\nimprove FSTM ERGE by adding â€œhandlersâ€ that check for common\nfalse negative cases ( e.g. renames, added references to modified\nelements) that remove these cases completely. LeÃŸenich noted that\nusing AST representations works well for merge, but differencing\nis NP-hard due to renamings and shifted code. They propose an ap-\nproach to improve performance of the JDIME algorithm at minimal\ncost [30]. Dinella et al. take a data driven approach to the merge\nconflict resolution problem and introduce DEEP MERGE , a deep neu-\nral network that uses a pointer network architecture to construct the\nresolution from lines in the different input versions of the code [15].\nFinally, Sousa et al. [46] explore the use of program verification\nto certify that a merge obeys a semantic correctness criteria, but does\nnot help synthesize resolutions. On the other hand, Pan et al . [35]\nexplore using program synthesis to learn repeated merge resolutions\nwithin a project. However, the approach is limited to a single C++\nproject, and only deals with restricted cases of import statements.\n9.3.1 Empirical Studies. Several empirical studies have investi-\ngated merge conflicts and challenges faced by developers in merge\nresolution. McKee et al. [ 31] and Nelson et al. [ 33] interviewed\ndevelopers and performed a follow-up survey with 162 developers\nto build a detailed understanding of developer perceptions regarding\nmerge conflicts in general. They found, among other things, that\ncomplexity of the conflicting lines of code and file as a whole, the\nProgram Merge Conflict Resolution via Neural Transformers ESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore\nnumber of LOC in the conflict, and developersâ€™ familiarity with\nthe conflicting lines of code impact how difficult developers find a\nconflict to resolve. Brindescu et al. investigated the impact of merge\nconflicts and their resolutions on software quality [7, 8]. They found\nthat 20% of code changes resulted in a merge conflict and the code in\nthese conflicts were twice as likely to contain bugs as other changes.\nFurther, if the changes included semantically interacting changes,\nthe likelihood of a defect is 26 times that of non-conflicting changes.\nCosta et al. presented TIPMerge, an approach for identifying and\nrecommending developers to participate in merge sessions when\nresolving conflicts [12]. They evaluated it on 2,040 merges across\n25 open source projects and found that TIPMerge can improve joint\nknowledge coverage by an average of 49% in merge scenarios [13].\nVale et al. [51] performed an empirical study to understand what\nmakes merge challenging for developers. Through a large scale\nautomated analysis and a survey of 140 developers, they identified\nfactors that contribute to merge conflict resolution difficulty (e.g.,\nnumber of chunks in the conflict and number of developers involved\nin the merge scenario). Seibt et al. [37] explore and evaluate merge\nalgorithms on a suite of ten software repositories, paying attention\nto the amount of resolutions produced, size of conflict, runtime cost,\nand correctness. Interestingly, they use the test suites of each project\nas an oracle to assess correctness of code after the merge.\nNone of the existing studies evaluate automatic merge resolution\ntools with software developers on their own real-world conflicts.\nThe participants in our survey have expertise to understand when\nMergeBERT resolution suggestions would be acceptable on their\nown real-world conflicts, providing rich explanations about when\nexternal context is required, or when tangled code changes are made.\n10 THREATS TO V ALIDITY\nThe choice of hyper-parameters in our model (Section 5.3) is based\non prior work of others and generally accepted norms [14]. Itâ€™s pos-\nsible that exploring the hyper-parameter space could yield different\nresults. The sample of conflicts and projects used in the study may\npose a threat to the external validity of our work. We only considered\npublic open-source projects hosted on GitHub, therefore, results may\nnot generalize to closed source projects or repositories hosted on\nother platforms. To mitigate this threat, we select a diverse set of\nprojects varying in size and language. Similarly, survey participants\nevaluate their own recently-merged conflicts and the set of conflicts\nused in the survey to answer RQ4 may not be a representative sam-\nple, as it was dependent on participant availability. We filtered out\nmerge conflicts from the user study that we considered to be â€œtriv-\nialâ€ conflicts. This was a subjective judgement, but we did aim to\nselect substantive conflicts in the hopes that they would elicit more\nvaluable and informative feedback from participants. The survey\ninterface replicates the VSCode diff3 view. Participants not familiar\nwith this view may have a harder time navigating the conflict view\nand answering survey questions, to mitigate this threat, we create an\ninstructional video for participants to watch.\n11 CONCLUSION\nThis paper introduces MergeBERT, a transformer-based program\nmerge framework that leverages token-level differencing and refor-\nmulates the task of generating the resolution sequence as a classi-\nfication task over a set of primitive merge patterns extracted from\nreal-world merge commit data. MergeBERT exploits pretraining over\nmassive amounts of code and then finetuning on specific program-\nming languages, achieving 64â€“69% precision and 63â€“68% recall\nof merge resolution synthesis. Lastly, MergeBERT is flexible and\neffective, capable of resolving more conflicts than the existing tools\nin multiple programming languages.\nTo better evaluate the resolutions generated by MergeBERT from\nthe perspective of users, we conduct a user study with 25 developers\nfrom large OSS projects. We ask participants to evaluate whether\nMergeBERT resolution suggestions are acceptable on a set of 122 of\ntheir own real-world conflicts. Results suggest, in practice, Merge-\nBERT resolutions would likely be accepted at a higher rate than\nestimated by the performance metrics chosen. Using participant\nfeedback we identify potential ways to improve MergeBERT by im-\nproving the oracle to remove tangled changes or considering external\ncontext â€“ project or team level information that is not present in the\nconflicting files.\nREFERENCES\n[1] Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu, and Charles Sutton. 2018.\nA Survey of Machine Learning for Big Code and Naturalness. ACM Comput. Surv.\n51, 4, Article 81 (July 2018), 37 pages. https://doi.org/10.1145/\n3212695\n[2] Sven Apel, Olaf LeÃŸenich, and Christian Lengauer. 2012. Structured merge\nwith auto-tuning: balancing precision and performance. In Proceedings of the\n27th IEEE/ACM International Conference on Automated Software Engineering.\n120â€“129.\n[3] Sven Apel, JÃ¶rg Liebig, Benjamin Brandl, Christian Lengauer, and Christian\nKÃ¤stner. 2011. Semistructured Merge: Rethinking Merge in Revision Control\nSystems. In Proceedings of the 19th ACM SIGSOFT Symposium and the 13th\nEuropean Conference on Foundations of Software Engineering(Szeged, Hungary)\n(ESEC/FSE â€™11). Association for Computing Machinery, New York, NY , USA,\n190â€“200. https://doi.org/10.1145/2025113.2025141\n[4] Sven Apel, JÃ¶rg Liebig, Christian Lengauer, Christian KÃ¤stner, and William R\nCook. 2010. Semistructured Merge in Revision Control Systems.. In VaMoS.\n13â€“19.\n[5] Ulf Asklund. 1999. Identifying Conflicts During Structural Merge.\n[6] Christian Bird and Thomas Zimmermann. 2012. Assessing the value of branches\nwith what-if analysis. In Proceedings of the ACM SIGSOFT 20th International\nSymposium on the Foundations of Software Engineering. 1â€“11.\n[7] Caius Brindescu, Iftekhar Ahmed, Carlos Jensen, and Anita Sarma. 2020. An\nempirical investigation into merge conflicts and their effect on software quality.\nEmpirical Software Engineering 25, 1 (2020), 562â€“590.\n[8] Caius Brindescu, Yenifer Ramirez, Anita Sarma, and Carlos Jensen. 2020. Lifting\nthe Curtain on Merge Conflict Resolution: A Sensemaking Perspective. In 2020\nIEEE International Conference on Software Maintenance and Evolution (ICSME).\nIEEE, 534â€“545.\n[9] Yuriy Brun, Reid Holmes, Michael D Ernst, and David Notkin. 2011. Proactive\ndetection of collaboration conflicts. In Proceedings of the 19th ACM SIGSOFT\nsymposium and the 13th European conference on Foundations of software engi-\nneering. 168â€“178.\n[10] Guilherme Cavalcanti, Paulo Borba, and Paola Accioly. 2017. Evaluating and\nimproving semistructured merge. Proceedings of the ACM on Programming\nLanguages 1, OOPSLA (2017), 1â€“27.\n[11] Colin Clement, Dawn Drain, Jonathan Timcheck, Alexey Svyatkovskiy, and Neel\nSundaresan. 2020. PyMT5: Multi-mode Translation of Natural Language and\nPython Code with Transformers. In Proceedings of the 2020 Conference on\nEmpirical Methods in Natural Language Processing (EMNLP). 9052â€“9065.\n[12] Catarina Costa, Jair Figueiredo, Leonardo Murta, and Anita Sarma. 2016. Tip-\nmerge: recommending experts for integrating changes across branches. InProceed-\nings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of\nSoftware Engineering. 523â€“534.\n[13] Catarina de Souza Costa, Jose Jair Figueiredo, Joao Felipe Pimentel, Anita Sarma,\nand Leonardo Gresta Paulino Murta. 2019. Recommending Participants for\nCollaborative Merge Sessions. IEEE Transactions on Software Engineering\n(2019).\n[14] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding. In\nProceedings of the 2019 Conference of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Language Technologies, Volume 1\nESEC/FSE â€™22, November 14â€“18, 2022, Singapore, Singapore Svyatkovskiy, Fakhoury, Ghorbani, Mytkowicz, Dinella, Bird, Jang, Sundaresan, Lahiri\n(Long and Short Papers). Association for Computational Linguistics, Minneapolis,\nMinnesota, 4171â€“4186. https://doi.org/10.18653/v1/N19-\n1423\n[15] Elizabeth Dinella, Todd Mytcowicz, Alexey Svyatkovskiy, Christian Bird, Mayur\nNaik, and Shuvendu Lahiri. 2021. DeepMerge: Learning to merge programs.\narXiv:2105.07569 https://arxiv.org/abs/2105.07569\n[16] Jean-RÃ©my Falleri, FlorÃ©al Morandat, Xavier Blanc, Matias Martinez, and Mar-\ntin Monperrus. 2014. Fine-grained and accurate source code differencing.\nIn ACM/IEEE International Conference on Automated Software Engineering,\nASE â€™14, Vasteras, Sweden - September 15 - 19, 2014 . 313â€“324. https:\n//doi.org/10.1145/2642937.2642982\n[17] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,\nLinjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT:\nA Pre-Trained Model for Programming and Natural Languages. In Findings of\nthe Association for Computational Linguistics: EMNLP 2020 . Association for\nComputational Linguistics, Online, 1536â€“1547. https://doi.org/10.\n18653/v1/2020.findings-emnlp.139\n[18] Authors Elided for Review. 2022.Appendix to Program Merge Conflict Resolution\nvia Neural Transformers. https://doi.org/10.5281/zenodo.\n6366877\n[19] Authors Elided for Review. 2022. Online Data Set for Program Merge Conflict\nResolution via Neural Transformers. https://doi.org/10.5281/\nzenodo.6366908\n[20] Gleiph Ghiotto, Leonardo Murta, MÃ¡rcio Barros, and Andre Van Der Hoek. 2018.\nOn the nature of merge conflicts: a study of 2,731 open source java projects hosted\nby github. IEEE Transactions on Software Engineering 46, 8 (2018), 892â€“915.\n[21] Georgios Gousios, Margaret-Anne Storey, and Alberto Bacchelli. 2016. Work\npractices and challenges in pull-based development: the contributorâ€™s perspective.\nIn 2016 IEEE/ACM 38th International Conference on Software Engineering\n(ICSE). IEEE, 285â€“296.\n[22] MÃ¡rio LuÃ­s GuimarÃ£es and AntÃ³nio Rito Silva. 2012. Improving early detection\nof software merge conflicts. In 2012 34th International Conference on Software\nEngineering (ICSE). IEEE, 342â€“352.\n[23] Kim Herzig and Andreas Zeller. 2013. The Impact of Tangled Code Changes. In\nProceedings of the Working Conference on Mining Software Repositories (MSR).\n121â€“130.\n[24] Abram Hindle, Earl T. Barr, Zhendong Su, Mark Gabel, and Premkumar Devanbu.\n2012. On the Naturalness of Software. In Proceedings of the 34th International\nConference on Software Engineering (Zurich, Switzerland) (ICSE â€™12). IEEE\nPress, 837â€“847.\n[25] JDime. 2022. JDime Publicly Available Implementation. https://github.\ncom/se-sic/jdime\n[26] Aditya Kanade, Petros Maniatis, Gogul Balakrishnan, and Kensen Shi. 2020.\nLearning and evaluating contextual embedding of source code. In International\nConference on Machine Learning. PMLR, 5110â€“5121.\n[27] Rafael-Michael Karampatsis, Hlib Babii, Romain Robbes, Charles Sutton, and\nAndrea Janes. 2020. Big Code Ì¸= Big V ocabulary: Open-V ocabulary Models for\nSource Code. In Proceedings of the ACM/IEEE 42nd International Conference on\nSoftware Engineering(Seoul, South Korea)(ICSE â€™20). Association for Computing\nMachinery, New York, NY , USA, 1073â€“1085. https://doi.org/10.\n1145/3377811.3380342\n[28] Bakhtiar Khan Kasi and Anita Sarma. 2013. Cassandra: Proactive conflict mini-\nmization through optimized task scheduling. In 2013 35th International Confer-\nence on Software Engineering (ICSE). IEEE, 732â€“741.\n[29] Hiroyuki Kirinuki, Yoshiki Higo, Keisuke Hotta, and Shinji Kusumoto. 2014.\nHey! Are You Committing Tangled Changes?. InProceedings of the International\nConference on Program Comprehension (ICPC).\n[30] Olaf LeÃŸenich, Sven Apel, Christian KÃ¤stner, Georg Seibt, and Janet Siegmund.\n2017. Renaming and shifted code in structured merging: Looking ahead for\nprecision and performance. In 2017 32nd IEEE/ACM International Conference on\nAutomated Software Engineering (ASE). IEEE, 543â€“553.\n[31] Shane McKee, Nicholas Nelson, Anita Sarma, and Danny Dig. 2017. Software\npractitioner perspectives on merge conflicts and resolutions. In 2017 IEEE Inter-\nnational Conference on Software Maintenance and Evolution (ICSME) . IEEE,\n467â€“478.\n[32] Tom Mens. 2002. A state-of-the-art survey on software merging. IEEE transac-\ntions on software engineering 28, 5 (2002), 449â€“462.\n[33] Nicholas Nelson, Caius Brindescu, Shane McKee, Anita Sarma, and Danny Dig.\n2019. The life-cycle of merge conflicts: processes, barriers, and strategies. Empir-\nical Software Engineering 24, 5 (2019), 2863â€“2906.\n[34] Rangeet Pan, Vu Le, Nachiappan Nagappan, Sumit Gulwani, Shuvendu Lahiri, and\nMike Kaufman. 2021. Can Program Synthesis be Used to Learn Merge Conflict\nResolutions? An Empirical Analysis. In 2021 IEEE/ACM 43rd International\nConference on Software Engineering (ICSE). IEEE, 785â€“796.\n[35] Rangeet Pan, Vu Le, Nachiappan Nagappan, Sumit Gulwani, Shuvendu K. Lahiri,\nand Mike Kaufman. 2021. Can Program Synthesis be Used to Learn Merge\nConflict Resolutions? An Empirical Analysis. CoRR abs/2103.02004 (2021).\narXiv:2103.02004 https://arxiv.org/abs/2103.02004\n[36] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya\nSutskever. 2019. Language Models are Unsupervised Multitask Learners. (2019).\n[37] Georg Seibt, Florian Heck, Guilherme Cavalcanti, Paulo Borba, and Sven Apel.\n2021. Leveraging Structure in Software Merge: An Empirical Study. IEEE\nTransactions on Software Engineering (2021).\n[38] Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020. BLEURT: Learning\nRobust Metrics for Text Generation. In Proceedings of the 58th Annual Meeting\nof the Association for Computational Linguistics. Association for Computational\nLinguistics, Online, 7881â€“7892. https://doi.org/10.18653/v1/\n2020.acl-main.704\n[39] Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural Machine\nTranslation of Rare Words with Subword Units. In Proceedings of the 54th An-\nnual Meeting of the Association for Computational Linguistics (Volume 1: Long\nPapers). Association for Computational Linguistics, Berlin, Germany, 1715â€“1725.\nhttps://doi.org/10.18653/v1/P16-1162\n[40] Bowen Shen, Cihan Xiao, Na Meng, and Fei He. 2021. Automatic Detection\nand Resolution of Software Merge Conflicts: Are We There Yet? arXiv preprint\narXiv:2102.11307 (2021).\n[41] Bo Shen, Wei Zhang, Haiyan Zhao, Guangtai Liang, Zhi Jin, and Qianxiang Wang.\n2019. IntelliMerge: a refactoring-aware software merging technique. Proceedings\nof the ACM on Programming Languages 3, OOPSLA (2019), 1â€“28.\n[42] R. Smith. 1998. GNU diff3. distributed with GNU diffutils package.\n[43] Codice Software. 2021. SemanticMerge. https://www.\nsemanticmerge.com.\n[44] Scooter Software. 2021. Beyond Compare. https://www.\nscootersoftware.com.\n[45] Marcelo Sousa, Isil Dillig, and Shuvendu K Lahiri. 2018. Verified three-way\nprogram merge. Proceedings of the ACM on Programming Languages2, OOPSLA\n(2018), 1â€“29.\n[46] M. Sousa, I. Dillig, and S. K. Lahiri. 2018. Verified Three-way Program Merge.\nProc. ACM Program. Lang.2 (2018), 165:1â€“165:29.\n[47] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020.\nIntellicode compose: Code generation using transformer. In Proceedings of the\n28th ACM Joint Meeting on European Software Engineering Conference and\nSymposium on the Foundations of Software Engineering. 1433â€“1443.\n[48] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020.\nIntelliCode Compose: Code Generation Using Transformer. In Proceedings of\nthe 28th ACM Joint Meeting on European Software Engineering Conference and\nSymposium on the Foundations of Software Engineering (Virtual Event, USA)\n(ESEC/FSE 2020). Association for Computing Machinery, New York, NY , USA,\n1433â€“1443. https://doi.org/10.1145/3368089.3417058\n[49] Alberto Trindade Tavares, Paulo Borba, Guilherme Cavalcanti, and SÃ©rgio Soares.\n2019. Semistructured merge in JavaScript systems. In 2019 34th IEEE/ACM\nInternational Conference on Automated Software Engineering (ASE). IEEE, 1014â€“\n1025.\n[50] Alberto Trindade Tavares, Paulo Borba, Guilherme Cavalcanti, and SÃ©rgio Soares.\n2019. Semistructured Merge in JavaScript Systems. In 2019 34th IEEE/ACM\nInternational Conference on Automated Software Engineering (ASE). 1014â€“1025.\nhttps://doi.org/10.1109/ASE.2019.00098\n[51] Gustavo Vale, Claus Hunsen, Eduardo Figueiredo, and Sven Apel. 2021. Chal-\nlenges of Resolving Merge Conflicts: A Mining and Survey Study. IEEE Transac-\ntions on Software Engineering (2021).\n[52] Bernhard Westfechtel. 1991. Structure-oriented merging of revisions of soft-\nware documents. In Proceedings of the 3rd international workshop on Software\nconfiguration management. 68â€“79.\n[53] Fengmin Zhu and Fei He. 2018. Conflict resolution for structured merge via\nversion space algebra. Proceedings of the ACM on Programming Languages 2,\nOOPSLA (2018), 1â€“25.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7537019848823547
    },
    {
      "name": "Merge (version control)",
      "score": 0.5002264976501465
    },
    {
      "name": "Software",
      "score": 0.48012375831604004
    },
    {
      "name": "Java",
      "score": 0.462515264749527
    },
    {
      "name": "Software engineering",
      "score": 0.37351828813552856
    },
    {
      "name": "Programming language",
      "score": 0.3607962727546692
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3597981035709381
    },
    {
      "name": "Information retrieval",
      "score": 0.18545138835906982
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1290206253",
      "name": "Microsoft (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I72951846",
      "name": "Washington State University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I204250578",
      "name": "University of California, Irvine",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I36788626",
      "name": "California University of Pennsylvania",
      "country": "US"
    }
  ],
  "cited_by": 22
}