{
  "title": "A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study",
  "url": "https://openalex.org/W4396775553",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A182589101",
      "name": "Bambang Parmanto",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2575874647",
      "name": "Bayu Aryoyudanta",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5106576067",
      "name": "Timothius Wilbert Soekinto",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2303934007",
      "name": "I Made Agus Setiawan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2117947532",
      "name": "Yuhan Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2262219166",
      "name": "Haomin Hu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2159266267",
      "name": "Andi Saptono",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2111599454",
      "name": "Yong-Kyung Choi",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3006430384",
    "https://openalex.org/W1792623909",
    "https://openalex.org/W2984261255",
    "https://openalex.org/W2027365236",
    "https://openalex.org/W122237833",
    "https://openalex.org/W2056830272",
    "https://openalex.org/W2030005411",
    "https://openalex.org/W2520560270",
    "https://openalex.org/W4281703518",
    "https://openalex.org/W3006572770",
    "https://openalex.org/W2318304706",
    "https://openalex.org/W4280608615",
    "https://openalex.org/W2919115771",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4385381606",
    "https://openalex.org/W4322761615",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4323050332",
    "https://openalex.org/W3164447366",
    "https://openalex.org/W4386155683",
    "https://openalex.org/W4391221150",
    "https://openalex.org/W4324309277",
    "https://openalex.org/W4296085637",
    "https://openalex.org/W2032568497",
    "https://openalex.org/W4380538374",
    "https://openalex.org/W4221106857",
    "https://openalex.org/W3206840963",
    "https://openalex.org/W4393335480",
    "https://openalex.org/W1276312578",
    "https://openalex.org/W2497265084"
  ],
  "abstract": "Background In the United States, 1 in 5 adults currently serves as a family caregiver for an individual with a serious illness or disability. Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Thus, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Leveraging technology as an educational tool or an adjunct to care is a promising approach that has the potential to enhance the learning and caregiving capabilities of family caregivers. Large language models (LLMs) can potentially be used as a foundation technology for supporting caregivers. An LLM can be categorized as a foundation model (FM), which is a large-scale model trained on a broad data set that can be adapted to a range of different domain tasks. Despite their potential, FMs have the critical weakness of “hallucination,” where the models generate information that can be misleading or inaccurate. Information reliability is essential when language models are deployed as front-line help tools for caregivers. Objective This study aimed to (1) develop a reliable caregiving language model (CaLM) by using FMs and a caregiving knowledge base, (2) develop an accessible CaLM using a small FM that requires fewer computing resources, and (3) evaluate the model’s performance compared with a large FM. Methods We developed a CaLM using the retrieval augmented generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. The key components of the CaLM are the caregiving knowledge base, a fine-tuned FM, and a retriever module. We used 2 small FMs as candidates for the foundation of the CaLM (LLaMA [large language model Meta AI] 2 and Falcon with 7 billion parameters) and adopted a large FM (GPT-3.5 with an estimated 175 billion parameters) as a benchmark. We developed the caregiving knowledge base by gathering various types of documents from the internet. We focused on caregivers of individuals with Alzheimer disease and related dementias. We evaluated the models’ performances using the benchmark metrics commonly used in evaluating language models and their reliability for providing accurate references with their answers. Results The RAG framework improved the performance of all FMs used in this study across all measures. As expected, the large FM performed better than the small FMs across all metrics. Interestingly, the small fine-tuned FMs with RAG performed significantly better than GPT 3.5 across all metrics. The fine-tuned LLaMA 2 with a small FM performed better than GPT 3.5 (even with RAG) in returning references with the answers. Conclusions The study shows that a reliable and accessible CaLM can be developed using small FMs with a knowledge base specific to the caregiving domain.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5369484424591064
    },
    {
      "name": "Quality (philosophy)",
      "score": 0.5219654440879822
    },
    {
      "name": "Set (abstract data type)",
      "score": 0.4841104745864868
    },
    {
      "name": "Reliability (semiconductor)",
      "score": 0.45361873507499695
    },
    {
      "name": "Family caregivers",
      "score": 0.4125683009624481
    },
    {
      "name": "Psychology",
      "score": 0.3495466411113739
    },
    {
      "name": "Medicine",
      "score": 0.18885591626167297
    },
    {
      "name": "Nursing",
      "score": 0.11432603001594543
    },
    {
      "name": "Epistemology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Power (physics)",
      "score": 0.0
    },
    {
      "name": "Philosophy",
      "score": 0.0
    }
  ],
  "institutions": [],
  "cited_by": 19
}