{
  "title": "Improvement of Performance in Freezing of Gait detection in Parkinson’s Disease using Transformer networks and a single waist-worn triaxial accelerometer",
  "url": "https://openalex.org/W4302763498",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2619437598",
      "name": "Luis Sigcha",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1985237424",
      "name": "Luigi Borzì",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2942258475",
      "name": "Ignacio Pavón",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2135497349",
      "name": "Nelson Costa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2114304268",
      "name": "Susana Costa",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3178180309",
      "name": "Pedro Arezes",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A819466458",
      "name": "Juan Manuel Lopez.",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1969174763",
      "name": "Guillermo De Arcas",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3175915085",
    "https://openalex.org/W3140854437",
    "https://openalex.org/W2054036102",
    "https://openalex.org/W2128892560",
    "https://openalex.org/W3158621908",
    "https://openalex.org/W3031695135",
    "https://openalex.org/W3121614540",
    "https://openalex.org/W3040987818",
    "https://openalex.org/W3089167295",
    "https://openalex.org/W2911964244",
    "https://openalex.org/W2765693785",
    "https://openalex.org/W3208249902",
    "https://openalex.org/W3120367919",
    "https://openalex.org/W2986888469",
    "https://openalex.org/W2945504666",
    "https://openalex.org/W3170120958",
    "https://openalex.org/W4225162219",
    "https://openalex.org/W2103919309",
    "https://openalex.org/W3044651858",
    "https://openalex.org/W1968018273",
    "https://openalex.org/W2013818400",
    "https://openalex.org/W6631943919",
    "https://openalex.org/W2157825442",
    "https://openalex.org/W6768547015",
    "https://openalex.org/W2064996887",
    "https://openalex.org/W2796449461",
    "https://openalex.org/W2338565696",
    "https://openalex.org/W3120766175",
    "https://openalex.org/W6758971952",
    "https://openalex.org/W3100117095",
    "https://openalex.org/W2999749474",
    "https://openalex.org/W2942630870",
    "https://openalex.org/W3120879559",
    "https://openalex.org/W3158559908",
    "https://openalex.org/W2897762618",
    "https://openalex.org/W2952199022",
    "https://openalex.org/W2171181994",
    "https://openalex.org/W2025926226",
    "https://openalex.org/W2122354382",
    "https://openalex.org/W2972942705",
    "https://openalex.org/W6810798322",
    "https://openalex.org/W2114134396",
    "https://openalex.org/W2145362071",
    "https://openalex.org/W2108572733",
    "https://openalex.org/W3194049625",
    "https://openalex.org/W2159552567",
    "https://openalex.org/W2132202626",
    "https://openalex.org/W2766915324",
    "https://openalex.org/W2062804064",
    "https://openalex.org/W6770295958",
    "https://openalex.org/W4225123941",
    "https://openalex.org/W2999579305",
    "https://openalex.org/W2141145756",
    "https://openalex.org/W3048212674",
    "https://openalex.org/W2079985134",
    "https://openalex.org/W2588989789",
    "https://openalex.org/W2763160983",
    "https://openalex.org/W2913141042",
    "https://openalex.org/W2136883398",
    "https://openalex.org/W3216913559",
    "https://openalex.org/W3156725333",
    "https://openalex.org/W3013838736",
    "https://openalex.org/W2592073184",
    "https://openalex.org/W2152062145",
    "https://openalex.org/W6742551766",
    "https://openalex.org/W2922088053",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W2019934350",
    "https://openalex.org/W2127700844",
    "https://openalex.org/W3003958915",
    "https://openalex.org/W2990845518",
    "https://openalex.org/W3159778524",
    "https://openalex.org/W3217525002",
    "https://openalex.org/W4286949165",
    "https://openalex.org/W2114808721",
    "https://openalex.org/W2912552271",
    "https://openalex.org/W2975006071",
    "https://openalex.org/W1522301498",
    "https://openalex.org/W2556522401",
    "https://openalex.org/W2742919113",
    "https://openalex.org/W4301481543",
    "https://openalex.org/W1547089042",
    "https://openalex.org/W4226419212"
  ],
  "abstract": null,
  "full_text": "Improvement of Performance in Freezing of Gait \ndetection in Parkinson’s Disease using Transformer \nnetworks and a single waist-worn triaxial accelerometer \nLuis Sigchaa,b, Luigi Borzìc, Ignacio Pavóna,∗, Nélson Costab, Susana Costab, Pedro Arezesb, Juan \nManuel Lópeza, Guillermo De Arcasa \naInstrumentation and Applied Acoustics Research Group (I2A2), ETSI Industriales, Universidad Politécnica de \nMadrid, Campus Sur UPM, Ctra. Valencia, Km 7, 28031 Madrid, Spain \nbALGORITMI Research Center, School of Engineering, University of Minho, 4800-058 Guimar˜aes, Portugal \ncDepartment of Control and Computer Engineering, Politecnico di Torino, 10129 Turin, Italy \n \nAbstract \nFreezing of gait (FOG) is one of the most incapacitating symptoms in Parkinson’s disease, affecting \nmore than 50% of patients in advanced stages of the disease. The presence of FOG may lead to falls \nand a loss of independence with a consequent reduction in the quality of life. Wearable technology \nand artificial intelligence have been used for automatic FOG detection to optimize monitoring. \nHowever, differences between laboratory and daily-life conditions present challenges for the \nimplementation of reliable detection systems. Consequently, improvement of FOG detection \nmethods remains important to provide accurate monitoring mechanisms intended for free-living and \nreal-time use. This paper presents advances in automatic FOG detection using a single body-worn \ntriaxial accelerometer and a novel classification algorithm based on Transformers and convolutional \nnetworks. This study was performed with data from 21 patients who manifested FOG episodes while \nperforming activities of daily living in a home setting. Results indicate that the proposed FOG-\nTransformer can bring a significant improvement in FOG detection using leave-one-subject-out cross- \nvalidation (LOSO CV). These results bring opportunities for the implementation of accurate \nmonitoring systems for use in ambulatory or home settings. \nKeywords: freezing of gait, Parkinson’s disease, wearable sensors, machine learning, deep learning, \nconvolutional neural networks, transformers, sequence analysis \n∗Corresponding author: ETSI Industriales, Universidad Politécnica de Madrid, Campus Sur UPM, Ctra. \nValencia, Km 7, 28031 Madrid, Spain. Tel.: +34-91-067-7222 \nEmail addresses: luisfrancisco.sigcha@upm.es (Luis Sigcha), luigi.borzi@polito.it (Luigi Borzì), \nignacio.pavon@upm.es (Ignacio Pavón), ncosta@dps.uminho.pt (Nélson Costa), \nsusana.costa@dps.uminho.pt (Susana Costa), parezes@dps.uminho.pt (Pedro Arezes), \njuanmanuel.lopez@upm.es (Juan Manuel López), g.dearcas@upm.es (Guillermo De Arcas) \n  \n1. Introduction \nFreezing of gait (FOG) is one of the most disabling symptoms in Parkinson’s disease (PD), \ncharacterized by brief episodes of inability to step or the presence of short steps when initiating gait, \non turning while walking (Nutt et al., 2011)  or when experiencing stressful situations (Nonnekes et \nal., 2015). FOG affects between 50% and 80% of people with PD (Weiss et al., 2015), and its presence \nis associated with an increased risk of falls, affecting the quality of life (Moore et al., 2007). \nWhen a FOG episode appears, PD patients can present variability in the gait pattern, with a reduction \nin step length, shuffling steps, trembling of the legs, and total akinesia with a loss of movement of \nthe limbs or trunk (Okuma, 2014). FOG episodes can have a duration of a few seconds (1 second or \nless for very short episodes and more than 5 seconds for long episodes) and appear more frequently \nduring typical daily-life conditions than during straight walking assessments in clinical and laboratory \nsettings (Okuma, 2014; Nonnekes et al., 2015). \nFOG assessment involves the identification of the presence (or absence) of FOG episodes and also \naims to identify their severity (Mancini et al., 2019). Assessing FOG in the clinical practice is difficult \nbecause of the lack of an optimal freezing score, and difficulties related to the clinical assessment \noften performed on conditions that hinder the appearance of FOG events during evaluation; for \nexample, the assessment is usually made in the ON state, while FOG occurs more often in OFF state \n(Schaafsma et al., 2003; Mancini et al., 2021). \nAlthough the clinical assessment provides relevant indicators for the characterization of FOG, the \nconditions whereby these are performed do not accurately represent the severity of FOG in daily life \n(Rahman et al., 2008; Snijders et al., 2008), such as the patients’ homes, where FOG events tend to \noccur more frequently (Nieuwboer et al., 1998). \nTherefore, the development of objective and reliable FOG monitoring mechanisms is necessary for \nthe proper implementation of pharmacological treatment (i.e., levodopa treatment), as well as for \nthe development of novel therapies to treat the FOG-associated symptomatology (Mancini et al., \n2019; Nonnekes et al., 2015). Consequently, an accurate and objective assessment of FOG should be \nperformed ideally during daily-life activities in home settings with the aim of assessing the full \nspectrum of the symptom, including the severity of FOG events and their fluctuations over the \ncourse of the day (Mancini et al., 2021). \nWearable devices have shown high potential for the development of systems for FOG detection in \nboth laboratory and home settings (Silva de Lima et al., 2017; Pardoel et al., 2019). They are \nequipped with sensors (i.e., accelerometers or gyroscopes) that can provide objective measures for \nthe quantification of motor symptoms (Rovini et al., 2017) such as FOG or gait disturbances, to \nimprove the monitoring of the disease progression or the effects of the treatments (Mancini et al., \n2021). In addition, the portability and low cost of wearable devices can allow the development of \naffordable systems for continuous tracking in an unobtrusive fashion without increasing the burden \non patients (Rovini et al., 2017; Monje et al., 2019; Del Din et al., 2021). \nMachine learning (ML) techniques in conjunction with wearable sensors have led to unprecedented \nperformance in a variety of applications related to motor symptom assessment (Borzì et al., 2020b; \nHeijmans et al., 2019; Borzì et al., 2020a), including FOG detection (Del Din et al., 2021; Landolfi et \nal., 2021). \nML algorithms (i.e. neural networks, decision trees, random forest, support vector machines, etc) \nhave provided methods for the development of FOG detection systems capable of surpassing the \nperformance of threshold-based methods. For this task, time and frequency-domain features have \nbeen extracted from wearable sensors located in different parts of the body and used to train models \nin supervised, unsupervised, and semi-supervised learning approaches (Pardoel et al., 2019). \nAmong the machine learning algorithms, in the last years, the use of deep learning (DL) approaches \nhas led to establishing the state-of-the-art in many domains and applications (Alzubaidi et al., 2021), \nsuch as the automatic assessment of movement disorders or the diagnosis of Parkinsonian \nsyndromes (Mei et al., 2021) including FOG detection by using mainly data collected with inertial \nsensors (San-Segundo et al., 2019; Li et al., 2020; Noor et al., 2021; Naghavi and Wade, 2021; Bikias \net al., 2021) and wearable devices (Camps et al., 2018; Sigcha et al., 2020). \nAlthough the automatic detection and prediction of FOG episodes using wearable sensors have been \na wide research area in the last years (Irrera et al., 2018), the development of improved FOG \ndetection methods remains important to provide accurate long-term FOG monitoring mechanisms \n(Borzì et al., 2021), and for the implementation of real-time cueing systems that can help to reduce \nthe occurrence of FOG episodes (Sweeney et al., 2019). \nChallenges like unpredictability, differences in movement patterns during the occurrence of freezing \nepisodes between OFF and ON states, and temporal resolution to distinguishing short freezing \nepisodes, make it difficult to implement reliable automatic FOG detection systems (Pardoel et al., \n2019). \nNovel approaches, based on DL techniques, are promising mechanisms for the development of \nimproved systems for FOG detection (Pardoel et al., 2019; Sigcha et al., 2020). The potential of these \ntechniques lies in their ability to process sequential data and inertial signals collected from different \nsensors with a minimum pre-processing and provide similar or superior performance to classic ML \nalgorithms (Sigcha et al., 2020). Despite the advantages provided by this technology, the use of DL \napproaches requires a great amount of data to obtain outperforming results (Alzubaidi et al., 2021), \nwhile the implementation of certain algorithms like recurrent neural networks (RNN) presents \nchallenges related to the length of the sequences and expensive computational requirements (Raza \net al., 2021). \nTransformer networks (Vaswani et al., 2017) were introduced for sequence to-sequence learning and \noffer improved performance at long-range sequential modelling over RNNs. These architectures were \nproposed to model dependencies over the whole range of sequential data without using recurrent \nconnections to improve efficiency (Lin et al., 2021). Transformer networks are based on attention \nmechanisms to analyze an input sequence and decide which parts of the sequence are important for \na specific task (Shavit and Klein, 2021). \nIn the last years, transformers have outperformed the RNNs in sequence- based tasks such as natural \nlanguage processing, computer vision, audio pro- cessing, etc. (Lin et al., 2021), and recently have \nbeen applied in human activity recognition based on inertial sensors (Shavit and Klein, 2021; Raza et \nal., 2021). Despite the potential advantages that this technology can provide in the analysis of \nsequential data, the use of transformer-based neural networks has not been evaluated for FOG \ndetection. \n2. Related Work \nA wide spectrum of FOG detection algorithms using wearable sensors data can be found in the \nliterature. Initially, basic threshold methods based on spectral analysis were proposed (Moore et al., \n2008; Bachlin et al., 2009). To increase the performance of the detection models, ML classification \nalgorithms were exploited in several studies (Rodríguez-Martín et al., 2017; Naghavi et al., 2019; \nBorzì et al., 2020; Demrozi et al., 2020). \nRecently, DL approaches were proposed to detect FOG, outperforming classical ML models. As far as \nthe wearable motion sensors concern, 3-axial accelerometers have been used either alone (San-\nSegundo et al., 2019; Sigcha et al., 2020; Li et al., 2020; Noor et al., 2021), in combination with 3-\naxial gyroscopes, (Camps et al., 2018; Bikias et al., 2021; Naghavi and Wade, 2021) or as part of \nmultimodal systems (Shalin et al., 2021). \nDifferent sensors’ configurations were used in different studies. The number of sensors ranges from 1 \n(Camps et al., 2018; Sigcha et al., 2020; Borzì et al., 2020) to 9 (Bikias et al., 2021; Mazilu et al., \n2013), and different sensor locations were proposed, including wrist (Bikias et al., 2021), lower back \n(Borzì et al., 2020; Zhang et al., 2020), waist (Camps et al., 2018; Sigcha et al., 2020), thigh (Noor et \nal., 2021), shank (Naghavi et al., 2019; Naghavi and Wade, 2021), or a combination of two or more \npositions (Demrozi et al., 2020; Li et al., 2020). Detailed literature reviews of the different proposed \nFOG detection methods based on wearable devices can be found in (Silva de Lima et al., 2017; \nPardoel et al., 2019; Sigcha et al., 2020). \nIn this section, recent studies published in the last two years focusing on FOG detection using DL \napproaches are described. \nThe Daphnet dataset (Bachlin et al., 2010) was used in Li et al. (2020) and Noor et al. (2021). The \ndatabase includes data from 10 PD patients while OFF therapy, of which 8 manifested FOG during the \nrecordings, providing a total number of 237 FOG episodes. Data from three accelerometers \npositioned on the left shank, left thigh, and lower back were recorded while subjects performed \ndifferent walking tasks.  \nIn Li et al. (2020), raw accelerometers’ readings from Daphnet dataset were segmented into 4s-long \nwindows. Data augmentation (arbitrary rotation) was employed to balance the dataset. The \nclassification model consisted in a combi- nation of convolutional neural network (CNN) and an \nattention-enhanced long short-term memory (LSTM) block. When using data from all three sensors \n(i.e., shank, thigh, back), accuracy 0.919, area under the curve (AUC) of 0.945, and equal error rate \n(EER) of 10.6% were obtained in LOSO CV. When considering only data from the back accelerometer, \nsensitivity 0.829, specificity 0.908, AUC 0.932, and EER 11.8% were obtained. In Noor et al. (2021), \nonly data from the sensor placed on the thigh were analyzed. Raw accelerometer readings were \nsegmented using 2s-long windows, with no overlap. A CNN denoising autoencoder was used, with \nthree convolutional layers both in the encoder and decoder part of the network. Sensitivity 0.909, \nspecificity 0.670, and accuracy 0.789 were achieved in LOSO CV. \nThe Cupid dataset (Mazilu et al., 2013) was used in Bikias et al. (2021). The database includes data \nfrom 18 PD patients while ON therapy, of which 11 manifested FOG during the experiments, \ncollecting a total of 184 FOG episodes. Data from nine inertial measurement units (IMUs) attached to \nwrists, thighs, ankles, feet, and lower back were recorded while patients performed different walking \ntasks, including walking sessions with 180° and 360° turns, on wide or narrow trails with obstacles, \nand walking through crowded hospital rooms. In Bikias et al. (2021), data from the accelerometer \nand gyroscope placed on the wrist were used. Inertial signals were segmented into 3s-long windows, \nwith 0.25s overlap. Raw signals were normalized to the maximum value and fed to a CNN with two \nconvolutional layers and one fully-connected layer. Sensitivity 0.830 and specificity 0.880 were \nobtained in LOSO CV. \nIn Naghavi and Wade (2021), 7 PD patients were asked to walk a narrow hallway while wearing an \naccelerometer and gyroscope on both ankles. A to- tal number of 154 FOG episodes were registered \nduring the experiments. Raw inertial signals were segmented into 2s-long windows, with steps of \n0.25s. A one-class classifier for anomaly detection was proposed, consisting of four convolutional \nlayers and two fully-connected layers. Sensitivity 0.630 and specificity 0.986 were achieved in LOSO \nvalidation. \nIn Shalin et al. (2021), 11 PD patients while OFF therapy were asked to walk a pre-defined path, \nincluding walking in a narrow corridor and turning. A total of 362 FOG episodes were recorded during \nthe experiments. Two plantar- pressure systems were used for data acquisition. Under-sampling of \nnon-FOG data was performed to balance the dataset. The classification model consisted in a network \nwith 2-layers LSTM, providing sensitivity 0.821, specificity 0.895, and precision 0.253, with 95% of \nthe total labeled FOG episodes detected. \nMajor limitations of the above-mentioned studies include the use of a reduced dataset (max 11 PD \npatients with FOG), the limited number of FOG episodes collected (max 362 FOG episodes), the PD \npatients’ state of therapy (either ON or OFF), the laboratory setting of the experiments, and finally \nthe use of several inertial sensors or the limited performance obtained using a single sensor. \nTo address some of these limitations, a system for FOG detection in home environments was \nproposed in Rodríguez-Martín et al. (2017). For this task, a dataset (hereinafter referred as to \nREMPARK-FOG dataset) was collected using a single waist-mounted triaxial accelerometer while \nperforming activities of daily living (ADL) in their home, both ON and OFF therapy. In this study the \nuse of time and frequency domain features were used to feed a support vector machine classifier, \nobtaining sensitivity 0.790 and specificity 0.747 in LOSO CV. The same authors (Camps et al., 2018) \nimproved the classification performance using a CNN consisting of four convolutional layers and two \nfully- connected layers, fed with two consecutive spectral representations of the signal. \nSensitivity 0.919 and specificity 0.895 were obtained when testing the model on a subset of four \npatients. In a previous work (Sigcha et al., 2020), we used the REMPARK-FOG dataset (Rodríguez-\nMartín et al., 2017) to evaluate a CNN-LSTM detection model, fed with spectral representations of \nthree consecutive signal windows. The algorithm achieved a sensitivity of 0.871 and specificity of \n0.871 in LOSO CV. Despite the results, the margin for improvement was identified in the performance \nand applicability of the system intended for FOG detection in home settings. \nFor these reasons, this paper describes some advances in automatic FOG detection using a single \nwaist-mounted triaxial accelerometer and a novel DL classification architecture based on the \ncombination of convolutional and Transformers neural networks. This study was performed using \ndata of 21 patients who manifested FOG episodes while performing ADL in home settings (Rodríguez- \nMartín et al., 2017). \nThe performance of the detection methods was evaluated using a LOSO CV, to propose a generic \nmodel which can be used with data of users that were not included during training. The results show \nan enhancement in FOG detection over methods proposed in the related literature (i.e., \nconvolutional or sequential models) while maintaining a reduced temporal window. \nIn addition, a post-processing methodology of the predictions obtained from the automatic FOG \ndetection system is proposed. The post-processing method- ology was developed with the aim of \nproviding a mechanism to improve the outcomes of systems intended for long-term FOG analysis in \nambulatory and free-living settings. \nThe remainder of this paper is organized as follows: Section 3 presents the materials and methods \nused in this work, including the data collection, algorithmic approaches, validation metrics and \nmethodologies, and the post-processing methodology. Section 4 presents the results and the \ndiscussion of the proposed methodology. Finally, Section 5 presents the conclusions obtained in this \nstudy. \n3. Materials and Methods \nThis section presents the materials and methods used for FOG detection. In this section is reported a \ndescription of the dataset, the signal pre-processing techniques, the ML and DL approaches used for \nFOG detection at the window level, and the proposed FOG detection post-processing methodology \nintended to analyze FOG episodes and clusters of FOG episodes.  \n3.1. FOG Dataset \nThe REMPARK-FOG dataset collected in Rodríguez-Martín et al. (2017) was used for evaluating the \nproposed methods. This dataset contains recordings from 21 patients (3 females and 18 males, 69 \n±9.7 years) who presented FOG symptoms during the recording sessions, in both ON and OFF states. \nThe participants recruited presented a mean Hoehn and Yahr (Hoehn and Yahr, 1967) scoring of 3.07 \n(standard deviation: 0.426) in the OFF state, while the mean FOG questionnaire (Giladi et al., 2009) \nwas an index of 15.2 (standard deviation: 4.47). \nThe protocol for data collection was carried out at the patients’ homes. With this free-living \napproach, is expected an increase in the time and frequency of the FOG episodes (Nieuwboer et al., \n1998). In this protocol, patients were asked to carry out a set of scripted ADL with an approximate \nduration of 20 minutes. Due to the medication effect, the tests were performed in both ON and OFF \nstates. The first test was made early in the morning without the effects of the medication (OFF state), \nwhile the second test was performed at least one hour after the patient took their usual medication \n(ON state). Although the protocol test was based on scripted activities, the patients performed \nseveral activities including their normal ADL (i.e., going outdoors, taking a short walk, Stand Up and \nGo test, brushing their teeth, etc.) in a familiar environment. \nThe dataset was collected through a single triaxial accelerometer from a wearable IMU located at the \nleft side of the waist (Rodríguez-Martín et al., 2013), the accelerometer’s sampling rate was set to \n200Hz, and the amplitude to ±6g. The occurrence of FOG episodes in the data was labeled offline by \nan experienced clinician using video recordings performed during the data col- lection experiments. \nOver a thousand FOG episodes were collected during the recordings. \nThe total signal duration corresponds to 18 hours (OFF state: 9.1 hours; ON State: 8.9 hours). All \npatients (21) manifested FOG during OFF state, while 14 patients reported FOG during ON state. The \ntotal FOG duration is 1.89 hours (OFF state: 85.1 min; ON state: 28 min). In this dataset, 785 FOG \nepisodes were recorded in OFF state and 273 episodes in ON state. Fig. 1 shows a histogram with the \nduration of FOG episodes in ON and OFF states. As shown in Fig. 1, most of the FOG events have a \nduration of less than 10 seconds for both motor states (ON/OFF). \nIn the dataset, 10.5% of the accelerometer triaxial signals correspond to FOG episodes, while 89.5% \ncorrespond to the absence of FOG episodes including normal (ADL) movements. According to this \ndistribution, this dataset can be considered as a binary unbalanced classification problem. \n \nFigure 1: Histogram of FOG episodes duration in ON and OFF. \n3.2. FOG Detection Approach \nAn algorithmic approach was proposed for the detection (window-based detection) and evaluation \nof FOG Episodes and clusters of FOG episodes.  In \nthe proposed approach, the tri-axial accelerometer signals were pre-processed (filtering and \nwindowing) before the feature extraction. After the signal pre- processing, several feature extraction \nmethodologies were implemented to evaluate classifiers based on ML and DL. The predictions of the \nbest approach for FOG detection (at window level) were used to perform the post-processing \nanalysis. In this analysis, the information of several windows was used to detect the presence of FOG \nepisodes and clusters of FOG episodes. \nThe proposed approach was developed according to the scheme shown in Fig. 2. Detailed \ndescriptions of the steps employed in the FOG detection approach are discussed in the subsequent \nsubsections. \n \nFigure 2: Algorithmic approach for FOG detection and episode detection. \n \n\n \n3.3. Signal Pre-processing \nThe dataset comprises triaxial accelerometer signals with a sampling rate of 200 Hz. The data were \nresampled at 40 Hz since this frequency can be a good trade for human activity recognition using \naccelerometers (Khan et al., 2016). Furthermore, this sampling rate allows the analysis of typical \nfrequencies that appear during FOG episodes (Moore et al., 2008) (i.e., freeze band from 3 to 8 Hz). \nFig. 3, shows the spectral representation of FOG episodes in both OFF and ON states. As shown in \nFig. 3, most of the energy is concentrated on the freeze band during FOG events. Also, a reduction of \nthe energy in frequencies below 3 Hz is observed. \n \nFigure 3: Spectral representation of FOG episodes in both OFF and ON states. \n \nThe resampled signals were filtered to remove the noise at high frequencies with a second-order \nButterworth low-pass filter with a cut-off frequency of 15 Hz. Also, to remove the influence of gravity, \na third-order Butterworth high-pass filter with a cut-off frequency of 0.2 Hz was used. \nAccording to the related literature, the best performances in FOG detection have been obtained with \nthe use of longer temporal windows (Moore et al., 2013; Bachlin et al., 2010), conversely, the typical \nFOG episodes are usually shorter than 10 seconds (Mancini et al., 2021), a situation that presents a \ntrade-off between latency and detection performance for real-time applications. \nIn other related studies, the use of windows between 2 and 4 seconds have reported similar \nperformances to those of longer windows (Mazilu et al., 2012; Zach et al., 2015). Hence, in this study, \nthe accelerometer signals were divided into windows of 128 samples (3.2 seconds) with different \noverlap settings. This allows the evaluation of the algorithm’s capability of being part of a cueing \nsystem intended to help the patient during FOG episodes to maintain a certain speed by using \nauditory, visual, or somatosensory feedback (Sweeney et al., 2019). \nTo assign a label to these windows, the following strategy was used: a window was labeled as FOG if \nmore than 50% of its samples were labeled as FOG; a non- FOG window was considered only if all its \nsamples were labeled as non-FOG. Windows containing FOG samples with less than 50% were \ndiscarded.  \n3.4. Feature Extraction Methodologies \n\nDiverse feature extraction methodologies were reproduced to evaluate the classification algorithms \nfor FOG detection. The sets of features include Mazilu features (Mazilu et al., 2012) (used as a \nbaseline), the raw signals (Bikias et al., 2021), and spectral representations based on the Fast Fourier \nTransform (FFT) and previous windows. The spectral representations include two staked windows \n(Camps et al., 2018), and the use of up to 3 previous FFT windows as proposed in (Sigcha et al., \n2020). The use of spectral data representations has shown high performance in FOG detection over \nthe hand-made features using both LOSO CV and hold-out evaluations (Sigcha et al., 2020; Camps et \nal., 2018). \nA summary of the feature extraction methodologies reproduced in this study is shown in Table 1. \nTable 1: Summary of the feature extraction methodologies. \n \nMazilu et al. (2012) features consist of a vector of 21 features extracted from time and frequency \ndomains (7 for each accelerometer axis), including the power of specific frequency bands and the \nfreeze index, that corresponds to the ratio between the power of the freeze-band (3–8 Hz) and the \nlocomotion band (0.5–3 Hz). To extract this group of features the signal was split using sliding \nwindows with a length of 128 samples with an overlap of 75%. \nThe second data representation corresponds to the raw triaxial signal, as proposed in Bikias et al. \n(2021) as a method for FOG detection with a minimum pre-processing. The 384 features correspond \nto the 3 accelerometer channels with a window length of 128 each. The signals were filtered (see \nsection 3.3) and split using sliding windows with an overlap of 10%. The data of each channel were \nnormalized from -1 to 1 to feed the corresponding classification algorithm. \nThe data representation proposed in Camps et al. (2018) was composed of the symmetric part (64-\nbin) of a 128-point Fast Fourier Transform (FFT) extracted from each accelerometer channel. For this \ndata representation, two consecutive windows (with no overlap) were “stacked”, resulting in a 2-D \nrepresentation of 384 features (64 features * 6 channels). \nAlso, a 3-D data representation was generated considering the addition of several previous windows \nas proposed in Sigcha et al. (2020). The data representation was composed of the symmetric part of \nthe FFT (64 bin) extracted for each of the three accelerometer channels. Then, the current and the \nprevious (FFT) windows were ordered as time steps. \nThe use of the current FFT window and up to 3 previous windows with different overlap settings \n(50% and 75%) was evaluated. Considering the current FFT and one previous window, a 3-D data \nrepresentation of 384 features was obtained (2 time steps * 64 features * 3 channels). Considering \nthe current FFT and 2 previous windows, a data representation of 576 features was obtained (3 time \nData \nrepresentation \nNo. of features \n(input shape) Description \nMazilu et al. \n(2012) (baseline) 21 (7*3) Time and Frequency-domain \nfeatures \n \nBikias et al. (2021) 384 (128*3) Raw triaxial signal \nCamps et al. \n(2018) \n384 (64*6) FFT + 1 stacked \nprevious window \nSigcha et al. (2020) \n384 (2*64*3) \n576 (3*64*3) \n768 (4*64*3) \nFFT + 1 previous window \nFFT + 2 previous windows \nFFT + 3 previous windows \n \nsteps * 64 features * 3 channels). Finally, 768 features (4 time steps * 64 features * 3 channels) were \nobtained considering the current FFT and the three previous windows. Fig. 4 shows the process to \nobtain the data representation based on the FFT and previous windows. \n \nFigure 4: Fast Fourier transform (FFT) spectral representation with three previous windows (Sigcha et \nal., 2020). \n3.5. Classification Algorithms  \nIn this work, diverse classification algorithms proposed in the related literature were reproduced and \nevaluated. The evaluated algorithms comprise random forest (Breiman, 2001), deep neural networks \n(DNN) composed of convolutional layers (Bikias et al., 2021; Camps et al., 2018), and a combination \nof convolutional and recurrent layers (Sigcha et al., 2020). In addition, this study proposes a novel \napproach based on the use of Transformer blocks in combination with convolutional blocks (FOG-\nTransformer) as a mechanism to improve the performance in FOG detection. The architecture \nemployed for the FOG-Transformer is shown in Section 3.5.1. \nMazilu features were evaluated with a Random Forest algorithm with 100 decision trees; this \napproach was selected as the baseline due to its ease of implementation and excellent results. \nOn the one hand, the architecture proposed in Bikias et al. (2021) that uses CNN with max-pooling \nand multilayer perceptron (MLP) was reproduced and evaluated with data representation based on \nraw signals. On the other hand, the architecture proposed in Camps et al. (2018) was evaluated with \nthe data representation that uses FFT with one stacked previous window. \nThe reproduction of these two architectures (Camps et al., 2018; Bikias et al., 2021) differs from that \nreported in their corresponding articles in the number of sensors and signals. In both studies, the use \nof triaxial gyroscopes in companion with triaxial accelerometers was reported, achieving sensitivities \nand specificities up to 0.92 using evaluation methodologies like hold-out (Camps et al., 2018) and 10-\nfold cross-validation (Bikias et al., 2021). In particular, the output of the model proposed in Bikias et \nal. (2021) was adapted for a binary prediction (FOG or Non-FOG) instead of the reported multi-class \nclassification (FOG, stop, walking-with-turns). Also, in both models, the loss function was changed to \nbinary cross-entropy to make the results comparable with the other deep architectures evaluated in \nthis study. \nThe recurrent architecture (CNN-LSTM) proposed in a previous work (Sigcha et al., 2020) was \nevaluated using the 3-D data representation that uses FFT plus 3 previous windows as shown in Fig. \n4. This architecture is composed of CNN and LSTM recurrent layers, which allows analyzing \nsequential data from previous windows to take advantage of temporal phases that appear at the \nbeginning of the FOG events (Cupertino et al., 2022). \n\nThe experiments to evaluate the classification algorithms were conducted on a computer with an \nIntel Xeon with 2.30 GHz processor, 25 GB of random- access memory (RAM), and a 12 GB NVIDIA \nTesla K80 graphics accelerator. The preprocessing, and feature extraction were performed using the \nMATLAB software (version R2020a), while the evaluation and training of the classification models \nwere performed in Python (version 3.6), using the libraries Keras (version 2.4), TensorFlow (version \n2.3), and Scikit-learn (version 0.22). \n3.5.1. Architecture for the Deep Neural Network with Convolutional and Trans- former \nBlocks (FOG-Transformer) \nThe FOG-Transformer model works as a classifier for FOG detection using the temporal information \nobtained from previous spectral windows. This architecture can work with sequential data, \nemploying a time-distributed layer to process the time steps. The temporal behavior of the FOG \nepisodes is analyzed using a Transformer encoder that uses attention blocks. The architecture \nproposed for the FOG-Transformer and its corresponding convolutional and attention blocks is shown \nin Fig. 5. \nThe FOG-Transformer is composed of three main parts, described in the following. \n1. Time-distributed layer. This layer works as a wrapper for a block of 1-D convolutional layers with \nmax-pooling and global average pooling (GAP). This block provides a mechanism to adapt the shape \n(3-D) of the input data to the input expected for the Transformer block. The convolutional block is \nused for automatic feature extraction from each single time step composed of triaxial FFT channels. \nIn the time distributed layer, the same convolution and pooling processing is applied to each time \nstep. \n  \nFigure 5: Deep neural network with convolutional and Transformer blocks (FOG- Transformer). \nThe convolutional block is composed of an input layer (64 samples and 3 channels) and three 1-D \nconvolutional layers with 128, 64, and 32 filters respectively, all of them with Rectified Linear Unit \n(ReLU) activation function and a kernel size of 4. The first two convolutional layers are connected to \nmax-pooling layers with a pool size of 2, while the last convolutional layer is connected to a GAP \nlayer. The output of the convolutional block has a size of 4*32, which corresponds to a sequence of 4 \ntime steps with 32 features each. \n\n2. Transformer encoder. It is responsible for analyzing the temporal information of the sequential \ndata provided from the time-distributed layer. The encoder generates an attention-based \nrepresentation with the capability to locate specific and relevant information across the whole (spec- \ntral) sequence. The encoder is composed of 3 Attention blocks, each with Multi-Head self-attention \nlayers (Vaswani et al., 2017) (3 heads with a size of 32), normalization layers, and a Feed-Forward \nsection with 1-D convolutional layers (16 filters, kernel size of 1, and dropout 0.25). The encoder \nemploys residual connections and dropout as proposed in keras.io (2021). The output of the \nTransformer encoder is connected to a GAP layer to reduce the dimensionality of each time step to \nenable the connection to the classification (fully-connected) layers. \n3. MLP Head: The last part of the FOG-Transformer is used for classification tasks. The MLP Head is \ncomposed of three fully-connected layers with 80, 40, and 1 neuron respectively. The first two layers \nuse ReLU activation and dropout of 0.4, while the output layer employs a sigmoid activation to \nprovide the probability in the classification of FOG (or Non-FOG) events.  \n3.5.2. FOG-Transformer Training and Hyperparameter Optimization \nThe training of the DNNs is an iterative process that repeats until finding an acceptable solution for a \nproblem. In this process, the weights and biases of the network layers are updated using the back-\npropagation algorithm to minimize a loss function. The training of a DNN is difficult because of the \nlarge number of parameters to be adjusted in each layer (Glorot and Bengio, 2010). \nHyperparameters like the learning rate, batch size, the number of epochs or number of layers, and \nthe layer’s parameters remain constant during training. Thus, the accurate selection (optimization) of \nthese hyperparameters has a great influence on the model performance and controls the training \nprocess in terms of computational processing. \nIn this work, the hyperparameter optimization of the FOG-Transformer model was performed with \nthe hyperband method. The method presents a good trade-off between speed and performance in \nproblems with high dimensionality space (Li et al., 2017). The FOG-Transformer was trained with the \nAdaptive moment estimation optimizer (ADAM) (Kingma and Ba, 2014) with a learning rate of 6*10-\n4, binary cross-entropy as loss function, a batch size of 512, and 150 as the maximum number of \nepochs. In addition, an early-stopping strategy was employed to prevent overfitting and unnecessary \ncomputing during training. This strategy stops the training when the loss value did not decrease for 7 \ncontinuous epochs. To apply this strategy the training data was subdivided into 80% for training \n(train–train) and 20% for validation (train–validation). \n3.6. Evaluation Methodology for FOG Detection Algorithms \n3.6.1. Leave-one-subject-out Cross-validation (LOSO CV) \nIn this study, the FOG detection algorithms were evaluated through LOSO CV. This evaluation method \nhas been employed to develop generalized FOG detection systems that can be used with data from \nnew patients that are not included during training. LOSO CV provides a subject-independent estimate \nof the performance for new subjects (Gholamiangonabadi et al., 2020), in contrast to the cross-\nvalidation methods (i.e., random k-fold) or the hold-out evaluation, which can employ data from the \nsame subjects for training and evaluation, or data from specific subsets or selected subjects. \nIn LOSO CV, the data of all patients except one is used for training, while the data of the remaining \npatient is used for evaluating the model; then, this process is repeated for each patient. The \nperformance of a model using LOSO CV can be analyzed for each subject, and the overall results can \nbe calculated by averaging the partial results from each patient. \nIn addition, LOSO CV is more appropriate for the evaluation of data pro- cessed with sliding windows \nwith overlap, to prevent signal segments to be shared between training and validation subsets (i.e., \nwhen using a random k- fold validation). In this study, the LOSO CV was performed using the data \nfrom 21 patients and the process was repeated six times for each subject. The reported results were \ncomputed by averaging the results of all evaluations.  \n3.6.2. Performance Metrics \nTo evaluate the performance of the proposed methods and those reproduced from the state-of-the-\nart approaches, several metrics were calculated and re- ported. For a binary classification problem \n(FOG or non-FOG), the results were expressed in terms of sensitivity, specificity, AUC of the receiver \noperating characteristic curve (ROC) (Hanley and McNeil, 1982), and EER (Jothilakshmi and Gudivada, \n2016). \nThe sensitivity is the ratio of positives that are correctly identified, while specificity is the ratio of \nnegatives that are correctly identified. These metrics were calculated using the number of true \npositives (TP), true negatives (TN), false positives (FP), and false negatives (FN). While the TP and the \nTN are the numbers of correctly identified positive and negative samples, the FP repre- sents the \nnumber of negative samples wrongly classified as positive, and the FN represents the number of \npositive samples wrongly classified as negative. The sensitivity and specificity were calculated using \nEq. (1) and Eq. (2) respectively. \n \nBecause FOG detection algorithms can provide a probability value in their output, rather than a \nspecific class, it is necessary to apply a classification threshold. For the comparison of the proposed \napproaches, the values of sen- sitivity and specificity have been obtained using the equal error rate \nthreshold (EER threshold) (Freeman and Moisen, 2008). \nIn addition, the accuracy (number of correct predictions out of all data) and F-score (harmonic mean \nof the model’s precision and sensitivity) were computed to evaluate the performance of the system \nwhen performing post-processing tasks for an overall analysis of FOG events. The accuracy and F-\nscore were obtained using Eq. (3) and Eq. (4) respectively. The precision was computed using the Eq. \n(5).  \n\n \n3.7. FOG Detection Post-processing \n  For further analysis, a post-processing analysis was performed using the best \napproach for FOG detection. Since the output of the FOG detection algorithms is a probability \n(instead of a specific class FOG/Non-FOG), the effect of tuning the classification thresholds was \nevaluated using the F-score and the geometric mean (GM) between sensitivity and specificity \n(Section 3.7.1). \nIn addition, the performance in the detection of FOG episodes was analyzed (Section 3.7.2), besides \nthe window-level FOG detection. Finally, a methodology for the analysis of the clusters of FOG \nepisodes was proposed and evaluated (Section 4.6.3). \n3.7.1. Threshold Tuning \nThe tuning procedure on the classification threshold was performed taking as input the label and the \ncontinuous prediction score provided by the proposed model. The classification threshold was tuned \nin the range 0.2-0.8, and the GM and the F-score were evaluated while increasing the threshold \nvalue. Perfor- mance was compared for two threshold selection strategies, namely EER mini- \nmization and F-score maximization. The rest of the subsequent post-processing on FOG detection \nwas performed for each of the threshold selection strategies. \n3.7.2. FOG Episode Detection \nThe analysis of FOG episodes and false FOG episode (FFE) was performed by analyzing groups of \nconsecutive windows with the presence of freezing episodes. The analysis was based on the results \nof the window-based FOG detection pro- vided by the FOG-Transformer model. FOG Episode \nDetection and FFE de- tection were performed using the methodology described as follows. \nFOG episode detection: When considering FOG episodes (i.e., group of consecutive windows labeled \nas FOG), the percentage of episodes detected and the proportion of FOG detected in each episode \nwere computed. As for the former, an episode was considered detected if at least one window of \nlabeled FOG inside that episode was correctly identified by the model. And for the proportion of FOG \ndetected in each episode, the number of windows detected as FOG in each episode was divided by \nthe total labeled FOG windows included in that episode. The analysis was performed both \nindependently of the duration of FOG episodes and dividing episodes based on their duration. FOG \nepisodes were divided into three groups, including episodes lasting less than 5s, episodes with \nduration in the range of 5-10s, and finally, episodes of duration longer than 10s. \nFalse FOG episode detection: FFE were identified as groups of consecutive windows predicted by the \nmodel as FOG, while none of them were labeled as FOG. The percentage of FFE was computed as the \nnumber of FFE divided by the total number of predicted episodes. For each FFE, the distance from \n\nthe nearest FOG was computed. This was done by performing four consecutive steps: Compute the \nnumber of windows between the beginning of the FFE and the end of the previous labeled FOG \nepisode; compute the number of windows separating the end of the FFE and the beginning of the \nfollowing labeled FOG episode; compute the minimum value between them; multiply the latter value \nby the sliding window size, which was set to 0.8s, to convert the number of windows into a time \ninterval. Finally, the percentage of FFE far less than 5s and 10s from the nearest FOG was computed.  \n3.7.3. Clustering of FOG episodes \nTo analyze the performance of the proposed algorithm in detecting clusters of FOG episodes, the \nfollowing processing was employed. First, the upper root- mean-square envelope of both the label \nvector and the binary prediction score was computed using a sliding window of 110 windows, \ncorresponding to 1.5 min of data. Then, the Pearson correlation coefficient and the corresponding p-\nvalue were computed considering the envelopes of the labeled and predicted vectors. Finally, real \nFOG clusters were identified as the portion of data in which the labeled envelop exceeded the zero-\nvalue. \nAs for the predicted clusters, a threshold of 0.1 was selected to define FOG clusters. Correctly \nidentified FOG clusters were defined as labeled clusters in which at least one window was predicted \nby the model as FOG. Predicted clusters in which none of the windows were labeled as FOG were \ndefined as false clusters. The percentage of true/false clusters was computed by dividing the number \nof true/false by the total number of labeled/predicted clusters. Finally, duration and FOG content \n(i.e., percentage of windows predicted as FOG) for each cluster were computed, and the results were \ncompared between true and false predicted FOG clusters. The Mann-Whitney U test was performed \nto verify whether those metrics were significantly different in the two populations. \n4. Results and Discussion  \nIn this section, the experiments and the results obtained from the different methods for FOG \ndetection at window-level and post-processing analysis are reported and discussed. All the detection \nmethods were evaluated through LOSO CV evaluation, the complete process was repeated six times \nto verify the variability in the results due to the stochastic processes in the training procedure. \n4.1. Baseline Results \nTo make a baseline, the Mazilu features in conjunction with a Random Forest classifier with 100 \nestimators were evaluated. Table 2 presents the results in terms of sensitivity, specificity, AUC, and \nEER using LOSO CV. The results are presented for each subject included in the experiment. \nTable 2: Results from the baseline model (Mazilu et al., 2012). \n \nAccording to Table 2, the baseline method presents sensitivities and specificities ranging from 0.7 to \n0.91. These results are lower than those reported in Mazilu et al. (2012) (0.995 in sensitivity and \n0.999 in specificity) using the Daphnet dataset. These differences are expected because Daphnet \nconsiders a different number of sensors and the data collection includes activities performed under \ncontrolled conditions in contrast to the normal ADL used in this study. \nThe baseline reproduction shows an average AUC of 0.916 and an EER of 16.3. This method presents \na good trade-off between ease of implementation and results, even considering that is expected a \ndecrease in the performance metrics using LOSO CV methodology in comparison to k-fold cross-\nvalidation methods.  \n4.2. Evaluation of Different FOG Detection Methods \nIn this experiment, different classification algorithms were tested using their corresponding data \nrepresentations. Table 3 shows a summary of the methods evaluated and the results in terms of \nsensitivity, specificity, AUC, and EER (%) obtained through LOSO CV. \nTable 3: Performance of different methods for FOG detection. \n \nThe results of the methods (Bikias et al., 2021; Camps et al., 2018; Sigcha et al., 2020) reproduced \nfrom the literature were achieved using the configuration (i.e., learning rate, number of epochs, \nbatch size) that reported the best performance in the training and evaluation process. While the \nhyperparameters used in the FOG-Transformer are described in Section 3.5.2. \nPatient Index Sensitivity Specificity AUC EER(%) \n1 0.844 0.833 0.928 16.3 \n2 0.708 0.695 0.771 30.5 \n3 0.899 0.904 0.960 9.6 \n4 0.786 0.803 0.898 19.7 \n5 0.824 0.821 0.905 17.9 \n6 0.839 0.832 0.931 16.8 \n7 0.855 0.855 0.933 14.5 \n8 0.851 0.857 0.914 14.3 \n9 0.776 0.782 0.879 21.8 \n10 0.865 0.886 0.943 13.4 \n11 0.831 0.819 0.904 18.1 \n12 0.776 0.762 0.846 23.8 \n13 0.844 0.837 0.930 16.3 \n14 0.912 0.915 0.971 8.5 \n15 0.898 0.907 0.961 9.3 \n16 0.851 0.857 0.929 14.3 \n17 0.876 0.877 0.940 12.4 \n18 0.885 0.887 0.954 11.3 \n19 0.852 0.839 0.942 16.1 \n20 0.759 0.774 0.870 22.6 \n21 0.861 0.861 0.933 13.9 \nAverage 0.838 0.837 0.916 16.3 \n \nMethod Classifier Sensitivity Specificity AUC EER(%) \nMazilu et al. (2012) Random Forest 0.838 0.837 0.916 16.3 \nBikias et al. (2021) CNN-MLP 0.856 0.857 0.921 14.3 \nCamps et al. (2018) CNN-MLP 0.863 0.863 0.938 13.7 \nSigcha et al. (2020) CNN-LSTM 0.871 0.871 0.939 12.9 \nPresent study FOG-Transformer 0.891 0.891 0.957 10.9 \n \nAccording to Table 3, the FOG-Transformer trained with the FFT plus 3 previous windows presents \nthe best performance compared to other methods, by reaching a sensitivity, specificity of 0.891 \neach, an AUC of 0.957, and a reduction of the 5.4% in the EER in comparison with the baseline. The \nAUC of the FOG-Transformer increased from 0.939 to 0.957 in comparison with the best (CNN-LSTM) \nmethod reproduced from the related literature. With this dataset, a difference of 0.018 (1.8%) in AUC \ncan be considered significant with p¡0.0005, according to Hanley’s method (Hanley and McNeil, \n1982). \nThe baseline method that uses a shallow ML algorithm presents a lower performance than the DL \napproaches with an AUC of 0.916 and an EER of 16.3%. \nOn the other hand, the results obtained with the DL methods based on CNN show similar \nperformances in terms of sensitivity and specificity, while the addition of recurrent layers to CNN \npresents a slight increase in the performance and a corresponding reduction in the EER. According to \nthese results, the method proposed in Bikias et al. (2021) presents a feasible approach for FOG \ndetection with a minimal signal pre-processing, whereas the use of the spectral representation (FFT) \nwith previous windows (Camps et al., 2018; Sigcha et al., 2020) can bring an additional improvement \nin the predictive performance of the DL based methods. \nAs shown in Table 3, the FOG-Transformer architecture presents a significant improvement over the \nbest method reproduced for the related literature using the same number of previous windows and \noverlap settings (75%) proposed in Sigcha et al. (2020). These results suggest that the use of \nTransformers and attention blocks can improve the performance in FOG detection based on the \nanalysis of adjacent windows and enables the development of DNNs without the use of recurrent \nlayers to model sequential data. Also, the use of CNN blocks within a time-distributed layer seems to \nbe a suitable mechanism for automatic feature extraction to feed recurrent layers (i.e., GRU or LSTM) \nor transformer blocks. \nThe addition of different positional encoding strategies before the Trans- former blocks did not \npresent significant differences in the performance of the proposed FOG-Transformer architecture. \nThe use of a trainable positional encoding shows slightly lower performance (AUC 0.950), as well as \nthe use of a fixed positional encoding scheme proposed in Vaswani et al. (2017) (AUC 0.949).  \nSimilar behaviors were reported using CNN layers before Transformers for im- age classification, \nshowing slight differences in the accuracy among approaches and turning optional the use of \npositional embedding (Hassani et al., 2021). \n4.3. Evaluation of the FOG-Transformer with Different Number of Previous Windows and \nOverlap \nIn a previous study (Sigcha et al., 2020), the addition of a larger number of previous windows using a \nCNN-LSTM model has shown a progressive increase in the overall performance in FOG detection, \nhowever, this approach presents a trade-off between performance and computational burden. Thus, \nthe accurate selection of the windows size and overlap setting turns critical to reducing the \ncomputational burden produced for the feature extraction process, in particular when using sliding \nwindows with a high overlap setting. \nIn this experiment, the performance of the FOG-Transformer with a different number of previous \nwindows and overlap settings was evaluated. Table 4 presents the results of the performance of the \nFOG-Transformer model in terms of sensitivity, specificity, AUC, and EER using LOSO CV. \nTable 4: FOG-Transformer performance at different overlap settings and previous windows. \n \nThe results in Table 4 indicate a higher performance in terms of AUC by using the current and three \nprevious windows with an overlap of 75%. However, the use of the current and two or three \nwindows with an overlap of 50% show similar performances (AUC 0.951 and 0.949 respectively) than \nthat obtained using two previous windows with an overlap of 75% (AUC 0.950). The use of a reduced \noverlap setting (i.e., 50% or less) can limit the number of windows to be analyzed in a given time \ninterval, thus, reducing the computational burden produced by the feature extraction procedure \nwithout a significant decrease in performance. This situation presents opportunities for the \ndevelopment of accurate detection systems that can be used for long-term monitoring in real-life \nsettings like ambulatory and home environments. \n4.4. Comparison of the Performance and Number Trainable Parameters of the DL Models \nTo compare the performance and size of the DNNs, Table 5 describes the number of features used to \nfeed the DL models, the number of trainable parameters, and its corresponding performance in \nterms of AUC. \nTable 5: Performance, number trainable parameters and input shape of the DL models. \n \nAs shown in Table 5, the reproduction of the deep architectures proposed in Camps et al. (2018) and \nBikias et al. (2021) present a lower number of trainable parameters and a reduced number of input \nfeatures in comparison with the CNN-LSTM and FOG-Transformer. However, the best results in terms \nof AUC were achieved with the CNN-LSTM model and the proposed FOG-Transformer using as input \na 3-D data representation with 768 features. Although the FOG- Transformer presents a higher \nnumber of trainable parameters over the models proposed in Camps et al. (2018) and Bikias et al. \n(2021), the model exhibits a reduction of 201,168 parameters in comparison to the CNN-LSTM. \nThe results in Table 5 show a trade-off between performance and complexity among the DL \napproaches. However, the reduction in the number of trainable parameters in the FOG-Transformer \ncould facilitate its implementation in real- time detection systems and stand-alone devices while \nModel No. of features \n(input shape) \nNo.of Trainable \nParameters AUC \nCNN-MLP(Bikias et al., 2021) 384 (128*3) 43,181 0.921 \nCNN-MLP(Camps et al., 2018) 384 (64*6) 32,961 0.938 \nCNN-LSTM (Sigcha et al., 2020) 768 (4*64*3) 288,993 0.939 \nFOG-Transformer 768 (4*64*3) 87,825 0.957 \n \nenhancing the performance in FOG detection. According to these results, the subsequent \nexperiments were performed with the FOG-Transformer model. \n4.5.  Results of the FOG-Transformer with Previous Windows Per Patient \nFor comparison purposes, Table 6 shows the results per patient obtained with the FOG-Transformer \nand the data representation based on the current and three previous windows (overlap 75%). \nTable 6: Results of the FOG-Transformer with three previous windows per patient. \n \nAccording to Table 6, the AUC value is in the range of 0.874 to 0.982, with a mean AUC of 0.957, \nwhile the mean EER is 10.9%. The results show a high performance in FOG detection in the majority \nof the patients, however, the average result is affected by patients 2, 4, and 20. The variation in the \nresults is expected because of the different freezing patterns and the low amount of freezing events \nfound in these subjects. \nWhen comparing the results per patient of the baseline (see Table 2) and the FOG-Transformer (see \nTable 6), increases of up to 10.3% in AUC (mean 4.1%; standard deviation 2.5%) and reductions of up \nto 10.5% in EER (mean 5.4%, standard deviation 2.3%) are observed. Comparison exhibits increases \nin AUC and reductions in EER for all subjects when using the FOG-Transformer; these results show a \nhigh predictive capability and the potential to predict FOG using data from new subjects. However, \nvalues as low as 1% increase in AUC have been observed in patients 3 and 14, which still present a \nchallenge in the algorithmic area. \nDespite partial results for specific subjects, the overall results suggest that the FOG-Transformer \nmodel presents a high generalization capability (model’s capability to adapt properly to new, \npreviously unseen data), avoiding the need to collect new data to train personalized models. \n4.6. Results of the FOG Detection Post-processing \nThe results of the post-processing are presented in the next subsections. The results include the \nclassification threshold tuning (Section 4.6.1), FOG event and FFE detection (Section 4.6.2), and the \nPatient Index Sensitivity Specificity AUC EER(%) \n1 0.926 0.927 0.982 7.3 \n2 0.787 0.786 0.874 21.4 \n3 0.925 0.925 0.969 7.5 \n4 0.818 0.819 0.920 18.1 \n5 0.881 0.881 0.957 11.9 \n6 0.888 0.888 0.954 11.2 \n7 0.909 0.905 0.971 9.5 \n8 0.897 0.898 0.943 10.2 \n9 0.863 0.863 0.946 13.7 \n10 0.908 0.909 0.970 9.9 \n11 0.887 0.887 0.953 11.3 \n12 0.866 0.867 0.941 13.3 \n13 0.895 0.895 0.965 10.5 \n14 0.936 0.936 0.982 6.4 \n15 0.939 0.939 0.983 6.1 \n16 0.910 0.911 0.965 8.9 \n17 0.920 0.920 0.972 8.0 \n18 0.931 0.931 0.981 6.9 \n19 0.888 0.888 0.964 11.2 \n20 0.836 0.836 0.940 16.4 \n21 0.908 0.909 0.960 9.1 \nAverage 0.891 0.891 0.957 10.9 \n \nclustering of FOG episodes (Section 4.6.3). These results were obtained using the window-based \npredictions derived from the FOG-Transformer fed with the 3-D data representation with three \nprevious windows. \n4.6.1.  Results of the Threshold Tuning \nFig. 6 reports the classification performance, in terms of GM between sensi- tivity and specificity, and \nF-score, for different values of the classification thresh- old (thr). \n As shown in Fig. 6, as thr increases up to 0.8, the GM curve decreases from \n0.91 to 0.76. The best performances in this metric were achieved using a low threshold setting. This \ntrend is expected due to the unbalanced data that is intrinsic to this symptom. \n  \nFigure 6: Classification performance using different threshold values.  \nAs far as concerns the F-score, it increases until thr=0.6, where a maximum of 0.72 is observed, and \nthen decreases for higher threshold values. However, while the F-score increases by only 1.2% in the \ninterval 0.4-0.6, a reduction of GM by 3.9% is registered in the same interval.  This suggest that thr = \n0.4 represents a good compromise between GM and F-score. Compared to the EER-based approach, \nthe F-score approach (thr = 0.4) improves F-score by 6.1%, with a reduction in GM by only 1.8%. \nFor further analysis, Table 7 reports the classification performance obtained using two different thr \nselection methods, namely EER minimization and the thr selected using the F-score method. \nTable 7: Classification performance using different classification threshold criteria. \n \nUsing the F-score method, accuracy (+2.2%), specificity (+3.2%), precision (+8.4%), and F-score \n(+4.1%) increase over the EER minimization. On the other hand, the EER minimization presents an \nincrease in the geometric mean (+6.5%) and sensitivity (+1.8%). According to these results, both \napproaches show their applicability depending on the need for high precision and accuracy, or a \nbalanced performance between sensitivity and specificity. \n4.6.2. Results of the FOG Episodes Detection \nThreshold    Performance  \nCriterion Value Accuracy Sensitivity Specificity Geometric mean Precision F-score \nEER minimization 0.22 0.907 0.907 0.907 0.907 0.533 0.671 \nF-score method 0.40 0.929 0.842 0.939 0.889 0.617 0.712 \n \nWhen analyzing FOG episodes, the results for the EER threshold and the F- score method (in \nparentheses) are reported in the following. The 95.5% (91.2%) of episodes were detected by the \nalgorithm, with an average proportion of 84.2% (74.6%) of FOG detected in each episode. The \nalgorithm exhibited a different detection rate based on FOG episodes duration, as reported in Table \n8. As FOG episodes duration increases, both detection rate and proportion of FOG detected in each \nepisode increase. Moreover, the EER-based threshold method provided better performance than \nthose obtained using the F-score approach. \nTable 8: Detection rate of FOG episodes based on duration. \n \nOn the other hand, when analyzing FFE, 55.6% (44.8%) of the total episodes detected were found to \nbe false positives, with a mean duration of 4s (3.9s), for the EER (F-score)–based threshold selection. \nFrom the total number of false episodes detected, 35.7% (40.1%) were found to be less than 5s \ndistant from the nearest real FOG episode. Table 9 reports the proportion of false episodes detected, \ntheir duration, and the distance from the nearest FOG. Removing short detected FOG episodes \npresent a slight improvement in F-score. More in detail, deleting episodes including 1, 2, 3 windows \nled to an improvement in F-score by 0.5% (0.4%), 1.2% (1.1%), 2.4% (1.6%), while reducing sensitivity \nby 0.2% (0.3%), 0.4% (0.6%), 0.6% (1.3%), for the EER (F-score) threshold selection strategy. \nTable 9: False FOG episodes detection performance. \n \nAs shown in Table 9, using the F-score threshold selection strategy led to the reduction of over 10% \nin FFE, with a larger percentage of FFE located close to real FOG episodes. This latter result is \nimportant for two reasons. In the case of a real-time implementation of the algorithm, false episodes \ndetected before the actual onset of FOG may be beneficial for triggering some sort of cueing system. \nConversely, when using the classification algorithm for offline processing of daily data, false episodes \ndetected near the real FOG do not significantly affect the performance of the algorithm, in terms of \naccumulations of FOG episodes. This latter point is discussed in detail in the next section. \n4.6.3. Results of the Clustering of FOG Episodes \nWhen analyzing clusters of FOG episodes, the envelope of detected FOG episodes is strongly \ncorrelated with that of labeled FOG episodes, as shown in Fig. 7. Table 10 reports the Pearson \ncorrelation coefficient (r), the percentage of true clusters detected, the percentage of FOG detected \nin each cluster, and finally, the percentage of false clusters detected. \nTable 9: False FOG episodes detection performance. \nFOG episodes duration (s)  <5s 5-10 s  >10s \nThreshold criterion EER F-score EER F-score EER F-score \n% FOG episodes detected 92.4 86.0 99.3 98.6 100 100 \n% FOG detected in each episode 77.9 68.7 89.1 82.4 93.2 87.9 \n \n\n \nAs can be observed from the table, the percentage of clusters detected is slightly larger using the EER \nthreshold (+1%), while the percentage of false clusters detected is significantly lower for the F-score \nthreshold (-11.4%). Pear- son correlation coefficient and the percentage of FOG detected in each \ncluster are similar for the two approaches. \nThe Mann-Whitney U-test demonstrated that true and false predicted clus- ters were different for \nduration and FOG content (p¡0.001), with false clusters being shorter (average: 1.42 min vs 6.17 min \nand 1.45 min vs 5.65 min for the EER and F-score approach, respectively) and including smaller FOG \namount (average: 8.9% vs 27.6% and 8.6% vs 31.5% for the EER and F-score approach, respectively) \nthan true clusters, as can be observed in Fig. 7. Clustering of FOG episodes represents an effective \ntool for summarizing the FOG distribu- tion throughout the day of PD patients. In fact, the \naccumulation of FOG episodes during specific periods of the day are strongly related to the OFF ther- \napy condition, when the pharmacological treatment is no longer effective (Borzì et al., 2021; Suppa \net al., 2017). Thus, results from clusters of FOG episodes may provide neurologists with useful \ninformation for scheduling proper therapy adjustments. \n  \nFigure 7: Labels and detected FOG episodes, together with computed envelops. \n5. Conclusions \nIn this paper, approaches for FOG detection using a single triaxial accelerometer (from a body-worn \nIMU) and FOG-Transformer networks have been evaluated. The data employed to evaluate the \nproposed methods were collected in the patients’ homes where it is expected an increase in the \noccurrence of FOG events (Nieuwboer et al., 1998). The evaluation of the models was carried out \nwith a LOSO CV to evaluate the performance of a FOG detection model generalizable for data from \nnew subjects. \nThe best results were obtained with the FOG-Transformer model that included a convolutional block \n(for feature extraction from the triaxial accelerometer spectra) and a Transformer encoder with \nattention blocks to model time dependencies. A significant improvement in the performance of FOG \n\ndetection was obtained using a 3-D data presentation that considers up to three previous spectral \nwindows, by taking advantage of the temporal phases (movement pat- terns) that appear before the \noccurrence of a FOG event (Borzì et al., 2021; Cupertino et al., 2022). Moreover, the use of CNN \nblocks (within time-distributed layers) seems to be a suitable method for automatic feature \nextraction from spectral data to feed the Transformer blocks. \nWhen comparing the baseline (hand-made features and a Random forest classifier) with the FOG-\nTransformer, an increase in AUC of 4.1% and a reduction of 5.4% in EER were achieved. The proposed \nFOG-Transformer architecture shows to be a suitable method for FOG detection without the need of \nusing recurrent layers to model temporal dependencies in the data. Also, a significant reduction in \nthe number of the trainable parameter is observed in comparison with the best method (CNN-LSTM \n(Sigcha et al., 2020)) reproduced from the related literature, thus reducing the computational \ncomplexity to support the implementation of this algorithm in long-term monitoring systems. \nIn the experiments made in this study, the FOG-Transformer has shown a capability of outperforming \nFOG detection methods based on convolutional layers (Bikias et al., 2021; Camps et al., 2018) and \nmethods based on the combination of convolutional and recurrent layers (Sigcha et al., 2020). In \naddition, the results show the feasibility of using a single sensor for FOG detection. The use of a low \nnumber of sensors or devices should be considered to simplify the usability and increase the \nacceptability of systems intended for use in free-living or ambulatory settings (Rodríguez-Martín et \nal., 2017). The detailed post-processing performed on predicted FOG episodes revealed an excellent \nperformance of the present algorithm in the detection of FOG episodes, while false episodes were \nlocated near real FOG. Finally, clustering of FOG episodes could be an effective tool for monitoring \nFOG in non-supervised environments during daily life. This can provide relevant information \nregarding the timing and the duration of FOG episodes accumulation, of fundamental importance for \na proper schedule of pharmacological treatments and long-term monitoring. \nAlthough the use of FOG-Transformer shows an enhancement in the FOG detection performance, the \nuse of reduced window size is still a requirement for the development of algorithms with low latency \nto be used as part of a cue system to reduce the occurrence of FOG events without interrupting \npatients’ daily life. According to the results, the use of a data presentation based on the current and \ntwo or three previous windows with an overlap of 50% seems to be a good trade-off between \nperformance and computational burning, while maintaining a short latency derived from the window \nlength and the computation time. \nThe main contributions of this paper are the implementation and evaluation of novel approaches \nbased on Transformer and convolutional networks for FOG detection. Also, a methodology for FOG \nepisode analysis and clustering is proposed with the aim of improving the outcomes of systems \nintended for long-term FOG analysis in ambulatory and free-living settings. The outcomes of these \nmethods could be used in conjunction with standard gait parameters to provide reliable indicators \nthat could be integrated into routine care, the implementation of gait assistance systems, and the \nremote assessment of PD patients. \nFuture work in algorithm optimization could focus on the contextualization of activities, thus limiting \nthe burden of complex algorithms to operate only during the sections of interest, i.e., automatic \nactivation of FOG detection algorithms only during walking. Also, a FOG prediction (Borzì et al., 2021; \nNaghavi and Wade, 2021) should be addressed by improving the predictive power and the efficiency \nof detection methods to support the implementation of a robust cueing system. \nIn addition, the improvement in the precision of the detection models should be addressed to \nreduce the false-positive rate observed in the experiments. The implementation of novel pre-\nprocessing techniques or novel end-to-end prediction models could provide mechanisms for the \nimplementation of accurate real-time cueing systems that help reduce the occurrence of FOG \nepisodes and their consequent falls. \nDeclaration of competing interest \nThe authors declare that they have no known competing financial interests or personal relationships \nthat could have appeared to influence the work reported in this paper. \nCRediT authorship contribution statement  \nLuis Sigcha: Conceptualization, Methodology, Software, Investigation, Vi- sualization, Writing - \nOriginal Draft. Luigi Borzì: Conceptualization, For- mal analysis, Investigation, Software, Validation, \nWriting - Original Draft. Ig- nacio Pavón: Formal analysis, Project administration, Writing - review & \nediting. Nelson Costa: Funding acquisition, Supervision, Writing - review & editing.Susana Costa: \nValidation, Formal analysis, Writing - review & editing. Pedro Arezes: Resources, Supervision, Writing \n- review & editing. Juan Manuel López: Resources, Supervision, Writing - review & editing. Guillermo \nDe Arcas: Funding acquisition, Project administration, Writing - review & editing. \nAcknowledgments \nThis work was supported by “Tecnologías Capacitadoras para la Asisten- cia, Seguimiento y \nRehabilitación de Pacientes con Enfermedad de Parkinson”. Centro Internacional sobre el \nenvejecimiento, CENIE (código 0348 CIE 6 E) Interreg V-A Espan˜a-Portugal (POCTEP); FCT-\nFunda¸c˜ao para a Ciˆencia e Tecnologia within the R&D Units Project Scope: UIDB/00319/2020; and \nthe Grupo de Investigación en Instrumentación y Acu´stica Aplicada (I2A2). ETSI Industriales. \nUniversidad Politécnica de Madrid. \nThe authors would like to thank Technical Research Centre for Dependency Care and Autonomous \nLiving (CETpD) for sharing the data used in this study. \nReferences  \nAlzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili, A., Duan, Y ., Al-Shamma, O., Santamaría, J., Fadhel, \nM.A., Al-Amidie, M., Farhan, L., 2021. Review of deep learning: concepts, CNN architectures, \nchallenges, applications, future directions. J Big Data 8, 53. \nBachlin, M., Hausdorff, J., Roggen, D., Giladi, N., Plotnik, M., Troster, G., 2009. Online detection of \nfreezing of gait in Parkinson’s disease patients: A performance characterization, in: Proceedings of \nthe Fourth International Conference on Body Area Networks, ICST (Institute for Computer Sciences, \nSocial-Informatics and Telecommunications Engineering), Brussels, BEL. \nBikias, T., Iakovakis, D., Hadjidimitriou, S., Charisis, V., Hadjileontiadis, L.J., 2021. DeepFoG: An IMU-\nBased Detection of Freezing of Gait Episodes in Parkinson’s Disease Patients via Deep Learning. \nFrontiers in Robotics and AI 8, 537384. \nBorzì, L., Fornara, S., Amato, F., Olmo, G., Artusi, C.A., Lopiano, L., 2020a. Smartphone-based \nevaluation of postural stability in Parkinson’s disease patients during quiet stance. Electronics \n(Switzerland) 9, 1–14. doi:10.3390/electronics9060919. \nBorzì, L., Olmo, G., Artusi, C.A., Fabbri, M., Rizzone, M.G., Romagnolo, A., Zibetti, M., Lopiano, L., \n2020b. A new index to assess turning quality and postural stability in patients with Parkinson’s \ndisease. Biomedical Signal Processing and Control 62. doi:10.1016/j.bspc.2020.102059. \nBorzì, L., Mazzetta, I., Zampogna, A., Suppa, A., Olmo, G., Irrera, F., 2021. Prediction of Freezing of \nGait in Parkinson’s Disease Using Wearables and Machine Learning. Sensors (Basel) 21. \nBorzì, L., Olmo, G., Artusi, C., Lopiano, L., 2020. Detection of Freezing of Gait in People with \nParkinson’s Disease using Smartphones. 2020 IEEE 44th Annual Computers, Software, and \nApplications Conference (COMPSAC) , 625–635. \nBreiman, L., 2001. Random forests. Machine learning 45, 5–32.  \nBachlin, M., Plotnik, M., Roggen, D., Maidan, I., J.M., H., Giladi, N., Tr¨oster, G., 2010. Wearable \nassistant for Parkinson’s disease patients with the freezing of gait symptom. IEEE Trans Inf Technol \nBiomed 14, 436–446. \nCamps, J., Sama, A., Martin, M., Rodriguez-Martin, D., Perez-Lopez, C., Arostegui, J., Cabestany, J., \nCatala, A., Alcaine, S., Mestre, B., et al., 2018. Deep learning for freezing of gait detection in \nParkinson’s disease patients in their homes using a waist-worn inertial measurement unit. Knowl. \nBased Syst. 139, 119–131. \nCupertino, L., Dos Reis, T.G., Los Angeles, E., Costa, T.M., Shokur, S., Bouri, M., de Lima-Pardini, A.C., \nCoelho, D.B., 2022. Biomechanical aspects that precede freezing episode during gait in individuals \nwith Parkinson’s disease: A systematic review. Gait Posture 91, 149–154. \nDel Din, S., Kirk, C., Yarnall, A.J., Rochester, L., Hausdorff, J.M., 2021. Body- Worn Sensors for Remote \nMonitoring of Parkinson’s Disease Motor Symp- toms: Vision, State of the Art, and Challenges Ahead. \nJ Parkinsons Dis 11, S35–S47. \nDemrozi, F., Bacchin, R., Tamburin, S., Cristani, M., Pravadelli, G., 2020. Toward a Wearable System for \nPredicting Freezing of Gait in People Affected by Parkinson’s Disease. IEEE J Biomed Health Inform. \n24, 2444–2451.  \nFreeman, E.A., Moisen, G.G., 2008. A comparison of the performance of threshold criteria for binary \nclassification in terms of predicted prevalence and kappa. Ecological modelling 217, 48–58. \nGholamiangonabadi, D., Kiselov, N., Grolinger, K., 2020. Deep neural networks for human activity \nrecognition with wearable sensors: Leave-one-subject-out cross-validation for model selection. IEEE \nAccess 8, 133982–133994. \nGiladi, N., Tal, J., Azulay, T., Rascol, O., Brooks, D.J., Melamed, E., Oertel, W., Poewe, W.H., Stocchi, F., \nTolosa, E., 2009. Validation of the freezing of gait questionnaire in patients with Parkinson’s disease. \nMov Disord 24, 655–661. \nGlorot, X., Bengio, Y ., 2010. Understanding the difficulty of training deep feed- forward neural \nnetworks, in: Teh, Y .W., Titterington, M. (Eds.), Proceed- ings of the Thirteenth International \nConference on Artificial Intelligence and Statistics, PMLR, Chia Laguna Resort, Sardinia, Italy. pp. 249–\n256. URL: https://proceedings.mlr.press/v9/glorot10a.html. \nHanley, J.A., McNeil, B.J., 1982. The meaning and use of the area under a receiver operating \ncharacteristic (roc) curve. Radiology 143, 29–36. \nHassani, A., Walton, S., Shah, N., Abuduweili, A., Li, J., Shi, H., 2021. Es- caping the big data paradigm \nwith compact transformers. arXiv preprint arXiv:2104.05704 . \nHeijmans, M., Habets, J., Herff, C., et al., 2019. Monitoring Parkinson’s disease symptoms during daily \nlife: a feasibility study. npj Parkinsons Dis. 5. doi:10. 1038/s41531-019-0093-5. \nHoehn, M.M., Yahr, M.D., 1967. Parkinsonism: onset, progression and mortal- ity. Neurology 17, 427–\n442. \nIrrera, F., Cabestany, J., Suppa, A., 2018. Editorial: New Advanced Wireless Technologies for Objective \nMonitoring of Motor Symptoms in Parkinson’s Disease. Front Neurol 9, 216. \nJothilakshmi, S., Gudivada, V., 2016. Handbook of statistics, vol. 35, ch. 10. keras.io,  2021.   Keras \ndocumentation:  Timeseries classification with a \ntransformer model. URL: https://keras.io/examples/timeseries/ \ntimeseries_classification_transformer/. accessed:  2021-12-20. \nKhan, A., Hammerla, N., Mellor, S., Pl¨otz, T., 2016. Optimising sampling rates for accelerometer-\nbased human activity recognition. Pattern Recogn. Lett. 73, 33–40. URL: \nhttps://doi.org/10.1016/j.patrec.2016.01.001, doi:10.1016/j.patrec.2016.01.001. \nKingma, D.P ., Ba, J., 2014. Adam: A method for stochastic optimization. arXiv arXiv:1412.6980.  \nLandolfi, A., Ricciardi, C., Donisi, L., Cesarelli, G., Troisi, J., Vitale, C., Barone, P ., Amboni, M., 2021. \nMachine Learning Approaches in Parkinson’s Disease. Curr Med Chem 28, 6548–6568. \nLi, B., Yao, Z., Wang, J., Wang, S., Yang, X., Sun, Y ., 2020. Improved Deep Learning Technique to Detect \nFreezing of Gait in Parkinson’s Disease Based on Wearable Sensors. Electronics 9, 1919. \nLi, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A., 2017. Hy- perband: A novel bandit-\nbased approach to hyperparameter optimization 18, 6765–6816. \nSilva de Lima, A.L., Evers, L.J.W., Hahn, T., Bataille, L., Hamilton, J.L., Little, M.A., Okuma, Y ., Bloem, \nB.R., Faber, M.J., 2017. Freezing of gait and fall detection in Parkinson’s disease using wearable \nsensors: a systematic review. J Neurol 264, 1642–1654. \nLin, T., Wang, Y ., Liu, X., Qiu, X., 2021. A survey of transformers. CoRR abs/2106.04554. \nMancini, M., Bloem, B.R., Horak, F.B., Lewis, S.J.G., Nieuwboer, A., Non- nekes, J., 2019. Clinical and \nmethodological challenges for assessing freezing of gait: Future perspectives. Mov Disord 34, 783–\n790. \nMancini, M., Shah, V.V., Stuart, S., Curtze, C., Horak, F.B., Safarpour, D., Nutt, J.G., 2021. Measuring \nfreezing of gait during daily-life: an open-source, wearable sensors approach. J Neuroeng Rehabil 18, \n1. \nMazilu, S., Blanke, U., Roggen, D., Troster, G., Gazit, E., Hausdorff, J.M., 2013. Engineers meet \nclinicians: Augmenting parkinson’s disease patients to gather information for gait rehabilitation, in: \nProceedings of the 4th Augmented Human International Conference, Association for Computing \nMachinery, New York, NY , USA. p. 124–127. \nMazilu, S., Hardegger, M., Zhu, Z., Roggen, D., Troster, G., Plotnik, M., Haus- dorff, J.M., 2012. Online \ndetection of freezing of gait with smartphones and machine learning techniques, IEEE. pp. 123 – 130. \n6th International Confer- ence on Pervasive Computing Technologies for Healthcare (PervasiveHealth \n2012); Conference Location: San Diego, CA, USA; Conference Date: May 21-24, 2012. \nMei, J., Desrosiers, C., Frasnelli, J., 2021. Machine learning for the diagnosis of parkinson’s disease: A \nreview of literature. Frontiers in Aging Neuroscience 13.  URL: \nhttps://www.frontiersin.org/article/10.3389/fnagi.2021.633752, doi:10.3389/fnagi.2021.633752. \nMonje, M.H.G., Foffani, G., Obeso, J., Sánchez-Ferro, 2019. New Sensor and Wearable Technologies \nto Aid in the Diagnosis and Treatment Monitoring of Parkinson’s Disease. Annu Rev Biomed Eng 21, \n111–143.  \nMoore, O., Peretz, C., Giladi, N., 2007. Freezing of gait affects quality of life of peoples with \nParkinson’s disease beyond its relationships with mobility and gait. Mov Disord 22, 2192–2195. \nMoore, S., MacDougall, H., W.G., O., 2008. Ambulatory monitoring of freezing of gait in Parkinson’s \ndisease. J Neurosci Methods 167, 340–348. \nMoore, S.T., Yungher, D.A., Morris, T.R., Dilda, V., MacDougall, H.G., Shine, J.M., Naismith, S.L., Lewis, \nS.J., 2013. Autonomous identification of freezing of gait in Parkinson’s disease from lower-body \nsegmental accelerometry. J Neuroeng Rehabil 10, 19.  \nNaghavi, N., Miller, A., Wade, E., 2019. Towards Real-Time Prediction of Freezing of Gait in Patients \nWith Parkinson’s Disease: Addressing the Class Imbalance Problem. Sensors 9, 3898. \nNaghavi, N., Wade, E., 2021. Towards Real-time Prediction of Freezing of Gait in Patients with \nParkinsons Disease: A Novel Deep One-class Classifier. IEEE Journal of Biomedical and Health \nInformatics . \nNieuwboer, A., De Weerdt, W., Dom, R., Lesaffre, E., 1998. A frequency and correlation analysis of \nmotor deficits in Parkinson patients. Disabil Rehabil 20, 142–150. \nNonnekes, J., Snijders, A.H., Nutt, J.G., Deuschl, G., Giladi, N., Bloem, B.R., 2015. Freezing of gait: a \npractical approach to management. Lancet Neurol 14, 768–778. \nNoor, M., Nazir, A., Wahab, M., Ling, J., 2021. Detection of Freezing of Gait Using Unsupervised \nConvolutional Denoising Autoencoder. IEEE Access 9. \nNutt, J.G., Bloem, B.R., Giladi, N., Hallett, M., Horak, F.B., Nieuwboer, A., 2011. Freezing of gait: \nmoving forward on a mysterious clinical phenomenon. Lancet Neurol 10, 734–744. \nOkuma, Y ., 2014. Practical approach to freezing of gait in Parkinson’s disease. Pract Neurol 14, 222–\n230. \nPardoel, S., Kofman, J., Nantel, J., Lemaire, E., 2019. Wearable-Sensor-Based Detection and \nPrediction of Freezing of Gait in Parkinson’s Disease: A Re- view. IEEE J Biomed Health Inform. 19, \n5141. \nRahman, S., Griffin, H.J., Quinn, N.P ., Jahanshahi, M., 2008. The factors that induce or overcome \nfreezing of gait in Parkinson’s disease. Behav Neurol 19, 127–136. \nRaza, A., Tran, K.P ., Koehl, L., Li, S., Zeng, X., Benzaidi, K., 2021. Lightweight transformer in federated \nsetting for human activity recognition. ArXiv abs/2110.00244.  \nRodríguez-Martín, D., Pérez-López, C., Samà, A., Cabestany, J., Català, A., 2013. A wearable inertial \nmeasurement unit for long-term monitoring in the dependency care area. Sensors (Basel) 13, 14079–\n14104. \nRodríguez-Martín, D., Samà, A., Pérez-López, C., Català, A., Moreno Arostegui, J., et al., 2017. Home \ndetection of freezing of gait using support vector machines through a single waist-worn triaxial ac- \ncelerometer. PLOS ONE 12. \nRovini, E., Maremmani, C., Cavallo, F., 2017. How Wearable Sensors Can Support Parkinson’s Disease \nDiagnosis and Treatment: A Systematic Review. Front Neurosci 11, 555. \nSan-Segundo, R., Navarro-Hellín, H., Torres-Sánchez, R., Hodgins, J., De la Torre, F., 2019. Increasing \nrobustness in the detection of freezing of gait in parkinson’s disease. Electronics 8. URL: \nhttps://www.mdpi.com/ 2079-9292/8/2/119. \nSchaafsma, J.D., Balash, Y ., Gurevich, T., Bartels, A.L., Hausdorff, J.M., Gi- ladi, N., 2003. \nCharacterization of freezing of gait subtypes and the response of each to levodopa in Parkinson’s \ndisease. Eur J Neurol 10, 391–398. \nShalin, G., Pardoel, S., Lemaire, E., Nantel, J., Kofman, J., 2021. Prediction and detection of freezing of \ngait in Parkinson’s disease from plantar pressure data using long short-term memory neural-\nnetworks. J NeuroEngineering Rehabil 18, 167. \nShavit, Y ., Klein, I., 2021. Boosting inertial-based human activity recognition with transformers. IEEE \nAccess 9, 53540–53547. doi:10.1109/ACCESS.2021. 3070646. \nSigcha, L., Costa, N., Pavón, I., Costa, S., Arezes, P ., López, J., De Arcas, G., 2020. Deep Learning \nApproaches for Detecting Freezing of Gait in Parkinson’s Disease Patients through On-Body \nAcceleration Sensors. Sensors 20, 1895. \nSnijders, A.H., Nijkrake, M.J., Bakker, M., Munneke, M., Wind, C., Bloem, B.R., 2008. Clinimetrics of \nfreezing of gait. Mov Disord 23 Suppl 2, S468– 474. \nSuppa, A., Kita, A., Leodori, G., Zampogna, A., Nicolini, E., Lorenzi, P ., Rao, R., Irrera, F., 2017. L-DOPA \nand freezing of gait in Parkinson’s disease: Ob- jective assessment through a wearable wireless \nsystem. Frontiers in Neurology \n8. doi:10.3389/fneur.2017.00406. \nSweeney, D., Quinlan, L.R., Browne, P ., Richardson, M., Meskell, P ., O´Laighin, G., 2019. A \nTechnological Review of Wearable Cueing Devices Addressing Freezing of Gait in Parkinson’s Disease. \nSensors (Basel) 19.  \nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L.u., Polosukhin, I., \n2017. Attention is all you need, in: Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R., \nVishwanathan, S., Gar- nett, R. (Eds.), Advances in Neural Information Processing Systems, Curran \nAssociates, Inc.  \nWeiss, A., Herman, T., Giladi, N., Hausdorff, J.M., 2015. New evidence for gait abnormalities among \nParkinson’s disease patients who suffer from freezing of gait: insights using a body-fixed sensor worn \nfor 3 days. J Neural Transm (Vienna) 122, 403–410. \nZach, H., Janssen, A.M., Snijders, A.H., Delval, A., Ferraye, M.U., Auff, E., Weerdesteyn, V., Bloem, \nB.R., Nonnekes, J., 2015. Identifying freezing of gait in Parkinson’s disease during freezing provoking \ntasks using waist-mounted accelerometry. Parkinsonism Relat Disord 21, 1362–1366. \nZhang, Y ., Yan, W., Yao, Y ., Ahmed, J., Tan, Y ., Gu, D., 2020. Prediction of Freezing of Gait in Patients \nWith Parkinson’s Disease by Identifying Impaired Gait Patterns. IEEE Transactions on Neural Systems \nand Rehabilitation Engineering 28, 591–600. ",
  "topic": "Accelerometer",
  "concepts": [
    {
      "name": "Accelerometer",
      "score": 0.8326101899147034
    },
    {
      "name": "Computer science",
      "score": 0.7284891605377197
    },
    {
      "name": "Waist",
      "score": 0.6364230513572693
    },
    {
      "name": "Transformer",
      "score": 0.5490657091140747
    },
    {
      "name": "Parkinson's disease",
      "score": 0.5377616286277771
    },
    {
      "name": "Gait",
      "score": 0.5093256235122681
    },
    {
      "name": "Simulation",
      "score": 0.3741801679134369
    },
    {
      "name": "Physical medicine and rehabilitation",
      "score": 0.3664451539516449
    },
    {
      "name": "Medicine",
      "score": 0.15082770586013794
    },
    {
      "name": "Disease",
      "score": 0.1471749246120453
    },
    {
      "name": "Voltage",
      "score": 0.13585203886032104
    },
    {
      "name": "Electrical engineering",
      "score": 0.13448205590248108
    },
    {
      "name": "Engineering",
      "score": 0.0
    },
    {
      "name": "Internal medicine",
      "score": 0.0
    },
    {
      "name": "Obesity",
      "score": 0.0
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I88060688",
      "name": "Universidad Politécnica de Madrid",
      "country": "ES"
    },
    {
      "id": "https://openalex.org/I99682543",
      "name": "University of Minho",
      "country": "PT"
    },
    {
      "id": "https://openalex.org/I177477856",
      "name": "Polytechnic University of Turin",
      "country": "IT"
    }
  ]
}