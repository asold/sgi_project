{
  "title": "PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry Generation",
  "url": "https://openalex.org/W4385573290",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A5083161796",
      "name": "Aitor Ormazabal",
      "affiliations": [
        "University of the Basque Country"
      ]
    },
    {
      "id": "https://openalex.org/A5023341622",
      "name": "Mikel Artetxe",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5062542123",
      "name": "Manex Agirrezabal",
      "affiliations": [
        "University of Copenhagen"
      ]
    },
    {
      "id": "https://openalex.org/A5053230169",
      "name": "Aitor Soroa",
      "affiliations": [
        "University of the Basque Country"
      ]
    },
    {
      "id": "https://openalex.org/A5047151336",
      "name": "Eneko Agirre",
      "affiliations": [
        "University of the Basque Country"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2963122608",
    "https://openalex.org/W3175637107",
    "https://openalex.org/W2963250244",
    "https://openalex.org/W3216596206",
    "https://openalex.org/W4385573604",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3205050810",
    "https://openalex.org/W2891911989",
    "https://openalex.org/W2973049837",
    "https://openalex.org/W2886314647",
    "https://openalex.org/W1587351043",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W3034807061",
    "https://openalex.org/W4288089799",
    "https://openalex.org/W2970091785",
    "https://openalex.org/W2741104967",
    "https://openalex.org/W2467834614",
    "https://openalex.org/W2798782765",
    "https://openalex.org/W2804191098",
    "https://openalex.org/W2963558617",
    "https://openalex.org/W3000537296",
    "https://openalex.org/W2250335499",
    "https://openalex.org/W2950909321",
    "https://openalex.org/W4229005866",
    "https://openalex.org/W2563845258",
    "https://openalex.org/W3214250531",
    "https://openalex.org/W2621157057",
    "https://openalex.org/W2982026991"
  ],
  "abstract": "Formal verse poetry imposes strict constraints on the meter and rhyme scheme of poems. Most prior work on generating this type of poetry uses existing poems for supervision, which are difficult to obtain for most languages and poetic forms. In this work, we propose an unsupervised approach to generate poems that follow any given meter and rhyme scheme, without requiring any poetic text for training. Our method works by splitting a regular, non-poetic corpus into phrases, prepending control codes that describe the length and end rhyme of each phrase, and training a transformer language model in the augmented corpus. The transformer learns to link the structure descriptor with the control codes to the number of lines, their length and their end rhyme. During inference, we build control codes for the desired meter and rhyme scheme, and condition our language model on them to generate formal verse poetry. Experiments in Spanish and Basque show that our approach is able to generate valid poems, which are often comparable in quality to those written by humans.",
  "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2022, pages 3655–3670\nDecember 7-11, 2022 ©2022 Association for Computational Linguistics\nPoeLM: A Meter- and Rhyme-Controllable Language Model for\nUnsupervised Poetry Generation\nAitor Ormazabal 1 Mikel Artetxe 2 Manex Agirrezabal 3 Aitor Soroa 1 Eneko Agirre 1\n1HiTZ Center, University of the Basque Country (UPV/EHU)\n2Meta AI 3University of Copenhagen\n{aitor.ormazabal,a.soroa,e.agirre}@ehu.eus\nartetxe@meta.com manex.aguirrezabal@hum.ku.dk\nAbstract\nFormal verse poetry imposes strict constraints\non the meter and rhyme scheme of poems.\nMost prior work on generating this type of po-\netry uses existing poems for supervision, which\nare difﬁcult to obtain for most languages and\npoetic forms. In this work, we propose an unsu-\npervised approach to generate poems that fol-\nlow any given meter and rhyme scheme, with-\nout requiring any poetic text for training. Our\nmethod works by splitting a regular, non-poetic\ncorpus into phrases, prepending control codes\nthat describe the length and end rhyme of each\nphrase, and training a transformer language\nmodel in the augmented corpus. The trans-\nformer learns to link the structure descriptor\nwith the control codes to the number of lines,\ntheir length and their end rhyme. During in-\nference, we build control codes for the desired\nmeter and rhyme scheme, and condition our lan-\nguage model on them to generate formal verse\npoetry. Experiments in Spanish and Basque\nshow that our approach is able to generate valid\npoems, which are often comparable in quality\nto those written by humans.\n1 Introduction\nDespite the impressive generative capabilities of\nlarge Language Models (LMs) ( Brown et al. , 2020;\nChowdhery et al. , 2022; Zhang et al. , 2022) au-\ntomatic poetry generation remains a challenging\nproblem. Formal verse poetry , in particular, im-\nposes strict constraints on the meter and rhyme\nscheme of poems (Figure\n1), which cannot be di-\nrectly controlled in conventional LMs.\nPrior work on generating formal verse poetry has\nprimarily focused on supervised approaches, lever-\naging existing poems to train LMs. This is often\ncombined with additional techniques to impose the\nmeter and rhyme constraints at inference time, such\nas using ﬁnite-state automata to discard invalid can-\ndidates ( Ghazvininejad et al. , 2016), or generating\ntext right-to-left to better control the rhyming word\nPen | san | do |  que el |  ca | mi | no i | ba |  de | r e | cho ,\nvi | ne a |  pa | rar |  en |  tan | ta |  des | ven | t u | ra ,\nque i | ma | gi | nar |  no |  pue | do, aún |  con |  lo | c u | ra ,\nal | go |  de |  que es | té un |  ra | to |  sa | tis | f e | cho .\n<LEN:11><END:echo>\n<LEN:11><END:ura>\n<LEN:11><END:ura>\n<LEN:11><END:echo>\nFigure 1: A formal verse poem and its associated\nstructure descriptor. The poem is the ﬁrst stanza of a\nSpanish sonnet, which must have 4 lines of 11 syllables\nand follow an ABBA rhyme scheme. We use control\ncodes to describe such constraints, and train a language\nmodel that can generate text conditioned on them.\n(Lau et al. , 2018; Jhamtani et al. , 2019; Xue et al. ,\n2021). However, these approaches require poetic\ntext for training, which is difﬁcult to obtain for\nmost languages and poetic forms.\nIn this paper, we propose an unsupervised ap-\nproach to generate formal verse poetry. Our Poetic\nLanguage Model (PoeLM) can be conditioned to\nfollow any desired meter and rhyme scheme, with-\nout requiring any poem for training. As illustrated\nin Figure 2, the key idea behind our method is that\nany text can be divided into phrases, which will\neach have a certain number of syllables and end\nin a certain sound that can make it rhyme with\nother phrases. While this structure will not follow\na regular pattern for standard text, as it would for\npoetry, we can still annotate it automatically, and\ntrain a language model that can be conditioned on\nsuch structure descriptors. At inference time, we\nbuild a structure descriptor for the desired meter\nand rhyme scheme, and condition our language\nmodel on it to generate formal verse poetry. To\nimprove results, we generate multiple candidates,\nwhich are automatically ﬁltered and re-ranked.\nOur experiments in Spanish and Basque show\nthat our method is able to generate high quality\npoems meeting the desired meter and rhyme con-\nstraints, with human evaluators ranking our system\nhigher than other humans in more than one third of\nthe cases. Our code is available at GitHub. 1\n1https://github.com/aitorormazabal/\npoetry_generation\n3655\nEn estos años se verá, \ndebido al cambio \nclimático, una subida de \ntemperatura.\n<PREF> <LEN:8><END:a>\n<LEN:10><END:atico>\n<LEN:11><END:ura> </PREF>\nEn estos años se verá, <BRK>\ndebido al cambio climático, <BRK>\nuna subida de temperatura. <BRK>\nTRANSFORMER LANGUAGE MODEL\n<PREF> <LEN:8> </PREF> En\n… …\n<LEN:8> <END:era> En estos\n… …\n(a) Training on regular, non-poetic text. Example in Spanish.\n<PREF>\n<LEN:11><END:ora>\n<LEN:11><END:ones>\n<LEN:11><END:ones>\n<LEN:11><END:ora>\n</PREF>\nTRANSFORMER LANGUAGE MODEL\n<PREF> <LEN:11> <END:ora> </PREF>\n… …\n<LEN:11> <END:ora> </PREF> w\n1\n… …\nMuerte, deidad temida, triunfad ora , <BRK>\npatrona de las desaparici ones , <BRK>\namamantadora de los ladr ones , <BRK>\npatrona de la ametrallad ora . <BRK>\n(b) Generation of formal verse poetry. Example in Spanish.\nFigure 2: Proposed method. (a) During training, we split non-poetic text into phrases according to punctuation\nmarks, prepend control codes describing the length and end rhyme of each phrase, and train a transformer language\nmodel on it. (b) During inference, we build a structure descriptor with control codes for the desired meter and rhyme\nscheme, and condition our language model on them to generate formal verse poetry.\n2 Background: formal verse poetry\nPoetic traditions differ across languages and cul-\ntures. In this work, we focus on formal verse po-\netry in Spanish and Basque, 2 which impose strict\nmeter and rhyme constraints as follows:\n• The syllabic meter speciﬁes the number of\nlines in the poem, as well as the number of syl-\nlables that each line must contain. 3 Spanish\nsyllabic meter allows for synalephas, where\ntwo syllables can be merged into one when\none word ends in a vowel and the next starts\nwith one. For simplicity, we do not consider\nsynalephas when counting syllables, although\nour method could easily be extended to ac-\ncount for them.\n• The rhyme scheme speciﬁes the pattern ac-\ncording to which lines must rhyme. For in-\nstance, the ABAB scheme requires the 1st line\nto rhyme with the 3rd one, and the 2nd line to\nrhyme with the 4th one. Two lines are consid-\nered to rhyme if they repeat the same sound\nat their last syllables.\n4 In addition, rhyming\nlines cannot end in the same word.\n2The selected languages where narrowed down according\nto the availability of publicly available high-quality syllabiza-\ntion and rhyme detection systems (which discarded English),\nas well as the ﬂuency of the authors.\n3Some traditions impose a stress pattern in addition to the\nnumber of syllables, which is known as accentual-syllabic\nmeter. We do not consider this type of meter in our work, as it\nis not common in Spanish and Basque.\n4In Spanish, two words rhyme if their sounds are identical\nfrom the last stressed vowel onwards. In Basque, two words\nrhyme if their sounds match from the ﬁrst vowel of the second\nThere are different poetic forms depending on\nthe speciﬁc meter and rhyme scheme that they im-\npose. For instance, the ﬁrst stanza of a Spanish\nsonnet must consist of four verses with 11 syllables\neach, following an ABBA rhyme scheme. As illus-\ntrated in Figure 1, we use control codes to deﬁne\nsuch meter and rhyme constraints, which we refer\nto as structure descriptors .\n3 Proposed method\nAs described in § 2, we want our system to be able\nto generate text that adheres to a speciﬁc structure.\nThe key idea behind our approach is that, similar\nto formal verse poetry, any text adheres to a certain\nimplicit structure. In the case of non-poetic text the\nstructure will not follow any regular pattern, but we\ncan still extract it and build a structure descriptor\nfor it. We can then augment the non-poetic corpus\nwith these descriptors, and train a regular LM on\nit (Figure 2a). The model thus learns to respect\nthe structure provided in the descriptor, which al-\nlows us to generate formal verse poetry at inference\ntime, by conditioning the model on the appropriate\nstructure descriptor (Figure 2b).\nWe next describe the two main components of\nour method: structure-aware training (§ 3.1) and\ninference with ﬁltered re-ranking (§ 3.2).\nto last syllable onwards, and the following consonant groups\nare considered to sound the same for the purposes of rhyme:\n{p,t,k}, {n,m}, {s,z,x}, and {b,d,g,r}.\n3656\n3.1 Structure-aware training\nLet X be the space of possible text sequences, and\nS be the space of possible structure descriptors.\nWe can deﬁne a function s : X → P (S) that maps\neach sequence of text into its corresponding set\nof descriptors.\n5 We want to build a model that\ncan sample from P (X|c ∈ s(X)), that is, that can\nsample text conditioned on an structure descriptor\nc. In theory, one could do this through rejection\nsampling, by repeatedly drawing sentences from\nx ∼ P (X) until one of them satisﬁes c ∈ s(x).\nHowever, this is intractable in practice, since the\nprobability of a randomly sampled text following\nthe desired structure is practically zero.\nInstead, we train a LM that can be conditioned\non any given structure (see Figure 2a). To that end,\nwe start by annotating the implicit structure of a\nregular, non-poetic corpus. We ﬁrst split the corpus\nin phrases, where we deﬁne a phrase as a sequence\nof text delimited by either a newline or a punctua-\ntion character (e.g., commas, colons or quotes). We\ndo this so that the rhyme words at the end of these\nunits correspond to natural stopping points. We\nthen group the text in blocks of n phrases, where n\nis randomly sampled. For each block x, we choose\na structure descriptor cx ∈ s(x) that deﬁnes the\nlength and end rhyme of each of the phrases it\ncontains. We then create an augmented corpus\n(cx1 , x1, cx2 , x2, ...) by interleaving the previously\ngenerated structure descriptor cxi before its corre-\nsponding text block xi (see Appendix A for more\ndetails). Finally, we train a transformer LM on\nthe augmented corpus. The control codes in the\nstructure descriptors are treated as regular tokens,\nand the model is trained with the standard next\ntoken prediction objective.\n3.2 Generation with ﬁltered re-ranking\nAt inference time, we use the LM from § 3.1 to\ngenerate formal verse poetry in 3 steps:\n1. Candidate generation. We specify the desired\nmeter and rhyme scheme as a structure descriptor, 6\nand use our LM to generate text conditioned on it\n(see Figure 2b). We repeat the process k = 3000\ntimes to generate k different candidates. In our\n5Each sequence is mapped to a subset of S, as the same\nsequence could be described by multiple descriptors.\n6A rhyme scheme speciﬁes which lines must rhyme, but\nnot what the rhyme sound should be. We thus generate a con-\ncrete structure descriptor from the given scheme by sampling\neach rhyme sound independently from the ﬁve most common\nrhyme sounds in the training corpus.\nexperiments, we provide the ﬁrst line of the poem\nto generate in addition to its structure descriptor,\nwhich is useful to deﬁne the subject and make dif-\nferent systems easier to compare.\n2. Filtering. In practice, some of the generated\ncandidates do not meet the given constraints or are\notherwise pathological. For that reason, we ﬁlter\ncandidates according to the following conditions:\n1. #Line. The candidate must have the number\nof lines speciﬁed in the structure descriptor.\n2. #Slb. Each line must have the number of syl-\nlables speciﬁed in the structure descriptor.\n3. Rhyme. Each line must end in the rhyme\nsound speciﬁed in the structure descriptor.\n4. Rep. word. No two rhyming lines can end in\nthe same word.\n5. BLEU. In order to prevent the model from\ngenerating repetitive text, the maximum and\naverage BLEU across any two lines must be\nbe less than or equal to 35 and 20.\n3. Re-ranking. We score the remaining candi-\ndates for ﬂuency using our LM, and output the\none with the highest score. Different from the ﬁrst\nstep, we do not condition on the structure descrip-\ntor when doing so, which gives a measure of the\ngeneral ﬂuency.\nWe test the efﬁcacy of the second and third steps\nin the experiments.\n4 Experimental design\nWe run experiments on Spanish and Basque. We\nnext detail the training details (§ 4.1) and the auto-\nmatic and human evaluation setup (§ 4.2 and § 4.3).\n4.1 Training details\nHyperparameters. We train transformer LMs\nusing the same settings as Brown et al. (2020). For\nBasque, we train a 350M model with a learning rate\nof 3 × 10−4 and linear decay over 300B tokens. 7\nFor Spanish, we train a 760M model over 100B\ntokens using a constant 8 learning rate of 2.5×10−4.\n7In practice, we stop training after seeing around 85B\ntokens, when performance plateaus in the validation set.\n8We initially planned to manually decay the learning rate\naccording to validation perplexity. However, we did not ob-\nserve performance plateauing (presumably due to the large\ncorpus and our constrained compute budget), so the full train-\ning was done with a constant learning rate.\n3657\nCorpora. We use EusCrawl ( Artetxe et al. , 2022)\nas our training corpus for Basque, which takes\n2.5GB in plain text format, and a subset of 700GB\nfrom mC4 ( Raffel et al. , 2019) for Spanish. Given\nthe small size of the Basque corpus, we combine\n10 versions of the corpus using different random\nseeds to generate the structure descriptors.\nPreprocessing. We use SentencePiece tokeniza-\ntion ( Kudo and Richardson , 2018) with a 50k vo-\ncabulary for each language, and reserve 8.5k tokens\nfor the control codes in the structure descriptors.\nFor syllabiﬁcation and rhyme sound extraction we\nuse the rules provided by Agirrezabal et al. (2012),9\nwhich are encoded as ﬁnite-state transducers imple-\nmented in Foma ( Hulden, 2009).\nModels. In addition to our proposed model\n(PoeLM), we train a regular LM for each lan-\nguage as a baseline, using the exact same hyper-\nparameters, tokenization, and corpora (without the\ninterleaved structure descriptors).\n4.2 Automatic evaluation\nWe use Spanish poems from the 20th century sub-\nset of the DISCO dataset ( Barbado et al. , 2021),\nand Basque poems from the BDB dataset 10 to eval-\nuate our approach. The DISCO and BDB datasets\nconsist of 20k and 44k tokens before our Sentence-\nPiece tokenizer is applied, respectively. We use the\nfollowing automatic metrics:\nFiltering rate. We take 10 poems 11 from each\ntest set, extract the ﬁrst line from them, generate\npoems for each as described in § 3.2 following the\nmeter and rhyme scheme of the original poem, with\nk = 3000 candidates for each, and measure the\npercentage of candidates that are ﬁltered according\nto the criteria in § 3.2. We compare the resulting\nﬁltering rate of our proposed PoeLM, which is con-\nditioned on the relevant structure descriptor, and a\nregular LM, which is not conditioned on any struc-\nture but could still generate a valid poem given\nenough trials.\n9https://bitbucket.org/\nmanexagirrezabal/syllabification_gold_\nstandard\n10https://bdb.bertsozale.eus/. We use the\n2005 segment of the corpus.\n11For Spanish, we use the ﬁrst Stanza of full sonnets from\nDISCO, which consist of either 11 or 14 syllable lines, follow-\ning a rhyme scheme of ABAB or ABBA. For Basque, we use\nZortziko Handia poems from BDB, which consist of 8 lines,\nwhere the odd ones are 10 syllables long, the even ones are 8\nsyllables long, and only the even lines are required to rhyme.\nSince, unlike PoeLM, the baseline LM does not\ngenerate break tokens to separate lines, we split the\ngenerated text into lines according to the relevant\nnumber of syllables. When this cannot be done\nwhile respecting word boundaries, we consider that\nthe candidate is rejected for breaking the #slb con-\ndition. As a consequence, generations from the\nbaseline LM are never considered to be rejected\ndue to the #verse condition.\nPerplexity. To understand how well the model\nis able to leverage the information provided by a\nknown structure, we compare the per-token per-\nplexity of (i) PoeLM conditioned on the relevant\nstructure descriptor, (ii) PoeLM without condition-\ning on any structure descriptor, (iii) the baseline\nLM. We do this both in the validation set of the\nnon-poetic corpus used for training, as well as the\npoem datasets used for evaluation.\nConsistent with training, we insert break tokens\nto separate lines for both PoeLM variants. How-\never, these special tokens are excluded from the\nperplexity computation to make them comparable\nwith the baseline LM.\n4.3 Human evaluation\nWe run a qualitative evaluation in Spanish compar-\ning poems generated by our system and humans.\nGiven that writing poems is also challenging for\nhumans, we consider both poems written by actual\npoets as well as layman volunteers. More con-\ncretely, we take the ﬁrst line of 50 poems from the\nDISCO dataset, and compare 3 poems generated\nby completing them as follows:\n• Expert: The original poem from DISCO from\nwhich the ﬁrst line was extracted, authored by\na renowned poet.\n• Layman: Poems written by non-expert volun-\nteers within a time limit of about 5 minutes.\n• PoeLM: Poems generated by our system us-\ning the full pipeline described in § 3.2.\nWe then give these 3 poems 12 to human evalua-\ntors in a random order, and ask them to rank from\nbest to worst. We report results according to two\nmetrics: the overall rank (the percentage of times\nthat each system has been ranked in each position),\nand the head-to-head comparison (the percentage\n12A 4th candidate, which we ignore when calculating the\nratings, was also included for the analysis in § 6.2.\n3658\nSpanish Basque\nPoeLM LM PoeLM LM\nCorrect 30.9 0.0 23.4 0.0\nReject due to\n#Verse 3.7 0.0 9.6 0.0\n#Slb 17.0 96.6 34.0 90.3\nRhyme 13.1 3.4 11.1 9.7\nRep. word 31.1 - 19.7 -\nBLEU 4.2 - 2.3 -\nTable 1: Percentage of ﬁltered candidates, with a break-\ndown for the reason of rejection. See § 4.2 for details.\nSpanish Basque\npoetic prose poetic prose\nBaseline LM 62.7 15.9 151.1 24.3\nPoeLM w/ struc 49.5 11.7 42.5 10.1\nno struc 129.5 18.0 634.2 81.4\nTable 2: Perplexity of poetic and non-poetic (prose)\ncorpora. See § 4.2 for details.\nof times that each system has been ranked before\neach other system).\nAll volunteers that wrote the poems, as well as\nthose that ranked the candidates, are native Span-\nish speakers with university studies. While there\nwas an overlap between both groups of volunteers,\nwe made sure that volunteers were never asked to\nrank poems written by themselves. All volunteers\nare familiar with the fundamentals of formal verse\npoetry, but are not experts in the matter. Refer to\nAppendix B for more details.\n5 Results\nWe next discuss our main results for the automatic\n(§5.1) and human evaluation (§ 5.2).\n5.1 Automatic evaluation\nWe report ﬁltering rate results in Table 1. We ﬁnd\nthat 30.9% of Spanish poems and 23.4% of Basque\npoems sampled from PoeLM meet the given con-\nstraints. While far from perfect, this means that\nsampling a few candidates is enough to obtain a\nvalid poem with our approach. In contrast, none of\nthe poems generated by the baseline LM is valid,\nshowing that our proposed structure-aware training\nis critical to generate formal verse poetry with LMs.\nRegarding the reason for rejection, we ﬁnd that the\nmajority of candidates from PoeLM are discarded\nfor repeating rhyming words, which the model was\nnot directly trained to prevent.\nS1\nS2 Expert Layman PoeLM\nExpert - 54.0% 62.7%\nLayman 46.0% - 60.7%\nPoeLM 37.3% 39.3% -\nTable 3: Percentage of times that system S1 is ranked\nahead of S2 in the human evaluation.\n1st 2nd 3rd\nExpert 44.0% 28.6% 27.3%\nLayman 36.7% 33.3% 30.0%\nPoeLM 19.3% 38.0% 42.7%\nTable 4: Percentage of times that each system has been\nranked in each position in the human evaluation.\nTable 2 reports the perplexity results. When\nconditioned on structure descriptors, our model\nalways outperforms the baseline LM, meaning that\nit is able to make better predictions accounting for\nthe meter and rhyme constraints. However, when\nthe structure descriptor is not provided, our model’s\nperplexity is higher, presumably because the model\ndid not see text without structure descriptors during\ntraining.\n5.2 Human evaluation\nWe report head-to-head results in Table 3, and rank-\ning results in Table 4. Human evaluators prefer\npoems generated by our system over those written\nby renowned poets in 37.3% of the cases. Similarly,\nour system does better than laymen in 39.3% of\nthe cases. This shows that our system is able to\ngenerate high-quality poems, which humans often\nprefer over poems written by other humans. This\ncan also be seen in the ranking evaluation, as our\nsystem has been ranked in ﬁrst position in 19.3% of\ncases, and among the ﬁrst two positions in 57.3%\nof cases.\nFinally, it is surprising that layman poems are\nranked above those from renowned poets nearly\nhalf of the times. We attribute this to the human\nevaluators themselves being laymen, leading them\nto prefer poems that use more plain language. This\nis also reﬂective of the subjective nature of the task,\nas different readers might enjoy poetry differently.\n6 Analysis\nWe further analyze our system by quantifying\nat which portion of the poem its perplexity gain\nis highest (§\n6.1), experimenting with manual re-\n3659\n0.0\n0.5\n1.0\n1.5\n0.00 0.25 0.50 0.75 1.00\nProximity\nLog prob. difference\nFigure 3: Interpolated advantage in log probability of\nour model compared to a regular LM over the Spanish\nmC4 validation set, as a function of normalized prox-\nimity to the next speciﬁed rhyme token. See §\n6.1 for\ndetails.\nS1\nS2 Exp. Lay. PoeLM PoeLM\n+rerank\nPoeLM 37.3 39.3 - 26.0\nPoeLM 41.3 42.7 38.0 -+rerank\nTable 5: Percentage of times that system S1 is ranked\nahead of S2 in the human evaluation. Since the candi-\ndate chosen by a human annotator among the top 6 can-\ndidates will sometimes be the same as the top candidate,\nthere can be ties, and thus the head-to-head percentages\ndo not add up to 100.\nranking (§ 6.2), and looking at some sample poems\n(§6.3).\n6.1 Perplexity gain\nWe quantify the predictive advantage of our system\nas a function of the distance to the next rhyme\nword. To this end, we plot the difference in token-\nwise log probabilities between our model and the\nbaseline LM as a function of proximity to the next\nrhyme word, interpolated between 0 and 1. We\nonly consider lines with 15 to 25 tokens.\nAs shown in Figure 3, our model’s advantage is\ngreatest near the rhyme word. This is not surpris-\ning, as there is less uncertainty towards the end of\nthe line when the meter and rhyme are known. We\nobserve a downward spike towards the end, that\nmay initially seem counter-intuitive. We hypothe-\nsize that, since the rhyme word will often be split\ninto multiple tokens, by the time the ﬁrst tokens\nof the rhyme word are known the regular LM will\nbe quite sure of what the word is, meaning that the\nadvantage of knowing the rhyme is lower.\n6.2 Manual re-ranking\nA potential application of automatic poetry genera-\ntion is helping (rather than replacing) humans when\nwriting poems. As a ﬁrst approximation, we ask\nour volunteers to manually choose a poem among\nthe top 6 candidates generated by our system. 13\nThe resulting poem was considered as part of the\nhuman evaluation described in § 4.3, and compared\nto the other 3 systems.\nTable 5 reports the head-to-head performance\nof our model with and without manual re-ranking.\nAs expected, the re-ranked model performs better,\nbeating the poems generated by laymen in 42.7%\nof cases, as opposed to 39.3% for the base system.\nHowever, the base system beats manual re-ranking\nin 26% of cases, meaning that human evaluators of-\nten prefer the top candidate automatically selected\nby the system over the one manually selected by\nanother human. This means that there is a con-\nsiderable disagreement across annotators, which is\nreﬂective of the subjective nature of the task.\n6.3 Sample poems\nTables 6 and 7 show some example poems gener-\nated by our system in Spanish and Basque. The\npoems were generated by providing the ﬁrst line\nalong with the structure descriptor to the system,\nand manually selecting a candidate among the top\nsix. Five lines were selected at random from the\nevaluation in Spanish, and two for Basque. The full\nlist with the six candidates is given in Appendix C.\nNo cherry-picking was done, except to choose one\npoem among the six candidates per line.\nWe observe that the system is capable of gener-\nating coherent poems covering varied topics. For\nexample, regarding the Spanish poems, the ﬁrst,\nthird and fourth Spanish poems cover themes of\ninner conﬂict, the second one describes a person’s\nbeauty, and the last is about an abbey called Mon-\nserrat. Note that the theme is implicit in the ﬁrst\nline, and mirrors the typical topics of Spanish son-\nnets of the time. Regarding the Basque poems, the\nthemes are friendship and swings in a park, also\nmirroring the themes used in contemporary sponta-\nneous poetry contests in the dataset.\n7 Related work\nWe next review relevant literature in poetry gen-\neration (§ 7.1), as well as controllable generation\n13We take the top three candidates with and without BLEU\nﬁltering to generate this list.\n3660\nGenerated Poem English translation\nSiento otro Yo que contra mí se empeña,\nun Yo para el que no debo luchar,\nun Yo al que no debo acompañar,\nun Yo que a menudo me condena.\nI feel another Self that is set against me,\na Self for which I must not ﬁght,\na Self that I should not accompany,\na Self that often condemns me.\nCasta su faz, bajo la blanca toca,\nsu faz es dulce,es bella sin cesar,\nsu faz es hermosa como un jaguar,\nsu faz es divina como la roca.\nChaste is her face, under her white cap,\nher face is sweet, relentlessly gorgeous,\nher face is beautiful like a jaguar,\nher face is divine like rock.\nNada más. De aquel sueño, que pasó como un ala,\narranco todo lo que había en mi mente,\ntodo lo que me atormentaba y no cala,\nlo que callo en el interior de mi presente.\nNothing more. Of that dream, that passed like a wing,\nit tore everything from my mind,\nall that tormented me and doesn’t seep through,\nwhich I keep quiet inside my present.\nEs inútil que luche por quitarme del pecho,\nque niegue repetidamente mis opiniones,\nque trague de nuevo mi entusiasmo deshecho,\nque rechace de nuevo todas mis negaciones.\nFighting to get it off my chest is futile,\nthat I repeatedly deny my emotions,\nthat I once again swallow my undone enthusiasm,\nthat I once again reject all my negations.\nDel Monserrat en la penumbra undosa,\nDel Monserrat silente en el Solar,\nDel Monserrat dolido en el remar,\nDel Monserrat cautivo en la prosa.\nOf the Monserrat in the gloomy twilight,\nOf the Monserrat, silent in sunlight,\nOf the Monserrat, pained in paddling,\nOf the Monserrat, captive in prose.\nTable 6: Spanish poems generated by our method, given ﬁve lines selected at random from the dataset. The ﬁve\npoems have been manually selected from the top six candidates generated by the system for each line, with no other\nform of cherry-picking. See Appendix C for the full list of six candidate poems.\n(§7.2).\n7.1 Poetry generation\nRetrieval based approaches. Early work in poetry\ngeneration focused on rule-base methods, which\ngenerate text according to predeﬁned rules that\nensure the desired structure is followed (\nGervás,\n2000; Gonçalo Oliveira et al. , 2007). A pop-\nular approach is to ﬁll templates with text ex-\ntracted from existing poems (\nColton et al. , 2012;\nGonçalo Oliveira , 2012; Gonçalo Oliveira et al. ,\n2017). This makes it easy to control poetic struc-\nture, since the meter and rhyme schemes of the text\npieces can be annotated in advance and combined\naccordingly when ﬁlling the templates. However,\nthe diversity and creativity of these approaches is\nlimited.\nNeural poetry generation. More recently, there\nhas been work on applying neural text generation to\npoetry. A popular approach is to train a ﬁnite-state\nacceptor (FSA) that ensures all accepted sequences\nobey the required structure, which is then used to\nguide a recurrent neural network (RNN) through re-\njection sampling (\nGhazvininejad et al. , 2016, 2018;\nHopkins and Kiela , 2017). However, these meth-\nods require some form of lyrical or poetic text to\ntrain the RNN or the FSA, and they must generate\ntext right-to-left in order to respect rhyme sounds,\nas the model has no concept of planning. Addition-\nally, a new FSA has to be trained for each desired\npoem structure. Lau et al. (2018) augment an RNN\nwith a pentameter model and learn the meter and\nrhyme constraints of sonnets in a supervised way\nfrom a sonnet corpus. They then generate poem\nlines right-to-left, to alleviate the model’s lack of\nplanning.\nVan de Cruys (2020) trains an encoder-\ndecoder RNN on prosaic text to generate each line\nright-to-left conditioned on the previous one, and\napplies constraints when decoding to ensure the\ngenerated text adheres to a rhyme scheme and con-\nsistent topic. However, their system cannot enforce\na speciﬁc syllabic meter.\nMultiple works focus on neural poetry genera-\ntion for the Chinese language, applying techniques\nsuch as reinforcement learning ( Yi et al. , 2018) or\nplanning ( Wang et al. , 2016). In Chinese, one char-\nacter corresponds to a syllable, but meter is gov-\nerned by tonal constraints. Most of the reviewed\nworks assume that, with a sufﬁciently large corpus,\nthe model should be able to learn the implicit tonal\nstructure of poetry ( Wang et al. , 2016; Zhang et al. ,\n2017; Liu et al. , 2018). Yeh et al. (2019) concate-\nnate tonal information to the character embeddings\nof an LSTM to create a model that is more phono-\nlogically compliant.\nNotably, current neural methods capable of con-\ntrolling both syllable count and rhyme scheme re-\nquire some form of poetic corpus to train, and usu-\n3661\nGenerated Poem English translation\nGu biok lagun handiak gara,\nanaia,aita,semea,\neta bion ideologia,\ngure identitatea,\nkonpartitzen dugu.Batzuetan,\nzaila da bat esatea,\nbesteak ulertzea,benetan,\nzein ahula den bestea.\nThe both of us are great friends,\nbrother,father,son,\nand our ideology,\nour identity,\nis shared. Sometimes,\nit is hard to say one,\nto understand others, truly,\nhow weak others are.\nNahiz kulunpio pila bat egon,\neguzkiak sikiera,\naukera du ondo goxatzeko,\neta ez beti gainera,\nbaita asteko egun denetan,\nbaita hemendik aurrera,\nilargi erdiko orduetan,\neta hori da ederra.\nEven though there are many swings,\nat least the sun,\nhas a chance to enjoy,\nnot always,\nalso during every day of the week,\nand, from now on,\nduring the moon hours,\nand that is beautiful.\nTable 7: Basque poems generated by our method, given two lines selected at random from the dataset. The poems\nhave been manually selected from the top six candidates generated by the system for each line, with no other from\nof cherry-picking. See Appendix C for the full list of six candidate poems.\nally generate text right-to-left to alleviate a lack of\nplanning when generating rhymes.\n7.2 Controllable generation\nSimilar to our approach, several works attempt to\ncontrol the generated output by augmenting the\ntraining data with tags.\nKeskar et al. (2019) aug-\nment the training corpus of a LM with codes auto-\nmatically extracted from metadata. Some works in\nmachine translation explore augmenting the train-\ning data in order to control the politeness ( Sen-\nnrich et al. , 2016), domain ( Kobus et al. , 2016),\nor length ( Lakew et al. , 2019) of generated trans-\nlations. Schioppa et al. (2021) experiment with\nvector-valued additive tags in order to control mul-\ntiple attributes of the generated text at once. How-\never, all of these systems use tags that only broadly\nspecify the length, domain or style of the text to\ngenerate. In contrast, our model is conditioned on\na very speciﬁc meter and rhyme scheme that the\ntext must follow.\n8 Conclusions and future work\nIn this work, we present an unsupervised approach\nto generate formal verse poetry. We identify and ex-\ntract the latent structure in non-poetic corpora, and\nfeed this information along with the text to a trans-\nformer LM, allowing us to control the structure of\nthe text at generation time. Our system is capa-\nble of generating formal verse poetry with ﬂexible\nmeter and rhyme schemes, without requiring any\nsort of poetic text to train. The required structure\ncan be easily altered by changing the descriptor,\nallowing us to generate different types of poetry\nwithout needing to re-train the system. Automatic\nand human evaluations show that our model learns\nto leverage the provided structure information to\nbetter predict the text, and is capable of generat-\ning short poems that are often preferred to those\ncreated by a human.\nIn future work, we would like to extend our\nframework to be able to control other aspects of the\ngenerated text in addition to meter and rhyme.\nLimitations\nGiven that our method requires tagging the implicit\nmeter and rhyme of the training corpus, we are\nlimited by the quality of available syllabization\nand rhyme detection systems. While rule-based\nsystems with a low error rate are easy to create for\nlanguages such as Spanish or Basque, this is not\nthe case for English, which is why we did not train\nan English version of our system. However, our\napproach is independent of the used syllabization\nand rhyme detection process, and could be readily\napplied on top of any system with a low error-rate.\nAdditionally, our Spanish syllabization system\nhas no concept of synalephas, where two syllables\ncan be merged into one when one word ends in\na vowel and the next starts with one. This means\nthat our system will never use this Spanish literary\ndevice when generating poems.\n3662\nAcknowledgements\nAitor Ormazabal, Aitor Soroa and Eneko Agirre\nwere partially supported by the Basque Govern-\nment (IXA excellence research group IT1343-19).\nAitor was supported by a doctoral grant from the\nSpanish MECD.\nWe would like to thank Ainara Estarrona, Be-\ngoña Altuna and Itziar Gonzalez-Dios for their as-\nsistance in deﬁning literary terminology, and Ed-\nward Yao for his help translating poems.\nReferences\nManex Agirrezabal, Inaki Alegria, Bertol Arrieta, and\nMans Hulden. 2012. Finite-state technology in a\nverse-making tool. In Proceedings of the 10th In-\nternational Workshop on Finite State Methods and\nNatural Language Processing , pages 35–39.\nMikel Artetxe, Itziar Aldabe, Rodrigo Agerri,\nOlatz Perez de Viñaspre, and Aitor Soroa. 2022.\nDoes corpus quality really matter for low-resource\nlanguages?\nAlberto Barbado, Víctor Fresno, Ángeles Manjarrés\nRiesco, and Salvador Ros. 2021. DISCO PAL: Di-\nachronic spanish sonnet corpus with psychological\nand affective labels . Language Resources and Evalu-\nation.\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\nWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\nteusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners . In Ad-\nvances in Neural Information Processing Systems ,\nvolume 33, pages 1877–1901. Curran Associates,\nInc.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022.\nPalm: Scaling language mod-\neling with pathways .\nSimon Colton, Jacob Goodwin, and Tony Veale. 2012.\nFull-face poetry generation. In International Confer-\nence on Computational Creativity 2012 , pages 95–\n102. University College Dublin.\nPablo Gervás. 2000. Wasp: Evaluation of different\nstrategies for the automatic generation of spanish\nverse. In Proceedings of the AISB-00 symposium on\ncreative & cultural aspects of AI , pages 93–100.\nMarjan Ghazvininejad, Yejin Choi, and Kevin Knight.\n2018. Neural poetry translation . In Proceedings of\nthe 2018 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 2 (Short Pa-\npers), pages 67–71, New Orleans, Louisiana. Associ-\nation for Computational Linguistics.\nMarjan Ghazvininejad, Xing Shi, Yejin Choi, and Kevin\nKnight. 2016. Generating topical poetry . In Proceed-\nings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , pages 1183–1191,\nAustin, Texas. Association for Computational Lin-\nguistics.\nHugo Gonçalo Oliveira. 2012. Poetryme: a versatile\nplatform for poetry generation. Computational Cre-\nativity, Concept Invention, and General Intelligence ,\n1:21.\nHugo Gonçalo Oliveira, Amílcar Cardoso, and Fran-\ncisco Pereira. 2007. Exploring different strategies for\nthe automatic generation of song lyrics with tra-la-\nlyrics. In Proceedings of 13th Portuguese Conference\non Artiﬁcial Intelligence, EPIA , pages 57–68.\nHugo Gonçalo Oliveira, Raquel Hervás, Alberto Díaz,\nand Pablo Gervás. 2017. Multilingual extension and\nevaluation of a poetry generator . Natural Language\nEngineering, 23(6):929–967.\nJack Hopkins and Douwe Kiela. 2017. Automatically\ngenerating rhythmic verse with neural networks . In\nProceedings of the 55th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) , pages 168–178, Vancouver, Canada.\nAssociation for Computational Linguistics.\nMans Hulden. 2009. Foma: a ﬁnite-state compiler and\nlibrary. In Proceedings of the Demonstrations Ses-\nsion at EACL 2009 , pages 29–32.\nHarsh Jhamtani, Sanket Vaibhav Mehta, Jaime Car-\nbonell, and Taylor Berg-Kirkpatrick. 2019. Learning\nrhyming constraints using structured adversaries . In\nProceedings of the 2019 Conference on Empirical\n3663\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP) , pages 6025–\n6031, Hong Kong, China. Association for Computa-\ntional Linguistics.\nNitish Shirish Keskar, Bryan McCann, Lav Varsh-\nney, Caiming Xiong, and Richard Socher. 2019.\nCTRL - A Conditional Transformer Language\nModel for Controllable Generation. arXiv preprint\narXiv:1909.05858.\nCatherine Kobus, Josep Maria Crego, and Jean Senellart.\n2016. Domain control for neural machine translation .\nCoRR, abs/1612.06140.\nTaku Kudo and John Richardson. 2018. SentencePiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing . In\nProceedings of the 2018 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 66–71, Brussels, Belgium.\nAssociation for Computational Linguistics.\nSurafel Melaku Lakew, Mattia Di Gangi, and Marcello\nFederico. 2019. Controlling the output length of neu-\nral machine translation . In Proceedings of the 16th\nInternational Conference on Spoken Language Trans-\nlation, Hong Kong. Association for Computational\nLinguistics.\nJey Han Lau, Trevor Cohn, Timothy Baldwin, Julian\nBrooke, and Adam Hammond. 2018. Deep-speare:\nA joint neural model of poetic language, meter and\nrhyme. In Proceedings of the 56th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1948–1958, Melbourne,\nAustralia. Association for Computational Linguistics.\nDayiheng Liu, Quan Guo, Wubo Li, and Jiancheng\nLv. 2018. A multi-modal chinese poetry generation\nmodel. In 2018 International Joint Conference on\nNeural Networks (IJCNN) , pages 1–8.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a uniﬁed text-to-text trans-\nformer. arXiv e-prints .\nAndrea Schioppa, David Vilar, Artem Sokolov, and\nKatja Filippova. 2021. Controlling machine transla-\ntion for multiple attributes with additive interventions .\nIn Proceedings of the 2021 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n6676–6696, Online and Punta Cana, Dominican Re-\npublic. Association for Computational Linguistics.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Controlling politeness in neural machine trans-\nlation via side constraints . In Proceedings of the 2016\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , pages 35–40, San Diego,\nCalifornia. Association for Computational Linguis-\ntics.\nTim Van de Cruys. 2020. Automatic poetry generation\nfrom prosaic text . In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 2471–2480, Online. Association for\nComputational Linguistics.\nZhe Wang, Wei He, Hua Wu, Haiyang Wu, Wei Li,\nHaifeng Wang, and Enhong Chen. 2016. Chinese\npoetry generation with planning based neural net-\nwork. In Proceedings of COLING 2016, the 26th\nInternational Conference on Computational Linguis-\ntics: Technical Papers , pages 1051–1060, Osaka,\nJapan. The COLING 2016 Organizing Committee.\nLanqing Xue, Kaitao Song, Duocai Wu, Xu Tan,\nNevin L. Zhang, Tao Qin, Wei-Qiang Zhang, and Tie-\nYan Liu. 2021. DeepRapper: Neural rap generation\nwith rhyme and rhythm modeling . In Proceedings\nof the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers) , pages 69–81, Online. As-\nsociation for Computational Linguistics.\nWen-Chao Yeh, Yung-Chun Chang, Yu-Hsuan Li, and\nWei-Chieh Chang. 2019. Rhyming knowledge-aware\ndeep neural network for chinese poetry generation . In\n2019 International Conference on Machine Learning\nand Cybernetics (ICMLC) , pages 1–6.\nXiaoyuan Yi, Maosong Sun, Ruoyu Li, and Wenhao\nLi. 2018. Automatic poetry generation with mutual\nreinforcement learning . In Proceedings of the 2018\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 3143–3153, Brussels, Bel-\ngium. Association for Computational Linguistics.\nJiyuan Zhang, Yang Feng, Dong Wang, Yang Wang,\nAndrew Abel, Shiyue Zhang, and Andi Zhang. 2017.\nFlexible and creative Chinese poetry generation using\nneural memory . In Proceedings of the 55th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers) , pages 1364–1373,\nVancouver, Canada. Association for Computational\nLinguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi-\nhaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel\nSimig, Punit Singh Koura, Anjali Sridhar, Tianlu\nWang, and Luke Zettlemoyer. 2022. OPT: Open pre-\ntrained transformer language models .\nA Structure descriptors\nThe process of extracting the meter descriptors\nfrom a regular corpus and creating the augmented\ncorpus consists of four steps:\n1. First, we split the text into phrases ac-\ncording to the following set delimiters: _-\n?\"!,:’‘()[].{}‘;»«><’. We do this so that the\nphrases, which will correspond to lines in\n3664\nour generated poems, end at natural stopping\npoints in speech. Additionally, we randomly\nmerge each phrase with the next or the next\ntwo phrases, with probabilities 0.15 and 0.05,\nrespectively, so that the model can generate\nverses that contain these special characters.\n2. Second, we syllabize each phrase and extract\nthe rhyme class of its ﬁnal word, using our\nFOMA transducers.\n3. Third, we split the text into blocks of n\nphrases, where n is sampled uniformly be-\ntween 3 and 10. For each block, we construct\na meter descriptor from the syllable count and\nrhyme class of each phrase. The descriptor\nbegins with a <PREF> token and ends with a\n</PREF> token, and a pair of tokens of the\nform <LEN_X> <CLS_Y> for each phrase,\nwhere X is the syllable count and Y is the\nrhyme class. In 15% of cases, the rhyme class\nis replaced with a special <CLS_UNK> class,\nwhich allows us to leave the rhyme of certain\nverses unspeciﬁed when generating. Addition-\nally, when there is a paragraph boundary (line\nbreak) in the text, we insert a <SEP> token in\nthe corresponding position.\n4. Fourth, we construct the corpus interleaving\nthe meter descriptors in between the corre-\nsponding blocks of text. Additionally, we in-\nsert a <BRK> token in between phrases in the\nactual text. The <BRK> token lets us clearly\nsee where the model has intended to end a\nphrase, allowing us to split the generated po-\nems into verses easily.\nB Human evaluation\nAs described in § 4.3, we extract the ﬁrst line from\nﬁfty real poems in the DISCO dataset, and compare\nthe poems obtained by completing them. Speciﬁ-\ncally, for each case, we present the four candidate\ncompletions in a randomized order, and ask a hu-\nman volunteer evaluator to rank them from best\nto worst. Additionally, the rhyme scheme that the\npoem should follow is provided, so that the evalua-\ntor can take it into account when judging a poem\n(our systems’ poems and the gold standard never\ncontain rhyme mistakes, but the poems generated\nby human annotators might). Each ranking is done\nby three different annotators.\nAll volunteers that participated in writing and\nranking poems are familiar with the fundamentals\nof formal verse poetry, but are not experts in the\nmatter. To obtain the \"Layman\" poems, volunteers\nwere asked to complete a poem within a time limit\nof 5 minutes. However, this time limit was not\nenforced, and it was slightly exceeded in some\ncases.\nC Full list of poems\nTables 8 and 9 show the full list of the six candi-\ndate poems generated by our system for each of\nthe ﬁve lines in Spanish and two lines in Basque\nchosen at random from their respective datasets.\nNo cherry-picking was done on these tables. From\nthese poems, we did select one for each line manu-\nally, as shown in Tables 7 and 6 in the main body\nof the paper (see § 6.3).\n3665\nSiento otro Yo que contra mí se empeña,\nSiento otro Yo que no quiere cambiar,\nSiento otro Yo que no sabe amar,\nSiento otro Yo que no se condena.\nSiento otro Yo que contra mí se empeña,\nsiento otro Yo que no quiero amar,\nsiento otro Yo que no puedo hablar,\nsiento otro Yo que no me enseña.\nSiento otro Yo que contra mí se empeña,\ny otro Yo que me quiere dominar,\ny otro Yo que no me quiere amar,\nque me condena y que me condena.\nSiento otro Yo que contra mí se empeña,\nun Yo para el que no debo luchar,\nun Yo al que no debo acompañar,\nun Yo que a menudo me condena.\nSiento otro Yo que contra mí se empeña,\no una voz que me hace suspirar,\no una risa que me hace llorar,\no un grito que me quita la pena.\nSiento otro Yo que contra mí se empeña,\nun Yo que no me deja amamantar,\nun Yo que me ensena a no llorar,\nun Yo que me enseña lo que pena.\nCasta su faz, bajo la blanca toca,\nvestida de dos trpitos de azahar,\nCasta su faz,bajo la blanca tocar,\nvestida de dos trpitos de su boca.\nCasta su faz, bajo la blanca toca,\ncarvaja y danseá del palomar,\nCasta su faz,bajo la blanca tocar,\ncarvaja y danseá de la roca.\nCasta su faz, bajo la blanca toca,\ncasta su faz sin tabiques que tapar,\ncasta su faz cuando quiere cabalgar,\ncasta su faz con guarnición de boca.\nCasta su faz, bajo la blanca toca,\nsu faz es dulce,es bella sin cesar,\nsu faz es hermosa como un jaguar,\nsu faz es divina como la roca.\nCasta su faz, bajo la blanca toca,\nennoblece este cantar popular,\ncasta su faz,bajo la blanca tocar,\nennoblece este cantar de boca.\nCasta su faz, bajo la blanca toca,\nno dejaba errar;casta su mirar,\nno dejaba turbar;casta su hablar,\nno dejaba hacer;casta su boca.\n3666\nNada más. De aquel sueño, que pasó como un ala,\nvoló el agua como un ave frugalmente,\nDe aquel sueño,que pasó como una bala,\nvoló el viento como un átomo ardiente.\nNada más. De aquel sueño, que pasó como un ala,\nno me devolviera la pálida piel caliente,\nDe aquel sueño,que pasó como una bala,\nno me devolviera la herida en la frente.\nNada más. De aquel sueño, que pasó como un ala,\narranco todo lo que había en mi mente,\ntodo lo que me atormentaba y no cala,\nlo que callo en el interior de mi presente.\nNada más. De aquel sueño, que pasó como un ala,\nsalió un pensamiento que viniera al frente,\nun pensamiento que pasó como una bala,\nsalió un rayo que se encendió en mi mente.\nNada más. De aquel sueño, que pasó como un ala,\ncomo un beso que se derrumbó de mi mente,\ny que se fue al pasado como una bala,\ny desapareció del mapa como un ente.\nNada más. De aquel sueño, que pasó como un ala,\nun ave se paró sola en un parapente,\nDe aquel sueño,que pasó como una bala,\nun viento se detuvo en el mar de enfrente.\nEs inútil que luche por quitarme del pecho,\nEs muy difícil que yo huya de mis traiciones,\nEs demasiado tarde para lo que he hecho,\nEs demasiado tarde para mis decisiones.\nEs inútil que luche por quitarme del pecho,\nque niegue repetidamente mis opiniones,\nque trague de nuevo mi entusiasmo deshecho,\nque rechace de nuevo todas mis negaciones.\nEs inútil que luche por quitarme del pecho,\nque no sea la tiranía de las pasiones,\nque se ría de mí de lo que yo le he hecho,\nEs inútil que se enoje por mis canciones.\nEs inútil que luche por quitarme del pecho,\nes inútil que llore por tus provocaciones,\nes inútil que te diga qué es lo más hecho,\nes inútil que aﬁrme mis acusaciones.\nEs inútil que luche por quitarme del pecho,\nque luche por alcanzarme con sus oraciones,\nque luche por bajarme del caballo derecho,\nque me meta en mi cama con sus peticiones.\nEs inútil que luche por quitarme del pecho,\nque me refugie en mi casa de ilusiones,\nque me grite a voces que quiero y no hecho,\nque me arregle los días sin palpitaciones.\n3667\nDel Monserrat en la penumbra undosa,\nDel Monserrat en la luz crepuscular,\nDel Monserrat en la vida de Aznar,\nDel Monserrat en la noche ansiosa.\nDel Monserrat en la penumbra undosa,\nDel Monserrat en la niebla uncular,\nDel Monserrat en la luna anular,\nDel Monserrat en la noche brumosa.\nDel Monserrat en la penumbra undosa,\nDel Monserrat en la noche un lugar,\nDel Monserrat en la luz un despertar,\nDel Monserrat en el sol una rosa.\nDel Monserrat en la penumbra undosa,\nDel Monserrat con los dedos sin borrar,\nDel Monserrat con las ganas de cantar,\nDel Monserrat de la roca ﬁlosa.\nDel Monserrat en la penumbra undosa,\nDel Monserrat silente en el Solar,\nDel Monserrat dolido en el remar,\nDel Monserrat cautivo en la prosa.\nDel Monserrat en la penumbra undosa,\nDel Monserrat cuando hay que claudicar,\nDel Monserrat hasta que hay que llorar,\nDel Monserrat con mantilla larosa.\nTable 8: Full list of six candidate poems for Spanish generated by our system for the ﬁve lines chosen at random in\nthe Spanish dataset. No cherry-picking was done on this table. From these poems, we did select one for each line\nmanually, as shown in Table 6 in the main body of the paper.\n3668\nGu biok lagun handiak gara,\nanaia,aita,semea,\neta bion ideologia,\ngure identitatea,\nkonpartitzen dugu.Batzuetan,\nzaila da bat esatea,\nbesteak ulertzea,benetan,\nzein ahula den bestea.\nGu biok lagun handiak gara,\nbata zinemazalea,\nbestea musikaria bera,\nbiek dugu lanbidea,\nDenok egiten dugu aurrera,\ndena da inportantea,\ndena dago egiteko era,\nizaten da idazlea.\nGu biok lagun handiak gara,\nargazkilari zalea,\neta asko gustatzen zait bera,\nnire bikotekidea,\nargazki kamera eskuetan,\nezaguna izatea,\ngogoratzen dudan argazkia,\nlagunekin ikustea.\nGu biok lagun handiak gara,\nEsne Beltzako kidea,\nanai zaharra eta arreba,\nJon eta nire semea,\neta bi panpin gaude honetan,\nOihan Vega da bestea,\nHesian taldeko kantaria,\nSorotan Bele taldea.\nGu biok lagun handiak gara,\nkatuak ardi taldea,\ntomateak eta haragia,\nsoja eta laborea,\noilaskoak fruitua lortzeko,\nlekalearen jeztea,\nbaratzea animalietan,\npinpilinpauxa zaintzea.\nGu biok lagun handiak gara,\nbaina gure bikotea,\nitxura guztien arabera,\nez da bideko jendea,\nBidaia ez da gauza berria,\nez da hala esatea,\nBaina batzuetan,batzuetan,\nizan daiteke jabea.\n3669\nNahiz kulunpio pila bat egon,\ngaltza belauna behera,\ngero eskailerak,hortz parea,\nsokak,besoak atzera,\nkautxuzko motxilak bizkotxetan,\neta astindu ederra,\nbularra,pultsuko aurpegia,\nizterra eta izterra.\nNahiz kulunpio pila bat egon,\nez da oso gauza bera,\nautoa hartu eta kotxea,\nleku batetik bestera,\nbeste leku batera sartzeko,\njendearekin batera,\negiten dugun bide horretan,\nkotxeak izorratzera.\nNahiz kulunpio pila bat egon,\naspiranteen antzera,\ngorputza sentsuala da ia,\nbetirako izaera,\neta erretzen duzu airea,\nez zara esterilera,\nkaka egiten duzu oinetan,\nlikidoa da gainera.\nNahiz kulunpio pila bat egon,\neguzkiak sikiera,\naukera du ondo goxatzeko,\neta ez beti gainera,\nbaita asteko egun denetan,\nbaita hemendik aurrera,\nilargi erdiko orduetan,\neta hori da ederra.\nNahiz kulunpio pila bat egon,\nkomunera lasaitzera,\nkomunera salto egiteko,\nirakurtzera,jotzera,\ntxorimaloetaz gozatzea,\nkonpainia egitera,\nburrunba burrunbatsuaz janztea,\nkoadrilan afaltzera.\nNahiz kulunpio pila bat egon,\nbada zerbaiten plazera,\ndena zure eskura uztea,\ndakizuna arabera,\nizan zaitez supergizakia,\nizan nahi izatera,\nhau da,zuhaur,dena emateko,\nmunduarekin batera.\nTable 9: Full list of six candidate poems for Basque generated by our system for the two lines chosen at random in\nthe Basque dataset. No cherry-picking was done on this table. From these poems, we did select one for each line\nmanually, as shown in Table 7 in the main body of the paper.\n3670",
  "topic": "Rhyme",
  "concepts": [
    {
      "name": "Rhyme",
      "score": 0.952834963798523
    },
    {
      "name": "Poetry",
      "score": 0.7942805290222168
    },
    {
      "name": "Computer science",
      "score": 0.7022453546524048
    },
    {
      "name": "Transformer",
      "score": 0.620094895362854
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5460749268531799
    },
    {
      "name": "Natural language processing",
      "score": 0.4994816780090332
    },
    {
      "name": "Phrase",
      "score": 0.4589252769947052
    },
    {
      "name": "Scheme (mathematics)",
      "score": 0.43027055263519287
    },
    {
      "name": "Metre",
      "score": 0.4267195463180542
    },
    {
      "name": "Literature",
      "score": 0.2607883810997009
    },
    {
      "name": "Art",
      "score": 0.19501331448554993
    },
    {
      "name": "Mathematics",
      "score": 0.15225479006767273
    },
    {
      "name": "Engineering",
      "score": 0.0879109799861908
    },
    {
      "name": "Electrical engineering",
      "score": 0.07870751619338989
    },
    {
      "name": "Voltage",
      "score": 0.0753265917301178
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    }
  ]
}