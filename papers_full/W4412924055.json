{
    "title": "Assessing the adherence of large language models to clinical practice guidelines in Chinese medicine: a content analysis",
    "url": "https://openalex.org/W4412924055",
    "year": 2025,
    "authors": [
        {
            "id": "https://openalex.org/A2153724856",
            "name": "Weilong Zhao",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A3027002599",
            "name": "Honghao Lai",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2154764302",
            "name": "Pan Bei",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2236919384",
            "name": "Jiajie Huang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2893407040",
            "name": "Danni Xia",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2429496208",
            "name": "Chun-Yang Bai",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2106477905",
            "name": "Jiayi Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2103633185",
            "name": "Jianing Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2111222632",
            "name": "Yinghui Jin",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2080716175",
            "name": "Hongcai Shang",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2098835858",
            "name": "Jian-ping Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2099757114",
            "name": "Nannan Shi",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2095245815",
            "name": "Jie Liu",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2318352383",
            "name": "Yaolong Chen",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2015882778",
            "name": "Janne Estill",
            "affiliations": []
        },
        {
            "id": "https://openalex.org/A2165231689",
            "name": "Long Ge",
            "affiliations": []
        }
    ],
    "references": [
        "https://openalex.org/W3092973095",
        "https://openalex.org/W4384561376",
        "https://openalex.org/W2110065044",
        "https://openalex.org/W4394694274",
        "https://openalex.org/W4410711823",
        "https://openalex.org/W4396977150",
        "https://openalex.org/W4407395599",
        "https://openalex.org/W2893214677",
        "https://openalex.org/W4391175800",
        "https://openalex.org/W4401820448",
        "https://openalex.org/W6891815172",
        "https://openalex.org/W4400359019",
        "https://openalex.org/W6891798182",
        "https://openalex.org/W1507711477",
        "https://openalex.org/W4394746513",
        "https://openalex.org/W6805258307",
        "https://openalex.org/W4398172022",
        "https://openalex.org/W4399774223",
        "https://openalex.org/W3214012004",
        "https://openalex.org/W4403177284",
        "https://openalex.org/W4383346782",
        "https://openalex.org/W2078304218",
        "https://openalex.org/W4395026179",
        "https://openalex.org/W4390921272",
        "https://openalex.org/W4402654426",
        "https://openalex.org/W2910172717",
        "https://openalex.org/W4400615258",
        "https://openalex.org/W4402751046",
        "https://openalex.org/W2997474044",
        "https://openalex.org/W4384561707",
        "https://openalex.org/W4391480546",
        "https://openalex.org/W4408613424",
        "https://openalex.org/W2599076725",
        "https://openalex.org/W4401800609",
        "https://openalex.org/W4391971084",
        "https://openalex.org/W3084221310",
        "https://openalex.org/W4385827193",
        "https://openalex.org/W4401350191",
        "https://openalex.org/W3209585908",
        "https://openalex.org/W4393529891",
        "https://openalex.org/W4411254634",
        "https://openalex.org/W4390711247",
        "https://openalex.org/W3145598376",
        "https://openalex.org/W4383483490",
        "https://openalex.org/W2615515696",
        "https://openalex.org/W2997696066",
        "https://openalex.org/W4392101515",
        "https://openalex.org/W4400068628",
        "https://openalex.org/W4200445708",
        "https://openalex.org/W4248429808"
    ],
    "abstract": "Objective Whether large language models (LLMs) can effectively facilitate CM knowledge acquisition remains uncertain. This study aims to assess the adherence of LLMs to Clinical Practice Guidelines (CPGs) in CM. Methods This cross-sectional study randomly selected ten CPGs in CM and constructed 150 questions across three categories: medication based on differential diagnosis (MDD), specific prescription consultation (SPC), and CM theory analysis (CTA). Eight LLMs (GPT-4o, Claude-3.5 Sonnet, Moonshot-v1, ChatGLM-4, DeepSeek-v3, DeepSeek-r1, Claude-4 sonnet, and Claude-4 sonnet thinking) were evaluated using both English and Chinese queries. The main evaluation metrics included accuracy, readability, and use of safety disclaimers. Results Overall, DeepSeek-v3 and DeepSeek-r1 demonstrated superior performance in both English (median 5.00, interquartile range (IQR) 4.00–5.00 vs. median 5.00, IQR 3.70–5.00) and Chinese (both median 5.00, IQR 4.30–5.00), significantly outperforming all other models. All models achieved significantly higher accuracy in Chinese versus English responses (all p &amp;lt; 0.05). Significant variations in accuracy were observed across the categories of questions, with MDD and SPC questions presenting more challenges than CTA questions. English responses had lower readability (mean flesch reading ease score 32.7) compared to Chinese responses. Moonshot-v1 provided the highest rate of safety disclaimers (98.7% English, 100% Chinese). Conclusion LLMs showed varying degrees of potential for acquiring CM knowledge. The performance of DeepSeek-v3 and DeepSeek-r1 is satisfactory. Optimizing LLMs to become effective tools for disseminating CM information is an important direction for future development.",
    "full_text": null
}