{
  "title": "MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots",
  "url": "https://openalex.org/W4391724817",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A3175524820",
      "name": "Gelei, Deng",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2024876568",
      "name": "Yi Liu",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2462021226",
      "name": "Yuekang Li",
      "affiliations": [
        "UNSW Sydney"
      ]
    },
    {
      "id": "https://openalex.org/A2120898136",
      "name": "Kailong Wang",
      "affiliations": [
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A1985094872",
      "name": "Ying Zhang",
      "affiliations": [
        "Virginia Tech"
      ]
    },
    {
      "id": "https://openalex.org/A2129452677",
      "name": "Zefeng Li",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A2117646672",
      "name": "Haoyu Wang",
      "affiliations": [
        "Huazhong University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2100180837",
      "name": "Tianwei Zhang",
      "affiliations": [
        "Nanyang Technological University"
      ]
    },
    {
      "id": "https://openalex.org/A1983143503",
      "name": "Yang Liu",
      "affiliations": [
        "Nanyang Technological University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6765556884",
    "https://openalex.org/W4225854714",
    "https://openalex.org/W2170334586",
    "https://openalex.org/W2970771982",
    "https://openalex.org/W4385848840",
    "https://openalex.org/W4381714872",
    "https://openalex.org/W4366196653",
    "https://openalex.org/W3088599783",
    "https://openalex.org/W4386081573",
    "https://openalex.org/W4318464200",
    "https://openalex.org/W6851467109",
    "https://openalex.org/W4378942304",
    "https://openalex.org/W4308643315",
    "https://openalex.org/W4380353722",
    "https://openalex.org/W4378506863",
    "https://openalex.org/W4225015015",
    "https://openalex.org/W4313563849",
    "https://openalex.org/W4327810286",
    "https://openalex.org/W4378509483",
    "https://openalex.org/W4378770719",
    "https://openalex.org/W4361019436",
    "https://openalex.org/W4309395891",
    "https://openalex.org/W4375869925",
    "https://openalex.org/W4378465191",
    "https://openalex.org/W3130319171",
    "https://openalex.org/W3213814821",
    "https://openalex.org/W6853370752",
    "https://openalex.org/W4295106014",
    "https://openalex.org/W4376632755",
    "https://openalex.org/W4312091617",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W3211484264",
    "https://openalex.org/W3047848029",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4366850566",
    "https://openalex.org/W6809908440",
    "https://openalex.org/W4211233231",
    "https://openalex.org/W6857245479",
    "https://openalex.org/W4306887348",
    "https://openalex.org/W6852874933",
    "https://openalex.org/W4308244910",
    "https://openalex.org/W4221055872",
    "https://openalex.org/W4238137008",
    "https://openalex.org/W4389520756",
    "https://openalex.org/W4205422029",
    "https://openalex.org/W4380353763",
    "https://openalex.org/W2263338482",
    "https://openalex.org/W4382202847",
    "https://openalex.org/W4389520749",
    "https://openalex.org/W3160638507",
    "https://openalex.org/W4366548330",
    "https://openalex.org/W3152879672",
    "https://openalex.org/W4388488609",
    "https://openalex.org/W4389518968",
    "https://openalex.org/W4288057743",
    "https://openalex.org/W2955835447",
    "https://openalex.org/W4385573287",
    "https://openalex.org/W4387355106",
    "https://openalex.org/W3100355250",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4388886073",
    "https://openalex.org/W4389519585"
  ],
  "abstract": "lenge in ensuring the secure and ethical usage of LLMs [31].Jailbreaking, in this context, refers to the strategic manipulation of input prompts to LLMs, devised to outsmart the chatbots' safeguards and generate content otherwise moderated or blocked.By exploiting such carefully crafted prompts, a malicious user can induce LLM chatbots to produce harmful outputs that contravene the defined policies.Past efforts have been made to investigate the jailbreak vulnerabilities of LLMs [31], [27], [62], [51].However, with the rapid evolution of LLM technology, these studies exhibit two significant limitations.First, the current focus is mainly limited on CHATGPT.We lack the understanding of potential vulnerabilities in other commercial LLM chatbots such as Bing Chat and Bard.In Section III, we will show that these services demonstrate distinct jailbreak resilience from CHATGPT.Second, in response to the jailbreak threat, service providers have deployed a variety of mitigation measures.These measures aim to monitor and regulate the input and output of LLM chatbots, effectively preventing the creation of harmful or inappropriate content.Each service provider deploys its proprietary solutions adhering to their respective usage policies.For instance, OpenAI [40] has laid out a stringent usage policy [42], designed to halt the generation of inappropriate content.This policy covers a range of topics from inciting violence to explicit content and political propaganda, serving as a fundamental guideline for their AI models.The black-box nature of these services, especially their defense mechanisms, poses a challenge to comprehending the underlying principles of both jailbreak attacks and their preventative measures.As of now, there is a noticeable lack of public disclosures or reports on jailbreak prevention techniques used in commercially available LLM-based chatbot solutions.To close these gaps and further obtain an in-depth and generalized understanding of the jailbreak mechanisms among various LLM chatbots, we first undertake an empirical study to examine the effectiveness of existing jailbreak attacks.We evaluate four mainstream LLM chatbots: CHATGPT powered",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7000107765197754
    },
    {
      "name": "Natural language processing",
      "score": 0.4676969051361084
    },
    {
      "name": "Language model",
      "score": 0.4301905930042267
    },
    {
      "name": "Programming language",
      "score": 0.37670308351516724
    },
    {
      "name": "Artificial intelligence",
      "score": 0.339910626411438
    }
  ]
}