{
  "title": "A Bidirectional Long Short-Term Memory Autoencoder Transformer for Remaining Useful Life Estimation",
  "url": "https://openalex.org/W4389913150",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5083056696",
      "name": "Zhengyang Fan",
      "affiliations": [
        "George Mason University"
      ]
    },
    {
      "id": "https://openalex.org/A5036747126",
      "name": "Wanru Li",
      "affiliations": [
        "George Mason University"
      ]
    },
    {
      "id": "https://openalex.org/A5019345566",
      "name": "Kuo‐Chu Chang",
      "affiliations": [
        "George Mason University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2325344880",
    "https://openalex.org/W3181794117",
    "https://openalex.org/W3136300763",
    "https://openalex.org/W2406882687",
    "https://openalex.org/W4386715033",
    "https://openalex.org/W4365453645",
    "https://openalex.org/W2055873761",
    "https://openalex.org/W3005147174",
    "https://openalex.org/W3175127519",
    "https://openalex.org/W4386820292",
    "https://openalex.org/W4381243769",
    "https://openalex.org/W4376606405",
    "https://openalex.org/W4327739961",
    "https://openalex.org/W6960050629",
    "https://openalex.org/W4211040998",
    "https://openalex.org/W2885732902",
    "https://openalex.org/W2022621390",
    "https://openalex.org/W2069262928",
    "https://openalex.org/W4380989392",
    "https://openalex.org/W2971077678",
    "https://openalex.org/W4320024113",
    "https://openalex.org/W4283014531",
    "https://openalex.org/W4388096928",
    "https://openalex.org/W2558869916",
    "https://openalex.org/W2617137613",
    "https://openalex.org/W2744067593",
    "https://openalex.org/W2772084711",
    "https://openalex.org/W2944676531",
    "https://openalex.org/W3112478554",
    "https://openalex.org/W4311358050",
    "https://openalex.org/W4310024794",
    "https://openalex.org/W4311970724",
    "https://openalex.org/W3216133543",
    "https://openalex.org/W4312761066",
    "https://openalex.org/W4321486786",
    "https://openalex.org/W4385834060",
    "https://openalex.org/W3137613462",
    "https://openalex.org/W4280510849",
    "https://openalex.org/W6797282723",
    "https://openalex.org/W6854472151",
    "https://openalex.org/W6842526476",
    "https://openalex.org/W4285186957",
    "https://openalex.org/W4285266752",
    "https://openalex.org/W4386760021",
    "https://openalex.org/W4213025374",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2136848157",
    "https://openalex.org/W2025768430",
    "https://openalex.org/W2120841219",
    "https://openalex.org/W2811131765",
    "https://openalex.org/W3150748923",
    "https://openalex.org/W2910660149",
    "https://openalex.org/W2471161958",
    "https://openalex.org/W2978540646",
    "https://openalex.org/W3093330784",
    "https://openalex.org/W4292976134",
    "https://openalex.org/W4382645144",
    "https://openalex.org/W3173407600"
  ],
  "abstract": "Estimating the remaining useful life (RUL) of aircraft engines holds a pivotal role in enhancing safety, optimizing operations, and promoting sustainability, thus being a crucial component of modern aviation management. Precise RUL predictions offer valuable insights into an engine’s condition, enabling informed decisions regarding maintenance and crew scheduling. In this context, we propose a novel RUL prediction approach in this paper, harnessing the power of bi-directional LSTM and Transformer architectures, known for their success in sequence modeling, such as natural languages. We adopt the encoder part of the full Transformer as the backbone of our framework, integrating it with a self-supervised denoising autoencoder that utilizes bidirectional LSTM for improved feature extraction. Within our framework, a sequence of multivariate time-series sensor measurements serves as the input, initially processed by the bidirectional LSTM autoencoder to extract essential features. Subsequently, these feature values are fed into our Transformer encoder backbone for RUL prediction. Notably, our approach simultaneously trains the autoencoder and Transformer encoder, different from the naive sequential training method. Through a series of numerical experiments carried out on the C-MAPSS datasets, we demonstrate that the efficacy of our proposed models either surpasses or stands on par with that of other existing methods.",
  "full_text": null,
  "topic": "Autoencoder",
  "concepts": [
    {
      "name": "Autoencoder",
      "score": 0.8368119597434998
    },
    {
      "name": "Computer science",
      "score": 0.6374130845069885
    },
    {
      "name": "Encoder",
      "score": 0.6134118437767029
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5580489635467529
    },
    {
      "name": "Transformer",
      "score": 0.555055558681488
    },
    {
      "name": "Feature extraction",
      "score": 0.46604931354522705
    },
    {
      "name": "Deep learning",
      "score": 0.4193216562271118
    },
    {
      "name": "Machine learning",
      "score": 0.4120349586009979
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.3436875641345978
    },
    {
      "name": "Engineering",
      "score": 0.2588040828704834
    },
    {
      "name": "Voltage",
      "score": 0.10817527770996094
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    },
    {
      "name": "Operating system",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I162714631",
      "name": "George Mason University",
      "country": "US"
    }
  ],
  "cited_by": 11
}