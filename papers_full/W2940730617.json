{
    "title": "Adapting State-of-the-Art Deep Language Models to Clinical Information Extraction Systems: Potentials, Challenges, and Solutions",
    "url": "https://openalex.org/W2940730617",
    "year": 2019,
    "authors": [
        {
            "id": "https://openalex.org/A2113494688",
            "name": "Liyuan Zhou",
            "affiliations": [
                "Australian National University",
                "Commonwealth Scientific and Industrial Research Organisation",
                "Health Sciences and Nutrition",
                "Data61"
            ]
        },
        {
            "id": "https://openalex.org/A2109909357",
            "name": "Hanna Suominen",
            "affiliations": [
                "University of Canberra",
                "University of Turku",
                "Health Sciences and Nutrition",
                "Australian National University",
                "Data61",
                "Commonwealth Scientific and Industrial Research Organisation"
            ]
        },
        {
            "id": "https://openalex.org/A2052936527",
            "name": "Tom Gedeon",
            "affiliations": [
                "Australian National University"
            ]
        },
        {
            "id": "https://openalex.org/A2113494688",
            "name": "Liyuan Zhou",
            "affiliations": [
                "Commonwealth Scientific and Industrial Research Organisation",
                "Australian National University",
                "Health Sciences and Nutrition",
                "Data61"
            ]
        },
        {
            "id": "https://openalex.org/A2109909357",
            "name": "Hanna Suominen",
            "affiliations": [
                "Australian National University",
                "Commonwealth Scientific and Industrial Research Organisation",
                "University of Turku",
                "Health Sciences and Nutrition",
                "Data61",
                "University of Canberra"
            ]
        },
        {
            "id": "https://openalex.org/A2052936527",
            "name": "Tom Gedeon",
            "affiliations": [
                "Australian National University"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W1901616594",
        "https://openalex.org/W2767381938",
        "https://openalex.org/W1530734550",
        "https://openalex.org/W2109651326",
        "https://openalex.org/W2400137014",
        "https://openalex.org/W4407816707",
        "https://openalex.org/W2612992329",
        "https://openalex.org/W2829251220",
        "https://openalex.org/W2117130368",
        "https://openalex.org/W2251803266",
        "https://openalex.org/W2963033440",
        "https://openalex.org/W2125883684",
        "https://openalex.org/W2076063813",
        "https://openalex.org/W2805057102",
        "https://openalex.org/W2806198715",
        "https://openalex.org/W2611669587",
        "https://openalex.org/W2156061936",
        "https://openalex.org/W2160987310",
        "https://openalex.org/W2145270227",
        "https://openalex.org/W2114039834",
        "https://openalex.org/W2027125310",
        "https://openalex.org/W1857789879",
        "https://openalex.org/W2919115771",
        "https://openalex.org/W2005730928",
        "https://openalex.org/W2158899491",
        "https://openalex.org/W2330406605",
        "https://openalex.org/W1889584887",
        "https://openalex.org/W1539309091",
        "https://openalex.org/W4252684946"
    ],
    "abstract": "To our knowledge, our study is the first attempt to transfer models from general deep models to specific tasks in health care and gain a significant improvement. As transfer learning shows its advantage over other methods, especially on classes with a limited amount of training data, less experts' time is needed to annotate data for ML, which may enable good results even in resource-poor domains.",
    "full_text": "Original Paper\nAdapting State-of-the-Art Deep Language Models to Clinical\nInformation Extraction Systems: Potentials, Challenges, and\nSolutions\nLiyuan Zhou1,2, BSc, MSc; Hanna Suominen1,2,3,4, MSc, PhD; Tom Gedeon1, BSc (Hons), PhD\n1Research School of Computer Science, College of Engineering and Computer Science, The Australian National University, Canberra, Australia\n2Machine Learning Group, Data61, Commonwealth Scientific and Industrial Research Organisation, Canberra, Australia\n3Faculty of Science and Technology, University of Canberra, Canberra, Australia\n4Department of Future Technologies, Faculty of Science and Engineering, University of Turku, Turku, Finland\nCorresponding Author:\nLiyuan Zhou, BSc, MSc\nResearch School of Computer Science\nCollege of Engineering and Computer Science\nThe Australian National University\n108 North Road\nCanberra, 2600\nAustralia\nPhone: 61 (02) 6125 5111\nEmail: annjouno@gmail.com\nAbstract\nBackground: Deep learning (DL) has been widely used to solve problems with success in speech recognition, visual object\nrecognition, and object detection for drug discovery and genomics. Natural language processing has achieved noticeable progress\nin artificial intelligence. This gives an opportunity to improve on the accuracy and human-computer interaction of clinical\ninformatics. However, due to difference of vocabularies and context between a clinical environment and generic English,\ntransplanting language models directly from up-to-date methods to real-world health care settings is not always satisfactory.\nMoreover, the legal restriction on using privacy-sensitive patient records hinders the progress in applying machine learning (ML)\nto clinical language processing.\nObjective: The aim of this study was to investigate 2 ways to adapt state-of-the-art language models to extracting patient\ninformation from free-form clinical narratives to populate a handover form at a nursing shift change automatically for proofing\nand revising by hand: first, by using domain-specific word representations and second, by using transfer learning models to adapt\nknowledge from general to clinical English. We have described the practical problem, composed it as an ML task known as\ninformation extraction, proposed methods for solving the task, and evaluated their performance.\nMethods: First, word representations trained from different domains served as the input of a DL system for information extraction.\nSecond, the transfer learning model was applied as a way to adapt the knowledge learned from general text sources to the task\ndomain. The goal was to gain improvements in the extraction performance, especially for the classes that were topically related\nbut did not have a sufficient amount of model solutions available for ML directly from the target domain. A total of 3 independent\ndatasets were generated for this task, and they were used as the training (101 patient reports), validation (100 patient reports),\nand test (100 patient reports) sets in our experiments.\nResults: Our system is now the state-of-the-art in this task. Domain-specific word representations improved the macroaveraged\nF1 by 3.4%. Transferring the knowledge from general English corpora to the task-specific domain contributed a further 7.1%\nimprovement. The best performance in populating the handover form with 37 headings was the macroaveraged F1 of 41.6% and\nF1 of 81.1% for filtering out irrelevant information. Performance differences between this system and its baseline were statistically\nsignificant (P<.001; Wilcoxon test).\nConclusions: To our knowledge, our study is the first attempt to transfer models from general deep models to specific tasks in\nhealth care and gain a significant improvement. As transfer learning shows its advantage over other methods, especially on classes\nwith a limited amount of training data, less experts’ time is needed to annotate data for ML, which may enable good results even\nin resource-poor domains.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 1http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n(JMIR Med Inform 2019;7(2):e11499) doi: 10.2196/11499\nKEYWORDS\ncomputer systems; artificial intelligence; deep learning; information storage and retrieval; medical informatics; nursing records;\npatient handoff\nIntroduction\nBackground\nMachine learning (ML) is being studied and used in a variety\nof health informatics applications (eg, disease progression\nprediction, therapy planning, medical diagnostic reasoning, and\nautomatic patient management) as a way to help clinical experts\nto improve the efficiency and quality of medical care [1,2].\nA clear majority of these applications use supervised learning,\nwhich infers knowledge from labeled training data. However,\nbecause of stringent restrictions on the use of clinical data [3],\ndata collections on real health care scenarios that are open for\nresearch and development are very limited [4]. Moreover, the\nfew available sources have limitations such as research-only\nuse [5], nondisclosure of data [6], or limited commercial licenses\n[7].\nZheng et al [8] proposed an information extraction (IE)\nframework called IDEAL-X, which uses online learning\ntechniques to update the learning model based on user feedback.\nAlthough the performance of their system looks very impressive,\nthe types of text this system is able to extract are limited to 5,\nand these types such as age, gender, and medicine can be easily\nretrieved with rule-based systems rather than ML systems. Leroy\nintroduced a rule-based automated IE system that extracts\ndiagnostic criteria from electronic health records for autism\nspectrum disorders [9]. As the rules are manually generated\nbased on human observations of 1 specific data set, their system\ncannot be generalized to other tasks.\nIn our previous study [4], we have already (1) discussed the\nimportance of comprehensive record keeping along with\ninformation flow in health care in general and clinical handover\nin particular, (2) developed and freely released a set of 101\nsynthetic clinical handover cases with verbatim conversations\nand associated audio recordings constructed by a nurse with\nover 12 years of experience in clinical practice to make sure the\ncases are closely matched with the typical data found in a\nnursing shift change, and (3) introduced and evaluated a\ncascaded system that uses speech recognition (SR) to recognize\nverbal clinical handover information and IE to fill in a handover\nform for clinical proofing and sign-off (Figure 1).\nObjectives\nIn this study, we have released another 2 datasets that follow\nexactly the same format as our first release to supplement the\noriginal dataset called the National Information and\nCommunications Technology Australia (NICTA) Synthetic\nNursing Handover Data. These 3 independent datasets target\nresearchers who are training, validating, and testing ML-based\nSR and IE methods for the handover record-keeping task. A\ndescription of our dataset is available in Multimedia Appendix\n1.\nMore importantly, in this study, we have improved our IE\nperformance by using an ML method, which learns from other\ndata collections and transfers this knowledge to the handover\ntask. Processing correctness is crucial in medical informatics\napplications; our benchmark results show that this task is very\nchallenging [4], and the previous state-of-the-art result on this\ntask was only 38.2% on macro F1 [10]. Even with our\nsupplementary data, the size of the in-domain training set is still\nnot adequate to train a traditional multilayer neural network\n(NN) model for our IE task composed as a 50-class\nclassification.\nFigure 1. A processing pipeline that transforms verbal clinical handover information into electronic structured records automatically.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 2http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nGenerating or getting access to a large manually labeled training\ncorpus for this task is not easy. Fortunately, distributed word\nrepresentations, which can be learned from unlabeled data, have\nrecently been shown to have high utility in many natural\nlanguage processing (NLP) applications [11-14]. In this study,\nwe have investigated whether pretrained word embeddings\ngenerated from general Web text could improve our system\nperformance in the IE task, even though it is relatively\ndomain-specific. Furthermore, we are also interested to discover\nif training supplementary word embeddings based on a\ndomain-related corpus is more helpful than from a general\nEnglish corpus.\nTransferring the knowledge learned from another domain to\nour task is another way to cope with the problem of lack of\ntraining instances. This method has shown its effectiveness in\nprevious studies [15,16]. In this study, we have implemented a\ntransfer learning–based approach to adapt weights of features\nand labels from different source data corpora to gain an\nimprovement in the clinical handover IE task. More specifically,\nif we define our current task as the target domain, then the\ndataset that we want to adapt weights from is the source domain,\nso we first train sequence labeling models on a source domain\ntraining corpus and then learn the correlations between source\nlabels and the labels in our task. After this, we use the model\nparameters of each related class in the source model to initialize\nour conditional random field (CRF) model in our clinical\nhandover IE task. To extend the study, we have also explored\nwhether models learned from a source corpus, which is close\nto a clinical domain, are more helpful than models trained on a\ngeneric, large labeled corpus.\nTo summarize the contributions of this study, we have released\nthe data to study SR and IE and introduced a state-of-the-art IE\nmethod for the handover task. The method is based on transfer\nlearning and compares with both the most recent deep learning\n(DL) approaches and more traditional CRFs for sequence\nlabeling.\nMethods\nNICTA Synthetic Nursing Handover Data\nTo fulfil the purpose of constructing systems to automatically\ngenerate structuring of the narrative documents from nursing\nshift change speech and handover, NICTA Synthetic Nursing\nHandover Data [17-19] was created at NICTA/Data61 from\n2012 to 2016. Their main author was a professional Registered\nNurse (RN), Maricel Angel, who has over 12 years of experience\nin clinical nursing, based on general practice in medical wards.\nTherefore, the text is very similar to real documents in typical\nclinical scenarios.\nThis data collection of 301 records in total contained 3 disjoint\nsubsets for training (101 records), validation (100 records), and\ntesting (100 records; Figure 2). All 3 subsets were created under\na consistent practice with the same standards as used by\nSuominen et al [4]. Each record contains a patient profile; a\nwritten, free-form clinical handover for this profile; a voice\nspeech record of the handover; and, finally, a written, structured\ndocument. To represent the most common chronic diseases and\nnational health priority areas in Australia [20], 4 kinds of\npatients (ie, cardiovascular, neurological, renal, and respiratory\npatients) were introduced into each subset and independently\nfollowed a uniform distribution to provide a balanced\ndemographic sample. The structured document includes\nannotation of 5 classes (PATIENT INTRODUCTION, MY\nSHIFT, APPOINTMENTS, MEDICATION, and FUTURE\nCARE), which were further divided into 37 subclasses,\nsupplemented by the category of not applicable (NA) for\nirrelevant information.\nFigure 2. Descriptive statistics of text snippets highlighted in the training, validation, and test set.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 3http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nWord Representation\nWord embedding is a vector matrix learned from an unlabeled\ntext corpus that maps vocabulary to a dense vector space. It\nattempts to model the distributional hypothesis that words that\noccur in similar contexts tend to be semantically similar. It has\nbeen shown to contribute to a variety of NLP tasks even without\nusing any other features [21].\nTo capture word vector representations from large amounts of\nunlabeled text, we adapted a skip-gram model [22] that uses\neach current word to predict words in the neighboring context.\nThe training objective of the skip-gram model is to maximize\nthe averaged log probability over all training cases (T) of\nappearance of the context word w_{t+j} given the current word\nw_t, where j is the offset of the context word from the current\nword in a context window size of c:\n1/T ∑ _{T}^{t=1}( ∑ _{-c ≤ j ≤ c,j ≠ 0}(log\np(w_{t+j}|w_t)))\nThen, applies softmax to each context word w_O of a given\noccurrence of word w_I:\nP(w_O|w_I)=exp(v’^{T}_{w_O}v_{w_I})/∑^W_{w=1}\nexp(v’^T_w v_{w_I})\n...where v_w is the input and v’_w is the output word embedding\nof a word w, and W is the size of the training vocabulary.\nOut of the 2 variations to optimize computational efficiency of\nthe skip-gram model, we have used negative sampling rather\nthan hierarchical softmax because, for sequence tagging tasks\nin NLP, it can maintain more semantic information during the\ntraining process [23] and obtain better results [24]. Rather than\ncalculating exp(v’^T_w v_{w_I}) for all w in the vocabulary\nwhen calculating log p(w_{t+j}|w_t), negative sampling replaces\nit with a logistic regression and distinguishes a context word\nw_O from noise (negative samples):\nlog σ(v’^T_{w_O} v_{w_I}) + ∑^k_{i=1}\nE_{w_i~U(w)} [log σ(-v’^T_{w_i} v_{w_I})],\n...where k is the amount of negative samples for each data\nsample, and U(w) is a unigram distribution of words.\nTo integrate context information from a new domain-specific\ncorpus D_1 (eg, our clinical handover dataset), we need to\nupdate our existing word embeddings that were learned from a\ngeneral large text collection D_0. However, this comes with a\nsignificant challenge in that the original word embeddings were\ntrained on a very large corpus whereas our target domain\ntraining data are normally much smaller in size. More\nspecifically, if we compare the vocabulary between D_0 and\nD_1, V_0 ∩ V_1 is the intersection between 2 vocabularies,\nwhich is mainly composed of more general terms compared\nwith V_1/V_0: the relative complement of V_0 with regard to\nV_1. As word vectors in V_0 have already been trained for\nseveral epochs and converged to our desired values, we do not\nwant to change them significantly. However, new words that\nwere just introduced to the vocabulary from V_1/V_0 contain\ndomain-specific, related terms about which we care the most.\nOwing to the limitations in the available amount of training\nsamples, a large learning rate at the beginning is useful to adjust\nthese vectors to the regions they belong. Using the original\nskip-gram algorithm will potentially either adjust the already\nconverged vectors from V_0 away from their optimized values\nor the new word vectors will not get close to words that are\nsimilar to them in the vector space. To cope with this problem,\nwe used 2 strategies in our experiments: averaged initialization\nas well as different learning rates.\nIn averaged initialization, our assumption was that words in\nsimilar contexts would have similar meanings or have\ngrammatical similarities. Although this is not always true, this\nstrategy helps in learning the new words, as they start from an\n(averaged) optimized point rather than from scratch. To model\nthis, whenever a new word appears, the initial value of the vector\nis set to be the averaged value in each dimension of words in\nthe same sentence:\n1/S∑^{S}_{i=1} v_i, where v_i= v, if v  V_0,\n= v_0, otherwise\n...where S is the sentence length and v_0 denotes the vector in\nV_0, which represents the vector of unknown words.\nDuring the training procedure, we have also used different\nlearning rates for words in V_1/V_0 in contrast with V_0∩V_1:\nα_t=α_{0_new}(1–t/n), t≠0, and v V_1/V_0\nα_t=0.2, t=0, and v V_1/V_0\nα_t=α_{0_old}(1–t/n), t≠0, and v V_1∩V_0\nα_t=α_{0_new}(|V_1/V_0|/|V_0∪V_1|), t≠0, and\nv V_1/V_0\n...where n is the amount of samples input to the network. For\nnew words, the initial learning rate α_{0_new} is set to 0.2 and\ndecreases over time. For words that are already in V_0, the initial\nlearning rate is set to the portion of new words in the entire\nvocabulary: the more learning samples we have for new words,\nthe larger the initial learning rate for old words.\nTransfer Learning for Sequence Labeling\nFor sequence tagging tasks that use supervised ML, the amount\nand purity of training data is crucial to the performance of our\nsystem. As the complexity of learning a 40-class classifier is\nhigh, for some labels, there is only 1 case in the training set,\nwhich could not be generalized to infer good functions [25].\nTherefore, introducing more training data could improve the\nfinal results. However, when more training instances are not\navailable, or are extremely costly in human labor, transfer\nlearning, which adapts weight matrixes from functions trained\nwith another dataset and applied to the current task, is another\nway to gain knowledge of labels with limited training instances.\nThe underlying idea of transfer learning is simple: in deep NNs,\nthere are several hidden layers between the input and output\nlayers; as data feed forward from the input layer to the output\nlayer, the composition of features is learned from earlier layers\n[26]. A typical sequence tagging structure can be demonstrated\nas the left block in Figure 3: neurons in lower layers tend to\ncapture some common, nondomain, or task-specific concepts,\nand later layers would concatenate these features and generate\nhigher-level concepts. Therefore, weights learned from other\ndatasets or even other tasks can be potentially reused as long\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 4http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nas the structure of the later layers are consistent between the\nsource model and target model.\nSeveral strategies of transfer learning on different NLP tasks\nand domains have been explored. A simple strategy is to copy\nall weight matrixes in the source model to the target model and\nfine-tune the target model with new data [27], which\nsuccessfully outperformed the leading team in the Multilingual\nEmoji Prediction task [28] by 1.55% without any feature\nengineering procedure. However, this method requires the source\nand target model to have the exact same structure. An alternative\nstrategy is to map annotations from different datasets into 3\nconsistent labels and use source domain model parameters\ndirectly as initializations for a target domain model in named\nentity recognition [16]. Finally, human adjustment of rules and\nfeatures [29,30] or clustering labels from source domain and\ntarget domains to automatically generate label mappings from\none dataset to the other [31] can be applied as transfer learning\nstrategies. However, their productivity may be limited when\nadapting a general source model to multiple tasks and also the\ngenerated mappings might not be satisfactory, especially when\n2 datasets have dramatic differences in terms of phraseology\nand grammar.\nThe method we have introduced in our study was able to transfer\nknowledge to a target domain that does not match labels in the\nsource domain, does not depend on human integration during\nthe label mapping process, and is able to map labels from very\ndifferent datasets. This method follows 3 steps (Figure 3): the\nfirst step trains a CRF model on the source domain, the second\nstep uses the weight matrix of the source model W^s to train a\n2-layer CRF that predicts a target domain label given a source\ndomain label, and, finally, the third step is to initialize the\nparameters of the target domain model using the product of W_s\nand the second layer weight matrix W^t obtained in step 2.\nFirst, in the source model training step, a linear-chain CRF\nmodel is trained on a large labeled source dataset. For each word\nx_i in a sequence x, y_i   Y is the label of x_i, where Y is the\nlabel set. Then (x; y) is a sequence of word label pairs; a linear\nchain CRF is a distribution p (y| x) that takes the form:\np( y| x) = 1/Z ∏^{L}_{l=1} ( W^f f(y_l, x) + W^g\ng(y_{l-1}, y_l))\n...where Z is a normalization constant, L is the length of x, f(y_l,\nx) is a real value feature function of x, g(y_{l-1}, y_l) is a feature\nfunction of current label y_l and previous label y_{l-1} in the\nsequence to capture the cooccurrence between adjunct labels,\nand contains the parameters of the feature functions.\nFor now, the source CRF model can be seen as an NN with 2\nhidden layers: the lower layer, which is connected by W^f, and\nthe upper layer connected by W^g (Figure 3). However, because\nthe information that is captured by W^g is normally domain-\nand task-specific, label correlations do not always have\nsimilarities between different domains, which would thus not\nbe suitable to be transferred to the other task. In contrast, the\nlower layer learned correlations between words and source\nlabels, which is what we are interested in, are actually a logistic\nregression model:\nσ(y*, x_i, W^f) = exp( W^f_{.y*}f(y*_i, x_i)) /\n∑_{y Y}exp( W^f_{.y}f(y, x_i))\nSecond, in the source label and target label correlations step,\nwe have propagated the label probabilities from the later layer\nof the source domain model to another logistic regression\nclassifier to form a 2-layer linear-chain CRF model that predicts\ntarget domain labels and uses source domain labels to learn\ncorrelations between the source and target labels. More\nspecifically, the linear layer from the source model can be\ndefined as:\na_i= W^s f(y, x_i)\n...where each a_i is the probability for each source label and\nW^s denotes the weight matrix from source domain. After this\nlayer, a linear regression classifier takes the output from a_i to\npredict target labels:\np(y’| a)=σ(y’, a_i; W^t),\n...where y’ is the target type. This is equal to:\np(y’| x)=σ(y’, x_i; W^t W^s)\nFigure 3. Transfer learning model structure.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 5http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nAfter W^s and W^t are trained, we were able to initialize a CRF\nmodel to predict target labels with W^f = W^tW^s as the third\nstep:\np( y| x)=1/Z ∏^{L}_{l=1} ( W^t W^s f(y_l, x))\nDuring this procedure, the parameters of label NA, W^t_{NA}\nare reset to be zeros because the amount of instances of NA in\nthe text corpus is much larger than that of other labels, which\nwould cause the model to be biased to the dominant class.\nTheoretically, the parameters of feature functions will converge\nto the same weights with a random initialization model when\nthe number of iterations is large enough because the loss\nfunction is convex. However, our aim was to inherit knowledge\nfrom the source domain, updating W^tW^s too often would\ncause the model to forget what it has learned so far. Therefore,\nearly stopping and adaptive gradient algorithm (AdaGrad) [32]\nare applied to preserve the learned source domain knowledge.\nPerformance Evaluation and Experimental Design\nTo compare the performance of systems, we have measured the\nprecision, recall, and F1 (harmonic mean of precision and recall)\nover all categories [33]. More specifically, microaveraged F1\nand macroaveraged F1 are calculated. As our purpose was to\nemphasize on systems that perform well in all classes rather\nthan only in the classes that have majority instances,\nmacroaveraged F1 was selected as the main evaluation\nmeasurement.\nThe resources used in our experiments were derived from 7\ndifferent corpora (Table 1). Among them, 3 were general English\ntext based, 3 were specific to the English health care domain,\nand 1 was the test set. Details of the test set are available in\nMultimedia Appendix 2.\n1. General English Corpora:\n• English Wikipedia is a freely available corpus from the\nSeptember 2014 version of all pages from all Wikipedia\nwikis. It contains more than 3 million English pages,\n100 million sentences, and 3.4 billion words in total\nafter cleaning.\n• University of Maryland, Baltimore County (UMBC)\nWebBase corpus is a dataset containing a collection of\n100 million English Web pages from more than 50,000\nwebsites with over 3 billion words processed from the\nFebruary 2007 crawl by the Stanford WebBase project\n[34].\n• One Billion Words Benchmark for Language Modeling\nis a freely available standard corpus of 4.2 GB (0.8\nbillion words) for building and testing language models\n[35].\n2. Medical Domain–specific English Corpora:\n• I2B2 is a collection of fully deidentified clinical records\nprovided by the I2B2 National Centre for Biomedical\nComputing funded by U54LM008748 and was\noriginally prepared for Shared Tasks for Challenges in\nNLP for Clinical Data organized by Uzuner, I2B2, and\nSUNY [36-39].\n• PubMed is a free resource containing over 27 million\ncitations to the biomedical literature and publication\nabstracts derived from MEDLINE, life science journals,\nand Web books. It was developed and is maintained\nby the National Centre for Biotechnology Information\nat the US National Library of Medicine (NLM).\n• PubMed Central (PMC) Open Access Subset contains\nover 1 million biomedical articles from PMC, which\nis a free archive of biomedical and life sciences journal\npublications at the US National Institutes of Health's\nNLM.\n• NICTA TRAIN is the NICTA Synthetic nursing\nhandover dataset, an open clinical dataset of 3 sets of\nnursing handover records, very similar to real\ndocuments in Australian English. Each record consists\nof a patient profile, spoken free-form text document,\nwritten free-form text document, and written structured\ndocument [40].\nTable 1. Word embeddings training corpora.\nSourceSizeCorpus\nWikimedia downloads [41]3.4 billion wordsEnglish Wikipedia\nUMBC WebBase corpus [42]>3 billion wordsUMBCa\nOne Billion Word Benchmark for Measuring Progress in\nStatistical Language Modeling [43]\n0.8 billion wordsOne Billion\nI2B2 NLPb research data sets [6]18,082 unique wordsI2B2\nPubMed resources [44]27 million recordsPubMed\nPubMed resources [45]1 million articlesPubMed Central\nHospital handover forms [17]101 recordsNational Information and Communications Technology\nAustralia Train\naUMBC: University of Maryland, Baltimore County.\nbNLP: natural language processing.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 6http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 2. Mapping of entity types between the source and target corpora.\nTarget: NICTAa Clinical HandoverOut-domain source: I2B2In-domain source: Bolt, Beranek and Newman\nPATIENT_INTRODUCTION/Given_namesPATIENTPERSON\nPATIENT_INTRODUCTION/Last_namePATIENTPERSON\nPATIENT_INTRODUCTION/Under_Dr:Given_namesDOCTORPERSON\nPATIENT_INTRODUCTION/Under_Dr:Last_nameDOCTORPERSON\nAPPOINTMENTS/Clinician:Last_nameDOCTORPERSON\nAPPOINTMENTS/Clinician: Given_namesDOCTORPERSON\nAPPOINTMENTS/HospitalHOSPITALORGANIZATION:HOSPITAL\nPATIENT_INTRODUCTION/Age_in_years—bDATE:AGE\nPATIENT_INTRODUCTION/Gender—PER_DESC\nAPPOINTMENTS/Clinician Title—PER_DESC\nAPPOINTMENTS/CityLOCATIONGPE:CITY\nAPPOINTMENTS/DayDATEDATE:DATE\nAPPOINTMENTS/Time—TIME\nPATIENT_INTRODUCTION/Current_roomIDCARDINAL\nPATIENT_INTRODUCTION/Current_bedIDCARDINAL\nMedication/Medicine—PRODUCT:OTHER\nMedication/Medicine—SUBSTANCE:DRUG\nMedication/Dosage—QUANTITY:3D (volume)\nMedication/Dosage—QUANTITY:OTHER\nMy_shift/Status—QUANTITY:TEMPERATURE\nMy_shift/Status—QUANTITY:WEIGHT\nMy_shift/Input_diet—SUBSTANCE:FOOD\nAPPOINTMENTS/Ward—FACILITY\nPATIENT_INTRODUCTION/Admission_reason/diagnosis—DISEASE\nPATIENT_INTRODUCTION/Chronic_condition—DISEASE\nPATIENT_INTRODUCTION/Disease/problem_history—DISEASE\naNICTA: National Information and Communications Technology Australia.\nbDoes not contain any matching label from the source domain.\nFor the source domain corpus, we used 1 domain-related dataset,\nwhich contained labels that were relevant but not exactly the\nsame as in our target domain data, and 1 of the domain corpora,\nwhich contained many of the general labels, including some\nlabels that were relevant to biometrics. With this setup, we were\nkeen to find out whether the parameters learned from the same\ndomain were more valuable than those from general English.\nThe related domain source corpus was the aforementioned I2B2.\nIt included fully deidentified discharge summaries and progress\nnotes from real hospital scenarios. All records had been\nmanually annotated for concept, assertion, and relation\ninformation. The corpus contained entities of 7 different labels:\nPATIENT, DOCTOR, HOSPITAL, DATE, PHONE,\nLOCATION, and ID. They were potentially relevant to labels\nin our NICTA dataset.\nThe general domain source corpus was Bolt, Beranek and\nNewman (BBN), which has a 1 million-word Penn Treebank\ncorpus of Wall Street Journal texts annotated by BBN with 28\nmain types of entities: 12 named entity types (Person, Facility,\nOrganization, geographical entities (GPE), Location, Nationality,\nProduct, Event, Work of Art, Law, Language, and Contact-Info),\n9 nominal entity types (Person, Facility, Organization, GPE,\nProduct, Plant, Animal, Substance, and Disease and Game),\nand 7 numeric types (Date, Time, Percent, Money, Quantity,\nOrdinal, and Cardinal). These types were further divided into\n64 subtypes [46] (see Table 2 for the types related to labels in\nthe target domain).\nTo examine what kind of word embeddings were most valuable\nto our task, we classified all the available datasets into 3\ndifferent groups: Group 1 General (English\nWikipedia+UMBC+One Billion) was composed of general\nEnglish materials, which do not contain many domain-specific\nwords or sentences. Group 2 Biomedical literature\n(PubMed+PMC) was composed of biomedical literature and\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 7http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nabstracts. Words in this group could be similar to clinical words\nbut would be used in different ways, considering that publication\nwriting is different from authoring clinical documents. Group\n3 Clinical documents (I2B2+NICTA Train) was composed of\nclinical handovers, discharge summaries, and progress notes\nthat closely resemble our task data. All corpora were\npreprocessed with the Stanford CoreNLP sentence splitter and\ntokenizer [47]. Digits were replaced with NUM[Length] (eg,\n08-08-1988 is replaced by NUM2-NUM2-NUM4), this method\nhelps to capture some digit patterns such as date and phone\nnumbers and will dramatically decrease the amount of words\nin vocabularies as well. To compute vector representations of\nword, word2vec [48] was used and modified with an extra option\nto incrementally train word embeddings based on existing\nmodels being given new text materials. We inherited the best\nparameter settings for named entity recognition from a previous\nstudy [24] with 200-word vector dimensions, 5 words in the\ncontext window, 10 negative samples, start with a 0.05 learning\nrate, and run over 20 iterations.\nBesides using word vectors as features, we also used a collection\nof hand-crafted features that were identical to our previous\nNICTA IE system [25] for performance tracking. For each\nfeature of 1-word instance, a unigram with a window size of 3\n(w_{i-1}, w_i, w_{i+1}), and bigrams with a window size of 2\n(w_{i-1}w_i, w_iw_{i+1}) were used. Features used in our\nexperiments include the lemma, part of speech tag, and parse\ntree, top 5 candidates and top mapping retrieved from the\nUnified Medical Language System (UMLS) [49], medication\nscore—derived from the Anatomical Therapeutic Chemical\nList, location, and frequency.\nTo track the performance improvement on this task, the\nfollowing 10 baselines were included for comparison, they are:\n1) Benchmark, 2) TUC-MI-A, 3) TUC-MI-B, 4) ECNU_ICA-A,\n5) ECNU_ICA-B, 6) LQRZ-A, 7) LQRZ-B, 8) Unigram NN, 9)\nRandom, 10) Majority.\nBenchmark\nThis was the initial NICTA benchmark system on this task using\na single-layer linear-chain CRF [50] with L2 regulator with the\nhandcrafted features mentioned before as input. A detailed\ndescription of this system can be found in the study by Suominen\net al [4].\nParticipants of Conference and Labs of the Evaluation Forum\n(CLEF) eHealth Evaluation Lab 2016 Task 1: The CLEF\neHealth 2016 Task 1 required the participants to implement\nsystems that are able to identify relevant text snippets from\nfree-text nursing handovers [51]. Participants were expected to\ntrain their systems using the given training set, optimize their\nperformances using the validation set, and their final result was\ntested on a previous confidential test set. It should be noted that\nthe benchmark NICTA IE system was provided to participants\nin the CLEF task as well as feature generators and intermediate\nprocessing results [51]. Participants could start their experiments\nfrom any point based on our previous work with very little\neffort. In fact, all systems except a and b were started from the\nNICTA benchmark IE system.\n• TUC-MI-A was based on our benchmark system; rather\nthan using our default features, this method constructed a\n41-feature set based on Stanford CoreNLP, latent Dirichlet\nallocation, regular expressions, and the ontologies of\nWordNet and UMLS features [10].\n• TUC-MI-Boptimized TUC-MI-A; 19 features were selected\nfrom the whole feature set with forward and backward\ngreedy search.\n• ECNU_ICA-A was a rule-based IE system to recognize bed\nnumber, room number, age, and doctor’s name and was\ncombined with CRF results using the same feature\ncollection with the organizers’ benchmark system [52].\n• ECNU_ICA-B has the same system architecture as\nECNU_ICA-A, except for CRF training, and a subcollection\nof features was used for different label types [52].\n• LQRZ-Awas a feed-forward neural network with one hidden\nlayer initialized with uniform distribution. Inputs to this\nNN model are pretrained word embeddings from\nGoogleNews. No handcrafted features were used in this\nmodel [53].\n• LQRZ-B firstly used a random forest to predict a subset of\nthe tags and the previous NN to further discriminate\nbetween the remaining labels [53].\nUnigram NN\nThe unigram NN was an implementation of a 2-layer, first-order\nlinear-chain graph transformer [21] with handcrafted features\nweighted by word vectors as the first layer and a linear-chain\nCRF on top of it. The model was trained using AdaGrad. This\nis a baseline to show separately, from the multilayer NN, what\nis the performance gain from using word embeddings and\ntransfer learning.\nOther Baselines\nWe evaluated the task difficulty of labeling each word with 1\nout of 37 classes by comparing 2 baseline systems: First, we\nbuilt a system that assigns classes randomly. Second, we\nimplemented another system that always predicts the majority\nclass (ie, the most common class in the training set): Random\nto randomly select 1 class label for each instance and Majority\nto assign the majority class of Future_Goal/\nTaskToBeCompleted/ExpectedOutcome for every instance.\nResults\nResearchers worldwide have contributed to achieve a significant\nimprovement on the clinical handover task because of a shared\ncomputational task organized in 2016 [51]. In this study, we\nhave reported the results from our experiments on the test set\n(Table 3) and have also taken this opportunity to overview\nperformance improvements in the task, to summarize methods\nthat have been used to solve the problems so far, and to inspire\nresearchers to work further on this task. Overall, the\nstate-of-the-art benchmark has been increased from 38.2% to\n41.6% F1 (P<.001; Wilcoxon text [54]). Our transfer learning\nmethod using BBN as source domain (Trans_BBN) outperforms\nall other methods.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 8http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 3. Results of transfer learning compared with baseline systems.\nMicF1fMicReceMicPrecdMacF1cMacRecbMacPrecaMethod\n0.5160.4880.5470.4160.4190.498 gTrans_BBN\n0.5140.4710.5650.3920.3900.481Trans_I2B2\n0.5030.5050.5000.3820.3690.493TUC-MI-B\n0.5160.5220.5100.3740.4060.493ECNU_ICA-A\n0.5400.4830.6120.3540.3610.477General+I2B2+train\n0.5370.4840.6040.3540.3670.443I2B2+train\n0.5350.4780.6060.3450.3560.429General\n0.5030.5170.4900.3450.3830.425LQRZ-B\n0.5320.4740.6060.3340.3460.409General+PubMed+PMC\n0.5030.4480.5740.3110.2920.393Unigram\n0.4710.4430.5030.3110.3000.423TUC-MI-A\n0.5140.4720.5630.3080.3070.411LQRZ-A\n0.5130.4590.5810.2970.2920.428ECNU_ICA-B\n0.3980.3680.4330.2460.2330.435National Information and Communications\nTechnology Australia\n0.0220.0300.0180.0190.0280.018Random\n0.0200.0270.0160.0010.0290.000Majority\naMacro averaged precision.\nbMacro averaged recall.\ncMacro averaged F1.\ndMicro averaged precision.\neMicro averaged recall.\nfMicro averaged F1.\ngItalics indicate the best result over the column.\nTransfer learning with I2B2 as a source model (Trans_I2B2) is\nalso able to increase the overall macro F1 by 4.7% (P<.001)\ncompared with models using a 2-layer NN with general word\nembeddings (General). When using the same collection of\nhandcrafted features, a 2-layer NN model (Unigram) performs\n6.5% better than a single-layer linear-chain CRF (NICTA). The\nsame model (Unigram) gains 3.4% improvement of macro F1\n(P<.001) by using word embeddings pretrained with a large\ntext collection with general English (Wiki). Word embeddings\ntrained with a domain-related corpus but different context\n(Wiki+PubMed+PMC) actually harm rather than help the result.\nThis is possibly because although the domain-related corpus\ncontains medical terms, which are also used in a clinical health\ncare environment, the context of these terms is still very different\nfrom clinical handovers. On the contrary, documents used in a\nsimilar scenario (I2B2+train) show their advantage at this point.\nFinally, embeddings trained with a combination of I2B2+train\nwith general English (Wiki_I2B2+train) do not help the system\nto increase the macro F1, but they yield the best result on micro\nF1.\nDiscussion\nPrincipal Findings\nIt can be seen from the experiment results that the DL system\nusing pretrained word representations as the input, and the\nproposed transfer learning technique, is able to achieve better\nperformance.\nWhen comparing the results of different system setups on\ndifferent subclasses, we observed that word representations\nlearned from different domains and the knowledge transferred\nfrom various sources affect the clinical IE system on certain\nsubclasses.\nComparing with the best result of feature engineering methods\nused in TUC-MI [9], our transfer learning method performs\n3.4% better without a labor-costing feature-selection procedure.\nFurthermore, in contrast with the rule-based methods used in\nECNU_ICA [52], which require domain-specific experts to\ninspect data carefully and make the rules, our method is much\nmore efficient and still able to achieve a 4.2% better macro F1.\nFinally, the best LQRZ [53] used a very similar architecture\nwith our General model, and we can see their performance is\nvery similar as well; the minor difference is caused by different\nmaterials to train the word embeddings. Our transfer learning\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 9http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nmethod is able to improve 7.1% macro F1 on top of the General\nmodel (P<.001).\nIn this section, we have analyzed these results and discussed\nthese effects. The default measure will be the official macro F1\nunless specifically mentioned otherwise.\nWord Representations\nWord embeddings trained from general English can improve\nthe clinical IE performance. Our results show that the General\nmodel, which used exactly the same model structure and feature\nmap as the Unigram model, except it used a combination of 3\nlarge corpora (English Wiki, UMBC, and One Billion) to train\ngeneral word embeddings, performed better on the overall task\n(34.5% vs 31.1%, respectively; P<.001). This indicates that\nword representations trained from unlabeled general English\ntext are able to capture word features that contribute to\nclassifying different annotations in clinical handovers.\nMoreover, general word embeddings fine-tuned with a small\ntask-relevant dataset can further increase the result. The model\ntrained with I2B2 and NICTA training data (I2B2+train)\noutperforms the Unigram model by 4.3% and outperforms\ngeneral embeddings when it is compared with the General model\n(35.4% vs 34.5%, respectively; P=.17).\nHowever, no evidence was found to indicate that continuing\ntraining word embeddings with a relevant dataset based on\npretrained general word embeddings contributes to the system\nperformance when comparing the I2B2+train with\nGeneral+I2B2+train. This might be because although the\ncorpora of I2B2 and NICTA training data are significantly\nsmaller than the general English corpus, the vocabulary is still\nenough to cover words that are present in the test set, and after\nseveral iterations of training, word embeddings in these 2\ndifferent settings eventually converged to similar values.\nWord embeddings trained from domain relevant data do not\nshow any evidence to contribute to improving the system result\neither. Our results showed that the General+PubMed+PMC\nmodel performed worse than the General model (33.4% vs\n34.5%, respectively; P=.07). This might be because even though\nwe considered clinical and biomedical areas as relevant, but\nbecause of having different scenarios, vocabulary and context\ncould end up too different. This would introduce more noise to\nthe word embeddings and so does not contribute to the IE\nperformance.\nTransfer Learning\nTransfer learning shows its advantage in the clinical handover\nIE task. The top 2 systems were both transfer learning models.\nTransfer learning from BBN (Trans_BBN) was 3.4% higher\nthan the previous best system TUC-MI-B (41.6% vs 38.2%,\nrespectively; P<.001).\nFor the overall result, there is no strong evidence to show any\nadvantage of transfer from domain-relevant source data\n(Trans_I2B2) over general annotations (Trans_BBN). On the\ncontrary, transfer learning from BBN with general annotations\nperformed slightly better than I2B2, which contains more\nrelevant entities with our target task on macro F1 (41.6% vs\n39.2%, respectively; P<.001).\nFor subclasses, Table 4 shows the results of transfer learning\ncompared with the baseline system when the performance is\nimproved on subclasses. When referring to Table 2:\n1. Some subclasses where the performance is improved by\ntransfer learning HAVE a mapping annotation type from\nthe source domain: for example, subclass\nPATIENT_INTRODUCTION: Age in years has a mapping\nannotation DATE:AGE in the source domain BBN, and\nTrans_BBN on this subclass performed better than the\nGeneral model (96.5% vs 94.8%, respectively; P<.001).\nThis indicates that when the target domain labels have\nmappings from the source domain annotations, transfer\nlearning can improve the extraction results of these labels.\n2. Some subclasses where the performance is improved by\ntransfer learning do not have a mapping annotation type\nfrom the source domain: for subclass FUTURE_CARE:\nAlert/waring/abnormal result, the general model was not\nable to predict any instance correctly, whereas transfer\nlearning did learn some knowledge from the training set\nbut the performance was still not very high. This might be\nbecause these subclasses may have some underlying\ncorrelations with source domain labels that are automatically\nlearned during the second process in our method, even\nthough the correlations were not straightforward or obvious\nfor human readers.\n3. Some subclasses that have mappings from the source\ndomains do not gain any improvement from transfer\nlearning: for example, PATIENT_INTRODUCTION/\nGiven_names. These classes normally already have good\nperformance from only using general models, so transfer\nlearning, in this case, might introduce extra noise from other\ndomains that potentially have different sentence structures\nto the target domain, and thus harm the results.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 10http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 4. Results of subclasses when transfer learning improved in the baseline system (F1 score).\nTrans_BBNTrans_I2B2GeneralInstances (n)Entity type\n0.965 a0.8790.948246PATIENT_INTRODUCTION: Age (years)\n0.9170.8960.82688PATIENT_INTRODUCTION: Gender\n0.3440.3110.214412PATIENT_INTRODUCTION: Admission reason\n0.0810.1050.00070PATIENT_INTRODUCTION: Chronic condition\n0.0440.0830.016147PATIENT_INTRODUCTION: Disease/problem history\n0.1330.1290.06936PATIENT_INTRODUCTION: Care plan\n0.5660.5000.26714PATIENT_INTRODUCTION: Allergy\n0.4000.4310.11428APPOINTMENTS: Time\n0.4000.0000.0003APPOINTMENTS: Place: Ward\n0.1320.1750.111159APPOINTMENTS: Status\n0.1780.0870.00059FUTURE_CARE: Alert/warning/abnormal result\n0.0700.0680.000496FUTURE_CARE: Goal/task to be completed/expected outcome\n0.3610.2880.32789FUTURE_CARE: Discharge/transfer place\n0.6380.6880.570481MY_SHIFT: Status\n0.8040.7830.413101MY_SHIFT: Input/diet\n0.4780.3960.28652MY_SHIFT: Output/diuresis/bowel movement\n0.4570.3570.44455MY_SHIFT: Wounds/skin\n0.7480.7530.579245MY_SHIFT: Activities of daily living\n0.2020.2200.177361MY_SHIFT: Other observation\n0.4950.5480.450156MEDICATION: Medicine\n0.0850.0860.03468MEDICATION: Status\naItalics indicate the best result over the column.\nConclusions\nThis study investigated adapting a DL method to extract patient\ninformation from clinical reports. Domain and task specification\nword representations have been used as inputs to a DL system\nto achieve better performance. In addition, a transfer learning\nmodel has been applied to adapt knowledge learned from general\ntext sources to a domain-specific task. This method was able\nto further improve the overall result, especially in the classes\nrelated to the source domain. Domain-specific word\nrepresentations improve the overall clinical IE system\nperformance by 3.4% on macro-F1. Transferring the knowledge\nfrom a general English corpus to our task-specific domain gains\na further 7.1% improvement. To our knowledge, our study is\nthe first attempt to transfer knowledge from general deep models\nto specific tasks in health care and gain a significant\nimprovement. The result of our system is state-of-the-art on this\ntask. Our method and result point out the way toward adapting\nan advanced ML technique to professional informatics system\ntasks.\nAcknowledgments\nThis work was supported by the Commonwealth Department of Education and Training (The Australian National University\nAustralian Postgraduate Award). The authors express their gratitude to Maricel Angel, RN at NICTA, for helping them to create\nthe dataset for SR and IE.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nDataset description.\n[PDF File (Adobe PDF File), 77KB-Multimedia Appendix 1]\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 11http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nMultimedia Appendix 2\nThe test set of our experiments in the format of each row contains the word with its features, and the last column is the\nhuman-assigned label.\n[ZIP File (Zip Archive), 189KB-Multimedia Appendix 2]\nReferences\n1. Jordan MI, Mitchell TM. Machine learning: trends, perspectives, and prospects. Science 2015 Jul 17;349(6245):255-260.\n[doi: 10.1126/science.aaa8415] [Medline: 26185243]\n2. Miller DD, Brown EW. Artificial intelligence in medical practice: the question to the answer? Am J Med 2018\nFeb;131(2):129-133. [doi: 10.1016/j.amjmed.2017.10.035] [Medline: 29126825]\n3. Anderson W. 2007 National statement on ethical conduct in human research. Intern Med J 2011 Jul;41(7):581-582. [doi:\n10.1111/j.1445-5994.2011.02528.x] [Medline: 21762341]\n4. Suominen H, Zhou L, Hanlen L, Ferraro G. Benchmarking clinical speech recognition and information extraction: new\ndata, methods, and evaluations. JMIR Med Inform 2015;3(2):e19 [FREE Full text] [doi: 10.2196/medinform.4321] [Medline:\n25917752]\n5. Boyle DI, Rafael N. BioGrid Australia and GRHANITE™: privacy-protecting subject matching. Stud Health Technol\nInform 2011;168:24-34. [doi: 10.3233/978-1-60750-791-8-24] [Medline: 21893908]\n6. I2B2. NLP research data sets URL: https://www.i2b2.org/NLP/DataSets/ [accessed 2018-03-07] [WebCite Cache ID\n6xjXRGcPN]\n7. Graff D, Cieri C. Linguistic Data Consortium. English gigaword, linguistic data consortium URL: https://catalog.\nldc.upenn.edu/LDC2003T05 [accessed 2019-01-28] [WebCite Cache ID 75lT1QCRw]\n8. Zheng S, Lu JJ, Ghasemzadeh N, Hayek S, Quyyumi AA, Wang F. Effective information extraction framework for\nheterogeneous clinical reports using online machine learning and controlled vocabularies. JMIR Med Inform 2017 May\n9;5(2):e12 [FREE Full text] [doi: 10.2196/medinform.7235] [Medline: 28487265]\n9. Leroy G, Gu Y, Pettygrove S, Galindo M, Arora A, Kurzius-Spencer M. Automated extraction of diagnostic criteria from\nelectronic health records for autism spectrum disorders: development, evaluation, and application. J Med Internet Res 2018\nNov 7;20(11):e10497 [FREE Full text] [doi: 10.2196/10497] [Medline: 30404767]\n10. Ebersbach M, Herms R, Lohr C, Eibl M. Wrappers for feature subset selection in CRF-based clinical information extraction.\n2016 Presented at: Conference and Labs of the Evaluation Forum (CLEF); September 5-8, 2016; Evora, Portugal p. 69-80\nURL: http://ceur-ws.org/Vol-1609/16090069.pdf\n11. Collobert R, Weston J. A unified architecture for natural language processing: Deep neural networks with multitask learning.\nIn: Proceedings of the 25th international conference on Machine learning.: ACM; 2008 Presented at: ICML'08; July 5-9,\n2008; Helsinki, Finland p. 160-167.\n12. Turian J, Ratinov L, Bengio Y. Word representations: A simple and general method for semi-supervised learning. In:\nProceedings of the 48th Annual Meeting of the Association for Computational Linguistics.: the Association for Computational\nLinguistics (ACL); 2010 Presented at: ACL'10; July 11-16, 2010; Uppsala, Sweden p. 384-394.\n13. Baroni M, Dinu G, Kruszewski G. Don't count, predict! A systematic comparison of context-counting vs context-predicting\nsemantic cectors. : Association for Computational Linguistics (ACL); 2014 Presented at: ACL'14; June 22-27, 2014;\nBaltimore, Maryland, USA p. 1:238-1:247 URL: http://www.aclweb.org/anthology/P14-1023\n14. Andreas J, Klein D. How much do word embeddings encode about syntax? : Association for Computational Linguistics\n(ACL); 2014 Presented at: ACL'14; June 22-27, 2014; Baltimore, Maryland, USA p. 822-827.\n15. Qu L, Ferraro G, Zhou L, Hou W, Baldwin T. Named entity recognition for novel types by transfer learning. : Association\nfor Computational Linguistics (ACL); 2016 Presented at: 2016 Conference on Empirical Methods in Natural Language\nProcessing (EMNLP); November 1–5, 2016; Austin, Texas, USA p. 899-905.\n16. Arnold A, Nallapati R, Cohen WW. Exploiting feature hierarchy for transfer learning in named entity recognition. :\nAssociation for Computational Linguistics (ACL); 2008 Presented at: 46th Annual Meeting of the Association for\nComputational Linguistics (ACL); June 15-20, 2008; Columbus, Ohio, USA p. 245-253 URL: http://aclweb.org/anthology/\nP08-1029\n17. Suominen H. Kaggle. 2017. NICTA synthetic nursing handover data URL: https://www.kaggle.com/c/hospital-handover-forms\n[accessed 2018-05-06] [WebCite Cache ID 6zDe1dLzT]\n18. Angel M, Suominen H, Zhou L, Hanlen L. CSIRO Data Access Portal. 2014. Synthetic nursing handover training and\ndevelopment data set - text files URL: https://data.csiro.au/collections/[accessed 2019-01-28] [WebCite Cache ID 75lrDsAGg]\n19. Angel M, Suominen H, Zhou L, Hanlen L. CSIRO Data Access Portal. 2014. Synthetic nursing handover training and\ndevelopment data set - audio files URL: https://data.csiro.au/collections/ [accessed 2019-01-28] [WebCite Cache ID\n75lrAfyeb]\n20. Australian Institute of Health and Welfare. 2016. Chronic diseases URL: https://www.aihw.gov.au/reports-data/\nhealth-conditions-disability-deaths/chronic-disease/overview [accessed 2019-01-28] [WebCite Cache ID 75lV7EA2r]\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 12http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n21. Collobert R, Weston J, Bottou L, Karlen M, Kavukcuoglu K, Kuksa P. Natural language processing (almost) from scratch.\nJ Mach Learn Res 2011;12(2011):2493-2537 [FREE Full text]\n22. Mikolov T, Chen K, Corrado G, Dean J. arXiv. 2013. Efficient estimation of word representations in vector space URL:\nhttps://arxiv.org/pdf/1301.3781.pdf [accessed 2019-03-20] [WebCite Cache ID 770Q1SOtq]\n23. Mikolov T, Sutskever I, Chen K, Corrado G, Dean J. Distributed representations of words and phrases and their\ncompositionality. In: Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume\n2. 2013 Presented at: NIPS'13; December 5-10, 2013; Stateline, NV, USA p. 3111-3119.\n24. Qu L, Ferraro G, Zhou L, Hou W, Schneider N, Baldwin T. Big data small data, in domain out-of domain, known word\nunknown word: The impact of word representations on sequence labelling tasks. 2015 Presented at: 19th Conference on\nComputational Natural Language Learning (CoNLL); July 30-31, 2015; Beijing, China p. 83-93.\n25. Suominen H, Johnson M, Zhou L, Sanchez P, Sirel R, Basilakis J, et al. Capturing patient information at nursing shift\nchanges: methodological evaluation of speech recognition and information extraction. J Am Med Inform Assoc 2014 Oct\n21. [doi: 10.1136/amiajnl-2014-002868] [Medline: 25336589]\n26. Schmidhuber J. Deep learning in neural networks: an overview. Neural Netw 2015 Jan;61:85-117. [doi:\n10.1016/j.neunet.2014.09.003] [Medline: 25462637]\n27. Zhou L, Xu Q, Suominen H, Gedeon T. EPUTION at SemEval-2018 task 2: Emoji prediction with user adaption. In:\nProceedings of The 12th International Workshop on Semantic Evaluation. 2018 Presented at: SemEval 2018; June 5-6,\n2018; New Orleans, Louisiana, USA p. 449-453. [doi: 10.18653/v1/S18-1071]\n28. Barbieri F, Camacho-Collados J, Ronzano F, Espinosa-Anke L, Ballesteros M, Basile V, et al. SemEval 2018 task 2:\nMultilingual emoji prediction. In: Proceedings of The 12th International Workshop on Semantic Evaluation. 2018 Presented\nat: SemEval 2018; June 5-6, 2018; New Orleans, Louisiana, USA p. 24-33. [doi: 10.18653/v1/S18-1003]\n29. Maynard D, Tablan V, Ursu C, Cunningham H, Wilks Y. Named entity recognition from diverse text types. In: Proceedings\nof the Recent Advances in Natural Language Processing 2001 Conference. 2001 Presented at: RANLP 2001; September\n5-7, 2001; Tzigov Chark, Bulgaria p. 257-274.\n30. Chiticariu L, Krishnamurthy R, Li Y, Reiss F, Vaithyanathan S. Domain adaptation of rule-based annotators for named-entity\nrecognition tasks. In: Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP).:\nAssociation for Computational Linguistics (ACL); 2010 Presented at: EMNLP'10; October 9-11, 2010; Cambridge,\nMassachusetts p. 1002-1012.\n31. Yosinski J, Clune J, Bengio Y, Lipson H. How transferable are features in deep neural networks? In: Proceedings of the\n27th International Conference on Neural Information Processing Systems - Volume 2. 2014 Presented at: NIPS'14; December\n8-13, 2014; Montreal, Quebec, Canada p. 3320-3328.\n32. Rizzo G, Troncy R. NERD: A framework for unifying named entity recognition and disambiguation extraction tools. In:\nProceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational\nLinguistics.: Association for Computational Linguistics (ACL); 2012 Presented at: EACL'12; April 23-27, 2012; Avignon,\nFrance p. 73-76.\n33. Suominen H, Pahikkala T, Salakoski T. Critical points in assessing learning performance via cross-validation. In: Proceedings\nof the 2nd International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning.: Helsinki\nUniversity of Technology; 2008 Presented at: AKKR'08; September 17-19, 2008; Porvoo, Finland p. 9-22.\n34. Han L, Kashyap AL, Finin T, Mayfield J, Weese J. UMBC_EBIQUITY-CORE: Semantic textual similarity systems. 2013\nPresented at: 2nd Joint Conference on Lexical and Computational Semantics (*SEM); 2013; Atlanta, GA, USA p. 44-52.\n35. Chelba C, Mikolov T, Schuster M, Ge Q, Brants T, Koehn P, et al. One billion word benchmark for measuring progress in\nstatistical language modeling. In: Proceedings of the 15th Annual Conference of the International Speech Communication\nAssociation. 2014 Presented at: Interspeech 2014; September 14-18, 2014; Singapore p. 2635-2639.\n36. Uzuner O, Sibanda TC, Luo Y, Szolovits P. A de-identifier for medical discharge summaries. Artif Intell Med 2008\nJan;42(1):13-35 [FREE Full text] [doi: 10.1016/j.artmed.2007.10.001] [Medline: 18053696]\n37. Uzuner O, Luo Y, Szolovits P. Evaluating the state-of-the-art in automatic de-identification. J Am Med Inform Assoc\n2007;14(5):550-563 [FREE Full text] [doi: 10.1197/jamia.M2444] [Medline: 17600094]\n38. Uzuner O, Solti I, Xia F, Cadag E. Community annotation experiment for ground truth generation for the I2B2 medication\nchallenge. J Am Med Inform Assoc 2010;17(5):519-523 [FREE Full text] [doi: 10.1136/jamia.2010.004200] [Medline:\n20819855]\n39. Uzuner O, Solti I, Cadag E. Extracting medication information from clinical text. J Am Med Inform Assoc 2010;17(5):514-518\n[FREE Full text] [doi: 10.1136/jamia.2010.003947] [Medline: 20819854]\n40. Zhou L, Suominen H, Hanlen L. Evaluation data and benchmarks for cascaded speech recognition and entity extraction.\nIn: Proceedings of the Third Edition Workshop on Speech, Language & Audio in Multimedia.: ACM; 2015 Presented at:\nSLAM'15; October 30, 2015; Brisbane, Australia p. 15-18.\n41. Wikimedia Downloads. URL: https://dumps.wikimedia.org/ [accessed 2018-03-07] [WebCite Cache ID 6xjWnvCVm]\n42. UMBC Ebiquity. UMBC webbase corpus URL: https://ebiquity.umbc.edu/resource/html/id/351 [accessed 2018-03-07]\n[WebCite Cache ID 6xjX5evo8]\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 13http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n43. Google Research. One billion word benchmark for measuring progress in statistical language modeling URL: https://research.\ngoogle.com/pubs/pub41880.html [accessed 2018-03-07] [WebCite Cache ID 6xjXGBpnU]\n44. NCBI. PubMed URL: https://www.ncbi.nlm.nih.gov/pubmed [accessed 2019-03-19] [WebCite Cache ID 6xjXaRZXU]\n45. NCBI. PMC URL: https://www.ncbi.nlm.nih.gov/pmc/ [accessed 2018-03-07] [WebCite Cache ID 6xjXgELxS]\n46. Weischedel R, Brunstein A. Linguistic Data Consortium. 2005. BBN pronoun conference and entity type corpus URL:\nhttps://catalog.ldc.upenn.edu/LDC2005T33\n47. Manning C, Surdeanu M, Bauer J, Finkel J, Bethard SJ, McClosky D. The Stanford CoreNLP natural language processing\ntoolkit. 2014 Presented at: 52nd Annual Meeting of the Association for Computational Linguistic system Demonstrations;\nJune 22-27, 2014; Baltimore, Maryland, USA p. 55-60.\n48. Google Code. 2013. Tool for computing continuous distributed representations of words URL: https://code.google.com/\narchive/p/word2vec/[WebCite Cache ID 748ORV86C]\n49. UMLS Terminology Server (and API). 2018. URL: https://umls.terminology.tools/ [accessed 2018-11-23] [WebCite Cache\nID 748Oh3vNG]\n50. Lafferty JD, McCallum A, Pereira FC. Conditional random fields: Probabilistic models for segmenting and labeling sequence\ndata. In: Proceedings of the Eighteenth International Conference on Machine Learning.: Morgan Kaufmann Publishers Inc;\n2001 Presented at: ICML'01; July 1, 2001; Williamstown, MA, USA p. 282-289.\n51. Suominen H, Zhou L, Goeuriot L, Kelly L. Task 1 of the CLEF eHealth evaluation lab 2016: Handover information\nextraction. 2016 Presented at: Conference and Labs of the Evaluation Forum (CLEF); September 5-8, 2016; Evora, Portugal\np. 1-14.\n52. Song Y, He Y, Liu H, Wang Y, Hu Q, He L, et al. ECNU at 2016 eHealth task 1: Handover information extraction. 2016\nPresented at: Conference and Labs of the Evaluation Forum (CLEF); September 5-8, 2016; Evora, Portugal p. 147-156.\n53. Quiroz L, Mennes L, Dehghani M. Distributional semantics for medical information extraction. 2016 Presented at: Conference\nand Labs of the Evaluation Forum (CLEF); September 5-8, 2016; Evora, Portugal p. 109-122.\n54. Wilcoxon F. Individual comparisons by ranking methods. Biometrics 1945;1(6):80-83. [doi: 10.1007/978-1-4612-4380-9_16]\n55. LeCun Y, Bengio Y, Hinton G. Deep learning. Nature 2015 May 28;521(7553):436-444. [doi: 10.1038/nature14539]\n[Medline: 26017442]\n56. Suominen H, Lehtikunnas T, Hiissa M, Back B, Karsten H, Salakoski T, et al. Natural Language Processing for Nursing\nDocumentation. 1945 Presented at: Proceddings of the Second International Conference on Computational Intelligence in\nMedicine and Health Care (CIMED), Lissabon, Portugal; 2005.\n57. Suominen H, Lehtikunnas T, Back B, Karsten H, Salakoski T, Salantera S. Applying Language Technology to Nursing\nDocuments: Pros and Cons with A Focus on Ethics. International Journal of Medical Informatics 2007;76:S293-S301.\n[Medline: 17604685]\nAbbreviations\nAdaGrad: adaptive gradient algorithm\nBBN: Bolt, Beranek and Newman\nCLEF: Conference and Labs of the Evaluation Forum\nCRF: conditional random field\nDL: deep learning\nGPE: geographical entities\nIE: information extraction\nML: machine learning\nNICTA: National Information and Communications Technology Australia\nNN: neural network\nNLM: National Library of Medicine\nNLP: natural language processing\nPMC: PubMed Central\nRN: registered nurse\nSR: speech recognition\nUMBC: University of Maryland, Baltimore County\nUMLS: Unified Medical Language System\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 14http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nEdited by G Eysenbach; submitted 06.07.18; peer-reviewed by Y Chu, M Torii; comments to author 07.10.18; revised version received\n02.02.19; accepted 17.02.19; published 25.04.19\nPlease cite as:\nZhou L, Suominen H, Gedeon T\nAdapting State-of-the-Art Deep Language Models to Clinical Information Extraction Systems: Potentials, Challenges, and Solutions\nJMIR Med Inform 2019;7(2):e11499\nURL: http://medinform.jmir.org/2019/2/e11499/\ndoi: 10.2196/11499\nPMID: 31021325\n©Liyuan Zhou, Hanna Suominen, Tom Gedeon. Originally published in JMIR Medical Informatics (http://medinform.jmir.org),\n25.04.2019. This is an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work, first published in JMIR Medical Informatics, is properly cited. The complete bibliographic information,\na link to the original publication on http://medinform.jmir.org/, as well as this copyright and license information must be included.\nJMIR Med Inform 2019 | vol. 7 | iss. 2 | e11499 | p. 15http://medinform.jmir.org/2019/2/e11499/\n(page number not for citation purposes)\nZhou et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX"
}