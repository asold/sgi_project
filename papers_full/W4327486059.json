{
    "title": "MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters",
    "url": "https://openalex.org/W4327486059",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A5100702158",
            "name": "Lin Tian",
            "affiliations": [
                "RMIT University"
            ]
        },
        {
            "id": "https://openalex.org/A5021983750",
            "name": "Xiuzhen Zhang",
            "affiliations": [
                "RMIT University"
            ]
        },
        {
            "id": "https://openalex.org/A5032767467",
            "name": "Jey Han Lau",
            "affiliations": [
                "The University of Melbourne"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2954482098",
        "https://openalex.org/W2988025470",
        "https://openalex.org/W2885316213",
        "https://openalex.org/W6778883912",
        "https://openalex.org/W3035390927",
        "https://openalex.org/W2112743132",
        "https://openalex.org/W2017327292",
        "https://openalex.org/W2905471643",
        "https://openalex.org/W2971048662",
        "https://openalex.org/W2194775991",
        "https://openalex.org/W3037924975",
        "https://openalex.org/W3099793224",
        "https://openalex.org/W4213041413",
        "https://openalex.org/W4256224965",
        "https://openalex.org/W6717697761",
        "https://openalex.org/W2964316912",
        "https://openalex.org/W2963361481",
        "https://openalex.org/W3123356687",
        "https://openalex.org/W4288087322",
        "https://openalex.org/W4292779060",
        "https://openalex.org/W4288322074",
        "https://openalex.org/W2742093937",
        "https://openalex.org/W4244512923",
        "https://openalex.org/W2604763608",
        "https://openalex.org/W2964303773",
        "https://openalex.org/W2888571776",
        "https://openalex.org/W1501349418",
        "https://openalex.org/W2968250601",
        "https://openalex.org/W2174227032",
        "https://openalex.org/W3091322135",
        "https://openalex.org/W2138969065",
        "https://openalex.org/W4297801719",
        "https://openalex.org/W4289763970",
        "https://openalex.org/W2963635075",
        "https://openalex.org/W3174193248",
        "https://openalex.org/W1522301498",
        "https://openalex.org/W2963341924",
        "https://openalex.org/W2896457183",
        "https://openalex.org/W2407434113",
        "https://openalex.org/W2472819217",
        "https://openalex.org/W3043892524",
        "https://openalex.org/W2547599276",
        "https://openalex.org/W2601450892",
        "https://openalex.org/W4288641046"
    ],
    "abstract": "State-sponsored trolls are the main actors of influence campaigns on social\\nmedia and automatic troll detection is important to combat misinformation at\\nscale. Existing troll detection models are developed based on training data for\\nknown campaigns (e.g.\\\\ the influence campaign by Russia's Internet Research\\nAgency on the 2016 US Election), and they fall short when dealing with {\\\\em\\nnovel} campaigns with new targets. We propose MetaTroll, a text-based troll\\ndetection model based on the meta-learning framework that enables high\\nportability and parameter-efficient adaptation to new campaigns using only a\\nhandful of labelled samples for few-shot transfer. We introduce\\n\\\\textit{campaign-specific} transformer adapters to MetaTroll to ``memorise''\\ncampaign-specific knowledge so as to tackle catastrophic forgetting, where a\\nmodel ``forgets'' how to detect trolls from older campaigns due to continual\\nadaptation. Our experiments demonstrate that MetaTroll substantially\\noutperforms baselines and state-of-the-art few-shot text classification models.\\nLastly, we explore simple approaches to extend MetaTroll to multilingual and\\nmultimodal detection. Source code for MetaTroll is available at:\\nhttps://github.com/ltian678/metatroll-code.git.\\n",
    "full_text": "MetaTroll: Few-shot Detection of State-Sponsored Trolls with\nTransformer Adapters\nLin Tian\nRMIT University\nMelbourne, Australia\nlin.tian2@student.rmit.edu.au\nXiuzhen Zhang\nRMIT University\nMelbourne, Australia\nxiuzhen.zhang@rmit.edu.au\nJey Han Lau\nThe University of Melbourne\nMelbourne, Australia\njeyhan.lau@gmail.com\nABSTRACT\nState-sponsored trolls are the main actors of influence campaigns\non social media and automatic troll detection is important to com-\nbat misinformation at scale. Existing troll detection models are\ndeveloped based on training data for known campaigns (e.g. the\ninfluence campaign by Russiaâ€™s Internet Research Agency on the\n2016 US Election), and they fall short when dealing with novel\ncampaigns with new targets. We propose MetaTroll, a text-based\ntroll detection model based on the meta-learning framework that\nenables high portability and parameter-efficient adaptation to new\ncampaigns using only a handful of labelled samples for few-shot\ntransfer. We introducecampaign-specific transformer adapters to\nMetaTroll to â€œmemoriseâ€ campaign-specific knowledge so as to\ntackle catastrophic forgetting, where a model â€œforgetsâ€ how to de-\ntect trolls from older campaigns due to continual adaptation. Our\nexperiments demonstrate that MetaTroll substantially outperforms\nbaselines and state-of-the-art few-shot text classification models.\nLastly, we explore simple approaches to extend MetaTroll to mul-\ntilingual and multimodal detection. Source code for MetaTroll is\navailable at: https://github.com/ltian678/metatroll-code.git\nCCS CONCEPTS\nâ€¢ Computing methodologies â†’Natural language processing;\nInformation extraction .\nKEYWORDS\ntroll detection, few-shot learning, adapter, continual learning, mul-\ntilingual, multimodal\nACM Reference Format:\nLin Tian, Xiuzhen Zhang, and Jey Han Lau. 2023. MetaTroll: Few-shot Detec-\ntion of State-Sponsored Trolls with Transformer Adapters. In Proceedings of\nthe ACM Web Conference 2023 (WWW â€™23), May 1â€“5, 2023, Austin, TX, USA.\nACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3543507.3583417\n1 INTRODUCTION\nState-sponsored trolls, along with bots, are the main actors in in-\nfluence operations and misinformation campaigns on social media.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nÂ© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9416-1/23/04. . . $15.00\nhttps://doi.org/10.1145/3543507.3583417\nThe 2016 US Presidential election for example, highlighted how for-\neign states can carry out mass influence campaign, and in this case\nby Russiaâ€™s Internet Research Agency [ 40].1 In another context,\nBroniatowski et al. [6] studied how influence operations under-\nmined the vaccine debate in public health. To help combat misin-\nformation on social media, Twitter began releasing user accounts\nassociated with state-sponsored influence activities. Our work uses\nthis dataset for troll detection, and as such a troll in our context is\na state-sponsored agent with links to an influence campaign.\nExisting troll detection models focus on extracting signals from\nuser online posts and user activities [ 1â€“3, 8, 10, 12, 32]. Recent\nneural approaches explore fusing different feature representations\nfor troll detection, e.g. social structure, source posts and propagated\nposts such as retweets on Twitter [3, 39]. These studies generally\nformulate the task as a standard supervised learning problem which\nrequires a substantial amount of labelled data for known campaigns.\nAs such, they are ill-equipped to detect novel campaigns sponsored\nby another state for a different target.\nMeta-learning is a well-established framework for few-shot learn-\ning [14, 16, 28, 33, 35]. The idea of meta-learning is to leverage the\nshared knowledge from previous tasks to facilitate the learning\nof new tasks. In our context, meta-learning has the potential to\nquickly adapt a troll detection model to a new campaign via few-\nshot transfer, once itâ€™s meta-trained on a set of known campaigns.\nHowever, in a continual learning setting where the troll detection\nmodel needs to be constantly updated to work with new campaigns\nover time, the standard meta-learning framework suffers from cata-\nstrophic forgetting â€” the problem where the model â€œforgetsâ€ how to\ndetect trolls from the older campaigns as they are updated [36, 37].\nThe main contributions of this work are as follows:\nâ€¢We introduce a troll detection problem under a realistic set-\nting where novel campaigns continually emerge, mimicking\nreal-world events on social media platforms.\nâ€¢We propose MetaTroll, a text-based meta-learning frame-\nwork for troll detection, which includes a three-stage meta-\ntraining process that allows it to learn knowledge across\ndifferent campaigns for fast adaptation to new campaigns.\nâ€¢MetaTroll tackles catastrophic forgetting by introducing\ncampaign-specific transformer adapters [19] (i.e. each cam-\npaign has its own set of adapter parameters), which can\nâ€œmemoriseâ€ campaign-specific knowledge.\nâ€¢MetaTroll has the ability to to work with multiple languages\n(multilingual) by using a pretrained multilingual model and\nincorporate images as an additional input (multimodal) by\n1https://www.adelaide.edu.au/newsroom/news/list/2021/12/09/understanding-mass-\ninfluence-activities-is-critical.\narXiv:2303.07354v1  [cs.CL]  13 Mar 2023\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA Lin Tian, Xiuzhen Zhang, and Jey Han Lau\neither encoding them using pretrained image classifiers or\nconverting them into text via optical character recognition.\nâ€¢Large-scale experiments on a real-world dataset of 14 Twitter\ncampaigns showed the superior performance of MetaTroll.\n2 RELATED WORK\nOur related work comes from three areas, troll detection, meta-\nlearning and few-shot text classification.\n2.1 Troll detection\nEarly studies of troll detection focus on extracting hand-engineered\nfeatures from the textual contents of user posts for troll detection [8,\n10, 12, 12, 25, 31]. Signals such as writing style, sentiment as well as\nemotions have been explored [10, 31]. User online activities have\nalso been used to detect trolls [ 8, 12]. Cheng et al. [8] presents a\nstudy on anti-social behavior in online discussion communities,\nfocusing on users that will eventually be banned.\nMore recently, approaches that combine user posts and online\nactivities for troll detection have emerged [ 1, 3, 4, 13, 20, 32, 34].\nAddawood et al. [1] identify 49 linguistic markers of deception and\nmeasure their use by troll accounts. They show that such deceptive\nlanguage cues can help to accurately identify trolls. Im et al. [20]\npropose a detection approach that relies on usersâ€™ metadata, activity\n(e.g. number of shared links, retweets, mentions, etc.), and linguistic\nfeatures to identify active trolls on Twitter. Shafiei and Dadlani[32]\nshow that Russian trolls aim to hijack the political conversation to\ncreate distrust among different groups in the community. Stewart\nand Dawson [34] similarly demonstrate how trolls act to accentuate\ndisagreement and sow division along divergent frames, and this\nis further validated by Dutt et al . [13] in relation to Russian ads\non Facebook. In Badawy et al. [4], the authors study the effects of\nmanipulation campaigns by analysing the accounts that endorsed\ntrollsâ€™ activity on Twitter. They find that conservative-leaning users\nre-shared troll content 30 times more than liberal ones. Zannettou\net al. [39] compare troll behavior with other (random) Twitter ac-\ncounts by recognising the differences in the content they spread,\nthe evolution of their accounts, and the strategies they adopted\nto increase their impact. Atanasov et al . [3] leverage both social\nstructure and textual contents to learn user representations via\ngraph embedding. We focus on how to detect trolls in emergent\nsocial activities with limited labelled data.\n2.2 Meta-learning\nMeta-learning aims to extract some transferable knowledge from a\nset of tasks to quickly adapt to a new task. These approaches can be\ndivided into three categories: metric-based, optimisation-based, and\nmodel-based. Metric-based meta-learning approaches [33, 35] aim\nto learn an embedding function to encode the input and a metric\nfunction to learn the distance (e.g. cosine distance and euclidean\ndistance) between the query data and support data. Optimisation-\nbased approaches [14, 16] are designed to learn good parameter\ninitialisation that can quickly adapt to new tasks within a few\ngradient descent steps. Model-based approaches [26, 30] use neural\nnetworks to embed task information and predict test examples\nconditioned on the task information. Our approach combines both\noptimisation and model-based ideas in that we adopt [14] to update\nmodel parameters and a novel architecture that involves adapters\nand adaptive classification layers to learn task information.\n2.3 Few-shot text classification\nText classification has shifted from task-specific training to pre-\ntrained language models (such as BERT) followed by task-specific\nfine-tuning [11, 27]. Recently, the language model GPT-3 [7] has\nshown strong few-shot performance for many natural language\nprocessing tasks. Few-shot text classification refer to a text classifi-\ncation setting where there are novel unseen tasks (domains) with\nonly a few labelled examples for training a classification model,\nand meta-learning have been shown to produce strong perfor-\nmance [5, 15, 17, 38]. Bao et al . [5] introduce distributional sig-\nnatures, such as word frequency and information entropy, into a\nmeta-learning framework. Gao et al. [15] combine attention mech-\nanism with prototypical network to solve noisy few-shot relation\nclassification task. Geng et al. [17] leverage the dynamic routing\nalgorithm in meta-learning to solve sentiment and intent text clas-\nsification tasks for English and Chinese datasets. Yu et al . [38]\npropose an adaptive metric-based method that can determine the\nbest weighted combination automatically. In our problem setting,\nour focus is on adapting the classifier to a new task (i.e. campaign)\nunder the meta-learning framework.\n3 PROBLEM STATEMENT\nWe first explain some preliminaries of meta-learning, and contex-\ntualise it under our problem setting, before describing our model\nin Section 4. Let E= {ğ‘’0,ğ‘’1,ğ‘’2,...,ğ‘’ ğ‘™}be a set of campaigns. These\ncampaigns are split into two partitions: Eğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› for meta-training\nand Eğ‘¡ğ‘’ğ‘ ğ‘¡ for meta-testing (in our case, we have 6 campaigns for\nEğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›, and 4 for Eğ‘¡ğ‘’ğ‘ ğ‘¡; see Table 1). For each campaign ğ‘’, we have\nlabeled users U, where each user u consists of a list of text posts\nand images, defined as u = {(ğ‘0,ğ‘š0,ğ‘0),..., (ğ‘ğ‘›,ğ‘šğ‘›,ğ‘ğ‘›)}, where ğ‘\nrefers to the textual content of the post, ğ‘ša set of images, and ğ‘\nthe timestamp of the post. Each user u is associated with a ground-\ntruth labelğ‘¦ âˆˆğ‘Œ, whereğ‘Œ represents the label set (troll or non-troll;\nbinary). Our goal is to leverage the knowledge learned from past\n(meta-train) campaigns (Eğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›) to adapt quickly to new (meta-test)\ncampaigns (Eğ‘¡ğ‘’ğ‘ ğ‘¡) via few-shot learning (e.g. 5 or 10 users for the\nnew campaign).\nIn our problem setting, the notion of a task (from meta-learning)\nis the binary troll detection task for a particular campaign . Each task\nTğ‘– = (Dğ‘ ,Dğ‘)includes a support set Dğ‘  with ğ‘† data points and a\nquery set Dğ‘ with ğ‘„ data points, where Dğ‘  =\n\b\nuğ‘ \nğ‘–,ğ‘¦ğ‘ \nğ‘–\n\tğ‘†\nğ‘–=1 ,Dğ‘ =\n\b\nuğ‘\nğ‘–,ğ‘¦ğ‘\nğ‘–\n\tğ‘„\nğ‘–=1, and uğ‘– is a user with a list of posts and images and\nğ‘¦ğ‘– âˆˆ{0,1}corresponding to troll/non-troll labels (as defined above).\nDuring meta-training, we iterate through different campaign in\nEğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› and sample support and query instances to train the model.\nOnce thatâ€™s done, to adapt to a new campaigns inEğ‘¡ğ‘’ğ‘ ğ‘¡, we follow a\nsimilar training process but we update the model parameters using\nonly the support instances from the new campaign, and reserve the\nquery set for evaluation (i.e. the query set is not used for model\nupdate).\nMetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters WWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nRussia-2016-MAGA\nFeature \nExtractor \nTroll\nNon-Troll\nX\n+\nIran-2018-Pakistan\nAggregator\n \nIran-2018-Palestine\nAdaptive \nlinear \nclassifier \nBERT\nIran-2018-Pakistan\nAdapter\nBERT\nRussia-2016-MAGA\nAdapter\nBERT\nIran-2018-Palestine\nAdapter\nDataset\nmean-pooling \nfor  \nLinear \nclassifier\nFigure 1: Overall architecture of MetaTroll.\n4 APPROACH\nWe present the overall architecture of MetaTroll in Figure 1. Meta-\nTroll has two modules, a BERT-based [11] feature extractor and an\nadaptive linear classifier.\nWe first explain at a high level how we train MetaTroll in three\nstages for the feature extractor and linear classifier (Algorithm 1).\nIn the first stage, we fine-tune an off-the-shelf BERT and update all\nits parameters (Î¦) using all training samples from the meta-train\ncampaigns Eğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› (line 1 in Algorithm 1). At this stage we do not\nintroduce adapters [19] to BERT and it is optimised to do binary\nclassification of trolls and non-trolls. The idea of this step is to\ntrain a feature extractor for the troll detection task (in other words,\nthis step is standard fine-tuning to adapt BERT for binary troll\ndetection).\nIn the second stage, we introduce adapters [19] to BERT and train\nthe adapter parameters ( Î¨) using model agnostic meta-learning\n(MAML: Finn et al . [14] ; line 3â€“16 in Algorithm 1). Note that\nthe adapter is shared across all campaigns (i.e. the adapter is not\ncampaign-specific), and the idea of this stage is to learn a good\ninitialisation for the adapter to do general troll detection; in the\nnext stage, the learned adapter parameters will be used to initalise\ncampaign-specific adapters. During this stage, only the adapter pa-\nrameters (Î¨) are updated while the BERT parameters (Î¦) are frozen.\nIn the third and final stage, we introduce campaign-specific\nadapters and adaptive linear classifiers to MetaTroll, creating the\nfull model. The campaign-specific adapters are initialised using\nthe campaign-general adapter from stage 2. The idea of using\ncampaign-specific adapters is to address catastrophic forgetting\nwhen MetaTroll is continuously updated for new campaigns that\nemerge over time in an application setting: the campaign-specific\nadapter solves the â€˜forgettingâ€™ problem because the knowledge of\ndetecting older/past campaigns are stored in their adapters which\nwill not be overwritten as MetaTroll is continually updated. As\nfor the adaptive linear classifiers, they are also campaign-specific\nand designed to encourage MetaTroll to learn campaign represen-\ntations that are distinct for different campaigns. 2 We update the\ncampaign-specific adapter (Î¨ğ‘’) and classifier parameters (Î©ğ‘’) via\n2The adaptive linear classifier parameters are initialised randomly for a new campaign.\nmeta-learning, similar to stage 2 training (line 17â€“32 in Algorithm 1),\nnoting that the BERT parameters (Î¦) are frozen in this stage.\nAfter MetaTroll is trained (over the 3 stages), to adapt it to trolls\nof a new campaign at test time, we follow the third stage training to\nlearn campaign-specific adapter (Î¨ğ‘’) and classifier (Î©ğ‘’) parameters\nfor the new campaign. Once adapted, MetaTroll can be used to\nclassify users from this new campaign. We next describe the training\nstages and test inference in detail.\n4.1 Stage One Training\nIn the first stage, MetaTroll is a standard BERT fine-tuned with\nstandard cross entropy loss to do binary classification of trolls vs.\nnon-trolls (ignoring the campaigns). Given a user u with posts\n{ğ‘0,...,ğ‘ ğ‘›}:\nğ‘£ = BERT([CLS]âŠ• ğ‘0 âŠ•... âŠ•ğ‘ğ‘›) (1)\nË†ğ‘¦ = softmax(ğ‘Šğ‘£ +ğ‘) (2)\nwhere ğ‘£is the contextual embedding of [CLS]and âŠ•is the concate-\nnation operation.\n4.2 Stage Two Training\nIn the second stage, we add adapters to BERT (see Figure 2). Fol-\nlowing [19], we insert two adapter modules containing bottleneck\nlayers into each transformer layer of BERT. Note that the adapter\nis shared across all campaigns here, as the goal in this stage is to\nlearn good set of initial adapter parameter values that can be used\nto initialise campaign-specific adapters in the next stage.\nCorrespondingly, Equation 1 is now modified to:\nğ‘£ = AdapterBERT([CLS]âŠ• ğ‘0 âŠ•... âŠ•ğ‘ğ‘›) (3)\nWe meta-train the adapter parameters using MAML (line 3â€“16\nin Algorithm 1). We first sample a task Tğ‘– for campaign ğ‘’ from\nEğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› to create the support ğ·ğ‘  and query set ğ·ğ‘. Denoting M as\nthe model, Î¦ the BERT parameters and Î¨ the adapter parameters,\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA Lin Tian, Xiuzhen Zhang, and Jey Han Lau\nAlgorithm 1 MetaTroll\nInput/hyper-parameters: meta-train campaigns Eğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘›, meta-test campaigns Eğ‘¡ğ‘’ğ‘ ğ‘¡, learning rate ğ›½, ğ›¾ and ğ›¿, model ğ‘€\nParameters: campaign-general adapter Î¨, campaign-specific adapter Î¨ğ‘’, BERT Î¦, linear classifier Î©, learning rate ğ›¼\n1: ### Meta-training ###\n2: Fine-tune base ğ‘€ on Eğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› and provide initial model parameters Î¦ #Stage 1\n3: while not done do #Stage 2\n4: for ğ‘’ âˆˆEğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› do\n5: Sample batch of tasks Tğ‘– âˆˆT\n6: for each Tğ‘– do\n7: Sample ğ‘† data-points to form Dğ‘  = {(uğ‘–,ğ‘¦ğ‘–)}ğ‘†\nğ‘–=1 âˆˆTğ‘– as support set\n8: Sample ğ‘„ data-points to form Dğ‘ = {(uğ‘–,ğ‘¦ğ‘–)}ğ‘„\nğ‘–=1 âˆˆTğ‘– as query set for meta-update\n9: Compute âˆ‡Î¨L\u0000ğ‘€Î¦,Î¨\n\u0001 on ğ·ğ‘ \n10: Compute adapted parameters for adapter: Î¨â€²= Î¨ âˆ’ğ›¼âˆ‡Î¨LTğ‘–\n\u0000ğ‘€Î¦,Î¨\n\u0001\n11: Compute LTğ‘–\n\u0000ğ‘€Î¦,Î¨â€²\n\u0001 on ğ·ğ‘\n12: end for\n13: Update adapter parameters: Î¨ â†Î¨ âˆ’ğ›½âˆ‡Î¨ETğ‘– âˆ¼T\n\u0002\nLTğ‘–\n\u0000ğ‘€Î¦,Î¨â€²,Dğ‘\u0001\u0003\n14: Update inner loop learning rate: ğ›¼ â†Î¨ âˆ’ğ›½âˆ‡ğ›¼ETğ‘– âˆ¼T\n\u0002\nLTğ‘–\n\u0000ğ‘€Î¦,Î¨â€²,Dğ‘\u0001\u0003\n15: end for\n16: end while\n17: while not done do #Stage 3\n18: for ğ‘’ âˆˆEğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› do\n19: Sample batch of tasks Tğ‘– âˆˆT\n20: for each Tğ‘– do\n21: Sample ğ‘† data-points to form Dğ‘  = {(uğ‘–,ğ‘¦ğ‘–)}ğ‘†\nğ‘–=1 âˆˆTğ‘– as support set\n22: Sample ğ‘„ data-points to form Dğ‘ = {(uğ‘–,ğ‘¦ğ‘–)}ğ‘„\nğ‘–=1 âˆˆTğ‘– as query set for meta-update\n23: Compute mean troll and non-troll representations based on support set\n24: Compute âˆ‡Î¨ğ‘’,Î©ğ‘’ L\u0000ğ‘€Î¦,Î¨ğ‘’,Î©ğ‘’\n\u0001 on ğ·ğ‘ \n25: Compute adapted parameters for adapter: Î¨â€²ğ‘’ = Î¨ğ‘’ âˆ’ğ›¾âˆ‡Î¨ğ‘’ LTğ‘–\n\u0000ğ‘€Î¦,Î¨ğ‘’,Î©ğ‘’\n\u0001\n26: Compute adapted parameters for classifier: Î©â€²ğ‘’ = Î©ğ‘’ âˆ’ğ›¾âˆ‡Î©ğ‘’ LTğ‘–\n\u0000ğ‘€Î¦,Î¨ğ‘’,Î©ğ‘’\n\u0001\n27: Compute LTğ‘–\n\u0010\nğ‘€Î¦,Î¨â€²ğ‘’,Î©â€²ğ‘’\n\u0011\non ğ·ğ‘\n28: end for\n29: Update campaign-specific adapter parameters: Î¨ğ‘’ â†Î¨ğ‘’ âˆ’ğ›¿âˆ‡Î¨ğ‘’ ETğ‘– âˆ¼T[LTğ‘– (ğ‘€Î¦,Î¨â€²ğ‘’,Î©â€²ğ‘’ ,Dğ‘)]\n30: Update classifier parameters: Î©ğ‘’ â†Î©ğ‘’ âˆ’ğ›¿âˆ‡Î©ğ‘’ ETğ‘– âˆ¼T[LTğ‘– (ğ‘€Î¦,Î¨â€²ğ‘’,Î©â€²ğ‘’ ,Dğ‘)]\n31: end for\n32: end while\n33: ### Meta-testing ###\n34: Perform few-shot learning on meta-test campaigns Eğ‘¡ğ‘’ğ‘ ğ‘¡ using meta-learned parameters (Î¦,Î¨ğ‘’,Î©ğ‘’)\nwe next compute the inner loop to update Î¨ as follows [23]:\nLTğ‘– (ğ‘€Î¦,Î¨,Dğ‘ )= 1\n|Dğ‘ |\nâˆ‘ï¸\nuğ‘– âˆˆDğ‘ \nâˆ’log ğ‘(ğ‘¦ğ‘–|uğ‘–; Î¦,Î¨)\nÎ¨â€²= Î¨ âˆ’ğ›¼âˆ‡Î¨L\u0000ğ‘€Î¦,Î¨,Dğ‘ \u0001\nwhere ğ›¼ is the learning rate (computed next in the outer loop) and\nLTğ‘– (ğ‘€Î¦,Î¨,Dğ‘ )is the cross entropy loss over the support set. Next\nwe compute the cross-entropy loss based on the query set, using\nthe updated parameters:\nLTğ‘– (ğ‘€Î¦,Î¨â€²,Dğ‘)= 1\n|Dğ‘|\nâˆ‘ï¸\nuğ‘– âˆˆDğ‘\nâˆ’log ğ‘\u0000ğ‘¦ğ‘–|uğ‘–; Î¦,Î¨â€²\u0001\nThis inner loop is carried out for multiple steps of gradient\ndescent (using several tasks from the same campaign). Note that\nin this stage Î¦ (BERT parameters) is frozen. Once thatâ€™s done, we\nupdate the adapter parameters Î¨ and inner loop learning rate ğ›¼:3\nÎ¨ â†Î¨ âˆ’ğ›½âˆ‡Î¨ETğ‘– âˆ¼T\n\u0002\nLTğ‘–\n\u0000ğ‘€Î¦,Î¨â€²,Dğ‘\u0001\u0003\nğ›¼ â†Î¨ âˆ’ğ›½âˆ‡ğ›¼ETğ‘– âˆ¼T\n\u0002\nLTğ‘–\n\u0000ğ‘€Î¦,Î¨â€²,Dğ‘\u0001\u0003\nwhere ğ›½ is the learning rate for the outer loop (set to 1ğ‘’âˆ’5 in our\nexperiments).\n4.3 Stage Three Training\nIn this stage, we introduce campaign-specific adapters for each\ncampaign, and they are all initialised using the campaign-general\nadapter learned from the previous stage. Formally, Equation 3 is\nnow updated to:\nğ‘£ = AdapterBERTğ‘’([CLS]âŠ• ğ‘0 âŠ•... âŠ•ğ‘ğ‘›)\n3In our implementation, ğ›¼is layer-specific, i.e. we have a separate learning rate for\neach adapter in different layers.\nMetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters WWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nMulti-headed \nattention\nFeed-forward \nlayer\nAdapter\nLayer \nNorm\n2x \nFeed-forward \nlayers\nLayer \nNorm\nAdapter\nFeed-Forward\nDown\nFeed-Forward\nUp\nNonLinear\nFigure 2: Overall architecture of Adapter-BERT. The left fig-\nure illustrates how two adapter modules are added to a trans-\nformer layer; right shows the components in the adapter.\nwhere ğ‘’ is the campaign.\nWe introduce campaign-specific adapters to our model for two\nreasons: (1) they are more efficient to train and less vulnerable to\noverfitting (which is important in a few-shot learning setting), since\nthey contain only a small number of parameters compared to the\nalternative where we have one BERT model for every campaign);\nand (2) they alleviate catastrophic forgetting in a continual learning\nsetting, as each campaign has its own adapter.\nInspired by Requeima et al. [28], we next introduce an adaptive\nlinear classifier network that replacesğ‘Š and ğ‘in the linear layer\nused for classification (Equation 2). Intuitively, this adaptive clas-\nsifier works by first computing the aggregate troll and non-troll\nrepresentation for each campaign, and then learn campaign-specific\nprojections to classify between trolls vs. non-trolls. Let Dğ‘ \n0 and Dğ‘ \n1\ndenote the support set where the labels are trolls ( ğ‘¦ = 0) and\nnon-trolls (ğ‘¦ = 1) respectively, we computeğ‘Šğ‘’, ğ‘ğ‘’ and Ë†ğ‘¦for troll\ncampaign ğ‘’ as follows:\nğ‘Š0\nğ‘’ = 1\f\fDğ‘ \n0\n\f\f\nâˆ‘ï¸\nğ‘£âˆˆDğ‘ \n0\n(ğ‘£) ğ‘0\nğ‘’ = 1\f\fDğ‘ \n0\n\f\f\nâˆ‘ï¸\nğ‘£âˆˆDğ‘ \n0\n(ğ‘£)\nğ‘Š1\nğ‘’ = 1\f\fDğ‘ \n1\n\f\f\nâˆ‘ï¸\nğ‘£âˆˆDğ‘ \n1\n(ğ‘£) ğ‘1\nğ‘’ = 1\f\fDğ‘ \n1\n\f\f\nâˆ‘ï¸\nğ‘£âˆˆDğ‘ \n1\n(ğ‘£)\nË†ğ‘¦ = softmax(ğ‘Šğ‘’ğ‘£+ğ‘ğ‘’)\nwhere ğ‘Šğ‘–ğ‘’ denotes the (ğ‘– âˆ’1)th column of ğ‘Šğ‘’. In other words,\nMetaTroll classifies a user based on whether its representation (ğ‘£)\nis closer to the (average) troll or non-troll representation.\nThe campaign-specific adaptive linear classifier parameters Î©ğ‘’\nand the adapters parameters Î¨ğ‘’ are trained using MAML, just like\nstage 2 training (line 17â€“31 in Algorithm 1).\n4.4 Meta-testing\nAfter MetaTroll is trained, to adapt it to a new campaign ğ‘’ , we\nfollow the process of the third stage training. To simulate few-\nshot learning, we sample only a small number of instances for the\nsupport and query set (e.g. 5 each), and use only the support set\nfor updating the adapter (Î¨ğ‘’) and classifier parameters (Î©ğ‘’) (line\n25â€“26 in Algorithm 1) and do not run the outer loop ((line 30â€“31).\nHere the query set is used only for computing performance (i.e. in\nline 27 we compute accuracy instead of loss over the query set).\n5 EXPERIMENTS AND RESULTS\n5.1 Datasets and models\nWe use the information operations dataset published by Twitter\nfor our experiments. 4 This dataset contains different groups of\nusers banned by Twitter since October 2018 for engaging in state-\nsponsored information operations, and each group represents a\ncampaign in our work. For example, the â€œIran-2018-Palestineâ€ cam-\npaign refers to trolls sponsored by Iran for an information campaign\ntargeting Palestine in 2018.5 To clarify, these campaigns are defined\nby Twitter when they release the data, and each campaign is asso-\nciated with a blogpost that explains the information operation.\nFor each campaign, we filter users and keep only those who have\nposted a tweet within the 6-month event period (â€œEvent Timeâ€ in\nTable 1) to remove users who are inactive during the event.6 For\neach user, we also filter their tweets to keep only their most recent\n20 posts that have a timestamp within the event period.\nTo create the non-troll users, we combine two sources: (1) â€œRan-\ndomâ€, random accounts that are sampled by generating random\nnumeric user IDs and validating their existence following [2]; and\n(2) â€œHashtagâ€, users whose posts contain popular hashtags used by\na campaign, where popular hashtags are defined as hashtags that\ncollectively cover 75% of trollsâ€™ posts. The reason why we have two\ntypes of non-troll users is that if we only sample random users as\nnon-trolls, the post content of non-trolls would be topically very\ndifferent to that of the trolls, and the detection task would degener-\nate into a topic detection task. The non-troll users sampled using\nthe â€œHashtagâ€ approach is designed to circumvent this and makes\nthe detection task more challenging.\nTable 1 present some statistics for trolls and non-trolls in different\ncampaigns, where 6 are used for meta-training and 4 for meta-\ntesting. Note that the non-trolls of a particular campaign are users\nsampled with the â€œHashtagâ€ approach, and the last row corresponds\nto non-troll users sampled using the â€œRandomâ€ approach. For these\ncampaigns, at least 80% of the trollsâ€™ posts are in English, and so\nthey are used for the monolingual (English) experiments in the\npaper.7\nThe trolls and non-trolls in Table 1 represent the pool of users\nwhich we draw from to construct the final training/testing data. In\nall of our experiments, we keep the ratio of trolls to non-trolls to\n50/50 through sampling, and when sampling for non-troll users,\nthe ratio from the two sources (â€œRandomâ€ and â€œHashtagâ€) is also\n50/50.8 As an example, â€œUganda-2021-NRMâ€ has 334 troll users. We\ntherefore sample 334 non-troll users, where 167 are from â€œRandomâ€\nand another 167 from â€œHashtagâ€.\n4https://transparency.twitter.com/en/reports/information-operations.html\n5https://blog.twitter.com/en_us/topics/company/2018/enabling-further-research-of-\ninformation-operations-on-twitter\n6The event period is determined as follows: (1) the end date is the last post in the\ncampaign; and the (2) start date is 6 months from the end date.\n7For non-troll users, we only keep English tweets (based on the predicted language\ngiven in the metadata).\n8We also only sample â€œRandomâ€ users whose most recent post is in the event time.\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA Lin Tian, Xiuzhen Zhang, and Jey Han Lau\nTable 1: Statistics of English meta-train and meta-test data. The last row is non-troll users that are sampled by generating\nrandom user Twitter IDs.\nTrain/Test Campaign Event Time Type #users Top-3 Hashtags\nMeta-Train\nIran-2018-Palestine Feb 2018 â€“ Aug 2018 Troll 557 #realiran #SavePalestine\n#InternationalQudsDay2018Non-troll 1,063\nRussia-2016-MAGA Aug 2015 â€“ Feb 2016 Troll 247 #MAGA #QAnon\n#ReleaseTheMemoNon-troll 663\nIran-2018-Pakistan May 2018 â€“ Nov 2018 Troll 2,267 #pakonlinenews\n#SachTimes #DeleteIsraelNon-troll 2,500\nVenezuela-2018-Trump Jun 2018 â€“ Dec 2018 Troll 1,330 #TrumpTrain #MAGA #RTNon-troll 1,500\nNigeria-2019-Racism Aug 2019 â€“ Feb 2020 Troll 1,120 #racism\n#BlackLivesMatter #PoliceBrutalityNon-troll 1,200\nIran-2020-BLM Jul 2020 â€“ Jan 2021 Troll 205 #black_lives_matter\n#Oscars #EEUUNon-troll 212\nMeta-Test\nGRU-2020-NATO Jun 2020 â€“ Dec 2020 Troll 35 #Syria #Idib\n#StopTerrorismInSyriaNon-troll 135\nIRA-2020-Russia Jun 2020 â€“ Dec 2020 Troll 20 #valdaiclub #Russia #UkraineNon-troll 81\nUganda-2021-NRM Jul 2020 â€“ Jan 2021 Troll 334 #SecuringYourFuture\n#M7UGsChoice #StopHooligansimNon-troll 542\nChina-2021-Xinjiang Jul 2020 â€“ Jan 2021 Troll 3,440 #Xinjiang\n#XinjiangOnline #UrumqiNon-troll 2,345\nRandom Varies Non-troll 8,000 #entertainment\n#SoundCloud #Vegas\nWe compare our MetaTroll model against the following baselines\nincluding state-of-the-art meta-learning methods and few-shot text\nclassification models:\nâ€¢BERT [11]9: BERT fine-tuned using the support set of meta-\ntest data.\nâ€¢KNN [21]: ğ¾-nearest neighbour classifier with off-the-shelf\nBERT as the feature extractor.10\nâ€¢AdBERT [27]11: BERT that fine-tunes an adapter for each\ncampaign.\nâ€¢GPT3 [7]12: a very large pretrained model adapted to our\ntasks using prompt-based learning [24].13\nâ€¢MAML [14]14: BERT trained with the MAML algorithm for\nfew-shot learning.\nâ€¢CNP [16]15: a model-based meta-learning framework that\nconsists of a shared encoder, aggregator and decoder.\nâ€¢ProtoNet [33]16: a deep metric-based approach using sam-\nple average as class prototypes and the distance is calculated\nbased on euclidean-distance.\nâ€¢Induct [17]: a few-shot classification model that uses a dy-\nnamic routing algorithm to learn a class-wise representation.\n9https://huggingface.co/docs/transformers/model_doc/bert\n10ğ¾is selected from [5,10].\n11https://adapterhub.ml/\n12https://gpt3demo.com/apps/openai-gpt-3-playground\n13We use â€œtext-davinci-002â€ in our experiments. The prompts are a small set of instances\n(e.g. 5) with their labels added to the beginning of the input.\n14https://github.com/tristandeleu/pytorch-meta/tree/master/examples/maml\n15https://github.com/deepmind/neural-processes\n16https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-\nPyTorch\nâ€¢HATT [15]17: A classification model of metric-based meta-\nlearning framework together with attention mechanism.\nâ€¢DS [5]18: A few-shot text classification model that uses distri-\nbutional signatures such as word frequency and information\nentropy for training.\n5.2 Results\nWe first present English troll detection performance. In Sections\n5.4 and 5.5 we extend MetaTroll to work with non-English data\nand images. As we focus on English here, non-English posts are\ndiscarded (although this only reduces the data size by a negligible\namount, as most data is in English, as explained in Section 5.1). All\nreported figures are an average accuracy performance over 5 runs\nwith different random seeds.19\nTable 2 presents 5-shot and 10-shot results for the 4 meta-test\ncampaigns.20 MetaTroll is the best model, achieving an average of\n76.35% accuracy over all campaigns. That said, some of the few-shot\ntext classifiers (Induct e.g.73.57%) are not far behind. Most models\nonly benefit marginally by seeing 5 more examples going from 5-\nto 10-shot, with the exception of GPT3 where we see a substantial\nperformance boost (average 14.64% gain).\n5.3 Continual learning performance\nIn continual learning [29], new tasks appear over time, where the\ngoal of learning is to adapt the model accordingly to the new tasks\n17https://github.com/thunlp/HATT-Proto\n18https://github.com/YujiaBao/Distributional-Signatures\n19Noting that the performance for one run is an average performance over the query\nsets from multiple tasks.\n205-shot means only 5 labelled instances for each class are given in the support set.\nMetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters WWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nTable 2: Troll detection accuracy in 5-shot and 10-shot settings.\nGRU-2020-NATO IRA-2020-Russia Uganda-2021-NRM China-2021-Xinjiang\nModel 5-shot 10-shot 5-shot 10-shot 5-shot 10-shot 5-shot 10-shot\nBERT [11] 50.41 51.39 â†‘0.98 51.70 52.21 â†‘0.51 55.96 56.53 â†‘0.39 60.36 61.68 â†‘1.32\nKNN [21] 46.10 48.91 â†‘2.81 42.52 44.28 â†‘1.76 46.74 48.49 â†‘1.75 50.21 51.85 â†‘1.37\nAdBERT [27] 65.05 66.73 â†‘1.68 55.16 57.39 â†‘2.23 52.24 56.27 â†‘4.03 65.49 67.38 â†‘1.89\nGPT3 [7] 54.25 71.39 â†‘17.14 61.87 75.96 â†‘14.09 52.49 69.66 â†‘17.17 70.34 80.49 â†‘10.15\nMAML [14] 70.13 72.43 â†‘2.30 70.11 71.82 â†‘1.71 61.11 65.74 â†‘4.63 70.99 73.87 â†‘2.85\nCNP [16] 69.88 71.26 â†‘1.38 69.47 72.70 â†‘3.23 64.48 66.95 â†‘2.47 67.05 69.95 â†‘2.90\nProtoNet [33] 60.43 62.87 â†‘2.44 67.87 70.05 â†‘2.18 64.43 67.79 â†‘3.36 74.56 76.65 â†‘2.09\nInduct [17] 71.11 72.26 â†‘1.15 76.49 77.24â†‘0.75 71.55 73.50 â†‘1.95 75.13 76.70 â†‘1.57\nHATT [15] 63.02 65.56 â†‘2.54 75.82 77.50 â†‘1.68 60.45 63.87 â†‘3.42 78.22 80.03 â†‘1.81\nDS [5] 62.69 64.62 â†‘1.93 66.05 68.92 â†‘2.87 62.43 64.50 â†‘2.07 71.74 73.43 â†‘1.69\nMetaTroll 72.74 75.13 â†‘2.39 76.25 77.99â†‘1.74 75.05 78.25 â†‘3.20 81.37 84.50 â†‘3.13\nTable 3: Catastrophic forgetting results under continual\nlearning. â€œGâ€ = GRU-2020-NATO, â€œIâ€ = IRA-2020-Russia, â€œUâ€\n= Uganda-2021-NRM, â€œCâ€ = China-2021-Xinjiang.\nModel Gâ†’I G â†’Iâ†’U G â†’I â†’Uâ†’C\nG G G I G I U\nBERT [11] 50.41 45.16 48.02 44.80 42.85 43.25 50.00\nKNN [21] 46.10 45.25 43.12 49.99 43.01 45.50 45.33\nAdBERT [27] 65.05 62.41 54.59 52.56 50.54 53.74 49.95\nGPT3 [7] 54.25 51.92 50.33 58.88 48.93 56.87 50.06\nMAML [14] 70.13 68.32 65.15 56.55 57.62 50.04 54.87\nCNP [16] 69.88 71.55 68.72 56.75 60.57 56.95 63.21\nProtoNet [33] 60.43 56.56 61.05 61.99 53.47 52.83 60.05\nInduct [17] 71.11 69.50 62.82 66.13 58.43 63.52 64.83\nHATT [15] 63.02 60.50 55.62 70.18 50.25 50.11 55.43\nDS [5] 62.69 60.05 58.85 61.50 50.65 60.12 61.85\nMetaTroll 72.74 73.45 72.18 70.81 71.15 69.74 68.75\nTable 4: Campaign classification results under continual\nlearning.\nModel Gâ†’I G â†’Iâ†’U G â†’I â†’Uâ†’C\nI I U I U C\nGPT3 [7] 74.86 79.25 82.86 81.17 79.38 74.62\nMetaTroll 85.57 85.15 87.50 83.61 86.92 86.11\nwithout forgetting the previous tasks. This is a more realistic setting\nfor a troll detection system, as it should continually adapt to new\ncampaigns that appear over time. But in this setting it will suffer\nfrom catastrophic forgetting [36, 37], where after adapting to newer\ncampaigns its performance to classify older campaigns will degrade.\nTo simulate this continual learning setting, we next evaluate\nthe troll detection models on a past campaign after it has been\nadapted for a number of campaigns in sequence. For example, a\nsystem is first adapted to GRU-2020-NATO (G), and then to IRA-\n2020-Russia (I), Uganda-2021-NRM (U) and China-2021-Xinjiang\n(C) in sequence (denoted as Gâ†’Iâ†’Uâ†’C). We then test the system\nusing trolls using the past campaigns, i.e. G, I and U.\nOne challenge with MetaTroll under this continual learning\nevaluation is that at test time it needs to know which adapter to use\nâ€” information that most other systems do not require as they donâ€™t\nhave campaign-specific parameters (exception: AdBERT and GPT-\n321). We experiment a simple approach to solve this: have MetaTroll\nclassify a user using all its adapters, and select the outcome that\nhas the highest probability.22\nWe present (5-shot) troll classification results under this contin-\nual learning setting in Table 3. AdBERT and GPT-3 suffers little\ncatastrophic forgetting, as they have campaign-specific parameters\nor prompts (they are unaffected by continual learning as their base\nmodel is unchanged), although their performance is only marginally\nabove random chance in the first place. MetaTroll is the clear winner\nhere, with only <5% accuracy degradation over time.23 In contrast,\nthe meta-learning methods and few-shot classifiers suffer from\ncatastrophic forgetting and their performance on older campaigns\ndrops substantially (e.g. MAMLâ€™s performance for GRU-2020-NATO\ndrops from 68.32 to 65.15 and 57.62 after several updates).\nAn unintended benefit of that MetaTroll classifies trolls using\nmultiple adapters is that it is effectively doing multi-class rather\nthan binary classification (with over 85% accuracy for campaign\nclassification; Table 4). What this means is that not only MetaTroll\nis able to retain its performance for classifying trolls vs. non-trolls\nfrom different campaigns over time, it can also predict which cam-\npaign an instance belongs to â€“ an arguably more difficult task.\n5.4 Multilingual performance\nWe extend MetaTroll to multilingual. To encode multilingual input\ntext, we replace BERT with XLM-R [9].24 For comparison, we in-\nclude baselines BERT, KNN, and AdBERT, and meta-learning meth-\nods ProtoNet and MAML as their base model can be replaced with\nXLM-R. We exclude the few-shot classifiers as they are designed\nfor English and cannot be trivially adapted to other languages.\n21GPT3 technically does not have campaign-specific parameters, but it needs to be\ngiven campaign-specific prompts, and so requires the campaign label.\n22We do the same for AdBERT and GPT3.\n23Note that performance of these systems on older campaigns will still degrade slightly\nover more adaptations, as there are more campaign-specific adapters or prompts to\nselect from.\n24Specifically, we use the following library that implements adapters into XLM-R:\nhttps://docs.adapterhub.ml/classes/models/xlmroberta.html\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA Lin Tian, Xiuzhen Zhang, and Jey Han Lau\nTable 5: Statistics of Multilingual meta-test data. Languages are in ISO code.\nCampaign Event Time Language Type #users Top-3 Hashtags\nThailand-2020-RTA Aug 2019 â€“ Feb 2020 th, en Troll 158 #army #parade\n#TheRoyalThaiArmyNon-troll 542\nMexico-2021-Election Sep 2020 â€“ Mar 2021 es, en Troll 190 #Elections2021\n#Elections2021MX #PollsMXNon-troll 542\nVenezuela-2021-Gov Nov 2020 â€“ May 2021 es, en Troll 257 #Venezuela\n#ConTodoPorLaPatria #LiveNon-troll 756\nChina-2021-Changyu Feb 2019 â€“ Aug 2019 fr,en Troll 280 #MBR #MorningBox\n#StopXinjiangRumorsNon-troll 542\nRandom Varies es, fr, th, en Non-troll 5,000 #news\n#COVID #Daily\nTable 6: Multilingual results. â€œGâ€ = GRU-2020-NATO, â€œIâ€\n= IRA-2020-Russia, â€œUâ€ = Uganda-2021-NRM, â€œCâ€ = China-\n2021-Xinjiang, â€œTâ€ = Thailand-2020-RTA, â€œMâ€ = Mexico-\n2021-Election, â€œVâ€ = Venezuela-2021-Gov,â€œYâ€= China-2021-\nChangyu\n.\nModel G I U C T M V Y\nBERT [9] 51.83 48.69 53.21 55.56 53.54 54.98 54.27 52.82\nKNN [21] 47.38 42.50 44.21 48.29 56.36 51.12 55.63 50.19\nAdBERT [27] 58.38 56.29 54.79 66.65 62.71 56.20 58.41 55.63\nProtoNet [33] 57.78 64.47 60.40 70.52 63.68 59.56 62.71 58.96\nMAML [14] 67.15 65.58 55.32 69.68 65.32 57.68 60.00 51.36\nMetaTroll 69.63 70.52 73.72 73.20 68.14 64.82 67.16 62.53\nTable 7: Multilingual and multimodal results. â€œ+Râ€ =\nResNet18, â€œ+Oâ€ = OCR, â€œ+R+Oâ€ = â€œ+ResNet18+OCRâ€.\nVariants G I U C T M V Y\n-image 69.63 70.52 73.72 73.20 68.14 64.82 67.16 62.53\n+image# 70.81 71.03 74.02 73.97 68.89 65.11 67.94 63.07\n+R 71.15 72.81 75.50 74.38 72.25 67.50 68.55 65.74\n+O 72.10 74.55 75.95 75.59 71.50 69.54 72.07 71.45\n+R+O 73.22 73.08 76.17 73.04 76.62 70.83 71.95 72.77\nIn terms of data, we expand the meta-test campaigns by adding\nfour new campaigns (Thailand-2020-RTA, Mexico-2021-Election,\nVenezuela-2021-Gov, and China-2021-Changyu) where the predomi-\nnant language is not in English and present their statistics in Table 5.\nFor the 10 English campaigns (Table 1), we restore the previously\ndiscarded non-English posts and include them for meta-training\nand meta-testing.\nResults are presented in Table 6. Generally we see that all modelsâ€™\nperformance has somewhat degraded when their feature extractor\nis replaced with a multilingual model, although MetaTroll manages\nto keep its accuracy around 60%. Interestingly, China-2021-Changyu\nappears to be the most difficult campaign, and we suspect it may\nbe due to its diverse set of languages (38% French, 12.3% English,\n12.1% Simplified Chinese).\n5.5 Multimodal performance\nNext we consider incorporating images posted by users, as image is\nan effective communication device (e.g. memes). Note that we only\npresent results for different variants of MetaTroll here, as we have\ndemonstrated that it is the most competitive detection system.\nTo process images, we use pre-trained ResNet18 [18] as an off-\nthe-shelf tool to extract image embeddings. We also explore using\na multilingual OCR model to extract text information from images\n(which will be useful for processing memes).25 As we have multiple\nimages for each user, we aggregate the ResNet18 image embeddings\nvia max-pooling, and concatenate the max-pooled vector with the\ntext representation (ğ‘£ in Equation 3). For texts that are extracted\nby OCR, we concatenate them into a long string and process them\nwith another AdapterBERT (Equation 3; their parameters are not\nshared), and similarly concatenate the final CLS representation to\nthe text representation.\nResults are in Table 7. â€œ+image#â€ is a baseline where we concate-\nnate a numeric feature that denotes the number of images posted\nby the user to the text representation. Interestingly, even with the\nbaseline approach we see a small improvement, indicating that\ntrolls use more images (e.g. average number of images used by\ntrolls is 20 vs. 5 for non-trolls in GRU-2020-NATO). Incorporating\neither ResNet or OCR encodings boosts performance further (with\nOCR being marginally more beneficial), and that adding them both\nproduces the best performance.\n6 CONCLUSION\nWe propose MetaTroll, a few-shot troll detection model with campaign-\nspecific adapters that tackles catastrophic forgetting in a continual\nlearning setting. Experimental results show that MetaTroll out-\nperforms existing state-of-the-art meta-learning and few-shot text\nclassification models, and it can be extended to handle multilingual\nand multimodal input.\nACKNOWLEDGEMENTS\nThis research is supported in part by the Australian Research Coun-\ncil Discovery Project DP200101441. Lin Tian is supported by the\nRMIT University Vice-Chancellor PhD Scholarship (VCPS).\n25https://github.com/JaidedAI/EasyOCR\nMetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters WWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nREFERENCES\n[1] Aseel Addawood, Adam Badawy, Kristina Lerman, and Emilio Ferrara. 2019.\nLinguistic cues to deception: Identifying political trolls on social media. In Pro-\nceedings of the international AAAI conference on web and social media , Vol. 13.\n15â€“25.\n[2] Meysam Alizadeh, Jacob N Shapiro, Cody Buntain, and Joshua A Tucker. 2020.\nContent-based features predict social media influence operations. Science ad-\nvances 6, 30 (2020), eabb5824.\n[3] Atanas Atanasov, Gianmarco De Francisci Morales, and Preslav Nakov. 2019.\nPredicting the Role of Political Trolls in Social Media. In Proceedings of the 23rd\nConference on Computational Natural Language Learning (CoNLL) . 1023â€“1034.\n[4] Adam Badawy, Kristina Lerman, and Emilio Ferrara. 2019. Who falls for online\npolitical manipulation?. In Companion Proceedings of The 2019 World Wide Web\nConference. 162â€“168.\n[5] Yujia Bao, Menghua Wu, Shiyu Chang, and Regina Barzilay. 2020. Few-shot Text\nClassification with Distributional Signatures. In ICLR.\n[6] David A Broniatowski, Amelia M Jamison, SiHua Qi, Lulwah AlKulaib, Tao\nChen, Adrian Benton, Sandra C Quinn, and Mark Dredze. 2018. Weaponized\nhealth communication: Twitter bots and Russian trolls amplify the vaccine debate.\nAmerican journal of public health 108, 10 (2018), 1378â€“1384.\n[7] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877â€“1901.\n[8] Justin Cheng, Cristian Danescu-Niculescu-Mizil, and Jure Leskovec. 2015. Antiso-\ncial behavior in online discussion communities. InProceedings of the international\naaai conference on web and social media , Vol. 9. 61â€“70.\n[9] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guil-\nlaume Wenzek, Francisco GuzmÃ¡n, Ã‰douard Grave, Myle Ott, Luke Zettlemoyer,\nand Veselin Stoyanov. 2020. Unsupervised Cross-lingual Representation Learn-\ning at Scale. In Proceedings of the 58th Annual Meeting of the Association for\nComputational Linguistics . 8440â€“8451.\n[10] Jorge De-La-PeÃ±a-Sordo, Igor Santos, Iker Pastor-LÃ³pez, and Pablo G Bringas.\n2013. Filtering trolling comments through collective classification. InInternational\nConference on Network and System Security . Springer, 707â€“713.\n[11] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding.arXiv\npreprint arXiv:1810.04805 (2018).\n[12] Imen Ouled Dlala, Dorra Attiaoui, Arnaud Martin, and Boutheina Ben Yaghlane.\n2014. Trolls identification within an uncertain framework. In 2014 IEEE 26th\nInternational Conference on Tools with Artificial Intelligence . IEEE, 1011â€“1015.\n[13] Ritam Dutt, Ashok Deb, and Emilio Ferrara. 2018. â€œSenator, We Sell Adsâ€: Analysis\nof the 2016 Russian Facebook Ads Campaign. In International conference on\nintelligent information technologies . Springer, 151â€“168.\n[14] Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-\nlearning for fast adaptation of deep networks. In International conference on\nmachine learning . PMLR, 1126â€“1135.\n[15] Tianyu Gao, Xu Han, Zhiyuan Liu, and Maosong Sun. 2019. Hybrid attention-\nbased prototypical networks for noisy few-shot relation classification. InProceed-\nings of the AAAI Conference on Artificial Intelligence , Vol. 33. 6407â€“6414.\n[16] Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David\nSaxton, Murray Shanahan, Yee Whye Teh, Danilo Rezende, and SM Ali Eslami.\n2018. Conditional neural processes. In International Conference on Machine\nLearning. PMLR, 1704â€“1713.\n[17] Ruiying Geng, Binhua Li, Yongbin Li, Xiaodan Zhu, Ping Jian, and Jian Sun. 2019.\nInduction Networks for Few-Shot Text Classification. In Proceedings of the 2019\nConference on Empirical Methods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language Processing (EMNLP-IJCNLP) .\n3904â€“3913.\n[18] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual\nlearning for image recognition. In Proceedings of the IEEE conference on computer\nvision and pattern recognition . 770â€“778.\n[19] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin\nDe Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019.\nParameter-efficient transfer learning for NLP. In International Conference on\nMachine Learning . PMLR, 2790â€“2799.\n[20] Jane Im, Eshwar Chandrasekharan, Jackson Sargent, Paige Lighthammer, Taylor\nDenby, Ankit Bhargava, Libby Hemphill, David Jurgens, and Eric Gilbert. 2020.\nStill out there: Modeling and identifying russian troll accounts on twitter. In12th\nACM Conference on Web Science . 1â€“10.\n[21] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike\nLewis. 2020. Generalization through Memorization: Nearest Neighbor Language\nModels. In International Conference on Learning Representations .\n[22] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\nmization. arXiv preprint arXiv:1412.6980 (2014).\n[23] Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. 2017. Meta-sgd: Learning to\nlearn quickly for few-shot learning. arXiv preprint arXiv:1707.09835 (2017).\n[24] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Gra-\nham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of prompt-\ning methods in natural language processing. arXiv preprint arXiv:2107.13586\n(2021).\n[25] Todor Mihaylov, Ivan Koychev, Georgi Georgiev, and Preslav Nakov. 2015. Ex-\nposing Paid Opinion Manipulation Trolls. In Proceedings of the International\nConference Recent Advances in Natural Language Processing . 443â€“450.\n[26] Tsendsuren Munkhdalai and Hong Yu. 2017. Meta networks. In International\nConference on Machine Learning . PMLR, 2554â€“2563.\n[27] Jonas Pfeiffer, Andreas RÃ¼cklÃ©, Clifton Poth, Aishwarya Kamath, Ivan VuliÄ‡,\nSebastian Ruder, Kyunghyun Cho, and Iryna Gurevych. 2020. AdapterHub: A\nFramework for Adapting Transformers. In Proceedings of the 2020 Conference\non Empirical Methods in Natural Language Processing: System Demonstrations .\n46â€“54.\n[28] James Requeima, Jonathan Gordon, John Bronskill, Sebastian Nowozin, and\nRichard E Turner. 2019. Fast and flexible multi-task classification using con-\nditional neural adaptive processes. Advances in Neural Information Processing\nSystems 32 (2019).\n[29] Mark B Ring. 1998. CHILD: A first step towards continual learning. In Learning\nto learn . Springer, 261â€“292.\n[30] Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy\nLillicrap. 2016. Meta-learning with memory-augmented neural networks. In\nInternational conference on machine learning . PMLR, 1842â€“1850.\n[31] Chun Wei Seah, Hai Leong Chieu, Kian Ming A Chai, Loo-Nin Teow, and Lee Wei\nYeong. 2015. Troll detection by domain-adapting sentiment analysis. In 2015 18th\nInternational Conference on Information Fusion (Fusion) . IEEE, 792â€“799.\n[32] Hossein Shafiei and Aresh Dadlani. 2022. Detection of fickle trolls in large-scale\nonline social networks. Journal of big Data 9, 1 (2022), 1â€“21.\n[33] Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical networks for\nfew-shot learning. Advances in neural information processing systems 30 (2017).\n[34] James Stewart and Maurice Dawson. 2018. How the modification of personality\ntraits leave one vulnerable to manipulation in social engineering. International\nJournal of Information Privacy, Security and Integrity 3, 3 (2018), 187â€“208.\n[35] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al . 2016.\nMatching networks for one shot learning. Advances in neural information pro-\ncessing systems 29 (2016).\n[36] Y. Xu, X. Zhong, A. Jimeno-Yepes, and J.H. Lau. 2020. Forget Me Not: Reducing\nCatastrophic Forgetting for Domain Adaptation in Reading Comprehension.\nIn Proceedings of the 2020 International Joint Conference on Neural Networks\n(IJCNN2020). Glasgow, UK, 1â€“8.\n[37] Pauching Yap, Hippolyt Ritter, and David Barber. 2021. Addressing catastrophic\nforgetting in few-shot problems. In International Conference on Machine Learning .\nPMLR, 11909â€“11919.\n[38] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald\nTesauro, Haoyu Wang, and Bowen Zhou. 2018. Diverse Few-Shot Text Clas-\nsification with Multiple Metrics. In Proceedings of the 2018 Conference of the\nNorth American Chapter of the Association for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long Papers) . 1206â€“1215.\n[39] Savvas Zannettou, Tristan Caulfield, Emiliano De Cristofaro, Michael Sirivianos,\nGianluca Stringhini, and Jeremy Blackburn. 2019. Disinformation warfare: Un-\nderstanding state-sponsored trolls on Twitter and their influence on the web. In\nCompanion proceedings of the 2019 world wide web conference . 218â€“226.\n[40] Yini Zhang, Josephine Lukito, Min-Hsin Su, Jiyoun Suk, Yiping Xia, Sang Jung\nKim, Larissa Doroshenko, and Chris Wells. 2021. Assembling the networks and\naudiences of disinformation: How successful Russian IRA Twitter accounts built\ntheir followings, 2015â€“2017. Journal of Communication 71, 2 (2021), 305â€“331.\nWWW â€™23, May 1â€“5, 2023, Austin, TX, USA Lin Tian, Xiuzhen Zhang, and Jey Han Lau\nA IMPLEMENTATION DETAILS\nWe implement our models in PyTorch using the HuggingFace li-\nbrary26 and their pretrained BERT27 and XML-R28. The adapter-\nbased models are from AdapterHub29.\nTo handle images, we use ResNet18 30 and EasyOCR 31.\nWe set maximum token length = 320 and dropout rate = 0.2 for\nBERT embedding and dropout rate = 0.1 for meta-learning process.\nLearning rate is tuned in the range between [1ğ‘’âˆ’5,5ğ‘’âˆ’5]for BERT\nin the first stage. Learning rate warmup is set up 10% of steps. The\nlearning rate ğ›½for MAML outer loop is1ğ‘’âˆ’5. In the first stage, BERT\nuses the Adam optimiser [22]. Search space for learning rateğ›¾and ğ›¿\nis from [1ğ‘’âˆ’4,1ğ‘’âˆ’5,2ğ‘’âˆ’5,3ğ‘’âˆ’5,4ğ‘’âˆ’5,5ğ‘’âˆ’5]. The outer loop learning\nrate for the third stage ğ›¿ is set as 1ğ‘’âˆ’5. The inner loop learning\nrate ğ›¾ for BERT-based models is set as 2ğ‘’âˆ’5 and for XLM-R-based\nmodels is set as5ğ‘’âˆ’5. We experimented with the number of training\ntasks in the range of 60,000 to 100,000, with 80,000 tasks generally\nyielding the best results. Our experiments are running using A100\nGPU with 40GB Memory.\nB ABLATION STUDY\nWe conduct ablation study to justify the importance of our three\nstages training processes. By removing the adaptive classifier, we\nattach a standard linear layer for the final classification. For â€œs1+s2â€,\nwe attach a standard linear layer for the final classification with\nremoving the adaptive classifier. â€œs2+s3â€ is initialise the BERT text\nencoder without pre-training on any troll data. â€œs1+s3â€ drops the\nmeta-trained task-specific adapter. We still allocate one adapter to\neach task with randomly initialised adaptor. We report the average\naccuracy on four English meta-testing campaigns of different model\nvariants in Table 8. Results show that our model, the combination\nof all three training stages achieves the best average accuracy of\n76.35%. Without pretraining the base text encoder, the framework\nperforms the worst, resulting in 3.04% drops on average accuracy.\nTable 8: Ablation results.\nVariants G I U C\ns1 + s2 71.35 75.02 72.47 80.03\nS1 + s3 72.43 74.81 72.25 79.55\ns2 + s3 71.25 75.19 73.50 78.33\nMetaTroll 72.74 76.25 75.05 81.37\nC DATASET DETAILS\nWe further include a detailed statistics of our Twitter troll data with\ndetailed topic for each campaign and online post link attached.\n26https://github.com/huggingface\n27https://huggingface.co/bert-base-cased\n28https://huggingface.co/xlm-roberta-base\n29urlhttps://github.com/adapter-hub/adapter-transformers\n30https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.h\ntml\n31https://github.com/JaidedAI/EasyOCR\nMetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer Adapters WWW â€™23, May 1â€“5, 2023, Austin, TX, USA\nTable 9: Statistics of Twitter data for troll and non-troll accounts. Languages are in ISO code.\nCampaign Topic Event Time Language #posts\nIran-2018-Palestine information campaigns potentially originated in Iran, dating back to 2009 [link] Feb 2018 â€“ Aug 2018 en,fr 276,495\nRussia-2016-MAGA behavior mimics the activity of prior accounts tied to the IRA [link] Aug 2015 â€“ Feb 2016 en 920,761\nIran-2018-Pakistan possible malicious activity with an attempted influence campaign identified as potentially\nlocated within Iran [link]\nMay 2018 â€“ Nov 2018 en 4,671,959\nVenezuela-2018-Trump were initial indications that these accounts were associated with the Russian IRA, further\nanalysis suggests that they were operated by a commercial entity originating in Venezuela\n[link]\nJun 2018 â€“ Dec 2018 en 569,453\nNigeria-2019-Racism operating out of Ghana and Nigeria and which we can reliably associate with Russia,\nattempted to sow discord by engaging in conversations about social issues, like race and\ncivil rights [link]\nAug 2019 â€“ Feb 2020 en 39,964\nThanliand-2020-RTA a network of accounts partaking in information operations that we can reliably link to\nthe Royal Thai Army (RTA). These accounts were engaging in amplifying pro-RTA and\npro-government content, as well as engaging in behavior targeting prominent political\nopposition figures [link]\nAug 2019 â€“ Feb 2020 th,en 21,385\nIran-2020-BLM artificially amplified conversations on politically sensitive topics, including Black Lives\nMatter (BLM), the murder of George Floyd, and other issues of racial and social justice in\nthe United States [link]\nJul 2020 â€“ Jan 2021 en 2,450\nIRA-2020-Russia accounts amplified narratives that had been previously associated with the IRA and other\nRussian influence efforts targeting the United States and European Union [link]\nJun 2020 â€“ Dec 2020 en 68,914\nGRU-2020-NATO accounts amplified narratives that were aligned with the Russian government, while other\nsubset of the network focused on undermining faith in the NATO alliance and its stability\n[link]\nJun 2020 â€“ Dec 2020 en 26,684\nMexico-2021-Election shared primarily civic content, in support of government initiatives related to public health\nand political parties.[link]\nSep 2020 â€“ Mar 2021 es,en 19,277\nVenezuela-2021-Gov amplified accounts, hashtags, and topics in support of the government and its official\nnarratives [link]\nNov 2020 â€“ May 2021 es,en 860,060\nUganda-2021-NRM engaged in coordinated inauthentic activity in support of Ugandan presidential incumbent\nMuseveni and his party, National Resistance Movement (NRM) [link]\nJul 2020 â€“ Jan 2021 en 524,081\nChina-2021-Xinjiang amplified Chinese Communist Party narratives related to the treatment of the Uyghur\npopulation in Xinjiang [link]\nJul 2020 â€“ Jan 2021 en, zh-cn 31,269\nChina-2021-Changyu â€œChangyu Cultureâ€ a private company backed by the Xinjiang regional government [link] Feb 2019 â€“ Aug 2019 fr, en 35,924"
}