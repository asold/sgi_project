{
  "title": "Show Some Love to Your n-grams: A Bit of Progress and Stronger n-gram Language Modeling Baselines",
  "url": "https://openalex.org/W2946595319",
  "year": 2019,
  "authors": [
    {
      "id": "https://openalex.org/A108414181",
      "name": "Ehsan Shareghi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2515171796",
      "name": "Daniela Gerz",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1969142033",
      "name": "Ivan VuliÄ‡",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1927037681",
      "name": "Anna Korhonen",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2057147815",
    "https://openalex.org/W2885142640",
    "https://openalex.org/W2609370997",
    "https://openalex.org/W3153005841",
    "https://openalex.org/W2890225082",
    "https://openalex.org/W2963766645",
    "https://openalex.org/W2741986357",
    "https://openalex.org/W2963932686",
    "https://openalex.org/W2971415639",
    "https://openalex.org/W1934041838",
    "https://openalex.org/W2189576523",
    "https://openalex.org/W2896871415",
    "https://openalex.org/W2963824800",
    "https://openalex.org/W2963899393",
    "https://openalex.org/W1632114991",
    "https://openalex.org/W2803431233",
    "https://openalex.org/W2898766142",
    "https://openalex.org/W2741281060",
    "https://openalex.org/W22168010",
    "https://openalex.org/W2963537482",
    "https://openalex.org/W2963748792",
    "https://openalex.org/W2952754453",
    "https://openalex.org/W2951559648",
    "https://openalex.org/W179875071",
    "https://openalex.org/W1938755728",
    "https://openalex.org/W4300427683",
    "https://openalex.org/W2087309226",
    "https://openalex.org/W2005902041",
    "https://openalex.org/W2803214681",
    "https://openalex.org/W2804385163",
    "https://openalex.org/W2567188764",
    "https://openalex.org/W1591801644",
    "https://openalex.org/W2158195707",
    "https://openalex.org/W2883158411",
    "https://openalex.org/W2259472270"
  ],
  "abstract": "In recent years neural language models (LMs) have set state-of-the-art performance for several benchmarking datasets. While the reasons for their success and their computational demand are well-documented, a comparison between neural models and more recent developments in n-gram models is neglected. In this paper, we examine the recent progress in n-gram literature, running experiments on 50 languages covering all morphological language families. Experimental results illustrate that a simple extension of Modified Kneser-Ney outperforms an LSTM language model on 42 languages while a word-level Bayesian n-gram LM outperforms the character-aware neural model on average across all languages, and its extension which explicitly injects linguistic knowledge on 8 languages. Further experiments on larger Europarl datasets for 3 languages indicate that neural architectures are able to outperform computationally much cheaper n-gram models: n-gram training is up to 15,000 times quicker. Our experiments illustrate that standalone n-gram models lend themselves as natural choices for resource-lean or morphologically rich languages, while the recent progress has significantly improved their accuracy.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.5716717839241028
    },
    {
      "name": "Computational linguistics",
      "score": 0.5597953796386719
    },
    {
      "name": "Gram",
      "score": 0.47453200817108154
    },
    {
      "name": "Language model",
      "score": 0.471480131149292
    },
    {
      "name": "Linguistics",
      "score": 0.4618223309516907
    },
    {
      "name": "Volume (thermodynamics)",
      "score": 0.4555245339870453
    },
    {
      "name": "Natural language processing",
      "score": 0.3661881387233734
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3233126997947693
    },
    {
      "name": "Arithmetic",
      "score": 0.3202511668205261
    },
    {
      "name": "Mathematics",
      "score": 0.23221251368522644
    },
    {
      "name": "Philosophy",
      "score": 0.12320306897163391
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Genetics",
      "score": 0.0
    },
    {
      "name": "Bacteria",
      "score": 0.0
    }
  ]
}