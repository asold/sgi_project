{
  "title": "Performance analysis of large language models in the domain of legal argument mining",
  "url": "https://openalex.org/W4388796972",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A3020901843",
      "name": "Abdullah Al Zubaer",
      "affiliations": [
        "University of Passau"
      ]
    },
    {
      "id": "https://openalex.org/A2789226822",
      "name": "Michael Granitzer",
      "affiliations": [
        "University of Passau"
      ]
    },
    {
      "id": "https://openalex.org/A2092795848",
      "name": "Jelena Mitrović",
      "affiliations": [
        "University of Passau"
      ]
    },
    {
      "id": "https://openalex.org/A3020901843",
      "name": "Abdullah Al Zubaer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2789226822",
      "name": "Michael Granitzer",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2092795848",
      "name": "Jelena Mitrović",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W4313572588",
    "https://openalex.org/W3015468748",
    "https://openalex.org/W2019842155",
    "https://openalex.org/W6691476020",
    "https://openalex.org/W4386504863",
    "https://openalex.org/W6778883912",
    "https://openalex.org/W2962854673",
    "https://openalex.org/W3099950029",
    "https://openalex.org/W4383605161",
    "https://openalex.org/W3177813494",
    "https://openalex.org/W4224308101",
    "https://openalex.org/W6739585900",
    "https://openalex.org/W6755207826",
    "https://openalex.org/W6785665037",
    "https://openalex.org/W4212926655",
    "https://openalex.org/W6841514217",
    "https://openalex.org/W4377864715",
    "https://openalex.org/W4377140494",
    "https://openalex.org/W6737402491",
    "https://openalex.org/W4323655724",
    "https://openalex.org/W4321854770",
    "https://openalex.org/W4366341216",
    "https://openalex.org/W2912924812",
    "https://openalex.org/W2979666134",
    "https://openalex.org/W4282586470",
    "https://openalex.org/W2327805699",
    "https://openalex.org/W4385988359",
    "https://openalex.org/W3122241445",
    "https://openalex.org/W3185341429",
    "https://openalex.org/W6766673545",
    "https://openalex.org/W3174167596",
    "https://openalex.org/W4366420437",
    "https://openalex.org/W6794800773",
    "https://openalex.org/W6676984168",
    "https://openalex.org/W2954257417",
    "https://openalex.org/W2912804155",
    "https://openalex.org/W6631982911",
    "https://openalex.org/W6644593340",
    "https://openalex.org/W4381855801",
    "https://openalex.org/W1964940342",
    "https://openalex.org/W4226278401",
    "https://openalex.org/W3098495697",
    "https://openalex.org/W6788622633",
    "https://openalex.org/W4304192721",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4382319715",
    "https://openalex.org/W4322718417",
    "https://openalex.org/W6691459498",
    "https://openalex.org/W6636688132",
    "https://openalex.org/W4327810667",
    "https://openalex.org/W6849941170",
    "https://openalex.org/W6854866820",
    "https://openalex.org/W4310829037",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4311726128",
    "https://openalex.org/W2923014074",
    "https://openalex.org/W4321649710",
    "https://openalex.org/W4311978971",
    "https://openalex.org/W4322760437",
    "https://openalex.org/W4311253308",
    "https://openalex.org/W6775180354",
    "https://openalex.org/W6839974392",
    "https://openalex.org/W4386520758",
    "https://openalex.org/W4379087156",
    "https://openalex.org/W6791446462",
    "https://openalex.org/W4362515116",
    "https://openalex.org/W3008374555",
    "https://openalex.org/W4377130677",
    "https://openalex.org/W2963748441",
    "https://openalex.org/W4320005767",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2251939518",
    "https://openalex.org/W2242464395",
    "https://openalex.org/W4404782964",
    "https://openalex.org/W3010600502",
    "https://openalex.org/W4320009668",
    "https://openalex.org/W4287779512",
    "https://openalex.org/W4322718191",
    "https://openalex.org/W2217783255",
    "https://openalex.org/W1490960179",
    "https://openalex.org/W3106882134",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4230329770",
    "https://openalex.org/W2612690371",
    "https://openalex.org/W3011655242",
    "https://openalex.org/W2597601064",
    "https://openalex.org/W1977155386",
    "https://openalex.org/W4392773006",
    "https://openalex.org/W3172943453",
    "https://openalex.org/W4381802325",
    "https://openalex.org/W4312107248",
    "https://openalex.org/W2113459411",
    "https://openalex.org/W2606964149",
    "https://openalex.org/W4360836968",
    "https://openalex.org/W4313564799",
    "https://openalex.org/W4221143046",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W4392477373",
    "https://openalex.org/W4321392130",
    "https://openalex.org/W4212774754",
    "https://openalex.org/W1534656862",
    "https://openalex.org/W1516184288"
  ],
  "abstract": "Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9% and 12% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6866934895515442
    },
    {
      "name": "Transformer",
      "score": 0.5740441083908081
    },
    {
      "name": "Classifier (UML)",
      "score": 0.565257728099823
    },
    {
      "name": "Natural language understanding",
      "score": 0.5279749035835266
    },
    {
      "name": "Sentence",
      "score": 0.5162032246589661
    },
    {
      "name": "Artificial intelligence",
      "score": 0.49960756301879883
    },
    {
      "name": "Embedding",
      "score": 0.4901891350746155
    },
    {
      "name": "Machine learning",
      "score": 0.4741230309009552
    },
    {
      "name": "Argument (complex analysis)",
      "score": 0.4684942662715912
    },
    {
      "name": "Language model",
      "score": 0.4153103232383728
    },
    {
      "name": "Natural language processing",
      "score": 0.4001927375793457
    },
    {
      "name": "Natural language",
      "score": 0.3222612142562866
    },
    {
      "name": "Engineering",
      "score": 0.1023612916469574
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    },
    {
      "name": "Electrical engineering",
      "score": 0.0
    }
  ]
}