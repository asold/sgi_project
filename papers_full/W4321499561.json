{
  "title": "The Utility of ChatGPT as an Example of Large Language Models in Healthcare Education, Research and Practice: Systematic Review on the Future Perspectives and Potential Limitations",
  "url": "https://openalex.org/W4321499561",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2568280950",
      "name": "Malik Sallam",
      "affiliations": [
        "Jordan Hospital",
        "University of Jordan"
      ]
    },
    {
      "id": "https://openalex.org/A2568280950",
      "name": "Malik Sallam",
      "affiliations": [
        "Jordan Hospital",
        "University of Jordan"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4225716729",
    "https://openalex.org/W3147517805",
    "https://openalex.org/W1901616594",
    "https://openalex.org/W4292779060",
    "https://openalex.org/W2773965434",
    "https://openalex.org/W2969715170",
    "https://openalex.org/W3049028910",
    "https://openalex.org/W4315797044",
    "https://openalex.org/W2889032597",
    "https://openalex.org/W4310917376",
    "https://openalex.org/W4319332853",
    "https://openalex.org/W4315874291",
    "https://openalex.org/W4320893927",
    "https://openalex.org/W3088017652",
    "https://openalex.org/W4205164650",
    "https://openalex.org/W2981296841",
    "https://openalex.org/W4294215472",
    "https://openalex.org/W4319312380",
    "https://openalex.org/W4320342216",
    "https://openalex.org/W4319653860",
    "https://openalex.org/W4319594283",
    "https://openalex.org/W4320895630",
    "https://openalex.org/W4318931874",
    "https://openalex.org/W4318263917",
    "https://openalex.org/W4318925155",
    "https://openalex.org/W4317390716",
    "https://openalex.org/W4318678021",
    "https://openalex.org/W4319083882",
    "https://openalex.org/W4320495408",
    "https://openalex.org/W4315498228",
    "https://openalex.org/W4313294616",
    "https://openalex.org/W4319301446",
    "https://openalex.org/W4319731909",
    "https://openalex.org/W4317853296",
    "https://openalex.org/W4319444452",
    "https://openalex.org/W4319227726",
    "https://openalex.org/W4319334927",
    "https://openalex.org/W4319304408",
    "https://openalex.org/W4317376696",
    "https://openalex.org/W4319777976",
    "https://openalex.org/W4319454867",
    "https://openalex.org/W4318591734",
    "https://openalex.org/W4319460381",
    "https://openalex.org/W4319301505",
    "https://openalex.org/W4315477395",
    "https://openalex.org/W4319341091",
    "https://openalex.org/W4317910576",
    "https://openalex.org/W4319985830",
    "https://openalex.org/W4320085275",
    "https://openalex.org/W4319656339",
    "https://openalex.org/W4313262066",
    "https://openalex.org/W4313453502",
    "https://openalex.org/W4320709689",
    "https://openalex.org/W4319457949",
    "https://openalex.org/W4318389352",
    "https://openalex.org/W4316671929",
    "https://openalex.org/W4319455199",
    "https://openalex.org/W4320342636",
    "https://openalex.org/W4319868628",
    "https://openalex.org/W6904005840",
    "https://openalex.org/W4313447794",
    "https://openalex.org/W4319663047",
    "https://openalex.org/W4319350602",
    "https://openalex.org/W4319460874",
    "https://openalex.org/W4320014806",
    "https://openalex.org/W4318592207",
    "https://openalex.org/W4312083290",
    "https://openalex.org/W4319662928",
    "https://openalex.org/W4319239832",
    "https://openalex.org/W4318069287",
    "https://openalex.org/W4317435136",
    "https://openalex.org/W4318829849",
    "https://openalex.org/W4319301633",
    "https://openalex.org/W4404519374",
    "https://openalex.org/W4320486331",
    "https://openalex.org/W2012950673",
    "https://openalex.org/W3006014645",
    "https://openalex.org/W2256474644",
    "https://openalex.org/W4312226936"
  ],
  "abstract": "Abstract An artificial intelligence (AI)-based conversational large language model (LLM) was launched in November 2022 namely, “ChatGPT”. Despite the wide array of potential applications of LLMs in healthcare education, research and practice, several valid concerns were raised. The current systematic review aimed to investigate the possible utility of ChatGPT and to highlight its limitations in healthcare education, research and practice. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar under the term “ChatGPT”. Eligibility criteria included the published research or preprints of any type that discussed ChatGPT in the context of healthcare education, research and practice. A total of 280 records were identified, and following full screening, a total of 60 records were eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records with the most common being the utility in scientific writing followed by benefits in healthcare research (efficient analysis of massive datasets, code generation and rapid concise literature reviews besides utility in drug discovery and development). Benefits in healthcare practice included cost saving, documentation, personalized medicine and improved health literacy. Concerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most common being the ethical issues including the risk of bias, plagiarism, copyright issues, transparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and inaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm shifts in healthcare education, research and practice, the embrace of this application should be done with extreme caution. Specific applications of ChatGPT in health education include the promising utility in personalized learning tools and shift towards more focus on critical thinking and problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining the workflow and refining personalized medicine. Saving time for the focus on experimental design and enhancing research equity and versatility are the benefits in scientific research. Regarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be listed as an author unless the ICMJE/COPE guidelines are revised and amended. An initiative involving all stakeholders involved in healthcare education, research and practice is urgently needed to set a code of ethics and conduct on the responsible practices involving ChatGPT among other LLMs.",
  "full_text": "1 \nThe Utility of ChatGPT as an Example of Large Language Models in \nHealthcare Education, Research and Practice: Systematic Review on the \nFuture Perspectives and Potential Limitations \nAuthor \nMalik Sallam 1,2,* \nAffiliations \n1Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, The \nUniversity of Jordan, Amman 11942, Jordan \n2Department of Clinical Laboratories and Forensic Medicine, Jordan University Hospital, \nAmman 11942, Jordan \n*Correspondence: Malik Sallam, MD, PhD. malik.sallam@ju.edu.jo; Tel.: +962-79-184-5186 \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \nNOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.\n2 \nAbstract \nAn artificial intelligence (AI)-based conversational large language model (LLM) was launched in \nNovember 2022 namely, “ChatGPT”. Despite the wide array of potential applications of LLMs in \nhealthcare education, research and practice, several valid concerns were raised. The current \nsystematic review aimed to investigate the possible utility of ChatGPT and to highlight its \nlimitations in healthcare education, research and practice. Using the PRIMSA guidelines, a \nsystematic search was conducted to retrieve English records in PubMed/MEDLINE and Google \nScholar under the term “ChatGPT”. Eligibility criteria included the published research or \npreprints of any type that discussed ChatGPT in the context of healthcare education, research and \npractice. A total of 280 records were identified, and following full screening, a total of 60 records \nwere eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records \nwith the most common being the utility in scientific writing followed by benefits in healthcare \nresearch (efficient analysis of massive datasets, code generation and rapid concise literature \nreviews besides utility in drug discovery and development). Benefits in healthcare practice \nincluded cost saving, documentation, personalized medicine and improved health literacy. \nConcerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most \ncommon being the ethical issues including the risk of bias, plagiarism, copyright issues, \ntransparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and \ninaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm \nshifts in healthcare education, research and practice, the embrace of this application should be \ndone with extreme caution. Specific applications of ChatGPT in health education include the \npromising utility in personalized learning tools and shift towards more focus on critical thinking \nand problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining \nthe workflow and refining personalized medicine. Saving time for the focus on experimental \ndesign and enhancing research equity and versatility are the benefits in scientific research. \nRegarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be \nlisted as an author unless the IC MJE/COPE guidelines are revised and amended. An initiative \ninvolving all stakeholders involved in healthcare education, research and practice is urgently \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n3 \nneeded to set a code of ethics and conduct on the responsible practices involving ChatGPT among \nother LLMs. \nKeywords: machine learning; digital health; artificial intelligence; healthcare; ethics \n \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n4 \n1. Introduction \nArtificial intelligence (AI) can be defined as the multidisciplinary approach of computer science \nand linguistics that aspires to create machines capable of performing tasks that normally require \nhuman intelligence [1]. These tasks include the ability to learn, adapt, rationalize, understand and \nto fathom abstract concepts, as well as the reactivity to complex human attributes such as \nattention, emotion, creativity, etc. [2]. \nThe history of AI as a scientific discipline can be traced back to the mid -XX century at the \nDartmouth Summer Research Project on AI [3]. This was followed by the development of \nmachine learning (ML) algorithms that allow decision making or p redictions based on the \npatterns in large datasets [4] . Subsequently, the development of neural networks (brain \nmimicking algorithms), genetic algorithms (finding optimal solutions for complex problems by \napplication of the evolutionary principles), and other advanced techniques followed [5]. \nLaunched in November 2022, “ChatGPT” is an AI-based large language model (LLM) trained on \nmassive text datasets in multiple languages with the ability to generate human-like responses to \ntext input [6] . Developed by OpenAI (OpenAI, L.L.C., San Francisco, CA, USA), ChatGPT \netymology is related to being a chatbot (a program able to understand and generate responses \nusing a text-based interface) and being based on the Generative Pre-trained Transformer (GPT) \narchitecture [6,7]. The GPT architecture utilizes a neural network to process natural language; \nthus, generating responses based on the context of input text [7]. The superiority of ChatGPT \ncompared to its GPT -based predecessors can be linked to its ability to respond to multiple \nlanguages generating refined and highly sophisticated responses based on advanced modelling \n[6,7]. \nIn the scientific community and academia, ChatGPT received mixed responses reflecting the \nhistory of controversy regarding the benefits vs. risks of advanced AI-technologies [8-10]. On one \nhand, ChatGPT among other LLMs, can be beneficial in conversational and writing tasks assisting \nto increase the efficiency and accuracy of the required output [11] . On the other hand, concerns \nraised in relation to possible bias based on the datasets used in ChatGPT training, which can limit \nits capabilities that could result in factual inaccuracies, yet alarmingly appearing scientif ically \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n5 \nplausible (a phenomenon termed hallucination) [11] . Additionally, security concerns and the \npotential of cyber-attacks with spread of misinformation utilizing LLMs should be considered as \nwell [11]. \nThe innate resistance of the human mind to any change is a well-described phenomenon and can \nbe understandable from evolutionary and social psychology perspectives [12] . Therefore, the \nconcerns and debates that arose instantaneously following the widespread release of ChatGPT \nappears understandable. The attention that ChatGPT received involved several disciplines. In \neducation as an example, ChatGPT release could mark the end of essays as assignments [13] . In \nhealthcare practice and academic writing, factual inaccuracies,  ethical issues and fear of misuse \nincluding the spread of misinformation should be considered [14-16]. \nThe versatility of human intelligence (HI) in comparison to AI should not be overlooked \nincluding its biologic evolutionary history, adaptability, creativity and the ability of emotional \nintelligence and to understand complex abstract concepts [2] . However, the HI-AI cooperation \ncan have great benefits if accurate and reliable output of AI is ensured. The utility of AI in \nhealthcare appears promising with possible applications in personalized medicine, drug \ndiscovery, and analysis of large datasets has been outlined previously besides the potential \nbenefits in improving diagnosis and clinical decisions [17,18]. Additionally, an interesting area to \nprobe is the utility of AI in healthcare education considering the massive information and various \nconcepts that healthcare students have to grasp [19]. However, all these applications should be \nconsidered cautiously considering the valid concerns, risks and categorical failures experienced \nand cited in the context of LLM applications. \nTherefore, the aim of the current review was to explore the future perspectives of ChatGPT as a \nprime example of LLMs in healthcare education, academic/scientific writing and healthcare \npractice based on the existing evidence. Importantly, the current review objectives extended to \ninvolve the identification of potential limitations and concerns associated with the application of \nChatGPT in the aforementioned areas. \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n6 \n2. Materials and Methods \nThe current systematic review was conducted according to the Preferred Reporting Items for \nSystematic Reviews and Meta-Analyses (PRIMSA) guidelines [20]. \nThe eligibility criteria involved any type of published scientific research or preprints (article, \nreview, communication, editorial, opinion, etc.), addressing ChatGPT that fell under the \nfollowing categories: (1) healthcare practice/research; (2) healthcare education; and (3) academic \nwriting. \nThe exclusion criteria included: (1) non -English records; (2) re cords addressing ChatGPT in \nsubjects other than those mentioned in the eligibility criteria; and (3) articles from non -academic \nsources (e.g., newspapers, internet websites, magazines, etc.). \nThe information sources included PubMed/MEDLINE and Google Scholar. \nThe exact PubMed/MEDLINE search strategy was as follows: (ChatGPT) AND \n((\"2022/11/30\"[Date - Publication] : \"3000\"[Date - Publication])) which yielded 42 records. The \nsearch concluded on 16 February 2023. \nThe search on Google Scholar was conducted using Publish or Perish (Version 8) [21]. The search \nterm was “ChatGPT” for the years: 2022–2023. The Google Scholar search yielded 238 records and \nconcluded on 16 February 2023. \nThen, the results from both searches were imported to EndNote v.20 for Windows (Thomson \nResearchSoft, Stanford, CA, USA), which yielded a total of 280 records. \nThen, screening of the title/abstract was done and duplicate records were excluded ( n = 40), \nfollowed by exclusion of records published in languages other than English (n = 32). Additionally, \nthe records that fell outside the scope of the review (records addressing ChatGPT in a context \noutside healthcare education, healthcare practice or scientific research/academic writing) were \nexcluded (n = 80). Moreover, the records published in non -academic sources (e.g., newspapers, \nmagazines, internet websites, blogs, etc.) were excluded (n = 18). \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n7 \nAfterwards, full screening of the remaining records ( n = 110) was done. Screening completed \nwhich resulted in the exclusion of an additional 41 records that fell outside the scope of the \ncurrent review. An additional nine records were excluded due to inability to access the full text \nbeing a subscription-based record. \nThis yielded a total of 60 records being eligible for inclusion in the current review. \nEach of the included records were searched specifically for the following: (1) type of record \n(preprint, published research article, opinion, commentary, editorial, review, etc.); (2) the listed \nbenefits/applications of ChatGPT in healthcare education, healthcare practice o r scientific \nresearch/academic writing; (3) the listed risks/concerns of ChatGPT in healthcare education, \nhealthcare practice or scientific research/academic writing; and (4) the main conclusions and \nrecommendation regarding ChatGPT in healthcare education , healthcare practice or scientific \nresearch/academic writing. \nCategorization of the benefits/applications of ChatGPT was as follows: (1) educational benefits in \nhealthcare education (e.g., generation of realistic and variable clinical vignettes, customized \nclinical cases with immediate feedback based on the student’s needs, enhanced communications \nskills); (2) benefits in academic/scientific writing (e.g., text generation, summarization, translation \nand literature review in scientific research); (3) benefits in scientific research (e.g., efficient \nanalysis of large datasets, drug discovery, identification of potential drug targets, generation of \ncodes in scientific research); (4) benefits in healthcare practice (e.g., improvements in personalized \nmedicine, diagnosis, treatment, life style recommendations based on personalized traits, \ndocumentation/generation of reports); and (5) being a freely available package.  \nCategorization of the risks/concerns of ChatGPT was as follows: (1) ethical issues (e.g., risk o f \nbias, discrimination based on the quality of training data, plagiarism); (2) hallucination (the \ngeneration of scientifically incorrect content that sounds plausible); (3) transparency issues (black \nbox application); (4) risk of declining need for human e xpertise with subsequent psychologic, \neconomic and social issues; (5) over -detailed, redundant, excessive content; (6) concerns about \ndata privacy for medical information; (7) risk of declining clinical skills, critical thinking and \nproblem-solving abiliti es; (8) legal issues (e.g., copyright issues, authorship status); (9) \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n8 \ninterpretability issues; (10) referencing issues; (11) risk of academic fraud in research; (12) \nincorrect content; and (13) infodemic risk \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n9 \n3. Results \nA total of 280 records were identified, and following the full screening process, a total of 60 \nrecords eligible to be included in the review. The PRISMA flow chart of the record selection \nprocess is shown in (Figure 1). \n \nFigure 1. Flow chart of the record selection process based on the Preferred Reporting Items for \nSystematic Reviews and Meta-Analyses (PRIMSA) guidelines. \n \n3.1. Summary of the ChatGPT Benefits and Limitations/Concerns in Healthcare \nA summary of the main conclusions of the included studies regarding ChatGPT utility in \nacademic writing, healthcare education and healthcare practice/research is provided in (Table 1). \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n10 \nTable 1. A summary of the main conclusions of the included studies. \nAuthor(s) \n[Record] Design, aims Applications, benefits Risks, concerns, limitations Suggested action, conclusions \nStokel-Walker \n[13] News explainer  Well-organized content with decent references; \nfree package \nImminent end of conventional educational \nassessment; concerns regarding the effect on \nhuman knowledge and ability \nRevising educational assessment to prioritize \ncritical thinking or reasoning \nKumar [22] \nBrief report; assessment of \nChatGPT for academic \nwriting in biomedicine \nOriginal, precise and accurate responses with \nsystematic approach; helpful for training and to \nimproving topic clarity; efficiency in time; \npromoting motivation to write \nInstances of failure to follow the instructions \ncorrectly; failure to cite references in-text \ninaccurate references; lack of practical examples; \nlack of personal experience highlights; superficial \nresponses \nChatGPT can help in improving academic writing \nskills; promote universal design for learning; \nproper use of ChatGPT under academic \nmentoring \nWang et al. [23] \narXiv preprint; \ninvestigating ChatGPT \neffectiveness to generate \nBoolean queries for \nsystematic literature \nreviews \nHigher precision compared to the current \nautomatic query formulation methods \nPossibly not suitable for high-recall retrieval; \nmany incorrect MeSH terms; variability in query \neffectiveness across multiple requests; a black-box \napplication \nA promising tool for research \nBorji [24] arXiv preprint; to highlight \nthe limitations of ChatGPT Extremely helpful in scientific writing \nProblems in spatial, temporal, physical, \npsychological and logical reasoning; limited \ncapability to calculate mathematical expressions; \nfactual errors; risk of bias and discrimination; \ndifficulty in using idioms; lack of real emotions \nand thoughts; no perspective for the subject; over-\ndetailed; lacks human-like divergences; lack of \ntransparency and reliability; security concerns \nwith vulnerability to data poisoning; violation of \ndata privacy; plagiarism; impact on the \nenvironment and climate; ethical and social \nconsequences \nImplementation of responsible use and \nprecautions; proper monitoring; transparent \ncommunication; regular inspection for biases, \nmisinformation, among other harmful purposes \n(e.g., identity theft) \nZielinski et al. \n[25] \nWAME recommendations \non ChatGPT  Can be a useful tool for researchers \nIncorrect or non-sensical answers; restricted \nknowledge to the period before 2021; no legal \npersonality; plagiarism \nChatGPT does not meet ICMJE criteria and \ncannot be listed as an author; authors should be \ntransparent regarding ChatGPT use and take \nresponsibility for its content; editors need \nappropriate detection tools for ChatGPT-\ngenerated content \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n11 \nChen [26] \nEditorial on ChatGPT \napplications in scientific \nwriting \nIt helps to overcome language barriers promoting \nequity in research \nEthical concerns (ghostwriting); doubtful \naccuracy; citation problems \nEmbrace this innovation with an open mind; \nauthors should have proper knowledge on how \nto exploit AI tools \nBiswas [27] \nPerspective record on the \nfuture of medical writing \nin light of ChatGPT \nImproved efficiency in medical writing  \nSuboptimal understanding of the medical field; \nethical concerns; risk of bias; legal issues; \ntransparency issues \nA powerful tool in the medical field; however, its \nseveral limitations should be considered \nThorp [28] Editorial: “ChatGPT is not \nan author” - Content is not original; incorrect answers that \nsound plausible; issues of referencing; plagiarism \nRevise assignments in education \nIn Science journals, the use of ChatGPT is \nconsidered a scientific misconduct \nKitamura [29] \nEditorial on ChatGPT and \nthe future of medical \nwriting \nImproved efficiency in medical writing; \ntranslation \nEthical concerns, plagiarism; lack of originality; \ninaccurate content; risk of bias “AI in the Loop: Humans in Charge” \nStokel-Walker \n[30] \nNews article on the view \nof ChatGPT as an author - Plagiarism; lack of accountability; concerns about \nmisuse in the academia ChatGPT is not an author \nLubowitz [31] Editorial, ChatGPT impact \non medical literature - \nInaccuracy; bias; spread of misinformation and \ndisinformation; lack of references; redundancy in \ntext \nAuthors should not use ChatGPT to compose any \npart of scientific submission; however, it can be \nused under careful human supervision to ensure \nthe integrity and originality of the scientific work \nvan Dis et al. \n[32] \nComment: Priorities for \nChatGPT research \nAccelerated innovation; increased efficiency in \npublication time; can make science more \nequitable; increase the diversity of scientific \nperspectives; more free time for experimental \ndesigns; it could optimize academic training \nCompromise research quality; transparency \nissues; spread of misinformation; inaccuracies, \nbias and plagiarism; ethical concerns; possible \nfuture monopoly; lack of transparency \nBanning ChatGPT will not work; develop rules \nfor accountability, integrity, transparency and \nhonesty; carefully consider which academic skills \nremain essential to researchers; widen the debate \nin the academia; an initiative is needed to address \nthe development and responsible use of LLM for \nresearch \nLund and \nWang [33] \nNews: ChatGPT impact in \nacademia \nUseful for literature review; data analysis; \ntranslation \nEthical concerns, issues about data privacy and \nsecurity; bias; transparency issues \nChatGPT has the potential to advance academia; \nconsider how to use ChatGPT responsibly and \nethically \nCotton et al. \n[34] \nEdArXiv preprint on the \nacademic integrity in \nChatGPT era \n- Plagiarism; academic dishonesty  Careful thinking of educational assessment tools \nGao et al. [35] \nbioRxiv preprint \ncomparing the scientific \nabstracts generated by \nChatGPT to original \nabstracts \nA tool to decrease the burden of writing and \nformatting; can help to overcome language \nbarriers \nMisuse to falsify research; bias The use of ChatGPT in scientific writing or \nassistance should be clearly disclosed \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n12 \nLiebrenz et al. \n[36] \nComment on the ethical \nissues of ChatGPT use in \nmedical publishing \nCan help to overcome language barriers \nEthical issues (copyright, attribution, plagiarism, \nand authorship); inequalities in scholarly \npublishing; spread of misinformation; inaccuracy \nImplement robust AI author guidelines in \nscholarly publishing; follow COPE AI in decision \nmaking; AI cannot be listed as an author and its \nuse must be properly acknowledged \nPolonsky and \nRotman [37] \nSSRN preprint on listing \nChatGPT as an author \nAccelerate the research process; increase accuracy \nand precision \nIntellectual property issues if financial gains are \nencountered AI can be listed as an author in some instances \nNature [38] \nNature editorial on the \nrules of ChatGPT use to \nensure transparent science \nCan summarize research papers; generate helpful \ncomputer code Ethical issues; transparency \nLLM tools will be accepted as authors; if LLM \ntools are to be used, it should be documented in \nthe methods or acknowledgements; advocate for \ntransparency in methods, and integrity and truth \nfrom researchers \nAczel and \nWagenmakers \n[39] \nPsyArXiv preprint as a \nguide of transparent \nChatGPT use in scientific \nwriting \n- Issues of originality, transparency Provide sufficient information, accreditation and \nverification of ChatGPT use \nManohar and \nPrasad [40] \nA case study written with \nChatGPT assistance Helped to generate a clear, comprehensible text Lack of scientific accuracy and reliability; citation \ninaccuracy \nChatGPT use must be discouraged because it can \nprovide false information and non-existent \ncitations; can be misleading in healthcare practice \nAkhter and \nCooper [41] \nA case study written with \nChatGPT assistance \nHelped provide a relevant general introductory \nsummary \nInability to access relevant literature; the limited \nknowledge up to 2021; citation inaccuracy; \nlimited ability to critically discuss results \nCurrently, ChatGPT does not replace \nindependent literature reviews in scientific \nresearch \nHolzinger et al. \n[42] \nArticle: AI/ChatGPT use in \nbiotechnology \nBiomedical image analysis; diagnostics and \ndisease prediction; personalized medicine; drug \ndiscovery and development \nEthical and legal issues; limited data availability \nto train the models; reproducibility of the runs Aspire for fairness, open science, and open data \nMann [43] Perspective: ChatGPT in \ntranslational research \nEfficiency in writing; analysis of large datasets \n(e.g., electronic health records or genomic data); \npredict risk factors for disease; predict disease \noutcomes \nQuality of data available; inability to understand \nthe complexity of biologic systems \nChatGPT role in scientific and medical journals \nwill grow in the near future \nDe Angelis et \nal. [44] \nSSRN preprint discussing \nthe concerns of an AI-\ndriven infodemic \nCan support and expediting academic research \nGeneration of misinformation and the risk of \nsubsequent infodemics; falsified or fake research; \nethical concerns \nCarefully weigh ChatGPT benefits vs. risks; \nestablish ethical guidelines for use; encourage a \nscience-driven debate \nBenoit [45] \nmedRxiv preprint on the \ngeneration, revision, and \nevaluation of clinical \nvignettes as a tool in \nhealth education using \nChatGPT \nConsistency, rapidity and flexibility of text and \nstyle; ability to generate plagiarism-free text \nClinical vignettes’ ownership issues; inaccurate or \nnon-existent references \nChatGPT can allow for improved medical \neducation; better patient communication \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n13 \nSharma and \nThakur [46] \nChemRxiv preprint on \nChatGPT possible use in \ndrug discovery \nIdentify and validate new drug targets; design \nnew drugs; optimize drug properties; assess \ntoxicity; generate drug-related reports \nReliance on the data available for training which \ncan result in bias or inaccuracy; inability to \nunderstand the complexity of biologic systems; \ntransparency issues; lack of experimental \nvalidation; limited interpretability; limited \nhandling of uncertainty; ethical issues \nChatGPT can be a powerful and promising \nassisting in drug discovery; however, ethical \nissues should be addressed \nMoons and Van \nBulck [47] \nEditorial on ChatGPT \npotential in cardiovascular \nnursing practice and \nresearch \nSummarize a large text; facilitate the work of \nresearchers; data collection \nInformation accuracy issues; the limited \nknowledge up to 2021; limited capacity ChatGPT can be a valuable tool in healthcare \nPatel and Lam \n[48] \nComment on ChatGPT \nutility in documentation of \ndischarge summary \nCan help to reduce the burden of discharge \nsummaries providing high-quality and efficient \noutput \nData governance issues; risk of depersonalization \nof care; risk of incorrect or inadequate \ninformation \nProactive adoption to limit future issues  \nCahan and \nTreutlein [49] \nEditorial reporting a \nconversation with \nChatGPT on stem cell \nresearch \nIt saves time Repetition; several responses lacked depth and \ninsight; lack of references ChatGPT helped to write an editorial saving time \nRao et al. [50] \nmedRxiv preprint on the \nusefulness of ChatGPT in \nradiologic decision making \nModerate accuracy to determine appropriate \nimaging steps in breast cancer screening and \nevaluation of breast pain \nLack of references; alignment with user intent; \ninaccurate information; over-detailed; \nrecommending imaging in futile situations; \nproviding rationale for incorrect imaging \ndecisions; black box nature \nUsing ChatGPT for radiologic decision making is \nfeasible, potentially improving the clinical \nworkflow and responsible use of radiology \nservices \nAntaki et al. \n[51] \nmedRxiv preprint on \nassessing ChatGPT to \nanswer a diverse MCQ \nexam in ophthalmology \nCurrently performing at the level of an average \nfirst-year ophthalmology resident \nInability to process images; risk of bias; \ndependence on training dataset quality \nThere is a potential of ChatGPT use in \nophthalmology; however, its applications should \nbe approached carefully \nAhn [52] \nLetter to the editor \nreporting a conversation of \nChatGPT regarding CPR \nPersonalized interaction; quick response time; can \nhelp to provide easily accessible and \nunderstandable information regarding CPR to the \ngeneral public \nInaccurate information might be generated with \nserious medical consequences \nExplore the potential utility of ChatGPT to \nprovide information and education on CPR \nGunawan [53] \nAn editorial reporting a \nconversation with \nChatGPT regarding the \nfuture of nursing \nIncreased efficiency; reduce errors in care \ndelivery \nLack of emotional and personal support ChatGPT can provide valuable perspectives in \nhealthcare \nD'Amico et al. \n[54] \nEditorial reporting a \nconversation of ChatGPT \nregarding incorporating \nChatbots into \nCan help to provide timely and accurate \ninformation for the patients about their treatment \nand care \nPossibility of inaccurate information; privacy \nconcerns; ethical issues; legal issues; bias;  \nNeurosurgery practice can be leading in utilizing \nChatGPT into patient care and research \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n14 \nneurosurgical practice and \nresearch \nAydın and \nKaraarslan [55] \nSSRN preprint on the use \nof ChatGPT to conduct a \nliterature review on digital \ntwin in healthcare \nLow risk of plagiarism; accelerated literature \nreview; more time for researchers Lack of originality \nExpression of knowledge can be accelerated using \nChatGPT; further work will use ChatGPT in \ncitation analysis to assess the attitude towards the \nfindings \nZhavoronkov * \n[56] \nPerspective reporting a \nconversation with \nChatGPT about \nRapamycin use from a \nphilosophical perspective \nProvided correct summary of rapamycin side \neffects. Referred to the need to consult a \nhealthcare provider based on the specific \nsituation \n- Demonstration ChatGPT potential to generate \ncomplex philosophical arguments \nHallsworth et \nal. [57] \nA comprehensive opinion \narticle submitted before \nChatGPT launching on the \nvalue of theory-based \nresearch \nCan help to circumvent language barriers; can \nrobustly help to process massive data in short \ntime; can spark creativity by humans if “AI in the \nLoop: Humans in Charge” is applied \nEthical issues; legal responsibility issues; lack of \nempathy and personal communication; lack of \ntransparency \nThere is an intrinsic value of human engagement \nin the scientific process which cannot be replaced \nby AI contribution \nSanmarchi et al. \n[58] \nmedRxiv preprint \nevaluating ChatGPT \nsupport to conduct an \nepidemiologic study \nfollowing the STROBE \nrecommendations \nconduction of an \nepidemiological study \nCan provide appropriate responses if properly \nqueried; more time for researchers to focus on \nexperimental phase \nBias in the training data; devaluation of human \nexpertise; risk of scientific fraud; legal issues; \nreproducibility issues \nThe research premise and originality will remain \nthe function of human brain; however, ChatGPT \ncan assist in reproducing the study \nStokel-Walker \nand Van \nNoorden [14] \nNature news feature \narticle on ChatGPT \nimplications in science \nMore productivity among researchers \nProblems in reliability and factual inaccuracies; \nmisleading information that seem plausible; over-\ndetailed; bias; ethical issues; copyright issues \n“AI in the Loop: Humans in Charge”; we are just \nat the beginning  \nDuong and \nSolomon [59] \nmedRxiv preprint \nevaluating ChatGPT vs. \nhuman responses to \nquestions on genetics \nGeneration of rapid and accurate responses; \neasily accessible information for the patients with \ngenetic disease and their families; can help can \nhealth professionals in the diagnosis and \ntreatment of genetic diseases; Could make genetic \ninformation widely available and help non-\nexperts to understand this information \nPlausible explanations for incorrect answers; \nreproducibility issues \nValue of ChatGPT use will increase in importance \nin research and clinical settings \nHuh [60] \nTo compare ChatGPT \nperformance on a \nparasitology exam to that \nPerformance will improve by deep learning \nChatGPT performance was lower compared to \nmedical students; Plausible explanations for \nincorrect answers \nChatGPT performance will continue to improve, \nand healthcare educators/students are advised on \nhow to incorporate it into the education process \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n15 \nof Korean medical \nstudents \nYeo et al. [61] \nmedRxiv preprint \nevaluating ChatGPT \nresponses to questions on \ncirrhosis and \nhepatocellular carcinoma \nImproved health literacy with better patient \noutcome; free availability; increased efficiency \namong health providers; emulation of empathetic \nresponses \nNon-comprehensive responses; the limited \nknowledge up to 2021; responses can be limited \nand not tailored to specific country or region; \nlegal issues \nChatGPT may serve as a useful adjunct tool for \npatients besides the standard of care; future \nstudies are recommended \nBašić et al. [62] \narXiv preprint on the \nperformance of ChatGPT \nin essay writing compared \nto masters forensic \nstudents in Croatia \n- Plagiarism; lack of originality; it did not \naccelerate essay writing \nThe concerns in the academia towards ChatGPT \nare not totally justified; ChatGPT text detectors \ncan fail \nFijačko et al. \n[63] \nLetter to the editor to \nreport the accuracy of \nChatGPT responses to life \nsupport exam questions by \nthe AHA \nRelevant, accurate responses on occasions Referencing issues; over-detailed \nChatGPT did not pass any of the exams; however, \nit can be a powerful self-learning tool to prepare \nfor the life support exams \nHisan and \nAmri [64] \nRG preprint on ChatGPT \nuse medical education \nGeneration of educational content; useful to learn \nlanguages \nEthical concerns; scientific fraud (papermills); \ninaccurate responses; declining quality of \neducations with the issues of cheating \nAppropriate medical exam design, especially for \npractical skills \nJeblick et al. \n[65] \narXiv preprint on \nChatGPT utility to \nsimplify and summarize \nradiology reports \nGeneration of medical information relevant for \nthe patients; moving towards patient-centered \ncare; cost efficiency \nBias and fairness issues; misinterpretation of \nmedical terms; imprecise responses; odd \nlanguage; hallucination (plausible yet inaccurate \nresponse); unspecific location of injury/disease \nDemonstration of the ability of ChatGPT \nsimplified radiology reports; however, the \nlimitations should be considered \nImprovements of patient-centered care in \nradiology could be achieved \nMbakwe et al. \n[66] \nEditorial on ChatGPT \nability to pass the USMLE - Bias; lack of thoughtful reasoning \nChatGPT passing the USMLE revealed the \ndeficiencies in medical education and assessment; \nthere is a need to reevaluate medical student \ntraining and education \nKhan et al. [67] \nCommunication on \nChatGPT use in medical \neducation and clinical \nmanagement \nAutomated scoring; assistance in teaching; \nimproved personalized learning; assistance in \nresearch; generation of clinical vignettes; rapid \naccess to information; translation; documentation \nin clinical practice; support in clinical decisions; \npersonalized medicine  \nLack of human-like understanding; the limited \nknowledge up to 2021 \nChatGPT can be a helpful in medical education, \nresearch, and clinical practice; however, it cannot \nreplace the human capabilities \nGilson et al. \n[68] \nPerformance of ChatGPT \non USMLE \nAbility to understand context and to complete a \ncoherent and relevant conversation in the medical \nfield; can be used as an adjunct in group learning \nThe limited knowledge up to 2021 \nChatGPT passes the USMLE with performance at \na 3rd year medical student level; can help to \nfacilitate learning as a virtual medical tutor \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n16 \nNisar and \nAslam [69]  \nSSRN preprint on the \nassessment of ChatGPT \nusefulness to study \npharmacology \nGood accuracy Content not sufficient for research purposes Can be a helpful self-learning tool \nHuh [70] Editorial of JEEHP policy \ntowards ChatGPT use - Reponses not accurate in some areas \nJEEHP will not accept ChatGPT as an author; \nhowever, ChatGPT content can be used if \nproperly cited and documented \nO'Connor * [71] \nEditorial written with \nChatGPT assistance on \nChatGPT in nursing \neducation \nPersonalized learning experience Plagiarism; biased or misleading results \nAdvocate ethical and responsible use of \nChatGPT; improve assessment in nursing \neducation \nKung et al. [72] \nChatGPT raised accuracy \nto enable passing the \nUSMLE \nAccuracy with high concordance and insight; \nfacilitate patient communication; personalized \nmedicine \n- \nChatGPT can have promising potential in medical \neducation; recommendation for future studies to \nconsider non-biased approach with quantitative \nnatural language processing and text mining \ntools such as word network analysis \nLin [73] \nPsyArXiv preprint \ndescribing the utility of \nChatGPT in academic \neducation \nVersatility \nHallucination (inaccurate information that \nsounds scientifically plausible); fraudulent \nresearch; plagiarism; copyright issues \nTransforming long-term effects; embrace \nChatGPT and use it to augment human \ncapabilities; however, sensible guidelines and \ncodes of conduct are urgently needed \nShen et al. [74] Editorial on ChatGPT \nstrengths and limitations \nGeneration of medical reports; providing \nsummary of medical records; drafting a letter to \nthe insurance provider; improve the \ninterpretability of CAD systems \nHallucination (inaccurate information that \nsounds scientifically plausible); the need to \ncarefully craft questions or prompts; possible \ninaccurate or incomplete results; dependence on \nthe training data; bias; research fraud \nDespite the extremely helpful powers of \nChatGPT, we should proceed cautiously in \nharnessing its power \nGordijn and \nHave [75] \nEditorial on the \nrevolutionary nature of \nChatGPT \n- Factual inaccuracies; plagiarism; fraud; copyright \ninfringements \nWe should prepare for a future with LLM has the \ncapacity to write papers that pass peer review \nMijwil et al. [76] \nEditorial on the role of \ncybersecurity in the \nprotection of medical \ninformation \nVersatility; efficiency; high quality of text \ngenerated; cost saving; room for innovation; \nimproved decision making; improved \ndiagnostics; predictive modeling; personalized \nmedicine; streamline clinical workflow increasing \nefficiency; remote monitoring \nData security issues Emphasis on the role of cybersecurity to protect \nmedical information \nThe Lancet \nDigital Health \n[77] \nEditorial on the strengths \nand limitations of \nChatGPT \nImprove language and readability \nOver-detailed; incorrect or biased content; \npotentially generating harmful errors; spread of \nmisinformation; plagiarism; issues with integrity \nof scientific records \nWidespread use of ChatGPT is inevitable; proper \ndocumentation of its use; ChatGPT should not be \nlisted or cited as an author or co-author \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n17 \nAljanabi et al. \n[78] \nEditorial on the \npossibilities provided by \nChatGPT \nAssist in academic writing; code generation Inaccurate content including inability to reliably \nhandle mathematical calculations \nChatGPT will receive a growing interest in the \nscientific community \nMarchandot et \nal. [79]  \nCommentary on ChatGPT \nin academic writing \nAssist in literature review saving time; ability to \nsummarize papers; improving language \nInaccurate content; bias; may lead to decreased \ncritical thinking and creativity in science; ethical \nconcerns; plagiarism  \nChatGPT can be credited as an author based on \nits significant contribution \nAbbreviations: arXiv: a free distribution service and an open- access archive for scholarly articles in the fields of physics, mathematics, computer \nscience, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics, m aterials on arXiv are not \npeer-reviewed by arXiv, available from: https://arxiv.org/ , accessed on 18 February 2023; MeSH: Medical Subject Headings; WAME: World \nAssociation of Medical Editors; ICMJE: International Committee of Medical Journal Editors; AI: Artificial intelligence; COPE AI in decision making: \nCommittee on Publication Ethics, Artificial intelligence (AI) in decision making, available from: https://publicationethics.org/node/50766, accessed \non 18 February 2023; LLM: Large-scale language model; ChemRxiv is a free submission, distribution, and archive service for unpublished preprints \nin chemistry and related areas, available from: https://chemrxiv.org/engage/chemrxiv/public-dashboard, accessed on 18 February 2023; medRxiv: \nFree online archive and distribution server for complete but unpublished manuscripts (preprints) in the medical, clinical, and related health sciences, \navailable from: https://www.medrxiv.org/, accessed on 18 February 2023; MCQ: Multiple choice exam; CPR: cardiopulmonary resuscitation; \nSTROBE: Strengthening the reporting of observational studies in epidemiology; * ChatGPT Generative Pre -trained Transformer was listed as an \nauthor; AHA: American Heart Association; USMLE: United States Medical Licensing Examination; JEEHP: Journal of Educational Evaluation for \nHealth P rofessions; PsyArXiv: psychology archive for preprints, available from: https://psyarxiv.com/, accessed on 18 February 2023; CAD: \nComputer-aided diagnosis; SSRN: Social Science Research Network repository for preprints, available from: https://www.ssrn.com/index.cfm/en/, \naccessed on 19 February 2023; EdArXiv: A preprint server for the education research  community, available from: https://edarxiv.org/, accessed on \n19 February 2023; bioRxiv: a free online archive and distribution service for unpublished preprints in the life sciences, available from: \nhttps://www.biorxiv.org/, accessed on 19 February 2023; RG: Researchgate: A commercial social networking site for scientists and researchers, \navailable from: https://www.researchgate.net/about, accessed on 19 February 2023. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n18 \n3.2. Characteristics of the Included Records \nA summary of the record types included in the current review is shown in (Figure 2). \n \nFigure 2. Summary of types of the included records (n = 60). Preprints (not peer reviewed) are \nhighlighted in grey while published records are highlighted in blue. \n \nOne-third of the included records were preprints (n = 20), with the most common preprint server \nbeing medRxiv (n  = 6, 30.0%), followed by SSRN a nd arXiv ( n = 4, 20.0%) for each. \nEditorials/letters to editors were the second most common type of the included records ( n = 19, \n31.7%).   \n3.3. Benefits and Possible Applications of ChatGPT in Healthcare Education, Practice and Research Based \non the Included Records \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n19 \nBenefits of ChatGPT was most frequently cited in the context of academic/scientific writing which \nwas mentioned in 31 records (51.7%). Examples included: efficiency and versatility in writing \nwith text of high quality, improved language, readab ility and translation promoting research \nequity, accelerated literature review. Benefits in scientific research followed which was \nmentioned in 20 records (33.3%). Examples included the ability to analyze massive data including \nelectronic health records or  genomic data, availability of more free time for the focus on \nexperimental design, and drug design and discovery. Benefits in healthcare practice was \nmentioned by 14 record (23.3%), with examples including personalized medicine, prediction of \ndisease risk and outcome, streamlining the clinical workflow, improved diagnostics, \ndocumentation, cost saving, and improved health literacy. Educational benefits in healthcare \ndisciplines were mentioned in seven records (11.7%) with examples including: generation of \naccurate and versatile clinical vignettes, improved personalized learning experience, and being \nan adjunct in group learning. Being a free package was mentioned as a benefit in two records \n(3.3%, Figure 3).  \n \nFigure 3. Summary of benefits/applications of ChatGPT in healthcare education, research and \npractice based on the included records. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n20 \n \n3.4. Risks and Concerns Towards ChatGPT in Healthcare Education, Practice and Research Based on the \nIncluded Records \nEthical concerns were commonly mentioned by 33 records (55.0%), especially in the context of \nrisk of bias (mentioned by 18 records, 30.0%) and plagiarism (mentioned by 14 records, 23.3%) \namong data privacy and security issues. \nOther concerns involved: the risk of incorrect/inaccurat e information that was mentioned by 20 \nrecords (33.3%); citation/reference inaccuracy or inadequate referencing which was mentioned by \n10 records (16.7%); transparency issues which was mentioned by 10 records (16.7%); legal issues \nmentioned in 7 records (11.7%); restricted knowledge before 2021 mentioned by 6 records (10.0%); \nrisk of misinformation spread mentioned by 5 records (8.3%); over -detailed content mentioned \nin 5 records (8.3%); copyright issues mentioned in 4 records (6.7%); and lack of originalit y \nmentioned by 4 records (6.7%, Figure 4).  \n \nFigure 4. Summary of risks/concerns of ChatGPT use in healthcare education, research and \npractice based on the included records. \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n21 \n4. Discussion \nThe far-reaching consequences of ChatGPT among other LLMs can be  described as a paradigm \nshift in the academia and healthcare practice [16] . The discussion of its potential benefits, future \nperspectives and importantly its limitations appear timely and relevant. \nTherefore, the current review aimed to highlight these issues based on the current evidence. The \nfollowing common themes emerged from the available literature: ChatGPT as an example of \nother LLMs can be a promising or even a revolutionary tool for scientific research both in \nacademic writing and in the research process itself. Specifically, ChatGPT was listed in several \nsources as an efficient and promising tool for conducting comprehensive literature reviews and \ngenerating computer codes, thereby saving time for the research steps that require more efforts \nfrom human intelligence (e.g., the focus on experimental design) [14,27,32,33,38,47,55,58,78,79] . \nAdditionally, ChatGPT can be helpful in generating queries for comprehensive systematic review \nwith high precision as shown by Wang et al. despite the authors highlighting the transparency \nissues and unsuitability for high-recall retrieval [23]. Moreover, the utility of ChatGPT extends to \ninvolve the improvement in language and better ability to express and communicate the research \nideas and results, ultimately speeding up the publication process with faster availability of \nresearch results [26,29,35,36,44,49,77]. This is particularly relevant for researchers who are non -\nnative English speakers [26,29,35] . Such a practice can be acceptable considering the already \nexistent English editing services provided by several a cademic publishers as an acceptable \npractice. Subsequently, this can help to promote equity and diversity in research [32,57].    \nOn the other hand, the use of ChatGPT in academic writing and scientific research should be done \nin light of the following current limitations that could compromise the quality of research: First, \nsuperficial, inaccurate or incorrect content was frequently cited as a shortcoming of ChatGPT use \n[14,47,49,77,79]. The ethical issues including the risk of bias based on training datasets, and \nplagiarism were frequently mentioned, besides the lack of transparency described on occasions \nas a black box technology [14,27,29-33,35,36,39,57,58,77,79]. Importantly, the concept of ChatGPT \nhallucination was mentioned which can be risky if not evaluated properly by researchers and \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n22 \nhealth providers with proper expertise [59,60,65,73,74] . This comes in light of ChatGPT’s ability \nto generate incorrect content that appears plausible scientifically. \nSecond, several records mentioned the current problems regarding citation inaccuracies, \ninsufficient references and ChatGPT referencing to non-existent sources [26,31]. This was clearly \nshown in two recently published case studies with ChatGPT use in a journal contest [40,41,49] . \nThese case studies discouraged the use of ChatGPT citing lack of scientific accuracy, limited \nupdated knowledge, and lack of ability to critically discuss the results [40,41,75] . Therefore, the \nChatGPT generated content albeit efficient should be meticulously examined prior to its inclusion \nin any research manuscripts or proposals for grants. \nThird, the generation of non -original, over -detailed or excessive content can be an additional \nburden for the researchers who should carefully supervise ChatGPT-generated content \n[14,28,29,31,39,55]. This can be addressed by supplying ChatGPT with proper prompts (text \ninput) du e to varying responses based on the construction of prompts in order to be able to \ngenerate succinct content [58]. \nFourth, as it currently stands, the knowledge of ChatGPT is limited to the period prior to 2021 \nbased on the training datasets used in ChatGPT training [6]. Thus, ChatGPT currently cannot be \nused as a reliable updated source of literature review; nevertheless, it can be used as a motivation \nto organize the  literature in a decent format and if supplemented by reliable and up -to-date \nreferences [47,61]. \nFifth, the risk of research fraud (e.g., ghostwriting, falsified or fake research) involving ChatGPT \nshould be considered seriously [26,44,58,73- 75], as well as the risk of generating mis- or dis -\ninformation with subsequent possibility of infodemics [31,32,36,44]. \nSixth, legal issues were raised by several records as well, including copyright issues \n[14,27,57,73,75]. Finally, the issue of listing ChatGPT as an author does not app ear acceptable \nbased on the current ICMJE and COPE guidelines for determining authorship as illustrated by \nZielinski et al. and Liebrenz et al. [25,36]. This comes in light of the fact that authorship entails \nlegal obligations which are not met by ChatGPT [25,36]. However, other researchers suggested \nthe possibility of inclusion of ChatGPT as an author in some specified instances [37,79]. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n23 \nA few instances were encountered where ChatGPT was cited as an author which can point to the \ninitial perplexity by publishers regarding the role of LLM including ChatGPT in research [56,71]. \nThe disapproval of incl uding ChatGPT or any other LLM in the list of authors was clearly \nexplained in Science, Nature, and the Lancet editorials referring to its use as a scientific misconduct, \nand this view was echoed by many scientists [28,30,38,70,77] . In case of ChatGPT use in the \nresearch process, several records advocated the need for proper and concise disclosure and \ndocumentation of ChatGPT or LLM use in the methodology or acknowledgement sections \n[35,39,70]. A noteworthy and comprehensive record by Borji can be used as a categorical guide \nfor the issues and concerns of ChatGPT use especially in scientific writing [24].   \nFrom the perspective of healthcare practice, it seems that there is a careful excitement vibe \nregarding ChatGPT applications. The utility of ChatGPT to streamline the clinical workflow \nappears promising with expected increased efficiency in healthcare delivery and saving costs \n[53,65,74,76]. This was illustrated recently by Patel and Lam highlighting the ability of ChatGPT \nto produc e efficient discharge summaries, which can be valuable to reduce the burden of \ndocumentation in healthcare [48] . Additionally, ChatGPT among other LLMs can have a \ntransforming potential in healthcare practice via enhancing diagnostics, prediction of disease risk \nand outcome, and drug discovery among other areas in translational research [42,43,46] . \nMoreover, ChatGPT showed moderate accuracy to determine the imaging steps needed in breast \ncancer screening and evaluation of breast pain which can be a promising application in decision \nmaking in radiology [50] . There is also the prospects of personalized medicine and improved \nhealth literacy by providing ea sily accessible and understandable health information for the \ngeneral public [52,54,59,61,72]. This utility was demonstrated by ChatGPT responses highlighting \nthe need to consult healthcare providers among other reliable sources on specific situations \n[16,56].  \nOn the other hand, several concerns regarding ChatGPT use in healthcare settings were raised. \nEthical issues including the risk of bias and transparency issues appear as a recurring major \nconcern [42,46,50,65]. Generation of inaccurate content can have severe negative consequences in \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n24 \nhealthcare; therefore, this valid concern should be cautiously considered [48,52,54]. This can also \nextend to involve providing justification for incorrect decisions [50]. \nIssues of interpretability, reproducibility and handling of uncertainty were raised as well, which \ncan have harmful consequences in healthcare settings including research [46,58,59]. In the area of \npersonalized medicine, the transparency issues in terms of ChatGPT being a black box with \nunclear information regarding the source of data used for its training is an important issue \nconsidering the variability observed among different populations in several traits [50]. The issue \nof reproducibility between prompt runs is of particular importance in healthcare practice [42]. \nMedico-legal issues and accountability in case of medical errors caused by ChatGPT application \nshould be carefully considered [27]. Importantly, the current LLMs including ChatGPT does not \nappear to be able to comprehend the complexity of biologic systems needed in healthcare \ndecisions and research [43,46]. The concerns regarding data governance, cybersecurity of medical \ninformation and data privacy should draw specific attention in the discussion regarding the \nutility of LLMs in healthcare [48,54,76]. \nOther issues include the lack of personal and emotional perspectives, which were listed among \nother concerns of ChatGPT utility in healthcare delivery and research [52,57]. However, ChatGPT \nemulation of empathetic responses was reported in a preprint in the context of hepatic disease \n[61]. Additionally, the issue of devaluing the function of the human brain should not be \noverlooked; therefore, stressing on the indi spensable human role in healthcare practice and \nresearch is important to address any psychologic, economic and social consequences [58].   \nIn the area of healthcare education, ChatGPT appears to have a massive transformative potential. \nThe need to rethink and revise the current assessment tools in healthcare education comes in light \nof ChatGPT’s ability to pass reputable exams (e.g., USMLE), and possibility of ChatGPT misuse \nthat would result in increased academic dishonesty [28,34,64,66,68,72]. \nSpecifically, in ophthalmology examination, Antaki et al. showed that ChatGPT currently \nperformed at the level of an average first-year resident [51]. The focus on questions involving the \nassessment of critical and problem-based thinking appears of utmost value [66]. Additionally, the \nutility of ChatGPT in healthcare edu cation can involve tailoring education based on the student \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n25 \nneeds with immediate feedback [32] . Interestingly, a recent preprint by Benoit showed th e \npromising potential of ChatGPT in rapidly crafting consistent realistic clinical vignettes of \nvariable complexities which can be a valuable educational source with lower costs [45] . Thus, \nChatGPT can be useful in healthcare education including enhanced communication skills given \nproper academic mentoring [22,45,67] . However, the copyright i ssue in ChatGPT -generated \nclinical vignettes besides the issue of inaccurate references should be taken into account [45] . \nAdditionally, ChatGPT availability can be considered as a motivation in healthcare education \nbased on the personalized interaction it provides, enabling powerful self -learning as well as its \nutility as an adjunct in group learning [52,63,67,68,71]. \nOther concerns in the educational context include the concern regarding the quality of training \ndatasets resulting in bias and inaccurate information limited to the period prior to the year 2021, \nand current inability to handle images, as well as the low performance in some topics (e.g., failure \nto pass a parasitology exam for Korean medical students) and the issue of possible plagiarism \n[51,60,62,63,67,68]. Despite being described by versatility in the context of academic education \n[73], the content of ChatGPT in research assignments was discouraged as well, being currently \ninsufficient, biased or misleading [69,71]. \n4.1. Future Perspectives \nAs stated comprehensively in a commentary by van Dis et al., there is an urgent need to develop \nguidelines for ChatGPT use in scientific research taking into account the issues of accountability, \nintegrity, transparency and honesty [32]. Thus, the application of ChatGPT to advance academia \nshould be done ethically and responsibly taking into account the risks and concerns it entails [33]. \nMore studies are needed to evaluate the LLMs’ content, including its potential impact to advance \nacademia and science with particular focus on healthcare settings. In academic writing, a question \nwould arise if the authors would prefer an AI-editor and an AI-reviewer considering the previous \nflaws in the editorial and peer review processes [80-82]. A similar question would a rise in \nhealthcare settings involving the preference personal and emotional support from healthcare \nproviders rather than the potential efficiency of AI-based systems \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n26 \n4.2. Strengths and Limitations \nThe current review represents the first rapid and concise overview of ChatGPT utility in \nhealthcare education, research and practice. However, the results of the current review should be \nviewed carefully in light of several shortcomings that included: (1) the quality of the included \nrecords can be variable compr omising generalizability of the results; (2) the exclusion of non -\nEnglish records might have resulted in selection bias; (3) the exclusion of several records that \ncould not be accessed could have resulted in missing relevant data despite being small in number; \n(4) the inclusion of preprints that have not been peer reviewed yet might compromise the \ngeneralizability of the results as well. \n \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n27 \n5. Conclusions \nThe imminent dominant use of LLM technology including ChatGPT utility will be inevitable. \nConsidering t he valid concerns raised over its potential misuse, particularly in the areas of \nhealthcare education, research and practice, appropriate guidelines and regulations are urgently \nneeded following the involvement of all stakeholder to help ensuring the harnessing of the \npotential powers of ChatGPT and other LLMs safely and responsibly. Ethical concerns, \ntransparency, and legal issues should be considered carefully and proactive embrace of this \ntechnology can limit the future complications. If properly addressed, these technologies can have \nthe potential to expedite the research and innovation in healthcare and can aid to promote equity \nin research by overcoming the language barriers. Therefore, a science-driven debate regarding \nthe pros and cons of ChatGPT is strongly recommended and the possible benefits should be \nweighed with the possible risks of misleading results and fraudulent research. \nHealthcare professionals could be described based on the available evidence as carefully \nenthusiastic considering the hu ge potential of ChatGPT among other LLMs in clinical decision \nmaking and optimizing the clinical workflow.  \n“ChatGPT in the Loop: Humans in Charge” can be the proper motto based on the intrinsic value \nof human knowledge and expertise in healthcare research and practice [14,57], reminiscent of the \nrelationship of the human character Cooper and robotic character TARS from interstellar. \nHowever, before its widespread adoption, ChatGPT impact in real world setting from healthcare \nperspective should be done (e.g., using a risk -based approach) [83] . Base d on the title of an \nimportant perspective article “AI in the hands of imperfect users” by Kostick -Quenet and Gerke \n[83], Ferrari F2004 (the highly successful formula 1 racing car) broke Formula 1 records in the \nhands of Michael Schumacher; however, in my own hands -as a humble researcher without \nexpertise in Formula 1 driving- it will only break walls and get broken beyond repair as well.  \n \n \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n28 \nDeclarations \nSupplementary Materials: None. \nAuthor Contributions: The author explicitly and clearly declares the sole role in the following: \nconceptualization, methodology, software, investigation, resources, writing —original draft \npreparation, writing —review and editing, and visualization. The author explicitly and clearly \ndeclares that neither ChatGPT nor any other LLMs were used to draft this manuscript. \nFunding: This research received no external funding. \nInstitutional Review Board Statement: Not applicable. \nInformed Consent Statement: Not applicable. \nData Availability Statement: Data supporting this systematic review are available in the original \npublications, reports and preprints that were cited in the reference section. In addition, the \nanalyzed data that were used during the current systematic review are available from the author \non reasonable request. \nAcknowledgments: None. \nConflicts of Interest: The author declares no conflict of interest. \n  \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n29 \nReferences \n1. Sarker, I.H. AI-Based Modeling: Techniques, Applications and Research Issues Towards \nAutomation, Intelligent and Smart Systems. SN Computer Science 2022, 3, 158, \ndoi:10.1007/s42979-022-01043-x. \n2. Korteling, J.E.; van de Boer -Visschedijk, G.C.; Blankendaal, R.A.M.; Boonekamp, R.C.; \nEikelboom, A.R. Human- versus Artificial Intelligence. Front. Artif. Intell. 2021, 4, 622364, \ndoi:10.3389/frai.2021.622364. \n3. McCarthy, J.; Minsky, M.L.; Rochester, N.; Shannon, C.E. A Proposal for t he Dartmouth \nSummer Research Project on Artificial Intelligence, August 31, 1955. AI magazine 2006, 27, \n12-12, doi:aimag.v27i4.1904. \n4. Jordan, M.I.; Mitchell, T.M. Machine learning: Trends, perspectives, and prospects. Science \n2015, 349, 255-260, doi:10.1126/science.aaa8415. \n5. Domingos, P. The master algorithm: how the quest for the ultimate learning machine will remake \nour world, First paperback edition ed.; Basic Books, a member of the Perseus Books Group: \nNew York, 2018; p. 329 pages. \n6. OpenAI. OpenAI: Models GPT -3. Available online: https://beta.openai.com/docs/models  \n(accessed on 14 January 2023). \n7. Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.D.; Dhariwal, P.; Neelakantan, A.; \nShyam, P.; Sastry, G.; Askell, A. Language models are few-shot learners. Advances in neural \ninformation processing systems 2020, 33, 1877-1901, doi:10.48550/arXiv.2005.14165. \n8. Wogu, I.A.P.; Olu -Owolabi, F.E.; Assibong, P.A.; Agoha, B.C.; Sholarin, M.; Elegbeleye, \nA.; Igbokwe, D.; Apeh, H.A. Artificial intelligence, alienation and ontological problems of \nother minds: A critical investigation into the future of man and machines. In Proceedings \nof the 2017 International Conference on Computing Networking and Informatics (ICCNI), \n29-31 Oct. 2017, 2017; pp. 1-10. \n9. Howard, J. Artificial intelligence: Implications for the future of work. American Journal of \nIndustrial Medicine 2019, 62, 917-926, doi:10.1002/ajim.23037. \n10. Tai, M.C. The impact of artificial intelligence on human society and bioethics. Tzu Chi Med \nJ 2020, 32, 339-343, doi:10.4103/tcmj.tcmj_71_20. \n11. Deng, J.; Lin, Y. The Benefits and Challenges of ChatGPT: An Overview. Frontiers in \nComputing and Intelligent Systems 2023, 2, 81-83, doi:10.54097/fcis.v2i2.4465. \n12. Tobore, T.O. On Energy Efficiency and the Brain's Resistance to Change: The Neurological \nEvolution of Dogmatism and Close -Mindedness. Psychol Rep 2019, 122, 2406- 2416, \ndoi:10.1177/0033294118792670. \n13. Stokel-Walker, C. AI bot ChatGPT writes smart essays - should professors worry? Nature \n2022, doi:10.1038/d41586-022-04397-7. \n14. Stokel-Walker, C.; Van Noorden, R. What ChatGPT and generative AI mean for science. \nNature 2023, 614, 214-216, doi:10.1038/d41586-023-00340-6. \n15. Chatterjee, J.; Dethlefs, N. This new conversational AI model can be your friend, \nphilosopher, and guide ... and even your worst enemy. Patterns (N Y) 2023, 4, 100676, \ndoi:10.1016/j.patter.2022.100676. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n30 \n16. Sallam, M.; Salim, N.A.; Al-Tammemi, A.B.; Barakat, M.; Fayyad, D.; Hallit, S.; Hara pan, \nH.; Hallit, R.; Mahafzah, A. ChatGPT Output Regarding Compulsory Vaccination and \nCOVID-19 Vaccine Conspiracy: A Descriptive Study at the Outset of a Paradigm Shift in \nOnline Search for Information. Cureus 2023, 15, e35029, doi:10.7759/cureus.35029. \n17. Johnson, K.B.; Wei, W.Q.; Weeraratne, D.; Frisse, M.E.; Misulis, K.; Rhee, K.; Zhao, J.; \nSnowdon, J.L. Precision Medicine, AI, and the Future of Personalized Health Care. Clin \nTransl Sci 2021, 14, 86-93, doi:10.1111/cts.12884. \n18. Rajpurkar, P.; Chen, E.; Banerjee, O.; Topol, E.J. AI in health and medicine. Nature Medicine \n2022, 28, 31-38, doi:10.1038/s41591-021-01614-0. \n19. Paranjape, K.; Schinkel, M.; Nannan Panday, R.; Car, J.; Nanayakkara, P. Introducing \nArtificial Intelligence Training in Medical Edu cation. JMIR Med Educ 2019, 5, e16048, \ndoi:10.2196/16048. \n20. Moher, D.; Liberati, A.; Tetzlaff, J.; Altman, D.G. Preferred reporting items for systematic \nreviews and meta -analyses: the PRISMA statement. PLoS Med 2009, 6, e1000097, \ndoi:10.1371/journal.pmed.1000097. \n21. Harzing, A. -W. Publish or Perish. Available online: \nhttps://harzing.com/resources/publish-or-perish\n (accessed on 16 February 2023). \n22. Kumar, A. Analysis of ChatGPT Tool to Assess the Potential of its Utility for Academic \nWriting in Biomedical Domain. Biology, Engineering, Medicine and Science Reports 2023, 9, \n24–30, doi:10.5530/bems.9.1.5. \n23. Wang, S.; Scells, H.; Koopman, B.; Zuccon, G. Can ChatGPT Write a Good Boolean Query \nfor Systematic Review Literature Search? arXiv preprint 2023, eprint: arXiv:2302.03495 , \ndoi:10.48550/arXiv.2302.03495. \n24. Borji, A. A Categorical Archive of ChatGPT Failu res. arXiv preprint 2023, Preprint, \ndoi:10.48550/arXiv.2302.03494. \n25. Zielinski, C.; Winker, M.; Aggarwal, R.; Ferris, L.; Heinemann, M.; Lapeña, J.; Pai, S.; Ing, \nE.; Citrome, L. Chatbots, ChatGPT, and Scholarly Manuscripts WAME Recommendations \non ChatGPT and Chatbots in Relation to Scholarly Publications. Maced J Med Sci [Internet] \n2023, 11, 83-86, doi:10.3889/oamjms.2023.11502. \n26. Chen, T.J. ChatGPT and other artificial intelligence applications speed up scientific \nwriting. J Chin Med Assoc 2023, doi:10.1097/jcma.0000000000000900. \n27. Biswas, S. ChatGPT and the Future of Medical Writing. Radiology 2023, 223312, \ndoi:10.1148/radiol.223312. \n28. Thorp, H.H. ChatGPT is fun, but not an author. Science 2023, 379, 313, \ndoi:10.1126/science.adg7879. \n29. Kitamura, F.C. ChatGPT Is Shaping the Future of Medical Writing but Still Requires \nHuman Judgment. Radiology 2023, 230171, doi:10.1148/radiol.230171. \n30. Stokel-Walker, C. ChatGPT listed as author on research papers: many scientists \ndisapprove. Nature 2023, 613, 620-621, doi:10.1038/d41586-023-00107-z. \n31. Lubowitz, J. ChatGPT, An Artificial Intelligence Chatbot, Is Impacting Medical Literature. \nArthroscopy 2023, In press, doi:10.1016/j.arthro.2023.01.015. \n32. van Dis, E.A.M.; Bollen, J.; Zuidema, W.; van Rooij, R.; Bockting, C.L. ChatGPT: five \npriorities for research. Nature 2023, 614, 224-226, doi:10.1038/d41586-023-00288-7. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n31 \n33. Lund, B.; Wang, S. Chatting about ChatGPT: how may AI and GPT impact academia and \nlibraries? Library Hi Tech News 2023, ahead-of-print, doi:10.1108/LHTN-01-2023-0009. \n34. Cotton, D.; Cotton, P.; Shipway, J. Chatting and Cheating. Ensuring academic integrity in \nthe era of ChatGPT. EdArXiv 2023, Preprint, doi:10.35542/osf.io/mrz8h. \n35. Gao, C.A.; Howard, F.M.; Markov, N.S.; Dyer, E.C.; Ramesh, S.; Luo, Y.; Pearson, A.T. \nComparing scientific abstracts generated by ChatGPT to original abstracts using an \nartificial intelligence output detector, plagiarism detector, and blinded human reviewers. \nbioRxiv 2022, Preprint, doi:10.1101/2022.12.23.521610. \n36. Liebrenz, M.; Schleifer, R.; Buadze, A.; Bhugra, D.; Smith, A. Generating scholarly content \nwith ChatGPT: ethical challenges for medical publishing. Lancet Digit Health 2023, Online \nfirst, doi:10.1016/s2589-7500(23)00019-5. \n37. Polonsky, M.; Rotman, J . Should Artificial Intelligent (AI) Agents be Your Co -author? \nArguments in favour, informed by ChatGPT. SSRN 2023, Preprint, \ndoi:10.2139/ssrn.4349524. \n38. Nature editorial. Tools such as ChatGPT threaten transparent science; here are our ground \nrules for their use. Nature 2023, 613, 612, doi:10.1038/d41586-023-00191-1. \n39. Aczel, B.; Wagenmakers, E. Transparency Guidance for ChatGPT Usage in Scientific \nWriting. PsyArXiv 2023, Preprint, doi:10.31234/osf.io/b58ex. \n40. Manohar, N.; Prasad, S.S. Use of ChatGPT in Academic Publishing: A Rare Case of \nSeronegative Systemic Lupus Erythematosus in a Patient With HIV Infection. Cureus 2023, \n15, e34616, doi:10.7759/cureus.34616. \n41. Akhter, H.M.; Cooper, J.S. Acute Pulmonary Edema After Hyperbaric Oxygen Treatment: \nA Case Report Written With ChatGPT Assistance. Cureus 2023, 15, e34752, \ndoi:10.7759/cureus.34752. \n42. Holzinger, A.; Keiblinger, K.; Holub, P.; Zatloukal, K.; Müller, H. AI for life: Trends in \nartificial intelligence f or biotechnology. N Biotechnol 2023, 74, 16 -24, \ndoi:10.1016/j.nbt.2023.02.001. \n43. Mann, D. Artificial Intelligence Discusses the Role of Artificial Intelligence in \nTranslational Medicine: A JACC: Basic to Translational Science Interview With ChatGPT. \nJ Am Coll Cardiol Basic Trans Science 2023, E-published, doi:10.1016/j.jacbts.2023.01.001. \n44. De Angelis, L.; Baglivo, F.; Arzilli, G.; Privitera, G.P.; Ferragina, P.; Tozzi, A.E.; Rizzo, C. \nChatGPT and the Rise of Large Language Models: The New AI-Driven Infodemic Threat \nin Public Health. SSRN 2023, Preprint, doi:10.2139/ssrn.4352931. \n45. Benoit, J. ChatGPT for Clinical Vignette Generation, Revision, and Evaluation. medRxiv \n2023, Preprint, doi:10.1101/2023.02.04.23285478. \n46. Sharma, G.; Thakur, A. ChatGPT in Drug Discovery. ChemRxiv 2023, Preprint, \ndoi:10.26434/chemrxiv-2023-qgs3k. \n47. Moons, P.; Van Bulck, L. ChatGPT: Can artificial intelligence language models be of value \nfor cardiovascular nurses and allied health professionals. Eur J Cardiovasc Nurs 2023, \nOnline ahead of print, doi:10.1093/eurjcn/zvad022. \n48. Patel, S.B.; Lam, K. ChatGPT: the future of discharge summaries? Lancet Digit Health 2023, \nOnline first, doi:10.1016/s2589-7500(23)00021-3. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n32 \n49. Cahan, P.; Treutlein, B. A conversation with ChatGPT on the role of computational \nsystems biology in  stem cell research. Stem Cell Reports 2023, 18, 1 -2, \ndoi:10.1016/j.stemcr.2022.12.009. \n50. Rao, A.; Kim, J.; Kamineni, M.; Pang, M.; Lie, W.; Succi, M.D. Evaluating ChatGPT as an \nAdjunct for Radiologic Decision-Making. medRxiv 2023, doi:10.1101/2023.02.02.23285399. \n51. Antaki, F.; Touma, S.; Milad, D.; El -Khoury, J.; Duval, R. Evaluating the Performance of \nChatGPT in Ophthalmology: An Analysis of its Successes and Shortcomings. medRxiv \n2023, Preprint, 2023.2001.2022.23284882, doi:10.1101/2023.01.22.23284882. \n52. Ahn, C. Exploring ChatGPT for information of cardiopulmonary resuscitation. \nResuscitation 2023, 185, 109729, doi:10.1016/j.resuscitation.2023.109729. \n53. Gunawan, J. Exploring the future of nursing: Insights from the ChatGPT model. Belitung \nNursing Journal 2023, 9, 1-5, doi:10.33546/bnj.2551. \n54. D'Amico, R.S.; White, T.G.; Shah, H.A.; Langer, D.J. I Asked a ChatGPT to Write an \nEditorial About How We Can Incorporate Chatbots Into Neurosurgical Research and \nPatient Care…. Neurosurgery 2023, Online ahead of print, \ndoi:10.1227/neu.0000000000002414. \n55. Aydın, Ö.; Karaarslan, E. OpenAI ChatGPT generated literature review: Digital twin in \nhealthcare. SSRN 2022, Preprint, doi:10.2139/ssrn.4308687. \n56. Zhavoronkov, A. Rapamycin in the context of Pascal's Wager: generative pre -trained \ntransformer perspective. Oncoscience 2022, 9, 82-84, doi:10.18632/oncoscience.571. \n57. Hallsworth, J.E.; Udaondo, Z.; Pedrós -Alió, C.; Höfer, J.; Benison, K.C.; Lloyd, K.G.; \nCordero, R.J.B.; de Campos, C.B.L.; Yakimov, M.M.; Amils, R. Scientific novelty beyond \nthe experiment. Microb Biotechnol 2023, Online ahead of print, doi:10.1111/1751-7915.14222. \n58. Sanmarchi, F.; Bucci, A.; Golinelli, D. A step-by -step Researcher’s Guide to the use of an \nAI-based transformer in epidemiology: an exploratory analysis of ChatGPT using the \nSTROBE checklist for observational studies. medRxiv 2023, Preprint, \n2023.2002.2006.23285514, doi:10.1101/2023.02.06.23285514. \n59. Duong, D.; Solomon, B.D. Analysis of large -language model versus human performance \nfor genetics questions. medRxiv 2023, Preprint, doi:10.1101/2023.01.27.23285115. \n60. Huh, S. Are ChatGPT’s knowledge and interpretation ability comparable to those of \nmedical students in Korea for taking a parasitology examination?: a descriptive study. J \nEduc Eval Health Prof 2023, 20, 1, doi:10.3352/jeehp.2023.20.1. \n61. Yeo, Y.H.; Samaan, J.S.; Ng, W.H.; Ting, P.-S.; Trivedi, H.; Vipani, A.; Ayoub, W.; Yang, \nJ.D.; Liran, O.; Spiegel, B.; et al. Assessing the performance of ChatGPT in answering \nquestions regarding cirrhosis and hepatocellula r carcinoma. medRxiv 2023, Preprint, \n2023.2002.2006.23285449, doi:10.1101/2023.02.06.23285449. \n62. Bašić, Ž.; Banovac, A.; Kružić, I.; Jerković, I. Better by You, better than Me? ChatGPT-3 as \nwriting assistance in students' essays. arXiv 2023, Preprint, doi:10.48550/arXiv.2302.04536. \n63. Fijačko, N.; Gosak, L.; Štiglic, G.; Picard, C.T.; John Douma, M. Can ChatGPT Pass the Life \nSupport Exams without Entering the American Heart Association Course? Resuscitation \n2023, Online ahead of print, 109732, doi:10.1016/j.resuscitation.2023.109732. \n64. Hisan, U.; Amri, M. ChatGPT and Medical Education: A Double -Edged Sword. \nResearchgate 2023, Preprint, doi:10.13140/RG.2.2.31280.23043/1. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n33 \n65. Jeblick, K.; Schachtner, B.; Dexl, J.; Mittermeier, A.; Stüber, A.T.; Topalis, J.; Weber, T.; \nWesp, P.; Sabel, B.; Ricke, J.; et al. ChatGPT Makes Medicine Easy to Swallow: An \nExploratory Case Study on Simplified Radiology Reports. arXiv 2022, Preprint, \ndoi:10.48550/arxiv.2212.14882. \n66. Mbakwe, A.B.; Lourentzou, I.; Celi, L.A.; Mechanic, O.J.; Dagan, A. ChatGPT passing \nUSMLE shines a spotlight on the flaws of medical education. PLOS Digital Health 2023, 2, \ne0000205, doi:10.1371/journal.pdig.0000205. \n67. Khan, A.; Jawaid, M.; Khan, A.; Sajjad, M. ChatGPT -Reshaping medical education and \nclinical management. Pakistan Journal of Medical Sciences 2023, 39, 605 -607, \ndoi:10.12669/pjms.39.2.7653. \n68. Gilson, A.; Safranek, C.W.; Huang, T.; Socrates, V.; Chi, L.; Taylor, R.A.; Chartash, D. How \nDoes ChatGPT Perform on the United States Medical Licensing Examination? The \nImplications of Large Language Models for Medical Education and Knowledge \nAssessment. JMIR Med Educ 2023, 9, e45312, doi:10.2196/45312. \n69. Nisar, S.; Aslam, M. Is ChatGPT a Good Tool for T&CM Students in Studying \nPharmacology? SSRN 2023, Preprint, doi:10.2139/ssrn.4324310. \n70. Huh, S. Issues in the 3rd year of the COVID-19 pandemic, including computer -based \ntesting, study design, ChatGPT, journal metrics, and appreciation to reviewers. J Educ Eval \nHealth Prof 2023, 20, 5, doi:10.3352/jeehp.2023.20.5. \n71. O'Connor, S. Open artificial intelligence platforms in nursing education: Tools for \nacademic progress or abuse? Nurse Educ Pract 2023, 66, 103537, \ndoi:10.1016/j.nepr.2022.103537. \n72. Kung, T.H.; Cheatham, M.; Medenilla, A.; Sillos, C.; De Leon, L.; Elepaño, C.; Madriaga, \nM.; Aggabao, R.; Diaz -Candido, G.; Maningo, J.; et al. Performance of ChatGPT on \nUSMLE: Potential for AI-assisted medical education using large language models. PLOS \nDigital Health 2023, 2, e0000198, doi:10.1371/journal.pdig.0000198. \n73. Lin, Z. Why and how to embrace AI such as ChatGPT in your academic life. PsyArXiv \n2023, Preprint, doi:10.31234/osf.io/sdx3j. \n74. Shen, Y.; Heacock, L.; Elias, J.; Hentel, K.D.; Reig, B.; Shih, G.; Moy, L. ChatGPT and Other \nLarge Language Models Are Double -edged Swords. Radiology 2023, 230163, \ndoi:10.1148/radiol.230163. \n75. Gordijn, B.; Have, H.t. ChatGPT: evolution or revolution? Medicine, Health Care and \nPhilosophy 2023, doi:10.1007/s11019-023-10136-0. \n76. Mijwil, M.; Aljanabi, M.; Ali, A. ChatGPT: Exploring the Role of Cybersecurity in the \nProtection of Medical Information. Mesopotamian Journal of CyberSecurity 2023, 18 –21, \ndoi:10.58496/MJCS/2023/004. \n77. The Lancet Digital Health. ChatGPT: friend or foe? Lancet Digit Health 2023, \ndoi:10.1016/s2589-7500(23)00023-7. \n78. Aljanabi, M.; Ghazi, M.; Ali, A.; Abed, S. ChatGpt: Open Possibilities. Iraqi Journal For \nComputer Science and Mathematics 2023, 4, 62–64, doi:10.52866/IJCSM.2023.01.01.0018. \n79. Marchandot, B.; Matsushita, K.; Carmona, A.; Trimaille, A.; Morel, O. ChatGPT: The Next \nFrontier in Academic Writing for Cardiologists or a Pandora's Bo x of Ethical Dilemmas. \nEuropean Heart Journal Open 2023, oead007, doi:10.1093/ehjopen/oead007. \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint \n34 \n80. Smith, R. Peer review: a flawed process at the heart of science and journals. J R Soc Med \n2006, 99, 178-182, doi:10.1177/014107680609900414. \n81. Mavrogenis, A.F.; Quaile, A.; Scarlat, M.M. The good, the bad and the rude peer -review. \nInternational Orthopaedics 2020, 44, 413-415, doi:10.1007/s00264-020-04504-1. \n82. Margalida, A.; Colomer, M. Improving the peer-review process and editorial quality: key \nerrors escaping the review and editorial process in top scientific journals. PeerJ 2016, 4, \ne1670, doi:10.7717/peerj.1670. \n83. Kostick-Quenet, K.M.; Gerke, S. AI in the  hands of imperfect users. npj Digital Medicine \n2022, 5, 197, doi:10.1038/s41746-022-00737-z. \n \n . CC-BY-NC-ND 4.0 International licenseIt is made available under a \n is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. (which was not certified by peer review)\nThe copyright holder for this preprint this version posted February 21, 2023. ; https://doi.org/10.1101/2023.02.19.23286155doi: medRxiv preprint ",
  "topic": "Health care",
  "concepts": [
    {
      "name": "Health care",
      "score": 0.6643844842910767
    },
    {
      "name": "Documentation",
      "score": 0.6029016375541687
    },
    {
      "name": "Context (archaeology)",
      "score": 0.5550336837768555
    },
    {
      "name": "Systematic review",
      "score": 0.5228605270385742
    },
    {
      "name": "Transparency (behavior)",
      "score": 0.5056421756744385
    },
    {
      "name": "MEDLINE",
      "score": 0.46631038188934326
    },
    {
      "name": "Grey literature",
      "score": 0.43582671880722046
    },
    {
      "name": "Medical education",
      "score": 0.38903436064720154
    },
    {
      "name": "Computer science",
      "score": 0.38483041524887085
    },
    {
      "name": "Medicine",
      "score": 0.33929145336151123
    },
    {
      "name": "Psychology",
      "score": 0.3362137973308563
    },
    {
      "name": "Political science",
      "score": 0.2135159969329834
    },
    {
      "name": "Paleontology",
      "score": 0.0
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Biology",
      "score": 0.0
    },
    {
      "name": "Computer security",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I2800233941",
      "name": "Jordan Hospital",
      "country": "JO"
    },
    {
      "id": "https://openalex.org/I114972647",
      "name": "University of Jordan",
      "country": "JO"
    }
  ],
  "cited_by": 233
}