{
  "title": "Identifying informative tweets during a pandemic via a topic-aware neural language model",
  "url": "https://openalex.org/W4221074297",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2096420133",
      "name": "Wang Gao",
      "affiliations": [
        "Jianghan University"
      ]
    },
    {
      "id": "https://openalex.org/A2081884318",
      "name": "Lin Li",
      "affiliations": [
        "Wuhan University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2144301289",
      "name": "Xiaohui Tao",
      "affiliations": [
        "University of Southern Queensland"
      ]
    },
    {
      "id": "https://openalex.org/A2086205026",
      "name": "Jing Zhou",
      "affiliations": [
        "Jianghan University"
      ]
    },
    {
      "id": "https://openalex.org/A2146498018",
      "name": "Jun Tao",
      "affiliations": [
        "Jianghan University"
      ]
    },
    {
      "id": "https://openalex.org/A2096420133",
      "name": "Wang Gao",
      "affiliations": [
        "Jianghan University"
      ]
    },
    {
      "id": "https://openalex.org/A2081884318",
      "name": "Lin Li",
      "affiliations": [
        "Wuhan University of Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2144301289",
      "name": "Xiaohui Tao",
      "affiliations": [
        "University of Southern Queensland"
      ]
    },
    {
      "id": "https://openalex.org/A2086205026",
      "name": "Jing Zhou",
      "affiliations": [
        "Jianghan University"
      ]
    },
    {
      "id": "https://openalex.org/A2146498018",
      "name": "Jun Tao",
      "affiliations": [
        "Jianghan University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2405148542",
    "https://openalex.org/W3035937838",
    "https://openalex.org/W3104613320",
    "https://openalex.org/W2048195127",
    "https://openalex.org/W3033369204",
    "https://openalex.org/W2996478248",
    "https://openalex.org/W4205794973",
    "https://openalex.org/W2905234665",
    "https://openalex.org/W2991696912",
    "https://openalex.org/W3084727607",
    "https://openalex.org/W3046650820",
    "https://openalex.org/W3168771658",
    "https://openalex.org/W2514450663",
    "https://openalex.org/W3086807592",
    "https://openalex.org/W3037111525",
    "https://openalex.org/W2745475103",
    "https://openalex.org/W3013573132",
    "https://openalex.org/W3108634112",
    "https://openalex.org/W3043958695",
    "https://openalex.org/W2487843204",
    "https://openalex.org/W3157714956",
    "https://openalex.org/W2888482885",
    "https://openalex.org/W3099342932",
    "https://openalex.org/W3023180635",
    "https://openalex.org/W3092441108",
    "https://openalex.org/W3131645232",
    "https://openalex.org/W3092870704",
    "https://openalex.org/W2964032708",
    "https://openalex.org/W3030145375",
    "https://openalex.org/W3185103244",
    "https://openalex.org/W3094122194",
    "https://openalex.org/W2891585127",
    "https://openalex.org/W798021849",
    "https://openalex.org/W4205902690",
    "https://openalex.org/W2778699319"
  ],
  "abstract": null,
  "full_text": "Vol.:(0123456789)\nhttps://doi.org/10.1007/s11280-022-01034-1\n1 3\nIdentifying informative tweets during a pandemic \nvia a topic‑aware neural language model\nWang Gao1  · Lin Li2 · Xiaohui Tao3 · Jing Zhou1 · Jun Tao1\nReceived: 18 October 2021 / Revised: 20 January 2022 / Accepted: 28 February 2022 \n© The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2022\nAbstract\nEvery epidemic affects the real lives of many people around the world and leads to terri -\nble consequences. Recently, many tweets about the COVID-19 pandemic have been shared \npublicly on social media platforms. The analysis of these tweets is helpful for emergency \nresponse organizations to prioritize their tasks and make better decisions. However, most \nof these tweets are non-informative, which is a challenge for establishing an automated \nsystem to detect useful information in social media. Furthermore, existing methods ignore \nunlabeled data and topic background knowledge, which can provide additional semantic \ninformation. In this paper, we propose a novel Topic-Aware BERT (TABERT) model to \nsolve the above challenges. TABERT first leverages a topic model to extract the latent top-\nics of tweets. Secondly, a flexible framework is used to combine topic information with the \noutput of BERT. Finally, we adopt adversarial training to achieve semi-supervised learn -\ning, and a large amount of unlabeled data can be used to improve inner representations of \nthe model. Experimental results on the dataset of COVID-19 English tweets show that our \nmodel outperforms classic and state-of-the-art baselines.\nKeywords Informative tweet identification · Social media · Topic model · Adversarial \ntraining\nWang Gao and Lin Li contributed equally to this work.\nThis article belongs to the Topical Collection: Special Issue on Decision Making in Heterogeneous \nNetwork Data Scenarios and Applications\nGuest Editors: Jianxin Li, Chengfei Liu, Ziyu Guan, and Yinghui Wu\n * Wang Gao \n gaow@jhun.edu.cn\n * Lin Li \n cathylilin@whut.edu.cn\n1 School of Artificial Intelligence, Jianghan University, 430056 Wuhan, China\n2 School of Computer Science and Artificial Intelligence, Wuhan University of Technology, \n430070 Wuhan, China\n3 School of Sciences, University of Southern Queensland, 4072, Queensland, Toowoomba, Australia\nPublished online: 16 March 2022\nWorld Wide Web (2023) 26:55–70\n/\n1 3\n1 Introduction\nThe popularity of social networks has generated a large amount of social interaction \nbetween users, which in turn produces massive unstructured textual data [15, 22]. In recent \nyears, social media platforms such as Twitter and Facebook have received widespread \nattention as a possible tool for tracking a pandemic [1, 24, 26]. The main reason is that \nthese platforms can provide real-time monitoring at a lower cost than conventional moni-\ntoring systems. For example, by the end of September 2021, the COVID-19 pandemic has \ncaused approximately 4.6 million deaths and 228.4 million infected cases worldwide\n1. Mil-\nlions of people are using social media platforms to share information related to COVID-19 \nsuch as testing or travel history.\nHowever, although there are massive COVID-19 related posts on Twitter, only a few of \nthem can provide useful information for monitoring systems. Manual detection of informa-\ntive tweets is costly and ineffective for large amounts of data. Therefore, there is an urgent \nneed to develop automated systems that can identify informative tweets. These tweets \ncontain geographic location and information about confirmed, suspected and death cases. \nMany studies regard this problem as a binary classification task that classifies a related \ntweet as informative or non-informative [9, 25, 35].\nRecently, the pre-trained language model Bidirectional Encoder Representations from \nTransformers (BERT) has achieved impressive performance improvements in various \nNatural Language Processing (NLP) tasks such as text classification and event detection \n[7]. The BERT model utilizes a large amount of textual data to pre-train encoders, and \nthen makes effective fine-tuning for a certain target task. Although great progress has been \nmade, identifying informative tweets during a pandemic remains a challenging issue. This \nis due to the short length and high noise of tweets, and high levels of text overlap between \nthe two categories. Probabilistic topic models may provide additional topic information for \nsemantic differences, and the latest research on neural networks has shown that topic inte-\ngration can improve the performance of NLP tasks such as summarization and question \nanswering [8, 11, 38]. However, there is no standard method to integrate topic informa-\ntion with pre-trained language models such as BERT. Furthermore, when there are huge \namounts of labeled data in a classification task, BERT can achieve state-of-the-art results. \nUnfortunately, obtaining annotated instances is time-consuming and requires expensive \nhuman labor.\nTo address the above challenges, we design a novel model based on BERT to detect \ninformative tweets during a pandemic. The main idea of the proposed model is derived \nfrom the answers to the following questions: (1) How to combine topic knowledge and \nBERT to learn distinguishable representations of short texts for informative tweet detec-\ntion? (2) When there is little labeled data, how to extend the BERT model to improve its \ngeneralization ability?\nSpecifically, we propose a Topic-Aware BERT (TABERT) model that combines topic \nmodeling with BERT using a simple architecture. TABERT leverages a three-stage frame-\nwork to solve both topic integration and generalization capability issues in informative \ntweet detection. In the first stage, TABERT utilizes a Conditional Random Field regular -\nized Topic Model (CRFTM) [10] to extract the topic information of tweets. CRFTM first \nmerges short texts into long pseudo-documents using an embedding-based distance metric. \n1 https://  coron  avirus.  jhu.  edu/  map.  html\n56 World Wide Web (2023) 26:55–70\n1 3\nSemantic correlations are then integrated into the topic model to increase the probability \nthat semantically related words belong to the same topic. Secondly, TABERT concatenates \nthe topic distribution extracted by CRFTM with the last layer of BERT as the represen-\ntation of a tweet. In the third stage, the proposed model extends the fine-tuning process \nof BERT from the perspective of the Generative Adversarial Network (GAN) [14], which \nconducts adversarial training in a zero-sum game. TABERT is used as a discriminator to \nclassify tweets as informative or non-informative, and a generator generates “false” tweets \nsimilar to the distribution of real data. In this way, we can employ unlabeled tweets to \nimprove the performance and generalization ability of the proposed model. To evaluate \nthe performance of TABERT, we conduct extensive experiments on a COVID-19 related \ndataset. Experimental results demonstrate that the performance of the proposed model is \nsignificantly better than state-of-the-art baselines. This paper makes three main contribu-\ntions as follows:\n1.\n W\ne propose a new Topic-Aware BERT (TABERT) model to identify informative tweets \nduring a pandemic. TABERT adopts CRFTM to discover hidden topics of tweets. We \ncombine topic information with BERT, which helps to enrich the semantics of short \ntexts. To the best of our knowledge, this is the first work to integrate topic information \ncaptured by CRFTM into BERT.\n2.\n T\nABERT exploits adversarial training to achieve semi-supervised learning in a GAN \nstructure. The proposed model trains a generator to produce new tweets, and a discrimi-\nnator is used to classify tweets as generated or real. Therefore, we train the discriminator \nwith labeled tweets, while unlabeled tweets improve the output representation of the \nmodel.\n3.\n Exper\nimental results on a COVID-19 related dataset show that the proposed model \nachieves improvements against state-of-the-art baseline methods. Furthermore, \nTABERT can still achieve comparable performance in identifying informative tweets, \neven though the number of annotated tweets is drastically reduced.\nThe rest of the paper is arranged as follows. Section 2 reviews the work related to TABERT. \nSection 3 describes the details of the proposed model. Section 4 contains experiments with \nevaluations and comparisons. Finally, we conclude the paper in Section 5.\n2  Related work\nThere have been many research reports on how to effectively use disaster-related tweets \nfor situational awareness during emergencies and disasters [5, 6]. Discovering informative \ncontent from social media platforms is an important task for government agencies and res-\ncue organizations [2, 41]. In this section, we give a brief overview of the work related to \nTABERT.\nDeep neural networks have made impressive progress in various artificial intelligence \ntasks over recent years [32, 36, 40]. These techniques are widely used in NLP to extract \ntextual features [12, 23, 39]. Neppalli et al. proposed various neural network models based \non Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) to iden-\ntify informative tweets [28]. They found that in different natural disasters, deep neural \nnetworks have better generalization ability than traditional machine learning techniques. \nKumar et  al. proposed a multi-modal neural network that uses multi-modal features to \n57World Wide Web (2023) 26:55–70\n1 3\ndetect disaster-related information from social media [19]. They employed Long Short-\nTerm Memory (LSTM) and VGG-16 to extract textual and visual features respectively, \nwhich proved to be better than using text or images alone. Gao et al. also proposed a multi-\nmodal neural network that captures the transferable features shared between different dis-\naster events [13]. The model utilizes adversarial training to evaluate the similarity between \ndifferent events and improve its performance in emerging disaster events.\nFurthermore, Roy et al. proposed a summarization and classification method to detect \ninformative social media data during a disaster [30]. In their model, a Support Vector \nMachine (SVM) is trained to capture Parts of Speech (POS) tags and other features to iden-\ntify informative short texts. After that, they used an abstractive summarization algorithm to \nobtain a real-time informative summary from these short texts. Zahera et al. added several \nstacked layers on top of BERT, and then applied the model to the multi-label classification \nof short texts [42]. They first preprocessed short texts in social media and then input them \ninto BERT, leading to better results.\nDue to the increasing amount of social media data associated with COVID-19, there \nhave been many studies to explore the intent and content of these data. Singh et al. ana-\nlyzed COVID-19 related social media data based on location, content and error message \npropagation [34]. The results show that despite the existence of a large amount of noise \ninformation, there is a significant spatio-temporal relationship between social media data \nand new cases of COVID-19. Shahi et al. presented a comprehensive study of social media \nanalysis techniques applicable to the COVID-19 epidemic [33]. They analyzed the differ -\nences between error messages and other COVID-19 related tweets, and how they spread. \nHowever, the above methods ignore topic information or unlabeled data, which can \nimprove the performance of informative tweet identification.\nTopic knowledge is able to provide additional information for short text classification \n[17]. Zeng et al. proposed a topic memory network that encodes topic representations and \nclassifies documents by memory networks [43]. Chaudhary et al. proposed a text classifica-\ntion model that combines topic modeling and a neural language model [3]. Their approach \nconsists of two components: Neural Variational Document Model (NVDM) and BERT for \ncomplementary and efficient document understanding. However, due to the short length \nof each tweet and lack of context, NVDM suffers from a severe feature sparsity problem. \nIn contrast, our model utilizes CRFTM to discover underlying topic knowledge in tweets, \nwhich has been shown to reveal more coherent topics from short texts. Furthermore, in \nComputer Vision (CV), GAN has been shown to be effective for semi-supervised learning. \nFor instance, Salimans et al. proposed a semi-supervised learning method based on GAN, \nwhich achieves competitive performance with less labeled data and a large number of unla-\nbeled data [31]. To the best of our knowledge, our model is the first to combine topic infor-\nmation and GAN into BERT to identify informative tweets.\n3  Methodology\nTABERT divides the process of identifying informative tweets during a pandemic into \nthree stages. In the first stage, we train the CRFTM model on all tweets, and extract the \ndocument-topic probability distribution of each tweet. In the second stage, we develop an \nefficient approach to combine topic information with BERT. Finally, TABERT utilizes \nunlabeled tweets in an adversarial training setting to extend the training process.\n58 World Wide Web (2023) 26:55–70\n1 3\n3.1  Topic extraction\nAs a common information extraction method, topic models have been widely applied \nin sentiment analysis, event detection and other NLP tasks. Traditional topic models \ninfer topics based on word co-occurrence patterns in documents. However, the features \nof short texts are sparse, and it is difficult to provide sufficient co-occurrence informa-\ntion for topic modeling. To alleviate the sparsity problem, we utilize CRFTM to extract \ntopic information of tweets. CRFTM first merges tweets into regular-sized pseudo-\ndocuments, and then combines word embeddings with word correlation knowledge to \nenhance the coherence of extracted topics.\nSpecifically, Embedding-based Minimum Average Distance (EMAD) is used to \nmeasure the distance between tweets [10]. EMAD is able to find semantically related \nwords in two different tweets, which may be assigned to the same topic label. Based on \na clustering algorithm, CRFTM then aggregates tweets into long pseudo-documents. \nNext, CRFTM draws a topic distribution \n/u1D73D∼ Dir(/u1D736) for the whole corpus. For each \ntopic k, the topic model draws a word distribution /u1D719k ∼ Dir(/u1D737) . /u1D6FC and /u1D6FD are Dirichlet \npriors. For each pseudo-document d, the topic model draws each word w di ∼ Mult(/u1D719zdi\n) \nand a topic assignment /u1D433d can be written as follows:\nwhere xdi represents the contextual words of the ith word, /u1D431d denotes the set of contextual \nwords for each word, /u1D6BF is a potential function that considers the impact of semantic rel-\nevance, and Nd denotes the number of words in d.\nIn CRFTM, collapsed Gibbs sampling can be adopted to do posterior inference. \nTherefore, the topic zdi of word w di in pseudo-document d  is derived as:\nwhere n(⋅)\n⋅,−di represents the number of times the word is assigned to topic k, when word w di \nis excluded from topic k or pseudo-document d. V denotes the dimension of the vocabulary.\nAccordingly, the document-topic distribution /u1D73D and the topic-word distribution /u1D753 \ncan be calculated as follows:\nwhere K is the number of topics. In the proposed model, two distributions representing the \ntopic information of tweets are integrated into BERT in different ways.\n(1)p(/u1D433d ∣ /u1D73Dd ,/u1D431d )=\nN d/uni220F.s1\ni=1\np(zdi ∣ /u1D73Dd )/u1D6BF(zdi,xdi),\n(2)p(zdi = k ∣ /u1D433d,−di, /u1D430)∝(n(w di)\nd,−di + /u1D6FC)\nn(w di)\nk,−di + /u1D6FD\nnk,−di + V /u1D6FD/u1D6BF(zdi = k, xdi),\n(3)/u1D703d,k =\nn(k)\nd + /u1D6FC\n∑K\nk=1 n(k)\nd + K /u1D6FC\n(4)/u1D719k,w =\nn(w)\nk + /u1D6FD\n∑V\nw=1 n(w)\nk + V/u1D6FD\n,\n59World Wide Web (2023) 26:55–70\n1 3\n3.2  T opic information fusion\nIn this section, we study how to fuse topic information and BERT to improve the perfor -\nmance of informative tweet detection. During pre-training, since the length of sentences \ninput to BERT is limited, it is more suitable for extracting the semantics of short texts. The \narchitecture of TABERT that combines topic information and BERT is shown in Figure  1. \nLet \nT ={ t1 ,t2 , ...,tj, ...,tn } be the input tweet, where n denotes the length of the tweet and \ntj represents the j-th token of the tweet. The input of BERT is a concatenation of token \nembeddings, segment embeddings and positional embeddings. Token embeddings are used \nto convert tokens into vector representations, while segment embeddings separate different \ntweets. BERT is based on the transformer structure that cannot encode the ordering infor -\nmation of input tweets [37]. Therefore, the BERT model takes advantage of the sequence \nof tweets by adding positional embeddings to the input representation.\nWe add these three embeddings element-wise to form a single vector \nE ={ e1 ,e2 , ...,ej, ...,en } , and t hen employ it as the input of an encoding layer. Subse-\nquently, BERT maps E into a sequence of hidden representations H ={ h1 ,h2 , ...,hj, ...,hn} \nby applying self-attention and multi-head attention mechanisms. An additional token [CLS] \nis appended to each input tweet as the first token, and its hidden state \nhc is the output repre-\nsentation of BERT:\nwhere dBERT  is the hidden dimension size of BERT. Following [21, 27], we combine BERT \nwith topic information at word and sentence levels respectively. For sentence-level topic \ninformation Rs , all w ords in a tweet are input to CRFTM to infer a document-topic distri-\nbution p(z ∣ d) for each tweet:\nFor word-level topic information Rw , T ABERT leverages Summation over Words (SW) \nrepresentations [21] to infer p(z ∣ d) , whic h has proved to be an ideal approach for tweets:\n(5)hc = BERT (T)∈ ℝdBERT ,\n(6)Rs = CRFTM ([t1 ,t2 , ...,tj, ...,tn]) ∈ ℝK .\nFig. 1  Ar chitecture of TABERT \ncombining topic information and \nBERT\n60 World Wide Web (2023) 26:55–70\n1 3\nwhere p(w ∣ d) is the number of times w occurs in d. Since topic features and textual fea-\ntures are structurally consistent, and semantically continuous and related, the proposed \nmodel directly combines sentence-level topic information with the output of BERT as:\nwhere ⊕ denotes the concatenation operator. The way of combining word-level topic infor-\nmation is as follows:\n3.3  Adversarial training\nBy training with additional unlabeled data in an adversarial training setting, Semi-supervised \nGAN (SGAN) proposed by [31] can significantly improve the effectiveness of a supervised \ntask. In the SGAN model, a discriminator module divides the data into \n(c + 1) classes. Real \ndata is classified as one of the target (1, ..., c) categories, while the data generated by a genera-\ntor is classified as a new “generated” class (c + 1).\nSpecifically, G and D represent the generator module and discriminator module respec-\ntively, while pG and pD are the generator distribution and real example distribution. We then \ndefine pm (y = c + 1 ∣ x) to provide the probability that a data point x belongs to a “generated” \nclass. pm (y ∈( 1, ...,c)∣ x) denotes the probability that x  is a real data, which is associated \nwith an original category. To train a semi-supervised c-class classifier, the objective function \nLD of D can be defined as:\nThe total cross-entropy loss can be decomposed into a supervised loss Lsupervised and an \nunsupervised loss function Lunsupervised:\nwhere Lsupervised measures the cumulative loss of classifying real data into a wrong cat-\negory among the target c classes. Lunsupervised measures the cumulative loss of identifying \nreal unlabeled data as the generated class (c + 1) and identifying generated data as real.\nMeanwhile, the generator module G needs to generate data close to the data sampled from \nthe real example distribution pD . Therefore, G should generate examples that match the sta-\ntistics of real examples as much as possible. The goal of training the generator is to learn the \nexpected values of features on the middle layer of the discriminator. By training \nD , SGAN \ncap\ntures the features that can best distinguish the real data from the data generated by G . The \nmodel defines t\nhe feature matching objective function of the generator as:\n(7)Rw =\n/uni2211.s1\nw\np(z= k ∣ w)p(w ∣ d)∈ℝ K ,\n(8)O c = hc ⊕ Rs,\n(9)Oc = hc ⊕ Rw .\n(10)LD = Lsupervised + Lunsupervised .\n(11)\nLsupervised =−/u1D53Cx,y∼pD (x,y)log[pm (y ∈( 1, ...,c)∣x )]\nLunsupervised =−/u1D53Cx∼pD (x)log[1 − pm (y = c + 1 ∣ x)]\n− /u1D53Cx∼pG(x)log[pm (y = c + 1 ∣ x)],\n(12)Lfm =∣∣ /u1D53Cx ∼ pD(x)f(x)− /u1D53Cx ∼ pG(x)f(x) ∣∣ 2\n2 ,\n61World Wide Web (2023) 26:55–70\n1 3\nwhere f(x) denotes an activation function. When the examples generated by G are input to \nD , t heir feature representations are very similar to that of real data. SGAN also needs to \nconsider the error Lgenerated that the discriminator classifies the generated data as real:\nThe objective function of G is LG = Lfm + Lgenerated . Alt hough SGAN is usually applied \nin CV, we extend TABERT by using it to improve the performance of informative tweet \ndetection.\nIn this paper, SGAN and TABERT are combined in the fine-tuning phase. The pro-\nposed method adjusts the fine-tuning process of the TABERT model by adding an \nSGAN layer containing a discriminator and a generator. We employ the discriminator \nfor classification and the generator for semi-supervised learning. Figure  2 illustrates the \narchitecture of the TABERT model with adversarial training.\nAs shown in the figure, we add the SGAN framework to the top of TABERT by inte-\ngrating a discriminator \nD and a generator G . D classifies the input tweets as informative, \nnon-informative or generated, while G produces generated data for adversarial training. \nMore formally, D is a multi-layer perceptron whose input is vector ID . ID can be either \nOc that is the output of TABERT for real unlabeled or labeled tweets, or OG generated \nby G . The generator is also composed of a multi-layer perceptron, which receives noise \nvectors sampled from a Gaussian distribution N(/u1D707,/u1D70E2 ) and outputs a generated vector \nOG . Similar t o SGAN, a softmax layer is the last layer of D to classify tweets.\nIn the training process, when the input is a real tweet (i.e., ID = O c ), t he discrimina-\ntor should identify whether it contains useful information. When generated data is used \nas input (i.e., \nID = O G ), D should identify whether it is a real tweet. Two competitive \nlosses, LD and LG , can be op timized during the adversarial training process.\nUnlabeled tweets only contribute to the unsupervised loss of D (i.e., Lunsupervised ) dur-\ning bac\nk-propagation. In other words, only if they are incorrectly identified as generated \n(13)Lgenerated = /u1D53Cx ∼ pG(x)log[1− pm (y = c + 1 ∣ x)]\nFig. 2  Ar chitecture of TABERT \nwith adversarial training\n62 World Wide Web (2023) 26:55–70\n1 3\ntweets, they are considered in the loss calculation. Furthermore, their contribution to \nthe loss is not considered in other cases. Correspondingly, annotated tweets contribute \nto the supervised loss of the discriminator (i.e., \nLsupervised ). The g enerated data produced \nby the generator has an impact on both LD and LG . If D recognizes tweets generated by \nG , then G will be penalized, and vice versa. When training the discriminator, we also \nupdate TABERT to fine-tune its network weights, which requires consideration of both \nlabeled and unlabeled tweets.\nThe generator can be discarded after the model training is completed, while the rest of \nthe model can be used for inference. As a result, in actual use, there is no additional time \nconsumption compared to the TABERT model.\n4  Experiments\nIn this section, we conduct extensive experiments to validate the effectiveness of TABERT. \nThe performance is reported over a real-world tweet dataset, i.e., a COVID-19 related cor -\npus. The experimental results illustrate the effectiveness of the proposed model for inform-\native tweet detection.\n4.1  Dataset\nThe dataset used in the experiment is provided by [29], which contains informative Eng-\nlish COVID-19 tweets. In the dataset, informative tweets contain various information \nabout COVID-19 cases, as well as their location and travel history. To collect unlabeled \ndata, we first employ the Twitter API to crawl English tweets containing keywords such \nas “covid19”, “covid2019”, or “coronavirus”. These tweets usually contain lots of noisy \ntext. Hence, we perform the following data pre-processing techniques on tweets, which \nhelp TABERT achieve better performance: (1) convert all letters to lowercase; (2) utilize \nthe emoji library\n2 to replace emojis with short text descriptions; (3) replace all hyperlinks \nin the corpus with “URL”; (4) remove tweets with less than five words; (5) remove all non-\nalphabetic characters as well as unnecessary newlines, spaces and tabs.\nTo balance the dataset, we ask three annotators to label a portion of the collected tweets. \nThe annotators first divide tweets into two categories: “Informative” and “Non-Informa-\ntive”. A post is considered “Informative” if it contains information useful to emergency \nresponse organizations (e.g., location of suspected cases). If there is a disagreement \nbetween the annotators, the post is removed. Finally, we select 15,935 labeled tweets, con-\nsisting of 7,983 informative tweets and 7,952 non-informative tweets as well as 158,341 \nunlabeled tweets.\n4.2  Baseline methods\nIn the experiment, the following classic and state-of-the-art baseline methods are compared \nby precision, recall and F1-score:\n2 https://  pypi.  org/  proje  ct/  emoji/\n63World Wide Web (2023) 26:55–70\n1 3\n• CNN: CNN uses convolution filters to learn local features of documents. CNN not only \nshows encouraging results in CV, but also has been widely used in various NLP tasks.\n• BiLSTM: LSTM shows excellent performance in classification problems like short text \nclassification by extracting contextual features. BiLSTM further improves performance \nby comprehensively considering the bi-directional context information of words.\n• BERT: The architecture of BERT is based on a multi-layer bi-directional transformer \nmodel [7]. The model is pre-trained on a large-scale corpus such as Wikipedia, and \nreplaces RNN with a self-attention mechanism.\n• ALBERT: This is a variant of BERT that utilizes parameter reduction methods to \nreduce memory consumption and speed up BERT training [20]. To further boost the \nperformance, a self-supervised loss is introduced.\n• TABERT-G: TABERT-G is a variant of TABERT, but it does not use GAN to train \nthe model. Specifically, TABERT-G directly adds a softmax layer on the top of the \nTABERT model with word-level topic information to identify informative tweets.\nFor the topic model, we run 1,000 Gibbs sampling iterations and set the Dirichlet priors \n/u1D6FC= 50∕K , /u1D6FD= 0.01 . The number of t opics is 100, and other parameters are set according \nto the original paper. For adversarial training, D is a multi-layer perceptron with a hid-\nden layer, and the top softmax layer is used for classification. The generator is also imple-\nmented by a multi-layer perceptron with a hidden layer. A noise representation sampled \nfrom a Gaussian distribution \nN(0, 1) is used as the input of G . These noise r epresentations \nare converted by the multi-layer perceptron into vectors with the same size as the output of \nTABERT, which are used as generated data in adversarial training. For CNN and BiLSTM, \nthe word embedding we use is freely-available Glove\n3, and the dimension size is equal to \n300. We exploit these word embeddings to build a vector matrix that converts the words of \ninput tweets into corresponding vector representations. Binary cross-entropy loss is used to \ntrain these models, and the dropout rate is set to 0.2.\nAccording to the ratio of 7:2:1, the COVID-19 dataset is randomly divided into a train-\ning set, a validation set and a testing set. When the loss of the validation set for three con-\nsecutive epochs does not decrease, the training process of the model will stop. For BERT, \nwe employ a pre-trained 12-layer BERT-base\n4 architecture with 12 self-attention heads and \nthe hidden size of 768. The adam optimizer with a learning rate of 2e-5 is utilized to train \nthe model. For the ALBERT model, we use albert-base-v2\n5 with 12 repeating layers and \n11M parameters.\n4.3  Classification results\nFigure 3 illustrates the experimental results of our models and five baseline methods. It \ncan be intuitively seen from the classification results that TABERT with word-level topic \ninformation achieves the best performance. The F1-score of the proposed model is 4.1% \nhigher than BERT, and the precision and recall are 2.3% and 5.8% higher, respectively. \nThis experimental result validates that our model utilizes topic information and unlabeled \n3 http://  nlp.  stanf or d.  edu/  proje  cts/  glove/\n4 https://  github.  com/  google-  resea  rch/  bert\n5 https://  github.  com/  google-  resea  rch/  ALBERT\n64 World Wide Web (2023) 26:55–70\n1 3\ndata as an additional source of dataset-specific features, which is beneficial for achieving \nbetter classification performance.\nAs shown in the figure, the combination of TABERT and word-level topic information \nachieves better results than sentence-level topic information. As discussed in [21], regard-\nless of topic models or the number of topics, using the SW approach is more effective \nthan other approaches for the topic representations of short texts. The reason may be that \nthe direct use of a document-topic distribution to infer \np(z ∣ d) , whic h results in extremely \nsparse sentence-level topic information. Therefore, this is not an ideal approach for short \ntexts such as tweets. In the rest of the experiment, we only use TABERT with word-level \ntopic information to classify tweets.\nAdditionally, the performance of BiLSTM is better than CNN because Bi-LSTM is \ncapable of learning long-term dependencies without retaining repetitive contextual infor -\nmation. The experimental results of classical methods such as CNN and BiLSTM are \nworse than transformer-based models such as BERT and ALBERT. This may be because \nthe transformer structure depends on an attention mechanism to encode the interdepend-\nence between input and output for better parallelization. Another reason is that BERT can \nlearn high-quality vector representations of tweets by pre-training on a large-scale unla-\nbeled corpus. The performance of ALBERT is slightly worse than BERT may be due to its \nfewer parameters.\nTABERT-G adds CRFTM topics to BERT, and experimental results show that this \nmechanism leads to its performance better than other neural systems. The reason is that \nTABERT introduces topic information to extend the features of tweets, which can allevi-\nate data sparsity issues. By using unlabeled data, we show that TABERT-G is inferior to \nTABERT in this tweet detection task. The result indicates that adversarial training not only \nenhances the performance of the model, but also helps the model to be generalized better, \nwhich can also be observed in [13].\n4.4  Influenc e of topic models\nTo investigate whether adding topic information improves the performance of BERT, \nthe effects of four different short text topic models on informative tweet identification \nFig. 3  Exper imental results of \nseven methods\n65World Wide Web (2023) 26:55–70\n1 3\nare compared. Biterm Topic Model (BTM) directly models word co-occurrence infor -\nmation from short text datasets, and then extracts hidden topics [4]. In the BTM model, \nunordered word pairs that co-occur in a sliding window are called biterms. Latent Con-\ncept Topic Model (LCTM) treats each latent concept as a local Gaussian distribution in \nthe word embedding space, and each topic is a probability distribution over latent concepts \n[16]. Generalized P\n ́olya Urn Dirichlet Multinomial Mixture (GPU-DMM) utilizes the GPU \nmodel to promote semantically correlated words belonging to the same topic during train-\ning [21].\nFigure  4 illustrates the classification results of BERT, TABERT-G with BTM, \nTABERT-G with LCTM, TABERT-G with GPU-DMM and TABERT-G with CRFTM. \nFrom the figure, we can find that adding any kind of topic information to BERT improves \nthe performance of the model. The CRFTM model outperforms other models, which vali-\ndates that the combination of word semantic relations and CRF is beneficial for extract-\ning discriminative topic information. GPU-DMM achieves the second best performance in \nterms of F1-score. Furthermore, the performance of BTM is worse than GPU-DMM. The \nresult suggests that biterms may only bring little additional word co-occurrence patterns \nfor short text topic modeling. LCTM achieves the worst performance among all models. \nThis may be because tweets in the COVID-19 dataset are much shorter, and adding a latent \nconcept layer would cause more serious sparsity problems, resulting in worse topic infer -\nence results.\n4.5  A nalysis of semi‑supervised learning\nTo assess the impact of semi-supervised learning on TABERT, different scale labeled \ntweets are employed to identify informative tweets. We also report the performance of the \nBERT model on the same scale of training corpus as a comparison. We first randomly \nsample 1% (150 instances) of the entire labeled dataset. Secondly, we repeated the training \nof TABERT and BERT with gradually increasing labeled data. The proposed model also \nprovides 50 unlabeled examples for each labeled tweet to enable semi-supervised learning \nfrom a GAN perspective. We randomly sample the COVID-19 corpus five times and report \nthe average performance.\nFig. 4  Exper imental results of \ndifferent topic models\n66 World Wide Web (2023) 26:55–70\n1 3\nFigure 5 shows F1 scores of TABERT and BERT, with the ratio of annotated data used \nranging from 1 to 21. When 1% of data is available, the performance of BERT is poor, and \nthe proposed model achieves a score of more than 40%. This trend continues until 21% of \nlabeled tweets are used. Using more annotated tweets would result in closer F1 scores, but \nTABERT is always better than BERT. Experimental results demonstrate that the proposed \nmodel can improve the robustness of transformer-based architectures without incurring \nadditional costs. In the inference process, our model only needs the discriminator module, \nwhile the generator module is only utilized in the training phase.\n4.6  A ctionable information mining\nTo help emergency response organizations make better decisions and formulate corre-\nsponding strategies, after filtering out non-informative tweets, we can further classify \nthe informative content. This helps send a tweet with actionable information to a specific \nresponse agency to better understand the situation related to the epidemic, and deploy tar -\ngeted epidemic prevention and control work.\nFollowing [18], actionable information can be defined as information that can alert \nemergency response organizations of a certain type (e.g., injured people or infrastructure \ndamage). To avoid affecting the judgment of responding organizations, we divide the data \naccording to the following sufficient granularity:\n• Caution and advice: These tweets provide the public with some advice on the epi-\ndemic (e.g., “You can be a hero to children and elderly by simply staying at home”).\n• Emerging threats: These tweets report information that may lead to the spread of the \nepidemic (e.g., “A goat at a zoo tested positive for COVID-19”).\n• Render services: These tweets indicate that some people are providing services (e.g., \n“A hotel provides free rooms for medical staff fighting against COVID-19”).\n• Volunteer: These tweets ask people to volunteer in response to special events (e.g., \n“Hospital staff need you to help them make food”).\n• New event: These tweets report new incidents that relevant agencies need to respond to \nin a timely manner (e.g., “The subway station should be closed tonight because a staff  \nmember tested positive for covid-19”).\nFig. 5  F1 scor es for different \nratios of annotated data\n67World Wide Web (2023) 26:55–70\n1 3\nAccording to the above actionable information categories, Figure  6 shows the number \nof informative tweets for each category (posts that do not belong to any category are \ndiscarded). Table  1 reports the performance of TABERT and BERT in actionable infor -\nmation mining. As seen from the table, in the face of serious class imbalance, the pro-\nposed model is better than the BERT model under all metrics. As a result, TABERT \nis a model built on data collected during past epidemics, and can detect and track new \nevents to strengthen the decision-making process of government agencies.\n5  Conclusion\nIn this paper, we propose a new Topic-Aware BERT (TABERT) model to detect inform-\native posts on social media platforms such as Twitter. In the proposed model, CRFTM \nis first used to discover the topic knowledge of each tweet. Next, we design a simple \narchitecture to combine topic information with BERT. TABERT finally extends the \ntraining process with unlabeled tweets in a GAN framework. Experimental results show \nthat our model is not only better than baseline methods, but also reduces the require-\nment for annotated data. Since TABERT does not exploit the domain-specific features \nof the dataset, the model can be generalized for identifying informative tweets in differ -\nent domains. In the future, we will study how to introduce topic knowledge into BERT \nwithout corrupting pre-trained contextual information, and evaluate the model on large-\nscale datasets. Moreover, we will also explore how to directly apply adversarial training \nin the pre-training phase to further improve performance.\nAcknowledgements This w ork is supported by National Science Foundation of China (NSFC, No. \n62106086), Scientific Research Program of Hubei Provincial Department of Education (No. B2021063) and \nResearch Projects of Jianghan University (No. 2021yb062).\nFig.\n \n6\n  N\number of tweets for five \nactionable information types\nTable 1  P erformance of \nTABERT and BERT in \nactionable information mining\nModel Precision Recall F1\nBERT 0.6114 0.6037 0.5976\nTABERT 0.6530 0.6306 0.6373\n68 World Wide Web (2023) 26:55–70\n1 3\nDeclarations \nConflicts of interest The aut hors declare that they have no conflict of interest.\nReferences\n 1.  Al-g aradi, M.A., Khan, M.S., Varathan, K.D., Mujtaba, G., Al-Kabsi, A.M.: Using online social net-\nworks to track a pandemic: A systematic review. Journal of Biomedical Informatics 62, 1–11 (2016)\n 2.\n Cai, T\n., Li, J., Mian, A.S., Sellis, T., Yu, J.X., et al.: Target-aware holistic influence maximization in \nspatial social networks. IEEE Transactions on Knowledge and Data Engineering 34(4), 1993–2007 \n(2022)\n 3.\n Chaudhar\ny, Y., Gupta, P., Saxena, K., Kulkarni, V., Runkler, T.A., Schütze, H.: Topicbert for energy \nefficient document classification. In: Proceedings of Empirical Methods in Natural Language Process-\ning (EMNLP), pp. 1682–1690 (2020)\n 4.\n Cheng, X., Y\nan, X., Lan, Y., Guo, J.: Btm: Topic modeling over short texts. IEEE Transactions on \nKnowledge and Data Engineering 26(12), 2928–2941 (2014)\n 5.\n Cho\nwdhury, J.R., Caragea, C., Caragea, D.: Cross-lingual disaster-related multi-label tweet classifica-\ntion with manifold mixup. In: Proceedings of the Annual Meeting of the Association for Computa-\ntional Linguistics (ACL), pp. 292–298 (2020)\n 6.\n Cho\nwdhury, J.R., Caragea, C., Caragea, D.: On identifying hashtags in disaster twitter data. In: Pro-\nceedings of Conference on Artificial Intelligence (AAAI), pp. 498–506 (2020)\n 7.\n De\nvlin, J., Chang, M.-W., Lee, K., Toutanova, K.: Bert: Pre-training of deep bidirectional transformers \nfor language understanding. In: Proceedings of North American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies (NAACL-HLT), pp. 4171–4186 (2019)\n 8.\n F\neng, J., Rao, Y., Xie, H., Wang, F.L., Li, Q.: User group based emotion detection and topic discovery \nover short text. World Wide Web 23(3), 1553–1587 (2020)\n 9.\n Gao, W\n., Fang, Y., Li, L., Tao, X.: Event detection in social media via graph neural network. In: Web \nInformation Systems Engineering (WISE), pp. 370–384 (2021)\n 10.\n Gao, W\n., Peng, M., Wang, H., Zhang, Y., Xie, Q., Tian, G.: Incorporating word embeddings into topic \nmodeling of short text. Knowledge and Information Systems 61, 1123–1145 (2019)\n 11.\n Gao, W\n., Peng, M., Wang, H., Zhang, Y., Han, W., Hu, G., Xie, Q.: Generation of topic evolution \ngraphs from short text streams. Neurocomputing 383, 282–294 (2020)\n 12.\n Gao, W\n., Fang, Y., Zhang, F., Yang, Z.: Representation learning of knowledge graphs using convolu-\ntional neural networks. Neural Network World 30, 145–160 (2020)\n 13.\n Gao, W\n., Li, L., Zhu, X., Wang, Y.: Detecting disaster-related tweets via multimodal adversarial neural \nnetwork. IEEE MultiMedia 27(4), 28–37 (2020)\n 14.\n Goodf\nellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.C., \nBengio, Y.: Generative adversarial nets. In: Proceedings of Advances in Neural Information Processing \nSystems (NIPS), pp. 2672–2680 (2014)\n 15.\n Haldar\n, N.A.H., Reynolds, M., Shao, Q., Paris, C., Li, J., Chen, Y.: Activity location inference of users \nbased on social relationship. World Wide Web 24(4), 1165–1183 (2021)\n 16.\n Hu, W\n., Tsujii, J.: A latent concept topic model for robust topic inference using word embeddings. \nIn: Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pp. \n380–386 (2016)\n 17.\n Huang, J., P\neng, M., Li, P., Hu, Z., Xu, C.: Improving biterm topic model with word embeddings. \nWorld Wide Web 23(6), 3099–3124 (2020)\n 18.\n Imr\nan, M., Mitra, P., Castillo, C.: Twitter as a lifeline: Human-annotated twitter corpora for NLP of \ncrisis-related messages. In: Proceedings of International Conference on Language Resources and Eval-\nuation (LREC), pp. 1–6 (2016)\n 19.\n K\numar, A., Singh, J.P., Dwivedi, Y.K., Rana, N.P.: A deep multi-modal neural network for informative \ntwitter content classification during emergencies. Annals of Operations Research 7, 1–32 (2020)\n 20.\n Lan, Z., Chen, M., Goodman, S., Gim\npel, K., Sharma, P., Soricut, R.: ALBERT: A lite BERT for \nself-supervised learning of language representations. In: Proceedings of International Conference on \nLearning Representations (ICLR), pp. 1–17 (2020)\n 21.\n Li, \nC., Duan, Y., Wang, H., Zhang, Z., Sun, A., Ma, Z.: Enhancing topic modeling for short texts with \nauxiliary word embeddings. ACM Transactions on Information Systems 36(2), 1–30 (2017)\n69World Wide Web (2023) 26:55–70\n1 3\n 22. Li, J., Cai, T ., Deng, K., Wang, X., Sellis, T., Xia, F.: Community-diversified influence maximization \nin social networks. Information Systems 92, 1–12 (2020)\n 23.\n Li, Z., W\nang, X., Li, J., Zhang, Q.: Deep attributed network representation learning of complex cou-\npling and interaction. Knowledge-Based Systems 212, 1–15 (2021)\n 24.\n Long, Z., Alhar\nthi, R., El Saddik, A.: Needfull-a tweet analysis platform to study human needs during \nthe covid-19 pandemic in new york state. IEEE Access 8, 136046–136055 (2020)\n 25.\n Mahat\na, D., Talburt, J.R., Singh, V.K.: From chirps to whistles: Discovering event-specific informative \ncontent from twitter. In: Proceedings of the ACM Web Science Conference (WebSci), pp. 1–10 (2015)\n 26.\n Mukher\njee, S., Kumar, R., Bala, P.K.: Managing a natural disaster: actionable insights from microblog \ndata. Journal of Decision Systems 31, 134–149 (2022)\n 27.\n N\narayan, S., Cohen, S.B., Lapata, M.: Don’t give me the details, just the summary! topic-aware convo-\nlutional neural networks for extreme summarization. In: Proceedings of Empirical Methods in Natural \nLanguage Processing (EMNLP), pp. 1797–1807 (2018)\n 28.\n N\neppalli, V.K., Caragea, C., Caragea, D.: Deep neural networks versus naive bayes classifiers for \nidentifying informative tweets during disasters. In: Proceedings of Information Systems for Crisis \nResponse and Management (ISCRAM), pp. 1–10 (2018)\n 29.\n Nguy\nen, D.Q., Vu, T., Rahimi, A., Dao, M.H., Nguyen, L.T., Doan, L.: WNUT-2020 task 2: identi-\nfication of informative COVID-19 english tweets. In: Proceedings of the Workshop on Noisy User-\ngenerated Text (WNUT), pp. 314–318 (2020)\n 30.\n R\noy, S., Mishra, S., Matam, R.: Classification and summarization for informative tweets. In: Proceed-\nings of IEEE International Students’ Conference on Electrical, Electronics and Computer Science \n(SCEECS), pp. 1–4 (2020)\n 31.\n Salimans, T\n., Goodfellow, I.J., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Improved techniques \nfor training gans. In: Proceedings of Advances in Neural Information Processing Systems (NIPS), pp. \n2226–2234 (2016)\n 32.\n Sar\nki, R., Ahmed, K., Wang, H., Zhang, Y.: Automated detection of mild and multi-class diabetic eye \ndiseases using deep learning. Health Information Science and Systems 8(1), 1–9 (2020)\n 33.\n Shahi, G.K., Dir\nkson, A., Majchrzak, T.A.: An exploratory study of COVID-19 misinformation on \ntwitter. Online Social Networks and Media 22, 1–16 (2021)\n 34.\n Singh, L., Bansal, S., Bode, L., Budak\n, C., Chi, G., Kawintiranon, K., Padden, C., Vanarsdall, R., \nVraga, E.K., Wang, Y.: A first look at COVID-19 information and misinformation sharing on twitter. \n1–24 arxiv:\n \n2003.\n \n13907 (2020)\n 35.\n Sr\neenivasulu, M., Sridevi, M.: Classifying informative and non-informative tweets from the twitter \nby adapting image features during disaster. Multimedia Tools and Applications 79(3), 28901–28923 \n(2020)\n 36.\n Supr\niya, S., Siuly, S., Wang, H., Zhang, Y.: Automated epilepsy detection techniques from electroen-\ncephalogram signals: a review study. Health Information Science and Systems 8(1), 1–15 (2020)\n 37.\n V\naswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, \nI.: Attention is all you need. In: Proceedings of Advances in Neural Information Processing Systems \n(NIPS), pp. 5998–6008 (2017)\n 38.\n W\nang, L., Yao, J., Tao, Y., Zhong, L., Liu, W., Du, Q.: A reinforced topic-aware convolutional \nsequence-to-sequence model for abstractive text summarization. In: Proceedings of the International \nJoint Conference on Artificial Intelligence (IJCAI), pp. 4453–4460 (2018)\n 39.\n Y\nang, Y., Guan, Z., Li, J., Zhao, W., Cui, J., Wang, Q.: Interpretable and efficient heterogeneous graph \nconvolutional network. IEEE Transactions on Knowledge and Data Engineering, 1–14 (2021)\n 40.\n Y\nin, J., Tang, M., Cao, J., Wang, H., You, M., Lin, Y.: Vulnerability exploitation time prediction: an \nintegrated framework for dynamic imbalanced learning. World Wide Web 25, 401–423 (2022)\n 41.\n Y\nin, H., Yang, S., Song, X., Liu, W., Li, J.: Deep fusion of multimodal features for social media \nretweet time prediction. World Wide Web 24(4), 1027–1044 (2021)\n 42.\n Zaher\na, H.M., Elgendy, I.A., Jalota, R., Sherif, M.A.: Fine-tuned BERT model for multi-label tweets \nclassification. In: Proceedings of the Text Retrieval Conference (TREC), pp. 1–7 (2019)\n 43.\n Zeng, J., Li, J., Song, Y\n., Gao, C., Lyu, M.R., King, I.: Topic memory networks for short text classi-\nfication. In: Proceedings of Empirical Methods in Natural Language Processing (EMNLP), pp. 3120–\n3131 (2018)\n70 World Wide Web (2023) 26:55–70",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8883249759674072
    },
    {
      "name": "Social media",
      "score": 0.7026125192642212
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6021287441253662
    },
    {
      "name": "Topic model",
      "score": 0.5640748143196106
    },
    {
      "name": "Adversarial system",
      "score": 0.5436659455299377
    },
    {
      "name": "Language model",
      "score": 0.5345740914344788
    },
    {
      "name": "Labeled data",
      "score": 0.5075603723526001
    },
    {
      "name": "Coronavirus disease 2019 (COVID-19)",
      "score": 0.4738921523094177
    },
    {
      "name": "Machine learning",
      "score": 0.46800294518470764
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.44851991534233093
    },
    {
      "name": "Natural language processing",
      "score": 0.38276153802871704
    },
    {
      "name": "Data science",
      "score": 0.37953469157218933
    },
    {
      "name": "World Wide Web",
      "score": 0.21911650896072388
    },
    {
      "name": "Pathology",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Disease",
      "score": 0.0
    },
    {
      "name": "Medicine",
      "score": 0.0
    },
    {
      "name": "Infectious disease (medical specialty)",
      "score": 0.0
    }
  ]
}