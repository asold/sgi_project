{
  "title": "Can Pretrained Language Models Derive Correct Semantics from Corrupt Subwords under Noise?",
  "url": "https://openalex.org/W4385718045",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A2154761486",
      "name": "Xinzhe Li",
      "affiliations": [
        "Deakin University"
      ]
    },
    {
      "id": "https://openalex.org/A2098006703",
      "name": "Ming Liu",
      "affiliations": [
        "Deakin University"
      ]
    },
    {
      "id": "https://openalex.org/A2104484959",
      "name": "Gao Shang",
      "affiliations": [
        "Deakin University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2966610483",
    "https://openalex.org/W1654173042",
    "https://openalex.org/W2125825154",
    "https://openalex.org/W2978670439",
    "https://openalex.org/W2963250244",
    "https://openalex.org/W2767899794",
    "https://openalex.org/W3102783139",
    "https://openalex.org/W3174150157",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W2991166755",
    "https://openalex.org/W3176893837",
    "https://openalex.org/W413544450",
    "https://openalex.org/W3175362188",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2792807351",
    "https://openalex.org/W2988217457",
    "https://openalex.org/W2962784628",
    "https://openalex.org/W2121879602",
    "https://openalex.org/W4385567173",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2996428491",
    "https://openalex.org/W3115462295",
    "https://openalex.org/W4224980447"
  ],
  "abstract": "For Pretrained Language Models (PLMs), their susceptibility to noise has recently been linked to subword segmentation. However, it is unclear which aspects of segmentation affect their understanding. This study assesses the robustness of PLMs against various disrupted segmentation caused by noise. An evaluation framework for subword segmentation, named Contrastive Lexical Semantic (CoLeS) probe, is proposed. It provides a systematic categorization of segmentation corruption under noise and evaluation protocols by generating contrastive datasets with canonical-noisy word pairs. Experimental results indicate that PLMs are unable to accurately compute word meanings if the noise introduces completely different subwords, small subword fragments, or a large number of additional subwords, particularly when they are inserted within other subwords.",
  "full_text": "Proceedings of the The 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023), pages 165–173\nJuly 13-14, 2023 ©2023 Association for Computational Linguistics\nCan Pretrained Language Models Derive Correct Semantics from Corrupt\nSubwords under Noise?\nXinzhe Li, Ming Liu, Shang Gao\nSchool of IT, Deakin University, Australia\n{lixinzhe, m.liu,shang.gao}@deakin.edu.au\nAbstract\nFor Pretrained Language Models (PLMs), their\nsusceptibility to noise has recently been linked\nto subword segmentation. However, it is un-\nclear which aspects of segmentation affect their\nunderstanding. This study assesses the robust-\nness of PLMs against various disrupted segmen-\ntation caused by noise. An evaluation frame-\nwork for subword segmentation, named Con-\ntrastive Lexical Semantic (CoLeS) probe, is\nproposed. It provides a systematic categoriza-\ntion of segmentation corruption under noise and\nevaluation protocols by generating contrastive\ndatasets with canonical-noisy word pairs. Ex-\nperimental results indicate that PLMs are un-\nable to accurately compute word meanings if\nthe noise introduces completely different sub-\nwords, small subword fragments, or a large\nnumber of additional subwords, particularly\nwhen they are inserted within other subwords.\n1 Introduction\nThe capability to understand the meaning of noisy\nwords through character arrangements is a crucial\naspect of human cognitive abilities (Rawlinson,\n2007). This capability is highly sought after in\npractical applications such as machine translation\nand sentiment analysis (Belinkov and Bisk, 2018).\nHowever, despite their success in in-distribution\ntest data with standardized word forms, Pretrained\nLanguage Models (PLMs), which serve as the back-\nbone models, tend to perform poorly on rare or\nnoisy words (Kumar et al., 2020; Baron, 2015).\nThese noisy words may be caused by accidental ty-\npos (Belinkov and Bisk, 2018) or spelling variants\non social media (Ritter et al., 2010).\nPrior studies show that most subword-based\nPLMs perform poorly under noise largely due to\nsubword segmentation (Zhuang and Zuccon, 2022),\nwhile character-based PLMs show more robustness\n(El Boukkouri et al., 2020). Examining the impact\nof subword segmentation factors on PLMs is also\ncrucial for defending against the adversarial attacks\nthat leverage the sensitivity of subword segmenta-\ntion to noise (Liu et al., 2022). However, rare work\nhas investigated how the subword segmentation\nfrom noisy words affects the word meaning.\nTo help address this question, we design and de-\nvelop a contrastive framework (CoLes) to assess\nthe robustness of PLMs in the face of various forms\nof segmentation corruption. As subword segmen-\ntation can be influenced by noise in various ways,\nsuch as adding extra subwords or losing original\nsubwords, we systematically categorize the ways\ninto four main categories and two additional sub-\ncategories based on three subword sets, as exem-\nplified in Table 1. Two types of noise models are\nproposed to effectively generate all the types of\ncorruption except missing corruption, and a con-\ntrastive dataset consisting of noisy and standard\nword pairs is created. This framework enables us\nto evaluate the significance of preserved subwords\nand the impact of subwords added by noise.\nThe experimental results provide the following\ninsights: 1) complete corruption: the PLMs strug-\ngle to infer meaning accurately if no subwords from\nthe original segmentation are retained. The worst\nperformance is observed when the meaning of orig-\ninal words is stored in the embedding; 2) partial\ncorruption: preserving larger subword chunks can\naid the understanding of PLMs, whereas retaining\nsmaller subword pieces tend to be ineffective; and\n3) additive corruption: even with all original sub-\nwords, however, the addition of subwords can harm\nthe meaning of words, particularly when they are\nplaced within other subwords. The more additive\nsubwords, the greater the deviation in word seman-\ntics. All the results are consistent on the three\nPLMs with different vocabularies and segmenta-\ntion algorithms.\n2 Contrastive Lexical-Semantic Probe\nThe CoLeS probe framework has segmentation\ncorruption and noise models that produce noisy\n165\nCorruption Types Examples Segmentation Sets\nMissing Overlap Additive\nComplete (intact) tasty →taaasty tasty ta, aa, sty\nComplete stun →stunn s, tun stu, nn\nPartial effectiveness →efeectiveness effect iveness efe, ect\nAdditive (infix) insubstantial →insuubstantial ins, ub, stan, tial u\nAdditive (affix) hilarious →hilariousss hil, ario, us s, s\nMissing insubstantial →insstantial ub ins, stan, tial\nTable 1: Examples of different types of segmentation corruption. Complete/partial: completely/partially disrupting\nthe original segmentation; additive: creating unnecessary subwords; missing: ignoring a token. A distinct form of\ncomplete corruption, referred to as “intact corruption”, arises when a clean word is tokenized into a single subword\nthat does not appear in the segmentation of its noisy counterpart. In the given example of intact corruption, the term\n“tasty” serves as an intact token.\nwords leading to different types of segmentation\ncorruption. These noisy words, along with their\ncorresponding canonical forms, are organized in a\ncontrastive lexical dataset Dcontrastive 1. An evalua-\ntion protocol is designed to examine the effect of\nvarious corruption types.\n2.1 Segmentation Corruption under Noise\nA PLM consists of a tokenizer Seg(·), which seg-\nments a given word w into a sequence of subwords,\ni.e., Seg(w) = ( ˜w1, ...,˜wK), and a PLM encoder\nEnc(·), which takes Seg(w) and outputs a word\nrepresentation. Formally, the segmentation of a\ncanonical word Seg(w) can be represented as a set\nS, while the segmentation of a noisy word Seg( ˜w)\ncan be represented as set ˜S = {˜w1, ...,˜wK}. We\ncan then utilize set operations to define the over-\nlap set (consisting of retained subwords), the miss-\ning set, and the additive set (comprising additional\ntokens that are not present in S) as O = S ∩˜S,\nM = S −O and A = ˜S −O, respectively.\nThe set data structure cannot count duplicated to-\nkens, which frequently occur in additive corruption\nscenarios, such as the additive (affix) corruption\nexample presented in Table 1. Hence, we utilize\na multiset implementation of S and ˜S since such\na data structure also stores the frequencies of ele-\nments, helping us assess the impact of duplicated\ntokens. Since the multiset implementation only in-\ncludes unique elements without considering their\norder of appearance, we further differentiate the\ntwo types of additive corruption by iteratively com-\nparing elements from two queue implementations\nof Seg(w) and Seg( ˜w).\nIn this study, we distinguish a unique category of\n1Sentiment lexicon used is from https://www.\ncs.uic.edu/~liub/FBS/sentiment-analysis.\nhtml#lexicon.\ncorruption referred to as “intact corruption” from\ncomplete corruption, as the canonical words in\nthis category (with whole-word vectors) remain\nunchanged. In total, there are six different types of\ncorruption, as outlined in Table 1.\nIdentification of corruption types. During the\nevaluation, we need to filter each word pair ac-\ncording to its corruption type. First, we segment\neach word pair in Dcontrastive by a model-specific\ntokenizer Seg(·) into subwords (S, ˜S). We then\nidentify the corruption type according to the fol-\nlowing conditions: 1) Complete corruption: S and\n˜S are disjoint, i.e., O = ∅. If the length of the miss-\ning set M is 1, this noise leads to intact corruption;\n2) Partial corruption: the corruption only occurs to\none of the subwords (i.e., the one in M), and the\nother subwords (i.e., those in O) are not affected.\nThe prerequisite is that there exist more than one\nsubwords in the original segmentation set S. We\ncan find such word pairs satisfy M, O, A ̸= ∅; 3)\nThe conditions for additive corruption and missing\ncorruption are S ∈˜S (or M = ∅) and ˜S ∈S (or\nA = ∅), respectively. 2\n2.2 Creation of Contrastive Dataset\nMost prior noisy datasets added noise to sentences,\nnot individual words (Belinkov and Bisk, 2018; Ku-\nmar et al., 2020; Warstadt et al., 2019; Hagiwara\nand Mita, 2020). Besides, as contrastive datasets\ncontaining both the original and noisy form of a\nword are not readily available, we create our own\nlexical dataset which includes both forms. Exam-\nples of the generated dataset can be found in Table\n2.\n2See https://github.com/xinzhel/word_\ncorruption/blob/main/word_corruption.py\nfor concrete implementation.\n166\nCanonical Words Keyboard Swap Letter-reduplication\nbad NA NA badddddddd, baaaadddd, bbbbaaaaddddd\ncrazy craxy carzy crazzyyyyyyyyy, crazzzzzy\namazing amazijg amzaing amazing, amazinnng, amazinggg, amaaazzziiingggg\nTable 2: Examples of contrastive datasets with canonical-noisy word pairs. Three types of noise models are applied:\nSwap-typos, Keyboard typos and letter reduplication. NA: we discard generated noisy words since typos on these\nwords generate noisy words that are even unrecognizable to humans.\nNoise models. Two sources of noise models are\nused to generate the lexical dataset. Findings given\nin Appendix E indicate that both types of noise\nmodels have comparable effects on model perfor-\nmance.\n1) Naturally and frequently occurring typos.\nUsers often type neighboring keys due to mobile\npenetration across the globe and fat finger problem\n(Kumar et al., 2020), while typing quickly may\nresult in swapping two letters Belinkov and Bisk\n(2018). We refer to them as Keyboard and Swap\ntypos, respectively. Our implementation of these\ntypos is based on Wang et al. (2021). Specifically,\nfor Keyboard, we only use letters in the English\nalphabet within one keyboard distance as the sub-\nstitute symbols. Further, we avoid unrecognizable\nword forms (e.g., “bad→bqd” or “top →tpp”) by\nselecting words with more than four characters.\nAccording to the psycholinguistic study (Davis,\n2003), to make noisy words recognizable for hu-\nmans, we only apply noise to the middle characters\nand keep characters at the beginning and the end.\nBesides such a constraint, Swap typo also requires\nat least two distinct characters in the middle for\nswapping. However, words like “aggressive” can\nstill be transformed into the same word by swap-\nping “ss”, so we transform them until we get a\ndistinct word. Finally, we set a one-edit constraint\nfor typos.\n2) Non-standard orthography. We gather\nwords with letter reduplication from 1.6 million\ntweets (Go et al., 2009). To create the canoni-\ncal and noisy word pairs, we match specific noisy\nword forms (e.g. words with repeated letters for\nemphasis) to their corresponding canonical forms\n(a sequence of definite characters). We use sim-\nple regular expression patterns to search for words\nwith repeated letters 3. Examples in Table 3 show\nhow effective these types of noise are in triggering\ndifferent types of segmentation corruption.\n3For example, pattern “\\bb+a+d+” for “bad” matches “bad-\nddddddd”.\nData-generating process. We create a con-\ntrastive dataset, Dcontrastive, by applying the noise\nmodels to the lexical dataset Dcanonical, which con-\ntains words in their canonical form. The noise\nmodels are applied to each word in Dcanonical to\ncreate two misspelled words. Additionally, a ran-\ndom number of noisy words is extracted from the\ncollection of 1.6 million tweets. As for the lexi-\ncal dataset, Dcanonical, we choose adjectives from\na sentiment lexicon that, by definition, provides\npositive or negative sentiment labels for use with\ndownstream classifiers.\nEvaluation. To assess the extent to which the\nmeanings of noisy words diverge from the standard\nword forms, we calculate the cosine similarity be-\ntween Enc(S) and Enc(˜S). For words that consist\nof multiple subwords, we aggregate their vectors\ninto a single representation by averaging the token\nembeddings obtained from the PLMs. It is impor-\ntant to note that the output embedding spaces of\nPLMs exhibit varying levels of anisotropy (Etha-\nyarajh, 2019; Yan et al., 2021; Gao et al., 2019).\nThus, the similarity scores cannot be directly com-\npared across different models. It is necessary to\nset a baseline by computing the similarity between\nEnc(S) and a random embedding (we use the em-\nbedding of token “the”, i.e., Enc(the)).\nAdditionally, we fine-tune downstream classi-\nfiers denoted as y = Cls(x), where y represents\nan arbitrary semantic dimension and x corresponds\nto the encoded representation obtained from the\nPLMs Enc(Seg(·)). We focus on sentiment clas-\nsification as individuals frequently use sentiment\nwords creatively on social media to express their\nemotions. To conduct our experiments, the senti-\nment of each word and its noisy variations is de-\nrived from the sentiment lexicon.\nTo gauge the semantic deviation caused by noise,\nwe measure the accuracy of the noisy counterparts\nof words that are accurately classified in their orig-\ninal form.\n167\nTokenizers Intact Complete Partial\nBERT 0.36 0.14 0.49\nRoBERTa 0.46 0.12 0.42\nALBERT 0.38 0.13 0.49\n(a) Typos.\nIntact Complete Partial Additive\naffix infix\n0.70 0.02 0.06 0.22 0\n0.61 0 0.06 0.30 0.01\n0.61 0.02 0.06 0.29 0.02\n(b) Letter Reduplication.\nTable 3: Frequency of each segmentation corruption.\n3 Experimental Results\nExperiments are performed on three widely\nused PLMs: BERTBASE, RoBERTaBASE and\nALBERTBASE (See Appendix A for details).\nBERT (Devlin et al., 2019) accepts inputs from\na Wordpiece tokenizer (Schuster and Nakajima,\n2012), while RoBERTa(Liu et al., 2019), another\npopular frequent-based segmentation scheme, uses\nBPE (Sennrich et al., 2016). For comparison, we\ninclude ALBERT (Lan et al., 2020) with a proba-\nbilistic tokenizer called Sentencepiece (Kudo and\nRichardson, 2018).\nSubwords retention is important for maintain-\ning the correct semantics. Table 4 shows the\nseverity of semantic deviation for each type of cor-\nruption. Generally, the more subwords the segmen-\ntation retains, the better the semantics are main-\ntained (additive corruption > partial corruption >\ncomplete and intact corruption). Under additive\ncorruption, the PLMs can always maintain more\nsemantics from noisy words than random words\n(the baseline), while only RoBERTa has similarity\nscore higher than the baseline under partial cor-\nruption. All the PLMs cannot infer word meaning\nfrom complete corruption.\nWhat subwords, if retained, would enhance the\ncomprehension of PLMs? We find that partial cor-\nruption can preserve word meaning if it retains a\nsignificant portion of the words, such as “upset”\nfor “upsetting” or “phenomena” for “phenomenal”\n(See Appendix B). This is backed up by the find-\ning that PLMs have the capability of learning mor-\nphological information, where stems contain more\nsemantic meaning in a word compared to smaller\ncomponents such as inflectional morphemes (Hof-\nmann et al., 2021).\nAre words more impacted by noise under com-\nplete corruption if their meaning is stored in\nthe embeddings? According to Hofmann et al.\n(2021), if a word is represented as a single vector,\nPLMs can access its meaning directly from the em-\nbedding (referred to as the “storage route”) instead\nof deducing it from the combination of subwords\n(known as the “computation route”). We presume\nthat PLMs struggle to maintain the original mean-\ning of these words when exposed to noise. We\nclassify this type of corruption as “intact corrup-\ntion”, which is a particular variation to complete\ncorruption. To validate our assumption, we evalu-\nate the performance of PLMs on words under intact\ncorruption. Results show that words with intact\ncorruption consistently perform worse than those\nwith complete corruption, despite both having com-\npletely distinct subwords. Although intact corrup-\ntion consistently yields the lowest similarity score,\nthe PLMs may still be able to better infer some\nsemantic dimensions, such as sentiment, under in-\ntact corruption compared to complete corruption.\n(Appendix C).\nPresence of additive subwords can damage the\nmeaning of words, particularly when they are\ninserted in the middle of other subwords. In\nsome cases, words under additive corruption (keep-\ning all subwords) can perform worse than those\nunder partial corruption (keeping only some sub-\nwords), as seen in the letter reduplication experi-\nment (Appendix C). The finding suggests that the\nretention of subwords is not the only factor impact-\ning the performance of PLMs. To uncover other\nfactors affecting the word meaning, we analyzed 10\nworst and best instances for each corruption type\nbased on similarity scores (Appendix B). All the\npoorly performing cases have incorrect predictions,\nfurther highlighting the damaging impact on se-\nmantic meaning. The results show that the number\nof additive tokens (i.e., the cardinality ofA) is a dis-\ntinct feature between good and bad instances. All\nthe good cases have only 1 additive token, while\nthe bad cases have at least 2 additive tokens (3.8 for\npartial corruption and 8.7 for additive corruption\non average).\nThus, our hypothesis is that as the number of\nadditive subwords increases, PLMs will have dif-\n168\nModels Intact Complete Partial Additive Baseline\nBERT 0.29 0.41 0.58 0.69 0.69\nRoBERTa 0.54 0.66 0.76 0.85 0.72\nALBERT 0.41 0.47 0.62 0.74 0.68\n(a) Similarity.\nIntact Complete Partial Additive\n0.56 0.65 0.8 0.91\n0.66 0.60 0.75 0.95\n0.61 0.63 0.76 0.93\n(b) Accuracy.\nTable 4: Performance of PLMs under various types of corruption. Similarity scores of pretrained representations and\naccuracy of downstream classifiers are evaluated. The best result per row is highlighted in gray, and the second-best\nis in light gray. As a baseline, we compare the similarity scores between canonical and random words (“the” used).\nThe unaffected accuracy is 1 since the canonical forms selected for evaluation are always correctly predicted.\nModels Infix Suffix\nBERT 0.59 0.70\nRoBERTa 0.85 0.95\nALBERT 0.66 0.74\n(a) Similarity.\nInfix Suffix\n0.74 0.91\n0.95 1\n0.82 0.94\n(b) Accuracy.\nTable 5: Comparison of two types of additive corruption.\nficulty determining the correct meaning of words.\nWe test the hypothesis by examining the perfor-\nmance of PLMs on both additive and intact corrup-\ntion, where the missing and overlap sets remain\nconstant. For additive corruption, we limit our ex-\nperiments to only one unique additive subword and\nvary its frequency. We find 23 words with at least\n3 noisy versions, each creating an additive set with\nthe same element but different multiplicities. Take\n“amazing” as an example: one of its noisy instances\n(“amazinggggggg”) has the multiplicity of 3 ac-\ncording to its additive set A = {“gg”, “gg”, “gg”}\nwhile “gg” only appears twice in another instance\n(“amazinggggg”). We sort every collection of noisy\nwords in either of two ways, depending on the simi-\nlarity scores or the multiplicities of additive tokens.\nIn 17 out of 23 collections, these two sorting crite-\nria produce identical results. This discovery also\nholds true for intact corruption, where the subwords\nwithin an additive set are typically diverse. Figure\n1 illustrates a strong negative correlation between\nthe number of additive tokens and the average simi-\nlarity of noisy words for all the three models under\nintact corruption, where the sizes of missing sets\nand overlap sets are fixed to 1 and 0.\nBesides, as shown in Table 5, additive subwords\nplaced within subwords cause more harm than\nthose that act as suffixes.\n4 Conclusion\nWe proposed the CoLeS framework which can eval-\nuate how corrupt segmentation under noise affects\nFigure 1: Correlation between the number of additive\nsubwords and the cosine similarity of noisy words with\ntheir canonical forms. The range of quantity of additive\nsubwords is subject to change depending on the tok-\nenizer used.\nPLMs’ understanding. The experimental results\nshow that three challenges can impair the PLMs’\nunderstanding of noisy words: insertion of additive\nsubwords (especially within existing subwords),\nloss of original subwords, and incapacity of com-\nputing the word meanings through the aggregation\nof smaller subword units.\nReproducibility. Data and source code for noisy\ndata generation, corruption types identification and\nPLMs’ performance evaluation are released on\nGithub 4.\nLimitations\nThe omission of missing corruption from the evalu-\nation process is justified due to its infrequent occur-\nrence in real-world scenarios (refer to Appendix D\nfor elaboration). Nevertheless, further investigation\ninto rare instances of missing corruption may be\nwarranted for research purposes. Our evaluation\nof language models was limited to auto-encoders\nbased on the BERT architecture. Future studies\nare anticipated to expand the scope of PLMs under\n4https://github.com/xinzhel/word_\ncorruption\n169\nconsideration 5.\nReferences\nNaomi S Baron. 2015. Words onscreen: The fate of\nreading in a digital world. Oxford University Press,\nUSA.\nYonatan Belinkov and Yonatan Bisk. 2018. Synthetic\nand natural noise both break neural machine transla-\ntion. In ICLR.\nMatt Davis. 2003. Psycholinguistic evidence on scram-\nbled letters in reading.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In NAACL.\nHicham El Boukkouri, Olivier Ferret, Thomas Lavergne,\nHiroshi Noji, Pierre Zweigenbaum, and Jun’ichi Tsu-\njii. 2020. CharacterBERT: Reconciling ELMo and\nBERT for word-level open-vocabulary representa-\ntions from characters. In CoLing, pages 6903–6915.\nKawin Ethayarajh. 2019. How contextual are contextu-\nalized word representations? Comparing the geom-\netry of BERT, ELMo, and GPT-2 embeddings. In\nEMNLP-IJCNLP, pages 55–65, Hong Kong, China.\nJun Gao, Di He, Xu Tan, Tao Qin, Liwei Wang, and\nTieyan Liu. 2019. Representation degeneration prob-\nlem in training natural language generation models.\nIn ICLR.\nAlec Go, Richa Bhayani, and Lei Huang. 2009. Twit-\nter sentiment classification using distant supervision.\nCS224N project report, Stanford.\nMasato Hagiwara and Masato Mita. 2020. GitHub typo\ncorpus: A large-scale multilingual dataset of mis-\nspellings and grammatical errors. In Language Re-\nsources and Evaluation Conference (LREC).\nMaria Heath. 2018. Orthography in social media: Prag-\nmatic and prosodic interpretations of caps lock. Pro-\nceedings of the Linguistic Society of America.\nValentin Hofmann, Janet Pierrehumbert, and Hinrich\nSchütze. 2021. Superbizarre is not superb: Deriva-\ntional morphology improves BERT’s interpretation\nof complex words. In ACL-IJCNLP.\nTaku Kudo and John Richardson. 2018. SentencePiece:\nA simple and language independent subword tok-\nenizer and detokenizer for neural text processing. In\nEMNLP: System Demonstrations, pages 66–71.\nAnkit Kumar, Piyush Makhija, and Anuj Gupta. 2020.\nNoisy text data: Achilles’ heel of BERT. In Proceed-\nings of the Sixth Workshop on Noisy User-generated\nText (W-NUT 2020).\n5Instructions within our codebase facilitate the evaluation\nof various types of pre-trained language models accessible via\nHuggingfacehttps://huggingface.co/models.\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2020. ALBERT: A lite BERT for self-supervised\nlearning of language representations. In ICLR.\nAiwei Liu, Honghai Yu, Xuming Hu, Shu’ang Li,\nLi Lin, Fukun Ma, Yawen Yang, and Lijie Wen. 2022.\nCharacter-level white-box adversarial attacks against\ntransformers via attachable subwords substitution. In\nEMNLP.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nGraham Rawlinson. 2007. The significance of letter\nposition in word recognition. IEEE Aerospace and\nElectronic Systems Magazine.\nAlan Ritter, Colin Cherry, and Bill Dolan. 2010. Un-\nsupervised modeling of Twitter conversations. In\nNAACL-HLT, pages 172–180.\nMike Schuster and Kaisuke Nakajima. 2012. Japanese\nand korean voice search. In 2012 IEEE International\nConference on Acoustics, Speech and Signal Process-\ning (ICASSP), pages 5149–5152.\nRico Sennrich, Barry Haddow, and Alexandra Birch.\n2016. Neural machine translation of rare words with\nsubword units. In ACL.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob\nUszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\nKaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in Neural Information Pro-\ncessing Systems.\nXiao Wang, Qin Liu, Tao Gui, Qi Zhang, et al. 2021.\nTextflint: Unified multilingual robustness evaluation\ntoolkit for natural language processing. In ACL-\nIJCNLP: System Demonstrations, Online.\nAlex Warstadt, Amanpreet Singh, and Samuel R. Bow-\nman. 2019. Neural network acceptability judgments.\nTACL.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn EMNLP: System Demonstrations.\nYuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang,\nWei Wu, and Weiran Xu. 2021. ConSERT: A con-\ntrastive framework for self-supervised sentence rep-\nresentation transfer. In ACL-IJCNLP.\nShengyao Zhuang and Guido Zuccon. 2022. Character-\nbert and self-teaching for improving the robustness\nof dense retrievers on queries with typos. SIGIR.\n170\nA Fine-tuning Pretrained Language Models\nAll the PLMs use BERT-based architecture, i.e., the encoding part of the transformer (Vaswani et al., 2017).\nBERTBASE (110M parameters) and RoBERTaBASE (125M parameters) are pretrained on BookCorpus\nand Wikipedia as masked language models. Only the pretraining of ALBERTBASE (11M parameters)\nincludes extra news and web data (Wolf et al., 2020). They are then fine-tuned for sentiment classification\non the SST-2 dataset. All the models are publicly available on the Huggingface Hub website https:\n//huggingface.co/textattack. Some configurations are shown as below. The BERT and\nRoBERTa models are fine-tuned using a learning rate of2e−5 with no scheduling employed. The batch\nsize is set to 32, and the training process spans 3 epochs, maintaining a gradient norm of 1. ALBERT is\nfined-tuned with a learning rate of 3e−5, a batch size of 32, and a total of 5 training epochs.\nB Good and Bad Cases\nFigure 2 shows the good and bad cases of partial and additive corruption under letter reduplication.\nFigure 2: Good and bad cases of partial and additive corruption under letter reduplication.\nC PLM Robustness to Segmentation Corruption under Different Types of Noise\nTable 6 displays the robustness of PLMs to segmentation corruption under various forms of noise. The\nresults are largely consistent with those seen in Table 4. However, we notice that for letter reduplication,\nPLMs may perform worse with additive corruption than with partial corruption. Additionally, the accuracy\nof intact corruption can be better than that of complete corruption, despite they consistently having the\nlowest similarity score.\nD Noisy words for Missing Corruption\nAs per the findings of Heath et al. (Heath, 2018), English word recognition by humans is predominantly\ninfluenced by consonants. Consequently, our investigation aims to identify abbreviations that disregard\nvowels and certain consonants when examining tweets. To be precise, an abbreviation is considered\nacceptable if its first letter and arbitrary consonants appear in a sequence that adheres to canonical words.\nFor instance, the pattern of regular expression for term “sorry” can be “\\bsr?r?y?” in such cases. However,\nwe find that even humans have difficulties in recognizing all these abbreviations. While the inclusion\nof all consonants may enhance human recognition, we contend that assessing this form of corruption is\n171\nModels Intact Complete Partial Additive\nBERT 0.24 0.34 0.62 0.69\nRoBERTa 0.54 0.73 0.8 0.85\nALBERT 0.42 0.53 0.77 0.74\n(a) Similarity.\nIntact Complete Partial Additive\n0.54 0.47 0.92 0.91\n0.54 0.73 0.87 0.95\n0.63 0.79 0.91 0.93\n(b) Accuracy.\nLetter Reduplication\nModels Intact Complete Partial Additive\nBERT 0.34 0.41 0.58 /\nRoBERTa 0.55 0.65 0.75 /\nALBERT 0.4 0.47 0.61 /\n(c) Similarity.\nIntact Complete Partial Additive\n0.59 0.66 0.79 /\n0.6 0.57 0.74 /\n0.59 0.61 0.75 /\n(d) Accuracy.\nTypos\nTable 6: Performance of PLMs under different types of corruption. Similarity scores of pretrained representations\nand accuracy of downstream classifiers are measured. The best result per row is highlighted in gray, the second-best\nis in light gray. There is no result for additive corruption under typos because intra-word noise (modifying characters\nexcept for the first and last characters) (i.e., typos) never results in additive corruption. Baseline similarity scores\nare calculated between canonical words and the word “the”.\nsuperfluous. This assertion stems from our demonstration in Table 7 that such aggressive search criteria\nare improbable to produce missing corruption.\nModels Intra\nBERT 0.50%\nRoBERTa 0.52%\nALBERT 0.43%\nTable 7: Proportion of abbreviations causing missing corruption.\nProvided below is a comprehensive inventory of the canonical words and their corresponding noisy\ncounterparts responsible for inducing missing corruption. It is worth noting that these noisy words are\ncompletely imperceptible to human cognition.\n• 24 word pairs under RoBERTa: enthral-enth, upgradable-upgr, abysmal-abys, chintzy-chzy, emphatic-\nemph, enslave-ensl, extraneous-extr, implacable-impl, implausible-impl, implicate-impl, imprudent-\nimpr, inflame-infl, instable-inst, intransigent-intr, irksomeness-irks, obscenity-obsc, obtrusive-obtr,\nungrateful-ungr, unscrupulous-unsc, unsteadily-unst, unsteadiness-unst, unsteady-unst, unsteady-\nunsty, untruthful-untr;\n• 23 word pairs under BERT: enthral-enth, exemplar-expl, exemplar-empl, idyllic-idyl, stylish-styl,\nabysmal-abys, brutish-brsh, crummy-crmy, enslave-ensl, hysteric-hyst, impenitent-impt, incognizant-\ninct, inconstant-inct, inexplainable-inpl, infamy-inmy, inflame-infl, irksomeness-irks, obscenity-obsc,\nobtrusive-obtr, unscrupulous-unsc, unspeakable-unsp, untrue-untr, untruthful-untr;\n• 2 word pairs under ALBERT: enthral-enth, exemplar-exmp.\nE Performance of PLMs under Different Noise\nWe compare the effect of two noise models “Naturally and frequently occurring typos” and “Non-standard\northography” with both the lexicon dataset and two sentential datasets. For a fair comparison, we constrain\n172\nthe length of letter-reduplication to 1. The accuracy of the noisy data and their standard deviation\nare reported in Table 8 and Table 9, respectively. It can be seen that the types of noise models in our\nexperiments have no much distinction on model performance, except for the Swap.\nData Noise Type BERT RoBERTa ALBERT\nAccuracy\nSST-2\nClean 0.93 0.85 0.92\nKeyboard 0.66 0.66 0.67\nSwap 0.71 0.72 0.72\nLetter-repetition 0.63 0.7 0.65\nAG-News\nClean 0.95 0.8 0.92\nKeyboard 0.88 0.62 0.86\nSwap 0.89 0.62 0.86\nLetter-repetition 0.88 0.61 0.86\nSimilarity\nSetiment Lexicon\nKeyboard 0.39 1 0.47\nSwap 0.45 1 0.5\nLetter-repetition 0.36 1 0.49\nSST-2\nKeyboard 0.5 0.52 0.61\nSwap 0.61 0.56 0.66\nLetter-repetition 0.46 0.55 0.58\nAG-News\nKeyboard 0.85 0.47 0.72\nSwap 0.87 0.5 0.75\nLetter-repetition 0.85 0.48 0.74\nTable 8: Performance of PLMs under Different Noise\nData BERT RoBERTa ALBERT\nSimilarity\nLexicon 0.037 0 0.016\nSST-2 0.061 0.016 0.035\nAG-News 0.009 0.013 0.013\nAccuracy\nSST-2 0.035 0.022 0.033\nAG-News 0.004 0.004 0.004\nTable 9: Standard deviations of PLMs’ performance under different types of noise.\n173",
  "topic": "Segmentation",
  "concepts": [
    {
      "name": "Segmentation",
      "score": 0.7700487375259399
    },
    {
      "name": "Computer science",
      "score": 0.7259754538536072
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.6948903799057007
    },
    {
      "name": "Noise (video)",
      "score": 0.6350842714309692
    },
    {
      "name": "Categorization",
      "score": 0.6339829564094543
    },
    {
      "name": "Artificial intelligence",
      "score": 0.600074827671051
    },
    {
      "name": "Natural language processing",
      "score": 0.5781756043434143
    },
    {
      "name": "Text segmentation",
      "score": 0.5778034329414368
    },
    {
      "name": "Semantics (computer science)",
      "score": 0.5224003791809082
    },
    {
      "name": "Speech recognition",
      "score": 0.47894150018692017
    },
    {
      "name": "Word (group theory)",
      "score": 0.4262252748012543
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.37980738282203674
    },
    {
      "name": "Linguistics",
      "score": 0.19050419330596924
    },
    {
      "name": "Image (mathematics)",
      "score": 0.09993240237236023
    },
    {
      "name": "Philosophy",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Programming language",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I149704539",
      "name": "Deakin University",
      "country": "AU"
    }
  ],
  "cited_by": 1
}