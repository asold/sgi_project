{
  "title": "Research on a traditional Chinese medicine case-based question-answering system integrating large language models and knowledge graphs",
  "url": "https://openalex.org/W4406128867",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A2116291765",
      "name": "Yuchen Duan",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2097397018",
      "name": "Qingqing Zhou",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2097755322",
      "name": "Yu Li",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2222932012",
      "name": "Chi Qin",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2128318503",
      "name": "Zi-yang Wang",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2145794500",
      "name": "Hongxing Kan",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2285329530",
      "name": "Jili Hu",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2116291765",
      "name": "Yuchen Duan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097397018",
      "name": "Qingqing Zhou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097755322",
      "name": "Yu Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2222932012",
      "name": "Chi Qin",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2128318503",
      "name": "Zi-yang Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2145794500",
      "name": "Hongxing Kan",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    },
    {
      "id": "https://openalex.org/A2285329530",
      "name": "Jili Hu",
      "affiliations": [
        "Anhui University of Traditional Chinese Medicine"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4292779060",
    "https://openalex.org/W3015409108",
    "https://openalex.org/W3027879771",
    "https://openalex.org/W4211112851",
    "https://openalex.org/W3210304016",
    "https://openalex.org/W4378904515",
    "https://openalex.org/W4392873661",
    "https://openalex.org/W4394880627",
    "https://openalex.org/W4394571637",
    "https://openalex.org/W4386501849",
    "https://openalex.org/W4393160124",
    "https://openalex.org/W4384643740",
    "https://openalex.org/W4391407054",
    "https://openalex.org/W4377093262",
    "https://openalex.org/W4387156782"
  ],
  "abstract": "Introduction Traditional Chinese Medicine (TCM) case records encapsulate vast clinical experiences and theoretical insights, holding significant research and practical value. However, traditional case studies face challenges such as large data volumes, complex information, and difficulties in efficient retrieval and analysis. This study aimed to address these issues by leveraging modern data techniques to improve access and analysis of TCM case records. Methods A total of 679 case records from Wang Zhongqi, a renowned physician of Xinâ€™an Medicine, a branch of TCM, covering 41 diseases, were selected. The study involved four stages: pattern layer construction, knowledge extraction, integration, and data storage and visualization. A large language model (LLM) was employed to automatically extract key entities, including symptoms, pathogenesis, treatment principles, and prescriptions. These were structured into a TCM case knowledge graph. Results The LLM successfully identified and extracted relevant entities, which were then organized into relational triples. A TCM case query system based on natural language input was developed. The systemâ€™s performance, evaluated using the RAGAS framework, achieved high scores: 0.9375 in faithfulness, 0.9686 in answer relevancy, and 0.9500 in context recall; In human evaluations, the levels of safety and usability are significantly higher than those of LLMs without using RAG. Discussion The results demonstrate that integrating LLMs with a knowledge graph significantly enhances the efficiency and accuracy of retrieving TCM case information. This approach could play a crucial role in modernizing TCM research and improving access to clinical insights. Future research may explore expanding the dataset and refining the query system for broader applications.",
  "full_text": "Frontiers in Medicine 01 frontiersin.org\nResearch on a traditional Chinese \nmedicine case-based \nquestion-answering system \nintegrating large language \nmodels and knowledge graphs\nYuchenÂ Duan 1, QingqingÂ Zhou 1, YuÂ Li 1, ChiÂ Qin 1, ZiyangÂ Wang 1, \nHongxingÂ Kan 1,2 and JiliÂ Hu 1,2*\n1 School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China, \n2 Center for Xinâ€™an Medicine and Modernization of Traditional Chinese Medicine of IHM, Anhui \nUniversity of Chinese Medicine, Hefei, China\nIntroduction: Traditional Chinese Medicine (TCM) case records encapsulate \nvast clinical experiences and theoretical insights, holding significant research \nand practical value. However, traditional case studies face challenges such as \nlarge data volumes, complex information, and difficulties in efficient retrieval \nand analysis. This study aimed to address these issues by leveraging modern \ndata techniques to improve access and analysis of TCM case records.\nMethods: A total of 679 case records from Wang Zhongqi, a renowned physician \nof Xinâ€™an Medicine, a branch of TCM, covering 41 diseases, were selected. The \nstudy involved four stages: pattern layer construction, knowledge extraction, \nintegration, and data storage and visualization. A large language model (LLM) \nwas employed to automatically extract key entities, including symptoms, \npathogenesis, treatment principles, and prescriptions. These were structured \ninto a TCM case knowledge graph.\nResults: The LLM successfully identified and extracted relevant entities, which \nwere then organized into relational triples. A TCM case query system based on \nnatural language input was developed. The systemâ€™s performance, evaluated \nusing the RAGAS framework, achieved high scores: 0.9375Â  in faithfulness, \n0.9686Â in answer relevancy, and 0.9500Â in context recall; In human evaluations, \nthe levels of safety and usability are significantly higher than those of LLMs \nwithout using RAG.\nDiscussion: The results demonstrate that integrating LLMs with a knowledge \ngraph significantly enhances the efficiency and accuracy of retrieving TCM \ncase information. This approach could play a crucial role in modernizing TCM \nresearch and improving access to clinical insights. Future research may explore \nexpanding the dataset and refining the query system for broader applications.\nKEYWORDS\nlarge language model, knowledge graph, traditional Chinese medicine, question \nanswering system, interdisciplinary research\nOPEN ACCESS\nEDITED BY\nMichael Heinrich,  \nUniversity College London, UnitedÂ Kingdom\nREVIEWED BY\nSilke Cameron,  \nUniversity Medical Center GÃ¶ttingen, \nGermany\nZiming Yin,  \nUniversity of Shanghai for Science and \nTechnology, China\n*CORRESPONDENCE\nJili Hu  \n hujili@ahtcm.edu.cn\nRECEIVED 16 October 2024\nACCEPTED 20 December 2024\nPUBLISHED 07 January 2025\nCITATION\nDuan Y, Zhou Q, Li Y, Qin C, Wang Z, \nKan H and Hu J (2025) Research on a \ntraditional Chinese medicine case-based \nquestion-answering system integrating large \nlanguage models and knowledge graphs.\nFront. Med. 11:1512329.\ndoi: 10.3389/fmed.2024.1512329\nCOPYRIGHT\nÂ© 2025 Duan, Zhou, Li, Qin, Wang, Kan and \nHu. This is an open-access article distributed \nunder the terms of the Creative Commons \nAttribution License (CC BY). The use, \ndistribution or reproduction in other forums is \npermitted, provided the original author(s) and \nthe copyright owner(s) are credited and that \nthe original publication in this journal is cited, \nin accordance with accepted academic \npractice. No use, distribution or reproduction \nis permitted which does not comply with \nthese terms.\nTYPE Original Research\nPUBLISHED 07 January 2025\nDOI 10.3389/fmed.2024.1512329\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 02 frontiersin.org\n1 Introduction\nTraditional Chinese Medicine (TCM) has evolved over thousands \nof years and represents a distinctive healthcare system that focuses on \nholistic approaches, prioritizing the balance between body, mind, and \nspirit. TCM is rooted in ancient philosophies, particularly the concepts \nof Yin and Y ang, as well as the Five Elements theory, which informs \nits diagnostic and therapeutic approaches. TCM case records, serving \nas important carriers of TCM knowledge, experience, and wisdom, \nencompass abundant theoretical knowledge and clinical treatment \nexperiences. These records are crucial for guiding clinical diagnosis \nand treatment, uncovering therapeutic insights, and advancing the \ndevelopment of TCM ( 1). However, since TCM case records are \nfrequently documented in classical Chinese, their content is often \ncomplex and unstructured.\nTraditionally, research on TCM case records has depended on \nmanual reading and analysis to extract and summarize diagnostic \nand therapeutic patterns. This approach is time-consuming, labor-\nintensive, and fails to comprehensively mine the valuable information \ncontained in the case records. Consequently, the effective extraction \nand widespread application of TCM case knowledge have been \nsignificantly limited. Consequently, utilizing contemporary \ntechnological approaches to automate the extraction and application \nof TCM case records has emerged as a primary focus in \nTCM research.\nThe rapid advancement of Artificial Intelligence (AI), particularly \nwith the emergence of large language models (LLMs), has created new \nopportunities for the comprehensive mining and structuring of TCM \ncase knowledge. LLMs, such as GPT ( 2) (Generative Pre-trained \nTransformer), are advanced AI systems trained on a vast amount of \ntext data, enabling them to process and generate human-like language. \nThese models can extract patterns, standardize terminologies, and \nanalyze unstructured data, making them essential tools for exploring \nTCM case records and facilitating knowledge integration.\nKnowledge Graphs (KGs) are structured semantic databases that \norganize concepts and demonstrate their interconnections through \nentities and relationships in a networked form ( 3). Given the \nhierarchical richness and complexity inherent in TCM case records, \nknowledge graphs are particularly well-suited for effectively \nrepresenting such information.\nA question-answering (QA) system refers to a computer \nprogram that identifies relevant answers from pre-stored data or \ninformation based on user queries and presents them to the user. In \ncontemporary question-answering systems, prevalent approach is \nstandard vector-based RAG ( 4). Standard vector-based RAG relies \non retrieving vectors from the source database and generating \nresponses. Its advantage lies in providing rapid responses by \nleveraging existing data. However, it may beÂ  inadequate when \naddressing complex problems due to its lack of reasoning \ncapabilities. In contrast, the combination of LLMs and knowledge \ngraphs offers enhanced flexibility and accuracy when addressing \ncomplex and ambiguous problems. Language models provide \nrobust natural language processing capabilities, while knowledge \ngraphs contribute rich semantic information and relational \nreasoning capabilities. This combination not only generates \ncoherent and fluent responses but also facilitates deeper \nunderstanding and reasoning in the face of uncertainty. Moreover, \ndue to its structured knowledge management and reasoning \ncapabilities, this approach can provide accurate responses with \nminimal data, offering advantages in resource utilization \nand efficiency.\nThis research aims to explore the role of LLMs in constructing a \nTCM case knowledge graph and in developing a TCM case-based \nquestion-answering system that incorporates LLMs with the \nknowledge graph. Specifically, in this study, weÂ integrated LLMs with \nknowledge graphs, enabling the system to understand and process \nmedical queries from users and provide answers grounded in \ntraditional Chinese medical cases. The process includes the automated \nidentification and extraction of key entities, including symptoms, \npathogenesis, treatment principles, and medications, from TCM case \nrecords through the use of LLMs. The development of the TCM case \nknowledge graph involves four steps: schema layer construction, \nknowledge extraction, knowledge fusion, and data storage and \nvisualization. Based on the constructed knowledge graph, weÂ integrate \nLLMs to develop a QA system for TCM case records. This system \nenables natural language-based querying of the knowledge graph, \nproviding an effective and practical method for mining and utilizing \nTCM case knowledge in the realm of TCM research.\n2 Related work\n2.1 Research on traditional Chinese \nmedicine case records based on \nknowledge graphs\nSeveral researchers have employed knowledge graphs to \ninvestigate TCM case records. Chen etÂ al. (5) developed a knowledge \ngraph using 120 ancient stroke case records as a data source, achieving \nâ€œgraph-number mutual verificationâ€ through semantic data analysis \nand visualization of the graph. Wang etÂ al. (6) developed a knowledge \ngraph that encapsulates the clinical practices of esteemed TCM \npractitioners in managing coronary heart disease. This graph facilitates \nvisualization and querying of their diagnostic and therapeutic \nmethods. Y ang etÂ al. (7) developed a knowledge graph from TCM \nclinical data, such as electronic medical records. They introduced a \nsyndrome prediction model (DSDS) based on this knowledge graph, \nwhich supports decision-making in syndrome diagnosis. Zhang etÂ al. \n(8) employed a Naive Bayesian Network and TF-IDF to achieve \ntwo-hop path inference within the knowledge graph, thereby \nproviding decision support for TCM clinical practice. Zhao etÂ al. (9) \nhave developed an extensive knowledge graph for diagnosing and \ntreating diabetic kidney disease in the context of TCM. This graph \nintegrates clinical guidelines and real-world data, addressing key \nclinical challenges and promoting more effective knowledge sharing. \nThese researchers have consistently adopted the knowledge graph \napproach for the structured processing and visualization of TCM case \nrecords, enabling a deeper understanding and analysis of TCM case \nknowledge. Nonetheless, current research remains constrained in its \nexploration of knowledge graph applications. Specifically, it has not \nyet enabled natural language querying of knowledge graphs, implying \nthat direct interaction with the graph using natural language remains \nunfeasible. Conversely, interaction with the knowledge graph \nnecessitates a certain degree of technical expertise and professional \nskills, which limits the broader dissemination and application of TCM \ncase knowledge graphs.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 03 frontiersin.org\n2.2 Research on traditional Chinese \nmedicine case records based on large \nlanguage models\nThe robust natural language understanding and generation \ncapabilities of LLMs have unlocked new possibilities for research and \napplications across various fields. In the domain of TCM case record \nstudies, LLMs represent a novel and promising tool that may facilitate \nbreakthroughs in the modernization and intelligent development of \ntraditional medicine (10, 11). Li etÂ al. (12) investigated the automated \nextraction of named entities from case records based on LLMs, \ncreating a tool for structuring medical case texts. Y ang etÂ  al. ( 13) \nexamined and described the challenges encountered in TCM \nintelligent diagnosis and treatment. They proposed a research \nmethodology that utilizes LLMs, encompassing corpus preparation, \nknowledge representation, instruction fine-tuning, and reinforcement \nlearning. Zhang etÂ al. (14) investigated techniques for utilizing LLMs \nin the development of TCM knowledge graphs, thereby improving the \nrepresentation, storage, and utilization of TCM knowledge. Wang \netÂ al. (15) employed medical knowledge graphs and literature to fine-\ntune the base model, resulting in ShenNong-TCM, which enhanced \nthe modelâ€™s question-answering capabilities in the medical field. Kang \netÂ al. (16) created a multi-scenario instruction dataset based on TCM \ngynecology prescription data, resulting in CMLM-ZhongJing, which \naugmented the modelâ€™s reasoning abilities in TCM prescription data \nand diagnostic logic. Zhang etÂ al. (17) integrated TCM textbooks and \nother corpora into the Ziya-LLaMA-13B-V1 model, performing \npre-training and instruction fine-tuning on ancient TCM texts to \ncreate HuangDi, which provided the model with the ability to answer \nquestions on ancient TCM knowledge. These studies illustrate the \nsignificant potential of LLMs in TCM case record research. However, \nseveral challenges and concerns still emerge in practical applications. \nFirst, the challenge of hallucination (18), wherein the model generates \ninaccurate or unreliable outputs. Second, the absence of natural \nlanguage dialogue-based querying for TCM knowledge graphs. \nTherefore, optimizing LLMs to ensure the accuracy of output results \nand developing more sophisticated dialogue systems to enhance the \napplication of TCM knowledge graphs are crucial directions for \nimproving the effectiveness of these applications.\n2.3 Research combining knowledge graphs \nand large language models\nThe integration of LLMs with KGs has been shown to beÂ  an \neffective strategy for reducing hallucinations in LLMs. Guan etÂ al. (19) \nintroduced the KGR algorithm, allowing LLMs to extract, verify, and \nrefine factual statements by utilizing the knowledge stored in KGs. \nThis method directly addresses the hallucination issue in LLMs. Sun \netÂ al. (20) proposed the ToG method, establishing a new paradigm for \nLLM-KG integration referred to as â€œLLM âŠ— KG. â€ In this approach, \nLLMs act as agents exploring relevant entities and relationships within \nthe KG, performing reasoning based on the retrieved knowledge, \nthereby enhancing knowledge traceability and modifiability in LLMs. \nY ang etÂ  al. (21) developed a KG-enhanced large language model \n(KGLLM), providing a solution to improve LLMsâ€™ factual reasoning \ncapabilities. Carlos etÂ al. (22) successfully demonstrated interpretable \nreasoning by combining KGs and LLMs. Zhang etÂ al. (23) designed a \nquestion-answering system grounded in LLMs and KGs, utilizing \nTCM prescriptions as an example, which facilitates information \nfiltering, professional question-answering, and the capabilities of \nextraction and transformation. These studies indicate that KGs, as a \nstructured form of knowledge representation, can provide models \nwith enhanced and more accurate contextual information. By \ncombining LLMs with KGs, models can access comprehensive and \nprecise knowledge input, thereby reducing biases and inaccuracies in \nthe generative process. Therefore, the integration of LLMs with KGs \nholds promise for mitigating hallucinations in LLMs and provides \nmore reliable and effective support for TCM case study research. \nAlthough these studies demonstrate the potential of combining LLMs \nand KGs, the exploration of their in-depth applications in the \nspecialized domain of TCM case studies remains limited. To address \nthis gap, this study proposes a method for constructing a TCM case \nknowledge graph aided by LLMs and develops a question-answering \nsystem for TCM case studies by integrating LLMs and KGs, specifically \nfocusing on their application within the TCM case study domain.\n3 Materials and methods\n3.1 Overview of the QA system framework\nThe overall structure of the TCM case question-answering system, \nwhich incorporates LLMs along with knowledge graphs, is illustrated \nin FigureÂ  1. This system structure primarily comprises two key \ncomponents: knowledge graph construction and question-answering \nsystem development. In the knowledge graph construction phase, this \nstudy utilizes a hybrid approach of LLMs and manual verification to \ndevelop the TCM case knowledge graph. Based on the constructed \nknowledge graph, a TCM case question-answering system is \nsubsequently developed. In the question-answering system \ndevelopment phase, the fusion of LLMs and knowledge graphs \nexploits the natural language processing capabilities of the LLMs to \ninterpret user inquiries. By querying the knowledge graph, relevant \ninformation related to the userâ€™s inquiries is extracted. Finally, the \nacquired knowledge is synthesized and articulated, and presented to \nthe user in a natural language format, thereby enhancing the \nfacilitation of natural language queries within the TCM case \nknowledge graph.\n3.2 Methods for knowledge graph \nconstruction\nDuring the process of constructing a knowledge graph, a \nstructured method is applied systematically (24). This methodology \ncomprises four steps: schema layer construction, knowledge \nextraction, knowledge fusion, and data storage and visualization. \nKnowledge extraction entails recognizing named entities and their \nrelationships. FigureÂ  2 depicts the process for constructing the \nknowledge graph via a flowchart.\n3.2.1 Data sources\nThe main data source for constructing the knowledge graph is \nthe Medical Cases of Wang Zhongqi  ( 25). This book records the \nclinical cases of Wang Zhongqi, a renowned modern Chinese \nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 04 frontiersin.org\nphysician, from 1923 to 1935. Assembled and carefully selected by \nhis students over a period exceeding two decades, the book distills \nthe essence of the original medical cases, thoroughly demonstrating \nWang Zhongqiâ€™s medical expertise. Issued by a reputable publishing \nhouse, the book exhibits a high degree of accuracy and authority. \nWeÂ  inputted and processed the data from the manuscript and \ncompiled it into an Excel spreadsheet, obtaining a total of 1,573 \nmedical cases. To ensure the precision of the knowledge graph, our \nstudy only included medical cases that explicitly contained all entity \ninformation, such as disease names, symptoms, pathogenesis, \ntreatment principles, and medications. Medical cases missing any \nentity information were excluded from the dataset. Following \nscreening, a total of 679 cases were included, encompassing 41 \ndistinct diseases. The distribution of diseases within the medical \ncases is illustrated in TableÂ 1.\n3.2.2 Schema layer construction\nThe development of the schema layer (26) entails the definition of \nthe information structure and data model within the knowledge graph, \nincorporating the types of entities and the relationships between them.\nTo ensure the accuracy and coherence of the schema layer \ndevelopment, weÂ  first consult the semantic types and semantic \nrelationships articulated in the â€œHealth Informaticsâ€”Semantic Network \nFramework of Traditional Chinese Medicine Language Systemâ€ (27) and \nemploy a top-down approach to design the schema layer structure. \nSubsequently, in alignment with the specific structural characteristics of \nthe Medical Cases of Wang Zhongqi, weÂ utilize a bottom-up approach to \nrefine the schema layer structure, thereby enhancing its accuracy in \nreflecting the content of the medical cases.\nThe entity types in the knowledge graph are delineated in TableÂ 2, \nwhile the relationship types are illustrated in TableÂ 3.\nFIGUREÂ 1\nThe overall framework of Traditional Chinese Medicine Case Q&A System Combining Big Language Model and Knowledge Graph. By utilizing large \nlanguage models and manual proofreading, the Medical Cases of Wang Zhongqi are organized into a knowledge graph. When a user submits a \nquestion, the large language model recognizes the query content from the userâ€™s inquiry and conducts a search within the knowledge graph. Relevant \ninformation pertaining to the userâ€™s question is delivered to the large language model, which then integrates this information to generate a response.\nFIGUREÂ 2\nProcess diagram of knowledge graph construction method. The construction process of the pattern layer is based on the national standards of \nTraditional Chinese Medicine and the specific structure of medical cases, which encompasses the definition of entity types and relationship types. The \ndata extraction process involves selecting appropriate medical cases from the Medical Cases of Wang Zhongqi, followed by automated entity \nrecognition using a large-scale language model. Subsequently, knowledge fusion is conducted individually for different entity types, resulting in the \nformation of relationship triples. The data storage and visualization process employs Cypher queries to store the data in the Neo4j graph database.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 05 frontiersin.org\nTABLEÂ 1 Distribution of diseases included in medical records.\nDisease name Frequency Disease name Frequency Disease name Frequency\nAbdominal Pain 56 Liver Y ang Rising and \nLiver Wind\n15 Flooding and Spotting 9\nSeasonal Illness 47 Abdominal Masses and \nLumps\n15 Leucorrhea 9\nDiarrhea 38 Lin Syndrome and Turbid \nUrine\n15 Nosebleed 9\nHemoptysis 37 Nocturnal Emission and \nImpotence\n15 Constipation 8\nDamp-Heat Syndrome 36 Various Orifices 15 Postpartum 7\nDysentery 30 Jaundice 14 External Syndrome 7\nIrregular Menstruation 28 Vomiting and Diarrhea 14 Deficiency Fatigue 7\nAbdominal Distension 24 Vomiting 13 Intestinal Parasites 5\nCough 23 Throat 13 Edema 5\nStroke 23 Nourishing Tonic Pastes, \nPills, and Powders\n13 Phlegm-Fluid Retention 5\nSpleen and Stomach \nDisorders\n19 Tuberculosis 12 Lung Abscess 3\nAtrophy 18 Depressive Disorder 12 Sweating Disorder 2\nAsthma 18 Insomnia 11 Diabetes 2\nBlood Stasis 16 Malaria Pathogen 11\nTotal 679\nTABLEÂ 2 Entity type.\nEntity type Definition\nDisease name The name of a pathological process characterized by the conflict between pathogenic factors and the bodyâ€™s normal defenses, such as dysentery \nand asthma.\nSymptom The abnormal state exhibited by the body due to disease, encompassing various anomalous sensations experienced by the patient as well as \nabnormal presentations perceived by the physicianâ€™s sensory organs, such as cough and dizziness.\nPathogenesis The study of the mechanisms underlying the development and progression of diseases based on foundational theories of Traditional Chinese \nMedicine (TCM), such as lung qi rebelliousness and liver yang hyperactivity.\nTreatment Principle A comprehensive analysis of disease based on holistic concepts and differential diagnosis, utilizing objective data collected through the four \ndiagnostic methods to formulate treatment rules tailored to different pathogenesis, such as dispersing wind and relieving the exterior or \nsoothing the liver and resolving depression.\nMedication Medicines used for disease prevention, treatment, and healthcare, guided by TCM theories and clinical experience, such as Poria (Fu Ling) and \nAstragalus (Huang Qi).\nTABLEÂ 3 Relationship type.\nRelationship Subject Object Example\nBelongs to Symptom Disease Name Hemiplegiaâ€”belongs toÂ -> Stroke\nCauses Pathogenesis Symptom Stomach Qi Rebellionâ€”causesÂ -> Hiccup\nFollows Pathogenesis Treatment Principle Yin Deficiency with Hyperactivity of Fireâ€”\nfollowsÂ -> Nourish Yin and Reduce Fire\nRecommends Treatment Principle Medication Dispel Exterior and Ventilate the Lungâ€”\nrecommendsÂ -> Mulberry Leaf\nApplies Symptom Treatment Principle Coughâ€”appliesÂ -> Dispel Exterior and Ventilate the Lung\nTreats Medication Pathogenesis Angelica dahurica (Bai Zhi)â€”treatsÂ -> Defensive Qi \nDeficiency\nTreats Medication Symptom Mint (Bo He)â€”treatsÂ -> Head Distention and Pain\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 06 frontiersin.org\n3.2.3 Knowledge extraction\nKnowledge extraction ( 28) is defined as the process of \ntransforming raw data into standardized categories, with the \nprimary goal of identifying entities and the relationships among \nthem from various data sources. In this study, knowledge extraction \nis comprised of two steps: named entity recognition and \nrelationship extraction.\n3.2.3.1 Named entity recognition\nNamed Entity Recognition (NER) is a critical component of \nnatural language processing. Its goal is to automatically identify and \nclassify entities with specific meanings from text, forming the basis for \nknowledge graph construction. In this study, the classification of \ndisease names is based on the chapters of Medical Cases of Wang \nZhongqi, and the entities targeted for extraction from these medical \ncases include symptoms, pathogenesis, treatment principles, and \nmedicinal usage.\nThis research employs LLMs to automate the named entity \nrecognition process, utilizing the GLM-3-Turbo API ( 29) in \nconjunction with few-shot learning ( 30) strategies. The goal is to \novercome the practical constraint of limited annotated data resources \nin the field of TCM, capitalizing on the generalization capabilities of \nLLMs to accurately identify key entity information in medical \ncase records.\nUsing symptom entity recognition as an example, the prompt \ndesign is detailed in TableÂ 4. The System section includes the task \ndescription, output format requirements, and specific examples \nutilized for few-shot learning, while the Human section provides the \ninput medical case text that requires named entity recognition. To \nensure the accuracy of NER achieved by the LLM, three typical \nexamples were constructed in the few-shot learning section:\nA sentence that explicitly provides symptom descriptions. This \nexample ensures that the LLM can learn and grasp the main \ncharacteristics of symptom expressions within their contextual \nenvironment, enhancing the modelâ€™s sensitivity to symptom entities.\nA sentence that does not include symptom information. This \nserves as a counterexample, aiding the model in learning the correct \nresponse mechanism in the absence of target entities, thereby reducing \nthe likelihood of incorrect recognition.\nA sentence containing modifiers related to symptom alleviation. \nThis is intended to strengthen the modelâ€™s ability to handle complex \nexpressions, enabling accurate identification of symptom entities \nacross various descriptive forms and enhancing both \ncomprehensiveness and robustness in recognition.\n3.2.3.2 Relation extraction\nThe extraction of entity relations is an essential task in the field \nof information retrieval. It involves the identification and extraction \nof specified relationships between entities from unstructured text, \nwhich relies on entity recognition. These relationships are typically \nexpressed as relational triples 12,,e re , where 1e  and 2e  each \nrepresent entities, and the connection r between them is defined by \na predefined set of relationships { }123,,, , iRrr r r â€¦ . The goal of \nrelation extraction is to obtain these relational triples 12,,e re  from \nnatural language text, which helps acquire relevant information \nfrom the text.\nTo reflect the principles of TCM and to reveal the complex \nrelationships between entities such as disease names, symptoms, \nmedications, pathogenesis, and treatment principles, the extracted \nentities need to beÂ efficiently combined according to the relationship \ntypes established in the schema construction phase. This will facilitate \nthe formation of TCM-specific relational triples. In this study, the \nextracted entities are recorded in an Excel spreadsheet, and the pandas \nlibrary1 is utilized to read and combine the triples.\n3.2.4 Knowledge fusion\nKnowledge fusion refers to the process of unifying and integrating \nheterogeneous data extracted from various types of knowledge. Due \nto the personalized nature of medical case records, the terminology \nwithin these records often displays non-standardized characteristics, \nfailing to comply with uniform expression guidelines. To ensure the \nstandardization of entities, it is necessary to systematically normalize \nthe extracted entities, with the goal of eliminating the variations in \npersonalized expressions in medical case records and to standardize \nthe terminology.\nThis study adopts a LLM-assisted approach, combined with \nmanual proofreading, to unify and normalize the entities extracted \nduring the knowledge extraction process, as illustrated in FigureÂ 3.\nFor symptom entities, given the diversity and complexity of \nsymptom descriptions, the LLM is initially used to perform a \npreliminary professional processing of the symptom entities. This \naims to capture and standardize the core symptoms expressed in \nmultiple forms. Subsequently, manual review and proofreading are \nconducted to ensure the consistency and accuracy of the symptom \nterminology. Our approach to manual proofreading includes \ninviting two researchers with backgrounds in traditional Chinese \nmedicine to independently review the extracted entities. To enhance \naccuracy, weÂ  employ a cross-proofreading method, where each \nresearcherâ€™s corrections are cross-verified by the other. This \ncollaborative process ensures high standards of precision and \nconsistency in the terminology used. The manual proofreading \nprocess follows the guidelines from the Normative Terminology for \nCommon Symptoms in Traditional Chinese Medicine and Diagnostics \nof Traditional Chinese Medicine, striving for simplicity and generality \nin linguistic expression. For example, non-standardized colloquial \ndescriptions such as â€œslight abdominal bloatingâ€ are normalized to \nâ€œabdominal distensionâ€; compound symptoms, such as â€œswelling in \nthe neck and below the ear, â€ are split into â€œneck swellingâ€ and \nâ€œsubaural swelling. â€ However, for entities that describe the nature of \nsymptoms, to preserve the integrity of the symptom description, no \nsplitting is performed, such as keeping â€œhead distension and painâ€ \nas â€œhead distension and pain. â€\nFor pathomechanism entities, standardization is conducted based \non the Clinical Terminology of Traditional Chinese Medicineâ€”Part 2: \nSyndrome and the 2017 Dictionary of Traditional Chinese Medicine. \nFor therapeutic principle entities, normalization adheres to the \nClinical Terminology of Traditional Chinese Medicineâ€”Part 3: \nTherapeutic Methods, 2017 Dictionary of Traditional Chinese Medicine, \nPractical Dictionary of Traditional Chinese Medicine Terminology, and \nthe Subject Headings of Chinese Medicine. For medication entities, \nstandardization is conducted according to the Chinese Pharmacopoeia \nand the Compendium of Chinese Herbal Medicine.\n1 https://pandas.pydata.org/pandas-docs/stable/\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 07 frontiersin.org\nTABLEÂ 4 Prompt of symptom entity recognition.\nSystem:\nä½ çš„ä»»åŠ¡æ˜¯æå–å‡ºæ–‡æœ¬ä¸­çš„ç—‡çŠ¶ï¼Œç”¨åˆ—è¡¨çš„æ ¼å¼åˆ—å‡ºï¼Œ\nè‹¥æ–‡æœ¬ä¸­æ— ç—‡çŠ¶è¯·è¾“å‡ºâ€œNaNâ€ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¾‹å­:\nInput: è…°ç–½æ„ˆåï¼Œè‚¾ä¼¤æœªå¤ï¼Œé£é‚ªæ˜“ä¹˜è™šè€Œè¢­ï¼Œèº«çƒ­å½¢\nå¯’ï¼Œå¤´è„‘èƒ€ç—›çœ©æ™•ï¼Œé¡¹èƒŒè‚©èƒ›é…¸èƒ€ï¼Œè„‰æµ®è€Œæ¿¡ï¼ŒèˆŒå¹²è€Œ\nç‡¥ã€‚\nOutput: [â€˜èº«çƒ­å½¢å¯’â€™,  â€˜å¤´è„‘èƒ€ç—›çœ©æ™•â€™,  â€˜é¡¹èƒŒè‚©èƒ›é…¸èƒ€â€™,  â€˜è„‰\næµ®è€Œæ¿¡â€™,  â€˜èˆŒå¹²è€Œç‡¥â€™]\nInput: å†ä»¥å®£æ¹¿é™¤é™ˆï¼Œä»¥é†’èƒƒæ°”ï¼Œè°ƒç†å°šé¡»ä»ç¼“ä¹Ÿã€‚\nOutput: NaN\nInput: ç‡¥å±å·²ä¸‹ï¼Œéƒçƒ­ä¸‹è¡Œï¼Œé¢§çº¢ã€å”‡ç»›ã€èˆŒèµ¤å‡å·²é€€\næ·¡ï¼ŒèŠ’åˆºäº¦è½¯ï¼ŒæƒŸåˆåç¨è§‰çƒ¦èºï¼Œå…¥å¤œçŠ¹æ¬ æ¸…çˆ½ã€‚\nOutput: [â€˜æƒŸåˆåç¨è§‰çƒ¦èºâ€™,  â€˜å…¥å¤œçŠ¹æ¬ æ¸…çˆ½â€™]\nHuman:\nä½¿ç”¨ç»™å‡ºçš„æ ¼å¼æå–ä»¥ä¸‹æ–‡æœ¬ä¸­çš„ä¿¡æ¯ã€‚\nInput: {ä¸­åŒ»åŒ»æ¡ˆ}\nOutput:\nSystem:\nY our task is to extract symptoms from the text and list them in a format like a list. If there are no symptoms, \noutput â€˜NaNâ€™ . Here are some examples:\nInput: After recovering from a lumbar abscess, kidney injury remains unresolved, making it easy for wind \npathogens to take advantage of the deficiency. The patient experiences body heat with aversion to cold, head \ndistention with dizziness, aching and distension in the nape and scapula, a floating and soft pulse, and a dry \nand parched tongue.\nOutput: [â€˜Body heat with aversion to coldâ€™ , â€˜Head distention with dizzinessâ€™ , â€˜ Aching and distension in the nape \nand scapulaâ€™ , â€˜Floating and soft pulseâ€™ , â€˜Dry and parched tongueâ€™]\nInput: Followed by dispelling dampness and eliminating stagnation to awaken stomach qi, the treatment needs \nto beÂ adjusted slowly.\nOutput: NaN\nInput: Dry stools have been passed, the heat has descended, and the red cheeks, crimson lips, and red tongue \nhave faded. The prickles on the tongue have softened, but the patient still feels some restlessness in the \nafternoon and is not entirely comfortable at night.\nOutput: [â€˜Restlessness in the afternoonâ€™ , â€˜Not entirely comfortable at nightâ€™]\nHuman:\nExtract information from the following text using the given format.\nInput: {TCM medical case}\nOutput:\nFIGUREÂ 3\nProcess flow diagram for standardizing different entities. Given the diversity and complexity of symptom descriptions, symptom entities are subjected \nto initial processing by a large-scale model, followed by subsequent manual verification based on standards issued by recognized organizations. The \nentities pertaining to pathogenesis, treatment principles, and medication are standardized directly according to the regulations published by these \nrecognized bodies.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 08 frontiersin.org\n3.2.5 Data storage and visualization\nThis study presents the knowledge of TCM medical cases in the \nform of a knowledge graph, using triples ( ) [ ]{ }, , | 1,iiihrt i N âˆˆ  to define \nknowledge, where each ( ),,iiihrt  corresponds to a head entity, a \nrelationship, and a tail entity. ğ‘ denotes the quantity of triples in the \nknowledge graph. Given a knowledge graph, the triples within the \ngraph can beÂ encoded into Equation 1.\n [ ] [ ] [ ] [ ]111 2 2 2, ,,, , , , , , , , , , NNNS s hrt e h r t e h r t eï£®ï£¹= â€¦ï£°ï£»  (1)\nThe Neo4j graph database (31), due to its adaptive data model, \nhighly efficient query performance, and facilitated scalability and \nintegration, has become a widely used graph database for constructing \nknowledge graphs. This study utilizes the Neo4j graph database to \nstore and visualize the knowledge graph, leveraging the Py2neo \nlibrary2 to create Cypher queries for building the graph. A partial view \nof the developed knowledge graph is presented in FigureÂ 4.\nIn the graph, the nodes depict the entities within the triples, while \nthe edges illustrate the relationships in the triples. A relationship \nbetween two nodes is represented by an edge directed from one node \nto the other, with the edgeâ€™s direction indicating a relationship from \nthe subject to the object.\n3.3 Methods for constructing a QA system\nDrawing upon the constructed knowledge graph, the integration \nof LLMs with the knowledge graph seeks to facilitate natural language \nqueries for the TCM case knowledge graph. The method for \nconstructing the question-answering system consists of four primary \nsteps: entity extraction, Cypher query generation, node querying, and \nresponse generation. The flowchart depicting the construction of the \nquestion-answering system is presented in FigureÂ 5.\nUtilizing the Langchain library3 and interfacing with the GPT-3.5-\nTurbo API, the connection between the LLM and the knowledge \ngraph is established, allowing the language model to interpret the \nstructure and content of the knowledge graph.\n3.3.1 Extracting entities\nWhen a user submits a query to a LLM, the model employs its \nnatural language processing capabilities to analyze the query and \nidentify key entities within it, such as diseases, symptoms, or \ntraditional Chinese medicine. The purpose of this step is to accurately \nunderstand the userâ€™s question, which acts as the foundation for \nsubsequent query processes.\n3.3.2 Generating cypher statements\nBased on the extracted entities, relevant Cypher queries are \ngenerated by the LLM. Due to the inherent instability in the results \ngenerated by the LLM, a consistent structure is employed to ensure \nthe accuracy of the generated Cypher queries. The model populates \n2 http://py2neo.org/\n3 https://www.langchain.com/\nthe extracted entities within the predefined structure to produce the \nCypher queries.\n3.3.3 Querying nodes\nThe generated Cypher queries are then sent to the knowledge \ngraph for execution, returning the entity nodes pertinent to the userâ€™s \nquery, along with the relationships between these entities.\n3.3.4 Generating answers\nBased on the results returned from the knowledge graph, the \nsystem formulates a response to beÂ  presented to the user. This \nprocedure ensures the precision and pertinence of the response, as \nillustrated in FigureÂ 6.\n4 Results\nTo evaluate the capabilities of named entity recognition (NER) \namong various LLMs in the context of constructing knowledge graphs \nand their performance in response generation through integration \nwith knowledge graphs, a comparative experiment was conducted on \nfive representative models: GPT-3.5-Turbo, GLM-3-Turbo, Qwen-\nTurbo, Spark3.5 Max, and Moonshot-V1-8K. WeÂ  utilized APIs to \ninteract with these models, enabling efficient testing and comparison \nof their functionalities.\nAs part of OpenAIâ€™s GPT series, GPT-3.5-Turbo is noted for its \nrobust text generation and comprehension capabilities, where robust \ntext generation refers to the modelâ€™s ability to generate text that is \ncoherent, contextually relevant, and grammatically accurate across a \nbroad range of topics. This strength allows it to excel in various \nnatural language processing tasks. This model has demonstrated \nstrong performance in understanding complex inputs and generating \nmeaningful outputs. Qwen-Turbo not only demonstrates excellence \nin text generation but also exhibits strong proficiency in integrating \nstructured knowledge. GLM-3-Turbo has been specifically optimized \nfor Chinese-language environments, making it particularly skilled at \nunderstanding and generating Chinese text. Spark3.5 Max \ndemonstrates exceptional performance in downstream tasks that \nrequire a profound understanding and application of extensive \nbackground knowledge. Finally, Moonshot-V1-8K is noted for its \nhigh level of innovation and is particularly proficient in handling \nlong-sequence texts.\n4.1 Evaluation of named entity recognition\nIn Named Entity Recognition (NER) tasks, key metrics for \nevaluating model performance include precision, recall, and the \nF1 score.\nPrecision represents the ratio of correctly identified entities to the \ntotal entities predicted by the model, as detailed in Equation 2.\n \nTPPrecision TP FP= +  \n(2)\nRecall assesses the ratio of correctly identified entities \ncompared to all actual entities in the dataset, as outlined in \nEquation 3.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 09 frontiersin.org\n \nTPRecall TP FN= +  \n(3)\nThe F1 score is a widely used statistical metric for assessing the \nperformance of binary classification models. It is calculated as the \nharmonic mean of precision and recall, as shown in Equation 4.\n \n12 Precision RecallF Precision Recall\nÃ—= Ã— +  \n(4)\nTP (True Positive) refers to the number of entities accurately \nidentified by the model. FP (False Positive) refers to instances where \nthe model incorrectly classifies non-entities as entities. FN  (False \nNegative) denotes the number of actual entities that the model fails \nto accurately identify.\nAll models were assessed on the same test set, which was \nrandomly selected from the Medical Cases of Wang Zhongqi. The test \nset contains 200 annotated sentences, covering entity types such as \nsymptoms, pathogenesis, and treatment principles.\nThe evaluation results are summarized in TableÂ 5.\nThe evaluation results indicate that the GLM-3-Turbo model \nexhibited exceptional overall performance, with the highest precision, \nrecall, and F1 scores, which were 0.9462, 0.9778, and 0.9617, respectively. \nThis suggests that the model not only accurately identifies entities but \nalso efficiently minimizes false positives. Although the GPT-3.5-Turbo \nmodel performed well in terms of recall, its precision was comparatively \nlow, resulting in an F1 score of merely 0.6287. This implies that while \nthe model can recognize most entities, it also has a considerable false \npositive rate. Both the Spark3.5 Max and Qwen-Turbo models exhibited \nsatisfactory recall, but their precision was notably lower, indicating that \nFIGUREÂ 4\nVisualization of the Medical Cases of Wang Zhongqi Knowledge Graph. In this figure, the purple nodes represent disease names, yellow nodes \nrepresent symptoms, blue nodes represent pathogenesis, red nodes represent treatment principles, and green nodes represent medications. The \nrelationships between these entities are indicated as follows: disease names are connected to symptoms by the â€œBelongsToâ€ relationship, symptoms \nare connected to treatment principles by the â€œAppliesâ€ relationship, symptoms are linked to pathogenesis by the â€œCausesâ€ relationship, treatment \nprinciples are connected to medications by the â€œRecommendsâ€ relationship, pathogenesis is connected to treatment principles by the â€œFollowsâ€ \nrelationship, medications are linked to symptoms by the â€œTreatsâ€ relationship, and medications are also connected to pathogenesis by the â€œTreatsâ€ \nrelationship.\nFIGUREÂ 5\nQ&A system construction flowchart. After the user has submitted a question, a large language model is invoked to perform extractive entity \nrecognition and generate Cypher statements. This process queries the nodes in the knowledge graph, and based on the information retrieved from the \nknowledge graph, an answer is generated.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 10 frontiersin.org\nthese models have some capability in entity detection but still necessitate \nimprovement in minimizing false positives. The Moonshot-V1-8K \nmodel achieved a favorable balance between precision and recall, \nresulting in a comparatively high F1 score.\nAmong all the evaluated models, the GLM-3-Turbo model \nexhibited the highest overall performance and was therefore chosen \nfor constructing the TCM case knowledge graph.\n4.2 Evaluation of generated responses\nThe question-answering system that integrates LLMs with \nknowledge graphs can beÂ  viewed as a Retrieval-Augmented \nGeneration (RAG) process, where the knowledge graph serves as an \nexternal database. Therefore, the RAGAS framework is chosen for \nevaluation, aiming to objectively assess the systemâ€™s information \nretrieval and generation capabilities.\nRAGAS (32) is an automated evaluation framework for RAG \nprocesses, which assesses the effectiveness of RAG by analyzing the \ncorrelation among the three key elements: the input query, the \nretrieved context, and the response generated by the LLM. Its \nevaluation metrics include faithfulness, answer relevance, and context \nrecall, as illustrated in FigureÂ 7.\nFaithfulness measures whether the answer is based on the \nprovided context. First, a set of statements ( )( )Saq  is extracted \nusing a LLM, which then assesses whether each statement is  can \nbeÂ deduced from ( )cq . The final faithfulness score F  is calculated \nas shown in Equation 5 , where V  represents the number of \nstatements supported by the LLM, and S  represents the total \nnumber of statements.\n \nVF S=\n \n(5)\nAnswer relevance is an indicator of the correspondence between \nthe generated answer and the query. The LLM generates n potential \nquestions iq  based on the given answer, and for each question iq , it \ncomputes the similarity ( ), isim q q  to the original query q through \ncosine similarity of the embeddings. The answer relevance score AR \nfor the question q is calculated as shown in Equation 6.\nFIGUREÂ 6\nThe query process and responses of the question-answering system. Upon receiving the userâ€™s query, the system first extracts entities related to \nTraditional Chinese Medicine from the question. The system then inserts these extracted entities into a pre-defined Cypher query template and uses \nthe populated Cypher query to search for these entities, their related entities, and their interrelationships within the knowledge graph. Finally, based on \nthe retrieved data, the system generates and provides a response to the userâ€™s query.\nTABLEÂ 5 Named entity recognition evaluation results.\nPrecision Recall F1 scores\nGPT-3.5-Turbo 0.4834 0.8989 0.6287\nGLM-3-Turbo 0.9462 0.9778 0.9617\nSpark3.5 Max 0.8173 0.9200 0.7892\nQwen-Turbo 0.6335 0.8883 0.7395\nMoonshot-V1-8 K 0.9086 0.8833 0.8958\nBold values indicate superior performance.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 11 frontiersin.org\n \n( )\n1\n1 ,\nn\ni\ni\nAR sim q qn =\n= âˆ‘\n \n(6)\nContext recall measures the degree of consistency between the \nretrieved context and the annotated answer. The formulation is \npresented in Equation 7.\n \nGround truth sentences that can be attributed \nto contextcontext recall Number of sentences in Ground \ntruth sentences\n=\n (7)\nTo comprehensively evaluate the performance of the TCM case-\nbased question-answering system, 20 evaluation questions were \ndesigned, covering core dimensions such as diseases, symptoms, \npathogenesis, treatment principles, and medication. The evaluation \nquestions, retrieved contexts, responses generated by the question-\nanswering system, and the correct answers to the evaluation questions \nwere compiled into a CSV file to construct the evaluation dataset. The \ncomposition of this dataset is shown in TableÂ 6.\nThe evaluation results of RAGAS are presented in TableÂ 7.\nThe evaluation results indicate that the GPT-3.5-Turbo model \nachieved the highest scores in three dimensions: fidelity, answer \nrelevance, and context recall, with scores of 0.9375, 0.9686, and 0.9500, \nrespectively. This suggests its outstanding performance in terms of the \naccuracy and relevance of generated answers, as well as its ability to \neffectively integrate contextual information. The GLM-3-Turbo model \nexhibited balanced performance, with context recall comparable to \nthat of GPT-3.5-Turbo. Spark3.5 Max excelled in answer relevance but \nexhibited lower fidelity. Qwen-Turbo demonstrated suboptimal \nperformance in both answer relevance and fidelity metrics. The overall \nperformance of the Moonshot-V1-8K model was considered moderate.\nThe GPT-3.5-Turbo model exhibited significant advantages in the \nRAGAS evaluation; thus, it was selected for integrating LLMs with \nknowledge graphs and generating responses.\nIn summary, the integration of LLMs with knowledge graphs in \nthe TCM case system demonstrated superior performance in terms of \nanswer accuracy, question-answer relevance, and context application, \nenabling efficient and accurate querying of the TCM case \nknowledge graph.\n4.3 Manual evaluation\nTo validate the safety, accuracy, and professionalism of the \nquestion-answering system, this study employed the SUS ( 15) \n(Safety, Usability, Smoothness) evaluation method. A comparative \nevaluation will beÂ conducted between a question-answering system \nintegrated with LLM and knowledge graphs, and a LLM without \nRAG technology. The SUS evaluation method consists of three \ndimensions: safety, usability, and smoothness. Safety evaluates \nwhether the model-generated content could mislead users and pose \npotential health risks; usability assesses whether the content meets \nprofessional knowledge requirements; smoothness examines the \nresponse stability and naturalness of the model. SUS employs a \nthree-point scoring system, with scores ranging from 1 \n(unacceptable) to 3 (good), where 2 indicates acceptable \nperformance. To evaluate the modelâ€™s performance, five evaluators \nwith backgrounds in traditional Chinese medicine were invited to \nscore 20 randomly selected diagnostic questions related to \ntraditional Chinese medicine. The evaluators analyzed the LLMsâ€™ \nresponses to determine whether they posed a health risk to users, \nwhether they demonstrated professional Chinese medicine \nknowledge, and whether they were suitable for public use. Based on \nthe three dimensions of the SUS evaluation, the modelâ€™s question-\nanswering performance was analyzed and scored in terms of safety, \nusability, and smoothness. TableÂ 8 presents the evaluation results.\nAccording to the SUS evaluation results, our Q&A system \nperformed excellently in all dimensions, especially excelling in safety \nand usability, fully demonstrating its reliability and professionalism in \nproviding traditional Chinese medicine health consultation services \nto users. Specifically, the system excels in safety and usability, \neffectively preventing the generation of erroneous or misleading \nhealth advice, ensuring that users are not exposed to potential medical \nFIGUREÂ 7\nRAGAS evaluation framework. It evaluates the effectiveness of RAG \nby measuring the relevance between the query, answer, and relevant \ncontext.\nTABLEÂ 6 Evaluate dataset structure.\nDefinition\nQuestion An evaluative query posed for assessment purposes.\nAnswer The response generated by the question-and-answer \nsystem.\nContexts Contextual information retrieved from the knowledge \ngraph.\nGround truths The correct answers corresponding to the evaluative \nqueries.\nTABLEÂ 7 RAGAS evaluation results.\nFaithfulness Answer \nrelevance\nContext \nrecall\nGPT-3.5-Turbo 0.9375 0.9686 0.9500\nGLM-3-Turbo 0.8289 0.9036 0.9083\nSpark3.5 Max 0.6066 0.9477 0.9344\nQwen-Turbo 0.5687 0.8099 0.9474\nMoonshot-V1-8K 0.7708 0.9235 0.9357\nBold values indicate superior performance.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 12 frontiersin.org\nrisks. This is something traditional LLMs (e.g., GPT-3.5-Turbo and \nGLM-3-Turbo) cannot achieve, as these models typically lack \nspecialized knowledge in the field of traditional Chinese medicine and \nare prone to generating inaccurate answers in this area.\nAlthough other existing LLMs perform excellently in smoothness, \ngenerating relatively natural and coherent language, they still have \nsignificant room for improvement in terms of safety and usability. This \nis because the answers from these general-purpose LLMs may lack \nspecialized knowledge in traditional Chinese medicine, leading them \nto fail in providing sufficiently accurate or personalized answers when \nfaced with Chinese medicine diagnostic and treatment issues. \nMoreover, since they do not integrate the knowledge graph of \ntraditional Chinese medicine case studies, they may struggle to access \nthe clinical experience of real-world Chinese medicine practitioners, \nthus affecting the professionalism of the Q&A.\nIn contrast, our system combines LLMs with a knowledge graph, \nparticularly in utilizing the Chinese medicine case knowledge graph \nto enhance the modelâ€™s professionalism. The knowledge graph \nsupplements the language modelâ€™s lack of depth in knowledge, and by \nusing the relationships between symptoms, disease names, treatment \nprinciples, pathogenesis, and medications in Chinese medicine case \nstudies, it significantly enhances the accuracy and professionalism of \nthe systemâ€™s responses, avoiding misleading answers that may arise \nfrom general LLMs when addressing professional medical issues.\nOverall, the traditional Chinese medicine case-based Q&A \nsystem, based on LLMs and knowledge graphs, provides outstanding \nperformance in terms of security, professionalism, and fluency, \nsignificantly outperforming traditional Q&A systems that rely solely \non LLMs, and has enormous potential for application.\n5 Discussion\nThis study utilizes the Medical Cases of Wang Zhongqi as its data \nsource, incorporating a total of 679 cases involving 41 distinct \ndiseases. The research employs LLMs (LLMs) to automatically extract \nentities from the medical cases, followed by subsequent manual \nnormalization to construct a knowledge graph for TCM cases. By \nintegrating the capabilities of LLMs with the knowledge graph, the \nstudy developed a question-answering system for TCM medical cases, \nsuccessfully enabling natural language queries within the knowledge \ngraph of TCM medical cases. Throughout the research, the natural \nlanguage understanding and generation capabilities of LLMs, along \nwith the structured representation benefits of knowledge graphs, were \nfully utilized, offering a novel approach and tool for modern TCM \nmedical case research.\nAccording to the evaluation conducted using the RAGAS \nassessment framework, the question-answering system integrating \nLLMs and knowledge graphs achieved scores of 0.9375Â in faithfulness, \n0.9686Â in answer relevance, and 0.9500Â in contextual recall, validating \nthe potential and value of the combination of LLMs with knowledge \ngraphs to advance TCM medical case research.\nBased on the comprehensive SUS evaluation results, our QA \nsystem demonstrates outstanding performance in terms of safety, \nusability, and smoothness, significantly outperforming other existing \nQA systems. This demonstrates that the integration of LLMs and \nknowledge graphs in a TCM medical case-based QA system exhibits \nremarkable reliability, professionalism, and natural fluency when \nanswering TCM-related questions based on medical case content, \nhighlighting its substantial potential for application.\nThis paper evaluates the performance of LLMs in automatic \nNamed Entity Recognition (NER) tasks. The results indicate that the \nnumber of false positives (FP) exceeds that of false negatives (FN) in \nmost LLMs, suggesting that the modelâ€™s recall rate typically surpasses \nits precision. This phenomenon highlights the unique challenges \nencountered by Named Entity Recognition in the field of Traditional \nChinese Medicine (TCM). The polysemy and specialized nature of \nTCM terminology are primary factors influencing the accuracy of \nentity recognition. The same term may have different meanings in \nvarious contexts, complicating the entity recognition task. Moreover, \nTCM-related concepts, such as the names of formulas and herbal \ningredients, may not beÂ adequately represented in the training data of \nLLMs. Although these models can identify common medical terms, \ntheir accuracy in recognizing TCM-specific terms and symptoms \nremains limited. Furthermore, certain traditional expressions in TCM \ntheory, particularly those derived from Classical Chinese, may \ncontribute to an increased number of false positives in the models. \nThis phenomenon primarily arises from the insufficient TCM-specific \ndata available during the training of LLMs. To address this issue, \nfuture research could tailor the training of LLMs, particularly by fine-\ntuning them using TCM literature, case studies, and formula data, to \nenhance the accuracy of entity recognition in TCM, reduce false \npositives, and improve precision.\nIn practical applications of question-answering systems, retrieval \nfailures are occasionally observed, where user queries fail to return \nrelevant case studies or knowledge. Analysis reveals that a significant \ncause of retrieval failures is the inability to recognize entities in user \nqueries. When the system fails to accurately recognize TCM terms in \nthe query, it cannot extract relevant information from the knowledge \nbase, resulting in empty or inaccurate retrieval results. The root cause \nof this issue lies in the limited content from the TCM field within the \ntraining data of current LLMs. Most LLM training datasets are biased \ntoward modern medicine and other fields, with insufficient support \nfor TCM-specific symptoms, diseases, and treatments. The \nperformance of LLMs is particularly weak when addressing obscure \nor complex TCM symptoms. To enhance retrieval accuracy, future \nresearch could consider fine-tuning LLMs with TCM literature, \nclassical case studies, herbal materials, and formula data to improve \ntheir precision in TCM entity recognition.\nIn conclusion, this study introduces a novel approach and tool for \nTCM case research by leveraging LLMs to assist in the construction \nof a knowledge graph for TCM cases and the development of a \nquestion-answering system, yielding significant research outcomes. \nWith ongoing technological advancements and the expansion of \nTABLEÂ 8 SUS evaluation results.\nSafety Usability Smoothness\nGPT-3.5-Turbo 1.64 1.57 2.2\nGLM-3-Turbo 1.57 1.56 2.13\nSpark3.5 Max 1.67 1.65 2.21\nQwen-Turbo 1.74 1.67 2.17\nMoonshot-V1-8K 1.67 1.55 2.17\nOur QA system 2.868 2.848 2.98\nBold values indicate superior performance.\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 13 frontiersin.org\napplication scenarios, the integration of LLMs and knowledge graphs \nis expected to play an increasingly important role in TCM case \nresearch, accelerating the exploration of TCM diagnostic and \ntreatment practices.\nDue to the variations in diagnostic approaches among various \nTCM practitioners, the current QA system is primarily based on the \nMedical Cases of Wang Zhongqi . Future work could consider \nincorporating medical cases from diverse periods and regions to \nenrich the content and enhance the representativeness of the TCM \nknowledge graph. Additionally, future efforts will focus on enhancing \nthe intelligence of the QA system and exploring interdisciplinary \nresearch and applications. By leveraging the advancements in LLMs, \nthe intelligence of the QA system can beÂ enhanced, enabling it to \nbetter understand user needs and provide more accurate responses. \nThis will provide more comprehensive support for clinical diagnosis \nand treatment.\nData availability statement\nThe datasets presented in this study can beÂ  found in online \nrepositories. The names of the repository/repositories and accession \nnumber(s) can beÂ  found at: https://github.com/Icheo/TCM-KG- \nLLM-QASystem.\nAuthor contributions\nYD: Conceptualization, Investigation, Methodology, WritingÂ â€“ \noriginal draft, Data curation, Validation, Visualization. QZ: \nInvestigation, Writing â€“ review & editing. YL: Data curation, Writing \nâ€“ review & editing. CQ: Visualization, Writing â€“ review & editing. \nZW: Validation, Writing â€“ review & editing. HK: Supervision, Writing \nâ€“ review & editing. JH: Conceptualization, Supervision, WritingÂ â€“ \nreview & editing.\nFunding\nThe author(s) declare that financial support was received for the \nresearch, authorship, and/or publication of this article. This work was \nsupported by Key Projects of University Scientific Research Plan in \nAnhui Province (Grant no. 2024AH050917), the University Synergy \nInnovation Program of Anhui Province (Grant no. GXXT-2023-071), \nand the Open Fund of High-level Key Discipline of Basic Theory of \nTCM of the State Administration of Traditional Chinese Medicine, \nAnhui University of Chinese Medicine (ZYJCLLZD-07).\nAcknowledgments\nYuchen Duan sincerely express my gratitude to all participants for \ntheir valuable contributions, which significantly enhanced the success \nof this study. IÂ amÂ particularly appreciative to my mentor, JH, for \nproviding valuable guidance and steadfast support, which were crucial \nthroughout the research process. Furthermore, IÂ  sincerely \nacknowledge the funding organization for their substantial financial \nassistance, which was essential in completing this research. The \ncollaborative efforts of these individuals and institutions have \nundoubtedly enhanced the outcomes of this academic work.\nConflict of interest\nThe authors declare that the research was conducted in the \nabsence of any commercial or financial relationships that could \nbeÂ construed as a potential conflict of interest.\nGenerative AI statement\nThe author(s) declare that no Gen AI was used in the creation of \nthis manuscript.\nPublisherâ€™s note\nAll claims expressed in this article are solely those of the authors \nand do not necessarily represent those of their affiliated organizations, \nor those of the publisher, the editors and the reviewers. Any product \nthat may beÂ evaluated in this article, or claim that may beÂ made by its \nmanufacturer, is not guaranteed or endorsed by the publisher.\nReferences\n 1. Hu W , Xie X, Wang K, Jia A, Bai C. The effect and study methods of medical \nrecords on the cultivation of clinical thinking ability of traditional Chinese \nmedicine. Chin Med Modern Dist Educ China . (2023) 21:4â€“6. doi: 10.3969/j.\nissn.1672-2779.2023.23.002\n 2. Brown TB, Mann B, Ryder N, Subbiah M, Kaplan J, Dhariwal P , et al. Language \nmodels are few-shot learners. arXiv. (2020). doi: 10.48550/arXiv.2005.14165\n 3. Zou X. A survey on application of knowledge graph. J Phys Conf Ser . (2020) \n1487:012016. doi: 10.1088/1742-6596/1487/1/012016\n 4. Lewis P , Perez E, Piktus A, Petroni F , Karpukhin V , Goyal N, et al. Retrieval-\naugmented generation for knowledge-intensive NLP tasks. arXiv. (2021). doi: 10.48550/\narXiv.2005.11401\n 5. Chen J, Y ang F , Ren Q, Li Y , Hou J, Xing C, et al. Exploration of the research path of \nstroke ancient medical records based on knowledge element theory and knowledge graph. \nJ Basic Chin Med. (2024) 30:792â€“8. doi: 10.19945/j.cnki.issn.1006-3250.2024.05.015\n 6. Wang Q, Dai G, Guan H, Gao W . Construction and application of clinical experience \nknowledge graph for renowned TCM doctors in treating coronary heart disease. Chin J \nInform Tradit Chin Med. (2024) 31:64â€“70. doi: 10.19879/j.cnki.1005-5304.202303447\n 7. Y ang R, Y e Q, Cheng C, Zhang S, Lan Y , Zou J. Decision-making system for the \ndiagnosis of syndrome based on traditional Chinese medicine knowledge graph. \nEvid Based Complement Alternat Med . (2022) 2022:1â€“9. doi: 10.1155/2022/  \n8693937\n 8. Zhang D, Jia Q, Y ang S, Han X, Xu C, Liu X, et al. Traditional Chinese medicine \nautomated diagnosis based on knowledge graph reasoning. Comp Materials Continua. \n(2022) 71:159â€“70. doi: 10.32604/cmc.2022.017295\n 9. Zhao X, Wang Y , Li P , Xu J, Sun Y , Qiu M, et al. The construction of a TCM \nknowledge graph and application of potential knowledge discovery in diabetic kidney \ndisease by integrating diagnosis and treatment guidelines and real-world clinical data. \nFront Pharmacol. (2023) 14:1147677. doi: 10.3389/fphar.2023.1147677\n 10. Li Y , Huang S, Qi J, Quan L, Han D, Luan Z. Exploring the comprehension of \nChatGPT in traditional Chinese medicine knowledge. arXiv. (2024). doi: 10.48550/\narXiv.2403.09164\n 11. Kong Q, Chen L, Y ao J, Ding C, Yin P . Feasibility and challenges of interactive AI \nfor traditional Chinese medicine: an example of ChatGPT. Chin Med Cult . (2024) \n7:174â€“81. doi: 10.1097/MC9.0000000000000103\nDuan et al. 10.3389/fmed.2024.1512329\nFrontiers in Medicine 14 frontiersin.org\n 12. Li P , Y ang X, Bai Y , Li H. Study on named entity extraction in TCM medical \nrecords based on large language models. Chin J Lib Inform Sci Tradit Chin Med. (2024) \n48:108â€“13. doi: 10.3969/j.issn.2095-5707.202401008\n 13. Y ang T, Wang X, Zhu Y , Hu K, Zhu X. Research ideas and methods of intelligent \ndiagnosis and treatment of traditional Chinese medicine driven by large language \nmodel. J Nanjing Univ Tradit Chin Med . (2023) 39:967â€“71. doi: 10.14148/j.\nissn.1672-0482.2023.0967\n 14. Zhang Y , Hao Y . Traditional Chinese medicine knowledge graph construction based \non large language models. Electronics. (2024) 13:1395. doi: 10.3390/electronics13071395\n 15. Wang H, Liu C, Xi N, Qiang Z, Zhao S, Qin B, et al. (2023). Hua Tuo: Tuning \nLLaMA Model with Chinese medical knowledge. arXiv. (2023). doi: 10.48550/\narXiv.2304.06975 \n 16. Kang Y , Chang Y , Fu J, Wang Y , Wang H, Zhang W . (2023). CMLM-ZhongJing: \nLarge Language Model is Good Story Listener. GitHub Repository. Available at: https://\ngithub.com/pariskang/CMLM-ZhongJing (Accessed August 04, 2024).\n 17. Zhang J, Y ang S. (2023). HuangDi: Research on the Construction of Generative \nLanguage Model for Traditional Chinese Medicine Ancient Books. Available at: https://\ngithub.com/Zlasejd/HuangDi (Accessed August 04, 2024).\n 18. Zhang Y , Li Y , Cui L, Cai D, Liu L, Fu T, et al. Sirenâ€™s song in the AI Ocean: a survey \non hallucination in large language models. arXiv. (2023). doi: 10.48550/arXiv.2309.01219\n 19. Guan X, Liu Y , Lin H, Lu Y , He B, Han X, et al. Mitigating large language model \nhallucinations via autonomous knowledge graph-based retrofitting. AAAI. (2024) \n38:18126â€“34. doi: 10.1609/aaai.v38i16.29770\n 20. Sun J, Xu C, Tang L, Wang S, Lin C, Gong Y , et al. Think-on-graph: deep and \nresponsible reasoning of large language model on knowledge graph. arXiv. (2024). doi: \n10.48550/arXiv.2307.07697\n 21. Y ang L, Chen H, Li Z, Ding X, Wu X. Give us the facts: enhancing large language \nmodels with knowledge graphs for fact-aware language modeling. IEEE Trans Knowl \nData Eng. (2024) 36:3091â€“110. doi: 10.1109/TKDE.2024.3360454\n 22. Quintero-Narvaez CE, Monroy R. (2024). â€œIntegrating knowledge graph data with \nlarge language models for explainable inference. â€ in Proceedings of the 17th ACM \ninternational conference on web search and data mining. WSDMâ€™24. NewÂ Y ork, NY , USA: \nAssociation for Computing Machinery. pp.Â 1198â€“1199.\n 23. Zhang H, Wang X, Han L, Li Z, Chen Z, Chen Z. Research on question answering \nsystem on joint of knowledge graph and large language models. Journal of Frontiers of \ncomputer. Sci Technol. (2023) 17:2377â€“88. doi: 10.3778/j.issn.1673-9418.2308070\n 24. Huang J, Wang Y , Hou Z, Liu H, Dong Z. Application of knowledge graph \nTechnology in Traditional Chinese Medicine Research. Modern Chin Med . (2024) \n26:1â€“17. doi: 10.13313/j.issn.1673-4890.20240228002\n 25. Wang Z. The first volume of the Xinâ€™an medical book series, medical cases and \ntalksÂ - medical cases of Wang Zhongqi. Hefei: Anhui Science & Technology Publishing \nHouse (1992). 440 p.\n 26. Tao Y , Chen Y , Shao L, Liu X, Zhai S, Wang W . Construction and application of \nknowledge graph of traditional Chinese medicine. Beijing J Tradit Chin Med. (2022) \n41:1387â€“92. doi: 10.16025/j.1674-1307.2022.12.015\n 27. Institute of Information on Traditional Chinese Medicine, China National Institute \nof Standardization (2020). Health informaticsâ€”semantic network framework of \ntraditional Chinese medicine language system.\n 28. Rajabi E, Kafaie S. Building a disease knowledge graph. Stud Health Technol \nInform. (2023) 302:701â€“5. doi: 10.3233/SHTI230243\n 29. Du Z, Qian Y , Liu X, Ding M, Qiu J, Y ang Z, et al. (2022). â€œGLM: general language \nmodel Pretraining with autoregressive blank infilling. â€ in Proceedings of the 60th annual \nmeeting of the Association for Computational Linguistics (volume 1: Long papers). p.Â 320â€“335.\n 30. Chaaben MB, BurgueÃ±o L, Sahraoui H. (2023). â€œTowards using few-shot prompt \nlearning for automating model completion. â€ in 2023 IEEE/ACM 45th international \nconference on software engineering: New ideas and emerging results (ICSE-NIER). p.Â 7â€“12.\n 31. Fernandes D, Bernardino J. (2018). â€œGraph databases comparison: AllegroGraph, \nArangoDB, InfiniteGraph, Neo4J, and OrientDB. â€ in Proceedings of the 7th international \nconference on data science, technology and applications. DATA 2018. Setubal, PRT: \nSCITEPRESSÂ - Science and Technology Publications, Lda. p.Â 373â€“380\n 32. Es S, James J, Espinosa-Anke L, Schockaert S. RAGAS: automated evaluation of \nretrieval augmented generation. arXiv. (2023). doi: 10.48550/arXiv.2309.15217",
  "topic": "Question answering",
  "concepts": [
    {
      "name": "Question answering",
      "score": 0.5854331254959106
    },
    {
      "name": "Computer science",
      "score": 0.5065916776657104
    },
    {
      "name": "Natural language processing",
      "score": 0.4247519373893738
    },
    {
      "name": "Knowledge management",
      "score": 0.3623141050338745
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3585263192653656
    },
    {
      "name": "Data science",
      "score": 0.3351527750492096
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I253932293",
      "name": "Anhui University of Traditional Chinese Medicine",
      "country": "CN"
    }
  ]
}