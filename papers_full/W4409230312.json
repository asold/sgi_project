{
  "title": "Evaluating Accuracy and Readability of Responses to Midlife Health Questions: A Comparative Analysis of Six Large Language Model Chatbots",
  "url": "https://openalex.org/W4409230312",
  "year": 2025,
  "authors": [
    {
      "id": "https://openalex.org/A5055876308",
      "name": "Himel Mondal",
      "affiliations": [
        "All India Institute of Medical Sciences, Deoghar"
      ]
    },
    {
      "id": "https://openalex.org/A5114591892",
      "name": "Devendra Nath Tiu",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5000009451",
      "name": "Shaikat Mondal",
      "affiliations": [
        "Government Medical College and Hospital",
        "Raiganj University"
      ]
    },
    {
      "id": "https://openalex.org/A5034958807",
      "name": "Rajib Dutta",
      "affiliations": [
        "Diamond Harbour Women's University",
        "Government Medical College and Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A5001299062",
      "name": "Avijit Naskar",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5046801817",
      "name": "Indrashis Podder",
      "affiliations": [
        "College of Medicine & Sagore Dutta Hospital"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W4392782765",
    "https://openalex.org/W4391345109",
    "https://openalex.org/W4394015705",
    "https://openalex.org/W4382774929",
    "https://openalex.org/W4225117612",
    "https://openalex.org/W6869355289",
    "https://openalex.org/W4394746513",
    "https://openalex.org/W4387242094",
    "https://openalex.org/W4353016766",
    "https://openalex.org/W4394964547",
    "https://openalex.org/W6857851596",
    "https://openalex.org/W4392234111",
    "https://openalex.org/W6870825426",
    "https://openalex.org/W4388162762",
    "https://openalex.org/W4323920935",
    "https://openalex.org/W4394785742",
    "https://openalex.org/W4400310895",
    "https://openalex.org/W4391554501",
    "https://openalex.org/W4380423243",
    "https://openalex.org/W4401542157",
    "https://openalex.org/W4388832642",
    "https://openalex.org/W4403087472",
    "https://openalex.org/W4391784553",
    "https://openalex.org/W4387108520",
    "https://openalex.org/W6863456474",
    "https://openalex.org/W4394593497",
    "https://openalex.org/W2911221410",
    "https://openalex.org/W2904683726",
    "https://openalex.org/W4311572974",
    "https://openalex.org/W6855723992",
    "https://openalex.org/W4401534827",
    "https://openalex.org/W4400359054",
    "https://openalex.org/W4225398083",
    "https://openalex.org/W4385719470",
    "https://openalex.org/W4393112132",
    "https://openalex.org/W4388370035"
  ],
  "abstract": "A BSTRACT Background: The use of large language model (LLM) chatbots in health-related queries is growing due to their convenience and accessibility. However, concerns about the accuracy and readability of their information persist. Many individuals, including patients and healthy adults, may rely on chatbots for midlife health queries instead of consulting a doctor. In this context, we evaluated the accuracy and readability of responses from six LLM chatbots to midlife health questions for men and women. Methods: Twenty questions on midlife health were asked to six different LLM chatbots – ChatGPT, Claude, Copilot, Gemini, Meta artificial intelligence (AI), and Perplexity. Each chatbot’s responses were collected and evaluated for accuracy, relevancy, fluency, and coherence by three independent expert physicians. An overall score was also calculated by taking the average of four criteria. In addition, readability was analyzed using the Flesch-Kincaid Grade Level, to determine how easily the information could be understood by the general population. Results: In terms of fluency, Perplexity scored the highest (4.3 ± 1.78), coherence was highest for Meta AI (4.26 ± 0.16), accuracy of responses was highest for Meta AI, and relevancy score was highest for Meta AI (4.35 ± 0.24). Overall, Meta AI scored the highest (4.28 ± 0.16), followed by ChatGPT (4.22 ± 0.21), whereas Copilot had the lowest score (3.72 ± 0.19) ( P &lt; 0.0001). Perplexity showed the highest score of 41.24 ± 10.57 in readability and lowest in grade level (11.11 ± 1.93), meaning its text is the easiest to read and requires a lower level of education. Conclusion: LLM chatbots can answer midlife-related health questions with variable capabilities. Meta AI was found to be highest scoring chatbot for addressing men’s and women’s midlife health questions, whereas Perplexity offers high readability for accessible information. Hence, LLM chatbots can be used as educational tools for midlife health by selecting appropriate chatbots according to its capability.",
  "full_text": null,
  "topic": "Readability",
  "concepts": [
    {
      "name": "Readability",
      "score": 0.9267048239707947
    },
    {
      "name": "Psychology",
      "score": 0.5009949207305908
    },
    {
      "name": "Natural language processing",
      "score": 0.48914292454719543
    },
    {
      "name": "Computer science",
      "score": 0.4437465965747833
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3517817556858063
    },
    {
      "name": "Linguistics",
      "score": 0.3366957902908325
    },
    {
      "name": "Philosophy",
      "score": 0.09295210242271423
    },
    {
      "name": "Programming language",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4396570500",
      "name": "All India Institute of Medical Sciences, Deoghar",
      "country": null
    },
    {
      "id": "https://openalex.org/I4210093352",
      "name": "Government Medical College and Hospital",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I275778967",
      "name": "Raiganj University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I3130807960",
      "name": "Diamond Harbour Women's University",
      "country": "IN"
    },
    {
      "id": "https://openalex.org/I265637623",
      "name": "College of Medicine & Sagore Dutta Hospital",
      "country": "IN"
    }
  ],
  "cited_by": 1
}