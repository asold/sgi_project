{
  "title": "A Concurrent Fault Diagnosis Method of Transformer Based on Graph Convolutional Network and Knowledge Graph",
  "url": "https://openalex.org/W4213048779",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2098405775",
      "name": "Liqing Liu",
      "affiliations": [
        "Tianjin Research Institute of Electric Science (China)"
      ]
    },
    {
      "id": "https://openalex.org/A290155247",
      "name": "Bo Wang",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A2793133828",
      "name": "Fuqi Ma",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A2105540836",
      "name": "Quan Zheng",
      "affiliations": [
        "Tianjin Research Institute of Electric Science (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2568185461",
      "name": "Liangzhong Yao",
      "affiliations": [
        "Wuhan University"
      ]
    },
    {
      "id": "https://openalex.org/A1492746850",
      "name": "Chi Zhang",
      "affiliations": [
        "Tianjin Research Institute of Electric Science (China)"
      ]
    },
    {
      "id": "https://openalex.org/A2122007156",
      "name": "Mohamed A. Mohamed",
      "affiliations": [
        "Minia University"
      ]
    },
    {
      "id": "https://openalex.org/A2098405775",
      "name": "Liqing Liu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A290155247",
      "name": "Bo Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2793133828",
      "name": "Fuqi Ma",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2105540836",
      "name": "Quan Zheng",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2568185461",
      "name": "Liangzhong Yao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1492746850",
      "name": "Chi Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122007156",
      "name": "Mohamed A. Mohamed",
      "affiliations": [
        "Minia University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2962444737",
    "https://openalex.org/W2144386448",
    "https://openalex.org/W2130372754",
    "https://openalex.org/W2942289617",
    "https://openalex.org/W2317595875",
    "https://openalex.org/W3034312857",
    "https://openalex.org/W6755647631",
    "https://openalex.org/W2904284137",
    "https://openalex.org/W2963613699",
    "https://openalex.org/W2988264991",
    "https://openalex.org/W2920719103",
    "https://openalex.org/W3138716143",
    "https://openalex.org/W2057756949",
    "https://openalex.org/W2985331920"
  ],
  "abstract": "In complex power systems, when power equipment fails, multiple concurrent failures usually occur instead of a single failure. Concurrent failures are so common and hidden in complex systems that diagnosis requires not only analysis of failure characteristics, but also correlation between failures. Therefore, in this paper, a concurrent fault diagnosis method is proposed for power equipment based on graph neural networks and knowledge graphs. First, an electrical equipment failure knowledge map is created based on operational and maintenance records to emphasize the relevance of the failed equipment or component. Next, a lightweight graph neural network model is built to detect concurrent faults in the graph data. Finally, a city’s transformer concurrent fault is taken as an example for simulation and validation. Simulation results show that the accuracy and acquisition rate of graph neural network mining in Knowledge Graph is superior to traditional algorithms such as convolutional neural networks, which can achieve the effectiveness and robustness of concurrent fault mining.",
  "full_text": "A Concurrent Fault Diagnosis Method\nof Transformer Based on Graph\nConvolutional Network and\nKnowledge Graph\nLiqing Liu1,2, Bo Wang3, Fuqi Ma3*, Quan Zheng4, Liangzhong Yao3, Chi Zhang1,2 and\nMohamed A. Mohamed5*\n1State Grid Tianjin Electric Power Research Institute, Company, Tianjin, China,2Tianjin Key Laboratory of Internet of Things in\nElectricity, Tianjin, China,3School of Electrical and Automation, Wuhan University, Wuhan, China,4State Grid Tianjin Electric\nPower Company, Company, Tianjin, China,5Electrical Engineering Department, Faculty of Engineering, Minia University, Minia,\nEgypt\nIn complex power systems, when power equipment fails, multiple concurrent failures\nusually occur instead of a single failure. Concurrent failures are so common and hidden in\ncomplex systems that diagnosis requires not only analysis of failure characteristics, but\nalso correlation between failures. Therefore, in this paper, a concurrent fault diagnosis\nmethod is proposed for power equipment based on graph neural networks and\nknowledge graphs. First, an electrical equipment failure knowledge map is created\nbased on operational and maintenance records to emphasize the relevance of the failed\nequipment or component. Next, a lightweight graph neural network model is built to\ndetect concurrent faults in the graph data. Finally, a city’s transformer concurrent fault is\ntaken as an example for simulation and validation. Simulation results show that the\naccuracy and acquisition rate of graph neural network mining in Knowledge Graph is\nsuperior to traditional algorithms such as convolutional neural networks, which can\nachieve the effectiveness and robustness of concurrent fault mining.\nKeywords: knowledge graph, graph convolutional neural network, fault diagnosis, concurrent failures, failures\nanalysis\n1 INTRODUCTION\nAt the end of 2016, China had built the world’s largest power grid and achieved a huge amount of\nconstruction (Liu et al., 2020). However, as the grid continues to grow, the number and variety of\npower devices in the grid continues to grow (Wang et al., 2021). Due to the large and complex system,\nthe power grid is more likely and more severe than a simple system (Wang et al., 2019a). Faults\noccurrence also has the nature of randomness, secondary, concurrency, explosiveness, and\nobfuscation. In most cases, multiple faults will occur at the same time (Wang et al., 2019b).\nThis type of faults is called concurrent faults (Qin et al., 2018) and is also known as compound faults\nor multiple faults. Concurrent faults in different scenarios are completely different, and the\ncharacteristics of the faults are extremely complex and difﬁcult to diagnose (Ma et al., 2018).\nTherefore, research on how to diagnose concurrent transformer faults is crucial for the operation and\nmaintenance of transmission and transmission equipment, and for the safe and reliable transmission\nof power systems.\nEdited by:\nPeng Hou,\nPeng Hou, Denmark\nReviewed by:\nJichao Hong,\nUniversity of Science and Technology\nBeijing, China\nXuguang Hu,\nNortheastern University, China\n*Correspondence:\nFuqi Ma\nwhumfq@whu.edu.cn\nMohamed A. Mohamed\ndr.mohamed.abdelaziz@mu.edu.eg\nSpecialty section:\nThis article was submitted to\nProcess and Energy Systems\nEngineering,\na section of the journal\nFrontiers in Energy Research\nReceived: 16 December 2021\nAccepted: 27 January 2022\nPublished: 21 February 2022\nCitation:\nLiu L, Wang B, Ma F, Zheng Q, Yao L,\nZhang C and Mohamed MA (2022) A\nConcurrent Fault Diagnosis Method of\nTransformer Based on Graph\nConvolutional Network and\nKnowledge Graph.\nFront. Energy Res. 10:837553.\ndoi: 10.3389/fenrg.2022.837553\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375531\nORIGINAL RESEARCH\npublished: 21 February 2022\ndoi: 10.3389/fenrg.2022.837553\nCurrently, there is a lot of research on fault diagnosis methods,\nwhich can be divided into two main types. One is the traditional\nmethod, namely the principal component analysis method\n(Wang and Xiao, 2004 ) and the physical feature diagnostic\nmethod (Lei et al., 2016 ). The other is based on arti ﬁcial\nintelligence algorithms such as neural network algorithms\n(Ding et al., 2011; Al-Saud et al., 2019), petri networks (Pan\net al., 2008), and fuzzy logic theorems (Lang et al., 2019). The\nformer pays attention only to the fault characteristics, records a\nsingle record, and cannot judge the concurrent faults which make\nit inapplicable. The research on the concurrent faults mainly\nfocuses on the latter. The authors in (Xu et al., 2010) proposed a\nmethod of concurrent fault diagnosis information fusion based\non random set theory. First, a combination rule of single and\nconcurrent faults is arti ﬁcially constructed, and then fuzzy\nfunctions are used for pattern matching to diagnose\nconcurrent faults. The authors in ( Guan and Jiang, 2020 )\nproposed a concurrent multi-fault diagnosis method for\nelectromechanical systems based on the Elman network and\nECOC-SVM. This method uses an Elman network instead of\nmanual construction rules to classify faults, splits concurrent\nfaults into single faults for analysis, and the efﬁciency is improved.\nBut the disadvantage is that the relationship between every single\nfault is not considered, and the diagnosis effect is not ideal. In\nresponse to the above problems, the authors in (Hu et al., 2009)\nproposed a concurrent fault diagnosis method based on multiple\nregression LSSVM, which uses multiple regression least squares\nsupport vector machines to model concurrent faults as a multi-\ninput and multi-output problem. In ( Li and He, 2013), the\nauthors proposed a kernel fuzzy clustering method used in the\ndiagnosis of multiple faults in complex products. It is believed\nthat the relationship between single failure modes in complex\nproducts is particularly important for diagnosing concurrent\nfaults and kernelized clustering. However, the manual\nconstruction of rules in the above literature is relatively\ncumbersome, and the constructed combination rules are only\napplicable to speciﬁc scenarios, the model is relatively single, the\ngeneralization ability is poor, and it is dif ﬁcult to adapt to\ncomplex scenarios.\nGraph Convolutional Network (GCN) is an extension of\ntraditional Convolutional Neural Network (CNN) in non-\nEuclidean space. It cannot only use multiple graph\nconvolutional layers to automatically extract the features of\ninput variables, as well as take into account the topology\nstructure between the individual nodes (Zhang et al., 2019).\nGCN currently has excellent application effectiveness in the\nareas of link prediction, protein classiﬁcation, drug synthesis,\nand cross-domain pedestrian detection (de Kleer and Williams,\n1987), but its application for simultaneous disability diagnosis is\nstill in its infancy (Cen, 2010). In the power system massive data\nscenario, the fault diagnosis of concurrent faults of electrical\nequipment has not been well resolved (Ryu et al., 2019).\nIn summary, existing methods primarily take two or more\nsimultaneous faults as separate categories of pattern recognition.\nThis is the same as judging multiple faults as a new fault type,\nignoring the coupling and correlation between multiple faults. To\nfurther investigate the correlation between multiple faults, this\npaper selects the Graph Convolutional Neural Network (GCN),\nwith strong topological feature expression ability as the basis,\nproposes a method for transformer concurrent fault diagnosis\nbased on graph neural network and knowledge graph. The main\ncontributions of this paper are summarized as follows:\n1) This paper proposes a fault knowledge-related expression\nmethod based on a knowledge map. The fault type is used\nas the node and the correlation relationship between faults is\nused as the edge to describe the fault knowledge relationship.\n2) A concurrent fault analysis method based on lightweight CNN\nis proposed. The concurrent fault analysis problem is\ntransformed into a connection prediction problem based\non graph structure data, and the correlation analysis and\nfault discovery of concurrent faults are realized.\n3) A city’s transformer concurrent fault is taken as an example in\nthis paper. The simulation results show that the accuracy and\nrecall rate of graph neural network mining on the knowledge\ngraph is better than traditional algorithms such as CNNs,\nwhich can meet the effectiveness and robustness of concurrent\nfault mining.\n2 TRANSFORMER FAULT\nKNOWLEDGE MAP\nThis paper divides the model layer of transformer fault\nknowledge graph into component layer and fault layer.\nAmong them, the component layer deﬁnes all possible faulty\ncomponents of the transformer and the connection relationship\nbetween the components. The component layer reﬂects theﬁrst-\norder connection relationship between the components of the\ntransformer. The fault layer deﬁnes all the types of possible faults\nin the transformer, as well as the similarity and subordination\nbetween the types of faults. The fault layer is based on the\ntransformer state evaluation guidelines, re ﬂecting the logical\nrelationship between the faults, and is essentially a knowledge\ngraph with the transformer state evaluation guidelines as the data\nsource.\nData layer triple extraction refers to obtaining structured\nknowledge such as entities and relationships between entities\nand attributes from unstructured data through a series of\nknowledge extraction methods under the guidance of the\nknowledge organization structure of the model layer. The fault\nknowledge graph in this paper has two entities: fault component\nand fault type. There are three relationships: fault component-\nfault component, fault component-fault type, and fault type-fault\ntype. The knowledge graph is stored and represented in the form\nof triples. Compared with the traditional structured relational\ndatabase, the relationship between ﬁelds and records requires\ncomplicated calculation and extraction. The triple representation\nof knowledge can explicitly express the relationship between the\nrelationships of entities.\nSince most of the model layers of the power transformer fault\nknowledge map can be determined by the transformer topology\ndiagram and transformer operation inspection guidelines, the\nfault attribute nodes still need to be summarized and\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375532\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\nsupplemented from the knowledge layer. Therefore, this paper\nuses a combination of top-down and bottom-up methods to\nconstruct a power transformer fault knowledge map. The\nconstruction process of the knowledge graph is shown inFigure 1\nThe speciﬁc steps are as follows:\nFirst, determine the various components of the power\ntransformer and their electrical and mechanical connections\nthrough the analysis of the transformer topology. Generate the\nﬁrst-level pattern diagram of the knowledge map. Determine the\ntype of failure of each component, the operation mode, and the\nmaintenance mode after the failure. A top-down approach is used\nto design the initial model layer of the knowledge map.\nThen, under the guidance of the model layer, a bottom-up\napproach is used to perform entity, relationship, and relationship\nanalysis of the operation and maintenance records based on the\ngraph CNN method. The three elements of attributes are\nextracted to form a high-quality knowledge expression.\nFinally, the extracted faulty components and fault time are\nadded to the model layer as attribute nodes to complete the\nupdate of the model layer. So far, the construction of the power\ntransformer fault knowledge map is completed, and the\nknowledge map is stored in the form of triples.\n3 CONCURRENT FAULT DIAGNOSIS OF\nTRANSFORMER BASED ON GCN AND\nKNOWLEDGE GRAPH\nThe model layer of the power transformer fault knowledge map is\nmainly composed of three core elements, including fault\ncomponents, fault time, and fault location, as well as their\ninterrelationships. Firstly, compile the ﬁrst model layer of the\nfault knowledge map according to the power transformer\nstructure diagram, and extract the relationship between the\ncomponents of the transformer. Secondly, according to the\ntransformer maintenance guide, extract the relationship\nbetween the components of the transformer and the fault.\nFinally, Form the second layer of the knowledge graph\nmodel layer.\n3.1 Knowledge Extraction\nAs shown inFigure 2, the construction of the data layer depends\non the type of data source. Structured data can directly use graph\nmapping or D2R conversion. And semi-structured data need to\nuse a wrapper, while unstructured text data needs to use a\ndedicated information extraction method.\nThe data source used in this paper is a structured excel table,\nbut some ﬁelds such as work content contain unstructured text\ncontent. Therefore, the knowledge extraction in this paper is\ndivided into two parts. The ﬁrst part is the structured data\nextraction of excel forms, and the second part is the\nunstructured data extraction ofﬁelds such as work content.\n3.1.1 Structured Data Extraction\nThe working hours, working location and otherﬁelds in the table\nare all structured data, and there are clear relationship names and\ncorresponding relationships between them. So, it can be directly\nconverted into the RDF graph data format. This paper uses the\ncommon R2RML (RDB2RDF) mapping language to complete the\nmapping.\nFIGURE 1 |Knowledge graph construction process.\nFIGURE 2 |The construction mode of the knowledge graph data layer.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375533\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\n3.1.2 Unstructured Data Extraction\nUnstructured data extraction is more complicated and can be\ndivided into the following subtasks: entity recognition,\nrelationship extraction, event extraction, and coreference\nresolution. The text content involved in this article comes\nfrom the work content ﬁeld of the maintenance record excel\nform. The text content components and events are relatively\nsimple. Only three tasks such as entity recognition,\nrelationship extraction, and common reference resolution\nare required to complete the construction of the data layer.\n3.2 Entity Recognition Algorithm Based on\nBiLSTM-RCF\nDue to the problems of concentrated professional\nterminology, fuzzy expression of entity relationships,\nunclear boundaries between entities, short text content,\nand large quantity in the overhaul content text, it is not\nsuitable to use manual rule templates for entity classiﬁcation.\nTo solve the above problems, this paper introduces the\nChinese entity recognition algorithm based on BiLSTM-\nRCF (Luo et al., 2021) to realize the Chinese named entity\nrecognition of the overhaul content text and solve the\nproblems of unclear boundaries between entities. The\nspeci ﬁc steps are as follow:\nStep 1: Represent each word in sentence x as a vector\ncontaining word and character embeddings. Character\nembedding is initialized randomly. Word embeddings are\nusually imported from pre-trained word embedding ﬁles. All\nembeddings will beﬁne-tuned during training.\nStep 2: The input of the BiLSTM-CRF model is these\nembeddings, and the output is the predicted label of the word in\nsentence x.I nt h i sp a p e r ,t h e r ea r eo n l yﬁve types of labels,B-\nEquipment, I-Equipment, B-Fault, I-Fault,a n d O.W h e r e\nB-Equipment and I-Equipment refer to equipment or component\nlabels, B-Fault and I-Fault refer to fault type labels, andO refers to\nother character labels.\nStep 3: Input all the scores predicted by the BiLSTM layer into\nthe CRF layer. In the CRF layer, the legal tag sequence with the\nhighest prediction score is selected as the best answer. The model\nstructure is shown inFigure 3.\n3.3 Algorithm for Extracting Relations\nBetween Entities Based on\nBiGRU-Attention\nEntity Relation Extraction (NRE) is to determine whether there is a\npredeﬁned relationship between entities based on named entity\nrecognition, thereby forming a series of triple knowledge. Based on\nthe BiLSTM-Attention (Peng, 2021)m o d e l ,as i m p l iﬁed Bidirectional\nGated Recurrent Unit (BiGRU) structure is used to reduce the number\nof parameters and improve the training speed of the model. The\nstructure of the BiGRU-Attention model is shown inFigure 4.\nBased on BiGRU, the attention mechanism is introduced in the\nBiGRU-Attention model toﬁnd words. By learning a weight, and\ngiving these words a higher weight to increase their importance,\nthereby improving the accuracy ofrelationship extraction rate.\n4 EVALUATION INDEX\nThe precision and recall as the evaluation indexes are introduced\nin the transformer concurrent fault diagnosis method based on\ngraph neural network and knowledge graph. Among them, the\naccuracy rate refers to the proportion of the correct target in the\ntotal number of targets detected by the model, which is usually\ncalled the precision rate. The recall rate refers to the ratio of the\nFIGURE 3 |BiLSTM-RCF Chinese entity recognition algorithmﬂow.\nFIGURE 4 |BiGRU-Attention model structure.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375534\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\nnumber of correct targets detected by the model to the total\nnumber of correct targets, also called the recall rate.\nAs shown in Figure 5, suppose that in the correct sample\nlibrary, the number of concurrent failures detected by the model\nis A, and the number of undetected concurrent failures isB. In the\nwrong sample library, the number of concurrent failures detected\nby the model isB. The number of failures isC, and the number of\nconcurrent failures detected isD. The calculation formula for the\naccuracy rate p and the recall rateR is as follow:\nP /equals\nC\nC + D (1)\nR /equalsC\nA + C (2)\n5 SIMULATION\nBased on the PyTorch deep learning computing environment, a\ncomparative experiment of lightweight graph convolution and\nstandard graph convolution, and a comparative experiment of\nlightweight graph convolution with different layers are set to\nverify the approach proposed in this paper. The relevant\nparameters of the model are shown in Table 1. The model\ntest veriﬁcation of this paper is carried out on the server of\nthe laboratory, the conﬁguration of server hardware and software\nenvironment with 8-core CPU, 32 GB memory and an NVIDIA\nTesla P4 graphics card with 8 GB video memory.\n5.1 Comparative Experiment of Lightweight\nGraph Convolution and Standard Graph\nConvolution\nIn this paper, the training data is imported into the lightweight\ngraph convolution (LightGCN), the standard graph convolution\nneural network (GCN) and convolutional neural network (CNN)\nrespectively. The training loss of the lightweight graph\nFIGURE 5 |Schematic diagram of precision and recall rate.\nTABLE 1 |Parameter settings.\nParameters Value\nEmbedding ways 60-dimensional word and term vector\nNumber of CNN layers 5\nRandom inactivation rate 0.5\nNumber of training batches 15\nLearning rate 0.0016\nLearning rate decay rate 0.04\nOptimizer Adamax\nNumber of convolution kernels per layer 128\nTABLE 2 |Training loss comparison.\nTraining times (epoch) Lightweight graph convolution\n(LightGCN)\nStandard graph convolutional network\n(GCN)\nConvolutional neural network\n(CNN)\n50 0.02 0.261 0.436\n200 0.0056 0.032 0.045\n400 0.0037 0.0137 0.015\n600 0.0036 0.0096 0.012\n800 0.0036 0.0065 0.0093\nTABLE 3 |Recall rate comparison.\nTraining times (epoch) Lightweight graph convolution\n(LightGCN)\nStandard graph convolution\n(GCN)\nConvolutional neural network\n(CNN)\n50 0.851 0.811 0.745\n200 0.868 0.839 0.749\n400 0.874 0.848 0.741\n600 0.875 0.850 0.752\n800 0.874 0.861 0.764\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375535\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\nconvolution and the standard graph convolution is shown in\nTable 2.\nIt can be seen that the convergence speed of lightweight graph\nconvolution training is much faster than standard graph\nconvolution and CNN, and the ﬁnal training loss of\nlightweight graph convolution is small. Standard graph\nconvolution shows the convergence speed and convergence\neffect of lightweight graph convolution are both better than\nstandard image convolution.\nFIGURE 6 |Comparisons of lightweight graph convolution and standard graph convolution.\nTABLE 4 |Comparison of lightweight graph convolution training batches for\n200 times.\nConvolutional layer number Training loss Average precision mean\n(mAP/%)\n1 0.0078 79.4\n2 0.0063 81.1\n3 0.0043 82.3\n4 0.0061 81.9\nFIGURE 7 |Comparison of graph convolutions with different layers.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375536\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\nAfter the training is completed, we use the test set to test the\nthree algorithms, and the recall rate is shown inTable 3.\nIt can be seen from Table 3 that the recall rate of the\nlightweight graph convolution is better than that of the\nstandard graph convolution and CNN, indicating that the\nlightweight graph convolution has a better mining effect on\nconcurrent faults than the standard graph convolution and CNN.\nThe comparison between lightweight graph convolution and\nstandard graph convolution is shown inFigure 6. It can be seen\nthat the concurrent fault mining effect of lightweight graph\nconvolution is indeed better than standard graph convolution,\nand the convergence speed of lightweight graph convolution is\nfaster, furthermore, the training difﬁculty is less. In terms of\npracticability and ease, the lightweight graph convolution is better\nthan the standard graph convolution.\n5.2 Comparative Experiment of Lightweight\nGraph Convolution With Different Layers\nA comparative experiment was conducted on GCN models with\ndifferent layers. The results are shown inTable 4. It can be seen\nthat the effect is best when the number of convolutional layers\nis three.\nThe graph convolution comparison of different layers is\nshown inFigure 7. It can be seen that whether it is lightweight\ngraph convolution or standard graph convolution, when the\nnumber of network layers is less than or equal to three layers,\nincreasing the number of network layers can effectively\nimprove the mining Accuracy. After the number of network\nlayers is greater than three, due to overﬁtting, increasing the\nnumber of network layers will reduce the mining effect, or even\nnot converge. Therefore, when the number of graph\nconvolutional layers is three, mining can achieve the best\nresults.\n6 CONCLUSION\nResponding to the problem of modeling and inference of safety\nhazards due to concurrency failures, this paper introduces the\nknowledge graph and uses its ability to model relational networks\nto extract a transformer fault relational network from operation\nand maintenance data. At the same time, based on graphs, the\nproduct neural network is marked by extracting a large number of\nsub-graphs of the transformer fault knowledge map, and a graph\nconvolutional network is trained to concurrent fault mining. By\ncomparing with the standard graph convolution network, the\naccuracy and recall rate of graph neural network mining on the\nknowledge graph are better than traditional algorithms such as\nconvolutional neural networks, which can meet the effectiveness\nand robustness of concurrent fault mining. Currently, the\nresearch in this paper focuses primarily on the analysis and\ninvestigation of known companion faults. Subsequent research\nwill consider the situation of unknown concurrent faults and\nstudy the discovery and update mechanism of unknown\nconcurrent faults.\nDATA AVAILABILITY STATEMENT\nThe raw data supporting the conclusions of this article will be\nmade available by the authors, without undue reservation.\nAUTHOR CONTRIBUTIONS\nLL: Conceptualization, Methodology, Software, Validation,\nVisualization, Supervision, Investigation, Writing — Original\nDraft, Writing— Review and Editing. BW: Conceptualization,\nMethodology, Software, Validation, Visualization, Supervision,\nInvestigation, Writing— Original Draft, Writing— Review and\nEditing. FM: Conceptualization, Methodology, Software,\nValidation, Visualization, Supervision, Investigation,\nWriting— Original Draft, Writing — Review and Editing. QZ:\nConceptualization, Methodology, Software, Validation,\nVisualization, Supervision, Investigation, Writing — Original\nDraft, Writing— Review and Editing. LY: Conceptualization,\nMethodology, Software, Validation, Visualization, Supervision,\nInvestigation, Writing— Original Draft, Writing— Review and\nEditing. CZ: Conceptualization, Methodology, Software,\nValidation, Visualization, Supervision, Investigation,\nWriting— Original Draft, Writing— Review and Editing. MM:\nConceptualization, Methodology, Software, Validation,\nVisualization, Supervision, Investigation, Writing — Original\nDraft, Writing— Review and Editing.\nFUNDING\nI declare that all sources of funding received for the research have\nbeen submitted. This work was supported by the Science and\nTechnology Program of the Headquarters of State Grid\nCorporation of China, Research on Knowledge Discovery,\nReasoning and Decision-making for Electric Power Operation\nand Maintenance Based on Graph Machine Learning and Its\nApplications, under Grant 5700-202012488A-0-0-00.\nREFERENCES\nAl-Saud, M., Eltamaly, A. M., Mohamed, M. A., and Kavousi-Fard, A. (2019). An\nIntelligent Data-Driven Model to Secure Intravehicle Communications Based\non Machine Learning.IEEE Trans. Ind. Elect.67 (6), 5112–5119. doi:10.1109/\ntie.2019.2924870\nCen, J. (2010).Research of Machine Unit Complex Fault Diagnosis Technology Based on\nArtiﬁcial Immune System [D]. Guangzhou: South China University of Technology.\nde Kleer, J., and Williams, B. C. (1987). Diagnosing Multiple Faults. Artif.\nIntelligence 32 (1), 97–130. doi:10.1016/0004-3702(87)90063-4\nDing, S., Su, C., and Yu, J. (2011). An Optimizing BP Neural Network Algorithm\nBased on Genetic Algorithm.Artif. Intell. Rev.36 (2), 153–162. doi:10.1007/\ns10462-011-9208-z\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375537\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer\nGuan, Y., and Jiang, Z. (2020). A Concurrent Multifault Diagnosis Method for\nElectromechanical Systems Based on the Elman Network and an ECOC-SVM\n[J]. J. Harbin Eng. Univ.41 (11), 1715–1720.\nHu, C., Cai, Y., and Zhang, Q. (2009). Simultaneous Fault Diagnosis Based on\nMulti-Regression LSSVM [J].J. Huazhong Univ. Sci. Technology(Natural Sci.\nEdition) 3 7 (S1), 1–5.\nLang, G., Miao, D., and Fujita, H. (2019). Three-way Group Conﬂict Analysis\nBased on Pythagorean Fuzzy Set Theory [J].IEEE Trans. Fuzzy Syst.28 (3),\n447–461. doi:10.1109/TFUZZ.2019.2908123\nLei, Y., Jia, F., Lin, J., Xing, S., and Ding, S. X. (2016). An Intelligent Fault Diagnosis\nMethod Using Unsupervised Feature Learning towards Mechanical Big Data.\nIEEE Trans. Ind. Electron.63 (5), 3137–3147. doi:10.1109/tie.2016.2519325\nLi, T., and He, Z. (2013). The Kernel Fuzzy Clustering Method in the Diagnosis of\nMultiple Faults in Complex Products[J].Syst. Engineering-Theory Pract.33 (1),\n181–186.\nLiu, W., Zhang, X., Wu, Y., and Feng, S. (2020). Economic Analysis of Renewable\nEnergy in the Electricity Marketization Framework: a Case Study in\nGuangdong, China. Front. Energ. Res.8, 98. doi:10.3389/fenrg.2020.00098\nLuo, X., Xia, X., An, Y., and Chen, X. (2021). Chinese CNER Combined with Multi-Head\nS e l f - A t t e n t i o na n dB i L S T M - C R F[ J ] .J. Hunan Univ. (Natural Sciences)48 (04),\n45–55.\nMa, K., Zhu, J., Soltani, M., Hajizadeh, A., Hou, P., and Chen, Z. (2018).“Active\nPower Dispatch Strategy of Wind Farms under Generator Faults,” in European\nSafety and Reliability Conference 2018: ESREL 2018(Hannover: CRC Press),\n2147–2152. doi:10.1201/9781351174664-269\nPan, C., Yue, J. P., Liu, B., and Yu, J. (2008). An Adaptive Petri Network Based Approach\nto Diagnose Power Network Faults [J].Power Syst. Tech.32 (1), 46–50.\nPeng, B. (2021). Research on Entity Relationship Extraction of Cultural Relic\nInformation Resources Based on Knowledge Map and Deep Learning [J].\nJ. Mod. Inf.41 (05), 87–94.\nQin, A., Hu, Q., Lv, Y., and Zhang, Q. (2018). Concurrent Fault Diagnosis\nBased on Bayesian Discriminating Analysis and Time Series Analysis with\nDimensionless Parameters. IEEE Sensors J.19 (6), 2254–2265. doi:10.1109/\njsen.2018.2885377\nRyu, S., Kwon, Y., and Kim, W. Y. (2019). A Bayesian Graph Convolutional\nNetwork for Reliable Prediction of Molecular Properties with Uncertainty\nQuantiﬁcation. Chem. Sci. 10 (36), 8438–8446. doi:10.1039/c9sc01992h\nWang, Q., Jin, T., Mohamed, M. A., and Chen, T. (2019). A Minimum Hitting Set\nAlgorithm with Prejudging Mechanism for Model-Based Fault Diagnosis in\nDistribution Networks.IEEE Trans. Instrumentation Meas.69 (7), 4702–4711.\ndoi:10.1109/tim.2019.2951866\nWang, Q., Jin, T., and Mohamed, M. A. (2019). An Innovative Minimum Hitting\nSet Algorithm for Model-Based Fault Diagnosis in Power Distribution\nNetwork. IEEE Access 7, 30683–30692. doi:10.1109/access.2019.2902598\nWang, Q., Jin, T., Mohamed, M. A., and Deb, D. (2021). A Novel Linear\nOptimization Method for Section Location of Single-phase Ground Faults in\nNeutral Noneffectively Grounded Systems. IEEE Trans. Instrum. Meas. 70,\n1–10. doi:10.1109/tim.2021.3066468\nWang, S., and Xiao, F. (2004). AHU Sensor Fault Diagnosis Using Principal\nComponent Analysis Method.Energy and Buildings 36 (2), 147–160. doi:10.\n1016/j.enbuild.2003.10.002\nXu, X., Wen, C., Jiang, H., and Wang, Y. C. (2010). Information Fusion Method of\nSimultaneous Fault Diagnosis Based on Random Set Theory [J]. Chin.\nJ. Scientiﬁc Instrument 31 (2), 335–361.\nZhang, S., Tong, H., Xu, J., and Maciejewski, R. (2019). Graph Convolutional\nNetworks: a Comprehensive Review [J].Comput. Soc. Networks 6( 1 ) ,1–23.\ndoi:10.1186/s40649-019-0069-y\nConﬂict of Interest:LL, CZ, and QZ were employed by the Company State Grid\nTianjin Electric Power Company.\nThe remaining authors declare that the research was conducted in the absence of\nany commercial orﬁnancial relationships that could be construed as a potential\nconﬂict of interest.\nThe authors declare that this study received funding from the State Grid\nCorporation of China. The funder had the following involvement with the\nstudy: data collection and analysis.\nPublisher’s Note:All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their afﬁliated organizations, or those of\nthe publisher, the editors and the reviewers. Any product that may be evaluated in\nthis article, orclaim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Liu, Wang, Ma, Zheng, Yao, Zhang and Mohamed. This is an\nopen-access article distributed under the terms of the Creative Commons Attribution\nLicense (CC BY). The use, distribution or reproduction in other forums is permitted,\nprovided the original author(s) and the copyright owner(s) are credited and that the\noriginal publication in this journal is cited, in accordance with accepted academic\npractice. No use, distribution or reproduction is permitted which does not comply\nwith these terms.\nFrontiers in Energy Research | www.frontiersin.org February 2022 | Volume 10 | Article 8375538\nLiu et al. A Concurrent Fault Diagnosis Method of Transformer",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.700069785118103
    },
    {
      "name": "Graph",
      "score": 0.5037395358085632
    },
    {
      "name": "Power graph analysis",
      "score": 0.4983353614807129
    },
    {
      "name": "Robustness (evolution)",
      "score": 0.45469561219215393
    },
    {
      "name": "Convolutional neural network",
      "score": 0.4361536502838135
    },
    {
      "name": "Artificial neural network",
      "score": 0.4309369623661041
    },
    {
      "name": "Data mining",
      "score": 0.405362993478775
    },
    {
      "name": "Reliability engineering",
      "score": 0.3712434768676758
    },
    {
      "name": "Artificial intelligence",
      "score": 0.33405905961990356
    },
    {
      "name": "Theoretical computer science",
      "score": 0.30114203691482544
    },
    {
      "name": "Engineering",
      "score": 0.18876227736473083
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Gene",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ]
}