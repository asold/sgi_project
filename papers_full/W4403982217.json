{
  "title": "EyeGPT for Patient Inquiries and Medical Education: Development and Validation of an Ophthalmology Large Language Model",
  "url": "https://openalex.org/W4403982217",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2126036584",
      "name": "Xiaolan Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2097240547",
      "name": "Ziwei Zhao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1978435048",
      "name": "Weiyi Zhang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2620825143",
      "name": "Pusheng Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2096475003",
      "name": "Yue Wu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2894344816",
      "name": "Mingpu Xu",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2132005909",
      "name": "Le Gao",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2115169426",
      "name": "Yinwen Li",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2687422944",
      "name": "Xianwen Shang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2954424513",
      "name": "Danli Shi",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2115893760",
      "name": "Mingguang He",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W3130938027",
    "https://openalex.org/W4388922836",
    "https://openalex.org/W2750786718",
    "https://openalex.org/W4384561707",
    "https://openalex.org/W4368340908",
    "https://openalex.org/W4389182159",
    "https://openalex.org/W4396605652",
    "https://openalex.org/W4385514573",
    "https://openalex.org/W4398775037",
    "https://openalex.org/W4391221150",
    "https://openalex.org/W4375850424",
    "https://openalex.org/W4367175039",
    "https://openalex.org/W4381092249",
    "https://openalex.org/W4387440167",
    "https://openalex.org/W4387496544",
    "https://openalex.org/W4392544551",
    "https://openalex.org/W4389505318",
    "https://openalex.org/W4392504747",
    "https://openalex.org/W4384918448",
    "https://openalex.org/W4401042136",
    "https://openalex.org/W4381930847",
    "https://openalex.org/W3162922479",
    "https://openalex.org/W2483658963",
    "https://openalex.org/W2970641574",
    "https://openalex.org/W4393335480",
    "https://openalex.org/W4282928279",
    "https://openalex.org/W4393175789",
    "https://openalex.org/W4392044798",
    "https://openalex.org/W4397024262",
    "https://openalex.org/W2050497410",
    "https://openalex.org/W4390065167",
    "https://openalex.org/W4401706657",
    "https://openalex.org/W2954850454",
    "https://openalex.org/W4400657362",
    "https://openalex.org/W4392984569",
    "https://openalex.org/W4386046428",
    "https://openalex.org/W4388729242",
    "https://openalex.org/W4390195781",
    "https://openalex.org/W4391136507",
    "https://openalex.org/W4389094583",
    "https://openalex.org/W4386346796",
    "https://openalex.org/W2980185546",
    "https://openalex.org/W2898718493"
  ],
  "abstract": "Background Large language models (LLMs) have the potential to enhance clinical flow and improve medical education, but they encounter challenges related to specialized knowledge in ophthalmology. Objective This study aims to enhance ophthalmic knowledge by refining a general LLM into an ophthalmology-specialized assistant for patient inquiries and medical education. Methods We transformed Llama2 into an ophthalmology-specialized LLM, termed EyeGPT, through the following 3 strategies: prompt engineering for role-playing, fine-tuning with publicly available data sets filtered for eye-specific terminology (83,919 samples), and retrieval-augmented generation leveraging a medical database and 14 ophthalmology textbooks. The efficacy of various EyeGPT variants was evaluated by 4 board-certified ophthalmologists through comprehensive use of 120 diverse category questions in both simple and complex question-answering scenarios. The performance of the best EyeGPT model was then compared with that of the unassisted human physician group and the EyeGPT+human group. We proposed 4 metrics for assessment: accuracy, understandability, trustworthiness, and empathy. The proportion of hallucinations was also reported. Results The best fine-tuned model significantly outperformed the original Llama2 model at providing informed advice (mean 9.30, SD 4.42 vs mean 13.79, SD 5.70; P&lt;.001) and mitigating hallucinations (97/120, 80.8% vs 53/120, 44.2%, P&lt;.001). Incorporating information retrieval from reliable sources, particularly ophthalmology textbooks, further improved the model's response compared with solely the best fine-tuned model (mean 13.08, SD 5.43 vs mean 15.14, SD 4.64; P=.001) and reduced hallucinations (71/120, 59.2% vs 57/120, 47.4%, P=.02). Subgroup analysis revealed that EyeGPT showed robustness across common diseases, with consistent performance across different users and domains. Among the variants, the model integrating fine-tuning and book retrieval ranked highest, closely followed by the combination of fine-tuning and the manual database, standalone fine-tuning, and pure role-playing methods. EyeGPT demonstrated competitive capabilities in understandability and empathy when compared with human ophthalmologists. With the assistance of EyeGPT, the performance of the ophthalmologist was notably enhanced. Conclusions We pioneered and introduced EyeGPT by refining a general domain LLM and conducted a comprehensive comparison and evaluation of different strategies to develop an ophthalmology-specific assistant. Our results highlight EyeGPTâ€™s potential to assist ophthalmologists and patients in medical settings.",
  "full_text": null,
  "topic": "Preprint",
  "concepts": [
    {
      "name": "Preprint",
      "score": 0.9038965702056885
    },
    {
      "name": "Medical education",
      "score": 0.4905344843864441
    },
    {
      "name": "Medicine",
      "score": 0.38581570982933044
    },
    {
      "name": "Computer science",
      "score": 0.37460994720458984
    },
    {
      "name": "World Wide Web",
      "score": 0.37260931730270386
    },
    {
      "name": "Multimedia",
      "score": 0.36343130469322205
    },
    {
      "name": "Psychology",
      "score": 0.35646331310272217
    },
    {
      "name": "Internet privacy",
      "score": 0.3512078523635864
    }
  ]
}