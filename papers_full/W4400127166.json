{
  "title": "Improving Text Classification with Large Language Model-Based Data Augmentation",
  "url": "https://openalex.org/W4400127166",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2125383744",
      "name": "Huanhuan Zhao",
      "affiliations": [
        "University of Tennessee at Knoxville"
      ]
    },
    {
      "id": "https://openalex.org/A2096994228",
      "name": "Haihua Chen",
      "affiliations": [
        "University of North Texas"
      ]
    },
    {
      "id": "https://openalex.org/A2902790303",
      "name": "Thomas A. Ruggles",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2746271494",
      "name": "Yunhe Feng",
      "affiliations": [
        "University of North Texas"
      ]
    },
    {
      "id": "https://openalex.org/A3005446648",
      "name": "Debjani Singh",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2960663546",
      "name": "Hong-Jun Yoon",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2125383744",
      "name": "Huanhuan Zhao",
      "affiliations": [
        "University of Tennessee at Knoxville"
      ]
    },
    {
      "id": "https://openalex.org/A2096994228",
      "name": "Haihua Chen",
      "affiliations": [
        "University of North Texas"
      ]
    },
    {
      "id": "https://openalex.org/A2902790303",
      "name": "Thomas A. Ruggles",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2746271494",
      "name": "Yunhe Feng",
      "affiliations": [
        "University of North Texas"
      ]
    },
    {
      "id": "https://openalex.org/A3005446648",
      "name": "Debjani Singh",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    },
    {
      "id": "https://openalex.org/A2960663546",
      "name": "Hong-Jun Yoon",
      "affiliations": [
        "Oak Ridge National Laboratory"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2971296908",
    "https://openalex.org/W2979624122",
    "https://openalex.org/W6767545298",
    "https://openalex.org/W3115283946",
    "https://openalex.org/W4221099399",
    "https://openalex.org/W3196750896",
    "https://openalex.org/W2137488759",
    "https://openalex.org/W2740839465",
    "https://openalex.org/W2963216553",
    "https://openalex.org/W4385573325",
    "https://openalex.org/W4380757873",
    "https://openalex.org/W3153451655",
    "https://openalex.org/W4386245246",
    "https://openalex.org/W2143017621",
    "https://openalex.org/W4205674008",
    "https://openalex.org/W6766978945",
    "https://openalex.org/W2979826702",
    "https://openalex.org/W2341158656",
    "https://openalex.org/W6675354045",
    "https://openalex.org/W2101234009",
    "https://openalex.org/W2982225063",
    "https://openalex.org/W4295312788"
  ],
  "abstract": "Large Language Models (LLMs) such as ChatGPT possess advanced capabilities in understanding and generating text. These capabilities enable ChatGPT to create text based on specific instructions, which can serve as augmented data for text classification tasks. Previous studies have approached data augmentation (DA) by either rewriting the existing dataset with ChatGPT or generating entirely new data from scratch. However, it is unclear which method is better without comparing their effectiveness. This study investigates the application of both methods to two datasets: a general-topic dataset (Reuters news data) and a domain-specific dataset (Mitigation dataset). Our findings indicate that: 1. ChatGPT generated new data consistently enhanced model’s classification results for both datasets. 2. Generating new data generally outperforms rewriting existing data, though crafting the prompts carefully is crucial to extract the most valuable information from ChatGPT, particularly for domain-specific data. 3. The augmentation data size affects the effectiveness of DA; however, we observed a plateau after incorporating 10 samples. 4. Combining the rewritten sample with new generated sample can potentially further improve the model’s performance.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8169920444488525
    },
    {
      "name": "Rewriting",
      "score": 0.6411325335502625
    },
    {
      "name": "Sample (material)",
      "score": 0.567599356174469
    },
    {
      "name": "Domain (mathematical analysis)",
      "score": 0.5296979546546936
    },
    {
      "name": "Data mining",
      "score": 0.4862579107284546
    },
    {
      "name": "Language model",
      "score": 0.4512346386909485
    },
    {
      "name": "Scratch",
      "score": 0.4435500502586365
    },
    {
      "name": "Information retrieval",
      "score": 0.4075058698654175
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3854535222053528
    },
    {
      "name": "Natural language processing",
      "score": 0.3534255921840668
    },
    {
      "name": "Machine learning",
      "score": 0.33684831857681274
    },
    {
      "name": "Programming language",
      "score": 0.12387976050376892
    },
    {
      "name": "Mathematical analysis",
      "score": 0.0
    },
    {
      "name": "Mathematics",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Chromatography",
      "score": 0.0
    }
  ]
}