{
  "title": "Neural Translation and Automated Recognition of ICD-10 Medical Entities From Natural Language: Model Development and Performance Assessment",
  "url": "https://openalex.org/W4206681774",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2736043946",
      "name": "Louis Falissard",
      "affiliations": [
        "Centre d'Épidémiologie sur les Causes Médicales de Décès",
        "Inserm"
      ]
    },
    {
      "id": "https://openalex.org/A2889293091",
      "name": "Claire Morgand",
      "affiliations": [
        "Inserm",
        "Centre d'Épidémiologie sur les Causes Médicales de Décès"
      ]
    },
    {
      "id": "https://openalex.org/A2035836121",
      "name": "Walid Ghosn",
      "affiliations": [
        "Inserm",
        "Centre d'Épidémiologie sur les Causes Médicales de Décès"
      ]
    },
    {
      "id": "https://openalex.org/A2763274884",
      "name": "Claire Imbaud",
      "affiliations": [
        "Inserm",
        "Centre d'Épidémiologie sur les Causes Médicales de Décès"
      ]
    },
    {
      "id": "https://openalex.org/A2278060517",
      "name": "Karim Bounebache",
      "affiliations": [
        "Inserm",
        "Centre d'Épidémiologie sur les Causes Médicales de Décès"
      ]
    },
    {
      "id": "https://openalex.org/A2122919095",
      "name": "Grégoire Rey",
      "affiliations": [
        "Inserm",
        "Centre d'Épidémiologie sur les Causes Médicales de Décès"
      ]
    },
    {
      "id": "https://openalex.org/A2736043946",
      "name": "Louis Falissard",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2889293091",
      "name": "Claire Morgand",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2035836121",
      "name": "Walid Ghosn",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2763274884",
      "name": "Claire Imbaud",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2278060517",
      "name": "Karim Bounebache",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2122919095",
      "name": "Grégoire Rey",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2576491980",
    "https://openalex.org/W2744369723",
    "https://openalex.org/W2963341956",
    "https://openalex.org/W2157331557",
    "https://openalex.org/W2946575095",
    "https://openalex.org/W3047315909",
    "https://openalex.org/W3037036598",
    "https://openalex.org/W2101105183",
    "https://openalex.org/W3096180285"
  ],
  "abstract": "Background The recognition of medical entities from natural language is a ubiquitous problem in the medical field, with applications ranging from medical coding to the analysis of electronic health data for public health. It is, however, a complex task usually requiring human expert intervention, thus making it expansive and time-consuming. Recent advances in artificial intelligence, specifically the rise of deep learning methods, have enabled computers to make efficient decisions on a number of complex problems, with the notable example of neural sequence models and their powerful applications in natural language processing. However, they require a considerable amount of data to learn from, which is typically their main limiting factor. The Centre for Epidemiology on Medical Causes of Death (CépiDc) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of natural language examples provided with their associated human-coded medical entities available to the machine learning practitioner. Objective The aim of this paper was to investigate the application of deep neural sequence models to the problem of medical entity recognition from natural language. Methods The investigated data set included every French death certificate from 2011 to 2016. These certificates contain information such as the subject’s age, the subject’s gender, and the chain of events leading to his or her death, both in French and encoded as International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) medical entities, for a total of around 3 million observations in the data set. The task of automatically recognizing ICD-10 medical entities from the French natural language–based chain of events leading to death was then formulated as a type of predictive modeling problem known as a sequence-to-sequence modeling problem. A deep neural network–based model, known as the Transformer, was then slightly adapted and fit to the data set. Its performance was then assessed on an external data set and compared to the current state-of-the-art approach. CIs for derived measurements were estimated via bootstrapping. Results The proposed approach resulted in an F-measure value of 0.952 (95% CI 0.946-0.957), which constitutes a significant improvement over the current state-of-the-art approach and its previously reported F-measure value of 0.825 as assessed on a comparable data set. Such an improvement makes possible a whole field of new applications, from nosologist-level automated coding to temporal harmonization of death statistics. Conclusions This paper shows that a deep artificial neural network can directly learn from voluminous data sets in order to identify complex relationships between natural language and medical entities, without any explicit prior knowledge. Although not entirely free from mistakes, the derived model constitutes a powerful tool for automated coding of medical entities from medical language with promising potential applications.",
  "full_text": "Original Paper\nNeural Translation and Automated Recognition of ICD-10 Medical\nEntities From Natural Language: Model Development and\nPerformance Assessment\nLouis Falissard, PhD; Claire Morgand, MD, PhD; Walid Ghosn, PhD; Claire Imbaud, PhD; Karim Bounebache, PhD;\nGrégoire Rey, PhD\nCentre for Epidemiology on Medical Causes of Death, Inserm, Le Kremlin Bicêtre, France\nCorresponding Author:\nLouis Falissard, PhD\nCentre for Epidemiology on Medical Causes of Death\nInserm\n80 Rue du Général Leclerc\nLe Kremlin Bicêtre, 94270\nFrance\nPhone: 33 679649178\nEmail: louis.falissard@gmail.com\nAbstract\nBackground: The recognition of medical entities from natural language is a ubiquitous problem in the medical field, with\napplications ranging from medical coding to the analysis of electronic health data for public health. It is, however, a complex\ntask usually requiring human expert intervention, thus making it expansive and time-consuming. Recent advances in artificial\nintelligence, specifically the rise of deep learning methods, have enabled computers to make efficient decisions on a number of\ncomplex problems, with the notable example of neural sequence models and their powerful applications in natural language\nprocessing. However, they require a considerable amount of data to learn from, which is typically their main limiting factor. The\nCentre for Epidemiology on Medical Causes of Death (CépiDc) stores an exhaustive database of death certificates at the French\nnational scale, amounting to several millions of natural language examples provided with their associated human-coded medical\nentities available to the machine learning practitioner.\nObjective: The aim of this paper was to investigate the application of deep neural sequence models to the problem of medical\nentity recognition from natural language.\nMethods: The investigated data set included every French death certificate from 2011 to 2016. These certificates contain\ninformation such as the subject’s age, the subject’s gender, and the chain of events leading to his or her death, both in French and\nencoded as International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) medical\nentities, for a total of around 3 million observations in the data set. The task of automatically recognizing ICD-10 medical entities\nfrom the French natural language–based chain of events leading to death was then formulated as a type of predictive modeling\nproblem known as a sequence-to-sequence modeling problem. A deep neural network–based model, known as the Transformer,\nwas then slightly adapted and fit to the data set. Its performance was then assessed on an external data set and compared to the\ncurrent state-of-the-art approach. CIs for derived measurements were estimated via bootstrapping.\nResults: The proposed approach resulted in an F-measure value of 0.952 (95% CI 0.946-0.957), which constitutes a significant\nimprovement over the current state-of-the-art approach and its previously reported F-measure value of 0.825 as assessed on a\ncomparable data set. Such an improvement makes possible a whole field of new applications, from nosologist-level automated\ncoding to temporal harmonization of death statistics.\nConclusions: This paper shows that a deep artificial neural network can directly learn from voluminous data sets in order to\nidentify complex relationships between natural language and medical entities, without any explicit prior knowledge. Although\nnot entirely free from mistakes, the derived model constitutes a powerful tool for automated coding of medical entities from\nmedical language with promising potential applications.\n(JMIR Med Inform 2022;10(4):e26353) doi: 10.2196/26353\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 1https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nKEYWORDS\nmachine learning; deep learning; machine translation; mortality statistics; automated medical entity recognition; ICD-10 coding\nIntroduction\nBackground\nThe democratization of electronic health record databases has\ncreated countless opportunities to gain precious insights in fields\nranging from precision medicine to public health and\nepidemiology. However, these databases still present many\nchallenges, both technical and methodological, that make their\nexploitation cumbersome. As an example, natural language is\nextensively present in some health-related databases, while\nbeing notoriously difficult to handle with traditional statistical\nmethods and preventing most international comparisons due to\nlanguage barriers. In order to counter these undesirable\nproperties, several approaches have been devised. For instance,\nby encapsulating most medical entities in a standardized\nhierarchical tree structure, the International Statistical\nClassification of Diseases and Related Health Problems, Tenth\nRevision (ICD-10) [1] offers a powerful and expressive way of\norganizing analytics-compatible health databases. On the other\nhand, ICD-10 entities are significantly less intuitive for human\nusers than natural language and require years of training and\npractice to handle fluently. As a consequence, the data\nproduction of classification-based medical data is usually\nhandmade, expansive, and time-consuming. Several attempts\nhave been made to design artificial intelligence–based systems\nthat are able to automatically derive medical entities from natural\nlanguage, some with quite promising performance [2-4].\nHowever, all of them fall short in automating the complex\nproduction schemes inherent to medical databases, specifically\nin regard to their high data-quality standards.\nHowever, recent innovations in deep artificial neural networks\nhave achieved significant progress in natural language\nprocessing (NLP) [5,6]. In particular, their applications in the\nfield of machine translation [7-9], fueled by increases in both\ndata and computing power, repeatedly bring automated systems\ncloser and closer to human-level performance. Several attempts\nhave been made to apply these powerful techniques in an\nelectronic health database setting, most of them with mitigated\nsuccess. As an example, the current state of the art in ICD-10\nentity recognition from natural language in death certificates\nstill remains a combination of expert systems and support vector\nmachine (SVM)–based classical machine learning [2]. Several\nexplanations exist for this discrepancy between traditional\nmachine translation and medical entity recognition. First, deep\nartificial neural network–based methods are known to require\nhuge amounts of data for optimal performance. However, most\nexperiments were either performed with slightly out-of-date\nneural architectures or with data set sizes at least an order of\nmagnitude below what would be typically required [10]. On the\nother hand, the Centre for Epidemiology on Medical Causes of\nDeath (CépiDc) has been storing French death certificates at\nthe national scale since 2011 in both natural language and\nICD-10–converted formats. The entire database amounts to just\nunder 3 million death certificates, thus providing considerably\nbetter settings in which to investigate the potential applications\nof deep neural networks in medical entity recognition.\nThis paper formulates the process of ICD-10 entity recognition\nfrom natural language as a sequence-to-sequence (Seq2Seq)\nstatistical modeling problem and proposes to solve it with a\nvariation one of the state-of-the-art machine translation neural\narchitectures, the Transformer. The Methods section focuses\non describing the aforementioned statistical modeling problem\nand overall methodology. The Results section reports the results\nof the experiments that were performed on the French CépiDc\ndata set as well as a comparison with the current state of the art.\nThe Discussion section presents a discussion on the model’s\npotential limitations through an error analysis and describes\npotential elements for improvement.\nRelated Work\nThe task of identifying ICD-10 medical entities from natural\nlanguage, whether in French or in any other language, is a\nwell-investigated problem, where several promising approaches\nhave already been proposed. Most of these solutions were\npublished at the Conference and Labs of the Evaluation Forum\n(CLEF) eHealth challenge [2,3,10], a competition held annually\nwhere teams compete to solve NLP tasks on medical textual\ndata. For instance, the task of recognizing ICD-10 entities from\ndeath certificates, in several languages including French, have\nbeen addressed several times over the years in this competition.\nSo far, when it comes to the task of extracting ICD-10 entities\nfrom French death certificates, the state of the art is held by the\nLaboratoire d'Informatique pour la Mécanique et les Sciences\nde l'Ingénieur (LIMSI); they used a hybrid approach that\ncombined data-based dictionaries for feature engineering and\nlinear SVMs. However, nowadays, most NLP tasks are typically\nbetter handled by neural network–based architectures. These\ndeep learning–based approaches have been applied to the\nproblem at hand in this paper, mainly through a range of\nSeq2Seq architectures, as follows:\n• Recurrent neural network–based encoder-decoder\narchitectures, either with or without attention [11]\n• Convolutional neural network–based encoder-decoder\narchitectures [12,13]\n• Fully attentional, although pretrained, architectures using\na Bidirectional Encoder Representations from Transformers\n(BERT) model and transfer learning [14,15].\nHowever, all those techniques, at least when applied to French\ndata, failed to outperform the LIMSI’s feature\nengineering–based approach. A possible explanation for this\nobservation might lie in the data set that the teams were given.\nIndeed, their sample sizes were generally less than 200,000\nobservations [2]; this is usually far from enough for proper\ntraining of advanced deep learning models, as modern neural\narchitectures in the neural translation academic literature usually\ntrain on data sets with up to tens of millions of observations [9].\nThis might also explain why teams using fully attentional\nmodels, which are the current state-of-the-art models in neural\ntranslation, used pretrained architectures and transfer learning\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 2https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nwith BERT instead of training a full neural architecture end to\nend in a purely supervised fashion. The latter is exactly what\nthis paper sets out to investigate and constitutes, at least to the\nauthors’ knowledge, the first attempt at training a modern, fully\nattentional, end-to-end trained model on a data set with a sample\nsize compliant with the requirements of modern deep learning\nmethods.\nMethods\nEthical Considerations\nThe use of the mortality data investigated in this paper aligns\nwith the mission of Inserm to produce national statistics on the\nmedical causes of death, as listed in Article L2223-42 of the\ngeneral code of local authorities (Code général des collectivités\nterritoriales), after consulting the French National Commission\nfor Data Protection and Liberties (Commission Nationale de\nl'Informatique et des Libertés).\nMaterials\nOverview\nThe data set used for this study consists of every available death\ncertificate found in the CépiDc database for the years 2011 to\n2016, representing just under 3 million training examples. These\ndocuments record various types of information about their\nsubjects, including the chain of events leading to the subject’s\ndeath, written by a medical practitioner.\nCausal Chain of Death\nThe causal chain of death constitutes the main source of\ninformation available on a death certificate in order to devise\nmortality statistics. It typically sums up the sequence of events\nthat led to the subject’s death, starting from immediate causes,\nsuch as cardiac arrest, and progressively expanding into the\nindividual’s past and to the underlying causes of death. The\nWorld Health Organization (WHO) provides countries with a\nstandardized causal chain of events format, which France\nfollows, alongside most developed countries. This WHO\nstandard asks the medical practitioner in charge of reporting the\nevents leading to the subject’s passing to fill out a two-part form\nin natural language. The first part is comprised of four lines, in\nwhich the practitioner is asked to report the chain of events in\ninverse causal order (ie, immediate causes are reported on the\nfirst lines, and underlying causes are reported on the last lines).\nAlthough four lines are available for reporting, they do not all\nneed to be filled. In fact, the last available lines are rarely used\nby the practitioner. The second part is comprised of two lines\nin which the practitioner is asked to report “any other significant\nconditions contributing to death but not related to the disease\nor condition causing it” [16] that the subject may have been\nsuffering from.\nIn order to counter the language-dependent variability of death\ncertificates across countries, a preprocessing step is typically\napplied to the causal chain of events leading to the individual’s\ndeath, where each natural language–based line on the certificate\nis converted into a sequence of codes defined by the ICD-10\n[1]. The ICD-10 is a medical classification created by the WHO\nthat defines 14,199 medical entities (eg, diseases, signs, and\nsymptoms) distributed over 22 chapters; entities are encoded\nwith three or four alphanumeric decimal symbols (ie, one letter\nand two or three digits), 5615 of which are present in the\ninvestigated data set. Table 1 shows an example of a causal\nchain of events, taken from an American death certificate, in\nboth natural language and ICD-10 formats.\nTable 1. Example of a causal chain of events leading to death as written in natural language and as ICD-10 codes.\nICD-10a,b encodingNatural languagePart of form\nPart 1\nI64 G819Stroke in September left hemiparesisLine 1\nS010 W19 S423Fall scalp laceration fracture humerusLine 2\nI251Coronary artery diseaseLine 3\nI629Acute intracranial hemorrhageLine 4\nF03 F329 I10Dementia depression hypertensionPart 2\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nbSome natural language lines correspond to several ICD-10 codes, whose orders matter in the overall coding process.\nAs previously mentioned, the process of converting the natural\nlanguage–based causal chain of events leading to death into an\nICD-10 format is the main focus of this paper. Consequently,\nthe latter will be selected as the target variable and the former\nas the main explanatory variable for the neural network–based\npredictive model that will be further defined.\nFor reasons related to the underlying cause of death production\nprocess, the natural language–based chain of events and its\nICD-10–encoded counterpart suffer from alignment errors at\nthe line level, as shown in Table 2. Although qualitatively\ndeemed quite rare, this misalignment phenomenon brings\nsufficient noise into the data set to prevent model convergence\nwhile fitting models with line-level sentence pairs.\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 3https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 2. Death certificate from showcasing the misalignment phenomenon.\nICD-10a encodingNatural languagePart of form\nPart 1\nI64 G819Stroke in September left hemiparesisLine 1\nS010 W19 S423Fall scalp laceration fracture humerusLine 2\nI629b I251Coronary artery diseaseLine 3\nN/AcAcute intracranial hemorrhagebLine 4\nF03 F329 I10Dementia depression hypertensionPart 2\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nbThe ICD-10 code related to line 4 has been moved to line 3 by a human coder. Concatenating lines in a backward fashion restores alignment while\npreserving ordering.\ncN/A: not applicable; the code that was previously here was moved to line 3, leaving this line blank.\nIn order to bypass this critical flaw in the investigated data set,\na decision was taken to consider as input and target variables\nthe certificate lines concatenated in a backward fashion (from\npart 2 to line 1 in part 1), as can be seen in Figure 1. This slight\nchange in data format does not significantly alter the problem\nat hand, as the investigated model is still trained to recognize\nICD-10–encoded medical entities from natural language. If\nanything, the modified modeling problem can be expected to\nbe more difficult, as both the variance and dimensionality of\nboth input and target variables have increased. Several methods\nare available to retrieve line-level aligned predictions from a\nmodel trained in such a configuration, for instance, using a\ncombination of transfer learning and pruned tree search.\nFigure 1. The original modeling problem and the modified investigated problem. In the original modeling problem (left), each certificate line is taken\nas an input variable to predict its corresponding ICD-10 code line. In the modified investigated problem (right), all certificate lines are concatenated\nand taken as an input variable to predict the corresponding concatenated ICD-10 code line. Lines 1-5 are from part 1 of the death certificate, and line 6\nis part 2 of the certificate. ICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nMiscellaneous Variables\nFrom gender to place of birth, a death certificate contains various\nadditional types of information on its subject besides the chain\nof events leading to death. As some of these items are typically\nused by both expert systems and human coders to detect ICD-10\nentities in the chain of events, they present an interest as\nexplanatory variables for the investigated predictive model.\nAfter consultation with expert coders, the following items\navailable on French death certificates were selected as additional\nexogenous variables:\n• Gender (two-state categorical variable)\n• Year of death (six-state categorical variable)\n• Age, categorized into 5-year intervals, with the exception\nof subjects less than 1 year of age, who were divided into\ntwo classes depending on whether they were more than 28\ndays of age\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 4https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n• Origin of the death certificate (two-state categorical\nvariable, from either the electronic- or paper-based death\ncertification pipeline).\nStrictly speaking, the subject’s year of passing should only have\na limited effect on the relationship between natural language\nand its contained medical entities. However, the WHO-defined\ncoding rules, as well as their interpretations by human coders,\nevolve slightly over the years. As a consequence, the model\nshould benefit, in terms of predictive performance, from being\nable to differentiate between different years.\nSimilarly, the impact of the certificate’s origin on the model’s\npredictive power is not entirely obvious at first sight. However,\nthe data entry process for the paper-based certificates is handled\nby humans through speech recognition technology. In addition,\nthe data entry clerks are asked to apply a small set of\nnormalization rules to the natural language. Electronic death\ncertificates, however, are received directly from the medical\npractitioner as is. As a consequence, distribution shifts are to\nbe expected from the paper- to electronic-based chain of events,\nand including this information as an explanatory variable might\nbe beneficial for the model’s predictive power.\nModel Definition\nWith both the explanatory and target variables well defined, the\ninvestigated modeling problem can be defined as follows:\nThe elements of equation 1 are defined as follows:\n• P(X)) is the probability density of discrete random variable\nX\n•\n is the sequence of ICD-10 codes present\non the death certificate concatenated on a single line of\nsequence length I\n•\n is the line in natural language, tokenized with\na vocabulary V and of sequence length L\n•\n is the categorized age\n•\n is the year of death\n•\n is the gender\n•\n is the death certificate’s origin\n• fθ is a mapping from the problem’s input space to its output\nspace, parameterized in θ∈Rn, a real-valued vector\n(typically a neural network) of dimensionality n∈N, the\nmodel’s dimensionality.\nTheoretically, the derived modeling problem is typical of\ntraditional statistical modeling problems and could be solved\nusing multinomial logistic regression. In practice, however, this\napproach presents a significant drawback. In this setting, the\ninvestigated target variable constitutes a categorical variable\nwith 561620 distinct states—death certificates in the data set\nhave, at most, 20 ICD-10 codes in them, each of which can take\n5616 distinct values—thus rendering the analysis intractable,\nboth in terms of computational expanses and sample size\nrequirements. This type of approach, however, makes no use\nof the data’s inherent sequential nature, which allows the\nrewriting of the investigated modeling problem as follows:\nwhere \n is the i-th code present on\nthe code line.\nFactors in the right-hand side of equation 2 can be interpreted\nas constituting a distinct predictive modeling problem, all with\nan output variable distributed across all ICD-10 codes. Although\nstill highly dimensional, predicting output variables of such\ndimensionality is typically tractable with modern machine\nlearning techniques [7]. However, they present two significant\ndrawbacks for traditional modeling techniques: (1) the number\nof output variables to predict varies across observations in the\ndata set (not all death certificates have 20 ICD-10 codes) and\n(2) the output variables’ distributions are conditioned on\nprevious ones.\nThis particular formulation is known in the deep artificial neural\nnetwork community as a Seq2Seq modeling problem [7] and\nhas been an active area of research for the past few years. As\none of the state-of-the-art neural architectures devised in the\nfield, the Transformer [9] was chosen as the predictive model\ninvestigated in the following experiments. It was recently\noutperformed by the Evolved Transformer [17], a variation on\nthe former. However, both approaches were investigated and\nyielded similar results. The Transformer architecture was\nretained due to its availability of official and maintained\nimplementations, and the final results further displayed were\nobtained using an ensemble of seven such models. Each of the\nensemble models’ hyper-parameters and individual\nperformances are available in Tables S1 and S2 of Multimedia\nAppendix 1, respectively.\nSeveral specificities in the previously defined modeling problem\nrequired small adaptations to the Transformer architecture.\nHowever, the authors feel that their complexity falls outside the\nscope of this paper. The interested reader will, however, find a\ncomplete description of these modifications as well as a\nvisualization in Figure S1 of Multimedia Appendix 1.\nFinally, the authors are aware that many other approaches to\nsequential learning architectures are available, and have already\nbeen used, in order to address the problem investigated in this\npaper. The current state of the art on French death certificates,\nfor instance, uses a multi-label classification approach. The\nauthors chose not to investigate those methods for several\nreasons.\nFirst, the task of extracting ICD-10 codes from natural language\non death certificates is only a preliminary step in the production\nof a mortality statistics pipeline. The final task in this process\nis to derive the underlying cause of death, from these ICD-10\ncodes, following a set of rules defined by the WHO. The choice\nof the underlying cause of death from this set of rules heavily\ndepends on the codes’order in the certificate. As a consequence,\nit is of paramount importance that the model be able to output\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 5https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nthese codes in the proper order, which is simply unachievable\nwith a multiclass classification approach; this makes the problem\na sequential learning problem, as our output is, indeed, a\nsequence of variable-length tags taken from a set of well-defined\nclasses. However, several approaches other than Seq2Seq are\nstill available to solve such problems, such as connectionist\ntemporal classification, which is typically used in optical\ncharacter recognition tasks.\nSecond, the ICD-10 codes that the model needs to output are\nnot necessarily independent. For instance, the presence of a\ngiven code in the outputted sequence can significantly alter\nother codes present in the sequence. As an example given by\nour expert coder, hematoma-related codes can be found in two\nICD-10 chapters: first in chapter 9 of the ICD-10 classification\n(ie, codes related to circulatory diseases, beginning with an “I”)\nand then in chapter 19 (ie, codes related to injury, poisoning,\nand certain other consequences of external causes, beginning\nwith an “S” or a “T”). The choice of attributing the presence of\nthe entity “hematoma” on a death certificate to the first or second\npossible chapter depends on whether an external\ncause—meaning an ICD-10 code from chapter 20—has already\nbeen outputted previously while converting the death certificate\ninto codes. In order to account for such dependencies, we are\ncompelled to model the joint distribution of the output sequence\nconditioned on the input variables, which is exactly what\nSeq2Seq is about. Therefore, the choice of using Seq2Seq\napproaches to solve the modeling problem investigated in this\npaper becomes not only natural but almost compulsory. In\naddition, due to the data-driven tokenization used in order to\nmake use of the ICD-10 classification’s hierarchical nature,\nsome tokens that the model is allowed to predict are not valid\nICD-10 codes. For instance, the code “I659” could be\ndecomposed into a sequence of two codes (ie, “I65” and “9-”\nwith the “-” character at the end used to keep track of spaces\nbetween codes). It appears clear here that when the model needs\nto output an “I659” code, predicting “9-” in itself is not possible\nwithout any conditioning on “I65” appearing earlier.\nTraining and Evaluation Methodology\nThe investigated model was trained using all French death\ncertificates from the year 2011 to 2016. A total of 5000\ncertificates were randomly excluded from each year; these were\ndistributed into a validation set for hyper-parameter fine-tuning\nand into a test data set for unbiased prediction performance\nestimation (2500 certificates each), resulting in three data sets\nwith following sample sizes: (1) training data set (3,240,109\nrecords), (2) validation data set (30,000 records), and (3) test\ndata set (30,000 records).\nThe model was adapted from TensorFlow’s official Transformer\nimplementation; TensorFlow is a Python-based distributed\nmachine learning framework. Training was performed on three\nNVIDIA RTX 2070 GPUs simultaneously with a mirrored\ndistribution strategy using a variant of stochastic gradient\ndescent, the Adam optimization algorithm.\nHyper-parameters were first initialized following the\nTransformer’s base setting, according to the architecture’s\nauthors. Further fine-tuning of a selected number of\nhyper-parameters was performed using a random search guided\non the validation set. The interested reader will find a complete\ndescription of the training process and hyper-parameter values\ndefining this model in Multimedia Appendix 1.\nAfter training, the model’s predictive performance was assessed\non the test data set, which was excluded prior to training, as\nmentioned earlier, and compared to the current state of the art,\nobtained by the LIMSI during the 2017 CLEF eHealth challenge\n[2]. As the CLEF eHealth challenge only provided electronic\ncertificates to the contestants, and in order to ensure\ncomparability, the model’s performance was assessed using\npaper-based and electronic certificates, separately. For the same\nreason, the performance metrics used for model evaluation were\nselected as follows:\nThe elements of equations 4 and 5 are defined as follows:\n• True positives: the number of codes predicted by the model\nthat are present in the test set’s true output target\n• False positives: the number of codes predicted by the model\nthat are not present in the test set’s true output target\n• False negatives: the number of codes not predicted by the\nmodel that are present in the test set’s true output.\nNote that predictions are considered as true positives only for\nexact code matches, up to the fourth character. Table 3 shows\nan example of how this can affect the reported performance, by\nfocusing on a line of the causal chain of events leading to death\nreported in Table 1 and fictional examples of predictions, as\nfollows:\n• The first prediction example outputs two incorrect codes.\nThe number of true positives is, thus, 0, leading to all\nmetrics being evaluated as 0.\n• The second prediction example correctly outputs the first\ncode (I64: “Stroke”) but fails to correctly output the second\ncode’s fourth character (G81: “Hemiplegia” is predicted\ninstead of the ground-truth value G819: “Hemiplegia,\nunspecified”). Although the prediction and ground truth\nare quite similar (ie, they share the three first characters),\nthis code is considered incorrect, which leads to counts of\nboth one false positive (ie, the code was predicted\nincorrectly) and one false negative (ie, the correct G819\ncode was not predicted), leading to all metrics being\nevaluated as 0.5.\n• The third prediction example correctly outputs the first code\nbut fails to recognize any additional codes from the textual\ninput, leading to a precision of 1 (ie, all predicted codes are\nindeed true positives) and a recall of 0.5 (ie, one code\npresent in the ground truth was not predicted). This then\nleads to an F-measure of 0.66. Note that in this context, the\nF-measure is higher than in the second example.\n• The fourth prediction example correctly outputs both codes\nbut also outputs two additional and completely unrelated\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 6https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\ncodes, leading to a precision of 0.5 (ie, only half of the\npredicted codes are present in the ground truth) and a recall\nof 1 (ie, all codes present in the ground truth were correctly\npredicted), leading to an F-measure of 0.66.\n• The fifth prediction example correctly outputs both codes\nand does not predict any additional codes (ie, perfect\nprediction), leading to all metrics being evaluated as 1.\n• The sixth prediction example correctly outputs both codes\nand does not predict any additional codes. However, the\ncodes are in the wrong order, but this is not penalized in\nany way in the metrics definitions, so this prediction is\nassociated with metrics all being evaluated as 1.\nTable 3. Examples of how the selected performance metrics behave for different predictions. The input text was “stroke in September left hemiparesis”\nand the true ICD-10 encoding was I64 and G819.\nF-measureRecallPrecisionICD-10a codesPrediction example\n0.00.00.0B189 H1551\n0.50.50.5I64 G812\n0.660.51.0I643\n0.661.00.5I64 G819 A338 B874\n1.01.01.0I64 G8195\n1.01.01.0G819 I646\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nThe informed reader might find that these metrics stray away\nfrom common machine translation system benchmarking\nmetrics, such as bilingual evaluation understudy (BLEU) or\nnegative log perplexity scores [7-9,18], but the former were the\nonly ones used in comparable work. As BLEU and negative log\nperplexity have close to no absolute interpretability without\ncomparisons to alternative methods, their use was discarded\nfrom the experiment. In order to present the reader with a more\ncomprehensive view of the performance of the proposed\napproaches, these accuracy metrics were also derived on a\nper-chapter basis, again on the same test set, and 95% CIs were\ncomputed using bootstrapping.\nResults\nPerformance Evaluation\nThe ensemble of Transformer models were trained as previously\ndescribed for approximately 3 weeks; the final ensemble’s\npredictive performance and that of the current state-of-the-art\nmodel are reported in Table 4. As previously mentioned, the\nperformance of the current state-of-the-art model was assessed\nbased on electronic certificates only and should, as a\nconsequence, be compared to the performance of the proposed\napproach based on a similar situation. Because paper-based\ncertificates are still more common than their electronic\ncounterparts in France (ie, approximately 90% of certificates\nin the data set are paper based), the performance of the approach\nusing all certificates and that of the paper-based certificate\napproach are also displayed.\nTable 4. Assessments of the current state-of-the-art model and the proposed approach.\nRecall (95% CI)Precision (95% CI)F-measure (95% CI)aApproach\n0.784c0.872c0.825cCurrent state of the art: LIMSIb\n0.948 (0.943-0.954)0.955 (0.95-0.96)0.952 (0.946-0.957)Proposed approach: electronic certificates\n0.936 (0.934-0.937)0.949 (0.947-0.95)0.942 (0.941-0.944)Proposed approach: paper-based certificates\n0.937 (0.935-0.938)0.949 (0.948-0.951)0.943 (0.941-0.944)Proposed approach: all certificates\na95% CIs were derived by bootstrapping.\nbLIMSI: Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur.\nc95% CIs were not provided in the LIMSI’s publication and are, therefore, not displayed.\nThe proposed approach shows an F-measure that is 73% closer\nto a perfect score when compared to the current state-of-the-art\napproach. In addition to its substantial improvement in the\nF-measure, the proposed approach displays significantly more\nbalanced precision and recall scores than the LIMSI’s method:\nfrom 5% relative difference to less than 1%.\nA surprising result, however, lies in the model’s lower\nperformance based on paper-based certificates. Indeed, the\nstandardization they receive due to their voice-based data\ncollection process considerably reduces variance and prevents\nany misspelled words in the data that are potentially present in\nelectronic-based certificates. As a consequence, model\nperformance on the former should be expected to be higher. A\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 7https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\npotential explanation for this phenomenon lies in the potential\nfor missing data in paper-based certificates. Indeed, when\nconfronted with poorly written words, data clerks are allowed\nto replace them with the “!” symbol when the word is estimated\nto be unreadable; this occurs in approximately 10% of\npaper-based certificates. Medical coders, however, are usually\nmore efficient in guessing the words from the written\ncertificates, typically with the addition of contextual clues. A\npurely text-based approach, however, is then limited to pure\nguesses for those observations with missing data, logically\nleading to poorer performance. Because this phenomenon is\nabsent from electronic-based certificates, it is a promising\ncandidate for explaining this unexpected difference in\nperformance. In addition, the model performance based on\npaper-based certificates that did not contain any “!” symbols in\nthe test set led to an F-measure of 96.2%, thus providing strong\nevidence to support this hypothesis.\nPer-Chapter Quantitative Analysis\nAlthough the proposed approach significantly outperformed the\ncurrent state-of-the-art approach, neural network–based methods\nare known to present several drawbacks that can significantly\nlimit their application in some situations. Typically, the current\nlack of systematic methods to interpret and understand neural\nnetwork–based models and their decision processes can lead\nthe former to perform catastrophically on incorrectly predicted\ncases, independent from their high predictive performance. As\na consequence, the proposed model behavior in incorrectly\npredicted cases requires careful analysis. In addition, such an\ninvestigation can lead to significant insights that are potentially\nrelevant when applying the derived model in practical\napplications.\nOne simple, straightforward approach to understanding the\nmodel’s weakness lies in assessing its performance on a\nfiner-grain level, for instance, by identifying false positives and\nnegatives not only at the global level, but per ICD-10 chapters,\nas can be seen in Table 5.\nIt appears from this table that although the most prevalent\nmedical entities are associated with low false positive and\nnegative rates, some rarer chapters are associated with\nunreasonably high error rates. Depending on their prevalence\nand accuracies, these chapters can be classified into two distinct\ncategories:\n1. Chapters associated with unreasonably high error rates but\nextremely low prevalence, such as “Diseases for the ear\nand mastoid process” or “Pregnancy, childbirth and the\npuerperium.” However, these entity groups remain rare\nenough within the data set to allow for alternative\ntreatments, like manual evaluation, for instance.\n2. Chapters associated with high error rates, although lower\nthan the former, but with significant prevalence, such as\n“External causes of morbidity and mortality” or “Injury,\npoisoning and certain other consequences of external\ncauses.”\nThe task of identifying these potential mistakes, however, is\nnot entirely trivial depending on whether mistakes are of false\npositive or false negative types. Indeed, potential false positive\nerrors are directly identifiable within the predicted ICD-10 code\nsequences. As a consequence, coding quality control for this\ntype of mistake should be fairly straightforward to implement:\none could, for instance, manually review all code sequences\ncontaining codes related to “Pregnancy, childbirth and the\npuerperium” systematically. Potential false negative errors,\nhowever, are inherently significantly harder to identify and\nrequire further investigation, for instance, through association\nrules analysis.\nA number of promising leads are already available and should\nreasonably improve upon the proposed approach:\n• Training methods adapted to imbalanced data sets, such as\nup-sampling or loss weighting\n• Data augmentation for rare medical entities\n• Addition of information to the model (ie, prenatal-related\ndeath, for instance, is explicitly defined as such on\ncertificates)\n• A hybrid approach with traditional NLP approaches, which\nare typically less expensive in terms of sample size\nrequirements.\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 8https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 5. False positive, false negative, and prevalence rates for each ICD-10 chapter, sorted in descending order by prevalence.\nPrevalence, %False negatives, %False positives, %ICD-10a chapter\n22.44.983.75Diseases of the circulatory system\n21.84.123.87Symptoms, signs and abnormal clinical and laboratory\nfindings, not elsewhere classified\n15.95.074.07Neoplasms\n8.764.003.02Diseases of the respiratory system\n4.833.442.17Endocrine, nutritional and metabolic diseases\n3.894.122.70Diseases of the nervous system\n3.584.142.88Mental, behavioral and neurodevelopmental disorders\n3.538.105.72Diseases of the digestive system\n3.0819.619.2Factors influencing health status and contact with health\nservices\n2.717.595.45Diseases of the genitourinary system\n2.5723.516.6External causes of morbidity and mortality\n2.559.237.98Certain infectious and parasitic diseases\n2.0719.814.0Injury, poisoning and certain other consequences of external\ncauses\n0.7712.26.72Diseases of the blood and blood-forming organs and certain\ndisorders involving the immune mechanism\n0.6217.312.2Diseases of the musculoskeletal system and connective\ntissue\n0.518.168.72Diseases of the skin and subcutaneous tissue\n0.1620.514.5Certain conditions originating in the perinatal period\n0.1525.622.4Congenital malformations, deformations and chromosomal\nabnormalities\n0.07613.64.93Diseases of the eye and adnexa\n0.04734.024.0Codes for special purposes\n0.01733.35.60Diseases of the ear and mastoid process\n0.005633.350.0Pregnancy, childbirth and the puerperium\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nScore Calibration Fitness Assessment\nWhen the model is fit in a similar fashion to multinomial logistic\nregression, it not only yields a prediction but an associated score\nsimilar to a confidence probability. If properly calibrated, this\nscore can offer powerful insights regarding the prediction’s\nquality at the individual level. Typically, a “good” score would\nbe expected to show higher values in cases where the ICD-10\nsequence is correctly predicted and lower values when\nincorrectly predicted. Such a well-calibrated score could, for\ninstance, allow for real-world applications of semiautonomous\nsystems where the following occurs:\n• A threshold value for the model’s score is defined.\n• All certificates whose predictions are associated with\nconfidence scores above the threshold level are accepted\nwithout any additional human supervision.\n• All certificates whose predictions are associated with\nconfidence scores below the threshold level are\nsystematically reviewed by a human expert and modified\nmanually, if required.\nBeing able to properly filter the model’s predictions according\nto a well-calibrated confidence score would, thus, allow us to\nget the best of both worlds. Most of the certificates would be\nautomatically coded by the autonomous system, leaving human\ncoders with only the most complex cases.\nEfficient assessment of such scores in traditional machine\nlearning problems is typically done through visualization of\nreceiver operating characteristic (ROC) curves. However, the\nsequential multinomial nature of the investigated problem\nrenders this approach ill-defined. The plot in Figure 2, while\nconceptually similar to an ROC curve, was derived following\na slightly different approach in order to efficiently appreciate\nthe model score’s quality. This visualization was derived as\nfollows:\n• A grid of score threshold values was defined with a uniform\ngrid with 0.01 intervals, corresponding to the threshold\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 9https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\ndefined above, filtering between model predictions that\nwould require human examination or not.\n• For every given threshold value, we computed the\npercentage of predictions with inferior or equal scores,\nwhich were considered as rejected, requiring human\nexamination due to poor score; we also computed the\nF-measure performance on the predictions with high enough\nscores that would be accepted without any human\nintervention following the above example.\n• The percentage of accepted certificates and F-measures\nwere plotted on a scatterplot against each other, with\nthreshold values displayed as colored points.\nFigure 2. Percentage of rejected predictions versus F-measure for accepted ones. The score threshold values defining the accepted predictions are\ndisplayed as colored points.\nBy showing a clean, increasing relationship between the number\nof rejected predictions and the F-measure evaluated using the\nremaining certificates, Figure 2 strongly indicates good score\ncalibration. As an example, by considering that only predictions\nassociated with a confidence score lower than 0.5 do not require\nany additional human supervision, the system is able to code\napproximately 80% of all certificates present in the test set with\nan F-measure of 0.98, significantly higher than the value of 0.94\nobtained on all test certificates.\nDiscussion\nPrincipal Findings\nThe error analysis carried out so far allowed for the assessment\nof the model’s strengths and weaknesses on a global level.\nHowever, it failed to yield any interesting insights regarding\npotential model biases, for instance, toward specific coding\nrules. Indeed, the coding of medical entities from natural\nlanguage, especially with regard to mortality statistics, is subject\nto a number of coding rules depending on context or pathology,\nwith a level of specificity oftentimes reaching casuistry [1].\nIn addition, all results have been presented so far with a model\nerror defined as a disagreement between the model’s output and\nthe information contained in the database. However, building\na medical database is a complex, mostly human-based process.\nAs such, an inevitable amount of noise is to be expected in the\nICD-10 codes present in the database, in two main forms. The\nfirst form is simple human errors in the ICD-10. The second\nform is the presence of unreadable text in paper-based\ncertificates. Unreadable words on paper-based certificates are\ndenoted as an exclamation point in the textual data that is fed\nto the model. However, human coders usually take additional\ntime to infer these words, for instance, via queries to the medical\ncertifier or from contextual cues. This leads to death certificates\nin the database where the ICD-10 sequences contain additional\ncodes compared to the textual data available. As such, not\npredicting these codes would result in a drop in performance\nmetrics, while the model has no way of predicting them. An\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 10https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nexample of such a death certificate can be found in Table S3 in\nMultimedia Appendix 1. These phenomena have the potential\nto negatively bias the proposed model’s performance estimations\nand should be the object of further investigation.\nOne straightforward, although fairly time-consuming, approach\nto address these two considerations can be to have an ICD-10\ncoding expert manually examine some of the death certificates\nwhere the model’s predictions do not match the ICD-10 codes\npresent in the database. Two experiments were conducted\nfollowing this idea.\nIn the first experiment, 99 certificates where the model’s\npredictions did not exactly match with the database’s ICD-10\nvariables (ie, the ICD-10 sequences differed by at least one\ncode) were selected at random from the test set and were shown\nto the medical practitioner representative and final decision\nmaker on ICD-10 mortality coding in France, who was asked\nto do the following with each certificate:\n• Manually recode all the ICD-10 medical entities present\non each death certificate by herself using the information\nthe proposed model had access to, without access to the\ndata set or to the model’s proposed ICD-10 sequences.\n• Give a qualitative comment on the outputs of the\ninvestigated model and database as compared to hers.\nSince the ICD-10 sequences derived from the medical expert\nand national representative for ICD-10 coding in France are\nsignificantly more reliable than the ones coming from the\ntraditional data production process (ie, using a combination of\nexpert system and human coders), they can be considered as\nexempt of any potential human error. As a consequence,\ncomparing them to both the proposed model’s output and the\nICD-10 values contained in the data set would allow for an\nestimation of the potential negative biases described above.\nThis can be done, for instance, by estimating the performance\nmetrics selected for the previous experiments, considering both\nthe model’s predictions and the database’s values as predictions,\nand the medical expert’s outputs as the ground truth. Depending\non the resulting values, several interpretations can be made\nranging between two extreme cases:\n1. If perfect agreement (ie, an F-measure of 1.0) is reached\nbetween the database’s ICD-10 sequences and the medical\nexpert’s outputs, suggesting that the database does not have\nany coding mistakes, then the performance metrics reported\nin the Results section can safely be considered unbiased.\n2. If perfect agreement is not reached between the model’s\npredictions of ICD-10 sequences and the medical expert’s\noutputs, suggesting that the model did not make any\nmistakes, then the performance metrics reported in the\nResults section should be considered significantly\nunderestimated.\nHowever, before estimating the performance metrics following\nthis methodology, a slight preprocessing step is required. Indeed,\non the death certificates sampled for the experiment, the\nF-measure estimation between the model’s prediction and the\ndatabase’s ICD-10 sequences yielded a value of 0.81. This is\nexplained by the sampling process, in which death certificates\nwere selected where at least one code differed in both ICD-10\nsequences. As a consequence, and because of the model’s\nperformance, most ICD-10 codes present on both sequences\nwere identical, as can be seen with the error examples presented\nin Tables S3 to S5 in Multimedia Appendix 1. The authors felt\nthat this might lead to artificially high values of the estimated\nmetrics in the experiment; consequently, we decided to delete\nall common codes on both the model’s outputs and the\ndatabase’s values prior to metrics estimation, as shown in Table\n6.\nFor better comparability, these statistics are reported based on\nboth (1) certificates without missing data in the natural\nlanguage–based causal chain of events leading to death (by\nexcluding certificates containing the “!” symbol) in Table 7 and\n(2) all certificates in Table 8.\nTable 6. Example of preprocessing used for the experiment on a real error example. The predicted and database ICD-10 sequences only differ by one\ncode, while they share five codes. All shared codes were deleted from all ICD-10 sequences prior to estimation of performance metrics.\nICD-10 codes after preprocessingICD-10 codes before preprocessingSource of ICD-10a codes\nZ951I259 Z951 I719 C679 I10 R092Predicted by the model\nI251I259 I251 I719 C679 I10 R092Present in the database\nI251I259 I251 I719 C679 I10 R092Predicted by medical expert\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nTable 7. F-measure, precision, and recall of both the database ICD-10 codes and the model’s prediction of codes compared to that of the medical expert\nfor sampled certificates without missing data.\nRecall (95% CI)Precision (95% CI)F-measure (95% CI)Source of ICD-10a codes\n0.531 (0.425-0.636)0.443 (0.341-0.555)0.483 (0.383-0.589)Presence in database against medical expert prediction\n0.407 (0.295-0.519)0.458 (0.338-0.580)0.431 (0.316-0.542)Model prediction against medical expert prediction\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 11https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nTable 8. F-measure, precision, and recall of both the database ICD-10 codes and the model’s prediction of codes compared to that of the medical expert\nfor all sampled certificates.\nRecall (95% CI)Precision (95% CI)F-measure (95% CI)Source of ICD-10a codes\n0.596 (0.471-0.721)0.630 (0.492-0.761)0.613 (0.486-0.733)Presence in database against medical expert prediction\n0.351 (0.222-0.482)0.392 (0.250-0.540)0.370 (0.237-0.504)Model prediction against medical expert prediction\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nTables 7 and 8 show no significant difference in prediction\nperformance between the proposed approach and the current\ndata production process (ie, based on a combination of expert\nsystem and human coders), although the database’s ICD-10\nvalues have better performance metrics in both cases. When\nincluding certificates containing missing text, the proposed\nmodel’s agreement with the medical expert increases\nconsiderably, further confirming the hypothesis that the\nperformance metrics reported in the Results section were\nnegatively biased.\nFrom the qualitative comments made by the medical expert,\nthree major types of model errors could be defined:\n1. In 16% (16/99) of cases, disagreement between the current\ndata production process and the proposed approach was\ndue to missing information in the input text. On these\nspecific cases, the F-measure between the model’s output\nand medical expert’s decision was determined to be 0.974;\nan example of such an error case can be seen in Table S3\nin Multimedia Appendix 1.\n2. In 14% (14/99) of cases, the correct ICD-10 sequence was\ndependent on highly contextual clues or external knowledge\nof world behavior (eg, someone found dead at the bottom\nof a set of stairs is quite likely to have suffered a fall). An\nexample of such an error case can be seen in Table S4 in\nMultimedia Appendix 1.\n3. In 12% (12/99) of cases, the correct ICD-10 sequence was\ndependent on highly nonlinear, almost casuistic rules. These\nwere typical examples of scenarios where a hybridized deep\nlearning and expert-based system would be beneficial; an\nexample of such an error case can be seen in Table S5 in\nMultimedia Appendix 1.\nThe remaining cases did not elicit any comment from the\nmedical expert.\nFinally, in the second experiment, the medical expert’s ability\nto discriminate between human coding and the proposed\napproach was assessed in a Turing test-like approach. To do so,\n100 additional certificates where the model’s output differed\nfrom the database’s ICD-10 sequences were sampled at random\nfrom the test set. The medical expert was shown their\ncorresponding input features (ie, text and auxiliary variables)\nas well as the two ICD-10 sequences, with their provenance\nfrom either the model or the database masked, as can be seen\nin Table 9.\nTable 9. Example of death certificate format given to the medical expert for the second experiment. The medical expert was asked, based on the\ninformation available in the line, to guess which of propositions 1 or 2 was produced by a human coder, with the other being the proposed model’s\noutput.\nProposition 2 (ICD-10\ncodes)\nProposition 1 (ICD-10c\ncodes)\nCertificate textbAge of deceased (years)Year of\ndeath\nSexa of de-\nceased\nItem\nR54 K659 K631 K566\nY839 J189 R092\nR54 K566 K659, K631\nY839 J958 R092\n90 ans, péritonite, perfora-\ntion grêle, occlusion,\nchirurgie digestive, infection\npulmonaire, arrêt respira-\ntoire\n9020132Death certifi-\ncate\naSex is a two-state categorical variable: 1 (female) or 2 (male).\nbThe certificate text was taken from a death certificate in France and is, therefore, written in French.\naICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision.\nAfter exclusion of certificates containing missing text data,\nwhere the human coder was easily identifiable due to the\napparently out-of-context additional codes (Table S3 in\nMultimedia Appendix 1), the medical expert was able to\ncorrectly identify the human coder in 63% (62/99; 95% CI\n50.7%-73.2%) of cases, which is significantly better than\nrandom guessing, although barely.\nConclusions\nIn this paper, the task of automatic recognition of ICD-10\nmedical entities from natural language in French was presented\nas a Seq2Seq modeling problem, well known in the deep\nartificial neural network academic literature. From this\nconsideration, the performance of a well-known approach in\nthe field, consisting of an ensemble of Transformer models,\nwas investigated using the CépiDc database and was shown to\nreach a new state of the art. The derived model’s behavior was\nthoroughly assessed following different approaches in order to\nidentify potential weaknesses and elements for improvements.\nAlthough the proposed approach significantly outperformed\nany other existing automated ICD-10 recognition systems based\non French free text, the question of method transferability to\nother languages requires more investigation.\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 12https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\nThe substantial performance reported in this paper makes\npossible a range of promising applications in various\nmedical-related fields, from automated medical coding to\nadvanced natural language–based analysis for epidemiology.\nHowever, these interesting opportunities are oftentimes\nprohibited by these methods’ massive drawbacks, mostly their\nrequirement for millions of annotated observations in order to\nperform well. Mortality data sets, despite their specificity,\nprovide researchers with a huge amount of clean, multilingual\nmedical text data perfectly fit for the application of deep neural\nnetworks. As a consequence, and keeping in mind the strong\ntransfer learning capability of neural networks, the authors\nfirmly believe that mortality data constitute one of the most\npromising points of entry into modern NLP methods applications\nin the biomedical sciences.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nSupplementary material.\n[DOCX File , 129 KB-Multimedia Appendix 1]\nReferences\n1. International Statistical Classification of Diseases and Related Health Problems, 10th Revision. Geneva, Switzerland: World\nHealth Organization; 2019. URL: https://icd.who.int/browse10/2019/en#/ [accessed 2022-03-19]\n2. Névéol A, Robert A, Anderson R, Cohen B, Grouin C, Lavergne T, et al. CLEF eHealth 2017 Multilingual information\nextraction task overview: ICD10 coding of death certificates in English and French. In: Proceedings of the Workshop of\nthe Cross-Language Evaluation Forum, CEUR Workshop Proceedings. 2017 Presented at: Workshop of the Cross-Language\nEvaluation Forum, CEUR Workshop; January 2017; Dublin, Ireland p. 1-17 URL: http://ceur-ws.org/Vol-1866/\ninvited_paper_6.pdf\n3. Névéol A, Bretonnel Cohen K, Grouin C, Hamon T, Lavergne T, Kelly L, et al. Clinical information extraction at the CLEF\neHealth evaluation lab 2016. In: Proceedings of the 7th International Conference of the CLEF Association, CEUR Workshop\nProceedings. 2016 Presented at: The 7th International Conference of the CLEF Association, CEUR Workshop; September\n5-8, 2016; Évora, Portugal p. 28-42 URL: http://ceur-ws.org/Vol-1609/16090028.pdf\n4. Duarte F, Martins B, Sousa Pinto C, Silva MJ. A deep learning method for ICD-10 coding of free-text death certificates.\nIn: Proceedings of the 18th EPIA Conference on Artificial Intelligence. 2017 Presented at: The 18th EPIA Conference on\nArtificial Intelligence; September 5-8, 2017; Porto, Portugal p. 137-149. [doi: 10.1007/978-3-319-65340-2_12]\n5. Mikolov T, Sutskever I, Chen K, Corrado G, Dean J. Distributed representations of words phrases and their compositionality.\nIn: Proceedings of the 26th International Conference on Neural Information Processing Systems. 2013 Presented at: The\n26th International Conference on Neural Information Processing Systems; December 5-10, 2013; Lake Tahoe, NV p.\n3111-3119 URL: https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\n6. Devin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language onderstanding.\nIn: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:\nHuman Language Technologies. 2019 Presented at: The 2019 Conference of the North American Chapter of the Association\nfor Computational Linguistics: Human Language Technologies; June 2-7, 2019; Minneapolis, MN p. 4171-4186 URL:\nhttps://aclanthology.org/N19-1423.pdf [doi: 10.18653/v1/N19-1423]\n7. Cho K, van Merriënboer B, Gulcehre C, Bahdanau D, Bougares F, Schwenk H, et al. Learning phrase representations using\nRNN encoder-decoder for statistical machine translation. In: Proceedings of the 2014 Conference on Empirical Methods\nin Natural Language Processing. 2014 Presented at: The 2014 Conference on Empirical Methods in Natural Language\nProcessing; October 25-29, 2014; Doha, Qatar p. 1724-1734 URL: https://aclanthology.org/D14-1179.pdf [doi:\n10.3115/v1/d14-1179]\n8. Gehring J, Auli M, Grangier D, Yarats D, Dauphin YN. Convoutional sequence to sequence learning. In: Proceedings of\nthe 34th International Conference on Machine Learning. 2017 Presented at: The 34th International Conference on Machine\nLearning; August 6-11, 2017; Sydney, Australia p. 1243-1252 URL: http://proceedings.mlr.press/v70/gehring17a/gehring17a.\npdf\n9. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, et al. Attention is all you need. In: Proceedings of the\n31st International Conference on Neural Information Processing Systems. 2017 Presented at: The 31st International\nConference on Neural Information Processing Systems; December 4-9, 2017; Long Beach, CA p. 5998-6008 URL: https:/\n/proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n10. Ševa J, Sänger M, Leser U. WBI at CLEF eHealth 2018 Task 1: Language-independent ICD-10 coding using multi-lingual\nembeddings and recurrent neural networks. In: Proceedings of 9th International Conference of the CLEF Association,\nCEUR Workshop Proceedings. 2018 Presented at: The 9th International Conference of the CLEF Association, CEUR\nWorkshop; September 10-14, 2018; Avignon, France p. 1-14 URL: http://ceur-ws.org/Vol-2125/paper_118.pdf\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 13https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n11. Atutxa A, de Ilarraza AD, Gojenola K, Oronoz M, Perez-de-Viñaspre O. Interpretable deep learning to map diagnostic\ntexts to ICD-10 codes. Int J Med Inform 2019 Sep;129:49-59. [doi: 10.1016/j.ijmedinf.2019.05.015] [Medline: 31445289]\n12. Reys AD, Sylva D, Severo D, Pedro S, de Sousa MM, Salgado GAC. Predicting multiple ICD-10 codes from\nBrazilian-Portuguese clinical notes. In: Proceedings of the Brazilian Conference on Intelligent Systems. 2020 Presented\nat: The Brazilian Conference on Intelligent Systems; October 20-23, 2020; Rio Grande, Brazil p. 566-580. [doi:\n10.1007/978-3-030-61377-8_39]\n13. Cao P, Yan C, Fu X, Chen Y, Liu K, Zhao J, et al. Clinical-coder: Assigning interpretable ICD-10 codes to Chinese clinical\nnotes. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations.\n2020 Presented at: The 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations;\nJuly 5-10, 2020; Virtual p. 294-301 URL: https://aclanthology.org/2020.acl-demos.33.pdf [doi:\n10.18653/v1/2020.acl-demos.33]\n14. Schafer H, Friedrich CM. Multilingual ICD-10 code assignment with transformer architectures using MIMIC-III discharge\nsummaries. In: Proceedings of the 11th Conference and Labs of the Evaluation Forum. 2020 Presented at: The 11th\nConference and Labs of the Evaluation Forum; September 22-25, 2020; Virtual p. 1-16 URL: http://ceur-ws.org/Vol-2696/\npaper_212.pdf\n15. Amin S, Neumann G, Dunfield K, Vechkaeva A, Chapman KA, Wixted MK. MLT-DFKI at CLEF eHealth 2019: Multi-label\nclassification of ICD-10 codes with BERT. In: Proceedings of the 10th Conference and Labs of the Evaluation Forum.\n2019 Presented at: The 10th Conference and Labs of the Evaluation Forum; September 9-12, 2019; Lugano, Switzerland\np. 1-15 URL: http://ceur-ws.org/Vol-2380/paper_67.pdf\n16. HM Passport Office. Completing a medical certificate of cause of death (MCCD). GOV.UK. 2018 Sep 25. URL: https:/\n/www.gov.uk/government/publications/guidance-notes-for-completing-a-medical-certificate-of-cause-of-death [accessed\n2019-04-24]\n17. So D, Le Q, Liang C. The evolved transformer. In: Proceedings of the 36th International Conference on Machine Learning.\n2019 Presented at: The 36th International Conference on Machine Learning; June 9-15, 2019; Long Beach, CA p. 5877-5886\nURL: http://proceedings.mlr.press/v97/so19a/so19a.pdf\n18. Papineni K, Roukos S, Ward T, Zhu WJ. BLEU: A method for automatic evaluation of machine translation. In: Proceedings\nof the 40th Annual Meeting on Association for Computational Linguistics. 2002 Presented at: The 40th Annual Meeting\non Association for Computational Linguistics; July 7-12, 2002; Philadelphia, PA p. 311-318 URL: https://dl.acm.org/doi/\npdf/10.3115/1073083.1073135 [doi: 10.3115/1073083.1073135]\nAbbreviations\nBERT: Bidirectional Encoder Representations from Transformers\nBLEU: bilingual evaluation understudy\nCépiDc: Centre for Epidemiology on Medical Causes of Death\nCLEF: Conference and Labs of the Evaluation Forum\nICD-10: International Statistical Classification of Diseases and Related Health Problems, Tenth Revision\nLIMSI: Laboratoire d'Informatique pour la Mécanique et les Sciences de l'Ingénieur\nNLP: natural language processing\nROC: receiver operating characteristic\nSeq2Seq: sequence-to-sequence\nSVM: support vector machine\nWHO: World Health Organization\nEdited by C Lovis; submitted 08.12.20; peer-reviewed by V Montmirail, H Park; comments to author 10.01.21; revised version received\n23.02.21; accepted 08.01.22; published 11.04.22\nPlease cite as:\nFalissard L, Morgand C, Ghosn W, Imbaud C, Bounebache K, Rey G\nNeural Translation and Automated Recognition of ICD-10 Medical Entities From Natural Language: Model Development and\nPerformance Assessment\nJMIR Med Inform 2022;10(4):e26353\nURL: https://medinform.jmir.org/2022/4/e26353\ndoi: 10.2196/26353\nPMID: 35404262\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 14https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX\n©Louis Falissard, Claire Morgand, Walid Ghosn, Claire Imbaud, Karim Bounebache, Grégoire Rey. Originally published in\nJMIR Medical Informatics (https://medinform.jmir.org), 11.04.2022. This is an open-access article distributed under the terms\nof the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use,\ndistribution, and reproduction in any medium, provided the original work, first published in JMIR Medical Informatics, is properly\ncited. The complete bibliographic information, a link to the original publication on https://medinform.jmir.org/, as well as this\ncopyright and license information must be included.\nJMIR Med Inform 2022 | vol. 10 | iss. 4 | e26353 | p. 15https://medinform.jmir.org/2022/4/e26353\n(page number not for citation purposes)\nFalissard et alJMIR MEDICAL INFORMATICS\nXSL•FO\nRenderX",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.6913386583328247
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6339929103851318
    },
    {
      "name": "Machine learning",
      "score": 0.4634307324886322
    },
    {
      "name": "Named-entity recognition",
      "score": 0.45722144842147827
    },
    {
      "name": "Natural language",
      "score": 0.44755294919013977
    },
    {
      "name": "Unified Medical Language System",
      "score": 0.4413459002971649
    },
    {
      "name": "Natural language processing",
      "score": 0.4019007682800293
    },
    {
      "name": "Task (project management)",
      "score": 0.3605908751487732
    },
    {
      "name": "Data science",
      "score": 0.35436150431632996
    },
    {
      "name": "Engineering",
      "score": 0.10232248902320862
    },
    {
      "name": "Systems engineering",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210128283",
      "name": "Centre d'Épidémiologie sur les Causes Médicales de Décès",
      "country": "FR"
    },
    {
      "id": "https://openalex.org/I154526488",
      "name": "Inserm",
      "country": "FR"
    }
  ]
}