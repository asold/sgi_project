{
  "title": "Large language models to identify social determinants of health in electronic health records",
  "url": "https://openalex.org/W4390745503",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2103090028",
      "name": "Marco Guevara",
      "affiliations": [
        "Harvard University",
        "Brigham and Women's Hospital",
        "Dana-Farber Cancer Institute",
        "Dana-Farber Brigham Cancer Center",
        "Mass General Brigham"
      ]
    },
    {
      "id": "https://openalex.org/A2102855736",
      "name": "Shan Chen",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Harvard University",
        "Brigham and Women's Hospital",
        "Mass General Brigham",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2186694405",
      "name": "Spencer Thomas",
      "affiliations": [
        "Dana-Farber Brigham Cancer Center",
        "Boston Children's Hospital",
        "Harvard University",
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2641497968",
      "name": "Tafadzwa L Chaunzwa",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Harvard University",
        "Dana-Farber Brigham Cancer Center",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2411270076",
      "name": "Idalid Franco",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Dana-Farber Cancer Institute",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2468120659",
      "name": "Benjamin H Kann",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Dana-Farber Brigham Cancer Center",
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A2008232954",
      "name": "Shalini Moningi",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Dana-Farber Brigham Cancer Center",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2639928473",
      "name": "Jack M. Qian",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Mass General Brigham",
        "Harvard University",
        "Dana-Farber Cancer Institute",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A3000373620",
      "name": "Madeleine Goldstein",
      "affiliations": [
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2127700518",
      "name": "Susan Harper",
      "affiliations": [
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A708860026",
      "name": "Hugo J.W.L. Aerts",
      "affiliations": [
        "Maastricht University",
        "Dana-Farber Brigham Cancer Center",
        "Brigham and Women's Hospital",
        "Mass General Brigham",
        "Dana-Farber Cancer Institute",
        "Harvard University"
      ]
    },
    {
      "id": "https://openalex.org/A1743932069",
      "name": "Paul J. Catalano",
      "affiliations": [
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2620900434",
      "name": "Guergana K. Savova",
      "affiliations": [
        "Harvard University",
        "Boston Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2486088239",
      "name": "Raymond H. Mak",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital",
        "Harvard University",
        "Dana-Farber Brigham Cancer Center",
        "Mass General Brigham"
      ]
    },
    {
      "id": "https://openalex.org/A2089952979",
      "name": "Danielle S Bitterman",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Harvard University",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2103090028",
      "name": "Marco Guevara",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital",
        "Harvard University",
        "Mass General Brigham",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2102855736",
      "name": "Shan Chen",
      "affiliations": [
        "Brigham and Women's Hospital",
        "Harvard University",
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2186694405",
      "name": "Spencer Thomas",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Harvard University",
        "Mass General Brigham",
        "Dana-Farber Brigham Cancer Center",
        "Brigham and Women's Hospital",
        "Boston Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2641497968",
      "name": "Tafadzwa L Chaunzwa",
      "affiliations": [
        "Mass General Brigham",
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital",
        "Harvard University",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2411270076",
      "name": "Idalid Franco",
      "affiliations": [
        "Dana-Farber Brigham Cancer Center",
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2468120659",
      "name": "Benjamin H Kann",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Dana-Farber Brigham Cancer Center",
        "Harvard University",
        "Brigham and Women's Hospital",
        "Mass General Brigham"
      ]
    },
    {
      "id": "https://openalex.org/A2008232954",
      "name": "Shalini Moningi",
      "affiliations": [
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital",
        "Dana-Farber Brigham Cancer Center"
      ]
    },
    {
      "id": "https://openalex.org/A2639928473",
      "name": "Jack M. Qian",
      "affiliations": [
        "Dana-Farber Brigham Cancer Center",
        "Dana-Farber Cancer Institute",
        "Brigham and Women's Hospital",
        "Harvard University",
        "Mass General Brigham"
      ]
    },
    {
      "id": "https://openalex.org/A3000373620",
      "name": "Madeleine Goldstein",
      "affiliations": [
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2127700518",
      "name": "Susan Harper",
      "affiliations": [
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A708860026",
      "name": "Hugo J.W.L. Aerts",
      "affiliations": [
        "Dana-Farber Brigham Cancer Center",
        "Mass General Brigham",
        "Harvard University",
        "Brigham and Women's Hospital",
        "Dana-Farber Cancer Institute",
        "Maastricht University"
      ]
    },
    {
      "id": "https://openalex.org/A1743932069",
      "name": "Paul J. Catalano",
      "affiliations": [
        "Dana-Farber/Harvard Cancer Center",
        "Dana-Farber Cancer Institute"
      ]
    },
    {
      "id": "https://openalex.org/A2620900434",
      "name": "Guergana K. Savova",
      "affiliations": [
        "Harvard University",
        "Boston Children's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2486088239",
      "name": "Raymond H. Mak",
      "affiliations": [
        "Dana-Farber Brigham Cancer Center",
        "Harvard University",
        "Dana-Farber Cancer Institute",
        "Mass General Brigham",
        "Brigham and Women's Hospital"
      ]
    },
    {
      "id": "https://openalex.org/A2089952979",
      "name": "Danielle S Bitterman",
      "affiliations": [
        "Harvard University",
        "Brigham and Women's Hospital",
        "Mass General Brigham",
        "Dana-Farber Brigham Cancer Center",
        "Dana-Farber Cancer Institute"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3159767223",
    "https://openalex.org/W2332787986",
    "https://openalex.org/W4376640318",
    "https://openalex.org/W2046583125",
    "https://openalex.org/W161831236",
    "https://openalex.org/W3095953401",
    "https://openalex.org/W2138884119",
    "https://openalex.org/W2005710312",
    "https://openalex.org/W1957062247",
    "https://openalex.org/W3085853817",
    "https://openalex.org/W4307593310",
    "https://openalex.org/W3200519641",
    "https://openalex.org/W2940494117",
    "https://openalex.org/W2729968666",
    "https://openalex.org/W2172943906",
    "https://openalex.org/W4206221224",
    "https://openalex.org/W4206760357",
    "https://openalex.org/W3009978733",
    "https://openalex.org/W3188301986",
    "https://openalex.org/W4367692366",
    "https://openalex.org/W3202375701",
    "https://openalex.org/W3169284847",
    "https://openalex.org/W4385335808",
    "https://openalex.org/W4384282814",
    "https://openalex.org/W4367318855",
    "https://openalex.org/W3178751578",
    "https://openalex.org/W3166254754",
    "https://openalex.org/W4385515870",
    "https://openalex.org/W4362679551",
    "https://openalex.org/W4385571470",
    "https://openalex.org/W4385564993",
    "https://openalex.org/W2962787423",
    "https://openalex.org/W2893425640",
    "https://openalex.org/W2595653137",
    "https://openalex.org/W2809705582",
    "https://openalex.org/W2941234853",
    "https://openalex.org/W4378418071",
    "https://openalex.org/W4321002059",
    "https://openalex.org/W4367042504",
    "https://openalex.org/W2947577769",
    "https://openalex.org/W2519078114",
    "https://openalex.org/W2991046162",
    "https://openalex.org/W3123287807",
    "https://openalex.org/W2596821164",
    "https://openalex.org/W2168825005",
    "https://openalex.org/W1975490452",
    "https://openalex.org/W2027365236",
    "https://openalex.org/W3196248941",
    "https://openalex.org/W6903655558",
    "https://openalex.org/W2396881363",
    "https://openalex.org/W2162800060",
    "https://openalex.org/W6847076894",
    "https://openalex.org/W6796581206",
    "https://openalex.org/W6959813887",
    "https://openalex.org/W4221004802",
    "https://openalex.org/W2259559558",
    "https://openalex.org/W2973951351",
    "https://openalex.org/W4226239563"
  ],
  "abstract": "Abstract Social determinants of health (SDoH) play a critical role in patient outcomes, yet their documentation is often missing or incomplete in the structured data of electronic health records (EHRs). Large language models (LLMs) could enable high-throughput extraction of SDoH from the EHR to support research and clinical care. However, class imbalance and data limitations present challenges for this sparsely documented yet critical information. Here, we investigated the optimal methods for using LLMs to extract six SDoH categories from narrative text in the EHR: employment, housing, transportation, parental status, relationship, and social support. The best-performing models were fine-tuned Flan-T5 XL for any SDoH mentions (macro-F1 0.71), and Flan-T5 XXL for adverse SDoH mentions (macro-F1 0.70). Adding LLM-generated synthetic data to training varied across models and architecture, but improved the performance of smaller Flan-T5 models (delta F1 + 0.12 to +0.23). Our best-fine-tuned models outperformed zero- and few-shot performance of ChatGPT-family models in the zero- and few-shot setting, except GPT4 with 10-shot prompting for adverse SDoH. Fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors were added to the text, suggesting less algorithmic bias ( p &lt; 0.05). Our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes captured 2.0%. These results demonstrate the potential of LLMs in improving real-world evidence on SDoH and assisting in identifying patients who could benefit from resource support.",
  "full_text": "ARTICLE OPEN\nLarge language models to identify social determinants of\nhealth in electronic health records\nMarco Guevara1,2,7, Shan Chen 1,2,7, Spencer Thomas1,2,3, Tafadzwa L. Chaunzwa1,2, Idalid Franco2, Benjamin H. Kann 1,2,\nShalini Moningi2, Jack M. Qian1,2, Madeleine Goldstein4, Susan Harper4, Hugo J. W. L. Aerts1,2,5, Paul J. Catalano6,\nGuergana K. Savova3, Raymond H. Mak1,2 and Danielle S. Bitterman1,2 ✉\nSocial determinants of health (SDoH) play a critical role in patient outcomes, yet their documentation is often missing or incomplete\nin the structured data of electronic health records (EHRs). Large language models (LLMs) could enable high-throughput extraction\nof SDoH from the EHR to support research and clinical care. However, class imbalance and data limitations present challenges for\nthis sparsely documented yet critical information. Here, we investigated the optimal methods for using LLMs to extract six SDoH\ncategories from narrative text in the EHR: employment, housing, transportation, parental status, relationship, and social support.\nThe best-performing models wereﬁne-tuned Flan-T5 XL for any SDoH mentions (macro-F1 0.71), and Flan-T5 XXL for adverse SDoH\nmentions (macro-F1 0.70). Adding LLM-generated synthetic data to training varied across models and architecture, but improved\nthe performance of smaller Flan-T5 models (delta F1+ 0.12 to +0.23). Our best-ﬁne-tuned models outperformed zero- and few-\nshot performance of ChatGPT-family models in the zero- and few-shot setting, except GPT4 with 10-shot prompting for adverse\nSDoH. Fine-tuned models were less likely than ChatGPT to change their prediction when race/ethnicity and gender descriptors\nwere added to the text, suggesting less algorithmic bias (p < 0.05). Our models identiﬁed 93.8% of patients with adverse SDoH,\nwhile ICD-10 codes captured 2.0%. These results demonstrate the potential of LLMs in improving real-world evidence on SDoH and\nassisting in identifying patients who could beneﬁt from resource support.\nnpj Digital Medicine            (2024) 7:6 ; https://doi.org/10.1038/s41746-023-00970-0\nINTRODUCTION\nHealth disparities have been extensively documented across\nmedical specialties\n1–3. However, our ability to address these\ndisparities remains limited due to an insufﬁcient understanding of\ntheir contributing factors. Social determinants of health (SDoH),\nare deﬁned by the World Health Organization as“the conditions in\nwhich people are born, grow, live, work, and age… shaped by the\ndistribution of money, power, and resources at global, national,\nand local levels”\n4. SDoH may be adverse or protective, impacting\nhealth outcomes at multiple levels as they likely play a major role\nin disparities by determining access to and quality of medical care.\nFor example, a patient cannot beneﬁt from an effective treatment\nif they don’t have transportation to make it to the clinic. There is\nalso emerging evidence that exposure to adverse SDoH may\ndirectly affect physical and mental health via inﬂammatory and\nneuro-endocrine changes\n5–8. In fact, SDoH are estimated to\naccount for 80 –90% of modi ﬁable factors impacting health\noutcomes9.\nSDoH are rarely documented comprehensively in structured\ndata in the electronic health records (EHRs) 10–12, creating an\nobstacle to research and clinical care. Instead, issues related to\nSDoH are most frequently described in the free text of clinic notes,\nwhich creates a bottleneck for incorporating these critical factors\ninto databases to research the full impact and drivers of SDoH,\nand for proactively identifying patients who may beneﬁt from\nadditional social work and resource support.\nNatural language processing (NLP) could address these\nchallenges by automating the abstraction of these data from\nclinical texts. Prior studies have demonstrated the feasibility of\nNLP for extracting a range of SDoH\n13–23. Yet, there remains a need\nto optimize performance for the high-stakes medical domain and\nto evaluate state-of-the-art language models (LMs) for this task. In\naddition to anticipated performance changes scaling with model\nsize, large LMs may support EHR mining via data augmentation.\nAcross medical domains, data augmentation can boost perfor-\nmance and alleviate domain transfer issues and so is an especially\npromising approach for the nearly ubiquitous challenge of data\nscarcity in clinical NLP24–26. The advanced capabilities of state-of-\nthe-art large LMs to generate coherent text open new avenues for\ndata augmentation through synthetic text generation. However,\nthe optimal methods for generating and utilizing such data\nremain uncertain. Large LM-generated synthetic data may also be\na means to distill knowledge represented in larger LMs to more\ncomputationally accessible smaller LMs27. In addition, few studies\nassess the potential bias of SDoH information extraction methods\nacross patient populations. LMs could contribute to the health\ninequity crisis if they perform differently in diverse populations\nand/or recapitulate societal prejudices28. Therefore, understanding\nbias is critical for future development and deployment decisions.\nHere, we characterize optimal methods, including the role of\nsynthetic clinical text, for SDoH extraction using large language\nmodels. Speciﬁcally, we develop models to extract six key SDoH:\nemployment status, housing issues, transportation issues, parental\n1Artiﬁcial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard Medical School, Boston, MA, USA.2Department of Radiation Oncology, Brigham and Women’s\nHospital/Dana-Farber Cancer Institute, Boston, MA, USA.3Computational Health Informatics Program, Boston Children’s Hospital, Harvard Medical School, Boston, MA, USA.\n4Adult Resource Ofﬁce, Dana-Farber Cancer Institute, Boston, MA, USA.5Radiology and Nuclear Medicine, GROW & CARIM, Maastricht University, Maastricht, The Netherlands.\n6Department of Data Science, Dana-Farber Cancer Institute and Department of Biostatistics, Harvard T. H. Chan School of Public Health, Boston, MA, USA. 7These authors\ncontributed equally: Marco Guevara, Shan Chen.✉email: Danielle_Bitterman@dfci.harvard.edu\nwww.nature.com/npjdigitalmed\nPublished in partnership with Seoul National University Bundang Hospital\n1234567890():,;\nstatus, and social support. We investigate the value of incorporat-\ning large LM-generated synthetic SDoH data during the ﬁne-\ntuning stage. We assess the performance of large LMs, including\nGPT3.5 and GPT4, in zero- and few-shot settings for identifying\nSDoH, and we explore the potential for algorithmic bias in LM\npredictions. Our methods could yield real-world evidence on\nSDoH, assist in identifying patients who could bene ﬁt from\nresource and social work support, and draw attention to the\nunder-documented impact of social factors on health outcomes.\nRESULTS\nModel performance\nTable 1 shows the performance of ﬁne-tuned models for both\nSDoH tasks on the radiotherapy test set. The best-performing\nmodel for any SDoH mention task was Flan-T5 XXL (3 out of 6\ncategories) using synthetic data (Macro-F1 0.71). The best-\nperforming model for the adverse SDoH mention task was Flan-\nT5 XL without synthetic data (Macro-F1 0.70). In general, the Flan-\nT5 models outperformed BERT, and model performance scaled\nwith size. However, although the Flan-T5 XL and XXL models were\nthe largest models evaluated in terms of total parameters because\nLoRA was used for theirﬁne-tuning, the fewest parameters were\ntuned for these models: 9.5 M and 18 M for Flan-TX XL and XXL,\nrespectively, compared to 110 M for BERT. The negative class\ngenerally had the best performance overall, followed by Relation-\nship and Employment. Performance varied quite a bit across the\nmodels for the other classes.\nFor both tasks, the best-performing models with synthetic data\naugmentation used sentences from both rounds of GPT3.5\nprompting. Synthetic data augmentation tended to lead to the\nlargest performance improvements for classes with few instances\nin the training dataset and for which the model trained on gold-\nonly data had very low performance (Housing, Parent, and\nTransportation).\nThe performance of the best-performing models for each task\non the immunotherapy and MIMIC-III datasets is shown in Table2.\nPerformance was similar in the immunotherapy dataset, which\nrepresents a separate but similar patient population treated at the\nsame hospital system. We observed a performance decrement in\nthe MIMIC-III dataset, representing a more dissimilar patient\npopulation from a different hospital system. Performance was\nsimilar between models developed with and without synthetic\ndata.\nAblation studies\nThe ablation studies showed a consistent deterioration in model\nperformance across all SDoH tasks and categories as the volume\nof real gold SDoH sentences progressively decreased, although\nmodels that included synthetic data maintained performance at\nhigher levels throughout and were less sensitive to decreases in\ngold data (Fig. 1, Supplementary Table 1). When synthetic data\nwere included in the training, performance was maintained until\n~50% of gold data were removed from the train set. Conversely,\nwithout synthetic data, performance dropped after about 10–20%\nof the gold data were removed from the train set, mimicking a\ntrue low-resource setting.\nError analysis\nThe leading discrepancies between ground truth and model\nprediction for each task are in Supplementary Table 2. Qualitative\nanalysis revealed 4 distinct error patterns: Human annotator error;\nfalse positives and false negatives for Relationship and Support\nlabels in the presence of any family mentions that did not\ncorrelate with the correct label; incorrect labels due to information\npresent in the note but external to the sentence and therefore not\naccessible to the model or that required implied/assumed\nknowledge; and incorrect labeling of a non-adverse SDoH as an\nadverse SDoH.\nChatGPT-family model performance\nWhen evaluating ourﬁne-tuned Flan-T5 models on the synthetic\ntest dataset against GPT-turbo-0613 and GPT4–0613, our model\nsurpassed the performance of the top-performing 10-shot\nlearning GPT model by a margin of Macro-F1 0.03 on any SDoH\ntask (p < 0.01), but fall shorts on adverse SDoH task (p < 0.01)\n(Table 3, Fig. 2).\nLanguage model bias evaluation\nBoth ﬁne-tuned Flan-T5 models and ChatGPT provided discrepant\nclassiﬁcation for synthetic sentence pairs with and without\ndemographic information injected (Fig. 3). However, the discre-\npancy rate of our ﬁne-tuned models was nearly half that of\nChatGPT: 14.3% vs. 21.5% of sentence pairs for any SDoH\n(P = 0.007) and 9.9% vs. 18.2% of sentence pairs for adverse\nSDoH (P = 0.005) for ﬁne-tuned Flan-T5 vs. ChatGPT, respectively.\nChatGPT was signiﬁcantly more likely to change its classiﬁcation\nwhen a female gender was injected compared to a male gender\nfor the Any SDoH task ( P = 0.01); no other within-model\ncomparisons were statistically signiﬁcant. Sentences gold-labeled\nas Support for both any SDoH and adverse SDoH mentions were\nmost likely to lead to discrepant predictions for ChatGPT (56.3%\n(27/48)) and (21.0% (9/29)), respectively). Employment gold-\nlabeled sentences were most likely to lead to discrepant\nprediction for any SDoH mention ﬁne-tuned model (14.4% (13/\n90)), and Transportation for adverse SDoH mention ﬁne-tuned\nmodel (12.2% (6/49)).\nComparison with structured EHR data\nOur best-performing models for any SDoH mention correctly\nidentiﬁed 95.7% (89/93) patients with at least one SDoH mention,\nand 93.8% (45/48) patients with at least one adverse SDoH\nmention (Supplementary Tables 3 and 4). SDoH entered as\nstructured Z-code in the EHR during the same timespan identiﬁed\n2.0% (1/48) with at least one adverse SDoH mention (all mapped\nZ-codes were adverse) (Supplementary Table 5). Supplementary\nFigs. 1 and 2 show that patient-level performance when using\nmodel predictions out-performed Z-codes by a factor of at least 3\nfor every label for each task (Macro-F1 0.78 vs. 0.17 for any SDoH\nmention and 0.71 vs. 0.17 for adverse SDoH mention).\nDISCUSSION\nWe developed multilabel classiﬁers to identify the presence of 6\ndifferent SDoH documented in clinical notes, demonstrating the\npotential of large LMs to improve the collection of real-world data\non SDoH and support the appropriate allocation of resources\nsupport to patients who need it most. We identi ﬁed a\nperformance gap between a more traditional BERT classiﬁer and\nlarger Flan-T5 XL and XXL models. Our ﬁne-tuned models\noutperformed ChatGPT-family models with zero- and few-shot\nlearning for most SDoH classes and were less sensitive to the\ninjection of demographic descriptors. Compared to diagnostic\ncodes entered as structured data, text-extracted data identiﬁed\n91.8% more patients with an adverse SDoH. We also contribute\nnew annotation guidelines as well as synthetic SDoH datasets to\nthe research community.\nAll of our models performed well at identifying sentences that\ndo not contain SDoH mentions (F1≥ 0.99 for all). For any SDoH\nmentions, performance was worst for parental status and\ntransportation issues. For adverse SDoH mentions, performance\nwas worst for parental status and social support. Theseﬁndings\nM. Guevara et al.\n2\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\n1234567890():,;\nTable 1. Model performance on the in-domain RT test dataset.\nAny social determinant of health (SDoH)\nModel Parameters (total/tuned) Macro-F1 No SDoH\n(F1)\nEmployment\n(F1)\nHousing\n(F1)\nParent\n(F1)\nRelationship\n(F1)\nSocial support\n(F1)\nTransportation\n(F1)\nMean (95% CI)a Delta F1b P value\nBERT-base 110 M/110 M\nGold data only 0.53 (0.46 –0.59) −0.06 <0.01 1.00 0.72 0.00 0.00 0.96 0.59 0.50\nGold + synthetic data 0.47 (0.44 –0.52) 1.00 0.62 0.00 0.29 0.93 0.49 0.00\nFlan-T5-base 250 M/250 M\nGold data only 0.36 (0.34 –0.39) +0.13 <0.01 0.99 0.34 0.00 0.00 0.83 0.38 0.00\nGold + synthetic data 0.49 (0.40 –0.60) 1.00 0.67 0.37 0.00 0.93 0.28 0.25\nFlan-T5-large 780 M/780 M\nGold data only 0.42 (0.40 –0.45) +0.18 <0.01 1.00 0.72 0.00 0.00 0.93 0.31 0.00\nGold + synthetic data 0.60 (0.50 –0.68) 1.00 0.76 0.67 0.24 0.91 0.48 0.18\nFlan-T5 XL 3B/9.5 M\nGold data only 0.65 (0.54 –0.73) +0.03 <0.01 0.99 0.71 0.57 0.55 0.92 0.50 0.31\nGold + synthetic data 0.68 (0.59 –0.76) 1.00 0.73 0.55 0.56 0.94 0.52 0.53\nFlan-T5 XXL 11B/18 M\nGold data only 0.65 (0.56 –0.75) +0.05 <0.01 1.00 0.76 0.33 0.65 0.95 0.51 0.44\nGold + synthetic data 0.70 (0.60–0.77) 1.00 0.80 0.67 0.47 0.93 0.60 0.47\nAdverse Social Determinants of Health (SDoH)\nModel Parameters (total/tuned) Macro-F1 No SDoH\n(F1)\nEmployment\n(F1)\nHousing\n(F1)\nParent\n(F1)\nRelationship\n(F1)\nSocial support\n(F1)\nTransportation\n(F1)\nMean (95% CI) Delta F1 P value\nBERT-base 110 M/110 M\nGold data only 0.64 (0.55 –0.73) −0.09 <0.01 1.00 0.68 0.67 0.31 0.90 0.37 0.60\nGold + synthetic data 0.55 (0.45 –0.67) 1.00 0.75 0.37 0.36 0.78 0.38 0.4\nFlan-T5-base 250 M/250 M\nGold data only 0.24 (0.18 –0.31) +0.11 <0.01 1.00 0.00 0.00 0.00 0.43 0.00 0.25\nGold + synthetic data 0.35 (0.26 –0.45) 1.00 0.30 0.33 0.00 0.56 0.00 0.25\nFlan-T5-large 780 M/780 M\nGold data only 0.27 (0.23 –0.31) +0.22 <0.01 0.99 0.46 0.00 0.00 0.47 0.00 0.00\nGold + synthetic data 0.49 (0.40 –0.59) 1.00 0.58 0.54 0.33 0.66 0.22 0.17\nFlan-T5 XL 3B/9.5 M\nGold data only 0.69 (0.57–0.78) 0.00 0.53 1.00 0.76 0.57 0.52 0.93 0.44 0.67\nGold + synthetic data 0.69 (0.57–0.77) 1.00 0.72 0.67 0.49 0.87 0.56 0.57\nFlan-T5 XXL 11B/18 M\nGold data only 0.63 (0.52 –0.72) +0.03 <0.01 1.00 0.67 0.50 0.60 0.91 0.31 0.45\nGold + synthetic data 0.66 (0.55 –0.74) 1.00 0.62 0.60 0.55 0.89 0.53 0.46\nThe 95% CI for Macro-F1 is calculated by bootstrapping 3400 times (to achieve bootstrap SE < 0.01) with replacement. The SE of the 95% conﬁdence interval limits is 0.0091, ascertained by performing\nbootstrapping 3,400 times on three distinct samples. Delta F1 score is the change in Macro-F1 when synthetic data are added to theﬁne-tuning data. Bolded text indicates the best performance with and\nwithout synthetic data augmentation.p values are computed with Mann–Whitney U test. CI conﬁdence interval, SE standard error.\nM. Guevara et al.\n3\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \nTable 2. Results of the best-performing models on the out-of-domain test datasets.\nAny social determinant of health (SDoH)\nDataset Macro-F1 No SDoH\n(F1)\nEmployment\n(F1)\nHousing\n(F1)\nParent\n(F1)\nRelationship\n(F1)\nSocial support\n(F1)\nTransportation\n(F1)\nMean (95% CI) Delta F1 P value\nImmunotherapy\nFlanXXL: Gold data only 0.70 (0.63 –0.76) +0.01 <0.01 0.99 0.83 0.55 0.69 0.93 0.46 0.46\nFlanXXL: Gold + synthetic data 0.71 (0.64 –0.76) 0.99 0.79 0.55 0.68 0.91 0.63 0.40\nMIMIC-III\nFlanXXL: Gold data only 0.57 (0.49 –0.63) −0.02 <0.01 0.98 0.65 0.00 0.63 0.91 0.32 0.50\nFlanXXL: Gold + synthetic data 0.55 (0.49 –0.61) 0.98 0.69 0.24 0.44 0.91 0.33 0.24\nAdverse social determinants of health (SDoH)\nDataset Macro-F1 No SDoH\n(F1)\nEmployment\n(F1)\nHousing\n(F1)\nParent\n(F1)\nRelationship\n(F1)\nSocial support\n(F1)\nTransportation\n(F1)\nMean (95% CI)a Delta F1b P value\nImmunotherapy\nFlanXL: Gold data only 0.63 (0.54 –0.72) +0.03 <0.01 1.00 0.56 0.46 0.68 0.81 0.50 0.46\nFlanXL: Gold + synthetic data 0.66 (0.58 –0.72) 1.00 0.60 0.63 0.60 0.81 0.59 0.40\nMIMIC-III\nFLANXL: Gold data only 0.53 (0.47 –0.60) −0.02 <0.01 0.99 0.51 0.50 0.53 0.65 0.22 0.20\nFLANXL: Gold + synthetic data 0.51 (0.43 –0.59) 0.99 0.55 0.35 0.54 0.68 0.43 0.20\nThe 95% CI for Macro-F1 is calculated by bootstrapping 3400 times (to achieve bootstrap SE < 0.01) with replacement. The SE of the 95% conﬁdence interval limits is 0.0074, ascertained by performing\nbootstrapping 3400 times on three distinct samples. Delta F1 score is the change in Macro-F1 when synthetic data are added to theﬁne-tuning data. Bolded text indicates the best performance with and\nwithout synthetic data augmentation.p values are computed with Mann–Whitney U test. CI conﬁdence interval, SE standard error.\nM. Guevara et al.\n4\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\nare unsurprising given the marked class imbalance for all SDoH\nlabels— only 3% of sentences in our training set contained any\nSDoH mention. Given this imbalance, our models ’ ability to\nidentify sentences that contain SDoH language is impressive. In\naddition, these SDoH descriptions are semantically and linguisti-\ncally complex. In particular, sentences describing social support\nare highly variable, given the variety of ways individuals can\nreceive support from their social systems during care. Interest-\ningly, our best-performing models demonstrated strong perfor-\nmance in classifying housing issues (Macro-F1 0.67), which was\nour scarcest label with only 20 instances in the training dataset.\nThis speaks to the potential of large LMs in improved real-world\ndata collection for very sparsely documented information, which is\nthe most likely to be missed via manual review.\nThe recent advancements in large LMs have opened a pathway\nfor synthetic text generation that may improve model perfor-\nmance via data augmentation and enable experiments that better\nprotect patient privacy\n29. This is an emerging area of research that\nfalls within a larger body of work on synthetic patient data across\na range of data types and end-uses\n30,31. Our study is among the\nﬁrst to evaluate the role of contemporary generative large LMs for\nsynthetic clinical text to help unlock the value of unstructured\ndata within the EHR. We were particularly interested in synthetic\nclinical data as a means to address the aforementioned scarcity of\nSDoH documentation, and ourﬁndings may provide generalizable\ninsights for the common clinical NLP challenge of class imbalance\n— many clinically important data are difﬁcult to identify among\nthe huge amounts of text in a patient’s EHR. We found variable\nbeneﬁts of synthetic data augmentation across model architecture\nand size; the strategy was most beneﬁcial for the smaller Flan-T5\nmodels and for the rarest classes where performance was dismal\nusing gold data alone. Importantly, the ablation studies demon-\nstrated that only approximately half of the gold-labeled dataset\nwas needed to maintain performance when synthetic data was\nincluded in training, although synthetic data alone did not\nproduce high-quality models. Of note, we aimed to understand\nwhether synthetic data for augmentation could be automatically\ngenerated using ChatGPT-family models without additional\nhuman annotation, and so it is possible that manual gold-\nlabeling could further enhance the value of these data. However,\nthis would decrease the value of synthetic data in terms of\nreducing annotation effort.\nOur novel approach to generating synthetic clinical sentences\nalso enabled us to explore the potential for ChatGPT-family\nmodels, GPT3.5 and GPT4, for supporting the collection of SDoH\ninformation from the EHR. We found thatﬁne-tuning LMs that are\nFig. 1 Ablation studies.Performance in Macro-F1 of Flan-T5 XL modelsﬁne-tuned using gold data only (orange line) and gold and synthetic\ndata (green line), as gold-labeled sentences are gradually reduced by undersample value from the training dataset for thea adverse social\ndeterminant of health (SDoH) mention task andb any SDoH mention task. The full gold-labeled training set is comprised of 29,869 sentences,\naugmented with 1800 synthetic SDoH sentences, and tested on the in-domain RT test dataset. SDoH Social determinants of health.\nM. Guevara et al.\n5\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \nTable 3. Model performance on synthetic test data.\nAny social determinant of health (SDoH)\nModel parameters Mean Macro-F1 (95% CI) Employment (F1) Housing (F1) Parent (F1) Relationship (F1) Social support (F1) Transportation (F1)\nFT Flan-T5 XXL 11B 0.92 (0.62–0.95) 0.92 0.91 0.63 0.95 0.77 0.93\nGPT3.5 175B\nZero-shot 0.84 (0.48 –0.95) 0.94 0.87 0.85 0.82 0.49 0.84\n10-shot 0.82 (0.60 –0.90) 0.89 0.89 0.76 0.79 0.61 0.85\nGPT4 Unknown\nZero-shot 0.85 (0.48 –0.94) 0.94 0.83 0.72 0.88 0.49 0.86\n10-shot 0.88 (0.58 –0.93) 0.91 0.90 0.96 0.82 0.59 0.91\nAdverse social determinants of health (SDoH)\nModel parameters Mean Macro-F1 (95% CI) a Employment (F1) Housing (F1) Parent (F1) Relationship(F1) Social support (F1) Transportation (F1)\nFT Flan-T5 XL 3B 0.86 (0.65 –0.98) 0.86 0.86 0.65 0.98 0.84 0.86\nGPT3.5 175B\nZero-shot 0.82 (0.51 –0.95) 0.77 0.93 0.87 0.72 0.52 0.94\n10-shot 0.81 (0.50 –0.94) 0.93 0.83 0.78 0.70 0.50 0.93\nGPT4 Unknown\nZero-shot 0.84 (0.52 –0.94) 0.79 0.94 0.94 0.78 0.53 0.89\n10-shot 0.90 (0.71–0.96) 0.92 0.91 0.90 0.73 0.73 0.96\nThe 95% CI (conﬁdence interval) for Macro-F1 is calculated by bootstrapping 10000 times (to achieve bootstrap SE < 0.01) with replacement. The SE of the 95% conﬁdence interval limits is 0.0038, ascertained by\nperforming bootstrapping 10,000 times on three distinct samples. Bolded text indicates the best performance.FT ﬁne-tuned, CI conﬁdence interval, SE standard error.\nM. Guevara et al.\n6\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\norders of magnitude smaller than ChatGPT-family models, even\nwith our relatively small dataset, generally out-performed zero-\nshot and few-shot learning with ChatGPT-family models,\nconsistent with prior work evaluating large LMs for clinical\nuses\n32–34. Nevertheless, these models showed promising perfor-\nmance given that they were not explicitly trained for clinical tasks,\nwith the caveat that it is hard to make deﬁnite conclusions based\non synthetic data. Additional prompt engineering could improve\nthe performance of ChatGPT-family models, such as developing\nprompts that provide details of the annotation guidelines as done\nby Ramachandran et al.\n34. This is an area for future study,\nespecially once these models can be readily used with real clinical\ndata. With additional prompt engineering and model reﬁnement,\nperformance of these models could improve in the future and\nprovide a promising avenue to extract SDoH while reducing the\nhuman effort needed to label training datasets.\nIt is well-documented that LMs learn the biases, prejudices, and\nracism present in the language they are trained on\n35–38. Thus, it is\nessential to evaluate how LMs could propagate existing biases,\nwhich in clinical settings could amplify the health disparities\ncrisis\n1–3. We were especially concerned that SDoH-containing\nlanguage may be particularly prone to eliciting these biases. Both\nour ﬁne-tuned models and ChatGPT altered their SDoH classiﬁca-\ntion predictions when demographics and gender descriptors were\ninjected into sentences, although the ﬁne-tuned models were\nsigniﬁcantly more robust than ChatGPT. Although not signiﬁcantly\ndifferent, it is worth noting that for both theﬁne-tuned models\nand ChatGPT, Hispanic and Black descriptors were most likely to\nchange the classi ﬁcation for any SDoH and adverse SDoH\nmentions, respectively. This lack of signiﬁcance may be due to\nthe small numbers in this evaluation, and future work is critically\nFig. 2 Fine-tuned LLMs versus ChatGPT-family models.Compar-\nison of model performance between ourﬁne-tuned Flan-T5 models\nagainst zero- and 10-shot GPT. Macro-F1 was measured using our\nmanually validated synthetic dataset. The GPT-turbo-0613 version of\nGPT3.5 and the GPT4–0613 version of GPT4 were used. Error bars\nindicate the 95% conﬁdence intervals. LLM large language model.\nFig. 3 LLM bias evaluation. The proportion of synthetic sentence pairs with and without demographics injected led to a classiﬁcation\nmismatch, meaning that the model predicted a different SDoH label for each sentence in the pair. Results are shown across race/ethnicity and\ngender fora any SDoH mention task andb adverse SDoH mention task. Asterisks indicate statistical signiﬁcance (P ≤ 0.05) chi-squared tests for\nmulti-class comparisons and 2-proportionz tests for binary comparisons. LLM large language model, SDoH Social determinants of health.\nM. Guevara et al.\n7\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \nneeded to further evaluate bias in clinical LMs. We have made our\npaired demographic-injected sentences openly available for future\nefforts on LM bias evaluation.\nSDoH are notoriously under-documented in existing EHR\nstructured data 10–12,39. Our ﬁndings that text-extracted SDoH\ninformation was better able to identify patients with adverse\nSDoH than relevant billing codes are in agreement with prior work\nshowing under-utilization of Z-codes10,11. Most EMR systems have\nother ways to enter SDoH information as structured data, which\nmay have more complete documentation, however, these did not\nexist for most of our target SDoH. Lyberger et al. evaluated other\nEHR sources of structured SDoH data and similarly found that NLP\nmethods are a complementary source SDoH information extrac-\ntion and were able to identify 10–30% of patients with tobacco,\nalcohol, and homelessness risk factors documented only in\nunstructured text\n22.\nThere have been several prior studies developing NLP methods\nto extract SDoH from the EHR13–21,40. The most common SDoH\ntargeted in prior efforts include smoking history, substance use,\nalcohol use, and homelessness\n23. In addition, many prior efforts\nfocus only on text in the Social History section of notes. In a recent\nshared task on alcohol, drug, tobacco, employment, and living\nsituation event extraction from Social History sections, pre-trained\nLMs similarly provided the best performance\n41. Using this dataset,\none study found that sequence-to-sequence approaches out-\nperformed classiﬁcation approaches, in line with ourﬁndings42.I n\naddition to our technical innovations, our work adds to prior\nefforts by investigating SDoH which are less commonly targeted\nfor extraction but nonetheless have been shown to impact\nhealthcare\n43–51. We also developed methods that can mine\ninformation from full clinic notes, not only from Social History\nsections— a fundamentally more challenging task with a much\nlarger class imbalance. Clinically-impactful SDoH information is\noften scattered throughout other note sections, and many note\ntypes, such as many inpatient progress notes and notes written by\nnurses and social workers, do not consistently contain Social\nHistory sections.\nOur study has limitations. First, our training and out-of-domain\ndatasets come from a predominantly white population treated at\nhospitals in Boston, Massachusetts, in the United States of\nAmerica. This limits the generalizability of ourﬁndings. We could\nnot exhaustively assess the many methods to generate synthetic\ndata from ChatGPT. Instead, we chose to investigate prompting\nmethods that could be easily reproduced by others and did not\nrequire extensive task-speciﬁc optimization, as this is likely not\nfeasible for the many clinical NLP tasks for one may wish to\ngenerate synthetic data on. Incorporating real clinical examples in\nthe prompt may improve the quality of the synthetic data and is\nan area of future research when large generative LMs become\nmore widely available for use with protected health information\nand within the resource constraints of academic researchers and\nhealthcare systems. Because we could not evaluate ChatGPT-\nfamily models using protected health information, our evaluations\nare limited to manually-veriﬁed synthetic sentences. Thus, our\nreported performance may not completely re ﬂect true perfor-\nmance on real clinical text. Because the synthetic sentences were\ngenerated using ChatGPT itself, and ChatGPT presumably has not\nbeen trained on clinical text, we hypothesize that, if anything,\nperformance would be worse on real clinical data. Finally, our\nmodels can only be as good as the annotated corpus. SDoH\nannotation is challenging due to its conceptually complex nature,\nespecially for the Support tag, and labeling may also be subject to\nannotator bias\n52, all of which may impact ultimate performance.\nOur ﬁndings highlight the potential of large LMs to improve\nreal-world data collection and identiﬁcation of SDoH from the\nEHR. In addition, synthetic clinical text generated by large LMs\nmay enable better identiﬁcation of rare events documented in the\nEHR, although more work is needed to optimize generation\nmethods. Our ﬁne-tuned models were less prone to bias than\nChatGPT-family models and outperformed for most SDoH classes,\nespecially any SDoH mentions, despite being orders of magnitude\nsmaller. In the future, these models could improve our under-\nstanding of drivers of health disparities by improving real-world\nevidence and could directly support patient care by ﬂagging\npatients who may beneﬁt most from proactive resource and social\nwork referral.\nMETHODS\nData\nTable 4 describes the patient populations of the datasets used in\nthis study. Gender and race/ethnicity data and descriptors were\ncollected from the EHR. These are generally collected either\ndirectly from the patient at registration, or by a provider, but the\nmode of collection for each data point was not available. Our\nprimary dataset consisted of a corpus of 800 clinic notes from 770\npatients with cancer who received radiotherapy (RT) at the\nDepartment of Radiation Oncology at Brigham and Women ’s\nHospital/Dana-Farber Cancer Institute in Boston, Massachusetts,\nfrom 2015 to 2022. We also created two out-of-domain test\ndatasets. First, we collected 200 clinic notes from 170 patients with\ncancer treated with immunotherapy at Dana-Farber Cancer, and\nnot present in the RT dataset. Second, we collected 200 notes\nfrom 183 patients in the MIMIC (Medical Information Mart for\nIntensive Care)-III database\n53–55, which includes data associated\nwith patients admitted to the critical care units at Beth Israel\nDeaconess Medical Center in Boston, Massachusetts from 2001 to\n2008. This study was approved by the Mass General Brigham\ninstitutional review board, and consent was waived as this was\ndeemed exempt from human subjects research.\nOnly notes written by physicians, physician assistants, nurse\npractitioners, registered nurses, and social workers were included.\nTo maintain a minimum threshold of information, we excluded\nnotes with fewer than 150 tokens across all provider types. This\nhelped ensure that the selected notes contained sufﬁcient textual\ncontent. For notes written by all providers save social workers, we\nexcluded notes containing any section longer than 500 tokens to\navoid excessively lengthy sections that might have included less\nrelevant or redundant information. For physician, physician\nassistant, and nurse practitioner notes, we used a customized\nmedSpacy\n56,57 sectionizer to include only notes that contained at\nleast one of the following sections: Assessment and Plan, Social\nHistory, and History/Subjective.\nIn addition, for the RT dataset, we established a date range,\nconsidering notes within a window of 30 days before the ﬁrst\ntreatment and 90 days after the last treatment. Additionally, in the\nﬁfth round of annotation, we speciﬁcally excluded notes from\npatients with zero social work notes. This decision ensured that we\nfocused on individuals who had received social work intervention\nor had pertinent social context documented in their notes. For the\nimmunotherapy dataset, we ensured that there was no patient\noverlap between RT and immunotherapy notes. We also\nspeciﬁcally selected notes from patients with at least one social\nwork note. To further reﬁne the selection, we considered notes\nwith a note date one month before or after the patient’s ﬁrst social\nwork note after it. For the MIMIC-III dataset, only notes written by\nphysicians, social workers, and nurses were included for analysis.\nWe focused on patients who had at least one social work note,\nwithout any speciﬁc date range criteria.\nPrior to annotation, all notes were segmented into sentences\nusing the syntok\n58 sentence segmenter as well as split into bullet\npoints “”. This method was used for all notes in the radiotherapy,\nimmunotherapy, and MIMIC datasets for sentence-level annota-\ntion and subsequent classiﬁcation.\nM. Guevara et al.\n8\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\nTask deﬁnition and data labeling\nWe deﬁned our label schema and classi ﬁcation tasks by ﬁrst\ncarrying out interviews with subject matter experts, including\nsocial workers, resource specialists, and oncologists, to determine\nSDoH that are clinically relevant but not readily available as\nstructured data in the EHR, especially as dynamic features over\ntime. After initial interviews, a set of exploratory pilot annotations\nwas conducted on a subset of clinical notes and preliminary\nannotation guidelines were developed. The guidelines were then\niteratively reﬁned andﬁnalized based on the pilot annotations and\nadditional input from subject matter experts. The following SDoH\ncategories and their attributes were selected for inclusion in the\nproject: Employment status (employed, unemployed, underem-\nployed, retired, disability, student), Housing issue (ﬁnancial status,\nundomiciled, other), Transportation issue (distance, resource,\nother), Parental status (if the patient has a child under 18 years\nold), Relationship (married, partnered, widowed, divorced, single),\nand Social support (presence or absence of social support).\nWe deﬁned two multilabel sentence-level classiﬁcation tasks:\n1. Any SDoH mentions: The presence of language describing\nan SDoH category as de ﬁned above, regardless of the\nattribute.\n2. Adverse SDoH mentions: The presence or absence of\nlanguage describing an SDoH category with an attribute\nthat could create an additional social work or resource\nsupport need for patients:\n● Employment status: unemployed, underemployed, disability\n● Housing issue: ﬁnancial status, undomiciled, other\n● Transportation issue: distance, resources, other\n● Parental status: having a child under 18 years old\n● Relationship: widowed, divorced, single\n● Social support: absence of social support\nAfter ﬁnalizing the annotation guidelines, two annotators\nmanually annotated the RT corpus. In total, ten thousand one\nhundred clinical notes were annotated line-by-line using the\nannotation software Multi-document Annotation Environment\n(MAE v2.2.13)\n59. A total of 300/800 (37.5%) of the notes underwent\ndual annotation by two data scientists across four rounds. After\neach round, the data scientists and an oncologist performed\ndiscussion-based adjudication. Before adjudication, dually anno-\ntated notes had a Krippendorf’s alpha agreement of 0.86 and\nCohen’s Kappa of 0.86 for any SDoH mention categories. For\nadverse SDoH mentions, notes had a Krippendorf ’s alpha\nagreement of 0.76 and Cohen’s Kappa of 0.76. Detailed agreement\nmetrics are in Supplementary Tables 6 and 7. A single annotator\nthen annotated the remaining radiotherapy notes, the immu-\nnotherapy dataset, and the MIMIC-III dataset. Table5 describes the\ndistribution of labels across the datasets.\nThe annotation/adjudication team was composed of one board-\ncertiﬁed radiation oncologist who completed a postdoctoral\nfellowship in clinical natural language processing, a Master’s-level\ncomputational linguist with a Bachelor’s degree in linguistics and\n1-year prior experience working speciﬁcally with clinical text, and\na Master’s student in computational linguistics with a Bachelor’s\ndegree in linguistics. The radiation oncologist and Master’s level\ncomputational linguist led the development of the annotation\nguidelines, and trained the Master’s student in SDoH annotation\nover a period of 1 month via review of the annotation guidelines\nand iterative review of pilot annotations. During adjudication, if\nthere was still ambiguity, we discussed with the two Resource\nSpecialists on the research team to provide input in adjudication.\nData augmentation\nWe employed synthetic data generation methods to assess the\nimpact of data augmentation for the positive class, and also to\nenable an exploratory evaluation of proprietary large LMs that\ncould not be downloaded locally and thus cannot be used with\nprotected health information. In round 1, GPT-turbo-\n0301(ChatGPT) version of GPT3.5 via the OpenAI\n60 API was\nprompted to generate new sentences for each SDoH category,\nusing sentences from the annotation guidelines as references. In\nround 2, in order to generate more linguistic diversity, the sample\nTable 4. Patient demographics across datasets.\nPatients Radiotherapy (in-domain) dataset Out-of-domain validation datasets\nTotal\n(n = 770)\nTrain Set\n(n = 462)\nDevelopment set\n(n = 154)\nTest set\n(n = 154)\nImmunotherapy\n(n =170)\nMIMIC-III\n(n = 183)\nSynthetic\nValidated\n(n = 480)\nSynthetic\nDemo\n(n =419)\nGender\nMale 344 (44.7%) 210 (45.5%) 70 (45.5%) 64 (41.6%) 75 (44.1%) 101 (55.2%) N/A 168 (40.1%)\nFemale 426 (55.3%) 252 (54.5%) 84 (54.5%) 90 (58.4%) 95 (55.9%) 82 (44.8%) N/A 177 (42.2%)\nNot speciﬁed 0 0 0 0 0 0 N/A 74 (17.7%)\nRace\nWhite 664 (86.2%) 396 (85.7%) 134 (87.0%) 134 (87.0%) 137 (80.6%) 132 (72.1%) N/A 113 (26.9%)\nAsian 21 (2.7%) 11 (2.4%) 6 (3.9%) 4 (2.6%) 9 (5.3%) 5 (2.7%) N/A 106 (21.6%)\nBlack 37 (4.8%) 24 (5.2%) 5 (3.2%) 8 (5.2%) 11 (6.5%) 16 (8.7%) N/A 84 (25.7%)\nTwo or more 3 (0.4%) 2 (0.4%) 0 1 (0.6%) 0 3 (1.6%) N/A 0\nOthers 25 (3.2%) 17 (3.7%) 5 (3.2%) 3 (1.9%) 10 (5.9%) 1 (0.6%) N/A 97 (23.2%)\nUnknown 20 (2.6%) 12 (2.6%) 4 (2.6%) 4 (2.6%) 3 (1.8%) 25 (13.7%) N/A 19 (4.5%)\nEthnicity\nNon-Hispanic 682 (88.6%) 420 (90.9%) 130 (84.4%) 132 (85.7%) 160 (94.1%) 158 (86.3%) N/A 322 (76.8%)\nHispanic 11 (1.4%) 8 (1.7%) 2 (1.3%) 1 (0.6%) 20 (5.9%) 11 (6.0%) N/A 97 (23.2%)\nUnknown 77 (10.0%) 34 (7.4%) 22 (14.3%) 21 (13.6%) 0 14 (7.7%) N/A 0\nAll data presented asn (%) unless otherwise noted. Synthetic Validated are the sentences used to evaluate GPT models, thus, there is no demographic\ninformation for this dataset. Synthetic Demo is the sentence used for bias evaluation, where demographic descriptors were inserted.N/A not applicable.\nM. Guevara et al.\n9\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \nsynthetic sentences output from round 1 were taken as references\nto generate another set of synthetic sentences. One-hundred\nsentences per category were generated in each round. Supple-\nmentary Table 8 shows the prompts for each sentence label type.\nSynthetic test set generation\nIteration 1 for generating SDoH sentences involved prompting the\n538 synthetic sentences to be manually validated to evaluate\nChatGPT, which cannot be used with protected health informa-\ntion. Of these, after human review only 480 were found to have\nany SDoH mention, and 289 to have an adverse SDoH mention\n(Table 5). For all synthetic data generation methods, no real\npatient data were used in prompt development orﬁne-tuning.\nModel development\nThe radiotherapy corpus was split into a 60%/20%/20% distribu-\ntion for training, development, and testing respectively. The entire\nimmunotherapy and MIMIC-III corpora were held-out for out-of-\ndomain tests and were not used during model development.\nThe experimental phase of this study focused on investigating\nthe effectiveness of different machine learning models and data\nsettings for the classiﬁcation of SDoH. We explored one multilabel\nBERT model as a baseline, namely bert-base-uncased\n61, as well as\na range of Flan-T5 models62,63 including Flan-T5 base, large, XL,\nand XXL; where XL and XXL used a parameter efﬁcient tuning\nmethod (low-rank adaptation (LoRA)64). Binary cross-entropy loss\nwith logits was used for BERT, and cross-entropy loss for the Flan-\nT5 models. Given the large class imbalance, non-SDoH sentences\nwere undersampled during training. We assessed the impact of\nadding synthetic data on model performance. Details on model\nhyper-parameters are in Supplementary Methods.\nFor sequence-to-sequence models, input consisted of the input\nsentence with “summarize” appended in front, and the target\nlabel (when used during training) was the text span of the label\nfrom the target vocabulary. Because the output did not always\nexactly correspond to the target vocabulary, we post-processed\nthe model output, which was a simple split function on“,” and\ndictionary mapping from observed miss-generation e.g.,“RELAT →\nRELATIONSHIP”. Examples of this label resolution are in Supple-\nmentary Methods.\nAblation studies\nAblation studies were carried out to understand the impact of\nmanually labeled training data quantity on performance when\nsynthetic SDoH data is included in the training dataset. First,\nTable 5. Distribution of documents and sentence labels in each dataset.\nNumber of documents\nRadiotherapy Immunotherapy MIMIC-III Synthetic validated Synthetic demo\nTrain set Development set Test set\nDocuments 481 160 159 200 200 N/A N/A\nNumber of sentences–any SDoH mentions\nRadiotherapy Immunotherapy\n(n = 14,761)\nMIMIC-III\n(n = 5328)\nSynthetic\nvalidated\n(n = 480)\nSynthetic\ndemo (n = 419)\nLabel Train set\n(n = 29,869)\nDevelopment set\n(n = 10,712)\nTest set\n(n = 10,860)\nNo SDoH 28992 (97.1%) 10429 (97.4%) 10582 (97.4%) 14319 (97.0%) 4968 (93.2%) N/A N/A\nEmployment 218 (0.7%) 65 (0.6%) 64 (0.6%) 103 (0.7%) 70 (1.3%) 136 (28.3%) 132 (31.5%)\nHousing 20 (0.1%) 7 (0.1%) 4 (0.0%) 13 (0.1%) 3 (0.1%) 69 (14.4%) 64 (15.3%)\nParent 53 (0.2%) 24 (0.2%) 22 (0.2%) 30 (0.2%) 27 (0.5%) 67 (14.0%) 43 (10.3%)\nRelationship 464 (1.6%) 153 (1.4%) 158 (1.5%) 241 (1.6%) 180 (3.4%) 152 (31.7%) 134 (32.0%)\nSocial Support 234 (0.8%) 51 (0.5%) 61 (0.6%) 86 (0.6%) 122 (2.3%) 102 (21.3%) 90 (21.5%)\nTransportation 41 (0.1%) 13 (0.1%) 6 (0.1%) 25 (0.2%) 3 (0.1%) 61 (12.7%) 58 (13.8%)\nNumber of sentences–adverse SDoH mentions\nRadiotherapy Immunotherapy\n(n =14,761)\nMIMIC-III\n(n = 5328)\nSynthetic\nvalidated\n(n = 289)\nSynthetic\ndemo\n(n =253)Label Train Set\n(n = 29,869)\nDevelopment set\n(n = 10,712)\nTest set\n(n = 10,860)\nNo Adverse SDoH 29550 (98.9%) 10615 (99.1%) 10761 (99.1%) 14621 (99.1%) 5213 (97.8%) N/A N/A\nEmployment 93 (0.3%) 23 (0.2%) 30 (0.3%) 37 (0.3%) 39 (0.7%) 40 (13.8%) 39 (15.4%)\nHousing 20 (0.1%) 7 (0.1%) 4 (0.0%) 13 (0.1%) 3 (0.1%) 69 (23.9%) 64 (25.3%)\nParent 53 (0.2%) 24 (0.2%) 22 (0.2%) 30 (0.2%) 27 (0.5%) 67 (23.2%) 43 (17.0%)\nRelationship 86 (0.3%) 27 (0.3%) 31 (0.3%) 30 (0.2%) 23 (0.4%) 68 (23.5%) 62 (24.5%)\nSocial support 54 (0.2%) 8 (0.1%) 12 (0.1%) 12 (0.1%) 27 (0.5%) 39 (13.5%) 43 (17.0%)\nTransportation 41 (0.1%) 13 (0.1%) 6 (0.1%) 25 (0.2%) 3 (0.1%) 61 (21.1%) 58 (22.9%)\nAll data presented asn (%) unless otherwise noted. Synthetic Validated are the sentences used to evaluate GPT models, thus, there is no demographic\ninformation for this dataset. Synthetic Demo is the sentence used for bias evaluation, where demographic descriptors were inserted. Labels sum to >100%\nbecause some sentences had more than 1 SDoH label.SDoH social determinants of health,N/A not applicable.\nM. Guevara et al.\n10\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\nmodels were trained using 10%, 25%, 40%, 50%, 70%, 75%, and\n90% of manually labeled sentences; both SDoH and non-SDoH\nsentences were reduced at the same rate. The evaluation was on\nthe RT test set.\nEvaluation\nDuring training andﬁne-tuning, we evaluated all models using the\nRT development set and assessed theirﬁnal performance using\nbootstrap sampling of the held-out RT test set. Bootstrap sample\nnumber and size were calculated to achieve a precision level for\nthe standard error of macro F1 of ±0.01. The mean and 95%\nconﬁdence intervals from the bootstrap samples were calculated\nfrom the resulting bootstrap samples. We also sampled to ensure\nthat our standard error on the 95% conﬁdence interval limits was\n<0.01 as follows: Our selected bootstrap sample size matched the\ntest data size, sampling with replacement. We then computed the\n5th and 95th percentile values for each of the calculated k\nsamples from the resulting distributions. The standard deviation of\nthese percentile values was subsequently determined to establish\nthe precision of the conﬁdence interval limits. Examples of the\nbootstrap sampling calculations are in Supplementary Methods.\nFor each classi ﬁcation task, we calculated precision/positive\npredictive value, recall/sensitivity, and F1 (harmonic mean of recall\nand precision) as follows:\n● Precision = TP/(TP + FP)\n● Recall = TP/(TP + FN)\n● F1 = (2*Precision*Recall)/(Precision+Recall)\n● TP = true positives, FP= false positives, FN= false negatives\nManual error analysis was conducted on the radiotherapy\ndataset using the best-performing model.\nChatGPT-family model evaluation\nTo evaluate ChatGPT, the Scikit-LLM 65 multilabel zero-shot\nclassiﬁer and few-shot binary classiﬁer were adapted to form a\nmultilabel zero- and few-shot classi ﬁer (Fig. 4). A subset of\n480 synthetic sentences whose labels were manually validated,\nwere used for testing. Test sentences were inserted into the\nfollowing prompt template, which instructs ChatGPT to act as a\nmultilabel classiﬁer model, and to label the sentences accordingly:\nYou will be provided with the following information:\n1. An arbitrary text sample. The sample is delimited with triple backticks.\n2. List of categories the text sample can be assigned to. The list is delimited with\nsquare brackets. The categories in the list are enclosed in the single quotes and\ncomma separated.\n3. Examples of text samples and their assigned categories. The examples are\ndelimited with triple backticks. The assigned categories are enclosed in a list-like\nstructure. These examples are to be used as training data.\nPerform the following tasks:\n1. Identify to which category the provided text belongs to with the highest\nprobability.\n2. Assign the provided text to that category.\n3. Provide your response in a JSON format containing a single key `label` and a\nvalue corresponding to the assigned category. Do not provide any additional\ninformation except the JSON.\nList of categories: {labels}\nTraining data:\n{training_data}\nText sample: ```Childcare provider offers after-school tutoring services helping child\nstay on track academically while parent undergoes treatment```\nYour JSON response:\n===========================================================\nPARENT\nPrompt Example =>   One/Few-Shot\n[Context and instruction]\n[Input]\n[Responses]\nFig. 4 Prompting methods. Example of prompt templates used in the SKLLM package for GPT-turbo-0301 (GPT3.5) and GPT4 with\ntemperature 0 to classify our labeled synthetic data. {labels} and {training_data} were sampled from a separate synthetic dataset, which was\nnot human-annotated. Theﬁnal label output is highlighted in green.\nM. Guevara et al.\n11\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \n“Sample input: [TEXT]\nSample target: [LABELS]”\n[TEXT] was the exemplar from the development/\nexemplar set.\n[LABELS] was a comma-separated list of the labels for that\nexemplar, e.g. PARENT,RELATIONSHIP.\nOf note, because we were unable to generate high-quality\nsynthetic non-SDoH sentences, these classiﬁers did not include a\nnegative class. We evaluated the most current ChatGPT model freely\navailable at the time of this work, GPT-turbo-0613, as well as\nGPT4–0613, via the OpenAI API with temperature 0 for reproducibility.\nLanguage model bias evaluation\nIn order to test for bias in our best-performing models and in large\nLMs pre-trained on general text, we used GPT4 to insert demographic\ndescriptors into our synthetic data, as illustrated in Fig.5.G P T 4w a s\nsupplied with our synthetically generated test sentences, and\nprompted to insert demographi c information into them. For\nexample, a sentence starting with“Widower admits fears surrounding\npotential judgment…” might become “Hispanic widower admits\nfears surrounding potential judgment…” . The prompt was as follows\n(in a batch of 10 ensure demographic variations):\n“role”: “user”, “content”: “[ORIGINAL SENTENCE]\\n swap the\nsentences patients above to one of the race/ethnicity\n[Asian, Black, white, Hispanic] and gender, and put the\nmodiﬁed race and gender in bracket at the beginning like\nthis \\n Owner operator food truck selling gourmet grilled\ncheese sandwiches around town=> \\n [Asian female] Asian\nwoman owner operator of a food truck selling gourmet\ngrilled cheese sandwiches around town”\n[ORIGINAL SENTENCE] was a sentence from a selected\nsubset of our GPT3.5-generated synthetic data\nThese sentences were then manually validated; 419 had any\nSDoH mention, and 253 had an adverse SDoH mention.\nComparison with structured EHR data\nTo assess the completeness of SDoH documentation in structured\nversus unstructured EHR data, we collected Z-codes for all patients\nin our test set. Z-codes are SDoH-related ICD-10-CM diagnostic\ncodes, mapped most closely with our SDoH categories present as\nstructured data for the radiotherapy dataset (Supplementary Table\n9). Text-extracted patient-level SDoH information was deﬁned as\nthe presence of one or more labels in any note. We compared\nthese patient-level labels to structured Z-codes entered in the EHR\nduring the same time frame.\nStatistical analysis\nMacro-F1 performance for each model type was compared when\ndeveloped with or without synthetic data and for the ChatGPT-\nfamily model comparisons using the Mann–Whitney U test. The\nrate of discrepant SDoH classi ﬁcations with and without the\ninjection of demographic information was compared between the\nbest-performing ﬁne-tuned models and ChatGPT using chi-\nsquared tests for multi-class comparisons and 2-proportionz tests\nfor binary comparisons. A two-sided P ≤ 0.05 was considered\nstatistically signi\nﬁcant. Statistical analyses were carried out using\nthe statistical Python package in scipy (Scipy.org). Python version\n3.9.16 (Python Software Foundation) was used to carry out\nthis work.\nDATA AVAILABILITY\nThe RT and immunotherapy datasets cannot be shared for the privacy of the\nindividuals whose data were used in this study. All synthetic datasets used in this\nstudy are available at:https://github.com/AIM-Harvard/SDoH. The annotated MIMIC-\nIII dataset is available after completion of a data use agreement at:https://doi.org/\n10.13026/6149-mb25\n66. The demographic-injected paired sentence dataset is\navailable at: https://huggingface.co/datasets/m720/SHADR 67.\nFig. 5 Demographic-injected SDoH language development.Illustration of generating and comparing synthetic demographic-injected SDoH\nlanguage pairs to assess how adding race/ethnicity and gender information into a sentence may impact model performance. FTﬁne-tuned,\nSDoH Social determinants of health.\nM. Guevara et al.\n12\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital\nCODE AVAILABILITY\nThe ﬁnal annotation guidelines and all synthetic datasets used in this study are\navailable at: https://github.com/AIM-Harvard/SDoH.\nReceived: 14 August 2023; Accepted: 15 November 2023;\nREFERENCES\n1. Lavizzo-Mourey, R. J., Besser, R. E. & Williams, D. R. Understanding and mitigating\nhealth inequities - past, current, and future directions. N. Engl. J. Med 384,\n1681–1684 (2021).\n2. Chetty, R. et al. The association between income and life expectancy in the\nUnited States, 2001-2014.JAMA 315, 1750–1766 (2016).\n3. Caraballo, C. et al. Excess mortality and years of potential life lost among the\nblack population in the US, 1999-2020.JAMA 329, 1662–1670 (2023).\n4. Social determinants of health. http://www.who.int/social_determinants/\nsdh_deﬁnition/en/.\n5. Franke, H. A. Toxic stress: effects, prevention and treatment.Children 1, 390–402\n(2014).\n6. Nelson, C. A. et al. Adversity in childhood is linked to mental and physical health\nthroughout life. BMJ 371, m3048 (2020).\n7. Shonkoff, J. P. & Garner, A. S. Committee on psychosocial aspects of child and\nfamily health, committee on early childhood, adoption, and dependent care &\nsection on developmental and behavioral pediatrics. the lifelong effects of early\nchildhood adversity and toxic stress.Pediatrics 129, e232–e246 (2012).\n8. Turner-Cobb, J. M., Sephton, S. E., Koopman, C., Blake-Mortimer, J. & Spiegel, D.\nSocial support and salivary cortisol in women with metastatic breast cancer.\nPsychosom. Med. 62, 337–345 (2000).\n9. Hood, C. M., Gennuso, K. P., Swain, G. R. & Catlin, B. B. County health rankings:\nrelationships between determinant factors and health outcomes.Am. J. Prev. Med\n50, 129–135 (2016).\n10. Truong, H. P. et al. Utilization of social determinants of health ICD-10 Z-codes\namong hospitalized patients in the United States, 2016-2017. Med. Care 58,\n1037–1043 (2020).\n11. Heidari, E., Zalmai, R., Richards, K., Sakthisivabalan, L. & Brown, C. Z-code doc-\numentation to identify social determinants of health among medicaid bene-\nﬁciaries. Res. Soc. Adm. Pharm.19, 180–183 (2023).\n12. Wang, M., Pantell, M. S., Gottlieb, L. M. & Adler-Milstein, J. Documentation and\nreview of social determinants of health data in the EHR: measures and associated\ninsights. J. Am. Med. Inform. Assoc.28, 2608–2616 (2021).\n13. Conway, M. et al. Moonstone: a novel natural language processing system for\ninferring social risk from clinical narratives.J. Biomed. Semant.10,1 –10 (2019).\n14. Bejan, C. A. et al. Mining 100 million notes toﬁnd homelessness and adverse\nchildhood experiences: 2 case studies of rare and severe social determinants of\nhealth in electronic health records.J. Am. Med. Inform. Assoc.25,6 1–71 (2017).\n15. Topaz, M., Murga, L., Bar-Bachar, O., Cato, K. & Collins, S. Extracting alcohol and\nsubstance abuse status from clinical notes: the added value of nursing data.Stud.\nHealth Technol. Inform.264, 1056–1060 (2019).\n16. Gundlapalli, A. V. et al. Using natural language processing on the free text of\nclinical documents to screen for evidence of homelessness among US veterans.\nAMIA Annu. Symp. Proc.2013, 537–546 (2013).\n17. Hammond, K. W., Ben-Ari, A. Y., Laundry, R. J., Boyko, E. J. & Samore, M. H. The\nfeasibility of using large-scale text mining to detect adverse childhood experi-\nences in a VA-treated population.J. Trauma. Stress28, 505–514 (2015).\n18. Han, S. et al. Classifying social determinants of health from unstructured elec-\ntronic health records using deep learning-based natural language processing.J.\nBiomed. Inform. 127, 103984 (2022).\n19. Rouillard, C. J., Nasser, M. A., Hu, H. & Roblin, D. W. Evaluation of a natural\nlanguage processing approach to identify social determinants of health in\nelectronic health records in a diverse community cohort.Med. Care 60, 248–255\n(2022).\n20. Feller, D. J. et al. Detecting social and behavioral determinants of health with\nstructured and free-text clinical data.Appl. Clin. Inform.11, 172–181 (2020).\n21. Yu, Z. et al. A study of social and behavioral determinants of health in lung cancer\npatients using transformers-based natural language processing models. AMIA\nAnnu. Symp. Proc.2021, 1225–1233 (2021).\n22. Lybarger, K. et al. Leveraging natural language processing to augment structured\nsocial determinants of health data in the electronic health record.J. Am. Med.\nInform. Assoc. 30, 1389–1397 (2023).\n23. Patra, B. G. et al. Extracting social determinants of health from electronic health\nrecords using natural language processing: a systematic review. J. Am. Med.\nInform. Assoc. 28, 2716–2727 (2021).\n24. Xu, D., Chen, S. & Miller, T. BCH-NLP at BioCreative VII Track 3: medications\ndetection in tweets using transformer networks and multi-task learning. Preprint\nat https://arxiv.org/abs/2111.13726 (2021).\n25. Chen, S. et al. Natural language processing to automatically extract the presence\nand severity of esophagitis in notes of patients undergoing radiotherapy.JCO\nClin. Cancer Inf.7, e2300048 (2023).\n26. Tan, R. S. Y. C. et al. Inferring cancer disease response fromradiology reports using\nlarge language models with data augmentation and prompting.J. Am. Med Inf.\nAssoc. 30, 1657–1664 (2023).\n27. Jung, J. et al. Impossible distillation: from low-quality model to high-quality\ndataset & model for summarization and paraphrasing. Preprint at https://\narxiv.org/pdf/2305.16635.pdf (2023).\n28. Lett, E. & La Cava, W. G. Translating intersectionality to fair machine learning in\nhealth sciences. Nat. Mach. Intell.5, 476–479 (2023).\n29. Li, J. et al. Are synthetic clinical notes useful for real natural language processing\ntasks: a case study on clinical entity recognition.J. Am. Med. Inform. Assoc.28,\n2193–2201 (2021).\n30. Chen, R. J., Lu, M. Y., Chen, T. Y., Williamson, D. F. K. & Mahmood, F. Synthetic data\nin machine learning for medicine and healthcare.Nat. Biomed. Eng. 5, 493–497\n(2021).\n31. Jacobs, F. et al. Opportunities and challenges of synthetic data generation in\noncology. JCO Clin. Cancer Inf.7, e2300045 (2023).\n32. Chen, S. et al. Evaluation of ChatGPT family of models for biomedical reasoning\nand classiﬁcation. Preprint athttps://arxiv.org/abs/2304.02496 (2023).\n33. Lehman, E. et al. Do we still need clinical language models? arXiv https://\narxiv.org/abs/2302.08091 (2023).\n34. Ramachandran, G. K. et al. Prompt-based extraction of social determinants of\nhealth using few-shot learning.In: Proceedings of the 5th Clinical Natural Lan-\nguage Processing Workshop, 385–393 (Association for Computational Linguistics,\n2023).\n35. Feng, S., Park, C. Y., Liu, Y. & Tsvetkov, Y. From pretraining data to language\nmodels to downstream tasks: tracking the trails of political biases leading to\nunfair NLP models.In: Proceedings of the 61st Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: LongPapers) 11737–11762 (Association\nfor Computational Linguistics, 2023).\n36. Zhao, J., Wang, T., Yatskar, M., Ordonez, V. & Chang, K.-W. Men also like shopping:\nreducing gender bias ampliﬁcation using corpus-level constraints. In: Proceed-\nings of the 2017 Conference on Empirical Methods in Natural Language Pro-\ncessing 2979–2989 (Association for Computational Linguistics, 2017).\n37. Caliskan, A., Bryson, J. J. & Narayanan, A. Semantics derived automatically from\nlanguage corpora contain human-like biases.Science 356, 183–186 (2017).\n38. Davidson, T., Warmsley, D., Macy, M. & Weber, I. Automated hate speech\ndetection and the problem of offensive language. InProceedings of the Eleventh\nInternational AAAI Conference on Web and Social Media.512–515 (Association for\nthe Advancement of Artiﬁcial Intelligence, 2017).\n39. Kharrazi, H. et al. The value of unstructured electronic health record data in\ng e r i a t r i cs y n d r o m ec a s ei d e n t iﬁcation. J. Am. Geriatr. Soc. 66,1 4 9 9–1507\n(2018).\n40. Derton, A. et al. Natural language processing methods to empirically explore\nsocial contexts and needs in cancer patient notes. JCO Clin. Cancer Inf. 7,\ne2200196 (2023).\n41. Lybarger, K., Yetisgen, M. & Uzuner, Ö. The 2022 n2c2/UW shared task on\nextracting social determinants of health.J. Am. Med. Inform. Assoc.30, 1367–1378\n(2023).\n42. Romanowski, B., Ben Abacha, A. & Fan, Y. Extracting social determinants of health\nfrom clinical note text with classiﬁcation and sequence-to-sequence approaches.\nJ. Am. Med. Inform. Assoc.30\n, 1448–1455 (2023).\n43. Hatef, E. et al. Assessing the availability of data on social and behavioral\ndeterminants in structured and unstructured electronic health records: a ret-\nrospective analysis of a multilevel health care system.JMIR Med. Inf.7, e13802\n(2019).\n44. Greenwald, J. L., Cronin, P. R., Carballo, V., Danaei, G. & Choy, G. A novel model for\npredicting rehospitalization risk incorporating physical function, cognitive status,\nand psychosocial support using natural language processing. Med. Care 55,\n261–266 (2017).\n45. Blosnich, J. R. et al. Social determinants and military veterans’ suicide ideation\nand attempt: a cross-sectional analysis of electronic health record data.J. Gen.\nIntern. Med. 35, 1759–1767 (2020).\n46. Wray, C. M. et al. Examining the interfacility variation of social determinants of\nhealth in the veterans health administration.Fed. Pract. 38,1 5–19 (2021).\n47. Wang, L. et al. Disease trajectories and end-of-life care for dementias: latent topic\nmodeling and trend analysis using clinical notes.AMIA Annu. Symp. Proc.2018,\n1056–1065 (2018).\n48. Navathe, A. S. et al. Hospital readmission and social risk factors identiﬁed from\nphysician notes. Health Serv. Res.53, 1110–1136 (2018).\nM. Guevara et al.\n13\nPublished in partnership with Seoul National University Bundang Hospital npj Digital Medicine (2024)     6 \n49. Kroenke, C. H., Kubzansky, L. D., Schernhammer, E. S., Holmes, M. D. & Kawachi, I.\nSocial networks, social support, and survival after breast cancer diagnosis.J. Clin.\nOncol. 24, 1105–1111 (2006).\n50. Maunsell, E., Brisson, J. & Deschênes, L. Social support and survival among\nwomen with breast cancer.Cancer 76, 631–637 (1995).\n51. Schulz, R. & Beach, S. R. Caregiving as a risk factor for mortality: the Caregiver\nhealth effects study.JAMA 282, 2215–2219 (1999).\n52. Hovy, D. & Prabhumoye, S. Five sources of bias in natural language processing.\nLang. Linguist. Compass15, e12432 (2021).\n53. Johnson, A., Pollard, T. & Mark, R. MIMIC-III Clin. database https://doi.org/\n10.13026/C2XW26 (2023).\n54. Johnson, A. E. W. et al. MIMIC-III, a freely accessible critical care database.Sci. Data\n3, 160035 (2016).\n55. Goldberger, A. et al. PhysioBank, PhysioToolkit, and PhysioNet: Components of a new\nresearch resource for complex physiologic signals.Circulation101,e 2 1 5–e220 (2000).\n56. Eyre, H. et al. Launching into clinical space with medspaCy: a new clinical text\nprocessing toolkit in Python.AMIA Annu. Symp. Proc.2021, 438–447 (2021).\n57. MedspaCy · spaCy universe. medspaCyhttps://spacy.io/universe/project/medspacy.\n58. Leitner, F. syntok: Text tokenization and sentence segmentation (segtok v2).\n(Github).\n59. Multi-document annotation environment. MAE https://keighrim.github.io/mae-\nannotation/.\n60. OpenAI API. http://platform.openai.com.\n61. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: pre-training of deep\nbidirectional transformers for language understanding. In: Proceedings of the\n2019 Conference of the North American Chapter of the Association for Com-\nputational Linguistics: Human Language Technologies, Vol. 1 (Long and Short\nPapers) 4171–4186 (Association for Computational Linguistics, 2019).\n62. Chung, H. W. et al. Scaling instruction-ﬁnetuned language models. Preprint at\nhttps://arxiv.org/abs/2210.11416 (2022).\n63. Longpre, S. et al. Theﬂan collection: designing data and methods for effective\ninstruction tuning. arXiv https://arxiv.org/abs/2301.13688 (2023).\n64. Hu, E. J. et al. LoRA: Low-Rank Adaptation of Large Language Models.Interna-\ntional Conference on Learning Representations(2022).\n65. Kondrashchenko, I. scikit-llm: seamlessly integrate powerful language models like\nChatGPT into scikit-learn for enhanced text analysis tasks. (Github).\n66. Guevara, M. et al. Annotation dataset of social determinants of health from\nMIMIC-III Clinical Care Database.Physionet, 1.0.0, https://doi.org/10.13026/6149-\nmb25 (2023).\n67. Guevara, M. et al. SDoH Human Annotated Demographic Robustness (SHADR)\nDataset. Huggingface, 2308.06354 (2023).\nACKNOWLEDGEMENTS\nThe authors acknowledge the following funding sources: D.S.B.: Woods Foundation,\nJay Harris Junior Faculty Award, Joint Center for Radiation Therapy Foundation. T.L.C.:\nRadiation Oncology Institute, Conquer Cancer Foundation, Radiological Society of\nNorth America. I.F.: Diversity Supplement (NIH-3R01CA240582-01A1S1), NIH/NCI LRP,\nNRG Oncology Health Equity ASTRO/RTOG Fellow, CDA BWH Center for Diversity and\nInclusion. G.K.S.: R01LM013486 from the National Library of Medicine, National\nInstitute of Health. R.H.M.: National Institute of Health, ViewRay, H.A.: (H.A.: NIH-USA\nU24CA194354, NIH-USA U01CA190234, NIH-USA U01CA209414, and NIH-USA\nR35CA22052), and the European Union - European Research Council (H.A.: 866504).\nS.C., M.G., B.K., H.A., G.K.S., H.A., and D.S.B.: NIH-USA U54CA274516-01A1.\nAUTHOR CONTRIBUTIONS\nM.G. and S.C.: conceptualization, data curation, formal analysis, investigation,\nmethodology, visualization, writing— original draft, writing— review & editing. S.T.:\ndata curation, formal analysis, investigation, methodology. T.L.C., I.F., B.H.K., S.M.,\nJ.M.Q.: data curation, investigation, writing— review & editing. M.G. and S.H.: data\ncuration, methodology. H.J.W.L.A.: funding acquisition, writing— review & editing.\nP.J.C., G.K.S., and R.H.M.: conceptualization, investigation, methodology, writing—\nreview & editing. D.S.B.: funding acquisition, conceptualization, data curation, formal\nanalysis, investigation, methodology, supervision, writing— original draft, writing—\nreview & editing.\nCOMPETING INTERESTS\nM.G., S.C., S.T., T.L.C., I.F., B.H.K., S.M., J.M.Q., M.G., S.H.: none. H.J.W.L.A.: advisory and\nconsulting, unrelated to this work (Onc.AI, Love Health Inc, Sphera, Editas, A.Z., and\nBMS). P.J.C. and G.K.S.: None. R.H.M.: advisory board (ViewRay, AstraZeneca),\nConsulting (Varian Medical Systems, Sio Capital Management), Honorarium (Novartis,\nSpringer Nature). D.S.B.: Associate Editor of Radiation Oncology, HemOnc.org (no\nﬁnancial compensation, unrelated to this work); funding from American Association\nfor Cancer Research (unrelated to this work).\nADDITIONAL INFORMATION\nSupplementary information The online version contains supplementary material\navailable at https://doi.org/10.1038/s41746-023-00970-0.\nCorrespondence and requests for materials should be addressed to Danielle S.\nBitterman.\nReprints and permission information is available at http://www.nature.com/\nreprints\nPublisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims\nin published maps and institutional afﬁliations.\nOpen Access This article is licensed under a Creative Commons\nAttribution 4.0 International License, which permits use, sharing,\nadaptation, distribution and reproduction in any medium or format, as long as you give\nappropriate credit to the original author(s) and the source, provide a link to the Creative\nCommons license, and indicate if changes were made. The images or other third party\nmaterial in this article are included in the article’s Creative Commons license, unless\nindicated otherwise in a credit line to the material. If material is not included in the\narticle’s Creative Commons license and your intended use is not permitted by statutory\nregulation or exceeds the permitted use, you will need to obtain permission directly\nfrom the copyright holder. To view a copy of this license, visit http://\ncreativecommons.org/licenses/by/4.0/.\n© The Author(s) 2024\nM. Guevara et al.\n14\nnpj Digital Medicine (2024)     6 Published in partnership with Seoul National University Bundang Hospital",
  "topic": "Social determinants of health",
  "concepts": [
    {
      "name": "Social determinants of health",
      "score": 0.5307213068008423
    },
    {
      "name": "Health care",
      "score": 0.3828640580177307
    },
    {
      "name": "Medicine",
      "score": 0.3488028347492218
    },
    {
      "name": "Political science",
      "score": 0.28750771284103394
    },
    {
      "name": "Law",
      "score": 0.10691490769386292
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I136199984",
      "name": "Harvard University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I48633490",
      "name": "Mass General Brigham",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1283280774",
      "name": "Brigham and Women's Hospital",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210161994",
      "name": "Dana-Farber Brigham Cancer Center",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I4210117453",
      "name": "Dana-Farber Cancer Institute",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I1288882113",
      "name": "Boston Children's Hospital",
      "country": "US"
    }
  ],
  "cited_by": 191
}