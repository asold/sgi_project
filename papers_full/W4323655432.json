{
  "title": "Object Detection Based on Swin Deformable Transformer‐BiPAFPN‐YOLOX",
  "url": "https://openalex.org/W4323655432",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5046985719",
      "name": "Peicheng Shi",
      "affiliations": [
        "Anhui Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5044931100",
      "name": "Xinhe Chen",
      "affiliations": [
        "Anhui Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5009721481",
      "name": "Heng Qi",
      "affiliations": [
        "Anhui Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5100641479",
      "name": "Chenghui Zhang",
      "affiliations": [
        "Anhui Polytechnic University"
      ]
    },
    {
      "id": "https://openalex.org/A5100415093",
      "name": "Zhi-Qiang Liu",
      "affiliations": [
        "Anhui Polytechnic University"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W3042011474",
    "https://openalex.org/W6739901393",
    "https://openalex.org/W3096609285",
    "https://openalex.org/W3189898414",
    "https://openalex.org/W3143320354",
    "https://openalex.org/W4313007769",
    "https://openalex.org/W3175515048",
    "https://openalex.org/W3139633126",
    "https://openalex.org/W3131500599",
    "https://openalex.org/W4312960790",
    "https://openalex.org/W3138516171",
    "https://openalex.org/W4312349930",
    "https://openalex.org/W2601564443",
    "https://openalex.org/W2966926453",
    "https://openalex.org/W2963857746",
    "https://openalex.org/W3034971973",
    "https://openalex.org/W2163605009",
    "https://openalex.org/W3203160579",
    "https://openalex.org/W2549139847",
    "https://openalex.org/W2982083293",
    "https://openalex.org/W3089728331",
    "https://openalex.org/W4214493665",
    "https://openalex.org/W3134144764",
    "https://openalex.org/W3209970085",
    "https://openalex.org/W3157528469",
    "https://openalex.org/W2565639579",
    "https://openalex.org/W2964444661",
    "https://openalex.org/W2613718673",
    "https://openalex.org/W2570343428",
    "https://openalex.org/W3035694605",
    "https://openalex.org/W6639102338",
    "https://openalex.org/W2964121718",
    "https://openalex.org/W2982220924",
    "https://openalex.org/W3035253074",
    "https://openalex.org/W3211783547",
    "https://openalex.org/W639708223",
    "https://openalex.org/W1861492603",
    "https://openalex.org/W4385245566",
    "https://openalex.org/W3169064633"
  ],
  "abstract": "Object detection technology plays a crucial role in people’s everyday lives, as well as enterprise production and modern national defense. Most current object detection networks, such as YOLOX, employ convolutional neural networks instead of a Transformer as a backbone. However, these techniques lack a global understanding of the images and may lose meaningful information, such as the precise location of the most active feature detector. Recently, a Transformer with larger receptive fields showed superior performance to corresponding convolutional neural networks in computer vision tasks. The Transformer splits the image into patches and subsequently feeds them to the Transformer in a sequence structure similar to word embeddings. This makes it capable of global modeling of entire images and implies global understanding of images. However, simply using a Transformer with a larger receptive field raises several concerns. For example, self‐attention in the Swin Transformer backbone will limit its ability to model long range relations, resulting in poor feature extraction results and low convergence speed during training. To address the above problems, first, we propose an important region‐based Reconstructed Deformable Self‐Attention that shifts attention to important regions for efficient global modeling. Second, based on the Reconstructed Deformable Self‐Attention, we propose the Swin Deformable Transformer backbone, which improves the feature extraction ability and convergence speed. Finally, based on the Swin Deformable Transformer backbone, we propose a novel object detection network, namely, Swin Deformable Transformer‐BiPAFPN‐YOLOX. experimental results on the COCO dataset show that the training period is reduced by 55.4%, average precision is increased by 2.4%, average precision of small objects is increased by 3.7%, and inference speed is increased by 35%.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.7139807343482971
    },
    {
      "name": "Transformer",
      "score": 0.6782928109169006
    },
    {
      "name": "Artificial intelligence",
      "score": 0.6153154373168945
    },
    {
      "name": "Convolutional neural network",
      "score": 0.5399314165115356
    },
    {
      "name": "Object detection",
      "score": 0.5020749568939209
    },
    {
      "name": "Feature extraction",
      "score": 0.455351859331131
    },
    {
      "name": "Computer vision",
      "score": 0.4457660913467407
    },
    {
      "name": "Pattern recognition (psychology)",
      "score": 0.4175727367401123
    },
    {
      "name": "Detector",
      "score": 0.4119637906551361
    },
    {
      "name": "Receptive field",
      "score": 0.4108502268791199
    },
    {
      "name": "Voltage",
      "score": 0.23225775361061096
    },
    {
      "name": "Engineering",
      "score": 0.09409323334693909
    },
    {
      "name": "Telecommunications",
      "score": 0.07755464315414429
    },
    {
      "name": "Electrical engineering",
      "score": 0.07115915417671204
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I70908550",
      "name": "Anhui Polytechnic University",
      "country": "CN"
    }
  ]
}