{
  "title": "Gct-TTE: graph convolutional transformer for travel time estimation",
  "url": "https://openalex.org/W4390838367",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A5092120643",
      "name": "Vladimir Mashurov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093714406",
      "name": "Vaagn Chopuryan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3205668944",
      "name": "Vadim Porvatov",
      "affiliations": [
        "National University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A3054296491",
      "name": "Arseny Ivanov",
      "affiliations": [
        "National University of Science and Technology"
      ]
    },
    {
      "id": "https://openalex.org/A2148996337",
      "name": "Natalia Semenova",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5092120643",
      "name": "Vladimir Mashurov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A5093714406",
      "name": "Vaagn Chopuryan",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3205668944",
      "name": "Vadim Porvatov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A3054296491",
      "name": "Arseny Ivanov",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2148996337",
      "name": "Natalia Semenova",
      "affiliations": [
        "State Research Institute of Mechanical Engineering"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2962917186",
    "https://openalex.org/W3009498923",
    "https://openalex.org/W2057824474",
    "https://openalex.org/W2803470206",
    "https://openalex.org/W2749954505",
    "https://openalex.org/W4206333838",
    "https://openalex.org/W3119912786",
    "https://openalex.org/W3194259208",
    "https://openalex.org/W2956452632",
    "https://openalex.org/W4298238646",
    "https://openalex.org/W3207377464",
    "https://openalex.org/W74439177",
    "https://openalex.org/W2972581457",
    "https://openalex.org/W2962834725",
    "https://openalex.org/W3161839639",
    "https://openalex.org/W2809128166",
    "https://openalex.org/W2475334473",
    "https://openalex.org/W2064675550",
    "https://openalex.org/W2788997482",
    "https://openalex.org/W2965832807",
    "https://openalex.org/W1888005072",
    "https://openalex.org/W4360982396",
    "https://openalex.org/W3098944285",
    "https://openalex.org/W3200786095",
    "https://openalex.org/W3034429256",
    "https://openalex.org/W4221167446",
    "https://openalex.org/W2602856279",
    "https://openalex.org/W2612690371",
    "https://openalex.org/W3106295757"
  ],
  "abstract": "Abstract This paper introduces a new transformer-based model for the problem of travel time estimation. The key feature of the proposed GCT-TTE architecture is the utilization of different data modalities capturing different properties of an input path. Along with the extensive study regarding the model configuration, we implemented and evaluated a sufficient number of actual baselines for path-aware and path-blind settings. The conducted computational experiments have confirmed the viability of our pipeline, which outperformed state-of-the-art models on both considered datasets. Additionally, GCT-TTE was deployed as a web service accessible for further experiments with user-defined routes.",
  "full_text": "Gct‑TTE: graph convolutional transformer \nfor travel time estimation\nVladimir Mashurov1†, Vaagn Chopuryan1†, Vadim Porvatov1,2†, Arseny Ivanov2 and Natalia Semenova1,3* \nIntroduction\nTravel time estimation (TTE) is an actively developing branch of computational logistics \nthat considers the prediction of potential time expenditures for specific types of trips \n[1, 2]. With the recent growth of urban environment complexity, such algorithms have \nbecome highly demanded both in commercial services and general traffic management \n[3]. Following this line, better TTE decreases logistic costs for different kinds of delivery \n[4], improves end-user experience for taxi services [5], and ensures the quality of \nadaptive traffic control [6].\nDespite the applied significance of travel time estimation, it still remains a challenging \ntask in the case of ground vehicles. This situation arises from the influence of different \npatterns of road network topology, nonlinear traffic dynamics, changing weather \nconditions, and other types of unexpected temporal events. The majority of the currently \nestablished algorithms [7, 8] tend to utilize specific data modalities in order to capture \ncomplex spatio-temporal dependencies influencing the traffic flow. With the recent \nsuccess of multimodal approaches in adjacent areas of travel demand prediction [9] and \njourney planning [10], fusing the features from different sources is expected to be the \nnext step towards better performance in TTE.\nAbstract \nThis paper introduces a new transformer-based model for the problem of travel time \nestimation. The key feature of the proposed GCT-TTE architecture is the utilization \nof different data modalities capturing different properties of an input path. Along \nwith the extensive study regarding the model configuration, we implemented \nand evaluated a sufficient number of actual baselines for path-aware and path-blind \nsettings. The conducted computational experiments have confirmed the viability \nof our pipeline, which outperformed state-of-the-art models on both considered \ndatasets. Additionally, GCT-TTE was deployed as a web service accessible for further \nexperiments with user-defined routes.\nKeywords: Machine learning, Graph convolutional networks, Transformers, Geospatial \ndata, Travel time estimation\nOpen Access\n© The Author(s) 2024. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the mate-\nrial. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// \ncreat iveco mmons. org/ licen ses/ by/4. 0/.\nBRIEF REPORT\nMashurov et al. Journal of Big Data           (2024) 11:15  \nhttps://doi.org/10.1186/s40537‑023‑00841‑1\nJournal of Big Data\n†Vladimir Mashurov, Vaagn \nChopurian and Vadim Porvatov \nare  equal contribution.\n*Correspondence:   \nsemenova.bnl@gmail.com\n1 PJSC Sberbank, Vavilova Street, \n117312 Moscow, Russia\n2 National University of Science \nand Technology “MISIS” , Lenin \nAvenue 4, 119049 Moscow, \nRussia\n3 Artificial Intelligence Research \nInstitute, Nizhniy Susalnyy Lane \n5, 105064 Moscow, Russia\nPage 2 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nIn this paper, we explored the predictive capabilities of TTE algorithms with different \ntemporal encoders and proposed a new transformer-based model GCT-TTE. The main \ncontributions of this study are the following: \n1. In order to perform the experiments with the image modality, we extended the graph-\nbased datasets for Abakan and Omsk [11] by the map patches (image modality) in \naccordance with the provided trajectories. Currently, the extended datasets are the \nonly publicly available option for experiments with multimodal TTE algorithms.\n2. In order to boost further research in the TTE area, we reimplemented and published \nthe considered baselines in a unified format as well as corresponding weights \nand data preprocessing code. This contribution will enable the community to \nenhance evaluation quality in the future, as most of the TTE methods lack official \nimplementations.\n3. We proposed the GCT-TTE neural network for travel time estimation and \nextensively studied its generalization ability under various conditions. Obtained \nresults allowed us to conclude that our pipeline achieved better performance \nregarding the baselines in terms of several metrics. Conducted experiments explicitly \nindicate that the performance of the transformer-based models is less prone to \ndecrease (in the sense of the considered metrics) with the scaling of a road network \nsize. This property remains crucial from an industrial perspective, as the classic \nrecurrent models undergo considerably larger performance dropdowns.\n4. For demonstration purposes, we deployed inference of the GCT-TTE model as the \nweb application accessible for manual experiments.\nThe web application is available at http://gctte.online and the code is published in the \nGitHub repository of the project. https:// github. com/ Eigho net/ GCT- TTE.\nRelated work\nTravel time estimation methods can be divided into two main types of approaches \ncorresponding to the path-blind and path-aware estimation, Table  1. The path-blind \nestimation refers to algorithms relying only on data about the start and end points of \na route [12]. The path-aware models use intermediate positions of a moving object \nrepresented in the form of GPS sequences [13], map patches [14], or a road subgraph [7]. \nDespite the computational complexity increase, such approaches provide significantly \nbetter results, which justify the attention paid to them in the recent studies [8, 15, 16].\nTable 1 Demonstration of utilized modalities in path-blind and path-aware models\nPath-blind models Path-aware models\nModel Modality Model Modality\nGraph Images GPS Graph Images GPS\n AVG − − −  WDR  + − −\n LR − − −  DeepIST −  + −\n MURAT  + − −  DeepTTE − −  + \n DeepI2T  +  + −  DeepI2T  +  + −\nPage 3 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \nOne of the earliest path-aware models was the wide-deep-recurrent (WDR) architec -\nture [17], which mostly inherited the concept of joint learning from recommender sys -\ntems [18]. In further studies, this approach was extended regarding the usage of different \ndata modalities. In particular, the DeepIST [14] model utilizes rectangular fragments of \na general reference map corresponding to elements of a route GPS sequence. Extracted \nimages are fed into a convolutional neural network (CNN) that captures spatial patterns \nof depicted infrastructure. These feature representations are further concatenated into \nthe matrix processed by the long short-term memory (LSTM) layer [19].\nIn contrast with the other approaches, DeepTTE [20] is designed to operate directly \non GPS coordinates via geospatial convolutions paired with a recurrent neural network. \nThe first part of this pipeline transforms raw GPS sequences into a series of feature maps \ncapturing the local spatial correlation between consecutive coordinates. The final block \nlearns the temporal relations of obtained feature maps and produces predictions for the \nentire route along with its separate segments.\nThe concept of modality fusing was first introduced in TTE as a part of the DeepI2T \n[21] model. This architecture uses large-scale information network embedding [22] \nto produce grid representations and 3-layer CNN with pooling for image processing. \nAs well as DeppTTE, DeepI2T includes the segment-based prediction component \nimplemented in the form of residual blocks on the top of the Bi-LSTM encoder.\nIn addition to extensively studied recurrent TTE methods, it is also important to \nmention recently emerged transformer models [23, 24]. Despite the limited comparison \nwith classic LSTM-based methods, they have already demonstrated promising \nprediction quality, preserving the potential for further major improvements [25, 26]. As \nmost of the transformer models lack a comprehensive evaluation, we intend to explore \nGCT-TTE performance with respect to a sufficient number of state-of-the-art solutions \nto reveal its capabilities explicitly.\nPreliminaries\nIn this section, we introduce the main concepts required to operate with the proposed \nmodel, Fig. 1.\nFig. 1 Example of data modalities of an arbitrary route r: for each GPS coordinate c r\ni from c r , there is a \ncorresponding node g r\ni with associated features and map patch p r\ni\nPage 4 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nRoute A route r is defined as the set {cr, a r, tr} , where cr is the sequence of GPS coor -\ndinates of a moving object, ar is the vector of temporal and weather data, tr is the travel \ntime.\nAs the image modality pr of a route r, we use geographical map patches corresponding \nto each coordinate cr\ni ∈ cr . Each image has a fixed size 256 × 256 × 3 across all of the \nGPS sequences in a specific dataset.\nRoad network Road network is represented in the form of graph G ={ V , E, X} , \nwhere V ={ v1 , ... , vn} is the set of nodes corresponding to the segments of city \nroads, E ={ (vi, vj) | vi → vj} is the set of edges between connected nodes vi, vj ∈ V  , \nX : n× m → R is a feature matrix of nodes describing properties of the roads’ segments \n(additional information regarding available graph features is provided in Additional \nfile 1: S1).\nDescription of a route r can be further extended by the graph modality \ngr ={ vk | k = argmin j ρ( cr\ni,vj)}|cr|\ni=1 , where ρ( cr\ni , v j) is the minimum Euclidean distance \nbetween coordinates associated with v j and cr\ni . Following the same concept as in the case \nof pr , the graph modality represents a sequence of nodes and their features aggregated \nwith respect to the initial GPS coordinates cr.\nTravel time estimation For each entry r, it is required to estimate the travel time tr \nusing the elements of feature description {cr, pr, gr, ar}.\nData\nWe explored the predictive performance of the algorithm on two real-world datasets \ncollected during the period from December 1, 2020 to December 31, 2020 in Abakan \n(112.4 square kilometers) and Omsk (577.9 square kilometers). Each dataset consists of a \nroad graph and associated routes, Table  2. In the preprocessing stage, we excluded trips \nthat lasted less than 30 s (273, 0.22% for Abakan; 1194, 0.15% for Omsk) along with the \nones that took more than 50 min (223, 0.18% for Abakan; 3681, 0.47% for Omsk). The \ndistributional statistics of both datasets are depicted in Fig. 2.\nSince initial versions of Abakan and Omsk datasets did not have any relevant input \ndata for image-based models, we extended their road graphs with the map patches \nparsed from Open Street Map (OSM) https:// www. opens treet map. org .  The pars -\ning algorithm extracted patches from the OSM tile server URLs in accordance with \nthe following request template: http://a.tile.openstreetmap.org/{zoom}/{longitude}/\n{latitude}.png. In order to utilize obtained data together with initial graphs, it was \nextended by mapping tables including the closest node id for each patch. The applied \nproximity measure was based on the Euclidean distance between location of image \nTable 2 Description of the Abakan and Omsk datasets\nRoad network Trips\nProperty\\city Abakan Omsk Property\\city Abakan Omsk\n Nodes 65,524 231,688  Trips number 121,557 767,343\n Edges 340,012 1,149,492  Coverage 53.3% 49.5%\n Clustering 0.5278 0.53  Average time 427 s 608 s\n Usage median 12 8  Average length 3604 m 4216 m\nPage 5 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \ncentroids and geographical coordinates of graph vertexes. Due to the limitations of \nthe API throughput, the procedure of image extraction was distributed between sev -\neral machines with a total execution time exceeding 1 week.\nThe provided extension consists of images dated July 2022: due to the absence of \nsignificant changes in the road network topology since 2020, image modality for \nAbakan and Omsk remains actual with respect to the original graph-based data. The \ncontent of the patches includes a full range of geographic objects useful for travel \ntime estimation (e.g., road networks, landscape groups, buildings and associated \ninfrastructural objects) and covers all of the routes provided in the initial datasets.\nDepending on the requirements of the considered learning model, image \ndatasets had to be organized regarding the fixed grid partitions or centered around \nthe elements of GPS sequences. In the first case, a geographical map of a city was \ndivided into equal disjoint patches, which were further mapped with the GPS data in \naccordance with the presence of coordinates in a specific partition. Trajectory-based \napproach to dataset construction does not require the disjoint property of images \nand relies on the extraction of patches with the center in the specified coordinate, \nAlgorithm 1 (collect and split functions can be accessed in Additional file  1: S2, S3). \nThe obtained grid-based image dataset consists of 96,101 instances for Abakan and \n838,865 for Omsk while the trajectory-based dataset has 544,502 and 3,376,294 \nimages correspondingly.\nOne of the crucial features of the considered datasets is the absence of traffic flow \nproperties. The availability of such data is directly related to the specialized tracking \nsystems (based on loop detectors or observation cameras), which are not presented in \nthe majority of cities. In order to make the GCT-TTE suitable for the greatest number \nof urban environments, we decided not to limit the study by the rarely accessible data.\nMethod\nIn this section, we provide an extensive description of the GCT-TTE main \ncomponents: pointwise and sequence representation blocks, Fig. 3 .\nFig. 2 Cumulative frequencies of car activity and distribution of trips duration for Abakan (a) and Omsk (b) in \nthe four hours interval\nPage 6 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nPatches encoder\nIn order to extract features from the image modality, we utilized the RegNetY [27] \narchitecture from the SEER model family. The key component of this architecture is \nthe convolutional recurrent neural network (ConvRNN) which controls the spatio-\ntemporal information flow between building blocks of the neural network.\nEach RegNetY block consists of three operators. The initial convolution layer of \nt’th block processes the input tensor X t\n1 and returns the feature map X t\n2 . Next, the \nobtained representation X t\n2 is fed to ConvRNN:\nwhere H t−1 is the hidden state of the previous RegNetY block, bh is a bias tensor, Cx and \nCh correspond to convolutional layers. In the following stage, X t\n2 and H t are fed as input \nto the last convolution layer, which is further extended by residual connection.\nAs the SEER models are capable of producing robust features that are well-suited \nfor out-of-distribution generalization [28], we pre-trained RegNetY with the following \nautoencoder loss:\nwhere L is the binary cross-entropy function, f is an image flattening operator, and W is \nthe projection matrix of learning parameters that maps model output to the flattened \nimage.\nAuxiliary encoder\nAlong with the map patches and graph elements, we apply additional features \nar corresponding to the temporal and weather data (e.g., trip hour, type of day, \nprecipitation). The GCT-TTE model processes this part of the input with the help of a \ntrivial linear layer:\n(1)H t = tanh(C x(X t\n2) + C h(H t−1) + bh),\n(2)L(W ×RegNet(X ), f(X )) → 0,\nFig. 3 Demonstration of the GCT-TTE pipeline: feature extraction algorithms applied to considered \nmodalities and extended by transformer encoder capturing the concatenated sequence of embeddings\nPage 7 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \nwhere W is a matrix of learning parameters.\nGraph encoder\nThe graph data is handled with the help of the graph convolutional layers defined as \nfollows:\nwhere h(k)\nu  is a k-hop embedding [29] of u ∈ V  , h(0)\nu = xu , W (k) is a matrix of learning \nparameters of k’th convolutional layer, N(u) is a set of neighbour nodes of u, AGG v∈N(u) \nis a sum aggregarion function, and ||Nuv|| = √|N(u)||N(v)|.\nTo accelerate the convergence of the GCT-TTE model, we pre-trained the weights \nof the graph convolutions by the Deep Graph InfoMax algorithm [30]. This approach \noptimizes the loss function that allows learning the difference between initial and \ncorrupted embeddings of nodes:\nwhere hu is an embedding of node u based on the initial graph G , ˜hu is an embedding of a \nnode u from the corrupted version ˜G of the graph G , D corresponds to the discriminator \nfunction.\nThe final output of the pointwise block constitutes a concatenation of the weighted \nrepresentations and auxiliary data for each route r with k segments:\nwhere H r is the matrix of size k × eg of graph-based segment embeddings, Ir is \nthe matrix of size k × ei obtained from a flattened RegNet output, α , (1 − α) , and β \ncorrespond to the weight coefficients of specific modalitites.\nSequence representation block\nTo extract sequential features from the output of the pointwise representation block, \nit is fed to transformer encoder [31]. The encoder consists of two attention layers with \na residual connection followed by a normalization operator. The multi-head attention \ncoefficients are defined as follows:\nwhere xi, xj ∈ P r , h is an attention head, dk is a scale coefficient, W T\nh,q and W T\nh,k are query \nand key weight matrices, w j is a vector of softmax learning parameters. The output of the \nattention layer will be:\n(3)Ar = Wa r,\n(4)h(k)\nu = ReLU\n(\nW (k) AGG v∈N(u) ( h(k−1)\nv\n||Nuv||)\n)\n,\n(5)L = 1\nN + M\n( N∑\ni=1\nEG\n[\nlog(D (hu,hG))\n]\n+\nM∑\nj=1\nE ˜G\n[\nlog(1 − D ( ˜hu,hG))\n])\n,\n(6)Pr = CONCAT (α · H r,(1− α) · Ir,β · A r),\n(7)α (h)\ni,j = softmaxw j\n(\n�W T\nh,qxi,W T\nh,kxj�\n√\ndk\n)\n,\nPage 8 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nwhere W T\nh,v is value weight matrix, H is a number of attention heads.\nThe final part of the sequence representation block corresponds to the flattening \noperator and several linear layers with the ReLU activation, which predict the travel time \nof a route.\nResults\nIn this section, we reveal the parameter dependencies of the model and compare the \nresults of the considered baselines.\nExperimental setup\nThe experiments were conducted on 16 GPU Tesla V100. For the GCT-TTE training, \nAdam optimizer [32] was chosen with a learning rate 5 × 10−5 and batch size of 16. For \nbetter convergence, we apply the scheduler with patience equal to 10 epochs and 0.1 \nscaling factor. The training time for the final configuration of the GCT-TTE model is 6 h \nin the case of Abakan and 30 for Omsk.\nThe established values of quality metrics were obtained from the 5-fold cross-\nvalidation procedure. As the measures of the model performance, we use mean absolute \nerror (MAE), rooted mean squared error (RMSE), and 10% satisfaction rate (SR). \nAdditionally, we compute mean absolute percentage error (MAPE) as it is frequently \napplied in related studies.\nModels comparison and evaluation\nThe results regarding path-blind evaluation are depicted in Table  3. Neighbor average \n(AVG) and linear regression (LR) demonstrated the worst results among the trivial \nbaselines as long as gradient boosted decision trees (GBDT) explicitly outperformed \nmore complex models in the case of the largest city. The MURAT model achieved the \nbest score for Abakan in terms of MAE and RMSE, while GCT-TTE has the minimum \nMAPE among all of the considered architectures.\nDemonstrated variability of metric values makes the identification of the best model \nrather a hard task for a path-blind setting. The simplest models are still capable to be \ncompetitive regarding such architectures as MURAT, which was expected to perform \n(8)u i = LayerNorm\n\nxi+\nH�\nh=1\nW T\nc,h\nn�\nj=1\nα (h)\ni,jW T\nh,vxj\n\n,\nTable 3 Path-blind models comparison\nThe best results are highlighted in bold\nBaseline/metric Abakan Omsk\nMAE RMSE MAPE SR MAE RMSE MAPE SR\nAVG 322.77 477.61 0.761 0.018 439.05 628.75 0.741 0.012\nLR 262.33 456.63 1.169 9.527 416.81 593.01 1.399 7.187\nGBDT 245.77 433.91 1.106 10.28 209.99 372.11 0.656 17.72\nMURAT 182.97 282.15 0.685 10.77 285.72 444.74 0.856 9.997\nGCT-TTE 221.71 337.59 0.505 11.12 376.74 590.93 0.5486 8.99\nPage 9 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \ntangibly better on both considered datasets. The results regarding GCT-TTE can be par-\ntially explained by its structure as it was not initially designed for a path-blind evaluation.\nAs can be seen in Table  4, the proposed solution outperformed baselines in terms of \nthe RMSE value, which proves the rigidity of GCT-TTE towards large errors prevention. \nThe comparison of MAE and RMSE for considered methods has shown a minimal gap \nbetween these metrics in the case of GCT-TTE for both cities, signifying the efficiency \nof the technique with respect to dataset size. Overall, the results have confirmed that \nGCT-TTE appeared to be a more reliable approach than the LSTM-based models: while \nMAPE remains approximately the same across top-performing architectures, GCT-TTE \nachieves significantly better MAE and RMSE values. Conducted computational experi -\nments also indicated that DeepI2T and WDR have intrinsic problems with the conver -\ngence, while GCT-TTE demonstrates smoother training dynamics.\nPerformance analysis\nIn the case of both datasets, dependencies between the travelled distance and obtained \nMAE on the corresponding trips reveal similar dynamics: as the path length increases, \nthe error rate continues to grow, Fig.  4b, d. The prediction variance is inversely \nproportional to the number of routes in a particular length interval except for the small \npercentage of the shortest routes. The main difference between the MAE curves is \nreflected in the higher magnitudes of performance fluctuations in Abakan compared to \nOmsk.\nThe temporal dynamics of GCT-TTE errors exhibit rich nonlinear properties during \na 24-hour period. The shape of the error curves demonstrates that our model tends to \naccumulate a majority of errors in the period between 16:00 and 18:00, Fig.  4a, c. This \ntime interval corresponds to the end of the working day, which has a crucial impact on \nthe traffic flow foreseeability.\nDespite the mentioned performance outlier, the general behaviour of temporal \ndependencies allows concluding that GCT-TTE successfully captures the factors \ninfluencing the target value in the daytime. With the growing sparsity of data during \nnight hours, it is still capable of producing relevant predictions for Omsk. In the case of \nAbakan, the GCT-TTE performance drop can be associated with a substantial reduction \nin intercity trips number (which emerged to be an easier target for the model).\nTable 4 Path-aware models comparison\nThe best results are highlighted in bold\nBaseline/metric Abakan Omsk\nMAE RMSE MAPE SR MAE RMSE MAPE SR\nDeepIST 153.88 241.29 0.3905 18.08 256.50 415.16 0.6361 14.39\nDeepTTE 111.03 174.56 0.2165 31.45 179.07 296.98 0.1898 34.03\nGridLSTM 100.27 206.91 0.2202 30.74 135.74 257.18 0.2120 31.21\nDeepI2T 97.99 201.33 0.2128 31.34 136.66 260.90 0.2124 31.23\nWDR 97.22 190.09 0.2162 31.98 131.57 269.00 0.2039 33.34\nGCT-TTE 92.26 147.89 0.2262 30.46 107.97 169.15 0.1961 35.17\nPage 10 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nFig. 4 Spatial and temporal (hour) dependencies across the different groups of test entries for Abakan (a, b) \nand Omsk (c, d): blue and red lines depict mean and median values of MAE, borders of filled area correspond \nto Q1 and Q3 quartiles of a MAE distribution\nFig. 5 Temporal (day and week) dependencies across the different groups of test entries for Abakan (a, b) \nand Omsk (c, d): blue and red lines depict mean and median values of MAE, borders of filled area correspond \nto Q1 and Q3 quartiles of a MAE distribution. The weekends are represented by the vertical areas filled with a \ndarker colour\nPage 11 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \nFocusing on higher levels of seasonality, day- and week-based temporal dependen -\ncies of error demonstrate explicit periodical behaviour, Fig.  5. The GCT-TTE model \nperforms better at the end of the week for both considered cities, with a pronounced \nerror decrease in the case of Omsk. In contrast, the middle of the week (i.e. Wednesday \nfor Abakan and Tuesday for Omsk) is the most challenging period, which has averagely \n12.48% higher MAE compared to Saturday and Sunday.\nSensitivity analysis\nIn order to achieve better prediction quality, we extensively studied the dependencies \nbetween GCT-TTE parameters and model performance in the sense of the MAE metric. \nThe best value for modality coefficient α was 0.9, which reflects the significant contri -\nbution of graph data towards error reduction. For the final model, we utilized 2 graph \nconvolutional layers with hidden size 192, Fig.  6a, b. The lack of aggregation depth can \nsignificantly reduce the performance of GCT-TTE, while the excessive number of layers \nhas a less expressive negative impact on MAE. A similar situation can be observed in the \ncase of the hidden size, which is getting close to a plateau after reaching a certain thresh-\nold value.\nAlong with the graph convolutions, we explored the configuration of the sequence \nrepresentation part of GCT-TTE. Since the transformer block remains its main com -\nponent, the computational experiments were focused on the influence of encoder depth \non quality metrics, Fig. 3c. As it can be derived from the U-shaped dependency, the best \nnumber of attention layers is 3.\nDemonstration\nIn order to provide access to the inference of GCT-TTE, we deployed a demonstrational \napplication http:// gctte. online in a website format, Fig.  7. The application’s interface \nconsists of a user guide, navigation buttons, erase button, and a comparison button. A \npotential user can construct and evaluate an arbitrary route by clicking on the map at the \ndesired start and end points: the system’s response will contain the shortest path and the \ncorresponding value of the estimated time of arrival.\nFor additional evaluation of considered baselines, the limited number of predefined \ntrajectories with known ground truth can also be requested. In this case, the response \nwill contain three random trajectories from the datasets with associated predictions of \nWDR, DeepI2T, and GCT-TTE models along with the real travel time.\nFig. 6 Parametric dependencies of GCT-TTE performance for Abakan: number of graph convolutions (a), \nhidden size of graph convolutions (b), and number of transformer encoder layers (c)\nPage 12 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \nConclusion\nIn this paper, we introduced a multimodal transformer architecture for travel time \nestimation and performed an extensive comparison with the other existing approaches. \nObtained results allow us to conclude that the transformer-based models can be \nefficiently utilized as sequence encoders in the path-aware setting. Our experiments \nwith different data modalities revealed the superior importance of graphs compared \nto map patches. Such an outcome can be explained by the inheritance of main features \nbetween modalities where graph data represents the same properties more explicitly. In \nfurther studies, we intend to focus on the design of a more expressive image encoder as \nwell as consider the task of path-blind travel time estimation, which currently remains \nchallenging for the GCT-TTE model.\nSupplementary Information\nThe online version contains supplementary material available at https:// doi. org/ 10. 1186/ s40537- 023- 00841-1.\nAdditional file 1:   Trajectory-based approach to dataset construction does not require the disjoint property of \nimages and relies on the extraction of patches with the center in the specified coordinate, Algorithm 1 (collect and \nsplit functions can be accessed in Additional file 1: S2, S3).\nAcknowledgements\nAuthors are grateful to Vladislav Zamkovy for the help with application deployment.\nAuthor Contributions\nVM, VC, and AI: software, data curation, validation, visualization; VP: software, visualization, conceptualization, \nmethodology, writing (original draft); NS: conceptualization, methodology, supervision, writing (review , editing).\nFunding\nNot applicable.\nAvailability of data and materials\nConsidered models and datasets are available in the project’s GitHub repository.\nDeclarations\n Ethics approval and consent to participate\nNot applicable. \nFig. 7 An interface of the demonstrational application\nPage 13 of 14\nMashurov et al. Journal of Big Data           (2024) 11:15 \n \nConsent for publication\nNot applicable. \nCompeting interests\nThe authors declare that they have no competing interests.\nReceived: 8 March 2023   Accepted: 11 October 2023\nReferences\n 1. Jenelius E, Koutsopoulos H. Travel time estimation for urban road networks using low frequency probe vehicle data. \nTransport Res Part B Methodol. 2013;53:64–81.\n 2. Wu X, Roy U, Hamidi M, Craig B. Estimate travel time of ships in narrow channel based on AIS data. Ocean Eng. \n2020;202: 106790.\n 3. Xuegang J, Ban XJ, Li Y, Skabardonis A, Margulici J. Performance evaluation of travel time estimation methods for \nreal-time traffic applications. Intell Transp Syst J. 2010;14:54–67.\n 4. Salehi S, Mahmoudabadi A. Estimating the reliability of travel time on railway networks for freight transportation. \nUrban Stud Public Adm. 2018;1:75. https:// doi. org/ 10. 22158/ uspa. v1n1p 75.\n 5. Shi C, Chen BY, Li Q. Estimation of travel time distributions in urban road networks using low-frequency floating car \ndata. ISPRS Int J Geo Inform. 2017;6(8):253.\n 6. Navarro-Espinoza A, López-Bonilla OR, García-Guerrero EE, Tlelo-Cuautle E, López-Mancilla D, Hernández-Mejía C, \nInzunza-González E. Traffic flow prediction for smart traffic lights using machine learning algorithms. Technologies. \n2022;10(1):5. https:// doi. org/ 10. 3390/ techn ologi es100 10005.\n 7. Wang Q, Xu C, Zhang W, Li J. Graphtte: travel time estimation based on attention-spatiotemporal graphs. IEEE Signal \nProcess Lett. 2021;28:239–43.\n 8. Derrow-Pinion A, She J, Wong D, Lange O, Hester T, Perez L, Nunkesser M, Lee S, Guo X, Wiltshire B et al. Eta predic-\ntion with graph neural networks in google maps. In: Proceedings of the 30th ACM International conference on \ninformation and knowledge management. 2021. pp. 3767–3776.\n 9. Chu K-F, Lam AYS, Li VOK. Deep multi-scale convolutional lstm network for travel demand and origin-destination \npredictions. IEEE Transact Intell Transport Syst. 2020;21(8):3219–32. https:// doi. org/ 10. 1109/ TITS. 2019. 29249 71.\n 10. He P , Jiang G, Lam S-K, Sun Y, Ning F. Exploring public transport transfer opportunities for pareto search of multicrite-\nria journeys. IEEE Transact Intell Transport Syst. 2022;23(12):22895–908. https:// doi. org/ 10. 1109/ TITS. 2022. 31945 23.\n 11. Porvatov V, Semenova N, Chertok A. Hybrid graph embedding techniques in estimated time of arrival task. In: Benito \nRM, Cherifi C, Cherifi H, Moro E, Rocha LM, Sales-Pardo M, editors. Complex networks their applications X. Cham: \nSpringer; 2022. p. 575–86.\n 12. Wang H, Tang X, Kuo Y-H, Kifer D, Li Z. A simple baseline for travel time estimation using large-scale trip data. ACM \nTransact Intell Syst Technol (TIST). 2019;10(2):1–22.\n 13. Wang Y, Zheng Y, Xue Y. Travel time estimation of a path using sparse trajectories. In: Proceedings of the 20th ACM \nSIGKDD International conference on knowledge discovery and data mining. KDD ’14. New York: Association for \nComputing Machinery. pp. 25–34\n 14. Fu TY, Lee WC. Deepist: Deep image-based spatio-temporal network for travel time estimation. In: Proceedings of \nthe 28th ACM International conference on information and knowledge management. CIKM ’19. New York: Associa-\ntion for Computing Machinery; 2019.\n 15. Zhang H, Wu H, Sun W, Zheng B. Deeptravel: a neural network based travel time estimation model with auxil-\niary supervision. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence. 2018. pp. \n3655–3661.\n 16. Sun Y, Fu K, Wang Z, Zhang C, Ye J. Road network metric learning for estimated time of arrival. In: 2020 25th Interna-\ntional conference on pattern recognition (ICPR). New York: IEEE; 2021. pp. 1820–1827\n 17. Wang Z, Fu K, Ye J. Learning to estimate the travel time. In: Proceedings of the 24th ACM SIGKDD International con-\nference on knowledge discovery and data mining. KDD ’18. New York: Association for Computing Machinery; 2018. \npp. 858–866.\n 18. Cheng H.-T, Koc L, Harmsen J, Shaked T, Chandra T, Aradhye H, Anderson G, Corrado G, Chai W, Ispir M, et al.: Wide & \ndeep learning for recommender systems. In: Proceedings of the 1st workshop on deep learning for recommender \nsystems. 2016. pp. 7–10.\n 19. Hochreiter S, Urgen Schmidhuber J, Elvezia C. Long short-term memory. Neural Comput. 1997;9(8):1735–80.\n 20. Wang D, Zhang J, Cao W, Li J, Zheng Y. When will you arrive? estimating travel time based on deep neural networks. \nIn: AAAI. 2018; 2018.\n 21. Lan W, Xu Y, Zhao B. Travel time estimation without road networks: an urban morphological layout representation \napproach. In: Proceedings of the 28th International joint conference on artificial intelligence. IJCAI’19. Washington: \nAAAI Press; 2019. pp. 1772–1778.\n 22. Tang J, Qu M, Wang M, Zhang M, Yan J, Mei Q. Line: Large-scale information network embedding. In: Proceedings of \nthe 24th International conference on world wide web. 2015. pp. 1067–1077.\n 23. Liu F, Yang J, Li M, Wang K. Mct-tte: travel time estimation based on transformer and convolution neural networks. \nSci Progr. 2022;2022:3235717.\n 24. Semenova N, Porvatov V, Tishin V, Sosedka A, Zamkovoy V. Logistics, graphs, and transformers: towards improving \ntravel time estimation. In: Amini MR, Canu S, Fischer A, Guns T, Kralj Novak P , Tsoumakas G, editors. Machine learn-\ning and knowledge discovery in databases. Lecture notes in computer science, vol. 13718. Springer, Cham; 2023. \nhttps:// doi. org/ 10. 1007/ 978-3- 031- 26422-1_ 36.\nPage 14 of 14Mashurov et al. Journal of Big Data           (2024) 11:15 \n 25. Shen Y, Jin C, Hua J, Huang D. Ttpnet: a neural network for travel time prediction based on tensor decomposition \nand graph embedding. IEEE Transact Knowl Data Eng. 2022;34(9):4514–26. https:// doi. org/ 10. 1109/ TKDE. 2020. 30382 \n59.\n 26. Fan S, Li J, Lv Z, Zhao A. Multimodal traffic travel time prediction. In: 2021 International Joint Conference on Neural \nNetworks (IJCNN). 2021. pp. 1–9. https:// doi. org/ 10. 1109/ IJCNN 52387. 2021. 95333 56.\n 27. Radosavovic I, Kosaraju R.P , Girshick R, He K, Dollar P . Designing network design spaces. In: Proceedings of the IEEE/\nCVF Conference on computer vision and pattern recognition (CVPR). 2020.\n 28. Goyal P , Duval Q, Seessel I, Caron M, Misra I, Sagun L, Joulin A, Bojanowski P . Vision models are more robust and fair \nwhen pretrained on uncurated images without supervision. arXiv.  2022. https:// doi. org/ 10. 48550/ arXiv. 2202. 08360.\n 29. Kipf TN, Welling M. Semi-supervised classification with graph convolutional networks. In: Proceedings of the 5th \ninternational conference on learning representations. Palais des Congrès Neptune, France; 2017.\n 30. Veličković P , Fedus W, Hamilton W.L, Liò P , Bengio Y, Hjelm R.D. Deep Graph Infomax. In: International conference on \nlearning representations. 2019.\n 31. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser LU, Polosukhin I. Attention is all you need. In: \nGuyon I, Luxburg UV, Bengio S, Wallach H, Fergus R, Vishwanathan S, Garnett R, editors. Advances in neural informa-\ntion processing systems, vol. 30. Red Hook: Curran Associates; 2017.\n 32. Kingma D, Ba J. Adam: a method for stochastic optimization. In: International conference on learning representa-\ntions. 2014.\nPublisher’s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8511968851089478
    },
    {
      "name": "Transformer",
      "score": 0.6787806153297424
    },
    {
      "name": "Modalities",
      "score": 0.5757682919502258
    },
    {
      "name": "Architecture",
      "score": 0.5144146084785461
    },
    {
      "name": "Graph",
      "score": 0.4627862572669983
    },
    {
      "name": "Data mining",
      "score": 0.4421551823616028
    },
    {
      "name": "Path (computing)",
      "score": 0.44001099467277527
    },
    {
      "name": "Pipeline (software)",
      "score": 0.41703590750694275
    },
    {
      "name": "Artificial intelligence",
      "score": 0.3367699384689331
    },
    {
      "name": "Machine learning",
      "score": 0.3230786919593811
    },
    {
      "name": "Theoretical computer science",
      "score": 0.24548205733299255
    },
    {
      "name": "Computer network",
      "score": 0.10119375586509705
    },
    {
      "name": "Programming language",
      "score": 0.08917918801307678
    },
    {
      "name": "Social science",
      "score": 0.0
    },
    {
      "name": "Art",
      "score": 0.0
    },
    {
      "name": "Quantum mechanics",
      "score": 0.0
    },
    {
      "name": "Visual arts",
      "score": 0.0
    },
    {
      "name": "Sociology",
      "score": 0.0
    },
    {
      "name": "Physics",
      "score": 0.0
    },
    {
      "name": "Voltage",
      "score": 0.0
    }
  ]
}