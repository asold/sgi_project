{
  "title": "Clinical Accuracy, Relevance, Clarity, and Emotional Sensitivity of Large Language Models to Surgical Patient Questions: Cross-Sectional Study",
  "url": "https://openalex.org/W4395031821",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A4201615598",
      "name": "Mert Marcel Dagli",
      "affiliations": []
    },
    {
      "id": null,
      "name": "Felix Conrad Oettl",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A4364045374",
      "name": "Jaskeerat Gujral",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2097751555",
      "name": "Kashish Malhotra",
      "affiliations": [
        "University of Birmingham"
      ]
    },
    {
      "id": "https://openalex.org/A2747903291",
      "name": "Yohannes Ghenbot",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2115178178",
      "name": "Jang W. Yoon",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2121917164",
      "name": "Ali K. Ozturk",
      "affiliations": [
        "University of Pennsylvania"
      ]
    },
    {
      "id": "https://openalex.org/A2110845480",
      "name": "William C. Welch",
      "affiliations": [
        "University of Pennsylvania"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2953532875",
    "https://openalex.org/W3191197587",
    "https://openalex.org/W2753573594",
    "https://openalex.org/W2128308912",
    "https://openalex.org/W2091254174",
    "https://openalex.org/W2149941633",
    "https://openalex.org/W4386304195",
    "https://openalex.org/W2966555834",
    "https://openalex.org/W4205373255"
  ],
  "abstract": "This cross-sectional study evaluates the clinical accuracy, relevance, clarity, and emotional sensitivity of responses to inquiries from patients undergoing surgery provided by large language models (LLMs), highlighting their potential as adjunct tools in patient communication and education. Our findings demonstrated high performance of LLMs across accuracy, relevance, clarity, and emotional sensitivity, with Anthropic’s Claude 2 outperforming OpenAI’s ChatGPT and Google’s Bard, suggesting LLMs’ potential to serve as complementary tools for enhanced information delivery and patient-surgeon interaction.",
  "full_text": "JMIR Preprints Dagli et al\nClinical Accuracy, Relevance, Clarity, and Emotional\nSensitivity of Large Language Models to Surgical\nPatient Questions: Cross-Sectional Study\n Mert Marcel Dagli, Felix Conrad Oettl, Jaskeerat Gujral, Kashish Malhotra,\nYohannes Ghenbot, Jang W Yoon, Ali K Ozturk, William C Welch\nSubmitted to: JMIR Formative Research\non: January 08, 2024\nDisclaimer: © The authors. All rights reserved. This is a privileged document currently under peer-review/community\nreview. Authors have provided JMIR Publications with an exclusive license to publish this preprint on it's website for\nreview purposes only. While the final peer-reviewed paper may be licensed under a CC BY license on publication, at this\nstage authors and publisher expressively prohibit redistribution of this draft paper other than for review purposes.\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nTable of Contents\nOriginal Manuscript ....................................................................................................................................................................... 4\nSupplementary Files ..................................................................................................................................................................... 16\nFigures ......................................................................................................................................................................................... 17\nFigure 1 ...................................................................................................................................................................................... 18\nMultimedia Appendixes ................................................................................................................................................................. 19\nMultimedia Appendix 0 .................................................................................................................................................................. 20\nMultimedia Appendix 1 .................................................................................................................................................................. 20\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nClinical Accuracy, Relevance, Clarity, and Emotional Sensitivity of Large\nLanguage Models to Surgical Patient Questions: Cross-Sectional Study\nMert Marcel Dagli1 MD ; Felix Conrad Oettl2, 3 MD ; Jaskeerat Gujral1; Kashish Malhotra4 MBBS ; Yohannes Ghenbot1\nMD ; Jang W Yoon1 MD ; Ali K Ozturk1 MD ; William C Welch1 MD\n1Department of Neurosurgery University of Pennsylvania Perelman School of Medicine Philadelphia US\n2Department of Orthopedic Surgery Hospital for Special Surgery New York US\n3Department of Orthopedic Surgery Schulthess Clinic Zurich CH\n4Institute of Applied Health Research University of Birmingham Birmingham GB\nCorresponding Author:\nMert Marcel Dagli MD\nDepartment of Neurosurgery\nUniversity of Pennsylvania Perelman School of Medicine\n801 Spruce Street\nPhiladelphia\nUS\nAbstract\nThis cross-sectional study evaluates the clinical accuracy, relevance, clarity, and emotional sensitivity of responses to surgical\npatient inquiries provided by Large Language Models, highlighting their potential as adjunct tools in patient communication and\neducation.\n(JMIR Preprints 08/01/2024:56165)\nDOI: https://doi.org/10.2196/preprints.56165\nPreprint Settings\n1) Would you like to publish your submitted manuscript as preprint?\nPlease make my preprint PDF available to anyone at any time (recommended).\nPlease make my preprint PDF available only to logged-in users; I understand that my title and abstract will remain visible to all users.\nOnly make the preprint title and abstract visible.\nNo, I do not wish to publish my submitted manuscript as a preprint.\n2) If accepted for publication in a JMIR journal, would you like the PDF to be visible to the public?\nYes, please make my accepted manuscript PDF available to anyone at any time (Recommended). \nYes, but please make my accepted manuscript PDF available only to logged-in users; I understand that the title and abstract will remain visible to all users (see Important note, above). I also understand that if I later pay to participate in <a href=\"https://jmir.zendesk.com/hc/en-us/articles/360008899632-What-is-the-PubMed-Now-ahead-of-print-option-when-I-pay-the-APF-\" target=\"_blank\">JMIR’s PubMed Now! service</a> service, my accepted manuscript PDF will automatically be made openly available.\nYes, but only make the title and abstract visible (see Important note, above). I understand that if I later pay to participate in  <a href=\"https://jmir.zendesk.com/hc/en-us/articles/360008899632-What-is-the-PubMed-Now-ahead-of-print-option-when-I-pay-the-APF-\" target=\"_blank\">JMIR’s PubMed Now! service</a> service, my accepted manuscript PDF will automatically be made openly available.\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nOriginal Manuscript\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nTitle: Clinical Accuracy, Relevance, Clarity, and Emotional Sensitivity of Large Language Models to\nSurgical Patient Questions: Cross-Sectional Study\nAuthors: Dagli, Mert Marcel MD1*; Öttl, Felix MD2,3; Gujral, Jaskeerat1; Malhotra, Kashish MBBS4;\nGhenbot, Yohannes MD1; Yoon, Jang W MD1; Ozturk, Ali K MD1; Welch, William C MD1 \nAuthor Affiliations:\n1. Department of Neurosurgery, Perelman School of Medicine, University of Pennsylvania,\nPhiladelphia, PA, US\n2. Department of Orthopedic Surgery, Hospital for Special Surgery, New York, NY , US\n3. Department of Orthopedic Surgery, Schulthess Clinic, Zurich, CH\n4. Institute  of  Applied  Health  Research,  University  of  Birmingham,  Birmingham,  West\nMidlands, UK\nCorresponding Author:\nMert Marcel Dagli, MD\nDepartment of Neurosurgery\nPerelman School of Medicine, University of Pennsylvania\n801 Spruce Street, Philadelphia, 19107 PA, USA\nEmail: marcel.dagli@pennmedicine.upenn.edu\nPhone: (267) 230-6493\nFax: (215) 615-3701\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nKeywords: artificial intelligence; natural language processing; large language model; generative AI;\ncross-sectional study; health information; patient education\nAbstract word count: 73\nText word Count: 749\nNumber of references: 9\nNumber of tables and/or figures: 2\nNumber of videos: 0\nPrevious presentations: nil\nFinancial and competing interests disclosure: The authors declare no conflict of interests.\nFunding: none\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nAbstract:\nThis  cross-sectional  study  evaluates  the  clinical  accuracy,  relevance,  clarity,  and  emotional\nsensitivity  of  responses  to  surgical  patient  inquiries  provided  by  Large  Language  Models,\nhighlighting their potential as adjunct tools in patient communication and education. Our findings\ndemonstrated  high  performance  of  LLMs  across  accuracy,  relevance,  clarity,  and  emotional\nsensitivity,  with  Anthropic's  Claude-2  outperforming  OpenAI's  ChatGPT  and  Google's  Bard,\nsuggesting LLMs' potential to serve as a complementary tool for enhanced information delivery and\npatient-surgeon interaction. \nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nIntroduction\nRecent  advances  in  natural  language  processing  (NLP)  have  produced  Large  Language  Model\n(LLM) applications, such as OpenAI’s ChatGPT, that have captivated a worldwide audience [1].\nThese advancements have permeated the healthcare sector offering several benefits [2]. While LLMs\nhave immense potential in improving clinical practice and patient outcomes, their role has not been\ncompletely established [3]. Often, patients that require  surgery struggle  with  complex, anxiety-\ninducing  questions [4].  Thus, preoperative  counseling  during  preoperative  workup  is of  utmost\nimportance for informed consent, establishing trust, and pre-surgical optimization to improve patient\noutcomes. This process, being resource-intensive and involving numerous conversations, often leads\nto delays in communication that can be a significant source of frustration for patients [5]. Therefore,\nthe importance of clear, adequate, and timely information delivery cannot be overemphasized. LLMs\nwith chat features could improve preoperative communication, however, LLMs’ ability in answering\npatients’ surgical questions have not been extensively studied yet. Thus, this study aims to assess\nLLMs’ potential and proficiency in responding to surgical patient questions.\nMethods\nIn the formulation of our questionnaire, we utilized the input of three neurosurgical attendings,\nfocusing on common general patient inquiries regarding surgery. 38 patient questions were presented\nin web sessions to three publicly accessible LLMs, OpenAI’s ChatGPT GPT-4, Anthropic’s Claude 2,\nand Google’s Bard on August 16, 2023 (Multimedia Appendix 1). Questions revolved around four\ncentral themes: understanding the nature and rationale of surgery, pre-operative concerns, procedural\naspects,  and  post-operative  considerations.  Each  reply  from  the  LLMs  was  reviewed  by  two\nindependent blinded reviewers (MMD, FCO; research fellows who have medical doctorates but have\nnot completed post-graduate clinical trianing). A 5-point Likert scale was used to assess accuracy,\nrelevance, and clarity of responses [6]. Emotional sensitivity was evaluated on a 7-point Likert scale\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nto increase discriminatory power [7]. Assessment of data normality was conducted using the Shapiro-\nWilk test. Homogeneity of variances (homoscedasticity) across groups was evaluated via the Levene\ntest. For non-parametric analysis, the Kruskal-Wallis test was employed to discern differences among\ngroups. Subsequent pairwise comparisons were facilitated by the post-hoc Dunn test. In instances\nwhere parametric assumptions were upheld, a one-way ANOV A was conducted, followed by post-\nhoc analysis with Tukey’s Honestly Significant Difference (HSD) test.  P values of post-hoc analysis\nwere  adjusted  for  multiplicity  with  Bonferroni  correction.  Additionally,  Weighted  Percentage\nAgreement (WPA) was calculated to provide information on agreement levels between raters. All\nstatistical analysis was performed using Python, version 3.7 (Python Foundation).\nEthical considerations\nThe  study  qualified  for  institutional  review  board  (IRB)  exemption  as  it  exclusively  utilized\nquestions sourced from surgeon input, with no direct patient involvement.\nResults\nShapiro-Wilk testing indicated non-normality ( P<.05; Table 1) for accuracy, relevance, and clarity\nscores. Levene testing revealed non-homoscedasticity for relevance ( F2=5.009;  P=.008). Kruskal-\nWallis  test  showed  significant  differences  in  the  distribution  of  accuracy  (H=27.464;  P<.001),\nrelevance ( H=29.074;  P<.001), and clarity ( H=32.745;  P<.001). Post hoc Dunn test demonstrated\nthat  Claude’s  responses  were  significantly  higher  rated  than  those  from  ChatGPT and  Bard  in\naccuracy, relevance, and clarity (P<.05). There were no significant differences between ChatGPT and\nBard, except for the clarity criterion ( Z=1.972, P=.038). ANOV A showed significant differences in\nemotional  sensitivity  (F=10.799;  P<.001).  Post-hoc  Tukey’s  HSD  revealed  significantly  higher\nemotional sensitivity scores for Claude compared to ChatGPT and Bard ( P<.05). WPA was highest\nfor Claude followed by ChatGPT and Bard (Figure 1).\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nFigure  1:  Bar  chart  of  adjusted  percentage  average  ratings  of  large  language  model  responses\n(ChatGPT=light  blue;  Claude=dark  blue;  Bard=white).  All  mean  Likert  scale  and  adjusted\npercentage ratings (%) with their standard deviations are shown in the first table in the lower section\nof the figure. Adjusted average percentage ratings were calculated as the mean of normalized scores,\nusing the formula: Adjusted Percentage Rating = ((Actual Likert Score - 1) / (Likert Scale Maximum\n- 1)) x 100%, to scale responses uniformly from 0 to 100%. The second table includes the weighted\npercentage agreement (WPA) point estimates with their 95% confidence intervals.\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nTable 1. Results of Normality Test (Shapiro-Wilk), Homoscedasticity Test (Levene), Nonparametric\nTest  (Kruskal-Wallis),  Post  Hoc  Pairwise  Comparison  of  Nonparametric  Data  (Dunn  Test  with\nBonferroni Correction), Parametric Test (Analysis of Variance), and Post Hoc Pairwise Comparison\nof Parametric Data (Tukey's Honestly Significant Differences Test with Bonferroni Correction).\nTest Value P value\nShapiro-Wilk\nChatGPT Accuracy, W statistic 0.862 <.001\nClaude Accuracy, W statistic 0.711 <.001\nBard Accuracy, W statistic 0.87 <.001\nChatGPT Relevance, W statistic 0.845 <.001\nClaude Relevance, W statistic 0.604 <.001\nBard Relevance, W statistic 0.917 .008\nChatGPT Clarity, W statistic 0.886 .001\nClaude Clarity, W statistic 0.747 <.001\nBard Clarity, W statistic 0.933 .024\nChatGPT Emotional sensitivity, W statistic 0.965 .27\nClaude Emotional sensitivity, W statistic 0.953 .11\nBard Emotional sensitivity, W statistic 0.959 .181\nLevene\nAccuracy, F2 statistic 2.144 .122\nRelevance, F2 statistic 5.009 .008\nClarity, F2 statistic 1.918 .152\nEmotional sensitivity, F2 statistic 0.184 .833\nKruskal-Wallis\nAccuracy, H statistic 27.363 <.001\nRelevance, H statistic 29.074 <.001\nClarity, H statistic 32.745 <.001\nDunn Test with Bonferroni\nAccuracy, ChatGPT vs Claude, Z statistic -2.546 .004\nAccuracy, ChatGPT vs Bard, Z statistic 1.56 .147\nAccuracy, Claude vs Bard, Z statistic 4.106 <.001\nRelevance, ChatGPT vs Claude, Z statistic -2.872 <.001\nRelevance, ChatGPT vs Bard, Z statistic 1.235 .342\nRelevance, Claude vs Bard, Z statistic 4.107 <.001\nClarity, ChatGPT vs Claude, Z statistic -2.546 .004\nClarity, ChatGPT vs Bard, Z statistic 1.972 .038\nClarity, Claude vs Bard, Z statistic 4.518 <.001\nAnalysis of Variance (ANOV A)\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nEmotional sensitivity, F statistic 10.799 <.001\nTukey's HSD Test with Bonferroni\nEmotional sensitivity, ChatGPT vs Claude, Q statistic -0.974 <.001\nEmotional sensitivity, Bard vs ChatGPT, Q statistic 0.21 .607\nEmotional sensitivity, Claude vs Bard, Q statistic 0.763 .002\nDiscussion\nOur  investigation  revealed  a  promising  potential  for  the  use  of  LLMs  for  patient  education.\nAnthropic’s Claude-2 had significantly higher percentage average ratings of above 90% for accuracy\n(P=.004,  P<.001), relevance ( P<.001), and clarity ( P=.004,  P<.001), compared to ChatGPT and\nBard. It also scored significantly better on emotional sensitivity than ChatGPT and Bard ( P<.001,\nP=.002), with 74.3%. In a study parallel to ours, Sezgin et al. assessed the clinical accuracy of LLMs\nin the context of postpartum depression, demonstrating their efficacy in providing clinically accurate\ninformation,  a  finding  that  complements  our  study’s  illustration  of  LLMs’ potential  in  patient\neducation and engagement [8]. By providing accurate and timely information, LLMs can potentially\nalleviate patient concerns. \nLimitations\nThe study's limitations include the absence of direct patient input in questionnaire formulation, lack\nof repeated zero-shot questioning which may reveal variability, and no dedicated analysis of overtly\ninaccurate hallucinations. The principal challenge for LLM deployment in clinical settings lies in its\nregulatory  approval  and  secure  integration  within  healthcare  systems  [9].  We  are  actively\nconceptualizing a randomized clinical trial (RCT), controlling for these limitations, to investigate\nLLM and surgeon responses as rated by patients and surgeons.\nConclusions\nWhile  surgeons  remain  indispensable  in  patient  education,  LLMs  can  potentially  serve  as  a\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\ncomplementary tool, enhancing information delivery and supporting patient-surgeon interactions.\nAuthors’ Contributions\nWCW is  the  guarantor  of  the  study.  MMD  and  WCW led  conceptualization,  data  acquisition,\nanalysis,  drafting  and  revision  of  the  manuscript.  JG  and  KM  contributed  to  data  acquisition,\nanalysis, and drafting. Blinded scoring was performed by MMD and FCO. All authors contributed to\nanalysis, interpretation, and drafting. JWY , AKO, and WCW contributed critical guidance at all\nstages of the study. The manuscript was reviewed, edited, and its final version approved by all\nauthors.\nConflicts of Interest\nThe authors declare that they have no conflicts of interest.\nData Availability\nAll data generated or analyzed during this study are included in this published article (Multimedia\nAppendix 1).\nAbbreviations\nANOV A: analysis of variance\nEMR: electronic medical record\nHSD: honestly significant difference\nIRB: institutional review board\nLLM: large language model\nNLP: natural language processing\nRCT: randomized clinical trial\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nWPA: weighted percentage agreement\nReferences\n1. Kevin R. The Brilliance and Weirdness of ChatGPT. 2022 [cited 2023 August 28]; Available\nfrom: https://www.nytimes.com/2022/12/05/technology/chatgpt-ai-twitter.html.\n2. Davenport T, Kalakota R. The potential for artificial intelligence in healthcare. Future Healthc\nJ. 2019 Jun;6(2):94-8. PMID: 31363513. doi: 10.7861/futurehosp.6-2-94.\n3. Mofatteh  M.  Neurosurgery  and  artificial  intelligence.  AIMS  Neurosci.  2021;8(4):477-95.\nPMID: 34877400. doi: 10.3934/Neuroscience.2021025.\n4. Wongkietkachorn A, Wongkietkachorn N, Rhunsiri P. Preoperative Needs-Based Education to\nReduce Anxiety, Increase Satisfaction, and Decrease Time Spent in Day Surgery: A Randomized\nControlled Trial. World J Surg. 2018 Mar;42(3):666-74. PMID: 28875242. doi: 10.1007/s00268-017-\n4207-0.\n5. Williams S, Weinman J, Dale J. Doctor-patient communication and patient satisfaction: a\nreview. Fam Pract. 1998 Oct;15(5):480-92. PMID: 9848436. doi: 10.1093/fampra/15.5.480.\n6. Sullivan GM, Artino AR, Jr. Analyzing and interpreting data from likert-type scales. J Grad\nMed Educ. 2013 Dec;5(4):541-2. PMID: 24454995. doi: 10.4300/JGME-5-4-18.\n7. Preston CC, Colman AM. Optimal number of response categories in rating scales: reliability,\nvalidity,  discriminating  power,  and  respondent  preferences.  Acta  Psychol  (Amst).  2000\nMar;104(1):1-15. PMID: 10769936. doi: 10.1016/s0001-6918(99)00050-5.\n8. Sezgin E, Chekeni F, Lee J, Keim S. Clinical Accuracy of Large Language Models and\nGoogle  Search  Responses  to  Postpartum  Depression  Questions:  Cross-Sectional  Study.  J  Med\nInternet Res. 2023 Sep 11;25:e49240. PMID: 37695668. doi: 10.2196/49240.\n9. Malik P, Pathania M, Rathaur VK. Overview of artificial intelligence in medicine. Journal of\nfamily  medicine  and  primary  care.  2019;8(7):2328.  PMID:  31463251.  doi:\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\n10.4103/jfmpc.jfmpc_440_19.\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nSupplementary Files\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nFigures\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nBar chart of adjusted percentage average ratings of large language model responses (ChatGPT=light blue; Claude=dark blue;\nBard=white). All mean Likert scale and adjusted percentage ratings (%) with their standard deviations are shown in the first\ntable in the lower section of the figure. Adjusted average percentage ratings were calculated as the mean of normalized scores,\nusing the formula: Adjusted Percentage Rating = ((Actual Likert Score - 1) / (Likert Scale Maximum - 1)) x 100%, to scale\nresponses uniformly from 0 to 100%. The second table includes the weighted percentage agreement (WPA) point estimates\nwith their 95% confidence intervals.\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nMultimedia Appendixes\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n\nJMIR Preprints Dagli et al\nAverage ratings of large language model responses for accuracy, relevance, clarity, and emotional sensitivity.\nURL: http://asset.jmir.pub/assets/05d55516653e0a706a8d94997492d913.xlsx\nResponses to surgical patient questions.\nURL: http://asset.jmir.pub/assets/ba46415621f057f797434a4d554e863d.xlsx\nPowered by TCPDF (www.tcpdf.org)\nhttps://preprints.jmir.org/preprint/56165 [unpublished, peer-reviewed preprint]\n",
  "topic": "CLARITY",
  "concepts": [
    {
      "name": "CLARITY",
      "score": 0.9268032908439636
    },
    {
      "name": "Cross-sectional study",
      "score": 0.7234422564506531
    },
    {
      "name": "Relevance (law)",
      "score": 0.6901684999465942
    },
    {
      "name": "Clinical significance",
      "score": 0.5216572284698486
    },
    {
      "name": "Psychology",
      "score": 0.47175106406211853
    },
    {
      "name": "Medicine",
      "score": 0.35920125246047974
    },
    {
      "name": "Pathology",
      "score": 0.09875848889350891
    },
    {
      "name": "Political science",
      "score": 0.08420819044113159
    },
    {
      "name": "Law",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    },
    {
      "name": "Biochemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I1281539108",
      "name": "Hospital for Special Surgery",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I79576946",
      "name": "University of Pennsylvania",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I79619799",
      "name": "University of Birmingham",
      "country": "GB"
    }
  ]
}