{
    "title": "Combining protein sequences and structures with transformers and equivariant graph neural networks to predict protein function",
    "url": "https://openalex.org/W4382632527",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A4207520657",
            "name": "Frimpong Boadu",
            "affiliations": [
                "University of Missouri"
            ]
        },
        {
            "id": "https://openalex.org/A2114333927",
            "name": "Hongyuan Cao",
            "affiliations": [
                "Florida State University"
            ]
        },
        {
            "id": "https://openalex.org/A2141057972",
            "name": "Jianlin Cheng",
            "affiliations": [
                "University of Missouri"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2158714788",
        "https://openalex.org/W2130479394",
        "https://openalex.org/W3143063265",
        "https://openalex.org/W2045204781",
        "https://openalex.org/W3137270128",
        "https://openalex.org/W2098432760",
        "https://openalex.org/W2001338440",
        "https://openalex.org/W2514044079",
        "https://openalex.org/W3177500196",
        "https://openalex.org/W3164046276",
        "https://openalex.org/W2108984616",
        "https://openalex.org/W3177828909",
        "https://openalex.org/W4236358448",
        "https://openalex.org/W4220952154",
        "https://openalex.org/W2100494857",
        "https://openalex.org/W4293046261",
        "https://openalex.org/W2167318540",
        "https://openalex.org/W2117486996",
        "https://openalex.org/W3146944767",
        "https://openalex.org/W2950954328",
        "https://openalex.org/W3211795435",
        "https://openalex.org/W2117694558",
        "https://openalex.org/W3179436811",
        "https://openalex.org/W2951282333",
        "https://openalex.org/W2951731136",
        "https://openalex.org/W2611792444",
        "https://openalex.org/W2989608901",
        "https://openalex.org/W2966590054"
    ],
    "abstract": "Abstract Motivation Millions of protein sequences have been generated by numerous genome and transcriptome sequencing projects. However, experimentally determining the function of the proteins is still a time consuming, low-throughput, and expensive process, leading to a large protein sequence-function gap. Therefore, it is important to develop computational methods to accurately predict protein function to fill the gap. Even though many methods have been developed to use protein sequences as input to predict function, much fewer methods leverage protein structures in protein function prediction because there was lack of accurate protein structures for most proteins until recently. Results We developed TransFunâ€”a method using a transformer-based protein language model and 3D-equivariant graph neural networks to distill information from both protein sequences and structures to predict protein function. It extracts feature embeddings from protein sequences using a pre-trained protein language model (ESM) via transfer learning and combines them with 3D structures of proteins predicted by AlphaFold2 through equivariant graph neural networks. Benchmarked on the CAFA3 test dataset and a new test dataset, TransFun outperforms several state-of-the-art methods, indicating that the language model and 3D-equivariant graph neural networks are effective methods to leverage protein sequences and structures to improve protein function prediction. Combining TransFun predictions and sequence similarity-based predictions can further increase prediction accuracy. Availability and implementation The source code of TransFun is available at https://github.com/jianlin-cheng/TransFun.",
    "full_text": null
}