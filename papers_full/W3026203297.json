{
    "title": "How effective are smart contract analysis tools? evaluating smart contract static analysis tools using bug injection",
    "url": "https://openalex.org/W3026203297",
    "year": 2020,
    "authors": [
        {
            "id": "https://openalex.org/A2230011734",
            "name": "Asem Ghaleb",
            "affiliations": [
                "University of British Columbia"
            ]
        },
        {
            "id": "https://openalex.org/A2184603505",
            "name": "Karthik Pattabiraman",
            "affiliations": [
                "University of British Columbia"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W2778144710",
        "https://openalex.org/W2538848838",
        "https://openalex.org/W1480909796",
        "https://openalex.org/W2515236103",
        "https://openalex.org/W2970809537",
        "https://openalex.org/W2788841915",
        "https://openalex.org/W2769609281",
        "https://openalex.org/W2846896781",
        "https://openalex.org/W2888928288",
        "https://openalex.org/W2539190473",
        "https://openalex.org/W2999378142",
        "https://openalex.org/W2890728226",
        "https://openalex.org/W2560041978",
        "https://openalex.org/W2019230987",
        "https://openalex.org/W2805827286",
        "https://openalex.org/W2805052744"
    ],
    "abstract": "Security attacks targeting smart contracts have been on the rise, which have\\nled to financial loss and erosion of trust. Therefore, it is important to\\nenable developers to discover security vulnerabilities in smart contracts\\nbefore deployment. A number of static analysis tools have been developed for\\nfinding security bugs in smart contracts. However, despite the numerous\\nbug-finding tools, there is no systematic approach to evaluate the proposed\\ntools and gauge their effectiveness. This paper proposes SolidiFI, an automated\\nand systematic approach for evaluating smart contract static analysis tools.\\nSolidiFI is based on injecting bugs (i.e., code defects) into all potential\\nlocations in a smart contract to introduce targeted security vulnerabilities.\\nSolidiFI then checks the generated buggy contract using the static analysis\\ntools, and identifies the bugs that the tools are unable to detect\\n(false-negatives) along with identifying the bugs reported as false-positives.\\nSolidiFI is used to evaluate six widely-used static analysis tools, namely,\\nOyente, Securify, Mythril, SmartCheck, Manticore and Slither, using a set of 50\\ncontracts injected by 9369 distinct bugs. It finds several instances of bugs\\nthat are not detected by the evaluated tools despite their claims of being able\\nto detect such bugs, and all the tools report many false positives\\n",
    "full_text": "How Effective are Smart Contract Analysis\nTools? Evaluating Smart Contract Static\nAnalysis Tools Using Bug Injection\nAsem Ghaleb\naghaleb@alumni.ubc.ca\nUniversity of British Columbia\nVancouver, Canada\nKarthik Pattabiraman\nkarthikp@ece.ubc.ca\nUniversity of British Columbia\nVancouver, Canada\nABSTRACT\nSecurity attacks targeting smart contracts have been on the rise,\nwhich have led to financial loss and erosion of trust. Therefore,\nit is important to enable developers to discover security vulnera-\nbilities in smart contracts before deployment. A number of static\nanalysis tools have been developed for finding security bugs in\nsmart contracts. However, despite the numerous bug-finding tools,\nthere is no systematic approach to evaluate the proposed tools\nand gauge their effectiveness. This paper proposes SolidiFI, an au-\ntomated and systematic approach for evaluating smart contracts’\nstatic analysis tools. SolidiFI is based on injecting bugs (i.e., code\ndefects) into all potential locations in a smart contract to introduce\ntargeted security vulnerabilities. SolidiFI then checks the generated\nbuggy contract using the static analysis tools, and identifies the\nbugs that the tools are unable to detect (false-negatives) along with\nidentifying the bugs reported as false-positives. SolidiFI is used to\nevaluate six widely-used static analysis tools, namely, Oyente, Secu-\nrify, Mythril, SmartCheck, Manticore and Slither, using a set of 50\ncontracts injected by 9369 distinct bugs. It finds several instances\nof bugs that are not detected by the evaluated tools despite their\nclaims of being able to detect such bugs, and all the tools report\nmany false positives.\nCCS CONCEPTS\n• Security and privacy →Software and application security ;\nKEYWORDS\nEthereum, Ethereum security, solidity code analysis, smart con-\ntracts, smart contracts security, smart contracts analysis, smart\ncontracts dataset, static analysis tools evaluation, bug injection,\nfault injection\nACM Reference Format:\nAsem Ghaleb and Karthik Pattabiraman. 2020. How Effective are Smart\nContract Analysis Tools? Evaluating Smart Contract Static Analysis Tools\nUsing Bug Injection. In Proceedings of the 29th ACM SIGSOFT International\nSymposium on Software Testing and Analysis (ISSTA ’20), July 18–22, 2020,\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\n© 2020 Association for Computing Machinery.\nACM ISBN 978-1-4503-8008-9/20/07. . . $15.00\nhttps://doi.org/10.1145/3395363.3397385\nLos Angeles/Virtual, CA, USA. ACM, New York, NY, USA, 13 pages. https:\n//doi.org/10.1145/3395363.3397385\n1 INTRODUCTION\nThe past few years have witnessed a dramatic rise in the popularity\nof smart contracts [Clack et al . 2016]. Smart contracts are small\nprograms written into blocks running on top of a blockchain that\ncan receive and execute transactions autonomously without trusted\nthird parties [Grishchenko et al. 2018]. Ethereum [Buterin 2014] is\nthe most popular framework for executing smart contracts.\nLike all software, smart contracts may contain bugs. Unfortu-\nnately, bugs in smart contracts can be exploited by malicious attack-\ners for financial gains. In addition, transactions on Ethereum are\nimmutable and cannot be reverted, so losses cannot be recovered.\nFurther, it is difficult to update a smart contract after its deployment.\nConsequently, there have been many bugs in smart contracts that\nhave been maliciously exploited in the recent past [dao 2016; par\n2017; Mathieu and Mathee 2017]. Therefore, there is a compelling\nneed to analyze smart contracts to detect and fix security bugs.\nSeveral approaches and tools have been developed that statically\nfind security bugs in smart contracts [Feist et al. 2019; Luu et al. 2016;\nMueller 2018; Tikhomirov et al. 2018; Tsankov et al. 2018]. However,\ndespite the prevalence of these static analysis tools, security bugs\nabound in smart contracts [Perez and Livshits 2019]. This calls into\nquestion the efficacy of these tools and their associated techniques.\nUnfortunately, many of the static analysis tools have been evaluated\neither only by their developers on custom data-sets and inputs, often\nin an ad-hoc manner, or on data-sets of contracts with a limited\nnumber of bugs (112 bugs [Durieux et al. 2019] and 10 bugs [Parizi\net al. 2018]). To the best of our knowledge, there is no systematic\nmethod to evaluate static analysis tools for smart contracts regarding\ntheir effectiveness in finding security bugs.\nTypically, static analysis tools can have both false-positives and\nfalse-negatives. While false positives are important, false negatives\nin smart contracts can lead to critical consequences, as exploiting\nbugs in contracts usually leads to loss of ether (money). Also, em-\npirical studies of software defects in the field have found that many\nof the defects can be detected by static analysis tools in theory, but\nare not detected due to limitations of the tools [Thung et al. 2012].\nIn our work, we focus mostly on the undetected bugs (i.e., false\nnegatives), though we also study false-positives of the tools.\nWe perform bug injection to evaluate the false-negatives of smart\ncontract static analysis tools. Bug injection as a testing approach\nhas been extensively explored in the domain of traditional programs\n[Bonett et al. 2018; Dolan-Gavitt et al. 2016; Pewny and Holz 2016];\narXiv:2005.11613v1  [cs.SE]  23 May 2020\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\nhowever, there have been few papers on bug injection in the context\nof smart contracts. This problem is challenging for two reasons.\nFirst, smart contracts on Ethereum are written using the Solidity\nlanguage, which differs from conventional programming languages\ntypically targeted by mutation testing tools [Dannen 2017]. Second,\nbecause our goal is to inject security bugs, the bugs injected should\nlead to exploitable vulnerabilities.\nThis paper proposes SolidiFI1, a methodology for systematic eval-\nuation of smart contracts’ static analysis tools to discover potential\nflaws in the tools that lead to undetected security bugs. SolidiFI\ninjects bugs formulated as code snippets into all possible locations\ninto a smart contract’s source code written in Solidity. The code\nsnippets are vulnerable to specific security vulnerabilities that can\nbe exploited by an attacker. The resulting buggy smart contracts\nare then analyzed using the static analysis tools being evaluated,\nand the results are inspected for those injected bugs that are not\ndetected by each tool - these are the false-negatives of the tool.\nBecause our methodology is agnostic of the tool being evaluated, it\ncan be applied to any static analysis tool that works on Solidity.\nWe make the following contributions in this paper.\n•Design a systematic approach for evaluating false-negatives\nand false-positives of smart contracts’ static analysis tools.\n•Implement our approach as an automated tool, SolidiFI, to\ninject security bugs into smart contracts written in Solidity.\n•Use SolidiFI to evaluate six static analysis tools of Ethereum\nsmart contracts for false-negatives and false-positives.\n•Provide an analysis of the undetected security bugs and\nfalse-positives for the 6 tools, and the reasons behind them.\nThe results of using SolidiFI on 50 contracts show that all of\nthe evaluated tools had significant false-negatives ranging from\n129 to 4137 undetected bugs across 7 different bug types despite\ntheir claims of being able to detect such bugs, as well as many\nfalse positives. Further, many of the undetected bugs were found\nto be exploitable when the contract is executed on the blockchain.\nFinally, we find that SolidiFI takes less than 1 minute to inject bugs\ninto a smart contract (on average). Our results can be used by\ntool developers to enhance the evaluated tools, and by researchers\nproposing new bug-finding tools for smart contracts.\n2 BACKGROUND\n2.1 Smart Contracts\nAs mentioned earlier, smart contracts are written in a high-level\nlanguage such as Solidity. They are compiled to Ethereum Vir-\ntual Machine (EVM) bytecode that is deployed and stored in the\nblockchain accounts. Smart contract transactions are executed by\nminers, which are a network of mutually untrusted nodes, and\ngoverned by the consensus protocol of the blockchain. Miners re-\nceive execution fees, called gas, for running the transactions which\nare paid by the users who submit the execution requests. We illus-\ntrate smart contracts through a running example shown in Figure 1\n(adapted from prior work [Atzei et al. 2017]).\nThis contract implements a public game that enables users to\nplay a game and submit their guesses or solutions for the game\nalong with some amount of money. The money will be transferred\n1SolidiFI stands for Solidity Fault Injector, pronounced as Solidify.\n1 pragma solidity >=0.4.21 <0.6.0;\n2 contract EGame {\n3 address payable private winner ;\n4 uint startTime ;\n5\n6 constructor () public {\n7 winner = msg . sender ;\n8 startTime = block . timestamp ;}\n9\n10 function play (bytes32 guess ) public {\n11 if ( keccak256 ( abi . encode ( guess )) ==keccak256 ( abi .\nencode ( 'solution '))){\n12 if ( startTime + (5 * 1 days ) == block . timestamp\n){\n13 winner = msg . sender ;}}}\n14\n15 function getReward () payable public {\n16 winner . transfer ( msg . value );}\n17 }\nFigure 1: Simple contract written in Solidity.\nto the account of the last winner if the guess is wrong; otherwise the\nuser will be set as the current winner and will receive the money\nfrom users who play later. The constructor() at line 6 runs only\nonce when the contract is created, and it sets the initial winner to\nthe owner of the contract defined by the user who submitted the\ncreate transaction of the contract ( msg.sender). It also initializes\nthe startTime variable to the current timestamp during the contract\ncreation. The function play at line 10 is called by the user who\nwants to submit his/her guess, and it compares the received guess\nwith the true guess value. If the comparison is successful, it sets the\nwinner to the address of the user account who called this function,\nprovided the guess was submitted within 5 days of creating the\ncontract. Finally, the function getReward sends the amount of ether\nspecified in the call to getReward (msg.value), to the last winner.\n2.2 Static Analysis Tools\nWe consider six static analysis tools for finding bugs in smart con-\ntracts in this paper, Oyente, Securify, Mythril, Smartcheck, Man-\nticore, and Slither. They all operate on smart contracts written in\nSolidity, and are freely available. Further, they are all automated\nand require no annotations from the programmer. We selected\nOyente [Luu et al. 2016], Securify [Tsankov et al. 2018], Mythril\n[Mueller 2018], and Manticore [Mossberg et al. 2019] as they were\nused in many smart contract analysis studies [Brent et al . 2018;\nParizi et al. 2018; Perez and Livshits 2019; Tsankov et al. 2018]. We\nincluded Smartcheck [Tikhomirov et al. 2018] as it uses a pattern\nmatching approach rather than symbolic execution employed by\nthe previous four tools. Similarly Slither [Feist et al. 2019] is another\nnon-symbolic-execution based tool, but unlike SmartCheck, it uses\nStatic Single Assignment (SSA) for analysis.\n3 MOTIVATION AND CHALLENGES\nThis section first presents motivating examples of undetected secu-\nrity bugs by static analysis tools, followed by an overview of the\nchallenges in the evaluation of the tools.\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\n11 uint _vtime = block . timestamp ;\n12 if ( startTime + (5 * 1 days ) == _vtime ){\nFigure 2: Modification made to the contract in Figure 1\n3.1 Motivating examples\nThe contract example in Figure 1 has at least 2 vulnerabilities,\n(1) two instances of timestamp dependency bug at lines 8 and 12,\nand (2) one instance of transaction ordering dependence (TOD)\nrepresented by the transactions at lines 13 and 16. The timestamp\ndependency bug is that the block’s timestamp should not be used\nin the transaction, while the TOD bug is that the state of the smart\ncontract should not be relied upon by the developer (Section 7).\nWe have used four of the static analysis tools in Section 2 (sup-\nposed to detect these bugs) to check this contract for bugs, Oyente,\nSecurify, Mythril, and SmartCheck. According to the tools’ re-\nsearch papers [Luu et al . 2016; Mueller 2018; Tikhomirov et al .\n2018; Tsankov et al. 2018], Oyente, Mythril and SmartCheck should\ndetect the timestamp dependency bug. However, we found that\nwhile Oyente and Mythrill were not able to detect both instances of\ntimestamp dependency bug in lines 8 and 12, Smartcheck detected\nonly the instance in line 12. For the second instance, Smartcheck\ngave a hint that block.timestamp should be “used only in equalities”.\nTo further test SmartCheck’s ability to detect the bug, we made a\nsmall modification to the syntax of the smart contract while keep-\ning its semantics the same (Figure 2). SmartCheck subsequently\nfailed to detect the bug altogether.\nRegarding the TOD bug, both Oyente and Securify are supposed\nto detect this class of bugs. However, we found that only Securify\ndetected this bug successfully while Oyente was not able to detect it.\nWe extracted the code snippet representing TOD from this contract\n(lines 10 to 16), injected it in another larger contract free of bugs,\nand obtained similar results.\nThese examples motivated us to prepare multiple code snippets\nfor the different bugs (within the scope of the tools) and to manually\ninject them into the code of 5 smart contracts (the first 5 contracts\nin the set of contracts in Section 7). We then used the tools to check\nthe buggy contracts, and found several instances of undetected bugs\neven though the tools were supposed to detect them. However, it\nwas tedious and error-prone to manually inject these bugs and\ninspect the results, and so we decided to automate this process.\n3.2 Automated bug injection challenges\nThe simplest way to inject bugs into smart contracts is to inject\nthem at random locations - this is how traditional fault injection\n(i.e., mutation testing) works. However, random injection is not a\ncost-effective approach as we have to follow specific guidelines for\nthe injected bug to be exploitable. We identify two main challenges.\n3.2.1 Bug injection locations. As the underlying techniques used\nby some tools (e.g., symbolic execution) depends on the control and\ndata flow in the analyzed contracts, injecting an instance of each\nbug at a single location would not be sufficient. Therefore, bugs\nshould be injected into all potential locations in the contract code.\nOn the other hand, the process of identifying the potential locations\ndepends on the code of the original contract, and also on the type\nand nature of each bug. Injecting bugs at the wrong locations would\nresult in compilation errors. In addition, it might yield instances of\ndead code in the contract. For example, injecting a bug formulated\nas a stand-alone function inside the body of another function would\nresult in a compilation error, as Solidity does not support nested\nfunctions. Moreover, a bug injected into an ’if’ statement condition\nthat would make the condition always fail, would make the ’then’\nclause unreachable.\n3.2.2 Semantics dependency. For the injected bug to be an active\nbug that can be exploited by an attacker, it has to be aligned with\nthe semantics of the original contract. For example, assume that we\nwant to inject a Denial of Service (DoS) bug by calling an external\ncontract. We can use an if-statement with a condition containing\na call to another contract function. However, for this bug to be\nexecuted, we also need to define the appropriate external contract.\nSolidiFI addresses the first challenge by parsing the Solidity lan-\nguage into an Abstract Syntax Tree (AST) and injecting bugs into\nall syntactically valid locations. It addresses the second challenge\nby formulating exploitable code snippets for each bug type.\n4 SOLIDIFI APPROACH AND WORKFLOW\nThe main goal ofSolidiFI is to perform systematic evaluation ofstatic\nanalysis tools used to check smart contracts for known security\nbugs. Figure 3 shows the workflow of SolidiFI. The code snippets\nrepresenting a specific security bug are injected in each smart\ncontract’s source code atall possible locations (step 1). The selection\nof the injection locations is a function of the bug to be injected.\nSolidiFI injects bugs into the source code to imitate the introduction\nof bugs by developers. However, its use is not restricted to tools that\nperform analysis at the source code level. For example, tools that work\non the EVM bytecode would compile the buggy contracts to produce\nthe EVM code for analysis. Then, the injected code is scanned using\nthe static analysis tools (step 2). Finally, the results of each tool are\nchecked, and false negatives and false positives are measured (step\n3).\nFigure 3: SolidiFI Workflow.\n4.1 Bug Model\nIn our work, a security bug is expressed as a code snippet, which\nleads to a vulnerability that the security tool being analyzed aims to\ndetect. SolidiFI reads code snippets to be injected from a pre-defined\nbug pool prepared by us (the bug pool can be easily extended by\nusers to add new bugs). For each tool, we only inject the bugs\nthat the tool claims to detect. based on the tool’s research paper.\nHowever, because the tools are continuously evolving, the research\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\npaper may not have the up-to-date list of bugs detected by the tool,\nand hence we use the tool’s online documentation to augment it.\n4.2 Bug Injection\nIn this work, the security bugs are injected in the source code in\nthree ways as follows.\n4.2.1 Full code snippet. In this approach, we prepare several code\nsnippets for each bug under study. Each code snippet is a piece of\ncode that introduces the security bug. To illustrate the process, we\ndiscuss the bugs and example code snippets.\nTimestamp dependency. The current timestamp of the block\ncan be used by contracts to trigger some time-dependent events.\nGiven the decentralized nature of Ethereum, miners can change\nthe timestamp (to some extent). Malicious miners can use this\ncapability and change the timestamp to favor themselves. This\nbug was exploited in the GoverMental Ponzi scheme attack [Eth\n[n.d.]]. Therefore, developers should not rely on the precision of the\nblock’s timestamp. Figure 4 shows an example of a code snippet that\nrepresents the bug (block.timestamp returns the block’s timestamp).\n1 function bug_tmstmp () public returns ( bool )\n2 { return block . timestamp >= 1546300;}\nFigure 4: Timestamp dependency examples.\nUnhandled exceptions. In Ethereum, contracts can call each\nother, and send ether to each other (e.g., send instruction, call in-\nstruction, etc.). If an exception is thrown by the callee contact (e.g.,\nlimited gas for execution), the contract is terminated, its state is\nreverted, and false is returned to the caller contract. Therefore,\nunchecked returned values within the caller contract could be used\nto attack the contract, leading to undesired behavior. A serious\nversion of this bug occurred in the “King of the Ether\" [Eth [n.d.]].\nFigure 5 shows an example (thesend() instruction requires its return\nvalue to be checked for exceptions to make it secure).\n1 function unhandledsend () public {\n2 callee . send (5 ether );}\nFigure 5: Unhandled exceptions examples.\nInteger overflow/underflow. In Solidity, storing a value in\nan integer variable bigger or smaller than its limits lead to integer\noverflow or underflow. This can be used by attackers to fraudulently\nsiphon off funds. For example, Figure 6 shows an example code\nsnippet in which an attacker can reset the lockTime for a user by\ncalling the function incrLockTime and passing 256 as an argument -\nthis would cause an overflow, and end up setting the lockTime to 0.\nBatch Transfer Overflow is a real-world example [PoW [n.d.]].\nUse of tx.origin. In a chain of calls, when contracts call func-\ntions of each other, the use of tx.origin (that returns the first caller\nthat originally sent the call) for authentication instead ofmsg.sender\n(that returns the immediate caller) can lead to phishing-like attacks\n[sol [n.d.]]. Figure 7 shows an example snippet in which tx.origin is\nused to withdraw money.\n1 function incrLockTime ( uint _sec ) public {\n2 lockTime [ msg . sender ] += _sec ;}\nFigure 6: Integer overflow/underflow example.\n1 function bug_txorigin ( address _recipient ) public {\n2 require (tx . origin == owner );\n3 _recipient . transfer ( this . balance );}\nFigure 7: tx.origin authentication example.\nRe-entrancy. Contracts expose external calls in their interface.\nThese external calls can be hijacked by attackers to call a func-\ntion within the contract itself several times, thereby performing\nunexpected operations within the contract itself. For example, the\nexternal call in Line 3 of the snippet code shown in Figure 8 can be\nused by an attacker to call thebug_reEntrancy() function repeatedly,\npotentially leading to withdrawal of ether more than the balance\nof the user. The DAO attack [dao 2016] is a well-known example\nexploiting this bug.\n1 function bug_reEntrancy ( uint256 _Amt ) public {\n2 require ( balances [msg . sender ] >= _Amt );\n3 require ( msg . sender . call . value ( _Amt ));\n4 balances [ msg . sender ] -= _Amt ;}\nFigure 8: Re-entrancy example.\nUnchecked send. Unauthorized Ether transfer, such as non\nzero sends, can be called by external users if they are visible to\npublic, even if they do not have the correct credentials. This means\nunauthorized users can call such functions and transfer ether from\nthe vulnerable contract [sol [n.d.]]. An example code snippet is\nshown in Figure 9.\n1 function bug_unchkSend () payable public {\n2 msg . sender . transfer (1 ether );}\nFigure 9: Unchecked send example.\nTransaction Ordering Dependancy (TOD). Changing the or-\nder of the transactions in a single block that has multiple calls to\nthe contract, results in changing the final output [Atzei et al. 2017].\nMalicious miners can benefit from this. An example code snippet\nvulnerable to this bug is shown in Figure 10. In this example, the\nattackers can send a puzzle solving reward to themselves instead of\nthe winner of the game by executing bug_tod2() before bug_tod1().\n4.2.2 Code transformation. This approach aims to transform a\npiece of code without changing its functionality, but make it vul-\nnerable to a specific bug. We leverage known patterns of vulnerable\ncode to inject this bug. We use this approach to inject two bug\nclasses that are compatible with this approach, namely (1) integer\noverflow/underflow and (2) use of tx.origin.\nTable 1 shows examples of the code patterns that are replaced to\nintroduce the bugs, and the vulnerable patterns for each bug type.\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\n1 address payable winner_tod ;\n2 function setWinner_tod () public {\n3 winner_tod = msg . sender ;}\n4 function getReward_tod () payable public {\n5 winner_tod . transfer ( msg . value );}\nFigure 10: TOD example.\nTable 1: Code transformation patterns.\nBug Type Original Code Patterns New Code Patterns\ntx.origin msg.sender==owner tx.origin==owner\nOverflow bytes32 bytes8\nOverflow uint256 uint8\nFigure 11 shows an example before and after bug injection us-\ning this approach. In this example, transfer instruction is used to\nperform a transfer of the specified ether amount to the receiver’s\naccount after verifying the direct caller of sendto() to be the owner.\nTo inject the tx.origin bug, the authorization condition msg.sender\n== owner should be replaced with the tx.origin == owner , in which\nthe owner is not the direct caller of sendto(). However, the autho-\nrization check is passed successfully, which enables attackers to\nauthorize themselves, and send ether from the contract, even if they\nare not the owner.\n1 /*( Before )*/\n2 function sendto ( address receiver , uint amount ) public\n{\n3 require ( msg . sender == owner );\n4 receiver . transfer ( amount );}\n5 /*( After injection )*/\n6 function sendto ( address receiver , uint amount ) public {\n7 require (tx . origin == owner );\n8 receiver . transfer ( amount );}\nFigure 11: Code transformation example.\n4.2.3 Weakening security mechanisms. In this approach, we weaken\nthe security protection mechanisms in the smart contract code,\nwhich protect external calls. Note that our goal is to evaluate the\nstatic analysis tool, and not the smart contract itself. We use this\napproach to inject Unhandled exception bugs. Figure 12 shows\nan example, in which the Unhandled exceptions bug is injected by\nremoving the revert() statement that reverts the state of the con-\ntract if the transfer transaction failed - this causes the balance to\nincorrectly become 0 even if the transaction failed.\n5 SOLIDIFI ALGORITHM\nThe process for injecting bugs takes as input the Abstract Syntax\nTree (AST) of the smart contract, and has the following steps.\n(1) Identify the potential locations for injecting bugs and gener-\nate an annotated AST marking all identified locations.\n(2) Inject bugs into all marked locations to generate the buggy\ncontract.\n1 /*( Before )*/\n2 function withdrawBal () public {\n3 Balances [ msg . sender ] = 0;\n4 if (! msg . sender . send ( Balances [msg . sender ]))\n5 { revert (); }}\n6 /*( After injection )*/\n7 function withdrawBal () public {\n8 Balances [ msg . sender ] = 0;\n9 if (! msg . sender . send ( Balances [msg . sender ]))\n10 { // revert ();\n11 }}\nFigure 12: Weakening security example.\n(3) Check the buggy contract using the evaluated tools and\ninspect the results for undetected bugs and false alarms.\nWe discuss the steps in detail below.\nBug locations identification: The AST is passed to Bug Loca-\ntions Identifier, that drives a bug injection profile (BIP) of all possible\ninjection locations in the target contract for a given security bug.\nThe BIP is derived using AST-based analysis for identifying po-\ntential injection locations in smart contract code by Algorithm 1.\nAlgorithm 1 takes as input the AST and the bug type to be injected,\nand outputs the BIP.\nAlgorithm 1 Identifying Injection Locations Algorithm\n1: procedure FindAllPotentialLocations(AST, bugType)\n2: for Each form of code snippets in bugType do\n3: if snippetForm == simple statement then\n4: BI P←W alkAST(simpleStatement )\n5: else if snippetForm == non-function block then\n6: BI P←W alkAST(nonFunctionBlock )\n7: else if snippetForm == functionDefinition then\n8: BI P←W alkAST(f unctionDef inition )\n9: end if\n10: end for\n11: BI P←FindRelatedSecurit yMechanisms\n12: BI P←FindCodeT hatCanBeT ransf ormed\n13: return BI P\n14: end procedure\nTo address the first challenge of identifying bug injection lo-\ncations as mentioned in Section 3.2, we define rules that specify\nthe relation between the bug to be injected and the target contract\nstructure. In general, bugs take two forms: an individual statement,\nand a block of statements. A block of statements can be defined\neither as a stand-alone function, or a non-function block such as\nan ’if’ statement. Therefore, we use a rule for each form of the bug\nthat defines the specifications of the locations for injecting it.\nTo identify such locations, for each distinct form of the code\nsnippets defining the bug type to be injected, we walk the AST\nbased on the code snippet form and the related rule (lines 2-10 in\nAlgorithm 1). W alkAST(simpleStatement ), for example, will visit\n(parse) the AST and find all the locations where a simple statement\ncan be injected without invalidating the compilation state of the\ncontract, and the same for the other forms of the code snippets\nof the bug type. After identifying the locations for injecting code\nsnippets of bugs, we also look for existing security mechanisms to\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\nbe weakened to introduce the related bug, and the code patterns to\nbe transformed for introducing the bug (lines 11 and 12).\nBug injection and code transformation: SolidiFI uses a sys-\ntematic approach to inject bugs into the potential locations in the\ntarget contract. The Bug Injector model seeds a bug for each loca-\ntion specified in the BIP. It uses text-based code transformation to\nmodify the code where the information derived from the AST is\nused to modify the code to inject bugs. Three different approaches\nare used to inject bugs as discussed in Section 4.2. In addition to\ninjecting bugs in the target contract, Bug Injector generates a Bu-\ngLog that specifies a unique identifier for each injected bug, and\nthe corresponding location(s) in the target contract where it has\nbeen injected.\nBuggy code check and results inspection: The resulting buggy\ncontract is passed to the Tool Evaluator that checks the buggy code\nusing the tools under evaluation. It then scans the results generated\nby the tools looking for the bugs that were injected but undetected,\nwith the help of BugLog generated by the Bug Injector . SolidiFI only\nconsiders the injected bugs that are undetected. So if an evalu-\nated tool reported bugs in locations other than where bugs have\nbeen injected, SolidiFI does not consider them in its output of false\nnegatives. This is to avoid potential vulnerabilities in the original\ncontract from being reported by SolidiFI, which would skew the\nresults. Moreover, SolidiFI inspects results generated by the tools\nlooking for other reported bugs and checks if they are true bugs or\nfalse alarms (more details in Section 7).\n6 IMPLEMENTATION\nSolidiFI approach is fully-automated (except for the pre-prepared\nbuggy snippets). This involves compiling the code, injecting and\ngenerating buggy contracts, running the evaluated tools on the\nbuggy contracts, and inspecting reports of the evaluated tools for\nfalse-negatives, mis-identified cases, and false-positives (except\nfor the manual validation of the filtered false-positives). To make\nSolidiFI reusable, we did not hard-code the patterns that are replaced\nto introduce bugs, but rather made them configurable from an\nexternal file. We have made SolidiFI code publicly available 2.\nSolidiFI uses the Solidity compiler solc (supports compiler ver-\nsions up to 0.5.12) to compile the source code of the smart contract\nto make sure it is free from compilation errors before bugs are\ninjected. In addition, SolidiFI uses solc to generate the AST of the\noriginal code in JavaScript Object Notation (JSON) format. We have\nimplemented the other components of SolidiFI in Python in about\n1500 lines of code. These components are responsible for identifying\nthe potential locations for injection, injecting bugs using a suitable\napproach, generating the buggy contract, and inspecting the results\nof the evaluated tools and then reporting the undetected bugs and\nfalse alarms. Finally, we developed a Python client to interact with\ncontracts deployed on Ethereum network - this client is used for\nassessing the exploitability of the injected bugs in the generated\nbuggy contracts.\n7 EVALUATION\nThe aim of our evaluation is to measure the efficacy of SolidiFI in\nevaluating smart contract static analysis tools, and finding cases of\n2 https://github.com/DependableSystemsLab/SolidiFI\nundetected bugs (i.e., false negatives) and false positives. We also\nmeasure the performance of SolidiFI itself, as well as the ability to\nexploit the undetected bugs. We made all the experimental artifacts\nused in this study and our results publicly available3. Our evaluation\nexperiments are thus derived to answer the following research\nquestions:\n• RQ1. What are the false negatives of the tools being evaluated?\n• RQ2. What are the false positives of the tools being evaluated?\n•RQ3. Can the injected bugs in the contracts be activated (i.e.,\nexploited) at runtime by an external attacker?\n•RQ4. What is the performance of SolidiFI?\nAs mentioned earlier, we have selected six static analysis tools\nfor evaluation, Oyente [Luu et al . 2016], Securify [Tsankov et al.\n2018], SmartCheck [Tikhomirov et al. 2018], Mythril [Mueller 2018],\nManticore [Mossberg et al. 2019], and Slither [Feist et al. 2019]. We\ndownloaded these tools from their respective online repositories,\nwhich are mentioned in the corresponding papers (Oyente 0.2.7,\nSecurify v1.0 as downloaded and installed in Dec 2019, Mythril\n0.21.20, Smartcheck 2.0, Manticore 0.3.2.1, and Slither 0.6.9).\nTo perform our experiments, we used a data set of fifty smart\ncontracts, chosen from the list of verified smart contracts available\non Etherscan [Etherscan [n.d.]], a public repository of smart con-\ntracts written in Solidity for Ethereum. We selected these contracts\nbased on three factors namely (1) code size (we selected contracts\nwith different sizes that were representative of Etherscan contracts\nranging from small contracts with tens of lines of code to large\ncontracts with hundreds of lines of code), (2) compatibility with\nSolidity version 0.5.12 (at the time of writing, 312 out of 500 verified\nsmart contracts in EtherScan supported Solidity 0.5x and higher),\nand (3) contracts with a wide range of functionality (e.g., tokens,\nwallets, games). Table 2 shows the number of lines of code (includ-\ning comments), and number of functions and function modifiers4\nfor each contract. The contracts range from 39 to 741 lines of code\n(loc), with an average of 242 loc.\nWe limited ourselves to 50 contracts due to the time and effort\nneeded to analyze the contracts by the evaluated tools and inspect\nthe analysis results of the tools to verify false-positives. With that\nsaid, even with this dataset, SolidiFI found significant numbers of\nundetected bugs in the tools (e.g., false negatives), as will be discussed\nin the following sections.\nAs explained in Section 4, in our experiments, we injected bugs\nbelonging to seven different bug types within the detection scope\nof the selected tools. Table 3 shows the bug types, and the tools\nthat are designed to detect each bug type. We chose these bug\ntypes based on the bug types detected by the individual tools, and\nbecause these bugs are common in smart contracts, and lead to\nvulnerabilities that have been exploited in practice [Eth [n.d.]; dao\n2016; bat 2018]. However,SolidiFI is not confined to these bug types.\nIn our experiments, we set the time-out value for each tool to\n15 minutes per smart contract and bug type. If a tool’s execution\nexceeds this timeout value, we terminate it and consider the bugs\nfound as its output. While 15 minutes may seem high, our goal is\nto give each tool as much leeway as possible. Only 2 of the tools\nexceeded this time limit in some cases (i.e., Mythril and Manticore).\n3 https://github.com/DependableSystemsLab/SolidiFI-benchmark\n4Function modifier checks a condition before the execution of the function.\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\nFor these two tools, we experimented with larger timeout values,\nbut they did not significantly increase their detection coverage.\nNote that the total time taken to run the experiments was already\nquite high with this timeout value - for example, it took us about\n4 days to analyze the contracts using Mythril (50-contract*6 bug-\ntypes*15-minute = 75 hours).\nTable 2: Contracts benchmark. F represents Functions, and\nM represents Function Modifiers\nId\nLines\nF+MId\nLines\nF+MId\nLines\nF+M\n1 103 6 18 406 29 35 317 29\n2 128 9 19 218 32 36 383 20\n3 132 10 20 308 27 37 368 24\n4 117 6 21 353 18 38 195 24\n5 250 17 22 383 19 39 52 4\n6 161 22 23 308 20 40 465 22\n7 165 22 24 741 27 41 160 8\n8 251 17 25 196 12 42 128 16\n9 249 19 26 143 20 43 285 22\n10 39 5 27 336 33 44 298 24\n11 193 19 28 195 24 45 156 14\n12 281 27 29 312 13 46 125 6\n13 161 8 30 711 57 47 223 18\n14 185 20 31 216 12 48 232 19\n15 160 8 32 143 14 49 52 4\n16 248 27 33 129 16 50 171 18\n17 128 17 34 445 29\nAverage values 242 18\nTable 3: Bug types used in our evaluation experiments: ’*’\nmeans that the tool can detect the bug type.\nBug Type\nOyente\nSecurify\nMythril\nSmartCheck\nManticore\nSlither\nRe-entrancy * * * * * *\nTimestamp dependency * * * *\nUnchecked send * *\nUnhandled exceptions * * * * *\nTOD * *\nInteger overflow/underflow * * * *\nUse of tx.origin * * *\n7.1 RQ1:What are the false negatives of the\ntools being evaluated?\nThe core part of our evaluation is to use SolidiFI to inject bugs, and\nevaluate the effectiveness of the tools in detecting the injected bugs.\nWe performed the following steps in our experiments. First,SolidiFI\nis used to inject bugs of each bug type in the code of the 50 smart\ncontracts, one bug type at a time. The resulting buggy contracts are\nthen checked using the static analysis tools. Finally, the number of\nthe injected bugs that were not detected by each tool were recorded.\nTo get meaningful results, we inject bugs that are as distinct\nas possible by preparing diverse set of distinct code snippets with\ndifferent data inputs and function calls- this resulted in9369 distinct\nbugs. We consider two injected bugs as distinct if the static analysis\ntool under study would reason about them differently based on the\nunderlying methodology, where either the data and control flow\nleading to the injected bug is different, or the design patterns of\nthe bug snippets are different. To ensure a fair evaluation, we inject\nonly the bugs that are supposed to be detected by each tool.\nWe consider an injected bug as being correctly detected by a tool\nif and only if it identified both the line of code in which the bug\nwas injected, as well as the bug type (e.g., Re-entrancy). In many\ncases, we observed that the tool would correctly identify the line\nof code in which the bug occurred, but would misidentify the bug\ntype. Therefore, we also report the former separately.\nThe results of injecting bugs of each bug type, and testing them\nusing the six tools are summarized in Table 4. In the table, “Injected\nbugs” column specifies the total number of injected bug for each\nbug type, “✓” means we did not find any undetected bug of that\nbug type (row), while “NA” means the bug type is out of scope of\nthe tool, i.e., it is not designed to detect the bug type. The numbers\nfor each column specify the total number of bugs that were either\nincorrectly detected or not detected by the tool corresponding to\nthe bug type specified in that row. The number within parentheses\nspecifies the number of cases that were not reported by the tool -\nthis does not consider the incorrect reporting of the bug type.\nFrom the table, we can see that a significant number of false\nnegatives occur for all the evaluated tools, and thatnone of the tools\nwas able to detect all the injected bugs correctly even if we accepted\na incorrect bug type with the correct line number as a detected bug .\nIn fact, the only tool that had 100% coverage for individual bug\ntypes was Slither, for Reentrancy and tx.origin bugs. Of all tools,\nSlither had the lowest false-negatives, followed by Securify across\nbug types.\nOur results thus show that all static analysis tools have many\ncorner cases of bugs that they are not able to detect. Note that it\nis surprising that our technique found as many undetected bugs by\nthe tools as it did, given that our goal was not specifically to exercise\ncorner cases of the tools in question. We will discuss the reasons for\nthe missed detections and the implications later (Section 8).\n7.2 RQ2: What are the false positives of the\ntools being evaluated?\nA false-positive occurs when a tool reports a bug, but there was\nno bug in reality. Unlike false negatives, where we know exactly\nwhere the bugs have been injected, and hence have ground truth,\nmeasuring false positives is challenging due to the lack of ground\ntruth. This is because we cannot assume that the smart contracts\nused are free of bugs (though they are chosen from the verified\ncontracts on Etherscan). Further, manually inspecting each bug\nreport and related contract involves a tremendous amount of effort\ndue to the large number of bug reports, and is hence not practical.\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\nTable 4: False negatives for each tool. Numbers within paran-\ntheses are bugs with incorrect line numbers or unreported.\nSecurity bug\nInjected bugs\nOyente\nSecurify\nMythril\nSmartCheck\nManticore\nSlither\nRe-entrancy 1343\n1008\n(844)\n232\n(232)\n1085\n(805)\n1343\n(106)\n1250\n(1108) ✓\nTimestamp dep 1381\n1381\n(886) NA\n810\n(810)\n902\n(341) NA\n537\n(1)\nUnchecked-send 1266 NA\n499\n(449)\n389\n(389) NA NA NA\nUnhandled exp 1374\n1052\n(918)\n673\n(571)\n756\n(756)\n1325\n(1170) NA\n457\n(128)\nTOD 1336\n1199\n(1199)\n263\n(263) NA NA NA NA\nInteger overflow 1333\n898\n(898) NA\n1069\n(932)\n1072\n(1072)\n1196\n(1127) NA\ntx.origin 1336 NA NA\n445\n(445)\n1239\n(1120) NA ✓\nTo keep the problem of determining false-positives tractable, we\ncame up with the following approach. The main idea is to manually\nexamine only those bugs that are not reported by the majority of\nthe other tools for each smart contract. In other words, we conser-\nvatively assume that a bug that is reported by a majority of the\ntools cannot be a false positive. However, at worst, we will under-\nestimate the number of false positives in this approach, subject\nto the vagaries of the manual inspection process. We also verified\nthat many of the bugs that are excluded by the majority are indeed\nfalse-positives by manually examining a random sample of them.\nEven after this filtering, we had to manually inspect a significant\nnumber of bugs to determine if they were false positives. There-\nfore, for each tool, we randomly selected 20 bugs of each bug type\ncategory that were not excluded by the majority approach, and\ninspected them manually. For those cases where the number of\nbugs is less than or equal to 20, we inspected them all. Based on the\nresults of our manual inspection, we estimated the false positives\nas the percentage of bugs inspected that were indeed false positives,\nmultiplied by the number of bugs filtered (i.e., not excluded).\nFor example, assume that the total number of bugs reported by a\ntool is 100. Of these 100 bugs, let us assume that60 are also reported\nby the majority of the other tools for the smart contract, and hence\nwe exclude them. Of the remaining 40 filtered bugs, we manually\nexamine 20 bugs chosen at random. Assume that 16 of these are\nindeed false-positives. We assume that 80% of the filtered bugs are\nfalse-positives, and estimate the number of false-positives to be 32.\nThe results of false positives reported by each tool are summa-\nrized in Table 5. In the table, the “Threshold” column refers to the\nmajority threshold, which is the number of tools that must detect\nthe bug in order for it to be excluded from consideration - this num-\nber depends on how many tools are able to detect the bug type. For\neach tool, the sub-column “Reported” shows the number of bugs re-\nported by the tool, the sub column “FIL” shows the number of bugs\nthat have been filtered (not excluded) by the majority approach,\nwhile the sub column “FP” shows the false positives of the tool\nbased on the manual inspection as explained above. Empty cells in\nthe table represent cases where a tool was not designed to detect a\nbug type. Note that some of the tools detected bugs outside the 7\ncategories that we considered - we called these as miscellaneous.\nFrom the table, we can see that all the evaluated tools have\nreported a number of false positives, ranging from 2 to 801 for\nmost of the bug types. Interestingly, the results show that the tools\nwith low numbers of false negatives reported high false positives,\ni.e., Slither and Securify. For example, although Slither was the\nonly tool that successfully detected all the injected Re-entrancy\nbugs, it reported significant false positives. This raises the question\nof whether the high detection rate was simply a result of over-\nzealously reporting bugs by the tool (this is also borne out by the\nhigh number of bugs reported under the miscellaneous category by\nthis tool). This highlights the need for security analysis tools that are\nable to detect bugs while maintaining low false positive rates.\nWe provide some examples of the false-positive cases below.\nFor example, most unhandled exception bugs were reported even\nthough the code checks the return values of the send functions for\nexceptions usingrequire(). As another example, many false positives\nwere re-entrancy bugs where the code contains the required checks\nof the contract balance, and updates the contract states before the\nEther transfer. Oyente reported several cases as integer over/un-\nderflow even though they are no integer related calculations (e.g.,\nstring public symbol = \"CRE\"; ). On the other side, we tried to be\nconsistent with the assumptions considered by the tools during\nour manual inspection. For example, some of the cases that we\nconsidered as true bugs were re-entrancy bugs that use the transfer\nfunction. This function protects against re-entrancy issues as it has\nlimited gas; however, we considered them as true bugs as the attack\ncan happen if the gas price changes - this is detected by some of\nthe tools (e.g., Slither).\n7.3 RQ3: Can the injected bugs be activated by\nan external attacker?\nThe goal of this RQ is to assess whether the undetected bugs in\nRQ1 can be activated in the contract at runtime. This is to deter-\nmine whether the reason behind the bug not being detected by the\nevaluated tool was because the bug cannot be activated (and hence\ncannot be exploited by an attacker). We deploy the set of buggy\ncontracts with the undetected bugs (found in RQ1) on the Ethereum\nblockchain, and execute transactions that attempt to activate them.\nTo conduct these experiments, we use MetaMask [Met [n.d.]], a\nbrowser extension that allows us to connect to an Ethereum node\ncalled INFURA [INF [n.d.]], and run our buggy contracts on this\nnode. We have created Ethereum accounts on Ethereum Kovan\nTestnet (test network) using MetaMask, and deposited sufficient\namount of Ether to these accounts to enable us to execute transac-\ntions (pay the required gas for transactions). We use Remix [rem\n2017] (Solidity editor) to deploy contracts on Ethereum Kovan Test-\nnet. Remix enables us to connect with MetaMask to deploy contracts\non INFURA Ethereum node.\nWe illustrate the process with an example. As mentioned in RQ1,\nManticore did not report instances of injected integer overflow/un-\nderflow bugs - an example is shown in Figure 13. Our goal is to\nattempt to activate this bug in the deployed buggy contract by call-\ning the function bug_intou3(). The returned result was 246 - this is\nnot the expected value (-10) due to the use of unsigned integer type\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\nTable 5: False positives reported by each tool. Empty cells mean that the tool was not designed for that particular bug type.\nBug Type\nThreshold\nOyente\nSecurify\nMythril\nSmartCheck\nManticore\nSlither\n= Reported FIL FP Reported FIL FP Reported FIL FP Reported FIL FP Reported FIL FP Reported FIL FP\nRe-entrancy 4 0 0 - 12 12 12 54 54 43 0 0 - 6 6 6 79 79 71\nTimestamp dep 3 0 0 - 12 12 0 0 0 - 12 12 0\nUnchecked send 2 7 4 4 14 3 3\nUnhandled exp 3 10 10 10 0 0 - 0 0 - 6 6 6 0 0 -\nTOD 2 32 24 24 121 97 97\nOver/under flow 3 947 943 801 17 3 3 3 2 2 9 9 9\nUse of tx.origin 2 0 0 - 3 1 0 4 2 0\nMiscellaneous 0 318 144 1520 169 1807\n(i.e., uint8) instead of a signed integer type, which resulted in an\ninteger underflow. Thus, the bug can be activated by an attacker.\nWe had to manually craft inputs for each bug in order to test\nits activation, which takes significant effort. Because of the large\nnumber of undetected bugs, we selected 5 undetected bugs for each\nbug type randomly from different contracts to test their activation.\nTable 6 shows the results of our activation experiments. In the\ntable “–” means we were not able to perform experiments on this\nbug type, as it requires the attacker to behave as a miner, which\nwould consume a significant amount of computational resources.\nThe results show that one can exploit (activate) all the selected\nbugs in their related buggy contracts. Therefore, the infeasibility of\nactivation of the bug was not the reason that the evaluated tools\nfailed to detect the injected bugs.\n1 function bug_intou3 () public {\n2 uint8 vundflw =0;\n3 vundflw = vundflw -10; // underflow\n4 return vundflw ;}\nFigure 13: Undetected integer underflow bug\nTable 6: Activity of Selected Undetected Bugs.\nBug type Selected bugs Activated bugs\nRe-entrancy 5 5\nTimestamp dependency 5 5\nUnchecked send 5 5\nUnhandled exceptions 5 5\nTOD – –\nInteger overflow/underflow 5 5\nUse of tx.origin 5 5\n7.4 RQ4: What is the performance of SolidiFI?\nFinally, we measured the performance ofSolidiFI in terms of the time\nit takes to inject bugs and generate buggy contracts. We excluded\nthe time of running the tools being evaluated to check the buggy\ncontracts, as this is tool-specific and independent of SolidiFI. We\npreformed injection of each bug type in each contract five times\nand calculated the average of the five runs, and then calculated\nthe average of injecting the seven bug types in each contract. The\naverage time of injecting all instances of bug types in a contract is\n25 seconds, and the worst case time was 46 seconds (for contract\n24, which was the largest contract in our set). Thus, SolidiFI takes\nless than 1 minute on average per contract and bug type.\n8 DISCUSSION\nIn this section, we examine the reasons for the false negatives of\nthe tools observed in RQ1. We then examine the implications of\nthe results, and our methodology, on both tool developers and end\nusers. Finally, we examine some of the limitations of SolidiFI and\nthreats to validity of our experiments.\n8.1 Reasons for False-Negatives\nTo establish a practical understanding of the presented results and\nwhy some bugs were not detected, we will highlight the code snip-\npets for some of the bugs that were not detected, and then discuss\nthe reasons behind them. We organize this discussion by tool.\nOyente was not able to detect many instances of injected re-\nentrnacy, timestamp dependency, unhandled exceptions, integer\noverflow/underflow, and TOD bugs as mentioned earlier 5. Accord-\ning to the paper [Luu et al. 2016], Oyente works on detecting only\nre-entrancy bugs that are based on the use ofcall.value. Some of the\nrecent tools, such as Slither, consider the detection of re-entrancy\nbugs with limited gas that are based on send and transfer. Those\npapers claim that send and transfer do not protect from re-entrancy\nbugs in case of gas price change. Furthermore, Oyente failed to\ndetect instances of re-entrancy bugs that are based on the use of\ncall.value. One of the TOD code snippets we used in our experi-\nments is mentioned in the running example at Figure 1 on lines 9-16,\nwhich emulates a simple game and its winner. The malicious behav-\nior occurs when the two transactions are executed in one block and\nthe attacker tries to change the order of the received transactions.\nTo understand why this bug is not detected by Oyente, in Oyente\nthe EVM bytecode is represented as a control flow graph (CFG).\nThe execution jumps are used as edges that connect the nodes of\nthe graph representing the basic execution blocks in the code. The\nsymbolic execution engine of Oyente uses the CFG to produce a\n5Because the released version of Oyente did not work with the latest version of the\nSolidity compiler (0.5.12), we made few changes to the injected contracts to get it to\nwork with Oyente - these did not impact the tool’s coverage.\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\nset of symbolic traces (execution paths), each associated with a\npath constraint and auxiliary data, to verify pre-defined properties\n(security bugs being detected). Basically, Oyente detects TOD by\ncomparing the different execution paths and the corresponding\ndata flow (Ether flow) for each path. Oyente reports those different\nexecution paths that have different Ether flows.\nFor Oyente to be able to detect all TOD bugs successfully, the\nsymbolic execution engine should generate all possible execution\npaths for the contract to find the erroneous path - this is challenging\ndue to the incompleteness of symbolic execution. It also uses some\nbounds that limit the symbolic execution.\nSmartcheck failed to detect most of the injected bugs across\nall the categories. Smartcheck checks for bugs by constructing an\nIntermediate Representation (IR) from the source code, and then\nusing XPath patterns to search for bugs in the IR. This approach\nlacks accuracy as some bugs cannot be expressed as XPath expres-\nsions. For example, the re-entracy bug is difficult to express as an\nXPath pattern, and is hence not detected.\nFurther, because Smartcheck uses XPath patterns that detect\nspecific syntax of some bugs, even a slight variation in the syntax\nof the bug snippets would not match the XPath patterns. For in-\nstance, SmartCheck did not report some occurrences of unhandled\nexceptions. By checking the code snippet for one of the undetected\nunhandled exception bug depicted in Figure 14, we found that\nSmartcheck was not able to detect it as unchecked send because\nSmartcheck only looks for send functions without an if-statement\n(that checks the return value). However, in this snippet, the send\nis within an if-statement even though the revert() exists in the else\nclause of the if-statement, which will be triggered on the successes\nof send. The same happens when other functions are used for send-\ning ether (e.g., call, etc.) instead ofsend. This is an inherent problem\nwith syntactic, rule-based tools such as Smartcheck.\n1 if (! addr .send (42 ether ))\n2 { receivers +=1;}\n3 else\n4 { revert () ;}}\nFigure 14: Unhandled exception code snippet 1.\nMythril was the tool with the largest set of undetected bugs in\nour experiments. It failed to detect many instances of re-entrancy,\ntimestamp dependency, unchecked send, unhandled exceptions,\ninteger overflow/underflow and use of tx.origin. For example, the\nbuggy code in Figure 15 was not detected by Mythril. The condition\nof the if-statement that checks the return value of the send will\nalways be evaluated as true because of the added condition “ ||\n1==1”. Hence, the execution of the contract would be reverted in\nall cases by the function revert(), regardless of whether the send\nsucceeds. This is incorrect as the execution should only be reverted\non the fails of send. However, Mythril does not detect this as it only\nevaluates the send() part in the condition of the if-statement rather\nthan evaluating the whole condition with the OR part (||1==1).\nMythril is also very slow in term of the time it takes to analyze\ncontracts. Although we set the time-out for analyzing each contract\nto 15 minutes, as mentioned earlier, we also tried setting the timeout\nto 30 minutes and did not observe any increase in the number of\nbugs demonstrating that increasing the time-out has diminishing\nreturns. We also found the number of undetected bugs increase in\nthe large contracts, as Mythril enumerates symbolic traces and this\ndoes not scale well in large contracts.\n1 if (! addr .send (10 ether ) || 1==1)\n2 { revert () ;}\nFigure 15: Unhandled exception code snippet 2.\nLike the other tools, Mythril also misreported the types of many\nof the injected bugs. Figure 16 shows part of a buggy contract\ninjected using SolidiFI. The injected contract allows users to man-\nage their tokens and send tokens to each other. We injected a re-\nentrancy bug usingSolidiFI in the contract at lines 185-188. However,\nMythril reported the re-entrancy bug as \"Unchecked Call Return\nValue\" (i.e., Unhandled exception) at line 186. By inspecting this\nline of code, we can see that the return value of thesend function is\nchecked and the balance is reset to zero on the success of send, so\nthere is no unhandled exception as reported. This calls into question\nMythril’s soundness in detecting this type of bugs as well as its\ncompleteness in detecting Re-entrancy bugs.\n177 function transfer ( address _to , uint256 _value ) public\nreturns ( bool success ) {\n178 require ( balances [msg . sender ] >= _value );\n179 balances [ msg . sender ] -= _value ;\n180 balances [ _to ] += _value ;\n181 emit Transfer (msg . sender , _to , _value );\n182 return true ;\n183 }\n184\n185 function withdraw_balances_re_ent36 () public {\n186 if ( msg . sender . send ( balances [msg . sender ]))\n187 balances [ msg . sender ] = 0;\n188 }\nFigure 16: Part of a buggy contract injected by reentrancy\nbug.\nManticore was not able to detect instances of re-entrancy and\ninteger overflow/underflow. Unlike other evaluated tools employing\nsymbolic executions, we noticed that Manticore takes a long time to\nanalyze smart contracts, and in some cases it times-out. It consumes\nsignificant memory space as well on our system. Moreover, Manti-\ncore crashed and failed to analyze most of the contracts and threw\nexception errors. The 50 main contracts used in our experiments\nconsist of 123 analyzable contracts (each contract file may contain\nmore than one contract). Out of them, Manticore crashed for 83\ncontracts injected by re-entrancy bugs and 73 contracts injected\nby integer overflow bugs. We reached out to the tool developers\nto get fixes or explanation for these issues; however, there was no\nresponse (as of the time of submission).\nSecurify was not able to detect several cases of injected bugs\nbelonging to re-entrancy, unchecked send, unhandled exceptions,\nand TOD. In addition, we found many cases where Securify failed\nto analyze the injected contracts and threw an error. Out of the 200\ncontracts injected by the four bug types (50 contracts for each bug\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\ntype), Securify failed to analyze 5 contracts injected by unhandled\nexceptions, 4 injected by re-entrancy, 4 injected by unchecked send,\nand 4 injected by TOD bugs. If we excluded the injected bugs in\nthose contracts, the number of undetected bugs by Securify will be\nas following: (re-entrancy: 105, unchecked send: 332, unhandled\nexceptions: 402, and TOD: 136). Securify also reported a high num-\nber of TOD false positives compared with Oyente. A recent study\n[Feng et al. 2019] found that the reported false alarms by Securify\nare due to over-approximation of the execution.\nSlither Although Slither has almost 100% accuracy in detecting\nre-entrancy, timestamp, and tx.origin bugs, it was not able to detect\nmany instances of unhandled exceptions. Moreover, it had high\nnumber of re-entrancy false positives as mentioned earlier.\n8.2 Implications\nTool Developers There are two implications for tool developers.\nThe first implication is that using pattern matching for detecting\nbugs, especially by employing simple approaches such as XPaths\nmatching, is not an effective way for detecting smart contract bugs\nfor the reasons mentioned earlier in this section. The second point\nis that bug detection approaches that are based on enumerating\nsymbolic traces are impeded by path explosion and scalability is-\nsues. Therefore, there is a need for sophisticated analysis tools\nthat also consider the semantics of the analyzed code instead of\ndepending only on analyzing the syntax and symbolic traces. For\nexample, static analysis might work better if combined with for-\nmal methods that consider the semantic specifications of Solidity\nand EVM. Recent papers [Amani et al. 2018; Bhargavan et al. 2016;\nGrishchenko et al. 2018; Hildenbrandt et al. 2017; Hirai 2017] have\nproposed semi-automated formal verification for performing anal-\nysis of smart contracts.\nEnd Users of Tools : For smart contract developers, who are the\nend users of the static analysis tools, there are three implications.\nFirst, they can use SolidiFI to assess the efficacy of static analysis\ntools to choose the most reliable tools with no or low false negatives\nfor their use cases. Second, developers should not rely exclusively\non static analysis tools, and should test the developed contracts\nextensively. SolidiFI can help them build test suites by introducing\nmutations and checking if the test cases can catch them. Finally,\nthe generated bugs by SolidiFI and their relative locations in the\ncode can be used for educating developers on writing secure code.\n8.3 Limitations of SolidiFI\nThere are two limitations ofSolidiFI. First, the current version ofSo-\nlidiFI works only on Solidity static analysis tools. Although Solidity\nis the most common language for writing Ethereum smart contracts\nand most of the proposed tools target analysis of Solidity contracts,\nSolidiFI functionality can be easily extended to other languages.\nSecondly, the bug injection approach employed by SolidiFI requires\npre-prepared code snippets (for each bug type), which requires\nsome manual effort. However, this is a one-time cost for each bug\ntype (we have provided these as part of the tool).\n8.4 Threats to Validity\nAn external threat to the validity is the limited number of smart\ncontracts considered, namely 50. We have mitigated this threat by\nconsidering a wide-range of smart contracts with varying function-\nality and code sizes. We emphasize that SolidiFI covers all syntactic\nelements of Solidity up to version 0.5.12 and, our data-set contains\na wide variety of contracts with different features (e.g., loops). Also,\nwe selected contracts with different sizes that were representative\nof EtherScan contracts ranging from 39 to 741 locs, with an average\nof 242 loc (Table 2).\nThere are two internal threats to validity. First, the number of\ntools considered is limited to 6. However, as mentioned, these rep-\nresent the common tools used in other studies on smart contract\nstatic analysis. Further, they are widely used in both academia\nand industry. All the tools available are open-source and are being\nactively maintained (with the exception of Oyente). Further, the\nimplemented prototype of SolidiFI is reusable and can be easily\nextended to evaluate other tools. The second internal threat to va-\nlidity is that we only injected 7 bug types. However, these bug types\nhave been (1) considered by most of the tools evaluated, and (2)\nexploited in the past by real attacks. Therefore, we believe they are\nrepresentative of security bugs in smart contracts.\nFinally, a construct threat to validity is our measurement of false-\nnegatives and false-positives. For false-negatives, it is possible that\nthe bugs cannot be exploited in practice. We have partially mitigated\nthis threat by sampling the set of false-negatives and attempting\nto exploit them (RQ3). For false-positives, it is possible that the\nreported bugs are true positives. Again, we have partially mitigated\nthis threat by conservatively considering the bugs reported by the\nmajority of the tools for each bug category as true positives.\n9 RELATED WORK\nBug-finding Tools Evaluation The approach of injecting bugs\nfor evaluating the effectiveness of bug finders has been applied in\nother contexts than smart contracts. Bonett et al. proposed µSE\n[Bonett et al. 2018], a mutation-based framework for the evalua-\ntion of Android static analysis tools that works as follows. First, a\nfixed set of security operators are created describing the unwanted\nbehavior that the tools being evaluated aim to detect (e.g., data\nleakage). Then, µSE inserts the security operators into mobile apps\nbased on mutation schemes, that consider Android abstractions,\ntools reachability and security goals of the tools, thereby creating\nmultiple mutants that represent unwanted behavior within the\napps. The mutated apps are analyzed using the static tools to be\nevaluated. However, unlike our work, the undetected mutants are\nanalyzed manually. Further, their framework focuses only on data\nleak detection tools, unlike our work, which is more general.\nPewny et al. [Pewny and Holz 2016] automatically find potential\nvulnerable locations in C code, and modify the source code to make\nit vulnerable. Program analysis techniques are used to find sinks\nin the programs matching specific bug patterns, and find connec-\ntions to user-controlled sources through data-flow. The program\nis modified accordingly to make it exploitable. In contrast to our\napproach, the vulnerable code locations to be injected are randomly\nchosen, and the implemented prototype targets the injection of\nspatial memory errors through the modification of security checks.\nDolan-Gavitt et al. [Dolan-Gavitt et al. 2016] proposed LAVA for\ngenerating and injecting bugs into the source code of programs\nusing dynamic taint analysis. A guard is inserted for every injected\nISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA Asem Ghaleb and Karthik Pattabiraman\nbug for triggering the vulnerability if a specific value occurs in\nthe input. Specifically, LAVA identifies an execution trace location\nwhere an unmodified and dead input data byte (DUA) is available.\nThen code is added at this location to make the DUA byte available,\nand use it execute the vulnerability. Unlike our work, the injection\nis based on dynamic taint analysis, and the injected bugs are accom-\npanied by triggering inputs. In contrast, our goal is to transform\ninvulnerable code to systematically introduce vulnerabilities in it.\nIn recent work, Akca et al. [Akca et al. 2019] proposed a tool that\nthe authors used to compare the effectiveness of their introduced\nsmart contracts static analyzer with some other tools. by injecting a\nsingle bug into the contract code. Unlike our approach that injects\nexploitable bugs into all potential locations in the contract code,\nthe tool uses Fault Seeder [Peng et al. 2019] to generate contract\nmutants by injecting only a single bug snippet (hard-coded in the\nsource code) into a specific location in the smart contract. In addi-\ntion, the authors conducted manual inspection of the tool reports to\ndetermine false negatives. Injecting a single bug does not provide a\ncomprehensive coverage evaluation of static analysis tools. Also, it\nis not clear how to evaluate the efficacy of static analysis tools on\ndetecting deep vulnerabilities and corner cases by injecting only\na single bug. As presented before, each bug can be introduced in\nthe code in several ways, in this case, injecting a single-bug will\nnot test the efficacy of the static analysis tools to detect various\nvariants of each bug.\nDurieux et al. [Durieux et al. 2019] compared a number of smart\ncontract static analysis tools. Unlike our work, the evaluation is\nbased on using 69 manually annotated smart contracts with 112\nbugs in total. The vulnerable contracts are collected from online\nrepositories that are not agnostic of the evaluated tools, hence, re-\nsults might be biased (e.g., collecting 50% of the contracts from SWC\nRegistry referenced by Mythril and maintained by the team behind\nit). In contrast, our goal is to perform systematic and comprehen-\nsive coverage evaluation of static analysis tools by transforming\ninvulnerable code to systematically introduce vulnerabilities into\nall valid locations. We evaluated 6 tools on detecting about 9369\ndistinct bugs. To provide a fair evaluation of the tools, we evalu-\nate each tool only on the bugs that it is designed to detect. Our\nproposed approach can be easily used to evaluate smart contract\nstatic analysis tools for detecting other bug types. Further, it enables\nend-users to choose any dataset of smart contracts for evaluating\nthe tools.\nSmart Contract Testing and Exploitation : There have been\nmany recent papers on testing smart contracts, and automatically\ngenerating security exploits on them. Wu et al. [Wu et al . 2019]\nproduce test cases by mutating specific patterns in smart contracts.\nChan et al. [Chan and Jiang 2018] develop a fuzz testing service\n(Fuse) to support the fuzz testing of smart contracts. This is a work\nin progress report, and only presents the architecture of the fuzz\nservice being developed. Wang et al. [Wang et al. 2019] target the\ngeneration of test suites for smart contracts. This work guides\nautomatic generation of test cases for Ethereum smart contracts.\nEth-mutants [eth [n.d.]] is another mutation testing tool for smart\ncontracts. However, it is limited to replacing < to ≤, and > to ≥\n(and vice versa). Unlike our focus on evaluating smart contracts’\nstatic analysis tools, these papers target the generation of test cases\nfor the smart contracts.\nOther papers focus on automatic exploitation of smart contracts\nto generate exploits or malicious inputs to exploit found code vul-\nnerabilities [Feng et al. 2019; Jiang et al. 2018; Krupp and Rossow\n2018]. teEther [Krupp and Rossow 2018] generates exploits for vul-\nnerable contracts using symbolic execution with the Z3 constraint\nsolver [De Moura and Bjørner 2008] to solve path constraints for the\ncritical paths in the control flow graph. Contractfuzzer [Jiang et al.\n2018] uses the Application Binary Interface (ABI) specifications of\nvulnerable smart contracts to generate exploits (fuzzing inputs) for\ntwo vulnerabilities. SMARTSCOPY [Feng et al. 2019] also synthe-\nsizes adversarial contracts for exploiting vulnerabilities in contracts\nbased on ABI specifications of the contracts covering larger set of\nvulnerabilities than Contractfuzzer. Echidna [Crytic [n.d.]] has been\nproposed for fuzzing smart contracts. It supports grammar-based\nfuzzing to generate transactions to test smart contracts. The goal\nof these techniques is testing the smart contracts themselves for\nsecurity vulnerabilities rather than testing bug-finding tools.\n10 CONCLUSION\nThis paper proposed SolidiFI, a technique for performing system-\natic evaluation of Ethereum smart contract’s static analysis tools\nbased on bug injection. SolidiFI analyzes the AST (Abstract Syntax\nTree) of smart-contracts and injects pre-defined bug patterns at\nall possible locations in the AST. SolidiFI was used to evaluate 6\nsmart contract static analysis tools, and the evaluation results show\nseveral cases of bugs that were not detected by the evaluated tools\neven though those undetected bugs are within the detection scope\nof tools. SolidiFI thus identifies important gaps in current static\nanalysis tools for smart contracts, and provides a reproducible set\nof tests for developers of future static analysis tools. It also allows\nsmart contract developers to understand the limitations of existing\nstatic analysis tools with respect to detecting security bugs.\nFuture work will consist of expanding SolidiFI to other smart\ncontract languages than Solidity, and automating the bug definition\nprocesses for injecting new bug types.\n11 ACKNOWLEDGMENTS\nThis work was partially supported by the Natural Sciences and\nEngineering Research Council of Canada (NSERC), and a research\ngift from Intel. We thank Julia Rubin, Sathish Gopalakrishnan, Kon-\nstantin Beznosov, and the anonymous reviewers of ISSTA’20 for\ntheir helpful comments about this work.\nREFERENCES\n[n.d.]. CVE-2018-10299 Detail. https://nvd.nist.gov/vuln/detail/CVE-2018-10299\n[n.d.]. eth-mutants. https://github.com/federicobond/eth-mutants\n[n.d.]. History of Ethereum Security Vulnerabilities, Hacks, and Their\nFixes. https://applicature.com/blog/blockchain-technology/history-of-ethereum-\nsecurity-vulnerabilities-hacks-and-their-fixes\n[n.d.]. INFURA. https://infura.io\n[n.d.]. MetaMask. https://metamask.io\n[n.d.]. solidity-security-blog. https://github.com/sigp/solidity-security-blog\n2016. Analysis of the DAO exploit. https://hackingdistributed.com/2016/06/18/\nanalysis-of-the-dao-exploit\n2017. The parity wallet breach. https://bitcoinexchangeguide.com/parity-wallet-\nbreach\n2017. Remix - Solidity IDE. http://remix.ethereum.org\n2018. New batchOverflow Bug in Multiple ERC20 Smart Contracts (CVE-\n2018âĂŞ10299). https://medium.com/@peckshield/alert-new-batchoverflow-\nbug-in-multiple-erc20-smart-contracts-cve-2018-10299-511067db6536\nHow Effective are Smart Contract Analysis Tools? Evaluating Smart Contract Static Analysis Tools Using Bug InjectionISSTA ’20, July 18–22, 2020, Los Angeles/Virtual, CA, USA\nSefa Akca, Ajitha Rajan, and Chao Peng. 2019. SolAnalyser: A Framework for Analysing\nand Testing Smart Contracts. In 2019 26th Asia-Pacific Software Engineering Confer-\nence (APSEC). IEEE, 482–489.\nSidney Amani, Myriam Bégel, Maksym Bortin, and Mark Staples. 2018. Towards\nverifying ethereum smart contract bytecode in Isabelle/HOL. In Proceedings of the\n7th ACM SIGPLAN International Conference on Certified Programs and Proofs . ACM,\n66–77.\nNicola Atzei, Massimo Bartoletti, and Tiziana Cimoli. 2017. A survey of attacks on\nethereum smart contracts (sok). In Principles of Security and Trust . Springer, 164–\n186.\nKarthikeyan Bhargavan, Antoine Delignat-Lavaud, Cédric Fournet, Anitha Gollamudi,\nGeorges Gonthier, Nadim Kobeissi, Natalia Kulatova, Aseem Rastogi, Thomas Sibut-\nPinote, Nikhil Swamy, et al. 2016. Formal verification of smart contracts: Short\npaper. In Proceedings of the 2016 ACM Workshop on Programming Languages and\nAnalysis for Security . ACM, 91–96.\nRichard Bonett, Kaushal Kafle, Kevin Moran, Adwait Nadkarni, and Denys Poshyvanyk.\n2018. Discovering flaws in security-focused static analysis tools for Android using\nsystematic mutation. In 27th {USENIX}Security Symposium ( {USENIX}Security\n18). 1263–1280.\nLexi Brent, Anton Jurisevic, Michael Kong, Eric Liu, Francois Gauthier, Vincent Gramoli,\nRalph Holz, and Bernhard Scholz. 2018. Vandal: A Scalable Security Analysis\nFramework for Smart Contracts. arXiv preprint arXiv:1809.03981 (2018).\nVitalik Buterin. 2014. Ethereum: A next-generation smart contract and decentralized\napplication platform. URL https://github. com/ethereum/wiki/wiki/% 5BEnglish%\n5D-White-Paper 7 (2014).\nWK Chan and Bo Jiang. 2018. Fuse: An Architecture for Smart Contract Fuzz Testing\nService. In 2018 25th Asia-Pacific Software Engineering Conference (APSEC) . IEEE,\n707–708.\nChristopher D Clack, Vikram A Bakshi, and Lee Braine. 2016. Smart contract tem-\nplates: foundations, design landscape and research directions. arXiv preprint\narXiv:1608.00771 (2016).\nCrytic. [n.d.]. Echdina. https://github.com/crytic/echidna\nChris Dannen. 2017. Introducing Ethereum and Solidity: Foundations of Cryptocurrency\nand Blockchain Programming for Beginners . Springer.\nLeonardo De Moura and Nikolaj Bjørner. 2008. Z3: An Efficient SMT Solver. InProceed-\nings of the Theory and Practice of Software, 14th International Conference on Tools\nand Algorithms for the Construction and Analysis of Systems (TACAS’08/ETAPS’08) .\n337–340.\nBrendan Dolan-Gavitt, Patrick Hulin, Engin Kirda, Tim Leek, Andrea Mambretti, Wil\nRobertson, Frederick Ulrich, and Ryan Whelan. 2016. Lava: Large-scale automated\nvulnerability addition. In 2016 IEEE Symposium on Security and Privacy (SP) . IEEE,\n110–121.\nThomas Durieux, João F Ferreira, Rui Abreu, and Pedro Cruz. 2019. Empirical Review\nof Automated Analysis Tools on 47,587 Ethereum Smart Contracts. arXiv preprint\narXiv:1910.10601 (2019).\nEtherscan. [n.d.]. Etherscan. https://etherscan.io\nJosselin Feist, Gustavo Grieco, and Alex Groce. 2019. Slither: a static analysis framework\nfor smart contracts. In 2019 IEEE/ACM 2nd International Workshop on Emerging\nTrends in Software Engineering for Blockchain (WETSEB) . IEEE, 8–15.\nYu Feng, Emina Torlak, and Rastislav Bodík. 2019. Precise Attack Synthesis for Smart\nContracts. CoRR abs/1902.06067 (2019). arXiv:1902.06067 http://arxiv.org/abs/1902.\n06067\nIlya Grishchenko, Matteo Maffei, and Clara Schneidewind. 2018. A Semantic Frame-\nwork for the Security Analysis of Ethereum smart contracts. In International Con-\nference on Principles of Security and Trust . Springer, 243–269.\nEverett Hildenbrandt, Manasvi Saxena, Xiaoran Zhu, Nishant Rodrigues, Philip Daian,\nDwight Guth, and Grigore Rosu. 2017. Kevm: A complete semantics of the ethereum\nvirtual machine . Technical Report.\nYoichi Hirai. 2017. Defining the ethereum virtual machine for interactive theorem\nprovers. In International Conference on Financial Cryptography and Data Security .\nSpringer, 520–535.\nBo Jiang, Ye Liu, and WK Chan. 2018. Contractfuzzer: Fuzzing smart contracts for\nvulnerability detection. InProceedings of the 33rd ACM/IEEE International Conference\non Automated Software Engineering . ACM, 259–269.\nJohannes Krupp and Christian Rossow. 2018. teether: Gnawing at ethereum to automat-\nically exploit smart contracts. In 27th {USENIX}Security Symposium ( {USENIX}\nSecurity 18) . {USENIX Association}, 1317–1333.\nLoi Luu, Duc-Hiep Chu, Hrishi Olickel, Prateek Saxena, and Aquinas Hobor. 2016.\nMaking smart contracts smarter. InProceedings of the 2016 ACM SIGSAC Conference\non Computer and Communications Security . ACM, 254–269.\nFlorian Mathieu and Ryno Mathee. 2017. Blocktix: decentralized event hosting\nand ticket distribution network. https://www.cryptoground.com/storage/files/\n1527588859-blocktix-wp-draft.pdf\nMark Mossberg, Felipe Manzano, Eric Hennenfent, Alex Groce, Gustavo Grieco, Josselin\nFeist, Trent Brunson, and Artem Dinaburg. 2019. Manticore: A user-friendly sym-\nbolic execution framework for binaries and smart contracts. In2019 34th IEEE/ACM\nInternational Conference on Automated Software Engineering (ASE) . IEEE, 1186–1189.\nBernhard Mueller. 2018. Smashing ethereum smart contracts for fun and real profit.\nHITB SECCONF Amsterdam (2018).\nReza M Parizi, Ali Dehghantanha, Kim-Kwang Raymond Choo, and Amritraj Singh.\n2018. Empirical vulnerability analysis of automated smart contracts security test-\ning on blockchains. In Proceedings of the 28th Annual International Conference on\nComputer Science and Software Engineering . IBM Corp., 103–113.\nChao Peng, Sefa Akca, and Ajitha Rajan. 2019. SIF: A Framework for Solidity Con-\ntract Instrumentation and Analysis. In 2019 26th Asia-Pacific Software Engineering\nConference (APSEC). IEEE, 466–473.\nDaniel Perez and Benjamin Livshits. 2019. Smart Contract Vulnerabilities: Does Anyone\nCare? arXiv preprint arXiv:1902.06710 (2019).\nJannik Pewny and Thorsten Holz. 2016. EvilCoder: automated bug insertion. In\nProceedings of the 32nd Annual Conference on Computer Security Applications . ACM,\n214–225.\nFerdian Thung, David Lo, Lingxiao Jiang, Foyzur Rahman, Premkumar T Devanbu,\net al. 2012. To what extent could we detect field defects? an empirical study of\nfalse negatives in static bug finding tools. In Proceedings of the 27th IEEE/ACM\nInternational Conference on Automated Software Engineering . ACM, 50–59.\nSergei Tikhomirov, Ekaterina Voskresenskaya, Ivan Ivanitskiy, Ramil Takhaviev,\nEvgeny Marchenko, and Yaroslav Alexandrov. 2018. SmartCheck: Static Anal-\nysis of Ethereum Smart Contracts. (2018).\nPetar Tsankov, Andrei Dan, Dana Drachsler-Cohen, Arthur Gervais, Florian Buenzli,\nand Martin Vechev. 2018. Securify: Practical security analysis of smart contracts. In\nProceedings of the 2018 ACM SIGSAC Conference on Computer and Communications\nSecurity. 67–82.\nXingya Wang, Haoran Wu, Weisong Sun, and Yuan Zhao. 2019. Towards Generating\nCost-Effective Test-Suite for Ethereum Smart Contract. In 2019 IEEE 26th Interna-\ntional Conference on Software Analysis, Evolution and Reengineering (SANER) . IEEE,\n549–553.\nHaoran Wu, Xingya Wang, Jiehui Xu, Weiqin Zou, Lingming Zhang, and Zhenyu Chen.\n2019. Mutation testing for ethereum smart contract. arXiv preprint arXiv:1908.03707\n(2019)."
}