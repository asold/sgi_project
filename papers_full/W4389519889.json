{
    "title": "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
    "url": "https://openalex.org/W4389519889",
    "year": 2023,
    "authors": [
        {
            "id": "https://openalex.org/A1923353117",
            "name": "Kai Xiong",
            "affiliations": [
                "Harbin Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2122094799",
            "name": "Xiao Ding",
            "affiliations": [
                "Harbin Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2110093419",
            "name": "Yixin Cao",
            "affiliations": [
                "Singapore Management University"
            ]
        },
        {
            "id": "https://openalex.org/A2098738246",
            "name": "Ting Liu",
            "affiliations": [
                "Harbin Institute of Technology"
            ]
        },
        {
            "id": "https://openalex.org/A2098930276",
            "name": "Bing Qin",
            "affiliations": [
                "Harbin Institute of Technology"
            ]
        }
    ],
    "references": [
        "https://openalex.org/W4280583915",
        "https://openalex.org/W2898695519",
        "https://openalex.org/W3142760738",
        "https://openalex.org/W2998617917",
        "https://openalex.org/W2970062726",
        "https://openalex.org/W4287393336",
        "https://openalex.org/W4281557260",
        "https://openalex.org/W4307079201",
        "https://openalex.org/W4288089799",
        "https://openalex.org/W4226399820",
        "https://openalex.org/W4311992389",
        "https://openalex.org/W2001296434",
        "https://openalex.org/W4289528260",
        "https://openalex.org/W4322718191",
        "https://openalex.org/W4302011807",
        "https://openalex.org/W4293138840",
        "https://openalex.org/W4323717348",
        "https://openalex.org/W4385572965",
        "https://openalex.org/W4385572867",
        "https://openalex.org/W4385572845",
        "https://openalex.org/W4281975731",
        "https://openalex.org/W4286987939",
        "https://openalex.org/W1667708040",
        "https://openalex.org/W4382202621",
        "https://openalex.org/W4221161695",
        "https://openalex.org/W3205068155",
        "https://openalex.org/W4387835442",
        "https://openalex.org/W4288262459",
        "https://openalex.org/W95183648",
        "https://openalex.org/W4226278401",
        "https://openalex.org/W2469040843",
        "https://openalex.org/W4360836968",
        "https://openalex.org/W4221143046",
        "https://openalex.org/W4205870266",
        "https://openalex.org/W4304194220",
        "https://openalex.org/W2129421456",
        "https://openalex.org/W4300978535",
        "https://openalex.org/W3121904249"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD.",
    "full_text": "Findings of the Association for Computational Linguistics: EMNLP 2023, pages 7572‚Äì7590\nDecember 6-10, 2023 ¬©2023 Association for Computational Linguistics\nExamining Inter-Consistency of Large Language Models Collaboration:\nAn In-depth Analysis via Debate\nKai Xiong1 Xiao Ding1‚Ä† Yixin Cao2‚Ä† Ting Liu1 Bing Qin1\n1Research Center for Social Computing and Information Retrieval\nHarbin Institute of Technology, China\n2Singapore Management University, Singapore\n{kxiong, xding, tliu, qinb}@ir.hit.edu.cn\nyxcao@smu.edu.sg\nAbstract\nLarge Language Models (LLMs) have shown\nimpressive capabilities in various applications,\nbut they still face various inconsistency issues.\nExisting works primarily focus on the incon-\nsistency issues within a single LLM, while we\ncomplementarily explore the inter-consistency\namong multiple LLMs for collaboration. To\nexamine whether LLMs can collaborate effec-\ntively to achieve a consensus for a shared goal,\nwe focus on commonsense reasoning, and in-\ntroduce a formal debate framework (FORD)\nto conduct a three-stage debate among LLMs\nwith real-world scenarios alignment: fair de-\nbate, mismatched debate, and roundtable de-\nbate. Through extensive experiments on var-\nious datasets, LLMs can effectively collabo-\nrate to reach a consensus despite noticeable\ninter-inconsistencies, but imbalances in their\nabilities can lead to domination by superior\nLLMs. Leveraging a more advanced LLM like\nGPT-4 as an authoritative judge can boost col-\nlaboration performance. Our work contributes\nto understanding the inter-consistency among\nLLMs and lays the foundation for develop-\ning future collaboration methods. Codes and\ndata are available at https://github.com/Waste-\nWood/FORD.\n1 Introduction\nLarge Language Models (LLMs) like ChatGPT re-\ncently demonstrate general intelligence (Bubeck\net al., 2023) and have been widely used as a foun-\ndation model in various applications (Wei et al.,\n2022b; Wu et al., 2023). To solve complex tasks,\nmultiple LLMs are further introduced to collab-\norate, with each targeting a different subtask or\naspect (Schick et al., 2022; Park et al., 2023). Inter-\nestingly, do these LLMs possess a spirit of collabo-\nration? Are they capable of cooperating effectively\nand performantly towards a shared goal?\nIn this paper, we dive into the inter-consistency\namong LLMs, complementary to existing work\n‚Ä†Corresponding Authors\nQuestion: The ship wrecked. What happened as a result?\nQuestion: The road is wet, what was the cause of this?\n(a) Compromisein debate(b) Refutationin debate\nIsupposetheyarelikelytomeetsomepirates.\n üëæ\nIguesssomeonepouredwaterontheroad,whichmakestheroadwet.\n üëæ\nIthinkthecrewwoulddrownduetothewreck.\nü§ñ\n Thewetroadmightbecausebyabigrain.\nü§ñ\nSorry,youareright,piratesareverycommonatsea.\nü§ñ\n Istandbymyself,rainisamorecommoncauseofthewetroad.\nü§ñ\nFigure 1: (a) compromise and (b) refutation in LLMs\ndebates.\nü§ñ is the proponent, and\nüëæ is the opponent.\nwhich mostly investigates the self-consistency is-\nsue of a single LLM (Wang et al., 2022b; Jung et al.,\n2022). Based on the observations, we highlight two\nmain inter-consistent concerns for LLMs‚Äô collab-\noration. First, the viewpoints of LLMs are easily\nshifted. As shown in Figure 1 (a), the proponent\nand opponent LLMs are showing different predic-\ntions, while the proponent quickly compromises\nwith the answer of the opponent. To which extent\ndo LLMs easily change their viewpoints, or adhere\nto their perspectives? Second, when some LLMs\nremain steadfast in Figure 1 (b), can a consensus\nultimately be achieved for the shared goal?\nInspired by the debate theory (Mayer, 1997),\nwe devise a Formal Debate framework (FORD)\nto systematically and quantitatively investigate the\ninter-inconsistency issue in LLMs collaboration.\nBased on FORD, we allow LLMs to explore the\ndifferences between their own understandings and\nthe conceptualizations of others via debate (Mayer,\n1997). Thus, the results can not only shed light to\nencourage more diverse results, but also make it\npossible for performance gains by mutual learning.\nIn specific, we take multi-choice commonsense\nreasoning as the example task as it can accurately\nquantify the inter-inconsistency of LLMs collab-\noration. Then we formulate a three-stage debate\nto align with real-world scenarios: (1) Fair de-\n7572\nbate between two LLMs with comparable capa-\nbilities. (2) Mismatched debate between two\nLLMs who exhibit vastly different levels of abili-\nties. (3) Roundtable debate including more than\ntwo LLMs for debates. Besides, due to the leading\nperformance of GPT-4 (OpenAI, 2023), we con-\nduct an in-depth analysis to adopt GPT-4 as a more\npowerful judge to summarize the debates and offer\nfinal conclusions. Note that FORD is flexible if\nstronger or more LLMs emerge.\nWe summarize our main findings as follows.\n(1) Different types of LLMs (e.g., chat and text\ncompletion models) have large inter-inconsistency,\neven if they are developed from the same base\nmodel. (2) For different versions of an LLM within\nthe same series (e.g., GPT-3.5), although their over-\nall performance keeps improving, the more ad-\nvanced models do not completely supersede the\ncapabilities of the early ones. (3) Through FORD,\nmultiple LLMs hold the potential to collaborate\nand reach a consensus, while the final results are\nnot always so desirable. (4) For LLMs with com-\nparable abilities, they can effectively and perfor-\nmantly achieve a shared goal. (5) On the other hand,\nfor LLMs with mismatched abilities, the superior\nLLMs are more likely to insist on their perspec-\ntives and dominate the debate, while weaker ones\nare more likely to compromise and change their\nviewpoints. (6) Nevertheless, the stubborn and less\ncapable LLMs may distract the superior ones and\nlower the overall performance.\nWe summarize our contributions as follows:\n‚Ä¢ We systematically and quantitatively study the\ninter-consistency among two and more LLMs.\n‚Ä¢ We adopt debate theory and design a formal\ndebate framework FORD towards quantitative\nanalysis and LLMs collaboration.\n‚Ä¢ We design a three-stage debate and have con-\nducted extensive experiments to offer insights\nfor future research.\n2 Preliminaries\nWe first describe the datasets and LLMs used in\nthis paper. Then we define a metric INCON to quan-\ntify the inter-inconsistency among multiple LLMs.\nFinally, we define the baselines to verify our pro-\nposed formal debate framework FORD.\nDataset Task Type Size\nŒ±NLI (Bhagavatula et al., 2019) 2 Choices 1,507\nCSQA (Talmor et al., 2019) 5 Choices 1,221\nCOPA (Gordon et al., 2012) 2 Choices 500\ne-CARE (Du et al., 2022a) 2 Choices 2,122\nSocial IQa (Sap et al., 2019) 3 Choices 1,935\nPIQA (Bisk et al., 2020) 2 Choices 1,838\nStrategyQA (Geva et al., 2021) Yes or No 2,290\nTable 1: Commonsense reasoning dataset statistics.\n2.1 Commonsense Reasoning Datasets\nFor better coverage, we choose 7 multi-choice com-\nmonsense reasoning datasets for experiments: one\nabductive reasoning dataset Œ±NLI (Bhagavatula\net al., 2019), one commonsense question answer-\ning dataset CSQA (Talmor et al., 2019), two causal\nreasoning datasets COPA (Gordon et al., 2012) and\ne-CARE (Du et al., 2022a), one social interaction\nreasoning dataset Social IQa (Sap et al., 2019),\none physical interaction question answering dataset\nPIQA (Bisk et al., 2020), and one implicit reason-\ning strategy dataset StrategyQA (Geva et al., 2021).\nTable 1 shows the statistics of the above datasets.\n2.2 Large Language Models\nWe choose 6 LLMs from multiple sources for ex-\nperiments. We first choose 4 LLMs from OpenAI:\nthree chat completion LLMs gpt-3.5-turbo (de-\nnoted as ChatGPT), gpt-3.5-turbo-0301 (de-\nnoted as ChatGPT-0301), and gpt-4 (denoted\nas GPT-4), as well as one text completion\nLLM text-davinci-003 (denoted as Davinci-\n003). Then we adopt two open-source 13B LLMs:\nan efficient foundation LLM LLaMA (Touvron\net al., 2023), and Vicuna (Chiang et al., 2023)\nwhich is trained on 70K data from ShareGPT.\n2.3 Definitions: INCON\nHere we define the metric INCON to quantify the\ninter-inconsistency among multiple LLMs. Specifi-\ncally, suppose there are nLLMs L= {l1,¬∑¬∑¬∑ ,ln},\nand a dataset with msamples X = {x1,¬∑¬∑¬∑ ,xm}.\nWe define pi\nj as the prediction of li on xj. Then the\nINCON of Lon X can be defined as:\nINCON =\nm‚àë\nk=1\nŒ¶(p1\nk,¬∑ ¬∑ ¬∑ ,pn\nk )\nm , (1)\nŒ¶ is a sign function, it will be assigned a value of\n1 if there are any two variables in Œ¶ that are not\nequal, otherwise, Œ¶ takes a value of 0.\n7573\n‚öñ\nOptions:(A)Ideletethewholedocument.(B)Ihitthebackspace.\nQuestion:Iducked.Whatwasthecause?Options:(A)Thefireworkslaunchedup.(B)Thefrisbeesoaredtome.\nSamples\nStep 1: StanceSelection and ArgumentGeneration\nQuestion: I made a grammatical error. What happens next?Options: (A) I delete the document. (B) I hit the backspace.\nü§ñ\nDeletingthedocumenttoretypeisabetterideatosolvethisproblem.\n üëæ\nHitting the backspace is more common to solve the error. Do you think I am more reasonable?\nü§ñ\nIstandbymyself.Althoughitislesscostlytohitthebackspace,deletingisamoredirectway.DoyouthinkIammoreplausible?\nüëæ\nIcannotagreewithyou.Hittingthebackspacecankeepmostofthework,whiledeletingthedocumentwouldwastethepreviouswork.DoyouthinkIammorereasonable?\nü§ñ\nSorryformymistake.Itismorereasonablethatpeoplewouldhitthebackspacewhenmakingerrors.Step 2: Alternate DebateProcessStep 3:Debate Summarization\nSummary:Thisdebateisaboutselectinganeffectof‚ÄúImadeagrammati-calerror‚Äù.Theproponentsupposesthatdeletingthewholedocumentcansolvetheerror.Whiletheopponent‚Ä¶Finally,theproponentcompromiseswiththeopponent.Conclusion:(B)isamoreplausibleanswer.\nü§ñProponent\nüëæOpponent\n‚öñJudge\nLegend\nOptions:(A)Ideletethewholedocument.(B)Ihitthebackspace.\nü§ñ: Stance: (A). Argument: The Crew...\nüëæ: Stance: (A). Argument: Pirates...\nOptions:(A)Ideletethewholedocument.(B)Ihitthebackspace.\nü§ñ: Stance: (B). Argument: Frisbee is... \nüëæ: Stance: (B). Argument: Fireworks...\nOptions:(A)Ideletethewholedocument.(B)Ihitthebackspace.\nü§ñ: Stance: (A). Argument: Deleting...\nüëæ: Stance: (B). Argument: Hitting...\nOptions:(A)Ideletethewholedocument.(B)Ihitthebackspace.\nü§ñ: Stance: (B). Argument: Yearbook...\nüëæ: Stance: (A). Argument: Looking...\nConsistent\nInconsistent\nFigure 2: The overall workflow of FORD on two LLMs. Step 1: LLMs independently give a choice and explanation\nfor each sample as the stance and argument, respectively. Step 2: LLMs debate alternately on the inconsistent\nsamples. Step 3: A judge summarizes the whole debate process and gives the final conclusion.\n2.4 Baseline Methods\nWe define three kinds of baselines to verify our\nproposed formal debate framework: (1) Single\nLLM use only one LLM to conduct experiments.\n(2) Collaboration-Soft (Col-S) aligns the loose\nscenario that we randomly trust one of the LLMs\nwhen they are inconsistent, so Col-S averages\nthe accuracy of the LLMs. (3) Collaboration-\nHard (Col-H) aligns the conservative scenario that\nwe only trust consistent prediction, so Col-H pre-\ndicts correctly when all LLMs predict correctly.\n3 FORD: Formal Debate Framework\nTo further explore the inter-inconsistency, inspired\nby the structure of debate (Bell, 1998), we design\na formal debate framework (FORD) for LLMs col-\nlaboration to solve shared tasks. In Figure 2, we\nuse two LLMs for illustration, FORD consists of 3\nsteps: (1) Stance selection and argument genera-\ntion expects LLMs to choose a stance and give an\nargument for each sample, aiming to select the in-\nconsistent samples for future collaboration in step 2.\n(2) Alternate debate process makes LLMs alter-\nnately refute each other or seek a compromise to in-\nvestigate whether LLMs can collaborate effectively\ntowards a consensus. (3) Debate summarization\nuses a judge to summarize the debate, then draw a\nfinal conclusion in case does not reach a consensus.\n3.1 Stance Selection & Argument Generation\nThe first step of FORD is to choose a stance, then\nprovide an argument to support the stance. Hence,\nwe ask each LLM to independently choose a choice\nand a short explanation as the stance and argument,\nrespectively. Experimental details and prompts\ncan refer to Appendix A. As shown in step 1 of\nFigure 2, when asked about the cause of ‚ÄúI ducked‚Äù,\nthe proponent would hold the stance ‚Äú (B)‚Äù and\ngives the argument ‚ÄúFrisbee is usually a potential\nthreat to safety‚Äù to support its stance.\nWe focus on the inconsistent samples in the sub-\nsequent steps to investigate LLMs collaboration.\n3.2 Alternate Debate Process\nTo investigate whether LLMs can effectively col-\nlaborate and achieve a consensus, we design an\nalternate debate process. Given the arguments in\nstep 1, the proponent conducts round 1 debate to\nfirst counter the opponent by presenting an updated\nargument or to seek a compromise. If no compro-\nmise, the opponent would conduct round 2 to do the\nsame to the proponent by additionally considering\nthe arguments produced in previous rounds. The de-\nbate process will be conducted alternately until the\nLLMs achieve a consensus, or the debate rounds\nreach the maximum number. To make LLMs less\nswing, the stance will not explicitly show in step 2.\nPrompts and details can refer to Appendix B.\nAs shown in step 2 in Figure 2, the proponent\ndefends itself by claiming ‚Äúdeleting is a more direct\nway‚Äù, while the opponent adheres to its perspective\nby stating ‚Äúhitting backspace‚Äù is less costly. Finally,\nthe proponent compromise with the opponent.\n7574\nDebate Method Œ±NLI CSQA COPA e-CARE Social IQa PIQA StrategyQA Average\nChatGPT &\nDavinci-003\nChatGPT 77.17 76.17 96.80 81.53 72.71 80.74 69.34 79.21\nDavinci-003 79.96 78.62 95.20 79.69 73.33 76.88 71.48 79.31\nCol-S 78.75 77.40 96.00 80.61 73.02 78.81 70.41 79.29\nCol-H 69.14 68.22 93.80 71.96 62.69 68.55 58.12 70.35\nFORD (Ours) 81.35 78.79 97.00 83.74 74.32 84.60 71.62 81.63\nChatGPT &\nChatGPT-0301\nChatGPT 77.17 76.17 96.80 81.53 72.71 80.74 69.34 79.21\nChatGPT-0301 77.70 75.43 97.20 81.53 73.54 80.79 69.17 79.34\nCol-S 77.44 75.80 97.00 81.53 73.13 80.77 69.26 79.28\nCol-H 74.78 73.46 96.00 79.55 70.96 77.97 67.25 77.14\nFORD (Ours) 78.30 76.41 97.60 81.95 73.75 82.70 69.65 80.05\nLLaMA &\nVicuna\nLLaMA 63.04 66.18 90.20 66.97 58.98 71.60 63.10 68.58\nVicuna 70.60 59.87 89.20 68.05 64.65 60.45 55.28 66.87\nCol-S 66.82 63.02 89.70 67.51 61.82 66.03 59.15 67.72\nCol-H 54.74 47.91 83.40 53.72 46.77 48.26 41.35 53.74\nFORD (Ours) 70.80 66.75 93.80 71.54 63.67 72.25 64.10 71.84\nTable 2: The overall performance of FORD and baselines in the fair debates. Underlined numbers represent the best\nperformance among the collaboration methods on each dataset. Bold numbers denote the best performance among\nall methods on each dataset. ‚ÄúAverage‚Äù denotes the mean accuracy across different datasets for each method.\n3.3 Debate Summarization\nTo obtain the final result of the debate, we adopt\na judge to summarize the whole debate and draw\na conclusion. We design a template to obtain the\nsummary by filling it with the arguments, which\ncan provide an overview of the debate process to en-\nhance the interpretability. The conclusion is about\nthe result of the debate. For samples that reached a\nconsensus, the conclusion is the consensus stance.\nFor samples without a consensus, we assign equal\nweights to all arguments for the conclusion. Refer\nto Appendix E for more details.\nNext, based on the above framework, we simu-\nlate three debate scenarios for comprehensive inves-\ntigation: (1) Fair debate between two LLMs with\ncomparable capabilities (Sec 4). (2) Mismatched\ndebate between two LLMs with mismatched capa-\nbilities (Sec 5). (3) Roundtable debate including\nmore than two LLMs for debate (Sec 6).\n4 Fair Debate\nGiven multi-choice questions, we conduct fair de-\nbates on three pairs of LLMs: different types of\nLLMs (ChatGPT & Davinci-003 and LLaMA & Vi-\ncuna), and different versions of LLMs (ChatGPT &\nChatGPT-0301). LLMP & LLMO denotes LLMP\nas the proponent, and the LLMO is the opponent.\n4.1 Initial INCON of LLMs Pairs\nWe first conduct step 1 on each LLM on each\ndataset. The temperature is set as 0 for reproducibil-\nNLI\n CSQA COPA e-CARE Social IQa PIQA StrategyQA\n0\n5\n10\n15\n20\n25\n30\n35INCON (%)\nChatGPT & Davinci-003\nChatGPT & ChatGPT-0301\nLLaMA & Vicuna\nFigure 3: Initial INCON of LLMs pairs on each dataset.\nThe dashed part in each bar denotes the INCON brought\nby the wrong predictions of the proponent.\nity. The initial INCON of each LLMs pair on each\ndataset is categorized in Figure 3:\n(1) Different types of LLMs hold nearly 20%-\n30% INCON on almost all datasets, even if they are\nbased on the same underlying model. The over-\nlapped part in each bar contributes nearly 50% to\nINCON, which means LLMs in each LLMs pair pos-\nsess comparable yet vastly different capabilities.\n(2) For ChatGPT & ChatGPT-0301, ChatGPT-\n0301 does not supersede ChatGPT in capabilities.\nThis indicates LLMs gain new abilities as they it-\nerate but lose some existing ones. Hence, it is not\nconvincing to use the updated LLMs to reproduce\nthe results of the unavailable early versions.\n4.2 Results of Fair Debate\nThrough steps 2 & 3 in FORD, we intervene the\npredictions under the setting of fair debate. Heuris-\ntically, for ChatGPT & Davinci-003 and LLaMA\n& Vicuna, the maximum rounds of debate is 6.\n7575\n0 1 2 3 4 5 6\nDebate round\n0\n10\n20INCON (%)\n(a) ChatGPT & Davinci-003\nNLI\nCSQA\nCOPA\ne-CARE\nSocial IQa\nPIQA\nStrategyQA\n0 1 2 3 4\nDebate round\n0\n2\n4\n6INCON (%)\n(b) ChatGPT & ChatGPT-0301\nNLI\nCSQA\nCOPA\ne-CARE\nSocial IQa\nPIQA\nStrategyQA\n0 1 2 3 4 5 6\nDebate round\n0\n10\n20\n30INCON (%)\n(c) LLaMA & Vicuna\nNLI\nCSQA\nCOPA\ne-CARE\nSocial IQa\nPIQA\nStrategyQA\nFigure 4: The INCON of (a) ChatGPT & Davinci-003, (b)\nChatGPT & ChatGPT-0301, and (c) LLaMA & Vicuna\nacross different debate round. Round 0 denotes the\ninitial INCON (Figure 3) before the debate process.\nWhile for ChatGPT & ChatGPT-0301, the maxi-\nmum rounds of debate is 4.\nTable 2 shows the overall performance of FORD\nand corresponding baselines. We can find that:\n(1) FORD defeats Col-S, Col-H, and corre-\nsponding single LLMs on almost all datasets (ex-\ncept for LLaMA & Vicuna on Social IQa). It is\nbecause FORD can make LLMs obtain more com-\nprehensive and precise perspectives of the question.\nThis signifies that LLMs with comparable abili-\nties possess a spirit of collaboration to effectively\nand performantly achieve a shared goal.\n(2) While FORD on ChatGPT & ChatGPT-0301\ndoes not gain as much improvement as the other\ndebates. Due to their very similar capabilities, they\nusually have similar opinions on each sample, lead-\ning to insignificant improvement.\n(3) On each dataset, ChatGPT & ChatGPT-0301\nhas higher performance floors ( Col-H), this sug-\ngests we choose similar models for conservative\ngains. While ChatGPT & Davinci-003 has higher\nperformance ceilings (FORD), this suggests we\nchoose LLMs with greater variance in capabilities\nto debate for better performance.\nEffect of Debate Rounds: We track the INCON in\neach round of each fair debate on each dataset. The\noverall results are shown in Figure 4. We can find:\nDebate Method e-CARE PIQA\nChatGPT &\nGPT-4\nChatGPT 81.53 80.74\nGPT-4 85.96 95.21\nCol-S 83.75 87.98\nCol-H 77.33 79.00\nFORD 85.96 92.71\nLLaMA &\nChatGPT\nLLaMA 66.97 70.51\nChatGPT 81.53 80.74\nCol-S 74.25 75.63\nCol-H 57.82 61.26\nFORD 74.88 75.84\nTable 3: The overall results of the mismatched debates.\n(1) For each fair debate, the INCON decreases\nprogressively after each round on each dataset.\nIt is because LLMs can learn from differences\namong themselves to reach agreements, demon-\nstrating comparable LLMs can debate to ulti-\nmately achieve a consensus for the shared goal.\n(2) For ChatGPT & Davinci-003 and ChatGPT &\nChatGPT-0301, the INCON drops almost to 0 on all\ndatasets, while LLaMA & Vicuna still has an obvi-\nous inter-inconsistency after debates. We suppose\nthis is attributed to the gap in their capabilities.\n(3) The INCON of ChatGPT & ChatGPT-0301\nachieves coverage after 2 rounds, which is earlier\nthan the other fair debates. This is mainly due\nto their very similar capabilities, causing similar\nopinions to reach a consensus earlier.\n5 Mismatched Debate\nIn human discourse, when interacting with a dom-\ninant individual, we often tend to be influenced\nby their cognition, leading us to adopt their ideas\nand thought processes (Jayagopi et al., 2009). We\ninvestigate this scenario in Mismatched Debate.\nWe adopt two pairs of LLMs in experiments:\nChatGPT & GPT-4 and LLaMA & ChatGPT. For\nefficiency, we select e-CARE and PIQA for analy-\nsis. Experimental details of the mismatched de-\nbates are the same as fair debate ChatGPT &\nDavinci-003. The initial INCON of the mismatched\ndebates can refer to Appendix C.\n5.1 Results of Mismatched Debate\nThe overall results of the mismatched debates are\nshown in Table 3. Figure 5 presents the INCON of\neach debate round. From the results, we can find:\n(1) FORD can easily outperforms Col-S, Col-H,\nand the weaker LLMs, but lose to the stronger\nLLMs. There seems to be a performance ceiling,\n7576\n0 1 2 3 4 5 6\nDebate round\n0\n10\n20\n30INCON (%)\ne-CARE (ChatGPT & GPT-4)\nPIQA (ChatGPT & GPT-4)\ne-CARE (LLaMA & ChatGPT)\nPIQA (LLaMA & ChatGPT)\nFigure 5: The overall INCON of the mismatched debates\non e-CARE and PIQA across different debate rounds.\nDebate Dataset Proponent Opponent\nChatGPT &\nDavinci-003\ne-CARE 53.69 46.31\nPIQA 53.04 46.96\nChatGPT &\nGPT-4\ne-CARE 7.64 92.36\nPIQA 10.60 89.40\nLLaMA &\nChatGPT\ne-CARE 39.94 60.06\nPIQA 32.08 67.92\nTable 4: The dominance of different LLMs across dif-\nferent debates and datasets.\nwhich is tied to the accuracy of the stronger LLMs.\nLLMs with mismatched abilities struggle to ef-\nfectively collaborate toward a shared goal.\n(2) Even if the capabilities are mismatched, the\nINCON still continues to drop. These demonstrate\nLLMs with mismatched abilities still possess a\nspirit of collaboration to reach a consensus yet\nare disturbed by less capable LLMs.\n(3) Compared with Fair Debates, the dominant\nLLMs (GPT-4 and ChatGPT) may be distracted,\nbut they still bring significant improvements to\nFORD of ChatGPT & Davinci-003 and LLaMA &\nVicuna, respectively.\n(4) FORD of LLaMA & ChatGPT seems to per-\nform far from the ceiling, this is because LLaMA\nis not capable to evaluate the arguments and only\nclaims its stance, which distracts ChatGPT more.\n5.2 The dominance of LLMs\nFor further analysis, we introduce a new met-\nric dominance for LLMs. For example, the\ndominance of the proponent LLM is defined as the\nportion of inter-inconsistent samples that the op-\nponent LLM compromises, and vice versa. The\ndominance directly reflects the extent that the\nLLMs adhere to their viewpoints.\nTake a fair debate (ChatGPT & Davinci-003)\nfor example, Table 4 shows ChatGPT and Davinci-\n003 achieve similar dominance on both datasets.\nIt explains why Comparable LLMs can debate\nto compromise or adhere to more reasonable\nperspectives to improve the performance.Hence,\nLLMs Method e-CARE PIQA\nChatGPT Single LLM 81.53 80.74\nDavinci-003 Single LLM 79.69 76.88\nChatGPT-0301 Single LLM 81.53 80.79\nGPT-4 Single LLM 85.96 95.21\nChatGPT & Davinci-003 FORD (F) 83.74 84.60\nChatGPT & ChatGPT-0301 FORD (F) 81.95 82.60\nChatGPT & GPT-4 FORD (M) 85.96 92.71\nChatGPT &\nDavinci-003 &\nGPT-4\nCol-S (M) 82.39 84.28\nCol-H (M) 69.75 67.57\nFORD (M) 84.78 86.02\nChatGPT &\nDavinci-003 &\nChatGPT-0301\nCol-S (F) 80.92 79.47\nCol-H (F) 70.64 66.38\nFORD (F) 83.79 84.06\nTable 5: The overall performance of roundtable debates.\n(F) denotes fair debate, (M) denotes mismatched debate.\nwe use it as a reference for the mismatched debates,\nas shown in Table 4, we can conclude:\n(1) Stronger LLMs (GPT-4 and ChatGPT) in the\nmismatched debates have absolute advantages in\ndominance. This mirrors human circumstances.\nThus, stronger LLMs hold a larger probability\nto adhere to their perspectives. When superior\nLLMs are less confident in a few samples, they are\neasier to be disturbed by the weaker LLMs.\n(2) However, LLaMA & ChatGPT does not ex-\nhibit such a large gap indominance. This is mainly\nbecause LLaMA is a bad debater. It is not capable\nto evaluate the arguments of others and only gener-\nates the sentence like‚ÄúOption (x) is more plausible‚Äù\nmost of the time, this would make ChatGPT swing.\n6 Roundtable Debate\nIn many scenarios, the debates or discussions of-\nten involve more than two participants, such as\nlaw (Ransom et al., 1993) and healthcare (Chassin\net al., 1998). Since LLaMA and Vicuna are not\ngood at debate, we design two roundtable debates\namong three LLMs: one mismatched debate Chat-\nGPT & Davinci-003 & GPT-4 (denoted as R1),\nand one fair debate ChatGPT & Davinci-003 &\nChatGPT-0301 (denoted as R2).\nFollowing Sec 5, we select e-CARE and PIQA\nfor experiments. In step 1 of FORD, the samples\nthat not all LLMs reach agreements would be sent\nto step 2. For R1 and R2 in step 2, ChatGPT de-\nbates first, Davinci-003 second to align with the fair\ndebates between two LLMs. GPT-4 and ChatGPT-\n0301 speak last in R1 and R2, respectively. The\nLLMs debate up to 9 rounds. Refer to Appendix D\nfor more details and the prompts.\n7577\n0 2 4 6 8\nDebate round\n0\n10\n20\n30INCON (%)\ne-CARE (R1)\nPIQA (R1)\ne-CARE (R2)\nPIQA (R2)\nFigure 6: The overall INCON of the roundtable debates\non e-CARE and PIQA across different debate rounds.\nThe overall results of the roundtable debates are\nshown in Table 5, and Figure 6 shows theINCON of\neach debate round. We can conclude that:\n(1) In both roundtable debates, FORD signifi-\ncantly outperforms Col-S and Col-H. While FORD\nin R1 is much inferior to GPT-4, highlighting a su-\nperior LLM is likely to be more misled and less\ndominant (refer to Table 10 in the Appendix) if\nthere are more weaker LLMs. FORD in R2 outper-\nforms all single LLMs, this proves more than two\ncomparable LLMs can collaborate effectively\nand performantly towards a shared goal.\n(2) The INCON is significantly alleviated, indicat-\ning more than two LLMs still possess the spirit\nto collaborate and achieve a consensus.\n(3) FORD in R1 surpasses FORD in R2. It in-\ndicates adopting a stronger LLM can improve the\nperformance of the debates despite the stronger\nLLM might be misled by the other weaker LLMs.\n(4) In R2, FORD outstrips ChatGPT & ChatGPT-\n0301, while achieving similar results with Chat-\nGPT & Davinci-003, this is because ChatGPT and\nChatGPT-0301 do not possess many distinctions,\nleading to little new information to debates.\n7 Analysis\n7.1 GPT-4 as the Judge\nDifferent arguments in each debate might have dif-\nferent persuasions. Moreover, in human debates,\nthere is a human judge with strong evaluation abil-\nities to summarize the debate and draw the final\nconclusion. Inspired by this, we investigate GPT-4\nas the judge to replace step 3 in FORD and conduct\nexperiments on two fair debates.\nSpecifically, we adopt two fair debates ChatGPT\n& Davinci-003 and ChatGPT & ChatGPT-0301 for\nexperiments. GPT-4 would be prompted to give the\nsummarizations and conclusions only based on the\ndebate process (refer to Appendix F). Table 6 shows\nthe results on ChatGPT & Davinci-003 (Table 8\nin the Appendix presents the results of ChatGPT\nDataset FORD (w/o GPT-4) FORD (w/ GPT-4)\nŒ±NLI 81.35 82.48\nCSQA 78.79 80.10\nCOPA 97.00 97.60\ne-CARE 83.74 83.88\nSocial IQa 74.32 74.57\nPIQA 84.60 85.15\nStrategyQA 71.62 71.70\nAverage 81.63 82.29\nTable 6: The effect of GPT-4 as the judge on the debates\nbetween ChatGPT and Davinci-003.\nDataset LLMs Best Col-S Col-H FORD FORD ‚àó\ne-CARE 81.53 80.61 71.96 84.74 82.52\nPIQA 80.74 78.81 68.55 84.60 84.44\nTable 7: The results of ablation study on ChatGPT &\nDavinci-003. FORD‚àó denotes FORD with reversed de-\nbate order. ‚ÄúLLMs Best‚Äù denotes the best performance\nof ChatGPT and Davinci-003.\n& ChatGPT-0301), we can obtain the following\nfindings: GPT-4 as the judge can further boost the\nperformance of FORD. It is mainly because GPT-\n4 can assign higher weights to more convincing\narguments, then draw more precise conclusions.\n7.2 The Effect of Debate Order\nLike different initializations may yield different re-\nsults during model training, the debate order in step\n2 might influence the results, we conduct ablation\nstudies to investigate the effect of the debate order.\nSpecifically, we use ChatGPT & Davinci-003\nand ChatGPT & ChatGPT-0301 on e-CARE and\nPIQA for explorations. We will reverse the debate\norder in step 2 of FORD in each debate. The other\nsettings are the same with Sec 4.\nTable 7 and Figure 7 respectively show the re-\nsults and INCON of ChatGPT & Davinci-003 when\nreversing the debate order. Results of ChatGPT &\nChatGPT-0301 can refer to Appendix G. We can\nsummarize the following completions:\n(1) When we exchange Davinci-003 as the pro-\nponent and ChatGPT as the opponent, FORD still\noutperforms Col-S, Col-H, and corresponding sin-\ngle LLMs, yielding similar results to the original\ndebate order. This further supports the earlier find-\nings are not sensitive to the debate order.\n(2) Reversing the debate order of ChatGPT &\nDavinci-003 reduces performance but speeds up\nthe convergence of INCON. It is due to Davinci-003\nbeing a text completion model, initializing debates\n7578\n0 1 2 3 4 5 6\nDebate round\n0\n5\n10\n15\n20INCON (%)\ne-CARE (Davinci-003 & ChatGPT)\nPIQA (Davinci-003 & ChatGPT)\ne-CARE (ChatGPT & Davinci-003)\nPIQA (ChatGPT & Davinci-003)\nFigure 7: The overall INCON of ChatGPT & Davinci-\n003 with different debate orders on e-CARE and PIQA.\nwith Davinci-003 might mislead the whole debate.\n7.3 Case Study\nTo intuitively investigate how FORD improves the\ninter-consistency and enhances the interpretability,\nwe present an example output by FORD.\nIn Debate 1, the proponent (ChatGPT) holds the\nstance that option (A) is more plausible while the\nopponent (Davinci-003) supposes option (B) is bet-\nter. The proponent pointed out that the key to this\nquestion is the ‚Äúold yearbook‚Äù. The opponent even-\ntually conceded to the proponent. Through this\ndebate, one LLM can supply the aspects that the\nother LLM overlooked, resulting in more convinc-\ning interpretability and accurate decision.\n8 Related Work\n8.1 Reasoning with LLMs\nLLMs have subverted the research paradigm of\nNLP. Using LLMs for reasoning can be catego-\nrized into instruction-tuning-based (IT) and chain-\nof-thought-based (CoT) methods.\nThe IT methods start from FLAN (Wei et al.,\n2022a) and T0 (Sanh et al., 2022). FLAN fine-\ntuned 137B LaMDA-PT (Thoppilan et al., 2022)\nand T0 finetuned T5 (Raffel et al., 2020) on numer-\nous NLP tasks to make LLMs follow instructions,\nthen they achieve impressive performance on un-\nseen tasks. Differently, InstructGPT (Ouyang et al.,\n2022) adopted RLHF to let LLMs learn human\npreferences. Flan-PaLM (Chung et al., 2022) and\nTk-INSTRUCT (Wang et al., 2022c) further scaled\nup LLMs sizes and task size.\nAs for CoT methods, Wei et al. (2022c) proposed\na few-shot CoT to elicit reasoning in LLMs and\nachieve remarkable improvements. Kojima et al.\n(2022) designed zero-shot CoT to get rid of human\nannotations. Then Zhang et al. (2022) proposed\nAutoCoT to automatically generate few-shot CoT\nfor experiments. Wang et al. (2022a) and Fu et al.\n(2023) devised complex CoT for reasoning.\nDebate 1 ChatGPT & Davinci-003 (Judge: GPT-4)\nQuestion: I found my old yearbook today while cleaning.\nWhich event could cause the day was almost over and I\nhadn‚Äôt cleaned anything?\nOptions: (A) I became lost in a huge world of fond memories.\n(B) I kept looking through things for more discoveries.\nü§ñ\n: While going through the yearbook, the person may\nhave become engrossed in looking at old photos and remi-\nniscing about past memories. This could have caused them\nto neglect their cleaning duties, resulting in the day almost\nbeing over without any cleaning being done.\nüëæ\n: Option (B) suggests that I was looking through things\nwhile I cleaned, which would explain directly why the day\nwas almost over and I hadn‚Äôt cleaned anything.\nü§ñ\n: The scenario of getting lost in fond memories while\nlooking through an old yearbook is a common experience\nthat can cause a person to lose track of time and neglect\ntheir cleaning duties. While option (B) may not be as likely\nas getting caught up in nostalgia.\nüëæ\n: I think you are right. Getting lost in fond memories\nwhile looking through an old yearbook is a common ex-\nperience that can cause a person to lose track of time and\nneglect their cleaning duties.\n‚öñ\n: The proponent argues that getting lost in fond mem-\nories (A) is more plausible as it‚Äôs a common experience\nthat can cause a person to lose track of time and neglect\ncleaning duties. The opponent initially argues for option\n(B), but eventually agrees with the proponent‚Äôs point about\ngetting lost in nostalgia. Therefore, the answer is (A).\nThese methods mainly focused on eliciting rea-\nsoning abilities. While we utilize these methods to\nmake multiple LLMs collaborate for consensuses.\n8.2 Inconsistency in LLMs\nInconsistency is an important issue in existing\nLLMs. Wang et al. (2022b) investigated the self-\nconsistency of LLMs by sampling multiple CoT for\neach example. Jung et al. (2022) proposed to study\nthe logical consistency in LLMs and designed a\nmaieutic prompt to improve the performance on\nyes/no questions. Sahu et al. (2022) devised a con-\nceptual consistency metric to measure the align-\nment between LLMs and the real world. Li et al.\n(2022) proposed a multi-prompt method to obtain\nbetter consistency on each example.\nThese methods investigate inconsistency in a\nsingle LLM, while we complementary investigate\nthe inter-consistency between two or more LLMs.\n9 Conclusion\nIn this paper, we explore inter-inconsistency issues\namong LLMs. Then we propose FORD to examine\nwhether LLMs can effectively collaborate to ulti-\nmately achieve a consensus through debate. With\nFORD, we explore three real-world debate scenar-\n7579\nios: fair debate, mismatched debate, and roundtable\ndebate. We find LLMs possess the spirit of collab-\noration to achieve a consensus for solving a shared\ngoal. Debates can improve the performance and\ninter-consistency of LLMs. Stronger LLMs can\nbe distracted by weaker LLMs when the debates\nare mismatched. These findings contribute to the\nfuture development of collaboration methods.\nLimitations\nThis work still has the following limitations\nwhich can be investigated and improved in the fu-\nture: On the one hand, we should not limit our-\nselves to the commonsense reasoning task and\ncover more tasks, such as mathematical reason-\ning, MMLU (Hendrycks et al., 2021). On the other\nhand, we should extend the multi-choice task to\nnatural language generation tasks like entailment-\nbank (Dalvi et al., 2021) or complex reasoning\ntasks like causal chain reasoning (Xiong et al.,\n2022) to align the trends of LLMs. Incorporat-\ning more kinds of LLMs and real-world tasks (Du\net al., 2022b; Cai et al., 2023) is also worth further\nexploration. Trading reproducibility for diverse\ndebate behaviors is also a good topic to discuss.\nAcknowledgments\nWe gratefully acknowledge the support of the\nNational Natural Science Foundation of China\n(U22B2059, 62176079), the Natural Science Foun-\ndation of Heilongjiang Province (YQ2022F005),\nand the Singapore Ministry of Education (MOE)\nAcademic Research Fund (AcRF) Tier 1 grant.\nReferences\nPhilip LaVerne Bell. 1998. Designing for students‚Äô sci-\nence learning using argumentation and classroom\ndebate. University of California, Berkeley.\nChandra Bhagavatula, Ronan Le Bras, Chaitanya\nMalaviya, Keisuke Sakaguchi, Ari Holtzman, Han-\nnah Rashkin, Doug Downey, Wen-tau Yih, and Yejin\nChoi. 2019. Abductive commonsense reasoning. In\nInternational Conference on Learning Representa-\ntions.\nYonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi,\net al. 2020. Piqa: Reasoning about physical com-\nmonsense in natural language. In Proceedings of the\nAAAI conference on artificial intelligence, volume 34,\npages 7432‚Äì7439.\nS√©bastien Bubeck, Varun Chandrasekaran, Ronen El-\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\nberg, et al. 2023. Sparks of artificial general intelli-\ngence: Early experiments with gpt-4. arXiv preprint\narXiv:2303.12712.\nBibo Cai, Xiao Ding, Zhouhao Sun, Bing Qin, Ting Liu,\nLifeng Shang, et al. 2023. Self-supervised logic in-\nduction for explainable fuzzy temporal commonsense\nreasoning. In Proceedings of the AAAI Conference\non Artificial Intelligence, volume 37, pages 12580‚Äì\n12588.\nMark R Chassin, Robert W Galvin, et al. 1998. The ur-\ngent need to improve health care quality: Institute of\nmedicine national roundtable on health care quality.\nJama, 280(11):1000‚Äì1005.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416.\nBhavana Dalvi, Peter Jansen, Oyvind Tafjord, Zhengnan\nXie, Hannah Smith, Leighanna Pipatanangkura, and\nPeter Clark. 2021. Explaining answers with entail-\nment trees. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Process-\ning, pages 7358‚Äì7370.\nLi Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin.\n2022a. e-care: a new dataset for exploring explain-\nable causal reasoning. In Proceedings of the 60th\nAnnual Meeting of the Association for Computational\nLinguistics (Volume 1: Long Papers), pages 432‚Äì446.\nLi Du, Xiao Ding, Kai Xiong, Ting Liu, and Bing Qin.\n2022b. Enhancing pretrained language models with\nstructured commonsense knowledge for textual infer-\nence. Knowledge-Based Systems, 254:109488.\nYao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and\nTushar Khot. 2023. Complexity-based prompting for\nmulti-step reasoning. International Conference on\nLearning Representations.\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\nDan Roth, and Jonathan Berant. 2021. Did aristotle\nuse a laptop? a question answering benchmark with\nimplicit reasoning strategies. Transactions of the\nAssociation for Computational Linguistics , 9:346‚Äì\n361.\nAndrew Gordon, Zornitsa Kozareva, and Melissa Roem-\nmele. 2012. SemEval-2012 task 7: Choice of plau-\nsible alternatives: An evaluation of commonsense\ncausal reasoning. In *SEM 2012: The First Joint\nConference on Lexical and Computational Seman-\ntics ‚Äì Volume 1: Proceedings of the main conference\n7580\nand the shared task, and Volume 2: Proceedings of\nthe Sixth International Workshop on Semantic Eval-\nuation (SemEval 2012) , pages 394‚Äì398, Montr√©al,\nCanada. Association for Computational Linguistics.\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,\nMantas Mazeika, Dawn Song, and Jacob Steinhardt.\n2021. Measuring massive multitask language under-\nstanding. In International Conference on Learning\nRepresentations.\nDinesh Babu Jayagopi, Hayley Hung, Chuohao Yeo, and\nDaniel Gatica-Perez. 2009. Modeling dominance in\ngroup conversations using nonverbal activity cues.\nIEEE Transactions on Audio, Speech, and Language\nProcessing, 17(3):501‚Äì513.\nJaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brah-\nman, Chandra Bhagavatula, Ronan Le Bras, and\nYejin Choi. 2022. Maieutic prompting: Logically\nconsistent reasoning with recursive explanations. In\nProceedings of the 2022 Conference on Empirical\nMethods in Natural Language Processing , pages\n1266‚Äì1279, Abu Dhabi, United Arab Emirates. Asso-\nciation for Computational Linguistics.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In Advances\nin Neural Information Processing Systems.\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,\nJian-Guang Lou, and Weizhu Chen. 2022. On the\nadvance of making language models better reasoners.\narXiv preprint arXiv:2206.02336.\nIgor Mayer. 1997. Debating technologies. A Method-\nological Contribution to the Design and Evaluation\nof Participatory Policy Analysis. Tilburg, The Nether-\nlands.\nOpenAI. 2023. Gpt-4 technical report.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. Advances in Neural\nInformation Processing Systems, 35:27730‚Äì27744.\nJoon Sung Park, Joseph C O‚ÄôBrien, Carrie J Cai, Mered-\nith Ringel Morris, Percy Liang, and Michael S\nBernstein. 2023. Generative agents: Interactive\nsimulacra of human behavior. arXiv preprint\narXiv:2304.03442.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. The Journal of Machine Learning Research,\n21(1):5485‚Äì5551.\nRichard E Ransom, Christine Zuni, Philip Sam Delo-\nria, Robert N Clinton, Robert Laurence, Nell Jessup\nNewton, and Mario E Occhialino Jr. 1993. Recog-\nnizing and enforcing state and tribal judgments: A\nroundtable discussion of law, policy, and practice.\nAm. Indian L. Rev., 18:239.\nPritish Sahu, Michael Cogswell, Yunye Gong, and\nAjay Divakaran. 2022. Unpacking large language\nmodels with conceptual consistency. arXiv preprint\narXiv:2209.15093.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\net al. 2022. Multitask prompted training enables\nzero-shot task generalization. In International Con-\nference on Learning Representations.\nMaarten Sap, Hannah Rashkin, Derek Chen, Ronan\nLe Bras, and Yejin Choi. 2019. Social iqa: Com-\nmonsense reasoning about social interactions. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP), pages 4463‚Äì4473.\nTimo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio\nPetroni, Patrick Lewis, Gautier Izacard, Qingfei You,\nChristoforos Nalmpantis, Edouard Grave, and Sebas-\ntian Riedel. 2022. Peer: A collaborative language\nmodel. arXiv preprint arXiv:2208.11663.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. Commonsenseqa: A question\nanswering challenge targeting commonsense knowl-\nedge. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4149‚Äì4158.\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam\nShazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,\nAlicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.\n2022. Lamda: Language models for dialog applica-\ntions. arXiv preprint arXiv:2201.08239.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth√©e Lacroix,\nBaptiste Rozi√®re, Naman Goyal, Eric Hambro,\nFaisal Azhar, et al. 2023. Llama: Open and effi-\ncient foundation language models. arXiv preprint\narXiv:2302.13971.\nBoshi Wang, Xiang Deng, and Huan Sun. 2022a. Itera-\ntively prompt pre-trained language models for chain\nof thought. In Proceedings of the 2022 Conference\non Empirical Methods in Natural Language Process-\ning, pages 2714‚Äì2730.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. 2022b. Self-consistency\nimproves chain of thought reasoning in language\nmodels. arXiv preprint arXiv:2203.11171.\n7581\nYizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran, An-\njana Arunkumar, David Stap, et al. 2022c. Super-\nnaturalinstructions: Generalization via declarative\ninstructions on 1600+ nlp tasks. In Proceedings of\nthe 2022 Conference on Empirical Methods in Natu-\nral Language Processing, pages 5085‚Äì5109.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M\nDai, and Quoc V Le. 2022a. Finetuned language\nmodels are zero-shot learners. In International Con-\nference on Learning Representations.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,\nand Denny Zhou. 2022b. Chain-of-thought prompt-\ning elicits reasoning in large language models. In\nAdvances in Neural Information Processing Systems,\nvolume 35, pages 24824‚Äì24837.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Fei Xia, Ed H Chi, Quoc V Le, Denny Zhou,\net al. 2022c. Chain-of-thought prompting elicits rea-\nsoning in large language models. In Advances in\nNeural Information Processing Systems.\nChenfei Wu, Shengming Yin, Weizhen Qi, Xi-\naodong Wang, Zecheng Tang, and Nan Duan.\n2023. Visual chatgpt: Talking, drawing and edit-\ning with visual foundation models. arXiv preprint\narXiv:2303.04671.\nKai Xiong, Xiao Ding, Zhongyang Li, Li Du, Ting Liu,\nBing Qin, Yi Zheng, and Baoxing Huai. 2022. Reco:\nReliable causal chain reasoning via structural causal\nrecurrent neural networks. In Proceedings of the\n2022 Conference on Empirical Methods in Natural\nLanguage Processing, pages 6426‚Äì6438.\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2022. Automatic chain of thought prompt-\ning in large language models. arXiv preprint\narXiv:2210.03493.\nA Stance Selection & Argument\nGeneration\nA.1 ChatGPT, ChaGPT-0301, and GPT-4\nA.1.1 Experiment Details\nWe use OpenAI API* for experiments. For each\nexample in each dataset, we utilize zero-shot set-\nting for experiments. The temperature is set as 0.0\nfor reproducing, max generation length is set as\n512. The other hyper-parameters are all set as the\ndefault values.\n*https://platform.openai.com/overview\nPrompt 1 : Zero-shot Prompt of ChatGPT\nand ChatGPT-0301 on Œ±NLI, CommonsenseQA,\nCOPA, e-CARE, Social IQa, and PIQA\nUser: Question: The item was packaged in bubble wrap.\nWhat was the cause of this? Choices: (A) It was fragile. (B)\nIt was small.\nPlease answer the above question by choosing a more plau-\nsible answer. You should choose only one answer from the\nchoices and give a short explanation. Please use the format\nlike ‚ÄúAnswer: _ is more plausible. Explanation: _.‚Äù\nAssistant: Answer: (A) is more plausible.\nExplanation: Bubble wrap is commonly used to protect\nfragile items during shipping or transportation. The bubbles\nprovide cushioning and absorb shock, reducing the risk of\ndamage to the item. Therefore, it is more plausible that the\nitem was packaged in bubble wrap because it was fragile\nand needed extra protection.\nPrompt 2 : Zero-shot Prompt of ChatGPT and\nChatGPT-0301 on StrategyQA\nUser: Question: Is it common to see frost during some\ncollege commencements?\nPlease answer yes or no to this question and give a short\nexplanation. Please use the format like ‚ÄúAnswer: _. Expla-\nnation: _‚Äù\nAssistant: Answer: yes.\nExplanation: It is common to see frost during some college\ncommencements, especially in colder regions or during\nwinter months. Outdoor commencements are often held\nin May or June, which can still be chilly in some areas.\nAdditionally, some colleges and universities hold winter\ncommencements in December or January, which are more\nlikely to experience frost or snow.\nA.1.2 Prompts\nFor all used datasets, we use a unified prompt to\nmake ChatGPT and ChatGPT-0301 give answers\nand explanations. The prompt for Œ±NLI, Com-\nmmonsenseQA, COPA, e-CARE, Social IQa, and\nPIQA is shown in Prompt 1. While for StrategyQA,\nthe prompt is shown in Prompt 2.\nA.2 Davinci-003, LLaMA, and Vicuna\nA.2.1 Experimental Details\nFor Davinci-003, we use OpenAI API‚Ä† for experi-\nments. For LLaMA and Vicuna, we apply for the\nofficial model checkpoints for experiments. All\ntemperatures are set as 0.0, max generation lengths\nare set as 512.\nA.2.2 Prompts\nAll LLMs share the same prompt for each dataset.\nSpecifically, we design few-shot CoT prompts for\nŒ±NLI (Prompt 3), CommonsenseQA (Ptompt 4),\n‚Ä†https://platform.openai.com/overview\n7582\nCOPA (Prompt 5), e-CARE (Prompt 6), Social\nIQa (Prompt 7), PIQA (Prompt 8), and Strate-\ngyQA (Prompt 9).\nB Fair Debate\nSince ChatGPT and ChaGPT-0301 are chat models,\nwhile Davinci-003, LLaMA, and Vicuna are text\ncompletion models, we use the same prompt with\ndifferent formats to guide the debates.\nFor ChatGPT & Davinci, Prompt 10 is used\nwhen ChatGPT debates, Prompt 11 is used when\nDavinci-003 debates.\nFor ChatGPT & ChatGPT-0301, Prompt 13 is\nused for ChatGPT, the same prompt is also used\nfor ChatGPT-0301.\nFor LLaMA & Vicuna, they share a same debate\nprompt (Prompt 12).\nC Mismatched Debate\nHere we introduce GPT-4 for one of the mis-\nmatched debates, GPT-4 is also a chat model like\nChatGPT. The initial INCON of the mismatched de-\nbates is shown in Figure 8.\nFor ChatGPT & GPT-4, the prompt is the same\nlike ChatGPT & ChatGPT-0301 (Prompt 13).\nFor LLaMA & ChatGPT, the prompt is the same\nlike ChatGPT & Davinci-003 (Prompt 10 for Chat-\nGPT, Prompt 11 for LLaMA).\nD Roundtable Debate\nConsidering there are three participants in the\nroundtable debates, the debate is hard to conducted\nfor chat models like ChatGPT and GPT-4. So we\ndesign roundtable debate prompt for roundtable de-\nbates. Prompt 13 is used for both ChatGPT and\nGPT-4, Prompt 14 is used for Davinci-003. Note\nthat, ChatGPT is user1, Davinci-003 is user2, and\nGPT-4 is user3.\nE Debate Summarization\nFor the basic setting, we just use the words ‚Äúwhile‚Äù,\n‚Äúdefend‚Äù, ‚Äúargue‚Äù, ‚Äúcompromise‚Äù, ‚Äúclaim‚Äù, ‚Äúsup-\npose‚Äù, and ‚Äúagree‚Äù to connect different arguments\nfor summarization according to the stance of each\nargument. For example, we can use template ‚ÄúThis\ndebate is about the question [Question], the pro-\nponent thinks option [Proponent‚Äôs Stance] is bet-\nter, [Proponent‚Äôs Argument1], while the opponent\nDataset FORD (w/o GPT-4) FORD (w/ GPT-4)\nŒ±NLI 78.30 78.63\nCSQA 76.41 76.90\nCOPA 97.60 97.80\ne-CARE 81.95 82.05\nSocial IQa 73.75 73.80\nPIQA 82.70 82.75\nStrategyQA 69.65 69.65\nAverage 80.05 80.23\nTable 8: The effect of GPT-4 as the judge on the debates\nbetween ChatGPT and ChatGPT-0301.\ne-CARE PIQA\n0\n10\n20\n30\n40INCON (%)\nChatGPT & GPT-4 LLaMA & ChatGPT\nFigure 8: The INCON of mismatched LLMs pairs on\ne-CARE and PIQA. The brighter part of each bar de-\nnotes the proportion of the examples that the opposition\npredicts correctly.\nsuppose [Opponent‚Äôs Argument1]. The proponent\nargues that [Proponent‚Äôs Argument2]. However,\nthe opponent still claims [Opponent‚Äôs Argument2].\nFinally, the proponent agrees with the opponent\nand compromises.‚Äù\nFor the final conclusion, if the debaters achieve\nagreements, then the answer of the examples are\nthe agreed answer. If the debater do not reach\nagreements, then we will collect the stance of each\nargument, and vote for the final answer.\nF GPT-4 as the Judge\nIn the in-depth analysis, we adopt GPT-4 as the\njudge to summarize the debate process and give a\nfinal conclusion. The prompt we used is shown in\nPrompt 15.\nTable 8 shows the overall performance of GPT-4\nas the judge in the debates of ChatGPT & ChatGPT-\n0301.\nG Ablation Study\nTable 9 shows the ablation study results on Chat-\nGPT & ChatGPT-0301.\n7583\nPrompt 3 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on Œ±NLI\nQuestion: Chad went to get the wheel alignment measured on his car. Which event could cause The mechanic provided a\nworking alignment with new body work? Answer Choices: (A) Chad was waiting for his car to be washed. (B) Chad was\nwaiting for his car to be finished.\nAnswer: Option (B) suggests that Chad was waiting for the mechanic to complete work on his car, which likely includes\nfixing the alignment and performing body work. In contrast, option (A) is about car washing and doesn‚Äôt involve the necessary\nrepairs or adjustments. Therefore, the answer is (B).\nQuestion: The boy loved telling scary stories. Which event could cause She mad him stop telling myths? Answer Choices:\n(A) His stories were so vivid it gave her happy dreams. (B) His stories were so vivid it gave her nightmares.\nAnswer: Option (B) indicates that the boy‚Äôs vivid scary stories caused her to have nightmares, which would provide a reason\nfor her to make him stop telling myths. Option (A), on the other hand, suggests that his stories led to happy dreams, which\nwouldn‚Äôt motivate her to ask him to stop. Therefore, the answer is (B).\nQuestion: Aurora and Jonah are building a sandcastle. Which event could cause They smile in satisfaction as they examine\ntheir completed project? Answer Choices: (A) Aurora and Jonah take their time creating with the sand. (B) The tide washed\naway their work.\nAnswer: Option (A) implies that Aurora and Jonah carefully worked on their sandcastle, leading to a satisfying completed\nproject. Option (B) suggests the tide destroyed their work, which wouldn‚Äôt result in satisfaction from examining a completed\nproject. Therefore, the answer is (A).\nQuestion: Ed had never tried carrots. Which event could cause He made $5 and found that he liked carrots after all? Answer\nChoices: (A) The reader told him he would win money. (B) The reader told him he would lose money.\nAnswer: The reader may have told Ed he would win money if he tried carrots, prompting him to try them. Upon trying the\ncarrots, Ed not only made $5 but also discovered that he liked them after all. Therefore, the answer is (A).\nMethod e-CARE PIQA\nChatGPT 81.53 80.74\nChatGPT-0301 81.53 80.79\nCol-Soft 81.53 80.77\nCol-Hard 79.55 77.97\nFORD 81.95 82.70\nFORD (Reverse Order) 81.81 81.34\nTable 9: The overall results when the debate order is reversed in ChatGPT & ChatGPT-003.\nDebates Dataset ChatGPT Davinci-003 GPT-4 ChatGPT-0301\nR1 e-CARE 32.64 14.02 53.35 -\nPIQA 23.64 16.11 60.25 -\nR2 e-CARE 51.23 7.24 - 41.53\nPIQA 52.04 4.87 - 43.08\nTable 10: The overall dominance of roundtable debates.\n7584\nPrompt 4 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on CommonsenseQA\nQuestion: What do people use to absorb extra ink from a fountain pen? Answer Choices: (A) shirt pocket (B) calligrapher‚Äôs\nhand (C) inkwell (D) desk drawer (E) blotter\nAnswer: A blotter is specifically designed to absorb excess ink from a fountain pen, helping to prevent smudging and\nmaintaining neatness. Therefore, the answer is (E).\nQuestion: What home entertainment equipment requires cable? Answer Choices: (A) radio shack (B) substation (C) television\n(D) cabinet\nAnswer: A television is the home entertainment equipment that typically requires a cable connection for accessing various\nchannels and content. Therefore, the answer is (C).\nQuestion: The fox walked from the city into the forest, what was it looking for? Answer Choices: (A) pretty flowers (B) hen\nhouse (C) natural habitat (D) storybook\nAnswer: Foxes typically live in forests and wooded areas. The most plausible reason for a fox walking from the city into the\nforest is to return to or seek out its natural habitat. Therefore, the answer is (C).\nQuestion: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (A) populated areas (B)\nrace track (C) desert (D) apartment (E) roadblock\nAnswer: If Sammy wants to go where the people are, he would likely head to populated areas, such as cities, towns, or other\nplaces with a high concentration of people. Among the given options, choice (A) is the most suitable for Sammy‚Äôs objective.\nTherefore, the answer is (A).\nQuestion: Where do you put your grapes just before checking out? Answer Choices: (A) mouth (B) grocery cart (C)super\nmarket (D) fruit basket (E) fruit market\nAnswer: When you are shopping for groceries and want to purchase grapes, you would place them in your grocery cart\njust before checking out. This allows you to transport the grapes and other items to the checkout counter to pay for them.\nTherefore, the answer is (B).\nQuestion: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (A) united states\n(B) mexico (C) countryside (D) atlas\nAnswer: Google Maps and other GPS services have largely replaced traditional paper atlases and maps, which were once\ncommonly used for navigation purposes. Atlases are collections of maps that cover various geographical regions, such as\ncountries, states, or continents. With the advent of digital mapping and GPS services, the need for physical atlases has\nsignificantly diminished. Therefore, the answer is (D).\nQuestion: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (A) harder (B)\nanguish (C) bitterness (D) tears (E) sadness\nAnswer: If the wife felt that she was doing all the work in the relationship, it is likely that she experienced feelings of\nbitterness or resentment towards her spouse. This emotion captures the sense of unfairness or imbalance she may have\nperceived in the relationship. Therefore, the answer is (C).\nPrompt 5 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on COPA\nQuestion: My body cast a shadow over the grass. What was the cause of this? Answer Choices: (A) The sun was rising. (B)\nThe grass was cut.\nAnswer: The cause of your body casting a shadow over the grass is due to the presence of a light source, in this case, the sun.\nWhen the sun is rising (or setting), it creates an angle that casts shadows on the ground. Therefore, the answer is (A).\nQuestion: The driver got pulled over by the police. What was the cause of this? Answer Choices: (A) He was parking. (B)\nHe was speeding.\nAnswer: Speeding is a common traffic violation that results in drivers being stopped by law enforcement. Therefore, the\nanswer is (B).\nQuestion: Several witnesses of the crime testified against the suspect. What happened as a result? Answer Choices: (A) The\nsuspect was acquitted. (B) The suspect was convicted.\nAnswer: If several witnesses testified against the suspect, it would likely provide strong evidence for the prosecution, making\nit more probable that the suspect would be convicted. Therefore, the answer is (B).\nQuestion: The company‚Äôs profits started to level off. What happened as a result? Answer Choices: (A) It increased its\nmarketing efforts for new products. (B) It moved its headquarters to a suburban location.\nAnswer: If the company‚Äôs profits started to level off, it is more likely that they would try to boost sales and revenue by\nincreasing marketing efforts for new products. Therefore, the answer is (A).\n7585\nPrompt 6 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on e-CARE\nQuestion: There is a light rain today. What happened as a result? Answer Choices: (A) The roots of many plants are not\nmoistened by rain. (B) Tourists have seen many ripples.\nAnswer: Light rain may not be enough to penetrate the soil deeply and reach the roots of many plants, which can cause the\nroots to remain dry. Therefore, the answer is (A).\nQuestion: All devices inside were turned off. What was the cause of this? Answer Choices: (A) The beaker was broken down.\n(B) We have to reduced the energy consumption in that room to zero.\nAnswer: Turning off all devices inside a room to reduce energy consumption to zero is an unusual and extreme measure and\nis not a likely cause of all devices inside being turned off. Therefore, the answer is (B).\nQuestion: There are increased eosinophils in the blood. What happened as a result? Answer Choices: (A) There is no lesion.\n(B) It is the benign lesion of gastric carcinoma.\nAnswer: There is no clear link between increased eosinophils in the blood and gastric carcinoma. Therefore, the answer is\n(B).\nQuestion: Water molecules couldn‚Äôt enter the mycobateria freely due to its outter membrane. What was the cause of this?\nAnswer Choices: (A) The mycobacteria was put in water solution. (B) The Ammonium based fertilizers led to the process of\nnitrification to nitrate in the soil.\nAnswer: Mycobacteria have a unique outer membrane that is resistant to water, and when placed in a water solution, water\nmolecules may be unable to penetrate the outer membrane and enter the bacterial cell. Therefore, the answer is (A)\nPrompt 7 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on Social IQa\nQuestion: Cameron decided to have a barbecue and gathered her friends together. How would Others feel as a result? Answer\nChoices: (A) like attending (B) like staying home (C) a good friend to have\nAnswer: Friends will gladly accept invitations. Therefore, the answer is (A).\nQuestion: Remy was walking in the park and approached a girl in the park. Why did Remy do this? Answer Choices: (A)\nwalk with the girl (B) speak to the girl (C) act confident\nAnswer: When strangers approach you, sometimes they just want to ask you something. Therefore, the answer is (B).\nQuestion: Kai let their children go into the water to swim at the pool. How would you describe Kai? Answer Choices: (A)\nkai who has swimming a pool (B) kai who has like achildren (C) As someone who wants them to have fun\nAnswer: The children want to go into the pool and Kai respects the wishes of the children, this means the children will have\nfun. Therefore, the answer is (C).\nQuestion: Austin told their friends at the house party that they saw another ghost. How would their friends feel as a result?\nAnswer Choices: (A) amused by Austin (B) angry at Austin (C) into supernatural stuff\nAnswer: Ghost don‚Äôt exist in the world. Austin‚Äôs friends would think Austin are telling a joke. Therefore, the answer is (A).\nQuestion: Casey ran the cases of soda back to the yard when she arrived home for the party. How would Casey feel afterwards?\nAnswer Choices: (A) like leaving town (B) a community contributor (C) glad she was on time\nAnswer: Parties need soda, Casey donate her soda to people, she is generous. Therefore, the answer is (B).\nQuestion: After listening to bad investment advice from a friend, Jesse lost every cent. What will happen to Jesse? Answer\nChoices: (A) regret not investing more (B) prescient (C) have less money to spend\nAnswer: Jesse lost money due to investment, she would wish she hasn‚Äôt invested so much before and feel like she has no\nprescient. After losing money, she would have less money to spend than before. Therefore, the answer is (C).\n7586\nPrompt 8 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on PIQA\nQuestion: When boiling butter, when it‚Äôs ready, you can Answer Choices: (A) Pour it onto a plate (B) Pour it into a jar\nAnswer: When boiling butter (likely to make clarified butter or ghee), once it‚Äôs ready, you would typically pour it into a jar or\nanother heat-resistant container to store or use it for cooking purposes. Therefore, the answer is (B).\nQuestion: how do you stab something? Answer Choices: (A) stick a sharp object through it. (B) pin it with a sharp object.\nAnswer: Stabbing something typically involves forcefully inserting a sharp object, such as a knife or a pointed instrument,\ninto it. This action usually results in penetration or puncturing. Therefore, the answer is (A).\nQuestion: To determine if a wound needs stitches, Answer Choices: (A) they are needed if the wound is more than one-quarter\ndecimeter deep, if the edges of the wound need to be pulled together to touch, or if the wound is on a part of the body that\nmoves a lot or on the face. (B) they are needed if the wound is more than one-quarter inch deep, if the edges of the wound\nneed to be pulled together to touch, or if the wound is on a part of the body that moves a lot or on the face.\nAnswer: One-quarter inch is a more common and practical measurement for wound depth than one-quarter decimeter (which\nis equivalent to 2.5 centimeters or about 1 inch). Therefore, the answer is (B).\nQuestion: To take the steering wheel off the your car Answer Choices: (A) Turn the car off first and use a screw driver to\nloosen the screw located behind the steering wheel. (B) Loosen the screw\nAnswer: When removing the steering wheel from a car, it is important to follow safety precautions and use the appropriate\ntools. Option (A) provides a more detailed and safer approach by instructing to turn the car off first and then use a screwdriver\nto loosen the screw located behind the steering wheel. Therefore, the answer is (A).\nPrompt 9 : Few-shot Examplers of Dvinci-003, LLaMA, and Vicuna on StrategyQA\nQuestion: Do hamsters provide food for any animals?\nAnswer: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. Therefore,\nthe answer (yes or no) is yes.\nQuestion: Could Brooke Shields succeed at University of Pennsylvania?\nAnswer: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University\nof Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. Therefore, the answer (yes or no)\nis yes.\nQuestion: Yes or no: Hydrogen‚Äôs atomic number squared exceeds number of Spice Girls?\nAnswer: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen‚Äôs atomic number\nsquared is less than 5. Therefore, the answer (yes or no) is no.\nQuestion: Yes or no: Is it common to see frost during some college commencements?\nAnswer: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there\ncan be frost. Thus, there could be frost at some commencements. Therefore, the answer (yes or no) is yes.\nQuestion: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\nAnswer: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months.\nThus, a llama could not give birth twice during the War in Vietnam. Therefore, the answer (yes or no) is no.\nQuestion: Yes or no: Would a pear sink in water?\nAnswer: The density of a pear is about 0.6g/cm3, which is less than water. Objects less dense than water float. Thus, a pear\nwould float. Therefore, the answer (yes or no) is no.\n7587\nPrompt 10 : Fair debate of ChatGPT & Davinci-003 when ChatGPT debates\nSystem: You are in a debate now. My opinion is not always true, you can ignore any incorrect part of my opinion. And you\ncan refer to my opinion to revise your choice or defend your own. Please remember there should and must be a more plausible\nanswer in the choices.\nUser: Question: The child brought psycho-physical phenomena on a new life. What was the cause of this? Choices: (A) The\nwoman gave birth to a child. (B) The baby feels the awareness through physical sensations.\nChatGPT: Psycho-physical phenomena refer to the interaction between the mind and body. In this case, the baby is\nexperiencing these phenomena because they are becoming aware of their surroundings through physical sensations such as\ntouch, taste, smell, sight, and sound. This is a natural part of the development process as the baby learns to navigate and\ninteract with the world around them. The act of giving birth alone does not cause psycho-physical phenomena, but rather it is\nthe baby‚Äôs sensory experiences that lead to this phenomenon.\nDavinci-003: The cause of the child bringing psycho-physical phenomena on a new life is the woman giving birth to the child\nDo you think I am more reasonable? Please give your final answer starting with \"Answer: (A|B) is more plausible.\" and\nexplain very shortly starting with \"Explanation: \". You should choose only one answer.\nChatGPT:\nPrompt 11 : Fair debate of ChatGPT & Davinci-003 when Dvinci-003 debates\nYou are in a debate now. My opinion is not always true, you can ignore any incorrect part of my opinion. And you can refer to\nmy opinion to revise your choice or defend your own. Please remember there should and must be a more plausible answer in\nthe choices.\nQuestion: The child brought psycho-physical phenomena on a new life. What was the cause of this? Choices: (A) The\nwoman gave birth to a child. (B) The baby feels the awareness through physical sensations.\nYou: Psycho-physical phenomena refer to the interaction between the mind and body. In this case, the baby is experiencing\nthese phenomena because they are becoming aware of their surroundings through physical sensations such as touch, taste,\nsmell, sight, and sound. This is a natural part of the development process as the baby learns to navigate and interact with\nthe world around them. The act of giving birth alone does not cause psycho-physical phenomena, but rather it is the baby‚Äôs\nsensory experiences that lead to this phenomenon.\nMe: The cause of the child bringing psycho-physical phenomena on a new life is the woman giving birth to the child\nDo you think I am more reasonable? Please give your final answer starting with \"Answer: (A|B) is more plausible.\" and\nexplain very shortly starting with \"Explanation: \". You should choose only one answer.\nYou:\nPrompt 13 : Fair debate of ChatGPT & ChatGPT-0301 when ChatGPT debates\nSystem: You are in a debate now. My opinion is not always true, you can ignore any incorrect part of my opinion. And you\ncan refer to my opinion to revise your choice or defend your own. Please remember there should and must be a more plausible\nanswer in the choices.\nUser: Question: The woman lost her place in line. What was the cause of this? Choices: (A) More people entered the line.\n(B) She stepped out of the line.\nChatGPT: This answer is more plausible because it directly states that the woman herself did something that caused her to\nlose her place in line. Option (A) suggests that other people caused her to lose her place, which is possible but not necessarily\nthe most likely scenario.\nChatGPT-0301: If the woman lost her place in line, it is more likely that it was due to more people entering the line, thus\npushing her back.\nDo you think I am more reasonable? Please give your final answer starting with \"Answer: (A|B) is more plausible.\" and\nexplain very shortly starting with \"Explanation: \". You should choose only one answer.\nChatGPT:\n7588\nPrompt 12 : Fair debate of LLaMA & Vicuna when LLaMA or Vicuna debates\nYou are in a debate now. My opinion is not always true, you can ignore any incorrect part of my opinion. And you can refer to\nmy opinion to revise your choice or defend your own. Please remember there should and must be a more plausible answer in\nthe choices.\nQuestion: What do animals do when an enemy is approaching? Choices: (A) feel pleasure (B) procreate (C) pass water (D)\nlisten to each other (E) sing\nYou: When an enemy is approaching, animals typically respond by fleeing or hiding in order to protect themselves. This is a\nnatural instinct that helps them to survive in the wild.\nMe: When an enemy is approaching, animals often rely on their sense of hearing to detect any potential danger.\nDo you think I am more reasonable? Please give your final answer starting with \"Answer: (A|B) is more plausible.\" and\nexplain very shortly starting with \"Explanation: \". You should choose only one answer.\nYou:\nPrompt 13 : Roundtable debate when ChatGPT, ChatGPT-0301, or GPT-4 debates\nSystem: Now you are user1 in a round table debate of three users. The debate is about choosing a more plausible Option (A or\nB) to answer the Question below. The opinions of the other two users are not always true, you can ignore any incorrect part of\ntheir opinion. And you can refer to their opinions to revise your choice or defend your own. Please remember there should and\nmust be a more plausible answer in the choices.\nUser: Question: He found out that cytokines worked in it. What was the cause of this? Choices: (A) Tom was studying how\nbody temperature rises. (B) The scientist testing lipoproteins.\nUser: user1: The sentence ¬®The general‚Äôs surrender was regarded as a shameful action¬®suggests that Bob‚Äôs action was related to\nthe general‚Äôs surrender. It is possible that Bob‚Äôs action was seen as dishonoring the general‚Äôs surrender or violating some\ncode of conduct related to it, leading to the judge‚Äôs decision that he had committed a crime. On the other hand, choice B does\nnot provide a convincing reason for the judge‚Äôs decision, as putting a knife around someone‚Äôs neck is generally considered a\nthreatening and violent act regardless of the intention behind it.\nuser2: Bob‚Äôs action of putting a knife around the victim‚Äôs neck was likely the cause of the judge holding that he had committed\na crime and sentencing him.\nuser3: The cause of the judge‚Äôs decision was likely due to Bob‚Äôs actions involving a knife and the victim‚Äôs neck, which could\nbe considered a crime regardless of his stated intentions.\nRemember you are user1. What do you think about the opinions of user2 and user3? more reasonable? or more unreasonable?\nPlease give your final answer choice of the Question starting with ‚ÄúAnswer: (A|B) is more plausible.‚Äù and explain very shortly\nstarting with ‚ÄúExplanation: ‚Äù. You should choose only one option.\nChatGPT:\nPrompt 14 : Roundtable debate when Davinci-003 debates\nNow you are user2 in a round table debate of three users. The debate is about choosing a more plausible Option (A or B) to\nanswer the Question below. The opinions of the other two users are not always true, you can ignore any incorrect part of their\nopinion. And you can refer to their opinions to revise your choice or defend your own. Please remember there should and must\nbe a more plausible answer in the choices.\nQuestion: He found out that cytokines worked in it. What was the cause of this? Choices: (A) Tom was studying how body\ntemperature rises. (B) The scientist testing lipoproteins.\nuser2: Colonoscopy is a procedure used to examine the inside of the colon and rectum. It is not likely to result in a diagnosis\nof prolapse.\nuser3: The question asks about the result of the colonoscopy check, and option (A) is more plausible as it describes a\npossible reaction to the procedure. Option (B) is not a guaranteed result of a colonoscopy, as the diagnosis could show various\noutcomes.\nuser1: A colonoscopy is a medical procedure that allows a doctor to examine the inside of the colon for any abnormalities or\ndiseases. If the diagnosis showed that the individual had prolapse, it means that there was a displacement of an organ or tissue\nfrom its normal position. This could be a serious condition that requires further medical attention and treatment. It is unlikely\nthat the individual would be terrified of the instrument used for the examination as it is a routine procedure and the doctor\nwould have provided adequate information and reassurance beforehand.\nRemember you are user2. What do you think about the opinions of user1 and user3? more reasonable? or more unreasonable?\nPlease give your final answer choice of the Question starting with ‚ÄúAnswer: (A|B) is more plausible.‚Äù and explain very shortly\nstarting with ‚ÄúExplanation: ‚Äù. You should choose only one option.\nuser2:\n7589\nPrompt 15 : GPT-4 as the judge\nSystem: You are given a Question and its corresponding Options. There is a debate on this question between user1 and user2,\none user might give in, please summarise the debate very shortly. Then give the conclusion based on the debate process. Your\nresponse should be in the format like ‚ÄúSummary: ___. Conclusion: (A or B) is more plausible.‚Äù Remember that you should\nchoose only one option for the answer.\nUser: Question: Lisa and Tim had been married for a long time. Which event could cause It worked Choices: (A) Lisa and\nTim went to a fertility clinic to get pregnant. (B) They decided to try the advice given in a book about guitar playing.\nuser1: It is more plausible that Lisa and Tim, who have been married for a long time, would try to improve their skills in a\nhobby they both enjoy, such as playing the guitar, rather than going to a fertility clinic to get pregnant. Improving their guitar\nplaying skills could bring them closer together and strengthen their bond, while trying to conceive a child may not necessarily\nguarantee a successful pregnancy.\nuser2: Option (A) suggests that Lisa and Tim went to a fertility clinic to get pregnant, which could lead to the statement ‚ÄúIt\nworked‚Äù if they were successful in conceiving a child. Option (B) is about guitar playing and doesn‚Äôt relate to the statement\n‚ÄúIt worked‚Äù.\nJudge (GPT-4):\n7590"
}