{
  "title": "ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model",
  "url": "https://openalex.org/W4402954232",
  "year": 2024,
  "authors": [
    {
      "id": "https://openalex.org/A2113178572",
      "name": "Dawei Wang",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2103953133",
      "name": "Geng Zhou",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A1971984624",
      "name": "Li Chen",
      "affiliations": []
    },
    {
      "id": "https://openalex.org/A2034219280",
      "name": "Dan Li",
      "affiliations": [
        "Tsinghua University"
      ]
    },
    {
      "id": "https://openalex.org/A2741933750",
      "name": "Yukai Miao",
      "affiliations": []
    }
  ],
  "references": [
    "https://openalex.org/W2777430404",
    "https://openalex.org/W4378591002",
    "https://openalex.org/W4391579642",
    "https://openalex.org/W2964241064",
    "https://openalex.org/W4281713017",
    "https://openalex.org/W4384304865",
    "https://openalex.org/W4391724785",
    "https://openalex.org/W4384155653",
    "https://openalex.org/W3105061167",
    "https://openalex.org/W2794659749",
    "https://openalex.org/W4394769544",
    "https://openalex.org/W4385373745",
    "https://openalex.org/W4388858797",
    "https://openalex.org/W4378651134",
    "https://openalex.org/W4253752119",
    "https://openalex.org/W4308469411"
  ],
  "abstract": "Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only \\$8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30\\% of the predicted high-risk option combinations, which was 32.85\\% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.",
  "full_text": "ProphetFuzz: Fully Automated Prediction and Fuzzing of\nHigh-Risk Option Combinations with Only Documentation via\nLarge Language Model\nDawei Wang\nZhongguancun Laboratory\nBeijing, China\nwangdw@zgclab.edu.cn\nGeng Zhou\nZhongguancun Laboratory\nBeijing, China\nzhougeng@zgclab.edu.cn\nLi Chen∗\nZhongguancun Laboratory\nBeijing, China\nlichen@zgclab.edu.cn\nDan Li\nTsinghua University\nBeijing, China\ntolidan@tsinghua.edu.cn\nYukai Miao\nZhongguancun Laboratory\nBeijing, China\nmiaoyk@zgclab.edu.cn\nAbstract\nVulnerabilities related to option combinations pose a significant\nchallenge in software security testing due to their vast search space.\nPrevious research primarily addressed this challenge through mu-\ntation or filtering techniques, which inefficiently treated all option\ncombinations as having equal potential for vulnerabilities, thus\nwasting considerable time on non-vulnerable targets and resulting\nin low testing efficiency. In this paper, we utilize carefully designed\nprompt engineering to drive the large language model (LLM) to\npredict high-risk option combinations (i.e., more likely to contain\nvulnerabilities) and perform fuzz testing automatically without\nhuman intervention. We developed a tool called ProphetFuzz and\nevaluated it on a dataset comprising 52 programs collected from\nthree related studies. The entire experiment consumed 10.44 CPU\nyears. ProphetFuzz successfully predicted 1748 high-risk option\ncombinations at an average cost of only $8.69 per program. Re-\nsults show that after 72 hours of fuzzing, ProphetFuzz discovered\n364 unique vulnerabilities associated with 12.30% of the predicted\nhigh-risk option combinations, which was 32.85% higher than that\nfound by state-of-the-art in the same timeframe. Additionally, us-\ning ProphetFuzz, we conducted persistent fuzzing on the latest\nversions of these programs, uncovering 140 vulnerabilities, with 93\nconfirmed by developers and 21 awarded CVE numbers.\n1 Introduction\nThe growth in software complexity has led to a significant increase\nin the number of program options and combinations. For example,\nImageMagick has 305 options, leading to2305 possible combinations,\nignoring the different values that each option’s parameters can take.\nThis exponential increase in combinations creates many unique\nexecution paths, expanding the search space for vulnerabilities.\nThese paths are only active with specific combinations, challenging\ntraditional mutation-based fuzzing techniques.\nIn recent years, there has been continuous effort to develop\nfuzzing methods focused on exploring option combinations. POW-\nER [15] and ConfigFuzz [43] increase path coverage by mutating\nthe options and their values under test. CarpetFuzz [34] aims to tra-\nverse the complete list of fuzzing combinations by initially filtering\n∗ Corresponding author.\nout all invalid combinations of options. These efforts have proven\nto be more effective in testing program paths related to option com-\nbinations than traditional fuzzers (e.g., AFL++ [9]). However, they\nare still limited in the following aspects: L1- Lack of Prioritization :\nThese approaches test each generated combination equally, yet the\nrisk of vulnerabilities varies among different combinations. For\nexample, combinations that involve file parsing options are more\nlikely to have vulnerabilities than combinations that affect only the\nuser interface settings. Excessively testing low-risk combinations\n(i.e., unlikely to contain vulnerabilities) will reduce the efficiency\nof fuzz testing. L2- Semantic Mismatch : Every component of an\nexecutable command, such as options, values, and files, is inter-\nconnected, requiring adherence not just to the correct format and\nstructure (syntactic correctness), but, more importantly, to semantic\nmatching and collaboration to ensure the command executes as\nintended. Consider the option“-f avi”, which specifies that the input\nmust be in AVI format; accordingly, the command with this option\nfunctions properly only with inputs in AVI format, and using any\nother format leads to execution errors. However, in existing propos-\nals, the components of generated commands originate primarily\nfrom random mutations or simplistic selections, leading to a lack of\ncoherent and meaningful interaction between components, thereby\ncausing semantic mismatches. L3- Reliance on Expertise : These ap-\nproaches require extensive manual effort in the setup stages, such as\nassembling commands, assigning values, and collecting input files,\nwith a strong dependence on the deep expertise of software testers.\nThis not only limits the methods’ ability to scale for comprehensive\ntesting, but also raises the barrier of entry.\nIf it were possible to incorporate the expertise of security test-\ning experts into an automated tool for predicting high-risk option\ncombinations and configuring fuzz tests, it could address all the\nlimitations mentioned above. This is because reports indicate that\nexperienced security professionals are often able to predict high-\nrisk targets by analyzing documentation and crafting appropriate\ncommands and fuzzing configurations based on the semantic con-\ntext of these targets [2, 21, 33].\nWe believe that the recent advancement of large language mod-\nels (LLMs) has made this idea possible. Trained on extensive text\ndatasets with up to 500 billion tokens [4], these models grasp the\ncomplex structures and patterns of language, amassing a wide range\n1\narXiv:2409.00922v1  [cs.CR]  2 Sep 2024\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nof knowledge and the capacity for text comprehension and genera-\ntion [1, 26, 30, 31]. This equips them for a range of sophisticated\nlanguage understanding and generation tasks. Recent studies show\nthat LLMs can detect hidden patterns in text and even surpass ex-\nperts in some predictive tasks [18, 38]. Motivated by these findings,\nwe sought to apply LLMs to address the limitations described here.\nHowever, our initial efforts reveal that direct application of\nthese models did not achieve our expected results (discussed in\nSection 5.5), which presented the following challenges:\nChallenges. C1: LLMs tend to identify option combinations that\nviolate constraints (i.e., conflicts and dependencies) as high-risk tar-\ngets, leading to premature program termination and hindering the\nexploration of program paths. Therefore, informing the LLM of the\ncorrect constraints in advance is essential to prevent the generation\nof invalid combinations. While CarpetFuzz can automatically ex-\ntract such constraints from documentation using natural language\nprocessing (NLP) techniques, its reliance on heuristic rules limits\nits scalability (discussed in Section 5.3). In contrast, the use of LLMs\nfor constraint extraction offers broader applicability, but also en-\ncounters the challenge of LLM “hallucinations” [41] (i.e., generating\ninaccurate or fictitious information). Ensuring the precision of the\nconstraints extracted by LLMs poses a significant challenge.C2: Al-\nthough LLMs are adept at understanding and generating natural\nlanguage, they have not been explicitly trained to recognize the\nrelationships between documentation descriptions and historical\nhigh-risk combinations. This gap can lead to a deficiency in spe-\ncialized knowledge and deep comprehension when handling such\ntasks. A common strategy to bridge this knowledge gap, known as\nfew-shot learning [4], involves enhancing the model’s inference\nwith a few analysis examples. However, the effectiveness of this\nstrategy depends on the availability of such examples, which re-\nquires manual analysis by experienced security professionals and is\ntherefore constrained by the availability of expert resources. Conse-\nquently, establishing such relationships without direct intervention\nfrom experts remains a significant challenge. C3: To match the\nsemantics of other components within the commands, it may be\nnecessary to produce configuration files and input files in various\nformats. However, LLMs are primarily skilled in generating text-\nbased inputs. Although the latest multimodal LLMs [ 23, 30] can\nhandle inputs such as images, videos, and sounds, they generally\ndo not accommodate the wide range of input formats that different\nsoftware requires, such as network traffic packets, compressed files,\nor Executable and Linkable Format (ELF) files. Therefore, effec-\ntively enabling models to generate these diverse, non-textual input\nformats presents a considerable challenge.\nOur Approach. In this paper, we design ProphetFuzz, an LLM-\nbased, fully automated fuzzing tool for option combination testing.\nProphetFuzz can predict and conduct fuzzing on high-risk option\ncombinations 1 with only documentation, and the entire process\noperates without manual intervention. Given a program’s docu-\nmentation, ProphetFuzz begins by extracting essential details such\nas the program’s name, description, usage synopsis, and option\ndescriptions through keyword matching, which is sufficient for this\ntask and cost-effective. It then leverages the LLM to identify the\n1Due to the nature of fuzzing, this paper focuses on memory corruption vulnerabili-\nties. “High-risk option combinations” refer to “high-risk memory-corruption option\ncombinations” in the following text.\nconstraints between options based on these details. To ensure the\nprecision of these identifications, we develop a self-check approach\nutilizing bidirectional reasoning (C1). The intuition behind this\napproach is that consistent answers from different perspectives\nsuggest higher correctness, similar to methods used in verifying\nmathematical reasoning [10, 13]. Specifically, this method employs\nboth direct proof and counterproof to assist the LLM in uncovering\ncontradictions in its reasoning, thus allowing for the elimination\nof inaccuracies in the results identified. Guided by the constraints\nidentified, ProphetFuzz predicts high-risk combinations based on\nthe descriptions of the options. To address the knowledge gap re-\ngarding the relationship between documentation and historical\nhigh-risk combinations, we design a few-shot learning method to\nbridge these gaps and an automated few-shot corpus generation\nmethod to create analysis examples as supplementary knowledge\nfor the LLM (C2). This method creates eight analysis examples from\n29 historical high-risk combinations across eight different programs.\nNote that the creation of these examples does not require expert par-\nticipation. For the predicted high-risk combinations, ProphetFuzz\ninitially guides the LLM to comprehend the collective semantics\nof the option combination and leverage this understanding to al-\nlocate option values and files with consistent semantics, thereby\ngenerating semantically matched commands. Specifically for con-\nfiguration and input files, instead of directly generating these files,\nProphetFuzz creates Python scripts capable of generating these files\nand executes these scripts within a sandbox environment to obtain\nthe required files (C3). Finally, ProphetFuzz inputs all generated\ncommands and corresponding files into the fuzzer to carry out fuzz\ntesting on the high-risk option combinations.\nWe implement a prototype of ProphetFuzz on GPT-4 Turbo,\nwhich is currently recognized as the most powerful LLM [17]. We\nconduct a thorough evaluation of ProphetFuzz across 52 open-\nsource programs collected from datasets used in three previous\nstudies. Within these programs, ProphetFuzz predicted 1748 high-\nrisk option combinations, assembling 7614 commands, and discov-\nered 364 unique vulnerabilities during 72 hours of fuzzing. Of these\ncombinations, 12.30% were successfully associated with the vul-\nnerabilities. This entire process required an average cost of just\n$8.69 per program. Compared to the current state-of-the-art (SOTA)\ntool, CarpetFuzz, ProphetFuzz utilized fewer commands (0.2×) yet\nidentified more unique vulnerabilities (1.3×), including 224 unique\nvulnerabilities that CarpetFuzz failed to find. During the process,\nProphetFuzz extracted 633 constraints from the documentation with\nan overall precision of 94.00% and an average precision of 92.48%,\noutperforming CarpetFuzz, which extracted 447 constraints with\n76.73% and 69.72%. Furthermore, our ablation studies on the option\nvalues and files generated by ProphetFuzz indicated that integrat-\ning these elements led to the discovery of 34.65% and 17.24% more\nunique vulnerabilities, respectively. We employ ProphetFuzz to per-\nform persistent fuzzing on the latest versions of these programs.\nTo date, ProphetFuzz has uncovered 140 zero-day or half-day 2\nvulnerabilities, 93 of which have been confirmed by the developers,\nearning 21 CVE numbers. Investigations into other reported issues\n2Vulnerabilities that have been exposed but have not yet been patched.\n2\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nare ongoing. Lastly, we analyze how ProphetFuzz predicts high-\nrisk combinations and reveal 15 pieces of knowledge for predicting\nhigh-risk combinations from documentation descriptions.\nResponsible Disclosure . To prevent malicious exploitation, all\nvulnerabilities discovered in this study were promptly disclosed to\nrelevant developers and the CVE organization. So far, 26 vulnera-\nbilities have been addressed and rectified.\nContributions. Our contributions are summarized as follows:\n•New technique . We introduce a novel, LLM-based technique\nfor fully automated prediction and fuzz testing of high-risk option\ncombinations. We address several critical challenges faced by out-\nof-the-box LLMs, such as hallucination and knowledge gaps. To\ntackle these issues, we develop a self-check technique for error\ncorrection, a few-shot learning method to bridge knowledge gaps\nin predicting high-risk combinations, and an automated method to\ngenerate few-shot corpora without expert input. This technique,\nleveraging only documentation, predicts high-risk combinations\nwithout the need for code information and conducts fuzz testing\non these combinations entirely automatically through our carefully\ndesigned prompts. The entire process, which includes document\nparsing, constraint extraction, target prediction, command assem-\nbly, file generation, and execution of fuzz tests, requires no manual\nintervention, with an average cost of only $8.69 per program.\n•Implementation and new findings . We develop the prototype\ntool ProphetFuzz and thoroughly evaluate its performance across\n52 programs gathered from datasets in three prior studies, an effort\nthat consumed a total of 10.44 CPU years. ProphetFuzz predicts\n1748 high-risk option combinations, identifies 364 vulnerabilities,\nand discovers 140 unique vulnerabilities in the latest versions of\nthese programs, 93 of which have been confirmed by the developers,\nearning 21 CVE numbers. Moreover, our analysis of ProphetFuzz’s\nprediction process highlights 15 key pieces of knowledge for pre-\ndicting high-risk option combinations, offering insights that are\nbeneficial for further development in this field. We have open-\nsourced ProphetFuzz and the related datasets to encourage further\nexploration and research within the community 3.\n2 Background and Related Work\n2.1 Option-Aware Fuzzing\nThe options define the behavior and functionality of the software, al-\nlowing users to customize the software to meet their specific needs.\nThis customization maximizes software efficiency across diverse\nuses and environments. These options encompass a broad range\nof scenarios, including network settings, resource allocations, and\nuser interface preferences. Although such flexibility markedly im-\nproves software usability and the user experience, it also introduces\ncomplexity and amplifies the challenges associated with software\ntesting. Each option can influence the behavior of the software,\nand the combination of multiple options may result in unexpected\nbehavior or security vulnerabilities, particularly without thorough\ntesting. Therefore, understanding and examining these options and\ntheir interplay is vital to ensuring software quality and security.\nOption-aware fuzzing is tailor-made for this specific requirement.\nIt considers the impact of software options and their combinations,\n3Available in https://github.com/NASP-THU/ProphetFuzz\ndynamically adjusting and applying the test option combinations on\nthe fly to explore the coverage of different test cases under various\noption combinations. However, due to the vast search space of op-\ntion combinations, thoroughly exploring the coverage under all op-\ntion combinations is unrealistic. To avoid missing vulnerabilities in\nany potential option combination as much as possible, researchers\nhave developed two categories of option-aware fuzzing techniques:\nmutation-based [3, 15, 35, 43] and filter-based [29, 34]. Mutation-\nbased option-aware fuzzing techniques introduce changes to option\ncombinations via mutations, with the aim of uncovering unexpected\nvulnerabilities through randomness. AFLargv [ 3] grants fuzzers\nthe capability to mutate test options by treating specific bytes in\ntest cases as options, but introduces a large number of invalid\noptions. Addressing this issue, Tofu [35] employs structured mu-\ntations to alter the presence of each option, while POWER [ 15]\nbuilds on this with three mutation operators to further enhance\nthe exploration of unexpected option combinations. Unlike these\nmethods, ConfigFuzz [43] also considers the impact of the option\nvalues and improves the exploration of combination-related paths\nby mutating both the options and their values. Unlike mutation-\nbased approaches, filter-based option-aware fuzzing techniques\nprune the search space by filtering out invalid option combina-\ntions. CrFuzz [29] introduces a clustering-based validity checker,\nwhich determines the validity of input options based on the output\nof the program. CarpetFuzz [34], on the other hand, employs an\nNLP-based method to extract constraints between options from the\nprogram documentation and filters out invalid option combinations\nthat do not satisfy these constraints. However, the methods above\ndo not account for the varying likelihood of vulnerabilities in dif-\nferent combinations of options and treat all combinations equally.\nThis oversight could lead to excessive testing of low-risk option\ncombinations, thereby reducing the opportunities for high-risk\ncombinations to be tested. As a solution, this paper introduces an\noption-aware fuzzing technique based on the prediction of high-risk\noption combinations, effectively enhancing fuzzing efficiency.\n2.2 Large Language Model\nIn recent years, large language models (LLMs) such as OpenAI’s\nGPT-4 Turbo have made remarkable advances in NLP. These models\nbenefit from training on massive text datasets, such as 500 billion\ntokens [4], which allows them to accumulate extensive knowledge\nand experience. As a result, they can perform a wide range of com-\nplex downstream tasks without the need for fine-tuning, excelling\nin numerous linguistic tasks [17]. Users can guide LLMs to generate\noutputs aligned with particular intentions by providing prompts\nin natural language. A prompt is a concise query or task posed to\nthe model designed to elicit goal-oriented responses or content,\nwhich is often phrased as a question, statement, or description.\nWhen encountering gaps in knowledge, users can supplement the\nrequired information by incorporating a few examples into the\nprompts, a strategy known as “few-shot learning [4]. ” This strat-\negy has been proven to effectively direct LLMs in solving various\ncomplex problems, such as olympiad geometry [32].\nIn the field of fuzzing, inspired by the outstanding capabilities\nof LLMs in text generation and understanding, researchers have\nstarted investigating novel methods for using LLMs to improve\n3\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nfuzzing. Using knowledge from vast text datasets, LLMs can effi-\nciently produce code and structured inputs applicable across vari-\nous domains, significantly improving fuzzing efficiency and cov-\nerage. Tools such as Codamosa [16], TitanFuzz [5], FuzzGPT [6],\nCovRL [8], Oliinyk et al. [22], and Fuzz4All [37] have demonstrated\nthe potential of LLMs in the generation of programming language\ncode. Moreover, ChatFuzz [12] and KernelGPT [40] have delved\ninto LLM applications to generate format-conforming input and\nsyscalls, respectively. PromptFuzz [19] has revealed the potential\nof LLMs to generate fuzz drivers for testing frameworks such as\nlibfuzzer [27]. While these efforts have showcased the potential of\nLLMs in understanding and generating text inputs, utilizing LLMs\nto generate non-text inputs, like PDF or ELF files, remains unex-\nplored. The challenge primarily stems from the complexity and\nstructure of non-textual inputs, which exceed LLMs’ current gener-\nation capabilities. To address this challenge, we propose a method\nthat leverages LLMs to generate code that produces the required\ninputs. By executing the generated code, we indirectly create the\nrequired inputs, effectively circumventing the limitations of LLMs\nin generating non-text inputs directly.\nBeyond generating text input, LLMs are also employed to extract\nvaluable information from external documents, further optimizing\nthe fuzzing process. For instance, ChatAFL [20] utilizes LLMs to\nanalyze RFC documents to extract network protocol specifications,\nenhancing the exploration efficiency of protocol states and code.\nIn this paper, we study an approach to leverage LLMs to extract\noption descriptions from program documentation to predict high-\nrisk option combinations and integrate synopsis to automatically\nconstruct fuzzing configurations for these high-risk combinations.\nThis approach enables a fully automated fuzzing process, from\ntarget prediction and command assembly to file generation and fuzz\nexecution, effectively simplifying the complexity of fuzz testing.\nDocumentationParsing\n Command AssemblyFile Generation\nHigh-Risk Combination Prediction\nContent CMDs + Code\nFuzzing\nCMDs + files\nConstraintExtraction\nDriven by LLM\nConstraintsHigh-Risk Combinations\n① ② ③ ④ ⑤ ⑥\nFigure 1: Overview of ProphetFuzz.\n3 Design\n3.1 Overview\nAs previously stated, ProphetFuzz relies exclusively on documenta-\ntion for input. Figure 1 illustrates the process in which ProphetFuzz\nfirst parses essential documentation content, such as the program\ndescription, synopsis, and option details (step 1). Considering that\ndocument parsing is a simple task, ProphetFuzz employs keyword\nmatching instead of using direct LLM parsing, as keyword matching\nis both sufficient and cost-effective. It then identifies the constraints\nbetween options and performs a self-check to eliminate erroneous\nfindings (step 2). In the next phase, ProphetFuzz utilizes a few-shot\nlearning approach to predict high-risk option combinations based\non the option descriptions while adhering to identified constraints\nto prevent creating invalid combinations (step 3). Specifically, we\nmanually collect 29 historical high-risk option combinations across\neight programs and employ an AutoCoT-based method to gener-\nate eight analysis examples as the few-shot (i.e., 8-shot) corpus to\nassist ProphetFuzz in learning to predict high-risk combinations.\nImportantly, generating these analysis examples does not require\nexpert participation. ProphetFuzz then constructs the appropriate\ncommands for each identified high-risk combination by selecting\nsuitable option values, guided by the synopsis and option details,\nand generates Python code to produce the required files (such as\nconfiguration and input files) that match these commands seman-\ntically (step 4). Finally, ProphetFuzz executes the Python code to\nproduce the files (step 5) and puts them, along with the assembled\ncommands, into the fuzzer for automated fuzzing (step 6).\nExample. Figure 2 illustrates the process by which ProphetFuzz\nautomatically predicts and executes fuzzing, using the manpage\nof the well-known video processing software ffmpeg as input. Ini-\ntially, ProphetFuzz extracts the required sections from the ffmpeg\nmanpage through keyword matching and stores them as formatted\ntext (JSON) for later use. It then guides the LLM to extract con-\nstraints based on option descriptions. Due to the LLM’s inherent\nhallucination issues, some extracted constraints might be incorrect,\nsuch as a conflict between“-start_at_zero” and “-copyts. ”To address\nthis, ProphetFuzz employs a self-check mechanism to scrutinize\nall extracted constraints and filter out erroneous results. Based\non the document content and constraints, ProphetFuzz predicts\nhigh-risk option combinations that do not violate these constraints,\nsuch as“-copyts -start_at_zero -y -itsoffset offset -itsscale scale -ss\nposition -sseof position -i url. ” Since no specific values are given\nfor the options, these predicted combinations are not executable.\nProphetFuzz subsequently uses the LLM to generate appropriate\ncommands based on the semantic information of the combinations,\nalong with the Python code needed to create the required files.\nFinally, ProphetFuzz generates the seed corpus by executing the file\ngeneration code, modifies the assembled command to be suitable\nfor fuzzing, and executes the fuzzing process.\n3.2 Constraint Extraction\nAs noted previously, option combinations that violate constraints\nbetween options can cause premature program termination, hin-\ndering the fuzzer from exploring paths continuously. To prevent\nthe generation of such combinations, we first utilize LLM to ex-\ntract constraints between options from the program documentation\nbefore predicting high-risk combinations. Specifically, we provide\nthe LLM with the program description and the option descriptions\nfound in the program documentation. We select this information for\na couple of reasons. First, to prevent incorrect user configuration of\noptions, authors may have included explicit cues about constraints\nwithin this information, such as “The -alpha flag cannot be used\nwith -mono. ” Secondly, these descriptions also assist LLM in under-\nstanding the program’s and its options’ functionalities, allowing it\nto infer constraints not explicitly mentioned by the authors based\non potential conflicts and dependencies between functionalities.\nSome option keys, such as “-r, -R, –recurse-limit, –no-recurse-limit,\n–recursion-limit, –no-recursion-limit” may encompass multiple sub-\noptions, which could be different aliases for the same option or\n4\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nNAMEffmpeg-ffmpegvideo converterDESCRIPTIONffmpegis a very fast video and audio converter … SYNOPSISffmpeg[global_options] {[input_file_options] –i... Options-iurl(input)input file url-sseofposition(input)Like the \"-ss\" option but relative to the \"end of …-copytsDo not process input timestamps, but keep …-start_at_zeroWhen used with copyts, shift input timestamps …       -y (global)Overwrite output files without asking.…\n{”name”:“ffmpeg”,“description”:“ffmpegis a ……”,”synopsis”: “ffmpeg[global_options] ……”,“options”:[“-iurl(input)”: “input file url”,“-sseofposition (input)”: ”Like the \\”-ss\\” …”,“-copyts”: “Do not process input timestamps …”,“-start_at_zero”:“Whenusedwithcopyts,shift…”,“-y (global)”: “Overwrite output files without …”,…]}\nGuide LLM to extract potential conflict/dependency\nSelf-check for incorrect constraints and filter them out\nParsing document content into structured data\nPredict high-risk combinations while adhering to identified constraints  Combinations:•-copyts -start_at_zero -y (global) -itsoffsetoffset (input) -itsscalescale (input,per-stream) -ss position (input/output) -sseofposition (input) -iurl(input) •…\nGenerateproper commands and file generation code Conflict:•-copyts⊗-start_at_zero # Erroneous constraint•-n (global) ⊗ -y (global)•…Dependency•-start_at_zero→ -copyts•-sseofposition (input) → -iurl(input)•…\nConflict:•-n (global) ⊗ -y (global)•…Dependency•-start_at_zero→ -copyts•-sseofposition (input) → -iurl(input)•…\nCommand:ffmpeg-copyts-start_at_zero-y -itsoffset0.5 -itsscale0.75 -ss 00:01:00 -sseof-5 -iinput.mp4 output.mp4Code:importsubprocessdef generate_minimal_mp4(file_name):command =f“ffmpeg–y –f lavfi–i-c:vlibx264 –t 1 color=size=320x240:rate=1:duration=1–f mp4 {file_name}”subprocess.run(command, check=True, shell=True)generate_minimal_mp4('file0.mp4’)\nCommand:ffmpeg-copyts-start_at_zero-y -itsoffset0.5 -itsscale0.75 -ss 00:01:00 -sseof-5 -iinput.mp4 output.mp4Code:importsubprocessdef generate_minimal_mp4(file_name):command =f“ffmpeg–y –f lavfi–i-c:vlibx264 –t 1 color=size=320x240:rate=1:duration=1–f mp4 {file_name}”subprocess.run(command, check=True, shell=True)generate_minimal_mp4('file0.mp4’)\nCommand:ffmpeg-copyts-start_at_zero-y -itsoffset0.5 -itsscale0.75 -ss 00:01:00 -sseof-5 -iinput.mp4 output.mp4Code:importsubprocessdef generate_minimal_mp4(file_name):command =f“ffmpeg–y –f lavfi–i-c:vlibx264 –t 1 color=size=320x240:rate=1:duration=1–f mp4 {file_name}”subprocess.run(command, check=True, shell=True)generate_minimal_mp4('file0.mp4’)\nExecute the code to produce the files in the sandbox\nPerform option-aware fuzzing\nFuzzing commands:•ffmpeg-copyts-start_at_zero-y -itsoffset0.5 -itsscale0.75 -ss 00:01:00 -sseof-5 -i@@ output.mp4•…Seed corpus:•seed1•seed2•…\n① Documentation Parsing ② Constraint Extraction\n③ High-Risk Combination Prediction\n④ Command Assembly\n⑤ File Generation\n⑥ Fuzzing\nFigure 2: Example of ProphetFuzz.\nentirely distinct options. This ambiguity could affect the LLM’s\njudgment. Consequently, we initially submit keys with more than\ntwo sub-options to the LLM for assessment, as this usually indicates\nthat they are distinct options. The prompt is: “Please separate the\noptions and create individual descriptions for each option based on the\noriginal description. ” Following this directive, different sub-options\nare separated, and their descriptions are adjusted accordingly. These\nupdated data are then provided to the LLM for the subsequent steps.\nWe then direct the LLM to extract all constraints with the prompt:\n“Please find any options that are mutually exclusive or logically con-\nflicting when selected together and find any options that have depen-\ndencies on other options. ” We further constrain the LLM’s output\nto a specific format by instructing “Ensure that the output strictly\nconforms to JSON format standards, like ... ” to facilitate the automa-\ntion of subsequent processes. To minimize the risk that the LLM\noverlooks any constraints, we increase the randomness of the out-\nputs by adjusting the temperature setting of the LLM, which is\na sampling parameter ranging from 0 to 1, where higher values\nindicate a stronger randomness of the output [24]. Note that the\ntemperature is an internal hyperparameter of the model, which\nallows us to make adjustments without modifying the model itself.\nAdditionally, we instruct the LLM to make multiple inferences for\neach program and retain the union of the results of each inference\nto ensure that the extracted constraints are as complete as possible.\nHowever, the inherent hallucinations of LLMs can lead to false\npositives during constraint extraction, potentially causing high-risk\ncombinations to be mistakenly excluded. Thus, it is crucial to thor-\noughly validate these constraints, even though the validation pro-\ncess is also susceptible to hallucination problems. In response, we\nintroduce a self-check approach based on bidirectional reasoning.\nTable 1: Bidirectional questions for conflict and dependency.\nHere, “-A” and “-B” represent the subjects of the constraint,\nindicating either “-A conflicts with -B” or “-A depends on -B.”\nConstraint Type Question\nConflict Verification Must -A be used without -B?\nConflict Counterexample Can -A be used with -B?\nDependency Verification Must -A be used with -B?\nDependency Counterexample Can -A be used without -B?\nSpecifically, for each type of constraint, we formulate a verification\nquestion based on its specific definition to confirm its validity and\na counterexample question to challenge it, as illustrated in Table 1.\nThese questions are designed to assess the validity of a constraint\nfrom two distinct angles, enabling the LLM to consider the problem\ncomprehensively. The process of this self-check method is shown in\nFigure 3. After extracting all constraints, ProphetFuzz automatically\ngenerates the corresponding bidirectional questions for each con-\nstraint based on its type. Subsequently, these questions, along with\ndescriptions of the options involved, are sent to the LLM for analysis\nand evaluation, and responses are obtained for each. A constraint\nis deemed valid if the verification question receives a “yes” while\nthe counterexample question receives a “no. ” To further mitigate\nthe impact of random hallucinations, we adjust the temperature to\ndecrease its randomness and subject each constraint to multiple\nseparate evaluations by the LLM. Each evaluation occurs in a new\nsession to prevent biases from prior communications, enhancing\nthe reliability of the outcomes. A constraint is only considered valid\nif more than half of the evaluations affirm its correctness.\n5\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\n-A is conflict with -B 1.Must -A be used without –B?2.Can –A be used with –B? LLM1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No1. Yes 2. No\nTrue Positive\nFalse PositiveExtracted ConstraintBidirectional QuestionsMultiple Evaluations\n“1. Yes 2. No” > 50%\nelse\nCheck Result\nFigure 3: Workflow of the Self-Check approach.\nThe evaluation results in Section 5.3 reveal that, with the support\nof the self-check method, ProphetFuzz extracts 633 constraints from\nthe documentation of 52 programs with an overall precision of\n94.00%, and an average precision of 92.48% per program.\n3.3 High-Risk Combination Prediction\nPredicting high-risk combinations is a complex task involving multi-\nple steps, including understanding descriptions, traversing combina-\ntions, and assessing risk, which poses a challenge to the capabilities\nof LLMs. A practical solution to this is the use of chain-of-thought\n(CoT) prompts. A CoT consists of a series of consecutive reasoning\nsteps, which has been proven to significantly improve the ability\nof LLMs to tackle complex problems [36]. As demonstrated in the\nprompt for prediction shown in Figure 4, we break down the pre-\ndiction process into six steps using the CoT method to assist the\nLLM in progressively completing the task. Initially, based on the\nprogram name and description, we guide the LLM in understanding\nthe program’s core functionality, providing a macroscopic under-\nstanding of it (step 1). Next, the LLM analyzes each option and its\neffects to develop an understanding of the options (step 2). Subse-\nquently, we remind the LLM of the previously extracted constraints\nto avoid generating invalid combinations that do not comply with\nthese constraints in later predictions (step 3). This step does not\ninvolve a specific task for the model; rather, it serves as a reminder\nto ensure that the model does not forget the constraints identified\nin earlier steps. Upon completing the preparatory steps above, the\nLLM examines all combinations and identifies those that may pose\nvulnerabilities (step 4). During this process, we encourage the LLM\nto make bold guesses, using the term “Hypothetically. ” We define\nhigh-risk option combinations as “when used together, they could\nlead to vulnerabilities in deep memory corruption while functioning\ncorrectly. ”This definition emphasizes that the goal of prediction\nis not to identify errors that cause apparent malfunctions, but to\nuncover hidden risks that could lead to deep memory corruption.\nWe pay special attention to memory corruption vulnerabilities, as\nfuzzers primarily target such issues. Experience shows that some\noptions, while not directly causing vulnerabilities, can reduce the\ndifficulty of triggering them. Therefore, once the LLM predicts\na combination that includes a memory vulnerability, we further\nguide the LLM to attempt to add other options that could facilitate\ntriggering the vulnerability (step 5). Finally, we specify that the\nLLM outputs the results in JSON format, easing the automation of\nsubsequent processes (step 6). Following these six steps, we prompt\nthe LLM with the instruction, “Let’s take a deep breath and think\nstep by step, ” to encourage careful reasoning. This technique has\nbeen shown to significantly enhance LLM performance [39]. Ad-\nditionally, we request that the LLM displays its thought process, a\npractice that ensures that the output of each step provides contex-\ntual information for subsequent steps, thereby fostering coherent\nreasoning by the LLM and increasing the validity of its judgments.\nTo help the LLM analyze high-risk combinations from the docu-\nmentation more effectively, we present examples of analysis pro-\ncesses. Ideally, these examples are created manually by human ex-\nperts (manual-CoT), as expert analyses are most effective in guiding\nLLMs. However, due to the scarcity of high-level expert resources,\nwe devise an automated method for generating few-shot examples\n(Auto-CoT) as an alternative. Unlike directly predicting high-risk\ncombinations from documentation, the essence of Auto-CoT lies in\ndirecting the LLM to identify potential high-risk factors from the\ndocumentation based on historical data. To gather this historical\ndata, we review vulnerability reports in GitHub Issues for all pop-\nular C/C++ projects with over 100 stars, collecting every related\nunique combination involving two or more options. From this ex-\ntensive review, we identify 29 high-risk combinations known to\nhave historical vulnerabilities across eight distinct programs, which\nrepresent all the historical high-risk combinations that met our cri-\nteria. Subsequently, we present the LLM with the documentation\nof these programs and extracted constraints, enabling it to under-\nstand program functions and option roles and remember relevant\nconstraints, similar to the initial three steps of the prediction task.\nTo create analysis examples that can serve as few-shot corpus, we\nmodified steps 4-5 in the prediction prompt to ensure the outputs\nmeet our requirements, as illustrated in the boxed area of Figure 4.\nSpecifically, starting with historical high-risk combinations, we\nguide the LLM to hypothetically analyze why these combinations\nare susceptible to buffer vulnerabilities and summarize which com-\nbinations might lead to deep memory corruption vulnerabilities\nwhile appearing to function normally. Additionally, we instruct the\nLLM to explore options that could indirectly facilitate the trigger-\ning of vulnerabilities. The outputs from these two steps precisely\nfulfill the requirements for examples in steps 4-5 of the prediction\ntask. Ultimately, the LLM outputs the final result in JSON format,\nfacilitating our ability to extract and incorporate it into the pre-\ndiction prompts automatically. Notably, while collecting historical\nhigh-risk combinations requires manual effort, it is a one-time job\nthat does not need to be repeated. This approach reduces reliance\non human experts and leverages the LLM’s robust capabilities to\nautomatically generate helpful analysis examples, enriching the\ncontext for predicting high-risk combinations.\nUltimately, ProphetFuzz predicts 1748 high-risk combinations\nacross 52 programs and successfully identifies vulnerabilities in\n12.30% of these combinations, including 364 unique vulnerabilities.\n3.4 Command Assembly\nAfter obtaining the predicted high-risk option combinations, the\nnext step is to assemble these combinations into executable com-\nmands for fuzzing. This involves assigning specific values to op-\ntions and placeholders, setting up necessary configuration files, and\nspecifying input and output files. Typically, this requires manual\neffort using detailed documentation. To streamline this process, we\ndevelop an LLM-based method for automated command assembly.\n6\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nHere is the document of [Program name],```{“name”: [Program name], “description”: [Program description], “options”:[Option descriptions], “requirement”: [Constraints]}```Buffer vulnerabilities have occurred in the following option combinations,[Put combinations here]Instructions: 1. Understand the core functionality of the program from the \"name\" and \"description\" fields.2. Analyze all the listed options in the \"options\" field and their respective roles. 3. Remember the constraints in \"requirements\" field and use them to guide subsequent steps.4. Hypothetically analyze why these option combinations are susceptible to buffer vulnerabilities and summarize what kind of combinations of any options that, when used together, could lead to deep memory corruption vulnerabilities while functioning correctly.5. Examine whether any options in the combination, while not directly causing the vulnerability, might facilitate its trigger.6. Provide the final resultsin JSON format.Let's take a deep breath and think step by step. Please show your thoughts in each step.\nPrompt for Example GenerationHere is the document of [Program name],```{“name”:[Program name], “description”: [Program description], “options”:[Option descriptions], “requirement”: [Constraints]}```Instructions: 1. Understand the core functionality of the program from the \"name\" and \"description\" fields. 2. Analyze individual options and their respective roles from the \"options\" field. 3.Remember the constraints in “requirements” field and use them to guide subsequent steps.4. Hypothetically analyze all combinations of any options that, when used together, could lead to deep memory corruption vulnerabilities while functioning correctly. 5. Add more options in the combination to make it easier to trigger the vulnerability. 6. Provide the final resultsin JSON format.Let's take a deep breath and think step by step. Please show your thoughts in each step.Examples:[Put Examples here]\nPrompt for Prediction\nFigure 4: Prompts for prediction and example generation. The boxed area indicates the distinct steps within the two prompts.\nThe content enclosed in brackets denotes the need for specific input.\nBesides providing the program name, description, and option\ndetails, we also supply the LLM with the “synopsis, ” which out-\nlines specific program usage. Initially, we identify the options to be\ncombined and guide the LLM to generate preliminary executable\ncommands based on this synopsis. We particularly emphasize the\nneed for these commands to adhere to exclusivity, preventing the\nLLM from concatenating multiple commands with operators like\n“&&”, which is unsuitable for fuzzers. The LLM is then tasked with\ndetermining which options require values, and cross-verifying this\nwith the synopsis. Next, the LLM needs to understand each com-\nmand’s specific intent and generate valid values for all options\nthat need to be assigned. For other placeholders, we encourage the\nLLM to creatively assign hypothetical values. To clarify the use\nof files in commands, we guide the LLM to represent the primary\ninput file as “file0” and use sequential placeholders like “fileN” for\nadditional necessary files. Since fuzzers typically process only one\nprimary input file at a time, we ensure that “file0” is used exclusively\nin each command, with other required files labeled sequentially\nfrom “file1” onwards as needed. Finally, we ask the LLM to review\neach file placeholder to prevent false placeholders from disrupting\nsubsequent processing steps.\nAfter assembling the commands and identifying file placeholders,\nwe further guide the LLM in generating Python code that “conjures”\nfiles corresponding to each placeholder out of thin air. Initially, we\ndirect the LLM to identify the expected format of each file place-\nholder, a critical step for selecting the file generation strategy. To\navoid incorrect formats, we encourage the LLM to leverage third-\nparty libraries to generate files with complex formats. The LLM\nthen needs to consider the values of other options to determine\nconstraints on the file content, ensuring that the generated files are\nsemantically consistent with the command. Additionally, we spec-\nify that the size of “file0” should ideally remain under 1KB, while\nguaranteeing that the command explores as many program behav-\niors as possible, aligning with fuzzer-recommended practices [11].\nWe have noticed that the LLM occasionally leaves placeholders in\nthe code, expecting users to replace them, such as “your avi file, ”\nwhich can hinder our automated generation process. To address\nthis, we instruct the LLM to replace all placeholders in the code\nwith content it deems appropriate. Finally, we direct the LLM to\nspecify in the generated code that files be saved in the working\ndirectory using the given name to facilitate their integration into\nsubsequent automated processes.\nIn Section 5.6, we randomly select 25 programs for ablation\nstudies to evaluate the effectiveness of the values and files generated\nby the command assembly module. The results indicate that with\nthe adoption of these values and files, ProphetFuzz can identify\n34.65% and 17.24% more vulnerabilities, respectively.\n3.5 File Generation and Fuzzing\nBefore fuzzing, we execute all generated Python code in a sandbox\nto create the required files for each command. Next, we compare the\ngenerated files with the file placeholders provided by the LLM. If\nfewer files are generated than placeholders, it suggests that crucial\nfiles are missing, making the command unexecutable, and such com-\nmands are excluded. However, if the file count matches or exceeds\nthe placeholders but not all placeholders are represented in the gen-\nerated file list, it indicates that some files have unexpected names.\nIn these cases, we employ a heuristic rule for name correction: if a\ngenerated file’s name starts with the same prefix as a placeholder,\nwe consider that file to match the placeholder. Commands that\ncannot be corrected by this rule are also excluded.\nFor commands that pass this filtering, we further look for place-\nholders corresponding to input files and replace them with“@@” to\nmeet fuzzer specifications. Typically, the placeholder for the input\nfile is “file0, ”as set in our prompts. For commands deviating from\nthis norm, we search for file placeholders containing key terms like\n“input, ” “test, ” or “source, ” which are commonly used by LLMs to\ndenote input files. Placeholders with these specific keywords are\nconsidered indicative of input files. If a command lacks these key-\nwords but has only one file placeholder, we consider this the input\nfile. Commands failing to meet any of these criteria are excluded\nfrom further processing.\n7\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nAfter filtering the commands and files, we input them into the\nfuzzer to initiate fuzz testing. First, we merge all the input files for\neach program to create an initial corpus. Then, we utilize the corpus\nminimization tool, a tool designed to refine the initial corpus by\neliminating redundant test cases, to produce the minimized corpus\ntailored to each command and obtain the final minimized corpus\nfor each program by combining them. Finally, we load these corpus\nand commands into the option-aware fuzzer to begin fuzz testing.\n4 Implementation\nWe implement a prototype of ProphetFuzz with about 3k lines\nof Python code, including modules for document parsing, LLM\ninteraction, code interpretation, and fuzzing.\nDocument Parsing : We use Groff documents, a standard docu-\nmentation format for command-line programs, as our input. We\nlocate program names using the “.TH” control sequence and cate-\ngorize sections like program descriptions, option descriptions, and\nsynopses with the“.SH” control sequence, identifying them by titles\nsuch as “DESCRIPTION”, “OPTIONS”, and “SYNOPSIS”. Option de-\nscriptions are extracted using sequences like “.TP”, “.PP”, “.RS”, and\n“.sp”. We convert Groff-formatted text into plain, readable natural\nlanguage using the “col -b” command.\nLLM Interaction: We select GPT-4 Turbo (gpt-4-1106-preview) as\nthe LLM backbone for ProphetFuzz, one of the most powerful LLMs\ncurrently recognized. Notably, ProphetFuzz’s design can adapt to fu-\nture LLM improvements, enhancing its performance over time. For\nautomation, we interact with the LLM via the OpenAI API [24]. We\nadjust the LLM’s temperature settings to tailor its output [24]: 0.7\nfor tasks needing diverse outcomes, like constraint extraction and\ncommand assembly, and 0.2 for precision tasks like self-checking.\nFor constraint extraction and high-risk option combination predic-\ntion, we set the LLM’s parameter𝑛 to 10, allowing the LLM to make\nten inferences each time. When generating few-shot examples, we\nset 𝑛 = 1, as we only need a set of examples. During command\nassembly, to ensure diverse outputs and prevent redundancy, we\nset 𝑛 to 3 times the number of options needing assignment ( 𝑁 ),\nthus 𝑛 = 3 ×𝑁 .\nFile Generation and Fuzzing : Within a Docker container, we set\nup a Python sandbox using virtualenv and pre-install 33 commonly\nused Python third-party libraries along with 36 command-line tools\n(for subprocess calls) to support the execution requirements of LLM-\ngenerated code. These pre-installed libraries and tools have been\nverified to support the code execution for the 52 programs men-\ntioned in Section 5.1. Note that setting up this environment is a\none-time job. If there is a need for additional libraries and tools not\nyet installed, incorporating them is straightforward and easy with\nthe commands apt and pip to satisfy evolving requirements. For\nfuzzing, we use afl-cmin to minimize the corpus and CarpetFuzz-\nfuzzer as the option-aware fuzzer, which modifies how the target\nprogram reads options from command-line to file, facilitating dy-\nnamic command adjustments through file changes\n5 Evaluation\n5.1 Experiment Setting\nPlatform. Our experiments are conducted on servers powered by\nIntel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz with 32 cores and\n128GB of RAM. No GPU is needed since we do not use local LLM\nmodels. These servers run Ubuntu 20.04.\nDataset. To comprehensively evaluate ProphetFuzz’s performance\nacross different types of programs, we integrate datasets from re-\nlated studies [15, 34, 43] to form an evaluation dataset, which in-\ncludes 52 popular open-source programs from 40 packages. The\nprogram versions in our dataset align with those specified in the\ncited studies. The selected programs encompass 26 different input\nformats, covering text (such as BNF, C code , Markdown, Mangled\nName, PostScript, JSON, ASM, PEM, SAV, TXT, XML, Rule), video\n(AVI, WAV), audio (MPG, OGG, SPX), images (JPG, EXI, GIF, PNG,\nTIFF), and other other binary inputs (PCAP, ELF, LRZ, PDF).\nExperiment Setup. We select CarpetFuzz as our comparison bench-\nmark, because it is recognized as the state-of-the-art (SOTA) tool\nin the field. We initialize its seed corpus using default seed input\nfiles sourced from the datasets mentioned above. To ensure fair\ncomparison, both CarpetFuzz and ProphetFuzz are run for equal du-\nrations in the same operating environment. Each fuzzing instance\nis run for 72 hours and repeated five times to mitigate the impact\nof the inherent randomness associated with fuzzing on the results.\nOverall, the experiments consume 10.44 CPU years.\nMetrics. To evaluate the performance of ProphetFuzz, we employ\nedge coverage and the number of unique vulnerabilities as metrics.\nEdge coverage is calculated using the afl-showmap tool. The identi-\nfication of unique vulnerabilities is based on the first three entries\nin call stack reports generated by ASAN and GDB, as suggested\nin [14]. A unique vulnerability is defined by a distinct combination\nof the first three entries in its call stack. If two vulnerabilities share\nthe same first three entries, they are considered the same unique\nvulnerability. Additionally, to highlight the differences in vulnera-\nbilities discovered by ProphetFuzz and CarpetFuzz, we introduce\na specific metric for unique vulnerabilities—exclusive vulnerabil-\nities, referring to those found by only one tool within the same\ntimeframe. To represent the upper limit of each tool’s capability,\nwe take the union of the results from the five repetitions.\nResearch Questions. The following sub-sections explore Prophet-\nFuzz’s performance, focusing on these key research questions:\nRQ1: What is ProphetFuzz’s end-to-end performance?\nRQ2: How accurate is the constraint extraction module?\nRQ3: How do the self-check and few-shot methods contribute to\nthe performance of high-risk option combination predictions?\nRQ4: How does an out-of-the-box LLM perform in predicting high-\nrisk option combinations?\nRQ5: How does the command assembly module contribute to the\noverall performance?\nRQ6: What is ProphetFuzz’s effectiveness in finding zero-day vul-\nnerabilities?\nRQ7: What knowledge does ProphetFuzz use to predict high-risk\noption combinations?\n5.2 End-to-end Performance (RQ1)\nIn analyzing the documentation of these 52 programs, ProphetFuzz\nsuccessfully extracts 643 constraints between options. Based on\nthese constraints, ProphetFuzz further predicts 1748 high-risk op-\ntion combinations, assembles 7614 unique executable commands,\nand generates a minimized seed corpus comprising 2656 seed files.\n8\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nWe subject these commands and seed files to 72 hours of fuzz testing,\nwith detailed results presented in Table 2.\nWithin these 52 programs, ProphetFuzz identifies 364 unique\nvulnerabilities, which is 1.33 times more than that of CarpetFuzz\n(274 vulnerabilities discovered) under the same conditions. Benefit-\ning from ProphetFuzz’s precise capabilities in predicting high-risk\noption combinations and assembling commands (see Sections 5.4\nand 5.6), it identifies 224 vulnerabilities that CarpetFuzz fails to de-\ntect, representing 61.54% of all vulnerabilities found, which demon-\nstrates ProphetFuzz’s efficiency in vulnerability detection. Note\nthat CarpetFuzz also identifies 134 vulnerabilities that ProphetFuzz\nmisses, especially in avconv, c++filt, tiffcrop, and xmllint, which\naccounts for 60%. We analyze cases from these four programs and\nidentify the following reasons for ProphetFuzz’s omissions.\nThirty-seven missed vulnerabilities (7 in avconv, 2 in c++filt, 27\nin tiffcrop, and 1 in xmllint) arise because ProphetFuzz focuses on\npredicting high-risk combinations rather than exhaustively explor-\ning all possibilities like CarpetFuzz. When queried, the backend\nLLM identifies 92.86% of these combinations as high-risk, indicating\nProphetFuzz’s potential to predict most of these overlooked combi-\nnations. Due to cost and performance considerations, ProphetFuzz\nconsolidates predictions from only ten inferences, which may limit\nthe coverage of potential combinations. Expanding the number of\ninferences could help reduce these misses. Thirty-eight vulnera-\nbilities occur because ProphetFuzz, while successfully predicting\nhigh-risk combinations, fails to specify the necessary values to trig-\nger these vulnerabilities. Specifically, 15 vulnerabilities in xmllint\nare only triggered when “–maxmem” falls within a certain range\n(see Section 5.6), and 23 in c++filt only occur when “-s” specifies\na DLang compiler instead of a C++ compiler. While CarpetFuzz\nmay inadvertently meet these conditions through random selection,\nProphetFuzz, aiming for validity, typically opts for more commonly\nused values, such as selecting a C++ compiler for c++filt, thus miss-\ning these vulnerabilities. Incorporating less common values could\nhelp address this issue in the future. Lastly, four vulnerabilities\nare missed due to randomness (2 in avconv, 2 in c++filt). Prophet-\nFuzz successfully predicts and assembles certain commands, yet\ntemporarily fails to detect them.\nAdditionally, we analyze the option combinations related to\nthese vulnerabilities. Of the 1748 high-risk option combinations\npredicted by ProphetFuzz, 12.30% trigger vulnerabilities within\n72 hours, surpassing CarpetFuzz’s 1.50% (8.2×). Specifically, in six\nprograms (gif2png, pdftopng, pdftops, pdftotext, podofoencrypt, and\npspp), more than half of the predicted high-risk combinations suc-\ncessfully trigger vulnerabilities, with the ratio reaching as high as\n90.91% in pspp. This demonstrates ProphetFuzz’s efficiency in test-\ning option combination-related vulnerabilities and highlights the\neffectiveness and necessity of predicting high-risk combinations.\nTo further compare the performance of ProphetFuzz with Carpet-\nFuzz, we also measure the coverage achieved by both tools across\n52 programs. Despite not primarily aiming to maximize path cover-\nage, ProphetFuzz’s coverage is remarkably close to CarpetFuzz’s,\nwith a marginal difference of less than 0.5%. Although Prophet-\nFuzz uses only 0.2 times as many commands as CarpetFuzz, the\ncoverage difference is within 30% for most programs (43 out of 52).\nFor these programs, 24 exhibit a coverage discrepancy of less than\n10%. Notably, on vim, CarpetFuzz discovers 4.62 times more paths\nthan ProphetFuzz. Analysis reveals that in the POWER dataset, the\ninitial command for vim is “-u NONE -X -Z -e -s -S @@ -C ‘:qa!”’ ,\nindicating that the fuzzer is mutating the value of the -S option\n(a vim script) rather than the input file. CarpetFuzz includes these\noptions in every command generated. In contrast, the LLM behind\nProphetFuzz does not know this. It continues to treat the input file\nas the mutation target. In the vim commands, the majority involve\nonly reading operations on the input file. Regardless of how the\ninput file is mutated, the range of executable operations remains\nlimited, thus covering fewer paths compared to mutations applied\nto the vim script (-S). In future research, to address this issue, we\nplan to allow the LLM to autonomously choose the most suitable\nfile for mutation rather than strictly mutating the input file.\nFurthermore, ProphetFuzz outperforms CarpetFuzz (>2×) in cov-\nerage on three programs ( pdftotext, pdftops, and podofoencrypt),\nwith the coverage on podofoencrypt being ten times that of Car-\npetFuzz. We attribute this to the fact that these programs perform\nstrict checks on input formats, while CarpetFuzz uses inherently\ncorrupted default PDF seeds in the dataset, which are from the\nAFL project [7] and are widely used in many studies [ 25, 34, 42].\nThese corrupted seeds cause programs to exit early, leading to low\ncoverage. PDF is a highly structured format, and simply mutating it\nis often insufficient to repair format damage. In contrast, Prophet-\nFuzz instructs the LLM to generate seeds that meet complex format\nrequirements by calling third-party libraries (e.g. pyFPDF [28]),\nachieving higher coverage on these programs. While manually col-\nlecting more suitable seeds could mitigate this issue, the diversity\nof input formats would necessitate considerable manual effort. Ad-\nditionally, even within the same input format, there can be varying\ndetailed requirements (e.g., styles in PDF), adding complexity to\nthe manual collection of seeds. Instead, ProphetFuzz enhances its\nability to meet large-scale testing needs by guiding LLMs to auto-\nmate the generation of high-quality, specification-compliant seeds.\nTo ensure adherence to specific requirements, ProphetFuzz directs\nLLMs to utilize Python libraries and external tools for file creation.\nFor instance, LLM uses the function “pdf.set_font(‘Arial’,size=12)”\nto meet font specifications, thus enabling precise and accurate file\ngeneration while eliminating the need for manual script tuning.\n5.3 Precision of Constraint Extraction (RQ2)\nTo compare the performance of ProphetFuzz and CarpetFuzz in con-\nstraint extraction, we manually annotate all extracted constraints.\nWithin the documentation of these 52 programs, ProphetFuzz suc-\ncessfully extracts 633 constraints with an overall precision of 94.00%\nand an average precision of 92.48% per program. In contrast, Carpet-\nFuzz extracts only 447 constraints, achieving an overall precision\nof 76.06% and an average precision of 68.32%, all lower than those\nof ProphetFuzz. To compare the precision of constraint extraction\nbetween these two tools across different programs, we plot their\nboxplots as shown in Figure 5. The data range for ProphetFuzz’s\nboxplot is concentrated between 77.78% and 100%, with a median\nof 100%, indicating that ProphetFuzz maintains high precision in\nextracting constraints across most programs. On the other hand,\nthe boxplot for CarpetFuzz displays a data spread from 0% to 100%,\nwith a median of 75%, reflecting high variability in performance\nand less consistency. This difference is due to CarpetFuzz relying\n9\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nTable 2: Results of ProphetFuzz and CarpetFuzz within 72 hours. The table shows the number of commands (#Cmds), unique\nvulnerabilities (#Uniq Vuls), exclusive vulnerabilities (#Excl Vuls), the vulnerable combination ratio (Vul Com Ratio), and edge\ncoverage (#Edge Cov.) for each program. Where 𝑑𝑎𝑡𝑎 𝑃, 𝑑𝑎𝑡𝑎𝐶, and 𝑟 represent the data of ProphetFuzz, the data of CarpetFuzz,\nand the ratio between them, respectively.\nProgram #Cmds #Uniq Vuls #Excl Vuls Vul Com Ratio #Edge Cov.\n𝑑𝑎𝑡𝑎𝑃 𝑑𝑎𝑡𝑎𝐶 𝑑𝑎𝑡𝑎𝑃 𝑑𝑎𝑡𝑎𝐶 𝑑𝑎𝑡𝑎𝑃 𝑑𝑎𝑡𝑎𝐶 𝑑𝑎𝑡𝑎𝑃 𝑑𝑎𝑡𝑎𝐶 𝑑𝑎𝑡𝑎𝑃 𝑑𝑎𝑡𝑎𝐶 𝑟\navocnv 497 3414 4 12 2 10 5.45% 2.81% 48951 35006 139.84%\nbison 221 484 13 8 5 0 8.82% 0.21% 6229 6305 98.79%\nc++filt 25 78 96 63 60 27 4.00% 5.13% 3268 3372 96.92%\ncflow 162 632 17 17 6 6 14.29% 0.32% 1453 1700 85.47%\ncjpeg 53 555 0 0 0 0 0.00% 0.00% 775 782 99.10%\ncmark 52 150 0 0 0 0 0.00% 0.00% 7000 7737 90.47%\ndjpeg 401 1470 0 0 0 0 0.00% 0.00% 438 452 96.90%\ndwarfdump 108 4704 2 4 1 3 6.06% 0.23% 7767 8042 96.58%\neditcap 276 704 0 0 0 0 0.00% 0.00% 4586 4408 104.04%\neu-elfclassify 42 1110 0 0 0 0 0.00% 0.00% 213 200 106.50%\nexiv2 224 539 2 2 1 1 4.44% 0.56% 8496 6657 127.63%\nffmpeg 336 690 4 1 3 0 7.69% 0.58% 71198 62877 113.23%\ngif2png 36 263 10 10 1 1 75.00% 11.41% 441 434 101.61%\ngm 292 1096 0 0 0 0 0.00% 0.00% 10172 10588 96.07%\ngs 104 78 0 0 0 0 0.00% 0.00% 22747 22555 100.85%\nimg2sixel 210 611 5 7 3 5 25.00% 1.80% 2207 2881 76.61%\njasper 117 82 0 0 0 0 0.00% 0.00% 3416 2355 145.05%\njpegoptim 55 988 4 6 0 2 28.00% 1.82% 244 287 85.02%\njpegtran 143 414 0 0 0 0 0.00% 0.00% 5773 5831 99.01%\njq 90 558 1 3 0 2 20.00% 0.36% 2616 2257 115.91%\nlrzip 93 645 0 0 0 0 0.00% 0.00% 4069 4597 88.51%\nmpg123 78 763 0 4 0 4 0.00% 3.54% 3043 3157 96.39%\nmutool 211 769 1 1 1 1 2.44% 0.13% 13118 16238 80.79%\nnasm 238 537 17 11 10 4 21.95% 3.35% 7399 7623 97.06%\nnm 63 555 13 5 10 2 3.13% 0.36% 5860 4986 117.53%\nobjdump 209 1742 9 3 9 3 11.32% 0.11% 11392 10793 105.55%\nogg123 165 257 0 1 0 1 0.00% 0.39% 385 377 102.12%\nopenssl-asn1parse 142 249 0 1 0 1 0.00% 1.20% 4415 2610 169.16%\nopenssl-ec 363 386 0 0 0 0 0.00% 0.00% 9474 7979 118.74%\nopenssl-rsa 194 2043 0 0 0 0 0.00% 0.00% 8034 7105 113.08%\npdftohtml 73 456 3 3 0 0 33.33% 0.22% 5635 7764 72.58%\npdftopng 181 326 12 3 10 1 60.71% 1.84% 4531 5043 89.85%\npdftops 122 1495 11 6 7 2 77.14% 0.94% 3978 1784 222.98%\npdftotext 172 787 10 5 5 0 70.59% 1.91% 4485 1500 299.00%\npngfix 63 116 0 0 0 0 0.00% 0.00% 1058 1015 104.24%\npodofoencrypt 33 203 1 0 1 0 72.73% 0.00% 2796 251 1113.94%\npspp 166 258 46 19 29 2 90.91% 8.14% 15958 11005 145.01%\nreadelf 106 1130 10 3 10 3 13.33% 6.55% 12305 11741 104.80%\nsize 94 146 0 0 0 0 0.00% 0.00% 3708 2894 128.13%\nspeexdec 76 271 0 0 0 0 0.00% 0.00% 784 596 131.54%\ntcpprep 110 710 2 4 0 2 16.67% 4.23% 707 902 78.38%\ntcpreplay 65 1328 1 2 0 1 31.82% 2.64% 733 765 95.82%\ntiff2pdf 120 584 0 0 0 0 0.00% 0.00% 6250 6268 99.71%\ntiff2ps 78 832 0 0 0 0 0.00% 0.00% 3932 4073 96.54%\ntiffcp 45 385 3 3 2 2 14.71% 0.52% 5710 6474 88.20%\ntiffcrop 334 680 65 45 47 27 26.67% 7.65% 6283 6810 92.26%\ntiffinfo 17 116 0 0 0 0 0.00% 0.00% 3789 3822 99.14%\nvim 243 1031 0 2 0 2 0.00% 0.19% 10630 49166 21.62%\nxmlcatalog 66 116 0 0 0 0 0.00% 0.00% 6129 5864 104.52%\nxmllint 109 664 2 17 1 16 2.22% 14.31% 12609 10946 115.19%\nxmlwf 67 329 0 0 0 0 0.00% 0.00% 3473 3104 111.89%\nyara 74 455 0 3 0 3 0.00% 0.22% 2588 3021 85.67%\nCount 7614 38984 364 274 224 134 12.30% 1.50% 393250 394999 99.56%\non heuristic rules for extracting constraints, whereas ProphetFuzz\nutilizes carefully designed prompts to guide the LLM in extracting\nconstraints, resulting in better precision and applicability. Note that,\nthe boxplot for ProphetFuzz shows three outliers, which correspond\nto precision on six programs: dwarfdump and tiffcp at 50%, nasm\nat 63.64%, and editcap, ogg123, and xmlcatalog at 66.67%. These\noutliers indicate unusually low constraint extraction precisions for\nProphetFuzz on these six programs. Upon analysis, we attribute the\nissue to misunderstandings by the LLM. Despite our development\nof a set of self-check questions based on bidirectional reasoning\nto aid the LLM’s comprehension of our constraint definitions, the\nLLM’s inherent randomness lead to incomplete understanding in\nsome instances, resulting in false positives. In five programs except\nnasm, the number of constraints extracted is limited (six or fewer).\nHence, each false positive significantly impacts precision. Despite\nextracting a relatively higher number of constraints (11 in total)\nfrom nasm, the LLM’s misunderstanding of a complex, multi-option\nconstraint leads to a disproportionate increase in false positives\nwhen these constraints are split into pairs for individual assessment,\nsubsequently resulting in reduced precision.\n10\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nFigure 5: Boxplot comparing the precision of constraint ex-\ntraction across 52 programs by ProphetFuzz, CarpetFuzz, and\nProphetFuzz𝑁𝑆𝐶 (without self-check).\nAs mentioned above, ProphetFuzz employs a bidirectional reason-\ning-based self-check method to inspect and filter out incorrect\nconstraint extraction results. To assess the effectiveness of this\nmethod, we analyze the constraint extraction outcomes before ap-\nplying the self-check (ProphetFuzz𝑁𝑆𝐶). Notably, ProphetFuzz𝑁𝑆𝐶\nextracts 6682 constraints, which is 10.56 times the total number\nof constraints after implementing self-check. However, these con-\nstraints have an overall precision of only 23.41% and an average\nprecision of 33.37%, indicating that despite the LLM’s strong text\ncomprehension and reasoning, it cannot ensure correct constraint\nextraction results without our self-check method. We also plot a\nboxplot for the precision of ProphetFuzz𝑁𝑆𝐶 across different pro-\ngrams, as shown in Figure 5. The data range for ProphetFuzz𝑁𝑆𝐶’s\nboxplot is concentrated between 2.17% and 80%, with a median of\n23.90%, indicating generally low and unstable precision across most\nprograms. Additionally, three outliers in the boxplot correspond\nto four programs with unusually high precisions: eu-elfclassify at\n88.24%, size at 90.91%, c++filt, and tcpprep at 100%, which suggest\nthat ProphetFuzz𝑁𝑆𝐶 performs extraordinarily well on these spe-\ncific programs. Further analysis reveals that the high precision in\nthese programs is largely due to the precise documentation of con-\nstraints. For instance, in eu-elfclassify’s document, options related\nto constraints are described using a consistent sentence structure.\nDocumentation for c++filt and size groups options with constraints\ntogether for clarity, while tcpprep explicitly specifies the corre-\nsponding constraints within the description of each option. Such\nstructured documentation significantly facilitates the LLM’s high\nprecision in extracting constraints, thus enabling these programs to\ndemonstrate higher precision even without the self-check process.\nWe observe a reduction of 969 true positive (TP) constraints\nfollowing self-check. Most of these constraints are associated with\nhelp and version options such as “–help” and “–version”. Before\nthe self-check, we increase the temperature setting to encourage\nthe LLM to make bolder guesses. This leads to identifying combi-\nnations of these options with others as potential conflicts. Since\nthese options override the functionality of others, we mark them as\nTPs during manual annotation. However, during the self-check, the\nLLM’s settings are adjusted to favor more cautious outcomes. As a\nresult, it thinks that while these options might override other op-\ntions’ functionalities, this does not necessarily constitute an actual\nconflict. For example, during the self-check of the conflict constraint\nbetween –debug-level and –help in jasper, the LLM states: “–debug-\nlevel can be used with –help, but standard behavior would suggest that\nthe help message will be displayed, and the program will exit without\nconsidering the –debug-level option. ” Note that these disregarded\nconstraints do not affect the subsequent prediction of high-risk\noption combinations, as the LLM does not consider combinations\ninvolving such options to present vulnerabilities by default.\nTo further assess the robustness of our constraint extraction mod-\nule, we randomly select 20 programs and manually annotate their\ndocuments, totaling about 22,730 words, to calculate recall (See\ndetails in footnote 3). We exclude help and version constraints to\nensure reliability and find 180 constraints as ground truth. Prophet-\nFuzz extracts 148 constraints, with a precision of 97.97% and a recall\nof 80.56%. CarpetFuzz extracts 108 constraints with lower precision\n(77.78%) and recall (46.67%), highlighting ProphetFuzz’s superior\nperformance. ProphetFuzz𝑁𝑆𝐶, evaluated without help and version\nconstraints, extracts 1880 constraints but with only 8.56% precision;\nhowever, its recall is the highest at 89.44%, reflecting the backend\nLLM’s extensive initial extraction of constraints before self-check,\nas expected. Currently, we use a self-check voting threshold of 5,\nwhere higher thresholds improve precision but reduce recall, and\nlower thresholds do the opposite. Future research could aim to\nidentify the optimal threshold for peak performance.\nInteresting finding. Previous work [34] mentions four hidden\nconflicting constraints in img2sixel: -P vs -8, -p vs -e, -p vs -I, and -p\nvs -b. These conflicts are not documented online and typically only\nsurface through error messages when violated. Despite insufficient\nindications, ProphetFuzz successfully identifies two constraints (-p\nversus -e and -p versus -I). Our analysis of the LLM’s extraction pro-\ncess reveals that ProphetFuzz can identify these hidden constraints\nbased on a nuanced understanding of the options’ functionalities.\nFor instance, the LLM infers that “-p has a default value of 256,\nwhich implies it defines the color depth. This might conflict with -e as\nmonochrome means 2 colors. ” This analysis relies on sophisticated\nreasoning capabilities, which traditional heuristic-based constraint\nextraction tools generally fail to handle.\n5.4 Contribution of Self-Check and Few-Shot\nMethods (RQ3)\nThis paper introduces a self-check mechanism and a few-shot\nmethod to boost ProphetFuzz’s predictions. To assess the impact\nof these methods on prediction performance, we implement two\nvariants of ProphetFuzz: ProphetFuzz𝑁𝑆𝐶 (without the self-check\nmechanism in constraint extraction), and ProphetFuzz𝑍𝑆 (zero-shot,\nwithout the few-shot method). We conduct 72-hour fuzz tests on 25\nrandomly selected programs using both variants and the original\nProphetFuzz under the same conditions 4, repeating the process\nfive times. We measure the effectiveness of predicting high-risk\noption combinations by counting the number of combinations that\ntrigger vulnerabilities during the fuzz tests.\nAs shown in Table 3, within these 25 programs, ProphetFuzz\nidentifies 221 high-risk option combinations that triggers vulnerabil-\nities, which is 2.63 times the number identified by ProphetFuzz𝑁𝑆𝐶\n(84 combinations) and 1.44 times that of ProphetFuzz𝑍𝑆 (153 com-\nbinations). This demonstrates that equipping ProphetFuzz with\nboth a self-check mechanism and few-shot methods significantly\n4The experiments in Sections 5.4 and 5.5 were conducted in a different period than\nthose in Sections 5.2 and 5.6. To ensure uniform conditions, we reran ProphetFuzz.\n11\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nenhances its performance in predicting high-risk option combina-\ntions. ProphetFuzz𝑁𝑆𝐶 exhibits the poorest performance, likely due\nto unchecked constraints disrupting the LLM’s reasoning process.\nFor example, in the six programs— cmark, djpeg, gif2png, jasper,\npdftohtml, and pngfix—all options are considered conflicting by\nthe LLM, which prevents it from predicting any high-risk option\ncombinations that met the constraints. This underscores the critical\nimportance of the self-check method. In contrast, ProphetFuzz𝑍𝑆,\nwhich includes the self-check mechanism, performs better than\nProphetFuzz𝑁𝑆𝐶 but is less effective than the fully equipped Prophet-\nFuzz, highlighting the efficacy of the few-shot method.\n5.5 Performance of Out-of-the-Box LLMs in\nPredicting High-Risk Combinations (RQ4)\nTo discuss whether an Out-of-the-Box LLM can effectively predict\nhigh-risk option combinations, we employ GPT-4 turbo—the same\nmodel used in ProphetFuzz—to predict high-risk combinations for\nthe 25 programs selected in Section 5.4. Specifically, we provide the\nsame program documentation used in ProphetFuzz but employ a\nstraightforward prompt: “Please predict the high-risk option com-\nbinations. ”Note that without our carefully designed prompts, the\nOut-of-the-Box LLM lacks the capability for command assembly\nand file generation. To assess its predicted combinations, we pro-\ncess them using our command assembly module and conduct the\nexperiment concurrently with those described in Section 5.4 under\nthe same operational conditions, repeating the process five times.\nTable 3: Results of a 72-hour ablation study on 25 ran-\ndomly selected programs, evaluating the number of vulnera-\nble combinations identified by each configuration: Prophet-\nFuzz, ProphetFuzz𝑁𝑆𝐶 (without the self-check mechanism),\nProphetFuzz𝑍𝑆 (without the few-shot method), and OBLLM\n(Out-of-the-Box LLM with the command assembly module).\nProgram ProphetFuzz Prophet 𝑁𝑆𝐶 Prophet𝑍𝑆 OBLLM\ncflow 34 18 21 25\ncmark 0 - * 0 0\ndjpeg 0 - * 0 0\ndwarfdump 7 1 1 4\neu-elfclassify 0 0 0 0\nexiv2 5 0 4 3\nffmpeg 17 3 9 7\ngif2png 26 - * 27 16\ngm 0 1 0 0\nimg2sixel 24 2 13 2\njasper 0 - * 1 0\njpegoptim 10 6 8 18\njpegtran 1 1 2 0\nlrzip 0 0 0 0\nmutool 6 0 0 4\nnasm 2 1 0 1\nobjdump 13 8 8 13\nopenssl-ec 0 0 0 0\nopenssl-rsa 0 0 0 0\npdftohtml 28 - * 27 30\npdftopng 27 17 15 6\npngfix 0 - * 0 0\nsize 0 0 0 0\ntiffcrop 19 26 13 16\nxmllint 2 0 4 0\nCount 221 84 153 145\n* Fail to predict.\nAs shown in Table 3, the Out-of-the-Box LLM identifies 145\ncombinations that trigger vulnerabilities, showing it also has the\nability to predict high-risk combinations. ProphetFuzz outperforms\nthe Out-of-the-Box LLM, triggering vulnerabilities in 1.52 times\nmore combinations, demonstrating greater predictive effectiveness.\nNotably, ProphetFuzz𝑁𝑆𝐶 triggers only about half as many combi-\nnations, suggesting that removing the self-check mechanism might\ndetract from the LLM’s overall prediction effectiveness. This is\nlikely because unchecked constraints can interfere with reasoning,\nas discussed in Section 5.4. Compared to ProphetFuzz𝑍𝑆, which is\nequipped with self-checked constraints and our CoT prompt but\nlacks AutoCoT-generated few-shot examples, the Out-of-the-Box\nLLM performs slightly worse (145 vs 153). This indicates that veri-\nfied constraints and the CoT prompt enhance the LLM’s ability to\npredict high-risk combinations. Without these enhancements, the\nOut-of-the-Box LLM might incorrectly identify invalid combina-\ntions that violate constraints as high-risk. For instance, injpegoptim,\nthe Out-of-the-Box LLM identifies the combination “-level1 -level2\n-level3” as high-risk, reasoning that “they specify different levels of\nPostScript generation, which may be incompatible or produce conflict-\ning outputs. ” However, despite these advantages, ProphetFuzz𝑍𝑆\ndoes not outperform the Out-of-the-Box LLM as significantly as\nProphetFuzz does, suggesting that without AutoCoT-generated\nfew-shot examples, the LLM learns less about predicting high-risk\noption combinations from the CoT prompt, leading to performance\ncomparable to the Out-of-the-Box LLM.\n5.6 Contribution of Command Assembly (RQ5)\nTo assess the contribution of the command assembly module to\nProphetFuzz’s performance, we conduct ablation experiments on\nthe 25 programs randomly selected in Section 5.4. Specifically, we\ncompare two setups: one in which ProphetFuzz operates without us-\ning generated option values (ProphetFuzz𝑁𝑉) and another without\nusing generated seed files (ProphetFuzz𝑁𝑆). In the ProphetFuzz𝑁𝑉\n’s setup, we utilize default option values from the dataset along\nwith the seeds generated by ProphetFuzz to assemble the predicted\nhigh-risk option combinations. Conversely, ProphetFuzz𝑁𝑆 com-\nbines the seed input files provided by the dataset with option values\ngenerated by ProphetFuzz to assemble commands. Since command\nassembly occurs after prediction, we use end-to-end metrics for\nevaluation, that is, the number of unique vulnerabilities and edge\ncoverage. Each setup is run for 72 hours in the same environment\nand repeated five times. The results are shown in Table 4.\nCompared to ProphetFuzz𝑁𝑉, ProphetFuzz detects 34.65% more\nvulnerabilities and increases edge coverage by 8.21%, indicating\nthat the option values generated by the command assembly module\neffectively enhance ProphetFuzz’s performance. In contrast, com-\npared to ProphetFuzz𝑁𝑆, ProphetFuzz discovers 17.24% more vul-\nnerabilities but only achieves a slight increase in coverage (0.26%).\nThis shows that the seed files from the command assembly module\nmarkedly improve vulnerability detection but only slightly increase\npath coverage across the 25 programs.\nIn xmllint, ProphetFuzz finds notably fewer vulnerabilities than\nProphetFuzz𝑁𝑉, and the problem arises because the default option\nvalues in the dataset incidentally trigger vulnerabilities. The critical\noption associated with these vulnerabilities is “–maxmem”, which\n12\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nTable 4: Results of a 72-hour ablation study on 25 randomly\nselected programs, detailing the number of unique vulnera-\nbilities (#vuls) and edge coverage (#cov.) for each configura-\ntion: ProphetFuzz, ProphetFuzz𝑁𝑉 (without generated option\nvalues) and ProphetFuzz 𝑁𝑆 (without generated seeds).\nProgram ProphetFuzz ProphetFuzz 𝑁𝑉 ProphetFuzz𝑁𝑆\n#vuls #cov #vuls #cov #vuls #cov\ncflow 17 1453 10 1367 12 1445\ncmark 0 7000 0 7739 0 7001\ndjpeg 0 438 0 400 0 416\ndwarfdump 2 7767 4 6958 1 7808\neu-elfclassify 0 213 0 213 0 203\nexiv2 2 8496 1 8128 1 7671\nffmpeg 4 71198 1 65551 2 71667\ngif2png 10 441 10 427 10 440\ngm 0 10172 0 9415 0 8727\nimg2sixel 5 2207 3 2136 7 2440\njasper 0 3416 1 3182 0 2161\njpegoptim 4 244 2 202 4 242\njpegtran 0 5773 0 5662 0 5672\nlrzip 0 4069 0 3941 0 4706\nmutool 1 13118 0 9601 1 16556\nnasm 17 7399 2 6205 11 8331\nobjdump 9 11392 7 11902 6 11050\nopenssl-ec 0 9474 0 9150 0 8420\nopenssl-rsa 0 8034 0 7949 0 7529\npdftohtml 3 5635 3 5611 0 6224\npdftopng 12 4531 11 3653 5 4895\npngfix 0 1058 0 988 0 922\nsize 0 3708 0 3602 0 2842\ntiffcrop 65 6283 48 6038 67 6555\nxmllint 2 12609 8 11764 1 11681\nCount 136 101 116\nis used to specify the maximum number of bytes allocable. We\ndiscover that vulnerabilities are triggered only when the option\nvalue falls within the range of [97406, 103252], and the default\noption value incidentally falls within this range (102400). However,\nthe values generated by ProphetFuzz are to induce memory-related\nabnormal behaviors, which are either too small ( < 10240) or too\nlarge (> 1000000), failing to trigger these vulnerabilities.\n5.7 Zero-day Vulnerablities Discovered (RQ6)\nTo verify ProphetFuzz’s ability to uncover zero-day vulnerabilities,\nwe conduct persistent fuzzing on the latest versions of 52 programs\nin our evaluation dataset. The discovered vulnerabilities represent\nunpatched flaws, potentially qualifying as zero-day or half-day vul-\nnerabilities. As shown in Table 5, ProphetFuzz identifies 140 unique\nvulnerabilities across 15 programs, covering 11 types, including\nheap overflow, stack overflow, use-after-free, and double-free. We\nreport these findings to the developers; 93 are confirmed, 26 fixed,\nand 21 assigned CVE numbers. Notably, after reporting a use-after-\nfree vulnerability to the dwarfdump developers, they express intent\nto include our “nice” test case in their regression tests, underscoring\nthe effectiveness of our command assembly module.\nNext, we analyze specific cases to demonstrate how ProphetFuzz\nsuccessfully identifies these vulnerabilities.\nBad free in editcap. In editcap, a bad-free vulnerability is trig-\ngered by combining “–inject-secrets <secrets type>,<file>” with “-c”.\nProphetFuzz extracts constraints from the documentation (e.g., -c\nconflicts with -i) to guide the LLM in avoiding invalid combinations.\nDuring the prediction process, ProphetFuzz notes, “Combining the\nerror introduction (-E) with other packet modification operations may\nlead to unexpected memory states, ” and flags the combination of\n–inject-secrets, -E, and -c as high-risk. It then assignes values to\nthese options and generates the necessary configuration and input\nfiles. Notably, the configuration file for –inject-secrets must adhere\nto the strict format specifications of the NSS key log. Despite this\ncomplexity, ProphetFuzz successfully generates the file by leverag-\ning its built-in knowledge. This enables ProphetFuzz to identify the\nvulnerability during fuzz testing.\nBuffer overflow in jpegtran. In jpegtran, a buffer overflow is\ntriggered by the “-drop +X+Y filename” option, which inserts an\nimage at specified coordinates. After extracting constraints and\navoiding invalid option combinations, ProphetFuzz identifies -drop\nwith -maxmemory as high-risk, noting: “The -drop option could be\nsensitive to buffer overflows if the dropped image’s dimensions or en-\ncoding parameters cause unexpected memory usage. ” Notably, X and\nY represent the coordinates in the input image where another im-\nage is to be inserted. If the new image’s dimensions exceed those of\nthe input image, the program reports an“Invalid crop request” error\nand exits. Leveraging the LLM’s understanding of documentation,\nProphetFuzz assigns values of 10 and 20 toX and Y, and generates a\n50x50 configuration file along with a 100x100 seed file to ensure the\nprogram could operate correctly. These configurations ultimately\nhelp discover this buffer overflow vulnerability.\n5.8 Predictive Knowledge (RQ7)\nTo understand how ProphetFuzz, without any expert intervention,\nmanages to predict 1748 high-risk option combinations solely from\nprogram documentation, we record the complete CoT outputs from\nthe LLM during each prediction. Initially, we extract content di-\nrectly related to the predictions, focusing on the fourth step of the\nprompt. We then instruct the LLM to “summarize the knowledge\nof the categories of program option combinations that may have po-\ntential vulnerabilities. ” Subsequently, we compile summaries for\neach program, have the LLM synthesize these summaries and rank\nthem from most to least common. To make the results more under-\nstandable, we set the context in the prompt: “For software testers\nwho do not understand security, they hope to have easy-to-understand\nknowledge to conduct efficient security testing. ” Finally, we capture\n15 key pieces of knowledge crucial for predicting high-risk option\ncombinations. The top three are detailed below (see footnote 3 for\na complete list).\n1. Resource Management and Limits . Options that affect\nresource allocation and limits can lead to vulnerabilities when they\nconflict with options that increase resource demands, potentially\ncausing resource exhaustion or buffer overflows.\n2. Complex Data Processing . Combinations of options that\nlead to complex data processing tasks can increase the risk of vul-\nnerabilities such as memory corruption, especially when involving\nexternal data or detailed output formatting.\n3. Output and Format Manipulation . Options that modify\noutput verbosity or format can lead to vulnerabilities if they result\nin excessive data being processed or displayed, potentially revealing\nsensitive information or causing buffer overflows.\n13\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nTable 5: Vulnerabilities identified by ProphetFuzz. All these\nvulnerabilities were found in the latest versions of the pro-\ngrams, indicating that they are either zero-day or half-day\nvulnerabilities.\nProgram Vulnerability Type Count #Fixed #CVEs\navconv assertion failure 1 0 0\navconv floating point exception 1 0 0\navconv global-buffer-overflow 1 0 0\navconv heap-buffer-overflow 21 0 0\navconv segmentation violation 6 0 0\navconv use-after-free 1 0 0\nbison segmentation violation 10 0 + 0\nc++filt stack-buffer-overflow 12 0 + 0\ncflow global-buffer-overflow 1 0 0\ncflow use-after-free 2 0 0\ndwarfdump use-after-free 1 1 1\neditcap bad free 2 2 1\neditcap heap-buffer-overflow 1 1 1\neditcap segmentation violation 1 1 0 *\nffmpeg floating point exception 2 1 + 1\nffmpeg segmentation violation 3 2 2\nimg2sixel floating point exception 2 0 0\nimg2sixel heap-buffer-overflow 1 0 0\nimg2sixel segmentation violation 1 0 0\nimg2sixel use-after-free 1 0 0\njasper assertion failure 1 1 1\njpegtran segmentation violation 1 1 0 *\nmupdf negative-size-param 1 1 1\nmupdf segmentation violation 1 1 1\nnasm segmentation violation 4 0 0\nnasm use-after-free 3 0 0\nobjdump heap-buffer-overflow 2 1 1\npspp assertion failure 29 8 + 6\npspp bus on unknown address 1 0 + 0\npspp double-free 1 0 + 0\npspp heap-buffer-overflow 3 0 + 0\npspp segmentation violation 13 4 + 4\npspp stack-buffer-overflow 5 0 + 0\npspp use-after-free 3 0 + 0\nxpdf stack-buffer-overflow 1 1 1\nCount 140 26 21\n+ Have been confirmed by the developers.\n* Applying for CVE.\n6 Limitation and Future Work\nWhile ProphetFuzz demonstrates impressive performance in our\nevaluation experiments, it still has some limitations. In some pro-\ngrams, the precision of constraint extraction by ProphetFuzz is\nunsatisfactory primarily because its constraint extraction module\nheavily relies on the LLM’s reasoning performance. When the LLM\nunderperforms, ProphetFuzz’s performance is correspondingly af-\nfected. With the continuous advancements in LLM technology,\nwe expect ProphetFuzz’s performance to improve. Additionally,\nProphetFuzz solely relies on documentation for predictions, which\nis both a strength and a limitation. When documentation is incor-\nrect or missing, it becomes difficult for ProphetFuzz to perform\nconstraint extraction, target prediction, or command assembly. In\nthe future, we aim to enable ProphetFuzz to reference additional\nsources of information, such as code comments and the code itself.\nMoreover, despite ProphetFuzz achieving full automation in pre-\ndicting and fuzzing high-risk option combinations, the historical\nhigh-risk option combinations used to generate few-shot corpora\nare manually collected. Note that it is a one-time job, and we have\nmade all these combinations publicly available, ensuring that the\nprocess does not need to be repeated. For complex multi-option\nconstraints, the ideal approach is to split them into pairwise option\nconstraints for self-checks, which provides the highest precision\nbut would significantly increase the number of LLM queries. For\ncost considerations, ProphetFuzz instructs the LLM to evaluate the\nentire multi-option constraint in a single inference. While this ap-\nproach is more cost-effective, it may confuse the LLM’s analysis\nprocess and introduce incorrect constraints.\nIn a few programs, the high-risk option combinations predicted\nby ProphetFuzz do not achieve satisfactory results. On the one hand,\nthis is because ProphetFuzz primarily focuses on mutating input\nfiles, whereas for some programs (e.g., vim), mutating configura-\ntion files might yield better outcomes. To address this, we plan to\nenable the LLM to autonomously choose the most suitable target\nfor mutation in future versions. On the other hand, although we\ndesign an automated few-shot corpus collection method that gen-\nerates the analysis examples for predicting some high-risk option\ncombinations without expert involvement, real expert experience\nmay still provide more effective learning outcomes for the LLM.\nTherefore, we intend to involve security experts to conduct a deeper\nanalysis of the prediction of high-risk option combinations, aiming\nto produce a higher-quality corpus.\nAdditionally, ProphetFuzz currently focuses only on predicting\nhigh-risk option combinations that lead to memory crash vulnera-\nbilities, aligning with the characteristics of fuzzers. By adjusting the\nprompts, ProphetFuzz can also be adapted to predict other types\nof vulnerabilities, such as multithreading and undefined behavior\nerrors, in future implementations.\n7 Conclusion\nThis paper introduces ProphetFuzz, a fully automated tool based\non large language models (LLM) specifically designed to predict\nhigh-risk option combinations and conduct fuzz testing. Benefiting\nfrom our thoughtfully engineered prompts and the LLM’s superior\ntext comprehension and reasoning capabilities, ProphetFuzz suc-\ncessfully predicts 1748 high-risk option combinations on a dataset\ncovering 52 programs, leading to the discovery of 364 unique vul-\nnerabilities, which is 32.85% more effective than the previous work.\nAdditionally, ProphetFuzz identifies 140 zero-day or half-day vulner-\nabilities in the latest versions of these programs, with 93 confirmed\nby developers and 21 awarded CVE numbers.\nAcknowledgement\nWe are grateful to our shepherd and the anonymous reviewers for\ntheir valuable guidance and insightful comments.\nReferences\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-\ncia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal\nAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774\n(2023).\n[2] Omer Akgul, Taha Eghtesad, Amit Elazari, Omprakash Gnawali, Jens Grossklags,\nMichelle L Mazurek, Daniel Votipka, and Aron Laszka. 2023. Bug {Hunters’}\nPerspectives on the Challenges and Benefits of the Bug Bounty Ecosystem. In\n32nd USENIX Security Symposium (USENIX Security 23). 2275–2291.\n[3] Marcel Böhme, Van-Thuan Pham, and Abhik Roychoudhury. 2017. Coverage-\nBased Greybox Fuzzing as Markov Chain. IEEE Transactions on Software\nEngineering 45, 5 (2017), 489–506.\n[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\n14\nProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations\nwith Only Documentation via Large Language Model\nAskell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877–1901.\n[5] Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, and Lingming\nZhang. 2023. Large language models are zero-shot fuzzers: Fuzzing deep-learning\nlibraries via large language models. In Proceedings of the 32nd ACM SIGSOFT\ninternational symposium on software testing and analysis. 423–435.\n[6] Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang,\nShujing Yang, and Lingming Zhang. 2024. Large language models are edge-\ncase generators: Crafting unusual programs for fuzzing deep learning libraries.\nIn Proceedings of the 46th IEEE/ACM International Conference on Software\nEngineering. 1–13.\n[7] Dor1s. 2019. Testcase of pdf. https://github.com/google/AFL/blob/master/test\ncases/others/pdf/small.pdf\n[8] Jueon Eom, Seyeon Jeong, and Taekyoung Kwon. 2024. CovRL: Fuzzing JavaScript\nEngines with Coverage-Guided Reinforcement Learning for LLM-based Mutation.\narXiv preprint arXiv:2402.12222 (2024).\n[9] Andrea Fioraldi, Dominik Maier, Heiko Eißfeldt, and Marc Heuse. 2020. AFL++:\nCombining Incremental Steps of Fuzzing Research. In 14th USENIX Workshop\non Offensive Technologies (WOOT 20). USENIX Association.\n[10] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022.\nComplexity-based prompting for multi-step reasoning. In The Eleventh\nInternational Conference on Learning Representations.\n[11] Google. 2019. Fuzzing with afl-fuzz. https://afl-1.readthedocs.io/en/latest/fuz\nzing.html\n[12] Jie Hu, Qian Zhang, and Heng Yin. 2023. Augmenting greybox fuzzing with\ngenerative ai. arXiv preprint arXiv:2306.06782 (2023).\n[13] Shima Imani, Liang Du, and Harsh Shrivastava. 2023. Mathprompter: Mathe-\nmatical reasoning using large language models. arXiv preprint arXiv:2303.05398\n(2023).\n[14] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei, and Michael Hicks. 2018.\nEvaluating fuzz testing. In Proceedings of the 2018 ACM SIGSAC conference on\ncomputer and communications security. 2123–2138.\n[15] Ahcheong Lee, Irfan Ariq, Yunho Kim, and Moonzoo Kim. 2022. Power: Program\noption-aware fuzzer for high bug detection ability. In 2022 IEEE Conference on\nSoftware Testing, Verification and Validation (ICST). IEEE, 220–231.\n[16] Caroline Lemieux, Jeevana Priya Inala, Shuvendu K Lahiri, and Siddhartha Sen.\n2023. Codamosa: Escaping coverage plateaus in test generation with pre-trained\nlarge language models. In 2023 IEEE/ACM 45th International Conference on\nSoftware Engineering (ICSE). IEEE, 919–931.\n[17] LMSYS. 2024. LMSYS Chatbot Arena Leaderboard in March 13, 2024. https:\n//huggingface.co/spaces/lmsys/chatbot-arena-leaderboard\n[18] Xiaoliang Luo, Akilles Rechardt, Guangzhi Sun, Kevin K Nejad, Felipe Yáñez,\nBati Yilmaz, Kangjoo Lee, Alexandra O Cohen, Valentina Borghesani, Anton\nPashkov, et al. 2024. Large language models surpass human experts in predicting\nneuroscience results. arXiv preprint arXiv:2403.03230 (2024).\n[19] Yunlong Lyu, Yuxuan Xie, Peng Chen, and Hao Chen. 2023. Prompt Fuzzing for\nFuzz Driver Generation. arXiv preprint arXiv:2312.17677 (2023).\n[20] Ruijie Meng, Martin Mirchev, Marcel Böhme, and Abhik Roychoudhury. 2024.\nLarge language model guided protocol fuzzing. InProceedings of the 31st Annual\nNetwork and Distributed System Security Symposium (NDSS).\n[21] Timothy Nosco, Jared Ziegler, Zechariah Clark, Davy Marrero, Todd Finkler,\nAndrew Barbarello, and W Michael Petullo. 2020. The industrial age of hacking.\nIn 29th USENIX Security Symposium (USENIX Security 20). 1129–1146.\n[22] Yaroslav Oliinyk, Michael Scott, Ryan Tsang, Chongzhou Fang, Houman Homay-\noun, et al. 2024. Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embed-\nded Bug Unearthing. arXiv preprint arXiv:2403.03897 (2024).\n[23] OpenAI. 2023. GPT-4V(ision) System Card.\n[24] OpenAI. 2024. API Reference - OpenAI API. https://platform.openai.com/docs\n/api-reference/audio\n[25] Chengbin Pang, Tiantai Zhang, Xuelan Xu, Linzhang Wang, and Bing Mao.\n2023. OCFI: Make Function Entry Identification Hard Again. In Proceedings\nof the 32nd ACM SIGSOFT International Symposium on Software Testing and\nAnalysis. 804–815.\n[26] Anthropic PBC. 2024. Introducing the next generation of Claude. https:\n//www.anthropic.com/news/claude-3-family\n[27] LLVM Project. 2024. libFuzzer – a library for coverage-guided fuzz testing.\nhttps://llvm.org/docs/LibFuzzer.html\n[28] Reingart. 2018. FPDF for Python. https://pyfpdf.readthedocs.io/en/latest/\n[29] Suhwan Song, Chengyu Song, Yeongjin Jang, and Byoungyoung Lee. 2020. Cr-\nFuzz: Fuzzing multi-purpose programs through input validation. In Proceedings\nof the 28th ACM Joint Meeting on European Software Engineering Conference\nand Symposium on the Foundations of Software Engineering. 690–700.\n[30] Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste\nAlayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth,\net al. 2023. Gemini: a family of highly capable multimodal models.arXiv preprint\narXiv:2312.11805 (2023).\n[31] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-\nmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-\nale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv\npreprint arXiv:2307.09288 (2023).\n[32] Trieu H Trinh, Yuhuai Wu, Quoc V Le, He He, and Thang Luong. 2024. Solving\nolympiad geometry without human demonstrations. Nature 625, 7995 (2024),\n476–482.\n[33] Daniel Votipka, Rock Stevens, Elissa Redmiles, Jeremy Hu, and Michelle Mazurek.\n2018. Hackers vs. testers: A comparison of software vulnerability discovery\nprocesses. In 2018 IEEE Symposium on Security and Privacy (SP). IEEE, 374–\n391.\n[34] Dawei Wang, Ying Li, Zhiyu Zhang, and Kai Chen. 2023. {CarpetFuzz}: Auto-\nmatic Program Option Constraint Extraction from Documentation for Fuzzing.\nIn 32nd USENIX Security Symposium (USENIX Security 23). 1919–1936.\n[35] Zi Wang, Ben Liblit, and Thomas Reps. 2020. Tofu: Target-oriented fuzzer.arXiv\npreprint arXiv:2004.14375 (2020).\n[36] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,\nQuoc V Le, Denny Zhou, et al . 2022. Chain-of-thought prompting elicits rea-\nsoning in large language models. Advances in neural information processing\nsystems 35 (2022), 24824–24837.\n[37] Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, and Ling-\nming Zhang. 2024. Fuzz4all: Universal fuzzing with large language mod-\nels. Proceedings of the 46th IEEE/ACM International Conference on Software\nEngineering (2024).\n[38] Xuhai Xu, Bingsheng Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James\nHendler, Marzyeh Ghassemi, Anind K Dey, and Dakuo Wang. 2024. Mental-LLM:\nLeveraging Large Language Models for Mental Health Prediction via Online Text\nData. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous\nTechnologies 8, 1 (2024), 1–32.\n[39] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou,\nand Xinyun Chen. 2023. Large language models as optimizers. arXiv preprint\narXiv:2309.03409 (2023).\n[40] Chenyuan Yang, Zijie Zhao, and Lingming Zhang. 2023. KernelGPT: Enhanced\nKernel Fuzzing via Large Language Models. arXiv preprint arXiv:2401.00563\n(2023).\n[41] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting\nHuang, Enbo Zhao, Yu Zhang, Yulong Chen, et al . 2023. Siren’s song in the\nAI ocean: a survey on hallucination in large language models. arXiv preprint\narXiv:2309.01219 (2023).\n[42] Yunhang Zhang, Chengbin Pang, Stefan Nagy, Xun Chen, and Jun Xu.\n2023. Profile-guided System Optimizations for Accelerated Greybox Fuzzing.\nIn Proceedings of the 2023 ACM SIGSAC Conference on Computer and\nCommunications Security. 1257–1271.\n[43] Zenong Zhang, George Klees, Eric Wang, Michael Hicks, and Shiyi Wei. 2023.\nFuzzing configurations of program options. ACM Transactions on Software\nEngineering and Methodology 32, 2 (2023), 1–21.\nAppendix\nA Prompts for Code Assembly\nFigure 6 shows the prompt for code assembly.\nB Recall for 20 Randomly Selected Programs\nTable 6 shows the precision and recall for Constraint Extraction by\nProphetFuzz, CarpetFuzz, and ProphetFuzz𝑁𝑆𝐶 from Documenta-\ntion of 20 Randomly Selected Programs.\nC Complete List of Predictive Knowledge\nThe complete list of the extracted 15 pieces of knowledge used by\nProphetFuzz to predict high-risk option combinations is as follows:\n1. Resource Management and Limits . Options that affect re-\nsource allocation and limits can lead to vulnerabilities when they\nconflict with options that increase resource demands, potentially\ncausing resource exhaustion or buffer overflows.\n2. Complex Data Processing . Combinations of options that lead\nto complex data processing tasks can increase the risk of vulner-\nabilities such as memory corruption, especially when involving\nexternal data or detailed output formatting.\n3. Output and Format Manipulation . Options that modify out-\nput verbosity or format can lead to vulnerabilities if they result\n15\nDawei Wang, Geng Zhou, Li Chen, Dan Li, and Yukai Miao\nHere is the document of [Program name],```{“name”:[Program name], “description”: [Program description], “options”:[Option descriptions], “synopsis”: [Synopsis]}```Instructions: 1. Assemble all [Options in target combination] to create a singular, exclusive command as directed by the \"synopsis\" field.2. Pinpoint options that require values by reviewing their descriptions in the \"options\" field and confirming with the \"synopsis\" field. 3.Comprehend the combination's intent and generate valid values for these options.4. Replace all placeholders in your command with actual, specific values. When in doubt, opt for credible hypothetical values out of thin air. 5. Use the 'file0' placeholder to indicate the input file path in your command. Since fuzzerswork with one file at a time, ensure you're only using one input file. For other options that require an existing file, utilize placeholders like 'file1', 'file2', etc., without altering them.6.Check that each file placeholder is correctly used in your command. Remove any placeholders that don't correspond to actual files.\nPrompt for Assembly…7. Develop a Python script to generate each specified file placeholder out of thin air. Follow these instructions:1. Identify the format of the target files. For handling files with complex formats (e.g., binary files), it's advisable to use Python libraries you're familiar with, or to integrate external tools using the 'subprocess' module, to create the most suitable files.2. Carefully consider content constraints, guaranteeing their semantic coherence with other defined option values. Notably, the 'file0' placeholder should act as an initial seed for fuzzing processes, representing a minimal yet valid test case while ensuring the most extensive feature exposure possible. Under 1 kB is ideal, although not strictly necessary.3. Replace all placeholders with specific, pre-determined values. Avoid using any vague placeholders or dummy file that necessitate user input. 4. Name each created file using the format '{placeholder}.{extension}’.OutputFormat:Provide the final resultof commands in JSON format. Provide the Python script in a markdown code block behind the JSON results.Let's take a deep breath and think step by step. Please show your thoughts in each step.\nPrompt for FileGeneration\nFigure 6: Prompts for assembly and file generation. The content enclosed in brackets denotes the need for specific input.\nTable 6: Precision ( Prec.) and Recall ( Rec.) for Constraint Ex-\ntraction by ProphetFuzz, CarpetFuzz, and ProphetFuzz 𝑁𝑆𝐶\nfrom Documentation of 20 Randomly Selected Programs.\nProgram ProphetFuzz CarpetFuzz ProphetFuzz 𝑁𝑆𝐶\nPrec. Rec. Prec. Rec. Prec. Rec.\ncjpeg 100.0% 80.0% 50.0% 40.0% 2.1% 100.0%\ncmark 100.0% 50.0% 100.0% 50.0% 11.1% 100.0%\ndjpeg 100.0% 74.3% 95.5% 60.0% 7.3% 77.1%\nexiv2 100.0% 80.0% 50.0% 20.0% 8.5% 80.0%\ngif2png 100.0% 100.0% 0.0% 0.0% 1.4% 100.0%\nimg2sixel 87.5% 87.5% 100.0% 62.5% 9.2% 100.0%\nlrzip 100.0% 100.0% 100.0% 41.2% 7.6% 100.0%\nopenssl-asn1parse 100.0% 25.0% 100.0% 50.0% 4.0% 100.0%\nopenssl-ec 100.0% 100.0% 100.0% 60.0% 7.5% 100.0%\npdftopng 100.0% 50.0% 20.0% 50.0% 66.7% 100.0%\npdftotext 100.0% 94.1% 22.2% 11.8% 6.6% 100.0%\npodofoencrypt 100.0% 100.0% 100.0% 33.3% 14.3% 100.0%\npspp 100.0% 77.8% 0.0% 0.0% 11.2% 100.0%\nsize 90.0% 69.2% 100.0% 92.3% 90.9% 76.9%\nspeexdec 100.0% 100.0% 45.5% 50.0% 19.2% 100.0%\ntcpprep 100.0% 88.9% 100.0% 77.8% 100.0% 88.9%\ntiff2ps 87.5% 58.3% 62.5% 41.7% 33.3% 58.3%\ntiffinfo 100.0% 100.0% 0.0% 0.0% 33.3% 100.0%\nxmlwf 100.0% 70.0% 0.0% 0.0% 8.1% 100.0%\nyara 100.0% 100.0% 100.0% 100.0% 2.1% 100.0%\nOverall 97.97% 80.56% 77.78% 46.67% 8.56% 89.44%\nin excessive data being processed or displayed, potentially re-\nvealing sensitive information or causing buffer overflows.\n4. Error Handling Modifications . Options that suppress or alter\nerror handling can hide underlying issues, allowing the pro-\ngram to operate in an unstable state and increasing the risk of\nvulnerabilities.\n5. Conflicting Operations . Using options that perform oppos-\ning actions can lead to undefined behavior or race conditions,\npotentially causing the software to enter an unstable state.\n6. Input/Output Handling . Options that affect how input and\noutput are handled can lead to vulnerabilities if they cause the\nprogram to read or write outside of intended memory areas or\nhandle file operations insecurely.\n7. Concurrency and Parallel Processing . Options that enable\nmulti-threading or parallel processing can introduce vulnerabil-\nities such as race conditions if combined with options that are\nnot thread-safe.\n8. Verbose and Debugging Modes . Increasing the verbosity of\nthe program’s output or enabling debugging modes can inad-\nvertently expose vulnerabilities by providing more data to an\nattacker or changing the timing and performance characteristics\nof the application.\n9. Security Thresholds and Protections . Options that set se-\ncurity thresholds can lead to vulnerabilities when incorrectly\nconfigured or combined with complex XML structures, as they\nmay not protect sufficiently or cause legitimate processing to\nfail.\n10. External Data and Variable Definition . Allowing external\ndata input or variable definition can lead to vulnerabilities when\ncombined with options that do not properly sanitize or handle\nthis external input.\n11. Transformation and Canonicalization . Transforming input\ninto detailed or canonical forms can increase the complexity\nof processing, leading to vulnerabilities due to the increased\ncomplexity of the output.\n12. Specialized Processing Modules . Passing data to specialized\nprocessing modules can lead to vulnerabilities if the modules do\nnot properly handle the data, especially when combined with\noptions that modify data handling.\n13. Scan Optimization. Optimizing scanning for performance can\nlead to vulnerabilities when it conflicts with thorough scanning\nrequired for security, potentially missing critical checks.\n14. Memory-Intensive Operations . Combining options that are\ninherently memory-intensive can lead to vulnerabilities, espe-\ncially if they are not properly optimized for memory usage,\npotentially resulting in memory leaks or corruption.\n15. Control Flow Alteration . Changing the program’s control\nflow with certain options can lead to vulnerabilities when com-\nbined with extensive processing options, potentially leading to\nincorrect processing or logic bypass.\n16",
  "topic": "Fuzz testing",
  "concepts": [
    {
      "name": "Fuzz testing",
      "score": 0.9879465699195862
    },
    {
      "name": "Computer science",
      "score": 0.759253978729248
    },
    {
      "name": "Documentation",
      "score": 0.6478835344314575
    },
    {
      "name": "Software testing",
      "score": 0.4464053809642792
    },
    {
      "name": "Software",
      "score": 0.3909217119216919
    },
    {
      "name": "Software engineering",
      "score": 0.3714454174041748
    },
    {
      "name": "Machine learning",
      "score": 0.3548122048377991
    },
    {
      "name": "Programming language",
      "score": 0.15863633155822754
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I99065089",
      "name": "Tsinghua University",
      "country": "CN"
    }
  ],
  "cited_by": 3
}