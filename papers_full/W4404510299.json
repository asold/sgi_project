{
  "title": "Optimizing Transformer Models for Resource-Constrained Environments: A Study on Model Compression Techniques",
  "url": "https://openalex.org/W4404510299",
  "year": 2023,
  "authors": [
    {
      "id": "https://openalex.org/A5101342051",
      "name": "Ziqian Luo",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5046375343",
      "name": "Hao Yan",
      "affiliations": [
        null
      ]
    },
    {
      "id": "https://openalex.org/A5032937271",
      "name": "Xueting Pan",
      "affiliations": [
        null
      ]
    }
  ],
  "references": [
    "https://openalex.org/W6739901393",
    "https://openalex.org/W4386630900",
    "https://openalex.org/W2977580351",
    "https://openalex.org/W6601204288",
    "https://openalex.org/W6606511648",
    "https://openalex.org/W2903795704",
    "https://openalex.org/W4308432368",
    "https://openalex.org/W4220788456",
    "https://openalex.org/W3026367556",
    "https://openalex.org/W3085208059",
    "https://openalex.org/W2998183051",
    "https://openalex.org/W3209824846",
    "https://openalex.org/W6803508786",
    "https://openalex.org/W4287503054",
    "https://openalex.org/W4309793872",
    "https://openalex.org/W3121523901",
    "https://openalex.org/W3114566572",
    "https://openalex.org/W3116489684",
    "https://openalex.org/W3194959296",
    "https://openalex.org/W4226484461",
    "https://openalex.org/W3205764742",
    "https://openalex.org/W4365446402",
    "https://openalex.org/W6797854001",
    "https://openalex.org/W2916954108",
    "https://openalex.org/W6796870316",
    "https://openalex.org/W3168124404",
    "https://openalex.org/W2984765336",
    "https://openalex.org/W4401154288",
    "https://openalex.org/W6600336842",
    "https://openalex.org/W4400366382",
    "https://openalex.org/W4393212691",
    "https://openalex.org/W4397020179",
    "https://openalex.org/W4401498546",
    "https://openalex.org/W4388186135",
    "https://openalex.org/W4387109367",
    "https://openalex.org/W4387968528",
    "https://openalex.org/W3093733835",
    "https://openalex.org/W4382318179",
    "https://openalex.org/W4388857839",
    "https://openalex.org/W3176080685",
    "https://openalex.org/W4308414048"
  ],
  "abstract": "Recent progress in computer vision has been driven by transformer-based models, which consistently outperform traditional methods across various tasks. However, their high computational and memory demands limit their use in resource-constrained environments. This research addresses these challenges by investigating four key model compression techniques: quantization, low-rank approximation, knowledge distillation, and pruning. We thoroughly evaluate the effects of these techniques, both individually and in combination, on optimizing transformers for resource-limited settings. Our experimental findings show that these methods can successfully strike a balance between accuracy and efficiency, enhancing the feasibility of transformer models for edge computing.",
  "full_text": null,
  "topic": "Transformer",
  "concepts": [
    {
      "name": "Transformer",
      "score": 0.5976477861404419
    },
    {
      "name": "Computer science",
      "score": 0.5726917386054993
    },
    {
      "name": "Engineering",
      "score": 0.19395551085472107
    },
    {
      "name": "Electrical engineering",
      "score": 0.09617266058921814
    },
    {
      "name": "Voltage",
      "score": 0.08144575357437134
    }
  ]
}