{
  "title": "Tweet Sentiment Extraction Using Byte Level Pretrained Language Modelâˆ—",
  "url": "https://openalex.org/W4283259268",
  "year": 2022,
  "authors": [
    {
      "id": "https://openalex.org/A2115876288",
      "name": "Haowei Liu",
      "affiliations": [
        "Engineering Systems (United States)",
        "Viterbo University"
      ]
    },
    {
      "id": "https://openalex.org/A4283291304",
      "name": "Enhao Tan",
      "affiliations": [
        "Beijing University of Posts and Telecommunications"
      ]
    }
  ],
  "references": [
    "https://openalex.org/W2896457183",
    "https://openalex.org/W2252215182",
    "https://openalex.org/W2089065004",
    "https://openalex.org/W2979860911",
    "https://openalex.org/W2615624292",
    "https://openalex.org/W2401379394",
    "https://openalex.org/W3020571278",
    "https://openalex.org/W2965373594",
    "https://openalex.org/W2979771119",
    "https://openalex.org/W2015525779",
    "https://openalex.org/W3198194255",
    "https://openalex.org/W2895715183"
  ],
  "abstract": "Research on sentiment analysis developed rapidly in recent years, and twitter sentiment analysis is one of the most popular topics. Besides classifying the sentiment, it is also important to find out the decisive phrases or words of the text to the classified sentimental category. In this paper, we proposed and developed byte-level pretained RoBERTa models, they are designed to extract phrases from tweet data with sentiment labels. We compared RoBERTa model and its' variants, including RoBERTa-base, RoBERTa-large, XLM-RoBERTa-base, and RoBERTa-large-mnli. We build the model with RoBERTa model and CNN, then train the model with given tweet text and sentiment labels so that the deciding phrases of sentiments can be predicted. Our results show that RoBERTa-base obtains Jaccard score of 0.712 and training time of 240 minutes in total, which is the best performance among all the models.",
  "full_text": null,
  "topic": "Computer science",
  "concepts": [
    {
      "name": "Computer science",
      "score": 0.8122415542602539
    },
    {
      "name": "Byte",
      "score": 0.753341019153595
    },
    {
      "name": "Extraction (chemistry)",
      "score": 0.5897932052612305
    },
    {
      "name": "Language model",
      "score": 0.5575672388076782
    },
    {
      "name": "Artificial intelligence",
      "score": 0.5365545749664307
    },
    {
      "name": "Natural language processing",
      "score": 0.5319063663482666
    },
    {
      "name": "Programming language",
      "score": 0.18915632367134094
    },
    {
      "name": "Chromatography",
      "score": 0.0
    },
    {
      "name": "Chemistry",
      "score": 0.0
    }
  ],
  "institutions": [
    {
      "id": "https://openalex.org/I4210116219",
      "name": "Engineering Systems (United States)",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I144571360",
      "name": "Viterbo University",
      "country": "US"
    },
    {
      "id": "https://openalex.org/I139759216",
      "name": "Beijing University of Posts and Telecommunications",
      "country": "CN"
    }
  ]
}